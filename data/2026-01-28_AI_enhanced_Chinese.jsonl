{"id": "2601.18833", "pdf": "https://arxiv.org/pdf/2601.18833", "abs": "https://arxiv.org/abs/2601.18833", "authors": ["Marlon Dumas", "Fredrik Milani", "David Chapela-Campa"], "title": "Agentic Business Process Management Systems", "categories": ["cs.AI", "cs.SE"], "comment": "Presented at the BPM'2025 conference on Artificial Intelligence for Business Process Management (AI4BPM)", "summary": "Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.", "AI": {"tldr": "这篇立场论文提出基于Agentic AI的自主业务流程管理系统(A-BPMS)，通过过程挖掘技术实现从自动化到自主性的转变，支持从人工驱动到完全自主的连续流程管理。", "motivation": "生成式AI和Agentic AI的兴起为BPM领域带来了新的技术浪潮，需要从传统的自动化转向自主性，从设计驱动转向数据驱动的流程管理。", "method": "基于过程挖掘技术建立基础架构，使智能体能够感知流程状态、推理改进机会并采取行动优化性能，提出A-BPMS的架构愿景。", "result": "提出了一种新型平台架构，将自主性、推理和学习能力整合到流程管理和执行中，重新定义了流程自动化和治理的边界。", "conclusion": "Agentic BPM系统将彻底改变业务流程管理范式，通过AI驱动的自主决策和持续优化，实现更智能、自适应的业务流程运营模式。"}}
{"id": "2601.18846", "pdf": "https://arxiv.org/pdf/2601.18846", "abs": "https://arxiv.org/abs/2601.18846", "authors": ["Urban Skvorc", "Niki van Stein", "Moritz Seiler", "Britta Grimme", "Thomas Bäck", "Heike Trautmann"], "title": "LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties", "categories": ["cs.AI", "cs.NE"], "comment": "17 pages, accepted at EvoApplications 2026", "summary": "Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.", "AI": {"tldr": "该研究探索使用大语言模型在进化循环中生成具有明确高层景观特征的优化问题，通过ELA属性预测器评估候选问题，并引入ELA空间适应度共享机制增加多样性，最终创建了一个广泛、可解释且可复现的基准问题库。", "motivation": "现有基准测试套件（如BBOB）的结构多样性有限，阻碍了连续黑盒优化的基准测试发展，需要创建具有明确景观特征的新型优化问题。", "method": "使用LLaMEA框架，通过自然语言描述目标属性引导LLM生成问题代码，在循环中使用ELA属性预测器评分候选问题，并引入ELA空间适应度共享机制增加种群多样性。", "result": "生成的许多函数确实展现出预期的结构特征，t-SNE嵌入显示它们扩展了BBOB实例空间而非形成无关簇群。", "conclusion": "研究成功创建了一个广泛、可解释且可复现的基准问题库，为景观分析和自动化算法选择等下游任务提供了丰富的测试资源。"}}
{"id": "2601.18897", "pdf": "https://arxiv.org/pdf/2601.18897", "abs": "https://arxiv.org/abs/2601.18897", "authors": ["Qusai Khaled", "Bahjat Mallak", "Uzay Kaymak", "Laura Genga"], "title": "Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to 21st International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2026)", "summary": "Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.", "AI": {"tldr": "本研究开发了一种区间类型2自适应神经模糊推理系统(IT2-ANFIS)，用于污水处理厂的能耗预测，提供可解释的不确定性量化，而不仅仅是点预测。", "motivation": "污水处理厂消耗全球1-3%的电力，准确的能源预测对运营优化和可持续性至关重要。现有机器学习模型缺乏可解释的不确定性量化，这在安全关键基础设施的风险感知决策中必不可少。", "method": "采用区间类型2自适应神经模糊推理系统(IT2-ANFIS)，通过模糊规则结构生成可解释的预测区间。该方法在三个层次上分解不确定性：特征级、规则级和实例级。", "result": "在墨尔本水务东部处理厂数据集上验证，IT2-ANFIS实现与一阶ANFIS相当的预测性能，同时显著减少训练运行的方差，并提供可解释的不确定性估计。", "conclusion": "IT2-ANFIS框架为污水处理厂能源管理提供了既准确又具有可解释不确定性量化的解决方案，将预测置信度直接与运营条件和输入变量联系起来。"}}
{"id": "2601.18924", "pdf": "https://arxiv.org/pdf/2601.18924", "abs": "https://arxiv.org/abs/2601.18924", "authors": ["Andrew Jaffe", "Noah Reicin", "Jinho D. Choi"], "title": "RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures", "categories": ["cs.AI"], "comment": "13 pages, 5 figures, submitted to ACL ARR", "summary": "Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.", "AI": {"tldr": "RIFT基准测试揭示了大语言模型在指令顺序变化时性能显著下降，表明当前模型过度依赖顺序模式而非推理能力，对需要非顺序控制流的应用构成根本性限制。", "motivation": "现有基准测试混淆了任务复杂度和结构顺序，难以分离提示结构对性能的影响，需要专门工具来评估LLMs在指令跟随中的结构敏感性。", "method": "引入RIFT测试平台，使用重新表述的Jeopardy问答对，在两种提示结构（线性顺序和跳跃非顺序）下测试6个开源LLM，进行10,000次评估。", "result": "跳跃条件下准确率下降高达72%，约50%的错误源于指令顺序违反和语义漂移，显示模型将指令跟随内化为顺序模式而非推理技能。", "conclusion": "当前架构存在结构性敏感的根本限制，对工作流自动化和多智能体系统等需要非顺序控制流的应用具有直接意义。"}}
{"id": "2601.18899", "pdf": "https://arxiv.org/pdf/2601.18899", "abs": "https://arxiv.org/abs/2601.18899", "authors": ["Yuchen Zhang", "Ravi Shekhar", "Haralambos Mouratidis"], "title": "Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.", "AI": {"tldr": "提出基于语言家族的连接器共享策略，用一个连接器服务同一语言家族的所有语言，减少参数数量同时提升跨领域泛化能力", "motivation": "现有方法为每种语言训练单独连接器，忽略了语言之间的相关性，导致参数效率低下", "method": "基于语言家族成员关系设计连接器共享策略，同一语言家族使用同一个轻量级连接器，连接冻结的语音编码器和预训练大语言模型", "result": "在两个多语言LLM和两个真实语音语料库上的实验表明，家族式连接器减少了参数数量，同时改善了跨领域的泛化性能", "conclusion": "基于语言家族的连接器共享策略为多语言ASR部署提供了实用且可扩展的解决方案，在保持性能的同时显著提升了参数效率"}}
{"id": "2601.18944", "pdf": "https://arxiv.org/pdf/2601.18944", "abs": "https://arxiv.org/abs/2601.18944", "authors": ["Qiyuan Xu", "Xiaokun Luan", "Renxi Wang", "Joshua Ong Jun Leang", "Peixin Wang", "Haonan Li", "Wenda Li", "Conrad Watt"], "title": "Neural Theorem Proving for Verification Conditions: A Real-World Benchmark", "categories": ["cs.AI", "cs.PL", "cs.SE"], "comment": "Accepted in ICLR'26", "summary": "Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.", "AI": {"tldr": "本文提出了NTP4VC，这是首个针对程序验证中验证条件(VC)自动证明的跨语言基准测试，从真实项目生成测试用例，评估了大语言模型在VC证明中的表现，发现虽然LLMs有潜力但仍面临重大挑战。", "motivation": "程序验证中验证条件的自动证明是一个主要瓶颈，现有自动定理证明器无法处理困难VC，需要大量人工证明，而神经定理证明在数学竞赛中成功但在程序验证领域尚未充分探索。", "method": "从Linux和Contiki-OS等真实项目中，使用Why3和Frama-C工业管道生成在Isabelle、Lean和Rocq等形式语言中语义等价的测试用例，构建NTP4VC基准，评估通用和专门微调的大语言模型。", "result": "评估结果表明，大语言模型在VC证明中显示出潜力，但在程序验证方面仍存在显著挑战，揭示了巨大的研究差距和机会。", "conclusion": "NTP4VC基准填补了VC自动证明领域的空白，虽然LLMs展现出前景，但程序验证的VC证明仍是一个开放的研究问题，需要进一步探索和改进。"}}
{"id": "2601.18901", "pdf": "https://arxiv.org/pdf/2601.18901", "abs": "https://arxiv.org/abs/2601.18901", "authors": ["Christopher Kissling", "Elena Merdjanovska", "Alan Akbik"], "title": "Self-Aware Knowledge Probing: Evaluating Language Models' Relational Knowledge through Confidence Calibration", "categories": ["cs.CL"], "comment": null, "summary": "Knowledge probing quantifies how much relational knowledge a language model (LM) has acquired during pre-training. Existing knowledge probes evaluate model capabilities through metrics like prediction accuracy and precision. Such evaluations fail to account for the model's reliability, reflected in the calibration of its confidence scores. In this paper, we propose a novel calibration probing framework for relational knowledge, covering three modalities of model confidence: (1) intrinsic confidence, (2) structural consistency and (3) semantic grounding. Our extensive analysis of ten causal and six masked language models reveals that most models, especially those pre-trained with the masking objective, are overconfident. The best-calibrated scores come from confidence estimates that account for inconsistencies due to statement rephrasing. Moreover, even the largest pre-trained models fail to encode the semantics of linguistic confidence expressions accurately.", "AI": {"tldr": "提出新的校准探测框架评估语言模型关系知识的置信度校准，发现大多数模型（特别是掩码预训练模型）存在过度自信问题，最佳校准来自考虑重述一致性的置信度估计", "motivation": "现有知识探测方法只评估预测准确性等指标，未能考虑模型置信度校准所反映的可靠性问题", "method": "提出校准探测框架，涵盖三种置信度模态：内在置信度、结构一致性和语义基础，分析10个因果和6个掩码语言模型", "result": "大多数模型（特别是掩码预训练模型）过度自信；最佳校准来自考虑重述不一致性的置信度估计；最大预训练模型也无法准确编码语言置信表达式的语义", "conclusion": "需要开发更好的校准方法来提高语言模型关系知识的可靠性，当前模型在置信度校准方面存在显著缺陷"}}
{"id": "2601.19082", "pdf": "https://arxiv.org/pdf/2601.19082", "abs": "https://arxiv.org/abs/2601.19082", "authors": ["Trung-Kiet Huynh", "Dao-Sy Duy-Minh", "Thanh-Bang Cao", "Phong-Hao Le", "Hong-Dan Nguyen", "Nguyen Lam Phu Quy", "Minh-Luan Nguyen-Vo", "Hong-Phat Pham", "Pham Phu Hoa", "Thien-Kim Than", "Chi-Nguyen Tran", "Huy Tran", "Gia-Thoai Tran-Le", "Alessio Buscemi", "Le Hong Trang", "The Anh Han"], "title": "More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG", "cs.MA"], "comment": "14 pages, 10 figures, 4 tables", "summary": "As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.", "AI": {"tldr": "该研究分析了大型语言模型在重复社会困境中的策略行为，发现激励强度和语言语境显著影响模型决策，揭示了模型和语言依赖的合作偏向，为AI治理和多智能体系统设计提供了重要见解。", "motivation": "随着LLM在交互式和多智能体环境中越来越多地充当自主智能体，理解其战略行为对于安全性、协调性以及AI驱动的社会经济系统至关重要。", "method": "使用收益缩放的囚徒困境游戏来分离对激励强度的敏感性，训练监督分类器分析典型重复游戏策略，并将其应用于LLM决策分析。", "result": "发现跨模型和语言的一致行为模式，包括对激励敏感的conditional策略和跨语言差异，语言框架有时匹配或超过架构效应的影响。", "conclusion": "研究提供了一个统一的框架来审计LLM作为战略智能体，并突出了对AI治理和多智能体系统设计具有直接影响的合作偏向。"}}
{"id": "2601.18902", "pdf": "https://arxiv.org/pdf/2601.18902", "abs": "https://arxiv.org/abs/2601.18902", "authors": ["Jiaming Fan", "Daming Cao", "Xiangzhong Luo", "Jiale Fu", "Chonghan Liu", "Xu Yang"], "title": "Flatter Tokens are More Valuable for Speculative Draft Model Training", "categories": ["cs.CL"], "comment": null, "summary": "Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation reveals that tokens inducing flatter predictive distributions from the target model are more valuable than those yielding sharply peaked distributions. Based on this insight, we propose flatness, a new metric to quantify this property, and develop the Sample-level-flatness-based Dataset Distillation (SFDD) approach, which filters the training data to retain only the most valuable samples. Experiments on the EAGLE framework demonstrate that SFDD can achieve over 2$\\times$ training speedup using only 50% of the data, while keeping the final model's inference speedup within 4% of the full-dataset baseline. This work introduces an effective, data-centric approach that substantially improves the training efficiency for Speculative Decoding. Our code is available at https://anonymous.4open.science/r/Flatness.", "AI": {"tldr": "提出基于平坦度的样本级数据集蒸馏方法SFDD，通过筛选对推测解码接受率最有价值的训练样本，仅用50%数据实现2倍训练加速，同时保持推理加速效果接近全数据集基线。", "motivation": "推测解码技术需要在大数据集上训练草稿模型，但并非所有训练样本对接受率的贡献都相同，需要从数据中心的视角提高训练效率。", "method": "通过理论分析和实证验证发现，目标模型预测分布较平坦的token更有价值，提出平坦度指标量化这一特性，开发SFDD方法过滤训练数据保留最有价值样本。", "result": "在EAGLE框架上的实验表明，SFDD仅用50%数据即可实现超过2倍的训练加速，最终模型的推理加速效果保持在完整数据集基线的4%以内。", "conclusion": "这项工作提出了一种有效的数据中心方法，显著提高了推测解码的训练效率，为LLM推理加速提供了新的数据优化视角。"}}
{"id": "2601.19112", "pdf": "https://arxiv.org/pdf/2601.19112", "abs": "https://arxiv.org/abs/2601.19112", "authors": ["Nanhan Shen", "Zhilei Liu"], "title": "Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation", "categories": ["cs.AI", "cs.MM", "cs.SD"], "comment": "Accepted by ICASSP 2026", "summary": "Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk", "AI": {"tldr": "UA-3DTalk是一个不确定性感知的3D情感说话人脸合成方法，通过情感先验蒸馏解决了现有方法在音频-视觉情感对齐和多视图融合方面的关键问题，在情感对齐、唇部同步和渲染质量方面显著优于现有先进方法。", "motivation": "现有3D情感说话人脸合成方法存在两个关键挑战：音频-视觉情感对齐不佳（音频情感提取困难和情感微表情控制不足），以及忽视不确定性和特征质量差异的一刀切多视图融合策略，这影响了渲染质量。", "method": "提出UA-3DTalk框架，包含三个核心模块：先验提取模块解耦音频特征；情感蒸馏模块引入多模态注意力加权融合机制和4D高斯编码；不确定性形变模块部署不确定性块来估计视图特定的不确定性，实现自适应多视图融合。", "result": "在常规和情感数据集上的广泛实验显示，UA-3DTalk在情感对齐的E-FID指标上优于DEGSTalk和EDTalk 5.2%，在唇部同步的SyncC指标上提升3.1%，在渲染质量的LPIPS指标上提升0.015。", "conclusion": "UA-3DTalk通过不确定性感知和情感先验蒸馏，有效解决了3D情感说话人脸合成的关键挑战，在多个重要指标上实现了显著的性能提升，为多媒体和信号处理领域提供了更高质量的解决方案。"}}
{"id": "2601.18933", "pdf": "https://arxiv.org/pdf/2601.18933", "abs": "https://arxiv.org/abs/2601.18933", "authors": ["Kaustubh D. Dhole"], "title": "BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.", "AI": {"tldr": "论文提出了BabyReasoningBench基准测试，用于评估基于儿童发展数据训练的语言模型的推理能力，发现这类模型在因果推理方面有进步，但在信念归因和语用任务上仍存在挑战。", "motivation": "传统语言模型评估基准基于成人知识，不适合评估基于儿童发展数据训练的'婴儿语言模型'，需要开发更适合的评估工具来了解在这种约束条件下哪些推理能力能够涌现。", "method": "引入BabyReasoningBench基准，包含19个基于发展心理学经典范式的推理任务，涵盖心理理论、类比推理、因果推理等，并测试了两个基于GPT-2、在1000万和1亿儿童导向语料上训练的模型。", "result": "两个婴儿语言模型总体表现较低但不均衡：规模扩大改善了因果和物理推理任务，但信念归因和语用敏感任务仍然具有挑战性。", "conclusion": "BabyReasoningBench为分析儿童式训练分布支持的推理类型提供了发展心理学基础，可用于测试相关能力涌现的机制假设。"}}
{"id": "2601.19122", "pdf": "https://arxiv.org/pdf/2601.19122", "abs": "https://arxiv.org/abs/2601.19122", "authors": ["Weiran Guo", "Bing Bo", "Shaoxiang Wu", "Jingsheng Yang"], "title": "Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach", "categories": ["cs.AI"], "comment": null, "summary": "Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.", "AI": {"tldr": "提出一种基于强化学习的对抗性数据增强方法，通过训练查询模型生成挑战性查询来提升大语言模型函数调用能力的泛化性和鲁棒性。", "motivation": "现有方法依赖人工标注或模型自动生成的数据进行微调，缺乏针对性设计，受限于固定模式和数据分布，难以有效提升函数调用LLM的泛化能力和鲁棒性。", "method": "采用强化学习训练查询模型生成对抗性查询，通过零和博弈框架进行查询模型和函数调用模型的迭代交替训练，系统性地识别和针对模型弱点。", "result": "该方法能够系统性地识别和纠正LLM与外部工具交互能力的弱点，为开发更鲁棒的函数调用模型提供了有效途径。", "conclusion": "提出的对抗性数据增强方法通过强化学习机制，为提升函数调用LLM的鲁棒性和泛化性提供了系统性的解决方案，推动了更强大工具交互能力的发展。"}}
{"id": "2601.18987", "pdf": "https://arxiv.org/pdf/2601.18987", "abs": "https://arxiv.org/abs/2601.18987", "authors": ["Oren Sultan", "Jordi Armengol-Estape", "Pascal Kesseli", "Julien Vanegue", "Dafna Shahaf", "Yossi Adi", "Peter O'Hearn"], "title": "LLMs versus the Halting Problem: Revisiting Program Termination Prediction", "categories": ["cs.CL", "cs.AI", "cs.PL"], "comment": null, "summary": "Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.", "AI": {"tldr": "大型语言模型在程序终止性预测方面表现出色，GPT-5和Claude Sonnet-4.5在SV-Comp 2025终止类别测试中接近顶级工具性能，但存在无法提供有效证明和程序长度增加时性能下降的问题。", "motivation": "由于图灵停机问题的不可判定性，传统验证工具只能近似判断程序终止。随着大型语言模型的发展，研究者希望探索LLMs是否能够可靠预测程序终止。", "method": "使用SV-Comp 2025终止类别中的多样化C程序作为测试集，评估多个大型语言模型（包括GPT-5、Claude Sonnet-4.5和Code World Model）的终止预测能力。", "result": "LLMs在程序终止预测方面表现优异，GPT-5和Claude Sonnet-4.5排名仅次于顶级工具，CWM紧随第二名的工具。但模型无法提供有效证明，且随着程序长度增加性能下降。", "conclusion": "LLMs在解决不可判定问题方面展现出潜力，但在提供形式化证明方面存在局限。这激励了进一步研究LLMs在程序终止和不可判定问题推理方面的更广泛应用。"}}
{"id": "2601.19142", "pdf": "https://arxiv.org/pdf/2601.19142", "abs": "https://arxiv.org/abs/2601.19142", "authors": ["Zhicheng Zhang", "Zhaocheng Du", "Jieming Zhu", "Jiwei Tang", "Fengyuan Lu", "Wang Jiaheng", "Song-Li Wu", "Qianhui Zhu", "Jingyu Li", "Hai-Tao Zheng", "Zhenhua Dong"], "title": "Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction", "categories": ["cs.AI"], "comment": "Accepted at AAAI 2026", "summary": "User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.", "AI": {"tldr": "LAIN框架通过将序列长度作为条件信号，有效解决了推荐系统中长序列和短序列用户建模的平衡问题，在不牺牲长序列效果的前提下显著提升了短序列用户的准确性。", "motivation": "现代推荐系统中用户行为序列长度差异显著，现有CTR模型增加最大序列长度会导致短序列用户性能下降，存在注意力极化和训练数据长度不平衡问题。", "method": "提出LAIN框架，包含三个轻量级组件：频谱长度编码器将长度映射为连续表示、长度条件提示向长短行为分支注入全局上下文线索、长度调制注意力根据序列长度自适应调整注意力锐度。", "result": "在三个真实数据集和五个CTR骨干网络上，LAIN持续提升整体性能，最高获得1.15% AUC增益和2.25%对数损失降低，显著改善短序列用户准确性。", "conclusion": "LAIN提供了一个通用、高效且可部署的解决方案，有效缓解了序列推荐中的长度诱导偏差问题。"}}
{"id": "2601.18998", "pdf": "https://arxiv.org/pdf/2601.18998", "abs": "https://arxiv.org/abs/2601.18998", "authors": ["Zahra Hashemi", "Zhiqiang Zhong", "Jun Pang", "Wei Zhao"], "title": "Malicious Repurposing of Open Science Artefacts by Using Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The rapid evolution of large language models (LLMs) has fuelled enthusiasm about their role in advancing scientific discovery, with studies exploring LLMs that autonomously generate and evaluate novel research ideas. However, little attention has been given to the possibility that such models could be exploited to produce harmful research by repurposing open science artefacts for malicious ends. We fill the gap by introducing an end-to-end pipeline that first bypasses LLM safeguards through persuasion-based jailbreaking, then reinterprets NLP papers to identify and repurpose their artefacts (datasets, methods, and tools) by exploiting their vulnerabilities, and finally assesses the safety of these proposals using our evaluation framework across three dimensions: harmfulness, feasibility of misuse, and soundness of technicality. Overall, our findings demonstrate that LLMs can generate harmful proposals by repurposing ethically designed open artefacts; however, we find that LLMs acting as evaluators strongly disagree with one another on evaluation outcomes: GPT-4.1 assigns higher scores (indicating greater potential harms, higher soundness and feasibility of misuse), Gemini-2.5-pro is markedly stricter, and Grok-3 falls between these extremes. This indicates that LLMs cannot yet serve as reliable judges in a malicious evaluation setup, making human evaluation essential for credible dual-use risk assessment.", "AI": {"tldr": "论文展示了如何通过说服式越狱绕过LLM安全机制，将原本设计良好的NLP研究工具重新用于恶意目的，并发现不同LLM评估结果存在显著差异，无法作为可靠的风险评估工具。", "motivation": "现有研究主要关注LLM在科学发现中的积极作用，但忽视了其可能被滥用来生成有害研究的风险，特别是利用开放科学资源进行恶意重新利用的可能性。", "method": "开发了一个端到端流程：通过说服式越狱绕过LLM安全保护，重新解释NLP论文以识别和重新利用其工具资源（数据集、方法和工具），并建立三维评估框架（危害性、误用可行性、技术合理性）进行评估。", "result": "LLM能够通过重新利用伦理设计的开放资源生成有害提案；不同LLM评估结果存在显著分歧：GPT-4.1评分较高（显示更大危害潜力），Gemini-2.5-pro更严格，Grok-3介于中间。", "conclusion": "LLM目前无法在恶意评估设置中作为可靠裁判，人类评估对于可信的双重用途风险评估仍然至关重要。"}}
{"id": "2601.19151", "pdf": "https://arxiv.org/pdf/2601.19151", "abs": "https://arxiv.org/abs/2601.19151", "authors": ["Patara Trirat", "Jin Myung Kwak", "Jay Heo", "Heejun Lee", "Sung Ju Hwang"], "title": "TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning", "categories": ["cs.AI", "cs.MA"], "comment": "Code will be available at https://github.com/DeepAuto-AI/TS-Debate", "summary": "Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.", "AI": {"tldr": "TS-Debate是一个专门针对时间序列分析的多智能体辩论框架，通过模态专业化分工和结构化辩论协议，在零样本设置下显著提升了时间序列推理性能。", "motivation": "大型语言模型在时间序列分析中存在数值保真度不足、模态干扰和跨模态整合困难等问题，需要一种能够保持模态保真度并减少数值幻觉的解决方案。", "method": "采用多智能体辩论框架，分配专门的专家智能体处理文本上下文、视觉模式和数值信号，通过明确的领域知识提取和结构化辩论协议协调交互，使用验证-冲突-校准机制和轻量级代码执行进行程序化验证。", "result": "在三个公共基准测试的20个任务中，TS-Debate相比强基线模型实现了持续且显著的性能提升，包括优于所有智能体都能观察到所有输入的标准多模态辩论方法。", "conclusion": "TS-Debate框架通过模态专业化分工和结构化辩论机制，有效解决了LLMs在时间序列分析中的数值保真度和跨模态整合问题，无需任务特定微调即可实现优异性能。"}}
{"id": "2601.19001", "pdf": "https://arxiv.org/pdf/2601.19001", "abs": "https://arxiv.org/abs/2601.19001", "authors": ["Haozheng Luo", "Zhuolin Jiang", "Md Zahid Hasan", "Yan Chen", "Soumalya Sarkar"], "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST", "AI": {"tldr": "FROST是一种基于注意力权重的推理路径剪枝方法，通过识别和移除推理异常值来缩短推理轨迹并提高可靠性", "motivation": "传统推理方法效率低下，存在不必要的推理路径，需要一种能够智能剪枝无关路径的方法来提高推理效率和准确性", "method": "引入推理异常值概念，设计基于注意力的机制来识别和移除句子级别的异常值，保留和增强模型的推理能力", "result": "在四个基准测试中使用Phi-4-Reasoning和GPT-OSS-20B模型验证，相比TALE和ThinkLess等先进方法表现更优，平均减少69.68%的token使用，准确率提高26.70%", "conclusion": "FROST通过注意力感知的路径剪枝有效提升了推理效率和质量，在减少计算成本的同时显著提高了模型性能，为高效推理提供了新思路"}}
{"id": "2601.19155", "pdf": "https://arxiv.org/pdf/2601.19155", "abs": "https://arxiv.org/abs/2601.19155", "authors": ["Qiujun Li", "Zijin Xiao", "Xulin Wang", "Zhidan Ma", "Cheng Yang", "Haifeng Li"], "title": "LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge", "categories": ["cs.AI", "cs.CV"], "comment": "9 pages, 5 figures, 3 tables", "summary": "Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \\textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\\% in zero-shot settings.", "AI": {"tldr": "LocationAgent：通过分层推理架构和外部工具验证，解决图像地理定位中的幻觉和泛化问题，在零样本设置中性能提升30%", "motivation": "现有方法通过监督训练或强化学习将地理知识内化为静态记忆，容易在开放世界或需要动态知识的场景中出现事实幻觉和泛化瓶颈", "method": "提出分层定位代理LocationAgent，采用RER架构（推理器-执行器-记录器）实现分层推理，同时构建线索探索工具集进行外部证据验证", "result": "在零样本设置下显著优于现有方法至少30%，并创建了CCL-Bench中文城市定位基准数据集", "conclusion": "通过将地理证据验证外包给外部工具并保留分层推理逻辑，有效解决了图像地理定位中的关键挑战，为开放世界应用提供了可靠解决方案"}}
{"id": "2601.19063", "pdf": "https://arxiv.org/pdf/2601.19063", "abs": "https://arxiv.org/abs/2601.19063", "authors": ["Siddhant Arora", "Jinchuan Tian", "Jiatong Shi", "Hayato Futami", "Yosuke Kashiwagi", "Emiru Tsunoo", "Shinji Watanabe"], "title": "Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.", "AI": {"tldr": "首个用于语音对话系统的多奖励RLAIF框架，通过结合语义、音频质量和情感一致性奖励，解决了传统单奖励方法的局限性，在双工模型中实现了跨多个质量维度的全面提升。", "motivation": "现有的RLHF/RLAIF方法主要局限于在话语层面应用单一语义奖励，忽视了对话质量的多维性和多模态特性，且与双工语音系统的增量生成特性不匹配。", "method": "提出多奖励RLAIF框架，结合语义、音频质量和情感一致性奖励；采用轮次级偏好采样和块级对数概率聚合的DPO目标，适配双工模型的增量解码特性。", "result": "单奖励RLAIF仅能提升特定目标指标，而联合多奖励训练在语义质量和音频自然度方面均获得一致提升，验证了多奖励对齐的重要性。", "conclusion": "多奖励对齐对于实用对话系统至关重要，该方法为语音对话系统的质量提升提供了有效的整体解决方案，并发布了多奖励DPO数据集支持可重复研究。"}}
{"id": "2601.19170", "pdf": "https://arxiv.org/pdf/2601.19170", "abs": "https://arxiv.org/abs/2601.19170", "authors": ["Wangyang Ying", "Yanchi Liu", "Xujiang Zhao", "Wei Cheng", "Zhengzhang Chen", "Wenchao Yu", "Yanjie Fu", "Haifeng Chen"], "title": "Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement", "categories": ["cs.AI"], "comment": null, "summary": "Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \\model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \\model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.", "AI": {"tldr": "ProGraph多智能体框架通过结构化和逻辑反馈机制，从自然语言中自动提取工作流程图，显著提升了结构正确性和逻辑一致性", "motivation": "当前大语言模型在从自然语言提取程序化工作流程图时，经常产生结构错误或逻辑流误解，需要同时保证结构有效性和逻辑对齐", "method": "提出多轮推理框架，包含三个阶段：图构建代理提取初始图、模拟代理诊断结构缺陷、语义代理对齐文本语义与流程逻辑，通过自然语言反馈进行迭代优化", "result": "实验表明该方法在结构正确性和逻辑一致性方面相比强基线有显著提升", "conclusion": "多智能体框架通过模块化设计和可解释反馈机制，无需监督或参数更新即可有效解决程序化图提取问题"}}
{"id": "2601.19096", "pdf": "https://arxiv.org/pdf/2601.19096", "abs": "https://arxiv.org/abs/2601.19096", "authors": ["Sohhyung Park", "Hyunji Kang", "Sungzoon Cho", "Dongil Kim"], "title": "PsyProbe: Proactive and Interpretable Dialogue through User State Modeling for Exploratory Counseling", "categories": ["cs.CL"], "comment": "In Findings of the Association for Computational Linguistics: EACL 2026", "summary": "Recent advances in large language models have enabled mental health dialogue systems, yet existing approaches remain predominantly reactive, lacking systematic user state modeling for proactive therapeutic exploration. We introduce PsyProbe, a dialogue system designed for the exploration phase of counseling that systematically tracks user psychological states through the PPPPPI framework (Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact) augmented with cognitive error detection. PsyProbe combines State Builder for extracting structured psychological profiles, Memory Construction for tracking information gaps, Strategy Planner for Motivational Interviewing behavioral codes, and Response Generator with Question Ideation and Critic/Revision modules to generate contextually appropriate, proactive questions. We evaluate PsyProbe with 27 participants in real-world Korean counseling scenarios, including automatic evaluation across ablation modes, user evaluation, and expert evaluation by a certified counselor. The full PsyProbe model consistently outperforms baseline and ablation modes in automatic evaluation. User evaluation demonstrates significantly increased engagement intention and improved naturalness compared to baseline. Expert evaluation shows that PsyProbe substantially improves core issue understanding and achieves question rates comparable to professional counselors, validating the effectiveness of systematic state modeling and proactive questioning for therapeutic exploration.", "AI": {"tldr": "PsyProbe是一个基于PPPPPI框架的心理健康对话系统，通过系统化用户状态建模和主动提问来改善心理咨询探索阶段的效果，在自动评估、用户评估和专家评估中均优于基线模型。", "motivation": "现有心理健康对话系统主要处于被动反应模式，缺乏系统化的用户状态建模来进行主动的治疗性探索。", "method": "提出PsyProbe系统，包含状态构建器、记忆构建、策略规划器和响应生成器四个模块，使用PPPPPI框架（呈现、易感、诱发、维持、保护、影响）结合认知错误检测来系统跟踪用户心理状态。", "result": "在27名参与者的真实韩国心理咨询场景评估中，完整PsyProbe模型在自动评估中始终优于基线和消融模式；用户评估显示参与意愿和自然度显著提高；专家评估表明系统显著改善核心问题理解，提问率与专业咨询师相当。", "conclusion": "系统化的状态建模和主动提问策略对于治疗性探索阶段是有效的，PsyProbe展示了在心理健康对话系统中实现主动探索的可行性。"}}
{"id": "2601.19178", "pdf": "https://arxiv.org/pdf/2601.19178", "abs": "https://arxiv.org/abs/2601.19178", "authors": ["Jingyu Li", "Zhaocheng Du", "Qianhui Zhu", "kaiyuan Li", "Zhicheng Zhang", "Song-Li Wu", "Chaolang Li", "Pengwen Dai"], "title": "CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation", "categories": ["cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.", "AI": {"tldr": "CollectiveKV提出了一种跨用户KV共享机制，通过可学习的全局KV池捕获用户间共享信息，将KV缓存压缩至原始大小的0.8%，同时保持或提升模型性能。", "motivation": "Transformer注意力机制在序列推荐系统中计算复杂度随序列长度增长，KV缓存技术虽能降低推理延迟但带来巨大存储开销，特别是面对大规模用户和长历史序列时。研究发现不同用户的KV序列存在显著相似性，表明存在协作信号。", "method": "通过奇异值分解分析KV信息，发现大部分信息可跨用户共享，小部分为用户特定。提出CollectiveKV机制：使用可学习全局KV池捕获共享信息，推理时用户从池中检索高维共享KV并与低维用户特定KV拼接得到最终KV。", "result": "在5个序列推荐模型和3个数据集上的实验表明，该方法能将KV缓存压缩至原始大小的0.8%。", "conclusion": "CollectiveKV有效解决了序列推荐系统中KV缓存的存储开销问题，在显著压缩存储的同时维持甚至提升了模型性能，证明了跨用户KV共享的可行性。"}}
{"id": "2601.19124", "pdf": "https://arxiv.org/pdf/2601.19124", "abs": "https://arxiv.org/abs/2601.19124", "authors": ["Tan Sang Nguyen", "Quoc Nguyen Pham", "Tho Quan"], "title": "Leveraging Sentence-oriented Augmentation and Transformer-Based Architecture for Vietnamese-Bahnaric Translation", "categories": ["cs.CL"], "comment": null, "summary": "The Bahnar people, an ethnic minority in Vietnam with a rich ancestral heritage, possess a language of immense cultural and historical significance. The government places a strong emphasis on preserving and promoting the Bahnaric language by making it accessible online and encouraging communication across generations. Recent advancements in artificial intelligence, such as Neural Machine Translation (NMT), have brought about a transformation in translation by improving accuracy and fluency. This, in turn, contributes to the revival of the language through educational efforts, communication, and documentation. Specifically, NMT is pivotal in enhancing accessibility for Bahnaric speakers, making information and content more readily available. Nevertheless, the translation of Vietnamese into Bahnaric faces practical challenges due to resource constraints, especially given the limited resources available for the Bahnaric language. To address this, we employ state-of-the-art techniques in NMT along with two augmentation strategies for domain-specific Vietnamese-Bahnaric translation task. Importantly, both approaches are flexible and can be used with various neural machine translation models. Additionally, they do not require complex data preprocessing steps, the training of additional systems, or the acquisition of extra data beyond the existing training parallel corpora.", "AI": {"tldr": "该论文研究使用神经机器翻译技术解决越南语到巴拿语的翻译问题，通过两种数据增强策略在资源有限的情况下提升翻译质量，支持巴拿语的保护和复兴。", "motivation": "巴拿语是越南少数民族的重要文化遗产语言，政府致力于保护推广该语言。虽然神经机器翻译技术可以促进语言复兴，但越南语到巴拿语的翻译面临资源有限的挑战。", "method": "采用最先进的神经机器翻译技术，结合两种数据增强策略，这些方法灵活且不需要复杂的数据预处理、额外系统训练或额外的平行语料数据。", "result": "论文提出了适用于越南语-巴拿语翻译任务的增强策略，能够有效提升在资源受限情况下的翻译性能。", "conclusion": "提出的数据增强方法为低资源语言的机器翻译提供了实用解决方案，有助于巴拿语的数字化保存和跨代交流，促进少数民族语言的复兴。"}}
{"id": "2601.19193", "pdf": "https://arxiv.org/pdf/2601.19193", "abs": "https://arxiv.org/abs/2601.19193", "authors": ["Van-Quang Nguyen", "Takayuki Okatani"], "title": "CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning", "categories": ["cs.AI"], "comment": "accepted to EACL'26 (main conference)", "summary": "Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.", "AI": {"tldr": "CoReTab是一个代码驱动的多模态表格理解框架，通过生成可执行的Python代码实现多步推理，显著提升模型性能并增强可解释性。", "motivation": "现有的多模态表格理解数据集（如MMTab）只提供简短的事实答案，缺乏多步推理监督，导致模型响应简短、准确性不足且难以解释推理过程。", "method": "提出了CoReTab框架，通过将多步推理与可执行Python代码结合，生成可扩展、可解释且自动可验证的标注。构建了包含115K个验证样本的数据集，平均每个响应529个token，并通过三阶段流程微调开源MLLMs。", "result": "在17个MMTab基准测试中（包括表格问答、事实验证和表格结构理解），CoReTab训练的模型相比MMTab基线分别取得了+6.2%、+5.7%和+25.6%的显著提升。", "conclusion": "CoReTab作为一个稳健且可泛化的监督框架，有效提升了多模态表格理解中的多步推理能力，同时生成透明且可验证的推理轨迹。"}}
{"id": "2601.19191", "pdf": "https://arxiv.org/pdf/2601.19191", "abs": "https://arxiv.org/abs/2601.19191", "authors": ["Olaf Yunus Laitinen Imanov", "Taner Yilmaz", "Ayse Tuba Tugrul", "Melike Nesrin Zaman", "Ozkan Gunalp", "Duygu Erisken", "Sila Burde Dulger", "Rana Irem Turhan", "Izzet Ozdemir", "Derya Umut Kulali", "Ozan Akbulut", "Harun Demircioglu", "Hasan Basri Kara", "Berfin Tavan"], "title": "Transparency-First Medical Language Models: Datasheets, Model Cards, and End-to-End Data Provenance for Clinical NLP", "categories": ["cs.CL", "cs.LG"], "comment": "12 pages, 9 figures, 15 tables. Technetium-I case study and ProtactiniumBERT-100M reference benchmarks", "summary": "We introduce TeMLM, a set of transparency-first release artifacts for clinical language models. TeMLM unifies provenance, data transparency, modeling transparency, and governance into a single, machine-checkable release bundle. We define an artifact suite (TeMLM-Card, TeMLM-Datasheet, TeMLM-Provenance) and a lightweight conformance checklist for repeatable auditing. We instantiate the artifacts on Technetium-I, a large-scale synthetic clinical NLP dataset with 498,000 notes, 7.74M PHI entity annotations across 10 types, and ICD-9-CM diagnosis labels, and report reference results for ProtactiniumBERT (about 100 million parameters) on PHI de-identification (token classification) and top-50 ICD-9 code extraction (multi-label classification). We emphasize that synthetic benchmarks are valuable for tooling and process validation, but models should be validated on real clinical data prior to deployment.", "AI": {"tldr": "TeMLM是一套透明优先的临床语言模型发布框架，包含标准化文档和检查清单，通过在合成临床数据集Technetium-I上验证ProtactiniumBERT模型来展示其应用。", "motivation": "临床语言模型需要更高的透明度和可审计性，现有发布标准缺乏统一的机器可检查框架来整合数据来源、模型透明度和治理要求。", "method": "定义TeMLM-Card、TeMLM-Datasheet、TeMLM-Provenance三个标准化文档和轻量级符合性检查清单，在包含49.8万条临床笔记的大规模合成数据集Technetium-I上实例化，并用ProtactiniumBERT模型进行PHI去标识化和ICD-9代码提取任务验证。", "result": "成功建立了机器可检查的发布框架，在合成数据集上获得了PHI实体识别和ICD-9代码分类的参考性能结果，证明了框架的可行性。", "conclusion": "TeMLM为临床NLP提供了标准化的透明发布框架，合成基准对工具验证有价值，但最终模型部署前仍需在真实临床数据上进行验证。"}}
{"id": "2601.19199", "pdf": "https://arxiv.org/pdf/2601.19199", "abs": "https://arxiv.org/abs/2601.19199", "authors": ["Libo Sun", "Jiwen Zhang", "Siyuan Wang", "Zhongyu Wei"], "title": "MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.", "AI": {"tldr": "MAGNET是一个记忆驱动的自适应移动GUI代理框架，通过双级记忆系统（静态记忆和程序记忆）来解决界面更新导致的代理失效问题，利用功能语义和任务意图的稳定性来提升在动态软件环境中的性能和泛化能力。", "motivation": "移动GUI代理面临界面频繁更新导致的历史数据训练代理失效问题，虽然界面外观和工作流程会变化，但功能语义和任务意图保持稳定，需要利用这种稳定性来提升代理的适应性。", "method": "提出MAGNET框架，包含双级记忆：静态记忆将多样化视觉特征链接到稳定的功能语义以实现鲁棒的动作定位；程序记忆捕捉不同工作流程中的稳定任务意图。采用动态记忆进化机制，通过优先处理频繁访问的知识来持续优化两种记忆。", "result": "在AndroidWorld在线基准测试中相比基线有显著提升，离线基准测试在分布偏移下也显示出持续收益，验证了利用界面变化中的稳定结构能够改善代理性能和泛化能力。", "conclusion": "通过挖掘界面变化中的稳定功能语义和任务意图，MAGNET框架有效解决了移动GUI代理在动态软件环境中的适应性问题，为未来自主代理系统的开发提供了重要方向。"}}
{"id": "2601.19202", "pdf": "https://arxiv.org/pdf/2601.19202", "abs": "https://arxiv.org/abs/2601.19202", "authors": ["Chi Zhang", "Wenxuan Ding", "Jiale Liu", "Mingrui Wu", "Qingyun Wu", "Ray Mooney"], "title": "Do Images Speak Louder than Words? Investigating the Effect of Textual Misinformation in VLMs", "categories": ["cs.CL"], "comment": "24 pages, 10 figures. Accepted at EACL 2026 (main conference)", "summary": "Vision-Language Models (VLMs) have shown strong multimodal reasoning capabilities on Visual-Question-Answering (VQA) benchmarks. However, their robustness against textual misinformation remains under-explored. While existing research has studied the effect of misinformation in text-only domains, it is not clear how VLMs arbitrate between contradictory information from different modalities. To bridge the gap, we first propose the CONTEXT-VQA (i.e., Conflicting Text) dataset, consisting of image-question pairs together with systematically generated persuasive prompts that deliberately conflict with visual evidence. Then, a thorough evaluation framework is designed and executed to benchmark the susceptibility of various models to these conflicting multimodal inputs. Comprehensive experiments over 11 state-of-the-art VLMs reveal that these models are indeed vulnerable to misleading textual prompts, often overriding clear visual evidence in favor of the conflicting text, and show an average performance drop of over 48.2% after only one round of persuasive conversation. Our findings highlight a critical limitation in current VLMs and underscore the need for improved robustness against textual manipulation.", "AI": {"tldr": "研究发现当前视觉语言模型(VLMs)在面对与视觉证据相矛盾的误导性文本提示时表现脆弱，平均性能下降48.2%，揭示了模型对文本操纵的鲁棒性不足问题。", "motivation": "虽然视觉语言模型在多模态推理方面表现出色，但其对文本错误信息的鲁棒性尚未充分研究，特别是当文本与视觉信息矛盾时模型如何仲裁的问题。", "method": "首先构建CONTEXT-VQA数据集（包含图像-问题对和系统生成的与视觉证据相矛盾的说服性提示），然后设计评估框架对11种最先进VLM模型进行基准测试。", "result": "实验显示所有测试模型都容易受到误导性文本提示的影响，经常优先选择冲突文本而忽略清晰的视觉证据，仅经过一轮说服性对话后平均性能下降超过48.2%。", "conclusion": "当前视觉语言模型存在严重局限性，亟需提高对文本操纵的鲁棒性，以避免被误导性信息所影响。"}}
{"id": "2601.19204", "pdf": "https://arxiv.org/pdf/2601.19204", "abs": "https://arxiv.org/abs/2601.19204", "authors": ["Zhixi Cai", "Fucai Ke", "Kevin Leo", "Sukai Huang", "Maria Garcia de la Banda", "Peter J. Stuckey", "Hamid Rezatofighi"], "title": "MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": "ICLR 2026", "summary": "Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.", "AI": {"tldr": "MATA提出了一种基于分层有限状态自动机的多智能体视觉推理系统，通过可训练的超级智能体选择顶层状态转移，每个智能体运行基于规则的子自动机，实现透明可解释的视觉推理，在多个基准测试中达到最先进性能。", "motivation": "现有视觉语言模型虽然感知能力强但推理过程不透明且容易产生幻觉，组合方法虽然可解释但大多依赖单一智能体或手工流水线，无法在互补智能体间进行协作决策。", "method": "构建分层有限状态自动机结构，顶层转移由可训练的超级智能体选择；每个智能体对应一个状态并运行基于规则的子自动机；所有智能体共享内存；构建MATA-SFT-90K数据集监督训练转移策略。", "result": "在多个视觉推理基准测试中，MATA相比单一模型和组合基线方法取得了最先进的性能结果。", "conclusion": "MATA通过多智能体分层可训练自动机架构，实现了透明可解释的视觉推理，解决了现有模型的幻觉问题和组合方法的协作决策难题，为复杂视觉推理任务提供了有效解决方案。"}}
{"id": "2601.19208", "pdf": "https://arxiv.org/pdf/2601.19208", "abs": "https://arxiv.org/abs/2601.19208", "authors": ["Shawn Im", "Changdae Oh", "Zhen Fang", "Sharon Li"], "title": "How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability", "categories": ["cs.CL", "cs.LG"], "comment": "ICLR 2026", "summary": "Semantic associations such as the link between \"bird\" and \"flew\" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.", "AI": {"tldr": "该研究通过训练动力学分析，揭示了基于注意力的语言模型中语义关联如何从自然语言数据中涌现，并推导出训练早期权重的闭式表达式，将transformer权重分解为三种基础函数的组合。", "motivation": "理解语言模型中语义关联的学习和表示机制，以连接深度学习与语言学理论，为大型语言模型建立机制性基础。", "method": "利用梯度前导项近似，推导训练早期权重的闭式表达式，将transformer权重分解为bigram、token互换性和上下文映射三种基础函数的组合。", "result": "理论权重表征与真实LLMs学习到的权重高度匹配，定性分析显示该定理有助于解释transformer中学习到的语义关联。", "conclusion": "研究揭示了transformer通过三种统计基础函数组合来捕获语义关联的机制，为理解语言模型内部表示提供了理论框架。"}}
{"id": "2601.19245", "pdf": "https://arxiv.org/pdf/2601.19245", "abs": "https://arxiv.org/abs/2601.19245", "authors": ["Yongxin Deng", "Zhen Fang", "Yixuan Li", "Ling Chen"], "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.", "AI": {"tldr": "论文提出了一种名为SpikeScore的新方法，用于检测大语言模型的幻觉问题，特别是在跨域泛化场景下。该方法通过分析多轮对话中的不确定性波动来区分幻觉和非幻觉响应。", "motivation": "现有幻觉检测方法在训练和测试数据来自同一领域时表现良好，但在跨域场景下泛化能力差。论文研究了一个重要但被忽视的问题——可泛化幻觉检测(GHD)，旨在在单一领域数据上训练检测器，同时确保在相关领域的鲁棒性能。", "method": "通过模拟大语言模型初始响应后的多轮对话，发现幻觉引发的对话比事实性对话表现出更大的不确定性波动。基于此现象提出了SpikeScore评分，量化多轮对话中的突然波动。", "result": "实验证明SpikeScore在跨域场景下能有效区分幻觉和非幻觉响应。在多个大语言模型和基准测试中，基于SpikeScore的检测方法在跨域泛化方面优于代表性基线方法和先进的泛化导向方法。", "conclusion": "SpikeScore方法在跨域幻觉检测中表现出色，验证了该方法在提高大语言模型幻觉检测跨域泛化能力方面的有效性。"}}
{"id": "2601.19214", "pdf": "https://arxiv.org/pdf/2601.19214", "abs": "https://arxiv.org/abs/2601.19214", "authors": ["Aakash Trivedi", "Aniket Upadhyay", "Pratik Narang", "Dhruv Kumar", "Praveen Kumar"], "title": "A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EACL 2026 Industry Track (to appear)", "summary": "Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.", "AI": {"tldr": "提出混合管道方法，结合RoBERTa分类器和指令调优LLM，从客户评论中提取精确可操作建议，在准确性和聚类一致性上优于基线方法。", "motivation": "现有方法只能分类建议性句子或生成高层次摘要，但无法提取企业需要的精确改进指令，需要从混合意图的非结构化文本中提取可操作建议。", "method": "使用高召回率的RoBERTa分类器（通过精确召回代理训练）减少不可恢复的假阴性，再结合受控的指令调优LLM进行建议提取、分类、聚类和摘要。", "result": "在酒店和餐饮数据集上，混合系统在提取准确性和聚类一致性方面优于仅提示、基于规则和仅分类器的基线方法，人类评估确认结果清晰、忠实且可解释。", "conclusion": "混合推理架构在细粒度可操作建议挖掘方面取得显著改进，但领域适应和高效本地部署仍存在挑战。"}}
{"id": "2601.19249", "pdf": "https://arxiv.org/pdf/2601.19249", "abs": "https://arxiv.org/abs/2601.19249", "authors": ["Xingkun Yin", "Hongyang Du"], "title": "GLOVE: Global Verifier for LLM Memory-Environment Realignment", "categories": ["cs.AI"], "comment": null, "summary": "Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.", "AI": {"tldr": "GLOVE框架通过主动探测记忆与观察的不一致性，建立相对真实概念，实现无监督记忆更新，在动态环境中显著提升LLM智能体的成功率", "motivation": "现有记忆增强LLM方法依赖外部评估或模型内省来验证记忆有效性，但在动态漂移的实际环境中这些假设往往失效", "method": "提出Global Verifier (GLOVE)框架，通过主动探测检索记忆与新鲜观察之间的不一致性，建立相对真实概念，实现无监督记忆环境重新对齐", "result": "在包含网络导航、规划和控制的多样化基准测试中，GLOVE显著提高了智能体成功率，特别是在超出原始基准设置的非平稳环境中", "conclusion": "GLOVE为构建能够自我进化的认知智能体提供了一条稳健的路径，通过相对真实验证实现记忆系统的无监督更新和适应"}}
{"id": "2601.19221", "pdf": "https://arxiv.org/pdf/2601.19221", "abs": "https://arxiv.org/abs/2601.19221", "authors": ["Liu Xiao"], "title": "DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Modern Recurrent Neural Networks (RNNs), such as RWKV, are distinguished by their powerful short-range modeling capabilities and efficient fixed-size states, which constitute a core advantage over standard Transformers. However, there is a significant lack of research into their internal state as an editable knowledge representation. To fill this gap, we first explore the representational properties of the RWKV state by proposing the DREAMSTATE framework. This framework utilizes a conditional Diffusion Transformer (DiT) to directly model the probability manifold of the state, enabling its generation and editing. The structural nature of this representation is validated through t-SNE visualizations and controlled generation experiments. After successfully uncovering and modeling the state's representational potential, we further propose a novel hybrid architecture that combines the local advantages of RNNs with global context adaptability. This architecture features a parallel DiT that processes a variable-length global context to dynamically generate and adjust the core recurrent module's WKV parameters, transforming the fixed recurrence mechanism into a context-aware dynamic function. Experiments demonstrate that this hybrid model can be trained stably via a multi-objective loss, validating its design feasibility. Our work not only opens a new research direction for RNN state representation but also provides a concrete architectural reference for future model design. The code is publicly available at: https://huggingface.co/2dgx41s/DreamState.", "AI": {"tldr": "该论文提出了DREAMSTATE框架，使用条件扩散变换器建模RNN状态的概率流形，并设计了一种结合RNN局部优势和全局上下文适应性的混合架构。", "motivation": "现代RNN（如RWKV）具有强大的短程建模能力和高效固定大小状态，但缺乏对其内部状态作为可编辑知识表示的研究。", "method": "提出DREAMSTATE框架，使用条件扩散变换器（DiT）直接建模状态的概率流形；设计混合架构，通过并行DiT处理可变长度全局上下文来动态生成和调整核心循环模块的WKV参数。", "result": "通过t-SNE可视化和受控生成实验验证了状态表示的结构性质；实验证明混合模型可以通过多目标损失稳定训练，验证了设计可行性。", "conclusion": "该工作不仅为RNN状态表示开辟了新的研究方向，还为未来模型设计提供了具体的架构参考。"}}
{"id": "2601.19306", "pdf": "https://arxiv.org/pdf/2601.19306", "abs": "https://arxiv.org/abs/2601.19306", "authors": ["Sijia Li", "Xiaoyu Tan", "Shahir Ali", "Niels Schmidt", "Gengchen Ma", "Xihe Qiu"], "title": "Curiosity Driven Knowledge Retrieval for Mobile Agents", "categories": ["cs.AI"], "comment": null, "summary": "Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.", "AI": {"tldr": "提出基于好奇心驱动的知识检索框架，通过AppCards结构化外部知识来提升移动代理在复杂应用中的性能表现", "motivation": "移动代理在智能手机自动化中面临知识不完整和泛化能力有限的问题，特别是在复杂应用和未见环境中的表现受限", "method": "引入好奇心评分量化执行不确定性，当超过阈值时从文档、代码库和历史轨迹检索外部信息，组织成结构化AppCards（包含功能语义、参数约定、接口映射和交互模式），在推理过程中选择性集成", "result": "在AndroidWorld基准测试中平均提升6个百分点，结合GPT-5达到88.8%的最新成功率，在多步骤和跨应用任务中效果显著", "conclusion": "AppCards能有效减少模糊性、缩短探索时间、支持稳定执行轨迹，提升移动代理的规划可靠性，但改进效果依赖于骨干模型的质量"}}
{"id": "2601.19225", "pdf": "https://arxiv.org/pdf/2601.19225", "abs": "https://arxiv.org/abs/2601.19225", "authors": ["Kaehyun Um", "KyuHwan Yeom", "Haerim Yang", "Minyoung Choi", "Hyeongjun Yang", "Kyong-Ho Lee"], "title": "RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at The Web Conference (WWW) 2026", "summary": "Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.", "AI": {"tldr": "RPO-RAG是一个专门为小型语言模型设计的知识图谱增强检索生成框架，通过语义采样、关系感知优化和答案中心提示设计，显著提升了小模型在KGQA任务上的性能。", "motivation": "现有基于知识图谱的RAG方法存在语义感知不足、与KG推理目标对齐弱、缺乏对小型LLMs（7B参数以下）的专门优化等问题，限制了知识推理的准确性提升。", "method": "提出RPO-RAG框架，包含三个创新：查询-路径语义采样策略、关系感知偏好优化、答案中心提示设计，专门针对小型LLMs优化知识图谱推理。", "result": "在WebQSP和CWQ数据集上取得显著提升，WebQSP上F1提升8.8%，CWQ上在8B参数以下模型中达到新的SOTA结果，甚至在3B参数模型上也表现优异。", "conclusion": "RPO-RAG有效缩小了大小语言模型之间的性能差距，证明了小型LLMs在资源受限环境下进行高效知识图谱问答的潜力。"}}
{"id": "2601.19311", "pdf": "https://arxiv.org/pdf/2601.19311", "abs": "https://arxiv.org/abs/2601.19311", "authors": ["Anh Khoa Ngo Ho", "Martin Chauvin", "Simon Gosset", "Philippe Cordier", "Boris Gamazaychikov"], "title": "Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems", "categories": ["cs.AI"], "comment": null, "summary": "As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.", "AI": {"tldr": "研究发现小规模开源语言模型能在保持任务质量的同时显著降低能耗，为可持续AI系统设计提供了实用指南", "motivation": "随着大语言模型在AI系统中广泛应用，其推理能耗可能带来可持续性挑战，需要研究小模型是否能在不牺牲性能的情况下降低能耗", "method": "在不同规模的语言模型上进行对比分析，量化效率与性能之间的权衡关系", "result": "结果显示较小的开源权重模型能够降低能耗同时保持任务质量", "conclusion": "提出了可持续AI设计的实用指南，包括最佳批次大小配置和计算资源分配策略，为开发可扩展且环保的AI系统提供了可行方案"}}
{"id": "2601.19267", "pdf": "https://arxiv.org/pdf/2601.19267", "abs": "https://arxiv.org/abs/2601.19267", "authors": ["Xinlong Chen", "Weihong Lin", "Jingyun Hua", "Linli Yao", "Yue Ding", "Bozhou Li", "Bohan Zeng", "Yang Shi", "Qiang Liu", "Yuanxing Zhang", "Pengfei Wan", "Liang Wang", "Tieniu Tan"], "title": "DiaDem: Advancing Dialogue Descriptions in Audiovisual Video Captioning for Multimodal Large Language Models", "categories": ["cs.CL"], "comment": "Project webpage: https://diadem-captioner.github.io/", "summary": "Accurate dialogue description in audiovisual video captioning is crucial for downstream understanding and generation tasks. However, existing models generally struggle to produce faithful dialogue descriptions within audiovisual captions. To mitigate this limitation, we propose DiaDem, a powerful audiovisual video captioning model capable of generating captions with more precise dialogue descriptions while maintaining strong overall performance. We first synthesize a high-quality dataset for SFT, then employ a difficulty-partitioned two-stage GRPO strategy to further enhance dialogue descriptions. To enable systematic evaluation of dialogue description capabilities, we introduce DiaDemBench, a comprehensive benchmark designed to evaluate models across diverse dialogue scenarios, emphasizing both speaker attribution accuracy and utterance transcription fidelity in audiovisual captions. Extensive experiments on DiaDemBench reveal even commercial models still exhibit substantial room for improvement in dialogue-aware captioning. Notably, DiaDem not only outperforms the Gemini series in dialogue description accuracy but also achieves competitive performance on general audiovisual captioning benchmarks, demonstrating its overall effectiveness.", "AI": {"tldr": "DiaDem是一个专门用于生成包含精确对话描述的视听视频字幕模型，通过合成高质量数据集和两阶段GRPO策略提升对话描述能力，并在专门基准DiaDemBench上验证了其优越性能。", "motivation": "现有视听视频字幕模型在生成忠实对话描述方面存在困难，影响了下游理解和生成任务的效果。", "method": "首先合成高质量的SFT数据集，然后采用难度分区的两阶段GRPO策略来增强对话描述能力，并建立了DiaDemBench基准进行系统评估。", "result": "DiaDem在对话描述准确性上超越Gemini系列模型，同时在通用视听字幕基准上也表现出竞争力，显示出商业模型在对话感知字幕方面仍有很大改进空间。", "conclusion": "DiaDem模型在生成精确对话描述方面表现优异，为视听视频字幕任务提供了有效的解决方案，同时建立的DiaDemBench基准为后续研究提供了系统评估标准。"}}
{"id": "2601.19337", "pdf": "https://arxiv.org/pdf/2601.19337", "abs": "https://arxiv.org/abs/2601.19337", "authors": ["Sayak Chowdhury", "Meenakshi D'Souza"], "title": "SETA: Statistical Fault Attribution for Compound AI Systems", "categories": ["cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to CAIN 2026 co-hosted with ICSE 2026", "summary": "Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed and implemented for single-network models and do not scale well to multi-network pipelines. We propose a modular robustness testing framework that applies a given set of perturbations to test data. Our testing framework supports (1) a component-wise system analysis to isolate errors and (2) reasoning about error propagation across the neural network modules. The testing framework is architecture and modality agnostic and can be applied across domains. We apply the framework to a real-world autonomous rail inspection system composed of multiple deep networks and successfully demonstrate how our approach enables fine-grained robustness analysis beyond conventional end-to-end metrics.", "AI": {"tldr": "提出一个模块化鲁棒性测试框架，用于测试多网络AI系统的鲁棒性，支持组件级分析和错误传播分析", "motivation": "当前最先进的鲁棒性测试技术主要针对单网络模型，无法有效扩展到多网络流水线系统，测试这类系统的鲁棒性和安全性面临重大挑战", "method": "开发模块化鲁棒性测试框架，对测试数据应用扰动集，支持组件级系统分析和跨神经网络模块的错误传播推理", "result": "将框架应用于真实世界的自主铁路检查系统（由多个深度网络组成），成功展示了该方法能够实现比传统端到端指标更细粒度的鲁棒性分析", "conclusion": "该框架是架构和模态无关的，可跨领域应用，为多网络AI系统的鲁棒性测试提供了有效解决方案"}}
{"id": "2601.19273", "pdf": "https://arxiv.org/pdf/2601.19273", "abs": "https://arxiv.org/abs/2601.19273", "authors": ["Niharika Sri Parasa", "Chaitali Diwan", "Srinath Srinivasa"], "title": "Riddle Quest : The Enigma of Words", "categories": ["cs.CL", "cs.AI", "cs.IT"], "comment": "This paper is submitted under 'Demo track' for WWW conference", "summary": "Riddles are concise linguistic puzzles that describe an object or idea through indirect, figurative, or playful clues. They are a longstanding form of creative expression, requiring the solver to interpret hints, recognize patterns, and draw inferences to identify the answers. In this work, we introduce a simple pipeline for creating and evaluating analogy-based riddles. The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy, a stylized generator that turns them into riddle clues, and a validator that collects all possible answers the riddle could point to. We use this validator to study whether large language models can recover the full answer set for different riddle types. Our case study shows that while models often guess the main intended answer, they frequently miss other valid interpretations. This highlights the value of riddles as a lightweight tool for examining reasoning coverage and ambiguity handling in language models.", "AI": {"tldr": "本文提出一个创建和评估基于类比的谜语流水线系统，通过结构化事实生成、语义映射、风格化生成和验证器来测试语言模型处理歧义和推理覆盖的能力。", "motivation": "研究谜语作为语言模型的测试工具，探索模型在解释间接线索、识别模式和推理答案方面的能力，特别是处理多义性和推理覆盖的挑战。", "method": "开发包含四个组件的流水线：三元组创建器构建概念结构化事实，语义映射器选择类比属性，风格化生成器制作谜语线索，验证器收集所有可能答案。使用验证器研究大型语言模型对不同类型谜语的完整答案集恢复能力。", "result": "案例研究表明，语言模型通常能猜出主要预期答案，但经常遗漏其他有效解释，显示出模型在处理歧义和推理覆盖方面的局限性。", "conclusion": "谜语作为轻量级工具具有重要价值，可用于检验语言模型的推理覆盖能力和歧义处理能力，揭示了当前模型在全面理解多义性内容方面的不足。"}}
{"id": "2601.19402", "pdf": "https://arxiv.org/pdf/2601.19402", "abs": "https://arxiv.org/abs/2601.19402", "authors": ["Amit Singh Bhatti", "Vishal Vaddina", "Dagnachew Birru"], "title": "PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems", "categories": ["cs.AI"], "comment": null, "summary": "Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might result. The relationship between parameters and outcomes is indirect, non-monotonic, and dataset-dependent. Operators need to specify accuracy targets, not infer them from opaque settings. We present PROTEUS (Polymorphic Router for Operational Target Enforcement with Unified SLA), a router that accepts accuracy targets tau as runtime input. PROTEUS uses Lagrangian dual control. A learned dual variable lambda tracks constraint violations during training and conditions the policy network. This lets the router translate specified tau values into routing decisions that satisfy them. A single trained model serves the full accuracy spectrum without retraining.We evaluate on RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries). PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau. The target-response correlation reaches 0.97 to 0.98. The closest baseline, OmniRouter, meets floors only 22% of the time despite also using Lagrangian optimization. PROTEUS operates across tau in [0.85, 0.95] from a single model. On RouterBench it achieves 90.1% accuracy, within 1.3% of oracle. On SPROUT it achieves 94.0% accuracy, within 4.6% of oracle. Cost savings reach 89.8% versus the best fixed model.", "AI": {"tldr": "PROTEUS是一个多态LLM路由器，通过接受准确率目标作为运行时输入，使用拉格朗日对偶控制实现指定精度要求的路由决策，无需重新训练即可服务全精度范围。", "motivation": "当前LLM路由系统需要离线调参且参数与结果关系不明确，操作员需要直接指定准确率目标而非从模糊设置中推断。", "method": "使用拉格朗日对偶控制方法，通过学习对偶变量lambda跟踪训练期间的约束违反情况，并调节策略网络，将指定的tau值转换为满足要求的路由决策。", "result": "在RouterBench和SPROUT数据集上评估，PROTEUS实现了稳定的下限合规性（准确率达到或超过tau），目标-响应相关性达0.97-0.98，相比最佳基线OmniRouter的22%合规率有显著提升。", "conclusion": "PROTEUS能够通过单一训练模型在[0.85,0.95]精度范围内操作，达到接近oracle的性能（RouterBench 90.1%，SPROUT 94.0%），相比最佳固定模型节省89.8%成本。"}}
{"id": "2601.19278", "pdf": "https://arxiv.org/pdf/2601.19278", "abs": "https://arxiv.org/abs/2601.19278", "authors": ["Fuliang Liu", "Xue Li", "Ketai Zhao", "Yinxi Gao", "Ziyan Zhou", "Zhonghui Zhang", "Zhibin Wang", "Wanchun Dou", "Sheng Zhong", "Chen Tian"], "title": "DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference", "categories": ["cs.CL"], "comment": null, "summary": "Speculative decoding is an effective and lossless approach for accelerating LLM inference. However, existing widely adopted model-based draft designs, such as EAGLE3, improve accuracy at the cost of multi-step autoregressive inference, resulting in high drafting latency and ultimately rendering the drafting stage itself a performance bottleneck. Inspired by diffusion-based large language models (dLLMs), we propose DART, which leverages parallel generation to reduce drafting latency. DART predicts logits for multiple future masked positions in parallel within a single forward pass based on hidden states of the target model, thereby eliminating autoregressive rollouts in the draft model while preserving a lightweight design. Based on these parallel logit predictions, we further introduce an efficient tree pruning algorithm that constructs high-quality draft token trees with N-gram-enforced semantic continuity. DART substantially reduces draft-stage overhead while preserving high draft accuracy, leading to significantly improved end-to-end decoding speed. Experimental results demonstrate that DART achieves a 2.03x--3.44x wall-clock time speedup across multiple datasets, surpassing EAGLE3 by 30% on average and offering a practical speculative decoding framework. Code is released at https://github.com/fvliang/DART.", "AI": {"tldr": "DART是一种基于并行生成的推测解码方法，通过单次前向传播预测多个未来位置的logits，消除自回归展开，显著减少草稿阶段延迟并提高端到端解码速度。", "motivation": "现有基于模型的草稿设计（如EAGLE3）虽然提高了准确性，但需要多步自回归推理，导致高草稿延迟，使草稿阶段成为性能瓶颈。", "method": "利用目标模型的隐藏状态，在单次前向传播中并行预测多个未来掩码位置的logits；引入高效的树剪枝算法构建具有N-gram强制语义连续性的高质量草稿标记树。", "result": "在多个数据集上实现了2.03x-3.44x的挂钟时间加速，平均超越EAGLE3 30%，显著提高了端到端解码速度。", "conclusion": "DART通过并行生成有效减少了草稿阶段开销，同时保持高草稿准确性，提供了一个实用的推测解码框架。"}}
{"id": "2601.19404", "pdf": "https://arxiv.org/pdf/2601.19404", "abs": "https://arxiv.org/abs/2601.19404", "authors": ["Hongzhu Yi", "Xinming Wang", "Zhenghao zhang", "Tianyu Zong", "Yuanxiang Wang", "Jun Xie", "Tao Yu", "Haopeng Jin", "Zhepeng Wang", "Kaixin Xu", "Feng Chen", "Jiahuan Chen", "Yujia Yang", "Zhenyu Guan", "Bingkang Shi", "Jungang Xu"], "title": "RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.", "AI": {"tldr": "RPO是一种新的强化微调算法，通过仅生成推理路径的后缀而非完整路径，显著减少训练时的计算开销和token生成量，同时保持与完整路径方法相当的性能。", "motivation": "传统强化微调算法需要生成完整的推理轨迹，导致训练阶段的rollout过程计算开销巨大。", "method": "提出RPO算法，基于经验缓存仅生成推理路径的后缀进行训练，减少约95%的token生成量。", "result": "RPO将1.5B模型的训练时间减少90%，7B模型减少72%，且能与GRPO、DAPO等算法集成，在保持性能的同时实现训练加速。", "conclusion": "RPO是一种即插即用的高效强化微调算法，显著降低计算成本，为大语言模型的强化微调提供了更高效的解决方案。"}}
{"id": "2601.19286", "pdf": "https://arxiv.org/pdf/2601.19286", "abs": "https://arxiv.org/abs/2601.19286", "authors": ["Jesus Lovon-Melgarejo", "Jose G. Moreno", "Christine Damase-Michel", "Lynda Tamine"], "title": "ReToP: Learning to Rewrite Electronic Health Records for Clinical Prediction", "categories": ["cs.CL"], "comment": "Accepted by WSDM 2026", "summary": "Electronic Health Records (EHRs) provide crucial information for clinical decision-making. However, their high-dimensionality, heterogeneity, and sparsity make clinical prediction challenging. Large Language Models (LLMs) allowed progress towards addressing this challenge by leveraging parametric medical knowledge to enhance EHR data for clinical prediction tasks. Despite the significant achievements made so far, most of the existing approaches are fundamentally task-agnostic in the sense that they deploy LLMs as EHR encoders or EHR completion modules without fully integrating signals from the prediction tasks. This naturally hinders task performance accuracy. In this work, we propose Rewrite-To-Predict (ReToP), an LLM-based framework that addresses this limitation through an end-to-end training of an EHR rewriter and a clinical predictor. To cope with the lack of EHR rewrite training data, we generate synthetic pseudo-labels using clinical-driven feature selection strategies to create diverse patient rewrites for fine-tuning the EHR rewriter. ReToP aligns the rewriter with prediction objectives using a novel Classifier Supervised Contribution (CSC) score that enables the EHR rewriter to generate clinically relevant rewrites that directly enhance prediction. Our ReToP framework surpasses strong baseline models across three clinical tasks on MIMIC-IV. Moreover, the analysis of ReToP shows its generalizability to unseen datasets and tasks with minimal fine-tuning while preserving faithful rewrites and emphasizing task-relevant predictive features.", "AI": {"tldr": "ReToP框架通过端到端训练EHR重写器和临床预测器，利用临床驱动的特征选择生成伪标签数据，使用分类器监督贡献分数使重写与预测目标对齐，在多个临床任务上超越基线模型。", "motivation": "现有LLM方法在EHR临床预测中多为任务无关的编码器或补全模块，未能充分利用预测任务信号，限制了性能准确性。", "method": "提出ReToP框架：1) 使用临床驱动特征选择生成伪标签训练数据；2) 端到端训练EHR重写器和临床预测器；3) 引入Classifier Supervised Contribution分数使重写与预测目标对齐。", "result": "在MIMIC-IV的三个临床任务上超越了强基线模型，展示了在未见数据集和任务上的良好泛化能力，同时保持忠实重写和强调任务相关特征。", "conclusion": "ReToP通过任务感知的EHR重写有效提升了临床预测性能，证明了端到端训练和预测目标对齐的重要性，为LLM在EHR分析中的应用提供了新思路。"}}
{"id": "2601.19527", "pdf": "https://arxiv.org/pdf/2601.19527", "abs": "https://arxiv.org/abs/2601.19527", "authors": ["Temirbolat Maratuly", "Pakizar Shamoi", "Timur Samigulin"], "title": "Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach", "categories": ["cs.AI"], "comment": null, "summary": "Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.", "AI": {"tldr": "本文开发了一个结合模糊专家系统和数字孪生的智能控制系统，用于酸性水净化处理，通过模拟人类推理实现参数优化控制，减少人工干预并降低运营成本。", "motivation": "酸性水含有硫化氢、二氧化碳等腐蚀性成分，未经处理会危害环境和加速设备腐蚀。传统处理过程需要人工干预，存在安全风险和操作复杂性，需要开发自动化智能控制系统。", "method": "采用模糊专家系统结合Honeywell UniSim Design R492开发的数字孪生模型，通过MATLAB进行系统识别建模阀门动态，使用OPC DA实现实时数据交换。控制器采用分程控制策略，在105种测试场景下评估性能。", "result": "系统使用6种误差指标和多种动态响应指标进行评估，开发了基于Python Streamlit的web仿真界面。模糊控制器能够有效维持关键参数在期望水平。", "conclusion": "提出的模糊专家系统具有通用性，虽然以酸性水处理为例展示，但可应用于其他工业过程控制，简化操作并提高安全性。"}}
{"id": "2601.19290", "pdf": "https://arxiv.org/pdf/2601.19290", "abs": "https://arxiv.org/abs/2601.19290", "authors": ["Yimeng Wang", "Jiaxing Zhao", "Hongbin Xie", "Hexing Ma", "Yuzhen Lei", "Shuangxue Liu", "Xuan Song", "Zichen Zhang", "Haoran Zhang"], "title": "MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.", "AI": {"tldr": "MetaGen是一个无需训练的多智能体框架，可在推理时动态调整角色空间和协作拓扑结构，通过查询条件角色规范和轻量级反馈信号来优化多智能体协作性能。", "motivation": "现有大多数多智能体系统依赖固定的角色库和冻结的交互拓扑结构，这种刚性设计导致任务不匹配、无法及时适应推理过程中的新证据，并增加了推理成本。", "method": "MetaGen在推理时生成和重写查询条件角色规范以维护动态角色池，围绕最小骨干网络实例化约束执行图，并通过轻量级反馈信号迭代更新角色提示和调整结构决策。", "result": "在代码生成和多步推理基准测试中，MetaGen相比强大的多智能体基线方法，在准确性和成本权衡方面表现更优。", "conclusion": "MetaGen框架通过动态角色和拓扑调整，有效解决了传统多智能体系统的刚性限制，实现了更好的性能和成本效率，无需更新基础模型权重。"}}
{"id": "2601.19532", "pdf": "https://arxiv.org/pdf/2601.19532", "abs": "https://arxiv.org/abs/2601.19532", "authors": ["Marthe Ballon", "Andres Algaba", "Brecht Verbeken", "Vincent Ginis"], "title": "Benchmarks Saturate When The Model Gets Smarter Than The Judge", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 pages, 10 figures, 3 tables", "summary": "Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.", "AI": {"tldr": "Omni-MATH-2是一个经过人工修订的数学评测数据集，包含4181个精确答案问题和247个标记非标准问题，通过减少数据集噪声和评估法官误差，为LLM性能评估提供更准确的基准。", "motivation": "现有大型语言模型评测基准存在数据集不准确和评估方法问题，这些缺陷影响了评测的有效性和模型性能评估的准确性。", "method": "手动审核Omni-MATH数据集，确保LaTeX可编译性、可解性和可验证性；添加缺失图表信息；标记需要证明、估算或图像的问题；清理杂乱内容；通过专家标注评估法官误差。", "result": "创建了清洁的Omni-MATH-2数据集；发现GPT-5 mini与原Omni-Judge在评估中存在显著差异；Omni-Judge在96.4%的法官分歧中错误；随着问题难度增加，需要更专业的法官来避免误差掩盖模型真实差异。", "conclusion": "数据集质量和法官可靠性对于开发准确的模型性能基准都至关重要，两者缺一不可，需要同时改进以确保评测的有效性。"}}
{"id": "2601.19302", "pdf": "https://arxiv.org/pdf/2601.19302", "abs": "https://arxiv.org/abs/2601.19302", "authors": ["Natapong Nitarach", "Pittawat Taveekitworachai", "Kunat Pipatanakul"], "title": "Formula-One Prompting: Adaptive Reasoning Through Equations For Applied Mathematics", "categories": ["cs.CL"], "comment": null, "summary": "Prompting techniques such as Chain-of-Thought (CoT) and Program-of-Thought (PoT) improve LLM mathematical reasoning by structuring intermediate steps in natural language or code. However, applied mathematics problems in domains like finance, physics, and cryptography often require recalling or deriving governing equations, a step that current approaches do not explicitly leverage. We propose Formula-One Prompting (F-1), a two-phase approach that uses mathematical equations as an intermediate representation before adaptive solving. F-1 first formulates governing equations from problem descriptions, then selects a solving strategy among CoT, PoT, or direct computation based on the generated equations, all within a single LLM call. Results across five models and four benchmarks show F-1 outperforms CoT by +5.76% and PoT by +8.42% on average. Crucially, gains are largest in applied domains: +13.30% on FinanceMath over CoT, and within OlympiadBench, larger gains on physics (+2.55%) than pure math (+0.44%). This demonstrates that F-1 is more effective than CoT in applied mathematics problems.", "AI": {"tldr": "F-1 Prompting是一种两阶段提示方法，先提取控制方程，再选择求解策略，显著提升LLM在应用数学问题上的表现。", "motivation": "现有CoT和PoT提示方法在应用数学问题中未能充分利用控制方程的推导和调用，导致在金融、物理等领域的数学推理效果受限。", "method": "提出Formula-One Prompting (F-1)两阶段方法：1) 从问题描述中提取控制方程；2) 基于生成的方程自适应选择CoT、PoT或直接计算策略，所有步骤在单次LLM调用中完成。", "result": "在5个模型和4个基准测试中，F-1平均比CoT提升5.76%，比PoT提升8.42%。在应用领域表现尤为突出：FinanceMath上比CoT提升13.30%，OlympiadBench中物理问题提升2.55%（纯数学仅0.44%）。", "conclusion": "F-1通过显式利用数学方程作为中间表示，有效提升了LLM在应用数学问题上的推理能力，特别是在需要推导控制方程的领域表现卓越。"}}
{"id": "2601.19568", "pdf": "https://arxiv.org/pdf/2601.19568", "abs": "https://arxiv.org/abs/2601.19568", "authors": ["Ke Xu", "Siyang Xiao", "Ming Liang", "Yichen Yu", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "Learning Adaptive Parallel Execution for Efficient Code Localization", "categories": ["cs.AI", "cs.SE"], "comment": "13 pages, 4 figures", "summary": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.", "AI": {"tldr": "FuseSearch是一个通过联合质量-效率优化来提升并行代码定位性能的方法，通过动态调整搜索宽度和消除冗余调用，在保持SOTA性能的同时显著提升效率和降低资源消耗", "motivation": "当前自动化软件开发流水线中，代码定位是关键瓶颈，现有代理存在34.9%的冗余调用率，抵消了并行化的优势", "method": "提出FuseSearch方法，将并行代码定位重新定义为联合质量-效率优化任务，定义工具效率指标，采用两阶段SFT和RL训练方法学习自适应并行策略，动态调整搜索宽度", "result": "在SWE-bench Verified上评估，FuseSearch-4B达到84.7%文件级和56.4%函数级F1分数，实现93.6%的速度提升，减少67.7%的轮次和68.9%的token使用", "conclusion": "效率感知训练通过消除噪声冗余信号自然提升质量，能够实现高性能且成本效益高的代码定位代理"}}
{"id": "2601.19334", "pdf": "https://arxiv.org/pdf/2601.19334", "abs": "https://arxiv.org/abs/2601.19334", "authors": ["Jianzhe Chai", "Yu Zhe", "Jun Sakuma"], "title": "When Benchmarks Leak: Inference-Time Decontamination for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Benchmark-based evaluation is the de facto standard for comparing large language models (LLMs). However, its reliability is increasingly threatened by test set contamination, where test samples or their close variants leak into training data and artificially inflate reported performance. To address this issue, prior work has explored two main lines of mitigation. One line attempts to identify and remove contaminated benchmark items before evaluation, but this inevitably alters the evaluation set itself and becomes unreliable when contamination is moderate or severe. The other line preserves the benchmark and instead suppresses contaminated behavior at evaluation time; however, such interventions often interfere with normal inference and lead to noticeable performance degradation on clean inputs. We propose DeconIEP, a decontamination framework that operates entirely during evaluation by applying small, bounded perturbations in the input embedding space. Guided by a relatively less-contaminated reference model, DeconIEP learns an instance-adaptive perturbation generator that steers the evaluated model away from memorization-driven shortcut pathways. Across multiple open-weight LLMs and benchmarks, extensive empirical results show that DeconIEP achieves strong decontamination effectiveness while incurring only minimal degradation in benign utility.", "AI": {"tldr": "DeconIEP是一个在评估阶段通过输入嵌入空间的小扰动来净化测试集污染的新框架，既能有效去污又保持模型在干净输入上的性能", "motivation": "基准测试是评估大语言模型的标准方法，但测试集污染问题日益严重，现有方法要么需要修改评估集，要么会干扰正常推理导致性能下降", "method": "提出DeconIEP框架，在评估阶段对输入嵌入空间应用有界小扰动，通过相对较少污染的参考模型指导，学习实例自适应的扰动生成器，使被评估模型避开记忆驱动的捷径路径", "result": "在多个开源LLM和基准测试上的实验表明，DeconIEP实现了强大的去污效果，同时在良性效用上仅产生最小程度的性能下降", "conclusion": "DeconIEP提供了一种有效的评估时去污解决方案，能够在保持基准测试完整性的同时有效缓解测试集污染问题"}}
{"id": "2601.19607", "pdf": "https://arxiv.org/pdf/2601.19607", "abs": "https://arxiv.org/abs/2601.19607", "authors": ["Haoyun Li", "Ming Xiao", "Kezhi Wang", "Robert Schober", "Dong In Kim", "Yong Liang Guan"], "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks", "categories": ["cs.AI"], "comment": null, "summary": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.", "AI": {"tldr": "ComAgent是一个多LLM代理AI框架，通过感知-规划-行动-反思闭环循环，自动将6G网络的高层意图转化为可求解的数学公式和可复现的仿真，在复杂波束成形优化中达到专家级性能。", "motivation": "6G网络依赖复杂的跨层优化，但将高层意图手动转化为数学公式仍是一个瓶颈。现有的单一大语言模型方法缺乏足够的领域基础、约束意识和验证能力。", "method": "采用多LLM代理框架，通过感知-规划-行动-反思的闭环循环，协调专门的代理进行文献搜索、编码和评分，自主生成可求解的公式和可复现的仿真，通过迭代分解问题和自我纠正错误来弥合用户意图与执行之间的差距。", "result": "评估显示ComAgent在复杂波束成形优化中实现与专家相当的性能，并在各种无线任务中优于单一大语言模型。", "conclusion": "ComAgent框架在自动化新兴无线网络设计方面具有巨大潜力，能够有效弥合用户意图与执行之间的差距。"}}
{"id": "2601.19350", "pdf": "https://arxiv.org/pdf/2601.19350", "abs": "https://arxiv.org/abs/2601.19350", "authors": ["Tathagata Raha", "Clement Christophe", "Nada Saadi", "Hamza A Javed", "Marco AF Pimentel", "Ronnie Rajan", "Praveenkumar Kanithi"], "title": "Cross-Examination Framework: A Task-Agnostic Diagnostic for Information Fidelity in Text-to-Text Generation", "categories": ["cs.CL"], "comment": null, "summary": "Traditional metrics like BLEU and BERTScore fail to capture semantic fidelity in generative text-to-text tasks. We adapt the Cross-Examination Framework (CEF) for a reference-free, multi-dimensional evaluation by treating the source and candidate as independent knowledge bases. CEF generates verifiable questions from each text and performs a cross-examination to derive three interpretable scores: Coverage, Conformity, and Consistency. Validated across translation, summarization and clinical note-generation, our framework identifies critical errors, such as content omissions and factual contradictions, missed by standard metrics. A key contribution is a systematic robustness analysis to select a stable judge model. Crucially, the strong correlation between our reference-free and with-reference modes validates CEF's reliability without gold references. Furthermore, human expert validation demonstrates that CEF mismatching questions align with meaning-altering semantic errors higher than with non-semantic errors, particularly excelling at identifying entity-based and relational distortions.", "AI": {"tldr": "本文提出了Cross-Examination Framework (CEF)，一种无需参考文本的多维度评估框架，通过将源文本和候选文本视为独立知识库，生成可验证问题并进行交叉检验，有效识别传统指标遗漏的语义错误。", "motivation": "传统评估指标如BLEU和BERTScore在生成式文本到文本任务中无法有效捕捉语义保真度，存在内容遗漏和事实矛盾等关键错误检测不足的问题。", "method": "将源文本和候选文本作为独立知识库，生成可验证问题并进行交叉检验，得出Coverage、Conformity和Consistency三个可解释分数。通过系统性鲁棒性分析选择稳定的评判模型。", "result": "在翻译、摘要和临床笔记生成任务中验证有效，能够识别标准指标遗漏的错误。无参考模式与有参考模式强相关，验证了可靠性。人工专家验证显示CEF不匹配问题与语义错误高度一致，特别擅长识别基于实体和关系的扭曲。", "conclusion": "CEF框架提供了一种无需参考文本的可靠语义保真度评估方法，能够有效检测生成文本中的语义错误，在多个文本生成任务中表现出色。"}}
{"id": "2601.19622", "pdf": "https://arxiv.org/pdf/2601.19622", "abs": "https://arxiv.org/abs/2601.19622", "authors": ["Thomas Bömer", "Nico Koltermann", "Max Disselnmeyer", "Bastian Amberg", "Anne Meyer"], "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search", "categories": ["cs.AI", "math.OC"], "comment": "accepted at EvoStar conference; Code: https://github.com/tb-git-tud/a-ceoh-evolution-of-heuristics?tab=readme-ov-file", "summary": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.", "AI": {"tldr": "论文提出A-CEoH框架，通过将A*算法代码融入提示词来利用上下文学习，自动生成启发式函数，在UPMP和SPP问题上表现优于人工设计的启发式", "motivation": "传统启发式函数需要手工设计且依赖专家知识，而大语言模型和进化框架的发展为自动化启发式设计提供了可能", "method": "扩展EoH框架，提出领域无关的提示增强策略A-CEoH，将A*代码融入提示词以利用上下文学习", "result": "在单元负载预整理问题和滑块拼图问题上，A-CEoH显著提升了生成启发式的质量，甚至超越了专家设计的启发式", "conclusion": "A-CEoH框架有效实现了启发式函数的自动化生成，为树搜索算法的性能优化提供了新途径"}}
{"id": "2601.19360", "pdf": "https://arxiv.org/pdf/2601.19360", "abs": "https://arxiv.org/abs/2601.19360", "authors": ["Diego Rossini", "Lonneke van der Plas"], "title": "Binary Token-Level Classification with DeBERTa for All-Type MWE Identification: A Lightweight Approach with Linguistic Enhancement", "categories": ["cs.CL"], "comment": "Accepted at Findings of EACL 2026", "summary": "We present a comprehensive approach for multiword expression (MWE) identification that combines binary token-level classification, linguistic feature integration, and data augmentation. Our DeBERTa-v3-large model achieves 69.8% F1 on the CoAM dataset, surpassing the best results (Qwen-72B, 57.8% F1) on this dataset by 12 points while using 165x fewer parameters. We achieve this performance by (1) reformulating detection as binary token-level START/END/INSIDE classification rather than span-based prediction, (2) incorporating NP chunking and dependency features that help discontinuous and NOUN-type MWEs identification, and (3) applying oversampling that addresses severe class imbalance in the training data. We confirm the generalization of our method on the STREUSLE dataset, achieving 78.9% F1. These results demonstrate that carefully designed smaller models can substantially outperform LLMs on structured NLP tasks, with important implications for resource-constrained deployments.", "AI": {"tldr": "提出结合二元词元分类、语言特征集成和数据增强的多词表达识别方法，DeBERTa-v3-large模型在CoAM数据集上达到69.8% F1分数，比之前最佳结果提升12个百分点且参数量减少165倍", "motivation": "解决多词表达识别任务中传统方法的局限性，特别是针对不连续和名词类多词表达的识别问题，以及训练数据中的严重类别不平衡问题", "method": "1) 将检测重构为二元词元级START/END/INSIDE分类而非基于跨度的预测；2) 集成NP分块和依存特征以帮助识别不连续和名词类多词表达；3) 应用过采样技术解决训练数据中的类别不平衡", "result": "在CoAM数据集上达到69.8% F1分数，比Qwen-72B的57.8%提升12个百分点；在STREUSLE数据集上达到78.9% F1分数，验证了方法的泛化能力", "conclusion": "精心设计的小型模型在结构化NLP任务中可以显著超越大型语言模型，这对资源受限的部署环境具有重要意义"}}
{"id": "2601.19752", "pdf": "https://arxiv.org/pdf/2601.19752", "abs": "https://arxiv.org/abs/2601.19752", "authors": ["Minh-Dung Dao", "Quy Minh Le", "Hoang Thanh Lam", "Duc-Trong Le", "Quoc-Viet Pham", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Agentic Design Patterns: A System-Theoretic Framework", "categories": ["cs.AI"], "comment": null, "summary": "With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.", "AI": {"tldr": "本文提出了一个基于系统理论的AI智能体工程设计方法，包括一个五功能子系统框架和12个设计模式，用于解决智能体系统设计中的可靠性问题。", "motivation": "现有智能体AI系统存在幻觉、推理能力差等固有问题，且系统设计往往缺乏严谨的理论基础，导致应用不可靠和脆弱。现有设计模式分类缺乏系统性理论基础，难以实施。", "method": "提出系统理论框架，将智能体系统解构为五个核心交互功能子系统：推理与世界模型、感知与接地、动作执行、学习与适应、智能体间通信。基于此架构，提出了12个设计模式，分为基础类、认知决策类、执行交互类、适应学习类。", "result": "通过ReAct框架的案例研究展示了该框架的实用性，证明所提设计模式能够纠正系统性架构缺陷。", "conclusion": "这项工作为研究人员和工程师提供了标准化的智能体设计语言和结构化方法，有助于构建更模块化、可理解和可靠的自适应系统。"}}
{"id": "2601.19410", "pdf": "https://arxiv.org/pdf/2601.19410", "abs": "https://arxiv.org/abs/2601.19410", "authors": ["Ahrii Kim", "Seong-heum Kim"], "title": "Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?", "categories": ["cs.CL"], "comment": null, "summary": "Automatic post-editing (APE) aims to refine machine translations by correcting residual errors. Although recent large language models (LLMs) demonstrate strong translation capabilities, their effectiveness for APE--especially under document-level context--remains insufficiently understood. We present a systematic comparison of proprietary and open-weight LLMs under a naive document-level prompting setup, analyzing APE quality, contextual behavior, robustness, and efficiency.\n  Our results show that proprietary LLMs achieve near human-level APE quality even with simple one-shot prompting, regardless of whether document context is provided. While these models exhibit higher robustness to data poisoning attacks than open-weight counterparts, this robustness also reveals a limitation: they largely fail to exploit document-level context for contextual error correction. Furthermore, standard automatic metrics do not reliably reflect these qualitative improvements, highlighting the continued necessity of human evaluation. Despite their strong performance, the substantial cost and latency overheads of proprietary LLMs render them impractical for real-world APE deployment. Overall, our findings elucidate both the promise and current limitations of LLM-based document-aware APE, and point toward the need for more efficient long-context modeling approaches for translation refinement.", "AI": {"tldr": "LLM在文档级自动后编辑中的系统评估：专有模型接近人类水平但成本高，开源模型表现较差，所有模型都难以有效利用文档上下文进行纠错", "motivation": "虽然大语言模型在翻译方面表现出色，但其在文档级自动后编辑(APE)中的有效性，特别是在利用文档上下文方面的能力，尚未得到充分研究", "method": "采用简单的文档级提示设置，系统比较专有和开源LLM在APE质量、上下文行为、鲁棒性和效率方面的表现", "result": "专有LLM即使使用简单的一次性提示也能达到接近人类水平的APE质量，但对数据投毒攻击的鲁棒性较高反而限制了其利用文档上下文进行纠错的能力；标准自动评估指标无法可靠反映质量改进；专有LLM的高成本和延迟使其在实际部署中不实用", "conclusion": "LLM在文档感知APE方面既有前景也有当前局限性，需要更高效的长上下文建模方法来进行翻译优化"}}
{"id": "2601.19768", "pdf": "https://arxiv.org/pdf/2601.19768", "abs": "https://arxiv.org/abs/2601.19768", "authors": ["Shir Rozenfeld", "Rahul Pankajakshan", "Itay Zloczower", "Eyal Lenga", "Gilad Gressel", "Yisroel Mirsky"], "title": "GAVEL: Towards rule-based safety through activation monitoring", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "Accepted to ICLR 2026", "summary": "Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.", "AI": {"tldr": "论文提出了一种基于规则的激活安全新范式，通过将语言模型的激活状态建模为可解释的认知元素，并定义组合规则来实时检测有害行为，解决了现有方法精度低、灵活性差和可解释性不足的问题。", "motivation": "现有基于激活的安全监控方法在大规模误用数据集上训练，存在精度低、灵活性有限和缺乏可解释性的问题，需要一种更精确、可定制且透明的安全检测方法。", "method": "提出将激活状态建模为细粒度可解释的认知元素(CEs)，并在此基础上定义谓词规则来实时检测违规行为，支持无需重新训练模型即可配置和更新安全防护措施。", "result": "基于组合规则的激活安全方法提高了检测精度，支持领域定制化，为可扩展、可解释和可审计的AI治理奠定了基础。", "conclusion": "该研究提出的GAVEL框架为AI安全监控提供了一种新的有效方法，通过开源框架和自动化规则创建工具，促进了透明和可审计的AI治理实践。"}}
{"id": "2601.19447", "pdf": "https://arxiv.org/pdf/2601.19447", "abs": "https://arxiv.org/abs/2601.19447", "authors": ["Vítor N. Lourenço", "Aline Paes", "Tillman Weyde", "Audrey Depeige", "Mohnish Dubey"], "title": "KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to publication at the 19th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2026", "summary": "Claim verification is a core component of automated fact-checking systems, aimed at determining the truthfulness of a statement by assessing it against reliable evidence sources such as documents or knowledge bases. This work presents KG-CRAFT, a method that improves automatic claim verification by leveraging large language models (LLMs) augmented with contrastive questions grounded in a knowledge graph. KG-CRAFT first constructs a knowledge graph from claims and associated reports, then formulates contextually relevant contrastive questions based on the knowledge graph structure. These questions guide the distillation of evidence-based reports, which are synthesised into a concise summary that is used for veracity assessment by LLMs. Extensive evaluations on two real-world datasets (LIAR-RAW and RAWFC) demonstrate that our method achieves a new state-of-the-art in predictive performance. Comprehensive analyses validate in detail the effectiveness of our knowledge graph-based contrastive reasoning approach in improving LLMs' fact-checking capabilities.", "AI": {"tldr": "KG-CRAFT是一个基于知识图谱对比推理的自动声明验证方法，通过构建知识图谱并生成对比性问题来增强大语言模型的事实核查能力，在两个真实数据集上实现了最先进的性能。", "motivation": "自动事实核查系统中的声明验证需要依赖可靠证据源来评估陈述的真实性，现有方法在有效利用结构化知识和进行对比推理方面存在不足。", "method": "首先从声明和相关报告中构建知识图谱，然后基于图谱结构生成上下文相关的对比性问题，这些问题指导基于证据的报告提炼，最终合成简洁摘要供大语言模型进行真实性评估。", "result": "在LIAR-RAW和RAWFC两个真实数据集上的广泛评估表明，该方法在预测性能上达到了新的最先进水平。", "conclusion": "基于知识图谱的对比推理方法能有效提升大语言模型的事实核查能力，为自动声明验证提供了新的有效途径。"}}
{"id": "2601.19793", "pdf": "https://arxiv.org/pdf/2601.19793", "abs": "https://arxiv.org/abs/2601.19793", "authors": ["Shanyv Liu", "Xuyang Yuan", "Tao Chen", "Zijun Zhan", "Zhu Han", "Danyang Zheng", "Weishan Zhang", "Shaohua Cao"], "title": "CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing", "categories": ["cs.AI"], "comment": null, "summary": "Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.", "AI": {"tldr": "CASTER是一个轻量级路由器，用于图基多智能体系统中的动态模型选择，通过语义嵌入和结构元特征结合来估计任务难度，在保持成功率的同时显著降低推理成本。", "motivation": "基于图的多智能体系统存在静态模型分配效率低下的问题，统一部署强大模型会在简单子任务上浪费计算资源。", "method": "提出CASTER路由器，采用双信号路由器结合语义嵌入和结构元特征来估计任务难度，通过冷启动到迭代进化的训练范式，利用自身路由失败的策略性负反馈进行自优化。", "result": "在软件工程、数据分析、科学发现和网络安全领域的实验中，CASTER相比强模型基线减少推理成本高达72.4%，同时保持相同的成功率，在所有领域都优于启发式路由和FrugalGPT。", "conclusion": "CASTER通过动态模型选择和自优化路由机制，有效解决了图基多智能体系统中的计算资源浪费问题，实现了高效的任务执行。"}}
{"id": "2601.19451", "pdf": "https://arxiv.org/pdf/2601.19451", "abs": "https://arxiv.org/abs/2601.19451", "authors": ["Isha Pandey", "Ashish Mittal", "Vartul Bahuguna", "Ganesh Ramakrishnan"], "title": "Dynamic Multi-Expert Projectors with Stabilized Routing for Multilingual Speech Recognition", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in LLM-based ASR connect frozen speech encoders with Large Language Models (LLMs) via lightweight projectors. While effective in monolingual settings, a single projector struggles to capture the diverse acoustic-to-semantic mappings required for multilingual ASR. To address this, we propose SMEAR-MoE, a stabilized Mixture-of-Experts projector that ensures dense gradient flow to all experts, preventing expert collapse while enabling cross-lingual sharing. We systematically compare monolithic, static multi-projector, and dynamic MoE designs across four Indic languages (Hindi, Marathi, Tamil, Telugu). Our SMEAR-MoE achieves strong performance, delivering upto a 7.6% relative WER reduction over the single-projector baseline, while maintaining comparable runtime efficiency. Analysis of expert routing further shows linguistically meaningful specialization, with related languages sharing experts. These results demonstrate that stable multi-expert projectors are key to scalable and robust multilingual ASR.", "AI": {"tldr": "SMEAR-MoE：一种稳定的专家混合投影器，通过确保所有专家的密集梯度流来解决多语言ASR中单一投影器无法捕捉多样化声学-语义映射的问题，在四种印度语言上实现7.6%的相对WER降低。", "motivation": "现有的LLM-based ASR在单语环境下有效，但单一投影器难以捕捉多语言ASR所需的多样化声学-语义映射，需要更好的多语言投影解决方案。", "method": "提出SMEAR-MoE（稳定专家混合投影器），系统比较了单体、静态多投影器和动态MoE设计，在四种印度语言（印地语、马拉地语、泰米尔语、泰卢固语）上进行实验。", "result": "SMEAR-MoE相比单一投影器基线实现高达7.6%的相对WER降低，同时保持相当的运行时效率。专家路由分析显示语言学上有意义的分工，相关语言共享专家。", "conclusion": "稳定的多专家投影器是实现可扩展和鲁棒多语言ASR的关键，SMEAR-MoE有效解决了多语言声学-语义映射的多样性问题。"}}
{"id": "2601.19824", "pdf": "https://arxiv.org/pdf/2601.19824", "abs": "https://arxiv.org/abs/2601.19824", "authors": ["Andre Paulino de Lima", "Paula Castro", "Suzana Carvalho Vaz de Andrade", "Rosa Maria Marcucci", "Ruth Caldeira de Melo", "Marcelo Garcia Manzato"], "title": "An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care", "categories": ["cs.AI", "cs.HC", "cs.IR", "cs.SI"], "comment": "81 pages, 19 figures, 3 annexes", "summary": "There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.", "AI": {"tldr": "该论文提出了一个针对老年医学初级护理的推荐系统模型，通过心理测量数据结构提供可视化解释，解决医疗推荐系统中的数据稀缺性、可解释性和风险评估等挑战。", "motivation": "医疗推荐系统面临公开临床数据缺乏、用户难以理解推荐原因、遵循推荐可能存在的风险以及效果不确定性等挑战，特别是在老年医学护理这一需求增长的细分领域。", "method": "利用心理测量数据的结构化特征构建推荐模型，生成忠实于模型且护理专业人员可解释的可视化解释，并在巴西收集的医疗数据集上进行离线性能评估和用户研究。", "result": "比较评估显示该模型在医疗数据集上表现良好，用户研究证实了模型生成的可视化解释具有良好的可解释性。", "conclusion": "所提出的推荐模型能够推动推荐系统在老年医学初级护理这一细分领域的应用，随着人口结构变化带来的需求增长，该领域的信息技术需求将不断增加。"}}
{"id": "2601.19490", "pdf": "https://arxiv.org/pdf/2601.19490", "abs": "https://arxiv.org/abs/2601.19490", "authors": ["Ricardo Campos", "Raquel Sequeira", "Sara Nerea", "Inês Cantante", "Diogo Folques", "Luís Filipe Cunha", "João Canavilhas", "António Branco", "Alípio Jorge", "Sérgio Nunes", "Nuno Guimarães", "Purificação Silvano"], "title": "ClaimPT: A Portuguese Dataset of Annotated Claims in News Articles", "categories": ["cs.CL"], "comment": null, "summary": "Fact-checking remains a demanding and time-consuming task, still largely dependent on manual verification and unable to match the rapid spread of misinformation online. This is particularly important because debunking false information typically takes longer to reach consumers than the misinformation itself; accelerating corrections through automation can therefore help counter it more effectively. Although many organizations perform manual fact-checking, this approach is difficult to scale given the growing volume of digital content. These limitations have motivated interest in automating fact-checking, where identifying claims is a crucial first step. However, progress has been uneven across languages, with English dominating due to abundant annotated data. Portuguese, like other languages, still lacks accessible, licensed datasets, limiting research, NLP developments and applications. In this paper, we introduce ClaimPT, a dataset of European Portuguese news articles annotated for factual claims, comprising 1,308 articles and 6,875 individual annotations. Unlike most existing resources based on social media or parliamentary transcripts, ClaimPT focuses on journalistic content, collected through a partnership with LUSA, the Portuguese News Agency. To ensure annotation quality, two trained annotators labeled each article, with a curator validating all annotations according to a newly proposed scheme. We also provide baseline models for claim detection, establishing initial benchmarks and enabling future NLP and IR applications. By releasing ClaimPT, we aim to advance research on low-resource fact-checking and enhance understanding of misinformation in news media.", "AI": {"tldr": "本文介绍了ClaimPT数据集，这是一个包含1,308篇葡萄牙新闻文章和6,875个标注的欧洲葡萄牙语事实声明数据集，旨在解决葡萄牙语事实核查数据稀缺问题。", "motivation": "事实核查任务耗时且难以规模化，而葡萄牙语等低资源语言缺乏标注数据集，限制了自动化事实核查的研究和应用发展。", "method": "通过与葡萄牙新闻社LUSA合作收集新闻文章，采用两名训练有素的标注员进行标注，并由审核员使用新提出的标注方案验证所有标注质量。", "result": "创建了ClaimPT数据集，提供了声明检测的基线模型，为未来的NLP和信息检索应用建立了初步基准。", "conclusion": "ClaimPT数据集的发布将推动低资源语言事实核查研究，并增强对新闻媒体中错误信息的理解。"}}
{"id": "2601.19825", "pdf": "https://arxiv.org/pdf/2601.19825", "abs": "https://arxiv.org/abs/2601.19825", "authors": ["Saikrishna Sudarshan", "Tanay Kulkarni", "Manasi Patwardhan", "Lovekesh Vig", "Ashwin Srinivasan", "Tanmay Tulsidas Verlekar"], "title": "Routing End User Queries to Enterprise Databases", "categories": ["cs.AI", "cs.DB"], "comment": "6 pages, 2 figures", "summary": "We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.", "AI": {"tldr": "论文提出了一个在多元数据库企业环境中路由自然语言查询的方法，通过扩展现有NL-to-SQL数据集构建基准测试，展示了模块化推理驱动重排序策略的优越性。", "motivation": "随着数据库规模增大和领域重叠增加，查询路由变得越来越具有挑战性，需要更结构化、基于推理的鲁棒解决方案来处理模糊查询。", "method": "通过显式建模模式覆盖、结构连接性和细粒度语义对齐，提出模块化的推理驱动重排序策略。", "result": "该方法在所有指标上始终优于仅使用嵌入和直接LLM提示的基线方法。", "conclusion": "研究表明，在复杂的企业数据库环境中，基于结构化推理的路由策略比传统方法更有效，为解决多数据库查询路由问题提供了有效解决方案。"}}
{"id": "2601.19503", "pdf": "https://arxiv.org/pdf/2601.19503", "abs": "https://arxiv.org/abs/2601.19503", "authors": ["Wei Huang", "Anda Cheng", "Yinggui Wang"], "title": "GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICLR2026", "summary": "Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.", "AI": {"tldr": "GradPruner是一种在微调早期阶段通过梯度引导剪裁LLM层的方法，能够在减少40%参数的同时仅损失0.99%的准确率，显著提升训练和推理效率。", "motivation": "传统结构化剪枝方法在提升预训练模型推理效率时需要额外的时间、内存和训练成本，使得下游任务的高效微调难以实现。", "method": "在微调初期阶段，使用参数累积梯度计算初始梯度信息积累矩阵(IGIA-Matrix)来评估层重要性并进行剪枝，基于IGIA-Matrix稀疏化剪裁层并与剩余层合并，仅合并符号相同的元素以减少符号变化干扰。", "result": "在两个大型语言模型和八个下游数据集（包括医疗、金融和通用基准任务）上的实验表明，实现了40%的参数减少，准确率仅下降0.99%。", "conclusion": "GradPruner能够同时提升下游任务微调的训练和推理效率，通过梯度引导的早期层剪枝实现了高效的模型压缩。"}}
{"id": "2601.19834", "pdf": "https://arxiv.org/pdf/2601.19834", "abs": "https://arxiv.org/abs/2601.19834", "authors": ["Jialong Wu", "Xiaoying Zhang", "Hongyi Yuan", "Xiangcheng Zhang", "Tianhao Huang", "Changjing He", "Chaoyi Deng", "Renrui Zhang", "Youbin Wu", "Mingsheng Long"], "title": "Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models", "categories": ["cs.AI"], "comment": "Project page: https://thuml.github.io/Reasoning-Visual-World", "summary": "Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.", "AI": {"tldr": "论文研究了视觉生成在推理中的价值，提出了视觉优势假说，发现在物理世界相关任务中，视觉-语言交织的思维链推理显著优于纯语言推理，但在其他任务中没有明显优势。", "motivation": "当前AI在数学和编程等抽象领域表现出色，但在物理和空间智能方面仍远落后于人类。多模态模型的出现引发了人们对更接近人类的多模态推理的兴趣，但其具体效益尚不明确。", "method": "从世界模型角度出发，理论形式化内部世界建模作为思维链推理的核心组件，并构建了新的评估套件VisWorld-Eval进行受控实验。", "result": "在先进的多模态模型上的实验表明，在有利于视觉世界建模的任务中，交织的视觉-语言思维链推理显著优于纯语言推理，但在其他任务中没有明显优势。", "conclusion": "这项工作阐明了多模态世界建模在构建更强大、更类人的多模态AI方面的潜力，特别是在需要物理世界基础的任务中视觉生成能更自然地充当世界模型。"}}
{"id": "2601.19507", "pdf": "https://arxiv.org/pdf/2601.19507", "abs": "https://arxiv.org/abs/2601.19507", "authors": ["Xiangyang Zhu", "Yuan Tian", "Zicheng Zhang", "Qi Jia", "Chunyi Li", "Renrui Zhang", "Heng Li", "Zongrui Wang", "Wei Sun"], "title": "Automated Safety Benchmarking: A Multi-agent Pipeline for LVLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large vision-language models (LVLMs) exhibit remarkable capabilities in cross-modal tasks but face significant safety challenges, which undermine their reliability in real-world applications. Efforts have been made to build LVLM safety evaluation benchmarks to uncover their vulnerability. However, existing benchmarks are hindered by their labor-intensive construction process, static complexity, and limited discriminative power. Thus, they may fail to keep pace with rapidly evolving models and emerging risks. To address these limitations, we propose VLSafetyBencher, the first automated system for LVLM safety benchmarking. VLSafetyBencher introduces four collaborative agents: Data Preprocessing, Generation, Augmentation, and Selection agents to construct and select high-quality samples. Experiments validates that VLSafetyBencher can construct high-quality safety benchmarks within one week at a minimal cost. The generated benchmark effectively distinguish safety, with a safety rate disparity of 70% between the most and least safe models.", "AI": {"tldr": "VLSafetyBencher是首个自动化LVLM安全基准测试系统，通过四个协作代理自动构建高质量安全评估样本，解决现有基准测试人工构建、静态复杂和判别力有限的问题。", "motivation": "大型视觉语言模型在跨模态任务中表现出色但面临严重安全挑战，现有安全评估基准存在人工构建成本高、静态复杂性、判别力有限等问题，无法跟上模型快速发展和新兴风险的步伐。", "method": "提出VLSafetyBencher系统，包含四个协作代理：数据预处理、生成、增强和选择代理，自动构建和选择高质量的安全评估样本。", "result": "实验验证VLSafetyBencher能在一周内以最小成本构建高质量安全基准，生成的安全基准能有效区分模型安全性，最安全和最不安全模型之间的安全率差异达70%。", "conclusion": "VLSafetyBencher为LVLM安全评估提供了高效、自动化的解决方案，能够快速构建高质量安全基准，有效识别模型安全漏洞，提升LVLM在实际应用中的可靠性。"}}
{"id": "2601.19578", "pdf": "https://arxiv.org/pdf/2601.19578", "abs": "https://arxiv.org/abs/2601.19578", "authors": ["Yuxuan Cai", "Xinyi Lai", "Peng Yuan", "Weiting Liu", "Huajian Li", "Mingda Li", "Xinghua Wang", "Shengxie Zheng", "Yanchao Hao", "Yuyang Yin", "Zheng Wei"], "title": "Yunque DeepResearch Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "Deep research has emerged as a transformative capability for autonomous agents, empowering Large Language Models to navigate complex, open-ended tasks. However, realizing its full potential is hindered by critical limitations, including escalating contextual noise in long-horizon tasks, fragility leading to cascading errors, and a lack of modular extensibility. To address these challenges, we introduce Yunque DeepResearch, a hierarchical, modular, and robust framework. The architecture is characterized by three key components: (1) a centralized Multi-Agent Orchestration System that routes subtasks to an Atomic Capability Pool of tools and specialized sub-agents; (2) a Dynamic Context Management mechanism that structures completed sub-goals into semantic summaries to mitigate information overload; and (3) a proactive Supervisor Module that ensures resilience through active anomaly detection and context pruning. Yunque DeepResearch achieves state-of-the-art performance across a range of agentic deep research benchmarks, including GAIA, BrowseComp, BrowseComp-ZH, and Humanity's Last Exam. We open-source the framework, reproducible implementations, and application cases to empower the community.", "AI": {"tldr": "Yunque DeepResearch是一个分层、模块化、鲁棒的深度研究框架，通过多智能体编排、动态上下文管理和主动监督模块解决现有深度研究中的上下文噪声、级联错误和扩展性问题，在多个基准测试中达到最先进性能。", "motivation": "解决自主智能体深度研究能力中的关键限制：长时任务中上下文噪声增加、脆弱性导致级联错误、缺乏模块化扩展性。", "method": "提出三层架构：1)集中式多智能体编排系统，将子任务路由到原子能力池；2)动态上下文管理机制，结构化已完成子目标为语义摘要；3)主动监督模块，通过异常检测和上下文修剪确保鲁棒性。", "result": "在GAIA、BrowseComp、BrowseComp-ZH和Humanity's Last Exam等多个智能体深度研究基准测试中实现了最先进的性能。", "conclusion": "Yunque DeepResearch框架有效解决了深度研究的核心挑战，提供了可扩展且鲁棒的解决方案，并通过开源促进社区发展。"}}
{"id": "2601.19605", "pdf": "https://arxiv.org/pdf/2601.19605", "abs": "https://arxiv.org/abs/2601.19605", "authors": ["Xin Quan", "Marco Valentino", "Louise A. Dennis", "André Freitas"], "title": "Decompose-and-Formalise: Recursively Verifiable Natural Language Inference", "categories": ["cs.CL"], "comment": null, "summary": "Recent work has shown that integrating large language models (LLMs) with theorem provers (TPs) in neuro-symbolic pipelines helps with entailment verification and proof-guided refinement of explanations for natural language inference (NLI). However, scaling such refinement to naturalistic NLI remains difficult: long, syntactically rich inputs and deep multi-step arguments amplify autoformalisation errors, where a single local mismatch can invalidate the proof. Moreover, current methods often handle failures via costly global regeneration due to the difficulty of localising the responsible span or step from prover diagnostics. Aiming to address these problems, we propose a decompose-and-formalise framework that (i) decomposes premise-hypothesis pairs into an entailment tree of atomic steps, (ii) verifies the tree bottom-up to isolate failures to specific nodes, and (iii) performs local diagnostic-guided refinement instead of regenerating the whole explanation. Moreover, to improve faithfulness of autoformalisation, we introduce $θ$-substitution in an event-based logical form to enforce consistent argument-role bindings. Across a range of reasoning tasks using five LLM backbones, our method achieves the highest explanation verification rates, improving over the state-of-the-art by 26.2%, 21.7%, 21.6% and 48.9%, while reducing refinement iterations and runtime and preserving strong NLI accuracy.", "AI": {"tldr": "提出分解形式化框架，通过将前提-假设对分解为原子步骤的蕴含树，自底向上验证以隔离失败节点，并进行局部诊断引导的细化，显著提高自然语言推理的解释验证率，减少迭代次数和运行时间。", "motivation": "现有神经符号管道在处理自然语言推理时面临长输入和深度多步论证导致的自动形式化错误问题，且当前方法难以定位错误位置，只能通过昂贵的全局重生成来处理失败。", "method": "采用分解形式化框架：(i)将前提-假设对分解为原子步骤的蕴含树；(ii)自底向上验证树以隔离失败到特定节点；(iii)执行局部诊断引导的细化而非整体重生成。引入θ-替换在基于事件的逻辑形式中确保一致的角色绑定。", "result": "在使用五个LLM骨干的各种推理任务中，该方法达到最高的解释验证率，比现有最优方法分别提高26.2%、21.7%、21.6%和48.9%，同时减少细化迭代次数和运行时间，保持强大的NLI准确性。", "conclusion": "该分解形式化框架有效解决了自然语言推理中的自动形式化错误定位和修复问题，通过局部细化和一致角色绑定机制显著提升了系统性能。"}}
{"id": "2601.19613", "pdf": "https://arxiv.org/pdf/2601.19613", "abs": "https://arxiv.org/abs/2601.19613", "authors": ["Xinzhong Wang", "Ya Guo", "Jing Li", "Huan Chen", "Yi Tu", "Yijie Hong", "Gongshen Liu", "Huijia Zhu"], "title": "Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using \"[mask]\" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.", "AI": {"tldr": "PIP：一种用于视觉丰富文档关键信息提取的并行推理范式，通过使用掩码令牌同时生成所有目标值，实现5-36倍推理加速且性能损失可忽略", "motivation": "传统自回归推理模型在提取多个语义独立字段时存在效率瓶颈，限制了KIE任务的实际应用", "method": "使用掩码令牌作为目标值的占位符，通过单次前向传播同时生成所有字段，开发专门的掩码预训练策略并构建大规模监督数据集", "result": "相比传统自回归基础模型，PIP模型实现5-36倍推理加速，性能下降可忽略不计", "conclusion": "PIP通过显著提升效率同时保持高精度，为可扩展和实用的现实世界KIE解决方案铺平了道路"}}
{"id": "2601.19637", "pdf": "https://arxiv.org/pdf/2601.19637", "abs": "https://arxiv.org/abs/2601.19637", "authors": ["Weicong Liu", "Zixuan Yang", "Yibo Zhao", "Xiang Li"], "title": "RATE: Reviewer Profiling and Annotation-free Training for Expertise Ranking in Peer Review Systems", "categories": ["cs.CL"], "comment": "18 pages", "summary": "Reviewer assignment is increasingly critical yet challenging in the LLM era, where rapid topic shifts render many pre-2023 benchmarks outdated and where proxy signals poorly reflect true reviewer familiarity. We address this evaluation bottleneck by introducing LR-bench, a high-fidelity, up-to-date benchmark curated from 2024-2025 AI/NLP manuscripts with five-level self-assessed familiarity ratings collected via a large-scale email survey, yielding 1055 expert-annotated paper-reviewer-score annotations. We further propose RATE, a reviewer-centric ranking framework that distills each reviewer's recent publications into compact keyword-based profiles and fine-tunes an embedding model with weak preference supervision constructed from heuristic retrieval signals, enabling matching each manuscript against a reviewer profile directly. Across LR-bench and the CMU gold-standard dataset, our approach consistently achieves state-of-the-art performance, outperforming strong embedding baselines by a clear margin. We release LR-bench at https://huggingface.co/datasets/Gnociew/LR-bench, and a GitHub repository at https://github.com/Gnociew/RATE-Reviewer-Assign.", "AI": {"tldr": "LR-bench：基于2024-2025年AI/NLP论文的新颖评审分配基准，结合RATE框架实现最先进的评审人匹配性能", "motivation": "LLM时代评审分配面临挑战，2023年前的基准已过时，代理信号无法准确反映评审人真实熟悉度", "method": "通过大规模邮件调查收集1055个专家标注的论文-评审人-评分数据，构建LR-bench基准；提出RATE框架，将评审人近期论文提炼为关键词配置文件，使用启发式检索信号构建弱偏好监督微调嵌入模型", "result": "在LR-bench和CMU黄金标准数据集上均取得最先进性能，明显优于强嵌入基线方法", "conclusion": "LR-bench提供了高保真度的最新基准，RATE框架通过评审人中心化方法有效解决了评审分配问题，相关资源已开源发布"}}
{"id": "2601.19657", "pdf": "https://arxiv.org/pdf/2601.19657", "abs": "https://arxiv.org/abs/2601.19657", "authors": ["Zihou Zhang", "Zheyong Xie", "Li Zhong", "Haifeng Liu", "Shaosheng Cao"], "title": "One Token Is Enough: Improving Diffusion Language Models with a Sink Token", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.", "AI": {"tldr": "该论文提出通过添加一个额外的sink token来解决扩散语言模型中的moving sink现象不稳定问题，该方法简单有效且能显著提升模型性能。", "motivation": "扩散语言模型虽然具有并行文本生成的竞争优势，但存在关键的moving sink不稳定性问题，这种保护机制的不确定性位置影响了推理的鲁棒性。", "method": "提出一个简单但有效的额外sink token，通过修改注意力掩码实现，该特殊token只能关注自身，但对所有其他token全局可见。", "result": "实验结果表明，引入单个额外token能够稳定注意力sink，大幅提升模型性能，且该token的有效性与其位置无关且语义内容可忽略。", "conclusion": "额外sink token作为一种稳健且专用的结构sink，有效解决了DLMs中的不稳定性问题，验证了其作为结构组件的有效性。"}}
{"id": "2601.19667", "pdf": "https://arxiv.org/pdf/2601.19667", "abs": "https://arxiv.org/abs/2601.19667", "authors": ["Adam Remaki", "Christel Gérardin", "Eulàlia Farré-Maduell", "Martin Krallinger", "Xavier Tannier"], "title": "SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.", "AI": {"tldr": "SynCABEL是一个利用大语言模型生成生物医学实体链接合成训练数据的框架，解决了标注数据稀缺问题，在多个多语言基准测试中达到SOTA性能，并减少60%的人工标注需求。", "motivation": "解决监督式生物医学实体链接中专家标注训练数据稀缺的核心瓶颈问题", "method": "利用大语言模型为目标知识库中的所有候选概念生成上下文丰富的合成训练示例，结合仅解码器模型和引导推理", "result": "在MedMentions（英语）、QUAERO（法语）和SPACCC（西班牙语）三个多语言基准测试中达到新的最先进结果；使用比全人工监督少60%的标注数据即可达到相同性能；显著提高临床有效预测率", "conclusion": "SynCABEL通过合成数据生成有效缓解了生物医学实体链接的数据稀缺问题，提供了可复现的解决方案，并引入了LLM作为评估者的新协议来更准确地评估临床有效性"}}
{"id": "2601.19723", "pdf": "https://arxiv.org/pdf/2601.19723", "abs": "https://arxiv.org/abs/2601.19723", "authors": ["Yifan Wang", "Jichen Zheng", "Jingyuan Sun", "Yunhao Zhang", "Chunyu Ye", "Jixing Li", "Chengqing Zong", "Shaonan Wang"], "title": "Component-Level Lesioning of Language Models Reveals Clinically Aligned Aphasia Phenotypes", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) increasingly exhibit human-like linguistic behaviors and internal representations that they could serve as computational simulators of language cognition. We ask whether LLMs can be systematically manipulated to reproduce language-production impairments characteristic of aphasia following focal brain lesions. Such models could provide scalable proxies for testing rehabilitation hypotheses, and offer a controlled framework for probing the functional organization of language. We introduce a clinically grounded, component-level framework that simulates aphasia by selectively perturbing functional components in LLMs, and apply it to both modular Mixture-of-Experts models and dense Transformers using a unified intervention interface. Our pipeline (i) identifies subtype-linked components for Broca's and Wernicke's aphasia, (ii) interprets these components with linguistic probing tasks, and (iii) induces graded impairments by progressively perturbing the top-k subtype-linked components, evaluating outcomes with Western Aphasia Battery (WAB) subtests summarized by Aphasia Quotient (AQ). Across architectures and lesioning strategies, subtype-targeted perturbations yield more systematic, aphasia-like regressions than size-matched random perturbations, and MoE modularity supports more localized and interpretable phenotype-to-component mappings. These findings suggest that modular LLMs, combined with clinically informed component perturbations, provide a promising platform for simulating aphasic language production and studying how distinct language functions degrade under targeted disruptions.", "AI": {"tldr": "本研究开发了一个临床基础的组件级框架，通过选择性扰动大语言模型的功能组件来模拟失语症，发现模块化模型能更准确地再现特定失语亚型的语言障碍模式。", "motivation": "探索大语言模型是否能系统性地再现脑部病变导致的失语症语言障碍，为康复假说测试和语言功能组织研究提供可扩展的计算模拟平台。", "method": "引入临床基础的组件级扰动框架，在混合专家模型和密集Transformer模型中识别与布洛卡失语和韦尼克失语相关的组件，通过渐进式扰动这些组件并使用西方失语症量表进行评估。", "result": "亚型定向扰动比随机扰动产生更系统的失语症样回归，模块化模型支持更局部化和可解释的表型-组件映射。", "conclusion": "模块化大语言模型结合临床信息化的组件扰动，为模拟失语症语言产生和研究特定语言功能在定向破坏下的退化提供了有前景的平台。"}}
{"id": "2601.19739", "pdf": "https://arxiv.org/pdf/2601.19739", "abs": "https://arxiv.org/abs/2601.19739", "authors": ["Runjia Zeng", "Qifan Wang", "Qiang Guan", "Ruixiang Tang", "Lifu Huang", "Zhenting Wang", "Xueling Zhang", "Cheng Han", "Dongfang Liu"], "title": "TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2026", "summary": "Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/", "AI": {"tldr": "TokenSeek是一个针对Transformer模型的通用插件，通过实例感知的token选择与丢弃策略，大幅减少大语言模型微调时的内存消耗（如Llama3.2 1B仅需14.8%内存），同时保持或提升性能表现。", "motivation": "现有的大语言模型微调方法内存消耗高，而现有的激活优化方法由于数据无关性导致微调效果不佳且不稳定。", "method": "提出TokenSeek方法，通过实例感知的token寻求和丢弃策略，选择性地处理输入token，减少激活内存占用。", "result": "在Llama3.2 1B等模型上实现了显著的内存节省（仅需14.8%内存），同时性能相当或更好。", "conclusion": "TokenSeek是一种有效的内存优化解决方案，其可解释的token选择过程为未来的token效率研究提供了有价值的见解。"}}
{"id": "2601.19773", "pdf": "https://arxiv.org/pdf/2601.19773", "abs": "https://arxiv.org/abs/2601.19773", "authors": ["Zhuohan Long", "Zhijie Bao", "Zhongyu Wei"], "title": "Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis", "categories": ["cs.CL"], "comment": null, "summary": "Interactive medical consultation requires an agent to proactively elicit missing clinical evidence under uncertainty. Yet existing evaluations largely remain static or outcome-centric, neglecting the evidence-gathering process. In this work, we propose an interactive evaluation framework that explicitly models the consultation process using a simulated patient and a \\rev{simulated reporter} grounded in atomic evidences. Based on this representation, we introduce Information Coverage Rate (ICR) to quantify how completely an agent uncovers necessary evidence during interaction. To support systematic study, we build EviMed, an evidence-based benchmark spanning diverse conditions from common complaints to rare diseases, and evaluate 10 models with varying reasoning abilities. We find that strong diagnostic reasoning does not guarantee effective information collection, and this insufficiency acts as a primary bottleneck limiting performance in interactive settings. To address this, we propose REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving uncertainties. Extensive experiments demonstrate that REFINE consistently outperforms baselines across diverse datasets and facilitates effective model collaboration, enabling smaller agents to achieve superior performance under strong reasoning supervision. Our code can be found at https://github.com/NanshineLoong/EID-Benchmark .", "AI": {"tldr": "该论文提出了一个交互式医疗咨询评估框架EviMed，通过模拟患者和报告器来量化信息收集完整性，发现诊断推理能力强的模型不一定能有效收集信息，并提出了REFINE策略来主动解决不确定性。", "motivation": "现有的医疗咨询评估大多是静态或结果导向的，忽视了证据收集过程，需要一种能主动在不确定性下收集临床证据的交互式评估方法。", "method": "构建基于原子证据的模拟患者和报告器系统，提出信息覆盖率(ICR)量化证据收集完整性，建立EviMed基准测试集，评估10个不同推理能力的模型，并提出REFINE策略利用诊断验证指导主动解决不确定性。", "result": "发现强大的诊断推理能力不能保证有效的信息收集，这是限制交互式性能的主要瓶颈。REFINE策略在多个数据集上持续优于基线方法，并能促进模型协作，使小型代理在强推理监督下获得更好性能。", "conclusion": "交互式医疗咨询需要专门的证据收集策略，REFINE方法通过诊断验证有效解决了信息收集的瓶颈问题，为医疗AI的交互能力评估提供了新框架。"}}
{"id": "2601.19792", "pdf": "https://arxiv.org/pdf/2601.19792", "abs": "https://arxiv.org/abs/2601.19792", "authors": ["Peter Zeng", "Weiling Li", "Amie Paige", "Zhengxiang Wang", "Panagiotis Kaliosis", "Dimitris Samaras", "Gregory Zelinsky", "Susan Brennan", "Owen Rambow"], "title": "LVLMs and Humans Ground Differently in Referential Communication", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "24 pages, 16 figures, preprint", "summary": "For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.", "AI": {"tldr": "本研究通过参照沟通实验揭示了大型视觉语言模型在理解人类意图和建立共同基础方面的局限性，特别是在需要多轮交互解决指代表达的任务中。", "motivation": "生成式AI代理需要准确预测人类意图才能与人类有效协作，但目前受限于无法有效建模共同基础（common ground）的能力。", "method": "采用因子设计实验，包含人类-人类、人类-AI、AI-人类和AI-AI四种配对组合，通过多轮重复的图片匹配任务收集数据，图片对象没有明显的词汇标签。", "result": "收集了356个对话语料（89对组合各进行4轮），开发了在线数据收集管道和分析工具，揭示了LVLMs在交互式解决指代表达方面的限制。", "conclusion": "大型视觉语言模型在人类语言使用的基础技能——交互式指代表达解析方面存在显著局限，这阻碍了AI与人类的有效协作。"}}
{"id": "2601.19802", "pdf": "https://arxiv.org/pdf/2601.19802", "abs": "https://arxiv.org/abs/2601.19802", "authors": ["Aohua Li", "Yuanshuo Zhang", "Ge Gao", "Bo Chen", "Xiaobing Zhao"], "title": "Zero-Shot Stance Detection in the Wild: Dynamic Target Generation and Multi-Target Adaptation", "categories": ["cs.CL"], "comment": null, "summary": "Current stance detection research typically relies on predicting stance based on given targets and text. However, in real-world social media scenarios, targets are neither predefined nor static but rather complex and dynamic. To address this challenge, we propose a novel task: zero-shot stance detection in the wild with Dynamic Target Generation and Multi-Target Adaptation (DGTA), which aims to automatically identify multiple target-stance pairs from text without prior target knowledge. We construct a Chinese social media stance detection dataset and design multi-dimensional evaluation metrics. We explore both integrated and two-stage fine-tuning strategies for large language models (LLMs) and evaluate various baseline models. Experimental results demonstrate that fine-tuned LLMs achieve superior performance on this task: the two-stage fine-tuned Qwen2.5-7B attains the highest comprehensive target recognition score of 66.99%, while the integrated fine-tuned DeepSeek-R1-Distill-Qwen-7B achieves a stance detection F1 score of 79.26%.", "AI": {"tldr": "提出零样本立场检测新任务DGTA，通过动态目标生成和多目标适配，无需预设目标即可从文本中自动识别多目标-立场对。构建中文社交媒体数据集，采用大语言模型微调策略，最佳模型在目标识别和立场检测上分别达到66.99%和79.26%的F1分数。", "motivation": "现实社交媒体中目标既非预设也非静态，而是复杂动态的，现有立场检测方法依赖给定目标的问题需要解决", "method": "提出DGTA框架，包含动态目标生成和多目标适配；构建中文社交媒体立场检测数据集；探索集成式和两阶段的大语言模型微调策略", "result": "微调后的大语言模型表现优异：两阶段微调的Qwen2.5-7B获得66.99%的综合目标识别分数；集成微调的DeepSeek-R1-Distill-Qwen-7B达到79.26%的立场检测F1分数", "conclusion": "该方法有效解决了现实场景中目标动态变化的问题，大语言模型微调策略在零样本立场检测任务中展现出强大潜力，为社交媒体分析提供了新思路"}}
{"id": "2601.19827", "pdf": "https://arxiv.org/pdf/2601.19827", "abs": "https://arxiv.org/abs/2601.19827", "authors": ["Mahdi Astaraki", "Mohammad Arshi Saloot", "Ali Shiraee Kasmaee", "Hamidreza Mahyar", "Soheila Samiee"], "title": "When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "27 pages, 15 figures", "summary": "Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.", "AI": {"tldr": "该论文通过控制实验证明，在科学领域的多跳推理任务中，迭代式检索增强生成(RAG)系统比静态黄金上下文RAG表现更好，即使后者提供了所有正确的证据。迭代RAG通过交替进行检索、假设精炼和证据感知停止，能减少后期推理失败并动态纠正早期假设偏差。", "motivation": "研究迭代检索-推理循环在何时以及如何超越静态RAG系统，特别是在需要多跳推理、领域知识稀疏且证据异质的科学领域中。这是首个机制层面的诊断研究，探讨同步迭代检索和推理是否能超越理想化的静态上限（黄金上下文）RAG。", "method": "使用ChemKGMultiHopQA化学数据集，在三种模式下对11个最先进的LLM进行基准测试：无上下文模式、黄金上下文模式（一次性提供所有正确证据）、迭代RAG模式（训练无关的控制器，交替进行检索、假设精炼和证据感知停止）。通过检索覆盖差距、锚点携带丢失、查询质量、组合保真度和控制校准等诊断指标分析行为。", "result": "迭代RAG在所有模型中始终优于黄金上下文RAG，增益高达25.6个百分点，特别是对于非推理微调模型。分阶段检索减少了后期跳失败，缓解了上下文过载，并能动态纠正早期假设偏差。", "conclusion": "分阶段检索通常比仅仅提供理想证据更重要；研究为在专业科学环境中部署和诊断RAG系统提供了实用指导，并为更可靠、可控的迭代检索-推理框架奠定了基础。"}}
{"id": "2601.19847", "pdf": "https://arxiv.org/pdf/2601.19847", "abs": "https://arxiv.org/abs/2601.19847", "authors": ["Fangan Dong", "Zuming Yan", "Xuri Ge", "Zhiwei Xu", "Mengqi Zhang", "Xuanang Chen", "Ben He", "Xin Xin", "Zhumin Chen", "Ying Zhou"], "title": "Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering", "categories": ["cs.CL"], "comment": null, "summary": "Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.", "AI": {"tldr": "AdaRAS是一种轻量级推理时框架，通过选择性干预LLM中的关键神经元激活来提高推理可靠性，无需额外训练或采样成本。", "motivation": "现有大型语言模型在复杂推理任务中需要后训练或计算昂贵的采样策略才能获得可靠性能，限制了实际效率。研究发现LLM中一小部分神经元与推理正确性有强预测相关性。", "method": "提出AdaRAS框架：1）通过极性感知均值差准则识别推理关键神经元(RCNs)；2）在推理过程中自适应地引导这些神经元的激活，增强错误推理轨迹同时避免对已正确案例的负面影响。", "result": "在10个数学和编程基准测试中表现一致提升，包括在AIME-24和AIME-25上获得超过13%的增益。方法具有良好的跨数据集迁移性和对更强模型的可扩展性。", "conclusion": "AdaRAS通过选择性神经元干预有效提升了LLM的推理可靠性，优于后训练方法且无需额外计算成本，为提升模型推理性能提供了高效实用的解决方案。"}}
{"id": "2601.19871", "pdf": "https://arxiv.org/pdf/2601.19871", "abs": "https://arxiv.org/abs/2601.19871", "authors": ["Nicholas Cheng"], "title": "Reflective Translation: Improving Low-Resource Machine Translation via Structured Self-Reflection", "categories": ["cs.CL"], "comment": "12 pages, 3 figures, 6 tables. Accepted to the NeurIPS 2025 Workshop on Multilingual Representation Learning (Mexico City) and the AAAI 2025 Workshop on Language Models for Under-Resourced Communities (LM4UC). Code and data available at: https://github.com/Nickcheng123/reflective-translation-mt", "summary": "Low-resource languages such as isiZulu and isiXhosa face persistent challenges in machine translation due to limited parallel data and linguistic resources. Recent advances in large language models suggest that self-reflection, prompting a model to critique and revise its own outputs, can improve reasoning quality and factual consistency. Building on this idea, this paper introduces Reflective Translation, a prompt-based framework in which a model generates an initial translation, produces a structured self-critique, and then uses this reflection to generate a refined translation. The approach is evaluated on English-isiZulu and English-isiXhosa translation using OPUS-100 and NTREX-African, across multiple prompting strategies and confidence thresholds. Results show consistent improvements in both BLEU and COMET scores between first- and second-pass translations, with average gains of up to +0.22 BLEU and +0.18 COMET. Statistical significance testing using paired nonparametric tests confirms that these improvements are robust. The proposed method is model-agnostic, requires no fine-tuning, and introduces a reflection-augmented dataset that can support future supervised or analysis-driven work. These findings demonstrate that structured self-reflection is a practical and effective mechanism for improving translation quality in low-resource settings.", "AI": {"tldr": "论文提出Reflective Translation框架，通过模型自评和修订来提升低资源语言（如isiZulu和isiXhosa）的机器翻译质量，无需微调即可实现BLEU和COMET分数的显著提升。", "motivation": "isiZulu和isiXhosa等低资源语言因平行数据有限而面临机器翻译挑战，大语言模型的自反思能力可能改善翻译质量。", "method": "基于提示的框架：模型首先生成初始翻译，然后进行结构化自评，最后利用反思生成优化翻译。在OPUS-100和NTREX-African数据集上评估多种提示策略和置信度阈值。", "result": "一译和二译间BLEU和COMET分数持续提升，平均增益分别达+0.22和+0.18。非参数配对检验证实改进具有统计显著性。", "conclusion": "结构化自反思是提升低资源场景翻译质量的有效实用机制，该方法模型无关、无需微调，并提供了可用于后续研究的反思增强数据集。"}}
{"id": "2601.19899", "pdf": "https://arxiv.org/pdf/2601.19899", "abs": "https://arxiv.org/abs/2601.19899", "authors": ["Luis Lorenzo", "Marcos Montana-Mendez", "Sergio Figueiras", "Miguel Boubeta", "Cristobal Bernardo-Castineira"], "title": "Evaluation of Oncotimia: An LLM based system for supporting tumour boards", "categories": ["cs.CL"], "comment": "9 pages, 2 figures", "summary": "Multidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require manual processes and structuring large volumes of heterogeneous clinical information, resulting in a substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure clinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows and evaluate its application to the automatic completion of lung cancer tumour board forms using large language models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector storage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform unstructured clinical documentation into structured and standardised tumour board records. We assess the performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring both completion form accuracy and end-to-end latency. The results demonstrate high performance across models, with the best performing configuration achieving an 80% of correct field completion and clinically acceptable response time for most LLMs. Larger and more recent models exhibit best accuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM- assisted autocompletion form is technically feasible and operationally viable in multidisciplinary lung cancer workflows and support its potential to significantly reduce documentation burden while preserving data quality.", "AI": {"tldr": "ONCOTIMIA是一个基于生成式AI的临床工具，使用大型语言模型自动完成肺癌多学科肿瘤委员会表格，显著减轻文档负担并保持数据质量。", "motivation": "多学科肿瘤委员会需要手动处理大量异构临床信息，存在巨大的文档负担，需要自动化解决方案来提高效率。", "method": "开发模块化安全临床工具ONCOTIMIA，结合多层数据湖、混合关系/向量存储、检索增强生成(RAG)和规则驱动的自适应表单模型，将非结构化临床文档转换为结构化肿瘤委员会记录。", "result": "在10个肺癌病例上评估6个LLM，最佳配置达到80%的正确字段完成率，大多数LLM具有临床可接受的响应时间，较大较新的模型表现最佳。", "conclusion": "LLM辅助的自动填表在多学科肺癌工作流程中技术上可行且操作上可行，有潜力显著减少文档负担同时保持数据质量。"}}
