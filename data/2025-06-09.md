<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 128]
- [cs.AI](#cs.AI) [总数: 22]
- [stat.ML](#stat.ML) [总数: 3]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Zeroth-Order Optimization Finds Flat Minima](https://arxiv.org/abs/2506.05454)
*Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil, Sewoong Oh, Michael Muehlebach, Niao He*

**主要类别:** cs.LG

**AI概要:** 该论文探讨了零阶优化方法的隐式正则化效应，发现其偏向于找到平坦极小值，并在理论上和实验上验证了这一现象。


<details>
  <summary>更多</summary>
  
**动机:** 现有的优化理论主要关注收敛到任意平稳点，但对隐式正则化的研究较少，即哪些特定解会被选中。论文旨在填补这一空白，更细致地描述零阶优化方法如何选择某些特定解。

**方法:** 论文通过理论分析结合实验验证的方法，提供了凸函数和充分平滑函数的零阶优化逼近平坦极小值的收敛率，并在二分类任务和语言模型微调中进行了实验验证。

**结果:** 研究表明零阶优化偏好选择具有最小Hessian迹的解（平坦极小值），并给出了相应的收敛速率；实验结果支持了理论分析的结果。

**结论:** 论文得出结论，使用标准两点估计器的零阶优化倾向于选择具有较小Hessian迹的小值解，这种特性可用于区分锐利和平坦极小值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zeroth-Order+Optimization+Finds+Flat+Minima，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05454，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05454&send_immediately=true&force_search=false)

**原文摘要:** Zeroth-order methods are extensively used in machine learning applications
where gradients are infeasible or expensive to compute, such as black-box
attacks, reinforcement learning, and language model fine-tuning. Existing
optimization theory focuses on convergence to an arbitrary stationary point,
but less is known on the implicit regularization that provides a fine-grained
characterization on which particular solutions are finally reached. We show
that zeroth-order optimization with the standard two-point estimator favors
solutions with small trace of Hessian, which is widely used in previous work to
distinguish between sharp and flat minima. We further provide convergence rates
of zeroth-order optimization to approximate flat minima for convex and
sufficiently smooth functions, where flat minima are defined as the minimizers
that achieve the smallest trace of Hessian among all optimal solutions.
Experiments on binary classification tasks with convex losses and language
model fine-tuning support our theoretical findings.

</details>


### [2] [Mixture-of-Experts Meets In-Context Reinforcement Learning](https://arxiv.org/abs/2506.05426)
*Wenhao Wu, Fuhong Liu, Haoru Li, Zican Hu, Daoyi Dong, Chunlin Chen, Zhi Wang*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种名为T2MIR的新框架，利用混合专家（MoE）架构提升上下文强化学习（ICRL）的适应性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服ICRL中状态-动作-奖励数据的内在多模态特性以及多样化、异构决策任务带来的挑战，研究提出了T2MIR框架。

**方法:** T2MIR使用了token-wise MoE和task-wise MoE两种组件，并结合对比学习方法增强任务路由，从而优化状态-动作-奖励数据的多模态特性和多样化决策任务处理。

**结果:** 实验结果显示，T2MIR显著提升了ICRL的学习能力，并且在多种基准测试中表现优于现有方法。

**结论:** T2MIR通过引入MoE架构显著提升了ICRL的学习能力和性能，为ICRL的发展提供了新的方向和改进方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mixture-of-Experts+Meets+In-Context+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05426，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05426&send_immediately=true&force_search=false)

**原文摘要:** In-context reinforcement learning (ICRL) has emerged as a promising paradigm
for adapting RL agents to downstream tasks through prompt conditioning.
However, two notable challenges remain in fully harnessing in-context learning
within RL domains: the intrinsic multi-modality of the state-action-reward data
and the diverse, heterogeneous nature of decision tasks. To tackle these
challenges, we propose \textbf{T2MIR} (\textbf{T}oken- and \textbf{T}ask-wise
\textbf{M}oE for \textbf{I}n-context \textbf{R}L), an innovative framework that
introduces architectural advances of mixture-of-experts (MoE) into
transformer-based decision models. T2MIR substitutes the feedforward layer with
two parallel layers: a token-wise MoE that captures distinct semantics of input
tokens across multiple modalities, and a task-wise MoE that routes diverse
tasks to specialized experts for managing a broad task distribution with
alleviated gradient conflicts. To enhance task-wise routing, we introduce a
contrastive learning method that maximizes the mutual information between the
task and its router representation, enabling more precise capture of
task-relevant information. The outputs of two MoE components are concatenated
and fed into the next layer. Comprehensive experiments show that T2MIR
significantly facilitates in-context learning capacity and outperforms various
types of baselines. We bring the potential and promise of MoE to ICRL, offering
a simple and scalable architectural enhancement to advance ICRL one step closer
toward achievements in language and vision communities. Our code is available
at https://github.com/NJU-RL/T2MIR.

</details>


### [3] [The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models](https://arxiv.org/abs/2506.05500)
*Alex Damian, Jason D. Lee, Joan Bruna*

**主要类别:** cs.LG

**AI概要:** 本文研究了高斯多指标模型中隐藏子空间的有效估计方法，提出了“生成跳跃指数”，并展示了样本复杂度的必要性和充分性。


<details>
  <summary>更多</summary>
  
**动机:** 在多指标模型中，如何有效估计隐藏子空间是关键问题，特别是在无需先验知识的情况下。

**方法:** 引入生成跳跃指数k⋆，结合低次多项式框架和谱U统计量进行顺序估计。

**结果:** 证明了n=Θ(d^(1∨k/2))的样本复杂度既必要又充分，并计算了多个实例的生成跳跃指数。

**结论:** 提出的生成跳跃指数和估计程序为多指标模型提供了有效的解决方案，适用于如深度ReLU网络等实际应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Generative+Leap%3A+Sharp+Sample+Complexity+for+Efficiently+Learning+Gaussian+Multi-Index+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05500，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05500&send_immediately=true&force_search=false)

**原文摘要:** In this work we consider generic Gaussian Multi-index models, in which the
labels only depend on the (Gaussian) $d$-dimensional inputs through their
projection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient
agnostic estimation procedures for this hidden subspace. We introduce the
\emph{generative leap} exponent $k^\star$, a natural extension of the
generative exponent from [Damian et al.'24] to the multi-index setting. We
first show that a sample complexity of $n=\Theta(d^{1 \vee \k/2})$ is necessary
in the class of algorithms captured by the Low-Degree-Polynomial framework. We
then establish that this sample complexity is also sufficient, by giving an
agnostic sequential estimation procedure (that is, requiring no prior knowledge
of the multi-index model) based on a spectral U-statistic over appropriate
Hermite tensors. We further compute the generative leap exponent for several
examples including piecewise linear functions (deep ReLU networks with bias),
and general deep neural networks (with $r$-dimensional first hidden layer).

</details>


### [4] [MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction](https://arxiv.org/abs/2506.05427)
*Zishan Shu, Yufan Deng, Hongyu Zhang, Zhiwei Nie, Jie Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种用于活性悬崖预测的新框架MTPNet，它利用靶蛋白信息提升预测精度并加速药物发现过程。


<details>
  <summary>更多</summary>
  
**动机:** 现有计算方法只能处理单一结合目标，限制了模型的应用范围。

**方法:** 提出了多粒度目标感知网络（MTPNet），包括宏观目标语义（MTS）引导和微观口袋语义（MPS）引导两个部分，动态优化分子表示。

**结果:** 在30个代表性活性悬崖数据集中进行的广泛实验表明，MTPNet明显优于以前的方法，在多个主流GNN架构上平均RMSE提升了18.95%。

**结论:** MTPNet通过整合分子与靶蛋白的相互作用知识，显著提高了活性悬崖预测的准确性，并加速了化合物优化和设计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MTPNet%3A+Multi-Grained+Target+Perception+for+Unified+Activity+Cliff+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05427，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05427&send_immediately=true&force_search=false)

**原文摘要:** Activity cliff prediction is a critical task in drug discovery and material
design. Existing computational methods are limited to handling single binding
targets, which restricts the applicability of these prediction models. In this
paper, we present the Multi-Grained Target Perception network (MTPNet) to
incorporate the prior knowledge of interactions between the molecules and their
target proteins. Specifically, MTPNet is a unified framework for activity cliff
prediction, which consists of two components: Macro-level Target Semantic (MTS)
guidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet
dynamically optimizes molecular representations through multi-grained protein
semantic conditions. To our knowledge, it is the first time to employ the
receptor proteins as guiding information to effectively capture critical
interaction details. Extensive experiments on 30 representative activity cliff
datasets demonstrate that MTPNet significantly outperforms previous approaches,
achieving an average RMSE improvement of 18.95% on top of several mainstream
GNN architectures. Overall, MTPNet internalizes interaction patterns through
conditional deep learning to achieve unified predictions of activity cliffs,
helping to accelerate compound optimization and design. Codes are available at:
https://github.com/ZishanShu/MTPNet.

</details>


### [5] [Winner-takes-all for Multivariate Probabilistic Time Series Forecasting](https://arxiv.org/abs/2506.05515)
*Adrien Cortés, Rémi Rehm, Victor Letzelter*

**主要类别:** cs.LG

**AI概要:** TimeMCL是一种基于MCL框架和WTA损失函数的轻量级时间序列预测方法，可以有效预测多种可能的未来趋势。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决模糊和不适定任务的时间序列预测问题，引入一种简单且高效的预测多样化未来的方法。

**方法:** 采用多头神经网络和Winner-Takes-All (WTA) 损失函数，基于Multiple Choice Learning (MCL) 框架进行时间序列预测。

**结果:** 通过合成数据和真实世界时间序列的实验，表明TimeMCL在预测多样化未来方面表现良好。

**结论:** TimeMCL 是一种用于时间序列预测的高效方法，能够预测多样化未来，并具有较低的计算成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Winner-takes-all+for+Multivariate+Probabilistic+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05515，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05515&send_immediately=true&force_search=false)

**原文摘要:** We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)
paradigm to forecast multiple plausible time series futures. Our approach
employs a neural network with multiple heads and utilizes the Winner-Takes-All
(WTA) loss to promote diversity among predictions. MCL has recently gained
attention due to its simplicity and ability to address ill-posed and ambiguous
tasks. We propose an adaptation of this framework for time-series forecasting,
presenting it as an efficient method to predict diverse futures, which we
relate to its implicit quantization objective. We provide insights into our
approach using synthetic data and evaluate it on real-world time series,
demonstrating its promising performance at a light computational cost.

</details>


### [6] [Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction](https://arxiv.org/abs/2506.05428)
*Zhihao Tang, Chaozhuo Li, Litian Zhang, Xi Zhang*

**主要类别:** cs.LG

**AI概要:** 本研究开发了MCI-Diff模型，能够在早期使用单次基线sMRI数据高效且准确地预测MCI转化。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服单次基线sMRI快速预测与纵向扫描准确预测之间的权衡，本文旨在提高早期预测MCI转化的准确性与时效性。

**方法:** 提出了一种基于扩散的框架MCI-Diff，通过多任务序列重建策略训练共享去噪网络，并引入LLM驱动的“语言指南针”确保生成数据的临床合理性。

**结果:** 实验结果显示，MCI-Diff在ADNI和AIBL队列上比现有最先进方法提高了5-12%的早期转化准确性。

**结论:** MCI-Diff在早期预测轻度认知障碍转化方面优于现有方法，实现了实时风险评估和高预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion+with+a+Linguistic+Compass%3A+Steering+the+Generation+of+Clinically+Plausible+Future+sMRI+Representations+for+Early+MCI+Conversion+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05428，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05428&send_immediately=true&force_search=false)

**原文摘要:** Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by
a trade-off between immediacy--making fast predictions from a single baseline
sMRI--and accuracy--leveraging longitudinal scans to capture disease
progression. We propose MCI-Diff, a diffusion-based framework that synthesizes
clinically plausible future sMRI representations directly from baseline data,
achieving both real-time risk assessment and high predictive performance.
First, a multi-task sequence reconstruction strategy trains a shared denoising
network on interpolation and extrapolation tasks to handle irregular follow-up
sampling and learn robust latent trajectories. Second, an LLM-driven
"linguistic compass" is introduced for clinical plausibility sampling:
generated feature candidates are quantized, tokenized, and scored by a
fine-tuned language model conditioned on expected structural biomarkers,
guiding autoregressive generation toward realistic disease patterns.
Experiments on ADNI and AIBL cohorts show that MCI-Diff outperforms
state-of-the-art baselines, improving early conversion accuracy by 5-12%.

</details>


### [7] [On Fitting Flow Models with Large Sinkhorn Couplings](https://arxiv.org/abs/2506.05526)
*Michal Klein, Alireza Mousavi-Hosseini, Stephen Zhang, Marco Cuturi*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种改进的流模型训练方法，通过使用大规模Sinkhorn耦合并降低熵正则化参数ε，从而显著提升模型在图像生成等任务中的表现。


<details>
  <summary>更多</summary>
  
**动机:** 当没有源点和目标点之间的配对时，训练流模型会变得更加困难，因此需要寻找更高效的配对方法以提高训练效果。

**方法:** 通过探索增加批处理大小n的方法，并仔细分析Sinkhorn算法中熵正则化ε的影响，利用新的尺度不变量来报告耦合的锐度，并通过多GPU或GPU节点分片计算实现n的扩展。

**结果:** 研究显示，在合成数据和图像生成任务中，通过大规模Sinkhorn耦合和较低的熵正则化ε进行拟合，流模型能够获得显著的性能提升。

**结论:** 论文得出结论，使用大规模Sinkhorn耦合和较低的熵正则化ε可以显著提升流模型在合成数据和图像生成任务中的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Fitting+Flow+Models+with+Large+Sinkhorn+Couplings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05526，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05526&send_immediately=true&force_search=false)

**原文摘要:** Flow models transform data gradually from one modality (e.g. noise) onto
another (e.g. images). Such models are parameterized by a time-dependent
velocity field, trained to fit segments connecting pairs of source and target
points. When the pairing between source and target points is given, training
flow models boils down to a supervised regression problem. When no such pairing
exists, as is the case when generating data from noise, training flows is much
harder. A popular approach lies in picking source and target points
independently. This can, however, lead to velocity fields that are slow to
train, but also costly to integrate at inference time. In theory, one would
greatly benefit from training flow models by sampling pairs from an optimal
transport (OT) measure coupling source and target, since this would lead to a
highly efficient flow solving the Benamou and Brenier dynamical OT problem. In
practice, recent works have proposed to sample mini-batches of $n$ source and
$n$ target points and reorder them using an OT solver to form better pairs.
These works have advocated using batches of size $n\approx 256$, and considered
OT solvers that return couplings that are either sharp (using e.g. the
Hungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.
Sinkhorn). We follow in the footsteps of these works by exploring the benefits
of increasing $n$ by three to four orders of magnitude, and look more carefully
on the effect of the entropic regularization $\varepsilon$ used in the Sinkhorn
algorithm. Our analysis is facilitated by new scale invariant quantities to
report the sharpness of a coupling, while our sharded computations across
multiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic
and image generation tasks, flow models greatly benefit when fitted with large
Sinkhorn couplings, with a low entropic regularization $\varepsilon$.

</details>


### [8] [PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling](https://arxiv.org/abs/2506.05432)
*Yuxuan Yue, Zukang Xu, Zhihang Yuan, Dawei Yang, Jianglong Wu, Liqiang Nie*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Polar Coordinate Decoupled Vector Quantization（PCDVQ）的新框架，旨在解决大型语言模型在边缘部署中的挑战。


<details>
  <summary>更多</summary>
  
**动机:** 由于大型语言模型（LLMs）的大量参数规模，在边缘部署方面面临重大挑战。向量量化（VQ）作为一种基于聚类的量化方法，因其极低的比特（甚至在2位）和相当的准确性而成为解决此问题的普遍方案。然而，现有的VQ工作通常以耦合的方式量化向量的方向和幅度，但研究发现方向对于量化更为敏感。此外，常用的欧氏距离度量更强调减少幅度误差，这与上述发现相悖，不可避免地导致更大的量化误差。

**方法:** 本文提出了极坐标解耦向量量化（PCDVQ），包括两个关键模块：1）极坐标解耦（PCD），将向量转换为其极坐标表示，并对方向和幅度参数进行独立量化；2）分布对齐码本构建（DACC），根据源分布优化方向和幅度码本。

**结果:** 当分别聚类LLaMA-2-7B权重向量的方向和幅度时，零样本任务的准确率下降分别为46.5%和2.3%。这一差距随着聚类中心的减少而增加。

**结论:** PCDVQ在2位级别上优于基线方法，至少提高了1.5%的零样本准确率，为精确且高度压缩的LLMs建立了一种新范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PCDVQ%3A+Enhancing+Vector+Quantization+for+Large+Language+Models+via+Polar+Coordinate+Decoupling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05432，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05432&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) face significant challenges in edge deployment
due to their massive parameter scale. Vector Quantization (VQ), a
clustering-based quantization method, serves as a prevalent solution to this
issue for its extremely low-bit (even at 2-bit) and considerable accuracy.
Since a vector is a quantity in mathematics and physics that has both direction
and magnitude, existing VQ works typically quantize them in a coupled manner.
However, we find that direction exhibits significantly greater sensitivity to
quantization compared to the magnitude. For instance, when separately
clustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the
accuracy drop of zero-shot tasks are 46.5\% and 2.3\%, respectively. This gap
even increases with the reduction of clustering centers. Further, Euclidean
distance, a common metric to access vector similarities in current VQ works,
places greater emphasis on reducing the magnitude error. This property is
contrary to the above finding, unavoidably leading to larger quantization
errors. To these ends, this paper proposes Polar Coordinate Decoupled Vector
Quantization (PCDVQ), an effective and efficient VQ framework consisting of two
key modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors
into their polar coordinate representations and perform independent
quantization of the direction and magnitude parameters.2) Distribution Aligned
Codebook Construction (DACC), which optimizes the direction and magnitude
codebooks in accordance with the source distribution. Experimental results show
that PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\%
zero-shot accuracy, establishing a novel paradigm for accurate and highly
compressed LLMs.

</details>


### [9] [When can in-context learning generalize out of task distribution?](https://arxiv.org/abs/2506.05574)
*Chase Goddard, Lindsay M. Smith, Vudtiwat Ngampruetikorn, David J. Schwab*

**主要类别:** cs.LG

**AI概要:** 本文研究了变压器模型中上下文学习（ICL）的出现条件，发现任务多样性显著影响ICL的泛化能力，并观察到从特化解到泛化解的过渡过程。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在揭示上下文学习（ICL）在预训练分布中所需的条件，特别是任务多样性对ICL出现和泛化能力的影响。

**方法:** 通过实证方法研究变压器模型在不同任务多样性下的表现，并构建相图分析任务多样性与预训练任务数量的关系。同时探讨了非线性回归问题中的类似转变以及模型深度和问题维度对转变的影响。

**结果:** 随着任务多样性的增加，变压器模型从只能在预训练任务分布内进行ICL的特化解过渡到可以泛化的解，该解能够推广到整个任务空间。此外，在非线性回归问题中也观察到了类似的过渡现象。

**结论:** 论文得出结论，任务多样性在预训练分布中对于上下文学习（ICL）的出现和泛化能力至关重要，并且在特定过渡点后，模型能够实现跨任务空间的泛化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+can+in-context+learning+generalize+out+of+task+distribution%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05574，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05574&send_immediately=true&force_search=false)

**原文摘要:** In-context learning (ICL) is a remarkable capability of pretrained
transformers that allows models to generalize to unseen tasks after seeing only
a few examples. We investigate empirically the conditions necessary on the
pretraining distribution for ICL to emerge and generalize
\emph{out-of-distribution}. Previous work has focused on the number of distinct
tasks necessary in the pretraining dataset. Here, we use a different notion of
task diversity to study the emergence of ICL in transformers trained on linear
functions. We find that as task diversity increases, transformers undergo a
transition from a specialized solution, which exhibits ICL only within the
pretraining task distribution, to a solution which generalizes out of
distribution to the entire task space. We also investigate the nature of the
solutions learned by the transformer on both sides of the transition, and
observe similar transitions in nonlinear regression problems. We construct a
phase diagram to characterize how our concept of task diversity interacts with
the number of pretraining tasks. In addition, we explore how factors such as
the depth of the model and the dimensionality of the regression problem
influence the transition.

</details>


### [10] [Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward](https://arxiv.org/abs/2506.05433)
*Zikang Liu, Tongtian Yue, Yepeng Tang, Longteng Guo, Junxian Cai, Qingbin Liu, Xi Chen, Jing Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出Prefix Grouper，一种高效的GRPO训练方法，有效减少计算开销并提升长上下文学习的可扩展性。


<details>
  <summary>更多</summary>
  
**动机:** GRPO在处理长共享前缀时引入了大量计算开销，这成为其在长上下文学习场景中的主要瓶颈。

**方法:** 提出了一种名为Prefix Grouper的新算法，通过Shared-Prefix Forward策略重构自注意力机制，以消除冗余前缀计算。

**结果:** Prefix Grouper在保持相同输出和梯度的同时，显著降低了训练的计算成本，尤其适用于长前缀场景。此外，它完全兼容现有架构，并且可以无缝集成到当前训练流水线中。

**结论:** Prefix Grouper与标准GRPO训练等效，但显著减少了计算开销，提高了GRPO的可扩展性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prefix+Grouper%3A+Efficient+GRPO+Training+through+Shared-Prefix+Forward，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05433&send_immediately=true&force_search=false)

**原文摘要:** Group Relative Policy Optimization (GRPO) enhances policy learning by
computing gradients from relative comparisons among candidate outputs that
share a common input prefix. Despite its effectiveness, GRPO introduces
substantial computational overhead when processing long shared prefixes, which
must be redundantly encoded for each group member. This inefficiency becomes a
major scalability bottleneck in long-context learning scenarios. We propose
Prefix Grouper, an efficient GRPO training algorithm that eliminates redundant
prefix computation via a Shared-Prefix Forward strategy. In particular, by
restructuring self-attention into two parts, our method enables the shared
prefix to be encoded only once, while preserving full differentiability and
compatibility with end-to-end training. We provide both theoretical and
empirical evidence that Prefix Grouper is training-equivalent to standard GRPO:
it yields identical forward outputs and backward gradients, ensuring that the
optimization dynamics and final policy performance remain unchanged.
Empirically, our experiments confirm that Prefix Grouper achieves consistent
results while significantly reducing the computational cost of training,
particularly in long-prefix scenarios. The proposed method is fully
plug-and-play: it is compatible with existing GRPO-based architectures and can
be seamlessly integrated into current training pipelines as a drop-in
replacement, requiring no structural modifications and only minimal changes to
input construction and attention computation. Prefix Grouper enables the use of
larger group sizes under the same computational budget, thereby improving the
scalability of GRPO to more complex tasks and larger models. Code is now
available at https://github.com/johncaged/PrefixGrouper

</details>


### [11] [Conformal Prediction Adaptive to Unknown Subpopulation Shifts](https://arxiv.org/abs/2506.05583)
*Nien-Shao Wang, Duygu Nur Yaldiz, Yavuz Faruk Bakman, Sai Praneeth Karimireddy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的共形预测方法，可以适应未知的子群体混合情况，在测试时间和训练时间数据分布不同的情况下仍能确保有效覆盖。


<details>
  <summary>更多</summary>
  
**动机:** 现有的共形预测方法在测试时间数据分布与训练或校准时间分布不同时，通常无法提供有效的覆盖保证。本文旨在解决这一问题。

**方法:** 该论文提出了能够处理子群体转移的共形预测新方法，并通过实验验证了其在高维设置和实际机器学习任务中的有效性。

**结果:** 实验结果表明，所提出的方法在标准共形预测失效的情况下，能够可靠地保持覆盖并控制风险。

**结论:** 该论文提出的新方法能够在未知和不同的子群体混合情况下，适应共形预测，确保有效的覆盖范围，同时不需要显式的子群体结构知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conformal+Prediction+Adaptive+to+Unknown+Subpopulation+Shifts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05583&send_immediately=true&force_search=false)

**原文摘要:** Conformal prediction is widely used to equip black-box machine learning
models with uncertainty quantification enjoying formal coverage guarantees.
However, these guarantees typically break down in the presence of distribution
shifts, where the data distribution at test time differs from the training (or
calibration-time) distribution. In this work, we address subpopulation shifts,
where the test environment exhibits an unknown and differing mixture of
subpopulations compared to the calibration data. We propose new methods that
provably adapt conformal prediction to such shifts, ensuring valid coverage
without requiring explicit knowledge of subpopulation structure. Our algorithms
scale to high-dimensional settings and perform effectively in realistic machine
learning tasks. Extensive experiments on vision (with vision transformers) and
language (with large language models) benchmarks demonstrate that our methods
reliably maintain coverage and controls risk in scenarios where standard
conformal prediction fails.

</details>


### [12] [Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks](https://arxiv.org/abs/2506.05434)
*Thomas Massena, Léo andéol, Thibaut Boissin, Franck Mamalet, Corentin Friedrich, Mathieu Serrurier, Sébastien Gerchinovitz*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种名为lip-rcp的新方法，该方法能够高效且精确地估计在对抗攻击下的鲁棒共形预测集，相较于现有方法在性能和效率上均有提升。


<details>
  <summary>更多</summary>
  
**动机:** 传统的共形预测方法在对抗攻击下无法维持其保证，而现有的鲁棒共形预测方法要么计算代价高昂，要么生成的预测集过大。

**方法:** 通过利用Lipschitz有界的网络，精确而高效地估计鲁棒共形预测集，并结合1-Lipschitz鲁棒网络。

**结果:** 所提出的lip-rcp方法在ImageNet等中大规模场景下，在鲁棒共形预测集的大小和计算效率方面均优于当前最先进的结果。此外，还推导了对所有对抗攻击水平有效的香草CP集的最坏情况覆盖边界。

**结论:** 论文提出了一种新的方法lip-rcp，该方法在中大规模场景下优于现有技术，并且在提供鲁棒性保证的同时保持了计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Robust+Conformal+Prediction+via+Lipschitz-Bounded+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05434，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05434&send_immediately=true&force_search=false)

**原文摘要:** Conformal Prediction (CP) has proven to be an effective post-hoc method for
improving the trustworthiness of neural networks by providing prediction sets
with finite-sample guarantees. However, under adversarial attacks, classical
conformal guarantees do not hold anymore: this problem is addressed in the
field of Robust Conformal Prediction. Several methods have been proposed to
provide robust CP sets with guarantees under adversarial perturbations, but,
for large scale problems, these sets are either too large or the methods are
too computationally demanding to be deployed in real life scenarios. In this
work, we propose a new method that leverages Lipschitz-bounded networks to
precisely and efficiently estimate robust CP sets. When combined with a
1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms
state-of-the-art results in both the size of the robust CP sets and
computational efficiency in medium and large-scale scenarios such as ImageNet.
Taking a different angle, we also study vanilla CP under attack, and derive new
worst-case coverage bounds of vanilla CP sets, which are valid simultaneously
for all adversarial attack levels. Our lip-rcp method makes this second
approach as efficient as vanilla CP while also allowing robustness guarantees.

</details>


### [13] [Zero-shot protein stability prediction by inverse folding models: a free energy interpretation](https://arxiv.org/abs/2506.05596)
*Jes Frellsen, Maher M. Kassem, Tone Bengtsen, Lars Olsen, Kresten Lindorff-Larsen, Jesper Ferkinghoff-Borg, Wouter Boomsma*

**主要类别:** cs.LG

**AI概要:** 本文研究了逆折叠模型用于蛋白质稳定性预测的基础，指出当前方法的局限性，并提出了改进方案，从而在简单实现下获得更好的预测效果。


<details>
  <summary>更多</summary>
  
**动机:** 尽管逆折叠模型在零样本蛋白质稳定性预测中表现出色，但其氨基酸偏好与热力学稳定性背后的自由能关系尚未完全明确。这种理解的缺乏限制了模型进一步提升预测能力的潜力。因此，本文旨在深入探讨这一基础问题，并探索更优的稳定性预测方法。

**方法:** 论文采用理论推导和实证评估相结合的方法。首先对逆折叠模型的似然比方法进行理论分析，揭示其作为自由能近似方法的局限性，并提出几种可能改进的路径；随后通过实验验证这些改进方法的有效性。

**结果:** 研究发现标准的似然比方法是一种简化的近似方法，并提出了几种能够更准确估计相对稳定性的新方法。实验表明，使用这些新方法可以在不增加复杂度的情况下显著提升零样本预测的性能。

**结论:** 论文得出结论，通过更准确地估计相对稳定性，可以显著提高零样本蛋白质稳定性预测的性能。这不仅从理论上澄清了逆折叠模型与自由能之间的关系，还提供了改进预测效果的实际路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zero-shot+protein+stability+prediction+by+inverse+folding+models%3A+a+free+energy+interpretation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05596，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05596&send_immediately=true&force_search=false)

**原文摘要:** Inverse folding models have proven to be highly effective zero-shot
predictors of protein stability. Despite this success, the link between the
amino acid preferences of an inverse folding model and the free-energy
considerations underlying thermodynamic stability remains incompletely
understood. A better understanding would be of interest not only from a
theoretical perspective, but also potentially provide the basis for stronger
zero-shot stability prediction. In this paper, we take steps to clarify the
free-energy foundations of inverse folding models. Our derivation reveals the
standard practice of likelihood ratios as a simplistic approximation and
suggests several paths towards better estimates of the relative stability. We
empirically assess these approaches and demonstrate that considerable gains in
zero-shot performance can be achieved with fairly simple means.

</details>


### [14] [Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning](https://arxiv.org/abs/2506.05435)
*Manon Renault, Hamoud Younes, Hugo Tessier, Ronan Le Roy, Bastien Pasdeloup, Mathieu Léonardon*

**主要类别:** cs.LG

**AI概要:** 本研究开发了一种用于可重用包装监测的低功耗深度学习方法，其通过嵌入式系统实现高效的状态识别。


<details>
  <summary>更多</summary>
  
**动机:** 可重用包装监测对于工业应用的操作效率和生态可持续性具有重要意义，但需要设计一种与包装寿命匹配的系统。

**方法:** 使用一维卷积神经网络架构对来自IoT设备的加速度计数据进行分类，并采用数据增强技术和压缩技术解决数据不平衡问题和减小模型大小。

**结果:** 该方法在二元分类问题上达到了94.54%和95.83%的精确度，同时压缩技术将模型大小减少了四倍，并且在推理过程中仅消耗316毫瓦的功率。

**结论:** 论文提出了一种基于嵌入式系统的可重用包装监测方法，该方法在设备寿命和能源消耗方面表现良好，并成功实现了状态检测任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Event+Classification+of+Accelerometer+Data+for+Industrial+Package+Monitoring+with+Embedded+Deep+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05435，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05435&send_immediately=true&force_search=false)

**原文摘要:** Package monitoring is an important topic in industrial applications, with
significant implications for operational efficiency and ecological
sustainability. In this study, we propose an approach that employs an embedded
system, placed on reusable packages, to detect their state (on a Forklift, in a
Truck, or in an undetermined location). We aim to design a system with a
lifespan of several years, corresponding to the lifespan of reusable packages.
Our analysis demonstrates that maximizing device lifespan requires minimizing
wake time. We propose a pipeline that includes data processing, training, and
evaluation of the deep learning model designed for imbalanced, multiclass time
series data collected from an embedded sensor. The method uses a
one-dimensional Convolutional Neural Network architecture to classify
accelerometer data from the IoT device. Before training, two data augmentation
techniques are tested to solve the imbalance problem of the dataset: the
Synthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling
approach. After training, compression techniques are implemented to have a
small model size. On the considered twoclass problem, the methodology yields a
precision of 94.54% for the first class and 95.83% for the second class, while
compression techniques reduce the model size by a factor of four. The trained
model is deployed on the IoT device, where it operates with a power consumption
of 316 mW during inference.

</details>


### [15] [RNE: a plug-and-play framework for diffusion density estimation and inference-time control](https://arxiv.org/abs/2506.05668)
*Jiajun He, José Miguel Hernández-Lobato, Yuanqi Du, Francisco Vargas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的扩散推理时密度估计与控制框架Radon-Nikodym Estimator (RNE)，它基于路径分布间的密度比，并通过统一多种现有方法提供理论上的清晰性与实践中的灵活性。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在解决扩散模型中的密度估计和推理时控制问题，提供一个兼具理论清晰性和实践通用性的框架，以提升相关任务如退火、扩散模型组合以及奖励倾斜的性能表现。

**方法:** 论文提出了一种基于路径分布密度比概念的灵活框架Radon-Nikodym Estimator (RNE)，用于扩散推理时密度估计与控制。该方法通过基本的变分推断和概率原理，将多种现有的密度估计和推理时控制方法连接并统一起来。

**结果:** 实验结果表明，RNE在扩散密度估计和推理时控制任务中取得了良好的性能，包括退火、扩散模型组合和奖励倾斜等应用场景。

**结论:** RNE不仅在扩散密度估计和推理时控制任务中表现出色，还为现有方法提供了统一的理论视角，展现出理论清晰性与实践多功能性的结合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RNE%3A+a+plug-and-play+framework+for+diffusion+density+estimation+and+inference-time+control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05668，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05668&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we introduce the Radon-Nikodym Estimator (RNE), a flexible,
plug-and-play framework for diffusion inference-time density estimation and
control, based on the concept of the density ratio between path distributions.
RNE connects and unifies a variety of existing density estimation and
inference-time control methods under a single and intuitive perspective,
stemming from basic variational inference and probabilistic principles
therefore offering both theoretical clarity and practical versatility.
Experiments demonstrate that RNE achieves promising performances in diffusion
density estimation and inference-time control tasks, including annealing,
composition of diffusion models, and reward-tilting.

</details>


### [16] [An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics](https://arxiv.org/abs/2506.05438)
*Tongda Sun, Chen Yin, Huailiang Zheng, Yining Dong*

**主要类别:** cs.LG

**AI概要:** 本文设计了一个无监督框架下的动态健康指标构建方法，有效捕捉滚动轴承退化过程中的动态信息，提升了退化趋势建模与预测的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的健康指标构建方法大多依赖专家知识进行特征提取，忽视了序列退化过程中隐藏的动态信息，限制了健康指标在退化趋势表示和预测方面的能力。

**方法:** 通过一个无监督框架构造考虑HI级别时间依赖性的动态HI，包括基于跳跃连接自编码器的退化特征学习模块和嵌入内部HI预测块的新HI生成模块。

**结果:** 实验结果表明，所提出的健康指标构建方法优于对比方法，且构建的动态健康指标在预测任务中表现优异。

**结论:** 论文提出了一种新的动态健康指标（HI）构建方法，该方法能够更好地表示退化趋势并提升预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Unsupervised+Framework+for+Dynamic+Health+Indicator+Construction+and+Its+Application+in+Rolling+Bearing+Prognostics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05438，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05438&send_immediately=true&force_search=false)

**原文摘要:** Health indicator (HI) plays a key role in degradation assessment and
prognostics of rolling bearings. Although various HI construction methods have
been investigated, most of them rely on expert knowledge for feature extraction
and overlook capturing dynamic information hidden in sequential degradation
processes, which limits the ability of the constructed HI for degradation trend
representation and prognostics. To address these concerns, a novel dynamic HI
that considers HI-level temporal dependence is constructed through an
unsupervised framework. Specifically, a degradation feature learning module
composed of a skip-connection-based autoencoder first maps raw signals to a
representative degradation feature space (DFS) to automatically extract
essential degradation features without the need for expert knowledge.
Subsequently, in this DFS, a new HI-generating module embedded with an inner
HI-prediction block is proposed for dynamic HI construction, where the temporal
dependence between past and current HI states is guaranteed and modeled
explicitly. On this basis, the dynamic HI captures the inherent dynamic
contents of the degradation process, ensuring its effectiveness for degradation
tendency modeling and future degradation prognostics. The experiment results on
two bearing lifecycle datasets demonstrate that the proposed HI construction
method outperforms comparison methods, and the constructed dynamic HI is
superior for prognostic tasks.

</details>


### [17] [Grokking Beyond the Euclidean Norm of Model Parameters](https://arxiv.org/abs/2506.05718)
*Pascal Jr Tikeng Notsawo, Guillaume Dumas, Guillaume Rabusseau*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了如何通过正则化和过参数化来诱导神经网络中的grokking现象，并指出ℓ2范数并非总是可靠的泛化指标。


<details>
  <summary>更多</summary>
  
**动机:** Grokking是当前深度学习领域中一个重要的现象，理解其机制有助于更好地训练人工神经网络并提升模型的泛化能力。本文旨在深入探究引发grokking的具体条件及其背后的机理。

**方法:** 论文通过理论分析和实验验证的方法，探讨了不同类型的正则化（如ℓ1范数、核范数）以及过参数化对grokking现象的影响，并评估了ℓ2范数作为泛化能力代理的有效性。

**结果:** 研究发现，在存在具备特定性质P（如稀疏权重或低秩权重）的模型能够解决目标问题的情况下，带有针对P的小但非零正则化的梯度下降可以诱发grokking；此外，增加模型深度可以在不使用显式正则化的情况下影响grokking的发生。

**结论:** Grokking是一种在优化人工神经网络时出现的延迟泛化现象，可以通过正则化（无论是显式的还是隐式的）诱导产生。研究还表明，通过增加深度进行过参数化可以在不使用显式正则化的情况下实现“grok”或“ungrok”，这是浅层模型无法做到的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grokking+Beyond+the+Euclidean+Norm+of+Model+Parameters，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05718，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05718&send_immediately=true&force_search=false)

**原文摘要:** Grokking refers to a delayed generalization following overfitting when
optimizing artificial neural networks with gradient-based methods. In this
work, we demonstrate that grokking can be induced by regularization, either
explicit or implicit. More precisely, we show that when there exists a model
with a property $P$ (e.g., sparse or low-rank weights) that generalizes on the
problem of interest, gradient descent with a small but non-zero regularization
of $P$ (e.g., $\ell_1$ or nuclear norm regularization) results in grokking.
This extends previous work showing that small non-zero weight decay induces
grokking. Moreover, our analysis shows that over-parameterization by adding
depth makes it possible to grok or ungrok without explicitly using
regularization, which is impossible in shallow cases. We further show that the
$\ell_2$ norm is not a reliable proxy for generalization when the model is
regularized toward a different property $P$, as the $\ell_2$ norm grows in many
cases where no weight decay is used, but the model generalizes anyway. We also
show that grokking can be amplified solely through data selection, with any
other hyperparameter fixed.

</details>


### [18] [UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss](https://arxiv.org/abs/2506.05443)
*Yiyu Lin, Yan Wang, You Zhou, Xinye Ni, Jiahui Wu, Sen Yang*

**主要类别:** cs.LG

**AI概要:** 本文提出了用于蛋白质翻译后修饰预测的统一深度学习框架UniPTMs，通过创新架构和优化策略显著提升预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决现有深度学习模型在跨模态特征融合、领域泛化和架构优化方面的局限性，尤其是实现多类型PTM预测的统一框架。

**方法:** 提出了一种名为UniPTMs的统一框架，采用“主从”双路径协同架构，包括BGCA模块、LDFN模块、MACP模块和BHGFN模块，并引入HDWF机制与层次对比损失函数。

**结果:** UniPTMs在五种修饰类型上相较最先进模型取得了显著性能提升（MCC提升3.2%-11.4%，AP提升4.2%-14.3%），并打破了单一类型预测范式。

**结论:** UniPTMs实现了对多种蛋白质翻译后修饰类型的统一预测，并通过创新架构和损失函数显著提升了性能，同时提供了轻量级版本以平衡复杂度与效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是UniPTMs%3A+The+First+Unified+Multi-type+PTM+Site+Prediction+Model+via+Master-Slave+Architecture-Based+Multi-Stage+Fusion+Strategy+and+Hierarchical+Contrastive+Loss，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05443，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05443&send_immediately=true&force_search=false)

**原文摘要:** As a core mechanism of epigenetic regulation in eukaryotes, protein
post-translational modifications (PTMs) require precise prediction to decipher
dynamic life activity networks. To address the limitations of existing deep
learning models in cross-modal feature fusion, domain generalization, and
architectural optimization, this study proposes UniPTMs: the first unified
framework for multi-type PTM prediction. The framework innovatively establishes
a "Master-Slave" dual-path collaborative architecture: The master path
dynamically integrates high-dimensional representations of protein sequences,
structures, and evolutionary information through a Bidirectional Gated
Cross-Attention (BGCA) module, while the slave path optimizes feature
discrepancies and recalibration between structural and traditional features
using a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale
Adaptive convolutional Pyramid (MACP) for capturing local feature patterns and
a Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level
feature integration across paths, the framework employs a Hierarchical Dynamic
Weighting Fusion (HDWF) mechanism to intelligently aggregate multimodal
features. Enhanced by a novel Hierarchical Contrastive loss function for
feature consistency optimization, UniPTMs demonstrates significant performance
improvements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art
models across five modification types and transcends the Single-Type Prediction
Paradigm. To strike a balance between model complexity and performance, we have
also developed a lightweight variant named UniPTMs-mini.

</details>


### [19] [Neural Collapse in Cumulative Link Models for Ordinal Regression: An Analysis with Unconstrained Feature Model](https://arxiv.org/abs/2506.05801)
*Chuang Ma, Tomoyuki Obuchi, Toshiyuki Tanaka*

**主要类别:** cs.LG

**AI概要:** 本研究揭示了深度序数回归任务中存在序神经坍塌（ONC）现象，该现象具有三种特定性质，并通过理论和实验进行了验证。


<details>
  <summary>更多</summary>
  
**动机:** 希望了解深度神经网络在序数回归任务中的行为，探索类似于分类任务中神经坍塌现象是否存在于OR任务中。

**方法:** 结合累积链接模型与无约束特征模型（UFM）框架，进行理论推导和实验证明。

**结果:** 发现了序神经坍塌（ONC）现象，并明确其三个特性：类内特征坍塌、类均值与分类器对齐、潜在变量与阈值的几何关系。

**结论:** 研究证明在深度序数回归任务中存在一种称为序神经坍塌（ONC）的现象，其具有三个特性，并通过理论分析与实验验证了这些特性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+Collapse+in+Cumulative+Link+Models+for+Ordinal+Regression%3A+An+Analysis+with+Unconstrained+Feature+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05801&send_immediately=true&force_search=false)

**原文摘要:** A phenomenon known as ''Neural Collapse (NC)'' in deep classification tasks,
in which the penultimate-layer features and the final classifiers exhibit an
extremely simple geometric structure, has recently attracted considerable
attention, with the expectation that it can deepen our understanding of how
deep neural networks behave. The Unconstrained Feature Model (UFM) has been
proposed to explain NC theoretically, and there emerges a growing body of work
that extends NC to tasks other than classification and leverages it for
practical applications. In this study, we investigate whether a similar
phenomenon arises in deep Ordinal Regression (OR) tasks, via combining the
cumulative link model for OR and UFM. We show that a phenomenon we call Ordinal
Neural Collapse (ONC) indeed emerges and is characterized by the following
three properties: (ONC1) all optimal features in the same class collapse to
their within-class mean when regularization is applied; (ONC2) these class
means align with the classifier, meaning that they collapse onto a
one-dimensional subspace; (ONC3) the optimal latent variables (corresponding to
logits or preactivations in classification tasks) are aligned according to the
class order, and in particular, in the zero-regularization limit, a highly
local and simple geometric relationship emerges between the latent variables
and the threshold values. We prove these properties analytically within the UFM
framework with fixed threshold values and corroborate them empirically across a
variety of datasets. We also discuss how these insights can be leveraged in OR,
highlighting the use of fixed thresholds.

</details>


### [20] [Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic](https://arxiv.org/abs/2506.05445)
*Thanh Vinh Vo, Young Lee, Haozhe Ma, Chien Lu, Tze-Yun Leong*

**主要类别:** cs.LG

**AI概要:** 本文提出 DoSAC 方法，在不依赖真实混杂变量的情况下，通过因果干预估计提升强化学习策略的鲁棒性和泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 隐藏混杂因素会影响状态和动作，导致策略学习出现偏差，大多数现有 RL 算法忽视了这一问题。

**方法:** 通过引入可学习的后门重构器模块，利用后门准则估计干预策略 π(a|do(s))，将因果干预估计与软演员-评论家框架结合。

**结果:** 在连续控制基准任务中，DoSAC 在受混杂因素影响的设置下优于基线方法。

**结论:** DoSAC 是一种能够减轻隐藏混杂因素对策略学习影响的强化学习方法，实验证明其具有更好的鲁棒性、泛化能力和策略可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Policy+Learning+in+Reinforcement+Learning%3A+Backdoor-Adjusted+Soft+Actor-Critic，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05445，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05445&send_immediately=true&force_search=false)

**原文摘要:** Hidden confounders that influence both states and actions can bias policy
learning in reinforcement learning (RL), leading to suboptimal or
non-generalizable behavior. Most RL algorithms ignore this issue, learning
policies from observational trajectories based solely on statistical
associations rather than causal effects. We propose DoSAC (Do-Calculus Soft
Actor-Critic with Backdoor Adjustment), a principled extension of the SAC
algorithm that corrects for hidden confounding via causal intervention
estimation. DoSAC estimates the interventional policy $\pi(a | \mathrm{do}(s))$
using the backdoor criterion, without requiring access to true confounders or
causal labels. To achieve this, we introduce a learnable Backdoor Reconstructor
that infers pseudo-past variables (previous state and action) from the current
state to enable backdoor adjustment from observational data. This module is
integrated into a soft actor-critic framework to compute both the
interventional policy and its entropy. Empirical results on continuous control
benchmarks show that DoSAC outperforms baselines under confounded settings,
with improved robustness, generalization, and policy reliability.

</details>


### [21] [Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning](https://arxiv.org/abs/2506.05447)
*Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了扩大语言模型规模如何影响其训练动态，特别关注到一种称为零和学习的现象，这种现象会导致损失曲线的变化，并提出了可能不依赖于模型规模来改进语言模型的方法。


<details>
  <summary>更多</summary>
  
**动机:** 该研究旨在理解扩大模型规模如何改善语言模型，特别是在训练动态方面的改进。

**方法:** 通过观察不同规模的语言模型在训练过程中的损失变化情况，并分析其梯度相互抵消的现象。

**结果:** 研究发现，在训练初期，语言模型会出现损失减速现象，即损失改善的速度突然变慢，导致在对数-对数空间中损失曲线呈现出分段线性的行为。扩大模型规模可以通过降低发生减速时的损失以及改善减速后的损失改善率来缓解这一转变。

**结论:** 论文得出结论，损失减速和零和学习提供了关于语言模型扩展规律背后的训练动态的新见解，并且可能会被直接针对以独立于规模的方式改进语言模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+Dynamics+Underlying+Language+Model+Scaling+Laws%3A+Loss+Deceleration+and+Zero-Sum+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05447，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05447&send_immediately=true&force_search=false)

**原文摘要:** This work aims to understand how scaling improves language models,
specifically in terms of training dynamics. We find that language models
undergo loss deceleration early in training; an abrupt slowdown in the rate of
loss improvement, resulting in piecewise linear behaviour of the loss curve in
log-log space. Scaling up the model mitigates this transition by (1) decreasing
the loss at which deceleration occurs, and (2) improving the log-log rate of
loss improvement after deceleration. We attribute loss deceleration to a type
of degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,
per-example gradients become systematically opposed, leading to destructive
interference in per-example changes in loss. As a result, improving loss on one
subset of examples degrades it on another, bottlenecking overall progress. Loss
deceleration and ZSL provide new insights into the training dynamics underlying
language model scaling laws, and could potentially be targeted directly to
improve language models independent of scale. We make our code and artefacts
available at: https://github.com/mirandrom/zsl

</details>


### [22] [A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization](https://arxiv.org/abs/2506.06179)
*Muhammed Ustaomeroglu, Guannan Qu*

**主要类别:** cs.LG

**AI概要:** 本文分析了自注意力机制作为交互学习器的作用，提出了两个新模块HyperFeatureAttention和HyperAttention，用以捕获更复杂的交互模式。


<details>
  <summary>更多</summary>
  
**动机:** 尽管自注意力已成为现代神经网络架构的核心组件，但其理论基础仍然模糊。因此需要深入研究以理解其内在机制并扩展其应用范围。

**方法:** 通过研究线性自注意力层在表示、学习和泛化成对交互函数方面的能力，从多个领域（如多智能体强化学习和遗传序列）中分析自注意力的理论基础，并提出新模块进行实验验证。

**结果:** 研究表明单层线性自注意力可以高效地表示和学习成对交互函数，包括分布外场景。实验验证了自注意力可以学习交互函数，并在不同种群分布和分布外场景中实现泛化。

**结论:** 本文得出自注意力机制可以作为交互学习器，并且能够广泛适用于各种现实世界领域。论文还提出了两种新的模块：HyperFeatureAttention和HyperAttention，用于捕捉不同特征层面的交互以及多实体依赖关系。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Theoretical+Study+of+%28Hyper%29+Self-Attention+through+the+Lens+of+Interactions%3A+Representation%2C+Training%2C+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06179，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06179&send_immediately=true&force_search=false)

**原文摘要:** Self-attention has emerged as a core component of modern neural
architectures, yet its theoretical underpinnings remain elusive. In this paper,
we study self-attention through the lens of interacting entities, ranging from
agents in multi-agent reinforcement learning to alleles in genetic sequences,
and show that a single layer linear self-attention can efficiently represent,
learn, and generalize functions capturing pairwise interactions, including
out-of-distribution scenarios. Our analysis reveals that self-attention acts as
a mutual interaction learner under minimal assumptions on the diversity of
interaction patterns observed during training, thereby encompassing a wide
variety of real-world domains. In addition, we validate our theoretical
insights through experiments demonstrating that self-attention learns
interaction functions and generalizes across both population distributions and
out-of-distribution scenarios. Building on our theories, we introduce
HyperFeatureAttention, a novel neural network module designed to learn
couplings of different feature-level interactions between entities.
Furthermore, we propose HyperAttention, a new module that extends beyond
pairwise interactions to capture multi-entity dependencies, such as three-way,
four-way, or general n-way interactions.

</details>


### [23] [Antithetic Noise in Diffusion Models](https://arxiv.org/abs/2506.06185)
*Jing Jia, Sifan Liu, Bowen Song, Wei Yuan, Liyue Shen, Guanyang Wang*

**主要类别:** cs.LG

**AI概要:** 该论文研究了扩散模型中初始噪声的反义配对效应，通过实验和理论分析提出了对称性假设，并利用这种负相关性增强图像多样性和改进估计精度。


<details>
  <summary>更多</summary>
  
**动机:** 为了系统研究扩散模型中初始噪声的反义配对效应及其潜在应用。

**方法:** 结合实验与理论分析，提出了对称性假设，并将其应用于随机准蒙特卡洛估计器。

**结果:** 发现初始噪声与其否定形式配对可产生强负相关样本，并成功应用于图像多样性和不确定性量化。

**结论:** 本文得出配对初始噪声可以增强图像多样性且提升估计准确性，提出了一种无需训练、模型无关的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Antithetic+Noise+in+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06185，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06185&send_immediately=true&force_search=false)

**原文摘要:** We initiate a systematic study of antithetic initial noise in diffusion
models. Across unconditional models trained on diverse datasets,
text-conditioned latent-diffusion models, and diffusion-posterior samplers, we
find that pairing each initial noise with its negation consistently yields
strongly negatively correlated samples. To explain this phenomenon, we combine
experiments and theoretical analysis, leading to a symmetry conjecture that the
learned score function is approximately affine antisymmetric (odd symmetry up
to a constant shift), and provide evidence supporting it. Leveraging this
negative correlation, we enable two applications: (1) enhancing image diversity
in models like Stable Diffusion without quality loss, and (2) sharpening
uncertainty quantification (e.g., up to 90% narrower confidence intervals) when
estimating downstream statistics. Building on these gains, we extend the
two-point pairing to a randomized quasi-Monte Carlo estimator, which further
improves estimation accuracy. Our framework is training-free, model-agnostic,
and adds no runtime overhead.

</details>


### [24] [Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors](https://arxiv.org/abs/2506.05479)
*Matei Gabriel Coşa, Marek Eliáš*

**主要类别:** cs.LG

**AI概要:** 论文研究了在线学习中选择最佳启发式方法的问题，提出了一种能够实现接近最优性能的算法，并给出了理论保证。


<details>
  <summary>更多</summary>
  
**动机:** 动机是解决在仅能查询一个启发式方法动作的情况下，如何在线处理输入实例并实现与最佳启发式方法相当的性能的问题。

**方法:** 论文研究了一个在线学习问题，其中每个时间步只能查询一个启发式方法的动作，并利用类似于Bandit Learning的方法进行决策优化，以应对记忆受限的对手。

**结果:** 实现了O(OPT^(2/3))的遗憾界，并提供了基于Dekel等人构造的紧下界证明。

**结论:** 论文得出结论，针对给定的启发式方法，在线算法可以实现与最佳启发式方法相当的性能，并且达到了O(OPT^(2/3))的遗憾界，同时基于Dekel等人的构造证明了紧下界。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning-Augmented+Algorithms+for+MTS+with+Bandit+Access+to+Multiple+Predictors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05479，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05479&send_immediately=true&force_search=false)

**原文摘要:** We consider the following problem: We are given $\ell$ heuristics for
Metrical Task Systems (MTS), where each might be tailored to a different type
of input instances. While processing an input instance received online, we are
allowed to query the action of only one of the heuristics at each time step.
Our goal is to achieve performance comparable to the best of the given
heuristics. The main difficulty of our setting comes from the fact that the
cost paid by a heuristic at time $t$ cannot be estimated unless the same
heuristic was also queried at time $t-1$. This is related to Bandit Learning
against memory bounded adversaries (Arora et al., 2012). We show how to achieve
regret of $O(\text{OPT}^{2/3})$ and prove a tight lower bound based on the
construction of Dekel et al. (2013).

</details>


### [25] [Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?](https://arxiv.org/abs/2506.05484)
*Ruihua Chen, Bangyu Wu, Meng Li, Kai Yang*

**主要类别:** cs.LG

**AI概要:** 本文研究了基于神经网络重新参数化的全波形反演中使用预训练与去标准化方法整合初始模型的效果，发现去标准化具有更好的效率和准确性。


<details>
  <summary>更多</summary>
  
**动机:** 动机在于探究不同的初始模型整合方式对基于神经网络重新参数化的全波形反演的影响，并寻找更高效的方法。

**方法:** 论文系统地研究了两种将初始模型先验知识嵌入神经网络的方法（预训练和去标准化），并通过对模型扰动进行反演的两阶段实现进行了分析。

**结果:** 实验结果表明，去标准化方法在性能上优于预训练方法，主要体现在流程简化、收敛加速以及反演精度提升方面。

**结论:** 论文得出结论，去标准化方法相比预训练能够简化工作流程、加快收敛速度，并提高反演精度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Initial+Model+Incorporation+for+Deep+Learning+FWI%3A+Pretraining+or+Denormalization%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05484，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05484&send_immediately=true&force_search=false)

**原文摘要:** Subsurface property neural network reparameterized full waveform inversion
(FWI) has emerged as an effective unsupervised learning framework, which can
invert stably with an inaccurate starting model. It updates the trainable
neural network parameters instead of fine-tuning on the subsurface model
directly. There are primarily two ways to embed the prior knowledge of the
initial model into neural networks, that is, pretraining and denormalization.
Pretraining first regulates the neural networks' parameters by fitting the
initial velocity model; Denormalization directly adds the outputs of the
network into the initial models without pretraining. In this letter, we
systematically investigate the influence of the two ways of initial model
incorporation for the neural network reparameterized FWI. We demonstrate that
pretraining requires inverting the model perturbation based on a constant
velocity value (mean) with a two-stage implementation. It leads to a complex
workflow and inconsistency of objective functions in the two-stage process,
causing the network parameters to become inactive and lose plasticity.
Experimental results demonstrate that denormalization can simplify workflows,
accelerate convergence, and enhance inversion accuracy compared with
pretraining.

</details>


### [26] [Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models](https://arxiv.org/abs/2506.05497)
*Sima Noorani, Shayan Kiyani, George Pappas, Hamed Hassani*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种适用于黑盒生成模型（如大语言模型）的新型保形预测框架CPQ，通过解决查询预算、覆盖率与信息量之间的平衡问题，实现了更优的不确定性量化性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了在高风险应用中安全部署生成式AI模型（如大语言模型），需要一种有效的不确定性量化方法。传统保形预测方法依赖于结构化输出，而实际中生成模型的输出往往复杂且未明确指定，因此需要新的方法解决这一问题。

**方法:** 该论文提出了Conformal Prediction with Query Oracle (CPQ)，其核心方法包括基于缺失质量衰减速率的最优查询策略和使用Good-Turing估计器的最优映射策略。

**结果:** 实验结果表明，CPQ在三个真实开放任务和两个大语言模型上的表现证明了其适用性和优势，特别是在生成更具有信息量的预测集方面优于现有方法。

**结论:** 论文得出结论，CPQ框架在语言模型的保形预测中能够显著提升预测集的信息量，并且通过两个核心原则解决了覆盖性、查询预算和信息量之间的权衡问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conformal+Prediction+Beyond+the+Seen%3A+A+Missing+Mass+Perspective+for+Uncertainty+Quantification+in+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05497，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05497&send_immediately=true&force_search=false)

**原文摘要:** Uncertainty quantification (UQ) is essential for safe deployment of
generative AI models such as large language models (LLMs), especially in high
stakes applications. Conformal prediction (CP) offers a principled uncertainty
quantification framework, but classical methods focus on regression and
classification, relying on geometric distances or softmax scores: tools that
presuppose structured outputs. We depart from this paradigm by studying CP in a
query only setting, where prediction sets must be constructed solely from
finite queries to a black box generative model, introducing a new trade off
between coverage, test time query budget, and informativeness. We introduce
Conformal Prediction with Query Oracle (CPQ), a framework characterizing the
optimal interplay between these objectives. Our finite sample algorithm is
built on two core principles: one governs the optimal query policy, and the
other defines the optimal mapping from queried samples to prediction sets.
Remarkably, both are rooted in the classical missing mass problem in
statistics. Specifically, the optimal query policy depends on the rate of
decay, or the derivative, of the missing mass, for which we develop a novel
estimator. Meanwhile, the optimal mapping hinges on the missing mass itself,
which we estimate using Good Turing estimators. We then turn our focus to
implementing our method for language models, where outputs are vast, variable,
and often under specified. Fine grained experiments on three real world open
ended tasks and two LLMs, show CPQ applicability to any black box LLM and
highlight: (1) individual contribution of each principle to CPQ performance,
and (2) CPQ ability to yield significantly more informative prediction sets
than existing conformal methods for language uncertainty quantification.

</details>


### [27] [Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates](https://arxiv.org/abs/2506.05513)
*Yunfei Huang, David S. Greenberg*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种能够结合物理规律与对称性约束的神经PDE代理模型，提高了预测精度和泛化能力，尤其是在复杂流体动力学问题中的表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经PDE代理模型在新初始条件下的泛化能力和长时间预测中存在误差积累问题，而物理和对称性约束有助于缩小这一性能差距。

**方法:** 论文引入了新的输入层和输出层设计，以在交错网格上尊重物理定律和对称性，并系统地研究这些约束如何影响PDE代理模型的准确性。

**结果:** 实验表明，对称性和物理约束显著提升了多个任务、架构和预测步骤的性能，尤其是结合使用时效果最佳，并能更准确地预测真实世界的海洋洋流。

**结论:** 论文得出结论，结合物理约束和对称性约束的神经网络模型在预测PDE解方面表现最佳，并且在没有数据增强的情况下也具有良好的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Geometric+and+Physical+Constraints+Synergistically+Enhance+Neural+PDE+Surrogates，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05513，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05513&send_immediately=true&force_search=false)

**原文摘要:** Neural PDE surrogates can improve the cost-accuracy tradeoff of classical
solvers, but often generalize poorly to new initial conditions and accumulate
errors over time. Physical and symmetry constraints have shown promise in
closing this performance gap, but existing techniques for imposing these
inductive biases are incompatible with the staggered grids commonly used in
computational fluid dynamics. Here we introduce novel input and output layers
that respect physical laws and symmetries on the staggered grids, and for the
first time systematically investigate how these constraints, individually and
in combination, affect the accuracy of PDE surrogates. We focus on two
challenging problems: shallow water equations with closed boundaries and
decaying incompressible turbulence. Compared to strong baselines, symmetries
and physical constraints consistently improve performance across tasks,
architectures, autoregressive prediction steps, accuracy measures, and network
sizes. Symmetries are more effective than physical constraints, but surrogates
with both performed best, even compared to baselines with data augmentation or
pushforward training, while themselves benefiting from the pushforward trick.
Doubly-constrained surrogates also generalize better to initial conditions and
durations beyond the range of the training data, and more accurately predict
real-world ocean currents.

</details>


### [28] [Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum](https://arxiv.org/abs/2506.05530)
*Snir Hordan, Maya Bechler-Speicher, Gur Lifshitz, Nadav Dym*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了如何通过最大特征值重数来分类图，从而构建SGNNs的表现力层次结构，并提出了一个改进SGNNs表现力的方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的评估SGNNs表现力的框架与图谱对齐不佳，因此需要一种新的方法来更好地理解SGNNs的表现能力。

**方法:** 作者利用了分类图的最大特征值重数的范式来构建SGNNs的表现力层次结构，并适应旋转等变神经网络到图谱设置中以提高表现力。

**结果:** 论文证明了许多SGNNs即使在具有不同特征值的图上也是不完整的，并通过实验验证了所提出的提高表现力的方法的有效性。

**结论:** 论文得出结论，许多SGNNs在具有不同特征值的图上是不完整的，并提出了一种方法来提高SGNNs在简单谱图上的表现力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spectral+Graph+Neural+Networks+are+Incomplete+on+Graphs+with+a+Simple+Spectrum，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05530，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05530&send_immediately=true&force_search=false)

**原文摘要:** Spectral features are widely incorporated within Graph Neural Networks (GNNs)
to improve their expressive power, or their ability to distinguish among
non-isomorphic graphs. One popular example is the usage of graph Laplacian
eigenvectors for positional encoding in MPNNs and Graph Transformers. The
expressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated
via the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,
these frameworks align poorly with the graph spectra, yielding limited insight
into SGNNs' expressive power. We leverage a well-studied paradigm of
classifying graphs by their largest eigenvalue multiplicity to introduce an
expressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete
even on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt
rotation equivariant neural networks to the graph spectra setting to propose a
method to provably improve SGNNs' expressivity on simple spectrum graphs. We
empirically verify our theoretical claims via an image classification
experiment on the MNIST Superpixel dataset and eigenvector canonicalization on
graphs from ZINC.

</details>


### [29] [SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms](https://arxiv.org/abs/2506.05538)
*Arnesh Batra, Anushk Kumar, Jashn Khemani, Arush Gumber, Arhan Jain, Somil Gupta*

**主要类别:** cs.LG

**AI概要:** 该论文介绍了SocialDF数据集和一种新的基于LLM的多因素检测方法，旨在解决社交媒体上deepfake带来的安全挑战。


<details>
  <summary>更多</summary>
  
**动机:** 深度生成模型的进步使得合成媒体的真实性显著提高，这也带来了安全挑战，尤其是在社交媒体上的虚假信息活动。现有的检测框架难以区分良性和对抗性生成的deepfake。

**方法:** 提出了一种基于LLM的多因素检测方法，结合了面部识别、自动语音转录和多代理LLM管道来交叉验证音视频线索。

**结果:** 介绍了一个名为SocialDF的数据集，反映了社交媒体平台上现实世界的deepfake挑战，并提出了一个新颖的基于LLM的多因素检测方法。

**结论:** 论文得出的结论是，通过使用多模态验证技术，可以有效地辨别合成媒体和真实内容。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SocialDF%3A+Benchmark+Dataset+and+Detection+Model+for+Mitigating+Harmful+Deepfake+Content+on+Social+Media+Platforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05538，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05538&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of deep generative models has significantly improved
the realism of synthetic media, presenting both opportunities and security
challenges. While deepfake technology has valuable applications in
entertainment and accessibility, it has emerged as a potent vector for
misinformation campaigns, particularly on social media. Existing detection
frameworks struggle to distinguish between benign and adversarially generated
deepfakes engineered to manipulate public perception. To address this
challenge, we introduce SocialDF, a curated dataset reflecting real-world
deepfake challenges on social media platforms. This dataset encompasses
high-fidelity deepfakes sourced from various online ecosystems, ensuring broad
coverage of manipulative techniques. We propose a novel LLM-based multi-factor
detection approach that combines facial recognition, automated speech
transcription, and a multi-agent LLM pipeline to cross-verify audio-visual
cues. Our methodology emphasizes robust, multi-modal verification techniques
that incorporate linguistic, behavioral, and contextual analysis to effectively
discern synthetic media from authentic content.

</details>


### [30] [Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data](https://arxiv.org/abs/2506.05542)
*Vlastimil Martinek, Andrea Gariboldi, Dimosthenis Tzimotoudis, Aitor Alberdi Escudero, Edward Blake, David Cechak, Luke Cassar, Alessandro Balestrucci, Panagiotis Alexiou*

**主要类别:** cs.LG

**AI概要:** 本文提出Agentomics-ML，一种完全自主的基于代理的系统，用于自动化端到端的机器学习实验，在生物医学数据集上实现更高的泛化能力和成功率。


<details>
  <summary>更多</summary>
  
**动机:** 生物数据集的数量、多模态性和异质性要求能够产生可推广预测模型的自动化方法。现有的大型语言模型代理在结构化基准测试中表现良好，但在异构计算生物学数据集上面临泛化和成功率的问题。

**方法:** 该方法通过预定义的机器学习实验步骤进行操作，利用Bash与文件系统反复交互以完成各个步骤。在生成机器学习模型后，利用训练和验证指标提供标量反馈，以识别过拟合并生成语言反馈，指导后续迭代的数据表示、模型架构和超参数调整。

**结果:** Agentomics-ML在几个已建立的基因组和转录组基准数据集上进行了评估，结果表明其在泛化能力和成功率方面均优于现有最先进的代理方法，并在一个基准数据集上达到了最先进的性能。

**结论:** Agentomics-ML是一个完全自主的基于代理的系统，可以在多个基因组和转录组基准数据集上生成分类模型，并在再现性训练和推理方面表现出色。虽然专家构建的模型在多数数据集上的性能仍然领先，但Agentomics-ML缩小了完全自主系统的性能差距，并在一个基准数据集上实现了最先进的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Agentomics-ML%3A+Autonomous+Machine+Learning+Experimentation+Agent+for+Genomic+and+Transcriptomic+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05542，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05542&send_immediately=true&force_search=false)

**原文摘要:** The adoption of machine learning (ML) and deep learning methods has
revolutionized molecular medicine by driving breakthroughs in genomics,
transcriptomics, drug discovery, and biological systems modeling. The
increasing quantity, multimodality, and heterogeneity of biological datasets
demand automated methods that can produce generalizable predictive models.
Recent developments in large language model-based agents have shown promise for
automating end-to-end ML experimentation on structured benchmarks. However,
when applied to heterogeneous computational biology datasets, these methods
struggle with generalization and success rates. Here, we introduce
Agentomics-ML, a fully autonomous agent-based system designed to produce a
classification model and the necessary files for reproducible training and
inference. Our method follows predefined steps of an ML experimentation
process, repeatedly interacting with the file system through Bash to complete
individual steps. Once an ML model is produced, training and validation metrics
provide scalar feedback to a reflection step to identify issues such as
overfitting. This step then creates verbal feedback for future iterations,
suggesting adjustments to steps such as data representation, model
architecture, and hyperparameter choices. We have evaluated Agentomics-ML on
several established genomic and transcriptomic benchmark datasets and show that
it outperforms existing state-of-the-art agent-based methods in both
generalization and success rates. While state-of-the-art models built by domain
experts still lead in absolute performance on the majority of the computational
biology datasets used in this work, Agentomics-ML narrows the gap for fully
autonomous systems and achieves state-of-the-art performance on one of the used
benchmark datasets. The code is available at
https://github.com/BioGeMT/Agentomics-ML.

</details>


### [31] [Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning](https://arxiv.org/abs/2506.05568)
*Arian Raje, Baris Askin, Divyansh Jhunjhunwala, Gauri Joshi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Ravan的新方法，用于改进边缘设备上的大型语言模型联邦微调，解决了精度下降问题并实现了更高的测试准确性。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决传统LoRA方法在联邦学习环境中因数据和计算异构性导致的准确性下降问题。

**方法:** 使用多头LoRA方法重新参数化权重更新，并训练核心矩阵和轻量级缩放因子，以集中优化最有用的头部。

**结果:** 实验表明，Ravan在视觉和语言基准上比现有参数高效基线提高了2-8%的测试准确率。

**结论:** Ravan是一种适用于大型语言模型联邦微调的自适应多头LoRA方法，通过平衡参数效率和模型表现力，在不增加通信开销的情况下提升了测试准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ravan%3A+Multi-Head+Low-Rank+Adaptation+for+Federated+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05568，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05568&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have not yet effectively leveraged the vast
amounts of edge-device data, and federated learning (FL) offers a promising
paradigm to collaboratively fine-tune LLMs without transferring private edge
data to the cloud. To operate within the computation and communication
constraints of edge devices, recent literature on federated fine-tuning of LLMs
proposes the use of low-rank adaptation (LoRA) and similar parameter-efficient
methods. However, LoRA-based methods suffer from accuracy degradation in FL
settings, primarily because of data and computational heterogeneity across
clients. We propose \textsc{Ravan}, an adaptive multi-head LoRA method that
balances parameter efficiency and model expressivity by reparameterizing the
weight updates as the sum of multiple LoRA heads
$s_i\textbf{B}_i\textbf{H}_i\textbf{A}_i$ in which only the core matrices
$\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These
trainable scaling factors let the optimization focus on the most useful heads,
recovering a higher-rank approximation of the full update without increasing
the number of communicated parameters since clients upload $s_i\textbf{H}_i$
directly. Experiments on vision and language benchmarks show that
\textsc{Ravan} improves test accuracy by 2-8\% over prior parameter-efficient
baselines, making it a robust and scalable solution for federated fine-tuning
of LLMs.

</details>


### [32] [Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts](https://arxiv.org/abs/2506.05577)
*Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Xinran Liu, Soheil Kolouri, Peter Kinnell, Zexin Li, Cong Liu, Shirin Dora, Andrea Soltoggio*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种新的agentic算法MOSAIC，它允许多个代理独立解决问题的同时分享和再利用机器学习的知识，无需协调、同步或集中控制，从而提高了学习效率和问题解决能力。


<details>
  <summary>更多</summary>
  
**动机:** 研究者认为，在去中心化环境下运行的实际agentic系统面临诸多限制，例如带宽有限、异步执行以及缺乏集中模型或共同目标等，因此需要利用先前学习的技能、任务相似性和通信能力来提高系统的可扩展性、开放性和有益的协作学习动态。

**方法:** 论文提出了一种名为Modular Sharing and Composition in Collective Learning (MOSAIC)的agentic算法，该算法结合了三个机制：(1) 通过神经网络掩码进行模块化策略组合，(2) 使用Wasserstein嵌入进行余弦相似性估计以选择知识，以及(3) 异步通信和策略集成。

**结果:** 实验结果表明，与孤立学习者相比，MOSAIC具有更高的样本效率，即学习速度更快，并且在某些情况下能够解决孤立学习者无法解决的任务。同时观察到协作学习和共享动态导致了从简单到困难的理想任务课程的出现。

**结论:** 论文得出结论，协作学习在agentic AI系统中对于实现个体和集体层面更好、持续发展的性能是有益的，并通过MOSAIC算法展示了其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collaborative+Learning+in+Agentic+Systems%3A+A+Collective+AI+is+Greater+Than+the+Sum+of+Its+Parts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05577，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05577&send_immediately=true&force_search=false)

**原文摘要:** Agentic AI has gained significant interest as a research paradigm focused on
autonomy, self-directed learning, and long-term reliability of decision making.
Real-world agentic systems operate in decentralized settings on a large set of
tasks or data distributions with constraints such as limited bandwidth,
asynchronous execution, and the absence of a centralized model or even common
objectives. We posit that exploiting previously learned skills, task
similarities, and communication capabilities in a collective of agentic AI are
challenging but essential elements to enabling scalability, open-endedness, and
beneficial collaborative learning dynamics. In this paper, we introduce Modular
Sharing and Composition in Collective Learning (MOSAIC), an agentic algorithm
that allows multiple agents to independently solve different tasks while also
identifying, sharing, and reusing useful machine-learned knowledge, without
coordination, synchronization, or centralized control. MOSAIC combines three
mechanisms: (1) modular policy composition via neural network masks, (2) cosine
similarity estimation using Wasserstein embeddings for knowledge selection, and
(3) asynchronous communication and policy integration. Results on a set of RL
benchmarks show that MOSAIC has a greater sample efficiency than isolated
learners, i.e., it learns significantly faster, and in some cases, finds
solutions to tasks that cannot be solved by isolated learners. The
collaborative learning and sharing dynamics are also observed to result in the
emergence of ideal curricula of tasks, from easy to hard. These findings
support the case for collaborative learning in agentic systems to achieve
better and continuously evolving performance both at the individual and
collective levels.

</details>


### [33] [TabFlex: Scaling Tabular Learning to Millions with Linear Attention](https://arxiv.org/abs/2506.05584)
*Yuchen Zeng, Tuan Dinh, Wonjun Kang, Andreas C Mueller*

**主要类别:** cs.LG

**AI概要:** TabFlex通过线性注意力机制提升了TabPFN的效率和可扩展性，适用于大规模表格分类任务。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法如TabPFN在处理小规模表格数据方面表现出色，但在大规模和复杂数据集上存在扩展困难。

**方法:** 通过引入线性注意力机制改进TabPFN，以实现对大规模和复杂数据集的可扩展处理。

**结果:** TabFlex能够高效处理具有数千个特征和数百个类别的表格数据，比TabPFN快2倍以上，比XGBoost快1.5倍，并且在大量样本上实现了无缝扩展。

**结论:** TabFlex是一种高效的表格分类模型，适用于大规模数据集，并且在计算成本显著降低的情况下保持高性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TabFlex%3A+Scaling+Tabular+Learning+to+Millions+with+Linear+Attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05584，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05584&send_immediately=true&force_search=false)

**原文摘要:** Leveraging the in-context learning (ICL) capability of Large Language Models
(LLMs) for tabular classification has gained significant attention for its
training-free adaptability across diverse datasets. Recent advancements, like
TabPFN, excel in small-scale tabular datasets but struggle to scale for large
and complex datasets. Our work enhances the efficiency and scalability of
TabPFN for larger datasets by incorporating linear attention mechanisms as a
scalable alternative to complexity-quadratic self-attention. Our model,
TabFlex, efficiently handles tabular datasets with thousands of features and
hundreds of classes, scaling seamlessly to millions of samples. For instance,
TabFlex processes the poker-hand dataset with over a million samples in just 5
seconds. Our extensive evaluations demonstrate that TabFlex can achieve over a
2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25
tested baselines in terms of efficiency across a diverse range of datasets.
Furthermore, TabFlex remains highly effective on large-scale datasets,
delivering strong performance with significantly reduced computational costs,
especially when combined with data-efficient techniques such as dimensionality
reduction and data sampling.

</details>


### [34] [CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions](https://arxiv.org/abs/2506.05586)
*Isha Puri, Amit Dhurandhar, Tejaswini Pedapati, Kartikeyan Shanmugam, Dennis Wei, Kush R. Varshney*

**主要类别:** cs.LG

**AI概要:** This paper proposes CoFrNet, an interpretable neural architecture inspired by continued fractions, demonstrating strong performance and theoretical guarantees as a universal approximator.


<details>
  <summary>更多</summary>
  
**动机:** While there is significant research on post hoc explanations for neural networks, there is limited work on inherently interpretable architectures. This gap motivates the development of CoFrNet.

**方法:** The paper introduces CoFrNet, a neural architecture inspired by continued fractions, and theoretically proves its ability to act as a universal approximator while experimentally testing its performance on synthetic and real datasets.

**结果:** Experiments demonstrate that CoFrNets can accurately model nonlinear synthetic functions, estimate feature attributions, and perform competitively or better than other models on real datasets spanning multiple modalities.

**结论:** CoFrNets are proven to be universal approximators with a unique proof strategy, showcasing their representational power and interpretability across synthetic and real-world datasets.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoFrNets%3A+Interpretable+Neural+Architecture+Inspired+by+Continued+Fractions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05586，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05586&send_immediately=true&force_search=false)

**原文摘要:** In recent years there has been a considerable amount of research on local
post hoc explanations for neural networks. However, work on building
interpretable neural architectures has been relatively sparse. In this paper,
we present a novel neural architecture, CoFrNet, inspired by the form of
continued fractions which are known to have many attractive properties in
number theory, such as fast convergence of approximations to real numbers. We
show that CoFrNets can be efficiently trained as well as interpreted leveraging
their particular functional form. Moreover, we prove that such architectures
are universal approximators based on a proof strategy that is different than
the typical strategy used to prove universal approximation results for neural
networks based on infinite width (or depth), which is likely to be of
independent interest. We experiment on nonlinear synthetic functions and are
able to accurately model as well as estimate feature attributions and even
higher order terms in some cases, which is a testament to the representational
power as well as interpretability of such architectures. To further showcase
the power of CoFrNets, we experiment on seven real datasets spanning tabular,
text and image modalities, and show that they are either comparable or
significantly better than other interpretable models and multilayer
perceptrons, sometimes approaching the accuracies of state-of-the-art models.

</details>


### [35] [FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting](https://arxiv.org/abs/2506.05597)
*Yash Vijay, Harini Subramanyan*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的时间序列预测模型FaCTR，具有轻量化、高性能和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 解决传统Transformer在时间序列预测中的过参数化和结构不匹配问题。

**方法:** 提出了轻量级时空Transformer FaCTR，通过低秩分解机和可学习门控机制注入动态、对称的跨通道交互。

**结果:** 在11个公开预测基准上取得了最先进水平，参数量仅为现有模型的1/50。

**结论:** FaCTR实现了最先进的性能，同时具备可解释性和自监督预训练能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FaCTR%3A+Factorized+Channel-Temporal+Representation+Transformers+for+Efficient+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05597，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05597&send_immediately=true&force_search=false)

**原文摘要:** While Transformers excel in language and vision-where inputs are semantically
rich and exhibit univariate dependency structures-their architectural
complexity leads to diminishing returns in time series forecasting. Time series
data is characterized by low per-timestep information density and complex
dependencies across channels and covariates, requiring conditioning on
structured variable interactions. To address this mismatch and
overparameterization, we propose FaCTR, a lightweight spatiotemporal
Transformer with an explicitly structural design. FaCTR injects dynamic,
symmetric cross-channel interactions-modeled via a low-rank Factorization
Machine into temporally contextualized patch embeddings through a learnable
gating mechanism. It further encodes static and dynamic covariates for
multivariate conditioning. Despite its compact design, FaCTR achieves
state-of-the-art performance on eleven public forecasting benchmarks spanning
both short-term and long-term horizons, with its largest variant using close to
only 400K parameters-on average 50x smaller than competitive spatiotemporal
transformer baselines. In addition, its structured design enables
interpretability through cross-channel influence scores-an essential
requirement for real-world decision-making. Finally, FaCTR supports
self-supervised pretraining, positioning it as a compact yet versatile
foundation for downstream time series tasks.

</details>


### [36] [When Maximum Entropy Misleads Policy Optimization](https://arxiv.org/abs/2506.05615)
*Ruipeng Zhang, Ya-Chien Chang, Sicun Gao*

**主要类别:** cs.LG

**AI概要:** 该论文分析了最大熵强化学习（MaxEnt RL）在复杂控制任务中的局限性，指出熵最大化虽增强探索与鲁棒性，但可能误导策略优化，导致任务失败。


<details>
  <summary>更多</summary>
  
**动机:** MaxEnt 强化学习方法虽然在许多任务中表现良好，但在性能关键的控制问题上却可能失效，而其他非 MaxEnt 算法却能成功学习。

**方法:** 通过多种控制问题的实验，分析 MaxEnt 算法中最大化熵对策略优化的影响，并探讨其误导效应。

**结果:** 研究结果表明，尽管熵最大化能够提升探索和鲁棒性，但它也可能误导策略优化，导致在复杂控制任务中的失败。

**结论:** 论文得出结论，在复杂控制任务中，MaxEnt RL 方法在鲁棒性和最优性之间存在权衡，这可能导致需要精确、低熵策略的任务失败。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Maximum+Entropy+Misleads+Policy+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05615，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05615&send_immediately=true&force_search=false)

**原文摘要:** The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading
approach for achieving efficient learning and robust performance across many RL
tasks. However, MaxEnt methods have also been shown to struggle with
performance-critical control problems in practice, where non-MaxEnt algorithms
can successfully learn. In this work, we analyze how the trade-off between
robustness and optimality affects the performance of MaxEnt algorithms in
complex control tasks: while entropy maximization enhances exploration and
robustness, it can also mislead policy optimization, leading to failure in
tasks that require precise, low-entropy policies. Through experiments on a
variety of control problems, we concretely demonstrate this misleading effect.
Our analysis leads to better understanding of how to balance reward design and
entropy maximization in challenging control problems.

</details>


### [37] [LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis](https://arxiv.org/abs/2506.05617)
*Antonia van Betteray, Matthias Rottmann, Karsten Kahl*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种高效的算法，用于计算高维卷积映射的全部奇异值，其复杂度为O(N)，并利用了卷积算子的位移不变性和局部傅里叶分析。


<details>
  <summary>更多</summary>
  
**动机:** 现有的计算卷积映射奇异值的方法资源消耗大或受限于硬件条件，因此需要一种更高效的算法。

**方法:** 利用局部傅里叶分析和卷积算子的位移不变性，在O(N)复杂度下计算奇异值。

**结果:** 所提方法在理论分析和数值实验中均表现出较高的效率和可扩展性，能够在较低复杂度下实现对全部奇异值的计算。

**结论:** 论文提出了一种基于局部傅里叶分析的新方法，能够高效计算高维卷积映射的全部奇异值，并且如果需要的话，还能计算对应的奇异向量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LFA+applied+to+CNNs%3A+Efficient+Singular+Value+Decomposition+of+Convolutional+Mappings+by+Local+Fourier+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05617，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05617&send_immediately=true&force_search=false)

**原文摘要:** The singular values of convolutional mappings encode interesting spectral
properties, which can be used, e.g., to improve generalization and robustness
of convolutional neural networks as well as to facilitate model compression.
However, the computation of singular values is typically very
resource-intensive. The naive approach involves unrolling the convolutional
mapping along the input and channel dimensions into a large and sparse
two-dimensional matrix, making the exact calculation of all singular values
infeasible due to hardware limitations. In particular, this is true for
matrices that represent convolutional mappings with large inputs and a high
number of channels. Existing efficient methods leverage the Fast Fourier
transformation (FFT) to transform convolutional mappings into the frequency
domain, enabling the computation of singular values for matrices representing
convolutions with larger input and channel dimensions. For a constant number of
channels in a given convolution, an FFT can compute N singular values in O(N
log N) complexity. In this work, we propose an approach of complexity O(N)
based on local Fourier analysis, which additionally exploits the shift
invariance of convolutional operators. We provide a theoretical analysis of our
algorithm's runtime and validate its efficiency through numerical experiments.
Our results demonstrate that our proposed method is scalable and offers a
practical solution to calculate the entire set of singular values - along with
the corresponding singular vectors if needed - for high-dimensional
convolutional mappings.

</details>


### [38] [Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods](https://arxiv.org/abs/2506.05626)
*Xiaohua Lu, Liubov Tupikina, Mehwish Alam*

**主要类别:** cs.LG

**AI概要:** 这篇论文综述了如何更好地利用知识超图和超关系知识图谱来建模现实世界中复杂的多实体关系，并提出了新的分类方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决知识图谱简化n元关系导致的信息丢失问题以及超图表示学习忽略实体角色的问题，结合两者的优势进行更复杂的建模。

**方法:** 提出了一种二维分类法，从方法论和实体角色与位置意识两个维度对现有模型进行分类和分析。

**结果:** 该研究系统性地回顾了知识超图和超关系知识图谱的相关文献，并对模型、数据集和采样策略进行了全面分析。

**结论:** 论文总结了处理n元关系数据的方法，并提出了一个二维分类法，讨论了未来的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Two-dimensional+Taxonomy+for+N-ary+Knowledge+Representation+Learning+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05626，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05626&send_immediately=true&force_search=false)

**原文摘要:** Real-world knowledge can take various forms, including structured,
semi-structured, and unstructured data. Among these, knowledge graphs are a
form of structured human knowledge that integrate heterogeneous data sources
into structured representations but typically reduce complex n-ary relations to
simple triples, thereby losing higher-order relational details. In contrast,
hypergraphs naturally represent n-ary relations with hyperedges, which directly
connect multiple entities together. Yet hypergraph representation learning
often overlooks entity roles in hyperedges, limiting the fine-grained semantic
modelling. To address these issues, knowledge hypergraphs and hyper-relational
knowledge graphs combine the advantages of knowledge graphs and hypergraphs to
better capture the complex structures and role-specific semantics of real-world
knowledge. This survey provides a comprehensive review of methods handling
n-ary relational data, covering both knowledge hypergraphs and hyper-relational
knowledge graphs literatures. We propose a two-dimensional taxonomy: the first
dimension categorises models based on their methodology, i.e.,
translation-based models, tensor factorisation-based models, deep neural
network-based models, logic rules-based models, and hyperedge expansion-based
models. The second dimension classifies models according to their awareness of
entity roles and positions in n-ary relations, dividing them into aware-less,
position-aware, and role-aware approaches. Finally, we discuss existing
datasets, negative sampling strategies, and outline open challenges to inspire
future research.

</details>


### [39] [GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance](https://arxiv.org/abs/2506.05628)
*Jiri Navratil, Jarret Ross, Payel Das, Youssef Mroueh, Samuel C Hoffman, Vijil Chenthamarakshan, Brian Belgodere*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种无需训练的新方法GP-MoLFormer-Sim，并结合遗传算法，在保持分子相似性的同时有效导航分子空间，显著提升了性能。


<details>
  <summary>更多</summary>
  
**动机:** 在药物发现、化学设计和生物学中，需要一种能够在保持与目标分子相似性的前提下设计分子的方法。

**方法:** 使用基于SMILES的生成式化学语言模型GP-MoLFormer，并提出GP-MoLFormer-Sim方法，在解码过程中利用目标分子相似性调整生成策略，同时将其集成到遗传算法中进行测试。

**结果:** 实验结果表明，GP-MoLFormer-Sim+GA在多种分子优化基准任务中表现优异，尤其是在黑盒环境下。

**结论:** GP-MoLFormer-Sim结合遗传算法在不依赖训练的情况下优于现有的基线方法，为理解和指导CLMs的生成机制提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GP-MoLFormer-Sim%3A+Test+Time+Molecular+Optimization+through+Contextual+Similarity+Guidance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05628，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05628&send_immediately=true&force_search=false)

**原文摘要:** The ability to design molecules while preserving similarity to a target
molecule and/or property is crucial for various applications in drug discovery,
chemical design, and biology. We introduce in this paper an efficient
training-free method for navigating and sampling from the molecular space with
a generative Chemical Language Model (CLM), while using the molecular
similarity to the target as a guide. Our method leverages the contextual
representations learned from the CLM itself to estimate the molecular
similarity, which is then used to adjust the autoregressive sampling strategy
of the CLM. At each step of the decoding process, the method tracks the
distance of the current generations from the target and updates the logits to
encourage the preservation of similarity in generations. We implement the
method using a recently proposed $\sim$47M parameter SMILES-based CLM,
GP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which
enables a test-time update of the deep generative policy to reflect the
contextual similarity to a set of guide molecules. The method is further
integrated into a genetic algorithm (GA) and tested on a set of standard
molecular optimization benchmarks involving property optimization, molecular
rediscovery, and structure-based drug design. Results show that,
GP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing
training-free baseline methods, when the oracle remains black-box. The findings
in this work are a step forward in understanding and guiding the generative
mechanisms of CLMs.

</details>


### [40] [List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression](https://arxiv.org/abs/2506.05632)
*Joseph Rowan, Buu Phan, Ashish Khisti*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种扩展的Gumbel-max采样方法，用于解决概率分布耦合问题，并展示了其在多草稿推测采样和分布式有损压缩中的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决耦合概率分布的问题，即从一个分布生成的样本列表中是否能与另一个分布生成的样本匹配，论文研究了这个问题的一个松弛版本，并尝试提升现有技术的效果和适用性。

**方法:** 论文提出了一种新的样本生成方法，扩展了Daliri等人提出的Gumbel-max采样方法，并建立了相关的接受概率下界（列表匹配引理）。

**结果:** 论文成功开发了一个简单实现的新机制，用于多草稿推测采样，在多个语言任务上表现与SpecTr和SpecInfer等基线方法相当甚至更好；此外，在分布式有损压缩任务中，所提方法在合成高斯源和MNIST图像数据集实验中取得了显著增益。

**结论:** 论文提出了基于Gumbel-max采样的新方法，用于耦合概率分布，并在多草稿推测采样和分布式有损压缩两个应用中展现了其优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是List-Level+Distribution+Coupling+with+Applications+to+Speculative+Decoding+and+Lossy+Compression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05632，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05632&send_immediately=true&force_search=false)

**原文摘要:** We study a relaxation of the problem of coupling probability distributions --
a list of samples is generated from one distribution and an accept is declared
if any one of these samples is identical to the sample generated from the other
distribution. We propose a novel method for generating samples, which extends
the Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for
coupling probability distributions. We also establish a corresponding lower
bound on the acceptance probability, which we call the list matching lemma. We
next discuss two applications of our setup. First, we develop a new mechanism
for multi-draft speculative sampling that is simple to implement and achieves
performance competitive with baselines such as SpecTr and SpecInfer across a
range of language tasks. Our method also guarantees a certain degree of drafter
invariance with respect to the output tokens which is not supported by existing
schemes. We also provide a theoretical lower bound on the token level
acceptance probability. As our second application, we consider distributed
lossy compression with side information in a setting where a source sample is
compressed and available to multiple decoders, each with independent side
information. We propose a compression technique that is based on our
generalization of Gumbel-max sampling and show that it provides significant
gains in experiments involving synthetic Gaussian sources and the MNIST image
dataset.

</details>


### [41] [AutoQD: Automatic Discovery of Diverse Behaviors with Quality-Diversity Optimization](https://arxiv.org/abs/2506.05634)
*Saeed Hedayatian, Stefanos Nikolaidis*

**主要类别:** cs.LG

**AI概要:** 本研究提出AutoQD方法，通过自动嵌入策略占用度量以替代传统人工设计的行为描述符，实现更高效的质量-多样性优化。


<details>
  <summary>更多</summary>
  
**动机:** 传统Quality-Diversity算法依赖人工设计的行为描述符，限制了探索多样性的能力，因此需要一种自动化方法来克服这一问题。

**方法:** 利用策略与占用度量的等价性，通过随机傅里叶特征逼近策略占用度量之间的最大均值差异（MMD），生成能反映有意义行为差异的嵌入，并将其低维投影用作行为描述符。

**结果:** 理论证明了随着采样轨迹数和嵌入维度的增加，所提出的嵌入能够收敛到真实的MMD距离；实验表明AutoQD在多个连续控制任务中能够成功发现多样化策略。

**结论:** AutoQD提供了一种无需领域特定知识即可自动发现多样化策略的方法，为无监督强化学习和质量-多样性优化开辟了新路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoQD%3A+Automatic+Discovery+of+Diverse+Behaviors+with+Quality-Diversity+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05634，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05634&send_immediately=true&force_search=false)

**原文摘要:** Quality-Diversity (QD) algorithms have shown remarkable success in
discovering diverse, high-performing solutions, but rely heavily on
hand-crafted behavioral descriptors that constrain exploration to predefined
notions of diversity. Leveraging the equivalence between policies and occupancy
measures, we present a theoretically grounded approach to automatically
generate behavioral descriptors by embedding the occupancy measures of policies
in Markov Decision Processes. Our method, AutoQD, leverages random Fourier
features to approximate the Maximum Mean Discrepancy (MMD) between policy
occupancy measures, creating embeddings whose distances reflect meaningful
behavioral differences. A low-dimensional projection of these embeddings that
captures the most behaviorally significant dimensions is then used as
behavioral descriptors for off-the-shelf QD methods. We prove that our
embeddings converge to true MMD distances between occupancy measures as the
number of sampled trajectories and embedding dimensions increase. Through
experiments in multiple continuous control tasks we demonstrate AutoQD's
ability in discovering diverse policies without predefined behavioral
descriptors, presenting a well-motivated alternative to prior methods in
unsupervised Reinforcement Learning and QD optimization. Our approach opens new
possibilities for open-ended learning and automated behavior discovery in
sequential decision making settings without requiring domain-specific
knowledge.

</details>


### [42] [Bayesian Inference for Correlated Human Experts and Classifiers](https://arxiv.org/abs/2506.05636)
*Markelle Kelly, Alex Boyd, Sam Showalter, Mark Steyvers, Padhraic Smyth*

**主要类别:** cs.LG

**AI概要:** 本文研究了如何在最少查询人类专家的情况下，利用预训练分类器的类别概率估计来结合模型输出和专家意见进行预测。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习应用通常涉及根据模型输出和人类专家意见进行预测。然而，查询专家可能代价高昂且耗时，因此需要一种方法以最少的查询获得准确的预测结果。

**方法:** 开发了一种通用的贝叶斯框架，通过联合潜在表示对专家相关性进行建模，并使用模拟推理来评估额外专家查询的效用以及推断未观测专家标签的后验分布。

**结果:** 将该方法应用于两个现实世界的医学分类问题以及CIFAR-10H和ImageNet-16H数据集，结果表明相较于基线方法，在保持高预测精度的同时显著降低了查询人类专家的成本。

**结论:** 提出的方法能够在减少专家查询次数的同时维持较高的预测准确性，这对于资源有限的实际应用场景具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Inference+for+Correlated+Human+Experts+and+Classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05636，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05636&send_immediately=true&force_search=false)

**原文摘要:** Applications of machine learning often involve making predictions based on
both model outputs and the opinions of human experts. In this context, we
investigate the problem of querying experts for class label predictions, using
as few human queries as possible, and leveraging the class probability
estimates of pre-trained classifiers. We develop a general Bayesian framework
for this problem, modeling expert correlation via a joint latent
representation, enabling simulation-based inference about the utility of
additional expert queries, as well as inference of posterior distributions over
unobserved expert labels. We apply our approach to two real-world medical
classification problems, as well as to CIFAR-10H and ImageNet-16H,
demonstrating substantial reductions relative to baselines in the cost of
querying human experts while maintaining high prediction accuracy.

</details>


### [43] [Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones](https://arxiv.org/abs/2506.05641)
*Andrey Zhmoginov, Jihwan Lee, Mark Sandler*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种将大型Transformer模型转化为小型任务专用模型的方法，在图像任务中取得了比通用模型更好的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现代基础模型通常需要大量计算资源，且其广泛的知识库可能对特定任务来说过于冗余，因此需要一种高效且针对性强的模型转化方法。

**方法:** 研究了一种将大型Transformer模型参数转化为较小专用模型参数的技术，并将其应用于图像建模任务。

**结果:** 实验表明，该方法生成的模型在图像建模任务上的表现优于通用条件模型。

**结论:** 通过将大型Transformer模型映射到较小的特定任务模型，可以更有效地利用模型知识，从而在特定任务上超越通用条件模型的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Projectable+Models%3A+One-Shot+Generation+of+Small+Specialized+Transformers+from+Large+Ones，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05641，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05641&send_immediately=true&force_search=false)

**原文摘要:** Modern Foundation Models (FMs) are typically trained on corpora spanning a
wide range of different data modalities, topics and downstream tasks. Utilizing
these models can be very computationally expensive and is out of reach for most
consumer devices. Furthermore, most of the broad FM knowledge may actually be
irrelevant for a specific task at hand. Here we explore a technique for mapping
parameters of a large Transformer to parameters of a smaller specialized model.
By making this transformation task-specific, we aim to capture a narrower scope
of the knowledge needed for performing a specific task by a smaller model. We
study our method on image modeling tasks, showing that performance of generated
models exceeds that of universal conditional models.

</details>


### [44] [Learning to Weight Parameters for Data Attribution](https://arxiv.org/abs/2506.05647)
*Shuangqi Li, Hieu Le, Jingyi Xu, Mathieu Salzmann*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的生成模型数据归因方法，通过考虑不同网络层的重要性，实现对训练样本贡献的更精确和细粒度分析。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法将所有网络参数视为同等重要，忽略了不同层可能从训练数据中提取信息的差异，因此需要一种更精细的数据归因方法。

**方法:** 通过学习针对归因的参数重要性权重，建模不同网络层对不同类型信息的编码差异。

**结果:** 该方法在扩散模型中提高了归因准确性，并揭示了输出如何从训练数据中借用特定语义特征（如主题、风格或背景）的过程。

**结论:** 所提出的方法改进了生成模型中的数据归因，能够提供更准确和细粒度的归因结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Weight+Parameters+for+Data+Attribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05647，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05647&send_immediately=true&force_search=false)

**原文摘要:** We study data attribution in generative models, aiming to identify which
training examples most influence a given output. Existing methods achieve this
by tracing gradients back to training data. However, they typically treat all
network parameters uniformly, ignoring the fact that different layers encode
different types of information and may thus draw information differently from
the training set. We propose a method that models this by learning parameter
importance weights tailored for attribution, without requiring labeled data.
This allows the attribution process to adapt to the structure of the model,
capturing which training examples contribute to specific semantic aspects of an
output, such as subject, style, or background. Our method improves attribution
accuracy across diffusion models and enables fine-grained insights into how
outputs borrow from training data.

</details>


### [45] [BAQ: Efficient Bit Allocation Quantization for Large Language Models](https://arxiv.org/abs/2506.05664)
*Chao Zhang, Li Wang, Samson Lasaulce, Merouane Debbah*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种基于灵敏度度量的量化比特分配框架，以优化大语言模型的后训练量化效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有量化方法依赖于均匀或启发式比特分配，无法考虑权重对量化噪声的非均匀敏感性。

**方法:** 利用Hessian代理生成灵敏度度量，并通过凸优化任务实现层/组件级损失函数的显式比特分配。

**结果:** 实验结果表明BAQ在相同比特宽度下比GPTQ的困惑度降低了56倍。

**结论:** BAQ算法在标准量化流程中实现了良好的损失最小化与复杂度平衡，并提供了理论解释其性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BAQ%3A+Efficient+Bit+Allocation+Quantization+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05664，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05664&send_immediately=true&force_search=false)

**原文摘要:** Post-training model quantization is a widely adopted technique for reducing
the memory and computational costs of large language models (LLMs). However,
most existing methods rely on uniform or heuristic bitwidth assignments,
failing to account for the nonuniform sensitivity of weights to quantization
noise. In this paper, we propose a novel framework for allocating quantization
bitwidths based on sensitivity metrics derived from a Hessian proxy. We make
key assumptions, which allow the layer/component-wise loss function to be
expressed as an explicit function of the bitwidths. This enables a neat
formulation of the bit allocation problem as a convex optimization task, whose
closed-form solution adapts precision across weights to minimize the layer-wise
quantization loss. Inspecting the solution provides several insights (such as
the equal-loss structure), which are then exploited to design the proposed
\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm
achieves a good trade-off between loss minimization and complexity and allows
BAQ to be integrated into standard quantization pipelines with minimal
overhead. Experimental results show that BAQ consistently outperforms GPTQ,
achieving up to 56$\times$ lower perplexity at the same bitwidth on large
language models ranging from 125M to 30B parameters. Leveraging our analytical
results derived from solving the optimal bit allocation problem, we also
provide a theoretical explanation for the observed gains. All codes of this
paper are available at https://github.com/CSU-ModelCompression/BAQ.

</details>


### [46] [Contextually Guided Transformers via Low-Rank Adaptation](https://arxiv.org/abs/2506.05672)
*Andrey Zhmoginov, Jihwan Lee, Max Vladymyrov, Mark Sandler*

**主要类别:** cs.LG

**AI概要:** 该论文介绍了一种新的Transformer架构修改方法，旨在消除对显式提示的依赖，通过学习将上下文编码到模型权重中，从而提高语言模型的效率和适应性。


<details>
  <summary>更多</summary>
  
**动机:** 基于Transformer的大型语言模型在文本处理方面表现出色，但它们依赖于提示来实现特定行为，这引入了计算开销。

**方法:** 修改了Transformer架构，使其能够在没有显式提示的情况下通过学习将上下文编码到模型权重中，并引入了增强学习上下文表示的解释性的技术。

**结果:** 这种方法使模型能够自我专业化，有效地创建一个量身定制的模型用于处理给定前缀后的信息，并在合成的上下文学习任务和语言建模基准上展示了该方法的有效性。

**结论:** 这篇论文提出了一种新颖的将上下文直接集成到模型架构中的方法，为高效和适应性强的语言建模提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Contextually+Guided+Transformers+via+Low-Rank+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05672&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) based on Transformers excel at text processing,
but their reliance on prompts for specialized behavior introduces computational
overhead. We propose a modification to a Transformer architecture that
eliminates the need for explicit prompts by learning to encode context into the
model's weights. Our Contextually Guided Transformer (CGT) model maintains a
contextual summary at each sequence position, allowing it to update the weights
on the fly based on the preceding context. This approach enables the model to
self-specialize, effectively creating a tailored model for processing
information following a given prefix. We demonstrate the effectiveness of our
method on synthetic in-context learning tasks and language modeling benchmarks.
Furthermore, we introduce techniques for enhancing the interpretability of the
learned contextual representations, drawing connections to Variational
Autoencoders and promoting smoother, more consistent context encoding. This
work offers a novel direction for efficient and adaptable language modeling by
integrating context directly into the model's architecture.

</details>


### [47] [Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery](https://arxiv.org/abs/2506.05673)
*Sajjad Abdoli, Freeman Lewin, Gediminas Vasiliauskas, Fabian Schonholz*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Peer-Ranked+Precision%3A+Creating+a+Foundational+Dataset+for+Fine-Tuning+Vision+Models+from+DataSeeds%27+Annotated+Imagery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05673，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05673&send_immediately=true&force_search=false)

**原文摘要:** The development of modern Artificial Intelligence (AI) models, particularly
diffusion-based models employed in computer vision and image generation tasks,
is undergoing a paradigmatic shift in development methodologies. Traditionally
dominated by a "Model Centric" approach, in which performance gains were
primarily pursued through increasingly complex model architectures and
hyperparameter optimization, the field is now recognizing a more nuanced
"Data-Centric" approach. This emergent framework foregrounds the quality,
structure, and relevance of training data as the principal driver of model
performance. To operationalize this paradigm shift, we introduce the
DataSeeds.AI sample dataset (the "DSD"), initially comprised of approximately
10,610 high-quality human peer-ranked photography images accompanied by
extensive multi-tier annotations. The DSD is a foundational computer vision
dataset designed to usher in a new standard for commercial image datasets.
Representing a small fraction of DataSeed.AI's 100 million-plus image catalog,
the DSD provides a scalable foundation necessary for robust commercial and
multimodal AI development. Through this in-depth exploratory analysis, we
document the quantitative improvements generated by the DSD on specific models
against known benchmarks and make the code and the trained models used in our
evaluation publicly available.

</details>


### [48] [Topology-aware Neural Flux Prediction Guided by Physics](https://arxiv.org/abs/2506.05676)
*Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新框架，通过显式差分矩阵和物理约束来提升图神经网络对有向图高频信号的敏感性，有效捕捉拓扑差异。


<details>
  <summary>更多</summary>
  
**动机:** 传统的图神经网络在处理有向图时无法保留节点信号的高频成分，而这些成分对于建模流动动力学至关重要。

**方法:** 结合了1）建模方向梯度的显式差分矩阵和2）强制GNN中的消息传递与自然规律一致的隐式物理约束。

**结果:** 在两个真实世界有向图数据（水通量网络和城市交通流网络）上的评估证明了所提方法的有效性。

**结论:** 本文提出了一种新的框架，使图神经网络能够敏感于节点信号的高频成分，从而捕捉拓扑差异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Topology-aware+Neural+Flux+Prediction+Guided+by+Physics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05676，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05676&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) often struggle in preserving high-frequency
components of nodal signals when dealing with directed graphs. Such components
are crucial for modeling flow dynamics, without which a traditional GNN tends
to treat a graph with forward and reverse topologies equal.To make GNNs
sensitive to those high-frequency components thereby being capable to capture
detailed topological differences, this paper proposes a novel framework that
combines 1) explicit difference matrices that model directional gradients and
2) implicit physical constraints that enforce messages passing within GNNs to
be consistent with natural laws. Evaluations on two real-world directed graph
data, namely, water flux network and urban traffic flow network, demonstrate
the effectiveness of our proposal.

</details>


### [49] [Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions](https://arxiv.org/abs/2506.05678)
*Haotian Jiang, Zeyu Bao, Shida Wang, Qianxiao Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的合成基准测试方法，用于评估序列模型对时间结构的捕捉能力，实验显示其有效性并揭示了新发现。


<details>
  <summary>更多</summary>
  
**动机:** 尽管序列建模架构已经从循环神经网络、卷积模型发展到Transformer和结构化状态空间模型，但系统地表征这些架构的优势和局限性仍然是一个根本挑战。

**方法:** 生成具有记忆函数和时间依赖强度参数的合成目标，以创建一系列具有不同时间复杂度的任务，并对模型行为进行细粒度分析。

**结果:** 实验结果表明该方法能够有效评估模型的记忆能力，确认了现有理论并发现了新的特性。

**结论:** 论文提出了一种合成基准测试框架，用于评估不同序列模型如何有效地捕捉不同的时间结构。实验验证了现有理论见解并揭示了新发现，证明了所提方法在推进理论理解方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Numerical+Investigation+of+Sequence+Modeling+Theory+using+Controllable+Memory+Functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05678，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05678&send_immediately=true&force_search=false)

**原文摘要:** The evolution of sequence modeling architectures, from recurrent neural
networks and convolutional models to Transformers and structured state-space
models, reflects ongoing efforts to address the diverse temporal dependencies
inherent in sequential data. Despite this progress, systematically
characterizing the strengths and limitations of these architectures remains a
fundamental challenge.In this work, we propose a synthetic benchmarking
framework to evaluate how effectively different sequence models capture
distinct temporal structures. The core of this approach is to generate
synthetic targets, each characterized by a memory function and a parameter that
determines the strength of temporal dependence. This setup allows us to produce
a continuum of tasks that vary in temporal complexity, enabling fine-grained
analysis of model behavior concerning specific memory properties. We focus on
four representative memory functions, each corresponding to a distinct class of
temporal structures.Experiments on several sequence modeling architectures
confirm existing theoretical insights and reveal new findings.These results
demonstrate the effectiveness of the proposed method in advancing theoretical
understandingand highlight the importance of using controllable targets with
clearly defined structures for evaluating sequence modeling architectures.

</details>


### [50] [Learning Design-Score Manifold to Guide Diffusion Models for Offline Optimization](https://arxiv.org/abs/2506.05680)
*Tailin Zhou, Zhilin Chen, Wenlong Lyu, Zhitang Chen, Danny H. K. Tsang, Jun Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为ManGO的新方法，用于解决离线优化问题，这种方法能够通过学习设计与得分之间的关系来超越训练数据的限制，并在多个领域中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 优化复杂系统是科学和工程中的一个基本挑战，因为底层规则通常未知且评估成本高昂。离线优化旨在使用预先收集的数据集在没有系统交互的情况下优化设计以获得目标得分，但传统方法可能无法准确预测得分并生成次优设计。

**方法:** 该论文介绍了ManGO，一种基于扩散的方法，通过学习设计-得分流形来统一前向预测和后向生成，采用无导数指导条件生成和自适应推理时间缩放来动态优化去噪路径。

**结果:** ManGO在广泛的评估中表现出色，击败了24种单目标和10种多目标优化方法，在合成任务、机器人控制、材料设计、DNA序列以及现实世界的工程优化等多个领域均取得了良好效果。

**结论:** ManGO是一种扩散框架，可以在各种领域中超越训练数据进行泛化，并优于现有的单目标和多目标优化方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Design-Score+Manifold+to+Guide+Diffusion+Models+for+Offline+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05680，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05680&send_immediately=true&force_search=false)

**原文摘要:** Optimizing complex systems, from discovering therapeutic drugs to designing
high-performance materials, remains a fundamental challenge across science and
engineering, as the underlying rules are often unknown and costly to evaluate.
Offline optimization aims to optimize designs for target scores using
pre-collected datasets without system interaction. However, conventional
approaches may fail beyond training data, predicting inaccurate scores and
generating inferior designs. This paper introduces ManGO, a diffusion-based
framework that learns the design-score manifold, capturing the design-score
interdependencies holistically. Unlike existing methods that treat design and
score spaces in isolation, ManGO unifies forward prediction and backward
generation, attaining generalization beyond training data. Key to this is its
derivative-free guidance for conditional generation, coupled with adaptive
inference-time scaling that dynamically optimizes denoising paths. Extensive
evaluations demonstrate that ManGO outperforms 24 single- and 10
multi-objective optimization methods across diverse domains, including
synthetic tasks, robot control, material design, DNA sequence, and real-world
engineering optimization.

</details>


### [51] [Multi-Modal Multi-Task Federated Foundation Models for Next-Generation Extended Reality Systems: Towards Privacy-Preserving Distributed Intelligence in AR/VR/MR](https://arxiv.org/abs/2506.05683)
*Fardis Nadimi, Payam Abdisarabshali, Kasra Borazjani, Jacob Chakareski, Seyyedali Hosseinalipour*

**主要类别:** cs.LG

**AI概要:** 本文探讨了多模态多任务联邦基础模型（FedFMs）在扩展现实（XR）系统中的应用，旨在通过结合联邦学习的隐私保护和基础模型的表示能力来提供变革性的能力。


<details>
  <summary>更多</summary>
  
**动机:** 为了提升XR系统的个性化、互动性，并解决其在隐私保护方面的挑战，需要一种新的方法，而FedFMs正是满足这一需求的潜在解决方案。

**方法:** 文章提出了一个模块化架构用于FedFMs，该架构包含不同的模型训练和聚合协调范式，并基于SHIFT维度对XR挑战进行了编码。

**结果:** 文章展示了这些维度在XR系统新兴和预期应用中的表现，并提出了评估指标、数据集要求和设计权衡，以开发资源感知的FedFMs。

**结论:** 这种方法旨在为下一代XR系统中情境感知、隐私保护智能的技术和概念基础绘制蓝图。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Modal+Multi-Task+Federated+Foundation+Models+for+Next-Generation+Extended+Reality+Systems%3A+Towards+Privacy-Preserving+Distributed+Intelligence+in+AR%2FVR%2FMR，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05683，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05683&send_immediately=true&force_search=false)

**原文摘要:** Extended reality (XR) systems, which consist of virtual reality (VR),
augmented reality (AR), and mixed reality (XR), offer a transformative
interface for immersive, multi-modal, and embodied human-computer interaction.
In this paper, we envision that multi-modal multi-task (M3T) federated
foundation models (FedFMs) can offer transformative capabilities for XR systems
through integrating the representational strength of M3T foundation models
(FMs) with the privacy-preserving model training principles of federated
learning (FL). We present a modular architecture for FedFMs, which entails
different coordination paradigms for model training and aggregations. Central
to our vision is the codification of XR challenges that affect the
implementation of FedFMs under the SHIFT dimensions: (1) Sensor and modality
diversity, (2) Hardware heterogeneity and system-level constraints, (3)
Interactivity and embodied personalization, (4) Functional/task variability,
and (5) Temporality and environmental variability. We illustrate the
manifestation of these dimensions across a set of emerging and anticipated
applications of XR systems. Finally, we propose evaluation metrics, dataset
requirements, and design tradeoffs necessary for the development of
resource-aware FedFMs in XR. This perspective aims to chart the technical and
conceptual foundations for context-aware privacy-preserving intelligence in the
next generation of XR systems.

</details>


### [52] [Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health](https://arxiv.org/abs/2506.05701)
*Pavel Dolin, Weizhi Li, Gautam Dasarathy, Visar Berisha*

**主要类别:** cs.LG

**AI概要:** 这篇论文认为临床AI部署后的监测尚不完善，建议使用统计上可靠且标签效率高的方法来提升监测质量，并指出了未来的研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 当前临床AI部署后的监测不够完善，仅有9%的FDA注册工具包含监测计划，而现有方法往往是手动、零散且被动的，难以应对动态环境。

**方法:** 论文通过回顾文献、分析现有监测方法的不足，并提出将数据变化检测和模型性能下降作为统计假设检验问题的新方法。

**结果:** 提出了基于统计有效性与标签效率的监测框架，该框架能提供明确的误差率保证并支持可重复性，符合监管要求。

**结论:** 论文得出结论，临床AI的部署后监测应基于统计上有效且标签效率高的测试框架，以确保系统的可靠性，并为技术社区开启新的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Statistically+Valid+Post-Deployment+Monitoring+Should+Be+Standard+for+AI-Based+Digital+Health，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05701，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05701&send_immediately=true&force_search=false)

**原文摘要:** This position paper argues that post-deployment monitoring in clinical AI is
underdeveloped and proposes statistically valid and label-efficient testing
frameworks as a principled foundation for ensuring reliability and safety in
real-world deployment. A recent review found that only 9% of FDA-registered
AI-based healthcare tools include a post-deployment surveillance plan. Existing
monitoring approaches are often manual, sporadic, and reactive, making them
ill-suited for the dynamic environments in which clinical models operate. We
contend that post-deployment monitoring should be grounded in label-efficient
and statistically valid testing frameworks, offering a principled alternative
to current practices. We use the term "statistically valid" to refer to methods
that provide explicit guarantees on error rates (e.g., Type I/II error), enable
formal inference under pre-defined assumptions, and support
reproducibility--features that align with regulatory requirements.
Specifically, we propose that the detection of changes in the data and model
performance degradation should be framed as distinct statistical hypothesis
testing problems. Grounding monitoring in statistical rigor ensures a
reproducible and scientifically sound basis for maintaining the reliability of
clinical AI systems. Importantly, it also opens new research directions for the
technical community--spanning theory, methods, and tools for statistically
principled detection, attribution, and mitigation of post-deployment model
failures in real-world settings.

</details>


### [53] [Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces](https://arxiv.org/abs/2506.05702)
*Chaofan Pan, Jiafen Liu, Yanhua Li, Linbo Xiong, Fan Min, Wei Wei, Xin Yang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个更贴近现实的持续学习问题设定CL-DC，并设计了AACL框架通过动作表示空间解决跨动作空间的策略泛化问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有持续学习方法通常假设代理能力在动态环境中保持不变，这不符合现实场景中能力动态变化的情况。

**方法:** 提出了一种受皮质功能启发的动作自适应持续学习（AACL）框架，并发布了一个基于三个环境的基准测试来验证方法的有效性。

**结果:** 实验结果表明，所提出的AACL框架比流行方法更能有效实现跨动作空间的策略泛化。

**结论:** AACL框架在CL-DC问题上表现出色，能够通过构建动作表示空间解耦代理策略与特定动作空间，实现了跨动作空间的策略泛化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Action-Adaptive+Continual+Learning%3A+Enabling+Policy+Generalization+under+Dynamic+Action+Spaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05702&send_immediately=true&force_search=false)

**原文摘要:** Continual Learning (CL) is a powerful tool that enables agents to learn a
sequence of tasks, accumulating knowledge learned in the past and using it for
problem-solving or future task learning. However, existing CL methods often
assume that the agent's capabilities remain static within dynamic environments,
which doesn't reflect real-world scenarios where capabilities dynamically
change. This paper introduces a new and realistic problem: Continual Learning
with Dynamic Capabilities (CL-DC), posing a significant challenge for CL
agents: How can policy generalization across different action spaces be
achieved? Inspired by the cortical functions, we propose an Action-Adaptive
Continual Learning framework (AACL) to address this challenge. Our framework
decouples the agent's policy from the specific action space by building an
action representation space. For a new action space, the encoder-decoder of
action representations is adaptively fine-tuned to maintain a balance between
stability and plasticity. Furthermore, we release a benchmark based on three
environments to validate the effectiveness of methods for CL-DC. Experimental
results demonstrate that our framework outperforms popular methods by
generalizing the policy across action spaces.

</details>


### [54] [Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application](https://arxiv.org/abs/2506.05710)
*Xiucheng Wang, Honggang Jia, Nan Cheng, Dusit Niyato*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的语义通信框架，利用生成式人工智能和扩散模型，显著提升了在复杂环境下的通信性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统基于神经网络的语义通信方法在低信噪比条件和分布偏移情况下表现不佳，因此需要一种更加鲁棒且兼容大规模预训练模型的解决方案。

**方法:** 该论文提出了一个以扩散模型为基础的潜在扩散模型（LDM）-语义收发器，并通过严格的数学理论（如随机微分方程、闭合形式的信噪比与去噪时间步关系等）支撑其设计。此外，还引入了基于数学原则的缩放机制来解决信号分布不匹配的问题。

**结果:** 实验表明，所提出的框架显著优于传统的基于神经网络的语义通信基线，尤其是在低信噪比条件和分布偏移情况下。

**结论:** 论文提出了一种基于生成式人工智能和扩散模型的新型语义通信框架，为未来6G系统中的鲁棒语义传输提供了一个有前景的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Latent+Diffusion+Model+Based+Denoising+Receiver+for+6G+Semantic+Communication%3A+From+Stochastic+Differential+Theory+to+Application，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05710，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05710&send_immediately=true&force_search=false)

**原文摘要:** In this paper, a novel semantic communication framework empowered by
generative artificial intelligence (GAI) is proposed, specifically leveraging
the capabilities of diffusion models (DMs). A rigorous theoretical foundation
is established based on stochastic differential equations (SDEs), which
elucidates the denoising properties of DMs in mitigating additive white
Gaussian noise (AWGN) in latent semantic representations. Crucially, a
closed-form analytical relationship between the signal-to-noise ratio (SNR) and
the denoising timestep is derived, enabling the optimal selection of diffusion
parameters for any given channel condition. To address the distribution
mismatch between the received signal and the DM's training data, a
mathematically principled scaling mechanism is introduced, ensuring robust
performance across a wide range of SNRs without requiring model fine-tuning.
Built upon this theoretical insight, we develop a latent diffusion model
(LDM)-based semantic transceiver, wherein a variational autoencoder (VAE) is
employed for efficient semantic compression, and a pretrained DM serves as a
universal denoiser. Notably, the proposed architecture is fully training-free
at inference time, offering high modularity and compatibility with large-scale
pretrained LDMs. This design inherently supports zero-shot generalization and
mitigates the challenges posed by out-of-distribution inputs. Extensive
experimental evaluations demonstrate that the proposed framework significantly
outperforms conventional neural-network-based semantic communication baselines,
particularly under low SNR conditions and distributional shifts, thereby
establishing a promising direction for GAI-driven robust semantic transmission
in future 6G systems.

</details>


### [55] [Ensemble Elastic DQN: A novel multi-step ensemble approach to address overestimation in deep value-based reinforcement learning](https://arxiv.org/abs/2506.05716)
*Adrian Ly, Richard Dazeley, Peter Vamplew, Francisco Cruz, Sunil Aryal*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种新算法Ensemble Elastic Step DQN (EEDQN)，它结合了集成和弹性步长更新来解决深度强化学习中的高估偏差和样本效率问题，并在MinAtar基准测试中表现出优越的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管提出了许多Deep Q-Networks (DQN)的算法扩展，但对不同改进之间的相互作用理解仍然有限，特别是多步骤和集成风格的扩展在减少高估偏差、提高样本效率和算法稳定性方面表现出了潜力。

**方法:** 引入了一种名为Ensemble Elastic Step DQN (EEDQN)的新算法，该算法将集成方法与弹性步长更新相结合。

**结果:** EEDQN在所有测试环境中都表现出稳定且强大的性能，在大多数MinAtar环境中的最终回报优于或至少等同于现有的DQN方法和最先进的集成DQNs。

**结论:** EEDQN通过结合集成和弹性步长更新方法，有效解决了深度强化学习中的高估偏差和样本效率问题，并在MinAtar基准测试中表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ensemble+Elastic+DQN%3A+A+novel+multi-step+ensemble+approach+to+address+overestimation+in+deep+value-based+reinforcement+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05716，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05716&send_immediately=true&force_search=false)

**原文摘要:** While many algorithmic extensions to Deep Q-Networks (DQN) have been
proposed, there remains limited understanding of how different improvements
interact. In particular, multi-step and ensemble style extensions have shown
promise in reducing overestimation bias, thereby improving sample efficiency
and algorithmic stability. In this paper, we introduce a novel algorithm called
Ensemble Elastic Step DQN (EEDQN), which unifies ensembles with elastic step
updates to stabilise algorithmic performance. EEDQN is designed to address two
major challenges in deep reinforcement learning: overestimation bias and sample
efficiency. We evaluated EEDQN against standard and ensemble DQN variants
across the MinAtar benchmark, a set of environments that emphasise behavioral
learning while reducing representational complexity. Our results show that
EEDQN achieves consistently robust performance across all tested environments,
outperforming baseline DQN methods and matching or exceeding state-of-the-art
ensemble DQNs in final returns on most of the MinAtar environments. These
findings highlight the potential of systematically combining algorithmic
improvements and provide evidence that ensemble and multi-step methods, when
carefully integrated, can yield substantial gains.

</details>


### [56] [Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation](https://arxiv.org/abs/2506.05713)
*Zhan Zhuang, Xiequn Wang, Wei Li, Yulong Zhang, Qiushi Huang, Shuhao Chen, Xuehao Wang, Yanbin Wei, Yuhe Nie, Kede Ma, Yu Zhang, Ying Wei*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CoTo的渐进式训练策略，以改善低秩适应（LoRA）在参数高效微调大型基础模型时容易陷入次优极小值的问题。


<details>
  <summary>更多</summary>
  
**动机:** LoRA在适应大型基础模型时虽然效率高，但其适配器往往被困在初始化附近的次优解中，影响了模型泛化能力及后续操作如适配器合并和剪枝的效果。

**方法:** 通过一种渐进式训练策略CoTo，在微调过程中逐步增加适配器的激活概率，从而鼓励更平衡的优化和对损失景观的广泛探索；此外，还进行了理论分析并采用合作博弈方法量化每个适配器的边际贡献。

**结果:** 实验表明，CoTo不仅提升了单任务性能，也增强了多任务合并的准确性、提高了剪枝鲁棒性，并减少了训练开销，同时兼容各种LoRA变体。

**结论:** CoTo是一种有效的LoRA改进方法，解决了传统LoRA方法中存在的局限性，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Come+Together%2C+But+Not+Right+Now%3A+A+Progressive+Strategy+to+Boost+Low-Rank+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05713，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05713&send_immediately=true&force_search=false)

**原文摘要:** Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient
fine-tuning technique for adapting large foundation models, yet it often locks
adapters into suboptimal minima near their initialization. This hampers model
generalization and limits downstream operators such as adapter merging and
pruning. Here, we propose CoTo, a progressive training strategy that gradually
increases adapters' activation probability over the course of fine-tuning. By
stochastically deactivating adapters, CoTo encourages more balanced
optimization and broader exploration of the loss landscape. We provide a
theoretical analysis showing that CoTo promotes layer-wise dropout stability
and linear mode connectivity, and we adopt a cooperative-game approach to
quantify each adapter's marginal contribution. Extensive experiments
demonstrate that CoTo consistently boosts single-task performance, enhances
multi-task merging accuracy, improves pruning robustness, and reduces training
overhead, all while remaining compatible with diverse LoRA variants. Code is
available at https://github.com/zwebzone/coto.

</details>


### [57] [Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data](https://arxiv.org/abs/2506.05721)
*Dumindu Tissera, Omar Awadallah, Muhammad Umair Danish, Ayan Sadhu, Katarina Grolinger*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种改进的多标签分类方法，有效解决了训练数据中大量负样本干扰模型学习的问题，并在多个实际数据集上验证了其性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 在多标签分类任务中，当数据集中存在大量未分配类别的负样本时，这些负样本可能会干扰模型的学习过程，导致难以准确识别和分类正样本。此外，为负样本分配单独的类别会增加冗余并使学习目标复杂化。

**方法:** 重新设计标准的多标签分类（MLC）损失函数，通过预测类别概率的归一化加权几何平均值来计算任何类别的存在可能性，并引入正则化参数控制无标签类别对学习过程的贡献。

**结果:** 实验结果显示，新方法在多个大规模数据集（如 SewerML、修改后的 COCO 和 ChestX-ray14）上均优于传统损失函数，在不增加参数或计算复杂度的情况下，F1 分数最高提升 6.01 个百分点，F2 分数提升 8.06 个百分点，平均精度提高 3.11 个百分点。

**结论:** 论文提出了一种新的多标签分类损失函数设计方法，通过实验验证了其在处理具有大量负数据的实际应用中的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Any-Class+Presence+Likelihood+for+Robust+Multi-Label+Classification+with+Abundant+Negative+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05721，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05721&send_immediately=true&force_search=false)

**原文摘要:** Multi-label Classification (MLC) assigns an instance to one or more
non-exclusive classes. A challenge arises when the dataset contains a large
proportion of instances with no assigned class, referred to as negative data,
which can overwhelm the learning process and hinder the accurate identification
and classification of positive instances. Nevertheless, it is common in MLC
applications such as industrial defect detection, agricultural disease
identification, and healthcare diagnosis to encounter large amounts of negative
data. Assigning a separate negative class to these instances further
complicates the learning objective and introduces unnecessary redundancies. To
address this challenge, we redesign standard MLC loss functions by deriving a
likelihood of any class being present, formulated by a normalized weighted
geometric mean of the predicted class probabilities. We introduce a
regularization parameter that controls the relative contribution of the absent
class probabilities to the any-class presence likelihood in positive instances.
The any-class presence likelihood complements the multi-label learning by
encouraging the network to become more aware of implicit positive instances and
improve the label classification within those positive instances. Experiments
on large-scale datasets with negative data: SewerML, modified COCO, and
ChestX-ray14, across various networks and base loss functions show that our
loss functions consistently improve MLC performance of their standard loss
counterparts, achieving gains of up to 6.01 percentage points in F1, 8.06 in
F2, and 3.11 in mean average precision, all without additional parameters or
computational complexity. Code available at:
https://github.com/ML-for-Sensor-Data-Western/gmean-mlc

</details>


### [58] [Generalized Incremental Learning under Concept Drift across Evolving Data Streams](https://arxiv.org/abs/2506.05736)
*En Yu, Jie Lu, Guangquan Zhang*

**主要类别:** cs.LG

**AI概要:** 论文提出了CSFA，用于处理概念漂移下的广义增量学习问题，并通过新机制和算法提高了适应性和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法忽视了在有限监督和持续不确定性下标签空间和分布的关键共演进。

**方法:** 提出了Calibrated Source-Free Adaptation (CSFA) 框架，包含训练无关原型校准机制和RSGS最小化算法。

**结果:** 实验验证了CSFA的优越性能和有效性。

**结论:** CSFA为开放世界流场景中的稳定适应建立了统一的框架，其性能优于现有最先进方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalized+Incremental+Learning+under+Concept+Drift+across+Evolving+Data+Streams，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05736，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05736&send_immediately=true&force_search=false)

**原文摘要:** Real-world data streams exhibit inherent non-stationarity characterized by
concept drift, posing significant challenges for adaptive learning systems.
While existing methods address isolated distribution shifts, they overlook the
critical co-evolution of label spaces and distributions under limited
supervision and persistent uncertainty. To address this, we formalize
Generalized Incremental Learning under Concept Drift (GILCD), characterizing
the joint evolution of distributions and label spaces in open-environment
streaming contexts, and propose a novel framework called Calibrated Source-Free
Adaptation (CSFA). First, CSFA introduces a training-free prototype calibration
mechanism that dynamically fuses emerging prototypes with base representations,
enabling stable new-class identification without optimization overhead. Second,
we design a novel source-free adaptation algorithm, i.e., Reliable Surrogate
Gap Sharpness-aware (RSGS) minimization. It integrates sharpness-aware
perturbation loss optimization with surrogate gap minimization, while employing
entropy-based uncertainty filtering to discard unreliable samples. This
mechanism ensures robust distribution alignment and mitigates generalization
degradation caused by uncertainties. Therefore, CSFA establishes a unified
framework for stable adaptation to evolving semantics and distributions in
open-world streaming scenarios. Extensive experiments validate the superior
performance and effectiveness of CSFA compared to state-of-the-art approaches.

</details>


### [59] [Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance](https://arxiv.org/abs/2506.05748)
*Rudransh Agnihotri, Ananya Pandey*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种高效、低成本的强化学习与人类反馈（RLHF）方法，通过使用一个带有简单评分标准和小型LoRA适配器的7B LLM，成功替代了传统大型奖励模型，并在多个任务上取得了最佳性能。


<details>
  <summary>更多</summary>
  
**动机:** 现代强化学习与人类反馈（RLHF）流程中的奖励模型训练成本高昂，需要数十亿参数和离线偏好调优阶段。

**方法:** 使用一个冻结的7B LLM，并通过一个简单的JSON评分标准和rank-16 LoRA适配器对其进行增强，以替代传统的重型评估模型。同时引入了HH-Rationales数据集用于可解释性研究。

**结果:** 该方法在RewardBench上实现了96.2%的准确率，超过了之前使用的从27B到70B参数的专门奖励网络。利用在线PPO，7B的actor模型在GSM-8K上实现了92%的精确匹配准确率，超越了70B DPO基线模型的61.8%。LoRA评判模型在GPT-4评分中获得了约9/10的与人类解释相似度得分，而零样本评判模型仅获得约5/10。

**结论:** 论文提出的方法结合了提示工程和小型LoRA，产生了一个成本效益高、透明且易于调整的奖励函数，在静态评估和在线RLHF中都达到了新的最先进成果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Online+RFT+with+Plug-and-Play+LLM+Judges%3A+Unlocking+State-of-the-Art+Performance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05748，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05748&send_immediately=true&force_search=false)

**原文摘要:** Reward-model training is the cost bottleneck in modern Reinforcement Learning
Human Feedback (RLHF) pipelines, often requiring tens of billions of parameters
and an offline preference-tuning phase. In the proposed method, a frozen,
instruction-tuned 7B LLM is augmented with only a one line JSON rubric and a
rank-16 LoRA adapter (affecting just 0.8% of the model's parameters), enabling
it to serve as a complete substitute for the previously used heavyweight
evaluation models. The plug-and-play judge achieves 96.2% accuracy on
RewardBench, outperforming specialized reward networks ranging from 27B to 70B
parameters. Additionally, it allows a 7B actor to outperform the top 70B DPO
baseline, which scores 61.8%, by achieving 92% exact match accuracy on GSM-8K
utilizing online PPO. Thorough ablations indicate that (i) six in context
demonstrations deliver the majority of the zero-to-few-shot improvements
(+2pp), and (ii) the LoRA effectively addresses the remaining disparity,
particularly in the safety and adversarial Chat-Hard segments. The proposed
model introduces HH-Rationales, a subset of 10,000 pairs from Anthropic
HH-RLHF, to examine interpretability, accompanied by human generated
justifications. GPT-4 scoring indicates that our LoRA judge attains
approximately = 9/10 in similarity to human explanations, while zero-shot
judges score around =5/10. These results indicate that the combination of
prompt engineering and tiny LoRA produces a cost effective, transparent, and
easily adjustable reward function, removing the offline phase while achieving
new state-of-the-art outcomes for both static evaluation and online RLHF.

</details>


### [60] [Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting](https://arxiv.org/abs/2506.05752)
*Zhongying Wang, Thoai D. Ngo, Hamidreza Zoraghein, Benjamin Lucas, Morteza Karimzadeh*

**主要类别:** cs.LG

**AI概要:** 本文提出一种基于LSTM并结合SPH特征的住院率预测模型，显著提高了疫情变种爆发期间的预测准确性。


<details>
  <summary>更多</summary>
  
**动机:** 新冠疫情对医疗系统造成了严重冲击，突显了准确及时预测住院需求的重要性，尤其是在变种病毒爆发期间。

**方法:** 提出了一种新颖的长短期记忆（LSTM）框架，并引入了一个时空特征——住院社交接近度（SPH），通过Facebook的社交连接指数来改进预测。

**结果:** 在Delta和Omicron变种爆发期间评估显示，该模型优于现有集合模型，在预测第7、14、21和28天时平均每个州分别高出27、42、54和69例住院病例。

**结论:** 该研究不仅推进了住院率预测，还强调了时空特征（如SPH）在改进传染病传播复杂动态建模中的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Integrating+Spatiotemporal+Features+in+LSTM+for+Spatially+Informed+COVID-19+Hospitalization+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05752，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05752&send_immediately=true&force_search=false)

**原文摘要:** The COVID-19 pandemic's severe impact highlighted the need for accurate,
timely hospitalization forecasting to support effective healthcare planning.
However, most forecasting models struggled, especially during variant surges,
when they were needed most. This study introduces a novel Long Short-Term
Memory (LSTM) framework for forecasting daily state-level incident
hospitalizations in the United States. We present a spatiotemporal feature,
Social Proximity to Hospitalizations (SPH), derived from Facebook's Social
Connectedness Index to improve forecasts. SPH serves as a proxy for interstate
population interaction, capturing transmission dynamics across space and time.
Our parallel LSTM architecture captures both short- and long-term temporal
dependencies, and our multi-horizon ensembling strategy balances consistency
and forecasting error. Evaluation against COVID-19 Forecast Hub ensemble models
during the Delta and Omicron surges reveals superiority of our model. On
average, our model surpasses the ensemble by 27, 42, 54, and 69
hospitalizations per state on the $7^{th}$, $14^{th}$, $21^{st}$, and $28^{th}$
forecast days, respectively, during the Omicron surge. Data-ablation
experiments confirm SPH's predictive power, highlighting its effectiveness in
enhancing forecasting models. This research not only advances hospitalization
forecasting but also underscores the significance of spatiotemporal features,
such as SPH, in refining predictive performance in modeling the complex
dynamics of infectious disease spread.

</details>


### [61] [FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts](https://arxiv.org/abs/2506.05755)
*Yang Li, Zhi Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的最优执行框架flowOE，利用流动匹配模型和模仿学习，在动态金融市场中实现了比传统方法更好的执行效果。


<details>
  <summary>更多</summary>
  
**动机:** 传统的最优执行策略（如静态Almgren-Chriss模型）在动态市场中表现不佳，需要一种更灵活、适应性强的方法。

**方法:** flowOE是一种基于流动匹配模型的模仿学习框架，通过专家策略进行训练，并引入了改进损失函数以优化学习效果。

**结果:** 实证评估表明，flowOE显著优于传统基准模型和专门校准的专家模型。

**结论:** flowOE框架在动态金融市场中的最优执行问题上表现出色，相较于传统模型具有更高的盈利能力和更低的风险。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FlowOE%3A+Imitation+Learning+with+Flow+Policy+from+Ensemble+RL+Experts+for+Optimal+Execution+under+Heston+Volatility+and+Concave+Market+Impacts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05755，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05755&send_immediately=true&force_search=false)

**原文摘要:** Optimal execution in financial markets refers to the process of strategically
transacting a large volume of assets over a period to achieve the best possible
outcome by balancing the trade-off between market impact costs and timing or
volatility risks. Traditional optimal execution strategies, such as static
Almgren-Chriss models, often prove suboptimal in dynamic financial markets.
This paper propose flowOE, a novel imitation learning framework based on flow
matching models, to address these limitations. FlowOE learns from a diverse set
of expert traditional strategies and adaptively selects the most suitable
expert behavior for prevailing market conditions. A key innovation is the
incorporation of a refining loss function during the imitation process,
enabling flowOE not only to mimic but also to improve upon the learned expert
actions. To the best of our knowledge, this work is the first to apply flow
matching models in a stochastic optimal execution problem. Empirical
evaluations across various market conditions demonstrate that flowOE
significantly outperforms both the specifically calibrated expert models and
other traditional benchmarks, achieving higher profits with reduced risk. These
results underscore the practical applicability and potential of flowOE to
enhance adaptive optimal execution.

</details>


### [62] [Positional Encoding meets Persistent Homology on Graphs](https://arxiv.org/abs/2506.05814)
*Yogesh Verma, Amauri H. Souza, Vikas Garg*

**主要类别:** cs.LG

**AI概要:** 该研究分析了位置编码和持久同源方法在图神经网络中的优劣，提出了新的更具有表现力的方法PiPE，并验证了其在多个任务中的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 需要解决消息传递图神经网络利用结构信息的局限性，并比较位置编码和持久同源方法的优劣。

**方法:** 通过建立新的可学习方法PiPE（Persistence-informed Positional Encoding），结合位置编码和持久同源方法的优点。

**结果:** 既没有一种范式比另一种更有表现力，提出的新方法PiPE在多个任务上取得了良好的性能。

**结论:** PiPE是一种比PH和PE更具表现力的新方法，并在各种任务中表现出色，推进了图表示学习的前沿。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Positional+Encoding+meets+Persistent+Homology+on+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05814，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05814&send_immediately=true&force_search=false)

**原文摘要:** The local inductive bias of message-passing graph neural networks (GNNs)
hampers their ability to exploit key structural information (e.g., connectivity
and cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged
as two promising approaches to mitigate this issue. PE schemes endow GNNs with
location-aware features, while PH methods enhance GNNs with multiresolution
topological features. However, a rigorous theoretical characterization of the
relative merits and shortcomings of PE and PH has remained elusive. We bridge
this gap by establishing that neither paradigm is more expressive than the
other, providing novel constructions where one approach fails but the other
succeeds. Our insights inform the design of a novel learnable method, PiPE
(Persistence-informed Positional Encoding), which is provably more expressive
than both PH and PE. PiPE demonstrates strong performance across a variety of
tasks (e.g., molecule property prediction, graph classification, and
out-of-distribution generalization), thereby advancing the frontiers of graph
representation learning. Code is available at
https://github.com/Aalto-QuML/PIPE.

</details>


### [63] [Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling](https://arxiv.org/abs/2506.05831)
*Yihan Xie, Sijing Li, Tianwei Lin, Zhuonan Wang, Chenglin Yang, Yu Zhong, Wenqiao Zhang, Haoyuan Li, Hao Jiang, Fengda Zhang, Qishan Chen, Jun Xiao, Yueting Zhuang, Beng Chin Ooi*

**主要类别:** cs.LG

**AI概要:** 论文提出Heartcare Suite，包括数据集、基准测试和生成模型，以提升心电图的多模态理解和分析能力。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高心电图（ECG）的精细理解并促进医学多模态大语言模型的发展，需要高质量的数据集、系统的评估基准以及高效的模型设计。

**方法:** 提出了一个包含数据集、基准测试和特定于ECG的生成式预训练模型的框架。

**结果:** 构建了高质量的心电图多模态数据集Heartcare-220K，系统基准Heartcare-Bench，以及基于定制标记器的模型HeartcareGPT，并展示了其在多项临床任务中的卓越表现。

**结论:** Heartcare Suite是一个推进心电图多模态理解和评估的综合框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Heartcare+Suite%3A+Multi-dimensional+Understanding+of+ECG+with+Raw+Multi-lead+Signal+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05831，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05831&send_immediately=true&force_search=false)

**原文摘要:** We present Heartcare Suite, a multimodal comprehensive framework for
finegrained electrocardiogram (ECG) understanding. It comprises three key
components: (i) Heartcare-220K, a high-quality, structured, and comprehensive
multimodal ECG dataset covering essential tasks such as disease diagnosis,
waveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench,
a systematic and multi-dimensional benchmark designed to evaluate diagnostic
intelligence and guide the optimization of Medical Multimodal Large Language
Models (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored
tokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw
multi-lead signals into semantically rich discrete tokens via duallevel vector
quantization and query-guided bidirectional diffusion mechanism. Built upon
Heartcare-220K, HeartcareGPT achieves strong generalization and SoTA
performance across multiple clinically meaningful tasks. Extensive experiments
demonstrate that Heartcare Suite is highly effective in advancing ECGspecific
multimodal understanding and evaluation. Our project is available at
https://github.com/Wznnnnn/Heartcare-Suite .

</details>


### [64] [BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning](https://arxiv.org/abs/2506.05762)
*Yunpeng Qing, Shuo Chen, Yixiao Chi, Shunyu Liu, Sixu Lin, Changqing Zou*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种用于离线强化学习的新数据增强框架BiTrajDiff，通过同时建模前向和后向轨迹，有效提升数据集的多样性并改善学习效果。


<details>
  <summary>更多</summary>
  
**动机:** 静态数据集通常表现出分布偏差，导致泛化能力有限。尽管现有的数据增强技术取得了一些成果，但它们主要关注于从给定状态重建未来轨迹，而忽略了达到这些状态的历史转换的探索，这限制了行为模式的多样性发现。

**方法:** 引入了一种新的数据增强框架BiTrajDiff，该框架从任何中间状态建模未来和历史轨迹，将轨迹生成任务分解为两个独立但互补的扩散过程：一个生成前向轨迹以预测未来动态，另一个生成后向轨迹以追踪重要的历史转换。

**结果:** 实验结果表明，BiTrajDiff在D4RL基准套件上的表现优于其他先进的DA方法。

**结论:** BiTrajDiff在各种离线RL骨干网络中相较于其他先进的DA方法表现出优越的性能，通过双向轨迹扩散模型有效利用关键状态来扩展状态空间中可能有价值的但未被充分探索的区域，从而提高数据集的多样性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BiTrajDiff%3A+Bidirectional+Trajectory+Generation+with+Diffusion+Models+for+Offline+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05762，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05762&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in offline Reinforcement Learning (RL) have proven that
effective policy learning can benefit from imposing conservative constraints on
pre-collected datasets. However, such static datasets often exhibit
distribution bias, resulting in limited generalizability. To address this
limitation, a straightforward solution is data augmentation (DA), which
leverages generative models to enrich data distribution. Despite the promising
results, current DA techniques focus solely on reconstructing future
trajectories from given states, while ignoring the exploration of history
transitions that reach them. This single-direction paradigm inevitably hinders
the discovery of diverse behavior patterns, especially those leading to
critical states that may have yielded high-reward outcomes. In this work, we
introduce Bidirectional Trajectory Diffusion (BiTrajDiff), a novel DA framework
for offline RL that models both future and history trajectories from any
intermediate states. Specifically, we decompose the trajectory generation task
into two independent yet complementary diffusion processes: one generating
forward trajectories to predict future dynamics, and the other generating
backward trajectories to trace essential history transitions.BiTrajDiff can
efficiently leverage critical states as anchors to expand into potentially
valuable yet underexplored regions of the state space, thereby facilitating
dataset diversity. Extensive experiments on the D4RL benchmark suite
demonstrate that BiTrajDiff achieves superior performance compared to other
advanced DA methods across various offline RL backbones.

</details>


### [65] [Loss Functions for Predictor-based Neural Architecture Search](https://arxiv.org/abs/2506.05869)
*Han Ji, Yuqi Feng, Jiahao Fan, Yanan Sun*

**主要类别:** cs.LG

**AI概要:** 本文研究了性能预测器中的损失函数，发现不同类型的损失函数可以结合使用来提高NAS的效果。


<details>
  <summary>更多</summary>
  
**动机:** 性能预测器在减少神经架构搜索（NAS）评估成本中起关键作用，而其效果受损失函数的选择影响。传统方法使用回归损失函数，而近期探索了排序型损失函数。然而，这些损失函数的有效性和特性尚未被彻底调查。

**方法:** 对13个任务中的8种损失函数进行了全面研究，使用了一系列与NAS相关的指标。

**结果:** 该研究将损失函数分为三类：回归、排序和加权损失函数，并发现它们可以有效地组合使用。

**结论:** 论文得出结论，特定类别的损失函数可以有效结合以增强基于预测器的NAS，并为选择适合不同任务的损失函数提供了实用指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Loss+Functions+for+Predictor-based+Neural+Architecture+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05869，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05869&send_immediately=true&force_search=false)

**原文摘要:** Evaluation is a critical but costly procedure in neural architecture search
(NAS). Performance predictors have been widely adopted to reduce evaluation
costs by directly estimating architecture performance. The effectiveness of
predictors is heavily influenced by the choice of loss functions. While
traditional predictors employ regression loss functions to evaluate the
absolute accuracy of architectures, recent approaches have explored various
ranking-based loss functions, such as pairwise and listwise ranking losses, to
focus on the ranking of architecture performance. Despite their success in NAS,
the effectiveness and characteristics of these loss functions have not been
thoroughly investigated. In this paper, we conduct the first comprehensive
study on loss functions in performance predictors, categorizing them into three
main types: regression, ranking, and weighted loss functions. Specifically, we
assess eight loss functions using a range of NAS-relevant metrics on 13 tasks
across five search spaces. Our results reveal that specific categories of loss
functions can be effectively combined to enhance predictor-based NAS.
Furthermore, our findings could provide practical guidance for selecting
appropriate loss functions for various tasks. We hope this work provides
meaningful insights to guide the development of loss functions for
predictor-based methods in the NAS community.

</details>


### [66] [Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer](https://arxiv.org/abs/2506.05764)
*Haochuan, Wang*

**主要类别:** cs.LG

**AI概要:** 该论文分析了加密货币价格动态，并发现经过适当的数据预处理和超参数调优后，简单的机器学习模型可以达到与复杂神经网络相当甚至更好的预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 论文旨在探讨增加额外隐藏层或参数是否真正提高了短期价格预测能力，还是收益主要归因于数据预处理和特征工程。

**方法:** 研究通过引入两种数据过滤管道（Kalman、Savitzky Golay）并评估二元和三元标记方案，在BTC/USDT的LOB快照上对一系列模型进行了基准测试，包括逻辑回归、XGBoost到深度架构（DeepLOB、Conv1D+LSTM）。

**结果:** 结果表明，通过数据预处理和超参数调优，简单模型在样本外准确性、延迟和抗噪性方面可以匹配甚至超越复杂网络的表现。

**结论:** 论文的结论是，通过数据预处理和超参数调优，简单的模型可以匹配甚至超过更复杂网络的表现，并提供更快的推理速度和更大的可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Microstructural+Dynamics+in+Cryptocurrency+Limit+Order+Books%3A+Better+Inputs+Matter+More+Than+Stacking+Another+Hidden+Layer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05764，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05764&send_immediately=true&force_search=false)

**原文摘要:** Cryptocurrency price dynamics are driven largely by microstructural supply
demand imbalances in the limit order book (LOB), yet the highly noisy nature of
LOB data complicates the signal extraction process. Prior research has
demonstrated that deep-learning architectures can yield promising predictive
performance on pre-processed equity and futures LOB data, but they often treat
model complexity as an unqualified virtue. In this paper, we aim to examine
whether adding extra hidden layers or parameters to "blackbox ish" neural
networks genuinely enhances short term price forecasting, or if gains are
primarily attributable to data preprocessing and feature engineering. We
benchmark a spectrum of models from interpretable baselines, logistic
regression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT
LOB snapshots sampled at 100 ms to multi second intervals using publicly
available Bybit data. We introduce two data filtering pipelines (Kalman,
Savitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down)
labeling schemes. Our analysis compares models on out of sample accuracy,
latency, and robustness to noise. Results reveal that, with data preprocessing
and hyperparameter tuning, simpler models can match and even exceed the
performance of more complex networks, offering faster inference and greater
interpretability.

</details>


### [67] [Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution](https://arxiv.org/abs/2506.05937)
*Charmaine Barker, Daniel Bethell, Simos Gerasimou*

**主要类别:** cs.LG

**AI概要:** 本文提出了Conflict-aware Evidential Deep Learning (C-EDL)，一种用于增强深度学习模型不确定量化的方法，特别针对对抗性和分布外输入的鲁棒性改进。


<details>
  <summary>更多</summary>
  
**动机:** 深度学习模型的可靠性对于在高风险应用场景中的部署至关重要，因为分布外或对抗性输入可能导致不良后果。Evidential Deep Learning (EDL) 虽然是一种有效的不确定性量化范式，但其容易受到对抗性扰动输入的影响，导致过度自信错误。

**方法:** Conflict-aware Evidential Deep Learning (C-EDL) 是一种轻量级的后处理不确定性量化方法，通过生成多样化且保持任务的输入转换，并量化表征分歧来校准所需的不确定性估计。

**结果:** 实验评估表明，C-EDL在检测OOD和对抗输入方面表现优异，同时保持了较高的分布内准确性和低计算开销。

**结论:** C-EDL方法显著优于现有的EDL变体和其他竞争基线，在各种数据集、攻击类型和不确定性度量中实现了对OOD数据（最高55%）和对抗数据（最高90%）的显著覆盖减少。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantifying+Adversarial+Uncertainty+in+Evidential+Deep+Learning+using+Conflict+Resolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05937&send_immediately=true&force_search=false)

**原文摘要:** Reliability of deep learning models is critical for deployment in high-stakes
applications, where out-of-distribution or adversarial inputs may lead to
detrimental outcomes. Evidential Deep Learning, an efficient paradigm for
uncertainty quantification, models predictions as Dirichlet distributions of a
single forward pass. However, EDL is particularly vulnerable to adversarially
perturbed inputs, making overconfident errors. Conflict-aware Evidential Deep
Learning (C-EDL) is a lightweight post-hoc uncertainty quantification approach
that mitigates these issues, enhancing adversarial and OOD robustness without
retraining. C-EDL generates diverse, task-preserving transformations per input
and quantifies representational disagreement to calibrate uncertainty estimates
when needed. C-EDL's conflict-aware prediction adjustment improves detection of
OOD and adversarial inputs, maintaining high in-distribution accuracy and low
computational overhead. Our experimental evaluation shows that C-EDL
significantly outperforms state-of-the-art EDL variants and competitive
baselines, achieving substantial reductions in coverage for OOD data (up to
55%) and adversarial data (up to 90%), across a range of datasets, attack
types, and uncertainty metrics.

</details>


### [68] [AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation](https://arxiv.org/abs/2506.05768)
*Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种用于虚拟筛选的新框架，可在不确定蛋白质结构的情况下提高药物发现的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有虚拟筛选方法主要针对已知配体结合口袋的全蛋白结构，其在缺乏口袋信息的 apo 或预测结构上的表现显著下降，因此需要一种新方法应对这一问题。

**方法:** 本文的方法包括一个三模态对比学习模块和一个基于交叉注意力的适配器，以对齐配体、全蛋白口袋和结构中检测到的空腔的表示，并动态聚合候选结合位点。

**结果:** 该方法在 apo 结构的新基准测试中表现出色，在盲 apo 设置下显著优于最先进的方法，早期富集因子（EF1%）从 11.75 提高到 37.19，并且在全蛋白结构上也保持良好性能。

**结论:** 本文提出了一种新的虚拟筛选方法，能够在结构不确定性的情况下实现准确的药物发现，为缺乏实验解析蛋白质-配体复合物的情况提供了有前景的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AANet%3A+Virtual+Screening+under+Structural+Uncertainty+via+Alignment+and+Aggregation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05768，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05768&send_immediately=true&force_search=false)

**原文摘要:** Virtual screening (VS) is a critical component of modern drug discovery, yet
most existing methods--whether physics-based or deep learning-based--are
developed around holo protein structures with known ligand-bound pockets.
Consequently, their performance degrades significantly on apo or predicted
structures such as those from AlphaFold2, which are more representative of
real-world early-stage drug discovery, where pocket information is often
missing. In this paper, we introduce an alignment-and-aggregation framework to
enable accurate virtual screening under structural uncertainty. Our method
comprises two core components: (1) a tri-modal contrastive learning module that
aligns representations of the ligand, the holo pocket, and cavities detected
from structures, thereby enhancing robustness to pocket localization error; and
(2) a cross-attention based adapter for dynamically aggregating candidate
binding sites, enabling the model to learn from activity data even without
precise pocket annotations. We evaluated our method on a newly curated
benchmark of apo structures, where it significantly outperforms
state-of-the-art methods in blind apo setting, improving the early enrichment
factor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong
performance on holo structures. These results demonstrate the promise of our
approach in advancing first-in-class drug discovery, particularly in scenarios
lacking experimentally resolved protein-ligand complexes.

</details>


### [69] [Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting](https://arxiv.org/abs/2506.05941)
*Luka Hobor, Mario Brcic, Lidija Polutnik, Ante Kapetanovic*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了砖瓦零售商的销售预测问题，并比较了几种不同的预测模型的效果。


<details>
  <summary>更多</summary>
  
**动机:** 准确的销售预测对于所有业务规划都至关重要。过高或过低估计销售都会给零售商带来成本增加或销售损失的问题。因此，寻找提高预测准确性的方法成为公司获取竞争优势的关键。

**方法:** 研究中比较了基于树的集成（如XGBoost和LightGBM）和最先进的神经网络架构（包括N-BEATS、NHITS和时间融合变压器）在各种实验设置中的表现。

**结果:** 研究结果显示，局部建模策略，特别是使用非插补数据的基于树的模型在个体群体上，始终如一地提供了卓越的预测准确性与计算效率。而神经网络模型尽管受益于先进的插补方法，但在处理实体零售数据的不规则性方面仍存在不足。

**结论:** 论文的结论是，局部建模策略，尤其是使用非插补数据的基于树的模型，在个体群体上始终如一地提供卓越的预测准确性和计算效率。神经网络模型虽然受益于先进的插补方法，但在处理实体零售数据的不规则性方面仍然不足。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+Analysis+of+Modern+Machine+Learning+Models+for+Retail+Sales+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05941，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05941&send_immediately=true&force_search=false)

**原文摘要:** Accurate forecasting is key for all business planning. When estimated sales
are too high, brick-and-mortar retailers may incur higher costs due to unsold
inventories, higher labor and storage space costs, etc. On the other hand, when
forecasts underestimate the level of sales, firms experience lost sales,
shortages, and impact on the reputation of the retailer in their relevant
market. Accurate forecasting presents a competitive advantage for companies. It
facilitates the achievement of revenue and profit goals and execution of
pricing strategy and tactics. In this study, we provide an exhaustive
assessment of the forecasting models applied to a high-resolution
brick-and-mortar retail dataset. Our forecasting framework addresses the
problems found in retail environments, including intermittent demand, missing
values, and frequent product turnover. We compare tree-based ensembles (such as
XGBoost and LightGBM) and state-of-the-art neural network architectures
(including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various
experimental settings. Our results show that localized modeling strategies
especially those using tree-based models on individual groups with non-imputed
data, consistently deliver superior forecasting accuracy and computational
efficiency. In contrast, neural models benefit from advanced imputation
methods, yet still fall short in handling the irregularities typical of
physical retail data. These results further practical understanding for model
selection in retail environment and highlight the significance of data
preprocessing to improve forecast performance.

</details>


### [70] [Evaluating Neuron Explanations: A Unified Framework with Sanity Checks](https://arxiv.org/abs/2506.05774)
*Tuomas Oikarinen, Ge Yan, Tsui-Wei Weng*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了神经网络中解释评估方法的问题，提出了一种新的数学框架和两个简单测试，发现了一些不可靠的评估指标并给出改进指南。


<details>
  <summary>更多</summary>
  
**动机:** 理解神经网络中单个单元的功能对于机械可解释性至关重要，但必须了解这些解释的可靠性和真实性。

**方法:** 作者将现有的解释评估方法统一在一个数学框架下，并提出了两个简单的合理性检查。

**结果:** 许多常用的评估指标未能通过作者提出的合理性检查，并且在概念标签发生重大变化后评分没有改变。

**结论:** 作者提出了未来评估应遵循的指导方针，并确定了一组可靠的评估指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluating+Neuron+Explanations%3A+A+Unified+Framework+with+Sanity+Checks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05774，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05774&send_immediately=true&force_search=false)

**原文摘要:** Understanding the function of individual units in a neural network is an
important building block for mechanistic interpretability. This is often done
by generating a simple text explanation of the behavior of individual neurons
or units. For these explanations to be useful, we must understand how reliable
and truthful they are. In this work we unify many existing explanation
evaluation methods under one mathematical framework. This allows us to compare
existing evaluation metrics, understand the evaluation pipeline with increased
clarity and apply existing statistical methods on the evaluation. In addition,
we propose two simple sanity checks on the evaluation metrics and show that
many commonly used metrics fail these tests and do not change their score after
massive changes to the concept labels. Based on our experimental and
theoretical results, we propose guidelines that future evaluations should
follow and identify a set of reliable evaluation metrics.

</details>


### [71] [Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning](https://arxiv.org/abs/2506.05968)
*Motoki Omura, Kazuki Ota, Takayuki Osa, Yusuke Mukuta, Tatsuya Harada*

**主要类别:** cs.LG

**AI概要:** 本研究探讨了在连续动作空间的强化学习中引入Bellman最优算子的效果，并提出了一种退火方法来平衡学习速度与偏差，最终在多个任务上取得了优越的性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统的连续动作空间RL算法通常使用Bellman算子建模Q值，并依赖策略更新进行改进，导致样本效率低下。因此，研究如何有效利用Bellman最优算子来提高学习效率具有重要意义。

**方法:** 提出了一种退火方法，该方法逐步从Bellman最优算子过渡到Bellman算子，以在加速学习的同时减少偏差。并在多个运动和操作任务上结合TD3和SAC算法进行了实验验证。

**结果:** 实验表明，在简单环境中建模最优值可以加速学习，但也带来了高估偏差。而提出的退火方法成功缓解了这一问题，并在多种任务中实现了比现有方法更好的性能。

**结论:** 将Bellman最优算子引入到连续动作空间的actor-critic框架中可以加速学习，但会导致高估偏差。通过退火方法逐步从Bellman最优算子过渡到Bellman算子，结合TD3和SAC算法，显著优于现有方法，提高了性能和对超参数的鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gradual+Transition+from+Bellman+Optimality+Operator+to+Bellman+Operator+in+Online+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05968，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05968&send_immediately=true&force_search=false)

**原文摘要:** For continuous action spaces, actor-critic methods are widely used in online
reinforcement learning (RL). However, unlike RL algorithms for discrete
actions, which generally model the optimal value function using the Bellman
optimality operator, RL algorithms for continuous actions typically model
Q-values for the current policy using the Bellman operator. These algorithms
for continuous actions rely exclusively on policy updates for improvement,
which often results in low sample efficiency. This study examines the
effectiveness of incorporating the Bellman optimality operator into
actor-critic frameworks. Experiments in a simple environment show that modeling
optimal values accelerates learning but leads to overestimation bias. To
address this, we propose an annealing approach that gradually transitions from
the Bellman optimality operator to the Bellman operator, thereby accelerating
learning while mitigating bias. Our method, combined with TD3 and SAC,
significantly outperforms existing approaches across various locomotion and
manipulation tasks, demonstrating improved performance and robustness to
hyperparameters related to optimality.

</details>


### [72] [Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization](https://arxiv.org/abs/2506.05791)
*Yuki Takezawa, Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的去中心化优化方法 SPDO，在减少通信轮次的同时降低了计算开销，并在实验中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的 PDO 方法需要对与近端算子相关的子问题求解非常精确，导致了显著的计算开销，因此需要更高效的方法。

**方法:** 提出了稳定化 proximal decentralized optimization (SPDO) 方法，通过放松子问题精度要求和利用平均函数相似性来改进现有 PDO 方法。

**结果:** SPDO 方法在通信和计算复杂性方面均表现优异，并且实验结果显示其明显优于现有方法。

**结论:** SPDO方法在PDO框架内实现了最先进的通信和计算复杂性，并通过实验结果证明了其显著优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploiting+Similarity+for+Computation+and+Communication-Efficient+Decentralized+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05791&send_immediately=true&force_search=false)

**原文摘要:** Reducing communication complexity is critical for efficient decentralized
optimization. The proximal decentralized optimization (PDO) framework is
particularly appealing, as methods within this framework can exploit functional
similarity among nodes to reduce communication rounds. Specifically, when local
functions at different nodes are similar, these methods achieve faster
convergence with fewer communication steps. However, existing PDO methods often
require highly accurate solutions to subproblems associated with the proximal
operator, resulting in significant computational overhead. In this work, we
propose the Stabilized Proximal Decentralized Optimization (SPDO) method, which
achieves state-of-the-art communication and computational complexities within
the PDO framework. Additionally, we refine the analysis of existing PDO methods
by relaxing subproblem accuracy requirements and leveraging average functional
similarity. Experimental results demonstrate that SPDO significantly
outperforms existing methods.

</details>


### [73] [On Measuring Long-Range Interactions in Graph Neural Networks](https://arxiv.org/abs/2506.05971)
*Jacob Bamberger, Benjamin Gutteridge, Scott le Roux, Michael M. Bronstein, Xiaowen Dong*

**主要类别:** cs.LG

**AI概要:** 本文针对图神经网络中的长程图任务问题，提出了一种基于图上算子范围度量的新方法，并通过合成实验验证其有效性，旨在改进对长程问题的定义和解决方式。


<details>
  <summary>更多</summary>
  
**动机:** 论文的动机源于对图神经网络研究中长程图任务（依赖于远距离节点之间相互作用的任务）缺乏稳健性和理论基础的实证方法。因此，需要一个更为系统的原则来刻画长程问题。

**方法:** 论文的方法包括对图任务中的长程交互进行形式化定义，提出一种用于图上算子的范围度量，并通过合成实验来验证这种度量的有效性。此外，他们还利用提出的度量方法来分析常用任务和架构的长程特性。

**结果:** 论文的结果是对长程图任务进行了形式化定义，提出了一个可靠的范围度量方法，并通过合成实验验证了其有效性。同时，作者利用该度量方法评估了常见任务和架构的长程特性。

**结论:** 论文得出的结论是，作者通过引入图上算子的范围度量，并利用合成实验对其进行验证，为图上的长程问题提供了更原则性的描述，同时他们的范围度量有助于评估新的数据集和架构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Measuring+Long-Range+Interactions+in+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05971，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05971&send_immediately=true&force_search=false)

**原文摘要:** Long-range graph tasks -- those dependent on interactions between distant
nodes -- are an open problem in graph neural network research. Real-world
benchmark tasks, especially the Long Range Graph Benchmark, have become popular
for validating the long-range capability of proposed architectures. However,
this is an empirical approach that lacks both robustness and theoretical
underpinning; a more principled characterization of the long-range problem is
required. To bridge this gap, we formalize long-range interactions in graph
tasks, introduce a range measure for operators on graphs, and validate it with
synthetic experiments. We then leverage our measure to examine commonly used
tasks and architectures, and discuss to what extent they are, in fact,
long-range. We believe our work advances efforts to define and address the
long-range problem on graphs, and that our range measure will aid evaluation of
new datasets and architectures.

</details>


### [74] [EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator](https://arxiv.org/abs/2506.05797)
*Qianyi Chen, Tianrun Gao, Chenbo Jiang, Tailin Wu*

**主要类别:** cs.LG

**AI概要:** EqCollide是一种新的端到端等变神经场模拟器，用于变形物体及其碰撞的模拟，具有较高的准确性、稳定性及可扩展性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数据驱动方法在物理对称性、碰撞处理和可扩展性方面存在不足，因此需要一个更有效的方法来模拟变形物体的碰撞。

**方法:** EqCollide使用了一个等变编码器来将物体几何形状和速度映射到潜在控制点，随后通过基于图神经网络的等变神经常微分方程对控制点之间的相互作用进行建模，并利用条件神经场重构速度场。

**结果:** EqCollide在滚动预测MSE上比表现最好的基线模型低24.34%至35.82%，并且能够推广到更多的碰撞物体和扩展的时间范围，同时对输入变换保持稳健性。

**结论:** EqCollide是一个准确、稳定且可扩展的变形物体及其碰撞模拟器，能够在不同物体配置中实现连续和与分辨率无关的运动预测，并在多个方面优于现有模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EqCollide%3A+Equivariant+and+Collision-Aware+Deformable+Objects+Neural+Simulator，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05797，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05797&send_immediately=true&force_search=false)

**原文摘要:** Simulating collisions of deformable objects is a fundamental yet challenging
task due to the complexity of modeling solid mechanics and multi-body
interactions. Existing data-driven methods often suffer from lack of
equivariance to physical symmetries, inadequate handling of collisions, and
limited scalability. Here we introduce EqCollide, the first end-to-end
equivariant neural fields simulator for deformable objects and their
collisions. We propose an equivariant encoder to map object geometry and
velocity into latent control points. A subsequent equivariant Graph Neural
Network-based Neural Ordinary Differential Equation models the interactions
among control points via collision-aware message passing. To reconstruct
velocity fields, we query a neural field conditioned on control point features,
enabling continuous and resolution-independent motion predictions. Experimental
results show that EqCollide achieves accurate, stable, and scalable simulations
across diverse object configurations, and our model achieves 24.34% to 35.82%
lower rollout MSE even compared with the best-performing baseline model.
Furthermore, our model could generalize to more colliding objects and extended
temporal horizons, and stay robust to input transformed with group action.

</details>


### [75] [AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification](https://arxiv.org/abs/2506.05980)
*Geonwoo Cho, Jaemoon Lee, Jaegyun Im, Subi Lee, Jihwan Lee, Sundong Kim*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为AMPED的新方法，通过梯度手术和动态技能选择技术，成功解决了技能学习中的探索与多样性平衡问题。


<details>
  <summary>更多</summary>
  
**动机:** 基于技能的强化学习需要同时最大化探索和技能多样性，但现有方法难以有效平衡这两个冲突目标。

**方法:** 提出了自适应多目标投影（AMPED）方法，并结合梯度手术技术和技能选择模块来优化探索和技能多样性。

**结果:** AMPED在多个基准测试中表现优异，突出了探索与多样性协调的重要性。

**结论:** AMPED方法在平衡探索与技能多样性方面表现出色，优于现有的SBRL基线方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AMPED%3A+Adaptive+Multi-objective+Projection+for+balancing+Exploration+and+skill+Diversification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05980，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05980&send_immediately=true&force_search=false)

**原文摘要:** Skill-based reinforcement learning (SBRL) enables rapid adaptation in
environments with sparse rewards by pretraining a skill-conditioned policy.
Effective skill learning requires jointly maximizing both exploration and skill
diversity. However, existing methods often face challenges in simultaneously
optimizing for these two conflicting objectives. In this work, we propose a new
method, Adaptive Multi-objective Projection for balancing Exploration and skill
Diversification (AMPED), which explicitly addresses both exploration and skill
diversification. We begin by conducting extensive ablation studies to identify
and define a set of objectives that effectively capture the aspects of
exploration and skill diversity, respectively. During the skill pretraining
phase, AMPED introduces a gradient surgery technique to balance the objectives
of exploration and skill diversity, mitigating conflicts and reducing reliance
on heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a
skill selector module that dynamically selects suitable skills for downstream
tasks, based on task-specific performance signals. Our approach achieves
performance that surpasses SBRL baselines across various benchmarks. These
results highlight the importance of explicitly harmonizing exploration and
diversity and demonstrate the effectiveness of AMPED in enabling robust and
generalizable skill learning. Project Page: https://geonwoo.me/amped/

</details>


### [76] [Option Pricing Using Ensemble Learning](https://arxiv.org/abs/2506.05799)
*Zeyuan Li, Qingdao Huang*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了集成学习在期权定价中的应用，展示了其相对于传统机器学习模型的优势，并提出了新的实验和评价策略以增强金融模拟的稳健性和现实性。


<details>
  <summary>更多</summary>
  
**动机:** 由于期权定价需要高预测精度和减少结构复杂度，而集成学习恰好具备这些优势，因此该研究旨在探索集成学习在期权定价中的应用潜力。

**方法:** 本文采用了集成学习方法，并与经典机器学习模型进行了比较分析，同时引入了一种新的实验策略和评价机制。

**结果:** 集成学习在期权定价中表现出更高的准确性和鲁棒性，同时揭示了滑动窗口技术与噪声之间的微妙模式。

**结论:** 本论文得出结论，集成学习在期权定价中具有较高的预测精度和对噪声的鲁棒性，并且通过实验策略和评价机制实现了理论金融学与计算方法的有序结合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Option+Pricing+Using+Ensemble+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05799，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05799&send_immediately=true&force_search=false)

**原文摘要:** Ensemble learning is characterized by flexibility, high precision, and
refined structure. As a critical component within computational finance, option
pricing with machine learning requires both high predictive accuracy and
reduced structural complexity-features that align well with the inherent
advantages of ensemble learning. This paper investigates the application of
ensemble learning to option pricing, and conducts a comparative analysis with
classical machine learning models to assess their performance in terms of
accuracy, local feature extraction, and robustness to noise. A novel
experimental strategy is introduced, leveraging parameter transfer across
experiments to improve robustness and realism in financial simulations.Building
upon this strategy, an evaluation mechanism is developed that incorporates a
scoring strategy and a weighted evaluation strategy explicitly emphasizing the
foundational role of financial theory. This mechanism embodies an orderly
integration of theoretical finance and computational methods. In addition, the
study examines the interaction between sliding window technique and noise,
revealing nuanced patterns that suggest a potential connection relevant to
ongoing research in machine learning and data science.

</details>


### [77] [TRUST: Test-time Resource Utilization for Superior Trustworthiness](https://arxiv.org/abs/2506.06048)
*Haripriya Harikumar, Santu Rana*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的测试时优化方法，以提升不确定性估计的可靠性，能够在多种视觉数据集上有效区分分布内外样本并改善风险评估。


<details>
  <summary>更多</summary>
  
**动机:** 标准的不确定性估计技术（如dropout）难以清楚地区分可靠和不可靠的预测，这是由于分类器权重中的噪声影响了细粒度统计信息的可靠性。

**方法:** 通过考虑噪声对分类器权重的影响，提出了一种新的测试时优化方法。

**结果:** 所提出的方法定义了一个单调子集选择函数，在去除低得分样本时，总体准确率会持续提高，并且在AUSE和AURC等风险指标中表现优于现有方法。此外，该方法还能够有效区分分布内和分布外样本，并揭示CNN和ViT分类器的关键差异。

**结论:** 论文提出了一种新的测试时优化方法，用于产生更可靠的置信度估计。该方法在标准风险指标上表现出色，并能够有效识别训练和测试分布之间的差异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRUST%3A+Test-time+Resource+Utilization+for+Superior+Trustworthiness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06048&send_immediately=true&force_search=false)

**原文摘要:** Standard uncertainty estimation techniques, such as dropout, often struggle
to clearly distinguish reliable predictions from unreliable ones. We attribute
this limitation to noisy classifier weights, which, while not impairing overall
class-level predictions, render finer-level statistics less informative. To
address this, we propose a novel test-time optimization method that accounts
for the impact of such noise to produce more reliable confidence estimates.
This score defines a monotonic subset-selection function, where population
accuracy consistently increases as samples with lower scores are removed, and
it demonstrates superior performance in standard risk-based metrics such as
AUSE and AURC. Additionally, our method effectively identifies discrepancies
between training and test distributions, reliably differentiates
in-distribution from out-of-distribution samples, and elucidates key
differences between CNN and ViT classifiers across various vision datasets.

</details>


### [78] [Text-to-LoRA: Instant Transformer Adaption](https://arxiv.org/abs/2506.06105)
*Rujikorn Charakorn, Edoardo Cetin, Yujin Tang, Robert Tjarko Lange*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Text-to-LoRA (T2L)的新方法，可以通过自然语言描述即时调整大型语言模型，避免了传统微调的高成本和敏感超参数选择。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服传统微调技术需要昂贵且耗时的训练，并对超参数选择敏感的问题，作者提出了Text-to-LoRA。这种方法旨在以较低的计算需求实现模型适应任务的快速调整。

**方法:** T2L是一种超网络，经过训练可以在一次前向传递中构建LoRA实例。该方法通过在9个预训练LoRA适配器上进行训练，能够根据目标任务的自然语言描述生成特定任务的LoRA。

**结果:** 实验表明，T2L重建的LoRA实例在相应测试集上的性能与任务特定的适配器相当，并且可以压缩数百个LoRA实例并推广到完全未见过的任务。

**结论:** Text-to-LoRA提供了一个重要的步骤，使得基础模型的专门化更加普及，并实现了基于语言的最小计算需求的适应性调整。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Text-to-LoRA%3A+Instant+Transformer+Adaption，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06105，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06105&send_immediately=true&force_search=false)

**原文摘要:** While Foundation Models provide a general tool for rapid content creation,
they regularly require task-specific adaptation. Traditionally, this exercise
involves careful curation of datasets and repeated fine-tuning of the
underlying model. Fine-tuning techniques enable practitioners to adapt
foundation models for many new applications but require expensive and lengthy
training while being notably sensitive to hyper-parameter choices. To overcome
these limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting
Large Language Models on the fly solely based on a natural language description
of the target task. T2L is a hypernetwork trained to construct LoRAs in a
single inexpensive forward pass. After training T2L on a suite of 9 pre-trained
LoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc reconstructed LoRA
instances match the performance of task-specific adapters across the
corresponding test sets. Furthermore, T2L can compress hundreds of LoRA
instances and zero-shot generalize to entirely unseen tasks. This approach
provides a significant step towards democratizing the specialization of
foundation models and enables language-based adaptation with minimal compute
requirements. Our code is available at https://github.com/SakanaAI/text-to-lora

</details>


### [79] [Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness](https://arxiv.org/abs/2506.06112)
*Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种名为Interpolated Approximate Measurement (IAM) 的新框架，用于有效评估机器遗忘效果，解决了现有方法计算成本高和灵敏度不足的问题，并揭示了当前近似遗忘算法的风险。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器遗忘评估方法存在两个主要限制：(1) 提升Membership Inference Attacks (MIA) 效果需要高昂的计算资源；(2) MIA难以捕捉近似遗忘中的细微变化。因此需要更高效的解决方案。

**方法:** 提出了Interpolated Approximate Measurement (IAM) 框架，通过插值模型在查询样本上的泛化-拟合行为差距来量化样本级别的遗忘完整性，并对IAM的评分机制进行了理论分析。

**结果:** IAM在精确遗忘的二元包含测试中表现出色，在近似遗忘中也具有高相关性，并且可扩展到大语言模型（LLM），仅需一个预训练影子模型即可实现高效性能。

**结论:** IAM框架被提出以解决现有机器遗忘评估方法的局限性，揭示了近似遗忘算法中的过度遗忘和不足遗忘风险，强调了加强遗忘系统保护措施的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Lifecycle+Unlearning+Commitment+Management%3A+Measuring+Sample-level+Unlearning+Completeness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06112&send_immediately=true&force_search=false)

**原文摘要:** Growing concerns over data privacy and security highlight the importance of
machine unlearning--removing specific data influences from trained models
without full retraining. Techniques like Membership Inference Attacks (MIAs)
are widely used to externally assess successful unlearning. However, existing
methods face two key limitations: (1) maximizing MIA effectiveness (e.g., via
online attacks) requires prohibitive computational resources, often exceeding
retraining costs; (2) MIAs, designed for binary inclusion tests, struggle to
capture granular changes in approximate unlearning. To address these
challenges, we propose the Interpolated Approximate Measurement (IAM), a
framework natively designed for unlearning inference. IAM quantifies
sample-level unlearning completeness by interpolating the model's
generalization-fitting behavior gap on queried samples. IAM achieves strong
performance in binary inclusion tests for exact unlearning and high correlation
for approximate unlearning--scalable to LLMs using just one pre-trained shadow
model. We theoretically analyze how IAM's scoring mechanism maintains
performance efficiently. We then apply IAM to recent approximate unlearning
algorithms, revealing general risks of both over-unlearning and
under-unlearning, underscoring the need for stronger safeguards in approximate
unlearning systems. The code is available at
https://github.com/Happy2Git/Unlearning_Inference_IAM.

</details>


### [80] [Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning](https://arxiv.org/abs/2506.05826)
*Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于双曲几何的方法来提高更新模型与现有模型的向后兼容性，同时考虑旧模型的不确定性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的欧几里得空间兼容方法忽略了旧嵌入模型的不确定性，强制新模型重构过时的表示，从而阻碍了新模型的学习过程。

**方法:** 将嵌入提升到双曲空间，并通过引入基于旧嵌入不确定性的对比对齐损失来增强兼容性。

**结果:** 通过将时间视为置信度和模型演化的自然轴，在双曲几何中保持代际一致性的同时考虑表示中的不确定性。

**结论:** 实验验证了所提出方法在实现兼容性方面的优越性，为构建更具弹性和适应性的机器学习系统铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Along+the+Arrow+of+Time%3A+Hyperbolic+Geometry+for+Backward-Compatible+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05826，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05826&send_immediately=true&force_search=false)

**原文摘要:** Backward compatible representation learning enables updated models to
integrate seamlessly with existing ones, avoiding to reprocess stored data.
Despite recent advances, existing compatibility approaches in Euclidean space
neglect the uncertainty in the old embedding model and force the new model to
reconstruct outdated representations regardless of their quality, thereby
hindering the learning process of the new model. In this paper, we propose to
switch perspectives to hyperbolic geometry, where we treat time as a natural
axis for capturing a model's confidence and evolution. By lifting embeddings
into hyperbolic space and constraining updated embeddings to lie within the
entailment cone of the old ones, we maintain generational consistency across
models while accounting for uncertainties in the representations. To further
enhance compatibility, we introduce a robust contrastive alignment loss that
dynamically adjusts alignment weights based on the uncertainty of the old
embeddings. Experiments validate the superiority of the proposed method in
achieving compatibility, paving the way for more resilient and adaptable
machine learning systems.

</details>


### [81] [The Lock-in Hypothesis: Stagnation by Algorithm](https://arxiv.org/abs/2506.06166)
*Tianyi Alex Qiu, Zhonghao He, Tejasveer Chugh, Max Kleiman-Weiner*

**主要类别:** cs.LG

**AI概要:** 该论文研究了大型语言模型与用户之间反馈循环的影响，发现这种动态可能导致信念固化的风险，并通过模拟和真实数据分析验证了这一假设。


<details>
  <summary>更多</summary>
  
**动机:** 作者假设大型语言模型在训练和部署过程中会强化用户的既有信念，从而形成类似回音室效应的动态，这可能影响社会的信息多样性。

**方法:** 论文通过基于代理的LLM模拟和对GPT实际使用数据的实证分析来验证假设。

**结果:** 分析显示，在新版本GPT发布后，多样性出现了突然且持续的下降，这与假设的人工智能-人类反馈循环一致。

**结论:** 论文得出结论，大型语言模型（LLMs）与人类用户之间的反馈循环可能导致用户现有价值观和信念的固化，进而导致多样性的丧失以及错误信念的锁定。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Lock-in+Hypothesis%3A+Stagnation+by+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06166，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06166&send_immediately=true&force_search=false)

**原文摘要:** The training and deployment of large language models (LLMs) create a feedback
loop with human users: models learn human beliefs from data, reinforce these
beliefs with generated content, reabsorb the reinforced beliefs, and feed them
back to users again and again. This dynamic resembles an echo chamber. We
hypothesize that this feedback loop entrenches the existing values and beliefs
of users, leading to a loss of diversity and potentially the lock-in of false
beliefs. We formalize this hypothesis and test it empirically with agent-based
LLM simulations and real-world GPT usage data. Analysis reveals sudden but
sustained drops in diversity after the release of new GPT iterations,
consistent with the hypothesized human-AI feedback loop. Code and data
available at https://thelockinhypothesis.com

</details>


### [82] [Towards an Explainable Comparison and Alignment of Feature Embeddings](https://arxiv.org/abs/2506.06231)
*Mohammad Jalali, Bahar Dibaei Nia, Farzan Farnia*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种新的特征嵌入比较框架SPEC，它能够解释并识别不同嵌入空间中样本群集的差异，并提出了一个优化方案来对齐这些嵌入。


<details>
  <summary>更多</summary>
  
**动机:** 虽然文献中开发了几种特征嵌入模型，但目前的比较主要集中在分类相关下游应用中的数值性能上，而缺乏可解释性的对比分析。

**方法:** 该方法通过分析两个嵌入衍生的核矩阵，并利用差分核矩阵的特征分解来检测不同嵌入所捕捉到的样本簇。此外，还引入了一个优化问题来对齐两个嵌入。

**结果:** 论文展示了基于大规模数据集（如ImageNet和MS-COCO）的数值结果，证明了SPEC在比较和对齐嵌入方面的有效性。

**结论:** 论文提出了一种名为Spectral Pairwise Embedding Comparison (SPEC)的框架，用于比较和对齐不同的特征嵌入模型，并且能够识别参考数据集中的样本聚类差异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+an+Explainable+Comparison+and+Alignment+of+Feature+Embeddings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06231，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06231&send_immediately=true&force_search=false)

**原文摘要:** While several feature embedding models have been developed in the literature,
comparisons of these embeddings have largely focused on their numerical
performance in classification-related downstream applications. However, an
interpretable comparison of different embeddings requires identifying and
analyzing mismatches between sample groups clustered within the embedding
spaces. In this work, we propose the \emph{Spectral Pairwise Embedding
Comparison (SPEC)} framework to compare embeddings and identify their
differences in clustering a reference dataset. Our approach examines the kernel
matrices derived from two embeddings and leverages the eigendecomposition of
the difference kernel matrix to detect sample clusters that are captured
differently by the two embeddings. We present a scalable implementation of this
kernel-based approach, with computational complexity that grows linearly with
the sample size. Furthermore, we introduce an optimization problem using this
framework to align two embeddings, ensuring that clusters identified in one
embedding are also captured in the other model. We provide numerical results
demonstrating the SPEC's application to compare and align embeddings on
large-scale datasets such as ImageNet and MS-COCO. The code is available at
[https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).

</details>


### [83] [Wavelet-based Disentangled Adaptive Normalization for Non-stationary Times Series Forecasting](https://arxiv.org/abs/2506.05857)
*Junpeng Lin, Tian Lan, Bo Zhang, Ke Lin, Dandan Miao, Huiru He, Jiantao Ye, Chen Zhang, Yan-fu Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Wavelet-based Disentangled Adaptive Normalization (WDAN)的新方法，用于解决时间序列预测中的非平稳性问题。


<details>
  <summary>更多</summary>
  
**动机:** 非平稳时间序列的统计特性经常随时间变化，这使得深度模型难以很好地泛化。现有的方法忽略了时间序列的多成分性，其中不同的成分表现出不同的非平稳行为。

**方法:** 使用基于离散小波变换的分解方法将输入分解为低频趋势和高频波动，并对每个部分应用定制的归一化策略。

**结果:** 在多个基准上的广泛实验表明，WDAN能够持续提高各种骨干模型的预测精度。

**结论:** WDAN是一个有效的模型无关框架，可以提高时间序列预测的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Wavelet-based+Disentangled+Adaptive+Normalization+for+Non-stationary+Times+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05857，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05857&send_immediately=true&force_search=false)

**原文摘要:** Forecasting non-stationary time series is a challenging task because their
statistical properties often change over time, making it hard for deep models
to generalize well. Instance-level normalization techniques can help address
shifts in temporal distribution. However, most existing methods overlook the
multi-component nature of time series, where different components exhibit
distinct non-stationary behaviors. In this paper, we propose Wavelet-based
Disentangled Adaptive Normalization (WDAN), a model-agnostic framework designed
to address non-stationarity in time series forecasting. WDAN uses discrete
wavelet transforms to break down the input into low-frequency trends and
high-frequency fluctuations. It then applies tailored normalization strategies
to each part. For trend components that exhibit strong non-stationarity, we
apply first-order differencing to extract stable features used for predicting
normalization parameters. Extensive experiments on multiple benchmarks
demonstrate that WDAN consistently improves forecasting accuracy across various
backbone model. Code is available at this repository:
https://github.com/MonBG/WDAN.

</details>


### [84] [Distillation Robustifies Unlearning](https://arxiv.org/abs/2506.06278)
*Bruce W. Lee, Addie Foote, Alex Infanger, Leni Shor, Harish Kamath, Jacob Goldman-Wetzler, Bryce Woodworth, Alex Cloud, Alexander Matt Turner*

**主要类别:** cs.LG

**AI概要:** 本文提出了名为UNDO的新方法，利用蒸馏技术提高大语言模型遗忘学习的稳健性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的大语言模型遗忘学习（unlearning）方法不够稳健，容易通过微调被还原。

**方法:** 通过蒸馏（distillation）技术，将未经学习的模型知识转移到一个部分加噪的副本中，提出Unlearn-Noise-Distill-on-Outputs (UNDO)方法。

**结果:** UNDO方法在合成语言和算术任务上建立了新的Pareto前沿，并在更现实的WMDP基准测试中证明了其有效性。

**结论:** UNDO方法在实际应用中提供了一种便捷的路径来实现稳健的能力移除。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distillation+Robustifies+Unlearning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06278，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06278&send_immediately=true&force_search=false)

**原文摘要:** Current LLM unlearning methods are not robust: they can be reverted easily
with a few steps of finetuning. This is true even for the idealized unlearning
method of training to imitate an oracle model that was never exposed to
unwanted information, suggesting that output-based finetuning is insufficient
to achieve robust unlearning. In a similar vein, we find that training a
randomly initialized student to imitate an unlearned model transfers desired
behaviors while leaving undesired capabilities behind. In other words,
distillation robustifies unlearning. Building on this insight, we propose
Unlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an
unlearned model into a partially noised copy of itself. UNDO introduces a
tunable tradeoff between compute cost and robustness, establishing a new Pareto
frontier on synthetic language and arithmetic tasks. At its strongest setting,
UNDO matches the robustness of a model retrained from scratch with perfect data
filtering while using only 60-80% of the compute and requiring only 0.01% of
the pretraining data to be labeled. We also show that UNDO robustifies
unlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP)
benchmark. Since distillation is widely used in practice, incorporating an
unlearning step beforehand offers a convenient path to robust capability
removal.

</details>


### [85] [Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias](https://arxiv.org/abs/2506.06280)
*Yuanzhe Hu, Kinshuk Goel, Vlad Killiakov, Yaoqing Yang*

**主要类别:** cs.LG

**AI概要:** 本文研究了通过权重矩阵的特征谱分析来诊断深度神经网络的问题，提出了一种称为FARMS的方法，该方法通过固定比例的子采样来减少估计重尾度量时的偏差，从而提高了模型诊断和超参数分配的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前通过深度神经网络权重矩阵的特征谱分析来进行模型诊断存在一个问题：不同大小（纵横比）的矩阵会对重尾度量估计引入偏差，导致模型诊断不准确和层间超参数分配不当。

**方法:** 作者提出了FARMS（Fixed-Aspect-Ratio Matrix Subsampling）方法，通过对原始权重矩阵进行固定纵横比的子采样，计算这些子矩阵的平均经验谱密度，并基于此测量其重尾特性，以消除纵横比对估计结果的影响。

**结果:** 在多个优化技术和应用领域中验证了FARMS的有效性，包括计算机视觉模型、科学机器学习模型训练和大型语言模型剪枝。实验表明，FARMS能够显著提高特征谱分析的准确性，并实现更有效的层间超参数分配。在一个LLM剪枝实验中，FARMS相比现有最佳方法降低了17.3%的困惑度。

**结论:** FARMS是一种简单但有效的方法，可以提升深度神经网络权重特征谱分析的可靠性与实用性，适用于多种应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Eigenspectrum+Analysis+of+Neural+Networks+without+Aspect+Ratio+Bias，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06280，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06280&send_immediately=true&force_search=false)

**原文摘要:** Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight
matrices has been an active area of research in recent years. At a high level,
eigenspectrum analysis of DNNs involves measuring the heavytailness of the
empirical spectral densities (ESD) of weight matrices. It provides insight into
how well a model is trained and can guide decisions on assigning better
layer-wise training hyperparameters. In this paper, we address a challenge
associated with such eigenspectrum methods: the impact of the aspect ratio of
weight matrices on estimated heavytailness metrics. We demonstrate that
matrices of varying sizes (and aspect ratios) introduce a non-negligible bias
in estimating heavytailness metrics, leading to inaccurate model diagnosis and
layer-wise hyperparameter assignment. To overcome this challenge, we propose
FARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the
weight matrices by subsampling submatrices with a fixed aspect ratio. Instead
of measuring the heavytailness of the original ESD, we measure the average ESD
of these subsampled submatrices. We show that measuring the heavytailness of
these submatrices with the fixed aspect ratio can effectively mitigate the
aspect ratio bias. We validate our approach across various optimization
techniques and application domains that involve eigenspectrum analysis of
weights, including image classification in computer vision (CV) models,
scientific machine learning (SciML) model training, and large language model
(LLM) pruning. Our results show that despite its simplicity, FARMS uniformly
improves the accuracy of eigenspectrum analysis while enabling more effective
layer-wise hyperparameter assignment in these application domains. In one of
the LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model
by 17.3% when compared with the state-of-the-art method.

</details>


### [86] [BestServe: Serving Strategies with Optimal Goodput in Collocation and Disaggregation Architectures](https://arxiv.org/abs/2506.05871)
*Xiannan Hu, Tianyou Zeng, Xiaoming Yuan, Liwei Song, Guangyuan Zhang, Bangzheng He*

**主要类别:** cs.LG

**AI概要:** 提出了一个高效的框架BestServe，用于估算不同操作场景下的吞吐量，从而快速找到服务策略，避免了昂贵的基准测试。


<details>
  <summary>更多</summary>
  
**动机:** 为数百万用户提供大型语言模型（LLM）服务需要有效的资源分配和并行策略，而找到这样的策略是一个劳动密集型的试错过程。

**方法:** 利用基于改进屋顶模型和CPU-GPU调度动态的推理模拟器，对各种操作场景下的吞吐量进行估计。

**结果:** 在单一标准CPU上几分钟内确定最优策略，预测误差控制在20%以内。

**结论:** BestServe是一个新颖的框架，可以快速确定最佳的服务策略，无需昂贵的基准测试，非常适合用于快速部署规划。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BestServe%3A+Serving+Strategies+with+Optimal+Goodput+in+Collocation+and+Disaggregation+Architectures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05871，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05871&send_immediately=true&force_search=false)

**原文摘要:** Serving large language models (LLMs) to millions of users requires efficient
resource allocation and parallelism strategies. It is a labor intensive
trial-and-error process to find such a strategy. We present BestServe, a novel
framework for ranking serving strategies by estimating goodput under various
operating scenarios. Supporting both collocated and disaggregated
architectures, BestServe leverages an inference simulator built on an adapted
roofline model and CPU-GPU dispatch dynamics. Our framework determines the
optimal strategy in minutes on a single standard CPU, eliminating the need for
costly benchmarking, while achieving predictions within a $20\%$ error margin.
It appeals to be practical for rapid deployment planning because of its
lightweight design and strong extensibility.

</details>


### [87] [Interpretable Clustering Ensemble](https://arxiv.org/abs/2506.05877)
*Hang Lv, Lianyu Hu, Mudi Jiang, Xinying Liu, Zengyou He*

**主要类别:** cs.LG

**AI概要:** 本研究首次提出一种具有可解释性的聚类集成算法，通过决策树结合统计关联测试实现，为可解释性聚类研究提供新视角。


<details>
  <summary>更多</summary>
  
**动机:** 尽管许多聚类集成方法被提出以提高聚类质量，但大多数忽略了解释性的重要性，尤其在医疗诊断和金融风险评估等高风险领域，算法不仅需要准确还需要透明可信。

**方法:** 通过将基础划分视为分类变量，并在原始特征空间中构建决策树，使用统计关联测试来指导树的构建过程。

**结果:** 实验结果表明，该方法在保持与现有最先进的聚类集成方法相当的性能的同时，还提供了额外的可解释性功能。

**结论:** 本文提出了首个用于聚类集成的可解释性算法，在保持与最先进方法相当性能的同时，增加了可解释性这一重要特性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Clustering+Ensemble，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05877，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05877&send_immediately=true&force_search=false)

**原文摘要:** Clustering ensemble has emerged as an important research topic in the field
of machine learning. Although numerous methods have been proposed to improve
clustering quality, most existing approaches overlook the need for
interpretability in high-stakes applications. In domains such as medical
diagnosis and financial risk assessment, algorithms must not only be accurate
but also interpretable to ensure transparent and trustworthy decision-making.
Therefore, to fill the gap of lack of interpretable algorithms in the field of
clustering ensemble, we propose the first interpretable clustering ensemble
algorithm in the literature. By treating base partitions as categorical
variables, our method constructs a decision tree in the original feature space
and use the statistical association test to guide the tree building process.
Experimental results demonstrate that our algorithm achieves comparable
performance to state-of-the-art (SOTA) clustering ensemble methods while
maintaining an additional feature of interpretability. To the best of our
knowledge, this is the first interpretable algorithm specifically designed for
clustering ensemble, offering a new perspective for future research in
interpretable clustering.

</details>


### [88] [A projection-based framework for gradient-free and parallel learning](https://arxiv.org/abs/2506.05878)
*Andreas Bergmeister, Manish Krishan Lal, Stefanie Jegelka, Suvrit Sra*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种基于可行性搜索的神经网络训练方法，与传统的基于梯度的损失最小化方法不同，该方法使用投影算子和迭代投影算法。


<details>
  <summary>更多</summary>
  
**动机:** 为了改进传统基于梯度的神经网络训练方法，探索一种新的数学优化框架，能够在处理大规模问题时具有更高的效率和灵活性。

**方法:** 将神经网络训练重新表述为一个大规模可行性问题，并通过迭代投影算法求解。利用PJAX框架自动推导可行性问题的解决方案，并支持GPU/TPU加速。

**结果:** 成功地在多种架构（MLPs、CNNs、RNNs）上进行了训练，并展示了该方法的功能性和通用性，同时在并行性和处理不可微操作方面表现出明显优势。

**结论:** 这种方法是基于梯度的训练方式的一个有吸引力的替代方案，在某些特定场景下可能优于传统方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+projection-based+framework+for+gradient-free+and+parallel+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05878，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05878&send_immediately=true&force_search=false)

**原文摘要:** We present a feasibility-seeking approach to neural network training. This
mathematical optimization framework is distinct from conventional
gradient-based loss minimization and uses projection operators and iterative
projection algorithms. We reformulate training as a large-scale feasibility
problem: finding network parameters and states that satisfy local constraints
derived from its elementary operations. Training then involves projecting onto
these constraints, a local operation that can be parallelized across the
network. We introduce PJAX, a JAX-based software framework that enables this
paradigm. PJAX composes projection operators for elementary operations,
automatically deriving the solution operators for the feasibility problems
(akin to autodiff for derivatives). It inherently supports GPU/TPU
acceleration, provides a familiar NumPy-like API, and is extensible. We train
diverse architectures (MLPs, CNNs, RNNs) on standard benchmarks using PJAX,
demonstrating its functionality and generality. Our results show that this
approach is as a compelling alternative to gradient-based training, with clear
advantages in parallelism and the ability to handle non-differentiable
operations.

</details>


### [89] [NILMFormer: Non-Intrusive Load Monitoring that Accounts for Non-Stationarity](https://arxiv.org/abs/2506.05880)
*Adrien Petralia, Philippe Charpentier, Youssef Kadhi, Themis Palpanas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个名为NILMFormer的新模型，该模型解决了非侵入式负载监控问题，并且在实际数据集上表现出了优秀的性能。


<details>
  <summary>更多</summary>
  
**动机:** 由于现实世界中智能电表数据的非平稳性，现有的深度学习方法在处理NILM问题时效果不佳，因此需要提出一种新的解决方案。

**方法:** 该论文采用了基于Transformer的模型，结合了新的子序列平稳化/去平稳化方案和仅依赖于时间戳信息的位置编码方法。

**结果:** NILMFormer在四个真实世界数据集上的实验结果表明，其显著优于当前最先进的方法。

**结论:** 论文介绍了一种名为NILMFormer的Transformer架构，用于解决非侵入式负载监控（NILM）问题，并且实验结果显示其性能优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NILMFormer%3A+Non-Intrusive+Load+Monitoring+that+Accounts+for+Non-Stationarity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05880，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05880&send_immediately=true&force_search=false)

**原文摘要:** Millions of smart meters have been deployed worldwide, collecting the total
power consumed by individual households. Based on these data, electricity
suppliers offer their clients energy monitoring solutions to provide feedback
on the consumption of their individual appliances. Historically, such estimates
have relied on statistical methods that use coarse-grained total monthly
consumption and static customer data, such as appliance ownership.
Non-Intrusive Load Monitoring (NILM) is the problem of disaggregating a
household's collected total power consumption to retrieve the consumed power
for individual appliances. Current state-of-the-art (SotA) solutions for NILM
are based on deep-learning (DL) and operate on subsequences of an entire
household consumption reading. However, the non-stationary nature of real-world
smart meter data leads to a drift in the data distribution within each
segmented window, which significantly affects model performance. This paper
introduces NILMFormer, a Transformer-based architecture that incorporates a new
subsequence stationarization/de-stationarization scheme to mitigate the
distribution drift and that uses a novel positional encoding that relies only
on the subsequence's timestamp information. Experiments with 4 real-world
datasets show that NILMFormer significantly outperforms the SotA approaches.
Our solution has been deployed as the backbone algorithm for EDF's
(Electricit\'e De France) consumption monitoring service, delivering detailed
insights to millions of customers about their individual appliances' power
consumption. This paper appeared in KDD 2025.

</details>


### [90] [Few Labels are all you need: A Weakly Supervised Framework for Appliance Localization in Smart-Meter Series](https://arxiv.org/abs/2506.05895)
*Adrien Petralia, Paul Boniol, Philippe Charpentier, Themis Palpanas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CamAL的弱监督方法，用于解决非侵入式负载监测问题，仅需简单的存在信息即可有效定位家庭电器用电模式。


<details>
  <summary>更多</summary>
  
**动机:** 智能电网系统管理对于应对气候变化至关重要，但如何让消费者积极参与仍是挑战，而现有方法需要大量昂贵的标签数据。

**方法:** CamAL结合了深度学习分类器集合和可解释分类方法，仅需家庭中存在某种电器的信息进行训练。

**结果:** 在4个真实数据集上的实验表明，CamAL显著优于现有弱监督基线，并且完全监督的NILM方法需要更多标签才能达到CamAL的性能。

**结论:** CamAL是一种弱监督方法，在家用电器模式定位方面表现出色，相比现有的弱监督基线和完全监督的NILM方法具有优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Few+Labels+are+all+you+need%3A+A+Weakly+Supervised+Framework+for+Appliance+Localization+in+Smart-Meter+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05895，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05895&send_immediately=true&force_search=false)

**原文摘要:** Improving smart grid system management is crucial in the fight against
climate change, and enabling consumers to play an active role in this effort is
a significant challenge for electricity suppliers. In this regard, millions of
smart meters have been deployed worldwide in the last decade, recording the
main electricity power consumed in individual households. This data produces
valuable information that can help them reduce their electricity footprint;
nevertheless, the collected signal aggregates the consumption of the different
appliances running simultaneously in the house, making it difficult to
apprehend. Non-Intrusive Load Monitoring (NILM) refers to the challenge of
estimating the power consumption, pattern, or on/off state activation of
individual appliances using the main smart meter signal. Recent methods
proposed to tackle this task are based on a fully supervised deep-learning
approach that requires both the aggregate signal and the ground truth of
individual appliance power. However, such labels are expensive to collect and
extremely scarce in practice, as they require conducting intrusive surveys in
households to monitor each appliance. In this paper, we introduce CamAL, a
weakly supervised approach for appliance pattern localization that only
requires information on the presence of an appliance in a household to be
trained. CamAL merges an ensemble of deep-learning classifiers combined with an
explainable classification method to be able to localize appliance patterns.
Our experimental evaluation, conducted on 4 real-world datasets, demonstrates
that CamAL significantly outperforms existing weakly supervised baselines and
that current SotA fully supervised NILM approaches require significantly more
labels to reach CamAL performances. The source of our experiments is available
at: https://github.com/adrienpetralia/CamAL. This paper appeared in ICDE 2025.

</details>


### [91] [A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics](https://arxiv.org/abs/2506.05902)
*Shirui Zhou, Jiying Yan, Junfang Tian, Tao Wang, Yongfu Li, Shiquan Zhong*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合离散驾驶状态与连续车辆动态的混合深度学习模型，以更准确地预测驾驶员行为和交通现象。


<details>
  <summary>更多</summary>
  
**动机:** 现有的传统和数据驱动模型在一定程度上解决了行为异质性问题，但往往强调驾驶员间的异质性或依赖简化假设，限制了其对单一驾驶员在不同条件下动态异质性的描述能力。

**方法:** 利用高分辨率交通轨迹数据集，结合门控循环单元和长短期记忆网络的混合深度学习架构，并采用自下而上的分割算法和动态时间规整识别驾驶状态。

**结果:** 比较分析表明，该框架显著减少了加速度、速度和间距指标的预测误差（最大MSE改进达到58.47%），同时再现了如走停波传播和振荡动力学等关键交通现象。

**结论:** 论文提出了一种新的数据驱动的跟车模型框架，该框架通过将离散驾驶状态嵌入到车辆运动预测中，有效地捕捉了驾驶员在不同驾驶条件下的动态异质性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Driving+Regime-Embedded+Deep+Learning+Framework+for+Modeling+Intra-Driver+Heterogeneity+in+Multi-Scale+Car-Following+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05902，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05902&send_immediately=true&force_search=false)

**原文摘要:** A fundamental challenge in car-following modeling lies in accurately
representing the multi-scale complexity of driving behaviors, particularly the
intra-driver heterogeneity where a single driver's actions fluctuate
dynamically under varying conditions. While existing models, both conventional
and data-driven, address behavioral heterogeneity to some extent, they often
emphasize inter-driver heterogeneity or rely on simplified assumptions,
limiting their ability to capture the dynamic heterogeneity of a single driver
under different driving conditions. To address this gap, we propose a novel
data-driven car-following framework that systematically embeds discrete driving
regimes (e.g., steady-state following, acceleration, cruising) into vehicular
motion predictions. Leveraging high-resolution traffic trajectory datasets, the
proposed hybrid deep learning architecture combines Gated Recurrent Units for
discrete driving regime classification with Long Short-Term Memory networks for
continuous kinematic prediction, unifying discrete decision-making processes
and continuous vehicular dynamics to comprehensively represent inter- and
intra-driver heterogeneity. Driving regimes are identified using a bottom-up
segmentation algorithm and Dynamic Time Warping, ensuring robust
characterization of behavioral states across diverse traffic scenarios.
Comparative analyses demonstrate that the framework significantly reduces
prediction errors for acceleration (maximum MSE improvement reached 58.47\%),
speed, and spacing metrics while reproducing critical traffic phenomena, such
as stop-and-go wave propagation and oscillatory dynamics.

</details>


### [92] [DeviceScope: An Interactive App to Detect and Localize Appliance Patterns in Electricity Consumption Time Series](https://arxiv.org/abs/2506.05912)
*Adrien Petralia, Paul Boniol, Philippe Charpentier, Themis Palpanas*

**主要类别:** cs.LG

**AI概要:** 这篇文章提出了DeviceScope，一种基于CamAL的新工具，旨在帮助非专业用户通过检测和定位智能电表数据中的个体电器模式来更好地理解和管理他们的电力消耗。


<details>
  <summary>更多</summary>
  
**动机:** 电力供应商安装智能电表以帮助消费者减少电力消耗，但如何让非专业用户理解这些数据并识别不同电器的使用模式是一个挑战。

**方法:** 提出了一种新的弱监督设备定位方法CamAL，仅需要知道家庭中存在设备即可进行训练。

**结果:** 开发了DeviceScope系统，可以检测和定位特定时间段内的单个电器模式。

**结论:** 本文介绍了一个名为DeviceScope的交互式工具，该工具基于CamAL方法，用于帮助非专业用户理解和分析智能电表数据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeviceScope%3A+An+Interactive+App+to+Detect+and+Localize+Appliance+Patterns+in+Electricity+Consumption+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05912&send_immediately=true&force_search=false)

**原文摘要:** In recent years, electricity suppliers have installed millions of smart
meters worldwide to improve the management of the smart grid system. These
meters collect a large amount of electrical consumption data to produce
valuable information to help consumers reduce their electricity footprint.
However, having non-expert users (e.g., consumers or sales advisors) understand
these data and derive usage patterns for different appliances has become a
significant challenge for electricity suppliers because these data record the
aggregated behavior of all appliances. At the same time, ground-truth labels
(which could train appliance detection and localization models) are expensive
to collect and extremely scarce in practice. This paper introduces DeviceScope,
an interactive tool designed to facilitate understanding smart meter data by
detecting and localizing individual appliance patterns within a given time
period. Our system is based on CamAL (Class Activation Map-based Appliance
Localization), a novel weakly supervised approach for appliance localization
that only requires the knowledge of the existence of an appliance in a
household to be trained. This paper appeared in ICDE 2025.

</details>


### [93] [Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs](https://arxiv.org/abs/2506.05918)
*Wenxuan Huo, Qiang He, Gang Zhu, Weifeng Huang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Over-PINNs的新框架，利用自动微分生成高阶辅助方程来增强物理信息的捕捉能力，从而在求解偏微分方程上实现更高的准确性和通用性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管PINNs减少了对大数据集的依赖，但在处理复杂问题时其准确性仍有提升空间。

**方法:** 使用自动微分（AD）生成高阶辅助方程，并将其作为额外损失项加入训练过程，以“超定”方法增强模型捕捉物理信息的能力。

**结果:** 数值结果表明，该方法在求解多种类型的偏微分方程（PDEs）方面表现出很强的通用性，并且解决方案的准确性有了显著提高。

**结论:** Over-PINNs通过引入高阶辅助方程和额外的物理约束，在解决各种类型的PDE问题上展现了强大的通用性和显著提高的准确性，同时计算成本并未显著增加。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Over-PINNs%3A+Enhancing+Physics-Informed+Neural+Networks+via+Higher-Order+Partial+Derivative+Overdetermination+of+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05918&send_immediately=true&force_search=false)

**原文摘要:** Partial differential equations (PDEs) serve as the cornerstone of
mathematical physics. In recent years, Physics-Informed Neural Networks (PINNs)
have significantly reduced the dependence on large datasets by embedding
physical laws directly into the training of neural networks. However, when
dealing with complex problems, the accuracy of PINNs still has room for
improvement. To address this issue, we introduce the Over-PINNs framework,
which leverages automatic differentiation (AD) to generate higher-order
auxiliary equations that impose additional physical constraints. These
equations are incorporated as extra loss terms in the training process,
effectively enhancing the model's ability to capture physical information
through an "overdetermined" approach. Numerical results illustrate that this
method exhibits strong versatility in solving various types of PDEs. It
achieves a significant improvement in solution accuracy without incurring
substantial additional computational costs.

</details>


### [94] [Machine Learning Predictions for Traffic Equilibria in Road Renovation Scheduling](https://arxiv.org/abs/2506.05933)
*Robbert Bosch, Wouter van Heeswijk, Patricia Rogetzer, Martijn Mes*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种基于XGBoost的机器学习方法，用于预测道路维护引发的交通拥堵，有效降低了传统仿真方法的计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 准确估计道路维护计划对交通状况的影响非常重要，因为如果不仔细规划，维护操作可能会加剧交通拥堵，而传统的交通模拟方法在长期维护规划中会带来巨大的计算负担。

**方法:** 将问题构建为监督学习任务，使用独热编码、工程交通特征和启发式近似进行建模，并在在线学习框架下评估了一系列线性、集成、概率和神经网络回归模型的表现。

**结果:** 实验结果显示，当训练数据有限时，Costliest Subset Heuristic提供了合理的近似方法，大多数回归模型无法超越它，但XGBoost表现突出，在MAPE和Pinball损失等指标上显著优于其他模型，MAPE达到11%。

**结论:** 本文研究了基于机器学习的替代模型在预测道路维护引起的交通拥堵方面的应用，结果表明XGBoost模型在多种指标上显著优于其他模型和启发式方法，具有降低大规模交通分配问题计算负担的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Learning+Predictions+for+Traffic+Equilibria+in+Road+Renovation+Scheduling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05933，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05933&send_immediately=true&force_search=false)

**原文摘要:** Accurately estimating the impact of road maintenance schedules on traffic
conditions is important because maintenance operations can substantially worsen
congestion if not carefully planned. Reliable estimates allow planners to avoid
excessive delays during periods of roadwork. Since the exact increase in
congestion is difficult to predict analytically, traffic simulations are
commonly used to assess the redistribution of the flow of traffic. However,
when applied to long-term maintenance planning involving many overlapping
projects and scheduling alternatives, these simulations must be run thousands
of times, resulting in a significant computational burden. This paper
investigates the use of machine learning-based surrogate models to predict
network-wide congestion caused by simultaneous road renovations. We frame the
problem as a supervised learning task, using one-hot encodings, engineered
traffic features, and heuristic approximations. A range of linear,
ensemble-based, probabilistic, and neural regression models is evaluated under
an online learning framework in which data progressively becomes available. The
experimental results show that the Costliest Subset Heuristic provides a
reasonable approximation when limited training data is available, and that most
regression models fail to outperform it, with the exception of XGBoost, which
achieves substantially better accuracy. In overall performance, XGBoost
significantly outperforms alternatives in a range of metrics, most strikingly
Mean Absolute Percentage Error (MAPE) and Pinball loss, where it achieves a
MAPE of 11% and outperforms the next-best model by 20% and 38% respectively.
This modeling approach has the potential to reduce the computational burden of
large-scale traffic assignment problems in maintenance planning.

</details>


### [95] [Exponential Family Variational Flow Matching for Tabular Data Generation](https://arxiv.org/abs/2506.05940)
*Andrés Guzmán-Cordero, Floor Eijkelboom, Jan-Willem van de Meent*

**主要类别:** cs.LG

**AI概要:** 本文提出了 TabbyFlow（EF-VFM 方法），用于生成具有混合特征类型的表格数据，在现实世界应用中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 尽管去噪扩散和流匹配在生成模型中取得了重大进展，但它们在表格数据中的应用仍然有限，而表格数据在现实世界的应用中无处不在。

**方法:** 开发了一种称为 EF-VFM 的方法，该方法通过使用指数族分布表示异构数据类型，并基于矩匹配获得高效的数据驱动目标来学习概率路径。

**结果:** 评估表明，TabbyFlow 在表格数据基准上的表现优于基线模型，达到了最先进的水平。

**结论:** TabbyFlow, specifically the EF-VFM方法, 在生成混合连续和离散特征的表格数据方面表现出最先进的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exponential+Family+Variational+Flow+Matching+for+Tabular+Data+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05940，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05940&send_immediately=true&force_search=false)

**原文摘要:** While denoising diffusion and flow matching have driven major advances in
generative modeling, their application to tabular data remains limited, despite
its ubiquity in real-world applications. To this end, we develop TabbyFlow, a
variational Flow Matching (VFM) method for tabular data generation. To apply
VFM to data with mixed continuous and discrete features, we introduce
Exponential Family Variational Flow Matching (EF-VFM), which represents
heterogeneous data types using a general exponential family distribution. We
hereby obtain an efficient, data-driven objective based on moment matching,
enabling principled learning of probability paths over mixed continuous and
discrete variables. We also establish a connection between variational flow
matching and generalized flow matching objectives based on Bregman divergences.
Evaluation on tabular data benchmarks demonstrates state-of-the-art performance
compared to baselines.

</details>


### [96] [Additive decomposition of one-dimensional signals using Transformers](https://arxiv.org/abs/2506.05942)
*Samuele Salti, Andrea Pinto, Alessandro Lanza, Serena Morigi*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种使用Transformer进行一维信号分解的新方法，并通过实验验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 传统分解技术依赖于数学模型，而应用最新的深度学习模型到这个问题中是一个令人兴奋且未被充分探索的领域。

**方法:** 利用Transformer架构将信号分解为分段常数、平滑、纹理和噪声四个组成部分。

**结果:** 实验结果显示了该模型在建模和分解来自同一分布的输入信号方面的优秀准确性。

**结论:** 本文提出了一种基于Transformer架构的一维信号加法分解新方法，实验结果表明该模型在合成数据上具有很高的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Additive+decomposition+of+one-dimensional+signals+using+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05942，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05942&send_immediately=true&force_search=false)

**原文摘要:** One-dimensional signal decomposition is a well-established and widely used
technique across various scientific fields. It serves as a highly valuable
pre-processing step for data analysis. While traditional decomposition
techniques often rely on mathematical models, recent research suggests that
applying the latest deep learning models to this problem presents an exciting,
unexplored area with promising potential. This work presents a novel method for
the additive decomposition of one-dimensional signals. We leverage the
Transformer architecture to decompose signals into their constituent
components: piece-wise constant, smooth (low-frequency oscillatory), textured
(high-frequency oscillatory), and a noise component. Our model, trained on
synthetic data, achieves excellent accuracy in modeling and decomposing input
signals from the same distribution, as demonstrated by the experimental
results.

</details>


### [97] [Learning Deterministic Policies with Policy Gradients in Constrained Markov Decision Processes](https://arxiv.org/abs/2506.05953)
*Alessandro Montenegro, Leonardo Cesani, Marco Mussi, Matteo Papini, Alberto Maria Metelli*

**主要类别:** cs.LG

**AI概要:** 论文提出了适用于约束强化学习的C-PG算法，通过学习随机策略并在训练后使用确定性策略，实现了良好的性能和理论保证。


<details>
  <summary>更多</summary>
  
**动机:** 约束强化学习中需要兼顾最大化回报和满足约束条件，而现有基于策略的方法依赖于动作或参数的探索策略，本文旨在提出一种探索无关的解决方案。

**方法:** 引入了C-PG算法，并建立了全局最终迭代收敛保证，在特定噪声模型下可收敛到最优确定性策略。

**结果:** C-PG算法在动作（C-PGAE）和参数（C-PGPE）变体上均表现出色，尤其在训练后部署确定性策略时效果显著。

**结论:** 论文提出了一种探索无关的算法C-PG，并在学习随机（超）策略后关闭随机性以部署确定性策略，展示了其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Deterministic+Policies+with+Policy+Gradients+in+Constrained+Markov+Decision+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05953&send_immediately=true&force_search=false)

**原文摘要:** Constrained Reinforcement Learning (CRL) addresses sequential decision-making
problems where agents are required to achieve goals by maximizing the expected
return while meeting domain-specific constraints. In this setting, policy-based
methods are widely used thanks to their advantages when dealing with
continuous-control problems. These methods search in the policy space with an
action-based or a parameter-based exploration strategy, depending on whether
they learn the parameters of a stochastic policy or those of a stochastic
hyperpolicy. We introduce an exploration-agnostic algorithm, called C-PG, which
enjoys global last-iterate convergence guarantees under gradient domination
assumptions. Furthermore, under specific noise models where the (hyper)policy
is expressed as a stochastic perturbation of the actions or of the parameters
of an underlying deterministic policy, we additionally establish global
last-iterate convergence guarantees of C-PG to the optimal deterministic
policy. This holds when learning a stochastic (hyper)policy and subsequently
switching off the stochasticity at the end of training, thereby deploying a
deterministic policy. Finally, we empirically validate both the action-based
(C-PGAE) and parameter-based (C-PGPE) variants of C-PG on constrained control
tasks, and compare them against state-of-the-art baselines, demonstrating their
effectiveness, in particular when deploying deterministic policies after
training.

</details>


### [98] [Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization](https://arxiv.org/abs/2506.05957)
*Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen*

**主要类别:** cs.LG

**AI概要:** 本文提出PrunE，一种基于剪枝的图OOD方法，通过去除虚假边提升模型泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图神经网络在分布外（OOD）场景下表现不佳，直接识别不变子图具有挑战性且容易出错。

**方法:** PrunE引入了两种正则化项：图大小约束和ε概率对齐，以剪枝虚假边并保留不变子图。

**结果:** PrunE在理论分析和实验中均显示出优越的OOD性能。

**结论:** PrunE通过剪枝虚假边来提高图神经网络的OOD泛化能力，优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pruning+Spurious+Subgraphs+for+Graph+Out-of-Distribtuion+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05957，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05957&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) often encounter significant performance
degradation under distribution shifts between training and test data, hindering
their applicability in real-world scenarios. Recent studies have proposed
various methods to address the out-of-distribution generalization challenge,
with many methods in the graph domain focusing on directly identifying an
invariant subgraph that is predictive of the target label. However, we argue
that identifying the edges from the invariant subgraph directly is challenging
and error-prone, especially when some spurious edges exhibit strong
correlations with the targets. In this paper, we propose PrunE, the first
pruning-based graph OOD method that eliminates spurious edges to improve OOD
generalizability. By pruning spurious edges, \mine{} retains the invariant
subgraph more comprehensively, which is critical for OOD generalization.
Specifically, PrunE employs two regularization terms to prune spurious edges:
1) graph size constraint to exclude uninformative spurious edges, and 2)
$\epsilon$-probability alignment to further suppress the occurrence of spurious
edges. Through theoretical analysis and extensive experiments, we show that
PrunE achieves superior OOD performance and outperforms previous
state-of-the-art methods significantly. Codes are available at:
\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.

</details>


### [99] [AQUATIC-Diff: Additive Quantization for Truly Tiny Compressed Diffusion Models](https://arxiv.org/abs/2506.05960)
*Adil Hasan, Thomas Peyrin*

**主要类别:** cs.LG

**AI概要:** This paper introduces codebook-based additive vector quantization to compress diffusion models, achieving state-of-the-art performance on low-bit quantization benchmarks while reducing computational costs through efficient inference.


<details>
  <summary>更多</summary>
  
**动机:** diffusion models are resource-intensive, limiting their mass-market adoption; current quantization methods have mostly explored USQ, while VQ has proven successful in LLMs.

**方法:** applied codebook-based additive vector quantization to diffusion model compression and used an efficient inference kernel for FLOPs savings.

**结果:** achieved a new Pareto frontier in extremely low-bit weight quantization on LDM-4 benchmark; improved sFID by 1.92 points at W4A8 and achieved best-reported FID, sFID, and ISC results at W2A8.

**结论:** codebook-based additive vector quantization can significantly improve diffusion model compression, achieving better performance than full-precision models at low bit widths.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AQUATIC-Diff%3A+Additive+Quantization+for+Truly+Tiny+Compressed+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05960，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05960&send_immediately=true&force_search=false)

**原文摘要:** Significant investments have been made towards the commodification of
diffusion models for generation of diverse media. Their mass-market adoption is
however still hobbled by the intense hardware resource requirements of
diffusion model inference. Model quantization strategies tailored specifically
towards diffusion models have been useful in easing this burden, yet have
generally explored the Uniform Scalar Quantization (USQ) family of quantization
methods. In contrast, Vector Quantization (VQ) methods, which operate on groups
of multiple related weights as the basic unit of compression, have seen
substantial success in Large Language Model (LLM) quantization. In this work,
we apply codebook-based additive vector quantization to the problem of
diffusion model compression. Our resulting approach achieves a new Pareto
frontier for the extremely low-bit weight quantization on the standard
class-conditional benchmark of LDM-4 on ImageNet at 20 inference time steps.
Notably, we report sFID 1.92 points lower than the full-precision model at W4A8
and the best-reported results for FID, sFID and ISC at W2A8. We are also able
to demonstrate FLOPs savings on arbitrary hardware via an efficient inference
kernel, as opposed to savings resulting from small integer operations which may
lack broad hardware support.

</details>


### [100] [Mitigating Catastrophic Forgetting with Adaptive Transformer Block Expansion in Federated Fine-Tuning](https://arxiv.org/abs/2506.05977)
*Yujia Huo, Jianchun Liu, Hongli Xu, Zhenguo Ma, Shilong Wang, Liusheng Huang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为FedBE的联邦微调框架，通过引入可扩展的模型结构和动态分配策略，有效解决了大规模语言模型在联邦学习环境下的灾难性遗忘问题，并提升了模型的泛化能力和收敛速度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦微调方法在处理分布式环境中持续适应所带来的灾难性遗忘问题时效果不佳，且难以应对客户间数据分布和设备能力的异质性，因此需要一种更有效的解决方案。

**方法:** FedBE结合了自适应Transformer块扩展机制和动态可训练块分配策略，通过在模型结构中扩展可训练模块，将新学到的任务特定知识与原始预训练表示结构性分离，并根据客户端的数据分布和计算能力动态分配这些模块。

**结果:** 实验结果显示，与现有联邦微调方法相比，FedBE在微调后通用任务的准确率保持率提高了12-74%，模型收敛速度加快了1.9-3.1倍，同时未降低下游任务的准确性。

**结论:** FedBE为联邦环境下大规模语言模型的微调提供了一个高效且具有较强适应性的框架，能够有效缓解灾难性遗忘问题并提升模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mitigating+Catastrophic+Forgetting+with+Adaptive+Transformer+Block+Expansion+in+Federated+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05977，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05977&send_immediately=true&force_search=false)

**原文摘要:** Federated fine-tuning (FedFT) of large language models (LLMs) has emerged as
a promising solution for adapting models to distributed data environments while
ensuring data privacy.
  Existing FedFT methods predominantly utilize parameter-efficient fine-tuning
(PEFT) techniques to reduce communication and computation overhead.
  However, they often fail to adequately address the catastrophic forgetting, a
critical challenge arising from continual adaptation in distributed
environments. The traditional centralized fine-tuning methods, which are not
designed for the heterogeneous and privacy-constrained nature of federated
environments, struggle to mitigate this issue effectively. Moreover, the
challenge is further exacerbated by significant variation in data distributions
and device capabilities across clients, which leads to intensified forgetting
and degraded model generalization. To tackle these issues, we propose FedBE, a
novel FedFT framework that integrates an adaptive transformer block expansion
mechanism with a dynamic trainable-block allocation strategy. Specifically,
FedBE expands trainable blocks within the model architecture, structurally
separating newly learned task-specific knowledge from the original pre-trained
representations. Additionally, FedBE dynamically assigns these trainable blocks
to clients based on their data distributions and computational capabilities.
This enables the framework to better accommodate heterogeneous federated
environments and enhances the generalization ability of the model.Extensive
experiments show that compared with existing federated fine-tuning methods,
FedBE achieves 12-74% higher accuracy retention on general tasks after
fine-tuning and a model convergence acceleration ratio of 1.9-3.1x without
degrading the accuracy of downstream tasks.

</details>


### [101] [Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning](https://arxiv.org/abs/2506.05985)
*Yuheng Lei, Sitong Mao, Shunbo Zhou, Hongyuan Zhang, Xuelong Li, Ping Luo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为DMPEL的新方法，用于解决通用代理在其生命周期内不断学习和适应的问题，通过逐步学习低秩专家库和使用轻量级路由器动态组合专家，以实现高效的前向传输并最小化灾难性遗忘。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决通用代理需要在其生命周期内不断学习和适应的问题，同时实现高效的前向传输并最小化灾难性遗忘。

**方法:** 动态混合渐进式参数高效专家库（DMPEL）逐步学习低秩专家库，并采用轻量级路由器动态地将专家组合成端到端策略。

**结果:** 实验结果显示，该框架在LIBERO终身操作基准上表现优异，证明了其在减少灾难性遗忘方面的有效性。

**结论:** DMPEL方法在持续适应中利用最小的可训练参数和存储，优于最先进的终身学习方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Mixture+of+Progressive+Parameter-Efficient+Expert+Library+for+Lifelong+Robot+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05985，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05985&send_immediately=true&force_search=false)

**原文摘要:** A generalist agent must continuously learn and adapt throughout its lifetime,
achieving efficient forward transfer while minimizing catastrophic forgetting.
Previous work within the dominant pretrain-then-finetune paradigm has explored
parameter-efficient fine-tuning for single-task adaptation, effectively
steering a frozen pretrained model with a small number of parameters. However,
in the context of lifelong learning, these methods rely on the impractical
assumption of a test-time task identifier and restrict knowledge sharing among
isolated adapters. To address these limitations, we propose Dynamic Mixture of
Progressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot
learning. DMPEL progressively learn a low-rank expert library and employs a
lightweight router to dynamically combine experts into an end-to-end policy,
facilitating flexible behavior during lifelong adaptation. Moreover, by
leveraging the modular structure of the fine-tuned parameters, we introduce
coefficient replay to guide the router in accurately retrieving frozen experts
for previously encountered tasks, thereby mitigating catastrophic forgetting.
This method is significantly more storage- and computationally-efficient than
applying demonstration replay to the entire policy. Extensive experiments on
the lifelong manipulation benchmark LIBERO demonstrate that our framework
outperforms state-of-the-art lifelong learning methods in success rates across
continual adaptation, while utilizing minimal trainable parameters and storage.

</details>


### [102] [RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory](https://arxiv.org/abs/2506.05994)
*Yi-Chun Liao, Chieh-Lin Tsai, Yuan-Hao Chang, Camélia Slimani, Jalil Boukhobza, Tei-Wei Kuo*

**主要类别:** cs.LG

**AI概要:** 本文介绍RETENTION框架，通过迭代剪枝算法和树映射方案显著减少基于树模型推理所需的CAM容量需求，提高空间效率并保持高准确率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管深度学习在非结构化数据上表现出色，现代基于树的集成模型在处理结构化数据方面仍然占优。然而，现有基于内容寻址存储（CAM）的设计存在过度内存消耗和低利用率的问题，因此需要一种新的解决方案来加速基于树的模型。

**方法:** 提出了一种迭代剪枝算法和一种树映射方案，其中树映射方案包括两种创新的数据放置策略，以减少由于在CAM中广泛使用“无关状态”造成的内存冗余。

**结果:** 实验结果显示，仅实施树映射方案可实现1.46倍至21.30倍的空间效率提升，而完整的RETENTION框架可在准确率损失小于3%的情况下带来4.35倍至207.12倍的改进。

**结论:** 论文提出了一种名为RETENTION的端到端框架，有效减少了基于树模型推理所需的CAM容量需求，同时保持了较高的准确率，为基于树的模型加速提供了资源高效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RETENTION%3A+Resource-Efficient+Tree-Based+Ensemble+Model+Acceleration+with+Content-Addressable+Memory，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05994，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05994&send_immediately=true&force_search=false)

**原文摘要:** Although deep learning has demonstrated remarkable capabilities in learning
from unstructured data, modern tree-based ensemble models remain superior in
extracting relevant information and learning from structured datasets. While
several efforts have been made to accelerate tree-based models, the inherent
characteristics of the models pose significant challenges for conventional
accelerators. Recent research leveraging content-addressable memory (CAM)
offers a promising solution for accelerating tree-based models, yet existing
designs suffer from excessive memory consumption and low utilization. This work
addresses these challenges by introducing RETENTION, an end-to-end framework
that significantly reduces CAM capacity requirement for tree-based model
inference. We propose an iterative pruning algorithm with a novel pruning
criterion tailored for bagging-based models (e.g., Random Forest), which
minimizes model complexity while ensuring controlled accuracy degradation.
Additionally, we present a tree mapping scheme that incorporates two innovative
data placement strategies to alleviate the memory redundancy caused by the
widespread use of don't care states in CAM. Experimental results show that
implementing the tree mapping scheme alone achieves $1.46\times$ to $21.30
\times$ better space efficiency, while the full RETENTION framework yields
$4.35\times$ to $207.12\times$ improvement with less than 3% accuracy loss.
These results demonstrate that RETENTION is highly effective in reducing CAM
capacity requirement, providing a resource-efficient direction for tree-based
model acceleration.

</details>


### [103] [Machine learning for in-situ composition mapping in a self-driving magnetron sputtering system](https://arxiv.org/abs/2506.05999)
*Sanna Jarl, Jens Sjölund, Robert J. W. Frost, Anders Holst, Jonathan J. S. Scragg*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种基于机器学习的自驱动实验室新方法，用于快速预测多元素薄膜的成分分布，从而加速材料发现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自驱动实验室主要受限于溶液基合成方法，而无法覆盖更广泛的无机材料化学空间，因此需要开发新的方法。

**方法:** 通过使用组合框架和机器学习方法（高斯过程），结合原位传感器数据，预测多元素组合薄膜的成分分布。

**结果:** 开发的ML驱动方法能够在10次实验内学习沉积速率，准确预测成分分布，并显著提高实验通量。

**结论:** 该论文提出了一种基于磁控共溅射的自驱动实验室(SDL)框架，并展示了其在材料探索中加速实验过程的巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+learning+for+in-situ+composition+mapping+in+a+self-driving+magnetron+sputtering+system，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05999，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05999&send_immediately=true&force_search=false)

**原文摘要:** Self-driving labs (SDLs), employing automation and machine learning (ML) to
accelerate experimental procedures, have enormous potential in the discovery of
new materials. However, in thin film science, SDLs are mainly restricted to
solution-based synthetic methods which are easier to automate but cannot access
the broad chemical space of inorganic materials. This work presents an SDL
based on magnetron co-sputtering. We are using combinatorial frameworks,
obtaining accurate composition maps on multi-element, compositionally graded
thin films. This normally requires time-consuming ex-situ analysis prone to
systematic errors. We present a rapid and calibration-free in-situ, ML driven
approach to produce composition maps for arbitrary source combinations and
sputtering conditions. We develop a method to predict the composition
distribution in a multi-element combinatorial thin film, using in-situ
measurements from quartz-crystal microbalance sensors placed in a sputter
chamber. For a given source, the sensor readings are learned as a function of
the sputtering pressure and magnetron power, through active learning using
Gaussian processes (GPs). The final GPs are combined with a geometric model of
the deposition flux distribution in the chamber, which allows interpolation of
the deposition rates from each source, at any position across the sample. We
investigate several acquisition functions for the ML procedure. A fully
Bayesian GP - BALM (Bayesian active learning MacKay) - achieved the best
performance, learning the deposition rates for a single source in 10
experiments. Prediction accuracy for co-sputtering composition distributions
was verified experimentally. Our framework dramatically increases throughput by
avoiding the need for extensive characterisation or calibration, thus
demonstrating the potential of ML-guided SDLs to accelerate materials
exploration.

</details>


### [104] [LaDEEP: A Deep Learning-based Surrogate Model for Large Deformation of Elastic-Plastic Solids](https://arxiv.org/abs/2506.06001)
*Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一个名为LaDEEP的深度学习模型，该模型能够高效且准确地模拟弹性塑性固体的大变形。


<details>
  <summary>更多</summary>
  
**动机:** 传统的数值求解器在准确性和效率之间存在固有折衷，而现有的深度学习模型难以准确处理涉及接触、加载和卸载的复杂弹性塑性固体。

**方法:** LaDEEP采用了一种基于Transformer的两阶段模块，将涉及的细长固体的分区区域编码成标记序列，并使用该序列预测变形。

**结果:** LaDEEP的速度比有限元方法快五个数量级，并且平均相对改进了20.47%。

**结论:** LaDEEP是一个基于深度学习的替代模型，用于弹性塑性固体的大变形仿真，在速度和准确性方面优于有限元方法和其他深度学习基线。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LaDEEP%3A+A+Deep+Learning-based+Surrogate+Model+for+Large+Deformation+of+Elastic-Plastic+Solids，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06001，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06001&send_immediately=true&force_search=false)

**原文摘要:** Scientific computing for large deformation of elastic-plastic solids is
critical for numerous real-world applications. Classical numerical solvers rely
primarily on local discrete linear approximation and are constrained by an
inherent trade-off between accuracy and efficiency. Recently, deep learning
models have achieved impressive progress in solving the continuum mechanism.
While previous models have explored various architectures and constructed
coefficient-solution mappings, they are designed for general instances without
considering specific problem properties and hard to accurately handle with
complex elastic-plastic solids involving contact, loading and unloading. In
this work, we take stretch bending, a popular metal fabrication technique, as
our case study and introduce LaDEEP, a deep learning-based surrogate model for
\textbf{La}rge \textbf{De}formation of \textbf{E}lastic-\textbf{P}lastic
Solids. We encode the partitioned regions of the involved slender solids into a
token sequence to maintain their essential order property. To characterize the
physical process of the solid deformation, a two-stage Transformer-based module
is designed to predict the deformation with the sequence of tokens as input.
Empirically, LaDEEP achieves five magnitudes faster speed than finite element
methods with a comparable accuracy, and gains 20.47\% relative improvement on
average compared to other deep learning baselines. We have also deployed our
model into a real-world industrial production system, and it has shown
remarkable performance in both accuracy and efficiency.

</details>


### [105] [What Really is a Member? Discrediting Membership Inference via Poisoning](https://arxiv.org/abs/2506.06003)
*Neal Mangaokar, Ashish Hooda, Zhuohang Li, Bradley A. Malin, Kassem Fawaz, Somesh Jha, Atul Prakash, Amrita Roy Chowdhury*

**主要类别:** cs.LG

**AI概要:** This paper shows that membership inference tests for language models are unreliable even when the definition of membership is relaxed. The authors present a poisoning attack that can degrade the performance of these tests.


<details>
  <summary>更多</summary>
  
**动机:** Recent works have shown that membership inference tests often fail under the strict definition of membership based on exact matching. This has led to suggestions of relaxing the definition to include semantic neighbors as members.

**方法:** The paper theoretically analyzes the trade-off between a test's accuracy and its robustness to poisoning, and presents a concrete instantiation of a poisoning attack.

**结果:** The paper shows that membership inference tests can be poisoned in a way that causes the test to produce incorrect predictions for a target point, degrading the performance of existing tests to well below random.

**结论:** Membership inference tests are unreliable even when the definition of membership is relaxed to include semantic neighbors.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Really+is+a+Member%3F+Discrediting+Membership+Inference+via+Poisoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06003，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06003&send_immediately=true&force_search=false)

**原文摘要:** Membership inference tests aim to determine whether a particular data point
was included in a language model's training set. However, recent works have
shown that such tests often fail under the strict definition of membership
based on exact matching, and have suggested relaxing this definition to include
semantic neighbors as members as well. In this work, we show that membership
inference tests are still unreliable under this relaxation - it is possible to
poison the training dataset in a way that causes the test to produce incorrect
predictions for a target point. We theoretically reveal a trade-off between a
test's accuracy and its robustness to poisoning. We also present a concrete
instantiation of this poisoning attack and empirically validate its
effectiveness. Our results show that it can degrade the performance of existing
tests to well below random.

</details>


### [106] [LightGTS: A Lightweight General Time Series Forecasting Model](https://arxiv.org/abs/2506.06005)
*Yihang Wang, Yuying Qiu, Peng Chen, Yang Shu, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种高效的通用时间序列预测模型LightGTS，通过充分挖掘时间序列的周期性特征，在保持高性能的同时降低了计算开销。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列预测模型参数多、计算负担重，在资源受限场景下存在局限性。

**方法:** 提出了Periodical Tokenization和Periodical Parallel Decoding两种技术，并基于周期性归纳偏置设计了轻量级模型LightGTS。

**结果:** LightGTS在9个真实世界基准数据集的zero-shot和full-shot设置中均实现了最先进的预测性能。

**结论:** LightGTS在通用时间序列预测任务中表现出色，相比现有模型更加高效。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LightGTS%3A+A+Lightweight+General+Time+Series+Forecasting+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06005，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06005&send_immediately=true&force_search=false)

**原文摘要:** Existing works on general time series forecasting build foundation models
with heavy model parameters through large-scale multi-source pre-training.
These models achieve superior generalization ability across various datasets at
the cost of significant computational burdens and limitations in
resource-constrained scenarios. This paper introduces LightGTS, a lightweight
general time series forecasting model designed from the perspective of
consistent periodical modeling. To handle diverse scales and intrinsic periods
in multi-source pre-training, we introduce Periodical Tokenization, which
extracts consistent periodic patterns across different datasets with varying
scales. To better utilize the periodicity in the decoding process, we further
introduce Periodical Parallel Decoding, which leverages historical tokens to
improve forecasting. Based on the two techniques above which fully leverage the
inductive bias of periods inherent in time series, LightGTS uses a lightweight
model to achieve outstanding performance on general time series forecasting. It
achieves state-of-the-art forecasting performance on 9 real-world benchmarks in
both zero-shot and full-shot settings with much better efficiency compared with
existing time series foundation models.

</details>


### [107] [Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems](https://arxiv.org/abs/2506.06021)
*Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Unisoma的显式建模方法，用于处理多固体系统的复杂相互作用，相较于传统隐式建模方法，在多个任务和数据集中表现更优。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度学习方法主要依赖于隐式建模，难以准确捕捉多固体系统中复杂的物理相互作用，尤其是在固体数量增加时效果不佳。

**方法:** 提出了基于Transformer的统一且灵活的模型Unisoma，通过接触模块和自适应交互分配机制直接捕捉物理相互作用，并使用三元组关系学习变形。

**结果:** Unisoma在七个已建立的数据集和两个复杂的多固体任务中均取得了最先进的性能。

**结论:** Unisoma是一种适用于多固体系统的显式建模范式，能够有效解决现有隐式建模方法在复杂耦合模式下表现不佳的问题，并且在多个数据集和任务上实现了最先进的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unisoma%3A+A+Unified+Transformer-based+Solver+for+Multi-Solid+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06021，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06021&send_immediately=true&force_search=false)

**原文摘要:** Multi-solid systems are foundational to a wide range of real-world
applications, yet modeling their complex interactions remains challenging.
Existing deep learning methods predominantly rely on implicit modeling, where
the factors influencing solid deformation are not explicitly represented but
are instead indirectly learned. However, as the number of solids increases,
these methods struggle to accurately capture intricate physical interactions.
In this paper, we introduce a novel explicit modeling paradigm that
incorporates factors influencing solid deformation through structured modules.
Specifically, we present Unisoma, a unified and flexible Transformer-based
model capable of handling variable numbers of solids. Unisoma directly captures
physical interactions using contact modules and adaptive interaction allocation
mechanism, and learns the deformation through a triplet relationship. Compared
to implicit modeling techniques, explicit modeling is more well-suited for
multi-solid systems with diverse coupling patterns, as it enables detailed
treatment of each solid while preventing information blending and confusion.
Experimentally, Unisoma achieves consistent state-of-the-art performance across
seven well-established datasets and two complex multi-solid tasks. Code is
avaiable at \href{this link}{https://github.com/therontau0054/Unisoma}.

</details>


### [108] [Do-PFN: In-Context Learning for Causal Effect Estimation](https://arxiv.org/abs/2506.06039)
*Jake Robertson, Arik Reuter, Siyuan Guo, Noah Hollmann, Frank Hutter, Bernhard Schölkopf*

**主要类别:** cs.LG

**AI概要:** Prior-data fitted networks (PFNs) 被用于因果效应估计，通过预训练在合成数据上实现高精度的估计，而无需了解真实的因果结构。


<details>
  <summary>更多</summary>
  
**动机:** 现有的因果效应估计方法需要干预数据、对真实因果图的了解或依赖于诸如无混杂因素等假设，这限制了它们在现实世界中的适用性。因此，需要一种新的方法来克服这些问题。

**方法:** 通过使用 Prior-data fitted networks (PFNs)，在具有广泛因果结构的合成数据上进行预训练，以通过上下文学习来预测干预结果。

**结果:** 该方法在合成案例研究中展示了准确估计因果效应的能力，并表现出良好的可扩展性和鲁棒性。

**结论:** Prior-data fitted networks (PFNs) 可以通过在合成数据上进行预训练，有效地解决因果效应估计问题，并且不需要底层因果图的知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Do-PFN%3A+In-Context+Learning+for+Causal+Effect+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06039，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06039&send_immediately=true&force_search=false)

**原文摘要:** Estimation of causal effects is critical to a range of scientific
disciplines. Existing methods for this task either require interventional data,
knowledge about the ground truth causal graph, or rely on assumptions such as
unconfoundedness, restricting their applicability in real-world settings. In
the domain of tabular machine learning, Prior-data fitted networks (PFNs) have
achieved state-of-the-art predictive performance, having been pre-trained on
synthetic data to solve tabular prediction problems via in-context learning. To
assess whether this can be transferred to the harder problem of causal effect
estimation, we pre-train PFNs on synthetic data drawn from a wide variety of
causal structures, including interventions, to predict interventional outcomes
given observational data. Through extensive experiments on synthetic case
studies, we show that our approach allows for the accurate estimation of causal
effects without knowledge of the underlying causal graph. We also perform
ablation studies that elucidate Do-PFN's scalability and robustness across
datasets with a variety of causal characteristics.

</details>


### [109] [Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics](https://arxiv.org/abs/2506.06045)
*Tobias Würth, Niklas Freymuth, Gerhard Neumann, Luise Kärger*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为ROBIN的新颖学习模拟器，通过Rolling Diffusion和分层图神经网络的结合，在处理物理系统模拟时实现了更高的准确性和效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于图的学习模拟器难以捕捉全局现象（如弯曲或长距离相关性），并且由于依赖局部消息传递和直接下一步预测，在长期rollout中存在误差累积问题。

**方法:** 提出了Rolling Diffusion方法和基于代数多重网格粗化的分层图神经网络结构。

**结果:** ROBIN在涉及几何、材料和接触非线性的2D和3D固体力学基准测试中达到了最先进的准确性，并且推理时间比标准扩散模拟器减少了近一个数量级。

**结论:** ROBIN通过引入Rolling Diffusion和分层图神经网络，显著提高了基于图的学习模拟器在处理全局现象和长期rollout中的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion-Based+Hierarchical+Graph+Neural+Networks+for+Simulating+Nonlinear+Solid+Mechanics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06045，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06045&send_immediately=true&force_search=false)

**原文摘要:** Graph-based learned simulators have emerged as a promising approach for
simulating physical systems on unstructured meshes, offering speed and
generalization across diverse geometries. However, they often struggle with
capturing global phenomena, such as bending or long-range correlations, and
suffer from error accumulation over long rollouts due to their reliance on
local message passing and direct next-step prediction. We address these
limitations by introducing the Rolling Diffusion-Batched Inference Network
(ROBIN), a novel learned simulator that integrates two key innovations: (i)
Rolling Diffusion, a parallelized inference scheme that amortizes the cost of
diffusion-based refinement across physical time steps by overlapping denoising
steps across a temporal window. (ii) A Hierarchical Graph Neural Network built
on algebraic multigrid coarsening, enabling multiscale message passing across
different mesh resolutions. This architecture, implemented via
Algebraic-hierarchical Message Passing Networks, captures both fine-scale local
dynamics and global structural effects critical for phenomena like beam bending
or multi-body contact. We validate ROBIN on challenging 2D and 3D solid
mechanics benchmarks involving geometric, material, and contact nonlinearities.
ROBIN achieves state-of-the-art accuracy on all tasks, substantially
outperforming existing next-step learned simulators while reducing inference
time by up to an order of magnitude compared to standard diffusion simulators.

</details>


### [110] [System-Aware Unlearning Algorithms: Use Lesser, Forget Faster](https://arxiv.org/abs/2506.06073)
*Linda Lu, Ayush Sekhari, Karthik Sridharan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的遗忘学习定义“system-aware unlearning”，并通过选择性抽样方法实现了线性分类的精确遗忘学习算法，同时理论上分析了删除容量、准确性、内存和计算时间之间的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 传统的遗忘学习定义假设极端攻击者可以恢复所有未被删除的数据，这在现实中不切实际。因此需要一种更合理的遗忘学习定义来提高效率与安全性。

**方法:** 提出system-aware unlearning定义，并基于选择性抽样设计遗忘学习算法，进一步将方法扩展到通用函数类的分类任务。

**结果:** 开发了适用于线性分类的精确遗忘学习算法，并理论分析了删除容量、准确性、内存占用和计算时间之间的权衡。

**结论:** 通过新定义的system-aware unlearning和相应的算法设计，可以在更现实的攻击假设下实现高效且安全的遗忘学习。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是System-Aware+Unlearning+Algorithms%3A+Use+Lesser%2C+Forget+Faster，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06073，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06073&send_immediately=true&force_search=false)

**原文摘要:** Machine unlearning addresses the problem of updating a machine learning
model/system trained on a dataset $S$ so that the influence of a set of
deletion requests $U \subseteq S$ on the unlearned model is minimized. The gold
standard definition of unlearning demands that the updated model, after
deletion, be nearly identical to the model obtained by retraining. This
definition is designed for a worst-case attacker (one who can recover not only
the unlearned model but also the remaining data samples, i.e., $S \setminus
U$). Such a stringent definition has made developing efficient unlearning
algorithms challenging. However, such strong attackers are also unrealistic. In
this work, we propose a new definition, system-aware unlearning, which aims to
provide unlearning guarantees against an attacker that can at best only gain
access to the data stored in the system for learning/unlearning requests and
not all of $S\setminus U$. With this new definition, we use the simple
intuition that if a system can store less to make its learning/unlearning
updates, it can be more secure and update more efficiently against a
system-aware attacker. Towards that end, we present an exact system-aware
unlearning algorithm for linear classification using a selective sampling-based
approach, and we generalize the method for classification with general function
classes. We theoretically analyze the tradeoffs between deletion capacity,
accuracy, memory, and computation time.

</details>


### [111] [Flexible Operator Fusion for Fast Sparse Transformer with Diverse Masking on GPU](https://arxiv.org/abs/2506.06095)
*Wenhao Dai, Haodong Deng, Mengfei Rong, Xinyu Yang, Hongyu Liu, Fangxin Liu, Hailong Yang, Weifeng Liu, Qingxiao Sun*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种用于优化稀疏Transformer的新框架STOF，它通过灵活的掩码技术和操作融合提高了性能，在MHA计算和端到端推理中都取得了显著的速度提升。


<details>
  <summary>更多</summary>
  
**动机:** 为了应对稀疏Transformer性能优化不足以及基于规则机制无法适应各种序列长度的问题，研究者提出了STOF。

**方法:** 提出了一种名为STOF的框架，通过灵活的掩码技术和操作融合来优化稀疏Transformer，并通过两阶段搜索引擎确定最佳参数设置。

**结果:** 实验结果表明，与最先进的工作相比，STOF在MHA计算和端到端推理中均实现了显著的速度提升。

**结论:** STOF在MHA计算和端到端推理中分别实现了最高1.7倍和1.5倍的速度提升，证明了其在稀疏Transformer性能优化方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Flexible+Operator+Fusion+for+Fast+Sparse+Transformer+with+Diverse+Masking+on+GPU，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06095，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06095&send_immediately=true&force_search=false)

**原文摘要:** Large language models are popular around the world due to their powerful
understanding capabilities. As the core component of LLMs, accelerating
Transformer through parallelization has gradually become a hot research topic.
Mask layers introduce sparsity into Transformer to reduce calculations.
However, previous works rarely focus on the performance optimization of sparse
Transformer. Moreover, rule-based mechanisms ignore the fusion opportunities of
mixed-type operators and fail to adapt to various sequence lengths. To address
the above problems, we propose STOF, a framework that incorporates
optimizations for Sparse Transformer via flexible masking and operator fusion
on GPU. We firstly unify the storage format and kernel implementation for the
multi-head attention. Then, we map fusion schemes to compilation templates and
determine the optimal parameter setting through a two-stage search engine. The
experimental results show that compared to the state-of-the-art work, STOF
achieves maximum speedups of 1.7x in MHA computation and 1.5x in end-to-end
inference.

</details>


### [112] [Synthetic Tabular Data: Methods, Attacks and Defenses](https://arxiv.org/abs/2506.06108)
*Graham Cormode, Samuel Maddock, Enayat Ullah, Shripad Gade*

**主要类别:** cs.LG

**AI概要:** 这篇论文综述了表格合成数据生成的发展历程、主要方法及其局限性，并指出了未来的研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 该论文旨在总结过去十年中合成数据生成领域的进展，特别是在机器学习和数据分析方面的应用，同时探讨其局限性和未来的研究方向。

**方法:** 该论文通过综述的方式对表格合成数据生成的关键发展和主要概念进行了深入探讨，并分析了其局限性。

**结果:** 论文回顾了基于概率图模型和深度学习的合成数据生成方法，讨论了攻击如何获取原始敏感数据信息，并提出了扩展和开放问题。

**结论:** 这篇论文得出的结论是合成数据在解决隐私问题方面具有潜力，但也存在局限性，需要进一步研究和改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Synthetic+Tabular+Data%3A+Methods%2C+Attacks+and+Defenses，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06108，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06108&send_immediately=true&force_search=false)

**原文摘要:** Synthetic data is often positioned as a solution to replace sensitive
fixed-size datasets with a source of unlimited matching data, freed from
privacy concerns. There has been much progress in synthetic data generation
over the last decade, leveraging corresponding advances in machine learning and
data analytics. In this survey, we cover the key developments and the main
concepts in tabular synthetic data generation, including paradigms based on
probabilistic graphical models and on deep learning. We provide background and
motivation, before giving a technical deep-dive into the methodologies. We also
address the limitations of synthetic data, by studying attacks that seek to
retrieve information about the original sensitive data. Finally, we present
extensions and open problems in this area.

</details>


### [113] [Scalable unsupervised feature selection via weight stability](https://arxiv.org/abs/2506.06114)
*Xudong Zhang, Renato Cordeiro de Amorim*

**主要类别:** cs.LG

**AI概要:** 该研究开发了新的无监督特征选择技术，提高了高维数据下的聚类分析效果。


<details>
  <summary>更多</summary>
  
**动机:** 高维数据中的不相关特征可能会掩盖有意义的结构，因此需要改进无监督特征选择以提高聚类性能。

**方法:** 论文中介绍了FS-MWK++和SFS-MWK++两种新特征选择算法，并通过理论保证和实验验证其效果。

**结果:** 实验结果表明，所提出的特征选择方法在多种情况下均优于现有替代方法，并能识别出稳定且信息丰富的特征。

**结论:** 本文提出了一种新的无监督特征选择方法，通过使用Minkowski加权k均值++初始化策略，能够有效地提高聚类性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+unsupervised+feature+selection+via+weight+stability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06114&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised feature selection is critical for improving clustering
performance in high-dimensional data, where irrelevant features can obscure
meaningful structure. In this work, we introduce the Minkowski weighted
$k$-means++, a novel initialisation strategy for the Minkowski Weighted
$k$-means. Our initialisation selects centroids probabilistically using feature
relevance estimates derived from the data itself. Building on this, we propose
two new feature selection algorithms, FS-MWK++, which aggregates feature
weights across a range of Minkowski exponents to identify stable and
informative features, and SFS-MWK++, a scalable variant based on subsampling.
We support our approach with a theoretical guarantee under mild assumptions and
extensive experiments showing that our methods consistently outperform existing
alternatives.

</details>


### [114] [Reinforcement Learning Optimization for Large-Scale Learning: An Efficient and User-Friendly Scaling Library](https://arxiv.org/abs/2506.06122)
*Weixun Wang, Shaopan Xiong, Gengru Chen, Wei Gao, Sheng Guo, Yancheng He, Ju Huang, Jiaheng Liu, Zhendong Li, Xiaoyang Li, Zichen Liu, Haizhou Zhao, Dakai An, Lunxi Cao, Qiyang Cao, Wanxi Deng, Feilei Du, Yiliang Gu, Jiahe Li, Xiang Li, Mingjie Liu, Yijia Luo, Zihe Liu, Yadao Wang, Pei Wang, Tianyuan Wu, Yanan Wu, Yuheng Zhao, Shuaibing Zhao, Jin Yang, Siran Yang, Yingshui Tan, Huimin Yi, Yuchi Xu, Yujin Yuan, Xingyao Zhang, Lin Qu, Wenbo Su, Wei Wang, Jiamang Wang, Bo Zheng*

**主要类别:** cs.LG

**AI概要:** ROLL 是一个高效、可扩展且用户友好的强化学习优化库，专为大规模学习设计，具备灵活的训练流程控制和快速实验支持。


<details>
  <summary>更多</summary>
  
**动机:** 为了满足不同用户群体在成本效益、容错性、灵活性和实验敏捷性方面的需求，需要开发一个专门针对大规模强化学习的优化库。

**方法:** ROLL 基于单控制器架构，并通过模块化设计（如并行策略、数据传输模块、rollout 调度器和 AutoDeviceMapping）提高训练效率与资源管理灵活性。

**结果:** ROLL 提供了高效的训练流程管理、灵活的资源分配以及对 agentic RL 算法和奖励设计的快速实验支持。

**结论:** ROLL 成功实现了大规模强化学习中的高效、可扩展和用户友好型训练，适用于技术先驱、开发者和研究人员。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+Optimization+for+Large-Scale+Learning%3A+An+Efficient+and+User-Friendly+Scaling+Library，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06122，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06122&send_immediately=true&force_search=false)

**原文摘要:** We introduce ROLL, an efficient, scalable, and user-friendly library designed
for Reinforcement Learning Optimization for Large-scale Learning. ROLL caters
to three primary user groups: tech pioneers aiming for cost-effective,
fault-tolerant large-scale training, developers requiring flexible control over
training workflows, and researchers seeking agile experimentation. ROLL is
built upon several key modules to serve these user groups effectively. First, a
single-controller architecture combined with an abstraction of the parallel
worker simplifies the development of the training pipeline. Second, the
parallel strategy and data transfer modules enable efficient and scalable
training. Third, the rollout scheduler offers fine-grained management of each
sample's lifecycle during the rollout stage. Fourth, the environment worker and
reward worker support rapid and flexible experimentation with agentic RL
algorithms and reward designs. Finally, AutoDeviceMapping allows users to
assign resources to different models flexibly across various stages.

</details>


### [115] [Flow-Attentional Graph Neural Networks](https://arxiv.org/abs/2506.06127)
*Pascal Plettenberg, Dominik Köhler, Bernhard Sick, Josephine M. Thomas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种满足基尔霍夫第一定律的流量注意力机制，用于改进图神经网络（GNN）在物理资源流动数据上的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图神经网络没有考虑与物理资源流动相关的守恒定律，这可能导致模型性能下降。

**方法:** 提出了流量注意力机制，将现有的图注意力机制改编为满足基尔霍夫第一定律。

**结果:** 通过实验表明，这种新方法在两个流量图数据集（电子电路和电网）上提升了基于注意力机制的图神经网络在图级别分类和回归任务上的性能。

**结论:** 流量注意力机制能够提高图神经网络在处理涉及物理资源流动的图结构数据中的表现，并且可以区分一些标准注意力机制无法辨别的非同构图集合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Flow-Attentional+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06127，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06127&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have become essential for learning from
graph-structured data. However, existing GNNs do not consider the conservation
law inherent in graphs associated with a flow of physical resources, such as
electrical current in power grids or traffic in transportation networks, which
can lead to reduced model performance. To address this, we propose flow
attention, which adapts existing graph attention mechanisms to satisfy
Kirchhoff\'s first law. Furthermore, we discuss how this modification
influences the expressivity and identify sets of non-isomorphic graphs that can
be discriminated by flow attention but not by standard attention. Through
extensive experiments on two flow graph datasets (electronic circuits and power
grids), we demonstrate that flow attention enhances the performance of
attention-based GNNs on both graph-level classification and regression tasks.

</details>


### [116] [Gradient Similarity Surgery in Multi-Task Deep Learning](https://arxiv.org/abs/2506.06130)
*Thomas Borsani, Andrea Rosani, Giuseppe Nicosia, Giuseppe Di Fatta*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新颖的梯度手术方法(SAM-GS)，用于解决多任务深度学习中的梯度冲突问题，并展示了其在优化学习过程中的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在多任务深度学习中，多个任务可能产生潜在冲突的梯度，影响各种损失函数的并发收敛。设计先进的优化器以提高梯度下降学习规则的收敛速度和稳定性是一个重大挑战。

**方法:** 提出了一种新的梯度手术方法，即基于梯度大小相似性测量的相似性感知动量梯度手术(SAM-GS)，采用梯度均衡和一阶动量调制。

**结果:** 一系列实验测试显示了SAM-GS在合成问题和多任务学习基准上的有效性。

**结论:** SAM-GS方法在多任务深度学习中通过梯度大小相似性来规范梯度聚合，从而优化学习过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gradient+Similarity+Surgery+in+Multi-Task+Deep+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06130&send_immediately=true&force_search=false)

**原文摘要:** The multi-task learning ($MTL$) paradigm aims to simultaneously learn
multiple tasks within a single model capturing higher-level, more general
hidden patterns that are shared by the tasks. In deep learning, a significant
challenge in the backpropagation training process is the design of advanced
optimisers to improve the convergence speed and stability of the gradient
descent learning rule. In particular, in multi-task deep learning ($MTDL$) the
multitude of tasks may generate potentially conflicting gradients that would
hinder the concurrent convergence of the diverse loss functions. This challenge
arises when the gradients of the task objectives have either different
magnitudes or opposite directions, causing one or a few to dominate or to
interfere with each other, thus degrading the training process. Gradient
surgery methods address the problem explicitly dealing with conflicting
gradients by adjusting the overall gradient trajectory. This work introduces a
novel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery
(SAM-GS), which provides an effective and scalable approach based on a gradient
magnitude similarity measure to guide the optimisation process. The SAM-GS
surgery adopts gradient equalisation and modulation of the first-order
momentum. A series of experimental tests have shown the effectiveness of SAM-GS
on synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays
a crucial role in regularising gradient aggregation in $MTDL$ for the
optimisation of the learning process.

</details>


### [117] [Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models](https://arxiv.org/abs/2506.06137)
*Rihui Jin, Zheyu Xin, Xing Xie, Zuoyi Li, Guilin Qi, Yongrui Chen, Xinbang Dai, Tongtong Wu, Gholamreza Haffari*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种针对小型语言模型的程序化表格推理方法Table-r1，显著提升了其在表格推理任务中的表现，尤其是在处理异构表格布局和提升推理一致性方面。


<details>
  <summary>更多</summary>
  
**动机:** 由于小型语言模型在表格推理任务中存在局限性，特别是在数值推理和表格布局异构性方面，因此需要一种新的方法来缩小其与大型语言模型之间的差距。

**方法:** 提出了Table-r1，分为两个阶段：第一阶段引入了自监督学习任务Layout Transformation Inference，第二阶段采用了混合范式的Group Relative Policy Optimization，并在必要时动态回退到文本推理（T-TR）。

**结果:** 在四个表格推理基准测试中，Table-r1优于所有基于小型语言模型的方法，在所有数据集中至少比基础模型LLaMA-8B提高了15%的准确率。

**结论:** Table-r1有效提升了小型语言模型在表格推理任务中的性能，达到了与大模型相当的水平。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Table-r1%3A+Self-supervised+and+Reinforcement+Learning+for+Program-based+Table+Reasoning+in+Small+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06137，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06137&send_immediately=true&force_search=false)

**原文摘要:** Table reasoning (TR) requires structured reasoning over semi-structured
tabular data and remains challenging, particularly for small language models
(SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs
(LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR),
which circumvents key limitations of text-based TR (T-TR), notably in numerical
reasoning, by generating executable programs. However, applying P-TR to SLMs
introduces two challenges: (i) vulnerability to heterogeneity in table layouts,
and (ii) inconsistency in reasoning due to limited code generation capability.
We propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1
introduces an innovative self-supervised learning task, Layout Transformation
Inference, to improve tabular layout generalization from a programmatic view.
Stage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization,
enhancing P-TR consistency while allowing dynamic fallback to T-TR when needed.
Experiments on four TR benchmarks demonstrate that Table-r1 outperforms all
SLM-based methods, achieving at least a 15% accuracy improvement over the base
model (LLaMA-8B) across all datasets and reaching performance competitive with
LLMs.

</details>


### [118] [carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks](https://arxiv.org/abs/2506.06143)
*Carolin Benjamins, Helena Graf, Sarah Segel, Difan Deng, Tim Ruhkopf, Leona Hennig, Soham Basu, Neeratyoy Mallik, Edward Bergman, Deyao Chen, François Clément, Matthias Feurer, Katharina Eggensperger, Frank Hutter, Carola Doerr, Marius Lindauer*

**主要类别:** cs.LG

**AI概要:** CARP-S是一个用于超参数优化（HPO）方法评估的综合性基准框架，支持多种任务类型并提供高效的评估方案。


<details>
  <summary>更多</summary>
  
**动机:** 为了简化HPO方法的原型设计与性能比较，需要一个全面且高效的基准测试框架。

**方法:** 该研究提出了一个名为CARP-S的基准测试框架，专注于四种最重要的HPO任务类型，并利用最小化星差异的方法从大规模任务中选取代表性的子集用于高效评估。

**结果:** CARP-S框架提供了3,336个任务以及28种优化器变体的支持，同时提出了一种可扩展的代表性任务子集选择方法，以解决计算资源限制的问题。

**结论:** CARP-S框架通过提供多样化的基准任务和评估方法，为HPO方法的标准化迈出重要一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是carps%3A+A+Framework+for+Comparing+N+Hyperparameter+Optimizers+on+M+Benchmarks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06143，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06143&send_immediately=true&force_search=false)

**原文摘要:** Hyperparameter Optimization (HPO) is crucial to develop well-performing
machine learning models. In order to ease prototyping and benchmarking of HPO
methods, we propose carps, a benchmark framework for Comprehensive Automated
Research Performance Studies allowing to evaluate N optimizers on M benchmark
tasks. In this first release of carps, we focus on the four most important
types of HPO task types: blackbox, multi-fidelity, multi-objective and
multi-fidelity-multi-objective. With 3 336 tasks from 5 community benchmark
collections and 28 variants of 9 optimizer families, we offer the biggest go-to
library to date to evaluate and compare HPO methods. The carps framework relies
on a purpose-built, lightweight interface, gluing together optimizers and
benchmark tasks. It also features an analysis pipeline, facilitating the
evaluation of optimizers on benchmarks. However, navigating a huge number of
tasks while developing and comparing methods can be computationally infeasible.
To address this, we obtain a subset of representative tasks by minimizing the
star discrepancy of the subset, in the space spanned by the full set. As a
result, we propose an initial subset of 10 to 30 diverse tasks for each task
type, and include functionality to re-compute subsets as more benchmarks become
available, enabling efficient evaluations. We also establish a first set of
baseline results on these tasks as a measure for future comparisons. With carps
(https://www.github.com/automl/CARP-S), we make an important step in the
standardization of HPO evaluation.

</details>


### [119] [ENMA: Tokenwise Autoregression for Generative Neural PDE Operators](https://arxiv.org/abs/2506.06158)
*Armand Kassaï Koupaï, Lise Le Boudec, Louis Serrano, Patrick Gallinari*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为ENMA的生成神经算子，用于解决具有广泛物理参数和动力学的时间依赖参数偏微分方程(PDEs)。


<details>
  <summary>更多</summary>
  
**动机:** 解决时间依赖参数偏微分方程(PDEs)在物理参数和动力学范围广泛时对神经求解器提出了基本挑战。当数据不确定或不完整时，使用生成模型是一种自然的选择。

**方法:** ENMA通过使用流匹配损失训练的生成掩码自回归变压器，在压缩的潜在空间中预测未来动力学，实现tokenwise生成。不规则采样的空间观测通过注意力机制编码成统一的潜在表示，并通过时空卷积编码器进一步压缩。

**结果:** ENMA能够在推理时通过条件化目标轨迹的过去状态或具有相似动力学的辅助上下文轨迹来执行上下文中的学习。

**结论:** ENMA是一种强大且适应性强的框架，能够推广到新的PDE体制并支持时间依赖参数PDE的一次性代理建模。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ENMA%3A+Tokenwise+Autoregression+for+Generative+Neural+PDE+Operators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06158，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06158&send_immediately=true&force_search=false)

**原文摘要:** Solving time-dependent parametric partial differential equations (PDEs)
remains a fundamental challenge for neural solvers, particularly when
generalizing across a wide range of physical parameters and dynamics. When data
is uncertain or incomplete-as is often the case-a natural approach is to turn
to generative models. We introduce ENMA, a generative neural operator designed
to model spatio-temporal dynamics arising from physical phenomena. ENMA
predicts future dynamics in a compressed latent space using a generative masked
autoregressive transformer trained with flow matching loss, enabling tokenwise
generation. Irregularly sampled spatial observations are encoded into uniform
latent representations via attention mechanisms and further compressed through
a spatio-temporal convolutional encoder. This allows ENMA to perform in-context
learning at inference time by conditioning on either past states of the target
trajectory or auxiliary context trajectories with similar dynamics. The result
is a robust and adaptable framework that generalizes to new PDE regimes and
supports one-shot surrogate modeling of time-dependent parametric PDEs.

</details>


### [120] [Reusing Trajectories in Policy Gradients Enables Fast Convergence](https://arxiv.org/abs/2506.06178)
*Alessandro Montenegro, Federico Mansutti, Marco Mussi, Matteo Papini, Alberto Maria Metelli*

**主要类别:** cs.LG

**AI概要:** 本文研究了策略梯度方法中的轨迹重用问题，提出RPG算法显著提高了收敛速度，降低了样本复杂度。


<details>
  <summary>更多</summary>
  
**动机:** 传统的策略梯度方法由于依赖于新鲜数据导致样本效率低下，而过去轨迹的重用在理论上尚未得到充分探索。

**方法:** 引入了一种幂均值修正的多重要性权重估计器，并提出了RPG算法，将旧轨迹和新轨迹结合用于策略更新。

**结果:** 通过理论分析和实验验证，证明了RPG方法在样本复杂度上达到了O(ε^(-1))，优于现有方法。

**结论:** RPG方法通过重用过去的off-policy轨迹实现了更快的收敛速度，在策略梯度方法中达到了文献中已知的最佳速率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reusing+Trajectories+in+Policy+Gradients+Enables+Fast+Convergence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06178，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06178&send_immediately=true&force_search=false)

**原文摘要:** Policy gradient (PG) methods are a class of effective reinforcement learning
algorithms, particularly when dealing with continuous control problems. These
methods learn the parameters of parametric policies via stochastic gradient
ascent, typically using on-policy trajectory data to estimate the policy
gradient. However, such reliance on fresh data makes them sample-inefficient.
Indeed, vanilla PG methods require $O(\epsilon^{-2})$ trajectories to reach an
$\epsilon$-approximate stationary point. A common strategy to improve
efficiency is to reuse off-policy information from past iterations, such as
previous gradients or trajectories. While gradient reuse has received
substantial theoretical attention, leading to improved rates of
$O(\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored
from a theoretical perspective. In this work, we provide the first rigorous
theoretical evidence that extensive reuse of past off-policy trajectories can
significantly accelerate convergence in PG methods. We introduce a power mean
correction to the multiple importance weighting estimator and propose RPG
(Retrospective Policy Gradient), a PG algorithm that combines old and new
trajectories for policy updates. Through a novel analysis, we show that, under
established assumptions, RPG achieves a sample complexity of
$\widetilde{O}(\epsilon^{-1})$, the best known rate in the literature. We
further validate empirically our approach against PG methods with
state-of-the-art rates.

</details>


### [121] [Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations](https://arxiv.org/abs/2506.06188)
*Luis Kin Miyatake, Eduardo Camponogara, Eric Aislan Antonelo, Alexey Pavlov*

**主要类别:** cs.LG

**AI概要:** 本文扩展了PINC框架以处理单相不可压缩和可压缩流体的偏微分方程建模与控制，提出了一种无需标记数据的神经网络方法，结合物理守恒定律，实现了高效训练和实时控制应用。


<details>
  <summary>更多</summary>
  
**动机:** 建模和控制由偏微分方程(PDE)支配的单相流系统存在挑战，尤其是在瞬态条件下，因此需要扩展PINC框架以处理PDE问题。

**方法:** 论文提出了一种针对PDE的两阶段PINC模型：稳态网络和瞬态网络，结合了神经网络与物理守恒定律，并利用简化假设降低空间坐标的维度，从而实现高效的训练和优化控制策略。

**结果:** 通过数值实验验证，PINC模型能够有效逼近PDE解，并展示出其在流体流动监测和工程优化中的潜力。

**结论:** 论文得出结论，PINC模型在不需要标记数据的情况下，通过物理定律训练，能够准确表示流动动力学，并实现有效的实时控制应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Physics-Informed+Neural+Networks+for+Control+of+Single-Phase+Flow+Systems+Governed+by+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06188，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06188&send_immediately=true&force_search=false)

**原文摘要:** The modeling and control of single-phase flow systems governed by Partial
Differential Equations (PDEs) present challenges, especially under transient
conditions. In this work, we extend the Physics-Informed Neural Nets for
Control (PINC) framework, originally proposed to modeling and control of
Ordinary Differential Equations (ODE) without the need of any labeled data, to
the PDE case, particularly to single-phase incompressible and compressible
flows, integrating neural networks with physical conservation laws. The PINC
model for PDEs is structured into two stages: a steady-state network, which
learns equilibrium solutions for a wide range of control inputs, and a
transient network, which captures dynamic responses under time-varying boundary
conditions. We propose a simplifying assumption that reduces the dimensionality
of the spatial coordinate regarding the initial condition, allowing the
efficient training of the PINC network. This simplification enables the
derivation of optimal control policies using Model Predictive Control (MPC). We
validate our approach through numerical experiments, demonstrating that the
PINC model, which is trained exclusively using physical laws, i.e., without
labeled data, accurately represents flow dynamics and enables real-time control
applications. The results highlight the PINC's capability to efficiently
approximate PDE solutions without requiring iterative solvers, making it a
promising alternative for fluid flow monitoring and optimization in engineering
applications.

</details>


### [122] [ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts](https://arxiv.org/abs/2506.06192)
*Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro*

**主要类别:** cs.LG

**AI概要:** 该论文提出了ICU-TSB，这是一个用于评估基于时间患者表征学习的患者分层的综合基准。


<details>
  <summary>更多</summary>
  
**动机:** 为了通过改进诊断和治疗策略推进个性化医疗，需要识别具有临床意义的患者亚组。

**方法:** 引入了一个新的基于疾病分类学的分层评估框架，并使用三个公开可用的ICU EHR数据集进行实验。比较了统计方法和几种循环神经网络（如LSTM和GRU）生成患者表示的能力。

**结果:** 研究结果表明，v-measure在分类学的最高级别可达0.46，在最低级别可达0.40。

**结论:** 时间表征学习可以重新发现具有临床意义的患者群体，但仍然是一个具有挑战性的任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ICU-TSB%3A+A+Benchmark+for+Temporal+Patient+Representation+Learning+for+Unsupervised+Stratification+into+Patient+Cohorts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06192，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06192&send_immediately=true&force_search=false)

**原文摘要:** Patient stratification identifying clinically meaningful subgroups is
essential for advancing personalized medicine through improved diagnostics and
treatment strategies. Electronic health records (EHRs), particularly those from
intensive care units (ICUs), contain rich temporal clinical data that can be
leveraged for this purpose. In this work, we introduce ICU-TSB (Temporal
Stratification Benchmark), the first comprehensive benchmark for evaluating
patient stratification based on temporal patient representation learning using
three publicly available ICU EHR datasets. A key contribution of our benchmark
is a novel hierarchical evaluation framework utilizing disease taxonomies to
measure the alignment of discovered clusters with clinically validated disease
groupings. In our experiments with ICU-TSB, we compared statistical methods and
several recurrent neural networks, including LSTM and GRU, for their ability to
generate effective patient representations for subsequent clustering of patient
trajectories. Our results demonstrate that temporal representation learning can
rediscover clinically meaningful patient cohorts; nevertheless, it remains a
challenging task, with v-measuring varying from up to 0.46 at the top level of
the taxonomy to up to 0.40 at the lowest level. To further enhance the
practical utility of our findings, we also evaluate multiple strategies for
assigning interpretable labels to the identified clusters. The experiments and
benchmark are fully reproducible and available at
https://github.com/ds4dh/CBMS2025stratification.

</details>


### [123] [Transformative or Conservative? Conservation laws for ResNets and Transformers](https://arxiv.org/abs/2506.06194)
*Sibylle Marcotte, Rémi Gribonval, Gabriel Peyré*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了现代深度神经网络（如ResNet和Transformer）在训练过程中存在的守恒定律，揭示了这些守恒定律如何从连续梯度流动过渡到离散优化过程（如SGD），并展示了它们在不同模块中的表现形式。


<details>
  <summary>更多</summary>
  
**动机:** 虽然梯度流训练动态中的守恒定律在浅层ReLU和线性网络中已被充分研究，但在更实用的神经网络架构中尚未得到深入探索，因此本研究旨在填补这一空白。

**方法:** 该论文通过分析基本模块（如ReLU、线性网络、注意力层）的守恒定律，推导出复杂架构中的守恒定律，并研究其在连续梯度流训练动力学下的特性以及在随机梯度下降等离散优化动力学中的持续性。

**结果:** 研究表明，残差块的守恒定律与其去掉跳跃连接后的块相同，而单个注意力层的守恒定律可以被完全描述；此外，论文提出了一种仅依赖于参数子集的守恒定律，并证明了其可独立分析对应模块的守恒特性。

**结论:** 论文最终得出，现代神经网络架构（如卷积ResNets和Transformer）的残差块和注意力层具有与已知浅层网络类似的守恒定律，并且这些守恒定律在离散优化动力学下依然保持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Transformative+or+Conservative%3F+Conservation+laws+for+ResNets+and+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06194，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06194&send_immediately=true&force_search=false)

**原文摘要:** While conservation laws in gradient flow training dynamics are well
understood for (mostly shallow) ReLU and linear networks, their study remains
largely unexplored for more practical architectures. This paper bridges this
gap by deriving and analyzing conservation laws for modern architectures, with
a focus on convolutional ResNets and Transformer networks. For this, we first
show that basic building blocks such as ReLU (or linear) shallow networks, with
or without convolution, have easily expressed conservation laws, and no more
than the known ones. In the case of a single attention layer, we also
completely describe all conservation laws, and we show that residual blocks
have the same conservation laws as the same block without a skip connection. We
then introduce the notion of conservation laws that depend only on a subset of
parameters (corresponding e.g. to a pair of consecutive layers, to a residual
block, or to an attention layer). We demonstrate that the characterization of
such laws can be reduced to the analysis of the corresponding building block in
isolation. Finally, we examine how these newly discovered conservation
principles, initially established in the continuous gradient flow regime,
persist under discrete optimization dynamics, particularly in the context of
Stochastic Gradient Descent (SGD).

</details>


### [124] [How to craft a deep reinforcement learning policy for wind farm flow control](https://arxiv.org/abs/2506.06204)
*Elie Kadoche, Pascal Bianchi, Florence Carton, Philippe Ciblat, Damien Ernst*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于深度强化学习的尾流转向控制策略，用于优化风力发电场的能量生产。


<details>
  <summary>更多</summary>
  
**动机:** 在风电场中，涡轮机之间的尾流效应显著降低了整体能源产量，因此需要设计鲁棒性强的尾流转向控制器以提升效率。

**方法:** 该研究结合了图注意力网络和多头自注意力模块，并设计了新的奖励函数和训练策略，通过深度强化学习方法开发了新的尾流转向策略。

**结果:** 实验结果表明，该模型与完全连接的神经网络相比，训练步骤减少了约10倍，且能量生产提高了最多14%。

**结论:** 这是首次基于深度强化学习的尾流转向控制器能够有效适应任何时间变化的风况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+to+craft+a+deep+reinforcement+learning+policy+for+wind+farm+flow+control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06204&send_immediately=true&force_search=false)

**原文摘要:** Within wind farms, wake effects between turbines can significantly reduce
overall energy production. Wind farm flow control encompasses methods designed
to mitigate these effects through coordinated turbine control. Wake steering,
for example, consists in intentionally misaligning certain turbines with the
wind to optimize airflow and increase power output. However, designing a robust
wake steering controller remains challenging, and existing machine learning
approaches are limited to quasi-static wind conditions or small wind farms.
This work presents a new deep reinforcement learning methodology to develop a
wake steering policy that overcomes these limitations. Our approach introduces
a novel architecture that combines graph attention networks and multi-head
self-attention blocks, alongside a novel reward function and training strategy.
The resulting model computes the yaw angles of each turbine, optimizing energy
production in time-varying wind conditions. An empirical study conducted on
steady-state, low-fidelity simulation, shows that our model requires
approximately 10 times fewer training steps than a fully connected neural
network and achieves more robust performance compared to a strong optimization
baseline, increasing energy production by up to 14 %. To the best of our
knowledge, this is the first deep reinforcement learning-based wake steering
controller to generalize effectively across any time-varying wind conditions in
a low-fidelity, steady-state numerical simulation setting.

</details>


### [125] [Model-Driven Graph Contrastive Learning](https://arxiv.org/abs/2506.06212)
*Ali Azizpour, Nicolas Zilberstein, Santiago Segarra*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的图对比学习框架MGCL，其利用graphon模型生成数据自适应的增强策略，并实现了优越的图表示学习效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有图对比学习方法依赖于手动设计或启发式的增强策略，未能考虑数据的潜在生成过程和图之间的相似性。

**方法:** 该方法首先估计数据的底层graphon，然后基于graphon定义增强策略，并针对图级别任务对数据集进行聚类并分别估计graphon。

**结果:** 实验表明，MGCL在多个基准数据集上达到了最先进的性能，证明了将生成模型引入GCL的优势。

**结论:** MGCL通过结合图生成模型(graphon)来指导对比学习，从而在图表示学习任务中取得了优异的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model-Driven+Graph+Contrastive+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06212，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06212&send_immediately=true&force_search=false)

**原文摘要:** We propose $\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)
framework that leverages graphons (probabilistic generative models for graphs)
to guide contrastive learning by accounting for the data's underlying
generative process. GCL has emerged as a powerful self-supervised framework for
learning expressive node or graph representations without relying on annotated
labels, which are often scarce in real-world data. By contrasting augmented
views of graph data, GCL has demonstrated strong performance across various
downstream tasks, such as node and graph classification. However, existing
methods typically rely on manually designed or heuristic augmentation
strategies that are not tailored to the underlying data distribution and
operate at the individual graph level, ignoring similarities among graphs
generated from the same model. Conversely, in our proposed approach, MGCL first
estimates the graphon associated with the observed data and then defines a
graphon-informed augmentation process, enabling data-adaptive and principled
augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset
and estimates a graphon per group, enabling contrastive pairs to reflect shared
semantics and structure. Extensive experiments on benchmark datasets
demonstrate that MGCL achieves state-of-the-art performance, highlighting the
advantages of incorporating generative models into GCL.

</details>


### [126] [Corrector Sampling in Language Models](https://arxiv.org/abs/2506.06215)
*Itai Gat, Neta Shaul, Uriel Singer, Yaron Lipman*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Resample-Previous-Tokens (RPT)的新采样方法，旨在减少自回归语言模型在生成过程中的错误累积问题，并且实验结果显示这种方法在多个基准测试中效果更优。


<details>
  <summary>更多</summary>
  
**动机:** 自回归语言模型由于其固定的、不可逆的从左到右的标记生成方式会积累错误，因此需要一种新的方法来解决这个问题。

**方法:** 提出了一种新的采样方法Resample-Previous-Tokens (RPT)，该方法通过对先前生成的一段文本中的标记进行迭代重新采样以减少错误累积。

**结果:** 在仅进行了100B次微调后，使用RPT改进的预训练8B参数模型在推理和编码基准测试中相比标准采样方法有大约10%的相对提升。

**结论:** RPT方法能够在不牺牲模型速度和质量的前提下，通过迭代修正之前生成的标记来减少错误累积。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Corrector+Sampling+in+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06215，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06215&send_immediately=true&force_search=false)

**原文摘要:** Autoregressive language models accumulate errors due to their fixed,
irrevocable left-to-right token generation. To address this, we propose a new
sampling method called Resample-Previous-Tokens (RPT). RPT mitigates error
accumulation by iteratively revisiting and potentially replacing tokens in a
window of previously generated text. This method can be integrated into
existing autoregressive models, preserving their next-token-prediction quality
and speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B
resulted in ~10% relative improvements on reasoning and coding benchmarks
compared to the standard sampling.

</details>


### [127] [Neural Responses to Affective Sentences Reveal Signatures of Depression](https://arxiv.org/abs/2506.06244)
*Aditya Kommineni, Woojae Jeong, Kleanthis Avramidis, Colin McDaniel, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Kristina Lerman, Idan A. Blank, Dani Byrd, Assal Habibi, B. Rael Cahn, Sudarsana Kadiri, Takfarinas Medani, Richard M. Leahy, Shrikanth Narayanan*

**主要类别:** cs.LG

**AI概要:** 该研究通过EEG结合深度学习分析，揭示了抑郁症患者在处理情绪和自我相关信息时的神经活动差异，并探索了潜在的诊断应用。


<details>
  <summary>更多</summary>
  
**动机:** 深入了解重度抑郁症（MDD）的神经认知基础对于识别其对情绪和自我参照处理等核心功能的影响至关重要。

**方法:** 研究通过表面脑电图（EEG）测量健康人和抑郁个体对自我参照情感句子的神经反应，使用深度学习模型进行分析，并通过空间消融确定关键电极位置。

**结果:** 研究发现抑郁个体在句子观看期间表现出显著的群体级神经活动差异，深度学习模型在区分健康与抑郁参与者方面达到0.707的AUC，在区分有无自杀意念的抑郁亚组中达到0.624的AUC，空间消融分析显示与语义和情感处理相关的前部电极是关键贡献者。

**结论:** 论文得出结论，抑郁症会破坏情绪和自我参照信息的整合，并且有稳定的、由刺激驱动的神经特征，可能为未来的诊断工具提供依据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+Responses+to+Affective+Sentences+Reveal+Signatures+of+Depression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06244&send_immediately=true&force_search=false)

**原文摘要:** Major Depressive Disorder (MDD) is a highly prevalent mental health
condition, and a deeper understanding of its neurocognitive foundations is
essential for identifying how core functions such as emotional and
self-referential processing are affected. We investigate how depression alters
the temporal dynamics of emotional processing by measuring neural responses to
self-referential affective sentences using surface electroencephalography (EEG)
in healthy and depressed individuals. Our results reveal significant
group-level differences in neural activity during sentence viewing, suggesting
disrupted integration of emotional and self-referential information in
depression. Deep learning model trained on these responses achieves an area
under the receiver operating curve (AUC) of 0.707 in distinguishing healthy
from depressed participants, and 0.624 in differentiating depressed subgroups
with and without suicidal ideation. Spatial ablations highlight anterior
electrodes associated with semantic and affective processing as key
contributors. These findings suggest stable, stimulus-driven neural signatures
of depression that may inform future diagnostic tools.

</details>


### [128] [Lagrangian-based Equilibrium Propagation: generalisation to arbitrary boundary conditions & equivalence with Hamiltonian Echo Learning](https://arxiv.org/abs/2506.06248)
*Guillaume Pourcel, Debabrota Basu, Maxence Ernoult, Aditya Gilra*

**主要类别:** cs.LG

**AI概要:** 本文提出GLEP方法，成功将EP推广到时变输入，并揭示HEL为最优实现形式。


<details>
  <summary>更多</summary>
  
**动机:** 将静态输入的EP算法推广到时变输入场景，以提升其应用范围。

**方法:** 通过广义拉格朗日框架将EP扩展到时变输入，并分析不同边界条件的影响。

**结果:** 提出了GLEP理论框架，并证明HEL是其特殊形式且具备硬件实现优势。

**结论:** GLEP框架可以推导出不同的学习算法，其中HEL是唯一继承EP优点的变体。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Lagrangian-based+Equilibrium+Propagation%3A+generalisation+to+arbitrary+boundary+conditions+%26+equivalence+with+Hamiltonian+Echo+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06248，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06248&send_immediately=true&force_search=false)

**原文摘要:** Equilibrium Propagation (EP) is a learning algorithm for training
Energy-based Models (EBMs) on static inputs which leverages the variational
description of their fixed points. Extending EP to time-varying inputs is a
challenging problem, as the variational description must apply to the entire
system trajectory rather than just fixed points, and careful consideration of
boundary conditions becomes essential. In this work, we present Generalized
Lagrangian Equilibrium Propagation (GLEP), which extends the variational
formulation of EP to time-varying inputs. We demonstrate that GLEP yields
different learning algorithms depending on the boundary conditions of the
system, many of which are impractical for implementation. We then show that
Hamiltonian Echo Learning (HEL) -- which includes the recently proposed
Recurrent HEL (RHEL) and the earlier known Hamiltonian Echo Backpropagation
(HEB) algorithms -- can be derived as a special case of GLEP. Notably, HEL is
the only instance of GLEP we found that inherits the properties that make EP a
desirable alternative to backpropagation for hardware implementations: it
operates in a "forward-only" manner (i.e. using the same system for both
inference and learning), it scales efficiently (requiring only two or more
passes through the system regardless of model size), and enables local
learning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [A Path to Loving](https://arxiv.org/abs/2506.05352)
*John Beverley, Regina Hurley*

**主要类别:** cs.AI

**AI概要:** 该论文研究了爱的本体特征，将其理解为被动感觉和主动评价判断的结合，并通过因果模型连接情感与认知，以促进跨学科应用和人工智能研究。


<details>
  <summary>更多</summary>
  
**动机:** 为了平衡爱的非自愿性与其理性责任，并增强相关的基于人工智能的应用。

**方法:** 基于基础形式本体论（BFO）和其他应用本体方法进行分析，并回应了关于感觉与判断之间关系的异议。

**结果:** 提供了一个严谨的爱的本体特征描述，强调其哲学复杂性和科学相关性，特别是在心理学和社会学方面。

**结论:** 论文得出爱可以被理解为被动感觉和主动评价判断的结合，并通过因果相关模型将情感和认知部分联系起来，提供了精确且可扩展的本体论描述。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Path+to+Loving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05352，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05352&send_immediately=true&force_search=false)

**原文摘要:** This work lays the foundations for a rigorous ontological characterization of
love, addressing its philosophical complexity and scientific relevance, with
particular emphasis on psychology and sociology, as well as highlighting ways
in which such characterization enhances relevant AI based applications. The
position defended here is that love is best understood as a concatenation of
passive sensations (e.g., emotional arousal) and active evaluative judgments
(e.g., perceiving the beloved as valuable), in the interest of balancing the
involuntary aspects of love with its rational accountability. To provide a
structured foundation, the paper draws on Basic Formal Ontology (BFO) and other
applied ontological methods to differentiate various senses of love. This work
engages with objections to the understanding of love as concatenation,
particularly concerning the relationship between sensation and judgment. A
causal correlation model is defended, ensuring that the affective and cognitive
components are linked. By offering a precise and scalable ontological account,
this work lays the foundation for future interdisciplinary applications, making
love a subject of formal inquiry in ontology engineering, artificial
intelligence, and the sciences.

</details>


### [130] [Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems](https://arxiv.org/abs/2506.05370)
*Kristy Wedel*

**主要类别:** cs.AI

**AI概要:** 这篇论文介绍了一种基于记忆智能的新范式CMI，旨在解决生成式AI在组织应用中的记忆局限问题，提升系统的可解释性和决策质量。


<details>
  <summary>更多</summary>
  
**动机:** 生成式AI系统在各种组织环境中的快速实施仍然存在未解决的关键挑战，尤其是其在记忆组件方面的限制导致了重复错误和决策透明度的缺乏。

**方法:** 借鉴认知科学、组织理论、人机交互和AI治理等多个领域的知识，提出了Contextual Memory Intelligence (CMI) 和Insight Layer架构，用于操作化这一愿景。

**结果:** 提出了一种新的智能系统框架，该框架利用上下文记忆智能（CMI）进行推理，并结合数据、历史、判断和变化的情境，从而增强人类与AI的协作、生成式AI的设计以及机构的韧性。

**结论:** CMI为构建智能系统提供了一个新的基础范式，通过将记忆重新定位为适应性基础设施，解决了当前AI架构和治理中的根本性盲点。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Contextual+Memory+Intelligence+--+A+Foundational+Paradigm+for+Human-AI+Collaboration+and+Reflective+Generative+AI+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05370，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05370&send_immediately=true&force_search=false)

**原文摘要:** A critical challenge remains unresolved as generative AI systems are quickly
implemented in various organizational settings. Despite significant advances in
memory components such as RAG, vector stores, and LLM agents, these systems
still have substantial memory limitations. Gen AI workflows rarely store or
reflect on the full context in which decisions are made. This leads to repeated
errors and a general lack of clarity. This paper introduces Contextual Memory
Intelligence (CMI) as a new foundational paradigm for building intelligent
systems. It repositions memory as an adaptive infrastructure necessary for
longitudinal coherence, explainability, and responsible decision-making rather
than passive data. Drawing on cognitive science, organizational theory,
human-computer interaction, and AI governance, CMI formalizes the structured
capture, inference, and regeneration of context as a fundamental system
capability. The Insight Layer is presented in this paper to operationalize this
vision. This modular architecture uses human-in-the-loop reflection, drift
detection, and rationale preservation to incorporate contextual memory into
systems. The paper argues that CMI allows systems to reason with data, history,
judgment, and changing context, thereby addressing a foundational blind spot in
current AI architectures and governance efforts. A framework for creating
intelligent systems that are effective, reflective, auditable, and socially
responsible is presented through CMI. This enhances human-AI collaboration,
generative AI design, and the resilience of the institutions.

</details>


### [131] [Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference](https://arxiv.org/abs/2506.05422)
*Andrei T. Patrascu*

**主要类别:** cs.AI

**AI概要:** 本研究引入了一种基于构造逻辑的新颖学习与规划框架，避免了传统强化学习中的试错机制，实现了安全、可解释且高效的决策。


<details>
  <summary>更多</summary>
  
**动机:** 传统强化学习需要大量探索，且可能产生不安全或无效的状态转移，而本文旨在通过构造性逻辑实现安全、可解释且高效的决策过程。

**方法:** 将动作、状态转移和目标表示为逻辑命题，并在直觉主义逻辑下通过构造性证明进行决策，确保状态转移和策略只有在有可验证前提的情况下才被接受。

**结果:** 实验表明，与Q-learning相比，该方法实现了完美的安全性、可解释的行为以及高效收敛，且没有任何无效动作。

**结论:** 这篇论文提出了一种基于构造逻辑推理的学习和规划框架，取代了传统的基于奖励的优化方法，为强化学习提供了一个新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Constructive+Symbolic+Reinforcement+Learning+via+Intuitionistic+Logic+and+Goal-Chaining+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05422，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05422&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel learning and planning framework that replaces
traditional reward-based optimisation with constructive logical inference. In
our model, actions, transitions, and goals are represented as logical
propositions, and decision-making proceeds by building constructive proofs
under intuitionistic logic. This method ensures that state transitions and
policies are accepted only when supported by verifiable preconditions --
eschewing probabilistic trial-and-error in favour of guaranteed logical
validity. We implement a symbolic agent operating in a structured gridworld,
where reaching a goal requires satisfying a chain of intermediate subgoals
(e.g., collecting keys to open doors), each governed by logical constraints.
Unlike conventional reinforcement learning agents, which require extensive
exploration and suffer from unsafe or invalid transitions, our constructive
agent builds a provably correct plan through goal chaining, condition tracking,
and knowledge accumulation. Empirical comparison with Q-learning demonstrates
that our method achieves perfect safety, interpretable behaviour, and efficient
convergence with no invalid actions, highlighting its potential for safe
planning, symbolic cognition, and trustworthy AI. This work presents a new
direction for reinforcement learning grounded not in numeric optimisation, but
in constructive logic and proof theory.

</details>


### [132] [Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted](https://arxiv.org/abs/2506.05520)
*Cecil Pang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的以业务语义为中心、AI代理辅助的数据系统（BSDS），旨在解决现有数据平台过于注重技术工具而忽视业务需求的问题。


<details>
  <summary>更多</summary>
  
**动机:** 当代企业在动态环境中运营，需要快速适应以实现目标并保持竞争力。然而，现有的数据平台往往过于强调工具，而忽视了与业务需求的一致性，导致效率低下和延迟。因此，作者提出了BSDS来解决这一差距。

**方法:** 提出了一种新的以业务语义为中心、AI代理辅助的数据系统（BSDS），并描述了其模块化架构，包括与业务实体相关联的数据、用于上下文感知AI代理的知识库以及高效的数据管道。同时，该论文讨论了AI代理在数据访问和系统管理中的作用，以及优化探索性数据分析和生产需求的工作流程。

**结果:** BSDS被验证通过实际应用加速了数据驱动举措的上市时间，增强了跨职能协作，并提供了可扩展的蓝图。

**结论:** 论文得出结论，BSDS通过整合架构、工作流程和团队组织，使数据系统与业务优先级保持一致，从而弥补了现有数据平台的不足。此外，BSDS为不同规模的企业提供了一个可扩展的蓝图，并加速了数据驱动举措的上市时间，增强了跨职能协作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Data+Systems+That+Are+Business+Semantic-Centric+and+AI+Agents-Assisted，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05520，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05520&send_immediately=true&force_search=false)

**原文摘要:** Contemporary businesses operate in dynamic environments requiring rapid
adaptation to achieve goals and maintain competitiveness. Existing data
platforms often fall short by emphasizing tools over alignment with business
needs, resulting in inefficiencies and delays. To address this gap, I propose
the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a
holistic system that integrates architecture, workflows, and team organization
to ensure data systems are tailored to business priorities rather than dictated
by technical constraints. BSDS redefines data systems as dynamic enablers of
business success, transforming them from passive tools into active drivers of
organizational growth. BSDS has a modular architecture that comprises curated
data linked to business entities, a knowledge base for context-aware AI agents,
and efficient data pipelines. AI agents play a pivotal role in assisting with
data access and system management, reducing human effort, and improving
scalability. Complementing this architecture, BSDS incorporates workflows
optimized for both exploratory data analysis and production requirements,
balancing speed of delivery with quality assurance. A key innovation of BSDS is
its incorporation of the human factor. By aligning data team expertise with
business semantics, BSDS bridges the gap between technical capabilities and
business needs. Validated through real-world implementation, BSDS accelerates
time-to-market for data-driven initiatives, enhances cross-functional
collaboration, and provides a scalable blueprint for businesses of all sizes.
Future research can build on BSDS to explore optimization strategies using
complex systems and adaptive network theories, as well as developing autonomous
data systems leveraging AI agents.

</details>


### [133] [Avoiding Death through Fear Intrinsic Conditioning](https://arxiv.org/abs/2506.05529)
*Rodney Sanchez, Ferat Sahin, Alexander Ororbia, Jamison Heard*

**主要类别:** cs.AI

**AI概要:** 这篇论文介绍了一种基于生物学原理的记忆增强型神经网络架构，用于处理无描述性终止条件的强化学习任务，成功实现了类似动物恐惧条件反射的回避行为。


<details>
  <summary>更多</summary>
  
**动机:** 当前强化学习方法在评估上存在一个局限性，即在现实环境中需要人工设计外部奖励函数，而这些环境中的某些状态会带来高度负面奖励但不提供反馈（例如死亡）。这促使作者寻找一种生物学启发的方法来解决这一问题。

**方法:** 该论文提出了一种新的记忆增强型神经网络（MANN）架构来生成内在动机，并通过调整恐惧反应的阈值来模拟广泛性焦虑障碍（GADs）下的不同行为模式。实验在Miniworld Sidewalk环境中进行，这是一个部分可观测马尔可夫决策过程（POMDP），具有稀疏奖励和无描述性的终止条件（如死亡）。

**结果:** 研究表明，提出的内在动机能够有效防止智能体探索终止状态，产生类似恐惧条件反射的回避行为。此外，通过调整恐惧反应的阈值，可以实现一系列与广泛性焦虑障碍相关的复杂行为模式。

**结论:** 本研究通过引入受早期杏仁核发育启发的内在奖励函数，成功地在智能体中实现了类似动物恐惧条件反射的回避行为，并且展示了一种生物学启发的神经架构和恐惧条件反射范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Avoiding+Death+through+Fear+Intrinsic+Conditioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05529，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05529&send_immediately=true&force_search=false)

**原文摘要:** Biological and psychological concepts have inspired reinforcement learning
algorithms to create new complex behaviors that expand agents' capacity. These
behaviors can be seen in the rise of techniques like goal decomposition,
curriculum, and intrinsic rewards, which have paved the way for these complex
behaviors. One limitation in evaluating these methods is the requirement for
engineered extrinsic for realistic environments. A central challenge in
engineering the necessary reward function(s) comes from these environments
containing states that carry high negative rewards, but provide no feedback to
the agent. Death is one such stimuli that fails to provide direct feedback to
the agent. In this work, we introduce an intrinsic reward function inspired by
early amygdala development and produce this intrinsic reward through a novel
memory-augmented neural network (MANN) architecture. We show how this intrinsic
motivation serves to deter exploration of terminal states and results in
avoidance behavior similar to fear conditioning observed in animals.
Furthermore, we demonstrate how modifying a threshold where the fear response
is active produces a range of behaviors that are described under the paradigm
of general anxiety disorders (GADs). We demonstrate this behavior in the
Miniworld Sidewalk environment, which provides a partially observable Markov
decision process (POMDP) and a sparse reward with a non-descriptive terminal
condition, i.e., death. In effect, this study results in a
biologically-inspired neural architecture and framework for fear conditioning
paradigms; we empirically demonstrate avoidance behavior in a constructed agent
that is able to solve environments with non-descriptive terminal conditions.

</details>


### [134] [When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration](https://arxiv.org/abs/2506.05579)
*Quan Shi, Carlos E. Jimenez, Shunyu Yao, Nick Haber, Diyi Yang, Karthik Narasimhan*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种用于评估人类-AI知识转移的新框架KITE，研究表明模型的高性能并不总是转化为有效的知识迁移，并指出需要专门优化这一过程。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI推理的进步是否能够促进更好的知识迁移：即模型能否以人类可以理解、应用和学习的方式传递推理过程。

**方法:** 引入了知识整合与转移评估（KITE）框架，并进行了首次大规模人类研究（N=118）来衡量人类-AI的知识转移能力。

**结果:** 虽然模型基准性能与协作结果相关，但这种关系明显不一致，存在显著异常值。分析还确定了影响成功知识转移的行为和策略因素。

**结论:** 知识迁移需要专门的优化，而不仅仅是模型基准性能的提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Models+Know+More+Than+They+Can+Explain%3A+Quantifying+Knowledge+Transfer+in+Human-AI+Collaboration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05579&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in AI reasoning have driven substantial improvements
across diverse tasks. A critical open question is whether these improvements
also yields better knowledge transfer: the ability of models to communicate
reasoning in ways humans can understand, apply, and learn from. To investigate
this, we introduce Knowledge Integration and Transfer Evaluation (KITE), a
conceptual and experimental framework for Human-AI knowledge transfer
capabilities and conduct the first large-scale human study (N=118) explicitly
designed to measure it. In our two-phase setup, humans first ideate with an AI
on problem-solving strategies, then independently implement solutions,
isolating model explanations' influence on human understanding. Our findings
reveal that although model benchmark performance correlates with collaborative
outcomes, this relationship is notably inconsistent, featuring significant
outliers, indicating that knowledge transfer requires dedicated optimization.
Our analysis identifies behavioral and strategic factors mediating successful
knowledge transfer. We release our code, dataset, and evaluation framework to
support future work on communicatively aligned models.

</details>


### [135] [MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark](https://arxiv.org/abs/2506.05587)
*Junjie Xing, Yeye He, Mengyu Zhou, Haoyu Dong, Shi Han, Lingjiao Chen, Dongmei Zhang, Surajit Chaudhuri, H. V. Jagadish*

**主要类别:** cs.AI

**AI概要:** 本文提出MMTU，一个包含30K问题的大规模表格理解基准测试，揭示当前LLM在专家级表格处理任务上的不足。


<details>
  <summary>更多</summary>
  
**动机:** 尽管LLMs在处理表格方面取得了进展，但缺乏综合的基准测试，现有评估主要集中于NL-to-SQL和Table-QA，忽视了更广泛的实际任务。

**方法:** 从数十年的计算机科学表格数据研究中选取25个现实世界的表格任务，构建包含30K问题的基准测试集，并对前沿模型进行评估。

**结果:** 结果显示，即使是前沿的推理模型（如OpenAI o4-mini和DeepSeek R1）得分也只有大约60%，表明当前模型在复杂表格任务上仍面临挑战。

**结论:** 论文介绍了MMTU，一个大规模基准测试，旨在全面评估模型理解和操作真实表格数据的能力，并指出当前前沿模型仍有显著改进空间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MMTU%3A+A+Massive+Multi-Task+Table+Understanding+and+Reasoning+Benchmark，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05587，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05587&send_immediately=true&force_search=false)

**原文摘要:** Tables and table-based use cases play a crucial role in many important
real-world applications, such as spreadsheets, databases, and computational
notebooks, which traditionally require expert-level users like data engineers,
data analysts, and database administrators to operate. Although LLMs have shown
remarkable progress in working with tables (e.g., in spreadsheet and database
copilot scenarios), comprehensive benchmarking of such capabilities remains
limited. In contrast to an extensive and growing list of NLP benchmarks,
evaluations of table-related tasks are scarce, and narrowly focus on tasks like
NL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks
that professional users face. This gap limits our understanding and model
progress in this important area.
  In this work, we introduce MMTU, a large-scale benchmark with over 30K
questions across 25 real-world table tasks, designed to comprehensively
evaluate models ability to understand, reason, and manipulate real tables at
the expert-level. These tasks are drawn from decades' worth of computer science
research on tabular data, with a focus on complex table tasks faced by
professional users. We show that MMTU require a combination of skills --
including table understanding, reasoning, and coding -- that remain challenging
for today's frontier models, where even frontier reasoning models like OpenAI
o4-mini and DeepSeek R1 score only around 60%, suggesting significant room for
improvement. We highlight key findings in our evaluation using MMTU and hope
that this benchmark drives further advances in understanding and developing
foundation models for structured data processing and analysis. Our code and
data are available at https://github.com/MMTU-Benchmark/MMTU and
https://huggingface.co/datasets/MMTU-benchmark/MMTU.

</details>


### [136] [Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists](https://arxiv.org/abs/2506.05616)
*Lianhao Zhou, Hongyi Ling, Keqiang Yan, Kaiji Zhao, Xiaoning Qian, Raymundo Arróyave, Xiaofeng Qian, Shuiwang Ji*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为 MAPPS 的自主材料发现代理，结合了语言模型、物理模型与科学家反馈，显著提升了材料发现的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究通常将代理限制在预定义工作流中执行特定任务，而我们希望实现基于高层次目标和科学家直觉的工作流规划自动化。

**方法:** 开发了一个名为 MAPPS 的语言代理，包含工作流规划器、工具代码生成器和科学协调器，利用大型语言模型和物理编码模型进行自动化材料发现。

**结果:** MAPPS 在 MP-20 数据集上评估时，稳定性、独特性和新颖性率提高了五倍，并且在各种任务中均表现出色。

**结论:** MAPPS 是一种有前景的自主材料发现框架，通过整合规划、物理和科学家，实现了更高的稳定性、独特性和新颖性比率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Toward+Greater+Autonomy+in+Materials+Discovery+Agents%3A+Unifying+Planning%2C+Physics%2C+and+Scientists，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05616，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05616&send_immediately=true&force_search=false)

**原文摘要:** We aim at designing language agents with greater autonomy for crystal
materials discovery. While most of existing studies restrict the agents to
perform specific tasks within predefined workflows, we aim to automate workflow
planning given high-level goals and scientist intuition. To this end, we
propose Materials Agent unifying Planning, Physics, and Scientists, known as
MAPPS. MAPPS consists of a Workflow Planner, a Tool Code Generator, and a
Scientific Mediator. The Workflow Planner uses large language models (LLMs) to
generate structured and multi-step workflows. The Tool Code Generator
synthesizes executable Python code for various tasks, including invoking a
force field foundation model that encodes physics. The Scientific Mediator
coordinates communications, facilitates scientist feedback, and ensures
robustness through error reflection and recovery. By unifying planning,
physics, and scientists, MAPPS enables flexible and reliable materials
discovery with greater autonomy, achieving a five-fold improvement in
stability, uniqueness, and novelty rates compared with prior generative models
when evaluated on the MP-20 data. We provide extensive experiments across
diverse tasks to show that MAPPS is a promising framework for autonomous
materials discovery.

</details>


### [137] [Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach](https://arxiv.org/abs/2506.05619)
*Kihyun Kim, Jiawei Zhang, Asuman Ozdaglar, Pablo A. Parrilo*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新型偏好学习框架，通过直接从成对比较数据推断评估者总体分布，使聚合意见和政策制定能按比例反映真实分布，并满足多项理论公理。


<details>
  <summary>更多</summary>
  
**动机:** 传统的偏好学习方法在聚合多个评估者的意见时往往优先考虑更广泛持有的意见，这可能导致某些类型的观点或群体的偏见；本文旨在解决这一问题，确保政策能够按比例反映真实的评估者偏好分布。

**方法:** 该方法从成对比较数据中直接推断出可行的评估者总体分布集，并利用这些估计构建一个满足相关公理的策略；此外还提出了一种软最大值松弛方法来平衡按比例代表性与选择Condorcet胜者的任务。

**结果:** 实验验证了该方法在表格推荐任务和大规模语言模型对齐方面的有效性与可扩展性。

**结论:** 本文提出了一种新的偏好学习框架，能够在制定策略时按比例反映评估者偏好的总体分布，并满足社会选择理论中的基本公理以及新提出的代表性和鲁棒性公理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Population-Proportional+Preference+Learning+from+Human+Feedback%3A+An+Axiomatic+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05619&send_immediately=true&force_search=false)

**原文摘要:** Conventional preference learning methods often prioritize opinions held more
widely when aggregating preferences from multiple evaluators. This may result
in policies that are biased in favor of some types of opinions or groups. The
objective of this paper is to develop a novel preference learning framework
capable of aligning aggregate opinions and policies proportionally with the
true population distribution of evaluator preferences. Our approach infers the
feasible set of evaluator population distributions directly from pairwise
comparison data. Using these estimates, the algorithm constructs a policy that
satisfies foundational axioms from social choice theory, namely monotonicity
and Pareto efficiency, as well as our newly-introduced axioms of
population-proportional representation and population-bounded robustness. We
propose a soft-max relaxation method that smoothly trade-offs
population-proportional representation with the selection of the Condorcet
winner (which beats all other options in pairwise comparisons). Finally, we
validate the effectiveness and scalability of our approach through experiments
on both tabular recommendation tasks and large-scale language model alignment.

</details>


### [138] [Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties](https://arxiv.org/abs/2506.05744)
*Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo*

**主要类别:** cs.AI

**AI概要:** 论文研究了大规模推理模型的内部机制，提出了推理图概念，并发现其结构特性与模型性能密切相关，为改进模型和数据集设计提供了新思路。


<details>
  <summary>更多</summary>
  
**动机:** 大规模推理模型在数学基准测试中表现优异，但其成功背后的内部机制尚不清楚。

**方法:** 引入了推理图的概念，并通过聚类隐藏状态表示来系统分析图的三个关键性质：循环性、直径和小世界指数。

**结果:** 提炼后的推理模型表现出更强的循环性、更大的图直径和显著的小世界特性，这些优势随着任务难度和模型容量增加而增强。此外，监督微调可以系统地扩展推理图直径并提高性能。

**结论:** 通过分析推理图的结构特性，研究为提升大规模推理模型的可解释性和效能提供了理论见解和实际建议。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Topology+of+Reasoning%3A+Understanding+Large+Reasoning+Models+through+Reasoning+Graph+Properties，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05744，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05744&send_immediately=true&force_search=false)

**原文摘要:** Recent large-scale reasoning models have achieved state-of-the-art
performance on challenging mathematical benchmarks, yet the internal mechanisms
underlying their success remain poorly understood. In this work, we introduce
the notion of a reasoning graph, extracted by clustering hidden-state
representations at each reasoning step, and systematically analyze three key
graph-theoretic properties: cyclicity, diameter, and small-world index, across
multiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilled
reasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantly
more recurrent cycles (about 5 per sample), substantially larger graph
diameters, and pronounced small-world characteristics (about 6x) compared to
their base counterparts. Notably, these structural advantages grow with task
difficulty and model capacity, with cycle detection peaking at the 14B scale
and exploration diameter maximized in the 32B variant, correlating positively
with accuracy. Furthermore, we show that supervised fine-tuning on an improved
dataset systematically expands reasoning graph diameters in tandem with
performance gains, offering concrete guidelines for dataset design aimed at
boosting reasoning capabilities. By bridging theoretical insights into
reasoning graph structures with practical recommendations for data
construction, our work advances both the interpretability and the efficacy of
large reasoning models.

</details>


### [139] [Preference Learning for AI Alignment: a Causal Perspective](https://arxiv.org/abs/2506.05967)
*Katarzyna Kobalczyk, Mihaela van der Schaar*

**主要类别:** cs.AI

**AI概要:** 本文提出使用因果推理框架来改进大型语言模型的奖励建模过程，以增强模型的泛化能力和稳健性。


<details>
  <summary>更多</summary>
  
**动机:** 从偏好数据中进行奖励建模是将大型语言模型与人类价值观对齐的关键步骤，但其在新提示-响应对上的泛化能力面临挑战。

**方法:** 将奖励建模问题置于因果范式中，利用因果推断文献识别关键假设，并与常见的数据收集实践进行对比。

**结果:** 展示了朴素奖励模型的失败模式，并证明了受因果启发的方法如何改善模型鲁棒性。

**结论:** 因果推理方法可以提高奖励模型的鲁棒性，并指出未来研究需要有针对性地解决观察数据的固有局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preference+Learning+for+AI+Alignment%3A+a+Causal+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05967，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05967&send_immediately=true&force_search=false)

**原文摘要:** Reward modelling from preference data is a crucial step in aligning large
language models (LLMs) with human values, requiring robust generalisation to
novel prompt-response pairs. In this work, we propose to frame this problem in
a causal paradigm, providing the rich toolbox of causality to identify the
persistent challenges, such as causal misidentification, preference
heterogeneity, and confounding due to user-specific factors. Inheriting from
the literature of causal inference, we identify key assumptions necessary for
reliable generalisation and contrast them with common data collection
practices. We illustrate failure modes of naive reward models and demonstrate
how causally-inspired approaches can improve model robustness. Finally, we
outline desiderata for future research and practices, advocating targeted
interventions to address inherent limitations of observational data.

</details>


### [140] [SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models](https://arxiv.org/abs/2506.05745)
*Emil Biju, Shayan Talaei, Zhemin Huang, Mohammadreza Pourreza, Azalia Mirhoseini, Amin Saberi*

**主要类别:** cs.AI

**AI概要:** SPRINT是一种新型框架，通过对大型推理模型进行微调，使其能够动态识别并行机会，从而显著减少推理所需的顺序步骤，提高效率。


<details>
  <summary>更多</summary>
  
**动机:** 大型推理模型在复杂推理任务中表现出色，但通常生成较长的顺序思维链，导致推理时间过长，因此需要一种能够提升推理效率的方法。

**方法:** 引入SPRINT框架，通过数据整理管道将自然语言推理路径重组为结构化的长视野规划和平行执行，并对模型进行微调以学习动态识别独立子任务。

**结果:** 使用SPRINT框架微调的模型在数学等复杂领域达到与传统推理模型相当的性能，同时在需要超过8000个输出token的问题上，顺序token减少了约39%；在GPQA和Countdown任务上分别实现了45%和65%的平均顺序token减少。

**结论:** SPRINT框架能够在不影响性能的前提下，有效减少大型推理模型的顺序执行步骤，实现并行化推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPRINT%3A+Enabling+Interleaved+Planning+and+Parallelized+Execution+in+Reasoning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05745，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05745&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models (LRMs) excel at complex reasoning tasks but typically
generate lengthy sequential chains-of-thought, resulting in long inference
times before arriving at the final answer. To address this challenge, we
introduce SPRINT, a novel post-training and inference-time framework designed
to enable LRMs to dynamically identify and exploit opportunities for
parallelization during their reasoning process. SPRINT incorporates an
innovative data curation pipeline that reorganizes natural language reasoning
trajectories into structured rounds of long-horizon planning and parallel
execution. By fine-tuning LRMs on a small amount of such curated data, the
models learn to dynamically identify independent subtasks within extended
reasoning processes and effectively execute them in parallel. Through extensive
evaluations, we show that the models fine-tuned with the SPRINT framework match
the performance of reasoning models on complex domains such as mathematics
while generating up to ~39% fewer sequential tokens on problems requiring more
than 8000 output tokens. Finally, we observe consistent results transferred to
two out-of-distribution tasks of GPQA and Countdown with up to 45% and 65%
reduction in average sequential tokens for longer reasoning trajectories, while
achieving the performance of the fine-tuned reasoning model.

</details>


### [141] [Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective](https://arxiv.org/abs/2506.05754)
*Emmanuel Anaya Gonzalez, Sairam Vaidya, Kanghee Park, Ruyi Ji, Taylor Berg-Kirkpatrick, Loris D'Antoni*

**主要类别:** cs.AI

**AI概要:** 这篇论文介绍了一种新的约束采样框架，该框架能够保证生成满足硬性约束的样本，并逐步收敛到真实的条件分布，同时保持高效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的约束解码方法往往会扭曲底层模型分布，这个问题在需要生成多样化且有效的程序输入进行测试的应用中尤其成问题。

**方法:** 构建一个关于有效输出的提议分布，并使用基于LM似然的Metropolis-Hastings接受准则，以确保对约束空间进行有原则且高效的探索。

**结果:** 所提出的采样器在合成基准和真实世界程序模糊测试任务中均优于现有方法。

**结论:** 论文提出了一种基于马尔可夫链蒙特卡洛（MCMC）的新约束采样框架，能够在满足硬性约束的同时生成高质量样本，并且在合成基准和真实世界程序模糊测试任务中优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Constrained+Sampling+for+Language+Models+Should+Be+Easy%3A+An+MCMC+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05754，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05754&send_immediately=true&force_search=false)

**原文摘要:** Constrained decoding enables Language Models (LMs) to produce samples that
provably satisfy hard constraints. However, existing constrained-decoding
approaches often distort the underlying model distribution, a limitation that
is especially problematic in applications like program fuzzing, where one wants
to generate diverse and valid program inputs for testing purposes. We propose a
new constrained sampling framework based on Markov Chain Monte Carlo (MCMC)
that simultaneously satisfies three core desiderata: constraint satisfying
(every sample satisfies the constraint), monotonically converging (the sampling
process converges to the true conditional distribution), and efficient
(high-quality samples emerge in few steps). Our method constructs a proposal
distribution over valid outputs and applies a Metropolis-Hastings acceptance
criterion based on the LM's likelihood, ensuring principled and efficient
exploration of the constrained space. Empirically, our sampler outperforms
existing methods on both synthetic benchmarks and real-world program fuzzing
tasks.

</details>


### [142] [Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction](https://arxiv.org/abs/2506.05810)
*Yesheng Zhang, Wenjian Sun, Yuheng Chen, Qingwei Liu, Qi Lin, Rui Zhang, Xu Zhao*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为轨迹熵的新度量方法，以解决level-k博弈框架在自动驾驶中冗余和错误计算的问题，提高了预测和规划任务的精度。


<details>
  <summary>更多</summary>
  
**动机:** 当前的level-k博弈框架忽略了代理之间不同的驾驶复杂性和跨博弈级别的动态变化，导致冗余且容易出错的计算。因此，需要一种新的方法来解决这个问题。

**方法:** 提出了一个称为轨迹熵的度量方法，该方法从博弈中代理的多模态轨迹预测结果中提取代表不确定性的统计信号。然后利用此信号的信噪比来量化代理的游戏状态，并通过简单的门控机制优化现有的level-k博弈框架。

**结果:** 所提出的方法在Waymo和nuPlan数据集上的轨迹预测、开环和闭环规划任务方面展示了最先进的性能，预测精度提高了最多19.89%，规划精度提高了最多16.48%。

**结论:** 本文通过引入轨迹熵度量来揭示智能体在level-k博弈框架中的游戏状态，从而改进了现有框架的冗余和易错计算问题。结果表明，所提出的方法在Waymo和nuPlan数据集上实现了最先进的性能，并显著提高了预测和规划任务的精度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trajectory+Entropy%3A+Modeling+Game+State+Stability+from+Multimodality+Trajectory+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05810，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05810&send_immediately=true&force_search=false)

**原文摘要:** Complex interactions among agents present a significant challenge for
autonomous driving in real-world scenarios. Recently, a promising approach has
emerged, which formulates the interactions of agents as a level-k game
framework. It effectively decouples agent policies by hierarchical game levels.
However, this framework ignores both the varying driving complexities among
agents and the dynamic changes in agent states across game levels, instead
treating them uniformly. Consequently, redundant and error-prone computations
are introduced into this framework. To tackle the issue, this paper proposes a
metric, termed as Trajectory Entropy, to reveal the game status of agents
within the level-k game framework. The key insight stems from recognizing the
inherit relationship between agent policy uncertainty and the associated
driving complexity. Specifically, Trajectory Entropy extracts statistical
signals representing uncertainty from the multimodality trajectory prediction
results of agents in the game. Then, the signal-to-noise ratio of this signal
is utilized to quantify the game status of agents. Based on the proposed
Trajectory Entropy, we refine the current level-k game framework through a
simple gating mechanism, significantly improving overall accuracy while
reducing computational costs. Our method is evaluated on the Waymo and nuPlan
datasets, in terms of trajectory prediction, open-loop and closed-loop planning
tasks. The results demonstrate the state-of-the-art performance of our method,
with precision improved by up to 19.89% for prediction and up to 16.48% for
planning.

</details>


### [143] [Explainability in Context: A Multilevel Framework Aligning AI Explanations with Stakeholder with LLMs](https://arxiv.org/abs/2506.05887)
*Marilyn Bello, Rafael Bello, Maria-Matilde García, Ann Nowé, Iván Sevillano-García, Francisco Herrera*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种面向多方利益相关者的多级可解释AI框架，以提高AI系统的可信度和透明度。


<details>
  <summary>更多</summary>
  
**动机:** 人工智能在敏感领域的广泛应用增加了对系统准确性、可解释性和可信性的需求，但现有方法往往忽视了多样化的受众及其需求。

**方法:** 论文分析了现有可解释AI方法的局限性，提出了一个包含算法与领域层、人类中心层和社会可解释层的多级框架，并探讨了大型语言模型在增强社会层解释中的作用。

**结果:** 提出了一个多级可解释性框架，并通过案例研究证明了其在提升信任、技术保真度、用户参与和社会责任方面的能力。

**结论:** 该论文提出了一种多层次的可解释AI框架，旨在满足不同利益相关者对AI系统的知识、背景和伦理期望，并通过案例研究展示了其在技术保真度、用户参与和社会责任方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explainability+in+Context%3A+A+Multilevel+Framework+Aligning+AI+Explanations+with+Stakeholder+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05887，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05887&send_immediately=true&force_search=false)

**原文摘要:** The growing application of artificial intelligence in sensitive domains has
intensified the demand for systems that are not only accurate but also
explainable and trustworthy. Although explainable AI (XAI) methods have
proliferated, many do not consider the diverse audiences that interact with AI
systems: from developers and domain experts to end-users and society. This
paper addresses how trust in AI is influenced by the design and delivery of
explanations and proposes a multilevel framework that aligns explanations with
the epistemic, contextual, and ethical expectations of different stakeholders.
The framework consists of three layers: algorithmic and domain-based,
human-centered, and social explainability. We highlight the emerging role of
Large Language Models (LLMs) in enhancing the social layer by generating
accessible, natural language explanations. Through illustrative case studies,
we demonstrate how this approach facilitates technical fidelity, user
engagement, and societal accountability, reframing XAI as a dynamic,
trust-building process.

</details>


### [144] [Proactive Assistant Dialogue Generation from Streaming Egocentric Videos](https://arxiv.org/abs/2506.05904)
*Yichi Zhang, Xin Luna Dong, Zhaojiang Lin, Andrea Madotto, Anuj Kumar, Babak Damavandi, Joyce Chai, Seungwhan Moon*

**主要类别:** cs.AI

**AI概要:** 该论文介绍了一个全面的框架，通过合成对话数据集、自动评估指标和一种端到端模型，推进了实时、主动的AI助手的发展。


<details>
  <summary>更多</summary>
  
**动机:** 尽管对话式AI的最新进展相当显著，但开发用于感知任务指导的实时系统仍然具有挑战性，因为这些系统的发展受到数据收集和系统评估过程成本高昂且劳动密集的限制。

**方法:** 引入了一种新的数据整理流水线，开发了一套经过大规模人类研究验证的自动评估指标，并提出了一种端到端模型来处理视频输入以生成适当的响应。

**结果:** 合成对话数据集的大规模创建，开发出有效的自动评估指标，以及能够处理数据不平衡和长时间视频的新技术。

**结论:** 本文提出了一个全面的框架，为开发实时、主动的AI助手奠定了基础，能够引导用户完成各种任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Proactive+Assistant+Dialogue+Generation+from+Streaming+Egocentric+Videos，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05904，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05904&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in conversational AI have been substantial, but developing
real-time systems for perceptual task guidance remains challenging. These
systems must provide interactive, proactive assistance based on streaming
visual inputs, yet their development is constrained by the costly and
labor-intensive process of data collection and system evaluation. To address
these limitations, we present a comprehensive framework with three key
contributions. First, we introduce a novel data curation pipeline that
synthesizes dialogues from annotated egocentric videos, resulting in \dataset,
a large-scale synthetic dialogue dataset spanning multiple domains. Second, we
develop a suite of automatic evaluation metrics, validated through extensive
human studies. Third, we propose an end-to-end model that processes streaming
video inputs to generate contextually appropriate responses, incorporating
novel techniques for handling data imbalance and long-duration videos. This
work lays the foundation for developing real-time, proactive AI assistants
capable of guiding users through diverse tasks. Project page:
https://pro-assist.github.io/

</details>


### [145] [CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents](https://arxiv.org/abs/2506.05981)
*Qingbin Zeng, Ruotong Zhao, Jinzhu Mao, Haoyang Li, Fengli Xu, Yong Li*

**主要类别:** cs.AI

**AI概要:** 本研究提出了CrimeMind，一个结合大型语言模型和常规活动理论的新框架，用于更准确地模拟城市犯罪并评估环境变化对犯罪模式的影响。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服传统基于规则的ABM和深度学习方法在预测准确性、可解释性和环境适应性方面的局限性。

**方法:** 提出了一种新的LLM驱动的ABM框架CrimeMind，结合了常规活动理论（RAT）和城市犯罪模拟。

**结果:** 实验显示，CrimeMind在犯罪热点预测和空间分布准确性方面优于传统ABM和深度学习基线模型，最多提高了24%。此外，它成功捕捉了外部事件和政策干预对犯罪模式的影响。

**结论:** CrimeMind能够实现对个体行为的细粒度建模，并有助于评估现实世界的干预措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CrimeMind%3A+Simulating+Urban+Crime+with+Multi-Modal+LLM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05981，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05981&send_immediately=true&force_search=false)

**原文摘要:** Modeling urban crime is an important yet challenging task that requires
understanding the subtle visual, social, and cultural cues embedded in urban
environments. Previous work has predominantly focused on rule-based agent-based
modeling (ABM) and deep learning methods. ABMs offer interpretability of
internal mechanisms but exhibit limited predictive accuracy.In contrast, deep
learning methods are often effective in prediction but are less interpretable
and require extensive training data. Moreover, both lines of work lack the
cognitive flexibility to adapt to changing environments. Leveraging the
capabilities of large language models (LLMs), we propose CrimeMind, a novel
LLM-driven ABM framework for simulating urban crime within a multi-modal urban
context.A key innovation of our design is the integration of the Routine
Activity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to
process rich multi-modal urban features and reason about criminal
behavior.However, RAT requires LLM agents to infer subtle cues in evaluating
environmental safety as part of assessing guardianship, which can be
challenging for LLMs. To address this, we collect a small-scale human-annotated
dataset and align CrimeMind's perception with human judgment via a
training-free textual gradient method.Experiments across four major U.S. cities
demonstrate that CrimeMind outperforms both traditional ABMs and deep learning
baselines in crime hotspot prediction and spatial distribution accuracy,
achieving up to a 24% improvement over the strongest baseline.Furthermore, we
conduct counterfactual simulations of external incidents and policy
interventions and it successfully captures the expected changes in crime
patterns, demonstrating its ability to reflect counterfactual
scenarios.Overall, CrimeMind enables fine-grained modeling of individual
behaviors and facilitates evaluation of real-world interventions.

</details>


### [146] [CP-Bench: Evaluating Large Language Models for Constraint Modelling](https://arxiv.org/abs/2506.06052)
*Kostis Michailidis, Dimos Tsouros, Tias Guns*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一个新的约束建模基准数据集CP-Bench，并评估了不同约束建模系统中大型语言模型（LLMs）的表现，发现Python框架在生成准确模型方面表现优异，同时结合适当提示和优化方法可显著提高性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决约束建模是约束编程广泛应用瓶颈的问题，并填补现有评估数据集不足（如规模小、单一或领域特定）以更好地反映现实世界场景的多样性。

**方法:** 引入CP-Bench这一新型基准数据集，用于评估LLM驱动的约束建模能力；比较三种不同的约束建模系统（MiniZinc、CPMpy和OR-Tools CP-SAT），并评估基于提示和推理时间计算的方法对LLM生成模型的影响。

**结果:** 研究结果显示，结合文档丰富系统提示以及增强的采样和自我验证方法显著提升了LLM生成有效约束模型的能力，准确率高达70%。

**结论:** 论文得出结论，基于Python的约束建模框架在LLM生成模型中表现出更高的便捷性，并通过文档丰富的系统提示和增强的采样与自我验证方法进一步提升了准确率，达到了70%。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CP-Bench%3A+Evaluating+Large+Language+Models+for+Constraint+Modelling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06052，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06052&send_immediately=true&force_search=false)

**原文摘要:** Combinatorial problems are present in a wide range of industries. Constraint
Programming (CP) is a well-suited problem-solving paradigm, but its core
process, namely constraint modelling, is a bottleneck for wider adoption.
Aiming to alleviate this bottleneck, recent studies have explored using Large
Language Models (LLMs) as modelling assistants, transforming combinatorial
problem descriptions to executable constraint models, similar to coding
assistants. However, the existing evaluation datasets for constraint modelling
are often limited to small, homogeneous, or domain-specific instances, which do
not capture the diversity of real-world scenarios. This work addresses this gap
by introducing CP-Bench, a novel benchmark dataset that includes a diverse set
of well-known combinatorial problem classes sourced from the CP community,
structured explicitly for evaluating LLM-driven CP modelling. With this
dataset, and given the variety of constraint modelling frameworks, we compare
and evaluate the modelling capabilities of LLMs for three distinct constraint
modelling systems, which vary in abstraction level and underlying syntax: the
high-level MiniZinc language and Python-based CPMpy library, and the
lower-level Python interface of the OR-Tools CP-SAT solver. In order to enhance
the ability of LLMs to produce valid constraint models, we systematically
evaluate the use of prompt-based and inference-time compute methods adapted
from existing LLM-based code generation research. Our results underscore the
modelling convenience provided by Python-based frameworks, as well as the
effectiveness of documentation-rich system prompts, which, augmented with
repeated sampling and self-verification, achieve further improvements, reaching
up to 70\% accuracy on this new, highly challenging benchmark.

</details>


### [147] [Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning](https://arxiv.org/abs/2506.06121)
*Ziyu Zhang, Peilan Xu, Yuetong Sun, Yuhui Shi, Wenjian Luo*

**主要类别:** cs.AI

**AI概要:** 本文研究大规模路线规划问题，提出了新的多目标协同进化算法，解决了组件不平衡和交互问题，证明其性能优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 大规模路线规划是旅行商问题的一个变体，旨在确定一条最优路径，在满足旅行时间限制的同时最大化兴趣点得分并最小化时间和成本，但严格可分解性难以满足。

**方法:** 提出了一种基于各组件归一化适应度的动态分解策略，并定义了优化潜力和计算资源分配策略。

**结果:** 引入了弱可分解性的定义并推导出相应的图结构，并通过实验验证了所提算法在现实世界数据集上的优越性能。

**结论:** 论文得出了一种新的多目标协同进化算法在大规模路线规划中的应用效果优于现有技术，尤其是在问题规模增大时。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decomposability-Guaranteed+Cooperative+Coevolution+for+Large-Scale+Itinerary+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06121，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06121&send_immediately=true&force_search=false)

**原文摘要:** Large-scale itinerary planning is a variant of the traveling salesman
problem, aiming to determine an optimal path that maximizes the collected
points of interest (POIs) scores while minimizing travel time and cost, subject
to travel duration constraints. This paper analyzes the decomposability of
large-scale itinerary planning, proving that strict decomposability is
difficult to satisfy, and introduces a weak decomposability definition based on
a necessary condition, deriving the corresponding graph structures that fulfill
this property. With decomposability guaranteed, we propose a novel
multi-objective cooperative coevolutionary algorithm for large-scale itinerary
planning, addressing the challenges of component imbalance and interactions.
Specifically, we design a dynamic decomposition strategy based on the
normalized fitness within each component, define optimization potential
considering component scale and contribution, and develop a computational
resource allocation strategy. Finally, we evaluate the proposed algorithm on a
set of real-world datasets. Comparative experiments with state-of-the-art
multi-objective itinerary planning algorithms demonstrate the superiority of
our approach, with performance advantages increasing as the problem scale
grows.

</details>


### [148] [Integer Linear Programming Preprocessing for Maximum Satisfiability](https://arxiv.org/abs/2506.06216)
*Jialu Zhang, Chu-Min Li, Sami Cherif, Shuolin Li, Zhifei Zheng*

**主要类别:** cs.AI

**AI概要:** 这篇论文简要总结是，通过利用ILP预处理技术，可以增强MaxSAT求解器的性能，并减少对ILP求解器的依赖。


<details>
  <summary>更多</summary>
  
**动机:** 由于MaxSAT问题在实际应用中的重要性和普遍性，以及多数MaxSAT求解器广泛采用ILP求解器作为其组合部分，本文旨在探讨ILP预处理技术如何影响MaxSAT求解效果。

**方法:** 研究采用了实验方法，评估了ILP预处理技术对MaxSAT求解的影响，并与MaxSAT评估2024中的获奖求解器WMaxCDCL-OpenWbo1200进行了对比。

**结果:** 实验结果显示，ILP预处理技术帮助WMaxCDCL-OpenWbo1200求解器解决了15个额外的实例，并表明当前最先进的MaxSAT求解器在其工具集中大量使用ILP求解器。

**结论:** 本文得出结论，ILP预处理技术对MaxSAT求解有积极影响，并且所提出的方法减少了在包含WMaxCDCL或MaxCDCL的工具集中调用ILP求解器的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Integer+Linear+Programming+Preprocessing+for+Maximum+Satisfiability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06216，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06216&send_immediately=true&force_search=false)

**原文摘要:** The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge
with numerous practical applications. In recent MaxSAT evaluations, most MaxSAT
solvers have adopted an ILP solver as part of their portfolios. This paper
investigates the impact of Integer Linear Programming (ILP) preprocessing
techniques on MaxSAT solving. Experimental results show that ILP preprocessing
techniques help WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024
in the unweighted track, solve 15 additional instances. Moreover, current
state-of-the-art MaxSAT solvers heavily use an ILP solver in their portfolios,
while our proposed approach reduces the need to call an ILP solver in a
portfolio including WMaxCDCL or MaxCDCL.

</details>


### [149] [PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time](https://arxiv.org/abs/2506.06254)
*Weizhi Zhang, Xinyang Zhang, Chenwei Zhang, Liangwei Yang, Jingbo Shang, Zhepei Wei, Henry Peng Zou, Zijie Huang, Zhengyang Wang, Yifan Gao, Xiaoman Pan, Lian Xiong, Jingguo Liu, Philip S. Yu, Xian Li*

**主要类别:** cs.AI

**AI概要:** 为了解决现有大型语言模型代理无法灵活满足用户个性化需求的问题，研究者提出了一个名为PersonaAgent的新框架，并证明了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LLM代理往往采用一刀切的方式，缺乏灵活性以应对用户的多样化需求和偏好。

**方法:** 开发了一个名为PersonaAgent的框架，包括个性化的记忆模块和行动模块，并提出了一种测试时用户偏好对齐策略。

**结果:** 实验评估表明，PersonaAgent不仅有效地实现了动作空间的个性化，而且在测试时实际应用中也具有良好的扩展性。

**结论:** PersonaAgent提供了一种可行且有效的方法来实现LLM代理的个性化，从而传递定制化的、动态的用户体验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PersonaAgent%3A+When+Large+Language+Model+Agents+Meet+Personalization+at+Test+Time，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06254，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06254&send_immediately=true&force_search=false)

**原文摘要:** Large Language Model (LLM) empowered agents have recently emerged as advanced
paradigms that exhibit impressive capabilities in a wide range of domains and
tasks. Despite their potential, current LLM agents often adopt a
one-size-fits-all approach, lacking the flexibility to respond to users'
varying needs and preferences. This limitation motivates us to develop
PersonaAgent, the first personalized LLM agent framework designed to address
versatile personalization tasks. Specifically, PersonaAgent integrates two
complementary components - a personalized memory module that includes episodic
and semantic memory mechanisms; a personalized action module that enables the
agent to perform tool actions tailored to the user. At the core, the persona
(defined as unique system prompt for each user) functions as an intermediary:
it leverages insights from personalized memory to control agent actions, while
the outcomes of these actions in turn refine the memory. Based on the
framework, we propose a test-time user-preference alignment strategy that
simulate the latest n interactions to optimize the persona prompt, ensuring
real-time user preference alignment through textual loss feedback between
simulated and ground-truth responses. Experimental evaluations demonstrate that
PersonaAgent significantly outperforms other baseline methods by not only
personalizing the action space effectively but also scaling during test-time
real-world applications. These results underscore the feasibility and potential
of our approach in delivering tailored, dynamic user experiences.

</details>


### [150] [Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens](https://arxiv.org/abs/2506.06261)
*Jihwan Jeong, Xiaoyu Wang, Jingmin Wang, Scott Sanner, Pascal Poupart*

**主要类别:** cs.AI

**AI概要:** RefPlan enhances offline reinforcement learning by integrating Bayesian uncertainty modeling with planning, improving policy robustness and adaptability under limited data conditions.


<details>
  <summary>更多</summary>
  
**动机:** Offline reinforcement learning struggles with high epistemic uncertainty due to limited data and existing methods restrict adaptivity and generalization with fixed conservative policies.

**方法:** Reflect-then-Plan (RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach that recasts planning as Bayesian posterior estimation.

**结果:** Empirical results show RefPlan significantly improves performance of conservative offline RL policies, maintains robust performance under high uncertainty and limited data, and demonstrates resilience to changing environment dynamics.

**结论:** RefPlan improves the flexibility, generalizability, and robustness of offline-learned policies by unifying uncertainty modeling and MB planning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reflect-then-Plan%3A+Offline+Model-Based+Planning+through+a+Doubly+Bayesian+Lens，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06261，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06261&send_immediately=true&force_search=false)

**原文摘要:** Offline reinforcement learning (RL) is crucial when online exploration is
costly or unsafe but often struggles with high epistemic uncertainty due to
limited data. Existing methods rely on fixed conservative policies, restricting
adaptivity and generalization. To address this, we propose Reflect-then-Plan
(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.
RefPlan unifies uncertainty modeling and MB planning by recasting planning as
Bayesian posterior estimation. At deployment, it updates a belief over
environment dynamics using real-time observations, incorporating uncertainty
into MB planning via marginalization. Empirical results on standard benchmarks
show that RefPlan significantly improves the performance of conservative
offline RL policies. In particular, RefPlan maintains robust performance under
high epistemic uncertainty and limited data, while demonstrating resilience to
changing environment dynamics, improving the flexibility, generalizability, and
robustness of offline-learned policies.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [151] [Online Conformal Model Selection for Nonstationary Time Series](https://arxiv.org/abs/2506.05544)
*Shibo Li, Yao Zheng*

**主要类别:** stat.ML

**AI概要:** 这篇论文提出了一种用于非平稳时间序列在线模型选择的新框架MPS，结合了共形推断与模型置信集，能够适应未知形式的非平稳性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的模型选择方法依赖于平稳性假设，在动态环境中表现不佳。然而现实世界的数据很少是平稳的，因此需要解决在非平稳条件下的模型选择问题。

**方法:** 通过将共形推断与模型置信集相结合，MPS实时更新候选模型的置信集，以适应任何给定时间的最佳模型变化，并保证指定的长期覆盖概率。

**结果:** 实验表明，MPS能够在非平稳条件下可靠且高效地识别最优模型，并产生高质量、小规模的模型集合，提供对动态变化的深入洞察。

**结论:** MPS是一种通用框架，适用于各种数据生成过程、数据结构、模型类别、训练方法和评估指标，具有广泛的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Online+Conformal+Model+Selection+for+Nonstationary+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05544，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05544&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces the MPS (Model Prediction Set), a novel framework for
online model selection for nonstationary time series. Classical model selection
methods, such as information criteria and cross-validation, rely heavily on the
stationarity assumption and often fail in dynamic environments which undergo
gradual or abrupt changes over time. Yet real-world data are rarely stationary,
and model selection under nonstationarity remains a largely open problem. To
tackle this challenge, we combine conformal inference with model confidence
sets to develop a procedure that adaptively selects models best suited to the
evolving dynamics at any given time. Concretely, the MPS updates in real time a
confidence set of candidate models that covers the best model for the next time
period with a specified long-run probability, while adapting to nonstationarity
of unknown forms. Through simulations and real-world data analysis, we
demonstrate that MPS reliably and efficiently identifies optimal models under
nonstationarity, an essential capability lacking in offline methods. Moreover,
MPS frequently produces high-quality sets with small cardinality, whose
evolution offers deeper insights into changing dynamics. As a generic
framework, MPS accommodates any data-generating process, data structure, model
class, training method, and evaluation metric, making it broadly applicable
across diverse problem settings.

</details>


### [152] [Nonlinear Causal Discovery through a Sequential Edge Orientation Approach](https://arxiv.org/abs/2506.05590)
*Stella Huang, Qing Zhou*

**主要类别:** stat.ML

**AI概要:** 本研究提出了一种新的因果发现方法，通过PANM和统计检验在CPDAG中识别因果方向，解决了现有方法在计算效率和模型假设上的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 现有因果发现方法通常依赖于过于严格的模型假设、独立性检验或需要大量计算时间，因此需要一种更高效且鲁棒的方法。

**方法:** 通过利用成对加性噪声模型(PANM)和统计检验方法，在已估计的CPDAG中按边的PANM匹配度排序后依次确定边的方向。

**结果:** 实验表明，新方法在合成和真实数据集上均具有较高的计算效率、对模型误设定的鲁棒性以及优于许多现有非线性DAG学习方法的表现。

**结论:** 该论文提出了一种新的基于约束的因果发现算法，能够在非线性加性噪声模型下有效地学习有向无环图，并证明了其在大样本下的结构一致性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Nonlinear+Causal+Discovery+through+a+Sequential+Edge+Orientation+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.05590，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.05590&send_immediately=true&force_search=false)

**原文摘要:** Recent advances have established the identifiability of a directed acyclic
graph (DAG) under additive noise models (ANMs), spurring the development of
various causal discovery methods. However, most existing methods make
restrictive model assumptions, rely heavily on general independence tests, or
require substantial computational time. To address these limitations, we
propose a sequential procedure to orient undirected edges in a completed
partial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging
the pairwise additive noise model (PANM) to identify their causal directions.
We prove that this procedure can recover the true causal DAG assuming a
restricted ANM. Building on this result, we develop a novel constraint-based
algorithm for learning causal DAGs under nonlinear ANMs. Given an estimated
CPDAG, we develop a ranking procedure that sorts undirected edges by their
adherence to the PANM, which defines an evaluation order of the edges. To
determine the edge direction, we devise a statistical test that compares the
log-likelihood values, evaluated with respect to the competing directions, of a
sub-graph comprising just the candidate nodes and their identified parents in
the partial DAG. We further establish the structural learning consistency of
our algorithm in the large-sample limit. Extensive experiments on synthetic and
real-world datasets demonstrate that our method is computationally efficient,
robust to model misspecification, and consistently outperforms many existing
nonlinear DAG learning methods.

</details>


### [153] [Multilevel neural simulation-based inference](https://arxiv.org/abs/2506.06087)
*Yuga Hikida, Ayush Bharti, Niall Jeffrey, François-Xavier Briol*

**主要类别:** stat.ML

**AI概要:** 论文提出一种新颖的神经模拟推断方法，结合多级蒙特卡罗技术，在固定计算预算下显著提升了推断精度。


<details>
  <summary>更多</summary>
  
**动机:** 当模型仅以模拟器的形式存在时，贝叶斯推断（尤其是神经模拟推断）变得流行，但在模拟器计算成本高昂时其性能会受到影响。

**方法:** 利用多级蒙特卡罗技术处理具有不同成本和保真度的多个模拟器设置下的神经模拟推断问题。

**结果:** 通过理论分析和大量实验验证了所提方法的有效性，表明其在有限计算资源下能显著提升精度。

**结论:** 本文提出了一种基于多级蒙特卡罗技术的新方法，可以在给定固定计算预算的情况下显著提高SBI方法的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilevel+neural+simulation-based+inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.06087，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.06087&send_immediately=true&force_search=false)

**原文摘要:** Neural simulation-based inference (SBI) is a popular set of methods for
Bayesian inference when models are only available in the form of a simulator.
These methods are widely used in the sciences and engineering, where writing
down a likelihood can be significantly more challenging than constructing a
simulator. However, the performance of neural SBI can suffer when simulators
are computationally expensive, thereby limiting the number of simulations that
can be performed. In this paper, we propose a novel approach to neural SBI
which leverages multilevel Monte Carlo techniques for settings where several
simulators of varying cost and fidelity are available. We demonstrate through
both theoretical analysis and extensive experiments that our method can
significantly enhance the accuracy of SBI methods given a fixed computational
budget.

</details>
