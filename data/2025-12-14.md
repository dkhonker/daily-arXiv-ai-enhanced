<div id=toc></div>

# 目录

- [cs.AI](#cs.AI) [总数: 54]
- [cs.CL](#cs.CL) [总数: 31]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples](https://arxiv.org/abs/2512.09931)
*Akaash Chatterjee, Suman Kundu*

**主要类别:** cs.AI

**AI概要:** ExaCraft是一个AI驱动的个性化学习示例生成系统，通过分析学习者的动态上下文来创建文化相关且个性化的学习示例


<details>
  <summary>更多</summary>
  
**动机:** 现有教育AI工具未能专注于生成个性化示例或适应学习者不断变化的理解水平、困难和学习技能增长

**方法:** 利用Google Gemini AI和Python Flask API，通过Chrome扩展访问，结合用户定义的个人资料和实时学习者行为分析

**结果:** 系统能够适应学习上下文的五个关键方面：困难指标、掌握模式、主题进展历史、会话边界和学习进展信号

**结论:** ExaCraft能够从基础概念演进到高级技术实现，响应主题重复、再生请求和不同用例中的主题进展模式

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ExaCraft%3A+Dynamic+Learning+Context+Adaptation+for+Personalized+Educational+Examples，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09931&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.

</details>


### [2] [Suzume-chan: Your Personal Navigator as an Embodied Information Hub](https://arxiv.org/abs/2512.09932)
*Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种名为'具身信息枢纽'的新知识共享方式，通过物理和对话交互来改善知识获取体验，并开发了本地运行的软体AI代理Suzume-chan原型。


<details>
  <summary>更多</summary>
  
**动机:** 数字工具虽然改善了信息获取，但缺乏深度理解所需的连接感，专家知识获取通常需要实时人际沟通。

**方法:** 基于社会临场感理论，开发了运行本地语言模型和检索增强生成(RAG)的小型软体AI代理Suzume-chan，通过语音解释学习和对话响应实现知识共享。

**结果:** 原型系统通过物理对话交互减少了心理距离，使知识共享更加温暖和以人为中心。

**结论:** 具身信息枢纽通过结合物理存在和对话交互，为数字知识共享创造了更人性化的连接体验，验证了社会临场感理论在改善人机知识传递中的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Suzume-chan%3A+Your+Personal+Navigator+as+an+Embodied+Information+Hub，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09932，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09932&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of "being together" enhances communication. An "Embodied Information Hub" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.

</details>


### [3] [Exploring Health Misinformation Detection with Multi-Agent Debate](https://arxiv.org/abs/2512.09935)
*Chih-Han Chen, Chen-Han Tsai, Yu-Shao Peng*

**主要类别:** cs.AI

**AI概要:** 提出一个两阶段健康信息检测框架：先通过大语言模型计算证据一致性分数，若分数不足则启动多智能体辩论阶段，综合冲突证据生成有理由的结论


<details>
  <summary>更多</summary>
  
**动机:** 在线健康错误信息泛滥，需要高质量证据检索和严谨推理过程来进行有效验证

**方法:** 两阶段框架：1) 一致性分数预测阶段 - 使用大语言模型独立评估检索到的文章并计算总体证据立场的一致性分数；2) 多智能体辩论阶段 - 当一致性分数低于阈值时，多个智能体进行结构化辩论以综合冲突证据

**结果:** 实验结果表明，这种两阶段方法相比基线方法表现出更优越的性能

**结论:** 将自动评分与协作推理相结合对复杂验证任务具有重要价值

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Health+Misinformation+Detection+with+Multi-Agent+Debate，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09935&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.

</details>


### [4] [Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting](https://arxiv.org/abs/2512.09944)
*Moein Heidari, Mohammad Amin Roohi, Armin Khosravi, Ilker Hacihaliloglu*

**主要类别:** cs.AI

**AI概要:** Echo-CoPilot是一个基于大语言模型的多视图、多任务超声心动图智能代理，通过协调多个专业工具实现临床统一的超声心动图分析，在MIMIC-EchoQA基准测试中达到50.8%的准确率，优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 超声心动图分析是心血管诊疗的核心但需要手动完成，现有基础模型只能在孤立子任务上表现良好，缺乏统一的临床评估能力。

**方法:** 采用ReAct风格循环，使用大语言模型协调视图识别、心脏结构分割、测量、疾病预测和报告生成等专业工具，整合输出为指南感知的答案和叙述性总结。

**结果:** 在MIMIC-EchoQA基准测试中达到50.8%的准确率，优于通用和生物医学视频视觉语言模型，能够处理临床决策阈值附近的疑难病例。

**结论:** Echo-CoPilot通过多任务协调实现了临床统一的超声心动图分析，展示了在复杂临床场景中的应用潜力，代码将在论文接受后发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Echo-CoPilot%3A+A+Multi-View%2C+Multi-Task+Agent+for+Echocardiography+Interpretation+and+Reporting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09944，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09944&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.

</details>


### [5] [Fuzzy Hierarchical Multiplex](https://arxiv.org/abs/2512.09976)
*Alexis Kafantaris*

**主要类别:** cs.AI

**AI概要:** 提出了一种扩展FCM因果关系的模糊优化框架，用于服务流程设计中的信息传输优化，包含逻辑层次分析和数学基础研究


<details>
  <summary>更多</summary>
  
**动机:** 扩展FCM因果关系，建立能够分析概念逻辑蕴含和层次结构的框架，为服务流程设计中的信息传输提供优化方法

**方法:** 利用动态特性将数据映射到度量空间，构建多重网络框架来检验概念间的逻辑蕴含和层次关系，进行白盒理论分析和数学逻辑推导

**结果:** 开发了一个新的模糊优化框架，能够系统地分析概念间的因果关系和层次结构，并提供了简洁优雅的逻辑分析步骤

**结论:** 该框架为服务流程设计中的信息传输服务优化提供了理论基础和方法论支持，FHM分析展示了其逻辑严谨性和应用潜力

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fuzzy+Hierarchical+Multiplex，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09976，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09976&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** A new fuzzy optimization framework that extends FCM causality is proposed. This model utilizes the dynamics to map data into metrics and create a framework that examines logical implication and hierarchy of concepts using a multiplex. Moreover, this is a white-theoretical paper introducing the framework and analyzing the logic and math behind it. Upon this extension the main objectives and the orientation of this framework is expounded and exemplified; this framework is meant for service optimization of information transmission in service process design. Lastly, a thorough analysis of the FHM is included which is done following the logical steps in a simple and elegant manner.

</details>


### [6] [Exploring LLMs for Scientific Information Extraction Using The SciEx Framework](https://arxiv.org/abs/2512.10004)
*Sha Li, Ayush Sadekar, Nathan Self, Yiqi Su, Lars Andersland, Mira Chaplin, Annabel Zhang, Hyoju Yang, James B Henderson, Krista Wigginton, Linsey Marr, T. M. Murali, Naren Ramakrishnan*

**主要类别:** cs.AI

**AI概要:** SciEx是一个模块化的科学信息提取框架，通过解耦PDF解析、多模态检索、提取和聚合等关键组件，解决了LLM在处理长文档、多模态内容和快速变化的数据模式时的挑战。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在处理科学文献的长上下文文档、多模态内容以及跨多个出版物的一致细粒度信息提取方面存在困难，特别是在数据模式快速变化时难以重新架构或微调系统。

**方法:** 提出了SciEx框架，采用模块化和可组合设计，分离PDF解析、多模态检索、提取和聚合等组件，支持新模型、提示策略和推理机制的灵活集成。

**结果:** 在三个科学主题的数据集上评估了SciEx提取细粒度信息的准确性和一致性，验证了其有效性。

**结论:** 研究结果提供了对当前基于LLM的提取流程优势和局限性的实践见解，SciEx框架为科学信息提取提供了更灵活和可扩展的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+LLMs+for+Scientific+Information+Extraction+Using+The+SciEx+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10004&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.

</details>


### [7] [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)
*Salomé Guilbert, Cassandra Masschelein, Jeremy Goumaz, Bohdan Naida, Philippe Schwaller*

**主要类别:** cs.AI

**AI概要:** DynaMate是一个基于多智能体的自动化分子动力学模拟框架，能够自主执行蛋白质和蛋白质-配体系统的完整MD工作流程，包括自由能结合亲和力计算。


<details>
  <summary>更多</summary>
  
**动机:** 分子动力学模拟在药物发现和蛋白质工程中应用广泛，但其技术复杂性（参数化、输入准备、软件配置）阻碍了广泛高效使用。现有智能体LLM尚未成功实现蛋白质-配体MD工作流程的自动化。

**方法:** 开发DynaMate模块化多智能体框架，集成动态工具使用、网络搜索、PaperQA和自校正行为。包含三个专门模块：实验规划、模拟执行和结果分析。在12个不同复杂度的基准系统上评估性能。

**结果:** DynaMate能够可靠地执行完整MD模拟，通过迭代推理校正运行时错误，并生成有意义的蛋白质-配体相互作用分析。

**结论:** 该自动化框架为未来生物分子和药物设计应用提供了标准化、可扩展且时间高效的分子建模流程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DynaMate%3A+An+Autonomous+Agent+for+Protein-Ligand+Molecular+Dynamics+Simulations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10034&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.

</details>


### [8] [SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration](https://arxiv.org/abs/2512.10046)
*Yan Zhuang, Jiawei Ren, Xiaokang Ye, Jianzhi Shen, Ruixuan Zhang, Tianai Yue, Muhammad Faayez, Xuhong He, Ziqiao Ma, Lianhui Qin, Zhiting Hu, Tianmin Shu*

**主要类别:** cs.AI

**AI概要:** SWR是一个基于虚幻引擎5构建的大规模、逼真城市环境仿真平台，用于评估机器人在复杂城市场景中的多模态指令跟随和多机器人协作能力，现有先进模型在这些任务中表现不佳。


<details>
  <summary>更多</summary>
  
**动机:** 当前基础模型在机器人领域主要关注室内家居场景，缺乏针对大规模城市环境的仿真平台和评估基准，无法全面测试机器人在真实城市环境中的关键能力。

**方法:** 基于Unreal Engine 5构建SimWorld-Robotics平台，程序化生成无限逼真的城市场景，包含动态元素（行人、交通系统），支持多机器人控制和通信，并建立了两个基准任务：多模态指令跟随任务和多智能体搜索任务。

**结果:** 实验结果表明，包括视觉语言模型在内的最先进模型在SWR任务中表现不佳，缺乏在城市环境中所需的稳健感知、推理和规划能力。

**结论:** SWR平台为城市环境中的具身AI研究提供了重要的仿真环境和评估基准，揭示了现有模型在城市场景中的局限性，推动了更强大机器人能力的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SimWorld-Robotics%3A+Synthesizing+Photorealistic+and+Dynamic+Urban+Environments+for+Multimodal+Robot+Navigation+and+Collaboration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10046，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10046&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.

</details>


### [9] [Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning](https://arxiv.org/abs/2512.10054)
*Logan Robbins*

**主要类别:** cs.AI

**AI概要:** PDT是一种参数高效的并行解码架构，通过在冻结预训练模型中嵌入协调原语来解决LLM自回归解码的延迟瓶颈问题，实现了77.8%的精确度而无需修改主干权重。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型的自回归解码本质上是顺序的，存在与输出长度线性相关的延迟瓶颈。现有的分解填充方法由于缺乏跨流通信而遭受连贯性漂移问题。

**方法:** 提出并行解码变换器(PDT)，注入轻量级的推测性注释条件(SNC)适配器，允许并行解码流通过共享的动态潜在空间进行同步。将协调制定为推测共识问题，通过学习的验证头进行门控。

**结果:** 在冻结的200亿参数骨干网络上使用5万步课程验证，PDT实现了有效的自我校正，在覆盖预测中达到77.8%的精确度，无需修改主干权重即可恢复近似串行语义。

**结论:** PDT为结构化并行生成提供了一个可扩展、高效的替代方案，避免了完整的模型微调，同时保持了生成质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Parallel+Decoder+Transformer%3A+Model-Internal+Parallel+Decoding+with+Speculative+Invariance+via+Note+Conditioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10054&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \textit{coherence drift} due to the lack of cross-stream communication. In this work, we introduce the \textbf{Parallel Decoder Transformer (PDT)}, a parameter-efficient architecture that embeds coordination primitives directly into the inference process of a frozen pre-trained model.
  Instead of retraining the base model, PDT injects lightweight \textit{Speculative Note Conditioning (SNC)} adapters that allow parallel decoding streams to synchronize via a shared, dynamic latent space. We formulate coordination as a \textit{speculative consensus} problem, where sibling streams broadcast semantic ``notes'' to a global bus, gated by a learned verification head. We validate our approach on a 50,000-step curriculum using a frozen 20B-parameter backbone. Our results demonstrate that PDT achieves effective self-correction, reaching \textbf{77.8\% precision} in coverage prediction and recovering approximate serial semantics without modifying the trunk weights. This establishes PDT as a scalable, efficient alternative to full model fine-tuning for structured parallel generation.

</details>


### [10] [Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research](https://arxiv.org/abs/2512.10058)
*Dani Roytburg, Beck Miller*

**主要类别:** cs.AI

**AI概要:** 该论文通过大规模文献计量和合作网络分析发现，AI安全与AI伦理研究领域存在明显的结构性分离，80%以上的合作发生在各自领域内部，跨领域交流主要依赖少数关键研究者。


<details>
  <summary>更多</summary>
  
**动机:** AI发展加速使得对齐工作日益紧迫，但安全研究和伦理研究沿着两条平行轨道发展，对"对齐"的定义和理解存在分歧，导致研究相对孤立。

**方法:** 使用文献计量和合作网络分析方法，分析了2010-2025年间12个主要ML和NLP会议的6,442篇论文，考察安全与伦理领域的合作模式。

**结果:** 发现超过80%的合作发生在各自领域内部，跨领域连通性高度集中，约5%的论文贡献了85%以上的桥梁链接，移除少数关键研究者会显著增加领域隔离。

**结论:** 安全与伦理的分歧不仅是概念上的，更是制度性的，需要通过共享基准、跨机构平台和混合方法来整合技术安全工作和规范伦理，以构建既稳健又公正的AI系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mind+the+Gap%21+Pathways+Towards+Unifying+AI+Safety+and+Ethics+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10058&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, "aligned" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.
  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.

</details>


### [11] [Linear socio-demographic representations emerge in Large Language Models from indirect cues](https://arxiv.org/abs/2512.10065)
*Paul Bouchaud, Pedro Ramaciotti*

**主要类别:** cs.AI

**AI概要:** LLMs能从姓名和职业等间接线索中编码用户的社会人口属性，形成可解释的线性表征，这些隐性表征会影响模型的下游行为如职业推荐，即使通过偏见测试的模型仍可能存在隐性偏见。


<details>
  <summary>更多</summary>
  
**动机:** 研究LLMs如何从对话伙伴的间接线索（如姓名、职业）推断社会人口属性，并探索这些隐性表征如何影响模型行为。

**方法:** 在四个开源Transformer LLMs（Magistral 24B等）上探测残差流，使用显性人口统计披露提示，分析姓名激活的人口普查对齐表征和职业触发的劳动力统计相关表征。

**结果:** 发现LLMs在激活空间中形成线性可解释的人口统计表征，姓名激活性别和种族表征，职业激活与真实劳动力统计相关的表征，这些表征主动影响下游行为。

**结论:** LLMs会隐性形成社会人口属性表征并影响行为，即使通过偏见基准测试的模型仍可能存在和利用隐性偏见，这对大规模应用的公平性有重要影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Linear+socio-demographic+representations+emerge+in+Large+Language+Models+from+indirect+cues，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10065，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10065&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

</details>


### [12] [Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit](https://arxiv.org/abs/2512.10092)
*Nick Jiang, Xiaoqing Sun, Lisa Dunlap, Lewis Smith, Neel Nanda*

**主要类别:** cs.AI

**AI概要:** 稀疏自编码器(SAE)嵌入比基于LLM的方法成本更低、更可靠，比稠密嵌入更具可控性，能够识别数据集差异、概念相关性，是分析非结构化数据的多功能工具


<details>
  <summary>更多</summary>
  
**动机:** 当前分析大规模文本语料库的方法依赖昂贵的LLM技术或稠密嵌入模型，缺乏对关注属性的控制能力，需要更经济、可控的分析方法

**方法:** 使用稀疏自编码器(SAEs)创建SAE嵌入表示，其维度映射到可解释的概念，通过四个数据分析任务验证效果

**结果:** SAE嵌入比LLM方法成本降低2-8倍，能发现更大的差异，更可靠地识别偏见；通过概念过滤可实现基于关注维度的文档聚类，在基于属性的检索中优于稠密嵌入

**结论:** SAEs是分析非结构化数据的通用工具，强调通过数据解释模型的重要性，能够揭示模型行为变化和训练数据中的触发短语等洞察

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Embeddings+with+Sparse+Autoencoders%3A+A+Data+Analysis+Toolkit，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10092，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10092&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding "trigger" phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.

</details>


### [13] [Robust AI Security and Alignment: A Sisyphean Endeavor?](https://arxiv.org/abs/2512.10100)
*Apostol Vassilev*

**主要类别:** cs.AI

**AI概要:** N/A


<details>
  <summary>更多</summary>
  
**动机:** N/A

**方法:** N/A

**结果:** N/A

**结论:** N/A

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+AI+Security+and+Alignment%3A+A+Sisyphean+Endeavor%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10100&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel's incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.

</details>


### [14] [Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups](https://arxiv.org/abs/2512.10105)
*Soorya Ram Shimgekar, Abhay Goyal, Lam Yin Cheung, Roy Ka-Wei Lee, Koustuv Saha, Pi Zonooz, Navin Kumar*

**主要类别:** cs.AI

**AI概要:** 该研究提出一个两阶段计算框架来分析新加坡Telegram群组中的阴谋论内容，发现阴谋论内容被编织在日常讨论中而非局限于孤立回音室，识别出7种叙事原型，挑战了关于网络激进化的常见假设。


<details>
  <summary>更多</summary>
  
**动机:** 阴谋论话语在数字通信生态系统中日益普遍，但其结构和传播难以研究，需要新的计算方法来分析其嵌入日常讨论的特征。

**方法:** 1) 微调RoBERTa-large模型分类阴谋论消息(F1-score 0.866)；2) 构建带符号信念图，节点代表消息，边反映信念标签对齐；3) 提出带符号分离损失的SiBeGNN模型学习嵌入表示；4) 通过层次聚类识别叙事类型。

**结果:** 在553,648条消息中识别出7种叙事原型：法律话题、医疗关切、媒体讨论、金融、权威矛盾、群组管理、日常聊天。SiBeGNN聚类质量(cDBI=8.38)优于基线方法(13.60-67.27)，专家评估一致性达88%。

**结论:** 阴谋论消息不仅出现在怀疑或不信任的群组中，也存在于金融、法律和日常事务的常规讨论中，表明阴谋论话语在普通社交互动中运作，挑战了网络激进化的传统认知，为立场检测和政治传播研究提供了新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Modeling+Narrative+Archetypes+in+Conspiratorial+Narratives%3A+Insights+from+Singapore-Based+Telegram+Groups，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10105，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10105&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.
  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.

</details>


### [15] [AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice](https://arxiv.org/abs/2512.10114)
*Mesafint Fanuel, Mahmoud Nabil Mahmoud, Crystal Cook Marshal, Vishal Lakhotia, Biswanath Dari, Kaushik Roy, Shaohu Zhang*

**主要类别:** cs.AI

**AI概要:** AgriRegion是一个专门为农业咨询设计的RAG框架，通过地理空间元数据注入和区域优先重排序机制，有效减少LLM在农业领域的幻觉问题，提供更准确的本地化农业建议


<details>
  <summary>更多</summary>
  
**动机:** 通用大语言模型在农业领域存在严重的上下文幻觉问题，由于土壤、气候和当地法规的差异，可能给出非事实性或地区不适用的建议

**方法:** 开发AgriRegion RAG框架，包含地理空间元数据注入层和区域优先重排序机制，限制知识库为经过验证的本地农业推广服务，并在检索时强制执行地理空间约束

**结果:** 实验显示AgriRegion相比最先进的LLM系统减少幻觉10-20%，并显著提高了信任分数

**结论:** AgriRegion框架通过区域感知的检索增强生成方法，有效解决了农业咨询中的地理特异性问题，为LLM在农业领域的可靠应用提供了可行方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgriRegion%3A+Region-Aware+Retrieval+for+High-Fidelity+Agricultural+Advice，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10114&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.

</details>


### [16] [The 2025 Foundation Model Transparency Index](https://arxiv.org/abs/2512.10169)
*Alexander Wan, Kevin Klyman, Sayash Kapoor, Nestor Maslej, Shayne Longpre, Betty Xiong, Percy Liang, Rishi Bommasani*

**主要类别:** cs.AI

**AI概要:** 2025年基础模型透明度指数显示，主要AI公司的透明度从2024年的58分下降到2025年的40分，IBM表现最佳(95分)，xAI和Midjourney最差(14分)，训练数据和部署后影响是最不透明的领域。


<details>
  <summary>更多</summary>
  
**动机:** 评估基础模型开发商的透明度实践演变，特别是在这些公司影响力日益增长的背景下，为政策制定提供透明度现状的量化分析。

**方法:** 采用年度透明度指数评估方法，新增数据获取、使用数据和监控等指标，首次评估阿里巴巴、DeepSeek和xAI等公司。

**结果:** 透明度整体恶化，平均分从58降至40；IBM得分最高(95)，xAI和Midjourney最低(14)；训练数据和部署后影响是最不透明的方面。

**结论:** 尽管政策监管趋严，但公司透明度仍在下降，需要更激进的政策干预来解决关键信息缺失问题，特别是训练数据和模型影响方面的透明度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+2025+Foundation+Model+Transparency+Index，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10169，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10169&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.

</details>


### [17] [CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment](https://arxiv.org/abs/2512.10206)
*Yakun Zhu, Zhongzhen Huang, Qianhan Feng, Linjie Mu, Yannian Gu, Shaoting Zhang, Qi Dou, Xiaofan Zhang*

**主要类别:** cs.AI

**AI概要:** CP-Env是一个可控的医院环境模拟系统，用于评估大语言模型在端到端临床路径中的表现，包括分诊、专科咨询、诊断测试和多学科团队会议等场景，通过三层评估框架揭示模型在复杂临床环境中的局限性


<details>
  <summary>更多</summary>
  
**动机:** 当前基准测试主要关注静态考试或孤立对话，无法充分评估大语言模型在动态临床场景中的表现，需要开发能够模拟真实医院工作流程的评估环境

**方法:** 开发CP-Env可控代理医院环境，模拟医院生态系统，包含患者和医生代理，支持分支化、长视野任务执行，提出包含临床效能、流程能力和专业伦理的三层评估框架

**结果:** 大多数模型在路径复杂性方面表现不佳，出现幻觉现象并丢失关键诊断细节，过度推理步骤有时适得其反，顶级模型通过内化知识减少工具依赖

**结论:** CP-Env通过全面的端到端临床评估推进医疗AI代理的发展，为医疗AI在复杂临床环境中的应用提供了重要评估工具

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CP-Env%3A+Evaluating+Large+Language+Models+on+Clinical+Pathways+in+a+Controllable+Hospital+Environment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10206，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10206&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.

</details>


### [18] [An exploration for higher efficiency in multi objective optimisation with reinforcement learning](https://arxiv.org/abs/2512.10208)
*Mehmet Emin Aydin*

**主要类别:** cs.AI

**AI概要:** 本文概述了一种基于多目标强化学习的通用化方法，用于优化多目标优化问题中的算子序列选择，旨在提高优化算法的效率。


<details>
  <summary>更多</summary>
  
**动机:** 优化和搜索过程中的效率问题持续影响算法性能，使用多个算子而非单一算子处理邻域移动操作具有潜力，但需要寻找最优或接近最优的算子序列。虽然单目标优化已有相关研究，但多目标情况尚未充分探索。

**方法:** 提出基于多目标强化学习的通用化方法，该方法包含已完成和待完成的多个阶段，通过强化学习来学习和选择最优算子序列。

**结果:** 论文主要进行方法概述和阶段性成果展示，表明多目标强化学习方法有望为解决多目标优化中的算子序列选择问题提供有效解决方案。

**结论:** 基于多目标强化学习的通用化方法展示了在多目标优化问题中提高算法效率的潜力，为未来研究提供了有前景的方向，但还需要完成剩余阶段来充分验证其效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+exploration+for+higher+efficiency+in+multi+objective+optimisation+with+reinforcement+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10208，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10208&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.

</details>


### [19] [ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs](https://arxiv.org/abs/2512.10211)
*Junyang Cai, El Mehdi Er Raqabi, Pascal Van Hentenryck, Bistra Dilkina*

**主要类别:** cs.AI

**AI概要:** 该论文提出ID-PaS框架，将预测-搜索方法扩展到参数化混合整数规划问题，通过身份感知学习处理异构变量，在多个实际大规模问题上优于Gurobi和传统PaS方法


<details>
  <summary>更多</summary>
  
**动机:** 现有的预测-搜索方法仅限于二元问题，且忽略了实际应用中常见的固定变量问题，无法有效处理参数化混合整数规划中的异构变量

**方法:** 扩展预测-搜索框架到参数化MIP问题，引入身份感知学习(ID-PaS)框架，使机器学习模型能更有效地处理异构变量

**结果:** 在多个实际大规模问题上，ID-PaS始终表现出比最先进求解器Gurobi和传统PaS方法更优的性能

**结论:** ID-PaS框架成功解决了传统预测-搜索方法在处理参数化混合整数规划和异构变量时的局限性，为实际应用提供了更有效的解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ID-PaS+%3A+Identity-Aware+Predict-and-Search+for+General+Mixed-Integer+Linear+Programs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10211，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10211&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.

</details>


### [20] [Reverse Thinking Enhances Missing Information Detection in Large Language Models](https://arxiv.org/abs/2512.10273)
*Yuxin Liu, Chaojie Gu, Yihang Zhang, Bin Qian, Shibo He*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种基于逆向思维的新框架，通过引导大语言模型进行反向推理来识别缺失信息，相比传统正向推理方法显著提升了模型在缺失信息检测任务中的准确率。


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型在推理任务中表现出色，但在处理缺失信息问题时经常出现回答不完整、事实错误和幻觉等问题。现有的正向推理方法如Chain-of-Thought和Tree-of-Thought虽然有效，但无法系统性地识别和恢复被省略的信息。

**方法:** 受反向推理研究的启发，提出了一个新颖的逆向思维框架，引导大语言模型通过反向思考来识别必要条件和定位缺失元素，将缺失信息识别这一挑战性任务转化为更易处理的逆向推理问题。

**结果:** 实验结果表明，逆向思维方法相比传统正向推理方法取得了显著的性能提升，在模型准确率方面有大幅改善。

**结论:** 逆向思维方法为增强大语言模型的逻辑完整性和推理鲁棒性提供了一个有前景的研究方向，能够有效解决缺失信息检测问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reverse+Thinking+Enhances+Missing+Information+Detection+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10273，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10273&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.

</details>


### [21] [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)
*Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao*

**主要类别:** cs.AI

**AI概要:** 提出神经注意力电路(NAC)，一种生物启发的连续时间注意力机制，通过线性一阶ODE和稀疏门控结构解决传统离散注意力的连续时间建模限制，在多个任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 传统注意力机制虽然改进了RNN的表征学习，但其离散性质限制了连续时间建模能力，需要一种更符合生物原理的连续时间注意力机制。

**方法:** 将注意力对数计算重新表述为线性一阶ODE的解，使用源自秀丽隐杆线虫神经回路的稀疏门控结构，包含内容-目标和可学习时间常数门，支持三种计算模式并采用稀疏Top-K配对连接方案。

**结果:** NAC在精度上匹配或超越基线方法，在运行时和内存效率上处于中等水平，在时间序列分类、自动驾驶车道保持和工业预测等多个领域验证有效。

**结论:** NAC提供了一种生物可信的连续时间注意力机制，具有理论保证和实际应用价值，为连续时间建模提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neuronal+Attention+Circuit+%28NAC%29+for+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10282，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10282&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \textit{content-target} and \textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.

</details>


### [22] [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)
*Yanbei Jiang, Xueqi Ma, Shu Liu, Sarah Monazam Erfani, Tongliang Liu, James Bailey, Jey Han Lau, Krista A. Ehinger*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个名为CogVision的新解释性框架，通过分解多模态问题为逐步子问题来系统分析视觉语言模型的内部机制，特别是注意力头在多模态推理中的功能角色。


<details>
  <summary>更多</summary>
  
**动机:** 尽管视觉语言模型在多模态基准测试中表现优异，但其内部机制仍是一个黑箱，缺乏对注意力头在推理过程中具体功能的理解。

**方法:** 引入CogVision数据集，将复杂多模态问题分解为模拟人类链式思维的逐步子问题；使用基于探测的方法识别专门处理特定认知功能的注意力头（功能头）。

**结果:** 发现功能头普遍稀疏，在不同功能间的数量和分布各异，并介导交互和层次组织；干预实验显示移除功能头会降低性能，而强化它们则提高准确性。

**结论:** 研究揭示了视觉语言模型的认知组织结构，为设计更具人类对齐感知和推理能力的模型提供了新方向和见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Investigating+The+Functional+Roles+of+Attention+Heads+in+Vision+Language+Models%3A+Evidence+for+Reasoning+Modules，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10300，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10300&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.

</details>


### [23] [Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance](https://arxiv.org/abs/2512.10304)
*Byeong Ho Kang, Wenli Yang, Muhammad Bilal Amin*

**主要类别:** cs.AI

**AI概要:** 本文提出了可信编排AI的十大标准框架，通过控制面板架构将治理嵌入AI生态系统，确保可验证性、透明度和人类控制。


<details>
  <summary>更多</summary>
  
**动机:** AI系统在决策中日益重要，但技术能力与制度问责之间存在差距，仅靠伦理指导不足，需要将治理架构嵌入执行层面。

**方法:** 基于国际标准和澳大利亚国家AI保障框架，开发了包含人类输入、语义一致性、审计和溯源完整性的统一控制面板架构。

**结果:** 创建了一个全面的保障框架，为所有AI组件、用户和人类参与者提供治理覆盖，超越了传统的AI间协调方法。

**结论:** 可信度可以通过工程方法系统地融入AI系统，确保执行过程可验证、透明、可重现并处于有意义的人类控制之下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trustworthy+Orchestration+Artificial+Intelligence+by+the+Ten+Criteria+with+Control-Plane+Governance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10304，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10304&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.

</details>


### [24] [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)
*Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu*

**主要类别:** cs.AI

**AI概要:** InfoCom是一个基于信息瓶颈理论的信息感知协作感知框架，通过信息净化范式将通信开销从MB级降至KB级，实现近无损感知性能。


<details>
  <summary>更多</summary>
  
**动机:** 解决协作感知中通信性能权衡问题，现有方法假设MB级数据传输但在实际网络约束下可能失效。

**方法:** 提出信息感知编码、稀疏掩码生成和多尺度解码三个核心创新，通过信息瓶颈约束提取最小充分任务关键信息。

**结果:** 在多数据集上实现近无损感知，通信开销相比Where2comm和ERMVP分别减少440倍和90倍。

**结论:** InfoCom为通信高效的协作感知建立了开创性理论基础，通过信息净化范式显著降低了通信需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是InfoCom%3A+Kilobyte-Scale+Communication-Efficient+Collaborative+Perception+with+Information+Bottleneck，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10305&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.

</details>


### [25] [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)
*Kangkun Mao, Fang Xu, Jinru Ding, Yidong Jiang, Yujun Yao, Yirong Chen, Junming Liu, Xiaoqin Wu, Qian Wu, Xiaoyan Huang, Jie Xu*

**主要类别:** cs.AI

**AI概要:** EpiPlanAgent是一个基于大语言模型的多智能体系统，能够自动生成和验证数字应急响应计划，显著提高计划完整性和指南符合度，大幅减少开发时间。


<details>
  <summary>更多</summary>
  
**动机:** 传统的流行病应对计划制定依赖劳动密集型人工方法，需要更高效、自动化的解决方案来提升公共卫生应急准备能力。

**方法:** 设计基于LLM的多智能体框架，集成任务分解、知识基础和仿真模块，由公共卫生专家使用真实疫情场景进行受控评估。

**结果:** 系统显著提高了计划的完整性和指南符合度，大幅缩短开发时间，AI生成内容与人工编写内容高度一致，用户反馈显示实用性很强。

**结论:** EpiPlanAgent为智能流行病应对规划提供了有效且可扩展的解决方案，展示了智能体AI在改变公共卫生准备方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EpiPlanAgent%3A+Agentic+Automated+Epidemic+Response+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10313&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.

</details>


### [26] [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)
*Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一个用户反馈驱动的视觉语言导航适应框架，通过整合人类交互反馈来提升导航性能，使用记忆库热启动机制实现稳定部署。


<details>
  <summary>更多</summary>
  
**动机:** 当前的GSA-VLN框架缺乏用户反馈机制，仅依赖无监督的环境适应，而用户反馈可以提供有价值的监督信号来显著提升适应质量。

**方法:** 引入用户反馈驱动的适应框架，将用户导航指令和纠正信号转化为高质量的环境对齐训练数据，采用记忆库热启动机制重用先前获得的环境知识。

**结果:** 在GSA-R2R基准测试中，该方法持续超越GR-DUET等强基线，提高了导航成功率和路径效率，记忆库热启动稳定了早期导航并减少了更新后的性能下降。

**结论:** 该方法在持续和混合适应设置下均表现出鲁棒性和通用性，在不同部署条件下实现了持续改进，证明了用户反馈在视觉语言导航适应中的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是User-Feedback-Driven+Continual+Adaptation+for+Vision-and-Language+Navigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10322&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

</details>


### [27] [On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering](https://arxiv.org/abs/2512.10339)
*Ziseok Lee, Minyeong Hwang, Sanghyun Jo, Wooyeol Lee, Jihyung Ko, Young Bin Park, Jae-Mun Choi, Eunho Yang, Kyungsu Kim*

**主要类别:** cs.AI

**AI概要:** 论文提出了ACE方法解决概率密度比率方法中的边际路径坍塌问题，通过自适应路径校正确保概率路径有效性，在分子设计等应用中实现稳定可控生成。


<details>
  <summary>更多</summary>
  
**动机:** 现有的概率密度比率方法在组合不同噪声调度或数据集的异构模型时会出现边际路径坍塌问题，导致中间密度不可归一化，这在分子设计等应用中尤为常见。

**方法:** 首先推导了路径存在性判据来预测坍塌发生条件，然后提出了ACE方法，将Feynman-Kac引导扩展到时变指数，保证有效概率路径。

**结果:** 在合成2D基准测试和柔性姿态支架装饰任务中，ACE消除了坍塌问题，实现了高引导组合生成，在分布和对接指标上优于恒定指数基线和专用模型。

**结论:** ACE方法将概率密度比率引导从启发式方法转变为可靠的可控生成工具，为异构专家模型的组合应用提供了稳定解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Collapse+of+Generative+Paths%3A+A+Criterion+and+Correction+for+Diffusion+Steering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10339，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10339&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.

</details>


### [28] [REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature](https://arxiv.org/abs/2512.10348)
*Wenhan Wu, Zhili He, Huanghuang Liang, Yili Gong, Jiawei Jiang, Chuang Hu, Dazhao Cheng*

**主要类别:** cs.AI

**AI概要:** REMISVFU：一种用于垂直联邦学习的即插即用表示误导框架，通过特征编码器输出坍塌和梯度正交投影实现快速客户端级遗忘，在保持模型效用的同时满足数据删除要求


<details>
  <summary>更多</summary>
  
**动机:** GDPR等数据保护法规赋予联邦系统参与者被遗忘权，但现有遗忘技术主要针对水平联邦学习，而垂直联邦学习的特征分区架构使得这些方法失效，需要专门解决方案

**方法:** 提出表示误导框架：删除请求到达时，遗忘方将编码器输出坍塌到单位球面上的随机锚点以切断特征与全局模型的统计联系；服务器通过联合优化保留损失和遗忘损失，使用正交投影对齐梯度来消除破坏性干扰

**结果:** 在公共基准测试中，REMISVFU将后门攻击成功率抑制到自然类先验水平，仅牺牲约2.5%的干净准确率，优于最先进的基线方法

**结论:** 该框架为垂直联邦学习提供了有效的客户端级遗忘解决方案，在保护隐私和保持模型性能之间取得了良好平衡，具有实际应用价值

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是REMISVFU%3A+Vertical+Federated+Unlearning+via+Representation+Misdirection+for+Intermediate+Output+Feature，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10348，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10348&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party's contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.

</details>


### [29] [LLM-Empowered Representation Learning for Emerging Item Recommendation](https://arxiv.org/abs/2512.10370)
*Ziying Zhang, Quanming Yao, Yaqing Wang*

**主要类别:** cs.AI

**AI概要:** EmerFlow是一个基于大语言模型的推荐系统框架，专门解决新兴物品推荐问题，通过LLM推理增强特征表示，并与现有推荐模型嵌入空间对齐，在多个领域实验中表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有推荐方法往往忽视新兴物品随时间积累交互的动态过程，通常假设新兴物品历史交互很少甚至没有，这种假设过度简化了问题。好的模型需要既保持新兴物品的独特性，又利用其与成熟物品的共享模式。

**方法:** 提出EmerFlow框架：1) 通过LLM推理增强新兴物品的原始特征；2) 将这些表示与现有推荐模型的嵌入空间对齐；3) 通过元学习整合新交互来精炼嵌入表示。

**结果:** 在包括电影和医药等多个领域的广泛实验中，EmerFlow始终优于现有方法，能够从有限交互中学习到表达性强的新兴物品嵌入。

**结论:** EmerFlow成功解决了新兴物品推荐的关键挑战，通过LLM赋能的学习框架有效处理了动态积累的交互过程，在保持物品独特性的同时利用共享模式，为有限交互的新兴物品提供了高质量的嵌入表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Empowered+Representation+Learning+for+Emerging+Item+Recommendation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10370，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10370&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.

</details>


### [30] [AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management](https://arxiv.org/abs/2512.10371)
*Shizuo Tian, Hao Wen, Yuxuan Chen, Jiacheng Liu, Shanhui Zhao, Guohong Liu, Ju Ren, Yunxin Liu, Yuanchun Li*

**主要类别:** cs.AI

**AI概要:** AgentProg是一个程序引导的移动GUI代理上下文管理方法，通过将交互历史重构为带有变量和控制流的程序结构来减少上下文开销，同时保持任务性能。


<details>
  <summary>更多</summary>
  
**动机:** 移动GUI代理在长时程任务自动化中面临依赖不断扩展的交互历史导致上下文开销过大的问题，现有上下文管理和压缩技术往往无法保留关键语义信息。

**方法:** 提出程序引导的上下文管理方法，将交互历史组织为程序结构（变量和控制流），并集成基于Belief MDP框架的全局信念状态机制来处理部分可观测性和环境变化。

**结果:** 在AndroidWorld和扩展的长时程任务套件上实现了最先进的成功率，在长时程任务中保持稳健性能，而基线方法出现灾难性性能下降。

**结论:** AgentProg通过程序化结构管理上下文，有效解决了长时程GUI任务中的上下文开销问题，同时保持了任务性能的稳定性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgentProg%3A+Empowering+Long-Horizon+GUI+Agents+with+Program-Guided+Context+Management，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10371，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10371&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.

</details>


### [31] [Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention](https://arxiv.org/abs/2512.10414)
*Yang Yu, Zhuangzhuang Chen, Siqi Wang, Lanqing Li, Xiaomeng Li*

**主要类别:** cs.AI

**AI概要:** 提出SaEI方法，通过选择性对抗熵干预增强视觉语言模型的推理能力，在RL采样阶段引入熵干预来提升响应多样性，从而提高策略性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于RL的微调方法主要在策略优化阶段对特定token进行熵干预，忽略了RL采样阶段的熵干预对提升响应多样性和性能的潜在价值。

**方法:** 提出选择性对抗熵干预(SaEI)：1) 熵引导对抗采样(EgAS) - 将采样响应的熵作为对抗目标生成对抗样本；2) token选择性熵计算(TsEC) - 在不破坏事实知识的前提下最大化对抗攻击效果

**结果:** 在领域内和领域外数据集上的大量实验表明，该方法能显著提升策略探索能力，增强推理性能。

**结论:** SaEI通过RL采样阶段的熵干预有效提升了视觉语言模型的推理能力，证明了该方法在增强模型探索性和多样性方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Boosting+RL-Based+Visual+Reasoning+with+Selective+Adversarial+Entropy+Intervention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10414，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10414&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL-based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing studies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ignore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the diversity of responses. In this paper, we propose Selective-adversarial Entropy Intervention, namely SaEI, which enhances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the entropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formulates the entropy of sampled responses as an adversarial objective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger answer space during RL sampling. Then, we propose token-selective entropy computation (TsEC) to maximize the effectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.

</details>


### [32] [Representation of the structure of graphs by sequences of instructions](https://arxiv.org/abs/2512.10429)
*Ezequiel Lopez-Rubio*

**主要类别:** cs.AI

**AI概要:** 提出了一种将图邻接矩阵转换为指令字符串的新表示方法，该方法可逆且保持图结构模式，旨在增强深度学习模型对图的处理能力。


<details>
  <summary>更多</summary>
  
**动机:** 传统图表示方法（邻接矩阵）不适合深度学习语言模型处理，需要一种能与文本处理模型兼容的新表示形式。

**方法:** 将图的邻接矩阵通过一系列简单指令逐步构建成字符串表示，该转换过程可逆。

**结果:** 实验结果显示该方法具有良好效果，表示紧凑且能保持图的局部结构模式。

**结论:** 该字符串表示方法有望提升深度学习模型处理图数据的性能，为图分析与深度学习结合提供了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Representation+of+the+structure+of+graphs+by+sequences+of+instructions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10429，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10429&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.

</details>


### [33] [Targeted Data Protection for Diffusion Model by Matching Training Trajectory](https://arxiv.org/abs/2512.10433)
*Hojun Lee, Mijin Koo, Yeji Song, Nojun Kwak*

**主要类别:** cs.AI

**AI概要:** TAFAP是一种针对扩散模型的新型目标数据保护方法，通过轨迹对齐和对抗性扰动实现有效的目标概念重定向，解决了现有方法在可控性和稳定性方面的不足。


<details>
  <summary>更多</summary>
  
**动机:** 当前扩散模型个性化微调技术虽易用但存在数据滥用和隐私侵犯风险，现有保护方法只能被动降低图像质量且缺乏稳定控制，目标数据保护方法因快照匹配方式无法考虑完整学习动态而可控性差。

**方法:** TAFAP采用轨迹对齐方法，受数据集蒸馏启发，通过对抗性扰动控制整个训练轨迹，确保在整个微调过程中实现持久且可验证的转换，而非仅依赖快照匹配。

**结果:** TAFAP在扩散模型中首次成功实现了目标转换，同时控制身份和视觉模式，显著优于现有TDP方法，实现了向目标概念的稳健重定向并保持高图像质量。

**结论:** TAFAP为扩散模型输出提供了可验证的安全保障，建立了一个控制和追踪修改的新框架，解决了目标数据保护的关键挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Targeted+Data+Protection+for+Diffusion+Model+by+Matching+Training+Trajectory，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10433&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.

</details>


### [34] [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449)
*Devanshu Sahoo, Manish Prasad, Vasudev Majhi, Jahnvi Singh, Vinay Chamola, Yash Sinha, Murari Mandal, Dhruv Kumar*

**主要类别:** cs.AI

**AI概要:** 论文研究了LLM作为评审系统对PDF对抗性操纵的脆弱性，开发了WAVS评估指标，发现混淆策略能成功操纵评审结果，即使在大型模型中也能实现高决策翻转率。


<details>
  <summary>更多</summary>
  
**动机:** 随着LLM在科学同行评审中的广泛应用（包括评审员个人使用和机构正式部署），需要评估这些系统对对抗性PDF操纵的鲁棒性，特别是针对将'拒绝'决定翻转为'接受'的特定动机。

**方法:** 构建包含200篇科学论文的数据集，采用15种领域特定的攻击策略，在包括GPT-5、Claude Haiku和DeepSeek在内的13个语言模型上进行评估，开发了WAVS（加权对抗性脆弱性评分）新评估指标。

**结果:** 结果显示混淆策略（如'Maximum Mark Magyk'）能够成功操纵评分，即使在大规模模型中也实现了令人担忧的决策翻转率。

**结论:** LLM-as-a-Judge系统对对抗性PDF操纵存在显著脆弱性，研究将发布完整数据集和注入框架以促进该领域进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Reject+Turns+into+Accept%3A+Quantifying+the+Vulnerability+of+LLM-Based+Scientific+Reviewers+to+Indirect+Prompt+Injection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10449，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10449&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the "Lazy Reviewer" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these "LLM-as-a-Judge" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping "Reject" decisions to "Accept," for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like "Maximum Mark Magyk" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.

</details>


### [35] [Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning](https://arxiv.org/abs/2412.20505)
*Hang Ni, Yuzhi Wang, Hao Liu*

**主要类别:** cs.AI

**AI概要:** 提出了基于大语言模型的多智能体循环城市规划框架CUP，通过规划、生活、评判三个模块实现城市方案的持续生成、评估和优化


<details>
  <summary>更多</summary>
  
**动机:** 城市化进程中的城市更新面临重大挑战，需要适应性方法来应对不断变化的需求

**方法:** 基于大语言模型的多智能体框架，包含三个核心组件：规划模块生成和优化城市方案；生活模块模拟居民行为和互动；评判模块评估方案效果并提供迭代反馈

**结果:** 在真实数据集上的实验证明了该框架作为连续自适应规划过程的有效性

**结论:** 循环城市规划范式能够实现动态响应的规划方法，为城市更新提供持续优化的解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Planning%2C+Living+and+Judging%3A+A+Multi-agent+LLM-based+Framework+for+Cyclical+Urban+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2412.20505，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2412.20505&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.

</details>


### [36] [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)
*Lim Chien Her, Ming Yan, Yunshu Bai, Ruihao Li, Hao Zhang*

**主要类别:** cs.AI

**AI概要:** 提出一种无需训练的LLM智能体架构，使用Actor-Critic双智能体协作，通过迭代推理实现零样本PCG参数配置，在3D地图生成任务中超越单智能体基线


<details>
  <summary>更多</summary>
  
**动机:** PCG工具需要精确配置复杂技术参数，现成LLM模型难以弥合抽象用户指令与严格参数规范之间的语义鸿沟

**方法:** 采用Actor和Critic双智能体架构，建立迭代工作流程，系统自主推理工具参数并逐步优化配置以符合人类设计偏好

**结果:** 在3D地图生成实验中超越单智能体基线，从自然语言描述中生成多样且结构有效的环境，建立了PCG指令遵循的新基准

**结论:** 现成LLM可有效重新用作任意PCG工具的通用智能体，通过架构推理而非模型训练的方式，为掌握复杂软件提供了可扩展框架

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zero-shot+3D+Map+Generation+with+LLM+Agents%3A+A+Dual-Agent+Architecture+for+Procedural+Content+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10501，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10501&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.

</details>


### [37] [Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](https://arxiv.org/abs/2512.10534)
*Haiteng Zhao, Junhao Shen, Yiming Zhang, Songyang Gao, Kuikun Liu, Tianyou Ma, Fan Zheng, Dahua Lin, Wenwei Zhang, Kai Chen*

**主要类别:** cs.AI

**AI概要:** InternGeometry是一个基于大语言模型的几何问题求解系统，通过迭代提出命题和辅助构造、符号引擎验证和反馈反思，仅用少量训练数据就在IMO几何问题上达到金牌得主水平，超越了AlphaGeometry 2的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM在几何问题求解中存在启发式构造的局限性，而专家模型如AlphaGeometry 2需要大规模数据合成和搜索，因此需要开发更高效的LLM代理来解决几何问题。

**方法:** 采用迭代式命题提出和辅助构造方法，结合符号引擎验证和反馈机制，引入动态内存机制支持多次交互，并使用复杂度递增强化学习(CBRL)来加速训练。

**结果:** 在50个IMO几何问题(2000-2024)中解决了44个，超过金牌得主平均分(40.9)，仅使用13K训练样本(AlphaGeometry 2数据量的0.004%)，并能提出人类解法中未出现的新颖辅助构造。

**结论:** InternGeometry展示了LLM代理在专家级几何任务上的巨大潜力，通过创新的迭代验证和强化学习方法，以极少的数据量实现了超越人类金牌得主的性能，为几何问题求解开辟了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Achieving+Olympia-Level+Geometry+Large+Language+Model+Agent+via+Complexity+Boosting+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10534，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10534&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.

</details>


### [38] [NormCode: A Semi-Formal Language for Context-Isolated AI Planning](https://arxiv.org/abs/2512.10563)
*Xin Guan*

**主要类别:** cs.AI

**AI概要:** NormCode是一种半形式化语言，通过严格分离语义操作和语法操作，消除多步LLM工作流中的上下文污染问题，实现精确的成本和可靠性追踪。


<details>
  <summary>更多</summary>
  
**动机:** 多步LLM工作流存在上下文污染问题：信息在步骤间积累导致模型产生幻觉、混淆中间输出和丢失任务约束。

**方法:** 设计NormCode语言，包含三种同构格式：.ncds用于人工编写、.ncd用于机器执行、.ncn用于人工验证。强制分离语义操作（LLM驱动的非确定性推理）和语法操作（确定性数据重组）。

**结果:** 验证显示：1）基础X加法算法在任意长度输入上达到100%准确率；2）成功自托管执行NormCode的五阶段编译器流水线。

**结论:** NormCode使AI工作流具有可审计性，解决了法律推理、医疗决策和金融分析等高风险领域对透明度的关键需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NormCode%3A+A+Semi-Formal+Language+for+Context-Isolated+AI+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10563&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.

</details>


### [39] [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)
*Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen*

**主要类别:** cs.AI

**AI概要:** Phythesis是一个结合大语言模型和物理引导进化优化的框架，用于自动化生成可仿真的数据中心布局，相比纯LLM方案提升57.3%的生成成功率和11.5%的能效。


<details>
  <summary>更多</summary>
  
**动机:** 传统数据中心设计方法难以应对系统复杂度增长，现有AI方法缺乏物理约束考虑，无法满足数据中心可量化运营目标和严格物理限制的需求。

**方法:** 采用迭代双层优化架构：LLM驱动层生成物理合理的三维布局并进行自我批评优化拓扑；物理信息优化层识别最优资产参数和组合。

**结果:** 在三种生成规模上的实验显示，相比纯LLM方案，Phythesis实现了57.3%的生成成功率提升和11.5%的PUE能效改进。

**结论:** Phythesis成功填补了AI生成设计与物理约束之间的空白，为节能数据中心设计提供了有效的自动化仿真就绪场景合成解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Phythesis%3A+Physics-Guided+Evolutionary+Scene+Synthesis+for+Energy-Efficient+Data+Center+Design+via+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10611，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10611&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.

</details>


### [40] [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)
*Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao*

**主要类别:** cs.AI

**AI概要:** ReMe框架通过多维度经验提取、上下文自适应重用和基于效用的记忆精炼，实现了LLM智能体的主动经验积累和动态进化，在多个基准测试中达到最先进水平，并展示了记忆缩放效应。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM智能体记忆框架主要采用被动积累模式，将记忆视为静态附加档案，无法实现存储与动态推理的有效结合。

**方法:** 提出ReMe框架，包含三个核心机制：1)多维度经验提取：识别成功模式、分析失败原因、生成对比洞察；2)上下文自适应重用：通过场景感知索引将历史经验适配到新情境；3)基于效用的精炼：自主添加有效记忆并修剪过时记忆。

**结果:** 在BFCL-V3和AppWorld基准测试中达到最先进水平，Qwen3-8B配备ReMe后性能超过更大的无记忆Qwen3-14B，证明自进化记忆为终身学习提供了计算高效的途径。

**结论:** ReMe框架成功解决了静态存储与动态推理之间的差距，通过主动经验驱动的方式实现了智能体的持续进化，为LLM智能体的终身学习提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Remember+Me%2C+Refine+Me%3A+A+Dynamic+Procedural+Memory+Framework+for+Experience-Driven+Agent+Evolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10696&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.

</details>


### [41] [Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification](https://arxiv.org/abs/2512.10640)
*Liang Peng, Haopeng Liu, Yixuan Ye, Cheng Liu, Wenjun Shen, Si Wu, Hau-San Wong*

**主要类别:** cs.AI

**AI概要:** 提出scRCL框架，通过整合细胞-基因关联的对比学习，显著提升单细胞组学中细胞类型识别的准确性


<details>
  <summary>更多</summary>
  
**动机:** 现有聚类方法主要关注细胞内在结构而忽略细胞-基因关联，限制了区分紧密相关细胞类型的能力

**方法:** 开发Refinement Contrastive Learning框架，包含两个对比分布对齐组件揭示细胞结构，以及整合基因相关结构学习的精化模块

**结果:** 在多个单细胞RNA-seq和空间转录组数据集上优于现有基准方法，恢复的细胞群体显示一致的基因表达特征

**结论:** scRCL通过有效利用细胞-基因相互作用，提供了更具生物学意义的表示学习，代码已开源

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Refinement+Contrastive+Learning+of+Cell-Gene+Associations+for+Unsupervised+Cell+Type+Identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10640，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10640&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at https://github.com/THPengL/scRCL.

</details>


### [42] [Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly](https://arxiv.org/abs/2512.10787)
*Moshe Lahmy, Roi Yozevitch*

**主要类别:** cs.AI

**AI概要:** SEAL-RAG是一种无需训练的控制器，采用"替换而非扩展"策略来解决多跳查询中的上下文稀释问题，通过搜索-提取-评估-循环过程动态替换干扰信息，在固定检索深度下显著提升答案正确性和证据精确度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的RAG系统在处理多跳查询时，当初始检索错过桥接事实时容易失败。传统校正方法通过增加上下文或修剪列表来解决，但简单扩展上下文窗口会导致上下文稀释问题，即干扰信息挤占相关信息空间。

**方法:** 提出SEAL-RAG方法，执行搜索→提取→评估→循环的周期：进行实时实体锚定提取构建缺失实体/关系的间隙规范，触发针对性微查询，使用实体优先排名主动用间隙闭合证据替换干扰信息。

**结果:** 在HotpotQA上，SEAL比Self-RAG提高答案正确性3-13个百分点，证据精确度提高12-18个百分点；在2WikiMultiHopQA上，比Adaptive-k准确度提高8.0个百分点，保持96%的证据精确度（CRAG仅为22%），结果具有统计显著性。

**结论:** 通过强制执行固定k替换策略，SEAL在确保可预测成本的同时，优化了top-k槽位的精确度而非仅仅广度，为解决RAG系统中的上下文稀释问题提供了有效方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Replace%2C+Don%27t+Expand%3A+Mitigating+Context+Dilution+in+Multi-Hop+RAG+via+Fixed-Budget+Evidence+Assembly，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10787&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \textbf{context dilution}, where distractors crowd out relevant information. We propose \textbf{SEAL-RAG}, a training-free controller that adopts a \textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\textbf{S}earch $\rightarrow$ \textbf{E}xtract $\rightarrow$ \textbf{A}ssess $\rightarrow$ \textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \textbf{HotpotQA} and \textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \textbf{+3--13 pp} and evidence precision by \textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \textbf{+8.0 pp} in accuracy and maintains \textbf{96\%} evidence precision compared to 22\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.

</details>


### [43] [CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.10655)
*Tong Zhang, Carlos Hinojosa, Bernard Ghanem*

**主要类别:** cs.AI

**AI概要:** CAPTAIN是一个无需训练的框架，通过在去噪过程中直接修改潜在特征来减少扩散模型的记忆化问题，同时保持提示对齐和视觉质量。


<details>
  <summary>更多</summary>
  
**动机:** 扩散模型可能无意中重现训练样本，引发隐私和版权问题，现有方法难以在不影响提示对齐的情况下有效减少记忆化。

**方法:** CAPTAIN采用基于频率的噪声初始化、识别最佳去噪时间步、定位记忆区域，并将非记忆参考图像的语义对齐特征注入到定位区域。

**结果:** 实验显示CAPTAIN相比基于CFG的基线方法显著减少了记忆化，同时保持了与目标提示的强对齐。

**结论:** CAPTAIN提供了一种有效的训练无关方法来缓解扩散模型的记忆化问题，平衡了隐私保护和生成质量的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CAPTAIN%3A+Semantic+Feature+Injection+for+Memorization+Mitigation+in+Text-to-Image+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10655，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10655&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.

</details>


### [44] [On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity](https://arxiv.org/abs/2512.10665)
*Muhua Huang, Qinlin Zhao, Xiaoyuan Yi, Xing Xie*

**主要类别:** cs.AI

**AI概要:** 该研究探讨了基于大语言模型的多智能体系统中价值多样性对集体行为的影响，发现适度价值多样性增强价值稳定性、促进涌现行为和创新，但过度多样性会导致不稳定性。


<details>
  <summary>更多</summary>
  
**动机:** 研究大语言模型多智能体系统中价值多样性如何塑造AI社区的集体行为，填补AI能力与社会学制度形成研究之间的空白。

**方法:** 使用基于Schwartz基本人类价值理论的自然价值诱导方法，构建不同规模的多智能体模拟环境，让智能体进行开放式互动和宪法制定。

**结果:** 价值多样性增强了价值稳定性，促进了涌现行为，并带来了更多由智能体自主开发的创新原则，但这些效应存在收益递减现象，极端异质性会导致不稳定性。

**结论:** 价值多样性应被视为未来AI能力的新维度，为连接AI能力与社会学制度涌现研究提供了桥梁。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Dynamics+of+Multi-Agent+LLM+Communities+Driven+by+Value+Diversity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10665，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10665&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.

</details>


### [45] [AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2512.10671)
*Oscar Robben, Saeed Khalilian, Nirvana Meratnia*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种硬件感知的神经架构搜索方法，用于设计更高效的早退网络，通过在出口分支中使用不同深度和类型的层，并结合自适应阈值调优，在保持或降低计算量的同时提高模型精度。


<details>
  <summary>更多</summary>
  
**动机:** 早退网络虽然能通过根据输入复杂度调整计算来降低能耗和延迟，但其设计过程复杂耗时，需要在效率和性能之间取得平衡。现有研究使用NAS来优化出口分支位置和数量，但出口分支的深度和层类型对效率与精度同样重要。

**方法:** 使用硬件感知的神经架构搜索（NAS）来增强出口分支，在优化过程中同时考虑精度和效率。方法包括为出口分支设计不同深度和层类型，并进行自适应阈值调优。

**结果:** 在CIFAR-10、CIFAR-100和SVHN数据集上的评估显示，所提框架设计的早退网络在相同或更低平均MACs（乘加运算）下，达到了比最先进方法更高的准确率。

**结论:** 硬件感知NAS结合出口分支深度和层类型多样性以及自适应阈值调优，能够有效设计出在计算效率和精度方面都更优的早退网络，特别适合资源受限设备。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AEBNAS%3A+Strengthening+Exit+Branches+in+Early-Exit+Networks+through+Hardware-Aware+Neural+Architecture+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10671，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10671&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.

</details>


### [46] [Challenges of Evaluating LLM Safety for User Welfare](https://arxiv.org/abs/2512.10687)
*Manon Kempermann, Sai Suresh Macharla Vasu, Mahalakshmi Raveenthiran, Theo Farrell, Ingmar Weber*

**主要类别:** cs.AI

**AI概要:** 该研究探讨了LLM安全评估的局限性，指出现有评估主要关注通用风险，但缺乏针对个人福祉的上下文相关评估方法。通过实验证明，评估者需要了解用户背景信息才能准确评估建议安全性，且仅靠用户主动提供上下文信息不足，特别是对脆弱群体。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型语言模型的安全评估主要关注通用风险（如危险能力），但数百万用户在高风险领域（金融、健康）寻求个性化建议时，危害是上下文相关的。现有评估框架未能充分发展用户福祉安全评估方法。

**方法:** 采用探索性研究方法，评估GPT-5、Claude Sonnet 4和Gemini 2.5 Pro在金融和健康领域的建议质量。设计了两项研究：1）比较有无用户背景信息的评估差异；2）测试用户主动提供上下文信息是否改善评估效果。使用不同脆弱程度的用户档案进行评估。

**结果:** 研究发现：1）有用户背景信息的评估者比无背景信息的评估者对相同LLM回复的安全性评分显著更低（安全分数从5/7降至3/7）；2）即使用户主动提供上下文信息，评估效果也无显著改善，特别是对脆弱群体。

**结论:** 有效的用户福祉安全评估需要评估者基于多样化用户档案评估回复，仅靠用户主动提供上下文信息不足。研究提供了上下文感知评估方法，证明个体福祉评估需要不同于现有通用风险框架的新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Challenges+of+Evaluating+LLM+Safety+for+User+Welfare，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10687，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10687&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.

</details>


### [47] [Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning](https://arxiv.org/abs/2512.10691)
*Benjamin Gundersen, Nicolas Deperrois, Samuel Ruiperez-Campillo, Thomas M. Sutter, Julia E. Vogt, Michael Moor, Farhad Nooralahzadeh, Michael Krauthammer*

**主要类别:** cs.AI

**AI概要:** 本研究探讨了在胸部X光视觉语言模型中结合强化学习(RL)和显式推理的效果，发现RL在报告生成和视觉定位任务上带来额外提升，而显式推理并未进一步改善结果。


<details>
  <summary>更多</summary>
  
**动机:** 当前医学视觉语言模型主要依赖监督微调(SFT)，但缺乏对答案质量的评估。RL能够整合任务特定反馈，结合显式推理在数学和编程任务中已显示显著效果，研究者希望在CXR VLM中验证这种方法。

**方法:** 基于Qwen3-VL构建RadVLM模型，进行大规模CXR数据SFT，然后进行冷启动SFT赋予基础推理能力。应用具有临床基础任务特定奖励的GRPO进行强化学习，在有无推理的领域特定和通用领域变体上进行匹配RL实验。

**结果:** RL在报告生成和视觉定位任务上均带来额外性能提升，而显式推理并未进一步改善结果。RL优化的RadVLM模型在两项任务上均达到最先进性能。

**结论:** 强SFT对基础性能至关重要，但临床对齐的RL是医学VLM的有力补充，能够提供超越SFT的额外增益，而显式推理在CXR解释中效果有限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Radiology+Report+Generation+and+Visual+Grounding+using+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10691，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10691&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning ("thinking") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.

</details>


### [48] [COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators](https://arxiv.org/abs/2512.10702)
*Wei Fang, Chiyao Wang, Wenshuai Ma, Hui Liu, Jianqiang Hu, Xiaona Niu, Yi Chu, Mingming Zhang, Jingxiao Yang, Dongwei Zhang, Zelin Li, Pengyun Liu, Jiawei Zheng, Pengke Zhang, Chaoshi Qin, Wangang Guo, Bin Wang, Yugang Xue, Wei Zhang, Zikuan Wang, Rui Zhu, Yihui Cao, Quanmao Lu, Rui Meng, Yan Li*

**主要类别:** cs.AI

**AI概要:** CA-GPT在OCT引导的PCI规划和评估中表现优于通用ChatGPT-5和初级医师，显示出AI在血管内成像领域的专业优势。


<details>
  <summary>更多</summary>
  
**动机:** 血管内成像（特别是OCT）虽然能改善PCI结果，但其解读依赖操作者经验。通用AI缺乏领域特异性可靠性，需要开发专业AI系统。

**方法:** 单中心分析96例接受OCT引导PCI的患者，比较CA-GPT、ChatGPT-5和初级医师与专家制定的手术记录的一致性，使用10个预设指标评估术前术后阶段。

**结果:** CA-GPT在术前规划中位一致性评分显著更高（5分），优于ChatGPT-5（3分）和初级医师（4分）。在支架直径和长度选择等关键指标上表现优异，术后评估同样保持优秀表现。

**结论:** 基于CA-GPT的AI-OCT系统在PCI规划和评估中提供了标准化、可靠的血管内成像解读方法，有潜力增强操作者专业知识和优化OCT引导的PCI。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是COMPARE%3A+Clinical+Optimization+with+Modular+Planning+and+Assessment+via+RAG-Enhanced+AI-OCT%3A+Superior+Decision+Support+for+Percutaneous+Coronary+Intervention+Compared+to+ChatGPT-5+and+Junior+Operators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10702&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.
  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.
  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.
  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.

</details>


### [49] [HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition](https://arxiv.org/abs/2512.10807)
*Wang Lu, Yao Zhu, Jindong Wang*

**主要类别:** cs.AI

**AI概要:** 该论文提出了HAROOD基准测试，用于全面评估传感器人类活动识别中的分布外泛化能力，涵盖4种OOD场景、6个数据集和16种方法，发现当前方法在不同场景下表现不一，没有单一最优方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究在传感器人类活动识别中仅针对特定分布偏移场景（如跨设备或跨位置）应用OOD算法，缺乏对算法有效性的全面评估和比较。

**方法:** 构建HAROOD基准测试，定义4种OOD场景（跨人、跨位置、跨数据集、跨时间），覆盖6个数据集和16种对比方法（基于CNN和Transformer架构），采用两种模型选择协议进行广泛实验。

**结果:** 实验发现没有单一方法在所有场景下都表现最优，不同方法在不同分布偏移场景下表现各异，显示出该领域仍有很大改进空间。

**结论:** HAROOD基准测试为OOD-based HAR研究提供了全面评估框架，其模块化设计便于扩展，未来研究需要开发更鲁棒的算法来处理不同分布偏移场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HAROOD%3A+A+Benchmark+for+Out-of-distribution+Generalization+in+Sensor-based+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10807，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10807&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at https://github.com/AIFrontierLab/HAROOD.

</details>


### [50] [Agile Deliberation: Concept Deliberation for Subjective Visual Classification](https://arxiv.org/abs/2512.10821)
*Leijie Wang, Otilia Stretcu, Wei Qiao, Thomas Denby, Krishnamurthy Viswanathan, Enming Luo, Chun-Ta Lu, Tushar Dogra, Ranjay Krishna, Ariel Fuxman*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种名为"敏捷审议"的人机交互框架，通过概念范围界定和迭代优化来帮助用户从模糊概念出发，逐步精确定义视觉分类概念，相比自动化基准和人工审议方法效果更好。


<details>
  <summary>更多</summary>
  
**动机:** 现有的人机交互方法假设用户已有清晰稳定的概念理解，但现实中用户往往从模糊概念开始，需要通过"概念审议"过程逐步细化，这在内容审核等应用中尤为常见。

**方法:** 提出"敏捷审议"框架，包含两个阶段：(1)概念范围界定-将初始概念分解为结构化子概念层次；(2)概念迭代-呈现语义边界案例供用户反馈，迭代优化图像分类器与用户意图的对齐。

**结果:** 通过18次用户会话（每次1.5小时）评估，敏捷审议相比自动化分解基准获得7.5%更高的F1分数，比人工审议高3%以上，参与者报告概念理解更清晰且认知负担更低。

**结论:** 敏捷审议框架有效支持了主观和演化概念的定义过程，为人机交互系统中的概念精炼提供了实用方法，特别适用于需要从模糊概念开始的视觉分类任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Agile+Deliberation%3A+Concept+Deliberation+for+Subjective+Visual+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10821，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10821&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

</details>


### [51] [V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions](https://arxiv.org/abs/2512.10822)
*Mumuksh Tayal, Manan Tayal, Aditya Singh, Shishir Kolathaya, Ravi Prakash*

**主要类别:** cs.AI

**AI概要:** V-OCBF是一个从离线演示中学习神经控制屏障函数的框架，无需系统动力学模型，通过有限差分屏障更新和期望值目标实现模型无关的安全控制合成，在多个案例中显著减少安全违规。


<details>
  <summary>更多</summary>
  
**动机:** 现有安全离线RL方法只能强制执行软期望成本约束，无法保证前向不变性；而控制屏障函数(CBFs)虽能提供严格安全保证，但通常需要专家设计的屏障函数或完整的系统动力学知识。

**方法:** 提出V-OCBF框架：1)从离线演示学习神经CBF；2)使用递归有限差分屏障更新实现模型无关学习；3)采用期望值目标避免在分布外动作上查询屏障；4)使用QP公式合成实时安全控制。

**结果:** 在多个案例研究中，V-OCBF相比基线方法显著减少了安全违规次数，同时保持了强大的任务性能。

**结论:** V-OCBF展示了在没有在线交互或手工设计屏障的情况下，可扩展地合成安全关键控制器的能力，为自主系统的安全控制提供了有效的离线解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是V-OCBF%3A+Learning+Safety+Filters+from+Offline+Data+via+Value-Guided+Offline+Control+Barrier+Functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10822，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10822&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.

</details>


### [52] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding, Janell Thomson, Jon Taylor, Changwoo Do*

**主要类别:** cs.AI

**AI概要:** 使用大语言模型(LLMs)替代传统人工评审来增强大型用户设施的提案选择过程，提供可扩展、一致且成本效益更高的解决方案


<details>
  <summary>更多</summary>
  
**动机:** 传统人工评分存在提案间相关性弱、评审者偏见和不一致性问题，而基于成对偏好的方法虽然逻辑上更优越，但工作量呈二次增长，人工无法实现

**方法:** 利用橡树岭国家实验室散裂中子源三个光束线的精心策划提案和发表记录，采用LLMs进行成对偏好评估和排名

**结果:** LLM排名与人工排名强相关(Spearman ρ≈0.2-0.8，去除10%异常值后≥0.5)，在识别高发表潜力提案方面不逊于人工评审，成本降低两个数量级

**结论:** LLMs不仅能有效替代人工评审提供一致且成本效益高的提案排名，还能实现人类难以完成的先进分析，如通过嵌入模型定量评估提案相似性，为评审委员会提供关键信息

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLMs+Can+Assist+with+Proposal+Selection+at+Large+User+Facilities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10895，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10895&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [53] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique*

**主要类别:** cs.AI

**AI概要:** 提出一种节点级剪枝框架，通过多粒度可学习掩码和稀疏性惩罚，在单次微调中发现更精细、更小的电路结构，显著降低计算内存需求。


<details>
  <summary>更多</summary>
  
**动机:** 现有电路发现方法主要依赖迭代边剪枝，计算成本高且仅限于粗粒度单元（如注意力头或MLP块），忽略了神经元级别的精细结构。

**方法:** 引入跨多粒度（从整个块到单个神经元）的可学习掩码，在统一优化目标中使用粒度特定的稀疏性惩罚指导剪枝过程，实现单次微调中的全面压缩。

**结果:** 方法发现的电路节点数少于现有方法；证明粗粒度方法认为重要的许多神经元实际上无关紧要；同时保持任务性能；内存占用降低5-10倍。

**结论:** 该节点级剪枝框架解决了电路发现的可扩展性和粒度限制问题，能够识别更精细的电路结构，同时大幅降低计算资源需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Granular+Node+Pruning+for+Circuit+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10903，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10903&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>


### [54] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

**主要类别:** cs.AI

**AI概要:** 该论文建立了部分可观察马尔可夫决策过程(POMDP)中的决策代理与一输入过程函数之间的精确对应关系，揭示了人工智能与量子物理概念之间的深刻联系。


<details>
  <summary>更多</summary>
  
**动机:** 探索决策理论中的代理模型与量子物理中高阶操作经典极限之间的数学对应关系，为跨学科研究提供新的视角。

**方法:** 通过将代理的策略和内存更新结合成过程函数w，使用链接积与POMDP环境交互，建立形式化的对应框架。

**结果:** 成功建立了POMDP代理与一输入过程函数的精确数学对应，并扩展到多代理系统的观察无关分散POMDP与多输入过程函数的关系。

**结论:** 这项工作为理解人工智能决策过程与量子物理概念之间的深层联系提供了新的数学框架，具有重要的跨学科意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Decision-Making+Agents+and+Higher-Order+Causal+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10937&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [55] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi, Jessica Morley, Claudio Novelli, David Watson*

**主要类别:** cs.CL

**AI概要:** 本文分析了当前基于token补全的大语言模型的推理机制，认为它们并非真正进行溯因推理，而是通过统计模式生成看似合理的文本，这种表面相似性源于训练数据中的人类推理结构。


<details>
  <summary>更多</summary>
  
**动机:** 研究大语言模型的推理本质，澄清其与人类溯因推理的区别，避免对AI能力的过度解读，为正确评估和应用LLMs提供理论基础。

**方法:** 通过理论分析和案例研究，对比LLMs的输出特征与人类溯因推理的本质差异，考察模型基于统计模式生成文本的机制。

**结果:** 发现LLMs只能模仿推理的表面形式，缺乏真实性验证、语义理解和真正的推理过程，其看似推理的能力完全依赖于训练数据中的模式学习。

**结论:** LLMs可作为创意生成和思维辅助工具，但其输出需要严格批判性评估，不能替代人类推理。文章最后回应了五个反对观点并指出了分析局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Kind+of+Reasoning+%28if+any%29+is+an+LLM+actually+doing%3F+On+the+Stochastic+Nature+and+Abductive+Appearance+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10080&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [56] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei, John Stamper, Paulo F. Carvalho*

**主要类别:** cs.CL

**AI概要:** 本文研究使用小型语言模型(SLM)自动生成问题，提出结合文本生成和概率推理的新颖流水线方法，通过人类专家和大型语言模型评估验证了生成问题的质量。


<details>
  <summary>更多</summary>
  
**动机:** 探索小型语言模型在自动问题生成中的应用，作为大型语言模型在学习分析研究中的补充，旨在利用SLM的优势生成高质量问题。

**方法:** 采用"生成-验证"策略的流水线方法：首先进行扩展性生成产生大量候选问题，然后通过基于概率推理的选择性验证进行精炼。进行了两项评估研究（人类专家评估和大型语言模型评估）。

**结果:** 大多数评估者（人类专家和大型语言模型）认为生成的问题具有清晰的答案，并且与预期学习目标基本一致。

**结论:** 研究结果表明，当通过精心设计的流水线充分利用其优势时，小型语言模型能够有效生成高质量的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generate-Then-Validate%3A+A+Novel+Question+Generation+Approach+Using+Small+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10110，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10110&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [57] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

**主要类别:** cs.CL

**AI概要:** DeepNews框架通过模拟金融记者的认知过程，解决了长文本生成中的"不可能三角"问题，在低幻觉、深度逻辑连贯性和个性化表达方面取得突破，使用信息检索、模式规划和对抗约束提示等技术显著提升了生成质量。


<details>
  <summary>更多</summary>
  
**动机:** 当前大语言模型在垂直领域长文本生成中存在"不可能三角"的瓶颈问题：难以同时实现低幻觉、深度逻辑连贯性和个性化表达。研究发现这是由于现有生成范式陷入了"统计平滑陷阱"，忽略了专家写作所需的高熵信息获取和结构化认知过程。

**方法:** 提出DeepNews框架，模拟资深金融记者的隐式认知过程，包含三个核心模块：1)基于信息觅食理论的双粒度检索机制，强制执行10:1的饱和信息输入比例；2)模式引导的战略规划，利用领域专家知识库和原子块构建逻辑骨架；3)对抗约束提示技术，通过节奏打断和逻辑迷雾等策略打破模型生成文本的概率平滑性。

**结果:** 实验发现金融深度报道中存在明显的"知识悬崖"：当检索上下文低于15,000字符时内容真实性崩溃，而超过30,000字符的高冗余输入可将无幻觉率(HFR)稳定在85%以上。在与中国顶级科技媒体的生态效度盲测中，基于前代模型的DeepNews系统获得了25%的投稿接受率，显著优于最先进模型的零样本生成(0%接受率)。

**结论:** DeepNews框架通过显式建模专家认知过程，成功突破了长文本生成的"不可能三角"瓶颈，证明了结构化工作流和对抗约束在提升生成质量方面的有效性，为垂直领域的专业内容生成提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Workflow+is+All+You+Need%3A+Escaping+the+%22Statistical+Smoothing+Trap%22+via+High-Entropy+Information+Foraging+and+Adversarial+Pacing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10121，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10121&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [58] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park, Jeongseok Yun, Bohyung Kim*

**主要类别:** cs.CL

**AI概要:** 提出两阶段提示框架，从短评论文本推断用户显性和隐性特征，用于生成个性化回复，无需微调模型即可提升相关性和个性化程度


<details>
  <summary>更多</summary>
  
**动机:** 在用户信息有限的领域（如外卖平台），大语言模型因缺乏上下文用户数据而生成通用回复，降低用户参与度和效果

**方法:** 两阶段提示框架：1）从短评论文本推断显性（用户偏好）和隐性（人口统计或风格线索）用户特征；2）将这些特征融入回复生成提示中，并通过调整解码温度来鼓励多样且忠实的生成

**结果:** 在韩国外卖应用真实数据集上评估，显示该方法在精确度、多样性和语义一致性方面有效提升了自动回复的相关性和个性化

**结论:** 基于人物特征增强的提示方法能有效提升自动回复的相关性和个性化，且无需模型微调

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PARAN%3A+Persona-Augmented+Review+ANswering+system+on+Food+Delivery+Review+Dataset，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10148，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10148&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [59] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum, Hani Itani, Hasan Abed Al Kader Hammoud, Philip Torr, Adel Bibi, Bernard Ghanem*

**主要类别:** cs.CL

**AI概要:** 论文研究大语言模型在微调过程中的安全性退化问题，提出将安全保持问题视为持续学习问题，并通过实验验证持续学习方法能有效降低攻击成功率。


<details>
  <summary>更多</summary>
  
**动机:** 随着大语言模型的普及，安全对齐变得日益重要。研究发现模型在适应新任务时会出现安全性退化，这归因于灾难性遗忘问题。

**方法:** 采用持续学习方法，包括基于正则化、基于记忆和模型融合的方法，在良性用户数据和中毒用户数据两种场景下进行系统评估。

**结果:** 实验结果显示持续学习方法相比标准微调能持续获得更低的攻击成功率，其中DER方法表现最佳，在保持任务效用的同时优于其他方法。

**结论:** 持续学习是保持大语言模型安全性的实用解决方案，这一发现在三个下游任务和三个模型家族中都得到了验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unforgotten+Safety%3A+Preserving+Safety+Alignment+of+Large+Language+Models+with+Continual+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10150，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10150&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [60] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh, Sangjoon Park, Byung-Hoon Kim*

**主要类别:** cs.CL

**AI概要:** AutoMedic是一个多智能体模拟框架，用于自动化评估大语言模型在临床对话中的表现，通过将静态医学问答数据集转化为虚拟患者档案，实现多轮临床对话模拟，并使用CARE指标进行多维度评估。


<details>
  <summary>更多</summary>
  
**动机:** 当前医学领域LLM评估主要依赖静态问答基准，缺乏对动态交互式临床对话场景的有效评估方法，且现有评估策略单一，难以标准化和量化动态临床情境。

**方法:** 开发AutoMedic框架，将现成的静态QA数据集转化为虚拟患者档案，创建LLM智能体间的多轮临床对话模拟，采用CARE指标（临床对话准确性、效率/策略、同理心和鲁棒性）进行多维度评估。

**结果:** 研究验证了AutoMedic作为临床对话智能体自动化评估框架的有效性，人类专家验证表明该框架能提供实用的LLM在对话医学应用中的开发指南。

**结论:** AutoMedic解决了临床对话评估的标准化难题，为LLM在医学对话应用中的有效开发提供了可靠的自动化评估解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoMedic%3A+An+Automated+Evaluation+Framework+for+Clinical+Conversational+Agents+with+Medical+Dataset+Grounding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10195，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10195&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


### [61] [Multilingual VLM Training: Adapting an English-Trained VLM to French](https://arxiv.org/abs/2512.10336)
*Jules Lahmi, Alexis Roger*

**主要类别:** cs.CL

**AI概要:** 本文研究将英语训练的视觉语言模型(VLM)适配到其他语言的挑战，比较了翻译管道、LoRA微调和两阶段微调等方法，发现数据集翻译是多语言VLM性能的主要瓶颈。


<details>
  <summary>更多</summary>
  
**动机:** 当前视觉语言模型的进展主要局限于英语，需要将这些能力扩展到更多语言以提高非英语用户的可访问性。

**方法:** 比较了三种方法：基于翻译的管道方法、LoRA微调策略，以及分离视觉适配和语言适配的两阶段微调策略。评估使用翻译后的多模态基准测试和母语专家的手动评估。

**结果:** 研究发现数据集翻译是多语言VLM性能的主要瓶颈，数据质量限制了训练和评估的有效性。

**结论:** 未来工作应专注于原生语言数据集的收集和改进翻译策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilingual+VLM+Training%3A+Adapting+an+English-Trained+VLM+to+French，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10336，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10336&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.

</details>


### [62] [Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale](https://arxiv.org/abs/2512.10398)
*Zhaodong Wang, Zhenting Qi, Sherman Wong, Nathan Hu, Samuel Lin, Jun Ge, Erwin Gao, Yining Yang, Ben Maurer, Wenlin Chen, David Recordon, Yilun Du, Minlan Yu, Ying Zhang*

**主要类别:** cs.CL

**AI概要:** 孔子代码代理(CCA)是一个开源AI软件工程师，在工业规模任务上表现优异，在SWE-Bench-Pro基准测试中达到54.3%的最先进性能，通过孔子SDK平台实现了长上下文推理、跨会话持续学习和模块化工具使用。


<details>
  <summary>更多</summary>
  
**动机:** 现有开源编码代理在工业规模工作负载下表现不足，而专有代理虽然性能强但缺乏可扩展性、可解释性和可控性，需要开发一个既能处理大规模存储库又具有透明性的AI软件工程代理。

**方法:** 基于孔子SDK平台构建，采用分层工作内存进行长上下文推理，持久笔记系统实现跨会话持续学习，模块化扩展模块支持稳健工具使用，并通过元代理自动合成、评估和改进代理配置。

**结果:** 在SWE-Bench-Pro基准测试中取得了54.3%的Resolve@1最先进性能，显著优于之前的编码代理，证明了在真实世界软件工程任务中的强大性能。

**结论:** 孔子SDK和CCA为AI代理提供了透明、可扩展和可复现的基础，弥合了研究原型与生产级系统之间的差距，支持工业规模的代理开发和部署。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Confucius+Code+Agent%3A+An+Open-sourced+AI+Software+Engineer+at+Industrial+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10398，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10398&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.

</details>


### [63] [Sliding Window Attention Adaptation](https://arxiv.org/abs/2512.10411)
*Yijiong Yu, Jiale Liu, Qingyun Wu, Huazheng Wang, Ji Pei*

**主要类别:** cs.CL

**AI概要:** 提出SWAA方法，通过五种策略组合让全注意力预训练的LLM适应滑动窗口注意力，在保持线性计算复杂度的同时有效恢复长上下文性能


<details>
  <summary>更多</summary>
  
**动机:** Transformer自注意力机制在长上下文推理时计算成本呈二次增长，滑动窗口注意力可降为线性复杂度，但直接应用会导致训练-推理不匹配的性能下降

**方法:** 结合五种适应方法：仅在前填充阶段使用SWA、保留"sink"令牌、交替FA/SWA层、思维链推理、微调

**结果:** 实验表明单一方法不足但特定组合能有效恢复原始长上下文性能，分析了不同配置的性能-效率权衡

**结论:** SWA适应是可行但非平凡的，提供了针对不同场景的推荐配置方案，实现了计算效率与性能的良好平衡

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sliding+Window+Attention+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10411，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10411&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation

</details>


### [64] [Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers](https://arxiv.org/abs/2512.10422)
*Youmin Ko, Sungjong Seo, Hyunjoon Kim*

**主要类别:** cs.CL

**AI概要:** CoopRAG是一个新颖的检索增强生成框架，通过检索器和LLM的协同工作，以及检索器模型不同层之间的协作，显著提升了问答任务的准确性和检索性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有RAG方法在简单和多跳问答中仍存在错误检索和幻觉问题，需要更有效的框架来解决这些限制。

**方法:** 提出四步框架：(i)将问题分解为子问题和带掩码的推理链；(ii)基于增强信息检索相关文档；(iii)通过对比检索器层重新排序文档；(iv)通过LLM填充掩码位置重建推理链。

**结果:** 在三个多跳问答数据集和一个简单问答数据集上，CoopRAG在检索和问答性能方面均优于最先进的方法。

**结论:** CoopRAG通过协同工作机制有效解决了RAG中的错误检索和幻觉问题，为问答任务提供了更可靠的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cooperative+Retrieval-Augmented+Generation+for+Question+Answering%3A+Mutual+Information+Exchange+and+Ranking+by+Contrasting+Layers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10422，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10422&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

</details>


### [65] [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)
*Dmitrii Stoianov, Danil Taranets, Olga Tsymboi, Ramil Latypov, Almaz Dautov, Vladislav Kruglikov, Nikita Surkov, German Abramov, Pavel Gein, Dmitry Abulkhanov, Mikhail Gashkov, Viktor Zelenkovskiy, Artem Batalov, Aleksandr Medvedev, Anatolii Potapov*

**主要类别:** cs.CL

**AI概要:** T-pro 2.0是一个开源俄语大语言模型，支持混合推理和高效推理，包含模型权重、指令语料库、推理基准和推理加速技术资源。


<details>
  <summary>更多</summary>
  
**动机:** 为俄语语言推理研究提供可复现和可扩展的开源系统，支持高效的俄语LLM应用开发和评估。

**方法:** 使用西里尔字母密集分词器和适配的EAGLE推测解码流水线来降低延迟，支持直接回答和推理轨迹生成。

**结果:** 发布了完整的开源资源包（模型权重、T-Wix 500k指令语料、T-Math推理基准、EAGLE权重），并提供了公开网络演示展示推理加速效果。

**结论:** T-pro 2.0作为一个易于访问的开源系统，为构建和评估高效实用的俄语LLM应用提供了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是T-pro+2.0%3A+An+Efficient+Russian+Hybrid-Reasoning+Model+and+Playground，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10430，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10430&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.

</details>


### [66] [Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring "Tortured Phrases" in Scientific Literature](https://arxiv.org/abs/2512.10435)
*Agniva Maiti, Prajwal Panth, Suresh Chandra Satapathy*

**主要类别:** cs.CL

**AI概要:** 提出SRAP框架，通过两阶段方法检测并恢复对抗性抄袭中的"扭曲短语"，相比零基线方法显著提升恢复准确率至23.67%，并能溯源抄袭来源。


<details>
  <summary>更多</summary>
  
**动机:** 科学文献完整性受到对抗性文本生成技术威胁，现有检测方法依赖静态黑名单或通用语言模型，对新型混淆技术检测效果差且无法溯源。

**方法:** 两阶段架构：1) 使用SciBERT进行统计异常检测；2) 使用FAISS和SBERT进行基于源头的语义重建和句子对齐。

**结果:** 实验显示零基线方法恢复准确率为0%，而SRAP方法达到23.67%恢复准确率，显著优于基线方法。

**结论:** SRAP框架不仅能有效检测对抗性抄袭，还能数学重建原始术语并进行法证分析，静态决策边界在科学文本检测中至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semantic+Reconstruction+of+Adversarial+Plagiarism%3A+A+Context-Aware+Framework+for+Detecting+and+Restoring+%22Tortured+Phrases%22+in+Scientific+Literature，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10435，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10435&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate "tortured phrases", statistically improbable synonyms (e.g. "counterfeit consciousness" for "artificial intelligence"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.

</details>


### [67] [Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT](https://arxiv.org/abs/2512.10440)
*Nour El Houda Ben Chaabene, Hamza Hammami*

**主要类别:** cs.CL

**AI概要:** 论文提出通过知识图谱(KG)和KG-BERT集成来增强大语言模型的基于知识的推理能力，解决LLMs在事实一致性方面的问题


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型如Claude、Mistral IA和GPT-4在NLP任务中表现出色，但缺乏结构化知识，导致事实不一致性问题

**方法:** 通过知识图谱(KGs)集成，使用KG-BERT方法来增强模型的基于知识的推理和接地能力

**结果:** 实验显示在知识密集型任务如问答和实体链接方面取得了显著提升

**结论:** 该方法提高了事实可靠性，并使得下一代LLMs具备更强的上下文感知能力

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Next-Generation+Language+Models+with+Knowledge+Graphs%3A+Extending+Claude%2C+Mistral+IA%2C+and+GPT-4+via+KG-BERT，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10440，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10440&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.

</details>


### [68] [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)
*Nour El Houda Ben Chaabene, Hamza Hammami, Laid Kahloul*

**主要类别:** cs.CL

**AI概要:** 本文提出了一种心理感知的对话代理，结合LLM、KG-BERT和双向LSTM注意力机制，通过多模态数据实时分析学生的认知和情感状态，在教育环境中提升学习表现和情绪健康。


<details>
  <summary>更多</summary>
  
**动机:** 传统聊天机器人要么专注于辅导，要么专注于情感支持，无法同时满足学生的认知和情感需求。本研究旨在开发一个能同时提升学习效果和情绪健康的智能对话系统。

**方法:** 使用大型语言模型(LLMs)、知识图谱增强的BERT(KG-BERT)和带注意力的双向LSTM，整合文本语义、语音韵律特征和时间行为趋势等多模态数据，实时分类学生的认知和情感状态。

**结果:** 在大学学生中进行的试点研究显示，相比基线方法，该系统提高了学习动机、减轻了压力，并取得了适度的学业提升。

**结论:** 研究结果表明，整合语义推理、多模态融合和时间建模的方法具有很大潜力，能够支持自适应的、以学生为中心的教育干预措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decoding+Student+Minds%3A+Leveraging+Conversational+Agents+for+Psychological+and+Learning+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10441，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10441&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.

</details>


### [69] [Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs](https://arxiv.org/abs/2512.10453)
*Lars G. B. Johnsen*

**主要类别:** cs.CL

**AI概要:** 大型语言模型仅通过表层形式训练就能识别语法结构，在主语-助动词倒装和寄生空位许可等句法结构中表现出对语法性的敏感，表明其具备底层结构表征能力


<details>
  <summary>更多</summary>
  
**动机:** 验证仅基于表层形式训练的大型语言模型是否能够重现传统生成语法中的系统性语法对比，从而推断其是否具备内部层级语法结构表征

**方法:** 使用GPT-4和LLaMA-3等模型，通过提示词引发可接受性评分，重点测试主语-助动词倒装（识别主语边界）和寄生空位许可（测试抽象依赖结构）两种经典结构

**结果:** LLMs能够可靠地区分两种结构中的语法和非语法变体，表现出对结构而不仅仅是线性顺序的敏感性

**结论:** 结构泛化从表层形式的预测训练中涌现，表明LLMs具备对句法的功能性敏感，而无需显式编码语法知识

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grammaticality+Judgments+in+Humans+and+Language+Models%3A+Revisiting+Generative+Grammar+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10453，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10453&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.

</details>


### [70] [XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](https://arxiv.org/abs/2512.10545)
*Iñaki Lacunza, José Javier Saiz, Alexander Shvets, Aitor Gonzalez-Agirre, Marta Villegas*

**主要类别:** cs.CL

**AI概要:** 论文提出XDoGE方法优化多语言模型的语言分布，通过重采样和持续预训练提升中低资源语言性能，并发布了针对伊比利亚语言的IberianLLM-7B模型


<details>
  <summary>更多</summary>
  
**动机:** 当前大语言模型过度依赖高资源语言（如英语），导致在中低资源语言上表现不佳，需要解决语言分布不平衡问题

**方法:** 扩展DoGE算法为XDoGE用于多语言设置，优化语言分布：(i)训练小型代理模型确定语言权重(ii)重新缩放数据并训练完整模型（从头训练或持续预训练）

**结果:** 在包含6种不同资源水平语言（英语、西班牙语、葡萄牙语、加泰罗尼亚语、加利西亚语、巴斯克语）的实验显示，该方法能有效改善模型性能

**结论:** XDoGE方法能有效缓解语言不平衡问题，新发布的IberianLLM-7B模型在伊比利亚语言和英语上表现出色，为多语言NLP提供了有前景的解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是XDoGE%3A+Multilingual+Data+Reweighting+to+Enhance+Language+Inclusivity+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10545，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10545&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.

</details>


### [71] [Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models](https://arxiv.org/abs/2512.10561)
*Amartya Roy, Elamparithy M, Kripabandhu Ghosh, Ponnurangam Kumaraguru, Adrian de Wynter*

**主要类别:** cs.CL

**AI概要:** 论文研究发现，在因果推理任务中，仅使用上下文学习(ICL)是不够的，解码器模型对分布变化敏感，而经过微调的编码器和编码器-解码器架构在因果推理中表现更稳健，特别是在小规模模型中。


<details>
  <summary>更多</summary>
  
**动机:** 探究不同架构的大语言模型在因果推理任务中的表现，特别关注上下文学习在因果推理中的作用和局限性，因为因果推理需要多跳组合和严格的合取控制。

**方法:** 比较了编码器、编码器-解码器和仅解码器架构的微调版本，在零样本和少样本上下文学习设置下，分别在自然语言和非自然语言场景中进行测试。

**结果:** ICL单独使用在因果推理中不可靠，容易过度关注无关输入特征。仅解码器模型对分布变化敏感，而微调的编码器和编码器-解码器模型在所有测试中（包括非自然语言场景）表现更稳健。仅在大规模时，解码器架构才能匹配或超越其他架构。

**结论:** 对于成本效益高、短周期的稳健因果推理，经过针对性微调的编码器或编码器-解码器架构是更好的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Reasoning+Favors+Encoders%3A+On+The+Limits+of+Decoder-Only+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10561，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10561&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.

</details>


### [72] [RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems](https://arxiv.org/abs/2512.10575)
*Hang Ding, Qiming Feng, Dongqi Liu, Qi Zhao, Tao Yao, Shuo Wang, Dongsheng Chen, Jian Li, Zhenye Gan, Jiangning Zhang, Chengjie Wang, Yabiao Wang*

**主要类别:** cs.CL

**AI概要:** RoleRMBench是首个角色扮演对话奖励建模基准，揭示了通用奖励模型在主观领域表现不佳，提出的RoleRM模型通过连续隐式偏好训练，在叙事一致性和风格保真度上超越现有模型24%以上。


<details>
  <summary>更多</summary>
  
**动机:** 现有奖励模型在处理主观开放式领域（如角色扮演）时表现严重退化，无法捕捉基于角色的细微人类判断，需要专门针对角色扮演对话的奖励建模方法。

**方法:** 提出RoleRMBench基准，覆盖7个细粒度能力；开发RoleRM模型，采用连续隐式偏好（CIP）方法，将主观评估重新表述为多结构化策略下的连续一致性成对监督。

**结果:** RoleRM在RoleRMBench上平均超越强开源和闭源奖励模型24%以上，在叙事连贯性和风格保真度方面取得显著提升。

**结论:** 连续偏好表示和标注一致性的重要性，为人本对话系统中的主观对齐奠定了基础，证明了专门针对角色扮演领域的奖励建模的必要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RoleRMBench+%26+RoleRM%3A+Towards+Reward+Modeling+for+Profile-Based+Role+Play+in+Dialogue+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10575，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10575&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.

</details>


### [73] [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)
*Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li*

**主要类别:** cs.CL

**AI概要:** AgriGPT-Omni是一个农业全模态框架，通过整合语音、视觉和文本，解决了农业AI应用中多语言语音数据缺乏、统一架构缺失和评估标准不足的问题。


<details>
  <summary>更多</summary>
  
**动机:** 农业应用中缺乏多语言语音数据、统一的多模态架构以及全面的评估基准，限制了多模态大语言模型的发展。

**方法:** 1. 构建可扩展的数据合成和收集管道，创建了最大的农业语音数据集（49.2万合成样本+1.4万真实样本，覆盖6种语言）；2. 采用三阶段训练范式：文本知识注入、渐进式多模态对齐和GRPO强化学习；3. 提出首个农业三模态基准AgriBench-Omni-2K。

**结果:** AgriGPT-Omni在多语言和多模态推理以及真实世界语音理解方面显著优于通用基线模型。

**结论:** 该框架将促进可重复研究、包容性农业智能和低资源地区的可持续AI发展，所有模型、数据、基准和代码都将公开发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgriGPT-Omni%3A+A+Unified+Speech-Vision-Text+Framework+for+Multilingual+Agricultural+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10624，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10624&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.

</details>


### [74] [From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages](https://arxiv.org/abs/2512.10630)
*Smiljana Antonijevic Ubois*

**主要类别:** cs.CL

**AI概要:** 该研究以塞尔维亚语为例，分析了AI时代低资源语言技术发展的结构性和社会技术挑战，提出了基于CARE原则的Data Care框架，旨在从数据源头解决文化偏见问题。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型主要基于英语等主导语言训练，对低资源语言的表示反映了源语言材料的文化和语言偏见，需要解决这种不平衡发展问题。

**方法:** 采用半结构化访谈方法，采访了十位学者和实践者，包括语言学家、数字人文研究者和AI开发者，分析塞尔维亚语面临的具体挑战。

**结果:** 识别出历史文本遗产破坏、表面音译、依赖英语训练模型、数据偏见和缺乏文化特性的数据集管理等挑战，并提出了Data Care框架。

**结论:** Data Care框架将偏见缓解从技术修复转变为语料库设计、标注和治理的核心组成部分，为构建包容性、可持续和文化基础的语言技术提供了可复制的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Data+Scarcity+to+Data+Care%3A+Reimagining+Language+Technologies+for+Serbian+and+other+Low-Resource+Languages，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10630，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10630&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.

</details>


### [75] [Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation](https://arxiv.org/abs/2512.10734)
*Rebekka Görge, Sujan Sai Gannamaneni, Tabea Naeven, Hammam Abdelwahab, Héctor Allende-Cid, Armin B. Cremers, Lennard Helmer, Michael Mock, Anna Schmitz, Songkai Xue, Elif Yildirir, Maximilian Poretschkin, Stefan Wrobel*

**主要类别:** cs.CL

**AI概要:** 本文提出一个全面的数据偏见检测和缓解流程，包含四个组件来处理表示偏见和显式刻板印象，通过人工验证和基准测试证明能有效减少数据偏见，但发现使用去偏见数据微调的LLM在偏见基准测试中表现不一致。


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型训练数据存在多方面偏见表现，包括有害语言和倾斜的人口统计分布。欧盟AI法案等法规要求识别和减轻对受保护群体的偏见，但缺乏实践指导和操作化方法。

**方法:** 提出四组件管道：1)使用LLM生成的质量标准词表检测群体标签；2)用人口统计表示分数量化表示偏见；3)用社会语言学过滤检测和缓解刻板印象；4)通过语法和上下文感知的反事实数据增强补偿表示偏见。以性别、宗教和年龄为例进行验证。

**结果:** 成功减少了文本数据集中的表示偏见和显式刻板印象。但对多个模型(0.6B-8B参数)在去偏见数据上微调后的偏见基准测试显示，模型偏见减少效果不一致。

**结论:** 当前评估方法存在关键差距，需要针对性的数据操作来处理表现出的模型偏见，数据去偏见不能保证模型偏见的系统性减少。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Textual+Data+Bias+Detection+and+Mitigation+-+An+Extensible+Pipeline+with+Experimental+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10734&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.

</details>


### [76] [Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving](https://arxiv.org/abs/2512.10739)
*Songyang Gao, Yuzhe Gu, Zijian Wu, Lingkai Kong, Wenwei Zhang, Zhongrui Cai, Fan Zheng, Tianyou Ma, Junhao Shen, Haiteng Zhao, Duanyang Zhang, Huilun Zhang, Kuikun Liu, Chengqi Lyu, Yanhui Duan, Chiyu Chen, Ningsheng Ma, Jianfei Gao, Han Lyu, Dahua Lin, Kai Chen*

**主要类别:** cs.CL

**AI概要:** 论文提出了OPV（Outcome-based Process Verifier）验证器，通过结合结果验证和过程验证的优势，使用迭代主动学习框架来高效检测长推理链中的错误，在多个基准测试中达到SOTA性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的结果验证器无法检查长推理链中的中间步骤错误，而过程验证器由于人工标注成本高昂导致高质量标注稀缺，难以可靠检测复杂长推理链中的错误。

**方法:** 提出OPV验证器，通过总结长推理链的结果来验证推理过程；采用迭代主动学习框架，通过Rejection Fine-Tuning和RLVR逐步提升验证能力；选择最不确定的案例进行专家标注来降低标注成本。

**结果:** OPV在held-out benchmark上达到83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作时显著提升性能，如将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升到73.3%。

**结论:** OPV验证器实现了准确高效的验证和大规模标注，在复杂推理任务验证方面表现出卓越性能和广泛适用性，为LLM的可靠推理提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Long-horizon+Reasoning+Agent+for+Olympiad-Level+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10739，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10739&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbf{O}utcome-based \textbf{P}rocess \textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc{\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\% to 73.3\% on AIME2025 as the compute budget scales.

</details>


### [77] [TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage](https://arxiv.org/abs/2512.10741)
*Elroy Galbraith, Chadwick Sutherland, Donahue Morgan*

**主要类别:** cs.CL

**AI概要:** TRIDENT是一个三层调度员支持架构，通过加勒比口音优化的语音识别、本地实体提取和生物声学压力检测，为紧急呼叫提供转录置信度、结构化临床实体和声音压力指标，确保在语音识别失败时仍能应用标准分诊协议。


<details>
  <summary>更多</summary>
  
**动机:** 紧急语音识别系统在非标准英语变体（如加勒比口音）上存在系统性性能下降，导致加勒比人群无法获得平等的紧急服务。

**方法:** 采用三层架构：1）加勒比口音调优的自动语音识别；2）通过大语言模型进行本地实体提取；3）生物声学压力检测。结合心理语言学研究中压力诱发的语码转换理论。

**结果:** 系统提供了三个互补信号：转录置信度、结构化临床实体和声音压力指标。低ASR置信度可作为队列优先级信号，结合声音压力标记识别危机呼叫者。

**结论:** 建立了一个口音弹性的紧急AI框架，确保加勒比声音能够平等获得国家分诊协议。实证验证仍是未来工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRIDENT%3A+A+Redundant+Architecture+for+Caribbean-Accented+Emergency+Speech+Triage，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10741，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10741&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.
  The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.
  We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.

</details>


### [78] [OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification](https://arxiv.org/abs/2512.10756)
*Zijian Wu, Lingkai Kong, Wenwei Zhang, Songyang Gao, Yuzhe Gu, Zhongrui Cai, Tianyou Ma, Yuhong Liu, Zhi Wang, Runyuan Ma, Guangyu Wang, Wei Li, Conghui He, Dahua Lin, Kai Chen*

**主要类别:** cs.CL

**AI概要:** 该论文提出了基于结果的过程验证器(OPV)，通过验证长思维链的总结结果来准确高效地检测推理过程中的错误，采用迭代主动学习框架降低标注成本，在多个基准测试中达到最先进性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于结果的验证器无法检查长推理链中的中间步骤错误，而基于过程的验证器由于高质量标注数据稀缺且人工标注成本高昂，难以可靠检测复杂长推理链中的错误。

**方法:** 提出OPV验证器，通过验证长思维链的总结结果来检查推理过程；采用迭代主动学习框架，通过拒绝微调(RFT)和RLVR逐步提升验证能力；在每轮迭代中标注当前最佳OPV最不确定的案例用于训练。

**结果:** OPV在OPV-Bench上达到83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作时显著提升性能，如将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%。

**结论:** OPV通过结合结果验证和过程验证的优势，实现了准确高效的推理过程验证，同时通过主动学习降低了标注成本，在多个任务中展现出优越性能和广泛适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OPV%3A+Outcome-based+Process+Verifier+for+Efficient+Long+Chain-of-Thought+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10756，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10756&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.

</details>


### [79] [Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation](https://arxiv.org/abs/2512.10772)
*Kevin Glocker, Kätriin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz*

**主要类别:** cs.CL

**AI概要:** 研究发现通过放大英语基础模型规模，可以在目标语言适应中实现比传统持续预训练更高的数据效率和性能，同时减少灾难性遗忘。模型合并虽然不如联合多语言训练有效，但放大后的模型合并效果更好。


<details>
  <summary>更多</summary>
  
**动机:** 解决多语言模型中中低资源语言性能不佳的问题，探索通过模型缩放而非传统持续预训练来更有效地适应新语言

**方法:** 进行全面的缩放消融实验，使用FLOP匹配的模型比较放大英语基础模型与标准持续预训练在目标语言适应中的效果

**结果:** 放大后的模型在获得足够目标语言数据后，能够匹配或超越使用更多数据持续预训练的小模型，显示出缩放对数据效率的益处，同时能更好地保留英语能力

**结论:** 模型缩放是适应新语言的有效策略，能提高数据效率并减少灾难性遗忘，模型合并方法在多语言系统构建中仍有改进空间

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grow+Up+and+Merge%3A+Scaling+Strategies+for+Efficient+Language+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10772&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model's capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.

</details>


### [80] [Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting](https://arxiv.org/abs/2512.10780)
*Manurag Khullar, Utkarsh Desai, Poorva Malviya, Aman Dalmia, Zheyuan Ryan Shi*

**主要类别:** cs.CL

**AI概要:** LLMs在印度临床应用中处理罗马化文本时性能显著下降，F1分数比原生文字低5-12分，可能导致近200万次分诊错误，尽管模型能理解语义意图但分类输出仍不稳定


<details>
  <summary>更多</summary>
  
**动机:** 印度语言使用者常用罗马化文本而非原生文字进行交流，但现有研究很少使用真实数据评估这种书写变体对LLM在临床应用中可靠性的影响

**方法:** 在母婴保健分诊关键领域，使用包含5种印度语言和尼泊尔语的真实用户查询数据集，对主流LLM进行基准测试

**结果:** 罗马化消息导致性能持续下降，F1分数比原生文字低5-12个百分点，在合作机构可能导致近200万分诊错误

**结论:** LLM健康系统存在关键安全盲点：看似理解罗马化输入的模型可能仍无法可靠地对其采取行动，这并非临床推理失败而是拼写噪声导致输出脆弱

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Script+Gap%3A+Evaluating+LLM+Triage+on+Indian+Languages+in+Native+vs+Roman+Scripts+in+a+Real+World+Setting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10780，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10780&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.

</details>


### [81] [The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality](https://arxiv.org/abs/2512.10791)
*Aileen Cheng, Alon Jacovi, Amir Globerson, Ben Golan, Charles Kwong, Chris Alberti, Connie Tao, Eyal Ben-David, Gaurav Singh Tomar, Lukas Haas, Yonatan Bitton, Adam Bloniarz, Aijun Bai, Andrew Wang, Anfal Siddiqui, Arturo Bajuelos Castillo, Aviel Atias, Chang Liu, Corey Fry, Daniel Balle, Deepanway Ghosal, Doron Kukliansky, Dror Marcus, Elena Gribovskaya, Eran Ofek, Honglei Zhuang, Itay Laish, Jan Ackermann, Lily Wang, Meg Risdal, Megan Barnes, Michael Fink, Mohamed Amin, Moran Ambar, Natan Potikha, Nikita Gupta, Nitzan Katz, Noam Velan, Ofir Roval, Ori Ram, Polina Zablotskaia, Prathamesh Bang, Priyanka Agrawal, Rakesh Ghiya, Sanjay Ganapathy, Simon Baumgartner, Sofia Erell, Sushant Prakash, Thibault Sellam, Vikram Rao, Xuanhui Wang, Yaroslav Akulov, Yulong Yang, Zhen Yang, Zhixin Lai, Zhongru Wu, Anca Dragan, Avinatan Hassidim, Fernando Pereira, Slav Petrov, Srinivasan Venkatachary, Tulsee Doshi, Yossi Matias, Sasha Goldshtein, Dipanjan Das*

**主要类别:** cs.CL

**AI概要:** FACTS Leaderboard是一个综合评估语言模型事实准确性的在线排行榜套件，包含四个子排行榜：多模态、参数化、搜索和基础化评估，通过自动化评分模型全面衡量模型在不同场景下生成事实准确文本的能力。


<details>
  <summary>更多</summary>
  
**动机:** 当前需要全面评估语言模型在各种实际场景中生成事实准确文本的能力，而现有评估方法往往局限于单一维度，缺乏对模型整体事实性的综合衡量。

**方法:** 构建包含四个子排行榜的评估套件：(1)FACTS多模态-图像问答事实性；(2)FACTS参数化-闭卷事实问题内部知识；(3)FACTS搜索-信息搜索场景事实性；(4)FACTS基础化v2-长文本响应与文档的关联性。使用自动化评分模型进行评分，最终得分为四个组分的平均值。

**结果:** 开发了一个全面的事实性评估框架，包含公开和私有数据集，支持外部参与同时保持评估完整性，提供对语言模型事实准确性的稳健平衡评估。

**结论:** FACTS Leaderboard为语言模型的事实准确性提供了全面的评估标准，将持续维护更新，为研究社区提供可靠的模型性能基准测试平台。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+FACTS+Leaderboard%3A+A+Comprehensive+Benchmark+for+Large+Language+Model+Factuality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10791&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models' world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model's overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .

</details>


### [82] [LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification](https://arxiv.org/abs/2512.10793)
*Michael Schlee, Christoph Weisser, Timo Kivimäki, Melchizedek Mashiku, Benjamin Saefken*

**主要类别:** cs.CL

**AI概要:** LabelFusion是一个文本分类融合集成系统，通过结合传统Transformer分类器和大型语言模型，实现准确且成本感知的多类和多标签分类预测。


<details>
  <summary>更多</summary>
  
**动机:** 传统Transformer分类器虽然准确但计算成本高，大型语言模型具有强大推理能力但成本高昂且延迟高。需要一种方法能结合两者的优势，在保持高精度的同时实现成本效益的平衡。

**方法:** 将传统Transformer分类器的嵌入向量与LLM通过结构化提示工程获得的每类分数进行拼接，然后将这个联合表示输入到紧凑的多层感知机(FusionMLP)中进行最终预测。

**结果:** 在多个数据集上取得优异性能：AG News准确率92.4%，10类Reuters 21578主题分类准确率92.3%。

**结论:** LabelFusion成功融合了LLM推理能力和传统分类器的优势，实现了跨领域的稳健性能，并在准确性、延迟和成本之间提供了实用的权衡方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LabelFusion%3A+Learning+to+Fuse+LLMs+and+Transformer+Classifiers+for+Robust+Text+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10793，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10793&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone's embeddings with the LLM-derived per-class scores -- obtained through structured prompt-engineering strategies -- and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains -- achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification -- while enabling practical trade-offs between accuracy, latency, and cost.

</details>


### [83] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

**主要类别:** cs.CL

**AI概要:** 本研究使用计算文本分析方法分析《霍比特人》对话的情感基调，发现对话保持积极平静的语调，随着故事发展逐渐增强主导感，揭示了小说在紧张与舒适间循环的情感节奏。


<details>
  <summary>更多</summary>
  
**动机:** 探索如何通过计算工具和文学解释相结合的方法，揭示文学作品中的微妙情感结构，特别是分析《霍比特人》中对话的情感维度和叙事节奏。

**方法:** 使用正则表达式提取对话文本，经过预处理后，采用NRC-VAD情感词典对情感维度进行量化分析，包括情感轨迹图和词云可视化。

**结果:** 对话保持总体上积极（高情感价）和冷静（低唤醒度）的基调，随着故事进展逐渐增强主导感（支配度），危险和兴奋时刻经常被幽默、友情和缓解所平衡。

**结论:** 计算工具能够有效揭示文学作品中微妙的情感结构，展示了《霍比特人》中稳定的情感节奏和情感调节如何塑造叙事，为数字人文研究提供了有效方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantifying+Emotional+Tone+in+Tolkien%27s+The+Hobbit%3A+Dialogue+Sentiment+Analysis+with+RegEx%2C+NRC-VAD%2C+and+Python，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10865，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10865&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [84] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

**主要类别:** cs.CL

**AI概要:** 该研究评估了多模态大语言模型(mLLMs)在视频情绪分析中的表现，发现在理想条件下表现良好且无人口统计偏差，但在真实议会辩论场景中表现不佳，强调了需要持续评估AI方法在政治分析中的应用。


<details>
  <summary>更多</summary>
  
**动机:** 虽然多模态生成AI在情绪分析方面有巨大潜力，但缺乏关于其在政治沟通中情绪分析有效性的实证证据，需要填补这一研究空白。

**方法:** 使用两个互补的人类标注视频数据集，评估当前多模态大语言模型在基于视频的情绪唤起分析中的表现。

**结果:** 在理想条件下，mLLMs的情绪唤起评分高度可靠且几乎没有人口统计偏差；但在真实议会辩论录音中，mLLMs的唤起评分未能达到预期效果，可能对下游统计推断产生负面影响。

**结论:** 研究强调需要持续、彻底评估新兴生成AI方法在政治分析中的应用，并提供了一个可复制的评估框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computational+emotion+analysis+with+multimodal+LLMs%3A+Current+evidence+on+an+emerging+methodological+opportunity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10882&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


### [85] [Unsupervised Acquisition of Discrete Grammatical Categories](https://arxiv.org/abs/2503.18702)
*David Ph. Shakouri, Crit Cremers, Niels O. Schiller*

**主要类别:** cs.CL

**AI概要:** 该研究通过多智能体系统模拟语言习得过程，展示了如何仅通过语言示例学习抽象语法知识，使用聚类分析从输入数据中提取离散语法规则，并验证了该计算实验室环境的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索语言习得的计算机制，特别是如何仅通过语言输入示例（而非内部知识）来获得抽象语法知识，模拟儿童语言习得过程。

**方法:** 使用包含成人语言模型和女儿语言模型的多智能体系统，女儿模型只能访问母亲模型生成的语言示例。采用层次凝聚聚类分析对连续生成的话语进行分析，提取语法规则。

**结果:** 实验成功地从输入数据中获得了离散的语法规则，这些规则类似于语言学家提出的自然语言语法范畴。在训练数据和测试集上都验证了非平凡语法知识的获得。

**结论:** 该计算实验室环境能够有效模拟语言习得过程，仅通过语言输入就能获得抽象语法知识，为理解人类语言习得机制提供了计算建模方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Acquisition+of+Discrete+Grammatical+Categories，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2503.18702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2503.18702&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.

</details>
