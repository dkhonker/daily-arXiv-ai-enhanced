{"id": "2505.23783", "pdf": "https://arxiv.org/pdf/2505.23783", "abs": "https://arxiv.org/abs/2505.23783", "authors": ["Korel Gundem", "Juncheng Dong", "Dennis Zhang", "Vahid Tarokh", "Zhengling Qi"], "title": "Boosting In-Context Learning in LLMs Through the Lens of Classical Supervised Learning", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "In-Context Learning (ICL) allows Large Language Models (LLMs) to adapt to new\ntasks with just a few examples, but their predictions often suffer from\nsystematic biases, leading to unstable performances in classification. While\ncalibration techniques are proposed to mitigate these biases, we show that, in\nthe logit space, many of these methods are equivalent to merely shifting the\nLLM's decision boundary without having the ability to alter its orientation.\nThis proves inadequate when biases cause the LLM to be severely misdirected. To\naddress these limitations and provide a unifying framework, we propose\nSupervised Calibration (SC), a loss-minimization based framework which learns\nan optimal, per-class affine transformation of the LLM's predictive\nprobabilities in the logit space without requiring external data beyond the\ncontext. By using a more expressive functional class, SC not only subsumes many\nexisting calibration methods in ICL as special cases, but also enables the\nability to alter and even completely reverse the orientation of the LLM's\ndecision boundary. Furthermore, SC's loss-based nature facilitates the seamless\nintegration of two purpose-built regularization techniques: context-invariance\nand directional trust-region. The former is designed to tackle the instability\nissue in ICL, while the latter controls the degree of calibration. Finally, SC\ndelivers state-of-the-art performance over calibration baselines in the 4-shot,\n8-shot, and 16-shot settings across all nine datasets for\nMistral-7B-Instruct-v0.3, LLaMA-2-7B-chat, and Qwen2-7B-Instruct.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa Supervised Calibration\uff08SC\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728 logit \u7a7a\u95f4\u4e2d\u8fdb\u884c\u6700\u4f18\u4eff\u5c04\u53d8\u6362\u5e76\u5f15\u5165\u65b0\u578b\u6b63\u5219\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347 In-Context Learning \u7684\u6821\u51c6\u6548\u679c\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "In-Context Learning (ICL) \u7684\u9884\u6d4b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u4f20\u7edf\u6821\u51c6\u65b9\u6cd5\u53ea\u80fd\u8c03\u6574\u51b3\u7b56\u8fb9\u754c\u7684\u4f4d\u7f6e\uff0c\u65e0\u6cd5\u6539\u53d8\u5176\u65b9\u5411\uff0c\u5bfc\u81f4\u5728\u4e25\u91cd\u504f\u5dee\u60c5\u51b5\u4e0b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa Supervised Calibration (SC)\uff0c\u57fa\u4e8e\u635f\u5931\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\uff0c\u5728 logit \u7a7a\u95f4\u4e2d\u5b66\u4e60\u6bcf\u4e2a\u7c7b\u522b\u7684\u4eff\u5c04\u53d8\u6362\uff0c\u540c\u65f6\u5f15\u5165\u4e24\u79cd\u6b63\u5219\u5316\u6280\u672f\uff1acontext-invariance \u548c directional trust-region\u3002", "result": "SC \u80fd\u591f\u6539\u53d8 LLM \u51b3\u7b56\u8fb9\u754c\u7684\u53d6\u5411\uff0c\u751a\u81f3\u5b8c\u5168\u53cd\u8f6c\uff1b\u5728 4-shot\u30018-shot \u548c 16-shot \u8bbe\u7f6e\u4e0b\uff0cSC \u5728\u6240\u6709\u4e5d\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6821\u51c6\u65b9\u6cd5\u3002", "conclusion": "Supervised Calibration (SC) \u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3 ICL \u4e2d\u7684\u7cfb\u7edf\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u4e14\u66f4\u5177\u8868\u8fbe\u80fd\u529b\u7684\u6821\u51c6\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2505.23869", "pdf": "https://arxiv.org/pdf/2505.23869", "abs": "https://arxiv.org/abs/2505.23869", "authors": ["M. S\u00fczen"], "title": "Gibbs randomness-compression proposition: An efficient deep learning", "categories": ["stat.ML", "cs.LG"], "comment": "5 pages, 5 figures", "summary": "A proposition that connects randomness and compression put forward via Gibbs\nentropy over set of measurement vectors associated with a compression process.\nThe proposition states that a lossy compression process is equivalent to {\\it\ndirected randomness} that preserves information content. The proposition\noriginated from the observed behaviour in newly proposed {\\it Dual Tomographic\nCompression} (DTC) compress-train framework. This is akin to tomographic\nreconstruction of layer weight matrices via building compressed sensed\nprojections, so called {\\it weight rays}. This tomographic approach is applied\nto previous and next layers in a dual fashion, that triggers neuronal-level\npruning. This novel model compress-train scheme appear in iterative fashion and\nact as smart neural architecture search, Experiments demonstrated utility of\nthis dual-tomography producing state-of-the-art performance with efficient\ncompression during training, accelerating and supporting lottery ticket\nhypothesis. However, random compress-train iterations having similar\nperformance demonstrated the connection between randomness and compression from\nstatistical physics perspective, we formulated so called {\\it Gibbs\nrandomness-compression proposition}, signifying randomness-compression\nrelationship via Gibbs entropy. Practically, DTC framework provides a promising\napproach for massively energy and resource efficient deep learning training\napproach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eGibbs\u71b5\u7684\u968f\u673a\u6027\u4e0e\u538b\u7f29\u5173\u7cfb\u7406\u8bba\uff0c\u5e76\u901a\u8fc7\u65b0\u7684Dual Tomographic Compression (DTC) \u6846\u67b6\u5728\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29\u4e0e\u9ad8\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u4f5c\u8005\u8bd5\u56fe\u63ed\u793a\u968f\u673a\u6027\u548c\u538b\u7f29\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u8282\u80fd\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u538b\u7f29\u4e0e\u8bad\u7ec3\u65b9\u6cd5\u3002\u53d7\u5f69\u7968\u5047\u8bbe\u542f\u53d1\uff0c\u4ed6\u4eec\u5e0c\u671b\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u5b9e\u73b0\u667a\u80fd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u641c\u7d22\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u201cDual Tomographic Compression (DTC) \u538b\u7f29-\u8bad\u7ec3\u6846\u67b6\u201d\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u538b\u7f29\u611f\u77e5\u6295\u5f71\uff08\u79f0\u4e3a\u6743\u91cd\u5c04\u7ebf\uff09\u8fdb\u884c\u5c42\u6743\u91cd\u77e9\u9635\u7684\u65ad\u5c42\u91cd\u5efa\uff0c\u5e76\u4ee5\u53cc\u6a21\u5f0f\u5e94\u7528\u4e8e\u524d\u4e00\u5c42\u548c\u4e0b\u4e00\u5c42\uff0c\u4ece\u800c\u89e6\u53d1\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u526a\u679d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDTC\u6846\u67b6\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u538b\u7f29\u5e76\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff1b\u540c\u65f6\uff0c\u4ece\u7edf\u8ba1\u7269\u7406\u7684\u89d2\u5ea6\u89c2\u5bdf\u5230\u968f\u673a\u538b\u7f29\u8fed\u4ee3\u5177\u6709\u76f8\u4f3c\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u968f\u673a\u6027\u4e0e\u538b\u7f29\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cGibbs randomness-compression proposition\u201d\u7684\u65b0\u547d\u9898\uff0c\u901a\u8fc7Gibbs\u71b5\u5c06\u968f\u673a\u6027\u548c\u538b\u7f29\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u8868\u660eDTC\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u4e00\u79cd\u5927\u89c4\u6a21\u8282\u80fd\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2505.24038", "pdf": "https://arxiv.org/pdf/2505.24038", "abs": "https://arxiv.org/abs/2505.24038", "authors": ["L\u00e9o And\u00e9ol", "Luca Mossina", "Adrien Mazoyer", "S\u00e9bastien Gerchinovitz"], "title": "Conformal Object Detection by Sequential Risk Control", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": "28 pages, 11 figures", "summary": "Recent advances in object detectors have led to their adoption for industrial\nuses. However, their deployment in critical applications is hindered by the\ninherent lack of reliability of neural networks and the complex structure of\nobject detection models. To address these challenges, we turn to Conformal\nPrediction, a post-hoc procedure which offers statistical guarantees that are\nvalid for any dataset size, without requiring prior knowledge on the model or\ndata distribution. Our contribution is manifold: first, we formally define the\nproblem of Conformal Object Detection (COD) and introduce a novel method,\nSequential Conformal Risk Control (SeqCRC), that extends the statistical\nguarantees of Conformal Risk Control (CRC) to two sequential tasks with two\nparameters, as required in the COD setting. Then, we propose loss functions and\nprediction sets suited to applying CRC to different applications and\ncertification requirements. Finally, we present a conformal toolkit, enabling\nreplication and further exploration of our methods. Using this toolkit, we\nperform extensive experiments, yielding a benchmark that validates the\ninvestigated methods and emphasizes trade-offs and other practical\nconsequences.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86Conformal Prediction\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5SeqCRC\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5173\u5de5\u5177\u5305\u4ee5\u589e\u5f3a\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u5728\u5173\u952e\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u53d7\u5230\u795e\u7ecf\u7f51\u7edc\u56fa\u6709\u4e0d\u53ef\u9760\u6027\u548c\u6a21\u578b\u7ed3\u6784\u590d\u6742\u6027\u7684\u963b\u788d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u9760\u7684\u540e\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5Sequential Conformal Risk Control (SeqCRC)\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9002\u7528\u4e8e\u4e0d\u540c\u5e94\u7528\u573a\u666f\u548c\u8ba4\u8bc1\u9700\u6c42\u7684\u635f\u5931\u51fd\u6570\u4e0e\u9884\u6d4b\u96c6\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u51c6\uff0c\u9a8c\u8bc1\u4e86\u6240\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u6743\u8861\u548c\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0cSeqCRC\u65b9\u6cd5\u548c\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u4e0e\u9884\u6d4b\u96c6\u80fd\u591f\u6709\u6548\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u5e76\u901a\u8fc7\u5de5\u5177\u5305\u4fc3\u8fdb\u4e86\u65b9\u6cd5\u7684\u590d\u73b0\u4e0e\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2505.24097", "pdf": "https://arxiv.org/pdf/2505.24097", "abs": "https://arxiv.org/abs/2505.24097", "authors": ["Victor Li", "Baiting Chen", "Yuzhen Mao", "Qi Lei", "Zhun Deng"], "title": "Performative Risk Control: Calibrating Models for Reliable Deployment under Performativity", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Calibrating blackbox machine learning models to achieve risk control is\ncrucial to ensure reliable decision-making. A rich line of literature has been\nstudying how to calibrate a model so that its predictions satisfy explicit\nfinite-sample statistical guarantees under a fixed, static, and unknown\ndata-generating distribution. However, prediction-supported decisions may\ninfluence the outcome they aim to predict, a phenomenon named performativity of\npredictions, which is commonly seen in social science and economics. In this\npaper, we introduce Performative Risk Control, a framework to calibrate models\nto achieve risk control under performativity with provable theoretical\nguarantees. Specifically, we provide an iteratively refined calibration\nprocess, where we ensure the predictions are improved and risk-controlled\nthroughout the process. We also study different types of risk measures and\nchoices of tail bounds. Lastly, we demonstrate the effectiveness of our\nframework by numerical experiments on the task of predicting credit default\nrisk. To the best of our knowledge, this work is the first one to study\nstatistically rigorous risk control under performativity, which will serve as\nan important safeguard against a wide range of strategic manipulation in\ndecision-making processes.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86Performative Risk Control\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6821\u51c6\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\u5904\u7406\u9884\u6d4b\u5f71\u54cd\u5b9e\u9645\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u51b3\u7b56\u53ef\u9760\u3002", "motivation": "\u786e\u4fdd\u9ed1\u7bb1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u6ee1\u8db3\u6709\u9650\u6837\u672c\u7684\u7edf\u8ba1\u4fdd\u8bc1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9884\u6d4b\u672c\u8eab\u53ef\u80fd\u5f71\u54cd\u5176\u8bd5\u56fe\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u8fd9\u79cd\u73b0\u8c61\u5728\u793e\u4f1a\u79d1\u5b66\u548c\u7ecf\u6d4e\u5b66\u4e2d\u5f88\u5e38\u89c1\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u4ecb\u7ecd\u4e86\u4e00\u79cd\u8fed\u4ee3\u4f18\u5316\u7684\u6821\u51c6\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u5728\u9884\u6d4b\u7ed3\u679c\u5f71\u54cd\u5b9e\u9645\u60c5\u51b5\u7684\u524d\u63d0\u4e0b\u6301\u7eed\u6539\u8fdb\u9884\u6d4b\u5e76\u8fdb\u884c\u98ce\u9669\u63a7\u5236\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u969c\u7684\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u98ce\u9669\u5ea6\u91cf\u548c\u5c3e\u90e8\u8fb9\u754c\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u901a\u8fc7\u4fe1\u7528\u8fdd\u7ea6\u98ce\u9669\u9884\u6d4b\u4efb\u52a1\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u5f97\u51fa\u7684\u7ed3\u8bba\u662f\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86Performative Risk Control\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u5728\u9884\u6d4b\u7ed3\u679c\u4f1a\u5f71\u54cd\u5b9e\u9645\u7ed3\u679c\uff08performativity\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u7edf\u8ba1\u4e0a\u4e25\u683c\u98ce\u9669\u63a7\u5236\u7684\u7814\u7a76\u3002"}}
{"id": "2505.23857", "pdf": "https://arxiv.org/pdf/2505.23857", "abs": "https://arxiv.org/abs/2505.23857", "authors": ["Wuhao Wang", "Zhiyong Chen"], "title": "DATD3: Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient For Model Free Reinforcement Learning Under Output Feedback Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning in real-world applications often involves\noutput-feedback settings, where the agent receives only partial state\ninformation. To address this challenge, we propose the Output-Feedback Markov\nDecision Process (OPMDP), which extends the standard MDP formulation to\naccommodate decision-making based on observation histories. Building on this\nframework, we introduce Depthwise Attention Twin Delayed Deep Deterministic\nPolicy Gradient (DATD3), a novel actor-critic algorithm that employs depthwise\nseparable convolution and multi-head attention to encode historical\nobservations. DATD3 maintains policy expressiveness while avoiding the\ninstability of recurrent models. Extensive experiments on continuous control\ntasks demonstrate that DATD3 outperforms existing memory-based and recurrent\nbaselines under both partial and full observability.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDATD3\u7684\u65b0\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u7ecf\u5e38\u6d89\u53ca\u8f93\u51fa\u53cd\u9988\u8bbe\u7f6e\uff0c\u4ee3\u7406\u53ea\u80fd\u63a5\u6536\u90e8\u5206\u72b6\u6001\u4fe1\u606f\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Output-Feedback Markov Decision Process (OPMDP)\u6846\u67b6\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f15\u5165\u4e86Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient (DATD3)\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0cDATD3\u5728\u90e8\u5206\u548c\u5b8c\u5168\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u548c\u9012\u5f52\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5DATD3\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u8bb0\u5fc6\u578b\u548c\u9012\u5f52\u57fa\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2505.23881", "pdf": "https://arxiv.org/pdf/2505.23881", "abs": "https://arxiv.org/abs/2505.23881", "authors": ["Christopher D. Rosin"], "title": "Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems", "categories": ["cs.AI", "cs.CL", "math.CO"], "comment": "arXiv admin note: text overlap with arXiv:2501.17725", "summary": "Large Language Models (LLMs) with reasoning are trained to iteratively\ngenerate and refine their answers before finalizing them, which can help with\napplications to mathematics and code generation. We apply code generation with\nreasoning LLMs to a specific task in the mathematical field of combinatorial\ndesign. This field studies diverse types of combinatorial designs, many of\nwhich have lists of open instances for which existence has not yet been\ndetermined. The Constructive Protocol CPro1 uses LLMs to generate search\nheuristics that have the potential to construct solutions to small open\ninstances. Starting with a textual definition and a validity verifier for a\nparticular type of design, CPro1 guides LLMs to select and implement\nstrategies, while providing automated hyperparameter tuning and execution\nfeedback. CPro1 with reasoning LLMs successfully solves long-standing open\ninstances for 7 of 16 combinatorial design problems selected from the 2006\nHandbook of Combinatorial Designs, including new solved instances for 3 of\nthese (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary\nDesigns) that were unsolved by CPro1 with non-reasoning LLMs. It also solves\nopen instances for several problems from recent (2025) literature, generating\nnew Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform\nNested Steiner Quadruple System.", "AI": {"tldr": "CPro1\u7ed3\u5408\u63a8\u7406LLMs\u89e3\u51b3\u4e86\u591a\u4e2a\u957f\u671f\u672a\u89e3\u7684\u7ec4\u5408\u8bbe\u8ba1\u95ee\u9898\uff0c\u5e76\u751f\u6210\u4e86\u65b0\u89e3\u3002", "motivation": "\u8bb8\u591a\u7ec4\u5408\u8bbe\u8ba1\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u6784\u9020\u5c0f\u5f00\u653e\u5b9e\u4f8b\u7684\u89e3\u3002", "method": "\u4ece\u6587\u672c\u5b9a\u4e49\u548c\u6709\u6548\u6027\u9a8c\u8bc1\u5668\u51fa\u53d1\uff0c\u901a\u8fc7\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\u548c\u6267\u884c\u53cd\u9988\u6307\u5bfcLLMs\u9009\u62e9\u5e76\u5b9e\u73b0\u7b56\u7565\u3002", "result": "\u89e3\u51b3\u4e8616\u4e2a\u7ec4\u5408\u8bbe\u8ba1\u95ee\u9898\u4e2d\u76847\u4e2a\u957f\u671f\u672a\u89e3\u5b9e\u4f8b\uff0c\u5e76\u751f\u6210\u4e86\u591a\u4e2a\u65b0\u89e3\u3002", "conclusion": "CPro1\u5229\u7528\u63a8\u7406LLMs\u6210\u529f\u89e3\u51b3\u4e86\u4e00\u4e9b\u957f\u671f\u672a\u89e3\u7684\u7ec4\u5408\u8bbe\u8ba1\u95ee\u9898\uff0c\u5e76\u751f\u6210\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.24134", "pdf": "https://arxiv.org/pdf/2505.24134", "abs": "https://arxiv.org/abs/2505.24134", "authors": ["Ricardo Baptista", "Andrew M. Stuart", "Son Tran"], "title": "A Mathematical Perspective On Contrastive Learning", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": "44 pages, 15 figures", "summary": "Multimodal contrastive learning is a methodology for linking different data\nmodalities; the canonical example is linking image and text data. The\nmethodology is typically framed as the identification of a set of encoders, one\nfor each modality, that align representations within a common latent space. In\nthis work, we focus on the bimodal setting and interpret contrastive learning\nas the optimization of (parameterized) encoders that define conditional\nprobability distributions, for each modality conditioned on the other,\nconsistent with the available data. This provides a framework for multimodal\nalgorithms such as crossmodal retrieval, which identifies the mode of one of\nthese conditional distributions, and crossmodal classification, which is\nsimilar to retrieval but includes a fine-tuning step to make it task specific.\n  The framework we adopt also gives rise to crossmodal generative models. This\nprobabilistic perspective suggests two natural generalizations of contrastive\nlearning: the introduction of novel probabilistic loss functions, and the use\nof alternative metrics for measuring alignment in the common latent space. We\nstudy these generalizations of the classical approach in the multivariate\nGaussian setting. In this context we view the latent space identification as a\nlow-rank matrix approximation problem. This allows us to characterize the\ncapabilities of loss functions and alignment metrics to approximate natural\nstatistics, such as conditional means and covariances; doing so yields novel\nvariants on contrastive learning algorithms for specific mode-seeking and for\ngenerative tasks. The framework we introduce is also studied through numerical\nexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a data\nassimilation application arising in oceanography.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5c06\u5176\u89e3\u91ca\u4e3a\u4f18\u5316\u53c2\u6570\u5316\u7f16\u7801\u5668\u4ee5\u5b9a\u4e49\u6761\u4ef6\u6982\u7387\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u4e86\u8de8\u6a21\u6001\u751f\u6210\u6a21\u578b\u53ca\u65b0\u7684\u5bf9\u6bd4\u5b66\u4e60\u6cdb\u5316\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u901a\u5e38\u7528\u4e8e\u8fde\u63a5\u4e0d\u540c\u6570\u636e\u6a21\u6001\uff08\u5982\u56fe\u50cf\u548c\u6587\u672c\uff09\uff0c\u4f46\u5176\u7406\u8bba\u6846\u67b6\u4ecd\u6709\u5f85\u6269\u5c55\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u6a21\u578b\u548c\u6982\u7387\u635f\u5931\u51fd\u6570\u65b9\u9762\u3002", "method": "\u4f5c\u8005\u4ece\u6982\u7387\u89d2\u5ea6\u51fa\u53d1\uff0c\u5c06\u5bf9\u6bd4\u5b66\u4e60\u89c6\u4e3a\u4f18\u5316\u5b9a\u4e49\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u7f16\u7801\u5668\u95ee\u9898\uff0c\u5e76\u5728\u591a\u5143\u9ad8\u65af\u73af\u5883\u4e2d\u7814\u7a76\u6f5c\u5728\u7a7a\u95f4\u8bc6\u522b\u4f5c\u4e3a\u4f4e\u79e9\u77e9\u9635\u8fd1\u4f3c\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\u65b0\u7684\u6982\u7387\u635f\u5931\u51fd\u6570\u3001\u5bf9\u9f50\u5ea6\u91cf\u4ee5\u53ca\u9002\u7528\u4e8e\u7279\u5b9a\u4efb\u52a1\u7684\u751f\u6210\u6a21\u578b\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u6982\u7387\u89c6\u89d2\u548c\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u68c0\u7d22\u3001\u5206\u7c7b\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.23859", "pdf": "https://arxiv.org/pdf/2505.23859", "abs": "https://arxiv.org/abs/2505.23859", "authors": ["Wenju Sun", "Qingyong Li", "Wen Wang", "Yang Liu", "Yangli-ao Geng", "Boyang Li"], "title": "Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task model merging aims to consolidate knowledge from multiple\nfine-tuned task-specific experts into a unified model while minimizing\nperformance degradation. Existing methods primarily approach this by minimizing\ndifferences between task-specific experts and the unified model, either from a\nparameter-level or a task-loss perspective. However, parameter-level methods\nexhibit a significant performance gap compared to the upper bound, while\ntask-loss approaches entail costly secondary training procedures. In contrast,\nwe observe that performance degradation closely correlates with feature drift,\ni.e., differences in feature representations of the same sample caused by model\nmerging. Motivated by this observation, we propose Layer-wise Optimal Task\nVector Merging (LOT Merging), a technique that explicitly minimizes feature\ndrift between task-specific experts and the unified model in a layer-by-layer\nmanner. LOT Merging can be formulated as a convex quadratic optimization\nproblem, enabling us to analytically derive closed-form solutions for the\nparameters of linear and normalization layers. Consequently, LOT Merging\nachieves efficient model consolidation through basic matrix operations.\nExtensive experiments across vision and vision-language benchmarks demonstrate\nthat LOT Merging significantly outperforms baseline methods, achieving\nimprovements of up to 4.4% (ViT-B/32) over state-of-the-art approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u65b9\u6cd5LOT Merging\uff0c\u901a\u8fc7\u9010\u5c42\u6700\u5c0f\u5316\u7279\u5f81\u6f02\u79fb\uff0c\u5728\u51cf\u5c11\u6027\u80fd\u635f\u5931\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u5408\u5e76\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u5728\u53c2\u6570\u7ea7\u522b\u6216\u4efb\u52a1\u635f\u5931\u7ea7\u522b\u4e0a\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u4f5c\u8005\u53d1\u73b0\u6027\u80fd\u4e0b\u964d\u4e0e\u7279\u5f81\u6f02\u79fb\u5bc6\u5207\u76f8\u5173\uff0c\u4ece\u800c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLayer-wise Optimal Task Vector Merging (LOT Merging)\uff0c\u4e00\u79cd\u901a\u8fc7\u9010\u5c42\u6700\u5c0f\u5316\u4efb\u52a1\u7279\u5b9a\u4e13\u5bb6\u6a21\u578b\u4e0e\u7edf\u4e00\u6a21\u578b\u4e4b\u95f4\u7279\u5f81\u6f02\u79fb\u6765\u5b9e\u73b0\u6a21\u578b\u5408\u5e76\u7684\u65b9\u6cd5\u3002", "result": "LOT Merging \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e86\u9ad8\u8fbe4.4%\uff08ViT-B/32\uff09\uff0c\u4e14\u65e0\u9700\u6602\u8d35\u7684\u4e8c\u6b21\u8bad\u7ec3\u8fc7\u7a0b\u3002", "conclusion": "LOT Merging\u901a\u8fc7\u9010\u5c42\u6700\u5c0f\u5316\u7279\u5f81\u6f02\u79fb\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u6a21\u578b\u5408\u5e76\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u635f\u5931\uff0c\u5e76\u5728\u591a\u4e2a\u89c6\u89c9\u548c\u89c6\u89c9-\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.23885", "pdf": "https://arxiv.org/pdf/2505.23885", "abs": "https://arxiv.org/abs/2505.23885", "authors": ["Mengkang Hu", "Yuhang Zhou", "Wendong Fan", "Yuzhou Nie", "Bowei Xia", "Tao Sun", "Ziyu Ye", "Zhaoxuan Jin", "Yingru Li", "Qiguang Chen", "Zeyu Zhang", "Yifeng Wang", "Qianshuo Ye", "Bernard Ghanem", "Ping Luo", "Guohao Li"], "title": "OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation", "categories": ["cs.AI", "cs.CL"], "comment": "Project Page: https://github.com/camel-ai/owl", "summary": "Large Language Model (LLM)-based multi-agent systems show promise for\nautomating real-world tasks but struggle to transfer across domains due to\ntheir domain-specific nature. Current approaches face two critical\nshortcomings: they require complete architectural redesign and full retraining\nof all components when applied to new domains. We introduce Workforce, a\nhierarchical multi-agent framework that decouples strategic planning from\nspecialized execution through a modular architecture comprising: (i) a\ndomain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask\nmanagement, and (iii) specialized Workers with domain-specific tool-calling\ncapabilities. This decoupling enables cross-domain transferability during both\ninference and training phases: During inference, Workforce seamlessly adapts to\nnew domains by adding or modifying worker agents; For training, we introduce\nOptimized Workforce Learning (OWL), which improves generalization across\ndomains by optimizing a domain-agnostic planner with reinforcement learning\nfrom real-world feedback. To validate our approach, we evaluate Workforce on\nthe GAIA benchmark, covering various realistic, multi-domain agentic tasks.\nExperimental results demonstrate Workforce achieves open-source\nstate-of-the-art performance (69.70%), outperforming commercial systems like\nOpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model\nachieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to\nGPT-4o on challenging tasks. To summarize, by enabling scalable generalization\nand modular domain transfer, our work establishes a foundation for the next\ngeneration of general-purpose AI assistants.", "AI": {"tldr": "Workforce\u662f\u4e00\u79cd\u652f\u6301\u8de8\u9886\u57df\u8fc1\u79fb\u7684\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408OWL\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8de8\u9886\u57df\u8fc1\u79fb\u65f6\u9762\u4e34\u67b6\u6784\u91cd\u65b0\u8bbe\u8ba1\u548c\u5b8c\u5168\u91cd\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "Workforce\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u9886\u57df\u65e0\u5173\u7684Planner\u3001\u5b50\u4efb\u52a1\u7ba1\u7406\u7684Coordinator\u548c\u5177\u6709\u7279\u5b9a\u529f\u80fd\u7684Workers\uff0c\u5e76\u5f15\u5165\u4e86OWL\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "Workforce\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523069.70%\u7684\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u5546\u4e1a\u7cfb\u7edfOpenAI Deep Research 2.34%\uff0c\u5e76\u4e14\u4f7f\u7528OWL\u8bad\u7ec3\u768432B\u6a21\u578b\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1GPT-4o\u3002", "conclusion": "Workforce\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u4f18\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u7684\u53ef\u6269\u5c55\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u901a\u7528AI\u52a9\u624b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24281", "pdf": "https://arxiv.org/pdf/2505.24281", "abs": "https://arxiv.org/abs/2505.24281", "authors": ["Yang Sui", "Qi Xu", "Yang Bai", "Annie Qu"], "title": "Multi-task Learning for Heterogeneous Data via Integrating Shared and Task-Specific Encodings", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Multi-task learning (MTL) has become an essential machine learning tool for\naddressing multiple learning tasks simultaneously and has been effectively\napplied across fields such as healthcare, marketing, and biomedical research.\nHowever, to enable efficient information sharing across tasks, it is crucial to\nleverage both shared and heterogeneous information. Despite extensive research\non MTL, various forms of heterogeneity, including distribution and posterior\nheterogeneity, present significant challenges. Existing methods often fail to\naddress these forms of heterogeneity within a unified framework. In this paper,\nwe propose a dual-encoder framework to construct a heterogeneous latent factor\nspace for each task, incorporating a task-shared encoder to capture common\ninformation across tasks and a task-specific encoder to preserve unique task\ncharacteristics. Additionally, we explore the intrinsic similarity structure of\nthe coefficients corresponding to learned latent factors, allowing for adaptive\nintegration across tasks to manage posterior heterogeneity. We introduce a\nunified algorithm that alternately learns the task-specific and task-shared\nencoders and coefficients. In theory, we investigate the excess risk bound for\nthe proposed MTL method using local Rademacher complexity and apply it to a new\nbut related task. Through simulation studies, we demonstrate that the proposed\nmethod outperforms existing data integration methods across various settings.\nFurthermore, the proposed method achieves superior predictive performance for\ntime to tumor doubling across five distinct cancer types in PDX data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u4efb\u52a1\u95f4\u7684\u5171\u4eab\u4e0e\u5f02\u8d28\u4fe1\u606f\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u9700\u8981\u6709\u6548\u5229\u7528\u5171\u4eab\u548c\u5f02\u8d28\u4fe1\u606f\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u89e3\u51b3\u5f02\u8d28\u6027\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4efb\u52a1\u5171\u4eab\u7f16\u7801\u5668\u548c\u4efb\u52a1\u7279\u5b9a\u7f16\u7801\u5668\uff0c\u5e76\u63a2\u7d22\u4e86\u6f5c\u5728\u56e0\u5b50\u7cfb\u6570\u7684\u5185\u5728\u76f8\u4f3c\u6027\u7ed3\u6784\uff0c\u4ee5\u7edf\u4e00\u7b97\u6cd5\u4ea4\u66ff\u5b66\u4e60\u7f16\u7801\u5668\u548c\u7cfb\u6570\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u8fc7\u91cf\u98ce\u9669\u754c\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548cPDX\u6570\u636e\u4e2d\u7684\u80bf\u7624\u500d\u589e\u65f6\u95f4\u9884\u6d4b\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u7f16\u7801\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u5f02\u8d28\u6027\u6f5c\u5728\u56e0\u5b50\u7a7a\u95f4\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5904\u7406\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u5171\u4eab\u548c\u7279\u5f02\u6027\u4fe1\u606f\u3002"}}
{"id": "2505.23861", "pdf": "https://arxiv.org/pdf/2505.23861", "abs": "https://arxiv.org/abs/2505.23861", "authors": ["Renye Zhang", "Mengyun Yang", "Qichang Zhao", "Jianxin Wang"], "title": "BiBLDR: Bidirectional Behavior Learning for Drug Repositioning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Drug repositioning aims to identify potential new indications for existing\ndrugs to reduce the time and financial costs associated with developing new\ndrugs. Most existing deep learning-based drug repositioning methods\npredominantly utilize graph-based representations. However, graph-based drug\nrepositioning methods struggle to perform effective inference in cold-start\nscenarios involving novel drugs because of the lack of association information\nwith the diseases. Unlike traditional graph-based approaches, we propose a\nbidirectional behavior learning strategy for drug repositioning, known as\nBiBLDR. This innovative framework redefines drug repositioning as a behavior\nsequential learning task to capture drug-disease interaction patterns. First,\nwe construct bidirectional behavioral sequences based on drug and disease\nsides. The consideration of bidirectional information ensures a more meticulous\nand rigorous characterization of the behavioral sequences. Subsequently, we\npropose a two-stage strategy for drug repositioning. In the first stage, we\nconstruct prototype spaces to characterize the representational attributes of\ndrugs and diseases. In the second stage, these refined prototypes and\nbidirectional behavior sequence data are leveraged to predict potential\ndrug-disease associations. Based on this learning approach, the model can more\nrobustly and precisely capture the interactive relationships between drug and\ndisease features from bidirectional behavioral sequences. Extensive experiments\ndemonstrate that our method achieves state-of-the-art performance on benchmark\ndatasets. Meanwhile, BiBLDR demonstrates significantly superior performance\ncompared to previous methods in cold-start scenarios. Our code is published in\nhttps://github.com/Renyeeah/BiBLDR.", "AI": {"tldr": "BiBLDR\u662f\u4e00\u79cd\u521b\u65b0\u6027\u7684\u836f\u7269\u91cd\u5b9a\u4f4d\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u53cc\u5411\u884c\u4e3a\u5b66\u4e60\u7b56\u7565\u6765\u63d0\u5347\u836f\u7269\u4e0e\u75be\u75c5\u4e4b\u95f4\u4ea4\u4e92\u5173\u7cfb\u7684\u9884\u6d4b\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684\u836f\u7269\u91cd\u5b9a\u4f4d\u65b9\u6cd5\u5728\u9762\u5bf9\u65b0\u836f\u65f6\u96be\u4ee5\u8fdb\u884c\u6709\u6548\u63a8\u65ad\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u4e0e\u75be\u75c5\u7684\u5173\u8054\u4fe1\u606f\u3002\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u9ad8\u836f\u7269\u91cd\u5b9a\u4f4d\u7684\u6548\u679c\u3002", "method": "BiBLDR\u5c06\u836f\u7269\u91cd\u5b9a\u4f4d\u91cd\u65b0\u5b9a\u4e49\u4e3a\u884c\u4e3a\u5e8f\u5217\u5b66\u4e60\u4efb\u52a1\uff0c\u4ee5\u6355\u6349\u836f\u7269-\u75be\u75c5\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\u3002\u9996\u5148\u57fa\u4e8e\u836f\u7269\u548c\u75be\u75c5\u65b9\u9762\u6784\u5efa\u53cc\u5411\u884c\u4e3a\u5e8f\u5217\uff1b\u968f\u540e\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\u8fdb\u884c\u836f\u7269\u91cd\u5b9a\u4f4d\uff1a\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u539f\u578b\u7a7a\u95f4\u6765\u8868\u5f81\u836f\u7269\u548c\u75be\u75c5\u7684\u8868\u793a\u5c5e\u6027\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u8fd9\u4e9b\u4f18\u5316\u7684\u539f\u578b\u548c\u53cc\u5411\u884c\u4e3a\u5e8f\u5217\u6570\u636e\u9884\u6d4b\u6f5c\u5728\u7684\u836f\u7269-\u75be\u75c5\u5173\u8054\u3002", "result": "BiBLDR\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u8868\u73b0\u4e5f\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "BiBLDR\u901a\u8fc7\u53cc\u5411\u884c\u4e3a\u5b66\u4e60\u7b56\u7565\uff0c\u80fd\u591f\u66f4\u7a33\u5065\u548c\u7cbe\u786e\u5730\u4ece\u53cc\u5411\u884c\u4e3a\u5e8f\u5217\u4e2d\u6355\u6349\u836f\u7269\u4e0e\u75be\u75c5\u7684\u4ea4\u4e92\u5173\u7cfb\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u660e\u663e\u4f18\u4e8e\u4ee5\u5f80\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.23946", "pdf": "https://arxiv.org/pdf/2505.23946", "abs": "https://arxiv.org/abs/2505.23946", "authors": ["Yuanzhe Liu", "Ryan Deng", "Tim Kaler", "Xuhao Chen", "Charles E. Leiserson", "Yao Ma", "Jie Chen"], "title": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SE"], "comment": null, "summary": "Recent studies show that LLMs possess different skills and specialize in\ndifferent tasks. In fact, we observe that their varied performance occur in\nseveral levels of granularity. For example, in the code optimization task, code\nLLMs excel at different optimization categories and no one dominates others.\nThis observation prompts the question of how one leverages multiple LLM agents\nto solve a coding problem without knowing their complementary strengths a\npriori. We argue that a team of agents can learn from each other's successes\nand failures so as to improve their own performance. Thus, a lesson is the\nknowledge produced by an agent and passed on to other agents in the collective\nsolution process. We propose a lesson-based collaboration framework, design the\nlesson solicitation--banking--selection mechanism, and demonstrate that a team\nof small LLMs with lessons learned can outperform a much larger LLM and other\nmulti-LLM collaboration methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6559\u8bad\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5c0f\u578bLLM\u4ee3\u7406\u901a\u8fc7\u76f8\u4e92\u5b66\u4e60\u6765\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\uff0c\u4f18\u4e8e\u5927\u578bLLM\u548c\u5176\u4ed6\u591aLLM\u534f\u4f5c\u65b9\u6cd5\u3002", "motivation": "\u89c2\u5bdf\u5230\u4e0d\u540cLLM\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u4f18\u5316\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u4e13\u957f\uff0c\u6ca1\u6709\u4e00\u4e2a\u6a21\u578b\u5168\u9762\u5360\u4f18\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u672a\u77e5\u4e92\u8865\u4f18\u52bf\u524d\u63d0\u4e0b\u7684\u534f\u4f5c\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6559\u8bad\u5f81\u96c6-\u5b58\u50a8-\u9009\u62e9\u673a\u5236\uff0c\u8ba9LLM\u4ee3\u7406\u4ece\u5f7c\u6b64\u7684\u6210\u529f\u4e0e\u5931\u8d25\u4e2d\u5b66\u4e60\u5e76\u6539\u8fdb\u81ea\u8eab\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u8be5\u6846\u67b6\u534f\u4f5c\u7684\u5c0f\u578bLLM\u56e2\u961f\u5728\u7f16\u7801\u95ee\u9898\u89e3\u51b3\u4e0a\u4f18\u4e8e\u5355\u4e00\u66f4\u5927\u7684LLM\u53ca\u5176\u5b83\u591aLLM\u534f\u4f5c\u65b9\u5f0f\u3002", "conclusion": "\u57fa\u4e8e\u6559\u8bad\u7684\u534f\u4f5c\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u4e2a\u5c0f\u578bLLM\u7684\u6574\u4f53\u6027\u80fd\uff0c\u800c\u65e0\u9700\u9884\u5148\u4e86\u89e3\u5b83\u4eec\u7684\u4f18\u52bf\u9886\u57df\u3002"}}
{"id": "2505.24311", "pdf": "https://arxiv.org/pdf/2505.24311", "abs": "https://arxiv.org/abs/2505.24311", "authors": ["Yi Gu"], "title": "Equilibrium Distribution for t-Distributed Stochastic Neighbor Embedding with Generalized Kernels", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH", "60"], "comment": null, "summary": "T-distributed stochastic neighbor embedding (t-SNE) is a well-known algorithm\nfor visualizing high-dimensional data by finding low-dimensional\nrepresentations. In this paper, we study the convergence of t-SNE with\ngeneralized kernels and extend the results of Auffinger and Fletcher in 2023.\nOur work starts by giving a concrete formulation of generalized input and\noutput kernels. Then we prove that under certain conditions, the t-SNE\nalgorithm converges to an equilibrium distribution for a wide range of input\nand output kernels as the number of data points diverges.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86t-SNE\u7b97\u6cd5\u5728\u5e7f\u4e49\u6838\u4e0b\u7684\u6536\u655b\u6027\uff0c\u8bc1\u660e\u5176\u5728\u6570\u636e\u70b9\u6570\u91cf\u589e\u52a0\u65f6\u4ecd\u80fd\u6536\u655b\u5230\u5e73\u8861\u5206\u5e03\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3t-SNE\u7b97\u6cd5\u5728\u4e0d\u540c\u6838\u51fd\u6570\u4e0b\u7684\u884c\u4e3a\u548c\u6536\u655b\u6027\u3002", "method": "\u901a\u8fc7\u7ed9\u51fa\u5e7f\u4e49\u8f93\u5165\u548c\u8f93\u51fa\u6838\u7684\u5177\u4f53\u5f62\u5f0f\uff0c\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "result": "\u8bba\u6587\u6269\u5c55\u4e86Auffinger\u548cFletcher\u57282023\u5e74\u7684\u7ed3\u679c\uff0c\u8868\u660e\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\uff0c\u5373\u4f7f\u6570\u636e\u70b9\u6570\u91cf\u53d1\u6563\uff0ct-SNE\u7b97\u6cd5\u4ecd\u80fd\u6536\u655b\u5230\u5e73\u8861\u5206\u5e03\u3002", "conclusion": "t-SNE\u7b97\u6cd5\u5728\u5e7f\u4e49\u6838\u4e0b\u4f1a\u6536\u655b\u5230\u4e00\u4e2a\u5e73\u8861\u5206\u5e03\u3002"}}
{"id": "2505.23863", "pdf": "https://arxiv.org/pdf/2505.23863", "abs": "https://arxiv.org/abs/2505.23863", "authors": ["Chang Liu", "Bohao Zhao", "Jingtao Ding", "Huandong Wang", "Yong Li"], "title": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term forecasting of chaotic systems from short-term observations remains\na fundamental and underexplored challenge due to the intrinsic sensitivity to\ninitial conditions and the complex geometry of strange attractors. Existing\napproaches often rely on long-term training data or focus on short-term\nsequence correlations, struggling to maintain predictive stability and\ndynamical coherence over extended horizons. We propose PhyxMamba, a novel\nframework that integrates a Mamba-based state-space model with physics-informed\nprinciples to capture the underlying dynamics of chaotic systems. By\nreconstructing the attractor manifold from brief observations using time-delay\nembeddings, PhyxMamba extracts global dynamical features essential for accurate\nforecasting. Our generative training scheme enables Mamba to replicate the\nphysical process, augmented by multi-token prediction and attractor geometry\nregularization for physical constraints, enhancing prediction accuracy and\npreserving key statistical invariants. Extensive evaluations on diverse\nsimulated and real-world chaotic systems demonstrate that PhyxMamba delivers\nsuperior long-term forecasting and faithfully captures essential dynamical\ninvariants from short-term data. This framework opens new avenues for reliably\npredicting chaotic systems under observation-scarce conditions, with broad\nimplications across climate science, neuroscience, epidemiology, and beyond.\nOur code is open-source at https://github.com/tsinghua-fib-lab/PhyxMamba.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPhyxMamba\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u77ed\u671f\u89c2\u6d4b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5bf9\u6df7\u6c8c\u7cfb\u7edf\u7684\u957f\u671f\u9884\u6d4b\u3002", "motivation": "\u7531\u4e8e\u6df7\u6c8c\u7cfb\u7edf\u5bf9\u521d\u59cb\u6761\u4ef6\u7684\u654f\u611f\u6027\u548c\u5947\u5f02\u5438\u5f15\u5b50\u7684\u590d\u6742\u51e0\u4f55\u7ed3\u6784\uff0c\u4ece\u77ed\u671f\u89c2\u6d4b\u4e2d\u957f\u671f\u9884\u6d4b\u6df7\u6c8c\u7cfb\u7edf\u662f\u4e00\u4e2a\u91cd\u8981\u4e14\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u957f\u5468\u671f\u5185\u4fdd\u6301\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u52a8\u6001\u4e00\u81f4\u6027\u3002", "method": "PhyxMamba\u7ed3\u5408\u4e86\u57fa\u4e8eMamba\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e0e\u7269\u7406\u4fe1\u606f\u539f\u5219\uff0c\u5e76\u5229\u7528\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u91cd\u6784\u5438\u5f15\u5b50\u6d41\u5f62\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u8bad\u7ec3\u65b9\u6848\u8fdb\u884c\u9884\u6d4b\u3002", "result": "PhyxMamba\u5728\u591a\u6837\u5316\u7684\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6df7\u6c8c\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u957f\u671f\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u80fd\u51c6\u786e\u6355\u6349\u5173\u952e\u7684\u52a8\u529b\u5b66\u4e0d\u53d8\u91cf\u3002", "conclusion": "PhyxMamba\u80fd\u591f\u5728\u89c2\u6d4b\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u53ef\u9760\u5730\u9884\u6d4b\u6df7\u6c8c\u7cfb\u7edf\uff0c\u4e3a\u6c14\u5019\u79d1\u5b66\u3001\u795e\u7ecf\u79d1\u5b66\u548c\u6d41\u884c\u75c5\u5b66\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2505.23950", "pdf": "https://arxiv.org/pdf/2505.23950", "abs": "https://arxiv.org/abs/2505.23950", "authors": ["Boyuan Chen", "Donghai Hong", "Jiaming Ji", "Jiacheng Zheng", "Bowen Dong", "Jiayi Zhou", "Kaile Wang", "Juntao Dai", "Xuyao Wang", "Wenqi Chen", "Qirui Zheng", "Wenxin Li", "Sirui Han", "Yike Guo", "Yaodong Yang"], "title": "InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback", "categories": ["cs.AI"], "comment": null, "summary": "As multimodal large models (MLLMs) continue to advance across challenging\ntasks, a key question emerges: What essential capabilities are still missing? A\ncritical aspect of human learning is continuous interaction with the\nenvironment -- not limited to language, but also involving multimodal\nunderstanding and generation. To move closer to human-level intelligence,\nmodels must similarly support multi-turn, multimodal interaction. In\nparticular, they should comprehend interleaved multimodal contexts and respond\ncoherently in ongoing exchanges. In this work, we present an initial\nexploration through the InterMT -- the first preference dataset for multi-turn\nmultimodal interaction, grounded in real human feedback. In this exploration,\nwe particularly emphasize the importance of human oversight, introducing expert\nannotations to guide the process, motivated by the fact that current MLLMs lack\nsuch complex interactive capabilities. InterMT captures human preferences at\nboth global and local levels into nine sub-dimensions, consists of 15.6k\nprompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled\npreference pairs. To compensate for the lack of capability for multi-modal\nunderstanding and generation, we introduce an agentic workflow that leverages\ntool-augmented MLLMs to construct multi-turn QA instances. To further this\ngoal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting\njudges with multi-turn, multimodal tasks. We demonstrate the utility of\n\\InterMT through applications such as judge moderation and further reveal the\nmulti-turn scaling law of judge model. We hope the open-source of our data can\nhelp facilitate further research on aligning current MLLMs to the next step.\nOur project website can be found at https://pku-intermt.github.io .", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u6570\u636e\u96c6InterMT\uff0c\u7528\u4e8e\u63d0\u5347\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u591a\u8f6e\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u7d22\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\u7f3a\u4e4f\u590d\u6742\u7684\u591a\u8f6e\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\uff0c\u9700\u8981\u5411\u4eba\u7c7b\u667a\u80fd\u8fc8\u8fdb\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aInterMT\u7684\u9996\u9009\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u4e13\u5bb6\u6ce8\u91ca\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u6765\u6784\u5efa\u591a\u8f6e\u95ee\u7b54\u5b9e\u4f8b\uff0c\u540c\u65f6\u63d0\u51fa\u4e86InterMT-Bench\u6765\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5f00\u53d1\u4e86InterMT\u6570\u636e\u96c6\uff0c\u5305\u542b15.6k\u63d0\u793a\u300152.6k\u591a\u8f6e\u5bf9\u8bdd\u5b9e\u4f8b\u548c32.4k\u4eba\u5de5\u6807\u6ce8\u504f\u597d\u5bf9\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6cd5\u5b98\u8c03\u89e3\u7b49\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u548c\u6570\u636e\u96c6InterMT\uff0c\u7528\u4e8e\u63a8\u52a8\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u53d1\u5c55\uff0c\u5e76\u671f\u671b\u901a\u8fc7\u5f00\u6e90\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2505.24333", "pdf": "https://arxiv.org/pdf/2505.24333", "abs": "https://arxiv.org/abs/2505.24333", "authors": ["Alessio Giorlandino", "Sebastian Goldt"], "title": "Two failure modes of deep transformers and how to avoid them: a unified theory of signal propagation at initialisation", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "comment": null, "summary": "Finding the right initialisation for neural networks is crucial to ensure\nsmooth training and good performance. In transformers, the wrong initialisation\ncan lead to one of two failure modes of self-attention layers: rank collapse,\nwhere all tokens collapse into similar representations, and entropy collapse,\nwhere highly concentrated attention scores lead to training instability. While\nthe right initialisation has been extensively studied in feed-forward networks,\nan exact description of signal propagation through a full transformer block has\nso far been lacking. Here, we provide an analytical theory of signal\npropagation through vanilla transformer blocks with self-attention layers,\nlayer normalisation, skip connections and ReLU MLP. To treat the self-attention\nlayer, we draw on a formal parallel with the Random Energy Model from\nstatistical physics. We identify and characterise two regimes governed by the\nvariance of the query and key initialisations: a low-variance regime, where we\nrecover the known rank collapse behaviour; and a previously unexplored\nhigh-variance regime, where signal is preserved but \\textit{entropy collapse}\noccurs. In the low-variance regime, we calculate the critical strength for the\nresidual connection to ensure signal propagation. Our theory yields\ntrainability diagrams that identify the correct choice of initialisation\nhyper-parameters for a given architecture. Experiments with BERT-style models\ntrained on TinyStories validate our predictions. Our theoretical framework\ngives a unified perspective on the two failure modes of self-attention and\ngives quantitative predictions on the scale of both weights and residual\nconnections that guarantees smooth training.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790Transformer\u67b6\u6784\u4e2d\u4fe1\u53f7\u4f20\u64ad\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u521d\u59cb\u5316\u4e0d\u5f53\u5bfc\u81f4\u7684\u95ee\u9898\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u627e\u5230\u795e\u7ecf\u7f51\u7edc\u5408\u9002\u7684\u521d\u59cb\u5316\u5bf9\u4e8e\u786e\u4fdd\u8bad\u7ec3\u5e73\u7a33\u548c\u826f\u597d\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5728Transformer\u4e2d\u9519\u8bef\u7684\u521d\u59cb\u5316\u4f1a\u5bfc\u81f4\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\uff1a\u79e9\u5d29\u6e83\u548c\u71b5\u5d29\u6e83\u3002", "method": "\u901a\u8fc7\u501f\u9274\u7edf\u8ba1\u7269\u7406\u5b66\u4e2d\u7684\u968f\u673a\u80fd\u91cf\u6a21\u578b\uff0c\u5bf9\u5305\u542b\u81ea\u6ce8\u610f\u529b\u5c42\u3001\u5c42\u5f52\u4e00\u5316\u3001\u8df3\u8dc3\u8fde\u63a5\u548cReLU MLP\u7684Transformer\u5757\u8fdb\u884c\u89e3\u6790\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u81ea\u6ce8\u610f\u529b\u5c42\u4e2d\u67e5\u8be2\u548c\u952e\u7684\u521d\u59cb\u65b9\u5dee\u6240\u4e3b\u5bfc\u7684\u4e24\u79cd\u72b6\u6001\uff1a\u4f4e\u65b9\u5dee\u72b6\u6001\u4e0b\u4f1a\u51fa\u73b0\u79e9\u5d29\u6e83\uff1b\u9ad8\u65b9\u5dee\u72b6\u6001\u4e0b\u4f1a\u51fa\u73b0\u71b5\u5d29\u6e83\u3002\u540c\u65f6\uff0c\u8ba1\u7b97\u51fa\u4e86\u6b8b\u5dee\u8fde\u63a5\u5f3a\u5ea6\u7684\u4e34\u754c\u503c\u4ee5\u786e\u4fdd\u4fe1\u53f7\u4f20\u64ad\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u4fe1\u53f7\u5728\u666e\u901aTransformer\u5757\u4e2d\u4f20\u64ad\u7684\u7406\u8bba\uff0c\u4e3a\u9009\u62e9\u5408\u9002\u7684\u521d\u59cb\u5316\u8d85\u53c2\u6570\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u7edf\u4e00\u4e86\u5bf9\u81ea\u6ce8\u610f\u529b\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\u7684\u8ba4\u8bc6\u3002"}}
{"id": "2505.23864", "pdf": "https://arxiv.org/pdf/2505.23864", "abs": "https://arxiv.org/abs/2505.23864", "authors": ["Wei Zhuo", "Zhaohuan Zhan", "Ziduo Yang", "Han Yu"], "title": "Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) on graph-structured data typically faces non-IID\nchallenges, particularly in scenarios where each client holds a distinct\nsubgraph sampled from a global graph. In this paper, we introduce Federated\nlearning with Auxiliary projections (FedAux), a personalized subgraph FL\nframework that learns to align, compare, and aggregate heterogeneously\ndistributed local models without sharing raw data or node embeddings. In\nFedAux, each client jointly trains (i) a local GNN and (ii) a learnable\nauxiliary projection vector (APV) that differentiably projects node embeddings\nonto a 1D space. A soft-sorting operation followed by a lightweight 1D\nconvolution refines these embeddings in the ordered space, enabling the APV to\neffectively capture client-specific information. After local training, these\nAPVs serve as compact signatures that the server uses to compute inter-client\nsimilarities and perform similarity-weighted parameter mixing, yielding\npersonalized models while preserving cross-client knowledge transfer. Moreover,\nwe provide rigorous theoretical analysis to establish the convergence and\nrationality of our design. Empirical evaluations across diverse graph\nbenchmarks demonstrate that FedAux substantially outperforms existing baselines\nin both accuracy and personalization performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 FedAux\uff0c\u4e00\u79cd\u57fa\u4e8e\u8f85\u52a9\u6295\u5f71\u5411\u91cf\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u4e2d\u7684\u975e IID \u6311\u6218\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u57fa\u4e8e APV \u76f8\u4f3c\u5ea6\u7684\u53c2\u6570\u6df7\u5408\u7b56\u7565\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8de8\u5ba2\u6237\u7aef\u77e5\u8bc6\u8fc1\u79fb\u4e0e\u4e2a\u6027\u5316\u5efa\u6a21\u3002", "motivation": "\u56fe\u7ed3\u6784\u6570\u636e\u4e0a\u7684\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5404\u5ba2\u6237\u7aef\u6301\u6709\u4e0d\u540c\u5b50\u56fe\u7684\u60c5\u51b5\u4e0b\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa FedAux \u65b9\u6cd5\u4ee5\u5b9e\u73b0\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\u6216\u8282\u70b9\u5d4c\u5165\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u5bf9\u9f50\u3001\u6bd4\u8f83\u548c\u805a\u5408\u5f02\u6784\u5206\u5e03\u7684\u672c\u5730\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a FedAux \u7684\u4e2a\u6027\u5316\u5b50\u56fe\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8f85\u52a9\u6295\u5f71\u5411\u91cf\uff08APV\uff09\u5bf9\u8282\u70b9\u5d4c\u5165\u8fdb\u884c\u4e00\u7ef4\u7a7a\u95f4\u7684\u53ef\u5fae\u6295\u5f71\uff0c\u5e76\u5229\u7528\u8f6f\u6392\u5e8f\u548c\u8f7b\u91cf\u7ea7\u4e00\u7ef4\u5377\u79ef\u4f18\u5316\u5d4c\u5165\uff0c\u5b9e\u73b0\u5ba2\u6237\u7aef\u95f4\u7684\u77e5\u8bc6\u8fc1\u79fb\u4e0e\u4e2a\u6027\u5316\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e FedAux \u663e\u8457\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u56fe\u7ed3\u6784\u6570\u636e\u4e0a\u7684\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u6027\u80fd\uff0c\u540c\u65f6\u5177\u5907\u7406\u8bba\u4e0a\u7684\u6536\u655b\u6027\u4fdd\u969c\u3002", "conclusion": "FedAux \u5728\u591a\u6837\u5316\u7684\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u6027\u80fd\u65b9\u9762\u5747\u6709\u63d0\u5347\u3002"}}
{"id": "2505.23982", "pdf": "https://arxiv.org/pdf/2505.23982", "abs": "https://arxiv.org/abs/2505.23982", "authors": ["Jerry Junyang Cheung", "Shiyao Shen", "Yuchen Zhuang", "Yinghao Li", "Rampi Ramprasad", "Chao Zhang"], "title": "MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge", "categories": ["cs.AI"], "comment": null, "summary": "Despite recent advances in large language models (LLMs) for materials\nscience, there is a lack of benchmarks for evaluating their domain-specific\nknowledge and complex reasoning abilities. To bridge this gap, we introduce\nMSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials\nscience questions in two formats: detailed explanatory responses and binary\nTrue/False assessments. MSQA distinctively challenges LLMs by requiring both\nprecise factual knowledge and multi-step reasoning across seven materials\nscience sub-fields, such as structure-property relationships, synthesis\nprocesses, and computational modeling. Through experiments with 10\nstate-of-the-art LLMs, we identify significant gaps in current LLM performance.\nWhile API-based proprietary LLMs achieve up to 84.5% accuracy, open-source\n(OSS) LLMs peak around 60.5%, and domain-specific LLMs often underperform\nsignificantly due to overfitting and distributional shifts. MSQA represents the\nfirst benchmark to jointly evaluate the factual and reasoning capabilities of\nLLMs crucial for LLMs in advanced materials science.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MSQA\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6750\u6599\u79d1\u5b66\u9886\u57dfLLMs\u7684\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u53d1\u73b0\u4e86\u5f53\u524dLLMs\u7684\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u53d6\u5f97\u4e86\u6700\u8fd1\u7684\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u7528\u4e8e\u8bc4\u4f30\u5176\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aMSQA\u7684\u7efc\u5408\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b1,757\u4e2a\u7814\u7a76\u751f\u7ea7\u522b\u7684\u6750\u6599\u79d1\u5b66\u95ee\u9898\uff0c\u5206\u4e3a\u8be6\u7ec6\u89e3\u91ca\u6027\u56de\u7b54\u548c\u4e8c\u5143\u5bf9\u9519\u8bc4\u4f30\u4e24\u79cd\u683c\u5f0f\uff0c\u5e76\u5bf910\u79cd\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u57fa\u4e8eAPI\u7684\u4e13\u6709LLMs\u51c6\u786e\u7387\u9ad8\u8fbe84.5%\uff0c\u800c\u5f00\u6e90LLMs\u7684\u5cf0\u503c\u7ea6\u4e3a60.5%\u3002\u9886\u57df\u7279\u5b9a\u7684LLMs\u7531\u4e8e\u8fc7\u62df\u5408\u548c\u5206\u5e03\u504f\u79fb\u5f80\u5f80\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "MSQA\u662f\u7b2c\u4e00\u4e2a\u8054\u5408\u8bc4\u4f30LLMs\u5728\u9ad8\u7ea7\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u4e8b\u5b9e\u548c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7a81\u51fa\u4e86\u5f53\u524dLLMs\u7684\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2505.24556", "pdf": "https://arxiv.org/pdf/2505.24556", "abs": "https://arxiv.org/abs/2505.24556", "authors": ["Gabriel V Cardoso", "Mike Pereira"], "title": "Predictive posterior sampling from non-stationnary Gaussian process priors via Diffusion models with application to climate data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bayesian models based on Gaussian processes (GPs) offer a flexible framework\nto predict spatially distributed variables with uncertainty. But the use of\nnonstationary priors, often necessary for capturing complex spatial patterns,\nmakes sampling from the predictive posterior distribution (PPD) computationally\nintractable. In this paper, we propose a two-step approach based on diffusion\ngenerative models (DGMs) to mimic PPDs associated with non-stationary GP\npriors: we replace the GP prior by a DGM surrogate, and leverage recent\nadvances on training-free guidance algorithms for DGMs to sample from the\ndesired posterior distribution. We apply our approach to a rich non-stationary\nGP prior from which exact posterior sampling is untractable and validate that\nthe issuing distributions are close to their GP counterpart using several\nstatistical metrics. We also demonstrate how one can fine-tune the trained DGMs\nto target specific parts of the GP prior. Finally we apply the proposed\napproach to solve inverse problems arising in environmental sciences, thus\nyielding state-of-the-art predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u751f\u6210\u6a21\u578b\uff08DGMs\uff09\u7684\u4e24\u6b65\u65b9\u6cd5\uff0c\u7528\u4e8e\u6a21\u62df\u4e0e\u975e\u5e73\u7a33\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u5148\u9a8c\u76f8\u5173\u7684\u9884\u6d4b\u540e\u9a8c\u5206\u5e03\uff08PPD\uff09\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u7684\u95ee\u9898\u3002", "motivation": "\u975e\u5e73\u7a33\u5148\u9a8c\u5728\u6355\u6349\u590d\u6742\u7a7a\u95f4\u6a21\u5f0f\u65f6\u5f80\u5f80\u662f\u5fc5\u8981\u7684\uff0c\u4f46\u5728\u8d1d\u53f6\u65af\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u4e2d\uff0c\u8fd9\u4f7f\u5f97\u4ece\u9884\u6d4b\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\u53d8\u5f97\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u7528\u6269\u6563\u751f\u6210\u6a21\u578b\uff08DGM\uff09\u66ff\u4ee3\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u5148\u9a8c\uff0c\u5e76\u5229\u7528\u6700\u8fd1\u5f00\u53d1\u7684\u65e0\u9700\u8bad\u7ec3\u7684DGM\u6307\u5bfc\u7b97\u6cd5\u4ece\u671f\u671b\u7684\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u4e00\u4e2a\u590d\u6742\u7684\u975e\u5e73\u7a33GP\u5148\u9a8c\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u7edf\u8ba1\u6307\u6807\u9a8c\u8bc1\u4e86\u6240\u5f97\u5206\u5e03\u4e0e\u5176\u5bf9\u5e94\u7684GP\u6a21\u578b\u76f8\u8fd1\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5fae\u8c03DGM\u4ee5\u9488\u5bf9GP\u5148\u9a8c\u7684\u7279\u5b9a\u90e8\u5206\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u73af\u5883\u79d1\u5b66\u4e2d\u7684\u9006\u95ee\u9898\u6c42\u89e3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u6269\u6563\u751f\u6210\u6a21\u578b\u7684\u65b9\u6cd5\u4e3a\u4ece\u975e\u5e73\u7a33\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u4e2d\u8fdb\u884c\u540e\u9a8c\u91c7\u6837\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2505.23865", "pdf": "https://arxiv.org/pdf/2505.23865", "abs": "https://arxiv.org/abs/2505.23865", "authors": ["Emanuele Masiero", "Vito Trianni", "Giuseppe Vizzari", "Dimitri Ognibene"], "title": "Combining Deep Architectures for Information Gain estimation and Reinforcement Learning for multiagent field exploration", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, presented at RLDM 2025", "summary": "Precision agriculture requires efficient autonomous systems for crop\nmonitoring, where agents must explore large-scale environments while minimizing\nresource consumption. This work addresses the problem as an active exploration\ntask in a grid environment representing an agricultural field. Each cell may\ncontain targets (e.g., damaged crops) observable from nine predefined points of\nview (POVs). Agents must infer the number of targets per cell using partial,\nsequential observations.\n  We propose a two-stage deep learning framework. A pre-trained LSTM serves as\na belief model, updating a probabilistic map of the environment and its\nassociated entropy, which defines the expected information gain (IG). This\nallows agents to prioritize informative regions. A key contribution is the\ninclusion of a POV visibility mask in the input, preserving the Markov property\nunder partial observability and avoiding revisits to already explored views.\n  Three agent architectures were compared: an untrained IG-based agent\nselecting actions to maximize entropy reduction; a DQN agent using CNNs over\nlocal 3x3 inputs with belief, entropy, and POV mask; and a Double-CNN DQN agent\nwith wider spatial context. Simulations on 20x20 maps showed that the untrained\nagent performs well despite its simplicity. The DQN agent matches this\nperformance when the POV mask is included, while the Double-CNN agent\nconsistently achieves superior exploration efficiency, especially in larger\nenvironments.\n  Results show that uncertainty-aware policies leveraging entropy, belief\nstates, and visibility tracking lead to robust and scalable exploration. Future\nwork includes curriculum learning, multi-agent cooperation with shared rewards,\ntransformer-based models, and intrinsic motivation mechanisms to further\nenhance learning efficiency and policy generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7cbe\u51c6\u519c\u4e1a\u4e2d\u4f5c\u7269\u76d1\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u4e3b\u63a2\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u548c\u4e09\u79cd\u4ee3\u7406\u67b6\u6784\u7684\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u7cbe\u51c6\u519c\u4e1a\u9700\u8981\u9ad8\u6548\u7684\u81ea\u4e3b\u7cfb\u7edf\u8fdb\u884c\u4f5c\u7269\u76d1\u6d4b\uff0c\u800c\u4ee3\u7406\u5fc5\u987b\u5728\u5c3d\u91cf\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\u63a2\u7d22\u5927\u89c4\u6a21\u73af\u5883\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u4e2d\u9884\u8bad\u7ec3LSTM\u4f5c\u4e3a\u4fe1\u5ff5\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86POV\u53ef\u89c1\u6027\u63a9\u7801\u6765\u4fdd\u6301\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u548c\u907f\u514d\u91cd\u590d\u8bbf\u95ee\u3002\u901a\u8fc7\u6bd4\u8f83\u4e09\u79cd\u4ee3\u7406\u67b6\u6784\uff08\u672a\u8bad\u7ec3\u7684IG\u4ee3\u7406\u3001\u4f7f\u7528CNN\u7684DQN\u4ee3\u7406\u4ee5\u53caDouble-CNN DQN\u4ee3\u7406\uff09\u572820x20\u5730\u56fe\u4e0a\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u63a2\u7d22\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u672a\u8bad\u7ec3\u7684IG\u4ee3\u7406\u7ed3\u6784\u7b80\u5355\uff0c\u4f46\u5176\u8868\u73b0\u826f\u597d\uff1b\u5f53\u5305\u542bPOV\u63a9\u7801\u65f6\uff0cDQN\u4ee3\u7406\u7684\u8868\u73b0\u4e0e\u4e4b\u76f8\u5f53\uff1b\u800cDouble-CNN DQN\u4ee3\u7406\u5728\u66f4\u5927\u7684\u73af\u5883\u4e2d\u59cb\u7ec8\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u63a2\u7d22\u6548\u7387\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\uff0c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7684\u7b56\u7565\u5728\u71b5\u3001\u4fe1\u5ff5\u72b6\u6001\u548c\u53ef\u89c1\u6027\u8ddf\u8e2a\u7684\u5e2e\u52a9\u4e0b\u80fd\u591f\u5b9e\u73b0\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u63a2\u7d22\u3002"}}
{"id": "2505.23990", "pdf": "https://arxiv.org/pdf/2505.23990", "abs": "https://arxiv.org/abs/2505.23990", "authors": ["Mingyang Mao", "Mariela M. Perez-Cabarcas", "Utteja Kallakuri", "Nicholas R. Waytowich", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding", "categories": ["cs.AI"], "comment": null, "summary": "To effectively engage in human society, the ability to adapt, filter\ninformation, and make informed decisions in ever-changing situations is\ncritical. As robots and intelligent agents become more integrated into human\nlife, there is a growing opportunity-and need-to offload the cognitive burden\non humans to these systems, particularly in dynamic, information-rich\nscenarios.\n  To fill this critical need, we present Multi-RAG, a multimodal\nretrieval-augmented generation system designed to provide adaptive assistance\nto humans in information-intensive circumstances. Our system aims to improve\nsituational understanding and reduce cognitive load by integrating and\nreasoning over multi-source information streams, including video, audio, and\ntext. As an enabling step toward long-term human-robot partnerships, Multi-RAG\nexplores how multimodal information understanding can serve as a foundation for\nadaptive robotic assistance in dynamic, human-centered situations. To evaluate\nits capability in a realistic human-assistance proxy task, we benchmarked\nMulti-RAG on the MMBench-Video dataset, a challenging multimodal video\nunderstanding benchmark. Our system achieves superior performance compared to\nexisting open-source video large language models (Video-LLMs) and large\nvision-language models (LVLMs), while utilizing fewer resources and less input\ndata. The results demonstrate Multi- RAG's potential as a practical and\nefficient foundation for future human-robot adaptive assistance systems in\ndynamic, real-world contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Multi-RAG \u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u51cf\u5c11\u8ba4\u77e5\u8d1f\u62c5\u6765\u63d0\u5347\u4eba\u7c7b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u548c\u667a\u80fd\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u4eba\u7c7b\u751f\u6d3b\uff0c\u9700\u8981\u51cf\u8f7b\u4eba\u7c7b\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u4f7f\u5176\u80fd\u66f4\u597d\u5730\u5e94\u5bf9\u590d\u6742\u591a\u53d8\u7684\u4fe1\u606f\u73af\u5883\u3002", "method": "\u5f00\u53d1\u4e86 Multi-RAG \u7cfb\u7edf\uff0c\u5e76\u5728 MMBench-Video \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30\u5176\u591a\u6a21\u6001\u89c6\u9891\u7406\u89e3\u80fd\u529b\u3002", "result": "Multi-RAG \u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u5f00\u6e90\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08Video-LLMs\uff09\u548c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\uff0c\u540c\u65f6\u6d88\u8017\u66f4\u5c11\u8d44\u6e90\u548c\u8f93\u5165\u6570\u636e\u3002", "conclusion": "Multi-RAG \u662f\u4e00\u4e2a\u5177\u6709\u6f5c\u529b\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u53ef\u5728\u52a8\u6001\u3001\u4fe1\u606f\u4e30\u5bcc\u7684\u73af\u5883\u4e2d\u4e3a\u4eba\u7c7b\u63d0\u4f9b\u81ea\u9002\u5e94\u5e2e\u52a9\u3002"}}
{"id": "2505.24668", "pdf": "https://arxiv.org/pdf/2505.24668", "abs": "https://arxiv.org/abs/2505.24668", "authors": ["Jonghyun Ham", "Maximilian Fleissner", "Debarghya Ghoshdastidar"], "title": "Impact of Bottleneck Layers and Skip Connections on the Generalization of Linear Denoising Autoencoders", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Modern deep neural networks exhibit strong generalization even in highly\noverparameterized regimes. Significant progress has been made to understand\nthis phenomenon in the context of supervised learning, but for unsupervised\ntasks such as denoising, several open questions remain. While some recent works\nhave successfully characterized the test error of the linear denoising problem,\nthey are limited to linear models (one-layer network). In this work, we focus\non two-layer linear denoising autoencoders trained under gradient flow,\nincorporating two key ingredients of modern deep learning architectures: A\nlow-dimensional bottleneck layer that effectively enforces a rank constraint on\nthe learned solution, as well as the possibility of a skip connection that\nbypasses the bottleneck. We derive closed-form expressions for all critical\npoints of this model under product regularization, and in particular describe\nits global minimizer under the minimum-norm principle. From there, we derive\nthe test risk formula in the overparameterized regime, both for models with and\nwithout skip connections. Our analysis reveals two interesting phenomena:\nFirstly, the bottleneck layer introduces an additional complexity measure akin\nto the classical bias-variance trade-off -- increasing the bottleneck width\nreduces bias but introduces variance, and vice versa. Secondly, skip connection\ncan mitigate the variance in denoising autoencoders -- especially when the\nmodel is mildly overparameterized. We further analyze the impact of skip\nconnections in denoising autoencoder using random matrix theory and support our\nclaims with numerical evidence.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u6709\u74f6\u9888\u5c42\u548c\u8df3\u8dc3\u8fde\u63a5\u7684\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5728\u68af\u5ea6\u6d41\u548c\u4ea7\u54c1\u6b63\u5219\u5316\u4e0b\u5206\u6790\u5176\u6d4b\u8bd5\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u74f6\u9888\u5bbd\u5ea6\u5bf9\u504f\u5dee-\u65b9\u5dee\u7684\u6743\u8861\u53ca\u8df3\u8dc3\u8fde\u63a5\u5bf9\u964d\u4f4e\u65b9\u5dee\u7684\u4f5c\u7528\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u9ad8\u5ea6\u8fc7\u53c2\u6570\u5316\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u9488\u5bf9\u65e0\u76d1\u7763\u4efb\u52a1\u5982\u53bb\u566a\u4ecd\u5b58\u5728\u8bb8\u591a\u672a\u89e3\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u68af\u5ea6\u6d41\u8bad\u7ec3\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5e76\u5229\u7528\u4e58\u79ef\u6b63\u5219\u5316\u63a8\u5bfc\u51fa\u6a21\u578b\u6240\u6709\u4e34\u754c\u70b9\u7684\u95ed\u5408\u5f62\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u8fc7\u53c2\u6570\u5316\u4f53\u5236\u4e0b\u7684\u6d4b\u8bd5\u98ce\u9669\u516c\u5f0f\u3002", "result": "\u6210\u529f\u63cf\u8ff0\u4e86\u5e26\u6216\u4e0d\u5e26\u8df3\u8dc3\u8fde\u63a5\u7684\u8fc7\u53c2\u6570\u5316\u4f53\u5236\u4e0b\u7684\u6d4b\u8bd5\u98ce\u9669\u516c\u5f0f\uff0c\u5e76\u63ed\u793a\u4e86\u4e24\u4e2a\u91cd\u8981\u73b0\u8c61\uff1a\u74f6\u9888\u5bbd\u5ea6\u4e0e\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u8df3\u8dc3\u8fde\u63a5\u5bf9\u964d\u4f4e\u65b9\u5dee\u7684\u5f71\u54cd\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\uff0c\u74f6\u9888\u5c42\u5f15\u5165\u4e86\u4e00\u79cd\u7c7b\u4f3c\u4e8e\u7ecf\u5178\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u7684\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u5e76\u4e14\u8df3\u8dc3\u8fde\u63a5\u53ef\u4ee5\u51cf\u8f7b\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u4e2d\u7684\u65b9\u5dee\u95ee\u9898\u3002"}}
{"id": "2505.23866", "pdf": "https://arxiv.org/pdf/2505.23866", "abs": "https://arxiv.org/abs/2505.23866", "authors": ["Chengli Tan", "Yubo Zhou", "Haishan Ye", "Guang Dai", "Junmin Liu", "Zengjie Song", "Jiangshe Zhang", "Zixiang Zhao", "Yunda Hao", "Yong Xu"], "title": "Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "Deep neural networks have been increasingly used in safety-critical\napplications such as medical diagnosis and autonomous driving. However, many\nstudies suggest that they are prone to being poorly calibrated and have a\npropensity for overconfidence, which may have disastrous consequences. In this\npaper, unlike standard training such as stochastic gradient descent, we show\nthat the recently proposed sharpness-aware minimization (SAM) counteracts this\ntendency towards overconfidence. The theoretical analysis suggests that SAM\nallows us to learn models that are already well-calibrated by implicitly\nmaximizing the entropy of the predictive distribution. Inspired by this\nfinding, we further propose a variant of SAM, coined as CSAM, to ameliorate\nmodel calibration. Extensive experiments on various datasets, including\nImageNet-1K, demonstrate the benefits of SAM in reducing calibration error.\nMeanwhile, CSAM performs even better than SAM and consistently achieves lower\ncalibration error than other approaches", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5CSAM\uff0c\u7528\u4e8e\u51cf\u5c11\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u503e\u5411\u4e8e\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u7684\u540e\u679c\u3002", "method": "\u63d0\u51fa\u4e86CSAM\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5176\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4f7f\u7528CSAM\u53ef\u4ee5\u964d\u4f4e\u6821\u51c6\u8bef\u5dee\u3002", "conclusion": "CSAM\u5728\u51cf\u5c11\u6821\u51c6\u8bef\u5dee\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5305\u62ecSAM\u3002"}}
{"id": "2505.24036", "pdf": "https://arxiv.org/pdf/2505.24036", "abs": "https://arxiv.org/abs/2505.24036", "authors": ["Amel Gader", "Alsayed Algergawy"], "title": "GenIC: An LLM-Based Framework for Instance Completion in Knowledge Graphs", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Knowledge graph completion aims to address the gaps of knowledge bases by\nadding new triples that represent facts. The complexity of this task depends on\nhow many parts of a triple are already known. Instance completion involves\npredicting the relation-tail pair when only the head is given (h, ?, ?).\nNotably, modern knowledge bases often contain entity descriptions and types,\nwhich can provide valuable context for inferring missing facts. By leveraging\nthese textual descriptions and the ability of large language models to extract\nfacts from them and recognize patterns within the knowledge graph schema, we\npropose an LLM-powered, end-to-end instance completion approach. Specifically,\nwe introduce GenIC: a two-step Generative Instance Completion framework. The\nfirst step focuses on property prediction, treated as a multi-label\nclassification task. The second step is link prediction, framed as a generative\nsequence-to-sequence task. Experimental results on three datasets show that our\nmethod outperforms existing baselines. Our code is available at\nhttps://github.com/amal-gader/genic.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u56fe\u8c31\u5b9e\u4f8b\u8865\u5168\u8fc7\u7a0bGenIC\uff0c\u901a\u8fc7\u4e24\u4e2a\u6b65\u9aa4\u8fdb\u884c\u5c5e\u6027\u9884\u6d4b\u548c\u94fe\u63a5\u9884\u6d4b\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u77e5\u8bc6\u5e93\u901a\u5e38\u5305\u542b\u5b9e\u4f53\u63cf\u8ff0\u548c\u7c7b\u578b\uff0c\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u4e3a\u63a8\u65ad\u7f3a\u5931\u4e8b\u5b9e\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u4e0a\u4e0b\u6587\uff0c\u56e0\u6b64\u5229\u7528\u8fd9\u4e9b\u6587\u672c\u63cf\u8ff0\u4ee5\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u6765\u63d0\u53d6\u4e8b\u5b9e\u5e76\u8bc6\u522b\u77e5\u8bc6\u56fe\u8c31\u6a21\u5f0f\u4e2d\u7684\u6a21\u5f0f\uff0c\u4ee5\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aGenIC\u7684\u4e24\u6b65\u751f\u6210\u5b9e\u4f8b\u8865\u5168\u8fc7\u7a0b\uff0c\u7b2c\u4e00\u6b65\u662f\u5c5e\u6027\u9884\u6d4b\uff0c\u4f5c\u4e3a\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff1b\u7b2c\u4e8c\u6b65\u662f\u94fe\u63a5\u9884\u6d4b\uff0c\u4f5c\u4e3a\u751f\u6210\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u4efb\u52a1\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u5b9e\u4f8b\u8865\u5168\u8fc7\u7a0b\uff0c\u5373GenIC\uff0c\u5e76\u4e14\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2505.24704", "pdf": "https://arxiv.org/pdf/2505.24704", "abs": "https://arxiv.org/abs/2505.24704", "authors": ["Hideaki Kim", "Tomoharu Iwata", "Akinori Fujino"], "title": "K$^2$IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Kernel method-based intensity estimators, formulated within reproducing\nkernel Hilbert spaces (RKHSs), and classical kernel intensity estimators (KIEs)\nhave been among the most easy-to-implement and feasible methods for estimating\nthe intensity functions of inhomogeneous Poisson processes. While both\napproaches share the term \"kernel\", they are founded on distinct theoretical\nprinciples, each with its own strengths and limitations. In this paper, we\npropose a novel regularized kernel method for Poisson processes based on the\nleast squares loss and show that the resulting intensity estimator involves a\nspecialized variant of the representer theorem: it has the dual coefficient of\nunity and coincides with classical KIEs. This result provides new theoretical\ninsights into the connection between classical KIEs and kernel method-based\nintensity estimators, while enabling us to develop an efficient KIE by\nleveraging advanced techniques from RKHS theory. We refer to the proposed model\nas the kernel method-based kernel intensity estimator (K$^2$IE). Through\nexperiments on synthetic datasets, we show that K$^2$IE achieves comparable\npredictive performance while significantly surpassing the state-of-the-art\nkernel method-based estimator in computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86K\u00b2IE\uff0c\u8fd9\u662f\u4e00\u79cd\u7ed3\u5408\u6838\u65b9\u6cd5\u548c\u7ecf\u5178KIE\u4f18\u52bf\u7684\u65b0\u5f3a\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u6838\u65b9\u6cd5\u548c\u7ecf\u5178KIE\u90fd\u7528\u4e8e\u4f30\u8ba1\u975e\u9f50\u6b21\u6cca\u677e\u8fc7\u7a0b\u7684\u5f3a\u5ea6\u51fd\u6570\uff0c\u4f46\u5b83\u4eec\u57fa\u4e8e\u4e0d\u540c\u7684\u7406\u8bba\u539f\u7406\uff0c\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e24\u8005\u4e4b\u95f4\u7684\u8054\u7cfb\u5e76\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u5c0f\u4e8c\u4e58\u635f\u5931\u7684\u6cca\u677e\u8fc7\u7a0b\u6b63\u5219\u5316\u6838\u65b9\u6cd5\uff0c\u5229\u7528RKHS\u7406\u8bba\u5f00\u53d1\u51fa\u66f4\u9ad8\u6548\u7684KIE\uff0c\u79f0\u4e3aK\u00b2IE\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cK\u00b2IE\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u5177\u6709\u53ef\u6bd4\u6027\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "K\u00b2IE\u63d0\u4f9b\u4e86\u5bf9\u7ecf\u5178KIE\u548c\u57fa\u4e8e\u6838\u65b9\u6cd5\u7684\u5f3a\u5ea6\u4f30\u8ba1\u91cf\u4e4b\u95f4\u8054\u7cfb\u7684\u65b0\u7406\u8bba\u6d1e\u5bdf\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u6838\u65b9\u6cd5\u7684\u4f30\u8ba1\u5668\u3002"}}
{"id": "2505.23868", "pdf": "https://arxiv.org/pdf/2505.23868", "abs": "https://arxiv.org/abs/2505.23868", "authors": ["Zhaokun Wang", "Jinyu Guo", "Jingwen Pu", "Lingfeng Chen", "Hongli Pu", "Jie Ou. Libo Qin", "Wenhong Tian"], "title": "Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current parameter-efficient fine-tuning methods for adapting pre-trained\nlanguage models to downstream tasks are susceptible to interference from noisy\ndata. Conventional noise-handling approaches either rely on laborious data\npre-processing or employ model architecture modifications prone to error\naccumulation. In contrast to existing noise-process paradigms, we propose a\nnoise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a\nnovel framework that enhances model robustness to noise only with generated\nnoisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE\nstrategically integrates a dedicated poisoning expert in an asymmetric LoRA\nconfiguration. Through a two-stage paradigm, LoPE performs noise injection on\nthe poisoning expert during fine-tuning to enhance its noise discrimination and\nprocessing ability. During inference, we selectively mask the dedicated\npoisoning expert to leverage purified knowledge acquired by normal experts for\nnoise-robust output. Extensive experiments demonstrate that LoPE achieves\nstrong performance and robustness purely through the low-cost noise injection,\nwhich completely eliminates the requirement of data cleaning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u566a\u58f0\u9c81\u68d2\u81ea\u9002\u5e94\u65b9\u6cd5LoPE\uff0c\u4ec5\u901a\u8fc7\u751f\u6210\u7684\u566a\u58f0\u6570\u636e\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u566a\u58f0\u5904\u7406\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7e41\u7410\u7684\u6570\u636e\u9884\u5904\u7406\uff0c\u8981\u4e48\u91c7\u7528\u5bb9\u6613\u4ea7\u751f\u8bef\u5dee\u79ef\u7d2f\u7684\u6a21\u578b\u67b6\u6784\u4fee\u6539\u3002", "method": "LoPE\u901a\u8fc7\u4e0d\u5bf9\u79f0\u7684LoRA\u914d\u7f6e\u96c6\u6210\u4e00\u4e2a\u4e13\u95e8\u7684\u4e2d\u6bd2\u4e13\u5bb6\uff0c\u5728\u4e24\u9636\u6bb5\u8303\u5f0f\u4e2d\u8fdb\u884c\u566a\u58f0\u6ce8\u5165\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9009\u62e9\u6027\u5730\u5c4f\u853d\u8be5\u4e13\u5bb6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLoPE\u901a\u8fc7\u4f4e\u6210\u672c\u7684\u566a\u58f0\u6ce8\u5165\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "LoPE\u662f\u4e00\u79cd\u65e0\u9700\u6570\u636e\u6e05\u6d17\u7684\u4f4e\u566a\u58f0\u6ce8\u5165\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24037", "pdf": "https://arxiv.org/pdf/2505.24037", "abs": "https://arxiv.org/abs/2505.24037", "authors": ["Qiao Xiao", "Alan Ansell", "Boqian Wu", "Lu Yin", "Mykola Pechenizkiy", "Shiwei Liu", "Decebal Constantin Mocanu"], "title": "Leave it to the Specialist: Repair Sparse LLMs with Sparse Fine-Tuning via Sparsity Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across various\ntasks but face deployment challenges due to their massive computational\ndemands. While post-training pruning methods like SparseGPT and Wanda can\neffectively reduce the model size, but struggle to maintain model performance\nat high sparsity levels, limiting their utility for downstream tasks. Existing\nfine-tuning methods, such as full fine-tuning and LoRA, fail to preserve\nsparsity as they require updating the whole dense metrics, not well-suited for\nsparse LLMs. In this paper, we propose Sparsity Evolution Fine-Tuning (SEFT), a\nnovel method designed specifically for sparse LLMs. SEFT dynamically evolves\nthe sparse topology of pruned models during fine-tuning, while preserving the\noverall sparsity throughout the process. The strengths of SEFT lie in its\nability to perform task-specific adaptation through a weight drop-and-grow\nstrategy, enabling the pruned model to self-adapt its sparse connectivity\npattern based on the target dataset. Furthermore, a sensitivity-driven pruning\ncriterion is employed to ensure that the desired sparsity level is consistently\nmaintained throughout fine-tuning. Our experiments on various LLMs, including\nLLaMA families, DeepSeek, and Mistral, across a diverse set of benchmarks\ndemonstrate that SEFT achieves stronger performance while offering superior\nmemory and time efficiency compared to existing baselines. Our code is publicly\navailable at: https://github.com/QiaoXiao7282/SEFT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5fae\u8c03\u65b9\u6cd5SEFT\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6f14\u5316\u7a00\u758f\u62d3\u6251\uff0c\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7a00\u758f\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u8bad\u7ec3\u526a\u679d\u65b9\u6cd5\u5982SparseGPT\u548cWanda\u5728\u9ad8\u7a00\u758f\u6c34\u5e73\u4e0b\u96be\u4ee5\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u800c\u73b0\u6709\u7684\u5fae\u8c03\u65b9\u6cd5\u5982\u5168\u5fae\u8c03\u548cLoRA\u8981\u6c42\u66f4\u65b0\u6574\u4e2a\u5bc6\u96c6\u5ea6\u91cf\uff0c\u4e0d\u9002\u5408\u7a00\u758fLLM\u3002", "method": "SEFT\u901a\u8fc7\u6743\u91cd\u4e0b\u964d\u548c\u589e\u957f\u7b56\u7565\u8fdb\u884c\u4efb\u52a1\u7279\u5b9a\u7684\u9002\u5e94\uff0c\u5e76\u91c7\u7528\u654f\u611f\u6027\u9a71\u52a8\u7684\u526a\u679d\u51c6\u5219\u4ee5\u4fdd\u6301\u6240\u9700\u7684\u7a00\u758f\u6c34\u5e73\u3002", "result": "SEFT\u5728\u5404\u79cdLLM\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u5176\u5f3a\u5927\u7684\u6027\u80fd\u4ee5\u53ca\u4f18\u8d8a\u7684\u5185\u5b58\u548c\u65f6\u95f4\u6548\u7387\u3002", "conclusion": "SEFT\u662f\u4e00\u79cd\u4e13\u4e3a\u7a00\u758fLLM\u8bbe\u8ba1\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6f14\u5316\u7a00\u758f\u62d3\u6251\uff0c\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7a00\u758f\u6027\u3002SEFT\u5728\u591a\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\uff0cSEFT\u5177\u6709\u66f4\u5f3a\u7684\u6027\u80fd\u4ee5\u53ca\u4f18\u8d8a\u7684\u5185\u5b58\u548c\u65f6\u95f4\u6548\u7387\u3002"}}
{"id": "2505.24727", "pdf": "https://arxiv.org/pdf/2505.24727", "abs": "https://arxiv.org/abs/2505.24727", "authors": ["Xiaochen Zhang", "Haoyi Xiong"], "title": "Knockoff-Guided Compressive Sensing: A Statistical Machine Learning Framework for Support-Assured Signal Recovery", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "This paper introduces a novel Knockoff-guided compressive sensing framework,\nreferred to as \\TheName{}, which enhances signal recovery by leveraging precise\nfalse discovery rate (FDR) control during the support identification phase.\nUnlike LASSO, which jointly performs support selection and signal estimation\nwithout explicit error control, our method guarantees FDR control in finite\nsamples, enabling more reliable identification of the true signal support. By\nseparating and controlling the support recovery process through statistical\nKnockoff filters, our framework achieves more accurate signal reconstruction,\nespecially in challenging scenarios where traditional methods fail. We\nestablish theoretical guarantees demonstrating how FDR control directly ensures\nrecovery performance under weaker conditions than traditional $\\ell_1$-based\ncompressive sensing methods, while maintaining accurate signal reconstruction.\nExtensive numerical experiments demonstrate that our proposed Knockoff-based\nmethod consistently outperforms LASSO-based and other state-of-the-art\ncompressive sensing techniques. In simulation studies, our method improves\nF1-score by up to 3.9x over baseline methods, attributed to principled false\ndiscovery rate (FDR) control and enhanced support recovery. The method also\nconsistently yields lower reconstruction and relative errors. We further\nvalidate the framework on real-world datasets, where it achieves top downstream\npredictive performance across both regression and classification tasks, often\nnarrowing or even surpassing the performance gap relative to uncompressed\nsignals. These results establish \\TheName{} as a robust and practical\nalternative to existing approaches, offering both theoretical guarantees and\nstrong empirical performance through statistically grounded support selection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\\TheName{}\uff0c\u4e00\u4e2a\u7ed3\u5408\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u7684\u65b0\u578b\u538b\u7f29\u611f\u77e5\u6846\u67b6\uff0c\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8df5\u4e2d\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u573a\u666f\u4e0b\u7684\u4fe1\u53f7\u6062\u590d\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982LASSO\u5728\u652f\u6301\u9009\u62e9\u548c\u4fe1\u53f7\u4f30\u8ba1\u4e2d\u6ca1\u6709\u660e\u786e\u63a7\u5236\u9519\u8bef\u7387\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u573a\u666f\u4e0b\u96be\u4ee5\u53ef\u9760\u5730\u8bc6\u522b\u771f\u5b9e\u4fe1\u53f7\u652f\u6301\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165FDR\u63a7\u5236\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u4fe1\u53f7\u6062\u590d\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u79f0\u4e3a\\TheName{}\u7684Knockoff\u5f15\u5bfc\u538b\u7f29\u611f\u77e5\u6846\u67b6\uff0c\u5c06\u652f\u6301\u9009\u62e9\u4e0e\u4fe1\u53f7\u4f30\u8ba1\u5206\u79bb\uff0c\u5e76\u5229\u7528\u7edf\u8ba1Knockoff\u6ee4\u6ce2\u5668\u8fdb\u884cFDR\u63a7\u5236\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u4fe1\u53f7\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u7684F1\u5206\u6570\u63d0\u9ad8\u4e86\u9ad8\u8fbe3.9\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u91cd\u6784\u8bef\u5dee\u548c\u76f8\u5bf9\u8bef\u5dee\u3002\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4e5f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u751a\u81f3\u63a5\u8fd1\u6216\u8d85\u8fc7\u672a\u538b\u7f29\u4fe1\u53f7\u7684\u8868\u73b0\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eKnockoff\u7684\u538b\u7f29\u611f\u77e5\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u8bef\u53d1\u73b0\u7387\uff08FDR\uff09\u5728\u652f\u6301\u8bc6\u522b\u9636\u6bb5\u63d0\u9ad8\u4fe1\u53f7\u6062\u590d\u7684\u53ef\u9760\u6027\u4e0e\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8bc1\u6027\u80fd\u4e0a\u90fd\u4f18\u4e8e\u4f20\u7edf\u7684LASSO\u548c\u5176\u4ed6\u538b\u7f29\u611f\u77e5\u6280\u672f\u3002"}}
{"id": "2505.23870", "pdf": "https://arxiv.org/pdf/2505.23870", "abs": "https://arxiv.org/abs/2505.23870", "authors": ["Yixian Shen", "Qi Bi", "Jia-Hong Huang", "Hongyi Zhu", "Andy D. Pimentel", "Anuj Pathania"], "title": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2410.09103", "summary": "We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine\nProjection, that achieves exceptional performance while requiring minimal\nparameters and memory for fine-tuning large foundation models. Its general idea\nis to exploit the superior energy compaction and decorrelation properties of\ncosine projection to improve both model efficiency and accuracy. Specifically,\nit projects the weight change from the low-rank adaptation into the discrete\ncosine space. Then, the weight change is partitioned over different levels of\nthe discrete cosine spectrum, and each partition's most critical frequency\ncomponents are selected. Extensive experiments demonstrate the effectiveness of\nMaCP across a wide range of single-modality tasks, including natural language\nunderstanding, natural language generation, text summarization, as well as\nmulti-modality tasks such as image classification and video understanding. MaCP\nconsistently delivers superior accuracy, significantly reduced computational\ncomplexity, and lower memory requirements compared to existing alternatives.", "AI": {"tldr": "MaCP\u662f\u4e00\u79cd\u7528\u4e8e\u5fae\u8c03\u5927\u578b\u6a21\u578b\u7684\u65b0\u9896\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6743\u91cd\u53d8\u5316\u6295\u5f71\u5230\u79bb\u6563\u4f59\u5f26\u7a7a\u95f4\u5e76\u9009\u53d6\u5173\u952e\u9891\u7387\u5206\u91cf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u5bfb\u627e\u4e00\u79cd\u53c2\u6570\u548c\u5185\u5b58\u9700\u6c42\u6700\u5c0f\u5316\u7684\u65b9\u6cd5\u6765\u9ad8\u6548\u5fae\u8c03\u5927\u57fa\u7840\u6a21\u578b\u3002", "method": "MaCP\u5229\u7528\u4f59\u5f26\u6295\u5f71\u7684\u4f18\u826f\u80fd\u91cf\u96c6\u4e2d\u548c\u53bb\u76f8\u5173\u7279\u6027\uff0c\u5c06\u4f4e\u79e9\u9002\u5e94\u7684\u6743\u91cd\u53d8\u5316\u6295\u5f71\u5230\u79bb\u6563\u4f59\u5f26\u7a7a\u95f4\uff0c\u5e76\u9009\u62e9\u6bcf\u4e2a\u5206\u533a\u6700\u5173\u952e\u9891\u7387\u5206\u91cf\u3002", "result": "MaCP\u5728\u5e7f\u6cdb\u7684\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u3001\u6587\u672c\u6458\u8981\u3001\u56fe\u50cf\u5206\u7c7b\u548c\u89c6\u9891\u7406\u89e3\u7b49\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u663e\u8457\u964d\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u6027\u548c\u66f4\u4f4e\u7684\u5185\u5b58\u9700\u6c42\u3002", "conclusion": "MaCP\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u4efb\u52a1\u3002"}}
{"id": "2505.24073", "pdf": "https://arxiv.org/pdf/2505.24073", "abs": "https://arxiv.org/abs/2505.24073", "authors": ["Chan-Wei Hu", "Yueqi Wang", "Shuo Xing", "Chia-Ju Chen", "Zhengzhong Tu"], "title": "mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "16 pages, 11 figures", "summary": "Large Vision-Language Models (LVLMs) have made remarkable strides in\nmultimodal tasks such as visual question answering, visual grounding, and\ncomplex reasoning. However, they remain limited by static training data,\nsusceptibility to hallucinations, and inability to verify claims against\nup-to-date, external evidence, compromising their performance in dynamic\nreal-world applications. Retrieval-Augmented Generation (RAG) offers a\npractical solution to mitigate these challenges by allowing the LVLMs to access\nlarge-scale knowledge databases via retrieval mechanisms, thereby grounding\nmodel outputs in factual, contextually relevant information. Here in this\npaper, we conduct the first systematic dissection of the multimodal RAG\npipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the\nmodality configurations and retrieval strategies, (2) the re-ranking stage: on\nstrategies to mitigate positional biases and improve the relevance of retrieved\nevidence, and (3) the generation phase: we further investigate how to best\nintegrate retrieved candidates into the final generation process. Finally, we\nextend to explore a unified agentic framework that integrates re-ranking and\ngeneration through self-reflection, enabling LVLMs to select relevant evidence\nand suppress irrelevant context dynamically. Our full-stack exploration of RAG\nfor LVLMs yields substantial insights, resulting in an average performance\nboost of 5% without any fine-tuning.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u9002\u7528\u4e8e\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u4ee3\u7406\u6846\u67b6\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u591a\u79cd\u591a\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u4ecd\u53d7\u9650\u4e8e\u9759\u6001\u8bad\u7ec3\u6570\u636e\u3001\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u4ee5\u53ca\u65e0\u6cd5\u9a8c\u8bc1\u6700\u65b0\u7684\u5916\u90e8\u8bc1\u636e\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u5176\u5728\u52a8\u6001\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u591a\u6a21\u6001RAG\u6d41\u6c34\u7ebf\u7684\u4e09\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a\u68c0\u7d22\u9636\u6bb5\u3001\u91cd\u6392\u5e8f\u9636\u6bb5\u548c\u751f\u6210\u9636\u6bb5\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u5c06\u91cd\u6392\u5e8f\u548c\u751f\u6210\u96c6\u6210\u5728\u4e00\u8d77\u3002", "result": "\u901a\u8fc7\u5bf9RAG\u6d41\u6c34\u7ebf\u7684\u5168\u6808\u63a2\u7d22\uff0c\u7814\u7a76\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u5747\u63d0\u9ad8\u4e865%\u4e14\u4e0d\u9700\u8981\u8fdb\u884c\u4efb\u4f55\u5fae\u8c03\u3002", "conclusion": "\u7814\u7a76\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5168\u9762\u63a2\u7d22RAG\u5bf9\u4e8eLVLMs\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u6548\u679c\uff0c\u5e73\u5747\u63d0\u5347\u4e865%\u800c\u65e0\u9700\u4efb\u4f55\u5fae\u8c03\u3002"}}
{"id": "2505.24769", "pdf": "https://arxiv.org/pdf/2505.24769", "abs": "https://arxiv.org/abs/2505.24769", "authors": ["Claudia Merger", "Sebastian Goldt"], "title": "Generalization Dynamics of Linear Diffusion Models", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Diffusion models trained on finite datasets with $N$ samples from a target\ndistribution exhibit a transition from memorisation, where the model reproduces\ntraining examples, to generalisation, where it produces novel samples that\nreflect the underlying data distribution. Understanding this transition is key\nto characterising the sample efficiency and reliability of generative models,\nbut our theoretical understanding of this transition is incomplete. Here, we\nanalytically study the memorisation-to-generalisation transition in a simple\nmodel using linear denoisers, which allow explicit computation of test errors,\nsampling distributions, and Kullback-Leibler divergences between samples and\ntarget distribution. Using these measures, we predict that this transition\noccurs roughly when $N \\asymp d$, the dimension of the inputs. When $N$ is\nsmaller than the dimension of the inputs $d$, so that only a fraction of\nrelevant directions of variation are present in the training data, we\ndemonstrate how both regularization and early stopping help to prevent\noverfitting. For $N > d$, we find that the sampling distributions of linear\ndiffusion models approach their optimum (measured by the Kullback-Leibler\ndivergence) linearly with $d/N$, independent of the specifics of the data\ndistribution. Our work clarifies how sample complexity governs generalisation\nin a simple model of diffusion-based generative models and provides insight\ninto the training dynamics of linear denoisers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6269\u6563\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u4ece\u8bb0\u5fc6\u5230\u6cdb\u5316\u7684\u8fc7\u6e21\uff0c\u53d1\u73b0\u5f53\u6837\u672c\u6570\u91cfN\u63a5\u8fd1\u8f93\u5165\u7ef4\u5ea6d\u65f6\u4f1a\u53d1\u751f\u8fd9\u4e00\u8fc7\u6e21\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u60c5\u51b5\u4e0b\u5982\u4f55\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7406\u89e3\u6269\u6563\u6a21\u578b\u4ece\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u5230\u6cdb\u5316\u751f\u6210\u65b0\u6837\u672c\u7684\u8f6c\u53d8\u5bf9\u4e8e\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u5bf9\u6b64\u8fc7\u6e21\u7684\u7406\u8bba\u7406\u89e3\u5c1a\u4e0d\u5b8c\u6574\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u53bb\u566a\u5668\u5bf9\u6269\u6563\u6a21\u578b\u8fdb\u884c\u5206\u6790\uff0c\u901a\u8fc7\u663e\u5f0f\u8ba1\u7b97\u6d4b\u8bd5\u8bef\u5dee\u3001\u91c7\u6837\u5206\u5e03\u4ee5\u53ca\u6837\u672c\u4e0e\u76ee\u6807\u5206\u5e03\u4e4b\u95f4\u7684Kullback-Leibler\u6563\u5ea6\u6765\u9884\u6d4b\u8bb0\u5fc6\u5230\u6cdb\u5316\u7684\u8fc7\u6e21\u3002", "result": "\u8bba\u6587\u9884\u6d4b\u8bb0\u5fc6\u5230\u6cdb\u5316\u8fc7\u6e21\u53d1\u751f\u5728\u6837\u672c\u6570N\u5927\u7ea6\u7b49\u4e8e\u8f93\u5165\u7ef4\u5ea6d\u7684\u65f6\u5019\u3002\u5f53N\u5c0f\u4e8ed\u65f6\uff0c\u8bad\u7ec3\u6570\u636e\u4e2d\u4ec5\u5305\u542b\u90e8\u5206\u76f8\u5173\u53d8\u5316\u65b9\u5411\uff0c\u6b63\u5219\u5316\u548c\u63d0\u524d\u505c\u6b62\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u8fc7\u62df\u5408\uff1b\u800c\u5f53N\u5927\u4e8ed\u65f6\uff0c\u91c7\u6837\u5206\u5e03\u63a5\u8fd1\u6700\u4f18\u72b6\u6001\uff0c\u4e14\u8fd9\u79cd\u72b6\u6001\u4e0e\u6570\u636e\u5206\u5e03\u7684\u5177\u4f53\u5f62\u5f0f\u65e0\u5173\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u7814\u7a76\u7ebf\u6027\u53bb\u566a\u6269\u6563\u6a21\u578b\uff0c\u53d1\u73b0\u5f53\u6837\u672c\u6570N\u5c0f\u4e8e\u8f93\u5165\u7ef4\u5ea6d\u65f6\uff0c\u6b63\u5219\u5316\u548c\u63d0\u524d\u505c\u6b62\u6709\u52a9\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff1b\u800c\u5f53N\u5927\u4e8ed\u65f6\uff0c\u91c7\u6837\u5206\u5e03\u63a5\u8fd1\u6700\u4f18\u72b6\u6001\uff0c\u5e76\u4e14\u8fd9\u79cd\u72b6\u6001\u4e0e\u6570\u636e\u5206\u5e03\u7684\u5177\u4f53\u5f62\u5f0f\u65e0\u5173\u3002"}}
{"id": "2505.23871", "pdf": "https://arxiv.org/pdf/2505.23871", "abs": "https://arxiv.org/abs/2505.23871", "authors": ["Zeyuan Liu", "Zhihe Yang", "Jiawei Xu", "Rui Yang", "Jiafei Lyu", "Baoxiang Wang", "Yunjian Xu", "Xiu Li"], "title": "ADG: Ambient Diffusion-Guided Dataset Recovery for Corruption-Robust Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world datasets collected from sensors or human inputs are prone to noise\nand errors, posing significant challenges for applying offline reinforcement\nlearning (RL). While existing methods have made progress in addressing\ncorrupted actions and rewards, they remain insufficient for handling corruption\nin high-dimensional state spaces and for cases where multiple elements in the\ndataset are corrupted simultaneously. Diffusion models, known for their strong\ndenoising capabilities, offer a promising direction for this problem-but their\ntendency to overfit noisy samples limits their direct applicability. To\novercome this, we propose Ambient Diffusion-Guided Dataset Recovery (ADG), a\nnovel approach that pioneers the use of diffusion models to tackle data\ncorruption in offline RL. First, we introduce Ambient Denoising Diffusion\nProbabilistic Models (DDPM) from approximated distributions, which enable\nlearning on partially corrupted datasets with theoretical guarantees. Second,\nwe use the noise-prediction property of Ambient DDPM to distinguish between\nclean and corrupted data, and then use the clean subset to train a standard\nDDPM. Third, we employ the trained standard DDPM to refine the previously\nidentified corrupted data, enhancing data quality for subsequent offline RL\ntraining. A notable strength of ADG is its versatility-it can be seamlessly\nintegrated with any offline RL algorithm. Experiments on a range of benchmarks,\nincluding MuJoCo, Kitchen, and Adroit, demonstrate that ADG effectively\nmitigates the impact of corrupted data and improves the robustness of offline\nRL under various noise settings, achieving state-of-the-art results.", "AI": {"tldr": "ADG\u662f\u4e00\u79cd\u5229\u7528\u6269\u6563\u6a21\u578b\u5904\u7406\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u6570\u636e\u635f\u574f\u95ee\u9898\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u79cd\u566a\u58f0\u8bbe\u7f6e\u4e0b\u63d0\u9ad8\u4e86\u79bb\u7ebfRL\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u5bb9\u6613\u53d7\u5230\u566a\u97f3\u548c\u9519\u8bef\u7684\u5f71\u54cd\uff0c\u8fd9\u5bf9\u5e94\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u548c\u591a\u4e2a\u5143\u7d20\u540c\u65f6\u635f\u574f\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAmbient Diffusion-Guided Dataset Recovery (ADG)\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86Ambient Denoising Diffusion Probabilistic Models\u4e0e\u6807\u51c6DDPM\uff0c\u4ee5\u8bc6\u522b\u5e76\u4fee\u590d\u635f\u574f\u7684\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aADG\u5728\u5305\u62ecMuJoCo\u3001Kitchen\u548cAdroit\u5728\u5185\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u51cf\u8f7b\u4e86\u635f\u574f\u6570\u636e\u7684\u5f71\u54cd\uff0c\u5e76\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "ADG\u56e0\u5176\u901a\u7528\u6027\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u4efb\u4f55\u79bb\u7ebfRL\u7b97\u6cd5\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9762\u5bf9\u5404\u79cd\u566a\u58f0\u73af\u5883\u65f6\u7684\u6027\u80fd\u3002"}}
{"id": "2505.24181", "pdf": "https://arxiv.org/pdf/2505.24181", "abs": "https://arxiv.org/abs/2505.24181", "authors": ["Guanghao Li", "Wenhao Jiang", "Mingfeng Chen", "Yan Li", "Hao Yu", "Shuting Dong", "Tao Ren", "Ming Tang", "Chun Yuan"], "title": "SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought", "categories": ["cs.AI"], "comment": null, "summary": "Chain of Thought (CoT) prompting improves the reasoning performance of large\nlanguage models (LLMs) by encouraging step by step thinking. However, CoT-based\nmethods depend on intermediate reasoning steps, which limits scalability and\ngeneralization. Recent work explores recursive reasoning, where LLMs reuse\ninternal layers across iterations to refine latent representations without\nexplicit CoT supervision. While promising, these approaches often require\ncostly pretraining and lack a principled framework for how reasoning should\nevolve across iterations. We address this gap by introducing Flow Chain of\nThought (Flow CoT), a reasoning paradigm that models recursive inference as a\nprogressive trajectory of latent cognitive states. Flow CoT frames each\niteration as a distinct cognitive stage deepening reasoning across iterations\nwithout relying on manual supervision. To realize this, we propose SCOUT\n(Stepwise Cognitive Optimization Using Teachers), a lightweight fine tuning\nframework that enables Flow CoT style reasoning without the need for\npretraining. SCOUT uses progressive distillation to align each iteration with a\nteacher of appropriate capacity, and a cross attention based retrospective\nmodule that integrates outputs from previous iterations while preserving the\nmodels original computation flow. Experiments across eight reasoning benchmarks\nshow that SCOUT consistently improves both accuracy and explanation quality,\nachieving up to 1.8% gains under fine tuning. Qualitative analyses further\nreveal that SCOUT enables progressively deeper reasoning across iterations\nrefining both belief formation and explanation granularity. These results not\nonly validate the effectiveness of SCOUT, but also demonstrate the practical\nviability of Flow CoT as a scalable framework for enhancing reasoning in LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faFlow CoT\u63a8\u7406\u8303\u5f0f\u53ca\u5176\u5b9e\u73b0\u6846\u67b6SCOUT\uff0c\u5728\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u6216\u9884\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfCoT\u65b9\u6cd5\u4f9d\u8d56\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff1b\u73b0\u6709\u9012\u5f52\u63a8\u7406\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u9884\u8bad\u7ec3\u4e14\u7f3a\u4e4f\u7406\u8bba\u6846\u67b6\u6307\u5bfc\u63a8\u7406\u8fed\u4ee3\u6f14\u5316\u3002", "method": "\u63d0\u51fa\u4e86SCOUT\uff08Stepwise Cognitive Optimization Using Teachers\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u6e10\u8fdb\u84b8\u998f\u548c\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u56de\u987e\u6a21\u5757\u5b9e\u73b0Flow CoT\u63a8\u7406\u3002", "result": "\u57288\u4e2a\u63a8\u7406\u57fa\u51c6\u5b9e\u9a8c\u4e2d\uff0cSCOUT\u5728\u5fae\u8c03\u6761\u4ef6\u4e0b\u6700\u9ad8\u63d0\u5347\u4e861.8%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u63a8\u7406\u6df1\u5ea6\u548c\u89e3\u91ca\u7c92\u5ea6\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u8303\u5f0fFlow CoT\uff0c\u5e76\u901a\u8fc7SCOUT\u6846\u67b6\u9a8c\u8bc1\u4e86\u5176\u5728\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\u548c\u89e3\u91ca\u8d28\u91cf\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.24781", "pdf": "https://arxiv.org/pdf/2505.24781", "abs": "https://arxiv.org/abs/2505.24781", "authors": ["Karim Abou-Moustafa"], "title": "Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV", "categories": ["stat.ML", "cs.CE", "cs.CV", "cs.LG", "eess.SP", "I.2.0; I.2.6"], "comment": "An extended version of a short article that appeared in 2023 IEEE\n  Workshop on Information Theory, Saint-Malo, France", "summary": "We consider the problem of estimating a regularization parameter, or a\nshrinkage coefficient $\\alpha \\in (0,1)$ for Regularized Tyler's M-estimator\n(RTME). In particular, we propose to estimate an optimal shrinkage coefficient\nby setting $\\alpha$ as the solution to a suitably chosen objective function;\nnamely the leave-one-out cross-validated (LOOCV) log-likelihood loss. Since\nLOOCV is computationally prohibitive even for moderate sample size $n$, we\npropose a computationally efficient approximation for the LOOCV log-likelihood\nloss that eliminates the need for invoking the RTME procedure $n$ times for\neach sample left out during the LOOCV procedure. This approximation yields an\n$O(n)$ reduction in the running time complexity for the LOOCV procedure, which\nresults in a significant speedup for computing the LOOCV estimate. We\ndemonstrate the efficiency and accuracy of the proposed approach on synthetic\nhigh-dimensional data sampled from heavy-tailed elliptical distributions, as\nwell as on real high-dimensional datasets for object recognition, face\nrecognition, and handwritten digit's recognition. Our experiments show that the\nproposed approach is efficient and consistently more accurate than other\nmethods in the literature for shrinkage coefficient estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u65b9\u6cd5\u6765\u4f30\u8ba1\u6b63\u5219\u5316 Tyler M-\u4f30\u8ba1\u5668\u7684\u6536\u7f29\u7cfb\u6570\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u7684\u4f18\u52bf\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6b63\u5219\u5316\u53c2\u6570\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u901a\u8fc7\u8bbe\u7f6e\u4e00\u4e2a\u5408\u9002\u7684\u76ee \u6807\u51fd\u6570\uff0c\u5373\u7559\u4e00\u4ea4\u53c9\u9a8c\u8bc1\uff08LOOCV\uff09\u5bf9\u6570\u4f3c\u7136\u635f\u5931\uff0c\u6765\u4f30\u8ba1\u6700\u4f18\u6536\u7f29\u7cfb\u6570\u3002\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\u6765\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u9ad8\u7ef4\u6570\u636e\u548c\u771f\u5b9e\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u90fd\u4f18\u4e8e\u6587\u732e\u4e2d\u7684\u5176\u4ed6\u65b9\u6cd5\u3002"}}
{"id": "2505.23875", "pdf": "https://arxiv.org/pdf/2505.23875", "abs": "https://arxiv.org/abs/2505.23875", "authors": ["Peter Samoaa", "Marcus Vukojevic", "Morteza Haghir Chehreghani", "Antonio Longa"], "title": "A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph-level regression underpins many real-world applications, yet public\nbenchmarks remain heavily skewed toward molecular graphs and citation networks.\nThis limited diversity hinders progress on models that must generalize across\nboth homogeneous and heterogeneous graph structures. We introduce RelSC, a new\ngraph-regression dataset built from program graphs that combine syntactic and\nsemantic information extracted from source code. Each graph is labelled with\nthe execution-time cost of the corresponding program, providing a continuous\ntarget variable that differs markedly from those found in existing benchmarks.\nRelSC is released in two complementary variants. RelSC-H supplies rich node\nfeatures under a single (homogeneous) edge type, while RelSC-M preserves the\noriginal multi-relational structure, connecting nodes through multiple edge\ntypes that encode distinct semantic relationships. Together, these variants let\nresearchers probe how representation choice influences model behaviour. We\nevaluate a diverse set of graph neural network architectures on both variants\nof RelSC. The results reveal consistent performance differences between the\nhomogeneous and multi-relational settings, emphasising the importance of\nstructural representation. These findings demonstrate RelSC's value as a\nchallenging and versatile benchmark for advancing graph regression methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u56de\u5f52\u6570\u636e\u96c6RelSC\uff0c\u5e76\u901a\u8fc7\u8bc4\u4f30\u4e0d\u540c\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u7ed3\u6784\u8868\u793a\u5728\u56fe\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\u4e3b\u8981\u504f\u5411\u5206\u5b50\u56fe\u548c\u5f15\u7528\u7f51\u7edc\uff0c\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u963b\u788d\u4e86\u80fd\u591f\u5728\u540c\u8d28\u548c\u5f02\u8d28\u56fe\u7ed3\u6784\u95f4\u6cdb\u5316\u7684\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u56fe\u56de\u5f52\u6570\u636e\u96c6RelSC\uff0c\u5305\u542b\u4e24\u79cd\u53d8\u4f53RelSC-H\u548cRelSC-M\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e00\u7cfb\u5217\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728\u8fd9\u4e24\u4e2a\u53d8\u4f53\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u540c\u8d28\u4e0e\u591a\u5173\u7cfb\u8bbe\u7f6e\u4e4b\u95f4\u5b58\u5728\u4e00\u81f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7a81\u51fa\u4e86\u7ed3\u6784\u8868\u793a\u7684\u91cd\u8981\u6027\u3002", "conclusion": "RelSC\u7684\u5f15\u5165\u4e3a\u56fe\u56de\u5f52\u65b9\u6cd5\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u591a\u529f\u80fd\u7684\u57fa\u51c6\uff0c\u5f3a\u8c03\u4e86\u7ed3\u6784\u8868\u793a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.24197", "pdf": "https://arxiv.org/pdf/2505.24197", "abs": "https://arxiv.org/abs/2505.24197", "authors": ["Bhrij Patel", "Ashish Jagmohan", "Aditya Vempaty"], "title": "Learning API Functionality from Demonstrations for Tool-based Agents", "categories": ["cs.AI"], "comment": "18 Pages, 13 Figures, 5 Tables", "summary": "Digital tool-based agents that invoke external Application Programming\nInterfaces (APIs) often rely on documentation to understand API functionality.\nHowever, such documentation is frequently missing, outdated, privatized, or\ninconsistent-hindering the development of reliable, general-purpose agents. In\nthis work, we propose learning API functionality directly from demonstrations\nas a new paradigm applicable in scenarios without documentation. Using existing\nAPI benchmarks, we collect demonstrations from both expert API-based agents and\nfrom self-exploration. To understand what information demonstrations must\nconvey for successful task completion, we extensively study how the number of\ndemonstrations and the use of LLM-generated summaries and evaluations affect\nthe task success rate of the API-based agent. Our experiments across 3 datasets\nand 5 models show that learning functionality from demonstrations remains a\nnon-trivial challenge, even for state-of-the-art LLMs. We find that providing\nexplicit function calls and natural language critiques significantly improves\nthe agent's task success rate due to more accurate parameter filling. We\nanalyze failure modes, identify sources of error, and highlight key open\nchallenges for future work in documentation-free, self-improving, API-based\nagents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6ca1\u6709\u6587\u6863\u7684\u60c5\u51b5\u4e0b\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60API\u529f\u80fd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u73b0\u6709API\u57fa\u51c6\u6d4b\u8bd5\u6536\u96c6\u6f14\u793a\uff0c\u7814\u7a76\u6f14\u793a\u4fe1\u606f\u5bf9\u4efb\u52a1\u5b8c\u6210\u7684\u5f71\u54cd\u3002", "motivation": "\u6570\u5b57\u5de5\u5177\u4ee3\u7406\u901a\u5e38\u4f9d\u8d56\u6587\u6863\u6765\u7406\u89e3API\u529f\u80fd\uff0c\u4f46\u8fd9\u4e9b\u6587\u6863\u7ecf\u5e38\u7f3a\u5931\u3001\u8fc7\u65f6\u3001\u79c1\u6709\u5316\u6216\u4e0d\u4e00\u81f4\uff0c\u963b\u788d\u4e86\u53ef\u9760\u901a\u7528\u4ee3\u7406\u7684\u53d1\u5c55\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6587\u6863\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u73b0\u6709\u7684API\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ece\u4e13\u5bb6API\u4ee3\u7406\u548c\u81ea\u6211\u63a2\u7d22\u4e2d\u6536\u96c6\u6f14\u793a\u3002\u7814\u7a76\u6f14\u793a\u6570\u91cf\u4ee5\u53caLLM\u751f\u6210\u7684\u6458\u8981\u548c\u8bc4\u4f30\u5982\u4f55\u5f71\u54cd\u57fa\u4e8eAPI\u4ee3\u7406\u7684\u4efb\u52a1\u6210\u529f\u7387\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u57283\u4e2a\u6570\u636e\u96c6\u548c5\u4e2a\u6a21\u578b\u4e0a\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LLM\uff0c\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60API\u529f\u80fd\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u63d0\u4f9b\u660e\u786e\u7684\u51fd\u6570\u8c03\u7528\u548c\u81ea\u7136\u8bed\u8a00\u6279\u8bc4\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "\u5b66\u4e60API\u529f\u80fd\u4ecd\u7136\u662f\u4e00\u4e2a\u975e\u5e73\u51e1\u7684\u6311\u6218\uff0c\u5373\u4f7f\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684LLM\u4e5f\u662f\u5982\u6b64\u3002\u63d0\u4f9b\u660e\u786e\u7684\u51fd\u6570\u8c03\u7528\u548c\u81ea\u7136\u8bed\u8a00\u6279\u8bc4\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002\u8bba\u6587\u8fd8\u5206\u6790\u4e86\u5931\u8d25\u6a21\u5f0f\uff0c\u786e\u5b9a\u4e86\u9519\u8bef\u6765\u6e90\uff0c\u5e76\u5f3a\u8c03\u4e86\u672a\u6765\u5de5\u4f5c\u7684\u4e3b\u8981\u5f00\u653e\u6027\u6311\u6218\u3002"}}
{"id": "2505.24849", "pdf": "https://arxiv.org/pdf/2505.24849", "abs": "https://arxiv.org/abs/2505.24849", "authors": ["Jean Barbier", "Francesco Camilli", "Minh-Toan Nguyen", "Mauro Pastore", "Rudy Skerk"], "title": "Statistical mechanics of extensive-width Bayesian neural networks near interpolation", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.IT", "cs.LG", "math.IT"], "comment": "9 pages + appendices, 12 figures. This submission supersedes\n  arXiv:2501.18530", "summary": "For three decades statistical mechanics has been providing a framework to\nanalyse neural networks. However, the theoretically tractable models, e.g.,\nperceptrons, random features models and kernel machines, or multi-index models\nand committee machines with few neurons, remained simple compared to those used\nin applications. In this paper we help reducing the gap between practical\nnetworks and their theoretical understanding through a statistical physics\nanalysis of the supervised learning of a two-layer fully connected network with\ngeneric weight distribution and activation function, whose hidden layer is\nlarge but remains proportional to the inputs dimension. This makes it more\nrealistic than infinitely wide networks where no feature learning occurs, but\nalso more expressive than narrow ones or with fixed inner weights. We focus on\nthe Bayes-optimal learning in the teacher-student scenario, i.e., with a\ndataset generated by another network with the same architecture. We operate\naround interpolation, where the number of trainable parameters and of data are\ncomparable and feature learning emerges. Our analysis uncovers a rich\nphenomenology with various learning transitions as the number of data\nincreases. In particular, the more strongly the features (i.e., hidden neurons\nof the target) contribute to the observed responses, the less data is needed to\nlearn them. Moreover, when the data is scarce, the model only learns non-linear\ncombinations of the teacher weights, rather than \"specialising\" by aligning its\nweights with the teacher's. Specialisation occurs only when enough data becomes\navailable, but it can be hard to find for practical training algorithms,\npossibly due to statistical-to-computational~gaps.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7edf\u8ba1\u7269\u7406\u65b9\u6cd5\u5206\u6790\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u7279\u5f81\u5b66\u4e60\u7684\u52a8\u6001\u53d8\u5316\u53ca\u5176\u5bf9\u6570\u636e\u91cf\u7684\u4f9d\u8d56\u6027\u3002", "motivation": "\u7f29\u5c0f\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u4e0e\u7406\u8bba\u7814\u7a76\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u662f\u672c\u8bba\u6587\u7684\u4e3b\u8981\u52a8\u673a\u3002\u901a\u8fc7\u5206\u6790\u66f4\u63a5\u8fd1\u5b9e\u9645\u5e94\u7528\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u63d0\u5347\u7406\u8bba\u7406\u89e3\u3002", "method": "\u8bba\u6587\u91c7\u7528\u7edf\u8ba1\u7269\u7406\u5b66\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5177\u6709\u901a\u7528\u6743\u91cd\u5206\u5e03\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u5e76\u805a\u7126\u8d1d\u53f6\u65af\u6700\u4f18\u5b66\u4e60\u573a\u666f\u3002", "result": "\u53d1\u73b0\u4e86\u4e30\u5bcc\u7684\u73b0\u8c61\u5b66\uff0c\u5305\u62ec\u968f\u7740\u6570\u636e\u91cf\u589e\u52a0\u51fa\u73b0\u7684\u5404\u79cd\u5b66\u4e60\u8f6c\u6362\u3002\u7279\u5f81\u5b66\u4e60\u5728\u63d2\u503c\u533a\u57df\u9644\u8fd1\u66f4\u4e3a\u660e\u663e\uff0c\u800c\u7a00\u758f\u6570\u636e\u5bfc\u81f4\u6a21\u578b\u4f9d\u8d56\u975e\u7ebf\u6027\u7ec4\u5408\u800c\u975e\u6743\u91cd\u5bf9\u9f50\u3002", "conclusion": "\u901a\u8fc7\u7edf\u8ba1\u7269\u7406\u5b66\u5206\u6790\uff0c\u8bba\u6587\u63ed\u793a\u4e86\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u5404\u79cd\u5b66\u4e60\u8f6c\u6362\u73b0\u8c61\u3002\u5f53\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u5b66\u4e60\u6559\u5e08\u6743\u91cd\u7684\u975e\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u5bf9\u9f50\u6743\u91cd\u3002"}}
{"id": "2505.23876", "pdf": "https://arxiv.org/pdf/2505.23876", "abs": "https://arxiv.org/abs/2505.23876", "authors": ["Polad Geidarov"], "title": "A comparative analysis of a neural network with calculated weights and a neural network with random generation of weights based on the training dataset size", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The paper discusses the capabilities of multilayer perceptron neural networks\nimplementing metric recognition methods, for which the values of the weights\nare calculated analytically by formulas. Comparative experiments in training a\nneural network with pre-calculated weights and with random initialization of\nweights on different sizes of the MNIST training dataset are carried out. The\nresults of the experiments show that a multilayer perceptron with\npre-calculated weights can be trained much faster and is much more robust to\nthe reduction of the training dataset.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u5206\u6790\u516c\u5f0f\u9884\u8ba1\u7b97\u6743\u91cd\u7684\u591a\u5c42\u611f\u77e5\u673a\uff0c\u53d1\u73b0\u5176\u5728\u8bad\u7ec3\u901f\u5ea6\u548c\u5c0f\u6570\u636e\u96c6\u8868\u73b0\u4e0a\u663e\u8457\u4f18\u4e8e\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u65b9\u6cd5\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6548\u7387\u548c\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u4f9d\u8d56\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u4f7f\u7528\u5206\u6790\u516c\u5f0f\u9884\u5148\u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\uff0c\u5e76\u4e0e\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u8fdb\u884c\u6bd4\u8f83\uff0c\u5728\u4e0d\u540c\u5927\u5c0f\u7684MNIST\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5177\u6709\u9884\u8ba1\u7b97\u6743\u91cd\u7684\u591a\u5c42\u611f\u77e5\u673a\u53ef\u4ee5\u66f4\u5feb\u5730\u8bad\u7ec3\uff0c\u5e76\u4e14\u5bf9\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u51cf\u5c11\u66f4\u52a0\u9c81\u68d2\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5177\u6709\u9884\u8ba1\u7b97\u6743\u91cd\u7684\u591a\u5c42\u611f\u77e5\u673a\u5728\u8bad\u7ec3\u901f\u5ea6\u548c\u5bf9\u8bad\u7ec3\u6570\u636e\u96c6\u51cf\u5c11\u7684\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u968f\u673a\u521d\u59cb\u5316\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u3002"}}
{"id": "2505.24201", "pdf": "https://arxiv.org/pdf/2505.24201", "abs": "https://arxiv.org/abs/2505.24201", "authors": ["Xu He", "Di Wu", "Yan Zhai", "Kun Sun"], "title": "SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "The rise of large language model (LLM)-based multi-agent systems (MAS)\nintroduces new security and reliability challenges. While these systems show\ngreat promise in decomposing and coordinating complex tasks, they also face\nmulti-faceted risks across prompt manipulation, unsafe tool usage, and emergent\nagent miscoordination. Existing guardrail mechanisms offer only partial\nprotection, primarily at the input-output level, and fall short in addressing\nsystemic or multi-point failures in MAS. In this work, we present a\nsystem-level anomaly detection framework tailored for MAS, integrating\nstructural modeling with runtime behavioral oversight. Our approach consists of\ntwo components. First, we propose a graph-based framework that models agent\ninteractions as dynamic execution graphs, enabling semantic anomaly detection\nat node, edge, and path levels. Second, we introduce a pluggable SentinelAgent,\nan LLM-powered oversight agent that observes, analyzes, and intervenes in MAS\nexecution based on security policies and contextual reasoning. By bridging\nabstract detection logic with actionable enforcement, our method detects not\nonly single-point faults and prompt injections but also multi-agent collusion\nand latent exploit paths. We validate our framework through two case studies,\nincluding an email assistant and Microsoft's Magentic-One system, demonstrating\nits ability to detect covert risks and provide explainable root-cause\nattribution. Our work lays the foundation for more trustworthy, monitorable,\nand secure agent-based AI ecosystems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u4e86\u4e00\u4e2a\u9488\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7cfb\u7edf\u7ea7\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3a\u57fa\u7840\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6846\u67b6\u548c\u4e00\u4e2a\u53ef\u63d2\u62d4\u7684SentinelAgent\u6765\u89c2\u5bdf\u3001\u5206\u6790\u548c\u5e72\u9884MAS\u6267\u884c\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u80fd\u529b\uff0c\u5305\u62ec\u7535\u5b50\u90ae\u4ef6\u52a9\u624b\u548c\u5fae\u8f6f\u7684Magentic-One\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5176\u68c0\u6d4b\u9690\u853d\u98ce\u9669\u548c\u63d0\u4f9b\u53ef\u89e3\u91ca\u6839\u672c\u539f\u56e0\u5f52\u56e0\u7684\u80fd\u529b\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u4e3aMAS\u63d0\u4f9b\u4e86\u66f4\u53ef\u4fe1\u3001\u53ef\u76d1\u63a7\u548c\u5b89\u5168\u7684AI\u751f\u6001\u7cfb\u7edf\u57fa\u7840\u3002"}}
{"id": "2505.23913", "pdf": "https://arxiv.org/pdf/2505.23913", "abs": "https://arxiv.org/abs/2505.23913", "authors": ["Gustavo Sutter Pessurno de Carvalho", "Mohammed Abdulrahman", "Hao Wang", "Sriram Ganapathi Subramanian", "Marc St-Aubin", "Sharon O'Sullivan", "Lawrence Wan", "Luis Ricardez-Sandoval", "Pascal Poupart", "Agustinus Kristiadi"], "title": "Simplifying Bayesian Optimization Via In-Context Direct Optimum Sampling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The optimization of expensive black-box functions is ubiquitous in science\nand engineering. A common solution to this problem is Bayesian optimization\n(BO), which is generally comprised of two components: (i) a surrogate model and\n(ii) an acquisition function, which generally require expensive re-training and\noptimization steps at each iteration, respectively. Although recent work\nenabled in-context surrogate models that do not require re-training, virtually\nall existing BO methods still require acquisition function maximization to\nselect the next observation, which introduces many knobs to tune, such as Monte\nCarlo samplers and multi-start optimizers. In this work, we propose a\ncompletely in-context, zero-shot solution for BO that does not require\nsurrogate fitting or acquisition function optimization. This is done by using a\npre-trained deep generative model to directly sample from the posterior over\nthe optimum point. We show that this process is equivalent to Thompson sampling\nand demonstrate the capabilities and cost-effectiveness of our foundation model\non a suite of real-world benchmarks. We achieve an efficiency gain of more than\n35x in terms of wall-clock time when compared with Gaussian process-based BO,\nenabling efficient parallel and distributed BO, e.g., for high-throughput\noptimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4ee3\u7406\u62df\u5408\u6216\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u7684\u5168\u65b0\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u91c7\u6837\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u518d\u8bad\u7ec3\u548c\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u6b65\u9aa4\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u76f4\u63a5\u4ece\u6700\u4f18\u89e3\u70b9\u7684\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4ece\u800c\u5b9e\u73b0\u6c64\u666e\u68ee\u62bd\u6837\u8fc7\u7a0b\u3002", "result": "\u4e0e\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u76f8\u6bd4\uff0c\u5728\u5899\u949f\u65f6\u95f4\u65b9\u9762\u5b9e\u73b0\u4e86\u8d85\u8fc735\u500d\u7684\u6548\u7387\u63d0\u5347\uff0c\u5e76\u652f\u6301\u9ad8\u6548\u7684\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u4e0a\u4e0b\u6587\u5185\u3001\u96f6\u6837\u672c\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u4e0d\u9700\u8981\u4ee3\u7406\u62df\u5408\u6216\u83b7\u53d6\u51fd\u6570\u4f18\u5316\uff0c\u5e76\u5728\u5b9e\u9645\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u9ad8\u6548\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2505.23878", "pdf": "https://arxiv.org/pdf/2505.23878", "abs": "https://arxiv.org/abs/2505.23878", "authors": ["Jing Ma", "Chenhao Dang", "Mingjie Liao"], "title": "Actor-Critic based Online Data Mixing For Language Model Pre-Training", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "The coverage and composition of pretraining data significantly impacts the\ngeneralization ability of Large Language Models (LLMs). To reduce the carbon\nfootprint and financial costs of training, some data mixing methods, which\napplied the optimized domain weights of a small proxy model to train a larger\none, were proposed. However, these methods did not evolute with the training\ndynamics. The existing online data mixing (ODM) method addressed this\nlimitation by applying the multi-armed bandit algorithm as data sampling\nstrategy. Yet, it did not consider the intra-domain interactions. In this\npaper, we develop an actor-critic based online data mixing (AC-ODM) method,\nwhich captures the varying domain weights by auxiliary actor-critic networks\nand consider the intra-domain interactions with the reward function. While\nconstructing the dataset to pretrain a large target LLM, we directly apply the\nactor, which is trained with a small proxy LLM as the environment, as the\nsampling strategy. The transfer of sampling strategy can not only ensure the\nefficiency of dynamical data mixing, but also expedite the convergence of\npretraining the target LLM. Numerical results demonstrate that AC-ODM-410M,\nwhich invokes the sampling strategy obtained by a proxy LLM with 410M\nparameters, reaching the optimal validation perplexity of ODM 71% faster, and\nimproves performance on the zero-shot MMLU benchmark by 27.5% of accuracy,\nabout 2.23x better on pass@1 of HumanEval benchmark.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u6570\u636e\u6df7\u5408\u65b9\u6cd5AC-ODM\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11\u8bad\u7ec3\u7684\u78b3\u8db3\u8ff9\u548c\u8d22\u52a1\u6210\u672c\uff0c\u4e00\u4e9b\u6570\u636e\u6df7\u5408\u65b9\u6cd5\u88ab\u63d0\u51fa\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u672a\u80fd\u968f\u7740\u8bad\u7ec3\u52a8\u6001\u6f14\u53d8\u3002\u73b0\u6709\u7684\u5728\u7ebf\u6570\u636e\u6df7\u5408\uff08ODM\uff09\u65b9\u6cd5\u867d\u7136\u89e3\u51b3\u4e86\u8fd9\u4e00\u9650\u5236\uff0c\u4f46\u672a\u8003\u8651\u9886\u57df\u5185\u4e92\u52a8\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eactor-critic\u7684\u5728\u7ebf\u6570\u636e\u6df7\u5408\uff08AC-ODM\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u8f85\u52a9\u7684actor-critic\u7f51\u7edc\u6355\u6349\u53d8\u5316\u7684\u9886\u57df\u6743\u91cd\uff0c\u5e76\u901a\u8fc7\u5956\u52b1\u51fd\u6570\u8003\u8651\u9886\u57df\u5185\u4e92\u52a8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAC-ODM-410M\u6bd4ODM\u66f4\u5feb\u8fbe\u5230\u6700\u4f73\u9a8c\u8bc1\u56f0\u60d1\u5ea6\uff0c\u5e76\u5728\u96f6\u6837\u672cMMLU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u63d0\u9ad8\u4e8627.5%\uff0c\u5728HumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684pass@1\u8868\u73b0\u4e5f\u66f4\u597d\u3002", "conclusion": "AC-ODM\u65b9\u6cd5\u901a\u8fc7\u6355\u83b7\u53d8\u5316\u7684\u9886\u57df\u6743\u91cd\u5e76\u8003\u8651\u9886\u57df\u5185\u4e92\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2505.24208", "pdf": "https://arxiv.org/pdf/2505.24208", "abs": "https://arxiv.org/abs/2505.24208", "authors": ["Wenhan Yang", "Spencer Stice", "Ali Payani", "Baharan Mirzasoleiman"], "title": "Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap", "categories": ["cs.AI"], "comment": null, "summary": "Ensuring Vision-Language Models (VLMs) generate safe outputs is crucial for\ntheir reliable deployment. However, LVLMs suffer from drastic safety\ndegradation compared to their LLM backbone. Even blank or irrelevant images can\ntrigger LVLMs to generate harmful responses to prompts that would otherwise be\nrefused in text-only contexts. The modality gap between image and text\nrepresentations has been recently hypothesized to contribute to safety\ndegradation of LVLMs. However, if and how the amount of modality gap affects\nLVLMs' safety is not studied. In this work, we show that the amount of modality\ngap is highly inversely correlated with VLMs' safety. Then, we show that this\nmodality gap is introduced during pretraining LVLMs and persists through\nfine-tuning. Inspired by this observation, we propose a regularization to\nreduce the modality gap during pretraining. Our extensive experiments on LLaVA\nv1.5, ShareGPT4V, and MiniGPT-4 show that our method substantially improves\nsafety alignment of LVLMs, reducing unsafe rate by up to 16.3% without\ncompromising performance, and can further boost existing defenses by up to\n18.2%.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u6a21\u6001\u5dee\u8ddd\u8d8a\u5927\uff0c\u5b89\u5168\u6027\u8d8a\u5dee\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u51cf\u5c11\u8fd9\u79cd\u5dee\u8ddd\uff0c\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u76f8\u6bd4\u5176\u6587\u672c\u6a21\u578b\u4e3b\u5e72\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u6027\u4e0b\u964d\u95ee\u9898\uff0c\u5373\u4f7f\u9762\u5bf9\u7a7a\u767d\u6216\u65e0\u5173\u56fe\u50cf\u4e5f\u53ef\u80fd\u751f\u6210\u6709\u5bb3\u54cd\u5e94\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6a21\u6001\u5dee\u8ddd\u4e0e\u6a21\u578b\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u5e76\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u6b63\u5219\u5316\u6765\u7f29\u5c0f\u8fd9\u79cd\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06\u4e0d\u5b89\u5168\u7387\u964d\u4f4e\u4e86\u6700\u591a16.3%\uff0c\u5e76\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u73b0\u6709\u9632\u5fa1\u673a\u5236\u6548\u679c\u8fbe18.2%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9884\u8bad\u7ec3\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6a21\u6001\u5dee\u8ddd\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u5176\u5b89\u5168\u6027\u5bf9\u9f50\uff0c\u5e76\u4e14\u4e0d\u635f\u5bb3\u6027\u80fd\u3002"}}
{"id": "2505.24022", "pdf": "https://arxiv.org/pdf/2505.24022", "abs": "https://arxiv.org/abs/2505.24022", "authors": ["Bhavya Vasudeva", "Jung Whan Lee", "Vatsal Sharan", "Mahdi Soltanolkotabi"], "title": "The Rich and the Simple: On the Implicit Bias of Adam and SGD", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "27 pages, 11 figures, 16 tables", "summary": "Adam is the de facto optimization algorithm for several deep learning\napplications, but an understanding of its implicit bias and how it differs from\nother algorithms, particularly standard first-order methods such as\n(stochastic) gradient descent (GD), remains limited. In practice, neural\nnetworks trained with SGD are known to exhibit simplicity bias -- a tendency to\nfind simple solutions. In contrast, we show that Adam is more resistant to such\nsimplicity bias. To demystify this phenomenon, in this paper, we investigate\nthe differences in the implicit biases of Adam and GD when training two-layer\nReLU neural networks on a binary classification task involving synthetic data\nwith Gaussian clusters. We find that GD exhibits a simplicity bias, resulting\nin a linear decision boundary with a suboptimal margin, whereas Adam leads to\nmuch richer and more diverse features, producing a nonlinear boundary that is\ncloser to the Bayes' optimal predictor. This richer decision boundary also\nallows Adam to achieve higher test accuracy both in-distribution and under\ncertain distribution shifts. We theoretically prove these results by analyzing\nthe population gradients. To corroborate our theoretical findings, we present\nempirical results showing that this property of Adam leads to superior\ngeneralization across datasets with spurious correlations where neural networks\ntrained with SGD are known to show simplicity bias and don't generalize well\nunder certain distributional shifts.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Adam\u548cGD\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\u7684\u9690\u5f0f\u504f\u5dee\u5dee\u5f02\uff0c\u53d1\u73b0Adam\u6bd4GD\u66f4\u80fd\u62b5\u6297\u7b80\u5355\u6027\u504f\u5dee\uff0c\u80fd\u751f\u6210\u66f4\u590d\u6742\u7684\u6a21\u578b\u5e76\u53d6\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1Adam\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u9690\u5f0f\u504f\u5dee\u4e0eGD\u7b49\u4f18\u5316\u7b97\u6cd5\u7684\u5dee\u5f02\u5c1a\u4e0d\u660e\u786e\uff0c\u5c24\u5176\u662f\u5176\u5bf9\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e24\u5c42ReLU\u795e\u7ecf\u7f51\u7edc\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u7814\u7a76Adam\u548cGD\u7684\u9690\u5f0f\u504f\u5dee\u5dee\u5f02\uff0c\u5e76\u7ed3\u5408\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u8bc1\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "GD\u503e\u5411\u4e8e\u4ea7\u751f\u7b80\u5355\u4e14\u6b21\u4f18\u7684\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\uff0c\u800cAdam\u80fd\u591f\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u548c\u975e\u7ebf\u6027\u8fb9\u754c\uff0c\u66f4\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\u5668\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "Adam\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\u76f8\u6bd4GD\u5177\u6709\u66f4\u4f18\u7684\u6cdb\u5316\u80fd\u529b\u548c\u62b5\u6297\u7b80\u5355\u6027\u504f\u5dee\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u5206\u5e03\u504f\u79fb\u548c\u865a\u5047\u76f8\u5173\u6027\u5b58\u5728\u65f6\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2505.23879", "pdf": "https://arxiv.org/pdf/2505.23879", "abs": "https://arxiv.org/abs/2505.23879", "authors": ["Caio Cheohen", "Vinn\u00edcius M. S. Gomes", "Manuela L. da Silva"], "title": "CNN-LSTM Hybrid Model for AI-Driven Prediction of COVID-19 Severity from Spike Sequences and Clinical Data", "categories": ["cs.LG", "cs.AI", "68T07, 62P10, 92C50, 68T05", "I.2.6; I.5.1; J.3"], "comment": "12 pages, 4 figures, 4 tables", "summary": "The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need\nfor accurate prediction of disease severity to optimize healthcare resource\nallocation and patient management. The spike protein, which facilitates viral\nentry into host cells, exhibits high mutation rates, particularly in the\nreceptor-binding domain, influencing viral pathogenicity. Artificial\nintelligence approaches, such as deep learning, offer promising solutions for\nleveraging genomic and clinical data to predict disease outcomes. Objective:\nThis study aimed to develop a hybrid CNN-LSTM deep learning model to predict\nCOVID-19 severity using spike protein sequences and associated clinical\nmetadata from South American patients. Methods: We retrieved 9,570 spike\nprotein sequences from the GISAID database, of which 3,467 met inclusion\ncriteria after standardization. The dataset included 2,313 severe and 1,154\nmild cases. A feature engineering pipeline extracted features from sequences,\nwhile demographic and clinical variables were one-hot encoded. A hybrid\nCNN-LSTM architecture was trained, combining CNN layers for local pattern\nextraction and an LSTM layer for long-term dependency modeling. Results: The\nmodel achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%,\nand recall of 82.85%, demonstrating robust classification performance. Training\nstabilized at 85% accuracy with minimal overfitting. The most prevalent\nlineages (P.1, AY.99.2) and clades (GR, GK) aligned with regional\nepidemiological trends, suggesting potential associations between viral\ngenetics and clinical outcomes. Conclusion: The CNN-LSTM hybrid model\neffectively predicted COVID-19 severity using spike protein sequences and\nclinical data, highlighting the utility of AI in genomic surveillance and\nprecision public health. Despite limitations, this approach provides a\nframework for early severity prediction in future outbreaks.", "AI": {"tldr": "This paper develops a deep learning model to predict the severity of  COVID-19 based on genetic and clinical data.", "motivation": "The study aimed to develop a hybrid CNN-LSTM deep learning model to predict  COVID-19 severity using spike protein sequences and associated clinical metadata from South American patients.", "method": "A hybrid CNN-LSTM architecture was trained, combining CNN layers for local pattern extraction and an LSTM layer for long-term dependency modeling.", "result": "The model achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%, and recall of 82.85%, demonstrating robust classification performance.", "conclusion": "The CNN-LSTM hybrid model effectively predicted COVID-19 severity using spike protein sequences and clinical data, highlighting the utility of AI in genomic surveillance and precision public health."}}
{"id": "2505.24226", "pdf": "https://arxiv.org/pdf/2505.24226", "abs": "https://arxiv.org/abs/2505.24226", "authors": ["Yibo Zhao", "Jiapeng Zhu", "Ye Guo", "Kangkang He", "Xiang Li"], "title": "E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness", "categories": ["cs.AI"], "comment": "16 pages", "summary": "Graph-based RAG methods like GraphRAG have shown promising global\nunderstanding of the knowledge base by constructing hierarchical entity graphs.\nHowever, they often suffer from inefficiency and rely on manually pre-defined\nquery modes, limiting practical use. In this paper, we propose E^2GraphRAG, a\nstreamlined graph-based RAG framework that improves both Efficiency and\nEffectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree\nwith large language models and an entity graph with SpaCy based on document\nchunks. We then construct bidirectional indexes between entities and chunks to\ncapture their many-to-many relationships, enabling fast lookup during both\nlocal and global retrieval. For the retrieval stage, we design an adaptive\nretrieval strategy that leverages the graph structure to retrieve and select\nbetween local and global modes. Experiments show that E^2GraphRAG achieves up\nto 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG\nin retrieval while maintaining competitive QA performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u56fe\u7684RAG\u6846\u67b6E^2GraphRAG\uff0c\u5176\u901a\u8fc7\u4f18\u5316\u7d22\u5f15\u548c\u68c0\u7d22\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u826f\u597d\u95ee\u7b54\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5904\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\uff08\u5982GraphRAG\uff09\u6548\u7387\u4f4e\u4e0b\u4e14\u4f9d\u8d56\u624b\u52a8\u9884\u5b9a\u4e49\u67e5\u8be2\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u6458\u8981\u6811\u548c\u5b9e\u4f53\u56fe\u7684\u7d22\u5f15\u7ed3\u6784\uff0c\u5e76\u8bbe\u8ba1\u4e86\u53cc\u5411\u7d22\u5f15\u4e0e\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cE^2GraphRAG\u7684\u7d22\u5f15\u901f\u5ea6\u6bd4GraphRAG\u5feb10\u500d\uff0c\u68c0\u7d22\u901f\u5ea6\u6bd4LightRAG\u5feb100\u500d\u3002", "conclusion": "E^2GraphRAG\u5728\u4fdd\u6301\u7ade\u4e89\u529bQA\u6027\u80fd\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u6539\u8fdb\u7d22\u5f15\u548c\u68c0\u7d22\u9636\u6bb5\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\u7684\u5904\u7406\u901f\u5ea6\u3002"}}
{"id": "2505.24060", "pdf": "https://arxiv.org/pdf/2505.24060", "abs": "https://arxiv.org/abs/2505.24060", "authors": ["Chris Mingard", "Lukas Seier", "Niclas G\u00f6ring", "Andrei-Vlad Badelita", "Charles London", "Ard Louis"], "title": "Characterising the Inductive Biases of Neural Networks on Boolean Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Deep neural networks are renowned for their ability to generalise well across\ndiverse tasks, even when heavily overparameterized. Existing works offer only\npartial explanations (for example, the NTK-based task-model alignment\nexplanation neglects feature learning). Here, we provide an end-to-end,\nanalytically tractable case study that links a network's inductive prior, its\ntraining dynamics including feature learning, and its eventual generalisation.\nSpecifically, we exploit the one-to-one correspondence between depth-2 discrete\nfully connected networks and disjunctive normal form (DNF) formulas by training\non Boolean functions. Under a Monte Carlo learning algorithm, our model\nexhibits predictable training dynamics and the emergence of interpretable\nfeatures. This framework allows us to trace, in detail, how inductive bias and\nfeature formation drive generalisation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5f52\u7eb3\u504f\u7f6e\u548c\u7279\u5f81\u5b66\u4e60\u5982\u4f55\u5f71\u54cd\u5176\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u53ef\u89e3\u6790\u7684\u6848\u4f8b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u7684\u5de5\u4f5c\u53ea\u80fd\u90e8\u5206\u89e3\u91ca\u8fc7\u53c2\u6570\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e3a\u4f55\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\uff0c\u4f8b\u5982\u57fa\u4e8eNTK\u7684\u4efb\u52a1-\u6a21\u578b\u5bf9\u9f50\u89e3\u91ca\u5ffd\u7565\u4e86\u7279\u5f81\u5b66\u4e60\u3002", "method": "\u5229\u7528\u6df1\u5ea6-2\u79bb\u6563\u5168\u8fde\u63a5\u7f51\u7edc\u4e0e\u6790\u53d6\u8303\u5f0f\uff08DNF\uff09\u516c\u5f0f\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5728\u5e03\u5c14\u51fd\u6570\u4e0a\u8fdb\u884c\u8bad\u7ec3\u4ee5\u7814\u7a76\u6a21\u578b\u7684\u5b66\u4e60\u52a8\u6001\u548c\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u51fa\u73b0\u3002", "result": "\u5728\u8499\u7279\u5361\u6d1b\u5b66\u4e60\u7b97\u6cd5\u4e0b\uff0c\u6a21\u578b\u5c55\u793a\u4e86\u53ef\u9884\u6d4b\u7684\u8bad\u7ec3\u52a8\u6001\u548c\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u51fa\u73b0\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u5f52\u7eb3\u5148\u9a8c\u5230\u6cdb\u5316\u80fd\u529b\u7684\u7aef\u5230\u7aef\u89e3\u6790\u6848\u4f8b\u7814\u7a76\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5f52\u7eb3\u5148\u9a8c\u548c\u7279\u5f81\u5f62\u6210\u53ef\u4ee5\u8be6\u7ec6\u89e3\u91ca\u5176\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2505.23884", "pdf": "https://arxiv.org/pdf/2505.23884", "abs": "https://arxiv.org/abs/2505.23884", "authors": ["Tianyuan Zhang", "Sai Bi", "Yicong Hong", "Kai Zhang", "Fujun Luan", "Songlin Yang", "Kalyan Sunkavalli", "William T. Freeman", "Hao Tan"], "title": "Test-Time Training Done Right", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "32 pages, 11 figures", "summary": "Test-Time Training (TTT) models context dependencies by adapting part of the\nmodel's weights (referred to as fast weights) during inference. This fast\nweight, akin to recurrent states in RNNs, stores temporary memories of past\ntokens in the current sequence. Existing TTT methods struggled to show\neffectiveness in handling long-context data, due to their inefficiency on\nmodern GPUs. The TTT layers in many of these approaches operate with extremely\nlow FLOPs utilization (often <5%) because they deliberately apply small online\nminibatch sizes (e.g., updating fast weights every 16 or 64 tokens). Moreover,\na small minibatch implies fine-grained block-wise causal dependencies in the\ndata, unsuitable for data beyond 1D ordered sequences, like sets or\nN-dimensional grids such as images or videos. In contrast, we pursue the\nopposite direction by using an extremely large chunk update, ranging from 2K to\n1M tokens across tasks of varying modalities, which we refer to as Large Chunk\nTest-Time Training (LaCT). It improves hardware utilization by orders of\nmagnitude, and more importantly, facilitates scaling of nonlinear state size\n(up to 40% of model parameters), hence substantially improving state capacity,\nall without requiring cumbersome and error-prone kernel implementations. It\nalso allows easy integration of sophisticated optimizers, e.g. Muon for online\nupdates. We validate our approach across diverse modalities and tasks,\nincluding novel view synthesis with image set, language models, and\nauto-regressive video diffusion. Our approach can scale up to 14B-parameter AR\nvideo diffusion model on sequences up to 56K tokens. In our longest sequence\nexperiment, we perform novel view synthesis with 1 million context length. We\nhope this work will inspire and accelerate new research in the field of\nlong-context modeling and test-time training. Website:\nhttps://tianyuanzhang.com/projects/ttt-done-right", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u65b9\u6cd5LaCT\uff0c\u5b83\u901a\u8fc7\u5927\u89c4\u6a21\u5757\u66f4\u65b0\u89e3\u51b3\u4e86\u4f20\u7edfTTT\u65b9\u6cd5\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u65f6\u6548\u7387\u4f4e\u4e0b\u548c\u72b6\u6001\u5bb9\u91cf\u53d7\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684TTT\u65b9\u6cd5\u7531\u4e8e\u5728\u73b0\u4ee3GPU\u4e0a\u7684\u4f4e\u6548\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u91c7\u7528\u4e86Large Chunk Test-Time Training (LaCT) \u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5bf9\u6a21\u578b\u7684\u90e8\u5206\u6743\u91cd\u8fdb\u884c\u9002\u5e94\u6027\u8c03\u6574\uff0c\u5e76\u5229\u7528\u5927\u89c4\u6a21\u5757\u66f4\u65b0\uff08\u4ece2K\u52301M\u4e2atoken\uff09\u6765\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u72b6\u6001\u5bb9\u91cf\u3002", "result": "LaCT\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u786c\u4ef6\u5229\u7528\u7387\uff0c\u540c\u65f6\u80fd\u591f\u6269\u5c55\u975e\u7ebf\u6027\u72b6\u6001\u5927\u5c0f\uff0c\u652f\u6301\u590d\u6742\u4f18\u5316\u5668\u7684\u5e94\u7528\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u6001\uff0c\u5305\u62ec\u8bed\u8a00\u6a21\u578b\u3001\u56fe\u50cf\u96c6\u7684\u65b0\u89c6\u89d2\u5408\u6210\u4ee5\u53ca\u81ea\u56de\u5f52\u89c6\u9891\u6269\u6563\u6a21\u578b\u7b49\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u65b9\u6cd5LaCT\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u5927\u89c4\u6a21\u5757\u66f4\u65b0\u663e\u8457\u63d0\u9ad8\u4e86\u786c\u4ef6\u5229\u7528\u7387\u548c\u6a21\u578b\u7684\u975e\u7ebf\u6027\u72b6\u6001\u89c4\u6a21\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u7684\u80fd\u529b\u3002"}}
{"id": "2505.24230", "pdf": "https://arxiv.org/pdf/2505.24230", "abs": "https://arxiv.org/abs/2505.24230", "authors": ["Murari Ambati"], "title": "ProofNet++: A Neuro-Symbolic System for Formal Proof Verification with Self-Correction", "categories": ["cs.AI"], "comment": "6 pages, 2 figures", "summary": "We propose ProofNet++, a neuro-symbolic framework that enhances automated\ntheorem proving by combining large language models (LLMs) with formal proof\nverification and self-correction mechanisms. Current LLM-based systems suffer\nfrom hallucinated logical steps and unverifiable reasoning. ProofNet++\nmitigates these limitations by integrating symbolic proof tree supervision, a\nreinforcement learning loop using verifiers as reward functions, and an\niterative self-correction module. Our experiments on miniF2F, Lean's mathlib,\nand HOL Light show that ProofNet++ significantly improves proof accuracy,\ncorrectness, and formal verifiability over prior models. We provide theoretical\nanalysis of the convergence and stability of the verifier-guided RL framework\nand release our datasets and codebase for future research.", "AI": {"tldr": "ProofNet++ \u662f\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7b26\u53f7\u65b9\u6cd5\u7684\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7b26\u53f7\u76d1\u7763\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u6211\u4fee\u6b63\u673a\u5236\uff0c\u63d0\u9ad8\u4e86\u8bc1\u660e\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e LLM \u7684\u7cfb\u7edf\u5b58\u5728\u903b\u8f91\u6b65\u9aa4\u5e7b\u89c9\u548c\u4e0d\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u63d0\u9ad8\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u7684\u51c6\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u5316\u8bc1\u660e\u9a8c\u8bc1\u53ca\u81ea\u6211\u4fee\u6b63\u673a\u5236\uff0c\u5f15\u5165\u7b26\u53f7\u8bc1\u660e\u6811\u76d1\u7763\u3001\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7684\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4ee5\u53ca\u8fed\u4ee3\u81ea\u6211\u4fee\u6b63\u6a21\u5757\u3002", "result": "\u5728 miniF2F\u3001Lean \u7684 mathlib \u548c HOL Light \u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cProofNet++ \u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u6a21\u578b\uff0c\u5728\u8bc1\u660e\u51c6\u786e\u6027\u548c\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "ProofNet++ \u5728\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3001\u6b63\u786e\u6027\u548c\u5f62\u5f0f\u9a8c\u8bc1\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u8d44\u6e90\u652f\u6301\u3002"}}
{"id": "2505.24205", "pdf": "https://arxiv.org/pdf/2505.24205", "abs": "https://arxiv.org/abs/2505.24205", "authors": ["Mingze Wang", "Weinan E"], "title": "On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "18 pages", "summary": "Mixture-of-experts networks (MoEs) have demonstrated remarkable efficiency in\nmodern deep learning. Despite their empirical success, the theoretical\nfoundations underlying their ability to model complex tasks remain poorly\nunderstood. In this work, we conduct a systematic study of the expressive power\nof MoEs in modeling complex tasks with two common structural priors:\nlow-dimensionality and sparsity. For shallow MoEs, we prove that they can\nefficiently approximate functions supported on low-dimensional manifolds,\novercoming the curse of dimensionality. For deep MoEs, we show that\n$\\cO(L)$-layer MoEs with $E$ experts per layer can approximate piecewise\nfunctions comprising $E^L$ pieces with compositional sparsity, i.e., they can\nexhibit an exponential number of structured tasks. Our analysis reveals the\nroles of critical architectural components and hyperparameters in MoEs,\nincluding the gating mechanism, expert networks, the number of experts, and the\nnumber of layers, and offers natural suggestions for MoE variants.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc\uff08MoEs\uff09\u5728\u5efa\u6a21\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8868\u660e\u5176\u5728\u5904\u7406\u4f4e\u7ef4\u548c\u7a00\u758f\u7ed3\u6784\u4efb\u52a1\u65f6\u7684\u9ad8\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u7f51\u7edc\u67b6\u6784\u5173\u952e\u56e0\u7d20\u7684\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1MoE\u7f51\u7edc\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u5c1a\u4e0d\u5b8c\u5584\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u5176\u5efa\u6a21\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\u7814\u7a76\u4e86\u6d45\u5c42\u548c\u6df1\u5c42MoE\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u903c\u8fd1\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u7684\u51fd\u6570\u548c\u652f\u6301\u7ec4\u5408\u7a00\u758f\u5206\u6bb5\u51fd\u6570\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u8bba\u6587\u8bc1\u660e\u4e86\u6d45\u5c42MoE\u80fd\u591f\u9ad8\u6548\u903c\u8fd1\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u7684\u51fd\u6570\uff0c\u800c\u6df1\u5ea6MoE\u5219\u53ef\u4ee5\u903c\u8fd1\u5177\u6709\u7ec4\u5408\u7a00\u758f\u6027\u7684\u5927\u91cf\u5206\u6bb5\u51fd\u6570\uff08\u5982$E^L$\u7247\u6bb5\uff09\uff0c\u4e14\u5c42\u6570\u548c\u4e13\u5bb6\u6570\u5bf9\u5176\u6548\u679c\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u8bba\u6587\u5f97\u51faMoE\u7f51\u7edc\u5728\u5efa\u6a21\u590d\u6742\u4efb\u52a1\u65f6\u5177\u5907\u9ad8\u6548\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5177\u6709\u4f4e\u7ef4\u5ea6\u548c\u7a00\u758f\u6027\u7279\u5f81\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u5173\u952e\u67b6\u6784\u7ec4\u4ef6\u7684\u4f5c\u7528\u3002"}}
{"id": "2505.24258", "pdf": "https://arxiv.org/pdf/2505.24258", "abs": "https://arxiv.org/abs/2505.24258", "authors": ["Vishal Pallagani", "Nitin Gupta", "John Aydin", "Biplav Srivastava"], "title": "FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Understanding how data moves, transforms, and persists, known as data flow,\nis fundamental to reasoning in procedural tasks. Despite their fluency in\nnatural and programming languages, large language models (LLMs), although\nincreasingly being applied to decisions with procedural tasks, have not been\nsystematically evaluated for their ability to perform data-flow reasoning. We\nintroduce FABLE, an extensible benchmark designed to assess LLMs' understanding\nof data flow using structured, procedural text. FABLE adapts eight classical\ndata-flow analyses from software engineering: reaching definitions, very busy\nexpressions, available expressions, live variable analysis, interval analysis,\ntype-state analysis, taint analysis, and concurrency analysis. These analyses\nare instantiated across three real-world domains: cooking recipes, travel\nroutes, and automated plans. The benchmark includes 2,400 question-answer\npairs, with 100 examples for each domain-analysis combination. We evaluate\nthree types of LLMs: a reasoning-focused model (DeepSeek-R1 8B), a\ngeneral-purpose model (LLaMA 3.1 8B), and a code-specific model (Granite Code\n8B). Each model is tested using majority voting over five sampled completions\nper prompt. Results show that the reasoning model achieves higher accuracy, but\nat the cost of over 20 times slower inference compared to the other models. In\ncontrast, the general-purpose and code-specific models perform close to random\nchance. FABLE provides the first diagnostic benchmark to systematically\nevaluate data-flow reasoning and offers insights for developing models with\nstronger procedural understanding.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86FABLE\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6570\u636e\u6d41\u63a8\u7406\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u4ecd\u6709\u663e\u8457\u4e0d\u8db3\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u548c\u7f16\u7a0b\u8bed\u8a00\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u7a0b\u5e8f\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u6d41\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u6539\u7f16\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u516b\u79cd\u7ecf\u5178\u6570\u636e\u6d41\u5206\u6790\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aFABLE\u7684\u6269\u5c55\u6027\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u63a8\u7406\u578b\u6a21\u578b\uff08DeepSeek-R1 8B\uff09\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4f46\u63a8\u65ad\u901f\u5ea6\u616220\u591a\u500d\uff1b\u901a\u7528\u548c\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\u6c34\u5e73\u3002", "conclusion": "FABLE\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u6d41\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.24243", "pdf": "https://arxiv.org/pdf/2505.24243", "abs": "https://arxiv.org/abs/2505.24243", "authors": ["Joohwan Ko", "Justin Domke"], "title": "Model Informed Flows for Bayesian Inference of Probabilistic Programs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Variational inference often struggles with the posterior geometry exhibited\nby complex hierarchical Bayesian models. Recent advances in flow-based\nvariational families and Variationally Inferred Parameters (VIP) each address\naspects of this challenge, but their formal relationship is unexplored. Here,\nwe prove that the combination of VIP and a full-rank Gaussian can be\nrepresented exactly as a forward autoregressive flow augmented with a\ntranslation term and input from the model's prior. Guided by this theoretical\ninsight, we introduce the Model-Informed Flow (MIF) architecture, which adds\nthe necessary translation mechanism, prior information, and hierarchical\nordering. Empirically, MIF delivers tighter posterior approximations and\nmatches or exceeds state-of-the-art performance across a suite of hierarchical\nand non-hierarchical benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 Model-Informed Flow \u67b6\u6784\uff0c\u6539\u8fdb\u4e86\u53d8\u5206\u63a8\u65ad\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u79c0\u7684\u8868\u73b0\u3002", "motivation": "\u53d8\u5206\u63a8\u65ad\u5728\u5904\u7406\u590d\u6742\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u540e\u9a8c\u51e0\u4f55\u7ed3\u6784\u65f6\u5e38\u5e38\u9762\u4e34\u6311\u6218\uff0c\u800c\u57fa\u4e8e\u6d41\u7684\u53d8\u5206\u65cf\u548c\u53d8\u5206\u63a8\u65ad\u53c2\u6570 (VIP) \u7684\u6700\u65b0\u8fdb\u5c55\u5404\u81ea\u89e3\u51b3\u4e86\u8fd9\u4e00\u6311\u6218\u7684\u90e8\u5206\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u4e4b\u95f4\u7684\u5f62\u5f0f\u5173\u7cfb\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u4e86 Model-Informed Flow (MIF) \u67b6\u6784\uff0c\u8be5\u67b6\u6784\u589e\u52a0\u4e86\u5fc5\u8981\u7684\u5e73\u79fb\u673a\u5236\u3001\u5148\u9a8c\u4fe1\u606f\u548c\u5c42\u6b21\u987a\u5e8f\uff0c\u5e76\u7ed3\u5408 VIP \u548c\u5168\u79e9\u9ad8\u65af\u5206\u5e03\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86 VIP \u548c\u5168\u79e9\u9ad8\u65af\u53ef\u4ee5\u8868\u793a\u4e3a\u524d\u5411\u81ea\u56de\u5f52\u6d41\u5e76\u589e\u52a0\u4e00\u4e2a\u5e73\u79fb\u9879\u548c\u6765\u81ea\u6a21\u578b\u5148\u9a8c\u7684\u8f93\u5165\uff1b\u7ecf\u9a8c\u4e0a MIF \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "MIF \u63d0\u4f9b\u4e86\u66f4\u7d27\u5bc6\u7684\u540e\u9a8c\u8fd1\u4f3c\uff0c\u5e76\u5728\u4e00\u7cfb\u5217\u5206\u5c42\u548c\u975e\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2505.23927", "pdf": "https://arxiv.org/pdf/2505.23927", "abs": "https://arxiv.org/abs/2505.23927", "authors": ["Songtao Feng", "Jie Fu"], "title": "Thompson Sampling in Online RLHF with General Function Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has achieved great\nempirical success in aligning large language models (LLMs) with human\npreference, and it is of great importance to study the statistical efficiency\nof RLHF algorithms from a theoretical perspective. In this work, we consider\nthe online RLHF setting where the preference data is revealed during the\nlearning process and study action value function approximation. We design a\nmodel-free posterior sampling algorithm for online RLHF inspired by Thompson\nsampling and provide its theoretical guarantee. Specifically, we adopt Bellman\neluder (BE) dimension as the complexity measure of the function class and\nestablish $O(\\sqrt{T})$ regret bound for the proposed algorithm with other\nmultiplicative factor depending on the horizon, BE dimension and the\n$log$-bracketing number of the function class. Further, in the analysis, we\nfirst establish the concentration-type inequality of the squared Bellman error\nbound based on the maximum likelihood estimator (MLE) generalization bound,\nwhich plays the crucial rules in obtaining the eluder-type regret bound and may\nbe of independent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebfRLHF\u8bbe\u7f6e\u4e0b\u7684\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u903c\u8fd1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6a21\u578b\u540e\u9a8c\u62bd\u6837\u7b97\u6cd5\u5e76\u7ed9\u51fa\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5305\u62ec\u9057\u61be\u754c\u548c\u96c6\u4e2d\u578b\u4e0d\u7b49\u5f0f\u3002", "motivation": "\u4ece\u5b9e\u8bc1\u89d2\u5ea6\u770b\uff0c\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u56e0\u6b64\u4ece\u7406\u8bba\u89d2\u5ea6\u7814\u7a76RLHF\u7b97\u6cd5\u7684\u7edf\u8ba1\u6548\u7387\u975e\u5e38\u91cd\u8981\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u66fc\u63a2\u7d22(Bellman eluder)\u7ef4\u5ea6\u4f5c\u4e3a\u51fd\u6570\u7c7b\u7684\u590d\u6742\u5ea6\u5ea6\u91cf\uff0c\u5e76\u8bbe\u8ba1\u4e00\u4e2a\u53d7Thompson\u62bd\u6837\u542f\u53d1\u7684\u65e0\u6a21\u578b\u540e\u9a8c\u62bd\u6837\u7b97\u6cd5\u3002", "result": "\u7814\u7a76\u5efa\u7acb\u4e86O(\u221aT)\u7684\u9057\u61be\u754c\uff0c\u5e76\u9996\u6b21\u5efa\u7acb\u4e86\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1(MLE)\u63a8\u5e7f\u754c\u7684\u5e73\u65b9Bellman\u8bef\u5dee\u754c\u7684\u96c6\u4e2d\u578b\u4e0d\u7b49\u5f0f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u7ebfRLHF\u8bbe\u7f6e\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65e0\u6a21\u578b\u540e\u9a8c\u62bd\u6837\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5305\u62ec\u57fa\u4e8e\u5e73\u65b9Bellman\u8bef\u5dee\u754c\u7684\u96c6\u4e2d\u578b\u4e0d\u7b49\u5f0f\u3002"}}
{"id": "2505.24260", "pdf": "https://arxiv.org/pdf/2505.24260", "abs": "https://arxiv.org/abs/2505.24260", "authors": ["Mingyi He", "Yuebing Liang", "Shenhao Wang", "Yunhan Zheng", "Qingyi Wang", "Dingyi Zhuang", "Li Tian", "Jinhua Zhao"], "title": "Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models", "categories": ["cs.AI"], "comment": null, "summary": "Urban design is a multifaceted process that demands careful consideration of\nsite-specific constraints and collaboration among diverse professionals and\nstakeholders. The advent of generative artificial intelligence (GenAI) offers\ntransformative potential by improving the efficiency of design generation and\nfacilitating the communication of design ideas. However, most existing\napproaches are not well integrated with human design workflows. They often\nfollow end-to-end pipelines with limited control, overlooking the iterative\nnature of real-world design. This study proposes a stepwise generative urban\ndesign framework that integrates multimodal diffusion models with human\nexpertise to enable more adaptive and controllable design processes. Instead of\ngenerating design outcomes in a single end-to-end process, the framework\ndivides the process into three key stages aligned with established urban design\nworkflows: (1) road network and land use planning, (2) building layout\nplanning, and (3) detailed planning and rendering. At each stage, multimodal\ndiffusion models generate preliminary designs based on textual prompts and\nimage-based constraints, which can then be reviewed and refined by human\ndesigners. We design an evaluation framework to assess the fidelity,\ncompliance, and diversity of the generated designs. Experiments using data from\nChicago and New York City demonstrate that our framework outperforms baseline\nmodels and end-to-end approaches across all three dimensions. This study\nunderscores the benefits of multimodal diffusion models and stepwise generation\nin preserving human control and facilitating iterative refinements, laying the\ngroundwork for human-AI interaction in urban design solutions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u57ce\u5e02\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u6269\u6563\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u77e5\u8bc6\uff0c\u4f7f\u5f97\u8bbe\u8ba1\u8fc7\u7a0b\u66f4\u52a0\u7075\u6d3b\u53ef\u63a7\uff0c\u5e76\u52a0\u5f3a\u4e86\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u5e76\u672a\u5f88\u597d\u5730\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u7a0b\u96c6\u6210\u3002\u5b83\u4eec\u901a\u5e38\u9075\u5faa\u7aef\u5230\u7aef\u7684\u6d41\u6c34\u7ebf\uff0c\u63a7\u5236\u6709\u9650\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u8bbe\u8ba1\u7684\u8fed\u4ee3\u6027\u8d28\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u9636\u6bb5\u7684\u751f\u6210\u5f0f\u57ce\u5e02\u8bbe\u8ba1\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u6269\u6563\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u76f8\u7ed3\u5408\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9002\u5e94\u6027\u548c\u53ef\u63a7\u7684\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "result": "\u4f7f\u7528\u829d\u52a0\u54e5\u548c\u7ebd\u7ea6\u5e02\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5728\u6240\u6709\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u7aef\u5230\u7aef\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u6269\u6563\u6a21\u578b\u548c\u5206\u9636\u6bb5\u751f\u6210\u5728\u4fdd\u6301\u4eba\u7c7b\u63a7\u5236\u548c\u4fc3\u8fdb\u8fed\u4ee3\u6539\u8fdb\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4e3a\u57ce\u5e02\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24261", "pdf": "https://arxiv.org/pdf/2505.24261", "abs": "https://arxiv.org/abs/2505.24261", "authors": ["Weiyi Wang", "Junwei Deng", "Yuzheng Hu", "Shiyuan Zhang", "Xirui Jiang", "Runting Zhang", "Han Zhao", "Jiaqi W. Ma"], "title": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Data attribution methods, which quantify the influence of individual training\ndata points on a machine learning model, have gained increasing popularity in\ndata-centric applications in modern AI. Despite a recent surge of new methods\ndeveloped in this space, the impact of hyperparameter tuning in these methods\nremains under-explored. In this work, we present the first large-scale\nempirical study to understand the hyperparameter sensitivity of common data\nattribution methods. Our results show that most methods are indeed sensitive to\ncertain key hyperparameters. However, unlike typical machine learning\nalgorithms -- whose hyperparameters can be tuned using computationally-cheap\nvalidation metrics -- evaluating data attribution performance often requires\nretraining models on subsets of training data, making such metrics\nprohibitively costly for hyperparameter tuning. This poses a critical open\nchallenge for the practical application of data attribution methods. To address\nthis challenge, we advocate for better theoretical understandings of\nhyperparameter behavior to inform efficient tuning strategies. As a case study,\nwe provide a theoretical analysis of the regularization term that is critical\nin many variants of influence function methods. Building on this analysis, we\npropose a lightweight procedure for selecting the regularization value without\nmodel retraining, and validate its effectiveness across a range of standard\ndata attribution benchmarks. Overall, our study identifies a fundamental yet\noverlooked challenge in the practical application of data attribution, and\nhighlights the importance of careful discussion on hyperparameter selection in\nfuture method development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u4e2d\u8d85\u53c2\u6570\u654f\u611f\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u503c\u9009\u62e9\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u672a\u6765\u65b9\u6cd5\u5f00\u53d1\u4e2d\u8d85\u53c2\u6570\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u5728\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u7684\u6570\u636e\u4e2d\u5fc3\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u5f71\u54cd\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u7406\u89e3\u8fd9\u4e00\u95ee\u9898\u4ee5\u63d0\u9ad8\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u8be5\u8bba\u6587\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u4ee5\u8bc4\u4f30\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u7684\u8d85\u53c2\u6570\u654f\u611f\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u5f71\u54cd\u51fd\u6570\u65b9\u6cd5\u4e2d\u7684\u6b63\u5219\u5316\u9879\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u503c\u9009\u62e9\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5927\u591a\u6570\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u786e\u5b9e\u5bf9\u67d0\u4e9b\u5173\u952e\u8d85\u53c2\u6570\u654f\u611f\uff0c\u4e14\u4f20\u7edf\u7684\u8ba1\u7b97\u9a8c\u8bc1\u6307\u6807\u7528\u4e8e\u8d85\u53c2\u6570\u8c03\u4f18\u6210\u672c\u8fc7\u9ad8\uff1b\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6709\u6548\u7684\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u503c\u9009\u62e9\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u5728\u8d85\u53c2\u6570\u9009\u62e9\u4e0a\u5177\u6709\u654f\u611f\u6027\uff0c\u4f46\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6b63\u5219\u5316\u503c\u9009\u62e9\u8fc7\u7a0b\uff0c\u4e3a\u672a\u6765\u65b9\u6cd5\u5f00\u53d1\u4e2d\u5bf9\u8d85\u53c2\u6570\u9009\u62e9\u7684\u6df1\u5165\u8ba8\u8bba\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.23933", "pdf": "https://arxiv.org/pdf/2505.23933", "abs": "https://arxiv.org/abs/2505.23933", "authors": ["Galen Pogoncheff", "Michael Beyeler"], "title": "BIRD: Behavior Induction via Representation-structure Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Human-aligned deep learning models exhibit behaviors consistent with human\nvalues, such as robustness, fairness, and honesty. Transferring these\nbehavioral properties to models trained on different tasks or data\ndistributions remains challenging: aligned behavior is easily forgotten during\nfine-tuning, and collecting task-specific data that preserves this behavior can\nbe prohibitively costly. We introduce BIRD (Behavior Induction via\nRepresentation-structure Distillation), a flexible framework for transferring\naligned behavior by matching the internal representation structure of a student\nmodel to that of a teacher. Applied to out-of-distribution robustness in image\nclassification, BIRD outperforms fine-tuning, transfer learning, and continual\nlearning methods, improving robust accuracy by up to 16% over the next\nstrongest baseline. It remains effective even when the teacher is trained on a\nmuch simpler dataset and is $25 \\times$ smaller than the student. In a\nlarge-scale study of over 400 teacher-student pairs, we show that three\ninterpretable and computable properties of the teacher's representations (i.e.,\ntask relevance, behavioral relevance, and complementary knowledge) explain up\nto 85% of the variance in transfer success. These insights offer practical\nguidance for teacher selection and design. BIRD turns small, well-aligned\nmodels into scalable alignment seeds, removing a key bottleneck in deploying\nsafe AI systems in the wild.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aBIRD\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u4fdd\u6301\u4e00\u81f4\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u9f50\u5b66\u751f\u6a21\u578b\u548c\u6559\u5e08\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u7ed3\u6784\u5b9e\u73b0\u9ad8\u6548\u7684\u5bf9\u9f50\u884c\u4e3a\u8fc1\u79fb\u3002", "motivation": "\u5c06\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u884c\u4e3a\u8f6c\u79fb\u5230\u5728\u4e0d\u540c\u4efb\u52a1\u6216\u6570\u636e\u5206\u5e03\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u4e0a\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5bf9\u9f50\u884c\u4e3a\u5bb9\u6613\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u88ab\u9057\u5fd8\uff0c\u800c\u6536\u96c6\u4fdd\u7559\u6b64\u884c\u4e3a\u7684\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u53ef\u80fd\u4ee3\u4ef7\u9ad8\u6602\u3002", "method": "\u7814\u7a76\u56e2\u961f\u5f15\u5165\u4e86BIRD\uff08Behavior Induction via Representation-structure Distillation\uff09\uff0c\u901a\u8fc7\u5339\u914d\u5b66\u751f\u6a21\u578b\u4e0e\u6559\u5e08\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u7ed3\u6784\u8fdb\u884c\u5bf9\u9f50\u884c\u4e3a\u7684\u8fc1\u79fb\uff0c\u5e76\u8fdb\u884c\u4e86\u8d85\u8fc7400\u4e2a\u6559\u5e08-\u5b66\u751f\u6a21\u578b\u5bf9\u7684\u5927\u89c4\u6a21\u7814\u7a76\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u7684\u5206\u5e03\u5916\u9c81\u68d2\u6027\u5e94\u7528\u4e2d\uff0cBIRD\u4f18\u4e8e\u5fae\u8c03\u3001\u8fc1\u79fb\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u6bd4\u6b21\u4f18\u57fa\u7ebf\u63d0\u9ad8\u4e8616%\u7684\u9c81\u68d2\u51c6\u786e\u6027\u3002\u5373\u4f7f\u6559\u5e08\u6a21\u578b\u662f\u5728\u66f4\u7b80\u5355\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u4e14\u6bd4\u5b66\u751f\u6a21\u578b\u5c0f25\u500d\uff0c\u5b83\u4ecd\u7136\u6709\u6548\u3002", "conclusion": "BIRD\u662f\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u901a\u8fc7\u5339\u914d\u5b66\u751f\u6a21\u578b\u548c\u6559\u5e08\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u7ed3\u6784\u6765\u4f20\u9012\u5bf9\u9f50\u884c\u4e3a\uff0c\u4ece\u800c\u6d88\u9664\u90e8\u7f72\u5b89\u5168AI\u7cfb\u7edf\u7684\u5173\u952e\u74f6\u9888\u3002"}}
{"id": "2505.24273", "pdf": "https://arxiv.org/pdf/2505.24273", "abs": "https://arxiv.org/abs/2505.24273", "authors": ["Hongyi James Cai", "Junlin Wang", "Xiaoyin Chen", "Bhuwan Dhingra"], "title": "How Much Backtracking is Enough? Exploring the Interplay of SFT and RL in Enhancing LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent breakthroughs in large language models (LLMs) have effectively\nimproved their reasoning abilities, particularly on mathematical and logical\nproblems that have verifiable answers, through techniques such as supervised\nfinetuning (SFT) and reinforcement learning (RL). Prior research indicates that\nRL effectively internalizes search strategies, enabling long chain-of-thought\n(CoT) reasoning, with backtracking emerging naturally as a learned capability.\nHowever, the precise benefits of backtracking, specifically, how significantly\nit contributes to reasoning improvements and the optimal extent of its use,\nremain poorly understood. In this work, we systematically investigate the\ndynamics between SFT and RL on eight reasoning tasks: Countdown, Sudoku, Arc\n1D, Geometry, Color Cube Rotation, List Functions, Zebra Puzzles, and Self\nReference. Our findings highlight that short CoT sequences used in SFT as a\nwarm-up do have moderate contribution to RL training, compared with cold-start\nRL; however such contribution diminishes when tasks become increasingly\ndifficult. Motivated by this observation, we construct synthetic datasets\nvarying systematically in the number of backtracking steps and conduct\ncontrolled experiments to isolate the influence of either the correctness\n(content) or the structure (i.e., backtrack frequency). We find that (1) longer\nCoT with backtracks generally induce better and more stable RL training, (2)\nmore challenging problems with larger search space tend to need higher numbers\nof backtracks during the SFT stage. Additionally, we demonstrate through\nexperiments on distilled data that RL training is largely unaffected by the\ncorrectness of long CoT sequences, suggesting that RL prioritizes structural\npatterns over content correctness. Collectively, our results offer practical\ninsights into designing optimal training strategies to effectively scale\nreasoning in LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u5e26\u6709\u56de\u6eaf\u7684\u957f\u94fe\u5f0f\u63a8\u7406\u5bf9\u8bad\u7ec3\u6548\u679c\u7684\u79ef\u6781\u5f71\u54cd\uff0c\u5c24\u5176\u5728\u590d\u6742\u95ee\u9898\u4e0a\u66f4\u4e3a\u663e\u8457\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u6e90\u4e8e\u5f53\u524d\u5bf9\u4e8e\u56de\u6eaf\u5728\u63a8\u7406\u6539\u8fdb\u4e2d\u7684\u5177\u4f53\u4f5c\u7528\u53ca\u5176\u6700\u4f18\u4f7f\u7528\u7a0b\u5ea6\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u8868\u660eRL\u80fd\u6709\u6548\u5185\u5316\u641c\u7d22\u7b56\u7565\u5e76\u5b9e\u73b0\u957f\u94fe\u5f0f\u63a8\u7406\uff0c\u4f46\u5982\u4f55\u4f18\u5316\u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u7684\u95ee\u9898\u3002", "method": "\u8bba\u6587\u7684\u65b9\u6cd5\u5305\u62ec\u5bf9\u516b\u4e2a\u63a8\u7406\u4efb\u52a1\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5e76\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u4ee5\u63a7\u5236\u56de\u6eaf\u6b65\u9aa4\u7684\u6570\u91cf\u3002\u901a\u8fc7\u6bd4\u8f83\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u56de\u6eaf\u7684\u4f5c\u7528\u4ee5\u53ca\u5185\u5bb9\u6b63\u786e\u6027\u548c\u7ed3\u6784\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\u3002", "result": "\u8bba\u6587\u7684\u7ed3\u679c\u8868\u660e\uff1a(1) \u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u5e26\u6709\u56de\u6eaf\u7684\u8f83\u957f\u94fe\u5f0f\u63a8\u7406\u901a\u5e38\u80fd\u4ea7\u751f\u66f4\u597d\u4e14\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u6548\u679c\uff1b(2) \u5bf9\u4e8e\u8f83\u96be\u3001\u641c\u7d22\u7a7a\u95f4\u66f4\u5927\u7684\u95ee\u9898\uff0c\u5728\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u9700\u8981\u66f4\u591a\u56de\u6eaf\u6b65\u9aa4\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u663e\u793a\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u53d7\u7ed3\u6784\u6a21\u5f0f\u5f71\u54cd\u66f4\u5927\uff0c\u800c\u5bf9\u957f\u94fe\u5f0f\u63a8\u7406\u5e8f\u5217\u7684\u5185\u5bb9\u6b63\u786e\u6027\u76f8\u5bf9\u4e0d\u654f\u611f\u3002", "conclusion": "\u8bba\u6587\u7684\u7ed3\u8bba\u662f\u957f\u94fe\u5f0f\u63a8\u7406\uff08CoT\uff09\u4e0e\u56de\u6eaf\u7ed3\u5408\u80fd\u591f\u8bf1\u5bfc\u51fa\u66f4\u597d\u4e14\u66f4\u7a33\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u641c\u7d22\u7a7a\u95f4\u8f83\u5927\u7684\u590d\u6742\u95ee\u9898\u65f6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0RL\u8bad\u7ec3\u4e3b\u8981\u5173\u6ce8\u7ed3\u6784\u6a21\u5f0f\u800c\u975e\u5185\u5bb9\u6b63\u786e\u6027\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u6709\u6548\u7684LLM\u63a8\u7406\u6269\u5c55\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2505.24275", "pdf": "https://arxiv.org/pdf/2505.24275", "abs": "https://arxiv.org/abs/2505.24275", "authors": ["Mingze Wang", "Jinbo Wang", "Jiaqi Zhang", "Wei Wang", "Peng Pei", "Xunliang Cai", "Weinan E", "Lei Wu"], "title": "GradPower: Powering Gradients for Faster Language Model Pre-Training", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "22 pages", "summary": "We propose GradPower, a lightweight gradient-transformation technique for\naccelerating language model pre-training. Given a gradient vector $g=(g_i)_i$,\nGradPower first applies the elementwise sign-power transformation:\n$\\varphi_p(g)=({\\rm sign}(g_i)|g_i|^p)_{i}$ for a fixed $p>0$, and then feeds\nthe transformed gradient into a base optimizer. Notably, GradPower requires\nonly a single-line code change and no modifications to the base optimizer's\ninternal logic, including the hyperparameters. When applied to Adam (termed\nAdamPower), GradPower consistently achieves lower terminal loss across diverse\narchitectures (LLaMA, Qwen2MoE), parameter scales (66M to 2B), datasets (C4,\nOpenWebText), and learning-rate schedules (cosine, warmup-stable-decay). The\nmost pronounced gains are observed when training modern mixture-of-experts\nmodels with warmup-stable-decay schedules. GradPower also integrates seamlessly\nwith other state-of-the-art optimizers, such as Muon, yielding further\nimprovements. Finally, we provide theoretical analyses that reveal the\nunderlying mechanism of GradPower and highlights the influence of gradient\nnoise.", "AI": {"tldr": "GradPower\u662f\u4e00\u79cd\u7528\u4e8e\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u68af\u5ea6\u8f6c\u6362\u6280\u672f\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\uff0c\u5e76\u5728\u5404\u79cd\u67b6\u6784\u3001\u53c2\u6570\u89c4\u6a21\u3001\u6570\u636e\u96c6\u548c\u5b66\u4e60\u7387\u8ba1\u5212\u4e2d\u5b9e\u73b0\u66f4\u4f4e\u7684\u7ec8\u7aef\u635f\u5931\u3002", "method": "GradPower\u9996\u5148\u5bf9\u68af\u5ea6\u5411\u91cf\u5e94\u7528\u5143\u7d20\u7ea7\u522b\u7684\u7b26\u53f7\u5e42\u53d8\u6362\uff0c\u7136\u540e\u5c06\u53d8\u6362\u540e\u7684\u68af\u5ea6\u8f93\u5165\u5230\u57fa\u7840\u4f18\u5316\u5668\u4e2d\u3002", "result": "GradPower\u5728\u591a\u79cd\u67b6\u6784\u3001\u53c2\u6570\u89c4\u6a21\u3001\u6570\u636e\u96c6\u548c\u5b66\u4e60\u7387\u8ba1\u5212\u4e2d\u4e00\u81f4\u5730\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u7ec8\u7aef\u635f\u5931\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u5176\u5b83\u6700\u5148\u8fdb\u7684\u4f18\u5316\u5668\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "GradPower\u662f\u4e00\u79cd\u6709\u6548\u7684\u68af\u5ea6\u8f6c\u6362\u6280\u672f\uff0c\u53ef\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u63ed\u793a\u5176\u673a\u5236\u548c\u68af\u5ea6\u566a\u58f0\u7684\u5f71\u54cd\u3002"}}
{"id": "2505.23939", "pdf": "https://arxiv.org/pdf/2505.23939", "abs": "https://arxiv.org/abs/2505.23939", "authors": ["Andrea Mattia Garavagno", "Edoardo Ragusa", "Antonio Frisoli", "Paolo Gastaldo"], "title": "Searching Neural Architectures for Sensor Nodes on IoT Gateways", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "This paper presents an automatic method for the design of Neural Networks\n(NNs) at the edge, enabling Machine Learning (ML) access even in\nprivacy-sensitive Internet of Things (IoT) applications. The proposed method\nruns on IoT gateways and designs NNs for connected sensor nodes without sharing\nthe collected data outside the local network, keeping the data in the site of\ncollection. This approach has the potential to enable ML for Healthcare\nInternet of Things (HIoT) and Industrial Internet of Things (IIoT), designing\nhardware-friendly and custom NNs at the edge for personalized healthcare and\nadvanced industrial services such as quality control, predictive maintenance,\nor fault diagnosis. By preventing data from being disclosed to cloud services,\nthis method safeguards sensitive information, including industrial secrets and\npersonal data. The outcomes of a thorough experimental session confirm that --\non the Visual Wake Words dataset -- the proposed approach can achieve\nstate-of-the-art results by exploiting a search procedure that runs in less\nthan 10 hours on the Raspberry Pi Zero 2.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u8054\u7f51\u7f51\u5173\u7684\u81ea\u52a8\u5316\u8fb9\u7f18\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u65e8\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u80fd\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u9690\u79c1\u654f\u611f\u7684\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u673a\u5668\u5b66\u4e60\u8bbf\u95ee\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u5982\u5de5\u4e1a\u673a\u5bc6\u548c\u4e2a\u4eba\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u8be5\u65b9\u6cd5\u5728\u7269\u8054\u7f51\u7f51\u5173\u4e0a\u8fd0\u884c\uff0c\u5e76\u901a\u8fc7\u641c\u7d22\u7a0b\u5e8f\u5728\u672c\u5730\u7f51\u7edc\u5185\u8bbe\u8ba1\u9002\u7528\u4e8e\u8fde\u63a5\u4f20\u611f\u5668\u8282\u70b9\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u800c\u65e0\u9700\u5c06\u6536\u96c6\u7684\u6570\u636e\u5206\u4eab\u5230\u5916\u90e8\u7f51\u7edc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728Visual Wake Words\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728Raspberry Pi Zero 2\u4e0a\u8fd0\u884c\u4e0d\u523010\u5c0f\u65f6\u7684\u641c\u7d22\u7a0b\u5e8f\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8fb9\u7f18\u81ea\u52a8\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u524d\u63d0\u4e0b\uff0c\u4e3a\u533b\u7597\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u63d0\u4f9b\u673a\u5668\u5b66\u4e60\u7684\u80fd\u529b\u3002"}}
{"id": "2505.24292", "pdf": "https://arxiv.org/pdf/2505.24292", "abs": "https://arxiv.org/abs/2505.24292", "authors": ["Yueqi Zhang", "Peiwen Yuan", "Shaoxiong Feng", "Yiwei Li", "Xinglin Wang", "Jiayi Shi", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Human-AI conversation frequently relies on quoting earlier text-\"check it\nwith the formula I just highlighted\"-yet today's large language models (LLMs)\nlack an explicit mechanism for locating and exploiting such spans. We formalise\nthe challenge as span-conditioned generation, decomposing each turn into the\ndialogue history, a set of token-offset quotation spans, and an intent\nutterance. Building on this abstraction, we introduce a quotation-centric data\npipeline that automatically synthesises task-specific dialogues, verifies\nanswer correctness through multi-stage consistency checks, and yields both a\nheterogeneous training corpus and the first benchmark covering five\nrepresentative scenarios. To meet the benchmark's zero-overhead and\nparameter-efficiency requirements, we propose QuAda, a lightweight\ntraining-based method that attaches two bottleneck projections to every\nattention head, dynamically amplifying or suppressing attention to quoted spans\nat inference time while leaving the prompt unchanged and updating < 2.8% of\nbackbone weights. Experiments across models show that QuAda is suitable for all\nscenarios and generalises to unseen topics, offering an effective,\nplug-and-play solution for quotation-aware dialogue.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86QuAda\uff0c\u4e00\u79cd\u9488\u5bf9\u5f15\u7528\u611f\u77e5\u5bf9\u8bdd\u7684\u8f7b\u91cf\u7ea7\u8bad\u7ec3\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5f15\u7528\u6587\u672c\u65f6\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u660e\u786e\u7684\u673a\u5236\u6765\u5b9a\u4f4d\u548c\u5229\u7528\u5bf9\u8bdd\u4e2d\u5f15\u7528\u7684\u6587\u672c\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u5904\u7406\u6d89\u53ca\u5f15\u7528\u7684\u5bf9\u8bdd\u65f6\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684QuAda\u65b9\u6cd5\uff0c\u901a\u8fc7\u9644\u52a0\u4e24\u4e2a\u74f6\u9888\u6295\u5f71\u5230\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u4e0a\uff0c\u52a8\u6001\u653e\u5927\u6216\u6291\u5236\u5bf9\u5f15\u7528\u8de8\u5ea6\u7684\u5173\u6ce8\u3002", "result": "QuAda\u6ee1\u8db3\u4e86\u96f6\u5f00\u9500\u548c\u53c2\u6570\u6548\u7387\u7684\u8981\u6c42\uff0c\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u66f4\u65b0\u4e0d\u52302.8%\u7684\u4e3b\u5e72\u6743\u91cd\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5QuAda\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5bf9\u8bdd\u573a\u666f\uff0c\u5e76\u80fd\u63a8\u5e7f\u5230\u672a\u89c1\u8fc7\u7684\u4e3b\u9898\u4e0a\uff0c\u4e3a\u5f15\u7528\u611f\u77e5\u7684\u5bf9\u8bdd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.24595", "pdf": "https://arxiv.org/pdf/2505.24595", "abs": "https://arxiv.org/abs/2505.24595", "authors": ["Andrei Chernov", "Vitaliy Pozdnyakov", "Ilya Makarov"], "title": "Binary Cumulative Encoding meets Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u8fdb\u5236\u7d2f\u79ef\u7f16\u7801\uff08BCE\uff09\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u4fdd\u6301\u5e8f\u6570\u4fe1\u606f\u7684\u7f16\u7801\u65b9\u5f0f\u548c\u4e13\u8bbe\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u51cf\u5c11\u53c2\u6570\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5ffd\u7565\u6f5c\u5728\u503c\u56fa\u6709\u5e8f\u6570\u7ed3\u6784\u7684\u4e00\u70ed\u7f16\u7801\uff0c\u56e0\u6b64\u65e0\u6cd5\u5728\u8bad\u7ec3\u671f\u95f4\u63d0\u4f9b\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u76f8\u5bf9\u8ddd\u79bb\u4fe1\u606f\u3002\u8fd9\u79cd\u9650\u5236\u662f\u672c\u7814\u7a76\u7684\u4e3b\u8981\u52a8\u673a\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u7f16\u7801\u7b56\u7565\uff0c\u5373\u4e8c\u8fdb\u5236\u7d2f\u79ef\u7f16\u7801\uff08BCE\uff09\uff0c\u5c06\u6807\u91cf\u76ee\u6807\u8f6c\u5316\u4e3a\u5355\u8c03\u4e8c\u8fdb\u5236\u5411\u91cf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eBCE\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u6b8b\u5dee\u548c\u6269\u5f20\u5377\u79ef\u4ee5\u5b9e\u73b0\u5feb\u901f\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u65f6\u95f4\u5efa\u6a21\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u70b9\u9884\u6d4b\u548c\u6982\u7387\u9884\u6d4b\u65b9\u9762\u5747\u8d85\u8d8a\u4e86\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u4ed6\u4eec\u63d0\u51fa\u7684\u4e8c\u8fdb\u5236\u7d2f\u79ef\u7f16\u7801\uff08BCE\uff09\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u65e2\u5728\u70b9\u9884\u6d4b\u548c\u6982\u7387\u9884\u6d4b\u65b9\u9762\u90fd\u4f18\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u53c2\u6570\u5e76\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\u3002"}}
{"id": "2505.23941", "pdf": "https://arxiv.org/pdf/2505.23941", "abs": "https://arxiv.org/abs/2505.23941", "authors": ["An Vo", "Khai-Nguyen Nguyen", "Mohammad Reza Taesiri", "Vy Tuong Dang", "Anh Totti Nguyen", "Daeyoung Kim"], "title": "Vision Language Models are Biased", "categories": ["cs.LG", "cs.CV"], "comment": "Code and qualitative examples are available at:\n  vlmsarebiased.github.io", "summary": "Large language models (LLMs) memorize a vast amount of prior knowledge from\nthe Internet that help them on downstream tasks but also may notoriously sway\ntheir outputs towards wrong or biased answers. In this work, we test how the\nknowledge about popular subjects hurt the accuracy of vision language models\n(VLMs) on standard, objective visual tasks of counting and identification. We\nfind that state-of-the-art VLMs are strongly biased (e.g, unable to recognize a\nfourth stripe has been added to a 3-stripe Adidas logo) scoring an average of\n17.05% accuracy in counting (e.g., counting stripes in an Adidas-like logo)\nacross 7 diverse domains from animals, logos, chess, board games, optical\nillusions, to patterned grids. Insert text (e.g., \"Adidas\") describing the\nsubject name into the counterfactual image further decreases VLM accuracy. The\nbiases in VLMs are so strong that instructing them to double-check their\nresults or rely exclusively on image details to answer improves counting\naccuracy by only +2 points, on average. Our work presents an interesting\nfailure mode in VLMs and an automated framework for testing VLM biases. Code\nand data are available at: vlmsarebiased.github.io.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u5148\u9a8c\u77e5\u8bc6\u4ea7\u751f\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5728\u591a\u79cd\u89c6\u89c9\u8ba1\u6570\u4efb\u52a1\u4e2d\u53d1\u73b0\u4e86\u663e\u8457\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u56e0\u4e92\u8054\u7f51\u77e5\u8bc6\u800c\u4ea7\u751f\u504f\u5dee\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u89c6\u89c9\u4efb\u52a1\u4e0a\u5bf9\u51c6\u786e\u6027\u548c\u504f\u89c1\u7684\u5f71\u54cd\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5f15\u5165\u6d41\u884c\u4e3b\u9898\u7684\u77e5\u8bc6\u6765\u6d4b\u8bd5\u5176\u5bf9VLMs\u5728\u8ba1\u6570\u548c\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u91cf\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u6700\u5148\u8fdb\u7684VLMs\u5728\u8ba1\u6570\u4efb\u52a1\u4e2d\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a17.05%\uff0c\u5e76\u4e14\u63cf\u8ff0\u5bf9\u8c61\u540d\u79f0\u7684\u63d2\u5165\u6587\u672c\u8fdb\u4e00\u6b65\u964d\u4f4e\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u5728\u6807\u51c6\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d4b\u8bd5VLM\u504f\u5dee\u7684\u81ea\u52a8\u5316\u6846\u67b6\u3002"}}
{"id": "2505.24306", "pdf": "https://arxiv.org/pdf/2505.24306", "abs": "https://arxiv.org/abs/2505.24306", "authors": ["Kechen Li", "Yaotian Tao", "Ximing Wen", "Quanwei Sun", "Zifei Gong", "Chang Xu", "Xizhe Zhang", "Tianbo Ji"], "title": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments", "categories": ["cs.AI"], "comment": "8 pages", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated their\npotential in planning and reasoning tasks, offering a flexible alternative to\nclassical pathfinding algorithms. However, most existing studies focus on LLMs'\nindependent reasoning capabilities and overlook the potential synergy between\nLLMs and traditional algorithms. To fill this gap, we propose a comprehensive\nevaluation benchmark GridRoute to assess how LLMs can take advantage of\ntraditional algorithms. We also propose a novel hybrid prompting technique\ncalled Algorithm of Thought (AoT), which introduces traditional algorithms'\nguidance into prompting. Our benchmark evaluates six LLMs ranging from 7B to\n72B parameters across various map sizes, assessing their performance in\ncorrectness, optimality, and efficiency in grid environments with varying\nsizes. Our results show that AoT significantly boosts performance across all\nmodel sizes, particularly in larger or more complex environments, suggesting a\npromising approach to addressing path planning challenges. Our code is\nopen-sourced at https://github.com/LinChance/GridRoute.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5Algorithm of Thought (AoT)\uff0c\u5c06\u4f20\u7edf\u7b97\u6cd5\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u7ed3\u5408\uff0c\u4ee5\u63d0\u5347\u5176\u5728\u8def\u5f84\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cAoT \u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728\u5404\u79cd\u5730\u56fe\u73af\u5883\u4e2d\u7684\u6b63\u786e\u6027\u3001\u6700\u4f18\u6027\u548c\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u73af\u5883\u4e2d\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89c4\u5212\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5927\u591a\u5173\u6ce8LLMs\u7684\u72ec\u7acb\u63a8\u7406\u80fd\u529b\uff0c\u5ffd\u89c6\u4e86\u5176\u4e0e\u4f20\u7edf\u7b97\u6cd5\u7ed3\u5408\u7684\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22LLMs\u4e0e\u4f20\u7edf\u7b97\u6cd5\u534f\u540c\u5de5\u4f5c\u7684\u53ef\u80fd\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u63d0\u793a\u6280\u672fAlgorithm of Thought (AoT)\uff0c\u5c06\u4f20\u7edf\u7b97\u6cd5\u7684\u6307\u5bfc\u5f15\u5165\u5230\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63d0\u793a\u4e2d\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6GridRoute\uff0c\u7528\u4e8e\u6d4b\u8bd5LLMs\u5728\u4e0d\u540c\u89c4\u6a21\u5730\u56fe\u73af\u5883\u4e2d\u5229\u7528\u4f20\u7edf\u7b97\u6cd5\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u90e8\u5206\u8bc4\u4f30\u4e86\u4ece7B\u523072B\u53c2\u6570\u8303\u56f4\u5185\u7684\u516d\u79cdLLMs\uff0c\u5728\u6b63\u786e\u6027\u3001\u6700\u4f18\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684Algorithm of Thought (AoT) \u65b9\u6cd5\u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\u4e0a\u5747\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8f83\u5927\u6216\u66f4\u590d\u6742\u7684\u73af\u5883\u4e2d\u6548\u679c\u66f4\u4e3a\u660e\u663e\uff0c\u8bc1\u660e\u4e86AoT\u5728\u7f51\u683c\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u5f15\u5165\u4f20\u7edf\u7b97\u6cd5\u6307\u5bfc\u63d0\u793a\u7684\u65b0\u578b\u6df7\u5408\u63d0\u793a\u6280\u672fAlgorithm of Thought (AoT)\uff0c\u5728\u5404\u79cd\u6a21\u578b\u5927\u5c0f\u548c\u5730\u56fe\u590d\u6742\u5ea6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u8868\u660e\u8fd9\u662f\u4e00\u79cd\u89e3\u51b3\u8def\u5f84\u89c4\u5212\u95ee\u9898\u7684\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u7684\u4ee3\u7801\u5df2\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002"}}
{"id": "2505.24692", "pdf": "https://arxiv.org/pdf/2505.24692", "abs": "https://arxiv.org/abs/2505.24692", "authors": ["Derek Everett", "Fred Lu", "Edward Raff", "Fernando Camacho", "James Holt"], "title": "Quick-Draw Bandits: Quickly Optimizing in Nonstationary Environments with Extremely Many Arms", "categories": ["cs.LG", "stat.ML"], "comment": "KDD 2025, Research Track", "summary": "Canonical algorithms for multi-armed bandits typically assume a stationary\nreward environment where the size of the action space (number of arms) is\nsmall. More recently developed methods typically relax only one of these\nassumptions: existing non-stationary bandit policies are designed for a small\nnumber of arms, while Lipschitz, linear, and Gaussian process bandit policies\nare designed to handle a large (or infinite) number of arms in stationary\nreward environments under constraints on the reward function. In this\nmanuscript, we propose a novel policy to learn reward environments over a\ncontinuous space using Gaussian interpolation. We show that our method\nefficiently learns continuous Lipschitz reward functions with\n$\\mathcal{O}^*(\\sqrt{T})$ cumulative regret. Furthermore, our method naturally\nextends to non-stationary problems with a simple modification. We finally\ndemonstrate that our method is computationally favorable (100-10000x faster)\nand experimentally outperforms sliding Gaussian process policies on datasets\nwith non-stationarity and an extremely large number of arms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23942", "pdf": "https://arxiv.org/pdf/2505.23942", "abs": "https://arxiv.org/abs/2505.23942", "authors": ["Gaurav Sarkar", "Jay Gala", "Subarna Tripathi"], "title": "SG-Blend: Learning an Interpolation Between Improved Swish and GELU for Robust Neural Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The design of activation functions remains a pivotal component in optimizing\ndeep neural networks. While prevailing choices like Swish and GELU demonstrate\nconsiderable efficacy, they often exhibit domain-specific optima. This work\nintroduces SG-Blend, a novel activation function that blends our proposed\nSSwish, a first-order symmetric variant of Swish and the established GELU\nthrough dynamic interpolation. By adaptively blending these constituent\nfunctions via learnable parameters, SG-Blend aims to harness their\ncomplementary strengths: SSwish's controlled non-monotonicity and symmetry, and\nGELU's smooth, probabilistic profile, to achieve a more universally robust\nbalance between model expressivity and gradient stability. We conduct\ncomprehensive empirical evaluations across diverse modalities and\narchitectures, showing performance improvements across all considered natural\nlanguage and computer vision tasks and models. These results, achieved with\nnegligible computational overhead, underscore SG-Blend's potential as a\nversatile, drop-in replacement that consistently outperforms strong\ncontemporary baselines. The code is available at\nhttps://anonymous.4open.science/r/SGBlend-6CBC.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6fc0\u6d3b\u51fd\u6570SG-Blend\uff0c\u7ed3\u5408\u4e86SSwish\u548cGELU\u7684\u4f18\u70b9\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u6fc0\u6d3b\u51fd\u6570\u5982Swish\u548cGELU\u901a\u5e38\u8868\u73b0\u51fa\u9886\u57df\u7279\u5b9a\u7684\u6700\u4f18\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u3002", "method": "SG-Blend\u901a\u8fc7\u52a8\u6001\u63d2\u503c\u5c06SSwish\u548cGELU\u7ed3\u5408\uff0c\u5e76\u5229\u7528\u53ef\u5b66\u4e60\u53c2\u6570\u8fdb\u884c\u81ea\u9002\u5e94\u6df7\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSG-Blend\u5728\u5404\u79cd\u6a21\u6001\u548c\u67b6\u6784\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SG-Blend\u5728\u81ea\u7136\u8bed\u8a00\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002"}}
{"id": "2505.24422", "pdf": "https://arxiv.org/pdf/2505.24422", "abs": "https://arxiv.org/abs/2505.24422", "authors": ["Zhenghua Pan", "Yong Wang"], "title": "Three Kinds of Negation in Knowledge and Their Mathematical Foundations", "categories": ["cs.AI"], "comment": "32 pages,13 figures", "summary": "In the field of artificial intelligence, understanding, distinguishing,\nexpressing, and computing the negation in knowledge is a fundamental issue in\nknowledge processing and research. In this paper, we examine and analyze the\nunderstanding and characteristics of negation in various fields such as\nphilosophy, logic, and linguistics etc. Based on the distinction between the\nconcepts of contradiction and opposition, we propose that there are three\ndifferent types of negation in knowledge from a conceptual perspective:\ncontradictory negation, opposite negation, and intermediary negation. To\nestablish a mathematical foundation that fully reflects the intrinsic\nconnections, properties, and laws of these different forms of negation, we\nintroduce SCOI: sets with contradictory negation, opposite negation and\nintermediary negation, and LCOI: logic with contradictory negation, opposite\nnegation and intermediary negation, and we proved the main operational\nproperties of SCOI as well as the formal inference relations in LCOI.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5426\u5b9a\u5728\u77e5\u8bc6\u5904\u7406\u4e2d\u7684\u4e09\u79cd\u7c7b\u578b\uff08\u77db\u76fe\u5426\u5b9a\u3001\u5bf9\u7acb\u5426\u5b9a\u548c\u4e2d\u4ecb\u5426\u5b9a\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u53cd\u6620\u5176\u7279\u6027\u7684\u6570\u5b66\u6846\u67b6SCOI\u4e0eLCOI\u3002", "motivation": "\u5426\u5b9a\u5728\u77e5\u8bc6\u5904\u7406\u548c\u7814\u7a76\u4e2d\u662f\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff0c\u7406\u89e3\u5176\u4e0d\u540c\u5f62\u5f0f\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u8fdb\u884c\u77e5\u8bc6\u8868\u8fbe\u4e0e\u8ba1\u7b97\u3002", "method": "\u901a\u8fc7\u54f2\u5b66\u3001\u903b\u8f91\u5b66\u3001\u8bed\u8a00\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u5bf9\u5426\u5b9a\u7684\u7406\u89e3\u548c\u7279\u5f81\u8fdb\u884c\u5206\u6790\uff0c\u57fa\u4e8e\u77db\u76fe\u4e0e\u5bf9\u7acb\u6982\u5ff5\u7684\u533a\u522b\uff0c\u63d0\u51fa\u4e09\u79cd\u5426\u5b9a\u7c7b\u578b\u3002", "result": "\u4f5c\u8005\u5f15\u5165\u4e86SCOI\u548cLCOI\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u4e3b\u8981\u8fd0\u7b97\u6027\u8d28\u53ca\u5f62\u5f0f\u63a8\u7406\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5426\u5b9a\u7c7b\u578b\uff0c\u5e76\u4ecb\u7ecd\u4e86SCOI\u548cLCOI\u4f5c\u4e3a\u53cd\u6620\u8fd9\u4e9b\u5426\u5b9a\u5f62\u5f0f\u5185\u5728\u8054\u7cfb\u548c\u6027\u8d28\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2505.24737", "pdf": "https://arxiv.org/pdf/2505.24737", "abs": "https://arxiv.org/abs/2505.24737", "authors": ["Erchi Wang", "Yuqing Zhu", "Yu-Xiang Wang"], "title": "Adapting to Linear Separable Subsets with Large-Margin in Differentially Private Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper studies the problem of differentially private empirical risk\nminimization (DP-ERM) for binary linear classification. We obtain an efficient\n$(\\varepsilon,\\delta)$-DP algorithm with an empirical zero-one risk bound of\n$\\tilde{O}\\left(\\frac{1}{\\gamma^2\\varepsilon n} +\n\\frac{|S_{\\mathrm{out}}|}{\\gamma n}\\right)$ where $n$ is the number of data\npoints, $S_{\\mathrm{out}}$ is an arbitrary subset of data one can remove and\n$\\gamma$ is the margin of linear separation of the remaining data points (after\n$S_{\\mathrm{out}}$ is removed). Here, $\\tilde{O}(\\cdot)$ hides only logarithmic\nterms. In the agnostic case, we improve the existing results when the number of\noutliers is small. Our algorithm is highly adaptive because it does not require\nknowing the margin parameter $\\gamma$ or outlier subset $S_{\\mathrm{out}}$. We\nalso derive a utility bound for the advanced private hyperparameter tuning\nalgorithm.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u7528\u4e8e\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\uff0c\u5e76\u5728\u79bb\u7fa4\u70b9\u8f83\u5c11\u65f6\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u98ce\u9669\u8fb9\u754c\u7ed3\u679c\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u4e2d\u7684\u5dee\u5206\u9690\u79c1\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u9488\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u79bb\u7fa4\u70b9\u8f83\u5c11\u65f6\u7684\u6548\u679c\u8fdb\u884c\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u4e0d\u9700\u77e5\u9053\u8fb9\u7f18\u53c2\u6570\u03b3\u6216\u79bb\u7fa4\u5b50\u96c6S_out\u7684\u9ad8\u6548(\u03b5,\u03b4)-DP\u7b97\u6cd5\uff0c\u7814\u7a76\u8005\u5206\u6790\u4e86\u5176\u5728\u7ecf\u9a8c\u96f6\u4e00\u98ce\u9669\u4e0a\u7684\u8fb9\u754c\u3002", "result": "\u83b7\u5f97\u4e86\u7ecf\u9a8c\u96f6\u4e00\u98ce\u9669\u7684\u4e0a\u754c\u4e3a\u00d5(1/(\u03b3\u00b2\u03b5n) + |S_out|/(\u03b3n))\u7684\u9ad8\u6548(\u03b5,\u03b4)-DP\u7b97\u6cd5\uff0c\u5176\u4e2dn\u662f\u6570\u636e\u70b9\u6570\u91cf\uff0cS_out\u662f\u4efb\u610f\u53ef\u79fb\u9664\u7684\u6570\u636e\u5b50\u96c6\uff0c\u03b3\u662f\u5269\u4f59\u6570\u636e\u70b9\u7684\u7ebf\u6027\u5206\u79bb\u8fb9\u7f18\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684(\u03b5,\u03b4)-DP\u7b97\u6cd5\u7528\u4e8e\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u7684\u5dee\u5206\u9690\u79c1\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff0c\u5e76\u6539\u8fdb\u4e86\u73b0\u6709\u7ed3\u679c\uff0c\u5c24\u5176\u662f\u5728\u79bb\u7fa4\u70b9\u6570\u91cf\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.23947", "pdf": "https://arxiv.org/pdf/2505.23947", "abs": "https://arxiv.org/abs/2505.23947", "authors": ["Samuel M\u00fcller", "Arik Reuter", "Noah Hollmann", "David R\u00fcgamer", "Frank Hutter"], "title": "Position: The Future of Bayesian Prediction Is Prior-Fitted", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as position paper at ICML 2025", "summary": "Training neural networks on randomly generated artificial datasets yields\nBayesian models that capture the prior defined by the dataset-generating\ndistribution. Prior-data Fitted Networks (PFNs) are a class of methods designed\nto leverage this insight. In an era of rapidly increasing computational\nresources for pre-training and a near stagnation in the generation of new\nreal-world data in many applications, PFNs are poised to play a more important\nrole across a wide range of applications. They enable the efficient allocation\nof pre-training compute to low-data scenarios. Originally applied to small\nBayesian modeling tasks, the field of PFNs has significantly expanded to\naddress more complex domains and larger datasets. This position paper argues\nthat PFNs and other amortized inference approaches represent the future of\nBayesian inference, leveraging amortized learning to tackle data-scarce\nproblems. We thus believe they are a fruitful area of research. In this\nposition paper, we explore their potential and directions to address their\ncurrent limitations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86 Prior-data Fitted Networks (PFNs) \u5728\u8d1d\u53f6\u65af\u63a8\u65ad\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\uff0c\u5c55\u793a\u4e86 PFNs \u7684\u6f5c\u529b\u4ee5\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3\u8ba1\u7b97\u8d44\u6e90\u7684\u8fc5\u901f\u589e\u52a0\uff0c\u8bb8\u591a\u5e94\u7528\u4e2d\u65b0\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u7684\u751f\u6210\u51e0\u4e4e\u505c\u6ede\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u52a0\u91cd\u89c6\u80fd\u591f\u6709\u6548\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u5e94\u5bf9\u4f4e\u6570\u636e\u573a\u666f\u7684\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u8ba8\u8bba\u4e86\u901a\u8fc7\u5728\u968f\u673a\u751f\u6210\u7684\u4eba\u5de5\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u6355\u83b7\u7531\u6570\u636e\u96c6\u751f\u6210\u5206\u5e03\u5b9a\u4e49\u7684\u5148\u9a8c\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\u3002", "result": "Prior-data Fitted Networks (PFNs) \u5df2\u4ece\u6700\u521d\u5e94\u7528\u4e8e\u5c0f\u578b\u8d1d\u53f6\u65af\u5efa\u6a21\u4efb\u52a1\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u9886\u57df\u548c\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u663e\u793a\u51fa\u5176\u5728\u5e7f\u6cdb\u7684\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\u7684\u6f5c\u529b\u3002", "conclusion": "Prior-data Fitted Networks (PFNs) \u548c\u5176\u4ed6\u644a\u9500\u63a8\u65ad\u65b9\u6cd5\u4ee3\u8868\u4e86\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u672a\u6765\uff0c\u5b83\u4eec\u5229\u7528\u644a\u9500\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u6709\u524d\u9014\u7684\u7814\u7a76\u9886\u57df\u3002"}}
{"id": "2505.24426", "pdf": "https://arxiv.org/pdf/2505.24426", "abs": "https://arxiv.org/abs/2505.24426", "authors": ["David Gamez"], "title": "P: A Universal Measure of Predictive Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Over the last thirty years, considerable progress has been made with the\ndevelopment of systems that can drive cars, play games, predict protein folding\nand generate natural language. These systems are described as intelligent and\nthere has been a great deal of talk about the rapid increase in artificial\nintelligence and its potential dangers. However, our theoretical understanding\nof intelligence and ability to measure it lag far behind our capacity for\nbuilding systems that mimic intelligent human behaviour. There is no commonly\nagreed definition of the intelligence that AI systems are said to possess.\nNo-one has developed a practical measure that would enable us to compare the\nintelligence of humans, animals and AIs on a single ratio scale.\n  This paper sets out a new universal measure of intelligence that is based on\nthe hypothesis that prediction is the most important component of intelligence.\nAs an agent interacts with its normal environment, the accuracy of its\npredictions is summed up and the complexity of its predictions and perceived\nenvironment is accounted for using Kolmogorov complexity. Two experiments were\ncarried out to evaluate the practical feasibility of the algorithm. These\ndemonstrated that it could measure the intelligence of an agent embodied in a\nvirtual maze and an agent that makes predictions about time-series data. This\nuniversal measure could be the starting point for a new comparative science of\nintelligence that ranks humans, animals and AIs on a single ratio scale.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u667a\u80fd\u6d4b\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u80fd\u529b\u548cKolmogorov\u590d\u6742\u6027\u6765\u8bc4\u4f30\u4ee3\u7406\uff08\u5305\u62ecAI\uff09\u7684\u667a\u80fd\u6c34\u5e73\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u865a\u62df\u8ff7\u5bab\u548c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u5bf9\u667a\u80fd\u7684\u7406\u89e3\u548c\u6d4b\u91cf\u843d\u540e\u4e8e\u6784\u5efa\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u7cfb\u7edf\u7684\u80fd\u529b\u5efa\u8bae\uff0c\u4e14\u7f3a\u4e4f\u516c\u8ba4\u7684AI\u667a\u80fd\u5b9a\u4e49\u548c\u5b9e\u7528\u7684\u8861\u91cf\u6807\u51c6\u3002", "method": "\u901a\u8fc7\u5728\u6b63\u5e38\u73af\u5883\u4e2d\u4e0e\u4ee3\u7406\u4e92\u52a8\uff0c\u603b\u7ed3\u5176\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u5229\u7528Kolmogorov\u590d\u6742\u6027\u8003\u8651\u9884\u6d4b\u548c\u611f\u77e5\u73af\u5883\u7684\u590d\u6742\u6027\uff1b\u5e76\u8fdb\u884c\u4e86\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u7b97\u6cd5\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "result": "\u8be5\u7b97\u6cd5\u80fd\u591f\u6d4b\u91cf\u865a\u62df\u8ff7\u5bab\u4e2d\u4ee3\u7406\u7684\u667a\u80fd\u6c34\u5e73\u4ee5\u53ca\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u4ee3\u7406\u7684\u667a\u80fd\u6c34\u5e73\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u80fd\u529b\u7684\u901a\u7528\u667a\u80fd\u5ea6\u91cf\u65b9\u6cd5\uff0c\u53ef\u4f5c\u4e3a\u5bf9\u4eba\u7c7b\u3001\u52a8\u7269\u548c\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u7edf\u4e00\u6bd4\u8f83\u7684\u8d77\u70b9\u3002"}}
{"id": "2505.24784", "pdf": "https://arxiv.org/pdf/2505.24784", "abs": "https://arxiv.org/abs/2505.24784", "authors": ["Conor Heins", "Toon Van de Maele", "Alexander Tschantz", "Hampus Linander", "Dimitrije Markovic", "Tommaso Salvatori", "Corrado Pezzato", "Ozan Catal", "Ran Wei", "Magnus Koudahl", "Marco Perin", "Karl Friston", "Tim Verbelen", "Christopher Buckley"], "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "10 pages main text, 4 figures, 2 tables; 25 pages supplementary\n  material, 8 figures", "summary": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art\nperformance in various domains, but struggle with data efficiency compared to\nhuman learning, which leverages core priors about objects and their\ninteractions. Active inference offers a principled framework for integrating\nsensory information with prior knowledge to learn a world model and quantify\nthe uncertainty of its own beliefs and predictions. However, active inference\nmodels are usually crafted for a single task with bespoke knowledge, so they\nlack the domain flexibility typical of DRL approaches. To bridge this gap, we\npropose a novel architecture that integrates a minimal yet expressive set of\ncore priors about object-centric dynamics and interactions to accelerate\nlearning in low-data regimes. The resulting approach, which we call AXIOM,\ncombines the usual data efficiency and interpretability of Bayesian approaches\nwith the across-task generalization usually associated with DRL. AXIOM\nrepresents scenes as compositions of objects, whose dynamics are modeled as\npiecewise linear trajectories that capture sparse object-object interactions.\nThe structure of the generative model is expanded online by growing and\nlearning mixture models from single events and periodically refined through\nBayesian model reduction to induce generalization. AXIOM masters various games\nwithin only 10,000 interaction steps, with both a small number of parameters\ncompared to DRL, and without the computational expense of gradient-based\noptimization.", "AI": {"tldr": "AXIOM\u662f\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u65b9\u6cd5\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u52bf\u7684\u65b0\u67b6\u6784\uff0c\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u6570\u636e\u6548\u7387\u4e0a\u4e0d\u5982\u4eba\u7c7b\u5b66\u4e60\uff1b\u800c\u4e3b\u52a8\u63a8\u7406\u6a21\u578b\u901a\u5e38\u4e3a\u5355\u4e00\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4fDRL\u7684\u9886\u57df\u7075\u6d3b\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u517c\u987e\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "AXIOM\u4f7f\u7528\u4e00\u4e2a\u6700\u5c0f\u4f46\u5177\u6709\u8868\u8fbe\u6027\u7684\u5173\u4e8e\u5bf9\u8c61\u52a8\u529b\u5b66\u7684\u6838\u5fc3\u5148\u9a8c\u77e5\u8bc6\u96c6\u5408\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7ed3\u6784\u5728\u7ebf\u6269\u5c55\uff0c\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u6a21\u578b\u7b80\u5316\u8bf1\u5bfc\u6cdb\u5316\u3002", "result": "AXIOM\u5728\u4ec510,000\u6b21\u4ea4\u4e92\u6b65\u9aa4\u5185\u638c\u63e1\u591a\u79cd\u6e38\u620f\uff0c\u53c2\u6570\u6570\u91cf\u5c11\u4e8eDRL\uff0c\u4e14\u65e0\u9700\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "AXIOM\u6210\u529f\u7ed3\u5408\u4e86\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u6570\u636e\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff0c\u901a\u8fc7\u5bf9\u8c61\u4e2d\u5fc3\u7684\u52a8\u529b\u5b66\u6a21\u578b\u52a0\u901f\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u3002"}}
{"id": "2505.23949", "pdf": "https://arxiv.org/pdf/2505.23949", "abs": "https://arxiv.org/abs/2505.23949", "authors": ["Xiang Meng", "Mehdi Makni", "Rahul Mazumder"], "title": "TSENOR: Highly-Efficient Algorithm for Finding Transposable N:M Sparse Masks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Network pruning reduces the computational requirements of large neural\nnetworks, with N:M sparsity -- retaining only N out of every M consecutive\nweights -- offering a compelling balance between compressed model quality and\nhardware acceleration. However, N:M sparsity only accelerates forward-pass\ncomputations, as N:M patterns are not preserved during matrix transposition,\nlimiting efficiency during training where both passes are computationally\nintensive. While transposable N:M sparsity has been proposed to address this\nlimitation, existing methods for finding transposable N:M sparse masks either\nfail to scale to large models or are restricted to M=4 which results in\nsuboptimal compression-accuracy trade-off. We introduce an efficient solver for\ntransposable N:M masks that scales to billion-parameter models. We formulate\nmask generation as optimal transport problems and solve through entropy\nregularization and Dykstra's algorithm, followed by a rounding procedure. Our\ntensor-based implementation exploits GPU parallelism, achieving up to 100x\nspeedup with only 1-10% error compared to existing methods. Our approach can be\nintegrated with layer-wise N:M pruning frameworks including Wanda, SparseGPT\nand ALPS to produce transposable N:M sparse models with arbitrary N:M values.\nExperiments show that LLaMA3.2-8B with transposable 16:32 sparsity maintains\nperformance close to its standard N:M counterpart and outperforms standard 2:4\nsparse model, showing the practical value of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u9ad8\u6548\u7684\u53ef\u8f49\u7f6eN:M\u7a00\u758f\u63a9\u78bc\u6c42\u89e3\u5668\uff0c\u80fd\u5920\u64f4\u5c55\u5230\u5341\u5104\u53c3\u6578\u6a21\u578b\uff0c\u89e3\u6c7a\u4e86\u73fe\u6709\u65b9\u6cd5\u7121\u6cd5\u5927\u898f\u6a21\u61c9\u7528\u6216\u9650\u5236\u65bcM=4\u7684\u554f\u984c\u3002", "motivation": "\u73fe\u6709\u7684N:M\u7a00\u758f\u6a21\u5f0f\u5728\u8a13\u7df4\u6642\u56e0\u77e9\u9663\u8f49\u7f6e\u800c\u5931\u53bb\u6548\u7387\uff0c\u800c\u73fe\u6709\u7684\u53ef\u8f49\u7f6eN:M\u7a00\u758f\u65b9\u6cd5\u7121\u6cd5\u64f4\u5c55\u5230\u5927\u578b\u6a21\u578b\u6216\u53d7\u9650\u65bcM=4\uff0c\u5c0e\u81f4\u58d3\u7e2e\u8207\u6e96\u78ba\u6027\u4e4b\u9593\u7684\u6b0a\u8861\u4e0d\u4f73\u3002", "method": "\u5c07\u63a9\u78bc\u751f\u6210\u8868\u8ff0\u70ba\u6700\u4f73\u50b3\u8f38\u554f\u984c\uff0c\u4e26\u901a\u904e\u71b5\u6b63\u5247\u5316\u548cDykstra\u7b97\u6cd5\u6c42\u89e3\uff0c\u96a8\u5f8c\u9032\u884c\u6368\u5165\u8655\u7406\u3002\u5be6\u73fe\u57fa\u65bc\u5f35\u91cf\u7684GPU\u52a0\u901f\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u8a72\u65b9\u6cd5\u5728\u5341\u5104\u53c3\u6578\u6a21\u578b\u4e0a\u5be6\u73fe\u9ad8\u9054100\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u8aa4\u5dee\u50c5\u70ba1-10%\u3002LLaMA3.2-8B\u6a21\u578b\u4f7f\u7528\u53ef\u8f49\u7f6e16:32\u7a00\u758f\u6a21\u5f0f\u6642\u8868\u73fe\u63a5\u8fd1\u6a19\u6e96N:M\u6a21\u578b\uff0c\u4e14\u512a\u65bc\u6a19\u6e962:4\u7a00\u758f\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ef\u8f49\u7f6eN:M\u7a00\u758f\u63a9\u78bc\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u53ef\u64f4\u5c55\u6027\u548c\u5be6\u969b\u50f9\u503c\uff0c\u53ef\u7528\u65bc\u5927\u578b\u795e\u7d93\u7db2\u7d61\u8a13\u7df4\u8207\u63a8\u8ad6\u3002"}}
{"id": "2505.24442", "pdf": "https://arxiv.org/pdf/2505.24442", "abs": "https://arxiv.org/abs/2505.24442", "authors": ["Zhentao Xie", "Chengcheng Han", "Jinxin Shi", "Wenjun Cui", "Xin Zhao", "Xingjiao Wu", "Jiabao Zhao"], "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation", "categories": ["cs.AI"], "comment": "Accepted by ACL 2025 (Findings)", "summary": "Although multi-agent systems based on large language models show strong\ncapabilities on multiple tasks, they are still limited by high computational\noverhead, information loss, and robustness. Inspired by ResNet's residual\nlearning, we propose Residual Mixture-of-Agents (RMoA), integrating residual\nconnections to optimize efficiency and reliability. To maximize information\nutilization from model responses while minimizing computational costs, we\ninnovatively design an embedding-based diversity selection mechanism that\ngreedily selects responses via vector similarity. Furthermore, to mitigate\niterative information degradation, we introduce a Residual Extraction Agent to\npreserve cross-layer incremental information by capturing inter-layer response\ndifferences, coupled with a Residual Aggregation Agent for hierarchical\ninformation integration. Additionally, we propose an adaptive termination\nmechanism that dynamically halts processing based on residual convergence,\nfurther improving inference efficiency. RMoA achieves state-of-the-art\nperformance on the benchmarks of across alignment, mathematical reasoning, code\ngeneration, and multitasking understanding, while significantly reducing\ncomputational overhead. Code is available at\nhttps://github.com/mindhunter01/RMoA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aResidual Mixture-of-Agents (RMoA)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6b8b\u5dee\u8fde\u63a5\u548c\u591a\u79cd\u4f18\u5316\u673a\u5236\uff0c\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u4ecd\u53d7\u9650\u4e8e\u9ad8\u8ba1\u7b97\u5f00\u9500\u3001\u4fe1\u606f\u635f\u5931\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8e\u6b8b\u5dee\u8fde\u63a5\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u5f15\u5165\u5d4c\u5165\u591a\u6837\u6027\u9009\u62e9\u673a\u5236\u3001\u6b8b\u5dee\u63d0\u53d6\u667a\u80fd\u4f53\u3001\u6b8b\u5dee\u805a\u5408\u667a\u80fd\u4f53\u4ee5\u53ca\u81ea\u9002\u5e94\u7ec8\u6b62\u673a\u5236\u3002", "result": "RMoA\u5728\u8de8\u5bf9\u9f50\u3001\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u591a\u4efb\u52a1\u7406\u89e3\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "RMoA\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2505.23954", "pdf": "https://arxiv.org/pdf/2505.23954", "abs": "https://arxiv.org/abs/2505.23954", "authors": ["Dylan Zapzalka", "Trenton Chang", "Lindsay Warrenburg", "Sae-Hwan Park", "Daniel K. Shenfeld", "Ravi B. Parikh", "Jenna Wiens", "Maggie Makar"], "title": "Estimating Misreporting in the Presence of Genuine Modification: A Causal Perspective", "categories": ["cs.LG"], "comment": null, "summary": "In settings where ML models are used to inform the allocation of resources,\nagents affected by the allocation decisions might have an incentive to\nstrategically change their features to secure better outcomes. While prior work\nhas studied strategic responses broadly, disentangling misreporting from\ngenuine modification remains a fundamental challenge. In this paper, we propose\na causally-motivated approach to identify and quantify how much an agent\nmisreports on average by distinguishing deceptive changes in their features\nfrom genuine modification. Our key insight is that, unlike genuine\nmodification, misreported features do not causally affect downstream variables\n(i.e., causal descendants). We exploit this asymmetry by comparing the causal\neffect of misreported features on their causal descendants as derived from\nmanipulated datasets against those from unmanipulated datasets. We formally\nprove identifiability of the misreporting rate and characterize the variance of\nour estimator. We empirically validate our theoretical results using a\nsemi-synthetic and real Medicare dataset with misreported data, demonstrating\nthat our approach can be employed to identify misreporting in real-world\nscenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u91cf\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u4ee3\u7406\u7684\u865a\u5047\u62a5\u544a\u884c\u4e3a\uff0c\u901a\u8fc7\u533a\u5206\u6b3a\u9a97\u6027\u7279\u5f81\u53d8\u5316\u548c\u771f\u5b9e\u4fee\u6539\uff0c\u89e3\u51b3\u4e86\u8d44\u6e90\u5206\u914d\u51b3\u7b56\u4e2d\u7684\u6218\u7565\u54cd\u5e94\u95ee\u9898\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u8d44\u6e90\u5206\u914d\u7684\u73af\u5883\u4e2d\uff0c\u53d7\u5f71\u54cd\u7684\u4ee3\u7406\u53ef\u80fd\u4f1a\u6218\u7565\u6027\u5730\u66f4\u6539\u5176\u7279\u5f81\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u800c\u5982\u4f55\u533a\u5206\u865a\u5047\u62a5\u544a\u548c\u771f\u5b9e\u4fee\u6539\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5229\u7528\u56e0\u679c\u63a8\u65ad\uff0c\u6bd4\u8f83\u64cd\u7eb5\u6570\u636e\u96c6\u4e0e\u975e\u64cd\u7eb5\u6570\u636e\u96c6\u4e2d\u865a\u5047\u62a5\u544a\u7279\u5f81\u5bf9\u5176\u56e0\u679c\u540e\u4ee3\u7684\u56e0\u679c\u6548\u5e94\u5dee\u5f02\uff0c\u4ece\u800c\u8bc6\u522b\u548c\u91cf\u5316\u5e73\u5747\u865a\u5047\u62a5\u544a\u7387\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u865a\u5047\u62a5\u544a\u7387\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u5bf9\u4f30\u8ba1\u91cf\u7684\u65b9\u5dee\u8fdb\u884c\u4e86\u8868\u5f81\uff1b\u5728\u534a\u5408\u6210\u548c\u771f\u5b9e\u7684Medicare\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u56e0\u679c\u9a71\u52a8\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u865a\u5047\u62a5\u544a\u884c\u4e3a\uff0c\u4e3a\u8d44\u6e90\u5206\u914d\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.24458", "pdf": "https://arxiv.org/pdf/2505.24458", "abs": "https://arxiv.org/abs/2505.24458", "authors": ["Tianlong Yu", "Chenghang Ye", "Zheyu Yang", "Ziyi Zhou", "Cui Tang", "Zui Tao", "Jun Zhang", "Kailong Wang", "Liting Zhou", "Yang Yang", "Ting Bi"], "title": "SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors", "categories": ["cs.AI"], "comment": null, "summary": "The SEAR Dataset is a novel multimodal resource designed to study the\nemerging threat of social engineering (SE) attacks orchestrated through\naugmented reality (AR) and multimodal large language models (LLMs). This\ndataset captures 180 annotated conversations across 60 participants in\nsimulated adversarial scenarios, including meetings, classes and networking\nevents. It comprises synchronized AR-captured visual/audio cues (e.g., facial\nexpressions, vocal tones), environmental context, and curated social media\nprofiles, alongside subjective metrics such as trust ratings and susceptibility\nassessments. Key findings reveal SEAR's alarming efficacy in eliciting\ncompliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and\nhijacking trust (76.7% post-interaction trust surge). The dataset supports\nresearch in detecting AR-driven SE attacks, designing defensive frameworks, and\nunderstanding multimodal adversarial manipulation. Rigorous ethical safeguards,\nincluding anonymization and IRB compliance, ensure responsible use. The SEAR\ndataset is available at https://github.com/INSLabCN/SEAR-Dataset.", "AI": {"tldr": "SEAR\u6570\u636e\u96c6\u63ed\u793a\u4e86\u57fa\u4e8e\u589e\u5f3a\u73b0\u5b9e\u7684\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u7684\u4e25\u91cd\u6027\uff0c\u5e76\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u9632\u5fa1\u6846\u67b6\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u6b63\u6210\u4e3a\u4e00\u79cd\u65b0\u5174\u5a01\u80c1\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u6765\u7814\u7a76\u548c\u5e94\u5bf9\u8fd9\u79cd\u653b\u51fb\u65b9\u5f0f\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b180\u4e2a\u6ce8\u91ca\u5bf9\u8bdd\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6SEAR\uff0c\u8986\u76d660\u540d\u53c2\u4e0e\u8005\u5728\u6a21\u62df\u5bf9\u6297\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\uff0c\u5e76\u540c\u6b65\u6355\u83b7\u89c6\u89c9\u548c\u97f3\u9891\u7ebf\u7d22\u3001\u73af\u5883\u80cc\u666f\u4ee5\u53ca\u793e\u4ea4\u5a92\u4f53\u8d44\u6599\u7b49\u4fe1\u606f\u3002", "result": "\u5173\u952e\u53d1\u73b0\u5305\u62ecSEAR\u5728\u8bf1\u5bfc\u7528\u6237\u987a\u4ece\u4e2d\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6548\u679c\uff08\u598293.3%\u7684\u9493\u9c7c\u94fe\u63a5\u70b9\u51fb\u7387\uff0c85%\u7684\u63a5\u542c\u7387\uff09\u4ee5\u53ca\u663e\u8457\u5f71\u54cd\u4fe1\u4efb\u5ea6\uff0876.7%\u7684\u4e92\u52a8\u540e\u4fe1\u4efb\u6fc0\u589e\uff09\u3002", "conclusion": "SEAR\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u589e\u5f3a\u73b0\u5b9e\u9a71\u52a8\u7684\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u9700\u8981\u5236\u5b9a\u9632\u5fa1\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002"}}
{"id": "2505.23960", "pdf": "https://arxiv.org/pdf/2505.23960", "abs": "https://arxiv.org/abs/2505.23960", "authors": ["Henry Conklin"], "title": "Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "PhD Thesis, 204 pages; entropy estimation discussed from p.94", "summary": "Despite the remarkable success of large large-scale neural networks, we still\nlack unified notation for thinking about and describing their representational\nspaces. We lack methods to reliably describe how their representations are\nstructured, how that structure emerges over training, and what kinds of\nstructures are desirable. This thesis introduces quantitative methods for\nidentifying systematic structure in a mapping between spaces, and leverages\nthem to understand how deep-learning models learn to represent information,\nwhat representational structures drive generalisation, and how design decisions\ncondition the structures that emerge. To do this I identify structural\nprimitives present in a mapping, along with information theoretic\nquantifications of each. These allow us to analyse learning, structure, and\ngeneralisation across multi-agent reinforcement learning models,\nsequence-to-sequence models trained on a single task, and Large Language\nModels. I also introduce a novel, performant, approach to estimating the\nentropy of vector space, that allows this analysis to be applied to models\nranging in size from 1 million to 12 billion parameters.\n  The experiments here work to shed light on how large-scale distributed models\nof cognition learn, while allowing us to draw parallels between those systems\nand their human analogs. They show how the structures of language and the\nconstraints that give rise to them in many ways parallel the kinds of\nstructures that drive performance of contemporary neural networks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u7a7a\u95f4\u7f3a\u4e4f\u7edf\u4e00\u63cf\u8ff0\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u5b9a\u91cf\u65b9\u6cd5\u5206\u6790\u6a21\u578b\u7ed3\u6784\u4e0e\u6cdb\u5316\u80fd\u529b\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5bf9\u5176\u8868\u793a\u7a7a\u95f4\u7684\u63cf\u8ff0\u7f3a\u4e4f\u7edf\u4e00\u7684\u7b26\u53f7\u4f53\u7cfb\u548c\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165\u65b0\u65b9\u6cd5\u6765\u7406\u89e3\u5176\u7ed3\u6784\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6027\u80fd\u4f30\u8ba1\u5411\u91cf\u7a7a\u95f4\u71b5\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u65b9\u6cd5\u5206\u6790\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u3001\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u91cf\u5316\u65b9\u6cd5\u63ed\u793a\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8ba4\u77e5\u6a21\u578b\u7684\u5b66\u4e60\u673a\u5236\uff0c\u5e76\u5728\u8bed\u8a00\u7ed3\u6784\u4e0e\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u4e4b\u95f4\u5efa\u7acb\u4e86\u7c7b\u6bd4\u5173\u7cfb\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u8bc6\u522b\u7ed3\u6784\u57fa\u672c\u5143\u7d20\u548c\u4fe1\u606f\u7406\u8bba\u91cf\u5316\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b66\u4e60\u3001\u7ed3\u6784\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u3002"}}
{"id": "2505.24478", "pdf": "https://arxiv.org/pdf/2505.24478", "abs": "https://arxiv.org/abs/2505.24478", "authors": ["Vasilije Markovic", "Lazar Obradovic", "Laszlo Hajdu", "Jovan Pavlovic"], "title": "Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "This is a preliminary version. A revised and expanded version is in\n  preparation", "summary": "Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) results\nin complex systems with numerous hyperparameters that directly affect\nperformance. While such systems are increasingly common in retrieval-augmented\ngeneration, the role of systematic hyperparameter optimization remains\nunderexplored. In this paper, we study this problem in the context of Cognee, a\nmodular framework for end-to-end KG construction and retrieval. Using three\nmulti-hop QA benchmarks (HotPotQA, TwoWikiMultiHop, and MuSiQue) we optimize\nparameters related to chunking, graph construction, retrieval, and prompting.\nEach configuration is scored using established metrics (exact match, F1, and\nDeepEval's LLM-based correctness metric). Our results demonstrate that\nmeaningful gains can be achieved through targeted tuning. While the gains are\nconsistent, they are not uniform, with performance varying across datasets and\nmetrics. This variability highlights both the value of tuning and the\nlimitations of standard evaluation measures. While demonstrating the immediate\npotential of hyperparameter tuning, we argue that future progress will depend\nnot only on architectural advances but also on clearer frameworks for\noptimization and evaluation in complex, modular systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u4f18\u5316\u590d\u6742\u7cfb\u7edf\u4e2d\u8d85\u53c2\u6570\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u7684\u73af\u5883\u4e2d\uff0c\u7ed3\u679c\u663e\u793a\u6709\u9488\u5bf9\u6027\u7684\u8c03\u4f18\u80fd\u591f\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u5408\u7684\u7cfb\u7edf\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u8d8a\u6765\u8d8a\u5e38\u89c1\uff0c\u4f46\u7cfb\u7edf\u7684\u8d85\u53c2\u6570\u4f18\u5316\u7814\u7a76\u4ecd\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u4e09\u4e2a\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\uff08HotPotQA\u3001TwoWikiMultiHop \u548c MuSiQue\uff09\u5bf9 Cognee \u6846\u67b6\u4e2d\u7684\u5757\u5212\u5206\u3001\u56fe\u6784\u5efa\u3001\u68c0\u7d22\u548c\u63d0\u793a\u7b49\u53c2\u6570\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u5229\u7528\u7cbe\u786e\u5339\u914d\u3001F1 \u5206\u6570\u4ee5\u53ca DeepEval \u7684\u57fa\u4e8e LLM \u7684\u6b63\u786e\u6027\u5ea6\u91cf\u6765\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6709\u9488\u5bf9\u6027\u7684\u8c03\u4f18\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u4e0d\u540c\u6570\u636e\u96c6\u548c\u5ea6\u91cf\u6807\u51c6\u4e0b\u7684\u63d0\u5347\u5e76\u4e0d\u4e00\u81f4\uff0c\u8fd9\u7a81\u51fa\u4e86\u8c03\u4f18\u7684\u4ef7\u503c\u4ee5\u53ca\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7684\u8fdb\u5c55\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u67b6\u6784\u7684\u6539\u8fdb\uff0c\u8fd8\u9700\u8981\u66f4\u6e05\u6670\u7684\u4f18\u5316\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2505.23967", "pdf": "https://arxiv.org/pdf/2505.23967", "abs": "https://arxiv.org/abs/2505.23967", "authors": ["Anders Aamand", "Justin Y. Chen", "Siddharth Gollapudi", "Sandeep Silwal", "Hao Wu"], "title": "Improved Approximations for Hard Graph Problems using Predictions", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We design improved approximation algorithms for NP-hard graph problems by\nincorporating predictions (e.g., learned from past data). Our prediction model\nbuilds upon and extends the $\\varepsilon$-prediction framework by Cohen-Addad,\nd'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024). We consider an edge-based\nversion of this model, where each edge provides two bits of information,\ncorresponding to predictions about whether each of its endpoints belong to an\noptimal solution. Even with weak predictions where each bit is only\n$\\varepsilon$-correlated with the true solution, this information allows us to\nbreak approximation barriers in the standard setting. We develop algorithms\nwith improved approximation ratios for MaxCut, Vertex Cover, Set Cover, and\nMaximum Independent Set problems (among others). Across these problems, our\nalgorithms share a unifying theme, where we separately satisfy constraints\nrelated to high degree vertices (using predictions) and low-degree vertices\n(without using predictions) and carefully combine the answers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u9884\u6d4b\u673a\u5236\uff08\u4f8b\u5982\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5b66\u4e60\u5f97\u5230\uff09\u8bbe\u8ba1\u4e86\u9488\u5bf9NP\u96be\u89e3\u56fe\u95ee\u9898\u7684\u6539\u8fdb\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u5728\u6807\u51c6\u8bbe\u5b9a\u4e2d\uff0c\u8bb8\u591a\u56fe\u95ee\u9898\u5b58\u5728\u8fd1\u4f3c\u6027\u969c\u788d\u3002\u4f5c\u8005\u65e8\u5728\u5229\u7528\u5f31\u9884\u6d4b\u4fe1\u606f\u6765\u7a81\u7834\u8fd9\u4e9b\u969c\u788d\uff0c\u5e76\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u6587\u7ae0\u57fa\u4e8e\u5e76\u6269\u5c55\u4e86Cohen-Addad\u7b49\u4eba\u63d0\u51fa\u7684\u03b5-\u9884\u6d4b\u6846\u67b6\uff0c\u91c7\u7528\u4e00\u79cd\u57fa\u4e8e\u8fb9\u7684\u6a21\u578b\uff0c\u6bcf\u6761\u8fb9\u63d0\u4f9b\u4e24\u4e2a\u6bd4\u7279\u7684\u9884\u6d4b\u4fe1\u606f\uff0c\u5206\u522b\u5bf9\u5e94\u5176\u7aef\u70b9\u662f\u5426\u5c5e\u4e8e\u6700\u4f18\u89e3\u3002\u7b97\u6cd5\u7edf\u4e00\u5730\u5904\u7406\u9ad8\u3001\u4f4e\u5ea6\u9876\u70b9\u7ea6\u675f\uff0c\u7ed3\u5408\u9884\u6d4b\u4e0e\u975e\u9884\u6d4b\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u5bf9\u4e8eMaxCut\u3001Vertex Cover\u3001Set Cover\u548cMaximum Independent Set\u7b49\u95ee\u9898\uff0c\u4f5c\u8005\u6210\u529f\u5f00\u53d1\u51fa\u5177\u6709\u66f4\u597d\u8fd1\u4f3c\u6bd4\u7684\u7b97\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u9884\u6d4b\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\uff0c\u5373\u4f7f\u4f7f\u7528\u8f83\u5f31\u7684\u9884\u6d4b\u4fe1\u606f\uff0c\u4e5f\u53ef\u4ee5\u663e\u8457\u6539\u5584\u7ecf\u5178\u8fd1\u4f3c\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.24479", "pdf": "https://arxiv.org/pdf/2505.24479", "abs": "https://arxiv.org/abs/2505.24479", "authors": ["Sania Nayab", "Marco Simoni", "Giulio Rossolini"], "title": "Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation", "categories": ["cs.AI", "cs.CL", "cs.SI"], "comment": null, "summary": "The rapid spread of misinformation, further amplified by recent advances in\ngenerative AI, poses significant threats to society, impacting public opinion,\ndemocratic stability, and national security. Understanding and proactively\nassessing these threats requires exploring methodologies that enable structured\nand scalable misinformation generation. In this paper, we propose a novel\napproach that leverages knowledge graphs (KGs) as structured semantic resources\nto systematically generate fake triplets. By analyzing the structural\nproperties of KGs, such as the distance between entities and their predicates,\nwe identify plausibly false relationships. These triplets are then used to\nguide large language models (LLMs) in generating misinformation statements with\nvarying degrees of credibility. By utilizing structured semantic relationships,\nour deterministic approach produces misinformation inherently challenging for\nhumans to detect, drawing exclusively upon publicly available KGs (e.g.,\nWikiGraphs).\n  Additionally, we investigate the effectiveness of LLMs in distinguishing\nbetween genuine and artificially generated misinformation. Our analysis\nhighlights significant limitations in current LLM-based detection methods,\nunderscoring the necessity for enhanced detection strategies and a deeper\nexploration of inherent biases in generative models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u865a\u5047\u4fe1\u606f\u7684\u65b0\u6280\u672f\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u68c0\u6d4b\u65b9\u6cd5\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u7531\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u800c\u52a0\u5267\u7684\u865a\u5047\u4fe1\u606f\u5a01\u80c1\uff0c\u9700\u8981\u63a2\u7d22\u80fd\u591f\u5b9e\u73b0\u7ed3\u6784\u5316\u548c\u53ef\u6269\u5c55\u865a\u5047\u4fe1\u606f\u751f\u6210\u7684\u65b9\u6cd5\u3002", "method": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\u4f5c\u4e3a\u7ed3\u6784\u5316\u8bed\u4e49\u8d44\u6e90\u6765\u7cfb\u7edf\u751f\u6210\u865a\u5047\u4e09\u5143\u7ec4\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u5177\u6709\u4e0d\u540c\u53ef\u4fe1\u5ea6\u7684\u865a\u5047\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u5206\u6790\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u8bc6\u522b\u51fa\u53ef\u80fd\u9519\u8bef\u7684\u5173\u7cfb\uff0c\u5e76\u751f\u6210\u7528\u4e8e\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5236\u9020\u865a\u5047\u4fe1\u606f\u7684\u4e09\u5143\u7ec4\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u865a\u5047\u4fe1\u606f\u7684\u65b9\u6cd5\u6781\u5177\u6311\u6218\u6027\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u6539\u8fdb\u68c0\u6d4b\u7b56\u7565\u53ca\u6df1\u5165\u7814\u7a76\u751f\u6210\u6a21\u578b\u4e2d\u7684\u56fa\u6709\u504f\u5dee\u3002"}}
{"id": "2505.23971", "pdf": "https://arxiv.org/pdf/2505.23971", "abs": "https://arxiv.org/abs/2505.23971", "authors": ["William Merrill", "Shane Arora", "Dirk Groeneveld", "Hannaneh Hajishirzi"], "title": "Critical Batch Size Revisited: A Simple Empirical Approach to Large-Batch Language Model Training", "categories": ["cs.LG"], "comment": null, "summary": "The right batch size is important when training language models at scale: a\nlarge batch size is necessary for fast training, but a batch size that is too\nlarge will harm token efficiency. To navigate this tradeoff, McCandlish et al.\n(2018) suggest that a critical batch size (CBS), below which training will not\nsubstantially degrade loss, can be estimated based on the gradient noise scale\nduring training. While their method has been adopted in practice, e.g., when\ntraining GPT-3, strong assumptions are required to justify gradient noise as a\nproxy for the CBS, which makes it unclear whether their approach should be\ntrusted in practice, limiting its applicability. In this paper, we introduce a\nsimple, empirical approach to directly measure the CBS and show how the CBS\nevolves over training. Applying our approach to the OLMo models, we find that\nCBS is near 0 at initialization, increases rapidly at first, and then plateaus\nas training progresses. Furthermore, we find that this trend holds across\ndifferent model sizes (1B and 7B), suggesting CBS from small training runs can\ninform larger-scale training runs. Our findings about how the CBS changes over\ntraining motivate batch size warmup as a natural way to reliably train language\nmodels at large batch size: start the batch size small and increase it as the\nCBS grows. To validate this claim, we use batch size warmup to train OLMo 1B to\nslightly better loss than the original training run with 43% fewer gradient\nsteps. This shows how our framework can be applied to reliably train language\nmodels at larger batch sizes, increasing data parallelism without compromising\nperformance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5b9e\u8bc1\u65b9\u6cd5\u6765\u6d4b\u91cf\u4e34\u754c\u6279\u91cf\u5927\u5c0f\uff08CBS\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\uff0c\u4ee5\u66f4\u9ad8\u6548\u548c\u53ef\u9760\u7684\u65b9\u5f0f\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4f7f\u7528\u68af\u5ea6\u566a\u58f0\u4f5c\u4e3aCBS\u4ee3\u7406\u65f6\u6240\u9700\u7684\u5f3a\u5047\u8bbe\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u66f4\u5b9e\u7528\u4e14\u53ef\u4fe1\u8d56\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5bf9OLMo\u6a21\u578b\u7684\u5b9e\u9a8c\uff0c\u89c2\u5bdfCBS\u968f\u8bad\u7ec3\u8fc7\u7a0b\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u5e76\u5229\u7528\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u53d1\u73b0CBS\u5728\u8bad\u7ec3\u521d\u671f\u8fc5\u901f\u589e\u52a0\uff0c\u968f\u540e\u8d8b\u4e8e\u7a33\u5b9a\uff1b\u901a\u8fc7\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\uff0c\u752843%\u66f4\u5c11\u7684\u68af\u5ea6\u6b65\u9aa4\u5b9e\u73b0\u4e86\u6bd4\u539f\u59cb\u8bad\u7ec3\u66f4\u597d\u7684\u635f\u5931\u503c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u6d4b\u91cf\u4e34\u754c\u6279\u91cf\u5927\u5c0f\uff08CBS\uff09\u7684\u5b9e\u8bc1\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4e0d\u635f\u5bb3\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u53ef\u9760\u5730\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2505.24493", "pdf": "https://arxiv.org/pdf/2505.24493", "abs": "https://arxiv.org/abs/2505.24493", "authors": ["Xin Jing", "Jiadong Wang", "Iosif Tsangko", "Andreas Triantafyllopoulos", "Bj\u00f6rn W. Schuller"], "title": "MELT: Towards Automated Multimodal Emotion Data Annotation by Leveraging LLM Embedded Knowledge", "categories": ["cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "Although speech emotion recognition (SER) has advanced significantly with\ndeep learning, annotation remains a major hurdle. Human annotation is not only\ncostly but also subject to inconsistencies annotators often have different\npreferences and may lack the necessary contextual knowledge, which can lead to\nvaried and inaccurate labels. Meanwhile, Large Language Models (LLMs) have\nemerged as a scalable alternative for annotating text data. However, the\npotential of LLMs to perform emotional speech data annotation without human\nsupervision has yet to be thoroughly investigated. To address these problems,\nwe apply GPT-4o to annotate a multimodal dataset collected from the sitcom\nFriends, using only textual cues as inputs. By crafting structured text\nprompts, our methodology capitalizes on the knowledge GPT-4o has accumulated\nduring its training, showcasing that it can generate accurate and contextually\nrelevant annotations without direct access to multimodal inputs. Therefore, we\npropose MELT, a multimodal emotion dataset fully annotated by GPT-4o. We\ndemonstrate the effectiveness of MELT by fine-tuning four self-supervised\nlearning (SSL) backbones and assessing speech emotion recognition performance\nacross emotion datasets. Additionally, our subjective experiments\\' results\ndemonstrate a consistence performance improvement on SER.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528GPT-4o\u5bf9\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u8fdb\u884c\u81ea\u52a8\u6807\u6ce8\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u7531GPT-4o\u6807\u6ce8\u7684\u591a\u6a21\u6001\u60c5\u611f\u6570\u636e\u96c6MELT\u3002", "motivation": "\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u80fd\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u7684GPT-4o\u5728\u60c5\u611f\u8bed\u97f3\u6570\u636e\u6807\u6ce8\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u6784\u9020\u7ed3\u6784\u5316\u6587\u672c\u63d0\u793a\uff0c\u5229\u7528GPT-4o\u751f\u6210\u51c6\u786e\u4e14\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6807\u6ce8\uff0c\u4ec5\u4f7f\u7528\u6587\u672c\u7ebf\u7d22\u4f5c\u4e3a\u8f93\u5165\u6765\u6807\u6ce8\u6765\u81ea\u60c5\u666f\u559c\u5267Friends\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u4e86MELT\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u56db\u79cd\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u9aa8\u5e72\u7f51\u7edc\u8bc4\u4f30\u5176\u5728\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u4e3b\u89c2\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728SER\u4efb\u52a1\u4e0a\u6709\u4e00\u81f4\u6027\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cGPT-4o\u80fd\u591f\u5728\u6ca1\u6709\u76f4\u63a5\u591a\u6a21\u6001\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u8fdb\u884c\u60c5\u611f\u8bed\u97f3\u6570\u636e\u6807\u6ce8\uff0cMELT\u6570\u636e\u96c6\u5c55\u793a\u4e86\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.23973", "pdf": "https://arxiv.org/pdf/2505.23973", "abs": "https://arxiv.org/abs/2505.23973", "authors": ["Asaf Goren", "Natalie Lang", "Nir Shlezinger", "Alejandro Cohen"], "title": "Adaptive Deadline and Batch Layered Synchronized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed edge devices while preserving data privacy, and typically operates\nin a round-based synchronous manner. However, synchronous FL suffers from\nlatency bottlenecks due to device heterogeneity, where slower clients\n(stragglers) delay or degrade global updates. Prior solutions, such as fixed\ndeadlines, client selection, and layer-wise partial aggregation, alleviate the\neffect of stragglers, but treat round timing and local workload as static\nparameters, limiting their effectiveness under strict time constraints. We\npropose ADEL-FL, a novel framework that jointly optimizes per-round deadlines\nand user-specific batch sizes for layer-wise aggregation. Our approach\nformulates a constrained optimization problem minimizing the expected L2\ndistance to the global optimum under total training time and global rounds. We\nprovide a convergence analysis under exponential compute models and prove that\nADEL-FL yields unbiased updates with bounded variance. Extensive experiments\ndemonstrate that ADEL-FL outperforms alternative methods in both convergence\nrate and final accuracy under heterogeneous conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ADEL-FL\uff0c\u4e00\u79cd\u52a8\u6001\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u622a\u6b62\u65f6\u95f4\u548c\u6279\u91cf\u5927\u5c0f\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f02\u6784\u73af\u5883\u4e0b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u540c\u6b65\u8054\u90a6\u5b66\u4e60\u7531\u4e8e\u8bbe\u5907\u5f02\u6784\u6027\uff08\u6162\u901f\u5ba2\u6237\u7aef\uff09\u5b58\u5728\u5ef6\u8fdf\u74f6\u9888\uff0c\u800c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5c06\u65f6\u95f4\u5b89\u6392\u548c\u5de5\u4f5c\u8d1f\u8f7d\u89c6\u4e3a\u9759\u6001\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5176\u6548\u679c\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u53d7\u9650\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u8bad\u7ec3\u65f6\u95f4\u548c\u5168\u5c40\u8f6e\u6b21\u7ea6\u675f\u4e0b\u7684\u9884\u671fL2\u8ddd\u79bb\u5230\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u5e76\u5728\u6307\u6570\u8ba1\u7b97\u6a21\u578b\u4e0b\u63d0\u4f9b\u6536\u655b\u6027\u5206\u6790\u548c\u8bc1\u660e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cADEL-FL\u5728\u5f02\u6784\u6761\u4ef6\u4e0b\u6bd4\u66ff\u4ee3\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u51c6\u786e\u7387\u8868\u73b0\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADEL-FL\u7684\u65b0\u578b\u6846\u67b6\uff0c\u80fd\u591f\u8054\u5408\u4f18\u5316\u6bcf\u8f6e\u622a\u6b62\u65f6\u95f4\u548c\u7528\u6237\u7279\u5b9a\u7684\u6279\u91cf\u5927\u5c0f\uff0c\u4ee5\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2505.24597", "pdf": "https://arxiv.org/pdf/2505.24597", "abs": "https://arxiv.org/abs/2505.24597", "authors": ["Shuai Liu", "Ning Cao", "Yile Chen", "Yue Jiang", "Gao Cong"], "title": "Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Next location prediction plays a critical role in understanding human\nmobility patterns. However, existing approaches face two core limitations: (1)\nthey fall short in capturing the complex, multi-functional semantics of\nreal-world locations; and (2) they lack the capacity to model heterogeneous\nbehavioral dynamics across diverse user groups. To tackle these challenges, we\nintroduce NextLocMoE, a novel framework built upon large language models (LLMs)\nand structured around a dual-level Mixture-of-Experts (MoE) design. Our\narchitecture comprises two specialized modules: a Location Semantics MoE that\noperates at the embedding level to encode rich functional semantics of\nlocations, and a Personalized MoE embedded within the Transformer backbone to\ndynamically adapt to individual user mobility patterns. In addition, we\nincorporate a history-aware routing mechanism that leverages long-term\ntrajectory data to enhance expert selection and ensure prediction stability.\nEmpirical evaluations across several real-world urban datasets show that\nNextLocMoE achieves superior performance in terms of predictive accuracy,\ncross-domain generalization, and interpretability", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NextLocMoE\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6df7\u5408\u4e13\u5bb6\u7ed3\u6784\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u7528\u6237\u4e0b\u4e00\u4f4d\u5740\u9884\u6d4b\u7684\u6548\u679c\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5f88\u597d\u5730\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u5730\u70b9\u7684\u590d\u6742\u591a\u4e49\u6027\u548c\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "method": "\u5f15\u5165NextLocMoE\uff0c\u5305\u542bLocation Semantics MoE\u548cPersonalized MoE\uff0c\u5e76\u7ed3\u5408\u5386\u53f2\u611f\u77e5\u8def\u7531\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u57ce\u5e02\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNextLocMoE\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8bba\u6587\u63d0\u51faNextLocMoE\u6846\u67b6\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u53cc\u5c42\u6df7\u5408\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u5730\u70b9\u8bed\u4e49\u548c\u5efa\u6a21\u7528\u6237\u884c\u4e3a\u52a8\u6001\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2505.23987", "pdf": "https://arxiv.org/pdf/2505.23987", "abs": "https://arxiv.org/abs/2505.23987", "authors": ["Vishal Dey", "Xiao Hu", "Xia Ning"], "title": "Large Language Models for Controllable Multi-property Multi-objective Molecule Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.BM"], "comment": null, "summary": "In real-world drug design, molecule optimization requires selectively\nimproving multiple molecular properties up to pharmaceutically relevant levels,\nwhile maintaining others that already meet such criteria. However, existing\ncomputational approaches and instruction-tuned LLMs fail to capture such\nnuanced property-specific objectives, limiting their practical applicability.\nTo address this, we introduce C-MuMOInstruct, the first instruction-tuning\ndataset focused on multi-property optimization with explicit, property-specific\nobjectives. Leveraging C-MuMOInstruct, we develop GeLLMO-Cs, a series of\ninstruction-tuned LLMs that can perform targeted property-specific\noptimization. Our experiments across 5 in-distribution and 5\nout-of-distribution tasks show that GeLLMO-Cs consistently outperform strong\nbaselines, achieving up to 126% higher success rate. Notably, GeLLMO-Cs exhibit\nimpressive 0-shot generalization to novel optimization tasks and unseen\ninstructions. This offers a step toward a foundational LLM to support\nrealistic, diverse optimizations with property-specific objectives.\nC-MuMOInstruct and code are accessible through\nhttps://github.com/ninglab/GeLLMO-C.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faC-MuMOInstruct\u548cGeLLMO-Cs\uff0c\u89e3\u51b3\u4e86\u836f\u7269\u8bbe\u8ba1\u4e2d\u591a\u5c5e\u6027\u4f18\u5316\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u51fa\u8272\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u548c\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u836f\u7269\u8bbe\u8ba1\u4e2d\u591a\u5c5e\u6027\u4f18\u5316\u7684\u7ec6\u5fae\u76ee\u6807\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6C-MuMOInstruct\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u6784\u5efa\u4e86GeLLMO-Cs\u6a21\u578b\u7cfb\u5217\uff0c\u7528\u4e8e\u6267\u884c\u9488\u5bf9\u7279\u5b9a\u5c5e\u6027\u7684\u4f18\u5316\u3002", "result": "GeLLMO-Cs\u572810\u9879\u4efb\u52a1\uff085\u4e2a\u5206\u5e03\u5185\u548c5\u4e2a\u5206\u5e03\u5916\uff09\u4e2d\u8868\u73b0\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u6210\u529f\u7387\u6700\u9ad8\u63d0\u9ad8126%\u3002\u540c\u65f6\u5c55\u793a\u4e86\u5bf9\u65b0\u4f18\u5316\u4efb\u52a1\u548c\u672a\u89c1\u6307\u4ee4\u7684\u5f3a\u5927\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "C-MuMOInstruct\u548cGeLLMO-Cs\u4e3a\u57fa\u4e8e\u5c5e\u6027\u7279\u5b9a\u76ee\u6807\u7684\u5206\u5b50\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.24601", "pdf": "https://arxiv.org/pdf/2505.24601", "abs": "https://arxiv.org/abs/2505.24601", "authors": ["Zekun Wang", "Ethan L. Haarer", "Nicki Barari", "Christopher J. MacLellan"], "title": "Taxonomic Networks: A Representation for Neuro-Symbolic Pairing", "categories": ["cs.AI"], "comment": "10 pages, 3 figures, NeuS 2025", "summary": "We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and\nsymbolic approaches that are linked through a common knowledge representation.\nNext, we present \\textbf{taxonomic networks}, a type of discrimination network\nin which nodes represent hierarchically organized taxonomic concepts. Using\nthis representation, we construct a novel neuro-symbolic pair and evaluate its\nperformance. We show that our symbolic method learns taxonomic nets more\nefficiently with less data and compute, while the neural method finds\nhigher-accuracy taxonomic nets when provided with greater resources. As a\nneuro-symbolic pair, these approaches can be used interchangeably based on\nsituational needs, with seamless translation between them when necessary. This\nwork lays the foundation for future systems that more fundamentally integrate\nneural and symbolic computation.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u5bf9\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u4e92\u6362\u4f7f\u7528\uff0c\u5e76\u5728\u5fc5\u8981\u65f6\u5b9e\u73b0\u65e0\u7f1d\u8f6c\u6362\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\u5728\u77e5\u8bc6\u8868\u793a\u4e0a\u7684\u7ed3\u5408\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u5229\u7528\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u5bf9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5171\u540c\u7684\u77e5\u8bc6\u8868\u793a\u5c06\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u6784\u5efa\u4e86\u65b0\u578b\u7684\u5206\u7c7b\u7f51\u7edc\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7b26\u53f7\u65b9\u6cd5\u5728\u8f83\u5c11\u7684\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u80fd\u66f4\u9ad8\u6548\u5730\u5b66\u4e60\u5206\u7c7b\u7f51\u7edc\uff0c\u800c\u795e\u7ecf\u65b9\u6cd5\u5728\u63d0\u4f9b\u66f4\u591a\u8d44\u6e90\u65f6\u80fd\u627e\u5230\u66f4\u9ad8\u51c6\u786e\u7387\u7684\u5206\u7c7b\u7f51\u7edc\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u5bf9\u65b9\u6cd5\u53ef\u4ee5\u6839\u636e\u60c5\u5883\u9700\u6c42\u4e92\u6362\u4f7f\u7528\uff0c\u5e76\u4e14\u5728\u5fc5\u8981\u65f6\u53ef\u4ee5\u65e0\u7f1d\u8f6c\u6362\uff0c\u4e3a\u672a\u6765\u66f4\u6df1\u5165\u6574\u5408\u795e\u7ecf\u548c\u7b26\u53f7\u8ba1\u7b97\u7684\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24003", "pdf": "https://arxiv.org/pdf/2505.24003", "abs": "https://arxiv.org/abs/2505.24003", "authors": ["ChengAo Shen", "Wenchao Yu", "Ziming Zhao", "Dongjin Song", "Wei Cheng", "Haifeng Chen", "Jingchao Ni"], "title": "Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series, typically represented as numerical sequences, can also be\ntransformed into images and texts, offering multi-modal views (MMVs) of the\nsame underlying signal. These MMVs can reveal complementary patterns and enable\nthe use of powerful pre-trained large models, such as large vision models\n(LVMs), for long-term time series forecasting (LTSF). However, as we identified\nin this work, applying LVMs to LTSF poses an inductive bias towards\n\"forecasting periods\". To harness this bias, we propose DMMV, a novel\ndecomposition-based multi-modal view framework that leverages trend-seasonal\ndecomposition and a novel backcast residual based adaptive decomposition to\nintegrate MMVs for LTSF. Comparative evaluations against 14 state-of-the-art\n(SOTA) models across diverse datasets show that DMMV outperforms single-view\nand existing multi-modal baselines, achieving the best mean squared error (MSE)\non 6 out of 8 benchmark datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6DMMV\uff0c\u901a\u8fc7\u5206\u89e3\u65b9\u6cd5\u6574\u5408\u591a\u6a21\u6001\u89c6\u56fe\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u89c6\u89c9\u6a21\u578b\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u7684\u5f52\u7eb3\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u901a\u8fc7\u8f6c\u5316\u4e3a\u56fe\u50cf\u548c\u6587\u672c\u63d0\u4f9b\u591a\u6a21\u6001\u89c6\u89d2\uff0c\u4ece\u800c\u63ed\u793a\u4e92\u8865\u6a21\u5f0f\u5e76\u5229\u7528\u5f3a\u5927\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982\u5927\u578b\u89c6\u89c9\u6a21\u578b\uff09\u8fdb\u884c\u957f\u671f\u9884\u6d4b\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u8fd9\u4e9b\u6a21\u578b\u5b58\u5728\u9884\u6d4b\u5468\u671f\u4e0a\u7684\u5f52\u7eb3\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86DMMV\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8d8b\u52bf-\u5b63\u8282\u5206\u89e3\u4e0e\u57fa\u4e8e\u56de\u6d4b\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u5206\u89e3\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5c06\u5927\u578b\u89c6\u89c9\u6a21\u578b\u5e94\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u7684\u5f52\u7eb3\u504f\u5dee\u95ee\u9898\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u76846\u4e2a\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e8614\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "conclusion": "DMMV\u5728LTSF\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u5355\u89c6\u56fe\u548c\u591a\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\uff0c\u901a\u8fc7\u5229\u7528\u8d8b\u52bf-\u5b63\u8282\u5206\u89e3\u548c\u57fa\u4e8e\u56de\u6d4b\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u5206\u89e3\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u6574\u5408\u4e86\u591a\u6a21\u6001\u89c6\u56fe\u3002"}}
{"id": "2505.24622", "pdf": "https://arxiv.org/pdf/2505.24622", "abs": "https://arxiv.org/abs/2505.24622", "authors": ["Ben Griffin", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success", "categories": ["cs.AI", "cs.LG", "I.2.7"], "comment": "9 pages, 4 figures", "summary": "Predicting startup success requires models that are both accurate and\ninterpretable. We present a lightweight ensemble framework that combines YES/NO\nquestions generated by large language models (LLMs), forming a transparent\ndecision-making system. Each question acts as a weak heuristic, and by\nfiltering, ranking, and aggregating them through a threshold-based voting\nmechanism, we construct a strong ensemble predictor. On a test set where 10% of\nstartups are classified as successful, our approach achieves a precision rate\nof 50%, representing a 5x improvement over random selection, while remaining\nfully transparent. When we incorporate expert-guided heuristics into the\ngeneration process, performance improves further to 54% precision. These\nresults highlight the value of combining LLM reasoning with human insight and\ndemonstrate that simple, interpretable ensembles can support high-stakes\ndecisions in domains such as venture capital (VC).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u900f\u660e\u7684\u8f7b\u91cf\u7ea7\u96c6\u6210\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u95ee\u9898\u8fdb\u884c\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u9ad8\u521d\u521b\u4f01\u4e1a\u6210\u529f\u9884\u6d4b\u7684\u7cbe\u5ea6\u3002", "motivation": "\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u6765\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u7684\u6210\u529f\uff0c\u4ee5\u652f\u6301\u98ce\u9669\u6295\u8d44\u7b49\u9ad8\u98ce\u9669\u51b3\u7b56\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210YES/NO\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u9608\u503c\u7684\u6295\u7968\u673a\u5236\u8fc7\u6ee4\u3001\u6392\u5e8f\u548c\u805a\u5408\uff0c\u6784\u5efa\u96c6\u6210\u9884\u6d4b\u5668\uff1b\u5f15\u5165\u4e13\u5bb6\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e2d\uff0c10%\u521d\u521b\u4f01\u4e1a\u88ab\u5206\u7c7b\u4e3a\u6210\u529f\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u8fbe\u523050%\u7684\u7cbe\u786e\u7387\uff0c\u6bd4\u968f\u673a\u9009\u62e9\u63d0\u9ad8\u4e865\u500d\uff1b\u52a0\u5165\u4e13\u5bb6\u6307\u5bfc\u540e\u63d0\u5347\u81f354%\u3002", "conclusion": "\u7ed3\u5408LLM\u63a8\u7406\u4e0e\u4eba\u7c7b\u6d1e\u5bdf\u529b\u7684\u8f7b\u91cf\u7ea7\u96c6\u6210\u6846\u67b6\u5728\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u53ef\u89e3\u91ca\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2505.24005", "pdf": "https://arxiv.org/pdf/2505.24005", "abs": "https://arxiv.org/abs/2505.24005", "authors": ["Priya Kasimbeg", "Vincent Roulet", "Naman Agarwal", "Sourabh Medapati", "Fabian Pedregosa", "Atish Agarwala", "George E. Dahl"], "title": "How far away are truly hyperparameter-free learning algorithms?", "categories": ["cs.LG"], "comment": null, "summary": "Despite major advances in methodology, hyperparameter tuning remains a\ncrucial (and expensive) part of the development of machine learning systems.\nEven ignoring architectural choices, deep neural networks have a large number\nof optimization and regularization hyperparameters that need to be tuned\ncarefully per workload in order to obtain the best results. In a perfect world,\ntraining algorithms would not require workload-specific hyperparameter tuning,\nbut would instead have default settings that performed well across many\nworkloads. Recently, there has been a growing literature on optimization\nmethods which attempt to reduce the number of hyperparameters -- particularly\nthe learning rate and its accompanying schedule. Given these developments, how\nfar away is the dream of neural network training algorithms that completely\nobviate the need for painful tuning?\n  In this paper, we evaluate the potential of learning-rate-free methods as\ncomponents of hyperparameter-free methods. We freeze their (non-learning rate)\nhyperparameters to default values, and score their performance using the\nrecently-proposed AlgoPerf: Training Algorithms benchmark. We found that\nliterature-supplied default settings performed poorly on the benchmark, so we\nperformed a search for hyperparameter configurations that performed well across\nall workloads simultaneously. The best AlgoPerf-calibrated learning-rate-free\nmethods had much improved performance but still lagged slightly behind a\nsimilarly calibrated NadamW baseline in overall benchmark score. Our results\nsuggest that there is still much room for improvement for learning-rate-free\nmethods, and that testing against a strong, workload-agnostic baseline is\nimportant to improve hyperparameter reduction techniques.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5b66\u4e60\u7387\u81ea\u7531\u65b9\u6cd5\u5728\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u8d85\u53c2\u6570\u8c03\u4f18\u9700\u6c42\u7684\u6f5c\u529b\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\uff0c\u5e76\u5f3a\u8c03\u4e86\u4e0e\u5f3a\u57fa\u7ebf\u5bf9\u6bd4\u6d4b\u8bd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8d85\u53c2\u6570\u8c03\u4f18\u4ecd\u7136\u662f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u4e14\u6602\u8d35\u7684\u90e8\u5206\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5b66\u4e60\u7387\u81ea\u7531\u65b9\u6cd5\u4f5c\u4e3a\u65e0\u8d85\u53c2\u6570\u65b9\u6cd5\u7ec4\u6210\u90e8\u5206\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u51bb\u7ed3\u975e\u5b66\u4e60\u7387\u8d85\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\uff0c\u5e76\u4f7f\u7528AlgoPerf: Training Algorithms\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u5b66\u4e60\u7387\u81ea\u7531\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u6587\u732e\u63d0\u4f9b\u7684\u9ed8\u8ba4\u8bbe\u7f6e\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7ecf\u8fc7\u641c\u7d22\u627e\u5230\u7684\u8de8\u6240\u6709\u5de5\u4f5c\u8d1f\u8f7d\u8868\u73b0\u826f\u597d\u7684\u8d85\u53c2\u6570\u914d\u7f6e\u663e\u8457\u63d0\u5347\u4e86\u6700\u4f73AlgoPerf\u6821\u51c6\u7684\u5b66\u4e60\u7387\u81ea\u7531\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4f46\u4ecd\u7565\u900a\u4e8e\u7c7b\u4f3c\u7684NadamW\u57fa\u7ebf\u3002", "conclusion": "\u5b66\u4e60\u7387\u81ea\u7531\u7684\u65b9\u6cd5\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\uff0c\u4e0eNadamW\u57fa\u7ebf\u76f8\u6bd4\u8868\u73b0\u7a0d\u900a\uff0c\u8868\u660e\u5728\u5b9e\u73b0\u5b8c\u5168\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7b97\u6cd5\u7684\u68a6\u60f3\u4e0a\u8fd8\u6709\u5f88\u957f\u7684\u8def\u8981\u8d70\u3002"}}
{"id": "2505.24655", "pdf": "https://arxiv.org/pdf/2505.24655", "abs": "https://arxiv.org/abs/2505.24655", "authors": ["Frederike L\u00fcbeck", "Jonas Wildberger", "Frederik Tr\u00e4uble", "Maximilian Mordig", "Sergios Gatidis", "Andreas Krause", "Bernhard Sch\u00f6lkopf"], "title": "Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular disease (CVD) risk prediction models are essential for\nidentifying high-risk individuals and guiding preventive actions. However,\nexisting models struggle with the challenges of real-world clinical practice as\nthey oversimplify patient profiles, rely on rigid input schemas, and are\nsensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk\nprediction framework built on large language models extensively fine-tuned on\nover half a million participants from the UK Biobank. In benchmark comparisons,\nAdaCVD surpasses established risk scores and standard machine learning\napproaches, achieving state-of-the-art performance. Crucially, for the first\ntime, it addresses key clinical challenges across three dimensions: it flexibly\nincorporates comprehensive yet variable patient information; it seamlessly\nintegrates both structured data and unstructured text; and it rapidly adapts to\nnew patient populations using minimal additional data. In stratified analyses,\nit demonstrates robust performance across demographic, socioeconomic, and\nclinical subgroups, including underrepresented cohorts. AdaCVD offers a\npromising path toward more flexible, AI-driven clinical decision support tools\nsuited to the realities of heterogeneous and dynamic healthcare environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAdaCVD\uff0c\u4e00\u79cd\u57fa\u4e8eAI\u7684\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u5728\u7075\u6d3b\u6027\u3001\u6570\u636e\u6574\u5408\u548c\u9002\u5e94\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u60a3\u8005\u8d44\u6599\u590d\u6742\u6027\u3001\u8f93\u5165\u6a21\u5f0f\u50f5\u5316\u4ee5\u53ca\u5bf9\u5206\u5e03\u53d8\u5316\u654f\u611f\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684AdaCVD\u6846\u67b6\uff0c\u5e76\u5728\u8d85\u8fc750\u4e07\u540d\u53c2\u4e0e\u8005\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "result": "AdaCVD\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u98ce\u9669\u8bc4\u5206\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u591f\u5feb\u901f\u9002\u5e94\u65b0\u4eba\u7fa4\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u5206\u5c42\u5206\u6790\u7ed3\u679c\u3002", "conclusion": "AdaCVD\u4e3a\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u548c\u52a8\u6001\u7684\u533b\u7597\u73af\u5883\u3002"}}
{"id": "2505.24030", "pdf": "https://arxiv.org/pdf/2505.24030", "abs": "https://arxiv.org/abs/2505.24030", "authors": ["Ziming Zhao", "ChengAo Shen", "Hanghang Tong", "Dongjin Song", "Zhigang Deng", "Qingsong Wen", "Jingchao Ni"], "title": "From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Transformer-based models have gained increasing attention in time series\nresearch, driving interest in Large Language Models (LLMs) and foundation\nmodels for time series analysis. As the field moves toward multi-modality,\nLarge Vision Models (LVMs) are emerging as a promising direction. In the past,\nthe effectiveness of Transformer and LLMs in time series has been debated. When\nit comes to LVMs, a similar question arises: are LVMs truely useful for time\nseries analysis? To address it, we design and conduct the first principled\nstudy involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across\nboth high-level (classification) and low-level (forecasting) tasks, with\nextensive ablation analysis. Our findings indicate LVMs are indeed useful for\ntime series classification but face challenges in forecasting. Although\neffective, the contemporary best LVM forecasters are limited to specific types\nof LVMs and imaging methods, exhibit a bias toward forecasting periods, and\nhave limited ability to utilize long look-back windows. We hope our findings\ncould serve as a cornerstone for future research on LVM- and multimodal-based\nsolutions to different time series tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86LVMs\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u6548\u7528\uff0c\u53d1\u73b0\u5176\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u9650\u5236\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5927\u578b\u89c6\u89c9\u6a21\u578b\uff08LVMs\uff09\u6210\u4e3a\u6709\u524d\u9014\u7684\u7814\u7a76\u65b9\u5411\u3002\u9274\u4e8eTransformer\u548cLLMs\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6709\u6548\u6027\u66fe\u53d7\u5230\u8d28\u7591\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff1aLVMs\u662f\u5426\u771f\u6b63\u9002\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff1f", "method": "\u7814\u7a76\u5305\u62ec4\u4e2aLVM\u6a21\u578b\u30018\u79cd\u6210\u50cf\u65b9\u6cd5\u300118\u4e2a\u6570\u636e\u96c6\u548c26\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c\u6db5\u76d6\u4e86\u9ad8\u5c42\u6b21\uff08\u5206\u7c7b\uff09\u548c\u4f4e\u5c42\u6b21\uff08\u9884\u6d4b\uff09\u4efb\u52a1\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6d88\u878d\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLVMs\u786e\u5b9e\u5bf9\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6709\u7528\uff0c\u4f46\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0cLVMs\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u662f\u6709\u6548\u7684\uff0c\u4f46\u5728\u9884\u6d4b\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5f53\u524d\u6700\u597d\u7684LVM\u9884\u6d4b\u5668\u4ec5\u9650\u4e8e\u7279\u5b9a\u7c7b\u578b\u7684LVM\u548c\u6210\u50cf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5bf9\u9884\u6d4b\u5468\u671f\u8868\u73b0\u51fa\u504f\u5dee\uff0c\u5229\u7528\u957f\u56de\u6eaf\u7a97\u53e3\u7684\u80fd\u529b\u6709\u9650\u3002"}}
{"id": "2505.24785", "pdf": "https://arxiv.org/pdf/2505.24785", "abs": "https://arxiv.org/abs/2505.24785", "authors": ["Patrick Tser Jern Kon", "Jiachen Liu", "Xinyi Zhu", "Qiuyi Ding", "Jingjia Peng", "Jiarong Xing", "Yibo Huang", "Yiming Qiu", "Jayanth Srinivasa", "Myungjin Lee", "Mosharaf Chowdhury", "Matei Zaharia", "Ang Chen"], "title": "EXP-Bench: Can AI Conduct AI Research Experiments?", "categories": ["cs.AI"], "comment": "45 pages, 13 figures", "summary": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.", "AI": {"tldr": "EXP-Bench\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30AI\u4ee3\u7406\u5728\u5b8c\u6574AI\u7814\u7a76\u5b9e\u9a8c\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u7684\u74f6\u9888\u3002", "motivation": "\u81ea\u52a8\u5316AI\u7814\u7a76\u5177\u6709\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65\u7684\u6f5c\u529b\uff0c\u4f46\u5f53\u524dAI\u4ee3\u7406\u96be\u4ee5\u5904\u7406\u5b8c\u6574\u7684\u5b9e\u9a8c\u6d41\u7a0b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u534a\u81ea\u52a8\u7ba1\u9053\u6765\u4ece\u7814\u7a76\u8bba\u6587\u53ca\u5176\u76f8\u5173\u5f00\u6e90\u4ee3\u7801\u4e2d\u63d0\u53d6\u548c\u6784\u5efa\u5b9e\u9a8c\u7ec6\u8282\uff0c\u5e76\u521b\u5efa\u4e86461\u4e2aAI\u7814\u7a76\u4efb\u52a1\u3002", "result": "\u5bf9OpenHands\u548cIterativeAgent\u7b49LLM\u4ee3\u7406\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u4eec\u5728\u4e2a\u522b\u5b9e\u9a8c\u65b9\u9762\u5f97\u5206\u8fbe\u523020-35%\uff0c\u4f46\u5728\u5b8c\u6574\u5b9e\u9a8c\u7684\u6210\u529f\u7387\u4ec5\u4e3a0.5%\u3002", "conclusion": "EXP-Bench \u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u4ee3\u7406\u8fdb\u884c\u7aef\u5230\u7aef\u5b9e\u9a8c\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5f53\u524dLLM\u4ee3\u7406\u5728\u6267\u884c\u5b8c\u6574\u5b9e\u9a8c\u4efb\u52a1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.24034", "pdf": "https://arxiv.org/pdf/2505.24034", "abs": "https://arxiv.org/abs/2505.24034", "authors": ["Bo Wu", "Sid Wang", "Yunhao Tang", "Jia Ding", "Eryk Helenowski", "Liang Tan", "Tengyu Xu", "Tushar Gowda", "Zhengxing Chen", "Chen Zhu", "Xiaocheng Tang", "Yundi Qian", "Beibei Zhu", "Rui Hou"], "title": "LlamaRL: A Distributed Asynchronous Reinforcement Learning Framework for Efficient Large-scale LLM Trainin", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has become the most effective post-training\napproach for improving the capabilities of Large Language Models (LLMs). In\npractice, because of the high demands on latency and memory, it is particularly\nchallenging to develop an efficient RL framework that reliably manages policy\nmodels with hundreds to thousands of billions of parameters.\n  In this paper, we present LlamaRL, a fully distributed, asynchronous RL\nframework optimized for efficient training of large-scale LLMs with various\nmodel sizes (8B, 70B, and 405B parameters) on GPU clusters ranging from a\nhandful to thousands of devices. LlamaRL introduces a streamlined,\nsingle-controller architecture built entirely on native PyTorch, enabling\nmodularity, ease of use, and seamless scalability to thousands of GPUs. We also\nprovide a theoretical analysis of LlamaRL's efficiency, including a formal\nproof that its asynchronous design leads to strict RL speed-up. Empirically, by\nleveraging best practices such as colocated model offloading, asynchronous\noff-policy training, and distributed direct memory access for weight\nsynchronization, LlamaRL achieves significant efficiency gains -- up to 10.7x\nspeed-up compared to DeepSpeed-Chat-like systems on a 405B-parameter policy\nmodel. Furthermore, the efficiency advantage continues to grow with increasing\nmodel scale, demonstrating the framework's suitability for future large-scale\nRL training.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u6846\u67b6LlamaRL\uff0c\u5176\u901a\u8fc7\u5f02\u6b65\u8bbe\u8ba1\u548c\u4f18\u5316\u6280\u672f\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u5ef6\u8fdf\u548c\u5185\u5b58\u9700\u6c42\u4e0a\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLlamaRL\u7684\u5168\u5206\u5e03\u5f0f\u3001\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\u539f\u751fPyTorch\u6784\u5efa\uff0c\u5e76\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u6d4b\u8bd5\u3002", "result": "LlamaRL\u5b9e\u73b0\u4e86\u9ad8\u8fbe10.7\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u76f8\u8f83\u4e8e\u7c7b\u4f3cDeepSpeed-Chat\u7cfb\u7edf\uff0c\u5e76\u4e14\u5176\u6548\u7387\u4f18\u52bf\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u52a0\u800c\u589e\u957f\u3002", "conclusion": "LlamaRL\u662f\u4e00\u4e2a\u4e13\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5f02\u6b65\u8bbe\u8ba1\u548c\u6700\u4f73\u5b9e\u8df5\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u672a\u6765\u7684\u5927\u578b\u8bad\u7ec3\u3002"}}
{"id": "2505.24846", "pdf": "https://arxiv.org/pdf/2505.24846", "abs": "https://arxiv.org/abs/2505.24846", "authors": ["Jingyan Shen", "Jiarui Yao", "Rui Yang", "Yifan Sun", "Feng Luo", "Rui Pan", "Tong Zhang", "Han Zhao"], "title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u4e2a\u6027\u5316\u504f\u597d\u5b66\u4e60\u6846\u67b6MiCRo\uff0c\u65e0\u9700\u663e\u5f0f\u7684\u7ec6\u7c92\u5ea6\u6ce8\u91ca\u5373\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u7684\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u57fa\u4e8eBradley-Terry\u6a21\u578b\u7684\u5956\u52b1\u5efa\u6a21\u5047\u8bbe\u4e86\u4e00\u4e2a\u5168\u5c40\u5956\u52b1\u51fd\u6570\uff0c\u65e0\u6cd5\u6355\u6349\u672c\u8d28\u4e0a\u591a\u6837\u5316\u548c\u5f02\u8d28\u5316\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u4ece\u800c\u9650\u5236\u4e86LLMs\u652f\u6301\u4e2a\u6027\u5316\u548c\u591a\u5143\u5316\u5bf9\u9f50\u7684\u80fd\u529b\u3002", "method": "MiCRo\u91c7\u7528\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u5f15\u5165\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6df7\u5408\u5efa\u6a21\u65b9\u6cd5\u6765\u6355\u6349\u591a\u6837\u5316\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u7b2c\u4e8c\u9636\u6bb5\u96c6\u6210\u4e86\u5728\u7ebf\u8def\u7531\u7b56\u7565\uff0c\u6839\u636e\u7279\u5b9a\u4e0a\u4e0b\u6587\u52a8\u6001\u8c03\u6574\u6df7\u5408\u6743\u91cd\u4ee5\u89e3\u51b3\u6b67\u4e49\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMiCRo\u80fd\u591f\u6709\u6548\u6355\u6349\u591a\u6837\u5316\u7684\u7528\u6237\u504f\u597d\uff0c\u5e76\u5728\u591a\u4e2a\u504f\u597d\u6570\u636e\u96c6\u4e2d\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u4e2a\u6027\u5316\u4efb\u52a1\u7684\u8868\u73b0\u3002", "conclusion": "MiCRo\u6709\u6548\u5730\u6355\u6349\u4e86\u591a\u6837\u5316\u7684\u7528\u6237\u504f\u597d\uff0c\u5e76\u5728\u4e0b\u6e38\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2505.24048", "pdf": "https://arxiv.org/pdf/2505.24048", "abs": "https://arxiv.org/abs/2505.24048", "authors": ["Guangtao Zheng", "Wenqian Ye", "Aidong Zhang"], "title": "NeuronTune: Towards Self-Guided Spurious Bias Mitigation", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Deep neural networks often develop spurious bias, reliance on correlations\nbetween non-essential features and classes for predictions. For example, a\nmodel may identify objects based on frequently co-occurring backgrounds rather\nthan intrinsic features, resulting in degraded performance on data lacking\nthese correlations. Existing mitigation approaches typically depend on external\nannotations of spurious correlations, which may be difficult to obtain and are\nnot relevant to the spurious bias in a model. In this paper, we take a step\ntowards self-guided mitigation of spurious bias by proposing NeuronTune, a post\nhoc method that directly intervenes in a model's internal decision process. Our\nmethod probes in a model's latent embedding space to identify and regulate\nneurons that lead to spurious prediction behaviors. We theoretically justify\nour approach and show that it brings the model closer to an unbiased one.\nUnlike previous methods, NeuronTune operates without requiring spurious\ncorrelation annotations, making it a practical and effective tool for improving\nmodel robustness. Experiments across different architectures and data\nmodalities demonstrate that our method significantly mitigates spurious bias in\na self-guided way.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5NeuronTune\uff0c\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u6ce8\u91ca\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u76f4\u63a5\u5e72\u9884\u6a21\u578b\u5185\u90e8\u51b3\u7b56\u8fc7\u7a0b\u6765\u51cf\u8f7b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u865a\u5047\u504f\u5dee\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ecf\u5e38\u4f1a\u4ea7\u751f\u865a\u5047\u504f\u5dee\uff0c\u4f9d\u8d56\u4e8e\u975e\u5fc5\u8981\u7279\u5f81\u4e0e\u7c7b\u522b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8fdb\u884c\u9884\u6d4b\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5728\u7f3a\u4e4f\u8fd9\u4e9b\u76f8\u5173\u6027\u7684\u6570\u636e\u4e0a\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u7684\u7f13\u89e3\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u5916\u90e8\u6ce8\u91ca\uff0c\u4f46\u53ef\u80fd\u96be\u4ee5\u83b7\u5f97\u4e14\u4e0e\u6a21\u578b\u4e2d\u7684\u865a\u5047\u504f\u5dee\u65e0\u5173\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeuronTune\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u5728\u6a21\u578b\u7684\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u63a2\u6d4b\uff0c\u4ee5\u8bc6\u522b\u548c\u8c03\u8282\u5bfc\u81f4\u865a\u5047\u9884\u6d4b\u884c\u4e3a\u7684\u795e\u7ecf\u5143\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u8f7b\u81ea\u5bfc\u5f0f\u865a\u5047\u504f\u5dee\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u67b6\u6784\u548c\u6570\u636e\u6a21\u6001\u3002", "conclusion": "NeuronTune\u662f\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u865a\u5047\u76f8\u5173\u6027\u6ce8\u91ca\u7684\u5b9e\u7528\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u76f4\u63a5\u5e72\u9884\u6a21\u578b\u5185\u90e8\u51b3\u7b56\u8fc7\u7a0b\u4ee5\u51cf\u8f7b\u865a\u5047\u504f\u5dee\u3002"}}
{"id": "2505.24878", "pdf": "https://arxiv.org/pdf/2505.24878", "abs": "https://arxiv.org/abs/2505.24878", "authors": ["Yaxin Luo", "Zhaoyi Li", "Jiacheng Liu", "Jiacheng Cui", "Xiaohan Zhao", "Zhiqiang Shen"], "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "Code at: https://github.com/MetaAgentX/OpenCaptchaWorld", "summary": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3a Open CaptchaWorld \u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4ee5\u8bc4\u4f30\u591a\u6a21\u6001\u4ee3\u7406\u89e3\u51b3 CAPTCHA \u96be\u9898\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u4ee3\u7406\u4e0e\u4eba\u7c7b\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u4ee3\u591a\u6a21\u6001 LLM \u4ee3\u7406\u5728\u9759\u6001\u611f\u77e5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5904\u7406\u50cf CAPTCHAs \u8fd9\u6837\u7684\u4ea4\u4e92\u5f0f\u3001\u591a\u6b65\u9aa4\u63a8\u7406\u6311\u6218\u7684\u80fd\u529b\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u7ecf\u68c0\u9a8c\u3002", "method": "\u5f15\u5165\u4e86 Open CaptchaWorld\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u4e8e\u7f51\u7edc\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7\u591a\u6837\u5316\u548c\u52a8\u6001\u7684 CAPTCHA \u96be\u9898\u6765\u8bc4\u4f30 MLLM \u652f\u6301\u7684\u4ee3\u7406\u7684\u89c6\u89c9\u63a8\u7406\u548c\u4ea4\u4e92\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4eba\u7c7b\u5f97\u5206\u63a5\u8fd1\u5b8c\u7f8e\uff0c\u800c\u6700\u5148\u8fdb\u7684 MLLM \u4ee3\u7406\u8868\u73b0\u663e\u8457\u6323\u624e\uff0c\u6700\u9ad8\u6210\u529f\u7387\u4ec5\u4e3a Browser-Use Openai-o3 \u7684 40.0%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u7684 93.3%\u3002", "conclusion": "Open CaptchaWorld \u662f\u4e00\u4e2a\u91cd\u8981\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bca\u65ad\u5f53\u524d\u591a\u6a21\u6001\u4ee3\u7406\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u5bfc\u66f4\u5f3a\u5927\u7684\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u7684\u5f00\u53d1\u3002"}}
{"id": "2505.24054", "pdf": "https://arxiv.org/pdf/2505.24054", "abs": "https://arxiv.org/abs/2505.24054", "authors": ["Elpiniki Maria Lygizou", "M\u00f3nika Farsang", "Radu Grosu"], "title": "Differential Gated Self-Attention", "categories": ["cs.LG"], "comment": null, "summary": "Transformers excel across a large variety of tasks but remain susceptible to\ncorrupted inputs, since standard self-attention treats all query-key\ninteractions uniformly. Inspired by lateral inhibition in biological neural\ncircuits and building on the recent use by the Differential Transformer's use\nof two parallel softmax subtraction for noise cancellation, we propose\nMultihead Differential Gated Self-Attention (M-DGSA) that learns per-head\ninput-dependent gating to dynamically suppress attention noise. Each head\nsplits into excitatory and inhibitory branches whose dual softmax maps are\nfused by a sigmoid gate predicted from the token embedding, yielding a\ncontext-aware contrast enhancement. M-DGSA integrates seamlessly into existing\nTransformer stacks with minimal computational overhead. We evaluate on both\nvision and language benchmarks, demonstrating consistent robustness gains over\nvanilla Transformer, Vision Transformer, and Differential Transformer\nbaselines. Our contributions are (i) a novel input-dependent gating mechanism\nfor self-attention grounded in lateral inhibition, (ii) a principled synthesis\nof biological contrast-enhancement and self-attention theory, and (iii)\ncomprehensive experiments demonstrating noise resilience and cross-domain\napplicability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u751f\u7269\u4fa7\u6291\u5236\u673a\u5236\u7684\u591a\u5934\u5dee\u5206\u95e8\u63a7\u81ea\u6ce8\u610f\u529b\u65b9\u6cd5\uff08M-DGSA\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u6291\u5236\u6ce8\u610f\u529b\u566a\u58f0\u63d0\u5347\u4e86Transformer\u5728\u566a\u58f0\u8f93\u5165\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfTransformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u6240\u6709\u67e5\u8be2-\u952e\u4ea4\u4e92\u4e00\u89c6\u540c\u4ec1\uff0c\u96be\u4ee5\u5e94\u5bf9\u8f93\u5165\u4e2d\u7684\u566a\u58f0\u95ee\u9898\uff1b\u53d7\u751f\u7269\u795e\u7ecf\u56de\u8def\u4e2d\u4fa7\u6291\u5236\u673a\u5236\u7684\u542f\u53d1\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u9c81\u68d2\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u63d0\u51faMultihead Differential Gated Self-Attention (M-DGSA)\uff0c\u91c7\u7528\u5174\u594b\u548c\u6291\u5236\u5206\u652f\u7684\u53ccsoftmax\u6620\u5c04\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8etoken\u5d4c\u5165\u7684sigmoid\u95e8\u63a7\u8fdb\u884c\u878d\u5408\u3002", "result": "M-DGSA\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u51fa\u4f18\u4e8e\u6807\u51c6Transformer\u3001Vision Transformer\u548cDifferential Transformer\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5177\u5907\u8f83\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "M-DGSA\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u8f93\u5165\u4f9d\u8d56\u7684\u95e8\u63a7\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86Transformer\u6a21\u578b\u5728\u566a\u58f0\u8f93\u5165\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u6210\u529f\u7ed3\u5408\u4e86\u751f\u7269\u795e\u7ecf\u56de\u8def\u4e2d\u7684\u4fa7\u6291\u5236\u539f\u7406\u3002"}}
{"id": "2505.24055", "pdf": "https://arxiv.org/pdf/2505.24055", "abs": "https://arxiv.org/abs/2505.24055", "authors": ["Yilong Wang", "Tianxiang Zhao", "Zongyu Wu", "Suhang Wang"], "title": "Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph neural networks (GNNs) have shown great ability for node classification\non graphs. However, the success of GNNs relies on abundant labeled data, while\nobtaining high-quality labels is costly and challenging, especially for newly\nemerging domains. Hence, unsupervised domain adaptation (UDA), which trains a\nclassifier on the labeled source graph and adapts it to the unlabeled target\ngraph, is attracting increasing attention. Various approaches have been\nproposed to alleviate the distribution shift between the source and target\ngraphs to facilitate the classifier adaptation. However, most of them simply\nadopt existing UDA techniques developed for independent and identically\ndistributed data to gain domain-invariant node embeddings for graphs, which do\nnot fully consider the graph structure and message-passing mechanism of GNNs\nduring the adaptation and will fail when label distribution shift exists among\ndomains. In this paper, we proposed a novel framework that adopts link\nprediction to connect nodes between source and target graphs, which can\nfacilitate message-passing between the source and target graphs and augment the\ntarget nodes to have ``in-distribution'' neighborhoods with the source domain.\nThis strategy modified the target graph on the input level to reduce its\ndeviation from the source domain in the embedding space and is insensitive to\ndisproportional label distributions across domains. To prevent the loss of\ndiscriminative information in the target graph, we further design a novel\nidentity-preserving learning objective, which guides the learning of the edge\ninsertion module together with reconstruction and adaptation losses.\nExperimental results on real-world datasets demonstrate the effectiveness of\nour framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u94fe\u63a5\u9884\u6d4b\u548c\u8eab\u4efd\u4fdd\u6301\u5b66\u4e60\u7684\u65b0\u578b\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8de8\u9886\u57df\u8282\u70b9\u5206\u7c7b\u4e2d\u6807\u7b7e\u793a\u8303\u5206\u5e03\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u76f4\u63a5\u5e94\u7528\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u6280\u672f\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u56fe\u7ed3\u6784\u548cGNN\u7684\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u96be\u4ee5\u5e94\u5bf9\u9886\u57df\u95f4\u7684\u6807\u7b7e\u5206\u5e03\u53d8\u5316\u3002", "method": "\u91c7\u7528\u94fe\u63a5\u9884\u6d4b\u6765\u8fde\u63a5\u6e90\u56fe\u548c\u76ee\u6807\u56fe\uff0c\u4fee\u6539\u76ee\u6807\u56fe\u8f93\u5165\u4ee5\u51cf\u5c11\u5176\u4e0e\u6e90\u57df\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u504f\u5dee\uff0c\u5e76\u7ed3\u5408\u91cd\u6784\u3001\u9002\u914d\u635f\u5931\u8bbe\u8ba1\u8eab\u4efd\u4fdd\u6301\u5b66\u4e60\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6709\u6548\uff0c\u80fd\u591f\u63d0\u5347\u8de8\u9886\u57df\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u8868\u73b0\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u94fe\u63a5\u9884\u6d4b\u8fde\u63a5\u6e90\u56fe\u548c\u76ee\u6807\u56fe\uff0c\u6539\u8fdb\u4e86\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8eab\u4efd\u4fdd\u6301\u5b66\u4e60\u76ee\u6807\u4ee5\u9632\u6b62\u76ee\u6807\u56fe\u5224\u522b\u4fe1\u606f\u7684\u4e22\u5931\u3002"}}
{"id": "2505.24059", "pdf": "https://arxiv.org/pdf/2505.24059", "abs": "https://arxiv.org/abs/2505.24059", "authors": ["Sean Foley", "Hong Nguyen", "Jihwan Lee", "Sudarsana Reddy Kadiri", "Dani Byrd", "Louis Goldstein", "Shrikanth Narayanan"], "title": "Towards disentangling the contributions of articulation and acoustics in multimodal phoneme recognition", "categories": ["cs.LG"], "comment": null, "summary": "Although many previous studies have carried out multimodal learning with\nreal-time MRI data that captures the audio-visual kinematics of the vocal tract\nduring speech, these studies have been limited by their reliance on\nmulti-speaker corpora. This prevents such models from learning a detailed\nrelationship between acoustics and articulation due to considerable\ncross-speaker variability. In this study, we develop unimodal audio and video\nmodels as well as multimodal models for phoneme recognition using a long-form\nsingle-speaker MRI corpus, with the goal of disentangling and interpreting the\ncontributions of each modality. Audio and multimodal models show similar\nperformance on different phonetic manner classes but diverge on places of\narticulation. Interpretation of the models' latent space shows similar encoding\nof the phonetic space across audio and multimodal models, while the models'\nattention weights highlight differences in acoustic and articulatory timing for\ncertain phonemes.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u5355\u8bf4\u8bdd\u4eba\u7684MRI\u6570\u636e\u96c6\u5f00\u53d1\u4e86\u97f3\u9891\u3001\u89c6\u9891\u53ca\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u89e3\u6790\u8bed\u97f3\u4e0e\u53d1\u97f3\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u6001\u5728\u97f3\u7d20\u8bc6\u522b\u4e2d\u7684\u72ec\u7279\u4f5c\u7528\u3002", "motivation": "\u4ee5\u5f80\u7684\u7814\u7a76\u53d7\u9650\u4e8e\u4f9d\u8d56\u591a\u8bf4\u8bdd\u4eba\u7684\u8bed\u6599\u5e93\uff0c\u8fd9\u963b\u788d\u4e86\u58f0\u5b66\u4e0e\u53d1\u97f3\u4e4b\u95f4\u8be6\u7ec6\u5173\u7cfb\u7684\u5b66\u4e60\uff0c\u56e0\u4e3a\u4e0d\u540c\u8bf4\u8bdd\u4eba\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u957f\u683c\u5f0f\u5355\u8bf4\u8bdd\u4ebaMRI\u8bed\u6599\u5e93\u5f00\u53d1\u4e86\u5355\u6a21\u6001\u97f3\u9891\u3001\u89c6\u9891\u6a21\u578b\u4ee5\u53ca\u7528\u4e8e\u97f3\u7d20\u8bc6\u522b\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u7f20\u5e76\u89e3\u91ca\u6bcf\u4e2a\u6a21\u6001\u7684\u8d21\u732e\u3002", "result": "\u97f3\u9891\u548c\u591a\u6a21\u6001\u6a21\u578b\u5728\u97f3\u7d20\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u5728\u53d1\u97f3\u4f4d\u7f6e\u7684\u9884\u6d4b\u4e0a\u51fa\u73b0\u5206\u6b67\uff1b\u6a21\u578b\u89e3\u91ca\u8868\u660e\u5176\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u7f16\u7801\u76f8\u4f3c\uff0c\u4f46\u6ce8\u610f\u529b\u6743\u91cd\u63ed\u793a\u4e86\u58f0\u5b66\u548c\u53d1\u97f3\u65f6\u95f4\u4e0a\u7684\u5dee\u5f02\u3002", "conclusion": "\u97f3\u9891\u548c\u591a\u6a21\u6001\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u97f3\u65b9\u5f0f\u7c7b\u522b\u4e0a\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u5728\u53d1\u97f3\u4f4d\u7f6e\u4e0a\u5b58\u5728\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u663e\u793a\u4e86\u8bed\u97f3\u7a7a\u95f4\u7684\u76f8\u4f3c\u7f16\u7801\uff0c\u4f46\u6ce8\u610f\u529b\u6743\u91cd\u7a81\u51fa\u4e86\u67d0\u4e9b\u97f3\u7d20\u7684\u58f0\u5b66\u548c\u53d1\u97f3\u65f6\u95f4\u5dee\u5f02\u3002"}}
{"id": "2505.24061", "pdf": "https://arxiv.org/pdf/2505.24061", "abs": "https://arxiv.org/abs/2505.24061", "authors": ["Jiashun Liu", "Zihao Wu", "Johan Obando-Ceron", "Pablo Samuel Castro", "Aaron Courville", "Ling Pan"], "title": "Measure gradients, not activations! Enhancing neuronal activity in deep reinforcement learning", "categories": ["cs.LG"], "comment": null, "summary": "Deep reinforcement learning (RL) agents frequently suffer from neuronal\nactivity loss, which impairs their ability to adapt to new data and learn\ncontinually. A common method to quantify and address this issue is the\ntau-dormant neuron ratio, which uses activation statistics to measure the\nexpressive ability of neurons. While effective for simple MLP-based agents,\nthis approach loses statistical power in more complex architectures. To address\nthis, we argue that in advanced RL agents, maintaining a neuron's learning\ncapacity, its ability to adapt via gradient updates, is more critical than\npreserving its expressive ability. Based on this insight, we shift the\nstatistical objective from activations to gradients, and introduce GraMa\n(Gradient Magnitude Neural Activity Metric), a lightweight,\narchitecture-agnostic metric for quantifying neuron-level learning capacity. We\nshow that GraMa effectively reveals persistent neuron inactivity across diverse\narchitectures, including residual networks, diffusion models, and agents with\nvaried activation functions. Moreover, resetting neurons guided by GraMa\n(ReGraMa) consistently improves learning performance across multiple deep RL\nalgorithms and benchmarks, such as MuJoCo and the DeepMind Control Suite.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u5143\u5b66\u4e60\u80fd\u529b\u5ea6\u91cf\u65b9\u6cd5GraMa\u53ca\u76f8\u5e94\u7684\u4f18\u5316\u7b56\u7565ReGraMa\uff0c\u7528\u4e8e\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u795e\u7ecf\u5143\u5931\u6d3b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684tau-dormant neuron ratio\u5728\u590d\u6742\u67b6\u6784\u4e2d\u5931\u53bb\u7edf\u8ba1\u6548\u529b\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9002\u7528\u4e8e\u9ad8\u7ea7RL\u4ee3\u7406\u7684\u65b9\u6cd5\u6765\u7ef4\u6301\u795e\u7ecf\u5143\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u5143\u6d3b\u52a8\u5ea6\u91cf\u65b9\u6cd5GraMa\uff0c\u57fa\u4e8e\u68af\u5ea6\u5e45\u5ea6\u6765\u8861\u91cf\u795e\u7ecf\u5143\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u4e86\u91cd\u7f6e\u7b56\u7565ReGraMa\u3002", "result": "GraMa\u80fd\u591f\u63ed\u793a\u591a\u79cd\u590d\u6742\u67b6\u6784\u4e2d\u7684\u795e\u7ecf\u5143\u4e0d\u6d3b\u8dc3\u95ee\u9898\uff0c\u5e76\u4e14ReGraMa\u5728\u591a\u4e2a\u6df1\u5ea6RL\u7b97\u6cd5\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u63d0\u5347\u4e86\u5b66\u4e60\u8868\u73b0\u3002", "conclusion": "GraMa\u662f\u4e00\u79cd\u6709\u6548\u7684\u91cf\u5316\u795e\u7ecf\u5143\u5b66\u4e60\u80fd\u529b\u7684\u6307\u6807\uff0c\u5e76\u901a\u8fc7ReGraMa\u63d0\u5347\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8868\u73b0\u3002"}}
{"id": "2505.24067", "pdf": "https://arxiv.org/pdf/2505.24067", "abs": "https://arxiv.org/abs/2505.24067", "authors": ["Yu He", "Ellen Vitercik"], "title": "Primal-Dual Neural Algorithmic Reasoning", "categories": ["cs.LG"], "comment": "The 42nd International Conference on Machine Learning, 2025", "summary": "Neural Algorithmic Reasoning (NAR) trains neural networks to simulate\nclassical algorithms, enabling structured and interpretable reasoning over\ncomplex data. While prior research has predominantly focused on learning exact\nalgorithms for polynomial-time-solvable problems, extending NAR to harder\nproblems remains an open challenge. In this work, we introduce a general NAR\nframework grounded in the primal-dual paradigm, a classical method for\ndesigning efficient approximation algorithms. By leveraging a bipartite\nrepresentation between primal and dual variables, we establish an alignment\nbetween primal-dual algorithms and Graph Neural Networks. Furthermore, we\nincorporate optimal solutions from small instances to greatly enhance the\nmodel's reasoning capabilities. Our empirical results demonstrate that our\nmodel not only simulates but also outperforms approximation algorithms for\nmultiple tasks, exhibiting robust generalization to larger and\nout-of-distribution graphs. Moreover, we highlight the framework's practical\nutility by integrating it with commercial solvers and applying it to real-world\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u59cb-\u5bf9\u5076\u65b9\u6cd5\u7684\u795e\u7ecf\u7b97\u6cd5\u63a8\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u7684\u6700\u4f18\u89e3\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u95ee\u9898\u7684\u9ad8\u6548\u63a8\u7406\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684NAR\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u95ee\u9898\u7684\u7cbe\u786e\u7b97\u6cd5\u5b66\u4e60\uff0c\u800c\u5982\u4f55\u5c06\u5176\u6269\u5c55\u5230\u66f4\u96be\u7684\u95ee\u9898\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u539f\u59cb-\u5bf9\u5076\u7b97\u6cd5\u4e4b\u95f4\u7684\u4e8c\u5206\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u7684\u6700\u4f18\u89e3\u6765\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u4e0d\u4ec5\u80fd\u591f\u6a21\u62df\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd8\u80fd\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u5b83\u4eec\uff0c\u5e76\u4e14\u80fd\u5f88\u597d\u5730\u63a8\u5e7f\u5230\u66f4\u5927\u548c\u5206\u5e03\u5916\u7684\u56fe\u6570\u636e\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u59cb-\u5bf9\u5076\u8303\u5f0f\u7684\u901a\u7528NAR\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u66f4\u590d\u6742\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.24069", "pdf": "https://arxiv.org/pdf/2505.24069", "abs": "https://arxiv.org/abs/2505.24069", "authors": ["Yu He", "Yingxi Li", "Colin White", "Ellen Vitercik"], "title": "DSR-Bench: Evaluating the Structural Reasoning Abilities of LLMs via Data Structures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed for real-world tasks\nthat fundamentally involve data manipulation. A core requirement across these\ntasks is the ability to perform structural reasoning--that is, to understand\nand reason about data relationships. For example, customer requests require a\ntemporal ordering, which can be represented by data structures such as queues.\nHowever, existing benchmarks primarily focus on high-level, application-driven\nevaluations without isolating this fundamental capability. To address this gap,\nwe introduce DSR-Bench, a novel benchmark evaluating LLMs' structural reasoning\ncapabilities through data structures, which provide interpretable\nrepresentations of data relationships. DSR-Bench includes 20 data structures,\n35 operations, and 4,140 problem instances, organized hierarchically for\nfine-grained analysis of reasoning limitations. Our evaluation pipeline is\nfully automated and deterministic, eliminating subjective human or model-based\njudgments. Its synthetic nature also ensures scalability and minimizes data\ncontamination risks. We benchmark nine state-of-the-art LLMs. Our analysis\nshows that instruction-tuned models struggle with basic multi-attribute and\nmulti-hop reasoning. Furthermore, while reasoning-oriented models perform\nbetter, they remain fragile on complex and hybrid structures, with the best\nmodel achieving an average score of only 47% on the challenge subset.\nCrucially, models often perform poorly on multi-dimensional data and natural\nlanguage task descriptions, highlighting a critical gap for real-world\ndeployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86DSR-Bench\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u6027\u63a8\u7406\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u590d\u6742\u7ed3\u6784\u548c\u591a\u7ef4\u6570\u636e\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u51f8\u663e\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u9ad8\u5c42\u6b21\u7684\u5e94\u7528\u9a71\u52a8\u8bc4\u4f30\u4e0a\uff0c\u7f3a\u4e4f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u6027\u63a8\u7406\u80fd\u529b\u7684\u5b64\u7acb\u8bc4\u4f30\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e13\u95e8\u9488\u5bf9\u7ed3\u6784\u6027\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6DSR-Bench\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86DSR-Bench\uff0c\u4e00\u4e2a\u5305\u542b20\u79cd\u6570\u636e\u7ed3\u6784\u300135\u79cd\u64cd\u4f5c\u548c4140\u4e2a\u95ee\u9898\u5b9e\u4f8b\u7684\u65b0\u57fa\u51c6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u7ec4\u7ec7\u5b9e\u73b0\u5bf9\u63a8\u7406\u9650\u5236\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3002\u8bc4\u4f30\u6d41\u7a0b\u5b8c\u5168\u81ea\u52a8\u5316\u4e14\u786e\u5b9a\u6027\uff0c\u6d88\u9664\u4e86\u4e3b\u89c2\u7684\u4eba\u5de5\u6216\u6a21\u578b\u5224\u65ad\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u6a21\u578b\u5728\u57fa\u672c\u7684\u591a\u5c5e\u6027\u548c\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e0a\u5b58\u5728\u56f0\u96be\uff1b\u5c3d\u7ba1\u9762\u5411\u63a8\u7406\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5b83\u4eec\u5728\u590d\u6742\u548c\u6df7\u5408\u7ed3\u6784\u4e0a\u7684\u8868\u73b0\u4f9d\u7136\u8106\u5f31\uff0c\u6700\u597d\u7684\u6a21\u578b\u5728\u6311\u6218\u5b50\u96c6\u4e0a\u7684\u5e73\u5747\u5f97\u5206\u4ec5\u4e3a47%\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6d89\u53ca\u590d\u6742\u548c\u6df7\u5408\u7ed3\u6784\u7684\u4efb\u52a1\u65f6\u4ecd\u7136\u8868\u73b0\u8106\u5f31\uff0c\u5e76\u4e14\u5728\u591a\u7ef4\u6570\u636e\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u4e0b\u8868\u73b0\u8f83\u5dee\uff0c\u8fd9\u7a81\u51fa\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u7684\u91cd\u8981\u5dee\u8ddd\u3002"}}
{"id": "2505.24085", "pdf": "https://arxiv.org/pdf/2505.24085", "abs": "https://arxiv.org/abs/2505.24085", "authors": ["Alireza Jafari", "Fereshteh Yousefirizi", "Vahid Seydi"], "title": "DeepBoost-AF: A Novel Unsupervised Feature Learning and Gradient Boosting Fusion for Robust Atrial Fibrillation Detection in Raw ECG Signals", "categories": ["cs.LG"], "comment": "12-page,4 figures,3 tables, Achieves 95.20% F1-score (99.99%\n  sensitivity) on 8,528 PhysioNet 2017 recordings, Mean inference time: 4\n  seconds, Python implementation will be open-sourced upon publication", "summary": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with\nelevated health risks, where timely detection is pivotal for mitigating\nstroke-related morbidity. This study introduces an innovative hybrid\nmethodology integrating unsupervised deep learning and gradient boosting models\nto improve AF detection. A 19-layer deep convolutional autoencoder (DCAE) is\ncoupled with three boosting classifiers-AdaBoost, XGBoost, and LightGBM\n(LGBM)-to harness their complementary advantages while addressing individual\nlimitations. The proposed framework uniquely combines DCAE with gradient\nboosting, enabling end-to-end AF identification devoid of manual feature\nextraction. The DCAE-LGBM model attains an F1-score of 95.20%, sensitivity of\n99.99%, and inference latency of four seconds, outperforming existing methods\nand aligning with clinical deployment requirements. The DCAE integration\nsignificantly enhances boosting models, positioning this hybrid system as a\nreliable tool for automated AF detection in clinical settings.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u521b\u65b0\u6027\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u68af\u5ea6\u63d0\u5347\u6280\u672f\u7ed3\u5408\u8d77\u6765\uff0c\u5b9e\u73b0\u65e0\u9700\u624b\u52a8\u7279\u5f81\u63d0\u53d6\u7684\u5fc3\u623f\u98a4\u52a8\u81ea\u52a8\u68c0\u6d4b\u3002", "motivation": "\u53ca\u65f6\u68c0\u6d4b\u5fc3\u623f\u98a4\u52a8\u5bf9\u4e8e\u964d\u4f4e\u4e2d\u98ce\u76f8\u5173\u53d1\u75c5\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u4e00\u5b9a\u7684\u5065\u5eb7\u98ce\u9669\uff0c\u8fd9\u5c31\u9700\u8981\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e8619\u5c42\u6df1\u5ea6\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff08DCAE\uff09\u4e0e\u4e09\u79cd\u589e\u5f3a\u5206\u7c7b\u5668-AdaBoost\u3001XGBoost\u548cLightGBM\uff08LGBM\uff09\u76f8\u7ed3\u5408\u7684\u6846\u67b6\u3002", "result": "DCAE-LGBM\u6a21\u578b\u8fbe\u5230\u4e8695.20%\u7684F1\u5206\u6570\uff0c99.99%\u7684\u654f\u611f\u6027\u4ee5\u53ca4\u79d2\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u7b26\u5408\u4e34\u5e8a\u90e8\u7f72\u8981\u6c42\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65e0\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u548c\u68af\u5ea6\u63d0\u5347\u6a21\u578b\u7684\u65b0\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u5584\u5fc3\u623f\u98a4\u52a8\uff08AF\uff09\u7684\u68c0\u6d4b\u3002\u8fd9\u79cd\u6df7\u5408\u7cfb\u7edf\u88ab\u5b9a\u4f4d\u4e3a\u4e00\u79cd\u53ef\u9760\u7684\u81ea\u52a8\u5316AF\u68c0\u6d4b\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2505.24088", "pdf": "https://arxiv.org/pdf/2505.24088", "abs": "https://arxiv.org/abs/2505.24088", "authors": ["Chen Huang", "Skyler Seto", "Hadi Pouransari", "Mehrdad Farajtabar", "Raviteja Vemulapalli", "Fartash Faghri", "Oncel Tuzel", "Barry-John Theobald", "Josh Susskind"], "title": "Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025", "summary": "Vision foundation models pre-trained on massive data encode rich\nrepresentations of real-world concepts, which can be adapted to downstream\ntasks by fine-tuning. However, fine-tuning foundation models on one task often\nleads to the issue of concept forgetting on other tasks. Recent methods of\nrobust fine-tuning aim to mitigate forgetting of prior knowledge without\naffecting the fine-tuning performance. Knowledge is often preserved by matching\nthe original and fine-tuned model weights or feature pairs. However, such\npoint-wise matching can be too strong, without explicit awareness of the\nfeature neighborhood structures that encode rich knowledge as well. We propose\na novel regularization method Proxy-FDA that explicitly preserves the\nstructural knowledge in feature space. Proxy-FDA performs Feature Distribution\nAlignment (using nearest neighbor graphs) between the pre-trained and\nfine-tuned feature spaces, and the alignment is further improved by informative\nproxies that are generated dynamically to increase data diversity. Experiments\nshow that Proxy-FDA significantly reduces concept forgetting during\nfine-tuning, and we find a strong correlation between forgetting and a\ndistributional distance metric (in comparison to L2 distance). We further\ndemonstrate Proxy-FDA's benefits in various fine-tuning settings (end-to-end,\nfew-shot and continual tuning) and across different tasks like image\nclassification, captioning and VQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProxy-FDA\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u4fdd\u7559\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u77e5\u8bc6\u6765\u51cf\u5c11\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u65f6\u7684\u6982\u5ff5\u9057\u5fd8\u3002", "motivation": "\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u65f6\u4f1a\u51fa\u73b0\u5176\u4ed6\u4efb\u52a1\u4e0a\u7684\u6982\u5ff5\u9057\u5fd8\u95ee\u9898\uff0c\u800c\u73b0\u6709\u7684\u9c81\u68d2\u5fae\u8c03\u65b9\u6cd5\u5728\u4fdd\u5b58\u77e5\u8bc6\u65b9\u9762\u7f3a\u4e4f\u5bf9\u7279\u5f81\u90bb\u57df\u7ed3\u6784\u7684\u663e\u5f0f\u8ba4\u77e5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5Proxy-FDA\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u6700\u8fd1\u90bb\u56fe\u5728\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7279\u5f81\u7a7a\u95f4\u4e4b\u95f4\u8fdb\u884c\u7279\u5f81\u5206\u5e03\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u751f\u6210\u7684\u4fe1\u606f\u4ee3\u7406\u6765\u63d0\u9ad8\u6570\u636e\u591a\u6837\u6027\uff0c\u4ece\u800c\u663e\u5f0f\u4fdd\u7559\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cProxy-FDA\u663e\u8457\u51cf\u5c11\u4e86\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u6982\u5ff5\u9057\u5fd8\uff0c\u5e76\u63ed\u793a\u4e86\u9057\u5fd8\u4e0e\u5206\u5e03\u8ddd\u79bb\u5ea6\u91cf\u4e4b\u95f4\u7684\u5f3a\u76f8\u5173\u6027\uff08\u76f8\u8f83\u4e8eL2\u8ddd\u79bb\uff09\u3002", "conclusion": "Proxy-FDA\u5728\u5404\u79cd\u5fae\u8c03\u8bbe\u7f6e\u548c\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u6982\u5ff5\u9057\u5fd8\uff0c\u5e76\u4e14\u53d1\u73b0\u9057\u5fd8\u4e0e\u5206\u5e03\u8ddd\u79bb\u5ea6\u91cf\u4e4b\u95f4\u5b58\u5728\u5f3a\u76f8\u5173\u6027\u3002"}}
{"id": "2505.24089", "pdf": "https://arxiv.org/pdf/2505.24089", "abs": "https://arxiv.org/abs/2505.24089", "authors": ["Marcus Lassila", "Johan \u00d6stman", "Khac-Hoang Ngo", "Alexandre Graell i Amat"], "title": "Practical Bayes-Optimal Membership Inference Attacks", "categories": ["cs.LG", "cs.CR"], "comment": "9 pages plus 13 pages of appendices", "summary": "We develop practical and theoretically grounded membership inference attacks\n(MIAs) against both independent and identically distributed (i.i.d.) data and\ngraph-structured data. Building on the Bayesian decision-theoretic framework of\nSablayrolles et al., we derive the Bayes-optimal membership inference rule for\nnode-level MIAs against graph neural networks, addressing key open questions\nabout optimal query strategies in the graph setting. We introduce BASE and\nG-BASE, computationally efficient approximations of the Bayes-optimal attack.\nG-BASE achieves superior performance compared to previously proposed\nclassifier-based node-level MIA attacks. BASE, which is also applicable to\nnon-graph data, matches or exceeds the performance of prior state-of-the-art\nMIAs, such as LiRA and RMIA, at a significantly lower computational cost.\nFinally, we show that BASE and RMIA are equivalent under a specific\nhyperparameter setting, providing a principled, Bayes-optimal justification for\nthe RMIA attack.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faBASE\u548cG-BASE\u4e24\u79cd\u9ad8\u6548\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u56fe\u7ed3\u6784\u548c\u975e\u56fe\u6570\u636e\u4e0a\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86BASE\u4e0eRMIA\u7684\u7b49\u4ef7\u6027\u53ca\u5176\u8d1d\u53f6\u65af\u6700\u4f18\u6027\u3002", "motivation": "\u89e3\u51b3\u56fe\u7ed3\u6784\u6570\u636e\u548c\u975e\u56fe\u6570\u636e\u4e2d\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5728\u56fe\u73af\u5883\u4e0b\u6700\u4f18\u67e5\u8be2\u7b56\u7565\u7684\u5173\u952e\u95ee\u9898\u3002\u540c\u65f6\uff0c\u65e8\u5728\u964d\u4f4e\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u7684\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u57fa\u4e8eSablayrolles\u7b49\u4eba\u63d0\u51fa\u7684\u8d1d\u53f6\u65af\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8282\u70b9\u7ea7\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u89c4\u5219\uff0c\u5e76\u63d0\u51fa\u4e86BASE\u548cG-BASE\u4f5c\u4e3a\u8d1d\u53f6\u65af\u6700\u4f18\u653b\u51fb\u7684\u8ba1\u7b97\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\u3002", "result": "G-BASE\u5728\u56fe\u7ed3\u6784\u6570\u636e\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u63d0\u51fa\u7684\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u8282\u70b9\u7ea7\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff1bBASE\u5728\u975e\u56fe\u6570\u636e\u4e0a\u8868\u73b0\u4e0eLiRA\u548cRMIA\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u663e\u8457\u66f4\u4f4e\u3002", "conclusion": "BASE\u548cRMIA\u5728\u7279\u5b9a\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u662f\u7b49\u4ef7\u7684\uff0c\u8fd9\u4e3aRMIA\u653b\u51fb\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8d1d\u53f6\u65af\u6700\u4f18\u7684\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2505.24101", "pdf": "https://arxiv.org/pdf/2505.24101", "abs": "https://arxiv.org/abs/2505.24101", "authors": ["Zhenran Xu"], "title": "A SHAP-based explainable multi-level stacking ensemble learning method for predicting the length of stay in acute stroke", "categories": ["cs.LG"], "comment": "Master Minor Thesis, Preprint", "summary": "Length of stay (LOS) prediction in acute stroke is critical for improving\ncare planning. Existing machine learning models have shown suboptimal\npredictive performance, limited generalisability, and have overlooked\nsystem-level factors. We aimed to enhance model efficiency, performance, and\ninterpretability by refining predictors and developing an interpretable\nmulti-level stacking ensemble model. Data were accessed from the biennial\nStroke Foundation Acute Audit (2015, 2017, 2019, 2021) in Australia. Models\nwere developed for ischaemic and haemorrhagic stroke separately. The outcome\nwas prolonged LOS (the LOS above the 75th percentile). Candidate predictors\n(ischaemic: n=89; haemorrhagic: n=83) were categorised into patient, clinical,\nand system domains. Feature selection with correlation-based approaches was\nused to refine key predictors. The evaluation of models included discrimination\n(AUC), calibration curves, and interpretability (SHAP plots). In ischaemic\nstroke (N=12,575), prolonged LOS was >=9 days, compared to >=11 days in\nhaemorrhagic stroke (N=1,970). The ensemble model achieved superior performance\n[AUC: 0.824 (95% CI: 0.801-0.846)] and statistically outperformed logistic\nregression [AUC: 0.805 (95% CI: 0.782-0.829); P=0.0004] for ischaemic. However,\nthe model [AUC: 0.843 (95% CI: 0.790-0.895)] did not statistically outperform\nlogistic regression [AUC: 0.828 (95% CI: 0.774-0.882); P=0.136] for\nhaemorrhagic. SHAP analysis identified shared predictors for both types of\nstroke: rehabilitation assessment, urinary incontinence, stroke unit care,\ninability to walk independently, physiotherapy, and stroke care coordinators\ninvolvement. An explainable ensemble model effectively predicted the prolonged\nLOS in ischaemic stroke. Further validation in larger cohorts is needed for\nhaemorrhagic stroke.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u9884\u6d4b\u6025\u6027\u4e2d\u98ce\u60a3\u8005\u4f4f\u9662\u65f6\u95f4\u7684\u53ef\u89e3\u91ca\u96c6\u6210\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u7f3a\u8840\u6027\u4e2d\u98ce\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5728\u51fa\u8840\u6027\u4e2d\u98ce\u9884\u6d4b\u4e2d\u7684\u63d0\u5347\u4e0d\u660e\u663e\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u6025\u6027\u4e2d\u98ce\u4f4f\u9662\u65f6\u95f4\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u901a\u7528\u6027\u6709\u9650\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u7cfb\u7edf\u7ea7\u56e0\u7d20\u3002\u7814\u7a76\u65e8\u5728\u589e\u5f3a\u6a21\u578b\u7684\u6548\u7387\u3001\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u6539\u8fdb\u9884\u6d4b\u56e0\u5b50\u5e76\u5f00\u53d1\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u591a\u5c42\u6b21\u5806\u53e0\u96c6\u6210\u6a21\u578b\u6765\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u3001\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6570\u636e\u6765\u81ea\u6fb3\u5927\u5229\u4e9a\u7684\u4e24\u5e74\u671f\u4e2d\u98ce\u57fa\u91d1\u4f1a\u6025\u6027\u75c5\u5ba1\u8ba1\uff0c\u5206\u522b\u9488\u5bf9\u7f3a\u8840\u6027\u548c\u51fa\u8840\u6027\u4e2d\u98ce\u5efa\u7acb\u6a21\u578b\u3002\u4f7f\u7528\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u901a\u8fc7AUC\u3001\u6821\u51c6\u66f2\u7ebf\u548cSHAP\u56fe\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5bf9\u4e8e\u7f3a\u8840\u6027\u4e2d\u98ce\uff08N=12,575\uff09\uff0c\u8be5\u96c6\u6210\u6a21\u578b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd[AUC: 0.824]\uff0c\u5e76\u7edf\u8ba1\u4e0a\u4f18\u4e8e\u903b\u8f91\u56de\u5f52[AUC: 0.805; P=0.0004]\u3002\u7136\u800c\uff0c\u5728\u51fa\u8840\u6027\u4e2d\u98ce\uff08N=1,970\uff09\u4e2d\uff0c\u8be5\u6a21\u578b[AUC: 0.843]\u4e0e\u903b\u8f91\u56de\u5f52[AUC: 0.828; P=0.136]\u76f8\u6bd4\u6ca1\u6709\u7edf\u8ba1\u5b66\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002SHAP\u5206\u6790\u786e\u5b9a\u4e86\u4e24\u79cd\u4e2d\u98ce\u7c7b\u578b\u7684\u5171\u540c\u9884\u6d4b\u56e0\u5b50\uff0c\u5305\u62ec\u5eb7\u590d\u8bc4\u4f30\u3001\u5c3f\u5931\u7981\u3001\u4e2d\u98ce\u5355\u5143\u62a4\u7406\u3001\u65e0\u6cd5\u72ec\u7acb\u884c\u8d70\u3001\u7269\u7406\u6cbb\u7597\u548c\u4e2d\u98ce\u62a4\u7406\u534f\u8c03\u5458\u7684\u53c2\u4e0e\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u53ef\u89e3\u91ca\u7684\u96c6\u6210\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u9884\u6d4b\u7f3a\u8840\u6027\u4e2d\u98ce\u60a3\u8005\u7684\u5ef6\u957f\u4f4f\u9662\u65f6\u95f4\uff0c\u4f46\u5bf9\u51fa\u8840\u6027\u4e2d\u98ce\u7684\u9884\u6d4b\u6548\u679c\u672a\u663e\u8457\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u3002\u9700\u8981\u5728\u66f4\u5927\u7684\u961f\u5217\u4e2d\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u51fa\u8840\u6027\u4e2d\u98ce\u7684\u7ed3\u679c\u3002"}}
{"id": "2505.24110", "pdf": "https://arxiv.org/pdf/2505.24110", "abs": "https://arxiv.org/abs/2505.24110", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Neural Networks as Universal Finite-State Machines: A Constructive ReLU Simulation Framework for NFAs", "categories": ["cs.LG", "cs.FL"], "comment": "16 pages, with proofs in Appendix", "summary": "We present a formal and constructive framework establishing the equivalence\nbetween nondeterministic finite automata (NFAs) and standard feedforward ReLU\nneural networks. By encoding automaton states as binary vectors and transitions\nas sparse linear layers, we show that ReLU activations simulate\nnondeterministic branching, subset construction, and $\\epsilon$-closures in a\nmathematically precise manner. Our core theoretical results prove that a\nthree-layer ReLU network of width $\\mathcal{O}(n)$ can exactly recognize any\nregular language accepted by an $n$-state NFA-without recurrence, memory, or\napproximation. Furthermore, we show that gradient descent over\nstructure-preserving networks preserves symbolic semantics and acceptance\nbehavior. Extensive experiments across multiple validation tasks-including\nparallel path tracking, symbolic subset construction, $\\epsilon$-closure\nconvergence, acceptance classification, structural training invariants, and\nfunctional equivalence-achieve perfect or near-perfect empirical alignment with\nground-truth automata. This work provides the first provably complete symbolic\nsimulation of NFAs within standard deep learning architectures, uniting\nautomata theory with neural computation through ReLU dynamics.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u524d\u9988ReLU\u795e\u7ecf\u7f51\u7edc\u7cbe\u786e\u6a21\u62df\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u81ea\u52a8\u673a\u7406\u8bba\u4e0e\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "motivation": "\u52a8\u673a\u662f\u5efa\u7acb\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u4e0e\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u4ece\u800c\u5c06\u81ea\u52a8\u673a\u7406\u8bba\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u3002", "method": "\u901a\u8fc7\u5c06\u81ea\u52a8\u673a\u72b6\u6001\u7f16\u7801\u4e3a\u4e8c\u8fdb\u5236\u5411\u91cf\u5e76\u5c06\u8f6c\u6362\u7f16\u7801\u4e3a\u7a00\u758f\u7ebf\u6027\u5c42\uff0c\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6570\u6a21\u62df\u975e\u786e\u5b9a\u6027\u5206\u652f\u3001\u5b50\u96c6\u6784\u9020\u548c\u03b5-\u95ed\u5305\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u4e2a\u9a8c\u8bc1\u4efb\u52a1\u4e2d\uff0c\u5305\u62ec\u5e76\u884c\u8def\u5f84\u8ddf\u8e2a\u3001\u7b26\u53f7\u5b50\u96c6\u6784\u9020\u7b49\uff0c\u6a21\u578b\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u6216\u63a5\u8fd1\u5b8c\u7f8e\u7684\u7ecf\u9a8c\u5bf9\u9f50\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u8868\u660e\uff0c\u6807\u51c6\u7684\u524d\u9988ReLU\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u5f62\u5f0f\u5316\u5730\u6a21\u62df\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff08NFA\uff09\uff0c\u4ece\u800c\u5728\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e2d\u5b9e\u73b0\u4e86\u7b26\u53f7\u5316\u7684NFA\u4eff\u771f\u3002"}}
{"id": "2505.24138", "pdf": "https://arxiv.org/pdf/2505.24138", "abs": "https://arxiv.org/abs/2505.24138", "authors": ["Yichen Shi", "Ze Zhang", "Hongyang Wang", "Zhuofu Tao", "Zhongyi Li", "Bingyu Chen", "Yaxin Wang", "Zhiping Yu", "Ting-Jung Lin", "Lei He"], "title": "AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated\ncircuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit\ndesign has remained a longstanding challenge due to its difficulty and\ncomplexity. Recent advances in Multi-modal Large Language Models (MLLMs) offer\npromising potential for supporting AMS circuit analysis and design. However,\ncurrent research typically evaluates MLLMs on isolated tasks within the domain,\nlacking a comprehensive benchmark that systematically assesses model\ncapabilities across diverse AMS-related challenges. To address this gap, we\nintroduce AMSbench, a benchmark suite designed to evaluate MLLM performance\nacross critical tasks including circuit schematic perception, circuit analysis,\nand circuit design. AMSbench comprises approximately 8000 test questions\nspanning multiple difficulty levels and assesses eight prominent models,\nencompassing both open-source and proprietary solutions such as Qwen 2.5-VL and\nGemini 2.5 Pro. Our evaluation highlights significant limitations in current\nMLLMs, particularly in complex multi-modal reasoning and sophisticated circuit\ndesign tasks. These results underscore the necessity of advancing MLLMs'\nunderstanding and effective application of circuit-specific knowledge, thereby\nnarrowing the existing performance gap relative to human expertise and moving\ntoward fully automated AMS circuit design workflows. Our data is released at\nhttps://huggingface.co/datasets/wwhhyy/AMSBench", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86AMSbench\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df/\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ecd\u6709\u660e\u663e\u5c40\u9650\u3002", "motivation": "\u81ea\u52a8\u5316\u6a21\u62df/\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u8bbe\u8ba1\u4ecd\u7136\u662f\u4e00\u4e2a\u957f\u671f\u6311\u6218\uff0c\u800c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u7814\u7a76\u901a\u5e38\u4ec5\u9488\u5bf9\u5b64\u7acb\u7684\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u7cfb\u7edf\u5730\u8861\u91cf\u6a21\u578b\u5728\u5404\u79cdAMS\u76f8\u5173\u6311\u6218\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAMSbench\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df/\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u5206\u6790\u548c\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u516b\u79cd\u4e3b\u6d41\u6a21\u578b\uff08\u5305\u62ec\u5f00\u6e90\u548c\u4e13\u6709\u89e3\u51b3\u65b9\u6848\uff09\u53d1\u73b0\uff0c\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u548c\u9ad8\u7ea7\u7535\u8def\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7684\u591a\u6a21\u6001\u63a8\u7406\u548c\u9ad8\u7ea7\u7535\u8def\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u5bf9\u7535\u8def\u4e13\u4e1a\u77e5\u8bc6\u7684\u7406\u89e3\u548c\u5e94\u7528\u80fd\u529b\uff0c\u4ee5\u7f29\u5c0f\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5b9e\u73b0AMS\u7535\u8def\u8bbe\u8ba1\u6d41\u7a0b\u7684\u5168\u81ea\u52a8\u5316\u3002"}}
{"id": "2505.24145", "pdf": "https://arxiv.org/pdf/2505.24145", "abs": "https://arxiv.org/abs/2505.24145", "authors": ["Wilfried Genuist", "\u00c9ric Savin", "Filippo Gatti", "Didier Clouteau"], "title": "Autoregressive regularized score-based diffusion models for multi-scenarios fluid flow prediction", "categories": ["cs.LG", "physics.flu-dyn", "65N75, 35Q30, 60H15, 76F55, 68T07", "I.2.6; G.1.7; I.6.1; I.6.3"], "comment": "34 pages, 17 figures", "summary": "Building on recent advances in scientific machine learning and generative\nmodeling for computational fluid dynamics, we propose a conditional score-based\ndiffusion model designed for multi-scenarios fluid flow prediction. Our model\nintegrates an energy constraint rooted in the statistical properties of\nturbulent flows, improving prediction quality with minimal training, while\nenabling efficient sampling at low cost. The method features a simple and\ngeneral architecture that requires no problem-specific design, supports\nplug-and-play enhancements, and enables fast and flexible solution generation.\nIt also demonstrates an efficient conditioning mechanism that simplifies\ntraining across different scenarios without demanding a redesign of existing\nmodels. We further explore various stochastic differential equation\nformulations to demonstrate how thoughtful design choices enhance performance.\nWe validate the proposed methodology through extensive experiments on complex\nfluid dynamics datasets encompassing a variety of flow regimes and\nconfigurations. Results demonstrate that our model consistently achieves\nstable, robust, and physically faithful predictions, even under challenging\nturbulent conditions. With properly tuned parameters, it achieves accurate\nresults across multiple scenarios while preserving key physical and statistical\nproperties. We present a comprehensive analysis of stochastic differential\nequation impact and discuss our approach across diverse fluid mechanics tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u901a\u7528\u3001\u9ad8\u6548\u7684\u6d41\u4f53\u9884\u6d4b\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u591a\u573a\u666f\u73af\u5883\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6d41\u4f53\u6d41\u52a8\u9884\u6d4b\u7684\u8d28\u91cf\u5e76\u51cf\u5c11\u8bad\u7ec3\u9700\u6c42\uff0c\u540c\u65f6\u652f\u6301\u7075\u6d3b\u7684\u5e94\u7528\u4e8e\u591a\u79cd\u573a\u666f\u3002", "method": "\u6761\u4ef6\u5206\u6570\u6269\u6563\u6a21\u578b\u7ed3\u5408\u80fd\u91cf\u7ea6\u675f\u548c\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u67b6\u6784\u8bbe\u8ba1\u5b9e\u73b0\u9ad8\u6548\u7684\u91c7\u6837\u548c\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u540c\u6d41\u52a8\u6761\u4ef6\u4e0b\u751f\u6210\u7a33\u5b9a\u4e14\u7269\u7406\u4e00\u81f4\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u591a\u79cd\u6d41\u4f53\u529b\u5b66\u4efb\u52a1\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u591a\u573a\u666f\u6d41\u4f53\u6d41\u52a8\u9884\u6d4b\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u590d\u6742\u6d41\u4f53\u52a8\u529b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.24149", "pdf": "https://arxiv.org/pdf/2505.24149", "abs": "https://arxiv.org/abs/2505.24149", "authors": ["Adam Piaseczny", "Md Kamran Chowdhury Shisher", "Shiqiang Wang", "Christopher G. Brinton"], "title": "RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning (ML) algorithms deployed in real-world environments are\noften faced with the challenge of adapting models to concept drift, where the\ntask data distributions are shifting over time. The problem becomes even more\ndifficult when model performance must be maintained under adherence to strict\nresource constraints. Existing solutions often depend on drift-detection\nmethods that produce high computational overhead for resource-constrained\nenvironments, and fail to provide strict guarantees on resource usage or\ntheoretical performance assurances. To address these shortcomings, we propose\nRCCDA: a dynamic model update policy that optimizes ML training dynamics while\nensuring strict compliance to predefined resource constraints, utilizing only\npast loss information and a tunable drift threshold. In developing our policy,\nwe analytically characterize the evolution of model loss under concept drift\nwith arbitrary training update decisions. Integrating these results into a\nLyapunov drift-plus-penalty framework produces a lightweight policy based on a\nmeasurable accumulated loss threshold that provably limits update frequency and\ncost. Experimental results on three domain generalization datasets demonstrate\nthat our policy outperforms baseline methods in inference accuracy while\nadhering to strict resource constraints under several schedules of concept\ndrift, making our solution uniquely suited for real-time ML deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a RCCDA \u7684\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u7b56\u7565\uff0c\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u6709\u6548\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u4f1a\u4ea7\u751f\u8f83\u9ad8\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u4e14\u65e0\u6cd5\u63d0\u4f9b\u5bf9\u8d44\u6e90\u4f7f\u7528\u6216\u7406\u8bba\u6027\u80fd\u7684\u4e25\u683c\u4fdd\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u8fc7\u53bb\u7684\u635f\u5931\u4fe1\u606f\u548c\u53ef\u8c03\u6f02\u79fb\u9608\u503c\uff0c\u901a\u8fc7 Lyapunov drift-plus-penalty \u6846\u67b6\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u57fa\u4e8e\u53ef\u6d4b\u91cf\u7684\u7d2f\u79ef\u635f\u5931\u9608\u503c\uff0c\u6709\u6548\u9650\u5236\u4e86\u6a21\u578b\u66f4\u65b0\u9891\u7387\u548c\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e09\u4e2a\u9886\u57df\u6cdb\u5316\u6570\u636e\u96c6\u4e0a\uff0cRCCDA \u5728\u6982\u5ff5\u6f02\u79fb\u7684\u51e0\u79cd\u8c03\u5ea6\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u591f\u4fdd\u6301\u4e25\u683c\u7684\u8d44\u6e90\u7ea6\u675f\u3002", "conclusion": "RCCDA \u662f\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u65f6\u673a\u5668\u5b66\u4e60\u90e8\u7f72\u7684\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4e25\u683c\u9075\u5b88\u8d44\u6e90\u9650\u5236\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u3002"}}
{"id": "2505.24155", "pdf": "https://arxiv.org/pdf/2505.24155", "abs": "https://arxiv.org/abs/2505.24155", "authors": ["Ehtesamul Azim", "Dongjie Wang", "Tae Hyun Hwang", "Yanjie Fu", "Wei Zhang"], "title": "Biological Pathway Guided Gene Selection Through Collaborative Reinforcement Learning", "categories": ["cs.LG"], "comment": "31st SIGKDD Conference on Knowledge Discovery and Data Mining (KDD\n  2025)", "summary": "Gene selection in high-dimensional genomic data is essential for\nunderstanding disease mechanisms and improving therapeutic outcomes.\nTraditional feature selection methods effectively identify predictive genes but\noften ignore complex biological pathways and regulatory networks, leading to\nunstable and biologically irrelevant signatures. Prior approaches, such as\nLasso-based methods and statistical filtering, either focus solely on\nindividual gene-outcome associations or fail to capture pathway-level\ninteractions, presenting a key challenge: how to integrate biological pathway\nknowledge while maintaining statistical rigor in gene selection? To address\nthis gap, we propose a novel two-stage framework that integrates statistical\nselection with biological pathway knowledge using multi-agent reinforcement\nlearning (MARL). First, we introduce a pathway-guided pre-filtering strategy\nthat leverages multiple statistical methods alongside KEGG pathway information\nfor initial dimensionality reduction. Next, for refined selection, we model\ngenes as collaborative agents in a MARL framework, where each agent optimizes\nboth predictive power and biological relevance. Our framework incorporates\npathway knowledge through Graph Neural Network-based state representations, a\nreward mechanism combining prediction performance with gene centrality and\npathway coverage, and collaborative learning strategies using shared memory and\na centralized critic component. Extensive experiments on multiple gene\nexpression datasets demonstrate that our approach significantly improves both\nprediction accuracy and biological interpretability compared to traditional\nmethods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u57fa\u56e0\u9009\u62e9\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7edf\u8ba1\u65b9\u6cd5\u548c\u751f\u7269\u901a\u8def\u77e5\u8bc6\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u4e86\u57fa\u56e0\u9009\u62e9\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u751f\u7269\u5b66\u610f\u4e49\u3002", "motivation": "\u4f20\u7edf\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u8bc6\u522b\u9884\u6d4b\u6027\u57fa\u56e0\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u4e86\u590d\u6742\u7684\u751f\u7269\u901a\u8def\u548c\u8c03\u63a7\u7f51\u7edc\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7a33\u5b9a\u4e14\u4e0e\u751f\u7269\u5b66\u65e0\u5173\u3002\u5982\u4f55\u5728\u4fdd\u6301\u7edf\u8ba1\u4e25\u8c28\u6027\u7684\u540c\u65f6\u6574\u5408\u751f\u7269\u901a\u8def\u77e5\u8bc6\u662f\u5f53\u524d\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u57fa\u4e8e\u901a\u8def\u7684\u9884\u7b5b\u9009\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u79cd\u7edf\u8ba1\u65b9\u6cd5\u548cKEGG\u901a\u8def\u4fe1\u606f\u8fdb\u884c\u521d\u6b65\u964d\u7ef4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u5c06\u57fa\u56e0\u5efa\u6a21\u4e3a\u534f\u4f5c\u667a\u80fd\u4f53\uff0c\u4f18\u5316\u9884\u6d4b\u80fd\u529b\u548c\u751f\u7269\u5b66\u76f8\u5173\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u751f\u7269\u5b66\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u751f\u7269\u901a\u8def\u77e5\u8bc6\u548c\u7edf\u8ba1\u9009\u62e9\u7684\u57fa\u56e0\u9009\u62e9\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u96c6\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u751f\u7269\u5b66\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2505.24157", "pdf": "https://arxiv.org/pdf/2505.24157", "abs": "https://arxiv.org/abs/2505.24157", "authors": ["Seungjoon Lee", "Suhwan Kim", "Minhyeon Oh", "Youngsik Yoon", "Jungseul Ok"], "title": "Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing autonomous agents capable of mastering complex, multi-step tasks\nin unpredictable, interactive environments presents a significant challenge.\nWhile Large Language Models (LLMs) offer promise for planning, existing\napproaches often rely on problematic internal knowledge or make unrealistic\nenvironmental assumptions. Although recent work explores learning planning\nknowledge, they still retain limitations due to partial reliance on external\nknowledge or impractical setups. Indeed, prior research has largely overlooked\ndeveloping agents capable of acquiring planning knowledge from scratch,\ndirectly in realistic settings. While realizing this capability is necessary,\nit presents significant challenges, primarily achieving robustness given the\nsubstantial risk of incorporating LLMs' inaccurate knowledge. Moreover,\nefficiency is crucial for practicality as learning can demand prohibitive\nexploration. In response, we introduce Robust and Efficient Planning for\nOpen-world Agents (REPOA), a novel framework designed to tackle these issues.\nREPOA features three key components: adaptive dependency learning and\nfine-grained failure-aware operation memory to enhance robustness to knowledge\ninaccuracies, and difficulty-based exploration to improve learning efficiency.\nOur evaluation in two established open-world testbeds demonstrates REPOA's\nrobust and efficient planning, showcasing its capability to successfully obtain\nchallenging late-game items that were beyond the reach of prior approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faREPOA\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u77e5\u8bc6\u9c81\u68d2\u6027\u548c\u63d0\u5347\u63a2\u7d22\u6548\u7387\uff0c\u89e3\u51b3\u5f00\u653e\u4e16\u754c\u4e2d\u591a\u6b65\u9aa4\u4efb\u52a1\u89c4\u5212\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u590d\u6742\u3001\u591a\u53d8\u73af\u5883\u4e2d\u8fdb\u884c\u89c4\u5212\u5b58\u5728\u8f83\u5927\u6311\u6218\uff0c\u4e3b\u8981\u95ee\u9898\u5305\u62ec\u5bf9LLM\u5185\u90e8\u77e5\u8bc6\u7684\u8fc7\u5ea6\u4f9d\u8d56\u548c\u73af\u5883\u5047\u8bbe\u4e0d\u73b0\u5b9e\u3002", "method": "\u5f15\u5165\u4e86REPOA\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u4f9d\u8d56\u5b66\u4e60\u3001\u7ec6\u7c92\u5ea6\u5931\u8d25\u611f\u77e5\u64cd\u4f5c\u8bb0\u5fc6\u4ee5\u53ca\u57fa\u4e8e\u96be\u5ea6\u7684\u63a2\u7d22\u673a\u5236\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u653e\u4e16\u754c\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cREPOA\u5177\u5907\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u9ad8\u6548\u6027\uff0c\u53ef\u4ee5\u6210\u529f\u83b7\u53d6\u4e4b\u524d\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u76ee\u6807\u3002", "conclusion": "REPOA\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e0b\u667a\u80fd\u4f53\u7684\u89c4\u5212\u80fd\u529b\u548c\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u77e5\u8bc6\u4f9d\u8d56\u548c\u63a2\u7d22\u6548\u7387\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.24178", "pdf": "https://arxiv.org/pdf/2505.24178", "abs": "https://arxiv.org/abs/2505.24178", "authors": ["Katherine Tieu", "Dongqi Fu", "Jun Wu", "Jingrui He"], "title": "Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by AISTATS 2025. 22 pages, 2 figures, 6 tables", "summary": "In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,\nthe data discrepancy between the training environments and testing\nenvironments, hinder AI generalization. Further, relational data like graphs\ndisobeying the Independent and Identically Distributed (IID) condition makes\nthe problem more challenging, especially much harder when it is associated with\ntime. Motivated by this, to realize the robust invariant learning over temporal\ngraphs, we want to investigate what components in temporal graphs are most\ninvariant and representative with respect to labels. With the Information\nBottleneck (IB) method, we propose an error-bounded Invariant Link Selector\nthat can distinguish invariant components and variant components during the\ntraining process to make the deep learning model generalizable for different\ntesting scenarios. Besides deriving a series of rigorous generalizable\noptimization functions, we also equip the training with task-specific loss\nfunctions, e.g., temporal link prediction, to make pretrained models solve\nreal-world application tasks like citation recommendation and merchandise\nrecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)\nmethods. Our code is available at https://github.com/kthrn22/OOD-Linker.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u65b9\u6cd5\u7684\u8bef\u5dee\u6709\u754c\u4e0d\u53d8\u94fe\u63a5\u9009\u62e9\u5668\uff0c\u7528\u4e8e\u5728\u65f6\u95f4\u56fe\u4e0a\u5b9e\u73b0\u9c81\u68d2\u4e0d\u53d8\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u5206\u5e03\u5916\u95ee\u9898\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u65f6\u4ee3\uff0c\u5206\u5e03\u5916\uff08OOD\uff09\u95ee\u9898\u963b\u788d\u4e86AI\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u8fdd\u53cd\u72ec\u7acb\u540c\u5206\u5e03\uff08IID\uff09\u6761\u4ef6\u7684\u5173\u7cfb\u6570\u636e\uff08\u5982\u56fe\uff09\u4e2d\uff0c\u8fd9\u4e00\u95ee\u9898\u66f4\u52a0\u4e25\u91cd\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u65f6\u95f4\u56fe\u4e2d\u54ea\u4e9b\u7ec4\u4ef6\u5bf9\u4e8e\u6807\u7b7e\u662f\u6700\u4e0d\u53d8\u4e14\u5177\u6709\u4ee3\u8868\u6027\u7684\u3002", "method": "\u5229\u7528\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bef\u5dee\u6709\u754c\u4e0d\u53d8\u94fe\u63a5\u9009\u62e9\u5668\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u80fd\u591f\u533a\u5206\u4e0d\u53d8\u7ec4\u4ef6\u548c\u53ef\u53d8\u7ec4\u4ef6\uff0c\u4ece\u800c\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u6d4b\u8bd5\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u540c\u65f6\u63a8\u5bfc\u4e86\u4e00\u7cfb\u5217\u4e25\u683c\u7684\u53ef\u6cdb\u5316\u4f18\u5316\u51fd\u6570\uff0c\u5e76\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u635f\u5931\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u4ee5\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u95ee\u9898\uff0c\u4f8b\u5982\u5f15\u7528\u63a8\u8350\u548c\u5546\u54c1\u63a8\u8350\uff0c\u5e76\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\uff08SOTA\uff09\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u9a8c\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u8bef\u5dee\u6709\u754c\u4e0d\u53d8\u94fe\u63a5\u9009\u62e9\u5668\uff0c\u5b9e\u73b0\u4e86\u5728\u65f6\u95f4\u56fe\u4e0a\u7684\u9c81\u68d2\u4e0d\u53d8\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.24179", "pdf": "https://arxiv.org/pdf/2505.24179", "abs": "https://arxiv.org/abs/2505.24179", "authors": ["Xiaodong Ji", "Hailin Zhang", "Fangcheng Fu", "Bin Cui"], "title": "SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many advanced Large Language Model (LLM) applications require long-context\nprocessing, but the self-attention module becomes a bottleneck during the\nprefilling stage of inference due to its quadratic time complexity with respect\nto sequence length. Existing sparse attention methods accelerate attention\ncomputation by skipping less significant regions of the attention map. However,\nthese approaches typically perform coarse-grained inspection of the attention\nmap, rendering considerable loss in model accuracy. In this paper, we propose\nSALE, a fine-grained sparse attention method that accelerates the long-context\nprefilling stage of LLM with negligible loss in model accuracy. SALE achieves\nfast and accurate fine-grained attention weight estimation through 4-bit\nquantized query-key products, followed by block-sparse attention to accelerate\nprefilling computations. For importance evaluation for query-key pairs, we\nadopt our Relative Attention Score metric, which offers significantly higher\nefficiency within our framework. We implement a custom CUDA kernel optimized\nfor our approach for hardware efficiency, reducing the additional overhead to\napproximately 11% of the full attention latency. Notably, SALE requires no\nparameter training and can be seamlessly integrated into existing systems with\ntrivial code modifications. Experiments on long-context benchmarks demonstrate\nthat our method outperforms existing approaches in accuracy-efficiency\ntrade-offs, achieving at least 3.36x speedups on Llama-3.1-8B for sequences\nlonger than 64K while maintaining model quality.", "AI": {"tldr": "This paper proposes SALE, a fine-grained sparse attention method for accelerating long-context prefilling in large language models (LLMs) with minimal impact on model accuracy.", "motivation": "The self-attention module becomes a bottleneck during the prefilling stage of inference for large language models (LLMs) due to its quadratic time complexity with respect to sequence length. Existing sparse attention methods accelerate attention computation but typically perform coarse-grained inspection of the attention map, leading to considerable loss in model accuracy.", "method": "SALE employs 4-bit quantized query-key products for fast and accurate fine-grained attention weight estimation, followed by block-sparse attention to accelerate prefilling computations. It also introduces the Relative Attention Score metric for importance evaluation of query-key pairs and implements a custom CUDA kernel optimized for hardware efficiency.", "result": "Experiments on long-context benchmarks demonstrate that SALE outperforms existing approaches in terms of accuracy-efficiency trade-offs, achieving at least 3.36x speedups on Llama-3.1-8B for sequences longer than 64K while maintaining model quality. The implementation of a custom CUDA kernel reduces additional overhead to approximately 11% of the full attention latency.", "conclusion": "SALE is a fine-grained sparse attention method that accelerates long-context prefilling in LLMs with negligible loss in model accuracy. It achieves significant speedups while maintaining model quality and can be seamlessly integrated into existing systems with minimal code modifications."}}
{"id": "2505.24183", "pdf": "https://arxiv.org/pdf/2505.24183", "abs": "https://arxiv.org/abs/2505.24183", "authors": ["Yaoyu Zhu", "Di Huang", "Hanqi Lyu", "Xiaoyun Zhang", "Chongxiao Li", "Wenxuan Shi", "Yutong Wu", "Jianan Mu", "Jinghua Wang", "Yang Zhao", "Pengwei Jin", "Shuyao Cheng", "Shengwen Liang", "Xishan Zhang", "Rui Zhang", "Zidong Du", "Qi Guo", "Xing Hu", "Yunji Chen"], "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation", "categories": ["cs.LG", "cs.AR", "cs.PL"], "comment": null, "summary": "Large language models (LLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have achieved breakthroughs on tasks with explicit,\nautomatable verification, such as software programming and mathematical\nproblems. Extending RLVR to electronic design automation (EDA), especially\nautomatically generating hardware description languages (HDLs) like Verilog\nfrom natural-language (NL) specifications, however, poses three key challenges:\nthe lack of automated and accurate verification environments, the scarcity of\nhigh-quality NL-code pairs, and the prohibitive computation cost of RLVR. To\nthis end, we introduce CodeV-R1, an RLVR framework for training Verilog\ngeneration LLMs. First, we develop a rule-based testbench generator that\nperforms robust equivalence checking against golden references. Second, we\npropose a round-trip data synthesis method that pairs open-source Verilog\nsnippets with LLM-generated NL descriptions, verifies code-NL-code consistency\nvia the generated testbench, and filters out inequivalent examples to yield a\nhigh-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training\npipeline: distillation for the cold start of reasoning abilities, followed by\nadaptive DAPO, our novel RLVR algorithm that can reduce training cost by\nadaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves\n68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively,\nsurpassing prior state-of-the-art by 12~20%, while matching or even exceeding\nthe performance of 671B DeepSeek-R1. We will release our model, training\npipeline, and dataset to facilitate research in EDA and LLM communities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u751f\u6210Verilog\u4ee3\u7801\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6CodeV-R1\uff0c\u901a\u8fc7\u89e3\u51b3\u9a8c\u8bc1\u73af\u5883\u3001\u6570\u636e\u8d28\u91cf\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u8f6c\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u6269\u5c55\u5230\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\uff0c\u7279\u522b\u662f\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff08\u5982Verilog\uff09\uff0c\u9762\u4e34\u7f3a\u4e4f\u81ea\u52a8\u4e14\u51c6\u786e\u7684\u9a8c\u8bc1\u73af\u5883\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u4ee5\u53ca\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u89c4\u5219\u7684\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\u5668\uff1b\u63d0\u51fa\u4e86\u5f80\u8fd4\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u201cdistill-then-RL\u201d\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94DAPO\u7b97\u6cd5\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "result": "\u6a21\u578bCodeV-R1-7B\u5728VerilogEval v2\u548cRTLLM v1.1\u4e0a\u5206\u522b\u8fbe\u523068.6%\u548c72.9%\u7684pass@1\uff0c\u8d85\u8fc7\u4e4b\u524d\u6700\u5148\u8fdb\u7684\u7ed3\u679c12~20%\uff0c\u6027\u80fd\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a671B\u7684DeepSeek-R1\u3002", "conclusion": "CodeV-R1\u4e3aVerilog\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684RLVR\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u9a8c\u8bc1\u73af\u5883\u7f3a\u5931\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002"}}
{"id": "2505.24185", "pdf": "https://arxiv.org/pdf/2505.24185", "abs": "https://arxiv.org/abs/2505.24185", "authors": ["Yipan Wei", "Yuchen Zou", "Yapeng Li", "Bo Du"], "title": "Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated Multi-Task Learning (FMTL) enables multiple clients performing\nheterogeneous tasks without exchanging their local data, offering broad\npotential for privacy preserving multi-task collaboration. However, most\nexisting methods focus on building personalized models for each client and\nunable to support the aggregation of multiple heterogeneous tasks into a\nunified model. As a result, in real-world scenarios where task objectives,\nlabel spaces, and optimization paths vary significantly, conventional FMTL\nmethods struggle to achieve effective joint training. To address this\nchallenge, we propose FedDEA (Federated Decoupled Aggregation), an\nupdate-structure-aware aggregation method specifically designed for multi-task\nmodel integration. Our method dynamically identifies task-relevant dimensions\nbased on the response strength of local updates and enhances their optimization\neffectiveness through rescaling. This mechanism effectively suppresses\ncross-task interference and enables task-level decoupled aggregation within a\nunified global model. FedDEA does not rely on task labels or architectural\nmodifications, making it broadly applicable and deployment-friendly.\nExperimental results demonstrate that it can be easily integrated into various\nmainstream federated optimization algorithms and consistently delivers\nsignificant overall performance improvements on widely used NYUD-V2 and\nPASCAL-Context. These results validate the robustness and generalization\ncapabilities of FedDEA under highly heterogeneous task settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedDEA\u7684\u8054\u90a6\u89e3\u8026\u805a\u5408\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4ea4\u6362\u672c\u5730\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u89e3\u51b3\u8054\u90a6\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u5f02\u6784\u4efb\u52a1\u805a\u5408\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u4fa7\u91cd\u4e8e\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6784\u5efa\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u65e0\u6cd5\u652f\u6301\u5c06\u591a\u4e2a\u5f02\u6784\u4efb\u52a1\u805a\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u6a21\u578b\u4e2d\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u8054\u5408\u8bad\u7ec3\u3002", "method": "FedDEA\u57fa\u4e8e\u672c\u5730\u66f4\u65b0\u7684\u54cd\u5e94\u5f3a\u5ea6\u52a8\u6001\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u7f29\u653e\u589e\u5f3a\u5176\u4f18\u5316\u6548\u679c\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u4efb\u52a1\u6a21\u578b\u7684\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedDEA\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u5404\u79cd\u4e3b\u6d41\u8054\u90a6\u4f18\u5316\u7b97\u6cd5\u4e2d\uff0c\u5e76\u5728NYUD-V2\u548cPASCAL-Context\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u63d0\u4f9b\u663e\u8457\u7684\u6574\u4f53\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "FedDEA\u662f\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u4efb\u52a1\u6807\u7b7e\u6216\u67b6\u6784\u4fee\u6539\u7684\u8054\u90a6\u89e3\u8026\u805a\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6291\u5236\u8de8\u4efb\u52a1\u5e72\u6270\uff0c\u5e76\u5728\u7edf\u4e00\u5168\u5c40\u6a21\u578b\u4e2d\u5b9e\u73b0\u4efb\u52a1\u7ea7\u89e3\u8026\u805a\u5408\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.24189", "pdf": "https://arxiv.org/pdf/2505.24189", "abs": "https://arxiv.org/abs/2505.24189", "authors": ["Orlando Marquez Ayala", "Patrice Bechard", "Emily Chen", "Maggie Baird", "Jingfei Chen"], "title": "Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4o can handle a wide range of\ncomplex tasks with the right prompt. As per token costs are reduced, the\nadvantages of fine-tuning Small Language Models (SLMs) for real-world\napplications -- faster inference, lower costs -- may no longer be clear. In\nthis work, we present evidence that, for domain-specific tasks that require\nstructured outputs, SLMs still have a quality advantage. We compare fine-tuning\nan SLM against prompting LLMs on the task of generating low-code workflows in\nJSON form. We observe that while a good prompt can yield reasonable results,\nfine-tuning improves quality by 10% on average. We also perform systematic\nerror analysis to reveal model limitations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7b80\u8981\u6307\u51fa\uff0c\u5728\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\uff0c\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u76f8\u6bd4\u63d0\u793a\u4f7f\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ecd\u5177\u6709\u8d28\u91cf\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u6bcf\u4e2atoken\u6210\u672c\u7684\u964d\u4f4e\uff0c\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u7684\u4f18\u52bf\u53ef\u80fd\u4e0d\u518d\u660e\u663e\uff0c\u56e0\u6b64\u672c\u6587\u63a2\u8ba8\u4e86SLMs\u662f\u5426\u4ecd\u5177\u6709\u8d28\u91cf\u4f18\u52bf\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u6bd4\u8f83\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4f7f\u7528\u63d0\u793a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210JSON\u683c\u5f0f\u4f4e\u4ee3\u7801\u5de5\u4f5c\u6d41\u7a0b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6765\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u8bba\u6587\u89c2\u5bdf\u5230\u867d\u7136\u826f\u597d\u7684\u63d0\u793a\u53ef\u4ee5\u4ea7\u751f\u5408\u7406\u7684\u7ed3\u679c\uff0c\u4f46\u5fae\u8c03\u53ef\u4ee5\u5e73\u5747\u63d0\u9ad810%\u7684\u8d28\u91cf\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5bf9\u4e8e\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u9886\u57df\u7279\u5b9a\u4efb\u52a1\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u901a\u8fc7\u5fae\u8c03\u4ecd\u7136\u5177\u6709\u8d28\u91cf\u4f18\u52bf\u3002"}}
{"id": "2505.24190", "pdf": "https://arxiv.org/pdf/2505.24190", "abs": "https://arxiv.org/abs/2505.24190", "authors": ["Lan-Cuong Nguyen", "Quan Nguyen-Tri", "Bang Tran Khanh", "Dung D. Le", "Long Tran-Thanh", "Khoat Than"], "title": "Provably Improving Generalization of Few-Shot Models with Synthetic Data", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Our code will be released soon", "summary": "Few-shot image classification remains challenging due to the scarcity of\nlabeled training examples. Augmenting them with synthetic data has emerged as a\npromising way to alleviate this issue, but models trained on synthetic samples\noften face performance degradation due to the inherent gap between real and\nsynthetic distributions. To address this limitation, we develop a theoretical\nframework that quantifies the impact of such distribution discrepancies on\nsupervised learning, specifically in the context of image classification. More\nimportantly, our framework suggests practical ways to generate good synthetic\nsamples and to train a predictor with high generalization ability. Building\nupon this framework, we propose a novel theoretical-based algorithm that\nintegrates prototype learning to optimize both data partitioning and model\ntraining, effectively bridging the gap between real few-shot data and synthetic\ndata. Extensive experiments results show that our approach demonstrates\nsuperior performance compared to state-of-the-art methods, outperforming them\nacross multiple datasets.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\u7ed3\u5408\u539f\u578b\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u6807\u8bb0\u8bad\u7ec3\u6837\u672c\u7a00\u7f3a\uff0c\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u5c1d\u8bd5\u901a\u8fc7\u6dfb\u52a0\u5408\u6210\u6570\u636e\u6765\u7f13\u89e3\u6b64\u95ee\u9898\u3002\u7136\u800c\uff0c\u7531\u4e8e\u771f\u5b9e\u6570\u636e\u548c\u5408\u6210\u6570\u636e\u5206\u5e03\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u9762\u4e34\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u91cf\u5316\u8fd9\u79cd\u5206\u5e03\u5dee\u5f02\u5f71\u54cd\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u636e\u6b64\u627e\u5230\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7406\u8bba\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u539f\u578b\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u5212\u5206\u548c\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u5176\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u6307\u5bfc\u751f\u6210\u4f18\u826f\u7684\u5408\u6210\u6837\u672c\u5e76\u7ed3\u5408\u539f\u578b\u5b66\u4e60\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u53ef\u4ee5\u6709\u6548\u5f25\u8865\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ece\u800c\u63d0\u5347\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u7684\u6027\u80fd\u3002"}}
{"id": "2505.24193", "pdf": "https://arxiv.org/pdf/2505.24193", "abs": "https://arxiv.org/abs/2505.24193", "authors": ["Ofir Schlisselberg", "Tal Lancewicki", "Peter Auer", "Yishay Mansour"], "title": "Improved Best-of-Both-Worlds Regret for Bandits with Delayed Feedback", "categories": ["cs.LG"], "comment": null, "summary": "We study the multi-armed bandit problem with adversarially chosen delays in\nthe Best-of-Both-Worlds (BoBW) framework, which aims to achieve near-optimal\nperformance in both stochastic and adversarial environments. While prior work\nhas made progress toward this goal, existing algorithms suffer from significant\ngaps to the known lower bounds, especially in the stochastic settings. Our main\ncontribution is a new algorithm that, up to logarithmic factors, matches the\nknown lower bounds in each setting individually.\n  In the adversarial case, our algorithm achieves regret of\n$\\widetilde{O}(\\sqrt{KT} + \\sqrt{D})$, which is optimal up to logarithmic\nterms, where $T$ is the number of rounds, $K$ is the number of arms, and $D$ is\nthe cumulative delay. In the stochastic case, we provide a regret bound which\nscale as $\\sum_{i:\\Delta_i>0}\\left(\\log T/\\Delta_i\\right) + \\frac{1}{K}\\sum\n\\Delta_i \\sigma_{max}$, where $\\Delta_i$ is the sub-optimality gap of arm $i$\nand $\\sigma_{\\max}$ is the maximum number of missing observations.\n  To the best of our knowledge, this is the first BoBW algorithm to\nsimultaneously match the lower bounds in both stochastic and adversarial\nregimes in delayed environment. Moreover, even beyond the BoBW setting, our\nstochastic regret bound is the first to match the known lower bound under\nadversarial delays, improving the second term over the best known result by a\nfactor of $K$.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5ef6\u8fdf\u73af\u5883\u4e2d\u9002\u7528\u4e8e\u968f\u673a\u548c\u5bf9\u6297\u6027\u73af\u5883\u7684\u6700\u4f73\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u3002", "motivation": "\u5df2\u6709\u65b9\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e0b\u4e0e\u5df2\u77e5\u4e0b\u754c\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5728\u6700\u4f73\u53cc\u4e16\u754c\u6846\u67b6\u4e0b\u5206\u6790\u4e86\u5177\u6709\u5bf9\u6297\u6027\u9009\u62e9\u5ef6\u8fdf\u7684\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u8fd9\u4e24\u79cd\u73af\u5883\u7684\u65b0\u7b97\u6cd5\u3002", "result": "\u5bf9\u4e8e\u5bf9\u6297\u6027\u60c5\u51b5\uff0c\u8be5\u7b97\u6cd5\u8fbe\u5230\u4e86\u6700\u4f18\u5bf9\u6570\u56e0\u5b50\u7684\u9057\u61be\uff1b\u5728\u968f\u673a\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u4e86\u4e0e\u5df2\u77e5\u4e0b\u754c\u5339\u914d\u7684\u9057\u61be\u754c\u9650\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u9996\u6b21\u5728\u5ef6\u8fdf\u73af\u5883\u4e2d\u540c\u65f6\u5339\u914d\u968f\u673a\u548c\u5bf9\u6297\u6027\u8bbe\u7f6e\u4e0b\u7684\u4e0b\u754c\u3002"}}
{"id": "2505.24231", "pdf": "https://arxiv.org/pdf/2505.24231", "abs": "https://arxiv.org/abs/2505.24231", "authors": ["Md Shahnawaz", "Bishwajit Prasad Gond", "Durga Prasad Mohapatra"], "title": "Dynamic Malware Classification of Windows PE Files using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Malware detection and classification remains a topic of concern for\ncybersecurity, since it is becoming common for attackers to use advanced\nobfuscation on their malware to stay undetected. Conventional static analysis\nis not effective against polymorphic and metamorphic malware as these change\ntheir appearance without modifying their behavior, thus defying the analysis by\ncode structure alone. This makes it important to use dynamic detection that\nmonitors malware behavior at runtime. In this paper, we present a dynamic\nmalware categorization framework that extracts API argument calls at the\nruntime execution of Windows Portable Executable (PE) files. Extracting and\nencoding the dynamic features of API names, argument return values, and other\nrelative features, we convert raw behavioral data to temporal patterns. To\nenhance feature portrayal, the generated patterns are subsequently converted\ninto grayscale pictures using a magma colormap. These improved photos are used\nto teach a Convolutional Neural Network (CNN) model discriminative features,\nwhich allows for reliable and accurate malware classification. Results from\nexperiments indicate that our method, with an average accuracy of 98.36% is\neffective in classifying different classes of malware and benign by integrating\ndynamic analysis and deep learning. It not only achieves high classification\naccuracy but also demonstrates significant resilience against typical evasion\nstrategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u65b9\u6cd5\uff0c\u5b83\u80fd\u6709\u6548\u5bf9\u6297\u591a\u6001\u6027\u548c\u53d8\u5f62\u6076\u610f\u8f6f\u4ef6\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u8fbe98.36%\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u9759\u6001\u5206\u6790\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u591a\u6001\u6027\u548c\u53d8\u5f62\u6076\u610f\u8f6f\u4ef6\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u5176\u884c\u4e3a\u7684\u60c5\u51b5\u4e0b\u6539\u53d8\u5176\u5916\u89c2\uff0c\u8fd9\u4f7f\u5f97\u4ec5\u51ed\u4ee3\u7801\u7ed3\u6784\u8fdb\u884c\u5206\u6790\u53d8\u5f97\u65e0\u6548\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76d1\u63a7\u6076\u610f\u8f6f\u4ef6\u8fd0\u884c\u65f6\u884c\u4e3a\u7684\u52a8\u6001\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728Windows\u53ef\u79fb\u690d\u6267\u884c\u6587\u4ef6\uff08PE\uff09\u6587\u4ef6\u8fd0\u884c\u65f6\u63d0\u53d6API\u53c2\u6570\u8c03\u7528\uff0c\u5c06\u539f\u59cb\u884c\u4e3a\u6570\u636e\u8f6c\u6362\u4e3a\u65f6\u95f4\u6a21\u5f0f\uff0c\u5e76\u5229\u7528magma\u989c\u8272\u6620\u5c04\u5c06\u8fd9\u4e9b\u6a21\u5f0f\u8f6c\u5316\u4e3a\u7070\u5ea6\u56fe\u50cf\uff0c\u6700\u7ec8\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u4ee5\u83b7\u5f97\u533a\u5206\u6027\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523098.36%\uff0c\u5728\u5206\u7c7b\u4e0d\u540c\u7c7b\u522b\u7684\u6076\u610f\u8f6f\u4ef6\u548c\u826f\u6027\u7a0b\u5e8f\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u6574\u5408\u52a8\u6001\u5206\u6790\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5728\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u4e2d\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u5bf9\u5178\u578b\u7684\u9003\u907f\u7b56\u7565\u8868\u73b0\u51fa\u663e\u8457\u7684\u62b5\u6297\u529b\u3002"}}
{"id": "2505.24254", "pdf": "https://arxiv.org/pdf/2505.24254", "abs": "https://arxiv.org/abs/2505.24254", "authors": ["Zheng Wang", "Wanhao Yu", "Li Yang", "Sen Lin"], "title": "Rethinking Continual Learning with Progressive Neural Collapse", "categories": ["cs.LG"], "comment": null, "summary": "Continual Learning (CL) seeks to build an agent that can continuously learn a\nsequence of tasks, where a key challenge, namely Catastrophic Forgetting,\npersists due to the potential knowledge interference among different tasks. On\nthe other hand, deep neural networks (DNNs) are shown to converge to a terminal\nstate termed Neural Collapse during training, where all class prototypes\ngeometrically form a static simplex equiangular tight frame (ETF). These\nmaximally and equally separated class prototypes make the ETF an ideal target\nfor model learning in CL to mitigate knowledge interference. Thus inspired,\nseveral studies have emerged very recently to leverage a fixed global ETF in\nCL, which however suffers from key drawbacks, such as impracticability and\nlimited performance.To address these challenges and fully unlock the potential\nof ETF in CL, we propose Progressive Neural Collapse (ProNC), a novel framework\nthat completely removes the need of a fixed global ETF in CL. Specifically,\nProNC progressively expands the ETF target in a principled way by adding new\nclass prototypes as vertices for new tasks, ensuring maximal separability\nacross all encountered classes with minimal shifts from the previous ETF. We\nnext develop a new CL framework by plugging ProNC into commonly used CL\nalgorithm designs, where distillation is further leveraged to balance between\ntarget shifting for old classes and target aligning for new classes. Extensive\nexperiments show that our approach significantly outperforms related baselines\nwhile maintaining superior flexibility, simplicity, and efficiency.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6ProNC\uff0c\u5b83\u901a\u8fc7\u9010\u6b65\u6269\u5c55ETF\u76ee\u6807\u6765\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u901a\u8fc7distillation\u5e73\u8861\u65e7\u7c7b\u548c\u65b0\u7c7b\u7684\u76ee\u6807\u8c03\u6574\u3002", "motivation": "\u73b0\u6709\u7684\u4f7f\u7528\u56fa\u5b9a\u5168\u5c40ETF\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e0d\u5207\u5b9e\u9645\u6027\u548c\u6027\u80fd\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684CL\u6846\u67b6\uff0c\u5229\u7528distillation\u5728\u65e7\u7c7b\u76ee\u6807\u8c03\u6574\u548c\u65b0\u7c7b\u76ee\u6807\u5bf9\u9f50\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u3001\u7b80\u5355\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6ProNC\uff0c\u901a\u8fc7\u9010\u6b65\u6269\u5c55ETF\u76ee\u6807\u6765\u6709\u6548\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2505.24262", "pdf": "https://arxiv.org/pdf/2505.24262", "abs": "https://arxiv.org/abs/2505.24262", "authors": ["Hiroki Naganuma", "Kotaro Yoshida", "Laura Gomezjurado Gonzalez", "Takafumi Horie", "Yuji Naraki", "Ryotaro Shimizu"], "title": "On Fairness of Task Arithmetic: The Role of Task Vectors", "categories": ["cs.LG"], "comment": null, "summary": "Model editing techniques, particularly task arithmetic using task vectors,\nhave shown promise in efficiently modifying pre-trained models through\narithmetic operations like task addition and negation. Despite computational\nadvantages, these methods may inadvertently affect model fairness, creating\nrisks in sensitive applications like hate speech detection. However, the\nfairness implications of task arithmetic remain largely unexplored, presenting\na critical gap in the existing literature. We systematically examine how\nmanipulating task vectors affects fairness metrics, including Demographic\nParity and Equalized Odds. To rigorously assess these effects, we benchmark\ntask arithmetic against full fine-tuning, a costly but widely used baseline,\nand Low-Rank Adaptation (LoRA), a prevalent parameter-efficient fine-tuning\nmethod. Additionally, we explore merging task vectors from models fine-tuned on\ndemographic subgroups vulnerable to hate speech, investigating whether fairness\noutcomes can be controlled by adjusting task vector coefficients, potentially\nenabling tailored model behavior. Our results offer novel insights into the\nfairness implications of model editing and establish a foundation for\nfairness-aware and responsible model editing practices.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u4efb\u52a1\u5411\u91cf\u8fdb\u884c\u6a21\u578b\u7f16\u8f91\u5bf9\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u8c03\u6574\u4efb\u52a1\u5411\u91cf\u7cfb\u6570\u5b9e\u73b0\u516c\u5e73\u6027\u63a7\u5236\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5c3d\u7ba1\u4efb\u52a1\u5411\u91cf\u5728\u8ba1\u7b97\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5b83\u4eec\u53ef\u80fd\u4f1a\u65e0\u610f\u95f4\u5f71\u54cd\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u8fd9\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7b49\u654f\u611f\u5e94\u7528\u4e2d\u5b58\u5728\u98ce\u9669\u3002\u7136\u800c\uff0c\u4efb\u52a1\u7b97\u672f\u7684\u516c\u5e73\u6027\u542b\u4e49\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u8fd9\u9879\u7814\u7a76\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u7b97\u672f\u4e0e\u5168\u5fae\u8c03\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u7814\u7a76\u4ece\u6613\u53d7\u4ec7\u6068\u8a00\u8bba\u5f71\u54cd\u7684\u4eba\u53e3\u7edf\u8ba1\u5b50\u7ec4\u4e2d\u5408\u5e76\u4efb\u52a1\u5411\u91cf\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u6a21\u578b\u7f16\u8f91\u516c\u5e73\u6027\u5f71\u54cd\u7684\u65b0\u89c1\u89e3\uff0c\u5e76\u53d1\u73b0\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u4efb\u52a1\u5411\u91cf\u7cfb\u6570\u6765\u63a7\u5236\u516c\u5e73\u6027\u7ed3\u679c\uff0c\u4ece\u800c\u5b9e\u73b0\u5b9a\u5236\u5316\u7684\u6a21\u578b\u884c\u4e3a\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u4efb\u52a1\u5411\u91cf\u7684\u4fee\u6539\u5bf9\u516c\u5e73\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u4e3a\u5b9e\u73b0\u5177\u6709\u516c\u5e73\u610f\u8bc6\u548c\u8d1f\u8d23\u4efb\u7684\u6a21\u578b\u7f16\u8f91\u5b9e\u8df5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24293", "pdf": "https://arxiv.org/pdf/2505.24293", "abs": "https://arxiv.org/abs/2505.24293", "authors": ["James R. Golden"], "title": "Large Language Models are Locally Linear Mappings", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Version 0", "summary": "We demonstrate that the inference operations of several open-weight large\nlanguage models (LLMs) can be mapped to an exactly equivalent linear system for\nan input sequence without modifying the model weights or altering output\npredictions. Extending techniques from image diffusion models that exhibit\nlocal or piecewise linearity, we strategically alter the gradient computation\nwith respect to a given input sequence for a next-token prediction such that\nthe Jacobian of the model nearly exactly reproduces the forward prediction with\na linear system. We demonstrate this approach across models (Llama 3, Gemma 3,\nQwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show\nthrough the singular value decomposition of the detached Jacobian that these\nLLMs operate in extremely low-dimensional subspaces where many of the largest\nsingular vectors decode to concepts related to the most-likely output token.\nThis approach also allows us to examine the operation of each successive layer\n(and its attention and MLP components) as nearly-exact linear systems and\nobserve the emergence of semantic concepts. Despite their expressive power and\nglobal nonlinearity, modern LLMs can be interpreted through nearly-exact\nlocally linear decompositions that provide insights into their internal\nrepresentations and reveal interpretable semantic structures in the next-token\nprediction process.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u7b49\u6548\u7684\u7ebf\u6027\u7cfb\u7edf\uff0c\u4ece\u800c\u63ed\u793a\u5176\u5185\u90e8\u7684\u8bed\u4e49\u7ed3\u6784\u548c\u5de5\u4f5c\u673a\u5236\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u4fee\u6539\u6743\u91cd\u6216\u6539\u53d8\u8f93\u51fa\u9884\u6d4b\u7684\u60c5\u51b5\u4e0b\u662f\u5426\u53ef\u4ee5\u6620\u5c04\u5230\u7b49\u6548\u7ebf\u6027\u7cfb\u7edf\uff0c\u4ece\u800c\u63ed\u793a\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6280\u672f\uff0c\u5bf9\u7ed9\u5b9a\u8f93\u5165\u5e8f\u5217\u7684\u68af\u5ea6\u8ba1\u7b97\u8fdb\u884c\u7b56\u7565\u6027\u4fee\u6539\uff0c\u4f7f\u5f97\u6a21\u578b\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u51e0\u4e4e\u7cbe\u786e\u5730\u518d\u73b0\u524d\u5411\u9884\u6d4b\u7684\u7ebf\u6027\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u8868\u660e\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982Llama 3, Gemma 3, Qwen 3\u7b49\uff09\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u8fd0\u884c\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u5947\u5f02\u503c\u5206\u89e3\u89c2\u5bdf\u5230\u4e0e\u6700\u53ef\u80fd\u8f93\u51fa\u6807\u8bb0\u76f8\u5173\u7684\u8bed\u4e49\u6982\u5ff5\u3002", "conclusion": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u51e0\u4e4e\u7cbe\u786e\u7684\u5c40\u90e8\u7ebf\u6027\u5206\u89e3\u6765\u89e3\u91ca\uff0c\u8fd9\u4e3a\u7406\u89e3\u5176\u5185\u90e8\u8868\u793a\u548c\u8bed\u4e49\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2505.24298", "pdf": "https://arxiv.org/pdf/2505.24298", "abs": "https://arxiv.org/abs/2505.24298", "authors": ["Wei Fu", "Jiaxuan Gao", "Xujie Shen", "Chen Zhu", "Zhiyu Mei", "Chuyi He", "Shusheng Xu", "Guo Wei", "Jun Mei", "Jiashu Wang", "Tongkai Yang", "Binhang Yuan", "Yi Wu"], "title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a trending paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are synchronous\nby alternating generation and training in a batch setting, where the rollouts\nin each training batch are generated by the same (or latest) model. This\nstabilizes RL training but suffers from severe system-level inefficiency.\nGeneration must wait until the longest output in the batch is completed before\nmodel update, resulting in GPU underutilization. We present AReaL, a\n\\emph{fully asynchronous} RL system that completely decouples generation from\ntraining. Rollout workers in AReaL continuously generate new outputs without\nwaiting, while training workers update the model whenever a batch of data is\ncollected. AReaL also incorporates a collection of system-level optimizations,\nleading to substantially higher GPU utilization. To stabilize RL training,\nAReaL balances the workload of rollout and training workers to control data\nstaleness, and adopts a staleness-enhanced PPO variant to better handle\noutdated training samples. Extensive experiments on math and code reasoning\nbenchmarks show that AReaL achieves \\textbf{up to 2.57$\\times$ training\nspeedup} compared to the best synchronous systems with the same number of GPUs\nand matched or even improved final performance. The code of AReaL is available\nat https://github.com/inclusionAI/AReaL/.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdAReaL\uff0c\u4e00\u79cd\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u5168\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\uff0c\u6709\u6548\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u4e0eGPU\u5229\u7528\u7387\uff0c\u5e76\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c4\u6a21RL\u7cfb\u7edf\u7531\u4e8e\u540c\u6b65\u673a\u5236\u5bfc\u81f4\u4e25\u91cd\u7684\u7cfb\u7edf\u7ea7\u6548\u7387\u4f4e\u4e0b\uff0c\u751f\u6210\u5fc5\u987b\u7b49\u5f85\u6574\u4e2a\u6279\u6b21\u4e2d\u6700\u957f\u8f93\u51fa\u5b8c\u6210\uff0c\u9020\u6210GPU\u5229\u7528\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u5f02\u6b65\u7684RL\u7cfb\u7edf\uff0c\u5c06\u751f\u6210\u4e0e\u8bad\u7ec3\u5b8c\u5168\u89e3\u8026\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u7cfb\u7edf\u7ea7\u4f18\u5316\u6765\u63d0\u9ad8GPU\u5229\u7528\u7387\u5e76\u91c7\u7528\u9648\u65e7\u589e\u5f3a\u7684PPO\u53d8\u4f53\u6765\u5904\u7406\u8fc7\u65f6\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAReaL\u5728\u76f8\u540c\u6570\u91cfGPU\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u540c\u6b65\u7cfb\u7edf\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e862.57\u500d\uff0c\u4e14\u6700\u7ec8\u6027\u80fd\u5339\u914d\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "AReaL\u901a\u8fc7\u5b8c\u5168\u5f02\u6b65\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.57\u500d\u7684\u8bad\u7ec3\u52a0\u901f\uff0c\u5e76\u4e14\u6700\u7ec8\u6027\u80fd\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002"}}
{"id": "2505.24313", "pdf": "https://arxiv.org/pdf/2505.24313", "abs": "https://arxiv.org/abs/2505.24313", "authors": ["Gengze Xu", "Wei Yao", "Ziqiao Wang", "Yong Liu"], "title": "On the Emergence of Weak-to-Strong Generalization: A Bias-Variance Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Weak-to-strong generalization (W2SG) refers to the phenomenon where a strong\nstudent model, trained on a dataset labeled by a weak teacher, ultimately\noutperforms the teacher on the target task. Recent studies attribute this\nperformance gain to the prediction misfit between the student and teacher\nmodels. In this work, we theoretically investigate the emergence of W2SG\nthrough a generalized bias-variance decomposition of Bregman divergence.\nSpecifically, we show that the expected population risk gap between the student\nand teacher is quantified by the expected misfit between the two models. While\nthis aligns with previous results, our analysis removes several restrictive\nassumptions, most notably, the convexity of the student's hypothesis class,\nrequired in earlier works. Moreover, we show that W2SG is more likely to emerge\nwhen the student model approximates its posterior mean teacher, rather than\nmimicking an individual teacher. Using a concrete example, we demonstrate that\nif the student model has significantly larger capacity than the teacher, it can\nindeed converge to this posterior mean. Our analysis also suggests that\navoiding overfitting to the teacher's supervision and reducing the entropy of\nstudent's prediction further facilitate W2SG. In addition, we show that the\nreverse cross-entropy loss, unlike the standard forward cross-entropy, is less\nsensitive to the predictive uncertainty of the teacher. Finally, we empirically\nverify our theoretical insights and demonstrate that incorporating the reverse\ncross-entropy loss consistently improves student performance.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f31\u5230\u5f3a\u6cdb\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u6765\u63d0\u9ad8\u5b66\u751f\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u5c06\u5f31\u5230\u5f3a\u6cdb\u5316\u5f52\u56e0\u4e8e\u5b66\u751f\u548c\u6559\u5e08\u6a21\u578b\u4e4b\u95f4\u7684\u9884\u6d4b\u4e0d\u5339\u914d\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\u3002", "method": "\u901a\u8fc7Bregman\u6563\u5ea6\u7684\u5e7f\u4e49\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u7406\u8bba\u4e0a\u7814\u7a76\u5b66\u751f\u548c\u6559\u5e08\u6a21\u578b\u4e4b\u95f4\u7684\u9884\u671f\u603b\u4f53\u98ce\u9669\u5dee\u8ddd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5b66\u751f\u6a21\u578b\u5982\u679c\u5177\u6709\u6bd4\u6559\u5e08\u66f4\u5927\u7684\u5bb9\u91cf\uff0c\u53ef\u4ee5\u6536\u655b\u5230\u540e\u9a8c\u5747\u503c\u6559\u5e08\uff0c\u4ece\u800c\u66f4\u5bb9\u6613\u4ea7\u751f\u5f31\u5230\u5f3a\u6cdb\u5316\u3002", "conclusion": "\u672c\u6587\u5f97\u51fa\u5f31\u5230\u5f3a\u6cdb\u5316\u73b0\u8c61\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u51cf\u5c11\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u76d1\u7763\u7684\u8fc7\u62df\u5408\u4ee5\u53ca\u964d\u4f4e\u5176\u9884\u6d4b\u71b5\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u8fd9\u4e00\u73b0\u8c61\u3002"}}
{"id": "2505.24317", "pdf": "https://arxiv.org/pdf/2505.24317", "abs": "https://arxiv.org/abs/2505.24317", "authors": ["Yongming Chen", "Miner Chen", "Liewen Liao", "Mingyang Jiang", "Xiang Zuo", "Hengrui Zhang", "Yuchen Xi", "Songan Zhang"], "title": "ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) in autonomous driving employs a trial-and-error\nmechanism, enhancing robustness in unpredictable environments. However,\ncrafting effective reward functions remains challenging, as conventional\napproaches rely heavily on manual design and demonstrate limited efficacy in\ncomplex scenarios. To address this issue, this study introduces a\nresponsibility-oriented reward function that explicitly incorporates traffic\nregulations into the RL framework. Specifically, we introduced a Traffic\nRegulation Knowledge Graph and leveraged Vision-Language Models alongside\nRetrieval-Augmented Generation techniques to automate reward assignment. This\nintegration guides agents to adhere strictly to traffic laws, thus minimizing\nrule violations and optimizing decision-making performance in diverse driving\nconditions. Experimental validations demonstrate that the proposed methodology\nsignificantly improves the accuracy of assigning accident responsibilities and\neffectively reduces the agent's liability in traffic incidents.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u8d23\u4efb\u5bfc\u5411\u578b\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u4e0e\u751f\u6210\u6280\u672f\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u679c\u548c\u89c4\u5219\u9075\u5b88\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u56e0\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u6548\u679c\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5956\u52b1\u673a\u5236\u3002", "method": "\u5f15\u5165\u4e86\u4ea4\u901a\u89c4\u5219\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u5b9e\u73b0\u5956\u52b1\u5206\u914d\u7684\u81ea\u52a8\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u6545\u8d23\u4efb\u5206\u914d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u6709\u6548\u51cf\u5c11\u4e86\u667a\u80fd\u4f53\u5728\u4ea4\u901a\u4e8b\u6545\u4e2d\u7684\u8d23\u4efb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u901a\u89c4\u5219\u77e5\u8bc6\u56fe\u8c31\u7684\u8d23\u4efb\u5bfc\u5411\u578b\u5956\u52b1\u51fd\u6570\uff0c\u4ee5\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u80fd\u529b\u548c\u4ea4\u901a\u89c4\u5219\u9075\u5b88\u80fd\u529b\u3002"}}
{"id": "2505.24324", "pdf": "https://arxiv.org/pdf/2505.24324", "abs": "https://arxiv.org/abs/2505.24324", "authors": ["Ivan Petrukha", "Yana Kurliak", "Nataliia Stulova"], "title": "SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE"], "comment": "Accepted to FORGE'25 Benchmarking on 15.01.2025, to be published by\n  IEEE under the CC BY-NC-ND 4.0 license. This is the accepted version of the\n  article (5 pages, 2 figures, 1 table). DOI will be added upon publication", "summary": "In recent years, large language models (LLMs) have showcased significant\nadvancements in code generation. However, most evaluation benchmarks are\nprimarily oriented towards Python, making it difficult to evaluate other\nprogramming languages, such as Swift, with high quality. By examining widely\nestablished multilingual benchmarks like HumanEval-XL and MultiPL-E, we\nidentified critical issues specific to their Swift components, making them\ninsufficient or even irrelevant for assessing LLM coding capabilities on Swift.\nUnlike these existing approaches, which prioritize rapid scaling and\ngeneralization by automatically translating Python-centric benchmarks with\nLLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the\nfirst Swift-oriented benchmark consisting of 28 carefully hand-crafted\nproblems, and evaluate 44 popular Code LLMs on it. Our results show significant\nLLM scores drop for problems requiring language-specific features, most\nnoticeable in the models of smaller sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u73b0\u6709\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u5728Swift\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u65b0\u7684Swift\u4e13\u7528\u57fa\u51c6\u6d4b\u8bd5SwiftEval\uff0c\u5e76\u53d1\u73b0\u5176\u5bf9\u5c0f\u578b\u6a21\u578b\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u9762\u5411Python\uff0c\u96be\u4ee5\u9ad8\u8d28\u91cf\u8bc4\u4f30\u5176\u4ed6\u7f16\u7a0b\u8bed\u8a00\u5982Swift\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u4e13\u6ce8\u4e8eSwift\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0Swift\u90e8\u5206\u5b58\u5728\u4e0d\u8db3\uff0c\u91c7\u7528\u8d28\u91cf\u4f18\u5148\u7684\u65b9\u6cd5\u521b\u5efa\u4e86\u5305\u542b28\u4e2a\u624b\u5de5\u8bbe\u8ba1\u95ee\u9898\u7684SwiftEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5bf944\u79cd\u6d41\u884c\u7684\u4ee3\u7801LLM\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u9700\u8981\u8bed\u8a00\u7279\u5b9a\u529f\u80fd\u7684\u95ee\u9898\u4e0a\uff0cLLM\u5f97\u5206\u663e\u8457\u4e0b\u964d\uff0c\u5c24\u5176\u662f\u8f83\u5c0f\u7684\u6a21\u578b\u66f4\u4e3a\u660e\u663e\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0cSwiftEval\u5bf9\u4e8e\u8bc4\u4f30LLM\u5728Swift\u7f16\u7a0b\u8bed\u8a00\u65b9\u9762\u7684\u7279\u5b9a\u529f\u80fd\u8868\u73b0\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5bf9\u5c0f\u578b\u6a21\u578b\u5f71\u54cd\u663e\u8457\u3002"}}
{"id": "2505.24353", "pdf": "https://arxiv.org/pdf/2505.24353", "abs": "https://arxiv.org/abs/2505.24353", "authors": ["Federico Milanesio", "Matteo Santoro", "Pietro G. Fr\u00e9", "Guido Sanguinetti"], "title": "Cartan Networks: Group theoretical Hyperbolic Deep Learning", "categories": ["cs.LG"], "comment": "20 pages, 3 figures, under review", "summary": "Hyperbolic deep learning leverages the metric properties of hyperbolic spaces\nto develop efficient and informative embeddings of hierarchical data. Here, we\nfocus on the solvable group structure of hyperbolic spaces, which follows\nnaturally from their construction as symmetric spaces. This dual nature of Lie\ngroup and Riemannian manifold allows us to propose a new class of hyperbolic\ndeep learning algorithms where group homomorphisms are interleaved with\nmetric-preserving diffeomorphisms. The resulting algorithms, which we call\nCartan networks, show promising results on various benchmark data sets and open\nthe way to a novel class of hyperbolic deep learning architectures.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u66f2\u7a7a\u95f4\u7ed3\u6784\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5Cartan\u7f51\u7edc\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u901a\u8fc7\u5229\u7528\u8d85\u7403\u7a7a\u95f4\u7684\u5ea6\u91cf\u7279\u6027\uff0c\u5f00\u53d1\u9ad8\u6548\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u5c42\u6b21\u6570\u636e\u5d4c\u5165\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u7684\u53ef\u89e3\u7fa4\u7ed3\u6784\uff0c\u5c06\u7fa4\u540c\u6001\u4e0e\u5ea6\u91cf\u4fdd\u6301\u5fae\u5206\u540c\u80da\u4ea4\u9519\u4f7f\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d85\u7403\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCartan\u7f51\u7edc\u7684\u65b0\u7b97\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002", "conclusion": "Cartan\u7f51\u7edc\u4e3a\u8d85\u7403\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u7c7b\u522b\uff0c\u5e76\u5728\u5404\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002"}}
{"id": "2505.24357", "pdf": "https://arxiv.org/pdf/2505.24357", "abs": "https://arxiv.org/abs/2505.24357", "authors": ["Xianglong Yan", "Zhiteng Li", "Tianao Zhang", "Linghe Kong", "Yulun Zhang", "Xiaokang Yang"], "title": "ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable performance, yet their\ncapability on long-context reasoning is often constrained by the excessive\nmemory required to store the Key-Value (KV) cache. This makes KV cache\ncompression an essential step toward enabling efficient long-context reasoning.\nRecent methods have explored reducing the hidden dimensions of the KV cache,\nbut many introduce additional computation through projection layers or suffer\nfrom significant performance degradation under high compression ratios. To\naddress these challenges, we propose ReCalKV, a post-training KV cache\ncompression method that reduces the hidden dimensions of the KV cache. We\ndevelop distinct compression strategies for Keys and Values based on their\ndifferent roles and varying importance in the attention mechanism. For Keys, we\npropose Head-wise Similarity-aware Reordering (HSR), which clusters similar\nheads and applies grouped SVD to the key projection matrix, reducing additional\ncomputation while preserving accuracy. For Values, we propose Offline\nCalibration and Matrix Fusion (OCMF) to preserve accuracy without extra\ncomputational overhead. Experiments show that ReCalKV outperforms existing\nlow-rank compression methods, achieving high compression ratios with minimal\nperformance loss. Code is available at:\nhttps://github.com/XIANGLONGYAN/ReCalKV.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReCalKV\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u522b\u5bf9Keys\u548cValues\u8fdb\u884c\u4f18\u5316\u538b\u7f29\uff0c\u4ee5\u6700\u5c0f\u7684\u6027\u80fd\u635f\u5931\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u5f80\u5f80\u5f15\u5165\u989d\u5916\u8ba1\u7b97\u6216\u5728\u9ad8\u538b\u7f29\u6bd4\u4e0b\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u9488\u5bf9Keys\u548cValues\u7684\u4e0d\u540c\u538b\u7f29\u7b56\u7565\uff0c\u5305\u62ecHead-wise Similarity-aware Reordering (HSR) \u548c Offline Calibration and Matrix Fusion (OCMF)\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u4f4e\u79e9\u538b\u7f29\u65b9\u6cd5\u76f8\u6bd4\uff0cReCalKV\u8868\u73b0\u66f4\u597d\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u538b\u7f29\u7387\u3002", "conclusion": "ReCalKV\u662f\u4e00\u79cd\u6709\u6548\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6700\u5c0f\u6027\u80fd\u635f\u5931\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u538b\u7f29\u6bd4\uff0c\u6709\u52a9\u4e8e\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3002"}}
{"id": "2505.24369", "pdf": "https://arxiv.org/pdf/2505.24369", "abs": "https://arxiv.org/abs/2505.24369", "authors": ["Yuanfu Wang", "Pengyu Wang", "Chenyang Xi", "Bo Tang", "Junyi Zhu", "Wenqiang Wei", "Chen Chen", "Chao Yang", "Jingfeng Zhang", "Chaochao Lu", "Yijun Niu", "Keming Mao", "Zhiyu Li", "Feiyu Xiong", "Jie Hu", "Mingchuan Yang"], "title": "Adversarial Preference Learning for Robust LLM Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ACL2025 Findings", "summary": "Modern language models often rely on Reinforcement Learning from Human\nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to\nadversarial attacks due to three key limitations: (1) the inefficiency and high\ncost of human annotation, (2) the vast diversity of potential adversarial\nattacks, and (3) the risk of feedback bias and reward hacking. To address these\nchallenges, we introduce Adversarial Preference Learning (APL), an iterative\nadversarial training method incorporating three key innovations. First, a\ndirect harmfulness metric based on the model's intrinsic preference\nprobabilities, eliminating reliance on external assessment. Second, a\nconditional generative attacker that synthesizes input-specific adversarial\nvariations. Third, an iterative framework with automated closed-loop feedback,\nenabling continuous adaptation through vulnerability discovery and mitigation.\nExperiments on Mistral-7B-Instruct-v0.3 demonstrate that APL significantly\nenhances robustness, achieving 83.33% harmlessness win rate over the base model\n(evaluated by GPT-4o), reducing harmful outputs from 5.88% to 0.43% (measured\nby LLaMA-Guard), and lowering attack success rate by up to 65% according to\nHarmBench. Notably, APL maintains competitive utility, with an MT-Bench score\nof 6.59 (comparable to the baseline 6.78) and an LC-WinRate of 46.52% against\nthe base model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdversarial Preference Learning (APL)\u7684\u8fed\u4ee3\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u5728\u4f7f\u7528\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60(RLHF)\u65f6\u7684\u5b89\u5168\u884c\u4e3a\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u5728\u9f13\u52b1\u5b89\u5168\u884c\u4e3a\u65b9\u9762\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60(RLHF)\uff0c\u4f46\u7531\u4e8e\u4eba\u5de5\u6807\u6ce8\u6548\u7387\u4f4e\u3001\u6f5c\u5728\u5bf9\u6297\u653b\u51fb\u591a\u6837\u6027\u4ee5\u53ca\u53cd\u9988\u504f\u5dee\u548c\u5956\u52b1\u9ed1\u5ba2\u98ce\u9669\u7b49\u539f\u56e0\uff0c\u5b83\u4eec\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "method": "\u5f15\u5165\u4e86Adversarial Preference Learning (APL)\uff0c\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1) \u57fa\u4e8e\u6a21\u578b\u5185\u5728\u504f\u597d\u6982\u7387\u7684\u76f4\u63a5\u6709\u5bb3\u6027\u5ea6\u91cf\uff1b(2) \u5408\u6210\u8f93\u5165\u7279\u5b9a\u5bf9\u6297\u53d8\u5316\u7684\u6761\u4ef6\u751f\u6210\u653b\u51fb\u8005\uff1b(3) \u5177\u6709\u81ea\u52a8\u5316\u95ed\u73af\u53cd\u9988\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7\u6f0f\u6d1e\u53d1\u73b0\u548c\u7f13\u89e3\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAPL\u663e\u8457\u589e\u5f3a\u4e86Mistral-7B-Instruct-v0.3\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5728GPT-4o\u8bc4\u4f30\u4e2d\u8fbe\u5230\u4e8683.33%\u7684\u65e0\u5bb3\u80dc\u7387\uff0c\u5c06LLaMA-Guard\u6d4b\u91cf\u7684\u6709\u5bb3\u8f93\u51fa\u4ece5.88%\u964d\u4f4e\u52300.43%\uff0c\u5e76\u6839\u636eHarmBench\u964d\u4f4e\u4e8665%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002\u6b64\u5916\uff0cAPL\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\uff0cMT-Bench\u5f97\u5206\u4e3a6.59\uff0cLC-WinRate\u4e3a46.52%\u5bf9\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "APL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86RLHF\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24360", "pdf": "https://arxiv.org/pdf/2505.24360", "abs": "https://arxiv.org/abs/2505.24360", "authors": ["Stepan Shabalin", "Ayush Panda", "Dmitrii Kharlapenko", "Abdur Raheem Ali", "Yixiong Hao", "Arthur Conmy"], "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "categories": ["cs.LG"], "comment": "10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR\n  2025", "summary": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u548cITDA\u5e94\u7528\u4e8e\u5927\u578b\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578bFlux 1\uff0c\u53d1\u73b0SAEs\u5728\u91cd\u6784\u548c\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u53ef\u7528\u4e8e\u5f15\u5bfc\u56fe\u50cf\u751f\u6210\u3002", "motivation": "\u63a2\u7d22\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u5206\u89e3\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u5e76\u5c1d\u8bd5\u5c06\u5176\u4e0eITDA\u65b9\u6cd5\u7ed3\u5408\u4ee5\u63d0\u5347\u6a21\u578b\u89e3\u91ca\u6027\u548c\u63a7\u5236\u80fd\u529b\u3002", "method": "\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u548c\u63a8\u65ad\u65f6\u6fc0\u6d3b\u5206\u89e3\uff08ITDA\uff09\u5e94\u7528\u4e8e\u5927\u578b\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578bFlux 1\uff0c\u5e76\u5f15\u5165\u89c6\u89c9\u81ea\u52a8\u5316\u89e3\u91ca\u7ba1\u9053\u6765\u8bc4\u4f30\u5d4c\u5165\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "SAEs\u80fd\u591f\u51c6\u786e\u5730\u91cd\u6784\u6b8b\u5dee\u6d41\u5d4c\u5165\uff0c\u5e76\u5728\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8eMLP\u795e\u7ecf\u5143\uff1b\u901a\u8fc7SAE\u7279\u5f81\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u56fe\u50cf\u751f\u6210\u7684\u5f15\u5bfc\uff1bITDA\u5728\u89e3\u91ca\u6027\u65b9\u9762\u4e0eSAEs\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u548cITDA\u5728Flux 1\u6a21\u578b\u4e2d\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u91cd\u6784\u80fd\u529b\uff0cSAEs\u5728\u5d4c\u5165\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8eMLP\u795e\u7ecf\u5143\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u6fc0\u6d3b\u52a0\u6cd5\u5f15\u5bfc\u56fe\u50cf\u751f\u6210\u3002"}}
{"id": "2505.24378", "pdf": "https://arxiv.org/pdf/2505.24378", "abs": "https://arxiv.org/abs/2505.24378", "authors": ["Yilun Kong", "Guozheng Ma", "Qi Zhao", "Haoyu Wang", "Li Shen", "Xueqian Wang", "Dacheng Tao"], "title": "Mastering Massive Multi-Task Reinforcement Learning via Mixture-of-Expert Decision Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Despite recent advancements in offline multi-task reinforcement learning\n(MTRL) have harnessed the powerful capabilities of the Transformer\narchitecture, most approaches focus on a limited number of tasks, with scaling\nto extremely massive tasks remaining a formidable challenge. In this paper, we\nfirst revisit the key impact of task numbers on current MTRL method, and\nfurther reveal that naively expanding the parameters proves insufficient to\ncounteract the performance degradation as the number of tasks escalates.\nBuilding upon these insights, we propose M3DT, a novel mixture-of-experts (MoE)\nframework that tackles task scalability by further unlocking the model's\nparameter scalability. Specifically, we enhance both the architecture and the\noptimization of the agent, where we strengthen the Decision Transformer (DT)\nbackbone with MoE to reduce task load on parameter subsets, and introduce a\nthree-stage training mechanism to facilitate efficient training with optimal\nperformance. Experimental results show that, by increasing the number of\nexperts, M3DT not only consistently enhances its performance as model expansion\non the fixed task numbers, but also exhibits remarkable task scalability,\nsuccessfully extending to 160 tasks with superior performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86M3DT\uff0c\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u7684\u79bb\u7ebf\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u4efb\u52a1\u4e0b\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6548\u8bad\u7ec3\u548c\u5353\u8d8a\u7684\u4efb\u52a1\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5c3d\u7ba1Transformer\u67b6\u6784\u5df2\u5728\u79bb\u7ebf\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u5f97\u5230\u5e94\u7528\uff0c\u4f46\u5f53\u4efb\u52a1\u6570\u91cf\u6781\u5927\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u663e\u8457\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u51b3\u7b56Transformer\u9aa8\u5e72\u7f51\u7edc\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u8bad\u7ec3\u673a\u5236\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cM3DT\u4e0d\u4ec5\u5728\u56fa\u5b9a\u4efb\u52a1\u6570\u91cf\u4e0b\u968f\u6a21\u578b\u6269\u5c55\u63d0\u5347\u6027\u80fd\uff0c\u800c\u4e14\u5728\u4efb\u52a1\u6570\u91cf\u589e\u52a0\u5230160\u4e2a\u65f6\u4ecd\u4fdd\u6301\u5353\u8d8a\u8868\u73b0\u3002", "conclusion": "M3DT\u901a\u8fc7\u5f15\u5165\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebf\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u4efb\u52a1\u53ef\u6269\u5c55\u6027\u7684\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5927\u91cf\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.24365", "pdf": "https://arxiv.org/pdf/2505.24365", "abs": "https://arxiv.org/abs/2505.24365", "authors": ["Vardhan Shorewala", "Shivam Shorewala"], "title": "Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm", "categories": ["cs.LG", "cs.PF"], "comment": "IEEE ICCCSP", "summary": "This paper introduces a unified approach to cluster refinement and anomaly\ndetection in datasets. We propose a novel algorithm that iteratively reduces\nthe intra-cluster variance of N clusters until a global minimum is reached,\nyielding tighter clusters than the standard k-means algorithm. We evaluate the\nmethod using intrinsic measures for unsupervised learning, including the\nsilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and\nextend it to anomaly detection by identifying points whose assignment causes a\nsignificant variance increase. External validation on synthetic data and the\nUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity\nscore, V-measure, and F1 score. Results show variance reductions of 18.7% and\n88.1% on the synthetic and Wine Quality datasets, respectively, along with\naccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality\ndataset.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u805a\u7c7b\u4f18\u5316\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u51cf\u5c11\u7c07\u5185\u65b9\u5dee\u6765\u5b9e\u73b0\u6bd4\u6807\u51c6k\u5747\u503c\u7b97\u6cd5\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u6807\u51c6k\u5747\u503c\u7b97\u6cd5\u5728\u751f\u6210\u66f4\u7d27\u5bc6\u7684\u805a\u7c7b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u805a\u7c7b\u4f18\u5316\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u4ece\u800c\u63d0\u9ad8\u6570\u636e\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fed\u4ee3\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4e0d\u65ad\u51cf\u5c11N\u4e2a\u805a\u7c7b\u7684\u7c07\u5185\u65b9\u5dee\uff0c\u76f4\u5230\u8fbe\u5230\u5168\u5c40\u6700\u5c0f\u503c\u3002\u4f7f\u7528\u8f6e\u5ed3\u7cfb\u6570\u3001Calinski-Harabasz\u6307\u6570\u548cDavies-Bouldin\u6307\u6570\u7b49\u5185\u5728\u5ea6\u91cf\u5bf9\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u8bc6\u522b\u5bfc\u81f4\u663e\u8457\u65b9\u5dee\u589e\u52a0\u7684\u70b9\u5c06\u5176\u6269\u5c55\u5230\u5f02\u5e38\u68c0\u6d4b\u3002\u5916\u90e8\u9a8c\u8bc1\u91c7\u7528\u4e86Jaccard\u76f8\u4f3c\u6027\u5f97\u5206\u3001V\u6d4b\u5ea6\u548cF1\u6d4b\u5ea6\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u548cUCI Wine Quality\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u5dee\u5206\u522b\u51cf\u5c11\u4e8618.7%\u548c88.1%\uff0c\u5e76\u4e14\u5728UCI Wine Quality\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u6027\u548cF1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e8622.5%\u548c20.8%\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7edf\u4e00\u65b9\u6cd5\u7528\u4e8e\u6570\u636e\u96c6\u4e2d\u7684\u805a\u7c7b\u4f18\u5316\u548c\u5f02\u5e38\u68c0\u6d4b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u51cf\u5c11\u65b9\u5dee\u548c\u63d0\u9ad8\u51c6\u786e\u6027\u548cF1\u5206\u6570\u65b9\u9762\u4f18\u4e8e\u6807\u51c6k\u5747\u503c\u7b97\u6cd5\u3002"}}
{"id": "2505.24379", "pdf": "https://arxiv.org/pdf/2505.24379", "abs": "https://arxiv.org/abs/2505.24379", "authors": ["Xiaoyu Wu", "Yifei Pang", "Terrance Liu", "Zhiwei Steven Wu"], "title": "Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Large language models are typically trained on datasets collected from the\nweb, which may inadvertently contain harmful or sensitive personal information.\nTo address growing privacy concerns, unlearning methods have been proposed to\nremove the influence of specific data from trained models. Of these, exact\nunlearning -- which retrains the model from scratch without the target data --\nis widely regarded the gold standard, believed to be robust against\nprivacy-related attacks. In this paper, we challenge this assumption by\nintroducing a novel data extraction attack that compromises even exact\nunlearning. Our method leverages both the pre- and post-unlearning models: by\nguiding the post-unlearning model using signals from the pre-unlearning model,\nwe uncover patterns that reflect the removed data distribution. Combining model\nguidance with a token filtering strategy, our attack significantly improves\nextraction success rates -- doubling performance in some cases -- across common\nbenchmarks such as MUSE, TOFU, and WMDP. Furthermore, we demonstrate our\nattack's effectiveness on a simulated medical diagnosis dataset to highlight\nreal-world privacy risks associated with exact unlearning. In light of our\nfindings, which suggest that unlearning may, in a contradictory way, increase\nthe risk of privacy leakage, we advocate for evaluation of unlearning methods\nto consider broader threat models that account not only for post-unlearning\nmodels but also for adversarial access to prior checkpoints.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9488\u5bf9\u7cbe\u786e\u9057\u5fd8\u65b9\u6cd5\u7684\u65b0\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff0c\u6307\u51fa\u5373\u4f7f\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u4e5f\u65e0\u6cd5\u5b8c\u5168\u4fdd\u62a4\u9690\u79c1\uff0c\u5e76\u5efa\u8bae\u8bc4\u4f30\u9057\u5fd8\u65b9\u6cd5\u65f6\u5e94\u8003\u8651\u66f4\u5e7f\u6cdb\u7684\u5a01\u80c1\u6a21\u578b\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u65e0\u610f\u4e2d\u5305\u542b\u6709\u5bb3\u6216\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u9057\u5fd8\u65b9\u6cd5\u4ee5\u6d88\u9664\u7279\u5b9a\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u63d0\u53d6\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u9057\u5fd8\u548c\u540e\u9057\u5fd8\u6a21\u578b\u6765\u63ed\u793a\u88ab\u5220\u9664\u6570\u636e\u7684\u5206\u5e03\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u6a21\u578b\u5f15\u5bfc\u548c\u4ee4\u724c\u8fc7\u6ee4\u7b56\u7565\u63d0\u9ad8\u63d0\u53d6\u6210\u529f\u7387\u3002", "result": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u80fd\u591f\u6311\u6218\u5f53\u524d\u8ba4\u4e3a\u6700\u6807\u51c6\u4e14\u6700\u5b89\u5168\u7684\u7cbe\u786e\u9057\u5fd8\u65b9\u6cd5\u7684\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff0c\u5e76\u8868\u660e\u5176\u653b\u51fb\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u63d0\u53d6\u6210\u529f\u7387\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5373\u5373\u4f7f\u662f\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u7cbe\u786e\u9057\u5fd8\u65b9\u6cd5\u4e5f\u65e0\u6cd5\u5b8c\u5168\u4fdd\u62a4\u9690\u79c1\uff0c\u5e76\u5efa\u8bae\u5728\u8bc4\u4f30\u9057\u5fd8\u65b9\u6cd5\u65f6\u5e94\u8003\u8651\u66f4\u5e7f\u6cdb\u7684\u5a01\u80c1\u6a21\u578b\u3002"}}
{"id": "2505.24415", "pdf": "https://arxiv.org/pdf/2505.24415", "abs": "https://arxiv.org/abs/2505.24415", "authors": ["Andreas Spilz", "Heiko Oppel", "Michael Munz"], "title": "Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Automated evaluation of movement quality holds significant potential for\nenhancing physiotherapeutic treatments and sports training by providing\nobjective, real-time feedback. However, the effectiveness of deep learning\nmodels in assessing movements captured by inertial measurement units (IMUs) is\noften hampered by limited data availability, class imbalance, and label\nambiguity. In this work, we present a novel data augmentation method that\ngenerates realistic IMU data using musculoskeletal simulations integrated with\nsystematic modifications of movement trajectories. Crucially, our approach\nensures biomechanical plausibility and allows for automatic, reliable labeling\nby combining inverse kinematic parameters with a knowledge-based evaluation\nstrategy. Extensive evaluations demonstrate that augmented variants closely\nresembles real-world data, significantly improving the classification accuracy\nand generalization capability of neural network models. Additionally, we\nhighlight the benefits of augmented data for patient-specific fine-tuning\nscenarios, particularly when only limited subject-specific training examples\nare available. Our findings underline the practicality and efficacy of this\naugmentation method in overcoming common challenges faced by deep learning\napplications in physiotherapeutic exercise evaluation.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u901a\u8fc7\u808c\u8089\u9aa8\u9abc\u6a21\u62df\u751f\u6210\u903c\u771f\u7684IMU\u8fd0\u52a8\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u7269\u7406\u6cbb\u7597\u8fd0\u52a8\u8bc4\u4f30\u4e2d\u7684\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8bc4\u4f30\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08IMU\uff09\u6355\u6349\u7684\u52a8\u4f5c\u65f6\u9762\u4e34\u6570\u636e\u6709\u9650\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6807\u7b7e\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u52a8\u4f5c\u8d28\u91cf\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4f7f\u7528\u808c\u8089\u9aa8\u9abc\u6a21\u62df\u751f\u6210IMU\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u8fd0\u52a8\u8f68\u8ff9\u7684\u7cfb\u7edf\u4fee\u6539\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u6570\u636e\u4e0e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u76f8\u4f3c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u60a3\u8005\u7279\u5f02\u6027\u5fae\u8c03\u573a\u666f\u4e2d\u6548\u679c\u660e\u663e\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u6240\u63d0\u51fa\u7684\u589e\u5f3a\u65b9\u6cd5\u5728\u7269\u7406\u6cbb\u7597\u8fd0\u52a8\u8bc4\u4f30\u4e2d\u514b\u670d\u4e86\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u9762\u4e34\u7684\u5e38\u89c1\u6311\u6218\u3002"}}
{"id": "2505.24445", "pdf": "https://arxiv.org/pdf/2505.24445", "abs": "https://arxiv.org/abs/2505.24445", "authors": ["Xin Chen", "Yarden As", "Andreas Krause"], "title": "Learning Safety Constraints for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 (Spotlight)", "summary": "Large language models (LLMs) have emerged as powerful tools but pose\nsignificant safety risks through harmful outputs and vulnerability to\nadversarial attacks. We propose SaP, short for Safety Polytope, a geometric\napproach to LLM safety that learns and enforces multiple safety constraints\ndirectly in the model's representation space. We develop a framework that\nidentifies safe and unsafe regions via the polytope's facets, enabling both\ndetection and correction of unsafe outputs through geometric steering. Unlike\nexisting approaches that modify model weights, SaP operates post-hoc in the\nrepresentation space, preserving model capabilities while enforcing safety\nconstraints. Experiments across multiple LLMs demonstrate that our method can\neffectively detect unethical inputs, reduce adversarial attack success rates\nwhile maintaining performance on standard tasks, thus highlighting the\nimportance of having an explicit geometric model for safety. Analysis of the\nlearned polytope facets reveals emergence of specialization in detecting\ndifferent semantic notions of safety, providing interpretable insights into how\nsafety is captured in LLMs' representation space.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u7684\u51e0\u4f55\u65b9\u6cd5SaP\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5b58\u5728\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\u548c\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u7684\u5b89\u5168\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u63d0\u9ad8\u5176\u5b89\u5168\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5728\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\u4e2d\u5b66\u4e60\u548c\u5b9e\u65bd\u591a\u4e2a\u5b89\u5168\u7ea6\u675f\uff0c\u901a\u8fc7\u591a\u9762\u4f53\u7684\u9762\u6765\u8bc6\u522b\u5b89\u5168\u548c\u975e\u5b89\u5168\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aLLM\u4e0a\u5747\u80fd\u6709\u6548\u68c0\u6d4b\u4e0d\u9053\u5fb7\u8f93\u5165\u3001\u51cf\u5c11\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6807\u51c6\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSaP\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u65b9\u6cd5\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u6709\u6548\u68c0\u6d4b\u4e0d\u9053\u5fb7\u8f93\u5165\u5e76\u964d\u4f4e\u5bf9\u6297\u653b\u51fb\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2505.24473", "pdf": "https://arxiv.org/pdf/2505.24473", "abs": "https://arxiv.org/abs/2505.24473", "authors": ["Nikita Balagansky", "Yaroslav Aksenov", "Daniil Laptev", "Vadim Kurochkin", "Gleb Gerasimov", "Nikita Koryagin", "Daniil Gavrilov"], "title": "Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse Autoencoders (SAEs) have proven to be powerful tools for interpreting\nneural networks by decomposing hidden representations into disentangled,\ninterpretable features via sparsity constraints. However, conventional SAEs are\nconstrained by the fixed sparsity level chosen during training; meeting\ndifferent sparsity requirements therefore demands separate models and increases\nthe computational footprint during both training and evaluation. We introduce a\nnovel training objective, \\emph{HierarchicalTopK}, which trains a single SAE to\noptimise reconstructions across multiple sparsity levels simultaneously.\nExperiments with Gemma-2 2B demonstrate that our approach achieves\nPareto-optimal trade-offs between sparsity and explained variance,\noutperforming traditional SAEs trained at individual sparsity levels. Further\nanalysis shows that HierarchicalTopK preserves high interpretability scores\neven at higher sparsity. The proposed objective thus closes an important gap\nbetween flexibility and interpretability in SAE design.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u8bad\u7ec3\u76ee\u6807HierarchicalTopK\uff0c\u53ef\u5728\u591a\u79cd\u7a00\u758f\u6c34\u5e73\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u7a00\u758f\u6c34\u5e73\u9009\u62e9\uff0c\u96be\u4ee5\u6ee1\u8db3\u4e0d\u540c\u7684\u7a00\u758f\u9700\u6c42\uff0c\u5e76\u4e14\u9700\u8981\u591a\u4e2a\u6a21\u578b\u6765\u589e\u52a0\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aHierarchicalTopK\u7684\u65b0\u8bad\u7ec3\u76ee\u6807\uff0c\u4f7f\u5f97\u5355\u4e2a\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u80fd\u591f\u5728\u4e0d\u540c\u7a00\u758f\u6c34\u5e73\u4e0b\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7a00\u758f\u6027\u548c\u89e3\u91ca\u65b9\u5dee\u4e4b\u95f4\u5b9e\u73b0\u4e86Pareto\u6700\u4f18\u6743\u8861\uff0c\u5e76\u5728\u66f4\u9ad8\u7a00\u758f\u5ea6\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u53ef\u89e3\u91ca\u6027\u5f97\u5206\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u76ee\u6807HierarchicalTopK\uff0c\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u7a00\u758f\u6c34\u5e73\u4e0b\u7684\u91cd\u6784\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u9ad8\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2505.24399", "pdf": "https://arxiv.org/pdf/2505.24399", "abs": "https://arxiv.org/abs/2505.24399", "authors": ["Yifei Cheng", "Li Shen", "Hao Sun", "Nan Yin", "Xiaochun Cao", "Enhong Chen"], "title": "LightSAM: Parameter-Agnostic Sharpness-Aware Minimization", "categories": ["cs.LG"], "comment": null, "summary": "Sharpness-Aware Minimization (SAM) optimizer enhances the generalization\nability of the machine learning model by exploring the flat minima landscape\nthrough weight perturbations. Despite its empirical success, SAM introduces an\nadditional hyper-parameter, the perturbation radius, which causes the\nsensitivity of SAM to it. Moreover, it has been proved that the perturbation\nradius and learning rate of SAM are constrained by problem-dependent parameters\nto guarantee convergence. These limitations indicate the requirement of\nparameter-tuning in practical applications. In this paper, we propose the\nalgorithm LightSAM which sets the perturbation radius and learning rate of SAM\nadaptively, thus extending the application scope of SAM. LightSAM employs three\npopular adaptive optimizers, including AdaGrad-Norm, AdaGrad and Adam, to\nreplace the SGD optimizer for weight perturbation and model updating, reducing\nsensitivity to parameters. Theoretical results show that under weak\nassumptions, LightSAM could converge ideally with any choices of perturbation\nradius and learning rate, thus achieving parameter-agnostic. We conduct\npreliminary experiments on several deep learning tasks, which together with the\ntheoretical findings validate the the effectiveness of LightSAM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u7b97\u6cd5LightSAM\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u8bbe\u7f6eSharpness-Aware Minimization (SAM)\u7684\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\uff0c\u51cf\u5c11\u4e86\u5bf9\u53c2\u6570\u8c03\u8282\u7684\u9700\u6c42\uff0c\u5e76\u6269\u5c55\u4e86SAM\u7684\u5e94\u7528\u8303\u56f4\u3002", "motivation": "\u5c3d\u7ba1SAM\u4f18\u5316\u5668\u5728\u7ecf\u9a8c\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u5f15\u5165\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u8d85\u53c2\u6570\u2014\u2014\u6270\u52a8\u534a\u5f84\uff0c\u5bfc\u81f4\u5176\u5bf9\u8be5\u53c2\u6570\u654f\u611f\u3002\u6b64\u5916\uff0c\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\u53d7\u5230\u95ee\u9898\u76f8\u5173\u53c2\u6570\u7684\u9650\u5236\u4ee5\u4fdd\u8bc1\u6536\u655b\u6027\u3002\u8fd9\u4e9b\u9650\u5236\u8868\u660e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8fdb\u884c\u53c2\u6570\u8c03\u4f18\u3002", "method": "LightSAM\u5229\u7528\u4e09\u79cd\u6d41\u884c\u7684\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08\u5305\u62ecAdaGrad-Norm\u3001AdaGrad\u548cAdam\uff09\u53d6\u4ee3SGD\u4f18\u5316\u5668\u6765\u8fdb\u884c\u6743\u91cd\u6270\u52a8\u548c\u6a21\u578b\u66f4\u65b0\uff0c\u4ece\u800c\u964d\u4f4e\u5bf9\u53c2\u6570\u7684\u654f\u611f\u5ea6\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8f83\u5f31\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u65e0\u8bba\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\u5982\u4f55\u9009\u62e9\uff0cLightSAM\u90fd\u53ef\u4ee5\u7406\u60f3\u5730\u6536\u655b\uff0c\u5b9e\u73b0\u4e86\u4e0e\u53c2\u6570\u65e0\u5173\u7684\u7279\u6027\u3002\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LightSAM\u7684\u6709\u6548\u6027\u3002", "conclusion": "LightSAM\u662f\u4e00\u79cd\u66f4\u52a0\u9c81\u68d2\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5bf9\u8d85\u53c2\u6570\u8c03\u8282\u7684\u4f9d\u8d56\uff0c\u62d3\u5c55\u4e86SAM\u5728\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.24492", "pdf": "https://arxiv.org/pdf/2505.24492", "abs": "https://arxiv.org/abs/2505.24492", "authors": ["David Steinmann", "Wolfgang Stammer", "Antonia W\u00fcst", "Kristian Kersting"], "title": "Object Centric Concept Bottlenecks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing high-performing, yet interpretable models remains a critical\nchallenge in modern AI. Concept-based models (CBMs) attempt to address this by\nextracting human-understandable concepts from a global encoding (e.g., image\nencoding) and then applying a linear classifier on the resulting concept\nactivations, enabling transparent decision-making. However, their reliance on\nholistic image encodings limits their expressiveness in object-centric\nreal-world settings and thus hinders their ability to solve complex vision\ntasks beyond single-label classification. To tackle these challenges, we\nintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combines\nthe strengths of CBMs and pre-trained object-centric foundation models,\nboosting performance and interpretability. We evaluate OCB on complex image\ndatasets and conduct a comprehensive ablation study to analyze key components\nof the framework, such as strategies for aggregating object-concept encodings.\nThe results show that OCB outperforms traditional CBMs and allows one to make\ninterpretable decisions for complex visual tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa OCB \u6846\u67b6\uff0c\u7ed3\u5408 CBM \u548c\u5bf9\u8c61\u4e2d\u5fc3\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u7684\u6027\u80fd\u548c\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf CBM \u4f9d\u8d56\u6574\u4f53\u56fe\u50cf\u7f16\u7801\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u3001\u7269\u4f53\u4e2d\u5fc3\u7684\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u65b9\u6cd5\u4ee5\u89e3\u51b3\u66f4\u590d\u6742\u7684\u89c6\u89c9\u4efb\u52a1\u3002", "method": "\u5f15\u5165 OCB\uff08Object-Centric Concept Bottlenecks\uff09\u6846\u67b6\uff0c\u7ed3\u5408 CBM \u548c\u9884\u8bad\u7ec3\u5bf9\u8c61\u4e2d\u5fc3\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u7efc\u5408\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u5173\u952e\u7ec4\u4ef6\u3002", "result": "OCB \u5728\u590d\u6742\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u4f20\u7edf CBM\uff0c\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "OCB \u6846\u67b6\u5728\u590d\u6742\u7684\u89c6\u89c9\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf CBM\uff0c\u5e76\u5141\u8bb8\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u3002"}}
{"id": "2505.24403", "pdf": "https://arxiv.org/pdf/2505.24403", "abs": "https://arxiv.org/abs/2505.24403", "authors": ["Giannis Nikolentzos", "Konstantinos Skianis"], "title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets", "categories": ["cs.LG"], "comment": null, "summary": "The Lipschitz constant of a neural network is connected to several important\nproperties of the network such as its robustness and generalization. It is thus\nuseful in many settings to estimate the Lipschitz constant of a model. Prior\nwork has focused mainly on estimating the Lipschitz constant of multi-layer\nperceptrons and convolutional neural networks. Here we focus on data modeled as\nsets or multisets of vectors and on neural networks that can handle such data.\nThese models typically apply some permutation invariant aggregation function,\nsuch as the sum, mean or max operator, to the input multisets to produce a\nsingle vector for each input sample. In this paper, we investigate whether\nthese aggregation functions are Lipschitz continuous with respect to three\ndistance functions for unordered multisets, and we compute their Lipschitz\nconstants. In the general case, we find that each aggregation function is\nLipschitz continuous with respect to only one of the three distance functions.\nThen, we build on these results to derive upper bounds on the Lipschitz\nconstant of neural networks that can process multisets of vectors, while we\nalso study their stability to perturbations and generalization under\ndistribution shifts. To empirically verify our theoretical analysis, we conduct\na series of experiments on datasets from different domains.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u4e8e\u5904\u7406\u96c6\u5408\u6570\u636e\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u805a\u5408\u51fd\u6570\u662f\u5426\u5177\u6709Lipschitz\u8fde\u7eed\u6027\uff0c\u5e76\u8ba1\u7b97\u5176Lipschitz\u5e38\u6570\uff0c\u8fdb\u4e00\u6b65\u63a8\u5bfc\u4e86\u6574\u4e2a\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\u4e0a\u754c\u53ca\u5176\u7a33\u5b9a\u6027\u4e0e\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\u4e0e\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u5bc6\u5207\u76f8\u5173\uff0c\u56e0\u6b64\u4f30\u8ba1\u6a21\u578b\u7684Lipschitz\u5e38\u6570\u5728\u8bb8\u591a\u573a\u666f\u4e2d\u662f\u6709\u7528\u7684\u3002\u4ee5\u5f80\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u591a\u5c42\u611f\u77e5\u673a\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\u4f30\u8ba1\u4e0a\uff0c\u800c\u672c\u6587\u5173\u6ce8\u4e8e\u80fd\u5904\u7406\u96c6\u5408\u6216\u591a\u91cd\u96c6\u6570\u636e\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "method": "\u5206\u6790\u4e86\u9002\u7528\u4e8e\u5904\u7406\u96c6\u5408\u6216\u591a\u91cd\u96c6\u6570\u636e\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u7528\u7684\u805a\u5408\u51fd\u6570\uff08\u5982sum\u3001mean\u3001max\uff09\u662f\u5426\u76f8\u5bf9\u4e8e\u4e09\u79cd\u65e0\u5e8f\u591a\u91cd\u96c6\u8ddd\u79bb\u51fd\u6570\u5177\u6709Lipschitz\u8fde\u7eed\u6027\uff0c\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684Lipschitz\u5e38\u6570\u3002", "result": "\u7406\u8bba\u4e0a\u53d1\u73b0\uff0c\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6bcf\u79cd\u805a\u5408\u51fd\u6570\u4ec5\u76f8\u5bf9\u4e8e\u4e09\u79cd\u8ddd\u79bb\u51fd\u6570\u4e4b\u4e00\u662fLipschitz\u8fde\u7eed\u7684\uff1b\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u6bcf\u79cd\u805a\u5408\u51fd\u6570\u4ec5\u76f8\u5bf9\u4e8e\u4e09\u79cd\u65e0\u5e8f\u591a\u91cd\u96c6\u8ddd\u79bb\u51fd\u6570\u4e4b\u4e00\u6ee1\u8db3Lipschitz\u8fde\u7eed\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u7ed3\u679c\u63a8\u5bfc\u51fa\u80fd\u591f\u5904\u7406\u5411\u91cf\u591a\u91cd\u96c6\u7684\u795e\u7ecf\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\u4e0a\u754c\uff0c\u540c\u65f6\u7814\u7a76\u4e86\u5176\u5728\u6270\u52a8\u4e0b\u7684\u7a33\u5b9a\u6027\u53ca\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2505.24511", "pdf": "https://arxiv.org/pdf/2505.24511", "abs": "https://arxiv.org/abs/2505.24511", "authors": ["Jiahao Wang", "Mingyue Cheng", "Qi Liu"], "title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting (TSF) is a fundamental and widely studied task,\nspanning methods from classical statistical approaches to modern deep learning\nand multimodal language modeling. Despite their effectiveness, these methods\noften follow a fast thinking paradigm emphasizing pattern extraction and direct\nvalue mapping, while overlooking explicit reasoning over temporal dynamics and\ncontextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g.,\nChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning\ncapabilities across diverse domains, suggesting a new opportunity for reframing\nTSF as a structured reasoning task. This motivates a key question: can\nslow-thinking LLMs effectively reason over temporal patterns to support time\nseries forecasting, even in zero-shot manner? To investigate this, in this\npaper, we propose TimeReasoner, an extensive empirical study that formulates\nTSF as a conditional reasoning task. We design a series of prompting strategies\nto elicit inference-time reasoning from pretrained slow-thinking LLMs and\nevaluate their performance across diverse TSF benchmarks. Our findings reveal\nthat slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities,\nespecially in capturing high-level trends and contextual shifts. While\npreliminary, our study surfaces important insights into the reasoning behaviors\nof LLMs in temporal domains highlighting both their potential and limitations.\nWe hope this work catalyzes further research into reasoning-based forecasting\nparadigms and paves the way toward more interpretable and generalizable TSF\nframeworks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528slow-thinking LLM\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u53ef\u80fd\u6027\uff0c\u63d0\u51faTimeReasoner\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u5176\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5177\u6709\u4e00\u5b9a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5feb\u901f\u601d\u7ef4\u6a21\u5f0f\uff0c\u5ffd\u7565\u4e86\u5bf9\u65f6\u95f4\u52a8\u6001\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u660e\u786e\u63a8\u7406\u3002\u800c\u65b0\u5174\u7684slow-thinking LLM\u5728\u591a\u6b65\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u56e0\u6b64\u8bba\u6587\u63a2\u8ba8\u662f\u5426\u80fd\u5229\u7528\u8fd9\u7c7b\u6a21\u578b\u6765\u8fdb\u884c\u6709\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "method": "\u63d0\u51faTimeReasoner\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6761\u4ef6\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e00\u7cfb\u5217\u63d0\u793a\u7b56\u7565\u6765\u5f15\u5bfc\u9884\u8bad\u7ec3\u7684slow-thinking LLM\u8fdb\u884c\u63a8\u7406\u3002\u540c\u65f6\uff0c\u5728\u591a\u4e2aTSF\u57fa\u51c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cslow-thinking LLM\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u5c55\u73b0\u51fa\u975e\u540c\u5bfb\u5e38\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5c24\u5176\u5728\u8bc6\u522b\u590d\u6742\u8d8b\u52bf\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u65b9\u9762\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u65f6\u95f4\u9886\u57df\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660eslow-thinking LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5177\u6709\u4e00\u5b9a\u7684\u96f6\u6837\u672c\u9884\u6d4b\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6355\u6349\u9ad8\u5c42\u6b21\u8d8b\u52bf\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u65b9\u9762\u3002\u8bba\u6587\u5f3a\u8c03\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u9884\u6d4b\u8303\u5f0f\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u65b9\u5411\u3002"}}
{"id": "2505.24413", "pdf": "https://arxiv.org/pdf/2505.24413", "abs": "https://arxiv.org/abs/2505.24413", "authors": ["Yang Sui", "Qi Xu", "Yang Bai", "Annie Qu"], "title": "Multi-task Learning for Heterogeneous Multi-source Block-Wise Missing Data", "categories": ["cs.LG", "stat.CO"], "comment": null, "summary": "Multi-task learning (MTL) has emerged as an imperative machine learning tool\nto solve multiple learning tasks simultaneously and has been successfully\napplied to healthcare, marketing, and biomedical fields. However, in order to\nborrow information across different tasks effectively, it is essential to\nutilize both homogeneous and heterogeneous information. Among the extensive\nliterature on MTL, various forms of heterogeneity are presented in MTL\nproblems, such as block-wise, distribution, and posterior heterogeneity.\nExisting methods, however, struggle to tackle these forms of heterogeneity\nsimultaneously in a unified framework. In this paper, we propose a two-step\nlearning strategy for MTL which addresses the aforementioned heterogeneity.\nFirst, we impute the missing blocks using shared representations extracted from\nhomogeneous source across different tasks. Next, we disentangle the mappings\nbetween input features and responses into a shared component and a\ntask-specific component, respectively, thereby enabling information borrowing\nthrough the shared component. Our numerical experiments and real-data analysis\nfrom the ADNI database demonstrate the superior MTL performance of the proposed\nmethod compared to other competing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u540c\u65f6\u5904\u7406\u591a\u79cd\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u540c\u65f6\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u5757\u72b6\u3001\u5206\u5e03\u548c\u540e\u9a8c\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u4e0b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u6b65\u5b66\u4e60\u7b56\u7565\uff1a\u9996\u5148\u5229\u7528\u8de8\u4efb\u52a1\u7684\u540c\u6e90\u4fe1\u606f\u586b\u8865\u7f3a\u5931\u5757\uff1b\u7136\u540e\u5c06\u8f93\u5165\u7279\u5f81\u4e0e\u54cd\u5e94\u4e4b\u95f4\u7684\u6620\u5c04\u5206\u89e3\u4e3a\u5171\u4eab\u6210\u5206\u548c\u4efb\u52a1\u7279\u5b9a\u6210\u5206\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u548c\u57fa\u4e8eADNI\u6570\u636e\u5e93\u7684\u5b9e\u9645\u6570\u636e\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u5f02\u8d28\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.24533", "pdf": "https://arxiv.org/pdf/2505.24533", "abs": "https://arxiv.org/abs/2505.24533", "authors": ["Mahesh Godavarti"], "title": "Directional Non-Commutative Monoidal Structures with Interchange Law via Commutative Generators", "categories": ["cs.LG", "cs.AI", "cs.SC", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "We introduce a novel framework consisting of a class of algebraic structures\nthat generalize one-dimensional monoidal systems into higher dimensions by\ndefining per-axis composition operators subject to non-commutativity and a\nglobal interchange law. These structures, defined recursively from a base case\nof vector-matrix pairs, model directional composition in multiple dimensions\nwhile preserving structural coherence through commutative linear operators.\n  We show that the framework that unifies several well-known linear transforms\nin signal processing and data analysis. In this framework, data indices are\nembedded into a composite structure that decomposes into simpler components. We\nshow that classic transforms such as the Discrete Fourier Transform (DFT), the\nWalsh transform, and the Hadamard transform are special cases of our algebraic\nstructure. The framework provides a systematic way to derive these transforms\nby appropriately choosing vector and matrix pairs. By subsuming classical\ntransforms within a common structure, the framework also enables the\ndevelopment of learnable transformations tailored to specific data modalities\nand tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9ad8\u7ef4\u4ee3\u6570\u7ed3\u6784\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u7ecf\u5178\u7ebf\u6027\u53d8\u6362\uff0c\u5e76\u53ef\u7528\u4e8e\u5f00\u53d1\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u7684\u53ef\u5b66\u4e60\u53d8\u6362\u3002", "motivation": "\u5c06\u4e00\u7ef4\u5355\u7c7b\u7cfb\u7edf\u6269\u5c55\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u5e76\u7edf\u4e00\u4fe1\u53f7\u5904\u7406\u548c\u6570\u636e\u5206\u6790\u4e2d\u7684\u591a\u79cd\u7ebf\u6027\u53d8\u6362\u3002", "method": "\u4ece\u5411\u91cf-\u77e9\u9635\u5bf9\u7684\u57fa\u672c\u60c5\u51b5\u9012\u5f52\u5b9a\u4e49\u591a\u7ef4\u65b9\u5411\u7ec4\u5408\u7684\u4ee3\u6570\u7ed3\u6784\uff0c\u5e76\u5f15\u5165\u975e\u4ea4\u6362\u6027\u548c\u5168\u5c40\u4ea4\u6362\u5f8b\u3002", "result": "\u8bc1\u660e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u3001Walsh\u53d8\u6362\u548cHadamard\u53d8\u6362\u90fd\u662f\u8be5\u4ee3\u6570\u7ed3\u6784\u7684\u7279\u4f8b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8fd9\u4e9b\u53d8\u6362\u7684\u7cfb\u7edf\u63a8\u5bfc\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7edf\u4e00\u591a\u4e2a\u7ecf\u5178\u53d8\u6362\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bbe\u8ba1\u53ef\u5b66\u4e60\u53d8\u6362\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u7279\u5b9a\u6570\u636e\u6a21\u6001\u548c\u4efb\u52a1\u3002"}}
{"id": "2505.24535", "pdf": "https://arxiv.org/pdf/2505.24535", "abs": "https://arxiv.org/abs/2505.24535", "authors": ["Narmeen Oozeer", "Luke Marks", "Fazl Barez", "Amirali Abdullah"], "title": "Beyond Linear Steering: Unified Multi-Attribute Control for Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Controlling multiple behavioral attributes in large language models (LLMs) at\ninference time is a challenging problem due to interference between attributes\nand the limitations of linear steering methods, which assume additive behavior\nin activation space and require per-attribute tuning. We introduce K-Steering,\na unified and flexible approach that trains a single non-linear multi-label\nclassifier on hidden activations and computes intervention directions via\ngradients at inference time. This avoids linearity assumptions, removes the\nneed for storing and tuning separate attribute vectors, and allows dynamic\ncomposition of behaviors without retraining. To evaluate our method, we propose\ntwo new benchmarks, ToneBank and DebateMix, targeting compositional behavioral\ncontrol. Empirical results across 3 model families, validated by both\nactivation-based classifiers and LLM-based judges, demonstrate that K-Steering\noutperforms strong baselines in accurately steering multiple behaviors.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd K-Steering \u65b9\u6cd5\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u4e0e\u68af\u5ea6\u8ba1\u7b97\uff0c\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u5bf9\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\u7684\u6709\u6548\u63a7\u5236\u3002", "motivation": "\u9700\u8981\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\u7684\u5e72\u6270\u95ee\u9898\uff0c\u5e76\u514b\u670d\u7ebf\u6027\u8f6c\u5411\u65b9\u6cd5\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u975e\u7ebf\u6027\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u548c\u68af\u5ea6\u8ba1\u7b97\u5e72\u9884\u65b9\u5411\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e2d\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cK-Steering \u5728\u51c6\u786e\u5f15\u5bfc\u591a\u79cd\u884c\u4e3a\u65b9\u9762\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "K-Steering \u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u63a8\u7406\u65f6\u63a7\u5236\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\uff0c\u907f\u514d\u4e86\u7ebf\u6027\u5047\u8bbe\u5e76\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u3002"}}
{"id": "2505.24424", "pdf": "https://arxiv.org/pdf/2505.24424", "abs": "https://arxiv.org/abs/2505.24424", "authors": ["Amit Peleg", "Naman Deep Singh", "Matthias Hein"], "title": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Vision-language models like CLIP have demonstrated remarkable zero-shot\ncapabilities in classification and retrieval. However, these models often\nstruggle with compositional reasoning - the ability to understand the\nrelationships between concepts. A recent benchmark, SugarCrepe++, reveals that\nprevious works on improving compositionality have mainly improved lexical\nsensitivity but neglected semantic understanding. In addition, downstream\nretrieval performance often deteriorates, although one would expect that\nimproving compositionality should enhance retrieval. In this work, we introduce\nCLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a\nnovel training technique combining multiple images and their associated\ncaptions. CLIC improves compositionality across architectures as well as\ndifferently pre-trained CLIP models, both in terms of lexical and semantic\nunderstanding, and achieves consistent gains in retrieval performance. This\neven applies to the recent CLIPS, which achieves SOTA retrieval performance.\nNevertheless, the short fine-tuning with CLIC leads to an improvement in\nretrieval and to the best compositional CLIP model on SugarCrepe++. All our\nmodels and code are available at https://clic-compositional-clip.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a CLIC \u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb CLIP \u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u63d0\u5347\u5176\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u63d0\u9ad8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u786e\u4fdd\u4e0d\u635f\u5bb3\u5176\u68c0\u7d22\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u591a\u5f20\u56fe\u50cf\u53ca\u5176\u76f8\u5173\u5b57\u5e55\u7684\u65b0\u8bad\u7ec3\u6280\u672f\u5bf9 CLIP \u8fdb\u884c\u5fae\u8c03\u3002", "result": "CLIC \u5728\u591a\u4e2a\u67b6\u6784\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u4e0a\u90fd\u63d0\u9ad8\u4e86\u8bcd\u6c47\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u5e76\u5728 SugarCrepe++ \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "CLIC \u63d0\u5347\u4e86 CLIP \u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u6539\u5584\u4e86\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2505.24584", "pdf": "https://arxiv.org/pdf/2505.24584", "abs": "https://arxiv.org/abs/2505.24584", "authors": ["Sakhinana Sagar Srinivas", "Shivam Gupta", "Venkataramana Runkana"], "title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7269\u7406\u6a21\u62df\u7684\u95ed\u73af\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u751f\u6210\u7b26\u5408\u5de5\u7a0b\u7ea6\u675f\u7684\u5de5\u4e1a\u7ea7\u5316\u5b66\u5de5\u827a\u6d41\u7a0b\u56fe\u548c\u7ba1\u9053\u4eea\u8868\u56fe\uff0c\u89e3\u51b3\u4e86\u4ece\u5b9e\u9a8c\u5ba4\u53d1\u73b0\u5230\u5de5\u4e1a\u5316\u751f\u4ea7\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u65b0\u578b\u5316\u5b66\u54c1\u548c\u6750\u6599\u7684\u53d1\u73b0\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c06\u5176\u8f6c\u5316\u4e3a\u5de5\u4e1a\u89c4\u6a21\u751f\u4ea7\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u74f6\u9888\uff0c\u56e0\u4e3a\u9700\u8981\u5f00\u53d1\u5168\u65b0\u7684\u5316\u5b66\u5236\u9020\u5de5\u827a\u3002\u73b0\u6709\u7684AI\u65b9\u6cd5\u65e0\u6cd5\u81ea\u52a8\u751f\u6210\u5de5\u827a\u6d41\u7a0b\u56fe\u548c\u7ba1\u9053\u4eea\u8868\u56fe\uff0c\u800c\u8fd9\u4e9b\u5bf9\u4e8e\u6269\u5927\u5316\u5b66\u5de5\u827a\u89c4\u6a21\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u6846\u67b6\u6574\u5408\u4e86\u9886\u57df\u4e13\u7528\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7b2c\u4e00\u6027\u539f\u7406\u6a21\u62df\uff0c\u5229\u7528\u4e86\u4e00\u4e2a\u5305\u542b1020\u591a\u79cd\u5316\u5b66\u54c1\u7684\u5de5\u827a\u6d41\u7a0b\u548c\u4eea\u8868\u63cf\u8ff0\u7684\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u540c\u65f6\u7ed3\u5408DWSIM\u6a21\u62df\u5668\u9a8c\u8bc1\u53ef\u884c\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5e94\u7528\u4e86\u591a\u79cd\u63a8\u7406\u65f6\u4f18\u5316\u6280\u672f\u548c\u7ed3\u6784\u526a\u679d\u6280\u672f\u4ee5\u63d0\u9ad8\u8fd0\u884c\u6548\u7387\u548c\u6a21\u578b\u7d27\u51d1\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9ad8\u4fdd\u771f\u5730\u751f\u6210\u7ecf\u8fc7\u6a21\u62df\u5668\u9a8c\u8bc1\u7684\u5de5\u827a\u63cf\u8ff0\uff0c\u5728\u6b63\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u63a8\u5e7f\u5230\u672a\u89c1\u8fc7\u7684\u5316\u5b66\u54c1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u95ed\u73af\u7684\u3001\u7269\u7406\u611f\u77e5\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u81ea\u52a8\u751f\u6210\u5de5\u4e1a\u4e0a\u53ef\u884c\u7684\u5de5\u827a\u6d41\u7a0b\u56fe\u548c\u7ba1\u9053\u4eea\u8868\u56fe\uff0c\u4ece\u800c\u663e\u8457\u7f29\u77ed\u4ece\u5b9e\u9a8c\u5ba4\u53d1\u73b0\u5230\u5de5\u5382\u90e8\u7f72\u7684\u7814\u53d1\u65f6\u95f4\u3002"}}
{"id": "2505.24434", "pdf": "https://arxiv.org/pdf/2505.24434", "abs": "https://arxiv.org/abs/2505.24434", "authors": ["Md Shahriar Rahim Siddiqui", "Moshe Eliasof", "Eldad Haber"], "title": "Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Flow matching casts sample generation as learning a continuous-time velocity\nfield that transports noise to data. Existing flow matching networks typically\npredict each point's velocity independently, considering only its location and\ntime along its flow trajectory, and ignoring neighboring points. However, this\npointwise approach may overlook correlations between points along the\ngeneration trajectory that could enhance velocity predictions, thereby\nimproving downstream generation quality. To address this, we propose Graph Flow\nMatching (GFM), a lightweight enhancement that decomposes the learned velocity\ninto a reaction term -- any standard flow matching network -- and a diffusion\nterm that aggregates neighbor information via a graph neural module. This\nreaction-diffusion formulation retains the scalability of deep flow models\nwhile enriching velocity predictions with local context, all at minimal\nadditional computational cost. Operating in the latent space of a pretrained\nvariational autoencoder, GFM consistently improves Fr\\'echet Inception Distance\n(FID) and recall across five image generation benchmarks (LSUN Church, LSUN\nBedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its\neffectiveness as a modular enhancement to existing flow matching architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aGraph Flow Matching (GFM)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6269\u6563\u9879\u6765\u6539\u5584\u6d41\u5339\u914d\u4e2d\u7684\u901f\u5ea6\u9884\u6d4b\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u70b9\u72ec\u7acb\u9884\u6d4b\u901f\u5ea6\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86\u70b9\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u53ef\u80fd\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u3002", "method": "\u5c06\u5b66\u4e60\u7684\u901f\u5ea6\u573a\u5206\u89e3\u4e3a\u53cd\u5e94\u9879\u548c\u6269\u6563\u9879\uff0c\u5e76\u4f7f\u7528\u56fe\u795e\u7ecf\u6a21\u5757\u805a\u5408\u90bb\u5c45\u4fe1\u606f\u3002", "result": "\u5728\u4e94\u4e2a\u56fe\u50cf\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGFM\u63d0\u9ad8\u4e86FID\u548c\u56de\u5fc6\u7387\u3002", "conclusion": "GFM\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u5165\u6269\u6563\u9879\u63d0\u5347\u73b0\u6709\u6d41\u5339\u914d\u67b6\u6784\u7684\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2505.24592", "pdf": "https://arxiv.org/pdf/2505.24592", "abs": "https://arxiv.org/abs/2505.24592", "authors": ["Weebum Yoo", "Sung Whan Yoon"], "title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model robustness indicates a model's capability to generalize well on\nunforeseen distributional shifts, including data corruption, adversarial\nattacks, and domain shifts. Data augmentation is one of the prevalent and\neffective ways to enhance robustness. Despite the great success of\naugmentations in different fields, a general theoretical understanding of their\nefficacy in improving model robustness is lacking. We offer a unified\ntheoretical framework to clarify how augmentations can enhance model robustness\nthrough the lens of loss surface flatness and PAC generalization bound. Our\nwork diverges from prior studies in that our analysis i) broadly encompasses\nmuch of the existing augmentation methods, and ii) is not limited to specific\ntypes of distribution shifts like adversarial attacks. We confirm our theories\nthrough simulations on the existing common corruption and adversarial\nrobustness benchmarks based on the CIFAR and ImageNet datasets, as well as\ndomain generalization benchmarks including PACS and OfficeHome.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u6570\u636e\u589e\u5f3a\u5982\u4f55\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u7406\u8bba\u3002", "motivation": "\u5c3d\u7ba1\u6570\u636e\u589e\u5f3a\u5728\u4e0d\u540c\u9886\u57df\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u7684\u6548\u679c\u7684\u4e00\u822c\u7406\u8bba\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u6790\u635f\u5931\u8868\u9762\u5e73\u5766\u6027\u548cPAC\u6cdb\u5316\u754c\uff0c\u7ed3\u5408CIFAR\u548cImageNet\u7b49\u73b0\u6709\u57fa\u51c6\u4e0a\u7684\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u8be5\u7406\u8bba\u6db5\u76d6\u4e86\u73b0\u6709\u7684\u5927\u91cf\u589e\u5f3a\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e0d\u4ec5\u9650\u4e8e\u7279\u5b9a\u7c7b\u578b\u7684\u5206\u5e03\u504f\u79fb\uff0c\u5982\u5bf9\u6297\u653b\u51fb\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u589e\u5f3a\u6570\u636e\u5982\u4f55\u901a\u8fc7\u635f\u5931\u8868\u9762\u5e73\u5766\u6027\u548cPAC\u6cdb\u5316\u754c\u6765\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24438", "pdf": "https://arxiv.org/pdf/2505.24438", "abs": "https://arxiv.org/abs/2505.24438", "authors": ["Franziska Heeg", "Jonas Sauer", "Petra Mutzel", "Ingo Scholtes"], "title": "Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs", "categories": ["cs.LG"], "comment": null, "summary": "An important characteristic of temporal graphs is how the directed arrow of\ntime influences their causal topology, i.e., which nodes can possibly influence\neach other causally via time-respecting paths. The resulting patterns are often\nneglected by temporal graph neural networks (TGNNs). To formally analyze the\nexpressive power of TGNNs, we lack a generalization of graph isomorphism to\ntemporal graphs that fully captures their causal topology. Addressing this gap,\nwe introduce the notion of consistent event graph isomorphism, which utilizes a\ntime-unfolded representation of time-respecting paths in temporal graphs. We\ncompare this definition with existing notions of temporal graph isomorphisms.\nWe illustrate and highlight the advantages of our approach and develop a\ntemporal generalization of the Weisfeiler-Leman algorithm to heuristically\ndistinguish non-isomorphic temporal graphs. Building on this theoretical\nfoundation, we derive a novel message passing scheme for temporal graph neural\nnetworks that operates on the event graph representation of temporal graphs. An\nexperimental evaluation shows that our approach performs well in a temporal\ngraph classification experiment.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u6355\u6349\u65f6\u95f4\u56fe\u56e0\u679c\u62d3\u6251\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u65b0\u7684\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\u5f80\u5f80\u5ffd\u89c6\u4e86\u65f6\u95f4\u7684\u65b9\u5411\u6027\u5bf9\u56e0\u679c\u62d3\u6251\u7684\u5f71\u54cd\uff0c\u7f3a\u4e4f\u4e00\u79cd\u80fd\u591f\u5b8c\u5168\u6355\u6349\u8fd9\u79cd\u56e0\u679c\u62d3\u6251\u7684\u56fe\u540c\u6784\u63a8\u5e7f\u3002", "method": "\u5f15\u5165\u4e86\u4e8b\u4ef6\u56fe\u540c\u6784\u7684\u4e00\u81f4\u6027\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86\u65f6\u95f4\u7248\u672c\u7684Weisfeiler-Leman\u7b97\u6cd5\u6765\u533a\u5206\u975e\u540c\u6784\u7684\u65f6\u95f4\u56fe\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u65f6\u95f4\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5f3a\u8c03\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5728\u65f6\u95f4\u56fe\u5206\u7c7b\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2505.24623", "pdf": "https://arxiv.org/pdf/2505.24623", "abs": "https://arxiv.org/abs/2505.24623", "authors": ["Wenyuan Li", "Guang Li", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "title": "Hyperbolic Dataset Distillation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "To address the computational and storage challenges posed by large-scale\ndatasets in deep learning, dataset distillation has been proposed to synthesize\na compact dataset that replaces the original while maintaining comparable model\nperformance. Unlike optimization-based approaches that require costly bi-level\noptimization, distribution matching (DM) methods improve efficiency by aligning\nthe distributions of synthetic and original data, thereby eliminating nested\noptimization. DM achieves high computational efficiency and has emerged as a\npromising solution. However, existing DM methods, constrained to Euclidean\nspace, treat data as independent and identically distributed points,\noverlooking complex geometric and hierarchical relationships. To overcome this\nlimitation, we propose a novel hyperbolic dataset distillation method, termed\nHDD. Hyperbolic space, characterized by negative curvature and exponential\nvolume growth with distance, naturally models hierarchical and tree-like\nstructures. HDD embeds features extracted by a shallow network into the Lorentz\nhyperbolic space, where the discrepancy between synthetic and original data is\nmeasured by the hyperbolic (geodesic) distance between their centroids. By\noptimizing this distance, the hierarchical structure is explicitly integrated\ninto the distillation process, guiding synthetic samples to gravitate towards\nthe root-centric regions of the original data distribution while preserving\ntheir underlying geometric characteristics. Furthermore, we find that pruning\nin hyperbolic space requires only 20% of the distilled core set to retain model\nperformance, while significantly improving training stability. Notably, HDD is\nseamlessly compatible with most existing DM methods, and extensive experiments\non different datasets validate its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHDD\u7684\u8d85\u7403\u9762\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u6570\u636e\u5c42\u6b21\u7ed3\u6784\u548c\u51e0\u4f55\u7279\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u5e03\u5339\u914d\u65b9\u6cd5\u53d7\u9650\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u6570\u636e\u51e0\u4f55\u548c\u5c42\u6b21\u5173\u7cfb\u3002", "method": "HDD\u5c06\u4ece\u6d45\u5c42\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u5d4c\u5165\u5230Lorentz\u8d85\u7403\u7a7a\u95f4\u4e2d\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5408\u6210\u6570\u636e\u4e0e\u539f\u59cb\u6570\u636e\u8d28\u5fc3\u4e4b\u95f4\u7684\u6d4b\u5730\u8ddd\u79bb\u6765\u96c6\u6210\u5206\u5c42\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHDD\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "HDD\u662f\u4e00\u79cd\u65b0\u7684\u8d85\u7403\u9762\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u4fdd\u7559\u539f\u59cb\u6570\u636e\u7684\u51e0\u4f55\u548c\u5c42\u6b21\u7ed3\u6784\u7279\u6027\u3002"}}
{"id": "2505.24452", "pdf": "https://arxiv.org/pdf/2505.24452", "abs": "https://arxiv.org/abs/2505.24452", "authors": ["Anda Tang", "Yiming Dong", "Yutao Zeng", "zhou Xun", "Zhouchen Lin"], "title": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training", "categories": ["cs.LG"], "comment": null, "summary": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets.While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations.In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient.In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets.First, we bridge the gap by constructing\na novel training budget-aware optimization framework, which explicitly accounts\nfor the robustness to landscape curvature variations.From this framework, we\nderive the UBA schedule, controlled by a single hyper-parameter $\\varphi$ that\nprovides a trade-off between flexibility and simplicity, eliminating the need\nfor per-network numerical optimization. Moreover, we establish a theoretical\nconnection between $\\varphi$ and the condition number, adding interpretation\nand justification to our approach. Besides, we prove the convergence for\ndifferent values of $\\varphi$.We offer practical guidelines for its selection\nvia theoretical analysis and empirical results.xtensive experimental results\nshow that UBA \\textit{consistently surpasses} the commonly-used schedules\nacross diverse vision and language tasks, spanning network architectures (e.g.,\nResNet, OLMo) and scales, under different training-iteration budgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u65b9\u6cd5UBA\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u548c\u7f51\u7edc\u67b6\u6784\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9884\u7b97\u8fed\u4ee3\u8bad\u7ec3\u7684\u9700\u6c42\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u9884\u7b97\u611f\u77e5\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u4ece\u4e2d\u63a8\u5bfc\u51faUBA\u8c03\u5ea6\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aUBA\u8c03\u5ea6\u65b9\u6cd5\u5728\u4e0d\u540c\u7f51\u7edc\u67b6\u6784\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "UBA\u8c03\u5ea6\u5728\u5404\u79cd\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5e38\u7528\u7684\u8c03\u5ea6\u65b9\u6cd5\u3002"}}
{"id": "2505.24684", "pdf": "https://arxiv.org/pdf/2505.24684", "abs": "https://arxiv.org/abs/2505.24684", "authors": ["Zihao Chen", "Yu Xiang", "Wenyong Wang"], "title": "Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the success in learning semantically meaningful, unsupervised\ndisentangled representations, variational autoencoders (VAEs) and their\nvariants face a fundamental theoretical challenge: substantial evidence\nindicates that unsupervised disentanglement is unattainable without implicit\ninductive bias, yet such bias remains elusive. In this work, we focus on\nexploring the implicit inductive bias that drive disentanglement in VAEs with\nfactorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we\nuncover a crucial implicit inductive bias called disentangling granularity,\nwhich leads to the discovery of an interesting \"V\"-shaped optimal Evidence\nLower Bound (ELBO) trajectory within the parameter space. This finding is\nvalidated through over 100K experiments using factorized VAEs and our newly\nproposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that\nconventional factorized VAEs, constrained by fixed disentangling granularity,\ninherently tend to disentangle low-complexity feature. Whereas, appropriately\ntuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the\nrange of disentangled representations, allowing for the disentanglement of\nhigh-complexity features. Our findings unveil that disentangling granularity as\nan implicit inductive bias in factorized VAEs influence both disentanglement\nperformance and the inference of the ELBO, offering fresh insights into the\ninterpretability and inherent biases of VAEs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u56e0\u5b50\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4e2d\u7684\u9690\u5f0f\u5f52\u7eb3\u504f\u7f6e\uff0c\u63d0\u51fa\u4e86\\b{eta}-STCVAE\u6a21\u578b\u6765\u8c03\u6574\u89e3\u7f20\u7c92\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u89e3\u7f20\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5728\u5b66\u4e60\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u65e0\u76d1\u7763\u89e3\u7f20\u8868\u793a\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46VAE\u53ca\u5176\u53d8\u4f53\u9762\u4e34\u4e00\u4e2a\u7406\u8bba\u6311\u6218\uff1a\u5728\u6ca1\u6709\u9690\u5f0f\u5f52\u7eb3\u504f\u7f6e\u7684\u60c5\u51b5\u4e0b\uff0c\u65e0\u76d1\u7763\u89e3\u7f20\u662f\u65e0\u6cd5\u5b9e\u73b0\u7684\uff0c\u800c\u8fd9\u79cd\u504f\u7f6e\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u9a71\u52a8VAE\u89e3\u7f20\u7684\u9690\u5f0f\u5f52\u7eb3\u504f\u7f6e\u3002", "method": "\u901a\u8fc7\u5206\u6790\\b{eta}-TCVAE\u4e2d\u7684\u603b\u76f8\u5173\u6027\uff0c\u4f5c\u8005\u53d1\u73b0\u4e86\u4e00\u79cd\u5173\u952e\u7684\u9690\u5f0f\u5f52\u7eb3\u504f\u7f6e\uff0c\u79f0\u4e3a\u89e3\u7f20\u7c92\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\\b{eta}-STCVAE\u4ee5\u8c03\u6574\u8fd9\u79cd\u7c92\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f20\u7edf\u7684\u56e0\u5b50\u5316VAE\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u89e3\u7f20\u7c92\u5ea6\uff0c\u503e\u5411\u4e8e\u89e3\u7f20\u4f4e\u590d\u6742\u5ea6\u7279\u5f81\uff1b\u800c\u901a\u8fc7\\b{eta}-STCVAE\u9002\u5f53\u8c03\u8282\u89e3\u7f20\u7c92\u5ea6\u53ef\u4ee5\u62d3\u5bbd\u89e3\u7f20\u8868\u793a\u7684\u8303\u56f4\uff0c\u5b9e\u73b0\u9ad8\u590d\u6742\u5ea6\u7279\u5f81\u7684\u89e3\u7f20\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u6307\u51fa\uff0c\u5206\u89e3\u7c92\u5ea6\u4f5c\u4e3a\u4e00\u79cd\u9690\u5f0f\u5f52\u7eb3\u504f\u7f6e\uff0c\u5728\u56e0\u5b50\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u4e2d\u5f71\u54cd\u4e86\u89e3\u7f20\u6027\u80fd\u548c\u8bc1\u636e\u4e0b\u754c\uff08ELBO\uff09\u7684\u63a8\u65ad\uff0c\u4e3aVAE\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5185\u5728\u504f\u7f6e\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.24461", "pdf": "https://arxiv.org/pdf/2505.24461", "abs": "https://arxiv.org/abs/2505.24461", "authors": ["Jingyao Li", "Senqiao Yang", "Sitong Wu", "Han Shi", "Chuanyang Zheng", "Hong Xu", "Jiaya Jia"], "title": "Logits-Based Finetuning", "categories": ["cs.LG"], "comment": null, "summary": "The core of out-of-distribution (OOD) detection is to learn the\nin-distribution (ID) representation, which is distinguishable from OOD samples.\nPrevious work applied recognition-based methods to learn the ID features, which\ntend to learn shortcuts instead of comprehensive representations. In this work,\nwe find surprisingly that simply using reconstruction-based methods could boost\nthe performance of OOD detection significantly. We deeply explore the main\ncontributors of OOD detection and find that reconstruction-based pretext tasks\nhave the potential to provide a generally applicable and efficacious prior,\nwhich benefits the model in learning intrinsic data distributions of the ID\ndataset. Specifically, we take Masked Image Modeling as a pretext task for our\nOOD detection framework (MOOD). Without bells and whistles, MOOD outperforms\nprevious SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by\n3.0%, and near-distribution OOD detection by 2.1%. It even defeats the\n10-shot-per-class outlier exposure OOD detection, although we do not include\nany OOD samples for our detection. Codes are available at\nhttps://github.com/JulietLJY/MOOD.", "AI": {"tldr": "Diese arbeit stellt mood vor, ein rahmenwerk zur erkennung von ausrei\u00dfern (oob) mithilfe von rekonstruktionsbasierten vorwandtaufgaben, insbesondere masked image modeling. Ohne weitere modifikationen wird eine signifikante verbesserung der erkennungsleistung im vergleich zum bisherigen stand der technik erreicht.", "motivation": "Fr\u00fchere arbeit konzentrierte sich auf erkennungsbasierte methoden zum lernen von ID-merkmalen, die jedoch neigen dazu, stattdessen abk\u00fcrzungen zu lernen anstelle umfassender darstellungen. Daher war eine effektivere methode erforderlich.", "method": "Verwendung von Masked Image Modeling als Vorwandtaufgabe f\u00fcr das OOD-Detektionsframework (MOOD).", "result": "MOOD verbessert die leistung der ein-klassen-oob-erkennung um 5,7 %, die leistung der mehrklassigen oob-erkennung um 3,0 % und die leistung der nahezu verteilten oob-erkennung um 2,1 %. Es schl\u00e4gt sogar die 10-shot-per-klasse outlier-exposure-oob-erkennung.", "conclusion": "MOOD, basierend auf rekonstruktionsbasierten Vorwandtaufgaben, verbessert die Leistung der OOD-Erkennung erheblich und \u00fcbertrifft den bisherigen Stand der Technik."}}
{"id": "2505.24709", "pdf": "https://arxiv.org/pdf/2505.24709", "abs": "https://arxiv.org/abs/2505.24709", "authors": ["Soichiro Nishimori", "Yu-Jie Zhang", "Thanawat Lodkaew", "Masashi Sugiyama"], "title": "On Symmetric Losses for Robust Policy Optimization with Noisy Preferences", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing policies based on human preferences is key to aligning language\nmodels with human intent. This work focuses on reward modeling, a core\ncomponent in reinforcement learning from human feedback (RLHF), and offline\npreference optimization, such as direct preference optimization. Conventional\napproaches typically assume accurate annotations. However, real-world\npreference data often contains noise due to human errors or biases. We propose\na principled framework for robust policy optimization under noisy preferences,\nviewing reward modeling as a classification problem. This allows us to leverage\nsymmetric losses, known for their robustness to label noise in classification,\nleading to our Symmetric Preference Optimization (SymPO) method. We prove that\nsymmetric losses enable successful policy optimization even under noisy labels,\nas the resulting reward remains rank-preserving -- a property sufficient for\npolicy improvement. Experiments on synthetic and real-world tasks demonstrate\nthe effectiveness of SymPO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSymPO\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u8bed\u8a00\u6a21\u578b\u4e2d\u5e26\u6709\u566a\u58f0\u7684\u4eba\u7c7b\u504f\u597d\u6570\u636e\uff0c\u901a\u8fc7\u5c06\u5956\u52b1\u5efa\u6a21\u4f5c\u4e3a\u5206\u7c7b\u95ee\u9898\u5e76\u4f7f\u7528\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u504f\u597d\u6570\u636e\u5f80\u5f80\u7531\u4e8e\u4eba\u7c7b\u9519\u8bef\u6216\u504f\u89c1\u800c\u5305\u542b\u566a\u58f0\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6807\u6ce8\u51c6\u786e\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5bf9\u566a\u58f0\u6570\u636e\u5904\u7406\u7684\u9700\u6c42\u3002", "method": "\u5c06\u5956\u52b1\u5efa\u6a21\u89c6\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u5e76\u5229\u7528\u5bf9\u79f0\u635f\u5931\u51fd\u6570\u6765\u5904\u7406\u6807\u7b7e\u4e2d\u7684\u566a\u58f0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSymPO\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u504f\u597d\u6570\u636e\u5e26\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u7a33\u5065\u7b56\u7565\u4f18\u5316\u7684\u6846\u67b6\uff0c\u5373SymPO\u65b9\u6cd5\u3002"}}
{"id": "2505.24469", "pdf": "https://arxiv.org/pdf/2505.24469", "abs": "https://arxiv.org/abs/2505.24469", "authors": ["Christina Runkel", "Natacha Kuete Meli", "Jovita Lukasik", "Ander Biguri", "Carola-Bibiane Sch\u00f6nlieb", "Michael Moeller"], "title": "Smooth Model Compression without Fine-Tuning", "categories": ["cs.LG"], "comment": null, "summary": "Compressing and pruning large machine learning models has become a critical\nstep towards their deployment in real-world applications. Standard pruning and\ncompression techniques are typically designed without taking the structure of\nthe network's weights into account, limiting their effectiveness. We explore\nthe impact of smooth regularization on neural network training and model\ncompression. By applying nuclear norm, first- and second-order derivative\npenalties of the weights during training, we encourage structured smoothness\nwhile preserving predictive performance on par with non-smooth models. We find\nthat standard pruning methods often perform better when applied to these smooth\nmodels. Building on this observation, we apply a\nSingular-Value-Decomposition-based compression method that exploits the\nunderlying smooth structure and approximates the model's weight tensors by\nsmaller low-rank tensors. Our approach enables state-of-the-art compression\nwithout any fine-tuning - reaching up to $91\\%$ accuracy on a smooth ResNet-18\non CIFAR-10 with $70\\%$ fewer parameters.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5e73\u6ed1\u6b63\u5219\u5316\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u53ca\u538b\u7f29\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\u7684\u9ad8\u6548\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u3002", "motivation": "\u6807\u51c6\u7684\u526a\u679d\u548c\u538b\u7f29\u6280\u672f\u901a\u5e38\u672a\u8003\u8651\u7f51\u7edc\u6743\u91cd\u7684\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u5e73\u6ed1\u6b63\u5219\u5316\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u6a21\u578b\u538b\u7f29\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u538b\u7f29\u7684\u6548\u679c\u3002", "method": "\u5e94\u7528\u6838\u8303\u6570\u3001\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570\u60e9\u7f5a\u4e8e\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\uff0c\u4ee5\u9f13\u52b1\u6743\u91cd\u53c2\u6570\u7684\u7ed3\u6784\u5316\u5e73\u6ed1\u6027\uff1b\u968f\u540e\u4f7f\u7528\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\u7684\u65b9\u6cd5\u5bf9\u6a21\u578b\u6743\u91cd\u5f20\u91cf\u8fdb\u884c\u4f4e\u79e9\u8fd1\u4f3c\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6a21\u578b\u538b\u7f29\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6807\u51c6\u526a\u679d\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u5e73\u6ed1\u6a21\u578b\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u538b\u7f29\u65b9\u6cd5\u80fd\u591f\u5728\u65e0\u9700\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u9ad8\u8fbe70%\u7684\u53c2\u6570\u51cf\u5c11\u548c91%\u7684\u51c6\u786e\u7387\uff08\u5982CIFAR-10\u4e0a\u7684ResNet-18\uff09\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e73\u6ed1\u6b63\u5219\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6838\u8303\u6570\u3001\u6743\u91cd\u7684\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570\u60e9\u7f5a\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u7684\u5e73\u6ed1\u6027\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u8fd9\u4e00\u7279\u6027\uff0c\u91c7\u7528\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u5728\u65e0\u9700\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u538b\u7f29\u6548\u679c\u3002"}}
{"id": "2505.24710", "pdf": "https://arxiv.org/pdf/2505.24710", "abs": "https://arxiv.org/abs/2505.24710", "authors": ["Wei Chen", "Jiahao Zhang", "Haipeng Zhu", "Boyan Xu", "Zhifeng Hao", "Keli Zhang", "Junjian Ye", "Ruichu Cai"], "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by IJCAI 2025", "summary": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Causal-aware LLMs\uff0c\u7ed3\u5408\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u51b3\u7b56\u7684\u80fd\u529b\u3002", "motivation": "\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u63a8\u7406\u80fd\u529b\uff0c\u5728\u9002\u5e94\u65b0\u73af\u5883\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u963b\u788d\u4e86\u5b83\u4eec\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528LLM\u63d0\u53d6\u73af\u5883\u7279\u5b9a\u7684\u56e0\u679c\u5b9e\u4f53\u53ca\u5176\u56e0\u679c\u5173\u7cfb\uff0c\u521d\u59cb\u5316\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff1b\u901a\u8fc7\u5916\u90e8\u53cd\u9988\u66f4\u65b0\u8be5\u6a21\u578b\uff1b\u6700\u540e\u5728\u51b3\u7b56\u9636\u6bb5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5229\u7528\u8fd9\u4e9b\u77e5\u8bc6\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754c\u6e38\u620f\u201cCrafter\u201d\u4e2d22\u4e2a\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "Causal-aware LLMs\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u5230\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u7406\u89e3\u73af\u5883\u5e76\u505a\u51fa\u66f4\u9ad8\u6548\u7684\u51b3\u7b56\u3002"}}
{"id": "2505.24715", "pdf": "https://arxiv.org/pdf/2505.24715", "abs": "https://arxiv.org/abs/2505.24715", "authors": ["Fabio Fehr", "Prabhu Teja Sivaprasad", "Luca Franceschi", "Giovanni Zappella"], "title": "CoRet: Improved Retriever for Code Editing", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ACL 2025", "summary": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoRet\u6a21\u578b\uff0c\u7ed3\u5408\u4ee3\u7801\u8bed\u4e49\u4e0e\u7ed3\u6784\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u7684\u53ec\u56de\u7387\u3002", "motivation": "\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff08\u5982\u5b9e\u73b0\u65b0\u529f\u80fd\u6216\u4fee\u590d\u9519\u8bef\uff09\u68c0\u7d22\u4ee3\u7801\u5b58\u50a8\u5e93\u7684\u76f8\u5173\u90e8\u5206\uff0c\u63d0\u9ad8\u4ee3\u7801\u7f16\u8f91\u4efb\u52a1\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoRet\u7684\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\uff0c\u4ee5\u53ca\u4e00\u4e2a\u4e13\u4e3a\u5b58\u50a8\u5e93\u7ea7\u68c0\u7d22\u8bbe\u8ba1\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728SWE-bench\u548cLong Code Arena\u7684\u9519\u8bef\u5b9a\u4f4d\u6570\u636e\u96c6\u4e0a\uff0cCoRet\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u53ec\u56de\u7387\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002", "conclusion": "CoRet\u901a\u8fc7\u6574\u5408\u4ee3\u7801\u8bed\u4e49\u3001\u5b58\u50a8\u5e93\u7ed3\u6784\u548c\u8c03\u7528\u56fe\u4f9d\u8d56\u6027\uff0c\u5728\u4ee3\u7801\u7f16\u8f91\u4efb\u52a1\u4e2d\u7684\u68c0\u7d22\u53ec\u56de\u7387\u4e0a\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u9ad8\u4e86\u81f3\u5c1115\u4e2a\u767e\u5206\u70b9\u3002"}}
{"id": "2505.24722", "pdf": "https://arxiv.org/pdf/2505.24722", "abs": "https://arxiv.org/abs/2505.24722", "authors": ["Neil He", "Rishabh Anand", "Hiren Madhu", "Ali Maatouk", "Smita Krishnaswamy", "Leandros Tassiulas", "Menglin Yang", "Rex Ying"], "title": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown great success in text modeling tasks\nacross domains. However, natural language exhibits inherent semantic\nhierarchies and nuanced geometric structure, which current LLMs do not capture\ncompletely owing to their reliance on Euclidean operations. Recent studies have\nalso shown that not respecting the geometry of token embeddings leads to\ntraining instabilities and degradation of generative capabilities. These\nfindings suggest that shifting to non-Euclidean geometries can better align\nlanguage models with the underlying geometry of text. We thus propose to\noperate fully in Hyperbolic space, known for its expansive, scale-free, and\nlow-distortion properties. We thus introduce HELM, a family of HypErbolic Large\nLanguage Models, offering a geometric rethinking of the Transformer-based LLM\nthat addresses the representational inflexibility, missing set of necessary\noperations, and poor scalability of existing hyperbolic LMs. We additionally\nintroduce a Mixture-of-Curvature Experts model, HELM-MICE, where each expert\noperates in a distinct curvature space to encode more fine-grained geometric\nstructure from text, as well as a dense model, HELM-D. For HELM-MICE, we\nfurther develop hyperbolic Multi-Head Latent Attention (HMLA) for efficient,\nreduced-KV-cache training and inference. For both models, we develop essential\nhyperbolic equivalents of rotary positional encodings and RMS normalization. We\nare the first to train fully hyperbolic LLMs at billion-parameter scale, and\nevaluate them on well-known benchmarks such as MMLU and ARC, spanning STEM\nproblem-solving, general knowledge, and commonsense reasoning. Our results show\nconsistent gains from our HELM architectures -- up to 4% -- over popular\nEuclidean architectures used in LLaMA and DeepSeek, highlighting the efficacy\nand enhanced reasoning afforded by hyperbolic geometry in large-scale LM\npretraining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u8d85\u53cc\u66f2\u7ebf\u7a7a\u95f4\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578bHELM\uff0c\u901a\u8fc7\u51e0\u4f55\u91cd\u6784\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u8868\u793a\u7075\u6d3b\u6027\u4e0d\u8db3\u3001\u5fc5\u8981\u64cd\u4f5c\u7f3a\u5931\u548c\u53ef\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u6a21\u578b\u7684\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u4f9d\u8d56\u4e8e\u6b27\u51e0\u91cc\u5f97\u8fd0\u7b97\u800c\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u81ea\u7136\u8bed\u8a00\u7684\u8bed\u4e49\u5c42\u6b21\u548c\u7ec6\u5fae\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u5bfc\u81f4\u4e86\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u751f\u6210\u80fd\u529b\u9000\u5316\u3002\u56e0\u6b64\uff0c\u8f6c\u5411\u975e\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u53ef\u4ee5\u66f4\u597d\u5730\u4f7f\u8bed\u8a00\u6a21\u578b\u4e0e\u6587\u672c\u7684\u57fa\u7840\u51e0\u4f55\u5bf9\u9f50\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u91cd\u6784\u7684Transformer\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff0c\u79f0\u4e3aHELM\uff0c\u5e76\u5f15\u5165\u4e86\u6df7\u5408\u66f2\u7387\u4e13\u5bb6\u6a21\u578bHELM-MICE\u4ee5\u53ca\u7a20\u5bc6\u6a21\u578bHELM-D\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u8d85\u53cc\u66f2\u7ebf\u591a\u5934\u6f5c\u5728\u6ce8\u610f\u529b\u673a\u5236\uff08HMLA\uff09\u548c\u5fc5\u8981\u7684\u8d85\u53cc\u66f2\u7ebf\u7b49\u6548\u64cd\u4f5c\u3002", "result": "\u8bba\u6587\u7ed3\u679c\u663e\u793a\uff0cHELM\u67b6\u6784\u5728MMLU\u548cARC\u7b49\u77e5\u540d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e86\u6bd4LLaMA\u548cDeepSeek\u4f7f\u7528\u7684\u6d41\u884c\u6b27\u51e0\u91cc\u5f97\u67b6\u6784\u9ad8\u8fbe4%\u7684\u4e00\u81f4\u6027\u63d0\u5347\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7684\u7ed3\u8bba\u662f\uff0c\u901a\u8fc7\u4f7f\u7528\u5b8c\u5168\u8d85\u53cc\u66f2\u7ebf\u7a7a\u95f4\u4e2d\u7684\u8bed\u8a00\u6a21\u578bHELM\u53ca\u5176\u53d8\u79cdHELM-MICE\u548cHELM-D\uff0c\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u4e2d\u53ef\u4ee5\u83b7\u5f97\u6bd4\u6d41\u884c\u7684\u6b27\u51e0\u91cc\u5f97\u67b6\u6784\u66f4\u597d\u7684\u6548\u679c\u548c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.24498", "pdf": "https://arxiv.org/pdf/2505.24498", "abs": "https://arxiv.org/abs/2505.24498", "authors": ["Andres Fernandez", "Juan Azcarreta", "Cagdas Bilen", "Jesus Monge Alvarez"], "title": "Efficient Neural and Numerical Methods for High-Quality Online Speech Spectrogram Inversion via Gradient Theorem", "categories": ["cs.LG"], "comment": "Accepted at InterSpeech 2025", "summary": "Recent work in online speech spectrogram inversion effectively combines Deep\nLearning with the Gradient Theorem to predict phase derivatives directly from\nmagnitudes. Then, phases are estimated from their derivatives via least\nsquares, resulting in a high quality reconstruction. In this work, we introduce\nthree innovations that drastically reduce computational cost, while maintaining\nhigh quality: Firstly, we introduce a novel neural network architecture with\njust 8k parameters, 30 times smaller than previous state of the art. Secondly,\nincreasing latency by 1 hop size allows us to further halve the cost of the\nneural inference step. Thirdly, we we observe that the least squares problem\nfeatures a tridiagonal matrix and propose a linear-complexity solver for the\nleast squares step that leverages tridiagonality and positive-semidefiniteness,\nachieving a speedup of several orders of magnitude. We release samples online.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5728\u7ebf\u8bed\u97f3\u9891\u8c31\u56fe\u53cd\u6f14\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u68af\u5ea6\u5b9a\u7406\u6765\u76f4\u63a5\u4ece\u5e45\u5ea6\u9884\u6d4b\u76f8\u4f4d\u5bfc\u6570\uff0c\u540c\u65f6\u5f15\u5165\u4e09\u79cd\u521b\u65b0\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u91cd\u5efa\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u7ebf\u8bed\u97f3\u9891\u8c31\u56fe\u53cd\u6f14\u65b9\u6cd5\u5728\u8ba1\u7b97\u6210\u672c\u4e0a\u8f83\u9ad8\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4e14\u4f4e\u5f00\u9500\u7684\u91cd\u5efa\u3002", "method": "\u9996\u5148\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ec5\u5305\u542b8k\u53c2\u6570\u7684\u65b0\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff1b\u5176\u6b21\u901a\u8fc7\u589e\u52a01\u4e2ahop\u5927\u5c0f\u7684\u5ef6\u8fdf\u8fdb\u4e00\u6b65\u964d\u4f4e\u795e\u7ecf\u63a8\u7406\u6b65\u9aa4\u7684\u6210\u672c\uff1b\u6700\u540e\u5229\u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4e2d\u7684\u4e09\u5bf9\u89d2\u77e9\u9635\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u6c42\u89e3\u5668\u3002", "result": "\u63d0\u51fa\u7684\u4e09\u79cd\u521b\u65b0\u6280\u672f\u4f7f\u8ba1\u7b97\u6210\u672c\u5927\u5e45\u4e0b\u964d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002\u5176\u4e2d\u65b0\u795e\u7ecf\u7f51\u7edc\u89c4\u6a21\u4ec5\u4e3a\u5148\u524d\u6280\u672f\u7684\u4e09\u5341\u5206\u4e4b\u4e00\uff0c\u800c\u65b0\u7684\u6c42\u89e3\u5668\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7ea7\u522b\u7684\u52a0\u901f\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7ecf\u5178\u6570\u5b66\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u5728\u4fdd\u8bc1\u9ad8\u8d28\u91cf\u91cd\u5efa\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5728\u7ebf\u8bed\u97f3\u9891\u8c31\u56fe\u53cd\u6f14\u7684\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2505.24760", "pdf": "https://arxiv.org/pdf/2505.24760", "abs": "https://arxiv.org/abs/2505.24760", "authors": ["Zafir Stojanovski", "Oliver Stanley", "Joe Sharratt", "Richard Jones", "Abdulhakeem Adefioye", "Jean Kaddour", "Andreas K\u00f6pf"], "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "For code, see https://github.com/open-thought/reasoning-gym", "summary": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u73af\u5883\u5e93 Reasoning Gym\uff0c\u5b83\u80fd\u751f\u6210\u5927\u91cf\u53ef\u9a8c\u8bc1\u7684\u52a8\u6001\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u5b9e\u73b0\u8fde\u7eed\u96be\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e4b\u524d\u63a8\u7406\u6570\u636e\u96c6\u901a\u5e38\u662f\u56fa\u5b9a\u7684\u3001\u7f3a\u4e4f\u7075\u6d3b\u6027\u7684\u95ee\u9898\uff0c\u5f15\u5165\u4e00\u4e2a\u53ef\u4ee5\u751f\u6210\u52a8\u6001\u8bad\u7ec3\u6570\u636e\u5e76\u652f\u6301\u8fde\u7eed\u8bc4\u4f30\u7684\u5de5\u5177\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3a Reasoning Gym \u7684\u5e93\uff0c\u5305\u542b\u8d85\u8fc7 100 \u4e2a\u6570\u636e\u751f\u6210\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cReasoning Gym \u5728\u63a8\u7406\u6a21\u578b\u7684\u8bc4\u4f30\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "conclusion": "Reasoning Gym \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u73af\u5883\u5e93\uff0c\u80fd\u591f\u751f\u6210\u53ef\u9a8c\u8bc1\u5956\u52b1\u548c\u51e0\u4e4e\u65e0\u9650\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5177\u6709\u53ef\u8c03\u6574\u590d\u6742\u6027\u3002"}}
{"id": "2505.24505", "pdf": "https://arxiv.org/pdf/2505.24505", "abs": "https://arxiv.org/abs/2505.24505", "authors": ["Ignacio Boero", "Santiago Diaz", "Tom\u00e1s V\u00e1zquez", "Enzo Coppes", "Pablo Belzarena", "Federico Larroca"], "title": "Learning to Optimally Dispatch Power: Performance on a Nation-Wide Real-World Dataset", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "The Optimal Reactive Power Dispatch (ORPD) problem plays a crucial role in\npower system operations, ensuring voltage stability and minimizing power\nlosses. Recent advances in machine learning, particularly within the ``learning\nto optimize'' framework, have enabled fast and efficient approximations of ORPD\nsolutions, typically by training models on precomputed optimization results.\nWhile these approaches have demonstrated promising performance on synthetic\ndatasets, their effectiveness under real-world grid conditions remains largely\nunexplored. This paper makes two key contributions. First, we introduce a\npublicly available power system dataset that includes both the structural\ncharacteristics of Uruguay's electrical grid and nearly two years of real-world\noperational data, encompassing actual demand and generation profiles. Given\nUruguay's high penetration of renewable energy, the ORPD problem has become the\nprimary optimization challenge in its power network. Second, we assess the\nimpact of real-world data on learning-based ORPD solutions, revealing a\nsignificant increase in prediction errors when transitioning from synthetic to\nactual demand and generation inputs. Our results highlight the limitations of\nexisting models in learning under the complex statistical properties of real\ngrid conditions and emphasize the need for more expressive architectures. By\nproviding this dataset, we aim to facilitate further research into robust\nlearning-based optimization techniques for power system management.", "AI": {"tldr": "\u672c\u8bba\u6587\u8ba8\u8bba\u4e86\u5728\u7535\u529b\u7cfb\u7edf\u64cd\u4f5c\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u6700\u4f18\u65e0\u529f\u529f\u7387\u8c03\u5ea6\uff08ORPD\uff09\u95ee\u9898\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5305\u542b\u4e4c\u62c9\u572d\u7535\u7f51\u7ed3\u6784\u7279\u5f81\u548c\u771f\u5b9e\u8fd0\u884c\u6570\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u5b9e\u6570\u636e\u5bf9\u57fa\u4e8e\u5b66\u4e60\u7684ORPD\u89e3\u51b3\u65b9\u6848\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5df2\u5728ORPD\u95ee\u9898\u4e0a\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u7535\u7f51\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u5b9e\u7528\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5305\u542b\u4e4c\u62c9\u572d\u7535\u7f51\u7ed3\u6784\u7279\u5f81\u548c\u8fd1\u4e24\u5e74\u771f\u5b9e\u8fd0\u884c\u6570\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u4e0e\u5b9e\u9645\u6570\u636e\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u57fa\u4e8e\u5b66\u4e60\u7684ORPD\u89e3\u51b3\u65b9\u6848\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4ece\u5408\u6210\u6570\u636e\u8fc7\u6e21\u5230\u5b9e\u9645\u9700\u6c42\u548c\u53d1\u7535\u8f93\u5165\u65f6\uff0c\u9884\u6d4b\u8bef\u5dee\u663e\u8457\u589e\u52a0\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u5b66\u4e60\u590d\u6742\u7edf\u8ba1\u7279\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u4e3a\u4e86\u63d0\u9ad8ORPD\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u9700\u8981\u66f4\u590d\u6742\u7684\u67b6\u6784\u6765\u5e94\u5bf9\u771f\u5b9e\u7535\u7f51\u6761\u4ef6\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u8be5\u6570\u636e\u96c6\u5c06\u6709\u52a9\u4e8e\u63a8\u52a8\u57fa\u4e8e\u5b66\u4e60\u7684\u7535\u529b\u7cfb\u7edf\u7ba1\u7406\u4f18\u5316\u6280\u672f\u7684\u7814\u7a76\u3002"}}
{"id": "2505.24791", "pdf": "https://arxiv.org/pdf/2505.24791", "abs": "https://arxiv.org/abs/2505.24791", "authors": ["Jiaru Zhang", "Juanwu Lu", "Ziran Wang", "Ruqi Zhang"], "title": "Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Normalizing flows are promising generative models with advantages such as\ntheoretical rigor, analytical log-likelihood computation, and end-to-end\ntraining. However, the architectural constraints to ensure invertibility and\ntractable Jacobian computation limit their expressive power and practical\nusability. Recent advancements utilize autoregressive modeling, significantly\nenhancing expressive power and generation quality. However, such sequential\nmodeling inherently restricts parallel computation during inference, leading to\nslow generation that impedes practical deployment. In this paper, we first\nidentify that strict sequential dependency in inference is unnecessary to\ngenerate high-quality samples. We observe that patches in sequential modeling\ncan also be approximated without strictly conditioning on all preceding\npatches. Moreover, the models tend to exhibit low dependency redundancy in the\ninitial layer and higher redundancy in subsequent layers. Leveraging these\nobservations, we propose a selective Jacobi decoding (SeJD) strategy that\naccelerates autoregressive inference through parallel iterative optimization.\nTheoretical analyses demonstrate the method's superlinear convergence rate and\nguarantee that the number of iterations required is no greater than the\noriginal sequential approach. Empirical evaluations across multiple datasets\nvalidate the generality and effectiveness of our acceleration technique.\nExperiments demonstrate substantial speed improvements up to 4.7 times faster\ninference while keeping the generation quality and fidelity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u9009\u62e9\u6027\u96c5\u53ef\u6bd4\u89e3\u7801\u7b56\u7565\uff0c\u52a0\u901f\u81ea\u56de\u5f52\u63a8\u7406\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u800c\u4e0d\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u5f52\u4e00\u5316\u6d41\u6a21\u578b\u5728\u67b6\u6784\u7ea6\u675f\u4e0b\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u4ee5\u53ca\u81ea\u56de\u5f52\u5efa\u6a21\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u5176\u5b9e\u7528\u6027\u548c\u90e8\u7f72\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9009\u62e9\u6027\u96c5\u53ef\u6bd4\u89e3\u7801\uff08SeJD\uff09\u7b56\u7565\uff0c\u901a\u8fc7\u5e76\u884c\u8fed\u4ee3\u4f18\u5316\u52a0\u901f\u81ea\u56de\u5f52\u63a8\u7406\uff0c\u5e76\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u52a0\u901f\u6280\u672f\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e86\u6700\u9ad8\u8fbe4.7\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u751f\u6210\u8d28\u91cf\u548c\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u4e25\u683c\u987a\u5e8f\u4f9d\u8d56\u5728\u63a8\u7406\u4e2d\u5bf9\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\u5e76\u4e0d\u5fc5\u8981\uff0c\u5e76\u4e14\u901a\u8fc7\u9009\u62e9\u6027\u96c5\u53ef\u6bd4\u89e3\u7801\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u4e0d\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u52a0\u901f\u81ea\u56de\u5f52\u63a8\u7406\u3002"}}
{"id": "2505.24823", "pdf": "https://arxiv.org/pdf/2505.24823", "abs": "https://arxiv.org/abs/2505.24823", "authors": ["Yinggan Xu", "Yue Liu", "Zhiqiang Gao", "Changnan Peng", "Di Luo"], "title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.", "AI": {"tldr": "PhySense \u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7c7b\u4f3c\u4eba\u7c7b\u4e13\u5bb6\u7684\u57fa\u4e8e\u7269\u7406\u539f\u5219\u7684\u9ad8\u6548\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u96be\u4ee5\u6a21\u4eff\u4eba\u7c7b\u4e13\u5bb6\u57fa\u4e8e\u6838\u5fc3\u7269\u7406\u539f\u7406\u7684\u7b80\u6d01\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8e\u7269\u7406\u539f\u7406\u7684\u63a8\u7406\u57fa\u51c6 PhySense\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684 LLMs \u7684\u8868\u73b0\u548c\u63d0\u793a\u7c7b\u578b\u3002", "result": "\u591a\u4e2a\u5148\u8fdb LLMs \u548c\u63d0\u793a\u7c7b\u578b\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5b83\u4eec\u666e\u904d\u65e0\u6cd5\u4e0e\u4e13\u5bb6\u7684\u63a8\u7406\u8def\u5f84\u4fdd\u6301\u4e00\u81f4\uff0c\u63ed\u793a\u4e86\u5176\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u6838\u5fc3\u7269\u7406\u539f\u7406\u7684\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\u3002"}}
{"id": "2505.24513", "pdf": "https://arxiv.org/pdf/2505.24513", "abs": "https://arxiv.org/abs/2505.24513", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "title": "Airborne Neural Network", "categories": ["cs.LG", "cs.NE"], "comment": "11 pages, 3 figures", "summary": "Deep Learning, driven by neural networks, has led to groundbreaking\nadvancements in Artificial Intelligence by enabling systems to learn and adapt\nlike the human brain. These models have achieved remarkable results,\nparticularly in data-intensive domains, supported by massive computational\ninfrastructure. However, deploying such systems in Aerospace, where real time\ndata processing and ultra low latency are critical, remains a challenge due to\ninfrastructure limitations. This paper proposes a novel concept: the Airborne\nNeural Network a distributed architecture where multiple airborne devices each\nhost a subset of neural network neurons. These devices compute collaboratively,\nguided by an airborne network controller and layer specific controllers,\nenabling real-time learning and inference during flight. This approach has the\npotential to revolutionize Aerospace applications, including airborne air\ntraffic control, real-time weather and geographical predictions, and dynamic\ngeospatial data processing. By enabling large-scale neural network operations\nin airborne environments, this work lays the foundation for the next generation\nof AI powered Aerospace systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5c06\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u90e8\u7f72\u5230\u822a\u7a7a\u822a\u5929\u9886\u57df\u7684\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u57fa\u7840\u8bbe\u65bd\u7684\u9650\u5236\uff0c\u5728\u9700\u8981\u5b9e\u65f6\u6570\u636e\u5904\u7406\u548c\u8d85\u4f4e\u5ef6\u8fdf\u7684\u822a\u7a7a\u822a\u5929\u9886\u57df\u90e8\u7f72\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u4ecd\u7136\u662f\u4e00\u9879\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u67b6\u6784\uff0c\u591a\u4e2a\u7a7a\u4e2d\u8bbe\u5907\u5404\u81ea\u6258\u7ba1\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u90e8\u5206\u795e\u7ecf\u5143\uff0c\u5e76\u5728\u7a7a\u4e2d\u7f51\u7edc\u63a7\u5236\u5668\u548c\u7279\u5b9a\u5c42\u63a7\u5236\u5668\u7684\u6307\u5bfc\u4e0b\u534f\u540c\u8ba1\u7b97\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u98de\u884c\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u5b66\u4e60\u548c\u63a8\u7406\uff0c\u5e76\u6709\u53ef\u80fd\u5f7b\u5e95\u6539\u53d8\u5305\u62ec\u7a7a\u4e2d\u4ea4\u901a\u63a7\u5236\u3001\u5b9e\u65f6\u5929\u6c14\u548c\u5730\u7406\u9884\u6d4b\u4ee5\u53ca\u52a8\u6001\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5904\u7406\u5728\u5185\u7684\u822a\u7a7a\u822a\u5929\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7a7a\u4e2d\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u6982\u5ff5\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u822a\u7a7a\u822a\u5929\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24850", "pdf": "https://arxiv.org/pdf/2505.24850", "abs": "https://arxiv.org/abs/2505.24850", "authors": ["Shuyao Xu", "Cheng Peng", "Jiangxuan Long", "Weidi Xu", "Wei Chu", "Yuan Qi"], "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "27 pages, 10 figures. Code available at\n  https://github.com/Tim-Siu/reinforcement-distillation", "summary": "Recent advances in model distillation demonstrate that data from advanced\nreasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer\ncomplex reasoning abilities to smaller, efficient student models. However,\nstandard practices employ rejection sampling, discarding incorrect reasoning\nexamples -- valuable, yet often underutilized data. This paper addresses the\ncritical question: How can both positive and negative distilled reasoning\ntraces be effectively leveraged to maximize LLM reasoning performance in an\noffline setting? To this end, We propose Reinforcement Distillation (REDI), a\ntwo-stage framework. Stage 1 learns from positive traces via Supervised\nFine-Tuning (SFT). Stage 2 further refines the model using both positive and\nnegative traces through our proposed REDI objective. This novel objective is a\nsimple, reference-free loss function that outperforms established methods like\nDPO and SimPO in this distillation context. Our empirical evaluations\ndemonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT\ncombined with DPO/SimPO on mathematical reasoning tasks. Notably, the\nQwen-REDI-1.5B model, post-trained on just 131k positive and negative examples\nfrom the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1).\nIts performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a\nmodel post-trained on 800k proprietary data) across various mathematical\nreasoning benchmarks, establishing a new state-of-the-art for 1.5B models\npost-trained offline with openly available data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86REDI\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6b63\u5411\u548c\u8d1f\u5411\u63a8\u7406\u8f68\u8ff9\u663e\u8457\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u57281.5B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u578b\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u62d2\u7edd\u91c7\u6837\u4e22\u5f03\u9519\u8bef\u7684\u63a8\u7406\u793a\u4f8b\uff0c\u800c\u8fd9\u4e9b\u6570\u636e\u53ef\u80fd\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u6765\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReinforcement Distillation (REDI)\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u5b66\u4e60\u6b63\u5411\u63a8\u7406\u8f68\u8ff9\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u3001\u65e0\u9700\u53c2\u8003\u7684\u635f\u5931\u51fd\u6570\u7ed3\u5408\u6b63\u5411\u548c\u8d1f\u5411\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u4f18\u5316\u3002", "result": "Qwen-REDI-1.5B\u6a21\u578b\u5728MATH-500\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8683.1%\u7684\u51c6\u786e\u7387\uff08pass@1\uff09\uff0c\u5176\u6027\u80fd\u4e0e\u751a\u81f3\u8d85\u8fc7\u57fa\u4e8e80\u4e07\u79c1\u6709\u6570\u636e\u8bad\u7ec3\u7684DeepSeek-R1-Distill-Qwen-1.5B\u6a21\u578b\u3002", "conclusion": "REDI\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u6b63\u5411\u548c\u8d1f\u5411\u63a8\u7406\u8f68\u8ff9\uff0c\u63d0\u9ad8\u5c0f\u578b\u6a21\u578b\u5728\u79bb\u7ebf\u8bbe\u7f6e\u4e0b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5e76\u57281.5B\u6a21\u578b\u4e0a\u4f7f\u7528\u516c\u5f00\u6570\u636e\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002"}}
{"id": "2505.24531", "pdf": "https://arxiv.org/pdf/2505.24531", "abs": "https://arxiv.org/abs/2505.24531", "authors": ["Sagar Ghosh", "Kushal Bose", "Swagatam Das"], "title": "Transformers Are Universally Consistent", "categories": ["cs.LG"], "comment": null, "summary": "Despite their central role in the success of foundational models and\nlarge-scale language modeling, the theoretical foundations governing the\noperation of Transformers remain only partially understood. Contemporary\nresearch has largely focused on their representational capacity for language\ncomprehension and their prowess in in-context learning, frequently under\nidealized assumptions such as linearized attention mechanisms. Initially\nconceived to model sequence-to-sequence transformations, a fundamental and\nunresolved question is whether Transformers can robustly perform functional\nregression over sequences of input tokens. This question assumes heightened\nimportance given the inherently non-Euclidean geometry underlying real-world\ndata distributions. In this work, we establish that Transformers equipped with\nsoftmax-based nonlinear attention are uniformly consistent when tasked with\nexecuting Ordinary Least Squares (OLS) regression, provided both the inputs and\noutputs are embedded in hyperbolic space. We derive deterministic upper bounds\non the empirical error which, in the asymptotic regime, decay at a provable\nrate of $\\mathcal{O}(t^{-1/2d})$, where $t$ denotes the number of input tokens\nand $d$ the embedding dimensionality. Notably, our analysis subsumes the\nEuclidean setting as a special case, recovering analogous convergence\nguarantees parameterized by the intrinsic dimensionality of the data manifold.\nThese theoretical insights are corroborated through empirical evaluations on\nreal-world datasets involving both continuous and categorical response\nvariables.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u4f7f\u7528Transformers\u6267\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u7684\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1Transformers\u5728\u57fa\u7840\u6a21\u578b\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u5efa\u6a21\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u4ecd\u4e0d\u5b8c\u5584\uff0c\u5c24\u5176\u662f\u5176\u5728\u5e8f\u5217\u51fd\u6570\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u7a33\u5065\u6027\u5c1a\u672a\u89e3\u51b3\u3002\u8003\u8651\u5230\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u5206\u5e03\u7684\u975e\u6b27\u51e0\u4f55\u7279\u6027\uff0c\u7814\u7a76Transformers\u662f\u5426\u80fd\u591f\u7a33\u5065\u5730\u6267\u884c\u5e8f\u5217\u51fd\u6570\u56de\u5f52\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8bba\u6587\u7684\u65b9\u6cd5\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u63a8\u5bfc\u51fa\u7ecf\u9a8c\u8bef\u5dee\u7684\u786e\u5b9a\u6027\u4e0a\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8003\u8651\u4e86\u53cc\u66f2\u7a7a\u95f4\u548c\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u60c5\u51b5\u3002", "result": "\u8bba\u6587\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u8f93\u5165\u548c\u8f93\u51fa\u5d4c\u5165\u5230\u53cc\u66f2\u7a7a\u95f4\u65f6\uff0cTransformers\u53ef\u4ee5\u5747\u5300\u4e00\u81f4\u5730\u6267\u884cOLS\u56de\u5f52\uff0c\u5e76\u7ed9\u51fa\u4e86\u8bef\u5dee\u4e0a\u754c\u7684\u6e10\u8fd1\u8870\u51cf\u901f\u7387$O(t^{-1/2d})$\u3002\u6b64\u5916\uff0c\u5c06\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4f5c\u4e3a\u7279\u6b8a\u60c5\u51b5\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5e26\u6709softmax\u975e\u7ebf\u6027\u6ce8\u610f\u529b\u7684Transformer\u5728\u8f93\u5165\u548c\u8f93\u51fa\u5d4c\u5165\u5230\u53cc\u66f2\u7a7a\u95f4\u65f6\uff0c\u6267\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u662f\u5747\u5300\u4e00\u81f4\u7684\u3002\u5206\u6790\u5305\u62ec\u4e86\u5bf9\u7ecf\u9a8c\u8bef\u5dee\u7684\u786e\u5b9a\u6027\u4e0a\u754c\u4ee5\u53ca\u5728\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2505.24534", "pdf": "https://arxiv.org/pdf/2505.24534", "abs": "https://arxiv.org/abs/2505.24534", "authors": ["Florian Frantzen", "Michael T. Schaub"], "title": "HLSAD: Hodge Laplacian-based Simplicial Anomaly Detection", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted for KDD 2025", "summary": "In this paper, we propose HLSAD, a novel method for detecting anomalies in\ntime-evolving simplicial complexes. While traditional graph anomaly detection\ntechniques have been extensively studied, they often fail to capture changes in\nhigher-order interactions that are crucial for identifying complex structural\nanomalies. These higher-order interactions can arise either directly from the\nunderlying data itself or through graph lifting techniques. Our approach\nleverages the spectral properties of Hodge Laplacians of simplicial complexes\nto effectively model multi-way interactions among data points. By incorporating\nhigher-dimensional simplicial structures into our method, our method enhances\nboth detection accuracy and computational efficiency. Through comprehensive\nexperiments on both synthetic and real-world datasets, we demonstrate that our\napproach outperforms existing graph methods in detecting both events and change\npoints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHLSAD\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u65f6\u95f4\u6f14\u53d8\u7684\u5355\u7eaf\u590d\u5f62\u4e2d\u7684\u5f02\u5e38\uff0c\u901a\u8fc7\u5229\u7528Hodge\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u7684\u8c31\u7279\u6027\u6765\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fe\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u96be\u4ee5\u6355\u6349\u5bf9\u4e8e\u8bc6\u522b\u590d\u6742\u7ed3\u6784\u5f02\u5e38\u81f3\u5173\u91cd\u8981\u7684\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u9ad8\u9636\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5355\u7eaf\u590d\u5f62\u7684Hodge\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u8c31\u7279\u6027\u6765\u5efa\u6a21\u6570\u636e\u70b9\u4e4b\u95f4\u7684\u591a\u4f53\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u7ed3\u5408\u9ad8\u7ef4\u5355\u7eaf\u7ed3\u6784\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cHLSAD\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u56fe\u65b9\u6cd5\uff0c\u5728\u4e8b\u4ef6\u548c\u53d8\u5316\u70b9\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "HLSAD\u65b9\u6cd5\u5728\u68c0\u6d4b\u65f6\u95f4\u6f14\u53d8\u7684\u5355\u7eaf\u590d\u5f62\u4e2d\u7684\u5f02\u5e38\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u56fe\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u4e5f\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2505.24578", "pdf": "https://arxiv.org/pdf/2505.24578", "abs": "https://arxiv.org/abs/2505.24578", "authors": ["Abhishek Chandra", "Taniya Kapoor", "Mitrofan Curti", "Koen Tiels", "Elena A. Lomonova"], "title": "Neuro-Symbolic Operator for Interpretable and Generalizable Characterization of Complex Piezoelectric Systems", "categories": ["cs.LG"], "comment": null, "summary": "Complex piezoelectric systems are foundational in industrial applications.\nTheir performance, however, is challenged by the nonlinear voltage-displacement\nhysteretic relationships. Efficient characterization methods are, therefore,\nessential for reliable design, monitoring, and maintenance. Recently proposed\nneural operator methods serve as surrogates for system characterization but\nface two pressing issues: interpretability and generalizability.\nState-of-the-art (SOTA) neural operators are black-boxes, providing little\ninsight into the learned operator. Additionally, generalizing them to novel\nvoltages and predicting displacement profiles beyond the training domain is\nchallenging, limiting their practical use. To address these limitations, this\npaper proposes a neuro-symbolic operator (NSO) framework that derives the\nanalytical operators governing hysteretic relationships. NSO first learns a\nFourier neural operator mapping voltage fields to displacement profiles,\nfollowed by a library-based sparse model discovery method, generating white-box\nparsimonious models governing the underlying hysteresis. These models enable\naccurate and interpretable prediction of displacement profiles across varying\nand out-of-distribution voltage fields, facilitating generalizability. The\npotential of NSO is demonstrated by accurately predicting voltage-displacement\nhysteresis, including butterfly-shaped relationships. Moreover, NSO predicts\ndisplacement profiles even for noisy and low-fidelity voltage data, emphasizing\nits robustness. The results highlight the advantages of NSO compared to SOTA\nneural operators and model discovery methods on several evaluation metrics.\nConsequently, NSO contributes to characterizing complex piezoelectric systems\nwhile improving the interpretability and generalizability of neural operators,\nessential for design, monitoring, maintenance, and other real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u7b97\u5b50\uff08NSO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u4e0e\u7a00\u758f\u6a21\u578b\u53d1\u73b0\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u538b\u7535\u7cfb\u7edf\u4e2d\u7535\u538b-\u4f4d\u79fb\u6ede\u56de\u5173\u7cfb\u5efa\u6a21\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u590d\u6742\u538b\u7535\u7cfb\u7edf\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u9650\u4e8e\u7535\u538b-\u4f4d\u79fb\u6ede\u56de\u5173\u7cfb\u7684\u975e\u7ebf\u6027\uff0c\u73b0\u6709\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u7b97\u5b50\uff08NSO\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u4e0e\u57fa\u4e8e\u5e93\u7684\u7a00\u758f\u6a21\u578b\u53d1\u73b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a8\u5bfc\u63cf\u8ff0\u6ede\u540e\u5173\u7cfb\u7684\u89e3\u6790\u7b97\u5b50\u3002", "result": "NSO\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u4e0d\u540c\u548c\u5206\u5e03\u5916\u7535\u538b\u573a\u7684\u4f4d\u79fb\u66f2\u7ebf\uff0c\u5305\u62ec\u8774\u8776\u5f62\u72b6\u7684\u6ede\u56de\u5173\u7cfb\uff0c\u5e76\u4e14\u5bf9\u566a\u58f0\u548c\u4f4e\u4fdd\u771f\u5ea6\u6570\u636e\u4e5f\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "NSO\u76f8\u6bd4\u73b0\u6709\u7684\u795e\u7ecf\u7b97\u5b50\u548c\u6a21\u578b\u53d1\u73b0\u65b9\u6cd5\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u4e3a\u8bbe\u8ba1\u3001\u76d1\u6d4b\u548c\u7ef4\u62a4\u7b49\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2505.24579", "pdf": "https://arxiv.org/pdf/2505.24579", "abs": "https://arxiv.org/abs/2505.24579", "authors": ["Chaoyu Liu", "Yangming Li", "Zhongying Deng", "Chris Budd", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Conservation-preserved Fourier Neural Operator through Adaptive Correction", "categories": ["cs.LG"], "comment": null, "summary": "Fourier Neural Operators (FNOs) have recently emerged as a promising and\nefficient approach for learning the numerical solutions to partial differential\nequations (PDEs) from data. However, standard FNO often fails to preserve key\nconservation laws, such as mass conservation, momentum conservation, norm\nconservation, etc., which are crucial for accurately modeling physical systems.\nExisting methods for incorporating these conservation laws into Fourier neural\noperators are achieved by designing related loss function or incorporating\npost-processing method at the training time. None of them can both exactly and\nadaptively correct the outputs to satisfy conservation laws, and our\nexperiments show that these methods can lead to inferior performance while\npreserving conservation laws. In this work, we propose a novel adaptive\ncorrection approach to ensure the conservation of fundamental quantities. Our\nmethod introduces a learnable matrix to adaptively adjust the solution to\nsatisfy the conservation law during training. It ensures that the outputs\nexactly satisfy the goal conservation law and allow for more flexibility and\nadaptivity for the model to correct the outputs. We theoretically show that\napplying our adaptive correction to an unconstrained FNO yields a solution with\ndata loss no worse than that of the best conservation-satisfying FNO. We\ncompare our approach with existing methods on a range of representative PDEs.\nExperiment results show that our method consistently outperform other methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u4fee\u6b63\u65b9\u6cd5\uff0c\u4f7f\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u80fd\u591f\u7cbe\u786e\u6ee1\u8db3\u7269\u7406\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u5728\u591a\u79cd\u504f\u5fae\u5206\u65b9\u7a0b\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "motivation": "\u6807\u51c6FNO\u5728\u5efa\u6a21\u7269\u7406\u7cfb\u7edf\u65f6\u65e0\u6cd5\u4fdd\u6301\u8d28\u91cf\u3001\u52a8\u91cf\u548c\u8303\u6570\u7b49\u5173\u952e\u5b88\u6052\u5b9a\u5f8b\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u7cbe\u786e\u4e14\u81ea\u9002\u5e94\u5730\u4fee\u6b63\u8f93\u51fa\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u5b88\u6052\u5b9a\u5f8b\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u53ef\u5b66\u4e60\u77e9\u9635\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u8c03\u6574\u89e3\u4ee5\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u8be5\u65b9\u6cd5\u7684\u6570\u636e\u635f\u5931\u4e0d\u52a3\u4e8e\u6700\u4f73\u6ee1\u8db3\u5b88\u6052\u6761\u4ef6\u7684FNO\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u5b88\u6052\u5b9a\u5f8b\u7684\u540c\u65f6\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u4fee\u6b63\u65b9\u6cd5\uff0c\u786e\u4fdd\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNO\uff09\u5728\u5b66\u4e60\u504f\u5fae\u5206\u65b9\u7a0b\u6570\u503c\u89e3\u65f6\u80fd\u591f\u51c6\u786e\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.24603", "pdf": "https://arxiv.org/pdf/2505.24603", "abs": "https://arxiv.org/abs/2505.24603", "authors": ["Omri Lev", "Vishwak Srinivasan", "Moshe Shenfeld", "Katrina Ligett", "Ayush Sekhari", "Ashia C. Wilson"], "title": "The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches", "categories": ["cs.LG"], "comment": null, "summary": "Gaussian sketching, which consists of pre-multiplying the data with a random\nGaussian matrix, is a widely used technique for multiple problems in data\nscience and machine learning, with applications spanning computationally\nefficient optimization, coded computing, and federated learning. This operation\nalso provides differential privacy guarantees due to its inherent randomness.\nIn this work, we revisit this operation through the lens of Renyi Differential\nPrivacy (RDP), providing a refined privacy analysis that yields significantly\ntighter bounds than prior results. We then demonstrate how this improved\nanalysis leads to performance improvement in different linear regression\nsettings, establishing theoretical utility guarantees. Empirically, our methods\nimprove performance across multiple datasets and, in several cases, reduce\nruntime.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u8349\u56fe\u6280\u672f\u5728\u745e\u4e3d\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u66f4\u7cbe\u786e\u7684\u9690\u79c1\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u9ad8\u65af\u8349\u56fe\u6280\u672f\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u4f46\u5176\u5728\u5dee\u5206\u9690\u79c1\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\u3002", "method": "\u901a\u8fc7\u745e\u4e3d\u5dee\u5206\u9690\u79c1\u7684\u89c6\u89d2\u5bf9\u9ad8\u65af\u8349\u56fe\u6280\u672f\u8fdb\u884c\u9690\u79c1\u5206\u6790\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u9690\u79c1\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u9ad8\u65af\u8349\u56fe\u6280\u672f\u5728\u745e\u4e3d\u5dee\u5206\u9690\u79c1\u5206\u6790\u4e0b\u80fd\u63d0\u5347\u7ebf\u6027\u56de\u5f52\u6027\u80fd\uff0c\u5e76\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u3002"}}
{"id": "2505.24612", "pdf": "https://arxiv.org/pdf/2505.24612", "abs": "https://arxiv.org/abs/2505.24612", "authors": ["Sujoy Chatterjee", "Everton Romanzini Colombo", "Marcos Medeiros Raimundo"], "title": "Multi-criteria Rank-based Aggregation for Explainable AI", "categories": ["cs.LG"], "comment": "Accepted at the 2025 International Joint Conference on Neural\n  Networks (IJCNN)", "summary": "Explainability is crucial for improving the transparency of black-box machine\nlearning models. With the advancement of explanation methods such as LIME and\nSHAP, various XAI performance metrics have been developed to evaluate the\nquality of explanations. However, different explainers can provide contrasting\nexplanations for the same prediction, introducing trade-offs across conflicting\nquality metrics. Although available aggregation approaches improve robustness,\nreducing explanations' variability, very limited research employed a\nmulti-criteria decision-making approach. To address this gap, this paper\nintroduces a multi-criteria rank-based weighted aggregation method that\nbalances multiple quality metrics simultaneously to produce an ensemble of\nexplanation models. Furthermore, we propose rank-based versions of existing XAI\nmetrics (complexity, faithfulness and stability) to better evaluate ranked\nfeature importance explanations. Extensive experiments on publicly available\ndatasets demonstrate the robustness of the proposed model across these metrics.\nComparative analyses of various multi-criteria decision-making and rank\naggregation algorithms showed that TOPSIS and WSUM are the best candidates for\nthis use case.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u6765\u4f18\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u89e3\u91ca\u7684\u8d28\u91cf\u8bc4\u4f30\u548c\u805a\u5408\uff0c\u6709\u6548\u5e73\u8861\u591a\u4e2a\u51b2\u7a81\u6307\u6807\u5e76\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e0d\u540c\u89e3\u91ca\u65b9\u6cd5\u5bf9\u540c\u4e00\u9884\u6d4b\u53ef\u80fd\u63d0\u4f9b\u76f8\u4e92\u77db\u76fe\u7684\u89e3\u91ca\u4ee5\u53ca\u591a\u8d28\u91cf\u6307\u6807\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u7684\u95ee\u9898\uff0c\u9700\u8981\u91c7\u7528\u66f4\u6709\u6548\u7684\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u6392\u540d\u7684\u591a\u51c6\u5219\u51b3\u7b56\u52a0\u6743\u805a\u5408\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86XAI\u6307\u6807\uff08\u590d\u6742\u5ea6\u3001\u771f\u5b9e\u6027\u548c\u7a33\u5b9a\u6027\uff09\u7684\u6392\u540d\u7248\u672c\u7528\u4e8e\u66f4\u597d\u5730\u8bc4\u4f30\u7279\u5f81\u91cd\u8981\u6027\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u6bd4\u8f83\u5206\u6790\u663e\u793aTOPSIS\u548cWSUM\u662f\u6700\u4f73\u7684\u591a\u51c6\u5219\u51b3\u7b56\u548c\u6392\u540d\u805a\u5408\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u51c6\u5219\u51b3\u7b56\u548c\u6392\u540d\u7684\u52a0\u6743\u805a\u5408\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u5728\u5e73\u8861\u591a\u4e2a\u8d28\u91cf\u6307\u6807\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u8bc1\u660e\u4e86TOPSIS\u548cWSUM\u662f\u9002\u7528\u4e8e\u6b64\u7c7b\u4efb\u52a1\u7684\u6700\u4f73\u7b97\u6cd5\u3002"}}
{"id": "2505.24627", "pdf": "https://arxiv.org/pdf/2505.24627", "abs": "https://arxiv.org/abs/2505.24627", "authors": ["Fu Luo", "Yaoxin Wu", "Zhi Zheng", "Zhenkun Wang"], "title": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees", "categories": ["cs.LG"], "comment": null, "summary": "Recent neural combinatorial optimization (NCO) methods have shown promising\nproblem-solving ability without requiring domain-specific expertise. Most\nexisting NCO methods use training and testing data with a fixed constraint\nvalue and lack research on the effect of constraint tightness on the\nperformance of NCO methods. This paper takes the capacity-constrained vehicle\nrouting problem (CVRP) as an example to empirically analyze the NCO performance\nunder different tightness degrees of the capacity constraint. Our analysis\nreveals that existing NCO methods overfit the capacity constraint, and they can\nonly perform satisfactorily on a small range of the constraint values but\npoorly on other values. To tackle this drawback of existing NCO methods, we\ndevelop an efficient training scheme that explicitly considers varying degrees\nof constraint tightness and proposes a multi-expert module to learn a generally\nadaptable solving strategy. Experimental results show that the proposed method\ncan effectively overcome the overfitting issue, demonstrating superior\nperformances on the CVRP and CVRP with time windows (CVRPTW) with various\nconstraint tightness degrees.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u5728\u4e0d\u540c\u5bb9\u91cf\u7ea6\u675f\u7d27\u5ea6\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6848\u4e0e\u591a\u4e13\u5bb6\u6a21\u5757\u6765\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\u7684\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\uff08NCO\uff09\u65b9\u6cd5\u65e0\u9700\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u5373\u53ef\u5c55\u73b0\u51fa\u826f\u597d\u7684\u95ee\u9898\u6c42\u89e3\u80fd\u529b\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684NCO\u65b9\u6cd5\u4f7f\u7528\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5177\u6709\u56fa\u5b9a\u7684\u7ea6\u675f\u503c\uff0c\u7f3a\u4e4f\u5bf9\u7ea6\u675f\u7d27\u5ea6\u53d8\u5316\u5f71\u54cd\u7684\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u4e0d\u540c\u7ea6\u675f\u7d27\u5ea6\u5bf9NCO\u65b9\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u672c\u6587\u4ee5\u5bb9\u91cf\u7ea6\u675f\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRP\uff09\u4e3a\u4f8b\uff0c\u5b9e\u8bc1\u5206\u6790\u4e86\u4e0d\u540c\u5bb9\u91cf\u7ea6\u675f\u7d27\u5ea6\u4e0bNCO\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8003\u8651\u4e0d\u540c\u7ea6\u675f\u7d27\u5ea6\u7684\u9ad8\u6548\u8bad\u7ec3\u65b9\u6848\uff0c\u5e76\u5f15\u5165\u591a\u4e13\u5bb6\u6a21\u5757\u4ee5\u5b66\u4e60\u901a\u7528\u7684\u6c42\u89e3\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u7684NCO\u65b9\u6cd5\u5728\u5bb9\u91cf\u7ea6\u675f\u4e0a\u5b58\u5728\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u4ec5\u5728\u7279\u5b9a\u7ea6\u675f\u503c\u8303\u56f4\u5185\u8868\u73b0\u826f\u597d\u3002\u800c\u4f5c\u8005\u63d0\u51fa\u7684\u8bad\u7ec3\u65b9\u6848\u7ed3\u5408\u591a\u4e13\u5bb6\u6a21\u5757\u80fd\u591f\u6709\u6548\u7f13\u89e3\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5728\u591a\u79cd\u7ea6\u675f\u7d27\u5ea6\u4e0b\u7684CVRP\u548cCVRPTW\u95ee\u9898\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u73b0\u6709\u7684NCO\u65b9\u6cd5\u5728\u5bb9\u91cf\u7ea6\u675f\u4e0b\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u53ea\u80fd\u5728\u5c0f\u8303\u56f4\u7684\u7ea6\u675f\u503c\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u800c\u5728\u5176\u4ed6\u503c\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u4f5c\u8005\u901a\u8fc7\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6848\u5e76\u63d0\u51fa\u591a\u4e13\u5bb6\u6a21\u5757\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u514b\u670d\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u5728\u4e0d\u540c\u7ea6\u675f\u7d27\u5ea6\u4e0b\u7684CVRP\u548cCVRPTW\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.24629", "pdf": "https://arxiv.org/pdf/2505.24629", "abs": "https://arxiv.org/abs/2505.24629", "authors": ["Lotte Bransen", "Tim Janssen", "Jesse Davis"], "title": "Stop Guessing: Optimizing Goalkeeper Policies for Soccer Penalty Kicks", "categories": ["cs.LG", "cs.GT"], "comment": "24 pages, 7 figures", "summary": "Penalties are fraught and game-changing moments in soccer games that teams\nexplicitly prepare for. Consequently, there has been substantial interest in\nanalyzing them in order to provide advice to practitioners. From a data science\nperspective, such analyses suffer from a significant limitation: they make the\nunrealistic simplifying assumption that goalkeepers and takers select their\naction -- where to dive and where to the place the kick -- independently of\neach other. In reality, the choices that some goalkeepers make depend on the\ntaker's movements and vice-versa. This adds substantial complexity to the\nproblem because not all players have the same action capacities, that is, only\nsome players are capable of basing their decisions on their opponent's\nmovements. However, the small sample sizes on the player level mean that one\nmay have limited insights into a specific opponent's capacities. We address\nthese challenges by developing a player-agnostic simulation framework that can\nevaluate the efficacy of different goalkeeper strategies. It considers a rich\nset of choices and incorporates information about a goalkeeper's skills. Our\nwork is grounded in a large dataset of penalties that were annotated by penalty\nexperts and include aspects of both kicker and goalkeeper strategies. We show\nhow our framework can be used to optimize goalkeeper policies in real-world\nsituations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u70b9\u7403\u5bf9\u6297\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4ee5\u4f18\u5316\u5b88\u95e8\u5458\u7684\u5e94\u5bf9\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u70b9\u7403\u662f\u8db3\u7403\u6bd4\u8d5b\u4e2d\u5177\u6709\u51b3\u5b9a\u6027\u7684\u5173\u952e\u65f6\u523b\uff0c\u4f46\u73b0\u6709\u6570\u636e\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5b88\u95e8\u5458\u548c\u7f5a\u7403\u8005\u72ec\u7acb\u884c\u52a8\uff0c\u8fd9\u79cd\u7b80\u5316\u4e0e\u73b0\u5b9e\u4e0d\u7b26\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u5177\u4f53\u7403\u5458\u7684\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5b88\u95e8\u5458\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u8003\u8651\u4e86\u4e30\u5bcc\u7684\u51b3\u7b56\u9009\u62e9\u5e76\u6574\u5408\u4e86\u5b88\u95e8\u5458\u7684\u6280\u80fd\u4fe1\u606f\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u57fa\u4e8e\u5927\u91cf\u7ecf\u4e13\u5bb6\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff0c\u5bf9\u5b88\u95e8\u5458\u7684\u7b56\u7565\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u4e00\u4e2a\u53ef\u884c\u7684\u5b88\u95e8\u5458\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u6846\u67b6\u8bc4\u4f30\u4e0d\u540c\u7b56\u7565\u7684\u6548\u679c\uff0c\u5e76\u7ed3\u5408\u5b88\u95e8\u5458\u81ea\u8eab\u80fd\u529b\u4fe1\u606f\u8fdb\u884c\u5206\u6790\u3002"}}
{"id": "2505.24642", "pdf": "https://arxiv.org/pdf/2505.24642", "abs": "https://arxiv.org/abs/2505.24642", "authors": ["Masahiro Negishi", "Thomas G\u00e4rtner", "Pascal Welke"], "title": "WILTing Trees: Interpreting the Distance Between MPNN Embeddings", "categories": ["cs.LG", "I.2.6"], "comment": "25 pages, 10 figures. Accepted to ICML 2025. See\n  https://github.com/masahiro-negishi/wilt for code", "summary": "We investigate the distance function learned by message passing neural\nnetworks (MPNNs) in specific tasks, aiming to capture the functional distance\nbetween prediction targets that MPNNs implicitly learn. This contrasts with\nprevious work, which links MPNN distances on arbitrary tasks to structural\ndistances on graphs that ignore task-specific information. To address this gap,\nwe distill the distance between MPNN embeddings into an interpretable graph\ndistance. Our method uses optimal transport on the Weisfeiler Leman Labeling\nTree (WILT), where the edge weights reveal subgraphs that strongly influence\nthe distance between embeddings. This approach generalizes two well-known graph\nkernels and can be computed in linear time. Through extensive experiments, we\ndemonstrate that MPNNs define the relative position of embeddings by focusing\non a small set of subgraphs that are known to be functionally important in the\ndomain.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08MPNNs\uff09\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5b66\u4e60\u5230\u7684\u8ddd\u79bb\u51fd\u6570\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u5206\u6790MPNN\u5d4c\u5165\u4e4b\u95f4\u7684\u529f\u80fd\u8ddd\u79bb\u3002", "motivation": "\u4ee5\u524d\u7684\u7814\u7a76\u5c06MPNN\u7684\u8ddd\u79bb\u4e0e\u5ffd\u7565\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u7684\u56fe\u7ed3\u6784\u8ddd\u79bb\u8054\u7cfb\u8d77\u6765\uff0c\u800c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5173\u6ce8MPNN\u5728\u5177\u4f53\u4efb\u52a1\u4e2d\u9690\u5f0f\u5b66\u4e60\u7684\u529f\u80fd\u8ddd\u79bb\u3002", "method": "\u901a\u8fc7\u5728Weisfeiler Leman Labeling Tree (WILT)\u4e0a\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\uff0c\u5c06MPNN\u5d4c\u5165\u4e4b\u95f4\u7684\u8ddd\u79bb\u63d0\u70bc\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u56fe\u8ddd\u79bb\uff0c\u5176\u4e2d\u8fb9\u6743\u91cd\u63ed\u793a\u4e86\u5bf9\u5d4c\u5165\u8ddd\u79bb\u6709\u663e\u8457\u5f71\u54cd\u7684\u5b50\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMPNNs\u901a\u8fc7\u5173\u6ce8\u5c11\u91cf\u5728\u9886\u57df\u5185\u5177\u6709\u529f\u80fd\u91cd\u8981\u6027\u7684\u5b50\u56fe\u6765\u5b9a\u4e49\u5d4c\u5165\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff1b\u6b64\u5916\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8ba1\u7b97\uff0c\u5e76\u63a8\u5e7f\u4e86\u4e24\u4e2a\u8457\u540d\u7684\u56fe\u6838\u65b9\u6cd5\u3002", "conclusion": "MPNNs\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u9690\u5f0f\u5b66\u4e60\u5d4c\u5165\u8ddd\u79bb\uff0c\u8fd9\u79cd\u8ddd\u79bb\u53ef\u4ee5\u901a\u8fc7\u4efb\u52a1\u76f8\u5173\u7684\u5b50\u56fe\u8fdb\u884c\u89e3\u91ca\u548c\u8ba1\u7b97\u3002"}}
{"id": "2505.24664", "pdf": "https://arxiv.org/pdf/2505.24664", "abs": "https://arxiv.org/abs/2505.24664", "authors": ["Daniel Severo", "Brian Karrer", "Niklas Nolte"], "title": "Learning Distributions over Permutations and Rankings with Factorized Representations", "categories": ["cs.LG"], "comment": null, "summary": "Learning distributions over permutations is a fundamental problem in machine\nlearning, with applications in ranking, combinatorial optimization, structured\nprediction, and data association. Existing methods rely on mixtures of\nparametric families or neural networks with expensive variational inference\nprocedures. In this work, we propose a novel approach that leverages\nalternative representations for permutations, including Lehmer codes,\nFisher-Yates draws, and Insertion-Vectors. These representations form a\nbijection with the symmetric group, allowing for unconstrained learning using\nconventional deep learning techniques, and can represent any probability\ndistribution over permutations. Our approach enables a trade-off between\nexpressivity of the model family and computational requirements. In the least\nexpressive and most computationally efficient case, our method subsumes\nprevious families of well established probabilistic models over permutations,\nincluding Mallow's and the Repeated Insertion Model. Experiments indicate our\nmethod significantly outperforms current approaches on the jigsaw puzzle\nbenchmark, a common task for permutation learning. However, we argue this\nbenchmark is limited in its ability to assess learning probability\ndistributions, as the target is a delta distribution (i.e., a single correct\nsolution exists). We therefore propose two additional benchmarks: learning\ncyclic permutations and re-ranking movies based on user preference. We show\nthat our method learns non-trivial distributions even in the least expressive\nmode, while traditional models fail to even generate valid permutations in this\nsetting.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6392\u5217\u4e0d\u540c\u8868\u793a\u5f62\u5f0f\uff08\u5982Lehmer\u4ee3\u7801\u3001Fisher-Yates\u62bd\u6837\u548c\u63d2\u5165\u5411\u91cf\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60\u6392\u5217\u5206\u5e03\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5177\u8868\u8fbe\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5b66\u4e60\u6392\u5217\u5206\u5e03\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6392\u540d\u3001\u7ec4\u5408\u4f18\u5316\u3001\u7ed3\u6784\u5316\u9884\u6d4b\u548c\u6570\u636e\u5173\u8054\u7b49\u9886\u57df\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u53c2\u6570\u5bb6\u65cf\u7684\u6df7\u5408\u6216\u9700\u8981\u6602\u8d35\u53d8\u5206\u63a8\u65ad\u8fc7\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u5177\u6709\u66f4\u597d\u8868\u8fbe\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6392\u5217\u7684\u4e0d\u540c\u8868\u793a\u5f62\u5f0f\uff08\u5305\u62ecLehmer\u4ee3\u7801\u3001Fisher-Yates\u62bd\u6837\u548c\u63d2\u5165\u5411\u91cf\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u8868\u793a\u4e0e\u5bf9\u79f0\u7fa4\u5f62\u6210\u53cc\u5c04\u5173\u7cfb\uff0c\u4ece\u800c\u5141\u8bb8\u4f7f\u7528\u5e38\u89c4\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u65e0\u7ea6\u675f\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u62fc\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u65b9\u6cd5\uff0c\u540c\u65f6\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1a\u5b66\u4e60\u5faa\u73af\u6392\u5217\u548c\u6839\u636e\u7528\u6237\u504f\u597d\u91cd\u65b0\u6392\u5e8f\u7535\u5f71\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u6700\u4e0d\u5177\u8868\u8fbe\u6027\u7684\u6a21\u5f0f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4e5f\u80fd\u5b66\u4e60\u975e\u5e73\u51e1\u7684\u5206\u5e03\uff0c\u800c\u4f20\u7edf\u6a21\u578b\u751a\u81f3\u65e0\u6cd5\u751f\u6210\u6709\u6548\u7684\u6392\u5217\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u5b66\u4e60\u6392\u5217\u5206\u5e03\uff0c\u901a\u8fc7\u5229\u7528\u6392\u5217\u7684\u66ff\u4ee3\u8868\u793a\uff0c\u5982Lehmer\u7f16\u7801\u3001Fisher-Yates\u62bd\u53d6\u548c\u63d2\u5165\u5411\u91cf\uff0c\u80fd\u591f\u4f7f\u7528\u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u65e0\u7ea6\u675f\u5b66\u4e60\uff0c\u5e76\u4e14\u53ef\u4ee5\u8868\u793a\u4efb\u4f55\u6982\u7387\u5206\u5e03\u3002\u6b64\u5916\uff0c\u5728\u6700\u4e0d\u5177\u8868\u8fbe\u6027\u4f46\u8ba1\u7b97\u6548\u7387\u6700\u9ad8\u7684\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e5f\u6db5\u76d6\u4e86\u4e4b\u524d\u4e00\u4e9b\u7ecf\u5178\u7684\u6982\u7387\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u4f20\u7edf\u6a21\u578b\u65e0\u6cd5\u751f\u6210\u6709\u6548\u6392\u5217\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.24665", "pdf": "https://arxiv.org/pdf/2505.24665", "abs": "https://arxiv.org/abs/2505.24665", "authors": ["Hanlin Yu", "S\u00f8ren Hauberg", "Marcelo Hartmann", "Arto Klami", "Georgios Arvanitidis"], "title": "Learning geometry and topology via multi-chart flows", "categories": ["cs.LG"], "comment": null, "summary": "Real world data often lie on low-dimensional Riemannian manifolds embedded in\nhigh-dimensional spaces. This motivates learning degenerate normalizing flows\nthat map between the ambient space and a low-dimensional latent space. However,\nif the manifold has a non-trivial topology, it can never be correctly learned\nusing a single flow. Instead multiple flows must be `glued together'. In this\npaper, we first propose the general training scheme for learning such a\ncollection of flows, and secondly we develop the first numerical algorithms for\ncomputing geodesics on such manifolds. Empirically, we demonstrate that this\nleads to highly significant improvements in topology estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u591a\u6d41\u5f62\u6620\u5c04\u96c6\u5408\u7684\u8bad\u7ec3\u65b9\u6848\u548c\u8ba1\u7b97\u6d41\u5f62\u6d4b\u5730\u7ebf\u7684\u65b0\u7b97\u6cd5\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u4e86\u6d41\u5f62\u62d3\u6251\u4f30\u8ba1\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u901a\u5e38\u4f4d\u4e8e\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u4f4e\u7ef4\u9ece\u66fc\u6d41\u5f62\u4e0a\uff0c\u800c\u5982\u679c\u6d41\u5f62\u5177\u6709\u975e\u5e73\u51e1\u62d3\u6251\u7ed3\u6784\uff0c\u5219\u65e0\u6cd5\u901a\u8fc7\u5355\u4e00\u7684\u5f52\u4e00\u5316\u6d41\u6b63\u786e\u5b66\u4e60\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b66\u4e60\u591a\u4e2a\u5f52\u4e00\u5316\u6d41\uff08normalizing flows\uff09\u96c6\u5408\u7684\u901a\u7528\u8bad\u7ec3\u65b9\u6848\uff0c\u5e76\u5f00\u53d1\u4e86\u5728\u6d41\u5f62\u4e0a\u8ba1\u7b97\u6d4b\u5730\u7ebf\u7684\u7b2c\u4e00\u4e2a\u6570\u503c\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u62d3\u6251\u4f30\u8ba1\u4efb\u52a1\u4e0a\u5e26\u6765\u4e86\u9ad8\u5ea6\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u7ec4\u5408\u591a\u4e2a\u6d41\u5f62\u6620\u5c04\u5e76\u8ba1\u7b97\u6d4b\u5730\u7ebf\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u6539\u8fdb\u4e86\u5bf9\u6d41\u5f62\u62d3\u6251\u7ed3\u6784\u7684\u4f30\u8ba1\u3002"}}
{"id": "2505.24676", "pdf": "https://arxiv.org/pdf/2505.24676", "abs": "https://arxiv.org/abs/2505.24676", "authors": ["Mihir Bhaskar", "Jun Tao Luo", "Zihan Geng", "Asmita Hajra", "Junia Howell", "Matthew R. Gormley"], "title": "Predicting the Past: Estimating Historical Appraisals with OCR and Machine Learning", "categories": ["cs.LG"], "comment": "Accepted to COMPASS 2025", "summary": "Despite well-documented consequences of the U.S. government's 1930s housing\npolicies on racial wealth disparities, scholars have struggled to quantify its\nprecise financial effects due to the inaccessibility of historical property\nappraisal records. Many counties still store these records in physical formats,\nmaking large-scale quantitative analysis difficult. We present an approach\nscholars can use to digitize historical housing assessment data, applying it to\nbuild and release a dataset for one county. Starting from publicly available\nscanned documents, we manually annotated property cards for over 12,000\nproperties to train and validate our methods. We use OCR to label data for an\nadditional 50,000 properties, based on our two-stage approach combining\nclassical computer vision techniques with deep learning-based OCR. For cases\nwhere OCR cannot be applied, such as when scanned documents are not available,\nwe show how a regression model based on building feature data can estimate the\nhistorical values, and test the generalizability of this model to other\ncounties. With these cost-effective tools, scholars, community activists, and\npolicy makers can better analyze and understand the historical impacts of\nredlining.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u91cf\u5316\u5206\u6790\u7f8e\u56fd1930\u5e74\u4ee3\u4f4f\u623f\u653f\u7b56\u5bf9\u79cd\u65cf\u8d22\u5bcc\u5dee\u8ddd\u5f71\u54cd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7OCR\u548c\u56de\u5f52\u6a21\u578b\u5efa\u7acb\u4e86\u5386\u53f2\u4f4f\u623f\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "motivation": "\u7531\u4e8e\u5386\u53f2\u623f\u4ea7\u4f30\u4ef7\u8bb0\u5f55\u96be\u4ee5\u83b7\u53d6\uff0c\u4f7f\u5f97\u96be\u4ee5\u7cbe\u786e\u91cf\u5316\u7f8e\u56fd1930\u5e74\u4ee3\u4f4f\u623f\u653f\u7b56\u5bf9\u79cd\u65cf\u8d22\u5bcc\u5dee\u8ddd\u7684\u5177\u4f53\u8d22\u52a1\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\u548c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684OCR\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5efa\u7b51\u7279\u5f81\u6570\u636e\u7684\u56de\u5f52\u6a21\u578b\u6765\u4f30\u8ba1\u5386\u53f2\u4ef7\u503c\u3002", "result": "\u5efa\u7acb\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u53bf\u7684\u5386\u53f2\u4f4f\u623f\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fd9\u79cd\u65b9\u6cd5\u63a8\u5e7f\u5230\u5176\u4ed6\u53bf\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528OCR\u548c\u56de\u5f52\u6a21\u578b\u7b49\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5de5\u5177\uff0c\u5b66\u8005\u3001\u793e\u533a\u6d3b\u52a8\u5bb6\u548c\u653f\u7b56\u5236\u5b9a\u8005\u53ef\u4ee5\u66f4\u597d\u5730\u5206\u6790\u548c\u7406\u89e3\u7ea2\u7ebf\u653f\u7b56\u7684\u5386\u53f2\u5f71\u54cd\u3002"}}
{"id": "2505.24717", "pdf": "https://arxiv.org/pdf/2505.24717", "abs": "https://arxiv.org/abs/2505.24717", "authors": ["Benjamin Holzschuh", "Qiang Liu", "Georg Kohl", "Nils Thuerey"], "title": "PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations", "categories": ["cs.LG"], "comment": "ICML 2025. Code available at\n  https://github.com/tum-pbs/pde-transformer", "summary": "We introduce PDE-Transformer, an improved transformer-based architecture for\nsurrogate modeling of physics simulations on regular grids. We combine recent\narchitectural improvements of diffusion transformers with adjustments specific\nfor large-scale simulations to yield a more scalable and versatile\ngeneral-purpose transformer architecture, which can be used as the backbone for\nbuilding large-scale foundation models in physical sciences. We demonstrate\nthat our proposed architecture outperforms state-of-the-art transformer\narchitectures for computer vision on a large dataset of 16 different types of\nPDEs. We propose to embed different physical channels individually as\nspatio-temporal tokens, which interact via channel-wise self-attention. This\nhelps to maintain a consistent information density of tokens when learning\nmultiple types of PDEs simultaneously. We demonstrate that our pre-trained\nmodels achieve improved performance on several challenging downstream tasks\ncompared to training from scratch and also beat other foundation model\narchitectures for physics simulations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PDE-Transformer\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u4e3a\u7269\u7406\u6a21\u62df\u8bbe\u8ba1\u7684transformer\u67b6\u6784\uff0c\u5176\u901a\u8fc7\u521b\u65b0\u6027\u7684\u8c03\u6574\u548c\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u591a\u7c7b\u578bPDEs\u65f6\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u66f4\u52a0\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684transformer\u67b6\u6784\u6765\u89e3\u51b3\u7269\u7406\u6a21\u62df\u4e2d\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u591a\u7c7b\u578bPDEs\u65f6\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u7ed3\u5408\u6269\u6563transformer\u7684\u6700\u65b0\u67b6\u6784\u6539\u8fdb\u548c\u9488\u5bf9\u5927\u89c4\u6a21\u6a21\u62df\u7684\u8c03\u6574\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684transformer\u67b6\u6784\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u901a\u9053\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6765\u5904\u7406\u4e0d\u540c\u7684\u7269\u7406\u901a\u9053\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u572816\u79cd\u4e0d\u540c\u7c7b\u578b\u7684PDEs\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u8ba1\u7b97\u673a\u89c6\u89c9transformer\u67b6\u6784\uff1b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "PDE-Transformer\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8etransformer\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u89c4\u5219\u7f51\u683c\u4e0a\u7684\u7269\u7406\u6a21\u62df\u4ee3\u7406\u5efa\u6a21\uff0c\u5e76\u4e14\u5728\u5927\u89c4\u6a21\u7269\u7406\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u6784\u5efa\u4e2d\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.24721", "pdf": "https://arxiv.org/pdf/2505.24721", "abs": "https://arxiv.org/abs/2505.24721", "authors": ["Nick Rossenbach", "Benedikt Hilmes", "Leon Brackmann", "Moritz Gunz", "Ralf Schl\u00fcter"], "title": "Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": "Accepted for the Blue Sky track at Interspeech 2025", "summary": "Memristor-based hardware offers new possibilities for energy-efficient\nmachine learning (ML) by providing analog in-memory matrix multiplication.\nCurrent hardware prototypes cannot fit large neural networks, and related\nliterature covers only small ML models for tasks like MNIST or single word\nrecognition. Simulation can be used to explore how hardware properties affect\nlarger models, but existing software assumes simplified hardware. We propose a\nPyTorch-based library based on \"Synaptogen\" to simulate neural network\nexecution with accurately captured memristor hardware properties. For the first\ntime, we show how an ML system with millions of parameters would behave on\nmemristor hardware, using a Conformer trained on the speech recognition task\nTED-LIUMv2 as example. With adjusted quantization-aware training, we limit the\nrelative degradation in word error rate to 25% when using a 3-bit weight\nprecision to execute linear operations via simulated analog computation.", "AI": {"tldr": "\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u786c\u4ef6\u63d0\u4f9b\u4e86\u8282\u80fd\u673a\u5668\u5b66\u4e60\u7684\u65b0\u53ef\u80fd\u6027\uff0c\u4f46\u76ee\u524d\u7684\u786c\u4ef6\u539f\u578b\u65e0\u6cd5\u5bb9\u7eb3\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201cSynaptogen\u201d\u7684PyTorch\u5e93\u6765\u6a21\u62df\u5177\u6709\u51c6\u786e\u6355\u6349\u7684\u5fc6\u963b\u5668\u786c\u4ef6\u5c5e\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u6267\u884c\u60c5\u51b5\u3002", "motivation": "\u5f53\u524d\u786c\u4ef6\u539f\u578b\u65e0\u6cd5\u5bb9\u7eb3\u5927\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u5173\u6587\u732e\u4ec5\u8986\u76d6\u4e86\u7528\u4e8e\u5c0f\u89c4\u6a21\u4efb\u52a1\u7684\u5c0f\u578b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u4e3a\u4e86\u63a2\u7d22\u786c\u4ef6\u5c5e\u6027\u5982\u4f55\u5f71\u54cd\u66f4\u5927\u7684\u6a21\u578b\uff0c\u9700\u8981\u4f7f\u7528\u4eff\u771f\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u7684\u8f6f\u4ef6\u5047\u8bbe\u4e86\u7b80\u5316\u7684\u786c\u4ef6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePyTorch\u7684\u540d\u4e3a\u201cSynaptogen\u201d\u7684\u5e93\uff0c\u7528\u4e8e\u6a21\u62df\u5e26\u6709\u771f\u5b9e\u5fc6\u963b\u5668\u786c\u4ef6\u5c5e\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u6267\u884c\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u8c03\u6574\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4ee5\u9002\u5e94\u4f4e\u7cbe\u5ea6\u6743\u91cd\u8ba1\u7b97\u3002", "result": "\u9996\u6b21\u5c55\u793a\u4e86\u5343\u4e07\u7ea7\u53c2\u6570\u7684ML\u7cfb\u7edf\u5728\u5fc6\u963b\u5668\u786c\u4ef6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7TED-LIUMv2\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u9a8c\u8bc1\u4e863\u4f4d\u6743\u91cd\u7cbe\u5ea6\u4e0b\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u9000\u5316\u9650\u5236\u572825%\u4ee5\u5185\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u6a21\u62df\u7684\u5fc6\u963b\u5668\u786c\u4ef6\u4e0a\u8fd0\u884c\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u9002\u5f53\u8c03\u6574\u8bad\u7ec3\u7b56\u7565\u6765\u4fdd\u6301\u6027\u80fd\uff0c\u4ece\u800c\u4e3a\u9ad8\u6548\u80fd\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.24728", "pdf": "https://arxiv.org/pdf/2505.24728", "abs": "https://arxiv.org/abs/2505.24728", "authors": ["Dongzi Jin", "Yong Xiao", "Yingyu Li"], "title": "Robust Federated Learning against Model Perturbation in Edge Networks", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by IEEE ICC 2025", "summary": "Federated Learning (FL) is a promising paradigm for realizing edge\nintelligence, allowing collaborative learning among distributed edge devices by\nsharing models instead of raw data. However, the shared models are often\nassumed to be ideal, which would be inevitably violated in practice due to\nvarious perturbations, leading to significant performance degradation. To\novercome this challenge, we propose a novel method, termed Sharpness-Aware\nMinimization-based Robust Federated Learning (SMRFL), which aims to improve\nmodel robustness against perturbations by exploring the geometrical property of\nthe model landscape. Specifically, SMRFL solves a min-max optimization problem\nthat promotes model convergence towards a flat minimum by minimizing the\nmaximum loss within a neighborhood of the model parameters. In this way, model\nsensitivity to perturbations is reduced, and robustness is enhanced since\nmodels in the neighborhood of the flat minimum also enjoy low loss values. The\ntheoretical result proves that SMRFL can converge at the same rate as FL\nwithout perturbations. Extensive experimental results show that SMRFL\nsignificantly enhances robustness against perturbations compared to three\nbaseline methods on two real-world datasets under three perturbation scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5SMRFL\uff0c\u7528\u4e8e\u589e\u5f3a\u6a21\u578b\u5bf9\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u5176\u901a\u8fc7\u89e3\u51b3\u4e00\u4e2amin-max\u4f18\u5316\u95ee\u9898\u5b9e\u73b0\uff0c\u5e76\u4e14\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u5747\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5171\u4eab\u6a21\u578b\u901a\u5e38\u5047\u8bbe\u662f\u7406\u60f3\u7684\uff0c\u5728\u5b9e\u8df5\u4e2d\u7531\u4e8e\u5404\u79cd\u6270\u52a8\u4f1a\u53d7\u5230\u6027\u80fd\u4e0b\u964d\u7684\u5f71\u54cd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSharpness-Aware Minimization-based Robust Federated Learning (SMRFL)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6a21\u578b\u53c2\u6570\u90bb\u57df\u5185\u7684\u6700\u5927\u635f\u5931\u6765\u4fc3\u8fdb\u6a21\u578b\u5411\u5e73\u5766\u6700\u5c0f\u503c\u6536\u655b\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4e09\u79cd\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cSMRFL\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u4e09\u79cd\u6270\u52a8\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SMRFL\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6536\u655b\u901f\u5ea6\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6a21\u578b\u5bf9\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24729", "pdf": "https://arxiv.org/pdf/2505.24729", "abs": "https://arxiv.org/abs/2505.24729", "authors": ["Magamed Taimeskhanov", "Damien Garreau"], "title": "Feature Attribution from First Principles", "categories": ["cs.LG"], "comment": "30 pages, 3 figures", "summary": "Feature attribution methods are a popular approach to explain the behavior of\nmachine learning models. They assign importance scores to each input feature,\nquantifying their influence on the model's prediction. However, evaluating\nthese methods empirically remains a significant challenge. To bypass this\nshortcoming, several prior works have proposed axiomatic frameworks that any\nfeature attribution method should satisfy. In this work, we argue that such\naxioms are often too restrictive, and propose in response a new feature\nattribution framework, built from the ground up. Rather than imposing axioms,\nwe start by defining attributions for the simplest possible models, i.e.,\nindicator functions, and use these as building blocks for more complex models.\nWe then show that one recovers several existing attribution methods, depending\non the choice of atomic attribution. Subsequently, we derive closed-form\nexpressions for attribution of deep ReLU networks, and take a step toward the\noptimization of evaluation metrics with respect to feature attributions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u4f9d\u8d56\u4e25\u683c\u516c\u7406\u7684\u65b0\u7279\u5f81\u5f52\u56e0\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u7b80\u5355\u6a21\u578b\u6784\u5efa\u590d\u6742\u6a21\u578b\u7684\u65b9\u5f0f\u63a8\u5bfc\u51fa\u73b0\u6709\u548c\u65b0\u7684\u5f52\u56e0\u65b9\u6cd5\u3002", "motivation": "\u56e0\u4e3a\u73b0\u6709\u7684\u516c\u7406\u5316\u6846\u67b6\u5f80\u5f80\u8fc7\u4e8e\u9650\u5236\uff0c\u800c\u7ecf\u9a8c\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u7279\u5f81\u5f52\u56e0\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u4ece\u6700\u7b80\u5355\u7684\u6a21\u578b\uff08\u5373\u6307\u793a\u51fd\u6570\uff09\u5f00\u59cb\u5b9a\u4e49\u5f52\u56e0\uff0c\u5e76\u5c06\u8fd9\u4e9b\u4f5c\u4e3a\u6784\u5efa\u5757\u7528\u4e8e\u66f4\u590d\u6742\u6a21\u578b\u7684\u5f52\u56e0\uff0c\u4ece\u800c\u63d0\u51fa\u65b0\u7684\u7279\u5f81\u5f52\u56e0\u6846\u67b6\u3002", "result": "\u5f97\u51fa\u4e86\u9488\u5bf9\u6df1\u5ea6ReLU\u7f51\u7edc\u7684\u5f52\u56e0\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u671d\u7740\u4f18\u5316\u8bc4\u4ef7\u6307\u6807\u76f8\u5bf9\u4e8e\u7279\u5f81\u5f52\u56e0\u7684\u65b9\u5411\u8fc8\u8fdb\u4e86\u4e00\u6b65\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7279\u5f81\u5f52\u56e0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e0d\u662f\u57fa\u4e8e\u516c\u7406\u800c\u662f\u4ece\u6700\u7b80\u5355\u7684\u6a21\u578b\u5f00\u59cb\u5b9a\u4e49\u5f52\u56e0\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u6839\u636e\u539f\u5b50\u5f52\u56e0\u7684\u9009\u62e9\u6062\u590d\u51e0\u79cd\u73b0\u6709\u7684\u5f52\u56e0\u65b9\u6cd5\u3002"}}
{"id": "2505.24749", "pdf": "https://arxiv.org/pdf/2505.24749", "abs": "https://arxiv.org/abs/2505.24749", "authors": ["Yehonathan Refael", "Guy Smorodinsky", "Tom Tirer", "Ofir Lindenbaum"], "title": "SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training", "categories": ["cs.LG", "cs.CL", "math.OC"], "comment": null, "summary": "Low-rank gradient-based optimization methods have significantly improved\nmemory efficiency during the training of large language models (LLMs), enabling\noperations within constrained hardware without sacrificing performance.\nHowever, these methods primarily emphasize memory savings, often overlooking\npotential acceleration in convergence due to their reliance on standard\nisotropic steepest descent techniques, which can perform suboptimally in the\nhighly anisotropic landscapes typical of deep networks, particularly LLMs. In\nthis paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an\noptimizer that employs exact singular value decomposition (SVD) for moment\northogonalization within a dynamically adapted low-dimensional subspace,\nenabling norm-inducing steepest descent optimization steps. By explicitly\naligning optimization steps with the spectral characteristics of the loss\nlandscape, SUMO effectively mitigates approximation errors associated with\ncommonly used methods like Newton-Schulz orthogonalization approximation. We\ntheoretically establish an upper bound on these approximation errors, proving\ntheir dependence on the condition numbers of moments, conditions we\nanalytically demonstrate are encountered during LLM training. Furthermore, we\nboth theoretically and empirically illustrate that exact orthogonalization via\nSVD substantially improves convergence rates while reducing overall complexity.\nEmpirical evaluations confirm that SUMO accelerates convergence, enhances\nstability, improves performance, and reduces memory requirements by up to 20%\ncompared to state-of-the-art methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668SUMO\uff0c\u901a\u8fc7\u7cbe\u786e\u7684SVD\u6b63\u4ea4\u5316\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u7684\u4f4e\u79e9\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5185\u5b58\u6548\u7387\u800c\u5ffd\u89c6\u6536\u655b\u52a0\u901f\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5ea6\u7f51\u7edc\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u9ad8\u5ea6\u5404\u5411\u5f02\u6027\u7684\u635f\u5931\u666f\u89c2\u4e0b\u8868\u73b0\u4e0d\u4f73\u7684\u60c5\u51b5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSUMO\u7684\u4f18\u5316\u5668\uff0c\u5229\u7528\u7cbe\u786e\u7684\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u8fdb\u884c\u52a8\u91cf\u6b63\u4ea4\u5316\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u7684\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u5b9e\u73b0\u8303\u6570\u8bf1\u5bfc\u7684\u6700\u901f\u4e0b\u964d\u4f18\u5316\u6b65\u9aa4\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cSUMO\u80fd\u591f\u6709\u6548\u7f13\u89e3\u8fd1\u4f3c\u6b63\u4ea4\u5316\u65b9\u6cd5\u5e26\u6765\u7684\u8bef\u5dee\uff0c\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u8fd9\u4e9b\u8bef\u5dee\u7684\u4e0a\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u6536\u655b\u6027\u3001\u7a33\u5b9a\u6027\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0cSUMO\u4f18\u5316\u5668\u5728\u6536\u655b\u901f\u5ea6\u3001\u7a33\u5b9a\u6027\u3001\u6027\u80fd\u4ee5\u53ca\u5185\u5b58\u9700\u6c42\u65b9\u9762\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2505.24773", "pdf": "https://arxiv.org/pdf/2505.24773", "abs": "https://arxiv.org/abs/2505.24773", "authors": ["Yajie Zhou", "Xiaoyi Pang", "Zhibo Wang"], "title": "AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption", "categories": ["cs.LG"], "comment": null, "summary": "Federated fine-tuning has emerged as a promising approach to adapt foundation\nmodels to downstream tasks using decentralized data. However, real-world\ndeployment remains challenging due to the high computational and communication\ndemands of fine-tuning Large Language Models (LLMs) on clients with data and\nsystem resources that are heterogeneous and constrained. In such settings, the\nglobal model's performance is often bottlenecked by the weakest clients and\nfurther degraded by the non-IID nature of local data. Although existing methods\nleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to\nreduce communication and computation overhead, they often fail to\nsimultaneously ensure accurate aggregation of low-rank updates and maintain low\nsystem costs, thereby hindering overall performance. To address these\nchallenges, we propose AFLoRA, an adaptive and lightweight federated\nfine-tuning framework for LLMs. AFLoRA decouples shared and client-specific\nupdates to reduce overhead and improve aggregation accuracy, incorporates\ndiagonal matrix-based rank pruning to better utilize local resources, and\nemploys rank-aware aggregation with public data refinement to strengthen\ngeneralization under data heterogeneity. Extensive experiments demonstrate that\nAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,\nproviding a practical solution for efficient LLM adaptation in heterogeneous\nenvironments in the real world.", "AI": {"tldr": "AFLoRA\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u548c\u5f02\u6784\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u4fdd\u8bc1\u4f4e\u7cfb\u7edf\u6210\u672c\u7684\u540c\u65f6\u6709\u6548\u805a\u5408\u4f4e\u79e9\u66f4\u65b0\uff0c\u4e14\u53d7\u6570\u636e\u5f02\u8d28\u6027\u548c\u6700\u5f31\u5ba2\u6237\u7aef\u6027\u80fd\u74f6\u9888\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4f18\u7684\u8054\u90a6\u5fae\u8c03\u65b9\u6848\u3002", "method": "AFLoRA\u901a\u8fc7\u89e3\u8026\u5171\u4eab\u4e0e\u5ba2\u6237\u7aef\u7279\u5b9a\u66f4\u65b0\u3001\u57fa\u4e8e\u5bf9\u89d2\u77e9\u9635\u7684\u79e9\u526a\u679d\u4ee5\u53ca\u7ed3\u5408\u516c\u5171\u6570\u636e\u4f18\u5316\u7684\u79e9\u611f\u77e5\u805a\u5408\uff0c\u51cf\u5c11\u901a\u4fe1\u8ba1\u7b97\u5f00\u9500\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAFLoRA\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u5f02\u6784\u73af\u5883\u4e0b\u7684LLM\u9002\u914d\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AFLoRA\u662f\u4e00\u79cd\u6709\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5e94\u5bf9LLMs\u5728\u5206\u5e03\u5f0f\u5f02\u6784\u73af\u5883\u4e0b\u5fae\u8c03\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u5177\u5907\u8f83\u9ad8\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.24776", "pdf": "https://arxiv.org/pdf/2505.24776", "abs": "https://arxiv.org/abs/2505.24776", "authors": ["Zachary Bastiani", "Robert M. Kirby", "Jacob Hochhalter", "Shandian Zhe"], "title": "Diffusion-Based Symbolic Regression", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion has emerged as a powerful framework for generative modeling,\nachieving remarkable success in applications such as image and audio synthesis.\nEnlightened by this progress, we propose a novel diffusion-based approach for\nsymbolic regression. We construct a random mask-based diffusion and denoising\nprocess to generate diverse and high-quality equations. We integrate this\ngenerative processes with a token-wise Group Relative Policy Optimization\n(GRPO) method to conduct efficient reinforcement learning on the given\nmeasurement dataset. In addition, we introduce a long short-term risk-seeking\npolicy to expand the pool of top-performing candidates, further enhancing\nperformance. Extensive experiments and ablation studies have demonstrated the\neffectiveness of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u6269\u6563\u6a21\u578b\u89e3\u51b3\u7b26\u53f7\u56de\u5f52\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u542f\u53d1\u4f5c\u8005\u5c06\u5176\u5e94\u7528\u4e8e\u7b26\u53f7\u56de\u5f52\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8e\u968f\u673a\u63a9\u7801\u7684\u6269\u6563\u548c\u53bb\u566a\u8fc7\u7a0b\uff0c\u5e76\u7ed3\u5408GRPO\u65b9\u6cd5\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u5f15\u5165\u957f\u671f\u98ce\u9669\u5bfb\u6c42\u7b56\u7565\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u4e2d\u8bc1\u660e\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u7b26\u53f7\u56de\u5f52\u65b0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2505.24779", "pdf": "https://arxiv.org/pdf/2505.24779", "abs": "https://arxiv.org/abs/2505.24779", "authors": ["Yidong Luo", "Chenguang Wang", "Jiahao Yang", "Fanzeng Xia", "Tianshu Yu"], "title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation", "categories": ["cs.LG"], "comment": "The code is available in\n  \\url{https://github.com/anonymous-neurips-submission-2025/EVA-MILP}", "summary": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u5b9e\u4f8b\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u91cd\u70b9\u5728\u4e8e\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u7531\u4e8eMILP\u5b9e\u4f8b\u751f\u6210\u65b9\u6cd5\u7684\u53d1\u5c55\u901f\u5ea6\u8d85\u8fc7\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6280\u672f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5408\u6210MILP\u5b9e\u4f8b\u7684\u771f\u5b9e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6c42\u89e3\u5668\u5185\u90e8\u7279\u5f81\uff0c\u5305\u62ec\u6839\u8282\u70b9\u95f4\u9699\u3001\u542f\u53d1\u5f0f\u6210\u529f\u7387\u548c\u5272\u5e73\u9762\u4f7f\u7528\u60c5\u51b5\uff0c\u63d0\u4f9b\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5b9e\u4f8b\u8d28\u91cf\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u5b9e\u4f8b\u96c6\u4fdd\u771f\u5ea6\u7684\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5e76\u4fc3\u8fdb\u4e0d\u540c\u751f\u6210\u6280\u672f\u4e4b\u95f4\u7684\u7a33\u5065\u6bd4\u8f83\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u9762\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u548c\u5ba2\u89c2\u5730\u8bc4\u4f30MILP\u5b9e\u4f8b\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2505.24780", "pdf": "https://arxiv.org/pdf/2505.24780", "abs": "https://arxiv.org/abs/2505.24780", "authors": ["Run-Ze He", "Jun-Jian Su", "Su-Juan Qin", "Zheng-Ping Jin", "Fei Gao"], "title": "QGAN-based data augmentation for hybrid quantum-classical neural networks", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Quantum neural networks converge faster and achieve higher accuracy than\nclassical models. However, data augmentation in quantum machine learning\nremains underexplored. To tackle data scarcity, we integrate quantum generative\nadversarial networks (QGANs) with hybrid quantum-classical neural networks\n(HQCNNs) to develop an augmentation framework. We propose two strategies: a\ngeneral approach to enhance data processing and classification across HQCNNs,\nand a customized strategy that dynamically generates samples tailored to the\nHQCNN's performance on specific data categories, improving its ability to learn\nfrom complex datasets. Simulation experiments on the MNIST dataset demonstrate\nthat QGAN outperforms traditional data augmentation methods and classical GANs.\nCompared to baseline DCGAN, QGAN achieves comparable performance with half the\nparameters, balancing efficiency and effectiveness. This suggests that QGANs\ncan simplify models and generate high-quality data, enhancing HQCNN accuracy\nand performance. These findings pave the way for applying quantum data\naugmentation techniques in machine learning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u5728\u6570\u636e\u589e\u5f3a\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u91cf\u5b50\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u548c\u6df7\u5408\u91cf\u5b50\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u548c\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u6570\u636e\u589e\u5f3a\u5728\u8be5\u9886\u57df\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06\u91cf\u5b50\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4e0e\u6df7\u5408\u91cf\u5b50\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u6570\u636e\u5904\u7406\u548c\u5206\u7c7b\u7684\u901a\u7528\u65b9\u6cd5\u4ee5\u53ca\u4e00\u4e2a\u6839\u636eHQCNN\u5728\u7279\u5b9a\u6570\u636e\u7c7b\u522b\u4e0a\u8868\u73b0\u52a8\u6001\u751f\u6210\u6837\u672c\u7684\u5b9a\u5236\u7b56\u7565\u3002", "result": "\u5728MNIST\u6570\u636e\u96c6\u4e0a\u7684\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u548c\u7ecf\u5178GAN\u76f8\u6bd4\uff0cQGAN\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5728\u53c2\u6570\u51cf\u5c11\u4e00\u534a\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u4e0eDCGAN\u76f8\u5f53\u7684\u8868\u73b0\u3002", "conclusion": "\u91cf\u5b50\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08QGANs\uff09\u80fd\u591f\u7b80\u5316\u6a21\u578b\u5e76\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u63d0\u9ad8\u6df7\u5408\u91cf\u5b50\u7ecf\u5178\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08HQCNNs\uff09\u7684\u51c6\u786e\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2505.24802", "pdf": "https://arxiv.org/pdf/2505.24802", "abs": "https://arxiv.org/abs/2505.24802", "authors": ["Marc Gonz\u00e1lez", "Rachid Guerraoui", "Rafael Pinot", "Geovani Rizk", "John Stephan", "Fran\u00e7ois Ta\u00efani"], "title": "ByzFL: Research Framework for Robust Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "We present ByzFL, an open-source Python library for developing and\nbenchmarking robust federated learning (FL) algorithms. ByzFL provides a\nunified and extensible framework that includes implementations of\nstate-of-the-art robust aggregators, a suite of configurable attacks, and tools\nfor simulating a variety of FL scenarios, including heterogeneous data\ndistributions, multiple training algorithms, and adversarial threat models. The\nlibrary enables systematic experimentation via a single JSON-based\nconfiguration file and includes built-in utilities for result visualization.\nCompatible with PyTorch tensors and NumPy arrays, ByzFL is designed to\nfacilitate reproducible research and rapid prototyping of robust FL solutions.\nByzFL is available at https://byzfl.epfl.ch/, with source code hosted on\nGitHub: https://github.com/LPD-EPFL/byzfl.", "AI": {"tldr": "ByzFL \u662f\u4e00\u4e2a\u7528\u4e8e\u5f00\u53d1\u548c\u6d4b\u8bd5\u9c81\u68d2\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u652f\u6301\u591a\u79cd\u573a\u666f\u6a21\u62df\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u5bf9\u9c81\u68d2\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u7cfb\u7edf\u5b9e\u9a8c\u7684\u9700\u6c42\uff0c\u63d0\u4f9b\u4e00\u4e2a\u96c6\u4e2d\u7684\u5e73\u53f0\u6765\u8bc4\u4f30\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5305\u62ec\u6700\u5148\u8fdb\u7684\u9c81\u68d2\u805a\u5408\u5668\u5b9e\u73b0\u3001\u4e00\u5957\u53ef\u914d\u7f6e\u7684\u653b\u51fb\u65b9\u6848\u4ee5\u53ca\u7528\u4e8e\u6a21\u62df\u591a\u79cd FL \u573a\u666f\u7684\u5de5\u5177\u3002", "result": "\u901a\u8fc7\u5355\u4e00\u7684\u57fa\u4e8e JSON \u7684\u914d\u7f6e\u6587\u4ef6\u5b9e\u73b0\u4e86\u7cfb\u7edf\u7684\u5b9e\u9a8c\uff0c\u5e76\u5305\u542b\u7ed3\u679c\u53ef\u89c6\u5316\u7684\u5185\u7f6e\u5de5\u5177\uff0c\u517c\u5bb9 PyTorch \u5f20\u91cf\u548c NumPy \u6570\u7ec4\u3002", "conclusion": "ByzFL \u662f\u4e00\u4e2a\u652f\u6301\u5f00\u53d1\u548c\u57fa\u51c6\u6d4b\u8bd5\u9c81\u68d2\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u7684\u5f00\u6e90 Python \u5e93\uff0c\u65e8\u5728\u4fc3\u8fdb\u53ef\u91cd\u590d\u7684\u7814\u7a76\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2505.24835", "pdf": "https://arxiv.org/pdf/2505.24835", "abs": "https://arxiv.org/abs/2505.24835", "authors": ["Fuyuan Lyu", "Linfeng Du", "Yunpeng Weng", "Qiufang Ying", "Zhiyan Xu", "Wen Zou", "Haolun Wu", "Xiuqiang He", "Xing Tang"], "title": "Timing is important: Risk-aware Fund Allocation based on Time-Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted by KDD 2025 ADS Track", "summary": "Fund allocation has been an increasingly important problem in the financial\ndomain. In reality, we aim to allocate the funds to buy certain assets within a\ncertain future period. Naive solutions such as prediction-only or\nPredict-then-Optimize approaches suffer from goal mismatch. Additionally, the\nintroduction of the SOTA time series forecasting model inevitably introduces\nadditional uncertainty in the predicted result. To solve both problems\nmentioned above, we introduce a Risk-aware Time-Series Predict-and-Allocate\n(RTS-PnO) framework, which holds no prior assumption on the forecasting models.\nSuch a framework contains three features: (i) end-to-end training with\nobjective alignment measurement, (ii) adaptive forecasting uncertainty\ncalibration, and (iii) agnostic towards forecasting models. The evaluation of\nRTS-PnO is conducted over both online and offline experiments. For offline\nexperiments, eight datasets from three categories of financial applications are\nused: Currency, Stock, and Cryptos. RTS-PnO consistently outperforms other\ncompetitive baselines. The online experiment is conducted on the Cross-Border\nPayment business at FiT, Tencent, and an 8.4\\% decrease in regret is witnessed\nwhen compared with the product-line approach. The code for the offline\nexperiment is available at https://github.com/fuyuanlyu/RTS-PnO.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u8d44\u91d1\u5206\u914d\u6846\u67b6RTS-PnO\uff0c\u5b83\u901a\u8fc7\u89e3\u51b3\u76ee\u6807\u4e0d\u5339\u914d\u548c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6765\u63d0\u9ad8\u8d44\u91d1\u5206\u914d\u51b3\u7b56\u7684\u8d28\u91cf\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u6734\u7d20\u7684\u8d44\u91d1\u5206\u914d\u89e3\u51b3\u65b9\u6848\u5982\u4ec5\u9884\u6d4b\u6216\u9884\u6d4b\u7136\u540e\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u4f1a\u5e26\u6765\u989d\u5916\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e9b\u95ee\u9898\u4fc3\u4f7f\u4e86RTS-PnO\u6846\u67b6\u7684\u53d1\u5c55\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u98ce\u9669\u611f\u77e5\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0e\u5206\u914d\u6846\u67b6\uff08RTS-PnO\uff09\uff0c\u5305\u542b\u7aef\u5230\u7aef\u8bad\u7ec3\u3001\u81ea\u9002\u5e94\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u4ee5\u53ca\u5bf9\u9884\u6d4b\u6a21\u578b\u7684\u65e0\u4f9d\u8d56\u6027\u4e09\u4e2a\u7279\u70b9\u3002", "result": "RTS-PnO\u5728\u6d89\u53ca\u8d27\u5e01\u3001\u80a1\u7968\u548c\u52a0\u5bc6\u8d27\u5e01\u7684\u91d1\u878d\u5e94\u7528\u4e2d\u7684\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5176\u8868\u73b0\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u7ade\u4e89\u57fa\u7ebf\u3002\u6b64\u5916\uff0c\u5728\u817e\u8bafFiT\u7684\u8de8\u5883\u652f\u4ed8\u4e1a\u52a1\u4e0a\u7684\u5728\u7ebf\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0e\u4ea7\u54c1\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u9057\u61be\u51cf\u5c11\u4e868.4%\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRTS-PnO\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u89e3\u51b3\u8d44\u91d1\u5206\u914d\u95ee\u9898\uff0c\u5e76\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u90fd\u8868\u73b0\u51fa\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u7684\u6548\u679c\u3002"}}
{"id": "2505.24842", "pdf": "https://arxiv.org/pdf/2505.24842", "abs": "https://arxiv.org/abs/2505.24842", "authors": ["Harsh Chaudhari", "Jamie Hayes", "Matthew Jagielski", "Ilia Shumailov", "Milad Nasr", "Alina Oprea"], "title": "Cascading Adversarial Bias from Injection to Distillation in Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Model distillation has become essential for creating smaller, deployable\nlanguage models that retain larger system capabilities. However, widespread\ndeployment raises concerns about resilience to adversarial manipulation. This\npaper investigates vulnerability of distilled models to adversarial injection\nof biased content during training. We demonstrate that adversaries can inject\nsubtle biases into teacher models through minimal data poisoning, which\npropagates to student models and becomes significantly amplified. We propose\ntwo propagation modes: Untargeted Propagation, where bias affects multiple\ntasks, and Targeted Propagation, focusing on specific tasks while maintaining\nnormal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning\nrate), student models generate biased responses 76.9% of the time in targeted\nscenarios - higher than 69.4% in teacher models. For untargeted propagation,\nadversarial bias appears 6x-29x more frequently in student models on unseen\ntasks. We validate findings across six bias types (targeted advertisements,\nphishing links, narrative manipulations, insecure coding practices), various\ndistillation methods, and different modalities spanning text and code\ngeneration. Our evaluation reveals shortcomings in current defenses -\nperplexity filtering, bias detection systems, and LLM-based autorater\nframeworks - against these attacks. Results expose significant security\nvulnerabilities in distilled models, highlighting need for specialized\nsafeguards. We propose practical design principles for building effective\nadversarial bias mitigation strategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u6a21\u578b\u84b8\u998f\u8fc7\u7a0b\u4e2d\u5bf9\u6297\u6027\u504f\u5dee\u6ce8\u5165\u7684\u98ce\u9669\uff0c\u53d1\u73b0\u5c11\u91cf\u4e2d\u6bd2\u6837\u672c\u5373\u53ef\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u663e\u8457\u653e\u5927\u504f\u5dee\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u9632\u5fa1\u624b\u6bb5\u7684\u4e0d\u8db3\u3002", "motivation": "\u6a21\u578b\u84b8\u998f\u5728\u521b\u5efa\u8f83\u5c0f\u3001\u53ef\u90e8\u7f72\u7684\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u64cd\u7eb5\u65f6\u7684\u97e7\u6027\u95ee\u9898\u5f15\u53d1\u4e86\u5173\u6ce8\u3002", "method": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8bad\u7ec3\u671f\u95f4\u901a\u8fc7\u6700\u5c0f\u6570\u636e\u6295\u6bd2\u6ce8\u5165\u504f\u5dee\u7684\u65b9\u5f0f\uff0c\u5206\u6790\u4e86\u4e24\u79cd\u4f20\u64ad\u6a21\u5f0f\uff1a\u65e0\u76ee\u6807\u4f20\u64ad\u548c\u6709\u76ee\u6807\u4f20\u64ad\uff0c\u5e76\u8bc4\u4f30\u4e86\u5f53\u524d\u9632\u5fa1\u65b9\u6cd5\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u624b\u53ef\u4ee5\u901a\u8fc7\u5c11\u91cf\u4e2d\u6bd2\u6837\u672c\u5c06\u504f\u5dee\u6ce8\u5165\u6559\u5e08\u6a21\u578b\uff0c\u8fd9\u4e9b\u504f\u5dee\u4f1a\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u663e\u8457\u653e\u5927\u3002\u5728\u76ee\u6807\u573a\u666f\u4e0b\uff0c\u5b66\u751f\u6a21\u578b\u751f\u6210\u504f\u5dee\u54cd\u5e94\u7684\u6982\u7387\u4e3a76.9%\uff0c\u800c\u6559\u5e08\u6a21\u578b\u4e3a69.4%\u3002\u5bf9\u4e8e\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\uff0c\u5b66\u751f\u6a21\u578b\u4e2d\u7684\u5bf9\u6297\u504f\u5dee\u51fa\u73b0\u9891\u7387\u662f\u6559\u5e08\u6a21\u578b\u76846-29\u500d\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u84b8\u998f\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\uff0c\u5e76\u63d0\u51fa\u4e86\u6784\u5efa\u6709\u6548\u5bf9\u6297\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u7684\u5b9e\u7528\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2505.24843", "pdf": "https://arxiv.org/pdf/2505.24843", "abs": "https://arxiv.org/abs/2505.24843", "authors": ["Ruqi Bai", "Yao Ji", "Zeyu Zhou", "David I. Inouye"], "title": "From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching", "categories": ["cs.LG"], "comment": null, "summary": "Spurious correlations can cause model performance to degrade in new\nenvironments. Prior causality-inspired works aim to learn invariant\nrepresentations (e.g., IRM) but typically underperform empirical risk\nminimization (ERM). Recent alternatives improve robustness by leveraging\ntest-time data, but such data may be unavailable in practice. To address these\nissues, we take a data-centric approach by leveraging invariant data pairs,\npairs of samples that would have the same prediction with the optimally robust\nclassifier. We prove that certain counterfactual pairs will naturally satisfy\nthis invariance property and introduce noisy counterfactual matching (NCM), a\nsimple constraint-based method for leveraging invariant pairs for enhanced\nrobustness, even with a small set of noisy pairs-in the ideal case, each pair\ncan eliminate one spurious feature. For linear causal models, we prove that the\ntest domain error can be upper bounded by the in-domain error and a term that\ndepends on the counterfactuals' diversity and quality. We validate on a\nsynthetic dataset and demonstrate on real-world benchmarks that linear probing\non a pretrained backbone improves robustness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a\u566a\u58f0\u53cd\u4e8b\u5b9e\u5339\u914d\uff08NCM\uff09\uff0c\u5373\u4f7f\u5728\u5c0f\u89c4\u6a21\u548c\u6709\u566a\u58f0\u7684\u6570\u636e\u5bf9\u4e2d\u4e5f\u6709\u6548\u3002", "motivation": "\u865a\u5047\u76f8\u5173\u6027\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u65b0\u73af\u5883\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u7684\u56e0\u679c\u542f\u53d1\u65b9\u6cd5\u901a\u5e38\u8868\u73b0\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u6d4b\u8bd5\u65f6\u6570\u636e\u53ef\u80fd\u4e0d\u53ef\u7528\u3002", "method": "\u5f15\u5165\u4e86\u566a\u58f0\u53cd\u4e8b\u5b9e\u5339\u914d\uff08NCM\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5177\u6709\u4e0d\u53d8\u6027\u7684\u6570\u636e\u5bf9\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u3002", "result": "\u8bba\u6587\u8bc1\u660e\u4e86\u67d0\u4e9b\u53cd\u4e8b\u5b9e\u5bf9\u81ea\u7136\u6ee1\u8db3\u4e0d\u53d8\u6027\u5c5e\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7ebf\u6027\u63a2\u6d4b\u9884\u8bad\u7ec3\u4e3b\u5e72\u4e0a\u63d0\u5347\u9c81\u68d2\u6027\u7684\u80fd\u529b\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNCM\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e0d\u53d8\u7684\u6570\u636e\u5bf9\u6765\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24844", "pdf": "https://arxiv.org/pdf/2505.24844", "abs": "https://arxiv.org/abs/2505.24844", "authors": ["Wanyun Xie", "Francesco Tonin", "Volkan Cevher"], "title": "Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning", "categories": ["cs.LG", "cs.CL"], "comment": "ICML 2025", "summary": "Training data mixtures greatly impact the generalization performance of large\nlanguage models. Existing domain reweighting methods often rely on costly\nweight computations and require retraining when new data is introduced. To this\nend, we introduce a flexible and efficient data mixing framework, Chameleon,\nthat employs leverage scores to quantify domain importance within a learned\nembedding space. We first construct a domain affinity matrix over domain\nembeddings. The induced leverage scores determine a mixture that upweights\ndomains sharing common representations in embedding space. This formulation\nallows direct transfer to new data by computing the new domain embeddings. In\nexperiments, we demonstrate improvements over three key scenarios: (i) our\ncomputed weights improve performance on pretraining domains with a fraction of\nthe compute of existing methods; (ii) Chameleon can adapt to data changes\nwithout proxy retraining, boosting few-shot reasoning accuracies when\ntransferred to new data; (iii) our method enables efficient domain reweighting\nin finetuning, consistently improving test perplexity on all finetuning domains\nover uniform mixture. Our code is available at\nhttps://github.com/LIONS-EPFL/Chameleon.", "AI": {"tldr": "Chameleon\u662f\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u7a7a\u95f4\u4e2d\u57df\u8868\u793a\u7684\u9ad8\u6548\u6570\u636e\u6df7\u5408\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57df\u91cd\u52a0\u6743\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u7684\u6743\u91cd\u8ba1\u7b97\uff0c\u5e76\u4e14\u5728\u5f15\u5165\u65b0\u6570\u636e\u65f6\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6760\u6746\u5f97\u5206\uff08leverage scores\uff09\u6765\u91cf\u5316\u57df\u5728\u5b66\u4e60\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6784\u5efa\u57df\u4eb2\u548c\u77e9\u9635\u4ee5\u786e\u5b9a\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u8ba1\u7b97\u65b0\u57df\u7684\u5d4c\u5165\u76f4\u63a5\u8f6c\u79fb\u5230\u65b0\u6570\u636e\u4e0a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cChameleon\u5728\u591a\u4e2a\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff1a(i) \u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u9884\u8bad\u7ec3\u57df\u4e0a\u7684\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u4e14\u6027\u80fd\u66f4\u597d\uff1b(ii) \u5728\u65e0\u9700\u4ee3\u7406\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9002\u5e94\u65b0\u6570\u636e\u53d8\u5316\uff0c\u63d0\u9ad8\u4e86\u5c11\u6837\u672c\u63a8\u7406\u51c6\u786e\u6027\uff1b(iii) \u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u57df\u91cd\u52a0\u6743\uff0c\u5e76\u5728\u6240\u6709\u5fae\u8c03\u57df\u4e0a\u4e00\u81f4\u5730\u6539\u5584\u4e86\u6d4b\u8bd5\u56f0\u60d1\u5ea6\u3002", "conclusion": "Chameleon\u662f\u4e00\u4e2a\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u6570\u636e\u6df7\u5408\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5229\u7528\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u57df\u8868\u793a\u6765\u91cf\u5316\u57df\u91cd\u8981\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u671f\u95f4\u7684\u6a21\u578b\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.24857", "pdf": "https://arxiv.org/pdf/2505.24857", "abs": "https://arxiv.org/abs/2505.24857", "authors": ["Heli Ben-Hamu", "Itai Gat", "Daniel Severo", "Niklas Nolte", "Brian Karrer"], "title": "Accelerated Sampling from Masked Diffusion Models via Entropy Bounded Unmasking", "categories": ["cs.LG"], "comment": null, "summary": "Recent masked diffusion models (MDMs) have shown competitive performance\ncompared to autoregressive models (ARMs) for language modeling. While most\nliterature has focused on performance enhancing sampling procedures, efficient\nsampling from MDMs has been scarcely explored. We make the observation that\noften a given sequence of partially masked tokens determines the values of\nmultiple unknown tokens deterministically, meaning that a single prediction of\na masked model holds additional information unused by standard sampling\nprocedures. Based on this observation, we introduce EB-Sampler, a simple\ndrop-in replacement for existing samplers, utilizing an Entropy Bounded\nunmasking procedure that dynamically unmasks multiple tokens in one function\nevaluation with predefined approximate error tolerance. We formulate the\nEB-Sampler as part of a broad family of adaptive samplers for which we provide\nan error analysis that motivates our algorithmic choices. EB-Sampler\naccelerates sampling from current state of the art MDMs by roughly 2-3x on\nstandard coding and math reasoning benchmarks without loss in performance. We\nalso validate the same procedure works well on smaller reasoning tasks\nincluding maze navigation and Sudoku, tasks ARMs often struggle with.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEB-Sampler\u7684\u65b0\u91c7\u6837\u5668\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u7684\u91c7\u6837\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u7a33\u5b9a\u3002", "motivation": "\u5c3d\u7ba1MDMs\u5728\u8bed\u8a00\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u6548\u91c7\u6837\u65b9\u6cd5\u7684\u7814\u7a76\u76f8\u5bf9\u532e\u4e4f\u3002\u89c2\u5bdf\u53d1\u73b0\uff0c\u90e8\u5206\u63a9\u7801\u5e8f\u5217\u80fd\u591f\u786e\u5b9a\u591a\u4e2a\u672a\u77e5\u4ee4\u724c\u7684\u503c\uff0c\u8fd9\u8868\u660e\u6807\u51c6\u91c7\u6837\u7a0b\u5e8f\u672a\u5145\u5206\u5229\u7528\u63a9\u7801\u6a21\u578b\u4e2d\u7684\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u754c\u7684\u89e3\u63a9\u7801\u8fc7\u7a0b\u7684\u65b0\u578b\u91c7\u6837\u5668EB-Sampler\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u73b0\u6709\u91c7\u6837\u5668\u7684\u7b80\u5355\u66ff\u4ee3\u54c1\u3002", "result": "EB-Sampler\u5728\u6807\u51c6\u7f16\u7801\u548c\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06MDMs\u7684\u91c7\u6837\u901f\u5ea6\u63d0\u9ad8\u4e86\u7ea62-3\u500d\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5c0f\u578b\u63a8\u7406\u4efb\u52a1\uff08\u5982\u8ff7\u5bab\u5bfc\u822a\u548c\u6570\u72ec\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "EB-Sampler\u901a\u8fc7\u5229\u7528\u5355\u6b21\u9884\u6d4b\u4e2d\u7684\u989d\u5916\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86MDMs\u7684\u91c7\u6837\u6548\u7387\uff0c\u4e14\u6ca1\u6709\u6027\u80fd\u635f\u5931\u3002"}}
{"id": "2505.24859", "pdf": "https://arxiv.org/pdf/2505.24859", "abs": "https://arxiv.org/abs/2505.24859", "authors": ["Joschka Braun", "Carsten Eickhoff", "Seyed Ali Bahrainian"], "title": "Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization", "categories": ["cs.LG", "cs.CL"], "comment": "29 pages, 21 figures, preprint", "summary": "Steering vectors are a lightweight method for controlling text properties by\nadding a learned bias to language model activations at inference time. So far,\nsteering vectors have predominantly been evaluated in multiple-choice settings,\nwhile their effectiveness in free-form generation tasks remains understudied.\nMoving \"Beyond Multiple Choice,\" we thoroughly evaluate the effectiveness of\nsteering vectors in adaptively controlling topical focus, sentiment, toxicity,\nand readability in abstractive summaries of the NEWTS dataset. We find that\nsteering effectively controls the targeted summary properties, but high\nsteering strengths consistently degrade both intrinsic and extrinsic text\nquality. Compared to steering, prompting offers weaker control, while\npreserving text quality. Combining steering and prompting yields the strongest\ncontrol over text properties and offers the most favorable efficacy-quality\ntrade-off at moderate steering strengths. Our results underscore the practical\ntrade-off between control strength and text quality preservation when applying\nsteering vectors to free-form generation tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86steering vectors\u5728\u81ea\u7531\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u63a7\u5236\u6548\u679c\uff0c\u5e76\u6307\u51fa\u63a7\u5236\u5f3a\u5ea6\u4e0e\u6587\u672c\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "Steering vectors\u76ee\u524d\u4e3b\u8981\u5728\u591a\u9879\u9009\u62e9\u73af\u5883\u4e2d\u88ab\u8bc4\u4f30\uff0c\u800c\u5b83\u4eec\u5728\u81ea\u7531\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5728NEWTS\u6570\u636e\u96c6\u7684\u6458\u8981\u4e0a\u4f7f\u7528steering vectors\u6765\u8bc4\u4f30\u5176\u5bf9\u4e3b\u9898\u7126\u70b9\u3001\u60c5\u611f\u3001\u6bd2\u6027\u4ee5\u53ca\u53ef\u8bfb\u6027\u7684\u9002\u5e94\u6027\u63a7\u5236\u6548\u679c\uff0c\u5e76\u4e0eprompting\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0csteering vectors\u80fd\u591f\u6709\u6548\u63a7\u5236\u76ee\u6807\u6458\u8981\u5c5e\u6027\uff0c\u4f46\u9ad8\u5f3a\u5ea6\u7684steering\u4f1a\u964d\u4f4e\u6587\u672c\u7684\u5185\u5728\u548c\u5916\u5728\u8d28\u91cf\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0cprompting\u63a7\u5236\u80fd\u529b\u8f83\u5f31\u4f46\u80fd\u4fdd\u6301\u6587\u672c\u8d28\u91cf\uff1b\u5c06\u4e24\u8005\u7ed3\u5408\u53ef\u4ee5\u5728\u9002\u5ea6\u7684steering\u5f3a\u5ea6\u4e0b\u5b9e\u73b0\u6700\u4f73\u63a7\u5236\u6548\u679c\u548c\u6700\u4f18\u7684\u8d28\u91cf\u6743\u8861\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5728\u81ea\u7531\u751f\u6210\u4efb\u52a1\u4e2d\u5e94\u7528steering vectors\u65f6\uff0c\u63a7\u5236\u5f3a\u5ea6\u4e0e\u6587\u672c\u8d28\u91cf\u4fdd\u6301\u4e4b\u95f4\u5b58\u5728\u5b9e\u9645\u7684\u6743\u8861\u3002"}}
{"id": "2505.24874", "pdf": "https://arxiv.org/pdf/2505.24874", "abs": "https://arxiv.org/abs/2505.24874", "authors": ["Adam Stein", "Aaditya Naik", "Neelay Velingker", "Mayur Naik", "Eric Wong"], "title": "The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models", "categories": ["cs.LG"], "comment": "19 pages, 11 figures", "summary": "Neuro-symbolic learning was proposed to address challenges with training\nneural networks for complex reasoning tasks with the added benefits of\ninterpretability, reliability, and efficiency. Neuro-symbolic learning methods\ntraditionally train neural models in conjunction with symbolic programs, but\nthey face significant challenges that limit them to simplistic problems. On the\nother hand, purely-neural foundation models now reach state-of-the-art\nperformance through prompting rather than training, but they are often\nunreliable and lack interpretability. Supplementing foundation models with\nsymbolic programs, which we call neuro-symbolic prompting, provides a way to\nuse these models for complex reasoning tasks. Doing so raises the question:\nWhat role does specialized model training as part of neuro-symbolic learning\nhave in the age of foundation models? To explore this question, we highlight\nthree pitfalls of traditional neuro-symbolic learning with respect to the\ncompute, data, and programs leading to generalization problems. This position\npaper argues that foundation models enable generalizable neuro-symbolic\nsolutions, offering a path towards achieving the original goals of\nneuro-symbolic learning without the downsides of training from scratch.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u4e86\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u7ed3\u5408\u5982\u4f55\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u5904\u7406\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u4f20\u7edf\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u7b80\u5355\u95ee\u9898\uff0c\u800c\u7eaf\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\u6a21\u578b\u5b58\u5728\u4e0d\u53ef\u9760\u6027\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u4f20\u7edf\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u5728\u8ba1\u7b97\u3001\u6570\u636e\u548c\u7a0b\u5e8f\u65b9\u9762\u7684\u4e09\u4e2a\u7f3a\u9677\uff0c\u4ee5\u53ca\u57fa\u7840\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u63a2\u8ba8\u4e86\u795e\u7ecf\u7b26\u53f7\u63d0\u793a\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u7b26\u53f7\u7a0b\u5e8f\u7684\u795e\u7ecf\u7b26\u53f7\u63d0\u793a\u65b9\u6cd5\u53ef\u4ee5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u57fa\u7840\u6a21\u578b\u53ef\u80fd\u514b\u670d\u4f20\u7edf\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u5c40\u9650\u6027\u7684\u89c2\u70b9\u3002", "conclusion": "\u672c\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u57fa\u7840\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u53ef\u63a8\u5e7f\u7684\u795e\u7ecf\u7b26\u53f7\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5b9e\u73b0\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u7684\u539f\u59cb\u76ee\u6807\u63d0\u4f9b\u4e86\u9014\u5f84\uff0c\u5e76\u907f\u514d\u4e86\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u7f3a\u70b9\u3002"}}
{"id": "2505.05880", "pdf": "https://arxiv.org/pdf/2505.05880", "abs": "https://arxiv.org/abs/2505.05880", "authors": ["Bettina Fazzinga", "Sergio Flesca", "Filippo Furfaro", "Luigi Pontieri", "Francesco Scala"], "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u57fa\u4e8e\u793a\u4f8b\u7684\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\u548c\u57fa\u4e8e\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff08AAF\uff09\u7684\u63a8\u7406\u5668\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8fc7\u7a0b\u8ddf\u8e2a\u4e2d\u4e8b\u4ef6\u5230\u6d3b\u52a8\u6620\u5c04\u7684\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u4ece\u800c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u9ad8\u6548\u7684\u89e3\u91ca\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u516c\u53f8\u548c\u7ec4\u7ec7\u9700\u8981\u76d1\u63a7\u548c\u5206\u6790\u8fc7\u7a0b\u8ddf\u8e2a\uff0c\u4f46\u5728\u8ddf\u8e2a\u4e8b\u4ef6\u4e0e\u53c2\u8003\u4e1a\u52a1\u6d3b\u52a8\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u65f6\uff0c\u8fd9\u4f1a\u6210\u4e3a\u4e00\u4e2a\u89e3\u91ca\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11\u52b3\u52a8\u548c\u8ba1\u7b97\u6210\u672c\u4ee5\u53ca\u78b3\u8db3\u8ff9\uff0c\u540c\u65f6\u6ee1\u8db3\u7eff\u8272\u4eba\u5de5\u667a\u80fd\u7684\u9700\u6c42\u3002", "method": "\u8bba\u6587\u7684\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff08AAF\uff09\u6765\u5206\u6790\u53ef\u80fd\u7684\u4e8b\u4ef6\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4ee5\u60c5\u5883\u611f\u77e5\u7684\u65b9\u5f0f\u5efa\u8bae\u9ad8\u6982\u7387\u7684\u5019\u9009\u4e8b\u4ef6\u89e3\u91ca\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u57fa\u4e8e\u793a\u4f8b\u7684\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\u548c\u57fa\u4e8eAAF\u7684\u63a8\u7406\u5668\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u5e76\u51cf\u5c11\u5bf9\u5927\u91cf\u624b\u52a8\u6ce8\u91ca\u6570\u636e\u7684\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u4e8b\u4ef6\u5230\u6d3b\u52a8\u6620\u5c04\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u6709\u6548\u5de5\u4f5c\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u793a\u4f8b\u7684\u5e8f\u5217\u6807\u6ce8\u5668\u548c\u57fa\u4e8eAAF\u7684\u63a8\u7406\u5668\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6982\u7387\u7684\u5019\u9009\u89e3\u91ca\uff0c\u5e76\u4e14\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u5f25\u8865\u4e86\u793a\u4f8b\u6570\u636e\u7684\u4e0d\u8db3\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u5c06\u57fa\u4e8e\u793a\u4f8b\u7684\u5e8f\u5217\u6807\u6ce8\u5668\u4e0e\u57fa\u4e8eAAF\u7684\u63a8\u7406\u5668\u7ed3\u5408\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6570\u636e\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u4e8b\u4ef6\u5230\u6d3b\u52a8\u6620\u5c04\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u9ad8\u6982\u7387\u7684\u5019\u9009\u89e3\u91ca\uff0c\u5e76\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u8865\u507f\u793a\u4f8b\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002"}}
