{"id": "2505.20306", "pdf": "https://arxiv.org/pdf/2505.20306", "abs": "https://arxiv.org/abs/2505.20306", "authors": ["Xueqiang Ouyang", "Jia Wei"], "title": "Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review", "categories": ["cs.AI", "eess.IV", "q-bio.QM"], "comment": null, "summary": "As a global disease, infertility has always affected human beings. The\ndevelopment of assisted reproductive technology can effectively solve this\ndisease. However, the traditional in vitro fertilization-embryo transfer\ntechnology still faces many challenges in improving the success rate of\npregnancy, such as the subjectivity of embryo grading and the inefficiency of\nintegrating multi-modal data. Therefore, the introduction of artificial\nintelligence-based technologies is particularly crucial. This article reviews\nthe application progress of multi-modal artificial intelligence in embryo\ngrading and pregnancy prediction based on different data modalities (including\nstatic images, time-lapse videos and structured table data) from a new\nperspective, and discusses the main challenges in current research, such as the\ncomplexity of multi-modal information fusion and data scarcity."}
{"id": "2505.20351", "pdf": "https://arxiv.org/pdf/2505.20351", "abs": "https://arxiv.org/abs/2505.20351", "authors": ["Tomer Shoham", "Katrina Ligettt"], "title": "Differentially private ratio statistics", "categories": ["stat.ML", "cs.LG"], "comment": "32 pages, 3 figures, under review", "summary": "Ratio statistics--such as relative risk and odds ratios--play a central role\nin hypothesis testing, model evaluation, and decision-making across many areas\nof machine learning, including causal inference and fairness analysis. However,\ndespite privacy concerns surrounding many datasets and despite increasing\nadoption of differential privacy, differentially private ratio statistics have\nlargely been neglected by the literature and have only recently received an\ninitial treatment by Lin et al. [1]. This paper attempts to fill this lacuna,\ngiving results that can guide practice in evaluating ratios when the results\nmust be protected by differential privacy. In particular, we show that even a\nsimple algorithm can provide excellent properties concerning privacy, sample\naccuracy, and bias, not just asymptotically but also at quite small sample\nsizes. Additionally, we analyze a differentially private estimator for relative\nrisk, prove its consistency, and develop a method for constructing valid\nconfidence intervals. Our approach bridges a gap in the differential privacy\nliterature and provides a practical solution for ratio estimation in private\nmachine learning pipelines."}
{"id": "2505.20310", "pdf": "https://arxiv.org/pdf/2505.20310", "abs": "https://arxiv.org/abs/2505.20310", "authors": ["Wanghan Xu", "Wenlong Zhang", "Fenghua Ling", "Ben Fei", "Yusong Hu", "Fangxuan Ren", "Jintai Lin", "Wanli Ouyang", "Lei Bai"], "title": "Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Meta-analysis is a systematic research methodology that synthesizes data from\nmultiple existing studies to derive comprehensive conclusions. This approach\nnot only mitigates limitations inherent in individual studies but also\nfacilitates novel discoveries through integrated data analysis. Traditional\nmeta-analysis involves a complex multi-stage pipeline including literature\nretrieval, paper screening, and data extraction, which demands substantial\nhuman effort and time. However, while LLM-based methods can accelerate certain\nstages, they still face significant challenges, such as hallucinations in paper\nscreening and data extraction. In this paper, we propose a multi-agent system,\nManalyzer, which achieves end-to-end automated meta-analysis through tool\ncalls. The hybrid review, hierarchical extraction, self-proving, and feedback\nchecking strategies implemented in Manalyzer significantly alleviate these two\nhallucinations. To comprehensively evaluate the performance of meta-analysis,\nwe construct a new benchmark comprising 729 papers across 3 domains,\nencompassing text, image, and table modalities, with over 10,000 data points.\nExtensive experiments demonstrate that Manalyzer achieves significant\nperformance improvements over the LLM baseline in multi meta-analysis tasks.\nProject page: https://black-yt.github.io/meta-analysis-page/ ."}
{"id": "2505.20433", "pdf": "https://arxiv.org/pdf/2505.20433", "abs": "https://arxiv.org/abs/2505.20433", "authors": ["Masha Naslidnyk", "Siu Lun Chau", "Fran√ßois-Xavier Briol", "Krikamol Muandet"], "title": "Kernel Quantile Embeddings and Associated Probability Metrics", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Embedding probability distributions into reproducing kernel Hilbert spaces\n(RKHS) has enabled powerful nonparametric methods such as the maximum mean\ndiscrepancy (MMD), a statistical distance with strong theoretical and\ncomputational properties. At its core, the MMD relies on kernel mean embeddings\nto represent distributions as mean functions in RKHS. However, it remains\nunclear if the mean function is the only meaningful RKHS representation.\nInspired by generalised quantiles, we introduce the notion of kernel quantile\nembeddings (KQEs). We then use KQEs to construct a family of distances that:\n(i) are probability metrics under weaker kernel conditions than MMD; (ii)\nrecover a kernelised form of the sliced Wasserstein distance; and (iii) can be\nefficiently estimated with near-linear cost. Through hypothesis testing, we\nshow that these distances offer a competitive alternative to MMD and its fast\napproximations."}
{"id": "2505.20313", "pdf": "https://arxiv.org/pdf/2505.20313", "abs": "https://arxiv.org/abs/2505.20313", "authors": ["Son Tran", "Edjard Mota", "Artur d'Avila Garcez"], "title": "Reasoning in Neurosymbolic AI", "categories": ["cs.AI", "cs.LO"], "comment": "50 pages, 13 figures, 56 references. Keywords: Neurosymbolic AI,\n  Restricted Boltzmann Machines, Logical Reasoning, SAT solving, MaxSAT,\n  Energy-based Learning, Constrained Optimization, Modular Deep Learning", "summary": "Knowledge representation and reasoning in neural networks have been a\nlong-standing endeavor which has attracted much attention recently. The\nprincipled integration of reasoning and learning in neural networks is a main\nobjective of the area of neurosymbolic Artificial Intelligence (AI). In this\nchapter, a simple energy-based neurosymbolic AI system is described that can\nrepresent and reason formally about any propositional logic formula. This\ncreates a powerful combination of learning from data and knowledge and logical\nreasoning. We start by positioning neurosymbolic AI in the context of the\ncurrent AI landscape that is unsurprisingly dominated by Large Language Models\n(LLMs). We identify important challenges of data efficiency, fairness and\nsafety of LLMs that might be addressed by neurosymbolic reasoning systems with\nformal reasoning capabilities. We then discuss the representation of logic by\nthe specific energy-based system, including illustrative examples and empirical\nevaluation of the correspondence between logical reasoning and energy\nminimization using Restricted Boltzmann Machines (RBM). Learning from data and\nknowledge is also evaluated empirically and compared with a symbolic, neural\nand a neurosymbolic system. Results reported in this chapter in an accessible\nway are expected to reignite the research on the use of neural networks as\nmassively-parallel models for logical reasoning and promote the principled\nintegration of reasoning and learning in deep networks. We conclude the chapter\nwith a discussion of the importance of positioning neurosymbolic AI within a\nbroader framework of formal reasoning and accountability in AI, discussing the\nchallenges for neurosynbolic AI to tackle the various known problems of\nreliability of deep learning."}
{"id": "2505.20465", "pdf": "https://arxiv.org/pdf/2505.20465", "abs": "https://arxiv.org/abs/2505.20465", "authors": ["Lorenzo Lucchese", "Mikko S. Pakkanen", "Almut E. D. Veraart"], "title": "Learning with Expected Signatures: Theory and Applications", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The expected signature maps a collection of data streams to a lower\ndimensional representation, with a remarkable property: the resulting feature\ntensor can fully characterize the data generating distribution. This\n\"model-free\" embedding has been successfully leveraged to build multiple\ndomain-agnostic machine learning (ML) algorithms for time series and sequential\ndata. The convergence results proved in this paper bridge the gap between the\nexpected signature's empirical discrete-time estimator and its theoretical\ncontinuous-time value, allowing for a more complete probabilistic\ninterpretation of expected signature-based ML methods. Moreover, when the data\ngenerating process is a martingale, we suggest a simple modification of the\nexpected signature estimator with significantly lower mean squared error and\nempirically demonstrate how it can be effectively applied to improve predictive\nperformance."}
{"id": "2505.20316", "pdf": "https://arxiv.org/pdf/2505.20316", "abs": "https://arxiv.org/abs/2505.20316", "authors": ["Yingpeng Du", "Tianjun Wei", "Zhu Sun", "Jie Zhang"], "title": "Reinforcement Speculative Decoding for Fast Ranking", "categories": ["cs.AI", "H.4.0"], "comment": "21 pages, 5 figures, 5 table", "summary": "Large Language Models (LLMs) have been widely adopted in ranking systems such\nas information retrieval (IR) systems and recommender systems (RSs). To\nalleviate the latency of auto-regressive decoding, some studies explore the\nsingle (first) token decoding for ranking approximation, but they suffer from\nsevere degradation in tail positions. Although speculative decoding (SD)\nmethods can be a remedy with verification at different positions, they face\nchallenges in ranking systems due to their left-to-right decoding paradigm.\nFirstly, ranking systems require strict latency constraints, but verification\nrounds in SD methods remain agnostic; Secondly, SD methods usually discard\nlistwise ranking knowledge about unaccepted items in previous rounds, hindering\nfuture multi-token prediction, especially when candidate tokens are the\nunaccepted items. In this paper, we propose a Reinforcement Speculative\nDecoding method for fast ranking inference of LLMs. To meet the ranking\nsystems' latency requirement, we propose an up-to-down decoding paradigm that\nemploys an agent to iteratively modify the ranking sequence under a constrained\nbudget. Specifically, we design a ranking-tailored policy optimization,\nactively exploring optimal multi-round ranking modification policy verified by\nLLMs via reinforcement learning (RL). To better approximate the target LLM\nunder the constrained budget, we trigger the agent fully utilizing the listwise\nranking knowledge about all items verified by LLMs across different rounds in\nRL, enhancing the modification policy of the agent. More importantly, we\ndemonstrate the theoretical robustness and advantages of our paradigm and\nimplementation. Experiments on both IR and RS tasks show the effectiveness of\nour proposed method."}
{"id": "2505.20536", "pdf": "https://arxiv.org/pdf/2505.20536", "abs": "https://arxiv.org/abs/2505.20536", "authors": ["Guanhao Zhou", "Yuefeng Han", "Xiufan Yu"], "title": "Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "comment": null, "summary": "This paper studies the task of estimating heterogeneous treatment effects in\ncausal panel data models, in the presence of covariate effects. We propose a\nnovel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,\nthat employs flexible model structures and powerful neural network\narchitectures to cohesively deal with the underlying heterogeneity and\nnonlinearity of both panel units and covariate effects. The proposed CoDEAL\nintegrates nonlinear covariate effect components (parameterized by a\nfeed-forward neural network) with nonlinear factor structures (modeled by a\nmulti-output autoencoder) to form a heterogeneous causal panel model. The\nnonlinear covariate component offers a flexible framework for capturing the\ncomplex influences of covariates on outcomes. The nonlinear factor analysis\nenables CoDEAL to effectively capture both cross-sectional and temporal\ndependencies inherent in the data panel. This latent structural information is\nsubsequently integrated into a customized matrix completion algorithm, thereby\nfacilitating more accurate imputation of missing counterfactual outcomes.\nMoreover, the use of a multi-output autoencoder explicitly accounts for\nheterogeneity across units and enhances the model interpretability of the\nlatent factors. We establish theoretical guarantees on the convergence of the\nestimated counterfactuals, and demonstrate the compelling performance of the\nproposed method using extensive simulation studies and a real data application."}
{"id": "2505.20300", "pdf": "https://arxiv.org/pdf/2505.20300", "abs": "https://arxiv.org/abs/2505.20300", "authors": ["Chenxi Wu", "Juan Diego Toscano", "Khemraj Shukla", "Yingjie Chen", "Ali Shahmohammadi", "Edward Raymond", "Thomas Toupy", "Neda Nazemifard", "Charles Papageorgiou", "George Em Karniadakis"], "title": "FMEnets: Flow, Material, and Energy networks for non-ideal plug flow reactor design", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We propose FMEnets, a physics-informed machine learning framework for the\ndesign and analysis of non-ideal plug flow reactors. FMEnets integrates the\nfundamental governing equations (Navier-Stokes for fluid flow, material balance\nfor reactive species transport, and energy balance for temperature\ndistribution) into a unified multi-scale network model. The framework is\ncomposed of three interconnected sub-networks with independent optimizers that\nenable both forward and inverse problem-solving. In the forward mode, FMEnets\npredicts velocity, pressure, species concentrations, and temperature profiles\nusing only inlet and outlet information. In the inverse mode, FMEnets utilizes\nsparse multi-residence-time measurements to simultaneously infer unknown\nkinetic parameters and states. FMEnets can be implemented either as FME-PINNs,\nwhich employ conventional multilayer perceptrons, or as FME-KANs, based on\nKolmogorov-Arnold Networks. Comprehensive ablation studies highlight the\ncritical role of the FMEnets architecture in achieving accurate predictions.\nSpecifically, FME-KANs are more robust to noise than FME-PINNs, although both\nrepresentations are comparable in accuracy and speed in noise-free conditions.\nThe proposed framework is applied to three different sets of reaction scenarios\nand is compared with finite element simulations. FMEnets effectively captures\nthe complex interactions, achieving relative errors less than 2.5% for the\nunknown kinetic parameters. The new network framework not only provides a\ncomputationally efficient alternative for reactor design and optimization, but\nalso opens new avenues for integrating empirical correlations, limited and\nnoisy experimental data, and fundamental physical equations to guide reactor\ndesign."}
{"id": "2505.20339", "pdf": "https://arxiv.org/pdf/2505.20339", "abs": "https://arxiv.org/abs/2505.20339", "authors": ["Antoni Gomila", "Vincent C. M√ºller"], "title": "Challenges for artificial cognitive systems", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The declared goal of this paper is to fill this gap: \"... cognitive systems\nresearch needs questions or challenges that define progress. The challenges are\nnot (yet more) predictions of the future, but a guideline to what are the aims\nand what would constitute progress.\" -- the quotation being from the project\ndescription of EUCogII, the project for the European Network for Cognitive\nSystems within which this formulation of the 'challenges' was originally\ndeveloped (http://www.eucognition.org). So, we stick out our neck and formulate\nthe challenges for artificial cognitive systems. These challenges are\narticulated in terms of a definition of what a cognitive system is: a system\nthat learns from experience and uses its acquired knowledge (both declarative\nand practical) in a flexible manner to achieve its own goals."}
{"id": "2505.20583", "pdf": "https://arxiv.org/pdf/2505.20583", "abs": "https://arxiv.org/abs/2505.20583", "authors": ["Michael O. Harding", "Kirthevasan Kandasamy"], "title": "Balancing Performance and Costs in Best Arm Identification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We consider the problem of identifying the best arm in a multi-armed bandit\nmodel. Despite a wealth of literature in the traditional fixed budget and fixed\nconfidence regimes of the best arm identification problem, it still remains a\nmystery to most practitioners as to how to choose an approach and corresponding\nbudget or confidence parameter. We propose a new formalism to avoid this\ndilemma altogether by minimizing a risk functional which explicitly balances\nthe performance of the recommended arm and the cost incurred by learning this\narm. In this framework, a cost is incurred for each observation during the\nsampling phase, and upon recommending an arm, a performance penalty is incurred\nfor identifying a suboptimal arm. The learner's goal is to minimize the sum of\nthe penalty and cost. This new regime mirrors the priorities of many\npractitioners, e.g. maximizing profit in an A/B testing framework, better than\nclassical fixed budget or confidence settings. We derive theoretical lower\nbounds for the risk of each of two choices for the performance penalty, the\nprobability of misidentification and the simple regret, and propose an\nalgorithm called DBCARE to match these lower bounds up to polylog factors on\nnearly all problem instances. We then demonstrate the performance of DBCARE on\na number of simulated models, comparing to fixed budget and confidence\nalgorithms to show the shortfalls of existing BAI paradigms on this problem."}
{"id": "2505.20330", "pdf": "https://arxiv.org/pdf/2505.20330", "abs": "https://arxiv.org/abs/2505.20330", "authors": ["Yunfu Song", "Zhijian Ou"], "title": "Joint-stochastic-approximation Random Fields with Application to Semi-supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2018 submission. arXiv admin note: text overlap with\n  arXiv:1808.01630, arXiv:2505.18558", "summary": "Our examination of deep generative models (DGMs) developed for\nsemi-supervised learning (SSL), mainly GANs and VAEs, reveals two problems.\nFirst, mode missing and mode covering phenomenons are observed in genertion\nwith GANs and VAEs. Second, there exists an awkward conflict between good\nclassification and good generation in SSL by employing directed generative\nmodels. To address these problems, we formally present\njoint-stochastic-approximation random fields (JRFs) -- a new family of\nalgorithms for building deep undirected generative models, with application to\nSSL. It is found through synthetic experiments that JRFs work well in balancing\nmode covering and mode missing, and match the empirical data distribution well.\nEmpirically, JRFs achieve good classification results comparable to the\nstate-of-art methods on widely adopted datasets -- MNIST, SVHN, and CIFAR-10 in\nSSL, and simultaneously perform good generation."}
{"id": "2505.20342", "pdf": "https://arxiv.org/pdf/2505.20342", "abs": "https://arxiv.org/abs/2505.20342", "authors": ["Paul de Font-Reaulx"], "title": "Machine Theory of Mind and the Structure of Human Values", "categories": ["cs.AI"], "comment": "This paper was originally submitted and accepted to the 2023 NeurIPS\n  MP2 Workshop", "summary": "Value learning is a crucial aspect of safe and ethical AI. This is primarily\npursued by methods inferring human values from behaviour. However, humans care\nabout much more than we are able to demonstrate through our actions.\nConsequently, an AI must predict the rest of our seemingly complex values from\na limited sample. I call this the value generalization problem. In this paper,\nI argue that human values have a generative rational structure and that this\nallows us to solve the value generalization problem. In particular, we can use\nBayesian Theory of Mind models to infer human values not only from behaviour,\nbut also from other values. This has been obscured by the widespread use of\nsimple utility functions to represent human values. I conclude that developing\ngenerative value-to-value inference is a crucial component of achieving a\nscalable machine theory of mind."}
{"id": "2505.20647", "pdf": "https://arxiv.org/pdf/2505.20647", "abs": "https://arxiv.org/abs/2505.20647", "authors": ["Ian Langmore"], "title": "Moment Expansions of the Energy Distance", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62G10 (Primary), 62E20, 62H15, 60E10 (Secondary)", "G.3"], "comment": null, "summary": "The energy distance is used to test distributional equality, and as a loss\nfunction in machine learning. While $D^2(X, Y)=0$ only when $X\\sim Y$, the\nsensitivity to different moments is of practical importance. This work\nconsiders $D^2(X, Y)$ in the case where the distributions are close. In this\nregime, $D^2(X, Y)$ is more sensitive to differences in the means\n$\\bar{X}-\\bar{Y}$, than differences in the covariances $\\Delta$. This is due to\nthe structure of the energy distance and is independent of dimension. The\nsensitivity to on versus off diagonal components of $\\Delta$ is examined when\n$X$ and $Y$ are close to isotropic. Here a dimension dependent averaging occurs\nand, in many cases, off diagonal correlations contribute significantly less.\nNumerical results verify these relationships hold even when distributional\nassumptions are not strictly met."}
{"id": "2505.20346", "pdf": "https://arxiv.org/pdf/2505.20346", "abs": "https://arxiv.org/abs/2505.20346", "authors": ["Jiahao Kuang", "Nuowei Liu", "Changzhi Sun", "Tao Ji", "Yuanbin Wu"], "title": "PDFBench: A Benchmark for De novo Protein Design from Function", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "In recent years, while natural language processing and multimodal learning\nhave seen rapid advancements, the field of de novo protein design has also\nexperienced significant growth. However, most current methods rely on\nproprietary datasets and evaluation rubrics, making fair comparisons between\ndifferent approaches challenging. Moreover, these methods often employ\nevaluation metrics that capture only a subset of the desired properties of\ndesigned proteins, lacking a comprehensive assessment framework. To address\nthese, we introduce PDFBench, the first comprehensive benchmark for evaluating\nde novo protein design from function. PDFBench supports two tasks:\ndescription-guided design and keyword-guided design. To ensure fair and\nmultifaceted evaluation, we compile 22 metrics covering sequence plausibility,\nstructural fidelity, and language-protein alignment, along with measures of\nnovelty and diversity. We evaluate five state-of-the-art baselines, revealing\ntheir respective strengths and weaknesses across tasks. Finally, we analyze\ninter-metric correlations, exploring the relationships between four categories\nof metrics, and offering guidelines for metric selection. PDFBench establishes\na unified framework to drive future advances in function-driven de novo protein\ndesign."}
{"id": "2505.20417", "pdf": "https://arxiv.org/pdf/2505.20417", "abs": "https://arxiv.org/abs/2505.20417", "authors": ["Meng Cao", "Shuyuan Zhang", "Xiao-Wen Chang", "Doina Precup"], "title": "SCAR: Shapley Credit Assignment for More Efficient RLHF", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is a widely used technique\nfor aligning Large Language Models (LLMs) with human preferences, yet it often\nsuffers from sparse reward signals, making effective credit assignment\nchallenging. In typical setups, the reward model provides a single scalar score\nfor an entire generated sequence, offering little insight into which token or\nspan-level decisions were responsible for the outcome. To address this, we\npropose Shapley Credit Assignment Rewards (SCAR), a novel method that leverages\nShapley values in cooperative game theory. SCAR distributes the total\nsequence-level reward among constituent tokens or text spans based on their\nprincipled marginal contributions. This creates dense reward signals,\ncrucially, without necessitating the training of auxiliary critique models or\nrecourse to fine-grained human annotations at intermediate generation stages.\nUnlike prior dense reward methods, SCAR offers a game-theoretic foundation for\nfair credit attribution. Theoretically, we demonstrate that SCAR preserves the\noriginal optimal policy, and empirically, across diverse tasks including\nsentiment control, text summarization, and instruction tuning, we show that\nSCAR converges significantly faster and achieves higher final reward scores\ncompared to standard RLHF and attention-based dense reward baselines. Our\nfindings suggest that SCAR provides a more effective and theoretically sound\nmethod for credit assignment in RLHF, leading to more efficient alignment of\nLLMs."}
{"id": "2505.20688", "pdf": "https://arxiv.org/pdf/2505.20688", "abs": "https://arxiv.org/abs/2505.20688", "authors": ["Taehyo Kim", "Qiran Jia", "Mony J. de Leon", "Hai Shu"], "title": "A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data", "categories": ["stat.ML", "cs.CV", "cs.LG", "stat.ME"], "comment": null, "summary": "False discovery rate (FDR) control methods are essential for voxel-wise\nmultiple testing in neuroimaging data analysis, where hundreds of thousands or\neven millions of tests are conducted to detect brain regions associated with\ndisease-related changes. Classical FDR control methods (e.g., BH, q-value, and\nLocalFDR) assume independence among tests and often lead to high false\nnon-discovery rates (FNR). Although various spatial FDR control methods have\nbeen developed to improve power, they still fall short in jointly addressing\nthree major challenges in neuroimaging applications: capturing complex spatial\ndependencies, maintaining low variability in both false discovery proportion\n(FDP) and false non-discovery proportion (FNP) across replications, and\nachieving computational scalability for high-resolution data. To address these\nchallenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR\ncontrol method for voxel-wise multiple testing. It integrates the local index\nof significance (LIS)-based testing procedure with a novel fully connected\nhidden Markov random field (fcHMRF) designed to model complex spatial\nstructures using a parsimonious parameterization. We develop an efficient\nexpectation-maximization algorithm incorporating mean-field approximation, the\nConditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and\npermutohedral lattice filtering, reducing the computational complexity from\nquadratic to linear in the number of tests. Extensive simulations demonstrate\nthat fcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability\nin FDP and FNP, and a higher number of true positives compared to existing\nmethods. Applied to an FDG-PET dataset from the Alzheimer's Disease\nNeuroimaging Initiative, fcHMRF-LIS identifies neurobiologically relevant brain\nregions and offers notable advantages in computational efficiency."}
{"id": "2505.20350", "pdf": "https://arxiv.org/pdf/2505.20350", "abs": "https://arxiv.org/abs/2505.20350", "authors": ["Jifeng Hu", "Sili Huang", "Siyuan Guo", "Zhaogeng Liu", "Li Shen", "Lichao Sun", "Hechang Chen", "Yi Chang", "Dacheng Tao"], "title": "Decision Flow Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, generative models have shown remarkable capabilities across\ndiverse fields, including images, videos, language, and decision-making. By\napplying powerful generative models such as flow-based models to reinforcement\nlearning, we can effectively model complex multi-modal action distributions and\nachieve superior robotic control in continuous action spaces, surpassing the\nlimitations of single-modal action distributions with traditional\nGaussian-based policies. Previous methods usually adopt the generative models\nas behavior models to fit state-conditioned action distributions from datasets,\nwith policy optimization conducted separately through additional policies using\nvalue-based sample weighting or gradient-based updates. However, this\nseparation prevents the simultaneous optimization of multi-modal distribution\nfitting and policy improvement, ultimately hindering the training of models and\ndegrading the performance. To address this issue, we propose Decision Flow, a\nunified framework that integrates multi-modal action distribution modeling and\npolicy optimization. Specifically, our method formulates the action generation\nprocedure of flow-based models as a flow decision-making process, where each\naction generation step corresponds to one flow decision. Consequently, our\nmethod seamlessly optimizes the flow policy while capturing multi-modal action\ndistributions. We provide rigorous proofs of Decision Flow and validate the\neffectiveness through extensive experiments across dozens of offline RL\nenvironments. Compared with established offline RL baselines, the results\ndemonstrate that our method achieves or matches the SOTA performance."}
{"id": "2505.20466", "pdf": "https://arxiv.org/pdf/2505.20466", "abs": "https://arxiv.org/abs/2505.20466", "authors": ["P. S. Kesavan", "Pontus Nordenfelt"], "title": "Reconceptualizing Smart Microscopy: From Data Collection to Knowledge Creation by Multi-Agent Integration", "categories": ["cs.AI", "cs.HC", "cs.MA", "q-bio.QM"], "comment": "34 pages, 5 figures", "summary": "Smart microscopy represents a paradigm shift in biological imaging, moving\nfrom passive observation tools to active collaborators in scientific inquiry.\nEnabled by advances in automation, computational power, and artificial\nintelligence, these systems are now capable of adaptive decision-making and\nreal-time experimental control. Here, we introduce a theoretical framework that\nreconceptualizes smart microscopy as a partner in scientific investigation.\nCentral to our framework is the concept of the 'epistemic-empirical divide' in\ncellular investigation-the gap between what is observable (empirical domain)\nand what must be understood (epistemic domain). We propose six core design\nprinciples: epistemic-empirical awareness, hierarchical context integration, an\nevolution from detection to perception, adaptive measurement frameworks,\nnarrative synthesis capabilities, and cross-contextual reasoning. Together,\nthese principles guide a multi-agent architecture designed to align empirical\nobservation with the goals of scientific understanding. Our framework provides\na roadmap for building microscopy systems that go beyond automation to actively\nsupport hypothesis generation, insight discovery, and theory development,\nredefining the role of scientific instruments in the process of knowledge\ncreation."}
{"id": "2505.20754", "pdf": "https://arxiv.org/pdf/2505.20754", "abs": "https://arxiv.org/abs/2505.20754", "authors": ["Zonghao Chen", "Toni Karvonen", "Heishiro Kanagawa", "Fran√ßois-Xavier Briol", "Chris. J. Oates"], "title": "Stationary MMD Points for Cubature", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Approximation of a target probability distribution using a finite set of\npoints is a problem of fundamental importance, arising in cubature, data\ncompression, and optimisation. Several authors have proposed to select points\nby minimising a maximum mean discrepancy (MMD), but the non-convexity of this\nobjective precludes global minimisation in general. Instead, we consider\n\\emph{stationary} points of the MMD which, in contrast to points globally\nminimising the MMD, can be accurately computed. Our main theoretical\ncontribution is the (perhaps surprising) result that, for integrands in the\nassociated reproducing kernel Hilbert space, the cubature error of stationary\nMMD points vanishes \\emph{faster} than the MMD. Motivated by this\n\\emph{super-convergence} property, we consider discretised gradient flows as a\npractical strategy for computing stationary points of the MMD, presenting a\nrefined convergence analysis that establishes a novel non-asymptotic\nfinite-particle error bound, which may be of independent interest."}
{"id": "2505.20353", "pdf": "https://arxiv.org/pdf/2505.20353", "abs": "https://arxiv.org/abs/2505.20353", "authors": ["Dong Liu", "Jiayi Zhang", "Yifan Li", "Yanxuan Yu", "Ben Lengerich", "Ying Nian Wu"], "title": "FastCache: Fast Caching for Diffusion Transformer Through Learnable Linear Approximation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM", "cs.PF"], "comment": null, "summary": "Diffusion Transformers (DiT) are powerful generative models but remain\ncomputationally intensive due to their iterative structure and deep transformer\nstacks. To alleviate this inefficiency, we propose FastCache, a\nhidden-state-level caching and compression framework that accelerates DiT\ninference by exploiting redundancy within the model's internal representations.\nFastCache introduces a dual strategy: (1) a spatial-aware token selection\nmechanism that adaptively filters redundant tokens based on hidden state\nsaliency, and (2) a transformer-level cache that reuses latent activations\nacross timesteps when changes are statistically insignificant. These modules\nwork jointly to reduce unnecessary computation while preserving generation\nfidelity through learnable linear approximation. Theoretical analysis shows\nthat FastCache maintains bounded approximation error under a\nhypothesis-testing-based decision rule. Empirical evaluations across multiple\nDiT variants demonstrate substantial reductions in latency and memory usage,\nwith best generation output quality compared to other cache methods, as\nmeasured by FID and t-FID. Code implementation of FastCache is available on\nGitHub at https://github.com/NoakLiu/FastCache-xDiT."}
{"id": "2505.20521", "pdf": "https://arxiv.org/pdf/2505.20521", "abs": "https://arxiv.org/abs/2505.20521", "authors": ["Ana Rita Ortigoso", "Gabriel Vieira", "Daniel Fuentes", "Luis Fraz√£o", "Nuno Costa", "Ant√≥nio Pereira"], "title": "Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.1; H.5.2"], "comment": "28 pages, 5 figures. Submitted for review to Information Fusion", "summary": "This paper presents Project Riley, a novel multimodal and multi-model\nconversational AI architecture oriented towards the simulation of reasoning\ninfluenced by emotional states. Drawing inspiration from Pixar's Inside Out,\nthe system comprises five distinct emotional agents - Joy, Sadness, Fear,\nAnger, and Disgust - that engage in structured multi-round dialogues to\ngenerate, criticise, and iteratively refine responses. A final reasoning\nmechanism synthesises the contributions of these agents into a coherent output\nthat either reflects the dominant emotion or integrates multiple perspectives.\nThe architecture incorporates both textual and visual large language models\n(LLMs), alongside advanced reasoning and self-refinement processes. A\nfunctional prototype was deployed locally in an offline environment, optimised\nfor emotional expressiveness and computational efficiency. From this initial\nprototype, another one emerged, called Armando, which was developed for use in\nemergency contexts, delivering emotionally calibrated and factually accurate\ninformation through the integration of Retrieval-Augmented Generation (RAG) and\ncumulative context tracking. The Project Riley prototype was evaluated through\nuser testing, in which participants interacted with the chatbot and completed a\nstructured questionnaire assessing three dimensions: Emotional Appropriateness,\nClarity and Utility, and Naturalness and Human-likeness. The results indicate\nstrong performance in structured scenarios, particularly with respect to\nemotional alignment and communicative clarity."}
{"id": "2505.21208", "pdf": "https://arxiv.org/pdf/2505.21208", "abs": "https://arxiv.org/abs/2505.21208", "authors": ["Thomas Deschatre", "Xavier Warin"], "title": "Input Convex Kolmogorov Arnold Networks", "categories": ["stat.ML", "cs.LG", "math.OC", "68T07"], "comment": null, "summary": "This article presents an input convex neural network architecture using\nKolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the\nfirst is based on a low-order, linear-by-part, representation of functions, and\na universal approximation theorem is provided. The second is based on cubic\nsplines, for which only numerical results support convergence. We demonstrate\non simple tests that these networks perform competitively with classical input\nconvex neural networks (ICNNs). In a second part, we use the networks to solve\nsome optimal transport problems needing a convex approximation of functions and\ndemonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs\nproduce results similar to those of classical ICNNs."}
{"id": "2505.20355", "pdf": "https://arxiv.org/pdf/2505.20355", "abs": "https://arxiv.org/abs/2505.20355", "authors": ["Yeonjoon Jung", "Daehyun Ahn", "Hyungjun Kim", "Taesu Kim", "Eunhyeok Park"], "title": "GraLoRA: Granular Low-Rank Adaptation for Parameter-Efficient Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is a popular method for parameter-efficient\nfine-tuning (PEFT) of generative models, valued for its simplicity and\neffectiveness. Despite recent enhancements, LoRA still suffers from a\nfundamental limitation: overfitting when the bottleneck is widened. It performs\nbest at ranks 32-64, yet its accuracy stagnates or declines at higher ranks,\nstill falling short of full fine-tuning (FFT) performance. We identify the root\ncause as LoRA's structural bottleneck, which introduces gradient entanglement\nto the unrelated input channels and distorts gradient propagation. To address\nthis, we introduce a novel structure, Granular Low-Rank Adaptation (GraLoRA)\nthat partitions weight matrices into sub-blocks, each with its own low-rank\nadapter. With negligible computational or storage cost, GraLoRA overcomes\nLoRA's limitations, effectively increases the representational capacity, and\nmore closely approximates FFT behavior. Experiments on code generation and\ncommonsense reasoning benchmarks show that GraLoRA consistently outperforms\nLoRA and other baselines, achieving up to +8.5% absolute gain in Pass@1 on\nHumanEval+. These improvements hold across model sizes and rank settings,\nmaking GraLoRA a scalable and robust solution for PEFT. Code, data, and scripts\nare available at https://github.com/SqueezeBits/GraLoRA.git"}
{"id": "2505.20522", "pdf": "https://arxiv.org/pdf/2505.20522", "abs": "https://arxiv.org/abs/2505.20522", "authors": ["Jian Wang", "Boyan Zhu", "Chak Tou Leong", "Yongqi Li", "Wenjie Li"], "title": "Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "Large reasoning models (LRMs) have exhibited the capacity of enhancing\nreasoning performance via internal test-time scaling. Building upon this, a\npromising direction is to further scale test-time compute to unlock even\ngreater reasoning capabilities. However, as we push these scaling boundaries,\nsystematically understanding the practical limits and achieving optimal\nresource allocation becomes a critical challenge. In this paper, we investigate\nthe scaling Pareto of test-time scaling and introduce the Test-Time Scaling\nPerformance Model (TTSPM). We theoretically analyze two fundamental paradigms\nfor such extended scaling, parallel scaling and sequential scaling, from a\nprobabilistic modeling perspective. Our primary contribution is the derivation\nof the saturation point on the scaling budget for both strategies, identifying\nthresholds beyond which additional computation yields diminishing returns.\nRemarkably, despite their distinct mechanisms, both paradigms converge to a\nunified mathematical structure in their upper bounds. We empirically validate\nour theoretical findings on challenging reasoning benchmarks, including AIME,\nMATH-500, and GPQA, demonstrating the practical utility of these bounds for\ntest-time resource allocation. We hope that this work provides insights into\nthe cost-benefit trade-offs of test-time scaling, guiding the development of\nmore resource-efficient inference strategies for large reasoning models."}
{"id": "2505.21441", "pdf": "https://arxiv.org/pdf/2505.21441", "abs": "https://arxiv.org/abs/2505.21441", "authors": ["Binh Duc Vu", "Jan Kapar", "Marvin Wright", "David S. Watson"], "title": "Autoencoding Random Forests", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "10 pages main text, 25 pages total. 5 figures main text, 9 figures\n  total", "summary": "We propose a principled method for autoencoding with random forests. Our\nstrategy builds on foundational results from nonparametric statistics and\nspectral graph theory to learn a low-dimensional embedding of the model that\noptimally represents relationships in the data. We provide exact and\napproximate solutions to the decoding problem via constrained optimization,\nsplit relabeling, and nearest neighbors regression. These methods effectively\ninvert the compression pipeline, establishing a map from the embedding space\nback to the input space using splits learned by the ensemble's constituent\ntrees. The resulting decoders are universally consistent under common\nregularity assumptions. The procedure works with supervised or unsupervised\nmodels, providing a window into conditional or joint distributions. We\ndemonstrate various applications of this autoencoder, including powerful new\ntools for visualization, compression, clustering, and denoising. Experiments\nillustrate the ease and utility of our method in a wide range of settings,\nincluding tabular, image, and genomic data."}
{"id": "2505.20357", "pdf": "https://arxiv.org/pdf/2505.20357", "abs": "https://arxiv.org/abs/2505.20357", "authors": ["Jun Tian", "He Wang", "Jibo He", "Yu Pan", "Shuo Cao", "Qingquan Jiang"], "title": "Learning and Interpreting Gravitational-Wave Features from CNNs with a Random Forest Approach", "categories": ["cs.LG", "gr-qc", "physics.data-an"], "comment": null, "summary": "Convolutional neural networks (CNNs) have become widely adopted in\ngravitational wave (GW) detection pipelines due to their ability to\nautomatically learn hierarchical features from raw strain data. However, the\nphysical meaning of these learned features remains underexplored, limiting the\ninterpretability of such models. In this work, we propose a hybrid architecture\nthat combines a CNN-based feature extractor with a random forest (RF)\nclassifier to improve both detection performance and interpretability. Unlike\nprior approaches that directly connect classifiers to CNN outputs, our method\nintroduces four physically interpretable metrics - variance, signal-to-noise\nratio (SNR), waveform overlap, and peak amplitude - computed from the final\nconvolutional layer. These are jointly used with the CNN output in the RF\nclassifier to enable more informed decision boundaries. Tested on long-duration\nstrain datasets, our hybrid model outperforms a baseline CNN model, achieving a\nrelative improvement of 21\\% in sensitivity at a fixed false alarm rate of 10\nevents per month. Notably, it also shows improved detection of low-SNR signals\n(SNR $\\le$ 10), which are especially vulnerable to misclassification in noisy\nenvironments. Feature attribution via the RF model reveals that both\nCNN-extracted and handcrafted features contribute significantly to\nclassification decisions, with learned variance and CNN outputs ranked among\nthe most informative. These findings suggest that physically motivated\npost-processing of CNN feature maps can serve as a valuable tool for\ninterpretable and efficient GW detection, bridging the gap between deep\nlearning and domain knowledge."}
{"id": "2505.20609", "pdf": "https://arxiv.org/pdf/2505.20609", "abs": "https://arxiv.org/abs/2505.20609", "authors": ["Hyungjun Park", "Chang-Yun Woo", "Seungjo Lim", "Seunghwan Lim", "Keunho Kwak", "Ju Young Jeong", "Chong Hyun Suh"], "title": "Comparisons between a Large Language Model-based Real-Time Compound Diagnostic Medical AI Interface and Physicians for Common Internal Medicine Cases using Simulated Patients", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Objective To develop an LLM based realtime compound diagnostic medical AI\ninterface and performed a clinical trial comparing this interface and\nphysicians for common internal medicine cases based on the United States\nMedical License Exam (USMLE) Step 2 Clinical Skill (CS) style exams. Methods A\nnonrandomized clinical trial was conducted on August 20, 2024. We recruited one\ngeneral physician, two internal medicine residents (2nd and 3rd year), and five\nsimulated patients. The clinical vignettes were adapted from the USMLE Step 2\nCS style exams. We developed 10 representative internal medicine cases based on\nactual patients and included information available on initial diagnostic\nevaluation. Primary outcome was the accuracy of the first differential\ndiagnosis. Repeatability was evaluated based on the proportion of agreement.\nResults The accuracy of the physicians' first differential diagnosis ranged\nfrom 50% to 70%, whereas the realtime compound diagnostic medical AI interface\nachieved an accuracy of 80%. The proportion of agreement for the first\ndifferential diagnosis was 0.7. The accuracy of the first and second\ndifferential diagnoses ranged from 70% to 90% for physicians, whereas the AI\ninterface achieved an accuracy rate of 100%. The average time for the AI\ninterface (557 sec) was 44.6% shorter than that of the physicians (1006 sec).\nThe AI interface ($0.08) also reduced costs by 98.1% compared to the\nphysicians' average ($4.2). Patient satisfaction scores ranged from 4.2 to 4.3\nfor care by physicians and were 3.9 for the AI interface Conclusion An LLM\nbased realtime compound diagnostic medical AI interface demonstrated diagnostic\naccuracy and patient satisfaction comparable to those of a physician, while\nrequiring less time and lower costs. These findings suggest that AI interfaces\nmay have the potential to assist primary care consultations for common internal\nmedicine cases."}
{"id": "2505.20330", "pdf": "https://arxiv.org/pdf/2505.20330", "abs": "https://arxiv.org/abs/2505.20330", "authors": ["Yunfu Song", "Zhijian Ou"], "title": "Joint-stochastic-approximation Random Fields with Application to Semi-supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2018 submission. arXiv admin note: text overlap with\n  arXiv:1808.01630, arXiv:2505.18558", "summary": "Our examination of deep generative models (DGMs) developed for\nsemi-supervised learning (SSL), mainly GANs and VAEs, reveals two problems.\nFirst, mode missing and mode covering phenomenons are observed in genertion\nwith GANs and VAEs. Second, there exists an awkward conflict between good\nclassification and good generation in SSL by employing directed generative\nmodels. To address these problems, we formally present\njoint-stochastic-approximation random fields (JRFs) -- a new family of\nalgorithms for building deep undirected generative models, with application to\nSSL. It is found through synthetic experiments that JRFs work well in balancing\nmode covering and mode missing, and match the empirical data distribution well.\nEmpirically, JRFs achieve good classification results comparable to the\nstate-of-art methods on widely adopted datasets -- MNIST, SVHN, and CIFAR-10 in\nSSL, and simultaneously perform good generation."}
{"id": "2505.20359", "pdf": "https://arxiv.org/pdf/2505.20359", "abs": "https://arxiv.org/abs/2505.20359", "authors": ["Lijun Zhang", "Lin Li", "Yajie Qi", "Huizhong Song", "Yaodong Yang", "Jun Wang", "Wei Wei"], "title": "Risk-aware Direct Preference Optimization under Nested Risk Measure", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When fine-tuning pre-trained Large Language Models (LLMs) to align with human\nvalues and intentions, maximizing the estimated reward can lead to superior\nperformance, but it also introduces potential risks due to deviations from the\nreference model's intended behavior. Most existing methods typically introduce\nKL divergence to constrain deviations between the trained model and the\nreference model; however, this may not be sufficient in certain applications\nthat require tight risk control. In this paper, we introduce Risk-aware Direct\nPreference Optimization (Ra-DPO), a novel approach that incorporates\nrisk-awareness by employing a class of nested risk measures. This approach\nformulates a constrained risk-aware advantage function maximization problem and\nthen converts the Bradley-Terry model into a token-level representation. The\nobjective function maximizes the likelihood of the policy while suppressing the\ndeviation between a trained model and the reference model using a sequential\nrisk ratio, thereby enhancing the model's risk-awareness. Experimental results\nacross three open-source datasets: IMDb Dataset, Anthropic HH Dataset, and\nAlpacaEval, demonstrate the proposed method's superior performance in balancing\nalignment performance and model drift. Our code is opensourced at\nhttps://github.com/zlj123-max/Ra-DPO."}
{"id": "2505.20642", "pdf": "https://arxiv.org/pdf/2505.20642", "abs": "https://arxiv.org/abs/2505.20642", "authors": ["Yi Zhan", "Qi Liu", "Weibo Gao", "Zheng Zhang", "Tianfu Wang", "Shuanghong Shen", "Junyu Lu", "Zhenya Huang"], "title": "CoderAgent: Simulating Student Behavior for Personalized Programming Learning with Large Language Models", "categories": ["cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Personalized programming tutoring, such as exercise recommendation, can\nenhance learners' efficiency, motivation, and outcomes, which is increasingly\nimportant in modern digital education. However, the lack of sufficient and\nhigh-quality programming data, combined with the mismatch between offline\nevaluation and real-world learning, hinders the practical deployment of such\nsystems. To address this challenge, many approaches attempt to simulate learner\npractice data, yet they often overlook the fine-grained, iterative nature of\nprogramming learning, resulting in a lack of interpretability and granularity.\nTo fill this gap, we propose a LLM-based agent, CoderAgent, to simulate\nstudents' programming processes in a fine-grained manner without relying on\nreal data. Specifically, we equip each human learner with an intelligent agent,\nthe core of which lies in capturing the cognitive states of the human\nprogramming practice process. Inspired by ACT-R, a cognitive architecture\nframework, we design the structure of CoderAgent to align with human cognitive\narchitecture by focusing on the mastery of programming knowledge and the\napplication of coding ability. Recognizing the inherent patterns in\nmulti-layered cognitive reasoning, we introduce the Programming Tree of Thought\n(PTOT), which breaks down the process into four steps: why, how, where, and\nwhat. This approach enables a detailed analysis of iterative problem-solving\nstrategies. Finally, experimental evaluations on real-world datasets\ndemonstrate that CoderAgent provides interpretable insights into learning\ntrajectories and achieves accurate simulations, paving the way for personalized\nprogramming education."}
{"id": "2505.20532", "pdf": "https://arxiv.org/pdf/2505.20532", "abs": "https://arxiv.org/abs/2505.20532", "authors": ["Dian Jin", "Xin Bing", "Yuqian Zhang"], "title": "One-shot Robust Federated Learning of Independent Component Analysis", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper investigates a general robust one-shot aggregation framework for\ndistributed and federated Independent Component Analysis (ICA) problem. We\npropose a geometric median-based aggregation algorithm that leverages $k$-means\nclustering to resolve the permutation ambiguity in local client estimations.\nOur method first performs k-means to partition client-provided estimators into\nclusters and then aggregates estimators within each cluster using the geometric\nmedian. This approach provably remains effective even in highly heterogeneous\nscenarios where at most half of the clients can observe only a minimal number\nof samples. The key theoretical contribution lies in the combined analysis of\nthe geometric median's error bound-aided by sample quantiles-and the maximum\nmisclustering rates of the aforementioned solution of $k$-means. The\neffectiveness of the proposed approach is further supported by simulation\nstudies conducted under various heterogeneous settings."}
{"id": "2505.20380", "pdf": "https://arxiv.org/pdf/2505.20380", "abs": "https://arxiv.org/abs/2505.20380", "authors": ["Simin Fan", "Maria Ios Glarou", "Martin Jaggi"], "title": "GRAPE: Optimize Data Mixture for Group Robust Multi-target Adaptive Pretraining", "categories": ["cs.LG"], "comment": null, "summary": "The performance of large language models (LLMs) across diverse downstream\napplications is fundamentally governed by the quality and composition of their\npretraining corpora. Existing domain reweighting algorithms primarily optimize\ndata mixtures for a single target task, thereby resulting in models that\noverfit to specialized objectives while exhibiting substantial performance\ndegradation on other benchmarks. This paper introduces Group Robust\nMulti-target Adaptive PrEtraining (GRAPE), a novel multi-source-multi-target\ndomain reweighting framework designed to calibrate pretraining data mixtures\nfor robust performance across multiple target tasks simultaneously. GRAPE\ndynamically adjusts sampling weights across source domains (domain weights)\nwhile concurrently modulating task weights that quantify the relative\nimportance of each individual target task. This adaptive process prioritizes\ntasks based on their learning difficulty throughout training. We formulate this\ninterleaved reweighting mechanism as a minimax optimization problem: The inner\nmaximization adjusts task weights leveraging group\ndistributed-robust-optimization (DRO), where those tasks demonstrating the\nleast improvement under the current data mixture are prioritized with higher\nweights; The outer minimization then optimizes domain weights to maximize loss\nreduction on the prioritized tasks. Experiments on ClimbLab and SlimPajama\ndatasets demonstrate that GRAPE consistently outperforms baseline methods in\nterms of reasoning performance across 6 benchmarks. Furthermore, when applied\nto multilingual targets, GRAPE effectively identifies optimal training mixtures\nfrom mainstream languages, achieving superior language modeling capabilities\nacross 8 low-resource target languages."}
{"id": "2505.20662", "pdf": "https://arxiv.org/pdf/2505.20662", "abs": "https://arxiv.org/abs/2505.20662", "authors": ["Xuanle Zhao", "Zilin Sang", "Yuxuan Li", "Qi Shi", "Shuo Wang", "Duzhen Zhang", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage", "categories": ["cs.AI"], "comment": "20 pages, preprint version", "summary": "Efficient experiment reproduction is critical to accelerating progress in\nartificial intelligence. However, the inherent complexity of method design and\ntraining procedures presents substantial challenges for automation. Notably,\nreproducing experiments often requires implicit domain-specific knowledge not\nexplicitly documented in the original papers. To address this, we introduce the\npaper lineage algorithm, which identifies and extracts implicit knowledge from\nthe relevant references cited by the target paper. Building on this idea, we\npropose AutoReproduce, a multi-agent framework capable of automatically\nreproducing experiments described in research papers in an end-to-end manner.\nAutoReproduce enhances code executability by generating unit tests alongside\nthe reproduction process. To evaluate the reproduction capability, we construct\nReproduceBench, a benchmark annotated with verified implementations, and\nintroduce novel evaluation metrics to assess both the reproduction and\nexecution fidelity. Experimental results demonstrate that AutoReproduce\noutperforms the existing strong agent baselines on all five evaluation metrics\nby a peak margin of over $70\\%$. In particular, compared to the official\nimplementations, AutoReproduce achieves an average performance gap of $22.1\\%$\non $89.74\\%$ of the executable experiment runs. The code will be available at\nhttps://github.com/AI9Stars/AutoReproduce."}
{"id": "2505.20561", "pdf": "https://arxiv.org/pdf/2505.20561", "abs": "https://arxiv.org/abs/2505.20561", "authors": ["Shenao Zhang", "Yaqing Wang", "Yinxiao Liu", "Tianqi Liu", "Peter Grabowski", "Eugene Ie", "Zhaoran Wang", "Yunxuan Li"], "title": "Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL."}
{"id": "2505.20435", "pdf": "https://arxiv.org/pdf/2505.20435", "abs": "https://arxiv.org/abs/2505.20435", "authors": ["Aideen Fay", "In√©s Garc√≠a-Redondo", "Qiquan Wang", "Haim Dubossarsky", "Anthea Monod"], "title": "Holes in Latent Space: Topological Signatures Under Adversarial Influence", "categories": ["cs.LG", "cs.AI", "cs.CG", "math.AT"], "comment": null, "summary": "Understanding how adversarial conditions affect language models requires\ntechniques that capture both global structure and local detail within\nhigh-dimensional activation spaces. We propose persistent homology (PH), a tool\nfrom topological data analysis, to systematically characterize multiscale\nlatent space dynamics in LLMs under two distinct attack modes -- backdoor\nfine-tuning and indirect prompt injection. By analyzing six state-of-the-art\nLLMs, we show that adversarial conditions consistently compress latent\ntopologies, reducing structural diversity at smaller scales while amplifying\ndominant features at coarser ones. These topological signatures are\nstatistically robust across layers, architectures, model sizes, and align with\nthe emergence of adversarial effects deeper in the network. To capture\nfiner-grained mechanisms underlying these shifts, we introduce a neuron-level\nPH framework that quantifies how information flows and transforms within and\nacross layers. Together, our findings demonstrate that PH offers a principled\nand unifying approach to interpreting representational dynamics in LLMs,\nparticularly under distributional shift."}
{"id": "2505.20670", "pdf": "https://arxiv.org/pdf/2505.20670", "abs": "https://arxiv.org/abs/2505.20670", "authors": ["Zikang Guo", "Benfeng Xu", "Xiaorui Wang", "Zhendong Mao"], "title": "MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning", "categories": ["cs.AI"], "comment": "Accepted to 34rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)", "summary": "Complex tasks involving tool integration pose significant challenges for\nLarge Language Models (LLMs), leading to the emergence of multi-agent workflows\nas a promising solution. Reflection has emerged as an effective strategy for\ncorrecting erroneous trajectories in agentic workflows. However, existing\napproaches only exploit such capability in the post-action stage, where the\nagent observes the execution outcomes. We argue that, like humans, LLMs can\nalso engage in reflection before action execution: the agent can anticipate\nundesirable outcomes from its own decisions, which not only provides a\nnecessarily complementary perspective to evaluate the decision but also\nprevents the propagation of errors throughout the trajectory. In this paper, we\npropose MIRROR, a framework that consists of both intra-reflection, which\ncritically assesses intended actions before execution, and inter-reflection,\nwhich further adjusts the trajectory based on observations. This design\nsystematically leverages LLM reflection capabilities to eliminate and rectify\nerroneous actions on a more comprehensive scope. Evaluations on both the\nStableToolBench and TravelPlanner benchmarks demonstrate MIRROR's superior\nperformance, achieving state-of-the-art results compared to existing\napproaches."}
{"id": "2505.20634", "pdf": "https://arxiv.org/pdf/2505.20634", "abs": "https://arxiv.org/abs/2505.20634", "authors": ["Ruiqi Lyu", "Alistair Turcan", "Bryan Wilder"], "title": "Explaining Concept Shift with Interpretable Feature Attribution", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Regardless the amount of data a machine learning (ML) model is trained on,\nthere will inevitably be data that differs from their training set, lowering\nmodel performance. Concept shift occurs when the distribution of labels\nconditioned on the features changes, making even a well-tuned ML model to have\nlearned a fundamentally incorrect representation. Identifying these shifted\nfeatures provides unique insight into how one dataset differs from another,\nconsidering the difference may be across a scientifically relevant dimension,\nsuch as time, disease status, population, etc. In this paper, we propose\nSGShift, a model for detecting concept shift in tabular data and attributing\nreduced model performance to a sparse set of shifted features. SGShift models\nconcept shift with a Generalized Additive Model (GAM) and performs subsequent\nfeature selection to identify shifted features. We propose further extensions\nof SGShift by incorporating knockoffs to control false discoveries and an\nabsorption term to account for models with poor fit to the data. We conduct\nextensive experiments in synthetic and real data across various ML models and\nfind SGShift can identify shifted features with AUC $>0.9$ and recall $>90\\%$,\noften 2 or 3 times as high as baseline methods."}
{"id": "2505.20444", "pdf": "https://arxiv.org/pdf/2505.20444", "abs": "https://arxiv.org/abs/2505.20444", "authors": ["Haoran Li", "Yingjie Qin", "Baoyuan Ou", "Lai Xu", "Ruiwen Xu"], "title": "HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) have made significant progress in multimodal\ntasks. However, their performance often deteriorates in long-context scenarios,\nparticularly long videos. While Rotary Position Embedding (RoPE) has been\nwidely adopted for length generalization in Large Language Models (LLMs),\nextending vanilla RoPE to capture the intricate spatial-temporal dependencies\nin videos remains an unsolved challenge. Existing methods typically allocate\ndifferent frequencies within RoPE to encode 3D positional information. However,\nthese allocation strategies mainly rely on heuristics, lacking in-depth\ntheoretical analysis. In this paper, we first study how different allocation\nstrategies impact the long-context capabilities of VLMs. Our analysis reveals\nthat current multimodal RoPEs fail to reliably capture semantic similarities\nover extended contexts. To address this issue, we propose HoPE, a Hybrid of\nPosition Embedding designed to improve the long-context capabilities of VLMs.\nHoPE introduces a hybrid frequency allocation strategy for reliable semantic\nmodeling over arbitrarily long context, and a dynamic temporal scaling\nmechanism to facilitate robust learning and flexible inference across diverse\ncontext lengths. Extensive experiments across four video benchmarks on long\nvideo understanding and retrieval tasks demonstrate that HoPE consistently\noutperforms existing methods, confirming its effectiveness. Code is available\nat https://github.com/hrlics/HoPE."}
{"id": "2505.20671", "pdf": "https://arxiv.org/pdf/2505.20671", "abs": "https://arxiv.org/abs/2505.20671", "authors": ["Heng Tan", "Hua Yan", "Yu Yang"], "title": "LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "While reinforcement learning (RL) has achieved notable success in various\ndomains, training effective policies for complex tasks remains challenging.\nAgents often converge to local optima and fail to maximize long-term rewards.\nExisting approaches to mitigate training bottlenecks typically fall into two\ncategories: (i) Automated policy refinement, which identifies critical states\nfrom past trajectories to guide policy updates, but suffers from costly and\nuncertain model training; and (ii) Human-in-the-loop refinement, where human\nfeedback is used to correct agent behavior, but this does not scale well to\nenvironments with large or continuous action spaces. In this work, we design a\nlarge language model-guided policy modulation framework that leverages LLMs to\nimprove RL training without additional model training or human intervention. We\nfirst prompt an LLM to identify critical states from a sub-optimal agent's\ntrajectories. Based on these states, the LLM then provides action suggestions\nand assigns implicit rewards to guide policy refinement. Experiments across\nstandard RL benchmarks demonstrate that our method outperforms state-of-the-art\nbaselines, highlighting the effectiveness of LLM-based explanations in\naddressing RL training bottlenecks."}
{"id": "2505.20697", "pdf": "https://arxiv.org/pdf/2505.20697", "abs": "https://arxiv.org/abs/2505.20697", "authors": ["Zachary C. Brown", "David Carlson"], "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method's ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics."}
{"id": "2505.20446", "pdf": "https://arxiv.org/pdf/2505.20446", "abs": "https://arxiv.org/abs/2505.20446", "authors": ["Tal Gonen", "Itai Pemper", "Ilan Naiman", "Nimrod Berman", "Omri Azencot"], "title": "Time Series Generation Under Data Scarcity: A Unified Generative Modeling Approach", "categories": ["cs.LG"], "comment": "The first two authors contributed equally", "summary": "Generative modeling of time series is a central challenge in time series\nanalysis, particularly under data-scarce conditions. Despite recent advances in\ngenerative modeling, a comprehensive understanding of how state-of-the-art\ngenerative models perform under limited supervision remains lacking. In this\nwork, we conduct the first large-scale study evaluating leading generative\nmodels in data-scarce settings, revealing a substantial performance gap between\nfull-data and data-scarce regimes. To close this gap, we propose a unified\ndiffusion-based generative framework that can synthesize high-fidelity time\nseries across diverse domains using just a few examples. Our model is\npre-trained on a large, heterogeneous collection of time series datasets,\nenabling it to learn generalizable temporal representations. It further\nincorporates architectural innovations such as dynamic convolutional layers for\nflexible channel adaptation and dataset token conditioning for domain-aware\ngeneration. Without requiring abundant supervision, our unified model achieves\nstate-of-the-art performance in few-shot settings-outperforming domain-specific\nbaselines across a wide range of subset sizes. Remarkably, it also surpasses\nall baselines even when tested on full datasets benchmarks, highlighting the\nstrength of pre-training and cross-domain generalization. We hope this work\nencourages the community to revisit few-shot generative modeling as a key\nproblem in time series research and pursue unified solutions that scale\nefficiently across domains. Code is available at\nhttps://github.com/azencot-group/ImagenFew."}
{"id": "2505.20672", "pdf": "https://arxiv.org/pdf/2505.20672", "abs": "https://arxiv.org/abs/2505.20672", "authors": ["Woochang Sim", "Hyunseok Ryu", "Kyungmin Choi", "Sungwon Han", "Sundong Kim"], "title": "GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general\nAI capabilities, requiring solvers to infer abstract patterns from only a\nhandful of examples. Despite substantial progress in deep learning,\nstate-of-the-art models still achieve accuracy rates of merely 40-55% on 2024\nARC Competition, indicative of a significant gap between their performance and\nhuman-level reasoning. In this work, we seek to bridge that gap by introducing\nan analogy-inspired ARC dataset, GIFARC. Leveraging large language models\n(LLMs) and vision-language models (VLMs), we synthesize new ARC-style tasks\nfrom a variety of GIF images that include analogies. Each new task is paired\nwith ground-truth analogy, providing an explicit mapping between visual\ntransformations and everyday concepts. By embedding robust human-intuitive\nanalogies into ARC-style tasks, GIFARC guides AI agents to evaluate the task\nanalogically before engaging in brute-force pattern search, thus efficiently\nreducing problem complexity and build a more concise and human-understandable\nsolution. We empirically validate that guiding LLM with analogic approach with\nGIFARC affects task-solving approaches of LLMs to align with analogic approach\nof human."}
{"id": "2505.20761", "pdf": "https://arxiv.org/pdf/2505.20761", "abs": "https://arxiv.org/abs/2505.20761", "authors": ["Ryota Ushio", "Takashi Ishida", "Masashi Sugiyama"], "title": "Practical estimation of the optimal classification error with soft labels and calibration", "categories": ["cs.LG", "stat.ML"], "comment": "36 pages, 24 figures; GitHub:\n  https://github.com/RyotaUshio/bayes-error-estimation", "summary": "While the performance of machine learning systems has experienced significant\nimprovement in recent years, relatively little attention has been paid to the\nfundamental question: to what extent can we improve our models? This paper\nprovides a means of answering this question in the setting of binary\nclassification, which is practical and theoretically supported. We extend a\nprevious work that utilizes soft labels for estimating the Bayes error, the\noptimal error rate, in two important ways. First, we theoretically investigate\nthe properties of the bias of the hard-label-based estimator discussed in the\noriginal work. We reveal that the decay rate of the bias is adaptive to how\nwell the two class-conditional distributions are separated, and it can decay\nsignificantly faster than the previous result suggested as the number of hard\nlabels per instance grows. Second, we tackle a more challenging problem\nsetting: estimation with corrupted soft labels. One might be tempted to use\ncalibrated soft labels instead of clean ones. However, we reveal that\ncalibration guarantee is not enough, that is, even perfectly calibrated soft\nlabels can result in a substantially inaccurate estimate. Then, we show that\nisotonic calibration can provide a statistically consistent estimator under an\nassumption weaker than that of the previous work. Our method is instance-free,\ni.e., we do not assume access to any input instances. This feature allows it to\nbe adopted in practical scenarios where the instances are not available due to\nprivacy issues. Experiments with synthetic and real-world datasets show the\nvalidity of our methods and theory."}
{"id": "2505.20452", "pdf": "https://arxiv.org/pdf/2505.20452", "abs": "https://arxiv.org/abs/2505.20452", "authors": ["Hao Zhao", "Rong Pan"], "title": "Active Learning for Multiple Change Point Detection in Non-stationary Time Series with Deep Gaussian Processes", "categories": ["cs.LG"], "comment": null, "summary": "Multiple change point (MCP) detection in non-stationary time series is\nchallenging due to the variety of underlying patterns. To address these\nchallenges, we propose a novel algorithm that integrates Active Learning (AL)\nwith Deep Gaussian Processes (DGPs) for robust MCP detection. Our method\nleverages spectral analysis to identify potential changes and employs AL to\nstrategically select new sampling points for improved efficiency. By\nincorporating the modeling flexibility of DGPs with the change-identification\ncapabilities of spectral methods, our approach adapts to diverse spectral\nchange behaviors and effectively localizes multiple change points. Experiments\non both simulated and real-world data demonstrate that our method outperforms\nexisting techniques in terms of detection accuracy and sampling efficiency for\nnon-stationary time series."}
{"id": "2505.20728", "pdf": "https://arxiv.org/pdf/2505.20728", "abs": "https://arxiv.org/abs/2505.20728", "authors": ["Zesen Lyu", "Dandan Zhang", "Wei Ye", "Fangdi Li", "Zhihang Jiang", "Yao Yang"], "title": "Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Spatial reasoning is a core component of human cognition, enabling\nindividuals to perceive, comprehend, and interact with the physical world. It\nrelies on a nuanced understanding of spatial structures and inter-object\nrelationships, serving as the foundation for complex reasoning and\ndecision-making. To investigate whether current vision-language models (VLMs)\nexhibit similar capability, we introduce Jigsaw-Puzzles, a novel benchmark\nconsisting of 1,100 carefully curated real-world images with high spatial\ncomplexity. Based on this dataset, we design five tasks to rigorously evaluate\nVLMs' spatial perception, structural understanding, and reasoning capabilities,\nwhile deliberately minimizing reliance on domain-specific knowledge to better\nisolate and assess the general spatial reasoning capability. We conduct a\ncomprehensive evaluation across 24 state-of-the-art VLMs. The results show that\neven the strongest model, Gemini-2.5-Pro, achieves only 77.14% overall accuracy\nand performs particularly poorly on the Order Generation task, with only 30.00%\naccuracy, far below the performance exceeding 90% achieved by human\nparticipants. This persistent gap underscores the need for continued progress,\npositioning Jigsaw-Puzzles as a challenging and diagnostic benchmark for\nadvancing spatial reasoning research in VLMs."}
{"id": "2505.20885", "pdf": "https://arxiv.org/pdf/2505.20885", "abs": "https://arxiv.org/abs/2505.20885", "authors": ["Haipeng Luo", "Spandan Senapati", "Vatsal Sharan"], "title": "Improved Bounds for Swap Multicalibration and Swap Omniprediction", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we consider the related problems of multicalibration -- a\nmultigroup fairness notion and omniprediction -- a simultaneous loss\nminimization paradigm, both in the distributional and online settings. The\nrecent work of Garg et al. (2024) raised the open problem of whether it is\npossible to efficiently achieve $O(\\sqrt{T})$ $\\ell_{2}$-multicalibration error\nagainst bounded linear functions. In this paper, we answer this question in a\nstrongly affirmative sense. We propose an efficient algorithm that achieves\n$O(T^{\\frac{1}{3}})$ $\\ell_{2}$-swap multicalibration error (both in high\nprobability and expectation). On propagating this bound onward, we obtain\nsignificantly improved rates for $\\ell_{1}$-swap multicalibration and swap\nomniprediction for a loss class of convex Lipschitz functions. In particular,\nwe show that our algorithm achieves $O(T^{\\frac{2}{3}})$ $\\ell_{1}$-swap\nmulticalibration and swap omniprediction errors, thereby improving upon the\nprevious best-known bound of $O(T^{\\frac{7}{8}})$. As a consequence of our\nimproved online results, we further obtain several improved sample complexity\nrates in the distributional setting. In particular, we establish a\n$O(\\varepsilon ^ {-3})$ sample complexity of efficiently learning an\n$\\varepsilon$-swap omnipredictor for the class of convex and Lipschitz\nfunctions, $O(\\varepsilon ^{-2.5})$ sample complexity of efficiently learning\nan $\\varepsilon$-swap agnostic learner for the squared loss, and $O(\\varepsilon\n^ {-5}), O(\\varepsilon ^ {-2.5})$ sample complexities of learning $\\ell_{1},\n\\ell_{2}$-swap multicalibrated predictors against linear functions, all of\nwhich significantly improve on the previous best-known bounds."}
{"id": "2505.20454", "pdf": "https://arxiv.org/pdf/2505.20454", "abs": "https://arxiv.org/abs/2505.20454", "authors": ["Reid Graves", "Anthony Zhou", "Amir Barati Farimani"], "title": "BlastOFormer: Attention and Neural Operator Deep Learning Methods for Explosive Blast Prediction", "categories": ["cs.LG"], "comment": "21 pages, 9 figures", "summary": "Accurate prediction of blast pressure fields is essential for applications in\nstructural safety, defense planning, and hazard mitigation. Traditional methods\nsuch as empirical models and computational fluid dynamics (CFD) simulations\noffer limited trade offs between speed and accuracy; empirical models fail to\ncapture complex interactions in cluttered environments, while CFD simulations\nare computationally expensive and time consuming. In this work, we introduce\nBlastOFormer, a novel Transformer based surrogate model for full field maximum\npressure prediction from arbitrary obstacle and charge configurations.\nBlastOFormer leverages a signed distance function (SDF) encoding and a grid to\ngrid attention based architecture inspired by OFormer and Vision Transformer\n(ViT) frameworks. Trained on a dataset generated using the open source\nblastFoam CFD solver, our model outperforms convolutional neural networks\n(CNNs) and Fourier Neural Operators (FNOs) across both log transformed and\nunscaled domains. Quantitatively, BlastOFormer achieves the highest R2 score\n(0.9516) and lowest error metrics, while requiring only 6.4 milliseconds for\ninference, more than 600,000 times faster than CFD simulations. Qualitative\nvisualizations and error analyses further confirm BlastOFormer's superior\nspatial coherence and generalization capabilities. These results highlight its\npotential as a real time alternative to conventional CFD approaches for blast\npressure estimation in complex environments."}
{"id": "2505.20733", "pdf": "https://arxiv.org/pdf/2505.20733", "abs": "https://arxiv.org/abs/2505.20733", "authors": ["Cheonsu Jeong", "Seongmin Sim", "Hyoyoung Cho", "Sungsu Kim", "Byounggwan Shin"], "title": "E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents an intelligent work automation approach in the context of\ncontemporary digital transformation by integrating generative AI and\nIntelligent Document Processing (IDP) technologies with an Automation Agent to\nrealize End-to-End (E2E) automation of corporate financial expense processing\ntasks. While traditional Robotic Process Automation (RPA) has proven effective\nfor repetitive, rule-based simple task automation, it faces limitations in\nhandling unstructured data, exception management, and complex decision-making.\nThis study designs and implements a four-stage integrated process comprising\nautomatic recognition of supporting documents such as receipts via OCR/IDP,\nitem classification based on a policy-driven database, intelligent exception\nhandling supported by generative AI (large language models, LLMs), and\nhuman-in-the-loop final decision-making with continuous system learning through\nan Automation Agent. Applied to a major Korean enterprise (Company S), the\nsystem demonstrated quantitative benefits including over 80% reduction in\nprocessing time for paper receipt expense tasks, decreased error rates, and\nimproved compliance, as well as qualitative benefits such as enhanced accuracy\nand consistency, increased employee satisfaction, and data-driven decision\nsupport. Furthermore, the system embodies a virtuous cycle by learning from\nhuman judgments to progressively improve automatic exception handling\ncapabilities. Empirically, this research confirms that the organic integration\nof generative AI, IDP, and Automation Agents effectively overcomes the\nlimitations of conventional automation and enables E2E automation of complex\ncorporate processes. The study also discusses potential extensions to other\ndomains such as accounting, human resources, and procurement, and proposes\nfuture directions for AI-driven hyper-automation development."}
{"id": "2505.20943", "pdf": "https://arxiv.org/pdf/2505.20943", "abs": "https://arxiv.org/abs/2505.20943", "authors": ["Anand Brahmbhatt", "Gon Buzaglo", "Sofiia Druchyna", "Elad Hazan"], "title": "Efficient Spectral Control of Partially Observed Linear Dynamical Systems", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new method for the problem of controlling linear dynamical\nsystems under partial observation and adversarial disturbances. Our new\nalgorithm, Double Spectral Control (DSC), matches the best known regret\nguarantees while exponentially improving runtime complexity over previous\napproaches in its dependence on the system's stability margin. Our key\ninnovation is a two-level spectral approximation strategy, leveraging double\nconvolution with a universal basis of spectral filters, enabling efficient and\naccurate learning of the best linear dynamical controllers."}
{"id": "2505.20485", "pdf": "https://arxiv.org/pdf/2505.20485", "abs": "https://arxiv.org/abs/2505.20485", "authors": ["Abhijit Chunduru", "Majid Morafah", "Mahdi Morafah", "Vishnu Pandi Chellapandi", "Ang Li"], "title": "Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.PF"], "comment": null, "summary": "The inevitable presence of data heterogeneity has made federated learning\nvery challenging. There are numerous methods to deal with this issue, such as\nlocal regularization, better model fusion techniques, and data sharing. Though\neffective, they lack a deep understanding of how data heterogeneity can affect\nthe global decision boundary. In this paper, we bridge this gap by performing\nan experimental analysis of the learned decision boundary using a toy example.\nOur observations are surprising: (1) we find that the existing methods suffer\nfrom forgetting and clients forget the global decision boundary and only learn\nthe perfect local one, and (2) this happens regardless of the initial weights,\nand clients forget the global decision boundary even starting from pre-trained\noptimal weights. In this paper, we present FedProj, a federated learning\nframework that robustly learns the global decision boundary and avoids its\nforgetting during local training. To achieve better ensemble knowledge fusion,\nwe design a novel server-side ensemble knowledge transfer loss to further\ncalibrate the learned global decision boundary. To alleviate the issue of\nlearned global decision boundary forgetting, we further propose leveraging an\nepisodic memory of average ensemble logits on a public unlabeled dataset to\nregulate the gradient updates at each step of local training. Experimental\nresults demonstrate that FedProj outperforms state-of-the-art methods by a\nlarge margin."}
{"id": "2505.20737", "pdf": "https://arxiv.org/pdf/2505.20737", "abs": "https://arxiv.org/abs/2505.20737", "authors": ["Zilong Wang", "Jingfeng Yang", "Sreyashi Nag", "Samarth Varshney", "Xianfeng Tang", "Haoming Jiang", "Jingbo Shang", "Sheikh Muhammad Sarwar"], "title": "RRO: LLM Agent Optimization Through Rising Reward Trajectories", "categories": ["cs.AI"], "comment": "preprint", "summary": "Large language models (LLMs) have exhibited extraordinary performance in a\nvariety of tasks while it remains challenging for them to solve complex\nmulti-step tasks as agents. In practice, agents sensitive to the outcome of\ncertain key steps which makes them likely to fail the task because of a subtle\nmistake in the planning trajectory. Recent approaches resort to calibrating the\nreasoning process through reinforcement learning. They reward or penalize every\nreasoning step with process supervision, as known as Process Reward Models\n(PRMs). However, PRMs are difficult and costly to scale up with a large number\nof next action candidates since they require extensive computations to acquire\nthe training data through the per-step trajectory exploration. To mitigate this\nissue, we focus on the relative reward trend across successive reasoning steps\nand propose maintaining an increasing reward in the collected trajectories for\nprocess supervision, which we term Reward Rising Optimization (RRO).\nSpecifically, we incrementally augment the process supervision until\nidentifying a step exhibiting positive reward differentials, i.e. rising\nrewards, relative to its preceding iteration. This method dynamically expands\nthe search space for the next action candidates, efficiently capturing\nhigh-quality data. We provide mathematical groundings and empirical results on\nthe WebShop and InterCode-SQL benchmarks, showing that our proposed RRO\nachieves superior performance while requiring much less exploration cost."}
{"id": "2505.21005", "pdf": "https://arxiv.org/pdf/2505.21005", "abs": "https://arxiv.org/abs/2505.21005", "authors": ["Fengzhe Zhang", "Laurence I. Midgley", "Jos√© Miguel Hern√°ndez-Lobato"], "title": "Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Score-based diffusion models (SBDMs) are powerful amortized samplers for\nBoltzmann distributions; however, imperfect score estimates bias downstream\nMonte Carlo estimates. Classical importance sampling (IS) can correct this\nbias, but computing exact likelihoods requires solving the probability-flow\nordinary differential equation (PF-ODE), a procedure that is prohibitively\ncostly and scales poorly with dimensionality. We introduce Variance-Tuned\nDiffusion Importance Sampling (VT-DIS), a lightweight post-training method that\nadapts the per-step noise covariance of a pretrained SBDM by minimizing the\n$\\alpha$-divergence ($\\alpha=2$) between its forward diffusion and reverse\ndenoising trajectories. VT-DIS assigns a single trajectory-wise importance\nweight to the joint forward-reverse process, yielding unbiased expectation\nestimates at test time with negligible overhead compared to standard sampling.\nOn the DW-4, LJ-13, and alanine-dipeptide benchmarks, VT-DIS achieves effective\nsample sizes of approximately 80 %, 35 %, and 3.5 %, respectively, while using\nonly a fraction of the computational budget required by vanilla diffusion + IS\nor PF-ODE-based IS."}
{"id": "2505.20515", "pdf": "https://arxiv.org/pdf/2505.20515", "abs": "https://arxiv.org/abs/2505.20515", "authors": ["Avik Pal", "Alan Edelman", "Christopher Rackauckas"], "title": "Semi-Explicit Neural DAEs: Learning Long-Horizon Dynamical Systems with Algebraic Constraints", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA"], "comment": null, "summary": "Despite the promise of scientific machine learning (SciML) in combining\ndata-driven techniques with mechanistic modeling, existing approaches for\nincorporating hard constraints in neural differential equations (NDEs) face\nsignificant limitations. Scalability issues and poor numerical properties\nprevent these neural models from being used for modeling physical systems with\ncomplicated conservation laws. We propose Manifold-Projected Neural ODEs\n(PNODEs), a method that explicitly enforces algebraic constraints by projecting\neach ODE step onto the constraint manifold. This framework arises naturally\nfrom semi-explicit differential-algebraic equations (DAEs), and includes both a\nrobust iterative variant and a fast approximation requiring a single Jacobian\nfactorization. We further demonstrate that prior works on relaxation methods\nare special cases of our approach. PNODEs consistently outperform baselines\nacross six benchmark problems achieving a mean constraint violation error below\n$10^{-10}$. Additionally, PNODEs consistently achieve lower runtime compared to\nother methods for a given level of error tolerance. These results show that\nconstraint projection offers a simple strategy for learning physically\nconsistent long-horizon dynamics."}
{"id": "2505.20740", "pdf": "https://arxiv.org/pdf/2505.20740", "abs": "https://arxiv.org/abs/2505.20740", "authors": ["Xiangyu Zhao", "Wanghan Xu", "Bo Liu", "Yuhao Zhou", "Fenghua Ling", "Ben Fei", "Xiaoyu Yue", "Lei Bai", "Wenlong Zhang", "Xiao-Ming Wu"], "title": "MSEarth: A Benchmark for Multimodal Scientific Comprehension of Earth Science", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of multimodal large language models (MLLMs) has\nunlocked new opportunities to tackle complex scientific challenges. Despite\nthis progress, their application in addressing earth science problems,\nespecially at the graduate level, remains underexplored. A significant barrier\nis the absence of benchmarks that capture the depth and contextual complexity\nof geoscientific reasoning. Current benchmarks often rely on synthetic datasets\nor simplistic figure-caption pairs, which do not adequately reflect the\nintricate reasoning and domain-specific insights required for real-world\nscientific applications. To address these gaps, we introduce MSEarth, a\nmultimodal scientific benchmark curated from high-quality, open-access\nscientific publications. MSEarth encompasses the five major spheres of Earth\nscience: atmosphere, cryosphere, hydrosphere, lithosphere, and biosphere,\nfeaturing over 7K figures with refined captions. These captions are crafted\nfrom the original figure captions and enriched with discussions and reasoning\nfrom the papers, ensuring the benchmark captures the nuanced reasoning and\nknowledge-intensive content essential for advanced scientific tasks. MSEarth\nsupports a variety of tasks, including scientific figure captioning, multiple\nchoice questions, and open-ended reasoning challenges. By bridging the gap in\ngraduate-level benchmarks, MSEarth provides a scalable and high-fidelity\nresource to enhance the development and evaluation of MLLMs in scientific\nreasoning. The benchmark is publicly available to foster further research and\ninnovation in this field. Resources related to this benchmark can be found at\nhttps://huggingface.co/MSEarth and https://github.com/xiangyu-mm/MSEarth."}
{"id": "2505.21012", "pdf": "https://arxiv.org/pdf/2505.21012", "abs": "https://arxiv.org/abs/2505.21012", "authors": ["Geetika", "Somya Tyagi", "Bapi Chatterjee"], "title": "Federated Instrumental Variable Analysis via Federated Generalized Method of Moments", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "28 pages, 3 figures, 1 table", "summary": "Instrumental variables (IV) analysis is an important applied tool for areas\nsuch as healthcare and consumer economics. For IV analysis in high-dimensional\nsettings, the Generalized Method of Moments (GMM) using deep neural networks\noffers an efficient approach. With non-i.i.d. data sourced from scattered\ndecentralized clients, federated learning is a popular paradigm for training\nthe models while promising data privacy. However, to our knowledge, no\nfederated algorithm for either GMM or IV analysis exists to date. In this work,\nwe introduce federated instrumental variables analysis (FedIV) via federated\ngeneralized method of moments (FedGMM). We formulate FedGMM as a federated\nzero-sum game defined by a federated non-convex non-concave minimax\noptimization problem, which is solved using federated gradient descent ascent\n(FedGDA) algorithm. One key challenge arises in theoretically characterizing\nthe federated local optimality. To address this, we present properties and\nexistence results of clients' local equilibria via FedGDA limit points.\nThereby, we show that the federated solution consistently estimates the local\nmoment conditions of every participating client. The proposed algorithm is\nbacked by extensive experiments to demonstrate the efficacy of our approach."}
{"id": "2505.20524", "pdf": "https://arxiv.org/pdf/2505.20524", "abs": "https://arxiv.org/abs/2505.20524", "authors": ["Alejandro Hern√°ndez-Cano", "Dhia Garbaya", "Imanol Schlag", "Martin Jaggi"], "title": "Towards Fully FP8 GEMM LLM Training at Scale", "categories": ["cs.LG"], "comment": "15 pages, 7 figures", "summary": "Despite the significant potential of FP8 data formats for large language\nmodel (LLM) pre-training, their adoption has been limited due to challenges in\nmaintaining stability at scale. Existing approaches often rely on suboptimal\nfine-grained FP8 kernels or fall back to higher-precision matrix\nmultiplications (GEMMs) in sensitive components, such as attention projections,\ncompromising potential throughput gains. We introduce a new class of LLM\narchitectures that, for the first time, support FP8 computation for all GEMMs\nwithin transformer blocks during both forward and backward passes. This enables\nunprecedented throughput gains, particularly at scale, while matching the\ndownstream performance of standard BF16 training. Our architecture design\nreduces large outlier activations, promoting stable long-term FP8 training. In\naddition, we identify key metrics to monitor low-precision training and predict\npotential future divergences."}
{"id": "2505.20749", "pdf": "https://arxiv.org/pdf/2505.20749", "abs": "https://arxiv.org/abs/2505.20749", "authors": ["Alfin Wijaya Rahardja", "Junwei Liu", "Weitong Chen", "Zhenpeng Chen", "Yiling Lou"], "title": "Can Agents Fix Agent Issues?", "categories": ["cs.AI", "cs.SE"], "comment": "18 pages, 7 figures", "summary": "LLM-based agent systems are emerging as a new software paradigm and have been\nwidely adopted across diverse domains such as medicine, robotics, and\nprogramming. However, maintaining these systems requires substantial effort, as\nthey are inevitably prone to bugs and continually evolve to meet changing\nexternal requirements. Therefore, automatically resolving agent issues (i.e.,\nbug reports or feature requests) is a crucial and challenging task. While\nrecent software engineering (SE) agents (e.g., SWE-agent) have shown promise in\naddressing issues in traditional software systems, it remains unclear how\neffectively they can resolve real-world issues in agent systems, which differ\nsignificantly from traditional software. To fill this gap, we first manually\nanalyze 201 real-world agent issues and identify common categories of agent\nissues. We then spend 500 person-hours constructing AGENTISSUE-BENCH, a\nreproducible benchmark comprising 50 agent issue resolution tasks (each with an\nexecutable environment and failure-triggering tests). We further evaluate\nstate-of-the-art SE agents on AGENTISSUE-BENCH and reveal their limited\neffectiveness (i.e., with only 3.33% - 12.67% resolution rates). These results\nunderscore the unique challenges of maintaining agent systems compared to\ntraditional software, highlighting the need for further research to develop\nadvanced SE agents for resolving agent issues. Data and code are available at\nhttps://alfin06.github.io/AgentIssue-Bench-Leaderboard/#/ ."}
{"id": "2505.21073", "pdf": "https://arxiv.org/pdf/2505.21073", "abs": "https://arxiv.org/abs/2505.21073", "authors": ["Pierre Houedry", "Nicolas Courty", "Florestan Martin-Baillon", "Laetitia Chapel", "Titouan Vayer"], "title": "Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Trees and the associated shortest-path tree metrics provide a powerful\nframework for representing hierarchical and combinatorial structures in data.\nGiven an arbitrary metric space, its deviation from a tree metric can be\nquantified by Gromov's $\\delta$-hyperbolicity. Nonetheless, designing\nalgorithms that bridge an arbitrary metric to its closest tree metric is still\na vivid subject of interest, as most common approaches are either heuristical\nand lack guarantees, or perform moderately well. In this work, we introduce a\nnovel differentiable optimization framework, coined DeltaZero, that solves this\nproblem. Our method leverages a smooth surrogate for Gromov's\n$\\delta$-hyperbolicity which enables a gradient-based optimization, with a\ntractable complexity. The corresponding optimization procedure is derived from\na problem with better worst case guarantees than existing bounds, and is\njustified statistically. Experiments on synthetic and real-world datasets\ndemonstrate that our method consistently achieves state-of-the-art distortion."}
{"id": "2505.20532", "pdf": "https://arxiv.org/pdf/2505.20532", "abs": "https://arxiv.org/abs/2505.20532", "authors": ["Dian Jin", "Xin Bing", "Yuqian Zhang"], "title": "One-shot Robust Federated Learning of Independent Component Analysis", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper investigates a general robust one-shot aggregation framework for\ndistributed and federated Independent Component Analysis (ICA) problem. We\npropose a geometric median-based aggregation algorithm that leverages $k$-means\nclustering to resolve the permutation ambiguity in local client estimations.\nOur method first performs k-means to partition client-provided estimators into\nclusters and then aggregates estimators within each cluster using the geometric\nmedian. This approach provably remains effective even in highly heterogeneous\nscenarios where at most half of the clients can observe only a minimal number\nof samples. The key theoretical contribution lies in the combined analysis of\nthe geometric median's error bound-aided by sample quantiles-and the maximum\nmisclustering rates of the aforementioned solution of $k$-means. The\neffectiveness of the proposed approach is further supported by simulation\nstudies conducted under various heterogeneous settings."}
{"id": "2505.20820", "pdf": "https://arxiv.org/pdf/2505.20820", "abs": "https://arxiv.org/abs/2505.20820", "authors": ["Hyomin Kim", "Yunhui Jang", "Sungsoo Ahn"], "title": "MT-Mol:Multi Agent System with Tool-based Reasoning for Molecular Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have large potential for molecular optimization,\nas they can gather external chemistry tools and enable collaborative\ninteractions to iteratively refine molecular candidates. However, this\npotential remains underexplored, particularly in the context of structured\nreasoning, interpretability, and comprehensive tool-grounded molecular\noptimization. To address this gap, we introduce MT-Mol, a multi-agent framework\nfor molecular optimization that leverages tool-guided reasoning and\nrole-specialized LLM agents. Our system incorporates comprehensive RDKit tools,\ncategorized into five distinct domains: structural descriptors, electronic and\ntopological features, fragment-based functional groups, molecular\nrepresentations, and miscellaneous chemical properties. Each category is\nmanaged by an expert analyst agent, responsible for extracting task-relevant\ntools and enabling interpretable, chemically grounded feedback. MT-Mol produces\nmolecules with tool-aligned and stepwise reasoning through the interaction\nbetween the analyst agents, a molecule-generating scientist, a reasoning-output\nverifier, and a reviewer agent. As a result, we show that our framework shows\nthe state-of-the-art performance of the PMO-1K benchmark on 17 out of 23 tasks."}
{"id": "2505.21074", "pdf": "https://arxiv.org/pdf/2505.21074", "abs": "https://arxiv.org/abs/2505.21074", "authors": ["Yichuan Cao", "Yibo Miao", "Xiao-Shan Gao", "Yinpeng Dong"], "title": "Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "stat.ML"], "comment": null, "summary": "Text-to-image (T2I) models raise ethical and safety concerns due to their\npotential to generate inappropriate or harmful images. Evaluating these models'\nsecurity through red-teaming is vital, yet white-box approaches are limited by\ntheir need for internal access, complicating their use with closed-source\nmodels. Moreover, existing black-box methods often assume knowledge about the\nmodel's specific defense mechanisms, limiting their utility in real-world\ncommercial API scenarios. A significant challenge is how to evade unknown and\ndiverse defense mechanisms. To overcome this difficulty, we propose a novel\nRule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively\nemploys LLM to modify prompts to query and leverages feedback from T2I systems\nfor fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a\nprior, enabling the LLM to dynamically adapt to unknown defense mechanisms.\nGiven that the feedback is often labeled and coarse-grained, making it\ndifficult to utilize directly, we further propose rule-based preference\nmodeling, which employs a set of rules to evaluate desired or undesired\nfeedback, facilitating finer-grained control over the LLM's dynamic adaptation\nprocess. Extensive experiments on nineteen T2I systems with varied safety\nmechanisms, three online commercial API services, and T2V models verify the\nsuperiority and practicality of our approach."}
{"id": "2505.20535", "pdf": "https://arxiv.org/pdf/2505.20535", "abs": "https://arxiv.org/abs/2505.20535", "authors": ["Uros Zivanovic", "Serafina Di Gioia", "Andre Scaffidi", "Mart√≠n de los Rios", "Gabriella Contardo", "Roberto Trotta"], "title": "Rotary Masked Autoencoders are Versatile Learners", "categories": ["cs.LG"], "comment": "26 pages, 5 figures", "summary": "Applying Transformers to irregular time-series typically requires\nspecializations to their baseline architecture, which can result in additional\ncomputational overhead and increased method complexity. We present the Rotary\nMasked Autoencoder (RoMAE), which utilizes the popular Rotary Positional\nEmbedding (RoPE) method for continuous positions. RoMAE is an extension to the\nMasked Autoencoder (MAE) that enables representation learning with\nmultidimensional continuous positional information while avoiding any\ntime-series-specific architectural specializations. We showcase RoMAE's\nperformance on a variety of modalities including irregular and multivariate\ntime-series, images, and audio, demonstrating that RoMAE surpasses specialized\ntime-series architectures on difficult datasets such as the DESC ELAsTiCC\nChallenge while maintaining MAE's usual performance across other modalities. In\naddition, we investigate RoMAE's ability to reconstruct the embedded continuous\npositions, demonstrating that including learned embeddings in the input\nsequence breaks RoPE's relative position property."}
{"id": "2505.20869", "pdf": "https://arxiv.org/pdf/2505.20869", "abs": "https://arxiv.org/abs/2505.20869", "authors": ["Kuo Zhou", "Lu Zhang"], "title": "Step-Wise Formal Verification for LLM-Based Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated formidable capabilities in\nsolving mathematical problems, yet they may still commit logical reasoning and\ncomputational errors during the problem-solving process. Thus, this paper\nproposes a framework, MATH-VF, which includes a Formalizer and a Critic, for\nformally verifying the correctness of the solutions generated by large language\nmodels. Our framework first utilizes a Formalizer which employs an LLM to\ntranslate a natural language solution into a formal context. Afterward, our\nCritic (which integrates various external tools such as a Computer Algebra\nSystem and an SMT solver) evaluates the correctness of each statement within\nthe formal context, and when a statement is incorrect, our Critic provides\ncorrective feedback. We empirically investigate the effectiveness of MATH-VF in\ntwo scenarios: 1) Verification: MATH-VF is utilized to determine the\ncorrectness of a solution to a given problem. 2) Refinement: When MATH-VF\nidentifies errors in the solution generated by an LLM-based solution generator\nfor a given problem, it submits the corrective suggestions proposed by the\nCritic to the solution generator to regenerate the solution. We evaluate our\nframework on widely used mathematical benchmarks: MATH500 and ProcessBench,\ndemonstrating the superiority of our approach over existing approaches."}
{"id": "2505.21119", "pdf": "https://arxiv.org/pdf/2505.21119", "abs": "https://arxiv.org/abs/2505.21119", "authors": ["Moritz A. Zanger", "Max Weltevrede", "Yaniv Oren", "Pascal R. Van der Vaart", "Caroline Horsch", "Wendelin B√∂hmer", "Matthijs T. J. Spaan"], "title": "Universal Value-Function Uncertainties", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Estimating epistemic uncertainty in value functions is a crucial challenge\nfor many aspects of reinforcement learning (RL), including efficient\nexploration, safe decision-making, and offline RL. While deep ensembles provide\na robust method for quantifying value uncertainty, they come with significant\ncomputational overhead. Single-model methods, while computationally favorable,\noften rely on heuristics and typically require additional propagation\nmechanisms for myopic uncertainty estimates. In this work we introduce\nuniversal value-function uncertainties (UVU), which, similar in spirit to\nrandom network distillation (RND), quantify uncertainty as squared prediction\nerrors between an online learner and a fixed, randomly initialized target\nnetwork. Unlike RND, UVU errors reflect policy-conditional value uncertainty,\nincorporating the future uncertainties any given policy may encounter. This is\ndue to the training procedure employed in UVU: the online network is trained\nusing temporal difference learning with a synthetic reward derived from the\nfixed, randomly initialized target network. We provide an extensive theoretical\nanalysis of our approach using neural tangent kernel (NTK) theory and show that\nin the limit of infinite network width, UVU errors are exactly equivalent to\nthe variance of an ensemble of independent universal value functions.\nEmpirically, we show that UVU achieves equal performance to large ensembles on\nchallenging multi-task offline RL settings, while offering simplicity and\nsubstantial computational savings."}
{"id": "2505.20553", "pdf": "https://arxiv.org/pdf/2505.20553", "abs": "https://arxiv.org/abs/2505.20553", "authors": ["Lu√≠s Carvalho", "Jo√£o L. Costa", "Jos√© Mour√£o", "Gon√ßalo Oliveira"], "title": "A ZeNN architecture to avoid the Gaussian trap", "categories": ["cs.LG", "math.PR", "68T07, 68T01", "I.2.0; G.0"], "comment": null, "summary": "We propose a new simple architecture, Zeta Neural Networks (ZeNNs), in order\nto overcome several shortcomings of standard multi-layer perceptrons (MLPs).\nNamely, in the large width limit, MLPs are non-parametric, they do not have a\nwell-defined pointwise limit, they lose non-Gaussian attributes and become\nunable to perform feature learning; moreover, finite width MLPs perform poorly\nin learning high frequencies. The new ZeNN architecture is inspired by three\nsimple principles from harmonic analysis:\n  i) Enumerate the perceptons and introduce a non-learnable weight to enforce\nconvergence;\n  ii) Introduce a scaling (or frequency) factor;\n  iii) Choose activation functions that lead to near orthogonal systems.\n  We will show that these ideas allow us to fix the referred shortcomings of\nMLPs. In fact, in the infinite width limit, ZeNNs converge pointwise, they\nexhibit a rich asymptotic structure beyond Gaussianity, and perform feature\nlearning. Moreover, when appropriate activation functions are chosen, (finite\nwidth) ZeNNs excel at learning high-frequency features of functions with low\ndimensional domains."}
{"id": "2505.20889", "pdf": "https://arxiv.org/pdf/2505.20889", "abs": "https://arxiv.org/abs/2505.20889", "authors": ["Leizhen Wang", "Peibo Duan", "Cheng Lyu", "Zhenliang Ma"], "title": "Reinforcement Learning-based Sequential Route Recommendation for System-Optimal Traffic Assignment", "categories": ["cs.AI"], "comment": null, "summary": "Modern navigation systems and shared mobility platforms increasingly rely on\npersonalized route recommendations to improve individual travel experience and\noperational efficiency. However, a key question remains: can such sequential,\npersonalized routing decisions collectively lead to system-optimal (SO) traffic\nassignment? This paper addresses this question by proposing a learning-based\nframework that reformulates the static SO traffic assignment problem as a\nsingle-agent deep reinforcement learning (RL) task. A central agent\nsequentially recommends routes to travelers as origin-destination (OD) demands\narrive, to minimize total system travel time. To enhance learning efficiency\nand solution quality, we develop an MSA-guided deep Q-learning algorithm that\nintegrates the iterative structure of traditional traffic assignment methods\ninto the RL training process. The proposed approach is evaluated on both the\nBraess and Ortuzar-Willumsen (OW) networks. Results show that the RL agent\nconverges to the theoretical SO solution in the Braess network and achieves\nonly a 0.35% deviation in the OW network. Further ablation studies demonstrate\nthat the route action set's design significantly impacts convergence speed and\nfinal performance, with SO-informed route sets leading to faster learning and\nbetter outcomes. This work provides a theoretically grounded and practically\nrelevant approach to bridging individual routing behavior with system-level\nefficiency through learning-based sequential assignment."}
{"id": "2505.21133", "pdf": "https://arxiv.org/pdf/2505.21133", "abs": "https://arxiv.org/abs/2505.21133", "authors": ["Marshal Arijona Sinaga", "Julien Martinelli", "Samuel Kaski"], "title": "Robust and Computation-Aware Gaussian Processes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian processes (GPs) are widely used for regression and optimization\ntasks such as Bayesian optimization (BO) due to their expressiveness and\nprincipled uncertainty estimates. However, in settings with large datasets\ncorrupted by outliers, standard GPs and their sparse approximations struggle\nwith computational tractability and robustness. We introduce Robust\nComputation-aware Gaussian Process (RCaGP), a novel GP model that jointly\naddresses these challenges by combining a principled treatment of\napproximation-induced uncertainty with robust generalized Bayesian updating.\nThe key insight is that robustness and approximation-awareness are not\northogonal but intertwined: approximations can exacerbate the impact of\noutliers, and mitigating one without the other is insufficient. Unlike previous\nwork that focuses narrowly on either robustness or approximation quality, RCaGP\ncombines both in a principled and scalable framework, thus effectively managing\nboth outliers and computational uncertainties introduced by approximations such\nas low-rank matrix multiplications. Our model ensures more conservative and\nreliable uncertainty estimates, a property we rigorously demonstrate.\nAdditionally, we establish a robustness property and show that the mean\nfunction is key to preserving it, motivating a tailored model selection scheme\nfor robust mean functions. Empirical results confirm that solving these\nchallenges jointly leads to superior performance across both clean and\noutlier-contaminated settings, both on regression and high-throughput Bayesian\noptimization benchmarks."}
{"id": "2505.20556", "pdf": "https://arxiv.org/pdf/2505.20556", "abs": "https://arxiv.org/abs/2505.20556", "authors": ["Yinglun Xu", "Hangoo Kang", "Tarun Suresh", "Yuxuan Wan", "Gagandeep Singh"], "title": "Learning a Pessimistic Reward Model in RLHF", "categories": ["cs.LG"], "comment": null, "summary": "This work proposes `PET', a novel pessimistic reward fine-tuning method, to\nlearn a pessimistic reward model robust against reward hacking in offline\nreinforcement learning from human feedback (RLHF). Traditional reward modeling\ntechniques in RLHF train an imperfect reward model, on which a KL\nregularization plays a pivotal role in mitigating reward hacking when\noptimizing a policy. Such an intuition-based method still suffers from reward\nhacking, and the policies with large KL divergence from the dataset\ndistribution are excluded during learning. In contrast, we show that when\noptimizing a policy on a pessimistic reward model fine-tuned through PET,\nreward hacking can be prevented without relying on any regularization. We test\nour methods on the standard TL;DR summarization dataset. We find that one can\nlearn a high-quality policy on our pessimistic reward without using any\nregularization. Such a policy has a high KL divergence from the dataset\ndistribution while having high performance in practice. In summary, our work\nshows the feasibility of learning a pessimistic reward model against reward\nhacking. The agent can greedily search for the policy with a high pessimistic\nreward without suffering from reward hacking."}
{"id": "2505.20948", "pdf": "https://arxiv.org/pdf/2505.20948", "abs": "https://arxiv.org/abs/2505.20948", "authors": ["Yisen Gao", "Jiaxin Bai", "Tianshi Zheng", "Qingyun Sun", "Ziwei Zhang", "Jianxin Li", "Yangqiu Song", "Xingcheng Fu"], "title": "Controllable Logical Hypothesis Generation for Abductive Reasoning in Knowledge Graphs", "categories": ["cs.AI"], "comment": "Under Review", "summary": "Abductive reasoning in knowledge graphs aims to generate plausible logical\nhypotheses from observed entities, with broad applications in areas such as\nclinical diagnosis and scientific discovery. However, due to a lack of\ncontrollability, a single observation may yield numerous plausible but\nredundant or irrelevant hypotheses on large-scale knowledge graphs. To address\nthis limitation, we introduce the task of controllable hypothesis generation to\nimprove the practical utility of abductive reasoning. This task faces two key\nchallenges when controlling for generating long and complex logical hypotheses:\nhypothesis space collapse and hypothesis oversensitivity. To address these\nchallenges, we propose CtrlHGen, a Controllable logcial Hypothesis Generation\nframework for abductive reasoning over knowledge graphs, trained in a two-stage\nparadigm including supervised learning and subsequent reinforcement learning.\nTo mitigate hypothesis space collapse, we design a dataset augmentation\nstrategy based on sub-logical decomposition, enabling the model to learn\ncomplex logical structures by leveraging semantic patterns in simpler\ncomponents. To address hypothesis oversensitivity, we incorporate smoothed\nsemantic rewards including Dice and Overlap scores, and introduce a\ncondition-adherence reward to guide the generation toward user-specified\ncontrol constraints. Extensive experiments on three benchmark datasets\ndemonstrate that our model not only better adheres to control conditions but\nalso achieves superior semantic similarity performance compared to baselines."}
{"id": "2505.21135", "pdf": "https://arxiv.org/pdf/2505.21135", "abs": "https://arxiv.org/abs/2505.21135", "authors": ["Anqi Tang", "Youming Chen", "Shuchen Xue", "Zhaoqiang Liu"], "title": "Learning Single Index Models with Diffusion Priors", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "ICML 2025", "summary": "Diffusion models (DMs) have demonstrated remarkable ability to generate\ndiverse and high-quality images by efficiently modeling complex data\ndistributions. They have also been explored as powerful generative priors for\nsignal recovery, resulting in a substantial improvement in the quality of\nreconstructed signals. However, existing research on signal recovery with\ndiffusion models either focuses on specific reconstruction problems or is\nunable to handle nonlinear measurement models with discontinuous or unknown\nlink functions. In this work, we focus on using DMs to achieve accurate\nrecovery from semi-parametric single index models, which encompass a variety of\npopular nonlinear models that may have {\\em discontinuous} and {\\em unknown}\nlink functions. We propose an efficient reconstruction method that only\nrequires one round of unconditional sampling and (partial) inversion of DMs.\nTheoretical analysis on the effectiveness of the proposed methods has been\nestablished under appropriate conditions. We perform numerical experiments on\nimage datasets for different nonlinear measurement models. We observe that\ncompared to competing methods, our approach can yield more accurate\nreconstructions while utilizing significantly fewer neural function\nevaluations."}
{"id": "2505.20561", "pdf": "https://arxiv.org/pdf/2505.20561", "abs": "https://arxiv.org/abs/2505.20561", "authors": ["Shenao Zhang", "Yaqing Wang", "Yinxiao Liu", "Tianqi Liu", "Peter Grabowski", "Eugene Ie", "Zhaoran Wang", "Yunxuan Li"], "title": "Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL."}
{"id": "2505.21045", "pdf": "https://arxiv.org/pdf/2505.21045", "abs": "https://arxiv.org/abs/2505.21045", "authors": ["Lingyi Cai", "Ruichen Zhang", "Changyuan Zhao", "Yu Zhang", "Jiawen Kang", "Dusit Niyato", "Tao Jiang", "Xuemin Shen"], "title": "Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking", "categories": ["cs.AI"], "comment": "7 pages, 5 figures", "summary": "Low-Altitude Economic Networking (LAENet) aims to support diverse flying\napplications below 1,000 meters by deploying various aerial vehicles for\nflexible and cost-effective aerial networking. However, complex\ndecision-making, resource constraints, and environmental uncertainty pose\nsignificant challenges to the development of the LAENet. Reinforcement learning\n(RL) offers a potential solution in response to these challenges but has\nlimitations in generalization, reward design, and model stability. The\nemergence of large language models (LLMs) offers new opportunities for RL to\nmitigate these limitations. In this paper, we first present a tutorial about\nintegrating LLMs into RL by using the capacities of generation, contextual\nunderstanding, and structured reasoning of LLMs. We then propose an\nLLM-enhanced RL framework for the LAENet in terms of serving the LLM as\ninformation processor, reward designer, decision-maker, and generator.\nMoreover, we conduct a case study by using LLMs to design a reward function to\nimprove the learning performance of RL in the LAENet. Finally, we provide a\nconclusion and discuss future work."}
{"id": "2505.21285", "pdf": "https://arxiv.org/pdf/2505.21285", "abs": "https://arxiv.org/abs/2505.21285", "authors": ["Xudong Wang", "Ziheng Sun", "Chris Ding", "Jicong Fan"], "title": "Learnable Kernel Density Estimation for Graphs", "categories": ["cs.LG", "stat.ML", "I.2; I.5.1; I.5.2"], "comment": "Under Review", "summary": "This work proposes a framework LGKDE that learns kernel density estimation\nfor graphs. The key challenge in graph density estimation lies in effectively\ncapturing both structural patterns and semantic variations while maintaining\ntheoretical guarantees. Combining graph kernels and kernel density estimation\n(KDE) is a standard approach to graph density estimation, but has\nunsatisfactory performance due to the handcrafted and fixed features of\nkernels. Our method LGKDE leverages graph neural networks to represent each\ngraph as a discrete distribution and utilizes maximum mean discrepancy to learn\nthe graph metric for multi-scale KDE, where all parameters are learned by\nmaximizing the density of graphs relative to the density of their well-designed\nperturbed counterparts. The perturbations are conducted on both node features\nand graph spectra, which helps better characterize the boundary of normal\ndensity regions. Theoretically, we establish consistency and convergence\nguarantees for LGKDE, including bounds on the mean integrated squared error,\nrobustness, and complexity. We validate LGKDE by demonstrating its\neffectiveness in recovering the underlying density of synthetic graph\ndistributions and applying it to graph anomaly detection across diverse\nbenchmark datasets. Extensive empirical evaluation shows that LGKDE\ndemonstrates superior performance compared to state-of-the-art baselines on\nmost benchmark datasets."}
{"id": "2505.20563", "pdf": "https://arxiv.org/pdf/2505.20563", "abs": "https://arxiv.org/abs/2505.20563", "authors": ["Jingjing Liu", "Xiansen Ju", "Xianchao Xiu", "Wanquan Liu"], "title": "Bi-Level Unsupervised Feature Selection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Unsupervised feature selection (UFS) is an important task in data\nengineering. However, most UFS methods construct models from a single\nperspective and often fail to simultaneously evaluate feature importance and\npreserve their inherent data structure, thus limiting their performance. To\naddress this challenge, we propose a novel bi-level unsupervised feature\nselection (BLUFS) method, including a clustering level and a feature level.\nSpecifically, at the clustering level, spectral clustering is used to generate\npseudo-labels for representing the data structure, while a continuous linear\nregression model is developed to learn the projection matrix. At the feature\nlevel, the $\\ell_{2,0}$-norm constraint is imposed on the projection matrix for\nmore effectively selecting features. To the best of our knowledge, this is the\nfirst work to combine a bi-level framework with the $\\ell_{2,0}$-norm. To solve\nthe proposed bi-level model, we design an efficient proximal alternating\nminimization (PAM) algorithm, whose subproblems either have explicit solutions\nor can be computed by fast solvers. Furthermore, we establish the convergence\nresult and computational complexity. Finally, extensive experiments on two\nsynthetic datasets and eight real datasets demonstrate the superiority of BLUFS\nin clustering and classification tasks."}
{"id": "2505.21055", "pdf": "https://arxiv.org/pdf/2505.21055", "abs": "https://arxiv.org/abs/2505.21055", "authors": ["Kaiming Liu", "Xuanyu Lei", "Ziyue Wang", "Peng Li", "Yang Liu"], "title": "Agent-Environment Alignment via Automated Interface Generation", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents have shown impressive reasoning\ncapabilities in interactive decision-making tasks. These agents interact with\nenvironment through intermediate interfaces, such as predefined action spaces\nand interaction rules, which mediate the perception and action. However,\nmismatches often happen between the internal expectations of the agent\nregarding the influence of its issued actions and the actual state transitions\nin the environment, a phenomenon referred to as \\textbf{agent-environment\nmisalignment}. While prior work has invested substantially in improving agent\nstrategies and environment design, the critical role of the interface still\nremains underexplored. In this work, we empirically demonstrate that\nagent-environment misalignment poses a significant bottleneck to agent\nperformance. To mitigate this issue, we propose \\textbf{ALIGN}, an\n\\underline{A}uto-A\\underline{l}igned \\underline{I}nterface\n\\underline{G}e\\underline{n}eration framework that alleviates the misalignment\nby enriching the interface. Specifically, the ALIGN-generated interface\nenhances both the static information of the environment and the step-wise\nobservations returned to the agent. Implemented as a lightweight wrapper, this\ninterface achieves the alignment without modifying either the agent logic or\nthe environment code. Experiments across multiple domains including embodied\ntasks, web navigation and tool-use, show consistent performance improvements,\nwith up to a 45.67\\% success rate improvement observed in ALFWorld. Meanwhile,\nALIGN-generated interface can generalize across different agent architectures\nand LLM backbones without interface regeneration. Code and experimental results\nare available at https://github.com/THUNLP-MT/ALIGN."}
{"id": "2505.21336", "pdf": "https://arxiv.org/pdf/2505.21336", "abs": "https://arxiv.org/abs/2505.21336", "authors": ["Loucas Pillaud-Vivien", "Adrien Schertzer"], "title": "Joint Learning in the Gaussian Single Index Model", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "31 Pages, 3 Figures", "summary": "We consider the problem of jointly learning a one-dimensional projection and\na univariate function in high-dimensional Gaussian models. Specifically, we\nstudy predictors of the form $f(x)=\\varphi^\\star(\\langle w^\\star, x \\rangle)$,\nwhere both the direction $w^\\star \\in \\mathcal{S}_{d-1}$, the sphere of\n$\\mathbb{R}^d$, and the function $\\varphi^\\star: \\mathbb{R} \\to \\mathbb{R}$ are\nlearned from Gaussian data. This setting captures a fundamental non-convex\nproblem at the intersection of representation learning and nonlinear\nregression. We analyze the gradient flow dynamics of a natural alternating\nscheme and prove convergence, with a rate controlled by the information\nexponent reflecting the \\textit{Gaussian regularity} of the function\n$\\varphi^\\star$. Strikingly, our analysis shows that convergence still occurs\neven when the initial direction is negatively correlated with the target. On\nthe practical side, we demonstrate that such joint learning can be effectively\nimplemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the\nstructure of the problem, enabling efficient and flexible estimation of the\nunivariate function. Our results offer both theoretical insight and practical\nmethodology for learning low-dimensional structure in high-dimensional\nsettings."}
{"id": "2505.20578", "pdf": "https://arxiv.org/pdf/2505.20578", "abs": "https://arxiv.org/abs/2505.20578", "authors": ["Xingyu Chen", "Shihao Ma", "Runsheng Lin", "Jiecong Lin", "Bo Wang"], "title": "Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "9 pages, 3 figures", "summary": "Designing regulatory DNA sequences that achieve precise cell-type-specific\ngene expression is crucial for advancements in synthetic biology, gene therapy\nand precision medicine. Although transformer-based language models (LMs) can\neffectively capture patterns in regulatory DNA, their generative approaches\noften struggle to produce novel sequences with reliable cell-specific activity.\nHere, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL)\nframework tailored for designing regulatory DNA sequences with controllable\ncell-type specificity. By formulating regulatory sequence design as a\nbiologically informed constrained optimization problem, we apply RL to\nautoregressive genomic LMs, enabling the models to iteratively refine sequences\nthat maximize regulatory activity in targeted cell types while constraining\noff-target effects. Our evaluation on human promoters and enhancers\ndemonstrates that Ctrl-DNA consistently outperforms existing generative and\nRL-based approaches, generating high-fitness regulatory sequences and achieving\nstate-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences\ncapture key cell-type-specific transcription factor binding sites (TFBS), short\nDNA motifs recognized by regulatory proteins that control gene expression,\ndemonstrating the biological plausibility of the generated sequences."}
{"id": "2505.21067", "pdf": "https://arxiv.org/pdf/2505.21067", "abs": "https://arxiv.org/abs/2505.21067", "authors": ["Xiao Hu", "Xingyu Lu", "Liyuan Mao", "YiFan Zhang", "Tianke Zhang", "Bin Wen", "Fan Yang", "Tingting Gao", "Guorui Zhou"], "title": "Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has played an important role in improving the\nreasoning ability of large language models (LLMs). Some studies apply RL\ndirectly to \\textit{smaller} base models (known as zero-RL) and also achieve\nnotable progress. However, in this paper, we show that using only 920 examples,\na simple distillation method based on the base model can clearly outperform\nzero-RL, which typically requires much more data and computational cost. By\nanalyzing the token frequency in model outputs, we find that the distilled\nmodel shows more flexible reasoning. It uses anthropomorphic tokens and logical\nconnectors much more often than the zero-RL model. Further analysis reveals\nthat distillation enhances the presence of two advanced cognitive behaviors:\nMulti-Perspective Thinking or Attempting and Metacognitive Awareness. Frequent\noccurrences of these two advanced cognitive behaviors give rise to flexible\nreasoning, which is essential for solving complex reasoning problems, while\nzero-RL fails to significantly boost the frequency of these behaviors."}
{"id": "2505.21391", "pdf": "https://arxiv.org/pdf/2505.21391", "abs": "https://arxiv.org/abs/2505.21391", "authors": ["Zixuan Xie", "Xinyu Liu", "Rohan Chandra", "Shangtong Zhang"], "title": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point."}
{"id": "2505.20579", "pdf": "https://arxiv.org/pdf/2505.20579", "abs": "https://arxiv.org/abs/2505.20579", "authors": ["Dane Malenfant", "Blake A. Richards"], "title": "The challenge of hidden gifts in multi-agent reinforcement learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings."}
{"id": "2505.21106", "pdf": "https://arxiv.org/pdf/2505.21106", "abs": "https://arxiv.org/abs/2505.21106", "authors": ["Zhengyang Ji", "Yifan Jia", "Shang Gao", "Yutao Yue"], "title": "Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Large Vision Language Models (LVLMs) have achieved remarkable progress in\nmultimodal tasks, yet they also exhibit notable social biases. These biases\noften manifest as unintended associations between neutral concepts and\nsensitive human attributes, leading to disparate model behaviors across\ndemographic groups. While existing studies primarily focus on detecting and\nquantifying such biases, they offer limited insight into the underlying\nmechanisms within the models. To address this gap, we propose an explanatory\nframework that combines information flow analysis with multi-round dialogue\nevaluation, aiming to understand the origin of social bias from the perspective\nof imbalanced internal information utilization. Specifically, we first identify\nhigh-contribution image tokens involved in the model's reasoning process for\nneutral questions via information flow analysis. Then, we design a multi-turn\ndialogue mechanism to evaluate the extent to which these key tokens encode\nsensitive information. Extensive experiments reveal that LVLMs exhibit\nsystematic disparities in information usage when processing images of different\ndemographic groups, suggesting that social bias is deeply rooted in the model's\ninternal reasoning dynamics. Furthermore, we complement our findings from a\ntextual modality perspective, showing that the model's semantic representations\nalready display biased proximity patterns, thereby offering a cross-modal\nexplanation of bias formation."}
{"id": "2505.21400", "pdf": "https://arxiv.org/pdf/2505.21400", "abs": "https://arxiv.org/abs/2505.21400", "authors": ["Gen Li", "Changxiao Cai"], "title": "A Convergence Theory for Diffusion Language Models: An Information-Theoretic Perspective", "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Diffusion models have emerged as a powerful paradigm for modern generative\nmodeling, demonstrating strong potential for large language models (LLMs).\nUnlike conventional autoregressive (AR) models that generate tokens\nsequentially, diffusion models enable parallel token sampling, leading to\nfaster generation and eliminating left-to-right generation constraints. Despite\ntheir empirical success, the theoretical understanding of diffusion model\napproaches remains underdeveloped. In this work, we develop convergence\nguarantees for diffusion language models from an information-theoretic\nperspective. Our analysis demonstrates that the sampling error, measured by the\nKullback-Leibler (KL) divergence, decays inversely with the number of\niterations $T$ and scales linearly with the mutual information between tokens\nin the target text sequence. In particular, we establish matching upper and\nlower bounds, up to some constant factor, to demonstrate the tightness of our\nconvergence analysis. These results offer novel theoretical insights into the\npractical effectiveness of diffusion language models."}
{"id": "2505.20589", "pdf": "https://arxiv.org/pdf/2505.20589", "abs": "https://arxiv.org/abs/2505.20589", "authors": ["Mahdi Pourmirzaei", "Farzaneh Esmaili", "Salhuldin Alqarghuli", "Mohammadreza Pourmirzaei", "Ye Han", "Kai Chen", "Mohsen Rezaei", "Duolin Wang", "Dong Xu"], "title": "Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "The diverse nature of protein prediction tasks has traditionally necessitated\nspecialized models, hindering the development of broadly applicable and\ncomputationally efficient Protein Language Models (PLMs). In this work, we\nintroduce Prot2Token, a unified framework that overcomes these challenges by\nconverting a wide spectrum of protein-related predictions, from sequence-level\nproperties and residue-specific attributes to complex inter-protein\ninteractions, into a standardized next-token prediction format. At its core,\nProt2Token employs an autoregressive decoder, conditioned on embeddings from\npre-trained protein encoders and guided by learnable task tokens, to perform\ndiverse predictions. This architecture uniquely facilitates multi-task\nlearning, enabling a single model to master numerous tasks with improved\nefficiency. We present extensive experimental validation across a variety of\nbenchmarks, demonstrating Prot2Tokens strong predictive power in different\ntypes of protein-prediction tasks. Key results include significant speedups\n(e.g., near 1000x over AlphaFold2 with MSA) and performance often matching or\nexceeding specialized approaches. Beyond that, we introduce an auxiliary\nself-supervised decoder pre-training approach to improve spatially sensitive\ntask performance. Prot2Token thus offers a significant step towards a\nversatile, high-throughput paradigm for protein modeling, promising to\naccelerate biological discovery and the development of novel therapeutics. The\ncode is available at https://github.com/mahdip72/prot2token ."}
{"id": "2505.21212", "pdf": "https://arxiv.org/pdf/2505.21212", "abs": "https://arxiv.org/abs/2505.21212", "authors": ["Martin C. Cooper", "Imane Bousdira", "Cl√©ment Carbonnel"], "title": "Interpretable DNFs", "categories": ["cs.AI", "68T27, 05C62", "F.4.1; I.2.6"], "comment": null, "summary": "A classifier is considered interpretable if each of its decisions has an\nexplanation which is small enough to be easily understood by a human user. A\nDNF formula can be seen as a binary classifier $\\kappa$ over boolean domains.\nThe size of an explanation of a positive decision taken by a DNF $\\kappa$ is\nbounded by the size of the terms in $\\kappa$, since we can explain a positive\ndecision by giving a term of $\\kappa$ that evaluates to true. Since both\npositive and negative decisions must be explained, we consider that\ninterpretable DNFs are those $\\kappa$ for which both $\\kappa$ and\n$\\overline{\\kappa}$ can be expressed as DNFs composed of terms of bounded size.\nIn this paper, we study the family of $k$-DNFs whose complements can also be\nexpressed as $k$-DNFs. We compare two such families, namely depth-$k$ decision\ntrees and nested $k$-DNFs, a novel family of models. Experiments indicate that\nnested $k$-DNFs are an interesting alternative to decision trees in terms of\ninterpretability and accuracy."}
{"id": "2505.21423", "pdf": "https://arxiv.org/pdf/2505.21423", "abs": "https://arxiv.org/abs/2505.21423", "authors": ["Vit Fojtik", "Maria Matveev", "Hung-Hsu Chou", "Gitta Kutyniok", "Johannes Maly"], "title": "Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A widely believed explanation for the remarkable generalization capacities of\noverparameterized neural networks is that the optimization algorithms used for\ntraining induce an implicit bias towards benign solutions. To grasp this\ntheoretically, recent works examine gradient descent and its variants in\nsimplified training settings, often assuming vanishing learning rates. These\nstudies reveal various forms of implicit regularization, such as $\\ell_1$-norm\nminimizing parameters in regression and max-margin solutions in classification.\nConcurrently, empirical findings show that moderate to large learning rates\nexceeding standard stability thresholds lead to faster, albeit oscillatory,\nconvergence in the so-called Edge-of-Stability regime, and induce an implicit\nbias towards minima of low sharpness (norm of training loss Hessian). In this\nwork, we argue that a comprehensive understanding of the generalization\nperformance of gradient descent requires analyzing the interaction between\nthese various forms of implicit regularization. We empirically demonstrate that\nthe learning rate balances between low parameter norm and low sharpness of the\ntrained model. We furthermore prove for diagonal linear networks trained on a\nsimple regression task that neither implicit bias alone minimizes the\ngeneralization error. These findings demonstrate that focusing on a single\nimplicit bias is insufficient to explain good generalization, and they motivate\na broader view of implicit regularization that captures the dynamic trade-off\nbetween norm and sharpness induced by non-negligible learning rates."}
{"id": "2505.20621", "pdf": "https://arxiv.org/pdf/2505.20621", "abs": "https://arxiv.org/abs/2505.20621", "authors": ["Shijie Liu", "Andrew C. Cullen", "Paul Montague", "Sarah Erfani", "Benjamin I. P. Rubinstein"], "title": "Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Similar to other machine learning frameworks, Offline Reinforcement Learning\n(RL) is shown to be vulnerable to poisoning attacks, due to its reliance on\nexternally sourced datasets, a vulnerability that is exacerbated by its\nsequential nature. To mitigate the risks posed by RL poisoning, we extend\ncertified defenses to provide larger guarantees against adversarial\nmanipulation, ensuring robustness for both per-state actions, and the overall\nexpected cumulative reward. Our approach leverages properties of Differential\nPrivacy, in a manner that allows this work to span both continuous and discrete\nspaces, as well as stochastic and deterministic environments -- significantly\nexpanding the scope and applicability of achievable guarantees. Empirical\nevaluations demonstrate that our approach ensures the performance drops to no\nmore than $50\\%$ with up to $7\\%$ of the training data poisoned, significantly\nimproving over the $0.008\\%$ in prior work~\\citep{wu_copa_2022}, while\nproducing certified radii that is $5$ times larger as well. This highlights the\npotential of our framework to enhance safety and reliability in offline RL."}
{"id": "2505.21279", "pdf": "https://arxiv.org/pdf/2505.21279", "abs": "https://arxiv.org/abs/2505.21279", "authors": ["Shaoqing Zhang", "Kehai Chen", "Zhuosheng Zhang", "Rumei Li", "Rongxiang Weng", "Yang Xiang", "Liqiang Nie", "Min Zhang"], "title": "XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in vision-language models (VLMs) have spurred increased\ninterest in Device-Control Agents (DC agents), such as utilizing in-the-wild\ndevice control to manage graphical user interfaces. Conventional methods for\nassessing the capabilities of DC agents, such as computing step-wise action\naccuracy and overall task success rates, provide a macroscopic view of DC\nagents' performance; however, they fail to offer microscopic insights into\npotential errors that may occur in real-world applications. Conducting a\nfiner-grained performance evaluation of DC agents presents significant\nchallenges. This study introduces a new perspective on evaluation methods for\nDC agents by proposing the XBOUND evaluation method, which employs the\ncalculation of a novel Explore Metric to delineate the capability boundaries of\nDC agents. Compared to previous evaluation methods, XBOUND focuses on\nindividual states to assess the proficiency of DC agents in mastering these\nstates. Furthermore, we have developed a ``pseudo'' episode tree dataset\nderived from Android Control test data. Utilizing this dataset and XBOUND, we\ncomprehensively evaluate the OS-Atlas and UI-TARS series, examining both the\noverall and specific performance across five common tasks. Additionally, we\nselect representative cases to highlight the current deficiencies and\nlimitations inherent in both series. Code is available at\nhttps://github.com/sqzhang-lazy/XBOUND."}
{"id": "2505.21460", "pdf": "https://arxiv.org/pdf/2505.21460", "abs": "https://arxiv.org/abs/2505.21460", "authors": ["Maxwell Fishelson", "Noah Golowich", "Mehryar Mohri", "Jon Schneider"], "title": "High-Dimensional Calibration from Swap Regret", "categories": ["cs.LG", "cs.DS", "cs.GT", "stat.ML"], "comment": null, "summary": "We study the online calibration of multi-dimensional forecasts over an\narbitrary convex set $\\mathcal{P} \\subset \\mathbb{R}^d$ relative to an\narbitrary norm $\\Vert\\cdot\\Vert$. We connect this with the problem of external\nregret minimization for online linear optimization, showing that if it is\npossible to guarantee $O(\\sqrt{\\rho T})$ worst-case regret after $T$ rounds\nwhen actions are drawn from $\\mathcal{P}$ and losses are drawn from the dual\n$\\Vert \\cdot \\Vert_*$ unit norm ball, then it is also possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\rho /\\epsilon^2))$ rounds.\nWhen $\\mathcal{P}$ is the $d$-dimensional simplex and $\\Vert \\cdot \\Vert$ is\nthe $\\ell_1$-norm, the existence of $O(\\sqrt{T\\log d})$-regret algorithms for\nlearning with experts implies that it is possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\log{d}/\\epsilon^2)) =\nd^{O(1/\\epsilon^2)}$ rounds, recovering a recent result of Peng (2025).\n  Interestingly, our algorithm obtains this guarantee without requiring access\nto any online linear optimization subroutine or knowledge of the optimal rate\n$\\rho$ -- in fact, our algorithm is identical for every setting of\n$\\mathcal{P}$ and $\\Vert \\cdot \\Vert$. Instead, we show that the optimal\nregularizer for the above OLO problem can be used to upper bound the above\ncalibration error by a swap regret, which we then minimize by running the\nrecent TreeSwap algorithm with Follow-The-Leader as a subroutine.\n  Finally, we prove that any online calibration algorithm that guarantees\n$\\epsilon T$ $\\ell_1$-calibration error over the $d$-dimensional simplex\nrequires $T \\geq \\exp(\\mathrm{poly}(1/\\epsilon))$ (assuming $d \\geq\n\\mathrm{poly}(1/\\epsilon)$). This strengthens the corresponding\n$d^{\\Omega(\\log{1/\\epsilon})}$ lower bound of Peng, and shows that an\nexponential dependence on $1/\\epsilon$ is necessary."}
{"id": "2505.20628", "pdf": "https://arxiv.org/pdf/2505.20628", "abs": "https://arxiv.org/abs/2505.20628", "authors": ["Juan Ramirez", "Meraj Hashemizadeh", "Simon Lacoste-Julien"], "title": "Position: Adopt Constraints Over Penalties in Deep Learning", "categories": ["cs.LG", "math.OC"], "comment": "Code available at\n  https://github.com/merajhashemi/constraints-vs-penalties", "summary": "Recent efforts toward developing trustworthy AI systems with accountability\nguarantees have led to a growing reliance on machine learning formulations that\nincorporate external requirements, or constraints. These requirements are often\nenforced through penalization--adding fixed-weight terms to the task loss. We\nargue that this approach is ill-suited, and that tailored constrained\noptimization methods should be adopted instead. In particular, no penalty\ncoefficient may yield a solution that both satisfies the constraints and\nachieves good performance--i.e., one solving the constrained problem. Moreover,\ntuning these coefficients is costly, incurring significant time and\ncomputational overhead. In contrast, tailored constrained methods--such as the\nLagrangian approach, which optimizes the penalization \"coefficients\" (the\nLagrange multipliers) alongside the model--(i) truly solve the constrained\nproblem and add accountability, (ii) eliminate the need for extensive penalty\ntuning, and (iii) integrate seamlessly with modern deep learning pipelines."}
{"id": "2505.21281", "pdf": "https://arxiv.org/pdf/2505.21281", "abs": "https://arxiv.org/abs/2505.21281", "authors": ["Yue Zhang", "Zhiliang Tian", "Shicheng Zhou", "Haiyang Wang", "Wenqing Hou", "Yuying Liu", "Xuechen Zhao", "Minlie Huang", "Ye Wang", "Bin Zhou"], "title": "RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing\nsemantic-enhanced LJP models integrate judicial precedents and legal knowledge\nfor high performance. But they neglect legal reasoning logic, a critical\ncomponent of legal judgments requiring rigorous logical analysis. Although some\napproaches utilize legal reasoning logic for high-quality predictions, their\nlogic rigidity hinders adaptation to case-specific logical frameworks,\nparticularly in complex cases that are lengthy and detailed. This paper\nproposes a rule-enhanced legal judgment prediction framework based on\nfirst-order logic (FOL) formalism and comparative learning (CL) to develop an\nadaptive adjustment mechanism for legal judgment logic and further enhance\nperformance in LJP. Inspired by the process of human exam preparation, our\nmethod follows a three-stage approach: first, we initialize judgment rules\nusing the FOL formalism to capture complex reasoning logic accurately; next, we\npropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize\nthe judgment rules through a quiz consisting of confusable cases; finally, we\nutilize the optimized judgment rules to predict legal judgments. Experimental\nresults on two public datasets show superior performance across all metrics.\nThe code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}."}
{"id": "2505.21468", "pdf": "https://arxiv.org/pdf/2505.21468", "abs": "https://arxiv.org/abs/2505.21468", "authors": ["Simon Dirmeier", "Antonietta Mira"], "title": "Causal Posterior Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present Causal Posterior Estimation (CPE), a novel method for Bayesian\ninference in simulator models, i.e., models where the evaluation of the\nlikelihood function is intractable or too computationally expensive, but where\none can simulate model outputs given parameter values. CPE utilizes a\nnormalizing flow-based (NF) approximation to the posterior distribution which\ncarefully incorporates the conditional dependence structure induced by the\ngraphical representation of the model into the neural network. Thereby it is\npossible to improve the accuracy of the approximation. We introduce both\ndiscrete and continuous NF architectures for CPE and propose a constant-time\nsampling procedure for the continuous case which reduces the computational\ncomplexity of drawing samples to O(1) as for discrete NFs. We show, through an\nextensive experimental evaluation, that by incorporating the conditional\ndependencies induced by the graphical model directly into the neural network,\nrather than learning them from data, CPE is able to conduct highly accurate\nposterior inference either outperforming or matching the state of the art in\nthe field."}
{"id": "2505.20634", "pdf": "https://arxiv.org/pdf/2505.20634", "abs": "https://arxiv.org/abs/2505.20634", "authors": ["Ruiqi Lyu", "Alistair Turcan", "Bryan Wilder"], "title": "Explaining Concept Shift with Interpretable Feature Attribution", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Regardless the amount of data a machine learning (ML) model is trained on,\nthere will inevitably be data that differs from their training set, lowering\nmodel performance. Concept shift occurs when the distribution of labels\nconditioned on the features changes, making even a well-tuned ML model to have\nlearned a fundamentally incorrect representation. Identifying these shifted\nfeatures provides unique insight into how one dataset differs from another,\nconsidering the difference may be across a scientifically relevant dimension,\nsuch as time, disease status, population, etc. In this paper, we propose\nSGShift, a model for detecting concept shift in tabular data and attributing\nreduced model performance to a sparse set of shifted features. SGShift models\nconcept shift with a Generalized Additive Model (GAM) and performs subsequent\nfeature selection to identify shifted features. We propose further extensions\nof SGShift by incorporating knockoffs to control false discoveries and an\nabsorption term to account for models with poor fit to the data. We conduct\nextensive experiments in synthetic and real data across various ML models and\nfind SGShift can identify shifted features with AUC $>0.9$ and recall $>90\\%$,\noften 2 or 3 times as high as baseline methods."}
{"id": "2505.21291", "pdf": "https://arxiv.org/pdf/2505.21291", "abs": "https://arxiv.org/abs/2505.21291", "authors": ["Saman Marandi", "Yu-Shu Hu", "Mohammad Modarres"], "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "categories": ["cs.AI"], "comment": "22 Pages, 11 Figures", "summary": "In this paper, we present a novel diagnostic framework that integrates\nKnowledge Graphs (KGs) and Large Language Models (LLMs) to support system\ndiagnostics in high-reliability systems such as nuclear power plants.\nTraditional diagnostic modeling struggles when systems become too complex,\nmaking functional modeling a more attractive approach. Our approach introduces\na diagnostic framework grounded in the functional modeling principles of the\nDynamic Master Logic (DML) model. It incorporates two coordinated LLM\ncomponents, including an LLM-based workflow for automated construction of DML\nlogic from system documentation and an LLM agent that facilitates interactive\ndiagnostics. The generated logic is encoded into a structured KG, referred to\nas KG-DML, which supports hierarchical fault reasoning. Expert knowledge or\noperational data can also be incorporated to refine the model's precision and\ndiagnostic depth. In the interaction phase, users submit natural language\nqueries, which are interpreted by the LLM agent. The agent selects appropriate\ntools for structured reasoning, including upward and downward propagation\nacross the KG-DML. Rather than embedding KG content into every prompt, the LLM\nagent distinguishes between diagnostic and interpretive tasks. For diagnostics,\nthe agent selects and executes external tools that perform structured KG\nreasoning. For general queries, a Graph-based Retrieval-Augmented Generation\n(Graph-RAG) approach is used, retrieving relevant KG segments and embedding\nthem into the prompt to generate natural explanations. A case study on an\nauxiliary feedwater system demonstrated the framework's effectiveness, with\nover 90% accuracy in key elements and consistent tool and argument extraction,\nsupporting its use in safety-critical diagnostics."}
{"id": "2505.20643", "pdf": "https://arxiv.org/pdf/2505.20643", "abs": "https://arxiv.org/abs/2505.20643", "authors": ["Bo Pan", "Liang Zhao"], "title": "Can Past Experience Accelerate LLM Reasoning?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Allocating more compute to large language models (LLMs) reasoning has\ngenerally been demonstrated to improve their effectiveness, but also results in\nincreased inference time. In contrast, humans can perform tasks faster and\nbetter with increased experience and exposure. Hence, this paper aims to\ninvestigate the question: Can LLMs also become faster at reasoning through\nrecurrent exposure on relevant tasks, and if so, how can it be achieved? To\naddress these questions, we first formalize the problem setting of LLM\nreasoning speedup systematically in the dimensions of task relevancy and\ncompute budget calculation. We then propose SpeedupLLM, a theoretically\nguaranteed framework to implement and benchmark such reasoning speedup\nbehaviour based on adaptive compute allocation and memory mechanisms. We\nfurther conduct comprehensive experiments to benchmark such behaviour across\ndifferent question similarity levels, memory methods, and reasoning methods.\nResults show that LLMs can generally reason faster with past experience,\nachieving up to a 56% reduction in compute cost when equipped with appropriate\nmemory and reasoning methods."}
{"id": "2505.21318", "pdf": "https://arxiv.org/pdf/2505.21318", "abs": "https://arxiv.org/abs/2505.21318", "authors": ["Hao Li", "He Cao", "Bin Feng", "Yanjun Shao", "Xiangru Tang", "Zhiyuan Yan", "Li Yuan", "Yonghong Tian", "Yu Li"], "title": "Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular Chemical Operations", "categories": ["cs.AI"], "comment": "22 pages, 10 figures", "summary": "While large language models (LLMs) with Chain-of-Thought (CoT) reasoning\nexcel in mathematics and coding, their potential for systematic reasoning in\nchemistry, a domain demanding rigorous structural analysis for real-world tasks\nlike drug design and reaction engineering, remains untapped. Current benchmarks\nfocus on simple knowledge retrieval, neglecting step-by-step reasoning required\nfor complex tasks such as molecular optimization and reaction prediction. To\naddress this, we introduce ChemCoTBench, a reasoning framework that bridges\nmolecular structure understanding with arithmetic-inspired operations,\nincluding addition, deletion, and substitution, to formalize chemical\nproblem-solving into transparent, step-by-step workflows. By treating molecular\ntransformations as modular \"chemical operations\", the framework enables\nslow-thinking reasoning, mirroring the logic of mathematical proofs while\ngrounding solutions in real-world chemical constraints. We evaluate models on\ntwo high-impact tasks: Molecular Property Optimization and Chemical Reaction\nPrediction. These tasks mirror real-world challenges while providing structured\nevaluability. By providing annotated datasets, a reasoning taxonomy, and\nbaseline evaluations, ChemCoTBench bridges the gap between abstract reasoning\nmethods and practical chemical discovery, establishing a foundation for\nadvancing LLMs as tools for AI-driven scientific innovation."}
{"id": "2505.20646", "pdf": "https://arxiv.org/pdf/2505.20646", "abs": "https://arxiv.org/abs/2505.20646", "authors": ["Eduardo Y. Sakabe", "Felipe S. Abrah√£o", "Alexandre Sim√µes", "Esther Colombini", "Paula Costa", "Ricardo Gudwin", "Hector Zenil"], "title": "Evaluating Training in Binarized Neural Networks Through the Lens of Algorithmic Information Theory", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "68T07, 68Q30, 68Q32", "I.2.6; F.1.1; F.1.3"], "comment": "10 pages total, 1 figure. Submitted to NeurIPS 2025", "summary": "Understanding and controlling the informational complexity of neural networks\nis a central challenge in machine learning, with implications for\ngeneralization, optimization, and model capacity. While most approaches rely on\nentropy-based loss functions and statistical metrics, these measures often fail\nto capture deeper, causally relevant algorithmic regularities embedded in\nnetwork structure. We propose a shift toward algorithmic information theory,\nusing Binarized Neural Networks (BNNs) as a first proxy. Grounded in\nalgorithmic probability (AP) and the universal distribution it defines, our\napproach characterizes learning dynamics through a formal, causally grounded\nlens. We apply the Block Decomposition Method (BDM) -- a scalable approximation\nof algorithmic complexity based on AP -- and demonstrate that it more closely\ntracks structural changes during training than entropy, consistently exhibiting\nstronger correlations with training loss across varying model sizes and\nrandomized training runs. These results support the view of training as a\nprocess of algorithmic compression, where learning corresponds to the\nprogressive internalization of structured regularities. In doing so, our work\noffers a principled estimate of learning progression and suggests a framework\nfor complexity-aware learning and regularization, grounded in first principles\nfrom information theory, complexity, and computability."}
{"id": "2505.21322", "pdf": "https://arxiv.org/pdf/2505.21322", "abs": "https://arxiv.org/abs/2505.21322", "authors": ["R. Spencer Hallyburton", "Miroslav Pajic"], "title": "Assured Autonomy with Neuro-Symbolic Perception", "categories": ["cs.AI"], "comment": null, "summary": "Many state-of-the-art AI models deployed in cyber-physical systems (CPS),\nwhile highly accurate, are simply pattern-matchers.~With limited security\nguarantees, there are concerns for their reliability in safety-critical and\ncontested domains. To advance assured AI, we advocate for a paradigm shift that\nimbues data-driven perception models with symbolic structure, inspired by a\nhuman's ability to reason over low-level features and high-level context. We\npropose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how\njoint object detection and scene graph generation (SGG) yields deep scene\nunderstanding.~Powered by foundation models for offline knowledge extraction\nand specialized SGG algorithms for real-time deployment, we design a framework\nleveraging structured relational graphs that ensures the integrity of\nsituational awareness in autonomy. Using physics-based simulators and\nreal-world datasets, we demonstrate how SGG bridges the gap between low-level\nsensor perception and high-level reasoning, establishing a foundation for\nresilient, context-aware AI and advancing trusted autonomy in CPS."}
{"id": "2505.20648", "pdf": "https://arxiv.org/pdf/2505.20648", "abs": "https://arxiv.org/abs/2505.20648", "authors": ["Mengmeng Chen", "Xiaohu Wu", "Qiqi Liu", "Tiantian He", "Yew-Soon Ong", "Yaochu Jin", "Qicheng Lao", "Han Yu"], "title": "Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-objective optimization (MOO) exists extensively in machine learning,\nand aims to find a set of Pareto-optimal solutions, called the Pareto front,\ne.g., it is fundamental for multiple avenues of research in federated learning\n(FL). Pareto-Front Learning (PFL) is a powerful method implemented using\nHypernetworks (PHNs) to approximate the Pareto front. This method enables the\nacquisition of a mapping function from a given preference vector to the\nsolutions on the Pareto front. However, most existing PFL approaches still face\ntwo challenges: (a) sampling rays in high-dimensional spaces; (b) failing to\ncover the entire Pareto Front which has a convex shape. Here, we introduce a\nnovel PFL framework, called as PHN-HVVS, which decomposes the design space into\nVoronoi grids and deploys a genetic algorithm (GA) for Voronoi grid\npartitioning within high-dimensional space. We put forward a new loss function,\nwhich effectively contributes to more extensive coverage of the resultant\nPareto front and maximizes the HV Indicator. Experimental results on multiple\nMOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines\nsignificantly in generating Pareto front. Also, we illustrate that PHN-HVVS\nadvances the methodologies of several recent problems in the FL field. The code\nis available at\nhttps://github.com/buptcmm/phnhvvs}{https://github.com/buptcmm/phnhvvs."}
{"id": "2505.21327", "pdf": "https://arxiv.org/pdf/2505.21327", "abs": "https://arxiv.org/abs/2505.21327", "authors": ["Jiakang Yuan", "Tianshuo Peng", "Yilei Jiang", "Yiting Lu", "Renrui Zhang", "Kaituo Feng", "Chaoyou Fu", "Tao Chen", "Lei Bai", "Bo Zhang", "Xiangyu Yue"], "title": "MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Logical reasoning is a fundamental aspect of human intelligence and an\nessential capability for multimodal large language models (MLLMs). Despite the\nsignificant advancement in multimodal reasoning, existing benchmarks fail to\ncomprehensively evaluate their reasoning abilities due to the lack of explicit\ncategorization for logical reasoning types and an unclear understanding of\nreasoning. To address these issues, we introduce MME-Reasoning, a comprehensive\nbenchmark designed to evaluate the reasoning ability of MLLMs, which covers all\nthree types of reasoning (i.e., inductive, deductive, and abductive) in its\nquestions. We carefully curate the data to ensure that each question\neffectively evaluates reasoning ability rather than perceptual skills or\nknowledge breadth, and extend the evaluation protocols to cover the evaluation\nof diverse questions. Our evaluation reveals substantial limitations of\nstate-of-the-art MLLMs when subjected to holistic assessments of logical\nreasoning capabilities. Even the most advanced MLLMs show limited performance\nin comprehensive logical reasoning, with notable performance imbalances across\nreasoning types. In addition, we conducted an in-depth analysis of approaches\nsuch as ``thinking mode'' and Rule-based RL, which are commonly believed to\nenhance reasoning abilities. These findings highlight the critical limitations\nand performance imbalances of current MLLMs in diverse logical reasoning\nscenarios, providing comprehensive and systematic insights into the\nunderstanding and evaluation of reasoning capabilities."}
{"id": "2505.20659", "pdf": "https://arxiv.org/pdf/2505.20659", "abs": "https://arxiv.org/abs/2505.20659", "authors": ["Nathan Monette", "Alistair Letcher", "Michael Beukman", "Matthew T. Jackson", "Alexander Rutherford", "Alexander D. Goldie", "Jakob N. Foerster"], "title": "An Optimisation Framework for Unsupervised Environment Design", "categories": ["cs.LG"], "comment": "Reinforcement Learning Conference 2025", "summary": "For reinforcement learning agents to be deployed in high-risk settings, they\nmust achieve a high level of robustness to unfamiliar scenarios. One method for\nimproving robustness is unsupervised environment design (UED), a suite of\nmethods aiming to maximise an agent's generalisability across configurations of\nan environment. In this work, we study UED from an optimisation perspective,\nproviding stronger theoretical guarantees for practical settings than prior\nwork. Whereas previous methods relied on guarantees if they reach convergence,\nour framework employs a nonconvex-strongly-concave objective for which we\nprovide a provably convergent algorithm in the zero-sum setting. We empirically\nverify the efficacy of our method, outperforming prior methods in a number of\nenvironments with varying difficulties."}
{"id": "2505.21344", "pdf": "https://arxiv.org/pdf/2505.21344", "abs": "https://arxiv.org/abs/2505.21344", "authors": ["Aidan Peppin", "Julia Kreutzer", "Alice Schoenauer Sebag", "Kelly Marchisio", "Beyza Ermis", "John Dang", "Samuel Cahyawijaya", "Shivalika Singh", "Seraphina Goldfarb-Tarrant", "Viraat Aryabumi", "Aakanksha", "Wei-Yin Ko", "Ahmet √úst√ºn", "Matthias Gall√©", "Marzieh Fadaee", "Sara Hooker"], "title": "The Multilingual Divide and Its Impact on Global AI Safety", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Despite advances in large language model capabilities in recent years, a\nlarge gap remains in their capabilities and safety performance for many\nlanguages beyond a relatively small handful of globally dominant languages.\nThis paper provides researchers, policymakers and governance experts with an\noverview of key challenges to bridging the \"language gap\" in AI and minimizing\nsafety risks across languages. We provide an analysis of why the language gap\nin AI exists and grows, and how it creates disparities in global AI safety. We\nidentify barriers to address these challenges, and recommend how those working\nin policy and governance can help address safety concerns associated with the\nlanguage gap by supporting multilingual dataset creation, transparency, and\nresearch."}
{"id": "2505.20666", "pdf": "https://arxiv.org/pdf/2505.20666", "abs": "https://arxiv.org/abs/2505.20666", "authors": ["Yukun Zhang", "Xueqing Zhou"], "title": "Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose a novel framework, Continuous_Time Attention, which infuses\npartial differential equations (PDEs) into the Transformer's attention\nmechanism to address the challenges of extremely long input sequences. Instead\nof relying solely on a static attention matrix, we allow attention weights to\nevolve over a pseudo_time dimension via diffusion, wave, or reaction_diffusion\ndynamics. This mechanism systematically smooths local noise, enhances\nlong_range dependencies, and stabilizes gradient flow. Theoretically, our\nanalysis shows that PDE_based attention leads to better optimization landscapes\nand polynomial rather than exponential decay of distant interactions.\nEmpirically, we benchmark our method on diverse experiments_demonstrating\nconsistent gains over both standard and specialized long sequence Transformer\nvariants. Our findings highlight the potential of PDE_based formulations to\nenrich attention mechanisms with continuous_time dynamics and global coherence."}
{"id": "2505.21398", "pdf": "https://arxiv.org/pdf/2505.21398", "abs": "https://arxiv.org/abs/2505.21398", "authors": ["Maria Cristina Carrisi", "Mirko Marras", "Sara Vergallo"], "title": "A Structured Unplugged Approach for Foundational AI Literacy in Primary Education", "categories": ["cs.AI", "cs.ET"], "comment": "Under review", "summary": "Younger generations are growing up in a world increasingly shaped by\nintelligent technologies, making early AI literacy crucial for developing the\nskills to critically understand and navigate them. However, education in this\nfield often emphasizes tool-based learning, prioritizing usage over\nunderstanding the underlying concepts. This lack of knowledge leaves\nnon-experts, especially children, prone to misconceptions, unrealistic\nexpectations, and difficulties in recognizing biases and stereotypes. In this\npaper, we propose a structured and replicable teaching approach that fosters\nfoundational AI literacy in primary students, by building upon core\nmathematical elements closely connected to and of interest in primary\ncurricula, to strengthen conceptualization, data representation, classification\nreasoning, and evaluation of AI. To assess the effectiveness of our approach,\nwe conducted an empirical study with thirty-one fifth-grade students across two\nclasses, evaluating their progress through a post-test and a satisfaction\nsurvey. Our results indicate improvements in terminology understanding and\nusage, features description, logical reasoning, and evaluative skills, with\nstudents showing a deeper comprehension of decision-making processes and their\nlimitations. Moreover, the approach proved engaging, with students particularly\nenjoying activities that linked AI concepts to real-world reasoning. Materials:\nhttps://github.com/tail-unica/ai-literacy-primary-ed."}
{"id": "2505.20686", "pdf": "https://arxiv.org/pdf/2505.20686", "abs": "https://arxiv.org/abs/2505.20686", "authors": ["Kiant√© Brantley", "Mingyu Chen", "Zhaolin Gao", "Jason D. Lee", "Wen Sun", "Wenhao Zhan", "Xuezhou Zhang"], "title": "Accelerating RL for LLM Reasoning with Optimal Advantage Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful tool for fine-tuning\nlarge language models (LLMs) to improve complex reasoning abilities. However,\nstate-of-the-art policy optimization methods often suffer from high\ncomputational overhead and memory consumption, primarily due to the need for\nmultiple generations per prompt and the reliance on critic networks or\nadvantage estimates of the current policy. In this paper, we propose $A$*-PO, a\nnovel two-stage policy optimization framework that directly approximates the\noptimal advantage function and enables efficient training of LLMs for reasoning\ntasks. In the first stage, we leverage offline sampling from a reference policy\nto estimate the optimal value function $V$*, eliminating the need for costly\nonline value estimation. In the second stage, we perform on-policy updates\nusing a simple least-squares regression loss with only a single generation per\nprompt. Theoretically, we establish performance guarantees and prove that the\nKL-regularized RL objective can be optimized without requiring complex\nexploration strategies. Empirically, $A$*-PO achieves competitive performance\nacross a wide range of mathematical reasoning benchmarks, while reducing\ntraining time by up to 2$\\times$ and peak memory usage by over 30% compared to\nPPO, GRPO, and REBEL. Implementation of $A$*-PO can be found at\nhttps://github.com/ZhaolinGao/A-PO."}
{"id": "2505.21410", "pdf": "https://arxiv.org/pdf/2505.21410", "abs": "https://arxiv.org/abs/2505.21410", "authors": ["Shashank Sharma", "Janina Hoffmann", "Vinay Namboodiri"], "title": "MRSD: Multi-Resolution Skill Discovery for HRL Agents", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Hierarchical reinforcement learning (HRL) relies on abstract skills to solve\nlong-horizon tasks efficiently. While existing skill discovery methods learns\nthese skills automatically, they are limited to a single skill per task. In\ncontrast, humans learn and use both fine-grained and coarse motor skills\nsimultaneously. Inspired by human motor control, we propose Multi-Resolution\nSkill Discovery (MRSD), an HRL framework that learns multiple skill encoders at\ndifferent temporal resolutions in parallel. A high-level manager dynamically\nselects among these skills, enabling adaptive control strategies over time. We\nevaluate MRSD on tasks from the DeepMind Control Suite and show that it\noutperforms prior state-of-the-art skill discovery and HRL methods, achieving\nfaster convergence and higher final performance. Our findings highlight the\nbenefits of integrating multi-resolution skills in HRL, paving the way for more\nversatile and efficient agents."}
{"id": "2505.20691", "pdf": "https://arxiv.org/pdf/2505.20691", "abs": "https://arxiv.org/abs/2505.20691", "authors": ["Shenkai Zhao", "Xinao Zhang", "Lipeng Pan", "Xiaobin Xu", "Danilo Pelusi"], "title": "Evidential Deep Active Learning for Semi-Supervised Classification", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "9 pages, 4 figures", "summary": "Semi-supervised classification based on active learning has made significant\nprogress, but the existing methods often ignore the uncertainty estimation (or\nreliability) of the prediction results during the learning process, which makes\nit questionable whether the selected samples can effectively update the model.\nHence, this paper proposes an evidential deep active learning approach for\nsemi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised\nlearning framework to simultaneously quantify the uncertainty estimation of\nlabeled and unlabeled data during the learning process. The uncertainty\nestimation of the former is associated with evidential deep learning, while\nthat of the latter is modeled by combining ignorance information and conflict\ninformation of the evidence from the perspective of the T-conorm operator.\nFurthermore, this article constructs a heuristic method to dynamically balance\nthe influence of evidence and the number of classes on uncertainty estimation\nto ensure that it does not produce counter-intuitive results in EDALSSC. For\nthe sample selection strategy, EDALSSC selects the sample with the greatest\nuncertainty estimation that is calculated in the form of a sum when the\ntraining loss increases in the latter half of the learning process.\nExperimental results demonstrate that EDALSSC outperforms existing\nsemi-supervised and supervised active learning approaches on image\nclassification datasets."}
{"id": "2505.21419", "pdf": "https://arxiv.org/pdf/2505.21419", "abs": "https://arxiv.org/abs/2505.21419", "authors": ["Yifan Wang", "Kenneth P. Birman"], "title": "Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs", "categories": ["cs.AI", "cs.OS"], "comment": "Published in EuroMLSys2025", "summary": "Today's cloud-hosted applications and services are complex systems, and a\nperformance or functional instability can have dozens or hundreds of potential\nroot causes. Our hypothesis is that by combining the pattern matching\ncapabilities of modern AI tools with a natural multi-modal RAG LLM interface,\nproblem identification and resolution can be simplified. ARCA is a new\nmulti-modal RAG LLM system that targets this domain. Step-wise evaluations show\nthat ARCA outperforms state-of-the-art alternatives."}
{"id": "2505.20697", "pdf": "https://arxiv.org/pdf/2505.20697", "abs": "https://arxiv.org/abs/2505.20697", "authors": ["Zachary C. Brown", "David Carlson"], "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method's ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics."}
{"id": "2505.21426", "pdf": "https://arxiv.org/pdf/2505.21426", "abs": "https://arxiv.org/abs/2505.21426", "authors": ["Francesco Cozzi", "Marco Pangallo", "Alan Perotti", "Andr√© Panisson", "Corrado Monti"], "title": "Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks", "categories": ["cs.AI", "cs.LG", "cs.MA", "econ.EM", "physics.soc-ph"], "comment": null, "summary": "Agent-Based Models (ABMs) are powerful tools for studying emergent properties\nin complex systems. In ABMs, agent behaviors are governed by local interactions\nand stochastic rules. However, these rules are, in general, non-differentiable,\nlimiting the use of gradient-based methods for optimization, and thus\nintegration with real-world data. We propose a novel framework to learn a\ndifferentiable surrogate of any ABM by observing its generated data. Our method\ncombines diffusion models to capture behavioral stochasticity and graph neural\nnetworks to model agent interactions. Distinct from prior surrogate approaches,\nour method introduces a fundamental shift: rather than approximating\nsystem-level outputs, it models individual agent behavior directly, preserving\nthe decentralized, bottom-up dynamics that define ABMs. We validate our\napproach on two ABMs (Schelling's segregation model and a Predator-Prey\necosystem) showing that it replicates individual-level patterns and accurately\nforecasts emergent dynamics beyond training. Our results demonstrate the\npotential of combining diffusion models and graph learning for data-driven ABM\nsimulation."}
{"id": "2505.20698", "pdf": "https://arxiv.org/pdf/2505.20698", "abs": "https://arxiv.org/abs/2505.20698", "authors": ["Woomin Song", "Jihoon Tack", "Sangwoo Mo", "Seunghyuk Oh", "Jinwoo Shin"], "title": "Sparsified State-Space Models are Efficient Highway Networks", "categories": ["cs.LG"], "comment": "Accepted to TMLR 2025.03", "summary": "State-space models (SSMs) offer a promising architecture for sequence\nmodeling, providing an alternative to Transformers by replacing expensive\nself-attention with linear recurrences. In this paper, we propose a simple yet\neffective trick to enhance SSMs within given computational budgets by\nsparsifying them. Our intuition is that tokens in SSMs are highly redundant due\nto gradual recurrent updates, and dense recurrence operations block the\ndelivery of past information. In particular, we observe that upper layers of\nSSMs tend to be more redundant as they encode global information, while lower\nlayers encode local information. Motivated by this, we introduce Simba, a\nhierarchical sparsification method for SSMs based on token pruning. Simba\nsparsifies upper layers more than lower layers, encouraging the upper layers to\nbehave like highways. To achieve this, we propose a novel token pruning\ncriterion for SSMs, measuring the global impact of tokens on the final output\nby accumulating local recurrences. We demonstrate that Simba outperforms the\nbaseline model, Mamba, with the same FLOPS in various natural language tasks.\nMoreover, we illustrate the effect of highways, showing that Simba not only\nenhances efficiency but also improves the information flow across long\nsequences. Code is available at https://github.com/woominsong/Simba."}
{"id": "2505.21427", "pdf": "https://arxiv.org/pdf/2505.21427", "abs": "https://arxiv.org/abs/2505.21427", "authors": ["Xianling Mu", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms."}
{"id": "2505.20716", "pdf": "https://arxiv.org/pdf/2505.20716", "abs": "https://arxiv.org/abs/2505.20716", "authors": ["Reza Nematirad", "Anil Pahwa", "Balasubramaniam Natarajan"], "title": "Are Data Embeddings effective in time series forecasting?", "categories": ["cs.LG"], "comment": "Code is available at:\n  https://github.com/neuripsdataembedidng/DataEmbedding", "summary": "Time series forecasting plays a crucial role in many real-world applications,\nand numerous complex forecasting models have been proposed in recent years.\nDespite their architectural innovations, most state-of-the-art models report\nonly marginal improvements -- typically just a few thousandths in standard\nerror metrics. These models often incorporate complex data embedding layers to\ntransform raw inputs into higher-dimensional representations to enhance\naccuracy. But are data embedding techniques actually effective in time series\nforecasting? Through extensive ablation studies across fifteen state-of-the-art\nmodels and four benchmark datasets, we find that removing data embedding layers\nfrom many state-of-the-art models does not degrade forecasting performance. In\nmany cases, it improves both accuracy and computational efficiency. The gains\nfrom removing embedding layers often exceed the performance differences\ntypically reported between competing models. Code available at:\nhttps://github.com/neuripsdataembedidng/DataEmbedding"}
{"id": "2505.21486", "pdf": "https://arxiv.org/pdf/2505.21486", "abs": "https://arxiv.org/abs/2505.21486", "authors": ["Yang Yang", "Jiemin Wu", "Yutao Yue"], "title": "Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming", "categories": ["cs.AI"], "comment": null, "summary": "Automating robust hypothesis generation in open environments is pivotal for\nAI cognition. We introduce a novel framework integrating a multi-agent system,\npowered by Large Language Models (LLMs), with Inductive Logic Programming\n(ILP). Our system's LLM agents autonomously define a structured symbolic\nvocabulary (predicates) and relational templates , i.e., \\emph{language bias}\ndirectly from raw textual data. This automated symbolic grounding (the\nconstruction of the language bias), traditionally an expert-driven bottleneck\nfor ILP, then guides the transformation of text into facts for an ILP solver,\nwhich inductively learns interpretable rules. This approach overcomes\ntraditional ILP's reliance on predefined symbolic structures and the\nnoise-sensitivity of pure LLM methods. Extensive experiments in diverse,\nchallenging scenarios validate superior performance, paving a new path for\nautomated, explainable, and verifiable hypothesis generation."}
{"id": "2505.20721", "pdf": "https://arxiv.org/pdf/2505.20721", "abs": "https://arxiv.org/abs/2505.20721", "authors": ["Zaijun Ye", "Chen-Song Zhang", "Wansheng Wang"], "title": "Recurrent Neural Operators: Stable Long-Term PDE Prediction", "categories": ["cs.LG", "cs.NA", "math.NA", "65M70, 68T07, 68U20"], "comment": null, "summary": "Neural operators have emerged as powerful tools for learning solution\noperators of partial differential equations. However, in time-dependent\nproblems, standard training strategies such as teacher forcing introduce a\nmismatch between training and inference, leading to compounding errors in\nlong-term autoregressive predictions. To address this issue, we propose\nRecurrent Neural Operators (RNOs)-a novel framework that integrates recurrent\ntraining into neural operator architectures. Instead of conditioning each\ntraining step on ground-truth inputs, RNOs recursively apply the operator to\ntheir own predictions over a temporal window, effectively simulating\ninference-time dynamics during training. This alignment mitigates exposure bias\nand enhances robustness to error accumulation. Theoretically, we show that\nrecurrent training can reduce the worst-case exponential error growth typical\nof teacher forcing to linear growth. Empirically, we demonstrate that\nrecurrently trained Multigrid Neural Operators significantly outperform their\nteacher-forced counterparts in long-term accuracy and stability on standard\nbenchmarks. Our results underscore the importance of aligning training with\ninference dynamics for robust temporal generalization in neural operator\nlearning."}
{"id": "2505.20346", "pdf": "https://arxiv.org/pdf/2505.20346", "abs": "https://arxiv.org/abs/2505.20346", "authors": ["Jiahao Kuang", "Nuowei Liu", "Changzhi Sun", "Tao Ji", "Yuanbin Wu"], "title": "PDFBench: A Benchmark for De novo Protein Design from Function", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "In recent years, while natural language processing and multimodal learning\nhave seen rapid advancements, the field of de novo protein design has also\nexperienced significant growth. However, most current methods rely on\nproprietary datasets and evaluation rubrics, making fair comparisons between\ndifferent approaches challenging. Moreover, these methods often employ\nevaluation metrics that capture only a subset of the desired properties of\ndesigned proteins, lacking a comprehensive assessment framework. To address\nthese, we introduce PDFBench, the first comprehensive benchmark for evaluating\nde novo protein design from function. PDFBench supports two tasks:\ndescription-guided design and keyword-guided design. To ensure fair and\nmultifaceted evaluation, we compile 22 metrics covering sequence plausibility,\nstructural fidelity, and language-protein alignment, along with measures of\nnovelty and diversity. We evaluate five state-of-the-art baselines, revealing\ntheir respective strengths and weaknesses across tasks. Finally, we analyze\ninter-metric correlations, exploring the relationships between four categories\nof metrics, and offering guidelines for metric selection. PDFBench establishes\na unified framework to drive future advances in function-driven de novo protein\ndesign."}
{"id": "2505.20725", "pdf": "https://arxiv.org/pdf/2505.20725", "abs": "https://arxiv.org/abs/2505.20725", "authors": ["Alberto Pliego Marug√°n", "Jes√∫s M. Pinar-P√©rez", "Fausto Pedro Garc√≠a M√°rquez"], "title": "A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs", "categories": ["cs.LG", "math.OC"], "comment": "Cite as: Marug\\'an, A. P., Pinar-P\\'erez, J. M., & M\\'arquez, F. P.\n  G. (2024). A reinforcement learning agent for maintenance of deteriorating\n  systems with increasingly imperfect repairs. Reliability Engineering & System\n  Safety, 252, 110466", "summary": "Efficient maintenance has always been essential for the successful\napplication of engineering systems. However, the challenges to be overcome in\nthe implementation of Industry 4.0 necessitate new paradigms of maintenance\noptimization. Machine learning techniques are becoming increasingly used in\nengineering and maintenance, with reinforcement learning being one of the most\npromising. In this paper, we propose a gamma degradation process together with\na novel maintenance model in which repairs are increasingly imperfect, i.e.,\nthe beneficial effect of system repairs decreases as more repairs are\nperformed, reflecting the degradational behavior of real-world systems. To\ngenerate maintenance policies for this system, we developed a\nreinforcement-learning-based agent using a Double Deep Q-Network architecture.\nThis agent presents two important advantages: it works without a predefined\npreventive threshold, and it can operate in a continuous degradation state\nspace. Our agent learns to behave in different scenarios, showing great\nflexibility. In addition, we performed an analysis of how changes in the main\nparameters of the environment affect the maintenance policy proposed by the\nagent. The proposed approach is demonstrated to be appropriate and to\nsignificatively improve long-run cost as compared with other common maintenance\nstrategies."}
{"id": "2505.20350", "pdf": "https://arxiv.org/pdf/2505.20350", "abs": "https://arxiv.org/abs/2505.20350", "authors": ["Jifeng Hu", "Sili Huang", "Siyuan Guo", "Zhaogeng Liu", "Li Shen", "Lichao Sun", "Hechang Chen", "Yi Chang", "Dacheng Tao"], "title": "Decision Flow Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, generative models have shown remarkable capabilities across\ndiverse fields, including images, videos, language, and decision-making. By\napplying powerful generative models such as flow-based models to reinforcement\nlearning, we can effectively model complex multi-modal action distributions and\nachieve superior robotic control in continuous action spaces, surpassing the\nlimitations of single-modal action distributions with traditional\nGaussian-based policies. Previous methods usually adopt the generative models\nas behavior models to fit state-conditioned action distributions from datasets,\nwith policy optimization conducted separately through additional policies using\nvalue-based sample weighting or gradient-based updates. However, this\nseparation prevents the simultaneous optimization of multi-modal distribution\nfitting and policy improvement, ultimately hindering the training of models and\ndegrading the performance. To address this issue, we propose Decision Flow, a\nunified framework that integrates multi-modal action distribution modeling and\npolicy optimization. Specifically, our method formulates the action generation\nprocedure of flow-based models as a flow decision-making process, where each\naction generation step corresponds to one flow decision. Consequently, our\nmethod seamlessly optimizes the flow policy while capturing multi-modal action\ndistributions. We provide rigorous proofs of Decision Flow and validate the\neffectiveness through extensive experiments across dozens of offline RL\nenvironments. Compared with established offline RL baselines, the results\ndemonstrate that our method achieves or matches the SOTA performance."}
{"id": "2505.20734", "pdf": "https://arxiv.org/pdf/2505.20734", "abs": "https://arxiv.org/abs/2505.20734", "authors": ["Zhuoyu Cheng", "Kohei Hatano", "Eiji Takimoto"], "title": "Adversarial bandit optimization for approximately linear functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We consider a bandit optimization problem for nonconvex and non-smooth\nfunctions, where in each trial the loss function is the sum of a linear\nfunction and a small but arbitrary perturbation chosen after observing the\nplayer's choice. We give both expected and high probability regret bounds for\nthe problem. Our result also implies an improved high-probability regret bound\nfor the bandit linear optimization, a special case with no perturbation. We\nalso give a lower bound on the expected regret."}
{"id": "2505.20353", "pdf": "https://arxiv.org/pdf/2505.20353", "abs": "https://arxiv.org/abs/2505.20353", "authors": ["Dong Liu", "Jiayi Zhang", "Yifan Li", "Yanxuan Yu", "Ben Lengerich", "Ying Nian Wu"], "title": "FastCache: Fast Caching for Diffusion Transformer Through Learnable Linear Approximation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM", "cs.PF"], "comment": null, "summary": "Diffusion Transformers (DiT) are powerful generative models but remain\ncomputationally intensive due to their iterative structure and deep transformer\nstacks. To alleviate this inefficiency, we propose FastCache, a\nhidden-state-level caching and compression framework that accelerates DiT\ninference by exploiting redundancy within the model's internal representations.\nFastCache introduces a dual strategy: (1) a spatial-aware token selection\nmechanism that adaptively filters redundant tokens based on hidden state\nsaliency, and (2) a transformer-level cache that reuses latent activations\nacross timesteps when changes are statistically insignificant. These modules\nwork jointly to reduce unnecessary computation while preserving generation\nfidelity through learnable linear approximation. Theoretical analysis shows\nthat FastCache maintains bounded approximation error under a\nhypothesis-testing-based decision rule. Empirical evaluations across multiple\nDiT variants demonstrate substantial reductions in latency and memory usage,\nwith best generation output quality compared to other cache methods, as\nmeasured by FID and t-FID. Code implementation of FastCache is available on\nGitHub at https://github.com/NoakLiu/FastCache-xDiT."}
{"id": "2505.20739", "pdf": "https://arxiv.org/pdf/2505.20739", "abs": "https://arxiv.org/abs/2505.20739", "authors": ["Kunpeng Zhao", "Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Detecting Informative Channels: ActionFormer", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Human Activity Recognition (HAR) has recently witnessed advancements with\nTransformer-based models. Especially, ActionFormer shows us a new perspectives\nfor HAR in the sense that this approach gives us additional outputs which\ndetect the border of the activities as well as the activity labels.\nActionFormer was originally proposed with its input as image/video. However,\nthis was converted to with its input as sensor signals as well. We analyze this\nextensively in terms of deep learning architectures. Based on the report of\nhigh temporal dynamics which limits the model's ability to capture subtle\nchanges effectively and of the interdependencies between the spatial and\ntemporal features. We propose the modified ActionFormer which will decrease\nthese defects for sensor signals. The key to our approach lies in accordance\nwith the Sequence-and-Excitation strategy to minimize the increase in\nadditional parameters and opt for the swish activation function to retain the\ninformation about direction in the negative range. Experiments on the WEAR\ndataset show that our method achieves substantial improvement of a 16.01\\% in\nterms of average mAP for inertial data."}
{"id": "2505.20355", "pdf": "https://arxiv.org/pdf/2505.20355", "abs": "https://arxiv.org/abs/2505.20355", "authors": ["Yeonjoon Jung", "Daehyun Ahn", "Hyungjun Kim", "Taesu Kim", "Eunhyeok Park"], "title": "GraLoRA: Granular Low-Rank Adaptation for Parameter-Efficient Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is a popular method for parameter-efficient\nfine-tuning (PEFT) of generative models, valued for its simplicity and\neffectiveness. Despite recent enhancements, LoRA still suffers from a\nfundamental limitation: overfitting when the bottleneck is widened. It performs\nbest at ranks 32-64, yet its accuracy stagnates or declines at higher ranks,\nstill falling short of full fine-tuning (FFT) performance. We identify the root\ncause as LoRA's structural bottleneck, which introduces gradient entanglement\nto the unrelated input channels and distorts gradient propagation. To address\nthis, we introduce a novel structure, Granular Low-Rank Adaptation (GraLoRA)\nthat partitions weight matrices into sub-blocks, each with its own low-rank\nadapter. With negligible computational or storage cost, GraLoRA overcomes\nLoRA's limitations, effectively increases the representational capacity, and\nmore closely approximates FFT behavior. Experiments on code generation and\ncommonsense reasoning benchmarks show that GraLoRA consistently outperforms\nLoRA and other baselines, achieving up to +8.5% absolute gain in Pass@1 on\nHumanEval+. These improvements hold across model sizes and rank settings,\nmaking GraLoRA a scalable and robust solution for PEFT. Code, data, and scripts\nare available at https://github.com/SqueezeBits/GraLoRA.git"}
{"id": "2505.20742", "pdf": "https://arxiv.org/pdf/2505.20742", "abs": "https://arxiv.org/abs/2505.20742", "authors": ["Sunwoo Kim", "Soo Yong Lee", "Jaemin Yoo", "Kijung Shin"], "title": "'Hello, World!': Making GNNs Talk with LLMs", "categories": ["cs.LG"], "comment": "Code and datasets are in https://github.com/kswoo97/GLN-Code", "summary": "While graph neural networks (GNNs) have shown remarkable performance across\ndiverse graph-related tasks, their high-dimensional hidden representations\nrender them black boxes. In this work, we propose Graph Lingual Network (GLN),\na GNN built on large language models (LLMs), with hidden representations in the\nform of human-readable text. Through careful prompt design, GLN incorporates\nnot only the message passing module of GNNs but also advanced GNN techniques,\nincluding graph attention and initial residual connection. The\ncomprehensibility of GLN's hidden representations enables an intuitive analysis\nof how node representations change (1) across layers and (2) under advanced GNN\ntechniques, shedding light on the inner workings of GNNs. Furthermore, we\ndemonstrate that GLN achieves strong zero-shot performance on node\nclassification and link prediction, outperforming existing LLM-based baseline\nmethods."}
{"id": "2505.20359", "pdf": "https://arxiv.org/pdf/2505.20359", "abs": "https://arxiv.org/abs/2505.20359", "authors": ["Lijun Zhang", "Lin Li", "Yajie Qi", "Huizhong Song", "Yaodong Yang", "Jun Wang", "Wei Wei"], "title": "Risk-aware Direct Preference Optimization under Nested Risk Measure", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When fine-tuning pre-trained Large Language Models (LLMs) to align with human\nvalues and intentions, maximizing the estimated reward can lead to superior\nperformance, but it also introduces potential risks due to deviations from the\nreference model's intended behavior. Most existing methods typically introduce\nKL divergence to constrain deviations between the trained model and the\nreference model; however, this may not be sufficient in certain applications\nthat require tight risk control. In this paper, we introduce Risk-aware Direct\nPreference Optimization (Ra-DPO), a novel approach that incorporates\nrisk-awareness by employing a class of nested risk measures. This approach\nformulates a constrained risk-aware advantage function maximization problem and\nthen converts the Bradley-Terry model into a token-level representation. The\nobjective function maximizes the likelihood of the policy while suppressing the\ndeviation between a trained model and the reference model using a sequential\nrisk ratio, thereby enhancing the model's risk-awareness. Experimental results\nacross three open-source datasets: IMDb Dataset, Anthropic HH Dataset, and\nAlpacaEval, demonstrate the proposed method's superior performance in balancing\nalignment performance and model drift. Our code is opensourced at\nhttps://github.com/zlj123-max/Ra-DPO."}
{"id": "2505.20755", "pdf": "https://arxiv.org/pdf/2505.20755", "abs": "https://arxiv.org/abs/2505.20755", "authors": ["Yifei Wang", "Weimin Bai", "Colin Zhang", "Debing Zhang", "Weijian Luo", "He Sun"], "title": "Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "In this paper, we unify more than 10 existing one-step diffusion distillation\napproaches, such as Diff-Instruct, DMD, SIM, SiD, $f$-distill, etc, inside a\ntheory-driven framework which we name the \\textbf{\\emph{Uni-Instruct}}.\nUni-Instruct is motivated by our proposed diffusion expansion theory of the\n$f$-divergence family. Then we introduce key theories that overcome the\nintractability issue of the original expanded $f$-divergence, resulting in an\nequivalent yet tractable loss that effectively trains one-step diffusion models\nby minimizing the expanded $f$-divergence family. The novel unification\nintroduced by Uni-Instruct not only offers new theoretical contributions that\nhelp understand existing approaches from a high-level perspective but also\nleads to state-of-the-art one-step diffusion generation performances. On the\nCIFAR10 generation benchmark, Uni-Instruct achieves record-breaking Frechet\nInception Distance (FID) values of \\textbf{\\emph{1.46}} for unconditional\ngeneration and \\textbf{\\emph{1.38}} for conditional generation. On the\nImageNet-$64\\times 64$ generation benchmark, Uni-Instruct achieves a new SoTA\none-step generation FID of \\textbf{\\emph{1.02}}, which outperforms its 79-step\nteacher diffusion with a significant improvement margin of 1.33 (1.02 vs 2.35).\nWe also apply Uni-Instruct on broader tasks like text-to-3D generation. For\ntext-to-3D generation, Uni-Instruct gives decent results, which slightly\noutperforms previous methods, such as SDS and VSD, in terms of both generation\nquality and diversity. Both the solid theoretical and empirical contributions\nof Uni-Instruct will potentially help future studies on one-step diffusion\ndistillation and knowledge transferring of diffusion models."}
{"id": "2505.20435", "pdf": "https://arxiv.org/pdf/2505.20435", "abs": "https://arxiv.org/abs/2505.20435", "authors": ["Aideen Fay", "In√©s Garc√≠a-Redondo", "Qiquan Wang", "Haim Dubossarsky", "Anthea Monod"], "title": "Holes in Latent Space: Topological Signatures Under Adversarial Influence", "categories": ["cs.LG", "cs.AI", "cs.CG", "math.AT"], "comment": null, "summary": "Understanding how adversarial conditions affect language models requires\ntechniques that capture both global structure and local detail within\nhigh-dimensional activation spaces. We propose persistent homology (PH), a tool\nfrom topological data analysis, to systematically characterize multiscale\nlatent space dynamics in LLMs under two distinct attack modes -- backdoor\nfine-tuning and indirect prompt injection. By analyzing six state-of-the-art\nLLMs, we show that adversarial conditions consistently compress latent\ntopologies, reducing structural diversity at smaller scales while amplifying\ndominant features at coarser ones. These topological signatures are\nstatistically robust across layers, architectures, model sizes, and align with\nthe emergence of adversarial effects deeper in the network. To capture\nfiner-grained mechanisms underlying these shifts, we introduce a neuron-level\nPH framework that quantifies how information flows and transforms within and\nacross layers. Together, our findings demonstrate that PH offers a principled\nand unifying approach to interpreting representational dynamics in LLMs,\nparticularly under distributional shift."}
{"id": "2505.20761", "pdf": "https://arxiv.org/pdf/2505.20761", "abs": "https://arxiv.org/abs/2505.20761", "authors": ["Ryota Ushio", "Takashi Ishida", "Masashi Sugiyama"], "title": "Practical estimation of the optimal classification error with soft labels and calibration", "categories": ["cs.LG", "stat.ML"], "comment": "36 pages, 24 figures; GitHub:\n  https://github.com/RyotaUshio/bayes-error-estimation", "summary": "While the performance of machine learning systems has experienced significant\nimprovement in recent years, relatively little attention has been paid to the\nfundamental question: to what extent can we improve our models? This paper\nprovides a means of answering this question in the setting of binary\nclassification, which is practical and theoretically supported. We extend a\nprevious work that utilizes soft labels for estimating the Bayes error, the\noptimal error rate, in two important ways. First, we theoretically investigate\nthe properties of the bias of the hard-label-based estimator discussed in the\noriginal work. We reveal that the decay rate of the bias is adaptive to how\nwell the two class-conditional distributions are separated, and it can decay\nsignificantly faster than the previous result suggested as the number of hard\nlabels per instance grows. Second, we tackle a more challenging problem\nsetting: estimation with corrupted soft labels. One might be tempted to use\ncalibrated soft labels instead of clean ones. However, we reveal that\ncalibration guarantee is not enough, that is, even perfectly calibrated soft\nlabels can result in a substantially inaccurate estimate. Then, we show that\nisotonic calibration can provide a statistically consistent estimator under an\nassumption weaker than that of the previous work. Our method is instance-free,\ni.e., we do not assume access to any input instances. This feature allows it to\nbe adopted in practical scenarios where the instances are not available due to\nprivacy issues. Experiments with synthetic and real-world datasets show the\nvalidity of our methods and theory."}
{"id": "2505.20485", "pdf": "https://arxiv.org/pdf/2505.20485", "abs": "https://arxiv.org/abs/2505.20485", "authors": ["Abhijit Chunduru", "Majid Morafah", "Mahdi Morafah", "Vishnu Pandi Chellapandi", "Ang Li"], "title": "Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.PF"], "comment": null, "summary": "The inevitable presence of data heterogeneity has made federated learning\nvery challenging. There are numerous methods to deal with this issue, such as\nlocal regularization, better model fusion techniques, and data sharing. Though\neffective, they lack a deep understanding of how data heterogeneity can affect\nthe global decision boundary. In this paper, we bridge this gap by performing\nan experimental analysis of the learned decision boundary using a toy example.\nOur observations are surprising: (1) we find that the existing methods suffer\nfrom forgetting and clients forget the global decision boundary and only learn\nthe perfect local one, and (2) this happens regardless of the initial weights,\nand clients forget the global decision boundary even starting from pre-trained\noptimal weights. In this paper, we present FedProj, a federated learning\nframework that robustly learns the global decision boundary and avoids its\nforgetting during local training. To achieve better ensemble knowledge fusion,\nwe design a novel server-side ensemble knowledge transfer loss to further\ncalibrate the learned global decision boundary. To alleviate the issue of\nlearned global decision boundary forgetting, we further propose leveraging an\nepisodic memory of average ensemble logits on a public unlabeled dataset to\nregulate the gradient updates at each step of local training. Experimental\nresults demonstrate that FedProj outperforms state-of-the-art methods by a\nlarge margin."}
{"id": "2505.20765", "pdf": "https://arxiv.org/pdf/2505.20765", "abs": "https://arxiv.org/abs/2505.20765", "authors": ["Kohei Obata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Robust and Explainable Detector of Time Series Anomaly via Augmenting Multiclass Pseudo-Anomalies", "categories": ["cs.LG"], "comment": "Accepted by KDD 2025", "summary": "Unsupervised anomaly detection in time series has been a pivotal research\narea for decades. Current mainstream approaches focus on learning normality, on\nthe assumption that all or most of the samples in the training set are normal.\nHowever, anomalies in the training set (i.e., anomaly contamination) can be\nmisleading. Recent studies employ data augmentation to generate\npseudo-anomalies and learn the boundary separating the training samples from\nthe augmented samples. Although this approach mitigates anomaly contamination\nif augmented samples mimic unseen real anomalies, it suffers from several\nlimitations. (1) Covering a wide range of time series anomalies is challenging.\n(2) It disregards augmented samples that resemble normal samples (i.e., false\nanomalies). (3) It places too much trust in the labels of training and\naugmented samples. In response, we propose RedLamp, which employs diverse data\naugmentations to generate multiclass pseudo-anomalies and learns the multiclass\nboundary. Such multiclass pseudo-anomalies cover a wide variety of time series\nanomalies. We conduct multiclass classification using soft labels, which\nprevents the model from being overconfident and ensures its robustness against\ncontaminated/false anomalies. The learned latent space is inherently\nexplainable as it is trained to separate pseudo-anomalies into multiclasses.\nExtensive experiments demonstrate the effectiveness of RedLamp in anomaly\ndetection and its robustness against anomaly contamination."}
{"id": "2505.20561", "pdf": "https://arxiv.org/pdf/2505.20561", "abs": "https://arxiv.org/abs/2505.20561", "authors": ["Shenao Zhang", "Yaqing Wang", "Yinxiao Liu", "Tianqi Liu", "Peter Grabowski", "Eugene Ie", "Zhaoran Wang", "Yunxuan Li"], "title": "Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL."}
{"id": "2505.20774", "pdf": "https://arxiv.org/pdf/2505.20774", "abs": "https://arxiv.org/abs/2505.20774", "authors": ["Xiaowen Ma", "Zhenliang Ni", "Shuai Xiao", "Xinghao Chen"], "title": "TimePro: Efficient Multivariate Long-term Time Series Forecasting with Variable- and Time-Aware Hyper-state", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "In long-term time series forecasting, different variables often influence the\ntarget variable over distinct time intervals, a challenge known as the\nmulti-delay issue. Traditional models typically process all variables or time\npoints uniformly, which limits their ability to capture complex variable\nrelationships and obtain non-trivial time representations. To address this\nissue, we propose TimePro, an innovative Mamba-based model that constructs\nvariate- and time-aware hyper-states. Unlike conventional approaches that\nmerely transfer plain states across variable or time dimensions, TimePro\npreserves the fine-grained temporal features of each variate token and\nadaptively selects the focused time points to tune the plain state. The\nreconstructed hyper-state can perceive both variable relationships and salient\ntemporal information, which helps the model make accurate forecasting. In\nexperiments, TimePro performs competitively on eight real-world long-term\nforecasting benchmarks with satisfactory linear complexity. Code is available\nat https://github.com/xwmaxwma/TimePro."}
{"id": "2505.20578", "pdf": "https://arxiv.org/pdf/2505.20578", "abs": "https://arxiv.org/abs/2505.20578", "authors": ["Xingyu Chen", "Shihao Ma", "Runsheng Lin", "Jiecong Lin", "Bo Wang"], "title": "Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "9 pages, 3 figures", "summary": "Designing regulatory DNA sequences that achieve precise cell-type-specific\ngene expression is crucial for advancements in synthetic biology, gene therapy\nand precision medicine. Although transformer-based language models (LMs) can\neffectively capture patterns in regulatory DNA, their generative approaches\noften struggle to produce novel sequences with reliable cell-specific activity.\nHere, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL)\nframework tailored for designing regulatory DNA sequences with controllable\ncell-type specificity. By formulating regulatory sequence design as a\nbiologically informed constrained optimization problem, we apply RL to\nautoregressive genomic LMs, enabling the models to iteratively refine sequences\nthat maximize regulatory activity in targeted cell types while constraining\noff-target effects. Our evaluation on human promoters and enhancers\ndemonstrates that Ctrl-DNA consistently outperforms existing generative and\nRL-based approaches, generating high-fitness regulatory sequences and achieving\nstate-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences\ncapture key cell-type-specific transcription factor binding sites (TFBS), short\nDNA motifs recognized by regulatory proteins that control gene expression,\ndemonstrating the biological plausibility of the generated sequences."}
{"id": "2505.20775", "pdf": "https://arxiv.org/pdf/2505.20775", "abs": "https://arxiv.org/abs/2505.20775", "authors": ["Fabian Scheurer", "Alexander Hammer", "Mario Schubert", "Robert-Patrick Steiner", "Oliver Gamm", "Kaomei Guan", "Frank Sonntag", "Hagen Malberg", "Martin Schmidt"], "title": "Non-invasive maturity assessment of iPSC-CMs based on optical maturity characteristics using interpretable AI", "categories": ["cs.LG", "eess.SP", "q-bio.CB"], "comment": null, "summary": "Human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) are an\nimportant resource for the identification of new therapeutic targets and\ncardioprotective drugs. After differentiation iPSC-CMs show an immature,\nfetal-like phenotype. Cultivation of iPSC-CMs in lipid-supplemented maturation\nmedium (MM) strongly enhances their structural, metabolic and functional\nphenotype. Nevertheless, assessing iPSC-CM maturation state remains challenging\nas most methods are time consuming and go in line with cell damage or loss of\nthe sample. To address this issue, we developed a non-invasive approach for\nautomated classification of iPSC-CM maturity through interpretable artificial\nintelligence (AI)-based analysis of beat characteristics derived from\nvideo-based motion analysis. In a prospective study, we evaluated 230 video\nrecordings of early-state, immature iPSC-CMs on day 21 after differentiation\n(d21) and more mature iPSC-CMs cultured in MM (d42, MM). For each recording, 10\nfeatures were extracted using Maia motion analysis software and entered into a\nsupport vector machine (SVM). The hyperparameters of the SVM were optimized in\na grid search on 80 % of the data using 5-fold cross-validation. The optimized\nmodel achieved an accuracy of 99.5 $\\pm$ 1.1 % on a hold-out test set. Shapley\nAdditive Explanations (SHAP) identified displacement, relaxation-rise time and\nbeating duration as the most relevant features for assessing maturity level.\nOur results suggest the use of non-invasive, optical motion analysis combined\nwith AI-based methods as a tool to assess iPSC-CMs maturity and could be\napplied before performing functional readouts or drug testing. This may\npotentially reduce the variability and improve the reproducibility of\nexperimental studies."}
{"id": "2505.20579", "pdf": "https://arxiv.org/pdf/2505.20579", "abs": "https://arxiv.org/abs/2505.20579", "authors": ["Dane Malenfant", "Blake A. Richards"], "title": "The challenge of hidden gifts in multi-agent reinforcement learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings."}
{"id": "2505.20797", "pdf": "https://arxiv.org/pdf/2505.20797", "abs": "https://arxiv.org/abs/2505.20797", "authors": ["Antonio Tudisco", "Deborah Volpe", "Giovanna Turvani"], "title": "Multi-VQC: A Novel QML Approach for Enhancing Healthcare Classification", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Accurate and reliable diagnosis of diseases is crucial in enabling timely\nmedical treatment and enhancing patient survival rates. In recent years,\nMachine Learning has revolutionized diagnostic practices by creating\nclassification models capable of identifying diseases. However, these\nclassification problems often suffer from significant class imbalances, which\ncan inhibit the effectiveness of traditional models. Therefore, the interest in\nQuantum models has arisen, driven by the captivating promise of overcoming the\nlimitations of the classical counterpart thanks to their ability to express\ncomplex patterns by mapping data in a higher-dimensional computational space."}
{"id": "2505.20621", "pdf": "https://arxiv.org/pdf/2505.20621", "abs": "https://arxiv.org/abs/2505.20621", "authors": ["Shijie Liu", "Andrew C. Cullen", "Paul Montague", "Sarah Erfani", "Benjamin I. P. Rubinstein"], "title": "Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Similar to other machine learning frameworks, Offline Reinforcement Learning\n(RL) is shown to be vulnerable to poisoning attacks, due to its reliance on\nexternally sourced datasets, a vulnerability that is exacerbated by its\nsequential nature. To mitigate the risks posed by RL poisoning, we extend\ncertified defenses to provide larger guarantees against adversarial\nmanipulation, ensuring robustness for both per-state actions, and the overall\nexpected cumulative reward. Our approach leverages properties of Differential\nPrivacy, in a manner that allows this work to span both continuous and discrete\nspaces, as well as stochastic and deterministic environments -- significantly\nexpanding the scope and applicability of achievable guarantees. Empirical\nevaluations demonstrate that our approach ensures the performance drops to no\nmore than $50\\%$ with up to $7\\%$ of the training data poisoned, significantly\nimproving over the $0.008\\%$ in prior work~\\citep{wu_copa_2022}, while\nproducing certified radii that is $5$ times larger as well. This highlights the\npotential of our framework to enhance safety and reliability in offline RL."}
{"id": "2505.20802", "pdf": "https://arxiv.org/pdf/2505.20802", "abs": "https://arxiv.org/abs/2505.20802", "authors": ["Hemanth Saratchandran", "Damien Teney", "Simon Lucey"], "title": "Leaner Transformers: More Heads, Less Depth", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Transformers have reshaped machine learning by utilizing attention mechanisms\nto capture complex patterns in large datasets, leading to significant\nimprovements in performance. This success has contributed to the belief that\n\"bigger means better\", leading to ever-increasing model sizes. This paper\nchallenge this ideology by showing that many existing transformers might be\nunnecessarily oversized. We discover a theoretical principle that redefines the\nrole of multi-head attention. An important benefit of the multiple heads is in\nimproving the conditioning of the attention block. We exploit this theoretical\ninsight and redesign popular architectures with an increased number of heads.\nThe improvement in the conditioning proves so significant in practice that\nmodel depth can be decreased, reducing the parameter count by up to 30-50%\nwhile maintaining accuracy. We obtain consistent benefits across a variety of\ntransformer-based architectures of various scales, on tasks in computer vision\n(ImageNet-1k) as well as language and sequence modeling (GLUE benchmark,\nTinyStories, and the Long-Range Arena benchmark)."}
{"id": "2505.20643", "pdf": "https://arxiv.org/pdf/2505.20643", "abs": "https://arxiv.org/abs/2505.20643", "authors": ["Bo Pan", "Liang Zhao"], "title": "Can Past Experience Accelerate LLM Reasoning?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Allocating more compute to large language models (LLMs) reasoning has\ngenerally been demonstrated to improve their effectiveness, but also results in\nincreased inference time. In contrast, humans can perform tasks faster and\nbetter with increased experience and exposure. Hence, this paper aims to\ninvestigate the question: Can LLMs also become faster at reasoning through\nrecurrent exposure on relevant tasks, and if so, how can it be achieved? To\naddress these questions, we first formalize the problem setting of LLM\nreasoning speedup systematically in the dimensions of task relevancy and\ncompute budget calculation. We then propose SpeedupLLM, a theoretically\nguaranteed framework to implement and benchmark such reasoning speedup\nbehaviour based on adaptive compute allocation and memory mechanisms. We\nfurther conduct comprehensive experiments to benchmark such behaviour across\ndifferent question similarity levels, memory methods, and reasoning methods.\nResults show that LLMs can generally reason faster with past experience,\nachieving up to a 56% reduction in compute cost when equipped with appropriate\nmemory and reasoning methods."}
{"id": "2505.20804", "pdf": "https://arxiv.org/pdf/2505.20804", "abs": "https://arxiv.org/abs/2505.20804", "authors": ["Antonio Tudisco", "Deborah Volpe", "Giovanna Turvani"], "title": "Quantum Machine Learning in Healthcare: Evaluating QNN and QSVM Models", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Effective and accurate diagnosis of diseases such as cancer, diabetes, and\nheart failure is crucial for timely medical intervention and improving patient\nsurvival rates. Machine learning has revolutionized diagnostic methods in\nrecent years by developing classification models that detect diseases based on\nselected features. However, these classification tasks are often highly\nimbalanced, limiting the performance of classical models. Quantum models offer\na promising alternative, exploiting their ability to express complex patterns\nby operating in a higher-dimensional computational space through superposition\nand entanglement. These unique properties make quantum models potentially more\neffective in addressing the challenges of imbalanced datasets. This work\nevaluates the potential of quantum classifiers in healthcare, focusing on\nQuantum Neural Networks (QNNs) and Quantum Support Vector Machines (QSVMs),\ncomparing them with popular classical models. The study is based on three\nwell-known healthcare datasets -- Prostate Cancer, Heart Failure, and Diabetes.\nThe results indicate that QSVMs outperform QNNs across all datasets due to\ntheir susceptibility to overfitting. Furthermore, quantum models prove the\nability to overcome classical models in scenarios with high dataset imbalance.\nAlthough preliminary, these findings highlight the potential of quantum models\nin healthcare classification tasks and lead the way for further research in\nthis domain."}
{"id": "2505.20646", "pdf": "https://arxiv.org/pdf/2505.20646", "abs": "https://arxiv.org/abs/2505.20646", "authors": ["Eduardo Y. Sakabe", "Felipe S. Abrah√£o", "Alexandre Sim√µes", "Esther Colombini", "Paula Costa", "Ricardo Gudwin", "Hector Zenil"], "title": "Evaluating Training in Binarized Neural Networks Through the Lens of Algorithmic Information Theory", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "68T07, 68Q30, 68Q32", "I.2.6; F.1.1; F.1.3"], "comment": "10 pages total, 1 figure. Submitted to NeurIPS 2025", "summary": "Understanding and controlling the informational complexity of neural networks\nis a central challenge in machine learning, with implications for\ngeneralization, optimization, and model capacity. While most approaches rely on\nentropy-based loss functions and statistical metrics, these measures often fail\nto capture deeper, causally relevant algorithmic regularities embedded in\nnetwork structure. We propose a shift toward algorithmic information theory,\nusing Binarized Neural Networks (BNNs) as a first proxy. Grounded in\nalgorithmic probability (AP) and the universal distribution it defines, our\napproach characterizes learning dynamics through a formal, causally grounded\nlens. We apply the Block Decomposition Method (BDM) -- a scalable approximation\nof algorithmic complexity based on AP -- and demonstrate that it more closely\ntracks structural changes during training than entropy, consistently exhibiting\nstronger correlations with training loss across varying model sizes and\nrandomized training runs. These results support the view of training as a\nprocess of algorithmic compression, where learning corresponds to the\nprogressive internalization of structured regularities. In doing so, our work\noffers a principled estimate of learning progression and suggests a framework\nfor complexity-aware learning and regularization, grounded in first principles\nfrom information theory, complexity, and computability."}
{"id": "2505.20807", "pdf": "https://arxiv.org/pdf/2505.20807", "abs": "https://arxiv.org/abs/2505.20807", "authors": ["Yurui Lai", "Taiyan Zhang", "Renchi Yang"], "title": "Simple yet Effective Graph Distillation via Clustering", "categories": ["cs.LG"], "comment": "This is the technical report of the paper \"Simple yet Effective Graph\n  Distillation via Clustering\" accepted by KDD 2025", "summary": "Despite plentiful successes achieved by graph representation learning in\nvarious domains, the training of graph neural networks (GNNs) still remains\ntenaciously challenging due to the tremendous computational overhead needed for\nsizable graphs in practice. Recently, graph data distillation (GDD), which\nseeks to distill large graphs into compact and informative ones, has emerged as\na promising technique to enable efficient GNN training. However, most existing\nGDD works rely on heuristics that align model gradients or representation\ndistributions on condensed and original graphs, leading to compromised result\nquality, expensive training for distilling large graphs, or both. Motivated by\nthis, this paper presents an efficient and effective GDD approach, ClustGDD.\nUnder the hood, ClustGDD resorts to synthesizing the condensed graph and node\nattributes through fast and theoretically-grounded clustering that minimizes\nthe within-cluster sum of squares and maximizes the homophily on the original\ngraph. The fundamental idea is inspired by our empirical and theoretical\nfindings unveiling the connection between clustering and empirical condensation\nquality using Fr\\'echet Inception Distance, a well-known quality metric for\nsynthetic images. Furthermore, to mitigate the adverse effects caused by the\nhomophily-based clustering, ClustGDD refines the nodal attributes of the\ncondensed graph with a small augmentation learned via class-aware graph\nsampling and consistency loss. Our extensive experiments exhibit that GNNs\ntrained over condensed graphs output by ClustGDD consistently achieve superior\nor comparable performance to state-of-the-art GDD methods in terms of node\nclassification on five benchmark datasets, while being orders of magnitude\nfaster."}
{"id": "2505.20648", "pdf": "https://arxiv.org/pdf/2505.20648", "abs": "https://arxiv.org/abs/2505.20648", "authors": ["Mengmeng Chen", "Xiaohu Wu", "Qiqi Liu", "Tiantian He", "Yew-Soon Ong", "Yaochu Jin", "Qicheng Lao", "Han Yu"], "title": "Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-objective optimization (MOO) exists extensively in machine learning,\nand aims to find a set of Pareto-optimal solutions, called the Pareto front,\ne.g., it is fundamental for multiple avenues of research in federated learning\n(FL). Pareto-Front Learning (PFL) is a powerful method implemented using\nHypernetworks (PHNs) to approximate the Pareto front. This method enables the\nacquisition of a mapping function from a given preference vector to the\nsolutions on the Pareto front. However, most existing PFL approaches still face\ntwo challenges: (a) sampling rays in high-dimensional spaces; (b) failing to\ncover the entire Pareto Front which has a convex shape. Here, we introduce a\nnovel PFL framework, called as PHN-HVVS, which decomposes the design space into\nVoronoi grids and deploys a genetic algorithm (GA) for Voronoi grid\npartitioning within high-dimensional space. We put forward a new loss function,\nwhich effectively contributes to more extensive coverage of the resultant\nPareto front and maximizes the HV Indicator. Experimental results on multiple\nMOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines\nsignificantly in generating Pareto front. Also, we illustrate that PHN-HVVS\nadvances the methodologies of several recent problems in the FL field. The code\nis available at\nhttps://github.com/buptcmm/phnhvvs}{https://github.com/buptcmm/phnhvvs."}
{"id": "2505.20815", "pdf": "https://arxiv.org/pdf/2505.20815", "abs": "https://arxiv.org/abs/2505.20815", "authors": ["Shiqi Yang", "Ziyi Huang", "Wengran Xiao", "Xinyu Shen"], "title": "Interpretable Credit Default Prediction with Ensemble Learning and SHAP", "categories": ["cs.LG"], "comment": null, "summary": "This study focuses on the problem of credit default prediction, builds a\nmodeling framework based on machine learning, and conducts comparative\nexperiments on a variety of mainstream classification algorithms. Through\npreprocessing, feature engineering, and model training of the Home Credit\ndataset, the performance of multiple models including logistic regression,\nrandom forest, XGBoost, LightGBM, etc. in terms of accuracy, precision, and\nrecall is evaluated. The results show that the ensemble learning method has\nobvious advantages in predictive performance, especially in dealing with\ncomplex nonlinear relationships between features and data imbalance problems.\nIt shows strong robustness. At the same time, the SHAP method is used to\nanalyze the importance and dependency of features, and it is found that the\nexternal credit score variable plays a dominant role in model decision making,\nwhich helps to improve the model's interpretability and practical application\nvalue. The research results provide effective reference and technical support\nfor the intelligent development of credit risk control systems."}
{"id": "2505.20666", "pdf": "https://arxiv.org/pdf/2505.20666", "abs": "https://arxiv.org/abs/2505.20666", "authors": ["Yukun Zhang", "Xueqing Zhou"], "title": "Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose a novel framework, Continuous_Time Attention, which infuses\npartial differential equations (PDEs) into the Transformer's attention\nmechanism to address the challenges of extremely long input sequences. Instead\nof relying solely on a static attention matrix, we allow attention weights to\nevolve over a pseudo_time dimension via diffusion, wave, or reaction_diffusion\ndynamics. This mechanism systematically smooths local noise, enhances\nlong_range dependencies, and stabilizes gradient flow. Theoretically, our\nanalysis shows that PDE_based attention leads to better optimization landscapes\nand polynomial rather than exponential decay of distant interactions.\nEmpirically, we benchmark our method on diverse experiments_demonstrating\nconsistent gains over both standard and specialized long sequence Transformer\nvariants. Our findings highlight the potential of PDE_based formulations to\nenrich attention mechanisms with continuous_time dynamics and global coherence."}
{"id": "2505.20836", "pdf": "https://arxiv.org/pdf/2505.20836", "abs": "https://arxiv.org/abs/2505.20836", "authors": ["Hexiong Yang", "Mingrui Chen", "Huaibo Huang", "Junxian Duan", "Jie Cao", "Zhen Zhou", "Ran He"], "title": "HAD: Hybrid Architecture Distillation Outperforms Teacher in Genomic Sequence Modeling", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Inspired by the great success of Masked Language Modeling (MLM) in the\nnatural language domain, the paradigm of self-supervised pre-training and\nfine-tuning has also achieved remarkable progress in the field of DNA sequence\nmodeling. However, previous methods often relied on massive pre-training data\nor large-scale base models with huge parameters, imposing a significant\ncomputational burden. To address this, many works attempted to use more compact\nmodels to achieve similar outcomes but still fell short by a considerable\nmargin. In this work, we propose a Hybrid Architecture Distillation (HAD)\napproach, leveraging both distillation and reconstruction tasks for more\nefficient and effective pre-training. Specifically, we employ the NTv2-500M as\nthe teacher model and devise a grouping masking strategy to align the feature\nembeddings of visible tokens while concurrently reconstructing the invisible\ntokens during MLM pre-training. To validate the effectiveness of our proposed\nmethod, we conducted comprehensive experiments on the Nucleotide Transformer\nBenchmark and Genomic Benchmark. Compared to models with similar parameters,\nour model achieved excellent performance. More surprisingly, it even surpassed\nthe distillation ceiling-teacher model on some sub-tasks, which is more than\n500 $\\times$ larger. Lastly, we utilize t-SNE for more intuitive visualization,\nwhich shows that our model can gain a sophisticated understanding of the\nintrinsic representation pattern in genomic sequences."}
{"id": "2505.20686", "pdf": "https://arxiv.org/pdf/2505.20686", "abs": "https://arxiv.org/abs/2505.20686", "authors": ["Kiant√© Brantley", "Mingyu Chen", "Zhaolin Gao", "Jason D. Lee", "Wen Sun", "Wenhao Zhan", "Xuezhou Zhang"], "title": "Accelerating RL for LLM Reasoning with Optimal Advantage Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful tool for fine-tuning\nlarge language models (LLMs) to improve complex reasoning abilities. However,\nstate-of-the-art policy optimization methods often suffer from high\ncomputational overhead and memory consumption, primarily due to the need for\nmultiple generations per prompt and the reliance on critic networks or\nadvantage estimates of the current policy. In this paper, we propose $A$*-PO, a\nnovel two-stage policy optimization framework that directly approximates the\noptimal advantage function and enables efficient training of LLMs for reasoning\ntasks. In the first stage, we leverage offline sampling from a reference policy\nto estimate the optimal value function $V$*, eliminating the need for costly\nonline value estimation. In the second stage, we perform on-policy updates\nusing a simple least-squares regression loss with only a single generation per\nprompt. Theoretically, we establish performance guarantees and prove that the\nKL-regularized RL objective can be optimized without requiring complex\nexploration strategies. Empirically, $A$*-PO achieves competitive performance\nacross a wide range of mathematical reasoning benchmarks, while reducing\ntraining time by up to 2$\\times$ and peak memory usage by over 30% compared to\nPPO, GRPO, and REBEL. Implementation of $A$*-PO can be found at\nhttps://github.com/ZhaolinGao/A-PO."}
{"id": "2505.20839", "pdf": "https://arxiv.org/pdf/2505.20839", "abs": "https://arxiv.org/abs/2505.20839", "authors": ["Daehyeon Baek", "Jieun Choi", "Jimyoung Son", "Kyungmin Bin", "Seungbeom Choi", "Kihyo Moon", "Minsung Jang", "Hyojung Lee"], "title": "FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration", "categories": ["cs.LG"], "comment": null, "summary": "As large language models become increasingly prevalent, memory bandwidth\nconstraints significantly limit inference throughput, motivating post-training\nquantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ\nframework and an INT4-FP8 matrix multiplication kernel that accelerates LLM\ninference across all linear layers. Specifically, FireQ quantizes linear layer\nweights and key-values to INT4, and activations and queries to FP8,\nsignificantly enhancing throughput. Additionally, we introduce a three-stage\npipelining for the prefill phase, which modifies the FlashAttention-3 kernel,\neffectively reducing time-to-first-token in the prefill phase. To minimize\naccuracy loss from quantization, we develop novel outlier smoothing techniques\ntailored separately for linear and attention layers. In linear layers, we\nexplicitly use per-tensor scaling to prevent underflow caused by the FP8\nquantization scaling factor of INT4 quantization, and channel-wise scaling to\ncompensate for coarse granularity of INT4. In attention layers, we address\nquantization challenges posed by rotary positional embeddings (RoPE) by\ncombining pre-RoPE and post-RoPE scaling strategies. FireQ significantly\noutperforms state-of-the-art methods, achieving 1.68x faster inference in\nfeed-forward network layers on Llama2-7B and 1.26x faster prefill phase\nperformance on Llama3-8B compared to QServe, with negligible accuracy loss."}
{"id": "2505.20691", "pdf": "https://arxiv.org/pdf/2505.20691", "abs": "https://arxiv.org/abs/2505.20691", "authors": ["Shenkai Zhao", "Xinao Zhang", "Lipeng Pan", "Xiaobin Xu", "Danilo Pelusi"], "title": "Evidential Deep Active Learning for Semi-Supervised Classification", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "9 pages, 4 figures", "summary": "Semi-supervised classification based on active learning has made significant\nprogress, but the existing methods often ignore the uncertainty estimation (or\nreliability) of the prediction results during the learning process, which makes\nit questionable whether the selected samples can effectively update the model.\nHence, this paper proposes an evidential deep active learning approach for\nsemi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised\nlearning framework to simultaneously quantify the uncertainty estimation of\nlabeled and unlabeled data during the learning process. The uncertainty\nestimation of the former is associated with evidential deep learning, while\nthat of the latter is modeled by combining ignorance information and conflict\ninformation of the evidence from the perspective of the T-conorm operator.\nFurthermore, this article constructs a heuristic method to dynamically balance\nthe influence of evidence and the number of classes on uncertainty estimation\nto ensure that it does not produce counter-intuitive results in EDALSSC. For\nthe sample selection strategy, EDALSSC selects the sample with the greatest\nuncertainty estimation that is calculated in the form of a sum when the\ntraining loss increases in the latter half of the learning process.\nExperimental results demonstrate that EDALSSC outperforms existing\nsemi-supervised and supervised active learning approaches on image\nclassification datasets."}
{"id": "2505.20840", "pdf": "https://arxiv.org/pdf/2505.20840", "abs": "https://arxiv.org/abs/2505.20840", "authors": ["Dooho Lee", "Myeong Kong", "Sagad Hamid", "Cheonwoo Lee", "Jaemin Yoo"], "title": "Aggregation Buffer: Revisiting DropEdge with a New Parameter Block", "categories": ["cs.LG"], "comment": null, "summary": "We revisit DropEdge, a data augmentation technique for GNNs which randomly\nremoves edges to expose diverse graph structures during training. While being a\npromising approach to effectively reduce overfitting on specific connections in\nthe graph, we observe that its potential performance gain in supervised\nlearning tasks is significantly limited. To understand why, we provide a\ntheoretical analysis showing that the limited performance of DropEdge comes\nfrom the fundamental limitation that exists in many GNN architectures. Based on\nthis analysis, we propose Aggregation Buffer, a parameter block specifically\ndesigned to improve the robustness of GNNs by addressing the limitation of\nDropEdge. Our method is compatible with any GNN model, and shows consistent\nperformance improvements on multiple datasets. Moreover, our method effectively\naddresses well-known problems such as degree bias or structural disparity as a\nunifying solution. Code and datasets are available at\nhttps://github.com/dooho00/agg-buffer."}
{"id": "2505.20697", "pdf": "https://arxiv.org/pdf/2505.20697", "abs": "https://arxiv.org/abs/2505.20697", "authors": ["Zachary C. Brown", "David Carlson"], "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method's ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics."}
{"id": "2505.20853", "pdf": "https://arxiv.org/pdf/2505.20853", "abs": "https://arxiv.org/abs/2505.20853", "authors": ["Shuo Wang", "Shunyang Huang", "Jinghui Yuan", "Zhixiang Shen", "Zhao Kang"], "title": "Cooperation of Experts: Fusing Heterogeneous Information with Large Margin", "categories": ["cs.LG", "cs.AI"], "comment": "Published in ICML 2025", "summary": "Fusing heterogeneous information remains a persistent challenge in modern\ndata analysis. While significant progress has been made, existing approaches\noften fail to account for the inherent heterogeneity of object patterns across\ndifferent semantic spaces. To address this limitation, we propose the\nCooperation of Experts (CoE) framework, which encodes multi-typed information\ninto unified heterogeneous multiplex networks. By overcoming modality and\nconnection differences, CoE provides a powerful and flexible model for\ncapturing the intricate structures of real-world complex data. In our\nframework, dedicated encoders act as domain-specific experts, each specializing\nin learning distinct relational patterns in specific semantic spaces. To\nenhance robustness and extract complementary knowledge, these experts\ncollaborate through a novel large margin mechanism supported by a tailored\noptimization strategy. Rigorous theoretical analyses guarantee the framework's\nfeasibility and stability, while extensive experiments across diverse\nbenchmarks demonstrate its superior performance and broad applicability. Our\ncode is available at https://github.com/strangeAlan/CoE."}
{"id": "2505.20734", "pdf": "https://arxiv.org/pdf/2505.20734", "abs": "https://arxiv.org/abs/2505.20734", "authors": ["Zhuoyu Cheng", "Kohei Hatano", "Eiji Takimoto"], "title": "Adversarial bandit optimization for approximately linear functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We consider a bandit optimization problem for nonconvex and non-smooth\nfunctions, where in each trial the loss function is the sum of a linear\nfunction and a small but arbitrary perturbation chosen after observing the\nplayer's choice. We give both expected and high probability regret bounds for\nthe problem. Our result also implies an improved high-probability regret bound\nfor the bandit linear optimization, a special case with no perturbation. We\nalso give a lower bound on the expected regret."}
{"id": "2505.20881", "pdf": "https://arxiv.org/pdf/2505.20881", "abs": "https://arxiv.org/abs/2505.20881", "authors": ["Yiding Shi", "Jianan Zhou", "Wen Song", "Jieyi Bi", "Yaoxin Wu", "Jie Zhang"], "title": "Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heuristic design with large language models (LLMs) has emerged as a promising\napproach for tackling combinatorial optimization problems (COPs). However,\nexisting approaches often rely on manually predefined evolutionary computation\n(EC) optimizers and single-task training schemes, which may constrain the\nexploration of diverse heuristic algorithms and hinder the generalization of\nthe resulting heuristics. To address these issues, we propose Meta-Optimization\nof Heuristics (MoH), a novel framework that operates at the optimizer level,\ndiscovering effective optimizers through the principle of meta-learning.\nSpecifically, MoH leverages LLMs to iteratively refine a meta-optimizer that\nautonomously constructs diverse optimizers through (self-)invocation, thereby\neliminating the reliance on a predefined EC optimizer. These constructed\noptimizers subsequently evolve heuristics for downstream tasks, enabling\nbroader heuristic exploration. Moreover, MoH employs a multi-task training\nscheme to promote its generalization capability. Experiments on classic COPs\ndemonstrate that MoH constructs an effective and interpretable meta-optimizer,\nachieving state-of-the-art performance across various downstream tasks,\nparticularly in cross-size settings."}
{"id": "2505.20853", "pdf": "https://arxiv.org/pdf/2505.20853", "abs": "https://arxiv.org/abs/2505.20853", "authors": ["Shuo Wang", "Shunyang Huang", "Jinghui Yuan", "Zhixiang Shen", "Zhao Kang"], "title": "Cooperation of Experts: Fusing Heterogeneous Information with Large Margin", "categories": ["cs.LG", "cs.AI"], "comment": "Published in ICML 2025", "summary": "Fusing heterogeneous information remains a persistent challenge in modern\ndata analysis. While significant progress has been made, existing approaches\noften fail to account for the inherent heterogeneity of object patterns across\ndifferent semantic spaces. To address this limitation, we propose the\nCooperation of Experts (CoE) framework, which encodes multi-typed information\ninto unified heterogeneous multiplex networks. By overcoming modality and\nconnection differences, CoE provides a powerful and flexible model for\ncapturing the intricate structures of real-world complex data. In our\nframework, dedicated encoders act as domain-specific experts, each specializing\nin learning distinct relational patterns in specific semantic spaces. To\nenhance robustness and extract complementary knowledge, these experts\ncollaborate through a novel large margin mechanism supported by a tailored\noptimization strategy. Rigorous theoretical analyses guarantee the framework's\nfeasibility and stability, while extensive experiments across diverse\nbenchmarks demonstrate its superior performance and broad applicability. Our\ncode is available at https://github.com/strangeAlan/CoE."}
{"id": "2505.20882", "pdf": "https://arxiv.org/pdf/2505.20882", "abs": "https://arxiv.org/abs/2505.20882", "authors": ["Marc Damie", "Edwige Cyffers"], "title": "Fedivertex: a Graph Dataset based on Decentralized Social Networks for Trustworthy Machine Learning", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Decentralized machine learning - where each client keeps its own data locally\nand uses its own computational resources to collaboratively train a model by\nexchanging peer-to-peer messages - is increasingly popular, as it enables\nbetter scalability and control over the data. A major challenge in this setting\nis that learning dynamics depend on the topology of the communication graph,\nwhich motivates the use of real graph datasets for benchmarking decentralized\nalgorithms. Unfortunately, existing graph datasets are largely limited to\nfor-profit social networks crawled at a fixed point in time and often collected\nat the user scale, where links are heavily influenced by the platform and its\nrecommendation algorithms. The Fediverse, which includes several free and\nopen-source decentralized social media platforms such as Mastodon, Misskey, and\nLemmy, offers an interesting real-world alternative. We introduce Fedivertex, a\nnew dataset of 182 graphs, covering seven social networks from the Fediverse,\ncrawled weekly over 14 weeks. We release the dataset along with a Python\npackage to facilitate its use, and illustrate its utility on several tasks,\nincluding a new defederation task, which captures a process of link deletion\nobserved on these networks."}
{"id": "2505.20881", "pdf": "https://arxiv.org/pdf/2505.20881", "abs": "https://arxiv.org/abs/2505.20881", "authors": ["Yiding Shi", "Jianan Zhou", "Wen Song", "Jieyi Bi", "Yaoxin Wu", "Jie Zhang"], "title": "Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heuristic design with large language models (LLMs) has emerged as a promising\napproach for tackling combinatorial optimization problems (COPs). However,\nexisting approaches often rely on manually predefined evolutionary computation\n(EC) optimizers and single-task training schemes, which may constrain the\nexploration of diverse heuristic algorithms and hinder the generalization of\nthe resulting heuristics. To address these issues, we propose Meta-Optimization\nof Heuristics (MoH), a novel framework that operates at the optimizer level,\ndiscovering effective optimizers through the principle of meta-learning.\nSpecifically, MoH leverages LLMs to iteratively refine a meta-optimizer that\nautonomously constructs diverse optimizers through (self-)invocation, thereby\neliminating the reliance on a predefined EC optimizer. These constructed\noptimizers subsequently evolve heuristics for downstream tasks, enabling\nbroader heuristic exploration. Moreover, MoH employs a multi-task training\nscheme to promote its generalization capability. Experiments on classic COPs\ndemonstrate that MoH constructs an effective and interpretable meta-optimizer,\nachieving state-of-the-art performance across various downstream tasks,\nparticularly in cross-size settings."}
{"id": "2505.20885", "pdf": "https://arxiv.org/pdf/2505.20885", "abs": "https://arxiv.org/abs/2505.20885", "authors": ["Haipeng Luo", "Spandan Senapati", "Vatsal Sharan"], "title": "Improved Bounds for Swap Multicalibration and Swap Omniprediction", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we consider the related problems of multicalibration -- a\nmultigroup fairness notion and omniprediction -- a simultaneous loss\nminimization paradigm, both in the distributional and online settings. The\nrecent work of Garg et al. (2024) raised the open problem of whether it is\npossible to efficiently achieve $O(\\sqrt{T})$ $\\ell_{2}$-multicalibration error\nagainst bounded linear functions. In this paper, we answer this question in a\nstrongly affirmative sense. We propose an efficient algorithm that achieves\n$O(T^{\\frac{1}{3}})$ $\\ell_{2}$-swap multicalibration error (both in high\nprobability and expectation). On propagating this bound onward, we obtain\nsignificantly improved rates for $\\ell_{1}$-swap multicalibration and swap\nomniprediction for a loss class of convex Lipschitz functions. In particular,\nwe show that our algorithm achieves $O(T^{\\frac{2}{3}})$ $\\ell_{1}$-swap\nmulticalibration and swap omniprediction errors, thereby improving upon the\nprevious best-known bound of $O(T^{\\frac{7}{8}})$. As a consequence of our\nimproved online results, we further obtain several improved sample complexity\nrates in the distributional setting. In particular, we establish a\n$O(\\varepsilon ^ {-3})$ sample complexity of efficiently learning an\n$\\varepsilon$-swap omnipredictor for the class of convex and Lipschitz\nfunctions, $O(\\varepsilon ^{-2.5})$ sample complexity of efficiently learning\nan $\\varepsilon$-swap agnostic learner for the squared loss, and $O(\\varepsilon\n^ {-5}), O(\\varepsilon ^ {-2.5})$ sample complexities of learning $\\ell_{1},\n\\ell_{2}$-swap multicalibrated predictors against linear functions, all of\nwhich significantly improve on the previous best-known bounds."}
{"id": "2505.20896", "pdf": "https://arxiv.org/pdf/2505.20896", "abs": "https://arxiv.org/abs/2505.20896", "authors": ["Yiwei Wu", "Atticus Geiger", "Rapha√´l Milli√®re"], "title": "How Do Transformers Learn Variable Binding in Symbolic Programs?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "16 pages, 10 figures, 1 table. To appear in the Proceedings of the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Variable binding -- the ability to associate variables with values -- is\nfundamental to symbolic computation and cognition. Although classical\narchitectures typically implement variable binding via addressable memory, it\nis not well understood how modern neural networks lacking built-in binding\noperations may acquire this capacity. We investigate this by training a\nTransformer to dereference queried variables in symbolic programs where\nvariables are assigned either numerical constants or other variables. Each\nprogram requires following chains of variable assignments up to four steps deep\nto find the queried value, and also contains irrelevant chains of assignments\nacting as distractors. Our analysis reveals a developmental trajectory with\nthree distinct phases during training: (1) random prediction of numerical\nconstants, (2) a shallow heuristic prioritizing early variable assignments, and\n(3) the emergence of a systematic mechanism for dereferencing assignment\nchains. Using causal interventions, we find that the model learns to exploit\nthe residual stream as an addressable memory space, with specialized attention\nheads routing information across token positions. This mechanism allows the\nmodel to dynamically track variable bindings across layers, resulting in\naccurate dereferencing. Our results show how Transformer models can learn to\nimplement systematic variable binding without explicit architectural support,\nbridging connectionist and symbolic approaches."}
{"id": "2505.20892", "pdf": "https://arxiv.org/pdf/2505.20892", "abs": "https://arxiv.org/abs/2505.20892", "authors": ["Jeonghwan Cheon", "Jaehyuk Bae", "Se-Bum Paik"], "title": "One-Time Soft Alignment Enables Resilient Learning without Weight Transport", "categories": ["cs.LG"], "comment": "28 pages", "summary": "Backpropagation is the cornerstone of deep learning, but its reliance on\nsymmetric weight transport and global synchronization makes it computationally\nexpensive and biologically implausible. Feedback alignment offers a promising\nalternative by approximating error gradients through fixed random feedback,\nthereby avoiding symmetric weight transport. However, this approach often\nstruggles with poor learning performance and instability, especially in deep\nnetworks. Here, we show that a one-time soft alignment between forward and\nfeedback weights at initialization enables deep networks to achieve performance\ncomparable to backpropagation, without requiring weight transport during\nlearning. This simple initialization condition guides stable error minimization\nin the loss landscape, improving network trainability. Spectral analyses\nfurther reveal that initial alignment promotes smoother gradient flow and\nconvergence to flatter minima, resulting in better generalization and\nrobustness. Notably, we also find that allowing moderate deviations from exact\nweight symmetry can improve adversarial robustness compared to standard\nbackpropagation. These findings demonstrate that a simple initialization\nstrategy can enable effective learning in deep networks in a biologically\nplausible and resource-efficient manner."}
{"id": "2505.20918", "pdf": "https://arxiv.org/pdf/2505.20918", "abs": "https://arxiv.org/abs/2505.20918", "authors": ["Rahul Nair", "Inge Vejsbjerg", "Elizabeth Daly", "Christos Varytimidis", "Bran Knowles"], "title": "Humble AI in the real-world: the case of algorithmic hiring", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": "CHIWORK '25, Symposium on Human-Computer Interaction for Work, June\n  23--25, 2025, Amsterdam, Netherlands Late Breaking Work", "summary": "Humble AI (Knowles et al., 2023) argues for cautiousness in AI development\nand deployments through scepticism (accounting for limitations of statistical\nlearning), curiosity (accounting for unexpected outcomes), and commitment\n(accounting for multifaceted values beyond performance). We present a\nreal-world case study for humble AI in the domain of algorithmic hiring.\nSpecifically, we evaluate virtual screening algorithms in a widely used hiring\nplatform that matches candidates to job openings. There are several challenges\nin misrecognition and stereotyping in such contexts that are difficult to\nassess through standard fairness and trust frameworks; e.g., someone with a\nnon-traditional background is less likely to rank highly. We demonstrate\ntechnical feasibility of how humble AI principles can be translated to practice\nthrough uncertainty quantification of ranks, entropy estimates, and a user\nexperience that highlights algorithmic unknowns. We describe preliminary\ndiscussions with focus groups made up of recruiters. Future user studies seek\nto evaluate whether the higher cognitive load of a humble AI system fosters a\nclimate of trust in its outcomes."}
{"id": "2505.20894", "pdf": "https://arxiv.org/pdf/2505.20894", "abs": "https://arxiv.org/abs/2505.20894", "authors": ["Marius Bock", "Michael Moeller", "Kristof Van Laerhoven"], "title": "DeepConvContext: A Multi-Scale Approach to Timeseries Classification in Human Activity Recognition", "categories": ["cs.LG", "cs.HC", "eess.IV"], "comment": "7 pages, 3 figures", "summary": "Despite recognized limitations in modeling long-range temporal dependencies,\nHuman Activity Recognition (HAR) has traditionally relied on a sliding window\napproach to segment labeled datasets. Deep learning models like the\nDeepConvLSTM typically classify each window independently, thereby restricting\nlearnable temporal context to within-window information. To address this\nconstraint, we propose DeepConvContext, a multi-scale time series\nclassification framework for HAR. Drawing inspiration from the vision-based\nTemporal Action Localization community, DeepConvContext models both intra- and\ninter-window temporal patterns by processing sequences of time-ordered windows.\nUnlike recent HAR models that incorporate attention mechanisms, DeepConvContext\nrelies solely on LSTMs -- with ablation studies demonstrating the superior\nperformance of LSTMs over attention-based variants for modeling inertial sensor\ndata. Across six widely-used HAR benchmarks, DeepConvContext achieves an\naverage 10% improvement in F1-score over the classic DeepConvLSTM, with gains\nof up to 21%. Code to reproduce our experiments is publicly available via\ngithub.com/mariusbock/context_har."}
{"id": "2505.20972", "pdf": "https://arxiv.org/pdf/2505.20972", "abs": "https://arxiv.org/abs/2505.20972", "authors": ["Sen Bai", "Chunqi Yang", "Xin Bai", "Xin Zhang", "Zhengang Jiang"], "title": "Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Along with AI computing shining in scientific discovery, its potential in the\ncombinatorial optimization (CO) domain has also emerged in recent years. Yet,\nexisting unsupervised neural network solvers struggle to solve $k$-grouping\nproblems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,\ndue to limited computational frameworks. In this work, we propose Deep\n$k$-grouping, an unsupervised learning-based CO framework. Specifically, we\ncontribute: Novel one-hot encoded polynomial unconstrained binary optimization\n(OH-PUBO), a formulation for modeling k-grouping problems on graphs and\nhypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated\nalgorithms for large-scale k-grouping CO problems. Deep $k$-grouping employs\nthe relaxation of large-scale OH-PUBO objectives as differentiable loss\nfunctions and trains to optimize them in an unsupervised manner. To ensure\nscalability, it leverages GPU-accelerated algorithms to unify the training\npipeline; A Gini coefficient-based continuous relaxation annealing strategy to\nenforce discreteness of solutions while preventing convergence to local optima.\nExperimental results demonstrate that Deep $k$-grouping outperforms existing\nneural network solvers and classical heuristics such as SCIP and Tabu."}
{"id": "2505.20896", "pdf": "https://arxiv.org/pdf/2505.20896", "abs": "https://arxiv.org/abs/2505.20896", "authors": ["Yiwei Wu", "Atticus Geiger", "Rapha√´l Milli√®re"], "title": "How Do Transformers Learn Variable Binding in Symbolic Programs?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "16 pages, 10 figures, 1 table. To appear in the Proceedings of the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Variable binding -- the ability to associate variables with values -- is\nfundamental to symbolic computation and cognition. Although classical\narchitectures typically implement variable binding via addressable memory, it\nis not well understood how modern neural networks lacking built-in binding\noperations may acquire this capacity. We investigate this by training a\nTransformer to dereference queried variables in symbolic programs where\nvariables are assigned either numerical constants or other variables. Each\nprogram requires following chains of variable assignments up to four steps deep\nto find the queried value, and also contains irrelevant chains of assignments\nacting as distractors. Our analysis reveals a developmental trajectory with\nthree distinct phases during training: (1) random prediction of numerical\nconstants, (2) a shallow heuristic prioritizing early variable assignments, and\n(3) the emergence of a systematic mechanism for dereferencing assignment\nchains. Using causal interventions, we find that the model learns to exploit\nthe residual stream as an addressable memory space, with specialized attention\nheads routing information across token positions. This mechanism allows the\nmodel to dynamically track variable bindings across layers, resulting in\naccurate dereferencing. Our results show how Transformer models can learn to\nimplement systematic variable binding without explicit architectural support,\nbridging connectionist and symbolic approaches."}
{"id": "2505.20997", "pdf": "https://arxiv.org/pdf/2505.20997", "abs": "https://arxiv.org/abs/2505.20997", "authors": ["Sen Bai", "Chunqi Yang", "Xin Bai", "Xin Zhang", "Zhengang Jiang"], "title": "BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Binary (0-1) integer programming (BIP) is pivotal in scientific domains\nrequiring discrete decision-making. As the advance of AI computing, recent\nworks explore neural network-based solvers for integer linear programming (ILP)\nproblems. Yet, they lack scalability for tackling nonlinear challenges. To\nhandle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear\nrelaxations, leading to exponential growth in auxiliary variables and severe\ncomputation limitations. To overcome these limitations, we propose BIPNN\n(Binary Integer Programming Neural Network), an unsupervised learning framework\nto solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).\nSpecifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear\n(sin, log, exp) optimization problems-into unconstrained, differentiable, and\npolynomial loss functions. The reformulation stems from the observation of a\nprecise one-to-one mapping between polynomial BIP objectives and hypergraph\nstructures, enabling the unsupervised training of HyperGNN to optimize BIP\nproblems in an end-to-end manner. On this basis, we propose a GPU-accelerated\nand continuous-annealing-enhanced training pipeline for BIPNN. The pipeline\nenables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel\nvia straightforward gradient descent, thus significantly reducing the training\ncost while ensuring the generation of discrete, high-quality solutions.\nExtensive experiments on synthetic and real-world datasets highlight the\nsuperiority of our approach."}
{"id": "2505.20918", "pdf": "https://arxiv.org/pdf/2505.20918", "abs": "https://arxiv.org/abs/2505.20918", "authors": ["Rahul Nair", "Inge Vejsbjerg", "Elizabeth Daly", "Christos Varytimidis", "Bran Knowles"], "title": "Humble AI in the real-world: the case of algorithmic hiring", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": "CHIWORK '25, Symposium on Human-Computer Interaction for Work, June\n  23--25, 2025, Amsterdam, Netherlands Late Breaking Work", "summary": "Humble AI (Knowles et al., 2023) argues for cautiousness in AI development\nand deployments through scepticism (accounting for limitations of statistical\nlearning), curiosity (accounting for unexpected outcomes), and commitment\n(accounting for multifaceted values beyond performance). We present a\nreal-world case study for humble AI in the domain of algorithmic hiring.\nSpecifically, we evaluate virtual screening algorithms in a widely used hiring\nplatform that matches candidates to job openings. There are several challenges\nin misrecognition and stereotyping in such contexts that are difficult to\nassess through standard fairness and trust frameworks; e.g., someone with a\nnon-traditional background is less likely to rank highly. We demonstrate\ntechnical feasibility of how humble AI principles can be translated to practice\nthrough uncertainty quantification of ranks, entropy estimates, and a user\nexperience that highlights algorithmic unknowns. We describe preliminary\ndiscussions with focus groups made up of recruiters. Future user studies seek\nto evaluate whether the higher cognitive load of a humble AI system fosters a\nclimate of trust in its outcomes."}
{"id": "2505.21012", "pdf": "https://arxiv.org/pdf/2505.21012", "abs": "https://arxiv.org/abs/2505.21012", "authors": ["Geetika", "Somya Tyagi", "Bapi Chatterjee"], "title": "Federated Instrumental Variable Analysis via Federated Generalized Method of Moments", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "28 pages, 3 figures, 1 table", "summary": "Instrumental variables (IV) analysis is an important applied tool for areas\nsuch as healthcare and consumer economics. For IV analysis in high-dimensional\nsettings, the Generalized Method of Moments (GMM) using deep neural networks\noffers an efficient approach. With non-i.i.d. data sourced from scattered\ndecentralized clients, federated learning is a popular paradigm for training\nthe models while promising data privacy. However, to our knowledge, no\nfederated algorithm for either GMM or IV analysis exists to date. In this work,\nwe introduce federated instrumental variables analysis (FedIV) via federated\ngeneralized method of moments (FedGMM). We formulate FedGMM as a federated\nzero-sum game defined by a federated non-convex non-concave minimax\noptimization problem, which is solved using federated gradient descent ascent\n(FedGDA) algorithm. One key challenge arises in theoretically characterizing\nthe federated local optimality. To address this, we present properties and\nexistence results of clients' local equilibria via FedGDA limit points.\nThereby, we show that the federated solution consistently estimates the local\nmoment conditions of every participating client. The proposed algorithm is\nbacked by extensive experiments to demonstrate the efficacy of our approach."}
{"id": "2505.20924", "pdf": "https://arxiv.org/pdf/2505.20924", "abs": "https://arxiv.org/abs/2505.20924", "authors": ["Marius Bock", "Maximilian Hopp", "Kristof Van Laerhoven", "Michael Moeller"], "title": "Label Leakage in Federated Inertial-based Human Activity Recognition", "categories": ["cs.LG", "cs.HC"], "comment": "7 pages, 4 figures", "summary": "While prior work has shown that Federated Learning updates can leak sensitive\ninformation, label reconstruction attacks, which aim to recover input labels\nfrom shared gradients, have not yet been examined in the context of Human\nActivity Recognition (HAR). Given the sensitive nature of activity labels, this\nstudy evaluates the effectiveness of state-of-the-art gradient-based label\nleakage attacks on HAR benchmark datasets. Our findings show that the number of\nactivity classes, sampling strategy, and class imbalance are critical factors\ninfluencing the extent of label leakage, with reconstruction accuracies\nreaching up to 90% on two benchmark datasets, even for trained models.\nMoreover, we find that Local Differential Privacy techniques such as gradient\nnoise and clipping offer only limited protection, as certain attacks still\nreliably infer both majority and minority class labels. We conclude by offering\npractical recommendations for the privacy-aware deployment of federated HAR\nsystems and identify open challenges for future research. Code to reproduce our\nexperiments is publicly available via github.com/mariusbock/leakage_har."}
{"id": "2505.21027", "pdf": "https://arxiv.org/pdf/2505.21027", "abs": "https://arxiv.org/abs/2505.21027", "authors": ["Zhipeng He", "Chun Ouyang", "Lijie Wen", "Cong Liu", "Catarina Moreira"], "title": "TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "63 pages, 22 figures, 6 tables", "summary": "Adversarial attacks pose a significant threat to machine learning models by\ninducing incorrect predictions through imperceptible perturbations to input\ndata. While these attacks have been extensively studied in unstructured data\nlike images, their application to tabular data presents new challenges. These\nchallenges arise from the inherent heterogeneity and complex feature\ninterdependencies in tabular data, which differ significantly from those in\nimage data. To address these differences, it is crucial to consider\nimperceptibility as a key criterion specific to tabular data. Most current\nresearch focuses primarily on achieving effective adversarial attacks, often\noverlooking the importance of maintaining imperceptibility. To address this\ngap, we propose a new benchmark for adversarial attacks on tabular data that\nevaluates both effectiveness and imperceptibility. In this study, we assess the\neffectiveness and imperceptibility of five adversarial attacks across four\nmodels using eleven tabular datasets, including both mixed and numerical-only\ndatasets. Our analysis explores how these factors interact and influence the\noverall performance of the attacks. We also compare the results across\ndifferent dataset types to understand the broader implications of these\nfindings. The findings from this benchmark provide valuable insights for\nimproving the design of adversarial attack algorithms, thereby advancing the\nfield of adversarial machine learning on tabular data."}
{"id": "2505.20930", "pdf": "https://arxiv.org/pdf/2505.20930", "abs": "https://arxiv.org/abs/2505.20930", "authors": ["Ruiqi Zhang", "Simon H. Tindemans"], "title": "MLMC-based Resource Adequacy Assessment with Active Learning Trained Surrogate Models", "categories": ["cs.LG"], "comment": "5 pages, 3 figures, 1 table", "summary": "Multilevel Monte Carlo (MLMC) is a flexible and effective variance reduction\ntechnique for accelerating reliability assessments of complex power system.\nRecently, data-driven surrogate models have been proposed as lower-level models\nin the MLMC framework due to their high correlation and negligible execution\ntime once trained. However, in resource adequacy assessments, pre-labeled\ndatasets are typically unavailable. For large-scale systems, the efficiency\ngains from surrogate models are often offset by the substantial time required\nfor labeling training data. Therefore, this paper introduces a speed metric\nthat accounts for training time in evaluating MLMC efficiency. Considering the\ntotal time budget is limited, a vote-by-committee active learning approach is\nproposed to reduce the required labeling calls. A case study demonstrates that,\nwithin practical variance thresholds, active learning enables significantly\nimproved MLMC efficiency with reduced training effort, compared to regular\nsurrogate modelling approaches."}
{"id": "2505.21046", "pdf": "https://arxiv.org/pdf/2505.21046", "abs": "https://arxiv.org/abs/2505.21046", "authors": ["Zhenling Chen", "Haiwei Fu", "Zhiguo Zeng"], "title": "A domain adaptation neural network for digital twin-supported fault diagnosis", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": "Preprint accepted by ICCAD 2025 at Barcelona", "summary": "Digital twins offer a promising solution to the lack of sufficient labeled\ndata in deep learning-based fault diagnosis by generating simulated data for\nmodel training. However, discrepancies between simulation and real-world\nsystems can lead to a significant drop in performance when models are applied\nin real scenarios. To address this issue, we propose a fault diagnosis\nframework based on Domain-Adversarial Neural Networks (DANN), which enables\nknowledge transfer from simulated (source domain) to real-world (target domain)\ndata. We evaluate the proposed framework using a publicly available robotics\nfault diagnosis dataset, which includes 3,600 sequences generated by a digital\ntwin model and 90 real sequences collected from physical systems. The DANN\nmethod is compared with commonly used lightweight deep learning models such as\nCNN, TCN, Transformer, and LSTM. Experimental results show that incorporating\ndomain adaptation significantly improves the diagnostic performance. For\nexample, applying DANN to a baseline CNN model improves its accuracy from\n70.00% to 80.22% on real-world test data, demonstrating the effectiveness of\ndomain adaptation in bridging the sim-to-real gap."}
{"id": "2505.20934", "pdf": "https://arxiv.org/pdf/2505.20934", "abs": "https://arxiv.org/abs/2505.20934", "authors": ["Max Collins", "Jordan Vice", "Tim French", "Ajmal Mian"], "title": "NatADiff: Adversarial Boundary Guidance for Natural Adversarial Diffusion", "categories": ["cs.LG", "I.2, I.4"], "comment": "10 pages, 3 figures, 2 tables", "summary": "Adversarial samples exploit irregularities in the manifold ``learned'' by\ndeep learning models to cause misclassifications. The study of these\nadversarial samples provides insight into the features a model uses to classify\ninputs, which can be leveraged to improve robustness against future attacks.\nHowever, much of the existing literature focuses on constrained adversarial\nsamples, which do not accurately reflect test-time errors encountered in\nreal-world settings. To address this, we propose `NatADiff', an adversarial\nsampling scheme that leverages denoising diffusion to generate natural\nadversarial samples. Our approach is based on the observation that natural\nadversarial samples frequently contain structural elements from the adversarial\nclass. Deep learning models can exploit these structural elements to shortcut\nthe classification process, rather than learning to genuinely distinguish\nbetween classes. To leverage this behavior, we guide the diffusion trajectory\ntowards the intersection of the true and adversarial classes, combining\ntime-travel sampling with augmented classifier guidance to enhance attack\ntransferability while preserving image fidelity. Our method achieves comparable\nattack success rates to current state-of-the-art techniques, while exhibiting\nsignificantly higher transferability across model architectures and better\nalignment with natural test-time errors as measured by FID. These results\ndemonstrate that NatADiff produces adversarial samples that not only transfer\nmore effectively across models, but more faithfully resemble naturally\noccurring test-time errors."}
{"id": "2505.21074", "pdf": "https://arxiv.org/pdf/2505.21074", "abs": "https://arxiv.org/abs/2505.21074", "authors": ["Yichuan Cao", "Yibo Miao", "Xiao-Shan Gao", "Yinpeng Dong"], "title": "Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "stat.ML"], "comment": null, "summary": "Text-to-image (T2I) models raise ethical and safety concerns due to their\npotential to generate inappropriate or harmful images. Evaluating these models'\nsecurity through red-teaming is vital, yet white-box approaches are limited by\ntheir need for internal access, complicating their use with closed-source\nmodels. Moreover, existing black-box methods often assume knowledge about the\nmodel's specific defense mechanisms, limiting their utility in real-world\ncommercial API scenarios. A significant challenge is how to evade unknown and\ndiverse defense mechanisms. To overcome this difficulty, we propose a novel\nRule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively\nemploys LLM to modify prompts to query and leverages feedback from T2I systems\nfor fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a\nprior, enabling the LLM to dynamically adapt to unknown defense mechanisms.\nGiven that the feedback is often labeled and coarse-grained, making it\ndifficult to utilize directly, we further propose rule-based preference\nmodeling, which employs a set of rules to evaluate desired or undesired\nfeedback, facilitating finer-grained control over the LLM's dynamic adaptation\nprocess. Extensive experiments on nineteen T2I systems with varied safety\nmechanisms, three online commercial API services, and T2V models verify the\nsuperiority and practicality of our approach."}
{"id": "2505.20938", "pdf": "https://arxiv.org/pdf/2505.20938", "abs": "https://arxiv.org/abs/2505.20938", "authors": ["Chongjie Si", "Yidan Cui", "Fuchao Yang", "Xiaokang Yang", "Wei Shen"], "title": "Revisiting Sparsity Constraint Under High-Rank Property in Partial Multi-Label Learning", "categories": ["cs.LG"], "comment": null, "summary": "Partial Multi-Label Learning (PML) extends the multi-label learning paradigm\nto scenarios where each sample is associated with a candidate label set\ncontaining both ground-truth labels and noisy labels. Existing PML methods\ncommonly rely on two assumptions: sparsity of the noise label matrix and\nlow-rankness of the ground-truth label matrix. However, these assumptions are\ninherently conflicting and impractical for real-world scenarios, where the true\nlabel matrix is typically full-rank or close to full-rank. To address these\nlimitations, we demonstrate that the sparsity constraint contributes to the\nhigh-rank property of the predicted label matrix. Based on this, we propose a\nnovel method Schirn, which introduces a sparsity constraint on the noise label\nmatrix while enforcing a high-rank property on the predicted label matrix.\nExtensive experiments demonstrate the superior performance of Schirn compared\nto state-of-the-art methods, validating its effectiveness in tackling\nreal-world PML challenges."}
{"id": "2505.21077", "pdf": "https://arxiv.org/pdf/2505.21077", "abs": "https://arxiv.org/abs/2505.21077", "authors": ["Mete Erdogan", "Francesco Tonin", "Volkan Cevher"], "title": "Efficient Large Language Model Inference with Neural Block Linearization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The high inference demands of transformer-based Large Language Models (LLMs)\npose substantial challenges in their deployment. To this end, we introduce\nNeural Block Linearization (NBL), a novel framework for accelerating\ntransformer model inference by replacing self-attention layers with linear\napproximations derived from Linear Minimum Mean Squared Error estimators. NBL\nleverages Canonical Correlation Analysis to compute a theoretical upper bound\non the approximation error. Then, we use this bound as a criterion for\nsubstitution, selecting the LLM layers with the lowest linearization error. NBL\ncan be efficiently applied to pre-trained LLMs without the need for\nfine-tuning. In experiments, NBL achieves notable computational speed-ups while\npreserving competitive accuracy on multiple reasoning benchmarks. For instance,\napplying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B\nincreases the inference speed by 32% with less than 1% accuracy trade-off,\nmaking it a flexible and promising solution to improve the inference efficiency\nof LLMs."}
{"id": "2505.20943", "pdf": "https://arxiv.org/pdf/2505.20943", "abs": "https://arxiv.org/abs/2505.20943", "authors": ["Anand Brahmbhatt", "Gon Buzaglo", "Sofiia Druchyna", "Elad Hazan"], "title": "Efficient Spectral Control of Partially Observed Linear Dynamical Systems", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new method for the problem of controlling linear dynamical\nsystems under partial observation and adversarial disturbances. Our new\nalgorithm, Double Spectral Control (DSC), matches the best known regret\nguarantees while exponentially improving runtime complexity over previous\napproaches in its dependence on the system's stability margin. Our key\ninnovation is a two-level spectral approximation strategy, leveraging double\nconvolution with a universal basis of spectral filters, enabling efficient and\naccurate learning of the best linear dynamical controllers."}
{"id": "2505.21119", "pdf": "https://arxiv.org/pdf/2505.21119", "abs": "https://arxiv.org/abs/2505.21119", "authors": ["Moritz A. Zanger", "Max Weltevrede", "Yaniv Oren", "Pascal R. Van der Vaart", "Caroline Horsch", "Wendelin B√∂hmer", "Matthijs T. J. Spaan"], "title": "Universal Value-Function Uncertainties", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Estimating epistemic uncertainty in value functions is a crucial challenge\nfor many aspects of reinforcement learning (RL), including efficient\nexploration, safe decision-making, and offline RL. While deep ensembles provide\na robust method for quantifying value uncertainty, they come with significant\ncomputational overhead. Single-model methods, while computationally favorable,\noften rely on heuristics and typically require additional propagation\nmechanisms for myopic uncertainty estimates. In this work we introduce\nuniversal value-function uncertainties (UVU), which, similar in spirit to\nrandom network distillation (RND), quantify uncertainty as squared prediction\nerrors between an online learner and a fixed, randomly initialized target\nnetwork. Unlike RND, UVU errors reflect policy-conditional value uncertainty,\nincorporating the future uncertainties any given policy may encounter. This is\ndue to the training procedure employed in UVU: the online network is trained\nusing temporal difference learning with a synthetic reward derived from the\nfixed, randomly initialized target network. We provide an extensive theoretical\nanalysis of our approach using neural tangent kernel (NTK) theory and show that\nin the limit of infinite network width, UVU errors are exactly equivalent to\nthe variance of an ensemble of independent universal value functions.\nEmpirically, we show that UVU achieves equal performance to large ensembles on\nchallenging multi-task offline RL settings, while offering simplicity and\nsubstantial computational savings."}
{"id": "2505.20964", "pdf": "https://arxiv.org/pdf/2505.20964", "abs": "https://arxiv.org/abs/2505.20964", "authors": ["Mehdi Bennis", "Salem Lahlou"], "title": "Semantic Communication meets System 2 ML: How Abstraction, Compositionality and Emergent Languages Shape Intelligence", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "The trajectories of 6G and AI are set for a creative collision. However,\ncurrent visions for 6G remain largely incremental evolutions of 5G, while\nprogress in AI is hampered by brittle, data-hungry models that lack robust\nreasoning capabilities. This paper argues for a foundational paradigm shift,\nmoving beyond the purely technical level of communication toward systems\ncapable of semantic understanding and effective, goal-oriented interaction. We\npropose a unified research vision rooted in the principles of System-2\ncognition, built upon three pillars: Abstraction, enabling agents to learn\nmeaningful world models from raw sensorimotor data; Compositionality, providing\nthe algebraic tools to combine learned concepts and subsystems; and Emergent\nCommunication, allowing intelligent agents to create their own adaptive and\ngrounded languages. By integrating these principles, we lay the groundwork for\ntruly intelligent systems that can reason, adapt, and collaborate, unifying\nadvances in wireless communications, machine learning, and robotics under a\nsingle coherent framework."}
{"id": "2505.21136", "pdf": "https://arxiv.org/pdf/2505.21136", "abs": "https://arxiv.org/abs/2505.21136", "authors": ["Jintao Zhang", "Xiaoming Xu", "Jia Wei", "Haofeng Huang", "Pengle Zhang", "Chendong Xiang", "Jun Zhu", "Jianfei Chen"], "title": "SageAttention2++: A More Efficient Implementation of SageAttention2", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CV"], "comment": null, "summary": "The efficiency of attention is critical because its time complexity grows\nquadratically with sequence length. SageAttention2 addresses this by utilizing\nquantization to accelerate matrix multiplications (Matmul) in attention. To\nfurther accelerate SageAttention2, we propose to utilize the faster instruction\nof FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8\nMatmul used in SageAttention2. Our experiments show that SageAttention2++\nachieves a 3.9x speedup over FlashAttention while maintaining the same\nattention accuracy as SageAttention2. This means SageAttention2++ effectively\naccelerates various models, including those for language, image, and video\ngeneration, with negligible end-to-end metrics loss. The code will be available\nat https://github.com/thu-ml/SageAttention."}
{"id": "2505.20970", "pdf": "https://arxiv.org/pdf/2505.20970", "abs": "https://arxiv.org/abs/2505.20970", "authors": ["Joonkyu Kim", "Yejin Kim", "Jy-yong Sohn"], "title": "Understanding the behavior of representation forgetting in continual learning", "categories": ["cs.LG"], "comment": null, "summary": "In continual learning scenarios, catastrophic forgetting of previously\nlearned tasks is a critical issue, making it essential to effectively measure\nsuch forgetting. Recently, there has been growing interest in focusing on\nrepresentation forgetting, the forgetting measured at the hidden layer. In this\npaper, we provide the first theoretical analysis of representation forgetting\nand use this analysis to better understand the behavior of continual learning.\nFirst, we introduce a new metric called representation discrepancy, which\nmeasures the difference between representation spaces constructed by two\nsnapshots of a model trained through continual learning. We demonstrate that\nour proposed metric serves as an effective surrogate for the representation\nforgetting while remaining analytically tractable. Second, through mathematical\nanalysis of our metric, we derive several key findings about the dynamics of\nrepresentation forgetting: the forgetting occurs more rapidly to a higher\ndegree as the layer index increases, while increasing the width of the network\nslows down the forgetting process. Third, we support our theoretical findings\nthrough experiments on real image datasets, including Split-CIFAR100 and\nImageNet1K."}
{"id": "2505.21140", "pdf": "https://arxiv.org/pdf/2505.21140", "abs": "https://arxiv.org/abs/2505.21140", "authors": ["Honglin Gao", "Xiang Li", "Lan Zhao", "Gaoxi Xiao"], "title": "HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heterogeneous graph neural networks (HGNNs) have recently drawn increasing\nattention for modeling complex multi-relational data in domains such as\nrecommendation, finance, and social networks. While existing research has been\nlargely focused on enhancing HGNNs' predictive performance, their robustness\nand security, especially under backdoor attacks, remain underexplored. In this\npaper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework\nfor node classification tasks on heterogeneous graphs. HeteroBA inserts\ncarefully crafted trigger nodes with realistic features and targeted structural\nconnections, leveraging attention-based and clustering-based strategies to\nselect influential auxiliary nodes for effective trigger propagation, thereby\ncausing the model to misclassify specific nodes into a target label while\nmaintaining accuracy on clean data. Experimental results on three datasets and\nvarious HGNN architectures demonstrate that HeteroBA achieves high attack\nsuccess rates with minimal impact on the clean accuracy. Our method sheds light\non potential vulnerabilities in HGNNs and calls for more robust defenses\nagainst backdoor threats in multi-relational graph scenarios."}
{"id": "2505.20972", "pdf": "https://arxiv.org/pdf/2505.20972", "abs": "https://arxiv.org/abs/2505.20972", "authors": ["Sen Bai", "Chunqi Yang", "Xin Bai", "Xin Zhang", "Zhengang Jiang"], "title": "Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Along with AI computing shining in scientific discovery, its potential in the\ncombinatorial optimization (CO) domain has also emerged in recent years. Yet,\nexisting unsupervised neural network solvers struggle to solve $k$-grouping\nproblems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,\ndue to limited computational frameworks. In this work, we propose Deep\n$k$-grouping, an unsupervised learning-based CO framework. Specifically, we\ncontribute: Novel one-hot encoded polynomial unconstrained binary optimization\n(OH-PUBO), a formulation for modeling k-grouping problems on graphs and\nhypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated\nalgorithms for large-scale k-grouping CO problems. Deep $k$-grouping employs\nthe relaxation of large-scale OH-PUBO objectives as differentiable loss\nfunctions and trains to optimize them in an unsupervised manner. To ensure\nscalability, it leverages GPU-accelerated algorithms to unify the training\npipeline; A Gini coefficient-based continuous relaxation annealing strategy to\nenforce discreteness of solutions while preventing convergence to local optima.\nExperimental results demonstrate that Deep $k$-grouping outperforms existing\nneural network solvers and classical heuristics such as SCIP and Tabu."}
{"id": "2505.21160", "pdf": "https://arxiv.org/pdf/2505.21160", "abs": "https://arxiv.org/abs/2505.21160", "authors": ["Michael Stenger", "Robert Leppich", "Andr√© Bauer", "Samuel Kounev"], "title": "STEB: In Search of the Best Evaluation Approach for Synthetic Time Series", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The growing need for synthetic time series, due to data augmentation or\nprivacy regulations, has led to numerous generative models, frameworks, and\nevaluation measures alike. Objectively comparing these measures on a large\nscale remains an open challenge. We propose the Synthetic Time series\nEvaluation Benchmark (STEB) -- the first benchmark framework that enables\ncomprehensive and interpretable automated comparisons of synthetic time series\nevaluation measures. Using 10 diverse datasets, randomness injection, and 13\nconfigurable data transformations, STEB computes indicators for measure\nreliability and score consistency. It tracks running time, test errors, and\nfeatures sequential and parallel modes of operation. In our experiments, we\ndetermine a ranking of 41 measures from literature and confirm that the choice\nof upstream time series embedding heavily impacts the final score."}
{"id": "2505.20992", "pdf": "https://arxiv.org/pdf/2505.20992", "abs": "https://arxiv.org/abs/2505.20992", "authors": ["Meng Qin", "Jiahong Liu", "Irwin King"], "title": "Efficient Identity and Position Graph Embedding via Spectral-Based Random Feature Aggregation", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted by ACM SIGKDD 2025", "summary": "Graph neural networks (GNNs), which capture graph structures via a feature\naggregation mechanism following the graph embedding framework, have\ndemonstrated a powerful ability to support various tasks. According to the\ntopology properties (e.g., structural roles or community memberships of nodes)\nto be preserved, graph embedding can be categorized into identity and position\nembedding. However, it is unclear for most GNN-based methods which property\nthey can capture. Some of them may also suffer from low efficiency and\nscalability caused by several time- and space-consuming procedures (e.g.,\nfeature extraction and training). From a perspective of graph signal\nprocessing, we find that high- and low-frequency information in the graph\nspectral domain may characterize node identities and positions, respectively.\nBased on this investigation, we propose random feature aggregation (RFA) for\nefficient identity and position embedding, serving as an extreme ablation study\nregarding GNN feature aggregation. RFA (i) adopts a spectral-based GNN without\nlearnable parameters as its backbone, (ii) only uses random noises as inputs,\nand (iii) derives embeddings via just one feed-forward propagation (FFP).\nInspired by degree-corrected spectral clustering, we further introduce a degree\ncorrection mechanism to the GNN backbone. Surprisingly, our experiments\ndemonstrate that two variants of RFA with high- and low-pass filters can\nrespectively derive informative identity and position embeddings via just one\nFFP (i.e., without any training). As a result, RFA can achieve a better\ntrade-off between quality and efficiency for both identity and position\nembedding over various baselines."}
{"id": "2505.21180", "pdf": "https://arxiv.org/pdf/2505.21180", "abs": "https://arxiv.org/abs/2505.21180", "authors": ["ShuNing Sun", "YinSong Xiong", "Yu Zhang", "Zhuoran Zheng"], "title": "Latent label distribution grid representation for modeling uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Although \\textbf{L}abel \\textbf{D}istribution \\textbf{L}earning (LDL) has\npromising representation capabilities for characterizing the polysemy of an\ninstance, the complexity and high cost of the label distribution annotation\nlead to inexact in the construction of the label space. The existence of a\nlarge number of inexact labels generates a label space with uncertainty, which\nmisleads the LDL algorithm to yield incorrect decisions. To alleviate this\nproblem, we model the uncertainty of label distributions by constructing a\n\\textbf{L}atent \\textbf{L}abel \\textbf{D}istribution \\textbf{G}rid (LLDG) to\nform a low-noise representation space. Specifically, we first construct a label\ncorrelation matrix based on the differences between labels, and then expand\neach value of the matrix into a vector that obeys a Gaussian distribution, thus\nbuilding a LLDG to model the uncertainty of the label space. Finally, the LLDG\nis reconstructed by the LLDG-Mixer to generate an accurate label distribution.\nNote that we enforce a customized low-rank scheme on this grid, which assumes\nthat the label relations may be noisy and it needs to perform noise-reduction\nwith the help of a Tucker reconstruction technique. Furthermore, we attempt to\nevaluate the effectiveness of the LLDG by considering its generation as an\nupstream task to achieve the classification of the objects. Extensive\nexperimental results show that our approach performs competitively on several\nbenchmarks."}
{"id": "2505.20997", "pdf": "https://arxiv.org/pdf/2505.20997", "abs": "https://arxiv.org/abs/2505.20997", "authors": ["Sen Bai", "Chunqi Yang", "Xin Bai", "Xin Zhang", "Zhengang Jiang"], "title": "BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Binary (0-1) integer programming (BIP) is pivotal in scientific domains\nrequiring discrete decision-making. As the advance of AI computing, recent\nworks explore neural network-based solvers for integer linear programming (ILP)\nproblems. Yet, they lack scalability for tackling nonlinear challenges. To\nhandle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear\nrelaxations, leading to exponential growth in auxiliary variables and severe\ncomputation limitations. To overcome these limitations, we propose BIPNN\n(Binary Integer Programming Neural Network), an unsupervised learning framework\nto solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).\nSpecifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear\n(sin, log, exp) optimization problems-into unconstrained, differentiable, and\npolynomial loss functions. The reformulation stems from the observation of a\nprecise one-to-one mapping between polynomial BIP objectives and hypergraph\nstructures, enabling the unsupervised training of HyperGNN to optimize BIP\nproblems in an end-to-end manner. On this basis, we propose a GPU-accelerated\nand continuous-annealing-enhanced training pipeline for BIPNN. The pipeline\nenables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel\nvia straightforward gradient descent, thus significantly reducing the training\ncost while ensuring the generation of discrete, high-quality solutions.\nExtensive experiments on synthetic and real-world datasets highlight the\nsuperiority of our approach."}
{"id": "2505.21182", "pdf": "https://arxiv.org/pdf/2505.21182", "abs": "https://arxiv.org/abs/2505.21182", "authors": ["Huy Hoang", "Tien Mai", "Pradeep Varakantham", "Tanvi Verma"], "title": "Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations", "categories": ["cs.LG", "cs.AI"], "comment": "preprint version", "summary": "Offline imitation learning typically learns from expert and unlabeled\ndemonstrations, yet often overlooks the valuable signal in explicitly\nundesirable behaviors. In this work, we study offline imitation learning from\ncontrasting behaviors, where the dataset contains both expert and undesirable\ndemonstrations. We propose a novel formulation that optimizes a difference of\nKL divergences over the state-action visitation distributions of expert and\nundesirable (or bad) data. Although the resulting objective is a DC\n(Difference-of-Convex) program, we prove that it becomes convex when expert\ndemonstrations outweigh undesirable demonstrations, enabling a practical and\nstable non-adversarial training objective. Our method avoids adversarial\ntraining and handles both positive and negative demonstrations in a unified\nframework. Extensive experiments on standard offline imitation learning\nbenchmarks demonstrate that our approach consistently outperforms\nstate-of-the-art baselines."}
{"id": "2505.21005", "pdf": "https://arxiv.org/pdf/2505.21005", "abs": "https://arxiv.org/abs/2505.21005", "authors": ["Fengzhe Zhang", "Laurence I. Midgley", "Jos√© Miguel Hern√°ndez-Lobato"], "title": "Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Score-based diffusion models (SBDMs) are powerful amortized samplers for\nBoltzmann distributions; however, imperfect score estimates bias downstream\nMonte Carlo estimates. Classical importance sampling (IS) can correct this\nbias, but computing exact likelihoods requires solving the probability-flow\nordinary differential equation (PF-ODE), a procedure that is prohibitively\ncostly and scales poorly with dimensionality. We introduce Variance-Tuned\nDiffusion Importance Sampling (VT-DIS), a lightweight post-training method that\nadapts the per-step noise covariance of a pretrained SBDM by minimizing the\n$\\alpha$-divergence ($\\alpha=2$) between its forward diffusion and reverse\ndenoising trajectories. VT-DIS assigns a single trajectory-wise importance\nweight to the joint forward-reverse process, yielding unbiased expectation\nestimates at test time with negligible overhead compared to standard sampling.\nOn the DW-4, LJ-13, and alanine-dipeptide benchmarks, VT-DIS achieves effective\nsample sizes of approximately 80 %, 35 %, and 3.5 %, respectively, while using\nonly a fraction of the computational budget required by vanilla diffusion + IS\nor PF-ODE-based IS."}
{"id": "2505.21184", "pdf": "https://arxiv.org/pdf/2505.21184", "abs": "https://arxiv.org/abs/2505.21184", "authors": ["Yu Yan", "Sheng Sun", "Zhifei Zheng", "Ziji Hao", "Teli Liu", "Min Liu"], "title": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "To construct responsible and secure AI applications, harmful information data\nis widely utilized for adversarial testing and the development of safeguards.\nExisting studies mainly leverage Large Language Models (LLMs) to synthesize\ndata to obtain high-quality task datasets at scale, thereby avoiding costly\nhuman annotation. However, limited by the safety alignment mechanisms of LLMs,\nthe synthesis of harmful data still faces challenges in generation reliability\nand content diversity. In this study, we propose a novel harmful information\nsynthesis framework, PoisonSwarm, which applies the model crowdsourcing\nstrategy to generate diverse harmful data while maintaining a high success\nrate. Specifically, we generate abundant benign data as the based templates in\na counterfactual manner. Subsequently, we decompose each based template into\nmultiple semantic units and perform unit-by-unit toxification and final\nrefinement through dynamic model switching, thus ensuring the success of\nsynthesis. Experimental results demonstrate that PoisonSwarm achieves\nstate-of-the-art performance in synthesizing different categories of harmful\ndata with high scalability and diversity."}
{"id": "2505.21012", "pdf": "https://arxiv.org/pdf/2505.21012", "abs": "https://arxiv.org/abs/2505.21012", "authors": ["Geetika", "Somya Tyagi", "Bapi Chatterjee"], "title": "Federated Instrumental Variable Analysis via Federated Generalized Method of Moments", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "28 pages, 3 figures, 1 table", "summary": "Instrumental variables (IV) analysis is an important applied tool for areas\nsuch as healthcare and consumer economics. For IV analysis in high-dimensional\nsettings, the Generalized Method of Moments (GMM) using deep neural networks\noffers an efficient approach. With non-i.i.d. data sourced from scattered\ndecentralized clients, federated learning is a popular paradigm for training\nthe models while promising data privacy. However, to our knowledge, no\nfederated algorithm for either GMM or IV analysis exists to date. In this work,\nwe introduce federated instrumental variables analysis (FedIV) via federated\ngeneralized method of moments (FedGMM). We formulate FedGMM as a federated\nzero-sum game defined by a federated non-convex non-concave minimax\noptimization problem, which is solved using federated gradient descent ascent\n(FedGDA) algorithm. One key challenge arises in theoretically characterizing\nthe federated local optimality. To address this, we present properties and\nexistence results of clients' local equilibria via FedGDA limit points.\nThereby, we show that the federated solution consistently estimates the local\nmoment conditions of every participating client. The proposed algorithm is\nbacked by extensive experiments to demonstrate the efficacy of our approach."}
{"id": "2505.21219", "pdf": "https://arxiv.org/pdf/2505.21219", "abs": "https://arxiv.org/abs/2505.21219", "authors": ["Qinjun Fei", "Nuria Rodr√≠guez-Barroso", "Mar√≠a Victoria Luz√≥n", "Zhongliang Zhang", "Francisco Herrera"], "title": "Addressing Data Quality Decompensation in Federated Learning via Dynamic Client Selection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In cross-silo Federated Learning (FL), client selection is critical to ensure\nhigh model performance, yet it remains challenging due to data quality\ndecompensation, budget constraints, and incentive compatibility. As training\nprogresses, these factors exacerbate client heterogeneity and degrade global\nperformance. Most existing approaches treat these challenges in isolation,\nmaking jointly optimizing multiple factors difficult. To address this, we\npropose Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a\nunified framework integrating dynamic bidding, reputation modeling, and\ncost-aware selection. Clients submit bids based on their perceived data\nquality, and their contributions are evaluated using Shapley values to quantify\ntheir marginal impact on the global model. A reputation system, inspired by\nprospect theory, captures historical performance while penalizing\ninconsistency. The client selection problem is formulated as a 0-1 integer\nprogram that maximizes reputation-weighted utility under budget constraints.\nExperiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets show that\nSBRO-FL improves accuracy, convergence speed, and robustness, even in\nadversarial and low-bid interference scenarios. Our results highlight the\nimportance of balancing data reliability, incentive compatibility, and cost\nefficiency to enable scalable and trustworthy FL deployments."}
{"id": "2505.21020", "pdf": "https://arxiv.org/pdf/2505.21020", "abs": "https://arxiv.org/abs/2505.21020", "authors": ["Yuan Gao", "Ruiqi Shu", "Hao Wu", "Fan Xu", "Yanfei Xiang", "Ruijian Gou", "Qingsong Wen", "Xian Wu", "Xiaomeng Huang"], "title": "NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically\nimportant for marine research, yet remains challenging due to its substantial\nthermal inertia and extended time delay. Machine learning (ML)-based models\nhave demonstrated significant advancements in simulation accuracy and\ncomputational efficiency compared to traditional numerical methods.\nNevertheless, a significant limitation of current ML models for S2S ocean\nsimulation is their inadequate incorporation of physical consistency and the\nslow-changing properties of the ocean system. In this work, we propose a neural\nocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive\ngraph neural network to emulate diverse physical phenomena associated with\nocean systems effectively. Specifically, we propose a multi-stage framework\ntailored to model the ocean's slowly changing nature. Additionally, we\nintroduce a multi-scale interactive messaging module to capture complex\ndynamical behaviors, such as gradient changes and multiplicative coupling\nrelationships inherent in ocean dynamics. Extensive experimental evaluations\nconfirm that our proposed NeuralOM outperforms state-of-the-art models in S2S\nand extreme event simulation. The codes are available at\nhttps://github.com/YuanGao-YG/NeuralOM."}
{"id": "2505.21236", "pdf": "https://arxiv.org/pdf/2505.21236", "abs": "https://arxiv.org/abs/2505.21236", "authors": ["Felix Chalumeau", "Daniel Rajaonarivonivelomanantsoa", "Ruan de Kock", "Claude Formanek", "Sasha Abramowitz", "Oumayma Mahjoub", "Wiem Khlifi", "Simon Du Toit", "Louay Ben Nessir", "Refiloe Shabe", "Arnol Fokam", "Siddarth Singh", "Ulrich Mbou Sob", "Arnu Pretorius"], "title": "Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Reinforcement learning (RL) systems have countless applications, from\nenergy-grid management to protein design. However, such real-world scenarios\nare often extremely difficult, combinatorial in nature, and require complex\ncoordination between multiple agents. This level of complexity can cause even\nstate-of-the-art RL systems, trained until convergence, to hit a performance\nceiling which they are unable to break out of with zero-shot inference.\nMeanwhile, many digital or simulation-based applications allow for an inference\nphase that utilises a specific time and compute budget to explore multiple\nattempts before outputting a final solution. In this work, we show that such an\ninference phase employed at execution time, and the choice of a corresponding\ninference strategy, are key to breaking the performance ceiling observed in\ncomplex multi-agent RL problems. Our main result is striking: we can obtain up\nto a 126% and, on average, a 45% improvement over the previous state-of-the-art\nacross 17 tasks, using only a couple seconds of extra wall-clock time during\nexecution. We also demonstrate promising compute scaling properties, supported\nby over 60k experiments, making it the largest study on inference strategies\nfor complex RL to date. Our experimental data and code are available at\nhttps://sites.google.com/view/inf-marl."}
{"id": "2505.21024", "pdf": "https://arxiv.org/pdf/2505.21024", "abs": "https://arxiv.org/abs/2505.21024", "authors": ["Charles London", "Varun Kanade"], "title": "Pause Tokens Strictly Increase the Expressivity of Constant-Depth Transformers", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Pause tokens, simple filler symbols such as \"...\", consistently improve\nTransformer performance on both language and mathematical tasks, yet their\ntheoretical effect remains unexplained. We provide the first formal separation\nresult, proving that adding pause tokens to constant-depth, logarithmic-width\nTransformers strictly increases their computational expressivity. With\nbounded-precision activations, Transformers without pause tokens compute only a\nstrict subset of $\\mathsf{AC}^0$ functions, while adding a polynomial number of\npause tokens allows them to express the entire class. For logarithmic-precision\nTransformers, we show that adding pause tokens achieves expressivity equivalent\nto $\\mathsf{TC}^0$, matching known upper bounds. Empirically, we demonstrate\nthat two-layer causally masked Transformers can learn parity when supplied with\npause tokens, a function that they appear unable to learn without them. Our\nresults provide a rigorous theoretical explanation for prior empirical\nfindings, clarify how pause tokens interact with width, depth, and numeric\nprecision, and position them as a distinct mechanism, complementary to\nchain-of-thought prompting, for enhancing Transformer reasoning."}
{"id": "2505.21288", "pdf": "https://arxiv.org/pdf/2505.21288", "abs": "https://arxiv.org/abs/2505.21288", "authors": ["Farshad Noravesh", "Reza Haffari", "Layki Soon", "Arghya Pal"], "title": "GSAT: Graph Structure Attention Networks", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "Graph Neural Networks (GNNs) have emerged as a powerful tool for processing\ndata represented in graph structures, achieving remarkable success across a\nwide range of applications. However, to further improve the performance on\ngraph classification benchmarks, structural representation of each node that\nencodes rich local topological information in the neighbourhood of nodes is an\nimportant type of feature that is often overlooked in the modeling. The\nconsequence of neglecting the structural information has resulted high number\nof layers to connect messages from distant nodes which by itself produces other\nproblems such as oversmoothing. In the present paper, we leverage these\nstructural information that are modeled by anonymous random walks (ARWs) and\nintroduce graph structure attention network (GSAT) which is a generalization of\ngraph attention network(GAT) to integrate the original attribute and the\nstructural representation to enforce the model to automatically find patterns\nfor attending to different edges in the node neighbourhood to enrich graph\nrepresentation. Our experiments show GSAT slightly improves SOTA on some graph\nclassification benchmarks."}
{"id": "2505.21027", "pdf": "https://arxiv.org/pdf/2505.21027", "abs": "https://arxiv.org/abs/2505.21027", "authors": ["Zhipeng He", "Chun Ouyang", "Lijie Wen", "Cong Liu", "Catarina Moreira"], "title": "TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "63 pages, 22 figures, 6 tables", "summary": "Adversarial attacks pose a significant threat to machine learning models by\ninducing incorrect predictions through imperceptible perturbations to input\ndata. While these attacks have been extensively studied in unstructured data\nlike images, their application to tabular data presents new challenges. These\nchallenges arise from the inherent heterogeneity and complex feature\ninterdependencies in tabular data, which differ significantly from those in\nimage data. To address these differences, it is crucial to consider\nimperceptibility as a key criterion specific to tabular data. Most current\nresearch focuses primarily on achieving effective adversarial attacks, often\noverlooking the importance of maintaining imperceptibility. To address this\ngap, we propose a new benchmark for adversarial attacks on tabular data that\nevaluates both effectiveness and imperceptibility. In this study, we assess the\neffectiveness and imperceptibility of five adversarial attacks across four\nmodels using eleven tabular datasets, including both mixed and numerical-only\ndatasets. Our analysis explores how these factors interact and influence the\noverall performance of the attacks. We also compare the results across\ndifferent dataset types to understand the broader implications of these\nfindings. The findings from this benchmark provide valuable insights for\nimproving the design of adversarial attack algorithms, thereby advancing the\nfield of adversarial machine learning on tabular data."}
{"id": "2505.21317", "pdf": "https://arxiv.org/pdf/2505.21317", "abs": "https://arxiv.org/abs/2505.21317", "authors": ["Ihab Bendidi", "Yassir El Mesbahi", "Alisandra K. Denton", "Karush Suri", "Kian Kenyon-Dean", "Auguste Genovesio", "Emmanuel Noutahi"], "title": "A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Main Proceedings", "summary": "Understanding cellular responses to stimuli is crucial for biological\ndiscovery and drug development. Transcriptomics provides interpretable,\ngene-level insights, while microscopy imaging offers rich predictive features\nbut is harder to interpret. Weakly paired datasets, where samples share\nbiological states, enable multimodal learning but are scarce, limiting their\nutility for training and multimodal inference. We propose a framework to\nenhance transcriptomics by distilling knowledge from microscopy images. Using\nweakly paired data, our method aligns and binds modalities, enriching gene\nexpression representations with morphological information. To address data\nscarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal\ndistillation using pretrained foundation models, achieving state-of-the-art\nresults, and (2) PEA (Perturbation Embedding Augmentation), a novel\naugmentation technique that enhances transcriptomics data while preserving\ninherent biological information. These strategies improve the predictive power\nand retain the interpretability of transcriptomics, enabling rich unimodal\nrepresentations for complex biological tasks."}
{"id": "2505.21034", "pdf": "https://arxiv.org/pdf/2505.21034", "abs": "https://arxiv.org/abs/2505.21034", "authors": ["Wenhu Li", "Niki van Stein", "Thomas B√§ck", "Elena Raponi"], "title": "LLaMEA-BO: A Large Language Model Evolutionary Algorithm for Automatically Generating Bayesian Optimization Algorithms", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Bayesian optimization (BO) is a powerful class of algorithms for optimizing\nexpensive black-box functions, but designing effective BO algorithms remains a\nmanual, expertise-driven task. Recent advancements in Large Language Models\n(LLMs) have opened new avenues for automating scientific discovery, including\nthe automatic design of optimization algorithms. While prior work has used LLMs\nwithin optimization loops or to generate non-BO algorithms, we tackle a new\nchallenge: Using LLMs to automatically generate full BO algorithm code. Our\nframework uses an evolution strategy to guide an LLM in generating Python code\nthat preserves the key components of BO algorithms: An initial design, a\nsurrogate model, and an acquisition function. The LLM is prompted to produce\nmultiple candidate algorithms, which are evaluated on the established Black-Box\nOptimization Benchmarking (BBOB) test suite from the COmparing Continuous\nOptimizers (COCO) platform. Based on their performance, top candidates are\nselected, combined, and mutated via controlled prompt variations, enabling\niterative refinement. Despite no additional fine-tuning, the LLM-generated\nalgorithms outperform state-of-the-art BO baselines in 19 (out of 24) BBOB\nfunctions in dimension 5 and generalize well to higher dimensions, and\ndifferent tasks (from the Bayesmark framework). This work demonstrates that\nLLMs can serve as algorithmic co-designers, offering a new paradigm for\nautomating BO development and accelerating the discovery of novel algorithmic\ncombinations. The source code is provided at\nhttps://github.com/Ewendawi/LLaMEA-BO."}
{"id": "2505.21339", "pdf": "https://arxiv.org/pdf/2505.21339", "abs": "https://arxiv.org/abs/2505.21339", "authors": ["Henryk Mustroph", "Michel Kunkler", "Stefanie Rinderle-Ma"], "title": "An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Suffix prediction of business processes forecasts the remaining sequence of\nevents until process completion. Current approaches focus on predicting a\nsingle, most likely suffix. However, if the future course of a process is\nexposed to uncertainty or has high variability, the expressiveness of a single\nsuffix prediction can be limited. To address this limitation, we propose\nprobabilistic suffix prediction, a novel approach that approximates a\nprobability distribution of suffixes. The proposed approach is based on an\nUncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)\nsuffix sampling algorithm. We capture epistemic uncertainties via MC dropout\nand aleatoric uncertainties as learned loss attenuation. This technical report\nprovides a detailed evaluation of the U-ED-LSTM's predictive performance and\nassesses its calibration on four real-life event logs with three different\nhyperparameter settings. The results show that i) the U-ED-LSTM has reasonable\npredictive performance across various datasets, ii) aggregating probabilistic\nsuffix predictions into mean values can outperform most likely predictions,\nparticularly for rare prefixes or longer suffixes, and iii) the approach\neffectively captures uncertainties present in event logs."}
{"id": "2505.21039", "pdf": "https://arxiv.org/pdf/2505.21039", "abs": "https://arxiv.org/abs/2505.21039", "authors": ["Louis Allain", "S√©bastien da Veiga", "Brian Staber"], "title": "Scalable and adaptive prediction bands with kernel sum-of-squares", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Conformal Prediction (CP) is a popular framework for constructing prediction\nbands with valid coverage in finite samples, while being free of any\ndistributional assumption. A well-known limitation of conformal prediction is\nthe lack of adaptivity, although several works introduced practically efficient\nalternate procedures. In this work, we build upon recent ideas that rely on\nrecasting the CP problem as a statistical learning problem, directly targeting\ncoverage and adaptivity. This statistical learning problem is based on\nreproducible kernel Hilbert spaces (RKHS) and kernel sum-of-squares (SoS)\nmethods. First, we extend previous results with a general representer theorem\nand exhibit the dual formulation of the learning problem. Crucially, such dual\nformulation can be solved efficiently by accelerated gradient methods with\nseveral hundreds or thousands of samples, unlike previous strategies based on\noff-the-shelf semidefinite programming algorithms. Second, we introduce a new\nhyperparameter tuning strategy tailored specifically to target adaptivity\nthrough bounds on test-conditional coverage. This strategy, based on the\nHilbert-Schmidt Independence Criterion (HSIC), is introduced here to tune\nkernel lengthscales in our framework, but has broader applicability since it\ncould be used in any CP algorithm where the score function is learned. Finally,\nextensive experiments are conducted to show how our method compares to related\nwork. All figures can be reproduced with the accompanying code."}
{"id": "2505.21363", "pdf": "https://arxiv.org/pdf/2505.21363", "abs": "https://arxiv.org/abs/2505.21363", "authors": ["Anissa Alloula", "Charles Jones", "Ben Glocker", "Bart≈Çomiej W. Papie≈º"], "title": "Subgroups Matter for Robust Bias Mitigation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and suggest it as a alternative lever for improving the\nrobustness and fairness of machine learning models."}
{"id": "2505.21046", "pdf": "https://arxiv.org/pdf/2505.21046", "abs": "https://arxiv.org/abs/2505.21046", "authors": ["Zhenling Chen", "Haiwei Fu", "Zhiguo Zeng"], "title": "A domain adaptation neural network for digital twin-supported fault diagnosis", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "comment": "Preprint accepted by ICCAD 2025 at Barcelona", "summary": "Digital twins offer a promising solution to the lack of sufficient labeled\ndata in deep learning-based fault diagnosis by generating simulated data for\nmodel training. However, discrepancies between simulation and real-world\nsystems can lead to a significant drop in performance when models are applied\nin real scenarios. To address this issue, we propose a fault diagnosis\nframework based on Domain-Adversarial Neural Networks (DANN), which enables\nknowledge transfer from simulated (source domain) to real-world (target domain)\ndata. We evaluate the proposed framework using a publicly available robotics\nfault diagnosis dataset, which includes 3,600 sequences generated by a digital\ntwin model and 90 real sequences collected from physical systems. The DANN\nmethod is compared with commonly used lightweight deep learning models such as\nCNN, TCN, Transformer, and LSTM. Experimental results show that incorporating\ndomain adaptation significantly improves the diagnostic performance. For\nexample, applying DANN to a baseline CNN model improves its accuracy from\n70.00% to 80.22% on real-world test data, demonstrating the effectiveness of\ndomain adaptation in bridging the sim-to-real gap."}
{"id": "2505.21364", "pdf": "https://arxiv.org/pdf/2505.21364", "abs": "https://arxiv.org/abs/2505.21364", "authors": ["James Oldfield", "Shawn Im", "Yixuan Li", "Mihalis A. Nicolaou", "Ioannis Patras", "Grigorios G Chrysos"], "title": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model's next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/."}
{"id": "2505.21073", "pdf": "https://arxiv.org/pdf/2505.21073", "abs": "https://arxiv.org/abs/2505.21073", "authors": ["Pierre Houedry", "Nicolas Courty", "Florestan Martin-Baillon", "Laetitia Chapel", "Titouan Vayer"], "title": "Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Trees and the associated shortest-path tree metrics provide a powerful\nframework for representing hierarchical and combinatorial structures in data.\nGiven an arbitrary metric space, its deviation from a tree metric can be\nquantified by Gromov's $\\delta$-hyperbolicity. Nonetheless, designing\nalgorithms that bridge an arbitrary metric to its closest tree metric is still\na vivid subject of interest, as most common approaches are either heuristical\nand lack guarantees, or perform moderately well. In this work, we introduce a\nnovel differentiable optimization framework, coined DeltaZero, that solves this\nproblem. Our method leverages a smooth surrogate for Gromov's\n$\\delta$-hyperbolicity which enables a gradient-based optimization, with a\ntractable complexity. The corresponding optimization procedure is derived from\na problem with better worst case guarantees than existing bounds, and is\njustified statistically. Experiments on synthetic and real-world datasets\ndemonstrate that our method consistently achieves state-of-the-art distortion."}
{"id": "2505.21372", "pdf": "https://arxiv.org/pdf/2505.21372", "abs": "https://arxiv.org/abs/2505.21372", "authors": ["Andrej Schwanke", "Lyubomir Ivanov", "David Salinas", "Fabio Ferreira", "Aaron Klein", "Frank Hutter", "Arber Zela"], "title": "Improving LLM-based Global Optimization with Search Space Partitioning", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 10 figures, 3 tables", "summary": "Large Language Models (LLMs) have recently emerged as effective surrogate\nmodels and candidate generators within global optimization frameworks for\nexpensive blackbox functions. Despite promising results, LLM-based methods\noften struggle in high-dimensional search spaces or when lacking\ndomain-specific priors, leading to sparse or uninformative suggestions. To\novercome these limitations, we propose HOLLM, a novel global optimization\nalgorithm that enhances LLM-driven sampling by partitioning the search space\ninto promising subregions. Each subregion acts as a ``meta-arm'' selected via a\nbandit-inspired scoring mechanism that effectively balances exploration and\nexploitation. Within each selected subregion, an LLM then proposes high-quality\ncandidate points, without any explicit domain knowledge. Empirical evaluation\non standard optimization benchmarks shows that HOLLM consistently matches or\nsurpasses leading Bayesian optimization and trust-region methods, while\nsubstantially outperforming global LLM-based sampling strategies."}
{"id": "2505.21074", "pdf": "https://arxiv.org/pdf/2505.21074", "abs": "https://arxiv.org/abs/2505.21074", "authors": ["Yichuan Cao", "Yibo Miao", "Xiao-Shan Gao", "Yinpeng Dong"], "title": "Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "stat.ML"], "comment": null, "summary": "Text-to-image (T2I) models raise ethical and safety concerns due to their\npotential to generate inappropriate or harmful images. Evaluating these models'\nsecurity through red-teaming is vital, yet white-box approaches are limited by\ntheir need for internal access, complicating their use with closed-source\nmodels. Moreover, existing black-box methods often assume knowledge about the\nmodel's specific defense mechanisms, limiting their utility in real-world\ncommercial API scenarios. A significant challenge is how to evade unknown and\ndiverse defense mechanisms. To overcome this difficulty, we propose a novel\nRule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively\nemploys LLM to modify prompts to query and leverages feedback from T2I systems\nfor fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a\nprior, enabling the LLM to dynamically adapt to unknown defense mechanisms.\nGiven that the feedback is often labeled and coarse-grained, making it\ndifficult to utilize directly, we further propose rule-based preference\nmodeling, which employs a set of rules to evaluate desired or undesired\nfeedback, facilitating finer-grained control over the LLM's dynamic adaptation\nprocess. Extensive experiments on nineteen T2I systems with varied safety\nmechanisms, three online commercial API services, and T2V models verify the\nsuperiority and practicality of our approach."}
{"id": "2505.21391", "pdf": "https://arxiv.org/pdf/2505.21391", "abs": "https://arxiv.org/abs/2505.21391", "authors": ["Zixuan Xie", "Xinyu Liu", "Rohan Chandra", "Shangtong Zhang"], "title": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point."}
{"id": "2505.21077", "pdf": "https://arxiv.org/pdf/2505.21077", "abs": "https://arxiv.org/abs/2505.21077", "authors": ["Mete Erdogan", "Francesco Tonin", "Volkan Cevher"], "title": "Efficient Large Language Model Inference with Neural Block Linearization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The high inference demands of transformer-based Large Language Models (LLMs)\npose substantial challenges in their deployment. To this end, we introduce\nNeural Block Linearization (NBL), a novel framework for accelerating\ntransformer model inference by replacing self-attention layers with linear\napproximations derived from Linear Minimum Mean Squared Error estimators. NBL\nleverages Canonical Correlation Analysis to compute a theoretical upper bound\non the approximation error. Then, we use this bound as a criterion for\nsubstitution, selecting the LLM layers with the lowest linearization error. NBL\ncan be efficiently applied to pre-trained LLMs without the need for\nfine-tuning. In experiments, NBL achieves notable computational speed-ups while\npreserving competitive accuracy on multiple reasoning benchmarks. For instance,\napplying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B\nincreases the inference speed by 32% with less than 1% accuracy trade-off,\nmaking it a flexible and promising solution to improve the inference efficiency\nof LLMs."}
{"id": "2505.21393", "pdf": "https://arxiv.org/pdf/2505.21393", "abs": "https://arxiv.org/abs/2505.21393", "authors": ["Maoli Liu", "Zhuohua Li", "Xiangxiang Dai", "John C. S. Lui"], "title": "Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 31st ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, 2025", "summary": "Conversational recommender systems proactively query users with relevant \"key\nterms\" and leverage the feedback to elicit users' preferences for personalized\nrecommendations. Conversational contextual bandits, a prevalent approach in\nthis domain, aim to optimize preference learning by balancing exploitation and\nexploration. However, several limitations hinder their effectiveness in\nreal-world scenarios. First, existing algorithms employ key term selection\nstrategies with insufficient exploration, often failing to thoroughly probe\nusers' preferences and resulting in suboptimal preference estimation. Second,\ncurrent algorithms typically rely on deterministic rules to initiate\nconversations, causing unnecessary interactions when preferences are\nwell-understood and missed opportunities when preferences are uncertain. To\naddress these limitations, we propose three novel algorithms: CLiSK, CLiME, and\nCLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in\npreference learning, CLiME adaptively initiates conversations based on\npreference uncertainty, and CLiSK-ME integrates both techniques. We\ntheoretically prove that all three algorithms achieve a tighter regret upper\nbound of $O(\\sqrt{dT\\log{T}})$ with respect to the time horizon $T$, improving\nupon existing methods. Additionally, we provide a matching lower bound\n$\\Omega(\\sqrt{dT})$ for conversational bandits, demonstrating that our\nalgorithms are nearly minimax optimal. Extensive evaluations on both synthetic\nand real-world datasets show that our approaches achieve at least a 14.6%\nimprovement in cumulative regret."}
{"id": "2505.21095", "pdf": "https://arxiv.org/pdf/2505.21095", "abs": "https://arxiv.org/abs/2505.21095", "authors": ["Kei Takemura", "Ryuta Matsuno", "Keita Sakuma"], "title": "Improved Impossible Tuning and Lipschitz-Adaptive Universal Online Learning with Gradient Variations", "categories": ["cs.LG"], "comment": null, "summary": "A central goal in online learning is to achieve adaptivity to unknown problem\ncharacteristics, such as environmental changes captured by gradient variation\n(GV), function curvature (universal online learning, UOL), and gradient scales\n(Lipschitz adaptivity, LA). Simultaneously achieving these with optimal\nperformance is a major challenge, partly due to limitations in algorithms for\nprediction with expert advice. These algorithms often serve as meta-algorithms\nin online ensemble frameworks, and their sub-optimality hinders overall UOL\nperformance. Specifically, existing algorithms addressing the ``impossible\ntuning'' issue incur an excess $\\sqrt{\\log T}$ factor in their regret bound\ncompared to the lower bound. To solve this problem, we propose a novel\noptimistic online mirror descent algorithm with an auxiliary initial round\nusing large learning rates. This design enables a refined analysis where a\ngenerated negative term cancels the gap-related factor, resolving the\nimpossible tuning issue up to $\\log\\log T$ factors. Leveraging our improved\nalgorithm as a meta-algorithm, we develop the first UOL algorithm that\nsimultaneously achieves state-of-the-art GV bounds and LA under standard\nassumptions. Our UOL result overcomes key limitations of prior works, notably\nresolving the conflict between LA mechanisms and regret analysis for GV bounds\n-- an open problem highlighted by Xie et al."}
{"id": "2505.21414", "pdf": "https://arxiv.org/pdf/2505.21414", "abs": "https://arxiv.org/abs/2505.21414", "authors": ["Brett Bissey", "Kyle Gatesman", "Walker Dimon", "Mohammad Alam", "Luis Robaina", "Joseph Weissman"], "title": "A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": null, "summary": "This paper introduces a comprehensive framework designed to analyze and\nsecure decision-support systems trained with Deep Reinforcement Learning (DRL),\nprior to deployment, by providing insights into learned behavior patterns and\nvulnerabilities discovered through simulation. The introduced framework aids in\nthe development of precisely timed and targeted observation perturbations,\nenabling researchers to assess adversarial attack outcomes within a strategic\ndecision-making context. We validate our framework, visualize agent behavior,\nand evaluate adversarial outcomes within the context of a custom-built\nstrategic game, CyberStrike. Utilizing the proposed framework, we introduce a\nmethod for systematically discovering and ranking the impact of attacks on\nvarious observation indices and time-steps, and we conduct experiments to\nevaluate the transferability of adversarial attacks across agent architectures\nand DRL training algorithms. The findings underscore the critical need for\nrobust adversarial defense mechanisms to protect decision-making policies in\nhigh-stakes environments."}
{"id": "2505.21101", "pdf": "https://arxiv.org/pdf/2505.21101", "abs": "https://arxiv.org/abs/2505.21101", "authors": ["Badr Moufad", "Yazid Janati", "Alain Durmus", "Ahmed Ghorbel", "Eric Moulines", "Jimmy Olsson"], "title": "Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance", "categories": ["cs.LG", "stat.ME"], "comment": "preprint", "summary": "Classifier-Free Guidance (CFG) is a widely used technique for improving\nconditional diffusion models by linearly combining the outputs of conditional\nand unconditional denoisers. While CFG enhances visual quality and improves\nalignment with prompts, it often reduces sample diversity, leading to a\nchallenging trade-off between quality and diversity. To address this issue, we\nmake two key contributions. First, CFG generally does not correspond to a\nwell-defined denoising diffusion model (DDM). In particular, contrary to common\nintuition, CFG does not yield samples from the target distribution associated\nwith the limiting CFG score as the noise level approaches zero -- where the\ndata distribution is tilted by a power $w \\gt 1$ of the conditional\ndistribution. We identify the missing component: a R\\'enyi divergence term that\nacts as a repulsive force and is required to correct CFG and render it\nconsistent with a proper DDM. Our analysis shows that this correction term\nvanishes in the low-noise limit. Second, motivated by this insight, we propose\na Gibbs-like sampling procedure to draw samples from the desired tilted\ndistribution. This method starts with an initial sample from the conditional\ndiffusion model without CFG and iteratively refines it, preserving diversity\nwhile progressively enhancing sample quality. We evaluate our approach on both\nimage and text-to-audio generation tasks, demonstrating substantial\nimprovements over CFG across all considered metrics. The code is available at\nhttps://github.com/yazidjanati/cfgig"}
{"id": "2505.21441", "pdf": "https://arxiv.org/pdf/2505.21441", "abs": "https://arxiv.org/abs/2505.21441", "authors": ["Binh Duc Vu", "Jan Kapar", "Marvin Wright", "David S. Watson"], "title": "Autoencoding Random Forests", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "10 pages main text, 25 pages total. 5 figures main text, 9 figures\n  total", "summary": "We propose a principled method for autoencoding with random forests. Our\nstrategy builds on foundational results from nonparametric statistics and\nspectral graph theory to learn a low-dimensional embedding of the model that\noptimally represents relationships in the data. We provide exact and\napproximate solutions to the decoding problem via constrained optimization,\nsplit relabeling, and nearest neighbors regression. These methods effectively\ninvert the compression pipeline, establishing a map from the embedding space\nback to the input space using splits learned by the ensemble's constituent\ntrees. The resulting decoders are universally consistent under common\nregularity assumptions. The procedure works with supervised or unsupervised\nmodels, providing a window into conditional or joint distributions. We\ndemonstrate various applications of this autoencoder, including powerful new\ntools for visualization, compression, clustering, and denoising. Experiments\nillustrate the ease and utility of our method in a wide range of settings,\nincluding tabular, image, and genomic data."}
{"id": "2505.21119", "pdf": "https://arxiv.org/pdf/2505.21119", "abs": "https://arxiv.org/abs/2505.21119", "authors": ["Moritz A. Zanger", "Max Weltevrede", "Yaniv Oren", "Pascal R. Van der Vaart", "Caroline Horsch", "Wendelin B√∂hmer", "Matthijs T. J. Spaan"], "title": "Universal Value-Function Uncertainties", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Estimating epistemic uncertainty in value functions is a crucial challenge\nfor many aspects of reinforcement learning (RL), including efficient\nexploration, safe decision-making, and offline RL. While deep ensembles provide\na robust method for quantifying value uncertainty, they come with significant\ncomputational overhead. Single-model methods, while computationally favorable,\noften rely on heuristics and typically require additional propagation\nmechanisms for myopic uncertainty estimates. In this work we introduce\nuniversal value-function uncertainties (UVU), which, similar in spirit to\nrandom network distillation (RND), quantify uncertainty as squared prediction\nerrors between an online learner and a fixed, randomly initialized target\nnetwork. Unlike RND, UVU errors reflect policy-conditional value uncertainty,\nincorporating the future uncertainties any given policy may encounter. This is\ndue to the training procedure employed in UVU: the online network is trained\nusing temporal difference learning with a synthetic reward derived from the\nfixed, randomly initialized target network. We provide an extensive theoretical\nanalysis of our approach using neural tangent kernel (NTK) theory and show that\nin the limit of infinite network width, UVU errors are exactly equivalent to\nthe variance of an ensemble of independent universal value functions.\nEmpirically, we show that UVU achieves equal performance to large ensembles on\nchallenging multi-task offline RL settings, while offering simplicity and\nsubstantial computational savings."}
{"id": "2505.21133", "pdf": "https://arxiv.org/pdf/2505.21133", "abs": "https://arxiv.org/abs/2505.21133", "authors": ["Marshal Arijona Sinaga", "Julien Martinelli", "Samuel Kaski"], "title": "Robust and Computation-Aware Gaussian Processes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian processes (GPs) are widely used for regression and optimization\ntasks such as Bayesian optimization (BO) due to their expressiveness and\nprincipled uncertainty estimates. However, in settings with large datasets\ncorrupted by outliers, standard GPs and their sparse approximations struggle\nwith computational tractability and robustness. We introduce Robust\nComputation-aware Gaussian Process (RCaGP), a novel GP model that jointly\naddresses these challenges by combining a principled treatment of\napproximation-induced uncertainty with robust generalized Bayesian updating.\nThe key insight is that robustness and approximation-awareness are not\northogonal but intertwined: approximations can exacerbate the impact of\noutliers, and mitigating one without the other is insufficient. Unlike previous\nwork that focuses narrowly on either robustness or approximation quality, RCaGP\ncombines both in a principled and scalable framework, thus effectively managing\nboth outliers and computational uncertainties introduced by approximations such\nas low-rank matrix multiplications. Our model ensures more conservative and\nreliable uncertainty estimates, a property we rigorously demonstrate.\nAdditionally, we establish a robustness property and show that the mean\nfunction is key to preserving it, motivating a tailored model selection scheme\nfor robust mean functions. Empirical results confirm that solving these\nchallenges jointly leads to superior performance across both clean and\noutlier-contaminated settings, both on regression and high-throughput Bayesian\noptimization benchmarks."}
{"id": "2505.21135", "pdf": "https://arxiv.org/pdf/2505.21135", "abs": "https://arxiv.org/abs/2505.21135", "authors": ["Anqi Tang", "Youming Chen", "Shuchen Xue", "Zhaoqiang Liu"], "title": "Learning Single Index Models with Diffusion Priors", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "ICML 2025", "summary": "Diffusion models (DMs) have demonstrated remarkable ability to generate\ndiverse and high-quality images by efficiently modeling complex data\ndistributions. They have also been explored as powerful generative priors for\nsignal recovery, resulting in a substantial improvement in the quality of\nreconstructed signals. However, existing research on signal recovery with\ndiffusion models either focuses on specific reconstruction problems or is\nunable to handle nonlinear measurement models with discontinuous or unknown\nlink functions. In this work, we focus on using DMs to achieve accurate\nrecovery from semi-parametric single index models, which encompass a variety of\npopular nonlinear models that may have {\\em discontinuous} and {\\em unknown}\nlink functions. We propose an efficient reconstruction method that only\nrequires one round of unconditional sampling and (partial) inversion of DMs.\nTheoretical analysis on the effectiveness of the proposed methods has been\nestablished under appropriate conditions. We perform numerical experiments on\nimage datasets for different nonlinear measurement models. We observe that\ncompared to competing methods, our approach can yield more accurate\nreconstructions while utilizing significantly fewer neural function\nevaluations."}
{"id": "2505.21136", "pdf": "https://arxiv.org/pdf/2505.21136", "abs": "https://arxiv.org/abs/2505.21136", "authors": ["Jintao Zhang", "Xiaoming Xu", "Jia Wei", "Haofeng Huang", "Pengle Zhang", "Chendong Xiang", "Jun Zhu", "Jianfei Chen"], "title": "SageAttention2++: A More Efficient Implementation of SageAttention2", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CV"], "comment": null, "summary": "The efficiency of attention is critical because its time complexity grows\nquadratically with sequence length. SageAttention2 addresses this by utilizing\nquantization to accelerate matrix multiplications (Matmul) in attention. To\nfurther accelerate SageAttention2, we propose to utilize the faster instruction\nof FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8\nMatmul used in SageAttention2. Our experiments show that SageAttention2++\nachieves a 3.9x speedup over FlashAttention while maintaining the same\nattention accuracy as SageAttention2. This means SageAttention2++ effectively\naccelerates various models, including those for language, image, and video\ngeneration, with negligible end-to-end metrics loss. The code will be available\nat https://github.com/thu-ml/SageAttention."}
{"id": "2505.21140", "pdf": "https://arxiv.org/pdf/2505.21140", "abs": "https://arxiv.org/abs/2505.21140", "authors": ["Honglin Gao", "Xiang Li", "Lan Zhao", "Gaoxi Xiao"], "title": "HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heterogeneous graph neural networks (HGNNs) have recently drawn increasing\nattention for modeling complex multi-relational data in domains such as\nrecommendation, finance, and social networks. While existing research has been\nlargely focused on enhancing HGNNs' predictive performance, their robustness\nand security, especially under backdoor attacks, remain underexplored. In this\npaper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework\nfor node classification tasks on heterogeneous graphs. HeteroBA inserts\ncarefully crafted trigger nodes with realistic features and targeted structural\nconnections, leveraging attention-based and clustering-based strategies to\nselect influential auxiliary nodes for effective trigger propagation, thereby\ncausing the model to misclassify specific nodes into a target label while\nmaintaining accuracy on clean data. Experimental results on three datasets and\nvarious HGNN architectures demonstrate that HeteroBA achieves high attack\nsuccess rates with minimal impact on the clean accuracy. Our method sheds light\non potential vulnerabilities in HGNNs and calls for more robust defenses\nagainst backdoor threats in multi-relational graph scenarios."}
{"id": "2505.21141", "pdf": "https://arxiv.org/pdf/2505.21141", "abs": "https://arxiv.org/abs/2505.21141", "authors": ["Nancy C. Woods", "Virtue Ene Agada", "Adebola K. Ojo"], "title": "A Predicting Phishing Websites Using Support Vector Machine and MultiClass Classification Based on Association Rule Techniques", "categories": ["cs.LG", "68T05"], "comment": "12 pages", "summary": "Phishing is a semantic attack which targets the user rather than the\ncomputer. It is a new Internet crime in comparison with other forms such as\nvirus and hacking. Considering the damage phishing websites has caused to\nvarious economies by collapsing organizations, stealing information and\nfinancial diversion, various researchers have embarked on different ways of\ndetecting phishing websites but there has been no agreement about the best\nalgorithm to be used for prediction. This study is interested in integrating\nthe strengths of two algorithms, Support Vector Machines (SVM) and Multi-Class\nClassification Rules based on Association Rules (MCAR) to establish a strong\nand better means of predicting phishing websites. A total of 11,056 websites\nwere used from both PhishTank and yahoo directory to verify the effectiveness\nof this approach. Feature extraction and rules generation were done by the MCAR\ntechnique; classification and prediction were done by SVM technique. The result\nshowed that the technique achieved 98.30% classification accuracy with a\ncomputation time of 2205.33s with minimum error rate. It showed a total of 98%\nArea under the Curve (AUC) which showed the proportion of accuracy in\nclassifying phishing websites. The model showed 82.84% variance in the\nprediction of phishing websites based on the coefficient of determination. The\nuse of two techniques together in detecting phishing websites produced a more\naccurate result as it combined the strength of both techniques respectively.\nThis research work centralized on this advantage by building a hybrid of two\ntechniques to help produce a more accurate result."}
{"id": "2505.21147", "pdf": "https://arxiv.org/pdf/2505.21147", "abs": "https://arxiv.org/abs/2505.21147", "authors": ["Xuanning Zhou", "Hao Zeng", "Xiaobo Xia", "Bingyi Jing", "Hongxin Wei"], "title": "Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score", "categories": ["cs.LG"], "comment": null, "summary": "Conformal prediction (CP) is a powerful framework for uncertainty\nquantification, providing prediction sets with coverage guarantees when\ncalibrated on sufficient labeled data. However, in real-world applications\nwhere labeled data is often limited, standard CP can lead to coverage deviation\nand output overly large prediction sets. In this paper, we extend CP to the\nsemi-supervised setting and propose SemiCP, leveraging both labeled data and\nunlabeled data for calibration. Specifically, we introduce a novel\nnonconformity score function, NNM, designed for unlabeled data. This function\nselects labeled data with similar pseudo-label scores to estimate nonconformity\nscores, integrating them into the calibration process to overcome sample size\nlimitations. We theoretically demonstrate that, under mild assumptions, SemiCP\nprovide asymptotically coverage guarantee for prediction sets. Extensive\nexperiments further validate that our approach effectively reduces instability\nand inefficiency under limited calibration data, can be adapted to conditional\ncoverage settings, and integrates seamlessly with existing CP methods."}
{"id": "2505.21160", "pdf": "https://arxiv.org/pdf/2505.21160", "abs": "https://arxiv.org/abs/2505.21160", "authors": ["Michael Stenger", "Robert Leppich", "Andr√© Bauer", "Samuel Kounev"], "title": "STEB: In Search of the Best Evaluation Approach for Synthetic Time Series", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The growing need for synthetic time series, due to data augmentation or\nprivacy regulations, has led to numerous generative models, frameworks, and\nevaluation measures alike. Objectively comparing these measures on a large\nscale remains an open challenge. We propose the Synthetic Time series\nEvaluation Benchmark (STEB) -- the first benchmark framework that enables\ncomprehensive and interpretable automated comparisons of synthetic time series\nevaluation measures. Using 10 diverse datasets, randomness injection, and 13\nconfigurable data transformations, STEB computes indicators for measure\nreliability and score consistency. It tracks running time, test errors, and\nfeatures sequential and parallel modes of operation. In our experiments, we\ndetermine a ranking of 41 measures from literature and confirm that the choice\nof upstream time series embedding heavily impacts the final score."}
{"id": "2505.21173", "pdf": "https://arxiv.org/pdf/2505.21173", "abs": "https://arxiv.org/abs/2505.21173", "authors": ["Zhiwang Yu"], "title": "Topological Deep Learning for Speech Data", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "comment": "21 pages, 15 figures", "summary": "Topological data analysis (TDA) offers novel mathematical tools for deep\nlearning. Inspired by Carlsson et al., this study designs topology-aware\nconvolutional kernels that significantly improve speech recognition networks.\nTheoretically, by investigating orthogonal group actions on kernels, we\nestablish a fiber-bundle decomposition of matrix spaces, enabling new filter\ngeneration methods. Practically, our proposed Orthogonal Feature (OF) layer\nachieves superior performance in phoneme recognition, particularly in low-noise\nscenarios, while demonstrating cross-domain adaptability. This work reveals\nTDA's potential in neural network optimization, opening new avenues for\nmathematics-deep learning interdisciplinary studies."}
{"id": "2505.21180", "pdf": "https://arxiv.org/pdf/2505.21180", "abs": "https://arxiv.org/abs/2505.21180", "authors": ["ShuNing Sun", "YinSong Xiong", "Yu Zhang", "Zhuoran Zheng"], "title": "Latent label distribution grid representation for modeling uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Although \\textbf{L}abel \\textbf{D}istribution \\textbf{L}earning (LDL) has\npromising representation capabilities for characterizing the polysemy of an\ninstance, the complexity and high cost of the label distribution annotation\nlead to inexact in the construction of the label space. The existence of a\nlarge number of inexact labels generates a label space with uncertainty, which\nmisleads the LDL algorithm to yield incorrect decisions. To alleviate this\nproblem, we model the uncertainty of label distributions by constructing a\n\\textbf{L}atent \\textbf{L}abel \\textbf{D}istribution \\textbf{G}rid (LLDG) to\nform a low-noise representation space. Specifically, we first construct a label\ncorrelation matrix based on the differences between labels, and then expand\neach value of the matrix into a vector that obeys a Gaussian distribution, thus\nbuilding a LLDG to model the uncertainty of the label space. Finally, the LLDG\nis reconstructed by the LLDG-Mixer to generate an accurate label distribution.\nNote that we enforce a customized low-rank scheme on this grid, which assumes\nthat the label relations may be noisy and it needs to perform noise-reduction\nwith the help of a Tucker reconstruction technique. Furthermore, we attempt to\nevaluate the effectiveness of the LLDG by considering its generation as an\nupstream task to achieve the classification of the objects. Extensive\nexperimental results show that our approach performs competitively on several\nbenchmarks."}
{"id": "2505.21182", "pdf": "https://arxiv.org/pdf/2505.21182", "abs": "https://arxiv.org/abs/2505.21182", "authors": ["Huy Hoang", "Tien Mai", "Pradeep Varakantham", "Tanvi Verma"], "title": "Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations", "categories": ["cs.LG", "cs.AI"], "comment": "preprint version", "summary": "Offline imitation learning typically learns from expert and unlabeled\ndemonstrations, yet often overlooks the valuable signal in explicitly\nundesirable behaviors. In this work, we study offline imitation learning from\ncontrasting behaviors, where the dataset contains both expert and undesirable\ndemonstrations. We propose a novel formulation that optimizes a difference of\nKL divergences over the state-action visitation distributions of expert and\nundesirable (or bad) data. Although the resulting objective is a DC\n(Difference-of-Convex) program, we prove that it becomes convex when expert\ndemonstrations outweigh undesirable demonstrations, enabling a practical and\nstable non-adversarial training objective. Our method avoids adversarial\ntraining and handles both positive and negative demonstrations in a unified\nframework. Extensive experiments on standard offline imitation learning\nbenchmarks demonstrate that our approach consistently outperforms\nstate-of-the-art baselines."}
{"id": "2505.21184", "pdf": "https://arxiv.org/pdf/2505.21184", "abs": "https://arxiv.org/abs/2505.21184", "authors": ["Yu Yan", "Sheng Sun", "Zhifei Zheng", "Ziji Hao", "Teli Liu", "Min Liu"], "title": "PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "To construct responsible and secure AI applications, harmful information data\nis widely utilized for adversarial testing and the development of safeguards.\nExisting studies mainly leverage Large Language Models (LLMs) to synthesize\ndata to obtain high-quality task datasets at scale, thereby avoiding costly\nhuman annotation. However, limited by the safety alignment mechanisms of LLMs,\nthe synthesis of harmful data still faces challenges in generation reliability\nand content diversity. In this study, we propose a novel harmful information\nsynthesis framework, PoisonSwarm, which applies the model crowdsourcing\nstrategy to generate diverse harmful data while maintaining a high success\nrate. Specifically, we generate abundant benign data as the based templates in\na counterfactual manner. Subsequently, we decompose each based template into\nmultiple semantic units and perform unit-by-unit toxification and final\nrefinement through dynamic model switching, thus ensuring the success of\nsynthesis. Experimental results demonstrate that PoisonSwarm achieves\nstate-of-the-art performance in synthesizing different categories of harmful\ndata with high scalability and diversity."}
{"id": "2505.21201", "pdf": "https://arxiv.org/pdf/2505.21201", "abs": "https://arxiv.org/abs/2505.21201", "authors": ["Steven Sam", "Silima Marshal DAbreo"], "title": "Crop recommendation with machine learning: leveraging environmental and economic factors for optimal crop selection", "categories": ["cs.LG"], "comment": "22 pages and 13 figures", "summary": "Agriculture constitutes a primary source of food production, economic growth\nand employment in India, but the sector is confronted with low farm\nproductivity and yields aggravated by increased pressure on natural resources\nand adverse climate change variability. Efforts involving green revolution,\nland irrigations, improved seeds and organic farming have yielded suboptimal\noutcomes. The adoption of computational tools like crop recommendation systems\noffers a new way to provide insights and help farmers tackle low productivity.\nHowever, most agricultural recommendation systems in India focus narrowly on\nenvironmental factors and regions, limiting accurate predictions of high-yield,\nprofitable crops. This study uses environmental and economic factors with 19\ncrops across 15 states to develop and evaluate Random Forest and SVM models\nusing 10-fold Cross Validation, Time-series Split, and Lag Variables. The\n10-fold cross validation showed high accuracy (RF: 99.96%, SVM: 94.71%) but\nraised overfitting concerns. Introducing temporal order, better reflecting\nreal-world conditions, reduced performance (RF: 78.55%, SVM: 71.18%) in the\nTime-series Split.To further increase the model accuracy while maintaining the\ntemporal order, the Lag Variables approach was employed, which resulted in\nimproved performance (RF: 83.62%, SVM: 74.38%) compared to the 10-fold cross\nvalidation approach. Overall, the models in the Time-series Split and Lag\nVariable Approaches offer practical insights by handling temporal dependencies\nand enhancing its adaptability to changing agricultural conditions over time.\nConsequently, the study shows the Random Forest model developed based on the\nLag Variables as the most preferred algorithm for optimal crop recommendation\nin the Indian context."}
{"id": "2505.21204", "pdf": "https://arxiv.org/pdf/2505.21204", "abs": "https://arxiv.org/abs/2505.21204", "authors": ["Marie Steinacker", "Yuri Kheifetz", "Markus Scholz"], "title": "Developing hybrid mechanistic and data-driven personalized prediction models for platelet dynamics", "categories": ["cs.LG", "q-bio.QM", "I.6.5; J.3"], "comment": null, "summary": "Hematotoxicity, drug-induced damage to the blood-forming system, is a\nfrequent side effect of cytotoxic chemotherapy and poses a significant\nchallenge in clinical practice due to its high inter-patient variability and\nlimited predictability. Current mechanistic models often struggle to accurately\nforecast outcomes for patients with irregular or atypical trajectories. In this\nstudy, we develop and compare hybrid mechanistic and data-driven approaches for\nindividualized time series modeling of platelet counts during chemotherapy. We\nconsider hybrid models that combine mechanistic models with neural networks,\nknown as universal differential equations. As a purely data-driven alternative,\nwe utilize a nonlinear autoregressive exogenous model using gated recurrent\nunits as the underlying architecture. These models are evaluated across a range\nof real patient scenarios, varying in data availability and sparsity, to assess\npredictive performance. Our findings demonstrate that data-driven methods, when\nprovided with sufficient data, significantly improve prediction accuracy,\nparticularly for high-risk patients with irregular platelet dynamics. This\nhighlights the potential of data-driven approaches in enhancing clinical\ndecision-making. In contrast, hybrid and mechanistic models are superior in\nscenarios with limited or sparse data. The proposed modeling and comparison\nframework is generalizable and could be extended to predict other\ntreatment-related toxicities, offering broad applicability in personalized\nmedicine."}
{"id": "2505.21219", "pdf": "https://arxiv.org/pdf/2505.21219", "abs": "https://arxiv.org/abs/2505.21219", "authors": ["Qinjun Fei", "Nuria Rodr√≠guez-Barroso", "Mar√≠a Victoria Luz√≥n", "Zhongliang Zhang", "Francisco Herrera"], "title": "Addressing Data Quality Decompensation in Federated Learning via Dynamic Client Selection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In cross-silo Federated Learning (FL), client selection is critical to ensure\nhigh model performance, yet it remains challenging due to data quality\ndecompensation, budget constraints, and incentive compatibility. As training\nprogresses, these factors exacerbate client heterogeneity and degrade global\nperformance. Most existing approaches treat these challenges in isolation,\nmaking jointly optimizing multiple factors difficult. To address this, we\npropose Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a\nunified framework integrating dynamic bidding, reputation modeling, and\ncost-aware selection. Clients submit bids based on their perceived data\nquality, and their contributions are evaluated using Shapley values to quantify\ntheir marginal impact on the global model. A reputation system, inspired by\nprospect theory, captures historical performance while penalizing\ninconsistency. The client selection problem is formulated as a 0-1 integer\nprogram that maximizes reputation-weighted utility under budget constraints.\nExperiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets show that\nSBRO-FL improves accuracy, convergence speed, and robustness, even in\nadversarial and low-bid interference scenarios. Our results highlight the\nimportance of balancing data reliability, incentive compatibility, and cost\nefficiency to enable scalable and trustworthy FL deployments."}
{"id": "2505.21226", "pdf": "https://arxiv.org/pdf/2505.21226", "abs": "https://arxiv.org/abs/2505.21226", "authors": ["Zijing Wang", "Xingle Xu", "Yongkang Liu", "Yiqun Zhang", "Peiqin Lin", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Hinrich Sch√ºtze"], "title": "Why Do More Experts Fail? A Theoretical Analysis of Model Merging", "categories": ["cs.LG"], "comment": null, "summary": "Model merging dramatically reduces storage and computational resources by\ncombining multiple expert models into a single multi-task model. Although\nrecent model merging methods have shown promising results, they struggle to\nmaintain performance gains as the number of merged models increases. In this\npaper, we investigate the key obstacles that limit the scalability of model\nmerging when integrating a large number of expert models. First, we prove that\nthere is an upper bound on model merging. Further theoretical analysis reveals\nthat the limited effective parameter space imposes a strict constraint on the\nnumber of models that can be successfully merged. Gaussian Width shows that the\nmarginal benefit of merging additional models diminishes according to a\nstrictly concave function. This implies that the effective parameter space\nbecomes rapidly saturated as the number of merged models increases.\nFurthermore, using Approximate Kinematics Theory, we prove the existence of a\nunique optimal threshold beyond which adding more models does not yield\nsignificant performance improvements. At the same time, we introduce a\nstraightforward Reparameterized Heavy-Tailed method (RHT) to extend the\ncoverage of the merged model, thereby enhancing its performance. Empirical\nresults on 12 benchmarks, including both knowledge-intensive and\ngeneral-purpose tasks, validate our theoretical analysis. We believe that these\nresults spark further research beyond the current scope of model merging. The\nsource code is in the anonymous Github repository\nhttps://github.com/wzj1718/ModelMergingAnalysis."}
{"id": "2505.21236", "pdf": "https://arxiv.org/pdf/2505.21236", "abs": "https://arxiv.org/abs/2505.21236", "authors": ["Felix Chalumeau", "Daniel Rajaonarivonivelomanantsoa", "Ruan de Kock", "Claude Formanek", "Sasha Abramowitz", "Oumayma Mahjoub", "Wiem Khlifi", "Simon Du Toit", "Louay Ben Nessir", "Refiloe Shabe", "Arnol Fokam", "Siddarth Singh", "Ulrich Mbou Sob", "Arnu Pretorius"], "title": "Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Reinforcement learning (RL) systems have countless applications, from\nenergy-grid management to protein design. However, such real-world scenarios\nare often extremely difficult, combinatorial in nature, and require complex\ncoordination between multiple agents. This level of complexity can cause even\nstate-of-the-art RL systems, trained until convergence, to hit a performance\nceiling which they are unable to break out of with zero-shot inference.\nMeanwhile, many digital or simulation-based applications allow for an inference\nphase that utilises a specific time and compute budget to explore multiple\nattempts before outputting a final solution. In this work, we show that such an\ninference phase employed at execution time, and the choice of a corresponding\ninference strategy, are key to breaking the performance ceiling observed in\ncomplex multi-agent RL problems. Our main result is striking: we can obtain up\nto a 126% and, on average, a 45% improvement over the previous state-of-the-art\nacross 17 tasks, using only a couple seconds of extra wall-clock time during\nexecution. We also demonstrate promising compute scaling properties, supported\nby over 60k experiments, making it the largest study on inference strategies\nfor complex RL to date. Our experimental data and code are available at\nhttps://sites.google.com/view/inf-marl."}
{"id": "2505.21241", "pdf": "https://arxiv.org/pdf/2505.21241", "abs": "https://arxiv.org/abs/2505.21241", "authors": ["Divya Nori", "Anisha Parsan", "Caroline Uhler", "Wengong Jin"], "title": "BindEnergyCraft: Casting Protein Structure Predictors as Energy-Based Models for Binder Design", "categories": ["cs.LG"], "comment": null, "summary": "Protein binder design has been transformed by hallucination-based methods\nthat optimize structure prediction confidence metrics, such as the interface\npredicted TM-score (ipTM), via backpropagation. However, these metrics do not\nreflect the statistical likelihood of a binder-target complex under the learned\ndistribution and yield sparse gradients for optimization. In this work, we\npropose a method to extract such likelihoods from structure predictors by\nreinterpreting their confidence outputs as an energy-based model (EBM). By\nleveraging the Joint Energy-based Modeling (JEM) framework, we introduce\npTMEnergy, a statistical energy function derived from predicted inter-residue\nerror distributions. We incorporate pTMEnergy into BindEnergyCraft (BECraft), a\ndesign pipeline that maintains the same optimization framework as BindCraft but\nreplaces ipTM with our energy-based objective. BECraft outperforms BindCraft,\nRFDiffusion, and ESM3 across multiple challenging targets, achieving higher in\nsilico binder success rates while reducing structural clashes. Furthermore,\npTMEnergy establishes a new state-of-the-art in structure-based virtual\nscreening tasks for miniprotein and RNA aptamer binders."}
{"id": "2505.21251", "pdf": "https://arxiv.org/pdf/2505.21251", "abs": "https://arxiv.org/abs/2505.21251", "authors": ["Mustafa Hajij", "Lennart Bastian", "Sarah Osentoski", "Hardik Kabaria", "John L. Davenport", "Sheik Dawood", "Balaji Cherukuri", "Joseph G. Kocheemoolayil", "Nastaran Shahmansouri", "Adrian Lew", "Theodore Papamarkou", "Tolga Birdal"], "title": "Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework", "categories": ["cs.LG"], "comment": null, "summary": "We introduce copresheaf topological neural networks (CTNNs), a powerful and\nunifying framework that encapsulates a wide spectrum of deep learning\narchitectures, designed to operate on structured data: including images, point\nclouds, graphs, meshes, and topological manifolds. While deep learning has\nprofoundly impacted domains ranging from digital assistants to autonomous\nsystems, the principled design of neural architectures tailored to specific\ntasks and data types remains one of the field's most persistent open\nchallenges. CTNNs address this gap by grounding model design in the language of\ncopresheaves, a concept from algebraic topology that generalizes and subsumes\nmost practical deep learning models in use today. This abstract yet\nconstructive formulation yields a rich design space from which theoretically\nsound and practically effective solutions can be derived to tackle core\nchallenges in representation learning: long-range dependencies, oversmoothing,\nheterophily, and non-Euclidean domains. Our empirical results on structured\ndata benchmarks demonstrate that CTNNs consistently outperform conventional\nbaselines, particularly in tasks requiring hierarchical or localized\nsensitivity. These results underscore CTNNs as a principled, multi-scale\nfoundation for the next generation of deep learning architectures."}
{"id": "2505.21285", "pdf": "https://arxiv.org/pdf/2505.21285", "abs": "https://arxiv.org/abs/2505.21285", "authors": ["Xudong Wang", "Ziheng Sun", "Chris Ding", "Jicong Fan"], "title": "Learnable Kernel Density Estimation for Graphs", "categories": ["cs.LG", "stat.ML", "I.2; I.5.1; I.5.2"], "comment": "Under Review", "summary": "This work proposes a framework LGKDE that learns kernel density estimation\nfor graphs. The key challenge in graph density estimation lies in effectively\ncapturing both structural patterns and semantic variations while maintaining\ntheoretical guarantees. Combining graph kernels and kernel density estimation\n(KDE) is a standard approach to graph density estimation, but has\nunsatisfactory performance due to the handcrafted and fixed features of\nkernels. Our method LGKDE leverages graph neural networks to represent each\ngraph as a discrete distribution and utilizes maximum mean discrepancy to learn\nthe graph metric for multi-scale KDE, where all parameters are learned by\nmaximizing the density of graphs relative to the density of their well-designed\nperturbed counterparts. The perturbations are conducted on both node features\nand graph spectra, which helps better characterize the boundary of normal\ndensity regions. Theoretically, we establish consistency and convergence\nguarantees for LGKDE, including bounds on the mean integrated squared error,\nrobustness, and complexity. We validate LGKDE by demonstrating its\neffectiveness in recovering the underlying density of synthetic graph\ndistributions and applying it to graph anomaly detection across diverse\nbenchmark datasets. Extensive empirical evaluation shows that LGKDE\ndemonstrates superior performance compared to state-of-the-art baselines on\nmost benchmark datasets."}
{"id": "2505.21288", "pdf": "https://arxiv.org/pdf/2505.21288", "abs": "https://arxiv.org/abs/2505.21288", "authors": ["Farshad Noravesh", "Reza Haffari", "Layki Soon", "Arghya Pal"], "title": "GSAT: Graph Structure Attention Networks", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "Graph Neural Networks (GNNs) have emerged as a powerful tool for processing\ndata represented in graph structures, achieving remarkable success across a\nwide range of applications. However, to further improve the performance on\ngraph classification benchmarks, structural representation of each node that\nencodes rich local topological information in the neighbourhood of nodes is an\nimportant type of feature that is often overlooked in the modeling. The\nconsequence of neglecting the structural information has resulted high number\nof layers to connect messages from distant nodes which by itself produces other\nproblems such as oversmoothing. In the present paper, we leverage these\nstructural information that are modeled by anonymous random walks (ARWs) and\nintroduce graph structure attention network (GSAT) which is a generalization of\ngraph attention network(GAT) to integrate the original attribute and the\nstructural representation to enforce the model to automatically find patterns\nfor attending to different edges in the node neighbourhood to enrich graph\nrepresentation. Our experiments show GSAT slightly improves SOTA on some graph\nclassification benchmarks."}
{"id": "2505.21289", "pdf": "https://arxiv.org/pdf/2505.21289", "abs": "https://arxiv.org/abs/2505.21289", "authors": ["Nurbek Tastan", "Stefanos Laskaridis", "Martin Takac", "Karthik Nandakumar", "Samuel Horvath"], "title": "LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Large pre-trained models are commonly adapted to downstream tasks using\nparameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA),\nwhich injects small trainable low-rank matrices instead of updating all\nweights. While LoRA dramatically reduces trainable parameters with little\noverhead, it can still underperform full fine-tuning in accuracy and often\nconverges more slowly. We introduce LoFT, a novel low-rank adaptation method\nthat behaves like full fine-tuning by aligning the optimizer's internal\ndynamics with those of updating all model weights. LoFT not only learns weight\nupdates in a low-rank subspace (like LoRA) but also properly projects the\noptimizer's first and second moments (Adam's momentum and variance) into the\nsame subspace, mirroring full-model updates. By aligning the low-rank update\nitself with the full update, LoFT eliminates the need for tuning extra\nhyperparameters, e.g., LoRA scaling factor $\\alpha$. Empirically, this approach\nsubstantially narrows the performance gap between adapter-based tuning and full\nfine-tuning and consistently outperforms standard LoRA-style methods, all\nwithout increasing inference cost."}
{"id": "2505.21317", "pdf": "https://arxiv.org/pdf/2505.21317", "abs": "https://arxiv.org/abs/2505.21317", "authors": ["Ihab Bendidi", "Yassir El Mesbahi", "Alisandra K. Denton", "Karush Suri", "Kian Kenyon-Dean", "Auguste Genovesio", "Emmanuel Noutahi"], "title": "A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Main Proceedings", "summary": "Understanding cellular responses to stimuli is crucial for biological\ndiscovery and drug development. Transcriptomics provides interpretable,\ngene-level insights, while microscopy imaging offers rich predictive features\nbut is harder to interpret. Weakly paired datasets, where samples share\nbiological states, enable multimodal learning but are scarce, limiting their\nutility for training and multimodal inference. We propose a framework to\nenhance transcriptomics by distilling knowledge from microscopy images. Using\nweakly paired data, our method aligns and binds modalities, enriching gene\nexpression representations with morphological information. To address data\nscarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal\ndistillation using pretrained foundation models, achieving state-of-the-art\nresults, and (2) PEA (Perturbation Embedding Augmentation), a novel\naugmentation technique that enhances transcriptomics data while preserving\ninherent biological information. These strategies improve the predictive power\nand retain the interpretability of transcriptomics, enabling rich unimodal\nrepresentations for complex biological tasks."}
{"id": "2505.21321", "pdf": "https://arxiv.org/pdf/2505.21321", "abs": "https://arxiv.org/abs/2505.21321", "authors": ["Leonard Papenmeier", "Luigi Nardi"], "title": "Bencher: Simple and Reproducible Benchmarking for Black-Box Optimization", "categories": ["cs.LG"], "comment": "7 pages, 1 figure", "summary": "We present Bencher, a modular benchmarking framework for black-box\noptimization that fundamentally decouples benchmark execution from optimization\nlogic. Unlike prior suites that focus on combining many benchmarks in a single\nproject, Bencher introduces a clean abstraction boundary: each benchmark is\nisolated in its own virtual Python environment and accessed via a unified,\nversion-agnostic remote procedure call (RPC) interface. This design eliminates\ndependency conflicts and simplifies the integration of diverse, real-world\nbenchmarks, which often have complex and conflicting software requirements.\nBencher can be deployed locally or remotely via Docker or on high-performance\ncomputing (HPC) clusters via Singularity, providing a containerized,\nreproducible runtime for any benchmark. Its lightweight client requires minimal\nsetup and supports drop-in evaluation of 80 benchmarks across continuous,\ncategorical, and binary domains."}
{"id": "2505.21330", "pdf": "https://arxiv.org/pdf/2505.21330", "abs": "https://arxiv.org/abs/2505.21330", "authors": ["Christos Fragkathoulas", "Evaggelia Pitoura"], "title": "UGCE: User-Guided Incremental Counterfactual Exploration", "categories": ["cs.LG"], "comment": "Accepted to the ForgtAI Workshop at IJCNN 2025", "summary": "Counterfactual explanations (CFEs) are a popular approach for interpreting\nmachine learning predictions by identifying minimal feature changes that alter\nmodel outputs. However, in real-world settings, users often refine feasibility\nconstraints over time, requiring counterfactual generation to adapt\ndynamically. Existing methods fail to support such iterative updates, instead\nrecomputing explanations from scratch with each change, an inefficient and\nrigid approach. We propose User-Guided Incremental Counterfactual Exploration\n(UGCE), a genetic algorithm-based framework that incrementally updates\ncounterfactuals in response to evolving user constraints. Experimental results\nacross five benchmark datasets demonstrate that UGCE significantly improves\ncomputational efficiency while maintaining high-quality solutions compared to a\nstatic, non-incremental approach. Our evaluation further shows that UGCE\nsupports stable performance under varying constraint sequences, benefits from\nan efficient warm-start strategy, and reveals how different constraint types\nmay affect search behavior."}
{"id": "2505.21336", "pdf": "https://arxiv.org/pdf/2505.21336", "abs": "https://arxiv.org/abs/2505.21336", "authors": ["Loucas Pillaud-Vivien", "Adrien Schertzer"], "title": "Joint Learning in the Gaussian Single Index Model", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "31 Pages, 3 Figures", "summary": "We consider the problem of jointly learning a one-dimensional projection and\na univariate function in high-dimensional Gaussian models. Specifically, we\nstudy predictors of the form $f(x)=\\varphi^\\star(\\langle w^\\star, x \\rangle)$,\nwhere both the direction $w^\\star \\in \\mathcal{S}_{d-1}$, the sphere of\n$\\mathbb{R}^d$, and the function $\\varphi^\\star: \\mathbb{R} \\to \\mathbb{R}$ are\nlearned from Gaussian data. This setting captures a fundamental non-convex\nproblem at the intersection of representation learning and nonlinear\nregression. We analyze the gradient flow dynamics of a natural alternating\nscheme and prove convergence, with a rate controlled by the information\nexponent reflecting the \\textit{Gaussian regularity} of the function\n$\\varphi^\\star$. Strikingly, our analysis shows that convergence still occurs\neven when the initial direction is negatively correlated with the target. On\nthe practical side, we demonstrate that such joint learning can be effectively\nimplemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the\nstructure of the problem, enabling efficient and flexible estimation of the\nunivariate function. Our results offer both theoretical insight and practical\nmethodology for learning low-dimensional structure in high-dimensional\nsettings."}
{"id": "2505.21339", "pdf": "https://arxiv.org/pdf/2505.21339", "abs": "https://arxiv.org/abs/2505.21339", "authors": ["Henryk Mustroph", "Michel Kunkler", "Stefanie Rinderle-Ma"], "title": "An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Suffix prediction of business processes forecasts the remaining sequence of\nevents until process completion. Current approaches focus on predicting a\nsingle, most likely suffix. However, if the future course of a process is\nexposed to uncertainty or has high variability, the expressiveness of a single\nsuffix prediction can be limited. To address this limitation, we propose\nprobabilistic suffix prediction, a novel approach that approximates a\nprobability distribution of suffixes. The proposed approach is based on an\nUncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)\nsuffix sampling algorithm. We capture epistemic uncertainties via MC dropout\nand aleatoric uncertainties as learned loss attenuation. This technical report\nprovides a detailed evaluation of the U-ED-LSTM's predictive performance and\nassesses its calibration on four real-life event logs with three different\nhyperparameter settings. The results show that i) the U-ED-LSTM has reasonable\npredictive performance across various datasets, ii) aggregating probabilistic\nsuffix predictions into mean values can outperform most likely predictions,\nparticularly for rare prefixes or longer suffixes, and iii) the approach\neffectively captures uncertainties present in event logs."}
{"id": "2505.21347", "pdf": "https://arxiv.org/pdf/2505.21347", "abs": "https://arxiv.org/abs/2505.21347", "authors": ["Ziheng Cheng", "Yixiao Huang", "Hui Xu", "Somayeh Sojoudi", "Xuandong Zhao", "Dawn Song", "Song Mei"], "title": "OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models", "categories": ["cs.LG"], "comment": null, "summary": "Text-to-Image (T2I) models have achieved remarkable success in generating\nvisual content from text inputs. Although multiple safety alignment strategies\nhave been proposed to prevent harmful outputs, they often lead to overly\ncautious behavior -- rejecting even benign prompts -- a phenomenon known as\n$\\textit{over-refusal}$ that reduces the practical utility of T2I models.\nDespite over-refusal having been observed in practice, there is no large-scale\nbenchmark that systematically evaluates this phenomenon for T2I models. In this\npaper, we present an automatic workflow to construct synthetic evaluation data,\nresulting in OVERT ($\\textbf{OVE}$r-$\\textbf{R}$efusal evaluation on\n$\\textbf{T}$ext-to-image models), the first large-scale benchmark for assessing\nover-refusal behaviors in T2I models. OVERT includes 4,600 seemingly harmful\nbut benign prompts across nine safety-related categories, along with 1,785\ngenuinely harmful prompts (OVERT-unsafe) to evaluate the safety-utility\ntrade-off. Using OVERT, we evaluate several leading T2I models and find that\nover-refusal is a widespread issue across various categories (Figure 1),\nunderscoring the need for further research to enhance the safety alignment of\nT2I models without compromising their functionality.As a preliminary attempt to\nreduce over-refusal, we explore prompt rewriting; however, we find it often\ncompromises faithfulness to the meaning of the original prompts. Finally, we\ndemonstrate the flexibility of our generation framework in accommodating\ndiverse safety requirements by generating customized evaluation data adapting\nto user-defined policies."}
{"id": "2505.21360", "pdf": "https://arxiv.org/pdf/2505.21360", "abs": "https://arxiv.org/abs/2505.21360", "authors": ["Dhanesh Ramachandram"], "title": "CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models", "categories": ["cs.LG"], "comment": null, "summary": "Competing risks are crucial considerations in survival modelling,\nparticularly in healthcare domains where patients may experience multiple\ndistinct event types. We propose CRISP-NAM (Competing Risks Interpretable\nSurvival Prediction with Neural Additive Models), an interpretable neural\nadditive model for competing risks survival analysis which extends the neural\nadditive architecture to model cause-specific hazards while preserving\nfeature-level interpretability. Each feature contributes independently to risk\nestimation through dedicated neural networks, allowing for visualization of\ncomplex non-linear relationships between covariates and each competing risk. We\ndemonstrate competitive performance on multiple datasets compared to existing\napproaches."}
{"id": "2505.21363", "pdf": "https://arxiv.org/pdf/2505.21363", "abs": "https://arxiv.org/abs/2505.21363", "authors": ["Anissa Alloula", "Charles Jones", "Ben Glocker", "Bart≈Çomiej W. Papie≈º"], "title": "Subgroups Matter for Robust Bias Mitigation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and suggest it as a alternative lever for improving the\nrobustness and fairness of machine learning models."}
{"id": "2505.21364", "pdf": "https://arxiv.org/pdf/2505.21364", "abs": "https://arxiv.org/abs/2505.21364", "authors": ["James Oldfield", "Shawn Im", "Yixuan Li", "Mihalis A. Nicolaou", "Ioannis Patras", "Grigorios G Chrysos"], "title": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model's next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/."}
{"id": "2505.21366", "pdf": "https://arxiv.org/pdf/2505.21366", "abs": "https://arxiv.org/abs/2505.21366", "authors": ["Qi Yu", "Zhichen Zeng", "Yuchen Yan", "Zhining Liu", "Baoyu Jing", "Ruizhong Qiu", "Ariful Azad", "Hanghang Tong"], "title": "PLANETALIGN: A Comprehensive Python Library for Benchmarking Network Alignment", "categories": ["cs.LG"], "comment": null, "summary": "Network alignment (NA) aims to identify node correspondence across different\nnetworks and serves as a critical cornerstone behind various downstream\nmulti-network learning tasks. Despite growing research in NA, there lacks a\ncomprehensive library that facilitates the systematic development and\nbenchmarking of NA methods. In this work, we introduce PLANETALIGN, a\ncomprehensive Python library for network alignment that features a rich\ncollection of built-in datasets, methods, and evaluation pipelines with\neasy-to-use APIs. Specifically, PLANETALIGN integrates 18 datasets and 14 NA\nmethods with extensible APIs for easy use and development of NA methods. Our\nstandardized evaluation pipeline encompasses a wide range of metrics, enabling\na systematic assessment of the effectiveness, scalability, and robustness of NA\nmethods. Through extensive comparative studies, we reveal practical insights\ninto the strengths and limitations of existing NA methods. We hope that\nPLANETALIGN can foster a deeper understanding of the NA problem and facilitate\nthe development and benchmarking of more effective, scalable, and robust\nmethods in the future. The source code of PLANETALIGN is available at\nhttps://github.com/yq-leo/PlanetAlign."}
{"id": "2505.21372", "pdf": "https://arxiv.org/pdf/2505.21372", "abs": "https://arxiv.org/abs/2505.21372", "authors": ["Andrej Schwanke", "Lyubomir Ivanov", "David Salinas", "Fabio Ferreira", "Aaron Klein", "Frank Hutter", "Arber Zela"], "title": "Improving LLM-based Global Optimization with Search Space Partitioning", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 10 figures, 3 tables", "summary": "Large Language Models (LLMs) have recently emerged as effective surrogate\nmodels and candidate generators within global optimization frameworks for\nexpensive blackbox functions. Despite promising results, LLM-based methods\noften struggle in high-dimensional search spaces or when lacking\ndomain-specific priors, leading to sparse or uninformative suggestions. To\novercome these limitations, we propose HOLLM, a novel global optimization\nalgorithm that enhances LLM-driven sampling by partitioning the search space\ninto promising subregions. Each subregion acts as a ``meta-arm'' selected via a\nbandit-inspired scoring mechanism that effectively balances exploration and\nexploitation. Within each selected subregion, an LLM then proposes high-quality\ncandidate points, without any explicit domain knowledge. Empirical evaluation\non standard optimization benchmarks shows that HOLLM consistently matches or\nsurpasses leading Bayesian optimization and trust-region methods, while\nsubstantially outperforming global LLM-based sampling strategies."}
{"id": "2505.21382", "pdf": "https://arxiv.org/pdf/2505.21382", "abs": "https://arxiv.org/abs/2505.21382", "authors": ["Nastaran Saadati", "Zhanhong Jiang", "Joshua R. Waite", "Shreyan Ganguly", "Aditya Balu", "Chinmay Hegde", "Soumik Sarkar"], "title": "DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has emerged as one of the most effective,\ncomputationally tractable fine-tuning approaches for training Vision-Language\nModels (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by\nfreezing the pre-trained model weights and injecting trainable low-rank\nmatrices, allowing for efficient learning of these foundation models even on\nedge devices. However, LoRA in decentralized settings still remains under\nexplored, particularly for the theoretical underpinnings due to the lack of\nsmoothness guarantee and model consensus interference (defined formally below).\nThis work improves the convergence rate of decentralized LoRA (DLoRA) to match\nthe rate of decentralized SGD by ensuring gradient smoothness. We also\nintroduce DeCAF, a novel algorithm integrating DLoRA with truncated singular\nvalue decomposition (TSVD)-based matrix factorization to resolve consensus\ninterference. Theoretical analysis shows TSVD's approximation error is bounded\nand consensus differences between DLoRA and DeCAF vanish as rank increases,\nyielding DeCAF's matching convergence rate. Extensive experiments across\nvision/language tasks demonstrate our algorithms outperform local training and\nrivals federated learning under both IID and non-IID data distributions."}
{"id": "2505.21391", "pdf": "https://arxiv.org/pdf/2505.21391", "abs": "https://arxiv.org/abs/2505.21391", "authors": ["Zixuan Xie", "Xinyu Liu", "Rohan Chandra", "Shangtong Zhang"], "title": "Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point."}
{"id": "2505.21393", "pdf": "https://arxiv.org/pdf/2505.21393", "abs": "https://arxiv.org/abs/2505.21393", "authors": ["Maoli Liu", "Zhuohua Li", "Xiangxiang Dai", "John C. S. Lui"], "title": "Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 31st ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, 2025", "summary": "Conversational recommender systems proactively query users with relevant \"key\nterms\" and leverage the feedback to elicit users' preferences for personalized\nrecommendations. Conversational contextual bandits, a prevalent approach in\nthis domain, aim to optimize preference learning by balancing exploitation and\nexploration. However, several limitations hinder their effectiveness in\nreal-world scenarios. First, existing algorithms employ key term selection\nstrategies with insufficient exploration, often failing to thoroughly probe\nusers' preferences and resulting in suboptimal preference estimation. Second,\ncurrent algorithms typically rely on deterministic rules to initiate\nconversations, causing unnecessary interactions when preferences are\nwell-understood and missed opportunities when preferences are uncertain. To\naddress these limitations, we propose three novel algorithms: CLiSK, CLiME, and\nCLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in\npreference learning, CLiME adaptively initiates conversations based on\npreference uncertainty, and CLiSK-ME integrates both techniques. We\ntheoretically prove that all three algorithms achieve a tighter regret upper\nbound of $O(\\sqrt{dT\\log{T}})$ with respect to the time horizon $T$, improving\nupon existing methods. Additionally, we provide a matching lower bound\n$\\Omega(\\sqrt{dT})$ for conversational bandits, demonstrating that our\nalgorithms are nearly minimax optimal. Extensive evaluations on both synthetic\nand real-world datasets show that our approaches achieve at least a 14.6%\nimprovement in cumulative regret."}
{"id": "2505.21395", "pdf": "https://arxiv.org/pdf/2505.21395", "abs": "https://arxiv.org/abs/2505.21395", "authors": ["Xingyu Zhou", "Yulian Wu", "Wenqian Weng", "Francesco Orabona"], "title": "Square$œá$PO: Differentially Private and Robust $œá^2$-Preference Optimization in Offline Direct Alignment", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we theoretically study the offline alignment of language\nmodels with human preference feedback, under both preference label corruption\nand privacy protections. To this end, we propose Square$\\chi$PO, a simple\none-line change to $\\chi$PO where the standard log-loss is replaced by a new\nsquare loss over probability. Thanks to the inherent properties of this new\nloss, we have advanced the state-of-the-art of differentially private and\nrobust offline direct alignment. Specifically, for the local model of label\nprivacy, Square$\\chi$PO is the first algorithm that attains an optimal rate\nbased on single-policy concentrability even with general function\napproximations. It also gives the first result under the central model of\nprivacy protection over both prompts (responses) and labels. On the robustness\nside against Huber label corruption, Square$\\chi$PO is the first alignment\nmethod that has a meaningful theoretical guarantee under general function\napproximations. More importantly, Square$\\chi$PO can address privacy protection\nand corruption simultaneously, where an interesting separation is observed,\nimplying that the order of privacy and corruption matters. Furthermore, we show\nthat Square$\\chi$PO can also be easily extended to handle the scenario of the\ngeneral preference model with state-of-the-art guarantees under corruption and\nprivacy. Last but not least, all of our theoretical guarantees enjoy a unified\nanalysis, building upon a new result on the generalization error bounds of\nleast-square regression under corruption and privacy constraints, which we\nbelieve is of independent interest to the community."}
{"id": "2505.21400", "pdf": "https://arxiv.org/pdf/2505.21400", "abs": "https://arxiv.org/abs/2505.21400", "authors": ["Gen Li", "Changxiao Cai"], "title": "A Convergence Theory for Diffusion Language Models: An Information-Theoretic Perspective", "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Diffusion models have emerged as a powerful paradigm for modern generative\nmodeling, demonstrating strong potential for large language models (LLMs).\nUnlike conventional autoregressive (AR) models that generate tokens\nsequentially, diffusion models enable parallel token sampling, leading to\nfaster generation and eliminating left-to-right generation constraints. Despite\ntheir empirical success, the theoretical understanding of diffusion model\napproaches remains underdeveloped. In this work, we develop convergence\nguarantees for diffusion language models from an information-theoretic\nperspective. Our analysis demonstrates that the sampling error, measured by the\nKullback-Leibler (KL) divergence, decays inversely with the number of\niterations $T$ and scales linearly with the mutual information between tokens\nin the target text sequence. In particular, we establish matching upper and\nlower bounds, up to some constant factor, to demonstrate the tightness of our\nconvergence analysis. These results offer novel theoretical insights into the\npractical effectiveness of diffusion language models."}
{"id": "2505.21404", "pdf": "https://arxiv.org/pdf/2505.21404", "abs": "https://arxiv.org/abs/2505.21404", "authors": ["Anas Jnini", "Flavio Vella"], "title": "Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Natural-gradient methods markedly accelerate the training of Physics-Informed\nNeural Networks (PINNs), yet their Gauss--Newton update must be solved in the\nparameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is\nthe number of network trainable weights. We show that exactly the same step can\ninstead be formulated in a generally smaller residual space of size $m =\n\\sum_{\\gamma} N_{\\gamma} d_{\\gamma}$, where each residual class $\\gamma$ (e.g.\nPDE interior, boundary, initial data) contributes $N_{\\gamma}$ collocation\npoints of output dimension $d_{\\gamma}$.\n  Building on this insight, we introduce \\textit{Dual Natural Gradient Descent}\n(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it\nwith a geodesic-acceleration correction at negligible extra cost, and provides\nboth a dense direct solver for modest $m$ and a Nystrom-preconditioned\nconjugate-gradient solver for larger $m$.\n  Experimentally, D-NGD scales second-order PINN optimization to networks with\nup to 12.8 million parameters, delivers one- to three-order-of-magnitude lower\nfinal error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton\nmethods, and -- crucially -- enables natural-gradient training of PINNs at this\nscale on a single GPU."}
{"id": "2505.21414", "pdf": "https://arxiv.org/pdf/2505.21414", "abs": "https://arxiv.org/abs/2505.21414", "authors": ["Brett Bissey", "Kyle Gatesman", "Walker Dimon", "Mohammad Alam", "Luis Robaina", "Joseph Weissman"], "title": "A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": null, "summary": "This paper introduces a comprehensive framework designed to analyze and\nsecure decision-support systems trained with Deep Reinforcement Learning (DRL),\nprior to deployment, by providing insights into learned behavior patterns and\nvulnerabilities discovered through simulation. The introduced framework aids in\nthe development of precisely timed and targeted observation perturbations,\nenabling researchers to assess adversarial attack outcomes within a strategic\ndecision-making context. We validate our framework, visualize agent behavior,\nand evaluate adversarial outcomes within the context of a custom-built\nstrategic game, CyberStrike. Utilizing the proposed framework, we introduce a\nmethod for systematically discovering and ranking the impact of attacks on\nvarious observation indices and time-steps, and we conduct experiments to\nevaluate the transferability of adversarial attacks across agent architectures\nand DRL training algorithms. The findings underscore the critical need for\nrobust adversarial defense mechanisms to protect decision-making policies in\nhigh-stakes environments."}
{"id": "2505.21422", "pdf": "https://arxiv.org/pdf/2505.21422", "abs": "https://arxiv.org/abs/2505.21422", "authors": ["Abbavaram Gowtham Reddy", "Celia Rubio-Madrigal", "Rebekka Burkholz", "Krikamol Muandet"], "title": "When Shift Happens - Confounding Is to Blame", "categories": ["cs.LG"], "comment": null, "summary": "Distribution shifts introduce uncertainty that undermines the robustness and\ngeneralization capabilities of machine learning models. While conventional\nwisdom suggests that learning causal-invariant representations enhances\nrobustness to such shifts, recent empirical studies present a counterintuitive\nfinding: (i) empirical risk minimization (ERM) can rival or even outperform\nstate-of-the-art out-of-distribution (OOD) generalization methods, and (ii) its\nOOD generalization performance improves when all available covariates, not just\ncausal ones, are utilized. Drawing on both empirical and theoretical evidence,\nwe attribute this phenomenon to hidden confounding. Shifts in hidden\nconfounding induce changes in data distributions that violate assumptions\ncommonly made by existing OOD generalization approaches. Under such conditions,\nwe prove that effective generalization requires learning environment-specific\nrelationships, rather than relying solely on invariant ones. Furthermore, we\nshow that models augmented with proxies for hidden confounders can mitigate the\nchallenges posed by hidden confounding shifts. These findings offer new\ntheoretical insights and practical guidance for designing robust OOD\ngeneralization algorithms and principled covariate selection strategies."}
{"id": "2505.21423", "pdf": "https://arxiv.org/pdf/2505.21423", "abs": "https://arxiv.org/abs/2505.21423", "authors": ["Vit Fojtik", "Maria Matveev", "Hung-Hsu Chou", "Gitta Kutyniok", "Johannes Maly"], "title": "Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A widely believed explanation for the remarkable generalization capacities of\noverparameterized neural networks is that the optimization algorithms used for\ntraining induce an implicit bias towards benign solutions. To grasp this\ntheoretically, recent works examine gradient descent and its variants in\nsimplified training settings, often assuming vanishing learning rates. These\nstudies reveal various forms of implicit regularization, such as $\\ell_1$-norm\nminimizing parameters in regression and max-margin solutions in classification.\nConcurrently, empirical findings show that moderate to large learning rates\nexceeding standard stability thresholds lead to faster, albeit oscillatory,\nconvergence in the so-called Edge-of-Stability regime, and induce an implicit\nbias towards minima of low sharpness (norm of training loss Hessian). In this\nwork, we argue that a comprehensive understanding of the generalization\nperformance of gradient descent requires analyzing the interaction between\nthese various forms of implicit regularization. We empirically demonstrate that\nthe learning rate balances between low parameter norm and low sharpness of the\ntrained model. We furthermore prove for diagonal linear networks trained on a\nsimple regression task that neither implicit bias alone minimizes the\ngeneralization error. These findings demonstrate that focusing on a single\nimplicit bias is insufficient to explain good generalization, and they motivate\na broader view of implicit regularization that captures the dynamic trade-off\nbetween norm and sharpness induced by non-negligible learning rates."}
{"id": "2505.21430", "pdf": "https://arxiv.org/pdf/2505.21430", "abs": "https://arxiv.org/abs/2505.21430", "authors": ["Shiwei Zeng", "Jie Shen"], "title": "Attribute-Efficient PAC Learning of Sparse Halfspaces with Constant Malicious Noise Rate", "categories": ["cs.LG"], "comment": null, "summary": "Attribute-efficient learning of sparse halfspaces has been a fundamental\nproblem in machine learning theory. In recent years, machine learning\nalgorithms are faced with prevalent data corruptions or even adversarial\nattacks. It is of central interest to design efficient algorithms that are\nrobust to noise corruptions. In this paper, we consider that there exists a\nconstant amount of malicious noise in the data and the goal is to learn an\nunderlying $s$-sparse halfspace $w^* \\in \\mathbb{R}^d$ with $\\text{poly}(s,\\log\nd)$ samples. Specifically, we follow a recent line of works and assume that the\nunderlying distribution satisfies a certain concentration condition and a\nmargin condition at the same time. Under such conditions, we show that\nattribute-efficiency can be achieved by simple variants to existing hinge loss\nminimization programs. Our key contribution includes: 1) an attribute-efficient\nPAC learning algorithm that works under constant malicious noise rate; 2) a new\ngradient analysis that carefully handles the sparsity constraint in hinge loss\nminimization."}
{"id": "2505.21438", "pdf": "https://arxiv.org/pdf/2505.21438", "abs": "https://arxiv.org/abs/2505.21438", "authors": ["Yiwen Tu", "Ziqi Liu", "Jiaqi W. Ma", "Weijing Tang"], "title": "Measuring Fine-Grained Relatedness in Multitask Learning via Data Attribution", "categories": ["cs.LG"], "comment": null, "summary": "Measuring task relatedness and mitigating negative transfer remain a critical\nopen challenge in Multitask Learning (MTL). This work extends data attribution\n-- which quantifies the influence of individual training data points on model\npredictions -- to MTL setting for measuring task relatedness. We propose the\nMultiTask Influence Function (MTIF), a method that adapts influence functions\nto MTL models with hard or soft parameter sharing. Compared to conventional\ntask relatedness measurements, MTIF provides a fine-grained, instance-level\nrelatedness measure beyond the entire-task level. This fine-grained relatedness\nmeasure enables a data selection strategy to effectively mitigate negative\ntransfer in MTL. Through extensive experiments, we demonstrate that the\nproposed MTIF efficiently and accurately approximates the performance of models\ntrained on data subsets. Moreover, the data selection strategy enabled by MTIF\nconsistently improves model performance in MTL. Our work establishes a novel\nconnection between data attribution and MTL, offering an efficient and\nfine-grained solution for measuring task relatedness and enhancing MTL models."}
{"id": "2505.21444", "pdf": "https://arxiv.org/pdf/2505.21444", "abs": "https://arxiv.org/abs/2505.21444", "authors": ["Sheikh Shafayat", "Fahim Tajwar", "Ruslan Salakhutdinov", "Jeff Schneider", "Andrea Zanette"], "title": "Can Large Reasoning Models Self-Train?", "categories": ["cs.LG"], "comment": "Project website: https://self-rewarding-llm-training.github.io/", "summary": "Scaling the performance of large language models (LLMs) increasingly depends\non methods that reduce reliance on human supervision. Reinforcement learning\nfrom automated verification offers an alternative, but it incurs scalability\nlimitations due to dependency upon human-designed verifiers. Self-training,\nwhere the model's own judgment provides the supervisory signal, presents a\ncompelling direction. We propose an online self-training reinforcement learning\nalgorithm that leverages the model's self-consistency to infer correctness\nsignals and train without any ground-truth supervision. We apply the algorithm\nto challenging mathematical reasoning tasks and show that it quickly reaches\nperformance levels rivaling reinforcement-learning methods trained explicitly\non gold-standard answers. Additionally, we analyze inherent limitations of the\nalgorithm, highlighting how the self-generated proxy reward initially\ncorrelated with correctness can incentivize reward hacking, where confidently\nincorrect outputs are favored. Our results illustrate how self-supervised\nimprovement can achieve significant performance gains without external labels,\nwhile also revealing its fundamental challenges."}
{"id": "2505.21452", "pdf": "https://arxiv.org/pdf/2505.21452", "abs": "https://arxiv.org/abs/2505.21452", "authors": ["Xiangxin Zhou", "Mingyu Li", "Yi Xiao", "Jiahan Li", "Dongyu Xue", "Zaixiang Zheng", "Jianzhu Ma", "Quanquan Gu"], "title": "Designing Cyclic Peptides via Harmonic SDE with Atom-Bond Modeling", "categories": ["cs.LG", "q-bio.BM"], "comment": "Accepted to ICML 2025", "summary": "Cyclic peptides offer inherent advantages in pharmaceuticals. For example,\ncyclic peptides are more resistant to enzymatic hydrolysis compared to linear\npeptides and usually exhibit excellent stability and affinity. Although deep\ngenerative models have achieved great success in linear peptide design, several\nchallenges prevent the development of computational methods for designing\ndiverse types of cyclic peptides. These challenges include the scarcity of 3D\nstructural data on target proteins and associated cyclic peptide ligands, the\ngeometric constraints that cyclization imposes, and the involvement of\nnon-canonical amino acids in cyclization. To address the above challenges, we\nintroduce CpSDE, which consists of two key components: AtomSDE, a generative\nstructure prediction model based on harmonic SDE, and ResRouter, a residue type\npredictor. Utilizing a routed sampling algorithm that alternates between these\ntwo models to iteratively update sequences and structures, CpSDE facilitates\nthe generation of cyclic peptides. By employing explicit all-atom and bond\nmodeling, CpSDE overcomes existing data limitations and is proficient in\ndesigning a wide variety of cyclic peptides. Our experimental results\ndemonstrate that the cyclic peptides designed by our method exhibit reliable\nstability and affinity."}
{"id": "2505.21460", "pdf": "https://arxiv.org/pdf/2505.21460", "abs": "https://arxiv.org/abs/2505.21460", "authors": ["Maxwell Fishelson", "Noah Golowich", "Mehryar Mohri", "Jon Schneider"], "title": "High-Dimensional Calibration from Swap Regret", "categories": ["cs.LG", "cs.DS", "cs.GT", "stat.ML"], "comment": null, "summary": "We study the online calibration of multi-dimensional forecasts over an\narbitrary convex set $\\mathcal{P} \\subset \\mathbb{R}^d$ relative to an\narbitrary norm $\\Vert\\cdot\\Vert$. We connect this with the problem of external\nregret minimization for online linear optimization, showing that if it is\npossible to guarantee $O(\\sqrt{\\rho T})$ worst-case regret after $T$ rounds\nwhen actions are drawn from $\\mathcal{P}$ and losses are drawn from the dual\n$\\Vert \\cdot \\Vert_*$ unit norm ball, then it is also possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\rho /\\epsilon^2))$ rounds.\nWhen $\\mathcal{P}$ is the $d$-dimensional simplex and $\\Vert \\cdot \\Vert$ is\nthe $\\ell_1$-norm, the existence of $O(\\sqrt{T\\log d})$-regret algorithms for\nlearning with experts implies that it is possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\log{d}/\\epsilon^2)) =\nd^{O(1/\\epsilon^2)}$ rounds, recovering a recent result of Peng (2025).\n  Interestingly, our algorithm obtains this guarantee without requiring access\nto any online linear optimization subroutine or knowledge of the optimal rate\n$\\rho$ -- in fact, our algorithm is identical for every setting of\n$\\mathcal{P}$ and $\\Vert \\cdot \\Vert$. Instead, we show that the optimal\nregularizer for the above OLO problem can be used to upper bound the above\ncalibration error by a swap regret, which we then minimize by running the\nrecent TreeSwap algorithm with Follow-The-Leader as a subroutine.\n  Finally, we prove that any online calibration algorithm that guarantees\n$\\epsilon T$ $\\ell_1$-calibration error over the $d$-dimensional simplex\nrequires $T \\geq \\exp(\\mathrm{poly}(1/\\epsilon))$ (assuming $d \\geq\n\\mathrm{poly}(1/\\epsilon)$). This strengthens the corresponding\n$d^{\\Omega(\\log{1/\\epsilon})}$ lower bound of Peng, and shows that an\nexponential dependence on $1/\\epsilon$ is necessary."}
{"id": "2505.21468", "pdf": "https://arxiv.org/pdf/2505.21468", "abs": "https://arxiv.org/abs/2505.21468", "authors": ["Simon Dirmeier", "Antonietta Mira"], "title": "Causal Posterior Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present Causal Posterior Estimation (CPE), a novel method for Bayesian\ninference in simulator models, i.e., models where the evaluation of the\nlikelihood function is intractable or too computationally expensive, but where\none can simulate model outputs given parameter values. CPE utilizes a\nnormalizing flow-based (NF) approximation to the posterior distribution which\ncarefully incorporates the conditional dependence structure induced by the\ngraphical representation of the model into the neural network. Thereby it is\npossible to improve the accuracy of the approximation. We introduce both\ndiscrete and continuous NF architectures for CPE and propose a constant-time\nsampling procedure for the continuous case which reduces the computational\ncomplexity of drawing samples to O(1) as for discrete NFs. We show, through an\nextensive experimental evaluation, that by incorporating the conditional\ndependencies induced by the graphical model directly into the neural network,\nrather than learning them from data, CPE is able to conduct highly accurate\nposterior inference either outperforming or matching the state of the art in\nthe field."}
{"id": "2505.21475", "pdf": "https://arxiv.org/pdf/2505.21475", "abs": "https://arxiv.org/abs/2505.21475", "authors": ["Ilias Diakonikolas", "Giannis Iakovidis", "Daniel M. Kane", "Lisheng Ren"], "title": "Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-index Models", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We study the complexity of learning real-valued Multi-Index Models (MIMs)\nunder the Gaussian distribution. A $K$-MIM is a function $f:\\mathbb{R}^d\\to\n\\mathbb{R}$ that depends only on the projection of its input onto a\n$K$-dimensional subspace. We give a general algorithm for PAC learning a broad\nclass of MIMs with respect to the square loss, even in the presence of\nadversarial label noise. Moreover, we establish a nearly matching Statistical\nQuery (SQ) lower bound, providing evidence that the complexity of our algorithm\nis qualitatively optimal as a function of the dimension. Specifically, we\nconsider the class of bounded variation MIMs with the property that degree at\nmost $m$ distinguishing moments exist with respect to projections onto any\nsubspace. In the presence of adversarial label noise, the complexity of our\nlearning algorithm is $d^{O(m)}2^{\\mathrm{poly}(K/\\epsilon)}$. For the\nrealizable and independent noise settings, our algorithm incurs complexity\n$d^{O(m)}2^{\\mathrm{poly}(K)}(1/\\epsilon)^{O(K)}$. To complement our upper\nbound, we show that if for some subspace degree-$m$ distinguishing moments do\nnot exist, then any SQ learner for the corresponding class of MIMs requires\ncomplexity $d^{\\Omega(m)}$. As an application, we give the first efficient\nlearner for the class of positive-homogeneous $L$-Lipschitz $K$-MIMs. The\nresulting algorithm has complexity $\\mathrm{poly}(d)\n2^{\\mathrm{poly}(KL/\\epsilon)}$. This gives a new PAC learning algorithm for\nLipschitz homogeneous ReLU networks with complexity independent of the network\nsize, removing the exponential dependence incurred in prior work."}
{"id": "2505.21487", "pdf": "https://arxiv.org/pdf/2505.21487", "abs": "https://arxiv.org/abs/2505.21487", "authors": ["Ted Zadouri", "Hubert Strauss", "Tri Dao"], "title": "Hardware-Efficient Attention for Fast Decoding", "categories": ["cs.LG", "cs.CL"], "comment": "37 pages, 15 figures, 45 tables", "summary": "LLM decoding is bottlenecked for large batches and long contexts by loading\nthe key-value (KV) cache from high-bandwidth memory, which inflates per-token\nlatency, while the sequential nature of decoding limits parallelism. We analyze\nthe interplay among arithmetic intensity, parallelization, and model quality\nand question whether current architectures fully exploit modern hardware. This\nwork redesigns attention to perform more computation per byte loaded from\nmemory to maximize hardware efficiency without trading off parallel\nscalability. We first propose Grouped-Tied Attention (GTA), a simple variant\nthat combines and reuses key and value states, reducing memory transfers\nwithout compromising model quality. We then introduce Grouped Latent Attention\n(GLA), a parallel-friendly latent attention paired with low-level optimizations\nfor fast decoding while maintaining high model quality. Experiments show that\nGTA matches Grouped-Query Attention (GQA) quality while using roughly half the\nKV cache and that GLA matches Multi-head Latent Attention (MLA) and is easier\nto shard. Our optimized GLA kernel is up to 2$\\times$ faster than FlashMLA, for\nexample, in a speculative decoding setting when the query length exceeds one.\nFurthermore, by fetching a smaller KV cache per device, GLA reduces end-to-end\nlatency and increases throughput in online serving benchmarks by up to\n2$\\times$."}
{"id": "2505.21493", "pdf": "https://arxiv.org/pdf/2505.21493", "abs": "https://arxiv.org/abs/2505.21493", "authors": ["Xiangxin Zhou", "Zichen Liu", "Anya Sims", "Haonan Wang", "Tianyu Pang", "Chongxuan Li", "Liang Wang", "Min Lin", "Chao Du"], "title": "Reinforcing General Reasoning without Verifiers", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The recent paradigm shift towards training large language models (LLMs) using\nDeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has\nled to impressive advancements in code and mathematical reasoning. However,\nthis methodology is limited to tasks where rule-based answer verification is\npossible and does not naturally extend to real-world domains such as chemistry,\nhealthcare, engineering, law, biology, business, and economics. Current\npractical workarounds use an additional LLM as a model-based verifier; however,\nthis introduces issues such as reliance on a strong verifier LLM,\nsusceptibility to reward hacking, and the practical burden of maintaining the\nverifier model in memory during training. To address this and extend\nDeepSeek-R1-Zero-style training to general reasoning domains, we propose a\nverifier-free method (VeriFree) that bypasses answer verification and instead\nuses RL to directly maximize the probability of generating the reference\nanswer. We compare VeriFree with verifier-based methods and demonstrate that,\nin addition to its significant practical benefits and reduced compute\nrequirements, VeriFree matches and even surpasses verifier-based methods on\nextensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related\nbenchmarks. Moreover, we provide insights into this method from multiple\nperspectives: as an elegant integration of training both the policy and\nimplicit verifier in a unified model, and as a variational optimization\napproach. Code is available at https://github.com/sail-sg/VeriFree."}
{"id": "2505.20351", "pdf": "https://arxiv.org/pdf/2505.20351", "abs": "https://arxiv.org/abs/2505.20351", "authors": ["Tomer Shoham", "Katrina Ligettt"], "title": "Differentially private ratio statistics", "categories": ["stat.ML", "cs.LG"], "comment": "32 pages, 3 figures, under review", "summary": "Ratio statistics--such as relative risk and odds ratios--play a central role\nin hypothesis testing, model evaluation, and decision-making across many areas\nof machine learning, including causal inference and fairness analysis. However,\ndespite privacy concerns surrounding many datasets and despite increasing\nadoption of differential privacy, differentially private ratio statistics have\nlargely been neglected by the literature and have only recently received an\ninitial treatment by Lin et al. [1]. This paper attempts to fill this lacuna,\ngiving results that can guide practice in evaluating ratios when the results\nmust be protected by differential privacy. In particular, we show that even a\nsimple algorithm can provide excellent properties concerning privacy, sample\naccuracy, and bias, not just asymptotically but also at quite small sample\nsizes. Additionally, we analyze a differentially private estimator for relative\nrisk, prove its consistency, and develop a method for constructing valid\nconfidence intervals. Our approach bridges a gap in the differential privacy\nliterature and provides a practical solution for ratio estimation in private\nmachine learning pipelines."}
{"id": "2505.20433", "pdf": "https://arxiv.org/pdf/2505.20433", "abs": "https://arxiv.org/abs/2505.20433", "authors": ["Masha Naslidnyk", "Siu Lun Chau", "Fran√ßois-Xavier Briol", "Krikamol Muandet"], "title": "Kernel Quantile Embeddings and Associated Probability Metrics", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Embedding probability distributions into reproducing kernel Hilbert spaces\n(RKHS) has enabled powerful nonparametric methods such as the maximum mean\ndiscrepancy (MMD), a statistical distance with strong theoretical and\ncomputational properties. At its core, the MMD relies on kernel mean embeddings\nto represent distributions as mean functions in RKHS. However, it remains\nunclear if the mean function is the only meaningful RKHS representation.\nInspired by generalised quantiles, we introduce the notion of kernel quantile\nembeddings (KQEs). We then use KQEs to construct a family of distances that:\n(i) are probability metrics under weaker kernel conditions than MMD; (ii)\nrecover a kernelised form of the sliced Wasserstein distance; and (iii) can be\nefficiently estimated with near-linear cost. Through hypothesis testing, we\nshow that these distances offer a competitive alternative to MMD and its fast\napproximations."}
{"id": "2505.20465", "pdf": "https://arxiv.org/pdf/2505.20465", "abs": "https://arxiv.org/abs/2505.20465", "authors": ["Lorenzo Lucchese", "Mikko S. Pakkanen", "Almut E. D. Veraart"], "title": "Learning with Expected Signatures: Theory and Applications", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The expected signature maps a collection of data streams to a lower\ndimensional representation, with a remarkable property: the resulting feature\ntensor can fully characterize the data generating distribution. This\n\"model-free\" embedding has been successfully leveraged to build multiple\ndomain-agnostic machine learning (ML) algorithms for time series and sequential\ndata. The convergence results proved in this paper bridge the gap between the\nexpected signature's empirical discrete-time estimator and its theoretical\ncontinuous-time value, allowing for a more complete probabilistic\ninterpretation of expected signature-based ML methods. Moreover, when the data\ngenerating process is a martingale, we suggest a simple modification of the\nexpected signature estimator with significantly lower mean squared error and\nempirically demonstrate how it can be effectively applied to improve predictive\nperformance."}
{"id": "2505.20522", "pdf": "https://arxiv.org/pdf/2505.20522", "abs": "https://arxiv.org/abs/2505.20522", "authors": ["Jian Wang", "Boyan Zhu", "Chak Tou Leong", "Yongqi Li", "Wenjie Li"], "title": "Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "Large reasoning models (LRMs) have exhibited the capacity of enhancing\nreasoning performance via internal test-time scaling. Building upon this, a\npromising direction is to further scale test-time compute to unlock even\ngreater reasoning capabilities. However, as we push these scaling boundaries,\nsystematically understanding the practical limits and achieving optimal\nresource allocation becomes a critical challenge. In this paper, we investigate\nthe scaling Pareto of test-time scaling and introduce the Test-Time Scaling\nPerformance Model (TTSPM). We theoretically analyze two fundamental paradigms\nfor such extended scaling, parallel scaling and sequential scaling, from a\nprobabilistic modeling perspective. Our primary contribution is the derivation\nof the saturation point on the scaling budget for both strategies, identifying\nthresholds beyond which additional computation yields diminishing returns.\nRemarkably, despite their distinct mechanisms, both paradigms converge to a\nunified mathematical structure in their upper bounds. We empirically validate\nour theoretical findings on challenging reasoning benchmarks, including AIME,\nMATH-500, and GPQA, demonstrating the practical utility of these bounds for\ntest-time resource allocation. We hope that this work provides insights into\nthe cost-benefit trade-offs of test-time scaling, guiding the development of\nmore resource-efficient inference strategies for large reasoning models."}
{"id": "2505.20536", "pdf": "https://arxiv.org/pdf/2505.20536", "abs": "https://arxiv.org/abs/2505.20536", "authors": ["Guanhao Zhou", "Yuefeng Han", "Xiufan Yu"], "title": "Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "comment": null, "summary": "This paper studies the task of estimating heterogeneous treatment effects in\ncausal panel data models, in the presence of covariate effects. We propose a\nnovel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,\nthat employs flexible model structures and powerful neural network\narchitectures to cohesively deal with the underlying heterogeneity and\nnonlinearity of both panel units and covariate effects. The proposed CoDEAL\nintegrates nonlinear covariate effect components (parameterized by a\nfeed-forward neural network) with nonlinear factor structures (modeled by a\nmulti-output autoencoder) to form a heterogeneous causal panel model. The\nnonlinear covariate component offers a flexible framework for capturing the\ncomplex influences of covariates on outcomes. The nonlinear factor analysis\nenables CoDEAL to effectively capture both cross-sectional and temporal\ndependencies inherent in the data panel. This latent structural information is\nsubsequently integrated into a customized matrix completion algorithm, thereby\nfacilitating more accurate imputation of missing counterfactual outcomes.\nMoreover, the use of a multi-output autoencoder explicitly accounts for\nheterogeneity across units and enhances the model interpretability of the\nlatent factors. We establish theoretical guarantees on the convergence of the\nestimated counterfactuals, and demonstrate the compelling performance of the\nproposed method using extensive simulation studies and a real data application."}
{"id": "2505.20583", "pdf": "https://arxiv.org/pdf/2505.20583", "abs": "https://arxiv.org/abs/2505.20583", "authors": ["Michael O. Harding", "Kirthevasan Kandasamy"], "title": "Balancing Performance and Costs in Best Arm Identification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We consider the problem of identifying the best arm in a multi-armed bandit\nmodel. Despite a wealth of literature in the traditional fixed budget and fixed\nconfidence regimes of the best arm identification problem, it still remains a\nmystery to most practitioners as to how to choose an approach and corresponding\nbudget or confidence parameter. We propose a new formalism to avoid this\ndilemma altogether by minimizing a risk functional which explicitly balances\nthe performance of the recommended arm and the cost incurred by learning this\narm. In this framework, a cost is incurred for each observation during the\nsampling phase, and upon recommending an arm, a performance penalty is incurred\nfor identifying a suboptimal arm. The learner's goal is to minimize the sum of\nthe penalty and cost. This new regime mirrors the priorities of many\npractitioners, e.g. maximizing profit in an A/B testing framework, better than\nclassical fixed budget or confidence settings. We derive theoretical lower\nbounds for the risk of each of two choices for the performance penalty, the\nprobability of misidentification and the simple regret, and propose an\nalgorithm called DBCARE to match these lower bounds up to polylog factors on\nnearly all problem instances. We then demonstrate the performance of DBCARE on\na number of simulated models, comparing to fixed budget and confidence\nalgorithms to show the shortfalls of existing BAI paradigms on this problem."}
{"id": "2505.20647", "pdf": "https://arxiv.org/pdf/2505.20647", "abs": "https://arxiv.org/abs/2505.20647", "authors": ["Ian Langmore"], "title": "Moment Expansions of the Energy Distance", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62G10 (Primary), 62E20, 62H15, 60E10 (Secondary)", "G.3"], "comment": null, "summary": "The energy distance is used to test distributional equality, and as a loss\nfunction in machine learning. While $D^2(X, Y)=0$ only when $X\\sim Y$, the\nsensitivity to different moments is of practical importance. This work\nconsiders $D^2(X, Y)$ in the case where the distributions are close. In this\nregime, $D^2(X, Y)$ is more sensitive to differences in the means\n$\\bar{X}-\\bar{Y}$, than differences in the covariances $\\Delta$. This is due to\nthe structure of the energy distance and is independent of dimension. The\nsensitivity to on versus off diagonal components of $\\Delta$ is examined when\n$X$ and $Y$ are close to isotropic. Here a dimension dependent averaging occurs\nand, in many cases, off diagonal correlations contribute significantly less.\nNumerical results verify these relationships hold even when distributional\nassumptions are not strictly met."}
{"id": "2505.20671", "pdf": "https://arxiv.org/pdf/2505.20671", "abs": "https://arxiv.org/abs/2505.20671", "authors": ["Heng Tan", "Hua Yan", "Yu Yang"], "title": "LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "While reinforcement learning (RL) has achieved notable success in various\ndomains, training effective policies for complex tasks remains challenging.\nAgents often converge to local optima and fail to maximize long-term rewards.\nExisting approaches to mitigate training bottlenecks typically fall into two\ncategories: (i) Automated policy refinement, which identifies critical states\nfrom past trajectories to guide policy updates, but suffers from costly and\nuncertain model training; and (ii) Human-in-the-loop refinement, where human\nfeedback is used to correct agent behavior, but this does not scale well to\nenvironments with large or continuous action spaces. In this work, we design a\nlarge language model-guided policy modulation framework that leverages LLMs to\nimprove RL training without additional model training or human intervention. We\nfirst prompt an LLM to identify critical states from a sub-optimal agent's\ntrajectories. Based on these states, the LLM then provides action suggestions\nand assigns implicit rewards to guide policy refinement. Experiments across\nstandard RL benchmarks demonstrate that our method outperforms state-of-the-art\nbaselines, highlighting the effectiveness of LLM-based explanations in\naddressing RL training bottlenecks."}
{"id": "2505.20688", "pdf": "https://arxiv.org/pdf/2505.20688", "abs": "https://arxiv.org/abs/2505.20688", "authors": ["Taehyo Kim", "Qiran Jia", "Mony J. de Leon", "Hai Shu"], "title": "A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data", "categories": ["stat.ML", "cs.CV", "cs.LG", "stat.ME"], "comment": null, "summary": "False discovery rate (FDR) control methods are essential for voxel-wise\nmultiple testing in neuroimaging data analysis, where hundreds of thousands or\neven millions of tests are conducted to detect brain regions associated with\ndisease-related changes. Classical FDR control methods (e.g., BH, q-value, and\nLocalFDR) assume independence among tests and often lead to high false\nnon-discovery rates (FNR). Although various spatial FDR control methods have\nbeen developed to improve power, they still fall short in jointly addressing\nthree major challenges in neuroimaging applications: capturing complex spatial\ndependencies, maintaining low variability in both false discovery proportion\n(FDP) and false non-discovery proportion (FNP) across replications, and\nachieving computational scalability for high-resolution data. To address these\nchallenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR\ncontrol method for voxel-wise multiple testing. It integrates the local index\nof significance (LIS)-based testing procedure with a novel fully connected\nhidden Markov random field (fcHMRF) designed to model complex spatial\nstructures using a parsimonious parameterization. We develop an efficient\nexpectation-maximization algorithm incorporating mean-field approximation, the\nConditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and\npermutohedral lattice filtering, reducing the computational complexity from\nquadratic to linear in the number of tests. Extensive simulations demonstrate\nthat fcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability\nin FDP and FNP, and a higher number of true positives compared to existing\nmethods. Applied to an FDG-PET dataset from the Alzheimer's Disease\nNeuroimaging Initiative, fcHMRF-LIS identifies neurobiologically relevant brain\nregions and offers notable advantages in computational efficiency."}
{"id": "2505.20754", "pdf": "https://arxiv.org/pdf/2505.20754", "abs": "https://arxiv.org/abs/2505.20754", "authors": ["Zonghao Chen", "Toni Karvonen", "Heishiro Kanagawa", "Fran√ßois-Xavier Briol", "Chris. J. Oates"], "title": "Stationary MMD Points for Cubature", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Approximation of a target probability distribution using a finite set of\npoints is a problem of fundamental importance, arising in cubature, data\ncompression, and optimisation. Several authors have proposed to select points\nby minimising a maximum mean discrepancy (MMD), but the non-convexity of this\nobjective precludes global minimisation in general. Instead, we consider\n\\emph{stationary} points of the MMD which, in contrast to points globally\nminimising the MMD, can be accurately computed. Our main theoretical\ncontribution is the (perhaps surprising) result that, for integrands in the\nassociated reproducing kernel Hilbert space, the cubature error of stationary\nMMD points vanishes \\emph{faster} than the MMD. Motivated by this\n\\emph{super-convergence} property, we consider discretised gradient flows as a\npractical strategy for computing stationary points of the MMD, presenting a\nrefined convergence analysis that establishes a novel non-asymptotic\nfinite-particle error bound, which may be of independent interest."}
{"id": "2505.21208", "pdf": "https://arxiv.org/pdf/2505.21208", "abs": "https://arxiv.org/abs/2505.21208", "authors": ["Thomas Deschatre", "Xavier Warin"], "title": "Input Convex Kolmogorov Arnold Networks", "categories": ["stat.ML", "cs.LG", "math.OC", "68T07"], "comment": null, "summary": "This article presents an input convex neural network architecture using\nKolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the\nfirst is based on a low-order, linear-by-part, representation of functions, and\na universal approximation theorem is provided. The second is based on cubic\nsplines, for which only numerical results support convergence. We demonstrate\non simple tests that these networks perform competitively with classical input\nconvex neural networks (ICNNs). In a second part, we use the networks to solve\nsome optimal transport problems needing a convex approximation of functions and\ndemonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs\nproduce results similar to those of classical ICNNs."}
{"id": "2505.21410", "pdf": "https://arxiv.org/pdf/2505.21410", "abs": "https://arxiv.org/abs/2505.21410", "authors": ["Shashank Sharma", "Janina Hoffmann", "Vinay Namboodiri"], "title": "MRSD: Multi-Resolution Skill Discovery for HRL Agents", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Hierarchical reinforcement learning (HRL) relies on abstract skills to solve\nlong-horizon tasks efficiently. While existing skill discovery methods learns\nthese skills automatically, they are limited to a single skill per task. In\ncontrast, humans learn and use both fine-grained and coarse motor skills\nsimultaneously. Inspired by human motor control, we propose Multi-Resolution\nSkill Discovery (MRSD), an HRL framework that learns multiple skill encoders at\ndifferent temporal resolutions in parallel. A high-level manager dynamically\nselects among these skills, enabling adaptive control strategies over time. We\nevaluate MRSD on tasks from the DeepMind Control Suite and show that it\noutperforms prior state-of-the-art skill discovery and HRL methods, achieving\nfaster convergence and higher final performance. Our findings highlight the\nbenefits of integrating multi-resolution skills in HRL, paving the way for more\nversatile and efficient agents."}
{"id": "2505.21426", "pdf": "https://arxiv.org/pdf/2505.21426", "abs": "https://arxiv.org/abs/2505.21426", "authors": ["Francesco Cozzi", "Marco Pangallo", "Alan Perotti", "Andr√© Panisson", "Corrado Monti"], "title": "Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks", "categories": ["cs.AI", "cs.LG", "cs.MA", "econ.EM", "physics.soc-ph"], "comment": null, "summary": "Agent-Based Models (ABMs) are powerful tools for studying emergent properties\nin complex systems. In ABMs, agent behaviors are governed by local interactions\nand stochastic rules. However, these rules are, in general, non-differentiable,\nlimiting the use of gradient-based methods for optimization, and thus\nintegration with real-world data. We propose a novel framework to learn a\ndifferentiable surrogate of any ABM by observing its generated data. Our method\ncombines diffusion models to capture behavioral stochasticity and graph neural\nnetworks to model agent interactions. Distinct from prior surrogate approaches,\nour method introduces a fundamental shift: rather than approximating\nsystem-level outputs, it models individual agent behavior directly, preserving\nthe decentralized, bottom-up dynamics that define ABMs. We validate our\napproach on two ABMs (Schelling's segregation model and a Predator-Prey\necosystem) showing that it replicates individual-level patterns and accurately\nforecasts emergent dynamics beyond training. Our results demonstrate the\npotential of combining diffusion models and graph learning for data-driven ABM\nsimulation."}
{"id": "2505.21427", "pdf": "https://arxiv.org/pdf/2505.21427", "abs": "https://arxiv.org/abs/2505.21427", "authors": ["Xianling Mu", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms."}
{"id": "2505.21441", "pdf": "https://arxiv.org/pdf/2505.21441", "abs": "https://arxiv.org/abs/2505.21441", "authors": ["Binh Duc Vu", "Jan Kapar", "Marvin Wright", "David S. Watson"], "title": "Autoencoding Random Forests", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "10 pages main text, 25 pages total. 5 figures main text, 9 figures\n  total", "summary": "We propose a principled method for autoencoding with random forests. Our\nstrategy builds on foundational results from nonparametric statistics and\nspectral graph theory to learn a low-dimensional embedding of the model that\noptimally represents relationships in the data. We provide exact and\napproximate solutions to the decoding problem via constrained optimization,\nsplit relabeling, and nearest neighbors regression. These methods effectively\ninvert the compression pipeline, establishing a map from the embedding space\nback to the input space using splits learned by the ensemble's constituent\ntrees. The resulting decoders are universally consistent under common\nregularity assumptions. The procedure works with supervised or unsupervised\nmodels, providing a window into conditional or joint distributions. We\ndemonstrate various applications of this autoencoder, including powerful new\ntools for visualization, compression, clustering, and denoising. Experiments\nillustrate the ease and utility of our method in a wide range of settings,\nincluding tabular, image, and genomic data."}
