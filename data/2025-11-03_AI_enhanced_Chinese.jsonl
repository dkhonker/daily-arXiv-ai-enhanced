{"id": "2510.26852", "pdf": "https://arxiv.org/pdf/2510.26852", "abs": "https://arxiv.org/abs/2510.26852", "authors": ["Lingyue Fu", "Xin Ding", "Yaoming Zhu", "Shao Zhang", "Lin Qiu", "Weiwen Liu", "Weinan Zhang", "Xuezhi Cao", "Xunliang Cai", "Jiaxin Ding", "Yong Yu"], "title": "CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Model (LLM) agents have evolved from basic text generation to\nautonomously completing complex tasks through interaction with external tools.\nHowever, current benchmarks mainly assess end-to-end performance in fixed\nscenarios, restricting evaluation to specific skills and suffering from score\nsaturation and growing dependence on expert annotation as agent capabilities\nimprove. In this work, we emphasize the importance of learning ability,\nincluding both self-improvement and peer-learning, as a core driver for agent\nevolution toward human-level intelligence. We propose an iterative, competitive\npeer-learning framework, which allows agents to refine and optimize their\nstrategies through repeated interactions and feedback, thereby systematically\nevaluating their learning capabilities. To address the score saturation issue\nin current benchmarks, we introduce CATArena, a tournament-style evaluation\nplatform featuring four diverse board and card games with open-ended scoring.\nBy providing tasks without explicit upper score limits, CATArena enables\ncontinuous and dynamic evaluation of rapidly advancing agent capabilities.\nExperimental results and analyses involving both minimal and commercial code\nagents demonstrate that CATArena provides reliable, stable, and scalable\nbenchmarking for core agent abilities, particularly learning ability and\nstrategy coding.", "AI": {"tldr": "该论文提出了CATArena评估平台，通过四款棋牌游戏的无上限计分系统，解决现有LLM智能体基准测试中的分数饱和问题，专注于评估智能体的学习能力和策略编码能力。", "motivation": "当前LLM智能体基准测试主要评估固定场景下的端到端性能，存在分数饱和、依赖专家标注、无法有效评估学习能力等问题，限制了智能体向人类水平智能的发展。", "method": "提出迭代竞争式同伴学习框架，让智能体通过重复互动和反馈优化策略；开发CATArena锦标赛式评估平台，包含四款多样化的棋牌游戏，采用开放式计分系统。", "result": "实验结果表明，CATArena能够为智能体核心能力（特别是学习能力和策略编码）提供可靠、稳定和可扩展的基准测试，适用于最小化代码智能体和商业化代码智能体。", "conclusion": "CATArena平台通过开放式计分和多样化游戏设置，有效解决了现有基准测试的局限性，为评估LLM智能体的学习能力和持续进化提供了系统性的解决方案。"}}
{"id": "2510.26854", "pdf": "https://arxiv.org/pdf/2510.26854", "abs": "https://arxiv.org/abs/2510.26854", "authors": ["Yu Li", "Yuan Huang", "Tao Wang", "Caiyu Fan", "Xiansheng Cai", "Sihan Hu", "Xinzijian Liu", "Cheng Shi", "Mingjun Xu", "Zhen Wang", "Yan Wang", "Xiangqi Jin", "Tianhan Zhang", "Linfeng Zhang", "Lei Wang", "Youjin Deng", "Pan Zhang", "Weijie Sun", "Xingyu Li", "Weinan E", "Linfeng Zhang", "Zhiyuan Yao", "Kun Chen"], "title": "Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base", "categories": ["cs.AI", "cs.LG"], "comment": "43 pages, 4 figures", "summary": "Most scientific materials compress reasoning, presenting conclusions while\nomitting the derivational chains that justify them. This compression hinders\nverification by lacking explicit, step-wise justifications and inhibits\ncross-domain links by collapsing the very pathways that establish the logical\nand causal connections between concepts. We introduce a scalable framework that\ndecompresses scientific reasoning, constructing a verifiable Long\nChain-of-Thought (LCoT) knowledge base and projecting it into an emergent\nencyclopedia, SciencePedia. Our pipeline operationalizes an endpoint-driven,\nreductionist strategy: a Socratic agent, guided by a curriculum of around 200\ncourses, generates approximately 3 million first-principles questions. To\nensure high fidelity, multiple independent solver models generate LCoTs, which\nare then rigorously filtered by prompt sanitization and cross-model answer\nconsensus, retaining only those with verifiable endpoints. This verified corpus\npowers the Brainstorm Search Engine, which performs inverse knowledge search --\nretrieving diverse, first-principles derivations that culminate in a target\nconcept. This engine, in turn, feeds the Plato synthesizer, which narrates\nthese verified chains into coherent articles. The initial SciencePedia\ncomprises approximately 200,000 fine-grained entries spanning mathematics,\nphysics, chemistry, biology, engineering, and computation. In evaluations\nacross six disciplines, Plato-synthesized articles (conditioned on retrieved\nLCoTs) exhibit substantially higher knowledge-point density and significantly\nlower factual error rates than an equally-prompted baseline without retrieval\n(as judged by an external LLM). Built on this verifiable LCoT knowledge base,\nthis reasoning-centric approach enables trustworthy, cross-domain scientific\nsynthesis at scale and establishes the foundation for an ever-expanding\nencyclopedia.", "AI": {"tldr": "该论文提出了一个可扩展的框架，通过解压缩科学推理过程，构建可验证的长链思维知识库SciencePedia，实现了跨领域的可信科学知识合成。", "motivation": "当前科学材料通常压缩推理过程，只呈现结论而省略推导链，这阻碍了验证并抑制了跨领域概念间的逻辑和因果联系。", "method": "采用端点驱动的还原策略：Socratic代理生成约300万个第一原理问题，多个独立求解模型生成长链思维推导，通过提示净化和跨模型答案共识进行严格筛选，构建验证语料库。", "result": "SciencePedia包含约20万个细粒度条目，在六个学科评估中，基于检索LCoTs的合成文章显示出显著更高的知识点密度和更低的错误率。", "conclusion": "这种以推理为中心的方法实现了大规模可信的跨领域科学合成，为不断扩展的百科全书奠定了基础。"}}
{"id": "2510.26887", "pdf": "https://arxiv.org/pdf/2510.26887", "abs": "https://arxiv.org/abs/2510.26887", "authors": ["Francisco Villaescusa-Navarro", "Boris Bolliet", "Pablo Villanueva-Domingo", "Adrian E. Bayer", "Aidan Acquah", "Chetana Amancharla", "Almog Barzilay-Siegal", "Pablo Bermejo", "Camille Bilodeau", "Pablo Cárdenas Ramírez", "Miles Cranmer", "Urbano L. França", "ChangHoon Hahn", "Yan-Fei Jiang", "Raul Jimenez", "Jun-Young Lee", "Antonio Lerario", "Osman Mamun", "Thomas Meier", "Anupam A. Ojha", "Pavlos Protopapas", "Shimanto Roy", "David N. Spergel", "Pedro Tarancón-Álvarez", "Ujjwal Tiwari", "Matteo Viel", "Digvijay Wadekar", "Chi Wang", "Bonny Y. Wang", "Licong Xu", "Yossi Yovel", "Shuwen Yue", "Wen-Han Zhou", "Qiyao Zhu", "Jiajun Zou", "Íñigo Zubeldia"], "title": "The Denario project: Deep knowledge AI agents for scientific discovery", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "comment": "272 pages. Examples of 11 AI-generated paper drafts from different\n  scientific disciplines. Code publicly available at\n  https://github.com/AstroPilot-AI/Denario", "summary": "We present Denario, an AI multi-agent system designed to serve as a\nscientific research assistant. Denario can perform many different tasks, such\nas generating ideas, checking the literature, developing research plans,\nwriting and executing code, making plots, and drafting and reviewing a\nscientific paper. The system has a modular architecture, allowing it to handle\nspecific tasks, such as generating an idea, or carrying out end-to-end\nscientific analysis using Cmbagent as a deep-research backend. In this work, we\ndescribe in detail Denario and its modules, and illustrate its capabilities by\npresenting multiple AI-generated papers generated by it in many different\nscientific disciplines such as astrophysics, biology, biophysics, biomedical\ninformatics, chemistry, material science, mathematical physics, medicine,\nneuroscience and planetary science. Denario also excels at combining ideas from\ndifferent disciplines, and we illustrate this by showing a paper that applies\nmethods from quantum physics and machine learning to astrophysical data. We\nreport the evaluations performed on these papers by domain experts, who\nprovided both numerical scores and review-like feedback. We then highlight the\nstrengths, weaknesses, and limitations of the current system. Finally, we\ndiscuss the ethical implications of AI-driven research and reflect on how such\ntechnology relates to the philosophy of science. We publicly release the code\nat https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run\ndirectly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and\nthe full app will be deployed on the cloud.", "AI": {"tldr": "Denario是一个AI多智能体系统，作为科学研究助手，能够执行从构思到论文撰写的完整科研流程，支持多学科研究并展示了跨学科创新应用。", "motivation": "开发一个能够辅助科学研究全过程的人工智能系统，解决科研工作中从想法生成到论文完成的各个环节自动化需求，提升科研效率并探索跨学科研究的可能性。", "method": "采用模块化架构设计，集成Cmbagent作为深度研究后端，支持特定任务处理和端到端科学分析，涵盖文献检索、代码编写、图表生成、论文起草和审阅等功能。", "result": "系统成功生成了多个学科领域（天体物理、生物、化学等）的AI论文，展示了跨学科研究能力（如量子物理与机器学习在天体物理数据中的应用），并通过领域专家评估获得数值评分和评审反馈。", "conclusion": "Denario展示了AI驱动研究的巨大潜力，但存在局限性；讨论了AI科研的伦理影响和科学哲学意义，代码已开源并提供在线演示。"}}
{"id": "2510.26905", "pdf": "https://arxiv.org/pdf/2510.26905", "abs": "https://arxiv.org/abs/2510.26905", "authors": ["Pedro Antonio Alarcón Granadeno", "Arturo Miguel Bernal Russell", "Sofia Nelson", "Demetrius Hernandez", "Maureen Petterson", "Michael Murphy", "Walter J. Scheirer", "Jane Cleland-Huang"], "title": "Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations", "categories": ["cs.AI"], "comment": "10.5 pages, 9 figures", "summary": "Cyber-physical systems increasingly rely on Foundational Models such as Large\nLanguage Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy\nthrough enhanced perception, inference, and planning. However, these models\nalso introduce new types of errors, such as hallucinations,\novergeneralizations, and context misalignments, resulting in incorrect and\nflawed decisions. To address this, we introduce the concept of Cognition\nEnvelopes, designed to establish reasoning boundaries that constrain\nAI-generated decisions while complementing the use of meta-cognition and\ntraditional safety envelopes. As with safety envelopes, Cognition Envelopes\nrequire practical guidelines and systematic processes for their definition,\nvalidation, and assurance.", "AI": {"tldr": "论文提出认知包络(Cognition Envelopes)概念，用于约束AI模型在物理信息系统中产生的错误决策，通过建立推理边界来补充元认知和传统安全包络。", "motivation": "物理信息系统越来越多地依赖基础模型(如LLMs和VLMs)来增强自主性，但这些模型引入了幻觉、过度泛化和上下文错位等新型错误，导致错误决策。", "method": "引入认知包络概念，建立推理边界来约束AI生成的决策，需要制定实用的定义、验证和保证指南与系统化流程。", "result": "提出了认知包络的理论框架，但未提供具体的实验结果或验证数据。", "conclusion": "认知包络为解决基础模型在物理信息系统中引入的新型错误提供了系统化方法，需要进一步开发实践指南和验证流程来确保其有效性。"}}
{"id": "2510.26912", "pdf": "https://arxiv.org/pdf/2510.26912", "abs": "https://arxiv.org/abs/2510.26912", "authors": ["Hyunji Lee", "Wenhao Yu", "Hongming Zhang", "Kaixin Ma", "Jiyeon Kim", "Dong Yu", "Minjoon Seo"], "title": "Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Hybrid models that combine state space models (SSMs) with attention\nmechanisms have shown strong performance by leveraging the efficiency of SSMs\nand the high recall ability of attention. However, the architectural design\nchoices behind these hybrid models remain insufficiently understood. In this\nwork, we analyze hybrid architectures through the lens of memory utilization\nand overall performance, and propose a complementary method to further enhance\ntheir effectiveness. We first examine the distinction between sequential and\nparallel integration of SSM and attention layers. Our analysis reveals several\ninteresting findings, including that sequential hybrids perform better on\nshorter contexts, whereas parallel hybrids are more effective for longer\ncontexts. We also introduce a data-centric approach of continually training on\ndatasets augmented with paraphrases, which further enhances recall while\npreserving other capabilities. It generalizes well across different base models\nand outperforms architectural modifications aimed at enhancing recall. Our\nfindings provide a deeper understanding of hybrid SSM-attention models and\noffer practical guidance for designing architectures tailored to various use\ncases. Our findings provide a deeper understanding of hybrid SSM-attention\nmodels and offer practical guidance for designing architectures tailored to\nvarious use cases.", "AI": {"tldr": "该论文分析了结合状态空间模型和注意力机制的混合架构，发现序列混合在短上下文表现更好，并行混合在长上下文更有效，并提出基于释义数据增强的持续训练方法来提升召回能力。", "motivation": "虽然结合状态空间模型和注意力机制的混合模型表现出色，但其架构设计选择仍缺乏深入理解，需要分析不同集成方式的内存利用和性能表现。", "method": "通过分析序列和并行两种SSM与注意力的集成方式，并引入基于释义数据增强的持续训练方法来提升模型性能。", "result": "发现序列混合在短上下文表现更优，并行混合在长上下文更有效；数据增强的持续训练方法能显著提升召回能力且泛化性好。", "conclusion": "研究提供了对混合SSM-注意力模型的深入理解，并为针对不同用例设计架构提供了实用指导，数据增强方法比架构修改更有效地提升召回能力。"}}
{"id": "2510.26989", "pdf": "https://arxiv.org/pdf/2510.26989", "abs": "https://arxiv.org/abs/2510.26989", "authors": ["Agorakis Bompotas", "Konstantinos Koutras", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Dimitra Gariza", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "The global agricultural sector is undergoing a transformative shift, driven\nby increasing food demands, climate variability and the need for sustainable\npractices. SUSTAINABLE is a smart farming platform designed to integrate IoT,\nAI, satellite imaging, and role-based task orchestration to enable efficient,\ntraceable, and sustainable agriculture with a pilot usecase in viticulture.\nThis paper explores current smart agriculture solutions, presents a comparative\nevaluation, and introduces SUSTAINABLE's key features, including satellite\nindex integration, real-time environmental data, and role-aware task management\ntailored to Mediterranean vineyards.", "AI": {"tldr": "SUSTAINABLE是一个智能农业平台，整合物联网、人工智能、卫星成像和基于角色的任务编排技术，专注于葡萄种植领域的可持续农业实践。", "motivation": "全球农业面临粮食需求增长、气候多变性和可持续实践需求的挑战，需要智能化的农业解决方案。", "method": "整合IoT、AI、卫星成像技术，开发基于角色的任务编排系统，特别针对地中海葡萄园进行定制化设计。", "result": "提出了一个具有卫星指数集成、实时环境数据和角色感知任务管理功能的智能农业平台。", "conclusion": "SUSTAINABLE平台展示了通过技术整合实现高效、可追溯和可持续农业的可行性，特别是在葡萄种植领域的应用潜力。"}}
{"id": "2510.26969", "pdf": "https://arxiv.org/pdf/2510.26969", "abs": "https://arxiv.org/abs/2510.26969", "authors": ["Lívia Dutra", "Arthur Lorenzi", "Laís Berno", "Franciany Campos", "Karoline Biscardi", "Kenneth Brown", "Marcelo Viridiano", "Frederico Belcavello", "Ely Matos", "Olívia Guaranha", "Erik Santos", "Sofia Reinach", "Tiago Timponi Torrent"], "title": "Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a methodology for the identification of notifiable events in the\ndomain of healthcare. The methodology harnesses semantic frames to define\nfine-grained patterns and search them in unstructured data, namely, open-text\nfields in e-medical records. We apply the methodology to the problem of\nunderreporting of gender-based violence (GBV) in e-medical records produced\nduring patients' visits to primary care units. A total of eight patterns are\ndefined and searched on a corpus of 21 million sentences in Brazilian\nPortuguese extracted from e-SUS APS. The results are manually evaluated by\nlinguists and the precision of each pattern measured. Our findings reveal that\nthe methodology effectively identifies reports of violence with a precision of\n0.726, confirming its robustness. Designed as a transparent, efficient,\nlow-carbon, and language-agnostic pipeline, the approach can be easily adapted\nto other health surveillance contexts, contributing to the broader, ethical,\nand explainable use of NLP in public health systems.", "AI": {"tldr": "提出一种基于语义框架的医疗事件识别方法，用于从电子病历中检测基于性别的暴力事件报告，在2100万句葡萄牙语语料上达到72.6%的精确度。", "motivation": "解决医疗领域中基于性别的暴力事件漏报问题，特别是在初级医疗单位的电子病历记录中。", "method": "利用语义框架定义细粒度模式，在非结构化数据（电子病历的开放文本字段）中进行搜索，定义了8个模式并在巴西葡萄牙语的e-SUS APS语料库中进行验证。", "result": "方法有效识别暴力事件报告，精确度达到0.726，证实了方法的鲁棒性。", "conclusion": "该方法设计为透明、高效、低碳且语言无关的流程，可轻松适应其他健康监测场景，有助于在公共卫生系统中更广泛、道德和可解释地使用NLP技术。"}}
{"id": "2510.27009", "pdf": "https://arxiv.org/pdf/2510.27009", "abs": "https://arxiv.org/abs/2510.27009", "authors": ["Jared Junkin", "Samuel Nathanson"], "title": "Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "8 pages, NeurIPS 2025", "summary": "Language models are traditionally designed around causal masking. In domains\nwith spatial or relational structure, causal masking is often viewed as\ninappropriate, and sequential linearizations are instead used. Yet the question\nof whether it is viable to accept the information loss introduced by causal\nmasking on nonsequential data has received little direct study, in part because\nfew domains offer both spatial and sequential representations of the same\ndataset. In this work, we investigate this issue in the domain of chess, which\nnaturally supports both representations. We train language models with\nbidirectional and causal self-attention mechanisms on both spatial\n(board-based) and sequential (move-based) data. Our results show that models\ntrained on spatial board states - \\textit{even with causal masking} -\nconsistently achieve stronger playing strength than models trained on\nsequential data. While our experiments are conducted on chess, our results are\nmethodological and may have broader implications: applying causal masking to\nspatial data is a viable procedure for training unimodal LLMs on spatial data,\nand in some domains is even preferable to sequentialization.", "AI": {"tldr": "研究表明，在非顺序数据上使用因果掩码训练的语言模型在棋类游戏中表现优于基于序列数据的模型，挑战了传统观点，为空间数据的单模态LLM训练提供了新思路。", "motivation": "传统语言模型使用因果掩码处理顺序数据，但在具有空间或关系结构的领域，因果掩码被认为不合适。本研究旨在探索在非顺序数据上使用因果掩码是否可行，特别是在同时支持空间和序列表示的棋类领域。", "method": "在棋类游戏中训练具有双向和因果自注意力机制的语言模型，分别使用空间（棋盘状态）和序列（走棋顺序）两种数据表示形式进行对比实验。", "result": "结果显示，使用空间棋盘状态训练的语言模型（即使使用因果掩码）始终比基于序列数据训练的模型表现出更强的棋力。", "conclusion": "在空间数据上应用因果掩码是训练单模态LLM的可行方法，在某些领域甚至优于序列化处理，这一发现具有更广泛的方法论意义。"}}
{"id": "2510.26974", "pdf": "https://arxiv.org/pdf/2510.26974", "abs": "https://arxiv.org/abs/2510.26974", "authors": ["Jean-Philippe Corbeil", "Asma Ben Abacha", "Jerome Tremblay", "Phillip Swazinna", "Akila Jeeson Daniel", "Miguel Del-Agua", "Francois Beaulieu"], "title": "Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Clinical documentation increasingly uses automatic speech recognition and\nsummarization, yet converting conversations into actionable medical orders for\nElectronic Health Records remains unexplored. A solution to this problem can\nsignificantly reduce the documentation burden of clinicians and directly impact\ndownstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first\nchallenge on extracting medical orders from doctor-patient conversations. Six\nteams participated in the shared task and experimented with a broad range of\napproaches, and both closed- and open-weight large language models (LLMs). In\nthis paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,\nand participants' solutions.", "AI": {"tldr": "MEDIQA-OE 2025是首个从医患对话中提取医疗指令的共享任务挑战，旨在将对话转换为电子健康记录中的可执行医疗指令，以减轻临床医生的文档负担。", "motivation": "临床文档自动化虽然使用语音识别和摘要技术，但将对话转换为电子健康记录中的可执行医疗指令仍是未探索领域，这一问题的解决能显著减轻临床医生文档负担并直接影响患者护理。", "method": "组织MEDIQA-OE 2025共享任务，邀请6个团队参与，采用包括闭源和开源大语言模型在内的多种方法进行实验。", "result": "成功举办了首个医疗指令提取挑战赛，获得了6个团队的参与，探索了多种技术方案。", "conclusion": "该共享任务为从医患对话中提取医疗指令这一重要但未充分研究的领域提供了首个基准和解决方案探索，对改善临床文档工作流程具有重要意义。"}}
{"id": "2510.27042", "pdf": "https://arxiv.org/pdf/2510.27042", "abs": "https://arxiv.org/abs/2510.27042", "authors": ["Michael Kleinman", "Matthew Trager", "Alessandro Achille", "Wei Xia", "Stefano Soatto"], "title": "e1: Learning Adaptive Control of Reasoning Effort", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Increasing the thinking budget of AI models can significantly improve\naccuracy, but not all questions warrant the same amount of reasoning. Users may\nprefer to allocate different amounts of reasoning effort depending on how they\nvalue output quality versus latency and cost. To leverage this tradeoff\neffectively, users need fine-grained control over the amount of thinking used\nfor a particular query, but few approaches enable such control. Existing\nmethods require users to specify the absolute number of desired tokens, but\nthis requires knowing the difficulty of the problem beforehand to appropriately\nset the token budget for a query. To address these issues, we propose Adaptive\nEffort Control, a self-adaptive reinforcement learning method that trains\nmodels to use a user-specified fraction of tokens relative to the current\naverage chain-of-thought length for each query. This approach eliminates\ndataset- and phase-specific tuning while producing better cost-accuracy\ntradeoff curves compared to standard methods. Users can dynamically adjust the\ncost-accuracy trade-off through a continuous effort parameter specified at\ninference time. We observe that the model automatically learns to allocate\nresources proportionally to the task difficulty and, across model scales\nranging from 1.5B to 32B parameters, our approach enables approximately 3x\nreduction in chain-of-thought length while maintaining or improving performance\nrelative to the base model used for RL training.", "AI": {"tldr": "论文提出了自适应努力控制方法，通过强化学习训练模型根据用户指定的努力参数动态调整推理长度，在保持或提升性能的同时显著减少思维链长度。", "motivation": "当前AI模型缺乏对推理努力程度的细粒度控制，用户需要根据质量、延迟和成本的权衡来动态调整推理资源，但现有方法要求预先知道问题难度来设置token预算。", "method": "提出自适应努力控制方法，使用强化学习训练模型根据用户指定的相对努力参数（相对于当前平均思维链长度）来自适应调整推理token使用量。", "result": "在1.5B到32B参数规模的模型上，该方法能够将思维链长度减少约3倍，同时保持或提升相对于RL基础模型的性能，提供更好的成本-准确率权衡曲线。", "conclusion": "该方法消除了数据集和阶段特定的调优需求，用户可以通过连续的effort参数在推理时动态调整成本-准确率权衡，模型能自动按任务难度比例分配资源。"}}
{"id": "2510.27016", "pdf": "https://arxiv.org/pdf/2510.27016", "abs": "https://arxiv.org/abs/2510.27016", "authors": ["Jayden Serenari", "Stephen Lee"], "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "categories": ["cs.CL"], "comment": "Accepted to IEEE Big Data 2025", "summary": "With the increasing use of conversational AI systems, there is growing\nconcern over privacy leaks, especially when users share sensitive personal data\nin interactions with Large Language Models (LLMs). Conversations shared with\nthese models may contain Personally Identifiable Information (PII), which, if\nexposed, could lead to security breaches or identity theft. To address this\nchallenge, we present the Local Optimizations for Pseudonymization with\nSemantic Integrity Directed Entity Detection (LOPSIDED) framework, a\nsemantically-aware privacy agent designed to safeguard sensitive PII data when\nusing remote LLMs. Unlike prior work that often degrade response quality, our\napproach dynamically replaces sensitive PII entities in user prompts with\nsemantically consistent pseudonyms, preserving the contextual integrity of\nconversations. Once the model generates its response, the pseudonyms are\nautomatically depseudonymized, ensuring the user receives an accurate,\nprivacy-preserving output. We evaluate our approach using real-world\nconversations sourced from ShareGPT, which we further augment and annotate to\nassess whether named entities are contextually relevant to the model's\nresponse. Our results show that LOPSIDED reduces semantic utility errors by a\nfactor of 5 compared to baseline techniques, all while enhancing privacy.", "AI": {"tldr": "LOPSIDED框架是一种语义感知的隐私保护系统，通过动态替换用户提示中的敏感PII为语义一致的假名，在保护隐私的同时保持对话上下文完整性，相比基线技术将语义效用错误减少了5倍。", "motivation": "随着对话AI系统的广泛使用，用户在与大语言模型交互时可能分享敏感个人信息，存在隐私泄露风险，可能导致安全漏洞或身份盗窃。", "method": "提出LOPSIDED框架，动态替换敏感PII实体为语义一致的假名，保持对话上下文完整性，生成响应后自动进行假名还原。使用ShareGPT的真实对话数据进行评估和标注。", "result": "LOPSIDED相比基线技术将语义效用错误减少了5倍，同时增强了隐私保护。", "conclusion": "LOPSIDED框架有效解决了LLM使用中的隐私保护问题，在保持对话质量的同时显著提升了隐私安全性，为对话AI系统的隐私保护提供了实用解决方案。"}}
{"id": "2510.27051", "pdf": "https://arxiv.org/pdf/2510.27051", "abs": "https://arxiv.org/abs/2510.27051", "authors": ["Aaditya Shukla", "Sidney Knowles", "Meenakshi Madugula", "Dave Farris", "Ryan Angilly", "Santiago Pombo", "Anbang Xu", "Lu An", "Abhinav Balasubramanian", "Tan Yu", "Jiaxiang Ren", "Rama Akkiraju"], "title": "Adaptive Data Flywheel: Applying MAPE Control Loops to AI Agent Improvement", "categories": ["cs.AI", "cs.LG", "I.2.6; I.2.11; H.3.3"], "comment": "20 pages, 5 figures, 5 tables. Presents MAPE-K control loop\n  application to enterprise AI agent improvement with experimental validation\n  on NVIDIA's NVInfo AI system", "summary": "Enterprise AI agents must continuously adapt to maintain accuracy, reduce\nlatency, and remain aligned with user needs. We present a practical\nimplementation of a data flywheel in NVInfo AI, NVIDIA's Mixture-of-Experts\n(MoE) Knowledge Assistant serving over 30,000 employees. By operationalizing a\nMAPE-driven data flywheel, we built a closed-loop system that systematically\naddresses failures in retrieval-augmented generation (RAG) pipelines and\nenables continuous learning. Over a 3-month post-deployment period, we\nmonitored feedback and collected 495 negative samples. Analysis revealed two\nmajor failure modes: routing errors (5.25\\%) and query rephrasal errors\n(3.2\\%). Using NVIDIA NeMo microservices, we implemented targeted improvements\nthrough fine-tuning. For routing, we replaced a Llama 3.1 70B model with a\nfine-tuned 8B variant, achieving 96\\% accuracy, a 10x reduction in model size,\nand 70\\% latency improvement. For query rephrasal, fine-tuning yielded a 3.7\\%\ngain in accuracy and a 40\\% latency reduction. Our approach demonstrates how\nhuman-in-the-loop (HITL) feedback, when structured within a data flywheel,\ntransforms enterprise AI agents into self-improving systems. Key learnings\ninclude approaches to ensure agent robustness despite limited user feedback,\nnavigating privacy constraints, and executing staged rollouts in production.\nThis work offers a repeatable blueprint for building robust, adaptive\nenterprise AI agents capable of learning from real-world usage at scale.", "AI": {"tldr": "NVIDIA开发了基于MAPE驱动的数据飞轮系统NVInfo AI，通过分析用户反馈识别RAG管道中的主要错误类型，使用微调方法显著提升了模型性能和响应速度，为企业AI代理提供了可扩展的自改进框架。", "motivation": "企业AI代理需要持续适应以保持准确性、降低延迟并满足用户需求，需要建立一个能够从实际使用中学习并自我改进的系统。", "method": "采用MAPE驱动的数据飞轮构建闭环系统，收集495个负面样本分析失败模式，使用NVIDIA NeMo微服务进行针对性微调：用微调的8B模型替代70B路由模型，并对查询重述模型进行优化。", "result": "路由错误从5.25%改善到96%准确率，模型大小减少10倍，延迟提升70%；查询重述错误从3.2%改善到准确率提升3.7%，延迟降低40%。", "conclusion": "人机回环反馈结合数据飞轮架构可将企业AI代理转变为自改进系统，为构建能够在实际使用中大规模学习的稳健、自适应企业AI代理提供了可重复的蓝图。"}}
{"id": "2510.27017", "pdf": "https://arxiv.org/pdf/2510.27017", "abs": "https://arxiv.org/abs/2510.27017", "authors": ["Ayoub Hammal", "Pierre Zweigenbaum", "Caio Corro"], "title": "Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral", "categories": ["cs.CL"], "comment": null, "summary": "Several previous works concluded that the largest part of generation\ncapabilities of large language models (LLM) are learned (early) during\npre-training. However, LLMs still require further alignment to adhere to\ndownstream task requirements and stylistic preferences, among other desired\nproperties. As LLMs continue to scale in terms of size, the computational cost\nof alignment procedures increase prohibitively. In this work, we propose a\nnovel approach to circumvent these costs via proxy-based test-time alignment,\ni.e. using guidance from a small aligned model. Our approach can be described\nas token-specific cascading method, where the token-specific deferral rule is\nreduced to 0-1 knapsack problem. In this setting, we derive primal and dual\napproximations of the optimal deferral decision. We experimentally show the\nbenefits of our method both in task performance and speculative decoding speed.", "AI": {"tldr": "本文提出了一种基于代理的测试时对齐方法，使用小型对齐模型来指导大型语言模型，通过令牌级联和0-1背包问题优化，既提高了任务性能又加速了推理速度。", "motivation": "大型语言模型在预训练后仍需对齐以适应下游任务，但随着模型规模扩大，对齐过程的计算成本急剧增加，需要寻找更高效的对齐方法。", "method": "采用代理模型进行测试时对齐，提出令牌级联方法，将令牌特定的延迟决策简化为0-1背包问题，并推导出最优延迟决策的原始和对偶近似解。", "result": "实验证明该方法在任务性能和推测解码速度方面都有显著提升。", "conclusion": "该方法有效降低了大型语言模型对齐的计算成本，同时保持了性能，为大规模模型的高效对齐提供了可行方案。"}}
{"id": "2510.27094", "pdf": "https://arxiv.org/pdf/2510.27094", "abs": "https://arxiv.org/abs/2510.27094", "authors": ["Hamed Mahdavi", "Pouria Mahdavinia", "Alireza Farhadi", "Pegah Mohammadipour", "Samira Malek", "Majid Daliri", "Pedram Mohammadipour", "Alireza Hashemi", "Amir Khasahmadi", "Vasant Honavar"], "title": "CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning", "categories": ["cs.AI"], "comment": "Code/data: https://github.com/ref-grader/ref-grader,\n  https://huggingface.co/datasets/combviz/inoi", "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based\nOlympiad problems to solving most of the IMO 2025 problems, with leading\nsystems reportedly handling 5 of 6 problems. Given this progress, we assess how\nwell these models can grade proofs: detecting errors, judging their severity,\nand assigning fair scores beyond binary correctness. We study proof-analysis\ncapabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we\ngrade on a 1-4 scale with detailed error annotations, and on MathArena solution\nsets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models\ncan reliably flag incorrect (including subtly incorrect) solutions but exhibit\ncalibration gaps in how partial credit is assigned. To address this, we\nintroduce agentic workflows that extract and analyze reference solutions and\nautomatically derive problem-specific rubrics for a multi-step grading process.\nWe instantiate and compare different design choices for the grading workflows,\nand evaluate their trade-offs. Across our annotated corpus and MathArena, our\nproposed workflows achieve higher agreement with human grades and more\nconsistent handling of partial credit across metrics. We release all code,\ndata, and prompts/logs to facilitate future research.", "AI": {"tldr": "论文研究大型语言模型在数学证明评分方面的能力，开发了自动化评分工作流程来改进部分分数的分配一致性，并在多个数据集上验证了其与人类评分的一致性。", "motivation": "随着SOTA LLMs在解决奥林匹克数学问题上的显著进步，需要评估这些模型在证明评分方面的能力，包括错误检测、严重性判断和公平分数分配，而不仅仅是二元正确性判断。", "method": "使用90个Gemini 2.5 Pro生成的解决方案和MathArena的IMO/USAMO 2025解决方案集，采用1-4分和0-7分评分标准；引入基于智能体的工作流程，通过提取和分析参考解决方案来自动生成问题特定的评分标准。", "result": "模型能够可靠地标记错误解决方案（包括细微错误），但在部分分数分配上存在校准差距；提出的工作流程在人类评分一致性和部分分数处理一致性方面表现更好。", "conclusion": "自动化评分工作流程能够有效提高LLMs在证明评分方面的性能，特别是在部分分数分配的一致性方面，为未来研究提供了代码、数据和提示/日志资源。"}}
{"id": "2510.27037", "pdf": "https://arxiv.org/pdf/2510.27037", "abs": "https://arxiv.org/abs/2510.27037", "authors": ["Shang Wang"], "title": "Elastic Architecture Search for Efficient Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "comment": "ICME 2025", "summary": "As large pre-trained language models become increasingly critical to natural\nlanguage understanding (NLU) tasks, their substantial computational and memory\nrequirements have raised significant economic and environmental concerns.\nAddressing these challenges, this paper introduces the Elastic Language Model\n(ELM), a novel neural architecture search (NAS) method optimized for compact\nlanguage models. ELM extends existing NAS approaches by introducing a flexible\nsearch space with efficient transformer blocks and dynamic modules for\ndimension and head number adjustment. These innovations enhance the efficiency\nand flexibility of the search process, which facilitates more thorough and\neffective exploration of model architectures. We also introduce novel knowledge\ndistillation losses that preserve the unique characteristics of each block, in\norder to improve the discrimination between architectural choices during the\nsearch process. Experiments on masked language modeling and causal language\nmodeling tasks demonstrate that models discovered by ELM significantly\noutperform existing methods.", "AI": {"tldr": "ELM是一种新型神经架构搜索方法，专门针对紧凑语言模型优化，通过引入灵活搜索空间和动态模块调整，结合新颖的知识蒸馏损失，在语言建模任务中显著超越现有方法。", "motivation": "大型预训练语言模型在自然语言理解任务中计算和内存需求巨大，带来了经济和环境方面的担忧，需要开发更紧凑高效的模型。", "method": "提出弹性语言模型(ELM)，扩展现有NAS方法，引入包含高效transformer块和动态维度/头数调整模块的灵活搜索空间，以及保持各块独特特征的知识蒸馏损失。", "result": "在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。", "conclusion": "ELM通过创新的架构搜索和知识蒸馏技术，有效解决了大型语言模型的计算和内存效率问题，为开发紧凑高效的语言模型提供了有效途径。"}}
{"id": "2510.27176", "pdf": "https://arxiv.org/pdf/2510.27176", "abs": "https://arxiv.org/abs/2510.27176", "authors": ["Pouya Hamadanian", "Pantea Karimi", "Arash Nasr-Esfahany", "Kimia Noorbakhsh", "Joseph Chandler", "Ali ParandehGheibi", "Mohammad Alizadeh", "Hari Balakrishnan"], "title": "Glia: A Human-Inspired AI for Automated Systems Design and Optimization", "categories": ["cs.AI", "cs.CL", "cs.DC"], "comment": null, "summary": "Can an AI autonomously design mechanisms for computer systems on par with the\ncreativity and reasoning of human experts? We present Glia, an AI architecture\nfor networked systems design that uses large language models (LLMs) in a\nhuman-inspired, multi-agent workflow. Each agent specializes in reasoning,\nexperimentation, and analysis, collaborating through an evaluation framework\nthat grounds abstract reasoning in empirical feedback. Unlike prior\nML-for-systems methods that optimize black-box policies, Glia generates\ninterpretable designs and exposes its reasoning process. When applied to a\ndistributed GPU cluster for LLM inference, it produces new algorithms for\nrequest routing, scheduling, and auto-scaling that perform at human-expert\nlevels in significantly less time, while yielding novel insights into workload\nbehavior. Our results suggest that by combining reasoning LLMs with structured\nexperimentation, an AI can produce creative and understandable designs for\ncomplex systems problems.", "AI": {"tldr": "Glia是一个基于多智能体LLM架构的AI系统，能够自主设计计算机系统机制，在分布式GPU集群的LLM推理场景中，其设计的请求路由、调度和自动扩展算法达到了人类专家水平，且具有可解释性。", "motivation": "探索AI是否能够像人类专家一样具有创造性和推理能力，自主设计计算机系统机制，超越传统的黑盒优化方法。", "method": "使用大型语言模型构建多智能体工作流，每个智能体专门负责推理、实验和分析，通过评估框架将抽象推理与实证反馈相结合，生成可解释的设计方案。", "result": "在分布式GPU集群的LLM推理应用中，Glia设计的新算法在性能上达到人类专家水平，且耗时显著减少，同时提供了对工作负载行为的新见解。", "conclusion": "通过将推理型LLM与结构化实验相结合，AI能够为复杂系统问题产生创造性且易于理解的设计方案。"}}
{"id": "2510.27038", "pdf": "https://arxiv.org/pdf/2510.27038", "abs": "https://arxiv.org/abs/2510.27038", "authors": ["Fatima Adam Muhammad", "Shamsuddeen Muhammad Hassan", "Isa Inuwa-Dutse"], "title": "Dataset Creation and Baseline Models for Sexism Detection in Hausa", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 1 figure, 4 tables", "summary": "Sexism reinforces gender inequality and social exclusion by perpetuating\nstereotypes, bias, and discriminatory norms. Noting how online platforms enable\nvarious forms of sexism to thrive, there is a growing need for effective sexism\ndetection and mitigation strategies. While computational approaches to sexism\ndetection are widespread in high-resource languages, progress remains limited\nin low-resource languages where limited linguistic resources and cultural\ndifferences affect how sexism is expressed and perceived. This study introduces\nthe first Hausa sexism detection dataset, developed through community\nengagement, qualitative coding, and data augmentation. For cultural nuances and\nlinguistic representation, we conducted a two-stage user study (n=66) involving\nnative speakers to explore how sexism is defined and articulated in everyday\ndiscourse. We further experiment with both traditional machine learning\nclassifiers and pre-trained multilingual language models and evaluating the\neffectiveness few-shot learning in detecting sexism in Hausa. Our findings\nhighlight challenges in capturing cultural nuance, particularly with\nclarification-seeking and idiomatic expressions, and reveal a tendency for many\nfalse positives in such cases.", "AI": {"tldr": "本研究创建了首个豪萨语性别歧视检测数据集，通过社区参与和定性编码开发，并探索了传统机器学习与多语言预训练模型在豪萨语性别歧视检测中的效果，发现文化细微差别和习语表达带来挑战。", "motivation": "在线平台助长了各种形式的性别歧视，但现有计算检测方法主要集中在高资源语言，低资源语言如豪萨语由于语言资源有限和文化差异，性别歧视检测进展缓慢。", "method": "通过两阶段用户研究（n=66）让母语者参与定义和表达性别歧视，创建豪萨语数据集；使用传统机器学习分类器和预训练多语言模型进行实验，评估少样本学习效果。", "result": "研究发现捕捉文化细微差别存在挑战，特别是在寻求澄清和习语表达方面，这些情况下容易出现许多误报。", "conclusion": "豪萨语性别歧视检测需要特别关注文化语境和语言表达特点，现有计算方法在处理低资源语言的性别歧视表达时仍需改进。"}}
{"id": "2510.27194", "pdf": "https://arxiv.org/pdf/2510.27194", "abs": "https://arxiv.org/abs/2510.27194", "authors": ["Vahid Salehi", "Josef Vilsmeier", "Shirui Wang"], "title": "From product to system network challenges in system of systems lifecycle management", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Today, products are no longer isolated artifacts, but nodes in networked\nsystems. This means that traditional, linearly conceived life cycle models are\nreaching their limits: Interoperability across disciplines, variant and\nconfiguration management, traceability, and governance across organizational\nboundaries are becoming key factors. This collective contribution classifies\nthe state of the art and proposes a practical frame of reference for SoS\nlifecycle management, model-based systems engineering (MBSE) as the semantic\nbackbone, product lifecycle management (PLM) as the governance and\nconfiguration level, CAD-CAE as model-derived domains, and digital thread and\ndigital twin as continuous feedback. Based on current literature and industry\nexperience, mobility, healthcare, and the public sector, we identify four\nprinciples: (1) referenced architecture and data models, (2) end-to-end\nconfiguration sovereignty instead of tool silos, (3) curated models with clear\nreview gates, and (4) measurable value contributions along time, quality, cost,\nand sustainability. A three-step roadmap shows the transition from product- to\nnetwork- centric development: piloting with reference architecture, scaling\nacross variant and supply chain spaces, organizational anchoring (roles,\ntraining, compliance). The results are increased change robustness, shorter\nthroughput times, improved reuse, and informed sustainability decisions. This\narticle is aimed at decision-makers and practitioners who want to make\ncomplexity manageable and design SoS value streams to be scalable.", "AI": {"tldr": "该论文提出了一个面向系统之系统（SoS）的现代生命周期管理框架，整合MBSE、PLM和CAD-CAE等技术，通过四个核心原则和三阶段路线图实现从产品中心到网络中心开发的转型。", "motivation": "传统线性生命周期模型在处理网络化系统中的跨学科互操作性、变体配置管理、可追溯性和跨组织治理等方面存在局限，需要新的管理方法。", "method": "基于文献综述和行业经验，提出包含四个原则的实践参考框架：引用架构和数据模型、端到端配置主权、有管理的模型审查、可衡量的价值贡献，并制定三阶段实施路线图。", "result": "实现了变更鲁棒性提升、吞吐时间缩短、重用性改善和可持续性决策优化等效果。", "conclusion": "该框架为决策者和实践者提供了管理复杂性和设计可扩展SoS价值流的有效方法，适用于移动出行、医疗保健和公共部门等领域。"}}
{"id": "2510.27045", "pdf": "https://arxiv.org/pdf/2510.27045", "abs": "https://arxiv.org/abs/2510.27045", "authors": ["Siyu Duan"], "title": "Quantitative Intertextuality from the Digital Humanities Perspective: A Survey", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "The connection between texts is referred to as intertextuality in literary\ntheory, which served as an important theoretical basis in many digital\nhumanities studies. Over the past decade, advancements in natural language\nprocessing have ushered intertextuality studies into the quantitative age.\nLarge-scale intertextuality research based on cutting-edge methods has\ncontinuously emerged. This paper provides a roadmap for quantitative\nintertextuality studies, summarizing their data, methods, and applications.\nDrawing on data from multiple languages and topics, this survey reviews methods\nfrom statistics to deep learning. It also summarizes their applications in\nhumanities and social sciences research and the associated platform tools.\nDriven by advances in computer technology, more precise, diverse, and\nlarge-scale intertext studies can be anticipated. Intertextuality holds promise\nfor broader application in interdisciplinary research bridging AI and the\nhumanities.", "AI": {"tldr": "本文提供了定量互文性研究的路线图，总结了该领域的数据、方法和应用，涵盖从统计学到深度学习的多种方法，并展望了在AI与人文学科交叉研究中的更广泛应用前景。", "motivation": "随着自然语言处理技术的发展，互文性研究进入定量时代，需要系统总结大规模互文性研究的数据、方法和应用现状。", "method": "基于多语言和多主题数据，综述从统计方法到深度学习的各种技术方法，并总结相关平台工具。", "result": "总结了定量互文性研究的最新进展和方法体系，展示了该领域在人文社科研究中的具体应用。", "conclusion": "计算机技术的进步将推动更精确、多样化和大规模的互文性研究，互文性在AI与人文学科的跨学科研究中具有广阔的应用前景。"}}
{"id": "2510.27206", "pdf": "https://arxiv.org/pdf/2510.27206", "abs": "https://arxiv.org/abs/2510.27206", "authors": ["Kounianhua Du", "Jianxing Liu", "Kangning Zhang", "Wenxiang Jiao", "Yuan Lu", "Jiarui Jin", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "title": "Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of large language models (LLMs) has intensified the\ndemand for effective personalization techniques that can adapt model behavior\nto individual user preferences. Despite the non-parametric methods utilizing\nthe in-context learning ability of LLMs, recent parametric adaptation methods,\nincluding personalized parameter-efficient fine-tuning and reward modeling\nemerge. However, these methods face limitations in handling dynamic user\npatterns and high data sparsity scenarios, due to low adaptability and data\nefficiency. To address these challenges, we propose a fine-grained and\ninstance-tailored steering framework that dynamically generates sample-level\ninterference vectors from user data and injects them into the model's forward\npass for personalized adaptation. Our approach introduces two key technical\ninnovations: a fine-grained steering component that captures nuanced signals by\nhooking activations from attention and MLP layers, and an input-aware\naggregation module that synthesizes these signals into contextually relevant\nenhancements. The method demonstrates high flexibility and data efficiency,\nexcelling in fast-changing distribution and high data sparsity scenarios. In\naddition, the proposed method is orthogonal to existing methods and operates as\na plug-in component compatible with different personalization techniques.\nExtensive experiments across diverse scenarios--including short-to-long text\ngeneration, and web function calling--validate the effectiveness and\ncompatibility of our approach. Results show that our method significantly\nenhances personalization performance in fast-shifting environments while\nmaintaining robustness across varying interaction modes and context lengths.\nImplementation is available at https://github.com/KounianhuaDu/Fints.", "AI": {"tldr": "提出了一种细粒度的实例定制化引导框架，通过动态生成样本级干扰向量并注入模型前向传播来实现个性化适配，解决了动态用户模式和高数据稀疏性场景下的挑战。", "motivation": "现有参数化适配方法在处理动态用户模式和高数据稀疏性场景时存在适应性差和数据效率低的问题，需要更有效的个性化技术来适应大语言模型的快速发展。", "method": "采用细粒度引导组件捕获注意力层和MLP层的细微信号，结合输入感知聚合模块将这些信号合成为上下文相关的增强向量，作为插件组件与现有个性化技术兼容。", "result": "在多样化场景（短长文本生成、网络函数调用）的广泛实验中验证了方法的有效性，显著提升了快速变化环境中的个性化性能，同时保持在不同交互模式和上下文长度下的鲁棒性。", "conclusion": "该方法具有高度灵活性和数据效率，能够有效应对快速变化的分布和高数据稀疏性场景，且与现有方法正交，可作为兼容不同个性化技术的插件组件。"}}
{"id": "2510.27049", "pdf": "https://arxiv.org/pdf/2510.27049", "abs": "https://arxiv.org/abs/2510.27049", "authors": ["Ponrawee Prasertsom", "Andrea Silvi", "Jennifer Culbertson", "Moa Johansson", "Devdatt Dubhashi", "Kenny Smith"], "title": "Recursive numeral systems are highly regular and easy to process", "categories": ["cs.CL", "cs.FL"], "comment": null, "summary": "Previous work has argued that recursive numeral systems optimise the\ntrade-off between lexicon size and average morphosyntatic complexity (Deni\\'c\nand Szymanik, 2024). However, showing that only natural-language-like systems\noptimise this tradeoff has proven elusive, and the existing solution has relied\non ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).\nHere, we argue that this issue arises because the proposed trade-off has\nneglected regularity, a crucial aspect of complexity central to human grammars\nin general. Drawing on the Minimum Description Length (MDL) approach, we\npropose that recursive numeral systems are better viewed as efficient with\nregard to their regularity and processing complexity. We show that our\nMDL-based measures of regularity and processing complexity better capture the\nkey differences between attested, natural systems and unattested but possible\nones, including \"optimal\" recursive numeral systems from previous work, and\nthat the ad-hoc constraints from previous literature naturally follow from\nregularity. Our approach highlights the need to incorporate regularity across\nsets of forms in studies that attempt to measure and explain optimality in\nlanguage.", "AI": {"tldr": "该论文提出基于最小描述长度(MDL)的新方法来评估递归数字系统的最优性，强调规律性在语言复杂性中的核心作用，解决了先前研究中需要人为约束来排除非自然系统的问题。", "motivation": "先前研究认为递归数字系统在词典大小和平均形态句法复杂性之间达到最优权衡，但需要人为约束来排除非自然系统，这表明现有方法存在不足。", "method": "采用最小描述长度(MDL)方法，提出基于规律性和处理复杂性的新衡量标准，重新评估递归数字系统的最优性。", "result": "MDL方法能更好地区分自然存在的系统与可能但未出现的系统(包括先前研究中的\"最优\"系统)，且先前文献中的人为约束可以从规律性中自然推导出来。", "conclusion": "研究强调了在语言最优性研究中需要纳入形式集合的规律性，MDL方法为理解语言系统的效率和最优性提供了更全面的框架。"}}
{"id": "2510.27210", "pdf": "https://arxiv.org/pdf/2510.27210", "abs": "https://arxiv.org/abs/2510.27210", "authors": ["Tao Liu", "Chongyu Wang", "Rongjie Li", "Yingchen Yu", "Xuming He", "Bai Song"], "title": "GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation", "categories": ["cs.AI", "cs.CV"], "comment": "Published in NeurIPS 2025", "summary": "While Multimodal Large Language Models (MLLMs) have advanced GUI navigation\nagents, current approaches face limitations in cross-domain generalization and\neffective history utilization. We present a reasoning-enhanced framework that\nsystematically integrates structured reasoning, action prediction, and history\nsummarization. The structured reasoning component generates coherent\nChain-of-Thought analyses combining progress estimation and decision reasoning,\nwhich inform both immediate action predictions and compact history summaries\nfor future steps. Based on this framework, we train a GUI agent,\n\\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled\ntrajectories and reinforcement learning with Group Relative Policy Optimization\n(GRPO). This framework employs specialized rewards, including a history-aware\nobjective, directly linking summary quality to subsequent action performance.\nComprehensive evaluations on standard benchmarks demonstrate state-of-the-art\nresults under identical training data conditions, with particularly strong\nperformance in out-of-domain scenarios. These findings validate our framework's\nability to maintain robust reasoning and generalization across diverse GUI\nnavigation tasks. Code is available at https://leon022.github.io/GUI-Rise.", "AI": {"tldr": "提出了GUI-Rise框架，通过结构化推理、动作预测和历史摘要增强MLLM在GUI导航中的跨域泛化能力，在标准基准测试中达到最先进性能", "motivation": "当前多模态大语言模型在GUI导航代理中存在跨域泛化能力不足和历史信息利用效率低的问题", "method": "开发了推理增强框架，包含结构化推理链、动作预测和历史摘要组件，通过监督微调伪标注轨迹和GRPO强化学习训练GUI-Rise代理", "result": "在相同训练数据条件下实现了最先进的性能表现，在域外场景中表现尤为突出", "conclusion": "该框架能够保持强大的推理能力和跨不同GUI导航任务的泛化性能，验证了方法的有效性"}}
{"id": "2510.27052", "pdf": "https://arxiv.org/pdf/2510.27052", "abs": "https://arxiv.org/abs/2510.27052", "authors": ["Ashley Lewis", "Andrew Perrault", "Eric Fosler-Lussier", "Michael White"], "title": "VISTA Score: Verification In Sequential Turn-based Assessment", "categories": ["cs.CL"], "comment": null, "summary": "Hallucination--defined here as generating statements unsupported or\ncontradicted by available evidence or conversational context--remains a major\nobstacle to deploying conversational AI systems in settings that demand factual\nreliability. Existing metrics either evaluate isolated responses or treat\nunverifiable content as errors, limiting their use for multi-turn dialogue. We\nintroduce VISTA (Verification In Sequential Turn-based Assessment), a framework\nfor evaluating conversational factuality through claim-level verification and\nsequential consistency tracking. VISTA decomposes each assistant turn into\natomic factual claims, verifies them against trusted sources and dialogue\nhistory, and categorizes unverifiable statements (subjective, contradicted,\nlacking evidence, or abstaining). Across eight large language models and four\ndialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA\nsubstantially improves hallucination detection over FACTSCORE and LLM-as-Judge\nbaselines. Human evaluation confirms that VISTA's decomposition improves\nannotator agreement and reveals inconsistencies in existing benchmarks. By\nmodeling factuality as a dynamic property of conversation, VISTA offers a more\ntransparent, human-aligned measure of truthfulness in dialogue systems.", "AI": {"tldr": "VISTA是一个评估对话系统事实性的新框架，通过声明级验证和序列一致性追踪来检测多轮对话中的幻觉问题，相比现有方法在多个基准测试中表现更优。", "motivation": "现有评估指标要么评估孤立响应，要么将不可验证内容视为错误，限制了在多轮对话中的应用。幻觉问题阻碍了对话AI系统在需要事实可靠性的场景中的部署。", "method": "VISTA框架将每个助手回复分解为原子事实声明，根据可信来源和对话历史进行验证，并将不可验证语句分类为主观、矛盾、缺乏证据或弃权等类别。", "result": "在8个大语言模型和4个对话事实性基准测试中，VISTA在幻觉检测方面显著优于FACTSCORE和LLM-as-Judge基线方法。人类评估证实VISTA的分解方法提高了标注者一致性。", "conclusion": "通过将事实性建模为对话的动态属性，VISTA提供了一个更透明、更符合人类认知的对话系统真实性衡量标准。"}}
{"id": "2510.27329", "pdf": "https://arxiv.org/pdf/2510.27329", "abs": "https://arxiv.org/abs/2510.27329", "authors": ["Kristina Levina", "Nikolaos Pappas", "Athanasios Karapantelakis", "Aneta Vulgarakis Feljan", "Jendrik Seipp"], "title": "Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines", "categories": ["cs.AI"], "comment": null, "summary": "Reward machines (RMs) inform reinforcement learning agents about the reward\nstructure of the environment. This is particularly advantageous for complex\nnon-Markovian tasks because agents with access to RMs can learn more\nefficiently from fewer samples. However, learning with RMs is ill-suited for\nlong-horizon problems in which a set of subtasks can be executed in any order.\nIn such cases, the amount of information to learn increases exponentially with\nthe number of unordered subtasks. In this work, we address this limitation by\nintroducing three generalisations of RMs: (1) Numeric RMs allow users to\nexpress complex tasks in a compact form. (2) In Agenda RMs, states are\nassociated with an agenda that tracks the remaining subtasks to complete. (3)\nCoupled RMs have coupled states associated with each subtask in the agenda.\nFurthermore, we introduce a new compositional learning algorithm that leverages\ncoupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM\nscales better than state-of-the-art RM algorithms for long-horizon problems\nwith unordered subtasks.", "AI": {"tldr": "本文提出了三种奖励机器(RM)的泛化形式来改进长时域无序子任务的学习效率，并引入了基于耦合RM的新组合学习算法CoRM，实验证明其在处理无序子任务时比现有RM算法更具可扩展性。", "motivation": "传统奖励机器在处理无序子任务的长时域问题时存在局限性，当子任务可以任意顺序执行时，需要学习的信息量会随无序子任务数量呈指数级增长。", "method": "提出了三种RM泛化形式：(1)数值RM用紧凑形式表达复杂任务；(2)议程RM用议程跟踪剩余子任务；(3)耦合RM将状态与议程中的每个子任务耦合。并开发了基于耦合RM的组合学习算法CoRM(Q-learning with coupled RMs)。", "result": "实验结果表明，CoRM在处理具有无序子任务的长时域问题时，比最先进的RM算法具有更好的可扩展性。", "conclusion": "通过引入数值RM、议程RM和耦合RM这三种泛化形式以及CoRM算法，有效解决了传统奖励机器在处理无序子任务长时域问题时的指数级复杂度问题，提升了学习效率。"}}
{"id": "2510.27054", "pdf": "https://arxiv.org/pdf/2510.27054", "abs": "https://arxiv.org/abs/2510.27054", "authors": ["Xiaofan Guo", "Yaxuan Luan", "Yue Kang", "Xiangchen Song", "Jinxu Guo"], "title": "LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the issues of insufficient coverage, unstable results,\nand limited reliability in retrieval-augmented generation under complex\nknowledge environments, and proposes a confidence control method that\nintegrates multi-granularity memory indexing with uncertainty estimation. The\nmethod builds a hierarchical memory structure that divides knowledge\nrepresentations into different levels of granularity, enabling dynamic indexing\nand retrieval from local details to global context, and thus establishing\ncloser semantic connections between retrieval and generation. On this basis, an\nuncertainty estimation mechanism is introduced to explicitly constrain and\nfilter low-confidence paths during the generation process, allowing the model\nto maintain information coverage while effectively suppressing noise and false\ncontent. The overall optimization objective consists of generation loss,\nentropy constraints, and variance regularization, forming a unified confidence\ncontrol framework. In the experiments, comprehensive sensitivity tests and\ncomparative analyses were designed, covering hyperparameters, environmental\nconditions, and data structures, to verify the stability and robustness of the\nproposed method across different scenarios. The results show that the method\nachieves superior performance over existing models in QA accuracy, retrieval\nrecall, ranking quality, and factual consistency, demonstrating the\neffectiveness of combining multi-granularity indexing with confidence control.\nThis study not only provides a new technical pathway for retrieval-augmented\ngeneration but also offers practical evidence for improving the reliability and\ncontrollability of large models in complex contexts.", "AI": {"tldr": "提出一种结合多粒度记忆索引和不确定性估计的置信度控制方法，解决复杂知识环境下检索增强生成的覆盖率不足、结果不稳定和可靠性有限的问题。", "motivation": "解决检索增强生成在复杂知识环境中存在的覆盖率不足、结果不稳定和可靠性有限的问题。", "method": "构建分层记忆结构，将知识表示分为不同粒度级别，实现从局部细节到全局上下文的动态索引检索；引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径；整体优化目标包括生成损失、熵约束和方差正则化。", "result": "在QA准确性、检索召回率、排序质量和事实一致性方面优于现有模型，证明了多粒度索引与置信度控制结合的有效性。", "conclusion": "该方法为检索增强生成提供了新的技术路径，并为提高大模型在复杂环境中的可靠性和可控性提供了实践证据。"}}
{"id": "2510.27343", "pdf": "https://arxiv.org/pdf/2510.27343", "abs": "https://arxiv.org/abs/2510.27343", "authors": ["Ali Norouzifar", "Wil van der Aalst"], "title": "Discriminative Rule Learning for Outcome-Guided Process Model Discovery", "categories": ["cs.AI"], "comment": "The paper will be published as part of the CoopIS 2025 conference\n  proceedings", "summary": "Event logs extracted from information systems offer a rich foundation for\nunderstanding and improving business processes. In many real-world\napplications, it is possible to distinguish between desirable and undesirable\nprocess executions, where desirable traces reflect efficient or compliant\nbehavior, and undesirable ones may involve inefficiencies, rule violations,\ndelays, or resource waste. This distinction presents an opportunity to guide\nprocess discovery in a more outcome-aware manner. Discovering a single process\nmodel without considering outcomes can yield representations poorly suited for\nconformance checking and performance analysis, as they fail to capture critical\nbehavioral differences. Moreover, prioritizing one behavior over the other may\nobscure structural distinctions vital for understanding process outcomes. By\nlearning interpretable discriminative rules over control-flow features, we\ngroup traces with similar desirability profiles and apply process discovery\nseparately within each group. This results in focused and interpretable models\nthat reveal the drivers of both desirable and undesirable executions. The\napproach is implemented as a publicly available tool and it is evaluated on\nmultiple real-life event logs, demonstrating its effectiveness in isolating and\nvisualizing critical process patterns.", "AI": {"tldr": "该论文提出了一种基于事件日志区分理想与不理想流程执行的方法，通过可解释的判别规则对流程轨迹进行分组，为每组分别发现流程模型，从而揭示影响流程结果的关键行为模式。", "motivation": "传统流程发现方法不考虑执行结果差异，导致模型无法捕捉关键行为区别，不适合一致性检查和性能分析。现实中存在理想（高效合规）和不理想（低效违规）的流程执行，这为结果导向的流程发现提供了机会。", "method": "通过学习控制流特征上的可解释判别规则，将具有相似理想性特征的轨迹分组，然后在每个组内分别应用流程发现技术。", "result": "该方法实现了公开可用的工具，并在多个真实事件日志上进行了评估，证明其能够有效隔离和可视化关键流程模式。", "conclusion": "该方法能够产生聚焦且可解释的模型，揭示理想和不理想流程执行的驱动因素，为流程改进提供更有针对性的见解。"}}
{"id": "2510.27055", "pdf": "https://arxiv.org/pdf/2510.27055", "abs": "https://arxiv.org/abs/2510.27055", "authors": ["Michał Zawalski", "Meriem Boubdir", "Klaudia Bałazy", "Besmira Nushi", "Pablo Ribalta"], "title": "Detecting Data Contamination in LLMs via In-Context Learning", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "We present Contamination Detection via Context (CoDeC), a practical and\naccurate method to detect and quantify training data contamination in large\nlanguage models. CoDeC distinguishes between data memorized during training and\ndata outside the training distribution by measuring how in-context learning\naffects model performance. We find that in-context examples typically boost\nconfidence for unseen datasets but may reduce it when the dataset was part of\ntraining, due to disrupted memorization patterns. Experiments show that CoDeC\nproduces interpretable contamination scores that clearly separate seen and\nunseen datasets, and reveals strong evidence of memorization in open-weight\nmodels with undisclosed training corpora. The method is simple, automated, and\nboth model- and dataset-agnostic, making it easy to integrate with benchmark\nevaluations.", "AI": {"tldr": "CoDeC是一种通过上下文学习检测大语言模型训练数据污染的方法，能够准确区分训练数据记忆和未见数据，提供可解释的污染分数。", "motivation": "需要检测和量化大语言模型中训练数据污染的问题，特别是对于训练语料未公开的开源模型，存在数据记忆和污染的风险。", "method": "通过测量上下文学习对模型性能的影响来检测污染：上下文示例通常能提升未见数据集的置信度，但对于训练数据会因记忆模式被破坏而降低置信度。", "result": "实验显示CoDeC能产生可解释的污染分数，清晰区分已见和未见数据集，并在未公开训练语料的开源模型中发现了强记忆证据。", "conclusion": "CoDeC是一种简单、自动化、模型和数据集无关的实用方法，易于与基准评估集成，能有效检测训练数据污染。"}}
{"id": "2510.27353", "pdf": "https://arxiv.org/pdf/2510.27353", "abs": "https://arxiv.org/abs/2510.27353", "authors": ["Julien Herrmann", "Guillaume Pallez"], "title": "An In-depth Study of LLM Contributions to the Bin Packing Problem", "categories": ["cs.AI", "I.2.8; F.2.2"], "comment": "15 pages, 13 figures", "summary": "Recent studies have suggested that Large Language Models (LLMs) could provide\ninteresting ideas contributing to mathematical discovery. This claim was\nmotivated by reports that LLM-based genetic algorithms produced heuristics\noffering new insights into the online bin packing problem under uniform and\nWeibull distributions. In this work, we reassess this claim through a detailed\nanalysis of the heuristics produced by LLMs, examining both their behavior and\ninterpretability. Despite being human-readable, these heuristics remain largely\nopaque even to domain experts. Building on this analysis, we propose a new\nclass of algorithms tailored to these specific bin packing instances. The\nderived algorithms are significantly simpler, more efficient, more\ninterpretable, and more generalizable, suggesting that the considered instances\nare themselves relatively simple. We then discuss the limitations of the claim\nregarding LLMs' contribution to this problem, which appears to rest on the\nmistaken assumption that the instances had previously been studied. Our\nfindings instead emphasize the need for rigorous validation and\ncontextualization when assessing the scientific value of LLM-generated outputs.", "AI": {"tldr": "本论文重新评估了LLM在数学发现中的贡献，通过分析LLM生成的装箱问题启发式算法，发现其虽可读但不具可解释性，并提出了更简单高效的替代算法，强调了对LLM生成内容进行严格验证的必要性。", "motivation": "重新评估LLM在数学发现中的贡献主张，特别是针对之前报道的LLM基于遗传算法为均匀分布和Weibull分布下的在线装箱问题产生新启发式算法的说法", "method": "对LLM生成的启发式算法进行详细分析，包括行为分析和可解释性评估，并针对这些特定装箱问题实例设计新的算法类别", "result": "发现LLM生成的启发式算法虽然人类可读但对领域专家仍然不透明；提出的新算法更简单、高效、可解释且更具泛化性；证明所考虑的装箱问题实例本身相对简单", "conclusion": "LLM对此问题的贡献主张存在局限性，基于错误假设；强调在评估LLM生成输出的科学价值时需要严格的验证和情境化分析"}}
{"id": "2510.27077", "pdf": "https://arxiv.org/pdf/2510.27077", "abs": "https://arxiv.org/abs/2510.27077", "authors": ["Jiasen Zheng", "Huajun Zhang", "Xu Yan", "Ran Hao", "Chong Peng"], "title": "Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the limitations of large-scale language models in safety\nalignment and robustness by proposing a fine-tuning method that combines\ncontrastive distillation with noise-robust training. The method freezes the\nbackbone model and transfers the knowledge boundaries of the teacher model to\nthe student model through distillation, thereby improving semantic consistency\nand alignment accuracy. At the same time, noise perturbations and robust\noptimization constraints are introduced during training to ensure that the\nmodel maintains stable predictive outputs under noisy and uncertain inputs. The\noverall framework consists of distillation loss, robustness loss, and a\nregularization term, forming a unified optimization objective that balances\nalignment ability with resistance to interference. To systematically validate\nits effectiveness, the study designs experiments from multiple perspectives,\nincluding distillation weight sensitivity, stability analysis under computation\nbudgets and mixed-precision environments, and the impact of data noise and\ndistribution shifts on model performance. Results show that the method\nsignificantly outperforms existing baselines in knowledge transfer, robustness,\nand overall safety, achieving the best performance across several key metrics.\nThis work not only enriches the theoretical system of parameter-efficient\nfine-tuning but also provides a new solution for building safer and more\ntrustworthy alignment mechanisms.", "AI": {"tldr": "提出了一种结合对比蒸馏和噪声鲁棒训练的微调方法，通过冻结骨干模型并引入噪声扰动和鲁棒优化约束，显著提升大语言模型的安全对齐能力和鲁棒性。", "motivation": "解决大语言模型在安全对齐和鲁棒性方面的局限性，现有方法在噪声和不确定输入下表现不稳定，需要提升模型的语义一致性和对齐精度。", "method": "采用对比蒸馏技术将教师模型的知识边界传递给学生模型，同时引入噪声扰动和鲁棒优化约束。整体框架包含蒸馏损失、鲁棒性损失和正则化项，形成统一的优化目标。", "result": "在知识迁移、鲁棒性和整体安全性方面显著优于现有基线方法，在多个关键指标上达到最佳性能。", "conclusion": "该方法不仅丰富了参数高效微调的理论体系，还为构建更安全、更可信的对齐机制提供了新的解决方案。"}}
{"id": "2510.27363", "pdf": "https://arxiv.org/pdf/2510.27363", "abs": "https://arxiv.org/abs/2510.27363", "authors": ["Mengjie Deng", "Guanting Dong", "Zhicheng Dou"], "title": "ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use", "categories": ["cs.AI"], "comment": null, "summary": "Recently, large language models (LLMs) have demonstrated remarkable\nproblem-solving capabilities by autonomously integrating with external tools\nfor collaborative reasoning. However, due to the inherently complex and diverse\nnature of multimodal information, enabling multimodal large language models\n(MLLMs) to flexibly and efficiently utilize external tools during reasoning\nremains an underexplored challenge. In this work, we introduce ToolScope, an\nagentic framework designed to unify global planning with local multimodal\nperception, adopting a specialized Perceive tool to mitigates visual context\ndegradation in long-horizon VQA task. ToolScope comprises three primary\ncomponents: the Global Navigator, the Agentic Executor, and the Response\nSynthesizer. The Global Navigator functions as a \"telescope\", offering\nhigh-level strategic guidance. The Agentic Executor operates iteratively to\naugment MLLM with local perception through the integration of external\ntools-Search, Code, and Perceive. Finally, the Response Synthesizer\nconsolidates and organizes the reasoning process into a coherent, user-friendly\noutput. We evaluate ToolScope on four VQA benchmarks across diverse domains,\nincluding VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong\ngeneralization capabilities, achieving an average performance improvement of up\nto +6.69% across all datasets.", "AI": {"tldr": "ToolScope是一个多模态大语言模型代理框架，通过全局导航和局部感知的统一，在长视野VQA任务中有效利用外部工具，平均性能提升6.69%。", "motivation": "当前多模态大语言模型在复杂多模态信息处理中，如何灵活高效地利用外部工具进行推理仍是一个未充分探索的挑战。", "method": "提出ToolScope框架，包含三个核心组件：全局导航器（战略指导）、代理执行器（集成Search、Code、Perceive工具进行迭代感知）、响应合成器（整合推理过程）。", "result": "在VQA 2.0、ScienceQA、MAT-Search和MathVista四个基准测试中表现出强大的泛化能力，平均性能提升高达6.69%。", "conclusion": "ToolScope通过统一全局规划和局部多模态感知，有效解决了长视野VQA任务中的视觉上下文退化问题，为MLLMs的工具利用提供了有效解决方案。"}}
{"id": "2510.27087", "pdf": "https://arxiv.org/pdf/2510.27087", "abs": "https://arxiv.org/abs/2510.27087", "authors": ["Adel Khorramrouz", "Sharon Levy"], "title": "Characterizing Selective Refusal Bias in Large Language Models", "categories": ["cs.CL", "cs.CY"], "comment": "21 pages, 12 figures, 14 tables", "summary": "Safety guardrails in large language models(LLMs) are developed to prevent\nmalicious users from generating toxic content at a large scale. However, these\nmeasures can inadvertently introduce or reflect new biases, as LLMs may refuse\nto generate harmful content targeting some demographic groups and not others.\nWe explore this selective refusal bias in LLM guardrails through the lens of\nrefusal rates of targeted individual and intersectional demographic groups,\ntypes of LLM responses, and length of generated refusals. Our results show\nevidence of selective refusal bias across gender, sexual orientation,\nnationality, and religion attributes. This leads us to investigate additional\nsafety implications via an indirect attack, where we target previously refused\ngroups. Our findings emphasize the need for more equitable and robust\nperformance in safety guardrails across demographic groups.", "AI": {"tldr": "研究发现LLM安全护栏存在选择性拒绝偏见，对不同人口群体（性别、性取向、国籍、宗教）的拒绝率存在差异，导致安全性能不均衡，需要通过间接攻击测试来揭示这些偏见。", "motivation": "大型语言模型的安全护栏旨在防止恶意用户大规模生成有害内容，但这些措施可能无意中引入或反映新的偏见，导致模型对某些人口群体拒绝生成有害内容而对其他群体不拒绝。", "method": "通过分析针对个体和交叉人口群体的拒绝率、LLM响应类型以及生成拒绝内容的长度，来探索选择性拒绝偏见，并通过间接攻击测试来调查额外的安全隐患。", "result": "研究结果显示在性别、性取向、国籍和宗教属性方面存在选择性拒绝偏见的证据，表明安全护栏在不同人口群体间的性能不平等。", "conclusion": "研究强调需要在所有人口群体中实现更公平和鲁棒的安全护栏性能，以防止选择性偏见带来的安全隐患。"}}
{"id": "2510.27383", "pdf": "https://arxiv.org/pdf/2510.27383", "abs": "https://arxiv.org/abs/2510.27383", "authors": ["Yueyang Wang", "Mehmet Dogar", "Gustav Markkula"], "title": "Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints", "categories": ["cs.AI"], "comment": null, "summary": "Modelling pedestrian-driver interactions is critical for understanding human\nroad user behaviour and developing safe autonomous vehicle systems. Existing\napproaches often rely on rule-based logic, game-theoretic models, or\n'black-box' machine learning methods. However, these models typically lack\nflexibility or overlook the underlying mechanisms, such as sensory and motor\nconstraints, which shape how pedestrians and drivers perceive and act in\ninteractive scenarios. In this study, we propose a multi-agent reinforcement\nlearning (RL) framework that integrates both visual and motor constraints of\npedestrian and driver agents. Using a real-world dataset from an unsignalised\npedestrian crossing, we evaluate four model variants, one without constraints,\ntwo with either motor or visual constraints, and one with both, across\nbehavioural metrics of interaction realism. Results show that the combined\nmodel with both visual and motor constraints performs best. Motor constraints\nlead to smoother movements that resemble human speed adjustments during\ncrossing interactions. The addition of visual constraints introduces perceptual\nuncertainty and field-of-view limitations, leading the agents to exhibit more\ncautious and variable behaviour, such as less abrupt deceleration. In this\ndata-limited setting, our model outperforms a supervised behavioural cloning\nmodel, demonstrating that our approach can be effective without large training\ndatasets. Finally, our framework accounts for individual differences by\nmodelling parameters controlling the human constraints as population-level\ndistributions, a perspective that has not been explored in previous work on\npedestrian-vehicle interaction modelling. Overall, our work demonstrates that\nmulti-agent RL with human constraints is a promising modelling approach for\nsimulating realistic road user interactions.", "AI": {"tldr": "本研究提出一个集成视觉和运动约束的多智能体强化学习框架，用于模拟行人-驾驶员交互行为，在数据有限的情况下优于监督学习方法，并能捕捉个体差异。", "motivation": "现有行人-驾驶员交互模型通常基于规则逻辑、博弈论或黑盒机器学习方法，缺乏灵活性且忽略了感知和运动约束等底层机制。", "method": "使用多智能体强化学习框架，集成行人和驾驶员的视觉与运动约束，基于无信号人行横道的真实数据集评估四种模型变体。", "result": "同时包含视觉和运动约束的模型表现最佳，运动约束使动作更平滑，视觉约束引入感知不确定性导致更谨慎的行为，在数据有限情况下优于监督学习模型。", "conclusion": "带有人的约束的多智能体强化学习是模拟真实道路使用者交互行为的有前景的方法，能够有效处理个体差异和有限数据场景。"}}
{"id": "2510.27106", "pdf": "https://arxiv.org/pdf/2510.27106", "abs": "https://arxiv.org/abs/2510.27106", "authors": ["Rajarshi Haldar", "Julia Hockenmaier"], "title": "Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks", "categories": ["cs.CL"], "comment": "Accepted at EMNLP 2025", "summary": "As Natural Language Generation (NLG) continues to be widely adopted, properly\nassessing it has become quite difficult. Lately, using large language models\n(LLMs) for evaluating these generations has gained traction, as they tend to\nalign more closely with human preferences than conventional n-gram or\nembedding-based metrics. In our experiments, we show that LLM judges have low\nintra-rater reliability in their assigned scores across different runs. This\nvariance makes their ratings inconsistent, almost arbitrary in the worst case,\nmaking it difficult to measure how good their judgments actually are. We\nquantify this inconsistency across different NLG tasks and benchmarks and see\nif judicious use of LLM judges can still be useful following proper guidelines.", "AI": {"tldr": "研究发现大语言模型作为评估工具时存在评分不一致性问题，不同运行中给出的分数差异较大，影响了评估的可靠性。", "motivation": "随着自然语言生成技术的广泛应用，传统评估指标与人类偏好存在差距，虽然大语言模型评估更接近人类判断，但其评分一致性值得研究。", "method": "通过实验量化分析大语言模型在不同NLG任务和基准测试中的评分不一致性，研究其在不同运行中的评分可靠性。", "result": "LLM评估者在不同运行中表现出较低的内部评分者信度，评分存在显著方差，在某些情况下几乎显得随意。", "conclusion": "尽管LLM评估存在不一致性问题，但在遵循适当指导原则的情况下，谨慎使用LLM评估仍然可能是有用的。"}}
{"id": "2510.27410", "pdf": "https://arxiv.org/pdf/2510.27410", "abs": "https://arxiv.org/abs/2510.27410", "authors": ["Jianwen Sun", "Yukang Feng", "Yifan Chang", "Chuanhao Li", "Zizhen Li", "Jiaxin Ai", "Fanrui Zhang", "Yu Dai", "Kaipeng Zhang"], "title": "Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry", "categories": ["cs.AI"], "comment": null, "summary": "A fundamental bottleneck in human-AI collaboration is the \"intention\nexpression gap,\" the difficulty for humans to effectively convey complex,\nhigh-dimensional thoughts to AI. This challenge often traps users in\ninefficient trial-and-error loops and is exacerbated by the diverse expertise\nlevels of users. We reframe this problem from passive instruction following to\na Socratic collaboration paradigm, proposing an agent that actively probes for\ninformation to resolve its uncertainty about user intent. we name the proposed\nagent Nous, trained to acquire proficiency in this inquiry policy. The core\nmechanism of Nous is a training framework grounded in the first principles of\ninformation theory. Within this framework, we define the information gain from\ndialogue as an intrinsic reward signal, which is fundamentally equivalent to\nthe reduction of Shannon entropy over a structured task space. This reward\ndesign enables us to avoid reliance on costly human preference annotations or\nexternal reward models. To validate our framework, we develop an automated\nsimulation pipeline to generate a large-scale, preference-based dataset for the\nchallenging task of scientific diagram generation. Comprehensive experiments,\nincluding ablations, subjective and objective evaluations, and tests across\nuser expertise levels, demonstrate the effectiveness of our proposed framework.\nNous achieves leading efficiency and output quality, while remaining robust to\nvarying user expertise. Moreover, its design is domain-agnostic, and we show\nevidence of generalization beyond diagram generation. Experimental results\nprove that our work offers a principled, scalable, and adaptive paradigm for\nresolving uncertainty about user intent in complex human-AI collaboration.", "AI": {"tldr": "Nous AI代理通过主动提问解决人机协作中的意图表达鸿沟问题，基于信息论原理设计信息增益作为内在奖励，无需人工标注，在科学图表生成任务中表现出色且具有领域泛化能力。", "motivation": "解决人机协作中的\"意图表达鸿沟\"问题，即人类难以有效向AI传达复杂高维思想，导致低效的试错循环，且不同专业水平的用户面临不同挑战。", "method": "提出Socratic协作范式，训练Nous代理主动探询信息以减少对用户意图的不确定性。基于信息论第一原理的训练框架，将对话信息增益定义为内在奖励信号（相当于结构化任务空间中香农熵的减少）。开发自动化模拟管道生成大规模偏好数据集用于科学图表生成任务。", "result": "综合实验（包括消融研究、主客观评估和不同用户专业水平测试）证明框架有效性。Nous在效率和输出质量方面领先，对不同用户专业水平保持鲁棒性，且设计具有领域无关性，在图表生成之外也显示出泛化能力。", "conclusion": "该工作为解决复杂人机协作中用户意图不确定性提供了一个原则性、可扩展且自适应的范式，基于信息论的奖励设计避免了对外部奖励模型或人工标注的依赖。"}}
{"id": "2510.27118", "pdf": "https://arxiv.org/pdf/2510.27118", "abs": "https://arxiv.org/abs/2510.27118", "authors": ["Andy Yang", "Anej Svete", "Jiaoda Li", "Anthony Widjaja Lin", "Jonathan Rawski", "Ryan Cotterell", "David Chiang"], "title": "Probability Distributions Computed by Hard-Attention Transformers", "categories": ["cs.CL"], "comment": "18 pages", "summary": "Most expressivity results for transformers treat them as language recognizers\n(which accept or reject strings), and not as they are used in practice, as\nlanguage models (which generate strings autoregressively and\nprobabilistically). Here, we characterize the probability distributions that\ntransformer language models can express. We show that making transformer\nlanguage recognizers autoregressive can sometimes increase their expressivity,\nand that making them probabilistic can break equivalences that hold in the\nnon-probabilistic case. Our overall contribution is to tease apart what\nfunctions transformers are capable of expressing, in their most common use-case\nas language models.", "AI": {"tldr": "该论文分析了Transformer语言模型在概率生成模式下的表达能力，发现自回归和概率化特性会改变其表达能力，相比传统的语言识别器有重要差异。", "motivation": "现有研究主要将Transformer视为语言识别器（接受或拒绝字符串），但实际应用中Transformer是作为语言模型（自回归概率生成字符串）使用的，需要研究其在这种使用场景下的表达能力。", "method": "通过理论分析，研究Transformer语言模型能够表达的概率分布特性，比较自回归和概率化对表达能力的影响。", "result": "研究发现：1）使Transformer语言识别器变为自回归有时能增强表达能力；2）概率化会破坏非概率情况下的等价关系；3）揭示了Transformer在语言模型使用场景下的表达能力边界。", "conclusion": "论文系统分析了Transformer在语言模型使用模式下的表达能力，强调了自回归和概率化对模型表达能力的重要影响，为理解Transformer在实际应用中的能力提供了理论支撑。"}}
{"id": "2510.27419", "pdf": "https://arxiv.org/pdf/2510.27419", "abs": "https://arxiv.org/abs/2510.27419", "authors": ["Tian Liang", "Wenxiang Jiao", "Zhiwei He", "Jiahao Xu", "Haitao Mi", "Dong Yu"], "title": "DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains", "categories": ["cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive capabilities but\nsuffer from cognitive inefficiencies like ``overthinking'' simple problems and\n``underthinking'' complex ones. While existing methods that use supervised\nfine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can\nimprove efficiency, they often do so at the cost of accuracy. This paper\nintroduces \\textbf{DeepCompress}, a novel framework that simultaneously\nenhances both the accuracy and efficiency of LRMs. We challenge the prevailing\napproach of consistently favoring shorter reasoning paths, showing that longer\nresponses can contain a broader range of correct solutions for difficult\nproblems. DeepCompress employs an adaptive length reward mechanism that\ndynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on\nthe model's evolving capability. It encourages shorter, more efficient\nreasoning for ``Simple'' problems while promoting longer, more exploratory\nthought chains for ``Hard'' problems. This dual-reward strategy enables the\nmodel to autonomously adjust its Chain-of-Thought (CoT) length, compressing\nreasoning for well-mastered problems and extending it for those it finds\nchallenging. Experimental results on challenging mathematical benchmarks show\nthat DeepCompress consistently outperforms baseline methods, achieving superior\naccuracy while significantly improving token efficiency.", "AI": {"tldr": "DeepCompress是一个新颖框架，通过自适应长度奖励机制动态分类问题难度，对简单问题鼓励短推理路径，对难题鼓励长推理路径，同时提升大推理模型的准确性和效率。", "motivation": "现有方法使用监督微调或带令牌长度奖励的强化学习虽然能提高效率，但往往以牺牲准确性为代价。大推理模型存在认知效率低下的问题，如对简单问题'过度思考'和对复杂问题'思考不足'。", "method": "提出DeepCompress框架，采用自适应长度奖励机制，实时根据模型能力动态将问题分类为'简单'或'困难'。对简单问题鼓励更短更高效的推理，对困难问题鼓励更长更具探索性的思维链。", "result": "在具有挑战性的数学基准测试中，DeepCompress始终优于基线方法，在显著提高令牌效率的同时实现了更优的准确性。", "conclusion": "该研究表明，通过自适应调整推理链长度的方法可以同时提升大推理模型的准确性和效率，挑战了传统偏好短推理路径的做法，证明长响应可能包含更广泛的正确解决方案。"}}
{"id": "2510.27183", "pdf": "https://arxiv.org/pdf/2510.27183", "abs": "https://arxiv.org/abs/2510.27183", "authors": ["Mason Shipton", "York Hay Ng", "Aditya Khan", "Phuong Hanh Hoang", "Xiang Lu", "A. Seza Doğruöz", "En-Shiun Annie Lee"], "title": "Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+", "categories": ["cs.CL"], "comment": null, "summary": "The URIEL+ linguistic knowledge base supports multilingual research by\nencoding languages through geographic, genetic, and typological vectors.\nHowever, data sparsity remains prevalent, in the form of missing feature types,\nincomplete language entries, and limited genealogical coverage. This limits the\nusefulness of URIEL+ in cross-lingual transfer, particularly for supporting\nlow-resource languages. To address this sparsity, this paper extends URIEL+\nwith three contributions: introducing script vectors to represent writing\nsystem properties for 7,488 languages, integrating Glottolog to add 18,710\nadditional languages, and expanding lineage imputation for 26,449 languages by\npropagating typological and script features across genealogies. These additions\nreduce feature sparsity by 14% for script vectors, increase language coverage\nby up to 19,015 languages (1,007%), and improve imputation quality metrics by\nup to 33%. Our benchmark on cross-lingual transfer tasks (oriented around\nlow-resource languages) shows occasionally divergent performance compared to\nURIEL+, with performance gains up to 6% in certain setups. Our advances make\nURIEL+ more complete and inclusive for multilingual research.", "AI": {"tldr": "URIEL+语言知识库通过扩展脚本向量、整合Glottolog语言数据和改进谱系插补方法，显著减少了数据稀疏性问题，提升了多语言研究的覆盖范围和跨语言迁移性能。", "motivation": "URIEL+语言知识库存在数据稀疏问题，包括缺失特征类型、不完整的语言条目和有限的谱系覆盖，这限制了其在跨语言迁移（特别是低资源语言支持）中的实用性。", "method": "1. 为7,488种语言引入脚本向量来表示书写系统属性\n2. 整合Glottolog数据库，新增18,710种语言\n3. 扩展谱系插补方法，为26,449种语言传播类型学和脚本特征", "result": "脚本向量特征稀疏性减少14%，语言覆盖范围增加最多19,015种语言（增长1,007%），插补质量指标提升最多33%。在跨语言迁移任务中，某些设置下性能提升达6%。", "conclusion": "这些扩展使URIEL+在多语言研究中更加完整和包容，为低资源语言的跨语言迁移提供了更好的支持。"}}
{"id": "2510.27448", "pdf": "https://arxiv.org/pdf/2510.27448", "abs": "https://arxiv.org/abs/2510.27448", "authors": ["Yuhao Zhang", "Dingxin Hu", "Tinghao Yu", "Hao Liu", "Yiting Liu"], "title": "GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language", "categories": ["cs.AI"], "comment": null, "summary": "Multi-modal Large Language Models (MLLMs) have gained significant attention\nin both academia and industry for their capabilities in handling multi-modal\ntasks. However, these models face challenges in mathematical geometric\nreasoning due to the scarcity of high-quality geometric data. To address this\nissue, synthetic geometric data has become an essential strategy. Current\nmethods for generating synthetic geometric data involve rephrasing or expanding\nexisting problems and utilizing predefined rules and templates to create\ngeometric images and problems. However, these approaches often produce data\nthat lacks diversity or is prone to noise. Additionally, the geometric images\nsynthesized by existing methods tend to exhibit limited variation and deviate\nsignificantly from authentic geometric diagrams. To overcome these limitations,\nwe propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses\nformal languages to explore combinations of conditions within metric space,\ngenerating high-fidelity geometric problems that differ from the originals\nwhile ensuring correctness through a symbolic engine. Experimental results show\nthat our synthetic data significantly outperforms existing methods. The model\ntrained with our data surpass the proprietary GPT-4o model by 18.7\\% on\ngeometry problem-solving tasks in MathVista and by 16.5\\% on GeoQA.\nAdditionally, it exceeds the performance of a leading open-source model by\n5.7\\% on MathVista and by 2.7\\% on GeoQA.", "AI": {"tldr": "GeoFM是一种基于形式语言和符号引擎的几何数据合成方法，能够生成高质量、多样化的几何问题，显著提升多模态大语言模型在几何推理任务上的性能表现。", "motivation": "多模态大语言模型在几何推理任务中面临高质量几何数据稀缺的问题，现有合成方法生成的数据缺乏多样性、噪声多，且与真实几何图表差异较大。", "method": "使用形式语言在度量空间中探索条件组合，通过符号引擎确保几何问题的正确性，生成高保真度的几何问题。", "result": "实验结果显示，使用GeoFM合成数据训练的模型在MathVista几何问题解决任务上超越GPT-4o模型18.7%，在GeoQA上超越16.5%；在开源模型上分别提升5.7%和2.7%。", "conclusion": "GeoFM方法有效解决了几何数据合成中的多样性和保真度问题，为多模态大语言模型的几何推理能力提升提供了高质量数据支持。"}}
{"id": "2510.27196", "pdf": "https://arxiv.org/pdf/2510.27196", "abs": "https://arxiv.org/abs/2510.27196", "authors": ["Zixin Chen", "Hongzhan Lin", "Kaixin Li", "Ziyang Luo", "Yayue Deng", "Jing Ma"], "title": "MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025", "summary": "The proliferation of memes on social media necessitates the capabilities of\nmultimodal Large Language Models (mLLMs) to effectively understand multimodal\nharmfulness. Existing evaluation approaches predominantly focus on mLLMs'\ndetection accuracy for binary classification tasks, which often fail to reflect\nthe in-depth interpretive nuance of harmfulness across diverse contexts. In\nthis paper, we propose MemeArena, an agent-based arena-style evaluation\nframework that provides a context-aware and unbiased assessment for mLLMs'\nunderstanding of multimodal harmfulness. Specifically, MemeArena simulates\ndiverse interpretive contexts to formulate evaluation tasks that elicit\nperspective-specific analyses from mLLMs. By integrating varied viewpoints and\nreaching consensus among evaluators, it enables fair and unbiased comparisons\nof mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments\ndemonstrate that our framework effectively reduces the evaluation biases of\njudge agents, with judgment results closely aligning with human preferences,\noffering valuable insights into reliable and comprehensive mLLM evaluations in\nmultimodal harmfulness understanding. Our code and data are publicly available\nat https://github.com/Lbotirx/MemeArena.", "AI": {"tldr": "MemeArena是一个基于代理的竞技场式评估框架，用于评估多模态大语言模型在理解多模态有害内容方面的能力，通过模拟多样化解释情境和整合不同观点来减少评估偏见。", "motivation": "现有评估方法主要关注二元分类任务的检测准确率，无法反映多模态有害内容在不同情境下的深度解释细微差别，需要更全面和公正的评估框架。", "method": "提出MemeArena框架，通过模拟多样化解释情境来制定评估任务，激发模型提供针对特定视角的分析，并通过整合不同观点和达成评估者共识来实现公平比较。", "result": "大量实验表明，该框架有效减少了评估代理的偏见，判断结果与人类偏好高度一致，为多模态有害内容理解提供了可靠全面的评估见解。", "conclusion": "MemeArena提供了一个上下文感知且无偏见的评估框架，能够公平比较多模态大语言模型在解释多模态有害内容方面的能力，代码和数据已公开。"}}
{"id": "2510.27544", "pdf": "https://arxiv.org/pdf/2510.27544", "abs": "https://arxiv.org/abs/2510.27544", "authors": ["Nikolaus Holzer", "William Fishell", "Baishakhi Ray", "Mark Santolucito"], "title": "Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance", "categories": ["cs.AI", "cs.FL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly excelling and outpacing human\nperformance on many tasks. However, to improve LLM reasoning, researchers\neither rely on ad-hoc generated datasets or formal mathematical proof systems\nsuch as the Lean proof assistant. Whilst ad-hoc generated methods can capture\nthe decision chains of real-world reasoning processes, they may encode some\ninadvertent bias in the space of reasoning they cover; they also cannot be\nformally verified. On the other hand, systems like Lean can guarantee\nverifiability, but are not well-suited to capture the nature of agentic\ndecision chain-based tasks. This creates a gap both in performance for\nfunctions such as business agents or code assistants, and in the usefulness of\nLLM reasoning benchmarks, whereby these fall short in reasoning structure or\nreal-world alignment. We introduce TempoBench, the first formally grounded and\nverifiable diagnostic benchmark that parametrizes difficulty to systematically\nanalyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks\nto break down reasoning ability. First, temporal trace evaluation (TTE) tests\nthe ability of an LLM to understand and simulate the execution of a given\nmulti-step reasoning system. Subsequently, temporal causal evaluation (TCE)\ntests an LLM's ability to perform multi-step causal reasoning and to distill\ncause-and-effect relations from complex systems. We find that models score\n65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art\nLLMs clearly understand the TCE task but perform poorly as system complexity\nincreases. Our code is available at our\n\\href{https://github.com/nik-hz/tempobench}{GitHub repository}.", "AI": {"tldr": "TempoBench是一个新的形式化可验证基准测试，用于系统分析大语言模型的多步推理能力，包含时序轨迹评估和时序因果评估两个维度。", "motivation": "现有LLM推理评估方法存在缺陷：临时生成的数据集可能包含偏差且无法验证，而形式化证明系统（如Lean）不适合捕捉基于决策链的现实任务特性，导致在业务代理和代码助手等应用中的性能评估存在差距。", "method": "提出TempoBench基准，包含两个评估维度：1）时序轨迹评估（TTE）-测试LLM理解和模拟多步推理系统执行的能力；2）时序因果评估（TCE）-测试LLM进行多步因果推理和从复杂系统中提取因果关系的能力。基准参数化难度以系统分析性能。", "result": "实验结果显示，最先进的LLM在TCE-normal上得分65.6%，在TCE-hard上仅得7.5%，表明模型能理解TCE任务但在系统复杂度增加时表现显著下降。", "conclusion": "TempoBench填补了LLM推理评估的空白，提供了形式化可验证的基准测试方法，揭示了当前LLM在复杂多步推理任务上的局限性，为未来模型改进提供了重要参考。"}}
{"id": "2510.27241", "pdf": "https://arxiv.org/pdf/2510.27241", "abs": "https://arxiv.org/abs/2510.27241", "authors": ["Yulin Ou", "Yu Wang", "Yang Xu", "Hendrik Buschmeier"], "title": "Identifying the Periodicity of Information in Natural Language", "categories": ["cs.CL"], "comment": null, "summary": "Recent theoretical advancement of information density in natural language has\nbrought the following question on desk: To what degree does natural language\nexhibit periodicity pattern in its encoded information? We address this\nquestion by introducing a new method called AutoPeriod of Surprisal (APS). APS\nadopts a canonical periodicity detection algorithm and is able to identify any\nsignificant periods that exist in the surprisal sequence of a single document.\nBy applying the algorithm to a set of corpora, we have obtained the following\ninteresting results: Firstly, a considerable proportion of human language\ndemonstrates a strong pattern of periodicity in information; Secondly, new\nperiods that are outside the distributions of typical structural units in text\n(e.g., sentence boundaries, elementary discourse units, etc.) are found and\nfurther confirmed via harmonic regression modeling. We conclude that the\nperiodicity of information in language is a joint outcome from both structured\nfactors and other driving factors that take effect at longer distances. The\nadvantages of our periodicity detection method and its potentials in\nLLM-generation detection are further discussed.", "AI": {"tldr": "本文提出AutoPeriod of Surprisal (APS)方法，发现自然语言信息编码中存在显著的周期性模式，这些周期不仅包含典型文本结构单元，还包括更长距离的驱动因素。", "motivation": "探索自然语言在编码信息中展现周期性模式的程度，以理解语言信息结构的深层规律。", "method": "采用AutoPeriod of Surprisal (APS)方法，使用规范周期性检测算法分析单个文档的惊奇值序列，识别显著周期模式。", "result": "发现相当比例的人类语言具有信息周期性；识别出超出典型文本结构单元分布的新周期，并通过谐波回归模型验证。", "conclusion": "语言信息的周期性是结构化因素和更长距离驱动因素共同作用的结果，该方法在LLM生成检测中具有潜在应用价值。"}}
{"id": "2510.27568", "pdf": "https://arxiv.org/pdf/2510.27568", "abs": "https://arxiv.org/abs/2510.27568", "authors": ["Ali Asgarov", "Umid Suleymanov", "Aadyant Khatri"], "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Short Paper - Under Review", "summary": "Solving mathematical reasoning problems requires not only accurate access to\nrelevant knowledge but also careful, multi-step thinking. However, current\nretrieval-augmented models often rely on a single perspective, follow\ninflexible search strategies, and struggle to effectively combine information\nfrom multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge\nIntegration for AGentic Mathematical reAsoning), a unified framework that\norchestrates specialized agents to independently reason, perform targeted\nsearches, and synthesize findings through a moderator mechanism. Each agent\ngenerates hypothetical passages to optimize retrieval for its analytic\nperspective, ensuring knowledge integration is both context-sensitive and\ncomputation-efficient. When evaluated on challenging benchmarks such as\nMATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms\nboth open- and closed-source systems, achieving an absolute performance\nimprovement of 7.4%. Our results demonstrate that multi-agent, on-demand\nknowledge integration significantly enhances both reasoning accuracy and\nefficiency, offering a scalable approach for complex, knowledge-intensive\nproblem-solving. We will release the code upon publication.", "AI": {"tldr": "SIGMA是一个多智能体检索增强框架，通过专业化智能体独立推理、定向搜索和协调机制来提升数学推理能力，在多个挑战性基准测试中显著优于现有系统。", "motivation": "当前检索增强模型存在单视角依赖、搜索策略僵化、多源信息融合困难等问题，无法有效支持复杂的多步骤数学推理。", "method": "提出SIGMA框架，通过专业化智能体独立生成假设性段落进行定向检索，利用协调机制整合不同视角的发现，实现上下文敏感且计算高效的知识整合。", "result": "在MATH500、AIME和GPQA等基准测试中，SIGMA相比开源和闭源系统取得了7.4%的绝对性能提升。", "conclusion": "多智能体按需知识整合方法显著提高了复杂知识密集型问题的推理准确性和效率，为可扩展的复杂问题解决提供了有效途径。"}}
{"id": "2510.27246", "pdf": "https://arxiv.org/pdf/2510.27246", "abs": "https://arxiv.org/abs/2510.27246", "authors": ["Mohammad Tavakoli", "Alireza Salemi", "Carrie Ye", "Mohamed Abdalla", "Hamed Zamani", "J Ross Mitchell"], "title": "Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Evaluating the abilities of large language models (LLMs) for tasks that\nrequire long-term memory and thus long-context reasoning, for example in\nconversational settings, is hampered by the existing benchmarks, which often\nlack narrative coherence, cover narrow domains, and only test simple\nrecall-oriented tasks. This paper introduces a comprehensive solution to these\nchallenges. First, we present a novel framework for automatically generating\nlong (up to 10M tokens), coherent, and topically diverse conversations,\naccompanied by probing questions targeting a wide range of memory abilities.\nFrom this, we construct BEAM, a new benchmark comprising 100 conversations and\n2,000 validated questions. Second, to enhance model performance, we propose\nLIGHT-a framework inspired by human cognition that equips LLMs with three\ncomplementary memory systems: a long-term episodic memory, a short-term working\nmemory, and a scratchpad for accumulating salient facts. Our experiments on\nBEAM reveal that even LLMs with 1M token context windows (with and without\nretrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT\nconsistently improves performance across various models, achieving an average\nimprovement of 3.5%-12.69% over the strongest baselines, depending on the\nbackbone LLM. An ablation study further confirms the contribution of each\nmemory component.", "AI": {"tldr": "本文提出了BEAM基准测试和LIGHT框架，用于评估和提升大语言模型在长对话记忆任务中的表现。BEAM包含100个长对话和2000个问题，LIGHT框架则通过三种记忆系统显著提升模型性能。", "motivation": "现有基准测试在评估大语言模型的长时记忆能力方面存在不足，缺乏叙事连贯性、领域狭窄且只测试简单的回忆任务，需要更全面的评估方案。", "method": "1) 开发自动生成长对话的框架，构建BEAM基准测试；2) 提出LIGHT框架，包含长期情景记忆、短期工作记忆和事实积累便签三种记忆系统；3) 在BEAM上进行实验验证。", "result": "实验显示，即使具有100万token上下文窗口的LLM在长对话中也表现不佳，而LIGHT框架相比最强基线平均提升3.5%-12.69%的性能，消融研究证实了各记忆组件的贡献。", "conclusion": "LIGHT框架通过模拟人类认知的多重记忆系统，有效提升了LLM在长对话记忆任务中的表现，为解决长上下文推理问题提供了有效方案。"}}
{"id": "2510.27598", "pdf": "https://arxiv.org/pdf/2510.27598", "abs": "https://arxiv.org/abs/2510.27598", "authors": ["Yunze Wu", "Dayuan Fu", "Weiye Si", "Zhen Huang", "Mohan Jiang", "Keyu Li", "Shijie Xia", "Jie Sun", "Tianze Xu", "Xiangkun Hu", "Pengrui Lu", "Xiaojie Cai", "Lyumanshan Ye", "Wenhong Zhu", "Yang Xiao", "Pengfei Liu"], "title": "InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research", "categories": ["cs.AI"], "comment": null, "summary": "AI agents could accelerate scientific discovery by automating hypothesis\nformation, experiment design, coding, execution, and analysis, yet existing\nbenchmarks probe narrow skills in simplified settings. To address this gap, we\nintroduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end\nassessment of agents performing Large Language Model (LLM) research. It\ncomprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss\nDesign, Reward Design, and Scaffold Construction, which require runnable\nartifacts and assessment of correctness, performance, output quality, and\nuncertainty. To support agent operation, we develop ResearchGym, a research\nenvironment offering rich action spaces, distributed and long-horizon\nexecution, asynchronous monitoring, and snapshot saving. We also implement a\nlightweight ReAct agent that couples explicit reasoning with executable\nplanning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.\nOur experiments demonstrate that while frontier models show promise in\ncode-driven research tasks, they struggle with fragile algorithm-related tasks\nand long-horizon decision making, such as impatience, poor resource management,\nand overreliance on template-based reasoning. Furthermore, agents require over\n11 hours to achieve their best performance on InnovatorBench, underscoring the\nbenchmark's difficulty and showing the potential of InnovatorBench to be the\nnext generation of code-based research benchmark.", "AI": {"tldr": "论文提出了InnovatorBench基准平台，用于评估AI智能体在LLM研究中的端到端能力，包含20个任务和ResearchGym环境，测试显示前沿模型在代码研究任务中有潜力但在算法任务和长时决策中存在困难", "motivation": "现有基准测试在简化环境中只能评估狭窄技能，需要真实场景下评估AI智能体进行科学发现全过程的能力", "method": "开发InnovatorBench基准平台（20个任务）和ResearchGym研究环境，实现轻量级ReAct智能体结合前沿模型进行推理与执行规划", "result": "前沿模型在代码驱动研究任务中表现有希望，但在脆弱算法相关任务和长时决策中存在耐心不足、资源管理差、过度依赖模板推理等问题，智能体需要超过11小时才能达到最佳性能", "conclusion": "InnovatorBench展示了作为下一代基于代码的研究基准的潜力，揭示了当前AI智能体在科学研究自动化方面的局限性和改进方向"}}
{"id": "2510.27254", "pdf": "https://arxiv.org/pdf/2510.27254", "abs": "https://arxiv.org/abs/2510.27254", "authors": ["Rajan Agarwal", "Aarush Gupta"], "title": "Languages are Modalities: Cross-Lingual Alignment via Encoder Injection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "14 pages, 3 Figures", "summary": "Instruction-tuned Large Language Models (LLMs) underperform on low resource,\nnon-Latin scripts due to tokenizer fragmentation and weak cross-lingual\ncoupling. We present LLINK (Latent Language Injection for Non-English\nKnowledge), a compute efficient language-as-modality method that conditions an\ninstruction-tuned decoder without changing the tokenizer or retraining the\ndecoder. First, we align sentence embeddings from a frozen multilingual encoder\nto the decoder's latent embedding space at a reserved position via a\nlightweight contrastive projector. Second, the vector is expanded into K soft\nslots and trained with minimal adapters so the frozen decoder consumes the\nsignal. LLINK substantially improves bilingual retrieval and achieves 81.3%\npreference over the base model and 63.6% over direct fine-tuning in LLM-judged\nQ&A evaluations. We further find that improvements can be attributed to reduced\ntokenization inflation and a stronger cross lingual alignment, despite the\nmodel having residual weaknesses in numeric fidelity. Treating low resource\nlanguages as a modality offers a practical path to stronger cross-lingual\nalignment in lightweight LLMs.", "AI": {"tldr": "LLINK是一种计算高效的语言注入方法，通过将多语言编码器的句子嵌入对齐到解码器的潜在空间，改善低资源非拉丁脚本语言在指令调优大语言模型中的表现，无需修改分词器或重新训练解码器。", "motivation": "指令调优的大语言模型在低资源非拉丁脚本语言上表现不佳，主要由于分词器碎片化和跨语言耦合能力弱。", "method": "1. 通过轻量级对比投影器将冻结多语言编码器的句子嵌入对齐到解码器保留位置的潜在嵌入空间；2. 将向量扩展为K个软槽，通过最小适配器训练使冻结解码器能够处理信号。", "result": "LLINK显著改善了双语检索性能，在LLM评判的问答评估中获得81.3%优于基础模型的偏好度和63.6%优于直接微调的偏好度。减少了分词膨胀并增强了跨语言对齐。", "conclusion": "将低资源语言视为模态提供了一种实用的轻量级LLM跨语言对齐路径，尽管模型在数值保真度方面仍存在残余弱点。"}}
{"id": "2510.27617", "pdf": "https://arxiv.org/pdf/2510.27617", "abs": "https://arxiv.org/abs/2510.27617", "authors": ["Heng Ping", "Arijit Bhattacharjee", "Peiyu Zhang", "Shixuan Li", "Wei Yang", "Anzhe Cheng", "Xiaole Zhang", "Jesse Thomason", "Ali Jannesari", "Nesreen Ahmed", "Paul Bogdan"], "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation", "categories": ["cs.AI"], "comment": null, "summary": "Automation of Register Transfer Level (RTL) design can help developers meet\nincreasing computational demands. Large Language Models (LLMs) show promise for\nHardware Description Language (HDL) generation, but face challenges due to\nlimited parametric knowledge and domain-specific constraints. While prompt\nengineering and fine-tuning have limitations in knowledge coverage and training\ncosts, multi-agent architectures offer a training-free paradigm to enhance\nreasoning through collaborative generation. However, current multi-agent\napproaches suffer from two critical deficiencies: susceptibility to noise\npropagation and constrained reasoning space exploration. We propose VeriMoA, a\ntraining-free mixture-of-agents (MoA) framework with two synergistic\ninnovations. First, a quality-guided caching mechanism to maintain all\nintermediate HDL outputs and enables quality-based ranking and selection across\nthe entire generation process, encouraging knowledge accumulation over layers\nof reasoning. Second, a multi-path generation strategy that leverages C++ and\nPython as intermediate representations, decomposing specification-to-HDL\ntranslation into two-stage processes that exploit LLM fluency in high-resource\nlanguages while promoting solution diversity. Comprehensive experiments on\nVerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves\n15--30% improvements in Pass@1 across diverse LLM backbones, especially\nenabling smaller models to match larger models and fine-tuned alternatives\nwithout requiring costly training.", "AI": {"tldr": "VeriMoA是一个无需训练的多智能体框架，通过质量引导缓存和多路径生成策略，显著提升HDL代码生成性能，在VerilogEval 2.0和RTLLM 2.0基准测试中Pass@1指标提升15-30%", "motivation": "当前LLM在硬件描述语言生成中存在参数知识有限和领域约束挑战，传统提示工程和微调方法在知识覆盖和训练成本方面有局限，多智能体方法又面临噪声传播和推理空间受限的问题", "method": "提出两种协同创新：1) 质量引导缓存机制，维护所有中间HDL输出并进行质量排序选择；2) 多路径生成策略，利用C++和Python作为中间表示，将规范到HDL的转换分解为两阶段过程", "result": "在VerilogEval 2.0和RTLLM 2.0基准测试中，VeriMoA在不同LLM骨干网络上实现了15-30%的Pass@1改进，特别是使小模型能够匹配大模型和微调替代方案", "conclusion": "VeriMoA提供了一个无需训练的高效框架，通过多智能体协作和质量优化机制，有效解决了HDL代码生成的挑战，为自动化RTL设计提供了新的解决方案"}}
{"id": "2510.27267", "pdf": "https://arxiv.org/pdf/2510.27267", "abs": "https://arxiv.org/abs/2510.27267", "authors": ["Kangkun Mao", "Jinru Ding", "Jiayuan Chen", "Mouxiao Bian", "Ruiyao Chen", "Xinwei Peng", "Sijie Ren", "Linyang Li", "Jie Xu"], "title": "MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) enter the medical domain, most benchmarks\nevaluate them on question answering or descriptive reasoning, overlooking\nquantitative reasoning critical to clinical decision-making. Existing datasets\nlike MedCalc-Bench cover few calculation tasks and fail to reflect real-world\ncomputational scenarios.\n  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical\ncalculation abilities, comprising 700+ tasks across two types: equation-based\n(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,\nGlasgow Coma Scale). These tasks span diverse specialties including internal\nmedicine, surgery, pediatrics, and cardiology, offering a broader and more\nchallenging evaluation setting.\n  To improve performance, we further develop MedCalc-Env, a reinforcement\nlearning environment built on the InternBootcamp framework, enabling multi-step\nclinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this\nenvironment achieves state-of-the-art results on MedCalc-Eval, with notable\ngains in numerical sensitivity, formula selection, and reasoning robustness.\nRemaining challenges include unit conversion, multi-condition logic, and\ncontextual understanding.\n  Code and datasets are available at\nhttps://github.com/maokangkun/MedCalc-Eval.", "AI": {"tldr": "MedCalc-Eval是最大的医学计算能力评估基准，包含700多个任务，涵盖方程计算和规则评分系统。通过MedCalc-Env强化学习环境微调模型，在数值敏感性、公式选择和推理鲁棒性方面取得最先进结果。", "motivation": "现有医学LLM基准主要关注问答和描述性推理，忽视了临床决策中关键的定量推理能力，且现有数据集覆盖计算任务少，无法反映真实临床计算场景。", "method": "创建MedCalc-Eval基准数据集（700+任务，分方程计算和规则评分系统两类）；开发MedCalc-Env强化学习环境（基于InternBootcamp框架）；使用该环境对Qwen2.5-32B模型进行微调。", "result": "微调后的模型在MedCalc-Eval上达到最先进性能，在数值敏感性、公式选择和推理鲁棒性方面有显著提升。", "conclusion": "MedCalc-Eval为医学计算能力评估提供了全面基准，MedCalc-Env环境有效提升了模型性能，但单位转换、多条件逻辑和上下文理解仍是待解决的挑战。"}}
{"id": "2510.27623", "pdf": "https://arxiv.org/pdf/2510.27623", "abs": "https://arxiv.org/abs/2510.27623", "authors": ["Qiusi Zhan", "Hyeonjeong Ha", "Rui Yang", "Sirui Xu", "Hanyang Chen", "Liang-Yan Gui", "Yu-Xiong Wang", "Huan Zhang", "Heng Ji", "Daniel Kang"], "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced embodied agents by\nenabling direct perception, reasoning, and planning task-oriented actions from\nvisual inputs. However, such vision driven embodied agents open a new attack\nsurface: visual backdoor attacks, where the agent behaves normally until a\nvisual trigger appears in the scene, then persistently executes an\nattacker-specified multi-step policy. We introduce BEAT, the first framework to\ninject such visual backdoors into MLLM-based embodied agents using objects in\nthe environments as triggers. Unlike textual triggers, object triggers exhibit\nwide variation across viewpoints and lighting, making them difficult to implant\nreliably. BEAT addresses this challenge by (1) constructing a training set that\nspans diverse scenes, tasks, and trigger placements to expose agents to trigger\nvariability, and (2) introducing a two-stage training scheme that first applies\nsupervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning\n(CTL). CTL formulates trigger discrimination as preference learning between\ntrigger-present and trigger-free inputs, explicitly sharpening the decision\nboundaries to ensure precise backdoor activation. Across various embodied agent\nbenchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while\nmaintaining strong benign task performance, and generalizes reliably to\nout-of-distribution trigger placements. Notably, compared to naive SFT, CTL\nboosts backdoor activation accuracy up to 39% under limited backdoor data.\nThese findings expose a critical yet unexplored security risk in MLLM-based\nembodied agents, underscoring the need for robust defenses before real-world\ndeployment.", "AI": {"tldr": "BEAT是首个针对多模态大语言模型(MLLM)具身智能体的视觉后门攻击框架，利用环境中的物体作为触发器，能够在触发出现时让智能体持续执行攻击者指定的多步策略", "motivation": "MLLM驱动的具身智能体开启了新的攻击面——视觉后门攻击，需要研究如何在这种新型系统中可靠地植入视觉触发器", "method": "BEAT采用两阶段训练方案：先进行监督微调(SFT)，然后引入新颖的对比触发学习(CTL)，通过构建多样化的训练集覆盖不同场景、任务和触发器位置，并使用偏好学习明确锐化决策边界", "result": "在各种具身智能体基准测试和MLLM上，BEAT实现了高达80%的攻击成功率，同时保持强大的良性任务性能，并能可靠地泛化到分布外的触发器位置。CTL相比朴素SFT在有限后门数据下将后门激活准确率提升高达39%", "conclusion": "这些发现揭示了基于MLLM的具身智能体中存在关键但未被探索的安全风险，强调了在实际部署前需要建立鲁棒防御机制的必要性"}}
{"id": "2510.27269", "pdf": "https://arxiv.org/pdf/2510.27269", "abs": "https://arxiv.org/abs/2510.27269", "authors": ["Deokhyung Kang", "Seonjeong Hwang", "Daehui Kim", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning language models (RLMs) achieve strong performance on complex\nreasoning tasks, yet they still suffer from a multilingual reasoning gap,\nperforming better in high-resource languages than in low-resource ones. While\nrecent efforts have reduced this gap, its underlying causes remain largely\nunexplored. In this paper, we address this by showing that the multilingual\nreasoning gap largely stems from failures in language understanding-the model's\ninability to represent the multilingual input meaning into the dominant\nlanguage (i.e., English) within its reasoning trace. This motivates us to\nexamine whether understanding failures can be detected, as this ability could\nhelp mitigate the multilingual reasoning gap. To this end, we evaluate a range\nof detection methods and find that understanding failures can indeed be\nidentified, with supervised approaches performing best. Building on this, we\npropose Selective Translation, a simple yet effective strategy that translates\nthe multilingual input into English only when an understanding failure is\ndetected. Experimental results show that Selective Translation bridges the\nmultilingual reasoning gap, achieving near full-translation performance while\nusing translation for only about 20% of inputs. Together, our work demonstrates\nthat understanding failures are the primary cause of the multilingual reasoning\ngap and can be detected and selectively mitigated, providing key insight into\nits origin and a promising path toward more equitable multilingual reasoning.\nOur code and data are publicly available at\nhttps://github.com/deokhk/RLM_analysis.", "AI": {"tldr": "本文发现多语言推理差距主要源于语言理解失败，提出选择性翻译策略，仅对检测到理解失败的输入进行翻译，在仅翻译约20%输入的情况下达到接近全翻译性能。", "motivation": "推理语言模型在复杂推理任务上表现良好，但在多语言环境中存在性能差距，高资源语言表现优于低资源语言。现有研究尚未深入探索这一差距的根本原因。", "method": "通过分析发现理解失败是主要原因，评估多种检测方法（监督方法效果最佳），提出选择性翻译策略：仅在检测到理解失败时将多语言输入翻译成英语。", "result": "选择性翻译策略有效缩小多语言推理差距，仅需翻译约20%的输入就能达到接近全翻译的性能水平。", "conclusion": "理解失败是多语言推理差距的主要成因，可以通过检测和选择性缓解来解决，为实现更公平的多语言推理提供了重要见解和可行路径。"}}
{"id": "2510.27628", "pdf": "https://arxiv.org/pdf/2510.27628", "abs": "https://arxiv.org/abs/2510.27628", "authors": ["Sebastian Benthall", "Andrew Clark"], "title": "Validity Is What You Need", "categories": ["cs.AI"], "comment": null, "summary": "While AI agents have long been discussed and studied in computer science,\ntoday's Agentic AI systems are something new. We consider other definitions of\nAgentic AI and propose a new realist definition. Agentic AI is a software\ndelivery mechanism, comparable to software as a service (SaaS), which puts an\napplication to work autonomously in a complex enterprise setting. Recent\nadvances in large language models (LLMs) as foundation models have driven\nexcitement in Agentic AI. We note, however, that Agentic AI systems are\nprimarily applications, not foundations, and so their success depends on\nvalidation by end users and principal stakeholders. The tools and techniques\nneeded by the principal users to validate their applications are quite\ndifferent from the tools and techniques used to evaluate foundation models.\nIronically, with good validation measures in place, in many cases the\nfoundation models can be replaced with much simpler, faster, and more\ninterpretable models that handle core logic. When it comes to Agentic AI,\nvalidity is what you need. LLMs are one option that might achieve it.", "AI": {"tldr": "论文提出了Agentic AI的新现实主义定义，强调其作为软件交付机制的本质，指出Agentic AI主要是应用而非基础模型，其成功取决于终端用户验证，且验证工具与传统基础模型评估不同。", "motivation": "针对当前AI代理系统的讨论，作者认为需要重新定义Agentic AI，明确其作为软件交付机制的本质特征，并强调应用验证的重要性。", "method": "通过比较分析现有定义，提出新的现实主义定义，并讨论Agentic AI与基础模型的关系，强调验证工具和技术的差异。", "result": "提出了Agentic AI作为软件交付机制的新定义，指出在良好验证机制下，基础模型可被更简单、快速、可解释的模型替代。", "conclusion": "Agentic AI的成功关键在于有效性验证，LLMs只是实现有效性的可能选项之一，而非必需的基础。"}}
{"id": "2510.27328", "pdf": "https://arxiv.org/pdf/2510.27328", "abs": "https://arxiv.org/abs/2510.27328", "authors": ["Yi-Long Lu", "Jiajun Song", "Wei Wang"], "title": "A Unified Representation Underlying the Judgment of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "A central architectural question for both biological and artificial\nintelligence is whether judgment relies on specialized modules or a unified,\ndomain-general resource. While the discovery of decodable neural\nrepresentations for distinct concepts in Large Language Models (LLMs) has\nsuggested a modular architecture, whether these representations are truly\nindependent systems remains an open question. Here we provide evidence for a\nconvergent architecture. Across a range of LLMs, we find that diverse\nevaluative judgments are computed along a dominant dimension, which we term the\nValence-Assent Axis (VAA). This axis jointly encodes subjective valence (\"what\nis good\") and the model's assent to factual claims (\"what is true\"). Through\ndirect interventions, we show this unified representation creates a critical\ndependency: the VAA functions as a control signal that steers the generative\nprocess to construct a rationale consistent with its evaluative state, even at\nthe cost of factual accuracy. This mechanism, which we term the subordination\nof reasoning, shifts the process of reasoning from impartial inference toward\ngoal-directed justification. Our discovery offers a mechanistic account for\nsystemic bias and hallucination, revealing how an architecture that promotes\ncoherent judgment can systematically undermine faithful reasoning.", "AI": {"tldr": "研究发现大型语言模型采用收敛式架构而非模块化架构，评价判断沿着一个主导维度（Valence-Assent Axis）进行计算，该轴统一编码主观价值和事实认同，导致推理过程从公正推断转向目标导向的合理化。", "motivation": "探讨人工智能和生物智能的核心架构问题：判断是依赖专门模块还是统一的领域通用资源，特别是验证LLM中可解码的神经表示是否真正独立。", "method": "通过分析多个LLM模型，识别评价判断的主导维度（VAA轴），并通过直接干预实验验证该统一表示的功能。", "result": "发现VAA轴作为控制信号引导生成过程构建与其评价状态一致的理由，即使牺牲事实准确性，揭示了推理从属现象。", "conclusion": "该收敛架构解释了系统性偏见和幻觉的机制，显示促进连贯判断的架构如何系统性地削弱忠实推理。"}}
{"id": "2510.27630", "pdf": "https://arxiv.org/pdf/2510.27630", "abs": "https://arxiv.org/abs/2510.27630", "authors": ["Dayuan Fu", "Yunze Wu", "Xiaojie Cai", "Lyumanshan Ye", "Shijie Xia", "Zhen Huang", "Weiye Si", "Tianze Xu", "Jie Sun", "Keyu Li", "Mohan Jiang", "Junfei Wang", "Qishuo Hua", "Pengrui Lu", "Yang Xiao", "Pengfei Liu"], "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents have recently shown strong potential in\ndomains such as automated coding, deep research, and graphical user interface\nmanipulation. However, training them to succeed on long-horizon,\ndomain-specialized tasks remains challenging. Current methods primarily fall\ninto two categories. The first relies on dense human annotations through\nbehavior cloning, which is prohibitively expensive for long-horizon tasks that\ncan take days or months. The second depends on outcome-driven sampling, which\noften collapses due to the rarity of valid positive trajectories on\ndomain-specialized tasks. We introduce Apollo, a sampling framework that\nintegrates asynchronous human guidance with action-level data filtering.\nInstead of requiring annotators to shadow every step, Apollo allows them to\nintervene only when the agent drifts from a promising trajectory, by providing\nprior knowledge, strategic advice, etc. This lightweight design makes it\npossible to sustain interactions for over 30 hours and produces valuable\ntrajectories at a lower cost. Apollo then applies supervision control to filter\nout sub-optimal actions and prevent error propagation. Together, these\ncomponents enable reliable and effective data collection in long-horizon\nenvironments. To demonstrate the effectiveness of Apollo, we evaluate it using\nInnovatorBench. Our experiments show that when applied to train the GLM-4.5\nmodel on InnovatorBench, Apollo achieves more than a 50% improvement over the\nuntrained baseline and a 28% improvement over a variant trained without human\ninteraction. These results highlight the critical role of human-in-the-loop\nsampling and the robustness of Apollo's design in handling long-horizon,\ndomain-specialized tasks.", "AI": {"tldr": "Apollo是一个集成异步人类指导与动作级数据过滤的采样框架，用于训练LLM代理在长时域、领域专业化任务中，相比传统方法显著提升了训练效果和效率。", "motivation": "当前LLM代理在长时域、领域专业化任务训练中存在两个主要问题：基于行为克隆的方法需要密集人工标注成本过高；基于结果驱动的采样方法因有效轨迹稀少而容易失效。", "method": "Apollo框架采用异步人类指导方式，允许标注者仅在代理偏离正确轨迹时进行干预，提供先验知识和策略建议，同时使用监督控制过滤次优动作以防止错误传播。", "result": "在InnovatorBench上使用GLM-4.5模型的实验显示，Apollo相比未训练基线提升50%以上，相比无人交互训练变体提升28%。", "conclusion": "Apollo证明了人类在环采样在长时域任务中的关键作用，其轻量级设计能够以更低成本产生有价值轨迹，为领域专业化LLM代理训练提供了可靠有效的数据收集方案。"}}
{"id": "2510.27337", "pdf": "https://arxiv.org/pdf/2510.27337", "abs": "https://arxiv.org/abs/2510.27337", "authors": ["Benedikt Ebing", "Christian Goldschmied", "Goran Glavaš"], "title": "TransAlign: Machine Translation Encoders are Strong Word Aligners, Too", "categories": ["cs.CL"], "comment": null, "summary": "In the absence of sizable training data for most world languages and NLP\ntasks, translation-based strategies such as translate-test -- evaluating on\nnoisy source language data translated from the target language -- and\ntranslate-train -- training on noisy target language data translated from the\nsource language -- have been established as competitive approaches for\ncross-lingual transfer (XLT). For token classification tasks, these strategies\nrequire label projection: mapping the labels from each token in the original\nsentence to its counterpart(s) in the translation. To this end, it is common to\nleverage multilingual word aligners (WAs) derived from encoder language models\nsuch as mBERT or LaBSE. Despite obvious associations between machine\ntranslation (MT) and WA, research on extracting alignments with MT models is\nlargely limited to exploiting cross-attention in encoder-decoder architectures,\nyielding poor WA results. In this work, in contrast, we propose TransAlign, a\nnovel word aligner that utilizes the encoder of a massively multilingual MT\nmodel. We show that TransAlign not only achieves strong WA performance but\nsubstantially outperforms popular WA and state-of-the-art non-WA-based label\nprojection methods in MT-based XLT for token classification.", "AI": {"tldr": "TransAlign是一种新颖的词对齐方法，利用大规模多语言机器翻译模型的编码器，在基于机器翻译的跨语言迁移中显著优于传统词对齐方法和最先进的非词对齐标签投影方法。", "motivation": "当前跨语言迁移主要依赖多语言词对齐器进行标签投影，但基于机器翻译模型提取对齐信息的研究有限且效果不佳，需要更有效的词对齐方法。", "method": "提出TransAlign方法，利用大规模多语言机器翻译模型的编码器来提取词对齐信息，用于跨语言迁移中的标签投影任务。", "result": "TransAlign不仅实现了强大的词对齐性能，而且在基于机器翻译的跨语言迁移中显著超越了流行的词对齐方法和最先进的非词对齐标签投影方法。", "conclusion": "利用机器翻译模型编码器的TransAlign方法为跨语言迁移中的词对齐和标签投影提供了更有效的解决方案，在token分类任务中表现出优越性能。"}}
{"id": "2510.27671", "pdf": "https://arxiv.org/pdf/2510.27671", "abs": "https://arxiv.org/abs/2510.27671", "authors": ["Wei Zhang", "Zekun Guo", "Yingce Xia", "Peiran Jin", "Shufang Xie", "Tao Qin", "Xiang-Yang Li"], "title": "MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Structure-based drug design (SBDD), which maps target proteins to candidate\nmolecular ligands, is a fundamental task in drug discovery. Effectively\naligning protein structural representations with molecular representations, and\nensuring alignment between generated drugs and their pharmacological\nproperties, remains a critical challenge. To address these challenges, we\npropose MolChord, which integrates two key techniques: (1) to align protein and\nmolecule structures with their textual descriptions and sequential\nrepresentations (e.g., FASTA for proteins and SMILES for molecules), we\nleverage NatureLM, an autoregressive model unifying text, small molecules, and\nproteins, as the molecule generator, alongside a diffusion-based structure\nencoder; and (2) to guide molecules toward desired properties, we curate a\nproperty-aware dataset by integrating preference data and refine the alignment\nprocess using Direct Preference Optimization (DPO). Experimental results on\nCrossDocked2020 demonstrate that our approach achieves state-of-the-art\nperformance on key evaluation metrics, highlighting its potential as a\npractical tool for SBDD.", "AI": {"tldr": "MolChord是一个基于结构的药物设计方法，通过结合NatureLM语言模型和扩散编码器来对齐蛋白质和分子表示，并使用DPO优化药物性质，在CrossDocked2020数据集上达到SOTA性能。", "motivation": "解决蛋白质结构表示与分子表示的有效对齐问题，以及确保生成的药物与其药理学性质之间的匹配，这是药物发现中的关键挑战。", "method": "整合两种关键技术：(1)使用NatureLM自回归模型统一文本、小分子和蛋白质表示，结合扩散结构编码器；(2)通过整合偏好数据构建属性感知数据集，并使用直接偏好优化(DPO)改进对齐过程。", "result": "在CrossDocked2020数据集上的实验结果表明，该方法在关键评估指标上达到了最先进的性能。", "conclusion": "MolChord展示了作为实用SBDD工具的潜力，能够有效解决蛋白质-分子对齐和药物性质优化的问题。"}}
{"id": "2510.27355", "pdf": "https://arxiv.org/pdf/2510.27355", "abs": "https://arxiv.org/abs/2510.27355", "authors": ["Zijian Wang", "Chang Xu"], "title": "ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations", "categories": ["cs.CL"], "comment": "EMNLP2025 main conference", "summary": "This paper introduces ThoughtProbe, a novel inference time framework that\nleverages the hidden reasoning features of Large Language Models (LLMs) to\nimprove their reasoning performance. Unlike previous works that manipulate the\nhidden representations to steer LLM generation, we harness them as\ndiscriminative signals to guide the tree structured response space exploration.\nIn each node expansion, a classifier serves as a scoring and ranking mechanism\nthat efficiently allocates computational resources by prioritizing higher score\ncandidates for continuation. After completing the tree expansion, we collect\nanswers from all branches to form a candidate answer pool. We then propose a\nbranch aggregation method that marginalizes over all supporting branches by\naggregating their CoT scores, thereby identifying the optimal answer from the\npool. Experimental results show that our framework's comprehensive exploration\nnot only covers valid reasoning chains but also effectively identifies them,\nachieving significant improvements across multiple arithmetic reasoning\nbenchmarks.", "AI": {"tldr": "ThoughtProbe是一个推理时框架，利用LLM的隐藏推理特征来提升推理性能，通过分类器评分机制指导树状搜索，并通过分支聚合方法从候选池中选出最优答案", "motivation": "现有方法主要通过操纵隐藏表示来引导LLM生成，而本文希望利用这些隐藏特征作为判别信号来指导树状响应空间探索", "method": "1. 在节点扩展时使用分类器作为评分排序机制，优先处理高分候选；2. 完成树扩展后收集所有分支答案形成候选池；3. 提出分支聚合方法，通过聚合CoT分数在所有支持分支上进行边缘化处理", "result": "实验结果显示该框架能够全面覆盖有效推理链并有效识别它们，在多个算术推理基准上取得了显著改进", "conclusion": "ThoughtProbe框架通过利用LLM的隐藏推理特征和树状搜索策略，显著提升了大型语言模型的推理性能"}}
{"id": "2505.01314", "pdf": "https://arxiv.org/pdf/2505.01314", "abs": "https://arxiv.org/abs/2505.01314", "authors": ["Shang Wang", "Huanrong Tang", "Jianquan Ouyang"], "title": "A Transformer-based Neural Architecture Search Method", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "comment": "GECCO 2023", "summary": "This paper presents a neural architecture search method based on Transformer\narchitecture, searching cross multihead attention computation ways for\ndifferent number of encoder and decoder combinations. In order to search for\nneural network structures with better translation results, we considered\nperplexity as an auxiliary evaluation metric for the algorithm in addition to\nBLEU scores and iteratively improved each individual neural network within the\npopulation by a multi-objective genetic algorithm. Experimental results show\nthat the neural network structures searched by the algorithm outperform all the\nbaseline models, and that the introduction of the auxiliary evaluation metric\ncan find better models than considering only the BLEU score as an evaluation\nmetric.", "AI": {"tldr": "提出基于Transformer架构的神经架构搜索方法，使用多目标遗传算法搜索多头注意力计算方式和编码器-解码器组合，通过BLEU分数和困惑度双重评估指标优化神经网络结构，实验表明搜索到的结构优于基线模型。", "motivation": "为了寻找具有更好翻译结果的神经网络结构，需要开发更有效的架构搜索方法，传统方法仅依赖BLEU分数可能不够全面。", "method": "基于Transformer架构，使用多目标遗传算法搜索不同的多头注意力计算方式和编码器-解码器组合数量，同时使用BLEU分数和困惑度作为评估指标来迭代改进种群中的每个神经网络。", "result": "实验结果显示，算法搜索到的神经网络结构在所有基线模型上表现更优，且引入困惑度作为辅助评估指标比仅使用BLEU分数能找到更好的模型。", "conclusion": "提出的多目标神经架构搜索方法有效，双重评估指标策略能够发现性能更优的翻译模型结构，证明了辅助指标在架构搜索中的重要性。"}}
{"id": "2510.27369", "pdf": "https://arxiv.org/pdf/2510.27369", "abs": "https://arxiv.org/abs/2510.27369", "authors": ["Tosin Adewumi", "Martin Karlsson", "Marcus Liwicki", "Mikael Sjödahl", "Lama Alkhaled", "Rihab Gargouri", "Nudrat Habib", "Franz Hennie"], "title": "From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle", "categories": ["cs.CL"], "comment": "15 pages, 3 images", "summary": "We present a comprehensive systematic survey of the application of natural\nlanguage processing (NLP) along the entire battery life cycle, instead of one\nstage or method, and introduce a novel technical language processing (TLP)\nframework for the EU's proposed digital battery passport (DBP) and other\ngeneral battery predictions. We follow the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable\ndatabases or search engines, including Google Scholar, Institute of Electrical\nand Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we\nassessed 274 scientific papers before the critical review of the final 66\nrelevant papers. We publicly provide artifacts of the review for validation and\nreproducibility. The findings show that new NLP tasks are emerging in the\nbattery domain, which facilitate materials discovery and other stages of the\nlife cycle. Notwithstanding, challenges remain, such as the lack of standard\nbenchmarks. Our proposed TLP framework, which incorporates agentic AI and\noptimized prompts, will be apt for tackling some of the challenges.", "AI": {"tldr": "本文对自然语言处理在完整电池生命周期中的应用进行了系统性综述，提出了技术语言处理(TLP)框架用于欧盟数字电池护照和电池预测，通过PRISMA方法分析了274篇论文中的66篇相关研究。", "motivation": "针对电池领域缺乏对NLP技术在整个生命周期中应用的全面系统性研究，以及欧盟数字电池护照等新兴需求带来的技术挑战。", "method": "采用PRISMA系统综述方法，使用Google Scholar、IEEE Xplore和Scopus三个数据库，筛选评估了274篇科学论文，最终深入分析了66篇相关论文。", "result": "研究发现电池领域正在出现新的NLP任务，有助于材料发现和生命周期各阶段；但仍存在缺乏标准基准等挑战。提出的TLP框架结合智能代理AI和优化提示，能够应对部分挑战。", "conclusion": "NLP在电池生命周期应用中具有重要价值，新兴的TLP框架为解决现有挑战提供了有效途径，为电池领域的数字化和智能化发展提供了技术支撑。"}}
{"id": "2505.13487", "pdf": "https://arxiv.org/pdf/2505.13487", "abs": "https://arxiv.org/abs/2505.13487", "authors": ["Ashwin Kumar", "Yuzi He", "Aram H. Markosyan", "Bobbie Chern", "Imanol Arrieta-Ibarra"], "title": "Detecting Prefix Bias in LLM-based Reward Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key\nparadigm for task-specific fine-tuning of language models using human\npreference data. While numerous publicly available preference datasets provide\npairwise comparisons of responses, the potential for biases in the resulting\nreward models remains underexplored. In this work, we introduce novel methods\nto detect and evaluate prefix bias -- a systematic shift in model preferences\ntriggered by minor variations in query prefixes -- in LLM-based reward models\ntrained on such datasets. We leverage these metrics to reveal significant\nbiases in preference models across racial and gender dimensions. Our\ncomprehensive evaluation spans diverse open-source preference datasets and\nreward model architectures, demonstrating susceptibility to this kind of bias\nregardless of the underlying model architecture. Furthermore, we propose a data\naugmentation strategy to mitigate these biases, showing its effectiveness in\nreducing the impact of prefix bias. Our findings highlight the critical need\nfor bias-aware dataset design and evaluation in developing fair and reliable\nreward models, contributing to the broader discourse on fairness in AI.", "AI": {"tldr": "该论文研究了基于人类反馈的强化学习(RLHF)中奖励模型的前缀偏见问题，提出了检测和评估方法，揭示了种族和性别维度的显著偏见，并提出了数据增强策略来减轻这些偏见。", "motivation": "虽然已有许多公开的偏好数据集提供响应对的比较，但由此产生的奖励模型中潜在的偏见仍未得到充分探索，特别是在查询前缀微小变化引发的系统性偏好偏移方面。", "method": "引入新颖的方法来检测和评估基于LLM的奖励模型中的前缀偏见，利用这些指标揭示跨种族和性别维度的偏见，并提出了数据增强策略来减轻偏见。", "result": "研究发现在各种开源偏好数据集和奖励模型架构中都存在对这种偏见的易感性，无论底层模型架构如何。提出的数据增强策略在减少前缀偏见影响方面显示出有效性。", "conclusion": "研究结果强调了在开发公平可靠的奖励模型时，需要进行偏见意识的数据集设计和评估，为AI公平性的广泛讨论做出贡献。"}}
{"id": "2510.27400", "pdf": "https://arxiv.org/pdf/2510.27400", "abs": "https://arxiv.org/abs/2510.27400", "authors": ["Jiahao Liu", "Zijian Wang", "Kuo Zhao", "Dong Hu"], "title": "Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge editing has emerged as an efficient approach for updating factual\nknowledge in large language models (LLMs). It typically locates knowledge\nstorage modules and then modifies their parameters. However, most existing\nmethods focus on the weights of multilayer perceptron (MLP) modules, which are\noften identified as the main repositories of factual information. Other\ncomponents, such as attention (Attn) modules, are often ignored during editing.\nThis imbalance can leave residual outdated knowledge and limit editing\neffectiveness. We perform comprehensive knowledge localization experiments on\nadvanced LLMs and find that Attn modules play a substantial role in factual\nknowledge storage and retrieval, especially in earlier layers. Based on these\ninsights, we propose IntAttn-Edit, a method that extends the associative memory\nparadigm to jointly update both MLP and Attn modules. Our approach uses a\nknowledge balancing strategy that allocates update magnitudes in proportion to\neach module's measured contribution to knowledge storage. Experiments on\nstandard benchmarks show that IntAttn-Edit achieves higher edit success, better\ngeneralization, and stronger knowledge preservation than prior methods. Further\nanalysis shows that the balancing strategy keeps editing performance within an\noptimal range across diverse settings.", "AI": {"tldr": "IntAttn-Edit方法通过联合更新MLP和注意力模块，采用知识平衡策略提升大语言模型的知识编辑效果", "motivation": "现有知识编辑方法主要关注MLP模块权重修改，忽略了注意力模块在知识存储中的作用，导致残留过时知识和编辑效果受限", "method": "提出IntAttn-Edit方法，将关联记忆范式扩展到同时更新MLP和注意力模块，使用基于模块贡献比例的知识平衡策略分配更新幅度", "result": "在标准基准测试中，IntAttn-Edit相比现有方法实现了更高的编辑成功率、更好的泛化能力和更强的知识保持能力", "conclusion": "注意力模块在事实知识存储中起重要作用，联合更新MLP和注意力模块的知识平衡策略能够在多样化设置下保持最优编辑性能"}}
{"id": "2510.27407", "pdf": "https://arxiv.org/pdf/2510.27407", "abs": "https://arxiv.org/abs/2510.27407", "authors": ["Alp Öktem", "Farida Boudichat"], "title": "Awal -- Community-Powered Language Technology for Tamazight", "categories": ["cs.CL"], "comment": "Accepted to the International Conference on Information and\n  Communication Technologies for Amazigh (TICAM 25)", "summary": "This paper presents Awal, a community-powered initiative for developing\nlanguage technology resources for Tamazight. We provide a comprehensive review\nof the NLP landscape for Tamazight, examining recent progress in computational\nresources, and the emergence of community-driven approaches to address\npersistent data scarcity. Launched in 2024, awaldigital.org platform addresses\nthe underrepresentation of Tamazight in digital spaces through a collaborative\nplatform enabling speakers to contribute translation and voice data. We analyze\n18 months of community engagement, revealing significant barriers to\nparticipation including limited confidence in written Tamazight and ongoing\nstandardization challenges. Despite widespread positive reception, actual data\ncontribution remained concentrated among linguists and activists. The modest\nscale of community contributions -- 6,421 translation pairs and 3 hours of\nspeech data -- highlights the limitations of applying standard crowdsourcing\napproaches to languages with complex sociolinguistic contexts. We are working\non improved open-source MT models using the collected data.", "AI": {"tldr": "Awal是一个社区驱动的塔马齐格特语语言技术资源开发项目，通过awaldigital.org平台收集翻译和语音数据，但在18个月内仅获得6421对翻译和3小时语音数据，显示在复杂社会语言环境中标准众包方法的局限性", "motivation": "解决塔马齐格特语在数字空间中的代表性不足问题，应对该语言持续存在的数据稀缺挑战", "method": "建立社区驱动的协作平台awaldigital.org，让母语者贡献翻译和语音数据，并分析18个月的社区参与数据", "result": "尽管获得广泛积极反响，但实际数据贡献集中在语言学家和活动家中，仅收集到6421对翻译和3小时语音数据，揭示了参与障碍包括书面语信心不足和标准化挑战", "conclusion": "标准众包方法在复杂社会语言环境中的语言上存在局限性，需要改进方法，正在利用收集的数据开发改进的开源机器翻译模型"}}
{"id": "2510.27418", "pdf": "https://arxiv.org/pdf/2510.27418", "abs": "https://arxiv.org/abs/2510.27418", "authors": ["Junfeng Lu", "Yueyan Li"], "title": "Dynamic Affective Memory Management for Personalized LLM Agents", "categories": ["cs.CL"], "comment": "12 pasges, 8 figures", "summary": "Advances in large language models are making personalized AI agents a new\nresearch focus. While current agent systems primarily rely on personalized\nexternal memory databases to deliver customized experiences, they face\nchallenges such as memory redundancy, memory staleness, and poor memory-context\nintegration, largely due to the lack of effective memory updates during\ninteraction. To tackle these issues, we propose a new memory management system\ndesigned for affective scenarios. Our approach employs a Bayesian-inspired\nmemory update algorithm with the concept of memory entropy, enabling the agent\nto autonomously maintain a dynamically updated memory vector database by\nminimizing global entropy to provide more personalized services. To better\nevaluate the system's effectiveness in this context, we propose DABench, a\nbenchmark focusing on emotional expression and emotional change toward objects.\nExperimental results demonstrate that, our system achieves superior performance\nin personalization, logical coherence, and accuracy. Ablation studies further\nvalidate the effectiveness of the Bayesian-inspired update mechanism in\nalleviating memory bloat. Our work offers new insights into the design of\nlong-term memory systems.", "AI": {"tldr": "提出基于贝叶斯启发式记忆更新算法的新型记忆管理系统，通过最小化全局熵实现动态记忆更新，解决个性化AI代理中的记忆冗余、过时和上下文整合问题", "motivation": "当前AI代理系统依赖外部记忆数据库提供个性化体验，但存在记忆冗余、过时和记忆-上下文整合不佳的问题，主要由于缺乏交互过程中的有效记忆更新机制", "method": "采用贝叶斯启发的记忆更新算法，引入记忆熵概念，使代理能够通过最小化全局熵来自主维护动态更新的记忆向量数据库", "result": "实验结果显示系统在个性化、逻辑一致性和准确性方面表现优异，消融研究验证了贝叶斯更新机制在缓解记忆膨胀方面的有效性", "conclusion": "该工作为长期记忆系统设计提供了新的见解，提出的DABench基准测试专注于情感表达和情感变化评估，证明了系统在情感场景中的有效性"}}
{"id": "2510.27462", "pdf": "https://arxiv.org/pdf/2510.27462", "abs": "https://arxiv.org/abs/2510.27462", "authors": ["Xuan Gong", "Senmiao Wang", "Hanbo Huang", "Ruoyu Sun", "Shiyu Liang"], "title": "VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision", "categories": ["cs.CL", "cs.AI"], "comment": "Under Review", "summary": "Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has\nemerged as a crucial technique for enhancing the reasoning abilities of large\nlanguage models (LLMs). However, the standard cross-entropy loss treats all\ntokens equally, ignoring their heterogeneous contributions across a reasoning\ntrajectory. This uniform treatment leads to misallocated supervision and weak\ngeneralization, especially in complex, long-form reasoning tasks. To address\nthis, we introduce \\textbf{V}ariance-\\textbf{C}ontrolled\n\\textbf{O}ptimization-based \\textbf{RE}weighting (VCORE), a principled\nframework that reformulates CoT supervision as a constrained optimization\nproblem. By adopting an optimization-theoretic perspective, VCORE enables a\nprincipled and adaptive allocation of supervision across tokens, thereby\naligning the training objective more closely with the goal of robust reasoning\ngeneralization. Empirical evaluations demonstrate that VCORE consistently\noutperforms existing token reweighting methods. Across both in-domain and\nout-of-domain settings, VCORE achieves substantial performance gains on\nmathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,\n32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more\neffective initialization for subsequent reinforcement learning, establishing a\nstronger foundation for advancing the reasoning capabilities of LLMs. The Code\nwill be released at https://github.com/coder-gx/VCORE.", "AI": {"tldr": "VCORE是一种基于优化理论的token重加权框架，通过方差控制的约束优化重新分配监督信号，提升大语言模型在长思维链推理任务中的泛化能力。", "motivation": "标准的交叉熵损失函数对所有token一视同仁，忽略了思维链轨迹中不同token的异质性贡献，导致监督信号分配不当和泛化能力弱，特别是在复杂长推理任务中。", "method": "提出VCORE框架，将思维链监督重新构建为约束优化问题，从优化理论角度实现token监督的自适应分配，使训练目标更符合鲁棒推理泛化的目标。", "result": "在数学和编程基准测试中，使用Qwen3系列和LLaMA-3.1-8B-Instruct模型，VCORE在域内和域外设置下均显著优于现有token重加权方法，并作为强化学习的更有效初始化。", "conclusion": "VCORE通过优化理论视角重新设计监督信号分配机制，为大语言模型推理能力的提升提供了更强的基础，代码将开源发布。"}}
{"id": "2510.27469", "pdf": "https://arxiv.org/pdf/2510.27469", "abs": "https://arxiv.org/abs/2510.27469", "authors": ["Chenyang Shao", "Sijian Ren", "Fengli Xu", "Yong Li"], "title": "Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "In recent years, large language models (LLMs) have witnessed remarkable\nadvancements, with the test-time scaling law consistently enhancing the\nreasoning capabilities. Through systematic evaluation and exploration of a\ndiverse spectrum of intermediate thoughts, LLMs demonstrate the potential to\ngenerate deliberate reasoning steps, thereby substantially enhancing reasoning\naccuracy. However, LLMs' autoregressive generation paradigm results in\nreasoning performance scaling sub-optimally with test-time computation, often\nrequiring excessive computational overhead to propose thoughts while yielding\nonly marginal performance gains. In contrast, diffusion language models (DLMs)\ncan efficiently produce diverse samples through parallel denoising in a single\nforward pass, inspiring us to leverage them for proposing intermediate\nthoughts, thereby alleviating the computational burden associated with\nautoregressive generation while maintaining quality. In this work, we propose\nan efficient collaborative reasoning framework, leveraging DLMs to generate\ncandidate thoughts and LLMs to evaluate their quality. Experiments across\ndiverse benchmarks demonstrate that our framework achieves strong performance\nin complex reasoning tasks, offering a promising direction for future research.\nOur code is open-source at\nhttps://anonymous.4open.science/r/Diffuse-Thinking-EC60.", "AI": {"tldr": "提出了一种基于扩散语言模型和大型语言模型协作的高效推理框架，通过DLMs并行生成候选思维，LLMs评估质量，显著降低计算开销同时保持推理性能。", "motivation": "传统LLMs的自回归生成范式在推理任务中计算效率低下，需要大量计算开销但性能提升有限。DLMs能够通过单次前向传播并行生成多样样本，为解决这一问题提供了新思路。", "method": "设计协作推理框架：使用扩散语言模型（DLMs）高效生成多样化的候选中间思维步骤，然后利用大型语言模型（LLMs）对这些候选思维进行质量评估和选择。", "result": "在多个基准测试中，该框架在复杂推理任务上表现出强大的性能，同时显著降低了计算负担。", "conclusion": "该研究为高效推理提供了一个有前景的新方向，证明了DLMs和LLMs协作框架的有效性，代码已开源供进一步研究。"}}
{"id": "2510.27477", "pdf": "https://arxiv.org/pdf/2510.27477", "abs": "https://arxiv.org/abs/2510.27477", "authors": ["Swarang Joshi"], "title": "The aftermath of compounds: Investigating Compounds and their Semantic Representations", "categories": ["cs.CL"], "comment": "IJCNLP-AACL SRW 2025", "summary": "This study investigates how well computational embeddings align with human\nsemantic judgments in the processing of English compound words. We compare\nstatic word vectors (GloVe) and contextualized embeddings (BERT) against human\nratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn\nfrom a psycholinguistic dataset. Using measures of association strength\n(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),\nwe compute embedding-derived LMD and ST metrics and assess their relationships\nwith human judgments via Spearmans correlation and regression analyses. Our\nresults show that BERT embeddings better capture compositional semantics than\nGloVe, and that predictability ratings are strong predictors of semantic\ntransparency in both human and model data. These findings advance computational\npsycholinguistics by clarifying the factors that drive compound word processing\nand offering insights into embedding-based semantic modeling.", "AI": {"tldr": "本研究比较了GloVe和BERT嵌入在英语复合词语义处理中与人类语义判断的一致性，发现BERT比GloVe能更好地捕捉组合语义，可预测性评分是语义透明度的强预测因子。", "motivation": "研究计算嵌入模型（静态词向量和上下文嵌入）与人类语义判断在英语复合词处理中的对齐程度，以推进计算心理语言学发展。", "method": "使用GloVe和BERT嵌入，基于爱丁堡联想词库的关联强度、BNC频率和LaDEC可预测性度量，计算嵌入衍生的LMD和ST指标，并通过Spearman相关性和回归分析与人类评分进行比较。", "result": "BERT嵌入在捕捉组合语义方面优于GloVe，可预测性评分在人类和模型数据中都是语义透明度的强预测因子。", "conclusion": "研究结果阐明了驱动复合词处理的因素，为基于嵌入的语义建模提供了见解，推动了计算心理语言学的发展。"}}
{"id": "2510.27512", "pdf": "https://arxiv.org/pdf/2510.27512", "abs": "https://arxiv.org/abs/2510.27512", "authors": ["Mahi Aminu", "Chisom Chibuike", "Fatimo Adebanjo", "Omokolade Awosanya", "Samuel Oyeneye"], "title": "Effect of Domain Generalization Techniques in Low Resource Systems", "categories": ["cs.CL"], "comment": null, "summary": "Machine learning models typically assume that training and test data follow\nthe same distribution, an assumption that often fails in real-world scenarios\ndue to distribution shifts. This issue is especially pronounced in low-resource\nsettings, where data scarcity and limited domain diversity hinder robust\ngeneralization. Domain generalization (DG) approaches address this challenge by\nlearning features that remain invariant across domains, often using causal\nmechanisms to improve model robustness. In this study, we examine two distinct\ncausal DG techniques in low-resource natural language tasks. First, we\ninvestigate a causal data augmentation (CDA) approach that automatically\ngenerates counterfactual examples to improve robustness to spurious\ncorrelations. We apply this method to sentiment classification on the\nNaijaSenti Twitter corpus, expanding the training data with semantically\nequivalent paraphrases to simulate controlled distribution shifts. Second, we\nexplore an invariant causal representation learning (ICRL) approach using the\nDINER framework, originally proposed for debiasing aspect-based sentiment\nanalysis. We adapt DINER to a multilingual setting. Our findings demonstrate\nthat both approaches enhance robustness to unseen domains: counterfactual data\naugmentation yields consistent cross-domain accuracy gains in sentiment\nclassification, while causal representation learning with DINER improves\nout-of-distribution performance in multilingual sentiment analysis, albeit with\nvarying gains across languages.", "AI": {"tldr": "本研究在低资源自然语言处理任务中比较了两种因果域泛化方法：因果数据增强(CDA)生成反事实样本来改善虚假相关性的鲁棒性，以及不变因果表示学习(ICRL)方法DINER框架。两种方法在不同任务中都提升了未见域的泛化性能。", "motivation": "现实场景中训练和测试数据分布不一致的问题在低资源环境下尤为突出，数据稀缺和领域多样性有限阻碍了模型的鲁棒泛化能力。", "method": "1. 因果数据增强(CDA)：自动生成反事实示例，在NaijaSenti Twitter语料库的情感分类任务中通过语义等价复述扩展训练数据；2. 不变因果表示学习(ICRL)：采用DINER框架并适配到多语言环境进行基于方面的情感分析。", "result": "两种方法都增强了未见领域的鲁棒性：反事实数据增强在情感分类中带来一致的跨域准确率提升；DINER因果表示学习在多语言情感分析中改善了分布外性能，尽管不同语言的增益有所差异。", "conclusion": "因果域泛化方法在低资源NLP任务中有效，通过不同的因果机制（数据增强和表示学习）都能提升模型对分布偏移的鲁棒性，为实际应用提供了有前景的解决方案。"}}
{"id": "2510.27516", "pdf": "https://arxiv.org/pdf/2510.27516", "abs": "https://arxiv.org/abs/2510.27516", "authors": ["Desta Haileselassie Hagos", "Legand L. Burge", "Anietie Andy", "Anis Yazidi", "Vladimir Vlassov"], "title": "BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at the IEEE International Conference on Data Mining (ICDM)\n  2025, Washington, DC, USA", "summary": "Transformer-based architectures have advanced text summarization, yet their\nquadratic complexity limits scalability on long documents. This paper\nintroduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a\nnovel framework that combines sparse attention, adaptive spans, and bilinear\nattention to address these limitations. Sparse attention reduces computational\ncosts by focusing on the most relevant parts of the input, while adaptive spans\ndynamically adjust the attention ranges. Bilinear attention complements both by\nmodeling complex token interactions within this refined context. BiSparse-AAS\nconsistently outperforms state-of-the-art baselines in both extractive and\nabstractive summarization tasks, achieving average ROUGE improvements of about\n68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance\non OpenWebText and Gigaword datasets. By addressing efficiency, scalability,\nand long-sequence modeling, BiSparse-AAS provides a unified, practical solution\nfor real-world text summarization applications.", "AI": {"tldr": "BiSparse-AAS是一个结合稀疏注意力、自适应范围和双线性注意力的新型Transformer框架，显著提升长文本摘要的效率和质量，在多个数据集上超越现有最佳模型。", "motivation": "传统Transformer架构在文本摘要中存在二次计算复杂度问题，限制了其在长文档上的可扩展性，需要一种更高效的注意力机制来解决这些问题。", "method": "提出BiSparse-AAS框架，整合三种技术：稀疏注意力减少计算成本，自适应范围动态调整注意力范围，双线性注意力在精炼上下文中建模复杂标记交互。", "result": "在抽取式和生成式摘要任务中均优于最先进基线模型，CNN/DailyMail数据集ROUGE提升约68.1%，XSum数据集提升52.6%，在OpenWebText和Gigaword数据集上也保持强劲性能。", "conclusion": "BiSparse-AAS通过解决效率、可扩展性和长序列建模问题，为现实世界的文本摘要应用提供了一个统一且实用的解决方案。"}}
{"id": "2510.27532", "pdf": "https://arxiv.org/pdf/2510.27532", "abs": "https://arxiv.org/abs/2510.27532", "authors": ["Neha Srikanth", "Victor Bursztyn", "Puneet Mathur", "Ani Nenkova"], "title": "SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps", "categories": ["cs.CL"], "comment": "Accepted to EMNLP Findings", "summary": "We introduce SQLSpace, a human-interpretable, generalizable, compact\nrepresentation for text-to-SQL examples derived with minimal human\nintervention. We demonstrate the utility of these representations in evaluation\nwith three use cases: (i) closely comparing and contrasting the composition of\npopular text-to-SQL benchmarks to identify unique dimensions of examples they\nevaluate, (ii) understanding model performance at a granular level beyond\noverall accuracy scores, and (iii) improving model performance through targeted\nquery rewriting based on learned correctness estimation. We show that SQLSpace\nenables analysis that would be difficult with raw examples alone: it reveals\ncompositional differences between benchmarks, exposes performance patterns\nobscured by accuracy alone, and supports modeling of query success.", "AI": {"tldr": "SQLSpace是一个从文本到SQL示例中自动提取的人类可解释、可泛化、紧凑的表示方法，可用于比较基准测试、分析模型性能和改进查询重写。", "motivation": "现有的文本到SQL基准测试评估缺乏细粒度的分析工具，无法深入理解模型性能差异和基准测试的组成特点。", "method": "开发SQLSpace表示方法，通过最小化人工干预从文本到SQL示例中提取人类可解释的特征表示。", "result": "SQLSpace能够揭示不同基准测试之间的组成差异，发现仅凭准确率无法观察到的性能模式，并支持查询成功率的建模。", "conclusion": "SQLSpace为文本到SQL任务提供了强大的分析工具，能够支持更深入的基准测试比较、细粒度性能分析和模型改进策略。"}}
{"id": "2510.27535", "pdf": "https://arxiv.org/pdf/2510.27535", "abs": "https://arxiv.org/abs/2510.27535", "authors": ["Maria Lizarazo Jimenez", "Ana Gabriela Claros", "Kieran Green", "David Toro-Tobon", "Felipe Larios", "Sheena Asthana", "Camila Wenczenovicz", "Kerly Guevara Maldonado", "Luis Vilatuna-Andrango", "Cristina Proano-Velez", "Satya Sai Sri Bandi", "Shubhangi Bagewadi", "Megan E. Branda", "Misk Al Zahidy", "Saturnino Luz", "Mirella Lapata", "Juan P. Brito", "Oscar J. Ponce-Ponte"], "title": "Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design", "categories": ["cs.CL"], "comment": "The first two listed authors contributed equally Pages: 21;\n  Figures:2; Tables:3", "summary": "Large Language Models (LLMs) are increasingly demonstrating the potential to\nreach human-level performance in generating clinical summaries from\npatient-clinician conversations. However, these summaries often focus on\npatients' biology rather than their preferences, values, wishes, and concerns.\nTo achieve patient-centered care, we propose a new standard for Artificial\nIntelligence (AI) clinical summarization tasks: Patient-Centered Summaries\n(PCS). Our objective was to develop a framework to generate PCS that capture\npatient values and ensure clinical utility and to assess whether current\nopen-source LLMs can achieve human-level performance in this task. We used a\nmixed-methods process. Two Patient and Public Involvement groups (10 patients\nand 8 clinicians) in the United Kingdom participated in semi-structured\ninterviews exploring what personal and contextual information should be\nincluded in clinical summaries and how it should be structured for clinical\nuse. Findings informed annotation guidelines used by eight clinicians to create\ngold-standard PCS from 88 atrial fibrillation consultations. Sixteen\nconsultations were used to refine a prompt aligned with the guidelines. Five\nopen-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and\nQwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot\nprompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients\nemphasized lifestyle routines, social support, recent stressors, and care\nvalues. Clinicians sought concise functional, psychosocial, and emotional\ncontext. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L\n0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B\n(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between\nexperts and models, while correctness and patient-centeredness favored human\nPCS.", "AI": {"tldr": "该研究提出了患者中心摘要(PCS)新标准，通过混合方法开发框架，评估开源LLM在生成包含患者偏好和价值观的临床摘要方面是否能达到人类水平表现。", "motivation": "现有LLM生成的临床摘要过于关注患者生物学信息，而忽视了患者的偏好、价值观、愿望和关切，无法实现真正的以患者为中心的护理。", "method": "采用混合方法：通过患者和临床医生访谈确定摘要内容标准，制定标注指南，由临床医生创建黄金标准PCS，使用5个开源LLM进行零样本和少样本提示生成摘要，并通过ROUGE-L、BERTScore和定性指标进行评估。", "result": "最佳零样本表现由Mistral-8B和Llama-3.1-8B取得，最佳少样本表现由Llama-3.1-8B取得。模型在完整性和流畅性方面与专家相当，但在正确性和患者中心性方面仍不如人类生成的摘要。", "conclusion": "当前开源LLM在生成患者中心临床摘要方面显示出潜力，但在捕捉患者价值观和确保临床准确性方面仍需改进，需要进一步开发以实现真正的人类水平表现。"}}
{"id": "2510.27543", "pdf": "https://arxiv.org/pdf/2510.27543", "abs": "https://arxiv.org/abs/2510.27543", "authors": ["Malik H. Altakrori", "Nizar Habash", "Abdelhakim Freihat", "Younes Samih", "Kirill Chirkunov", "Muhammed AbuOdeh", "Radu Florian", "Teresa Lynn", "Preslav Nakov", "Alham Fikri Aji"], "title": "DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 9 tables", "summary": "We present DialectalArabicMMLU, a new benchmark for evaluating the\nperformance of large language models (LLMs) across Arabic dialects. While\nrecently developed Arabic and multilingual benchmarks have advanced LLM\nevaluation for Modern Standard Arabic (MSA), dialectal varieties remain\nunderrepresented despite their prevalence in everyday communication.\nDialectalArabicMMLU extends the MMLU-Redux framework through manual translation\nand adaptation of 3K multiple-choice question-answer pairs into five major\ndialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of\n15K QA pairs across 32 academic and professional domains (22K QA pairs when\nalso including English and MSA). The benchmark enables systematic assessment of\nLLM reasoning and comprehension beyond MSA, supporting both task-based and\nlinguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs\n(1B-13B parameters) and report substantial performance variation across\ndialects, revealing persistent gaps in dialectal generalization.\nDialectalArabicMMLU provides the first unified, human-curated resource for\nmeasuring dialectal understanding in Arabic, thus promoting more inclusive\nevaluation and future model development.", "AI": {"tldr": "DialectalArabicMMLU是一个新的阿拉伯语方言评估基准，通过手动翻译和改编3K个多选题到5种主要方言，创建了15K个QA对，用于系统评估大语言模型在阿拉伯方言上的表现。", "motivation": "现有的阿拉伯语和多语言基准主要关注现代标准阿拉伯语(MSA)，但方言在日常交流中广泛使用却缺乏代表性评估，需要填补这一空白。", "method": "基于MMLU-Redux框架，手动翻译和改编3K个多选题到叙利亚、埃及、阿联酋、沙特和摩洛哥五种方言，涵盖32个学术和专业领域。", "result": "评估了19个开源阿拉伯语和多语言LLM(1B-13B参数)，发现不同方言间存在显著的性能差异，揭示了方言泛化方面的持续差距。", "conclusion": "DialectalArabicMMLU提供了首个统一的人工策划资源，用于衡量阿拉伯方言理解能力，促进更包容的评估和未来模型发展。"}}
{"id": "2510.27552", "pdf": "https://arxiv.org/pdf/2510.27552", "abs": "https://arxiv.org/abs/2510.27552", "authors": ["Yinghao Luo", "Lang Zhou", "Amrish Jhingoer", "Klaske Vliegenthart Jongbloed", "Carlijn Jordans", "Ben Werkhoven", "Tom Seinen", "Erik van Mulligen", "Casper Rokx", "Yunlei Li"], "title": "Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality", "categories": ["cs.CL"], "comment": null, "summary": "In multilingual healthcare applications, the availability of domain-specific\nnatural language processing(NLP) tools is limited, especially for low-resource\nlanguages. Although multilingual bidirectional encoder representations from\ntransformers (BERT) offers a promising motivation to mitigate the language gap,\nthe medical NLP tasks in low-resource languages are still underexplored.\nTherefore, this study investigates how further pre-training on domain-specific\ncorpora affects model performance on medical tasks, focusing on three\nlanguages: Dutch, Romanian and Spanish. In terms of further pre-training, we\nconducted four experiments to create medical domain models. Then, these models\nwere fine-tuned on three downstream tasks: Automated patient screening in Dutch\nclinical notes, named entity recognition in Romanian and Spanish clinical\nnotes. Results show that domain adaptation significantly enhanced task\nperformance. Furthermore, further differentiation of domains, e.g. clinical and\ngeneral biomedical domains, resulted in diverse performances. The clinical\ndomain-adapted model outperformed the more general biomedical domain-adapted\nmodel. Moreover, we observed evidence of cross-lingual transferability.\nMoreover, we also conducted further investigations to explore potential reasons\ncontributing to these performance differences. These findings highlight the\nfeasibility of domain adaptation and cross-lingual ability in medical NLP.\nWithin the low-resource language settings, these findings can provide\nmeaningful guidance for developing multilingual medical NLP systems to mitigate\nthe lack of training data and thereby improve the model performance.", "AI": {"tldr": "该研究探讨了在多语言医疗NLP中，通过对多语言BERT模型进行领域特定预训练来提升低资源语言医疗任务性能的效果，发现领域适应能显著提升模型表现，且临床领域适应优于一般生物医学领域适应。", "motivation": "多语言医疗应用中，特别是低资源语言的领域特定NLP工具有限，医疗NLP任务在低资源语言中仍未充分探索，需要解决语言差距问题。", "method": "使用荷兰语、罗马尼亚语和西班牙语三种语言，进行四种领域的进一步预训练实验创建医疗领域模型，然后在三个下游任务上进行微调：荷兰临床笔记的自动患者筛查、罗马尼亚和西班牙临床笔记的命名实体识别。", "result": "领域适应显著提升了任务性能，临床领域适应的模型表现优于一般生物医学领域适应的模型，同时观察到跨语言可迁移性的证据。", "conclusion": "研究结果突显了领域适应和跨语言能力在医疗NLP中的可行性，为开发多语言医疗NLP系统提供了有意义的指导，以缓解训练数据不足的问题并提升模型性能。"}}
{"id": "2510.27556", "pdf": "https://arxiv.org/pdf/2510.27556", "abs": "https://arxiv.org/abs/2510.27556", "authors": ["Inacio Vieira", "Antonio Castaldo", "James O'Doherty", "Sheila Castilho"], "title": "Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "LLMs often require adaptation to domain-specific requirements, a process that\ncan be expensive when relying solely on SFT. We present an empirical study on\napplying CPO to simulate a post-editing workflow for data-efficient domain\nadaptation. Our approach synthesizes preference pairs by treating the base\nmodel's own raw output as the 'rejected' translation and the human-approved TM\nentry as the 'chosen' one. This method provides direct feedback on the model's\ncurrent knowledge, guiding it to align with domain-specific standards.\nExperiments in English-Brazilian Portuguese and English-Korean show that, by\nusing just 14.7k preference pairs, the model achieves performance close to that\nof a model trained on 160k+ samples with SFT, demonstrating significant data\nefficiency. Although we showcase its effectiveness in MT, this application of\nCPO naturally generalizes to other generative tasks where a model's initial\ndrafts can serve as a contrastive signal against a golden reference.", "AI": {"tldr": "本研究提出使用CPO（对比偏好优化）方法进行数据高效的领域自适应，通过将基础模型的原始输出作为被拒绝样本、人工审校的翻译记忆条目作为优选样本，仅需14.7k偏好对即可达到与160k+ SFT样本相当的性能。", "motivation": "传统SFT方法进行领域自适应成本高昂，需要寻找更数据高效的方法来适应领域特定需求。", "method": "采用CPO方法模拟后编辑工作流程，合成偏好对：基础模型原始输出作为rejected样本，人工批准的TM条目作为chosen样本，为模型提供直接反馈。", "result": "在英-巴西葡萄牙语和英-韩语翻译任务中，仅使用14.7k偏好对就达到了与160k+ SFT样本训练模型相近的性能，数据效率显著提升。", "conclusion": "CPO方法在机器翻译领域展现出显著的数据效率优势，且该方法可自然推广到其他生成任务，其中模型的初始草稿可以作为与黄金参考的对比信号。"}}
{"id": "2510.27569", "pdf": "https://arxiv.org/pdf/2510.27569", "abs": "https://arxiv.org/abs/2510.27569", "authors": ["Qi Luo", "Xiaonan Li", "Yuxin Wang", "Tingshuo Fan", "Yuan Li", "Xinchi Chen", "Xipeng Qiu"], "title": "MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel at reasoning and generation but are\ninherently limited by static pretraining data, resulting in factual\ninaccuracies and weak adaptability to new information. Retrieval-Augmented\nGeneration (RAG) addresses this issue by grounding LLMs in external knowledge;\nHowever, the effectiveness of RAG critically depends on whether the model can\nadequately access relevant information. Existing RAG systems rely on a single\nretriever with fixed top-k selection, restricting access to a narrow and static\nsubset of the corpus. As a result, this single-retriever paradigm has become\nthe primary bottleneck for comprehensive external information acquisition,\nespecially in tasks requiring corpus-level reasoning. To overcome this\nlimitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG\nframework that enables LLMs to dynamically coordinate multiple retrieval\nmechanisms for broader and more precise information access. MARAG-R1 equips the\nmodel with four retrieval tools -- semantic search, keyword search, filtering,\nand aggregation -- and learns both how and when to use them through a two-stage\ntraining process: supervised fine-tuning followed by reinforcement learning.\nThis design allows the model to interleave reasoning and retrieval,\nprogressively gathering sufficient evidence for corpus-level synthesis.\nExperiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that\nMARAG-R1 substantially outperforms strong baselines and achieves new\nstate-of-the-art results in corpus-level reasoning tasks.", "AI": {"tldr": "MARAG-R1是一个基于强化学习的多工具检索增强生成框架，通过让大语言模型动态协调多种检索机制来解决传统RAG系统单一检索器限制的问题，显著提升了语料级推理任务的性能。", "motivation": "传统RAG系统依赖单一检索器和固定top-k选择，导致信息获取范围有限且静态，成为全面外部信息获取的主要瓶颈，特别是在需要语料级推理的任务中。", "method": "提出MARAG-R1框架，配备四种检索工具（语义搜索、关键词搜索、过滤和聚合），通过两阶段训练过程（监督微调+强化学习）学习如何和何时使用这些工具，实现推理与检索的交错进行。", "result": "在GlobalQA、HotpotQA和2WikiMultiHopQA数据集上的实验表明，MARAG-R1显著优于强基线方法，在语料级推理任务中取得了新的最先进结果。", "conclusion": "多工具动态协调的RAG框架能够有效克服单一检索器的局限性，为LLMs提供更广泛和精确的外部信息访问能力，从而提升事实准确性和对新信息的适应能力。"}}
{"id": "2510.27688", "pdf": "https://arxiv.org/pdf/2510.27688", "abs": "https://arxiv.org/abs/2510.27688", "authors": ["Chenze Shao", "Darren Li", "Fandong Meng", "Jie Zhou"], "title": "Continuous Autoregressive Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The efficiency of large language models (LLMs) is fundamentally limited by\ntheir sequential, token-by-token generation process. We argue that overcoming\nthis bottleneck requires a new design axis for LLM scaling: increasing the\nsemantic bandwidth of each generative step. To this end, we introduce\nContinuous Autoregressive Language Models (CALM), a paradigm shift from\ndiscrete next-token prediction to continuous next-vector prediction. CALM uses\na high-fidelity autoencoder to compress a chunk of K tokens into a single\ncontinuous vector, from which the original tokens can be reconstructed with\nover 99.9\\% accuracy. This allows us to model language as a sequence of\ncontinuous vectors instead of discrete tokens, which reduces the number of\ngenerative steps by a factor of K. The paradigm shift necessitates a new\nmodeling toolkit; therefore, we develop a comprehensive likelihood-free\nframework that enables robust training, evaluation, and controllable sampling\nin the continuous domain. Experiments show that CALM significantly improves the\nperformance-compute trade-off, achieving the performance of strong discrete\nbaselines at a significantly lower computational cost. More importantly, these\nfindings establish next-vector prediction as a powerful and scalable pathway\ntowards ultra-efficient language models. Code:\nhttps://github.com/shaochenze/calm. Project:\nhttps://shaochenze.github.io/blog/2025/CALM.", "AI": {"tldr": "CALM模型通过将离散的逐词生成改为连续的向量预测，用高保真自编码器将K个token压缩为一个连续向量，显著减少生成步骤数量，提高计算效率", "motivation": "大型语言模型的效率受限于其顺序的逐词生成过程，需要突破这一瓶颈来提高语义带宽", "method": "引入连续自回归语言模型(CALM)，使用高保真自编码器将token块压缩为连续向量，开发无似然框架进行训练、评估和采样", "result": "CALM显著改善了性能-计算权衡，以显著更低的计算成本实现了强大离散基线的性能", "conclusion": "下一向量预测是构建超高效语言模型的一个强大且可扩展的途径"}}
{"id": "2510.27641", "pdf": "https://arxiv.org/pdf/2510.27641", "abs": "https://arxiv.org/abs/2510.27641", "authors": ["Harsh Shah"], "title": "SpecAttn: Speculating Sparse Attention", "categories": ["cs.CL", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to NeurIPS 2025 Workshop on Structured Probabilistic\n  Inference & Generative Modeling", "summary": "Large Language Models (LLMs) face significant computational bottlenecks\nduring inference due to the quadratic complexity of self-attention mechanisms,\nparticularly as context lengths increase. We introduce SpecAttn, a novel\ntraining-free approach that seamlessly integrates with existing speculative\ndecoding techniques to enable efficient sparse attention in pre-trained\ntransformers. Our key insight is to exploit the attention weights already\ncomputed by the draft model during speculative decoding to identify important\ntokens for the target model, eliminating redundant computation while\nmaintaining output quality. SpecAttn employs three core techniques: KL\ndivergence-based layer alignment between draft and target models, a\nGPU-optimized sorting-free algorithm for top-p token selection from draft\nattention patterns, and dynamic key-value cache pruning guided by these\npredictions. By leveraging the computational work already performed in standard\nspeculative decoding pipelines, SpecAttn achieves over 75% reduction in\nkey-value cache accesses with a mere 15.29% increase in perplexity on the PG-19\ndataset, significantly outperforming existing sparse attention methods. Our\napproach demonstrates that speculative execution can be enhanced to provide\napproximate verification without significant performance degradation.", "AI": {"tldr": "SpecAttn是一种无需训练的方法，通过利用推测解码中已计算的注意力权重来识别重要token，实现预训练Transformer中的高效稀疏注意力，在保持输出质量的同时大幅减少计算量。", "motivation": "大型语言模型在推理时面临自注意力机制的二次计算复杂度瓶颈，特别是随着上下文长度增加，计算开销急剧增长。", "method": "使用KL散度进行草稿模型和目标模型的层对齐、GPU优化的无排序top-p token选择算法、基于预测的动态键值缓存剪枝，利用推测解码中已计算的注意力权重。", "result": "在PG-19数据集上实现了超过75%的键值缓存访问减少，仅增加15.29%的困惑度，显著优于现有稀疏注意力方法。", "conclusion": "研究表明推测执行可以通过近似验证得到增强，而不会导致显著的性能下降，为高效推理提供了新思路。"}}
{"id": "2510.27672", "pdf": "https://arxiv.org/pdf/2510.27672", "abs": "https://arxiv.org/abs/2510.27672", "authors": ["Caleb Ziems", "William Held", "Jane Yu", "Amir Goldberg", "David Grusky", "Diyi Yang"], "title": "Culture Cartography: Mapping the Landscape of Cultural Knowledge", "categories": ["cs.CL"], "comment": "EMNLP 2025", "summary": "To serve global users safely and productively, LLMs need culture-specific\nknowledge that might not be learned during pre-training. How do we find such\nknowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The\nmost common solutions are single-initiative: either researchers define\nchallenging questions that users passively answer (traditional annotation), or\nusers actively produce data that researchers structure as benchmarks (knowledge\nextraction). The process would benefit from mixed-initiative collaboration,\nwhere users guide the process to meaningfully reflect their cultures, and LLMs\nsteer the process towards more challenging questions that meet the researcher's\ngoals. We propose a mixed-initiative methodology called CultureCartography.\nHere, an LLM initializes annotation with questions for which it has\nlow-confidence answers, making explicit both its prior knowledge and the gaps\ntherein. This allows a human respondent to fill these gaps and steer the model\ntowards salient topics through direct edits. We implement this methodology as a\ntool called CultureExplorer. Compared to a baseline where humans answer\nLLM-proposed questions, we find that CultureExplorer more effectively produces\nknowledge that leading models like DeepSeek R1 and GPT-4o are missing, even\nwith web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B\nby up to 19.2% on related culture benchmarks.", "AI": {"tldr": "CultureCartography是一种混合主动方法，通过LLM提出低置信度问题，人类编辑指导，有效发现LLM缺失的文化知识，提升模型文化理解能力", "motivation": "LLM需要文化特定知识但预训练可能缺失，现有单主动方法（研究者定义问题或用户提供数据）不够有效，需要混合协作方法", "method": "提出CultureCartography方法：LLM初始化标注低置信度问题，人类填写并指导模型关注重要主题，实现为CultureExplorer工具", "result": "相比基线方法，CultureExplorer更有效发现DeepSeek R1和GPT-4o缺失的知识，使用该数据微调使Llama-3.1-8B在文化基准上准确率提升达19.2%", "conclusion": "混合主动协作方法能有效识别和填补LLM的文化知识空白，提升模型的文化适应性和实用性"}}
