<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 60]
- [cs.AI](#cs.AI) [总数: 50]
- [stat.ML](#stat.ML) [总数: 17]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models](https://arxiv.org/abs/2505.15845)
*Zhibiao Wang, Yunlong Zhou, Ziwei Zhang, Mengmei Zhang, Shirui Pan, Chunming Hu, Xiao Wang*

**主要类别:** cs.LG

**概要:** 提出Learnable Graph Token List (LGTL)，解决现有Tokenized Graph Learning Models中手动生成的token列表在异质图上的hop-overpriority问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Tokenized Graph Learning Models依赖于手工设计的token列表，这些列表在处理异质图时存在优先关注近邻节点的问题，影响了模型平衡局部和全局信号的能力。

**方法:** 提出Learnable Graph Token List (LGTL)，通过图注意力门模块和选择模块自适应调整跨跳权重并优先选择信息量大的节点。

**结果:** LGTL在多种基准数据集上验证了其有效性，适用于基于Graph Transformers和Graph LLM的主干网络。

**结论:** LGTL解决了现有方法中的hop-overpriority问题，并提高了对异质图的适应性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Tokenization%3A+On+the+Hop-Overpriority+Problem+in+Tokenized+Graph+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15845，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15845&send_immediately=true&force_search=false)

**原文摘要:** Graph Transformers, leveraging the global attention to capture long-range
dependencies in graph structures, have significantly advanced graph machine
learning, but face prohibitive computational complexity. Tokenized Graph
Learning Models (TGLMs) address this issue by converting graphs into ordered
token lists for scalable processing. Besides, TGLMs also empower Large Language
Models (LLMs) to handle text-attributed graphs more effectively and thus are
also employed in Graph LLMs. However, existing TGLMs rely on hand-designed
token lists and their adaptability to diverse graph learning scenarios remains
unexplored. In this paper, we first conduct extensive empirical and theoretical
preliminary studies for hand-designed token lists. Surprisingly, we identify an
unexplored hop-overpriority problem: the common pre-defined token lists
overemphasize nearby nodes and overwhelm the ability of TGLMs to balance local
and global signals. This phenomenon is especially harmful for heterophilic
graphs. To address this problem, we propose the Learnable Graph Token List
(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.
Specifically, LGTL adaptively adjusts the weights across hops and prioritizes
informative nodes within hops through a graph attention gate module and a
selection module, respectively. In this way, contextually informative nodes can
be adaptively emphasized for both homophilic and heterophilic graphs. Besides,
we theoretically show that LGTL can address the hop-overpriority problem.
Extensive experiments on benchmarks validate the efficacy of LGTL across both
Graph Transformers and Graph LLM backbones.

</details>


### [2] [Last Layer Empirical Bayes](https://arxiv.org/abs/2505.15888)
*Valentin Villecroze, Yixin Wang, Gabriel Loaiza-Ganem*

**主要类别:** cs.LG

**概要:** 提出了一种新的方法LLEB，它通过使用归一化流来实例化可学习先验，并在最后一层上训练以最大化证据下界，该方法在不确定性量化方面表现良好。


<details>
  <summary>更多</summary>
  
**动机:** 量化神经网络预测所固有的不确定性是人工智能中的一个关键挑战。

**方法:** 提出了一种新的方法LLEB，它通过使用归一化流来实例化可学习先验，并在最后一层上训练以最大化证据下界。

**结果:** LLEB在不确定性量化方面表现良好。

**结论:** LLEB是经验贝叶斯的一个有前途的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Last+Layer+Empirical+Bayes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15888，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15888&send_immediately=true&force_search=false)

**原文摘要:** The task of quantifying the inherent uncertainty associated with neural
network predictions is a key challenge in artificial intelligence. Bayesian
neural networks (BNNs) and deep ensembles are among the most prominent
approaches to tackle this task. Both approaches produce predictions by
computing an expectation of neural network outputs over some distribution on
the corresponding weights; this distribution is given by the posterior in the
case of BNNs, and by a mixture of point masses for ensembles. Inspired by
recent work showing that the distribution used by ensembles can be understood
as a posterior corresponding to a learned data-dependent prior, we propose last
layer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a
normalizing flow, which is then trained to maximize the evidence lower bound;
to retain tractability we use the flow only on the last layer. We show why LLEB
is well motivated, and how it interpolates between standard BNNs and ensembles
in terms of the strength of the prior that they use. LLEB performs on par with
existing approaches, highlighting that empirical Bayes is a promising direction
for future research in uncertainty quantification.

</details>


### [3] [Is (Selective) Round-To-Nearest Quantization All You Need?](https://arxiv.org/abs/2505.15909)
*Alex Kogan*

**主要类别:** cs.LG

**概要:** This work shows that the Round-to-Nearest (RTN) quantization method, despite being considered outdated, is cost-effective and comparable in performance to more advanced methods when properly optimized.


<details>
  <summary>更多</summary>
  
**动机:** To challenge the established viewpoint that RTN is inferior to more advanced quantization methods.

**方法:** Implementation of RTN based on Marlin kernels and selective increase in data precision format.

**结果:** RTN is shown to be cheaper to apply with better token generation throughput and similar accuracy after optimization.

**结论:** RTN is a viable and practical choice for quantizing large language models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Is+%28Selective%29+Round-To-Nearest+Quantization+All+You+Need%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15909，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15909&send_immediately=true&force_search=false)

**原文摘要:** Quantization became a necessary tool for serving ever-increasing Large
Language Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest
quantization technique that has been around well before LLMs surged to the
forefront of machine learning (ML) research. Yet, it has been largely dismissed
by recent and more advanced quantization methods that claim superiority over
RTN in nearly every aspect of performance. This work aims to dispel this
established point of view, showing that RTN is not only much cheaper to apply,
but also its token generation throughput can be better than and accuracy can be
similar to more advanced alternatives. In particular, we discuss our
implementation of RTN based on the recent Marlin kernels and demonstrate how
the accuracy of RTN can be gradually improved by selectively increasing the
data precision format of certain model layers and modules. Based on our
results, we argue that RTN presents a viable and practical choice for
quantizing LLMs.

</details>


### [4] [AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning](https://arxiv.org/abs/2505.15931)
*Morteza Alizadeh, Mehrdad Oveisi, Sonya Falahati, Ghazal Mousavi, Mohsen Alambardar Meybodi, Somayeh Sadat Mehrnia, Ilker Hacihaliloglu, Arman Rahmim, Mohammad R. Salmanpour*

**主要类别:** cs.LG

**概要:** 本文介绍了一个名为AllMetrics的新库，它是一个开源的Python库，旨在通过统一的标准解决机器学习性能评估中的不一致问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器学习性能评估库存在碎片化、不一致的实现以及数据验证协议不足的问题，导致无法可靠地比较不同框架的结果。

**方法:** 设计并实现了一个名为AllMetrics的开源Python库，该库统一了多种机器学习任务的性能度量标准，并通过模块化API和强大的输入验证机制确保了评估的可重复性和可靠性。

**结果:** AllMetrics在多个领域（如医疗保健、金融和房地产）的数据集上进行了测试，并与Python、Matlab和R中的组件进行了比较，发现其能够产生相似的结果。

**结论:** 提出AllMetrics库，解决了现有机器学习性能评估中的标准化问题，提升了模型评价的可靠性和一致性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AllMetrics%3A+A+Unified+Python+Library+for+Standardized+Metric+Evaluation+and+Robust+Data+Validation+in+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15931&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML) models rely heavily on consistent and accurate
performance metrics to evaluate and compare their effectiveness. However,
existing libraries often suffer from fragmentation, inconsistent
implementations, and insufficient data validation protocols, leading to
unreliable results. Existing libraries have often been developed independently
and without adherence to a unified standard, particularly concerning the
specific tasks they aim to support. As a result, each library tends to adopt
its conventions for metric computation, input/output formatting, error
handling, and data validation protocols. This lack of standardization leads to
both implementation differences (ID) and reporting differences (RD), making it
difficult to compare results across frameworks or ensure reliable evaluations.
To address these issues, we introduce AllMetrics, an open-source unified Python
library designed to standardize metric evaluation across diverse ML tasks,
including regression, classification, clustering, segmentation, and
image-to-image translation. The library implements class-specific reporting for
multi-class tasks through configurable parameters to cover all use cases, while
incorporating task-specific parameters to resolve metric computation
discrepancies across implementations. Various datasets from domains like
healthcare, finance, and real estate were applied to our library and compared
with Python, Matlab, and R components to identify which yield similar results.
AllMetrics combines a modular Application Programming Interface (API) with
robust input validation mechanisms to ensure reproducibility and reliability in
model evaluation. This paper presents the design principles, architectural
components, and empirical analyses demonstrating the ability to mitigate
evaluation errors and to enhance the trustworthiness of ML workflows.

</details>


### [5] [MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding](https://arxiv.org/abs/2505.15946)
*Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun*

**主要类别:** cs.LG

**概要:** 提出了一种名为MoRE-Brain的新框架，用于从功能磁共振成像(fMRI)信号中解码视觉体验。该框架结合了脑启发的Mixture-of-Experts架构与扩散模型，旨在实现高保真度、可适应性和可解释性的视觉重建。


<details>
  <summary>更多</summary>
  
**动机:** 当前fMRI视觉解码研究过于关注重建保真度而忽视了解释性，这限制了神经科学洞见的获取。

**方法:** 设计了一个基于脑网络原理的层级专家混合架构，并引入了双阶段路由机制来动态调整不同专家的贡献。

**结果:** 实验验证了MoRE-Brain在高保真视觉重建方面的有效性，并通过瓶颈分析证明了其对fMRI信号的有效利用。

**结论:** MoRE-Brain实现了更通用且可解释的fMRI视觉解码，标志着该领域的重要进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoRE-Brain%3A+Routed+Mixture+of+Experts+for+Interpretable+and+Generalizable+Cross-Subject+fMRI+Visual+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15946，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15946&send_immediately=true&force_search=false)

**原文摘要:** Decoding visual experiences from fMRI offers a powerful avenue to understand
human perception and develop advanced brain-computer interfaces. However,
current progress often prioritizes maximizing reconstruction fidelity while
overlooking interpretability, an essential aspect for deriving neuroscientific
insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework
designed for high-fidelity, adaptable, and interpretable visual reconstruction.
MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture
where distinct experts process fMRI signals from functionally related voxel
groups, mimicking specialized brain networks. The experts are first trained to
encode fMRI into the frozen CLIP space. A finetuned diffusion model then
synthesizes images, guided by expert outputs through a novel dual-stage routing
mechanism that dynamically weighs expert contributions across the diffusion
process. MoRE-Brain offers three main advancements: First, it introduces a
novel Mixture-of-Experts architecture grounded in brain network principles for
neuro-decoding. Second, it achieves efficient cross-subject generalization by
sharing core expert networks while adapting only subject-specific routers.
Third, it provides enhanced mechanistic insight, as the explicit routing
reveals precisely how different modeled brain regions shape the semantic and
spatial attributes of the reconstructed image. Extensive experiments validate
MoRE-Brain's high reconstruction fidelity, with bottleneck analyses further
demonstrating its effective utilization of fMRI signals, distinguishing genuine
neural decoding from over-reliance on generative priors. Consequently,
MoRE-Brain marks a substantial advance towards more generalizable and
interpretable fMRI-based visual decoding. Code will be publicly available soon:
https://github.com/yuxiangwei0808/MoRE-Brain.

</details>


### [6] [Towards Identifiability of Interventional Stochastic Differential Equations](https://arxiv.org/abs/2505.15987)
*Aaron Zweig, Zaikang Lin, Elham Azizi, David Knowles*

**主要类别:** cs.LG

**概要:** 研究了随机微分方程模型在多种干预下的可识别性。给出了线性和非线性SDEs在小噪声情况下的必要干预次数的紧界和上界，并验证了合成数据中真实参数的恢复。


<details>
  <summary>更多</summary>
  
**动机:** 研究多个干预下随机微分方程模型的可识别性。

**方法:** 分析了线性和非线性SDEs的参数可识别性并给出了必要干预次数的界。

**结果:** 给出了唯一恢复SDE参数的可证明界限，并验证了合成数据中的参数恢复。

**结论:** 该研究提供了SDE参数可识别性的理论基础，并展示了具有可学习激活函数的参数化的优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Identifiability+of+Interventional+Stochastic+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15987&send_immediately=true&force_search=false)

**原文摘要:** We study identifiability of stochastic differential equation (SDE) models
under multiple interventions. Our results give the first provable bounds for
unique recovery of SDE parameters given samples from their stationary
distributions. We give tight bounds on the number of necessary interventions
for linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.
We experimentally validate the recovery of true parameters in synthetic data,
and motivated by our theoretical results, demonstrate the advantage of
parameterizations with learnable activation functions.

</details>


### [7] [Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations](https://arxiv.org/abs/2505.16004)
*Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju*

**主要类别:** cs.LG

**概要:** This paper examines the robustness of sparse autoencoder (SAE) concept representations against input perturbations, finding that small adversarial changes can significantly alter SAE-based interpretations without affecting the underlying large language model's outputs.


<details>
  <summary>更多</summary>
  
**动机:** To address the overlooked aspect of robustness in evaluating SAE concept representations which is crucial for their reliability and applicability in model monitoring and oversight.

**方法:** Formulating robustness quantification as input-space optimization problems and developing an evaluation framework with realistic adversarial perturbation scenarios.

**结果:** Most SAE concept representations are sensitive to tiny adversarial input perturbations, leading to altered interpretations without noticeable impact on the base large language model's outputs.

**结论:** The fragility of SAE concept representations suggests they may not be suitable for tasks requiring stable interpretations such as model monitoring and oversight.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretability+Illusions+with+Sparse+Autoencoders%3A+Evaluating+Robustness+of+Concept+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16004&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are commonly used to interpret the internal
activations of large language models (LLMs) by mapping them to
human-interpretable concept representations. While existing evaluations of SAEs
focus on metrics such as the reconstruction-sparsity tradeoff, human
(auto-)interpretability, and feature disentanglement, they overlook a critical
aspect: the robustness of concept representations to input perturbations. We
argue that robustness must be a fundamental consideration for concept
representations, reflecting the fidelity of concept labeling. To this end, we
formulate robustness quantification as input-space optimization problems and
develop a comprehensive evaluation framework featuring realistic scenarios in
which adversarial perturbations are crafted to manipulate SAE representations.
Empirically, we find that tiny adversarial input perturbations can effectively
manipulate concept-based interpretations in most scenarios without notably
affecting the outputs of the base LLMs themselves. Overall, our results suggest
that SAE concept representations are fragile and may be ill-suited for
applications in model monitoring and oversight.

</details>


### [8] [GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2505.16017)
*Mariia Seleznova, Hung-Hsu Chou, Claudio Mayrink Verdun, Gitta Kutyniok*

**主要类别:** cs.LG

**概要:** 提出GradPCA方法用于神经网络的Out-of-Distribution检测，通过梯度的低秩结构和主成分分析实现比现有方法更一致的表现。理论分析揭示了特征空间性质与NTK对齐的关系，并强调预训练表示的重要性。实验验证了GradPCA的有效性并提供了设计新方法的指导框架。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在标准图像分类基准上的表现不一致，需要一种新的方法来提高检测性能。

**方法:** GradPCA利用神经网络梯度的低秩结构，应用主成分分析于梯度类均值上。

**结果:** GradPCA在标准图像分类基准上表现出色，且其理论分析揭示了特征质量的影响。

**结论:** GradPCA提供了一种有效且一致的Out-of-Distribution检测方法，并通过理论分析指导未来方法的设计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GradPCA%3A+Leveraging+NTK+Alignment+for+Reliable+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16017&send_immediately=true&force_search=false)

**原文摘要:** We introduce GradPCA, an Out-of-Distribution (OOD) detection method that
exploits the low-rank structure of neural network gradients induced by Neural
Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis
(PCA) to gradient class-means, achieving more consistent performance than
existing methods across standard image classification benchmarks. We provide a
theoretical perspective on spectral OOD detection in neural networks to support
GradPCA, highlighting feature-space properties that enable effective detection
and naturally emerge from NTK alignment. Our analysis further reveals that
feature quality -- particularly the use of pretrained versus non-pretrained
representations -- plays a crucial role in determining which detectors will
succeed. Extensive experiments validate the strong performance of GradPCA, and
our theoretical framework offers guidance for designing more principled
spectral OOD detectors.

</details>


### [9] [Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging](https://arxiv.org/abs/2505.16024)
*Weiguo Gao, Ming Li*

**主要类别:** cs.LG

**概要:** 本文重新解释扩散轨迹蒸馏为操作合并问题，并提出动态规划算法以找到最优合并策略，揭示了相变现象并增强理论理解。


<details>
  <summary>更多</summary>
  
**动机:** 加速采样在扩散模型中的应用，解决不同蒸馏策略与生成质量之间的权衡问题，优化和选择蒸馏策略。

**方法:** 将轨迹蒸馏重新解释为线性阶段的操作合并问题，并提出动态规划算法计算最优合并策略。

**结果:** 发现了最优策略中存在的尖锐相变现象，受数据协方差结构控制；增强了对扩散轨迹蒸馏的理论理解；为改进蒸馏策略提供了实用见解。

**结论:** 本文通过重新解释轨迹蒸馏为线性阶段的操作合并问题，提出了一个动态规划算法来计算最优合并策略，以最大程度地保持信号保真度，并展示了最优策略中存在的尖锐相变现象，受数据协方差结构控制。这些发现增强了对扩散轨迹蒸馏的理论理解，并为改进蒸馏策略提供了实用见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Toward+Theoretical+Insights+into+Diffusion+Trajectory+Distillation+via+Operator+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16024&send_immediately=true&force_search=false)

**原文摘要:** Diffusion trajectory distillation methods aim to accelerate sampling in
diffusion models, which produce high-quality outputs but suffer from slow
sampling speeds. These methods train a student model to approximate the
multi-step denoising process of a pretrained teacher model in a single step,
enabling one-shot generation. However, theoretical insights into the trade-off
between different distillation strategies and generative quality remain
limited, complicating their optimization and selection. In this work, we take a
first step toward addressing this gap. Specifically, we reinterpret trajectory
distillation as an operator merging problem in the linear regime, where each
step of the teacher model is represented as a linear operator acting on noisy
data. These operators admit a clear geometric interpretation as projections and
rescalings corresponding to the noise schedule. During merging, signal
shrinkage occurs as a convex combination of operators, arising from both
discretization and limited optimization time of the student model. We propose a
dynamic programming algorithm to compute the optimal merging strategy that
maximally preserves signal fidelity. Additionally, we demonstrate the existence
of a sharp phase transition in the optimal strategy, governed by data
covariance structures. Our findings enhance the theoretical understanding of
diffusion trajectory distillation and offer practical insights for improving
distillation strategies.

</details>


### [10] [Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces](https://arxiv.org/abs/2505.16035)
*Alejandro García-Castellanos, David R. Wessels, Nicky J. van den Berg, Remco Duits, Daniël M. Pelt, Erik J. Bekkers*

**主要类别:** cs.LG

**概要:** 介绍了一种新的框架Equivalant Neural Eikonal Solvers，它结合了等变神经场和神经Eikonal求解器，能够高效地建模Eikonal方程的解，并且可以推广到任意黎曼流形。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经算子方法在建模Eikonal方程时存在不足，需要一种更高效、可推广且可控的方法。

**方法:** 提出了一种新的框架，该框架利用单个神经场，通过条件化信号特定的潜在变量来模拟多样的Eikonal解。这种方法确保了从潜在表示到解场的等变映射。

**结果:** 在二维和三维基准数据集上对地震旅行时间建模的应用验证了该方法的有效性，其性能、可扩展性和适应性优于现有的基于神经算子的方法。

**结论:** 所提出的框架不仅提高了表示效率，而且提供了强大的几何基础和解决方案的可控性，能够在任意黎曼流形上准确建模Eikonal旅行时间解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Eikonal+Neural+Networks%3A+Grid-Free%2C+Scalable+Travel-Time+Prediction+on+Homogeneous+Spaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16035，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16035&send_immediately=true&force_search=false)

**原文摘要:** We introduce Equivariant Neural Eikonal Solvers, a novel framework that
integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our
approach employs a single neural field where a unified shared backbone is
conditioned on signal-specific latent variables - represented as point clouds
in a Lie group - to model diverse Eikonal solutions. The ENF integration
ensures equivariant mapping from these latent representations to the solution
field, delivering three key benefits: enhanced representation efficiency
through weight-sharing, robust geometric grounding, and solution steerability.
This steerability allows transformations applied to the latent point cloud to
induce predictable, geometrically meaningful modifications in the resulting
Eikonal solution. By coupling these steerable representations with
Physics-Informed Neural Networks (PINNs), our framework accurately models
Eikonal travel-time solutions while generalizing to arbitrary Riemannian
manifolds with regular group actions. This includes homogeneous spaces such as
Euclidean, position-orientation, spherical, and hyperbolic manifolds. We
validate our approach through applications in seismic travel-time modeling of
2D and 3D benchmark datasets. Experimental results demonstrate superior
performance, scalability, adaptability, and user controllability compared to
existing Neural Operator-based Eikonal solver methods.

</details>


### [11] [Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs](https://arxiv.org/abs/2505.16053)
*Jan Tönshoff, Martin Grohe*

**主要类别:** cs.LG

**概要:** This paper introduces Reinforcement Learning from Algorithm Feedback (RLAF) to improve Boolean Satisfiability (SAT) solvers' performance by learning branching heuristics with Graph Neural Networks.


<details>
  <summary>更多</summary>
  
**动机:** Current SAT solvers rely heavily on hand-crafted heuristics, which may not be optimal.

**方法:** Using RLAF to train GNNs that inject variable weights and polarities into existing SAT solvers' branching heuristics.

**结果:** RLAF-trained policies reduce mean solve times by over 2x in some cases and generalize well to larger and harder problems.

**结论:** The proposed method outperforms expert-supervised approaches and shows promise for data-driven heuristic design in combinatorial optimization.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+from+Algorithm+Feedback%3A+One-Shot+SAT+Solver+Guidance+with+GNNs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16053，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16053&send_immediately=true&force_search=false)

**原文摘要:** Boolean Satisfiability (SAT) solvers are foundational to computer science,
yet their performance typically hinges on hand-crafted heuristics. This work
introduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm
for learning to guide SAT solver branching heuristics with Graph Neural
Networks (GNNs). Central to our approach is a novel and generic mechanism for
injecting inferred variable weights and polarities into the branching
heuristics of existing SAT solvers. In a single forward pass, a GNN assigns
these parameters to all variables. Casting this one-shot guidance as a
reinforcement learning problem lets us train the GNN with off-the-shelf
policy-gradient methods, such as GRPO, directly using the solver's
computational cost as the sole reward signal. Extensive evaluations demonstrate
that RLAF-trained policies significantly reduce the mean solve times of
different base solvers across diverse SAT problem distributions, achieving more
than a 2x speedup in some cases, while generalizing effectively to larger and
harder problems after training. Notably, these policies consistently outperform
expert-supervised approaches based on learning handcrafted weighting
heuristics, offering a promising path towards data-driven heuristic design in
combinatorial optimization.

</details>


### [12] [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org/abs/2505.16056)
*Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei*

**主要类别:** cs.LG

**概要:** 提出两种度量方法来衡量MoE模型的局部路由一致性，并对20个不同大小和架构的MoE LLMs进行了分析，发现某些设计特点能提高一致性，且大多数模型在缓存大小约为活跃专家数量两倍时可以平衡缓存效率与效果。代码已开源。


<details>
  <summary>更多</summary>
  
**动机:** 研究MoE模型在内存受限设备上的高效部署，特别是局部路由一致性的度量与影响。

**方法:** 提出了SRP和SCH两个度量指标，并分析了20个MoE LLMs。

**结果:** 发现特定设计（如每层应用MoE且不使用共享专家）能提高局部路由一致性；领域专用专家比词汇专用专家对一致性贡献更大；大多数模型在缓存大小约为活跃专家数量两倍时可平衡缓存效果与效率。

**结论:** 这些发现有助于设计和部署内存高效的MoE模型，同时保持推理速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Not+All+Models+Suit+Expert+Offloading%3A+On+Local+Routing+Consistency+of+Mixture-of-Expert+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16056，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16056&send_immediately=true&force_search=false)

**原文摘要:** Mixture-of-Experts (MoE) enables efficient scaling of large language models
(LLMs) with sparsely activated experts during inference. To effectively deploy
large MoE models on memory-constrained devices, many systems introduce *expert
offloading* that caches a subset of experts in fast memory, leaving others on
slow memory to run on CPU or load on demand. While some research has exploited
the locality of expert activations, where consecutive tokens activate similar
experts, the degree of this **local routing consistency** varies across models
and remains understudied. In this paper, we propose two metrics to measure
local routing consistency of MoE models: (1) **Segment Routing Best Performance
(SRP)**, which evaluates how well a fixed group of experts can cover the needs
of a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which
measures the optimal segment-level cache hit rate under a given cache size
limit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found
that models that apply MoE on every layer and do not use shared experts exhibit
the highest local routing consistency. We further showed that
domain-specialized experts contribute more to routing consistency than
vocabulary-specialized ones, and that most models can balance between cache
effectiveness and efficiency with cache sizes approximately 2x the active
experts. These findings pave the way for memory-efficient MoE design and
deployment without compromising inference speed. We publish the code for
replicating experiments at https://github.com/ljcleo/moe-lrc .

</details>


### [13] [Mesh-free sparse identification of nonlinear dynamics](https://arxiv.org/abs/2505.16058)
*Mars Liyao Gao, J. Nathan Kutz, Bernat Font*

**主要类别:** cs.LG

**概要:** 提出了一种新的算法mesh-free SINDy，可以从任意传感器放置和非均匀时间数据采样中识别控制方程。该算法在高噪声水平和有限数据下表现出了鲁棒性，并且在多种偏微分方程上进行了有效的验证。


<details>
  <summary>更多</summary>
  
**动机:** 现有的动力系统科学建模方法通常需要高质量的空间-时间数据在结构化网格上的均匀采样，而现实中的数据往往不符合这些要求。

**方法:** 利用神经网络逼近和自动微分技术，提出了一种名为mesh-free SINDy的新算法，可以处理任意传感器放置和非均匀时间数据采样。

**结果:** 在多种偏微分方程上进行了有效的验证，包括Burgers方程、热方程、Korteweg-De Vries方程和二维对流-扩散方程。即使在高噪声和低数据情况下，mesh-free SINDy也能成功识别控制方程。

**结论:** mesh-free SINDy是一种广泛适用于科学和工程问题的算法，其训练过程简单，几乎不需要超参数调整。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mesh-free+sparse+identification+of+nonlinear+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16058&send_immediately=true&force_search=false)

**原文摘要:** Identifying the governing equations of a dynamical system is one of the most
important tasks for scientific modeling. However, this procedure often requires
high-quality spatio-temporal data uniformly sampled on structured grids. In
this paper, we propose mesh-free SINDy, a novel algorithm which leverages the
power of neural network approximation as well as auto-differentiation to
identify governing equations from arbitrary sensor placements and non-uniform
temporal data sampling. We show that mesh-free SINDy is robust to high noise
levels and limited data while remaining computationally efficient. In our
implementation, the training procedure is straight-forward and nearly free of
hyperparameter tuning, making mesh-free SINDy widely applicable to many
scientific and engineering problems. In the experiments, we demonstrate its
effectiveness on a series of PDEs including the Burgers' equation, the heat
equation, the Korteweg-De Vries equation and the 2D advection-diffusion
equation. We conduct detailed numerical experiments on all datasets, varying
the noise levels and number of samples, and we also compare our approach to
previous state-of-the-art methods. It is noteworthy that, even in high-noise
and low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,
achieving successful identification with up to 75% noise for the Burgers'
equation using 5,000 samples and with as few as 100 samples and 1% noise. All
of this is achieved within a training time of under one minute.

</details>


### [14] [Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond](https://arxiv.org/abs/2505.16060)
*Shangding Gu, Donghao Ying, Ming Jin, Yu Joe Lu, Jun Wang, Javad Lavaei, Costas Spanos*

**主要类别:** cs.LG

**概要:** 提出了一种名为Model Feedback Learning (MFL)的新框架，用于在不修改模型或硬件的情况下优化预训练AI模型或部署的硬件系统。该方法通过轻量级反向模型迭代寻找最优输入，在半导体制造等实际应用中表现出色，并且在多种任务中优于其他优化方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法依赖于调整模型参数，而在许多实际场景中修改部署的系统是不可行或成本高昂的，因此需要一种新的优化方法来适应新目标。

**方法:** MFL利用轻量级反向模型迭代搜索最优输入，无需重新训练模型或更改硬件。

**结果:** 在半导体刻蚀任务中，MFL仅需五次迭代即可实现目标配方生成，显著优于贝叶斯优化和人类专家。此外，它还在化学过程和电子系统中表现良好。

**结论:** MFL提供了一种可扩展且高效的范例，用于在现实环境中部署智能控制，特别是在需要少量样本适应的场景中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Few-Shot+Test-Time+Optimization+Without+Retraining+for+Semiconductor+Recipe+Generation+and+Beyond，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16060，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16060&send_immediately=true&force_search=false)

**原文摘要:** We introduce Model Feedback Learning (MFL), a novel test-time optimization
framework for optimizing inputs to pre-trained AI models or deployed hardware
systems without requiring any retraining of the models or modifications to the
hardware. In contrast to existing methods that rely on adjusting model
parameters, MFL leverages a lightweight reverse model to iteratively search for
optimal inputs, enabling efficient adaptation to new objectives under
deployment constraints. This framework is particularly advantageous in
real-world settings, such as semiconductor manufacturing recipe generation,
where modifying deployed systems is often infeasible or cost-prohibitive. We
validate MFL on semiconductor plasma etching tasks, where it achieves target
recipe generation in just five iterations, significantly outperforming both
Bayesian optimization and human experts. Beyond semiconductor applications, MFL
also demonstrates strong performance in chemical processes (e.g., chemical
vapor deposition) and electronic systems (e.g., wire bonding), highlighting its
broad applicability. Additionally, MFL incorporates stability-aware
optimization, enhancing robustness to process variations and surpassing
conventional supervised learning and random search methods in high-dimensional
control settings. By enabling few-shot adaptation, MFL provides a scalable and
efficient paradigm for deploying intelligent control in real-world
environments.

</details>


### [15] [Merge to Mix: Mixing Datasets via Model Merging](https://arxiv.org/abs/2505.16066)
*Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix*

**主要类别:** cs.LG

**概要:** 提出了一种名为'Merge to Mix'的新方法，通过模型合并加速数据集混合的组成。该方法利用了将单独微调在每个数据集上的模型合并来替代对整个混合数据集进行微调的见解，从而无需对每个候选混合进行完整的微调。实验表明，这种方法在微调大型语言模型的数据集选择上超越了现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 当前数据集混合的方法依赖于启发式和试错法，通常需要多次微调运行才能达到预期效果。

**方法:** 提出了'Merge to Mix'方法，利用模型合并技术来加速数据集混合的组成过程。

**结果:** 实验显示'Merge to Mix'在大型语言模型的数据集选择上优于现有的最先进方法。

**结论:** 通过模型合并加速数据集混合的方法在提高下游任务性能方面具有潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge+to+Mix%3A+Mixing+Datasets+via+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16066，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16066&send_immediately=true&force_search=false)

**原文摘要:** Mixing datasets for fine-tuning large models (LMs) has become critical for
maximizing performance on downstream tasks. However, composing effective
dataset mixtures typically relies on heuristics and trial-and-error, often
requiring multiple fine-tuning runs to achieve the desired outcome. We propose
a novel method, $\textit{Merge to Mix}$, that accelerates composing dataset
mixtures through model merging. Model merging is a recent technique that
combines the abilities of multiple individually fine-tuned LMs into a single LM
by using a few simple arithmetic operations. Our key insight is that merging
models individually fine-tuned on each dataset in a mixture can effectively
serve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix
leverages this insight to accelerate selecting dataset mixtures without
requiring full fine-tuning on each candidate mixture. Our experiments
demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset
selection for fine-tuning LMs.

</details>


### [16] [Bidirectional Variational Autoencoders](https://arxiv.org/abs/2505.16074)
*Bart Kosko, Olaoluwa Adigun*

**主要类别:** cs.LG

**概要:** 提出一种新的双向变分自编码器(BVAE)网络架构，与普通VAE相比，在四个图像任务上表现出色的同时，参数数量减少近50%。


<details>
  <summary>更多</summary>
  
**动机:** 提出一种新的神经网络架构以提高效率和性能。

**方法:** 设计了一种单个神经网络既用于编码又用于解码的双向变分自编码器(BVAE)，而不是传统的编码器-解码器对。

**结果:** 在MNIST手写数字、Fashion-MNIST、CIFAR-10和CelebA-64人脸图像数据集上的图像重建、分类、插值和生成任务中，BVAE的双向结构使其参数数量减少近50%，并且稍微优于单向VAE。

**结论:** 提出的BVAE网络架构在保持甚至略微提升性能的同时显著减少了参数数量，显示出良好的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bidirectional+Variational+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16074，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16074&send_immediately=true&force_search=false)

**原文摘要:** We present the new bidirectional variational autoencoder (BVAE) network
architecture. The BVAE uses a single neural network both to encode and decode
instead of an encoder-decoder network pair. The network encodes in the forward
direction and decodes in the backward direction through the same synaptic web.
Simulations compared BVAEs and ordinary VAEs on the four image tasks of image
reconstruction, classification, interpolation, and generation. The image
datasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and
CelebA-64 face images. The bidirectional structure of BVAEs cut the parameter
count by almost 50% and still slightly outperformed the unidirectional VAEs.

</details>


### [17] [Ensembling Sparse Autoencoders](https://arxiv.org/abs/2505.16077)
*Soham Gadgil, Chris Lin, Su-In Lee*

**主要类别:** cs.LG

**概要:** This paper proposes methods to ensemble multiple sparse autoencoders (SAEs) through naive bagging and boosting to improve the reconstruction of language model activations, feature diversity, and SAE stability, which also performs better than a single SAE on downstream tasks.


<details>
  <summary>更多</summary>
  
**动机:** A single SAE captures only a limited subset of features that can be extracted from the activation space, so the authors want to overcome this limitation by ensembling multiple SAEs.

**方法:** The authors propose to ensemble multiple SAEs through naive bagging and boosting. In naive bagging, SAEs trained with different weight initializations are ensembled. In boosting, SAEs sequentially trained to minimize the residual error are ensembled.

**结果:** Ensembling SAEs improves the reconstruction of language model activations, diversity of features, and SAE stability. It also performs better than a single SAE on downstream tasks such as concept detection and spurious correlation removal.

**结论:** Ensembling multiple SAEs can enhance practical utility and performance on various tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ensembling+Sparse+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16077，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16077&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are used to decompose neural network activations
into human-interpretable features. Typically, features learned by a single SAE
are used for downstream applications. However, it has recently been shown that
SAEs trained with different initial weights can learn different features,
demonstrating that a single SAE captures only a limited subset of features that
can be extracted from the activation space. Motivated by this limitation, we
propose to ensemble multiple SAEs through naive bagging and boosting.
Specifically, SAEs trained with different weight initializations are ensembled
in naive bagging, whereas SAEs sequentially trained to minimize the residual
error are ensembled in boosting. We evaluate our ensemble approaches with three
settings of language models and SAE architectures. Our empirical results
demonstrate that ensembling SAEs can improve the reconstruction of language
model activations, diversity of features, and SAE stability. Furthermore,
ensembling SAEs performs better than applying a single SAE on downstream tasks
such as concept detection and spurious correlation removal, showing improved
practical utility.

</details>


### [18] [Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks](https://arxiv.org/abs/2505.16204)
*Ichiro Hashimoto*

**主要类别:** cs.LG

**概要:** 本文证明了固定宽度的两层神经网络通过梯度下降优化的方向收敛性，并发现了新的测试误差界相变，其适用范围超出了先前的研究。


<details>
  <summary>更多</summary>
  
**动机:** 之前仅对于梯度流已知的结果，本文将其扩展到梯度下降的情况。并且研究超越了先前工作中研究过的近似正交数据设定。

**方法:** 对收敛方向进行了仔细分析，建立了良性过拟合的充分条件，并发现测试误差界中的新相变。

**结果:** 所有结果都适用于更广泛的场景，并且在高斯混合模型中展示了良性过拟合的发生概率很高。

**结论:** 证明了固定宽度的泄漏ReLU两层神经网络在指数损失下通过梯度下降优化的方向收敛性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Directional+Convergence%2C+Benign+Overfitting+of+Gradient+Descent+in+leaky+ReLU+two-layer+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16204&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we prove directional convergence of network parameters of
fixed width leaky ReLU two-layer neural networks optimized by gradient descent
with exponential loss, which was previously only known for gradient flow. By a
careful analysis of the convergent direction, we establish sufficient
conditions of benign overfitting and discover a new phase transition in the
test error bound. All of these results hold beyond the nearly orthogonal data
setting which was studied in prior works. As an application, we demonstrate
that benign overfitting occurs with high probability in sub-Gaussian mixture
models.

</details>


### [19] [FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model](https://arxiv.org/abs/2505.16083)
*Jiahuan Long, Wenzhe Zhang, Ning Wang, Tingsong Jiang, Wen Yao*

**主要类别:** cs.LG

**概要:** This paper introduces FR-Mamba, a new method for reconstructing physical field states using a hybrid neural network combining Fourier Neural Operator and State Space Model to improve long-range temporal dependency handling.


<details>
  <summary>更多</summary>
  
**动机:** Existing deep learning methods often fail to capture long-range temporal dependencies in time-evolving physical systems like those in fluid dynamics and thermodynamics.

**方法:** Proposes FR-Mamba which uses a combination of Fourier Neural Operator (for spatial features) and Mamba (a State Space Model for temporal dependencies) to reconstruct physical field states.

**结果:** The approach shows superior performance in reconstructing flow fields, particularly on long sequences, compared to other Physical Field Reconstruction methods.

**结论:** FR-Mamba effectively captures both global spatial features and long-range temporal dependencies, leading to improved accuracy in physical field reconstructions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FR-Mamba%3A+Time-Series+Physical+Field+Reconstruction+Based+on+State+Space+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16083，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16083&send_immediately=true&force_search=false)

**原文摘要:** Physical field reconstruction (PFR) aims to predict the state distribution of
physical quantities (e.g., velocity, pressure, and temperature) based on
limited sensor measurements. It plays a critical role in domains such as fluid
dynamics and thermodynamics. However, existing deep learning methods often fail
to capture long-range temporal dependencies, resulting in suboptimal
performance on time-evolving physical systems. To address this, we propose
FR-Mamba, a novel spatiotemporal flow field reconstruction framework based on
state space modeling. Specifically, we design a hybrid neural network
architecture that combines Fourier Neural Operator (FNO) and State Space Model
(SSM) to capture both global spatial features and long-range temporal
dependencies. We adopt Mamba, a recently proposed efficient SSM architecture,
to model long-range temporal dependencies with linear time complexity. In
parallel, the FNO is employed to capture non-local spatial features by
leveraging frequency-domain transformations. The spatiotemporal representations
extracted by these two components are then fused to reconstruct the full-field
distribution of the physical system. Extensive experiments demonstrate that our
approach significantly outperforms existing PFR methods in flow field
reconstruction tasks, achieving high-accuracy performance on long sequences.

</details>


### [20] [AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training](https://arxiv.org/abs/2505.16363)
*Huishuai Zhang, Bohan Wang, Luoxin Chen*

**主要类别:** cs.LG

**概要:** 提出了一种名为AdamS的新优化器，它是一种简单有效的Adam替代方案，适用于大型语言模型的预训练和后训练。AdamS通过利用新的分母（动量与当前梯度平方的加权和的平方根）消除了对二阶矩估计的需求，效率高且易于采用。


<details>
  <summary>更多</summary>
  
**动机:** 观察到Transformer目标函数中的(L0, L1)平滑性特性，其中局部平滑性由梯度大小控制，梯度大小可以进一步近似为动量大小。

**方法:** 引入AdamS优化器，它使用动量与当前梯度平方的加权和的平方根作为分母，无需二阶矩估计。

**结果:** AdamS在各种任务中表现出色，包括GPT-2和Llama2的预训练（高达13B参数）以及后训练中的强化学习。

**结论:** AdamS因其效率、简单性和理论基础，成为现有优化器的一个有吸引力的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdamS%3A+Momentum+Itself+Can+Be+A+Normalizer+for+LLM+Pretraining+and+Post-training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16363，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16363&send_immediately=true&force_search=false)

**原文摘要:** We introduce AdamS, a simple yet effective alternative to Adam for large
language model (LLM) pretraining and post-training. By leveraging a novel
denominator, i.e., the root of weighted sum of squares of the momentum and the
current gradient, AdamS eliminates the need for second-moment estimates. Hence,
AdamS is efficient, matching the memory and compute footprint of SGD with
momentum while delivering superior optimization performance. Moreover, AdamS is
easy to adopt: it can directly inherit hyperparameters of AdamW, and is
entirely model-agnostic, integrating seamlessly into existing pipelines without
modifications to optimizer APIs or architectures. The motivation behind AdamS
stems from the observed $(L_0, L_1)$ smoothness properties in transformer
objectives, where local smoothness is governed by gradient magnitudes that can
be further approximated by momentum magnitudes. We establish rigorous
theoretical convergence guarantees and provide practical guidelines for
hyperparameter selection. Empirically, AdamS demonstrates strong performance in
various tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B
parameters) and reinforcement learning in post-training regimes. With its
efficiency, simplicity, and theoretical grounding, AdamS stands as a compelling
alternative to existing optimizers.

</details>


### [21] [A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization](https://arxiv.org/abs/2505.16094)
*Ziqing Wang, Kexin Zhang, Zihan Zhao, Yibo Wen, Abhishek Pandey, Han Liu, Kaize Ding*

**主要类别:** cs.LG

**概要:** 这篇综述提供了大型语言模型在分子发现中的新兴应用的最新且前瞻性的回顾，重点介绍了分子生成和优化两大任务。通过提出的问题分类，分析了每种类别中的代表性技术，并强调了在不同学习设置下如何利用大型语言模型的能力。此外，还包含了常用的数据集和评估协议。最后讨论了关键挑战和未来方向。


<details>
  <summary>更多</summary>
  
**动机:** 推动大型语言模型在分子发现领域的发展。

**方法:** 基于提出的分类对代表性技术进行分析。

**结果:** 提供了大型语言模型在分子生成和优化方面的应用回顾。

**结论:** 讨论了关键挑战和未来方向，为从事大型语言模型与分子科学交叉领域的研究人员提供资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Large+Language+Models+for+Text-Guided+Molecular+Discovery%3A+from+Molecule+Generation+to+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16094&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are introducing a paradigm shift in molecular
discovery by enabling text-guided interaction with chemical spaces through
natural language, symbolic notations, with emerging extensions to incorporate
multi-modal inputs. To advance the new field of LLM for molecular discovery,
this survey provides an up-to-date and forward-looking review of the emerging
use of LLMs for two central tasks: molecule generation and molecule
optimization. Based on our proposed taxonomy for both problems, we analyze
representative techniques in each category, highlighting how LLM capabilities
are leveraged across different learning settings. In addition, we include the
commonly used datasets and evaluation protocols. We conclude by discussing key
challenges and future directions, positioning this survey as a resource for
researchers working at the intersection of LLMs and molecular science. A
continuously updated reading list is available at
https://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.

</details>


### [22] [Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling](https://arxiv.org/abs/2505.16481)
*Xinxing Shi, Xiaoyu Jiang, Mauricio A. Álvarez*

**主要类别:** cs.LG

**概要:** This work introduces a scalable Gaussian Process Variational Autoencoder (GPVAE) by using a neighbor-driven approximation strategy that reduces computation while maintaining performance.


<details>
  <summary>更多</summary>
  
**动机:** Standard GPVAEs cannot handle large-scale data due to computational limitations.

**方法:** A neighbor-driven approximation strategy that limits computations to nearest neighbors in the latent space.

**结果:** The proposed method improves predictive performance and computational efficiency compared to other GPVAE variants.

**结论:** The neighbor-driven approximation strategy allows more flexible kernel choices and fewer inducing points, making GPVAEs more practical for large-scale data.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neighbour-Driven+Gaussian+Process+Variational+Autoencoders+for+Scalable+Structured+Latent+Modelling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16481，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16481&send_immediately=true&force_search=false)

**原文摘要:** Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by
replacing the fully factorised Gaussian prior with a GP prior, thereby
capturing richer correlations among latent variables. However, performing exact
GP inference in large-scale GPVAEs is computationally prohibitive, often
forcing existing approaches to rely on restrictive kernel assumptions or large
sets of inducing points. In this work, we propose a neighbour-driven
approximation strategy that exploits local adjacencies in the latent space to
achieve scalable GPVAE inference. By confining computations to the nearest
neighbours of each data point, our method preserves essential latent
dependencies, allowing more flexible kernel choices and mitigating the need for
numerous inducing points. Through extensive experiments on tasks including
representation learning, data imputation, and conditional generation, we
demonstrate that our approach outperforms other GPVAE variants in both
predictive performance and computational efficiency.

</details>


### [23] [Reinforcement Learning for Stock Transactions](https://arxiv.org/abs/2505.16099)
*Ziyi, Zhou, Nicholas Stern, Julien Laasri*

**主要类别:** cs.LG

**概要:** This paper applies reinforcement learning methods including Q-Learning and deep Q-Learning to determine optimal buying times for stocks based on a defined Markov Decision Process problem.


<details>
  <summary>更多</summary>
  
**动机:** To make profit by identifying patterns in stock market transactions using reinforcement learning.

**方法:** Defining a custom Markov Decision Process problem and training agents using various Q-Learning techniques as well as machine learning models for stock price prediction.

**结果:** Agents trained with different reinforcement learning methods converge on policies, and their performances are compared to find the best strategy for maximizing profit.

**结论:** Reinforcement learning can effectively determine optimal times to buy stocks, and the approach can potentially be extended to selling decisions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+for+Stock+Transactions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16099&send_immediately=true&force_search=false)

**原文摘要:** Much research has been done to analyze the stock market. After all, if one
can determine a pattern in the chaotic frenzy of transactions, then they could
make a hefty profit from capitalizing on these insights. As such, the goal of
our project was to apply reinforcement learning (RL) to determine the best time
to buy a stock within a given time frame. With only a few adjustments, our
model can be extended to identify the best time to sell a stock as well. In
order to use the format of free, real-world data to train the model, we define
our own Markov Decision Process (MDP) problem. These two papers [5] [6] helped
us in formulating the state space and the reward system of our MDP problem. We
train a series of agents using Q-Learning, Q-Learning with linear function
approximation, and deep Q-Learning. In addition, we try to predict the stock
prices using machine learning regression and classification models. We then
compare our agents to see if they converge on a policy, and if so, which one
learned the best policy to maximize profit on the stock market.

</details>


### [24] [Incremental Sequence Classification with Temporal Consistency](https://arxiv.org/abs/2505.16548)
*Lucas Maystre, Gabriel Barello, Tudor Berariu, Aleix Cambray, Rares Dolga, Alvaro Ortega Gonzalez, Andrei Nica, David Barber*

**主要类别:** cs.LG

**概要:** This paper introduces a new method for incremental sequence classification using a novel loss function derived from a temporal-consistency condition. The method is shown to improve data efficiency and predictive accuracy in text classification and verifying large language model generations.


<details>
  <summary>更多</summary>
  
**动机:** To improve the efficiency and accuracy of incremental sequence classification by leveraging temporal-difference learning.

**方法:** Developing a novel loss function based on a temporal-consistency condition and applying it to text classification and verifying large language model generations.

**结果:** The method shows substantial gains in data efficiency and improves predictive accuracy over competing approaches on several benchmark datasets.

**结论:** The proposed method can effectively distinguish promising generations from unpromising ones after observing only a few tokens, demonstrating its potential in various applications.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incremental+Sequence+Classification+with+Temporal+Consistency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16548，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16548&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of incremental sequence classification, where
predictions are updated as new elements in the sequence are revealed. Drawing
on temporal-difference learning from reinforcement learning, we identify a
temporal-consistency condition that successive predictions should satisfy. We
leverage this condition to develop a novel loss function for training
incremental sequence classifiers. Through a concrete example, we demonstrate
that optimizing this loss can offer substantial gains in data efficiency. We
apply our method to text classification tasks and show that it improves
predictive accuracy over competing approaches on several benchmark datasets. We
further evaluate our approach on the task of verifying large language model
generations for correctness in grade-school math problems. Our results show
that models trained with our method are better able to distinguish promising
generations from unpromising ones after observing only a few tokens.

</details>


### [25] [Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI](https://arxiv.org/abs/2505.16103)
*Monirul Islam Mahmud*

**主要类别:** cs.LG

**概要:** This study explores keylogger detection using various machine learning models and feature selection methods, achieving high accuracy mainly through AdaBoost with Fisher Score.


<details>
  <summary>更多</summary>
  
**动机:** To provide a comprehensive analysis for keylogger detection with traditional and advanced machine learning models and assess feature selection approaches to enhance predictive performance.

**方法:** Using traditional models (SVC, Random Forest, etc.), ensemble methods, and feature selection approaches (Information gain, Lasso L1, Fisher Score). Implementing XAI techniques for model interpretation.

**结果:** Achieved best performance with AdaBoost: 99.76% accuracy, 0.99 F1 score, 100% precision, 98.6% recall, 1.0 specificity, and 0.99 AUC.

**结论:** The study successfully identifies keyloggers with near-perfect classification using AdaBoost combined with Fisher Score.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Trustworthy+Keylogger+detection%3A+A+Comprehensive+Analysis+of+Ensemble+Techniques+and+Feature+Selections+through+Explainable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16103，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16103&send_immediately=true&force_search=false)

**原文摘要:** Keylogger detection involves monitoring for unusual system behaviors such as
delays between typing and character display, analyzing network traffic patterns
for data exfiltration. In this study, we provide a comprehensive analysis for
keylogger detection with traditional machine learning models - SVC, Random
Forest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes
and advanced ensemble methods including Stacking, Blending and Voting.
Moreover, feature selection approaches such as Information gain, Lasso L1 and
Fisher Score are thoroughly assessed to improve predictive performance and
lower computational complexity. The Keylogger Detection dataset from publicly
available Kaggle website is used in this project. In addition to accuracy-based
classification, this study implements the approach for model interpretation
using Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to
deliver finer explanations for how much each feature contributes in assisting
or hindering the detection process. To evaluate the models result, we have used
AUC score, sensitivity, Specificity, Accuracy and F1 score. The best
performance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,
100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is
near-perfect classification with Fisher Score.

</details>


### [26] [Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity](https://arxiv.org/abs/2505.16638)
*Benedikt Höltgen, Nuria Oliver*

**主要类别:** cs.LG

**概要:** This paper challenges the traditional view that fairness through unawareness (FtU) reduces model accuracy while addressing discrimination.


<details>
  <summary>更多</summary>
  
**动机:** To explore whether FtU can effectively reduce algorithmic discrimination without sacrificing accuracy.

**方法:** Theoretical analysis and empirical experiments.

**结果:** FtU can indeed reduce discrimination without reducing accuracy, and it contributes to equitable policy deployment.

**结论:** FtU deserves consideration in practical applications, especially in high-risk situations, with proper justification for using protected attributes.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reconsidering+Fairness+Through+Unawareness+from+the+Perspective+of+Model+Multiplicity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16638，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16638&send_immediately=true&force_search=false)

**原文摘要:** Fairness through Unawareness (FtU) describes the idea that discrimination
against demographic groups can be avoided by not considering group membership
in the decisions or predictions. This idea has long been criticized in the
machine learning literature as not being sufficient to ensure fairness. In
addition, the use of additional features is typically thought to increase the
accuracy of the predictions for all groups, so that FtU is sometimes thought to
be detrimental to all groups. In this paper, we show both theoretically and
empirically that FtU can reduce algorithmic discrimination without necessarily
reducing accuracy. We connect this insight with the literature on Model
Multiplicity, to which we contribute with novel theoretical and empirical
results. Furthermore, we illustrate how, in a real-life application, FtU can
contribute to the deployment of more equitable policies without losing
efficacy. Our findings suggest that FtU is worth considering in practical
applications, particularly in high-risk scenarios, and that the use of
protected attributes such as gender in predictive models should be accompanied
by a clear and well-founded justification.

</details>


### [27] [Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools](https://arxiv.org/abs/2505.16113)
*Panagiotis Lymperopoulos, Vasanth Sarathy*

**主要类别:** cs.LG

**概要:** 提出一种新的框架来量化工具调用型大语言模型的不确定性，该框架在合成问答数据集和检索增强生成系统上的实验表明其在提高基于LLM系统的可信度方面是有效的。


<details>
  <summary>更多</summary>
  
**动机:** 现有不确定性量化方法无法处理工具调用场景下的不确定性问题，特别是在高风险应用中确保最终响应可靠性时需要评估LLM生成文本和工具输出的不确定性。

**方法:** 提出一种新颖的框架，联合考虑LLM和外部工具的预测不确定性，并扩展了以前的序列标记不确定性量化方法，提出了高效的近似方法。

**结果:** 在两个新的合成QA数据集上评估了该框架，并在一个证明概念实验中应用于检索增强生成系统，展示了不确定性度量在需要外部信息检索场景中的有效性。

**结论:** 提出的框架能够有效提高基于LLM系统的信任度，尤其是在LLM内部知识不足且需要外部工具的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Tools+in+the+Loop%3A+Quantifying+Uncertainty+of+LLM+Question+Answering+Systems+That+Use+Tools，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16113，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16113&send_immediately=true&force_search=false)

**原文摘要:** Modern Large Language Models (LLMs) often require external tools, such as
machine learning classifiers or knowledge retrieval systems, to provide
accurate answers in domains where their pre-trained knowledge is insufficient.
This integration of LLMs with external tools expands their utility but also
introduces a critical challenge: determining the trustworthiness of responses
generated by the combined system. In high-stakes applications, such as medical
decision-making, it is essential to assess the uncertainty of both the LLM's
generated text and the tool's output to ensure the reliability of the final
response. However, existing uncertainty quantification methods do not account
for the tool-calling scenario, where both the LLM and external tool contribute
to the overall system's uncertainty. In this work, we present a novel framework
for modeling tool-calling LLMs that quantifies uncertainty by jointly
considering the predictive uncertainty of the LLM and the external tool. We
extend previous methods for uncertainty quantification over token sequences to
this setting and propose efficient approximations that make uncertainty
computation practical for real-world applications. We evaluate our framework on
two new synthetic QA datasets, derived from well-known machine learning
datasets, which require tool-calling for accurate answers. Additionally, we
apply our method to retrieval-augmented generation (RAG) systems and conduct a
proof-of-concept experiment demonstrating the effectiveness of our uncertainty
metrics in scenarios where external information retrieval is needed. Our
results show that the framework is effective in enhancing trust in LLM-based
systems, especially in cases where the LLM's internal knowledge is insufficient
and external tools are required.

</details>


### [28] [Sequential Monte Carlo for Policy Optimization in Continuous POMDPs](https://arxiv.org/abs/2505.16732)
*Hany Abdulsamad, Sahel Iqbal, Simo Särkkä*

**主要类别:** cs.LG

**概要:** 提出了一种新的策略优化框架用于解决连续部分可观察马尔可夫决策过程中的探索与利用平衡问题。该方法通过非马尔可夫费曼-卡茨模型将策略学习视为概率推断，并开发了嵌套序列蒙特卡洛算法来估计历史相关的策略梯度。实验表明该算法在标准连续部分可观察马尔可夫决策过程基准测试中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 解决部分可观测环境下决策中探索与利用之间的平衡问题。

**方法:** 引入新的策略优化框架，通过非马尔可夫费曼-卡茨模型进行概率推断，并采用嵌套序列蒙特卡洛算法估计政策梯度。

**结果:** 算法在标准连续部分可观察马尔可夫决策过程基准测试中表现出色。

**结论:** 提出的策略优化框架能够有效处理部分可观测环境下的决策问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sequential+Monte+Carlo+for+Policy+Optimization+in+Continuous+POMDPs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16732，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16732&send_immediately=true&force_search=false)

**原文摘要:** Optimal decision-making under partial observability requires agents to
balance reducing uncertainty (exploration) against pursuing immediate
objectives (exploitation). In this paper, we introduce a novel policy
optimization framework for continuous partially observable Markov decision
processes (POMDPs) that explicitly addresses this challenge. Our method casts
policy learning as probabilistic inference in a non-Markovian Feynman--Kac
model that inherently captures the value of information gathering by
anticipating future observations, without requiring extrinsic exploration
bonuses or handcrafted heuristics. To optimize policies under this model, we
develop a nested sequential Monte Carlo~(SMC) algorithm that efficiently
estimates a history-dependent policy gradient under samples from the optimal
trajectory distribution induced by the POMDP. We demonstrate the effectiveness
of our algorithm across standard continuous POMDP benchmarks, where existing
methods struggle to act under uncertainty.

</details>


### [29] [A Generic Framework for Conformal Fairness](https://arxiv.org/abs/2505.16115)
*Aditya T. Vadlamani, Anutam Srinivasan, Pranav Maneriker, Ali Payani, Srinivasan Parthasarathy*

**主要类别:** cs.LG

**概要:** 提出了一种基于一致性预测的公平性概念（一致性公平性），并提供了一个算法框架来控制不同敏感组之间的覆盖率差距。该框架适用于非独立同分布的数据类型，如图数据，并在图和表格数据集上验证了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统一致性预测对数据集中敏感属性的存在不提供保证，本文旨在解决这一问题。

**方法:** 提出了基于一致性预测的公平性概念，并设计了一个算法框架来控制不同敏感组之间的覆盖率差距。

**结果:** 在图数据和表格数据集上的实验表明，该算法能够控制与公平性相关的差距，并且覆盖率符合理论预期。

**结论:** 本文提出的方法可以有效实现一致性公平性，并且具有广泛的应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Generic+Framework+for+Conformal+Fairness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16115，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16115&send_immediately=true&force_search=false)

**原文摘要:** Conformal Prediction (CP) is a popular method for uncertainty quantification
with machine learning models. While conformal prediction provides probabilistic
guarantees regarding the coverage of the true label, these guarantees are
agnostic to the presence of sensitive attributes within the dataset. In this
work, we formalize \textit{Conformal Fairness}, a notion of fairness using
conformal predictors, and provide a theoretically well-founded algorithm and
associated framework to control for the gaps in coverage between different
sensitive groups. Our framework leverages the exchangeability assumption
(implicit to CP) rather than the typical IID assumption, allowing us to apply
the notion of Conformal Fairness to data types and tasks that are not IID, such
as graph data. Experiments were conducted on graph and tabular datasets to
demonstrate that the algorithm can control fairness-related gaps in addition to
coverage aligned with theoretical expectations.

</details>


### [30] [Meta-reinforcement learning with minimum attention](https://arxiv.org/abs/2505.16741)
*Pilhwa Lee, Shashank Gupta*

**主要类别:** cs.LG

**概要:** Minimum attention is applied in reinforcement learning as part of the rewards, showing better performance than state-of-the-art algorithms.


<details>
  <summary>更多</summary>
  
**动机:** To emulate biological control and improve reinforcement learning performance.

**方法:** Using minimum attention in reinforcement learning, alternating ensemble-based model learning and gradient-based meta-policy learning.

**结果:** Outperforms state-of-the-art algorithms in model-free and model-based RL in terms of fast adaptation and variance reduction.

**结论:** Minimum attention improves energy efficiency and provides a promising approach for reinforcement learning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-reinforcement+learning+with+minimum+attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16741，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16741&send_immediately=true&force_search=false)

**原文摘要:** Minimum attention applies the least action principle in the changes of
control concerning state and time, first proposed by Brockett. The involved
regularization is highly relevant in emulating biological control, such as
motor learning. We apply minimum attention in reinforcement learning (RL) as
part of the rewards and investigate its connection to meta-learning and
stabilization. Specifically, model-based meta-learning with minimum attention
is explored in high-dimensional nonlinear dynamics. Ensemble-based model
learning and gradient-based meta-policy learning are alternately performed.
Empirically, we show that the minimum attention does show outperforming
competence in comparison to the state-of-the-art algorithms in model-free and
model-based RL, i.e., fast adaptation in few shots and variance reduction from
the perturbations of the model and environment. Furthermore, the minimum
attention demonstrates the improvement in energy efficiency.

</details>


### [31] [Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning](https://arxiv.org/abs/2505.16122)
*Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou*

**主要类别:** cs.LG

**概要:** 提出了一种名为Plan-and-Budget的新框架，通过分解复杂查询和基于估计复杂度的自适应调度来分配令牌预算，提高了各种任务和模型的推理效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有大型语言模型在复杂推理任务上表现良好但推理计算效率低，存在过度思考和欠思考的问题。

**方法:** 开发了BBAM（贝叶斯预算分配模型），提出了E³指标，并提出了Plan-and-Budget框架，该框架是一种与模型无关的测试时框架。

**结果:** Plan-and-Budget在多个任务和模型上提高了推理效率，提升了较小模型的表现，使其接近更大模型的效率。

**结论:** Plan-and-Budget能够提高推理效率并缩小性能差距，无需重新训练模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Plan+and+Budget%3A+Effective+and+Efficient+Test-Time+Scaling+on+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16122，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16122&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have achieved remarkable success in complex
reasoning tasks, but their inference remains computationally inefficient. We
observe a common failure mode in many prevalent LLMs, overthinking, where
models generate verbose and tangential reasoning traces even for simple
queries. Recent works have tried to mitigate this by enforcing fixed token
budgets, however, this can lead to underthinking, especially on harder
problems. Through empirical analysis, we identify that this inefficiency often
stems from unclear problem-solving strategies. To formalize this, we develop a
theoretical model, BBAM (Bayesian Budget Allocation Model), which models
reasoning as a sequence of sub-questions with varying uncertainty, and
introduce the $E^3$ metric to capture the trade-off between correctness and
computation efficiency. Building on theoretical results from BBAM, we propose
Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex
queries into sub-questions and allocates token budgets based on estimated
complexity using adaptive scheduling. Plan-and-Budget improves reasoning
efficiency across a range of tasks and models, achieving up to +70% accuracy
gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it
elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger
model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close
performance gaps without retraining. Our code is available at
anonymous.4open.science/r/P-and-B-6513/.

</details>


### [32] [ICYM2I: The illusion of multimodal informativeness under missingness](https://arxiv.org/abs/2505.16953)
*Young Sang Choi, Vincent Jeanselme, Pierre Elias, Shalmali Joshi*

**主要类别:** cs.LG

**概要:** This paper addresses the issue of missing modalities in multimodal learning and introduces ICYM2I, a framework using inverse probability weighting to correct and evaluate predictive performance and information gain.


<details>
  <summary>更多</summary>
  
**动机:** The paper aims to tackle the problem of information gain estimation when modalities are missing due to various factors such as cost or hardware failure.

**方法:** Introduces ICYM2I, a framework based on inverse probability weighting to adjust for missingness in multimodal learning.

**结果:** Demonstrates the importance of the adjustment in estimating information gain under missingness on different datasets including synthetic, semi-synthetic, and real-world medical datasets.

**结论:** The work formalizes the problem of missingness in multimodal learning and shows how ignoring this can lead to biased results.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ICYM2I%3A+The+illusion+of+multimodal+informativeness+under+missingness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16953&send_immediately=true&force_search=false)

**原文摘要:** Multimodal learning is of continued interest in artificial intelligence-based
applications, motivated by the potential information gain from combining
different types of data. However, modalities collected and curated during
development may differ from the modalities available at deployment due to
multiple factors including cost, hardware failure, or -- as we argue in this
work -- the perceived informativeness of a given modality. Na{\"i}ve estimation
of the information gain associated with including an additional modality
without accounting for missingness may result in improper estimates of that
modality's value in downstream tasks. Our work formalizes the problem of
missingness in multimodal learning and demonstrates the biases resulting from
ignoring this process. To address this issue, we introduce ICYM2I (In Case You
Multimodal Missed It), a framework for the evaluation of predictive performance
and information gain under missingness through inverse probability
weighting-based correction. We demonstrate the importance of the proposed
adjustment to estimate information gain under missingness on synthetic,
semi-synthetic, and real-world medical datasets.

</details>


### [33] [Robust Invariant Representation Learning by Distribution Extrapolation](https://arxiv.org/abs/2505.16126)
*Kotaro Yoshida, Slavakis Konstantinos*

**主要类别:** cs.LG

**概要:** This paper addresses the limitations of current IRM approaches by introducing a new method based on synthetic distributional shifts, which improves environmental diversity and outperforms existing IRM variants.


<details>
  <summary>更多</summary>
  
**动机:** To enable out-of-distribution generalization in deep learning by learning invariant representations, overcoming the challenges of bi-level optimization and improving upon the limitations of existing IRM approaches.

**方法:** Proposes a novel extrapolation-based framework that enhances environmental diversity by augmenting the IRM penalty with synthetic distributional shifts.

**结果:** The proposed method consistently outperforms state-of-the-art IRM variants across various experimental settings, from synthetic setups to realistic over-parameterized scenarios.

**结论:** The study theoretically identifies a key limitation of many IRM variants and introduces a robust solution that enhances the effectiveness and reliability of invariant risk minimization.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Invariant+Representation+Learning+by+Distribution+Extrapolation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16126，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16126&send_immediately=true&force_search=false)

**原文摘要:** Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)
generalization in deep learning by learning invariant representations. As IRM
poses an inherently challenging bi-level optimization problem, most existing
approaches -- including IRMv1 -- adopt penalty-based single-level
approximations. However, empirical studies consistently show that these methods
often fail to outperform well-tuned empirical risk minimization (ERM),
highlighting the need for more robust IRM implementations. This work
theoretically identifies a key limitation common to many IRM variants: their
penalty terms are highly sensitive to limited environment diversity and
over-parameterization, resulting in performance degradation. To address this
issue, a novel extrapolation-based framework is proposed that enhances
environmental diversity by augmenting the IRM penalty through synthetic
distributional shifts. Extensive experiments -- ranging from synthetic setups
to realistic, over-parameterized scenarios -- demonstrate that the proposed
method consistently outperforms state-of-the-art IRM variants, validating its
effectiveness and robustness.

</details>


### [34] [Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models](https://arxiv.org/abs/2505.16959)
*Alessandro Favero, Antonio Sclocchi, Matthieu Wyart*

**主要类别:** cs.LG

**概要:** Diffusion probabilistic models generalize in natural data domains during training before memorization occurs, with memorization time proportional to dataset size. A phase diagram summarizes these findings.


<details>
  <summary>更多</summary>
  
**动机:** Understanding the mechanisms behind generalization in overparameterized diffusion models.

**方法:** Analyzing the relationship between generalization, memorization, and dataset size in diffusion models.

**结果:** Generalization happens before memorization in overparameterized diffusion models, with memorization time proportional to dataset size. This is also observed in models learning a probabilistic context-free grammar.

**结论:** A principled early-stopping criterion based on dataset size can optimize generalization and avoid memorization, with implications for hyperparameter transfer and privacy-sensitive applications.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bigger+Isn%27t+Always+Memorizing%3A+Early+Stopping+Overparameterized+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16959，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16959&send_immediately=true&force_search=false)

**原文摘要:** Diffusion probabilistic models have become a cornerstone of modern generative
AI, yet the mechanisms underlying their generalization remain poorly
understood. In fact, if these models were perfectly minimizing their training
loss, they would just generate data belonging to their training set, i.e.,
memorize, as empirically found in the overparameterized regime. We revisit this
view by showing that, in highly overparameterized diffusion models,
generalization in natural data domains is progressively achieved during
training before the onset of memorization. Our results, ranging from image to
language diffusion models, systematically support the empirical law that
memorization time is proportional to the dataset size. Generalization vs.
memorization is then best understood as a competition between time scales. We
show that this phenomenology is recovered in diffusion models learning a simple
probabilistic context-free grammar with random rules, where generalization
corresponds to the hierarchical acquisition of deeper grammar rules as training
time grows, and the generalization cost of early stopping can be characterized.
We summarize these results in a phase diagram. Overall, our results support
that a principled early-stopping criterion - scaling with dataset size - can
effectively optimize generalization while avoiding memorization, with direct
implications for hyperparameter transfer and privacy-sensitive applications.

</details>


### [35] [Scalable Graph Generative Modeling via Substructure Sequences](https://arxiv.org/abs/2505.16130)
*Zehong Wang, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye*

**主要类别:** cs.LG

**概要:** This paper introduces G$^2$PM, a scalable graph representation learning method using generative pre-training beyond traditional message-passing.


<details>
  <summary>更多</summary>
  
**动机:** Traditional message-passing GNNs have fundamental limitations like limited expressiveness and inability to model long-range dependencies.

**方法:** Generative Graph Pattern Machine (G$^2$PM) represents graph instances as sequences of substructures and uses generative pre-training to learn representations.

**结果:** G$^2$PM shows strong scalability and better performance than previous methods across various tasks.

**结论:** G$^2$PM is a new approach beyond message-passing for graph neural networks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Graph+Generative+Modeling+via+Substructure+Sequences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16130&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) has been predominantly driven by
message-passing, where node representations are iteratively updated via local
neighborhood aggregation. Despite their success, message-passing suffers from
fundamental limitations -- including constrained expressiveness,
over-smoothing, over-squashing, and limited capacity to model long-range
dependencies. These issues hinder scalability: increasing data size or model
size often fails to yield improved performance, limiting the viability of GNNs
as backbones for graph foundation models. In this work, we explore pathways
beyond message-passing and introduce Generative Graph Pattern Machine
(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM
represents graph instances (nodes, edges, or entire graphs) as sequences of
substructures, and employs generative pre-training over the sequences to learn
generalizable, transferable representations. Empirically, G$^2$PM demonstrates
strong scalability: on the ogbn-arxiv benchmark, it continues to improve with
model sizes up to 60M parameters, outperforming prior generative approaches
that plateau at significantly smaller scales (e.g., 3M). In addition, we
systematically analyze the model design space, highlighting key architectural
choices that contribute to its scalability and generalization. Across diverse
tasks -- including node classification, graph classification, and transfer
learning -- G$^2$PM consistently outperforms strong baselines, establishing a
compelling foundation for scalable graph learning. The code and dataset are
available at https://github.com/Zehong-Wang/G2PM.

</details>


### [36] [Guided Diffusion Sampling on Function Spaces with Applications to PDEs](https://arxiv.org/abs/2505.17004)
*Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul Ye, Kamyar Azizzadenesheli, Anima Anandkumar*

**主要类别:** cs.LG

**概要:** 提出了一种用于基于PDE的逆问题条件采样的通用框架，该框架通过函数空间扩散模型和插件式指导实现从极稀疏或噪声测量中恢复整个解。数学分析扩展了Tweedie公式到无限维Hilbert空间，提供了后验采样的理论基础。实验显示在五个PDE任务中，方法比最先进的固定分辨率扩散基准提高了32%的准确性，同时减少了4倍的采样步骤。这是首个不依赖离散化的扩散框架，适用于PDE的正向和反向问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在处理基于PDE的逆问题时，通常需要大量的观测数据，而本研究旨在解决从极稀疏或噪声测量中恢复整个解的问题。

**方法:** 提出的方法首先训练一个无条件的、与离散无关的去噪模型，然后在推理阶段通过梯度引导机制来调整样本，使其符合稀疏观测数据。此外，还扩展了Tweedie公式到无限维Hilbert空间。

**结果:** 在五个PDE任务中，该方法实现了平均32%的准确性提升，并且减少了4倍的采样步骤。

**结论:** 这是首个不依赖离散化的扩散框架，为基于PDE的正向和逆向问题提供了一个实用且灵活的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Guided+Diffusion+Sampling+on+Function+Spaces+with+Applications+to+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17004&send_immediately=true&force_search=false)

**原文摘要:** We propose a general framework for conditional sampling in PDE-based inverse
problems, targeting the recovery of whole solutions from extremely sparse or
noisy measurements. This is accomplished by a function-space diffusion model
and plug-and-play guidance for conditioning. Our method first trains an
unconditional discretization-agnostic denoising model using neural operator
architectures. At inference, we refine the samples to satisfy sparse
observation data via a gradient-based guidance mechanism. Through rigorous
mathematical analysis, we extend Tweedie's formula to infinite-dimensional
Hilbert spaces, providing the theoretical foundation for our posterior sampling
approach. Our method (FunDPS) accurately captures posterior distributions in
function spaces under minimal supervision and severe data scarcity. Across five
PDE tasks with only 3% observation, our method achieves an average 32% accuracy
improvement over state-of-the-art fixed-resolution diffusion baselines while
reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning
ensures strong cross-resolution generalizability. To the best of our knowledge,
this is the first diffusion-based framework to operate independently of
discretization, offering a practical and flexible solution for forward and
inverse problems in the context of PDEs. Code is available at
https://github.com/neuraloperator/FunDPS

</details>


### [37] [Multimodal Online Federated Learning with Modality Missing in Internet of Things](https://arxiv.org/abs/2505.16138)
*Heqiang Wang, Xiang Liu, Xiaoxiong Zhong, Lixing Chen, Fangming Liu, Weizhe Zhang*

**主要类别:** cs.LG

**概要:** This paper introduces MMO-FL, a new framework for multimodal online federated learning in IoT environments, and the PMM algorithm to handle missing modalities, showing improved performance.


<details>
  <summary>更多</summary>
  
**动机:** To handle large amounts of multimodal data generated by IoT devices and the challenges of real-time data processing with limited storage.

**方法:** Developing MMO-FL framework and PMM algorithm for compensating missing modalities in decentralized multimodal learning.

**结果:** Superior performance of PMM algorithm compared to benchmarks on two multimodal datasets.

**结论:** MMO-FL framework addresses the challenges of handling multimodal data in IoT environments, and PMM algorithm effectively mitigates the impact of missing modalities.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multimodal+Online+Federated+Learning+with+Modality+Missing+in+Internet+of+Things，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16138，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16138&send_immediately=true&force_search=false)

**原文摘要:** The Internet of Things (IoT) ecosystem generates vast amounts of multimodal
data from heterogeneous sources such as sensors, cameras, and microphones. As
edge intelligence continues to evolve, IoT devices have progressed from simple
data collection units to nodes capable of executing complex computational
tasks. This evolution necessitates the adoption of distributed learning
strategies to effectively handle multimodal data in an IoT environment.
Furthermore, the real-time nature of data collection and limited local storage
on edge devices in IoT call for an online learning paradigm. To address these
challenges, we introduce the concept of Multimodal Online Federated Learning
(MMO-FL), a novel framework designed for dynamic and decentralized multimodal
learning in IoT environments. Building on this framework, we further account
for the inherent instability of edge devices, which frequently results in
missing modalities during the learning process. We conduct a comprehensive
theoretical analysis under both complete and missing modality scenarios,
providing insights into the performance degradation caused by missing
modalities. To mitigate the impact of modality missing, we propose the
Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype
learning to effectively compensate for missing modalities. Experimental results
on two multimodal datasets further demonstrate the superior performance of PMM
compared to benchmarks.

</details>


### [38] [Understanding Prompt Tuning and In-Context Learning via Meta-Learning](https://arxiv.org/abs/2505.17010)
*Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter*

**主要类别:** cs.LG

**概要:** 本文从贝叶斯视角探讨了最优提示的理解及其局限性，并通过实验证明了软提示的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前提示优化方法主要基于经验发展，缺乏对提示概念性的理解。

**方法:** 从贝叶斯预测器的角度解释元训练神经网络的行为，并研究最优提示的标准。

**结果:** 通过教育实验验证了理论，在LSTMs和Transformers上比较了不同的前缀微调版本和不同的权重调整方法，证实了软提示的有效性。

**结论:** 提出了从贝叶斯视角理解最优提示的方法，并揭示了仅通过调整权重才能克服的提示的基本限制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Prompt+Tuning+and+In-Context+Learning+via+Meta-Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17010，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17010&send_immediately=true&force_search=false)

**原文摘要:** Prompting is one of the main ways to adapt a pretrained model to target
tasks. Besides manually constructing prompts, many prompt optimization methods
have been proposed in the literature. Method development is mainly empirically
driven, with less emphasis on a conceptual understanding of prompting. In this
paper we discuss how optimal prompting can be understood through a Bayesian
view, which also implies some fundamental limitations of prompting that can
only be overcome by tuning weights. The paper explains in detail how
meta-trained neural networks behave as Bayesian predictors over the pretraining
distribution, whose hallmark feature is rapid in-context adaptation. Optimal
prompting can be studied formally as conditioning these Bayesian predictors,
yielding criteria for target tasks where optimal prompting is and is not
possible. We support the theory with educational experiments on LSTMs and
Transformers, where we compare different versions of prefix-tuning and
different weight-tuning methods. We also confirm that soft prefixes, which are
sequences of real-valued vectors outside the token alphabet, can lead to very
effective prompts for trained and even untrained networks by manipulating
activations in ways that are not achievable by hard tokens. This adds an
important mechanistic aspect beyond the conceptual Bayesian theory.

</details>


### [39] [NAN: A Training-Free Solution to Coefficient Estimation in Model Merging](https://arxiv.org/abs/2505.16148)
*Chongjie Si, Kangtao Lv, Jingjing Jiang, Yadao Wang, Yongwei Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen*

**主要类别:** cs.LG

**概要:** This work proposes NAN, a novel approach for model merging that uses least-squares optimization and parameter norm inversion to estimate merging coefficients, showing consistent performance improvements across various tasks.


<details>
  <summary>更多</summary>
  
**动机:** Existing model merging approaches often rely on heuristics, which limits their scalability and generality.

**方法:** NAN estimates merging coefficients via the inverse of parameter norm based on the insight that optimal merging weights should scale with task-specific information.

**结果:** NAN improves the performance of baseline methods in extensive experiments.

**结论:** NAN provides a training-free, plug-and-play method for model merging that is applicable to a wide range of merging strategies.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NAN%3A+A+Training-Free+Solution+to+Coefficient+Estimation+in+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16148，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16148&send_immediately=true&force_search=false)

**原文摘要:** Model merging offers a training-free alternative to multi-task learning by
combining independently fine-tuned models into a unified one without access to
raw data. However, existing approaches often rely on heuristics to determine
the merging coefficients, limiting their scalability and generality. In this
work, we revisit model merging through the lens of least-squares optimization
and show that the optimal merging weights should scale with the amount of
task-specific information encoded in each model. Based on this insight, we
propose NAN, a simple yet effective method that estimates model merging
coefficients via the inverse of parameter norm. NAN is training-free,
plug-and-play, and applicable to a wide range of merging strategies. Extensive
experiments on show that NAN consistently improves performance of baseline
methods.

</details>


### [40] [Why Can Accurate Models Be Learned from Inaccurate Annotations?](https://arxiv.org/abs/2505.16159)
*Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen*

**主要类别:** cs.LG

**概要:** 研究了从不准确标注中学习的现象，并提出了一种轻量级插件LIP来帮助分类器在存在标签不准确的情况下保持主子空间信息并减轻噪声影响。


<details>
  <summary>更多</summary>
  
**动机:** 由于精确标记的成本高昂，基于不准确标注的学习引起了广泛关注。然而，尽管存在错误标签，模型仍能保留准确预测的能力，这一现象背后的原因尚不清楚。

**方法:** 通过从经验性和理论性两个角度分析权重矩阵，发现标签不准确性主要累积在较低奇异值分量中，并微妙地扰动主子空间。提出了LIP插件。

**结果:** 证明了在适度标签不准确的情况下，主子空间的角度偏差最小，解释了为什么模型仍然可以有效地推广。实验表明，LIP在各种不准确条件下都能提高现有算法的性能。

**结论:** 研究提供了对模型在不准确监督下鲁棒性的有价值的理论和实践见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Can+Accurate+Models+Be+Learned+from+Inaccurate+Annotations%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16159，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16159&send_immediately=true&force_search=false)

**原文摘要:** Learning from inaccurate annotations has gained significant attention due to
the high cost of precise labeling. However, despite the presence of erroneous
labels, models trained on noisy data often retain the ability to make accurate
predictions. This intriguing phenomenon raises a fundamental yet largely
unexplored question: why models can still extract correct label information
from inaccurate annotations remains unexplored. In this paper, we conduct a
comprehensive investigation into this issue. By analyzing weight matrices from
both empirical and theoretical perspectives, we find that label inaccuracy
primarily accumulates noise in lower singular components and subtly perturbs
the principal subspace. Within a certain range, the principal subspaces of
weights trained on inaccurate labels remain largely aligned with those learned
from clean labels, preserving essential task-relevant information. We formally
prove that the angles of principal subspaces exhibit minimal deviation under
moderate label inaccuracy, explaining why models can still generalize
effectively. Building on these insights, we propose LIP, a lightweight plug-in
designed to help classifiers retain principal subspace information while
mitigating noise induced by label inaccuracy. Extensive experiments on tasks
with various inaccuracy conditions demonstrate that LIP consistently enhances
the performance of existing algorithms. We hope our findings can offer valuable
theoretical and practical insights to understand of model robustness under
inaccurate supervision.

</details>


### [41] [Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare](https://arxiv.org/abs/2505.16190)
*Navid Seidi, Satyaki Roy, Sajal Das*

**主要类别:** cs.LG

**概要:** 提出了一种用于联邦医疗保健的鲁棒同行驱动的声誉机制，该机制采用混合通信模型整合分散的同行反馈，并通过差分隐私保护敏感信息，同时动态调整信任分数以应对数据异质性和声誉赤字。实验表明，该方法在合成数据集和SEER数据集上均表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 解决联邦学习在数字健康中的机构异质性、持续声誉缺乏及贡献不可靠等问题。

**方法:** 设计一种基于混合通信模型的声誉机制，采用差分隐私保护敏感信息并动态调整信任分数。

**结果:** 在多个联邦节点上实现了高且稳定的C-index值，有效降低了噪声客户端更新的影响。

**结论:** 提出的声誉机制能够有效应对联邦学习中的数据异质性和声誉问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Federated+Survival+Analysis+through+Peer-Driven+Client+Reputation+in+Healthcare，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16190，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16190&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) holds great promise for digital health by enabling
collaborative model training without compromising patient data privacy.
However, heterogeneity across institutions, lack of sustained reputation, and
unreliable contributions remain major challenges. In this paper, we propose a
robust, peer-driven reputation mechanism for federated healthcare that employs
a hybrid communication model to integrate decentralized peer feedback with
clustering-based noise handling to enhance model aggregation. Crucially, our
approach decouples the federated aggregation and reputation mechanisms by
applying differential privacy to client-side model updates before sharing them
for peer evaluation. This ensures sensitive information remains protected
during reputation computation, while unaltered updates are sent to the server
for global model training. Using the Cox Proportional Hazards model for
survival analysis across multiple federated nodes, our framework addresses both
data heterogeneity and reputation deficit by dynamically adjusting trust scores
based on local performance improvements measured via the concordance index.
Experimental evaluations on both synthetic datasets and the SEER dataset
demonstrate that our method consistently achieves high and stable C-index
values, effectively down-weighing noisy client updates and outperforming FL
methods that lack a reputation system.

</details>


### [42] [NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics](https://arxiv.org/abs/2505.16210)
*Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei*

**主要类别:** cs.LG

**概要:** This paper presents NQKV, a new algorithm that uses per-block quantile quantization to enable more efficient inference in large language models.


<details>
  <summary>更多</summary>
  
**动机:** To reduce memory resource consumption of the Key-Value (KV) cache during inference which has become a major bottleneck in LLM deployment.

**方法:** Analyzed the element distribution of the KV cache and designed the NQKV algorithm which employs per-block quantile quantization to achieve information-theoretically optimal quantization error.

**结果:** Without significantly compromising model output quality, NQKV enables the OPT model to perform inference with an 2x larger batch size or a 4x longer context length, and it improves throughput by 9.3x compared to when the KV cache is not used.

**结论:** The proposed NQKV algorithm achieves significant improvements in throughput while maintaining model output quality.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NQKV%3A+A+KV+Cache+Quantization+Scheme+Based+on+Normal+Distribution+Characteristics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16210，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16210&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable proficiency across
a wide range of tasks. However, LLMs often require larger batch sizes to
enhance throughput or longer context lengths to meet task demands, which
significantly increases the memory resource consumption of the Key-Value (KV)
cache during inference, becoming a major bottleneck in LLM deployment. To
address this issue, quantization is a common and straightforward approach.
Currently, quantization methods for activations are limited to 8-bit, and
quantization to even lower bits can lead to substantial accuracy drops. To
further save space by quantizing the KV cache to even lower bits, we analyzed
the element distribution of the KV cache and designed the NQKV algorithm. Since
the elements within each block of the KV cache follow a normal distribution,
NQKV employs per-block quantile quantization to achieve
information-theoretically optimal quantization error. Without significantly
compromising model output quality, NQKV enables the OPT model to perform
inference with an 2x larger batch size or a 4x longer context length, and it
improves throughput by 9.3x compared to when the KV cache is not used.

</details>


### [43] [Reward-Aware Proto-Representations in Reinforcement Learning](https://arxiv.org/abs/2505.16217)
*Hon Tik Tse, Siddarth Chandrasekar, Marlos C. Machado*

**主要类别:** cs.LG

**概要:** This paper introduces the Default Representation (DR), which extends the Successor Representation (SR) by incorporating reward dynamics. The authors provide theoretical foundations for the DR in tabular and function approximation cases and empirically demonstrate its advantages in various RL tasks.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitation of the SR being reward-agnostic and introduce a reward-aware representation.

**方法:** Theoretical derivation of dynamic programming and temporal-difference methods for DR, characterization of its vector space basis, and extension to function approximation through default features.

**结果:** DR shows qualitatively different and quantitatively better performance than SR in tasks like reward shaping, option discovery, exploration, and transfer learning.

**结论:** The DR offers a reward-aware alternative to the SR with improved performance in several reinforcement learning settings.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reward-Aware+Proto-Representations+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16217，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16217&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the successor representation (SR) has attracted increasing
attention in reinforcement learning (RL), and it has been used to address some
of its key challenges, such as exploration, credit assignment, and
generalization. The SR can be seen as representing the underlying credit
assignment structure of the environment by implicitly encoding its induced
transition dynamics. However, the SR is reward-agnostic. In this paper, we
discuss a similar representation that also takes into account the reward
dynamics of the problem. We study the default representation (DR), a recently
proposed representation with limited theoretical (and empirical) analysis.
Here, we lay some of the theoretical foundation underlying the DR in the
tabular case by (1) deriving dynamic programming and (2) temporal-difference
methods to learn the DR, (3) characterizing the basis for the vector space of
the DR, and (4) formally extending the DR to the function approximation case
through default features. Empirically, we analyze the benefits of the DR in
many of the settings in which the SR has been applied, including (1) reward
shaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our
results show that, compared to the SR, the DR gives rise to qualitatively
different, reward-aware behaviour and quantitatively better performance in
several settings.

</details>


### [44] [Realistic Evaluation of TabPFN v2 in Open Environments](https://arxiv.org/abs/2505.16226)
*Zi-Jian Cheng, Zi-Yi Jia, Zhi Zhou, Yu-Feng Li, Lan-Zhe Guo*

**主要类别:** cs.LG

**概要:** This paper evaluates TabPFN v2's adaptability in open environments and finds it unsuitable for most real-world challenges, though it can handle small-scale, covariate-shifted, and class-balanced tasks.


<details>
  <summary>更多</summary>
  
**动机:** To investigate whether TabPFN v2 maintains good performance in open environments where real-world challenges like data distribution shifts are common.

**方法:** Constructing a unified evaluation framework covering various real-world challenges to assess TabPFN v2's robustness in open environment scenarios.

**结果:** TabPFN v2 shows significant limitations in open environments, being only suitable for small-scale, covariate-shifted, and class-balanced tasks.

**结论:** Tree-based models remain superior for general tabular tasks in open environments, and open environments tabular benchmarks, multi-metric evaluation, and universal modules are recommended to enhance model robustness.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Realistic+Evaluation+of+TabPFN+v2+in+Open+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16226，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16226&send_immediately=true&force_search=false)

**原文摘要:** Tabular data, owing to its ubiquitous presence in real-world domains, has
garnered significant attention in machine learning research. While tree-based
models have long dominated tabular machine learning tasks, the recently
proposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled
performance and scalability potential. Although extensive research has been
conducted on TabPFN v2 to further improve performance, the majority of this
research remains confined to closed environments, neglecting the challenges
that frequently arise in open environments. This raises the question: Can
TabPFN v2 maintain good performance in open environments? To this end, we
conduct the first comprehensive evaluation of TabPFN v2's adaptability in open
environments. We construct a unified evaluation framework covering various
real-world challenges and assess the robustness of TabPFN v2 under open
environments scenarios using this framework. Empirical results demonstrate that
TabPFN v2 shows significant limitations in open environments but is suitable
for small-scale, covariate-shifted, and class-balanced tasks. Tree-based models
remain the optimal choice for general tabular tasks in open environments. To
facilitate future research on open environments challenges, we advocate for
open environments tabular benchmarks, multi-metric evaluation, and universal
modules to strengthen model robustness. We publicly release our evaluation
framework at https://anonymous.4open.science/r/tabpfn-ood-4E65.

</details>


### [45] [Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies](https://arxiv.org/abs/2505.16242)
*Runze Yan, Xun Shen, Akifumi Wachi, Sebastien Gros, Anni Zhao, Xiao Hu*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Offline+Guarded+Safe+Reinforcement+Learning+for+Medical+Treatment+Optimization+Strategies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16242，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16242&send_immediately=true&force_search=false)

**原文摘要:** When applying offline reinforcement learning (RL) in healthcare scenarios,
the out-of-distribution (OOD) issues pose significant risks, as inappropriate
generalization beyond clinical expertise can result in potentially harmful
recommendations. While existing methods like conservative Q-learning (CQL)
attempt to address the OOD issue, their effectiveness is limited by only
constraining action selection by suppressing uncertain actions. This
action-only regularization imitates clinician actions that prioritize
short-term rewards, but it fails to regulate downstream state trajectories,
thereby limiting the discovery of improved long-term treatment strategies. To
safely improve policy beyond clinician recommendations while ensuring that
state-action trajectories remain in-distribution, we propose \textit{Offline
Guarded Safe Reinforcement Learning} ($\mathsf{OGSRL}$), a theoretically
grounded model-based offline RL framework. $\mathsf{OGSRL}$ introduces a novel
dual constraint mechanism for improving policy with reliability and safety.
First, the OOD guardian is established to specify clinically validated regions
for safe policy exploration. By constraining optimization within these regions,
it enables the reliable exploration of treatment strategies that outperform
clinician behavior by leveraging the full patient state history, without
drifting into unsupported state-action trajectories. Second, we introduce a
safety cost constraint that encodes medical knowledge about physiological
safety boundaries, providing domain-specific safeguards even in areas where
training data might contain potentially unsafe interventions. Notably, we
provide theoretical guarantees on safety and near-optimality: policies that
satisfy these constraints remain in safe and reliable regions and achieve
performance close to the best possible policy supported by the data.

</details>


### [46] [Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems](https://arxiv.org/abs/2505.16248)
*Wenxuan Zhu, Qiyuan Wu, Tengda Tang, Renzi Meng, Sheng Chai, Xuehui Quan*

**主要类别:** cs.LG

**概要:** 提出了一种基于图神经网络的分布式系统多节点协作感知机制，解决了多节点感知和延迟调度响应的问题。通过构造多层图神经网络实现高效的信息聚合和动态状态推理，并设计了融合局部状态与全局特征的感知表示方法。实验表明该方法在任务完成率、平均延迟、负载均衡和传输效率等方面优于主流算法。


<details>
  <summary>更多</summary>
  
**动机:** 解决分布式系统中的多节点感知和延迟调度响应问题。

**方法:** 提出基于图神经网络的多节点协作感知机制，包括消息传递和状态更新模块，以及融合局部状态与全局特征的感知表示方法。

**结果:** 提出的机制在任务完成率、平均延迟、负载均衡和传输效率等方面表现出色，优于主流算法。

**结论:** 所提方法能够快速收敛并有效应对复杂系统状态，具有优越的感知能力和协同调度性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Neural+Network-Based+Collaborative+Perception+for+Adaptive+Scheduling+in+Distributed+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16248，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16248&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the limitations of multi-node perception and delayed
scheduling response in distributed systems by proposing a GNN-based multi-node
collaborative perception mechanism. The system is modeled as a graph structure.
Message-passing and state-update modules are introduced. A multi-layer graph
neural network is constructed to enable efficient information aggregation and
dynamic state inference among nodes. In addition, a perception representation
method is designed by fusing local states with global features. This improves
each node's ability to perceive the overall system status. The proposed method
is evaluated within a customized experimental framework. A dataset featuring
heterogeneous task loads and dynamic communication topologies is used.
Performance is measured in terms of task completion rate, average latency, load
balancing, and transmission efficiency. Experimental results show that the
proposed method outperforms mainstream algorithms under various conditions,
including limited bandwidth and dynamic structural changes. It demonstrates
superior perception capabilities and cooperative scheduling performance. The
model achieves rapid convergence and efficient responses to complex system
states.

</details>


### [47] [Small-to-Large Generalization: Data Influences Models Consistently Across Scale](https://arxiv.org/abs/2505.16260)
*Alaa Khaddaj, Logan Engstrom, Aleksander Madry*

**主要类别:** cs.LG

**概要:** This paper investigates how training data distribution influences model behavior across different compute scales for large-scale language models.


<details>
  <summary>更多</summary>
  
**动机:** To understand how choice of training data affects large-scale models since changes in data do not influence smaller and larger models identically.

**方法:** Correlating small- and large-scale language model predictions across choice of training data.

**结果:** Small- and large-scale language model predictions generally highly correlate across choice of training data.

**结论:** Proxy scale affects effectiveness in downstream proxy model applications such as data attribution and dataset selection.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Small-to-Large+Generalization%3A+Data+Influences+Models+Consistently+Across+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16260&send_immediately=true&force_search=false)

**原文摘要:** Choice of training data distribution greatly influences model behavior. Yet,
in large-scale settings, precisely characterizing how changes in training data
affects predictions is often difficult due to model training costs. Current
practice is to instead extrapolate from scaled down, inexpensive-to-train proxy
models. However, changes in data do not influence smaller and larger models
identically. Therefore, understanding how choice of data affects large-scale
models raises the question: how does training data distribution influence model
behavior across compute scale? We find that small- and large-scale language
model predictions (generally) do highly correlate across choice of training
data. Equipped with these findings, we characterize how proxy scale affects
effectiveness in two downstream proxy model applications: data attribution and
dataset selection.

</details>


### [48] [Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models](https://arxiv.org/abs/2505.16265)
*Ilgee Hong, Changlong Yu, Liang Qiu, Weixiang Yan, Zhenghao Xu, Haoming Jiang, Qingru Zhang, Qin Lu, Xin Liu, Chao Zhang, Tuo Zhao*

**主要类别:** cs.LG

**概要:** 提出了一种名为Think-RM的新框架，该框架通过建模内部思考过程来增强生成奖励模型（GenRMs）的长期推理能力。Think-RM生成灵活的自我指导推理轨迹，并提出了一种新的基于成对偏好的强化学习从人类反馈（RLHF）管道，直接优化策略使用成对偏好奖励。实验表明，Think-RM在RM-Bench上达到了最先进的结果，比Bradley-Terry奖励模型和垂直扩展的GenRM分别高出8%和10%。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成奖励模型（GenRMs）存在推理深度不足的问题，且其输出与标准RLHF算法不兼容。

**方法:** 提出了一种新的训练框架Think-RM，通过建模内部思考过程增强GenRMs的长期推理能力，包括自我反思、假设推理和发散推理等高级能力。此外，还提出了一种新的基于成对偏好的RLHF管道，直接优化策略使用成对偏好奖励。

**结果:** Think-RM在RM-Bench上达到了最先进的结果，比Bradley-Terry奖励模型和垂直扩展的GenRM分别高出8%和10%。当与新的RLHF管道结合时，其端到端策略性能优于传统方法。

**结论:** Think-RM显著提高了GenRMs的推理能力和RLHF的效果，为未来的奖励建模研究提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think-RM%3A+Enabling+Long-Horizon+Reasoning+in+Generative+Reward+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16265，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16265&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning from human feedback (RLHF) has become a powerful
post-training paradigm for aligning large language models with human
preferences. A core challenge in RLHF is constructing accurate reward signals,
where the conventional Bradley-Terry reward models (BT RMs) often suffer from
sensitivity to data size and coverage, as well as vulnerability to reward
hacking. Generative reward models (GenRMs) offer a more robust alternative by
generating chain-of-thought (CoT) rationales followed by a final reward.
However, existing GenRMs rely on shallow, vertically scaled reasoning, limiting
their capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.
Moreover, their pairwise preference outputs are incompatible with standard RLHF
algorithms that require pointwise reward signals. In this work, we introduce
Think-RM, a training framework that enables long-horizon reasoning in GenRMs by
modeling an internal thinking process. Rather than producing structured,
externally provided rationales, Think-RM generates flexible, self-guided
reasoning traces that support advanced capabilities such as self-reflection,
hypothetical reasoning, and divergent reasoning. To elicit these reasoning
abilities, we first warm-up the models by supervised fine-tuning (SFT) over
long CoT data. We then further improve the model's long-horizon abilities by
rule-based reinforcement learning (RL). In addition, we propose a novel
pairwise RLHF pipeline that directly optimizes policies using pairwise
preference rewards, eliminating the need for pointwise reward conversion and
enabling more effective use of Think-RM outputs. Experiments show that Think-RM
achieves state-of-the-art results on RM-Bench, outperforming both BT RM and
vertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,
it demonstrates superior end-policy performance compared to traditional
approaches.

</details>


### [49] [Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse](https://arxiv.org/abs/2505.16284)
*Josh Alman, Zhao Song*

**主要类别:** cs.LG

**概要:** 本研究探讨了大型语言模型中注意力机制的时间复杂度问题，指出为了保持表达能力，权重必须足够大，否则会出现层坍塌现象，这使得具有表现力的Transformer的注意力计算时间不可避免地为二次级。


<details>
  <summary>更多</summary>
  
**动机:** 研究的动机在于理解为什么在大型语言模型中，注意力机制的前向和后向计算需要二次时间，以及如何避免表示能力的减弱。

**方法:** 通过理论分析和引入层坍塌的概念，研究了不同条件下注意力机制的时间复杂度。

**结果:** 发现即使有跳跃连接，如果权重较小，层坍塌仍然会发生；只有较大的权重才能防止这些表示弱点。

**结论:** 为了保持大型语言模型的表达能力，需要较大的权重，因此二次运行时间对于表达性的Transformer是不可避免的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Only+Large+Weights+%28And+Not+Skip+Connections%29+Can+Prevent+the+Perils+of+Rank+Collapse，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16284，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16284&send_immediately=true&force_search=false)

**原文摘要:** Attention mechanisms lie at the heart of modern large language models (LLMs).
Straightforward algorithms for forward and backward (gradient) computation take
quadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]
and [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary
unless the model weights are small, in which case almost linear time algorithms
are possible. In this paper, we show that large weights are necessary to avoid
a strong preclusion to representational strength we call layer collapse, which
means that the entire network can be approximated well by a network with only a
single layer. Thus, the quadratic running time of attention is unavoidable for
expressive transformers.
  The notion of layer collapse that we introduce is a variant on the notion of
rank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They
showed that in Self Attention Networks with small weights and with skip
connections, rank collapse must occur. This is typically interpreted as
justifying the necessity of skip connections in expressive networks. However,
our result shows that even with skip connections, if the weights are small,
then layer collapse still occurs. Thus, only large weights, and not skip
connections, can prevent these representational weaknesses.

</details>


### [50] [Fairness under Competition](https://arxiv.org/abs/2505.16291)
*Ronen Gradwohl, Eilam Shapira, Moshe Tennenholtz*

**主要类别:** cs.LG

**概要:** This paper studies the impact of fair classifiers on ecosystem fairness in competitive environments, demonstrating that even fair individual classifiers can lead to unfair outcomes at the ecosystem level.


<details>
  <summary>更多</summary>
  
**动机:** To address the growing concern over algorithmic fairness in machine learning and examine how fair classifiers affect overall ecosystem fairness.

**方法:** Introduces a study of fairness with competing firms, analyzing classifier correlation and data overlap.

**结果:** Fair individual classifiers can result in an unfair ecosystem, and improving individual fairness might worsen ecosystem fairness.

**结论:** The paper calls for a new approach to ensure fairness across ecosystems rather than just at the individual classifier level.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fairness+under+Competition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16291，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16291&send_immediately=true&force_search=false)

**原文摘要:** Algorithmic fairness has emerged as a central issue in ML, and it has become
standard practice to adjust ML algorithms so that they will satisfy fairness
requirements such as Equal Opportunity. In this paper we consider the effects
of adopting such fair classifiers on the overall level of ecosystem fairness.
Specifically, we introduce the study of fairness with competing firms, and
demonstrate the failure of fair classifiers in yielding fair ecosystems. Our
results quantify the loss of fairness in systems, under a variety of
conditions, based on classifiers' correlation and the level of their data
overlap. We show that even if competing classifiers are individually fair, the
ecosystem's outcome may be unfair; and that adjusting biased algorithms to
improve their individual fairness may lead to an overall decline in ecosystem
fairness. In addition to these theoretical results, we also provide supporting
experimental evidence. Together, our model and results provide a novel and
essential call for action.

</details>


### [51] [Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution](https://arxiv.org/abs/2505.16305)
*Bingyang Cheng, Zhongtao Chen, Yichen Jin, Hao Zhang, Chen Zhang, Edmud Y. Lam, Yik-Chung Wu*

**主要类别:** cs.LG

**概要:** This paper introduces CP-GAMP, a scalable Bayesian Tensor CPD algorithm that avoids high-dimensional matrix inversions using GAMP and jointly infers tensor rank and noise power, showing significant runtime reduction compared to previous methods.


<details>
  <summary>更多</summary>
  
**动机:** Existing Bayesian methods for tensor CPD do not scale well for large tensors due to high-dimensional matrix inversions.

**方法:** Introduces CP-GAMP which uses GAMP to avoid matrix inversions and includes an expectation-maximization routine for joint inference of tensor rank and noise power.

**结果:** The proposed algorithm reduces runtime by 82.7% compared to the state-of-the-art variational Bayesian CPD method while maintaining similar reconstruction accuracy.

**结论:** CP-GAMP provides a scalable solution for Bayesian tensor CPD with efficient computation.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large-Scale+Bayesian+Tensor+Reconstruction%3A+An+Approximate+Message+Passing+Solution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16305&send_immediately=true&force_search=false)

**原文摘要:** Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for
tensor reconstruction. Although the Bayesian framework allows for principled
uncertainty quantification and automatic hyperparameter learning, existing
methods do not scale well for large tensors because of high-dimensional matrix
inversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD
algorithm. This algorithm leverages generalized approximate message passing
(GAMP) to avoid matrix inversions and incorporates an expectation-maximization
routine to jointly infer the tensor rank and noise power. Through multiple
experiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements
observed, the proposed algorithm reduces runtime by 82.7% compared to the
state-of-the-art variational Bayesian CPD method, while maintaining comparable
reconstruction accuracy.

</details>


### [52] [CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting](https://arxiv.org/abs/2505.16308)
*Xingyu Zhang, Wenwen Qiang, Siyu Zhao, Huijie Guo, Jiangmeng Li, Chuxiong Sun, Changwen Zheng*

**主要类别:** cs.LG

**概要:** This paper introduces a new forecasting paradigm and model, CAIFormer, which improves forecasting accuracy by focusing on causally relevant information.


<details>
  <summary>更多</summary>
  
**动机:** Existing multivariate time series forecasting methods have difficulty identifying variable-specific causal influences due to undifferentiated paradigms.

**方法:** The paper proposes an all-to-one forecasting paradigm and a novel forecasting model called CAIFormer.

**结果:** The proposed method can effectively exclude spurious correlations and improve forecasting accuracy.

**结论:** Extensive experiments show that the proposed CAIFormer outperforms other state-of-the-art methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CAIFormer%3A+A+Causal+Informed+Transformer+for+Multivariate+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16308，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16308&send_immediately=true&force_search=false)

**原文摘要:** Most existing multivariate time series forecasting methods adopt an
all-to-all paradigm that feeds all variable histories into a unified model to
predict their future values without distinguishing their individual roles.
However, this undifferentiated paradigm makes it difficult to identify
variable-specific causal influences and often entangles causally relevant
information with spurious correlations. To address this limitation, we propose
an all-to-one forecasting paradigm that predicts each target variable
separately. Specifically, we first construct a Structural Causal Model from
observational data and then, for each target variable, we partition the
historical sequence into four sub-segments according to the inferred causal
structure: endogenous, direct causal, collider causal, and spurious
correlation. The prediction relies solely on the first three causally relevant
sub-segments, while the spurious correlation sub-segment is excluded.
Furthermore, we propose Causal Informed Transformer (CAIFormer), a novel
forecasting model comprising three components: Endogenous Sub-segment
Prediction Block, Direct Causal Sub-segment Prediction Block, and Collider
Causal Sub-segment Prediction Block, which process the endogenous, direct
causal, and collider causal sub-segments, respectively. Their outputs are then
combined to produce the final prediction. Extensive experiments on multiple
benchmark datasets demonstrate the effectiveness of the CAIFormer.

</details>


### [53] [FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail](https://arxiv.org/abs/2505.16319)
*Yangyang Wang, Jiawei Gu, Li Long, Xin Li, Li Shen, Zhouyu Fu, Xiangjun Zhou, Xu Jiang*

**主要类别:** cs.LG

**概要:** This paper introduces FreshRetailNet-50K, a large-scale benchmark for censored demand estimation in perishable products. It presents a two-stage demand modeling approach that improves prediction accuracy and addresses long-standing limitations in retail AI.


<details>
  <summary>更多</summary>
  
**动机:** Existing datasets lack the temporal resolution and annotations needed to address the censoring effect in censored sales data during stockouts, which leads to systemic policy biases.

**方法:** Two-stage demand modeling: 1) Reconstruct latent demand during stockouts using precise hourly annotations. 2) Train robust demand forecasting models using recovered demand.

**结果:** The approach achieves a 2.73% improvement in prediction accuracy and reduces systematic demand underestimation from 7.37% to near-zero bias.

**结论:** The dataset FreshRetailNet-50K improves prediction accuracy and reduces systematic demand underestimation. It opens new research directions in demand imputation, perishable inventory optimization, and causal retail analytics.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FreshRetailNet-50K%3A+A+Stockout-Annotated+Censored+Demand+Dataset+for+Latent+Demand+Recovery+and+Forecasting+in+Fresh+Retail，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16319，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16319&send_immediately=true&force_search=false)

**原文摘要:** Accurate demand estimation is critical for the retail business in guiding the
inventory and pricing policies of perishable products. However, it faces
fundamental challenges from censored sales data during stockouts, where
unobserved demand creates systemic policy biases. Existing datasets lack the
temporal resolution and annotations needed to address this censoring effect. To
fill this gap, we present FreshRetailNet-50K, the first large-scale benchmark
for censored demand estimation. It comprises 50,000 store-product time series
of detailed hourly sales data from 898 stores in 18 major cities, encompassing
863 perishable SKUs meticulously annotated for stockout events. The hourly
stock status records unique to this dataset, combined with rich contextual
covariates, including promotional discounts, precipitation, and temporal
features, enable innovative research beyond existing solutions. We demonstrate
one such use case of two-stage demand modeling: first, we reconstruct the
latent demand during stockouts using precise hourly annotations. We then
leverage the recovered demand to train robust demand forecasting models in the
second stage. Experimental results show that this approach achieves a 2.73\%
improvement in prediction accuracy while reducing the systematic demand
underestimation from 7.37\% to near-zero bias. With unprecedented temporal
granularity and comprehensive real-world information, FreshRetailNet-50K opens
new research directions in demand imputation, perishable inventory
optimization, and causal retail analytics. The unique annotation quality and
scale of the dataset address long-standing limitations in retail AI, providing
immediate solutions and a platform for future methodological innovation. The
data (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code
(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.

</details>


### [54] [AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners](https://arxiv.org/abs/2505.16322)
*Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun*

**主要类别:** cs.LG

**概要:** 提出了一种新的自适应采样算法AdaSTaR，用于改进自我提升推理语言模型的训练过程。在六个基准测试中，AdaSTaR在所有情况下都达到了最佳测试准确率，并且减少了平均58.6%的训练浮点运算次数（FLOPs）。


<details>
  <summary>更多</summary>
  
**动机:** 现有的随机观察采样方法会导致训练样本不平衡，即过度训练于简单示例而训练不足于困难示例。

**方法:** 引入了AdaSTaR算法，包含两个自适应采样原则：(1) 多样性自适应采样；(2) 课程自适应采样，动态调整数据难度以匹配模型的演化能力。

**结果:** 在六个基准测试中，AdaSTaR取得了最佳的测试准确性，并且显著减少了训练所需的计算资源。

**结论:** AdaSTaR提升了自我提升推理语言模型的性能和效率，适用于不同的预训练语言模型和更大规模的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdaSTaR%3A+Adaptive+Data+Sampling+for+Training+Self-Taught+Reasoners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16322&send_immediately=true&force_search=false)

**原文摘要:** Self-Taught Reasoners (STaR), synonymously known as Rejection sampling
Fine-Tuning (RFT), is an integral part of the training pipeline of
self-improving reasoning Language Models (LMs). The self-improving mechanism
often employs random observation (data) sampling. However, this results in
trained observation imbalance; inefficiently over-training on solved examples
while under-training on challenging ones. In response, we introduce Adaptive
STaR (AdaSTaR), a novel algorithm that rectifies this by integrating two
adaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting
balanced training across observations, and (2) Adaptive Sampling for
Curriculum: dynamically adjusting data difficulty to match the model's evolving
strength. Across six benchmarks, AdaSTaR achieves best test accuracy in all
instances (6/6) and reduces training FLOPs by an average of 58.6% against an
extensive list of baselines. These improvements in performance and efficiency
generalize to different pre-trained LMs and larger models, paving the way for
more efficient and effective self-improving LMs.

</details>


### [55] [ChemMLLM: Chemical Multimodal Large Language Model](https://arxiv.org/abs/2505.16326)
*Qian Tan, Dongzhan Zhou, Peng Xia, Wanhao Liu, Wanli Ouyang, Lei Bai, Yuqiang Li, Tianfan Fu*

**主要类别:** cs.LG

**概要:** 提出了一种用于分子理解和生成的统一化学多模态大语言模型ChemMLLM，并在五个跨文本、分子SMILES字符串和图像的任务上进行了评估，实验结果显示ChemMLLM在所有任务中都取得了优异的表现。


<details>
  <summary>更多</summary>
  
**动机:** 填补化学多模态大语言模型在交叉模态理解和生成方面研究不足的空白。

**方法:** 提出了一个名为ChemMLLM的统一化学多模态大语言模型，并设计了五个跨模态任务以及相应的数据集。

**结果:** ChemMLLM在所有评估的任务中都表现出了优越的性能，例如在分子图像优化任务中比最好的基线模型GPT-4o高出118.9%。

**结论:** 所提出的ChemMLLM在化学多模态任务中表现出色，表明其在分子理解和生成方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ChemMLLM%3A+Chemical+Multimodal+Large+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16326&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) have made impressive progress in
many applications in recent years. However, chemical MLLMs that can handle
cross-modal understanding and generation remain underexplored. To fill this
gap, in this paper, we propose ChemMLLM, a unified chemical multimodal large
language model for molecule understanding and generation. Also, we design five
multimodal tasks across text, molecular SMILES strings, and image, and curate
the datasets. We benchmark ChemMLLM against a range of general leading MLLMs
and Chemical LLMs on these tasks. Experimental results show that ChemMLLM
achieves superior performance across all evaluated tasks. For example, in
molecule image optimization task, ChemMLLM outperforms the best baseline
(GPT-4o) by 118.9\% (4.27 vs 1.95 property improvement). The code is publicly
available at https://github.com/bbsbz/ChemMLLM.git.

</details>


### [56] [Understanding Differential Transformer Unchains Pretrained Self-Attentions](https://arxiv.org/abs/2505.16333)
*Chaerin Kong, Jiho Jang, Nojun Kwak*

**主要类别:** cs.LG

**概要:** This paper investigates Differential Transformer and proposes DEX, which efficiently integrates differential attention into pretrained language models and significantly improves their performance with minimal adaptation data.


<details>
  <summary>更多</summary>
  
**动机:** Precisely how differential attention achieves its empirical benefits remains poorly understood. Differential Transformer architecture demands large-scale training from scratch, hindering utilization of open pretrained weights.

**方法:** DEX efficiently integrates the advantages of differential attention into pretrained language models by reusing the softmax attention scores and adding a lightweight differential operation on the output value matrix.

**结果:** DEX effectively incorporates the key advantages of differential attention while remaining lightweight in both training and inference.

**结论:** DEX substantially improves the pretrained LLMs across diverse benchmarks, achieving significant performance gains with minimal adaptation data.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Differential+Transformer+Unchains+Pretrained+Self-Attentions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16333，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16333&send_immediately=true&force_search=false)

**原文摘要:** Differential Transformer has recently gained significant attention for its
impressive empirical performance, often attributed to its ability to perform
noise canceled attention. However, precisely how differential attention
achieves its empirical benefits remains poorly understood. Moreover,
Differential Transformer architecture demands large-scale training from
scratch, hindering utilization of open pretrained weights. In this work, we
conduct an in-depth investigation of Differential Transformer, uncovering three
key factors behind its success: (1) enhanced expressivity via negative
attention, (2) reduced redundancy among attention heads, and (3) improved
learning dynamics. Based on these findings, we propose DEX, a novel method to
efficiently integrate the advantages of differential attention into pretrained
language models. By reusing the softmax attention scores and adding a
lightweight differential operation on the output value matrix, DEX effectively
incorporates the key advantages of differential attention while remaining
lightweight in both training and inference. Evaluations confirm that DEX
substantially improves the pretrained LLMs across diverse benchmarks, achieving
significant performance gains with minimal adaptation data (< 0.01\%).

</details>


### [57] [Improving Chemical Understanding of LLMs via SMILES Parsing](https://arxiv.org/abs/2505.16340)
*Yunhui Jang, Jaehyung Kim, Sungsoo Ahn*

**主要类别:** cs.LG

**概要:** CLEANMOL is a new method that improves large language models' understanding of molecular structures in SMILES format by turning it into a set of clear tasks.


<details>
  <summary>更多</summary>
  
**动机:** Current large language models struggle to interpret SMILES, even for simple tasks like counting molecular rings.

**方法:** Introduce CLEANMOL, which transforms SMILES parsing into various tasks promoting molecular comprehension, and pre-trains models on these tasks.

**结果:** CLEANMOL improves structural comprehension and performs well on the Mol-Instructions benchmark.

**结论:** CLEANMOL effectively enhances large language models' ability to understand molecular structures.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Chemical+Understanding+of+LLMs+via+SMILES+Parsing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16340，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16340&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly recognized as powerful tools
for scientific discovery, particularly in molecular science. A fundamental
requirement for these models is the ability to accurately understand molecular
structures, commonly encoded in the SMILES representation. However, current
LLMs struggle to interpret SMILES, even failing to carry out basic tasks such
as counting molecular rings. To address this limitation, we introduce CLEANMOL,
a novel framework that formulates SMILES parsing into a suite of clean and
deterministic tasks explicitly designed to promote graph-level molecular
comprehension. These tasks span from subgraph matching to global graph
matching, providing structured supervision aligned with molecular structural
properties. We construct a molecular pretraining dataset with adaptive
difficulty scoring and pre-train open-source LLMs on these tasks. Our results
show that CLEANMOL not only enhances structural comprehension but also achieves
the best or competes with the baseline on the Mol-Instructions benchmark.

</details>


### [58] [A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2505.16341)
*Yaxin Hou, Yuheng Jia*

**主要类别:** cs.LG

**概要:** This paper proposes a method to improve semi-supervised learning for long-tailed data by dynamically assigning experts and fusing multi-depth features.


<details>
  <summary>更多</summary>
  
**动机:** Existing methods do not fully utilize the expertise of different auxiliary classifiers in LTSSL with distribution mismatch.

**方法:** Proposes a dynamic expert assignment module and a multi-depth feature fusion module.

**结果:** The proposed method leads to a smaller generalization error bound and improves performance on CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets.

**结论:** Our method shows its effectiveness through extensive experiments.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Square+Peg+in+a+Square+Hole%3A+Meta-Expert+for+Long-Tailed+Semi-Supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16341，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16341&send_immediately=true&force_search=false)

**原文摘要:** This paper studies the long-tailed semi-supervised learning (LTSSL) with
distribution mismatch, where the class distribution of the labeled training
data follows a long-tailed distribution and mismatches with that of the
unlabeled training data. Most existing methods introduce auxiliary classifiers
(experts) to model various unlabeled data distributions and produce
pseudo-labels, but the expertises of various experts are not fully utilized. We
observe that different experts are good at predicting different intervals of
samples, e.g., long-tailed expert is skilled in samples located in the head
interval and uniform expert excels in samples located in the medium interval.
Therefore, we propose a dynamic expert assignment module that can estimate the
class membership (i.e., head, medium, or tail class) of samples, and
dynamically assigns suitable expert to each sample based on the estimated
membership to produce high-quality pseudo-label in the training phase and
produce prediction in the testing phase. We also theoretically reveal that
integrating different experts' strengths will lead to a smaller generalization
error bound. Moreover, we find that the deeper features are more biased toward
the head class but with more discriminative ability, while the shallower
features are less biased but also with less discriminative ability. We,
therefore, propose a multi-depth feature fusion module to utilize different
depth features to mitigate the model bias. Our method demonstrates its
effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,
and SVHN-LT datasets across various settings. The code is available at
https://github.com/yaxinhou/Meta-Expert.

</details>


### [59] [Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning](https://arxiv.org/abs/2505.16353)
*Céline Comte, Pascal Moyal*

**主要类别:** cs.LG

**概要:** This paper introduces a new method for optimizing arrival rates in quasi-reversible queueing systems by defining balanced arrival control policies.


<details>
  <summary>更多</summary>
  
**动机:** To improve the efficiency and performance of quasi-reversible queueing systems through better arrival rate optimization.

**方法:** Proposes a new definition of quasi-reversibility and balanced arrival control policies, proving their impact on preserving quasi-reversibility and specifying stationary measures.

**结果:** Successfully applies the method to Whittle networks and order-independent queues, also addresses admission control using optimization and reinforcement learning.

**结论:** The proposed scheme effectively optimizes arrival rates in a broad class of queueing systems, with potential applications in admission control.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Arrival+Control+in+Quasi-Reversible+Queueing+Systems%3A+Optimization+and+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16353&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we introduce a versatile scheme for optimizing the arrival
rates of quasi-reversible queueing systems. We first propose an alternative
definition of quasi-reversibility that encompasses reversibility and highlights
the importance of the definition of customer classes. In a second time, we
introduce balanced arrival control policies, which generalize the notion of
balanced arrival rates introduced in the context of Whittle networks, to the
much broader class of quasi-reversible queueing systems. We prove that
supplementing a quasi-reversible queueing system with a balanced
arrival-control policy preserves the quasi-reversibility, and we specify the
form of the stationary measures. We revisit two canonical examples of
quasi-reversible queueing systems, Whittle networks and order-independent
queues. Lastly, we focus on the problem of admission control and leverage our
results in the frameworks of optimization and reinforcement learning.

</details>


### [60] [A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules](https://arxiv.org/abs/2505.16365)
*Manuel Ruiz-Botella, Marta Sales-Pardo, Roger Guimerà*

**主要类别:** cs.LG

**概要:** CoCoGraph is a novel graph diffusion model that efficiently generates chemically valid molecules, surpassing existing methods in performance and accuracy while using fewer parameters.


<details>
  <summary>更多</summary>
  
**动机:** To address the challenge of exploring the vast molecular space for new compounds.

**方法:** Introducing CoCoGraph, which uses collaborative and constrained graph diffusion.

**结果:** Outperforms state-of-the-art approaches on benchmarks and creates a database of synthetic molecules.

**结论:** CoCoGraph is efficient and accurate in generating plausible molecules, with potential biases and limitations assessed through expert evaluation.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+collaborative+constrained+graph+diffusion+model+for+the+generation+of+realistic+synthetic+molecules，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16365，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16365&send_immediately=true&force_search=false)

**原文摘要:** Developing new molecular compounds is crucial to address pressing challenges,
from health to environmental sustainability. However, exploring the molecular
space to discover new molecules is difficult due to the vastness of the space.
Here we introduce CoCoGraph, a collaborative and constrained graph diffusion
model capable of generating molecules that are guaranteed to be chemically
valid. Thanks to the constraints built into the model and to the collaborative
mechanism, CoCoGraph outperforms state-of-the-art approaches on standard
benchmarks while requiring up to an order of magnitude fewer parameters.
Analysis of 36 chemical properties also demonstrates that CoCoGraph generates
molecules with distributions more closely matching real molecules than current
models. Leveraging the model's efficiency, we created a database of 8.2M
million synthetically generated molecules and conducted a Turing-like test with
organic chemistry experts to further assess the plausibility of the generated
molecules, and potential biases and limitations of CoCoGraph.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems](https://arxiv.org/abs/2505.15862)
*Long Wanga, Jiongzhi Zheng, Zhengda Xiong, ChuMin Li, Kun He*

**主要类别:** cs.AI

**概要:** This paper proposes a method using multi-armed bandit models to dynamically select candidate edges in the Lin-Kernighan-Helsgaun (LKH) algorithm for solving the Traveling Salesman Problem (TSP). The approach improves solution quality by avoiding getting trapped in local optima.


<details>
  <summary>更多</summary>
  
**动机:** Existing routing algorithms often use static candidate edges which can limit finding better solutions due to being stuck in local optima.

**方法:** Incorporating multi-armed bandit models to dynamically choose candidate edges in LKH iterations.

**结果:** The proposed method shows excellent performance on multiple TSP benchmarks and also improves LKH-3's performance on various TSP variant problems.

**结论:** Dynamic selection of candidate edges using multi-armed bandit models enhances the LKH algorithm's ability to find better solutions for the TSP.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bandit+based+Dynamic+Candidate+Edge+Selection+in+Solving+Traveling+Salesman+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15862，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15862&send_immediately=true&force_search=false)

**原文摘要:** Algorithms designed for routing problems typically rely on high-quality
candidate edges to guide their search, aiming to reduce the search space and
enhance the search efficiency. However, many existing algorithms, like the
classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman
Problem (TSP), often use predetermined candidate edges that remain static
throughout local searches. This rigidity could cause the algorithm to get
trapped in local optima, limiting its potential to find better solutions. To
address this issue, we propose expanding the candidate sets to include other
promising edges, providing them an opportunity for selection. Specifically, we
incorporate multi-armed bandit models to dynamically select the most suitable
candidate edges in each iteration, enabling LKH to make smarter choices and
lead to improved solutions. Extensive experiments on multiple TSP benchmarks
show the excellent performance of our method. Moreover, we employ this
bandit-based method to LKH-3, an extension of LKH tailored for solving various
TSP variant problems, and our method also significantly enhances LKH-3's
performance across typical TSP variants.

</details>


### [62] [PhyX: Does Your Model Have the "Wits" for Physical Reasoning?](https://arxiv.org/abs/2505.15929)
*Hui Shen, Taiqiang Wu, Qi Han, Yunta Hsieh, Jizhou Wang, Yuyue Zhang, Yuxin Cheng, Zijian Hao, Yuansheng Ni, Xin Wang, Zhongwei Wan, Kai Zhang, Wendong Xu, Jing Xiong, Ping Luo, Wenhu Chen, Chaofan Tao, Zhuoqing Mao, Ngai Wong*

**主要类别:** cs.AI

**概要:** Introducing PhyX, a new benchmark that tests AI's physical reasoning in visual scenarios, reveals significant performance gaps between top AI models and humans.


<details>
  <summary>更多</summary>
  
**动机:** To address the lack of benchmarks capturing physical reasoning, an essential aspect of intelligence.

**方法:** The introduction of PhyX, a large-scale benchmark that evaluates models' capacity for physics-grounded reasoning in visual scenarios.

**结果:** State-of-the-art models perform poorly on PhyX, with accuracy below 50% compared to human experts.

**结论:** PhyX benchmark highlights the significant gap between current AI models and human-level physical reasoning capabilities.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhyX%3A+Does+Your+Model+Have+the+%22Wits%22+for+Physical+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15929，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15929&send_immediately=true&force_search=false)

**原文摘要:** Existing benchmarks fail to capture a crucial aspect of intelligence:
physical reasoning, the integrated ability to combine domain knowledge,
symbolic reasoning, and understanding of real-world constraints. To address
this gap, we introduce PhyX: the first large-scale benchmark designed to assess
models capacity for physics-grounded reasoning in visual scenarios. PhyX
includes 3K meticulously curated multimodal questions spanning 6 reasoning
types across 25 sub-domains and 6 core physics domains: thermodynamics,
electromagnetism, mechanics, modern physics, optics, and wave\&acoustics. In
our comprehensive evaluation, even state-of-the-art models struggle
significantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and
GPT-o4-mini achieve only 32.5\%, 42.2\%, and 45.8\% accuracy
respectively-performance gaps exceeding 29\% compared to human experts. Our
analysis exposes critical limitations in current models: over-reliance on
memorized disciplinary knowledge, excessive dependence on mathematical
formulations, and surface-level visual pattern matching rather than genuine
physical understanding. We provide in-depth analysis through fine-grained
statistics, detailed case studies, and multiple evaluation paradigms to
thoroughly examine physical reasoning capabilities. To ensure reproducibility,
we implement a compatible evaluation protocol based on widely-used toolkits
such as VLMEvalKit, enabling one-click evaluation.

</details>


### [63] [Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics](https://arxiv.org/abs/2505.15998)
*Thomas Michel, Marko Cvjetko, Gautier Hamon, Pierre-Yves Oudeyer, Clément Moulin-Frier*

**主要类别:** cs.AI

**概要:** 提出了一种利用好奇心驱动的人工智能科学家自动发现Flow-Lenia系统级动态的方法。该方法能够揭示导致细胞自动机自组织演化的动力过程，并且在大环境中支持不同交互模式。通过适应内在动机目标探索过程来驱动多样化的Flow-Lenia环境探索。实验表明，与随机搜索相比，该方法能揭示出更加多样的动态。同时，还提供了一个互动探索工具，形成了有效的人工智能辅助科学研究工作流程。虽然该方法是在Flow-Lenia上展示的，但它也为理解其他可参数化复杂系统的涌现集体属性提供了框架。


<details>
  <summary>更多</summary>
  
**动机:** 研究Flow-Lenia系统级动态，特别是自组织演化和生态系统动力学的过程。

**方法:** 使用好奇心驱动的人工智能科学家，结合内在动机目标探索过程（IMGEPs），通过模拟范围内的指标（如进化活动、基于压缩的复杂性和多尺度熵）来驱动对Flow-Lenia环境的探索。

**结果:** 该方法在两个实验中展示了其能力，可以揭示比随机搜索更多的多样化动态。此外，还展示了生态模拟如何促进复杂集体行为的自组织，这些行为未被以前的个体模式搜索和分析捕捉到。

**结论:** 此方法不仅适用于Flow-Lenia，也为理解其他可参数化复杂系统的涌现集体属性提供了一个潜在适用的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Flow-Lenia+Universes+with+a+Curiosity-driven+AI+Scientist%3A+Discovering+Diverse+Ecosystem+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15998，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15998&send_immediately=true&force_search=false)

**原文摘要:** We present a method for the automated discovery of system-level dynamics in
Flow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and
parameter localization$-$using a curiosity-driven AI scientist. This method
aims to uncover processes leading to self-organization of evolutionary and
ecosystemic dynamics in CAs. We build on previous work which uses diversity
search algorithms in Lenia to find self-organized individual patterns, and
extend it to large environments that support distinct interacting patterns. We
adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive
exploration of diverse Flow-Lenia environments using simulation-wide metrics,
such as evolutionary activity, compression-based complexity, and multi-scale
entropy. We test our method in two experiments, showcasing its ability to
illuminate significantly more diverse dynamics compared to random search. We
show qualitative results illustrating how ecosystemic simulations enable
self-organization of complex collective behaviors not captured by previous
individual pattern search and analysis. We complement automated discovery with
an interactive exploration tool, creating an effective human-AI collaborative
workflow for scientific investigation. Though demonstrated specifically with
Flow-Lenia, this methodology provides a framework potentially applicable to
other parameterizable complex systems where understanding emergent collective
properties is of interest.

</details>


### [64] [Children's Mental Models of AI Reasoning: Implications for AI Literacy Education](https://arxiv.org/abs/2505.16031)
*Aayushi Dangol, Robert Wolfe, Runhua Zhao, JaeWon Kim, Trushaa Ramanan, Katie Davis, Julie A. Kientz*

**主要类别:** cs.AI

**概要:** 研究了儿童对人工智能推理过程的理解，识别出三种模型：演绎、归纳和固有。发现年幼的孩子认为AI有固有的智能，而年长的孩子认识到AI是一个模式识别器。提出了支持AI课程和设计可解释AI工具的启示。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能推理能力的发展，特别是大型推理模型（LRMs）的出现，理解儿童如何概念化AI的推理过程变得至关重要，以促进AI素养。

**方法:** 采用两阶段方法，包括与8个孩子进行协同设计会议，然后与106个孩子（3-8年级）进行实地研究。

**结果:** 识别出三种AI推理模型：演绎、归纳和固有。发现年幼的孩子（3-5年级）通常将AI的推理归因于固有的智能，而年长的孩子（6-8年级）则认识到AI是一个模式识别器。

**结论:** 提出了在支持AI课程和设计可解释AI工具方面的启示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Children%27s+Mental+Models+of+AI+Reasoning%3A+Implications+for+AI+Literacy+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16031，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16031&send_immediately=true&force_search=false)

**原文摘要:** As artificial intelligence (AI) advances in reasoning capabilities, most
recently with the emergence of Large Reasoning Models (LRMs), understanding how
children conceptualize AI's reasoning processes becomes critical for fostering
AI literacy. While one of the "Five Big Ideas" in AI education highlights
reasoning algorithms as central to AI decision-making, less is known about
children's mental models in this area. Through a two-phase approach, consisting
of a co-design session with 8 children followed by a field study with 106
children (grades 3-8), we identified three models of AI reasoning: Deductive,
Inductive, and Inherent. Our findings reveal that younger children (grades 3-5)
often attribute AI's reasoning to inherent intelligence, while older children
(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions
that surfaced in children's understanding of AI reasoning and conclude with
implications for scaffolding AI curricula and designing explainable AI tools.

</details>


### [65] [Causal LLM Routing: End-to-End Regret Minimization from Observational Data](https://arxiv.org/abs/2505.16037)
*Asterios Tsiourvas, Wei Sun, Georgia Perakis*

**主要类别:** cs.AI

**概要:** This paper introduces a causal end-to-end framework for LLM routing that learns from observational data, introducing two surrogate objectives for efficient optimization and extending the framework to handle heterogeneous cost preferences.


<details>
  <summary>更多</summary>
  
**动机:** Existing methods for LLM routing rely on decoupled strategies and full-feedback data, which can lead to compounding errors and high costs.

**方法:** Proposes a causal end-to-end framework that minimizes decision-making regret from observational data, with two surrogate objectives: a classification-based upper bound and a softmax-weighted regret approximation.

**结果:** The proposed method outperforms existing baselines on public benchmarks, achieving state-of-the-art performance across different embedding models.

**结论:** The proposed framework provides a more efficient and effective approach to LLM routing by learning from observational data and handling heterogeneous cost preferences.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+LLM+Routing%3A+End-to-End+Regret+Minimization+from+Observational+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16037&send_immediately=true&force_search=false)

**原文摘要:** LLM routing aims to select the most appropriate model for each query,
balancing competing performance metrics such as accuracy and cost across a pool
of language models. Prior approaches typically adopt a decoupled strategy,
where the metrics are first predicted and the model is then selected based on
these estimates. This setup is prone to compounding errors and often relies on
full-feedback data, where each query is evaluated by all candidate models,
which is costly to obtain and maintain in practice. In contrast, we learn from
observational data, which records only the outcome of the model actually
deployed. We propose a causal end-to-end framework that learns routing policies
by minimizing decision-making regret from observational data. To enable
efficient optimization, we introduce two theoretically grounded surrogate
objectives: a classification-based upper bound, and a softmax-weighted regret
approximation shown to recover the optimal policy at convergence. We further
extend our framework to handle heterogeneous cost preferences via an
interval-conditioned architecture. Experiments on public benchmarks show that
our method outperforms existing baselines, achieving state-of-the-art
performance across different embedding models.

</details>


### [66] [SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution](https://arxiv.org/abs/2505.16048)
*Philipp D. Siedler*

**主要类别:** cs.AI

**概要:** 介绍了一个新的数据集，用于评估基于拓扑优化的大型语言模型在物理和空间推理方面的能力。该数据集包含各种任务，要求模型在没有模拟工具或显式物理模型的情况下，推理出给定约束下的最优材料分布。


<details>
  <summary>更多</summary>
  
**动机:** 评估大型语言模型在物理和空间推理方面的能力

**方法:** 提供边界、受力情况和支撑条件等条件，让模型推理出最优材料分布

**结果:** 数据集包括填充部分结构中的掩蔽区域以及预测完整的材料分布等任务

**结论:** 此数据集旨在评估2D设置中的空间和物理推理能力，为传统语言和逻辑基准测试提供了补充视角

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPhyR%3A+Spatial-Physical+Reasoning+Benchmark+on+Material+Distribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16048&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel dataset designed to benchmark the physical and spatial
reasoning capabilities of Large Language Models (LLM) based on topology
optimization, a method for computing optimal material distributions within a
design space under prescribed loads and supports. In this dataset, LLMs are
provided with conditions such as 2D boundary, applied forces and supports, and
must reason about the resulting optimal material distribution. The dataset
includes a variety of tasks, ranging from filling in masked regions within
partial structures to predicting complete material distributions. Solving these
tasks requires understanding the flow of forces and the required material
distribution under given constraints, without access to simulation tools or
explicit physical models, challenging models to reason about structural
stability and spatial organization. Our dataset targets the evaluation of
spatial and physical reasoning abilities in 2D settings, offering a
complementary perspective to traditional language and logic benchmarks.

</details>


### [67] [How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](https://arxiv.org/abs/2505.16067)
*Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang*

**主要类别:** cs.AI

**概要:** 研究了记忆管理选择对基于大型语言模型的代理行为的影响，特别是它们的长期性能。发现LLM代理具有经验跟随特性，并揭示了与此特性相关的两个挑战：误差传播和不一致的经验重放。通过控制实验表明，结合选择性添加和删除策略可以缓解这些负面影响，平均绝对性能提升10%。此外，还展示了记忆管理选择如何影响代理在任务分布变化和内存资源受限等困难条件下的行为。


<details>
  <summary>更多</summary>
  
**动机:** 理解记忆管理选择对基于大型语言模型的代理行为的影响，尤其是长期性能。

**方法:** 专注于两种基本的记忆操作：添加和删除，系统地研究它们对代理行为的影响。

**结果:** 发现LLM代理具有经验跟随特性，即任务输入与检索到的记忆记录中的输入高度相似时，代理输出也往往高度相似。揭示了误差传播和不一致的经验重放这两个挑战。通过控制实验显示，结合选择性添加和删除策略可以提高性能。

**结论:** 本研究提供了关于LLM代理记忆系统行为动态的见解，并为设计支持稳健、长期代理性能的记忆组件提供了实用指导。同时发布了代码以促进进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Memory+Management+Impacts+LLM+Agents%3A+An+Empirical+Study+of+Experience-Following+Behavior，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16067，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16067&send_immediately=true&force_search=false)

**原文摘要:** Memory is a critical component in large language model (LLM)-based agents,
enabling them to store and retrieve past executions to improve task performance
over time. In this paper, we conduct an empirical study on how memory
management choices impact the LLM agents' behavior, especially their long-term
performance. Specifically, we focus on two fundamental memory operations that
are widely used by many agent frameworks-addition, which incorporates new
experiences into the memory base, and deletion, which selectively removes past
experiences-to systematically study their impact on the agent behavior. Through
our quantitative analysis, we find that LLM agents display an
experience-following property: high similarity between a task input and the
input in a retrieved memory record often results in highly similar agent
outputs. Our analysis further reveals two significant challenges associated
with this property: error propagation, where inaccuracies in past experiences
compound and degrade future performance, and misaligned experience replay,
where outdated or irrelevant experiences negatively influence current tasks.
Through controlled experiments, we show that combining selective addition and
deletion strategies can help mitigate these negative effects, yielding an
average absolute performance gain of 10% compared to naive memory growth.
Furthermore, we highlight how memory management choices affect agents' behavior
under challenging conditions such as task distribution shifts and constrained
memory resources. Our findings offer insights into the behavioral dynamics of
LLM agent memory systems and provide practical guidance for designing memory
components that support robust, long-term agent performance. We also release
our code to facilitate further study.

</details>


### [68] [SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation](https://arxiv.org/abs/2505.16080)
*Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang*

**主要类别:** cs.AI

**概要:** 提出了一种名为SynEVO的神经网络模型，该模型通过学习跨域集体智能来提升信息边界，并实现了跨域知识共享和聚合。实验表明，SynEVO在跨域场景下最多提高了42%的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 当前时空学习器通常从特定源数据训练独立模型，导致跨源迁移性有限，即使相关任务也需要新的设计和训练。

**方法:** 受神经科学理论启发，提出了一种名为SynEVO的神经网络模型，采用人类课程学习的样本分组重排方法，并设计了两个互补的学习器（弹性公共容器和任务无关提取器）以及一个自适应动态耦合器。

**结果:** 实验显示SynEVO在跨域场景下的泛化能力提升了最多42%。

**结论:** SynEVO提供了一个神经人工智能的知识转移和适应范例。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SynEVO%3A+A+neuro-inspired+spatiotemporal+evolutional+framework+for+cross-domain+adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16080&send_immediately=true&force_search=false)

**原文摘要:** Discovering regularities from spatiotemporal systems can benefit various
scientific and social planning. Current spatiotemporal learners usually train
an independent model from a specific source data that leads to limited
transferability among sources, where even correlated tasks requires new design
and training. The key towards increasing cross-domain knowledge is to enable
collective intelligence and model evolution. In this paper, inspired by
neuroscience theories, we theoretically derive the increased information
boundary via learning cross-domain collective intelligence and propose a
Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the
model independence and enables cross-domain knowledge to be shared and
aggregated. Specifically, we first re-order the sample groups to imitate the
human curriculum learning, and devise two complementary learners, elastic
common container and task-independent extractor to allow model growth and
task-wise commonality and personality disentanglement. Then an adaptive dynamic
coupler with a new difference metric determines whether the new sample group
should be incorporated into common container to achieve model evolution under
various domains. Experiments show that SynEVO improves the generalization
capacity by at most 42% under cross-domain scenarios and SynEVO provides a
paradigm of NeuroAI for knowledge transfer and adaptation.

</details>


### [69] [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org/abs/2505.16086)
*Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang*

**主要类别:** cs.AI

**概要:** This paper studies the optimization of role-based multi-agent systems using natural language feedback for software development tasks.


<details>
  <summary>更多</summary>
  
**动机:** Optimizing large language model-based multi-agent systems remains challenging.

**方法:** Proposes a two-step agent prompts optimization pipeline that identifies underperforming agents and optimizes their system prompts using failure explanations.

**结果:** Demonstrates the effectiveness of the proposed optimization method for role-based multi-agent systems tackling software development tasks evaluated on diverse evaluation dimensions.

**结论:** Investigates the impact of diverse optimization settings on group behaviors of multi-agent systems to provide practical insights for future development.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+LLM-Based+Multi-Agent+System+with+Textual+Feedback%3A+A+Case+Study+on+Software+Development，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16086，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16086&send_immediately=true&force_search=false)

**原文摘要:** We have seen remarkable progress in large language models (LLMs) empowered
multi-agent systems solving complex tasks necessitating cooperation among
experts with diverse skills. However, optimizing LLM-based multi-agent systems
remains challenging. In this work, we perform an empirical case study on group
optimization of role-based multi-agent systems utilizing natural language
feedback for challenging software development tasks under various evaluation
dimensions. We propose a two-step agent prompts optimization pipeline:
identifying underperforming agents with their failure explanations utilizing
textual feedback and then optimizing system prompts of identified agents
utilizing failure explanations. We then study the impact of various
optimization settings on system performance with two comparison groups: online
against offline optimization and individual against group optimization. For
group optimization, we study two prompting strategies: one-pass and multi-pass
prompting optimizations. Overall, we demonstrate the effectiveness of our
optimization method for role-based multi-agent systems tackling software
development tasks evaluated on diverse evaluation dimensions, and we
investigate the impact of diverse optimization settings on group behaviors of
the multi-agent systems to provide practical insights for future development.

</details>


### [70] [Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance](https://arxiv.org/abs/2505.16090)
*Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg*

**主要类别:** cs.AI

**概要:** 研究了大型语言模型（LLMs）在金融文本情感分析中的表现，并比较了微软Copilot、OpenAI的ChatGPT、Google的Gemini以及传统机器学习模型。使用微软的收益电话会议记录评估了LLM衍生情感与市场情绪和股票走势的相关性，并对模型输出的准确性进行了评价。此外，还研究了提示工程方法以改善情感分析结果。


<details>
  <summary>更多</summary>
  
**动机:** 随着生成式人工智能（GenAI）在各行业的广泛应用，特别是其在编码、数据分析和研究工作流中的关键作用，评估LLMs在高风险领域如金融中的可靠性变得至关重要。然而，LLMs在处理金融语境中微妙且策略上含糊的语言时存在困难。

**方法:** 本研究使用了由Charlie Goldenberg教授领导的圣克拉拉微软实习项目，对Microsoft Copilot、OpenAI ChatGPT、Google Gemini及传统机器学习模型进行基准测试，采用微软收益电话会议记录作为数据源，通过可视化手段分析情感一致性与股票表现之间的关系，并跨微软业务线分析情感趋势。

**结果:** 研究发现LLMs在金融文本情感分析方面具有潜力，但其准确性仍有待提高。通过提示工程可以优化情感分析结果，同时揭示了不同业务部门对整体市场情绪的影响程度。

**结论:** 尽管LLMs在情感分析方面表现出色，但在金融领域仍面临挑战，尤其是在复杂和模糊的语言环境中。未来的工作应集中在改进这些模型以更好地理解和解释金融文本的情感内涵。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+AI+Read+Between+The+Lines%3F+Benchmarking+LLMs+On+Financial+Nuance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16090，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16090&send_immediately=true&force_search=false)

**原文摘要:** As of 2025, Generative Artificial Intelligence (GenAI) has become a central
tool for productivity across industries. Beyond text generation, GenAI now
plays a critical role in coding, data analysis, and research workflows. As
large language models (LLMs) continue to evolve, it is essential to assess the
reliability and accuracy of their outputs, especially in specialized,
high-stakes domains like finance. Most modern LLMs transform text into
numerical vectors, which are used in operations such as cosine similarity
searches to generate responses. However, this abstraction process can lead to
misinterpretation of emotional tone, particularly in nuanced financial
contexts. While LLMs generally excel at identifying sentiment in everyday
language, these models often struggle with the nuanced, strategically ambiguous
language found in earnings call transcripts. Financial disclosures frequently
embed sentiment in hedged statements, forward-looking language, and
industry-specific jargon, making it difficult even for human analysts to
interpret consistently, let alone AI models. This paper presents findings from
the Santa Clara Microsoft Practicum Project, led by Professor Charlie
Goldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's
ChatGPT, Google's Gemini, and traditional machine learning models for sentiment
analysis of financial text. Using Microsoft earnings call transcripts, the
analysis assesses how well LLM-derived sentiment correlates with market
sentiment and stock movements and evaluates the accuracy of model outputs.
Prompt engineering techniques are also examined to improve sentiment analysis
results. Visualizations of sentiment consistency are developed to evaluate
alignment between tone and stock performance, with sentiment trends analyzed
across Microsoft's lines of business to determine which segments exert the
greatest influence.

</details>


### [71] [TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials](https://arxiv.org/abs/2505.16097)
*Zifeng Wang, Qiao Jin, Jiacheng Lin, Junyi Gao, Jathurshan Pradeepkumar, Pengcheng Jiang, Benjamin Danek, Zhiyong Lu, Jimeng Sun*

**主要类别:** cs.AI

**概要:** 介绍了一个包含1,657,476个临床试验记录的大规模结构化数据库TrialPanorama，它能支持多种临床试验任务，并展示了其在八个基准任务中的应用。实验表明通用大语言模型在此领域表现有限。


<details>
  <summary>更多</summary>
  
**动机:** 为垂直领域的人工智能开发提供坚实的数据基础，特别是针对临床试验的任务。

**方法:** 构建了TrialPanorama数据库，该数据库从15个全球来源汇总数据并链接到标准生物医学本体论。此外，还定义了一套基准任务来展示数据库的应用。

**结果:** 试验显示，虽然现有的大语言模型有一定的零样本能力，但它们的表现还不足以满足高风险的临床试验工作流程的需求。

**结论:** 发布TrialPanorama数据库和基准任务，以促进临床试验中的人工智能研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TrialPanorama%3A+Database+and+Benchmark+for+Systematic+Review+and+Design+of+Clinical+Trials，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16097，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16097&send_immediately=true&force_search=false)

**原文摘要:** Developing artificial intelligence (AI) for vertical domains requires a solid
data foundation for both training and evaluation. In this work, we introduce
TrialPanorama, a large-scale, structured database comprising 1,657,476 clinical
trial records aggregated from 15 global sources. The database captures key
aspects of trial design and execution, including trial setups, interventions,
conditions, biomarkers, and outcomes, and links them to standard biomedical
ontologies such as DrugBank and MedDRA. This structured and ontology-grounded
design enables TrialPanorama to serve as a unified, extensible resource for a
wide range of clinical trial tasks, including trial planning, design, and
summarization. To demonstrate its utility, we derive a suite of benchmark tasks
directly from the TrialPanorama database. The benchmark spans eight tasks
across two categories: three for systematic review (study search, study
screening, and evidence summarization) and five for trial design (arm design,
eligibility criteria, endpoint selection, sample size estimation, and trial
completion assessment). The experiments using five state-of-the-art large
language models (LLMs) show that while general-purpose LLMs exhibit some
zero-shot capability, their performance is still inadequate for high-stakes
clinical trial workflows. We release TrialPanorama database and the benchmark
to facilitate further research on AI for clinical trials.

</details>


### [72] [BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research](https://arxiv.org/abs/2505.16100)
*Zifeng Wang, Benjamin Danek, Jimeng Sun*

**主要类别:** cs.AI

**概要:** 提出BioDSA-1K基准来评估AI在真实数据驱动的生物医学假设验证任务中的表现。该基准包含从300多篇已发表的研究中提取的1029个假设任务和1177个分析计划。


<details>
  <summary>更多</summary>
  
**动机:** 科学假设验证在生物医学研究中很重要，但对AI来说仍然很困难。

**方法:** 创建了一个名为BioDSA-1K的基准，它包含了从300多篇研究中提取的任务和分析计划。

**结果:** BioDSA-1K可以沿着四个轴进行评估，并且包括不可验证的假设情况。

**结论:** 建议使用BioDSA-1K作为构建和评估可推广、可信的AI代理的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioDSA-1K%3A+Benchmarking+Data+Science+Agents+for+Biomedical+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16100&send_immediately=true&force_search=false)

**原文摘要:** Validating scientific hypotheses is a central challenge in biomedical
research, and remains difficult for artificial intelligence (AI) agents due to
the complexity of real-world data analysis and evidence interpretation. In this
work, we present BioDSA-1K, a benchmark designed to evaluate AI agents on
realistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K
consists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,
curated from over 300 published biomedical studies to reflect the structure and
reasoning found in authentic research workflows. Each task includes a
structured hypothesis derived from the original study's conclusions, expressed
in the affirmative to reflect the language of scientific reporting, and one or
more pieces of supporting evidence grounded in empirical data tables. While
these hypotheses mirror published claims, they remain testable using standard
statistical or machine learning methods. The benchmark enables evaluation along
four axes: (1) hypothesis decision accuracy, (2) alignment between evidence and
conclusion, (3) correctness of the reasoning process, and (4) executability of
the AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable
hypotheses: cases where the available data are insufficient to support or
refute a claim, reflecting a common yet underexplored scenario in real-world
science. We propose BioDSA-1K as a foundation for building and evaluating
generalizable, trustworthy AI agents for biomedical discovery.

</details>


### [73] [Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language](https://arxiv.org/abs/2505.16114)
*Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia*

**主要类别:** cs.AI

**概要:** 提出了一种名为Logic-of-Thought（Logot）的新框架，结合大语言模型和逻辑编程解决复杂自然语言谜题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大语言模型在需要精确推理和全面搜索的复杂谜题上表现不佳。

**方法:** 将谜题规则和状态转换为答案集程序，并通过ASP解释器推断解决方案。

**结果:** 在多种网格谜题和涉及动作的动态谜题上表现出接近完美的准确性。

**结论:** 该方法成功地结合了大语言模型的理解能力和逻辑程序的推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Logic-of-Thought%3A+Empowering+Large+Language+Models+with+Logic+Programs+for+Solving+Puzzles+in+Natural+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16114&send_immediately=true&force_search=false)

**原文摘要:** Solving puzzles in natural language poses a long-standing challenge in AI.
While large language models (LLMs) have recently shown impressive capabilities
in a variety of tasks, they continue to struggle with complex puzzles that
demand precise reasoning and exhaustive search. In this paper, we propose
Logic-of-Thought (Logot), a novel framework that bridges LLMs with logic
programming to address this problem. Our method leverages LLMs to translate
puzzle rules and states into answer set programs (ASPs), the solution of which
are then accurately and efficiently inferred by an ASP interpreter. This hybrid
approach combines the natural language understanding of LLMs with the precise
reasoning capabilities of logic programs. We evaluate our method on various
grid puzzles and dynamic puzzles involving actions, demonstrating near-perfect
accuracy across all tasks. Our code and data are available at:
https://github.com/naiqili/Logic-of-Thought.

</details>


### [74] [LLM-Powered AI Agent Systems and Their Applications in Industry](https://arxiv.org/abs/2505.16120)
*Guannan Liang, Qianqian Tong*

**主要类别:** cs.AI

**概要:** Large Language Models (LLMs) have transformed agent systems, offering flexible, cross-domain reasoning and natural language interaction. Current systems can process multiple data modalities. The paper reviews the development of agent systems from pre-LLM to current architectures, categorizing them into software-based, physical, and hybrid types with various applications. It also addresses challenges like latency, uncertainty, lack of metrics, and security issues.


<details>
  <summary>更多</summary>
  
**动机:** To examine the evolution of agent systems from pre-LLM to current LLM-powered architectures and address challenges posed by LLM-powered agents.

**方法:** Categorizing agent systems into software-based, physical, and adaptive hybrid systems and discussing their applications in different fields.

**结果:** Current agent systems powered by LLMs can process diverse data modalities and exhibit rich, adaptive behaviors. They have been applied in customer service, software development, manufacturing, education, finance, and healthcare.

**结论:** LLMs have significantly enhanced agent systems, but challenges such as high inference latency, output uncertainty, lack of evaluation metrics, and security issues need to be addressed.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Powered+AI+Agent+Systems+and+Their+Applications+in+Industry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16120&send_immediately=true&force_search=false)

**原文摘要:** The emergence of Large Language Models (LLMs) has reshaped agent systems.
Unlike traditional rule-based agents with limited task scope, LLM-powered
agents offer greater flexibility, cross-domain reasoning, and natural language
interaction. Moreover, with the integration of multi-modal LLMs, current agent
systems are highly capable of processing diverse data modalities, including
text, images, audio, and structured tabular data, enabling richer and more
adaptive real-world behavior. This paper comprehensively examines the evolution
of agent systems from the pre-LLM era to current LLM-powered architectures. We
categorize agent systems into software-based, physical, and adaptive hybrid
systems, highlighting applications across customer service, software
development, manufacturing automation, personalized education, financial
trading, and healthcare. We further discuss the primary challenges posed by
LLM-powered agents, including high inference latency, output uncertainty, lack
of evaluation metrics, and security vulnerabilities, and propose potential
solutions to mitigate these concerns.

</details>


### [75] [Sudoku-Bench: Evaluating creative reasoning with Sudoku variants](https://arxiv.org/abs/2505.16135)
*Jeffrey Seely, Yuki Imajuku, Tianyu Zhao, Edoardo Cetin, Llion Jones*

**主要类别:** cs.AI

**概要:** Introduces Sudoku-Bench, a benchmark for evaluating creative, multi-step logical reasoning in large language models, showing current models solve less than 15% of puzzles unaided.


<details>
  <summary>更多</summary>
  
**动机:** Existing reasoning benchmarks often reward memorization rather than creativity; aim to address this by creating a challenging Sudoku-based benchmark.

**方法:** Develops Sudoku-Bench with curated puzzles, standardized representations, and tools for diverse yet consistent evaluation.

**结果:** State-of-the-art LLMs solve less than 15% of puzzles without assistance, indicating room for improvement in long-horizon reasoning.

**结论:** Sudoku-Bench provides an effective domain for advancing creative and strategic reasoning in large language models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sudoku-Bench%3A+Evaluating+creative+reasoning+with+Sudoku+variants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16135&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning benchmarks for large language models (LLMs) frequently
fail to capture authentic creativity, often rewarding memorization of
previously observed patterns. We address this shortcoming with Sudoku-Bench, a
curated benchmark of challenging and unconventional Sudoku variants
specifically selected to evaluate creative, multi-step logical reasoning.
Sudoku variants form an unusually effective domain for reasoning research: each
puzzle introduces unique or subtly interacting constraints, making memorization
infeasible and requiring solvers to identify novel logical breakthroughs
(``break-ins''). Despite their diversity, Sudoku variants maintain a common and
compact structure, enabling clear and consistent evaluation. Sudoku-Bench
includes a carefully chosen puzzle set, a standardized text-based puzzle
representation, and flexible tools compatible with thousands of publicly
available puzzles -- making it easy to extend into a general research
environment. Baseline experiments show that state-of-the-art LLMs solve fewer
than 15\% of puzzles unaided, highlighting significant opportunities to advance
long-horizon, strategic reasoning capabilities.

</details>


### [76] [Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value](https://arxiv.org/abs/2505.16147)
*Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种名为Unlearning Shapley的新框架，利用机器遗忘技术高效估计数据价值。该方法通过从预训练模型中删除目标数据并测量可达测试集上的性能变化来计算Shapley值，避免了重新训练并消除了对完整数据的依赖。实验表明，该方法在准确性和计算开销上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型模型的普及，量化单个数据提供者贡献的需求变得更加迫切。然而，传统的方法如基于博弈论的Shapley值和基于影响函数的技术面临高昂的计算成本或需要访问完整的数据和模型训练细节的问题，难以实现部分数据估值。

**方法:** 提出了一种新的框架Unlearning Shapley，它利用机器遗忘技术来高效估计数据价值。该方法通过从预训练模型中删除目标数据并测量可达测试集上的性能变化来计算Shapley值，避免了重新训练并消除了对完整数据的依赖。

**结果:** 该方法在基准数据集和大规模文本语料库上的实验表明，其准确性与最先进的方法相当，但计算开销减少了几个数量级。进一步的分析证实了估计值与数据子集真实影响之间的强相关性，验证了其在现实场景中的可靠性。

**结论:** 这项工作弥合了数据估值理论与实际部署之间的差距，为现代AI生态系统提供了一个可扩展、符合隐私保护的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Losing+is+for+Cherishing%3A+Data+Valuation+Based+on+Machine+Unlearning+and+Shapley+Value，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16147，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16147&send_immediately=true&force_search=false)

**原文摘要:** The proliferation of large models has intensified the need for efficient data
valuation methods to quantify the contribution of individual data providers.
Traditional approaches, such as game-theory-based Shapley value and
influence-function-based techniques, face prohibitive computational costs or
require access to full data and model training details, making them hardly
achieve partial data valuation. To address this, we propose Unlearning Shapley,
a novel framework that leverages machine unlearning to estimate data values
efficiently. By unlearning target data from a pretrained model and measuring
performance shifts on a reachable test set, our method computes Shapley values
via Monte Carlo sampling, avoiding retraining and eliminating dependence on
full data. Crucially, Unlearning Shapley supports both full and partial data
valuation, making it scalable for large models (e.g., LLMs) and practical for
data markets. Experiments on benchmark datasets and large-scale text corpora
demonstrate that our approach matches the accuracy of state-of-the-art methods
while reducing computational overhead by orders of magnitude. Further analysis
confirms a strong correlation between estimated values and the true impact of
data subsets, validating its reliability in real-world scenarios. This work
bridges the gap between data valuation theory and practical deployment,
offering a scalable, privacy-compliant solution for modern AI ecosystems.

</details>


### [77] [Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning](https://arxiv.org/abs/2505.16176)
*Jun Rao, Xuebo Liu, Hexuan Deng, Zepeng Lin, Zixiong Yu, Jiansheng Wei, Xiaojun Meng, Min Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种名为SAI-DPO的算法，通过动态评估模型在不同训练阶段的推理能力来选择训练数据。该方法能够根据模型实时性能反馈调整数据选择，从而提高数据利用效率和任务表现。实验显示SAI-DPO在多个数学推理基准测试上带来了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有数据选择方法依赖于预先定义的静态指标，缺乏适应连续训练过程的能力，尤其在动态训练范式和在线强化学习框架下表现不足。

**方法:** 引入SAI-DPO算法，该算法通过实时评估模型的推理能力，在不同训练阶段动态调整数据选择。

**结果:** SAI-DPO在三个最先进的模型和八个数学推理基准测试上取得了显著的性能提升，特别是在AIME24和AMC23数据集上分别提升了10和15个百分点，平均提升21.3个百分点。

**结论:** 动态、模型自适应的数据选择优于静态、外部定义的策略，有助于推动推理任务的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Sampling+that+Adapts%3A+Iterative+DPO+for+Self-Aware+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16176&send_immediately=true&force_search=false)

**原文摘要:** In the realm of data selection for reasoning tasks, existing approaches
predominantly rely on externally predefined static metrics such as difficulty
and diversity, which are often designed for supervised fine-tuning (SFT) and
lack adaptability to continuous training processes. A critical limitation of
these methods is their inability to dynamically align with the evolving
capabilities of models during online training, a gap that becomes increasingly
pronounced with the rise of dynamic training paradigms and online reinforcement
learning (RL) frameworks (e.g., R1 models). To address this, we introduce
SAI-DPO, an algorithm that dynamically selects training data by continuously
assessing a model's stage-specific reasoning abilities across different
training phases. By integrating real-time model performance feedback, SAI-DPO
adaptively adapts data selection to the evolving strengths and weaknesses of
the model, thus enhancing both data utilization efficiency and final task
performance. Extensive experiments on three state-of-the-art models and eight
mathematical reasoning benchmarks, including challenging competition-level
datasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average
performance boost of up to 21.3 percentage points, with particularly notable
improvements of 10 and 15 points on AIME24 and AMC23, respectively. These
results highlight the superiority of dynamic, model-adaptive data selection
over static, externally defined strategies in advancing reasoning.

</details>


### [78] [SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning](https://arxiv.org/abs/2505.16186)
*Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang*

**主要类别:** cs.AI

**概要:** 本文提出了SafeKey方法以增强大型推理模型的安全性，特别是在应对未见过的越狱提示时，实验结果表明该方法有效。


<details>
  <summary>更多</summary>
  
**动机:** 虽然监督微调(SFT)改善了大型推理模型(LRMs)的安全性能，但SFT对齐的模型在未见过的越狱提示上泛化能力较弱。

**方法:** 提出SafeKey方法，包括两个互补的目标：(1) Dual-Path Safety Head 和 (2) Query-Mask Modeling objective。

**结果:** 实验表明SafeKey方法显著提升了安全泛化能力，降低了有害率，并且通过分析揭示了SafeKey如何通过重塑内部注意力和提高隐藏表示的质量来增强安全性。

**结论:** SafeKey方法显著提高了大型推理模型对多种越狱攻击和分布外有害提示的安全泛化能力，降低了平均有害率9.6%，同时保持了模型的一般能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SafeKey%3A+Amplifying+Aha-Moment+Insights+for+Safety+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16186&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) introduce a new generation paradigm of
explicitly reasoning before answering, leading to remarkable improvements in
complex tasks. However, they pose great safety risks against harmful queries
and adversarial attacks. While recent mainstream safety efforts on LRMs,
supervised fine-tuning (SFT), improve safety performance, we find that
SFT-aligned models struggle to generalize to unseen jailbreak prompts. After
thorough investigation of LRMs' generation, we identify a safety aha moment
that can activate safety reasoning and lead to a safe response. This aha moment
typically appears in the `key sentence', which follows models' query
understanding process and can indicate whether the model will proceed safely.
Based on these insights, we propose SafeKey, including two complementary
objectives to better activate the safety aha moment in the key sentence: (1) a
Dual-Path Safety Head to enhance the safety signal in the model's internal
representations before the key sentence, and (2) a Query-Mask Modeling
objective to improve the models' attention on its query understanding, which
has important safety hints. Experiments across multiple safety benchmarks
demonstrate that our methods significantly improve safety generalization to a
wide range of jailbreak attacks and out-of-distribution harmful prompts,
lowering the average harmfulness rate by 9.6\%, while maintaining general
abilities. Our analysis reveals how SafeKey enhances safety by reshaping
internal attention and improving the quality of hidden representations.

</details>


### [79] [Velocity Completion Task and Method for Event-based Player Positional Data in Soccer](https://arxiv.org/abs/2505.16199)
*Rikuhei Umemoto, Keisuke Fujii*

**主要类别:** cs.AI

**概要:** 提出一种新方法，利用事件驱动的位置数据同时完成所有运动员的速度估计，并验证了神经网络在速度补全任务上的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于事件的位置数据缺乏连续的时间信息，限制了对个体行为和团队策略的深入动态分析。

**方法:** 提出的新方法基于事件驱动的位置数据来完成速度估计，并研究其在团队运动分析中的适用性。

**结果:** 实验表明，基于神经网络的方法在速度补全误差上优于基于规则的方法，并且使用完成的速度评估空间的结果更接近于完整的跟踪数据。

**结论:** 所提出的方法可以增强团队运动系统的动态分析能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Velocity+Completion+Task+and+Method+for+Event-based+Player+Positional+Data+in+Soccer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16199，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16199&send_immediately=true&force_search=false)

**原文摘要:** In many real-world complex systems, the behavior can be observed as a
collection of discrete events generated by multiple interacting agents.
Analyzing the dynamics of these multi-agent systems, especially team sports,
often relies on understanding the movement and interactions of individual
agents. However, while providing valuable snapshots, event-based positional
data typically lacks the continuous temporal information needed to directly
calculate crucial properties such as velocity. This absence severely limits the
depth of dynamic analysis, preventing a comprehensive understanding of
individual agent behaviors and emergent team strategies. To address this
challenge, we propose a new method to simultaneously complete the velocity of
all agents using only the event-based positional data from team sports. Based
on this completed velocity information, we investigate the applicability of
existing team sports analysis and evaluation methods. Experiments using soccer
event data demonstrate that neural network-based approaches outperformed
rule-based methods regarding velocity completion error, considering the
underlying temporal dependencies and graph structure of player-to-player or
player-to-ball interaction. Moreover, the space evaluation results obtained
using the completed velocity are closer to those derived from complete tracking
data, highlighting our method's potential for enhanced team sports system
analysis.

</details>


### [80] [LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead](https://arxiv.org/abs/2505.16221)
*Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin*

**主要类别:** cs.AI

**概要:** LightRouter是一个新框架，用于从大型语言模型池中选择和集成小部分模型，以优化任务性能和成本效率。它通过减少启动令牌数量降低成本，并结合输出提高准确性。实验表明其在多个基准上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有大型语言模型在成本、性能和计算需求方面存在显著差异，用户难以找到适合特定任务的最佳模型。

**方法:** 提出LightRouter框架，利用自适应选择机制减少启动令牌数量并降低费用，同时采用有效整合策略来组合模型输出。

**结果:** 在多个基准测试中，LightRouter的表现优于广泛使用的集成基线，提升了最多25%的准确性；与高性能模型相比，它在保持相似性能的同时减少了高达27%的推理成本。

**结论:** 此工作提供了一种高效大型语言模型选择的实际方法，并对模型组合的最佳策略提供了有价值的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LightRouter%3A+Towards+Efficient+LLM+Collaboration+with+Minimal+Overhead，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16221，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16221&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of large language models has unlocked remarkable
capabilities across a diverse array of natural language processing tasks.
However, the considerable differences among available LLMs-in terms of cost,
performance, and computational demands-pose significant challenges for users
aiming to identify the most suitable model for specific tasks. In this work, we
present LightRouter, a novel framework designed to systematically select and
integrate a small subset of LLMs from a larger pool, with the objective of
jointly optimizing both task performance and cost efficiency. LightRouter
leverages an adaptive selection mechanism to identify models that require only
a minimal number of boot tokens, thereby reducing costs, and further employs an
effective integration strategy to combine their outputs. Extensive experiments
across multiple benchmarks demonstrate that LightRouter matches or outperforms
widely-used ensemble baselines, achieving up to a 25% improvement in accuracy.
Compared with leading high-performing models, LightRouter achieves comparable
performance while reducing inference costs by up to 27%. Importantly, our
framework operates without any prior knowledge of individual models and relies
exclusively on inexpensive, lightweight models. This work introduces a
practical approach for efficient LLM selection and provides valuable insights
into optimal strategies for model combination.

</details>


### [81] [MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network](https://arxiv.org/abs/2505.16223)
*Sangyong Lee, Subo Hwang, Dohoon Kim*

**主要类别:** cs.AI

**概要:** 提出了一种名为MADCluster的新模型不可知异常检测框架，它利用自监督聚类解决了现有深度学习方法中的'超球塌陷'问题。


<details>
  <summary>更多</summary>
  
**动机:** 解决现有深度学习方法中的'超球塌陷'问题。

**方法:** 利用自监督聚类，通过引入'单向自适应损失'和三个主要组件（基础嵌入器、聚类距离映射和序列聚类）来实现模型不可知特性。

**结果:** 在四个时间序列基准数据集上的实验表明，应用MADCluster可以提高比较模型的整体性能。

**结论:** MADCluster在各种架构中显示出增强模型性能的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MADCluster%3A+Model-agnostic+Anomaly+Detection+with+Self-supervised+Clustering+Network，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16223&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose MADCluster, a novel model-agnostic anomaly
detection framework utilizing self-supervised clustering. MADCluster is
applicable to various deep learning architectures and addresses the
'hypersphere collapse' problem inherent in existing deep learning-based anomaly
detection methods. The core idea is to cluster normal pattern data into a
'single cluster' while simultaneously learning the cluster center and mapping
data close to this center. Also, to improve expressiveness and enable effective
single clustering, we propose a new 'One-directed Adaptive loss'. The
optimization of this loss is mathematically proven. MADCluster consists of
three main components: Base Embedder capturing high-dimensional temporal
dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous
center updates. Its model-agnostic characteristics are achieved by applying
various architectures to the Base Embedder. Experiments on four time series
benchmark datasets demonstrate that applying MADCluster improves the overall
performance of comparative models. In conclusion, the compatibility of
MADCluster shows potential for enhancing model performance across various
architectures.

</details>


### [82] [MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning](https://arxiv.org/abs/2505.16225)
*Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen*

**主要类别:** cs.AI

**概要:** 提出MAPLE框架，利用伪标签样本解决大量标注数据获取成本高的问题，提升大规模语言模型在许多示例上下文学习中的适应性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 解决许多示例上下文学习中因需要大量标注数据导致的成本高昂的问题。

**方法:** 提出MAPLE框架，通过识别有影响力的未标记样本并进行伪标签处理来增强模型性能。

**结果:** 实验表明MAPLE框架能有效提高大规模语言模型的适应性和性能，且无需显著增加标注成本。

**结论:** MAPLE是一种创新的基于影响的许多示例上下文学习框架，能在有限标注数据情况下提升模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAPLE%3A+Many-Shot+Adaptive+Pseudo-Labeling+for+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16225&send_immediately=true&force_search=false)

**原文摘要:** In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle
diverse tasks by incorporating multiple input-output examples, known as
demonstrations, into the input of LLMs. More recently, advancements in the
expanded context windows of LLMs have led to many-shot ICL, which uses hundreds
of demonstrations and outperforms few-shot ICL, which relies on fewer examples.
However, this approach is often hindered by the high cost of obtaining large
amounts of labeled data. To address this challenge, we propose Many-Shot
Adaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL
framework that utilizes pseudo-labeled samples to compensate for the lack of
label information. We first identify a subset of impactful unlabeled samples
and perform pseudo-labeling on them by querying LLMs. These pseudo-labeled
samples are then adaptively selected and tailored to each test query as input
to improve the performance of many-shot ICL, without significant labeling
costs. Extensive experiments on real-world datasets demonstrate the
effectiveness of our framework, showcasing its ability to enhance LLM
adaptability and performance with limited labeled data.

</details>


### [83] [How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance](https://arxiv.org/abs/2505.16276)
*Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel*

**主要类别:** cs.AI

**概要:** This study explores the relationship between model size and performance in large language models used for knowledge graph engineering tasks.


<details>
  <summary>更多</summary>
  
**动机:** To investigate whether larger models always perform better in knowledge graph engineering tasks and to find cost-effective solutions.

**方法:** Using the LLM-KG-Bench framework, the researchers compared 26 open state-of-the-art LLMs and analyzed how benchmark scores evolved across different model size categories.

**结果:** The results showed that the model size scaling laws generally apply to KGE tasks, but there were exceptions where performance plateaus or ceilings occurred, suggesting smaller models can be more cost-effective in some cases.

**结论:** While larger models tend to perform better, there are instances where smaller models can be more efficient, especially when considering resource costs and performance plateaus.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+do+Scaling+Laws+Apply+to+Knowledge+Graph+Engineering+Tasks%3F+The+Impact+of+Model+Size+on+Large+Language+Model+Performance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16276，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16276&send_immediately=true&force_search=false)

**原文摘要:** When using Large Language Models (LLMs) to support Knowledge Graph
Engineering (KGE), one of the first indications when searching for an
appropriate model is its size. According to the scaling laws, larger models
typically show higher capabilities. However, in practice, resource costs are
also an important factor and thus it makes sense to consider the ratio between
model performance and costs. The LLM-KG-Bench framework enables the comparison
of LLMs in the context of KGE tasks and assesses their capabilities of
understanding and producing KGs and KG queries. Based on a dataset created in
an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the
model size scaling laws specific to KGE tasks. In our analyses, we assess how
benchmark scores evolve between different model size categories. Additionally,
we inspect how the general score development of single models and families of
models correlates to their size. Our analyses revealed that, with a few
exceptions, the model size scaling laws generally also apply to the selected
KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,
the task performance did not change much between a model and the next larger
model. In these cases, smaller models could be considered to achieve high
cost-effectiveness. Regarding models of the same family, sometimes larger
models performed worse than smaller models of the same family. These effects
occurred only locally. Hence it is advisable to additionally test the next
smallest and largest model of the same family.

</details>


### [84] [No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](https://arxiv.org/abs/2505.16288)
*Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning*

**主要类别:** cs.AI

**概要:** 提出II-KEA框架，结合个性化知识库和主动LLMs，提升深度学习模型在医疗诊断预测中的可解释性和互动性，并在MIMIC数据集上验证了其优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于电子健康记录的深度学习模型虽然在诊断预测上准确率高，但缺乏临床医生重视的可解释性和互动性。

**方法:** 提出II-KEA框架，通过知识增强的主动代理因果发现方法，结合个性化知识库和主动LLMs来提高模型的可解释性和互动性。

**结果:** II-KEA在MIMIC-III和MIMIC-IV数据集上的表现优于其他模型，并通过案例研究展示了其增强的可解释性和互动性。

**结论:** II-KEA框架成功提升了深度学习模型在医疗领域的可解释性和互动性，有助于临床决策支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是No+Black+Boxes%3A+Interpretable+and+Interactable+Predictive+Healthcare+with+Knowledge-Enhanced+Agentic+Causal+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16288，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16288&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models trained on extensive Electronic Health Records (EHR)
data have achieved high accuracy in diagnosis prediction, offering the
potential to assist clinicians in decision-making and treatment planning.
However, these models lack two crucial features that clinicians highly value:
interpretability and interactivity. The ``black-box'' nature of these models
makes it difficult for clinicians to understand the reasoning behind
predictions, limiting their ability to make informed decisions. Additionally,
the absence of interactive mechanisms prevents clinicians from incorporating
their own knowledge and experience into the decision-making process. To address
these limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal
discovery framework that integrates personalized knowledge databases and
agentic LLMs. II-KEA enhances interpretability through explicit reasoning and
causal analysis, while also improving interactivity by allowing clinicians to
inject their knowledge and experience through customized knowledge bases and
prompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating
superior performance along with enhanced interpretability and interactivity, as
evidenced by its strong results from extensive case studies.

</details>


### [85] [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org/abs/2505.16312)
*Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian*

**主要类别:** cs.AI

**概要:** 提出了一种名为EquivPruner的方法来减少大型语言模型在复杂推理任务中的令牌消耗，同时提高了推理准确性。


<details>
  <summary>更多</summary>
  
**动机:** 当前策略由于语义等效步骤的冗余探索而导致大量令牌消耗，尤其是在数学推理等特定领域中，现有的语义相似性方法难以准确识别这种等效性。

**方法:** 提出EquivPruner方法，用于识别和剪枝大型语言模型推理搜索过程中的语义等效动作，并创建了MathEquiv数据集以训练轻量级等效检测器。

**结果:** 实验表明，EquivPruner显著减少了令牌消耗，提高了搜索效率，并且常常增强了推理准确性。例如，在GSM8K上应用到Qwen2.5-Math-7B-Instruct时，EquivPruner将令牌消耗减少了48.1％，并提高了准确性。

**结论:** 所提出的EquivPruner方法有效解决了令牌消耗问题，提升了推理性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EquivPruner%3A+Boosting+Efficiency+and+Quality+in+LLM-Based+Search+via+Action+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16312，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16312&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) excel at complex reasoning through search
algorithms, yet current strategies often suffer from massive token consumption
due to redundant exploration of semantically equivalent steps. Existing
semantic similarity methods struggle to accurately identify such equivalence in
domain-specific contexts like mathematical reasoning. To address this, we
propose EquivPruner, a simple yet effective approach that identifies and prunes
semantically equivalent actions during LLM reasoning search. We also introduce
MathEquiv, the first dataset we created for mathematical statement equivalence,
which enables the training of a lightweight equivalence detector. Extensive
experiments across various models and tasks demonstrate that EquivPruner
significantly reduces token consumption, improving searching efficiency and
often bolstering reasoning accuracy. For instance, when applied to
Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by
48.1\% while also improving accuracy. Our code is available at
https://github.com/Lolo1222/EquivPruner.

</details>


### [86] [Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2505.16315)
*Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种名为ACPO的强化学习框架，该框架通过自适应认知分配和动态系统切换使大型推理模型能够实现高效推理。实验结果表明，ACPO在减少冗余推理的同时，能根据任务复杂性自适应调整认知分配，实现了高效的混合推理。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型推理模型在复杂推理任务上表现出色，但常常因为过度思考而产生冗余内容，不论任务难度如何。

**方法:** 提出了一个名为ACPO的强化学习框架，包含两个关键组件：引入系统感知推理标记以明确表示思维模式，以及整合在线难度估计和标记长度预算以指导自适应系统切换和推理。采用两阶段训练策略：第一阶段通过监督微调开始模型训练，第二阶段应用ACPO进一步增强自适应系统切换能力。

**结果:** 实验结果表明，ACPO能够有效减少冗余推理，同时根据任务复杂性自适应调整认知分配，实现高效的混合推理。

**结论:** ACPO提供了一个有效的解决方案来解决现有大型推理模型中的过度思考问题，通过自适应认知分配和动态系统切换提高了推理效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incentivizing+Dual+Process+Thinking+for+Efficient+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16315&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models (LRMs) have demonstrated strong performance on complex
reasoning tasks, but often suffer from overthinking, generating redundant
content regardless of task difficulty. Inspired by the dual process theory in
cognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a
reinforcement learning framework that enables LRMs to achieve efficient
reasoning through adaptive cognitive allocation and dynamic system switch. ACPO
incorporates two key components: (1) introducing system-aware reasoning tokens
to explicitly represent the thinking modes thereby making the model's cognitive
process transparent, and (2) integrating online difficulty estimation and token
length budget to guide adaptive system switch and reasoning during
reinforcement learning. To this end, we propose a two-stage training strategy.
The first stage begins with supervised fine-tuning to cold start the model,
enabling it to generate reasoning paths with explicit thinking modes. In the
second stage, we apply ACPO to further enhance adaptive system switch for
difficulty-aware reasoning. Experimental results demonstrate that ACPO
effectively reduces redundant reasoning while adaptively adjusting cognitive
allocation based on task complexity, achieving efficient hybrid reasoning.

</details>


### [87] [Serious Games: Human-AI Interaction, Evolution, and Coevolution](https://arxiv.org/abs/2505.16388)
*Nandini Doreswamy, Louise Horstmanshof*

**主要类别:** cs.AI

**概要:** This paper examines three Evolutionary Game Theory (EGT) models (Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition) relevant to human-AI interaction, evolution, and coevolution. It suggests that EGT could help predict the potential evolutionary equilibrium of humans and AI.


<details>
  <summary>更多</summary>
  
**动机:** To understand and predict the human-AI evolutionary dynamic using EGT models.

**方法:** Examining three selected EGT models: Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition.

**结果:** These models predict balanced coevolution, cognitive coevolution, and strategic coevolution respectively. They suggest that EGT provides a suitable framework for understanding human-AI evolutionary dynamics.

**结论:** Future research should explore beyond EGT, consider empirical validation methods, interdisciplinary perspectives, and ethical/cognitive implications of human-AI interaction, evolution, and coevolution.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Serious+Games%3A+Human-AI+Interaction%2C+Evolution%2C+and+Coevolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16388，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16388&send_immediately=true&force_search=false)

**原文摘要:** The serious games between humans and AI have only just begun. Evolutionary
Game Theory (EGT) models the competitive and cooperative strategies of
biological entities. EGT could help predict the potential evolutionary
equilibrium of humans and AI. The objective of this work was to examine some of
the EGT models relevant to human-AI interaction, evolution, and coevolution. Of
thirteen EGT models considered, three were examined: the Hawk-Dove Game,
Iterated Prisoner's Dilemma, and the War of Attrition. This selection was based
on the widespread acceptance and clear relevance of these models to potential
human-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove
Game predicts balanced mixed-strategy equilibria based on the costs of
conflict. It also shows the potential for balanced coevolution rather than
dominance. Iterated Prisoner's Dilemma suggests that repeated interaction may
lead to cognitive coevolution. It demonstrates how memory and reciprocity can
lead to cooperation. The War of Attrition suggests that competition for
resources may result in strategic coevolution, asymmetric equilibria, and
conventions on sharing resources. Therefore, EGT may provide a suitable
framework to understand and predict the human-AI evolutionary dynamic. However,
future research could extend beyond EGT and explore additional frameworks,
empirical validation methods, and interdisciplinary perspectives. AI is being
shaped by human input and is evolving in response to it. So too,
neuroplasticity allows the human brain to grow and evolve in response to
stimuli. If humans and AI converge in future, what might be the result of human
neuroplasticity combined with an ever-evolving AI? Future research should be
mindful of the ethical and cognitive implications of human-AI interaction,
evolution, and coevolution.

</details>


### [88] [FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS](https://arxiv.org/abs/2505.16409)
*Chaeeun Kim, Seungone Kim*

**主要类别:** cs.AI

**概要:** 提出了一种新的框架FREESON，该框架允许大型推理模型（LRMs）自行检索相关信息，从而提高多步推理和开放域问答任务的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法中的检索增强推理方法依赖于单独的检索模型，这限制了LRMs在检索中的作用，并导致硬件和运营成本增加以及检索错误。

**方法:** 提出了一个新的框架FREESON，它使LRMs能够同时作为生成器和检索器工作，并引入了一种名为CT-MCTS的算法来实现这一目标。

**结果:** 在五个开放域问答基准测试中，FREESON平均提高了14.4％的EM和F1得分，并且在PopQA和2WikiMultihopQA上比最强基线高出3％。

**结论:** 通过改变视角并提出新的框架和算法，成功地提高了LRMs在多步推理和开放域问答任务中的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FREESON%3A+Retriever-Free+Retrieval-Augmented+Reasoning+via+Corpus-Traversing+MCTS，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16409，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16409&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in
multi-step reasoning and calling search engines at appropriate steps. However,
existing retrieval-augmented reasoning approaches rely on separate retrieval
models, limiting the LRM's role in retrieval to deciding when to retrieve and
how to query. This separation not only increases hardware and operational costs
but also leads to errors in the retrieval process due to the representation
bottleneck, a phenomenon where the retriever's embedding space is not
expressive enough to meet the generator's requirements. To address this, we
shift our perspective from sequence-to-sequence matching to locating the
answer-containing paths within the corpus, and propose a novel framework called
FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables
LRMs to retrieve relevant knowledge on their own by acting as both a generator
and retriever. To achieve this, we introduce a variant of the MCTS algorithm
specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing
Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus
toward answer-containing regions. Our results on five open-domain QA
benchmarks, including single-hop and multi-hop questions, show that FREESON
achieves an average improvement of 14.4% in EM and F1 over four multi-step
reasoning models with a separate retriever, and it also performs comparably to
the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.

</details>


### [89] [Internal Bias in Reasoning Models leads to Overthinking](https://arxiv.org/abs/2505.16448)
*Renfei Dang, Shujian Huang, Jiajun Chen*

**主要类别:** cs.AI

**概要:** This paper explores the issue of overthinking in reasoning models, identifying internal bias as the cause and demonstrating that reducing attention to input text can mitigate overthinking while improving accuracy.


<details>
  <summary>更多</summary>
  
**动机:** To address the problem of overthinking in reasoning models due to internal bias.

**方法:** Analyzing the impact of internal bias on reasoning models and experimenting with masking input sections.

**结果:** Reduction in reasoning length by 31%-53% and improvement in accuracy in most cases.

**结论:** Internal bias significantly contributes to overthinking in reasoning models, and mitigating this bias can enhance efficiency and performance.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Internal+Bias+in+Reasoning+Models+leads+to+Overthinking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16448&send_immediately=true&force_search=false)

**原文摘要:** While current reasoning models possess strong exploratory capabilities, they
are often criticized for overthinking due to redundant and unnecessary
reflections. In this work, we reveal for the first time that overthinking in
reasoning models may stem from their internal bias towards input texts. Upon
encountering a reasoning problem, the model immediately forms a preliminary
guess about the answer, which we term as an internal bias since it is not
derived through actual reasoning. When this guess conflicts with its reasoning
result, the model tends to engage in reflection, leading to the waste of
computational resources. Through further interpretability experiments, we find
that this behavior is largely driven by the model's excessive attention to the
input section, which amplifies the influence of internal bias on its
decision-making process. Additionally, by masking out the original input
section, the affect of internal bias can be effectively alleviated and the
reasoning length could be reduced by 31%-53% across different complex reasoning
tasks. Notably, in most cases, this approach also leads to improvements in
accuracy. These findings demonstrate a causal relationship between internal
bias and overthinking.

</details>


### [90] [Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](https://arxiv.org/abs/2505.16455)
*Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin*

**主要类别:** cs.AI

**概要:** 提出了一种基于情绪唤醒理论的心理驱动生成代理框架（PsychoAgent），用于可解释的恐慌预测，解决了标注数据不足、风险感知未建模和恐慌形成机制解释性差的问题。实验表明，与基线模型相比，PsychoAgent在恐慌情绪预测性能上提高了12.6%到21.7%。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测社交媒体上的公众恐慌情绪对于突发事件中的主动治理和危机管理至关重要，但目前存在标注数据不足、风险感知未建模和预测解释性差等问题。

**方法:** 提出了一个基于情绪唤醒理论的心理驱动生成代理框架（PsychoAgent），包括构建细粒度开放恐慌情绪数据集（COPE）以减轻语义偏差，开发整合跨领域异构数据的心理学机制框架以建模风险感知和认知差异，以及设计基于LLM的角色扮演游戏代理以增强解释性。

**结果:** 实验结果显示，PsychoAgent比基线模型在恐慌情绪预测性能上提升了12.6%到21.7%，并且验证了方法的可解释性和泛化能力。

**结论:** 这项工作代表了从“数据驱动拟合”到“基于角色模拟并具有机制解释”的恐慌情绪预测范式转变。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Psychology-driven+LLM+Agents+for+Explainable+Panic+Prediction+on+Social+Media+during+Sudden+Disaster+Events，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16455，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16455&send_immediately=true&force_search=false)

**原文摘要:** During sudden disaster events, accurately predicting public panic sentiment
on social media is crucial for proactive governance and crisis management.
Current efforts on this problem face three main challenges: lack of finely
annotated data hinders emotion prediction studies, unmodeled risk perception
causes prediction inaccuracies, and insufficient interpretability of panic
formation mechanisms. We address these issues by proposing a Psychology-driven
generative Agent framework (PsychoAgent) for explainable panic prediction based
on emotion arousal theory. Specifically, we first construct a fine-grained open
panic emotion dataset (namely COPE) via human-large language models (LLMs)
collaboration to mitigate semantic bias. Then, we develop a framework
integrating cross-domain heterogeneous data grounded in psychological
mechanisms to model risk perception and cognitive differences in emotion
generation. To enhance interpretability, we design an LLM-based role-playing
agent that simulates individual psychological chains through dedicatedly
designed prompts. Experimental results on our annotated dataset show that
PsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%
compared to baseline models. Furthermore, the explainability and generalization
of our approach is validated. Crucially, this represents a paradigm shift from
opaque "data-driven fitting" to transparent "role-based simulation with
mechanistic interpretation" for panic emotion prediction during emergencies.
Our implementation is publicly available at:
https://anonymous.4open.science/r/PsychoAgent-19DD.

</details>


### [91] [MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks](https://arxiv.org/abs/2505.16459)
*Guiyao Tie, Xueyang Zhou, Tianhe Gu, Ruihang Zhang, Chaoran Hu, Sizhe Zhang, Mengqu Sun, Yan Zhang, Pan Zhou, Lichao Sun*

**主要类别:** cs.AI

**概要:** 提出一个新的基准MMMR来评估多模态推理，包含高难度数据集和推理痕迹评估流程。实验表明，有中间思维痕迹的模型表现更好，但顶级模型仍存在推理问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有对多模态大语言模型推理能力的理解有限，缺乏标准化评估基准。

**方法:** 引入MMMR基准，包括高难度数据集和推理痕迹评估流程。

**结果:** 有中间思维痕迹的模型整体表现优于无思维痕迹的模型，但顶级模型在一致性等方面存在问题。

**结论:** MMMR为下一代多模态推理系统的评估、比较和改进提供了可扩展的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MMMR%3A+Benchmarking+Massive+Multi-Modal+Reasoning+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16459，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16459&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled
unified processing of language, vision, and structured inputs, opening the door
to complex tasks such as logical deduction, spatial reasoning, and scientific
analysis. Despite their promise, the reasoning capabilities of MLLMs,
particularly those augmented with intermediate thinking traces (MLLMs-T),
remain poorly understood and lack standardized evaluation benchmarks. Existing
work focuses primarily on perception or final answer correctness, offering
limited insight into how models reason or fail across modalities. To address
this gap, we introduce the MMMR, a new benchmark designed to rigorously
evaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a
high-difficulty dataset of 1,083 questions spanning six diverse reasoning types
with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace
Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy
through metrics like relevance, consistency, and structured error annotations.
Empirical results show that MLLMs-T overall outperform non-thinking
counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro
suffer from reasoning pathologies such as inconsistency and overthinking. This
benchmark reveals persistent gaps between accuracy and reasoning quality and
provides an actionable evaluation pipeline for future model development.
Overall, the MMMR offers a scalable foundation for evaluating, comparing, and
improving the next generation of multi-modal reasoning systems.

</details>


### [92] [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://arxiv.org/abs/2505.16475)
*Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng*

**主要类别:** cs.AI

**概要:** 提出了一种新的管道ReflectEvo，证明小语言模型可以通过反射学习增强元内省能力。通过构建大规模自我生成的反射数据集，并使用SFT和DPO方法，显著提升了Llama-3和Mistral的推理能力，且无需从更优模型蒸馏或精细的人类注释。


<details>
  <summary>更多</summary>
  
**动机:** 证明小语言模型可以通过反射学习增强元内省能力。

**方法:** 提出了一种名为ReflectEvo的新管道，构建了一个大规模、全面的自我生成反射数据集，并使用了SFT和DPO方法。

**结果:** 显著提高了Llama-3和Mistral的推理能力，分别从52.4%提升到71.2%，从44.4%提升到71.1%，且在BIG-bench上与三个开源模型相当甚至超越。

**结论:** 持续通过迭代反射学习可以提高小语言模型的推理性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReflectEvo%3A+Improving+Meta+Introspection+of+Small+LLMs+by+Learning+Self-Reflection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16475，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16475&send_immediately=true&force_search=false)

**原文摘要:** We present a novel pipeline, ReflectEvo, to demonstrate that small language
models (SLMs) can enhance meta introspection through reflection learning. This
process iteratively generates self-reflection for self-training, fostering a
continuous and self-evolving process. Leveraging this pipeline, we construct
ReflectEvo-460k, a large-scale, comprehensive, self-generated reflection
dataset with broadened instructions and diverse multi-domain tasks. Building
upon this dataset, we demonstrate the effectiveness of reflection learning to
improve SLMs' reasoning abilities using SFT and DPO with remarkable
performance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral
from 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the
reasoning capability of the three prominent open-sourced models on BIG-bench
without distillation from superior models or fine-grained human annotation. We
further conduct a deeper analysis of the high quality of self-generated
reflections and their impact on error localization and correction. Our work
highlights the potential of continuously enhancing the reasoning performance of
SLMs through iterative reflection learning in the long run.

</details>


### [93] [Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery](https://arxiv.org/abs/2505.16477)
*Yanbo Zhang, Sumeer A. Khan, Adnan Mahmud, Huck Yang, Alexander Lavin, Michael Levin, Jeremy Frey, Jared Dunnmon, James Evans, Alan Bundy, Saso Dzeroski, Jesper Tegner, Hector Zenil*

**主要类别:** cs.AI

**概要:** Large Language Models (LLMs) are revolutionizing scientific research by improving productivity and altering the scientific method, especially in chemistry and biology. Despite challenges like hallucinations and reliability issues, they have potential applications throughout the scientific process. For LLMs to be effective creative tools, their integration needs to align with human scientific goals and include clear evaluation metrics. Ethical considerations around oversight and responsibility are necessary as AI-driven science evolves.


<details>
  <summary>更多</summary>
  
**动机:** AI contributions recognized by Nobel Prizes motivate the exploration of how LLMs can enhance productivity and reshape the scientific method.

**方法:** Reviewing how LLMs redefine the scientific method and exploring their potential applications across various stages of the scientific cycle.

**结果:** LLMs show promise in experimental design, data analysis, and workflows but face challenges such as hallucinations and reliability issues.

**结论:** For LLMs to become effective creative engines and productivity enhancers, their integration into the scientific process must align with human goals and include clear evaluation metrics. Ethical considerations about creativity, oversight, and responsibility are essential.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+the+Scientific+Method+with+Large+Language+Models%3A+From+Hypothesis+to+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16477，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16477&send_immediately=true&force_search=false)

**原文摘要:** With recent Nobel Prizes recognising AI contributions to science, Large
Language Models (LLMs) are transforming scientific research by enhancing
productivity and reshaping the scientific method. LLMs are now involved in
experimental design, data analysis, and workflows, particularly in chemistry
and biology. However, challenges such as hallucinations and reliability
persist. In this contribution, we review how Large Language Models (LLMs) are
redefining the scientific method and explore their potential applications
across different stages of the scientific cycle, from hypothesis testing to
discovery. We conclude that, for LLMs to serve as relevant and effective
creative engines and productivity enhancers, their deep integration into all
steps of the scientific process should be pursued in collaboration and
alignment with human scientific goals, with clear evaluation metrics. The
transition to AI-driven science raises ethical questions about creativity,
oversight, and responsibility. With careful guidance, LLMs could evolve into
creative engines, driving transformative breakthroughs across scientific
disciplines responsibly and effectively. However, the scientific community must
also decide how much it leaves to LLMs to drive science, even when associations
with 'reasoning', mostly currently undeserved, are made in exchange for the
potential to explore hypothesis and solution regions that might otherwise
remain unexplored by human exploration alone.

</details>


### [94] [Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes](https://arxiv.org/abs/2505.16482)
*Huynh Thi Thanh Binh, Le Van Cuong, Dang Hai Dang, Le Trong Vinh*

**主要类别:** cs.AI

**概要:** 提出了一种新的部分充电方法，采用双层优化方案以最小化WRSNs中的能量消耗。同时优化了充电路径和时间，并通过数学模型和两种近似算法实现。实验验证表明所提算法优于现有工作。


<details>
  <summary>更多</summary>
  
**动机:** 解决无线能量传输技术在WRSNs中的有限能量问题，避免因无效充电策略导致的传感器能耗过度及死亡现象。

**方法:** 引入一种部分充电方法，采用双层优化方案，结合多起点局部搜索与遗传算法以及嵌套的多任务与协方差矩阵适应进化策略。

**结果:** 所提出的算法在各种网络场景下表现出比现有工作的优越性。

**结论:** 所提出的方法能够有效减少WRSNs的能量消耗，优化充电路径和时间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Minimizing+the+energy+depletion+in+wireless+rechargeable+sensor+networks+using+bi-level+metaheuristic+charging+schemes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16482，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16482&send_immediately=true&force_search=false)

**原文摘要:** Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the
advantage of wireless energy transfer technology have opened a promising
opportunity in solving the limited energy issue. However, an ineffective
charging strategy may reduce the charging performance. Although many practical
charging algorithms have been introduced, these studies mainly focus on
optimizing the charging path with a fully charging approach. This approach may
lead to the death of a series of sensors due to their extended charging
latency. This paper introduces a novel partial charging approach that follows a
bi-level optimized scheme to minimize energy depletion in WRSNs. We aim at
optimizing simultaneously two factors: the charging path and time. To
accomplish this, we first formulate a mathematical model of the investigated
problem. We then propose two approximate algorithms in which the optimization
of the charging path and the charging time are considered as the upper and
lower level, respectively. The first algorithm combines a Multi-start Local
Search method and a Genetic Algorithm to find a solution. The second algorithm
adopts a nested approach that utilizes the advantages of the Multitasking and
Covariance Matrix Adaptation Evolutionary Strategies. Experimental validations
on various network scenarios demonstrate that our proposed algorithms
outperform the existing works.

</details>


### [95] [Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)](https://arxiv.org/abs/2505.16507)
*Anshu Xiong, Songmao Zhang*

**主要类别:** cs.AI

**概要:** 本文扩展了不完整论证框架中相关性的概念，研究了一组论证验证状态的稳定性，并提出了强相关性的概念来描述在所有情况下解决不确定性的必要性。复杂性分析表明，在大多数语义下检测论证集的相关性可以在多项式时间内完成。


<details>
  <summary>更多</summary>
  
**动机:** 在不完整论证框架中，为了保证单一论证合理性的稳定性，提出了相关性的概念。本文旨在进一步扩展这一概念。

**方法:** 研究了一组论证验证状态的稳定性，提出了强相关性的概念，并进行了复杂性分析。

**结果:** 发现检测论证集相关性可以在P时间内完成，但在grounded语义下找到可处理的相关性检测方法较为困难。

**结论:** 本文扩展了不完整论证框架中相关性的概念，提出了强相关性的概念，并分析了其复杂性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Relevance+for+Stability+of+Verification+Status+of+a+Set+of+Arguments+in+Incomplete+Argumentation+Frameworks+%28with+Proofs%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16507&send_immediately=true&force_search=false)

**原文摘要:** The notion of relevance was proposed for stability of justification status of
a single argument in incomplete argumentation frameworks (IAFs) in 2024 by
Odekerken et al. To extend the notion, we study the relevance for stability of
verification status of a set of arguments in this paper, i.e., the
uncertainties in an IAF that have to be resolved in some situations so that
answering whether a given set of arguments is an extension obtains the same
result in every completion of the IAF. Further we propose the notion of strong
relevance for describing the necessity of resolution in all situations reaching
stability. An analysis of complexity reveals that detecting the (strong)
relevance for stability of sets of arguments can be accomplished in P time
under the most semantics discussed in the paper. We also discuss the difficulty
in finding tractable methods for relevance detection under grounded semantics.

</details>


### [96] [Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org/abs/2505.16579)
*Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang*

**主要类别:** cs.AI

**概要:** 提出GRASSLAND基准测试以评估动态空间推理能力，并提出D2R框架来增强多模态大型语言模型在动态环境中的空间推理性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法局限于文本或静态视觉领域，在动态空间推理任务上表现不佳。

**方法:** 提出D2R框架，通过将文本推理链与输入图像上的动态视觉草图相结合来增强多模态大型语言模型的能力。

**结果:** 实验表明，D2R框架在不同任务中持续提升性能，为动态空间推理建立了稳健的基线。

**结论:** D2R无需模型微调即可有效提升多模态大型语言模型的动态空间推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+the+Dynamic+Perception+Gap%3A+Training-Free+Draft+Chain-of-Thought+for+Dynamic+Multimodal+Spatial+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16579&send_immediately=true&force_search=false)

**原文摘要:** While chains-of-thought (CoT) have advanced complex reasoning in multimodal
large language models (MLLMs), existing methods remain confined to text or
static visual domains, often faltering in dynamic spatial reasoning tasks. To
bridge this gap, we present GRASSLAND, a novel maze navigation benchmark
designed to evaluate dynamic spatial reasoning. Our experiments show that
augmenting textual reasoning chains with dynamic visual drafts, overlaid on
input images, significantly outperforms conventional approaches, offering new
insights into spatial reasoning in evolving environments. To generalize this
capability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free
framework that seamlessly integrates textual CoT with corresponding visual
drafts into MLLMs. Extensive evaluations demonstrate that D2R consistently
enhances performance across diverse tasks, establishing a robust baseline for
dynamic spatial reasoning without requiring model fine-tuning. Project is open
at https://github.com/Cratileo/D2R.

</details>


### [97] [Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences](https://arxiv.org/abs/2505.16619)
*Gavin Farrell, Eleni Adamidi, Rafael Andrade Buono, Mihail Anton, Omar Abdelghani Attafi, Salvador Capella Gutierrez, Emidio Capriotti, Leyla Jael Castro, Davide Cirillo, Lisa Crossman, Christophe Dessimoz, Alexandros Dimopoulos, Raul Fernandez-Diaz, Styliani-Christina Fragkouli, Carole Goble, Wei Gu, John M. Hancock, Alireza Khanteymoori, Tom Lenaerts, Fabio G. Liberante, Peter Maccallum, Alexander Miguel Monzon, Magnus Palmblad, Lucy Poveda, Ovidiu Radulescu, Denis C. Shields, Shoaib Sufi, Thanasis Vergoulis, Fotis Psomopoulos, Silvio C. E. Tosatto*

**主要类别:** cs.AI

**概要:** 本文回顾了人工智能在生命科学研究中的应用及其带来的信任危机和生态碎片化问题，提出了一套开放且可持续的人工智能（OSAI）建议，并将其映射到超过300个AI生态系统组件上，旨在促进可持续、可重用和透明的AI发展。


<details>
  <summary>更多</summary>
  
**动机:** 加速AI在生命科学领域的进展，解决因快速采用AI方法而加剧的长期研究挑战。

**方法:** 提出了一套开放且可持续的人工智能（OSAI）建议，并将其映射到超过300个AI生态系统组件上。

**结果:** 揭示了AI研究输出信任度下降的问题，讨论了AI生态系统的碎片化及缺乏指导路径的情况。

**结论:** 本研究连接研究人员与相关AI资源，为未来制定政策和指导AI实施的结构化路径提供帮助。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Open+and+Sustainable+AI%3A+challenges%2C+opportunities+and+the+road+ahead+in+the+life+sciences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16619&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) has recently seen transformative breakthroughs
in the life sciences, expanding possibilities for researchers to interpret
biological information at an unprecedented capacity, with novel applications
and advances being made almost daily. In order to maximise return on the
growing investments in AI-based life science research and accelerate this
progress, it has become urgent to address the exacerbation of long-standing
research challenges arising from the rapid adoption of AI methods. We review
the increased erosion of trust in AI research outputs, driven by the issues of
poor reusability and reproducibility, and highlight their consequent impact on
environmental sustainability. Furthermore, we discuss the fragmented components
of the AI ecosystem and lack of guiding pathways to best support Open and
Sustainable AI (OSAI) model development. In response, this perspective
introduces a practical set of OSAI recommendations directly mapped to over 300
components of the AI ecosystem. Our work connects researchers with relevant AI
resources, facilitating the implementation of sustainable, reusable and
transparent AI. Built upon life science community consensus and aligned to
existing efforts, the outputs of this perspective are designed to aid the
future development of policy and structured pathways for guiding AI
implementation.

</details>


### [98] [SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving](https://arxiv.org/abs/2505.16646)
*Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang*

**主要类别:** cs.AI

**概要:** 提出SMART框架，通过分解数学问题解决为四个维度来评估大语言模型的行为，发现仅用最终答案准确性作为衡量标准是不够的。


<details>
  <summary>更多</summary>
  
**动机:** 现有评估指标无法区分大语言模型在数学推理中的真实能力与表面模式识别。

**方法:** 引入SMART框架，分解数学问题解决为理解、推理、算术和反思与精炼四个维度，并集成自动自我生成和验证机制。

**结果:** 应用SMART框架评估了21个最先进的开源和闭源LLMs，在不同维度上发现了显著的能力差异。

**结论:** 证明了仅用最终答案准确性作为唯一度量标准的不足，并促使采用新的整体度量标准来更好地捕捉真正的问题解决能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMART%3A+Self-Generating+and+Self-Validating+Multi-Dimensional+Assessment+for+LLMs%27+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16646，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16646&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models have achieved remarkable results on a variety of
mathematical benchmarks. However, concerns remain as to whether these successes
reflect genuine mathematical reasoning or superficial pattern recognition.
Common evaluation metrics, such as final answer accuracy, fail to disentangle
the underlying competencies involved, offering limited diagnostic value. To
address these limitations, we introduce SMART: a Self-Generating and
Self-Validating Multi-Dimensional Assessment Framework. SMART decomposes
mathematical problem solving into four distinct dimensions: understanding,
reasoning, arithmetic, and reflection \& refinement. Each dimension is
evaluated independently through tailored tasks, enabling interpretable and
fine-grained analysis of LLM behavior. Crucially, SMART integrates an automated
self-generating and self-validating mechanism to produce and verify benchmark
data, ensuring both scalability and reliability. We apply SMART to 21
state-of-the-art open- and closed-source LLMs, uncovering significant
discrepancies in their abilities across different dimensions. Our findings
demonstrate the inadequacy of final answer accuracy as a sole metric and
motivate a new holistic metric to better capture true problem-solving
capabilities. Code and benchmarks will be released upon acceptance.

</details>


### [99] [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://arxiv.org/abs/2505.16667)
*Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei*

**主要类别:** cs.AI

**概要:** 提出了一种新的编程数据集和基准测试方法来评估人与大型语言模型（LLM）在竞争性编程中的协作。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究过于碎片化且使用多样化的应用特定反馈，缺乏对人-LLM协作的全面理解。

**方法:** 提出了一个编程过程的人类反馈分类法，设计了一个名为ELABORATIONSET的新编程数据集，并引入了ELABORATION基准测试。

**结果:** 通过ELABORATION，确定了现有方法的优势和劣势，为未来改进奠定了基础。

**结论:** 本研究填补了人-LLM协作研究中的空白，提供了代码和数据集供进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ELABORATION%3A+A+Comprehensive+Benchmark+on+Human-LLM+Competitive+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16667，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16667&send_immediately=true&force_search=false)

**原文摘要:** While recent research increasingly emphasizes the value of human-LLM
collaboration in competitive programming and proposes numerous empirical
methods, a comprehensive understanding remains elusive due to the fragmented
nature of existing studies and their use of diverse, application-specific human
feedback. Thus, our work serves a three-fold purpose: First, we present the
first taxonomy of human feedback consolidating the entire programming process,
which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a
novel programming dataset specifically designed for human-LLM collaboration,
meticulously annotated to enable large-scale simulated human feedback and
facilitate costeffective real human interaction studies. Third, we introduce
ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM
competitive programming. With ELABORATION, we pinpoint strengthes and
weaknesses of existing methods, thereby setting the foundation for future
improvement. Our code and dataset are available at
https://github.com/SCUNLP/ELABORATION

</details>


### [100] [SPaRC: A Spatial Pathfinding Reasoning Challenge](https://arxiv.org/abs/2505.16686)
*Lars Benedikt Kaesberg, Jan Philip Wahle, Terry Ruas, Bela Gipp*

**主要类别:** cs.AI

**概要:** This paper introduces SPaRC, a new dataset of 1,000 2D grid pathfinding puzzles designed to evaluate spatial and symbolic reasoning. Humans outperform current reasoning models significantly.


<details>
  <summary>更多</summary>
  
**动机:** Current reasoning datasets fail to effectively test abstract, multi-step problems like pathfinding. Existing models struggle with these types of challenges.

**方法:** Developed SPaRC dataset containing 1,000 puzzles requiring step-by-step planning with arithmetic and geometric rules.

**结果:** Human performance is near-perfect (98.0%), whereas the best models achieve only 15.8%. Models also generate many invalid paths and make navigation errors.

**结论:** SPaRC highlights limitations in current models' spatial reasoning abilities and suggests potential improvements through better training and test-time scaling methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPaRC%3A+A+Spatial+Pathfinding+Reasoning+Challenge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16686&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning datasets saturate and fail to test abstract, multi-step
problems, especially pathfinding and complex rule constraint satisfaction. We
introduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000
2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,
requiring step-by-step planning with arithmetic and geometric rules. Humans
achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best
reasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).
Models often generate invalid paths (>50% of puzzles for o4-mini), and
reasoning tokens reveal they make errors in navigation and spatial logic.
Unlike humans, who take longer on hard puzzles, models fail to scale test-time
compute with difficulty. Allowing models to make multiple solution attempts
improves accuracy, suggesting potential for better spatial reasoning with
improved training and efficient test-time scaling methods. SPaRC can be used as
a window into models' spatial reasoning limitations and drive research toward
new methods that excel in abstract, multi-step problem-solving.

</details>


### [101] [MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](https://arxiv.org/abs/2505.16700)
*Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen*

**主要类别:** cs.AI

**概要:** 本文介绍了一个新的基准MCP-RADAR，用于全面评估大型语言模型在模型上下文协议框架内的工具利用能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的评估方法未能充分评估LLMs在新范式中的工具利用能力。

**方法:** 提出了一个名为MCP-RADAR的新基准，采用五维方法测量答案准确性、工具选择效率、计算资源效率、参数构建准确性和执行速度。

**结果:** MCP-RADAR评估显示了领先商业和开源LLMs的独特能力特征，并揭示了准确度、效率和速度之间的显著权衡。

**结论:** 提出了一种新的基准MCP-RADAR来评估LLMs在MCP框架下的性能，并揭示了不同模型在准确度、效率和速度之间的权衡。我们的方法不仅适用于MCP，也为优化整个LLM-工具交互生态系统提供了有价值的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCP-RADAR%3A+A+Multi-Dimensional+Benchmark+for+Evaluating+Tool+Use+Capabilities+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16700&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLMs) evolve from passive text generators to active
reasoning agents capable of tool interaction, the Model Context Protocol (MCP)
has emerged as a standardized framework for dynamic tool discovery and
orchestration. Despite widespread industry adoption, existing evaluation
methodologies fail to adequately assess tool utilization capabilities within
this new paradigm. This paper introduces MCP-RADAR, the first comprehensive
benchmark specifically designed to evaluate LLM performance in the MCP
framework through a novel five-dimensional approach measuring: answer accuracy,
tool selection efficiency, computational resource efficiency, parameter
construction accuracy, and execution speed. Unlike conventional benchmarks that
rely on subjective human evaluations or binary success metrics, MCP-RADAR
employs objective, quantifiable measurements across multiple task domains
including software engineering, mathematical reasoning, and general
problem-solving. Our evaluations of leading commercial and open-source LLMs
reveal distinctive capability profiles with significant trade-offs between
accuracy, efficiency, and speed, challenging traditional single-metric
performance rankings. Besides, we provide valuable guidance for developers to
optimize their tools for maximum model compatibility and effectiveness. While
focused on MCP due to its standardized approach, our methodology remains
applicable across all LLM agent tool integration frameworks, providing valuable
insights for both LLM developers and tool creators to optimize the entire
LLM-tool interaction ecosystem. The implementation, configurations, and
datasets used in our evaluation are publicly available at
https://anonymous.4open.science/r/MCPRadar-B143.

</details>


### [102] [Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review](https://arxiv.org/abs/2505.16771)
*Beyazit Bestami Yuksel, Ayse Yilmazer Metin*

**主要类别:** cs.AI

**概要:** 本文综述了过去十五年中人工智能领域的重大突破，从历史、理论和技术角度整合了这些进展。通过追踪计算资源、数据访问和算法创新的交汇点来识别AI发展的关键转折点。文章强调了研究人员如何利用GPU进行模型训练、通过ImageNet触发数据为中心的转变、简化架构为Transformer，并扩展了GPT系列的建模能力。除了孤立地看待这些进步外，还将其视为更深层次范式转换的指标。运用统计学习理论中的样本复杂性和数据效率等概念解释了研究者如何将突破转化为可扩展的解决方案，并探讨了隐私问题日益突出的情况下新兴的数据中心化方法。此外，对于无法获得现实世界数据的情况，评估了模拟和合成数据生成的实用性和限制。这项研究结合技术洞察与不断发展的数据基础设施，为未来的AI研究和政策制定提供了战略指导。


<details>
  <summary>更多</summary>
  
**动机:** 总结过去十五年中人工智能领域的重要进展，并从多个视角理解这些突破的本质及意义。

**方法:** 通过追踪计算资源、数据访问和算法创新的交汇点来识别AI发展的关键转折点，同时运用统计学习理论的概念来解释这些进展。

**结果:** 识别出了几个重要的转折点，如GPU模型训练、ImageNet引发的数据中心化转变、Transformer简化架构以及GPT系列扩展建模能力。提出了数据中心化方法的重要性，并评估了模拟和合成数据生成在特定情况下的应用。

**结论:** 本研究不仅总结了AI领域的重大进展，还揭示了这些进步背后的深层模式，并为未来的研究方向和政策制定提供了战略建议。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Driven+Breakthroughs+and+Future+Directions+in+AI+Infrastructure%3A+A+Comprehensive+Review，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16771，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16771&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a comprehensive synthesis of major breakthroughs in
artificial intelligence (AI) over the past fifteen years, integrating
historical, theoretical, and technological perspectives. It identifies key
inflection points in AI' s evolution by tracing the convergence of
computational resources, data access, and algorithmic innovation. The analysis
highlights how researchers enabled GPU based model training, triggered a data
centric shift with ImageNet, simplified architectures through the Transformer,
and expanded modeling capabilities with the GPT series. Rather than treating
these advances as isolated milestones, the paper frames them as indicators of
deeper paradigm shifts. By applying concepts from statistical learning theory
such as sample complexity and data efficiency, the paper explains how
researchers translated breakthroughs into scalable solutions and why the field
must now embrace data centric approaches. In response to rising privacy
concerns and tightening regulations, the paper evaluates emerging solutions
like federated learning, privacy enhancing technologies (PETs), and the data
site paradigm, which reframe data access and security. In cases where real
world data remains inaccessible, the paper also assesses the utility and
constraints of mock and synthetic data generation. By aligning technical
insights with evolving data infrastructure, this study offers strategic
guidance for future AI research and policy development.

</details>


### [103] [Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making](https://arxiv.org/abs/2505.16781)
*Qianlei Jia, Xinliang Zhou, Ondrej Krejcar, Enrique Herrera-Viedma*

**主要类别:** cs.AI

**概要:** This study proposes a new SNGDM framework integrating three-way decision theory, dynamic network reconstruction, and linguistic opinion representation to handle uncertainty and dynamic social structures in GDM.


<details>
  <summary>更多</summary>
  
**动机:** To address challenges in traditional opinion dynamics models regarding uncertainty, dynamic social structures, and vague information in GDM scenarios.

**方法:** Integrates three-way decision theory, develops a connection adjustment rule based on opinion similarity, uses linguistic terms for opinions, and constructs a multi-agent decision-making framework.

**结果:** The model is effective in a multi-UAV cooperative decision-making scenario, with simulation results and consensus analysis demonstrating its performance.

**结论:** The proposed framework enhances system stability and represents realistic decision-making behaviors better than traditional models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fuzzy+Information+Evolution+with+Three-Way+Decision+in+Social+Network+Group+Decision-Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16781，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16781&send_immediately=true&force_search=false)

**原文摘要:** In group decision-making (GDM) scenarios, uncertainty, dynamic social
structures, and vague information present major challenges for traditional
opinion dynamics models. To address these issues, this study proposes a novel
social network group decision-making (SNGDM) framework that integrates
three-way decision (3WD) theory, dynamic network reconstruction, and linguistic
opinion representation. First, the 3WD mechanism is introduced to explicitly
model hesitation and ambiguity in agent judgments, thereby preventing
irrational decisions. Second, a connection adjustment rule based on opinion
similarity is developed, enabling agents to adaptively update their
communication links and better reflect the evolving nature of social
relationships. Third, linguistic terms are used to describe agent opinions,
allowing the model to handle subjective, vague, or incomplete information more
effectively. Finally, an integrated multi-agent decision-making framework is
constructed, which simultaneously considers individual uncertainty, opinion
evolution, and network dynamics. The proposed model is applied to a multi-UAV
cooperative decision-making scenario, where simulation results and consensus
analysis demonstrate its effectiveness. Experimental comparisons further verify
the advantages of the algorithm in enhancing system stability and representing
realistic decision-making behaviors.

</details>


### [104] [Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce](https://arxiv.org/abs/2505.16787)
*Ashish Sundar, Chunbo Luo, Xiaoyang Wang*

**主要类别:** cs.AI

**概要:** This paper proposes a novel approach for model-based reinforcement learning (MBRL) that improves the world model's fidelity and reduces its time to convergence by seeking out high-entropy states.


<details>
  <summary>更多</summary>
  
**动机:** To address the neglect of optimizing the world model learning in MBRL methods and improve the sample efficiency of model-free RL methods.

**方法:** Anticipating and actively seeking out high-entropy states using short-horizon latent predictions generated by the world model, and presenting a hierarchical planner that dynamically decides when to replan, planning horizon length, and the weighting between reward and entropy.

**结果:** The proposed method finishes the Miniworld procedurally generated mazes 50% faster than base Dreamer at convergence and the policy trained in imagination converges in only 60% of the environment steps that base Dreamer needs.

**结论:** The proposed method significantly improves the performance of MBRL methods by enhancing the world model and reducing its time to convergence.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gaze+Into+the+Abyss+--+Planning+to+Seek+Entropy+When+Reward+is+Scarce，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16787&send_immediately=true&force_search=false)

**原文摘要:** Model-based reinforcement learning (MBRL) offers an intuitive way to increase
the sample efficiency of model-free RL methods by simultaneously training a
world model that learns to predict the future. MBRL methods have progressed by
largely prioritising the actor; optimising the world model learning has been
neglected meanwhile. Improving the fidelity of the world model and reducing its
time to convergence can yield significant downstream benefits, one of which is
improving the ensuing performance of any actor it may train. We propose a novel
approach that anticipates and actively seeks out high-entropy states using
short-horizon latent predictions generated by the world model, offering a
principled alternative to traditional curiosity-driven methods that chase
once-novel states well after they were stumbled into. While many model
predictive control (MPC) based methods offer similar alternatives, they
typically lack commitment, synthesising multi step plans after every step. To
mitigate this, we present a hierarchical planner that dynamically decides when
to replan, planning horizon length, and the weighting between reward and
entropy. While our method can theoretically be applied to any model that trains
its own actors with solely model generated data, we have applied it to just
Dreamer as a proof of concept. Our method finishes the Miniworld procedurally
generated mazes 50% faster than base Dreamer at convergence and the policy
trained in imagination converges in only 60% of the environment steps that base
Dreamer needs.

</details>


### [105] [KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning](https://arxiv.org/abs/2505.16826)
*Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang*

**主要类别:** cs.AI

**概要:** Proposes Key-token Advantage Estimation (KTAE) to improve token-level advantage estimation in reinforcement learning for large language models.


<details>
  <summary>更多</summary>
  
**动机:** Existing reinforcement learning algorithms suffer from coarse granularity issues when computing advantages, failing to capture token-specific contributions.

**方法:** Introduces KTAE, which estimates fine-grained, token-level advantages by leveraging sampled rollouts and statistical analysis.

**结果:** Models trained with GRPO+KTAE and DAPO+KTAE outperform baseline methods on five mathematical reasoning benchmarks.

**结论:** KTAE improves the reasoning capabilities of large language models without introducing additional models or requiring supervised fine-tuning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是KTAE%3A+A+Model-Free+Algorithm+to+Key-Tokens+Advantage+Estimation+in+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16826，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16826&send_immediately=true&force_search=false)

**原文摘要:** Recent advances have demonstrated that integrating reinforcement learning
with rule-based rewards can significantly enhance the reasoning capabilities of
large language models, even without supervised fine-tuning. However, prevalent
reinforcement learning algorithms such as GRPO and its variants like DAPO,
suffer from a coarse granularity issue when computing the advantage.
Specifically, they compute rollout-level advantages that assign identical
values to every token within a sequence, failing to capture token-specific
contributions and hindering effective learning. To address this limitation, we
propose Key-token Advantage Estimation (KTAE) - a novel algorithm that
estimates fine-grained, token-level advantages without introducing additional
models. KTAE leverages the correctness of sampled rollouts and applies
statistical analysis to quantify the importance of individual tokens within a
sequence to the final outcome. This quantified token-level importance is then
combined with the rollout-level advantage to obtain a more fine-grained
token-level advantage estimation. Empirical results show that models trained
with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five
mathematical reasoning benchmarks. Notably, they achieve higher accuracy with
shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base
model.

</details>


### [106] [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://arxiv.org/abs/2505.16827)
*Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie*

**主要类别:** cs.AI

**概要:** A novel training-free GUI agent, GUI-explorer, addresses challenges in GUI automation by incorporating two mechanisms, achieving better performance than current state-of-the-art agents without needing parameter updates for new apps.


<details>
  <summary>更多</summary>
  
**动机:** To address the challenges faced by MLLMs in dynamic environments, including misinterpreting UI components and outdated knowledge, and the high cost of traditional fine-tuning methods for app-specific knowledge updates.

**方法:** GUI-explorer incorporates two mechanisms: Autonomous Exploration of Function-aware Trajectory and Unsupervised Mining of Transition-aware Knowledge.

**结果:** GUI-explorer achieves a task success rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, outperforming other state-of-the-art agents.

**结论:** GUI-explorer demonstrates significant improvements over state-of-the-art agents without requiring parameter updates for new apps.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUI-explorer%3A+Autonomous+Exploration+and+Mining+of+Transition-aware+Knowledge+for+GUI+Agent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16827，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16827&send_immediately=true&force_search=false)

**原文摘要:** GUI automation faces critical challenges in dynamic environments. MLLMs
suffer from two key issues: misinterpreting UI components and outdated
knowledge. Traditional fine-tuning methods are costly for app-specific
knowledge updates. We propose GUI-explorer, a training-free GUI agent that
incorporates two fundamental mechanisms: (1) Autonomous Exploration of
Function-aware Trajectory. To comprehensively cover all application
functionalities, we design a Function-aware Task Goal Generator that
automatically constructs exploration goals by analyzing GUI structural
information (e.g., screenshots and activity hierarchies). This enables
systematic exploration to collect diverse trajectories. (2) Unsupervised Mining
of Transition-aware Knowledge. To establish precise screen-operation logic, we
develop a Transition-aware Knowledge Extractor that extracts effective
screen-operation logic through unsupervised analysis the state transition of
structured interaction triples (observation, action, outcome). This eliminates
the need for human involvement in knowledge extraction. With a task success
rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows
significant improvements over SOTA agents. It requires no parameter updates for
new apps. GUI-explorer is open-sourced and publicly available at
https://github.com/JiuTian-VL/GUI-explorer.

</details>


### [107] [From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization](https://arxiv.org/abs/2505.16832)
*Haonian Ji, Shi Qiu, Siyang Xin, Siwei Han, Zhaorun Chen, Hongyi Wang, Dake Zhang, Huaxiu Yao*

**主要类别:** cs.AI

**概要:** 提出EduVisBench基准测试集和EduVisAgent框架来评估和提升基础模型在教育场景中的视觉推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法主要关注文本推理，忽视了结构化可视化在概念理解中的重要作用。

**方法:** 引入EduVisBench基准测试集和EduVisAgent多代理协作框架。

**结果:** EduVisAgent比基线模型表现更好，提高了40.2%。

**结论:** EduVisBench和EduVisAgent有助于提高基础模型生成教育上有效的视觉解释的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+EduVisBench+to+EduVisAgent%3A+A+Benchmark+and+Multi-Agent+Framework+for+Pedagogical+Visualization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16832，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16832&send_immediately=true&force_search=false)

**原文摘要:** While foundation models (FMs), such as diffusion models and large
vision-language models (LVLMs), have been widely applied in educational
contexts, their ability to generate pedagogically effective visual explanations
remains limited. Most existing approaches focus primarily on textual reasoning,
overlooking the critical role of structured and interpretable visualizations in
supporting conceptual understanding. To better assess the visual reasoning
capabilities of FMs in educational settings, we introduce EduVisBench, a
multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem
sets requiring visually grounded solutions, along with a fine-grained
evaluation rubric informed by pedagogical theory. Our empirical analysis
reveals that existing models frequently struggle with the inherent challenge of
decomposing complex reasoning and translating it into visual representations
aligned with human cognitive processes. To address these limitations, we
propose EduVisAgent, a multi-agent collaborative framework that coordinates
specialized agents for instructional planning, reasoning decomposition,
metacognitive prompting, and visualization design. Experimental results show
that EduVisAgent substantially outperforms all baselines, achieving a 40.2%
improvement and delivering more educationally aligned visualizations.
EduVisBench and EduVisAgent are available at
https://github.com/aiming-lab/EduVisBench and
https://github.com/aiming-lab/EduVisAgent.

</details>


### [108] [Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models](https://arxiv.org/abs/2505.16854)
*Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou*

**主要类别:** cs.AI

**概要:** A novel two-stage training strategy named TON is proposed to improve reasoning efficiency in vision-language models.


<details>
  <summary>更多</summary>
  
**动机:** To enable vision-language models to determine when reasoning is necessary, inspired by human-like thinking processes.

**方法:** TON includes a supervised fine-tuning stage with 'thought dropout' and a Group Relative Policy Optimization stage allowing models to freely decide when to reason.

**结果:** TON reduces completion length by up to 90% compared to vanilla GRPO, improving efficiency without losing performance.

**结论:** The study suggests that TON helps vision-language models learn human-like reasoning patterns, which is beneficial for various vision-language tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think+or+Not%3F+Selective+Reasoning+via+Reinforcement+Learning+for+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16854&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning (RL) has proven to be an effective post-training
strategy for enhancing reasoning in vision-language models (VLMs). Group
Relative Policy Optimization (GRPO) is a recent prominent method that
encourages models to generate complete reasoning traces before answering,
leading to increased token usage and computational cost. Inspired by the
human-like thinking process-where people skip reasoning for easy questions but
think carefully when needed-we explore how to enable VLMs to first decide when
reasoning is necessary. To realize this, we propose TON, a two-stage training
strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective
'thought dropout' operation, where reasoning traces are randomly replaced with
empty thoughts. This introduces a think-or-not format that serves as a cold
start for selective reasoning; (ii) a GRPO stage that enables the model to
freely explore when to think or not, while maximizing task-aware outcome
rewards. Experimental results show that TON can reduce the completion length by
up to 90% compared to vanilla GRPO, without sacrificing performance or even
improving it. Further evaluations across diverse vision-language tasks-covering
a range of reasoning difficulties under both 3B and 7B models-consistently
reveal that the model progressively learns to bypass unnecessary reasoning
steps as training advances. These findings shed light on the path toward
human-like reasoning patterns in reinforcement learning approaches. Our code is
available at https://github.com/kokolerk/TON.

</details>


### [109] [Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings](https://arxiv.org/abs/2505.16877)
*Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab*

**主要类别:** cs.AI

**概要:** 提出CondKGCP方法，提供基于谓词的条件覆盖保证，同时保持紧凑的预测集，证明了理论保障并展示了实证有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在高风险应用中需要更强的预测集一致性覆盖保证（条件覆盖保证）而非平均覆盖保证（边际覆盖保证）。

**方法:** 通过合并具有相似向量表示的谓词和使用排名信息增强校准来近似提供条件覆盖保证。

**结果:** CondKGCP方法提供了更强的条件覆盖保证并且保持预测集紧凑，在全面评估中证明了其理论保障和实证有效性。

**结论:** 提出的方法CondKGCP能够在知识图谱嵌入方法中提供更可靠的不确定性量化，特别是在需要强预测保证的高风险应用场景中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predicate-Conditional+Conformalized+Answer+Sets+for+Knowledge+Graph+Embeddings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16877，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16877&send_immediately=true&force_search=false)

**原文摘要:** Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is
crucial for ensuring the reliability of downstream applications. A recent work
applies conformal prediction to KGE methods, providing uncertainty estimates by
generating a set of answers that is guaranteed to include the true answer with
a predefined confidence level. However, existing methods provide probabilistic
guarantees averaged over a reference set of queries and answers (marginal
coverage guarantee). In high-stakes applications such as medical diagnosis, a
stronger guarantee is often required: the predicted sets must provide
consistent coverage per query (conditional coverage guarantee). We propose
CondKGCP, a novel method that approximates predicate-conditional coverage
guarantees while maintaining compact prediction sets. CondKGCP merges
predicates with similar vector representations and augments calibration with
rank information. We prove the theoretical guarantees and demonstrate empirical
effectiveness of CondKGCP by comprehensive evaluations.

</details>


### [110] [Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships](https://arxiv.org/abs/2505.16899)
*Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky*

**主要类别:** cs.AI

**概要:** This commentary discusses the risks of AI thought partners and proposes evaluation metrics and mitigation strategies for developers and policymakers.


<details>
  <summary>更多</summary>
  
**动机:** To explore the risks of AI thought partners and provide actionable suggestions for risk management.

**方法:** A novel framework is used to identify risks at multiple levels of analysis, including real-time, individual, and societal risks.

**结果:** The framework helps to propose concrete metrics for risk evaluation and suggests specific mitigation strategies.

**结论:** As AI thought partners become more common, these strategies can help prevent major harms and ensure human benefits.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Identifying%2C+Evaluating%2C+and+Mitigating+Risks+of+AI+Thought+Partnerships，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16899&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) systems have historically been used as tools
that execute narrowly defined tasks. Yet recent advances in AI have unlocked
possibilities for a new class of models that genuinely collaborate with humans
in complex reasoning, from conceptualizing problems to brainstorming solutions.
Such AI thought partners enable novel forms of collaboration and extended
cognition, yet they also pose major risks-including and beyond risks of typical
AI tools and agents. In this commentary, we systematically identify risks of AI
thought partners through a novel framework that identifies risks at multiple
levels of analysis, including Real-time, Individual, and Societal risks arising
from collaborative cognition (RISc). We leverage this framework to propose
concrete metrics for risk evaluation, and finally suggest specific mitigation
strategies for developers and policymakers. As AI thought partners continue to
proliferate, these strategies can help prevent major harms and ensure that
humans actively benefit from productive thought partnerships.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [111] [CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision](https://arxiv.org/abs/2505.15927)
*Awni Altabaa, Omar Montasser, John Lafferty*

**主要类别:** stat.ML

**概要:** 本文发展了链式思维(CoT)监督下的统计学习理论，通过CoT信息度量量化推理过程带来的额外判别能力，并证明了CoT监督可以比标准端到端(E2E)监督实现更快的学习速率。


<details>
  <summary>更多</summary>
  
**动机:** 学习涉及多步推理的复杂函数面临显著挑战，而CoT监督提供了中间推理步骤和最终输出，成为提升大型语言模型推理能力的强大经验技术。

**方法:** 引入了CoT信息度量来连接训练目标（CoT风险）和测试目标（端到端风险），并分析其对样本复杂度的影响。

**结果:** 证明了在CoT监督下，达到目标端到端错误所需的样本复杂度可以显著小于标准端到端监督所需的复杂度。

**结论:** CoT信息是链式思维监督下统计复杂性的基本度量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoT+Information%3A+Improved+Sample+Complexity+under+Chain-of-Thought+Supervision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15927&send_immediately=true&force_search=false)

**原文摘要:** Learning complex functions that involve multi-step reasoning poses a
significant challenge for standard supervised learning from input-output
examples. Chain-of-thought (CoT) supervision, which provides intermediate
reasoning steps together with the final output, has emerged as a powerful
empirical technique, underpinning much of the recent progress in the reasoning
capabilities of large language models. This paper develops a statistical theory
of learning under CoT supervision. A key characteristic of the CoT setting, in
contrast to standard supervision, is the mismatch between the training
objective (CoT risk) and the test objective (end-to-end risk). A central part
of our analysis, distinguished from prior work, is explicitly linking those two
types of risk to achieve sharper sample complexity bounds. This is achieved via
the *CoT information measure* $\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, which quantifies the additional
discriminative power gained from observing the reasoning process. The main
theoretical results demonstrate how CoT supervision can yield significantly
faster learning rates compared to standard E2E supervision. Specifically, it is
shown that the sample complexity required to achieve a target E2E error
$\epsilon$ scales as $d/\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, where $d$ is a measure of hypothesis
class complexity, which can be much faster than standard $d/\epsilon$ rates.
Information-theoretic lower bounds in terms of the CoT information are also
obtained. Together, these results suggest that CoT information is a fundamental
measure of statistical complexity for learning under chain-of-thought
supervision.

</details>


### [112] [PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals](https://arxiv.org/abs/2505.16051)
*Dongze Wu, David I. Inouye, Yao Xie*

**主要类别:** stat.ML

**概要:** 提出PO-Flow框架用于因果推断，能够同时建模潜在结果和反事实，无需显式分布假设，并在多个基准数据集上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 开发一种新的连续归一化流(CNF)框架来解决因果推理问题，特别是潜在结果和反事实的联合建模。

**方法:** 提出PO-Flow框架，通过流匹配训练，提供一个统一的潜在结果预测、反事实预测以及不确定性感知密度学习的方法。

**结果:** 在ACIC、IHDP、IBM等基准数据集上，PO-Flow在多种因果推理任务中表现优于先前方法，并且能够在高维设置下成功应用，例如反事实图像生成。

**结论:** PO-Flow是一个强大的工具，能够在不依赖于显式分布假设的情况下进行潜在结果的密度学习，并支持基于事实结果的反事实预测，展示了其广泛的适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PO-Flow%3A+Flow-based+Generative+Models+for+Sampling+Potential+Outcomes+and+Counterfactuals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16051，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16051&send_immediately=true&force_search=false)

**原文摘要:** We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for
causal inference that jointly models potential outcomes and counterfactuals.
Trained via flow matching, PO-Flow provides a unified framework for
individualized potential outcome prediction, counterfactual predictions, and
uncertainty-aware density learning. Among generative models, it is the first to
enable density learning of potential outcomes without requiring explicit
distributional assumptions (e.g., Gaussian mixtures), while also supporting
counterfactual prediction conditioned on factual outcomes in general
observational datasets. On benchmarks such as ACIC, IHDP, and IBM, it
consistently outperforms prior methods across a range of causal inference
tasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including
counterfactual image generation, demonstrating its broad applicability.

</details>


### [113] [Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schrödinger Bridge's End](https://arxiv.org/abs/2505.16082)
*Renato Berlinghieri, Yunyi Shen, Jialong Jiang, Tamara Broderick*

**主要类别:** stat.ML

**概要:** 提出了一种新的框架SnapMMD，用于学习潜伏随机动力学中的状态测量和观测时间的联合分布，提供准确的预测并改善了插值和速度场重建的表现。


<details>
  <summary>更多</summary>
  
**动机:** 科学家们经常希望根据“快照”数据的潜伏随机动力学做出超出观察时间范围的预测。然而，过去的Schrödinger-bridge (SB) 方法没有解决预测问题，因为现有的方法要么遵循预设的参考动力学，要么要求用户选择固定的状态无关的波动性，这些都可能导致预测质量差。

**方法:** 提出了一种新的框架SnapMMD，它通过最大均值差异(MMD)损失直接拟合状态测量和观测时间的联合分布来学习动力学。

**结果:** 在各种真实和合成实验中，SnapMMD方法提供了准确的预测，并且在插值（和一般速度场重建）方面的表现至少与最先进的方法一样好，通常更好。此外，该方法允许我们在存在不完整状态测量的情况下进行学习，并产生了一个诊断拟合的R²样式统计量。

**结论:** SnapMMD方法通过直接拟合状态测量和观测时间的联合分布来学习动力学，这种方法允许我们从观测数据中推断未知且状态相关的波动性。该方法在各种真实和合成实验中提供了准确的预测，并且允许我们在存在不完整状态测量的情况下进行学习，还产生了一个诊断拟合的R²样式统计量。此外，该方法在插值（和一般速度场重建）方面的表现至少与最先进的方法一样好，通常更好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Oh+SnapMMD%21+Forecasting+Stochastic+Dynamics+Beyond+the+Schr%C3%B6dinger+Bridge%27s+End，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16082，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16082&send_immediately=true&force_search=false)

**原文摘要:** Scientists often want to make predictions beyond the observed time horizon of
"snapshot" data following latent stochastic dynamics. For example, in time
course single-cell mRNA profiling, scientists have access to cellular
transcriptional state measurements (snapshots) from different biological
replicates at different time points, but they cannot access the trajectory of
any one cell because measurement destroys the cell. Researchers want to
forecast (e.g.) differentiation outcomes from early state measurements of stem
cells. Recent Schr\"odinger-bridge (SB) methods are natural for interpolating
between snapshots. But past SB papers have not addressed forecasting -- likely
since existing methods either (1) reduce to following pre-set reference
dynamics (chosen before seeing data) or (2) require the user to choose a fixed,
state-independent volatility since they minimize a Kullback-Leibler divergence.
Either case can lead to poor forecasting quality. In the present work, we
propose a new framework, SnapMMD, that learns dynamics by directly fitting the
joint distribution of both state measurements and observation time with a
maximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to
infer unknown and state-dependent volatilities from the observed data. We show
in a variety of real and synthetic experiments that our method delivers
accurate forecasts. Moreover, our approach allows us to learn in the presence
of incomplete state measurements and yields an $R^2$-style statistic that
diagnoses fit. We also find that our method's performance at interpolation (and
general velocity-field reconstruction) is at least as good as (and often better
than) state-of-the-art in almost all of our experiments.

</details>


### [114] [Dimension-adapted Momentum Outscales SGD](https://arxiv.org/abs/2505.16098)
*Damien Ferbach, Katie Everett, Gauthier Gidel, Elliot Paquette, Courtney Paquette*

**主要类别:** stat.ML

**概要:** 研究了随机动量算法在幂律随机特征模型中的缩放规律，提出了一种改进的动量超参数调整方法（DANA），在多种复杂度下优于传统SGD-M。


<details>
  <summary>更多</summary>
  
**动机:** 探索随机动量算法的缩放规律及其在不同数据和目标复杂度下的表现。

**方法:** 对幂律随机特征模型进行分析，并提出DANA方法来优化动量超参数。

**结果:** 发现四种不同的损失曲线形状，并证明DANA在改善计算最优缩放行为方面优于传统方法。

**结论:** DANA在多种复杂度下表现出更优的损失指数，并在大规模文本实验中得到验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dimension-adapted+Momentum+Outscales+SGD，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16098&send_immediately=true&force_search=false)

**原文摘要:** We investigate scaling laws for stochastic momentum algorithms with small
batch on the power law random features model, parameterized by data complexity,
target complexity, and model size. When trained with a stochastic momentum
algorithm, our analysis reveals four distinct loss curve shapes determined by
varying data-target complexities. While traditional stochastic gradient descent
with momentum (SGD-M) yields identical scaling law exponents to SGD,
dimension-adapted Nesterov acceleration (DANA) improves these exponents by
scaling momentum hyperparameters based on model size and data complexity. This
outscaling phenomenon, which also improves compute-optimal scaling behavior, is
achieved by DANA across a broad range of data and target complexities, while
traditional methods fall short. Extensive experiments on high-dimensional
synthetic quadratics validate our theoretical predictions and large-scale text
experiments with LSTMs show DANA's improved loss exponents over SGD hold in a
practical setting.

</details>


### [115] [Exponential Convergence of CAVI for Bayesian PCA](https://arxiv.org/abs/2505.16145)
*Arghya Datta, Philippe Gagnon, Florian Maire*

**主要类别:** stat.ML

**概要:** 本文研究了贝叶斯概率主成分分析(BPCA)中坐标上升变分推断(CAVI)算法的收敛性问题，填补了现有文献中的空白。


<details>
  <summary>更多</summary>
  
**动机:** 填补了现有文献中关于BPCA中CAVI收敛速度未被表征的空白。

**方法:** 通过与经典幂迭代算法的联系以及利用最近的信息论工具，分别证明了单主成分和任意数量主成分情况下的指数收敛性。

**结果:** 证明了单主成分情况下CAVI的精确指数收敛结果；证明了任意数量主成分情况下CAVI的指数收敛性，并提出了一个新的信息论工具。

**结论:** 证明了坐标上升变分推断(CAVI)算法在BPCA模型中的指数收敛性，并引入了一个新的多元正态分布之间的对称KL散度下界。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exponential+Convergence+of+CAVI+for+Bayesian+PCA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16145，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16145&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic principal component analysis (PCA) and its Bayesian variant
(BPCA) are widely used for dimension reduction in machine learning and
statistics. The main advantage of probabilistic PCA over the traditional
formulation is allowing uncertainty quantification. The parameters of BPCA are
typically learned using mean-field variational inference, and in particular,
the coordinate ascent variational inference (CAVI) algorithm. So far, the
convergence speed of CAVI for BPCA has not been characterized. In our paper, we
fill this gap in the literature. Firstly, we prove a precise exponential
convergence result in the case where the model uses a single principal
component (PC). Interestingly, this result is established through a connection
with the classical $\textit{power iteration algorithm}$ and it indicates that
traditional PCA is retrieved as points estimates of the BPCA parameters.
Secondly, we leverage recent tools to prove exponential convergence of CAVI for
the model with any number of PCs, thus leading to a more general result, but
one that is of a slightly different flavor. To prove the latter result, we
additionally needed to introduce a novel lower bound for the symmetric
Kullback--Leibler divergence between two multivariate normal distributions,
which, we believe, is of independent interest in information theory.

</details>


### [116] [Integral Imprecise Probability Metrics](https://arxiv.org/abs/2505.16156)
*Siu Lun Chau, Michele Caprio, Krikamol Muandet*

**主要类别:** stat.ML

**概要:** 本文提出了一种积分不精确概率度量（IIPM）框架，用于比较和量化认识不确定性（EU）。


<details>
  <summary>更多</summary>
  
**动机:** 经典概率不足以表示认识不确定性（EU），而模糊概率（IP）理论提供了这样的模型，因此需要超越经典概率的度量方法。

**方法:** 提出了一种基于Choquet积分的积分不精确概率度量（IIPM）框架，并验证了其作为有效度量的条件以及支持弱收敛的度量化。

**结果:** IIPM能够跨不同的IP模型进行比较，并在一个单一的IP模型内支持对认识不确定性的量化，提出了新的最大均值不精确性（MMI）度量，验证了其在选择性分类实验中的表现。

**结论:** 提出了积分不精确概率度量（IIPM）框架，它在能力设置上推广了经典的积分概率度量（IPM），并且在理论上建立了IIPM作为有效度量的条件，并且支持弱收敛的度量化。实践上，IIPM不仅能够跨不同的IP模型进行比较，还能在一个单一的IP模型内支持对认识不确定性（EU）的量化。通过选择性分类实验验证了IIPM的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Integral+Imprecise+Probability+Metrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16156，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16156&send_immediately=true&force_search=false)

**原文摘要:** Quantifying differences between probability distributions is fundamental to
statistics and machine learning, primarily for comparing statistical
uncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete
knowledge -- requires richer representations than those offered by classical
probability. Imprecise probability (IP) theory offers such models, capturing
ambiguity and partial belief. This has driven growing interest in imprecise
probabilistic machine learning (IPML), where inference and decision-making rely
on broader uncertainty models -- highlighting the need for metrics beyond
classical probability. This work introduces the Integral Imprecise Probability
Metric (IIPM) framework, a Choquet integral-based generalisation of classical
Integral Probability Metric (IPM) to the setting of capacities -- a broad class
of IP models encompassing many existing ones, including lower probabilities,
probability intervals, belief functions, and more. Theoretically, we establish
conditions under which IIPM serves as a valid metric and metrises a form of
weak convergence of capacities. Practically, IIPM not only enables comparison
across different IP models but also supports the quantification of epistemic
uncertainty within a single IP model. In particular, by comparing an IP model
with its conjugate, IIPM gives rise to a new class of EU measures -- Maximum
Mean Imprecision -- which satisfy key axiomatic properties proposed in the
Uncertainty Quantification literature. We validate MMI through selective
classification experiments, demonstrating strong empirical performance against
established EU measures, and outperforming them when classical methods struggle
to scale to a large number of classes. Our work advances both theory and
practice in IPML, offering a principled framework for comparing and quantifying
epistemic uncertainty under imprecision.

</details>


### [117] [Generalized Power Priors for Improved Bayesian Inference with Historical Data](https://arxiv.org/abs/2505.16244)
*Masanari Kimura, Howard Bondell*

**主要类别:** stat.ML

**概要:** This paper extends the power prior framework by using Amari's α-divergence instead of KL divergence, showing potential for improved performance and offering new geometric insights.


<details>
  <summary>更多</summary>
  
**动机:** To enhance the power prior framework by generalizing it with a more flexible divergence measure.

**方法:** Reformulating the power prior as the minimizer of a linear combination of Amari's α-divergence.

**结果:** Improved performance due to better adaptation to data via appropriate α parameter choices.

**结论:** This generalized power prior provides deeper geometric understanding and potentially better performance in Bayesian analysis.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalized+Power+Priors+for+Improved+Bayesian+Inference+with+Historical+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16244&send_immediately=true&force_search=false)

**原文摘要:** The power prior is a class of informative priors designed to incorporate
historical data alongside current data in a Bayesian framework. It includes a
power parameter that controls the influence of historical data, providing
flexibility and adaptability. A key property of the power prior is that the
resulting posterior minimizes a linear combination of KL divergences between
two pseudo-posterior distributions: one ignoring historical data and the other
fully incorporating it. We extend this framework by identifying the posterior
distribution as the minimizer of a linear combination of Amari's
$\alpha$-divergence, a generalization of KL divergence. We show that this
generalization can lead to improved performance by allowing for the data to
adapt to appropriate choices of the $\alpha$ parameter. Theoretical properties
of this generalized power posterior are established, including behavior as a
generalized geodesic on the Riemannian manifold of probability distributions,
offering novel insights into its geometric interpretation.

</details>


### [118] [Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry](https://arxiv.org/abs/2505.16251)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** 提出一种基于图平滑贝叶斯方法(GS-B³SE)解决标签转移适应问题，该方法通过在目标先验和混淆矩阵列上放置拉普拉斯-高斯先验，并在标记相似性图上进行关联，提供了一种完全概率性的替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 现有经典黑盒移位估计器存在脆弱性，会忽略采样噪声和类别之间的相似性。

**方法:** GS-B³SE方法在目标先验和混淆矩阵列上放置拉普拉斯-高斯先验，并在标签相似性图上进行关联，提供了完全概率性的解决方案。

**结果:** 证明了可识别性、N⁻¹/²收敛、随图代数连通性增加的方差界缩小以及拉普拉斯误指定的鲁棒性。

**结论:** GS-B³SE方法重新解释了信息几何，推广了现有的移位估计器。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-Smoothed+Bayesian+Black-Box+Shift+Estimator+and+Its+Information+Geometry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16251，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16251&send_immediately=true&force_search=false)

**原文摘要:** Label shift adaptation aims to recover target class priors when the labelled
source distribution $P$ and the unlabelled target distribution $Q$ share $P(X
\mid Y) = Q(X \mid Y)$ but $P(Y) \neq Q(Y)$. Classical black-box shift
estimators invert an empirical confusion matrix of a frozen classifier,
producing a brittle point estimate that ignores sampling noise and similarity
among classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully
probabilistic alternative that places Laplacian-Gaussian priors on both target
log-priors and confusion-matrix columns, tying them together on a
label-similarity graph. The resulting posterior is tractable with HMC or a fast
block Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,
variance bounds that shrink with the graph's algebraic connectivity, and
robustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE
through information geometry, showing that it generalizes existing shift
estimators.

</details>


### [119] [Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics](https://arxiv.org/abs/2505.16257)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** This study develops a new framework for test-time adaptation of Batch Normalization statistics under distribution shift using advanced statistical methods.


<details>
  <summary>更多</summary>
  
**动机:** To improve the reliability and performance of BN layers when adapting to changing data distributions.

**方法:** Integrating Edgeworth expansion, saddlepoint approximation techniques, and a novel one-step M-estimation perspective.

**结果:** Derives an optimal weighting parameter, higher-order local asymptotic normality results, and establishes a generalization bound on model risk.

**结论:** Higher-order corrections and robust one-step updating enhance the reliability and performance of BN layers.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Higher-Order+Asymptotics+of+Test-Time+Adaptation+for+Batch+Normalization+Statistics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16257，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16257&send_immediately=true&force_search=false)

**原文摘要:** This study develops a higher-order asymptotic framework for test-time
adaptation (TTA) of Batch Normalization (BN) statistics under distribution
shift by integrating classical Edgeworth expansion and saddlepoint
approximation techniques with a novel one-step M-estimation perspective. By
analyzing the statistical discrepancy between training and test distributions,
we derive an Edgeworth expansion for the normalized difference in BN means and
obtain an optimal weighting parameter that minimizes the mean-squared error of
the adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows
us to derive higher-order local asymptotic normality results, which incorporate
skewness and other higher moments into the estimator's behavior. Moreover, we
quantify the trade-offs among bias, variance, and skewness in the adaptation
process and establish a corresponding generalization bound on the model risk.
The refined saddlepoint approximations further deliver uniformly accurate
density and tail probability estimates for the BN TTA statistic. These
theoretical insights provide a comprehensive understanding of how higher-order
corrections and robust one-step updating can enhance the reliability and
performance of BN layers in adapting to changing data distributions.

</details>


### [120] [Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions](https://arxiv.org/abs/2505.16311)
*Marc Brooks, Gabriel Durham, Kihyuk Hong, Ambuj Tewari*

**主要类别:** stat.ML

**概要:** This paper introduces GAMBITTS, a novel bandit approach for personalized GenAI-powered interventions. It improves policy learning by modeling both treatment and reward processes.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitations of standard bandit methods in handling the unique structure of GenAI-powered interventions.

**方法:** Introduces GAMBITTS, which models both treatment and reward generation processes and uses information from delivered treatments to speed up policy learning.

**结果:** In simulations, GAMBITTS outperforms traditional algorithms by more accurately estimating expected rewards.

**结论:** GAMBITTS provides a promising solution for personalization in GenAI-powered interventions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generator-Mediated+Bandits%3A+Thompson+Sampling+for+GenAI-Powered+Adaptive+Interventions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16311，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16311&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in generative artificial intelligence (GenAI) models have
enabled the generation of personalized content that adapts to up-to-date user
context. While personalized decision systems are often modeled using bandit
formulations, the integration of GenAI introduces new structure into otherwise
classical sequential learning problems. In GenAI-powered interventions, the
agent selects a query, but the environment experiences a stochastic response
drawn from the generative model. Standard bandit methods do not explicitly
account for this structure, where actions influence rewards only through
stochastic, observed treatments. We introduce generator-mediated
bandit-Thompson sampling (GAMBITTS), a bandit approach designed for this
action/treatment split, using mobile health interventions with large language
model-generated text as a motivating case study. GAMBITTS explicitly models
both the treatment and reward generation processes, using information in the
delivered treatment to accelerate policy learning relative to standard methods.
We establish regret bounds for GAMBITTS by decomposing sources of uncertainty
in treatment and reward, identifying conditions where it achieves stronger
guarantees than standard bandit approaches. In simulation studies, GAMBITTS
consistently outperforms conventional algorithms by leveraging observed
treatments to more accurately estimate expected rewards.

</details>


### [121] [Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping](https://arxiv.org/abs/2505.16329)
*Simone Bombari, Inbar Seroussi, Marco Mondelli*

**主要类别:** stat.ML

**概要:** 本文通过理论分析和实证研究，解决了差分隐私线性回归中理论与实践之间的不一致问题，提出并验证了激进裁剪的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的理论工作和实际表现之间存在差距，特别是DP线性回归中的误差率改进问题。

**方法:** 通过建立DP-SGD轨迹的确定性等价于一族常微分方程（ODEs），并研究这些ODEs在n/d足够大时的行为。

**结果:** 提供了DP-SGD的更尖锐的速率，在频繁裁剪的条件下，对于多变量高斯数据和特定比例的训练样本数，保证常量阶零集中DP。

**结论:** 提出了新的理论方法来解释DP-SGD在实际中的表现，证明了激进裁剪的最优性，并揭示了衰减学习率和私有噪声调度的好处。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Better+Rates+for+Private+Linear+Regression+in+the+Proportional+Regime+via+Aggressive+Clipping，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16329，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16329&send_immediately=true&force_search=false)

**原文摘要:** Differentially private (DP) linear regression has received significant
attention in the recent theoretical literature, with several works aimed at
obtaining improved error rates. A common approach is to set the clipping
constant much larger than the expected norm of the per-sample gradients. While
simplifying the analysis, this is however in sharp contrast with what empirical
evidence suggests to optimize performance. Our work bridges this gap between
theory and practice: we provide sharper rates for DP stochastic gradient
descent (DP-SGD) by crucially operating in a regime where clipping happens
frequently. Specifically, we consider the setting where the data is
multivariate Gaussian, the number of training samples $n$ is proportional to
the input dimension $d$, and the algorithm guarantees constant-order zero
concentrated DP. Our method relies on establishing a deterministic equivalent
for the trajectory of DP-SGD in terms of a family of ordinary differential
equations (ODEs). As a consequence, the risk of DP-SGD is bounded between two
ODEs, with upper and lower bounds matching for isotropic data. By studying
these ODEs when $n / d$ is large enough, we demonstrate the optimality of
aggressive clipping, and we uncover the benefits of decaying learning rate and
private noise scheduling.

</details>


### [122] [Learning non-equilibrium diffusions with Schrödinger bridges: from exactly solvable to simulation-free](https://arxiv.org/abs/2505.16644)
*Stephen Y. Zhang, Michael P H Stumpf*

**主要类别:** stat.ML

**概要:** This paper studies the Schrödinger bridge problem using multivariate Ornstein-Uhlenbeck processes, proposing a novel method (mvOU-OTFM) for both static and dynamic cases, showing high accuracy and efficiency in synthetic and real single-cell data.


<details>
  <summary>更多</summary>
  
**动机:** To develop a more general approach for the Schrödinger bridge problem that can handle non-equilibrium systems with non-conservative forces, particularly relevant for biological applications.

**方法:** Derives explicit solutions for Gaussian marginals and proposes a simulation-free algorithm called mvOU-OTFM for general marginals using flow and score matching.

**结果:** The proposed method mvOU-OTFM shows higher accuracy and faster training times compared to other methods when applied to synthetic and real single-cell data.

**结论:** The study successfully extends the Schrödinger bridge framework to non-equilibrium systems using multivariate Ornstein-Uhlenbeck processes, demonstrating practical utility through efficient and accurate algorithms.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+non-equilibrium+diffusions+with+Schr%C3%B6dinger+bridges%3A+from+exactly+solvable+to+simulation-free，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16644，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16644&send_immediately=true&force_search=false)

**原文摘要:** We consider the Schr\"odinger bridge problem which, given ensemble
measurements of the initial and final configurations of a stochastic dynamical
system and some prior knowledge on the dynamics, aims to reconstruct the "most
likely" evolution of the system compatible with the data. Most existing
literature assume Brownian reference dynamics and are implicitly limited to
potential-driven dynamics. We depart from this regime and consider reference
processes described by a multivariate Ornstein-Uhlenbeck process with generic
drift matrix $\mathbf{A} \in \mathbb{R}^{d \times d}$. When $\mathbf{A}$ is
asymmetric, this corresponds to a non-equilibrium system with non-conservative
forces at play: this is important for applications to biological systems, which
are naturally exist out-of-equilibrium. In the case of Gaussian marginals, we
derive explicit expressions that characterise the solution of both the static
and dynamic Schr\"odinger bridge. For general marginals, we propose mvOU-OTFM,
a simulation-free algorithm based on flow and score matching for learning the
Schr\"odinger bridge. In application to a range of problems based on synthetic
and real single cell data, we demonstrate that mvOU-OTFM achieves higher
accuracy compared to competing methods, whilst being significantly faster to
train.

</details>


### [123] [Sharp concentration of uniform generalization errors in binary linear classification](https://arxiv.org/abs/2505.16713)
*Shogo Nakakita*

**主要类别:** stat.ML

**概要:** 通过等周论证，研究二元线性分类问题中均匀推广误差的集中情况，并证明了Poincaré和log-Sobolev不等式，得到集中界限。


<details>
  <summary>更多</summary>
  
**动机:** 研究二元线性分类问题中均匀推广误差围绕其期望的集中情况。

**方法:** 使用等周论点和二元线性分类问题中的联合分布输出标签和标记加权输入向量。

**结果:** 得到了关于均匀推广误差的集中界限，且这些界限在适度的乘法常数内是尖锐的。

**结论:** 证明了Poincaré和log-Sobolev不等式，并得到了关于均匀推广误差的集中界限。在渐近分析中，展示了几乎确定的收敛性，并建立了无维度条件下的均匀大数定律。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sharp+concentration+of+uniform+generalization+errors+in+binary+linear+classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16713，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16713&send_immediately=true&force_search=false)

**原文摘要:** We examine the concentration of uniform generalization errors around their
expectation in binary linear classification problems via an isoperimetric
argument. In particular, we establish Poincar\'{e} and log-Sobolev inequalities
for the joint distribution of the output labels and the label-weighted input
vectors, which we apply to derive concentration bounds. The derived
concentration bounds are sharp up to moderate multiplicative constants by those
under well-balanced labels. In asymptotic analysis, we also show that almost
sure convergence of uniform generalization errors to their expectation occurs
in very broad settings, such as proportionally high-dimensional regimes. Using
this convergence, we establish uniform laws of large numbers under
dimension-free conditions.

</details>


### [124] [How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning](https://arxiv.org/abs/2505.16879)
*Hannah Sansford, Nick Whiteley, Patrick Rubin-Delanchy*

**主要类别:** stat.ML

**概要:** This paper introduces a generalized Hanson-Wright inequality and applies it to understand the geometry of data clouds, defining three types of dimensions and showing conditions under which latent structures can be revealed.


<details>
  <summary>更多</summary>
  
**动机:** To provide statistical insights into the geometry of data point-clouds using a generalized Hanson-Wright inequality.

**方法:** Analyzing the roles of three notions of dimensionality in a general random function model of data.

**结果:** Sufficient condition for persistence diagrams to reveal latent homology and for manifold structure to emerge is $p_{\mathrm{int}}\gg \log n$.

**结论:** Theoretical findings support that grid cell activity conveys a geometrically accurate representation of the real world.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+high+is+%60high%27%3F+Rethinking+the+roles+of+dimensionality+in+topological+data+analysis+and+manifold+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16879，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16879&send_immediately=true&force_search=false)

**原文摘要:** We present a generalised Hanson-Wright inequality and use it to establish new
statistical insights into the geometry of data point-clouds. In the setting of
a general random function model of data, we clarify the roles played by three
notions of dimensionality: ambient intrinsic dimension $p_{\mathrm{int}}$,
which measures total variability across orthogonal feature directions;
correlation rank, which measures functional complexity across samples; and
latent intrinsic dimension, which is the dimension of manifold structure hidden
in data. Our analysis shows that in order for persistence diagrams to reveal
latent homology and for manifold structure to emerge it is sufficient that
$p_{\mathrm{int}}\gg \log n$, where $n$ is the sample size. Informed by these
theoretical perspectives, we revisit the ground-breaking neuroscience discovery
of toroidal structure in grid-cell activity made by Gardner et al. (Nature,
2022): our findings reveal, for the first time, evidence that this structure is
in fact isometric to physical space, meaning that grid cell activity conveys a
geometrically faithful representation of the real world.

</details>


### [125] [Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference](https://arxiv.org/abs/2505.16893)
*Shuichi Nishino, Tomohiro Shiraishi, Teruyuki Katsuoka, Ichiro Takeuchi*

**主要类别:** stat.ML

**概要:** 提出一种统计测试框架评估图神经网络显著性图的可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 解决图神经网络决策解释的可靠性问题，特别是显著性图对噪声的鲁棒性。

**方法:** 利用选择性推断框架构建统计测试方法，控制I型错误率并提供有效的p值。

**结果:** 在合成和真实数据集上验证了方法的有效性。

**结论:** 所提方法确保识别出的显著子图包含有意义的信息。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Statistical+Test+for+Saliency+Maps+of+Graph+Neural+Networks+via+Selective+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16893&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have gained prominence for their ability to
process graph-structured data across various domains. However, interpreting GNN
decisions remains a significant challenge, leading to the adoption of saliency
maps for identifying influential nodes and edges. Despite their utility, the
reliability of GNN saliency maps has been questioned, particularly in terms of
their robustness to noise. In this study, we propose a statistical testing
framework to rigorously evaluate the significance of saliency maps. Our main
contribution lies in addressing the inflation of the Type I error rate caused
by double-dipping of data, leveraging the framework of Selective Inference. Our
method provides statistically valid $p$-values while controlling the Type I
error rate, ensuring that identified salient subgraphs contain meaningful
information rather than random artifacts. To demonstrate the effectiveness of
our method, we conduct experiments on both synthetic and real-world datasets,
showing its effectiveness in assessing the reliability of GNN interpretations.

</details>


### [126] [TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation](https://arxiv.org/abs/2505.16923)
*Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori*

**主要类别:** stat.ML

**概要:** 提出了一种名为TULiP的理论驱动后验不确定性估计方法用于异常检测，该方法通过线性化训练动态来限制网络在收敛前假设扰动的影响，从而计算不确定性得分，并在多个数据集上展示了其有效性，尤其是在近似分布样本的检测中表现出最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 可靠地估计不确定性对于深度学习模型在开放世界的安全部署至关重要，而现有的异常检测方法需要改进。

**方法:** 提出了TULiP方法，考虑了网络在收敛前的假设扰动，并基于线性化训练动力学限定了这种扰动的影响，从而计算出可由模型参数扰动得到的不确定性分数。

**结果:** TULiP方法在合成回归和分类数据集上可视化了其界限，并在大规模异常检测基准测试中证明了其有效性，特别是在处理近似分布样本时表现出最先进的性能。

**结论:** TULiP提供了一种新的理论驱动的后验不确定性估计方法，对于深度学习模型的安全部署具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TULiP%3A+Test-time+Uncertainty+Estimation+via+Linearization+and+Weight+Perturbation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16923，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16923&send_immediately=true&force_search=false)

**原文摘要:** A reliable uncertainty estimation method is the foundation of many modern
out-of-distribution (OOD) detectors, which are critical for safe deployments of
deep learning models in the open world. In this work, we propose TULiP, a
theoretically-driven post-hoc uncertainty estimator for OOD detection. Our
approach considers a hypothetical perturbation applied to the network before
convergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Ultimately, our approach computes uncertainty from a set of sampled
predictions. We visualize our bound on synthetic regression and classification
datasets. Furthermore, we demonstrate the effectiveness of TULiP using
large-scale OOD detection benchmarks for image classification. Our method
exhibits state-of-the-art performance, particularly for near-distribution
samples.

</details>


### [127] [Critical Points of Random Neural Networks](https://arxiv.org/abs/2505.17000)
*Simmaco Di Lillo*

**主要类别:** stat.ML

**概要:** 研究了无限宽度限制下不同激活函数随机神经网络的临界点数量随深度变化的情况。在适当正则条件下，推导出固定指数和超过给定阈值的临界点期望数量的精确渐近公式。揭示了三个不同的区域，其取决于协方差在1处的一阶导数值，并通过数值实验支持理论预测。此外，提供了当正则条件不满足时临界点数量增加的数值证据。


<details>
  <summary>更多</summary>
  
**动机:** 研究随机神经网络临界点数量的变化规律，特别是在不同激活函数和无限宽度限制下的行为。

**方法:** 通过数学分析推导出精确的渐近公式，并结合数值实验验证理论预测。

**结果:** 揭示了三种不同的增长模式（收敛、多项式增长、指数增长）取决于协方差的一阶导数，并发现ReLU激活函数等情况下临界点数量可能发散。

**结论:** 本研究揭示了随机神经网络在不同激活函数和无限宽度限制下临界点数量的增长规律，对理解神经网络的优化景观有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Critical+Points+of+Random+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17000，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17000&send_immediately=true&force_search=false)

**原文摘要:** This work investigates the expected number of critical points of random
neural networks with different activation functions as the depth increases in
the infinite-width limit. Under suitable regularity conditions, we derive
precise asymptotic formulas for the expected number of critical points of fixed
index and those exceeding a given threshold. Our analysis reveals three
distinct regimes depending on the value of the first derivative of the
covariance evaluated at 1: the expected number of critical points may converge,
grow polynomially, or grow exponentially with depth. The theoretical
predictions are supported by numerical experiments. Moreover, we provide
numerical evidence suggesting that, when the regularity condition is not
satisfied (e.g. for neural networks with ReLU as activation function), the
number of critical points increases as the map resolution increases, indicating
a potential divergence in the number of critical points.

</details>
