<div id=toc></div>

# 目录

- [cs.AI](#cs.AI) [总数: 29]
- [cs.CL](#cs.CL) [总数: 46]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions](https://arxiv.org/abs/2510.26852)
*Lingyue Fu, Xin Ding, Yaoming Zhu, Shao Zhang, Lin Qiu, Weiwen Liu, Weinan Zhang, Xuezhi Cao, Xunliang Cai, Jiaxin Ding, Yong Yu*

**主要类别:** cs.AI

**AI概要:** 该论文提出了CATArena评估平台，通过四款棋牌游戏的无上限计分系统，解决现有LLM智能体基准测试中的分数饱和问题，专注于评估智能体的学习能力和策略编码能力。


<details>
  <summary>更多</summary>
  
**动机:** 当前LLM智能体基准测试主要评估固定场景下的端到端性能，存在分数饱和、依赖专家标注、无法有效评估学习能力等问题，限制了智能体向人类水平智能的发展。

**方法:** 提出迭代竞争式同伴学习框架，让智能体通过重复互动和反馈优化策略；开发CATArena锦标赛式评估平台，包含四款多样化的棋牌游戏，采用开放式计分系统。

**结果:** 实验结果表明，CATArena能够为智能体核心能力（特别是学习能力和策略编码）提供可靠、稳定和可扩展的基准测试，适用于最小化代码智能体和商业化代码智能体。

**结论:** CATArena平台通过开放式计分和多样化游戏设置，有效解决了现有基准测试的局限性，为评估LLM智能体的学习能力和持续进化提供了系统性的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CATArena%3A+Evaluation+of+LLM+Agents+through+Iterative+Tournament+Competitions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26852，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26852&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Model (LLM) agents have evolved from basic text generation to
autonomously completing complex tasks through interaction with external tools.
However, current benchmarks mainly assess end-to-end performance in fixed
scenarios, restricting evaluation to specific skills and suffering from score
saturation and growing dependence on expert annotation as agent capabilities
improve. In this work, we emphasize the importance of learning ability,
including both self-improvement and peer-learning, as a core driver for agent
evolution toward human-level intelligence. We propose an iterative, competitive
peer-learning framework, which allows agents to refine and optimize their
strategies through repeated interactions and feedback, thereby systematically
evaluating their learning capabilities. To address the score saturation issue
in current benchmarks, we introduce CATArena, a tournament-style evaluation
platform featuring four diverse board and card games with open-ended scoring.
By providing tasks without explicit upper score limits, CATArena enables
continuous and dynamic evaluation of rapidly advancing agent capabilities.
Experimental results and analyses involving both minimal and commercial code
agents demonstrate that CATArena provides reliable, stable, and scalable
benchmarking for core agent abilities, particularly learning ability and
strategy coding.

</details>


### [2] [Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base](https://arxiv.org/abs/2510.26854)
*Yu Li, Yuan Huang, Tao Wang, Caiyu Fan, Xiansheng Cai, Sihan Hu, Xinzijian Liu, Cheng Shi, Mingjun Xu, Zhen Wang, Yan Wang, Xiangqi Jin, Tianhan Zhang, Linfeng Zhang, Lei Wang, Youjin Deng, Pan Zhang, Weijie Sun, Xingyu Li, Weinan E, Linfeng Zhang, Zhiyuan Yao, Kun Chen*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一个可扩展的框架，通过解压缩科学推理过程，构建可验证的长链思维知识库SciencePedia，实现了跨领域的可信科学知识合成。


<details>
  <summary>更多</summary>
  
**动机:** 当前科学材料通常压缩推理过程，只呈现结论而省略推导链，这阻碍了验证并抑制了跨领域概念间的逻辑和因果联系。

**方法:** 采用端点驱动的还原策略：Socratic代理生成约300万个第一原理问题，多个独立求解模型生成长链思维推导，通过提示净化和跨模型答案共识进行严格筛选，构建验证语料库。

**结果:** SciencePedia包含约20万个细粒度条目，在六个学科评估中，基于检索LCoTs的合成文章显示出显著更高的知识点密度和更低的错误率。

**结论:** 这种以推理为中心的方法实现了大规模可信的跨领域科学合成，为不断扩展的百科全书奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inverse+Knowledge+Search+over+Verifiable+Reasoning%3A+Synthesizing+a+Scientific+Encyclopedia+from+a+Long+Chains-of-Thought+Knowledge+Base，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26854&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Most scientific materials compress reasoning, presenting conclusions while
omitting the derivational chains that justify them. This compression hinders
verification by lacking explicit, step-wise justifications and inhibits
cross-domain links by collapsing the very pathways that establish the logical
and causal connections between concepts. We introduce a scalable framework that
decompresses scientific reasoning, constructing a verifiable Long
Chain-of-Thought (LCoT) knowledge base and projecting it into an emergent
encyclopedia, SciencePedia. Our pipeline operationalizes an endpoint-driven,
reductionist strategy: a Socratic agent, guided by a curriculum of around 200
courses, generates approximately 3 million first-principles questions. To
ensure high fidelity, multiple independent solver models generate LCoTs, which
are then rigorously filtered by prompt sanitization and cross-model answer
consensus, retaining only those with verifiable endpoints. This verified corpus
powers the Brainstorm Search Engine, which performs inverse knowledge search --
retrieving diverse, first-principles derivations that culminate in a target
concept. This engine, in turn, feeds the Plato synthesizer, which narrates
these verified chains into coherent articles. The initial SciencePedia
comprises approximately 200,000 fine-grained entries spanning mathematics,
physics, chemistry, biology, engineering, and computation. In evaluations
across six disciplines, Plato-synthesized articles (conditioned on retrieved
LCoTs) exhibit substantially higher knowledge-point density and significantly
lower factual error rates than an equally-prompted baseline without retrieval
(as judged by an external LLM). Built on this verifiable LCoT knowledge base,
this reasoning-centric approach enables trustworthy, cross-domain scientific
synthesis at scale and establishes the foundation for an ever-expanding
encyclopedia.

</details>


### [3] [The Denario project: Deep knowledge AI agents for scientific discovery](https://arxiv.org/abs/2510.26887)
*Francisco Villaescusa-Navarro, Boris Bolliet, Pablo Villanueva-Domingo, Adrian E. Bayer, Aidan Acquah, Chetana Amancharla, Almog Barzilay-Siegal, Pablo Bermejo, Camille Bilodeau, Pablo Cárdenas Ramírez, Miles Cranmer, Urbano L. França, ChangHoon Hahn, Yan-Fei Jiang, Raul Jimenez, Jun-Young Lee, Antonio Lerario, Osman Mamun, Thomas Meier, Anupam A. Ojha, Pavlos Protopapas, Shimanto Roy, David N. Spergel, Pedro Tarancón-Álvarez, Ujjwal Tiwari, Matteo Viel, Digvijay Wadekar, Chi Wang, Bonny Y. Wang, Licong Xu, Yossi Yovel, Shuwen Yue, Wen-Han Zhou, Qiyao Zhu, Jiajun Zou, Íñigo Zubeldia*

**主要类别:** cs.AI

**AI概要:** Denario是一个AI多智能体系统，作为科学研究助手，能够执行从构思到论文撰写的完整科研流程，支持多学科研究并展示了跨学科创新应用。


<details>
  <summary>更多</summary>
  
**动机:** 开发一个能够辅助科学研究全过程的人工智能系统，解决科研工作中从想法生成到论文完成的各个环节自动化需求，提升科研效率并探索跨学科研究的可能性。

**方法:** 采用模块化架构设计，集成Cmbagent作为深度研究后端，支持特定任务处理和端到端科学分析，涵盖文献检索、代码编写、图表生成、论文起草和审阅等功能。

**结果:** 系统成功生成了多个学科领域（天体物理、生物、化学等）的AI论文，展示了跨学科研究能力（如量子物理与机器学习在天体物理数据中的应用），并通过领域专家评估获得数值评分和评审反馈。

**结论:** Denario展示了AI驱动研究的巨大潜力，但存在局限性；讨论了AI科研的伦理影响和科学哲学意义，代码已开源并提供在线演示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Denario+project%3A+Deep+knowledge+AI+agents+for+scientific+discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26887，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26887&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We present Denario, an AI multi-agent system designed to serve as a
scientific research assistant. Denario can perform many different tasks, such
as generating ideas, checking the literature, developing research plans,
writing and executing code, making plots, and drafting and reviewing a
scientific paper. The system has a modular architecture, allowing it to handle
specific tasks, such as generating an idea, or carrying out end-to-end
scientific analysis using Cmbagent as a deep-research backend. In this work, we
describe in detail Denario and its modules, and illustrate its capabilities by
presenting multiple AI-generated papers generated by it in many different
scientific disciplines such as astrophysics, biology, biophysics, biomedical
informatics, chemistry, material science, mathematical physics, medicine,
neuroscience and planetary science. Denario also excels at combining ideas from
different disciplines, and we illustrate this by showing a paper that applies
methods from quantum physics and machine learning to astrophysical data. We
report the evaluations performed on these papers by domain experts, who
provided both numerical scores and review-like feedback. We then highlight the
strengths, weaknesses, and limitations of the current system. Finally, we
discuss the ethical implications of AI-driven research and reflect on how such
technology relates to the philosophy of science. We publicly release the code
at https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run
directly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and
the full app will be deployed on the cloud.

</details>


### [4] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno, Arturo Miguel Bernal Russell, Sofia Nelson, Demetrius Hernandez, Maureen Petterson, Michael Murphy, Walter J. Scheirer, Jane Cleland-Huang*

**主要类别:** cs.AI

**AI概要:** 论文提出认知包络(Cognition Envelopes)概念，用于约束AI模型在物理信息系统中产生的错误决策，通过建立推理边界来补充元认知和传统安全包络。


<details>
  <summary>更多</summary>
  
**动机:** 物理信息系统越来越多地依赖基础模型(如LLMs和VLMs)来增强自主性，但这些模型引入了幻觉、过度泛化和上下文错位等新型错误，导致错误决策。

**方法:** 引入认知包络概念，建立推理边界来约束AI生成的决策，需要制定实用的定义、验证和保证指南与系统化流程。

**结果:** 提出了认知包络的理论框架，但未提供具体的实验结果或验证数据。

**结论:** 认知包络为解决基础模型在物理信息系统中引入的新型错误提供了系统化方法，需要进一步开发实践指南和验证流程来确保其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cognition+Envelopes+for+Bounded+AI+Reasoning+in+Autonomous+UAS+Operations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26905，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26905&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [5] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas, Konstantinos Koutras, Nikitas Rigas Kalogeropoulos, Panagiotis Kechagias, Dimitra Gariza, Athanasios P. Kalogeras, Christos Alexakos*

**主要类别:** cs.AI

**AI概要:** SUSTAINABLE是一个智能农业平台，整合物联网、人工智能、卫星成像和基于角色的任务编排技术，专注于葡萄种植领域的可持续农业实践。


<details>
  <summary>更多</summary>
  
**动机:** 全球农业面临粮食需求增长、气候多变性和可持续实践需求的挑战，需要智能化的农业解决方案。

**方法:** 整合IoT、AI、卫星成像技术，开发基于角色的任务编排系统，特别针对地中海葡萄园进行定制化设计。

**结果:** 提出了一个具有卫星指数集成、实时环境数据和角色感知任务管理功能的智能农业平台。

**结论:** SUSTAINABLE平台展示了通过技术整合实现高效、可追溯和可持续农业的可行性，特别是在葡萄种植领域的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SUSTAINABLE+Platform%3A+Seamless+Smart+Farming+Integration+Towards+Agronomy+Automation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26989，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26989&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [6] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin, Samuel Nathanson*

**主要类别:** cs.AI

**AI概要:** 研究表明，在非顺序数据上使用因果掩码训练的语言模型在棋类游戏中表现优于基于序列数据的模型，挑战了传统观点，为空间数据的单模态LLM训练提供了新思路。


<details>
  <summary>更多</summary>
  
**动机:** 传统语言模型使用因果掩码处理顺序数据，但在具有空间或关系结构的领域，因果掩码被认为不合适。本研究旨在探索在非顺序数据上使用因果掩码是否可行，特别是在同时支持空间和序列表示的棋类领域。

**方法:** 在棋类游戏中训练具有双向和因果自注意力机制的语言模型，分别使用空间（棋盘状态）和序列（走棋顺序）两种数据表示形式进行对比实验。

**结果:** 结果显示，使用空间棋盘状态训练的语言模型（即使使用因果掩码）始终比基于序列数据训练的模型表现出更强的棋力。

**结论:** 在空间数据上应用因果掩码是训练单模态LLM的可行方法，在某些领域甚至优于序列化处理，这一发现具有更广泛的方法论意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Masking+on+Spatial+Data%3A+An+Information-Theoretic+Case+for+Learning+Spatial+Datasets+with+Unimodal+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27009，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27009&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [7] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman, Matthew Trager, Alessandro Achille, Wei Xia, Stefano Soatto*

**主要类别:** cs.AI

**AI概要:** 论文提出了自适应努力控制方法，通过强化学习训练模型根据用户指定的努力参数动态调整推理长度，在保持或提升性能的同时显著减少思维链长度。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI模型缺乏对推理努力程度的细粒度控制，用户需要根据质量、延迟和成本的权衡来动态调整推理资源，但现有方法要求预先知道问题难度来设置token预算。

**方法:** 提出自适应努力控制方法，使用强化学习训练模型根据用户指定的相对努力参数（相对于当前平均思维链长度）来自适应调整推理token使用量。

**结果:** 在1.5B到32B参数规模的模型上，该方法能够将思维链长度减少约3倍，同时保持或提升相对于RL基础模型的性能，提供更好的成本-准确率权衡曲线。

**结论:** 该方法消除了数据集和阶段特定的调优需求，用户可以通过连续的effort参数在推理时动态调整成本-准确率权衡，模型能自动按任务难度比例分配资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是e1%3A+Learning+Adaptive+Control+of+Reasoning+Effort，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27042&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [8] [Adaptive Data Flywheel: Applying MAPE Control Loops to AI Agent Improvement](https://arxiv.org/abs/2510.27051)
*Aaditya Shukla, Sidney Knowles, Meenakshi Madugula, Dave Farris, Ryan Angilly, Santiago Pombo, Anbang Xu, Lu An, Abhinav Balasubramanian, Tan Yu, Jiaxiang Ren, Rama Akkiraju*

**主要类别:** cs.AI

**AI概要:** NVIDIA开发了基于MAPE驱动的数据飞轮系统NVInfo AI，通过分析用户反馈识别RAG管道中的主要错误类型，使用微调方法显著提升了模型性能和响应速度，为企业AI代理提供了可扩展的自改进框架。


<details>
  <summary>更多</summary>
  
**动机:** 企业AI代理需要持续适应以保持准确性、降低延迟并满足用户需求，需要建立一个能够从实际使用中学习并自我改进的系统。

**方法:** 采用MAPE驱动的数据飞轮构建闭环系统，收集495个负面样本分析失败模式，使用NVIDIA NeMo微服务进行针对性微调：用微调的8B模型替代70B路由模型，并对查询重述模型进行优化。

**结果:** 路由错误从5.25%改善到96%准确率，模型大小减少10倍，延迟提升70%；查询重述错误从3.2%改善到准确率提升3.7%，延迟降低40%。

**结论:** 人机回环反馈结合数据飞轮架构可将企业AI代理转变为自改进系统，为构建能够在实际使用中大规模学习的稳健、自适应企业AI代理提供了可重复的蓝图。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Data+Flywheel%3A+Applying+MAPE+Control+Loops+to+AI+Agent+Improvement，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27051，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27051&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Enterprise AI agents must continuously adapt to maintain accuracy, reduce
latency, and remain aligned with user needs. We present a practical
implementation of a data flywheel in NVInfo AI, NVIDIA's Mixture-of-Experts
(MoE) Knowledge Assistant serving over 30,000 employees. By operationalizing a
MAPE-driven data flywheel, we built a closed-loop system that systematically
addresses failures in retrieval-augmented generation (RAG) pipelines and
enables continuous learning. Over a 3-month post-deployment period, we
monitored feedback and collected 495 negative samples. Analysis revealed two
major failure modes: routing errors (5.25\%) and query rephrasal errors
(3.2\%). Using NVIDIA NeMo microservices, we implemented targeted improvements
through fine-tuning. For routing, we replaced a Llama 3.1 70B model with a
fine-tuned 8B variant, achieving 96\% accuracy, a 10x reduction in model size,
and 70\% latency improvement. For query rephrasal, fine-tuning yielded a 3.7\%
gain in accuracy and a 40\% latency reduction. Our approach demonstrates how
human-in-the-loop (HITL) feedback, when structured within a data flywheel,
transforms enterprise AI agents into self-improving systems. Key learnings
include approaches to ensure agent robustness despite limited user feedback,
navigating privacy constraints, and executing staged rollouts in production.
This work offers a repeatable blueprint for building robust, adaptive
enterprise AI agents capable of learning from real-world usage at scale.

</details>


### [9] [CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning](https://arxiv.org/abs/2510.27094)
*Hamed Mahdavi, Pouria Mahdavinia, Alireza Farhadi, Pegah Mohammadipour, Samira Malek, Majid Daliri, Pedram Mohammadipour, Alireza Hashemi, Amir Khasahmadi, Vasant Honavar*

**主要类别:** cs.AI

**AI概要:** 论文研究大型语言模型在数学证明评分方面的能力，开发了自动化评分工作流程来改进部分分数的分配一致性，并在多个数据集上验证了其与人类评分的一致性。


<details>
  <summary>更多</summary>
  
**动机:** 随着SOTA LLMs在解决奥林匹克数学问题上的显著进步，需要评估这些模型在证明评分方面的能力，包括错误检测、严重性判断和公平分数分配，而不仅仅是二元正确性判断。

**方法:** 使用90个Gemini 2.5 Pro生成的解决方案和MathArena的IMO/USAMO 2025解决方案集，采用1-4分和0-7分评分标准；引入基于智能体的工作流程，通过提取和分析参考解决方案来自动生成问题特定的评分标准。

**结果:** 模型能够可靠地标记错误解决方案（包括细微错误），但在部分分数分配上存在校准差距；提出的工作流程在人类评分一致性和部分分数处理一致性方面表现更好。

**结论:** 自动化评分工作流程能够有效提高LLMs在证明评分方面的性能，特别是在部分分数分配的一致性方面，为未来研究提供了代码、数据和提示/日志资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CombiGraph-Vis%3A+A+Curated+Multimodal+Olympiad+Benchmark+for+Discrete+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27094&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [10] [Glia: A Human-Inspired AI for Automated Systems Design and Optimization](https://arxiv.org/abs/2510.27176)
*Pouya Hamadanian, Pantea Karimi, Arash Nasr-Esfahany, Kimia Noorbakhsh, Joseph Chandler, Ali ParandehGheibi, Mohammad Alizadeh, Hari Balakrishnan*

**主要类别:** cs.AI

**AI概要:** Glia是一个基于多智能体LLM架构的AI系统，能够自主设计计算机系统机制，在分布式GPU集群的LLM推理场景中，其设计的请求路由、调度和自动扩展算法达到了人类专家水平，且具有可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 探索AI是否能够像人类专家一样具有创造性和推理能力，自主设计计算机系统机制，超越传统的黑盒优化方法。

**方法:** 使用大型语言模型构建多智能体工作流，每个智能体专门负责推理、实验和分析，通过评估框架将抽象推理与实证反馈相结合，生成可解释的设计方案。

**结果:** 在分布式GPU集群的LLM推理应用中，Glia设计的新算法在性能上达到人类专家水平，且耗时显著减少，同时提供了对工作负载行为的新见解。

**结论:** 通过将推理型LLM与结构化实验相结合，AI能够为复杂系统问题产生创造性且易于理解的设计方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Glia%3A+A+Human-Inspired+AI+for+Automated+Systems+Design+and+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27176&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Can an AI autonomously design mechanisms for computer systems on par with the
creativity and reasoning of human experts? We present Glia, an AI architecture
for networked systems design that uses large language models (LLMs) in a
human-inspired, multi-agent workflow. Each agent specializes in reasoning,
experimentation, and analysis, collaborating through an evaluation framework
that grounds abstract reasoning in empirical feedback. Unlike prior
ML-for-systems methods that optimize black-box policies, Glia generates
interpretable designs and exposes its reasoning process. When applied to a
distributed GPU cluster for LLM inference, it produces new algorithms for
request routing, scheduling, and auto-scaling that perform at human-expert
levels in significantly less time, while yielding novel insights into workload
behavior. Our results suggest that by combining reasoning LLMs with structured
experimentation, an AI can produce creative and understandable designs for
complex systems problems.

</details>


### [11] [From product to system network challenges in system of systems lifecycle management](https://arxiv.org/abs/2510.27194)
*Vahid Salehi, Josef Vilsmeier, Shirui Wang*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一个面向系统之系统（SoS）的现代生命周期管理框架，整合MBSE、PLM和CAD-CAE等技术，通过四个核心原则和三阶段路线图实现从产品中心到网络中心开发的转型。


<details>
  <summary>更多</summary>
  
**动机:** 传统线性生命周期模型在处理网络化系统中的跨学科互操作性、变体配置管理、可追溯性和跨组织治理等方面存在局限，需要新的管理方法。

**方法:** 基于文献综述和行业经验，提出包含四个原则的实践参考框架：引用架构和数据模型、端到端配置主权、有管理的模型审查、可衡量的价值贡献，并制定三阶段实施路线图。

**结果:** 实现了变更鲁棒性提升、吞吐时间缩短、重用性改善和可持续性决策优化等效果。

**结论:** 该框架为决策者和实践者提供了管理复杂性和设计可扩展SoS价值流的有效方法，适用于移动出行、医疗保健和公共部门等领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+product+to+system+network+challenges+in+system+of+systems+lifecycle+management，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27194，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27194&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Today, products are no longer isolated artifacts, but nodes in networked
systems. This means that traditional, linearly conceived life cycle models are
reaching their limits: Interoperability across disciplines, variant and
configuration management, traceability, and governance across organizational
boundaries are becoming key factors. This collective contribution classifies
the state of the art and proposes a practical frame of reference for SoS
lifecycle management, model-based systems engineering (MBSE) as the semantic
backbone, product lifecycle management (PLM) as the governance and
configuration level, CAD-CAE as model-derived domains, and digital thread and
digital twin as continuous feedback. Based on current literature and industry
experience, mobility, healthcare, and the public sector, we identify four
principles: (1) referenced architecture and data models, (2) end-to-end
configuration sovereignty instead of tool silos, (3) curated models with clear
review gates, and (4) measurable value contributions along time, quality, cost,
and sustainability. A three-step roadmap shows the transition from product- to
network- centric development: piloting with reference architecture, scaling
across variant and supply chain spaces, organizational anchoring (roles,
training, compliance). The results are increased change robustness, shorter
throughput times, improved reuse, and informed sustainability decisions. This
article is aimed at decision-makers and practitioners who want to make
complexity manageable and design SoS value streams to be scalable.

</details>


### [12] [Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering](https://arxiv.org/abs/2510.27206)
*Kounianhua Du, Jianxing Liu, Kangning Zhang, Wenxiang Jiao, Yuan Lu, Jiarui Jin, Weiwen Liu, Yong Yu, Weinan Zhang*

**主要类别:** cs.AI

**AI概要:** 提出了一种细粒度的实例定制化引导框架，通过动态生成样本级干扰向量并注入模型前向传播来实现个性化适配，解决了动态用户模式和高数据稀疏性场景下的挑战。


<details>
  <summary>更多</summary>
  
**动机:** 现有参数化适配方法在处理动态用户模式和高数据稀疏性场景时存在适应性差和数据效率低的问题，需要更有效的个性化技术来适应大语言模型的快速发展。

**方法:** 采用细粒度引导组件捕获注意力层和MLP层的细微信号，结合输入感知聚合模块将这些信号合成为上下文相关的增强向量，作为插件组件与现有个性化技术兼容。

**结果:** 在多样化场景（短长文本生成、网络函数调用）的广泛实验中验证了方法的有效性，显著提升了快速变化环境中的个性化性能，同时保持在不同交互模式和上下文长度下的鲁棒性。

**结论:** 该方法具有高度灵活性和数据效率，能够有效应对快速变化的分布和高数据稀疏性场景，且与现有方法正交，可作为兼容不同个性化技术的插件组件。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fints%3A+Efficient+Inference-Time+Personalization+for+LLMs+with+Fine-Grained+Instance-Tailored+Steering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27206，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27206&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The rapid evolution of large language models (LLMs) has intensified the
demand for effective personalization techniques that can adapt model behavior
to individual user preferences. Despite the non-parametric methods utilizing
the in-context learning ability of LLMs, recent parametric adaptation methods,
including personalized parameter-efficient fine-tuning and reward modeling
emerge. However, these methods face limitations in handling dynamic user
patterns and high data sparsity scenarios, due to low adaptability and data
efficiency. To address these challenges, we propose a fine-grained and
instance-tailored steering framework that dynamically generates sample-level
interference vectors from user data and injects them into the model's forward
pass for personalized adaptation. Our approach introduces two key technical
innovations: a fine-grained steering component that captures nuanced signals by
hooking activations from attention and MLP layers, and an input-aware
aggregation module that synthesizes these signals into contextually relevant
enhancements. The method demonstrates high flexibility and data efficiency,
excelling in fast-changing distribution and high data sparsity scenarios. In
addition, the proposed method is orthogonal to existing methods and operates as
a plug-in component compatible with different personalization techniques.
Extensive experiments across diverse scenarios--including short-to-long text
generation, and web function calling--validate the effectiveness and
compatibility of our approach. Results show that our method significantly
enhances personalization performance in fast-shifting environments while
maintaining robustness across varying interaction modes and context lengths.
Implementation is available at https://github.com/KounianhuaDu/Fints.

</details>


### [13] [GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation](https://arxiv.org/abs/2510.27210)
*Tao Liu, Chongyu Wang, Rongjie Li, Yingchen Yu, Xuming He, Bai Song*

**主要类别:** cs.AI

**AI概要:** 提出了GUI-Rise框架，通过结构化推理、动作预测和历史摘要增强MLLM在GUI导航中的跨域泛化能力，在标准基准测试中达到最先进性能


<details>
  <summary>更多</summary>
  
**动机:** 当前多模态大语言模型在GUI导航代理中存在跨域泛化能力不足和历史信息利用效率低的问题

**方法:** 开发了推理增强框架，包含结构化推理链、动作预测和历史摘要组件，通过监督微调伪标注轨迹和GRPO强化学习训练GUI-Rise代理

**结果:** 在相同训练数据条件下实现了最先进的性能表现，在域外场景中表现尤为突出

**结论:** 该框架能够保持强大的推理能力和跨不同GUI导航任务的泛化性能，验证了方法的有效性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUI-Rise%3A+Structured+Reasoning+and+History+Summarization+for+GUI+Navigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27210，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27210&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While Multimodal Large Language Models (MLLMs) have advanced GUI navigation
agents, current approaches face limitations in cross-domain generalization and
effective history utilization. We present a reasoning-enhanced framework that
systematically integrates structured reasoning, action prediction, and history
summarization. The structured reasoning component generates coherent
Chain-of-Thought analyses combining progress estimation and decision reasoning,
which inform both immediate action predictions and compact history summaries
for future steps. Based on this framework, we train a GUI agent,
\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled
trajectories and reinforcement learning with Group Relative Policy Optimization
(GRPO). This framework employs specialized rewards, including a history-aware
objective, directly linking summary quality to subsequent action performance.
Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art
results under identical training data conditions, with particularly strong
performance in out-of-domain scenarios. These findings validate our framework's
ability to maintain robust reasoning and generalization across diverse GUI
navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.

</details>


### [14] [Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines](https://arxiv.org/abs/2510.27329)
*Kristina Levina, Nikolaos Pappas, Athanasios Karapantelakis, Aneta Vulgarakis Feljan, Jendrik Seipp*

**主要类别:** cs.AI

**AI概要:** 本文提出了三种奖励机器(RM)的泛化形式来改进长时域无序子任务的学习效率，并引入了基于耦合RM的新组合学习算法CoRM，实验证明其在处理无序子任务时比现有RM算法更具可扩展性。


<details>
  <summary>更多</summary>
  
**动机:** 传统奖励机器在处理无序子任务的长时域问题时存在局限性，当子任务可以任意顺序执行时，需要学习的信息量会随无序子任务数量呈指数级增长。

**方法:** 提出了三种RM泛化形式：(1)数值RM用紧凑形式表达复杂任务；(2)议程RM用议程跟踪剩余子任务；(3)耦合RM将状态与议程中的每个子任务耦合。并开发了基于耦合RM的组合学习算法CoRM(Q-learning with coupled RMs)。

**结果:** 实验结果表明，CoRM在处理具有无序子任务的长时域问题时，比最先进的RM算法具有更好的可扩展性。

**结论:** 通过引入数值RM、议程RM和耦合RM这三种泛化形式以及CoRM算法，有效解决了传统奖励机器在处理无序子任务长时域问题时的指数级复杂度问题，提升了学习效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+for+Long-Horizon+Unordered+Tasks%3A+From+Boolean+to+Coupled+Reward+Machines，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27329，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27329&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reward machines (RMs) inform reinforcement learning agents about the reward
structure of the environment. This is particularly advantageous for complex
non-Markovian tasks because agents with access to RMs can learn more
efficiently from fewer samples. However, learning with RMs is ill-suited for
long-horizon problems in which a set of subtasks can be executed in any order.
In such cases, the amount of information to learn increases exponentially with
the number of unordered subtasks. In this work, we address this limitation by
introducing three generalisations of RMs: (1) Numeric RMs allow users to
express complex tasks in a compact form. (2) In Agenda RMs, states are
associated with an agenda that tracks the remaining subtasks to complete. (3)
Coupled RMs have coupled states associated with each subtask in the agenda.
Furthermore, we introduce a new compositional learning algorithm that leverages
coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM
scales better than state-of-the-art RM algorithms for long-horizon problems
with unordered subtasks.

</details>


### [15] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar, Wil van der Aalst*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一种基于事件日志区分理想与不理想流程执行的方法，通过可解释的判别规则对流程轨迹进行分组，为每组分别发现流程模型，从而揭示影响流程结果的关键行为模式。


<details>
  <summary>更多</summary>
  
**动机:** 传统流程发现方法不考虑执行结果差异，导致模型无法捕捉关键行为区别，不适合一致性检查和性能分析。现实中存在理想（高效合规）和不理想（低效违规）的流程执行，这为结果导向的流程发现提供了机会。

**方法:** 通过学习控制流特征上的可解释判别规则，将具有相似理想性特征的轨迹分组，然后在每个组内分别应用流程发现技术。

**结果:** 该方法实现了公开可用的工具，并在多个真实事件日志上进行了评估，证明其能够有效隔离和可视化关键流程模式。

**结论:** 该方法能够产生聚焦且可解释的模型，揭示理想和不理想流程执行的驱动因素，为流程改进提供更有针对性的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Discriminative+Rule+Learning+for+Outcome-Guided+Process+Model+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27343，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27343&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [16] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann, Guillaume Pallez*

**主要类别:** cs.AI

**AI概要:** 本论文重新评估了LLM在数学发现中的贡献，通过分析LLM生成的装箱问题启发式算法，发现其虽可读但不具可解释性，并提出了更简单高效的替代算法，强调了对LLM生成内容进行严格验证的必要性。


<details>
  <summary>更多</summary>
  
**动机:** 重新评估LLM在数学发现中的贡献主张，特别是针对之前报道的LLM基于遗传算法为均匀分布和Weibull分布下的在线装箱问题产生新启发式算法的说法

**方法:** 对LLM生成的启发式算法进行详细分析，包括行为分析和可解释性评估，并针对这些特定装箱问题实例设计新的算法类别

**结果:** 发现LLM生成的启发式算法虽然人类可读但对领域专家仍然不透明；提出的新算法更简单、高效、可解释且更具泛化性；证明所考虑的装箱问题实例本身相对简单

**结论:** LLM对此问题的贡献主张存在局限性，基于错误假设；强调在评估LLM生成输出的科学价值时需要严格的验证和情境化分析

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+In-depth+Study+of+LLM+Contributions+to+the+Bin+Packing+Problem，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27353&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [17] [ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use](https://arxiv.org/abs/2510.27363)
*Mengjie Deng, Guanting Dong, Zhicheng Dou*

**主要类别:** cs.AI

**AI概要:** ToolScope是一个多模态大语言模型代理框架，通过全局导航和局部感知的统一，在长视野VQA任务中有效利用外部工具，平均性能提升6.69%。


<details>
  <summary>更多</summary>
  
**动机:** 当前多模态大语言模型在复杂多模态信息处理中，如何灵活高效地利用外部工具进行推理仍是一个未充分探索的挑战。

**方法:** 提出ToolScope框架，包含三个核心组件：全局导航器（战略指导）、代理执行器（集成Search、Code、Perceive工具进行迭代感知）、响应合成器（整合推理过程）。

**结果:** 在VQA 2.0、ScienceQA、MAT-Search和MathVista四个基准测试中表现出强大的泛化能力，平均性能提升高达6.69%。

**结论:** ToolScope通过统一全局规划和局部多模态感知，有效解决了长视野VQA任务中的视觉上下文退化问题，为MLLMs的工具利用提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ToolScope%3A+An+Agentic+Framework+for+Vision-Guided+and+Long-Horizon+Tool+Use，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27363，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27363&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recently, large language models (LLMs) have demonstrated remarkable
problem-solving capabilities by autonomously integrating with external tools
for collaborative reasoning. However, due to the inherently complex and diverse
nature of multimodal information, enabling multimodal large language models
(MLLMs) to flexibly and efficiently utilize external tools during reasoning
remains an underexplored challenge. In this work, we introduce ToolScope, an
agentic framework designed to unify global planning with local multimodal
perception, adopting a specialized Perceive tool to mitigates visual context
degradation in long-horizon VQA task. ToolScope comprises three primary
components: the Global Navigator, the Agentic Executor, and the Response
Synthesizer. The Global Navigator functions as a "telescope", offering
high-level strategic guidance. The Agentic Executor operates iteratively to
augment MLLM with local perception through the integration of external
tools-Search, Code, and Perceive. Finally, the Response Synthesizer
consolidates and organizes the reasoning process into a coherent, user-friendly
output. We evaluate ToolScope on four VQA benchmarks across diverse domains,
including VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong
generalization capabilities, achieving an average performance improvement of up
to +6.69% across all datasets.

</details>


### [18] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang, Mehmet Dogar, Gustav Markkula*

**主要类别:** cs.AI

**AI概要:** 本研究提出一个集成视觉和运动约束的多智能体强化学习框架，用于模拟行人-驾驶员交互行为，在数据有限的情况下优于监督学习方法，并能捕捉个体差异。


<details>
  <summary>更多</summary>
  
**动机:** 现有行人-驾驶员交互模型通常基于规则逻辑、博弈论或黑盒机器学习方法，缺乏灵活性且忽略了感知和运动约束等底层机制。

**方法:** 使用多智能体强化学习框架，集成行人和驾驶员的视觉与运动约束，基于无信号人行横道的真实数据集评估四种模型变体。

**结果:** 同时包含视觉和运动约束的模型表现最佳，运动约束使动作更平滑，视觉约束引入感知不确定性导致更谨慎的行为，在数据有限情况下优于监督学习模型。

**结论:** 带有人的约束的多智能体强化学习是模拟真实道路使用者交互行为的有前景的方法，能够有效处理个体差异和有限数据场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Realistic+pedestrian-driver+interaction+modelling+using+multi-agent+RL+with+human+perceptual-motor+constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27383，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27383&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [19] [Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry](https://arxiv.org/abs/2510.27410)
*Jianwen Sun, Yukang Feng, Yifan Chang, Chuanhao Li, Zizhen Li, Jiaxin Ai, Fanrui Zhang, Yu Dai, Kaipeng Zhang*

**主要类别:** cs.AI

**AI概要:** Nous AI代理通过主动提问解决人机协作中的意图表达鸿沟问题，基于信息论原理设计信息增益作为内在奖励，无需人工标注，在科学图表生成任务中表现出色且具有领域泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 解决人机协作中的"意图表达鸿沟"问题，即人类难以有效向AI传达复杂高维思想，导致低效的试错循环，且不同专业水平的用户面临不同挑战。

**方法:** 提出Socratic协作范式，训练Nous代理主动探询信息以减少对用户意图的不确定性。基于信息论第一原理的训练框架，将对话信息增益定义为内在奖励信号（相当于结构化任务空间中香农熵的减少）。开发自动化模拟管道生成大规模偏好数据集用于科学图表生成任务。

**结果:** 综合实验（包括消融研究、主客观评估和不同用户专业水平测试）证明框架有效性。Nous在效率和输出质量方面领先，对不同用户专业水平保持鲁棒性，且设计具有领域无关性，在图表生成之外也显示出泛化能力。

**结论:** 该工作为解决复杂人机协作中用户意图不确定性提供了一个原则性、可扩展且自适应的范式，基于信息论的奖励设计避免了对外部奖励模型或人工标注的依赖。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dialogue+as+Discovery%3A+Navigating+Human+Intent+Through+Principled+Inquiry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27410，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27410&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** A fundamental bottleneck in human-AI collaboration is the "intention
expression gap," the difficulty for humans to effectively convey complex,
high-dimensional thoughts to AI. This challenge often traps users in
inefficient trial-and-error loops and is exacerbated by the diverse expertise
levels of users. We reframe this problem from passive instruction following to
a Socratic collaboration paradigm, proposing an agent that actively probes for
information to resolve its uncertainty about user intent. we name the proposed
agent Nous, trained to acquire proficiency in this inquiry policy. The core
mechanism of Nous is a training framework grounded in the first principles of
information theory. Within this framework, we define the information gain from
dialogue as an intrinsic reward signal, which is fundamentally equivalent to
the reduction of Shannon entropy over a structured task space. This reward
design enables us to avoid reliance on costly human preference annotations or
external reward models. To validate our framework, we develop an automated
simulation pipeline to generate a large-scale, preference-based dataset for the
challenging task of scientific diagram generation. Comprehensive experiments,
including ablations, subjective and objective evaluations, and tests across
user expertise levels, demonstrate the effectiveness of our proposed framework.
Nous achieves leading efficiency and output quality, while remaining robust to
varying user expertise. Moreover, its design is domain-agnostic, and we show
evidence of generalization beyond diagram generation. Experimental results
prove that our work offers a principled, scalable, and adaptive paradigm for
resolving uncertainty about user intent in complex human-AI collaboration.

</details>


### [20] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang, Wenxiang Jiao, Zhiwei He, Jiahao Xu, Haitao Mi, Dong Yu*

**主要类别:** cs.AI

**AI概要:** DeepCompress是一个新颖框架，通过自适应长度奖励机制动态分类问题难度，对简单问题鼓励短推理路径，对难题鼓励长推理路径，同时提升大推理模型的准确性和效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法使用监督微调或带令牌长度奖励的强化学习虽然能提高效率，但往往以牺牲准确性为代价。大推理模型存在认知效率低下的问题，如对简单问题'过度思考'和对复杂问题'思考不足'。

**方法:** 提出DeepCompress框架，采用自适应长度奖励机制，实时根据模型能力动态将问题分类为'简单'或'困难'。对简单问题鼓励更短更高效的推理，对困难问题鼓励更长更具探索性的思维链。

**结果:** 在具有挑战性的数学基准测试中，DeepCompress始终优于基线方法，在显著提高令牌效率的同时实现了更优的准确性。

**结论:** 该研究表明，通过自适应调整推理链长度的方法可以同时提升大推理模型的准确性和效率，挑战了传统偏好短推理路径的做法，证明长响应可能包含更广泛的正确解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeepCompress%3A+A+Dual+Reward+Strategy+for+Dynamically+Exploring+and+Compressing+Reasoning+Chains，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27419&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [21] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang, Dingxin Hu, Tinghao Yu, Hao Liu, Yiting Liu*

**主要类别:** cs.AI

**AI概要:** GeoFM是一种基于形式语言和符号引擎的几何数据合成方法，能够生成高质量、多样化的几何问题，显著提升多模态大语言模型在几何推理任务上的性能表现。


<details>
  <summary>更多</summary>
  
**动机:** 多模态大语言模型在几何推理任务中面临高质量几何数据稀缺的问题，现有合成方法生成的数据缺乏多样性、噪声多，且与真实几何图表差异较大。

**方法:** 使用形式语言在度量空间中探索条件组合，通过符号引擎确保几何问题的正确性，生成高保真度的几何问题。

**结果:** 实验结果显示，使用GeoFM合成数据训练的模型在MathVista几何问题解决任务上超越GPT-4o模型18.7%，在GeoQA上超越16.5%；在开源模型上分别提升5.7%和2.7%。

**结论:** GeoFM方法有效解决了几何数据合成中的多样性和保真度问题，为多模态大语言模型的几何推理能力提升提供了高质量数据支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GeoFM%3A+Enhancing+Geometric+Reasoning+of+MLLMs+via+Synthetic+Data+Generation+through+Formal+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27448&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [22] [Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance](https://arxiv.org/abs/2510.27544)
*Nikolaus Holzer, William Fishell, Baishakhi Ray, Mark Santolucito*

**主要类别:** cs.AI

**AI概要:** TempoBench是一个新的形式化可验证基准测试，用于系统分析大语言模型的多步推理能力，包含时序轨迹评估和时序因果评估两个维度。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM推理评估方法存在缺陷：临时生成的数据集可能包含偏差且无法验证，而形式化证明系统（如Lean）不适合捕捉基于决策链的现实任务特性，导致在业务代理和代码助手等应用中的性能评估存在差距。

**方法:** 提出TempoBench基准，包含两个评估维度：1）时序轨迹评估（TTE）-测试LLM理解和模拟多步推理系统执行的能力；2）时序因果评估（TCE）-测试LLM进行多步因果推理和从复杂系统中提取因果关系的能力。基准参数化难度以系统分析性能。

**结果:** 实验结果显示，最先进的LLM在TCE-normal上得分65.6%，在TCE-hard上仅得7.5%，表明模型能理解TCE任务但在系统复杂度增加时表现显著下降。

**结论:** TempoBench填补了LLM推理评估的空白，提供了形式化可验证的基准测试方法，揭示了当前LLM在复杂多步推理任务上的局限性，为未来模型改进提供了重要参考。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mechanics+of+Learned+Reasoning+1%3A+TempoBench%2C+A+Benchmark+for+Interpretable+Deconstruction+of+Reasoning+System+Performance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27544，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27544&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) are increasingly excelling and outpacing human
performance on many tasks. However, to improve LLM reasoning, researchers
either rely on ad-hoc generated datasets or formal mathematical proof systems
such as the Lean proof assistant. Whilst ad-hoc generated methods can capture
the decision chains of real-world reasoning processes, they may encode some
inadvertent bias in the space of reasoning they cover; they also cannot be
formally verified. On the other hand, systems like Lean can guarantee
verifiability, but are not well-suited to capture the nature of agentic
decision chain-based tasks. This creates a gap both in performance for
functions such as business agents or code assistants, and in the usefulness of
LLM reasoning benchmarks, whereby these fall short in reasoning structure or
real-world alignment. We introduce TempoBench, the first formally grounded and
verifiable diagnostic benchmark that parametrizes difficulty to systematically
analyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks
to break down reasoning ability. First, temporal trace evaluation (TTE) tests
the ability of an LLM to understand and simulate the execution of a given
multi-step reasoning system. Subsequently, temporal causal evaluation (TCE)
tests an LLM's ability to perform multi-step causal reasoning and to distill
cause-and-effect relations from complex systems. We find that models score
65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art
LLMs clearly understand the TCE task but perform poorly as system complexity
increases. Our code is available at our
\href{https://github.com/nik-hz/tempobench}{GitHub repository}.

</details>


### [23] [SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning](https://arxiv.org/abs/2510.27568)
*Ali Asgarov, Umid Suleymanov, Aadyant Khatri*

**主要类别:** cs.AI

**AI概要:** SIGMA是一个多智能体检索增强框架，通过专业化智能体独立推理、定向搜索和协调机制来提升数学推理能力，在多个挑战性基准测试中显著优于现有系统。


<details>
  <summary>更多</summary>
  
**动机:** 当前检索增强模型存在单视角依赖、搜索策略僵化、多源信息融合困难等问题，无法有效支持复杂的多步骤数学推理。

**方法:** 提出SIGMA框架，通过专业化智能体独立生成假设性段落进行定向检索，利用协调机制整合不同视角的发现，实现上下文敏感且计算高效的知识整合。

**结果:** 在MATH500、AIME和GPQA等基准测试中，SIGMA相比开源和闭源系统取得了7.4%的绝对性能提升。

**结论:** 多智能体按需知识整合方法显著提高了复杂知识密集型问题的推理准确性和效率，为可扩展的复杂问题解决提供了有效途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SIGMA%3A+Search-Augmented+On-Demand+Knowledge+Integration+for+Agentic+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27568，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27568&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Solving mathematical reasoning problems requires not only accurate access to
relevant knowledge but also careful, multi-step thinking. However, current
retrieval-augmented models often rely on a single perspective, follow
inflexible search strategies, and struggle to effectively combine information
from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge
Integration for AGentic Mathematical reAsoning), a unified framework that
orchestrates specialized agents to independently reason, perform targeted
searches, and synthesize findings through a moderator mechanism. Each agent
generates hypothetical passages to optimize retrieval for its analytic
perspective, ensuring knowledge integration is both context-sensitive and
computation-efficient. When evaluated on challenging benchmarks such as
MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms
both open- and closed-source systems, achieving an absolute performance
improvement of 7.4%. Our results demonstrate that multi-agent, on-demand
knowledge integration significantly enhances both reasoning accuracy and
efficiency, offering a scalable approach for complex, knowledge-intensive
problem-solving. We will release the code upon publication.

</details>


### [24] [InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research](https://arxiv.org/abs/2510.27598)
*Yunze Wu, Dayuan Fu, Weiye Si, Zhen Huang, Mohan Jiang, Keyu Li, Shijie Xia, Jie Sun, Tianze Xu, Xiangkun Hu, Pengrui Lu, Xiaojie Cai, Lyumanshan Ye, Wenhong Zhu, Yang Xiao, Pengfei Liu*

**主要类别:** cs.AI

**AI概要:** 论文提出了InnovatorBench基准平台，用于评估AI智能体在LLM研究中的端到端能力，包含20个任务和ResearchGym环境，测试显示前沿模型在代码研究任务中有潜力但在算法任务和长时决策中存在困难


<details>
  <summary>更多</summary>
  
**动机:** 现有基准测试在简化环境中只能评估狭窄技能，需要真实场景下评估AI智能体进行科学发现全过程的能力

**方法:** 开发InnovatorBench基准平台（20个任务）和ResearchGym研究环境，实现轻量级ReAct智能体结合前沿模型进行推理与执行规划

**结果:** 前沿模型在代码驱动研究任务中表现有希望，但在脆弱算法相关任务和长时决策中存在耐心不足、资源管理差、过度依赖模板推理等问题，智能体需要超过11小时才能达到最佳性能

**结论:** InnovatorBench展示了作为下一代基于代码的研究基准的潜力，揭示了当前AI智能体在科学研究自动化方面的局限性和改进方向

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是InnovatorBench%3A+Evaluating+Agents%27+Ability+to+Conduct+Innovative+LLM+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27598，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27598&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** AI agents could accelerate scientific discovery by automating hypothesis
formation, experiment design, coding, execution, and analysis, yet existing
benchmarks probe narrow skills in simplified settings. To address this gap, we
introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end
assessment of agents performing Large Language Model (LLM) research. It
comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss
Design, Reward Design, and Scaffold Construction, which require runnable
artifacts and assessment of correctness, performance, output quality, and
uncertainty. To support agent operation, we develop ResearchGym, a research
environment offering rich action spaces, distributed and long-horizon
execution, asynchronous monitoring, and snapshot saving. We also implement a
lightweight ReAct agent that couples explicit reasoning with executable
planning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.
Our experiments demonstrate that while frontier models show promise in
code-driven research tasks, they struggle with fragile algorithm-related tasks
and long-horizon decision making, such as impatience, poor resource management,
and overreliance on template-based reasoning. Furthermore, agents require over
11 hours to achieve their best performance on InnovatorBench, underscoring the
benchmark's difficulty and showing the potential of InnovatorBench to be the
next generation of code-based research benchmark.

</details>


### [25] [VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation](https://arxiv.org/abs/2510.27617)
*Heng Ping, Arijit Bhattacharjee, Peiyu Zhang, Shixuan Li, Wei Yang, Anzhe Cheng, Xiaole Zhang, Jesse Thomason, Ali Jannesari, Nesreen Ahmed, Paul Bogdan*

**主要类别:** cs.AI

**AI概要:** VeriMoA是一个无需训练的多智能体框架，通过质量引导缓存和多路径生成策略，显著提升HDL代码生成性能，在VerilogEval 2.0和RTLLM 2.0基准测试中Pass@1指标提升15-30%


<details>
  <summary>更多</summary>
  
**动机:** 当前LLM在硬件描述语言生成中存在参数知识有限和领域约束挑战，传统提示工程和微调方法在知识覆盖和训练成本方面有局限，多智能体方法又面临噪声传播和推理空间受限的问题

**方法:** 提出两种协同创新：1) 质量引导缓存机制，维护所有中间HDL输出并进行质量排序选择；2) 多路径生成策略，利用C++和Python作为中间表示，将规范到HDL的转换分解为两阶段过程

**结果:** 在VerilogEval 2.0和RTLLM 2.0基准测试中，VeriMoA在不同LLM骨干网络上实现了15-30%的Pass@1改进，特别是使小模型能够匹配大模型和微调替代方案

**结论:** VeriMoA提供了一个无需训练的高效框架，通过多智能体协作和质量优化机制，有效解决了HDL代码生成的挑战，为自动化RTL设计提供了新的解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VeriMoA%3A+A+Mixture-of-Agents+Framework+for+Spec-to-HDL+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27617，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27617&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Automation of Register Transfer Level (RTL) design can help developers meet
increasing computational demands. Large Language Models (LLMs) show promise for
Hardware Description Language (HDL) generation, but face challenges due to
limited parametric knowledge and domain-specific constraints. While prompt
engineering and fine-tuning have limitations in knowledge coverage and training
costs, multi-agent architectures offer a training-free paradigm to enhance
reasoning through collaborative generation. However, current multi-agent
approaches suffer from two critical deficiencies: susceptibility to noise
propagation and constrained reasoning space exploration. We propose VeriMoA, a
training-free mixture-of-agents (MoA) framework with two synergistic
innovations. First, a quality-guided caching mechanism to maintain all
intermediate HDL outputs and enables quality-based ranking and selection across
the entire generation process, encouraging knowledge accumulation over layers
of reasoning. Second, a multi-path generation strategy that leverages C++ and
Python as intermediate representations, decomposing specification-to-HDL
translation into two-stage processes that exploit LLM fluency in high-resource
languages while promoting solution diversity. Comprehensive experiments on
VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves
15--30% improvements in Pass@1 across diverse LLM backbones, especially
enabling smaller models to match larger models and fine-tuned alternatives
without requiring costly training.

</details>


### [26] [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://arxiv.org/abs/2510.27623)
*Qiusi Zhan, Hyeonjeong Ha, Rui Yang, Sirui Xu, Hanyang Chen, Liang-Yan Gui, Yu-Xiong Wang, Huan Zhang, Heng Ji, Daniel Kang*

**主要类别:** cs.AI

**AI概要:** BEAT是首个针对多模态大语言模型(MLLM)具身智能体的视觉后门攻击框架，利用环境中的物体作为触发器，能够在触发出现时让智能体持续执行攻击者指定的多步策略


<details>
  <summary>更多</summary>
  
**动机:** MLLM驱动的具身智能体开启了新的攻击面——视觉后门攻击，需要研究如何在这种新型系统中可靠地植入视觉触发器

**方法:** BEAT采用两阶段训练方案：先进行监督微调(SFT)，然后引入新颖的对比触发学习(CTL)，通过构建多样化的训练集覆盖不同场景、任务和触发器位置，并使用偏好学习明确锐化决策边界

**结果:** 在各种具身智能体基准测试和MLLM上，BEAT实现了高达80%的攻击成功率，同时保持强大的良性任务性能，并能可靠地泛化到分布外的触发器位置。CTL相比朴素SFT在有限后门数据下将后门激活准确率提升高达39%

**结论:** 这些发现揭示了基于MLLM的具身智能体中存在关键但未被探索的安全风险，强调了在实际部署前需要建立鲁棒防御机制的必要性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Visual+Backdoor+Attacks+on+MLLM+Embodied+Decision+Making+via+Contrastive+Trigger+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27623，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27623&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) have advanced embodied agents by
enabling direct perception, reasoning, and planning task-oriented actions from
visual inputs. However, such vision driven embodied agents open a new attack
surface: visual backdoor attacks, where the agent behaves normally until a
visual trigger appears in the scene, then persistently executes an
attacker-specified multi-step policy. We introduce BEAT, the first framework to
inject such visual backdoors into MLLM-based embodied agents using objects in
the environments as triggers. Unlike textual triggers, object triggers exhibit
wide variation across viewpoints and lighting, making them difficult to implant
reliably. BEAT addresses this challenge by (1) constructing a training set that
spans diverse scenes, tasks, and trigger placements to expose agents to trigger
variability, and (2) introducing a two-stage training scheme that first applies
supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning
(CTL). CTL formulates trigger discrimination as preference learning between
trigger-present and trigger-free inputs, explicitly sharpening the decision
boundaries to ensure precise backdoor activation. Across various embodied agent
benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while
maintaining strong benign task performance, and generalizes reliably to
out-of-distribution trigger placements. Notably, compared to naive SFT, CTL
boosts backdoor activation accuracy up to 39% under limited backdoor data.
These findings expose a critical yet unexplored security risk in MLLM-based
embodied agents, underscoring the need for robust defenses before real-world
deployment.

</details>


### [27] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall, Andrew Clark*

**主要类别:** cs.AI

**AI概要:** 论文提出了Agentic AI的新现实主义定义，强调其作为软件交付机制的本质，指出Agentic AI主要是应用而非基础模型，其成功取决于终端用户验证，且验证工具与传统基础模型评估不同。


<details>
  <summary>更多</summary>
  
**动机:** 针对当前AI代理系统的讨论，作者认为需要重新定义Agentic AI，明确其作为软件交付机制的本质特征，并强调应用验证的重要性。

**方法:** 通过比较分析现有定义，提出新的现实主义定义，并讨论Agentic AI与基础模型的关系，强调验证工具和技术的差异。

**结果:** 提出了Agentic AI作为软件交付机制的新定义，指出在良好验证机制下，基础模型可被更简单、快速、可解释的模型替代。

**结论:** Agentic AI的成功关键在于有效性验证，LLMs只是实现有效性的可能选项之一，而非必需的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Validity+Is+What+You+Need，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27628，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27628&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


### [28] [Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training](https://arxiv.org/abs/2510.27630)
*Dayuan Fu, Yunze Wu, Xiaojie Cai, Lyumanshan Ye, Shijie Xia, Zhen Huang, Weiye Si, Tianze Xu, Jie Sun, Keyu Li, Mohan Jiang, Junfei Wang, Qishuo Hua, Pengrui Lu, Yang Xiao, Pengfei Liu*

**主要类别:** cs.AI

**AI概要:** Apollo是一个集成异步人类指导与动作级数据过滤的采样框架，用于训练LLM代理在长时域、领域专业化任务中，相比传统方法显著提升了训练效果和效率。


<details>
  <summary>更多</summary>
  
**动机:** 当前LLM代理在长时域、领域专业化任务训练中存在两个主要问题：基于行为克隆的方法需要密集人工标注成本过高；基于结果驱动的采样方法因有效轨迹稀少而容易失效。

**方法:** Apollo框架采用异步人类指导方式，允许标注者仅在代理偏离正确轨迹时进行干预，提供先验知识和策略建议，同时使用监督控制过滤次优动作以防止错误传播。

**结果:** 在InnovatorBench上使用GLM-4.5模型的实验显示，Apollo相比未训练基线提升50%以上，相比无人交互训练变体提升28%。

**结论:** Apollo证明了人类在环采样在长时域任务中的关键作用，其轻量级设计能够以更低成本产生有价值轨迹，为领域专业化LLM代理训练提供了可靠有效的数据收集方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interaction+as+Intelligence+Part+II%3A+Asynchronous+Human-Agent+Rollout+for+Long-Horizon+Task+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27630，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27630&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Model (LLM) agents have recently shown strong potential in
domains such as automated coding, deep research, and graphical user interface
manipulation. However, training them to succeed on long-horizon,
domain-specialized tasks remains challenging. Current methods primarily fall
into two categories. The first relies on dense human annotations through
behavior cloning, which is prohibitively expensive for long-horizon tasks that
can take days or months. The second depends on outcome-driven sampling, which
often collapses due to the rarity of valid positive trajectories on
domain-specialized tasks. We introduce Apollo, a sampling framework that
integrates asynchronous human guidance with action-level data filtering.
Instead of requiring annotators to shadow every step, Apollo allows them to
intervene only when the agent drifts from a promising trajectory, by providing
prior knowledge, strategic advice, etc. This lightweight design makes it
possible to sustain interactions for over 30 hours and produces valuable
trajectories at a lower cost. Apollo then applies supervision control to filter
out sub-optimal actions and prevent error propagation. Together, these
components enable reliable and effective data collection in long-horizon
environments. To demonstrate the effectiveness of Apollo, we evaluate it using
InnovatorBench. Our experiments show that when applied to train the GLM-4.5
model on InnovatorBench, Apollo achieves more than a 50% improvement over the
untrained baseline and a 28% improvement over a variant trained without human
interaction. These results highlight the critical role of human-in-the-loop
sampling and the robustness of Apollo's design in handling long-horizon,
domain-specialized tasks.

</details>


### [29] [MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design](https://arxiv.org/abs/2510.27671)
*Wei Zhang, Zekun Guo, Yingce Xia, Peiran Jin, Shufang Xie, Tao Qin, Xiang-Yang Li*

**主要类别:** cs.AI

**AI概要:** MolChord是一个基于结构的药物设计方法，通过结合NatureLM语言模型和扩散编码器来对齐蛋白质和分子表示，并使用DPO优化药物性质，在CrossDocked2020数据集上达到SOTA性能。


<details>
  <summary>更多</summary>
  
**动机:** 解决蛋白质结构表示与分子表示的有效对齐问题，以及确保生成的药物与其药理学性质之间的匹配，这是药物发现中的关键挑战。

**方法:** 整合两种关键技术：(1)使用NatureLM自回归模型统一文本、小分子和蛋白质表示，结合扩散结构编码器；(2)通过整合偏好数据构建属性感知数据集，并使用直接偏好优化(DPO)改进对齐过程。

**结果:** 在CrossDocked2020数据集上的实验结果表明，该方法在关键评估指标上达到了最先进的性能。

**结论:** MolChord展示了作为实用SBDD工具的潜力，能够有效解决蛋白质-分子对齐和药物性质优化的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MolChord%3A+Structure-Sequence+Alignment+for+Protein-Guided+Drug+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27671，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27671&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Structure-based drug design (SBDD), which maps target proteins to candidate
molecular ligands, is a fundamental task in drug discovery. Effectively
aligning protein structural representations with molecular representations, and
ensuring alignment between generated drugs and their pharmacological
properties, remains a critical challenge. To address these challenges, we
propose MolChord, which integrates two key techniques: (1) to align protein and
molecule structures with their textual descriptions and sequential
representations (e.g., FASTA for proteins and SMILES for molecules), we
leverage NatureLM, an autoregressive model unifying text, small molecules, and
proteins, as the molecule generator, alongside a diffusion-based structure
encoder; and (2) to guide molecules toward desired properties, we curate a
property-aware dataset by integrating preference data and refine the alignment
process using Direct Preference Optimization (DPO). Experimental results on
CrossDocked2020 demonstrate that our approach achieves state-of-the-art
performance on key evaluation metrics, highlighting its potential as a
practical tool for SBDD.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [30] [Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling](https://arxiv.org/abs/2510.26912)
*Hyunji Lee, Wenhao Yu, Hongming Zhang, Kaixin Ma, Jiyeon Kim, Dong Yu, Minjoon Seo*

**主要类别:** cs.CL

**AI概要:** 该论文分析了结合状态空间模型和注意力机制的混合架构，发现序列混合在短上下文表现更好，并行混合在长上下文更有效，并提出基于释义数据增强的持续训练方法来提升召回能力。


<details>
  <summary>更多</summary>
  
**动机:** 虽然结合状态空间模型和注意力机制的混合模型表现出色，但其架构设计选择仍缺乏深入理解，需要分析不同集成方式的内存利用和性能表现。

**方法:** 通过分析序列和并行两种SSM与注意力的集成方式，并引入基于释义数据增强的持续训练方法来提升模型性能。

**结果:** 发现序列混合在短上下文表现更优，并行混合在长上下文更有效；数据增强的持续训练方法能显著提升召回能力且泛化性好。

**结论:** 研究提供了对混合SSM-注意力模型的深入理解，并为针对不同用例设计架构提供了实用指导，数据增强方法比架构修改更有效地提升召回能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+and+Enhancing+Mamba-Transformer+Hybrids+for+Memory+Recall+and+Language+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26912&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Hybrid models that combine state space models (SSMs) with attention
mechanisms have shown strong performance by leveraging the efficiency of SSMs
and the high recall ability of attention. However, the architectural design
choices behind these hybrid models remain insufficiently understood. In this
work, we analyze hybrid architectures through the lens of memory utilization
and overall performance, and propose a complementary method to further enhance
their effectiveness. We first examine the distinction between sequential and
parallel integration of SSM and attention layers. Our analysis reveals several
interesting findings, including that sequential hybrids perform better on
shorter contexts, whereas parallel hybrids are more effective for longer
contexts. We also introduce a data-centric approach of continually training on
datasets augmented with paraphrases, which further enhances recall while
preserving other capabilities. It generalizes well across different base models
and outperforms architectural modifications aimed at enhancing recall. Our
findings provide a deeper understanding of hybrid SSM-attention models and
offer practical guidance for designing architectures tailored to various use
cases. Our findings provide a deeper understanding of hybrid SSM-attention
models and offer practical guidance for designing architectures tailored to
various use cases.

</details>


### [31] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra, Arthur Lorenzi, Laís Berno, Franciany Campos, Karoline Biscardi, Kenneth Brown, Marcelo Viridiano, Frederico Belcavello, Ely Matos, Olívia Guaranha, Erik Santos, Sofia Reinach, Tiago Timponi Torrent*

**主要类别:** cs.CL

**AI概要:** 提出一种基于语义框架的医疗事件识别方法，用于从电子病历中检测基于性别的暴力事件报告，在2100万句葡萄牙语语料上达到72.6%的精确度。


<details>
  <summary>更多</summary>
  
**动机:** 解决医疗领域中基于性别的暴力事件漏报问题，特别是在初级医疗单位的电子病历记录中。

**方法:** 利用语义框架定义细粒度模式，在非结构化数据（电子病历的开放文本字段）中进行搜索，定义了8个模式并在巴西葡萄牙语的e-SUS APS语料库中进行验证。

**结果:** 方法有效识别暴力事件报告，精确度达到0.726，证实了方法的鲁棒性。

**结论:** 该方法设计为透明、高效、低碳且语言无关的流程，可轻松适应其他健康监测场景，有助于在公共卫生系统中更广泛、道德和可解释地使用NLP技术。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Frame+Semantic+Patterns+for+Identifying+Underreporting+of+Notifiable+Events+in+Healthcare%3A+The+Case+of+Gender-Based+Violence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26969，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26969&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [32] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil, Asma Ben Abacha, Jerome Tremblay, Phillip Swazinna, Akila Jeeson Daniel, Miguel Del-Agua, Francois Beaulieu*

**主要类别:** cs.CL

**AI概要:** MEDIQA-OE 2025是首个从医患对话中提取医疗指令的共享任务挑战，旨在将对话转换为电子健康记录中的可执行医疗指令，以减轻临床医生的文档负担。


<details>
  <summary>更多</summary>
  
**动机:** 临床文档自动化虽然使用语音识别和摘要技术，但将对话转换为电子健康记录中的可执行医疗指令仍是未探索领域，这一问题的解决能显著减轻临床医生文档负担并直接影响患者护理。

**方法:** 组织MEDIQA-OE 2025共享任务，邀请6个团队参与，采用包括闭源和开源大语言模型在内的多种方法进行实验。

**结果:** 成功举办了首个医疗指令提取挑战赛，获得了6个团队的参与，探索了多种技术方案。

**结论:** 该共享任务为从医患对话中提取医疗指令这一重要但未充分研究的领域提供了首个基准和解决方案探索，对改善临床文档工作流程具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Overview+of+the+MEDIQA-OE+2025+Shared+Task+on+Medical+Order+Extraction+from+Doctor-Patient+Consultations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.26974，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.26974&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [33] [Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services](https://arxiv.org/abs/2510.27016)
*Jayden Serenari, Stephen Lee*

**主要类别:** cs.CL

**AI概要:** LOPSIDED框架是一种语义感知的隐私保护系统，通过动态替换用户提示中的敏感PII为语义一致的假名，在保护隐私的同时保持对话上下文完整性，相比基线技术将语义效用错误减少了5倍。


<details>
  <summary>更多</summary>
  
**动机:** 随着对话AI系统的广泛使用，用户在与大语言模型交互时可能分享敏感个人信息，存在隐私泄露风险，可能导致安全漏洞或身份盗窃。

**方法:** 提出LOPSIDED框架，动态替换敏感PII实体为语义一致的假名，保持对话上下文完整性，生成响应后自动进行假名还原。使用ShareGPT的真实对话数据进行评估和标注。

**结果:** LOPSIDED相比基线技术将语义效用错误减少了5倍，同时增强了隐私保护。

**结论:** LOPSIDED框架有效解决了LLM使用中的隐私保护问题，在保持对话质量的同时显著提升了隐私安全性，为对话AI系统的隐私保护提供了实用解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semantically-Aware+LLM+Agent+to+Enhance+Privacy+in+Conversational+AI+Services，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27016，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27016&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** With the increasing use of conversational AI systems, there is growing
concern over privacy leaks, especially when users share sensitive personal data
in interactions with Large Language Models (LLMs). Conversations shared with
these models may contain Personally Identifiable Information (PII), which, if
exposed, could lead to security breaches or identity theft. To address this
challenge, we present the Local Optimizations for Pseudonymization with
Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a
semantically-aware privacy agent designed to safeguard sensitive PII data when
using remote LLMs. Unlike prior work that often degrade response quality, our
approach dynamically replaces sensitive PII entities in user prompts with
semantically consistent pseudonyms, preserving the contextual integrity of
conversations. Once the model generates its response, the pseudonyms are
automatically depseudonymized, ensuring the user receives an accurate,
privacy-preserving output. We evaluate our approach using real-world
conversations sourced from ShareGPT, which we further augment and annotate to
assess whether named entities are contextually relevant to the model's
response. Our results show that LOPSIDED reduces semantic utility errors by a
factor of 5 compared to baseline techniques, all while enhancing privacy.

</details>


### [34] [Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral](https://arxiv.org/abs/2510.27017)
*Ayoub Hammal, Pierre Zweigenbaum, Caio Corro*

**主要类别:** cs.CL

**AI概要:** 本文提出了一种基于代理的测试时对齐方法，使用小型对齐模型来指导大型语言模型，通过令牌级联和0-1背包问题优化，既提高了任务性能又加速了推理速度。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在预训练后仍需对齐以适应下游任务，但随着模型规模扩大，对齐过程的计算成本急剧增加，需要寻找更高效的对齐方法。

**方法:** 采用代理模型进行测试时对齐，提出令牌级联方法，将令牌特定的延迟决策简化为0-1背包问题，并推导出最优延迟决策的原始和对偶近似解。

**结果:** 实验证明该方法在任务性能和推测解码速度方面都有显著提升。

**结论:** 该方法有效降低了大型语言模型对齐的计算成本，同时保持了性能，为大规模模型的高效对齐提供了可行方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Kad%3A+A+Framework+for+Proxy-based+Test-time+Alignment+with+Knapsack+Approximation+Deferral，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27017&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Several previous works concluded that the largest part of generation
capabilities of large language models (LLM) are learned (early) during
pre-training. However, LLMs still require further alignment to adhere to
downstream task requirements and stylistic preferences, among other desired
properties. As LLMs continue to scale in terms of size, the computational cost
of alignment procedures increase prohibitively. In this work, we propose a
novel approach to circumvent these costs via proxy-based test-time alignment,
i.e. using guidance from a small aligned model. Our approach can be described
as token-specific cascading method, where the token-specific deferral rule is
reduced to 0-1 knapsack problem. In this setting, we derive primal and dual
approximations of the optimal deferral decision. We experimentally show the
benefits of our method both in task performance and speculative decoding speed.

</details>


### [35] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

**主要类别:** cs.CL

**AI概要:** ELM是一种新型神经架构搜索方法，专门针对紧凑语言模型优化，通过引入灵活搜索空间和动态模块调整，结合新颖的知识蒸馏损失，在语言建模任务中显著超越现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 大型预训练语言模型在自然语言理解任务中计算和内存需求巨大，带来了经济和环境方面的担忧，需要开发更紧凑高效的模型。

**方法:** 提出弹性语言模型(ELM)，扩展现有NAS方法，引入包含高效transformer块和动态维度/头数调整模块的灵活搜索空间，以及保持各块独特特征的知识蒸馏损失。

**结果:** 在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。

**结论:** ELM通过创新的架构搜索和知识蒸馏技术，有效解决了大型语言模型的计算和内存效率问题，为开发紧凑高效的语言模型提供了有效途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Elastic+Architecture+Search+for+Efficient+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27037&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [36] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad, Shamsuddeen Muhammad Hassan, Isa Inuwa-Dutse*

**主要类别:** cs.CL

**AI概要:** 本研究创建了首个豪萨语性别歧视检测数据集，通过社区参与和定性编码开发，并探索了传统机器学习与多语言预训练模型在豪萨语性别歧视检测中的效果，发现文化细微差别和习语表达带来挑战。


<details>
  <summary>更多</summary>
  
**动机:** 在线平台助长了各种形式的性别歧视，但现有计算检测方法主要集中在高资源语言，低资源语言如豪萨语由于语言资源有限和文化差异，性别歧视检测进展缓慢。

**方法:** 通过两阶段用户研究（n=66）让母语者参与定义和表达性别歧视，创建豪萨语数据集；使用传统机器学习分类器和预训练多语言模型进行实验，评估少样本学习效果。

**结果:** 研究发现捕捉文化细微差别存在挑战，特别是在寻求澄清和习语表达方面，这些情况下容易出现许多误报。

**结论:** 豪萨语性别歧视检测需要特别关注文化语境和语言表达特点，现有计算方法在处理低资源语言的性别歧视表达时仍需改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dataset+Creation+and+Baseline+Models+for+Sexism+Detection+in+Hausa，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27038，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27038&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [37] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

**主要类别:** cs.CL

**AI概要:** 本文提供了定量互文性研究的路线图，总结了该领域的数据、方法和应用，涵盖从统计学到深度学习的多种方法，并展望了在AI与人文学科交叉研究中的更广泛应用前景。


<details>
  <summary>更多</summary>
  
**动机:** 随着自然语言处理技术的发展，互文性研究进入定量时代，需要系统总结大规模互文性研究的数据、方法和应用现状。

**方法:** 基于多语言和多主题数据，综述从统计方法到深度学习的各种技术方法，并总结相关平台工具。

**结果:** 总结了定量互文性研究的最新进展和方法体系，展示了该领域在人文社科研究中的具体应用。

**结论:** 计算机技术的进步将推动更精确、多样化和大规模的互文性研究，互文性在AI与人文学科的跨学科研究中具有广阔的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantitative+Intertextuality+from+the+Digital+Humanities+Perspective%3A+A+Survey，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27045，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27045&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [38] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom, Andrea Silvi, Jennifer Culbertson, Moa Johansson, Devdatt Dubhashi, Kenny Smith*

**主要类别:** cs.CL

**AI概要:** 该论文提出基于最小描述长度(MDL)的新方法来评估递归数字系统的最优性，强调规律性在语言复杂性中的核心作用，解决了先前研究中需要人为约束来排除非自然系统的问题。


<details>
  <summary>更多</summary>
  
**动机:** 先前研究认为递归数字系统在词典大小和平均形态句法复杂性之间达到最优权衡，但需要人为约束来排除非自然系统，这表明现有方法存在不足。

**方法:** 采用最小描述长度(MDL)方法，提出基于规律性和处理复杂性的新衡量标准，重新评估递归数字系统的最优性。

**结果:** MDL方法能更好地区分自然存在的系统与可能但未出现的系统(包括先前研究中的"最优"系统)，且先前文献中的人为约束可以从规律性中自然推导出来。

**结论:** 研究强调了在语言最优性研究中需要纳入形式集合的规律性，MDL方法为理解语言系统的效率和最优性提供了更全面的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Recursive+numeral+systems+are+highly+regular+and+easy+to+process，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27049，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27049&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [39] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis, Andrew Perrault, Eric Fosler-Lussier, Michael White*

**主要类别:** cs.CL

**AI概要:** VISTA是一个评估对话系统事实性的新框架，通过声明级验证和序列一致性追踪来检测多轮对话中的幻觉问题，相比现有方法在多个基准测试中表现更优。


<details>
  <summary>更多</summary>
  
**动机:** 现有评估指标要么评估孤立响应，要么将不可验证内容视为错误，限制了在多轮对话中的应用。幻觉问题阻碍了对话AI系统在需要事实可靠性的场景中的部署。

**方法:** VISTA框架将每个助手回复分解为原子事实声明，根据可信来源和对话历史进行验证，并将不可验证语句分类为主观、矛盾、缺乏证据或弃权等类别。

**结果:** 在8个大语言模型和4个对话事实性基准测试中，VISTA在幻觉检测方面显著优于FACTSCORE和LLM-as-Judge基线方法。人类评估证实VISTA的分解方法提高了标注者一致性。

**结论:** 通过将事实性建模为对话的动态属性，VISTA提供了一个更透明、更符合人类认知的对话系统真实性衡量标准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VISTA+Score%3A+Verification+In+Sequential+Turn-based+Assessment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27052，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27052&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [40] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo, Yaxuan Luan, Yue Kang, Xiangchen Song, Jinxu Guo*

**主要类别:** cs.CL

**AI概要:** 提出一种结合多粒度记忆索引和不确定性估计的置信度控制方法，解决复杂知识环境下检索增强生成的覆盖率不足、结果不稳定和可靠性有限的问题。


<details>
  <summary>更多</summary>
  
**动机:** 解决检索增强生成在复杂知识环境中存在的覆盖率不足、结果不稳定和可靠性有限的问题。

**方法:** 构建分层记忆结构，将知识表示分为不同粒度级别，实现从局部细节到全局上下文的动态索引检索；引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径；整体优化目标包括生成损失、熵约束和方差正则化。

**结果:** 在QA准确性、检索召回率、排序质量和事实一致性方面优于现有模型，证明了多粒度索引与置信度控制结合的有效性。

**结论:** 该方法为检索增强生成提供了新的技术路径，并为提高大模型在复杂环境中的可靠性和可控性提供了实践证据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Centric+RAG+with+Multi-Granular+Indexing+and+Confidence+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27054&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [41] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski, Meriem Boubdir, Klaudia Bałazy, Besmira Nushi, Pablo Ribalta*

**主要类别:** cs.CL

**AI概要:** CoDeC是一种通过上下文学习检测大语言模型训练数据污染的方法，能够准确区分训练数据记忆和未见数据，提供可解释的污染分数。


<details>
  <summary>更多</summary>
  
**动机:** 需要检测和量化大语言模型中训练数据污染的问题，特别是对于训练语料未公开的开源模型，存在数据记忆和污染的风险。

**方法:** 通过测量上下文学习对模型性能的影响来检测污染：上下文示例通常能提升未见数据集的置信度，但对于训练数据会因记忆模式被破坏而降低置信度。

**结果:** 实验显示CoDeC能产生可解释的污染分数，清晰区分已见和未见数据集，并在未公开训练语料的开源模型中发现了强记忆证据。

**结论:** CoDeC是一种简单、自动化、模型和数据集无关的实用方法，易于与基准评估集成，能有效检测训练数据污染。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+Data+Contamination+in+LLMs+via+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27055，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27055&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [42] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng, Huajun Zhang, Xu Yan, Ran Hao, Chong Peng*

**主要类别:** cs.CL

**AI概要:** 提出了一种结合对比蒸馏和噪声鲁棒训练的微调方法，通过冻结骨干模型并引入噪声扰动和鲁棒优化约束，显著提升大语言模型的安全对齐能力和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 解决大语言模型在安全对齐和鲁棒性方面的局限性，现有方法在噪声和不确定输入下表现不稳定，需要提升模型的语义一致性和对齐精度。

**方法:** 采用对比蒸馏技术将教师模型的知识边界传递给学生模型，同时引入噪声扰动和鲁棒优化约束。整体框架包含蒸馏损失、鲁棒性损失和正则化项，形成统一的优化目标。

**结果:** 在知识迁移、鲁棒性和整体安全性方面显著优于现有基线方法，在多个关键指标上达到最佳性能。

**结论:** 该方法不仅丰富了参数高效微调的理论体系，还为构建更安全、更可信的对齐机制提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Contrastive+Knowledge+Transfer+and+Robust+Optimization+for+Secure+Alignment+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27077，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27077&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [43] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz, Sharon Levy*

**主要类别:** cs.CL

**AI概要:** 研究发现LLM安全护栏存在选择性拒绝偏见，对不同人口群体（性别、性取向、国籍、宗教）的拒绝率存在差异，导致安全性能不均衡，需要通过间接攻击测试来揭示这些偏见。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型的安全护栏旨在防止恶意用户大规模生成有害内容，但这些措施可能无意中引入或反映新的偏见，导致模型对某些人口群体拒绝生成有害内容而对其他群体不拒绝。

**方法:** 通过分析针对个体和交叉人口群体的拒绝率、LLM响应类型以及生成拒绝内容的长度，来探索选择性拒绝偏见，并通过间接攻击测试来调查额外的安全隐患。

**结果:** 研究结果显示在性别、性取向、国籍和宗教属性方面存在选择性拒绝偏见的证据，表明安全护栏在不同人口群体间的性能不平等。

**结论:** 研究强调需要在所有人口群体中实现更公平和鲁棒的安全护栏性能，以防止选择性偏见带来的安全隐患。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Characterizing+Selective+Refusal+Bias+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27087，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27087&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [44] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar, Julia Hockenmaier*

**主要类别:** cs.CL

**AI概要:** 研究发现大语言模型作为评估工具时存在评分不一致性问题，不同运行中给出的分数差异较大，影响了评估的可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 随着自然语言生成技术的广泛应用，传统评估指标与人类偏好存在差距，虽然大语言模型评估更接近人类判断，但其评分一致性值得研究。

**方法:** 通过实验量化分析大语言模型在不同NLG任务和基准测试中的评分不一致性，研究其在不同运行中的评分可靠性。

**结果:** LLM评估者在不同运行中表现出较低的内部评分者信度，评分存在显著方差，在某些情况下几乎显得随意。

**结论:** 尽管LLM评估存在不一致性问题，但在遵循适当指导原则的情况下，谨慎使用LLM评估仍然可能是有用的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rating+Roulette%3A+Self-Inconsistency+in+LLM-As-A-Judge+Frameworks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27106，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27106&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [45] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang, Anej Svete, Jiaoda Li, Anthony Widjaja Lin, Jonathan Rawski, Ryan Cotterell, David Chiang*

**主要类别:** cs.CL

**AI概要:** 该论文分析了Transformer语言模型在概率生成模式下的表达能力，发现自回归和概率化特性会改变其表达能力，相比传统的语言识别器有重要差异。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究主要将Transformer视为语言识别器（接受或拒绝字符串），但实际应用中Transformer是作为语言模型（自回归概率生成字符串）使用的，需要研究其在这种使用场景下的表达能力。

**方法:** 通过理论分析，研究Transformer语言模型能够表达的概率分布特性，比较自回归和概率化对表达能力的影响。

**结果:** 研究发现：1）使Transformer语言识别器变为自回归有时能增强表达能力；2）概率化会破坏非概率情况下的等价关系；3）揭示了Transformer在语言模型使用场景下的表达能力边界。

**结论:** 论文系统分析了Transformer在语言模型使用模式下的表达能力，强调了自回归和概率化对模型表达能力的重要影响，为理解Transformer在实际应用中的能力提供了理论支撑。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probability+Distributions+Computed+by+Hard-Attention+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27118，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27118&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [46] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton, York Hay Ng, Aditya Khan, Phuong Hanh Hoang, Xiang Lu, A. Seza Doğruöz, En-Shiun Annie Lee*

**主要类别:** cs.CL

**AI概要:** URIEL+语言知识库通过扩展脚本向量、整合Glottolog语言数据和改进谱系插补方法，显著减少了数据稀疏性问题，提升了多语言研究的覆盖范围和跨语言迁移性能。


<details>
  <summary>更多</summary>
  
**动机:** URIEL+语言知识库存在数据稀疏问题，包括缺失特征类型、不完整的语言条目和有限的谱系覆盖，这限制了其在跨语言迁移（特别是低资源语言支持）中的实用性。

**方法:** 1. 为7,488种语言引入脚本向量来表示书写系统属性
2. 整合Glottolog数据库，新增18,710种语言
3. 扩展谱系插补方法，为26,449种语言传播类型学和脚本特征

**结果:** 脚本向量特征稀疏性减少14%，语言覆盖范围增加最多19,015种语言（增长1,007%），插补质量指标提升最多33%。在跨语言迁移任务中，某些设置下性能提升达6%。

**结论:** 这些扩展使URIEL+在多语言研究中更加完整和包容，为低资源语言的跨语言迁移提供了更好的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Simple+Additions%2C+Substantial+Gains%3A+Expanding+Scripts%2C+Languages%2C+and+Lineage+Coverage+in+URIEL%2B，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27183，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27183&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [47] [MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models](https://arxiv.org/abs/2510.27196)
*Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Yayue Deng, Jing Ma*

**主要类别:** cs.CL

**AI概要:** MemeArena是一个基于代理的竞技场式评估框架，用于评估多模态大语言模型在理解多模态有害内容方面的能力，通过模拟多样化解释情境和整合不同观点来减少评估偏见。


<details>
  <summary>更多</summary>
  
**动机:** 现有评估方法主要关注二元分类任务的检测准确率，无法反映多模态有害内容在不同情境下的深度解释细微差别，需要更全面和公正的评估框架。

**方法:** 提出MemeArena框架，通过模拟多样化解释情境来制定评估任务，激发模型提供针对特定视角的分析，并通过整合不同观点和达成评估者共识来实现公平比较。

**结果:** 大量实验表明，该框架有效减少了评估代理的偏见，判断结果与人类偏好高度一致，为多模态有害内容理解提供了可靠全面的评估见解。

**结论:** MemeArena提供了一个上下文感知且无偏见的评估框架，能够公平比较多模态大语言模型在解释多模态有害内容方面的能力，代码和数据已公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MemeArena%3A+Automating+Context-Aware+Unbiased+Evaluation+of+Harmfulness+Understanding+for+Multimodal+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27196，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27196&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The proliferation of memes on social media necessitates the capabilities of
multimodal Large Language Models (mLLMs) to effectively understand multimodal
harmfulness. Existing evaluation approaches predominantly focus on mLLMs'
detection accuracy for binary classification tasks, which often fail to reflect
the in-depth interpretive nuance of harmfulness across diverse contexts. In
this paper, we propose MemeArena, an agent-based arena-style evaluation
framework that provides a context-aware and unbiased assessment for mLLMs'
understanding of multimodal harmfulness. Specifically, MemeArena simulates
diverse interpretive contexts to formulate evaluation tasks that elicit
perspective-specific analyses from mLLMs. By integrating varied viewpoints and
reaching consensus among evaluators, it enables fair and unbiased comparisons
of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments
demonstrate that our framework effectively reduces the evaluation biases of
judge agents, with judgment results closely aligning with human preferences,
offering valuable insights into reliable and comprehensive mLLM evaluations in
multimodal harmfulness understanding. Our code and data are publicly available
at https://github.com/Lbotirx/MemeArena.

</details>


### [48] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou, Yu Wang, Yang Xu, Hendrik Buschmeier*

**主要类别:** cs.CL

**AI概要:** 本文提出AutoPeriod of Surprisal (APS)方法，发现自然语言信息编码中存在显著的周期性模式，这些周期不仅包含典型文本结构单元，还包括更长距离的驱动因素。


<details>
  <summary>更多</summary>
  
**动机:** 探索自然语言在编码信息中展现周期性模式的程度，以理解语言信息结构的深层规律。

**方法:** 采用AutoPeriod of Surprisal (APS)方法，使用规范周期性检测算法分析单个文档的惊奇值序列，识别显著周期模式。

**结果:** 发现相当比例的人类语言具有信息周期性；识别出超出典型文本结构单元分布的新周期，并通过谐波回归模型验证。

**结论:** 语言信息的周期性是结构化因素和更长距离驱动因素共同作用的结果，该方法在LLM生成检测中具有潜在应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Identifying+the+Periodicity+of+Information+in+Natural+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27241，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27241&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [49] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli, Alireza Salemi, Carrie Ye, Mohamed Abdalla, Hamed Zamani, J Ross Mitchell*

**主要类别:** cs.CL

**AI概要:** 本文提出了BEAM基准测试和LIGHT框架，用于评估和提升大语言模型在长对话记忆任务中的表现。BEAM包含100个长对话和2000个问题，LIGHT框架则通过三种记忆系统显著提升模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有基准测试在评估大语言模型的长时记忆能力方面存在不足，缺乏叙事连贯性、领域狭窄且只测试简单的回忆任务，需要更全面的评估方案。

**方法:** 1) 开发自动生成长对话的框架，构建BEAM基准测试；2) 提出LIGHT框架，包含长期情景记忆、短期工作记忆和事实积累便签三种记忆系统；3) 在BEAM上进行实验验证。

**结果:** 实验显示，即使具有100万token上下文窗口的LLM在长对话中也表现不佳，而LIGHT框架相比最强基线平均提升3.5%-12.69%的性能，消融研究证实了各记忆组件的贡献。

**结论:** LIGHT框架通过模拟人类认知的多重记忆系统，有效提升了LLM在长对话记忆任务中的表现，为解决长上下文推理问题提供了有效方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+a+Million+Tokens%3A+Benchmarking+and+Enhancing+Long-Term+Memory+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27246，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27246&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [50] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal, Aarush Gupta*

**主要类别:** cs.CL

**AI概要:** LLINK是一种计算高效的语言注入方法，通过将多语言编码器的句子嵌入对齐到解码器的潜在空间，改善低资源非拉丁脚本语言在指令调优大语言模型中的表现，无需修改分词器或重新训练解码器。


<details>
  <summary>更多</summary>
  
**动机:** 指令调优的大语言模型在低资源非拉丁脚本语言上表现不佳，主要由于分词器碎片化和跨语言耦合能力弱。

**方法:** 1. 通过轻量级对比投影器将冻结多语言编码器的句子嵌入对齐到解码器保留位置的潜在嵌入空间；2. 将向量扩展为K个软槽，通过最小适配器训练使冻结解码器能够处理信号。

**结果:** LLINK显著改善了双语检索性能，在LLM评判的问答评估中获得81.3%优于基础模型的偏好度和63.6%优于直接微调的偏好度。减少了分词膨胀并增强了跨语言对齐。

**结论:** 将低资源语言视为模态提供了一种实用的轻量级LLM跨语言对齐路径，尽管模型在数值保真度方面仍存在残余弱点。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Languages+are+Modalities%3A+Cross-Lingual+Alignment+via+Encoder+Injection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27254，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27254&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [51] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao, Jinru Ding, Jiayuan Chen, Mouxiao Bian, Ruiyao Chen, Xinwei Peng, Sijie Ren, Linyang Li, Jie Xu*

**主要类别:** cs.CL

**AI概要:** MedCalc-Eval是最大的医学计算能力评估基准，包含700多个任务，涵盖方程计算和规则评分系统。通过MedCalc-Env强化学习环境微调模型，在数值敏感性、公式选择和推理鲁棒性方面取得最先进结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有医学LLM基准主要关注问答和描述性推理，忽视了临床决策中关键的定量推理能力，且现有数据集覆盖计算任务少，无法反映真实临床计算场景。

**方法:** 创建MedCalc-Eval基准数据集（700+任务，分方程计算和规则评分系统两类）；开发MedCalc-Env强化学习环境（基于InternBootcamp框架）；使用该环境对Qwen2.5-32B模型进行微调。

**结果:** 微调后的模型在MedCalc-Eval上达到最先进性能，在数值敏感性、公式选择和推理鲁棒性方面有显著提升。

**结论:** MedCalc-Eval为医学计算能力评估提供了全面基准，MedCalc-Env环境有效提升了模型性能，但单位转换、多条件逻辑和上下文理解仍是待解决的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MedCalc-Eval+and+MedCalc-Env%3A+Advancing+Medical+Calculation+Capabilities+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27267，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27267&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [52] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang, Seonjeong Hwang, Daehui Kim, Hyounghun Kim, Gary Geunbae Lee*

**主要类别:** cs.CL

**AI概要:** 本文发现多语言推理差距主要源于语言理解失败，提出选择性翻译策略，仅对检测到理解失败的输入进行翻译，在仅翻译约20%输入的情况下达到接近全翻译性能。


<details>
  <summary>更多</summary>
  
**动机:** 推理语言模型在复杂推理任务上表现良好，但在多语言环境中存在性能差距，高资源语言表现优于低资源语言。现有研究尚未深入探索这一差距的根本原因。

**方法:** 通过分析发现理解失败是主要原因，评估多种检测方法（监督方法效果最佳），提出选择性翻译策略：仅在检测到理解失败时将多语言输入翻译成英语。

**结果:** 选择性翻译策略有效缩小多语言推理差距，仅需翻译约20%的输入就能达到接近全翻译的性能水平。

**结论:** 理解失败是多语言推理差距的主要成因，可以通过检测和选择性缓解来解决，为实现更公平的多语言推理提供了重要见解和可行路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Do+Multilingual+Reasoning+Gaps+Emerge+in+Reasoning+Language+Models%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27269，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27269&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [53] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu, Jiajun Song, Wei Wang*

**主要类别:** cs.CL

**AI概要:** 研究发现大型语言模型采用收敛式架构而非模块化架构，评价判断沿着一个主导维度（Valence-Assent Axis）进行计算，该轴统一编码主观价值和事实认同，导致推理过程从公正推断转向目标导向的合理化。


<details>
  <summary>更多</summary>
  
**动机:** 探讨人工智能和生物智能的核心架构问题：判断是依赖专门模块还是统一的领域通用资源，特别是验证LLM中可解码的神经表示是否真正独立。

**方法:** 通过分析多个LLM模型，识别评价判断的主导维度（VAA轴），并通过直接干预实验验证该统一表示的功能。

**结果:** 发现VAA轴作为控制信号引导生成过程构建与其评价状态一致的理由，即使牺牲事实准确性，揭示了推理从属现象。

**结论:** 该收敛架构解释了系统性偏见和幻觉的机制，显示促进连贯判断的架构如何系统性地削弱忠实推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Unified+Representation+Underlying+the+Judgment+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27328，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27328&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [54] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing, Christian Goldschmied, Goran Glavaš*

**主要类别:** cs.CL

**AI概要:** TransAlign是一种新颖的词对齐方法，利用大规模多语言机器翻译模型的编码器，在基于机器翻译的跨语言迁移中显著优于传统词对齐方法和最先进的非词对齐标签投影方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前跨语言迁移主要依赖多语言词对齐器进行标签投影，但基于机器翻译模型提取对齐信息的研究有限且效果不佳，需要更有效的词对齐方法。

**方法:** 提出TransAlign方法，利用大规模多语言机器翻译模型的编码器来提取词对齐信息，用于跨语言迁移中的标签投影任务。

**结果:** TransAlign不仅实现了强大的词对齐性能，而且在基于机器翻译的跨语言迁移中显著超越了流行的词对齐方法和最先进的非词对齐标签投影方法。

**结论:** 利用机器翻译模型编码器的TransAlign方法为跨语言迁移中的词对齐和标签投影提供了更有效的解决方案，在token分类任务中表现出优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TransAlign%3A+Machine+Translation+Encoders+are+Strong+Word+Aligners%2C+Too，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27337，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27337&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [55] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang, Chang Xu*

**主要类别:** cs.CL

**AI概要:** ThoughtProbe是一个推理时框架，利用LLM的隐藏推理特征来提升推理性能，通过分类器评分机制指导树状搜索，并通过分支聚合方法从候选池中选出最优答案


<details>
  <summary>更多</summary>
  
**动机:** 现有方法主要通过操纵隐藏表示来引导LLM生成，而本文希望利用这些隐藏特征作为判别信号来指导树状响应空间探索

**方法:** 1. 在节点扩展时使用分类器作为评分排序机制，优先处理高分候选；2. 完成树扩展后收集所有分支答案形成候选池；3. 提出分支聚合方法，通过聚合CoT分数在所有支持分支上进行边缘化处理

**结果:** 实验结果显示该框架能够全面覆盖有效推理链并有效识别它们，在多个算术推理基准上取得了显著改进

**结论:** ThoughtProbe框架通过利用LLM的隐藏推理特征和树状搜索策略，显著提升了大型语言模型的推理性能

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ThoughtProbe%3A+Classifier-Guided+LLM+Thought+Space+Exploration+via+Probing+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27355&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [56] [A Transformer-based Neural Architecture Search Method](https://arxiv.org/abs/2505.01314)
*Shang Wang, Huanrong Tang, Jianquan Ouyang*

**主要类别:** cs.CL

**AI概要:** 提出基于Transformer架构的神经架构搜索方法，使用多目标遗传算法搜索多头注意力计算方式和编码器-解码器组合，通过BLEU分数和困惑度双重评估指标优化神经网络结构，实验表明搜索到的结构优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 为了寻找具有更好翻译结果的神经网络结构，需要开发更有效的架构搜索方法，传统方法仅依赖BLEU分数可能不够全面。

**方法:** 基于Transformer架构，使用多目标遗传算法搜索不同的多头注意力计算方式和编码器-解码器组合数量，同时使用BLEU分数和困惑度作为评估指标来迭代改进种群中的每个神经网络。

**结果:** 实验结果显示，算法搜索到的神经网络结构在所有基线模型上表现更优，且引入困惑度作为辅助评估指标比仅使用BLEU分数能找到更好的模型。

**结论:** 提出的多目标神经架构搜索方法有效，双重评估指标策略能够发现性能更优的翻译模型结构，证明了辅助指标在架构搜索中的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Transformer-based+Neural+Architecture+Search+Method，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.01314，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.01314&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a neural architecture search method based on Transformer
architecture, searching cross multihead attention computation ways for
different number of encoder and decoder combinations. In order to search for
neural network structures with better translation results, we considered
perplexity as an auxiliary evaluation metric for the algorithm in addition to
BLEU scores and iteratively improved each individual neural network within the
population by a multi-objective genetic algorithm. Experimental results show
that the neural network structures searched by the algorithm outperform all the
baseline models, and that the introduction of the auxiliary evaluation metric
can find better models than considering only the BLEU score as an evaluation
metric.

</details>


### [57] [From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle](https://arxiv.org/abs/2510.27369)
*Tosin Adewumi, Martin Karlsson, Marcus Liwicki, Mikael Sjödahl, Lama Alkhaled, Rihab Gargouri, Nudrat Habib, Franz Hennie*

**主要类别:** cs.CL

**AI概要:** 本文对自然语言处理在完整电池生命周期中的应用进行了系统性综述，提出了技术语言处理(TLP)框架用于欧盟数字电池护照和电池预测，通过PRISMA方法分析了274篇论文中的66篇相关研究。


<details>
  <summary>更多</summary>
  
**动机:** 针对电池领域缺乏对NLP技术在整个生命周期中应用的全面系统性研究，以及欧盟数字电池护照等新兴需求带来的技术挑战。

**方法:** 采用PRISMA系统综述方法，使用Google Scholar、IEEE Xplore和Scopus三个数据库，筛选评估了274篇科学论文，最终深入分析了66篇相关论文。

**结果:** 研究发现电池领域正在出现新的NLP任务，有助于材料发现和生命周期各阶段；但仍存在缺乏标准基准等挑战。提出的TLP框架结合智能代理AI和优化提示，能够应对部分挑战。

**结论:** NLP在电池生命周期应用中具有重要价值，新兴的TLP框架为解决现有挑战提供了有效途径，为电池领域的数字化和智能化发展提供了技术支撑。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+the+Rock+Floor+to+the+Cloud%3A+A+Systematic+Survey+of+State-of-the-Art+NLP+in+Battery+Life+Cycle，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27369，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27369&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We present a comprehensive systematic survey of the application of natural
language processing (NLP) along the entire battery life cycle, instead of one
stage or method, and introduce a novel technical language processing (TLP)
framework for the EU's proposed digital battery passport (DBP) and other
general battery predictions. We follow the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable
databases or search engines, including Google Scholar, Institute of Electrical
and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we
assessed 274 scientific papers before the critical review of the final 66
relevant papers. We publicly provide artifacts of the review for validation and
reproducibility. The findings show that new NLP tasks are emerging in the
battery domain, which facilitate materials discovery and other stages of the
life cycle. Notwithstanding, challenges remain, such as the lack of standard
benchmarks. Our proposed TLP framework, which incorporates agentic AI and
optimized prompts, will be apt for tackling some of the challenges.

</details>


### [58] [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org/abs/2505.13487)
*Ashwin Kumar, Yuzi He, Aram H. Markosyan, Bobbie Chern, Imanol Arrieta-Ibarra*

**主要类别:** cs.CL

**AI概要:** 该论文研究了基于人类反馈的强化学习(RLHF)中奖励模型的前缀偏见问题，提出了检测和评估方法，揭示了种族和性别维度的显著偏见，并提出了数据增强策略来减轻这些偏见。


<details>
  <summary>更多</summary>
  
**动机:** 虽然已有许多公开的偏好数据集提供响应对的比较，但由此产生的奖励模型中潜在的偏见仍未得到充分探索，特别是在查询前缀微小变化引发的系统性偏好偏移方面。

**方法:** 引入新颖的方法来检测和评估基于LLM的奖励模型中的前缀偏见，利用这些指标揭示跨种族和性别维度的偏见，并提出了数据增强策略来减轻偏见。

**结果:** 研究发现在各种开源偏好数据集和奖励模型架构中都存在对这种偏见的易感性，无论底层模型架构如何。提出的数据增强策略在减少前缀偏见影响方面显示出有效性。

**结论:** 研究结果强调了在开发公平可靠的奖励模型时，需要进行偏见意识的数据集设计和评估，为AI公平性的广泛讨论做出贡献。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+Prefix+Bias+in+LLM-based+Reward+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.13487，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.13487&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning with Human Feedback (RLHF) has emerged as a key
paradigm for task-specific fine-tuning of language models using human
preference data. While numerous publicly available preference datasets provide
pairwise comparisons of responses, the potential for biases in the resulting
reward models remains underexplored. In this work, we introduce novel methods
to detect and evaluate prefix bias -- a systematic shift in model preferences
triggered by minor variations in query prefixes -- in LLM-based reward models
trained on such datasets. We leverage these metrics to reveal significant
biases in preference models across racial and gender dimensions. Our
comprehensive evaluation spans diverse open-source preference datasets and
reward model architectures, demonstrating susceptibility to this kind of bias
regardless of the underlying model architecture. Furthermore, we propose a data
augmentation strategy to mitigate these biases, showing its effectiveness in
reducing the impact of prefix bias. Our findings highlight the critical need
for bias-aware dataset design and evaluation in developing fair and reliable
reward models, contributing to the broader discourse on fairness in AI.

</details>


### [59] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu, Zijian Wang, Kuo Zhao, Dong Hu*

**主要类别:** cs.CL

**AI概要:** IntAttn-Edit方法通过联合更新MLP和注意力模块，采用知识平衡策略提升大语言模型的知识编辑效果


<details>
  <summary>更多</summary>
  
**动机:** 现有知识编辑方法主要关注MLP模块权重修改，忽略了注意力模块在知识存储中的作用，导致残留过时知识和编辑效果受限

**方法:** 提出IntAttn-Edit方法，将关联记忆范式扩展到同时更新MLP和注意力模块，使用基于模块贡献比例的知识平衡策略分配更新幅度

**结果:** 在标准基准测试中，IntAttn-Edit相比现有方法实现了更高的编辑成功率、更好的泛化能力和更强的知识保持能力

**结论:** 注意力模块在事实知识存储中起重要作用，联合更新MLP和注意力模块的知识平衡策略能够在多样化设置下保持最优编辑性能

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Balancing+Knowledge+Updates%3A+Toward+Unified+Modular+Editing+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27400，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27400&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [60] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem, Farida Boudichat*

**主要类别:** cs.CL

**AI概要:** Awal是一个社区驱动的塔马齐格特语语言技术资源开发项目，通过awaldigital.org平台收集翻译和语音数据，但在18个月内仅获得6421对翻译和3小时语音数据，显示在复杂社会语言环境中标准众包方法的局限性


<details>
  <summary>更多</summary>
  
**动机:** 解决塔马齐格特语在数字空间中的代表性不足问题，应对该语言持续存在的数据稀缺挑战

**方法:** 建立社区驱动的协作平台awaldigital.org，让母语者贡献翻译和语音数据，并分析18个月的社区参与数据

**结果:** 尽管获得广泛积极反响，但实际数据贡献集中在语言学家和活动家中，仅收集到6421对翻译和3小时语音数据，揭示了参与障碍包括书面语信心不足和标准化挑战

**结论:** 标准众包方法在复杂社会语言环境中的语言上存在局限性，需要改进方法，正在利用收集的数据开发改进的开源机器翻译模型

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Awal+--+Community-Powered+Language+Technology+for+Tamazight，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27407，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27407&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [61] [Dynamic Affective Memory Management for Personalized LLM Agents](https://arxiv.org/abs/2510.27418)
*Junfeng Lu, Yueyan Li*

**主要类别:** cs.CL

**AI概要:** 提出基于贝叶斯启发式记忆更新算法的新型记忆管理系统，通过最小化全局熵实现动态记忆更新，解决个性化AI代理中的记忆冗余、过时和上下文整合问题


<details>
  <summary>更多</summary>
  
**动机:** 当前AI代理系统依赖外部记忆数据库提供个性化体验，但存在记忆冗余、过时和记忆-上下文整合不佳的问题，主要由于缺乏交互过程中的有效记忆更新机制

**方法:** 采用贝叶斯启发的记忆更新算法，引入记忆熵概念，使代理能够通过最小化全局熵来自主维护动态更新的记忆向量数据库

**结果:** 实验结果显示系统在个性化、逻辑一致性和准确性方面表现优异，消融研究验证了贝叶斯更新机制在缓解记忆膨胀方面的有效性

**结论:** 该工作为长期记忆系统设计提供了新的见解，提出的DABench基准测试专注于情感表达和情感变化评估，证明了系统在情感场景中的有效性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Affective+Memory+Management+for+Personalized+LLM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27418，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27418&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Advances in large language models are making personalized AI agents a new
research focus. While current agent systems primarily rely on personalized
external memory databases to deliver customized experiences, they face
challenges such as memory redundancy, memory staleness, and poor memory-context
integration, largely due to the lack of effective memory updates during
interaction. To tackle these issues, we propose a new memory management system
designed for affective scenarios. Our approach employs a Bayesian-inspired
memory update algorithm with the concept of memory entropy, enabling the agent
to autonomously maintain a dynamically updated memory vector database by
minimizing global entropy to provide more personalized services. To better
evaluate the system's effectiveness in this context, we propose DABench, a
benchmark focusing on emotional expression and emotional change toward objects.
Experimental results demonstrate that, our system achieves superior performance
in personalization, logical coherence, and accuracy. Ablation studies further
validate the effectiveness of the Bayesian-inspired update mechanism in
alleviating memory bloat. Our work offers new insights into the design of
long-term memory systems.

</details>


### [62] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong, Senmiao Wang, Hanbo Huang, Ruoyu Sun, Shiyu Liang*

**主要类别:** cs.CL

**AI概要:** VCORE是一种基于优化理论的token重加权框架，通过方差控制的约束优化重新分配监督信号，提升大语言模型在长思维链推理任务中的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 标准的交叉熵损失函数对所有token一视同仁，忽略了思维链轨迹中不同token的异质性贡献，导致监督信号分配不当和泛化能力弱，特别是在复杂长推理任务中。

**方法:** 提出VCORE框架，将思维链监督重新构建为约束优化问题，从优化理论角度实现token监督的自适应分配，使训练目标更符合鲁棒推理泛化的目标。

**结果:** 在数学和编程基准测试中，使用Qwen3系列和LLaMA-3.1-8B-Instruct模型，VCORE在域内和域外设置下均显著优于现有token重加权方法，并作为强化学习的更有效初始化。

**结论:** VCORE通过优化理论视角重新设计监督信号分配机制，为大语言模型推理能力的提升提供了更强的基础，代码将开源发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VCORE%3A+Variance-Controlled+Optimization-based+Reweighting+for+Chain-of-Thought+Supervision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27462，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27462&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [63] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao, Sijian Ren, Fengli Xu, Yong Li*

**主要类别:** cs.CL

**AI概要:** 提出了一种基于扩散语言模型和大型语言模型协作的高效推理框架，通过DLMs并行生成候选思维，LLMs评估质量，显著降低计算开销同时保持推理性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统LLMs的自回归生成范式在推理任务中计算效率低下，需要大量计算开销但性能提升有限。DLMs能够通过单次前向传播并行生成多样样本，为解决这一问题提供了新思路。

**方法:** 设计协作推理框架：使用扩散语言模型（DLMs）高效生成多样化的候选中间思维步骤，然后利用大型语言模型（LLMs）对这些候选思维进行质量评估和选择。

**结果:** 在多个基准测试中，该框架在复杂推理任务上表现出强大的性能，同时显著降低了计算负担。

**结论:** 该研究为高效推理提供了一个有前景的新方向，证明了DLMs和LLMs协作框架的有效性，代码已开源供进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffuse+Thinking%3A+Exploring+Diffusion+Language+Models+as+Efficient+Thought+Proposers+for+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27469，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27469&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [64] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

**主要类别:** cs.CL

**AI概要:** 本研究比较了GloVe和BERT嵌入在英语复合词语义处理中与人类语义判断的一致性，发现BERT比GloVe能更好地捕捉组合语义，可预测性评分是语义透明度的强预测因子。


<details>
  <summary>更多</summary>
  
**动机:** 研究计算嵌入模型（静态词向量和上下文嵌入）与人类语义判断在英语复合词处理中的对齐程度，以推进计算心理语言学发展。

**方法:** 使用GloVe和BERT嵌入，基于爱丁堡联想词库的关联强度、BNC频率和LaDEC可预测性度量，计算嵌入衍生的LMD和ST指标，并通过Spearman相关性和回归分析与人类评分进行比较。

**结果:** BERT嵌入在捕捉组合语义方面优于GloVe，可预测性评分在人类和模型数据中都是语义透明度的强预测因子。

**结论:** 研究结果阐明了驱动复合词处理的因素，为基于嵌入的语义建模提供了见解，推动了计算心理语言学的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+aftermath+of+compounds%3A+Investigating+Compounds+and+their+Semantic+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27477，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27477&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [65] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu, Chisom Chibuike, Fatimo Adebanjo, Omokolade Awosanya, Samuel Oyeneye*

**主要类别:** cs.CL

**AI概要:** 本研究在低资源自然语言处理任务中比较了两种因果域泛化方法：因果数据增强(CDA)生成反事实样本来改善虚假相关性的鲁棒性，以及不变因果表示学习(ICRL)方法DINER框架。两种方法在不同任务中都提升了未见域的泛化性能。


<details>
  <summary>更多</summary>
  
**动机:** 现实场景中训练和测试数据分布不一致的问题在低资源环境下尤为突出，数据稀缺和领域多样性有限阻碍了模型的鲁棒泛化能力。

**方法:** 1. 因果数据增强(CDA)：自动生成反事实示例，在NaijaSenti Twitter语料库的情感分类任务中通过语义等价复述扩展训练数据；2. 不变因果表示学习(ICRL)：采用DINER框架并适配到多语言环境进行基于方面的情感分析。

**结果:** 两种方法都增强了未见领域的鲁棒性：反事实数据增强在情感分类中带来一致的跨域准确率提升；DINER因果表示学习在多语言情感分析中改善了分布外性能，尽管不同语言的增益有所差异。

**结论:** 因果域泛化方法在低资源NLP任务中有效，通过不同的因果机制（数据增强和表示学习）都能提升模型对分布偏移的鲁棒性，为实际应用提供了有前景的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Effect+of+Domain+Generalization+Techniques+in+Low+Resource+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27512，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27512&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [66] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos, Legand L. Burge, Anietie Andy, Anis Yazidi, Vladimir Vlassov*

**主要类别:** cs.CL

**AI概要:** BiSparse-AAS是一个结合稀疏注意力、自适应范围和双线性注意力的新型Transformer框架，显著提升长文本摘要的效率和质量，在多个数据集上超越现有最佳模型。


<details>
  <summary>更多</summary>
  
**动机:** 传统Transformer架构在文本摘要中存在二次计算复杂度问题，限制了其在长文档上的可扩展性，需要一种更高效的注意力机制来解决这些问题。

**方法:** 提出BiSparse-AAS框架，整合三种技术：稀疏注意力减少计算成本，自适应范围动态调整注意力范围，双线性注意力在精炼上下文中建模复杂标记交互。

**结果:** 在抽取式和生成式摘要任务中均优于最先进基线模型，CNN/DailyMail数据集ROUGE提升约68.1%，XSum数据集提升52.6%，在OpenWebText和Gigaword数据集上也保持强劲性能。

**结论:** BiSparse-AAS通过解决效率、可扩展性和长序列建模问题，为现实世界的文本摘要应用提供了一个统一且实用的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BiSparse-AAS%3A+Bilinear+Sparse+Attention+and+Adaptive+Spans+Framework+for+Scalable+and+Efficient+Text+Summarization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27516，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27516&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [67] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth, Victor Bursztyn, Puneet Mathur, Ani Nenkova*

**主要类别:** cs.CL

**AI概要:** SQLSpace是一个从文本到SQL示例中自动提取的人类可解释、可泛化、紧凑的表示方法，可用于比较基准测试、分析模型性能和改进查询重写。


<details>
  <summary>更多</summary>
  
**动机:** 现有的文本到SQL基准测试评估缺乏细粒度的分析工具，无法深入理解模型性能差异和基准测试的组成特点。

**方法:** 开发SQLSpace表示方法，通过最小化人工干预从文本到SQL示例中提取人类可解释的特征表示。

**结果:** SQLSpace能够揭示不同基准测试之间的组成差异，发现仅凭准确率无法观察到的性能模式，并支持查询成功率的建模。

**结论:** SQLSpace为文本到SQL任务提供了强大的分析工具，能够支持更深入的基准测试比较、细粒度性能分析和模型改进策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SQLSpace%3A+A+Representation+Space+for+Text-to-SQL+to+Discover+and+Mitigate+Robustness+Gaps，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27532，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27532&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [68] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez, Ana Gabriela Claros, Kieran Green, David Toro-Tobon, Felipe Larios, Sheena Asthana, Camila Wenczenovicz, Kerly Guevara Maldonado, Luis Vilatuna-Andrango, Cristina Proano-Velez, Satya Sai Sri Bandi, Shubhangi Bagewadi, Megan E. Branda, Misk Al Zahidy, Saturnino Luz, Mirella Lapata, Juan P. Brito, Oscar J. Ponce-Ponte*

**主要类别:** cs.CL

**AI概要:** 该研究提出了患者中心摘要(PCS)新标准，通过混合方法开发框架，评估开源LLM在生成包含患者偏好和价值观的临床摘要方面是否能达到人类水平表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM生成的临床摘要过于关注患者生物学信息，而忽视了患者的偏好、价值观、愿望和关切，无法实现真正的以患者为中心的护理。

**方法:** 采用混合方法：通过患者和临床医生访谈确定摘要内容标准，制定标注指南，由临床医生创建黄金标准PCS，使用5个开源LLM进行零样本和少样本提示生成摘要，并通过ROUGE-L、BERTScore和定性指标进行评估。

**结果:** 最佳零样本表现由Mistral-8B和Llama-3.1-8B取得，最佳少样本表现由Llama-3.1-8B取得。模型在完整性和流畅性方面与专家相当，但在正确性和患者中心性方面仍不如人类生成的摘要。

**结论:** 当前开源LLM在生成患者中心临床摘要方面显示出潜力，但在捕捉患者价值观和确保临床准确性方面仍需改进，需要进一步开发以实现真正的人类水平表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Patient-Centered+Summarization+Framework+for+AI+Clinical+Summarization%3A+A+Mixed-Methods+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27535，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27535&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [69] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori, Nizar Habash, Abdelhakim Freihat, Younes Samih, Kirill Chirkunov, Muhammed AbuOdeh, Radu Florian, Teresa Lynn, Preslav Nakov, Alham Fikri Aji*

**主要类别:** cs.CL

**AI概要:** DialectalArabicMMLU是一个新的阿拉伯语方言评估基准，通过手动翻译和改编3K个多选题到5种主要方言，创建了15K个QA对，用于系统评估大语言模型在阿拉伯方言上的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的阿拉伯语和多语言基准主要关注现代标准阿拉伯语(MSA)，但方言在日常交流中广泛使用却缺乏代表性评估，需要填补这一空白。

**方法:** 基于MMLU-Redux框架，手动翻译和改编3K个多选题到叙利亚、埃及、阿联酋、沙特和摩洛哥五种方言，涵盖32个学术和专业领域。

**结果:** 评估了19个开源阿拉伯语和多语言LLM(1B-13B参数)，发现不同方言间存在显著的性能差异，揭示了方言泛化方面的持续差距。

**结论:** DialectalArabicMMLU提供了首个统一的人工策划资源，用于衡量阿拉伯方言理解能力，促进更包容的评估和未来模型发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DialectalArabicMMLU%3A+Benchmarking+Dialectal+Capabilities+in+Arabic+and+Multilingual+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27543，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27543&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [70] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo, Lang Zhou, Amrish Jhingoer, Klaske Vliegenthart Jongbloed, Carlijn Jordans, Ben Werkhoven, Tom Seinen, Erik van Mulligen, Casper Rokx, Yunlei Li*

**主要类别:** cs.CL

**AI概要:** 该研究探讨了在多语言医疗NLP中，通过对多语言BERT模型进行领域特定预训练来提升低资源语言医疗任务性能的效果，发现领域适应能显著提升模型表现，且临床领域适应优于一般生物医学领域适应。


<details>
  <summary>更多</summary>
  
**动机:** 多语言医疗应用中，特别是低资源语言的领域特定NLP工具有限，医疗NLP任务在低资源语言中仍未充分探索，需要解决语言差距问题。

**方法:** 使用荷兰语、罗马尼亚语和西班牙语三种语言，进行四种领域的进一步预训练实验创建医疗领域模型，然后在三个下游任务上进行微调：荷兰临床笔记的自动患者筛查、罗马尼亚和西班牙临床笔记的命名实体识别。

**结果:** 领域适应显著提升了任务性能，临床领域适应的模型表现优于一般生物医学领域适应的模型，同时观察到跨语言可迁移性的证据。

**结论:** 研究结果突显了领域适应和跨语言能力在医疗NLP中的可行性，为开发多语言医疗NLP系统提供了有意义的指导，以缓解训练数据不足的问题并提升模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilingual+BERT+language+model+for+medical+tasks%3A+Evaluation+on+domain-specific+adaptation+and+cross-linguality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27552，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27552&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [71] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira, Antonio Castaldo, James O'Doherty, Sheila Castilho*

**主要类别:** cs.CL

**AI概要:** 本研究提出使用CPO（对比偏好优化）方法进行数据高效的领域自适应，通过将基础模型的原始输出作为被拒绝样本、人工审校的翻译记忆条目作为优选样本，仅需14.7k偏好对即可达到与160k+ SFT样本相当的性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统SFT方法进行领域自适应成本高昂，需要寻找更数据高效的方法来适应领域特定需求。

**方法:** 采用CPO方法模拟后编辑工作流程，合成偏好对：基础模型原始输出作为rejected样本，人工批准的TM条目作为chosen样本，为模型提供直接反馈。

**结果:** 在英-巴西葡萄牙语和英-韩语翻译任务中，仅使用14.7k偏好对就达到了与160k+ SFT样本训练模型相近的性能，数据效率显著提升。

**结论:** CPO方法在机器翻译领域展现出显著的数据效率优势，且该方法可自然推广到其他生成任务，其中模型的初始草稿可以作为与黄金参考的对比信号。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Efficient+Domain+Adaptation+for+LLM-based+MT+using+Contrastive+Preference+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27556，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27556&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [72] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo, Xiaonan Li, Yuxin Wang, Tingshuo Fan, Yuan Li, Xinchi Chen, Xipeng Qiu*

**主要类别:** cs.CL

**AI概要:** MARAG-R1是一个基于强化学习的多工具检索增强生成框架，通过让大语言模型动态协调多种检索机制来解决传统RAG系统单一检索器限制的问题，显著提升了语料级推理任务的性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统RAG系统依赖单一检索器和固定top-k选择，导致信息获取范围有限且静态，成为全面外部信息获取的主要瓶颈，特别是在需要语料级推理的任务中。

**方法:** 提出MARAG-R1框架，配备四种检索工具（语义搜索、关键词搜索、过滤和聚合），通过两阶段训练过程（监督微调+强化学习）学习如何和何时使用这些工具，实现推理与检索的交错进行。

**结果:** 在GlobalQA、HotpotQA和2WikiMultiHopQA数据集上的实验表明，MARAG-R1显著优于强基线方法，在语料级推理任务中取得了新的最先进结果。

**结论:** 多工具动态协调的RAG框架能够有效克服单一检索器的局限性，为LLMs提供更广泛和精确的外部信息访问能力，从而提升事实准确性和对新信息的适应能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MARAG-R1%3A+Beyond+Single+Retriever+via+Reinforcement-Learned+Multi-Tool+Agentic+Retrieval，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27569，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27569&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [73] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao, Darren Li, Fandong Meng, Jie Zhou*

**主要类别:** cs.CL

**AI概要:** CALM模型通过将离散的逐词生成改为连续的向量预测，用高保真自编码器将K个token压缩为一个连续向量，显著减少生成步骤数量，提高计算效率


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型的效率受限于其顺序的逐词生成过程，需要突破这一瓶颈来提高语义带宽

**方法:** 引入连续自回归语言模型(CALM)，使用高保真自编码器将token块压缩为连续向量，开发无似然框架进行训练、评估和采样

**结果:** CALM显著改善了性能-计算权衡，以显著更低的计算成本实现了强大离散基线的性能

**结论:** 下一向量预测是构建超高效语言模型的一个强大且可扩展的途径

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Continuous+Autoregressive+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27688，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27688&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


### [74] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

**主要类别:** cs.CL

**AI概要:** SpecAttn是一种无需训练的方法，通过利用推测解码中已计算的注意力权重来识别重要token，实现预训练Transformer中的高效稀疏注意力，在保持输出质量的同时大幅减少计算量。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在推理时面临自注意力机制的二次计算复杂度瓶颈，特别是随着上下文长度增加，计算开销急剧增长。

**方法:** 使用KL散度进行草稿模型和目标模型的层对齐、GPU优化的无排序top-p token选择算法、基于预测的动态键值缓存剪枝，利用推测解码中已计算的注意力权重。

**结果:** 在PG-19数据集上实现了超过75%的键值缓存访问减少，仅增加15.29%的困惑度，显著优于现有稀疏注意力方法。

**结论:** 研究表明推测执行可以通过近似验证得到增强，而不会导致显著的性能下降，为高效推理提供了新思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SpecAttn%3A+Speculating+Sparse+Attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27641，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27641&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [75] [Culture Cartography: Mapping the Landscape of Cultural Knowledge](https://arxiv.org/abs/2510.27672)
*Caleb Ziems, William Held, Jane Yu, Amir Goldberg, David Grusky, Diyi Yang*

**主要类别:** cs.CL

**AI概要:** CultureCartography是一种混合主动方法，通过LLM提出低置信度问题，人类编辑指导，有效发现LLM缺失的文化知识，提升模型文化理解能力


<details>
  <summary>更多</summary>
  
**动机:** LLM需要文化特定知识但预训练可能缺失，现有单主动方法（研究者定义问题或用户提供数据）不够有效，需要混合协作方法

**方法:** 提出CultureCartography方法：LLM初始化标注低置信度问题，人类填写并指导模型关注重要主题，实现为CultureExplorer工具

**结果:** 相比基线方法，CultureExplorer更有效发现DeepSeek R1和GPT-4o缺失的知识，使用该数据微调使Llama-3.1-8B在文化基准上准确率提升达19.2%

**结论:** 混合主动协作方法能有效识别和填补LLM的文化知识空白，提升模型的文化适应性和实用性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Culture+Cartography%3A+Mapping+the+Landscape+of+Cultural+Knowledge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2510.27672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2510.27672&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** To serve global users safely and productively, LLMs need culture-specific
knowledge that might not be learned during pre-training. How do we find such
knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The
most common solutions are single-initiative: either researchers define
challenging questions that users passively answer (traditional annotation), or
users actively produce data that researchers structure as benchmarks (knowledge
extraction). The process would benefit from mixed-initiative collaboration,
where users guide the process to meaningfully reflect their cultures, and LLMs
steer the process towards more challenging questions that meet the researcher's
goals. We propose a mixed-initiative methodology called CultureCartography.
Here, an LLM initializes annotation with questions for which it has
low-confidence answers, making explicit both its prior knowledge and the gaps
therein. This allows a human respondent to fill these gaps and steer the model
towards salient topics through direct edits. We implement this methodology as a
tool called CultureExplorer. Compared to a baseline where humans answer
LLM-proposed questions, we find that CultureExplorer more effectively produces
knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even
with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B
by up to 19.2% on related culture benchmarks.

</details>
