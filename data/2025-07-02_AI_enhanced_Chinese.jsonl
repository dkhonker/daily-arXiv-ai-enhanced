{"id": "2507.00002", "pdf": "https://arxiv.org/pdf/2507.00002", "abs": "https://arxiv.org/abs/2507.00002", "authors": ["Christopher James Augeri"], "title": "Hypertokens: Holographic Associative Memory in Tokenized LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "preprint as accepted to https://qnlp.ai/ - Quantum AI and NLP\n  Conference 2025", "summary": "Large Language Models (LLMs) exhibit remarkable capabilities but suffer from\napparent precision loss, reframed here as information spreading. This reframing\nshifts the problem from computational precision to an information-theoretic\ncommunication issue. We address the K:V and V:K memory problem in LLMs by\nintroducing HDRAM (Holographically Defined Random Access Memory), a symbolic\nmemory framework treating transformer latent space as a spread-spectrum\nchannel. Built upon hypertokens, structured symbolic codes integrating\nclassical error-correcting codes (ECC), holographic computing, and\nquantum-inspired search, HDRAM recovers distributed information through\nprincipled despreading. These phase-coherent memory addresses enable efficient\nkey-value operations and Grover-style search in latent space. By combining ECC\ngrammar with compressed sensing and Krylov subspace alignment, HDRAM\nsignificantly improves associative retrieval without architectural changes,\ndemonstrating how Classical-Holographic-Quantum-inspired (CHQ) principles can\nfortify transformer architectures.", "AI": {"tldr": "Large Language Models (LLMs) face precision loss, redefined as information spreading. To tackle this issue, HDRAM (Holographically Defined Random Access Memory) is introduced, which treats transformer latent space as a spread-spectrum channel and uses hypertokens integrating error-correcting codes, holographic computing, and quantum-inspired search to recover distributed information efficiently.", "motivation": "The motivation of this paper is to address the apparent precision loss in Large Language Models (LLMs), reframing it as an information spreading problem rather than computational precision loss.", "method": "HDRAM, built upon hypertokens, structured symbolic codes that incorporate classical error-correcting codes (ECC), holographic computing, and quantum-inspired search, treats the transformer latent space as a spread-spectrum channel. It enables efficient key-value operations and Grover-style search in latent space through phase-coherent memory addresses.", "result": "HDRAM significantly improves associative retrieval without requiring architectural changes, demonstrating the effectiveness of Classical-Holographic-Quantum-inspired (CHQ) principles.", "conclusion": "By applying HDRAM, the paper shows how CHQ principles can fortify transformer architectures against information spreading issues."}}
{"id": "2507.00003", "pdf": "https://arxiv.org/pdf/2507.00003", "abs": "https://arxiv.org/abs/2507.00003", "authors": ["Eyhab Al-Masri"], "title": "Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NI"], "comment": null, "summary": "This paper presents NeutroSENSE, a neutrosophic-enhanced ensemble framework\nfor interpretable intrusion detection in IoT environments. By integrating\nRandom Forest, XGBoost, and Logistic Regression with neutrosophic logic, the\nsystem decomposes prediction confidence into truth (T), falsity (F), and\nindeterminacy (I) components, enabling uncertainty quantification and\nabstention. Predictions with high indeterminacy are flagged for review using\nboth global and adaptive, class-specific thresholds. Evaluated on the IoT-CAD\ndataset, NeutroSENSE achieved 97% accuracy, while demonstrating that\nmisclassified samples exhibit significantly higher indeterminacy (I = 0.62)\nthan correct ones (I = 0.24). The use of indeterminacy as a proxy for\nuncertainty enables informed abstention and targeted review-particularly\nvaluable in edge deployments. Figures and tables validate the correlation\nbetween I-scores and error likelihood, supporting more trustworthy,\nhuman-in-the-loop AI decisions. This work shows that neutrosophic logic\nenhances both accuracy and explainability, providing a practical foundation for\ntrust-aware AI in edge and fog-based IoT security systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeutroSENSE\u7684\u4e2d\u667a\u589e\u5f3a\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u53ef\u89e3\u91ca\u5165\u4fb5\u68c0\u6d4b\u3002\u901a\u8fc7\u6574\u5408\u968f\u673a\u68ee\u6797\u3001XGBoost\u548c\u903b\u8f91\u56de\u5f52\u4e0e\u4e2d\u667a\u903b\u8f91\uff0c\u7cfb\u7edf\u5c06\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u5206\u89e3\u4e3a\u771f\uff08T\uff09\u3001\u5047\uff08F\uff09\u548c\u4e0d\u786e\u5b9a\u6027\uff08I\uff09\u4e09\u4e2a\u90e8\u5206\uff0c\u5b9e\u73b0\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5f03\u6743\u673a\u5236\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cNeutroSENSE\u5728IoT-CAD\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8697%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u8868\u660e\u9519\u8bef\u5206\u7c7b\u6837\u672c\u7684\u4e0d\u786e\u5b9a\u6027\u663e\u8457\u9ad8\u4e8e\u6b63\u786e\u5206\u7c7b\u6837\u672c\u3002\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u7684\u4ee3\u7406\u53ef\u4ee5\u5b9e\u73b0\u660e\u667a\u7684\u5f03\u6743\u548c\u6709\u9488\u5bf9\u6027\u7684\u5ba1\u67e5\uff0c\u8fd9\u5bf9\u4e8e\u8fb9\u7f18\u90e8\u7f72\u7279\u522b\u6709\u4ef7\u503c\u3002\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e2d\u667a\u903b\u8f91\u5982\u4f55\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8fb9\u7f18\u548c\u96fe\u57fa\u7269\u8054\u7f51\u5b89\u5168\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u611f\u77e5AI\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u7269\u8054\u7f51\u73af\u5883\u4e2d\uff0c\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u65f6\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u590d\u6742\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u63d0\u5347\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "NeutroSENSE\u6846\u67b6\u7ed3\u5408\u4e86\u968f\u673a\u68ee\u6797\u3001XGBoost\u548c\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e2d\u667a\u903b\u8f91\uff0c\u5c06\u9884\u6d4b\u7ed3\u679c\u5206\u4e3a\u771f\uff08T\uff09\u3001\u5047\uff08F\uff09\u548c\u4e0d\u786e\u5b9a\u6027\uff08I\uff09\u4e09\u4e2a\u90e8\u5206\u3002\u901a\u8fc7\u5168\u5c40\u548c\u81ea\u9002\u5e94\u7c7b\u7279\u5b9a\u9608\u503c\u6807\u8bb0\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u9884\u6d4b\u4ee5\u4f9b\u5ba1\u67e5\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u4f5c\u4e3a\u4ee3\u7406\u6765\u8861\u91cf\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u652f\u6301\u4eba\u7c7b\u53c2\u4e0e\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "NeutroSENSE\u5728IoT-CAD\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u523097%\uff0c\u5e76\u4e14\u53d1\u73b0\u9519\u8bef\u5206\u7c7b\u6837\u672c\u7684\u4e0d\u786e\u5b9a\u6027\uff08I = 0.62\uff09\u660e\u663e\u9ad8\u4e8e\u6b63\u786e\u5206\u7c7b\u6837\u672c\uff08I = 0.24\uff09\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86I\u5206\u6570\u4e0e\u9519\u8bef\u6982\u7387\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4fe1\u4efb\u611f\u77e5AI\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e2d\u667a\u903b\u8f91\u589e\u5f3a\u4e86\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8fb9\u7f18\u548c\u96fe\u57fa\u7269\u8054\u7f51\u5b89\u5168\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u611f\u77e5AI\u63d0\u4f9b\u4e86\u5b9e\u9645\u53ef\u884c\u7684\u57fa\u7840\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8fd8\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u503c\u5f97\u4fe1\u8d56\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002"}}
{"id": "2507.00004", "pdf": "https://arxiv.org/pdf/2507.00004", "abs": "https://arxiv.org/abs/2507.00004", "authors": ["Austin R. Ellis-Mohr", "Anuj K. Nayak", "Lav R. Varshney"], "title": "A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.PF"], "comment": null, "summary": "Large language models (LLMs) demand considerable computational, energy, and\nfinancial resources during both training and deployment. While scaling laws for\ntraining have guided much of the field's recent progress, inference costs now\nrepresent a significant and growing component of the overall resource burden,\nparticularly for reasoning-focused models. Existing characterizations of\ncompute-optimality that consider model size, dataset size, and inference tokens\nin isolation or in fixed combinations risk overlooking more efficient operating\npoints. We introduce directed stochastic skill search (DS3), a general\nframework that represents inference as stochastic traversal over a learned\nskill graph. From a simplified yet expressive instantiation, we derive\nclosed-form expressions for task success and compute cost across a wide range\nof inference strategies -- including chain-of-thought (CoT) and tree-of-thought\n(ToT) -- enabling comparative analysis as a function of task difficulty and\nmodel capability. To that end, we extend a prior first-principles tripartite\ngraph framework of LLM training to incorporate inference, and separately bridge\nDS3 with empirical methods that characterize LLM scaling behavior. We\ntheoretically recover empirically observed patterns, including: linear accuracy\nscaling with logarithmic compute; variation in preferred inference strategies\nas a function of task difficulty and model capability; emergent behavior\nelicited by reasoning even when performance plateaus under parameter scaling;\nand both best-of-N (BoN) and majority voting behavior captured within a unified\nanalytical framework. By explicitly characterizing training-inference\ninterdependencies, our framework deepens theoretical understanding and supports\nprincipled algorithmic design and resource allocation.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u3001\u80fd\u6e90\u548c\u8d44\u91d1\u8d44\u6e90\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u5b9a\u5411\u968f\u673a\u6280\u80fd\u641c\u7d22\uff08DS3\uff09\u7684\u901a\u7528\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u8868\u793a\u4e3a\u5728\u5b66\u4e60\u5230\u7684\u6280\u80fd\u56fe\u4e0a\u7684\u968f\u673a\u904d\u5386\u3002\u8be5\u6846\u67b6\u63a8\u5bfc\u51fa\u4efb\u52a1\u6210\u529f\u548c\u8ba1\u7b97\u6210\u672c\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u6db5\u76d6\u591a\u79cd\u63a8\u7406\u7b56\u7565\uff0c\u5982\u601d\u7ef4\u94fe\uff08CoT\uff09\u548c\u601d\u7ef4\u6811\uff08ToT\uff09\u3002\u901a\u8fc7\u5c06\u63a8\u7406\u7eb3\u5165\u5148\u524d\u7684\u7b2c\u4e00\u6027\u539f\u7406\u4e09\u65b9\u56fe\u6846\u67b6\u5e76\u7ed3\u5408\u7ecf\u9a8c\u65b9\u6cd5\uff0c\u6587\u7ae0\u63ed\u793a\u4e86\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u80fd\u529b\u5bf9\u63a8\u7406\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u5e76\u89e3\u91ca\u4e86\u8bf8\u5982\u7ebf\u6027\u51c6\u786e\u7387\u968f\u5bf9\u6570\u8ba1\u7b97\u91cf\u589e\u957f\u7b49\u73b0\u8c61\u3002\u6b64\u5916\uff0c\u6846\u67b6\u8fd8\u7edf\u4e00\u4e86\u6700\u4f73N\u9009\u62e9\uff08BoN\uff09\u548c\u591a\u6570\u6295\u7968\u884c\u4e3a\uff0c\u5e76\u660e\u786e\u523b\u753b\u4e86\u8bad\u7ec3\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u6df1\u5316\u7406\u8bba\u7406\u89e3\u5e76\u652f\u6301\u7b97\u6cd5\u8bbe\u8ba1\u548c\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u5c3d\u7ba1\u6269\u5c55\u5b9a\u5f8b\u5728\u8bad\u7ec3\u65b9\u9762\u6307\u5bfc\u4e86\u8bb8\u591a\u9886\u57df\u7684\u8fd1\u671f\u8fdb\u5c55\uff0c\u4f46\u63a8\u7406\u6210\u672c\u73b0\u5728\u5df2\u7ecf\u6210\u4e3a\u6574\u4f53\u8d44\u6e90\u8d1f\u62c5\u7684\u91cd\u8981\u4e14\u4e0d\u65ad\u589e\u957f\u7684\u90e8\u5206\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4e13\u6ce8\u4e8e\u63a8\u7406\u7684\u6a21\u578b\u3002\u73b0\u6709\u7684\u8ba1\u7b97\u6700\u4f18\u6027\u8868\u5f81\u53ef\u80fd\u5ffd\u7565\u4e86\u66f4\u6709\u6548\u7684\u64cd\u4f5c\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u5b9a\u5411\u968f\u673a\u6280\u80fd\u641c\u7d22\uff08DS3\uff09\u7684\u901a\u7528\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u89c6\u4e3a\u5728\u5b66\u4e60\u5230\u7684\u6280\u80fd\u56fe\u4e0a\u7684\u968f\u673a\u904d\u5386\u3002\u4ece\u7b80\u5316\u7684\u8868\u8fbe\u5f62\u5f0f\u4e2d\uff0c\u63a8\u5bfc\u51fa\u4efb\u52a1\u6210\u529f\u548c\u8ba1\u7b97\u6210\u672c\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u6db5\u76d6\u4e86\u5404\u79cd\u63a8\u7406\u7b56\u7565\u3002\u540c\u65f6\uff0c\u5c06DS3\u6846\u67b6\u4e0e\u7ecf\u9a8c\u65b9\u6cd5\u7ed3\u5408\uff0c\u4ee5\u63cf\u8ff0LLM\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u5e76\u6269\u5c55\u4e86\u5148\u524d\u5173\u4e8eLLM\u8bad\u7ec3\u7684\u4e09\u65b9\u56fe\u6846\u67b6\u4ee5\u5305\u542b\u63a8\u7406\u3002", "result": "\u7406\u8bba\u4e0a\u6062\u590d\u4e86\u89c2\u5bdf\u5230\u7684\u73b0\u8c61\uff0c\u5305\u62ec\uff1a\u968f\u7740\u5bf9\u6570\u8ba1\u7b97\u91cf\u7684\u589e\u52a0\uff0c\u51c6\u786e\u7387\u7ebf\u6027\u589e\u957f\uff1b\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u80fd\u529b\uff0c\u9996\u9009\u7684\u63a8\u7406\u7b56\u7565\u6709\u6240\u53d8\u5316\uff1b\u5373\u4f7f\u5728\u53c2\u6570\u6269\u5c55\u4e0b\u6027\u80fd\u8fbe\u5230\u5e73\u53f0\u671f\uff0c\u63a8\u7406\u4ecd\u80fd\u5f15\u53d1\u65b0\u5174\u884c\u4e3a\uff1b\u6700\u4f73N\u9009\u62e9\uff08BoN\uff09\u548c\u591a\u6570\u6295\u7968\u884c\u4e3a\u88ab\u7edf\u4e00\u5728\u4e00\u4e2a\u5206\u6790\u6846\u67b6\u5185\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u523b\u753b\u8bad\u7ec3\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6df1\u5316\u4e86\u5bf9LLM\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u652f\u6301\u6709\u539f\u5219\u7684\u7b97\u6cd5\u8bbe\u8ba1\u548c\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2507.00011", "pdf": "https://arxiv.org/pdf/2507.00011", "abs": "https://arxiv.org/abs/2507.00011", "authors": ["Nathan Vaartjes", "Vincent Francois-Lavet"], "title": "Novel RL approach for efficient Elevator Group Control Systems", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 12 figures", "summary": "Efficient elevator traffic management in large buildings is critical for\nminimizing passenger travel times and energy consumption. Because heuristic- or\npattern-detection-based controllers struggle with the stochastic and\ncombinatorial nature of dispatching, we model the six-elevator, fifteen-floor\nsystem at Vrije Universiteit Amsterdam as a Markov Decision Process and train\nan end-to-end Reinforcement Learning (RL) Elevator Group Control System (EGCS).\nKey innovations include a novel action space encoding to handle the\ncombinatorial complexity of elevator dispatching, the introduction of\ninfra-steps to model continuous passenger arrivals, and a tailored reward\nsignal to improve learning efficiency. In addition, we explore various ways to\nadapt the discounting factor to the infra-step formulation. We investigate RL\narchitectures based on Dueling Double Deep Q-learning, showing that the\nproposed RL-based EGCS adapts to fluctuating traffic patterns, learns from a\nhighly stochastic environment, and thereby outperforms a traditional rule-based\nalgorithm.", "AI": {"tldr": "\u901a\u8fc7\u5c06Vrije Universiteit Amsterdam\u7684\u516d\u7535\u68af\u5341\u4e94\u697c\u5c42\u7cfb\u7edf\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8bad\u7ec3\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60(EGCS)\u7cfb\u7edf\uff0c\u63d0\u51fa\u65b0\u7684\u52a8\u4f5c\u7a7a\u95f4\u7f16\u7801\u3001\u8fde\u7eed\u4e58\u5ba2\u5230\u8fbe\u5efa\u6a21\u548c\u5956\u52b1\u4fe1\u53f7\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u6298\u6263\u56e0\u5b50\u9002\u5e94\u65b9\u6cd5\uff0c\u6700\u7ec8\u8868\u660eRL-EGCS\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7b97\u6cd5\u3002", "motivation": "\u5927\u578b\u5efa\u7b51\u4e2d\u6709\u6548\u7684\u7535\u68af\u4ea4\u901a\u7ba1\u7406\u5bf9\u51cf\u5c11\u4e58\u5ba2\u65c5\u884c\u65f6\u95f4\u548c\u80fd\u6e90\u6d88\u8017\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u7684\u542f\u53d1\u5f0f\u6216\u6a21\u5f0f\u68c0\u6d4b\u63a7\u5236\u5668\u96be\u4ee5\u5e94\u5bf9\u6d3e\u9063\u4efb\u52a1\u7684\u968f\u673a\u6027\u548c\u7ec4\u5408\u6027\u8d28\u3002", "method": "\u5c06\u7535\u68af\u7cfb\u7edf\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08\u7279\u522b\u662fDueling Double Deep Q-learning\u67b6\u6784\uff09\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528\u4ee5\u4e0b\u5173\u952e\u521b\u65b0\uff1a\u65b0\u578b\u52a8\u4f5c\u7a7a\u95f4\u7f16\u7801\u3001\u5f15\u5165infra-steps\u4ee5\u6a21\u62df\u8fde\u7eed\u4e58\u5ba2\u5230\u8fbe\u3001\u5b9a\u5236\u5316\u5956\u52b1\u4fe1\u53f7\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u4ee5\u53ca\u63a2\u7d22\u4e0d\u540c\u7684\u6298\u6263\u56e0\u5b50\u9002\u5e94\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684EGCS\u80fd\u591f\u9002\u5e94\u6ce2\u52a8\u7684\u4ea4\u901a\u6a21\u5f0f\uff0c\u4ece\u9ad8\u5ea6\u968f\u673a\u7684\u73af\u5883\u4e2d\u5b66\u4e60\uff0c\u5e76\u4e14\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7535\u68af\u7fa4\u63a7\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u7684\u7535\u68af\u8c03\u5ea6\u95ee\u9898\u4e0a\u5c55\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\uff0c\u672a\u6765\u53ef\u80fd\u8fdb\u4e00\u6b65\u4f18\u5316\u5927\u578b\u5efa\u7b51\u4e2d\u7684\u7535\u68af\u4ea4\u901a\u7ba1\u7406\u3002"}}
{"id": "2507.00260", "pdf": "https://arxiv.org/pdf/2507.00260", "abs": "https://arxiv.org/abs/2507.00260", "authors": ["Jin-Hong Du", "Kathryn Roeder", "Larry Wasserman"], "title": "Disentangled Feature Importance", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "26 main and 29 supplementary pages", "summary": "Feature importance quantification faces a fundamental challenge: when\npredictors are correlated, standard methods systematically underestimate their\ncontributions. We prove that major existing approaches target identical\npopulation functionals under squared-error loss, revealing why they share this\ncorrelation-induced bias.\n  To address this limitation, we introduce \\emph{Disentangled Feature\nImportance (DFI)}, a nonparametric generalization of the classical $R^2$\ndecomposition via optimal transport. DFI transforms correlated features into\nindependent latent variables using a transport map, eliminating correlation\ndistortion. Importance is computed in this disentangled space and attributed\nback through the transport map's sensitivity. DFI provides a principled\ndecomposition of importance scores that sum to the total predictive variability\nfor latent additive models and to interaction-weighted functional ANOVA\nvariances more generally, under arbitrary feature dependencies.\n  We develop a comprehensive semiparametric theory for DFI. For general\ntransport maps, we establish root-$n$ consistency and asymptotic normality of\nimportance estimators in the latent space, which extends to the original\nfeature space for the Bures-Wasserstein map. Notably, our estimators achieve\nsecond-order estimation error, which vanishes if both regression function and\ntransport map estimation errors are $o_{\\mathbb{P}}(n^{-1/4})$. By design, DFI\navoids the computational burden of repeated submodel refitting and the\nchallenges of conditional covariate distribution estimation, thereby achieving\ncomputational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7279\u5f81\u91cd\u8981\u6027\u91cf\u5316\u65b9\u6cd5Disentangled Feature Importance (DFI)\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u9762\u5bf9\u76f8\u5173\u9884\u6d4b\u53d8\u91cf\u65f6\u7cfb\u7edf\u6027\u4f4e\u4f30\u5176\u8d21\u732e\u7684\u95ee\u9898\u3002\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u7406\u8bba\uff0cDFI\u5c06\u76f8\u5173\u7279\u5f81\u8f6c\u6362\u4e3a\u72ec\u7acb\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u504f\u7684\u7279\u5f81\u91cd\u8981\u6027\u5206\u89e3\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u5f00\u53d1\u4e86DFI\u7684\u534a\u53c2\u6570\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u4f30\u8ba1\u91cf\u7684\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u7684\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u7279\u5f81\u91cd\u8981\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u5904\u7406\u76f8\u5173\u9884\u6d4b\u53d8\u91cf\u65f6\u5b58\u5728\u504f\u5dee\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u8fd9\u4e9b\u53d8\u91cf\u7684\u5b9e\u9645\u8d21\u732e\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u627e\u4e00\u79cd\u80fd\u591f\u6d88\u9664\u76f8\u5173\u6027\u5f71\u54cd\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86Disentangled Feature Importance (DFI) \u65b9\u6cd5\uff0c\u5229\u7528\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5c06\u76f8\u5173\u7279\u5f81\u8f6c\u5316\u4e3a\u72ec\u7acb\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u76f8\u5173\u6027\u5f15\u8d77\u7684\u504f\u5dee\u3002DFI\u57fa\u4e8e\u975e\u53c2\u6570\u7684 $R^2$ \u5206\u89e3\uff0c\u5e76\u901a\u8fc7\u4f20\u8f93\u56fe\u7684\u654f\u611f\u6027\u5c06\u91cd\u8981\u6027\u5f52\u56e0\u56de\u539f\u59cb\u7279\u5f81\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u53d1\u5c55\u4e86DFI\u7684\u534a\u53c2\u6570\u7406\u8bba\uff0c\u5206\u6790\u4e86\u4f30\u8ba1\u91cf\u5728\u6f5c\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u6839-$n$ \u4e00\u81f4\u6027\u4e0e\u6e10\u8fd1\u6b63\u6001\u6027\u3002", "result": "DFI \u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u7279\u5f81\u91cd\u8981\u6027\u5206\u89e3\uff0c\u8be5\u5206\u89e3\u53ef\u4ee5\u603b\u548c\u4e3a\u76ee\u6807\u9884\u6d4b\u53d8\u5316\u7684\u603b\u503c\u3002\u5bf9\u4e8e\u9690\u542b\u52a0\u6027\u6a21\u578b\uff0c\u5b83\u7b49\u4e8e\u4ea4\u4e92\u52a0\u6743\u7684\u529f\u80fdANOVA\u65b9\u5dee\u3002\u5e76\u4e14\uff0cDFI\u907f\u514d\u4e86\u91cd\u590d\u5b50\u6a21\u578b\u62df\u5408\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4ee5\u53ca\u6761\u4ef6\u534f\u53d8\u91cf\u5206\u5e03\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "DFI \u662f\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7279\u5f81\u76f8\u5173\u6027\u5bfc\u81f4\u7684\u7279\u5f81\u91cd\u8981\u6027\u4f4e\u4f30\u95ee\u9898\u3002\u5b83\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u65e0\u504f\u7684\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\uff0c\u8fd8\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e86\u4f30\u8ba1\u91cf\u7684\u826f\u597d\u6027\u8d28\u3002"}}
{"id": "2507.00008", "pdf": "https://arxiv.org/pdf/2507.00008", "abs": "https://arxiv.org/abs/2507.00008", "authors": ["Hang Wu", "Hongkai Chen", "Yujun Cai", "Chang Liu", "Qingwen Ye", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "categories": ["cs.AI", "cs.CV", "cs.HC"], "comment": "8 pages, 6 figures", "summary": "Grounding natural language queries in graphical user interfaces (GUIs) poses\nunique challenges due to the diversity of visual elements, spatial clutter, and\nthe ambiguity of language. In this paper, we introduce DiMo-GUI, a\ntraining-free framework for GUI grounding that leverages two core strategies:\ndynamic visual grounding and modality-aware optimization. Instead of treating\nthe GUI as a monolithic image, our method splits the input into textual\nelements and iconic elements, allowing the model to reason over each modality\nindependently using general-purpose vision-language models. When predictions\nare ambiguous or incorrect, DiMo-GUI dynamically focuses attention by\ngenerating candidate focal regions centered on the model's initial predictions\nand incrementally zooms into subregions to refine the grounding result. This\nhierarchical refinement process helps disambiguate visually crowded layouts\nwithout the need for additional training or annotations. We evaluate our\napproach on standard GUI grounding benchmarks and demonstrate consistent\nimprovements over baseline inference pipelines, highlighting the effectiveness\nof combining modality separation with region-focused reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiMo-GUI\u7684\u65e0\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8eGUI\u63a5\u5730\uff0c\u901a\u8fc7\u52a8\u6001\u89c6\u89c9\u63a5\u5730\u548c\u6a21\u6001\u611f\u77e5\u4f18\u5316\u7b56\u7565\u89e3\u51b3\u4e86\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5728GUI\u4e2d\u7684\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u5c06\u8f93\u5165\u5206\u4e3a\u6587\u672c\u5143\u7d20\u548c\u56fe\u6807\u5143\u7d20\uff0c\u5e76\u5229\u7528\u901a\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u72ec\u7acb\u63a8\u7406\u6bcf\u4e2a\u6a21\u6001\u3002\u901a\u8fc7\u751f\u6210\u5019\u9009\u7126\u70b9\u533a\u57df\u5e76\u9010\u6b65\u7f29\u653e\u5b50\u533a\u57df\u6765\u6539\u8fdb\u9884\u6d4b\u7ed3\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6GUI\u57fa\u51c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u63a8\u7406\u7ba1\u9053\u3002", "motivation": "\u7531\u4e8e\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4e2d\u89c6\u89c9\u5143\u7d20\u7684\u591a\u6837\u6027\u3001\u7a7a\u95f4\u6df7\u4e71\u4ee5\u53ca\u8bed\u8a00\u7684\u6a21\u7cca\u6027\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0eGUI\u7ed3\u5408\u5177\u6709\u72ec\u7279\u6311\u6218\u3002", "method": "DiMo-GUI\u91c7\u7528\u4e24\u79cd\u6838\u5fc3\u7b56\u7565\uff1a\u52a8\u6001\u89c6\u89c9\u63a5\u5730\u548c\u6a21\u6001\u611f\u77e5\u4f18\u5316\u3002\u5b83\u5c06GUI\u8f93\u5165\u5206\u4e3a\u6587\u672c\u5143\u7d20\u548c\u56fe\u6807\u5143\u7d20\uff0c\u5141\u8bb8\u6a21\u578b\u4f7f\u7528\u901a\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5bf9\u6bcf\u4e2a\u6a21\u6001\u72ec\u7acb\u8fdb\u884c\u63a8\u7406\u3002\u5f53\u9884\u6d4b\u4e0d\u660e\u786e\u6216\u9519\u8bef\u65f6\uff0cDiMo-GUI\u901a\u8fc7\u751f\u6210\u4ee5\u521d\u59cb\u9884\u6d4b\u4e3a\u4e2d\u5fc3\u7684\u5019\u9009\u7126\u70b9\u533a\u57df\u5e76\u9010\u6b65\u805a\u7126\u5b50\u533a\u57df\u6765\u6539\u8fdb\u7ed3\u679c\u3002", "result": "\u5728\u6807\u51c6GUI\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cDiMo-GUI\u5728\u57fa\u7ebf\u63a8\u7406\u7ba1\u9053\u4e0a\u6301\u7eed\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u6a21\u6001\u5206\u79bb\u548c\u533a\u57df\u5173\u6ce8\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "DiMo-GUI\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u8bad\u7ec3\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u52a8\u6001\u89c6\u89c9\u63a5\u5730\u548c\u6a21\u6001\u611f\u77e5\u4f18\u5316\u7b56\u7565\u89e3\u51b3GUI\u63a5\u5730\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2507.00012", "pdf": "https://arxiv.org/pdf/2507.00012", "abs": "https://arxiv.org/abs/2507.00012", "authors": ["Linfeng Ye", "Shayan Mohajer Hamidi", "En-hui Yang"], "title": "Towards Undistillable Models by Minimizing Conditional Mutual Information", "categories": ["cs.LG", "cs.AI", "E.4"], "comment": "27 pages, 6 figures, Transactions on Machine Learning Research", "summary": "A deep neural network (DNN) is said to be undistillable if, when used as a\nblack-box input-output teacher, it cannot be distilled through knowledge\ndistillation (KD). In this case, the distilled student (referred to as the\nknockoff student) does not outperform a student trained independently with\nlabel smoothing (LS student) in terms of prediction accuracy. To protect\nintellectual property of DNNs, it is desirable to build undistillable DNNs. To\nthis end, it is first observed that an undistillable DNN may have the trait\nthat each cluster of its output probability distributions in response to all\nsample instances with the same label should be highly concentrated to the\nextent that each cluster corresponding to each label should ideally collapse\ninto one probability distribution. Based on this observation and by measuring\nthe concentration of each cluster in terms of conditional mutual information\n(CMI), a new training method called CMI minimized (CMIM) method is proposed,\nwhich trains a DNN by jointly minimizing the conventional cross entropy (CE)\nloss and the CMI values of all temperature scaled clusters across the entire\ntemperature spectrum. The resulting CMIM model is shown, by extensive\nexperiments, to be undistillable by all tested KD methods existing in the\nliterature. That is, the knockoff students distilled by these KD methods from\nthe CMIM model underperform the respective LS students. In addition, the CMIM\nmodel is also shown to performs better than the model trained with the CE loss\nalone in terms of their own prediction accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aCMI\u6700\u5c0f\u5316\uff08CMIM\uff09\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u6700\u5c0f\u5316\u4f20\u7edf\u4ea4\u53c9\u71b5\uff08CE\uff09\u635f\u5931\u548c\u6240\u6709\u6e29\u5ea6\u7f29\u653e\u7c07\u7684\u6761\u4ef6\u4e92\u4fe1\u606f\uff08CMI\uff09\u503c\uff0c\u6784\u5efa\u4e0d\u53ef\u84b8\u998f\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528CMIM\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u5bf9\u6240\u6709\u6d4b\u8bd5\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u65b9\u6cd5\u90fd\u662f\u4e0d\u53ef\u84b8\u998f\u7684\uff0c\u5e76\u4e14\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u4ec5\u4f7f\u7528CE\u635f\u5931\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u4fdd\u62a4\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u7684\u77e5\u8bc6\u4ea7\u6743\uff0c\u5e0c\u671b\u6784\u5efa\u4e0d\u53ef\u84b8\u998f\u7684DNN\u3002\u89c2\u5bdf\u5230\u4e0d\u53ef\u84b8\u998f\u7684DNN\u5177\u6709\u5176\u8f93\u51fa\u6982\u7387\u5206\u5e03\u9ad8\u5ea6\u96c6\u4e2d\u7684\u7279\u6027\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u57fa\u4e8e\u6761\u4ef6\u4e92\u4fe1\u606f\uff08CMI\uff09\u6d4b\u91cf\u8fd9\u79cd\u96c6\u4e2d\u6027\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u79f0\u4e3aCMI\u6700\u5c0f\u5316\uff08CMIM\uff09\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u6700\u5c0f\u5316\u4f20\u7edf\u4ea4\u53c9\u71b5\uff08CE\uff09\u635f\u5931\u548c\u6240\u6709\u6e29\u5ea6\u7f29\u653e\u7c07\u7684\u6761\u4ef6\u4e92\u4fe1\u606f\uff08CMI\uff09\u503c\u6765\u8bad\u7ec3DNN\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528CMIM\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u5bf9\u6240\u6709\u6d4b\u8bd5\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u65b9\u6cd5\u90fd\u662f\u4e0d\u53ef\u84b8\u998f\u7684\uff0c\u5373\u4eceCMIM\u6a21\u578b\u4e2d\u84b8\u998f\u51fa\u7684\u5b66\u751f\u6a21\u578b\u6027\u80fd\u4e0d\u5982\u72ec\u7acb\u4f7f\u7528\u6807\u7b7e\u5e73\u6ed1\uff08LS\uff09\u8bad\u7ec3\u7684\u5b66\u751f\u6a21\u578b\u3002\u6b64\u5916\uff0cCMIM\u6a21\u578b\u5728\u81ea\u8eab\u7684\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u4e5f\u4f18\u4e8e\u4ec5\u4f7f\u7528CE\u635f\u5931\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "CMI\u6700\u5c0f\u5316\uff08CMIM\uff09\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6784\u5efa\u4e0d\u53ef\u84b8\u998f\u7684DNN\uff0c\u5e76\u4e14\u5728\u4fdd\u62a4\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2507.00298", "pdf": "https://arxiv.org/pdf/2507.00298", "abs": "https://arxiv.org/abs/2507.00298", "authors": ["Arkaprabha Ganguli", "Nesar Ramachandra", "Julie Bessac", "Emil Constantinescu"], "title": "Enhancing Interpretability in Generative Modeling: Statistically Disentangled Latent Spaces Guided by Generative Factors in Scientific Datasets", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This study addresses the challenge of statistically extracting generative\nfactors from complex, high-dimensional datasets in unsupervised or\nsemi-supervised settings. We investigate encoder-decoder-based generative\nmodels for nonlinear dimensionality reduction, focusing on disentangling\nlow-dimensional latent variables corresponding to independent physical factors.\nIntroducing Aux-VAE, a novel architecture within the classical Variational\nAutoencoder framework, we achieve disentanglement with minimal modifications to\nthe standard VAE loss function by leveraging prior statistical knowledge\nthrough auxiliary variables. These variables guide the shaping of the latent\nspace by aligning latent factors with learned auxiliary variables. We validate\nthe efficacy of Aux-VAE through comparative assessments on multiple datasets,\nincluding astronomical simulations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAux-VAE\u7684\u65b0\u67b6\u6784\uff0c\u5728\u7ecf\u5178\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6846\u67b6\u5185\uff0c\u901a\u8fc7\u8f85\u52a9\u53d8\u91cf\u5229\u7528\u5148\u9a8c\u7edf\u8ba1\u77e5\u8bc6\uff0c\u5bf9\u4f4e\u7ef4\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u89e3\u8026\uff0c\u9002\u7528\u4e8e\u590d\u6742\u9ad8\u7ef4\u6570\u636e\u96c6\u7684\u975e\u7ebf\u6027\u964d\u7ef4\u95ee\u9898\u3002", "motivation": "\u5728\u65e0\u76d1\u7763\u6216\u534a\u76d1\u7763\u73af\u5883\u4e0b\uff0c\u4ece\u590d\u6742\u3001\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7edf\u8ba1\u63d0\u53d6\u751f\u6210\u56e0\u7d20\u662f\u4e00\u4e2a\u6311\u6218\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7684\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u7528\u4e8e\u975e\u7ebf\u6027\u964d\u7ef4\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u89e3\u8026\u4e0e\u72ec\u7acb\u7269\u7406\u56e0\u7d20\u76f8\u5bf9\u5e94\u7684\u4f4e\u7ef4\u6f5c\u5728\u53d8\u91cf\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86Aux-VAE\uff08\u8f85\u52a9\u53d8\u91cf\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5728\u7ecf\u5178\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6846\u67b6\u5185\u7684\u65b0\u67b6\u6784\u3002\u901a\u8fc7\u5728\u6807\u51c6VAE\u635f\u5931\u51fd\u6570\u4e2d\u8fdb\u884c\u6700\u5c0f\u4fee\u6539\uff0c\u5e76\u5229\u7528\u8f85\u52a9\u53d8\u91cf\u5f15\u5165\u5148\u9a8c\u7edf\u8ba1\u77e5\u8bc6\uff0c\u4f7f\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u56e0\u5b50\u4e0e\u5b66\u4e60\u5230\u7684\u8f85\u52a9\u53d8\u91cf\u5bf9\u9f50\uff0c\u4ece\u800c\u5b9e\u73b0\u89e3\u8026\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u8bc4\u4f30\uff08\u5305\u62ec\u5929\u6587\u5b66\u6a21\u62df\u6570\u636e\uff09\uff0c\u9a8c\u8bc1\u4e86Aux-VAE\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5176\u80fd\u591f\u6210\u529f\u5b9e\u73b0\u6f5c\u5728\u53d8\u91cf\u7684\u89e3\u8026\u3002", "conclusion": "Aux-VAE\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b0\u578b\u67b6\u6784\uff0c\u80fd\u591f\u5728\u590d\u6742\u7684\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u89e3\u8026\u6f5c\u5728\u53d8\u91cf\uff0c\u4e3a\u975e\u7ebf\u6027\u964d\u7ef4\u548c\u751f\u6210\u6a21\u578b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.00041", "pdf": "https://arxiv.org/pdf/2507.00041", "abs": "https://arxiv.org/abs/2507.00041", "authors": ["Varun Mannam", "Fang Wang", "Chaochun Liu", "Xin Chen"], "title": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables", "categories": ["cs.AI", "cs.CV", "cs.IR"], "comment": "Submitted to KDD conference, workshop: Talent and Management\n  Computing (TMC 2025), https://tmcworkshop.github.io/2025/", "summary": "In talent management systems, critical information often resides in complex\ntabular formats, presenting significant retrieval challenges for conventional\nlanguage models. These challenges are pronounced when processing Talent\ndocumentation that requires precise interpretation of tabular relationships for\naccurate information retrieval and downstream decision-making. Current table\nextraction methods struggle with semantic understanding, resulting in poor\nperformance when integrated into retrieval-augmented chat applications. This\npaper identifies a key bottleneck - while structural table information can be\nextracted, the semantic relationships between tabular elements are lost,\ncausing downstream query failures. To address this, we introduce TalentMine, a\nnovel LLM-enhanced framework that transforms extracted tables into semantically\nenriched representations. Unlike conventional approaches relying on CSV or text\nlinearization, our method employs specialized multimodal reasoning to preserve\nboth structural and semantic dimensions of tabular data. Experimental\nevaluation across employee benefits document collections demonstrates\nTalentMine's superior performance, achieving 100% accuracy in query answering\ntasks compared to 0% for standard AWS Textract extraction and 40% for AWS\nTextract Visual Q&A capabilities. Our comparative analysis also reveals that\nthe Claude v3 Haiku model achieves optimal performance for talent management\napplications. The key contributions of this work include (1) a systematic\nanalysis of semantic information loss in current table extraction pipelines,\n(2) a novel LLM-based method for semantically enriched table representation,\n(3) an efficient integration framework for retrieval-augmented systems as\nend-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks\nshowing substantial improvements across multiple categories.", "AI": {"tldr": "The paper introduces TalentMine, a new framework enhancing LLMs to improve semantic understanding and retrieval of tabular data in talent management systems. It achieves 100% accuracy in query answering tasks, compared to 0% for standard AWS Textract and 40% for AWS Textract Visual Q&A.", "motivation": "Current table extraction methods struggle with semantic understanding, leading to poor performance when integrated into retrieval-augmented chat applications in talent management systems.", "method": "TalentMine, an LLM-enhanced framework that transforms extracted tables into semantically enriched representations using specialized multimodal reasoning to preserve both structural and semantic dimensions of tabular data.", "result": "Experimental evaluation shows TalentMine achieving 100% accuracy in query answering tasks, outperforming standard AWS Textract (0%) and AWS Textract Visual Q&A (40%).", "conclusion": "The key contributions include systematic analysis of semantic information loss, a novel LLM-based method for enriched table representation, an efficient integration framework, and comprehensive benchmarks showing significant improvements."}}
{"id": "2507.00013", "pdf": "https://arxiv.org/pdf/2507.00013", "abs": "https://arxiv.org/abs/2507.00013", "authors": ["Hyunwoo Seo", "Chiehyeon Lim"], "title": "ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted by KDD 2025 research track", "summary": "Forecasting complex time series is an important yet challenging problem that\ninvolves various industrial applications. Recently, masked time-series modeling\nhas been proposed to effectively model temporal dependencies for forecasting by\nreconstructing masked segments from unmasked ones. However, since the semantic\ninformation in time series is involved in intricate temporal variations\ngenerated by multiple time series components, simply masking a raw time series\nignores the inherent semantic structure, which may cause MTM to learn spurious\ntemporal patterns present in the raw data. To capture distinct temporal\nsemantics, we show that masked modeling techniques should address entangled\npatterns through a decomposition approach. Specifically, we propose ST-MTM, a\nmasked time-series modeling framework with seasonal-trend decomposition, which\nincludes a novel masking method for the seasonal-trend components that\nincorporates different temporal variations from each component. ST-MTM uses a\nperiod masking strategy for seasonal components to produce multiple masked\nseasonal series based on inherent multi-periodicity and a sub-series masking\nstrategy for trend components to mask temporal regions that share similar\nvariations. The proposed masking method presents an effective pre-training task\nfor learning intricate temporal variations and dependencies. Additionally,\nST-MTM introduces a contrastive learning task to support masked modeling by\nenhancing contextual consistency among multiple masked seasonal\nrepresentations. Experimental results show that our proposed ST-MTM achieves\nconsistently superior forecasting performance compared to existing masked\nmodeling, contrastive learning, and supervised forecasting methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6ST-MTM\uff0c\u901a\u8fc7\u5b63\u8282-\u8d8b\u52bf\u5206\u89e3\u548c\u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\uff0c\u6709\u6548\u6355\u6349\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5\u7b80\u5355\u5c4f\u853d\u539f\u59cb\u6570\u636e\u53ef\u80fd\u6355\u83b7\u865a\u5047\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u5ffd\u7565\u4e86\u590d\u6742\u7684\u8bed\u4e49\u7ed3\u6784\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5206\u89e3\u5e76\u5904\u7406\u7ea0\u7f20\u6a21\u5f0f\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u6355\u6349\u65f6\u95f4\u8bed\u4e49\u3002", "method": "\u63d0\u51faST-MTM\u6846\u67b6\uff0c\u5305\u62ec\uff1a1) \u5b63\u8282-\u8d8b\u52bf\u5206\u89e3\uff1b2) \u65b0\u578b\u5c4f\u853d\u7b56\u7565\uff08\u5468\u671f\u5c4f\u853d\u7528\u4e8e\u5b63\u8282\u6210\u5206\uff0c\u5b50\u5e8f\u5217\u5c4f\u853d\u7528\u4e8e\u8d8b\u52bf\u6210\u5206\uff09\uff1b3) \u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\u4ee5\u589e\u5f3a\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cST-MTM\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u5c4f\u853d\u5efa\u6a21\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u76d1\u7763\u9884\u6d4b\u65b9\u6cd5\u3002", "conclusion": "ST-MTM\u901a\u8fc7\u5206\u89e3\u548c\u5c4f\u853d\u7b56\u7565\u6709\u6548\u6355\u6349\u590d\u6742\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.00402", "pdf": "https://arxiv.org/pdf/2507.00402", "abs": "https://arxiv.org/abs/2507.00402", "authors": ["Suqing Liu", "Xuan Bi", "Tianxi Li"], "title": "GRAND: Graph Release with Assured Node Differential Privacy", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Differential privacy is a well-established framework for safeguarding\nsensitive information in data. While extensively applied across various\ndomains, its application to network data -- particularly at the node level --\nremains underexplored. Existing methods for node-level privacy either focus\nexclusively on query-based approaches, which restrict output to pre-specified\nnetwork statistics, or fail to preserve key structural properties of the\nnetwork. In this work, we propose GRAND (Graph Release with Assured Node\nDifferential privacy), which is, to the best of our knowledge, the first\nnetwork release mechanism that releases entire networks while ensuring\nnode-level differential privacy and preserving structural properties. Under a\nbroad class of latent space models, we show that the released network\nasymptotically follows the same distribution as the original network. The\neffectiveness of the approach is evaluated through extensive experiments on\nboth synthetic and real-world datasets.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGRAND\u7684\u65b0\u65b9\u6cd5\uff0c\u8fd9\u662f\u636e\u4f5c\u8005\u6240\u77e5\u7b2c\u4e00\u4e2a\u80fd\u591f\u5728\u786e\u4fdd\u8282\u70b9\u7ea7\u5dee\u5206\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u7559\u7ed3\u6784\u5c5e\u6027\u5e76\u53d1\u5e03\u6574\u4e2a\u7f51\u7edc\u7684\u673a\u5236\u3002\u901a\u8fc7\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5dee\u5206\u9690\u79c1\u5728\u8bb8\u591a\u9886\u57df\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u7f51\u7edc\u6570\u636e\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u8282\u70b9\u7ea7\u522b\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u4ecd\u7136\u6ca1\u6709\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u73b0\u6709\u7684\u8282\u70b9\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u8981\u4e48\u4ec5\u5173\u6ce8\u67e5\u8be2\u65b9\u6cd5\uff0c\u9650\u5236\u8f93\u51fa\u5230\u9884\u5b9a\u4e49\u7684\u7f51\u7edc\u7edf\u8ba1\u4fe1\u606f\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u7559\u7f51\u7edc\u7684\u5173\u952e\u7ed3\u6784\u5c5e\u6027\u3002", "method": "\u63d0\u51fa\u4e86GRAND\uff08Graph Release with Assured Node Differential privacy\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u53d1\u5e03\u673a\u5236\uff0c\u8be5\u673a\u5236\u53ef\u4ee5\u53d1\u5e03\u6574\u4e2a\u7f51\u7edc\uff0c\u540c\u65f6\u786e\u4fdd\u8282\u70b9\u7ea7\u522b\u7684\u5dee\u5206\u9690\u79c1\u5e76\u4fdd\u7559\u7ed3\u6784\u5c5e\u6027\u3002\u5728\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u7684\u4e00\u822c\u7c7b\u522b\u4e0b\uff0c\u5c55\u793a\u4e86\u53d1\u5e03\u7684\u7f51\u7edc\u6e10\u8fd1\u5730\u9075\u5faa\u4e0e\u539f\u59cb\u7f51\u7edc\u76f8\u540c\u7684\u5206\u5e03\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff08\u5305\u62ec\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff09\u9a8c\u8bc1\u4e86GRAND\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "GRAND\u662f\u9996\u4e2a\u80fd\u591f\u786e\u4fdd\u8282\u70b9\u7ea7\u522b\u5dee\u5206\u9690\u79c1\u5e76\u4fdd\u7559\u7f51\u7edc\u7ed3\u6784\u7279\u6027\u7684\u7f51\u7edc\u53d1\u5e03\u673a\u5236\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\uff0c\u5e76\u4e14\u5176\u6709\u6548\u6027\u5f97\u5230\u4e86\u5b9e\u9a8c\u8bc1\u660e\u3002"}}
{"id": "2507.00048", "pdf": "https://arxiv.org/pdf/2507.00048", "abs": "https://arxiv.org/abs/2507.00048", "authors": ["Thomas M. Deucher", "Juan C. Verduzco", "Michael Titus", "Alejandro Strachan"], "title": "A collaborative digital twin built on FAIR data and compute infrastructure", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CE", "cs.LG"], "comment": "10 pages, 5 figures", "summary": "The integration of machine learning with automated experimentation in\nself-driving laboratories (SDL) offers a powerful approach to accelerate\ndiscovery and optimization tasks in science and engineering applications. When\nsupported by findable, accessible, interoperable, and reusable (FAIR) data\ninfrastructure, SDLs with overlapping interests can collaborate more\neffectively. This work presents a distributed SDL implementation built on\nnanoHUB services for online simulation and FAIR data management. In this\nframework, geographically dispersed collaborators conducting independent\noptimization tasks contribute raw experimental data to a shared central\ndatabase. These researchers can then benefit from analysis tools and machine\nlearning models that automatically update as additional data become available.\nNew data points are submitted through a simple web interface and automatically\nprocessed using a nanoHUB Sim2L, which extracts derived quantities and indexes\nall inputs and outputs in a FAIR data repository called ResultsDB. A separate\nnanoHUB workflow enables sequential optimization using active learning, where\nresearchers define the optimization objective, and machine learning models are\ntrained on-the-fly with all existing data, guiding the selection of future\nexperiments. Inspired by the concept of ``frugal twin\", the optimization task\nseeks to find the optimal recipe to combine food dyes to achieve the desired\ntarget color. With easily accessible and inexpensive materials, researchers and\nstudents can set up their own experiments, share data with collaborators, and\nexplore the combination of FAIR data, predictive ML models, and sequential\noptimization. The tools introduced are generally applicable and can easily be\nextended to other optimization problems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e nanoHUB \u670d\u52a1\u7684\u5206\u5e03\u5f0f\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u5b9e\u73b0\u65b9\u6848\uff0c\u7528\u4e8e\u5728\u7ebf\u6a21\u62df\u548c FAIR \u6570\u636e\u7ba1\u7406\u3002\u901a\u8fc7\u5171\u4eab\u4e2d\u5fc3\u6570\u636e\u5e93\u548c\u81ea\u52a8\u66f4\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8fdb\u884c\u4f18\u5316\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u987a\u5e8f\u4f18\u5316\u65b9\u6cd5\u627e\u5230\u6700\u4f73\u5b9e\u9a8c\u6761\u4ef6\u3002\u4ee5\u5bfb\u627e\u6700\u4f73\u98df\u7528\u8272\u7d20\u6df7\u5408\u6bd4\u4f8b\u4e3a\u76ee\u6807\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u7ed3\u5408 FAIR \u6570\u636e\u3001\u9884\u6d4b\u6027\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u987a\u5e8f\u4f18\u5316\u6765\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002", "motivation": "\u5c06\u673a\u5668\u5b66\u4e60\u4e0e\u81ea\u52a8\u5316\u5b9e\u9a8c\u76f8\u7ed3\u5408\u7684\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u80fd\u591f\u52a0\u901f\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u7684\u53d1\u73b0\u4e0e\u4f18\u5316\u4efb\u52a1\u3002\u7136\u800c\uff0c\u4e0d\u540c SDL \u4e4b\u95f4\u7684\u534f\u4f5c\u6548\u7387\u5f80\u5f80\u53d7\u9650\u4e8e\u6570\u636e\u5171\u4eab\u548c\u4e92\u64cd\u4f5c\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u652f\u6301 FAIR \u6570\u636e\u539f\u5219\u7684\u5206\u5e03\u5f0f SDL \u6846\u67b6\uff0c\u4fc3\u8fdb\u591a\u5730\u70b9\u72ec\u7acb\u4f18\u5316\u4efb\u52a1\u7684\u5408\u4f5c\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u63d0\u5347\u5b9e\u9a8c\u6548\u7387\u3002", "method": "1. \u6784\u5efa\u57fa\u4e8e nanoHUB \u7684\u5206\u5e03\u5f0f SDL \u7cfb\u7edf\uff0c\u5305\u542b\u5728\u7ebf\u6a21\u62df\u548c FAIR \u6570\u636e\u7ba1\u7406\u529f\u80fd\u3002\n2. \u4f7f\u7528\u5171\u4eab\u4e2d\u5fc3\u6570\u636e\u5e93\u5b58\u50a8\u6765\u81ea\u5730\u7406\u5206\u6563\u56e2\u961f\u7684\u539f\u59cb\u5b9e\u9a8c\u6570\u636e\u3002\n3. \u5229\u7528 nanoHUB Sim2L \u5de5\u5177\u81ea\u52a8\u5904\u7406\u65b0\u6570\u636e\u70b9\uff0c\u63d0\u53d6\u884d\u751f\u91cf\u5e76\u5c06\u6240\u6709\u8f93\u5165\u8f93\u51fa\u7d22\u5f15\u5230 ResultsDB \u4e2d\u3002\n4. \u5f15\u5165\u987a\u5e8f\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u6307\u5bfc\u672a\u6765\u5b9e\u9a8c\u8bbe\u8ba1\u3002\n5. \u501f\u52a9\u201c\u8282\u4fed\u5b6a\u751f\u201d\u6982\u5ff5\uff0c\u4ee5\u4f18\u5316\u98df\u7528\u8272\u7d20\u6df7\u5408\u6bd4\u4f8b\u8fbe\u5230\u76ee\u6807\u989c\u8272\u4e3a\u6848\u4f8b\u5c55\u793a\u6846\u67b6\u7684\u5e94\u7528\u6f5c\u529b\u3002", "result": "\u8be5\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f SDL \u534f\u4f5c\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u8f7b\u677e\u63d0\u4ea4\u548c\u5904\u7406\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b9e\u65f6\u4f18\u5316\u5b9e\u9a8c\u8bbe\u8ba1\u3002\u5728\u98df\u7528\u8272\u7d20\u4f18\u5316\u6848\u4f8b\u4e2d\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86 FAIR \u6570\u636e\u539f\u5219\u5bf9\u79d1\u5b66\u7814\u7a76\u7684\u652f\u6301\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u5206\u5e03\u5f0f SDL \u5b9e\u73b0\u65b9\u6848\u4e3a\u8de8\u5730\u57df\u79d1\u7814\u5408\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u900f\u660e\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u7ed3\u5408 FAIR \u6570\u636e\u7ba1\u7406\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5b9e\u9a8c\u6548\u7387\uff0c\u8fd8\u4e3a\u5176\u4ed6\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u6613\u6269\u5c55\u7684\u5de5\u5177\u3002"}}
{"id": "2507.00014", "pdf": "https://arxiv.org/pdf/2507.00014", "abs": "https://arxiv.org/abs/2507.00014", "authors": ["Thomas Joshi", "Shayan Chowdhury", "Fatih Uysal"], "title": "SWE-Bench-CL: Continual Learning for Coding Agents", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive results on static\ncode-generation benchmarks, but real-world software development unfolds as a\ncontinuous stream of evolving issues, fixes, and feature requests. We introduce\nSWE-Bench-CL, a novel continual learning benchmark built on the human-verified\nSWE-Bench Verified dataset introduced by OpenAI and Princeton-NLP in 2024. By\norganizing GitHub issues into chronologically ordered sequences that reflect\nnatural repository evolution, SWE-Bench-CL enables direct evaluation of an\nagent's ability to accumulate experience, transfer knowledge across tasks, and\nresist catastrophic forgetting. We complement the dataset with (i) a\npreliminary analysis of inter-task structural similarity and contextual\nsensitivity, (ii) an interactive LangGraph-based evaluation framework augmented\nwith a FAISS-backed semantic memory module, and (iii) a suite of specialized\ncontinual learning metrics -- including average accuracy, forgetting,\nforward/backward transfer, tool-use efficiency, and a generalized Composite\nContinual Learning Score and CL-F-beta score -- to capture the\nstability-plasticity trade-off. We outline a rigorous experimental protocol\ncomparing memory-enabled and memory-disabled agents across diverse Python\nrepositories. All code and data are publicly available at\nhttps://github.com/thomasjoshi/agents-never-forget, providing the community\nwith a reproducible platform for developing more adaptive and robust AI agents\nin software engineering.", "AI": {"tldr": "SWE-Bench-CL\u662f\u4e00\u4e2a\u57fa\u4e8eGitHub\u8bae\u9898\u7684\u8fde\u7eed\u5b66\u4e60\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u5305\u62ec\u7ecf\u9a8c\u79ef\u7d2f\u3001\u77e5\u8bc6\u8fc1\u79fb\u548c\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u3002\u7814\u7a76\u5f15\u5165\u4e86\u4e13\u95e8\u7684\u5ea6\u91cf\u6807\u51c6\u548c\u5b9e\u9a8c\u534f\u8bae\uff0c\u5e76\u63d0\u4f9b\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u548c\u4ee3\u7801\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9759\u6001\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u662f\u4e00\u4e2a\u4e0d\u65ad\u6f14\u5316\u7684\u8fc7\u7a0b\uff0c\u6d89\u53ca\u95ee\u9898\u3001\u4fee\u590d\u548c\u529f\u80fd\u8bf7\u6c42\u3002\u4e3a\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u80fd\u529b\uff0c\u9700\u8981\u4e00\u4e2a\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u5f00\u53d1\u7684\u8fde\u7eed\u5b66\u4e60\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aSWE-Bench-CL\u7684\u65b0\u578b\u8fde\u7eed\u5b66\u4e60\u57fa\u51c6\uff0c\u4f7f\u7528\u4eba\u7c7b\u9a8c\u8bc1\u8fc7\u7684SWE-Bench Verified\u6570\u636e\u96c6\u3002\u901a\u8fc7\u6309\u65f6\u95f4\u987a\u5e8f\u7ec4\u7ec7GitHub\u8bae\u9898\uff0c\u6a21\u62df\u81ea\u7136\u7684\u4ed3\u5e93\u6f14\u5316\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4efb\u52a1\u95f4\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u7684\u521d\u6b65\u5206\u6790\uff0c\u4ee5\u53ca\u57fa\u4e8eLangGraph\u7684\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6\u548cFAISS\u652f\u6301\u7684\u8bed\u4e49\u8bb0\u5fc6\u6a21\u5757\u3002\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u4e13\u95e8\u7684\u8fde\u7eed\u5b66\u4e60\u5ea6\u91cf\u6307\u6807\uff0c\u5982\u5e73\u5747\u51c6\u786e\u6027\u3001\u9057\u5fd8\u7a0b\u5ea6\u3001\u524d/\u540e\u5411\u8f6c\u79fb\u7b49\u3002", "result": "\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u5b9e\u9a8c\u534f\u8bae\uff0c\u6bd4\u8f83\u4e86\u5177\u6709\u548c\u4e0d\u5177\u6709\u8bb0\u5fc6\u529f\u80fd\u7684\u4ee3\u7406\u5728\u4e0d\u540cPython\u4ed3\u5e93\u4e0a\u7684\u8868\u73b0\u3002\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u90fd\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u5e73\u53f0\uff0c\u4ee5\u5f00\u53d1\u66f4\u5177\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u7684AI\u4ee3\u7406\u3002", "conclusion": "SWE-Bench-CL\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbAI\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u548c\u57fa\u51c6\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u8bb0\u5fc6\u548c\u77e5\u8bc6\u8fc1\u79fb\u5728\u52a8\u6001\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.00640", "pdf": "https://arxiv.org/pdf/2507.00640", "abs": "https://arxiv.org/abs/2507.00640", "authors": ["Denis Belomestny", "John. Schoenmakers"], "title": "Forward Reverse Kernel Regression for the Schr\u00f6dinger bridge problem", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "90C40, 65C05, 62G08"], "comment": null, "summary": "In this paper, we study the Schr\\\"odinger Bridge Problem (SBP), which is\ncentral to entropic optimal transport. For general reference processes and\nbegin--endpoint distributions, we propose a forward-reverse iterative Monte\nCarlo procedure to approximate the Schr\\\"odinger potentials in a nonparametric\nway. In particular, we use kernel based Monte Carlo regression in the context\nof Picard iteration of a corresponding fixed point problem. By preserving in\nthe iteration positivity and contractivity in a Hilbert metric sense, we\ndevelop a provably convergent algorithm. Furthermore, we provide convergence\nrates for the potential estimates and prove their optimality. Finally, as an\napplication, we propose a non-nested Monte Carlo procedure for the final\ndimensional distributions of the Schr\\\"odinger Bridge process, based on the\nconstructed potentials and the forward-reverse simulation method for\nconditional diffusions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86Schr\u00f6dinger\u6865\u95ee\u9898(SBP)\uff0c\u5b83\u662f\u71b5\u6700\u4f18\u4f20\u8f93\u7684\u6838\u5fc3\u3002\u5bf9\u4e8e\u4e00\u822c\u7684\u53c2\u8003\u8fc7\u7a0b\u548c\u8d77\u59cb-\u7ec8\u70b9\u5206\u5e03\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u524d\u5411-\u53cd\u5411\u8fed\u4ee3Monte Carlo\u8fc7\u7a0b\uff0c\u4ee5\u975e\u53c2\u6570\u65b9\u5f0f\u903c\u8fd1Schr\u00f6dinger\u52bf\u80fd\u3002\u7279\u522b\u5730\uff0c\u5728\u76f8\u5e94\u4e0d\u52a8\u70b9\u95ee\u9898\u7684Picard\u8fed\u4ee3\u4e2d\u4f7f\u7528\u57fa\u4e8e\u6838\u7684Monte Carlo\u56de\u5f52\u3002\u901a\u8fc7\u5728\u8fed\u4ee3\u4e2d\u4fdd\u6301Hilbert\u5ea6\u91cf\u610f\u4e49\u4e0a\u7684\u6b63\u6027\u548c\u6536\u7f29\u6027\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u8bc1\u660e\u6536\u655b\u7684\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u63d0\u4f9b\u4e86\u52bf\u80fd\u4f30\u8ba1\u7684\u6536\u655b\u901f\u5ea6\u5e76\u8bc1\u660e\u4e86\u5176\u6700\u4f18\u6027\u3002\u6700\u540e\uff0c\u4f5c\u4e3a\u5e94\u7528\uff0c\u57fa\u4e8e\u6784\u9020\u7684\u52bf\u80fd\u548c\u6761\u4ef6\u6269\u6563\u7684\u524d\u5411-\u53cd\u5411\u6a21\u62df\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u5d4c\u5957Monte Carlo\u8fc7\u7a0b\uff0c\u7528\u4e8eSchr\u00f6dinger\u6865\u8fc7\u7a0b\u7684\u6700\u7ec8\u7ef4\u5206\u5e03\u3002", "motivation": "Schr\u00f6dinger\u6865\u95ee\u9898\u662f\u71b5\u6700\u4f18\u4f20\u8f93\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u4f20\u8f93\u8fc7\u7a0b\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u5730\u5904\u7406\u4e00\u822c\u53c2\u8003\u8fc7\u7a0b\u548c\u8d77\u59cb-\u7ec8\u70b9\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u51c6\u786e\u5730\u903c\u8fd1Schr\u00f6dinger\u52bf\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u524d\u5411-\u53cd\u5411\u8fed\u4ee3Monte Carlo\u8fc7\u7a0b\uff0c\u7ed3\u5408\u57fa\u4e8e\u6838\u7684Monte Carlo\u56de\u5f52\u548cPicard\u8fed\u4ee3\u65b9\u6cd5\uff0c\u4ee5\u975e\u53c2\u6570\u65b9\u5f0f\u903c\u8fd1Schr\u00f6dinger\u52bf\u80fd\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u4fdd\u6301\u8fed\u4ee3\u4e2d\u7684\u6b63\u6027\u548c\u6536\u7f29\u6027\uff0c\u786e\u4fdd\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u52bf\u80fd\u4f30\u8ba1\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u4f18\u6027\u8bc1\u660e\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u6784\u9020\u7684\u52bf\u80fd\u548c\u6761\u4ef6\u6269\u6563\u7684\u524d\u5411-\u53cd\u5411\u6a21\u62df\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u5d4c\u5957Monte Carlo\u8fc7\u7a0b\uff0c\u7528\u4e8eSchr\u00f6dinger\u6865\u8fc7\u7a0b\u7684\u6700\u7ec8\u7ef4\u5206\u5e03\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u903c\u8fd1Schr\u00f6dinger\u52bf\u80fd\uff0c\u5e76\u4e14\u7b97\u6cd5\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6536\u655b\u6027\u3002\u63d0\u4f9b\u7684\u52bf\u80fd\u4f30\u8ba1\u6536\u655b\u901f\u5ea6\u8bc1\u660e\u4e86\u5176\u6700\u4f18\u6027\u3002\u63d0\u51fa\u7684\u975e\u5d4c\u5957Monte Carlo\u8fc7\u7a0b\u53ef\u4ee5\u51c6\u786e\u6a21\u62dfSchr\u00f6dinger\u6865\u8fc7\u7a0b\u7684\u6700\u7ec8\u7ef4\u5206\u5e03\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3Schr\u00f6dinger\u6865\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u524d\u5411-\u53cd\u5411\u8fed\u4ee3Monte Carlo\u8fc7\u7a0b\u548c\u57fa\u4e8e\u6838\u7684Monte Carlo\u56de\u5f52\uff0c\u4ee5\u975e\u53c2\u6570\u65b9\u5f0f\u903c\u8fd1Schr\u00f6dinger\u52bf\u80fd\u3002\u6b64\u65b9\u6cd5\u4e0d\u4ec5\u4fdd\u8bc1\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u8fd8\u8bc1\u660e\u4e86\u52bf\u80fd\u4f30\u8ba1\u7684\u6700\u4f18\u6027\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u7684\u5e94\u7528\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u6a21\u62dfSchr\u00f6dinger\u6865\u8fc7\u7a0b\u7684\u6700\u7ec8\u7ef4\u5206\u5e03\u3002"}}
{"id": "2507.00050", "pdf": "https://arxiv.org/pdf/2507.00050", "abs": "https://arxiv.org/abs/2507.00050", "authors": ["Devin Y. De Silva", "Sandareka Wickramanayake", "Dulani Meedeniya", "Sanka Rasnayaka"], "title": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network", "categories": ["cs.AI", "cs.HC", "cs.LG", "I.2.0"], "comment": null, "summary": "Human Activity Recognition (HAR), which uses data from Inertial Measurement\nUnit (IMU) sensors, has many practical applications in healthcare and assisted\nliving environments. However, its use in real-world scenarios has been limited\nby the lack of comprehensive IMU-based HAR datasets that cover a wide range of\nactivities and the lack of transparency in existing HAR models. Zero-shot HAR\n(ZS-HAR) overcomes the data limitations, but current models struggle to explain\ntheir decisions, making them less transparent. This paper introduces a novel\nIMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity\nRecognition Network (SEZ-HARN). It can recognize activities not encountered\nduring training and provide skeleton videos to explain its decision-making\nprocess. We evaluate the effectiveness of the proposed SEZ-HARN on four\nbenchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its\nperformance against three state-of-the-art black-box ZS-HAR models. The\nexperiment results demonstrate that SEZ-HARN produces realistic and\nunderstandable explanations while achieving competitive Zero-shot recognition\naccuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\\% of the\nbest-performing black-box model on PAMAP2 while maintaining comparable\nperformance on the other three datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684IMU-based\u96f6\u6837\u672c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6a21\u578bSEZ-HARN\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u672a\u5728\u8bad\u7ec3\u4e2d\u9047\u5230\u7684\u6d3b\u52a8\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u9aa8\u67b6\u89c6\u9891\u6765\u89e3\u91ca\u5176\u51b3\u7b56\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSEZ-HARN\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4e0e\u6700\u5148\u8fdb\u7684\u9ed1\u7bb1\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eIMU\u7684\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u6027\uff0c\u4e14\u73b0\u6709\u6570\u636e\u96c6\u8986\u76d6\u7684\u6d3b\u52a8\u8303\u56f4\u6709\u9650\uff0c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u96f6\u6837\u672cHAR\u867d\u7136\u514b\u670d\u4e86\u6570\u636e\u9650\u5236\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u96be\u4ee5\u89e3\u91ca\u5176\u51b3\u7b56\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u5177\u6709\u9ad8\u51c6\u786e\u7387\u53c8\u53ef\u89e3\u91ca\u7684\u96f6\u6837\u672cHAR\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86Self-Explainable Zero-shot Human Activity Recognition Network (SEZ-HARN)\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\uff1a1) \u8bc6\u522b\u672a\u5728\u8bad\u7ec3\u9636\u6bb5\u51fa\u73b0\u7684\u6d3b\u52a8\uff1b2) \u751f\u6210\u9aa8\u67b6\u89c6\u9891\u4ee5\u89e3\u91ca\u5176\u51b3\u7b56\u8fc7\u7a0b\u3002\u6a21\u578b\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6PAMAP2\u3001DaLiAc\u3001HTD-MHAD\u548cMHealth\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u9ed1\u7bb1\u96f6\u6837\u672cHAR\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "SEZ-HARN\u5728\u96f6\u6837\u672c\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u4e0e\u6700\u4f73\u9ed1\u7bb1\u6a21\u578b\u76f8\u5f53\uff0c\u5728PAMAP2\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u51c6\u786e\u6027\u4ec5\u76f8\u5dee3%\uff0c\u5e76\u5728\u5176\u4ed6\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u53ef\u6bd4\u6027\u80fd\u3002\u6b64\u5916\uff0cSEZ-HARN\u751f\u6210\u7684\u89e3\u91ca\u5177\u6709\u73b0\u5b9e\u6027\u548c\u53ef\u7406\u89e3\u6027\u3002", "conclusion": "SEZ-HARN\u6a21\u578b\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u96f6\u6837\u672c\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u4f9d\u636e\uff0c\u4e3a\u57fa\u4e8eIMU\u7684\u96f6\u6837\u672c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.00015", "pdf": "https://arxiv.org/pdf/2507.00015", "abs": "https://arxiv.org/abs/2507.00015", "authors": ["Lu Zhang", "Sangarapillai Lambotharan", "Gan Zheng", "Guisheng Liao", "Xuekang Liu", "Fabio Roli", "Carsten Maple"], "title": "Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The remarkable success of transformers across various fields such as natural\nlanguage processing and computer vision has paved the way for their\napplications in automatic modulation classification, a critical component in\nthe communication systems of Internet of Things (IoT) devices. However, it has\nbeen observed that transformer-based classification of radio signals is\nsusceptible to subtle yet sophisticated adversarial attacks. To address this\nissue, we have developed a defensive strategy for transformer-based modulation\nclassification systems to counter such adversarial attacks. In this paper, we\npropose a novel vision transformer (ViT) architecture by introducing a new\nconcept known as adversarial indicator (AdvI) token to detect adversarial\nattacks. To the best of our knowledge, this is the first work to propose an\nAdvI token in ViT to defend against adversarial attacks. Integrating an\nadversarial training method with a detection mechanism using AdvI token, we\ncombine a training time defense and running time defense in a unified neural\nnetwork model, which reduces architectural complexity of the system compared to\ndetecting adversarial perturbations using separate models. We investigate into\nthe operational principles of our method by examining the attention mechanism.\nWe show the proposed AdvI token acts as a crucial element within the ViT,\ninfluencing attention weights and thereby highlighting regions or features in\nthe input data that are potentially suspicious or anomalous. Through\nexperimental results, we demonstrate that our approach surpasses several\ncompetitive methods in handling white-box attack scenarios, including those\nutilizing the fast gradient method, projected gradient descent attacks and\nbasic iterative method.", "AI": {"tldr": "The paper proposes a novel vision transformer (ViT) architecture with an adversarial indicator (AdvI) token to defend against adversarial attacks in transformer-based modulation classification systems for IoT devices. It integrates adversarial training and detection mechanism, reduces system complexity, and surpasses several competitive methods in white-box attack scenarios.", "motivation": "Transformers have been successful in various fields, but they are susceptible to adversarial attacks in radio signal classification for IoT devices. There is a need for a defensive strategy to counter such attacks.", "method": "A new concept called adversarial indicator (AdvI) token is introduced in the ViT architecture. This is combined with adversarial training and a detection mechanism within a unified neural network model. The attention mechanism is examined to understand the operational principles.", "result": "The proposed AdvI token influences attention weights in the ViT, highlighting potentially suspicious or anomalous features in input data. Experimental results show that the approach outperforms several competitive methods in handling white-box attack scenarios.", "conclusion": "This work presents the first application of an AdvI token in ViT to defend against adversarial attacks. The integrated defense mechanism reduces architectural complexity and provides superior performance in white-box attack scenarios."}}
{"id": "2507.00894", "pdf": "https://arxiv.org/pdf/2507.00894", "abs": "https://arxiv.org/abs/2507.00894", "authors": ["Davide Adamo", "Marco Corneli", "Manon Vuillien", "Emmanuelle Vila"], "title": "An in depth look at the Procrustes-Wasserstein distance: properties and barycenters", "categories": ["stat.ML", "cs.LG"], "comment": "16 pages", "summary": "Due to its invariance to rigid transformations such as rotations and\nreflections, Procrustes-Wasserstein (PW) was introduced in the literature as an\noptimal transport (OT) distance, alternative to Wasserstein and more suited to\ntasks such as the alignment and comparison of point clouds. Having that\napplication in mind, we carefully build a space of discrete probability\nmeasures and show that over that space PW actually is a distance. Algorithms to\nsolve the PW problems already exist, however we extend the PW framework by\ndiscussing and testing several initialization strategies. We then introduce the\nnotion of PW barycenter and detail an algorithm to estimate it from the data.\nThe result is a new method to compute representative shapes from a collection\nof point clouds. We benchmark our method against existing OT approaches,\ndemonstrating superior performance in scenarios requiring precise alignment and\nshape preservation. We finally show the usefulness of the PW barycenters in an\narchaeological context. Our results highlight the potential of PW in boosting\n2D and 3D point cloud analysis for machine learning and computational geometry\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eProcrustes-Wasserstein (PW) \u8ddd\u79bb\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u70b9\u4e91\u96c6\u5408\u4e2d\u8ba1\u7b97\u4ee3\u8868\u6027\u5f62\u72b6\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u7cbe\u786e\u5bf9\u9f50\u548c\u5f62\u72b6\u4fdd\u7559\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u80fd\u4ee5\u53ca\u5728\u8003\u53e4\u5b66\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3Wasserstein\u8ddd\u79bb\u5728\u70b9\u4e91\u5bf9\u9f50\u548c\u6bd4\u8f83\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u5f15\u5165\u4e86\u5bf9\u521a\u6027\u53d8\u6362\uff08\u5982\u65cb\u8f6c\u548c\u53cd\u5c04\uff09\u5177\u6709\u4e0d\u53d8\u6027\u7684Procrustes-Wasserstein (PW) \u8ddd\u79bb\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u79bb\u6563\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\uff0c\u5728\u8be5\u7a7a\u95f4\u4e0a\u8bc1\u660e\u4e86PW\u5b9e\u9645\u4e0a\u662f\u4e00\u79cd\u8ddd\u79bb\uff1b\u6269\u5c55\u4e86PW\u6846\u67b6\uff0c\u8ba8\u8bba\u5e76\u6d4b\u8bd5\u4e86\u51e0\u79cd\u521d\u59cb\u5316\u7b56\u7565\uff1b\u5f15\u5165\u4e86PW\u91cd\u5fc3\u7684\u6982\u5ff5\uff0c\u5e76\u8be6\u7ec6\u63cf\u8ff0\u4e86\u4e00\u79cd\u4ece\u6570\u636e\u4e2d\u4f30\u8ba1\u5b83\u7684\u7b97\u6cd5\u3002", "result": "\u4e0e\u73b0\u6709\u7684\u6700\u4f18\u4f20\u8f93(OT)\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u9700\u8981\u7cbe\u786e\u5bf9\u9f50\u548c\u5f62\u72b6\u4fdd\u7559\u7684\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u8003\u53e4\u5b66\u80cc\u666f\u4e0b\u5c55\u793a\u4e86PW\u91cd\u5fc3\u7684\u5b9e\u9645\u7528\u9014\u3002", "conclusion": "Procrustes-Wasserstein\u8ddd\u79bb\u53ca\u5176\u76f8\u5173\u7b97\u6cd5\u5728\u63d0\u53472D\u548c3D\u70b9\u4e91\u5206\u6790\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u8ba1\u7b97\u51e0\u4f55\u9886\u57df\u3002"}}
{"id": "2507.00054", "pdf": "https://arxiv.org/pdf/2507.00054", "abs": "https://arxiv.org/abs/2507.00054", "authors": ["Shreyansh Padarha"], "title": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 Pages, 7 figures", "summary": "The push to compress and impart the proficiency of Large Language Models\n(LLMs) into more deployable and efficient Small Language Models (SLMs) has\nbenefited from improvements in knowledge distillation (KD) techniques. These\ntechniques allow a smaller student model to learn from a more capable and\nlarger teacher model's responses. However, distillation often revolves around\nthe student model merely copying the teacher's in-distribution responses,\nlimiting its generalisability. This limitation is amplified on reasoning tasks\nand can be computationally expensive. In this study, we propose AdvDistill, a\nreward-guided dataset distillation framework. We utilise multiple generations\n(responses) from a teacher for each prompt and assign rewards based on\nrule-based verifiers. These varying and normally distributed rewards serve as\nweights when training student models. Our methods and their subsequent\nbehavioural analysis demonstrate a significant improvement in student model\nperformance for mathematical and complex reasoning tasks, showcasing the\nefficacy and benefits of incorporating a rewarding mechanism in dataset\ndistillation processes.", "AI": {"tldr": "The study proposes AdvDistill, a reward-guided dataset distillation framework to enhance the performance of small language models (SLMs) in mathematical and complex reasoning tasks by using multiple teacher responses and rule-based verifiers.", "motivation": "To address the limitation of current knowledge distillation techniques where student models merely copy teacher's in-distribution responses, leading to poor generalisability especially in reasoning tasks.", "method": "Propose AdvDistill, a reward-guided dataset distillation framework that uses multiple generations from a teacher model for each prompt, assigns rewards based on rule-based verifiers, and uses these rewards as weights when training student models.", "result": "Significant improvement in student model performance for mathematical and complex reasoning tasks.", "conclusion": "AdvDistill demonstrates the efficacy and benefits of incorporating a rewarding mechanism in dataset distillation processes."}}
{"id": "2507.00016", "pdf": "https://arxiv.org/pdf/2507.00016", "abs": "https://arxiv.org/abs/2507.00016", "authors": ["Xuanbo Liu", "Liu Liu", "Fuxiang Wu", "Fusheng Hao", "Xianglong Liu"], "title": "Gradient-based Fine-Tuning through Pre-trained Model Regularization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Large pre-trained models have demonstrated extensive applications across\nvarious fields. However, fine-tuning these models for specific downstream tasks\ndemands significant computational resources and storage. One fine-tuning\nmethod, gradient-based parameter selection (GPS), focuses on fine-tuning only\nthe parameters with high gradients in each neuron, thereby reducing the number\nof training parameters. Nevertheless, this approach increases computational\nresource requirements and storage demands. In this paper, we propose an\nefficient gradient-based and regularized fine-tuning method (GRFT) that updates\nthe rows or columns of the weight matrix. We theoretically demonstrate that the\nrows or columns with the highest sum of squared gradients are optimal for\nupdating. This strategy effectively reduces storage overhead and improves the\nefficiency of parameter selection. Additionally, we incorporate regularization\nto enhance knowledge transfer from the pre-trained model. GRFT achieves\nstate-of-the-art performance, surpassing existing methods such as GPS, Adapter\nTuning, and LoRA. Notably, GRFT requires updating only 1.22% and 0.30% of the\ntotal parameters on FGVC and VTAB datasets, respectively, demonstrating its\nhigh efficiency and effectiveness. The source code will be released soon.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5GRFT\uff0c\u901a\u8fc7\u66f4\u65b0\u6743\u91cd\u77e9\u9635\u7684\u884c\u6216\u5217\u5e76\u7ed3\u5408\u6b63\u5219\u5316\uff0c\u51cf\u5c11\u4e86\u5b58\u50a8\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u63d0\u5347\u4e86\u5fae\u8c03\u6548\u7387\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5404\u4e2a\u9886\u57df\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\u3002\u7136\u800c\uff0c\u4e3a\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u8fd9\u4e9b\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u5b58\u50a8\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u53c2\u6570\u9009\u62e9\uff08GPS\uff09\u65b9\u6cd5\u867d\u7136\u51cf\u5c11\u4e86\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\uff0c\u4f46\u589e\u52a0\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u5b58\u50a8\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8e\u68af\u5ea6\u548c\u6b63\u5219\u5316\u7684\u5fae\u8c03\u65b9\u6cd5\uff08GRFT\uff09\uff0c\u8be5\u65b9\u6cd5\u66f4\u65b0\u6743\u91cd\u77e9\u9635\u7684\u884c\u6216\u5217\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5177\u6709\u6700\u9ad8\u5e73\u65b9\u68af\u5ea6\u548c\u7684\u884c\u6216\u5217\u662f\u6700\u4f18\u7684\u66f4\u65b0\u5bf9\u8c61\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u6709\u6548\u51cf\u5c11\u4e86\u5b58\u50a8\u5f00\u9500\uff0c\u8fd8\u63d0\u9ad8\u4e86\u53c2\u6570\u9009\u62e9\u7684\u6548\u7387\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5f15\u5165\u6b63\u5219\u5316\u589e\u5f3a\u4e86\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "GRFT\u5728FGVC\u548cVTAB\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53ea\u9700\u66f4\u65b01.22%\u548c0.30%\u7684\u603b\u53c2\u6570\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u65b9\u6cd5\u5982GPS\u3001Adapter Tuning\u548cLoRA\u3002", "conclusion": "GRFT\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5fae\u8c03\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5b58\u50a8\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u3002\u6e90\u4ee3\u7801\u5373\u5c06\u53d1\u5e03\u3002"}}
{"id": "2507.00079", "pdf": "https://arxiv.org/pdf/2507.00079", "abs": "https://arxiv.org/abs/2507.00079", "authors": ["Ethan Smyth", "Alessandro Suglia"], "title": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "categories": ["cs.AI", "cs.LG"], "comment": "website: https://esmyth-dev.github.io/VoyagerVision.github.io/", "summary": "Open-endedness is an active field of research in the pursuit of capable\nArtificial General Intelligence (AGI), allowing models to pursue tasks of their\nown choosing. Simultaneously, recent advancements in Large Language Models\n(LLMs) such as GPT-4o [9] have allowed such models to be capable of\ninterpreting image inputs. Implementations such as OMNI-EPIC [4] have made use\nof such features, providing an LLM with pixel data of an agent's POV to parse\nthe environment and allow it to solve tasks. This paper proposes that providing\nthese visual inputs to a model gives it greater ability to interpret spatial\nenvironments, and as such, can increase the number of tasks it can successfully\nperform, extending its open-ended potential. To this aim, this paper proposes\nVoyagerVision -- a multi-modal model capable of creating structures within\nMinecraft using screenshots as a form of visual feedback, building on the\nfoundation of Voyager. VoyagerVision was capable of creating an average of 2.75\nunique structures within fifty iterations of the system, as Voyager was\nincapable of this, it is an extension in an entirely new direction.\nAdditionally, in a set of building unit tests VoyagerVision was successful in\nhalf of all attempts in flat worlds, with most failures arising in more complex\nstructures. Project website is available at\nhttps://esmyth-dev.github.io/VoyagerVision.github.io/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVoyagerVision\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u4f7f\u7528\u622a\u56fe\u4f5c\u4e3a\u89c6\u89c9\u53cd\u9988\uff0c\u5728Minecraft\u4e2d\u521b\u5efa\u7ed3\u6784\uff0c\u6269\u5c55\u4e86Voyager\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5e73\u5766\u4e16\u754c\u4e2d\u7684\u6784\u5efa\u5355\u5143\u6d4b\u8bd5\u4e2d\u6210\u529f\u7387\u4e3a50\uff05\uff0c\u800c\u5728\u66f4\u590d\u6742\u7ed3\u6784\u4e2d\u5b58\u5728\u5931\u8d25\u60c5\u51b5\u3002", "motivation": "\u7814\u7a76\u5f00\u653e\u6027AI\uff08AGI\uff09\u9886\u57df\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8fdb\u6b65\uff0c\u63a2\u7d22\u63d0\u4f9b\u89c6\u89c9\u8f93\u5165\u7ed9\u6a21\u578b\u4ee5\u589e\u5f3a\u5176\u5bf9\u7a7a\u95f4\u73af\u5883\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u5347\u5176\u5b8c\u6210\u4efb\u52a1\u7684\u6570\u91cf\u548c\u5f00\u653e\u6027\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86VoyagerVision\u6a21\u578b\uff0c\u57fa\u4e8eVoyager\uff0c\u5229\u7528Minecraft\u4e2d\u7684\u622a\u56fe\u4f5c\u4e3a\u89c6\u89c9\u53cd\u9988\u6765\u521b\u5efa\u7ed3\u6784\u3002", "result": "VoyagerVision\u80fd\u591f\u572850\u6b21\u7cfb\u7edf\u8fed\u4ee3\u4e2d\u5e73\u5747\u521b\u5efa2.75\u4e2a\u72ec\u7279\u7684\u7ed3\u6784\uff1b\u5728\u5efa\u7b51\u5355\u5143\u6d4b\u8bd5\u4e2d\uff0c\u5b83\u5728\u5e73\u5766\u4e16\u754c\u4e2d\u7684\u6210\u529f\u7387\u4e3a50\uff05\uff0c\u4f46\u590d\u6742\u7684\u7ed3\u6784\u5bfc\u81f4\u4e86\u4e00\u4e9b\u5931\u8d25\u3002", "conclusion": "\u901a\u8fc7\u5c06\u89c6\u89c9\u8f93\u5165\u5f15\u5165\u6a21\u578b\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5176\u89e3\u91ca\u7a7a\u95f4\u73af\u5883\u7684\u80fd\u529b\uff0c\u589e\u52a0\u53ef\u6210\u529f\u6267\u884c\u7684\u4efb\u52a1\u6570\u91cf\uff0c\u8fdb\u4e00\u6b65\u62d3\u5c55\u4e86\u6a21\u578b\u7684\u5f00\u653e\u6027\u6f5c\u529b\u3002"}}
{"id": "2507.00018", "pdf": "https://arxiv.org/pdf/2507.00018", "abs": "https://arxiv.org/abs/2507.00018", "authors": ["Bo Wang", "Qinyuan Cheng", "Runyu Peng", "Rong Bao", "Peiji Li", "Qipeng Guo", "Linyang Li", "Zhiyuan Zeng", "Yunhua Zhou", "Xipeng Qiu"], "title": "Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Post-training processes are essential phases in grounding pre-trained\nlanguage models to real-world tasks, with learning from demonstrations or\npreference signals playing a crucial role in this adaptation. We present a\nunified theoretical framework bridging Supervised Fine-Tuning (SFT) and\npreference learning in Large Language Model (LLM) post-training. Through\nrigorous mathematical derivation, we demonstrate that both SFT and preference\nlearning methods like Direct Preference Optimization (DPO) operate within the\nsame optimal policy-reward subspace, with SFT representing a special case of\nimplicit reward learning. Our analysis reveals a critical limitation in\nconventional SFT: the KL divergence term in distribution matching becomes\nconstant with respect to the policy during optimization, failing to constrain\nmodel updates. To address this, we propose a simple yet effective learning rate\nreduction approach that yields significant performance improvements (up to\n\\textbf{25\\%} relative gain and \\textbf{6\\%} absolute win rate increase in\ninstruction following tasks. Additionally, we derive alternative SFT objectives\nfrom various f-divergence functions that preserve the KL term during\noptimization, further enhancing post-DPO model performance. Finally, we extend\nthe theoretical relationship between LLM logits and Q-functions from preference\nlearning to the SFT context, providing mathematical derivations and\nexperimental validation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u504f\u597d\u5b66\u4e60\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u63ed\u793a\u4e86SFT\u7684\u5c40\u9650\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u964d\u4f4e\u5b66\u4e60\u7387\u7684\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u4e0d\u540cf-\u6563\u5ea6\u51fd\u6570\u7684\u66ff\u4ee3SFT\u76ee\u6807\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u63a8\u5bfc\u4e86LLM logits\u4e0eQ\u51fd\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u5230\u5b9e\u9645\u4efb\u52a1\u65f6\uff0c\u4ece\u793a\u4f8b\u6216\u504f\u597d\u4fe1\u53f7\u4e2d\u5b66\u4e60\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684SFT\u65b9\u6cd5\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u4f8b\u5982KL\u6563\u5ea6\u9879\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u53d8\u5f97\u4e0e\u7b56\u7565\u65e0\u5173\uff0c\u65e0\u6cd5\u6709\u6548\u7ea6\u675f\u6a21\u578b\u66f4\u65b0\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u6df1\u5165\u5730\u7406\u89e3SFT\u548c\u504f\u597d\u5b66\u4e60\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u6539\u8fdb\u73b0\u6709\u7684SFT\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8fde\u63a5SFT\u548c\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\uff08\u5982DPO\uff09\uff0c\u5e76\u8bc1\u660e\u4e24\u8005\u90fd\u5728\u76f8\u540c\u7684\u6700\u4f18\u7b56\u7565-\u5956\u52b1\u5b50\u7a7a\u95f4\u4e2d\u8fd0\u884c\u3002\n2. \u5206\u6790\u4e86\u4f20\u7edfSFT\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff1aKL\u6563\u5ea6\u9879\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u53d8\u4e3a\u5e38\u6570\uff0c\u4e0d\u80fd\u7ea6\u675f\u6a21\u578b\u66f4\u65b0\u3002\n3. \u63d0\u51fa\u4e86\u964d\u4f4e\u5b66\u4e60\u7387\u7684\u7b80\u5355\u65b9\u6cd5\uff0c\u4ee5\u6539\u5584SFT\u6027\u80fd\u3002\n4. \u4ece\u4e0d\u540c\u7684f-\u6563\u5ea6\u51fd\u6570\u4e2d\u63a8\u5bfc\u51fa\u65b0\u7684SFT\u76ee\u6807\uff0c\u4fdd\u7559KL\u6563\u5ea6\u9879\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u3002\n5. \u6269\u5c55\u4e86\u504f\u597d\u5b66\u4e60\u4e2d\u5173\u4e8eLLM logits\u548cQ\u51fd\u6570\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u8bba\uff0c\u5e76\u63d0\u4f9b\u4e86\u6570\u5b66\u63a8\u5bfc\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u964d\u4f4e\u5b66\u4e60\u7387\u7684\u65b9\u6cd5\uff0c\u5728\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe25%\u7684\u76f8\u5bf9\u589e\u76ca\u548c6%\u7684\u7edd\u5bf9\u80dc\u7387\u63d0\u5347\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u4e0d\u540cf-\u6563\u5ea6\u51fd\u6570\u7684\u65b0SFT\u76ee\u6807\u4e5f\u663e\u8457\u63d0\u9ad8\u4e86\u540eDPO\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u548c\u6539\u8fdb\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8LLM\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a\u8fde\u63a5SFT\u548c\u504f\u597d\u5b66\u4e60\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4f20\u7edfSFT\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e9b\u6539\u8fdb\u4e0d\u4ec5\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u8fd8\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.00020", "pdf": "https://arxiv.org/pdf/2507.00020", "abs": "https://arxiv.org/abs/2507.00020", "authors": ["Marcio Borges", "Felipe Pereira", "Michel Tosin"], "title": "Variational Autoencoder for Generating Broader-Spectrum prior Proposals in Markov chain Monte Carlo Methods", "categories": ["cs.LG", "stat.ML"], "comment": "The main contribution of this work is to show the advantages of using\n  deep generative models like VAE to provide more flexible and versatile prior\n  distributions", "summary": "This study uses a Variational Autoencoder method to enhance the efficiency\nand applicability of Markov Chain Monte Carlo (McMC) methods by generating\nbroader-spectrum prior proposals. Traditional approaches, such as the\nKarhunen-Lo\\`eve Expansion (KLE), require previous knowledge of the covariance\nfunction, often unavailable in practical applications. The VAE framework\nenables a data-driven approach to flexibly capture a broader range of\ncorrelation structures in Bayesian inverse problems, particularly subsurface\nflow modeling. The methodology is tested on a synthetic groundwater flow\ninversion problem, where pressure data is used to estimate permeability fields.\nNumerical experiments demonstrate that the VAE-based parameterization achieves\ncomparable accuracy to KLE when the correlation length is known and outperforms\nKLE when the assumed correlation length deviates from the true value. Moreover,\nthe VAE approach significantly reduces stochastic dimensionality, improving\ncomputational efficiency. The results suggest that leveraging deep generative\nmodels in McMC methods can lead to more adaptable and efficient Bayesian\ninference in high-dimensional problems.", "AI": {"tldr": "This study enhances McMC methods using VAE for broader-spectrum prior proposals, achieving better performance in Bayesian inverse problems without requiring prior knowledge of covariance functions.", "motivation": "To improve the efficiency and applicability of McMC methods by overcoming limitations of traditional approaches like KLE that require prior knowledge of covariance functions.", "method": "A Variational Autoencoder (VAE) is used to generate prior proposals in Bayesian inverse problems, specifically tested in a synthetic groundwater flow inversion problem.", "result": "The VAE-based parameterization matches KLE's accuracy when correlation length is known and surpasses it when correlation length deviates. It also reduces stochastic dimensionality, enhancing computational efficiency.", "conclusion": "Using deep generative models such as VAE in McMC methods can lead to more adaptable and efficient Bayesian inference in high-dimensional problems."}}
{"id": "2507.00092", "pdf": "https://arxiv.org/pdf/2507.00092", "abs": "https://arxiv.org/abs/2507.00092", "authors": ["Basab Jha", "Firoj Paudel", "Ujjwal Puri", "Zhang Yuting", "Choi Donghyuk", "Wang Junhao"], "title": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "19 pages, 2 figures, 9 tables", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities at\nsolving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but\ntheir decision-making processes remain somewhat blackbox. We introduce\ntextbfinverse reasoning, a novel paradigm enabling LLMs to decompose and\nexplain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a\n4-billion-parameter reasoning model, employs a metacognitive structure that\nreflects back via attention processes to identify major decision points and\ngenerate explanations of reasoning choices. While typical CoT approaches are\ndirected towards forward reasoning generation, inverse reasoning provides\ninsight into why specific reasoning chains were selected over others. Through\nthorough testing of logical reasoning puzzles, math problems and ethical\ndilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we\ndemonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy\n(74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for\nits task, and offers performance almost on par with models like Claude-3.5\nSonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for\nLLM self-reflection via inverse reasoning, (ii) a novel metalearning framework\nto reverse the attention flow, (iii) comprehensive evaluation frameworks for\nreasoning transparency, and (iv) evidence that increasing reasoning using\ninverse reasoning improves interpretability along with reasoning performance.\nOur work creates new avenues for transparent AI systems and closes significant\ngaps in AI safety, education, and scientific discovery.", "AI": {"tldr": "SAGE-nano\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u9006\u5411\u63a8\u7406\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u53cd\u601d\u80fd\u529b\u53ca\u51b3\u7b56\u900f\u660e\u5ea6\uff0c\u5176\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u51b3\u7b56\u8fc7\u7a0b\u4ecd\u8f83\u4e3a\u9ed1\u7bb1\u5316\uff0c\u7f3a\u4e4f\u900f\u660e\u6027\u3002\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u4e86\u65b0\u7684\u65b9\u6cd5\u6765\u5206\u89e3\u548c\u89e3\u91ca\u6a21\u578b\u81ea\u8eab\u7684\u63a8\u7406\u94fe\u3002", "method": "\u63d0\u51fa\u4e86\u6587\u672c\u9006\u5411\u63a8\u7406\u65b9\u6cd5\uff0c\u7ed3\u5408\u5143\u8ba4\u77e5\u7ed3\u6784\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u8bc6\u522b\u5173\u952e\u51b3\u7b56\u70b9\u5e76\u751f\u6210\u63a8\u7406\u9009\u62e9\u7684\u89e3\u91ca\uff1b\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e40\u4ebf\u53c2\u6570\u7684SAGE-nano\u63a8\u7406\u6a21\u578b\u4e2d\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u6d4b\u8bd5\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "SAGE-nano\u5728\u63a8\u7406\u51c6\u786e\u6027\uff08AQUA-RAT\u6d4b\u8bd5\u4e2d\u8fbe74.6%\uff09\u548c\u89e3\u91ca\u8d28\u91cf\uff0892.1%\u7684\u4eba\u7c7b\u504f\u597d\u5f97\u5206\uff09\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u63a5\u8fd1Claude-3.5 Sonnet\u6216GPT-4o\u7b49\u5148\u8fdb\u6a21\u578b\u6c34\u5e73\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u53cd\u601d\u63d0\u4f9b\u4e86\u9996\u4e2a\u4e25\u8c28\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u9006\u5411\u63a8\u7406\u80fd\u591f\u63d0\u5347\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u900f\u660eAI\u7cfb\u7edf\u7684\u53d1\u5c55\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.00019", "pdf": "https://arxiv.org/pdf/2507.00019", "abs": "https://arxiv.org/abs/2507.00019", "authors": ["Minati Rath", "Hema Date"], "title": "Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": null, "summary": "In this study, we propose, evaluate and compare three quantum inspired data\nencoding strategies, Instance Level Strategy (ILS), Global Discrete Strategy\n(GDS) and Class Conditional Value Strategy (CCVS), for transforming classical\ndata into quantum data for use in pure classical machine learning models. The\nprimary objective is to reduce high encoding time while ensuring correct\nencoding values and analyzing their impact on classification performance. The\nInstance Level Strategy treats each row of dataset independently; mimics local\nquantum states. Global Discrete Value Based encoding strategy maps all unique\nfeature values across the full dataset to quantum states uniformly. In\ncontrast, the Class conditional Value based encoding strategy encodes unique\nvalues separately for each class, preserving class dependent information.\n  We apply these encoding strategies to a classification task and assess their\nimpact on en-coding efficiency, correctness, model accuracy, and computational\ncost. By analyzing the trade offs between encoding time, precision, and\npredictive performance, this study provides insights into optimizing quantum\ninspired data transformations for classical machine learning workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u79cd\u91cf\u5b50\u542f\u53d1\u7684\u6570\u636e\u7f16\u7801\u7b56\u7565\uff1a\u5b9e\u4f8b\u7ea7\u7b56\u7565\uff08ILS\uff09\u3001\u5168\u5c40\u79bb\u6563\u7b56\u7565\uff08GDS\uff09\u548c\u7c7b\u522b\u6761\u4ef6\u503c\u7b56\u7565\uff08CCVS\uff09\uff0c\u7528\u4e8e\u5c06\u7ecf\u5178\u6570\u636e\u8f6c\u6362\u4e3a\u91cf\u5b50\u6570\u636e\uff0c\u5e94\u7528\u4e8e\u7eaf\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u901a\u8fc7\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e94\u7528\u8fd9\u4e9b\u7b56\u7565\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u7f16\u7801\u6548\u7387\u3001\u6b63\u786e\u6027\u3001\u6a21\u578b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u4f18\u5316\u91cf\u5b50\u542f\u53d1\u6570\u636e\u8f6c\u6362\u7684\u89c1\u89e3\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11\u9ad8\u7f16\u7801\u65f6\u95f4\uff0c\u540c\u65f6\u786e\u4fdd\u6b63\u786e\u7684\u7f16\u7801\u503c\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u7f16\u7801\u7b56\u7565\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u91cf\u5b50\u542f\u53d1\u6570\u636e\u7f16\u7801\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u7f16\u7801\u7b56\u7565\uff1a1) \u5b9e\u4f8b\u7ea7\u7b56\u7565\uff08ILS\uff09\uff0c\u72ec\u7acb\u5904\u7406\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e00\u884c\uff0c\u6a21\u62df\u5c40\u90e8\u91cf\u5b50\u6001\uff1b2) \u5168\u5c40\u79bb\u6563\u503c\u7f16\u7801\u7b56\u7565\uff08GDS\uff09\uff0c\u5c06\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u6240\u6709\u552f\u4e00\u7684\u7279\u5f81\u503c\u5747\u5300\u6620\u5c04\u5230\u91cf\u5b50\u6001\uff1b3) \u7c7b\u522b\u6761\u4ef6\u503c\u7f16\u7801\u7b56\u7565\uff08CCVS\uff09\uff0c\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u7f16\u7801\u552f\u4e00\u503c\uff0c\u4fdd\u7559\u7c7b\u522b\u4f9d\u8d56\u4fe1\u606f\u3002", "result": "\u8fd9\u4e9b\u7b56\u7565\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u88ab\u5e94\u7528\uff0c\u7ed3\u679c\u8868\u660e\u4e0d\u540c\u7684\u7f16\u7801\u7b56\u7565\u5728\u7f16\u7801\u65f6\u95f4\u3001\u7cbe\u5ea6\u548c\u9884\u6d4b\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4f18\u5316\u91cf\u5b50\u542f\u53d1\u7684\u6570\u636e\u8f6c\u6362\u4ee5\u9002\u5e94\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.00025", "pdf": "https://arxiv.org/pdf/2507.00025", "abs": "https://arxiv.org/abs/2507.00025", "authors": ["Tiexin Qin", "Hong Yan", "Haoliang Li"], "title": "Generalizing to New Dynamical Systems via Frequency Domain Adaptation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted by TPAMI 2025", "summary": "Learning the underlying dynamics from data with deep neural networks has\nshown remarkable potential in modeling various complex physical dynamics.\nHowever, current approaches are constrained in their ability to make reliable\npredictions in a specific domain and struggle with generalizing to unseen\nsystems that are governed by the same general dynamics but differ in\nenvironmental characteristics. In this work, we formulate a parameter-efficient\nmethod, Fourier Neural Simulator for Dynamical Adaptation (FNSDA), that can\nreadily generalize to new dynamics via adaptation in the Fourier space.\nSpecifically, FNSDA identifies the shareable dynamics based on the known\nenvironments using an automatic partition in Fourier modes and learns to adjust\nthe modes specific for each new environment by conditioning on low-dimensional\nlatent systematic parameters for efficient generalization. We evaluate our\napproach on four representative families of dynamic systems, and the results\nshow that FNSDA can achieve superior or competitive generalization performance\ncompared to existing methods with a significantly reduced parameter cost. Our\ncode is available at https://github.com/WonderSeven/FNSDA.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0cFNSDA\uff08Fourier Neural Simulator for Dynamical Adaptation\uff09\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6f5c\u5728\u7684\u52a8\u529b\u5b66\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u5085\u91cc\u53f6\u7a7a\u95f4\u4e2d\u7684\u81ea\u9002\u5e94\u6765\u5b9e\u73b0\u5bf9\u65b0\u52a8\u529b\u5b66\u7684\u5feb\u901f\u6cdb\u5316\u3002FNSDA\u5229\u7528\u81ea\u52a8\u5212\u5206\u7684\u5085\u91cc\u53f6\u6a21\u5f0f\u8bc6\u522b\u53ef\u5171\u4eab\u7684\u52a8\u529b\u5b66\uff0c\u5e76\u901a\u8fc7\u6761\u4ef6\u4e8e\u4f4e\u7ef4\u6f5c\u5728\u7cfb\u7edf\u53c2\u6570\u6765\u8c03\u6574\u7279\u5b9a\u73af\u5883\u7684\u52a8\u529b\u5b66\u6a21\u5f0f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFNSDA\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u5bb6\u65cf\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u65b9\u6cd5\u5728\u7279\u5b9a\u9886\u57df\u5185\u7684\u9884\u6d4b\u80fd\u529b\u6709\u9650\uff0c\u5e76\u4e14\u96be\u4ee5\u6cdb\u5316\u5230\u5177\u6709\u76f8\u540c\u4e00\u822c\u52a8\u529b\u5b66\u4f46\u73af\u5883\u7279\u5f81\u4e0d\u540c\u7684\u672a\u89c1\u7cfb\u7edf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86FNSDA\uff08Fourier Neural Simulator for Dynamical Adaptation\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u6a21\u578b\u3002FNSDA\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5b9e\u73b0\u6cdb\u5316\uff1a1) \u4f7f\u7528\u81ea\u52a8\u5212\u5206\u7684\u5085\u91cc\u53f6\u6a21\u5f0f\u8bc6\u522b\u5df2\u77e5\u73af\u5883\u4e2d\u53ef\u5171\u4eab\u7684\u52a8\u529b\u5b66\uff1b2) \u6761\u4ef6\u4e8e\u4f4e\u7ef4\u6f5c\u5728\u7cfb\u7edf\u53c2\u6570\uff0c\u5b66\u4e60\u8c03\u6574\u7279\u5b9a\u4e8e\u6bcf\u4e2a\u65b0\u73af\u5883\u7684\u52a8\u529b\u5b66\u6a21\u5f0f\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5feb\u901f\u9002\u5e94\u65b0\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u3002", "result": "FNSDA\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u5bb6\u65cf\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u5b83\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u4f18\u8d8a\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u53c2\u6570\u6210\u672c\u3002\u8fd9\u8bc1\u660e\u4e86FNSDA\u5728\u6cdb\u5316\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "FNSDA\u662f\u4e00\u79cd\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002\u5176\u5728\u4e0d\u540c\u52a8\u529b\u5b66\u7cfb\u7edf\u4e0a\u7684\u6210\u529f\u5e94\u7528\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2507.00180", "pdf": "https://arxiv.org/pdf/2507.00180", "abs": "https://arxiv.org/abs/2507.00180", "authors": ["Vidhi Rathore"], "title": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modernizing legacy software systems is a critical but challenging task, often\nhampered by a lack of documentation and understanding of the original system's\nintricate decision logic. Traditional approaches like behavioral cloning merely\nreplicate input-output behavior without capturing the underlying intent. This\npaper proposes a novel pipeline to automatically extract interpretable decision\nlogic from legacy systems treated as black boxes. The approach uses a\nReinforcement Learning (RL) agent to explore the input space and identify\ncritical decision boundaries by rewarding actions that cause meaningful changes\nin the system's output. These counterfactual state transitions, where the\noutput changes, are collected and clustered using K-Means. Decision trees are\nthen trained on these clusters to extract human-readable rules that approximate\nthe system's decision logic near the identified boundaries. I demonstrated the\npipeline's effectiveness on three dummy legacy systems with varying complexity,\nincluding threshold-based, combined-conditional, and non-linear range logic.\nResults show that the RL agent successfully focuses exploration on relevant\nboundary regions, and the extracted rules accurately reflect the core logic of\nthe underlying dummy systems, providing a promising foundation for generating\nspecifications and test cases during legacy migration.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u63a2\u7d22\u8f93\u5165\u7a7a\u95f4\u5e76\u8bc6\u522b\u5173\u952e\u51b3\u7b56\u8fb9\u754c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6536\u96c6\u548c\u805a\u7c7b\u53cd\u4e8b\u5b9e\u72b6\u6001\u8f6c\u6362\uff0c\u5e76\u8bad\u7ec3\u51b3\u7b56\u6811\u4ee5\u63d0\u53d6\u53ef\u8bfb\u89c4\u5219\uff0c\u4ece\u800c\u4ece\u88ab\u89c6\u4e3a\u9ed1\u7bb1\u7684\u9057\u7559\u7cfb\u7edf\u4e2d\u81ea\u52a8\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u903b\u8f91\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u865a\u62df\u9057\u7559\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8868\u660e\u5176\u80fd\u591f\u51c6\u786e\u53cd\u6620\u6838\u5fc3\u903b\u8f91\u3002", "motivation": "\u73b0\u4ee3\u5316\u9057\u7559\u8f6f\u4ef6\u7cfb\u7edf\u662f\u4e00\u9879\u91cd\u8981\u4f46\u5145\u6ee1\u6311\u6218\u7684\u4efb\u52a1\uff0c\u901a\u5e38\u56e0\u7f3a\u4e4f\u6587\u6863\u548c\u5bf9\u539f\u7cfb\u7edf\u590d\u6742\u51b3\u7b56\u903b\u8f91\u7684\u7406\u89e3\u800c\u53d7\u963b\u3002\u4f20\u7edf\u65b9\u6cd5\u5982\u884c\u4e3a\u514b\u9686\u4ec5\u590d\u5236\u8f93\u5165-\u8f93\u51fa\u884c\u4e3a\uff0c\u65e0\u6cd5\u6355\u6349\u5e95\u5c42\u610f\u56fe\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u9057\u7559\u7cfb\u7edf\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u63a2\u7d22\u8f93\u5165\u7a7a\u95f4\uff0c\u901a\u8fc7\u5956\u52b1\u5bfc\u81f4\u7cfb\u7edf\u8f93\u51fa\u6709\u610f\u4e49\u53d8\u5316\u7684\u52a8\u4f5c\u6765\u8bc6\u522b\u5173\u952e\u51b3\u7b56\u8fb9\u754c\u3002\u6536\u96c6\u8fd9\u4e9b\u53cd\u4e8b\u5b9e\u72b6\u6001\u8f6c\u6362\u5e76\u4f7f\u7528K-Means\u8fdb\u884c\u805a\u7c7b\uff0c\u7136\u540e\u5728\u8fd9\u4e9b\u805a\u7c7b\u4e0a\u8bad\u7ec3\u51b3\u7b56\u6811\u4ee5\u63d0\u53d6\u8fd1\u4f3c\u7cfb\u7edf\u51b3\u7b56\u903b\u8f91\u7684\u4eba\u7c7b\u53ef\u8bfb\u89c4\u5219\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u5177\u6709\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u865a\u62df\u9057\u7559\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5305\u62ec\u57fa\u4e8e\u9608\u503c\u3001\u7ec4\u5408\u6761\u4ef6\u548c\u975e\u7ebf\u6027\u8303\u56f4\u903b\u8f91\u7684\u7cfb\u7edf\u3002\u7ed3\u679c\u8868\u660e\uff0cRL\u4ee3\u7406\u6210\u529f\u5730\u5c06\u63a2\u7d22\u96c6\u4e2d\u5728\u76f8\u5173\u7684\u8fb9\u754c\u533a\u57df\uff0c\u63d0\u53d6\u7684\u89c4\u5219\u51c6\u786e\u53cd\u6620\u4e86\u5e95\u5c42\u865a\u62df\u7cfb\u7edf\u7684\u6838\u2f3c\u903b\u8f91\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ba1\u9053\u4e3a\u751f\u6210\u89c4\u8303\u548c\u6d4b\u8bd5\u7528\u4f8b\u4ee5\u5b9e\u73b0\u9057\u7559\u7cfb\u7edf\u8fc1\u79fb\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u57fa\u7840\u3002"}}
{"id": "2507.00073", "pdf": "https://arxiv.org/pdf/2507.00073", "abs": "https://arxiv.org/abs/2507.00073", "authors": ["Urvi Pawar", "Kunal Telangi"], "title": "Fractional Policy Gradients: Reinforcement Learning with Long-Term Memory", "categories": ["cs.LG", "stat.ML", "I.2.6; I.2.8"], "comment": "Submitted to Journal of Machine Learning Research (JMLR), June 2025.\n  24 pages, 3 figures. Under review", "summary": "We propose Fractional Policy Gradients (FPG), a reinforcement learning\nframework incorporating fractional calculus for long-term temporal modeling in\npolicy optimization. Standard policy gradient approaches face limitations from\nMarkovian assumptions, exhibiting high variance and inefficient sampling. By\nreformulating gradients using Caputo fractional derivatives, FPG establishes\npower-law temporal correlations between state transitions. We develop an\nefficient recursive computation technique for fractional temporal-difference\nerrors with constant time and memory requirements. Theoretical analysis shows\nFPG achieves asymptotic variance reduction of order O(t^(-alpha)) versus\nstandard policy gradients while preserving convergence. Empirical validation\ndemonstrates 35-68% sample efficiency gains and 24-52% variance reduction\nversus state-of-the-art baselines. This framework provides a mathematically\ngrounded approach for leveraging long-range dependencies without computational\noverhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6FPG\uff0c\u901a\u8fc7\u5206\u6570\u9636\u5fae\u79ef\u5206\u51cf\u5c11\u65b9\u5dee\u5e76\u63d0\u9ad8\u91c7\u6837\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6536\u655b\u6027\u3002", "motivation": "\u6807\u51c6\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7531\u4e8e\u9a6c\u5c14\u53ef\u592b\u5047\u8bbe\u800c\u5b58\u5728\u9ad8\u65b9\u5dee\u548c\u91c7\u6837\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528Caputo\u5206\u6570\u9636\u5bfc\u6570\u91cd\u65b0\u5b9a\u4e49\u68af\u5ea6\uff0c\u5efa\u7acb\u72b6\u6001\u8f6c\u79fb\u4e4b\u95f4\u7684\u5e42\u5f8b\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u9012\u5f52\u8ba1\u7b97\u6280\u672f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eFPG\u53ef\u4ee5\u5b9e\u73b0\u6e10\u8fdb\u65b9\u5dee\u51cf\u5c11\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u663e\u793a\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e8635-68%\u7684\u91c7\u6837\u6548\u7387\u548c24-52%\u7684\u65b9\u5dee\u51cf\u5c11\u3002", "conclusion": "FPG\u63d0\u4f9b\u4e86\u4e00\u79cd\u6570\u5b66\u4e0a\u6709\u6839\u636e\u7684\u65b9\u6cd5\uff0c\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u5229\u7528\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2507.00181", "pdf": "https://arxiv.org/pdf/2507.00181", "abs": "https://arxiv.org/abs/2507.00181", "authors": ["Georgios P. Georgiou"], "title": "ChatGPT produces more \"lazy\" thinkers: Evidence of cognitive engagement decline", "categories": ["cs.AI"], "comment": null, "summary": "Despite the increasing use of large language models (LLMs) in education,\nconcerns have emerged about their potential to reduce deep thinking and active\nlearning. This study investigates the impact of generative artificial\nintelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of\nstudents during academic writing tasks. The study employed an experimental\ndesign with participants randomly assigned to either an AI-assisted (ChatGPT)\nor a non-assisted (control) condition. Participants completed a structured\nargumentative writing task followed by a cognitive engagement scale (CES), the\nCES-AI, developed to assess mental effort, attention, deep processing, and\nstrategic thinking. The results revealed significantly lower cognitive\nengagement scores in the ChatGPT group compared to the control group. These\nfindings suggest that AI assistance may lead to cognitive offloading. The study\ncontributes to the growing body of literature on the psychological implications\nof AI in education and raises important questions about the integration of such\ntools into academic practice. It calls for pedagogical strategies that promote\nactive, reflective engagement with AI-generated content to avoid compromising\nself-regulated learning and deep cognitive involvement of students.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6559\u80b2\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u4eba\u4eec\u5bf9\u5176\u53ef\u80fd\u51cf\u5c11\u6df1\u5ea6\u601d\u8003\u548c\u4e3b\u52a8\u5b66\u4e60\u8868\u793a\u62c5\u5fe7\u3002\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bbe\u8ba1\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5de5\u5177\uff08\u7279\u522b\u662fChatGPT\uff09\u5bf9\u5b66\u751f\u5b66\u672f\u5199\u4f5c\u4efb\u52a1\u4e2d\u8ba4\u77e5\u53c2\u4e0e\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\uff0cChatGPT\u7ec4\u7684\u8ba4\u77e5\u53c2\u4e0e\u5f97\u5206\u663e\u8457\u4f4e\u4e8e\u5bf9\u7167\u7ec4\uff0c\u8868\u660eAI\u8f85\u52a9\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u5378\u8f7d\u3002\u8be5\u7814\u7a76\u547c\u5401\u5236\u5b9a\u4fc3\u8fdb\u5b66\u751f\u4e0eAI\u751f\u6210\u5185\u5bb9\u79ef\u6781\u3001\u53cd\u601d\u6027\u4e92\u52a8\u7684\u6559\u5b66\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6559\u80b2\u4e2d\u5e7f\u6cdb\u5e94\u7528\u53ef\u80fd\u5bfc\u81f4\u5b66\u751f\u51cf\u5c11\u6df1\u5ea6\u601d\u8003\u548c\u4e3b\u52a8\u5b66\u4e60\u7684\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5c06\u53c2\u4e0e\u8005\u968f\u673a\u5206\u914d\u5230AI\u8f85\u52a9\uff08ChatGPT\uff09\u6216\u975e\u8f85\u52a9\uff08\u5bf9\u7167\uff09\u6761\u4ef6\u4e0b\u3002\u53c2\u4e0e\u8005\u5b8c\u6210\u7ed3\u6784\u5316\u8bba\u8bc1\u5199\u4f5c\u4efb\u52a1\u540e\uff0c\u586b\u5199\u8ba4\u77e5\u53c2\u4e0e\u91cf\u8868\uff08CES-AI\uff09\uff0c\u4ee5\u8bc4\u4f30\u5fc3\u7406\u52aa\u529b\u3001\u6ce8\u610f\u529b\u3001\u6df1\u5ea6\u5904\u7406\u548c\u6218\u7565\u6027\u601d\u7ef4\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cChatGPT\u7ec4\u7684\u8ba4\u77e5\u53c2\u4e0e\u5f97\u5206\u663e\u8457\u4f4e\u4e8e\u5bf9\u7167\u7ec4\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u5177\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8ba4\u77e5\u5378\u8f7d\uff0c\u9700\u8981\u5236\u5b9a\u6559\u5b66\u7b56\u7565\u6765\u4fc3\u8fdb\u5b66\u751f\u4e0eAI\u751f\u6210\u5185\u5bb9\u7684\u79ef\u6781\u3001\u53cd\u601d\u6027\u4e92\u52a8\uff0c\u4ee5\u907f\u514d\u5f71\u54cd\u81ea\u6211\u8c03\u8282\u5b66\u4e60\u548c\u5b66\u751f\u7684\u6df1\u5ea6\u8ba4\u77e5\u53c2\u4e0e\u3002"}}
{"id": "2507.00022", "pdf": "https://arxiv.org/pdf/2507.00022", "abs": "https://arxiv.org/abs/2507.00022", "authors": ["Zehao Wang"], "title": "GLU Attention Improve Transformer", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "comment": "4 pages 4 figures", "summary": "Gated Linear Units (GLU) have shown great potential in enhancing neural\nnetwork performance. In this paper, I introduce a novel attention mechanism\ncalled GLU Attention, which introduces nonlinearity into the values of\nAttention. My experiments demonstrate that GLU Attention improves both model\nperformance and convergence speed across text and vision modalities with zero\nadditional parameters and negligible computational costs. GLU Attention is\nlightweight and can seamlessly integrate with other technologies, such as Flash\nAttention, Rotary Position Embedding (RoPE), and various Multi-Head Attention\n(MHA) variants such as Grouped-Query Attention (GQA). This project is\nopen-sourced at github.", "AI": {"tldr": "GLU Attention\u662f\u4e00\u79cd\u5f15\u5165\u975e\u7ebf\u6027\u7684\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b83\u5728\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u4e0a\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\uff0c\u4e14\u65e0\u9700\u989d\u5916\u53c2\u6570\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u95e8\u63a7\u7ebf\u6027\u5355\u5143\uff08GLU\uff09\u5728\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u56e0\u6b64\u4f5c\u8005\u5c1d\u8bd5\u5c06GLU\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGLU Attention\u7684\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u5c06\u975e\u7ebf\u6027\u5f15\u5165\u6ce8\u610f\u529b\u7684\u503c\u4e2d\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0eFlash Attention\u3001RoPE\u7b49\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGLU Attention\u5728\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u4e0a\u90fd\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\uff0c\u540c\u65f6\u6ca1\u6709\u589e\u52a0\u989d\u5916\u53c2\u6570\u548c\u663e\u8457\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "GLU Attention\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u548c\u6613\u96c6\u6210\u7684\u7279\u70b9\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6a21\u6001\u4efb\u52a1\u3002"}}
{"id": "2507.00195", "pdf": "https://arxiv.org/pdf/2507.00195", "abs": "https://arxiv.org/abs/2507.00195", "authors": ["Kumar Kshitij Patel"], "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness", "categories": ["cs.LG", "cs.AI", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "This thesis contributes to the theoretical understanding of local update\nalgorithms, especially Local SGD, in distributed and federated optimization\nunder realistic models of data heterogeneity. A central focus is on the bounded\nsecond-order heterogeneity assumption, which is shown to be both necessary and\nsufficient for local updates to outperform centralized or mini-batch methods in\nconvex and non-convex settings. The thesis establishes tight upper and lower\nbounds in several regimes for various local update algorithms and characterizes\nthe min-max complexity of multiple problem classes. At its core is a\nfine-grained consensus-error-based analysis framework that yields sharper\nfinite-time convergence bounds under third-order smoothness and relaxed\nheterogeneity assumptions. The thesis also extends to online federated\nlearning, providing fundamental regret bounds under both first-order and bandit\nfeedback. Together, these results clarify when and why local updates offer\nprovable advantages, and the thesis serves as a self-contained guide for\nanalyzing Local SGD in heterogeneous environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6df1\u5165\u7814\u7a76\u4e86\u5728\u6570\u636e\u5f02\u8d28\u6027\u5b9e\u9645\u6a21\u578b\u4e0b\u7684\u5206\u5e03\u5f0f\u548c\u8054\u5408\u4f18\u5316\u4e2d\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\uff08\u7279\u522b\u662f\u672c\u5730SGD\uff09\u7684\u7406\u8bba\u57fa\u7840\u3002\u6838\u5fc3\u662f\u6709\u9650\u7684\u4e8c\u9636\u5f02\u8d28\u6027\u5047\u8bbe\uff0c\u8be5\u5047\u8bbe\u88ab\u8bc1\u660e\u662f\u5728\u51f8\u548c\u975e\u51f8\u8bbe\u7f6e\u4e0b\u672c\u5730\u66f4\u65b0\u4f18\u4e8e\u96c6\u4e2d\u6216\u5c0f\u6279\u91cf\u65b9\u6cd5\u7684\u5fc5\u8981\u548c\u5145\u5206\u6761\u4ef6\u3002\u8bba\u6587\u4e3a\u591a\u79cd\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\u5efa\u7acb\u4e86\u591a\u4e2a\u573a\u666f\u4e0b\u7684\u4e25\u683c\u4e0a\u4e0b\u754c\uff0c\u5e76\u523b\u753b\u4e86\u591a\u7c7b\u95ee\u9898\u7684\u6781\u5c0f\u6781\u5927\u590d\u6742\u5ea6\u3002\u901a\u8fc7\u7cbe\u7ec6\u7684\u5171\u8bc6\u8bef\u5dee\u5206\u6790\u6846\u67b6\uff0c\u5728\u4e09\u9636\u5e73\u6ed1\u6027\u548c\u653e\u677e\u7684\u5f02\u8d28\u6027\u5047\u8bbe\u4e0b\uff0c\u5f97\u5230\u4e86\u66f4\u7cbe\u786e\u7684\u6709\u9650\u65f6\u95f4\u6536\u655b\u8fb9\u754c\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u6269\u5c55\u5230\u5728\u7ebf\u8054\u5408\u5b66\u4e60\u9886\u57df\uff0c\u63d0\u4f9b\u4e86\u5728\u68af\u5ea6\u548cbandit\u53cd\u9988\u4e0b\u7684\u57fa\u672c\u540e\u6094\u8fb9\u754c\u3002\u8fd9\u4e9b\u7ed3\u679c\u9610\u660e\u4e86\u672c\u5730\u66f4\u65b0\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u5206\u6790\u5f02\u8d28\u73af\u5883\u4e2d\u7684\u672c\u5730SGD\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6307\u5bfc\u3002", "motivation": "\u5c3d\u7ba1\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\uff08\u5982\u672c\u5730SGD\uff09\u5728\u5206\u5e03\u5f0f\u548c\u8054\u5408\u4f18\u5316\u4e2d\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u6570\u636e\u5f02\u8d28\u6027\u5b9e\u9645\u6a21\u578b\u4e0b\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u4e0d\u5145\u5206\u3002\u4e3a\u4e86\u660e\u786e\u672c\u5730\u66f4\u65b0\u5728\u54ea\u4e9b\u60c5\u51b5\u4e0b\u5177\u6709\u4f18\u52bf\u53ca\u5176\u539f\u56e0\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u4e25\u683c\u7684\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u5176\u6027\u80fd\u548c\u590d\u6742\u5ea6\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5171\u8bc6\u8bef\u5dee\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86\u4e8c\u9636\u5f02\u8d28\u6027\u5047\u8bbe\u7684\u4f5c\u7528\uff0c\u5e76\u5728\u4e09\u9636\u5e73\u6ed1\u6027\u548c\u653e\u677e\u7684\u5f02\u8d28\u6027\u5047\u8bbe\u4e0b\u63a8\u5bfc\u4e86\u66f4\u7cbe\u786e\u7684\u6709\u9650\u65f6\u95f4\u6536\u655b\u8fb9\u754c\u3002\u6b64\u5916\uff0c\u8bba\u6587\u5bf9\u5728\u7ebf\u8054\u5408\u5b66\u4e60\u8fdb\u884c\u4e86\u6269\u5c55\u7814\u7a76\uff0c\u5206\u522b\u5728\u68af\u5ea6\u548cbandit\u53cd\u9988\u4e0b\u63d0\u4f9b\u4e86\u540e\u6094\u8fb9\u754c\u3002", "result": "\u8bba\u6587\u4e3a\u591a\u79cd\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u4e0a\u4e0b\u754c\uff0c\u5e76\u660e\u786e\u4e86\u4e0d\u540c\u95ee\u9898\u7c7b\u522b\u7684\u6781\u5c0f\u6781\u5927\u590d\u6742\u5ea6\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u5206\u6790\u6846\u67b6\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6536\u655b\u8fb9\u754c\u3002\u5bf9\u4e8e\u5728\u7ebf\u8054\u5408\u5b66\u4e60\uff0c\u4e5f\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\uff08\u5c24\u5176\u662f\u672c\u5730SGD\uff09\u5728\u6ee1\u8db3\u7279\u5b9a\u6570\u636e\u5f02\u8d28\u6027\u5047\u8bbe\u65f6\uff0c\u53ef\u4ee5\u5728\u51f8\u548c\u975e\u51f8\u73af\u5883\u4e0b\u663e\u8457\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u6216\u5c0f\u6279\u91cf\u65b9\u6cd5\u3002\u8bba\u6587\u7684\u7ed3\u679c\u4e3a\u7406\u89e3\u672c\u5730\u66f4\u65b0\u7b97\u6cd5\u5728\u5f02\u8d28\u73af\u5883\u4e0b\u7684\u4f18\u52bf\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u65b9\u5411\u3002"}}
{"id": "2507.00205", "pdf": "https://arxiv.org/pdf/2507.00205", "abs": "https://arxiv.org/abs/2507.00205", "authors": ["Periklis Petridis", "Georgios Margaritis", "Vasiliki Stoumpou", "Dimitris Bertsimas"], "title": "Holistic Artificial Intelligence in Medicine; improved performance and explainability", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to npj Digital Medicine", "summary": "With the increasing interest in deploying Artificial Intelligence in\nmedicine, we previously introduced HAIM (Holistic AI in Medicine), a framework\nthat fuses multimodal data to solve downstream clinical tasks. However, HAIM\nuses data in a task-agnostic manner and lacks explainability. To address these\nlimitations, we introduce xHAIM (Explainable HAIM), a novel framework\nleveraging Generative AI to enhance both prediction and explainability through\nfour structured steps: (1) automatically identifying task-relevant patient data\nacross modalities, (2) generating comprehensive patient summaries, (3) using\nthese summaries for improved predictive modeling, and (4) providing clinical\nexplanations by linking predictions to patient-specific medical knowledge.\nEvaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9%\nto 90.3% across chest pathology and operative tasks. Importantly, xHAIM\ntransforms AI from a black-box predictor into an explainable decision support\nsystem, enabling clinicians to interactively trace predictions back to relevant\npatient data, bridging AI advancements with clinical utility.", "AI": {"tldr": "\u901a\u8fc7\u56db\u4e2a\u6b65\u9aa4\u63d0\u5347\u533b\u7597\u591a\u6a21\u6001\u6570\u636e\u9884\u6d4b\u4e0e\u53ef\u89e3\u91ca\u6027\uff0cxHAIM\u5728HAIM-MIMIC-MM\u6570\u636e\u96c6\u4e0a\u5c06\u5e73\u5747AUC\u4ece79.9%\u63d0\u9ad8\u523090.3%\uff0c\u5e76\u63d0\u4f9b\u4e34\u5e8a\u89e3\u91ca\u652f\u6301\u7cfb\u7edf\u3002", "motivation": "\u4e4b\u524d\u7684HAIM\u6846\u67b6\u867d\u7136\u878d\u5408\u4e86\u591a\u6a21\u6001\u6570\u636e\u89e3\u51b3\u4e34\u5e8a\u4efb\u52a1\uff0c\u4f46\u4ee5\u4efb\u52a1\u65e0\u5173\u7684\u65b9\u5f0f\u4f7f\u7528\u6570\u636e\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faxHAIM\u6846\u67b6\uff0c\u5305\u62ec\uff1a\u81ea\u52a8\u8bc6\u522b\u8de8\u6a21\u6001\u7684\u4efb\u52a1\u76f8\u5173\u60a3\u8005\u6570\u636e\u3001\u751f\u6210\u5168\u9762\u7684\u60a3\u8005\u6458\u8981\u3001\u5229\u7528\u6458\u8981\u6539\u8fdb\u9884\u6d4b\u5efa\u6a21\u3001\u63d0\u4f9b\u8fde\u63a5\u9884\u6d4b\u4e0e\u60a3\u8005\u7279\u5b9a\u533b\u5b66\u77e5\u8bc6\u7684\u4e34\u5e8a\u89e3\u91ca\u3002", "result": "\u5728HAIM-MIMIC-MM\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0cxHAIM\u5c06\u5e73\u5747AUC\u4ece79.9%\u63d0\u9ad8\u523090.3%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "xHAIM\u5c06AI\u4ece\u9ed1\u7bb1\u9884\u6d4b\u5668\u8f6c\u53d8\u4e3a\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u4f7f\u4e34\u5e8a\u533b\u751f\u80fd\u591f\u4ea4\u4e92\u5f0f\u5730\u5c06\u9884\u6d4b\u8ffd\u6eaf\u5230\u76f8\u5173\u60a3\u8005\u6570\u636e\uff0c\u5f25\u5408\u4e86AI\u8fdb\u5c55\u4e0e\u4e34\u5e8a\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.00024", "pdf": "https://arxiv.org/pdf/2507.00024", "abs": "https://arxiv.org/abs/2507.00024", "authors": ["Yeyong Yu", "Xilei Bian", "Jie Xiong", "Xing Wu", "Quan Qian"], "title": "AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "With the growing demand for novel materials, machine learning-driven inverse\ndesign methods face significant challenges in reconciling the high-dimensional\nmaterials composition space with limited experimental data. Existing approaches\nsuffer from two major limitations: (I) machine learning models often lack\nreliability in high-dimensional spaces, leading to prediction biases during the\ndesign process; (II) these models fail to effectively incorporate domain expert\nknowledge, limiting their capacity to support knowledge-guided inverse design.\nTo address these challenges, we introduce AIMatDesign, a reinforcement learning\nframework that addresses these limitations by augmenting experimental data\nusing difference-based algorithms to build a trusted experience pool,\naccelerating model convergence. To enhance model reliability, an automated\nrefinement strategy guided by large language models (LLMs) dynamically corrects\nprediction inconsistencies, reinforcing alignment between reward signals and\nstate value functions. Additionally, a knowledge-based reward function\nleverages expert domain rules to improve stability and efficiency during\ntraining. Our experiments demonstrate that AIMatDesign significantly surpasses\ntraditional machine learning and reinforcement learning methods in discovery\nefficiency, convergence speed, and success rates. Among the numerous candidates\nproposed by AIMatDesign, experimental synthesis of representative Zr-based\nalloys yielded a top-performing BMG with 1.7GPa yield strength and 10.2\\%\nelongation, closely matching predictions. Moreover, the framework accurately\ncaptured the trend of yield strength variation with composition, demonstrating\nits reliability and potential for closed-loop materials discovery.", "AI": {"tldr": "\u968f\u7740\u5bf9\u65b0\u578b\u6750\u6599\u9700\u6c42\u7684\u589e\u957f\uff0c\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u9006\u5411\u8bbe\u8ba1\u65b9\u6cd5\u5728\u9ad8\u7ef4\u6750\u6599\u7ec4\u6210\u7a7a\u95f4\u4e0e\u6709\u9650\u5b9e\u9a8c\u6570\u636e\u4e4b\u95f4\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u5c40\u9650\u6027\uff1a(I) \u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7f3a\u4e4f\u53ef\u9760\u6027\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u9884\u6d4b\u504f\u5dee\uff1b(II) \u8fd9\u4e9b\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u6574\u5408\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5176\u652f\u6301\u77e5\u8bc6\u5f15\u5bfc\u578b\u9006\u5411\u8bbe\u8ba1\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 AIMatDesign\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u5dee\u5f02\u7684\u7b97\u6cd5\u589e\u5f3a\u5b9e\u9a8c\u6570\u636e\u6765\u6784\u5efa\u53ef\u4fe1\u7684\u7ecf\u9a8c\u6c60\uff0c\u52a0\u901f\u6a21\u578b\u6536\u655b\u3002\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\uff0c\u91c7\u7528\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLMs) \u5f15\u5bfc\u7684\u81ea\u52a8\u5316\u7cbe\u5316\u7b56\u7565\u52a8\u6001\u6821\u6b63\u9884\u6d4b\u4e0d\u4e00\u81f4\u6027\uff0c\u52a0\u5f3a\u5956\u52b1\u4fe1\u53f7\u4e0e\u72b6\u6001\u503c\u51fd\u6570\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u77e5\u8bc6\u7684\u5956\u52b1\u51fd\u6570\u5229\u7528\u4e13\u5bb6\u9886\u57df\u89c4\u5219\u63d0\u9ad8\u4e86\u8bad\u7ec3\u671f\u95f4\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAIMatDesign \u5728\u53d1\u73b0\u6548\u7387\u3001\u6536\u655b\u901f\u5ea6\u548c\u6210\u529f\u7387\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u5728 AIMatDesign \u63d0\u51fa\u7684\u4f17\u591a\u5019\u9009\u6750\u6599\u4e2d\uff0c\u4ee3\u8868\u6027 Zr \u57fa\u5408\u91d1\u7684\u5b9e\u9a8c\u5408\u6210\u4ea7\u751f\u4e86\u4e00\u79cd\u6027\u80fd\u6700\u4f73\u7684 BMG\uff0c\u5177\u6709 1.7GPa \u5c48\u670d\u5f3a\u5ea6\u548c 10.2% \u7684\u5ef6\u4f38\u7387\uff0c\u4e0e\u9884\u6d4b\u7ed3\u679c\u975e\u5e38\u63a5\u8fd1\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u51c6\u786e\u6355\u6349\u4e86\u5c48\u670d\u5f3a\u5ea6\u968f\u6210\u5206\u53d8\u5316\u7684\u8d8b\u52bf\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u9760\u6027\u548c\u95ed\u73af\u6750\u6599\u53d1\u73b0\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u9006\u5411\u8bbe\u8ba1\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u6750\u6599\u7ec4\u6210\u7a7a\u95f4\u65f6\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a(1) \u6a21\u578b\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u9884\u6d4b\u53ef\u9760\u6027\u4e0d\u8db3\uff1b(2) \u65e0\u6cd5\u6709\u6548\u6574\u5408\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86\u9ad8\u6548\u6750\u6599\u53d1\u73b0\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a AIMatDesign \u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4e3b\u8981\u65b9\u6cd5\u5305\u62ec\uff1a\n- \u4f7f\u7528\u57fa\u4e8e\u5dee\u5f02\u7684\u7b97\u6cd5\u589e\u5f3a\u5b9e\u9a8c\u6570\u636e\uff0c\u6784\u5efa\u53ef\u4fe1\u7ecf\u9a8c\u6c60\u4ee5\u52a0\u901f\u6a21\u578b\u6536\u655b\u3002\n- \u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLMs) \u5f15\u5bfc\u7684\u81ea\u52a8\u5316\u7cbe\u5316\u7b56\u7565\u52a8\u6001\u6821\u6b63\u9884\u6d4b\u4e0d\u4e00\u81f4\u6027\uff0c\u786e\u4fdd\u5956\u52b1\u4fe1\u53f7\u4e0e\u72b6\u6001\u503c\u51fd\u6570\u7684\u4e00\u81f4\u6027\u3002\n- \u8bbe\u8ba1\u57fa\u4e8e\u77e5\u8bc6\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u4e13\u5bb6\u9886\u57df\u89c4\u5219\u63d0\u9ad8\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a AIMatDesign \u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u4ee5\u4e0b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff1a\n- \u6750\u6599\u53d1\u73b0\u6548\u7387\u66f4\u9ad8\u3002\n- \u6536\u655b\u901f\u5ea6\u66f4\u5feb\u3002\n- \u6210\u529f\u7387\u66f4\u9ad8\u3002\n- \u5b9e\u9a8c\u5408\u6210\u7684 Zr \u57fa\u5408\u91d1\u6027\u80fd\u4e0e\u9884\u6d4b\u9ad8\u5ea6\u543b\u5408\uff0c\u4e14\u6846\u67b6\u80fd\u591f\u51c6\u786e\u6355\u6349\u5c48\u670d\u5f3a\u5ea6\u968f\u6210\u5206\u53d8\u5316\u7684\u8d8b\u52bf\u3002", "conclusion": "AIMatDesign \u662f\u4e00\u79cd\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9006\u5411\u8bbe\u8ba1\u65b9\u6cd5\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5e76\u6210\u529f\u6574\u5408\u4e86\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u3002\u5b83\u5728\u6750\u6599\u53d1\u73b0\u6548\u7387\u3001\u6536\u655b\u901f\u5ea6\u548c\u6210\u529f\u7387\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u51fa\u95ed\u73af\u6750\u6599\u53d1\u73b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.00451", "pdf": "https://arxiv.org/pdf/2507.00451", "abs": "https://arxiv.org/abs/2507.00451", "authors": ["Matthew Stephenson", "Alex Newcombe", "Eric Piette", "Dennis Soemers"], "title": "Best Agent Identification for General Game Playing", "categories": ["cs.LG", "cs.AI", "cs.DS", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "We present an efficient and generalised procedure to accurately identify the\nbest performing algorithm for each sub-task in a multi-problem domain. Our\napproach treats this as a set of best arm identification problems for\nmulti-armed bandits, where each bandit corresponds to a specific task and each\narm corresponds to a specific algorithm or agent. We propose an optimistic\nselection process based on the Wilson score interval (Optimistic-WS) that ranks\neach arm across all bandits in terms of their potential regret reduction. We\nevaluate the performance of Optimistic-WS on two of the most popular general\ngame domains, the General Video Game AI (GVGAI) framework and the Ludii general\ngame playing system, with the goal of identifying the highest performing agent\nfor each game within a limited number of trials. Compared to previous best arm\nidentification algorithms for multi-armed bandits, our results demonstrate a\nsubstantial performance improvement in terms of average simple regret. This\nnovel approach can be used to significantly improve the quality and accuracy of\nagent evaluation procedures for general game frameworks, as well as other\nmulti-task domains with high algorithm runtimes.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWilson\u5f97\u5206\u533a\u95f4\uff08Optimistic-WS\uff09\u7684\u4e50\u89c2\u9009\u62e9\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5728\u591a\u95ee\u9898\u9886\u57df\u4e2d\u51c6\u786e\u8bc6\u522b\u6bcf\u4e2a\u5b50\u4efb\u52a1\u7684\u6700\u4f73\u7b97\u6cd5\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u5e73\u5747\u7b80\u5355\u540e\u6094\u503c\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u53ef\u4f18\u5316\u901a\u7528\u6e38\u620f\u6846\u67b6\u548c\u5176\u4ed6\u591a\u4efb\u52a1\u9886\u57df\u7684\u4ee3\u7406\u8bc4\u4f30\u8fc7\u7a0b\u3002", "motivation": "\u5728\u591a\u95ee\u9898\u9886\u57df\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\u6765\u51c6\u786e\u8bc6\u522b\u6bcf\u4e2a\u5b50\u4efb\u52a1\u7684\u6700\u4f73\u7b97\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u4ee3\u7406\u8bc4\u4f30\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002", "method": "\u5c06\u95ee\u9898\u89c6\u4e3a\u591a\u81c2\u8001\u864e\u673a\u4e2d\u7684\u6700\u4f73\u624b\u81c2\u8bc6\u522b\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8001\u864e\u673a\u5bf9\u5e94\u7279\u5b9a\u4efb\u52a1\uff0c\u6bcf\u53ea\u624b\u81c2\u5bf9\u5e94\u7279\u5b9a\u7b97\u6cd5\u6216\u4ee3\u7406\u3002\u63d0\u51fa\u57fa\u4e8eWilson\u5f97\u5206\u533a\u95f4\u7684\u4e50\u89c2\u9009\u62e9\u8fc7\u7a0b\uff08Optimistic-WS\uff09\uff0c\u901a\u8fc7\u6f5c\u5728\u540e\u6094\u51cf\u5c11\u91cf\u5bf9\u6240\u6709\u8001\u864e\u673a\u7684\u624b\u81c2\u8fdb\u884c\u6392\u540d\u3002", "result": "\u5728GVGAI\u6846\u67b6\u548cLudii\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5148\u524d\u7684\u6700\u4f73\u624b\u81c2\u8bc6\u522b\u7b97\u6cd5\u76f8\u6bd4\uff0cOptimistic-WS\u5728\u51cf\u5c11\u5e73\u5747\u7b80\u5355\u540e\u6094\u503c\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u7684Optimistic-WS\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u901a\u7528\u6e38\u620f\u6846\u67b6\u548c\u5176\u4ed6\u9ad8\u8fd0\u884c\u65f6\u7b97\u6cd5\u7684\u591a\u4efb\u52a1\u9886\u57df\u4e2d\u4ee3\u7406\u8bc4\u4f30\u8fc7\u7a0b\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.00218", "pdf": "https://arxiv.org/pdf/2507.00218", "abs": "https://arxiv.org/abs/2507.00218", "authors": ["Fangting Zhou", "Attila Lischka", "Balazs Kulcsar", "Jiaming Wu", "Morteza Haghir Chehreghani", "Gilbert Laporte"], "title": "Learning for routing: A guided review of recent developments and future directions", "categories": ["cs.AI", "math.OC"], "comment": "Accepted for publication in Transportation Research Part E: Logistics\n  and Transportation Review", "summary": "This paper reviews the current progress in applying machine learning (ML)\ntools to solve NP-hard combinatorial optimization problems, with a focus on\nrouting problems such as the traveling salesman problem (TSP) and the vehicle\nrouting problem (VRP). Due to the inherent complexity of these problems, exact\nalgorithms often require excessive computational time to find optimal\nsolutions, while heuristics can only provide approximate solutions without\nguaranteeing optimality. With the recent success of machine learning models,\nthere is a growing trend in proposing and implementing diverse ML techniques to\nenhance the resolution of these challenging routing problems. We propose a\ntaxonomy categorizing ML-based routing methods into construction-based and\nimprovement-based approaches, highlighting their applicability to various\nproblem characteristics. This review aims to integrate traditional OR methods\nwith state-of-the-art ML techniques, providing a structured framework to guide\nfuture research and address emerging VRP variants.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u5c06\u673a\u5668\u5b66\u4e60\u5de5\u5177\u5e94\u7528\u4e8e\u89e3\u51b3NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5c24\u5176\u662f\u65c5\u884c\u5546\u95ee\u9898\u548c\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff09\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6784\u5efa\u548c\u6539\u8fdb\u65b9\u6cd5\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u65e8\u5728\u7ed3\u5408\u4f20\u7edf\u8fd0\u7b79\u5b66\u65b9\u6cd5\u4e0e\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6280\u672f\u4ee5\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u7531\u4e8eNP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u56fa\u6709\u590d\u6742\u6027\uff0c\u7cbe\u786e\u7b97\u6cd5\u901a\u5e38\u9700\u8981\u8fc7\u591a\u7684\u8ba1\u7b97\u65f6\u95f4\u6765\u5bfb\u627e\u6700\u4f18\u89e3\uff0c\u800c\u542f\u53d1\u5f0f\u7b97\u6cd5\u53ea\u80fd\u63d0\u4f9b\u8fd1\u4f3c\u89e3\u4e14\u65e0\u6cd5\u4fdd\u8bc1\u6700\u4f18\u6027\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u5728\u8fd9\u4e9b\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u6210\u4e3a\u91cd\u8981\u7684\u7814\u7a76\u65b9\u5411\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u5c06\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u5206\u4e3a\u6784\u5efa\u578b\u548c\u6539\u8fdb\u578b\u4e24\u7c7b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u95ee\u9898\u7279\u6027\u4e2d\u7684\u9002\u7528\u6027\u3002\u540c\u65f6\uff0c\u6574\u5408\u4e86\u4f20\u7edf\u8fd0\u7b79\u5b66\u65b9\u6cd5\u4e0e\u6700\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u6846\u67b6\u3002", "result": "\u8be5\u7efc\u8ff0\u603b\u7ed3\u4e86\u673a\u5668\u5b66\u4e60\u5728\u89e3\u51b3\u8def\u7531\u95ee\u9898\u4e0a\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u901a\u8fc7\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u660e\u786e\u4e86\u5404\u7c7b\u65b9\u6cd5\u7684\u9002\u7528\u573a\u666f\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u89e3\u51b3NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u672a\u6765\u7684\u7814\u7a76\u5e94\u8fdb\u4e00\u6b65\u7ed3\u5408\u4f20\u7edf\u65b9\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u65b0\u5174\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u53d8\u79cd\u3002"}}
{"id": "2507.00480", "pdf": "https://arxiv.org/pdf/2507.00480", "abs": "https://arxiv.org/abs/2507.00480", "authors": ["Kiyoung Om", "Kyuil Sim", "Taeyoung Yun", "Hyeongyu Kang", "Jinkyoo Park"], "title": "Posterior Inference in Latent Space for Scalable Constrained Black-box Optimization", "categories": ["cs.LG", "stat.ML"], "comment": "25 pages, 11 figures, 5 tables. Equal contribution by Kiyoung Om,\n  Kyuil Sim, and Taeyoung Yun", "summary": "Optimizing high-dimensional black-box functions under black-box constraints\nis a pervasive task in a wide range of scientific and engineering problems.\nThese problems are typically harder than unconstrained problems due to\nhard-to-find feasible regions. While Bayesian optimization (BO) methods have\nbeen developed to solve such problems, they often struggle with the curse of\ndimensionality. Recently, generative model-based approaches have emerged as a\npromising alternative for constrained optimization. However, they suffer from\npoor scalability and are vulnerable to mode collapse, particularly when the\ntarget distribution is highly multi-modal. In this paper, we propose a new\nframework to overcome these challenges. Our method iterates through two stages.\nFirst, we train flow-based models to capture the data distribution and\nsurrogate models that predict both function values and constraint violations\nwith uncertainty quantification. Second, we cast the candidate selection\nproblem as a posterior inference problem to effectively search for promising\ncandidates that have high objective values while not violating the constraints.\nDuring posterior inference, we find that the posterior distribution is highly\nmulti-modal and has a large plateau due to constraints, especially when\nconstraint feedback is given as binary indicators of feasibility. To mitigate\nthis issue, we amortize the sampling from the posterior distribution in the\nlatent space of flow-based models, which is much smoother than that in the data\nspace. We empirically demonstrate that our method achieves superior performance\non various synthetic and real-world constrained black-box optimization tasks.\nOur code is publicly available \\href{https://github.com/umkiyoung/CiBO}{here}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bad\u7ec3\u6d41\u6a21\u578b\u548c\u4ee3\u7406\u6a21\u578b\uff0c\u5e76\u5c06\u5019\u9009\u9009\u62e9\u95ee\u9898\u89c6\u4e3a\u540e\u9a8c\u63a8\u7406\u95ee\u9898\uff0c\u4ee5\u89e3\u51b3\u9ad8\u7ef4\u7ea6\u675f\u9ed1\u7bb1\u4f18\u5316\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u7ea6\u675f\u9ed1\u7bb1\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "motivation": "\u9ad8\u7ef4\u9ed1\u7bb1\u51fd\u6570\u5728\u9ed1\u7bb1\u7ea6\u675f\u4e0b\u7684\u4f18\u5316\u662f\u4e00\u4e2a\u666e\u904d\u7684\u4efb\u52a1\uff0c\u6bd4\u65e0\u7ea6\u675f\u95ee\u9898\u66f4\u96be\uff0c\u56e0\u4e3a\u96be\u4ee5\u627e\u5230\u53ef\u884c\u533a\u57df\u3002\u73b0\u6709\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u7ef4\u5ea6\u8bc5\u5492\uff0c\u800c\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u65b9\u6cd5\u867d\u7136\u6709\u6f5c\u529b\uff0c\u4f46\u53ef\u6269\u5c55\u6027\u5dee\u4e14\u5bb9\u6613\u51fa\u73b0\u6a21\u5f0f\u5d29\u584c\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u8bad\u7ec3\u6d41\u6a21\u578b\u4ee5\u6355\u6349\u6570\u636e\u5206\u5e03\u548c\u4ee3\u7406\u6a21\u578b\u4ee5\u9884\u6d4b\u51fd\u6570\u503c\u548c\u7ea6\u675f\u8fdd\u53cd\u60c5\u51b5\uff1b2) \u5c06\u5019\u9009\u9009\u62e9\u95ee\u9898\u4f5c\u4e3a\u540e\u9a8c\u63a8\u7406\u95ee\u9898\uff0c\u4ee5\u641c\u7d22\u5177\u6709\u9ad8\u76ee\u6807\u503c\u800c\u4e0d\u8fdd\u53cd\u7ea6\u675f\u7684\u5019\u9009\u8005\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u5904\u7406\u591a\u6a21\u6001\u540e\u9a8c\u5206\u5e03\u7684\u95ee\u9898\uff0c\u5728\u6d41\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u644a\u9500\u91c7\u6837\uff0c\u4f7f\u5176\u6bd4\u6570\u636e\u7a7a\u95f4\u66f4\u5e73\u6ed1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u7ea6\u675f\u9ed1\u7bb1\u4f18\u5316\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u9ad8\u7ef4\u7ea6\u675f\u9ed1\u7bb1\u4f18\u5316\u4e2d\u7684\u7ef4\u5ea6\u8bc5\u5492\u3001\u53ef\u6269\u5c55\u6027\u548c\u6a21\u5f0f\u5d29\u584c\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.00417", "pdf": "https://arxiv.org/pdf/2507.00417", "abs": "https://arxiv.org/abs/2507.00417", "authors": ["Joongwon Kim", "Anirudh Goyal", "Liang Tan", "Hannaneh Hajishirzi", "Srinivasan Iyer", "Tianlu Wang"], "title": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context", "categories": ["cs.AI", "cs.CL"], "comment": "36 pages, 23 figures", "summary": "We introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework\nfor training language models to reason like search algorithms, explicitly\nleveraging self-reflection, backtracking, and exploration in their outputs.\nRecently, training large language models (LLMs) via reinforcement learning (RL)\nhas led to the advent of reasoning models with greatly enhanced reasoning\ncapabilities. Open-source replications of reasoning models, while successful,\nbuild upon models that already exhibit strong reasoning capabilities along with\nsearch behavior observed even before RL. As a result, it is yet unclear how to\nboost the reasoning capabilities of other non-reasoner models including Llama\n3. ASTRO teaches such models to internalize structured search behavior through\na synthetic dataset derived from Monte Carlo Tree Search (MCTS) over\nmathematical problem-solving trajectories. By converting search traces into\nnatural language chain-of-thoughts that capture both successes and recoveries\nfrom failure, ASTRO bootstraps models with a rich prior for exploration during\nRL. We finetune our models on these search-derived traces and further improve\nperformance via RL with verifiable rewards. We apply ASTRO to the Llama 3\nfamily of models and achieve absolute performance gains of 16.0% on MATH-500,\n26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon\nchallenging problems that require iterative correction. Our results demonstrate\nthat search-inspired training offers a principled way to instill robust\nreasoning capabilities into open LLMs.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aASTRO\uff08Autoregressive Search-Taught Reasoner\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u751f\u6210\u7684\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u50cf\u641c\u7d22\u7b97\u6cd5\u4e00\u6837\u63a8\u7406\u3002\u6b64\u65b9\u6cd5\u589e\u5f3a\u4e86\u975e\u63a8\u7406\u6a21\u578b\uff08\u5982Llama 3\u7cfb\u5217\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u5f00\u6e90\u590d\u73b0\u4e3b\u8981\u4f9d\u8d56\u4e8e\u539f\u672c\u5c31\u5177\u5907\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u3002\u5982\u4f55\u63d0\u5347\u5176\u4ed6\u975e\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u589e\u5f3a\u8fd9\u4e9b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "ASTRO\u6846\u67b6\u5229\u7528\u4ece\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u884d\u751f\u7684\u6570\u636e\u96c6\uff0c\u5c06\u641c\u7d22\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u7684\u601d\u8003\u94fe\u6761\uff0c\u5305\u62ec\u6210\u529f\u4e0e\u5931\u8d25\u6062\u590d\u7684\u8fc7\u7a0b\u3002\u901a\u8fc7\u5728\u8fd9\u4e9b\u6570\u636e\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u5185\u90e8\u5316\u7ed3\u6784\u5316\u7684\u641c\u7d22\u884c\u4e3a\u3002", "result": "\u5728Llama 3\u7cfb\u5217\u6a21\u578b\u4e0a\u7684\u5e94\u7528\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728MATH-500\u3001AMC 2023\u548cAIME 2024\u7b49\u6570\u5b66\u6d4b\u8bd5\u4e2d\u5206\u522b\u63d0\u5347\u4e8616.0%\u300126.9%\u548c20.0%\u7684\u7edd\u5bf9\u6027\u80fd\uff0c\u5c24\u5176\u5728\u9700\u8981\u8fed\u4ee3\u4fee\u6b63\u7684\u96be\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u53d7\u641c\u7d22\u542f\u53d1\u7684\u8bad\u7ec3\u65b9\u6cd5\u4e3a\u5411\u5f00\u653e\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6ce8\u5165\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u539f\u5219\u7684\u8def\u5f84\u3002"}}
{"id": "2507.00026", "pdf": "https://arxiv.org/pdf/2507.00026", "abs": "https://arxiv.org/abs/2507.00026", "authors": ["Jiale Ding", "Xiang Zheng", "Cong Wang", "Wei-Bin Lee", "Xingjun Ma", "Yu-Gang Jiang"], "title": "ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as black-box\ncomponents in real-world applications, evaluating their safety-especially under\nadversarial prompting-has become critical. Arguably, effective safety\nevaluations should be adaptive, evolving with LLM capabilities, and also cover\na broad spectrum of harmful topics and real-world scenarios to fully expose\npotential vulnerabilities. Existing manual safety benchmarks, built on\nhandcrafted adversarial prompts, are limited by their static nature and the\nintensive labor required to update them, making it difficult to keep pace with\nrapidly advancing LLMs. In contrast, automated adversarial prompt generation\noffers a promising path toward adaptive evaluation. However, current methods\noften suffer from insufficient adversarial topic coverage (topic-level\ndiversity) and weak alignment with real-world contexts. These shortcomings stem\nfrom the exploration-exploitation dilemma in black-box optimization and a lack\nof real-world contextualization, resulting in adversarial prompts that are both\ntopically narrow and scenario-repetitive. To address these issues, we propose\nReality-Oriented Safety Evaluation (ROSE), a novel framework that uses\nmulti-objective reinforcement learning to fine-tune an adversarial LLM for\ngenerating topically diverse and contextually rich adversarial prompts.\nExperiments show that ROSE outperforms existing methods in uncovering safety\nvulnerabilities in state-of-the-art LLMs, with notable improvements in\nintegrated evaluation metrics. We hope ROSE represents a step toward more\npractical and reality-oriented safety evaluation of LLMs. WARNING: This paper\ncontains examples of potentially harmful text.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aROSE\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5bf9\u6297\u6027LLM\uff0c\u751f\u6210\u4e3b\u9898\u591a\u6837\u4e14\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u8bc4\u4f30LLM\u5b89\u5168\u6027\u65f6\u5b58\u5728\u7684\u4e3b\u9898\u8986\u76d6\u4e0d\u8db3\u548c\u4e0e\u73b0\u5b9e\u60c5\u5883\u5bf9\u9f50\u4e0d\u4f73\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cROSE\u5728\u53d1\u73b0\u6700\u5148\u8fdbLLM\u7684\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u4e0a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u4f5c\u4e3a\u9ed1\u7bb1\u7ec4\u4ef6\u90e8\u7f72\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5bf9\u5176\u5b89\u5168\u6027\u7684\u8bc4\u4f30\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5bf9\u6297\u6027\u63d0\u793a\u4e0b\u7684\u5b89\u5168\u6027\u3002\u73b0\u6709\u7684\u624b\u52a8\u5b89\u5168\u57fa\u51c6\u7531\u4e8e\u5176\u9759\u6001\u6027\u8d28\u548c\u66f4\u65b0\u6240\u9700\u7684\u4eba\u529b\u5bc6\u96c6\u578b\u5de5\u4f5c\uff0c\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684LLMs\u3002\u800c\u81ea\u52a8\u5316\u7684\u5bf9\u6297\u6027\u63d0\u793a\u751f\u6210\u867d\u7136\u63d0\u4f9b\u4e86\u9002\u5e94\u6027\u8bc4\u4f30\u7684\u5e0c\u671b\uff0c\u4f46\u76ee\u524d\u7684\u65b9\u6cd5\u5b58\u5728\u4e3b\u9898\u8986\u76d6\u4e0d\u8db3\u548c\u4e0e\u73b0\u5b9e\u60c5\u5883\u5bf9\u9f50\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aReality-Oriented Safety Evaluation (ROSE)\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6765\u5fae\u8c03\u4e00\u4e2a\u5bf9\u6297\u6027LLM\uff0c\u4ece\u800c\u751f\u6210\u4e3b\u9898\u591a\u6837\u4e14\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u5bf9\u6297\u6027\u63d0\u793a\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u514b\u670d\u63a2\u7d22-\u5229\u7528\u56f0\u5883\u4ee5\u53ca\u7f3a\u4e4f\u73b0\u5b9e\u60c5\u5883\u5316\u7684\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cROSE\u5728\u63ed\u793a\u6700\u5148\u8fdbLLMs\u7684\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u4f5c\u8005\u8ba4\u4e3aROSE\u4ee3\u8868\u4e86\u5411\u66f4\u5b9e\u7528\u548c\u73b0\u5b9e\u5bfc\u5411\u7684LLM\u5b89\u5168\u6027\u8bc4\u4f30\u8fc8\u8fdb\u7684\u4e00\u6b65\uff0c\u5e76\u5e0c\u671b\u8fd9\u4e00\u5de5\u4f5c\u80fd\u591f\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.00651", "pdf": "https://arxiv.org/pdf/2507.00651", "abs": "https://arxiv.org/abs/2507.00651", "authors": ["Maurizio Filippone", "Marius P. Linhard"], "title": "GANs Secretly Perform Approximate Bayesian Model Selection", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Generative Adversarial Networks (GANs) are popular and successful generative\nmodels. Despite their success, optimization is notoriously challenging and they\nrequire regularization against overfitting. In this work, we explain the\nsuccess and limitations of GANs by interpreting them as probabilistic\ngenerative models. This interpretation enables us to view GANs as Bayesian\nneural networks with partial stochasticity, allowing us to establish conditions\nof universal approximation. We can then cast the adversarial-style optimization\nof several variants of GANs as the optimization of a proxy for the marginal\nlikelihood. Taking advantage of the connection between marginal likelihood\noptimization and Occam's razor, we can define regularization and optimization\nstrategies to smooth the loss landscape and search for solutions with minimum\ndescription length, which are associated with flat minima and good\ngeneralization. The results on a wide range of experiments indicate that these\nstrategies lead to performance improvements and pave the way to a deeper\nunderstanding of regularization strategies for GANs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5c06GAN\u89e3\u91ca\u4e3a\u6982\u7387\u751f\u6210\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u89e3\u5176\u6210\u529f\u4e0e\u5c40\u9650\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u4f18\u5316\u548c\u6b63\u5219\u5316\u7b56\u7565\u4ee5\u6539\u5584\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1GANs\u975e\u5e38\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u7684\u4f18\u5316\u8fc7\u7a0b\u5145\u6ee1\u6311\u6218\u4e14\u9700\u8981\u6b63\u5219\u5316\u6765\u9632\u6b62\u8fc7\u62df\u5408\u3002", "method": "\u5c06GANs\u89e3\u91ca\u4e3a\u6982\u7387\u751f\u6210\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u89c6\u4e3a\u5177\u6709\u90e8\u5206\u968f\u673a\u6027\u7684\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u800c\u5efa\u7acb\u666e\u904d\u8fd1\u4f3c\u7684\u6761\u4ef6\u3002\u5c06\u51e0\u79cdGAN\u53d8\u4f53\u7684\u5bf9\u6297\u5f0f\u4f18\u5316\u89c6\u4e3a\u8fb9\u7f18\u4f3c\u7136\u7684\u4ee3\u7406\u4f18\u5316\u3002\u5229\u7528\u8fb9\u7f18\u4f3c\u7136\u4f18\u5316\u4e0e\u5965\u5361\u59c6\u5243\u5200\u539f\u7406\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5b9a\u4e49\u6b63\u5219\u5316\u548c\u4f18\u5316\u7b56\u7565\u4ee5\u5bfb\u627e\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u7684\u89e3\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8fd9\u4e9b\u7b56\u7565\u5e26\u6765\u4e86\u6027\u80fd\u7684\u63d0\u5347\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7406\u89e3GANs\u7684\u6b63\u5219\u5316\u7b56\u7565\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "\u901a\u8fc7\u5c06GANs\u4f5c\u4e3a\u6982\u7387\u751f\u6210\u6a21\u578b\u8fdb\u884c\u89e3\u91ca\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u5b83\u4eec\u7684\u6210\u529f\u4e0e\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u7279\u5b9a\u7684\u6b63\u5219\u5316\u548c\u4f18\u5316\u7b56\u7565\u63d0\u9ad8\u5176\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.00432", "pdf": "https://arxiv.org/pdf/2507.00432", "abs": "https://arxiv.org/abs/2507.00432", "authors": ["Maggie Huan", "Yuetai Li", "Tuney Zheng", "Xiaoyu Xu", "Seungone Kim", "Minxin Du", "Radha Poovendran", "Graham Neubig", "Xiang Yue"], "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Math reasoning has become the poster child of progress in large language\nmodels (LLMs), with new models rapidly surpassing human-level performance on\nbenchmarks like MATH and AIME. But as math leaderboards improve week by week,\nit is worth asking: do these gains reflect broader problem-solving ability or\njust narrow overfitting? To answer this question, we evaluate over 20\nopen-weight reasoning-tuned models across a broad suite of tasks, including\nmath, scientific QA, agent planning, coding, and standard\ninstruction-following. We surprisingly find that most models that succeed in\nmath fail to transfer their gains to other domains. To rigorously study this\nphenomenon, we conduct controlled experiments on Qwen3-14B models using\nmath-only data but different tuning methods. We find that reinforcement\nlearning (RL)-tuned models generalize well across domains, while supervised\nfine-tuning (SFT)-tuned models often forget general capabilities. Latent-space\nrepresentation and token-space distribution shift analyses reveal that SFT\ninduces substantial representation and output drift, while RL preserves\ngeneral-domain structure. Our results suggest a need to rethink standard\npost-training recipes, particularly the reliance on SFT-distilled data for\nadvancing reasoning models.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u7684\u80fd\u529b\u5f80\u5f80\u5c40\u9650\u4e8e\u6570\u5b66\u9886\u57df\uff0c\u96be\u4ee5\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\u3002\u901a\u8fc7\u5bf9\u6bd4\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u53d1\u73b0\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u66f4\u597d\u5730\u4fdd\u6301\u6a21\u578b\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u76d1\u7763\u5fae\u8c03\u5219\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5728\u975e\u6570\u5b66\u9886\u57df\u7684\u6027\u80fd\u4e0b\u964d\u3002\u8fd9\u63d0\u793a\u6211\u4eec\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u5f53\u524d\u7684\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u9886\u57df\u53d6\u5f97\u7684\u8fdb\u6b65\u662f\u5426\u80fd\u4ee3\u8868\u5176\u66f4\u5e7f\u6cdb\u7684\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\u7684\u8fc7\u62df\u5408\u3002", "method": "\u5bf9\u8d85\u8fc720\u4e2a\u5f00\u6e90\u6743\u91cd\u7684\u63a8\u7406\u8c03\u6574\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u6db5\u76d6\u6570\u5b66\u3001\u79d1\u5b66\u95ee\u7b54\u3001\u4ee3\u7406\u89c4\u5212\u3001\u7f16\u7801\u548c\u6807\u51c6\u6307\u4ee4\u9075\u5faa\u7b49\u4efb\u52a1\u3002\u4f7f\u7528Qwen3-14B\u6a21\u578b\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u91c7\u7528\u4ec5\u6570\u5b66\u6570\u636e\u4f46\u4e0d\u540c\u8c03\u6574\u65b9\u6cd5\uff08\u5982\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\uff09\u3002\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u8868\u793a\u548c\u6807\u8bb0\u7a7a\u95f4\u5206\u5e03\u8f6c\u79fb\u5206\u6790\u6765\u63ed\u793a\u4e0d\u540c\u8c03\u6574\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u5927\u591a\u6570\u5728\u6570\u5b66\u4e0a\u8868\u73b0\u826f\u597d\u7684\u6a21\u578b\u672a\u80fd\u5c06\u5176\u6536\u76ca\u8f6c\u79fb\u5230\u5176\u4ed6\u9886\u57df\u3002\u5f3a\u5316\u5b66\u4e60\u8c03\u6574\u7684\u6a21\u578b\u5728\u5404\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u76d1\u7763\u5fae\u8c03\u8c03\u6574\u7684\u6a21\u578b\u5f80\u5f80\u4f1a\u5fd8\u8bb0\u4e00\u822c\u80fd\u529b\u3002\u76d1\u7763\u5fae\u8c03\u4f1a\u5f15\u53d1\u663e\u8457\u7684\u8868\u793a\u548c\u8f93\u51fa\u6f02\u79fb\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u5219\u4fdd\u7559\u4e86\u901a\u7528\u57df\u7ed3\u6784\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003\u6807\u51c6\u7684\u540e\u8bad\u7ec3\u914d\u65b9\uff0c\u7279\u522b\u662f\u5bf9\u4f9d\u8d56SFT\u84b8\u998f\u6570\u636e\u4ee5\u63a8\u8fdb\u63a8\u7406\u6a21\u578b\u7684\u505a\u6cd5\u3002"}}
{"id": "2507.00028", "pdf": "https://arxiv.org/pdf/2507.00028", "abs": "https://arxiv.org/abs/2507.00028", "authors": ["Lihuan Li", "Hao Xue", "Shuang Ao", "Yang Song", "Flora Salim"], "title": "HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The representation of urban trajectory data plays a critical role in\neffectively analyzing spatial movement patterns. Despite considerable progress,\nthe challenge of designing trajectory representations that can capture diverse\nand complementary information remains an open research problem. Existing\nmethods struggle in incorporating trajectory fine-grained details and\nhigh-level summary in a single model, limiting their ability to attend to both\nlong-term dependencies while preserving local nuances. To address this, we\npropose HiT-JEPA (Hierarchical Interactions of Trajectory Semantics via a Joint\nEmbedding Predictive Architecture), a unified framework for learning\nmulti-scale urban trajectory representations across semantic abstraction\nlevels. HiT-JEPA adopts a three-layer hierarchy that progressively captures\npoint-level fine-grained details, intermediate patterns, and high-level\ntrajectory abstractions, enabling the model to integrate both local dynamics\nand global semantics in one coherent structure. Extensive experiments on\nmultiple real-world datasets for trajectory similarity computation show that\nHiT-JEPA's hierarchical design yields richer, multi-scale representations. Code\nis available at: https://anonymous.4open.science/r/HiT-JEPA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6HiT-JEPA\uff0c\u7528\u4e8e\u5b66\u4e60\u591a\u5c3a\u5ea6\u57ce\u5e02\u8f68\u8ff9\u8868\u793a\uff0c\u80fd\u591f\u540c\u65f6\u6355\u83b7\u7ec6\u7c92\u5ea6\u7ec6\u8282\u548c\u9ad8\u5c42\u6b21\u62bd\u8c61\u3002\u901a\u8fc7\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u8f68\u8ff9\u76f8\u4f3c\u6027\u8ba1\u7b97\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u8f68\u8ff9\u8868\u793a\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6355\u83b7\u7ec6\u7c92\u5ea6\u7ec6\u8282\u548c\u9ad8\u5c42\u6b21\u7684\u603b\u7ed3\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5bf9\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u7684\u5173\u6ce8\u4ee5\u53ca\u5c40\u90e8\u7279\u5f81\u7684\u4fdd\u7559\u3002", "method": "\u63d0\u51fa\u4e86HiT-JEPA\uff08\u57fa\u4e8e\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u7684\u8f68\u8ff9\u8bed\u4e49\u5c42\u6b21\u4ea4\u4e92\uff09\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u5c42\u7b49\u7ea7\u7ed3\u6784\u9010\u6b65\u6355\u83b7\u70b9\u7ea7\u7ec6\u7c92\u5ea6\u7ec6\u8282\u3001\u4e2d\u95f4\u6a21\u5f0f\u548c\u9ad8\u5c42\u6b21\u8f68\u8ff9\u62bd\u8c61\uff0c\u4ece\u800c\u6574\u5408\u5c40\u90e8\u52a8\u6001\u548c\u5168\u5c40\u8bed\u4e49\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHiT-JEPA\u7684\u5c42\u6b21\u8bbe\u8ba1\u751f\u6210\u4e86\u66f4\u4e30\u5bcc\u3001\u591a\u5c3a\u5ea6\u7684\u8f68\u8ff9\u8868\u793a\uff0c\u5728\u8f68\u8ff9\u76f8\u4f3c\u6027\u8ba1\u7b97\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "HiT-JEPA\u4e3a\u5b66\u4e60\u591a\u5c3a\u5ea6\u57ce\u5e02\u8f68\u8ff9\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5206\u6790\u7a7a\u95f4\u8fd0\u52a8\u6a21\u5f0f\u3002"}}
{"id": "2507.00736", "pdf": "https://arxiv.org/pdf/2507.00736", "abs": "https://arxiv.org/abs/2507.00736", "authors": ["Arthur Thuy", "Ekaterina Loginova", "Dries F. Benoit"], "title": "Ordinality in Discrete-level Question Difficulty Estimation: Introducing Balanced DRPS and OrderedLogitNN", "categories": ["cs.LG", "stat.ML"], "comment": "Published in the EvalLAC'25 workshop at AIED 2025", "summary": "Recent years have seen growing interest in Question Difficulty Estimation\n(QDE) using natural language processing techniques. Question difficulty is\noften represented using discrete levels, framing the task as ordinal regression\ndue to the inherent ordering from easiest to hardest. However, the literature\nhas neglected the ordinal nature of the task, relying on classification or\ndiscretized regression models, with specialized ordinal regression methods\nremaining unexplored. Furthermore, evaluation metrics are tightly coupled to\nthe modeling paradigm, hindering cross-study comparability. While some metrics\nfail to account for the ordinal structure of difficulty levels, none adequately\naddress class imbalance, resulting in biased performance assessments. This\nstudy addresses these limitations by benchmarking three types of model outputs\n-- discretized regression, classification, and ordinal regression -- using the\nbalanced Discrete Ranked Probability Score (DRPS), a novel metric that jointly\ncaptures ordinality and class imbalance. In addition to using popular ordinal\nregression methods, we propose OrderedLogitNN, extending the ordered logit\nmodel from econometrics to neural networks. We fine-tune BERT on the RACE++ and\nARC datasets and find that OrderedLogitNN performs considerably better on\ncomplex tasks. The balanced DRPS offers a robust and fair evaluation metric for\ndiscrete-level QDE, providing a principled foundation for future research.", "AI": {"tldr": "\u8fd1\u5e74\u6765\uff0c\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u95ee\u9898\u96be\u5ea6\u4f30\u8ba1\uff08QDE\uff09\u5f15\u8d77\u4e86\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u672c\u6587\u901a\u8fc7\u5e73\u8861\u79bb\u6563\u6392\u5e8f\u6982\u7387\u5f97\u5206\uff08DRPS\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e09\u79cd\u6a21\u578b\u8f93\u51fa\u7c7b\u578b\uff0c\u5e76\u63d0\u51faOrderedLogitNN\u65b9\u6cd5\uff0c\u53d1\u73b0\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u540c\u65f6\u4e3a\u79bb\u6563\u7ea7\u522bQDE\u63d0\u4f9b\u4e86\u7a33\u5065\u548c\u516c\u5e73\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5ffd\u89c6\u4e86\u95ee\u9898\u96be\u5ea6\u4f30\u8ba1\u4efb\u52a1\u4e2d\u7684\u5e8f\u6570\u6027\u8d28\uff0c\u4f7f\u7528\u5206\u7c7b\u6216\u79bb\u6563\u5316\u56de\u5f52\u6a21\u578b\u800c\u672a\u63a2\u7d22\u4e13\u95e8\u7684\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u672a\u80fd\u5145\u5206\u8003\u8651\u96be\u5ea6\u7b49\u7ea7\u7684\u5e8f\u6570\u7ed3\u6784\u53ca\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u8bc4\u4f30\u504f\u5dee\u3002", "method": "1. \u57fa\u51c6\u6d4b\u8bd5\u4e09\u79cd\u6a21\u578b\u8f93\u51fa\uff1a\u79bb\u6563\u5316\u56de\u5f52\u3001\u5206\u7c7b\u548c\u5e8f\u6570\u56de\u5f52\u3002\n2. \u63d0\u51fa\u5e73\u8861\u79bb\u6563\u6392\u5e8f\u6982\u7387\u5f97\u5206\uff08DRPS\uff09\uff0c\u8054\u5408\u6355\u6349\u5e8f\u6570\u6027\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u3002\n3. \u63d0\u51faOrderedLogitNN\u65b9\u6cd5\uff0c\u5c06\u7ecf\u6d4e\u5b66\u4e2d\u7684\u6709\u5e8flogit\u6a21\u578b\u6269\u5c55\u5230\u795e\u7ecf\u7f51\u7edc\u3002\n4. \u5728RACE++\u548cARC\u6570\u636e\u96c6\u4e0a\u5fae\u8c03BERT\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5176\u5b83\u65b9\u6cd5\u76f8\u6bd4\uff0cOrderedLogitNN\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u66f4\u597d\u7684\u6027\u80fd\u3002\u5e73\u8861DRPS\u4f5c\u4e3a\u4e00\u79cd\u7a33\u5065\u4e14\u516c\u5e73\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u79bb\u6563\u7ea7\u522bQDE\u4e2d\u7684\u5e8f\u6570\u6027\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u6709\u5e8f\u56de\u5f52\u65b9\u6cd5\u548c\u5e73\u8861DRPS\uff0c\u4e3a\u79bb\u6563\u7ea7\u522b\u95ee\u9898\u96be\u5ea6\u4f30\u8ba1\u4efb\u52a1\u5960\u5b9a\u4e86\u539f\u5219\u6027\u7684\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u672a\u6765\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.00557", "pdf": "https://arxiv.org/pdf/2507.00557", "abs": "https://arxiv.org/abs/2507.00557", "authors": ["Tianyi Ding", "Haokun Li", "Xinpeng Ni", "Bican Xia", "Tianqi Zhao"], "title": "Advancing Local Search in SMT-NRA with MCSAT Integration", "categories": ["cs.AI", "cs.LO", "cs.SC"], "comment": null, "summary": "In this paper, we advance local search for Satisfiability Modulo the Theory\nof Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a\ntwo-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the\nkey operation, cell-jump, of the local search method for SMT-NRA. Then, we\npropose an extended local search framework, named \\emph{$2d$-LS} (following the\nlocal search framework, LS, for SMT-NRA), integrating the model constructing\nsatisfiability calculus (MCSAT) framework to improve search efficiency. To\nfurther improve the efficiency of MCSAT, we implement a recently proposed\ntechnique called \\emph{sample-cell projection operator} for MCSAT, which is\nwell suited for CDCL-style search in the real domain and helps guide the search\naway from conflicting states. Finally, we design a hybrid framework for SMT-NRA\ncombining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through\ninformation exchange. The experimental results demonstrate improvements in\nlocal search performance, highlighting the effectiveness of the proposed\nmethods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eSMT-NRA\u7684\u4e8c\u7ef4\u5355\u5143\u8df3\u8dc3\uff082d-cell-jump\uff09\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u5c40\u90e8\u641c\u7d22\u6846\u67b6\uff0c\u5e76\u7ed3\u5408MCSAT\u548cOpenCAD\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5c40\u90e8\u641c\u7d22\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u975e\u7ebf\u6027\u5b9e\u6570\u7b97\u672f\u7406\u8bba\uff08SMT-NRA\uff09\u4e2d\u7684\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\u95ee\u9898\u7684\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\uff0c\u63d0\u9ad8\u5176\u6c42\u89e3\u6548\u7387\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5355\u5143\u8df3\u8dc3\uff082d-cell-jump\uff09\u64cd\u4f5c\uff0c\u63a8\u5e7f\u4e86SMT-NRA\u4e2d\u5c40\u90e8\u641c\u7d22\u7684\u5173\u952e\u64cd\u4f5c\u3002\n2. \u63d0\u51fa\u4e00\u4e2a\u6269\u5c55\u7684\u5c40\u90e8\u641c\u7d22\u6846\u67b6\uff082d-LS\uff09\uff0c\u5c06\u6a21\u578b\u6784\u9020\u53ef\u6ee1\u8db3\u6027\u6f14\u7b97\uff08MCSAT\uff09\u6846\u67b6\u96c6\u6210\u5230\u5c40\u90e8\u641c\u7d22\u4e2d\u4ee5\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u3002\n3. \u5b9e\u73b0\u4e86\u6837\u672c\u5355\u5143\u6295\u5f71\u8fd0\u7b97\u7b26\uff08sample-cell projection operator\uff09\u6765\u8fdb\u4e00\u6b65\u63d0\u5347MCSAT\u7684\u6548\u7387\u3002\n4. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408MCSAT\u30012d-LS\u548cOpenCAD\uff0c\u901a\u8fc7\u4fe1\u606f\u4ea4\u6362\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u5c40\u90e8\u641c\u7d22\u6027\u80fd\u7684\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u76842d-cell-jump\u65b9\u6cd5\u30012d-LS\u6846\u67b6\u4ee5\u53ca\u6df7\u5408\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86SMT-NRA\u95ee\u9898\u7684\u5c40\u90e8\u641c\u7d22\u6027\u80fd\u3002"}}
{"id": "2507.00029", "pdf": "https://arxiv.org/pdf/2507.00029", "abs": "https://arxiv.org/abs/2507.00029", "authors": ["Wenbing Li", "Zikai Song", "Hang Zhou", "Yunyao Zhang", "Junqing Yu", "Wei Yang"], "title": "LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent efforts to combine low-rank adaptation (LoRA) with mixture-of-experts\n(MoE) for adapting large language models (LLMs) to multiple tasks still exhibit\nprevailing limitations: they either swap entire attention/feed-forward layers\nfor switch experts or bolt on parallel expert branches, diluting parameter\nefficiency and task fidelity. We propose the LoRA-Mixer, a modular and\nlightweight MoE framework that integrates LoRA experts. Our core innovation\nlies in replacing the projection matrices of the attention module's\ninput/output linear layers with dynamically routed, task-specific LoRA experts.\nThis design ensures seamless compatibility with diverse foundation models,\nincluding transformers and state space models (SSMs), by leveraging their\ninherent linear projection structures. The framework supports two operational\nparadigms: (1) joint optimization of LoRA experts and routing mechanisms via a\nnovel hard-soft routing strategy, or (2) direct deployment of pre-trained,\nfrozen LoRA modules sourced from external repositories. To enable robust router\ntraining with limited data while ensuring stable routing decisions and\nmaximizing expert reuse, we introduce an adaptive Specialization Balance Loss\n(SBL) that jointly optimizes expert balance and task-specific alignment.\nExtensive experiments on seven benchmark datasets, including MedQA, CoLA,\nSST-2, GSM8K, ARC-E, ARC-C, and HumanEval, demonstrate the effectiveness of\nLoRA-Mixer. On datasets such as GSM8K, HumanEval, and MedQA, LoRA-Mixer\nachieves significant improvements of 7.61%, 4.88%, and 3.08% over the base\nmodels, respectively. Compared with state-of-the-art methods, LoRA-Mixer\nachieves additional improvements of 1.09%, 1.45%, and 1.68%, respectively,\nusing only 48% of the parameters, demonstrating its efficiency and strong\nperformance.", "AI": {"tldr": "\u8fd1\u671f\u5c06\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u4e0e\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u7ed3\u5408\u4ee5\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9002\u5e94\u591a\u4efb\u52a1\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u4e14\u8f7b\u91cf\u7ea7\u7684MoE\u6846\u67b6\u2014\u2014LoRA-Mixer\uff0c\u901a\u8fc7\u7528\u52a8\u6001\u8def\u7531\u7684\u4efb\u52a1\u7279\u5b9aLoRA\u4e13\u5bb6\u66ff\u6362\u6ce8\u610f\u529b\u6a21\u5757\u8f93\u5165/\u8f93\u51fa\u7ebf\u6027\u5c42\u7684\u6295\u5f71\u77e9\u9635\uff0c\u89e3\u51b3\u4e86\u53c2\u6570\u6548\u7387\u548c\u4efb\u52a1\u4fdd\u771f\u5ea6\u7684\u95ee\u9898\u3002\u8be5\u8bbe\u8ba1\u4e0e\u5305\u62ec\u53d8\u538b\u5668\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u5185\u7684\u591a\u79cd\u57fa\u7840\u6a21\u578b\u517c\u5bb9\uff0c\u5e76\u652f\u6301\u4e24\u79cd\u64cd\u4f5c\u6a21\u5f0f\uff1a\u8054\u5408\u4f18\u5316LoRA\u4e13\u5bb6\u548c\u8def\u7531\u673a\u5236\u6216\u76f4\u63a5\u90e8\u7f72\u9884\u8bad\u7ec3\u7684\u51bb\u7ed3LoRA\u6a21\u5757\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u81ea\u9002\u5e94\u4e13\u4e1a\u5316\u5e73\u8861\u635f\u5931\uff08SBL\uff09\uff0c\u4ee5\u786e\u4fdd\u7a33\u5b9a\u7684\u8def\u7531\u51b3\u7b56\u548c\u6700\u5927\u5316\u4e13\u5bb6\u91cd\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLoRA-Mixer\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6548\u679c\u548c\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4ec5\u4f7f\u752848%\u7684\u53c2\u6570\uff0c\u5c55\u73b0\u4e86\u5176\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5c06LoRA\u4e0eMoE\u7ed3\u5408\u7684\u65b9\u6cd5\u8981\u4e48\u5b8c\u5168\u4ea4\u6362\u6ce8\u610f\u529b/\u524d\u9988\u5c42\u4ee5\u8fdb\u884c\u4e13\u5bb6\u5207\u6362\uff0c\u8981\u4e48\u6dfb\u52a0\u5e76\u884c\u4e13\u5bb6\u5206\u652f\uff0c\u5bfc\u81f4\u53c2\u6570\u6548\u7387\u964d\u4f4e\u548c\u4efb\u52a1\u4fdd\u771f\u5ea6\u4e0b\u964d\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLoRA-Mixer\u7684\u6a21\u5757\u5316\u8f7b\u91cf\u7ea7MoE\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u7528\u52a8\u6001\u8def\u7531\u7684\u4efb\u52a1\u7279\u5b9aLoRA\u4e13\u5bb6\u66ff\u6362\u6ce8\u610f\u529b\u6a21\u5757\u8f93\u5165/\u8f93\u51fa\u7ebf\u6027\u5c42\u7684\u6295\u5f71\u77e9\u9635\u3002\u8be5\u6846\u67b6\u652f\u6301\u4e24\u79cd\u64cd\u4f5c\u6a21\u5f0f\uff1a1) \u901a\u8fc7\u65b0\u9896\u7684\u786c\u8f6f\u8def\u7531\u7b56\u7565\u8054\u5408\u4f18\u5316LoRA\u4e13\u5bb6\u548c\u8def\u7531\u673a\u5236\uff1b2) \u76f4\u63a5\u90e8\u7f72\u4ece\u5916\u90e8\u5b58\u50a8\u5e93\u83b7\u53d6\u7684\u9884\u8bad\u7ec3\u51bb\u7ed3LoRA\u6a21\u5757\u3002\u4e3a\u4e86\u786e\u4fdd\u6709\u9650\u6570\u636e\u4e0b\u7684\u7a33\u5065\u8def\u7531\u8bad\u7ec3\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u4e13\u4e1a\u5316\u5e73\u8861\u635f\u5931\uff08SBL\uff09\uff0c\u7528\u4e8e\u8054\u5408\u4f18\u5316\u4e13\u5bb6\u5e73\u8861\u548c\u4efb\u52a1\u7279\u5b9a\u5bf9\u9f50\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLoRA-Mixer\u5728GSM8K\u3001HumanEval\u548cMedQA\u7b49\u6570\u636e\u96c6\u4e0a\u5206\u522b\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u9ad8\u4e867.61%\u30014.88%\u548c3.08%\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cLoRA-Mixer\u5206\u522b\u989d\u5916\u63d0\u9ad8\u4e861.09%\u30011.45%\u548c1.68%\uff0c\u540c\u65f6\u4ec5\u4f7f\u7528\u4e8648%\u7684\u53c2\u6570\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5f3a\u6027\u80fd\u3002", "conclusion": "LoRA-Mixer\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u5757\u5316\u548c\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u4efb\u52a1\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u3002\u5b83\u4e0e\u591a\u79cd\u57fa\u7840\u6a21\u578b\u517c\u5bb9\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u81ea\u9002\u5e94\u4e13\u4e1a\u5316\u5e73\u8861\u635f\u5931\uff08SBL\uff09\u786e\u4fdd\u4e86\u7a33\u5065\u7684\u8def\u7531\u8bad\u7ec3\u548c\u4e13\u5bb6\u91cd\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86LoRA-Mixer\u7684\u4f18\u8d8a\u6027\u80fd\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2507.00726", "pdf": "https://arxiv.org/pdf/2507.00726", "abs": "https://arxiv.org/abs/2507.00726", "authors": ["Dongyoon Hwang", "Hojoon Lee", "Jaegul Choo", "Dongmin Park", "Jongho Park"], "title": "Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess", "categories": ["cs.AI", "cs.LG"], "comment": "27 pages", "summary": "While reinforcement learning (RL) for large language models (LLMs) has shown\npromise in mathematical reasoning, strategic reasoning for LLMs using RL\nremains largely unexplored. We investigate whether LLMs can develop strategic\nreasoning capabilities through RL in chess. To this end, we leverage a\nchess-pretrained action-value network to provide dense reward on the LLM's\noutput move quality, which can be seen as a form of knowledge distillation. Our\nexperiments show that our distillation-based dense rewards often outperform\nsparse binary rewards. However, surprisingly, all models plateau far below\nexpert levels. We provide SFT and RL ablations on chess reasoning training and\nfind evidence that this limitation stems from a deficit in the pretrained\nmodels' internal understanding of chess--a deficit which RL alone may not be\nable to fully overcome.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u56fd\u9645\u8c61\u68cb\u7684\u6218\u7565\u63a8\u7406\u3002\u5229\u7528\u9884\u8bad\u7ec3\u7684\u52a8\u4f5c-\u4ef7\u503c\u7f51\u7edc\u63d0\u4f9b\u5bc6\u96c6\u5956\u52b1\uff0c\u8fd9\u79cd\u5bc6\u96c6\u5956\u52b1\u901a\u5e38\u4f18\u4e8e\u7a00\u758f\u4e8c\u5143\u5956\u52b1\u3002\u7136\u800c\uff0c\u6240\u6709\u6a21\u578b\u7684\u8868\u73b0\u90fd\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u6c34\u5e73\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u56fd\u9645\u8c61\u68cb\u7684\u5185\u90e8\u7406\u89e3\u5b58\u5728\u4e0d\u8db3\uff0c\u800c\u4ec5\u9760RL\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u514b\u670d\u8fd9\u4e00\u7f3a\u9677\u3002", "motivation": "\u5c3d\u7ba1\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4f7f\u7528RL\u8fdb\u884c\u6218\u7565\u63a8\u7406\u7684\u7814\u7a76\u5c1a\u5904\u4e8e\u521d\u6b65\u9636\u6bb5\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8LLMs\u662f\u5426\u53ef\u4ee5\u901a\u8fc7RL\u53d1\u5c55\u51fa\u56fd\u9645\u8c61\u68cb\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u4f7f\u7528\u4e86\u4e00\u4e2a\u56fd\u9645\u8c61\u68cb\u9884\u8bad\u7ec3\u7684\u52a8\u4f5c-\u4ef7\u503c\u7f51\u7edc\u6765\u4e3aLLMs\u7684\u8f93\u51fa\u79fb\u52a8\u8d28\u91cf\u63d0\u4f9b\u5bc6\u96c6\u5956\u52b1\uff0c\u8fd9\u79cd\u65b9\u5f0f\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u77e5\u8bc6\u84b8\u998f\u3002\u7136\u540e\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u8fd9\u79cd\u5bc6\u96c6\u5956\u52b1\u4e0e\u7a00\u758f\u4e8c\u5143\u5956\u52b1\u7684\u6548\u679c\uff0c\u5e76\u8fdb\u884c\u4e86SFT\u548cRL\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u84b8\u998f\u7684\u5bc6\u96c6\u5956\u52b1\u5f80\u5f80\u6bd4\u7a00\u758f\u4e8c\u5143\u5956\u52b1\u8868\u73b0\u66f4\u597d\u3002\u7136\u800c\uff0c\u6240\u6709\u6a21\u578b\u7684\u8868\u73b0\u90fd\u5728\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u6c34\u5e73\u7684\u5730\u65b9\u505c\u6ede\u4e0d\u524d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cLLMs\u901a\u8fc7RL\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u56fd\u9645\u8c61\u68cb\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u6548\u679c\u53d7\u5230\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u56fd\u9645\u8c61\u68cb\u5185\u90e8\u7406\u89e3\u4e0d\u8db3\u7684\u9650\u5236\uff0c\u5355\u9760RL\u53ef\u80fd\u65e0\u6cd5\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2507.00030", "pdf": "https://arxiv.org/pdf/2507.00030", "abs": "https://arxiv.org/abs/2507.00030", "authors": ["Abhishek Verma", "Nallarasan V", "Balaraman Ravindran"], "title": "Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) has achieved remarkable success in complex\nsequential decision-making tasks, such as playing Atari 2600 games and\nmastering board games. A critical yet underexplored aspect of DRL is the\ntemporal scale of action execution. We propose a novel paradigm that integrates\ncontextual bandits with DRL to adaptively select action durations, enhancing\npolicy flexibility and computational efficiency. Our approach augments a Deep\nQ-Network (DQN) with a contextual bandit module that learns to choose optimal\naction repetition rates based on state contexts. Experiments on Atari 2600\ngames demonstrate significant performance improvements over static duration\nbaselines, highlighting the efficacy of adaptive temporal abstractions in DRL.\nThis paradigm offers a scalable solution for real-time applications like gaming\nand robotics, where dynamic action durations are critical.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e0a\u4e0b\u6587Bandits\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u65b0\u8303\u5f0f\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u9009\u62e9\u52a8\u4f5c\u6267\u884c\u65f6\u957f\uff0c\u4ece\u800c\u63d0\u5347\u7b56\u7565\u7075\u6d3b\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u9759\u6001\u65f6\u957f\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u5728Atari 2600\u6e38\u620f\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u5982\u6e38\u620f\u548c\u673a\u5668\u4eba\u9886\u57df\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5728\u590d\u6742\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u52a8\u4f5c\u6267\u884c\u7684\u65f6\u95f4\u5c3a\u5ea6\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7684DRL\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u7684\u6216\u9884\u5b9a\u4e49\u7684\u52a8\u4f5c\u6301\u7eed\u65f6\u95f4\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u7b56\u7565\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\uff0c\u5c06\u4e0a\u4e0b\u6587Bandits\u4e0eDRL\u76f8\u7ed3\u5408\uff0c\u4ee5\u81ea\u9002\u5e94\u5730\u9009\u62e9\u52a8\u4f5c\u6301\u7eed\u65f6\u95f4\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ed6\u4eec\u5728Deep Q-Network (DQN)\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u4e0a\u4e0b\u6587Bandits\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6839\u636e\u72b6\u6001\u60c5\u5883\u5b66\u4e60\u9009\u62e9\u6700\u4f18\u7684\u52a8\u4f5c\u91cd\u590d\u7387\u3002", "result": "\u5728Atari 2600\u6e38\u620f\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u76f8\u8f83\u4e8e\u9759\u6001\u65f6\u957f\u57fa\u7ebf\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u65f6\u95f4\u62bd\u8c61\u5728DRL\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u8303\u5f0f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u9700\u8981\u52a8\u6001\u52a8\u4f5c\u6301\u7eed\u65f6\u95f4\u7684\u5b9e\u65f6\u5e94\u7528\uff0c\u4f8b\u5982\u6e38\u620f\u548c\u673a\u5668\u4eba\u6280\u672f\u3002"}}
{"id": "2507.00810", "pdf": "https://arxiv.org/pdf/2507.00810", "abs": "https://arxiv.org/abs/2507.00810", "authors": ["Qing Xu", "Xiaohua Xuan"], "title": "A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "In this paper, we propose an improved numerical algorithm for solving minimax\nproblems based on nonsmooth optimization, quadratic programming and iterative\nprocess. We also provide a rigorous proof of convergence for our algorithm\nunder some mild assumptions, such as gradient continuity and boundedness. Such\nan algorithm can be widely applied in various fields such as robust\noptimization, imbalanced learning, etc.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5149\u6ed1\u4f18\u5316\u3001\u4e8c\u6b21\u89c4\u5212\u548c\u8fed\u4ee3\u8fc7\u7a0b\u7684\u6539\u8fdb\u6570\u503c\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u9c81\u68d2\u4f18\u5316\u548c\u4e0d\u5e73\u8861\u5b66\u4e60\u7b49\u9886\u57df\uff0c\u5e76\u5728\u4e00\u5b9a\u5047\u8bbe\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u57fa\u4e8e\u975e\u5149\u6ed1\u4f18\u5316\u7684\u6781\u5c0f\u6781\u5927\u95ee\u9898\uff0c\u63d0\u9ad8\u6c42\u89e3\u6548\u7387\u5e76\u6269\u5c55\u5176\u5e94\u7528\u9886\u57df\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u975e\u5149\u6ed1\u4f18\u5316\u3001\u4e8c\u6b21\u89c4\u5212\u4ee5\u53ca\u8fed\u4ee3\u8fc7\u7a0b\u8bbe\u8ba1\u4e00\u79cd\u6539\u8fdb\u7684\u6570\u503c\u7b97\u6cd5\uff0c\u5e76\u5728\u68af\u5ea6\u8fde\u7eed\u6027\u548c\u6709\u754c\u6027\u7b49\u6e29\u548c\u5047\u8bbe\u4e0b\u4e25\u683c\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "result": "\u8be5\u7b97\u6cd5\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u53ef\u4ee5\u5728\u9c81\u68d2\u4f18\u5316\u3001\u4e0d\u5e73\u8861\u5b66\u4e60\u7b49\u591a\u4e2a\u9886\u57df\u4e2d\u5e94\u7528\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u89e3\u51b3\u6781\u5c0f\u6781\u5927\u95ee\u9898\u65f6\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u7406\u8bba\u5206\u6790\u8868\u660e\u5176\u5177\u5907\u6536\u655b\u6027\u3002"}}
{"id": "2507.00031", "pdf": "https://arxiv.org/pdf/2507.00031", "abs": "https://arxiv.org/abs/2507.00031", "authors": ["Chuan Li", "Jiang You", "Hassine Moungla", "Vincent Gauthier", "Miguel Nunez-del-Prado", "Hugo Alatrista-Salas"], "title": "Enhancing Spatio-Temporal Forecasting with Spatial Neighbourhood Fusion:A Case Study on COVID-19 Mobility in Peru", "categories": ["cs.LG"], "comment": null, "summary": "Accurate modeling of human mobility is critical for understanding epidemic\nspread and deploying timely interventions. In this work, we leverage a\nlarge-scale spatio-temporal dataset collected from Peru's national Digital\nContact Tracing (DCT) application during the COVID-19 pandemic to forecast\nmobility flows across urban regions. A key challenge lies in the spatial\nsparsity of hourly mobility counts across hexagonal grid cells, which limits\nthe predictive power of conventional time series models. To address this, we\npropose a lightweight and model-agnostic Spatial Neighbourhood Fusion (SPN)\ntechnique that augments each cell's features with aggregated signals from its\nimmediate H3 neighbors. We evaluate this strategy on three forecasting\nbackbones: NLinear, PatchTST, and K-U-Net, under various historical input\nlengths. Experimental results show that SPN consistently improves forecasting\nperformance, achieving up to 9.85 percent reduction in test MSE. Our findings\ndemonstrate that spatial smoothing of sparse mobility signals provides a simple\nyet effective path toward robust spatio-temporal forecasting during public\nhealth crises.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdSpatial Neighbourhood Fusion (SPN)\u6280\u672f\uff0c\u901a\u8fc7\u805a\u5408\u76f8\u90bb\u533a\u57df\u7684\u7279\u5f81\u6765\u589e\u5f3a\u7a00\u758f\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u5efa\u6a21\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSPN\u5728\u591a\u4e2a\u9884\u6d4b\u6a21\u578b\u4e0a\u90fd\u80fd\u663e\u8457\u964d\u4f4e\u6d4b\u8bd5MSE\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u4eba\u7c7b\u79fb\u52a8\u5bf9\u4e8e\u7406\u89e3\u75ab\u60c5\u4f20\u64ad\u548c\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u75ab\u60c5\u671f\u95f4\uff0c\u57fa\u4e8e\u65f6\u7a7a\u6570\u636e\u7684\u79fb\u52a8\u6027\u5efa\u6a21\u9762\u4e34\u6570\u636e\u7a00\u758f\u6027\u7684\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u4e0e\u6a21\u578b\u65e0\u5173\u7684Spatial Neighbourhood Fusion\uff08SPN\uff09\u6280\u672f\uff0c\u8be5\u6280\u672f\u901a\u8fc7\u805a\u5408\u6bcf\u4e2a\u5355\u5143\u683c\u7684\u76f4\u63a5H3\u90bb\u5c45\u7684\u7279\u5f81\u6765\u589e\u5f3a\u5176\u7279\u6027\u3002SPN\u53ef\u4ee5\u5728\u4e0d\u540c\u7684\u9884\u6d4b\u6a21\u578b\u4e2d\u5e94\u7528\u4ee5\u6539\u5584\u9884\u6d4b\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSPN\u5728NLinear\u3001PatchTST\u548cK-U-Net\u4e09\u4e2a\u9884\u6d4b\u6a21\u578b\u4e0a\u5747\u80fd\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u6700\u591a\u53ef\u5c06\u6d4b\u8bd5MSE\u51cf\u5c119.85%\u3002", "conclusion": "\u7a7a\u95f4\u5e73\u6ed1\u5904\u7406\u7a00\u758f\u79fb\u52a8\u4fe1\u53f7\u4e3a\u516c\u5171\u5065\u5eb7\u5371\u673a\u671f\u95f4\u7684\u9c81\u68d2\u65f6\u7a7a\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u6761\u7b80\u5355\u800c\u6709\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2507.00841", "pdf": "https://arxiv.org/pdf/2507.00841", "abs": "https://arxiv.org/abs/2507.00841", "authors": ["Siyuan Liang", "Tianmeng Fang", "Zhe Liu", "Aishan Liu", "Yan Xiao", "Jinyuan He", "Ee-Chien Chang", "Xiaochun Cao"], "title": "SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents", "categories": ["cs.AI", "cs.CR"], "comment": "12 pages", "summary": "With the wide application of multimodal foundation models in intelligent\nagent systems, scenarios such as mobile device control, intelligent assistant\ninteraction, and multimodal task execution are gradually relying on such large\nmodel-driven agents. However, the related systems are also increasingly exposed\nto potential jailbreak risks. Attackers may induce the agents to bypass the\noriginal behavioral constraints through specific inputs, and then trigger\ncertain risky and sensitive operations, such as modifying settings, executing\nunauthorized commands, or impersonating user identities, which brings new\nchallenges to system security. Existing security measures for intelligent\nagents still have limitations when facing complex interactions, especially in\ndetecting potentially risky behaviors across multiple rounds of conversations\nor sequences of tasks. In addition, an efficient and consistent automated\nmethodology to assist in assessing and determining the impact of such risks is\ncurrently lacking. This work explores the security issues surrounding mobile\nmultimodal agents, attempts to construct a risk discrimination mechanism by\nincorporating behavioral sequence information, and designs an automated\nassisted assessment scheme based on a large language model. Through preliminary\nvalidation in several representative high-risk tasks, the results show that the\nmethod can improve the recognition of risky behaviors to some extent and assist\nin reducing the probability of agents being jailbroken. We hope that this study\ncan provide some valuable references for the security risk modeling and\nprotection of multimodal intelligent agent systems.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u884c\u4e3a\u5e8f\u5217\u4fe1\u606f\u878d\u5165\u98ce\u9669\u5224\u522b\u673a\u5236\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8f85\u52a9\u8bc4\u4f30\u65b9\u6848\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u79fb\u52a8\u591a\u6a21\u6001\u4ee3\u7406\u7684\u5b89\u5168\u95ee\u9898\u5e76\u964d\u4f4e\u5176\u88ab\u8d8a\u72f1\u7684\u98ce\u9669\u3002\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u63d0\u9ad8\u5bf9\u5371\u9669\u884c\u4e3a\u7684\u8bc6\u522b\u80fd\u529b\u5e76\u51cf\u5c11\u4ee3\u7406\u88ab\u8d8a\u72f1\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u76f8\u5173\u7cfb\u7edf\u9010\u6e10\u4f9d\u8d56\u4e8e\u8fd9\u4e9b\u5927\u578b\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7406\uff0c\u4f46\u540c\u65f6\u4e5f\u9762\u4e34\u6f5c\u5728\u7684\u8d8a\u72f1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u7279\u5b9a\u8f93\u5165\u8bf1\u5bfc\u4ee3\u7406\u7ed5\u8fc7\u539f\u59cb\u884c\u4e3a\u7ea6\u675f\uff0c\u89e6\u53d1\u5371\u9669\u548c\u654f\u611f\u64cd\u4f5c\uff0c\u800c\u73b0\u6709\u7684\u5b89\u5168\u63aa\u65bd\u5728\u590d\u6742\u4ea4\u4e92\u573a\u666f\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u56f4\u7ed5\u79fb\u52a8\u591a\u6a21\u6001\u4ee3\u7406\u7684\u5b89\u5168\u95ee\u9898\uff0c\u5c1d\u8bd5\u901a\u8fc7\u878d\u5408\u884c\u4e3a\u5e8f\u5217\u4fe1\u606f\u6784\u5efa\u98ce\u9669\u5224\u522b\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8f85\u52a9\u8bc4\u4f30\u65b9\u6848\u3002", "result": "\u5728\u51e0\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u9ad8\u98ce\u9669\u4efb\u52a1\u4e2d\u7684\u521d\u6b65\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u5bf9\u5371\u9669\u884c\u4e3a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u6709\u52a9\u4e8e\u964d\u4f4e\u4ee3\u7406\u88ab\u8d8a\u72f1\u7684\u6982\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\u5efa\u6a21\u548c\u9632\u62a4\u63d0\u4f9b\u4e86\u4e00\u4e9b\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2507.00034", "pdf": "https://arxiv.org/pdf/2507.00034", "abs": "https://arxiv.org/abs/2507.00034", "authors": ["Reece Bourisaw", "Reid McCants", "Jean-Marie Le Corre", "Anna Iskhakova", "Arsen S. Iskhakov"], "title": "Data Collection with Non-Uniform Axial Power for Phase II of the OECD/NEA AI/ML Critical Heat Flux Benchmark", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Critical heat flux (CHF) marks the onset of boiling crisis in light-water\nreactors, defining safe thermal-hydraulic operating limits. To support Phase II\nof the OECD/NEA AI/ML CHF benchmark, which introduces spatially varying power\nprofiles, this work compiles and digitizes a broad CHF dataset covering both\nuniform and non-uniform axial heating conditions. Heating profiles were\nextracted from technical reports, interpolated onto a consistent axial mesh,\nvalidated via energy-balance checks, and encoded in machine-readable formats\nfor benchmark compatibility.\n  Classical CHF correlations exhibit substantial errors under uniform heating\nand degrade markedly when applied to non-uniform profiles, while modern tabular\nmethods offer improved but still imperfect predictions. A neural network\ntrained solely on uniform data performs well in that regime but fails to\ngeneralize to spatially varying scenarios, underscoring the need for models\nthat explicitly incorporate axial power distributions. By providing these\ncurated datasets and baseline modeling results, this study lays the groundwork\nfor advanced transfer-learning strategies, rigorous uncertainty quantification,\nand design-optimization efforts in the next phase of the CHF benchmark.", "AI": {"tldr": "\u672c\u7814\u7a76\u6c47\u7f16\u548c\u6570\u5b57\u5316\u4e86\u4e00\u4e2a\u5e7f\u6cdb\u7684\u4e34\u754c\u70ed\u6d41\u5bc6\u5ea6\uff08CHF\uff09\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e86\u5747\u5300\u548c\u975e\u5747\u5300\u8f74\u5411\u52a0\u70ed\u6761\u4ef6\uff0c\u4e3aOECD/NEA AI/ML CHF\u57fa\u51c6\u7b2c\u4e8c\u9636\u6bb5\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u7ecf\u5178CHF\u76f8\u5173\u6027\u5728\u5747\u5300\u52a0\u70ed\u4e0b\u5b58\u5728\u663e\u8457\u8bef\u5dee\uff0c\u5728\u975e\u5747\u5300\u52a0\u70ed\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u5dee\uff1b\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u867d\u7136\u5728\u5747\u5300\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u65e0\u6cd5\u63a8\u5e7f\u5230\u7a7a\u95f4\u53d8\u5316\u573a\u666f\u4e2d\u3002\u56e0\u6b64\u9700\u8981\u663e\u5f0f\u7ed3\u5408\u8f74\u5411\u529f\u7387\u5206\u5e03\u7684\u6a21\u578b\u3002", "method": "\u4ece\u6280\u672f\u62a5\u544a\u4e2d\u63d0\u53d6\u52a0\u70ed\u66f2\u7ebf\uff0c\u5c06\u5176\u63d2\u503c\u5230\u4e00\u81f4\u7684\u8f74\u5411\u7f51\u683c\u4e0a\uff0c\u5e76\u901a\u8fc7\u80fd\u91cf\u5e73\u8861\u68c0\u67e5\u8fdb\u884c\u9a8c\u8bc1\uff0c\u6700\u540e\u5c06\u6570\u636e\u7f16\u7801\u4e3a\u673a\u5668\u53ef\u8bfb\u683c\u5f0f\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u8fd9\u4e9b\u7b56\u5212\u7684\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u5efa\u6a21\u7ed3\u679c\u3002", "result": "\u7f16\u5236\u7684\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u5747\u5300\u548c\u975e\u5747\u5300\u8f74\u5411\u52a0\u70ed\u6761\u4ef6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u9ad8\u7ea7\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u3001\u4e25\u683c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u8bbe\u8ba1\u4f18\u5316\u5de5\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u63a8\u52a8\u4e86CHF\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e0b\u4e00\u9636\u6bb5\u53d1\u5c55\u3002"}}
{"id": "2507.00951", "pdf": "https://arxiv.org/pdf/2507.00951", "abs": "https://arxiv.org/abs/2507.00951", "authors": ["Rizwan Qureshi", "Ranjan Sapkota", "Abbas Shah", "Amgad Muneer", "Anas Zafar", "Ashmal Vayani", "Maged Shoman", "Abdelrahman B. M. Eldaly", "Kai Zhang", "Ferhat Sadak", "Shaina Raza", "Xinqi Fan", "Ravid Shwartz-Ziv", "Hong Yan", "Vinjia Jain", "Aman Chadha", "Manoj Karkee", "Jia Wu", "Philip Torr", "Seyedali Mirjalili"], "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "categories": ["cs.AI"], "comment": null, "summary": "Can machines truly think, reason and act in domains like humans? This\nenduring question continues to shape the pursuit of Artificial General\nIntelligence (AGI). Despite the growing capabilities of models such as GPT-4.5,\nDeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal\nfluency and partial reasoning, these systems remain fundamentally limited by\ntheir reliance on token-level prediction and lack of grounded agency. This\npaper offers a cross-disciplinary synthesis of AGI development, spanning\nartificial intelligence, cognitive neuroscience, psychology, generative models,\nand agent-based systems. We analyze the architectural and cognitive foundations\nof general intelligence, highlighting the role of modular reasoning, persistent\nmemory, and multi-agent coordination. In particular, we emphasize the rise of\nAgentic RAG frameworks that combine retrieval, planning, and dynamic tool use\nto enable more adaptive behavior. We discuss generalization strategies,\nincluding information compression, test-time adaptation, and training-free\nmethods, as critical pathways toward flexible, domain-agnostic intelligence.\nVision-Language Models (VLMs) are reexamined not just as perception modules but\nas evolving interfaces for embodied understanding and collaborative task\ncompletion. We also argue that true intelligence arises not from scale alone\nbut from the integration of memory and reasoning: an orchestration of modular,\ninteractive, and self-improving components where compression enables adaptive\nbehavior. Drawing on advances in neurosymbolic systems, reinforcement learning,\nand cognitive scaffolding, we explore how recent architectures begin to bridge\nthe gap between statistical learning and goal-directed cognition. Finally, we\nidentify key scientific, technical, and ethical challenges on the path to AGI.", "AI": {"tldr": "\u5c3d\u7ba1\u5f53\u524d\u6a21\u578b\uff08\u5982GPT-4.5\u7b49\uff09\u5728\u591a\u6a21\u6001\u6d41\u7545\u6027\u548c\u90e8\u5206\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u53d7\u9650\u4e8e\u57fa\u4e8etoken\u7684\u9884\u6d4b\u548c\u7f3a\u4e4f\u5b9e\u9645\u4ee3\u7406\u80fd\u529b\u3002\u672c\u6587\u4ece\u8de8\u5b66\u79d1\u89d2\u5ea6\u63a2\u8ba8\u4e86\u901a\u4e49\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u53d1\u5c55\uff0c\u5f3a\u8c03\u6a21\u5757\u5316\u63a8\u7406\u3001\u6301\u4e45\u8bb0\u5fc6\u548c\u591a\u4ee3\u7406\u534f\u8c03\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u667a\u80fd\u4e0d\u4ec5\u6765\u81ea\u4e8e\u89c4\u6a21\uff0c\u8fd8\u6765\u81ea\u4e8e\u8bb0\u5fc6\u4e0e\u63a8\u7406\u7684\u6574\u5408\u3002", "motivation": "\u63a2\u8ba8\u5b9e\u73b0\u771f\u6b63\u7684\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u7684\u53ef\u80fd\u6027\u53ca\u8def\u5f84\uff0c\u5206\u6790\u73b0\u6709\u6a21\u578b\u7684\u80fd\u529b\u9650\u5236\u53ca\u5176\u6539\u8fdb\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u3001\u5fc3\u7406\u5b66\u3001\u751f\u6210\u6a21\u578b\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u7cfb\u7edf\u7b49\u9886\u57df\uff0c\u8fdb\u884c\u8de8\u5b66\u79d1\u7efc\u5408\u5206\u6790\uff1b\u91cd\u70b9\u7814\u7a76\u6a21\u5757\u5316\u63a8\u7406\u3001\u6301\u4e45\u8bb0\u5fc6\u548c\u591a\u4ee3\u7406\u534f\u8c03\u7684\u4f5c\u7528\uff1b\u8ba8\u8bba\u4fe1\u606f\u538b\u7f29\u3001\u6d4b\u8bd5\u65f6\u9002\u5e94\u548c\u65e0\u8bad\u7ec3\u65b9\u6cd5\u7b49\u7b56\u7565\uff1b\u91cd\u65b0\u5ba1\u89c6\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u611f\u77e5\u6a21\u5757\u7684\u529f\u80fd\u3002", "result": "\u63d0\u51fa\u667a\u80fd\u4e0d\u4ec5\u6765\u81ea\u4e8e\u89c4\u6a21\uff0c\u66f4\u6765\u81ea\u4e8e\u8bb0\u5fc6\u548c\u63a8\u7406\u7684\u6574\u5408\uff0c\u8fd1\u671f\u67b6\u6784\u5f00\u59cb\u5f25\u5408\u7edf\u8ba1\u5b66\u4e60\u4e0e\u76ee\u6807\u5bfc\u5411\u8ba4\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u8bc6\u522b\u51fa\u901a\u5f80AGI\u7684\u5173\u952e\u79d1\u5b66\u3001\u6280\u672f\u548c\u4f26\u7406\u6311\u6218\u3002", "conclusion": "\u5b9e\u73b0AGI\u9700\u8981\u514b\u670d\u6280\u672f\u4e0e\u4f26\u7406\u6311\u6218\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u6a21\u5757\u5316\u3001\u81ea\u9002\u5e94\u548c\u81ea\u6211\u6539\u8fdb\u7ec4\u4ef6\u7684\u96c6\u6210\uff0c\u4ee5\u53ca\u538b\u7f29\u5982\u4f55\u652f\u6301\u9002\u5e94\u6027\u884c\u4e3a\u3002"}}
{"id": "2507.00036", "pdf": "https://arxiv.org/pdf/2507.00036", "abs": "https://arxiv.org/abs/2507.00036", "authors": ["Rohan Putatunda", "Sanjay Purushotham", "Ratnaksha Lele", "Vandana P. Janeja"], "title": "IDRIFTNET: Physics-Driven Spatiotemporal Deep Learning for Iceberg Drift Forecasting", "categories": ["cs.LG", "physics.ao-ph"], "comment": "16 pages, 4 figures", "summary": "Drifting icebergs in the polar oceans play a key role in the Earth's climate\nsystem, impacting freshwater fluxes into the ocean and regional ecosystems\nwhile also posing a challenge to polar navigation. However, accurately\nforecasting iceberg trajectories remains a formidable challenge, primarily due\nto the scarcity of spatiotemporal data and the complex, nonlinear nature of\niceberg motion, which is also impacted by environmental variables. The iceberg\nmotion is influenced by multiple dynamic environmental factors, creating a\nhighly variable system that makes trajectory identification complex. These\nlimitations hinder the ability of deep learning models to effectively capture\nthe underlying dynamics and provide reliable predictive outcomes. To address\nthese challenges, we propose a hybrid IDRIFTNET model, a physics-driven deep\nlearning model that combines an analytical formulation of iceberg drift\nphysics, with an augmented residual learning model. The model learns the\npattern of mismatch between the analytical solution and ground-truth\nobservations, which is combined with a rotate-augmented spectral neural network\nthat captures both global and local patterns from the data to forecast future\niceberg drift positions. We compare IDRIFTNET model performance with\nstate-of-the-art models on two Antarctic icebergs: A23A and B22A. Our findings\ndemonstrate that IDRIFTNET outperforms other models by achieving a lower Final\nDisplacement Error (FDE) and Average Displacement Error (ADE) across a variety\nof time points. These results highlight IDRIFTNET's effectiveness in capturing\nthe complex, nonlinear drift of icebergs for forecasting iceberg trajectories\nunder limited data and dynamic environmental conditions.", "AI": {"tldr": "\u5728\u6781\u5730\u6d77\u6d0b\u4e2d\u6f02\u6d41\u7684\u51b0\u5c71\u5bf9\u5730\u7403\u6c14\u5019\u7cfb\u7edf\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u5f71\u54cd\u6d77\u6d0b\u4e2d\u7684\u6de1\u6c34\u6d41\u91cf\u548c\u533a\u57df\u751f\u6001\u7cfb\u7edf\uff0c\u540c\u65f6\u4e5f\u5bf9\u6781\u5730\u5bfc\u822a\u6784\u6210\u6311\u6218\u3002\u7136\u800c\uff0c\u7531\u4e8e\u65f6\u7a7a\u6570\u636e\u7684\u532e\u4e4f\u548c\u51b0\u5c71\u8fd0\u52a8\u7684\u590d\u6742\u975e\u7ebf\u6027\u6027\u8d28\uff0c\u51c6\u786e\u9884\u6d4b\u51b0\u5c71\u8f68\u8ff9\u4ecd\u7136\u662f\u4e00\u4e2a\u8270\u5de8\u7684\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408IDRIFTNET\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a\u7269\u7406\u9a71\u52a8\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5b83\u7ed3\u5408\u4e86\u51b0\u5c71\u6f02\u79fb\u7269\u7406\u7684\u89e3\u6790\u516c\u5f0f\u548c\u589e\u5f3a\u6b8b\u5dee\u5b66\u4e60\u6a21\u578b\u3002\u6211\u4eec\u5c06IDRIFTNET\u6a21\u578b\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u4e24\u4e2a\u5357\u6781\u51b0\u5c71A23A\u548cB22A\u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cIDRIFTNET\u901a\u8fc7\u5728\u5404\u79cd\u65f6\u95f4\u70b9\u5b9e\u73b0\u66f4\u4f4e\u7684\u6700\u7ec8\u4f4d\u79fb\u8bef\u5dee\uff08FDE\uff09\u548c\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\uff08ADE\uff09\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u51b0\u5c71\u8f68\u8ff9\u5bf9\u4e8e\u7406\u89e3\u5730\u7403\u6c14\u5019\u7cfb\u7edf\u3001\u4fdd\u62a4\u533a\u57df\u751f\u6001\u7cfb\u7edf\u4ee5\u53ca\u786e\u4fdd\u6781\u5730\u5bfc\u822a\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f53\u524d\u5b58\u5728\u65f6\u7a7a\u6570\u636e\u7a00\u7f3a\u548c\u51b0\u5c71\u8fd0\u52a8\u590d\u6742\u975e\u7ebf\u6027\u7684\u6311\u6218\uff0c\u9650\u5236\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u5e76\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIDRIFTNET\u7684\u6df7\u5408\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u51b0\u5c71\u6f02\u79fb\u7269\u7406\u7684\u89e3\u6790\u516c\u5f0f\u4e0e\u589e\u5f3a\u6b8b\u5dee\u5b66\u4e60\u6a21\u578b\u76f8\u7ed3\u5408\u3002\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u89e3\u6790\u89e3\u4e0e\u771f\u5b9e\u89c2\u6d4b\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u6a21\u5f0f\uff0c\u5e76\u5229\u7528\u65cb\u8f6c\u589e\u5f3a\u9891\u8c31\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u6570\u636e\u4e2d\u7684\u5168\u5c40\u548c\u5c40\u90e8\u6a21\u5f0f\uff0c\u4ece\u800c\u9884\u6d4b\u672a\u6765\u7684\u51b0\u5c71\u6f02\u79fb\u4f4d\u7f6e\u3002", "result": "IDRIFTNET\u6a21\u578b\u5728\u5357\u6781\u51b0\u5c71A23A\u548cB22A\u4e0a\u7684\u6d4b\u8bd5\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u65f6\u95f4\u70b9\u4e0a\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u6700\u7ec8\u4f4d\u79fb\u8bef\u5dee\uff08FDE\uff09\u548c\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\uff08ADE\uff09\u3002", "conclusion": "IDRIFTNET\u6a21\u578b\u6709\u6548\u5730\u6355\u6349\u4e86\u51b0\u5c71\u590d\u6742\u7684\u975e\u7ebf\u6027\u6f02\u79fb\u52a8\u6001\uff0c\u5728\u6709\u9650\u6570\u636e\u548c\u52a8\u6001\u73af\u5883\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u51b0\u5c71\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u8fd9\u8868\u660e\u7269\u7406\u9a71\u52a8\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5e94\u5bf9\u590d\u6742\u81ea\u7136\u73b0\u8c61\u9884\u6d4b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.00979", "pdf": "https://arxiv.org/pdf/2507.00979", "abs": "https://arxiv.org/abs/2507.00979", "authors": ["Dongyoon Hahm", "Woogyeol Jin", "June Suk Choi", "Sungsoo Ahn", "Kimin Lee"], "title": "Enhancing LLM Agent Safety via Causal Influence Prompting", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted at ACL 2025 Findings, Source code:\n  https://github.com/HahmDY/causal_influence_prompting.git", "summary": "As autonomous agents powered by large language models (LLMs) continue to\ndemonstrate potential across various assistive tasks, ensuring their safe and\nreliable behavior is crucial for preventing unintended consequences. In this\nwork, we introduce CIP, a novel technique that leverages causal influence\ndiagrams (CIDs) to identify and mitigate risks arising from agent\ndecision-making. CIDs provide a structured representation of cause-and-effect\nrelationships, enabling agents to anticipate harmful outcomes and make safer\ndecisions. Our approach consists of three key steps: (1) initializing a CID\nbased on task specifications to outline the decision-making process, (2)\nguiding agent interactions with the environment using the CID, and (3)\niteratively refining the CID based on observed behaviors and outcomes.\nExperimental results demonstrate that our method effectively enhances safety in\nboth code execution and mobile device control tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCIP\u7684\u65b0\u6280\u672f\uff0c\u5229\u7528\u56e0\u679c\u5f71\u54cd\u56fe\uff08CIDs\uff09\u6765\u8bc6\u522b\u548c\u51cf\u8f7b\u81ea\u4e3b\u4ee3\u7406\u51b3\u7b56\u5e26\u6765\u7684\u98ce\u9669\uff0c\u901a\u8fc7\u521d\u59cb\u5316\u3001\u5f15\u5bfc\u548c\u8fed\u4ee3\u4f18\u5316CID\u4e09\u4e2a\u6b65\u9aa4\uff0c\u5728\u4ee3\u7801\u6267\u884c\u548c\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u4efb\u52a1\u4e2d\u6709\u6548\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u4e3b\u4ee3\u7406\u5728\u5404\u79cd\u8f85\u52a9\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u786e\u4fdd\u5176\u884c\u4e3a\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u9632\u6b62\u610f\u5916\u540e\u679c\u7684\u53d1\u751f\u3002", "method": "CIP\u6280\u672f\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a1) \u6839\u636e\u4efb\u52a1\u89c4\u8303\u521d\u59cb\u5316CID\uff0c\u6982\u8ff0\u51b3\u7b56\u8fc7\u7a0b\uff1b2) \u4f7f\u7528CID\u6307\u5bfc\u4ee3\u7406\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\uff1b3) \u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u548c\u7ed3\u679c\u8fed\u4ee3\u4f18\u5316CID\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u6267\u884c\u548c\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u4efb\u52a1\u4e2d\u6709\u6548\u5730\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002", "conclusion": "CIP\u662f\u4e00\u79cd\u6709\u6548\u63d0\u9ad8\u81ea\u4e3b\u4ee3\u7406\u5b89\u5168\u6027\u7684\u65b0\u6280\u672f\uff0c\u5c24\u5176\u662f\u5728\u4ee3\u7801\u6267\u884c\u548c\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2507.00037", "pdf": "https://arxiv.org/pdf/2507.00037", "abs": "https://arxiv.org/abs/2507.00037", "authors": ["Phoomraphee Luenam", "Andreas Spanopoulos", "Amit Sant", "Thomas Hofmann", "Sotiris Anagnostidis", "Sidak Pal Singh"], "title": "Model Fusion via Neuron Interpolation", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.1"], "comment": "5 figures, 15 tables, 23 pages", "summary": "Model fusion aims to combine the knowledge of multiple models by creating one\nrepresentative model that captures the strengths of all of its parents.\nHowever, this process is non-trivial due to differences in internal\nrepresentations, which can stem from permutation invariance, random\ninitialization, or differently distributed training data. We present a novel,\nneuron-centric family of model fusion algorithms designed to integrate multiple\ntrained neural networks into a single network effectively regardless of\ntraining data distribution. Our algorithms group intermediate neurons of parent\nmodels to create target representations that the fused model approximates with\nits corresponding sub-network. Unlike prior approaches, our approach\nincorporates neuron attribution scores into the fusion process. Furthermore,\nour algorithms can generalize to arbitrary layer types. Experimental results on\nvarious benchmark datasets demonstrate that our algorithms consistently\noutperform previous fusion techniques, particularly in zero-shot and non-IID\nfusion scenarios. The code is available at\nhttps://github.com/AndrewSpano/neuron-interpolation-model-fusion.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u878d\u5408\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u5143\u5f52\u5c5e\u5206\u6570\u548c\u4e2d\u95f4\u795e\u7ecf\u5143\u5206\u7ec4\uff0c\u80fd\u591f\u6709\u6548\u5730\u5c06\u591a\u4e2a\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\u6574\u5408\u4e3a\u4e00\u4e2a\u5355\u4e00\u7f51\u7edc\uff0c\u65e0\u8bba\u8bad\u7ec3\u6570\u636e\u7684\u5206\u5e03\u5982\u4f55\u3002\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u548c\u975eIID\u878d\u5408\u573a\u666f\u4e2d\u4f18\u4e8e\u5148\u524d\u7684\u6280\u672f\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u5728\u5904\u7406\u5185\u90e8\u8868\u793a\u5dee\u5f02\u65f6\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u4e9b\u5dee\u5f02\u53ef\u80fd\u6e90\u4e8e\u6392\u5217\u4e0d\u53d8\u6027\u3001\u968f\u673a\u521d\u59cb\u5316\u6216\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u7684\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u795e\u7ecf\u5143\u4e3a\u4e2d\u5fc3\u7684\u6a21\u578b\u878d\u5408\u7b97\u6cd5\u5bb6\u65cf\uff0c\u901a\u8fc7\u5c06\u7236\u6a21\u578b\u7684\u4e2d\u95f4\u795e\u7ecf\u5143\u5206\u7ec4\u521b\u5efa\u76ee\u6807\u8868\u793a\uff0c\u5e76\u8ba9\u878d\u5408\u6a21\u578b\u7528\u76f8\u5e94\u7684\u5b50\u7f51\u7edc\u8fdb\u884c\u8fd1\u4f3c\u3002\u6b64\u65b9\u6cd5\u5c06\u795e\u7ecf\u5143\u5f52\u5c5e\u5206\u6570\u7eb3\u5165\u878d\u5408\u8fc7\u7a0b\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u4efb\u610f\u5c42\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u65b0\u7b97\u6cd5\u5728\u96f6\u6837\u672c\u548c\u975eIID\u878d\u5408\u573a\u666f\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4ee5\u524d\u7684\u878d\u5408\u6280\u672f\u3002", "conclusion": "\u63d0\u51fa\u7684\u795e\u7ecf\u5143\u63d2\u503c\u6a21\u578b\u878d\u5408\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4e0d\u540c\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0b\u7684\u6a21\u578b\u878d\u5408\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.00038", "pdf": "https://arxiv.org/pdf/2507.00038", "abs": "https://arxiv.org/abs/2507.00038", "authors": ["Fei Chen", "Wenchi Zhou"], "title": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data reduction plays a vital role in data-centric AI by identifying the most\ninformative instance within large-scale datasets to enhance model training\nefficiency. The core challenge lies in how to select the optimal\ninstances-rather than the entire datasets-to improve data quality and training\nefficiency. In this paper, we propose an effective data reduction strategy\nbased on Pointwise V-information(PVI). First, we quantify instance difficulty\nusing PVI and filter out low-difficulty instances enabling a static approach.\nExperiments demonstrate that removing 10%-30% of the data preserves the\nclassifier performance with only a 0.0001% to 0.76% loss in accuracy.Second, we\nuse a progressive learning approach to training the classifiers on instances\nsorted by ascending PVI, accelerating convergence and achieving a 0.8% accuracy\ngain over conventional training. Our results suggest that with the effective\ndata reduction strategy, training a classifier on the selected optimal subset\ncould enhance the model performance and boost training efficiency. Moreover, we\nhave transferred the PVI framework, which previously applied only to English\ndatasets, to diverse Chinese NLP tasks and base models, leading to valuable\ninsights for cross-lingual data reduction and faster training. The codes are\nreleased at https://github.com/zhouwenchi/DatasetReductionStrategy.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70b9\u4fe1\u606f\u91cf\uff08PVI\uff09\u7684\u6570\u636e\u7f29\u51cf\u7b56\u7565\uff0c\u901a\u8fc7\u91cf\u5316\u5b9e\u4f8b\u96be\u5ea6\u548c\u6e10\u8fdb\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e2\u51cf\u5c11\u6570\u636e\u91cf\u53c8\u4fdd\u6301\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u540c\u65f6\u52a0\u901f\u6a21\u578b\u6536\u655b\u5e76\u63d0\u5347\u8de8\u8bed\u8a00\u6570\u636e\u5904\u7406\u6548\u7387\u3002", "motivation": "\u5728\u6570\u636e\u9a71\u52a8\u7684AI\u4e2d\uff0c\u6570\u636e\u7f29\u51cf\u5bf9\u4e8e\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5982\u4f55\u9009\u62e9\u6700\u4f18\u5b9e\u4f8b\u800c\u975e\u6574\u4e2a\u6570\u636e\u96c6\u4ee5\u6539\u5584\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u662f\u6838\u5fc3\u6311\u6218\u3002", "method": "1. \u4f7f\u7528PVI\u91cf\u5316\u5b9e\u4f8b\u96be\u5ea6\uff0c\u5e76\u8fc7\u6ee4\u6389\u4f4e\u96be\u5ea6\u5b9e\u4f8b\u4ee5\u5b9e\u73b0\u9759\u6001\u6570\u636e\u7f29\u51cf\u65b9\u6cd5\u3002\n2. \u91c7\u7528\u6e10\u8fdb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u6309\u5347\u5e8f\u6392\u5217\u7684PVI\u5b9e\u4f8b\u4e0a\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u4ee5\u52a0\u901f\u6536\u655b\u3002", "result": "1. \u79fb\u966410%-30%\u7684\u6570\u636e\u4ec5\u5bfc\u81f40.0001%\u52300.76%\u7684\u51c6\u786e\u7387\u635f\u5931\u3002\n2. \u6e10\u8fdb\u5b66\u4e60\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8bad\u7ec3\u63d0\u5347\u4e860.8%\u7684\u51c6\u786e\u7387\u3002\n3. PVI\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e\u4e2d\u6587NLP\u4efb\u52a1\u548c\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u8de8\u8bed\u8a00\u6570\u636e\u7f29\u51cf\u7684\u89c1\u89e3\u3002", "conclusion": "\u6709\u6548\u7684\u6570\u636e\u7f29\u51cf\u7b56\u7565\u4e0d\u4ec5\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u6027\u80fd\uff0c\u8fd8\u80fd\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u8de8\u8bed\u8a00\u573a\u666f\u4e0b\u3002"}}
{"id": "2507.00039", "pdf": "https://arxiv.org/pdf/2507.00039", "abs": "https://arxiv.org/abs/2507.00039", "authors": ["Lucas Potin", "Rosa Figueiredo", "Vincent Labatut", "Christine Largeron"], "title": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph classification aims to categorize graphs based on their structural and\nattribute features, with applications in diverse fields such as social network\nanalysis and bioinformatics. Among the methods proposed to solve this task,\nthose relying on patterns (i.e. subgraphs) provide good explainability, as the\npatterns used for classification can be directly interpreted. To identify\nmeaningful patterns, a standard approach is to use a quality measure, i.e. a\nfunction that evaluates the discriminative power of each pattern. However, the\nliterature provides tens of such measures, making it difficult to select the\nmost appropriate for a given application. Only a handful of surveys try to\nprovide some insight by comparing these measures, and none of them specifically\nfocuses on graphs. This typically results in the systematic use of the most\nwidespread measures, without thorough evaluation. To address this issue, we\npresent a comparative analysis of 38 quality measures from the literature. We\ncharacterize them theoretically, based on four mathematical properties. We\nleverage publicly available datasets to constitute a benchmark, and propose a\nmethod to elaborate a gold standard ranking of the patterns. We exploit these\nresources to perform an empirical comparison of the measures, both in terms of\npattern ranking and classification performance. Moreover, we propose a\nclustering-based preprocessing step, which groups patterns appearing in the\nsame graphs to enhance classification performance. Our experimental results\ndemonstrate the effectiveness of this step, reducing the number of patterns to\nbe processed while achieving comparable performance. Additionally, we show that\nsome popular measures widely used in the literature are not associated with the\nbest results.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf938\u79cd\u8d28\u91cf\u5ea6\u91cf\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u56fe\u6a21\u5f0f\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u9884\u5904\u7406\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6027\u80fd\u548c\u51cf\u5c11\u6a21\u5f0f\u6570\u91cf\u3002", "motivation": "\u56fe\u5206\u7c7b\u4efb\u52a1\u9700\u8981\u4f9d\u636e\u56fe\u7684\u7ed3\u6784\u548c\u5c5e\u6027\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u548c\u751f\u7269\u4fe1\u606f\u5b66\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u4f7f\u7528\u6a21\u5f0f\uff08\u5373\u5b50\u56fe\uff09\u7684\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u9009\u62e9\u5408\u9002\u7684\u8d28\u91cf\u5ea6\u91cf\u51fd\u6570\u56f0\u96be\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u9488\u5bf9\u56fe\u6570\u636e\u7684\u8d28\u91cf\u5ea6\u91cf\u5bf9\u6bd4\u5206\u6790\u3002", "method": "\u7406\u8bba\u4e0a\u6839\u636e\u56db\u4e2a\u6570\u5b66\u6027\u8d28\u5bf938\u79cd\u8d28\u91cf\u5ea6\u91cf\u8fdb\u884c\u8868\u5f81\uff1b\u5229\u7528\u516c\u5f00\u6570\u636e\u96c6\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u751f\u6210\u6a21\u5f0f\u9ec4\u91d1\u6807\u51c6\u6392\u540d\u7684\u65b9\u6cd5\uff1b\u901a\u8fc7\u7ecf\u9a8c\u6bd4\u8f83\u8bc4\u4f30\u8fd9\u4e9b\u5ea6\u91cf\u5728\u6a21\u5f0f\u6392\u540d\u548c\u5206\u7c7b\u6027\u80fd\u4e0a\u7684\u8868\u73b0\uff1b\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u5c06\u51fa\u73b0\u5728\u76f8\u540c\u56fe\u4e2d\u7684\u6a21\u5f0f\u5206\u7ec4\u4ee5\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u57fa\u4e8e\u805a\u7c7b\u7684\u9884\u5904\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u9700\u5904\u7406\u7684\u6a21\u5f0f\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u6027\u80fd\uff1b\u4e00\u4e9b\u5e7f\u6cdb\u4f7f\u7528\u7684\u6d41\u884c\u5ea6\u91cf\u5e76\u672a\u5e26\u6765\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u8d28\u91cf\u5ea6\u91cf\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8bc1\u6307\u5bfc\uff0c\u5e76\u8bc1\u660e\u4e86\u57fa\u4e8e\u805a\u7c7b\u7684\u9884\u5904\u7406\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.00055", "pdf": "https://arxiv.org/pdf/2507.00055", "abs": "https://arxiv.org/abs/2507.00055", "authors": ["Varsha Pendyala", "Pedro Morgado", "William Sethares"], "title": "Leveraging Unlabeled Audio-Visual Data in Speech Emotion Recognition using Knowledge Distillation", "categories": ["cs.LG", "cs.HC", "cs.MM", "eess.AS", "eess.IV", "eess.SP"], "comment": "Accepted at INTERSPEECH 2025", "summary": "Voice interfaces integral to the human-computer interaction systems can\nbenefit from speech emotion recognition (SER) to customize responses based on\nuser emotions. Since humans convey emotions through multi-modal audio-visual\ncues, developing SER systems using both the modalities is beneficial. However,\ncollecting a vast amount of labeled data for their development is expensive.\nThis paper proposes a knowledge distillation framework called LightweightSER\n(LiSER) that leverages unlabeled audio-visual data for SER, using large teacher\nmodels built on advanced speech and face representation models. LiSER transfers\nknowledge regarding speech emotions and facial expressions from the teacher\nmodels to lightweight student models. Experiments conducted on two benchmark\ndatasets, RAVDESS and CREMA-D, demonstrate that LiSER can reduce the dependence\non extensive labeled datasets for SER tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a LightweightSER (LiSER) \u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u5229\u7528\u672a\u6807\u8bb0\u7684\u97f3\u89c6\u9891\u6570\u636e\u8fdb\u884c\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\uff0c\u901a\u8fc7\u5927\u578b\u6559\u5e08\u6a21\u578b\u5411\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u4f20\u9012\u5173\u4e8e\u8bed\u97f3\u60c5\u611f\u548c\u9762\u90e8\u8868\u60c5\u7684\u77e5\u8bc6\u3002\u5728 RAVDESS \u548c CREMA-D \u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLiSER \u53ef\u4ee5\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u3002", "motivation": "\u7531\u4e8e\u4eba\u7c7b\u901a\u8fc7\u591a\u6a21\u6001\u7684\u97f3\u9891-\u89c6\u89c9\u7ebf\u7d22\u4f20\u8fbe\u60c5\u611f\uff0c\u56e0\u6b64\u5f00\u53d1\u7ed3\u5408\u8fd9\u4e24\u79cd\u6a21\u5f0f\u7684\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u662f\u6709\u76ca\u7684\u3002\u7136\u800c\uff0c\u6536\u96c6\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4ee5\u53d1\u5c55\u6b64\u7c7b\u7cfb\u7edf\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u51cf\u5c11\u5bf9\u8fd9\u4e9b\u6570\u636e\u7684\u4f9d\u8d56\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a LightweightSER (LiSER) \u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u672a\u6807\u8bb0\u7684\u97f3\u89c6\u9891\u6570\u636e\u8fdb\u884c\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u3002\u901a\u8fc7\u57fa\u4e8e\u5148\u8fdb\u8bed\u97f3\u548c\u9762\u90e8\u8868\u793a\u6a21\u578b\u6784\u5efa\u7684\u5927\u89c4\u6a21\u6559\u5e08\u6a21\u578b\uff0cLiSER \u5c06\u6709\u5173\u8bed\u97f3\u60c5\u611f\u548c\u9762\u90e8\u8868\u60c5\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u4e0a\u3002", "result": "\u5728 RAVDESS \u548c CREMA-D \u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLiSER \u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u7684\u6548\u7387\u3002", "conclusion": "LiSER \u6846\u67b6\u901a\u8fc7\u5229\u7528\u672a\u6807\u8bb0\u7684\u97f3\u89c6\u9891\u6570\u636e\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\uff0c\u6210\u529f\u51cf\u5c11\u4e86\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u5bf9\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.00061", "pdf": "https://arxiv.org/pdf/2507.00061", "abs": "https://arxiv.org/abs/2507.00061", "authors": ["Hoang-Dieu Vu", "Duc-Nghia Tran", "Quang-Tu Pham", "Hieu H. Pham", "Nicolas Vuillerme", "Duc-Tan Tran"], "title": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "This paper introduces Smooth-Distill, a novel self-distillation framework\ndesigned to simultaneously perform human activity recognition (HAR) and sensor\nplacement detection using wearable sensor data. The proposed approach utilizes\na unified CNN-based architecture, MTL-net, which processes accelerometer data\nand branches into two outputs for each respective task. Unlike conventional\ndistillation methods that require separate teacher and student models, the\nproposed framework utilizes a smoothed, historical version of the model itself\nas the teacher, significantly reducing training computational overhead while\nmaintaining performance benefits. To support this research, we developed a\ncomprehensive accelerometer-based dataset capturing 12 distinct sleep postures\nacross three different wearing positions, complementing two existing public\ndatasets (MHealth and WISDM). Experimental results show that Smooth-Distill\nconsistently outperforms alternative approaches across different evaluation\nscenarios, achieving notable improvements in both human activity recognition\nand device placement detection tasks. This method demonstrates enhanced\nstability in convergence patterns during training and exhibits reduced\noverfitting compared to traditional multitask learning baselines. This\nframework contributes to the practical implementation of knowledge distillation\nin human activity recognition systems, offering an effective solution for\nmultitask learning with accelerometer data that balances accuracy and training\nefficiency. More broadly, it reduces the computational cost of model training,\nwhich is critical for scenarios requiring frequent model updates or training on\nresource-constrained platforms. The code and model are available at\nhttps://github.com/Kuan2vn/smooth\\_distill.", "AI": {"tldr": "This paper introduces Smooth-Distill, a self-distillation framework for human activity recognition and sensor placement detection using wearable accelerometer data. It employs MTL-net, a unified CNN-based architecture that branches into two outputs. Unlike traditional methods, it uses a smoothed historical version of the model itself as the teacher, reducing training overhead while maintaining performance. Experiments show improvements in both tasks, enhanced stability during training, and reduced overfitting compared to baselines.", "motivation": "To develop an efficient method for human activity recognition (HAR) and sensor placement detection using wearable accelerometer data, addressing the computational cost and overfitting issues of traditional multitask learning approaches.", "method": "A novel self-distillation framework named Smooth-Distill is proposed, utilizing MTL-net, a unified CNN-based architecture that processes accelerometer data and branches into two outputs for HAR and sensor placement detection. The framework uses a smoothed historical version of the model itself as the teacher, reducing the need for separate teacher and student models.", "result": "Smooth-Distill consistently outperforms alternative approaches across different evaluation scenarios, achieving notable improvements in both human activity recognition and device placement detection tasks. It demonstrates enhanced stability in convergence patterns during training and exhibits reduced overfitting compared to traditional multitask learning baselines.", "conclusion": "Smooth-Distill offers an effective solution for multitask learning with accelerometer data, balancing accuracy and training efficiency. It reduces the computational cost of model training, which is critical for scenarios requiring frequent model updates or training on resource-constrained platforms."}}
{"id": "2507.00075", "pdf": "https://arxiv.org/pdf/2507.00075", "abs": "https://arxiv.org/abs/2507.00075", "authors": ["Yifan Sun", "Yushan Liang", "Zhen Zhang", "Jiaye Teng"], "title": "Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages", "summary": "Self-improvement is among the most prominent techniques within the realm of\nlarge language models (LLM), aiming to enhance the LLM performance without\nrelying on external data. Despite its significance, generally how LLM\nperformances evolve during the self-improvement process remains underexplored.\nIn this paper, we theoretically model the training dynamics of self-improvement\nvia the concept of solver-verifier gap. This is inspired by the conjecture that\nthe performance enhancement of self-improvement stems from the gap between\nLLM's solver capability and verifier capability. Based on the theoretical\nframework, we further introduce how to predict the ultimate power of\nself-improvement using only information from the first few training epochs. We\nempirically validate the effectiveness of the theoretical model on various LLMs\nand datasets. Beyond self-improvement, we extend our analysis to investigate\nhow external data influences these dynamics within the framework. Notably, we\nfind that under limited external data regimes, such external data can be\nutilized at any stage without significantly affecting final performances, which\naccords with the empirical observations.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6c42\u89e3\u5668-\u9a8c\u8bc1\u5668\u5dee\u8ddd\u7684\u6982\u5ff5\uff0c\u5bf9\u81ea\u6539\u8fdb\u8fc7\u7a0b\u4e2d\u7684\u8bad\u7ec3\u52a8\u6001\u8fdb\u884c\u4e86\u7406\u8bba\u5efa\u6a21\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u6d4b\u81ea\u6539\u8fdb\u6781\u9650\u80fd\u529b\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u6709\u9650\u5916\u90e8\u6570\u636e\u5728\u81ea\u6539\u8fdb\u6846\u67b6\u5185\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u6539\u8fdb\u6280\u672f\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u5bf9\u5176\u6027\u80fd\u5728\u81ea\u6539\u8fdb\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\u4ecd\u7f3a\u4e4f\u6df1\u5165\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6c42\u89e3\u5668-\u9a8c\u8bc1\u5668\u5dee\u8ddd\u7684\u6982\u5ff5\u5bf9\u81ea\u6539\u8fdb\u8fdb\u884c\u7406\u8bba\u5efa\u6a21\uff0c\u5e76\u57fa\u4e8e\u6b64\u6846\u67b6\u9884\u6d4b\u81ea\u6539\u8fdb\u7684\u6700\u7ec8\u80fd\u529b\u3002\u540c\u65f6\uff0c\u5206\u6790\u6709\u9650\u5916\u90e8\u6570\u636e\u5bf9\u81ea\u6539\u8fdb\u52a8\u6001\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u6a21\u578b\u5728\u5404\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4e14\u53d1\u73b0\u6709\u9650\u5916\u90e8\u6570\u636e\u53ef\u5728\u4efb\u610f\u9636\u6bb5\u4f7f\u7528\u800c\u4e0d\u663e\u8457\u5f71\u54cd\u6700\u7ec8\u6027\u80fd\u3002", "conclusion": "\u6c42\u89e3\u5668\u4e0e\u9a8c\u8bc1\u5668\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\u662f\u81ea\u6539\u8fdb\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\uff0c\u4e14\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9884\u6d4b\u81ea\u6539\u8fdb\u6781\u9650\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5916\u90e8\u6570\u636e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u4f7f\u7528\u7b56\u7565\u3002"}}
{"id": "2507.00078", "pdf": "https://arxiv.org/pdf/2507.00078", "abs": "https://arxiv.org/abs/2507.00078", "authors": ["Yi Xie", "Yun Xiong", "Zejian Shi", "Hao Niu", "Zhengfu Liu"], "title": "The language of time: a language model perspective on time-series foundation models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "With the rise of large language models, the paradigm of training foundation\nmodels with massive parameter counts on vast datasets has been adopted in\nmultiple domains to achieve remarkable success. Time series foundation models\nrepresent a significant extension of this paradigm, demonstrating exceptional\nexpressive power, generalization, and cross-domain transferability. However,\nthis gives rise to a fundamental paradox: time series data reflect distinct\ndynamical systems, making cross-domain transfer intuitively implausible, yet\nthis is contradicted by the models' empirical success. To resolve this paradox,\nthis paper investigates, from both theoretical and experimental perspectives,\nthe representation learning mechanisms and generalization capabilities of\npatch-based time series foundation models. We argue that such models are not\nmerely applying a new architecture but are fundamentally generalizing the\nrepresentation paradigm of language models by extending deterministic\nvector-based representations to latent probabilistic distributional forms. Our\ntheoretical analysis supports this framework by demonstrating that continuous\ntime-series patches can be faithfully quantized into a discrete vocabulary\nwhose key statistical properties are highly consistent with those of natural\nlanguage. This generalization allows time series models to inherit the robust\nrepresentation and transfer abilities of large language models, thereby\nexplaining their superior performance in temporal tasks. Ultimately, our work\nprovides a rigorous theoretical cornerstone for understanding, evaluating, and\nimproving the safety and reliability of large-scale time series foundation\nmodels.", "AI": {"tldr": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u57fa\u4e8e\u5927\u91cf\u53c2\u6570\u548c\u5e7f\u6cdb\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\u8303\u5f0f\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\u3002\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u8fd9\u4e00\u8303\u5f0f\u7684\u91cd\u5927\u6269\u5c55\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u8868\u8fbe\u80fd\u529b\u3001\u6cdb\u5316\u80fd\u529b\u548c\u8de8\u57df\u8fc1\u79fb\u80fd\u529b\u3002\u7136\u800c\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u57fa\u672c\u6096\u8bba\uff1a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53cd\u6620\u4e86\u4e0d\u540c\u7684\u52a8\u6001\u7cfb\u7edf\uff0c\u4f7f\u8de8\u57df\u8fc1\u79fb\u5728\u76f4\u89c9\u4e0a\u770b\u4f3c\u4e0d\u53ef\u80fd\uff0c\u4f46\u5374\u4e0e\u6a21\u578b\u7684\u7ecf\u9a8c\u6210\u529f\u76f8\u77db\u76fe\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u6096\u8bba\uff0c\u672c\u6587\u4ece\u7406\u8bba\u548c\u5b9e\u9a8c\u7684\u89d2\u5ea6\u7814\u7a76\u4e86\u57fa\u4e8e\u8865\u4e01\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u8868\u793a\u5b66\u4e60\u673a\u5236\u548c\u6cdb\u5316\u80fd\u529b\u3002\u6211\u4eec\u4e3b\u5f20\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4ec5\u4ec5\u662f\u5e94\u7528\u4e86\u4e00\u79cd\u65b0\u67b6\u6784\uff0c\u800c\u662f\u4ece\u6839\u672c\u4e0a\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u8303\u5f0f\u63a8\u5e7f\u5230\u4e86\u786e\u5b9a\u6027\u5411\u91cf\u8868\u793a\u5230\u6f5c\u5728\u6982\u7387\u5206\u5e03\u5f62\u5f0f\u7684\u6269\u5c55\u3002\u6211\u4eec\u7684\u7406\u8bba\u5206\u6790\u901a\u8fc7\u8bc1\u660e\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u8865\u4e01\u53ef\u4ee5\u5fe0\u5b9e\u5730\u91cf\u5316\u4e3a\u4e00\u4e2a\u79bb\u6563\u8bcd\u6c47\u8868\uff0c\u5176\u5173\u952e\u7edf\u8ba1\u7279\u6027\u4e0e\u81ea\u7136\u8bed\u8a00\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4ece\u800c\u652f\u6301\u4e86\u8fd9\u4e00\u6846\u67b6\u3002\u8fd9\u79cd\u63a8\u5e7f\u4f7f\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u80fd\u591f\u7ee7\u627f\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u8868\u793a\u548c\u8fc1\u79fb\u80fd\u529b\uff0c\u4ece\u800c\u89e3\u91ca\u4e86\u5b83\u4eec\u5728\u65f6\u95f4\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u6700\u7ec8\uff0c\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u8bc4\u4f30\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8de8\u57df\u8fc1\u79fb\u80fd\u529b\u4e0e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53cd\u6620\u7684\u4e0d\u540c\u52a8\u6001\u7cfb\u7edf\u4e4b\u95f4\u5b58\u5728\u76f4\u89c2\u4e0a\u7684\u77db\u76fe\u3002\u4e3a\u4e86\u89e3\u91ca\u8fd9\u4e00\u6096\u8bba\uff0c\u9700\u8981\u6df1\u5165\u63a2\u8ba8\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u8868\u793a\u5b66\u4e60\u673a\u5236\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u7814\u7a76\u57fa\u4e8e\u8865\u4e01\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u8868\u793a\u5b66\u4e60\u673a\u5236\u548c\u6cdb\u5316\u80fd\u529b\u3002\n2. \u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u91cf\u5316\u8f6c\u6362\u4e3a\u79bb\u6563\u8bcd\u6c47\u8868\uff0c\u5e76\u4e14\u5176\u7edf\u8ba1\u7279\u6027\u4e0e\u81ea\u7136\u8bed\u8a00\u7c7b\u4f3c\u3002\n3. \u63d0\u51fa\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u662f\u5bf9\u8bed\u8a00\u6a21\u578b\u8868\u793a\u8303\u5f0f\u7684\u63a8\u5e7f\uff0c\u5373\u5c06\u786e\u5b9a\u6027\u5411\u91cf\u8868\u793a\u6269\u5c55\u5230\u6f5c\u5728\u6982\u7387\u5206\u5e03\u5f62\u5f0f\u3002\n4. \u7ed3\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e0d\u4ec5\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u7684\u67b6\u6784\uff0c\u8fd8\u901a\u8fc7\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u8303\u5f0f\u63a8\u5e7f\u5230\u6982\u7387\u5206\u5e03\u5f62\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u548c\u8fc1\u79fb\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u4ee5\u88ab\u91cf\u5316\u4e3a\u79bb\u6563\u8bcd\u6c47\u8868\uff0c\u5176\u7edf\u8ba1\u7279\u6027\u4e0e\u81ea\u7136\u8bed\u8a00\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u7684\u7814\u7a76\u4e3a\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u901a\u8fc7\u63a8\u5e7f\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u8303\u5f0f\uff0c\u7ee7\u627f\u4e86\u5176\u5f3a\u5927\u7684\u8868\u793a\u548c\u8fc1\u79fb\u80fd\u529b\uff0c\u89e3\u91ca\u4e86\u5176\u5728\u65f6\u95f4\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.00080", "pdf": "https://arxiv.org/pdf/2507.00080", "abs": "https://arxiv.org/abs/2507.00080", "authors": ["Ali Tavasoli", "Heman Shakeri"], "title": "Online Meal Detection Based on CGM Data Dynamics", "categories": ["cs.LG", "nlin.AO", "stat.AP"], "comment": null, "summary": "We utilize dynamical modes as features derived from Continuous Glucose\nMonitoring (CGM) data to detect meal events. By leveraging the inherent\nproperties of underlying dynamics, these modes capture key aspects of glucose\nvariability, enabling the identification of patterns and anomalies associated\nwith meal consumption. This approach not only improves the accuracy of meal\ndetection but also enhances the interpretability of the underlying glucose\ndynamics. By focusing on dynamical features, our method provides a robust\nframework for feature extraction, facilitating generalization across diverse\ndatasets and ensuring reliable performance in real-world applications. The\nproposed technique offers significant advantages over traditional approaches,\nimproving detection accuracy,", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5229\u7528\u4ece\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\uff08CGM\uff09\u6570\u636e\u4e2d\u63d0\u53d6\u7684\u52a8\u529b\u5b66\u6a21\u5f0f\u4f5c\u4e3a\u7279\u5f81\uff0c\u7528\u4e8e\u68c0\u6d4b\u7528\u9910\u4e8b\u4ef6\u3002\u8fd9\u4e9b\u6a21\u5f0f\u901a\u8fc7\u6355\u6349\u8461\u8404\u7cd6\u53d8\u5316\u7684\u5173\u952e\u65b9\u9762\uff0c\u8bc6\u522b\u4e0e\u7528\u9910\u76f8\u5173\u7684\u6a21\u5f0f\u548c\u5f02\u5e38\u3002\u6b64\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7528\u9910\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u5e76\u589e\u5f3a\u4e86\u5bf9\u57fa\u7840\u8461\u8404\u7cd6\u52a8\u6001\u7684\u53ef\u89e3\u91ca\u6027\u3002\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u8be5\u6280\u672f\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u53ef\u9760\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7528\u9910\u4e8b\u4ef6\u68c0\u6d4b\u65b9\u6cd5\u53ef\u80fd\u7f3a\u4e4f\u8db3\u591f\u7684\u51c6\u786e\u6027\u548c\u5bf9\u8840\u7cd6\u52a8\u529b\u5b66\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u6216\u591a\u6837\u5316\u7684\u6570\u636e\u65f6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u3001\u66f4\u5177\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\u6765\u5206\u6790\u548c\u89e3\u8bfb\u8840\u7cd6\u6570\u636e\u4e2d\u7684\u7528\u9910\u76f8\u5173\u6a21\u5f0f\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ece\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\uff08CGM\uff09\u6570\u636e\u4e2d\u63d0\u53d6\u52a8\u529b\u5b66\u6a21\u5f0f\u7684\u65b9\u6cd5\uff0c\u7528\u4ee5\u68c0\u6d4b\u7528\u9910\u4e8b\u4ef6\u3002\u8fd9\u79cd\u65b9\u6cd5\u5229\u7528\u4e86\u57fa\u7840\u52a8\u6001\u7684\u56fa\u6709\u5c5e\u6027\uff0c\u6355\u83b7\u8840\u7cd6\u53d8\u5316\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u7528\u4e8e\u5206\u6790\u7684\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6280\u672f\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u9910\u4e8b\u4ef6\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u8840\u7cd6\u52a8\u6001\u7684\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u4f7f\u7528\u52a8\u529b\u5b66\u6a21\u5f0f\u4f5c\u4e3a\u7279\u5f81\u53ef\u4ee5\u4ece\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u6570\u636e\u4e2d\u6709\u6548\u68c0\u6d4b\u7528\u9910\u4e8b\u4ef6\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u8fd8\u589e\u5f3a\u4e86\u5bf9\u8840\u7cd6\u52a8\u6001\u7684\u7406\u89e3\u3002\u6b64\u65b9\u6cd5\u4e3a\u7279\u5f81\u63d0\u53d6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.00082", "pdf": "https://arxiv.org/pdf/2507.00082", "abs": "https://arxiv.org/abs/2507.00082", "authors": ["Faranaksadat Solat", "Joohyung Lee", "Mohamed Seif", "Dusit Niyato", "H. Vincent Poor"], "title": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "17 pages, 16 figures, IEEE Internet of Things", "summary": "Hybrid Language Models (HLMs) combine the low-latency efficiency of Small\nLanguage Models (SLMs) on edge devices with the high accuracy of Large Language\nModels (LLMs) on centralized servers. Unlike traditional end-to-end LLM\ninference, HLMs reduce latency and communication by invoking LLMs only when\nlocal SLM predictions are uncertain, i.e., when token-level confidence is low\nor entropy is high. However, ambiguous or low-confidence predictions still\nrequire frequent offloading to the LLM, leading to significant communication\noverhead in bandwidth-constrained settings. To address this, we propose FedHLM,\na communication-efficient HLM framework that integrates uncertainty-aware\ninference with Federated Learning (FL). FedHLM's key innovation lies in\ncollaboratively learning token-level uncertainty thresholds that govern when\nLLM assistance is needed. Rather than using static or manually tuned\nthresholds, FedHLM employs FL to optimize these thresholds in a\nprivacy-preserving, distributed manner. Additionally, it leverages\nembedding-based token representations for Peer-to-Peer (P2P) resolution,\nenabling clients to reuse tokens inferred by semantically similar peers without\nengaging the LLM. We further introduce hierarchical model aggregation: edge\nservers refine local routing policies through client updates, while\ncross-cluster coordination aligns global decision boundaries. This layered\ndesign captures recurring uncertainty patterns, reducing redundant LLM queries.\nExperiments on large-scale news classification tasks show that FedHLM reduces\nLLM transmissions by over 95 percent with negligible accuracy loss, making it\nwell-suited for scalable and efficient edge-AI applications.", "AI": {"tldr": "\u63d0\u51faFedHLM\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u9608\u503c\uff0c\u5e76\u5229\u7528\u5d4c\u5165\u5f0f\u4ee4\u724c\u8868\u793a\u8fdb\u884c\u70b9\u5bf9\u70b9\u89e3\u6790\uff0c\u663e\u8457\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f20\u8f93\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4ee5\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u5728\u4e0d\u786e\u5b9a\u9884\u6d4b\u65f6\u4ecd\u9700\u9891\u7e41\u8c03\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5bfc\u81f4\u5e26\u5bbd\u53d7\u9650\u73af\u5883\u4e0b\u7684\u901a\u4fe1\u5f00\u9500\u8f83\u5927\u3002", "method": "FedHLM\u6846\u67b6\u7ed3\u5408\u4e86\u8054\u90a6\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a8\u7406\uff0c\u534f\u540c\u5b66\u4e60\u4ee4\u724c\u7ea7\u4e0d\u786e\u5b9a\u6027\u9608\u503c\uff0c\u52a8\u6001\u51b3\u5b9a\u4f55\u65f6\u9700\u8981\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e2e\u52a9\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5229\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u4ee4\u724c\u8868\u793a\u8fdb\u884c\u70b9\u5bf9\u70b9\u89e3\u6790\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u91cd\u7528\u8bed\u4e49\u76f8\u4f3c\u5bf9\u7b49\u65b9\u63a8\u65ad\u7684\u4ee4\u724c\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9700\u6c42\u3002\u6700\u540e\uff0c\u5f15\u5165\u5206\u5c42\u6a21\u578b\u805a\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fb9\u7f18\u670d\u52a1\u5668\u66f4\u65b0\u672c\u5730\u8def\u7531\u7b56\u7565\u5e76\u534f\u8c03\u5168\u5c40\u51b3\u7b56\u8fb9\u754c\u3002", "result": "\u5728\u5927\u89c4\u6a21\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedHLM\u53ef\u4ee5\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f20\u8f93\u9700\u6c42\u51cf\u5c1195%\u4ee5\u4e0a\uff0c\u4e14\u51c6\u786e\u7387\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "FedHLM\u4e3a\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u8fb9\u7f18AI\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u5e76\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002"}}
{"id": "2507.00083", "pdf": "https://arxiv.org/pdf/2507.00083", "abs": "https://arxiv.org/abs/2507.00083", "authors": ["Wei Meng"], "title": "Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks", "categories": ["cs.LG", "cs.AI", "91A80, 91B62, 68T07", "I.2.6; J.7; K.4.1; C.2.4"], "comment": "This paper proposes the first closed-loop causal modeling framework\n  (IA-STGNN) that links tactical strike variables to strategic delay outcomes\n  via graph neural networks with counterfactual reasoning", "summary": "This study addresses the lack of structured causal modeling between tactical\nstrike behavior and strategic delay in current strategic-level simulations,\nparticularly the structural bottlenecks in capturing intermediate variables\nwithin the \"resilience - nodal suppression - negotiation window\" chain. We\npropose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN),\na novel framework that closes the causal loop from tactical input to strategic\ndelay output. The model integrates graph attention mechanisms, counterfactual\nsimulation units, and spatial intervention node reconstruction to enable\ndynamic simulations of strike configurations and synchronization strategies.\nTraining data are generated from a multi-physics simulation platform (GEANT4 +\nCOMSOL) under NIST SP 800-160 standards, ensuring structural traceability and\npolicy-level validation. Experimental results demonstrate that IA-STGNN\nsignificantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost),\nachieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5\npercent accuracy, while improving causal path consistency and intervention\nstability. IA-STGNN enables interpretable prediction of strategic delay and\nsupports applications such as nuclear deterrence simulation, diplomatic window\nassessment, and multi-strategy optimization, providing a structured and\ntransparent AI decision-support mechanism for high-level policy modeling.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6 Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN)\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6218\u7565\u7ea7\u6a21\u62df\u4e2d\u6218\u672f\u6253\u51fb\u884c\u4e3a\u4e0e\u6218\u7565\u5ef6\u8fdf\u4e4b\u95f4\u7f3a\u4e4f\u7ed3\u6784\u5316\u56e0\u679c\u5efa\u6a21\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u201c\u97e7\u6027 - \u8282\u70b9\u6291\u5236 - \u8c08\u5224\u7a97\u53e3\u201d\u94fe\u4e2d\u7684\u4e2d\u95f4\u53d8\u91cf\u7684\u7ed3\u6784\u6027\u74f6\u9888\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cIA-STGNN \u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff08ST-GNN\u3001GCN-LSTM\u3001XGBoost\uff09\uff0c\u5728\u51cf\u5c11 MAE \u548c\u63d0\u9ad8 Top-5 \u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u56e0\u679c\u8def\u5f84\u4e00\u81f4\u6027\u548c\u5e72\u9884\u7a33\u5b9a\u6027\u3002\u8be5\u6a21\u578b\u652f\u6301\u6838\u5a01\u6151\u6a21\u62df\u3001\u5916\u4ea4\u7a97\u53e3\u8bc4\u4f30\u548c\u591a\u7b56\u7565\u4f18\u5316\u7b49\u5e94\u7528\uff0c\u4e3a\u9ad8\u7ea7\u653f\u7b56\u5efa\u6a21\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u548c\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u652f\u6301\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u6218\u7565\u7ea7\u6a21\u62df\u4e2d\u5b58\u5728\u6218\u672f\u6253\u51fb\u884c\u4e3a\u4e0e\u6218\u7565\u5ef6\u8fdf\u4e4b\u95f4\u7f3a\u4e4f\u7ed3\u6784\u5316\u56e0\u679c\u5efa\u6a21\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u201c\u97e7\u6027 - \u8282\u70b9\u6291\u5236 - \u8c08\u5224\u7a97\u53e3\u201d\u94fe\u4e2d\u7684\u4e2d\u95f4\u53d8\u91cf\u7684\u7ed3\u6784\u6027\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e86 Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN) \u6846\u67b6\uff0c\u6574\u5408\u4e86\u56fe\u6ce8\u610f\u529b\u673a\u5236\u3001\u53cd\u4e8b\u5b9e\u6a21\u62df\u5355\u5143\u548c\u7a7a\u95f4\u5e72\u9884\u8282\u70b9\u91cd\u5efa\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u6253\u51fb\u914d\u7f6e\u548c\u540c\u6b65\u7b56\u7565\u7684\u52a8\u6001\u6a21\u62df\u3002\u8bad\u7ec3\u6570\u636e\u7531\u591a\u7269\u7406\u6a21\u62df\u5e73\u53f0\uff08GEANT4 + COMSOL\uff09\u751f\u6210\uff0c\u9075\u5faa NIST SP 800-160 \u6807\u51c6\uff0c\u786e\u4fdd\u7ed3\u6784\u53ef\u8ffd\u6eaf\u6027\u548c\u653f\u7b56\u7ea7\u522b\u9a8c\u8bc1\u3002", "result": "IA-STGNN \u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff08ST-GNN\u3001GCN-LSTM\u3001XGBoost\uff09\uff0c\u5b9e\u73b0\u4e86 MAE \u51cf\u5c11 12.8%\uff0cTop-5 \u51c6\u786e\u6027\u589e\u52a0 18.4%\uff0c\u5e76\u6539\u5584\u4e86\u56e0\u679c\u8def\u5f84\u4e00\u81f4\u6027\u548c\u5e72\u9884\u7a33\u5b9a\u6027\u3002", "conclusion": "IA-STGNN \u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6218\u7565\u5ef6\u8fdf\u9884\u6d4b\uff0c\u5e76\u652f\u6301\u6838\u5a01\u6151\u6a21\u62df\u3001\u5916\u4ea4\u7a97\u53e3\u8bc4\u4f30\u548c\u591a\u7b56\u7565\u4f18\u5316\u7b49\u5e94\u7528\uff0c\u4e3a\u9ad8\u7ea7\u653f\u7b56\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u548c\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u652f\u6301\u673a\u5236\u3002"}}
{"id": "2507.00085", "pdf": "https://arxiv.org/pdf/2507.00085", "abs": "https://arxiv.org/abs/2507.00085", "authors": ["Ruiyuan Jiang", "Dongyao Jia", "Eng Gee Lim", "Pengfei Fan", "Yuli Zhang", "Shangbo Wang"], "title": "A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate traffic prediction is essential for Intelligent Transportation\nSystems (ITS), yet current methods struggle with the inherent complexity and\nnon-linearity of traffic dynamics, making it difficult to integrate spatial and\ntemporal characteristics. Furthermore, existing approaches use static\ntechniques to address non-stationary and anomalous historical data, which\nlimits adaptability and undermines data smoothing. To overcome these\nchallenges, we propose the Graph Fusion Enhanced Network (GFEN), an innovative\nframework for network-level traffic speed prediction. GFEN introduces a novel\ntopological spatiotemporal graph fusion technique that meticulously extracts\nand merges spatial and temporal correlations from both data distribution and\nnetwork topology using trainable methods, enabling the modeling of multi-scale\nspatiotemporal features. Additionally, GFEN employs a hybrid methodology\ncombining a k-th order difference-based mathematical framework with an\nattention-based deep learning structure to adaptively smooth historical\nobservations and dynamically mitigate data anomalies and non-stationarity.\nExtensive experiments demonstrate that GFEN surpasses state-of-the-art methods\nby approximately 6.3% in prediction accuracy and exhibits convergence rates\nnearly twice as fast as recent hybrid models, confirming its superior\nperformance and potential to significantly enhance traffic prediction system\nefficiency.", "AI": {"tldr": "GFEN\u662f\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u7ea7\u4ea4\u901a\u901f\u5ea6\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u878d\u5408\u6280\u672f\u63d0\u53d6\u65f6\u7a7a\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u6570\u5b66\u5e73\u6ed1\u65b9\u6cd5\u6765\u5904\u7406\u6570\u636e\u5f02\u5e38\u548c\u975e\u5e73\u7a33\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad86.3%\uff0c\u6536\u655b\u901f\u5ea6\u51e0\u4e4e\u662f\u73b0\u6709\u6a21\u578b\u7684\u4e24\u500d\u3002", "motivation": "\u5f53\u524d\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4ea4\u901a\u52a8\u6001\u7684\u590d\u6742\u6027\u548c\u975e\u7ebf\u6027\uff0c\u6574\u5408\u65f6\u7a7a\u7279\u6027\u56f0\u96be\uff0c\u540c\u65f6\u9759\u6001\u6280\u672f\u5728\u5904\u7406\u975e\u5e73\u7a33\u548c\u5f02\u5e38\u5386\u53f2\u6570\u636e\u65f6\u9002\u5e94\u6027\u5dee\u4e14\u6570\u636e\u5e73\u6ed1\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faGraph Fusion Enhanced Network (GFEN)\uff0c\u5305\u542b\uff1a1) \u4e00\u79cd\u65b0\u7684\u62d3\u6251\u65f6\u7a7a\u56fe\u878d\u5408\u6280\u672f\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u5206\u5e03\u548c\u7f51\u7edc\u62d3\u6251\u4e2d\u63d0\u53d6\u5e76\u5408\u5e76\u65f6\u7a7a\u76f8\u5173\u6027\uff1b2) \u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8ek\u9636\u5dee\u5206\u7684\u6570\u5b66\u6846\u67b6\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784\uff0c\u4ee5\u81ea\u9002\u5e94\u5e73\u6ed1\u5386\u53f2\u89c2\u6d4b\u503c\u5e76\u52a8\u6001\u7f13\u89e3\u6570\u636e\u5f02\u5e38\u548c\u975e\u5e73\u7a33\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGFEN\u5728\u9884\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u9ad8\u51fa\u7ea66.3%\uff0c\u5e76\u4e14\u6536\u655b\u901f\u5ea6\u51e0\u4e4e\u4e3a\u6700\u8fd1\u6df7\u5408\u6a21\u578b\u7684\u4e24\u500d\u3002", "conclusion": "GFEN\u5728\u4ea4\u901a\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u53ef\u663e\u8457\u63d0\u5347\u4ea4\u901a\u9884\u6d4b\u7cfb\u7edf\u7684\u6548\u7387\u3002"}}
{"id": "2507.00087", "pdf": "https://arxiv.org/pdf/2507.00087", "abs": "https://arxiv.org/abs/2507.00087", "authors": ["Jiale Zhao", "Pengzhi Mao", "Kaifei Wang", "Yiming Li", "Yaping Peng", "Ranfei Chen", "Shuqi Lu", "Xiaohong Ji", "Jiaxiang Ding", "Xin Zhang", "Yucheng Liao", "Weinan E", "Weijie Zhang", "Han Wen", "Hao Chi"], "title": "pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep learning has advanced mass spectrometry data interpretation, yet most\nmodels remain feature extractors rather than unified scoring frameworks. We\npresent pUniFind, the first large-scale multimodal pre-trained model in\nproteomics that integrates end-to-end peptide-spectrum scoring with open,\nzero-shot de novo sequencing. Trained on over 100 million open search-derived\nspectra, pUniFind aligns spectral and peptide modalities via cross modality\nprediction and outperforms traditional engines across diverse datasets,\nparticularly achieving a 42.6 percent increase in the number of identified\npeptides in immunopeptidomics. Supporting over 1,300 modifications, pUniFind\nidentifies 60 percent more PSMs than existing de novo methods despite a\n300-fold larger search space. A deep learning based quality control module\nfurther recovers 38.5 percent additional peptides including 1,891 mapped to the\ngenome but absent from reference proteomes while preserving full fragment ion\ncoverage. These results establish a unified, scalable deep learning framework\nfor proteomic analysis, offering improved sensitivity, modification coverage,\nand interpretability.", "AI": {"tldr": "pUniFind\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7528\u4e8e\u86cb\u767d\u8d28\u7ec4\u5b66\u4e2d\u7684\u80bd\u8c31\u8bc4\u5206\u548c\u4ece\u5934\u6d4b\u5e8f\u3002\u5b83\u5728\u514d\u75ab\u80bd\u7ec4\u5b66\u4e2d\u63d0\u9ad8\u4e8642.6%\u7684\u80bd\u9274\u5b9a\u6570\u91cf\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u7684\u4ece\u5934\u6d4b\u5e8f\u65b9\u6cd5\u591a\u8bc6\u522b\u4e8660%\u7684PSMs\u3002\u6b64\u5916\uff0c\u5176\u6df1\u5ea6\u5b66\u4e60\u8d28\u91cf\u63a7\u5236\u6a21\u5757\u8fd8\u6062\u590d\u4e86\u989d\u591638.5%\u7684\u80bd\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u63a8\u52a8\u4e86\u8d28\u8c31\u6570\u636e\u89e3\u91ca\u7684\u53d1\u5c55\uff0c\u4f46\u5927\u591a\u6570\u6a21\u578b\u4ecd\u7136\u662f\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u800c\u975e\u7edf\u4e00\u7684\u8bc4\u5206\u6846\u67b6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u7aef\u5230\u7aef\u80bd\u8c31\u8bc4\u5206\u548c\u5f00\u653e\u3001\u96f6\u6837\u672c\u4ece\u5934\u6d4b\u5e8f\u7684\u6a21\u578b\u3002", "method": "pUniFind\u662f\u4e00\u79cd\u86cb\u767d\u8d28\u7ec4\u5b66\u4e2d\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u8de8\u6a21\u6001\u9884\u6d4b\u5c06\u5149\u8c31\u548c\u80bd\u6a21\u6001\u5bf9\u9f50\u3002\u8be5\u6a21\u578b\u57fa\u4e8e\u8d85\u8fc71\u4ebf\u4e2a\u5f00\u653e\u641c\u7d22\u884d\u751f\u7684\u5149\u8c31\u8fdb\u884c\u8bad\u7ec3\uff0c\u652f\u63011300\u591a\u79cd\u4fee\u9970\u3002\u540c\u65f6\uff0c\u5b83\u5305\u542b\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8d28\u91cf\u63a7\u5236\u6a21\u5757\u3002", "result": "\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e2d\uff0cpUniFind\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5f15\u64ce\uff0c\u7279\u522b\u662f\u5728\u514d\u75ab\u80bd\u7ec4\u5b66\u4e2d\uff0c\u80bd\u7684\u9274\u5b9a\u6570\u91cf\u589e\u52a0\u4e8642.6%\u3002\u4e0e\u73b0\u6709\u7684\u4ece\u5934\u6d4b\u5e8f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5c3d\u7ba1\u641c\u7d22\u7a7a\u95f4\u5927\u4e86300\u500d\uff0c\u4f46pUniFind\u8bc6\u522b\u51fa\u7684PSMs\u591a\u4e8660%\u3002\u6b64\u5916\uff0c\u5176\u8d28\u91cf\u63a7\u5236\u6a21\u5757\u8fd8\u6062\u590d\u4e86\u989d\u591638.5%\u7684\u80bd\u3002", "conclusion": "pUniFind\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u86cb\u767d\u8d28\u7ec4\u5b66\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u654f\u5ea6\u3001\u4fee\u9970\u8986\u76d6\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.00089", "pdf": "https://arxiv.org/pdf/2507.00089", "abs": "https://arxiv.org/abs/2507.00089", "authors": ["Aho Yapi", "Pierre Latouche", "Arnaud Guillin", "Yan Bailly"], "title": "A new machine learning framework for occupational accidents forecasting with safety inspections integration", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "We propose a generic framework for short-term occupational accident\nforecasting that leverages safety inspections and models accident occurrences\nas binary time series. The approach generates daily predictions, which are then\naggregated into weekly safety assessments to better inform decision making. To\nensure the reliability and operational applicability of the forecasts, we apply\na sliding-window cross-validation procedure specifically designed for time\nseries data, combined with an evaluation based on aggregated period-level\nmetrics. Several machine learning algorithms, including logistic regression,\ntree-based models, and neural networks, are trained and systematically compared\nwithin this framework. Unlike the other approaches, the long short-term memory\n(LSTM) network outperforms the other approaches and detects the upcoming\nhigh-risk periods with a balanced accuracy of 0.86, confirming the robustness\nof our methodology and demonstrating that a binary time series model can\nanticipate these critical periods based on safety inspections. The proposed\nmethodology converts routine safety inspection data into clear weekly risk\nscores, detecting the periods when accidents are most likely. Decision-makers\ncan integrate these scores into their planning tools to classify inspection\npriorities, schedule targeted interventions, and funnel resources to the sites\nor shifts classified as highest risk, stepping in before incidents occur and\ngetting the greatest return on safety investments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u77ed\u671f\u804c\u4e1a\u4e8b\u6545\u9884\u6d4b\u7684\u901a\u7528\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5b89\u5168\u68c0\u67e5\u6570\u636e\uff0c\u5e76\u5c06\u4e8b\u6545\u7684\u53d1\u751f\u5efa\u6a21\u4e3a\u4e8c\u5143\u65f6\u95f4\u5e8f\u5217\u3002\u901a\u8fc7\u8bad\u7ec3\u548c\u6bd4\u8f83\u51e0\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u53d1\u73b0\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u591f\u4ee50.86\u7684\u5e73\u8861\u51c6\u786e\u7387\u68c0\u6d4b\u5373\u5c06\u5230\u6765\u7684\u9ad8\u98ce\u9669\u671f\u3002\u6b64\u65b9\u6cd5\u53ef\u5c06\u5e38\u89c4\u5b89\u5168\u68c0\u67e5\u6570\u636e\u8f6c\u5316\u4e3a\u660e\u786e\u7684\u6bcf\u5468\u98ce\u9669\u8bc4\u5206\uff0c\u5e2e\u52a9\u51b3\u7b56\u8005\u4f18\u5316\u8d44\u6e90\u914d\u7f6e\u548c\u9884\u9632\u4e8b\u6545\u53d1\u751f\u3002", "motivation": "\u804c\u4e1a\u4e8b\u6545\u9884\u6d4b\u5bf9\u4e8e\u63d0\u5347\u5de5\u4f5c\u573a\u6240\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u672a\u80fd\u5145\u5206\u5229\u7528\u5b89\u5168\u68c0\u67e5\u6570\u636e\u8fdb\u884c\u6709\u6548\u7684\u77ed\u671f\u9884\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u5e76\u66f4\u597d\u5730\u652f\u6301\u51b3\u7b56\u3002", "method": "1. \u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u5c06\u804c\u4e1a\u4e8b\u6545\u7684\u53d1\u751f\u5efa\u6a21\u4e3a\u4e8c\u5143\u65f6\u95f4\u5e8f\u5217\u3002\n2. \u4f7f\u7528\u5b89\u5168\u68c0\u67e5\u6570\u636e\u751f\u6210\u6bcf\u65e5\u9884\u6d4b\uff0c\u5e76\u5c06\u5176\u6c47\u603b\u4e3a\u6bcf\u5468\u5b89\u5168\u8bc4\u4f30\u3002\n3. \u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u4ea4\u53c9\u9a8c\u8bc1\u7a0b\u5e8f\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u5408\u57fa\u4e8e\u805a\u5408\u5468\u671f\u7ea7\u522b\u7684\u6307\u6807\u3002\n4. \u8bad\u7ec3\u5e76\u6bd4\u8f83\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5305\u62ec\u903b\u8f91\u56de\u5f52\u3001\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\uff08\u7279\u522b\u662fLSTM\uff09\u3002", "result": "LSTM\u6a21\u578b\u5728\u9884\u6d4b\u5373\u5c06\u5230\u6765\u7684\u9ad8\u98ce\u9669\u671f\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5176\u5e73\u8861\u51c6\u786e\u7387\u8fbe\u52300.86\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u5b89\u5168\u68c0\u67e5\u6570\u636e\u8f6c\u5316\u4e3a\u6e05\u6670\u7684\u6bcf\u5468\u98ce\u9669\u8bc4\u5206\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u4e8b\u6545\u6700\u53ef\u80fd\u53d1\u751f\u7684\u65f6\u95f4\u6bb5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e8c\u5143\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7ed3\u5408\u5b89\u5168\u68c0\u67e5\u6570\u636e\u53ef\u4ee5\u6709\u6548\u9884\u6d4b\u804c\u4e1a\u4e8b\u6545\u7684\u9ad8\u98ce\u9669\u671f\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u4ee5\u4fbf\u4ed6\u4eec\u80fd\u591f\u5728\u4e8b\u6545\u53d1\u751f\u524d\u91c7\u53d6\u5e72\u9884\u63aa\u65bd\uff0c\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u4ece\u800c\u83b7\u5f97\u6700\u5927\u7684\u5b89\u5168\u6295\u8d44\u56de\u62a5\u3002"}}
{"id": "2507.00090", "pdf": "https://arxiv.org/pdf/2507.00090", "abs": "https://arxiv.org/abs/2507.00090", "authors": ["Corbeau Michael", "Claeys Emmanuelle", "Serrurier Mathieu", "Zarat\u00e9 Pascale"], "title": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study", "categories": ["cs.LG", "cs.AI"], "comment": "accepted at IEEE SMC 2025 Vienna", "summary": "Allocation of personnel and material resources is highly sensible in the case\nof firefighter interventions. This allocation relies on simulations to\nexperiment with various scenarios. The main objective of this allocation is the\nglobal optimization of the firefighters response. Data generation is then\nmandatory to study various scenarios In this study, we propose to compare\ndifferent data generation methods. Methods such as Random Sampling, Tabular\nVariational Autoencoders, standard Generative Adversarial Networks, Conditional\nTabular Generative Adversarial Networks and Diffusion Probabilistic Models are\nexamined to ascertain their efficacy in capturing the intricacies of\nfirefighter interventions. Traditional evaluation metrics often fall short in\ncapturing the nuanced requirements of synthetic datasets for real-world\nscenarios. To address this gap, an evaluation of synthetic data quality is\nconducted using a combination of domain-specific metrics tailored to the\nfirefighting domain and standard measures such as the Wasserstein distance.\nDomain-specific metrics include response time distribution, spatial-temporal\ndistribution of interventions, and accidents representation. These metrics are\ndesigned to assess data variability, the preservation of fine and complex\ncorrelations and anomalies such as event with a very low occurrence, the\nconformity with the initial statistical distribution and the operational\nrelevance of the synthetic data. The distribution has the particularity of\nbeing highly unbalanced, none of the variables following a Gaussian\ndistribution, adding complexity to the data generation process.", "AI": {"tldr": "\u5728\u6d88\u9632\u5458\u5e72\u9884\u60c5\u51b5\u4e0b\uff0c\u4eba\u5458\u548c\u7269\u8d44\u8d44\u6e90\u7684\u5206\u914d\u9ad8\u5ea6\u654f\u611f\u3002\u672c\u6587\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u91c7\u6837\u3001\u8868\u683c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7b49\uff09\u4ee5\u4f18\u5316\u6d88\u9632\u5458\u54cd\u5e94\uff0c\u5e76\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u6307\u6807\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u3002", "motivation": "\u6d88\u9632\u5458\u5e72\u9884\u4e2d\u7684\u4eba\u529b\u7269\u529b\u8d44\u6e90\u5206\u914d\u9700\u8981\u4f9d\u8d56\u6a21\u62df\u6765\u6d4b\u8bd5\u5404\u79cd\u573a\u666f\uff0c\u56e0\u6b64\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\uff0c\u9700\u5f15\u5165\u9886\u57df\u7279\u5b9a\u6307\u6807\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u79cd\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u5305\u62ec\u968f\u673a\u91c7\u6837\u3001\u8868\u683c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u3001\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u3001\u6761\u4ef6\u8868\u683c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u548c\u6269\u6563\u6982\u7387\u6a21\u578b\u3002\u5e76\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u6307\u6807\uff08\u5982\u54cd\u5e94\u65f6\u95f4\u5206\u5e03\u3001\u65f6\u7a7a\u5206\u5e03\u7b49\uff09\u4e0e\u6807\u51c6\u5ea6\u91cf\uff08\u5982Wasserstein\u8ddd\u79bb\uff09\u8bc4\u4f30\u5408\u6210\u6570\u636e\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u6307\u6807\u548c\u6807\u51c6\u5ea6\u91cf\u7684\u7ed3\u5408\u8bc4\u4f30\uff0c\u53d1\u73b0\u4e0d\u540c\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u6355\u6349\u6d88\u9632\u5e72\u9884\u590d\u6742\u6027\u65b9\u9762\u8868\u73b0\u5404\u5f02\uff0c\u4e14\u7531\u4e8e\u6570\u636e\u5206\u5e03\u7684\u9ad8\u5ea6\u4e0d\u5e73\u8861\u6027\u548c\u975e\u9ad8\u65af\u7279\u6027\uff0c\u751f\u6210\u8fc7\u7a0b\u66f4\u5177\u6311\u6218\u6027\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u7684\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5176\u5bf9\u6d88\u9632\u5e72\u9884\u590d\u6742\u6027\u7684\u6355\u6349\u80fd\u529b\u3002\u9886\u57df\u7279\u5b9a\u6307\u6807\u5bf9\u4e8e\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u672a\u6765\u7684\u7814\u7a76\u5e94\u8fdb\u4e00\u6b65\u6539\u8fdb\u751f\u6210\u65b9\u6cd5\u4ee5\u9002\u5e94\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u6570\u636e\u5206\u5e03\u3002"}}
{"id": "2507.00101", "pdf": "https://arxiv.org/pdf/2507.00101", "abs": "https://arxiv.org/abs/2507.00101", "authors": ["Giovanni Ruggieri"], "title": "DFReg: A Physics-Inspired Framework for Global Weight Distribution Regularization in Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "We introduce DFReg, a physics-inspired regularization method for deep neural\nnetworks that operates on the global distribution of weights. Drawing from\nDensity Functional Theory (DFT), DFReg applies a functional penalty to\nencourage smooth, diverse, and well-distributed weight configurations. Unlike\ntraditional techniques such as Dropout or L2 decay, DFReg imposes global\nstructural regularity without architectural changes or stochastic\nperturbations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDFReg\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u53d7\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u542f\u53d1\uff0c\u901a\u8fc7\u5168\u5c40\u6743\u91cd\u5206\u5e03\u65bd\u52a0\u529f\u80fd\u6027\u60e9\u7f5a\uff0c\u4ee5\u4fc3\u8fdb\u5e73\u6ed1\u3001\u591a\u6837\u4e14\u5206\u5e03\u826f\u597d\u7684\u6743\u91cd\u914d\u7f6e\u3002\u4e0eDropout\u6216L2\u8870\u51cf\u7b49\u4f20\u7edf\u6280\u672f\u4e0d\u540c\uff0cDFReg\u5728\u4e0d\u6539\u53d8\u67b6\u6784\u6216\u5f15\u5165\u968f\u673a\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5168\u5c40\u7ed3\u6784\u6b63\u5219\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6b63\u5219\u5316\u65b9\u6cd5\u5982Dropout\u6216L2\u8870\u51cf\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u9700\u8981\u67b6\u6784\u66f4\u6539\u6216\u5f15\u5165\u968f\u673a\u6270\u52a8\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u7f51\u7edc\u67b6\u6784\u6216\u5f15\u5165\u968f\u673a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "DFReg\u662f\u4e00\u79cd\u53d7\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u542f\u53d1\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5bf9\u6743\u91cd\u7684\u5168\u5c40\u5206\u5e03\u65bd\u52a0\u529f\u80fd\u6027\u60e9\u7f5a\u6765\u5b9e\u73b0\u6b63\u5219\u5316\u3002\u8fd9\u79cd\u65b9\u6cd5\u9f13\u52b1\u6743\u91cd\u914d\u7f6e\u5e73\u6ed1\u3001\u591a\u6837\u4e14\u5206\u5e03\u826f\u597d\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDFReg\u53ef\u4ee5\u6709\u6548\u6539\u5584\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "DFReg\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u6b63\u5219\u5316\u89c6\u89d2\uff0c\u80fd\u591f\u5728\u5168\u7403\u8303\u56f4\u5185\u5bf9\u6743\u91cd\u5206\u5e03\u8fdb\u884c\u8c03\u63a7\uff0c\u800c\u65e0\u9700\u6539\u53d8\u7f51\u7edc\u67b6\u6784\u6216\u5f15\u5165\u968f\u673a\u6270\u52a8\u3002\u8fd9\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.00102", "pdf": "https://arxiv.org/pdf/2507.00102", "abs": "https://arxiv.org/abs/2507.00102", "authors": ["Bernd Hofmann", "Patrick Bruendl", "Huong Giang Nguyen", "Joerg Franke"], "title": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Ensuring consistent product quality in modern manufacturing is crucial,\nparticularly in safety-critical applications. Conventional quality control\napproaches, reliant on manually defined thresholds and features, lack\nadaptability to the complexity and variability inherent in production data and\nnecessitate extensive domain expertise. Conversely, data-driven methods, such\nas machine learning, demonstrate high detection performance but typically\nfunction as black-box models, thereby limiting their acceptance in industrial\nenvironments where interpretability is paramount. This paper introduces a\nmethodology for industrial fault detection, which is both data-driven and\ntransparent. The approach integrates a supervised machine learning model for\nmulti-class fault classification, Shapley Additive Explanations for post-hoc\ninterpretability, and a do-main-specific visualisation technique that maps\nmodel explanations to operator-interpretable features. Furthermore, the study\nproposes an evaluation methodology that assesses model explanations through\nquantitative perturbation analysis and evaluates visualisations by qualitative\nexpert assessment. The approach was applied to the crimping process, a\nsafety-critical joining technique, using a dataset of univariate, discrete time\nseries. The system achieves a fault detection accuracy of 95.9 %, and both\nquantitative selectivity analysis and qualitative expert evaluations confirmed\nthe relevance and inter-pretability of the generated explanations. This\nhuman-centric approach is designed to enhance trust and interpretability in\ndata-driven fault detection, thereby contributing to applied system design in\nindustrial quality control.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u4e14\u900f\u660e\u7684\u5de5\u4e1a\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u3001Shapley Additive Explanations\u89e3\u91ca\u6027\u5de5\u5177\u548c\u9886\u57df\u7279\u5b9a\u53ef\u89c6\u5316\u6280\u672f\u3002\u8be5\u65b9\u6cd5\u5728\u538b\u63a5\u8fc7\u7a0b\u6570\u636e\u4e2d\u5b9e\u73b0\u4e8695.9%\u7684\u6545\u969c\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u5b9a\u91cf\u6270\u52a8\u5206\u6790\u548c\u4e13\u5bb6\u5b9a\u6027\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u89e3\u91ca\u7684\u76f8\u5173\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u5de5\u4e1a\u8d28\u91cf\u63a7\u5236\u4e2d\u7684\u4fe1\u4efb\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u4e2d\u786e\u4fdd\u4ea7\u54c1\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u8d28\u91cf\u63a7\u5236\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u751f\u4ea7\u6570\u636e\u590d\u6742\u6027\u548c\u53d8\u5f02\u6027\u9002\u5e94\u80fd\u529b\uff0c\u540c\u65f6\u9700\u8981\u5927\u91cf\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u800c\u673a\u5668\u5b66\u4e60\u7b49\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u867d\u7136\u68c0\u6d4b\u6027\u80fd\u9ad8\uff0c\u4f46\u901a\u5e38\u4e3a\u9ed1\u7bb1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u63a5\u53d7\u5ea6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u6570\u636e\u9a71\u52a8\u53c8\u900f\u660e\u7684\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a1) \u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u591a\u7c7b\u6545\u969c\u5206\u7c7b\uff1b2) \u4f7f\u7528Shapley Additive Explanations\uff08SHAP\uff09\u8fdb\u884c\u4e8b\u540e\u89e3\u91ca\uff1b3) \u9886\u57df\u7279\u5b9a\u7684\u53ef\u89c6\u5316\u6280\u672f\uff0c\u5c06\u6a21\u578b\u89e3\u91ca\u6620\u5c04\u5230\u64cd\u4f5c\u5458\u53ef\u7406\u89e3\u7684\u7279\u5f81\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u91cf\u6270\u52a8\u5206\u6790\u8bc4\u4f30\u6a21\u578b\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u5b9a\u6027\u8bc4\u4f30\u8bc4\u4ef7\u53ef\u89c6\u5316\u6548\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u538b\u63a5\u8fc7\u7a0b\u6570\u636e\u96c6\uff08\u5355\u53d8\u91cf\u79bb\u6563\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u5b9e\u73b0\u4e8695.9%\u7684\u6545\u969c\u68c0\u6d4b\u51c6\u786e\u7387\u3002\u5b9a\u91cf\u9009\u62e9\u6027\u5206\u6790\u548c\u4e13\u5bb6\u5b9a\u6027\u8bc4\u4f30\u5747\u8bc1\u5b9e\u4e86\u89e3\u91ca\u7684\u76f8\u5173\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u6b64\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6570\u636e\u9a71\u52a8\u6545\u969c\u68c0\u6d4b\u7684\u4fe1\u4efb\u5ea6\u548c\u89e3\u91ca\u6027\uff0c\u4e3a\u5de5\u4e1a\u8d28\u91cf\u63a7\u5236\u4e2d\u7684\u5e94\u7528\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u8d21\u732e\u3002"}}
{"id": "2507.00105", "pdf": "https://arxiv.org/pdf/2507.00105", "abs": "https://arxiv.org/abs/2507.00105", "authors": ["Javier Castellano", "Ignacio Villanueva"], "title": "Graph Neural Networks in Wind Power Forecasting", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We study the applicability of GNNs to the problem of wind energy forecasting.\nWe find that certain architectures achieve performance comparable to our best\nCNN-based benchmark. The study is conducted on three wind power facilities\nusing five years of historical data. Numerical Weather Prediction (NWP)\nvariables were used as predictors, and models were evaluated on a 24 to 36 hour\nahead test horizon.", "AI": {"tldr": "\u7814\u7a76\u4e86GNNs\u5728\u98ce\u80fd\u9884\u6d4b\u95ee\u9898\u4e0a\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u67d0\u4e9b\u67b6\u6784\u7684\u8868\u73b0\u4e0e\u57fa\u4e8eCNN\u7684\u6700\u4f73\u57fa\u51c6\u76f8\u5f53\u3002\u4f7f\u7528\u4e09\u4e2a\u98ce\u7535\u573a\u4e94\u5e74\u7684\u5386\u53f2\u6570\u636e\u8fdb\u884c\u7814\u7a76\uff0c\u91c7\u7528NWP\u53d8\u91cf\u4f5c\u4e3a\u9884\u6d4b\u56e0\u5b50\uff0c\u5e76\u572824\u81f336\u5c0f\u65f6\u7684\u9884\u6d4b\u8303\u56f4\u5185\u8bc4\u4f30\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u98ce\u80fd\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u671f\u627e\u5230\u53ef\u80fd\u4f18\u4e8e\u6216\u7b49\u6548\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\uff09\u7684\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u4e09\u4e2a\u98ce\u529b\u53d1\u7535\u5382\u4e94\u5e74\u7684\u5386\u53f2\u6570\u636e\uff0c\u4ee5\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\u53d8\u91cf\u4e3a\u9884\u6d4b\u56e0\u5b50\uff0c\u5c06GNN\u7684\u4e0d\u540c\u67b6\u6784\u4e0e\u57fa\u4e8eCNN\u7684\u57fa\u51c6\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u67d0\u4e9bGNN\u67b6\u6784\u5728\u98ce\u80fd\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u8fbe\u5230\u4e86\u4e0e\u57fa\u4e8eCNN\u7684\u6700\u4f73\u57fa\u51c6\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "GNNs\u5728\u98ce\u80fd\u9884\u6d4b\u9886\u57df\u5177\u6709\u4e00\u5b9a\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u7279\u5b9a\u67b6\u6784\u4e0b\u80fd\u591f\u5b9e\u73b0\u4e0eCNN\u57fa\u51c6\u6a21\u578b\u76f8\u5f53\u7684\u6548\u679c\u3002"}}
{"id": "2507.00184", "pdf": "https://arxiv.org/pdf/2507.00184", "abs": "https://arxiv.org/abs/2507.00184", "authors": ["Jacob Schrum", "Olivia Kilday", "Emilio Salas", "Bess Hagan", "Reid Williams"], "title": "Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research shows how diffusion models can unconditionally generate\ntile-based game levels, but use of diffusion models for text-to-level\ngeneration is underexplored. There are practical considerations for creating a\nusable model: caption/level pairs are needed, as is a text embedding model, and\na way of generating entire playable levels, rather than individual scenes. We\npresent strategies to automatically assign descriptive captions to an existing\nlevel dataset, and train diffusion models using both pretrained text encoders\nand simple transformer models trained from scratch. Captions are automatically\nassigned to generated levels so that the degree of overlap between input and\noutput captions can be compared. We also assess the diversity and playability\nof the resulting levels. Results are compared with an unconditional diffusion\nmodel and a generative adversarial network, as well as the text-to-level\napproaches Five-Dollar Model and MarioGPT. Notably, the best diffusion model\nuses a simple transformer model for text embedding, and takes less time to\ntrain than diffusion models employing more complex text encoders, indicating\nthat reliance on larger language models is not necessary. We also present a GUI\nallowing designers to construct long levels from model-generated scenes.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u6587\u672c\u7684\u6e38\u620f\u5173\u5361\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u81ea\u52a8\u4e3a\u5173\u5361\u6570\u636e\u96c6\u5206\u914d\u63cf\u8ff0\u6027\u6807\u9898\u7684\u7b56\u7565\uff0c\u5e76\u8bad\u7ec3\u4e86\u6269\u6563\u6a21\u578b\u7528\u4e8e\u751f\u6210\u53ef\u73a9\u7684\u5b8c\u6574\u5173\u5361\u3002\u4e0e\u65e0\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548c\u5176\u4ed6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6700\u4f73\u6a21\u578b\u91c7\u7528\u7b80\u5355\u53d8\u538b\u5668\u8fdb\u884c\u6587\u672c\u5d4c\u5165\uff0c\u8bad\u7ec3\u65f6\u95f4\u66f4\u77ed\uff0c\u4e14\u4e0d\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2aGUI\u5de5\u5177\uff0c\u65b9\u4fbf\u8bbe\u8ba1\u5e08\u6784\u5efa\u957f\u5173\u5361\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u6a21\u578b\u5728 unconditional \u751f\u6210\u74e6\u7247\u6e38\u620f\u5173\u5361\u65b9\u9762\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5bf9\u6587\u672c\u5230\u5173\u5361\uff08text-to-level\uff09\u751f\u6210\u7684\u5e94\u7528\u63a2\u7d22\u4e0d\u8db3\u3002\u9700\u8981\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\uff0c\u5982\u83b7\u53d6\u6807\u9898/\u5173\u5361\u5bf9\u3001\u6587\u672c\u5d4c\u5165\u6a21\u578b\u4ee5\u53ca\u751f\u6210\u5b8c\u6574\u53ef\u73a9\u6e38\u620f\u5173\u5361\u7684\u65b9\u6cd5\u3002", "method": "1. \u81ea\u52a8\u4e3a\u73b0\u6709\u5173\u5361\u6570\u636e\u96c6\u5206\u914d\u63cf\u8ff0\u6027\u6807\u9898\u3002\n2. \u4f7f\u7528\u9884\u8bad\u7ec3\u6587\u672c\u7f16\u7801\u5668\u548c\u4ece\u5934\u8bad\u7ec3\u7684\u7b80\u5355\u53d8\u538b\u5668\u6a21\u578b\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u3002\n3. \u81ea\u52a8\u751f\u6210\u5173\u5361\u6807\u9898\u4ee5\u6bd4\u8f83\u8f93\u5165\u8f93\u51fa\u6807\u9898\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\u3002\n4. \u8bc4\u4f30\u751f\u6210\u5173\u5361\u7684\u591a\u6837\u6027\u548c\u53ef\u73a9\u6027\u3002\n5. \u5c06\u7ed3\u679c\u4e0e\u65e0\u6761\u4ef6\u6269\u6563\u6a21\u578b\u3001\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u53ca\u5176\u5b83\u6587\u672c\u5230\u5173\u5361\u65b9\u6cd5\uff08Five-Dollar Model \u548c MarioGPT\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6700\u4f73\u6269\u6563\u6a21\u578b\u91c7\u7528\u4e86\u7b80\u5355\u53d8\u538b\u5668\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5d4c\u5165\uff0c\u8bad\u7ec3\u65f6\u95f4\u6bd4\u4f7f\u7528\u66f4\u590d\u6742\u6587\u672c\u7f16\u7801\u5668\u7684\u6269\u6563\u6a21\u578b\u66f4\u77ed\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u5b8c\u6574\u53ef\u73a9\u5173\u5361\u7684\u6548\u679c\u826f\u597d\uff0c\u4e14\u4e0d\u9700\u8981\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u53d8\u538b\u5668\u6a21\u578b\u5728\u6587\u672c\u5230\u5173\u5361\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u4e14\u6548\u7387\u66f4\u9ad8\u3002\u540c\u65f6\uff0c\u63d0\u4f9b\u7684GUI\u5de5\u5177\u53ef\u4ee5\u8f85\u52a9\u8bbe\u8ba1\u5e08\u5229\u7528\u6a21\u578b\u751f\u6210\u7684\u573a\u666f\u6784\u5efa\u957f\u5173\u5361\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.00191", "pdf": "https://arxiv.org/pdf/2507.00191", "abs": "https://arxiv.org/abs/2507.00191", "authors": ["Eray Erturk", "Fahad Kamran", "Salar Abbaspourazad", "Sean Jewell", "Harsh Sharma", "Yujie Li", "Sinead Williamson", "Nicholas J Foti", "Joseph Futoma"], "title": "Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Wearable devices record physiological and behavioral signals that can improve\nhealth predictions. While foundation models are increasingly used for such\npredictions, they have been primarily applied to low-level sensor data, despite\nbehavioral data often being more informative due to their alignment with\nphysiologically relevant timescales and quantities. We develop foundation\nmodels of such behavioral signals using over 2.5B hours of wearable data from\n162K individuals, systematically optimizing architectures and tokenization\nstrategies for this unique dataset. Evaluated on 57 health-related tasks, our\nmodel shows strong performance across diverse real-world applications including\nindividual-level classification and time-varying health state prediction. The\nmodel excels in behavior-driven tasks like sleep prediction, and improves\nfurther when combined with representations of raw sensor data. These results\nunderscore the importance of tailoring foundation model design to wearables and\ndemonstrate the potential to enable new health applications.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8d85\u8fc72.5B\u5c0f\u65f6\u53ef\u7a7f\u6234\u6570\u636e\u7684\u884c\u4e3a\u4fe1\u53f7\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u572857\u4e2a\u4e0e\u5065\u5eb7\u76f8\u5173\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u662f\u5728\u884c\u4e3a\u9a71\u52a8\u7684\u4efb\u52a1\u5982\u7761\u7720\u9884\u6d4b\u4e0a\u3002\u8fd9\u5f3a\u8c03\u4e86\u4e3a\u53ef\u7a7f\u6234\u8bbe\u5907\u91cf\u8eab\u5b9a\u5236\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u65b0\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u884c\u4e3a\u6570\u636e\u5f80\u5f80\u6bd4\u4f4e\u7ea7\u4f20\u611f\u5668\u6570\u636e\u66f4\u5177\u4fe1\u606f\u91cf\uff0c\u4f46\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u5e94\u7528\u4e8e\u4f4e\u7ea7\u4f20\u611f\u5668\u6570\u636e\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u9488\u5bf9\u884c\u4e3a\u4fe1\u53f7\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u6539\u5584\u5065\u5eb7\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u6765\u81ea162K\u4e2a\u4eba\u7684\u8d85\u8fc72.5B\u5c0f\u65f6\u7684\u53ef\u7a7f\u6234\u6570\u636e\uff0c\u7cfb\u7edf\u5730\u4f18\u5316\u67b6\u6784\u548c\u6807\u8bb0\u5316\u7b56\u7565\uff0c\u6784\u5efa\u4e00\u4e2a\u9488\u5bf9\u884c\u4e3a\u4fe1\u53f7\u7684\u57fa\u7840\u6a21\u578b\u3002\u5e76\u572857\u4e2a\u5065\u5eb7\u76f8\u5173\u4efb\u52a1\u4e2d\u8bc4\u4f30\u8be5\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u8be5\u6a21\u578b\u5728\u5404\u79cd\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u4e2a\u4f53\u6c34\u5e73\u5206\u7c7b\u548c\u65f6\u95f4\u53d8\u5316\u7684\u5065\u5eb7\u72b6\u6001\u9884\u6d4b\u3002\u5c24\u5176\u5728\u884c\u4e3a\u9a71\u52a8\u7684\u4efb\u52a1\uff08\u5982\u7761\u7720\u9884\u6d4b\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5f53\u4e0e\u539f\u59cb\u4f20\u611f\u5668\u6570\u636e\u8868\u793a\u7ed3\u5408\u65f6\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u9488\u5bf9\u53ef\u7a7f\u6234\u8bbe\u5907\u91cf\u8eab\u5b9a\u5236\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u65b0\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.00230", "pdf": "https://arxiv.org/pdf/2507.00230", "abs": "https://arxiv.org/abs/2507.00230", "authors": ["Peilin He", "James Joshi"], "title": "PPFL-RDSN: Privacy-Preserving Federated Learning-based Residual Dense Spatial Networks for Encrypted Lossy Image Reconstruction", "categories": ["cs.LG", "cs.CR"], "comment": "This paper is under review; do not distribute", "summary": "Reconstructing high-quality images from low-resolution inputs using Residual\nDense Spatial Networks (RDSNs) is crucial yet challenging, particularly in\ncollaborative scenarios where centralized training poses significant privacy\nrisks, including data leakage and inference attacks, as well as high\ncomputational costs. We propose a novel Privacy-Preserving Federated\nLearning-based RDSN (PPFL-RDSN) framework specifically tailored for lossy image\nreconstruction. PPFL-RDSN integrates Federated Learning (FL), local\ndifferential privacy, and robust model watermarking techniques, ensuring data\nremains secure on local devices, safeguarding sensitive information, and\nmaintaining model authenticity without revealing underlying data. Empirical\nevaluations show that PPFL-RDSN achieves comparable performance to the\nstate-of-the-art centralized methods while reducing computational burdens, and\neffectively mitigates security and privacy vulnerabilities, making it a\npractical solution for secure and privacy-preserving collaborative computer\nvision applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684PPFL-RDSN\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u8fdb\u884c\u56fe\u50cf\u91cd\u5efa\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u8054\u90a6\u5b66\u4e60\u3001\u672c\u5730\u5dee\u5206\u9690\u79c1\u548c\u9c81\u68d2\u6a21\u578b\u6c34\u5370\u6280\u672f\uff0c\u786e\u4fdd\u6570\u636e\u5b89\u5168\u5e76\u7ef4\u6301\u6a21\u578b\u771f\u5b9e\u6027\uff0c\u540c\u65f6\u6027\u80fd\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u4e14\u51cf\u8f7b\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u9ad8\u8d28\u91cf\u56fe\u50cf\u91cd\u5efa\u5728\u4f4e\u5206\u8fa8\u7387\u8f93\u5165\u4e0b\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4fdd\u62a4\u9690\u79c1\u7684\u534f\u4f5c\u573a\u666f\u4e2d\uff0c\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff08\u5982\u6570\u636e\u6cc4\u9732\u548c\u63a8\u7406\u653b\u51fb\uff09\u53ca\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u95ee\u9898\u3002", "method": "PPFL-RDSN\u6846\u67b6\u6574\u5408\u4e86\u8054\u90a6\u5b66\u4e60(FL)\u3001\u672c\u5730\u5dee\u5206\u9690\u79c1\u4ee5\u53ca\u9c81\u68d2\u6a21\u578b\u6c34\u5370\u6280\u672f\uff0c\u4ee5\u4fdd\u8bc1\u6570\u636e\u4e0d\u79bb\u5f00\u672c\u5730\u8bbe\u5907\uff0c\u5e76\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u548c\u6a21\u578b\u771f\u5b9e\u6027\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cPPFL-RDSN\u5728\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u5b89\u5168\u548c\u9690\u79c1\u6f0f\u6d1e\u3002", "conclusion": "PPFL-RDSN\u662f\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u534f\u4f5c\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u3002"}}
{"id": "2507.00234", "pdf": "https://arxiv.org/pdf/2507.00234", "abs": "https://arxiv.org/abs/2507.00234", "authors": ["Jiztom Kavalakkatt Francis", "Matthew J Darr"], "title": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages", "summary": "In this paper, we present a novel framework for enhancing model\ninterpretability by integrating heatmaps produced separately by ResNet and a\nrestructured 2D Transformer with globally weighted input saliency. We address\nthe critical problem of spatial-temporal misalignment in existing\ninterpretability methods, where convolutional networks fail to capture global\ncontext and Transformers lack localized precision - a limitation that impedes\nactionable insights in safety-critical domains like healthcare and industrial\nmonitoring. Our method merges gradient-weighted activation maps (ResNet) and\nTransformer attention rollout into a unified visualization, achieving full\nspatial-temporal alignment while preserving real-time performance. Empirical\nevaluations on clinical (ECG arrhythmia detection) and industrial (energy\nconsumption prediction) datasets demonstrate significant improvements: the\nhybrid framework achieves 94.1% accuracy (F1 0.93) on the PhysioNet dataset and\nreduces regression error to RMSE = 0.28 kWh (R2 = 0.95) on the UCI Energy\nAppliance dataset-outperforming standalone ResNet, Transformer, and\nInceptionTime baselines by 3.8-12.4%. An NLP module translates fused heatmaps\ninto domain-specific narratives (e.g., \"Elevated ST-segment between 2-4 seconds\nsuggests myocardial ischemia\"), validated via BLEU-4 (0.586) and ROUGE-L\n(0.650) scores. By formalizing interpretability as causal fidelity and\nspatial-temporal alignment, our approach bridges the gap between technical\noutputs and stakeholder understanding, offering a scalable solution for\ntransparent, time-aware decision-making.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408ResNet\u548c\u91cd\u65b0\u6784\u5efa\u76842D Transformer\u4ea7\u751f\u7684\u70ed\u56fe\u6765\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u5728\u65f6\u7a7a\u5bf9\u9f50\u4e0a\u7684\u95ee\u9898\uff0c\u5e76\u5728\u4e34\u5e8a\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002\u6b64\u5916\uff0cNLP\u6a21\u5757\u5c06\u878d\u5408\u70ed\u56fe\u8f6c\u5316\u4e3a\u9886\u57df\u7279\u5b9a\u53d9\u8ff0\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u7406\u89e3\u5ea6\u3002\u6574\u4f53\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51b3\u7b56\u900f\u660e\u6027\u548c\u65f6\u95f4\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5b58\u5728\u65f6\u7a7a\u9519\u4f4d\u7684\u95ee\u9898\uff0c\u5377\u79ef\u7f51\u7edc\u65e0\u6cd5\u6355\u6349\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u800cTransformer\u7f3a\u4e4f\u5c40\u90e8\u7cbe\u5ea6\uff0c\u8fd9\u963b\u788d\u4e86\u5728\u533b\u7597\u4fdd\u5065\u548c\u5de5\u4e1a\u76d1\u63a7\u7b49\u5173\u952e\u5b89\u5168\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86ResNet\u751f\u6210\u7684\u68af\u5ea6\u52a0\u6743\u6fc0\u6d3b\u56fe\u548c\u5177\u6709\u5168\u5c40\u52a0\u6743\u8f93\u5165\u663e\u8457\u6027\u7684\u91cd\u65b0\u6784\u5efa\u76842D Transformer\u6ce8\u610f\u529b\u56de\u6eda\u56fe\uff0c\u5f62\u6210\u7edf\u4e00\u53ef\u89c6\u5316\uff0c\u5b9e\u73b0\u5b8c\u5168\u7684\u65f6\u7a7a\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u5728PhysioNet\u6570\u636e\u96c6\u4e0a\uff0c\u6df7\u5408\u6846\u67b6\u8fbe\u5230\u4e8694.1%\u7684\u51c6\u786e\u7387\uff08F1\u4e3a0.93\uff09\uff1b\u5728UCI Energy Appliance\u6570\u636e\u96c6\u4e0a\uff0c\u56de\u5f52\u8bef\u5dee\u964d\u4f4e\u81f3RMSE = 0.28 kWh\uff08R2 = 0.95\uff09\uff0c\u6bd4\u5355\u72ec\u7684ResNet\u3001Transformer\u548cInceptionTime\u57fa\u7ebf\u9ad8\u51fa3.8-12.4%\u3002NLP\u6a21\u5757\u901a\u8fc7BLEU-4\uff080.586\uff09\u548cROUGE-L\uff080.650\uff09\u5206\u6570\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u53ef\u89e3\u91ca\u6027\u5f62\u5f0f\u5316\u4e3a\u56e0\u679c\u4fdd\u771f\u5ea6\u548c\u65f6\u7a7a\u5bf9\u9f50\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5f25\u5408\u4e86\u6280\u672f\u8f93\u51fa\u4e0e\u5229\u76ca\u76f8\u5173\u8005\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u900f\u660e\u3001\u65f6\u95f4\u611f\u77e5\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.00257", "pdf": "https://arxiv.org/pdf/2507.00257", "abs": "https://arxiv.org/abs/2507.00257", "authors": ["Davide Salaorni", "Vincenzo De Paola", "Samuele Delpero", "Giovanni Dispoto", "Paolo Bonetti", "Alessio Russo", "Giuseppe Calcagno", "Francesco Trov\u00f2", "Matteo Papini", "Alberto Maria Metelli", "Marco Mussi", "Marcello Restelli"], "title": "Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages", "summary": "In recent years, \\emph{Reinforcement Learning} (RL) has made remarkable\nprogress, achieving superhuman performance in a wide range of simulated\nenvironments. As research moves toward deploying RL in real-world applications,\nthe field faces a new set of challenges inherent to real-world settings, such\nas large state-action spaces, non-stationarity, and partial observability.\nDespite their importance, these challenges are often underexplored in current\nbenchmarks, which tend to focus on idealized, fully observable, and stationary\nenvironments, often neglecting to incorporate real-world complexities\nexplicitly. In this paper, we introduce \\texttt{Gym4ReaL}, a comprehensive\nsuite of realistic environments designed to support the development and\nevaluation of RL algorithms that can operate in real-world scenarios. The suite\nincludes a diverse set of tasks that expose algorithms to a variety of\npractical challenges. Our experimental results show that, in these settings,\nstandard RL algorithms confirm their competitiveness against rule-based\nbenchmarks, motivating the development of new methods to fully exploit the\npotential of RL to tackle the complexities of real-world tasks.", "AI": {"tldr": "\u8fd1\u5e74\u6765\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u6a21\u62df\u73af\u5883\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\u7136\u800c\uff0c\u771f\u5b9e\u4e16\u754c\u7684\u6311\u6218\u5982\u5927\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u3001\u975e\u5e73\u7a33\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u5f80\u5f80\u88ab\u73b0\u6709\u57fa\u51c6\u6240\u5ffd\u89c6\u3002\u672c\u6587\u4ecb\u7ecd\u4e86Gym4ReaL\uff0c\u8fd9\u662f\u4e00\u4e2a\u652f\u6301\u5f00\u53d1\u548c\u8bc4\u4f30\u9002\u7528\u4e8e\u771f\u5b9e\u573a\u666f\u7684RL\u7b97\u6cd5\u7684\u73af\u5883\u5957\u4ef6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6807\u51c6RL\u7b97\u6cd5\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6fc0\u52b1\u4e86\u8fdb\u4e00\u6b65\u5f00\u53d1\u65b0\u65b9\u6cd5\u4ee5\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u590d\u6742\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9762\u5bf9\u771f\u5b9e\u4e16\u754c\u7684\u6311\u6218\uff08\u5982\u5927\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u3001\u975e\u5e73\u7a33\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\uff09\u65f6\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u6db5\u76d6\u8fd9\u4e9b\u590d\u6742\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684\u73af\u5883\u6765\u63a8\u52a8RL\u7b97\u6cd5\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u540d\u4e3aGym4ReaL\u7684\u7efc\u5408\u73af\u5883\uff0c\u5305\u542b\u591a\u79cd\u4efb\u52a1\uff0c\u65e8\u5728\u8ba9RL\u7b97\u6cd5\u66b4\u9732\u4e8e\u5404\u79cd\u5b9e\u9645\u6311\u6218\u4e2d\uff0c\u4ece\u800c\u652f\u6301\u5176\u5f00\u53d1\u4e0e\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8fd9\u4e9b\u8bbe\u7f6e\u4e0b\uff0c\u6807\u51c6RL\u7b97\u6cd5\u76f8\u8f83\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u51c6\u6d4b\u8bd5\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165Gym4ReaL\uff0c\u7814\u7a76\u8005\u53ef\u4ee5\u66f4\u597d\u5730\u53d1\u5c55\u548c\u8bc4\u4f30\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7684RL\u7b97\u6cd5\uff0c\u540c\u65f6\u6fc0\u53d1\u4e86\u65b0\u65b9\u6cd5\u7684\u5f00\u53d1\u4ee5\u5145\u5206\u5229\u7528RL\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.00259", "pdf": "https://arxiv.org/pdf/2507.00259", "abs": "https://arxiv.org/abs/2507.00259", "authors": ["Amr Abourayya", "Jens Kleesiek", "Bharat Rao", "Michael Kamp"], "title": "Who Should I Listen To? Adaptive Collaboration in Personalized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Data heterogeneity is a central challenge in federated learning, and\npersonalized federated learning (PFL) aims to address it by tailoring models to\neach client's distribution. Yet many PFL methods fail to outperform local or\ncentralized baselines, suggesting a mismatch between the collaboration they\nenforce and the structure of the data. We propose an approach based on adaptive\ncollaboration, where clients decide adaptively not only how much to rely on\nothers, but also whom to trust at the level of individual examples. We\ninstantiate this principle in FEDMOSAIC, a federated co-training method in\nwhich clients exchange predictions over a shared unlabeled dataset. This\nenables fine-grained trust decisions that are difficult to achieve with\nparameter sharing alone. Each client adjusts its loss weighting based on the\nagreement between private and public data, and contributes to global\npseudo-labels in proportion to its estimated per-example confidence.\nEmpirically, FEDMOSAIC improves upon state-of-the-art PFL methods across\ndiverse non-IID settings, and we provide convergence guarantees under standard\nassumptions. Our results demonstrate the potential of data-aware collaboration\nfor robust and effective personalization.", "AI": {"tldr": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u6570\u636e\u5f02\u8d28\u6027\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\uff08PFL\uff09\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u6570\u636e\u5206\u5e03\u91cf\u8eab\u5b9a\u5236\u6a21\u578b\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002\u7136\u800c\uff0c\u8bb8\u591aPFL\u65b9\u6cd5\u672a\u80fd\u8d85\u8d8a\u672c\u5730\u6216\u96c6\u4e2d\u5f0f\u57fa\u7ebf\uff0c\u8868\u660e\u5b83\u4eec\u7684\u534f\u4f5c\u65b9\u5f0f\u4e0e\u6570\u636e\u7ed3\u6784\u4e0d\u5339\u914d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u534f\u4f5c\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u5ba2\u6237\u7aef\u4e0d\u4ec5\u51b3\u5b9a\u4f9d\u8d56\u5176\u4ed6\u5ba2\u6237\u7aef\u7684\u7a0b\u5ea6\uff0c\u8fd8\u51b3\u5b9a\u5728\u5355\u4e2a\u6837\u672c\u7ea7\u522b\u4e0a\u4fe1\u4efb\u8c01\u3002\u6211\u4eec\u5728FEDMOSAIC\u4e2d\u5b9e\u4f8b\u5316\u4e86\u8fd9\u4e00\u539f\u5219\uff0c\u8fd9\u662f\u4e00\u79cd\u8054\u90a6\u534f\u540c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5ba2\u6237\u7aef\u5728\u4e00\u4e2a\u5171\u4eab\u7684\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u4ea4\u6362\u9884\u6d4b\u3002\u8fd9\u4f7f\u5f97\u7ec6\u7c92\u5ea6\u7684\u4fe1\u4efb\u51b3\u7b56\u53d8\u5f97\u56f0\u96be\uff0c\u800c\u4ec5\u4f7f\u7528\u53c2\u6570\u5171\u4eab\u96be\u4ee5\u5b9e\u73b0\u3002\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6839\u636e\u79c1\u6709\u548c\u516c\u5171\u6570\u636e\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u8c03\u6574\u5176\u635f\u5931\u6743\u91cd\uff0c\u5e76\u6839\u636e\u5176\u4f30\u8ba1\u7684\u6bcf\u4e2a\u6837\u672c\u7f6e\u4fe1\u5ea6\u6309\u6bd4\u4f8b\u8d21\u732e\u5168\u5c40\u4f2a\u6807\u7b7e\u3002\u7ecf\u9a8c\u8bc1\uff0cFEDMOSAIC\u5728\u591a\u79cd\u975eIID\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684PFL\u65b9\u6cd5\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u6807\u51c6\u5047\u8bbe\u4e0b\u7684\u6536\u655b\u6027\u4fdd\u8bc1\u3002\u6211\u4eec\u7684\u7ed3\u679c\u5c55\u793a\u4e86\u6570\u636e\u611f\u77e5\u534f\u4f5c\u5728\u5b9e\u73b0\u7a33\u5065\u548c\u6709\u6548\u7684\u4e2a\u6027\u5316\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f02\u8d28\u6027\u662f\u4e3b\u8981\u6311\u6218\uff0c\u5f53\u524d\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u672a\u80fd\u8d85\u8d8a\u672c\u5730\u6216\u96c6\u4e2d\u5f0f\u57fa\u51c6\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u5339\u914d\u6570\u636e\u7ed3\u6784\u5e76\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u534f\u4f5c\u7684\u65b9\u6cd5\uff0c\u5e76\u5728FEDMOSAIC\u4e2d\u5177\u4f53\u5b9e\u73b0\u3002\u8be5\u65b9\u6cd5\u8ba9\u5ba2\u6237\u7aef\u5728\u5171\u4eab\u7684\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u4ea4\u6362\u9884\u6d4b\uff0c\u4ece\u800c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u4fe1\u4efb\u51b3\u7b56\u3002\u5ba2\u6237\u7aef\u6839\u636e\u79c1\u6709\u548c\u516c\u5171\u6570\u636e\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u8c03\u6574\u635f\u5931\u6743\u91cd\uff0c\u5e76\u6309\u4f30\u8ba1\u7684\u6bcf\u4e2a\u6837\u672c\u7f6e\u4fe1\u5ea6\u8d21\u732e\u5168\u5c40\u4f2a\u6807\u7b7e\u3002", "result": "FEDMOSAIC\u5728\u591a\u4e2a\u975eIID\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdbPFL\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u5177\u6709\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u6570\u636e\u611f\u77e5\u534f\u4f5c\u5177\u6709\u5b9e\u73b0\u7a33\u5065\u548c\u6709\u6548\u4e2a\u6027\u5316\u6a21\u578b\u7684\u6f5c\u529b\uff0cFEDMOSAIC\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6210\u529f\u7684\u793a\u4f8b\u3002"}}
{"id": "2507.00265", "pdf": "https://arxiv.org/pdf/2507.00265", "abs": "https://arxiv.org/abs/2507.00265", "authors": ["Alexis Carrillo", "Asieh Abolpour Mofrad", "Anis Yazidi", "Moises Betancort"], "title": "Examining Reject Relations in Stimulus Equivalence Simulations", "categories": ["cs.LG", "q-bio.NC", "I.2.0; J.4; I.6.5"], "comment": "18 pages, 6 figures", "summary": "Simulations offer a valuable tool for exploring stimulus equivalence (SE),\nyet the potential of reject relations to disrupt the assessment of equivalence\nclass formation is contentious. This study investigates the role of reject\nrelations in the acquisition of stimulus equivalence using computational\nmodels. We examined feedforward neural networks (FFNs), bidirectional encoder\nrepresentations from transformers (BERT), and generative pre-trained\ntransformers (GPT) across 18 conditions in matching-to-sample (MTS)\nsimulations. Conditions varied in training structure (linear series,\none-to-many, and many-to-one), relation type (select-only, reject-only, and\nselect-reject), and negative comparison selection (standard and biased). A\nprobabilistic agent served as a benchmark, embodying purely associative\nlearning. The primary goal was to determine whether artificial neural networks\ncould demonstrate equivalence class formation or whether their performance\nreflected associative learning. Results showed that reject relations influenced\nagent performance. While some agents achieved high accuracy on equivalence\ntests, particularly with reject relations and biased negative comparisons, this\nperformance was comparable to the probabilistic agent. These findings suggest\nthat artificial neural networks, including transformer models, may rely on\nassociative strategies rather than SE. This underscores the need for careful\nconsideration of reject relations and more stringent criteria in computational\nmodels of equivalence.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u62d2\u7edd\u5173\u7cfb\u5728\u523a\u6fc0\u7b49\u4ef7\u6027\u83b7\u53d6\u4e2d\u7684\u4f5c\u7528\uff0c\u4f7f\u7528\u8ba1\u7b97\u6a21\u578b\uff08\u5982\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3001BERT\u548cGPT\uff09\u8fdb\u884c\u5339\u914d\u6837\u672c\u6a21\u62df\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u4e00\u4e9b\u6a21\u578b\u5728\u7b49\u4ef7\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u5176\u6027\u80fd\u53ef\u80fd\u57fa\u4e8e\u8054\u60f3\u5b66\u4e60\u800c\u975e\u771f\u6b63\u7684\u523a\u6fc0\u7b49\u4ef7\u6027\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u8ba1\u7b97\u6a21\u578b\u4e2d\u9700\u8981\u66f4\u4e25\u683c\u7684\u6807\u51c6\u6765\u8bc4\u4f30\u7b49\u4ef7\u6027\u3002", "motivation": "\u63a2\u7d22\u62d2\u7edd\u5173\u7cfb\u662f\u5426\u4f1a\u5f71\u54cd\u7b49\u4ef7\u7c7b\u5f62\u6210\u7684\u8bc4\u4f30\uff0c\u5e76\u4e86\u89e3\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u5c55\u793a\u51fa\u7b49\u4ef7\u7c7b\u5f62\u6210\u8fd8\u662f\u4ec5\u53cd\u6620\u8054\u60f3\u5b66\u4e60\u3002", "method": "\u91c7\u7528\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3001BERT\u548cGPT\u6a21\u578b\uff0c\u572818\u79cd\u6761\u4ef6\u4e0b\u8fdb\u884c\u5339\u914d\u6837\u672c\u6a21\u62df\u3002\u6761\u4ef6\u5305\u62ec\u4e0d\u540c\u7684\u8bad\u7ec3\u7ed3\u6784\u3001\u5173\u7cfb\u7c7b\u578b\u548c\u8d1f\u9762\u6bd4\u8f83\u9009\u62e9\u65b9\u5f0f\u3002\u540c\u65f6\u4f7f\u7528\u6982\u7387\u4ee3\u7406\u4f5c\u4e3a\u57fa\u51c6\u5bf9\u6bd4\u3002", "result": "\u62d2\u7edd\u5173\u7cfb\u5f71\u54cd\u4e86\u4ee3\u7406\u7684\u8868\u73b0\u3002\u4e00\u4e9b\u4ee3\u7406\u5728\u7b49\u4ef7\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u6709\u62d2\u7edd\u5173\u7cfb\u548c\u504f\u5411\u8d1f\u9762\u6bd4\u8f83\u7684\u60c5\u51b5\u4e0b\uff0c\u4f46\u5176\u8868\u73b0\u4e0e\u6982\u7387\u4ee3\u7406\u76f8\u5f53\u3002", "conclusion": "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u4f9d\u8d56\u4e8e\u8054\u60f3\u7b56\u7565\u800c\u975e\u523a\u6fc0\u7b49\u4ef7\u6027\uff0c\u56e0\u6b64\u5728\u8ba1\u7b97\u6a21\u578b\u7684\u7b49\u4ef7\u6027\u8bc4\u4f30\u4e2d\u9700\u8981\u66f4\u52a0\u4e25\u683c\u7684\u51c6\u5219\u548c\u5bf9\u62d2\u7edd\u5173\u7cfb\u7684\u4ed4\u7ec6\u8003\u8651\u3002"}}
{"id": "2507.00275", "pdf": "https://arxiv.org/pdf/2507.00275", "abs": "https://arxiv.org/abs/2507.00275", "authors": ["Prabhat Nagarajan", "Martha White", "Marlos C. Machado"], "title": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited", "categories": ["cs.LG", "cs.AI"], "comment": "44 pages", "summary": "Overestimation is pervasive in reinforcement learning (RL), including in\nQ-learning, which forms the algorithmic basis for many value-based deep RL\nalgorithms. Double Q-learning is an algorithm introduced to address\nQ-learning's overestimation by training two Q-functions and using both to\nde-correlate action-selection and action-evaluation in bootstrap targets.\nShortly after Q-learning was adapted to deep RL in the form of deep Q-networks\n(DQN), Double Q-learning was adapted to deep RL in the form of Double DQN.\nHowever, Double DQN only loosely adapts Double Q-learning, forgoing the\ntraining of two different Q-functions that bootstrap off one another. In this\npaper, we study algorithms that adapt this core idea of Double Q-learning for\nvalue-based deep RL. We term such algorithms Deep Double Q-learning (DDQL). Our\naim is to understand whether DDQL exhibits less overestimation than Double DQN\nand whether performant instantiations of DDQL exist. We answer both questions\naffirmatively, demonstrating that DDQL reduces overestimation and outperforms\nDouble DQN in aggregate across 57 Atari 2600 games, without requiring\nadditional hyperparameters. We also study several aspects of DDQL, including\nits network architecture, replay ratio, and minibatch sampling strategy.", "AI": {"tldr": "\u5728\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u8fc7\u4f30\u8ba1\u662f\u4e00\u4e2a\u666e\u904d\u5b58\u5728\u7684\u95ee\u9898\u3002\u672c\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u53ccQ\u5b66\u4e60\uff08DDQL\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u53ccQ\u5b66\u4e60\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u8bad\u7ec3\u4e24\u4e2a\u76f8\u4e92\u5f15\u5bfc\u7684Q\u51fd\u6570\uff0c\u4ee5\u51cf\u5c11\u8fc7\u4f30\u8ba1\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDDQL\u76f8\u8f83\u4e8eDouble DQN\u51cf\u5c11\u4e86\u8fc7\u4f30\u8ba1\uff0c\u5e76\u572857\u4e2aAtari 2600\u6e38\u620f\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u65e0\u9700\u989d\u5916\u7684\u8d85\u53c2\u6570\u8c03\u6574\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8fc7\u4f30\u8ba1\u95ee\u9898\uff0c\u7279\u522b\u662fQ-learning\u4e2d\u7684\u8fc7\u4f30\u8ba1\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u6539\u8fdb\u7684\u65b9\u6cd5\u3002\u867d\u7136Double DQN\u5df2\u7ecf\u90e8\u5206\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5176\u5e76\u672a\u5b8c\u5168\u9075\u5faaDouble Q-learning\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u5373\u8bad\u7ec3\u4e24\u4e2a\u4e0d\u540c\u7684Q\u51fd\u6570\u8fdb\u884c\u5f15\u5bfc\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u5f00\u53d1\u51fa\u66f4\u7b26\u5408Double Q-learning\u539f\u5219\u3001\u8fdb\u4e00\u6b65\u51cf\u5c11\u8fc7\u4f30\u8ba1\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeep Double Q-learning (DDQL) \u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4e25\u683c\u9075\u5faaDouble Q-learning\u7684\u601d\u60f3\uff0c\u8bad\u7ec3\u4e24\u4e2a\u72ec\u7acb\u7684Q\u51fd\u6570\uff0c\u901a\u8fc7\u8fd9\u4e24\u4e2aQ\u51fd\u6570\u6765\u89e3\u8026\u52a8\u4f5c\u9009\u62e9\u548c\u52a8\u4f5c\u8bc4\u4f30\u3002\u4e0eDouble DQN\u4e0d\u540c\uff0cDDQL\u786e\u4fdd\u4e24\u4e2aQ\u51fd\u6570\u5728\u5f15\u5bfc\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u5dee\u5f02\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9DDQL\u7684\u7f51\u7edc\u67b6\u6784\u3001\u91cd\u653e\u7f13\u51b2\u6bd4\u4ee5\u53ca\u5c0f\u6279\u91cf\u91c7\u6837\u7b56\u7565\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cDDQL\u76f8\u6bd4Double DQN\u663e\u8457\u51cf\u5c11\u4e86\u8fc7\u4f30\u8ba1\uff0c\u5e76\u572857\u4e2aAtari 2600\u6e38\u620f\u7684\u603b\u4f53\u8868\u73b0\u4e0a\u4f18\u4e8eDouble DQN\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u4e9b\u6539\u8fdb\u662f\u5728\u65e0\u9700\u589e\u52a0\u989d\u5916\u8d85\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7684\u3002", "conclusion": "Deep Double Q-learning (DDQL) \u662f\u4e00\u79cd\u6709\u6548\u51cf\u5c11\u8fc7\u4f30\u8ba1\u5e76\u63d0\u5347\u6027\u80fd\u7684\u7b97\u6cd5\uff0c\u5176\u6548\u679c\u4f18\u4e8eDouble DQN\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7b97\u6cd5\u7684\u7b80\u6d01\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4ef7\u503c\u578b\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u4e25\u683c\u9075\u5faaDouble Q-learning\u7684\u539f\u5219\u80fd\u591f\u5e26\u6765\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2507.00301", "pdf": "https://arxiv.org/pdf/2507.00301", "abs": "https://arxiv.org/abs/2507.00301", "authors": ["Harsh Sharma", "Juan Diego Draxl Giannoni", "Boris Kramer"], "title": "Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "arXiv admin note: substantial text overlap with arXiv:2503.02273", "summary": "This work presents structure-preserving Lift & Learn, a scientific machine\nlearning method that employs lifting variable transformations to learn\nstructure-preserving reduced-order models for nonlinear partial differential\nequations (PDEs) with conservation laws. We propose a hybrid learning approach\nbased on a recently developed energy-quadratization strategy that uses\nknowledge of the nonlinearity at the PDE level to derive an equivalent\nquadratic lifted system with quadratic system energy. The lifted dynamics\nobtained via energy quadratization are linear in the old variables, making\nmodel learning very effective in the lifted setting. Based on the lifted\nquadratic PDE model form, the proposed method derives quadratic reduced terms\nanalytically and then uses those derived terms to formulate a constrained\noptimization problem to learn the remaining linear reduced operators in a\nstructure-preserving way. The proposed hybrid learning approach yields\ncomputationally efficient quadratic reduced-order models that respect the\nunderlying physics of the high-dimensional problem. We demonstrate the\ngeneralizability of quadratic models learned via the proposed\nstructure-preserving Lift & Learn method through three numerical examples: the\none-dimensional wave equation with exponential nonlinearity, the\ntwo-dimensional sine-Gordon equation, and the two-dimensional\nKlein-Gordon-Zakharov equations. The numerical results show that the proposed\nlearning approach is competitive with the state-of-the-art structure-preserving\ndata-driven model reduction method in terms of both accuracy and computational\nefficiency.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u4fdd\u6301\u7684 Lift & Learn \u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u5347\u53d8\u91cf\u8f6c\u6362\u6765\u5b66\u4e60\u5177\u6709\u5b88\u6052\u5f8b\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDE\uff09\u7684\u7ed3\u6784\u4fdd\u6301\u7b80\u5316\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u80fd\u91cf\u4e8c\u6b21\u5316\u7b56\u7565\uff0c\u4f7f\u7528 PDE \u975e\u7ebf\u6027\u77e5\u8bc6\u63a8\u5bfc\u51fa\u7b49\u6548\u7684\u4e8c\u6b21\u63d0\u5347\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u5b66\u4e60\u5269\u4f59\u7684\u7ebf\u6027\u7b80\u5316\u7b97\u5b50\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u7684\u7ed3\u6784\u4fdd\u6301\u6570\u636e\u9a71\u52a8\u6a21\u578b\u964d\u9636\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDE\uff09\u7684\u7b80\u5316\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u5bf9\u7269\u7406\u7ed3\u6784\u548c\u5b88\u6052\u5f8b\u7684\u4fdd\u7559\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528\u6548\u679c\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5b66\u4e60\u7ed3\u6784\u4fdd\u6301\u7684\u7b80\u5316\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u4e8c\u6b21\u5316\u7b56\u7565\u7684\u6df7\u5408\u5b66\u4e60\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u63d0\u5347\u53d8\u91cf\u8f6c\u6362\u5c06\u975e\u7ebf\u6027 PDE \u8f6c\u6362\u4e3a\u7b49\u6548\u7684\u4e8c\u6b21\u63d0\u5347\u7cfb\u7edf\uff1b2) \u63a8\u5bfc\u51fa\u89e3\u6790\u7684\u4e8c\u6b21\u7b80\u5316\u9879\uff1b3) \u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u5b66\u4e60\u5269\u4f59\u7684\u7ebf\u6027\u7b80\u5316\u7b97\u5b50\uff1b4) \u6784\u5efa\u4e00\u4e2a\u7ed3\u6784\u4fdd\u6301\u7684\u4e8c\u6b21\u7b80\u5316\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6570\u503c\u4f8b\u5b50\uff08\u4e00\u7ef4\u6307\u6570\u975e\u7ebf\u6027\u6ce2\u52a8\u65b9\u7a0b\u3001\u4e8c\u7ef4 sine-Gordon \u65b9\u7a0b\u548c\u4e8c\u7ef4 Klein-Gordon-Zakharov \u65b9\u7a0b\uff09\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684 Lift & Learn \u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u7ed3\u6784\u4fdd\u6301\u6570\u636e\u9a71\u52a8\u6a21\u578b\u964d\u9636\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u7ed3\u6784\u4fdd\u6301\u7684 Lift & Learn \u65b9\u6cd5\u662f\u4e00\u79cd\u6709\u6548\u7684\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u9002\u7528\u4e8e\u6784\u5efa\u5177\u6709\u5b88\u6052\u5f8b\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7b80\u5316\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u8ba1\u7b97\u9ad8\u6548\uff0c\u800c\u4e14\u5c0a\u91cd\u9ad8\u7ef4\u95ee\u9898\u7684\u5e95\u5c42\u7269\u7406\u7279\u6027\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2507.00304", "pdf": "https://arxiv.org/pdf/2507.00304", "abs": "https://arxiv.org/abs/2507.00304", "authors": ["Yujun Zhang", "Runlong Li", "Xiaoxiang Liang", "Xinhao Yang", "Tian Su", "Bo Liu", "Yan Zhou"], "title": "MamNet: A Novel Hybrid Model for Time-Series Forecasting and Frequency Pattern Analysis in Network Traffic", "categories": ["cs.LG", "cs.NI"], "comment": "16 pages", "summary": "The abnormal fluctuations in network traffic may indicate potential security\nthreats or system failures. Therefore, efficient network traffic prediction and\nanomaly detection methods are crucial for network security and traffic\nmanagement. This paper proposes a novel network traffic prediction and anomaly\ndetection model, MamNet, which integrates time-domain modeling and\nfrequency-domain feature extraction. The model first captures the long-term\ndependencies of network traffic through the Mamba module (time-domain\nmodeling), and then identifies periodic fluctuations in the traffic using\nFourier Transform (frequency-domain feature extraction). In the feature fusion\nlayer, multi-scale information is integrated to enhance the model's ability to\ndetect network traffic anomalies. Experiments conducted on the UNSW-NB15 and\nCAIDA datasets demonstrate that MamNet outperforms several recent mainstream\nmodels in terms of accuracy, recall, and F1-Score. Specifically, it achieves an\nimprovement of approximately 2% to 4% in detection performance for complex\ntraffic patterns and long-term trend detection. The results indicate that\nMamNet effectively captures anomalies in network traffic across different time\nscales and is suitable for anomaly detection tasks in network security and\ntraffic management. Future work could further optimize the model structure by\nincorporating external network event information, thereby improving the model's\nadaptability and stability in complex network environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u6d41\u91cf\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u6a21\u578bMamNet\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u65f6\u57df\u5efa\u6a21\u548c\u9891\u57df\u7279\u5f81\u63d0\u53d6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMamNet\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u65b9\u9762\u4f18\u4e8e\u51e0\u79cd\u6700\u8fd1\u7684\u4e3b\u6d41\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u590d\u6742\u6d41\u91cf\u6a21\u5f0f\u548c\u957f\u671f\u8d8b\u52bf\u68c0\u6d4b\u65b9\u9762\u7684\u6027\u80fd\u63d0\u9ad8\u4e86\u7ea62%\u52304%\u3002\u7ed3\u679c\u8868\u660e\uff0cMamNet\u80fd\u591f\u6709\u6548\u5730\u6355\u6349\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u548c\u6d41\u91cf\u7ba1\u7406\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u7f51\u7edc\u4e8b\u4ef6\u4fe1\u606f\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u7ed3\u6784\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u5728\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u7f51\u7edc\u6d41\u91cf\u4e2d\u7684\u5f02\u5e38\u6ce2\u52a8\u53ef\u80fd\u9884\u793a\u7740\u6f5c\u5728\u7684\u5b89\u5168\u5a01\u80c1\u6216\u7cfb\u7edf\u6545\u969c\uff0c\u56e0\u6b64\u9ad8\u6548\u7684\u7f51\u7edc\u6d41\u91cf\u9884\u6d4b\u548c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u4e8e\u7f51\u7edc\u5b89\u5168\u548c\u6d41\u91cf\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMamNet\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u96c6\u6210\u4e86\u65f6\u57df\u5efa\u6a21\uff08\u901a\u8fc7Mamba\u6a21\u5757\u6355\u83b7\u957f\u671f\u4f9d\u8d56\u6027\uff09\u548c\u9891\u57df\u7279\u5f81\u63d0\u53d6\uff08\u4f7f\u7528\u5085\u91cc\u53f6\u53d8\u6362\u8bc6\u522b\u5468\u671f\u6027\u6ce2\u52a8\uff09\u3002\u5728\u7279\u5f81\u878d\u5408\u5c42\u4e2d\uff0c\u6574\u5408\u591a\u5c3a\u5ea6\u4fe1\u606f\u4ee5\u589e\u5f3a\u6a21\u578b\u68c0\u6d4b\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\u7684\u80fd\u529b\u3002", "result": "\u5728UNSW-NB15\u548cCAIDA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMamNet\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1-Score\u65b9\u9762\u4f18\u4e8e\u51e0\u4e2a\u6700\u8fd1\u7684\u4e3b\u6d41\u6a21\u578b\u3002\u7279\u522b\u662f\u5728\u590d\u6742\u6d41\u91cf\u6a21\u5f0f\u548c\u957f\u671f\u8d8b\u52bf\u68c0\u6d4b\u65b9\u9762\uff0c\u6027\u80fd\u63d0\u5347\u4e86\u7ea62%\u52304%\u3002", "conclusion": "MamNet\u6709\u6548\u5730\u6355\u6349\u4e86\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\uff0c\u9002\u5408\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u548c\u6d41\u91cf\u7ba1\u7406\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u4ee5\u8003\u8651\u901a\u8fc7\u52a0\u5165\u5916\u90e8\u7f51\u7edc\u4e8b\u4ef6\u4fe1\u606f\u6765\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u7ed3\u6784\uff0c\u63d0\u9ad8\u5176\u5728\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2507.00310", "pdf": "https://arxiv.org/pdf/2507.00310", "abs": "https://arxiv.org/abs/2507.00310", "authors": ["Dhruv Agarwal", "Bodhisattwa Prasad Majumder", "Reece Adamson", "Megha Chakravorty", "Satvika Reddy Gavireddy", "Aditya Parashar", "Harshit Surana", "Bhavana Dalvi Mishra", "Andrew McCallum", "Ashish Sabharwal", "Peter Clark"], "title": "Open-ended Scientific Discovery via Bayesian Surprise", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The promise of autonomous scientific discovery (ASD) hinges not only on\nanswering questions, but also on knowing which questions to ask. Most recent\nworks in ASD explore the use of large language models (LLMs) in goal-driven\nsettings, relying on human-specified research questions to guide hypothesis\ngeneration. However, scientific discovery may be accelerated further by\nallowing the AI system to drive exploration by its own criteria. The few\nexisting approaches in open-ended ASD select hypotheses based on diversity\nheuristics or subjective proxies for human interestingness, but the former\nstruggles to meaningfully navigate the typically vast hypothesis space, and the\nlatter suffers from imprecise definitions. This paper presents AutoDS -- a\nmethod for open-ended ASD that instead drives scientific exploration using\nBayesian surprise. Here, we quantify the epistemic shift from the LLM's prior\nbeliefs about a hypothesis to its posterior beliefs after gathering\nexperimental results. To efficiently explore the space of nested hypotheses,\nour method employs a Monte Carlo tree search (MCTS) strategy with progressive\nwidening using surprisal as the reward function. We evaluate AutoDS in the\nsetting of data-driven discovery across 21 real-world datasets spanning domains\nsuch as biology, economics, finance, and behavioral science. Our results\ndemonstrate that under a fixed budget, AutoDS substantially outperforms\ncompetitors by producing 5--29\\% more discoveries deemed surprising by the LLM.\nOur human evaluation further finds that two-thirds of AutoDS discoveries are\nsurprising to the domain experts, suggesting this is an important step forward\ntowards building open-ended ASD systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAutoDS\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u653e\u5f0f\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\uff08ASD\uff09\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u8d1d\u53f6\u65af\u60ca\u8bb6\u5ea6\u6765\u9a71\u52a8\u79d1\u5b66\u63a2\u7d22\uff0c\u91cf\u5316\u4ece\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5148\u9a8c\u4fe1\u5ff5\u5230\u540e\u9a8c\u4fe1\u5ff5\u7684\u77e5\u8bc6\u8f6c\u53d8\u3002\u91c7\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b56\u7565\u7ed3\u5408\u9010\u6b65\u6269\u5c55\u7684\u65b9\u5f0f\u63a2\u7d22\u5047\u8bbe\u7a7a\u95f4\uff0c\u5e76\u4ee5\u60ca\u8bb6\u5ea6\u4f5c\u4e3a\u5956\u52b1\u51fd\u6570\u3002\u572821\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cAutoDS\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u6bd4\u7ade\u4e89\u5bf9\u624b\u591a\u4ea7\u751f5-29%\u7684\u4ee4\u4eba\u60ca\u8bb6\u7684\u53d1\u73b0\uff0c\u5e76\u4e14\u4e09\u5206\u4e4b\u4e8c\u7684\u53d1\u73b0\u88ab\u9886\u57df\u4e13\u5bb6\u8ba4\u4e3a\u662f\u51fa\u4e4e\u610f\u6599\u7684\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u7684ASD\u7814\u7a76\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u6307\u5b9a\u7684\u7814\u7a76\u95ee\u9898\u6765\u5f15\u5bfc\u5047\u8bbe\u751f\u6210\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u9650\u5236\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u52a0\u901f\u3002\u5f00\u653e\u5f0f\u7684ASD\u65b9\u6cd5\u867d\u7136\u5b58\u5728\uff0c\u4f46\u57fa\u4e8e\u591a\u6837\u6027\u548c\u4e3b\u89c2\u6709\u8da3\u6027\u7684\u9009\u62e9\u6807\u51c6\u5206\u522b\u9762\u4e34\u96be\u4ee5\u6709\u6548\u5bfc\u822a\u5e9e\u5927\u7684\u5047\u8bbe\u7a7a\u95f4\u548c\u5b9a\u4e49\u4e0d\u7cbe\u786e\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u5047\u8bbe\u9009\u62e9\u6807\u51c6\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u63a8\u52a8\u79d1\u5b66\u63a2\u7d22\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAutoDS\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u60ca\u8bb6\u5ea6\u9a71\u52a8\u79d1\u5b66\u63a2\u7d22\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u901a\u8fc7\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6536\u96c6\u5b9e\u9a8c\u7ed3\u679c\u524d\u540e\u7684\u4fe1\u5ff5\u53d8\u5316\uff0c\u5373\u77e5\u8bc6\u8f6c\u53d8\uff0c\u6765\u8861\u91cf\u60ca\u8bb6\u5ea6\u3002\u4e3a\u4e86\u9ad8\u6548\u63a2\u7d22\u5d4c\u5957\u5047\u8bbe\u7a7a\u95f4\uff0c\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u5e26\u6709\u9010\u6b65\u6269\u5c55\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7b56\u7565\uff0c\u5e76\u4ee5\u60ca\u8bb6\u5ea6\u4f5c\u4e3a\u5956\u52b1\u51fd\u6570\u3002", "result": "\u572821\u4e2a\u6db5\u76d6\u751f\u7269\u5b66\u3001\u7ecf\u6d4e\u5b66\u3001\u91d1\u878d\u5b66\u548c\u884c\u4e3a\u79d1\u5b66\u7b49\u9886\u57df\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0cAutoDS\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8e\u7ade\u4e89\u5bf9\u624b\uff0c\u4ea7\u751f\u7684\u4ee4\u4eba\u60ca\u8bb6\u7684\u53d1\u73b0\u591a\u51fa5-29%\u3002\u6b64\u5916\uff0c\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0cAutoDS\u53d1\u73b0\u4e2d\u6709\u4e09\u5206\u4e4b\u4e8c\u88ab\u9886\u57df\u4e13\u5bb6\u8ba4\u4e3a\u662f\u4ee4\u4eba\u60ca\u8bb6\u7684\u3002", "conclusion": "AutoDS\u4ee3\u8868\u4e86\u6784\u5efa\u5f00\u653e\u5f0f\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u7684\u91cd\u8981\u4e00\u6b65\u3002\u901a\u8fc7\u4f7f\u7528\u8d1d\u53f6\u65af\u60ca\u8bb6\u5ea6\u4f5c\u4e3a\u9a71\u52a8\u63a2\u7d22\u7684\u6807\u51c6\uff0cAutoDS\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u53d1\u73b0\u6548\u7387\uff0c\u800c\u4e14\u5176\u53d1\u73b0\u5f97\u5230\u4e86\u9886\u57df\u4e13\u5bb6\u7684\u8ba4\u53ef\uff0c\u4e3a\u672a\u6765\u7684ASD\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2507.00316", "pdf": "https://arxiv.org/pdf/2507.00316", "abs": "https://arxiv.org/abs/2507.00316", "authors": ["Siyou Li", "Pengyao Qin", "Huanan Wu", "Dong Nie", "Arun J. Thirunavukarasu", "Juntao Yu", "Le Zhang"], "title": "$\u03bc^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation", "categories": ["cs.LG", "cs.CL", "eess.IV"], "comment": "Accepted by MICCAI 2025", "summary": "Automated radiology report generation (RRG) aims to produce detailed textual\nreports from clinical imaging, such as computed tomography (CT) scans, to\nimprove the accuracy and efficiency of diagnosis and provision of management\nadvice. RRG is complicated by two key challenges: (1) inherent complexity in\nextracting relevant information from imaging data under resource constraints,\nand (2) difficulty in objectively evaluating discrepancies between\nmodel-generated and expert-written reports. To address these challenges, we\npropose $\\mu^2$LLM, a $\\underline{\\textbf{mu}}$ltiscale\n$\\underline{\\textbf{mu}}$ltimodal large language models for RRG tasks. The\nnovel ${\\mu}^2$Tokenizer, as an intermediate layer, integrates multi-modal\nfeatures from the multiscale visual tokenizer and the text tokenizer, then\nenhances report generation quality through direct preference optimization\n(DPO), guided by GREEN-RedLlama. Experimental results on four large CT\nimage-report medical datasetdemonstrate that our method outperforms existing\napproaches, highlighting the potential of our fine-tuned $\\mu^2$LLMs on limited\ndata for RRG tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u5c3a\u5ea6\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u03bc\u00b2LLM\uff0c\u7528\u4e8e\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u4efb\u52a1\u3002\u901a\u8fc7\u03bc\u00b2Tokenizer\u6574\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u4f18\u5316\u63d0\u5347\u62a5\u544a\u751f\u6210\u8d28\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u6570\u636e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\uff08RRG\uff09\u65e8\u5728\u4ece\u4e34\u5e8a\u5f71\u50cf\u4e2d\u751f\u6210\u8be6\u7ec6\u7684\u6587\u672c\u62a5\u544a\uff0c\u4ee5\u63d0\u9ad8\u8bca\u65ad\u548c\u7ba1\u7406\u5efa\u8bae\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u7136\u800c\uff0cRRG\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a(1) \u5728\u8d44\u6e90\u9650\u5236\u4e0b\u4ece\u5f71\u50cf\u6570\u636e\u4e2d\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\u7684\u56fa\u6709\u590d\u6742\u6027\uff1b(2) \u96be\u4ee5\u5ba2\u89c2\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u62a5\u544a\u4e0e\u4e13\u5bb6\u64b0\u5199\u62a5\u544a\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u03bc\u00b2LLM\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u03bc\u00b2LLM\uff0c\u4e00\u79cd\u591a\u5c3a\u5ea6\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8eRRG\u4efb\u52a1\u3002\u5176\u4e2d\uff0c\u03bc\u00b2Tokenizer\u4f5c\u4e3a\u4e2d\u95f4\u5c42\uff0c\u6574\u5408\u4e86\u591a\u5c3a\u5ea6\u89c6\u89c9\u6807\u8bb0\u5316\u5668\u548c\u6587\u672c\u6807\u8bb0\u5316\u5668\u7684\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7GREEN-RedLlama\u6307\u5bfc\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u63d0\u5347\u4e86\u62a5\u544a\u751f\u6210\u7684\u8d28\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u5927\u578bCT\u56fe\u50cf-\u62a5\u544a\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u7684\u6570\u636e\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5fae\u8c03\u540e\u7684\u03bc\u00b2LLMs\u5728RRG\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u03bc\u00b2LLM\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u6001\u7279\u5f81\u548c\u4f18\u5316\u6280\u672f\uff0c\u5728\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u4f18\u52bf\uff0c\u8fd9\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.00320", "pdf": "https://arxiv.org/pdf/2507.00320", "abs": "https://arxiv.org/abs/2507.00320", "authors": ["Christiana Westlin", "Ashutosh Singh", "Deniz Erdogmus", "Georgios Stratis", "Lisa Feldman Barrett"], "title": "Exploring Theory-Laden Observations in the Brain Basis of Emotional Experience", "categories": ["cs.LG", "cs.CV", "q-bio.NC"], "comment": null, "summary": "In the science of emotion, it is widely assumed that folk emotion categories\nform a biological and psychological typology, and studies are routinely\ndesigned and analyzed to identify emotion-specific patterns. This approach\nshapes the observations that studies report, ultimately reinforcing the\nassumption that guided the investigation. Here, we reanalyzed data from one\nsuch typologically-guided study that reported mappings between individual brain\npatterns and group-averaged ratings of 34 emotion categories. Our reanalysis\nwas guided by an alternative view of emotion categories as populations of\nvariable, situated instances, and which predicts a priori that there will be\nsignificant variation in brain patterns within a category across instances.\nCorrespondingly, our analysis made minimal assumptions about the structure of\nthe variance present in the data. As predicted, we did not observe the original\nmappings and instead observed significant variation across individuals. These\nfindings demonstrate how starting assumptions can ultimately impact scientific\nconclusions and suggest that a hypothesis must be supported using multiple\nanalytic methods before it is taken seriously.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u91cd\u65b0\u5206\u6790\u4e86\u4e00\u4e2a\u4ee5\u7c7b\u578b\u5b66\u4e3a\u5bfc\u5411\u7684\u7814\u7a76\uff0c\u8be5\u7814\u7a76\u62a5\u9053\u4e86\u4e2a\u4f53\u5927\u8111\u6a21\u5f0f\u4e0e34\u79cd\u60c5\u7eea\u7c7b\u522b\u7684\u7fa4\u4f53\u5e73\u5747\u8bc4\u5206\u4e4b\u95f4\u7684\u6620\u5c04\u3002\u901a\u8fc7\u91c7\u7528\u4e00\u79cd\u5c06\u60c5\u7eea\u7c7b\u522b\u89c6\u4e3a\u53ef\u53d8\u3001\u60c5\u5883\u5316\u5b9e\u4f8b\u7684\u4eba\u53e3\u7684\u89c2\u70b9\uff0c\u91cd\u65b0\u5206\u6790\u53d1\u73b0\uff0c\u5728\u7c7b\u522b\u5185\u7684\u4e0d\u540c\u5b9e\u4f8b\u4e2d\uff0c\u5927\u8111\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u53d8\u5f02\u3002\u8fd9\u8868\u660e\u521d\u59cb\u5047\u8bbe\u5982\u4f55\u6700\u7ec8\u5f71\u54cd\u79d1\u5b66\u7ed3\u8bba\uff0c\u5e76\u5efa\u8bae\u5728\u8ba4\u771f\u5bf9\u5f85\u4e00\u4e2a\u5047\u8bbe\u4e4b\u524d\uff0c\u5fc5\u987b\u4f7f\u7528\u591a\u79cd\u5206\u6790\u65b9\u6cd5\u6765\u652f\u6301\u5b83\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u60c5\u611f\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u63a5\u53d7\u7684\u5047\u8bbe\uff0c\u5373\u6c11\u95f4\u60c5\u611f\u7c7b\u522b\u5f62\u6210\u4e86\u4e00\u79cd\u751f\u7269\u548c\u5fc3\u7406\u5b66\u7684\u5206\u7c7b\u5b66\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u5047\u8bbe\u4f1a\u5f71\u54cd\u7814\u7a76\u7684\u8bbe\u8ba1\u548c\u5206\u6790\uff0c\u4ece\u800c\u5f3a\u5316\u81ea\u8eab\u3002\u56e0\u6b64\uff0c\u4ed6\u4eec\u5e0c\u671b\u901a\u8fc7\u91cd\u65b0\u5206\u6790\u5df2\u6709\u6570\u636e\uff0c\u9a8c\u8bc1\u57fa\u4e8e\u66ff\u4ee3\u89c2\u70b9\u7684\u7ed3\u679c\u662f\u5426\u4f1a\u6709\u6240\u4e0d\u540c\u3002", "method": "\u91cd\u65b0\u5206\u6790\u4e86\u4e00\u9879\u5148\u524d\u62a5\u9053\u4e2a\u4f53\u5927\u8111\u6a21\u5f0f\u4e0e34\u79cd\u60c5\u611f\u7c7b\u522b\u7fa4\u4f53\u5e73\u5747\u8bc4\u5206\u4e4b\u95f4\u6620\u5c04\u7684\u7814\u7a76\u6570\u636e\u3002\u6b64\u6b21\u5206\u6790\u57fa\u4e8e\u4e00\u79cd\u66ff\u4ee3\u89c2\u70b9\uff0c\u5373\u5c06\u60c5\u611f\u7c7b\u522b\u89c6\u4e3a\u5177\u6709\u53ef\u53d8\u6027\u548c\u60c5\u5883\u5316\u7684\u5b9e\u4f8b\u4eba\u53e3\uff0c\u5e76\u9884\u6d4b\u5728\u540c\u4e00\u7c7b\u522b\u5185\u4e0d\u540c\u5b9e\u4f8b\u7684\u5927\u8111\u6a21\u5f0f\u4f1a\u5b58\u5728\u663e\u8457\u53d8\u5f02\u3002\u5206\u6790\u8fc7\u7a0b\u4e2d\u5bf9\u6570\u636e\u4e2d\u7684\u65b9\u5dee\u7ed3\u6784\u505a\u51fa\u4e86\u6700\u5c11\u7684\u5047\u8bbe\u3002", "result": "\u672a\u89c2\u5bdf\u5230\u539f\u59cb\u7814\u7a76\u62a5\u9053\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u800c\u662f\u53d1\u73b0\u4e86\u4e2a\u4f53\u95f4\u5927\u8111\u6a21\u5f0f\u7684\u663e\u8457\u53d8\u5f02\u3002\u8fd9\u8868\u660e\u57fa\u4e8e\u4e0d\u540c\u5047\u8bbe\u7684\u5206\u6790\u53ef\u4ee5\u5f97\u51fa\u4e0d\u540c\u7684\u7ed3\u8bba\u3002", "conclusion": "\u521d\u59cb\u5047\u8bbe\u53ef\u80fd\u663e\u8457\u5f71\u54cd\u79d1\u5b66\u7814\u7a76\u7684\u7ed3\u8bba\u3002\u56e0\u6b64\uff0c\u5728\u8ba4\u771f\u5bf9\u5f85\u67d0\u4e2a\u5047\u8bbe\u4e4b\u524d\uff0c\u5e94\u8be5\u4f7f\u7528\u591a\u79cd\u5206\u6790\u65b9\u6cd5\u5bf9\u5176\u8fdb\u884c\u9a8c\u8bc1\u3002"}}
{"id": "2507.00358", "pdf": "https://arxiv.org/pdf/2507.00358", "abs": "https://arxiv.org/abs/2507.00358", "authors": ["Yilie Huang", "Xun Yu Zhou"], "title": "Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": "36 pages, 10 figures", "summary": "We study reinforcement learning (RL) for the same class of continuous-time\nstochastic linear--quadratic (LQ) control problems as in\n\\cite{huang2024sublinear}, where volatilities depend on both states and\ncontrols while states are scalar-valued and running control rewards are absent.\nWe propose a model-free, data-driven exploration mechanism that adaptively\nadjusts entropy regularization by the critic and policy variance by the actor.\nUnlike the constant or deterministic exploration schedules employed in\n\\cite{huang2024sublinear}, which require extensive tuning for implementations\nand ignore learning progresses during iterations, our adaptive exploratory\napproach boosts learning efficiency with minimal tuning. Despite its\nflexibility, our method achieves a sublinear regret bound that matches the\nbest-known model-free results for this class of LQ problems, which were\npreviously derived only with fixed exploration schedules. Numerical experiments\ndemonstrate that adaptive explorations accelerate convergence and improve\nregret performance compared to the non-adaptive model-free and model-based\ncounterparts.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u7c7b\u4e0eHuang2024\u5b50\u7ebf\u6027\u8bba\u6587\u76f8\u540c\u7684\u8fde\u7eed\u65f6\u95f4\u968f\u673a\u7ebf\u6027-\u4e8c\u6b21\uff08LQ\uff09\u63a7\u5236\u95ee\u9898\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6a21\u578b\u3001\u6570\u636e\u9a71\u52a8\u7684\u63a2\u7d22\u673a\u5236\uff0c\u901a\u8fc7critic\u81ea\u9002\u5e94\u8c03\u6574\u71b5\u6b63\u5219\u5316\uff0c\u901a\u8fc7actor\u8c03\u6574\u7b56\u7565\u65b9\u5dee\u3002\u76f8\u6bd4\u4e4b\u524d\u9700\u8981\u5e7f\u6cdb\u8c03\u4f18\u4e14\u5ffd\u7565\u5b66\u4e60\u8fdb\u5ea6\u7684\u65b9\u6cd5\uff0c\u65b0\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u8c03\u4f18\u9700\u6c42\u3002\u5c3d\u7ba1\u65b9\u6cd5\u7075\u6d3b\uff0c\u4ecd\u8fbe\u5230\u4e86\u4e0e\u6700\u4f73\u5df2\u77e5\u6a21\u578b\u65e0\u5173\u7ed3\u679c\u76f8\u5339\u914d\u7684\u5b50\u7ebf\u6027\u540e\u6094\u754c\uff0c\u8fd9\u5728\u4ee5\u524d\u4ec5\u901a\u8fc7\u56fa\u5b9a\u63a2\u7d22\u8ba1\u5212\u5f97\u51fa\u3002\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u81ea\u9002\u5e94\u63a2\u7d22\u52a0\u901f\u4e86\u6536\u655b\uff0c\u5e76\u6539\u5584\u4e86\u76f8\u5bf9\u4e8e\u975e\u81ea\u9002\u5e94\u6a21\u578b\u65e0\u5173\u548c\u57fa\u4e8e\u6a21\u578b\u65b9\u6cd5\u7684\u540e\u6094\u8868\u73b0\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u968f\u673a\u7ebf\u6027-\u4e8c\u6b21\uff08LQ\uff09\u63a7\u5236\u95ee\u9898\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u6311\u6218\uff0c\u7279\u522b\u662f\u5f53\u6ce2\u52a8\u4f9d\u8d56\u4e8e\u72b6\u6001\u548c\u63a7\u5236\u800c\u72b6\u6001\u662f\u6807\u91cf\u503c\u4e14\u6ca1\u6709\u8fd0\u884c\u63a7\u5236\u5956\u52b1\u65f6\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u6a21\u578b\u3001\u6570\u636e\u9a71\u52a8\u7684\u63a2\u7d22\u673a\u5236\uff0c\u4ee5\u51cf\u5c11\u5bf9\u4eba\u5de5\u8c03\u4f18\u7684\u4f9d\u8d56\u5e76\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6a21\u578b\u3001\u6570\u636e\u9a71\u52a8\u7684\u63a2\u7d22\u673a\u5236\uff0c\u8be5\u673a\u5236\u901a\u8fc7critic\u81ea\u9002\u5e94\u8c03\u6574\u71b5\u6b63\u5219\u5316\uff0c\u901a\u8fc7actor\u8c03\u6574\u7b56\u7565\u65b9\u5dee\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u540c\u4e8e\u4e4b\u524d\u4f7f\u7528\u56fa\u5b9a\u6216\u786e\u5b9a\u6027\u63a2\u7d22\u8ba1\u5212\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u5b66\u4e60\u8fdb\u5ea6\u81ea\u52a8\u8c03\u6574\uff0c\u4ece\u800c\u51cf\u5c11\u8c03\u4f18\u9700\u6c42\u5e76\u63d0\u9ad8\u7075\u6d3b\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u7075\u6d3b\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6700\u4f73\u5df2\u77e5\u6a21\u578b\u65e0\u5173\u7ed3\u679c\u76f8\u5339\u914d\u7684\u5b50\u7ebf\u6027\u540e\u6094\u754c\u3002\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0c\u81ea\u9002\u5e94\u63a2\u7d22\u52a0\u901f\u4e86\u7b97\u6cd5\u6536\u655b\uff0c\u5e76\u6539\u5584\u4e86\u540e\u6094\u6027\u80fd\uff0c\u4f18\u4e8e\u975e\u81ea\u9002\u5e94\u7684\u6a21\u578b\u65e0\u5173\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u79cd\u81ea\u9002\u5e94\u63a2\u7d22\u673a\u5236\u4e0d\u4ec5\u51cf\u5c11\u4e86\u4eba\u5de5\u8c03\u4f18\u7684\u9700\u6c42\uff0c\u8fd8\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u8fbe\u5230\u4e86\u4e0e\u6700\u4f73\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u76f8\u540c\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u540e\u6094\u6027\u80fd\u3002"}}
{"id": "2507.00390", "pdf": "https://arxiv.org/pdf/2507.00390", "abs": "https://arxiv.org/abs/2507.00390", "authors": ["Geng Zhang", "Yuxuan Han", "Yuxuan Lou", "Wangbo Zhao", "Yiqi Zhang", "Yang You"], "title": "MoNE: Replacing Redundant Experts with Lightweight Novices for Structured Pruning of MoE", "categories": ["cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\nby activating only a subset of experts per input token. However, deploying\nMoE-based models incurs significant memory overhead due to the need to retain\nall experts in memory. While structured pruning is promising to reduce memory\ncosts, existing methods often show suboptimal performance and unstable\ndegradation in three dimensions: model architectures, calibration data sources,\nand calibration sample sizes. This paper proposes\nMixture-of-Novices-and-Experts (MoNE), a novel expert pruning method that\nreplaces redundant experts with lightweight novices to achieve effective and\nrobust model compression. MoNE evaluates expert redundancy based on two\nmetrics: access frequency and output variance. Experts exhibiting low usage and\nstable outputs are pruned and replaced with lightweight novices-unbiased\nestimations of their original outputs-minimizing performance degradation.\nExtensive experiments demonstrate that MoNE consistently outperforms baseline\nmethods with minimal accuracy degradation across the three dimensions,\nconfirming its effectiveness and robustness. Notably, it improves the average\nzero shot accuracy across nine downstream tasks by up to 2.71 under 25\\%\npruning ratio and 3.61 under 50\\% pruning. The code is available at\nhttps://github.com/zxgx/mode-pd.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e13\u5bb6\u526a\u679d\u65b9\u6cd5Mixture-of-Novices-and-Experts (MoNE)\uff0c\u901a\u8fc7\u7528\u8f7b\u91cf\u7ea7\u7684novices\u66ff\u6362\u5197\u4f59\u7684experts\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u6a21\u578b\u538b\u7f29\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMoNE\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u572825%\u548c50%\u7684\u526a\u679d\u7387\u4e0b\u5206\u522b\u63d0\u9ad8\u4e86\u5e73\u5747\u96f6\u6837\u672c\u51c6\u786e\u73872.71\u548c3.61\u3002", "motivation": "\u73b0\u6709\u7684MoE\u6a21\u578b\u5728\u90e8\u7f72\u65f6\u9700\u8981\u4fdd\u7559\u6240\u6709expert\uff0c\u5bfc\u81f4\u5185\u5b58\u5f00\u9500\u5927\u3002\u5c3d\u7ba1\u7ed3\u6784\u5316\u526a\u679d\u53ef\u4ee5\u964d\u4f4e\u5185\u5b58\u6210\u672c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u67b6\u6784\u3001\u6821\u51c6\u6570\u636e\u6e90\u548c\u6821\u51c6\u6837\u672c\u5927\u5c0f\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u6027\u80fd\u4e0b\u964d\u4e0d\u7a33\u5b9a\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u548c\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMixture-of-Novices-and-Experts (MoNE)\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8bbf\u95ee\u9891\u7387\u548c\u8f93\u51fa\u65b9\u5dee\u4e24\u4e2a\u6307\u6807\u8bc4\u4f30expert\u7684\u5197\u4f59\u6027\uff0c\u5c06\u4f4e\u4f7f\u7528\u7387\u548c\u7a33\u5b9a\u8f93\u51fa\u7684expert\u526a\u679d\uff0c\u5e76\u7528\u8f7b\u91cf\u7ea7\u7684novices\u4ee3\u66ff\uff0c\u4ee5\u6700\u5c0f\u5316\u6027\u80fd\u4e0b\u964d\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMoNE\u5728\u4e09\u4e2a\u7ef4\u5ea6\uff08\u6a21\u578b\u67b6\u6784\u3001\u6821\u51c6\u6570\u636e\u6e90\u548c\u6821\u51c6\u6837\u672c\u5927\u5c0f\uff09\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u572825%\u526a\u679d\u7387\u4e0b\u63d0\u9ad8\u4e5d\u4e2a\u4e0b\u6e38\u4efb\u52a1\u7684\u5e73\u5747\u96f6\u6837\u672c\u51c6\u786e\u73872.71\uff0c\u572850%\u526a\u679d\u7387\u4e0b\u63d0\u9ad83.61\u3002", "conclusion": "Mixture-of-Novices-and-Experts (MoNE)\u662f\u4e00\u79cd\u6709\u6548\u7684\u4e13\u5bb6\u526a\u679d\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7528novices\u66ff\u4ee3\u5197\u4f59experts\u6765\u5b9e\u73b0\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u6a21\u578b\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.00394", "pdf": "https://arxiv.org/pdf/2507.00394", "abs": "https://arxiv.org/abs/2507.00394", "authors": ["Geng Zhang", "Shenggan Cheng", "Xuanlei Zhao", "Ziming Liu", "Yang You"], "title": "HelixPipe: Efficient Distributed Training of Long Sequence Transformers with Attention Parallel Pipeline Parallelism", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As transformer sequence lengths grow, existing pipeline parallelisms incur\nsuboptimal performance due to the quadratic attention computation and the\nsubstantial memory overhead. To relieve these challenges, we propose HelixPipe,\na novel pipeline parallelism for long sequence transformer training. First,\nHelixPipe introduces attention parallel partition, which schedules attention\ncomputations of different micro batches across different pipeline stages in\nparallel, reducing pipeline bubbles. Second, it employs a two-fold\nfirst-in-last-out micro batch schedule to balance memory usage and overlap\ncommunication with computation. Additionally, HelixPipe utilizes recomputation\nwithout attention and chunked MLP to mitigate fragmentation and enable longer\nsequences. Experiments demonstrate that HelixPipe gains increasing advantages\nwith longer sequence lengths, and outperforms existing methods in throughput\nand scalability across varying pipeline sizes, model sizes, and cluster\nconfigurations. Notably, it achieves a 26\\% speedup over baseline methods when\ntraining a 7B model with 128k sequence length on 64 H20 GPUs. Code is available\nat https://github.com/code-tunnel/Megatron-LM/tree/dev.", "AI": {"tldr": "\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u73b0\u6709\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\u7531\u4e8e\u4e8c\u6b21\u6ce8\u610f\u529b\u8ba1\u7b97\u548c\u5de8\u5927\u7684\u5185\u5b58\u5f00\u9500\u800c\u6027\u80fd\u4e0b\u964d\u3002HelixPipe\u901a\u8fc7\u5f15\u5165\u6ce8\u610f\u529b\u5e76\u884c\u5206\u533a\u3001\u4e24\u5c42\u5148\u8fdb\u540e\u51fa\u5fae\u6279\u6b21\u8c03\u5ea6\u4ee5\u53ca\u65e0\u6ce8\u610f\u529b\u91cd\u8ba1\u7b97\u548c\u5206\u5757MLP\u7b49\u6280\u672f\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u548c\u96c6\u7fa4\u914d\u7f6e\u4e0b\uff0cHelixPipe\u5728\u541e\u5410\u91cf\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u8bad\u7ec37B\u6a21\u578b\uff08\u5e8f\u5217\u957f\u5ea6128k\uff09\u65f6\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5feb26%\u3002", "motivation": "\u73b0\u6709\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\uff0c\u7531\u4e8e\u4e8c\u6b21\u6ce8\u610f\u529b\u8ba1\u7b97\u548c\u5de8\u5927\u7684\u5185\u5b58\u5f00\u9500\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u957f\u5e8f\u5217Transformer\u8bad\u7ec3\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHelixPipe\u7684\u65b0\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u70b9\uff1a1) \u6ce8\u610f\u529b\u5e76\u884c\u5206\u533a\uff0c\u51cf\u5c11\u7ba1\u9053\u6c14\u6ce1\uff1b2) \u4e24\u5c42\u5148\u8fdb\u540e\u51fa\u5fae\u6279\u6b21\u8c03\u5ea6\uff0c\u5e73\u8861\u5185\u5b58\u4f7f\u7528\u5e76\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\uff1b3) \u65e0\u6ce8\u610f\u529b\u91cd\u8ba1\u7b97\u548c\u5206\u5757MLP\uff0c\u7f13\u89e3\u788e\u7247\u5316\u5e76\u652f\u6301\u66f4\u957f\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHelixPipe\u5728\u957f\u5e8f\u5217\u957f\u5ea6\u4e0a\u5177\u6709\u8d8a\u6765\u8d8a\u660e\u663e\u7684\u4f18\u52bf\uff0c\u5728\u4e0d\u540c\u6d41\u6c34\u7ebf\u89c4\u6a21\u3001\u6a21\u578b\u5927\u5c0f\u548c\u96c6\u7fa4\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u8272\u3002\u7279\u522b\u662f\u5728\u4f7f\u752864\u4e2aH20 GPU\u8bad\u7ec37B\u6a21\u578b\uff08\u5e8f\u5217\u957f\u5ea6128k\uff09\u65f6\uff0c\u901f\u5ea6\u63d0\u9ad8\u4e8626%\u3002", "conclusion": "HelixPipe\u662f\u4e00\u79cd\u6709\u6548\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u957f\u5e8f\u5217Transformer\u8bad\u7ec3\u7684\u6027\u80fd\uff0c\u5728\u541e\u5410\u91cf\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.00411", "pdf": "https://arxiv.org/pdf/2507.00411", "abs": "https://arxiv.org/abs/2507.00411", "authors": ["Jinfu Fan", "Xiaohui Zhong", "Kangrui Ren", "Jiangnan Li", "Linqing Huang"], "title": "Diffusion Disambiguation Models for Partial Label Learning", "categories": ["cs.LG"], "comment": null, "summary": "Learning from ambiguous labels is a long-standing problem in practical\nmachine learning applications. The purpose of \\emph{partial label learning}\n(PLL) is to identify the ground-truth label from a set of candidate labels\nassociated with a given instance. Inspired by the remarkable performance of\ndiffusion models in various generation tasks, this paper explores their\npotential to denoise ambiguous labels through the reverse denoising process.\nTherefore, this paper reformulates the label disambiguation problem from the\nperspective of generative models, where labels are generated by iteratively\nrefining initial random guesses. This perspective enables the diffusion model\nto learn how label information is generated stochastically. By modeling the\ngeneration uncertainty, we can use the maximum likelihood estimate of the label\nfor classification inference. However, such ambiguous labels lead to a mismatch\nbetween instance and label, which reduces the quality of generated data. To\naddress this issue, this paper proposes a \\emph{diffusion disambiguation model\nfor PLL} (DDMP), which first uses the potential complementary information\nbetween instances and labels to construct pseudo-clean labels for initial\ndiffusion training. Furthermore, a transition-aware matrix is introduced to\nestimate the potential ground-truth labels, which are dynamically updated\nduring the diffusion generation. During training, the ground-truth label is\nprogressively refined, improving the classifier. Experiments show the advantage\nof the DDMP and its suitability for PLL.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\uff08PLL\uff09\u7684\u6269\u6563\u53bb\u6a21\u7cca\u6a21\u578b\uff08DDMP\uff09\uff0c\u901a\u8fc7\u5229\u7528\u5b9e\u4f8b\u548c\u6807\u7b7e\u4e4b\u95f4\u7684\u6f5c\u5728\u4e92\u8865\u4fe1\u606f\u6784\u5efa\u4f2a\u5e72\u51c0\u6807\u7b7e\uff0c\u5e76\u5f15\u5165\u8f6c\u6362\u611f\u77e5\u77e9\u9635\u52a8\u6001\u66f4\u65b0\u6f5c\u5728\u771f\u5b9e\u6807\u7b7e\uff0c\u4ece\u800c\u63d0\u9ad8\u5206\u7c7b\u5668\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660eDDMP\u5728PLL\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\uff08PLL\uff09\u65e8\u5728\u4ece\u4e00\u7ec4\u5019\u9009\u6807\u7b7e\u4e2d\u8bc6\u522b\u51fa\u771f\u5b9e\u6807\u7b7e\uff0c\u4f46\u7531\u4e8e\u6a21\u7cca\u6807\u7b7e\u5bfc\u81f4\u5b9e\u4f8b\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\uff0c\u964d\u4f4e\u4e86\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u4ece\u751f\u6210\u6a21\u578b\u7684\u89d2\u5ea6\u91cd\u65b0\u5b9a\u4e49\u6807\u7b7e\u53bb\u6a21\u7cca\u95ee\u9898\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u521d\u59cb\u968f\u673a\u731c\u6d4b\u751f\u6210\u6807\u7b7e\u3002\n2. \u63d0\u51fa\u6269\u6563\u53bb\u6a21\u7cca\u6a21\u578b\uff08DDMP\uff09\uff0c\u5229\u7528\u5b9e\u4f8b\u548c\u6807\u7b7e\u95f4\u7684\u6f5c\u5728\u4e92\u8865\u4fe1\u606f\u6784\u5efa\u4f2a\u5e72\u51c0\u6807\u7b7e\u8fdb\u884c\u521d\u59cb\u6269\u6563\u8bad\u7ec3\u3002\n3. \u5f15\u5165\u8f6c\u6362\u611f\u77e5\u77e9\u9635\u4f30\u8ba1\u6f5c\u5728\u771f\u5b9e\u6807\u7b7e\uff0c\u5e76\u5728\u6269\u6563\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u66f4\u65b0\u3002\n4. \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u4f18\u5316\u771f\u5b9e\u6807\u7b7e\u4ee5\u6539\u8fdb\u5206\u7c7b\u5668\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684DDMP\u6a21\u578b\u5728\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u4efb\u52a1\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u4e14\u9002\u5408\u5904\u7406PLL\u95ee\u9898\u3002", "conclusion": "\u6269\u6563\u53bb\u6a21\u7cca\u6a21\u578b\uff08DDMP\uff09\u80fd\u591f\u6709\u6548\u89e3\u51b3\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u4e2d\u7684\u6807\u7b7e\u6a21\u7cca\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u5668\u7684\u6027\u80fd\uff0c\u4e3aPLL\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.00425", "pdf": "https://arxiv.org/pdf/2507.00425", "abs": "https://arxiv.org/abs/2507.00425", "authors": ["Ruixiang Zhang", "Shuangfei Zhai", "Jiatao Gu", "Yizhe Zhang", "Huangjie Zheng", "Tianrong Chen", "Miguel Angel Bautista", "Josh Susskind", "Navdeep Jaitly"], "title": "Flexible Language Modeling in Continuous Space with Transformer-based Autoregressive Flows", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Autoregressive models have driven remarkable progress in language modeling.\nTheir foundational reliance on discrete tokens, unidirectional context, and\nsingle-pass decoding, while central to their success, also inspires the\nexploration of a design space that could offer new axes of modeling\nflexibility. In this work, we explore an alternative paradigm, shifting\nlanguage modeling from a discrete token space to a continuous latent space. We\npropose a novel framework TarFlowLM, that employs transformer-based\nautoregressive normalizing flows to model these continuous representations.\nThis approach unlocks substantial flexibility, enabling the construction of\nmodels that can capture global bi-directional context through stacked,\nalternating-direction autoregressive transformations, support block-wise\ngeneration with flexible token patch sizes, and facilitate a hierarchical\nmulti-pass generation process. We further propose new mixture-based coupling\ntransformations designed to capture complex dependencies within the latent\nspace shaped by discrete data, and demonstrate theoretical connections to\nconventional discrete autoregressive models. Extensive experiments on language\nmodeling benchmarks demonstrate strong likelihood performance and highlight the\nflexible modeling capabilities inherent in our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6TarFlowLM\uff0c\u5c06\u8bed\u8a00\u5efa\u6a21\u4ece\u79bb\u6563\u7684\u6807\u8bb0\u7a7a\u95f4\u8f6c\u79fb\u5230\u8fde\u7eed\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u5f52\u4e00\u5316\u6d41\u6765\u5efa\u6a21\u8fd9\u4e9b\u8fde\u7eed\u8868\u793a\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5bf9\u79bb\u6563\u6807\u8bb0\u3001\u5355\u5411\u4e0a\u4e0b\u6587\u548c\u5355\u6b21\u89e3\u7801\u7684\u6838\u5fc3\u4f9d\u8d56\u4e5f\u6fc0\u53d1\u4e86\u63a2\u7d22\u65b0\u7684\u8bbe\u8ba1\u7a7a\u95f4\u7684\u9700\u6c42\uff0c\u4ee5\u63d0\u4f9b\u65b0\u7684\u5efa\u6a21\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u4e86TarFlowLM\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u5f52\u4e00\u5316\u6d41\u6765\u5efa\u6a21\u8fde\u7eed\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6355\u6349\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u3001\u652f\u6301\u7075\u6d3b\u6807\u8bb0\u5757\u5927\u5c0f\u7684\u5757\u751f\u6210\uff0c\u5e76\u4fc3\u8fdb\u5206\u5c42\u591a\u904d\u751f\u6210\u8fc7\u7a0b\u3002\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df7\u5408\u7684\u65b0\u8026\u5408\u53d8\u6362\uff0c\u4ee5\u6355\u6349\u7531\u79bb\u6563\u6570\u636e\u5851\u9020\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u4e0a\u5177\u6709\u5f3a\u5927\u7684\u4f3c\u7136\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u6846\u67b6\u56fa\u6709\u7684\u7075\u6d3b\u5efa\u6a21\u80fd\u529b\u3002", "conclusion": "TarFlowLM\u4e3a\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u548c\u590d\u6742\u7684\u4f9d\u8d56\u5173\u7cfb\u6355\u6349\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2507.00440", "pdf": "https://arxiv.org/pdf/2507.00440", "abs": "https://arxiv.org/abs/2507.00440", "authors": ["Yujia Yin", "Tianyi Qu", "Zihao Wang", "Yifan Chen"], "title": "A Recipe for Causal Graph Regression: Confounding Effects Revisited", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": "ICML 2025 accepted", "summary": "Through recognizing causal subgraphs, causal graph learning (CGL) has risen\nto be a promising approach for improving the generalizability of graph neural\nnetworks under out-of-distribution (OOD) scenarios. However, the empirical\nsuccesses of CGL techniques are mostly exemplified in classification settings,\nwhile regression tasks, a more challenging setting in graph learning, are\noverlooked. We thus devote this work to tackling causal graph regression (CGR);\nto this end we reshape the processing of confounding effects in existing CGL\nstudies, which mainly deal with classification. Specifically, we reflect on the\npredictive power of confounders in graph-level regression, and generalize\nclassification-specific causal intervention techniques to regression through a\nlens of contrastive learning. Extensive experiments on graph OOD benchmarks\nvalidate the efficacy of our proposals for CGR. The model implementation and\nthe code are provided on https://github.com/causal-graph/CGR.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06\u56e0\u679c\u56fe\u5b66\u4e60\uff08CGL\uff09\u6280\u672f\u4ece\u5206\u7c7b\u4efb\u52a1\u6269\u5c55\u5230\u56de\u5f52\u4efb\u52a1\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f5c\u8005\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u7684\u89c6\u89d2\uff0c\u91cd\u65b0\u8bbe\u8ba1\u4e86\u5904\u7406\u6df7\u6dc6\u6548\u5e94\u7684\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u56fe\u5916\u5206\u5e03\uff08OOD\uff09\u57fa\u51c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u56e0\u679c\u56fe\u5b66\u4e60\uff08CGL\uff09\u6280\u672f\u4e3b\u8981\u5e94\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22CGL\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u56fe\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f5c\u8005\u53cd\u601d\u4e86\u56fe\u7ea7\u56de\u5f52\u4e2d\u6df7\u6dc6\u53d8\u91cf\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b9\u5f0f\uff0c\u5c06\u539f\u672c\u9488\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u56e0\u679c\u5e72\u9884\u6280\u672f\u63a8\u5e7f\u5230\u56de\u5f52\u4efb\u52a1\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u56fe\u5916\u5206\u5e03\uff08OOD\uff09\u57fa\u51c6\u4e0a\u5bf9\u56e0\u679c\u56fe\u56de\u5f52\uff08CGR\uff09\u5177\u6709\u826f\u597d\u7684\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u56e0\u679c\u56fe\u56de\u5f52\u65b9\u6cd5\u6210\u529f\u5730\u6269\u5c55\u4e86\u56e0\u679c\u56fe\u5b66\u4e60\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u5904\u7406\u56fe\u56de\u5f52\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u601d\u8def\u3002"}}
{"id": "2507.00445", "pdf": "https://arxiv.org/pdf/2507.00445", "abs": "https://arxiv.org/abs/2507.00445", "authors": ["Xingyu Su", "Xiner Li", "Masatoshi Uehara", "Sunwoo Kim", "Yulai Zhao", "Gabriele Scalia", "Ehsan Hajiramezanali", "Tommaso Biancalani", "Degui Zhi", "Shuiwang Ji"], "title": "Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "We address the problem of fine-tuning diffusion models for reward-guided\ngeneration in biomolecular design. While diffusion models have proven highly\neffective in modeling complex, high-dimensional data distributions, real-world\napplications often demand more than high-fidelity generation, requiring\noptimization with respect to potentially non-differentiable reward functions\nsuch as physics-based simulation or rewards based on scientific knowledge.\nAlthough RL methods have been explored to fine-tune diffusion models for such\nobjectives, they often suffer from instability, low sample efficiency, and mode\ncollapse due to their on-policy nature. In this work, we propose an iterative\ndistillation-based fine-tuning framework that enables diffusion models to\noptimize for arbitrary reward functions. Our method casts the problem as policy\ndistillation: it collects off-policy data during the roll-in phase, simulates\nreward-based soft-optimal policies during roll-out, and updates the model by\nminimizing the KL divergence between the simulated soft-optimal policy and the\ncurrent model policy. Our off-policy formulation, combined with KL divergence\nminimization, enhances training stability and sample efficiency compared to\nexisting RL-based methods. Empirical results demonstrate the effectiveness and\nsuperior reward optimization of our approach across diverse tasks in protein,\nsmall molecule, and regulatory DNA design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u84b8\u998f\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u6269\u6563\u6a21\u578b\u4ee5\u9002\u5e94\u4efb\u610f\u5956\u52b1\u51fd\u6570\u3002\u901a\u8fc7\u6536\u96c6\u79bb\u7b56\u7565\u6570\u636e\u3001\u6a21\u62df\u57fa\u4e8e\u5956\u52b1\u7684\u8f6f\u6700\u4f18\u7b56\u7565\u4ee5\u53ca\u6700\u5c0f\u5316KL\u6563\u5ea6\u6765\u66f4\u65b0\u6a21\u578b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u5e76\u5728\u86cb\u767d\u8d28\u3001\u5c0f\u5206\u5b50\u548c\u8c03\u63a7DNA\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u64c5\u957f\u751f\u6210\u590d\u6742\u9ad8\u7ef4\u6570\u636e\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u4f18\u5316\u975e\u53ef\u5fae\u5206\u7684\u5956\u52b1\u51fd\u6570\uff08\u5982\u57fa\u4e8e\u7269\u7406\u7684\u6a21\u62df\u6216\u79d1\u5b66\u77e5\u8bc6\uff09\uff0c\u8fd9\u4f7f\u5f97\u4f20\u7edf\u7684RL\u65b9\u6cd5\u56e0\u4e0d\u7a33\u5b9a\u3001\u91c7\u6837\u6548\u7387\u4f4e\u548c\u6a21\u5f0f\u5d29\u6e83\u800c\u96be\u4ee5\u80dc\u4efb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u84b8\u998f\u5fae\u8c03\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u89c6\u4e3a\u7b56\u7565\u84b8\u998f\uff1a\u5728roll-in\u9636\u6bb5\u6536\u96c6\u79bb\u7b56\u7565\u6570\u636e\uff0c\u5728roll-out\u9636\u6bb5\u6a21\u62df\u57fa\u4e8e\u5956\u52b1\u7684\u8f6f\u6700\u4f18\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5316\u5f53\u524d\u6a21\u578b\u7b56\u7565\u4e0e\u6a21\u62df\u8f6f\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684KL\u6563\u5ea6\u6765\u66f4\u65b0\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u86cb\u767d\u8d28\u3001\u5c0f\u5206\u5b50\u548c\u8c03\u63a7DNA\u8bbe\u8ba1\u7b49\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5956\u52b1\u4f18\u5316\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fed\u4ee3\u84b8\u998f\u5fae\u8c03\u6846\u67b6\u80fd\u591f\u6709\u6548\u4f18\u5316\u6269\u6563\u6a21\u578b\u4ee5\u9002\u5e94\u4efb\u610f\u5956\u52b1\u51fd\u6570\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u57fa\u4e8eRL\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u53ca\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2507.00449", "pdf": "https://arxiv.org/pdf/2507.00449", "abs": "https://arxiv.org/abs/2507.00449", "authors": ["Zhihao Zhan", "Jianan Zhao", "Zhaocheng Zhu", "Jian Tang"], "title": "Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention", "categories": ["cs.LG", "cs.CL", "I.2.7"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18\n  pages, 9 figures", "summary": "Efficient long-context modeling remains a critical challenge for natural\nlanguage processing (NLP), as the time complexity of the predominant\nTransformer architecture scales quadratically with the sequence length. While\nstate-space models (SSMs) offer alternative sub-quadratic solutions, they\nstruggle to capture long-range dependencies effectively. In this work, we focus\non analyzing and improving the long-context modeling capabilities of SSMs. We\nshow that the widely used synthetic task, associative recall, which requires a\nmodel to recall a value associated with a single key without context,\ninsufficiently represents the complexities of real-world long-context modeling.\nTo address this limitation, we extend the associative recall to a novel\nsynthetic task, \\emph{joint recall}, which requires a model to recall the value\nassociated with a key given in a specified context. Theoretically, we prove\nthat SSMs do not have the expressiveness to solve multi-query joint recall in\nsub-quadratic time complexity. To resolve this issue, we propose a solution\nbased on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which\nhas the expressiveness to solve multi-query joint recall with sub-quadratic\ncomputation. To bridge the gap between theoretical analysis and real-world\napplications, we propose locality-sensitive Hashing Attention with sparse Key\nSelection (HAX), which instantiates the theoretical solution and is further\ntailored to natural language domains. Extensive experiments on both synthetic\nand real-world long-context benchmarks show that HAX consistently outperforms\nSSM baselines and SSMs integrated with context-independent sparse attention\n(CISA).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u5728\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u4e0a\u4e0b\u6587\u76f8\u5173\u7a00\u758f\u6ce8\u610f\u529b\uff08CDSA\uff09\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5177\u4f53\u5b9e\u73b0\u65b9\u6848\u54c8\u5e0c\u6ce8\u610f\u4e0e\u7a00\u758f\u952e\u9009\u62e9\uff08HAX\uff09\u3002\u5b9e\u9a8c\u8868\u660eHAX\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u63d0\u4f9b\u4e86\u4f4e\u4e8e\u4e8c\u6b21\u65b9\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b83\u4eec\u5728\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7684\u5173\u8054\u56de\u5fc6\u4efb\u52a1\u4e0d\u8db3\u4ee5\u4ee3\u8868\u73b0\u5b9e\u4e16\u754c\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u7684\u590d\u6742\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u548c\u4efb\u52a1\u6765\u66f4\u597d\u5730\u8bc4\u4f30\u548c\u63d0\u5347SSMs\u7684\u6027\u80fd\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5408\u6210\u4efb\u52a1\u2014\u2014\u8054\u5408\u56de\u5fc6\uff08joint recall\uff09\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u7684\u957f\u4e0a\u4e0b\u6587\u9700\u6c42\u3002\n2. \u7406\u8bba\u4e0a\u8bc1\u660e\u4e86SSMs\u65e0\u6cd5\u5728\u4e9a\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u5185\u89e3\u51b3\u591a\u67e5\u8be2\u8054\u5408\u56de\u5fc6\u95ee\u9898\u3002\n3. \u63d0\u51fa\u4e86\u57fa\u4e8e\u96c6\u6210SSMs\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7a00\u758f\u6ce8\u610f\u529b\uff08CDSA\uff09\u7684\u89e3\u51b3\u65b9\u6848\u3002\n4. \u5f00\u53d1\u4e86\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u6ce8\u610f\u4e0e\u7a00\u758f\u952e\u9009\u62e9\uff08HAX\uff09\uff0c\u4f5c\u4e3a\u7406\u8bba\u65b9\u6848\u7684\u5b9e\u9645\u5b9e\u73b0\uff0c\u5e76\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u9886\u57df\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cHAX\u7684\u8868\u73b0\u59cb\u7ec8\u4f18\u4e8eSSM\u57fa\u7ebf\u548cSSM\u4e0e\u4e0a\u4e0b\u6587\u65e0\u5173\u7a00\u758f\u6ce8\u610f\u529b\uff08CISA\uff09\u7ed3\u5408\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u8054\u5408\u56de\u5fc6\u4efb\u52a1\u3001\u7406\u8bba\u5206\u6790\u4ee5\u53caHAX\u7684\u5b9e\u9645\u5b9e\u73b0\uff0c\u672c\u7814\u7a76\u6709\u6548\u5730\u63d0\u5347\u4e86SSMs\u5728\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u4e2d\u7684\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.00453", "pdf": "https://arxiv.org/pdf/2507.00453", "abs": "https://arxiv.org/abs/2507.00453", "authors": ["Ankit Kashyap"], "title": "Recurrent Memory-Augmented Transformers with Chunked Attention for Long-Context Language Modeling", "categories": ["cs.LG", "F.2.2; I.2.6; I.2.7"], "comment": "19 pages, 9 figures, 1 table; implemented entirely from scratch in\n  PyTorch", "summary": "We present a Transformer architecture for long-context language modeling that\ncombines global attention with two biologically inspired components: chunked\nlocal attention and a gated FIFO memory mechanism. This unified attention block\nallows the model to efficiently handle both short-range and long-range\ndependencies without increasing attention cost quadratically. The memory module\npersistently stores past token representations using a gated update mechanism\ninspired by recurrent networks. Rotary positional encoding is applied per\nattention head to enable directionally disentangled, scale-invariant positional\nsignals. The architecture is implemented entirely from scratch in PyTorch, with\nno reliance on high-level libraries, enabling transparent and modular\nexperimentation. Our model offers a lightweight and extensible design for tasks\nsuch as dialogue modeling, code completion, and document understanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5168\u5c40\u6ce8\u610f\u529b\u3001\u5206\u5757\u5c40\u90e8\u6ce8\u610f\u529b\u548c\u95e8\u63a7FIFO\u5b58\u50a8\u673a\u5236\u7684Transformer\u67b6\u6784\uff0c\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u5b9e\u73b0\u65b9\u5411\u89e3\u8026\u548c\u5c3a\u5ea6\u4e0d\u53d8\u7684\u4f4d\u7f6e\u4fe1\u53f7\uff0c\u5e76\u5728PyTorch\u4e2d\u5b8c\u5168\u4ece\u96f6\u5f00\u59cb\u5b9e\u73b0\uff0c\u9002\u7528\u4e8e\u5bf9\u8bdd\u5efa\u6a21\u3001\u4ee3\u7801\u8865\u5168\u548c\u6587\u6863\u7406\u89e3\u7b49\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u7684Transformer\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u6709\u6548\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5c06\u5168\u5c40\u6ce8\u610f\u529b\u4e0e\u5206\u5757\u5c40\u90e8\u6ce8\u610f\u529b\u548c\u95e8\u63a7FIFO\u5b58\u50a8\u673a\u5236\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff1b\u4f7f\u7528\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u4e3a\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u63d0\u4f9b\u65b9\u5411\u89e3\u8026\u4e14\u5c3a\u5ea6\u4e0d\u53d8\u7684\u4f4d\u7f6e\u4fe1\u53f7\uff1b\u6574\u4e2a\u67b6\u6784\u57fa\u4e8ePyTorch\u4ece\u96f6\u5f00\u59cb\u5b9e\u73b0\uff0c\u65e0\u9700\u9ad8\u7ea7\u5e93\u652f\u6301\u3002", "result": "\u6b64\u67b6\u6784\u80fd\u591f\u9ad8\u6548\u5904\u7406\u77ed\u8ddd\u79bb\u548c\u957f\u8ddd\u79bb\u4f9d\u8d56\uff0c\u800c\u4e0d\u4f1a\u4f7f\u6ce8\u610f\u529b\u6210\u672c\u5448\u4e8c\u6b21\u589e\u957f\uff1b\u540c\u65f6\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u548c\u53ef\u6269\u5c55\u7684\u8bbe\u8ba1\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Transformer\u67b6\u6784\u4e3a\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u900f\u660e\u6027\u548c\u6a21\u5757\u5316\u7684\u7279\u70b9\uff0c\u9002\u5408\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2507.00467", "pdf": "https://arxiv.org/pdf/2507.00467", "abs": "https://arxiv.org/abs/2507.00467", "authors": ["Sijan Bhattarai", "Saurav Bhandari", "Girija Bhusal", "Saroj Shakya", "Tapendra Pandey"], "title": "Diversity Conscious Refined Random Forest", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Random Forest (RF) is a widely used ensemble learning technique known for its\nrobust classification performance across diverse domains. However, it often\nrelies on hundreds of trees and all input features, leading to high inference\ncost and model redundancy. In this work, our goal is to grow trees dynamically\nonly on informative features and then enforce maximal diversity by clustering\nand retaining uncorrelated trees. Therefore, we propose a Refined Random Forest\nClassifier that iteratively refines itself by first removing the least\ninformative features and then analytically determines how many new trees should\nbe grown, followed by correlation-based clustering to remove redundant trees.\nThe classification accuracy of our model was compared against the standard RF\non the same number of trees. Experiments on 8 multiple benchmark datasets,\nincluding binary and multiclass datasets, demonstrate that the proposed model\nachieves improved accuracy compared to standard RF.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u70bc\u7684\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u957f\u6811\u3001\u53bb\u9664\u4e0d\u91cd\u8981\u7684\u7279\u5f81\u4ee5\u53ca\u5229\u7528\u76f8\u5173\u6027\u805a\u7c7b\u6d88\u9664\u5197\u4f59\u6811\u6765\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u76f8\u540c\u6570\u91cf\u7684\u6811\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6bd4\u6807\u51c6\u968f\u673a\u68ee\u6797\u5177\u6709\u66f4\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u673a\u68ee\u6797\u867d\u7136\u5e7f\u6cdb\u4f7f\u7528\u4e14\u5206\u7c7b\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u4f9d\u8d56\u4e8e\u5927\u91cf\u7684\u6811\u548c\u6240\u6709\u8f93\u5165\u7279\u5f81\uff0c\u5bfc\u81f4\u63a8\u7406\u6210\u672c\u9ad8\u548c\u6a21\u578b\u5197\u4f59\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u968f\u673a\u68ee\u6797\u6a21\u578b\u3002", "method": "1. \u52a8\u6001\u5730\u4ec5\u5728\u4fe1\u606f\u7279\u5f81\u4e0a\u751f\u957f\u6811\u3002\n2. \u901a\u8fc7\u805a\u7c7b\u4fdd\u7559\u4e0d\u76f8\u5173\u7684\u6811\u4ee5\u5b9e\u73b0\u6700\u5927\u591a\u6837\u6027\u3002\n3. \u63d0\u51fa\u7cbe\u70bc\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff08Refined Random Forest Classifier\uff09\uff0c\u8be5\u65b9\u6cd5\u8fed\u4ee3\u4f18\u5316\u81ea\u8eab\uff1a\n   - \u9996\u5148\u79fb\u9664\u6700\u4e0d\u91cd\u8981\u7684\u7279\u5f81\u3002\n   - \u7136\u540e\u5206\u6790\u6027\u5730\u786e\u5b9a\u5e94\u751f\u957f\u7684\u65b0\u6811\u7684\u6570\u91cf\u3002\n   - \u6700\u540e\u57fa\u4e8e\u76f8\u5173\u6027\u8fdb\u884c\u805a\u7c7b\uff0c\u4ee5\u53bb\u9664\u5197\u4f59\u6811\u3002", "result": "\u57288\u4e2a\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5305\u62ec\u4e8c\u5143\u548c\u591a\u7c7b\u522b\u6570\u636e\u96c6\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6807\u51c6\u968f\u673a\u68ee\u6797\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u76f8\u540c\u6570\u91cf\u7684\u6811\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7cbe\u70bc\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6a21\u578b\u5197\u4f59\u5e76\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u6807\u51c6\u968f\u673a\u68ee\u6797\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.00485", "pdf": "https://arxiv.org/pdf/2507.00485", "abs": "https://arxiv.org/abs/2507.00485", "authors": ["Weiran Guo", "Guanjun Liu", "Ziyuan Zhou", "Ling Wang"], "title": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) is widely used in tasks where agents interact\nwith an environment to maximize rewards. Building on this foundation, Safe\nReinforcement Learning (Safe RL) incorporates a cost metric alongside the\nreward metric, ensuring that agents adhere to safety constraints during\ndecision-making. In this paper, we identify that Safe RL is vulnerable to\nbackdoor attacks, which can manipulate agents into performing unsafe actions.\nFirst, we introduce the relevant concepts and evaluation metrics for backdoor\nattacks in Safe RL. It is the first attack framework in the Safe RL field that\ninvolves both Positive and Negative Action sample (PNAct) is to implant\nbackdoors, where positive action samples provide reference actions and negative\naction samples indicate actions to be avoided. We theoretically point out the\nproperties of PNAct and design an attack algorithm. Finally, we conduct\nexperiments to evaluate the effectiveness of our proposed backdoor attack\nframework, evaluating it with the established metrics. This paper highlights\nthe potential risks associated with Safe RL and underscores the feasibility of\nsuch attacks. Our code and supplementary material are available at\nhttps://github.com/azure-123/PNAct.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff08Safe RL\uff09\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5f15\u5165\u4e86\u5305\u542b\u6b63\u8d1f\u52a8\u4f5c\u6837\u672c\uff08PNAct\uff09\u7684\u540e\u95e8\u690d\u5165\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u653b\u51fb\u7684\u6709\u6548\u6027\u3002\u8fd9\u63ed\u793a\u4e86Safe RL\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\u5e76\u8bc1\u660e\u4e86\u6b64\u7c7b\u653b\u51fb\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5c3d\u7ba1Safe RL\u5728\u6700\u5927\u5316\u5956\u52b1\u7684\u540c\u65f6\u8003\u8651\u4e86\u5b89\u5168\u6027\u7ea6\u675f\uff0c\u4f46\u76ee\u524d\u5c1a\u65e0\u7814\u7a76\u63a2\u8ba8\u5176\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63ed\u793aSafe RL\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u540e\u95e8\u653b\u51fb\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u653b\u51fb\u6846\u67b6\u4ee5\u8bc4\u4f30\u5176\u53ef\u884c\u6027\u3002", "method": "\u8bba\u6587\u9996\u5148\u5b9a\u4e49\u4e86\u4e0e\u540e\u95e8\u653b\u51fb\u76f8\u5173\u7684\u6982\u5ff5\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6b63\u8d1f\u52a8\u4f5c\u6837\u672c\uff08PNAct\uff09\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\u3002\u5176\u4e2d\uff0c\u6b63\u6837\u672c\u63d0\u4f9b\u53c2\u8003\u52a8\u4f5c\uff0c\u8d1f\u6837\u672c\u6807\u8bc6\u5e94\u907f\u514d\u7684\u52a8\u4f5c\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u653b\u51fb\u7b97\u6cd5\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86PNAct\u7684\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\u5728Safe RL\u4e2d\u5177\u6709\u8f83\u9ad8\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u6210\u529f\u8bf1\u5bfc\u667a\u80fd\u4f53\u6267\u884c\u4e0d\u5b89\u5168\u52a8\u4f5c\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63ed\u793a\u4e86Safe RL\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86PNAct\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u8fd9\u4e3a\u672a\u6765\u63d0\u5347Safe RL\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.00589", "pdf": "https://arxiv.org/pdf/2507.00589", "abs": "https://arxiv.org/abs/2507.00589", "authors": ["Seok Bin Son", "Joongheon Kim"], "title": "Quantum Circuit Structure Optimization for Quantum Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) enables agents to learn optimal policies through\nenvironmental interaction. However, RL suffers from reduced learning efficiency\ndue to the curse of dimensionality in high-dimensional spaces. Quantum\nreinforcement learning (QRL) addresses this issue by leveraging superposition\nand entanglement in quantum computing, allowing efficient handling of\nhigh-dimensional problems with fewer resources. QRL combines quantum neural\nnetworks (QNNs) with RL, where the parameterized quantum circuit (PQC) acts as\nthe core computational module. The PQC performs linear and nonlinear\ntransformations through gate operations, similar to hidden layers in classical\nneural networks. Previous QRL studies, however, have used fixed PQC structures\nbased on empirical intuition without verifying their optimality. This paper\nproposes a QRL-NAS algorithm that integrates quantum neural architecture search\n(QNAS) to optimize PQC structures within QRL. Experiments demonstrate that\nQRL-NAS achieves higher rewards than QRL with fixed circuits, validating its\neffectiveness and practical utility.", "AI": {"tldr": "\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60(Quantum Reinforcement Learning, QRL)\u901a\u8fc7\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def(Parameterized Quantum Circuit, PQC)\u4f18\u5316\u9ad8\u7ef4\u95ee\u9898\u7684\u5904\u7406\u6548\u7387\u3002\u672c\u6587\u63d0\u51faQRL-NAS\u7b97\u6cd5\uff0c\u7ed3\u5408\u91cf\u5b50\u795e\u7ecf\u67b6\u6784\u641c\u7d22(QNAS)\uff0c\u4f18\u5316PQC\u7ed3\u6784\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u76f8\u8f83\u4e8e\u56fa\u5b9a\u7535\u8def\u7684QRL\u5177\u6709\u66f4\u9ad8\u7684\u5956\u52b1\u503c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7531\u4e8e\u7ef4\u5ea6\u707e\u96be\u5bfc\u81f4\u5b66\u4e60\u6548\u7387\u964d\u4f4e\uff0c\u800c\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u53e0\u52a0\u548c\u7ea0\u7f20\u7279\u6027\uff0c\u80fd\u591f\u4ee5\u8f83\u5c11\u8d44\u6e90\u9ad8\u6548\u5904\u7406\u9ad8\u7ef4\u95ee\u9898\u3002\u7136\u800c\uff0c\u4ee5\u5f80\u7814\u7a76\u4e2d\u7684\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u7ed3\u6784\u662f\u57fa\u4e8e\u7ecf\u9a8c\u8bbe\u5b9a\u7684\uff0c\u672a\u9a8c\u8bc1\u5176\u6700\u4f18\u6027\u3002", "method": "\u63d0\u51faQRL-NAS\u7b97\u6cd5\uff0c\u5c06\u91cf\u5b50\u795e\u7ecf\u67b6\u6784\u641c\u7d22(QNAS)\u4e0e\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60(QRL)\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u4f18\u5316\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def(PQC)\u7684\u7ed3\u6784\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528QRL-NAS\u4f18\u5316\u540e\u7684PQC\u7ed3\u6784\u5728\u5956\u52b1\u503c\u4e0a\u663e\u8457\u9ad8\u4e8e\u4f7f\u7528\u56fa\u5b9a\u7535\u8def\u7684\u4f20\u7edfQRL\u65b9\u6cd5\u3002", "conclusion": "QRL-NAS\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316PQC\u7ed3\u6784\uff0c\u63d0\u5347\u4e86\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.00611", "pdf": "https://arxiv.org/pdf/2507.00611", "abs": "https://arxiv.org/abs/2507.00611", "authors": ["Chenyang Cao", "Miguel Rogel-Garc\u00eda", "Mohamed Nabail", "Xueqian Wang", "Nicholas Rhinehart"], "title": "Residual Reward Models for Preference-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "26 pages, 22 figures", "summary": "Preference-based Reinforcement Learning (PbRL) provides a way to learn\nhigh-performance policies in environments where the reward signal is hard to\nspecify, avoiding heuristic and time-consuming reward design. However, PbRL can\nsuffer from slow convergence speed since it requires training in a reward\nmodel. Prior work has proposed learning a reward model from demonstrations and\nfine-tuning it using preferences. However, when the model is a neural network,\nusing different loss functions for pre-training and fine-tuning can pose\nchallenges to reliable optimization. In this paper, we propose a method to\neffectively leverage prior knowledge with a Residual Reward Model (RRM). An RRM\nassumes that the true reward of the environment can be split into a sum of two\nparts: a prior reward and a learned reward. The prior reward is a term\navailable before training, for example, a user's ``best guess'' reward\nfunction, or a reward function learned from inverse reinforcement learning\n(IRL), and the learned reward is trained with preferences. We introduce\nstate-based and image-based versions of RRM and evaluate them on several tasks\nin the Meta-World environment suite. Experimental results show that our method\nsubstantially improves the performance of a common PbRL method. Our method\nachieves performance improvements for a variety of different types of prior\nrewards, including proxy rewards, a reward obtained from IRL, and even a\nnegated version of the proxy reward. We also conduct experiments with a Franka\nPanda to show that our method leads to superior performance on a real robot. It\nsignificantly accelerates policy learning for different tasks, achieving\nsuccess in fewer steps than the baseline. The videos are presented at\nhttps://sunlighted.github.io/RRM-web/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b8b\u5dee\u5956\u52b1\u6a21\u578b\uff08RRM\uff09\u7684\u65b9\u6cd5\uff0c\u5c06\u73af\u5883\u7684\u771f\u5b9e\u5956\u52b1\u5206\u4e3a\u5148\u9a8c\u5956\u52b1\u548c\u5b66\u4e60\u5956\u52b1\u4e24\u90e8\u5206\uff0c\u4ee5\u52a0\u901fPreference-based Reinforcement Learning (PbRL)\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684PbRL\u65b9\u6cd5\u5728\u5956\u52b1\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5b58\u5728\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u4e0d\u540c\u635f\u5931\u51fd\u6570\u65f6\u3002\u6b64\u5916\uff0cPbRL\u65b9\u6cd5\u901a\u5e38\u6536\u655b\u8f83\u6162\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6b8b\u5dee\u5956\u52b1\u6a21\u578b\uff08RRM\uff09\uff0c\u5c06\u73af\u5883\u7684\u771f\u5b9e\u5956\u52b1\u8868\u793a\u4e3a\u5148\u9a8c\u5956\u52b1\u548c\u5b66\u4e60\u5956\u52b1\u7684\u603b\u548c\u3002\u5148\u9a8c\u5956\u52b1\u53ef\u4ee5\u662f\u7528\u6237\u7684\u201c\u6700\u4f73\u731c\u6d4b\u201d\u5956\u52b1\u51fd\u6570\u6216\u901a\u8fc7\u9006\u5f3a\u5316\u5b66\u4e60\uff08IRL\uff09\u83b7\u5f97\u7684\u5956\u52b1\u51fd\u6570\uff0c\u800c\u5b66\u4e60\u5956\u52b1\u5219\u901a\u8fc7\u504f\u597d\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u57fa\u4e8e\u72b6\u6001\u548c\u57fa\u4e8e\u56fe\u50cf\u7684RRM\u7248\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRRM\u663e\u8457\u63d0\u9ad8\u4e86PbRL\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7c7b\u578b\u7684\u5148\u9a8c\u5956\u52b1\uff0c\u5305\u62ec\u4ee3\u7406\u5956\u52b1\u3001\u901a\u8fc7IRL\u83b7\u5f97\u7684\u5956\u52b1\u4ee5\u53ca\u4ee3\u7406\u5956\u52b1\u7684\u5426\u5b9a\u7248\u672c\u3002\u5728\u771f\u5b9e\u673a\u5668\u4ebaFranka Panda\u4e0a\u7684\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u4ee5\u66f4\u5c11\u7684\u6b65\u9aa4\u5b9e\u73b0\u6210\u529f\u3002", "conclusion": "RRM\u65b9\u6cd5\u6709\u6548\u5730\u5229\u7528\u4e86\u5148\u9a8c\u77e5\u8bc6\uff0c\u52a0\u901f\u4e86\u7b56\u7565\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4e3aPbRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.00518", "pdf": "https://arxiv.org/pdf/2507.00518", "abs": "https://arxiv.org/abs/2507.00518", "authors": ["Walid Bendada", "Guillaume Salha-Galvan", "Romain Hennequin", "Th\u00e9o Bontempelli", "Thomas Bouab\u00e7a", "Tristan Cazenave"], "title": "Exploring Large Action Sets with Hyperspherical Embeddings using von Mises-Fisher Sampling", "categories": ["cs.LG", "cs.IR"], "comment": "42nd International Conference on Machine Learning (ICML 2025)", "summary": "This paper introduces von Mises-Fisher exploration (vMF-exp), a scalable\nmethod for exploring large action sets in reinforcement learning problems where\nhyperspherical embedding vectors represent these actions. vMF-exp involves\ninitially sampling a state embedding representation using a von Mises-Fisher\ndistribution, then exploring this representation's nearest neighbors, which\nscales to virtually unlimited numbers of candidate actions. We show that, under\ntheoretical assumptions, vMF-exp asymptotically maintains the same probability\nof exploring each action as Boltzmann Exploration (B-exp), a popular\nalternative that, nonetheless, suffers from scalability issues as it requires\ncomputing softmax values for each action. Consequently, vMF-exp serves as a\nscalable alternative to B-exp for exploring large action sets with\nhyperspherical embeddings. Experiments on simulated data, real-world public\ndata, and the successful large-scale deployment of vMF-exp on the recommender\nsystem of a global music streaming service empirically validate the key\nproperties of the proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3avon Mises-Fisher\u63a2\u7d22\uff08vMF-exp\uff09\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e2d\u63a2\u7d22\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u5408\uff0c\u5176\u4e2d\u8d85\u7403\u9762\u5d4c\u5165\u5411\u91cf\u8868\u793a\u8fd9\u4e9b\u52a8\u4f5c\u3002\u4e0eBoltzmann Exploration\u76f8\u6bd4\uff0cvMF-exp\u5728\u7406\u8bba\u4e0a\u5177\u6709\u76f8\u540c\u7684\u63a2\u7d22\u6982\u7387\uff0c\u4f46\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u66f4\u80dc\u4e00\u7b79\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u7684\u573a\u666f\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684Boltzmann Exploration\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u65f6\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5b83\u9700\u8981\u4e3a\u6bcf\u4e2a\u52a8\u4f5c\u8ba1\u7b97softmax\u503c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6709\u6548\u63a2\u7d22\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u3002", "method": "vMF-exp\u65b9\u6cd5\u9996\u5148\u901a\u8fc7von Mises-Fisher\u5206\u5e03\u5bf9\u72b6\u6001\u5d4c\u5165\u8868\u793a\u8fdb\u884c\u91c7\u6837\uff0c\u7136\u540e\u63a2\u7d22\u5176\u6700\u8fd1\u90bb\u7684\u52a8\u4f5c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6269\u5c55\u5230\u51e0\u4e4e\u65e0\u9650\u6570\u91cf\u7684\u5019\u9009\u52a8\u4f5c\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u4e00\u5b9a\u5047\u8bbe\u4e0b\uff0cvMF-exp\u6e10\u8fd1\u5730\u4fdd\u6301\u4e0eBoltzmann Exploration\u76f8\u540c\u7684\u63a2\u7d22\u6982\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u6570\u636e\u3001\u771f\u5b9e\u4e16\u754c\u516c\u5171\u6570\u636e\u4ee5\u53ca\u5168\u7403\u97f3\u4e50\u6d41\u5a92\u4f53\u670d\u52a1\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "vMF-exp\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4f7f\u7528\u8d85\u7403\u9762\u5d4c\u5165\u8868\u793a\u52a8\u4f5c\u7684\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u63a2\u7d22\u95ee\u9898\uff0c\u4e14\u5176\u5b9e\u9a8c\u6548\u679c\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.00653", "pdf": "https://arxiv.org/pdf/2507.00653", "abs": "https://arxiv.org/abs/2507.00653", "authors": ["Yilun Zhang"], "title": "Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages", "summary": "The escalating computational costs of Large Language Model (LLM) inference\nhave become a critical barrier to their widespread and sustainable deployment.\nWhile existing optimization strategies are effective, they are predominantly\nbased on statistical heuristics or architectural modifications, lacking a\nguiding cognitive theory to manage the inference process itself. This paper\naims to bridge this gap by introducing a novel paradigm: the Cognitive\nLoad-Aware Inference (CLAI) framework, which operationalizes principles from\nCognitive Load Theory (CLT) and neuroscience for LLM inference. We formalize\nthe concepts of Intrinsic Cognitive Load, Extraneous Cognitive Load, and\nGermane Cognitive Load into quantifiable LLM metrics ($ICL_{LLM}$, $ECL_{LLM}$,\nand $GCL_{LLM}$), thereby reframing the inference process as a cognitive\neconomics optimization problem: based on the intrinsic complexity of a problem\n($ICL_{LLM}$), minimize wasteful computation ($ECL_{LLM}$), and strategically\nallocate the token budget to productive reasoning ($GCL_{LLM}$). We propose two\nimplementation paths: CLAI-Prompt, a zero-shot method that guides a base LLM\nthrough cognitive control steps via a structured meta-prompt, and CLAI-Tune, a\nfine-tuned model that internalizes these principles for spontaneous cognitive\neconomy. Across a range of benchmarks in complex reasoning, long-context\nquestion answering, and code generation, our methods achieve significant\nreductions in token consumption (up to 45\\%) without sacrificing accuracy.\nFurthermore, CLAI-Tune exhibits an emergent ability to autonomously decompose\ndifficult problems, a key characteristic of human expert cognition. This work\ndemonstrates that by emulating the brain's resource management strategies, we\ncan build more efficient, robust, and capable artificial intelligence systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86Cognitive Load-Aware Inference (CLAI)\u6846\u67b6\uff0c\u5c06\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u5e94\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4f18\u5316\u4e2d\uff0c\u63d0\u51fa\u4e24\u79cd\u5b9e\u73b0\u8def\u5f84CLAI-Prompt\u548cCLAI-Tune\uff0c\u663e\u8457\u964d\u4f4etoken\u6d88\u8017\u800c\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u81ea\u4e3b\u5206\u89e3\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u65e5\u76ca\u589e\u52a0\uff0c\u6210\u4e3a\u5176\u5e7f\u6cdb\u5e94\u7528\u548c\u53ef\u6301\u7eed\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\u3002\u5f53\u524d\u7684\u4f18\u5316\u7b56\u7565\u591a\u4f9d\u8d56\u7edf\u8ba1\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u67b6\u6784\u4fee\u6539\uff0c\u7f3a\u4e4f\u6307\u5bfc\u6027\u7684\u8ba4\u77e5\u7406\u8bba\u6765\u7ba1\u7406\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u3002", "method": "\u901a\u8fc7\u5f15\u5165CLAI\u6846\u67b6\uff0c\u5c06\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u4e2d\u7684\u5185\u5728\u3001\u5916\u5728\u548c\u76f8\u5173\u8ba4\u77e5\u8d1f\u8377\u6982\u5ff5\u5f62\u5f0f\u5316\u4e3a\u53ef\u91cf\u5316\u7684LLM\u6307\u6807($ICL_{LLM}$, $ECL_{LLM}$, \u548c$GCL_{LLM}$)\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u8ba4\u77e5\u7ecf\u6d4e\u5b66\u4f18\u5316\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9e\u65bd\u8def\u5f84\uff1aCLAI-Prompt\uff08\u96f6\u6837\u672c\u65b9\u6cd5\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u5143\u63d0\u793a\u5f15\u5bfc\u57fa\u7840LLM\u8fdb\u884c\u8ba4\u77e5\u63a7\u5236\u6b65\u9aa4\uff09\u548cCLAI-Tune\uff08\u5fae\u8c03\u6a21\u578b\u4ee5\u5185\u5728\u5316\u8fd9\u4e9b\u539f\u5219\u5b9e\u73b0\u81ea\u53d1\u7684\u8ba4\u77e5\u7ecf\u6d4e\uff09\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u3001\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u548c\u4ee3\u7801\u751f\u6210\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe45%\u7684token\u6d88\u8017\u51cf\u5c11\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0cCLAI-Tune\u8868\u73b0\u51fa\u81ea\u4e3b\u5206\u89e3\u96be\u9898\u7684\u80fd\u529b\uff0c\u8fd9\u662f\u4eba\u7c7b\u4e13\u5bb6\u8ba4\u77e5\u7684\u4e00\u4e2a\u5173\u952e\u7279\u5f81\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u5927\u8111\u7684\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u66f4\u7a33\u5065\u4e14\u80fd\u529b\u66f4\u5f3a\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2507.00574", "pdf": "https://arxiv.org/pdf/2507.00574", "abs": "https://arxiv.org/abs/2507.00574", "authors": ["Haresh Rengaraj Rajamohan", "Xiang Gao", "Weicheng Zhu", "Shih-Lun Huang", "Long Chen", "Kyunghyun Cho", "Cem M. Deniz", "Narges Razavian"], "title": "Foundation Models for Clinical Records at Health System Scale", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025 Workshop on Foundation Models for Structured\n  Data", "summary": "Large-scale pretraining has transformed modeling of language and other data\ntypes, but its potential remains underexplored in healthcare with structured\nelectronic health records (EHRs). We present a novel generative pretraining\nstrategy for sequential EHR data using next-visit event prediction. Our model\nlearns to autoregressively generate various tokenized clinical events for the\nnext visit based on patient history and inherently handles the joint prediction\nof heterogeneous data types. Additionally, we introduce regularization on\npredicting repeated events and highlight a key pitfall in EHR-based foundation\nmodel evaluations: repeated event tokens can inflate performance metrics when\nnew onsets are not distinguished from subsequent occurrences. Our model is\nevaluated via zero-shot prediction for forecasting dementia and knee\nosteoarthritis incidence within 2 and 5 years, and the model performance rivals\na fully fine-tuned masked pretrained Transformer baseline, demonstrating that\nour approach captures complex clinical dependencies without requiring costly\ntask-specific fine-tuning.", "AI": {"tldr": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5728\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u9884\u6d4b\u4e0b\u4e00\u6b21\u5c31\u8bca\u4e8b\u4ef6\u6765\u5904\u7406\u987a\u5e8fEHR\u6570\u636e\uff0c\u5e76\u5f15\u5165\u4e86\u5bf9\u91cd\u590d\u4e8b\u4ef6\u9884\u6d4b\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u6a21\u578b\u5728\u96f6\u6837\u672c\u9884\u6d4b\u75f4\u5446\u548c\u819d\u5173\u8282\u9aa8\u5173\u8282\u708e\u53d1\u75c5\u7387\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u53ef\u4e0e\u5b8c\u5168\u5fae\u8c03\u7684\u63a9\u7801\u9884\u8bad\u7ec3Transformer\u57fa\u7ebf\u76f8\u5ab2\u7f8e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5728\u8bed\u8a00\u548c\u5176\u4ed6\u6570\u636e\u7c7b\u578b\u5efa\u6a21\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5177\u6709\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u7684\u533b\u7597\u4fdd\u5065\u9886\u57df\uff0c\u5176\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u7528\u4e0b\u4e00\u6b21\u5c31\u8bca\u4e8b\u4ef6\u9884\u6d4b\u6765\u5904\u7406\u987a\u5e8fEHR\u6570\u636e\u3002\u6a21\u578b\u81ea\u56de\u5f52\u5730\u751f\u6210\u5404\u79cd\u6807\u8bb0\u5316\u7684\u4e34\u5e8a\u4e8b\u4ef6\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u5f02\u6784\u6570\u636e\u7c7b\u578b\u7684\u8054\u5408\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u5bf9\u91cd\u590d\u4e8b\u4ef6\u9884\u6d4b\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3EHR\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff1a\u533a\u5206\u65b0\u53d1\u4e8b\u4ef6\u548c\u540e\u7eed\u4e8b\u4ef6\u7684\u53d1\u751f\u3002", "result": "\u5728\u96f6\u6837\u672c\u9884\u6d4b\u75f4\u5446\u548c\u819d\u5173\u8282\u9aa8\u5173\u8282\u708e\u53d1\u75c5\u7387\u7684\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u7684\u8868\u73b0\u4e0e\u5b8c\u5168\u5fae\u8c03\u7684\u63a9\u7801\u9884\u8bad\u7ec3Transformer\u57fa\u7ebf\u76f8\u5f53\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u8981\u6602\u8d35\u7684\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u6355\u83b7\u590d\u6742\u7684\u4e34\u5e8a\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u7b56\u7565\u4e3a\u987a\u5e8fEHR\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e14\u5728\u4e0d\u8fdb\u884c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u6355\u6349\u590d\u6742\u7684\u4e34\u5e8a\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2507.00669", "pdf": "https://arxiv.org/pdf/2507.00669", "abs": "https://arxiv.org/abs/2507.00669", "authors": ["Duc Cao-Dinh", "Khai Le-Duc", "Anh Dao", "Bach Phan Tat", "Chris Ngo", "Duy M. H. Nguyen", "Nguyen X. Khanh", "Thanh Nguyen-Tang"], "title": "Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Work in progress, 42 pages", "summary": "3D Visual Grounding (3DVG) involves localizing target objects in 3D point\nclouds based on natural language. While prior work has made strides using\ntextual descriptions, leveraging spoken language-known as Audio-based 3D Visual\nGrounding-remains underexplored and challenging. Motivated by advances in\nautomatic speech recognition (ASR) and speech representation learning, we\npropose Audio-3DVG, a simple yet effective framework that integrates audio and\nspatial information for enhanced grounding. Rather than treating speech as a\nmonolithic input, we decompose the task into two complementary components.\nFirst, we introduce Object Mention Detection, a multi-label classification task\nthat explicitly identifies which objects are referred to in the audio, enabling\nmore structured audio-scene reasoning. Second, we propose an Audio-Guided\nAttention module that captures interactions between candidate objects and\nrelational speech cues, improving target discrimination in cluttered scenes. To\nsupport benchmarking, we synthesize audio descriptions for standard 3DVG\ndatasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstrate\nthat Audio-3DVG not only achieves new state-of-the-art performance in\naudio-based grounding, but also competes with text-based methods-highlighting\nthe promise of integrating spoken language into 3D vision tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAudio-3DVG\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u97f3\u9891\u548c\u7a7a\u95f4\u4fe1\u606f\u7ed3\u5408\u8d77\u6765\u7528\u4e8e3D\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u3002\u901a\u8fc7\u5f15\u5165\u5bf9\u8c61\u63d0\u53ca\u68c0\u6d4b\u548c\u97f3\u9891\u5f15\u5bfc\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5e76\u4e14\u4e0e\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5728\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8fdb\u884c3D\u89c6\u89c9\u5b9a\u4f4d\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u5229\u7528\u53e3\u8bed\uff08\u5373\u57fa\u4e8e\u97f3\u9891\u76843D\u89c6\u89c9\u5b9a\u4f4d\uff09\u4ecd\u7136\u672a\u88ab\u5145\u5206\u7814\u7a76\u5e76\u4e14\u5145\u6ee1\u6311\u6218\u3002\u53d7\u5230\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u548c\u8bed\u97f3\u8868\u5f81\u5b66\u4e60\u8fdb\u6b65\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u5982\u4f55\u66f4\u597d\u5730\u5c06\u8bed\u97f3\u4fe1\u606f\u6574\u5408\u52303D\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684\u6846\u67b6\uff0c\u79f0\u4e3aAudio-3DVG\uff0c\u5b83\u7ed3\u5408\u4e86\u97f3\u9891\u548c\u7a7a\u95f4\u4fe1\u606f\u4ee5\u63d0\u9ad8\u5b9a\u4f4d\u6548\u679c\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ed6\u4eec\u5c06\u8bed\u97f3\u5904\u7406\u5206\u4e3a\u4e24\u4e2a\u4e92\u8865\u7684\u90e8\u5206\uff1a1) \u5bf9\u8c61\u63d0\u53ca\u68c0\u6d4b\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff0c\u7528\u4e8e\u660e\u786e\u8bc6\u522b\u97f3\u9891\u4e2d\u63d0\u5230\u7684\u5bf9\u8c61\uff1b2) \u97f3\u9891\u5f15\u5bfc\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6355\u6349\u5019\u9009\u5bf9\u8c61\u548c\u5173\u7cfb\u8bed\u97f3\u63d0\u793a\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0c\u4ece\u800c\u63d0\u9ad8\u5728\u6742\u4e71\u573a\u666f\u4e2d\u7684\u76ee\u6807\u533a\u5206\u80fd\u529b\u3002\u4e3a\u4e86\u652f\u6301\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f5c\u8005\u8fd8\u4e3a\u6807\u51c63DVG\u6570\u636e\u96c6\uff08\u5982ScanRefer\u3001Sr3D\u548cNr3D\uff09\u5408\u6210\u4e86\u97f3\u9891\u63cf\u8ff0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAudio-3DVG\u4e0d\u4ec5\u5728\u57fa\u4e8e\u97f3\u9891\u7684\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u800c\u4e14\u5176\u8868\u73b0\u8fd8\u80fd\u4e0e\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002\u8fd9\u7a81\u663e\u4e86\u5c06\u53e3\u8bed\u6574\u5408\u52303D\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Audio-3DVG\u6846\u67b6\u6210\u529f\u5730\u5c06\u97f3\u9891\u4fe1\u606f\u6574\u5408\u52303D\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u4e2d\uff0c\u5e76\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002\u8fd9\u8868\u660e\uff0c\u5728\u672a\u6765\u7684\u7814\u7a76\u4e2d\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u5982\u4f55\u66f4\u6709\u6548\u5730\u5229\u7528\u53e3\u8bed\u4fe1\u606f\u6765\u6539\u55843D\u89c6\u89c9\u4efb\u52a1\u7684\u6548\u679c\u3002"}}
{"id": "2507.00880", "pdf": "https://arxiv.org/pdf/2507.00880", "abs": "https://arxiv.org/abs/2507.00880", "authors": ["Ruihan Xu", "Haokui Zhang", "Yaowei Wang", "Wei Zeng", "Shiliang Zhang"], "title": "NN-Former: Rethinking Graph Structure in Neural Architecture Representation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to CVPR 2025. Code is avaiable at\n  https://github.com/XuRuihan/NNFormer", "summary": "The growing use of deep learning necessitates efficient network design and\ndeployment, making neural predictors vital for estimating attributes such as\naccuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers\nhave shown promising performance in representing neural architectures. However,\neach of both methods has its disadvantages. GNNs lack the capabilities to\nrepresent complicated features, while transformers face poor generalization\nwhen the depth of architecture grows. To mitigate the above issues, we rethink\nneural architecture topology and show that sibling nodes are pivotal while\noverlooked in previous research. We thus propose a novel predictor leveraging\nthe strengths of GNNs and transformers to learn the enhanced topology. We\nintroduce a novel token mixer that considers siblings, and a new channel mixer\nnamed bidirectional graph isomorphism feed-forward network. Our approach\nconsistently achieves promising performance in both accuracy and latency\nprediction, providing valuable insights for learning Directed Acyclic Graph\n(DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9884\u6d4b\u5668\uff0c\u7ed3\u5408\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u548c\u53d8\u538b\u5668\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u5f15\u5165\u8003\u8651\u5144\u5f1f\u8282\u70b9\u7684\u65b0\u6807\u8bb0\u6df7\u5408\u5668\u548c\u53cc\u5411\u56fe\u540c\u6784\u524d\u9988\u7f51\u7edc\u7684\u65b0\u901a\u9053\u6df7\u5408\u5668\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u7279\u5f81\u8868\u793a\u548c\u6df1\u5ea6\u67b6\u6784\u6cdb\u5316\u4e0a\u7684\u4e0d\u8db3\uff0c\u4ece\u800c\u5728\u51c6\u786e\u6027\u548c\u5ef6\u8fdf\u9884\u6d4b\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u9700\u8981\u9ad8\u6548\u7684\u7f51\u7edc\u8bbe\u8ba1\u548c\u90e8\u7f72\uff0c\u795e\u7ecf\u9884\u6d4b\u5668\u5bf9\u4e8e\u4f30\u8ba1\u8bf8\u5982\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u7b49\u5c5e\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684GNNs\u548ctransformers\u65b9\u6cd5\u5206\u522b\u5b58\u5728\u65e0\u6cd5\u8868\u793a\u590d\u6742\u7279\u5f81\u548c\u6df1\u5ea6\u67b6\u6784\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u91cd\u65b0\u601d\u8003\u4e86\u795e\u7ecf\u67b6\u6784\u62d3\u6251\u7ed3\u6784\uff0c\u53d1\u73b0\u4e4b\u524d\u7814\u7a76\u4e2d\u88ab\u5ffd\u89c6\u7684\u5144\u5f1f\u8282\u70b9\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u9884\u6d4b\u5668\uff0c\u8be5\u9884\u6d4b\u5668\u7ed3\u5408\u4e86GNNs\u548ctransformers\u7684\u4f18\u52bf\u6765\u5b66\u4e60\u589e\u5f3a\u7684\u62d3\u6251\u7ed3\u6784\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6807\u8bb0\u6df7\u5408\u5668\u4ee5\u8003\u8651\u5144\u5f1f\u8282\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u53cc\u5411\u56fe\u540c\u6784\u524d\u9988\u7f51\u7edc\u7684\u65b0\u901a\u9053\u6df7\u5408\u5668\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u5ef6\u8fdf\u9884\u6d4b\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5b66\u4e60\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u62d3\u6251\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9884\u6d4b\u5668\u6709\u6548\u5730\u7f13\u89e3\u4e86GNNs\u548ctransformers\u5404\u81ea\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5728\u795e\u7ecf\u67b6\u6784\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u601d\u8def\u3002"}}
{"id": "2507.00971", "pdf": "https://arxiv.org/pdf/2507.00971", "abs": "https://arxiv.org/abs/2507.00971", "authors": ["Taeyoun Kim", "Fahim Tajwar", "Aditi Raghunathan", "Aviral Kumar"], "title": "Reasoning as an Adaptive Defense for Safety", "categories": ["cs.LG", "cs.AI"], "comment": "42 pages, 11 Figures, 7 Tables", "summary": "Reasoning methods that adaptively allocate test-time compute have advanced\nLLM performance on easy to verify domains such as math and code. In this work,\nwe study how to utilize this approach to train models that exhibit a degree of\nrobustness to safety vulnerabilities, and show that doing so can provide\nbenefits. We build a recipe called $\\textit{TARS}$ (Training Adaptive Reasoners\nfor Safety), a reinforcement learning (RL) approach that trains models to\nreason about safety using chain-of-thought traces and a reward signal that\nbalances safety with task completion. To build TARS, we identify three critical\ndesign choices: (1) a \"lightweight\" warmstart SFT stage, (2) a mix of harmful,\nharmless, and ambiguous prompts to prevent shortcut behaviors such as too many\nrefusals, and (3) a reward function to prevent degeneration of reasoning\ncapabilities during training. Models trained with TARS exhibit adaptive\nbehaviors by spending more compute on ambiguous queries, leading to better\nsafety-refusal trade-offs. They also internally learn to better distinguish\nbetween safe and unsafe prompts and attain greater robustness to both white-box\n(e.g., GCG) and black-box attacks (e.g., PAIR). Overall, our work provides an\neffective, open recipe for training LLMs against jailbreaks and harmful\nrequests by reasoning per prompt.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTARS\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u6a21\u578b\u5728\u5904\u7406\u5b89\u5168\u6027\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u81ea\u9002\u5e94\u884c\u4e3a\uff0c\u63d0\u9ad8\u5bf9\u4e0d\u540c\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u9002\u5e94\u5206\u914d\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u8d44\u6e90\u7684\u65b9\u6cd5\u5728\u6570\u5b66\u548c\u4ee3\u7801\u7b49\u6613\u4e8e\u9a8c\u8bc1\u7684\u9886\u57df\u63d0\u5347\u4e86\u5927\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3\u51fa\u5177\u5907\u4e00\u5b9a\u5b89\u5168\u6f0f\u6d1e\u9c81\u68d2\u6027\u7684\u6a21\u578b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u6784\u5efa\u4e86TARS\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff1a\u8f7b\u91cf\u7ea7\u9884\u70edSFT\u9636\u6bb5\u3001\u6df7\u5408\u63d0\u793a\u8bcd\u4ee5\u907f\u514d\u6377\u5f84\u884c\u4e3a\u3001\u5956\u52b1\u51fd\u6570\u9632\u6b62\u63a8\u7406\u80fd\u529b\u9000\u5316\uff1b\u4f7f\u7528\u94fe\u5f0f\u601d\u7ef4\u8f68\u8ff9\u548c\u5e73\u8861\u5b89\u5168\u4e0e\u4efb\u52a1\u5b8c\u6210\u7684\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u4f7f\u7528TARS\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6a21\u7cca\u67e5\u8be2\u4e0a\u82b1\u8d39\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u5b89\u5168-\u62d2\u7edd\u6743\u8861\uff0c\u5e76\u4e14\u80fd\u591f\u66f4\u597d\u5730\u533a\u5206\u5b89\u5168\u548c\u4e0d\u5b89\u5168\u63d0\u793a\uff0c\u589e\u5f3a\u5bf9\u767d\u76d2\u548c\u9ed1\u76d2\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5f00\u6e90\u65b9\u6848\uff0c\u901a\u8fc7\u6bcf\u63d0\u793a\u63a8\u7406\u6765\u8bad\u7ec3\u5927\u6a21\u578b\u4ee5\u5e94\u5bf9\u8d8a\u72f1\u548c\u6709\u5bb3\u8bf7\u6c42\u3002"}}
{"id": "2507.00647", "pdf": "https://arxiv.org/pdf/2507.00647", "abs": "https://arxiv.org/abs/2507.00647", "authors": ["Andr\u00e9 Ribeiro", "Ana Luiza Ten\u00f3rio", "Juan Belieni", "Amauri H. Souza", "Diego Mesquita"], "title": "Cooperative Sheaf Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Sheaf diffusion has recently emerged as a promising design pattern for graph\nrepresentation learning due to its inherent ability to handle heterophilic data\nand avoid oversmoothing. Meanwhile, cooperative message passing has also been\nproposed as a way to enhance the flexibility of information diffusion by\nallowing nodes to independently choose whether to propagate/gather information\nfrom/to neighbors. A natural question ensues: is sheaf diffusion capable of\nexhibiting this cooperative behavior? Here, we provide a negative answer to\nthis question. In particular, we show that existing sheaf diffusion methods\nfail to achieve cooperative behavior due to the lack of message directionality.\nTo circumvent this limitation, we introduce the notion of cellular sheaves over\ndirected graphs and characterize their in- and out-degree Laplacians. We\nleverage our construction to propose Cooperative Sheaf Neural Networks (CSNNs).\nTheoretically, we characterize the receptive field of CSNN and show it allows\nnodes to selectively attend (listen) to arbitrarily far nodes while ignoring\nall others in their path, potentially mitigating oversquashing. Our experiments\nshow that CSNN presents overall better performance compared to prior art on\nsheaf diffusion as well as cooperative graph neural networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578bCSNN\uff0c\u89e3\u51b3\u4e86\u73b0\u6709sheaf diffusion\u65b9\u6cd5\u7f3a\u4e4f\u4fe1\u606f\u65b9\u5411\u6027\u7684\u95ee\u9898\uff0c\u4f7f\u5176\u80fd\u591f\u5b9e\u73b0\u7c7b\u4f3ccooperative message passing\u7684\u884c\u4e3a\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u8ba8\u73b0\u6709\u7684sheaf diffusion\u65b9\u6cd5\u662f\u5426\u80fd\u5c55\u73b0\u51facooperative message passing\u7684\u884c\u4e3a\uff0c\u5e76\u89e3\u51b3oversmoothing\u548cheterophilic\u6570\u636e\u5904\u7406\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86\u5728\u6709\u5411\u56fe\u4e0a\u7684cellular sheaves\u6982\u5ff5\uff0c\u5e76\u5b9a\u4e49\u4e86\u5176in-\u548cout-degree Laplacians\uff0c\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86Cooperative Sheaf Neural Networks (CSNNs)\u3002\u8be5\u6a21\u578b\u5141\u8bb8\u8282\u70b9\u9009\u62e9\u6027\u5730\u63a5\u6536\u8fdc\u5904\u8282\u70b9\u7684\u4fe1\u606f\u5e76\u5ffd\u7565\u8def\u5f84\u4e0a\u7684\u5176\u4ed6\u8282\u70b9\uff0c\u4ece\u800c\u7f13\u89e3\u4e86\u4fe1\u606f\u538b\u7f29\uff08oversquashing\uff09\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cCSNN\u7684\u63a5\u6536\u573a\u5141\u8bb8\u8282\u70b9\u9009\u62e9\u6027\u5173\u6ce8\u8fdc\u5904\u8282\u70b9\u800c\u5ffd\u7565\u8def\u5f84\u4e0a\u7684\u5176\u4ed6\u8282\u70b9\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u663e\u793aCSNN\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684sheaf diffusion\u65b9\u6cd5\u548ccooperative graph neural networks\u5177\u6709\u66f4\u597d\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165cellular sheaves\u548cCSNN\uff0c\u6210\u529f\u5b9e\u73b0\u4e86sheaf diffusion\u4e2d\u7684cooperative behavior\uff0c\u5e76\u63d0\u5347\u4e86\u56fe\u8868\u793a\u5b66\u4e60\u7684\u6548\u679c\u3002"}}
{"id": "2507.01003", "pdf": "https://arxiv.org/pdf/2507.01003", "abs": "https://arxiv.org/abs/2507.01003", "authors": ["Eun-Ji Park", "Sangwon Yun"], "title": "Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "Recent studies have proposed interpreting the training process from an\nergodic perspective. Building on this foundation we present a unified framework\nfor understanding and accelerating the training of deep neural networks via\nstochastic gradient descent. By analyzing the geometric landscape of the\nobjective function we introduce a practical diagnostic, the running estimate of\nthe largest Lyapunov exponent, which provably distinguishes genuine convergence\ntoward stable minimizers from mere statistical stabilization near saddle\npoints. We then propose a ghost category extension for standard classifiers\nthat adds auxiliary ghost output nodes so the model gains extra descent\ndirections that open a lateral corridor around narrow loss barriers and enable\nthe optimizer to bypass poor basins during the early training phase. We show\nthat this extension strictly reduces approximation error and that after\nsufficient convergence the ghost dimensions collapse and the extended model's\ninvariant law coincides with that of the original and there exists a path in\nthe enlarged parameter space along which the total loss does not increase while\nthe original loss decreases by an arbitrary margin. Taken together these\nresults provide a principled architecture level intervention that accelerates\nearly stage trainability while preserving asymptotic behavior.", "AI": {"tldr": "\u8fd1\u671f\u7814\u7a76\u63d0\u51fa\u4e86\u4ece\u904d\u5386\u6027\u89c6\u89d2\u89e3\u91ca\u8bad\u7ec3\u8fc7\u7a0b\u3002\u57fa\u4e8e\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7406\u89e3\u5e76\u52a0\u901f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u7684\u7edf\u4e00\u6846\u67b6\u3002\u901a\u8fc7\u5bf9\u76ee\u6807\u51fd\u6570\u51e0\u4f55\u666f\u89c2\u7684\u5206\u6790\uff0c\u5f15\u5165\u4e86\u6700\u5927\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u7684\u5b9e\u9645\u8bca\u65ad\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6807\u51c6\u5206\u7c7b\u5668\u7684\u5e7d\u7075\u7c7b\u522b\u6269\u5c55\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6dfb\u52a0\u8f85\u52a9\u5e7d\u7075\u8f93\u51fa\u8282\u70b9\u4f7f\u6a21\u578b\u83b7\u5f97\u989d\u5916\u7684\u4e0b\u964d\u65b9\u5411\uff0c\u4ece\u800c\u7ed5\u8fc7\u72ed\u7a84\u635f\u5931\u969c\u788d\u5e76\u52a0\u901f\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u3002\u8fd9\u4e9b\u7ed3\u679c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u67b6\u6784\u7ea7\u522b\u4e0a\u52a0\u901f\u65e9\u671f\u8bad\u7ec3\u540c\u65f6\u4fdd\u7559\u6e10\u8fd1\u884c\u4e3a\u7684\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u8fd1\u671f\u7814\u7a76\u63d0\u51fa\u4e86\u4ece\u904d\u5386\u6027\u89c6\u89d2\u89e3\u91ca\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u4e3a\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\u7136\u800c\uff0c\u5982\u4f55\u8fdb\u4e00\u6b65\u5229\u7528\u8fd9\u79cd\u89c6\u89d2\u6765\u52a0\u901f\u8bad\u7ec3\u4ecd\u9700\u63a2\u7d22\u3002", "method": "1. \u5206\u6790\u76ee\u6807\u51fd\u6570\u7684\u51e0\u4f55\u666f\u89c2\uff0c\u5f15\u5165\u6700\u5927\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u7684\u5b9e\u9645\u8bca\u65ad\u65b9\u6cd5\u4ee5\u533a\u5206\u771f\u5b9e\u6536\u655b\u548c\u7edf\u8ba1\u7a33\u5b9a\u3002\n2. \u63d0\u51fa\u5e7d\u7075\u7c7b\u522b\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u8f85\u52a9\u5e7d\u7075\u8f93\u51fa\u8282\u70b9\u4e3a\u6a21\u578b\u63d0\u4f9b\u989d\u5916\u7684\u4e0b\u964d\u65b9\u5411\uff0c\u5e2e\u52a9\u4f18\u5316\u5668\u7ed5\u8fc7\u4e0d\u826f\u76c6\u5730\u3002\n3. \u8bc1\u660e\u5e7d\u7075\u7ef4\u5ea6\u5728\u5145\u5206\u6536\u655b\u540e\u4f1a\u5d29\u6e83\uff0c\u4e14\u6269\u5c55\u6a21\u578b\u7684\u4e0d\u53d8\u5f8b\u4e0e\u539f\u59cb\u6a21\u578b\u4e00\u81f4\u3002", "result": "1. \u5e7d\u7075\u7c7b\u522b\u6269\u5c55\u65b9\u6cd5\u4e25\u683c\u51cf\u5c11\u4e86\u8fd1\u4f3c\u8bef\u5dee\u3002\n2. \u5728\u5145\u5206\u6536\u655b\u540e\uff0c\u5e7d\u7075\u7ef4\u5ea6\u5d29\u6e83\uff0c\u6269\u5c55\u6a21\u578b\u7684\u884c\u4e3a\u4e0e\u539f\u59cb\u6a21\u578b\u4e00\u81f4\u3002\n3. \u5b58\u5728\u4e00\u6761\u8def\u5f84\u4f7f\u5f97\u603b\u635f\u5931\u4e0d\u589e\u52a0\u800c\u539f\u59cb\u635f\u5931\u53ef\u4ee5\u51cf\u5c11\u4efb\u610f\u5e45\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5e7d\u7075\u7c7b\u522b\u6269\u5c55\u65b9\u6cd5\u4e3a\u52a0\u901f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u67b6\u6784\u7ea7\u5e72\u9884\u624b\u6bb5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6e10\u8fd1\u884c\u4e3a\u3002"}}
{"id": "2507.00654", "pdf": "https://arxiv.org/pdf/2507.00654", "abs": "https://arxiv.org/abs/2507.00654", "authors": ["Hans van Gorp", "Davide Belli", "Amir Jalalirad", "Bence Major"], "title": "Neural Augmented Kalman Filters for Road Network assisted GNSS positioning", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": "Accepted to ICML 2025 workshop ML4Wireless", "summary": "The Global Navigation Satellite System (GNSS) provides critical positioning\ninformation globally, but its accuracy in dense urban environments is often\ncompromised by multipath and non-line-of-sight errors. Road network data can be\nused to reduce the impact of these errors and enhance the accuracy of a\npositioning system. Previous works employing road network data are either\nlimited to offline applications, or rely on Kalman Filter (KF) heuristics with\nlittle flexibility and robustness. We instead propose training a Temporal Graph\nNeural Network (TGNN) to integrate road network information into a KF. The TGNN\nis designed to predict the correct road segment and its associated uncertainty\nto be used in the measurement update step of the KF. We validate our approach\nwith real-world GNSS data and open-source road networks, observing a 29%\ndecrease in positioning error for challenging scenarios compared to a GNSS-only\nKF. To the best of our knowledge, ours is the first deep learning-based\napproach jointly employing road network data and GNSS measurements to determine\nthe user position on Earth.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u9053\u8def\u7f51\u7edc\u6570\u636e\u548cGNSS\u6d4b\u91cf\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u786e\u5b9a\u7528\u6237\u5728\u5730\u7403\u4e0a\u7684\u4f4d\u7f6e\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\uff08TGNN\uff09\u9884\u6d4b\u6b63\u786e\u7684\u9053\u8def\u6bb5\u53ca\u5176\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u5176\u6574\u5408\u5230\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08KF\uff09\u4e2d\uff0c\u4ece\u800c\u663e\u8457\u51cf\u5c11\u4e86\u5b9a\u4f4d\u8bef\u5dee\u3002", "motivation": "\u5168\u7403\u5bfc\u822a\u536b\u661f\u7cfb\u7edf (GNSS) \u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u7531\u4e8e\u591a\u8def\u5f84\u548c\u975e\u89c6\u8ddd\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u5176\u5b9a\u4f4d\u7cbe\u5ea6\u5e38\u5e38\u53d7\u5230\u5f71\u54cd\u3002\u5229\u7528\u9053\u8def\u7f51\u7edc\u6570\u636e\u53ef\u4ee5\u51cf\u5c11\u8fd9\u4e9b\u8bef\u5dee\u5e76\u63d0\u9ad8\u5b9a\u4f4d\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u3002\u7136\u800c\uff0c\u4ee5\u5f80\u7684\u7814\u7a76\u8981\u4e48\u4ec5\u9650\u4e8e\u79bb\u7ebf\u5e94\u7528\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u8f83\u4f4e\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668 (KF) \u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u8bad\u7ec3\u4e00\u4e2a\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\uff08TGNN\uff09\uff0c\u5c06\u9053\u8def\u7f51\u7edc\u4fe1\u606f\u6574\u5408\u5230\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08KF\uff09\u4e2d\u3002\u8bbe\u8ba1\u7684TGNN\u7528\u4e8e\u9884\u6d4b\u6b63\u786e\u7684\u9053\u8def\u6bb5\u53ca\u5176\u5173\u8054\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728KF\u7684\u6d4b\u91cf\u66f4\u65b0\u6b65\u9aa4\u4e2d\u4f7f\u7528\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u7684GNSS\u6570\u636e\u548c\u5f00\u6e90\u9053\u8def\u7f51\u7edc\u9a8c\u8bc1\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\uff0c\u4e0e\u4ec5\u4f7f\u7528GNSS\u7684KF\u76f8\u6bd4\uff0c\u5b9a\u4f4d\u8bef\u5dee\u51cf\u5c11\u4e8629%\u3002", "conclusion": "\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u8054\u5408\u4f7f\u7528\u9053\u8def\u7f51\u7edc\u6570\u636e\u548cGNSS\u6d4b\u91cf\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9a\u5730\u7403\u4e0a\u7684\u7528\u6237\u4f4d\u7f6e\u3002"}}
{"id": "2507.00687", "pdf": "https://arxiv.org/pdf/2507.00687", "abs": "https://arxiv.org/abs/2507.00687", "authors": ["Philipp Vaeth", "Dibyanshu Kumar", "Benjamin Paassen", "Magda Gregorov\u00e1"], "title": "Diffusion Classifier Guidance for Non-robust Classifiers", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at ECML 2025", "summary": "Classifier guidance is intended to steer a diffusion process such that a\ngiven classifier reliably recognizes the generated data point as a certain\nclass. However, most classifier guidance approaches are restricted to robust\nclassifiers, which were specifically trained on the noise of the diffusion\nforward process. We extend classifier guidance to work with general,\nnon-robust, classifiers that were trained without noise. We analyze the\nsensitivity of both non-robust and robust classifiers to noise of the diffusion\nprocess on the standard CelebA data set, the specialized SportBalls data set\nand the high-dimensional real-world CelebA-HQ data set. Our findings reveal\nthat non-robust classifiers exhibit significant accuracy degradation under\nnoisy conditions, leading to unstable guidance gradients. To mitigate these\nissues, we propose a method that utilizes one-step denoised image predictions\nand implements stabilization techniques inspired by stochastic optimization\nmethods, such as exponential moving averages. Experimental results demonstrate\nthat our approach improves the stability of classifier guidance while\nmaintaining sample diversity and visual quality. This work contributes to\nadvancing conditional sampling techniques in generative models, enabling a\nbroader range of classifiers to be used as guidance classifiers.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u5206\u7c7b\u5668\u5f15\u5bfc\u6280\u672f\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u4e00\u822c\u7684\u3001\u975e\u9c81\u68d2\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u9ad8\u5206\u7c7b\u5668\u5f15\u5bfc\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6837\u672c\u591a\u6837\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u7c7b\u5668\u5f15\u5bfc\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u5bf9\u6269\u6563\u8fc7\u7a0b\u566a\u58f0\u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\u7684\u9c81\u68d2\u5206\u7c7b\u5668\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u9002\u7528\u8303\u56f4\u3002\u4e3a\u4e86\u4f7f\u4e00\u822c\u7684\u3001\u975e\u9c81\u68d2\u7684\u5206\u7c7b\u5668\u4e5f\u80fd\u6709\u6548\u7528\u4e8e\u5f15\u5bfc\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u5206\u7c7b\u5668\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u51c6\u786e\u7387\u4e0b\u964d\u548c\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "method": "\u5206\u6790\u4e86\u975e\u9c81\u68d2\u548c\u9c81\u68d2\u5206\u7c7b\u5668\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u566a\u58f0\u654f\u611f\u6027\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u4e00\u6b65\u53bb\u566a\u56fe\u50cf\u9884\u6d4b\u548c\u53d7\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u542f\u53d1\u7684\u7a33\u5b9a\u5316\u6280\u672f\uff08\u5982\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5206\u7c7b\u5668\u5f15\u5bfc\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6837\u672c\u591a\u6837\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86\u751f\u6210\u6a21\u578b\u4e2d\u6761\u4ef6\u91c7\u6837\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4f7f\u5f97\u66f4\u5e7f\u6cdb\u7684\u5206\u7c7b\u5668\u53ef\u4ee5\u4f5c\u4e3a\u5f15\u5bfc\u5206\u7c7b\u5668\u4f7f\u7528\u3002"}}
{"id": "2507.00695", "pdf": "https://arxiv.org/pdf/2507.00695", "abs": "https://arxiv.org/abs/2507.00695", "authors": ["Daniel Pfrommer", "Max Simchowitz", "Ali Jadbabaie"], "title": "A Test-Function Approach to Incremental Stability", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages", "summary": "This paper presents a novel framework for analyzing\nIncremental-Input-to-State Stability ($\\delta$ISS) based on the idea of using\nrewards as \"test functions.\" Whereas control theory traditionally deals with\nLyapunov functions that satisfy a time-decrease condition, reinforcement\nlearning (RL) value functions are constructed by exponentially decaying a\nLipschitz reward function that may be non-smooth and unbounded on both sides.\nThus, these RL-style value functions cannot be directly understood as Lyapunov\ncertificates. We develop a new equivalence between a variant of incremental\ninput-to-state stability of a closed-loop system under given a policy, and the\nregularity of RL-style value functions under adversarial selection of a\nH\\\"older-continuous reward function. This result highlights that the regularity\nof value functions, and their connection to incremental stability, can be\nunderstood in a way that is distinct from the traditional Lyapunov-based\napproach to certifying stability in control theory.", "AI": {"tldr": "This paper introduces a novel framework connecting reinforcement learning (RL) value functions with incremental input-to-state stability ($\\delta$ISS). It establishes an equivalence between the regularity of RL-style value functions and a variant of $\\delta$ISS under adversarial reward selection.", "motivation": "The motivation is to bridge the gap between control theory and reinforcement learning by analyzing stability using RL concepts. Specifically, it aims to understand how RL-style value functions relate to incremental input-to-state stability.", "method": "The method involves developing an equivalence between a variant of incremental input-to-state stability of a closed-loop system under a given policy, and the regularity of RL-style value functions when a H\u00f6lder-continuous reward function is adversarially selected.", "result": "The result shows that there is an equivalence between the regularity of RL-style value functions and a specific form of incremental input-to-state stability, offering a new perspective on stability certification distinct from traditional Lyapunov-based approaches.", "conclusion": "This work concludes that the regularity of value functions and their connection to incremental stability can be understood differently from the traditional Lyapunov-based approach, providing a novel framework for analyzing stability in control systems using RL concepts."}}
{"id": "2507.00701", "pdf": "https://arxiv.org/pdf/2507.00701", "abs": "https://arxiv.org/abs/2507.00701", "authors": ["Chong Zhang", "Xichao Liu", "Yibing Zhan", "Dapeng Tao", "Jun Ni"], "title": "SCAWaveNet: A Spatial-Channel Attention-based Network for Global Significant Wave Height Retrieval", "categories": ["cs.LG"], "comment": "16 pages,6 tables,11 figures", "summary": "Recent advancements in spaceborne GNSS missions have produced extensive\nglobal datasets, providing a robust basis for deep learning-based significant\nwave height (SWH) retrieval. While existing deep learning models predominantly\nutilize CYGNSS data with four-channel information, they often adopt\nsingle-channel inputs or simple channel concatenation without leveraging the\nbenefits of cross-channel information interaction during training. To address\nthis limitation, a novel spatial-channel attention-based network, namely\nSCAWaveNet, is proposed for SWH retrieval. Specifically, features from each\nchannel of the DDMs are modeled as independent attention heads, enabling the\nfusion of spatial and channel-wise information. For auxiliary parameters, a\nlightweight attention mechanism is designed to assign weights along the spatial\nand channel dimensions. The final feature integrates both spatial and\nchannel-level characteristics. Model performance is evaluated using\nfour-channel CYGNSS data. When ERA5 is used as a reference, SCAWaveNet achieves\nan average RMSE of 0.438 m. When using buoy data from NDBC, the average RMSE\nreaches 0.432 m. Compared to state-of-the-art models, SCAWaveNet reduces the\naverage RMSE by at least 3.52% on the ERA5 dataset and by 5.47% on the NDBC\nbuoy observations. The code is available at\nhttps://github.com/Clifx9908/SCAWaveNet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7a7a\u95f4-\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u7684\u7f51\u7edcSCAWaveNet\u7528\u4e8e\u663e\u8457\u6ce2\u9ad8\uff08SWH\uff09\u68c0\u7d22\uff0c\u901a\u8fc7\u878d\u5408\u591a\u901a\u9053\u4fe1\u606f\u548c\u7a7a\u95f4\u4fe1\u606f\uff0c\u76f8\u6bd4\u73b0\u6709\u6a21\u578b\u5728ERA5\u548cNDBC\u6570\u636e\u96c6\u4e0a\u5206\u522b\u964d\u4f4e\u81f3\u5c113.52%\u548c5.47%\u7684\u5e73\u5747RMSE\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e3b\u8981\u5229\u7528CYGNSS\u6570\u636e\u7684\u56db\u901a\u9053\u4fe1\u606f\uff0c\u4f46\u901a\u5e38\u91c7\u7528\u5355\u901a\u9053\u8f93\u5165\u6216\u7b80\u5355\u7684\u901a\u9053\u62fc\u63a5\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u8de8\u901a\u9053\u4fe1\u606f\u4ea4\u4e92\u7684\u4f18\u52bf\u3002", "method": "\u8bbe\u8ba1\u4e86SCAWaveNet\u7f51\u7edc\uff0c\u5c06DDMs\u5404\u901a\u9053\u7684\u7279\u5f81\u5efa\u6a21\u4e3a\u72ec\u7acb\u7684\u6ce8\u610f\u529b\u5934\uff0c\u4ee5\u878d\u5408\u7a7a\u95f4\u548c\u901a\u9053\u4fe1\u606f\uff1b\u8f85\u52a9\u53c2\u6570\u4e2d\u5f15\u5165\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u4e0d\u540c\u7ef4\u5ea6\u5206\u914d\u6743\u91cd\uff1b\u6700\u7ec8\u8f93\u51fa\u6574\u5408\u4e86\u7a7a\u95f4\u548c\u901a\u9053\u7ea7\u522b\u7684\u7279\u6027\u3002", "result": "\u5728ERA5\u53c2\u8003\u4e0b\uff0cSCAWaveNet\u7684\u5e73\u5747RMSE\u4e3a0.438\u7c73\uff1b\u4f7f\u7528NDBC\u6d6e\u6807\u6570\u636e\u65f6\uff0c\u5e73\u5747RMSE\u4e3a0.432\u7c73\u3002\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u6a21\u578b\uff0c\u5728ERA5\u548cNDBC\u6570\u636e\u96c6\u4e0a\u5206\u522b\u964d\u4f4e\u4e86\u81f3\u5c113.52%\u548c5.47%\u7684\u5e73\u5747RMSE\u3002", "conclusion": "SCAWaveNet\u6709\u6548\u878d\u5408\u4e86\u7a7a\u95f4\u548c\u901a\u9053\u4fe1\u606f\uff0c\u63d0\u5347\u4e86\u663e\u8457\u6ce2\u9ad8\u68c0\u7d22\u7684\u7cbe\u5ea6\uff0c\u5e76\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002"}}
{"id": "2507.00711", "pdf": "https://arxiv.org/pdf/2507.00711", "abs": "https://arxiv.org/abs/2507.00711", "authors": ["Jhouben Cuesta-Ramirez", "Samuel Beaussant", "Mehdi Mounsif"], "title": "Large Reasoning Models are not thinking straight: on the unreliability of thinking trajectories", "categories": ["cs.LG"], "comment": "Accepted to KONVENS 2025", "summary": "Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nrecently achieved impressive results on reasoning benchmarks. Yet, growing\nevidence shows that these models often generate longer but ineffective chains\nof thought (CoTs), calling into question whether benchmark gains reflect real\nreasoning improvements. We present new evidence of overthinking, where models\ndisregard correct solutions even when explicitly provided, instead continuing\nto generate unnecessary reasoning steps that often lead to incorrect\nconclusions. Experiments on three state-of-the-art models using the AIME2024\nmath benchmark reveal critical limitations in these models ability to integrate\ncorrective information, posing new challenges for achieving robust and\ninterpretable reasoning.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u6709\u8bc1\u636e\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u8f83\u957f\u4f46\u65e0\u6548\u7684\u601d\u7ef4\u94fe\uff08CoTs\uff09\uff0c\u8d28\u7591\u57fa\u51c6\u589e\u76ca\u662f\u5426\u53cd\u6620\u771f\u5b9e\u7684\u63a8\u7406\u6539\u8fdb\u3002\u672c\u6587\u63d0\u51fa\u4e86\u8fc7\u5ea6\u601d\u8003\u7684\u65b0\u8bc1\u636e\uff0c\u5176\u4e2d\u6a21\u578b\u5373\u4f7f\u5728\u660e\u786e\u63d0\u4f9b\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u65f6\u4e5f\u4f1a\u5ffd\u7565\u5b83\u4eec\uff0c\u7ee7\u7eed\u751f\u6210\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u6700\u7ec8\u5bfc\u81f4\u9519\u8bef\u7ed3\u8bba\u3002\u4f7f\u7528AIME2024\u6570\u5b66\u57fa\u51c6\u5bf9\u4e09\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8fdb\u884c\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u6574\u5408\u7ea0\u6b63\u4fe1\u606f\u65b9\u9762\u7684\u91cd\u8981\u5c40\u9650\u6027\uff0c\u4e3a\u5b9e\u73b0\u5f3a\u5927\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u751f\u6210\u7684\u601d\u7ef4\u94fe\u53ef\u80fd\u65e0\u6548\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u53ca\u6539\u8fdb\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u5bf9\u4e09\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528AIME2024\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u89c2\u5bdf\u6a21\u578b\u5728\u9762\u5bf9\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u65f6\u7684\u884c\u4e3a\uff0c\u5e76\u5206\u6790\u5176\u751f\u6210\u7684\u63a8\u7406\u6b65\u9aa4\u53ca\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u6574\u5408\u7ea0\u6b63\u4fe1\u606f\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5373\u5373\u4f7f\u63d0\u4f9b\u4e86\u6b63\u786e\u7b54\u6848\uff0c\u6a21\u578b\u4ecd\u4f1a\u7ee7\u7eed\u751f\u6210\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u6b65\u9aa4\u5e76\u5f97\u51fa\u9519\u8bef\u7ed3\u8bba\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u5176\u63a8\u7406\u80fd\u529b\u7684\u771f\u5b9e\u63d0\u5347\u63d0\u51fa\u4e86\u8d28\u7591\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u51fa\u4e86\u65b0\u65b9\u5411\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5f3a\u5927\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u3002"}}
{"id": "2507.00733", "pdf": "https://arxiv.org/pdf/2507.00733", "abs": "https://arxiv.org/abs/2507.00733", "authors": ["Stefan Haas", "Eyke H\u00fcllermeier"], "title": "Aleatoric and Epistemic Uncertainty Measures for Ordinal Classification through Binary Reduction", "categories": ["cs.LG"], "comment": null, "summary": "Ordinal classification problems, where labels exhibit a natural order, are\nprevalent in high-stakes fields such as medicine and finance. Accurate\nuncertainty quantification, including the decomposition into aleatoric\n(inherent variability) and epistemic (lack of knowledge) components, is crucial\nfor reliable decision-making. However, existing research has primarily focused\non nominal classification and regression. In this paper, we introduce a novel\nclass of measures of aleatoric and epistemic uncertainty in ordinal\nclassification, which is based on a suitable reduction to (entropy- and\nvariance-based) measures for the binary case. These measures effectively\ncapture the trade-off in ordinal classification between exact hit-rate and\nminimial error distances. We demonstrate the effectiveness of our approach on\nvarious tabular ordinal benchmark datasets using ensembles of gradient-boosted\ntrees and multi-layer perceptrons for approximate Bayesian inference. Our\nmethod significantly outperforms standard and label-wise entropy and\nvariance-based measures in error detection, as indicated by misclassification\nrates and mean absolute error. Additionally, the ordinal measures show\ncompetitive performance in out-of-distribution (OOD) detection. Our findings\nhighlight the importance of considering the ordinal nature of classification\nproblems when assessing uncertainty.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e8f\u6570\u5206\u7c7b\u4e2d\u4e0d\u786e\u5b9a\u6027\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5206\u89e3\u968f\u673a\u6027\u548c\u8ba4\u77e5\u6027\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u5206\u5e03\u5916\u68c0\u6d4b\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5e8f\u6570\u5206\u7c7b\u95ee\u9898\u5728\u533b\u5b66\u548c\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u5f88\u5e38\u89c1\uff0c\u800c\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6807\u79f0\u5206\u7c7b\u548c\u56de\u5f52\u4e0a\uff0c\u7f3a\u4e4f\u5bf9\u5e8f\u6570\u5206\u7c7b\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u7c7b\u57fa\u4e8e\u4e8c\u5143\u60c5\u51b5\u4e0b\u71b5\u548c\u65b9\u5dee\u7684\u5e8f\u6570\u5206\u7c7b\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u6355\u6349\u7cbe\u786e\u547d\u4e2d\u7387\u4e0e\u6700\u5c0f\u8bef\u5dee\u8ddd\u79bb\u4e4b\u95f4\u7684\u6743\u8861\u6765\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u3002\u4f7f\u7528\u68af\u5ea6\u63d0\u5347\u6811\u548c\u591a\u5c42\u611f\u77e5\u5668\u96c6\u6210\u8fdb\u884c\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u7406\u3002", "result": "\u76f8\u6bd4\u6807\u51c6\u548c\u6807\u7b7e\u7ea7\u71b5\u53ca\u65b9\u5dee\u57fa\u7ebf\u65b9\u6cd5\uff0c\u65b0\u65b9\u6cd5\u5728\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5206\u5e03\u5916\u68c0\u6d4b\u4e0a\u4e5f\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "conclusion": "\u8003\u8651\u5e8f\u6570\u5206\u7c7b\u95ee\u9898\u4e2d\u7684\u5e8f\u6027\u8d28\u5bf9\u4e8e\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\uff0c\u6240\u63d0\u51fa\u7684\u5e8f\u6570\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.00742", "pdf": "https://arxiv.org/pdf/2507.00742", "abs": "https://arxiv.org/abs/2507.00742", "authors": ["Carlos Caminha", "Maria de Lourdes M. Silva", "Iago C. Chaves", "Felipe T. Brito", "Victor A. E. Farias", "Javam C. Machado"], "title": "Evaluating LLMs and Prompting Strategies for Automated Hardware Diagnosis from Textual User-Reports", "categories": ["cs.LG"], "comment": "To be published in the Proceedings of the Brazilian Integrated\n  Software and Hardware Seminar 2025 (SEMISH 2025)", "summary": "Computer manufacturers offer platforms for users to describe device faults\nusing textual reports such as \"My screen is flickering\". Identifying the faulty\ncomponent from the report is essential for automating tests and improving user\nexperience. However, such reports are often ambiguous and lack detail, making\nthis task challenging. Large Language Models (LLMs) have shown promise in\naddressing such issues. This study evaluates 27 open-source models (1B-72B\nparameters) and 2 proprietary LLMs using four prompting strategies: Zero-Shot,\nFew-Shot, Chain-of-Thought (CoT), and CoT+Few-Shot (CoT+FS). We conducted\n98,948 inferences, processing over 51 million input tokens and generating 13\nmillion output tokens. We achieve f1-score up to 0.76. Results show that three\nmodels offer the best balance between size and performance:\nmistral-small-24b-instruct and two smaller models, llama-3.2-1b-instruct and\ngemma-2-2b-it, that offer competitive performance with lower VRAM usage,\nenabling efficient inference on end-user devices as modern laptops or\nsmartphones with NPUs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u7528\u6237\u63d0\u4ea4\u7684\u8bbe\u5907\u6545\u969c\u6587\u672c\u62a5\u544a\u4e2d\u8bc6\u522b\u6545\u969c\u7ec4\u4ef6\u7684\u95ee\u9898\u3002\u7814\u7a76\u8bc4\u4f30\u4e8627\u4e2a\u5f00\u6e90\u6a21\u578b\u548c2\u4e2a\u4e13\u6709LLMs\uff0c\u4f7f\u7528\u4e86\u56db\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u8fdb\u884c\u4e86\u5927\u91cf\u63a8\u7406\u5b9e\u9a8c\u3002\u6700\u7ec8\u53d1\u73b0\u4e09\u4e2a\u6a21\u578b\u5728\u5927\u5c0f\u548c\u6027\u80fd\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u80fd\u591f\u5728\u73b0\u4ee3\u7b14\u8bb0\u672c\u7535\u8111\u6216\u667a\u80fd\u624b\u673a\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u7528\u6237\u901a\u8fc7\u6587\u672c\u62a5\u544a\u63cf\u8ff0\u8bbe\u5907\u6545\u969c\u65f6\uff0c\u8fd9\u4e9b\u62a5\u544a\u901a\u5e38\u6a21\u7cca\u4e14\u7f3a\u4e4f\u7ec6\u8282\uff0c\u5bfc\u81f4\u96be\u4ee5\u81ea\u52a8\u8bc6\u522b\u6545\u969c\u7ec4\u4ef6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u663e\u793a\u51fa\u4e86\u89e3\u51b3\u8fd9\u79cd\u95ee\u9898\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e8627\u4e2a\u5f00\u6e90\u6a21\u578b\u548c2\u4e2a\u4e13\u6709LLMs\uff0c\u53c2\u6570\u8303\u56f4\u4ece1B\u523072B\u3002\u91c7\u7528\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff1aZero-Shot\u3001Few-Shot\u3001Chain-of-Thought (CoT) \u548c CoT+Few-Shot (CoT+FS)\u3002\u901a\u8fc7\u8fd9\u4e9b\u7b56\u7565\uff0c\u8fdb\u884c\u4e8698,948\u6b21\u63a8\u7406\u5b9e\u9a8c\uff0c\u5904\u7406\u4e86\u8d85\u8fc75100\u4e07\u4e2a\u8f93\u5165\u6807\u8bb0\u5e76\u751f\u6210\u4e861300\u4e07\u4e2a\u8f93\u51fa\u6807\u8bb0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u67d0\u4e9b\u6a21\u578b\u5728\u6027\u80fd\u548c\u89c4\u6a21\u4e4b\u95f4\u8fbe\u5230\u4e86\u826f\u597d\u7684\u5e73\u8861\u3002\u4f8b\u5982\uff0cmistral-small-24b-instruct\u8868\u73b0\u51fa\u8272\uff0c\u800cllama-3.2-1b-instruct\u548cgemma-2-2b-it\u5219\u4ee5\u8f83\u4f4e\u7684VRAM\u4f7f\u7528\u7387\u63d0\u4f9b\u4e86\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u9002\u5408\u5728\u7aef\u7528\u6237\u8bbe\u5907\u4e0a\u8fdb\u884c\u9ad8\u6548\u63a8\u7406\u3002f1\u5206\u6570\u6700\u9ad8\u53ef\u8fbe0.76\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u7279\u5b9a\u7684LLMs\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u6a21\u7cca\u7684\u7528\u6237\u62a5\u544a\u4e2d\u8bc6\u522b\u51fa\u8bbe\u5907\u6545\u969c\u7ec4\u4ef6\u3002\u7279\u522b\u5730\uff0c\u4e00\u4e9b\u8f83\u5c0f\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u975e\u5e38\u9002\u5408\u5728\u73b0\u4ee3\u7b14\u8bb0\u672c\u7535\u8111\u6216\u667a\u80fd\u624b\u673a\u7b49\u7aef\u7528\u6237\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2507.00761", "pdf": "https://arxiv.org/pdf/2507.00761", "abs": "https://arxiv.org/abs/2507.00761", "authors": ["Wenbo Yu", "Anirbit Ghosh", "Tobias Sebastian Finn", "Rossella Arcucci", "Marc Bocquet", "Sibo Cheng"], "title": "A Probabilistic Approach to Wildfire Spread Prediction Using a Denoising Diffusion Surrogate Model", "categories": ["cs.LG"], "comment": null, "summary": "Thanks to recent advances in generative AI, computers can now simulate\nrealistic and complex natural processes. We apply this capability to predict\nhow wildfires spread, a task made difficult by the unpredictable nature of fire\nand the variety of environmental conditions it depends on. In this study, We\npresent the first denoising diffusion model for predicting wildfire spread, a\nnew kind of AI framework that learns to simulate fires not just as one fixed\noutcome, but as a range of possible scenarios. By doing so, it accounts for the\ninherent uncertainty of wildfire dynamics, a feature that traditional models\ntypically fail to represent. Unlike deterministic approaches that generate a\nsingle prediction, our model produces ensembles of forecasts that reflect\nphysically meaningful distributions of where fire might go next. This\ntechnology could help us develop smarter, faster, and more reliable tools for\nanticipating wildfire behavior, aiding decision-makers in fire risk assessment\nand response planning.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7528\u4e8e\u6a21\u62df\u590d\u6742\u81ea\u7136\u8fc7\u7a0b\uff0c\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u53bb\u566a\u6269\u6563\u6a21\u578b\u9884\u6d4b\u91ce\u706b\u8513\u5ef6\uff0c\u8003\u8651\u4e86\u91ce\u706b\u52a8\u6001\u7684\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u4ea7\u751f\u4e00\u7cfb\u5217\u53ef\u80fd\u7684\u60c5\u666f\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u706b\u707e\u98ce\u9669\u8bc4\u4f30\u548c\u54cd\u5e94\u89c4\u5212\u3002", "motivation": "\u5f53\u524d\u9884\u6d4b\u91ce\u706b\u4f20\u64ad\u56f0\u96be\uff0c\u56e0\u5176\u4e0d\u53ef\u9884\u6d4b\u6027\u53ca\u4f9d\u8d56\u591a\u6837\u7684\u73af\u5883\u6761\u4ef6\uff0c\u4f20\u7edf\u6a21\u578b\u901a\u5e38\u65e0\u6cd5\u8868\u793a\u91ce\u706b\u52a8\u6001\u7684\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u53bb\u566a\u6269\u6563\u6a21\u578b\uff0c\u5b66\u4e60\u6a21\u62df\u91ce\u706b\u4f20\u64ad\uff0c\u4e0d\u4ec5\u4f5c\u4e3a\u5355\u4e00\u56fa\u5b9a\u7ed3\u679c\uff0c\u800c\u662f\u4f5c\u4e3a\u4e00\u7cfb\u5217\u53ef\u80fd\u60c5\u666f\uff0c\u53cd\u6620\u7269\u7406\u4e0a\u6709\u610f\u4e49\u7684\u5206\u5e03\u3002", "result": "\u6a21\u578b\u80fd\u591f\u751f\u6210\u53cd\u6620\u91ce\u706b\u53ef\u80fd\u4f20\u64ad\u4f4d\u7f6e\u7684\u7269\u7406\u6709\u610f\u4e49\u5206\u5e03\u7684\u9884\u6d4b\u96c6\u5408\uff0c\u76f8\u6bd4\u786e\u5b9a\u6027\u65b9\u6cd5\u66f4\u53ef\u9760\u3002", "conclusion": "\u8be5\u6280\u672f\u53ef\u5e2e\u52a9\u5f00\u53d1\u66f4\u667a\u80fd\u3001\u66f4\u5feb\u3001\u66f4\u53ef\u9760\u7684\u5de5\u5177\u6765\u9884\u6d4b\u91ce\u706b\u884c\u4e3a\uff0c\u8f85\u52a9\u51b3\u7b56\u8005\u8fdb\u884c\u706b\u707e\u98ce\u9669\u8bc4\u4f30\u548c\u54cd\u5e94\u89c4\u5212\u3002"}}
{"id": "2507.00762", "pdf": "https://arxiv.org/pdf/2507.00762", "abs": "https://arxiv.org/abs/2507.00762", "authors": ["Tom Maus", "Asma Atamna", "Tobias Glasmachers"], "title": "Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments", "categories": ["cs.LG"], "comment": "This article has been submitted to and accepted for presentation at\n  the 11th International Conference on Machine Learning, Optimization, and Data\n  Science (LOD 2025). After publication, it will appear in the official LOD\n  2025 proceedings", "summary": "Reinforcement Learning (RL) has demonstrated significant potential in certain\nreal-world industrial applications, yet its broader deployment remains limited\nby inherent challenges such as sample inefficiency and unstable learning\ndynamics. This study investigates the utilization of Genetic Algorithms (GAs)\nas a mechanism for improving RL performance in an industrially inspired sorting\nenvironment. We propose a novel approach in which GA-generated expert\ndemonstrations are used to enhance policy learning. These demonstrations are\nincorporated into a Deep Q-Network (DQN) replay buffer for experience-based\nlearning and utilized as warm-start trajectories for Proximal Policy\nOptimization (PPO) agents to accelerate training convergence. Our experiments\ncompare standard RL training with rule-based heuristics, brute-force\noptimization, and demonstration data, revealing that GA-derived demonstrations\nsignificantly improve RL performance. Notably, PPO agents initialized with\nGA-generated data achieved superior cumulative rewards, highlighting the\npotential of hybrid learning paradigms, where heuristic search methods\ncomplement data-driven RL. The utilized framework is publicly available and\nenables further research into adaptive RL strategies for real-world\napplications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5de5\u4e1a\u542f\u53d1\u7684\u6392\u5e8f\u73af\u5883\u4e2d\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\uff08GAs\uff09\u6765\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6027\u80fd\u7684\u65b9\u6cd5\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5c06GA\u751f\u6210\u7684\u4e13\u5bb6\u6f14\u793a\u6574\u5408\u5230DQN\u91cd\u653e\u7f13\u51b2\u533a\u4e2d\uff0c\u5e76\u4f5c\u4e3aPPO\u4ee3\u7406\u7684\u9884\u70ed\u8f68\u8ff9\uff0c\u4ee5\u52a0\u901f\u8bad\u7ec3\u6536\u655b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGA\u751f\u6210\u7684\u6f14\u793a\u663e\u8457\u63d0\u9ad8\u4e86RL\u6027\u80fd\uff0c\u7279\u522b\u662fPPO\u4ee3\u7406\u5728GA\u751f\u6210\u7684\u6570\u636e\u521d\u59cb\u5316\u540e\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u7d2f\u79ef\u5956\u52b1\uff0c\u5c55\u793a\u4e86\u6df7\u5408\u5b66\u4e60\u8303\u5f0f\u7684\u6f5c\u529b\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u67d0\u4e9b\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5e7f\u6cdb\u5e94\u7528\u53d7\u9650\u4e8e\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u548c\u5b66\u4e60\u52a8\u6001\u4e0d\u7a33\u5b9a\u7b49\u56fa\u6709\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5bfb\u627e\u6539\u8fdbRL\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u4e13\u5bb6\u6f14\u793a\u6570\u636e\uff0c\u5e76\u5c06\u5176\u7528\u4e8e\u589e\u5f3a\u7b56\u7565\u5b66\u4e60\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8fd9\u4e9b\u6f14\u793a\u88ab\u6574\u5408\u5230Deep Q-Network\u7684\u91cd\u653e\u7f13\u51b2\u533a\u4e2d\u8fdb\u884c\u7ecf\u9a8c\u5b66\u4e60\uff0c\u540c\u65f6\u7528\u4f5cProximal Policy Optimization\u4ee3\u7406\u7684\u9884\u70ed\u8f68\u8ff9\u4ee5\u52a0\u901f\u8bad\u7ec3\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u6807\u51c6RL\u8bad\u7ec3\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u3001\u66b4\u529b\u4f18\u5316\u548c\u6f14\u793a\u6570\u636e\u7684\u7ed3\u679c\uff0c\u53d1\u73b0GA\u751f\u6210\u7684\u6f14\u793a\u663e\u8457\u63d0\u9ad8\u4e86RL\u6027\u80fd\u3002\u7279\u522b\u662f\uff0c\u4f7f\u7528GA\u751f\u6210\u7684\u6570\u636e\u521d\u59cb\u5316\u7684PPO\u4ee3\u7406\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u7d2f\u79ef\u5956\u52b1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u7684\u6f14\u793a\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002\u8fd9\u7a81\u663e\u4e86\u6df7\u5408\u5b66\u4e60\u8303\u5f0f\u7684\u6f5c\u529b\uff0c\u5176\u4e2d\u542f\u53d1\u5f0f\u641c\u7d22\u65b9\u6cd5\u53ef\u4ee5\u8865\u5145\u6570\u636e\u9a71\u52a8\u7684RL\u3002"}}
{"id": "2507.00846", "pdf": "https://arxiv.org/pdf/2507.00846", "abs": "https://arxiv.org/abs/2507.00846", "authors": ["Rishal Aggrwal", "Jacky Chen", "Nicholas M. Boffi", "David Ryan Koes"], "title": "BoltzNCE: Learning Likelihoods for Boltzmann Generation with Stochastic Interpolants and Noise Contrastive Estimation", "categories": ["cs.LG", "physics.bio-ph"], "comment": "19 pages, 25 figures, submitted to NeurIPS 2025", "summary": "Efficient sampling from the Boltzmann distribution defined by an energy\nfunction is a key challenge in modeling physical systems such as molecules.\nBoltzmann Generators tackle this by leveraging Continuous Normalizing Flows\nthat transform a simple prior into a distribution that can be reweighted to\nmatch the Boltzmann distribution using sample likelihoods. However, obtaining\nlikelihoods requires computing costly Jacobians during integration, making it\nimpractical for large molecular systems. To overcome this, we propose learning\nthe likelihood of the generated distribution via an energy-based model trained\nwith noise contrastive estimation and score matching. By using stochastic\ninterpolants to anneal between the prior and generated distributions, we\ncombine both the objective functions to efficiently learn the density function.\nOn the alanine dipeptide system, we demonstrate that our method yields free\nenergy profiles and energy distributions comparable to those obtained with\nexact likelihoods. Additionally, we show that free energy differences between\nmetastable states can be estimated accurately with orders-of-magnitude speedup.", "AI": {"tldr": "\u901a\u8fc7\u80fd\u91cf\u6a21\u578b\u548c\u968f\u673a\u63d2\u503c\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u8ba1\u7b97\u6602\u8d35\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u4ece\u800c\u5728\u5206\u5b50\u7cfb\u7edf\u4e2d\u6709\u6548\u751f\u6210\u63a5\u8fd1\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u7684\u6837\u672c\uff0c\u5e76\u663e\u8457\u52a0\u901f\u81ea\u7531\u80fd\u5dee\u5f02\u8ba1\u7b97\u3002", "motivation": "\u4ece\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u4e2d\u9ad8\u6548\u91c7\u6837\u5bf9\u4e8e\u5efa\u6a21\u7269\u7406\u7cfb\u7edf\uff08\u5982\u5206\u5b50\uff09\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u56e0\u9700\u8981\u8ba1\u7b97\u6602\u8d35\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u800c\u4e0d\u9002\u7528\u4e8e\u5927\u578b\u5206\u5b50\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u80fd\u91cf\u6a21\u578b\u548c\u968f\u673a\u63d2\u503c\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u548c\u5f97\u5206\u5339\u914d\u8bad\u7ec3\u80fd\u91cf\u6a21\u578b\u4ee5\u5b66\u4e60\u751f\u6210\u5206\u5e03\u7684\u4f3c\u7136\u6027\uff0c\u540c\u65f6\u5229\u7528\u968f\u673a\u63d2\u503c\u5728\u5148\u9a8c\u548c\u751f\u6210\u5206\u5e03\u4e4b\u95f4\u8fdb\u884c\u9000\u706b\uff0c\u7ed3\u5408\u4e24\u79cd\u76ee\u6807\u51fd\u6570\u4ee5\u9ad8\u6548\u5b66\u4e60\u5bc6\u5ea6\u51fd\u6570\u3002", "result": "\u5728\u4e19\u6c28\u9178\u4e8c\u80bd\u7cfb\u7edf\u4e0a\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u81ea\u7531\u80fd\u66f2\u7ebf\u548c\u80fd\u91cf\u5206\u5e03\u4e0e\u4f7f\u7528\u7cbe\u786e\u4f3c\u7136\u6027\u83b7\u5f97\u7684\u7ed3\u679c\u76f8\u5f53\uff0c\u5e76\u4e14\u80fd\u591f\u4ee5\u6570\u91cf\u7ea7\u7684\u901f\u5ea6\u63d0\u5347\u51c6\u786e\u4f30\u8ba1\u4e9a\u7a33\u6001\u4e4b\u95f4\u7684\u81ea\u7531\u80fd\u5dee\u5f02\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u74f6\u9888\uff0c\u4e3a\u5927\u578b\u5206\u5b50\u7cfb\u7edf\u7684\u9ad8\u6548\u91c7\u6837\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.00848", "pdf": "https://arxiv.org/pdf/2507.00848", "abs": "https://arxiv.org/abs/2507.00848", "authors": ["Don Roosan", "Saif Nirzhor", "Rubayat Khan", "Fahmida Hai", "Mohammad Rifat Haidar"], "title": "Quantum Approximate Optimization Algorithm for Spatiotemporal Forecasting of HIV Clusters", "categories": ["cs.LG", "q-bio.MN"], "comment": "Conference details can be found here:\n  https://www.insticc.org/node/technicalprogram/DATA/2025", "summary": "HIV epidemiological data is increasingly complex, requiring advanced\ncomputation for accurate cluster detection and forecasting. We employed\nquantum-accelerated machine learning to analyze HIV prevalence at the ZIP-code\nlevel using AIDSVu and synthetic SDoH data for 2022. Our approach compared\nclassical clustering (DBSCAN, HDBSCAN) with a quantum approximate optimization\nalgorithm (QAOA), developed a hybrid quantum-classical neural network for HIV\nprevalence forecasting, and used quantum Bayesian networks to explore causal\nlinks between SDoH factors and HIV incidence. The QAOA-based method achieved\n92% accuracy in cluster detection within 1.6 seconds, outperforming classical\nalgorithms. Meanwhile, the hybrid quantum-classical neural network predicted\nHIV prevalence with 94% accuracy, surpassing a purely classical counterpart.\nQuantum Bayesian analysis identified housing instability as a key driver of HIV\ncluster emergence and expansion, with stigma exerting a geographically variable\ninfluence. These quantum-enhanced methods deliver greater precision and\nefficiency in HIV surveillance while illuminating critical causal pathways.\nThis work can guide targeted interventions, optimize resource allocation for\nPrEP, and address structural inequities fueling HIV transmission.", "AI": {"tldr": "\u8bba\u6587\u5229\u7528\u91cf\u5b50\u52a0\u901f\u673a\u5668\u5b66\u4e60\u5206\u6790\u4e86HIV\u6d41\u884c\u75c5\u5b66\u6570\u636e\uff0c\u5c55\u793a\u4e86\u66f4\u9ad8\u7684\u805a\u7c7b\u68c0\u6d4b\u548c\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u5173\u952e\u7684\u793e\u4f1a\u51b3\u5b9a\u56e0\u7d20\u3002", "motivation": "HIV\u6d41\u884c\u75c5\u5b66\u6570\u636e\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u8ba1\u7b97\u65b9\u6cd5\u6765\u8fdb\u884c\u7cbe\u786e\u7684\u96c6\u7fa4\u68c0\u6d4b\u548c\u9884\u6d4b\u3002", "method": "\u6bd4\u8f83\u7ecf\u5178\u805a\u7c7b\u7b97\u6cd5\u4e0e\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\uff0c\u5f00\u53d1\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u8fdb\u884cHIV\u6d41\u884c\u7387\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u91cf\u5b50\u8d1d\u53f6\u65af\u7f51\u7edc\u63a2\u7d22\u793e\u4f1a\u51b3\u5b9a\u56e0\u7d20\u4e0eHIV\u53d1\u75c5\u7387\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "QAOA\u65b9\u6cd5\u57281.6\u79d2\u5185\u8fbe\u5230\u4e8692%\u7684\u805a\u7c7b\u68c0\u6d4b\u51c6\u786e\u5ea6\uff0c\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u9884\u6d4bHIV\u6d41\u884c\u7387\u8fbe\u523094%\u7684\u51c6\u786e\u5ea6\uff0c\u91cf\u5b50\u8d1d\u53f6\u65af\u5206\u6790\u786e\u5b9a\u4f4f\u623f\u4e0d\u7a33\u5b9a\u662fHIV\u96c6\u7fa4\u51fa\u73b0\u548c\u6269\u5c55\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u91cf\u5b50\u589e\u5f3a\u65b9\u6cd5\u63d0\u9ad8\u4e86HIV\u76d1\u6d4b\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u63ed\u793a\u4e86\u5173\u952e\u56e0\u679c\u9014\u5f84\uff0c\u53ef\u6307\u5bfc\u76ee\u6807\u5e72\u9884\u3001\u4f18\u5316PrEP\u8d44\u6e90\u5206\u914d\u5e76\u89e3\u51b3\u63a8\u52a8HIV\u4f20\u64ad\u7684\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u3002"}}
{"id": "2507.00851", "pdf": "https://arxiv.org/pdf/2507.00851", "abs": "https://arxiv.org/abs/2507.00851", "authors": ["Rares Cristian", "Pavithra Harsha", "Georgia Perakis", "Brian Quanz"], "title": "Aligning Learning and Endogenous Decision-Making", "categories": ["cs.LG"], "comment": null, "summary": "Many of the observations we make are biased by our decisions. For instance,\nthe demand of items is impacted by the prices set, and online checkout choices\nare influenced by the assortments presented. The challenge in decision-making\nunder this setting is the lack of counterfactual information, and the need to\nlearn it instead. We introduce an end-to-end method under endogenous\nuncertainty to train ML models to be aware of their downstream, enabling their\neffective use in the decision-making stage. We further introduce a robust\noptimization variant that accounts for uncertainty in ML models -- specifically\nby constructing uncertainty sets over the space of ML models and optimizing\nactions to protect against worst-case predictions. We prove guarantees that\nthis robust approach can capture near-optimal decisions with high probability\nas a function of data. Besides this, we also introduce a new class of two-stage\nstochastic optimization problems to the end-to-end learning framework that can\nnow be addressed through our framework. Here, the first stage is an\ninformation-gathering problem to decide which random variable to poll and gain\ninformation about before making a second-stage decision based off of it. We\npresent several computational experiments for pricing and inventory\nassortment/recommendation problems. We compare against existing methods in\nonline learning/bandits/offline reinforcement learning and show our approach\nhas consistent improved performance over these. Just as in the endogenous\nsetting, the model's prediction also depends on the first-stage decision made.\nWhile this decision does not affect the random variable in this setting, it\ndoes affect the correct point forecast that should be made.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u5185\u751f\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u65b9\u6cd5\u53ca\u9c81\u68d2\u4f18\u5316\u53d8\u4f53\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u968f\u673a\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4fe1\u606f\u6536\u96c6\u4e0e\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u5728\u5b9a\u4ef7\u548c\u5e93\u5b58\u9009\u62e9\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u8bb8\u591a\u89c2\u5bdf\u7ed3\u679c\u53d7\u5230\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u4f8b\u5982\u7269\u54c1\u9700\u6c42\u53d7\u4ef7\u683c\u5f71\u54cd\uff0c\u7ebf\u4e0a\u7ed3\u7b97\u9009\u62e9\u53d7\u9648\u5217\u9009\u9879\u5f71\u54cd\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u51b3\u7b56\u7f3a\u4e4f\u53cd\u4e8b\u5b9e\u4fe1\u606f\uff0c\u9700\u8981\u5b66\u4e60\u8fd9\u4e9b\u4fe1\u606f\u4ee5\u652f\u6301\u51b3\u7b56\u3002\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u8003\u8651\u8fd9\u79cd\u5185\u751f\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u5728\u5185\u751f\u4e0d\u786e\u5b9a\u6027\u4e0b\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u63d0\u9ad8\u5176\u5728\u51b3\u7b56\u9636\u6bb5\u7684\u6709\u6548\u6027\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u4e2a\u9c81\u68d2\u4f18\u5316\u53d8\u4f53\uff0c\u901a\u8fc7\u6784\u5efaML\u6a21\u578b\u7a7a\u95f4\u4e0a\u7684\u4e0d\u786e\u5b9a\u6027\u96c6\u6765\u4f18\u5316\u884c\u52a8\uff0c\u4ee5\u5e94\u5bf9\u6700\u574f\u60c5\u51b5\u7684\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u7c7b\u65b0\u7684\u4e24\u9636\u6bb5\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u5176\u4e2d\u7b2c\u4e00\u9636\u6bb5\u4e3a\u4fe1\u606f\u6536\u96c6\u95ee\u9898\uff0c\u51b3\u5b9a\u5bf9\u54ea\u4e2a\u968f\u673a\u53d8\u91cf\u8fdb\u884c\u91c7\u6837\u4ee5\u83b7\u53d6\u4fe1\u606f\uff0c\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u8fd9\u4e9b\u4fe1\u606f\u505a\u51fa\u51b3\u7b56\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u8be5\u9c81\u68d2\u65b9\u6cd5\u80fd\u591f\u5728\u9ad8\u6982\u7387\u4e0b\u6355\u83b7\u63a5\u8fd1\u6700\u4f18\u7684\u51b3\u7b56\u3002\u8ba1\u7b97\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9a\u4ef7\u548c\u5e93\u5b58\u9009\u62e9/\u63a8\u8350\u95ee\u9898\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u76f8\u8f83\u4e8e\u5728\u7ebf\u5b66\u4e60\u3001\u591a\u81c2\u8001\u864e\u673a\u548c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b49\u73b0\u6709\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u4e86\u66f4\u4e00\u81f4\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5185\u751f\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9c81\u68d2\u4f18\u5316\u65b9\u6cd5\u786e\u4fdd\u5728\u9ad8\u6982\u7387\u4e0b\u83b7\u5f97\u63a5\u8fd1\u6700\u4f18\u7684\u51b3\u7b56\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e24\u9636\u6bb5\u968f\u673a\u4f18\u5316\u95ee\u9898\u7684\u65b0\u7c7b\u522b\uff0c\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86\u6846\u67b6\u7684\u5e94\u7528\u8303\u56f4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u4ef7\u548c\u5e93\u5b58\u9009\u62e9\u7b49\u95ee\u9898\u4e0a\u5177\u6709\u66f4\u4e00\u81f4\u7684\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2507.00862", "pdf": "https://arxiv.org/pdf/2507.00862", "abs": "https://arxiv.org/abs/2507.00862", "authors": ["Davide Andreoletti", "Aris Marcolongo", "Natasa Sarafijanovic Djukic", "Julien Roulet", "Stefano Billeter", "Andrzej Kurenda", "Margot Visse-Mansiaux", "Brice Dupuis", "Carrol Annette Plummer", "Beatrice Paoli", "Omran Ayoub"], "title": "Machine Learning-based Early Detection of Potato Sprouting Using Electrophysiological Signals", "categories": ["cs.LG"], "comment": "8 pages, 7 figures", "summary": "Accurately predicting potato sprouting before the emergence of any visual\nsigns is critical for effective storage management, as sprouting degrades both\nthe commercial and nutritional value of tubers. Effective forecasting allows\nfor the precise application of anti-sprouting chemicals (ASCs), minimizing\nwaste and reducing costs. This need has become even more pressing following the\nban on Isopropyl N-(3-chlorophenyl) carbamate (CIPC) or Chlorpropham due to\nhealth and environmental concerns, which has led to the adoption of\nsignificantly more expensive alternative ASCs. Existing approaches primarily\nrely on visual identification, which only detects sprouting after morphological\nchanges have occurred, limiting their effectiveness for proactive management. A\nreliable early prediction method is therefore essential to enable timely\nintervention and improve the efficiency of post-harvest storage strategies,\nwhere early refers to detecting sprouting before any visible signs appear. In\nthis work, we address the problem of early prediction of potato sprouting. To\nthis end, we propose a novel machine learning (ML)-based approach that enables\nearly prediction of potato sprouting using electrophysiological signals\nrecorded from tubers using proprietary sensors. Our approach preprocesses the\nrecorded signals, extracts relevant features from the wavelet domain, and\ntrains supervised ML models for early sprouting detection. Additionally, we\nincorporate uncertainty quantification techniques to enhance predictions.\nExperimental results demonstrate promising performance in the early detection\nof potato sprouting by accurately predicting the exact day of sprouting for a\nsubset of potatoes and while showing acceptable average error across all\npotatoes. Despite promising results, further refinements are necessary to\nminimize prediction errors, particularly in reducing the maximum observed\ndeviations.", "AI": {"tldr": "\u51c6\u786e\u9884\u6d4b\u9a6c\u94c3\u85af\u53d1\u82bd\u5bf9\u4e8e\u50a8\u5b58\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u4efb\u4f55\u89c6\u89c9\u8ff9\u8c61\u51fa\u73b0\u4e4b\u524d\u3002\u7531\u4e8e\u5065\u5eb7\u548c\u73af\u5883\u95ee\u9898\uff0cCIPC\u88ab\u7981\u7528\u540e\uff0c\u66ff\u4ee3\u7684\u9632\u53d1\u82bd\u5316\u5b66\u7269\u8d28\uff08ASCs\uff09\u6210\u672c\u663e\u8457\u589e\u52a0\u3002\u76ee\u524d\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u89c6\u89c9\u8bc6\u522b\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u4e3b\u52a8\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u4e13\u6709\u4f20\u611f\u5668\u8bb0\u5f55\u7684\u7535\u751f\u7406\u4fe1\u53f7\u8fdb\u884c\u65e9\u671f\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u5c0f\u6ce2\u57df\u7279\u5f81\u63d0\u53d6\u548c\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u68c0\u6d4b\uff0c\u540c\u65f6\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u90e8\u5206\u9a6c\u94c3\u85af\u4e0a\u80fd\u51c6\u786e\u9884\u6d4b\u53d1\u82bd\u65e5\u671f\uff0c\u4f46\u8fd8\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u51cf\u5c11\u6700\u5927\u504f\u5dee\u3002", "motivation": "\u6709\u6548\u9884\u6d4b\u9a6c\u94c3\u85af\u53d1\u82bd\u5bf9\u4e8e\u4fdd\u6301\u5176\u5546\u4e1a\u548c\u8425\u517b\u4ef7\u503c\u3001\u4f18\u5316\u5b58\u50a8\u7ba1\u7406\u548c\u51cf\u5c11\u6d6a\u8d39\u975e\u5e38\u91cd\u8981\u3002\u968f\u7740CIPC\u7684\u7981\u7528\uff0c\u66f4\u6602\u8d35\u7684ASCs\u88ab\u91c7\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u9760\u7684\u65e9\u671f\u9884\u6d4b\u65b9\u6cd5\u6765\u964d\u4f4e\u5b58\u50a8\u6210\u672c\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e13\u6709\u4f20\u611f\u5668\u8bb0\u5f55\u7684\u7535\u751f\u7406\u4fe1\u53f7\u8fdb\u884c\u65e9\u671f\u9884\u6d4b\u3002\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a\u4fe1\u53f7\u9884\u5904\u7406\u3001\u4ece\u5c0f\u6ce2\u57df\u4e2d\u63d0\u53d6\u76f8\u5173\u7279\u5f81\u3001\u8bad\u7ec3\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u65e9\u671f\u53d1\u82bd\u68c0\u6d4b\uff0c\u5e76\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\u4ee5\u589e\u5f3a\u9884\u6d4b\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u65e9\u671f\u68c0\u6d4b\u9a6c\u94c3\u85af\u53d1\u82bd\u65b9\u9762\u7684\u826f\u597d\u6027\u80fd\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u90e8\u5206\u9a6c\u94c3\u85af\u7684\u53d1\u82bd\u65e5\u671f\uff0c\u5e76\u4e14\u5728\u6574\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u53ef\u63a5\u53d7\u7684\u5e73\u5747\u8bef\u5dee\u3002\u7136\u800c\uff0c\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u51cf\u5c11\u6700\u5927\u9884\u6d4b\u504f\u5dee\u3002", "conclusion": "\u867d\u7136\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u793a\u51fa\u65e9\u671f\u9884\u6d4b\u9a6c\u94c3\u85af\u53d1\u82bd\u7684\u6f5c\u529b\uff0c\u4f46\u5728\u51cf\u5c11\u9884\u6d4b\u8bef\u5dee\u7279\u522b\u662f\u6700\u5927\u504f\u5dee\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u96c6\u4e2d\u5728\u4f18\u5316\u6a21\u578b\u548c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5176\u5728\u66f4\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2507.00899", "pdf": "https://arxiv.org/pdf/2507.00899", "abs": "https://arxiv.org/abs/2507.00899", "authors": ["Carlos Vonessen", "Charles Harris", "Miruna Cretu", "Pietro Li\u00f2"], "title": "TABASCO: A Fast, Simplified Model for Molecular Generation with Improved Physical Quality", "categories": ["cs.LG"], "comment": null, "summary": "State-of-the-art models for 3D molecular generation are based on significant\ninductive biases, SE(3), permutation equivariance to respect symmetry and graph\nmessage-passing networks to capture local chemistry, yet the generated\nmolecules still struggle with physical plausibility. We introduce TABASCO which\nrelaxes these assumptions: The model has a standard non-equivariant transformer\narchitecture, treats atoms in a molecule as sequences and reconstructs bonds\ndeterministically after generation. The absence of equivariant layers and\nmessage passing allows us to significantly simplify the model architecture and\nscale data throughput. On the GEOM-Drugs benchmark TABASCO achieves\nstate-of-the-art PoseBusters validity and delivers inference roughly 10x faster\nthan the strongest baseline, while exhibiting emergent rotational equivariance\ndespite symmetry not being hard-coded. Our work offers a blueprint for training\nminimalist, high-throughput generative models suited to specialised tasks such\nas structure- and pharmacophore-based drug design. We provide a link to our\nimplementation at github.com/carlosinator/tabasco.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTABASCO\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u7b80\u5316\u67b6\u6784\u548c\u975e\u5bf9\u79f0\u7f16\u7801\u65b9\u6cd5\uff0c\u5728GEOM-Drugs\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684PoseBusters\u6709\u6548\u6027\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u6bd4\u6700\u5f3a\u7684\u57fa\u7ebf\u5feb\u7ea610\u500d\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u76843D\u5206\u5b50\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u4e8e\u663e\u8457\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u5982SE(3)\u3001\u7f6e\u6362\u7b49\u53d8\u6027\u4ee5\u5c0a\u91cd\u5bf9\u79f0\u6027\u548c\u56fe\u6d88\u606f\u4f20\u9012\u7f51\u7edc\u4ee5\u6355\u6349\u5c40\u90e8\u5316\u5b66\u6027\u8d28\uff0c\u4f46\u751f\u6210\u7684\u5206\u5b50\u5728\u7269\u7406\u5408\u7406\u6027\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u6311\u6218\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65b0\u6a21\u578b\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u751f\u6210\u66f4\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u7684\u5206\u5b50\u3002", "method": "\u5f15\u5165\u4e86TABASCO\u6a21\u578b\uff0c\u5176\u91c7\u7528\u6807\u51c6\u7684\u975e\u7b49\u53d8\u53d8\u538b\u5668\u67b6\u6784\uff0c\u5c06\u5206\u5b50\u4e2d\u7684\u539f\u5b50\u89c6\u4e3a\u5e8f\u5217\uff0c\u5e76\u5728\u751f\u6210\u540e\u786e\u5b9a\u6027\u5730\u91cd\u5efa\u952e\u3002\u8be5\u6a21\u578b\u53bb\u9664\u4e86\u7b49\u53d8\u5c42\u548c\u6d88\u606f\u4f20\u9012\uff0c\u4ece\u800c\u6781\u5927\u5730\u7b80\u5316\u4e86\u6a21\u578b\u67b6\u6784\u5e76\u63d0\u9ad8\u4e86\u6570\u636e\u541e\u5410\u91cf\u3002", "result": "\u5728GEOM-Drugs\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTABASCO\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684PoseBusters\u6709\u6548\u6027\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5feb\u7ea610\u500d\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u5c3d\u7ba1\u672a\u786c\u7f16\u7801\u5bf9\u79f0\u6027\u5374\u5177\u6709\u51fa\u73b0\u65cb\u8f6c\u7b49\u53d8\u6027\u7684\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bad\u7ec3\u6781\u7b80\u4e3b\u4e49\u3001\u9ad8\u541e\u5410\u91cf\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u84dd\u56fe\uff0c\u8fd9\u4e9b\u6a21\u578b\u9002\u5408\u8bf8\u5982\u57fa\u4e8e\u7ed3\u6784\u548c\u836f\u6548\u56e2\u7684\u836f\u7269\u8bbe\u8ba1\u7b49\u4e13\u95e8\u4efb\u52a1\u3002"}}
{"id": "2507.00920", "pdf": "https://arxiv.org/pdf/2507.00920", "abs": "https://arxiv.org/abs/2507.00920", "authors": ["Dang Qua Nguyen", "Morteza Hashemi", "Erik Perrins", "Sergiy A. Vorobyov", "David J. Love", "Taejoon Kim"], "title": "Privacy-Preserving Quantized Federated Learning with Diverse Precision", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for distributed\nmachine learning, enabling collaborative training of a global model across\nmultiple local devices without requiring them to share raw data. Despite its\nadvancements, FL is limited by factors such as: (i) privacy risks arising from\nthe unprotected transmission of local model updates to the fusion center (FC)\nand (ii) decreased learning utility caused by heterogeneity in model\nquantization resolution across participating devices. Prior work typically\naddresses only one of these challenges because maintaining learning utility\nunder both privacy risks and quantization heterogeneity is a non-trivial task.\nIn this paper, our aim is therefore to improve the learning utility of a\nprivacy-preserving FL that allows clusters of devices with different\nquantization resolutions to participate in each FL round. Specifically, we\nintroduce a novel stochastic quantizer (SQ) that is designed to simultaneously\nachieve differential privacy (DP) and minimum quantization error. Notably, the\nproposed SQ guarantees bounded distortion, unlike other DP approaches. To\naddress quantization heterogeneity, we introduce a cluster size optimization\ntechnique combined with a linear fusion approach to enhance model aggregation\naccuracy. Numerical simulations validate the benefits of our approach in terms\nof privacy protection and learning utility compared to the conventional\nLaplaceSQ-FL algorithm.", "AI": {"tldr": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u8303\u5f0f\uff0c\u4f46\u5b58\u5728\u9690\u79c1\u98ce\u9669\u548c\u6a21\u578b\u91cf\u5316\u5f02\u8d28\u6027\u7b49\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u968f\u673a\u91cf\u5316\u5668\uff08SQ\uff09\uff0c\u53ef\u4ee5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u6700\u5c0f\u5316\u91cf\u5316\u8bef\u5dee\uff0c\u5e76\u901a\u8fc7\u96c6\u7fa4\u4f18\u5316\u548c\u7ebf\u6027\u878d\u5408\u65b9\u6cd5\u89e3\u51b3\u91cf\u5316\u5f02\u8d28\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b66\u4e60\u6548\u7528\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5c3d\u7ba1\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u9690\u79c1\u98ce\u9669\uff08\u5982\u672c\u5730\u6a21\u578b\u66f4\u65b0\u4f20\u8f93\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\uff09\u548c\u56e0\u8bbe\u5907\u95f4\u91cf\u5316\u5206\u8fa8\u7387\u4e0d\u540c\u800c\u5bfc\u81f4\u7684\u5b66\u4e60\u6548\u7528\u4e0b\u964d\u7b49\u95ee\u9898\u3002\u73b0\u6709\u5de5\u4f5c\u901a\u5e38\u53ea\u80fd\u89e3\u51b3\u5176\u4e2d\u4e00\u4e2a\u6311\u6218\uff0c\u96be\u4ee5\u540c\u65f6\u5e94\u5bf9\u9690\u79c1\u4fdd\u62a4\u548c\u91cf\u5316\u5f02\u8d28\u6027\u7684\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u968f\u673a\u91cf\u5316\u5668\uff08SQ\uff09\uff0c\u53ef\u540c\u65f6\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u548c\u6700\u5c0f\u91cf\u5316\u8bef\u5dee\uff0c\u5e76\u4fdd\u8bc1\u6709\u754c\u7684\u5931\u771f\u3002\n2. \u5f15\u5165\u96c6\u7fa4\u89c4\u6a21\u4f18\u5316\u6280\u672f\u548c\u7ebf\u6027\u878d\u5408\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u805a\u5408\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u91cf\u5316\u5f02\u8d28\u6027\u95ee\u9898\u3002\n3. \u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u4e0e\u4f20\u7edf\u7684LaplaceSQ-FL\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b66\u4e60\u6548\u7528\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u968f\u673a\u91cf\u5316\u5668\uff08SQ\uff09\u548c\u76f8\u5173\u6280\u672f\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u7684\u5b66\u4e60\u6548\u7528\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u91cf\u5316\u5f02\u8d28\u6027\u7684\u60c5\u51b5\u4e0b\u3002\u8fd9\u4e3a\u672a\u6765\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b66\u4e60\u6548\u7528\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.00927", "pdf": "https://arxiv.org/pdf/2507.00927", "abs": "https://arxiv.org/abs/2507.00927", "authors": ["Antonis Vasileiou", "Timo Stoll", "Christopher Morris"], "title": "Understanding Generalization in Node and Link Prediction", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2412.07106", "summary": "Using message-passing graph neural networks (MPNNs) for node and link\nprediction is crucial in various scientific and industrial domains, which has\nled to the development of diverse MPNN architectures. Besides working well in\npractical settings, their ability to generalize beyond the training set remains\npoorly understood. While some studies have explored MPNNs' generalization in\ngraph-level prediction tasks, much less attention has been given to node- and\nlink-level predictions. Existing works often rely on unrealistic i.i.d.\\@\nassumptions, overlooking possible correlations between nodes or links, and\nassuming fixed aggregation and impractical loss functions while neglecting the\ninfluence of graph structure. In this work, we introduce a unified framework to\nanalyze the generalization properties of MPNNs in inductive and transductive\nnode and link prediction settings, incorporating diverse architectural\nparameters and loss functions and quantifying the influence of graph structure.\nAdditionally, our proposed generalization framework can be applied beyond\ngraphs to any classification task under the inductive or transductive setting.\nOur empirical study supports our theoretical insights, deepening our\nunderstanding of MPNNs' generalization capabilities in these tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790MPNN\u5728\u5f52\u7eb3\u548c\u8f6c\u6362\u8282\u70b9\u53ca\u94fe\u63a5\u9884\u6d4b\u4e2d\u7684\u6cdb\u5316\u7279\u6027\uff0c\u8003\u8651\u4e86\u67b6\u6784\u53c2\u6570\u3001\u635f\u5931\u51fd\u6570\u548c\u56fe\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u652f\u6301\u4e86\u7406\u8bba\u89c1\u89e3\u3002", "motivation": "\u5c3d\u7ba1MPNN\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u7279\u522b\u662f\u8282\u70b9\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u3002\u73b0\u6709\u7814\u7a76\u4f9d\u8d56\u4e0d\u5207\u5b9e\u9645\u7684\u5047\u8bbe\uff0c\u5ffd\u7565\u4e86\u8282\u70b9\u6216\u94fe\u63a5\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u4ee5\u53ca\u56fe\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u5206\u6790MPNN\u5728\u5f52\u7eb3\u548c\u8f6c\u6362\u8282\u70b9\u53ca\u94fe\u63a5\u9884\u6d4b\u8bbe\u7f6e\u4e2d\u7684\u6cdb\u5316\u5c5e\u6027\uff0c\u5305\u62ec\u591a\u79cd\u67b6\u6784\u53c2\u6570\u548c\u635f\u5931\u51fd\u6570\uff0c\u540c\u65f6\u91cf\u5316\u56fe\u7ed3\u6784\u7684\u5f71\u54cd\u3002\u8be5\u6846\u67b6\u8fd8\u53ef\u6269\u5c55\u5230\u4efb\u4f55\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u80fd\u591f\u6709\u6548\u52a0\u6df1\u5bf9MPNN\u5728\u8282\u70b9\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u6cdb\u5316\u80fd\u529b\u7684\u7406\u89e3\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6cdb\u5316\u5206\u6790\u6846\u67b6\uff0c\u9002\u7528\u4e8eMPNN\u5728\u8282\u70b9\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5176\u4ed6\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2507.00945", "pdf": "https://arxiv.org/pdf/2507.00945", "abs": "https://arxiv.org/abs/2507.00945", "authors": ["Massimiliano Luca", "Ciro Beneduce", "Bruno Lepri"], "title": "Time Series Foundation Models are Flow Predictors", "categories": ["cs.LG", "cs.CY"], "comment": "arXiv admin note: text overlap with arXiv:2203.07372", "summary": "We investigate the effectiveness of time series foundation models (TSFMs) for\ncrowd flow prediction, focusing on Moirai and TimesFM. Evaluated on three\nreal-world mobility datasets-Bike NYC, Taxi Beijing, and Spanish national OD\nflows-these models are deployed in a strict zero-shot setting, using only the\ntemporal evolution of each OD flow and no explicit spatial information. Moirai\nand TimesFM outperform both statistical and deep learning baselines, achieving\nup to 33% lower RMSE, 39% lower MAE and up to 49% higher CPC compared to\nstate-of-the-art competitors. Our results highlight the practical value of\nTSFMs for accurate, scalable flow prediction, even in scenarios with limited\nannotated data or missing spatial context.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5728\u4eba\u7fa4\u6d41\u52a8\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662fMoirai\u548cTimesFM\u3002\u901a\u8fc7\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u79fb\u52a8\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5728\u4e25\u683c\u7684\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u90e8\u7f72\u8fd9\u4e9b\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u6bcf\u4e2aOD\u6d41\u7684\u65f6\u95f4\u6f14\u53d8\u800c\u4e0d\u4f7f\u7528\u660e\u786e\u7684\u7a7a\u95f4\u4fe1\u606f\u3002Moirai\u548cTimesFM\u7684\u8868\u73b0\u4f18\u4e8e\u7edf\u8ba1\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u6a21\u578b\uff0c\u4e0e\u73b0\u6709\u6700\u4f73\u7ade\u4e89\u5bf9\u624b\u76f8\u6bd4\uff0cRMSE\u964d\u4f4e\u591a\u8fbe33%\uff0cMAE\u964d\u4f4e39%\uff0cCPC\u9ad8\u51fa49%\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u6807\u6ce8\u6570\u636e\u6709\u9650\u6216\u7a7a\u95f4\u80cc\u666f\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\uff0cTSFMs\u5728\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u6d41\u91cf\u9884\u6d4b\u4e2d\u5177\u6709\u5b9e\u9645\u4ef7\u503c\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7a76\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5728\u4eba\u7fa4\u6d41\u52a8\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u6ca1\u6709\u660e\u786e\u7a7a\u95f4\u4fe1\u606f\u60c5\u51b5\u4e0b\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528Moirai\u548cTimesFM\u4e24\u79cd\u6a21\u578b\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u91c7\u7528\u4e25\u683c\u7684\u96f6\u6837\u672c\u8bbe\u7f6e\uff0c\u4ec5\u5229\u7528OD\u6d41\u7684\u65f6\u95f4\u6f14\u53d8\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u3002", "result": "Moirai\u548cTimesFM\u5728\u9884\u6d4b\u6548\u679c\u4e0a\u663e\u8457\u4f18\u4e8e\u7edf\u8ba1\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u6a21\u578b\uff0c\u5206\u522b\u5728RMSE\u3001MAE\u548cCPC\u6307\u6807\u4e0a\u6709\u5927\u5e45\u6539\u8fdb\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5728\u4eba\u7fa4\u6d41\u52a8\u9884\u6d4b\u4e2d\u5177\u6709\u9ad8\u51c6\u786e\u6027\u3001\u53ef\u6269\u5c55\u6027\uff0c\u5373\u4f7f\u5728\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u6216\u7a7a\u95f4\u80cc\u666f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u5b9e\u7528\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2507.00964", "pdf": "https://arxiv.org/pdf/2507.00964", "abs": "https://arxiv.org/abs/2507.00964", "authors": ["Jack Foxabbott", "Arush Tagade", "Andrew Cusick", "Robbie McCorkell", "Leo McKee-Reid", "Jugal Patel", "Jamie Rumbelow", "Jessica Rumbelow", "Zohreh Shams"], "title": "Benchmarking the Discovery Engine", "categories": ["cs.LG", "I.2.6; I.2.3; I.5.1; H.2.8; J.2; J.3; J.4"], "comment": "16 pages, 8 figures, benchmarks Discovery Engine on five scientific\n  datasets (medicine, materials science, climate, air quality, social science)", "summary": "The Discovery Engine is a general purpose automated system for scientific\ndiscovery, which combines machine learning with state-of-the-art ML\ninterpretability to enable rapid and robust scientific insight across diverse\ndatasets. In this paper, we benchmark the Discovery Engine against five recent\npeer-reviewed scientific publications applying machine learning across\nmedicine, materials science, social science, and environmental science. In each\ncase, the Discovery Engine matches or exceeds prior predictive performance\nwhile also generating deeper, more actionable insights through rich\ninterpretability artefacts. These results demonstrate its potential as a new\nstandard for automated, interpretable scientific modelling that enables complex\nknowledge discovery from data.", "AI": {"tldr": "The Discovery Engine is a new standard for automated, interpretable scientific modelling that enables complex knowledge discovery from data.", "motivation": "To create a general purpose automated system for scientific discovery that combines machine learning with state-of-the-art ML interpretability.", "method": "Benchmark the Discovery Engine against five recent peer-reviewed scientific publications applying machine learning across different fields.", "result": "In each case, the Discovery Engine matches or exceeds prior predictive performance while also generating deeper, more actionable insights through rich interpretability artefacts.", "conclusion": "Demonstrates its potential as a new standard for automated, interpretable scientific modelling."}}
{"id": "2507.00965", "pdf": "https://arxiv.org/pdf/2507.00965", "abs": "https://arxiv.org/abs/2507.00965", "authors": ["F\u00e9lix Lefebvre", "Ga\u00ebl Varoquaux"], "title": "Scalable Feature Learning on Huge Knowledge Graphs for Downstream Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Many machine learning tasks can benefit from external knowledge. Large\nknowledge graphs store such knowledge, and embedding methods can be used to\ndistill it into ready-to-use vector representations for downstream\napplications. For this purpose, current models have however two limitations:\nthey are primarily optimized for link prediction, via local contrastive\nlearning, and they struggle to scale to the largest graphs due to GPU memory\nlimits. To address these, we introduce SEPAL: a Scalable Embedding Propagation\nALgorithm for large knowledge graphs designed to produce high-quality\nembeddings for downstream tasks at scale. The key idea of SEPAL is to enforce\nglobal embedding alignment by optimizing embeddings only on a small core of\nentities, and then propagating them to the rest of the graph via message\npassing. We evaluate SEPAL on 7 large-scale knowledge graphs and 46 downstream\nmachine learning tasks. Our results show that SEPAL significantly outperforms\nprevious methods on downstream tasks. In addition, SEPAL scales up its base\nembedding model, enabling fitting huge knowledge graphs on commodity hardware.", "AI": {"tldr": "SEPAL\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5d4c\u5165\u4f20\u64ad\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728\u5b9e\u4f53\u7684\u5c0f\u6838\u5fc3\u4e0a\u4f18\u5316\u5d4c\u5165\u5e76\u5c06\u5176\u4f20\u64ad\u5230\u56fe\u7684\u5176\u4f59\u90e8\u5206\uff0c\u4ece\u800c\u4e3a\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5d4c\u5165\u3002\u5b83\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u9002\u5e94\u5de8\u5927\u7684\u77e5\u8bc6\u56fe\u8c31\u3002", "motivation": "\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u53ef\u4ee5\u4ece\u5916\u90e8\u77e5\u8bc6\u4e2d\u53d7\u76ca\u3002\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u5b58\u50a8\u4e86\u8fd9\u79cd\u77e5\u8bc6\uff0c\u800c\u5d4c\u5165\u65b9\u6cd5\u53ef\u4ee5\u5c06\u77e5\u8bc6\u63d0\u70bc\u6210\u53ef\u7528\u4e8e\u4e0b\u6e38\u5e94\u7528\u7684\u5411\u91cf\u8868\u793a\u3002\u7136\u800c\uff0c\u5f53\u524d\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u94fe\u63a5\u9884\u6d4b\u8fdb\u884c\u4f18\u5316\uff0c\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u6700\u5927\u7684\u56fe\u8c31\u3002", "method": "SEPAL\u7684\u5173\u952e\u601d\u60f3\u662f\u901a\u8fc7\u5bf9\u5b9e\u4f53\u7684\u5c0f\u6838\u5fc3\u8fdb\u884c\u4f18\u5316\u5d4c\u5165\u4ee5\u5f3a\u5236\u6267\u884c\u5168\u5c40\u5d4c\u5165\u5bf9\u9f50\uff0c\u7136\u540e\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u5c06\u8fd9\u4e9b\u5d4c\u5165\u4f20\u64ad\u5230\u56fe\u7684\u5176\u4f59\u90e8\u5206\u3002", "result": "SEPAL\u57287\u4e2a\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u548c46\u4e2a\u4e0b\u6e38\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0cSEPAL\u80fd\u591f\u6269\u5c55\u5176\u57fa\u7840\u5d4c\u5165\u6a21\u578b\uff0c\u4f7f\u5f97\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u9002\u5e94\u5de8\u5927\u77e5\u8bc6\u56fe\u8c31\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "SEPAL\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u94fe\u63a5\u9884\u6d4b\u4f18\u5316\u548c\u6269\u5c55\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u9ad8\u8d28\u91cf\u5d4c\u5165\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.01004", "pdf": "https://arxiv.org/pdf/2507.01004", "abs": "https://arxiv.org/abs/2507.01004", "authors": ["Yuhong Chou", "Zehao Liu", "Ruijie Zhu", "Xinyi Wan", "Tianjian Li", "Congying Chu", "Qian Liu", "Jibin Wu", "Zejun Ma"], "title": "ZeCO: Zero Communication Overhead Sequence Parallelism for Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "Linear attention mechanisms deliver significant advantages for Large Language\nModels (LLMs) by providing linear computational complexity, enabling efficient\nprocessing of ultra-long sequences (e.g., 1M context). However, existing\nSequence Parallelism (SP) methods, essential for distributing these workloads\nacross devices, become the primary bottleneck due to substantial communication\noverhead. In this paper, we introduce ZeCO (Zero Communication Overhead)\nsequence parallelism for linear attention models, a new SP method designed to\novercome these limitations and achieve end-to-end near-linear scalability for\nlong sequence training. For example, training a model with a 1M sequence length\nacross 64 devices using ZeCO takes roughly the same time as training with an\n16k sequence on a single device. At the heart of ZeCO lies All-Scan, a new\ncollective communication primitive. All-Scan provides each SP rank with\nprecisely the initial operator state it requires while maintaining a minimal\ncommunication footprint, effectively eliminating communication overhead.\nTheoretically, we prove the optimaity of ZeCO, showing that it introduces only\nnegligible time and space overhead. Empirically, we compare the communication\ncosts of different sequence parallelism strategies and demonstrate that\nAll-Scan achieves the fastest communication in SP scenarios. Specifically, on\n256 GPUs with an 8M sequence length, ZeCO achieves a 60\\% speedup compared to\nthe current state-of-the-art (SOTA) SP method. We believe ZeCO establishes a\nclear path toward efficiently training next-generation LLMs on previously\nintractable sequence lengths.", "AI": {"tldr": "ZeCO\u662f\u4e00\u79cd\u65b0\u7684\u5e8f\u5217\u5e76\u884c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165All-Scan\u901a\u4fe1\u539f\u8bed\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u5b9e\u73b0\u4e86\u957f\u5e8f\u5217\u8bad\u7ec3\u7684\u8fd1\u7ebf\u6027\u6269\u5c55\u3002\u5728256\u4e2aGPU\u4e0a\uff0c\u4e0e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u76f8\u6bd4\uff0cZeCO\u57288M\u5e8f\u5217\u957f\u5ea6\u4e0b\u5b9e\u73b0\u4e8660%\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e3a\u672a\u6765LLM\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u94fa\u5e73\u4e86\u9053\u8def\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u5e76\u884c\uff08SP\uff09\u65b9\u6cd5\u5728\u5904\u7406\u8d85\u957f\u5e8f\u5217\u65f6\u56e0\u901a\u4fe1\u5f00\u9500\u5927\u800c\u6210\u4e3a\u74f6\u9888\uff0c\u9650\u5236\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aZeCO\u7684\u65b0SP\u65b9\u6cd5\uff0c\u5176\u6838\u5fc3\u662fAll-Scan\u901a\u4fe1\u539f\u8bed\u3002All-Scan\u901a\u8fc7\u63d0\u4f9b\u7cbe\u786e\u7684\u521d\u59cb\u64cd\u4f5c\u72b6\u6001\u5e76\u4fdd\u6301\u6700\u5c0f\u901a\u4fe1\u91cf\uff0c\u6d88\u9664\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86ZeCO\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u5f00\u9500\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff1b\u5b9e\u8bc1\u4e0a\uff0c\u5728256\u4e2aGPU\u30018M\u5e8f\u5217\u957f\u5ea6\u7684\u573a\u666f\u4e0b\uff0cZeCO\u6bd4\u5f53\u524d\u6700\u4f73SP\u65b9\u6cd5\u5feb60%\u3002", "conclusion": "ZeCO\u4e3a\u9ad8\u6548\u8bad\u7ec3\u4e0b\u4e00\u4ee3LLM\u63d0\u4f9b\u4e86\u660e\u786e\u8def\u5f84\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e4b\u524d\u96be\u4ee5\u5904\u7406\u7684\u8d85\u957f\u5e8f\u5217\u65f6\u3002"}}
