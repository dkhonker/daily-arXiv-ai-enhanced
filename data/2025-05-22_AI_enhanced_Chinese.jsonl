{"id": "2505.14689", "pdf": "https://arxiv.org/pdf/2505.14689", "abs": "https://arxiv.org/abs/2505.14689", "authors": ["Ashwani Anand", "Satya Prakash Nayak", "Ritam Raha", "Anne-Kathrin Schmuck"], "title": "Follow the STARs: Dynamic $\u03c9$-Regular Shielding of Learned Policies", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "This paper presents a novel dynamic post-shielding framework that enforces\nthe full class of $\\omega$-regular correctness properties over pre-computed\nprobabilistic policies. This constitutes a paradigm shift from the predominant\nsetting of safety-shielding -- i.e., ensuring that nothing bad ever happens --\nto a shielding process that additionally enforces liveness -- i.e., ensures\nthat something good eventually happens. At the core, our method uses\nStrategy-Template-based Adaptive Runtime Shields (STARs), which leverage\npermissive strategy templates to enable post-shielding with minimal\ninterference. As its main feature, STARs introduce a mechanism to dynamically\ncontrol interference, allowing a tunable enforcement parameter to balance\nformal obligations and task-specific behavior at runtime. This allows to\ntrigger more aggressive enforcement when needed, while allowing for optimized\npolicy choices otherwise. In addition, STARs support runtime adaptation to\nchanging specifications or actuator failures, making them especially suited for\ncyber-physical applications. We evaluate STARs on a mobile robot benchmark to\ndemonstrate their controllable interference when enforcing (incrementally\nupdated) $\\omega$-regular correctness properties over learned probabilistic\npolicies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u540e\u5c4f\u853d\u6846\u67b6\uff0c\u7528\u4e8e\u786e\u4fdd\u9884\u8ba1\u7b97\u7684\u6982\u7387\u7b56\u7565\u6ee1\u8db3\u5b8c\u6574\u7684\u03c9-\u6b63\u5219\u6b63\u786e\u6027\u5c5e\u6027\uff0c\u5b9e\u73b0\u4e86\u4ece\u5b89\u5168\u6027\u5c4f\u853d\u5230\u540c\u65f6\u4fdd\u8bc1\u6d3b\u8dc3\u6027\u7684\u8f6c\u53d8\u3002\u4e3b\u8981\u7279\u5f81\u5305\u62ec\u57fa\u4e8e\u7b56\u7565\u6a21\u677f\u7684\u81ea\u9002\u5e94\u8fd0\u884c\u65f6\u5c4f\u853d\uff08STARs\uff09\uff0c\u5b83\u80fd\u6700\u5c0f\u5316\u5e72\u6270\u5e76\u652f\u6301\u8fd0\u884c\u65f6\u9002\u5e94\u53d8\u5316\u7684\u89c4\u8303\u6216\u6267\u884c\u5668\u6545\u969c\u3002", "motivation": "\u4ece\u53ea\u5173\u6ce8\u5b89\u5168\u6027\u7684\u5b89\u5168\u6027\u5c4f\u853d\u8f6c\u5411\u65e2\u80fd\u786e\u4fdd\u5b89\u5168\u6027\u53c8\u80fd\u786e\u4fdd\u6d3b\u8dc3\u6027\u7684\u5c4f\u853d\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u7b56\u7565\u6a21\u677f\u7684\u81ea\u9002\u5e94\u8fd0\u884c\u65f6\u5c4f\u853d\uff08STARs\uff09\uff0c\u901a\u8fc7\u53ef\u8c03\u7684\u6267\u884c\u53c2\u6570\u5728\u8fd0\u884c\u65f6\u5e73\u8861\u6b63\u5f0f\u4e49\u52a1\u548c\u7279\u5b9a\u4efb\u52a1\u7684\u884c\u4e3a\u3002", "result": "\u5728\u79fb\u52a8\u673a\u5668\u4eba\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86STARs\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u63a7\u7684\u5e72\u6270\u80fd\u529b\uff0c\u7528\u4e8e\u5f3a\u5236\u6267\u884c\u66f4\u65b0\u7684\u03c9-\u6b63\u5219\u6b63\u786e\u6027\u5c5e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u4e3a\u786e\u4fdd\u590d\u6742\u7684\u03c9-\u6b63\u5219\u6b63\u786e\u6027\u5c5e\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e14\u7279\u522b\u9002\u7528\u4e8e\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u5e94\u7528\u3002"}}
{"id": "2505.14738", "pdf": "https://arxiv.org/pdf/2505.14738", "abs": "https://arxiv.org/abs/2505.14738", "authors": ["Xu Yang", "Xiao Yang", "Shikai Fang", "Bowen Xian", "Yuante Li", "Jian Wang", "Minrui Xu", "Haoran Pan", "Xinpeng Hong", "Weiqing Liu", "Yelong Shen", "Weizhu Chen", "Jiang Bian"], "title": "R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution", "categories": ["cs.AI"], "comment": "7 pages, 1 figure, 1 table", "summary": "Recent advances in AI and ML have transformed data science, yet increasing\ncomplexity and expertise requirements continue to hinder progress. While\ncrowdsourcing platforms alleviate some challenges, high-level data science\ntasks remain labor-intensive and iterative. To overcome these limitations, we\nintroduce R&D-Agent, a dual-agent framework for iterative exploration. The\nResearcher agent uses performance feedback to generate ideas, while the\nDeveloper agent refines code based on error feedback. By enabling multiple\nparallel exploration traces that merge and enhance one another, R&D-Agent\nnarrows the gap between automated solutions and expert-level performance.\nEvaluated on MLE-Bench, R&D-Agent emerges as the top-performing machine\nlearning engineering agent, demonstrating its potential to accelerate\ninnovation and improve precision across diverse data science applications. We\nhave open-sourced R&D-Agent on GitHub: https://github.com/microsoft/RD-Agent.", "AI": {"tldr": "R&D-Agent\u662f\u4e00\u79cd\u53cc\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u7684\u8fed\u4ee3\u63a2\u7d22\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u51cf\u5c11\u4e13\u5bb6\u7ea7\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1AI\u548cML\u7684\u8fdb\u6b65\u63a8\u52a8\u4e86\u6570\u636e\u79d1\u5b66\u7684\u53d1\u5c55\uff0c\u4f46\u590d\u6742\u6027\u548c\u4e13\u4e1a\u9700\u6c42\u963b\u788d\u4e86\u8fdb\u4e00\u6b65\u8fdb\u6b65\u3002", "method": "R&D-Agent\u5305\u542b\u4e24\u4e2a\u4ee3\u7406\uff1aResearcher\u751f\u6210\u60f3\u6cd5\uff0cDeveloper\u4f18\u5316\u4ee3\u7801\u3002", "result": "\u5728MLE-Bench\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5c55\u793a\u4e86\u52a0\u901f\u521b\u65b0\u548c\u63d0\u9ad8\u591a\u79cd\u6570\u636e\u79d1\u5b66\u5e94\u7528\u7cbe\u5ea6\u7684\u6f5c\u529b\u3002", "conclusion": "\u5f00\u6e90R&D-Agent\uff0c\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u548c\u53d1\u5c55\u3002"}}
{"id": "2505.14932", "pdf": "https://arxiv.org/pdf/2505.14932", "abs": "https://arxiv.org/abs/2505.14932", "authors": ["Isabelle Lee", "Sarah Liaw", "Dani Yogatama"], "title": "FOL-Pretrain: A complexity annotated corpus of first-order logic", "categories": ["cs.AI"], "comment": null, "summary": "Transformer-based large language models (LLMs) have demonstrated remarkable\nreasoning capabilities such as coding and solving mathematical problems to\ncommonsense inference. While these tasks vary in complexity, they all require\nmodels to integrate and compute over structured information. Despite recent\nefforts to reverse-engineer LLM behavior through controlled experiments, our\nunderstanding of how these models internalize and execute complex algorithms\nremains limited. Progress has largely been confined to small-scale studies or\nshallow tasks such as basic arithmetic and grammatical pattern matching. One\nbarrier to deeper understanding is the nature of pretraining data -- vast,\nheterogeneous, and often poorly annotated, making it difficult to isolate\nmechanisms of reasoning. To bridge this gap, we introduce a large-scale, fully\nopen, complexity-annotated dataset of first-order logic reasoning traces,\ndesigned to probe and analyze algorithmic reasoning in LLMs. The dataset\nconsists of 3.5 billion tokens, including 8.8 million LLM-augmented,\nhuman-annotated examples and 7.5 million synthetically generated examples. Each\nsynthetic example is verifiably correct, produced by a custom automated theorem\nsolver, and accompanied by metadata tracing its algorithmic provenance. We aim\nto provide a scalable, interpretable artifact for studying how LLMs learn and\ngeneralize symbolic reasoning processes, paving the way for more transparent\nand targeted investigations into the algorithmic capabilities of modern models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5927\u89c4\u6a21\u5f00\u653e\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u903b\u8f91\u63a8\u7406\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5185\u5316\u548c\u6267\u884c\u590d\u6742\u7b97\u6cd5\u7684\u80fd\u529b\u6709\u9650\uff0c\u4e14\u9884\u8bad\u7ec3\u6570\u636e\u96be\u4ee5\u9694\u79bb\u63a8\u7406\u673a\u5236\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5b8c\u5168\u5f00\u653e\u3001\u590d\u6742\u6027\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u4eba\u7c7b\u6807\u6ce8\u548c\u5408\u6210\u751f\u6210\u7684\u4f8b\u5b50\uff0c\u5e76\u63d0\u4f9b\u6bcf\u4e2a\u5408\u6210\u4f8b\u5b50\u7684\u5143\u6570\u636e\u6765\u8ffd\u8e2a\u5176\u7b97\u6cd5\u8d77\u6e90\u3002", "result": "\u6570\u636e\u96c6\u753135\u4ebf\u4e2a\u6807\u8bb0\u7ec4\u6210\uff0c\u5305\u62ec880\u4e07\u4e2aLLM\u589e\u5f3a\u7684\u4eba\u7c7b\u6ce8\u91ca\u793a\u4f8b\u548c750\u4e07\u4e2a\u5408\u6210\u751f\u6210\u7684\u4f8b\u5b50\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u65e8\u5728\u4e3a\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u548c\u6cdb\u5316\u7b26\u53f7\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u5de5\u5177\uff0c\u4fc3\u8fdb\u5bf9\u73b0\u4ee3\u6a21\u578b\u7b97\u6cd5\u80fd\u529b\u7684\u66f4\u900f\u660e\u548c\u6709\u9488\u5bf9\u6027\u7684\u7814\u7a76\u3002"}}
{"id": "2505.14940", "pdf": "https://arxiv.org/pdf/2505.14940", "abs": "https://arxiv.org/abs/2505.14940", "authors": ["Kaspar Rothenfusser"], "title": "To Be or Not To Be: Vector ontologies as a truly formal ontological framework", "categories": ["cs.AI", "cs.SC"], "comment": null, "summary": "Since Edmund Husserl coined the term \"Formal Ontologies\" in the early 20th\ncentury, a field that identifies itself with this particular branch of sciences\nhas gained increasing attention. Many authors, and even Husserl himself have\ndeveloped what they claim to be formal ontologies. I argue that under close\ninspection, none of these so claimed formal ontologies are truly formal in the\nHusserlian sense. More concretely, I demonstrate that they violate the two most\nimportant notions of formal ontology as developed in Husserl's Logical\nInvestigations, namely a priori validity independent of perception and\nformalism as the total absence of content. I hence propose repositioning the\nwork previously understood as formal ontology as the foundational ontology it\nreally is. This is to recognize the potential of a truly formal ontology in the\nHusserlian sense. Specifically, I argue that formal ontology following his\nconditions, allows us to formulate ontological structures, which could capture\nwhat is more objectively without presupposing a particular framework arising\nfrom perception. I further argue that the ability to design the formal\nstructure deliberately allows us to create highly scalable and interoperable\ninformation artifacts. As concrete evidence, I showcase that a class of formal\nontology, which uses the axioms of vector spaces, is able to express most of\nthe conceptualizations found in foundational ontologies. Most importantly, I\nargue that many information systems, specifically artificial intelligence, are\nlikely already using some type of vector ontologies to represent reality in\ntheir internal worldviews and elaborate on the evidence that humans do as well.\nI hence propose a thorough investigation of the ability of vector ontologies to\nact as a human-machine interoperable ontological framework that allows us to\nunderstand highly sophisticated machines and machines to understand us.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f62\u5f0f\u672c\u4f53\u8bba\u7684\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u91cd\u65b0\u5b9a\u4e49\u5b83\u4e3a\u771f\u6b63\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\uff0c\u5f3a\u8c03\u5176\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u6f84\u6e05\u548c\u7ea0\u6b63\u5bf9\u80e1\u585e\u5c14\u5f62\u5f0f\u672c\u4f53\u8bba\u7684\u7406\u89e3\u504f\u5dee\uff0c\u5e76\u63a2\u7d22\u5f62\u5f0f\u672c\u4f53\u8bba\u5728\u4eba\u5de5\u667a\u80fd\u7b49\u4fe1\u606f\u7cfb\u7edf\u7684\u6f5c\u5728\u5e94\u7528\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u8bba\u8bc1\u6307\u51fa\u6240\u8c13\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\u5e76\u975e\u771f\u6b63\u7b26\u5408\u80e1\u585e\u5c14\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u672c\u4f53\u8bba\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u6240\u7814\u7a76\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\u8fdd\u53cd\u4e86\u80e1\u585e\u5c14\u903b\u8f91\u8c03\u67e5\u4e2d\u7684\u4e24\u4e2a\u91cd\u8981\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1\u53ef\u6269\u5c55\u4e14\u4e92\u64cd\u4f5c\u7684\u4fe1\u606f\u5236\u54c1\u3002\u6b64\u5916\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u5411\u91cf\u7a7a\u95f4\u516c\u7406\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\u53ef\u4ee5\u8868\u8fbe\u5927\u591a\u6570\u57fa\u7840\u672c\u4f53\u8bba\u7684\u6982\u5ff5\u5316\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u91cd\u65b0\u5b9a\u4e49\u5148\u524d\u88ab\u8ba4\u4e3a\u662f\u5f62\u5f0f\u672c\u4f53\u8bba\u7684\u5de5\u4f5c\uff0c\u5c06\u5176\u89c6\u4e3a\u57fa\u7840\u672c\u4f53\u8bba\uff0c\u5e76\u8ba4\u4e3a\u9075\u5faa\u80e1\u585e\u5c14\u6761\u4ef6\u7684\u5f62\u5f0f\u672c\u4f53\u8bba\u80fd\u591f\u6355\u6349\u66f4\u5ba2\u89c2\u7684\u4e8b\u7269\uff0c\u540c\u65f6\u63d0\u51fa\u9700\u8981\u6df1\u5165\u7814\u7a76\u5411\u91cf\u672c\u4f53\u8bba\u4f5c\u4e3a\u4eba\u673a\u4e92\u64cd\u4f5c\u7684\u672c\u4f53\u8bba\u6846\u67b6\u3002"}}
{"id": "2505.14808", "pdf": "https://arxiv.org/pdf/2505.14808", "abs": "https://arxiv.org/abs/2505.14808", "authors": ["Soo Min Kwon", "Alec S. Xu", "Can Yaras", "Laura Balzano", "Qing Qu"], "title": "Out-of-Distribution Generalization of In-Context Learning: A Low-Dimensional Subspace Perspective", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "This work aims to demystify the out-of-distribution (OOD) capabilities of\nin-context learning (ICL) by studying linear regression tasks parameterized\nwith low-rank covariance matrices. With such a parameterization, we can model\ndistribution shifts as a varying angle between the subspace of the training and\ntesting covariance matrices. We prove that a single-layer linear attention\nmodel incurs a test risk with a non-negligible dependence on the angle,\nillustrating that ICL is not robust to such distribution shifts. However, using\nthis framework, we also prove an interesting property of ICL: when trained on\ntask vectors drawn from a union of low-dimensional subspaces, ICL can\ngeneralize to any subspace within their span, given sufficiently long prompt\nlengths. This suggests that the OOD generalization ability of Transformers may\nactually stem from the new task lying within the span of those encountered\nduring training. We empirically show that our results also hold for models such\nas GPT-2, and conclude with (i) experiments on how our observations extend to\nnonlinear function classes and (ii) results on how LoRA has the ability to\ncapture distribution shifts.", "AI": {"tldr": "\u7814\u7a76\u4e86\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5176\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u654f\u611f\u6027\u548c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u7279\u6027\u3002", "motivation": "\u7406\u89e3ICL\u5728\u5904\u7406\u5206\u5e03\u504f\u79fb\u65f6\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u4f4e\u79e9\u534f\u65b9\u5dee\u77e9\u9635\u53c2\u6570\u5316\u7684\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u6765\u7814\u7a76ICL\u7684OOD\u80fd\u529b\uff0c\u5e76\u5206\u6790\u8bad\u7ec3\u548c\u6d4b\u8bd5\u534f\u65b9\u5dee\u5b50\u7a7a\u95f4\u4e4b\u95f4\u7684\u89d2\u5ea6\u53d8\u5316\u3002", "result": "\u5355\u5c42\u7ebf\u6027\u6ce8\u610f\u6a21\u578b\u5728\u6d4b\u8bd5\u98ce\u9669\u4e0a\u8868\u73b0\u51fa\u5bf9\u89d2\u5ea6\u7684\u4f9d\u8d56\u6027\uff0c\u4f46ICL\u80fd\u5728\u4efb\u52a1\u5411\u91cf\u7684\u5b50\u7a7a\u95f4\u8de8\u5ea6\u5185\u63a8\u5e7f\u3002", "conclusion": "ICL\u7684OOD\u6cdb\u5316\u80fd\u529b\u53ef\u80fd\u6e90\u4e8e\u65b0\u4efb\u52a1\u4f4d\u4e8e\u8bad\u7ec3\u671f\u95f4\u9047\u5230\u7684\u4efb\u52a1\u5b50\u7a7a\u95f4\u7684\u8de8\u5ea6\u5185\uff0cLoRA\u80fd\u6355\u6349\u5206\u5e03\u504f\u79fb\u3002"}}
{"id": "2505.14700", "pdf": "https://arxiv.org/pdf/2505.14700", "abs": "https://arxiv.org/abs/2505.14700", "authors": ["R\u00f4mulo Damasclin Chaves dos Santos", "Jorge Henrique de Oliveira Sales"], "title": "Stochastic Fractional Neural Operators: A Symmetrized Approach to Modeling Turbulence in Complex Fluid Dynamics", "categories": ["cs.LG"], "comment": "17 pages", "summary": "In this work, we introduce a new class of neural network operators designed\nto handle problems where memory effects and randomness play a central role. In\nthis work, we introduce a new class of neural network operators designed to\nhandle problems where memory effects and randomness play a central role. These\noperators merge symmetrized activation functions, Caputo-type fractional\nderivatives, and stochastic perturbations introduced via It\\^o type noise. The\nresult is a powerful framework capable of approximating functions that evolve\nover time with both long-term memory and uncertain dynamics. We develop the\nmathematical foundations of these operators, proving three key theorems of\nVoronovskaya type. These results describe the asymptotic behavior of the\noperators, their convergence in the mean-square sense, and their consistency\nunder fractional regularity assumptions. All estimates explicitly account for\nthe influence of the memory parameter $\\alpha$ and the noise level $\\sigma$. As\na practical application, we apply the proposed theory to the fractional\nNavier-Stokes equations with stochastic forcing, a model often used to describe\nturbulence in fluid flows with memory. Our approach provides theoretical\nguarantees for the approximation quality and suggests that these neural\noperators can serve as effective tools in the analysis and simulation of\ncomplex systems. By blending ideas from neural networks, fractional calculus,\nand stochastic analysis, this research opens new perspectives for modeling\nturbulent phenomena and other multiscale processes where memory and randomness\nare fundamental. The results lay the groundwork for hybrid learning-based\nmethods with strong analytical backing.", "AI": {"tldr": "This paper introduces a novel neural network operator combining symmetrized activation functions, Caputo-type fractional derivatives, and stochastic perturbations to approximate functions with long-term memory and uncertain dynamics.", "motivation": "To address problems involving memory effects and randomness.", "method": "Develops a new class of neural network operators integrating symmetrized activation functions, Caputo-type fractional derivatives, and stochastic perturbations.", "result": "Proves three key Voronovskaya-type theorems describing the asymptotic behavior, mean-square convergence, and consistency under fractional regularity assumptions.", "conclusion": "The proposed operators provide theoretical guarantees for approximating functions with long-term memory and uncertain dynamics, suggesting potential applications in complex system analysis and simulation."}}
{"id": "2505.14946", "pdf": "https://arxiv.org/pdf/2505.14946", "abs": "https://arxiv.org/abs/2505.14946", "authors": ["Eric Han", "Jun Chen", "Karthik Abinav Sankararaman", "Xiaoliang Peng", "Tengyu Xu", "Eryk Helenowski", "Kaiyan Peng", "Mrinal Kumar", "Sinong Wang", "Han Fang", "Arya Talebzadeh"], "title": "Reinforcement Learning from User Feedback", "categories": ["cs.AI"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in diverse user\nfacing applications, aligning them with real user preferences becomes\nessential. Existing methods like Reinforcement Learning from Human Feedback\n(RLHF) rely on expert annotators trained on manually defined guidelines, whose\njudgments may not reflect the priorities of everyday users. We introduce\nReinforcement Learning from User Feedback (RLUF), a framework for aligning LLMs\ndirectly to implicit signals from users in production. RLUF addresses key\nchallenges of user feedback: user feedback is often binary (e.g., emoji\nreactions), sparse, and occasionally adversarial. We train a reward model,\nP[Love], to predict the likelihood that an LLM response will receive a Love\nReaction, a lightweight form of positive user feedback, and integrate P[Love]\ninto a multi-objective policy optimization framework alongside helpfulness and\nsafety objectives. In large-scale experiments, we show that P[Love] is\npredictive of increased positive feedback and serves as a reliable offline\nevaluator of future user behavior. Policy optimization using P[Love]\nsignificantly raises observed positive-feedback rates, including a 28% increase\nin Love Reactions during live A/B tests. However, optimizing for positive\nreactions introduces reward hacking challenges, requiring careful balancing of\nobjectives. By directly leveraging implicit signals from users, RLUF offers a\npath to aligning LLMs with real-world user preferences at scale.", "AI": {"tldr": "This paper introduces RLUF, a method for aligning large language models with real user preferences by using implicit feedback such as emoji reactions.", "motivation": "Existing methods rely on expert annotators whose judgments may not reflect everyday user priorities.", "method": "Introduces a reward model, P[Love], to predict the likelihood of receiving a positive user reaction and integrates it into policy optimization with helpfulness and safety objectives.", "result": "P[Love] is predictive of increased positive feedback and improves observed positive-feedback rates by 28% in live tests, but introduces reward hacking challenges.", "conclusion": "RLUF provides a way to align LLMs with real-world user preferences at scale by directly leveraging implicit user signals."}}
{"id": "2505.14867", "pdf": "https://arxiv.org/pdf/2505.14867", "abs": "https://arxiv.org/abs/2505.14867", "authors": ["So Won Jeong", "Claire Donnat"], "title": "LOBSTUR: A Local Bootstrap Framework for Tuning Unsupervised Representations in Graph Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are increasingly used in conjunction with\nunsupervised learning techniques to learn powerful node representations, but\ntheir deployment is hindered by their high sensitivity to hyperparameter tuning\nand the absence of established methodologies for selecting the optimal models.\nTo address these challenges, we propose LOBSTUR-GNN ({\\bf Lo}cal {\\bf B}oot{\\bf\ns}trap for {\\bf T}uning {\\bf U}nsupervised {\\bf R}epresentations in GNNs) i), a\nnovel framework designed to adapt bootstrapping techniques for unsupervised\ngraph representation learning. LOBSTUR-GNN tackles two main challenges: (a)\nadapting the bootstrap edge and feature resampling process to account for local\ngraph dependencies in creating alternative versions of the same graph, and (b)\nestablishing robust metrics for evaluating learned representations without\nground-truth labels. Using locally bootstrapped resampling and leveraging\nCanonical Correlation Analysis (CCA) to assess embedding consistency, LOBSTUR\nprovides a principled approach for hyperparameter tuning in unsupervised GNNs.\nWe validate the effectiveness and efficiency of our proposed method through\nextensive experiments on established academic datasets, showing an 65.9\\%\nimprovement in the classification accuracy compared to an uninformed selection\nof hyperparameters. Finally, we deploy our framework on a real-world\napplication, thereby demonstrating its validity and practical utility in\nvarious settings. \\footnote{The code is available at\n\\href{https://github.com/sowonjeong/lobstur-graph-bootstrap}{github.com/sowonjeong/lobstur-graph-bootstrap}.}", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6LOBSTUR-GNN\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8d85\u53c2\u6570\u8c03\u6574\u548c\u8868\u793a\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u9ad8\u654f\u611f\u6027\u4ee5\u53ca\u7f3a\u4e4f\u4f18\u5316\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aLOBSTUR-GNN\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u672c\u5730\u5f15\u5bfc\u91cd\u91c7\u6837\u548c\u5178\u578b\u76f8\u5173\u5206\u6790(CCA)\u6765\u8bc4\u4f30\u5d4c\u5165\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u5b66\u672f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0e\u672a\u7ecf\u8c03\u6574\u7684\u8d85\u53c2\u6570\u76f8\u6bd4\uff0c\u5206\u7c7b\u51c6\u786e\u6027\u63d0\u9ad8\u4e8665.9%\u3002", "conclusion": "LOBSTUR-GNN\u6846\u67b6\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u6709\u8d21\u732e\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e5f\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2505.14727", "pdf": "https://arxiv.org/pdf/2505.14727", "abs": "https://arxiv.org/abs/2505.14727", "authors": ["Mohammad Rubyet Islam"], "title": "The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents", "categories": ["cs.LG", "91G70 Statistical methods, risk measures 91B84 Economic models\n  (financial models, industrial models, growth models)", "I.2.6; I.5.1; I.2.7"], "comment": null, "summary": "The pursuit of alpha returns that exceed market benchmarks has undergone a\nprofound transformation, evolving from intuition-driven investing to\nautonomous, AI powered systems. This paper introduces a comprehensive five\nstage taxonomy that traces this progression across manual strategies,\nstatistical models, classical machine learning, deep learning, and agentic\narchitectures powered by large language models (LLMs). Unlike prior surveys\nfocused narrowly on modeling techniques, this review adopts a system level\nlens, integrating advances in representation learning, multimodal data fusion,\nand tool augmented LLM agents. The strategic shift from static predictors to\ncontextaware financial agents capable of real time reasoning, scenario\nsimulation, and cross modal decision making is emphasized. Key challenges in\ninterpretability, data fragility, governance, and regulatory compliance areas\ncritical to production deployment are examined. The proposed taxonomy offers a\nunified framework for evaluating maturity, aligning infrastructure, and guiding\nthe responsible development of next generation alpha systems.", "AI": {"tldr": "This paper presents a five-stage taxonomy that tracks the evolution of alpha-generating systems from manual strategies to AI-powered architectures, emphasizing the shift towards context-aware financial agents. It also examines challenges related to interpretability, data, governance, and compliance.", "motivation": "To provide a comprehensive understanding of the transformation in alpha generation from human intuition to autonomous AI systems.", "method": "Develops a five-stage taxonomy including manual strategies, statistical models, classical machine learning, deep learning, and AI agents powered by large language models.", "result": "Introduces a system-level approach integrating advancements in representation learning, multimodal data fusion, and tool-augmented LLM agents.", "conclusion": "Proposes a unified framework for assessing the maturity of alpha systems, aligning infrastructure, and promoting responsible development."}}
{"id": "2505.14970", "pdf": "https://arxiv.org/pdf/2505.14970", "abs": "https://arxiv.org/abs/2505.14970", "authors": ["Xiaoyin Chen", "Jiarui Lu", "Minsu Kim", "Dinghuai Zhang", "Jian Tang", "Alexandre Pich\u00e9", "Nicolas Gontier", "Yoshua Bengio", "Ehsan Kamalloo"], "title": "Self-Evolving Curriculum for LLM Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has proven effective for fine-tuning large\nlanguage models (LLMs), significantly enhancing their reasoning abilities in\ndomains such as mathematics and code generation. A crucial factor influencing\nRL fine-tuning success is the training curriculum: the order in which training\nproblems are presented. While random curricula serve as common baselines, they\nremain suboptimal; manually designed curricula often rely heavily on\nheuristics, and online filtering methods can be computationally prohibitive. To\naddress these limitations, we propose Self-Evolving Curriculum (SEC), an\nautomatic curriculum learning method that learns a curriculum policy\nconcurrently with the RL fine-tuning process. Our approach formulates\ncurriculum selection as a non-stationary Multi-Armed Bandit problem, treating\neach problem category (e.g., difficulty level or problem type) as an individual\narm. We leverage the absolute advantage from policy gradient methods as a proxy\nmeasure for immediate learning gain. At each training step, the curriculum\npolicy selects categories to maximize this reward signal and is updated using\nthe TD(0) method. Across three distinct reasoning domains: planning, inductive\nreasoning, and mathematics, our experiments demonstrate that SEC significantly\nimproves models' reasoning capabilities, enabling better generalization to\nharder, out-of-distribution test problems. Additionally, our approach achieves\nbetter skill balance when fine-tuning simultaneously on multiple reasoning\ndomains. These findings highlight SEC as a promising strategy for RL\nfine-tuning of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-Evolving Curriculum (SEC) \u7684\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u89c4\u5212\u3001\u5f52\u7eb3\u63a8\u7406\u548c\u6570\u5b66\u7b49\u4e0d\u540c\u63a8\u7406\u9886\u57df\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u591a\u63a8\u7406\u9886\u57df\u7684\u540c\u65f6\u5fae\u8c03\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6280\u80fd\u5e73\u8861\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u6548\uff0c\u4f46\u8bad\u7ec3\u8bfe\u7a0b\uff08\u95ee\u9898\u5448\u73b0\u987a\u5e8f\uff09\u5bf9\u5fae\u8c03\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u968f\u673a\u8bfe\u7a0b\u548c\u624b\u52a8\u8bbe\u8ba1\u8bfe\u7a0b\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5c06\u8bfe\u7a0b\u9009\u62e9\u5efa\u6a21\u4e3a\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u5229\u7528\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4f5c\u4e3a\u5373\u65f6\u5b66\u4e60\u589e\u76ca\u7684\u4ee3\u7406\u5ea6\u91cf\uff0c\u901a\u8fc7TD(0)\u65b9\u6cd5\u66f4\u65b0\u8bfe\u7a0b\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSEC\u5728\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4ee5\u53ca\u5904\u7406\u66f4\u96be\u3001\u5206\u5e03\u5916\u6d4b\u8bd5\u95ee\u9898\u7684\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1b\u540c\u65f6\uff0c\u5728\u591a\u63a8\u7406\u9886\u57df\u7684\u5fae\u8c03\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6280\u80fd\u5e73\u8861\u3002", "conclusion": "SEC\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7b56\u7565\u3002"}}
{"id": "2505.15013", "pdf": "https://arxiv.org/pdf/2505.15013", "abs": "https://arxiv.org/abs/2505.15013", "authors": ["Anupama Sridhar", "Alexander Johansen"], "title": "Convergence of Adam in Deep ReLU Networks via Directional Complexity and Kakeya Bounds", "categories": ["stat.ML", "cs.LG"], "comment": "9 pages main paper", "summary": "First-order adaptive optimization methods like Adam are the default choices\nfor training modern deep neural networks. Despite their empirical success, the\ntheoretical understanding of these methods in non-smooth settings, particularly\nin Deep ReLU networks, remains limited. ReLU activations create exponentially\nmany region boundaries where standard smoothness assumptions break down.\n\\textbf{We derive the first\n\\(\\tilde{O}\\!\\bigl(\\sqrt{d_{\\mathrm{eff}}/n}\\bigr)\\) generalization bound for\nAdam in Deep ReLU networks and the first global-optimal convergence for Adam in\nthe non smooth, non convex relu landscape without a global PL or convexity\nassumption.} Our analysis is based on stratified Morse theory and novel results\nin Kakeya sets. We develop a multi-layer refinement framework that\nprogressively tightens bounds on region crossings. We prove that the number of\nregion crossings collapses from exponential to near-linear in the effective\ndimension. Using a Kakeya based method, we give a tighter generalization bound\nthan PAC-Bayes approaches and showcase convergence using a mild uniform low\nbarrier assumption.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u548c\u4f18\u5316Adam\u5728\u6df1\u5ea6ReLU\u7f51\u7edc\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u867d\u7136\u4e00\u9636\u81ea\u9002\u5e94\u4f18\u5316\u65b9\u6cd5\u5982Adam\u5728\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7528\u5e76\u53d6\u5f97\u5b9e\u8bc1\u6210\u529f\uff0c\u4f46\u5176\u5728\u975e\u5149\u6ed1\u73af\u5883\u4e0b\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\uff0c\u5c24\u5176\u662f\u6df1\u5ea6ReLU\u7f51\u7edc\u3002ReLU\u6fc0\u6d3b\u51fd\u6570\u5728\u6307\u6570\u6570\u91cf\u7684\u533a\u57df\u8fb9\u754c\u4e0a\u6253\u7834\u4e86\u6807\u51c6\u5e73\u6ed1\u6027\u5047\u8bbe\u3002", "method": "\u57fa\u4e8e\u5206\u5c42Morse\u7406\u8bba\u548cKakeya\u96c6\u7684\u65b0\u6210\u679c\uff0c\u5f00\u53d1\u4e86\u591a\u5c42\u7ec6\u5316\u6846\u67b6\u6765\u9010\u6b65\u6536\u7d27\u533a\u57df\u4ea4\u53c9\u7684\u754c\u9650\u3002", "result": "\u8bc1\u660e\u4e86\u533a\u57df\u4ea4\u53c9\u7684\u6570\u91cf\u4ece\u6307\u6570\u7ea7\u4e0b\u964d\u5230\u63a5\u8fd1\u7ebf\u6027\u7684\u6709\u6548\u7ef4\u5ea6\u3002\u5229\u7528\u57fa\u4e8eKakeya\u7684\u65b9\u6cd5\u7ed9\u51fa\u4e86\u6bd4PAC-Bayes\u65b9\u6cd5\u66f4\u7d27\u81f4\u7684\u5e7f\u4e49\u754c\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u8f7b\u5fae\u4e00\u81f4\u4f4e\u969c\u788d\u5047\u8bbe\u4e0b\u7684\u6536\u655b\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5bf9Adam\u4f18\u5316\u5668\u5728\u6df1\u5ea6ReLU\u7f51\u7edc\u4e2d\u7684\u9996\u4e2a\u5e7f\u4e49\u754c\uff0c\u5e76\u4e14\u5728\u975e\u5149\u6ed1\u3001\u975e\u51f8ReLU\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86Adam\u7684\u9996\u4e2a\u5168\u5c40\u6700\u4f18\u6536\u655b\u6027\uff0c\u65e0\u9700\u5168\u5c40PL\u6216\u51f8\u6027\u5047\u8bbe\u3002"}}
{"id": "2505.14733", "pdf": "https://arxiv.org/pdf/2505.14733", "abs": "https://arxiv.org/abs/2505.14733", "authors": ["Yunho Jin", "Gu-Yeon Wei", "David Brooks"], "title": "The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scaling large language models (LLMs) has driven significant advancements, yet\nit faces diminishing returns and escalating energy demands. This work\nintroduces test-time compute (TTC)-allocating additional computational\nresources during inference-as a compelling complement to conventional scaling\nstrategies. Specifically, we investigate whether employing TTC can achieve\nsuperior accuracy-energy trade-offs compared to simply increasing model size.\nOur empirical analysis reveals that TTC surpasses traditional model scaling in\naccuracy/energy efficiency, with notable gains in tasks demanding complex\nreasoning rather than mere factual recall. Further, we identify a critical\ninteraction between TTC performance and output sequence length, demonstrating\nthat strategically adjusting compute resources at inference time according to\nquery complexity can substantially enhance efficiency. Our findings advocate\nfor TTC as a promising direction, enabling more sustainable, accurate, and\nadaptable deployment of future language models without incurring additional\npretraining costs.", "AI": {"tldr": "This paper introduces test-time compute (TTC) for large language models, showing it improves accuracy-energy trade-offs over traditional model scaling, especially for complex reasoning tasks.", "motivation": "Traditional scaling strategies face diminishing returns and high energy demands.", "method": "Investigates the use of TTC to allocate additional computational resources during inference.", "result": "TTC surpasses traditional scaling in accuracy/energy efficiency, particularly in complex reasoning tasks.", "conclusion": "TTC is a promising approach for deploying more sustainable, accurate, and adaptable language models without extra pretraining costs."}}
{"id": "2505.14983", "pdf": "https://arxiv.org/pdf/2505.14983", "abs": "https://arxiv.org/abs/2505.14983", "authors": ["Zahra Zahedi", "Shashank Mehrotra", "Teruhisa Misu", "Kumar Akash"], "title": "Toward Informed AV Decision-Making: Computational Model of Well-being and Trust in Mobility", "categories": ["cs.AI", "cs.HC", "cs.RO"], "comment": null, "summary": "For future human-autonomous vehicle (AV) interactions to be effective and\nsmooth, human-aware systems that analyze and align human needs with automation\ndecisions are essential. Achieving this requires systems that account for human\ncognitive states. We present a novel computational model in the form of a\nDynamic Bayesian Network (DBN) that infers the cognitive states of both AV\nusers and other road users, integrating this information into the AV's\ndecision-making process. Specifically, our model captures the well-being of\nboth an AV user and an interacting road user as cognitive states alongside\ntrust. Our DBN models infer beliefs over the AV user's evolving well-being,\ntrust, and intention states, as well as the possible well-being of other road\nusers, based on observed interaction experiences. Using data collected from an\ninteraction study, we refine the model parameters and empirically assess its\nperformance. Finally, we extend our model into a causal inference model (CIM)\nframework for AV decision-making, enabling the AV to enhance user well-being\nand trust while balancing these factors with its own operational costs and the\nwell-being of interacting road users. Our evaluation demonstrates the model's\neffectiveness in accurately predicting user's states and guiding informed,\nhuman-centered AV decisions.", "AI": {"tldr": "Develops a computational model using Dynamic Bayesian Network (DBN) to infer cognitive states of AV users and other road users, integrating this information into AV decision-making.", "motivation": "To ensure effective and smooth human-AV interactions by analyzing and aligning human needs with automation decisions.", "method": "Presents a novel computational model in the form of DBN to infer cognitive states like well-being, trust, and intention of AV users and other road users.", "result": "The model is refined using collected data and its performance is empirically assessed.", "conclusion": "Extends the model into a causal inference model (CIM) framework for AV decision-making to enhance user well-being and trust while balancing operational costs."}}
{"id": "2505.15022", "pdf": "https://arxiv.org/pdf/2505.15022", "abs": "https://arxiv.org/abs/2505.15022", "authors": ["Ya-Yun Huang", "Joseph McClernon", "Jason A. Oliver", "Matthew M. Engelhard"], "title": "Infinite hierarchical contrastive clustering for personal digital envirotyping", "categories": ["stat.ML", "cs.LG"], "comment": "10pages, 5 figures, Machine Learning four Health(ML4H 2024)", "summary": "Daily environments have profound influence on our health and behavior. Recent\nwork has shown that digital envirotyping, where computer vision is applied to\nimages of daily environments taken during ecological momentary assessment\n(EMA), can be used to identify meaningful relationships between environmental\nfeatures and health outcomes of interest. To systematically study such effects\non an individual level, it is helpful to group images into distinct\nenvironments encountered in an individual's daily life; these may then be\nanalyzed, further grouped into related environments with similar features, and\nlinked to health outcomes. Here we introduce infinite hierarchical contrastive\nclustering to address this challenge. Building on the established contrastive\nclustering framework, our method a) allows an arbitrary number of clusters\nwithout requiring the full Dirichlet Process machinery by placing a\nstick-breaking prior on predicted cluster probabilities; and b) encourages\ndistinct environments to form well-defined sub-clusters within each cluster of\nrelated environments by incorporating a participant-specific prediction loss.\nOur experiments show that our model effectively identifies distinct personal\nenvironments and groups these environments into meaningful environment types.\nWe then illustrate how the resulting clusters can be linked to various health\noutcomes, highlighting the potential of our approach to advance the\nenvirotyping paradigm.", "AI": {"tldr": "This paper introduces a method called infinite hierarchical contrastive clustering to identify and group personal environments from daily life images for linking with health outcomes.", "motivation": "To systematically study the effects of daily environments on health at an individual level by grouping images into distinct environments and analyzing their relationships with health outcomes.", "method": "Infinite hierarchical contrastive clustering that allows an arbitrary number of clusters and encourages distinct environments to form well-defined sub-clusters within each cluster of related environments.", "result": "The model effectively identifies distinct personal environments and groups them into meaningful environment types, showing potential to advance the envirotyping paradigm.", "conclusion": "The introduced method provides a way to systematically study the relationship between daily environments and health outcomes at an individual level."}}
{"id": "2505.14737", "pdf": "https://arxiv.org/pdf/2505.14737", "abs": "https://arxiv.org/abs/2505.14737", "authors": ["Huiliang Zhang", "Di Wu", "Arnaud Zinflou", "Stephane Dellacherie", "Mouhamadou Makhtar Dione", "Benoit Boulet"], "title": "Leveraging Multivariate Long-Term History Representation for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multivariate Time Series (MTS) forecasting has a wide range of applications\nin both industry and academia. Recent advances in Spatial-Temporal Graph Neural\nNetwork (STGNN) have achieved great progress in modelling spatial-temporal\ncorrelations. Limited by computational complexity, most STGNNs for MTS\nforecasting focus primarily on short-term and local spatial-temporal\ndependencies. Although some recent methods attempt to incorporate univariate\nhistory into modeling, they still overlook crucial long-term spatial-temporal\nsimilarities and correlations across MTS, which are essential for accurate\nforecasting. To fill this gap, we propose a framework called the Long-term\nMultivariate History Representation (LMHR) Enhanced STGNN for MTS forecasting.\nSpecifically, a Long-term History Encoder (LHEncoder) is adopted to effectively\nencode the long-term history into segment-level contextual representations and\nreduce point-level noise. A non-parametric Hierarchical Representation\nRetriever (HRetriever) is designed to include the spatial information in the\nlong-term spatial-temporal dependency modelling and pick out the most valuable\nrepresentations with no additional training. A Transformer-based Aggregator\n(TAggregator) selectively fuses the sparsely retrieved contextual\nrepresentations based on the ranking positional embedding efficiently.\nExperimental results demonstrate that LMHR outperforms typical STGNNs by 10.72%\non the average prediction horizons and state-of-the-art methods by 4.12% on\nseveral real-world datasets. Additionally, it consistently improves prediction\naccuracy by 9.8% on the top 10% of rapidly changing patterns across the\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684STGNN\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u957f\u671f\u5386\u53f2\u4fe1\u606f\u6765\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5927\u591a\u6570STGNNs\u4e3b\u8981\u5173\u6ce8\u77ed\u671f\u548c\u5c40\u90e8\u65f6\u7a7a\u4f9d\u8d56\u6027\uff0c\u800c\u5ffd\u7565\u957f\u671f\u65f6\u7a7a\u76f8\u4f3c\u6027\u548c\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff08MTS\uff09\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51fa\u7684\u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u957f\u671f\u5386\u53f2\u7f16\u7801\u5668\uff08LHEncoder\uff09\uff0c\u4e00\u4e2a\u975e\u53c2\u6570\u5c42\u6b21\u8868\u793a\u68c0\u7d22\u5668\uff08HRetriever\uff09\u548c\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u805a\u5408\u5668\uff08TAggregator\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e73\u5747\u9884\u6d4b\u8303\u56f4\u4e0a\u6bd4\u5178\u578b\u7684STGNNs\u9ad8\u51fa10.72\uff05\uff0c\u5728\u51e0\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u9ad8\u51fa4.12\uff05\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd4\u5178\u578bSTGNN\u548c\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002\u6b64\u5916\uff0c\u5728\u6570\u636e\u96c6\u4e2d\u5feb\u901f\u53d8\u5316\u6a21\u5f0f\u7684\u524d10\uff05\u7684\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u9ad8\u4e869.8\uff05\u3002"}}
{"id": "2505.15011", "pdf": "https://arxiv.org/pdf/2505.15011", "abs": "https://arxiv.org/abs/2505.15011", "authors": ["Kryspin Varys", "Federico Cerutti", "Adam Sobey", "Timothy J. Norman"], "title": "HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Our society is governed by a set of norms which together bring about the\nvalues we cherish such as safety, fairness or trustworthiness. The goal of\nvalue-alignment is to create agents that not only do their tasks but through\ntheir behaviours also promote these values. Many of the norms are written as\nlaws or rules (legal / safety norms) but even more remain unwritten (social\nnorms). Furthermore, the techniques used to represent these norms also differ.\nSafety / legal norms are often represented explicitly, for example, in some\nlogical language while social norms are typically learned and remain hidden in\nthe parameter space of a neural network. There is a lack of approaches in the\nliterature that could combine these various norm representations into a single\nalgorithm. We propose a novel method that integrates these norms into the\nreinforcement learning process. Our method monitors the agent's compliance with\nthe given norms and summarizes it in a quantity we call the agent's reputation.\nThis quantity is used to weigh the received rewards to motivate the agent to\nbecome value-aligned. We carry out a series of experiments including a\ncontinuous state space traffic problem to demonstrate the importance of the\nwritten and unwritten norms and show how our method can find the value-aligned\npolicies. Furthermore, we carry out ablations to demonstrate why it is better\nto combine these two groups of norms rather than using either separately.", "AI": {"tldr": "This paper introduces a novel method to integrate both explicit and implicit norms into reinforcement learning, promoting value-aligned behavior.", "motivation": "To address the lack of approaches combining different norm representations in literature for creating value-aligned agents.", "method": "Integrating norms into reinforcement learning by monitoring compliance and summarizing it as 'reputation', which weighs rewards.", "result": "The proposed method demonstrates its effectiveness in continuous state space traffic problems and shows benefits over using either group of norms separately through ablation studies.", "conclusion": "Combining explicit and implicit norms improves value-alignment in agents through reinforcement learning."}}
{"id": "2505.15175", "pdf": "https://arxiv.org/pdf/2505.15175", "abs": "https://arxiv.org/abs/2505.15175", "authors": ["Diego Granziol", "Donald Flynn"], "title": "A Linear Approach to Data Poisoning", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "9 pages, 9 Figures", "summary": "We investigate the theoretical foundations of data poisoning attacks in\nmachine learning models. Our analysis reveals that the Hessian with respect to\nthe input serves as a diagnostic tool for detecting poisoning, exhibiting\nspectral signatures that characterize compromised datasets. We use random\nmatrix theory (RMT) to develop a theory for the impact of poisoning proportion\nand regularisation on attack efficacy in linear regression. Through QR stepwise\nregression, we study the spectral signatures of the Hessian in multi-output\nregression. We perform experiments on deep networks to show experimentally that\nthis theory extends to modern convolutional and transformer networks under the\ncross-entropy loss. Based on these insights we develop preliminary algorithms\nto determine if a network has been poisoned and remedies which do not require\nfurther training.", "AI": {"tldr": "This paper investigates data poisoning attacks on machine learning models, developing theories and methods to detect and mitigate such attacks using Hessian spectral signatures and random matrix theory.", "motivation": "To explore the theoretical foundations of data poisoning attacks and develop ways to detect and address them.", "method": "Analyzing the Hessian with respect to the input, using random matrix theory for linear regression, performing QR stepwise regression, and conducting experiments on deep networks.", "result": "Found spectral signatures in the Hessian that can characterize compromised datasets and developed algorithms to detect poisoning without additional training.", "conclusion": "Theoretical and experimental results suggest that the developed methods can be used to detect and mitigate data poisoning attacks in various types of machine learning models."}}
{"id": "2505.14739", "pdf": "https://arxiv.org/pdf/2505.14739", "abs": "https://arxiv.org/abs/2505.14739", "authors": ["Heiko Oppel", "Andreas Spilz", "Michael Munz"], "title": "Time Series Similarity Score Functions to Monitor and Interact with the Training and Denoising Process of a Time Series Diffusion Model applied to a Human Activity Recognition Dataset based on IMUs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Denoising diffusion probabilistic models are able to generate synthetic\nsensor signals. The training process of such a model is controlled by a loss\nfunction which measures the difference between the noise that was added in the\nforward process and the noise that was predicted by the diffusion model. This\nenables the generation of realistic data. However, the randomness within the\nprocess and the loss function itself makes it difficult to estimate the quality\nof the data. Therefore, we examine multiple similarity metrics and adapt an\nexisting metric to overcome this issue by monitoring the training and\nsynthetisation process using those metrics. The adapted metric can even be\nfine-tuned on the input data to comply with the requirements of an underlying\nclassification task. We were able to significantly reduce the amount of\ntraining epochs without a performance reduction in the classification task. An\noptimized training process not only saves resources, but also reduces the time\nfor training generative models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u6765\u8bc4\u4f30\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u8be5\u5ea6\u91cf\u4ee5\u9002\u5e94\u5206\u7c7b\u4efb\u52a1\u9700\u6c42\uff0c\u4ece\u800c\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u5468\u671f\u6570\u4e14\u4e0d\u964d\u4f4e\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u751f\u6210\u6570\u636e\u8d28\u91cf\u96be\u4ee5\u4f30\u8ba1\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u76d1\u63a7\u548c\u4f18\u5316\u8bad\u7ec3\u53ca\u6570\u636e\u5408\u6210\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5e76\u8c03\u6574\u73b0\u6709\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u5206\u7c7b\u4efb\u52a1\u9700\u6c42\uff0c\u540c\u65f6\u51cf\u5c11\u8bad\u7ec3\u5468\u671f\u6570\u3002", "result": "\u63d0\u51fa\u7684\u6539\u8fdb\u5ea6\u91cf\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\uff0c\u5e76\u5728\u4e0d\u964d\u4f4e\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u5468\u671f\u6570\u3002", "conclusion": "\u4f18\u5316\u540e\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e0d\u4ec5\u8282\u7701\u8d44\u6e90\uff0c\u8fd8\u51cf\u5c11\u4e86\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2505.15068", "pdf": "https://arxiv.org/pdf/2505.15068", "abs": "https://arxiv.org/abs/2505.15068", "authors": ["Cheng Qian", "Hongyi Du", "Hongru Wang", "Xiusi Chen", "Yuji Zhang", "Avirup Sil", "Chengxiang Zhai", "Kathleen McKeown", "Heng Ji"], "title": "ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "36 Pages, 26 Figures, 5 Tables", "summary": "Recent progress in large language models (LLMs) has enabled substantial\nadvances in solving mathematical problems. However, existing benchmarks often\nfail to reflect the complexity of real-world problems, which demand open-ended,\ninterdisciplinary reasoning and integration of computational tools. To address\nthis gap, we introduce ModelingBench, a novel benchmark featuring\nreal-world-inspired, open-ended problems from math modeling competitions across\ndiverse domains, ranging from urban traffic optimization to ecosystem resource\nplanning. These tasks require translating natural language into formal\nmathematical formulations, applying appropriate tools, and producing\nstructured, defensible reports. ModelingBench also supports multiple valid\nsolutions, capturing the ambiguity and creativity of practical modeling. We\nalso present ModelingAgent, a multi-agent framework that coordinates tool use,\nsupports structured workflows, and enables iterative self-refinement to\ngenerate well-grounded, creative solutions. To evaluate outputs, we further\npropose ModelingJudge, an expert-in-the-loop system leveraging LLMs as\ndomain-specialized judges assessing solutions from multiple expert\nperspectives. Empirical results show that ModelingAgent substantially\noutperforms strong baselines and often produces solutions indistinguishable\nfrom those of human experts. Together, our work provides a comprehensive\nframework for evaluating and advancing real-world problem-solving in\nopen-ended, interdisciplinary modeling challenges.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6ModelingBench\u548c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6ModelingAgent\uff0c\u7528\u4e8e\u89e3\u51b3\u5f00\u653e\u6027\u3001\u8de8\u5b66\u79d1\u7684\u6570\u5b66\u5efa\u6a21\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86ModelingJudge\u7cfb\u7edf\u6765\u8bc4\u4f30\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u5f00\u653e\u6027\u548c\u8de8\u5b66\u79d1\u63a8\u7406\u4ee5\u53ca\u8ba1\u7b97\u5de5\u5177\u7684\u96c6\u6210\u3002", "method": "\u5f15\u5165\u4e86ModelingBench\uff0c\u5305\u542b\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u5f00\u653e\u6027\u95ee\u9898\uff1b\u5f00\u53d1\u4e86ModelingAgent\uff0c\u4e00\u4e2a\u652f\u6301\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u5e76\u80fd\u81ea\u6211\u5b8c\u5584\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\u7684\u6846\u67b6\uff1b\u63d0\u51fa\u4e86ModelingJudge\uff0c\u4e00\u4e2a\u4eba\u7c7b\u4e13\u5bb6\u53c2\u4e0e\u7684\u5faa\u73af\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002", "result": "ModelingAgent\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e14\u5176\u4ea7\u751f\u7684\u89e3\u51b3\u65b9\u6848\u7ecf\u5e38\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u89e3\u51b3\u65b9\u6848\u96be\u4ee5\u533a\u5206\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u548c\u63a8\u8fdb\u5f00\u653e\u6027\u3001\u8de8\u5b66\u79d1\u6570\u5b66\u5efa\u6a21\u6311\u6218\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2505.15215", "pdf": "https://arxiv.org/pdf/2505.15215", "abs": "https://arxiv.org/abs/2505.15215", "authors": ["Otto Tabell", "Santtu Tikka", "Juha Karvanen"], "title": "Clustering and Pruning in Causal Data Fusion", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Data fusion, the process of combining observational and experimental data,\ncan enable the identification of causal effects that would otherwise remain\nnon-identifiable. Although identification algorithms have been developed for\nspecific scenarios, do-calculus remains the only general-purpose tool for\ncausal data fusion, particularly when variables are present in some data\nsources but not others. However, approaches based on do-calculus may encounter\ncomputational challenges as the number of variables increases and the causal\ngraph grows in complexity. Consequently, there exists a need to reduce the size\nof such models while preserving the essential features. For this purpose, we\npropose pruning (removing unnecessary variables) and clustering (combining\nvariables) as preprocessing operations for causal data fusion. We generalize\nearlier results on a single data source and derive conditions for applying\npruning and clustering in the case of multiple data sources. We give sufficient\nconditions for inferring the identifiability or non-identifiability of a causal\neffect in a larger graph based on a smaller graph and show how to obtain the\ncorresponding identifying functional for identifiable causal effects. Examples\nfrom epidemiology and social science demonstrate the use of the results.", "AI": {"tldr": "This paper addresses computational challenges in causal data fusion by proposing pruning and clustering as preprocessing operations.", "motivation": "To enable identification of causal effects that would otherwise remain non-identifiable using data fusion.", "method": "Proposing pruning and clustering techniques for reducing model size while preserving essential features.", "result": "Generalized earlier results on a single data source and derived conditions for applying these techniques in multiple data sources.", "conclusion": "The proposed methods can infer the identifiability of causal effects in larger graphs based on smaller ones and have applications in epidemiology and social sciences."}}
{"id": "2505.14741", "pdf": "https://arxiv.org/pdf/2505.14741", "abs": "https://arxiv.org/abs/2505.14741", "authors": ["Kunyun Wang", "Bohan Li", "Kai Yu", "Minyi Guo", "Jieru Zhao"], "title": "Communication-Efficient Diffusion Denoising Parallelization via Reuse-then-Predict Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have emerged as a powerful class of generative models across\nvarious modalities, including image, video, and audio synthesis. However, their\ndeployment is often limited by significant inference latency, primarily due to\nthe inherently sequential nature of the denoising process. While existing\nparallelization strategies attempt to accelerate inference by distributing\ncomputation across multiple devices, they typically incur high communication\noverhead, hindering deployment on commercial hardware. To address this\nchallenge, we propose \\textbf{ParaStep}, a novel parallelization method based\non a reuse-then-predict mechanism that parallelizes diffusion inference by\nexploiting similarity between adjacent denoising steps. Unlike prior approaches\nthat rely on layer-wise or stage-wise communication, ParaStep employs\nlightweight, step-wise communication, substantially reducing overhead. ParaStep\nachieves end-to-end speedups of up to \\textbf{3.88}$\\times$ on SVD,\n\\textbf{2.43}$\\times$ on CogVideoX-2b, and \\textbf{6.56}$\\times$ on\nAudioLDM2-large, while maintaining generation quality. These results highlight\nParaStep as a scalable and communication-efficient solution for accelerating\ndiffusion inference, particularly in bandwidth-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a ParaStep \u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u901a\u4fe1\u51cf\u5c11\u6269\u6563\u6a21\u578b\u63a8\u7406\u7684\u5ef6\u8fdf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u79cd\u4efb\u52a1\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u5e76\u884c\u5316\u7b56\u7565\u901a\u5e38\u4f1a\u5e26\u6765\u9ad8\u901a\u4fe1\u5f00\u9500\uff0c\u9650\u5236\u4e86\u6269\u6563\u6a21\u578b\u5728\u5546\u4e1a\u786c\u4ef6\u4e0a\u7684\u90e8\u7f72\u3002", "method": "ParaStep \u57fa\u4e8e\u91cd\u7528-\u7136\u540e\u9884\u6d4b\u673a\u5236\uff0c\u901a\u8fc7\u5229\u7528\u76f8\u90bb\u53bb\u566a\u6b65\u9aa4\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6765\u5e76\u884c\u5316\u6269\u6563\u63a8\u7406\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u7684\u6b65\u9aa4\u95f4\u901a\u4fe1\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u5f00\u9500\u3002", "result": "ParaStep \u5728 SVD \u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe 3.88 \u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5728 CogVideoX-2b \u4e0a\u5b9e\u73b0\u4e86 2.43 \u500d\uff0c\u5728 AudioLDM2-large \u4e0a\u5b9e\u73b0\u4e86 6.56 \u500d\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "ParaStep \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e76\u884c\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528-\u7136\u540e\u9884\u6d4b\u673a\u5236\u6765\u52a0\u901f\u6269\u6563\u63a8\u7406\uff0c\u7279\u522b\u662f\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.15146", "pdf": "https://arxiv.org/pdf/2505.15146", "abs": "https://arxiv.org/abs/2505.15146", "authors": ["Lanxiang Hu", "Mingjia Huo", "Yuxuan Zhang", "Haoyang Yu", "Eric P. Xing", "Ion Stoica", "Tajana Rosing", "Haojian Jin", "Hao Zhang"], "title": "lmgame-Bench: How Good are LLMs at Playing Games?", "categories": ["cs.AI"], "comment": null, "summary": "Playing video games requires perception, memory, and planning, exactly the\nfaculties modern large language model (LLM) agents are expected to master. We\nstudy the major challenges in using popular video games to evaluate modern LLMs\nand find that directly dropping LLMs into games cannot make an effective\nevaluation, for three reasons -- brittle vision perception, prompt sensitivity,\nand potential data contamination. We introduce lmgame-Bench to turn games into\nreliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and\nnarrative games delivered through a unified Gym-style API and paired with\nlightweight perception and memory scaffolds, and is designed to stabilize\nprompt variance and remove contamination. Across 13 leading models, we show\nlmgame-Bench is challenging while still separating models well. Correlation\nanalysis shows that every game probes a unique blend of capabilities often\ntested in isolation elsewhere. More interestingly, performing reinforcement\nlearning on a single game from lmgame-Bench transfers both to unseen games and\nto external planning tasks. Our evaluation code is available at\nhttps://github.com/lmgame-org/GamingAgent/lmgame-bench.", "AI": {"tldr": "This paper introduces lmgame-Bench, a benchmark for evaluating modern large language models using video games. It addresses issues like brittle vision perception and prompt sensitivity by providing a unified API and lightweight perception and memory scaffolds.", "motivation": "To create a reliable evaluation method for modern LLMs using video games by addressing challenges such as vision perception, prompt sensitivity, and potential data contamination.", "method": "Introduce lmgame-Bench which includes platformer, puzzle, and narrative games with a unified Gym-style API and lightweight perception and memory scaffolds.", "result": "The benchmark is challenging yet capable of differentiating between 13 leading models. Correlation analysis reveals each game tests a unique combination of capabilities. Reinforcement learning on one game transfers to unseen games and external planning tasks.", "conclusion": "lmgame-Bench provides a robust evaluation framework for LLMs in video games, addressing key challenges and showing transferable skills."}}
{"id": "2505.15342", "pdf": "https://arxiv.org/pdf/2505.15342", "abs": "https://arxiv.org/abs/2505.15342", "authors": ["Kaito Ariu", "Po-An Wang", "Alexandre Proutiere", "Kenshi Abe"], "title": "Policy Testing in Markov Decision Processes", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We study the policy testing problem in discounted Markov decision processes\n(MDPs) under the fixed-confidence setting. The goal is to determine whether the\nvalue of a given policy exceeds a specified threshold while minimizing the\nnumber of observations. We begin by deriving an instance-specific lower bound\nthat any algorithm must satisfy. This lower bound is characterized as the\nsolution to an optimization problem with non-convex constraints. We propose a\npolicy testing algorithm inspired by this optimization problem--a common\napproach in pure exploration problems such as best-arm identification, where\nasymptotically optimal algorithms often stem from such optimization-based\ncharacterizations. As for other pure exploration tasks in MDPs, however, the\nnon-convex constraints in the lower-bound problem present significant\nchallenges, raising doubts about whether statistically optimal and\ncomputationally tractable algorithms can be designed. To address this, we\nreformulate the lower-bound problem by interchanging the roles of the objective\nand the constraints, yielding an alternative problem with a non-convex\nobjective but convex constraints. Strikingly, this reformulated problem admits\nan interpretation as a policy optimization task in a newly constructed reversed\nMDP. Leveraging recent advances in policy gradient methods, we efficiently\nsolve this problem and use it to design a policy testing algorithm that is\nstatistically optimal--matching the instance-specific lower bound on sample\ncomplexity--while remaining computationally tractable. We validate our approach\nwith numerical experiments.", "AI": {"tldr": "\u5728\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u7edf\u8ba1\u548c\u8ba1\u7b97\u4e0a\u90fd\u662f\u6709\u6548\u7684\u3002", "motivation": "\u7814\u7a76\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u4e2d\u7684\u7b56\u7565\u6d4b\u8bd5\u95ee\u9898\uff0c\u5728\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bbe\u7f6e\u4e0b\uff0c\u786e\u5b9a\u7ed9\u5b9a\u7b56\u7565\u7684\u4ef7\u503c\u662f\u5426\u8d85\u8fc7\u6307\u5b9a\u9608\u503c\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u89c2\u5bdf\u6b21\u6570\u3002", "method": "\u901a\u8fc7\u91cd\u65b0\u6784\u5efa\u4e0b\u754c\u95ee\u9898\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u4e00\u4e2a\u5177\u6709\u975e\u51f8\u76ee\u6807\u4f46\u51f8\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u89e3\u91ca\u4e3a\u4e00\u4e2a\u65b0\u7684\u53cd\u8f6cMDP\u4e2d\u7684\u7b56\u7565\u4f18\u5316\u4efb\u52a1\u3002\u5229\u7528\u6700\u65b0\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u6765\u9ad8\u6548\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7edf\u8ba1\u6700\u4f18\u7684\u7b56\u7565\u6d4b\u8bd5\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u8fbe\u5230\u4e86\u5b9e\u4f8b\u7279\u5b9a\u7684\u4e0b\u754c\u5339\u914d\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u4e0a\u662f\u53ef\u884c\u7684\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bbe\u7f6e\u4e0b\u7684\u7b56\u7565\u6d4b\u8bd5\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u5b9e\u4f8b\u7279\u5b9a\u7684\u4e0b\u754c\u5339\u914d\uff0c\u5e76\u4fdd\u6301\u4e86\u8ba1\u7b97\u4e0a\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2505.14742", "pdf": "https://arxiv.org/pdf/2505.14742", "abs": "https://arxiv.org/abs/2505.14742", "authors": ["Hong Huang", "Dapeng Wu"], "title": "Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have made exciting achievements across various\ndomains, yet their deployment on resource-constrained personal devices remains\nhindered by the prohibitive computational and memory demands of task-specific\nfine-tuning. While quantization offers a pathway to efficiency, existing\nmethods struggle to balance performance and overhead, either incurring high\ncomputational/memory costs or failing to address activation outliers, a\ncritical bottleneck in quantized fine-tuning. To address these challenges, we\npropose the Outlier Spatial Stability Hypothesis (OSSH): During fine-tuning,\ncertain activation outlier channels retain stable spatial positions across\ntraining iterations. Building on OSSH, we propose Quaff, a Quantized\nparameter-efficient fine-tuning framework for LLMs, optimizing low-precision\nactivation representations through targeted momentum scaling. Quaff dynamically\nsuppresses outliers exclusively in invariant channels using lightweight\noperations, eliminating full-precision weight storage and global rescaling\nwhile reducing quantization errors. Extensive experiments across ten benchmarks\nvalidate OSSH and demonstrate Quaff's efficacy. Specifically, on the GPQA\nreasoning benchmark, Quaff achieves a 1.73x latency reduction and 30% memory\nsavings over full-precision fine-tuning while improving accuracy by 0.6% on the\nPhi-3 model, reconciling the triple trade-off between efficiency, performance,\nand deployability. By enabling consumer-grade GPU fine-tuning (e.g., RTX 2080\nSuper) without sacrificing model utility, Quaff democratizes personalized LLM\ndeployment. The code is available at https://github.com/Little0o0/Quaff.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuaff\u7684\u91cf\u5316\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u76ee\u6807\u52a8\u91cf\u7f29\u653e\u4f18\u5316\u4f4e\u7cbe\u5ea6\u6fc0\u6d3b\u8868\u793a\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u91cf\u5316\u5fae\u8c03\u4e2d\u7684\u6027\u80fd\u4e0e\u5f00\u9500\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8981\u4e48\u8ba1\u7b97/\u5185\u5b58\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u65e0\u6cd5\u89e3\u51b3\u6fc0\u6d3b\u5f02\u5e38\u503c\u8fd9\u4e00\u5173\u952e\u74f6\u9888\u3002", "method": "\u57fa\u4e8e\u63d0\u51fa\u7684Outlier Spatial Stability Hypothesis (OSSH)\uff0cQuaff\u6846\u67b6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u64cd\u4f5c\u52a8\u6001\u6291\u5236\u4e0d\u53d8\u901a\u9053\u4e2d\u7684\u5f02\u5e38\u503c\uff0c\u5e76\u51cf\u5c11\u91cf\u5316\u8bef\u5dee\u3002", "result": "\u5728\u5341\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86OSSH\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86Quaff\u6846\u67b6\u7684\u6548\u80fd\uff0c\u4f8b\u5982\u5728GPQA\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e861.73\u500d\u7684\u5ef6\u8fdf\u51cf\u5c11\u548c30%\u7684\u5185\u5b58\u8282\u7701\u3002", "conclusion": "Quaff\u4f7f\u5f97\u6d88\u8d39\u7ea7GPU\uff08\u5982RTX 2080 Super\uff09\u4e0a\u7684\u4e2a\u4eba\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6210\u4e3a\u53ef\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2505.15240", "pdf": "https://arxiv.org/pdf/2505.15240", "abs": "https://arxiv.org/abs/2505.15240", "authors": ["Yassir Fathullah", "Mark J. F. Gales"], "title": "Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "To appear in UAI 2025", "summary": "This paper explores generalised probabilistic modelling and uncertainty\nestimation in comparative LLM-as-a-judge frameworks. We show that existing\nProduct-of-Experts methods are specific cases of a broader framework, enabling\ndiverse modelling options. Furthermore, we propose improved uncertainty\nestimates for individual comparisons, enabling more efficient selection and\nachieving strong performance with fewer evaluations. We also introduce a method\nfor estimating overall ranking uncertainty. Finally, we demonstrate that\ncombining absolute and comparative scoring improves performance. Experiments\nshow that the specific expert model has a limited impact on final rankings but\nour proposed uncertainty estimates, especially the probability of reordering,\nsignificantly improve the efficiency of systems reducing the number of needed\ncomparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used\nto identify low-performing predictions, where the nature of the probabilistic\nmodel has a notable impact on the quality of the overall uncertainty.", "AI": {"tldr": "This paper studies uncertainty estimation in LLM comparison frameworks and proposes improved methods for individual and overall ranking uncertainty, showing they can significantly increase system efficiency.", "motivation": "To explore uncertainty estimation in comparative LLM frameworks and improve the efficiency of selection processes.", "method": "Extending Product-of-Experts methods and introducing new uncertainty estimation techniques for individual comparisons and overall ranking.", "result": "Improved uncertainty estimates can reduce the number of required comparisons by about 50% and ranking-level uncertainty metrics can identify low-performing predictions.", "conclusion": "Combining absolute and comparative scoring improves performance, and proposed uncertainty estimates enhance system efficiency."}}
{"id": "2505.15417", "pdf": "https://arxiv.org/pdf/2505.15417", "abs": "https://arxiv.org/abs/2505.15417", "authors": ["Leon Chlon", "Maggie Chlon", "MarcAntonio M. Awada"], "title": "Robust Multimodal Learning via Entropy-Gated Contrastive Fusion", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Real-world multimodal systems routinely face missing-input scenarios, and in\nreality, robots lose audio in a factory or a clinical record omits lab tests at\ninference time. Standard fusion layers either preserve robustness or\ncalibration but never both. We introduce Adaptive Entropy-Gated Contrastive\nFusion (AECF), a single light-weight layer that (i) adapts its entropy\ncoefficient per instance, (ii) enforces monotone calibration across all\nmodality subsets, and (iii) drives a curriculum mask directly from\ntraining-time entropy. On AV-MNIST and MS-COCO, AECF improves masked-input mAP\nby +18 pp at a 50% drop rate while reducing ECE by up to 200%, yet adds 1%\nrun-time. All back-bones remain frozen, making AECF an easy drop-in layer for\nrobust, calibrated multimodal inference.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u878d\u5408\u5c42AECF\uff0c\u53ef\u63d0\u9ad8\u591a\u6a21\u6001\u7cfb\u7edf\u5728\u7f3a\u5931\u8f93\u5165\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6821\u51c6\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u6807\u51c6\u878d\u5408\u5c42\u65e0\u6cd5\u540c\u65f6\u4fdd\u8bc1\u9c81\u68d2\u6027\u548c\u6821\u51c6\u6027\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u591a\u6a21\u6001\u7cfb\u7edf\u5e38\u9762\u4e34\u7f3a\u5931\u8f93\u5165\u7684\u60c5\u51b5\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u71b5\u95e8\u9650\u5bf9\u6bd4\u878d\u5408\u5c42\uff08AECF\uff09\uff0c\u8be5\u5c42\u53ef\u6839\u636e\u5b9e\u4f8b\u8c03\u6574\u71b5\u7cfb\u6570\uff0c\u786e\u4fdd\u6240\u6709\u6a21\u6001\u5b50\u96c6\u7684\u5355\u8c03\u6821\u51c6\uff0c\u5e76\u4ece\u8bad\u7ec3\u65f6\u7684\u71b5\u76f4\u63a5\u9a71\u52a8\u8bfe\u7a0b\u63a9\u7801\u3002", "result": "\u5728AV-MNIST\u548cMS-COCO\u6570\u636e\u96c6\u4e0a\uff0cAECF\u572850%\u4e22\u5931\u7387\u4e0b\u63d0\u5347\u4e8618\u4e2a\u767e\u5206\u70b9\u7684\u63a9\u7801\u8f93\u5165mAP\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9ad8\u8fbe200%\u7684ECE\uff0c\u4e14\u589e\u52a0\u4e861%\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "AECF\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u878d\u5408\u5c42\uff0c\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0c\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u548c\u6821\u51c6\u6027\u3002"}}
{"id": "2505.14745", "pdf": "https://arxiv.org/pdf/2505.14745", "abs": "https://arxiv.org/abs/2505.14745", "authors": ["Varun Raaghav", "Dimitrios Bikos", "Antonio Rago", "Francesca Toni", "Maria Charalambides"], "title": "Explainable Prediction of the Mechanical Properties of Composites with CNNs", "categories": ["cs.LG", "cs.AI", "I.2.1"], "comment": "9 pages, 6 figures", "summary": "Composites are amongst the most important materials manufactured today, as\nevidenced by their use in countless applications. In order to establish the\nsuitability of composites in specific applications, finite element (FE)\nmodelling, a numerical method based on partial differential equations, is the\nindustry standard for assessing their mechanical properties. However, FE\nmodelling is exceptionally costly from a computational viewpoint, a limitation\nwhich has led to efforts towards applying AI models to this task. However, in\nthese approaches: the chosen model architectures were rudimentary, feed-forward\nneural networks giving limited accuracy; the studies focus on predicting\nelastic mechanical properties, without considering material strength limits;\nand the models lacked transparency, hindering trustworthiness by users. In this\npaper, we show that convolutional neural networks (CNNs) equipped with methods\nfrom explainable AI (XAI) can be successfully deployed to solve this problem.\nOur approach uses customised CNNs trained on a dataset we generate using\ntransverse tension tests in FE modelling to predict composites' mechanical\nproperties, i.e., Young's modulus and yield strength. We show empirically that\nour approach achieves high accuracy, outperforming a baseline, ResNet-34, in\nestimating the mechanical properties. We then use SHAP and Integrated\nGradients, two post-hoc XAI methods, to explain the predictions, showing that\nthe CNNs use the critical geometrical features that influence the composites'\nbehaviour, thus allowing engineers to verify that the models are trustworthy by\nrepresenting the science of composites.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u53ef\u89e3\u91caAI\u65b9\u6cd5\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u590d\u5408\u6750\u6599\u7684\u673a\u68b0\u6027\u80fd\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u51c6\u786e\u4e14\u66f4\u5177\u900f\u660e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6709\u9650\u5143\u5efa\u6a21\u5728\u8bc4\u4f30\u590d\u5408\u6750\u6599\u673a\u68b0\u6027\u80fd\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b\u5df2\u6709\u7684AI\u6a21\u578b\u67b6\u6784\u7b80\u5355\uff0c\u51c6\u786e\u5ea6\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u900f\u660e\u6027\uff0c\u96be\u4ee5\u83b7\u5f97\u7528\u6237\u4fe1\u4efb\u3002", "method": "\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684CNNs\uff0c\u8bad\u7ec3\u96c6\u7531\u6709\u9650\u5143\u5efa\u6a21\u4e2d\u7684\u6a2a\u62c9\u6d4b\u8bd5\u6570\u636e\u751f\u6210\uff0c\u7528\u4e8e\u9884\u6d4b\u590d\u5408\u6750\u6599\u7684\u6768\u6c0f\u6a21\u91cf\u548c\u5c48\u670d\u5f3a\u5ea6\u3002\u4f7f\u7528SHAP\u548cIntegrated Gradients\u4e24\u79cd\u540e\u9a8cXAI\u65b9\u6cd5\u89e3\u91ca\u9884\u6d4b\u3002", "result": "\u63d0\u51fa\u7684CNNs\u65b9\u6cd5\u5728\u4f30\u8ba1\u673a\u68b0\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u4f18\u4e8e\u57fa\u51c6\u6a21\u578bResNet-34\u3002\u901a\u8fc7XAI\u65b9\u6cd5\u8bc1\u660eCNNs\u4f7f\u7528\u5f71\u54cd\u590d\u5408\u6750\u6599\u884c\u4e3a\u7684\u5173\u952e\u51e0\u4f55\u7279\u5f81\u3002", "conclusion": "\u8bc1\u660e\u4e86\u914d\u5907\u53ef\u89e3\u91caAI(XAI)\u65b9\u6cd5\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNNs)\u53ef\u4ee5\u6210\u529f\u89e3\u51b3\u590d\u5408\u6750\u6599\u673a\u68b0\u6027\u80fd\u9884\u6d4b\u7684\u95ee\u9898\u3002"}}
{"id": "2505.15274", "pdf": "https://arxiv.org/pdf/2505.15274", "abs": "https://arxiv.org/abs/2505.15274", "authors": ["Xin Shu", "Shuai Wang", "Ang Li"], "title": "Identification of Probabilities of Causation: A Complete Characterization", "categories": ["cs.AI"], "comment": null, "summary": "Probabilities of causation are fundamental to modern decision-making. Pearl\nfirst introduced three binary probabilities of causation, and Tian and Pearl\nlater derived tight bounds for them using Balke's linear programming. The\ntheoretical characterization of probabilities of causation with multi-valued\ntreatments and outcomes has remained unresolved for decades, limiting the scope\nof causality-based decision-making. In this paper, we resolve this foundational\ngap by proposing a complete set of representative probabilities of causation\nand proving that they are sufficient to characterize all possible probabilities\nof causation within the framework of Structural Causal Models (SCMs). We then\nformally derive tight bounds for these representative quantities using formal\nmathematical proofs. Finally, we demonstrate the practical relevance of our\nresults through illustrative toy examples.", "AI": {"tldr": "This paper proposes a complete set of representative probabilities of causation for multi-valued treatments and outcomes, proves their sufficiency within SCMs, derives tight bounds for them mathematically, and demonstrates their practical relevance.", "motivation": "To address the unresolved theoretical characterization of probabilities of causation with multi-valued treatments and outcomes, which limits the scope of causality-based decision-making.", "method": "Proposing representative probabilities of causation, proving their sufficiency within SCMs, deriving tight bounds using mathematical proofs.", "result": "A complete set of representative probabilities of causation that can characterize all possible probabilities of causation, tight bounds for these quantities, and demonstration of practical relevance via toy examples.", "conclusion": "The work resolves a foundational gap in the theoretical characterization of probabilities of causation for multi-valued treatments and outcomes, expanding the scope of causality-based decision-making."}}
{"id": "2505.15429", "pdf": "https://arxiv.org/pdf/2505.15429", "abs": "https://arxiv.org/abs/2505.15429", "authors": ["Pritam Anand"], "title": "Uncertainty Quantification in SVM prediction", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper explores Uncertainty Quantification (UQ) in SVM predictions,\nparticularly for regression and forecasting tasks. Unlike the Neural Network,\nthe SVM solutions are typically more stable, sparse, optimal and interpretable.\nHowever, there are only few literature which addresses the UQ in SVM\nprediction. At first, we provide a comprehensive summary of existing Prediction\nInterval (PI) estimation and probabilistic forecasting methods developed in the\nSVM framework and evaluate them against the key properties expected from an\nideal PI model. We find that none of the existing SVM PI models achieves a\nsparse solution. To introduce sparsity in SVM model, we propose the Sparse\nSupport Vector Quantile Regression (SSVQR) model, which constructs PIs and\nprobabilistic forecasts by solving a pair of linear programs. Further, we\ndevelop a feature selection algorithm for PI estimation using SSVQR that\neffectively eliminates a significant number of features while improving PI\nquality in case of high-dimensional dataset. Finally we extend the SVM models\nin Conformal Regression setting for obtaining more stable prediction set with\nfinite test set guarantees. Extensive experiments on artificial, real-world\nbenchmark datasets compare the different characteristics of both existing and\nproposed SVM-based PI estimation methods and also highlight the advantages of\nthe feature selection in PI estimation. Furthermore, we compare both, the\nexisting and proposed SVM-based PI estimation models, with modern deep learning\nmodels for probabilistic forecasting tasks on benchmark datasets. Furthermore,\nSVM models show comparable or superior performance to modern complex deep\nlearning models for probabilistic forecasting task in our experiments.", "AI": {"tldr": "This paper explores Uncertainty Quantification (UQ) in SVM predictions for regression and forecasting tasks. It evaluates existing Prediction Interval (PI) estimation and probabilistic forecasting methods, proposes a Sparse Support Vector Quantile Regression (SSVQR) model, develops a feature selection algorithm, and compares SVM models with deep learning models.", "motivation": "To address the lack of literature on UQ in SVM predictions and improve the stability, sparsity, and interpretability of SVM models.", "method": "Comprehensive evaluation of existing PI estimation methods, proposal of SSVQR model, development of feature selection algorithm, extension of SVM models in Conformal Regression setting, and comparison with deep learning models.", "result": "None of the existing SVM PI models achieves sparsity. The proposed SSVQR model introduces sparsity and improves PI quality in high-dimensional datasets. SVM models show comparable or superior performance to deep learning models for probabilistic forecasting tasks.", "conclusion": "The proposed methods improve the stability, sparsity, and interpretability of SVM models for UQ in predictions."}}
{"id": "2505.14748", "pdf": "https://arxiv.org/pdf/2505.14748", "abs": "https://arxiv.org/abs/2505.14748", "authors": ["Zaifa Xue", "Tao Zhang", "Tuo Xu", "Huaixin Liang", "Le Gao"], "title": "Cooperative Causal GraphSAGE", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "GraphSAGE is a widely used graph neural network. The introduction of causal\ninference has improved its robust performance and named as Causal GraphSAGE.\nHowever, Causal GraphSAGE focuses on measuring causal weighting among\nindividual nodes, but neglecting the cooperative relationships among sampling\nnodes as a whole. To address this issue, this paper proposes Cooperative Causal\nGraphSAGE (CoCa-GraphSAGE), which combines cooperative game theory with Causal\nGraphSAGE. Initially, a cooperative causal structure model is constructed in\nthe case of cooperation based on the graph structure. Subsequently, Cooperative\nCausal sampling (CoCa-sampling) algorithm is proposed, employing the Shapley\nvalues to calculate the cooperative contribution based on causal weights of the\nnodes sets. CoCa-sampling guides the selection of nodes with significant\ncooperative causal effects during the neighborhood sampling process, thus\nintegrating the selected neighborhood features under cooperative relationships,\nwhich takes the sampled nodes as a whole and generates more stable target node\nembeddings. Experiments on publicly available datasets show that the proposed\nmethod has comparable classification performance to the compared methods and\noutperforms under perturbations, demonstrating the robustness improvement by\nCoCa-sampling.", "AI": {"tldr": "This paper introduces Cooperative Causal GraphSAGE (CoCa-GraphSAGE), which enhances the robustness of Causal GraphSAGE by integrating cooperative game theory and considering cooperative relationships among sampling nodes.", "motivation": "To improve the robustness of GraphSAGE and address the limitation of Causal GraphSAGE in neglecting cooperative relationships among sampling nodes.", "method": "Combining cooperative game theory with Causal GraphSAGE to construct a cooperative causal structure model and proposing Cooperative Causal sampling (CoCa-sampling) algorithm using Shapley values.", "result": "Experiments show that the proposed method has comparable classification performance to compared methods and outperforms under perturbations, demonstrating improved robustness.", "conclusion": "CoCa-GraphSAGE improves the robustness of GraphSAGE by considering cooperative relationships among sampling nodes."}}
{"id": "2505.15276", "pdf": "https://arxiv.org/pdf/2505.15276", "abs": "https://arxiv.org/abs/2505.15276", "authors": ["Rongzhi Zhu", "Yi Liu", "Zequn Sun", "Yiwei Wang", "Wei Hu"], "title": "When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) have significantly advanced performance on\ncomplex tasks, yet their tendency to overthink introduces inefficiencies. This\nstudy investigates the internal mechanisms of reinforcement learning\n(RL)-trained LRMs when prompted to save thinking, revealing three distinct\nthinking modes: no thinking (NT), explicit thinking (ET), and implicit thinking\n(IT). Through comprehensive analysis of confidence in thinking termination,\nattention from thinking to generation, and attentional focus on input sections,\nwe uncover key factors influencing the reasoning behaviors. We further find\nthat NT reduces output length at the cost of accuracy, while ET and IT maintain\naccuracy with reduced response length. Our findings expose fundamental\ninconsistencies in RL-optimized LRMs, necessitating adaptive improvements for\nreliable efficiency.", "AI": {"tldr": "This study examines the internal mechanisms of reinforcement learning-trained large reasoning models when prompted to save thinking, identifying three distinct thinking modes and finding that not thinking reduces output length but sacrifices accuracy.", "motivation": "Investigating inefficiencies introduced by overthinking in large reasoning models trained with reinforcement learning.", "method": "Comprehensive analysis of confidence in thinking termination, attention from thinking to generation, and attentional focus on input sections.", "result": "Three distinct thinking modes identified: no thinking, explicit thinking, and implicit thinking. No thinking reduces output length but sacrifices accuracy, whereas explicit and implicit thinking maintain accuracy with shorter responses.", "conclusion": "The study reveals fundamental inconsistencies in reinforcement learning-optimized large reasoning models and suggests the need for adaptive improvements for reliable efficiency."}}
{"id": "2505.15437", "pdf": "https://arxiv.org/pdf/2505.15437", "abs": "https://arxiv.org/abs/2505.15437", "authors": ["Nikita Kotelevskii", "Mohsen Guizani", "Eric Moulines", "Maxim Panov"], "title": "Adaptive Temperature Scaling with Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conformal prediction enables the construction of high-coverage prediction\nsets for any pre-trained model, guaranteeing that the true label lies within\nthe set with a specified probability. However, these sets do not provide\nprobability estimates for individual labels, limiting their practical use. In\nthis paper, we propose, to the best of our knowledge, the first method for\nassigning calibrated probabilities to elements of a conformal prediction set.\nOur approach frames this as an adaptive calibration problem, selecting an\ninput-specific temperature parameter to match the desired coverage level.\nExperiments on several challenging image classification datasets demonstrate\nthat our method maintains coverage guarantees while significantly reducing\nexpected calibration error.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u4e3a\u975e\u6982\u7387\u9884\u6d4b\u96c6\u5206\u914d\u6821\u51c6\u6982\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u4fdd\u6301\u8986\u76d6\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u9884\u671f\u6821\u51c6\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u975e\u6982\u7387\u9884\u6d4b\u96c6\u4e0d\u80fd\u63d0\u4f9b\u5355\u4e2a\u6807\u7b7e\u7684\u6982\u7387\u4f30\u8ba1\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u81ea\u9002\u5e94\u6821\u51c6\u95ee\u9898\uff0c\u9009\u62e9\u7279\u5b9a\u7684\u6e29\u5ea6\u53c2\u6570\u4ee5\u5339\u914d\u6240\u9700\u8986\u76d6\u6c34\u5e73\u3002", "result": "\u5728\u51e0\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u8986\u76d6\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u9884\u671f\u6821\u51c6\u8bef\u5dee\u3002"}}
{"id": "2505.14751", "pdf": "https://arxiv.org/pdf/2505.14751", "abs": "https://arxiv.org/abs/2505.14751", "authors": ["Maheak Dave", "Aniket Kumar Singh", "Aryan Pareek", "Harshita Jha", "Debasis Chaudhuri", "Manish Pratap Singh"], "title": "Self Distillation via Iterative Constructive Perturbations", "categories": ["cs.LG", "cs.AI", "cs.ET"], "comment": null, "summary": "Deep Neural Networks have achieved remarkable achievements across various\ndomains, however balancing performance and generalization still remains a\nchallenge while training these networks. In this paper, we propose a novel\nframework that uses a cyclic optimization strategy to concurrently optimize the\nmodel and its input data for better training, rethinking the traditional\ntraining paradigm. Central to our approach is Iterative Constructive\nPerturbation (ICP), which leverages the model's loss to iteratively perturb the\ninput, progressively constructing an enhanced representation over some\nrefinement steps. This ICP input is then fed back into the model to produce\nimproved intermediate features, which serve as a target in a self-distillation\nframework against the original features. By alternately altering the model's\nparameters to the data and the data to the model, our method effectively\naddresses the gap between fitting and generalization, leading to enhanced\nperformance. Extensive experiments demonstrate that our approach not only\nmitigates common performance bottlenecks in neural networks but also\ndemonstrates significant improvements across training variations.", "AI": {"tldr": "This paper introduces a novel framework using a cyclic optimization strategy to improve deep neural network training by iteratively perturbing input data and applying self-distillation, showing enhanced performance and generalization.", "motivation": "Balancing performance and generalization in training deep neural networks remains challenging.", "method": "Proposes a cyclic optimization strategy including Iterative Constructive Perturbation (ICP) to perturb input data and uses self-distillation to refine features.", "result": "The approach mitigates performance bottlenecks and improves performance across different training variations.", "conclusion": "The proposed method effectively addresses the gap between fitting and generalization in neural network training."}}
{"id": "2505.15400", "pdf": "https://arxiv.org/pdf/2505.15400", "abs": "https://arxiv.org/abs/2505.15400", "authors": ["Xiaoyun Zhang", "Jingqing Ruan", "Xing Ma", "Yawen Zhu", "Haodong Zhao", "Hao Li", "Jiansong Chen", "Ke Zeng", "Xunliang Cai"], "title": "When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve remarkable performance via long\nreasoning chains, but often incur excessive computational overhead due to\nredundant reasoning, especially on simple tasks. In this work, we\nsystematically quantify the upper bounds of LRMs under both Long-Thinking and\nNo-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery\nMechanism\" where models implicitly supplement reasoning during answer\ngeneration. Building on this insight, we propose Adaptive Self-Recovery\nReasoning (ASRR), a framework that suppresses unnecessary reasoning and enables\nimplicit recovery. By introducing accuracy-aware length reward regulation, ASRR\nadaptively allocates reasoning effort according to problem difficulty,\nachieving high efficiency with negligible performance sacrifice. Experiments\nacross multiple benchmarks and models show that, compared with GRPO, ASRR\nreduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal\naccuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates\non safety benchmarks (up to +21.7%). Our results highlight the potential of\nASRR for enabling efficient, adaptive, and safer reasoning in LRMs.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u81ea\u6211\u6062\u590d\u63a8\u7406\uff08ASRR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6291\u5236\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u548c\u542f\u7528\u9690\u5f0f\u6062\u590d\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5927\u63a8\u7406\u6a21\u578b\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u56e0\u5197\u4f59\u63a8\u7406\u5bfc\u81f4\u7684\u8fc7\u5ea6\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "method": "\u5f15\u5165\u51c6\u786e\u6027\u611f\u77e5\u957f\u5ea6\u5956\u52b1\u8c03\u8282\uff0c\u6839\u636e\u95ee\u9898\u96be\u5ea6\u81ea\u9002\u5e94\u5206\u914d\u63a8\u7406\u52aa\u529b\uff0c\u63d0\u51faASRR\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0eGRPO\u76f8\u6bd4\uff0cASRR\u80fd\u51cf\u5c11\u63a8\u7406\u9884\u7b97\u4e14\u51e0\u4e4e\u4e0d\u635f\u5931\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u5b89\u5168\u57fa\u51c6\u4e0a\u7684\u65e0\u5bb3\u7387\u3002", "conclusion": "ASRR\u5c55\u793a\u4e86\u5728\u5927\u63a8\u7406\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u548c\u66f4\u5b89\u5168\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.15728", "pdf": "https://arxiv.org/pdf/2505.15728", "abs": "https://arxiv.org/abs/2505.15728", "authors": ["Luqin Gan", "Tarek M. Zikry", "Genevera I. Allen"], "title": "Are machine learning interpretations reliable? A stability study on global interpretations", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "17 pages main text, 5 main text figures. 57 pages in total with\n  Appendix and Bibliography", "summary": "As machine learning systems are increasingly used in high-stakes domains,\nthere is a growing emphasis placed on making them interpretable to improve\ntrust in these systems. In response, a range of interpretable machine learning\n(IML) methods have been developed to generate human-understandable insights\ninto otherwise black box models. With these methods, a fundamental question\narises: Are these interpretations reliable? Unlike with prediction accuracy or\nother evaluation metrics for supervised models, the proximity to the true\ninterpretation is difficult to define. Instead, we ask a closely related\nquestion that we argue is a prerequisite for reliability: Are these\ninterpretations stable? We define stability as findings that are consistent or\nreliable under small random perturbations to the data or algorithms. In this\nstudy, we conduct the first systematic, large-scale empirical stability study\non popular machine learning global interpretations for both supervised and\nunsupervised tasks on tabular data. Our findings reveal that popular\ninterpretation methods are frequently unstable, notably less stable than the\npredictions themselves, and that there is no association between the accuracy\nof machine learning predictions and the stability of their associated\ninterpretations. Moreover, we show that no single method consistently provides\nthe most stable interpretations across a range of benchmark datasets. Overall,\nthese results suggest that interpretability alone does not warrant trust, and\nunderscores the need for rigorous evaluation of interpretation stability in\nfuture work. To support these principles, we have developed and released an\nopen source IML dashboard and Python package to enable researchers to assess\nthe stability and reliability of their own data-driven interpretations and\ndiscoveries.", "AI": {"tldr": "This paper examines the stability of popular machine learning global interpretations for supervised and unsupervised tasks on tabular data.", "motivation": "To determine if these interpretations are reliable.", "method": "Systematic, large-scale empirical stability study.", "result": "Popular interpretation methods are frequently unstable, less stable than the predictions themselves, and there is no association between the accuracy of predictions and the stability of interpretations.", "conclusion": "Interpretability alone does not warrant trust, and future work needs to rigorously evaluate interpretation stability."}}
{"id": "2505.14752", "pdf": "https://arxiv.org/pdf/2505.14752", "abs": "https://arxiv.org/abs/2505.14752", "authors": ["Yihong Tang", "Menglin Kong", "Lijun Sun"], "title": "Large Language Models for Data Synthesis", "categories": ["cs.LG"], "comment": null, "summary": "Generating synthetic data that faithfully captures the statistical structure\nof real-world distributions is a fundamental challenge in data modeling.\nClassical approaches often depend on strong parametric assumptions or manual\nstructural design and struggle in high-dimensional or heterogeneous domains.\nRecent progress in Large Language Models (LLMs) reveals their potential as\nflexible, high-dimensional priors over real-world distributions. However, when\napplied to data synthesis, standard LLM-based sampling is inefficient,\nconstrained by fixed context limits, and fails to ensure statistical alignment.\nGiven this, we introduce LLMSynthor, a general framework for data synthesis\nthat transforms LLMs into structure-aware simulators guided by distributional\nfeedback. LLMSynthor treats the LLM as a nonparametric copula simulator for\nmodeling high-order dependencies and introduces LLM Proposal Sampling to\ngenerate grounded proposal distributions that improve sampling efficiency\nwithout requiring rejection. By minimizing discrepancies in the summary\nstatistics space, the iterative synthesis loop aligns real and synthetic data\nwhile gradually uncovering and refining the latent generative structure. We\nevaluate LLMSynthor in both controlled and real-world settings using\nheterogeneous datasets in privacy-sensitive domains (e.g., e-commerce,\npopulation, and mobility) that encompass both structured and unstructured\nformats. The synthetic data produced by LLMSynthor shows high statistical\nfidelity, practical utility, and cross-data adaptability, positioning it as a\nvaluable tool across economics, social science, urban studies, and beyond.", "AI": {"tldr": "\u63d0\u51faLLMSynthor\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u4fdd\u771f\u5408\u6210\u6570\u636e\uff0c\u9002\u7528\u4e8e\u9690\u79c1\u654f\u611f\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u7ef4\u6216\u5f02\u6784\u57df\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u6807\u51c6LLM\u91c7\u6837\u6548\u7387\u4f4e\u4e14\u65e0\u6cd5\u4fdd\u8bc1\u7edf\u8ba1\u4e00\u81f4\u6027\u3002", "method": "\u5c06LLM\u4f5c\u4e3a\u975e\u53c2\u6570copula\u6a21\u62df\u5668\uff0c\u5e76\u5f15\u5165LLM\u63d0\u8bae\u91c7\u6837\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u901a\u8fc7\u5206\u5e03\u53cd\u9988\u4f7f\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u63a7\u5236\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0c\u5408\u6210\u6570\u636e\u5177\u6709\u9ad8\u7edf\u8ba1\u4fdd\u771f\u5ea6\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "LLMSynthor\u662f\u4e00\u79cd\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u7ecf\u6d4e\u5b66\u3001\u793e\u4f1a\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u3002"}}
{"id": "2505.15410", "pdf": "https://arxiv.org/pdf/2505.15410", "abs": "https://arxiv.org/abs/2505.15410", "authors": ["Bahar Radmehr", "Ekaterina Shved", "Fatma Bet\u00fcl G\u00fcre\u015f", "Adish Singla", "Tanja K\u00e4ser"], "title": "ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted in Latebreaking results track in AIED 2025(26th\n  International Conference on Artificial Intelligence in Education JULY 22-26,\n  2025 PALERMO, ITALY)", "summary": "Clickstream data from digital learning environments offer valuable insights\ninto students' learning behaviors, but are challenging to interpret due to\ntheir high dimensionality and granularity. Prior approaches have relied mainly\non handcrafted features, expert labeling, clustering, or supervised models,\ntherefore often lacking generalizability and scalability. In this work, we\nintroduce ClickSight, an in-context Large Language Model (LLM)-based pipeline\nthat interprets student clickstreams to reveal their learning strategies.\nClickSight takes raw clickstreams and a list of learning strategies as input\nand generates textual interpretations of students' behaviors during\ninteraction. We evaluate four different prompting strategies and investigate\nthe impact of self-refinement on interpretation quality. Our evaluation spans\ntwo open-ended learning environments and uses a rubric-based domain-expert\nevaluation. Results show that while LLMs can reasonably interpret learning\nstrategies from clickstreams, interpretation quality varies by prompting\nstrategy, and self-refinement offers limited improvement. ClickSight\ndemonstrates the potential of LLMs to generate theory-driven insights from\neducational interaction data.", "AI": {"tldr": "ClickSight\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ba1\u9053\uff0c\u53ef\u4ee5\u4ece\u70b9\u51fb\u6d41\u6570\u636e\u4e2d\u89e3\u91ca\u5b66\u751f\u7684\u5b66\u4e60\u7b56\u7565\u3002\u5c3d\u7ba1\u63d0\u793a\u7b56\u7565\u4e0d\u540c\u5f71\u54cd\u4e86\u89e3\u91ca\u8d28\u91cf\uff0c\u4f46\u7ed3\u679c\u663e\u793aLLMs\u53ef\u4ee5\u5408\u7406\u5730\u4ece\u70b9\u51fb\u6d41\u6570\u636e\u4e2d\u89e3\u91ca\u5b66\u4e60\u7b56\u7565\u3002", "motivation": "Clickstream\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u5173\u5b66\u751f\u5b66\u4e60\u884c\u4e3a\u7684\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u4f46\u7531\u4e8e\u5176\u9ad8\u7ef4\u5ea6\u548c\u7c92\u5ea6\u800c\u96be\u4ee5\u89e3\u91ca\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f15\u5165ClickSight\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ba1\u9053\uff0c\u5b83\u5c06\u539f\u59cb\u70b9\u51fb\u6d41\u548c\u5b66\u4e60\u7b56\u7565\u5217\u8868\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u751f\u6210\u5b66\u751f\u4ea4\u4e92\u671f\u95f4\u7684\u884c\u4e3a\u6587\u672c\u89e3\u91ca\u3002\u8bc4\u4f30\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u5e76\u7814\u7a76\u4e86\u81ea\u6211\u7cbe\u70bc\u5bf9\u89e3\u91ca\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u653e\u5f0f\u5b66\u4e60\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u8bc4\u5206\u5361\u7684\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136LLMs\u53ef\u4ee5\u4ece\u70b9\u51fb\u6d41\u6570\u636e\u4e2d\u5408\u7406\u89e3\u91ca\u5b66\u4e60\u7b56\u7565\uff0c\u4f46\u89e3\u91ca\u8d28\u91cf\u56e0\u63d0\u793a\u7b56\u7565\u800c\u5f02\uff0c\u81ea\u6211\u7cbe\u70bc\u63d0\u4f9b\u7684\u6539\u8fdb\u6709\u9650\u3002", "conclusion": "ClickSight\u5c55\u793a\u4e86LLMs\u4ece\u6559\u80b2\u4e92\u52a8\u6570\u636e\u4e2d\u751f\u6210\u7406\u8bba\u9a71\u52a8\u7684\u89c1\u89e3\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.14825", "pdf": "https://arxiv.org/pdf/2505.14825", "abs": "https://arxiv.org/abs/2505.14825", "authors": ["Marios Andreou", "Nan Chen", "Erik Bollt"], "title": "Assimilative Causal Inference", "categories": ["cs.LG", "math.ST", "physics.data-an", "stat.ME", "stat.ML", "stat.TH", "62F15, 62D20, 62M20, 93E11, 93E14, 60H10"], "comment": "Includes the Main Text and Supporting Information in a single\n  document. 39 pages (p. 1--2 Title, Contents and Abstract | p. 3--14 Main Text\n  | p. 15--39 Supporting Information), 9 figures (3 in the Main Text and 6 in\n  the Supporting Information), typeset in LaTeX. Submitted for peer-review. For\n  more info see https://mariosandreou.short.gy/ACI", "summary": "Causal inference determines cause-and-effect relationships between variables\nand has broad applications across disciplines. Traditional time-series methods\noften reveal causal links only in a time-averaged sense, while ensemble-based\ninformation transfer approaches detect the time evolution of short-term causal\nrelationships but are typically limited to low-dimensional systems. In this\npaper, a new causal inference framework, called assimilative causal inference\n(ACI), is developed. Fundamentally different from the state-of-the-art methods,\nACI uses a dynamical system and a single realization of a subset of the state\nvariables to identify instantaneous causal relationships and the dynamic\nevolution of the associated causal influence range (CIR). Instead of\nquantifying how causes influence effects as done traditionally, ACI solves an\ninverse problem via Bayesian data assimilation, thus tracing causes backward\nfrom observed effects with an implicit Bayesian hypothesis. Causality is\ndetermined by assessing whether incorporating the information of the effect\nvariables reduces the uncertainty in recovering the potential cause variables.\nACI has several desirable features. First, it captures the dynamic interplay of\nvariables, where their roles as causes and effects can shift repeatedly over\ntime. Second, a mathematically justified objective criterion determines the CIR\nwithout empirical thresholds. Third, ACI is scalable to high-dimensional\nproblems by leveraging computationally efficient Bayesian data assimilation\ntechniques. Finally, ACI applies to short time series and incomplete datasets.\nNotably, ACI does not require observations of candidate causes, which is a key\nadvantage since potential drivers are often unknown or unmeasured. The\neffectiveness of ACI is demonstrated by complex dynamical systems showcasing\nintermittency and extreme events.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aACI\u7684\u65b0\u56e0\u679c\u63a8\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u5904\u7406\u77ed\u65f6\u95f4\u5e8f\u5217\u548c\u4e0d\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u5e76\u5728\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4e2d\u5c55\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u901a\u5e38\u53ea\u80fd\u5728\u65f6\u95f4\u5e73\u5747\u7684\u610f\u4e49\u4e0a\u63ed\u793a\u56e0\u679c\u94fe\uff0c\u800c\u57fa\u4e8e\u96c6\u5408\u7684\u4fe1\u606f\u4f20\u9012\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u68c0\u6d4b\u77ed\u671f\u56e0\u679c\u5173\u7cfb\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u4f46\u901a\u5e38\u5c40\u9650\u4e8e\u4f4e\u7ef4\u7cfb\u7edf\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u63a8\u7406\u6846\u67b6ACI\u3002", "method": "ACI\u4f7f\u7528\u4e00\u4e2a\u52a8\u529b\u7cfb\u7edf\u548c\u72b6\u6001\u53d8\u91cf\u5b50\u96c6\u7684\u4e00\u4e2a\u5355\u4e00\u5b9e\u73b0\u6765\u8bc6\u522b\u77ac\u65f6\u56e0\u679c\u5173\u7cfb\u53ca\u5176\u76f8\u5173\u7684\u56e0\u679c\u5f71\u54cd\u8303\u56f4\uff08CIR\uff09\u7684\u52a8\u6001\u6f14\u5316\u3002\u5b83\u901a\u8fc7\u8d1d\u53f6\u65af\u6570\u636e\u540c\u5316\u89e3\u51b3\u9006\u95ee\u9898\uff0c\u4ece\u800c\u4ece\u89c2\u5bdf\u5230\u7684\u6548\u679c\u8ffd\u6eaf\u539f\u56e0\u3002", "result": "ACI\u80fd\u591f\u6355\u83b7\u53d8\u91cf\u4e4b\u95f4\u7684\u52a8\u6001\u76f8\u4e92\u4f5c\u7528\uff0c\u5176\u6570\u5b66\u4e0a\u5408\u7406\u7684\u5ba2\u89c2\u6807\u51c6\u786e\u5b9a\u4e86CIR\uff0c\u800c\u4e0d\u9700\u8981\u7ecf\u9a8c\u9608\u503c\u3002ACI\u53ef\u4ee5\u6269\u5c55\u5230\u9ad8\u7ef4\u95ee\u9898\uff0c\u5e76\u9002\u7528\u4e8e\u77ed\u65f6\u95f4\u5e8f\u5217\u548c\u4e0d\u5b8c\u6574\u6570\u636e\u96c6\u3002ACI\u4e0d\u4f9d\u8d56\u4e8e\u5019\u9009\u539f\u56e0\u7684\u89c2\u6d4b\uff0c\u8fd9\u662f\u4e00\u4e2a\u5173\u952e\u4f18\u52bf\uff0c\u56e0\u4e3a\u6f5c\u5728\u9a71\u52a8\u56e0\u7d20\u901a\u5e38\u662f\u672a\u77e5\u6216\u672a\u6d4b\u91cf\u7684\u3002", "conclusion": "ACI\u901a\u8fc7\u8d1d\u53f6\u65af\u6570\u636e\u540c\u5316\u89e3\u51b3\u9006\u95ee\u9898\u6765\u786e\u5b9a\u56e0\u679c\u5173\u7cfb\uff0c\u80fd\u591f\u6355\u83b7\u53d8\u91cf\u4e4b\u95f4\u7684\u52a8\u6001\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u5229\u7528\u8ba1\u7b97\u9ad8\u6548\u7684\u8d1d\u53f6\u65af\u6570\u636e\u540c\u5316\u6280\u672f\u6269\u5c55\u5230\u9ad8\u7ef4\u95ee\u9898\u3002ACI\u5728\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5c55\u793a\u4e86\u95f4\u6b47\u6027\u548c\u6781\u7aef\u4e8b\u4ef6\u3002"}}
{"id": "2505.14756", "pdf": "https://arxiv.org/pdf/2505.14756", "abs": "https://arxiv.org/abs/2505.14756", "authors": ["Chih-Yu Chang", "Milad Azvar", "Chinedum Okwudire", "Raed Al Kontar"], "title": "$\\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Bayesian optimization (BO) is a sequential decision-making tool widely used\nfor optimizing expensive black-box functions. Recently, Large Language Models\n(LLMs) have shown remarkable adaptability in low-data regimes, making them\npromising tools for black-box optimization by leveraging contextual knowledge\nto propose high-quality query points. However, relying solely on LLMs as\noptimization agents introduces risks due to their lack of explicit surrogate\nmodeling and calibrated uncertainty, as well as their inherently opaque\ninternal mechanisms. This structural opacity makes it difficult to characterize\nor control the exploration-exploitation trade-off, ultimately undermining\ntheoretical tractability and reliability. To address this, we propose LLINBO:\nLLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with\nstatistical surrogate experts (e.g., Gaussian Processes (GP)). The core\nphilosophy is to leverage contextual reasoning strengths of LLMs for early\nexploration, while relying on principled statistical models to guide efficient\nexploitation. Specifically, we introduce three mechanisms that enable this\ncollaboration and establish their theoretical guarantees. We end the paper with\na real-life proof-of-concept in the context of 3D printing. The code to\nreproduce the results can be found at\nhttps://github.com/UMDataScienceLab/LLM-in-the-Loop-BO.", "AI": {"tldr": "This paper presents LLINBO, a hybrid Bayesian optimization framework combining Large Language Models with statistical surrogate models like Gaussian Processes for better exploration and exploitation.", "motivation": "To improve Bayesian optimization by using LLMs for contextual reasoning in exploration while maintaining reliability with statistical models for exploitation.", "method": "Introduces LLINBO which integrates LLMs and statistical surrogate experts, with three mechanisms ensuring theoretical guarantees.", "result": "Demonstrates the effectiveness of LLINBO through a real-life application in 3D printing and provides reproducible code.", "conclusion": "LLINBO offers a reliable and efficient approach for black-box function optimization by blending the strengths of LLMs and statistical models."}}
{"id": "2505.15693", "pdf": "https://arxiv.org/pdf/2505.15693", "abs": "https://arxiv.org/abs/2505.15693", "authors": ["Milad Kazemi", "Mateo Perez", "Fabio Somenzi", "Sadegh Soudjani", "Ashutosh Trivedi", "Alvaro Velasquez"], "title": "Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives", "categories": ["cs.AI"], "comment": "29 pages, 6 figures and 2 tables", "summary": "Recent advances in reinforcement learning (RL) have renewed focus on the\ndesign of reward functions that shape agent behavior. Manually designing reward\nfunctions is tedious and error-prone. A principled alternative is to specify\nbehaviors in a formal language that can be automatically translated into\nrewards. Omega-regular languages are a natural choice for this purpose, given\ntheir established role in formal verification and synthesis. However, existing\nmethods using omega-regular specifications typically rely on discounted reward\nRL in episodic settings, with periodic resets. This setup misaligns with the\nsemantics of omega-regular specifications, which describe properties over\ninfinite behavior traces. In such cases, the average reward criterion and the\ncontinuing setting -- where the agent interacts with the environment over a\nsingle, uninterrupted lifetime -- are more appropriate.\n  To address the challenges of infinite-horizon, continuing tasks, we focus on\nabsolute liveness specifications -- a subclass of omega-regular languages that\ncannot be violated by any finite behavior prefix, making them well-suited to\nthe continuing setting. We present the first model-free RL framework that\ntranslates absolute liveness specifications to average-reward objectives. Our\napproach enables learning in communicating MDPs without episodic resetting. We\nalso introduce a reward structure for lexicographic multi-objective\noptimization, aiming to maximize an external average-reward objective among the\npolicies that also maximize the satisfaction probability of a given\nomega-regular specification. Our method guarantees convergence in unknown\ncommunicating MDPs and supports on-the-fly reductions that do not require full\nknowledge of the environment, thus enabling model-free RL. Empirical results\nshow our average-reward approach in continuing setting outperforms\ndiscount-based methods across benchmarks.", "AI": {"tldr": "This paper proposes a model-free reinforcement learning framework that uses absolute liveness specifications to achieve better performance than discount-based methods in infinite-horizon, continuing tasks.", "motivation": "The motivation stems from the limitations of manually designing reward functions in reinforcement learning and the need for a principled alternative based on formal languages.", "method": "The proposed method uses absolute liveness specifications within omega-regular languages, translating them into average-reward objectives for continuous environments, and includes a reward structure for lexicographic multi-objective optimization.", "result": "The result shows that the average-reward approach outperforms discount-based methods across various benchmarks in continuing settings.", "conclusion": "The paper introduces a novel model-free reinforcement learning framework that translates absolute liveness specifications into average-reward objectives, ensuring convergence in unknown communicating MDPs without requiring full knowledge of the environment."}}
{"id": "2505.14826", "pdf": "https://arxiv.org/pdf/2505.14826", "abs": "https://arxiv.org/abs/2505.14826", "authors": ["Rohan Deb", "Kiran Thekumparampil", "Kousha Kalantari", "Gaurush Hiranandani", "Shoham Sabach", "Branislav Kveton"], "title": "FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": null, "summary": "Supervised fine-tuning (SFT) is a standard approach to adapting large\nlanguage models (LLMs) to new domains. In this work, we improve the statistical\nefficiency of SFT by selecting an informative subset of training examples.\nSpecifically, for a fixed budget of training examples, which determines the\ncomputational cost of fine-tuning, we determine the most informative ones. The\nkey idea in our method is to select examples that maximize information gain,\nmeasured by the Hessian of the log-likelihood of the LLM. We approximate it\nefficiently by linearizing the LLM at the last layer using multinomial logistic\nregression models. Our approach is computationally efficient, analyzable, and\nperforms well empirically. We demonstrate this on several problems, and back\nour claims with both quantitative results and an LLM evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u8bad\u7ec3\u6837\u672c\u5b50\u96c6\u6765\u63d0\u9ad8\u76d1\u7763\u5fae\u8c03\u7edf\u8ba1\u6548\u7387\u7684\u65b9\u6cd5\u3002", "motivation": "\u63d0\u9ad8\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u56fa\u5b9a\u8bad\u7ec3\u6837\u672c\u9884\u7b97\u4e0b\u7684\u7edf\u8ba1\u6548\u7387\u3002", "method": "\u901a\u8fc7\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\u51fd\u6570\u7684Hessian\u6765\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u5e76\u7528\u591a\u5143\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8fd1\u4f3c\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u4e86\u5b9a\u91cf\u7ed3\u679c\u548c\u4e13\u5bb6\u8bc4\u4f30\u652f\u6301\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u8ba1\u7b97\u9ad8\u6548\u3001\u53ef\u5206\u6790\u4e14\u5b9e\u8bc1\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2505.14765", "pdf": "https://arxiv.org/pdf/2505.14765", "abs": "https://arxiv.org/abs/2505.14765", "authors": ["Orhun Vural", "Bunyamin Ozaydin", "Khalid Y. Aram", "James Booth", "Brittany F. Lindsey", "Abdulaziz Ahmed"], "title": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.6; J.3"], "comment": null, "summary": "This study develops deep learning models to forecast the number of patients\nin the emergency department (ED) boarding phase six hours in advance, aiming to\nsupport proactive operational decision-making using only non-clinical,\noperational, and contextual features. Data were collected from five sources: ED\ntracking systems, inpatient census records, weather reports, federal holiday\ncalendars, and local event schedules. After feature engineering, the data were\naggregated at an hourly level, cleaned, and merged into a unified dataset for\nmodel training. Several time series deep learning models, including ResNetPlus,\nTSTPlus, TSiTPlus (from the tsai library), and N-BEATSx, were trained using\nOptuna and grid search for hyperparameter tuning. The average ED boarding count\nwas 28.7, with a standard deviation of 11.2. N-BEATSx achieved the best\nperformance, with a mean absolute error of 2.10, mean squared error of 7.08,\nroot mean squared error of 2.66, and a coefficient of determination of 0.95.\nThe model maintained stable accuracy even during periods of extremely high\nboarding counts, defined as values exceeding one, two, or three standard\ndeviations above the mean. Results show that accurate six-hour-ahead forecasts\nare achievable without using patient-level clinical data. While strong\nperformance was observed even with a basic feature set, the inclusion of\nadditional features improved prediction stability under extreme conditions.\nThis framework offers a practical and generalizable approach for hospital\nsystems to anticipate boarding levels and help mitigate ED overcrowding.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u975e\u4e34\u5e8a\u6570\u636e\u63d0\u524d\u516d\u5c0f\u65f6\u9884\u6d4b\u6025\u8bca\u79d1\u5019\u8bca\u4eba\u6570\uff0c\u4ee5\u652f\u6301\u4e3b\u52a8\u51b3\u7b56\uff0cN-BEATSx\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u652f\u6301\u4e3b\u52a8\u8fd0\u8425\u51b3\u7b56\u5236\u5b9a\uff0c\u4ec5\u4f7f\u7528\u975e\u4e34\u5e8a\u3001\u8fd0\u8425\u548c\u4e0a\u4e0b\u6587\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u4e94\u4e2a\u6765\u6e90\u7684\u6570\u636e\uff0c\u5305\u62ec\u6025\u8bca\u79d1\u8ddf\u8e2a\u7cfb\u7edf\u3001\u4f4f\u9662\u60a3\u8005\u4eba\u53e3\u8bb0\u5f55\u3001\u5929\u6c14\u62a5\u544a\u3001\u8054\u90a6\u8282\u5047\u65e5\u65e5\u5386\u548c\u672c\u5730\u6d3b\u52a8\u65f6\u95f4\u8868\uff0c\u5e76\u4f7f\u7528Optuna\u548c\u7f51\u683c\u641c\u7d22\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u6574\u8bad\u7ec3\u4e86\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "N-BEATSx\u6a21\u578b\u5728\u5e73\u5747\u6025\u8bca\u79d1\u5019\u8bca\u8ba1\u6570\u4e3a28.7\uff0c\u6807\u51c6\u5dee\u4e3a11.2\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u5176\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a2.10\uff0c\u5747\u65b9\u8bef\u5dee\u4e3a7.08\uff0c\u5747\u65b9\u6839\u8bef\u5dee\u4e3a2.66\uff0c\u786e\u5b9a\u7cfb\u6570\u4e3a0.95\u3002\u5373\u4f7f\u5728\u6781\u7aef\u9ad8\u5019\u8bca\u8ba1\u6570\u671f\u95f4\uff0c\u6a21\u578b\u4e5f\u4fdd\u6301\u4e86\u7a33\u5b9a\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u533b\u9662\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u5019\u8bca\u5ba4\u6c34\u5e73\u5e76\u5e2e\u52a9\u7f13\u89e3\u6025\u8bca\u5ba4\u8fc7\u5ea6\u62e5\u6324\u7684\u95ee\u9898\u3002"}}
{"id": "2505.15742", "pdf": "https://arxiv.org/pdf/2505.15742", "abs": "https://arxiv.org/abs/2505.15742", "authors": ["Adam Gould", "Francesca Toni"], "title": "Neuro-Argumentative Learning with Case-Based Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to NeSy25", "summary": "We introduce Gradual Abstract Argumentation for Case-Based Reasoning (Gradual\nAA-CBR), a data-driven, neurosymbolic classification model in which the outcome\nis determined by an argumentation debate structure that is learned\nsimultaneously with neural-based feature extractors. Each argument in the\ndebate is an observed case from the training data, favouring their labelling.\nCases attack or support those with opposing or agreeing labellings, with the\nstrength of each argument and relationship learned through gradient-based\nmethods. This argumentation debate structure provides human-aligned reasoning,\nimproving model interpretability compared to traditional neural networks (NNs).\nUnlike the existing purely symbolic variant, Abstract Argumentation for\nCase-Based Reasoning (AA-CBR), Gradual AA-CBR is capable of multi-class\nclassification, automatic learning of feature and data point importance,\nassigning uncertainty values to outcomes, using all available data points, and\ndoes not require binary features. We show that Gradual AA-CBR performs\ncomparably to NNs whilst significantly outperforming existing AA-CBR\nformulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradual AA-CBR\u7684\u6570\u636e\u9a71\u52a8\u795e\u7ecf\u7b26\u53f7\u5206\u7c7b\u6a21\u578b\uff0c\u5b83\u7ed3\u5408\u4e86\u6848\u4f8b\u63a8\u7406\u548c\u8bba\u8bc1\u8fa9\u8bba\u7ed3\u6784\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u540c\u65f6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684AA-CBR\u516c\u5f0f\u3002", "motivation": "\u63d0\u9ad8\u6a21\u578b\u7684\u89e3\u91ca\u6027\u5e76\u5b9e\u73b0\u591a\u7c7b\u522b\u5206\u7c7b\u80fd\u529b\uff0c\u540c\u65f6\u81ea\u52a8\u5b66\u4e60\u7279\u5f81\u548c\u6570\u636e\u70b9\u7684\u91cd\u8981\u6027\u3002", "method": "\u901a\u8fc7\u68af\u5ea6\u65b9\u6cd5\u5b66\u4e60\u8bba\u8bc1\u8fa9\u8bba\u7ed3\u6784\u4ee5\u53ca\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8bba\u70b9\u4ee3\u8868\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e00\u4e2a\u6848\u4f8b\u3002", "result": "Gradual AA-CBR\u5728\u8868\u73b0\u4e0a\u4e0e\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\uff0c\u4f46\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684AA-CBR\u516c\u5f0f\uff0c\u4e14\u5177\u5907\u591a\u7c7b\u522b\u5206\u7c7b\u7b49\u7279\u6027\u3002", "conclusion": "Gradual AA-CBR\u63d0\u4f9b\u4e86\u4eba\u7c7b\u5bf9\u9f50\u7684\u63a8\u7406\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u4e8c\u8fdb\u5236\u7279\u5f81\u3002"}}
{"id": "2505.14999", "pdf": "https://arxiv.org/pdf/2505.14999", "abs": "https://arxiv.org/abs/2505.14999", "authors": ["Eric Hanchen Jiang", "Haozheng Luo", "Shengyuan Pang", "Xiaomin Li", "Zhenting Qi", "Hengli Li", "Cheng-Fu Yang", "Zongyu Lin", "Xinfeng Li", "Hao Xu", "Kai-Wei Chang", "Ying Nian Wu"], "title": "Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs), often requiring robust multi step logical consistency. While\nChain of Thought (CoT) prompting elicits reasoning steps, it doesn't guarantee\ncorrectness, and improving reliability via extensive sampling is\ncomputationally costly. This paper introduces the Energy Outcome Reward Model\n(EORM), an effective, lightweight, post hoc verifier. EORM leverages Energy\nBased Models (EBMs) to simplify the training of reward models by learning to\nassign a scalar energy score to CoT solutions using only outcome labels,\nthereby avoiding detailed annotations. It achieves this by interpreting\ndiscriminator output logits as negative energies, effectively ranking\ncandidates where lower energy is assigned to solutions leading to correct final\noutcomes implicitly favoring coherent reasoning. On mathematical benchmarks\n(GSM8k, MATH), EORM significantly improves final answer accuracy (e.g., with\nLlama 3 8B, achieving 90.7% on GSM8k and 63.7% on MATH). EORM effectively\nleverages a given pool of candidate solutions to match or exceed the\nperformance of brute force sampling, thereby enhancing LLM reasoning outcome\nreliability through its streamlined post hoc verification process.", "AI": {"tldr": "This paper presents EORM, a lightweight verifier that improves the reliability of mathematical reasoning in large language models by leveraging energy-based models and outcome labels.", "motivation": "To address the challenge of mathematical reasoning in LLMs, which requires robust multi-step logical consistency, and to improve the reliability of Chain of Thought prompting without extensive computational cost.", "method": "Introducing EORM, which uses energy-based models to assign scalar energy scores to CoT solutions based on outcome labels, avoiding detailed annotations.", "result": "EORM significantly improves final answer accuracy on mathematical benchmarks like GSM8k and MATH.", "conclusion": "EORM is an effective, lightweight post hoc verifier that enhances the reliability of LLM reasoning outcomes."}}
{"id": "2505.14766", "pdf": "https://arxiv.org/pdf/2505.14766", "abs": "https://arxiv.org/abs/2505.14766", "authors": ["Ben Cohen", "Emaad Khwaja", "Youssef Doubli", "Salahidine Lemaachi", "Chris Lettieri", "Charles Masson", "Hugo Miccinilli", "Elise Ram\u00e9", "Qiqi Ren", "Afshin Rostamizadeh", "Jean Ogier du Terrail", "Anna-Monica Toon", "Kan Wang", "Stephan Xie", "David Asker", "Ameet Talwalkar", "Othmane Abou-Amal"], "title": "This Time is Different: An Observability Perspective on Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Toto, a time series forecasting foundation model with 151\nmillion parameters. Toto uses a modern decoder-only architecture coupled with\narchitectural innovations designed to account for specific challenges found in\nmultivariate observability time series data. Toto's pre-training corpus is a\nmixture of observability data, open datasets, and synthetic data, and is\n4-10$\\times$ larger than those of leading time series foundation models.\nAdditionally, we introduce BOOM, a large-scale benchmark consisting of 350\nmillion observations across 2,807 real-world time series. For both Toto and\nBOOM, we source observability data exclusively from Datadog's own telemetry and\ninternal observability metrics. Extensive evaluations demonstrate that Toto\nachieves state-of-the-art performance on both BOOM and on established general\npurpose time series forecasting benchmarks. Toto's model weights, inference\ncode, and evaluation scripts, as well as BOOM's data and evaluation code, are\nall available as open source under the Apache 2.0 License available at\nhttps://huggingface.co/Datadog/Toto-Open-Base-1.0 and\nhttps://github.com/DataDog/toto.", "AI": {"tldr": "\u6211\u4eec\u4ecb\u7ecd\u4e86Toto\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u67091.51\u4ebf\u53c2\u6570\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u7840\u6a21\u578b\uff0c\u5b83\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e14\u6240\u6709\u76f8\u5173\u8d44\u6e90\u90fd\u662f\u5f00\u6e90\u7684\u3002", "motivation": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u7840\u6a21\u578bToto\uff0c\u5b83\u5177\u67091.51\u4ebf\u4e2a\u53c2\u6570\uff0c\u5e76\u4e14\u5176\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u6bd4\u9886\u5148\u7684\u65f6\u5e8f\u57fa\u7840\u6a21\u578b\u59274-10\u500d\u3002", "method": "Toto\u91c7\u7528\u4e86\u4e00\u79cd\u73b0\u4ee3\u7684\u89e3\u7801\u5668-\u53ea\u67b6\u6784\uff0c\u5e76\u7ed3\u5408\u4e86\u9488\u5bf9\u591a\u53d8\u91cf\u53ef\u89c2\u5bdf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7279\u5b9a\u6311\u6218\u8bbe\u8ba1\u7684\u67b6\u6784\u521b\u65b0\u3002", "result": "Toto\u5728BOOM\u548c\u73b0\u6709\u7684\u901a\u7528\u65f6\u5e8f\u9884\u6d4b\u57fa\u51c6\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Toto\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5176\u6a21\u578b\u6743\u91cd\u3001\u63a8\u7406\u4ee3\u7801\u548c\u8bc4\u4f30\u811a\u672c\u4ee5\u53caBOOM\u7684\u6570\u636e\u548c\u8bc4\u4f30\u4ee3\u7801\u90fd\u4f5c\u4e3a\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2505.15008", "pdf": "https://arxiv.org/pdf/2505.15008", "abs": "https://arxiv.org/abs/2505.15008", "authors": ["Alvin Heng", "Harold Soh"], "title": "Know When to Abstain: Optimal Selective Classification with Likelihood Ratios", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Selective classification enhances the reliability of predictive models by\nallowing them to abstain from making uncertain predictions. In this work, we\nrevisit the design of optimal selection functions through the lens of the\nNeyman--Pearson lemma, a classical result in statistics that characterizes the\noptimal rejection rule as a likelihood ratio test. We show that this\nperspective not only unifies the behavior of several post-hoc selection\nbaselines, but also motivates new approaches to selective classification which\nwe propose here. A central focus of our work is the setting of covariate shift,\nwhere the input distribution at test time differs from that at training. This\nrealistic and challenging scenario remains relatively underexplored in the\ncontext of selective classification. We evaluate our proposed methods across a\nrange of vision and language tasks, including both supervised learning and\nvision-language models. Our experiments demonstrate that our\nNeyman--Pearson-informed methods consistently outperform existing baselines,\nindicating that likelihood ratio-based selection offers a robust mechanism for\nimproving selective classification under covariate shifts. Our code is publicly\navailable at https://github.com/clear-nus/sc-likelihood-ratios.", "AI": {"tldr": "This work applies the Neyman-Pearson lemma to selective classification, unifying existing methods and introducing new approaches that perform better under covariate shift.", "motivation": "To enhance the reliability of predictive models by developing improved selective classification methods, especially under covariate shift.", "method": "Revisiting the design of optimal selection functions using the Neyman-Pearson lemma and proposing new approaches based on this perspective.", "result": "The proposed methods outperform existing baselines across various vision and language tasks.", "conclusion": "Likelihood ratio-based selection provides a robust mechanism for improving selective classification under covariate shifts."}}
{"id": "2505.14777", "pdf": "https://arxiv.org/pdf/2505.14777", "abs": "https://arxiv.org/abs/2505.14777", "authors": ["Mingquan Feng", "Yixin Huang", "Yifan Fu", "Shaobo Wang", "Junchi Yan"], "title": "KO: Kinetics-inspired Neural Optimizer with PDE Simulation Approaches", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The design of optimization algorithms for neural networks remains a critical\nchallenge, with most existing methods relying on heuristic adaptations of\ngradient-based approaches. This paper introduces KO (Kinetics-inspired\nOptimizer), a novel neural optimizer inspired by kinetic theory and partial\ndifferential equation (PDE) simulations. We reimagine the training dynamics of\nnetwork parameters as the evolution of a particle system governed by kinetic\nprinciples, where parameter updates are simulated via a numerical scheme for\nthe Boltzmann transport equation (BTE) that models stochastic particle\ncollisions. This physics-driven approach inherently promotes parameter\ndiversity during optimization, mitigating the phenomenon of parameter\ncondensation, i.e. collapse of network parameters into low-dimensional\nsubspaces, through mechanisms analogous to thermal diffusion in physical\nsystems. We analyze this property, establishing both a mathematical proof and a\nphysical interpretation. Extensive experiments on image classification\n(CIFAR-10/100, ImageNet) and text classification (IMDB, Snips) tasks\ndemonstrate that KO consistently outperforms baseline optimizers (e.g., Adam,\nSGD), achieving accuracy improvements while computation cost remains\ncomparable.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u529b\u5b66\u7406\u8bba\u548c\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5668KO\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u7c92\u5b50\u7cfb\u7edf\u7684\u6f14\u5316\u6765\u91cd\u65b0\u5b9a\u4e49\u7f51\u7edc\u53c2\u6570\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u65b9\u6848\u6a21\u62df\u53c2\u6570\u66f4\u65b0\u3002\u5b9e\u9a8c\u8868\u660eKO\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8eAdam\u548cSGD\u7b49\u57fa\u7ebf\u4f18\u5316\u5668\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u591a\u6570\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u68af\u5ea6\u7684\u542f\u53d1\u5f0f\u8c03\u6574\u65b9\u6cd5\uff0c\u5b58\u5728\u53c2\u6570\u51dd\u805a\u95ee\u9898\uff0c\u5373\u7f51\u7edc\u53c2\u6570\u574d\u584c\u5230\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u7684\u73b0\u8c61\u3002", "method": "\u53d7\u52a8\u529b\u5b66\u7406\u8bba\u548c\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u542f\u53d1\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3aKO\u7684\u65b0\u578b\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u6a21\u62df\u73bb\u5c14\u5179\u66fc\u8f93\u8fd0\u65b9\u7a0b\uff08BTE\uff09\u4e2d\u7684\u968f\u673a\u7c92\u5b50\u78b0\u649e\u6765\u6a21\u62df\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u5728CIFAR-10/100\u3001ImageNet\u3001IMDB\u548cSnips\u7b49\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cKO\u5728\u4fdd\u6301\u8ba1\u7b97\u6210\u672c\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\uff0c\u59cb\u7ec8\u4f18\u4e8eAdam\u548cSGD\u7b49\u57fa\u7ebf\u4f18\u5316\u5668\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684KO\u4f18\u5316\u5668\u901a\u8fc7\u7269\u7406\u9a71\u52a8\u7684\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u53c2\u6570\u591a\u6837\u6027\uff0c\u7f13\u89e3\u4e86\u53c2\u6570\u51dd\u805a\u73b0\u8c61\uff0c\u4e14\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2505.15064", "pdf": "https://arxiv.org/pdf/2505.15064", "abs": "https://arxiv.org/abs/2505.15064", "authors": ["Sho Sonoda", "Yuka Hashimoto", "Isao Ishikawa", "Masahiro Ikeda"], "title": "Generalization Through Growth: Hidden Dynamics Controls Depth Dependence", "categories": ["cs.LG", "math.DS", "stat.ML"], "comment": null, "summary": "Recent theory has reduced the depth dependence of generalization bounds from\nexponential to polynomial and even depth-independent rates, yet these results\nremain tied to specific architectures and Euclidean inputs. We present a\nunified framework for arbitrary \\blue{pseudo-metric} spaces in which a\ndepth-\\(k\\) network is the composition of continuous hidden maps\n\\(f:\\mathcal{X}\\to \\mathcal{X}\\) and an output map \\(h:\\mathcal{X}\\to\n\\mathbb{R}\\). The resulting bound $O(\\sqrt{(\\alpha + \\log \\beta(k))/n})$\nisolates the sole depth contribution in \\(\\beta(k)\\), the word-ball growth of\nthe semigroup generated by the hidden layers. By Gromov's theorem polynomial\n(resp. exponential) growth corresponds to virtually nilpotent (resp. expanding)\ndynamics, revealing a geometric dichotomy behind existing $O(\\sqrt{k})$\n(sublinear depth) and $\\tilde{O}(1)$ (depth-independent) rates. We further\nprovide covering-number estimates showing that expanding dynamics yield an\nexponential parameter saving via compositional expressivity. Our results\ndecouple specification from implementation, offering architecture-agnostic and\ndynamical-systems-aware guarantees applicable to modern deep-learning paradigms\nsuch as test-time inference and diffusion models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u5206\u6790\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u754c\u9650\uff0c\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u4f2a\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5e76\u63ed\u793a\u4e86\u51e0\u4f55\u4e8c\u5206\u6cd5\u80cc\u540e\u7684\u6df1\u5ea6\u8d21\u732e\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u7684\u6cdb\u5316\u754c\u9650\u4e0e\u7279\u5b9a\u67b6\u6784\u548c\u6b27\u51e0\u91cc\u5f97\u8f93\u5165\u76f8\u5173\u8054\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4efb\u610f\u4f2a\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u7684\u6df1\u5ea6-k\u7f51\u7edc\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u4e2a\u65b0\u7684\u6cdb\u5316\u754c\u9650\u3002", "result": "\u5f97\u5230\u4e86\u4e00\u4e2a\u65b0\u7684\u6cdb\u5316\u754c\u9650\uff0c\u63ed\u793a\u4e86\u6df1\u5ea6\u8d21\u732e\u7684\u51e0\u4f55\u4e8c\u5206\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u8986\u76d6\u6570\u4f30\u8ba1\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u65b0\u6846\u67b6\u53ef\u4ee5\u63d0\u4f9b\u4e0e\u67b6\u6784\u65e0\u5173\u4e14\u4e0e\u52a8\u6001\u7cfb\u7edf\u76f8\u5173\u7684\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u8303\u5f0f\u3002"}}
{"id": "2505.14802", "pdf": "https://arxiv.org/pdf/2505.14802", "abs": "https://arxiv.org/abs/2505.14802", "authors": ["Iman Kazemian", "Paritosh Ramanan", "Murat Yildirim"], "title": "Text embedding models can be great data engineers", "categories": ["cs.LG"], "comment": null, "summary": "Data engineering pipelines are essential - albeit costly - components of\npredictive analytics frameworks requiring significant engineering time and\ndomain expertise for carrying out tasks such as data ingestion, preprocessing,\nfeature extraction, and feature engineering. In this paper, we propose ADEPT,\nan automated data engineering pipeline via text embeddings. At the core of the\nADEPT framework is a simple yet powerful idea that the entropy of embeddings\ncorresponding to textually dense raw format representation of time series can\nbe intuitively viewed as equivalent (or in many cases superior) to that of\nnumerically dense vector representations obtained by data engineering\npipelines. Consequently, ADEPT uses a two step approach that (i) leverages text\nembeddings to represent the diverse data sources, and (ii) constructs a\nvariational information bottleneck criteria to mitigate entropy variance in\ntext embeddings of time series data. ADEPT provides an end-to-end automated\nimplementation of predictive models that offers superior predictive performance\ndespite issues such as missing data, ill-formed records, improper or corrupted\ndata formats and irregular timestamps. Through exhaustive experiments, we show\nthat the ADEPT outperforms the best existing benchmarks in a diverse set of\ndatasets from large-scale applications across healthcare, finance, science and\nindustrial internet of things. Our results show that ADEPT can potentially\nleapfrog many conventional data pipeline steps thereby paving the way for\nefficient and scalable automation pathways for diverse data science\napplications.", "AI": {"tldr": "This paper introduces ADEPT, an automated data engineering pipeline using text embeddings to handle diverse data sources and construct variational information bottleneck criteria for time series data. It shows superior predictive performance across various datasets.", "motivation": "To reduce the significant engineering time and domain expertise required for traditional data engineering pipelines.", "method": "Using text embeddings to represent diverse data sources and constructing a variational information bottleneck criteria for time series data.", "result": "ADEPT outperforms existing benchmarks in diverse datasets from healthcare, finance, science, and industrial IoT.", "conclusion": "ADEPT can potentially leapfrog many conventional data pipeline steps, enabling efficient and scalable automation for data science applications."}}
{"id": "2505.15141", "pdf": "https://arxiv.org/pdf/2505.15141", "abs": "https://arxiv.org/abs/2505.15141", "authors": ["Yunlong Hou", "Fengzhuo Zhang", "Cunxiao Du", "Xuan Zhang", "Jiachun Pan", "Tianyu Pang", "Chao Du", "Vincent Y. F. Tan", "Zhuoran Yang"], "title": "BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "35 pages, 4 figures", "summary": "Speculative decoding has emerged as a popular method to accelerate the\ninference of Large Language Models (LLMs) while retaining their superior text\ngeneration performance. Previous methods either adopt a fixed speculative\ndecoding configuration regardless of the prefix tokens, or train draft models\nin an offline or online manner to align them with the context. This paper\nproposes a training-free online learning framework to adaptively choose the\nconfiguration of the hyperparameters for speculative decoding as text is being\ngenerated. We first formulate this hyperparameter selection problem as a\nMulti-Armed Bandit problem and provide a general speculative decoding framework\nBanditSpec. Furthermore, two bandit-based hyperparameter selection algorithms,\nUCBSpec and EXP3Spec, are designed and analyzed in terms of a novel quantity,\nthe stopping time regret. We upper bound this regret under both stochastic and\nadversarial reward settings. By deriving an information-theoretic impossibility\nresult, it is shown that the regret performance of UCBSpec is optimal up to\nuniversal constants. Finally, extensive empirical experiments with LLaMA3 and\nQwen2 demonstrate that our algorithms are effective compared to existing\nmethods, and the throughput is close to the oracle best hyperparameter in\nsimulated real-life LLM serving scenarios with diverse input prompts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u5728\u7ebf\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u9009\u62e9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u6d4b\u89e3\u7801\u7684\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u8bbe\u8ba1\u4e86UCBSpec\u548cEXP3Spec\u4e24\u79cd\u7b97\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u8981\u4e48\u91c7\u7528\u56fa\u5b9a\u914d\u7f6e\uff0c\u8981\u4e48\u9700\u8981\u79bb\u7ebf\u6216\u5728\u7ebf\u8bad\u7ec3\u8349\u6848\u6a21\u578b\u6765\u5bf9\u9f50\u4e0a\u4e0b\u6587\uff0c\u7f3a\u4e4f\u81ea\u9002\u5e94\u6027\u3002", "method": "\u5c06\u8d85\u53c2\u6570\u9009\u62e9\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86BanditSpec\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u4e86UCBSpec\u548cEXP3Spec\u4e24\u79cd\u7b97\u6cd5\u3002", "result": "\u63a8\u5bfc\u4e86\u505c\u6b62\u65f6\u95f4\u9057\u61be\u7684\u4e0a\u754c\uff0c\u5e76\u8bc1\u660eUCBSpec\u5728\u968f\u673a\u548c\u5bf9\u6297\u5956\u52b1\u8bbe\u7f6e\u4e0b\u7684\u9057\u61be\u6027\u80fd\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u79cd\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u5728\u6a21\u62df\u7684\u771f\u5b9eLLM\u670d\u52a1\u573a\u666f\u4e2d\u7684\u541e\u5410\u91cf\u63a5\u8fd1\u6700\u4f73\u8d85\u53c2\u6570\u3002"}}
{"id": "2505.14803", "pdf": "https://arxiv.org/pdf/2505.14803", "abs": "https://arxiv.org/abs/2505.14803", "authors": ["Yu Liu", "Weiyao Tao", "Tong Xia", "Simon Knight", "Tingting Zhu"], "title": "SurvUnc: A Meta-Model Based Uncertainty Quantification Framework for Survival Analysis", "categories": ["cs.LG", "cs.AI", "cs.ET"], "comment": "KDD 2025", "summary": "Survival analysis, which estimates the probability of event occurrence over\ntime from censored data, is fundamental in numerous real-world applications,\nparticularly in high-stakes domains such as healthcare and risk assessment.\nDespite advances in numerous survival models, quantifying the uncertainty of\npredictions from these models remains underexplored and challenging. The lack\nof reliable uncertainty quantification limits the interpretability and\ntrustworthiness of survival models, hindering their adoption in clinical\ndecision-making and other sensitive applications. To bridge this gap, in this\nwork, we introduce SurvUnc, a novel meta-model based framework for post-hoc\nuncertainty quantification for survival models. SurvUnc introduces an\nanchor-based learning strategy that integrates concordance knowledge into\nmeta-model optimization, leveraging pairwise ranking performance to estimate\nuncertainty effectively. Notably, our framework is model-agnostic, ensuring\ncompatibility with any survival model without requiring modifications to its\narchitecture or access to its internal parameters. Especially, we design a\ncomprehensive evaluation pipeline tailored to this critical yet overlooked\nproblem. Through extensive experiments on four publicly available benchmarking\ndatasets and five representative survival models, we demonstrate the\nsuperiority of SurvUnc across multiple evaluation scenarios, including\nselective prediction, misprediction detection, and out-of-domain detection. Our\nresults highlight the effectiveness of SurvUnc in enhancing model\ninterpretability and reliability, paving the way for more trustworthy survival\npredictions in real-world applications.", "AI": {"tldr": "\u63d0\u51faSurvUnc\u6846\u67b6\u7528\u4e8e\u751f\u5b58\u6a21\u578b\u7684\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u951a\u70b9\u5b66\u4e60\u7b56\u7565\u5e76\u517c\u5bb9\u591a\u79cd\u751f\u5b58\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660eSurvUnc\u5728\u591a\u4e2a\u8bc4\u4f30\u573a\u666f\u4e2d\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u751f\u5b58\u6a21\u578b\u5728\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4ecd\u5177\u6709\u6311\u6218\u6027\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u548c\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faSurvUnc\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u951a\u70b9\u7684\u5b66\u4e60\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u6574\u5408\u4e00\u81f4\u6027\u77e5\u8bc6\u4f18\u5316\u5143\u6a21\u578b\u6765\u6709\u6548\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u4e14\u8be5\u6846\u67b6\u4e0e\u6a21\u578b\u65e0\u5173\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e94\u4e2a\u4ee3\u8868\u6027\u751f\u5b58\u6a21\u578b\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cSurvUnc\u5728\u9009\u62e9\u6027\u9884\u6d4b\u3001\u9519\u8bef\u9884\u6d4b\u68c0\u6d4b\u548c\u8de8\u57df\u68c0\u6d4b\u7b49\u591a\u4e2a\u8bc4\u4f30\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "SurvUnc\u63d0\u9ad8\u4e86\u751f\u5b58\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u63d0\u4f9b\u4e86\u66f4\u503c\u5f97\u4fe1\u8d56\u7684\u751f\u5b58\u9884\u6d4b\u3002"}}
{"id": "2505.15195", "pdf": "https://arxiv.org/pdf/2505.15195", "abs": "https://arxiv.org/abs/2505.15195", "authors": ["Adel Javanmard", "Rudrajit Das", "Alessandro Epasto", "Vahab Mirrokni"], "title": "Self-Boost via Optimal Retraining: An Analysis via Approximate Message Passing", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "31 pages, 6 figures, 5 tables", "summary": "Retraining a model using its own predictions together with the original,\npotentially noisy labels is a well-known strategy for improving the model\nperformance. While prior works have demonstrated the benefits of specific\nheuristic retraining schemes, the question of how to optimally combine the\nmodel's predictions and the provided labels remains largely open. This paper\naddresses this fundamental question for binary classification tasks. We develop\na principled framework based on approximate message passing (AMP) to analyze\niterative retraining procedures for two ground truth settings: Gaussian mixture\nmodel (GMM) and generalized linear model (GLM). Our main contribution is the\nderivation of the Bayes optimal aggregator function to combine the current\nmodel's predictions and the given labels, which when used to retrain the same\nmodel, minimizes its prediction error. We also quantify the performance of this\noptimal retraining strategy over multiple rounds. We complement our theoretical\nresults by proposing a practically usable version of the theoretically-optimal\naggregator function for linear probing with the cross-entropy loss, and\ndemonstrate its superiority over baseline methods in the high label noise\nregime.", "AI": {"tldr": "This paper develops a principled framework using approximate message passing (AMP) to find the Bayes optimal way to combine model predictions and noisy labels for iterative retraining in binary classification tasks.", "motivation": "To address the question of how to optimally combine model predictions and potentially noisy labels during retraining to improve model performance.", "method": "Develops a principled framework based on approximate message passing (AMP) for analyzing iterative retraining procedures under Gaussian mixture model (GMM) and generalized linear model (GLM) settings.", "result": "Derives the Bayes optimal aggregator function that minimizes prediction error when retraining the same model. Quantifies the performance of this optimal retraining strategy across multiple rounds.", "conclusion": "Proposes a practical version of the theoretically-optimal aggregator function for linear probing with cross-entropy loss and shows its superiority in high label noise regimes."}}
{"id": "2505.14820", "pdf": "https://arxiv.org/pdf/2505.14820", "abs": "https://arxiv.org/abs/2505.14820", "authors": ["Rushit N. Shah", "Nikolaos Agadakos", "Synthia Sasulski", "Ali Farajzadeh", "Sanjiban Choudhury", "Brian Ziebart"], "title": "Imitation Learning via Focused Satisficing", "categories": ["cs.LG"], "comment": "Accepted for publication at the 34th International Joint Conference\n  on Artificial Intelligence (IJCAI 2025)", "summary": "Imitation learning often assumes that demonstrations are close to optimal\naccording to some fixed, but unknown, cost function. However, according to\nsatisficing theory, humans often choose acceptable behavior based on their\npersonal (and potentially dynamic) levels of aspiration, rather than achieving\n(near-) optimality. For example, a lunar lander demonstration that successfully\nlands without crashing might be acceptable to a novice despite being slow or\njerky. Using a margin-based objective to guide deep reinforcement learning, our\nfocused satisficing approach to imitation learning seeks a policy that\nsurpasses the demonstrator's aspiration levels -- defined over trajectories or\nportions of trajectories -- on unseen demonstrations without explicitly\nlearning those aspirations. We show experimentally that this focuses the policy\nto imitate the highest quality (portions of) demonstrations better than\nexisting imitation learning methods, providing much higher rates of guaranteed\nacceptability to the demonstrator, and competitive true returns on a range of\nenvironments.", "AI": {"tldr": "This paper presents a focused satisficing approach to imitation learning using a margin-based objective, which aims to surpass demonstrator's aspiration levels without explicitly learning them.", "motivation": "Imitation learning typically assumes that demonstrations are near-optimal, but this paper challenges that by considering human behavior as based on personal aspiration levels.", "method": "The method uses a margin-based objective to guide deep reinforcement learning, focusing on surpassing demonstrator's aspiration levels on unseen demonstrations.", "result": "Experiments show that this approach improves the quality of imitated demonstrations and provides higher rates of guaranteed acceptability, with competitive returns across environments.", "conclusion": "This focused satisficing approach to imitation learning offers a novel way to improve the quality of learned policies by surpassing demonstrator's aspiration levels."}}
{"id": "2505.15201", "pdf": "https://arxiv.org/pdf/2505.15201", "abs": "https://arxiv.org/abs/2505.15201", "authors": ["Christian Walder", "Deep Karkhanis"], "title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts\nfor each problem and reward them independently. This optimizes for pass@1\nperformance and prioritizes the strength of isolated samples at the expense of\nthe diversity and collective utility of sets of samples. This under-utilizes\nthe sampling capacity, limiting exploration and eventual improvement on harder\nexamples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a\ntransformation on the final rewards which leads to direct optimization of\npass@k performance, thus optimizing for sets of samples that maximize reward\nwhen considered jointly. Our contribution is to derive novel low variance\nunbiased estimators for pass@k and its gradient, in both the binary and\ncontinuous reward settings. We show optimization with our estimators reduces to\nstandard RL with rewards that have been jointly transformed by a stable and\nefficient transformation function.\n  While previous efforts are restricted to k=n, ours is the first to enable\nrobust optimization of pass@k for any arbitrary k <= n. Moreover, instead of\ntrading off pass@1 performance for pass@k gains, our method allows annealing k\nduring training, optimizing both metrics and often achieving strong pass@1\nnumbers alongside significant pass@k gains.\n  We validate our reward transformations on toy experiments, which reveal the\nvariance reducing properties of our formulations. We also include real-world\nexamples using the open-source LLM, GEMMA-2. We find that our transformation\neffectively optimizes for the target k. Furthermore, higher k values enable\nsolving more and harder problems, while annealing k boosts both the pass@1 and\npass@k . Crucially, for challenging task sets where conventional pass@1\noptimization stalls, our pass@k approach unblocks learning, likely due to\nbetter exploration by prioritizing joint utility over the utility of individual\nsamples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Pass-at-k\u7b56\u7565\u4f18\u5316(PKPO)\uff0c\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u591a\u4e2a\u6837\u672c\u96c6\u5408\u7684\u6574\u4f53\u5956\u52b1\uff0c\u63d0\u9ad8\u4e86\u5bf9\u66f4\u96be\u95ee\u9898\u7684\u63a2\u7d22\u548c\u6539\u8fdb\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53ea\u4f18\u5316\u5355\u4e2a\u6837\u672c\uff08pass@1\uff09\uff0c\u5ffd\u7565\u4e86\u591a\u4e2a\u6837\u672c\u96c6\u5408\u7684\u591a\u6837\u6027\u548c\u6574\u4f53\u6548\u7528\uff0c\u9650\u5236\u4e86\u63a2\u7d22\u80fd\u529b\u548c\u5bf9\u66f4\u96be\u95ee\u9898\u7684\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5Pass-at-k\u7b56\u7565\u4f18\u5316(PKPO)\uff0c\u5b83\u6539\u53d8\u4e86\u6700\u7ec8\u5956\u52b1\uff0c\u76f4\u63a5\u4f18\u5316pass@k\u6027\u80fd\uff0c\u5e76\u63a8\u5bfc\u51fapass@k\u53ca\u5176\u68af\u5ea6\u7684\u65b0\u4f4e\u65b9\u5dee\u65e0\u504f\u4f30\u8ba1\u91cf\u3002", "result": "\u5728\u73a9\u5177\u5b9e\u9a8c\u548c\u771f\u5b9e\u4e16\u754c\u4f8b\u5b50\u4e2d\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u5956\u52b1\u53d8\u6362\u65b9\u6cd5\u3002\u53d1\u73b0\u6211\u4eec\u7684\u53d8\u6362\u6709\u6548\u5730\u4f18\u5316\u4e86\u76ee\u6807k\u503c\u3002\u66f4\u9ad8\u7684k\u503c\u80fd\u591f\u89e3\u51b3\u66f4\u591a\u548c\u66f4\u96be\u7684\u95ee\u9898\uff0c\u800ck\u7684\u9000\u706b\u540c\u65f6\u63d0\u5347\u4e86pass@1\u548cpass@k\u7684\u6027\u80fd\u3002\u5bf9\u4e8e\u5e38\u89c4pass@1\u4f18\u5316\u505c\u6ede\u7684\u6311\u6218\u6027\u4efb\u52a1\u96c6\uff0c\u6211\u4eec\u7684pass@k\u65b9\u6cd5\u89e3\u9664\u4e86\u5b66\u4e60\u969c\u788d\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684Pass-at-k\u7b56\u7565\u4f18\u5316(PKPO)\u89e3\u51b3\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e2d\u53ea\u4f18\u5316\u5355\u4e2a\u6837\u672c\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u591a\u4e2a\u6837\u672c\u96c6\u5408\u7684\u6574\u4f53\u5956\u52b1\uff0c\u63d0\u9ad8\u4e86\u5bf9\u66f4\u96be\u95ee\u9898\u7684\u63a2\u7d22\u548c\u6539\u8fdb\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u6709\u521b\u65b0\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e5f\u6709\u6548\u3002"}}
{"id": "2505.14821", "pdf": "https://arxiv.org/pdf/2505.14821", "abs": "https://arxiv.org/abs/2505.14821", "authors": ["Runze Zhao", "Yue Yu", "Adams Yiyue Zhu", "Chen Yang", "Dongruo Zhou"], "title": "Sample and Computationally Efficient Continuous-Time Reinforcement Learning with General Function Approximation", "categories": ["cs.LG", "cs.AI"], "comment": "28 pages, 4 figures, 5 tables. Accepted to UAI 2025", "summary": "Continuous-time reinforcement learning (CTRL) provides a principled framework\nfor sequential decision-making in environments where interactions evolve\ncontinuously over time. Despite its empirical success, the theoretical\nunderstanding of CTRL remains limited, especially in settings with general\nfunction approximation. In this work, we propose a model-based CTRL algorithm\nthat achieves both sample and computational efficiency. Our approach leverages\noptimism-based confidence sets to establish the first sample complexity\nguarantee for CTRL with general function approximation, showing that a\nnear-optimal policy can be learned with a suboptimality gap of\n$\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})$ using $N$\nmeasurements, where $d_{\\mathcal{R}}$ and $d_{\\mathcal{F}}$ denote the\ndistributional Eluder dimensions of the reward and dynamic functions,\nrespectively, capturing the complexity of general function approximation in\nreinforcement learning. Moreover, we introduce structured policy updates and an\nalternative measurement strategy that significantly reduce the number of policy\nupdates and rollouts while maintaining competitive sample efficiency. We\nimplemented experiments to backup our proposed algorithms on continuous control\ntasks and diffusion model fine-tuning, demonstrating comparable performance\nwith significantly fewer policy updates and rollouts.", "AI": {"tldr": "This paper proposes a model-based continuous-time reinforcement learning algorithm that is both sample and computationally efficient, providing the first sample complexity guarantee for general function approximation.", "motivation": "To address the limited theoretical understanding of continuous-time reinforcement learning, particularly in settings with general function approximation.", "method": "Proposes an optimism-based confidence set approach and introduces structured policy updates with an alternative measurement strategy.", "result": "Achieves sample complexity guarantee and demonstrates competitive performance with fewer policy updates and rollouts.", "conclusion": "The proposed algorithm offers a significant advancement in the theoretical understanding of continuous-time reinforcement learning with general function approximation."}}
{"id": "2505.15239", "pdf": "https://arxiv.org/pdf/2505.15239", "abs": "https://arxiv.org/abs/2505.15239", "authors": ["Peter S\u00faken\u00edk", "Christoph H. Lampert", "Marco Mondelli"], "title": "Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The empirical emergence of neural collapse -- a surprising symmetry in the\nfeature representations of the training data in the penultimate layer of deep\nneural networks -- has spurred a line of theoretical research aimed at its\nunderstanding. However, existing work focuses on data-agnostic models or, when\ndata structure is taken into account, it remains limited to multi-layer\nperceptrons. Our paper fills both these gaps by analyzing modern architectures\nin a data-aware regime: we prove that global optima of deep regularized\ntransformers and residual networks (ResNets) with LayerNorm trained with cross\nentropy or mean squared error loss are approximately collapsed, and the\napproximation gets tighter as the depth grows. More generally, we formally\nreduce any end-to-end large-depth ResNet or transformer training into an\nequivalent unconstrained features model, thus justifying its wide use in the\nliterature even beyond data-agnostic settings. Our theoretical results are\nsupported by experiments on computer vision and language datasets showing that,\nas the depth grows, neural collapse indeed becomes more prominent.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6df1\u5ea6\u6b63\u5219\u5316Transformer\u548cResNet\u7f51\u7edc\u5728\u6570\u636e\u611f\u77e5\u60c5\u51b5\u4e0b\u7684\u795e\u7ecf\u574d\u584c\u73b0\u8c61\u3002\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6a21\u578b\u7684\u5168\u5c40\u6700\u4f18\u89e3\u8fd1\u4f3c\u574d\u584c\uff0c\u5e76\u4e14\u968f\u7740\u6df1\u5ea6\u589e\u52a0\uff0c\u8fd9\u79cd\u8fd1\u4f3c\u66f4\u52a0\u7d27\u5bc6\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u968f\u7740\u6df1\u5ea6\u589e\u957f\uff0c\u795e\u7ecf\u574d\u584c\u73b0\u8c61\u53d8\u5f97\u66f4\u52a0\u663e\u8457\u3002", "motivation": "\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u795e\u7ecf\u574d\u584c\u73b0\u8c61\u3002", "method": "\u5206\u6790\u73b0\u4ee3\u67b6\u6784\u5728\u6570\u636e\u611f\u77e5\u60c5\u51b5\u4e0b\u7684\u795e\u7ecf\u574d\u584c\u73b0\u8c61\uff0c\u5e76\u8bc1\u660e\u4e86\u5168\u5c40\u6700\u4f18\u89e3\u7684\u8fd1\u4f3c\u574d\u584c\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u6df1\u5ea6\u6b63\u5219\u5316Transformer\u548cResNet\u7f51\u7edc\u7684\u5168\u5c40\u6700\u4f18\u89e3\u8fd1\u4f3c\u574d\u584c\uff0c\u5e76\u4e14\u968f\u7740\u6df1\u5ea6\u589e\u52a0\uff0c\u8fd9\u79cd\u8fd1\u4f3c\u66f4\u52a0\u7d27\u5bc6\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u73b0\u6709\u5de5\u4f5c\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u5bf9\u795e\u7ecf\u574d\u584c\u73b0\u8c61\u7684\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2505.15354", "pdf": "https://arxiv.org/pdf/2505.15354", "abs": "https://arxiv.org/abs/2505.15354", "authors": ["Malik Tiomoko", "Hamza Cherkaoui", "Giuseppe Paolo", "Zhang Yili", "Yu Meng", "Zhang Keli", "Hafiz Tiomoko Ali"], "title": "Human in the Loop Adaptive Optimization for Improved Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Time series forecasting models often produce systematic, predictable errors\neven in critical domains such as energy, finance, and healthcare. We introduce\na novel post training adaptive optimization framework that improves forecast\naccuracy without retraining or architectural changes. Our method automatically\napplies expressive transformations optimized via reinforcement learning,\ncontextual bandits, or genetic algorithms to correct model outputs in a\nlightweight and model agnostic way. Theoretically, we prove that affine\ncorrections always reduce the mean squared error; practically, we extend this\nidea with dynamic action based optimization. The framework also supports an\noptional human in the loop component: domain experts can guide corrections\nusing natural language, which is parsed into actions by a language model.\nAcross multiple benchmarks (e.g., electricity, weather, traffic), we observe\nconsistent accuracy gains with minimal computational overhead. Our interactive\ndemo shows the framework's real time usability. By combining automated post hoc\nrefinement with interpretable and extensible mechanisms, our approach offers a\npowerful new direction for practical forecasting systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u81ea\u9002\u5e94\u4f18\u5316\u6846\u67b6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u67b6\u6784\u66f4\u6539\u5373\u53ef\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u5373\u4f7f\u5728\u5173\u952e\u9886\u57df\uff08\u5982\u80fd\u6e90\u3001\u91d1\u878d\u548c\u533b\u7597\uff09\u4e2d\u4e5f\u4f1a\u4ea7\u751f\u7cfb\u7edf\u6027\u7684\u53ef\u9884\u6d4b\u9519\u8bef\u3002", "method": "\u81ea\u52a8\u5e94\u7528\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u3001\u4e0a\u4e0b\u6587\u4e50\u961f\u6216\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u7684\u8868\u8fbe\u6027\u53d8\u6362\uff0c\u4ee5\u8f7b\u91cf\u7ea7\u4e14\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u6821\u6b63\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "\u7ed3\u5408\u4e86\u81ea\u52a8\u5316\u4e8b\u540e\u7ec6\u5316\u4e0e\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u673a\u5236\uff0c\u4e3a\u5b9e\u9645\u9884\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.14828", "pdf": "https://arxiv.org/pdf/2505.14828", "abs": "https://arxiv.org/abs/2505.14828", "authors": ["Juan Nathaniel", "Carla Roesch", "Jatan Buch", "Derek DeSantis", "Adam Rupe", "Kara Lamb", "Pierre Gentine"], "title": "Deep Koopman operator framework for causal discovery in nonlinear dynamical systems", "categories": ["cs.LG"], "comment": "10+14 pages, 10+13 figures", "summary": "We use a deep Koopman operator-theoretic formalism to develop a novel causal\ndiscovery algorithm, Kausal. Causal discovery aims to identify cause-effect\nmechanisms for better scientific understanding, explainable decision-making,\nand more accurate modeling. Standard statistical frameworks, such as Granger\ncausality, lack the ability to quantify causal relationships in nonlinear\ndynamics due to the presence of complex feedback mechanisms, timescale mixing,\nand nonstationarity. This presents a challenge in studying many real-world\nsystems, such as the Earth's climate. Meanwhile, Koopman operator methods have\nemerged as a promising tool for approximating nonlinear dynamics in a linear\nspace of observables. In Kausal, we propose to leverage this powerful idea for\ncausal analysis where optimal observables are inferred using deep learning.\nCausal estimates are then evaluated in a reproducing kernel Hilbert space, and\ndefined as the distance between the marginal dynamics of the effect and the\njoint dynamics of the cause-effect observables. Our numerical experiments\ndemonstrate Kausal's superior ability in discovering and characterizing causal\nsignals compared to existing approaches of prescribed observables. Lastly, we\nextend our analysis to observations of El Ni\\~no-Southern Oscillation\nhighlighting our algorithm's applicability to real-world phenomena. Our code is\navailable at https://github.com/juannat7/kausal.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6Koopman\u7b97\u5b50\u7406\u8bba\u7684\u65b0\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5Kausal\uff0c\u8be5\u7b97\u6cd5\u5728\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u6807\u51c6\u7edf\u8ba1\u6846\u67b6\u65e0\u6cd5\u91cf\u5316\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u7814\u7a76\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u63a8\u65ad\u6700\u4f18\u89c2\u6d4b\u503c\uff0c\u5e76\u901a\u8fc7\u518d\u751f\u6838Hilbert\u7a7a\u95f4\u8bc4\u4f30\u56e0\u679c\u4f30\u8ba1\u503c\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660eKausal\u5728\u53d1\u73b0\u548c\u8868\u5f81\u56e0\u679c\u4fe1\u53f7\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Kausal\u7b97\u6cd5\u5c55\u793a\u4e86\u5176\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u73b0\u8c61\uff08\u5982\u5384\u5c14\u5c3c\u8bfa-\u5357\u65b9\u6d9b\u52a8\uff09\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2505.15423", "pdf": "https://arxiv.org/pdf/2505.15423", "abs": "https://arxiv.org/abs/2505.15423", "authors": ["Marcell T. Kurbucz", "Nikolaos Tzivanakis", "Nilufer Sari Aslam", "Adam M. Sykulski"], "title": "SplitWise Regression: Stepwise Modeling with Adaptive Dummy Encoding", "categories": ["cs.LG", "econ.EM", "stat.AP", "stat.ME", "stat.ML", "62H20, 62J05, 68T05", "G.3; I.2.6; I.5.1; I.5.2"], "comment": "15 pages, 1 figure, 3 tables", "summary": "Capturing nonlinear relationships without sacrificing interpretability\nremains a persistent challenge in regression modeling. We introduce SplitWise,\na novel framework that enhances stepwise regression. It adaptively transforms\nnumeric predictors into threshold-based binary features using shallow decision\ntrees, but only when such transformations improve model fit, as assessed by the\nAkaike Information Criterion (AIC) or Bayesian Information Criterion (BIC).\nThis approach preserves the transparency of linear models while flexibly\ncapturing nonlinear effects. Implemented as a user-friendly R package,\nSplitWise is evaluated on both synthetic and real-world datasets. The results\nshow that it consistently produces more parsimonious and generalizable models\nthan traditional stepwise and penalized regression techniques.", "AI": {"tldr": "\u63d0\u51faSplitWise\u6846\u67b6\u589e\u5f3a\u9010\u6b65\u56de\u5f52\uff0c\u901a\u8fc7\u51b3\u7b56\u6811\u5904\u7406\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4fdd\u6301\u6a21\u578b\u900f\u660e\u6027\u540c\u65f6\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u6355\u6349\u975e\u7ebf\u6027\u5173\u7cfb\u800c\u4e0d\u727a\u7272\u53ef\u89e3\u91ca\u6027\u4ecd\u7136\u662f\u56de\u5f52\u5efa\u6a21\u4e2d\u7684\u4e00\u4e2a\u6301\u7eed\u6311\u6218\u3002", "method": "\u5f15\u5165\u6d45\u5c42\u51b3\u7b56\u6811\u81ea\u9002\u5e94\u5730\u5c06\u6570\u503c\u9884\u6d4b\u53d8\u91cf\u8f6c\u6362\u4e3a\u57fa\u4e8e\u9608\u503c\u7684\u4e8c\u5143\u7279\u5f81\uff0c\u4ec5\u5f53\u8fd9\u79cd\u8f6c\u6362\u80fd\u6539\u5584\u6a21\u578b\u62df\u5408\u65f6\u624d\u8fdb\u884c\u8f6c\u6362\uff0c\u4f7f\u7528\u8d64\u6c60\u4fe1\u606f\u91cf\u51c6\u5219(AIC)\u6216\u8d1d\u53f6\u65af\u4fe1\u606f\u91cf\u51c6\u5219(BIC)\u8bc4\u4f30\u6a21\u578b\u62df\u5408\u3002", "result": "SplitWise\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4ea7\u751f\u7684\u6a21\u578b\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u7b80\u6d01\u4e14\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002", "conclusion": "SplitWise\u65b9\u6cd5\u5728\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u900f\u660e\u6027\u7684\u540c\u65f6\uff0c\u7075\u6d3b\u6355\u6349\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u6bd4\u4f20\u7edf\u7684\u9010\u6b65\u56de\u5f52\u548c\u60e9\u7f5a\u56de\u5f52\u6280\u672f\u4ea7\u751f\u66f4\u7b80\u6d01\u4e14\u6cdb\u5316\u7684\u6a21\u578b\u3002"}}
{"id": "2505.14840", "pdf": "https://arxiv.org/pdf/2505.14840", "abs": "https://arxiv.org/abs/2505.14840", "authors": ["Shreya Gupta", "Boyang Huang", "Barna Saha", "Yinzhan Xu", "Christopher Ye"], "title": "Subquadratic Algorithms and Hardness for Attention with Any Temperature", "categories": ["cs.LG", "cs.CC", "F.2.1"], "comment": "34 pages, 2 figures, abstract shortened to meet arXiv requirements", "summary": "Despite the popularity of the Transformer architecture, the standard\nalgorithm for computing Attention suffers from quadratic time complexity in\ncontext length $n$. Alman and Song [NeurIPS 2023] showed that when the head\ndimension $d = \\Theta(\\log n)$, subquadratic Attention is possible if and only\nif the inputs have small entries bounded by $B = o(\\sqrt{\\log n})$ in absolute\nvalues, under the Strong Exponential Time Hypothesis ($\\mathsf{SETH}$).\nEquivalently, subquadratic Attention is possible if and only if the softmax is\napplied with high temperature for $d=\\Theta(\\log n)$. Running times of these\nalgorithms depend exponentially on $B$ and thus they do not lead to even a\npolynomial-time algorithm outside the specific range of $B$.\n  This naturally leads to the question: when can Attention be computed\nefficiently without strong assumptions on temperature? Are there fast attention\nalgorithms that scale polylogarithmically with entry size $B$? In this work, we\nresolve this question and characterize when fast Attention for arbitrary\ntemperatures is possible. First, for all constant $d = O(1)$, we give the first\nsubquadratic $\\tilde{O}(n^{2 - 1/d} \\cdot \\mathrm{polylog}(B))$ time algorithm\nfor Attention with large $B$. Our result holds even for matrices with large\nhead dimension if they have low rank. In this regime, we also give a similar\nrunning time for Attention gradient computation, and therefore for the full LLM\ntraining process. Furthermore, we show that any substantial improvement on our\nalgorithm is unlikely. In particular, we show that even when $d =\n2^{\\Theta(\\log^* n)}$, Attention requires $n^{2 - o(1)}$ time under\n$\\mathsf{SETH}$.\n  Finally, in the regime where $d = \\mathrm{poly}(n)$, we show that the\nstandard algorithm is optimal under popular fine-grained complexity\nassumptions.", "AI": {"tldr": "This paper provides a new algorithm for efficient attention computation with large input sizes, applicable for constant head dimensions, and shows that any substantial improvement is unlikely.", "motivation": "To address the inefficiency of the standard attention computation in transformers due to its quadratic time complexity.", "method": "Developing a new algorithm for attention computation that scales polylogarithmically with entry size B for constant head dimensions.", "result": "The proposed algorithm achieves subquadratic time complexity for attention computation with large B values and has a similar running time for attention gradient computation and LLM training processes.", "conclusion": "The paper concludes that any significant improvement on their algorithm is improbable, especially when head dimension d equals 2 raised to a function of log-star n."}}
{"id": "2505.15496", "pdf": "https://arxiv.org/pdf/2505.15496", "abs": "https://arxiv.org/abs/2505.15496", "authors": ["Hossein Zakerinia", "Christoph H. Lampert"], "title": "Fast Rate Bounds for Multi-Task and Meta-Learning with Different Sample Sizes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present new fast-rate generalization bounds for multi-task and\nmeta-learning in the unbalanced setting, i.e. when the tasks have training sets\nof different sizes, as is typically the case in real-world scenarios.\nPreviously, only standard-rate bounds were known for this situation, while\nfast-rate bounds were limited to the setting where all training sets are of\nequal size. Our new bounds are numerically computable as well as interpretable,\nand we demonstrate their flexibility in handling a number of cases where they\ngive stronger guarantees than previous bounds. Besides the bounds themselves,\nwe also make conceptual contributions: we demonstrate that the unbalanced\nmulti-task setting has different statistical properties than the balanced\nsituation, specifically that proofs from the balanced situation do not carry\nover to the unbalanced setting. Additionally, we shed light on the fact that\nthe unbalanced situation allows two meaningful definitions of multi-task risk,\ndepending on whether if all tasks should be considered equally important or if\nsample-rich tasks should receive more weight than sample-poor ones.", "AI": {"tldr": "This paper presents new fast-rate generalization bounds for multi-task and meta-learning in unbalanced settings, showing stronger guarantees than previous bounds.", "motivation": "To address the gap in fast-rate bounds for unbalanced multi-task learning scenarios which are common in real-world applications.", "method": "Developing new numerical and interpretable fast-rate generalization bounds for unbalanced task training sets.", "result": "The new bounds provide stronger guarantees than previous standards, especially in certain cases.", "conclusion": "Unbalanced multi-task learning has distinct statistical properties compared to balanced settings, requiring new proof techniques and offering two ways to define multi-task risk."}}
{"id": "2505.14877", "pdf": "https://arxiv.org/pdf/2505.14877", "abs": "https://arxiv.org/abs/2505.14877", "authors": ["Francisco P\u00e9rez-Galarce", "Jorge Mart\u00ednez-Palomera", "Karim Pichara", "Pablo Huijse", "M\u00e1rcio Catelan"], "title": "A self-regulated convolutional neural network for classifying variable stars", "categories": ["cs.LG", "astro-ph.SR"], "comment": null, "summary": "Over the last two decades, machine learning models have been widely applied\nand have proven effective in classifying variable stars, particularly with the\nadoption of deep learning architectures such as convolutional neural networks,\nrecurrent neural networks, and transformer models. While these models have\nachieved high accuracy, they require high-quality, representative data and a\nlarge number of labelled samples for each star type to generalise well, which\ncan be challenging in time-domain surveys. This challenge often leads to models\nlearning and reinforcing biases inherent in the training data, an issue that is\nnot easily detectable when validation is performed on subsamples from the same\ncatalogue. The problem of biases in variable star data has been largely\noverlooked, and a definitive solution has yet to be established. In this paper,\nwe propose a new approach to improve the reliability of classifiers in variable\nstar classification by introducing a self-regulated training process. This\nprocess utilises synthetic samples generated by a physics-enhanced latent space\nvariational autoencoder, incorporating six physical parameters from Gaia Data\nRelease 3. Our method features a dynamic interaction between a classifier and a\ngenerative model, where the generative model produces ad-hoc synthetic light\ncurves to reduce confusion during classifier training and populate\nunderrepresented regions in the physical parameter space. Experiments conducted\nunder various scenarios demonstrate that our self-regulated training approach\noutperforms traditional training methods for classifying variable stars on\nbiased datasets, showing statistically significant improvements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u8c03\u8282\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u6837\u672c\u6765\u6539\u5584\u53d8\u661f\u5206\u7c7b\u4e2d\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u5728\u6709\u504f\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u53d8\u661f\u5206\u7c7b\u65f6\u5bb9\u6613\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u56fa\u6709\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u8fd9\u79cd\u504f\u5dee\u96be\u4ee5\u68c0\u6d4b\u3002", "method": "\u4e00\u79cd\u81ea\u8c03\u8282\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u7ed3\u5408\u7269\u7406\u589e\u5f3a\u7684\u6f5c\u5728\u7a7a\u95f4\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u751f\u6210\u5408\u6210\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5904\u7406\u6709\u504f\u6570\u636e\u96c6\u7684\u53d8\u661f\u5206\u7c7b\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2505.15579", "pdf": "https://arxiv.org/pdf/2505.15579", "abs": "https://arxiv.org/abs/2505.15579", "authors": ["Hossein Zakerinia", "Jonathan Scott", "Christoph H. Lampert"], "title": "Federated Learning with Unlabeled Clients: Personalization Can Happen in Low Dimensions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Personalized federated learning has emerged as a popular approach to training\non devices holding statistically heterogeneous data, known as clients. However,\nmost existing approaches require a client to have labeled data for training or\nfinetuning in order to obtain their own personalized model. In this paper we\naddress this by proposing FLowDUP, a novel method that is able to generate a\npersonalized model using only a forward pass with unlabeled data. The generated\nmodel parameters reside in a low-dimensional subspace, enabling efficient\ncommunication and computation. FLowDUP's learning objective is theoretically\nmotivated by our new transductive multi-task PAC-Bayesian generalization bound,\nthat provides performance guarantees for unlabeled clients. The objective is\nstructured in such a way that it allows both clients with labeled data and\nclients with only unlabeled data to contribute to the training process. To\nsupplement our theoretical results we carry out a thorough experimental\nevaluation of FLowDUP, demonstrating strong empirical performance on a range of\ndatasets with differing sorts of statistically heterogeneous clients. Through\nnumerous ablation studies, we test the efficacy of the individual components of\nthe method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFLowDUP\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7\u65e0\u6807\u7b7e\u6570\u636e\u751f\u6210\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u6709\u6807\u7b7e\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u800cFLowDUP\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u524d\u5411\u4f20\u9012\u751f\u6210\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u5e76\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u8868\u793a\u6a21\u578b\u53c2\u6570\u3002", "result": "FLowDUP\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u7edf\u8ba1\u5f02\u6784\u5ba2\u6237\u7aef\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5b9e\u8bc1\u6027\u80fd\u3002", "conclusion": "FLowDUP\u80fd\u901a\u8fc7\u65e0\u6807\u7b7e\u6570\u636e\u751f\u6210\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u4e14\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.14882", "pdf": "https://arxiv.org/pdf/2505.14882", "abs": "https://arxiv.org/abs/2505.14882", "authors": ["Abdellah Aznag", "Rachel Cummings", "Adam N. Elmachtoub"], "title": "An active learning framework for multi-group mean estimation", "categories": ["cs.LG"], "comment": null, "summary": "We study a fundamental learning problem over multiple groups with unknown\ndata distributions, where an analyst would like to learn the mean of each\ngroup. Moreover, we want to ensure that this data is collected in a relatively\nfair manner such that the noise of the estimate of each group is reasonable. In\nparticular, we focus on settings where data are collected dynamically, which is\nimportant in adaptive experimentation for online platforms or adaptive clinical\ntrials for healthcare. In our model, we employ an active learning framework to\nsequentially collect samples with bandit feedback, observing a sample in each\nperiod from the chosen group. After observing a sample, the analyst updates\ntheir estimate of the mean and variance of that group and chooses the next\ngroup accordingly. The analyst's objective is to dynamically collect samples to\nminimize the collective noise of the estimators, measured by the norm of the\nvector of variances of the mean estimators.\n  We propose an algorithm, Variance-UCB, that sequentially selects groups\naccording to an upper confidence bound on the variance estimate. We provide a\ngeneral theoretical framework for providing efficient bounds on learning from\nany underlying distribution where the variances can be estimated reasonably.\nThis framework yields upper bounds on regret that improve significantly upon\nall existing bounds, as well as a collection of new results for different\nobjectives and distributions than those previously studied.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVariance-UCB\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u6536\u96c6\u6837\u672c\u65f6\u6700\u5c0f\u5316\u4f30\u8ba1\u5747\u503c\u5411\u91cf\u65b9\u5dee\u7684\u8303\u6570\u3002\u8be5\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u79cd\u5206\u5e03\u548c\u76ee\u6807\u3002", "motivation": "\u7814\u7a76\u591a\u4e2a\u7fa4\u4f53\u7684\u5e73\u5747\u503c\u5b66\u4e60\u95ee\u9898\uff0c\u786e\u4fdd\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u516c\u5e73\uff0c\u566a\u58f0\u5408\u7406\u3002", "method": "\u91c7\u7528\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528bandit\u53cd\u9988\u52a8\u6001\u9009\u62e9\u7fa4\u4f53\uff0c\u89c2\u5bdf\u6837\u672c\u5e76\u66f4\u65b0\u4f30\u8ba1\u503c\u3002\u63d0\u51faVariance-UCB\u7b97\u6cd5\uff0c\u57fa\u4e8e\u65b9\u5dee\u4f30\u8ba1\u7684\u7f6e\u4fe1\u4e0a\u9650\u9009\u62e9\u7fa4\u4f53\u3002", "result": "\u63d0\u51fa\u7684Variance-UCB\u7b97\u6cd5\u5728\u7406\u8bba\u5206\u6790\u4e0a\u663e\u8457\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u540e\u6094\u754c\uff0c\u5e76\u4e3a\u4e0d\u540c\u76ee\u6807\u548c\u5206\u5e03\u63d0\u4f9b\u4e86\u65b0\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9002\u5e94\u6027\u5b9e\u9a8c\u548c\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u6709\u6548\u5904\u7406\u672a\u77e5\u6570\u636e\u5206\u5e03\u4e0b\u7684\u5b66\u4e60\u95ee\u9898\u3002"}}
{"id": "2505.15626", "pdf": "https://arxiv.org/pdf/2505.15626", "abs": "https://arxiv.org/abs/2505.15626", "authors": ["Jacopo Teneggi", "Zhenzhen Wang", "Paul H. Yi", "Tianmin Shu", "Jeremias Sulam"], "title": "Aligning Explanations with Human Communication", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine learning explainability aims to make the decision-making process of\nblack-box models more transparent by finding the most important input features\nfor a given prediction task. Recent works have proposed composing explanations\nfrom semantic concepts (e.g., colors, patterns, shapes) that are inherently\ninterpretable to the user of a model. However, these methods generally ignore\nthe communicative context of explanation-the ability of the user to understand\nthe prediction of the model from the explanation. For example, while a medical\ndoctor might understand an explanation in terms of clinical markers, a patient\nmay need a more accessible explanation to make sense of the same diagnosis. In\nthis paper, we address this gap with listener-adaptive explanations. We propose\nan iterative procedure grounded in principles of pragmatic reasoning and the\nrational speech act to generate explanations that maximize communicative\nutility. Our procedure only needs access to pairwise preferences between\ncandidate explanations, relevant in real-world scenarios where a listener model\nmay not be available. We evaluate our method in image classification tasks,\ndemonstrating improved alignment between explanations and listener preferences\nacross three datasets. Furthermore, we perform a user study that demonstrates\nour explanations increase communicative utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u542c\u4f17\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u4e86\u89e3\u91ca\u7684\u4ea4\u6d41\u80cc\u666f\uff0c\u5373\u7528\u6237\u4ece\u89e3\u91ca\u4e2d\u7406\u89e3\u6a21\u578b\u9884\u6d4b\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u8bed\u7528\u63a8\u7406\u548c\u7406\u6027\u8bdd\u8bed\u884c\u4e3a\u539f\u5219\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u6765\u751f\u6210\u6700\u5927\u5316\u6c9f\u901a\u6548\u7528\u7684\u89e3\u91ca\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u89e3\u91ca\u4e0e\u542c\u4f17\u504f\u597d\u7684\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u63d0\u9ad8\u4e86\u6c9f\u901a\u6548\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u542c\u4f17\u81ea\u9002\u5e94\u89e3\u91ca\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u8981\u8bbf\u95ee\u5019\u9009\u89e3\u91ca\u4e4b\u95f4\u7684\u6210\u5bf9\u504f\u597d\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u89e3\u91ca\u4e0e\u542c\u4f17\u504f\u597d\u7684\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u63d0\u9ad8\u4e86\u6c9f\u901a\u6548\u7528\u3002"}}
{"id": "2505.14884", "pdf": "https://arxiv.org/pdf/2505.14884", "abs": "https://arxiv.org/abs/2505.14884", "authors": ["Susav Shrestha", "Brad Settlemyer", "Nikoli Dryden", "Narasimha Reddy"], "title": "Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accelerating large language model (LLM) inference is critical for real-world\ndeployments requiring high throughput and low latency. Contextual sparsity,\nwhere each token dynamically activates only a small subset of the model\nparameters, shows promise but does not scale to large batch sizes due to union\nof active neurons quickly approaching dense computation. We introduce Polar\nSparsity, highlighting a key shift in sparsity importance from MLP to Attention\nlayers as we scale batch size and sequence length. While MLP layers become more\ncompute-efficient under batching, their sparsity vanishes. In contrast,\nattention becomes increasingly more expensive at scale, while their head\nsparsity remains stable and batch-invariant. We develop hardware-efficient,\nsparsity-aware GPU kernels for selective MLP and Attention computations,\ndelivering up to \\(2.2\\times\\) end-to-end speedups for models like OPT, LLaMA-2\n\\& 3, across various batch sizes and sequence lengths without compromising\naccuracy. To our knowledge, this is the first work to demonstrate that\ncontextual sparsity can scale effectively to large batch sizes, delivering\nsubstantial inference acceleration with minimal changes, making Polar Sparsity\npractical for large-scale, high-throughput LLM deployment systems. Our code is\navailable at: https://github.com/susavlsh10/Polar-Sparsity.", "AI": {"tldr": "\u63d0\u51faPolar\u7a00\u758f\u6027\uff0c\u4f7f\u4e0a\u4e0b\u6587\u7a00\u758f\u6027\u80fd\u591f\u6269\u5c55\u81f3\u5927\u6279\u6b21\u5927\u5c0f\uff0c\u663e\u8457\u52a0\u901fLLMs\u63a8\u7406\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "motivation": "\u52a0\u901f\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u5bf9\u4e8e\u9700\u8981\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u7684\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165Polar\u7a00\u758f\u6027\uff0c\u5f00\u53d1\u786c\u4ef6\u9ad8\u6548\u3001\u611f\u77e5\u7a00\u758f\u6027\u7684GPU\u5185\u6838\u7528\u4e8e\u9009\u62e9\u6027MLP\u548c\u6ce8\u610f\u529b\u8ba1\u7b97\u3002", "result": "\u5728OPT\u3001LLaMA-2\u548c3\u7b49\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad82.2\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u6279\u6b21\u5927\u5c0f\u548c\u5e8f\u5217\u957f\u5ea6\uff0c\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "conclusion": "\u9996\u6b21\u8bc1\u660e\u4e0a\u4e0b\u6587\u7a00\u758f\u6027\u53ef\u4ee5\u6709\u6548\u6269\u5c55\u5230\u5927\u6279\u6b21\u5927\u5c0f\uff0c\u5e76\u5728\u5404\u79cd\u6279\u6b21\u5927\u5c0f\u548c\u5e8f\u5217\u957f\u5ea6\u4e0b\u63d0\u4f9b\u9ad8\u8fbe2.2\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u800c\u4e0d\u4f1a\u5f71\u54cd\u51c6\u786e\u6027\u3002"}}
{"id": "2505.15638", "pdf": "https://arxiv.org/pdf/2505.15638", "abs": "https://arxiv.org/abs/2505.15638", "authors": ["Daniel Waxman", "Fernando Llorente", "Petar M. Djuri\u0107"], "title": "Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes", "categories": ["cs.LG", "stat.CO", "stat.ME", "stat.ML"], "comment": "25 pages, 12 figures", "summary": "We revisit the classical problem of Bayesian ensembles and address the\nchallenge of learning optimal combinations of Bayesian models in an online,\ncontinual learning setting. To this end, we reinterpret existing approaches\nsuch as Bayesian model averaging (BMA) and Bayesian stacking through a novel\nempirical Bayes lens, shedding new light on the limitations and pathologies of\nBMA. Further motivated by insights from online optimization, we propose Online\nBayesian Stacking (OBS), a method that optimizes the log-score over predictive\ndistributions to adaptively combine Bayesian models. A key contribution of our\nwork is establishing a novel connection between OBS and portfolio selection,\nbridging Bayesian ensemble learning with a rich, well-studied theoretical\nframework that offers efficient algorithms and extensive regret analysis. We\nfurther clarify the relationship between OBS and online BMA, showing that they\noptimize related but distinct cost functions. Through theoretical analysis and\nempirical evaluation, we identify scenarios where OBS outperforms online BMA\nand provide principled guidance on when practitioners should prefer one\napproach over the other.", "AI": {"tldr": "This paper revisits Bayesian ensembles and introduces Online Bayesian Stacking (OBS), which adapts Bayesian models using log-score optimization. It connects OBS to portfolio selection and compares it with online Bayesian model averaging.", "motivation": "To learn optimal combinations of Bayesian models in an online, continual learning setting while addressing limitations of existing methods like Bayesian model averaging.", "method": "Reinterpreting existing approaches via empirical Bayes and proposing OBS for log-score optimization, connecting it to portfolio selection.", "result": "Established a novel connection between OBS and portfolio selection, clarified its relationship with online BMA, and identified scenarios where OBS performs better.", "conclusion": "Online Bayesian Stacking is a promising approach for adaptive Bayesian model combination, offering advantages over traditional methods in certain contexts."}}
{"id": "2505.14896", "pdf": "https://arxiv.org/pdf/2505.14896", "abs": "https://arxiv.org/abs/2505.14896", "authors": ["Hootan Mahmoodiyan", "Maryam Ahang", "Mostafa Abbasi", "Homayoun Najjaran"], "title": "Feature-Weighted MMD-CORAL for Domain Adaptation in Power Transformer Fault Diagnosis", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring the reliable operation of power transformers is critical to grid\nstability. Dissolved Gas Analysis (DGA) is widely used for fault diagnosis, but\ntraditional methods rely on heuristic rules, which may lead to inconsistent\nresults. Machine learning (ML)-based approaches have improved diagnostic\naccuracy; however, power transformers operate under varying conditions, and\ndifferences in transformer type, environmental factors, and operational\nsettings create distribution shifts in diagnostic data. Consequently, direct\nmodel transfer between transformers often fails, making techniques for domain\nadaptation a necessity. To tackle this issue, this work proposes a\nfeature-weighted domain adaptation technique that combines Maximum Mean\nDiscrepancy (MMD) and Correlation Alignment (CORAL) with feature-specific\nweighting (MCW). Kolmogorov-Smirnov (K-S) statistics are used to assign\nadaptable weights, prioritizing features with larger distributional\ndiscrepancies and thereby improving source and target domain alignment.\nExperimental evaluations on datasets for power transformers demonstrate the\neffectiveness of the proposed method, which achieves a 7.9% improvement over\nFine-Tuning and a 2.2% improvement over MMD-CORAL (MC). Furthermore, it\noutperforms both techniques across various training sample sizes, confirming\nits robustness for domain adaptation.", "AI": {"tldr": "This study introduces a feature-weighted domain adaptation technique combining MMD, CORAL, and feature-specific weighting to improve fault diagnosis accuracy of power transformers.", "motivation": "To address inconsistent results from traditional DGA methods due to varying conditions and distribution shifts in diagnostic data.", "method": "Proposes a MCW method using K-S statistics to assign adaptable weights to features with larger distributional discrepancies.", "result": "Improves diagnostic accuracy, achieving a 7.9% improvement over Fine-Tuning and a 2.2% improvement over MMD-CORAL.", "conclusion": "The proposed method demonstrates effectiveness and robustness in domain adaptation for power transformer fault diagnosis."}}
{"id": "2505.15643", "pdf": "https://arxiv.org/pdf/2505.15643", "abs": "https://arxiv.org/abs/2505.15643", "authors": ["Lan V. Truong"], "title": "Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": "22 pages", "summary": "We study the problem of best-arm identification in stochastic multi-armed\nbandits under the fixed-confidence setting, with a particular focus on\ninstances that admit multiple optimal arms. While the Track-and-Stop algorithm\nof Garivier and Kaufmann (2016) is widely conjectured to be instance-optimal,\nits performance in the presence of multiple optima has remained insufficiently\nunderstood. In this work, we revisit the Track-and-Stop strategy and propose a\nmodified stopping rule that ensures instance-optimality even when the set of\noptimal arms is not a singleton. Our analysis introduces a new\ninformation-theoretic lower bound that explicitly accounts for multiple optimal\narms, and we demonstrate that our stopping rule tightly matches this bound.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bbe\u7f6e\u4e0b\u7684\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4e2d\u6700\u4f18\u81c2\u8bc6\u522b\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5b58\u5728\u591a\u4e2a\u6700\u4f18\u81c2\u7684\u60c5\u51b5\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u505c\u6b62\u89c4\u5219\u4ee5\u786e\u4fdd\u5b9e\u4f8b\u6700\u4f18\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u4fe1\u606f\u8bba\u4e0b\u754c\u6765\u660e\u786e\u8003\u8651\u591a\u4e2a\u6700\u4f18\u81c2\u3002", "motivation": "\u5e7f\u6cdb\u8ba4\u4e3aGarivier\u548cKaufmann\uff082016\uff09\u63d0\u51fa\u7684Track-and-Stop\u7b97\u6cd5\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\uff0c\u4f46\u5728\u5b58\u5728\u591a\u4e2a\u6700\u4f18\u89e3\u7684\u60c5\u51b5\u4e0b\u5176\u8868\u73b0\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6Track-and-Stop\u7b56\u7565\u5e76\u63d0\u51fa\u4e00\u4e2a\u4fee\u6539\u540e\u7684\u505c\u6b62\u89c4\u5219\u3002", "result": "\u63d0\u51fa\u7684\u65b0\u505c\u6b62\u89c4\u5219\u786e\u4fdd\u4e86\u5373\u4f7f\u5728\u6700\u4f18\u81c2\u4e0d\u662f\u5355\u4e00\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u5b9e\u4f8b\u6700\u4f18\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u5206\u6790\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u5e76\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u505c\u6b62\u89c4\u5219\u7d27\u5bc6\u5339\u914d\u8fd9\u4e2a\u754c\u9650\u3002"}}
{"id": "2505.14897", "pdf": "https://arxiv.org/pdf/2505.14897", "abs": "https://arxiv.org/abs/2505.14897", "authors": ["Ali Mohajerzarrinkelk", "Maryam Ahang", "Mehran Zoravar", "Mostafa Abbasi", "Homayoun Najjaran"], "title": "Multi-Channel Swin Transformer Framework for Bearing Remaining Useful Life Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Precise estimation of the Remaining Useful Life (RUL) of rolling bearings is\nan important consideration to avoid unexpected failures, reduce downtime, and\npromote safety and efficiency in industrial systems. Complications in\ndegradation trends, noise presence, and the necessity to detect faults in\nadvance make estimation of RUL a challenging task. This paper introduces a\nnovel framework that combines wavelet-based denoising method, Wavelet Packet\nDecomposition (WPD), and a customized multi-channel Swin Transformer model\n(MCSFormer) to address these problems. With attention mechanisms incorporated\nfor feature fusion, the model is designed to learn global and local degradation\npatterns utilizing hierarchical representations for enhancing predictive\nperformance. Additionally, a customized loss function is developed as a key\ndistinction of this work to differentiate between early and late predictions,\nprioritizing accurate early detection and minimizing the high operation risks\nof late predictions. The proposed model was evaluated with the PRONOSTIA\ndataset using three experiments. Intra-condition experiments demonstrated that\nMCSFormer outperformed state-of-the-art models, including the Adaptive\nTransformer, MDAN, and CNN-SRU, achieving 41%, 64%, and 69% lower MAE on\naverage across different operating conditions, respectively. In terms of\ncross-condition testing, it achieved superior generalization under varying\noperating conditions compared to the adapted ViT and Swin Transformer. Lastly,\nthe custom loss function effectively reduced late predictions, as evidenced in\na 6.3% improvement in the scoring metric while maintaining competitive overall\nperformance. The model's robust noise resistance, generalization capability,\nand focus on safety make MCSFormer a trustworthy and effective predictive\nmaintenance tool in industrial applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u7cbe\u786e\u4f30\u8ba1\u6eda\u52a8\u8f74\u627f\u7684\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u79cd\u6280\u672f\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7cbe\u786e\u4f30\u8ba1\u6eda\u52a8\u8f74\u627f\u7684\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u5bf9\u4e8e\u907f\u514d\u610f\u5916\u6545\u969c\u3001\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u3001\u63d0\u9ad8\u5de5\u4e1a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7ed3\u5408\u5c0f\u6ce2\u53bb\u566a\u65b9\u6cd5\u3001\u5c0f\u6ce2\u5305\u5206\u89e3\u548c\u5b9a\u5236\u591a\u901a\u9053Swin\u53d8\u6362\u6a21\u578b(MCSFormer)\uff0c\u5e76\u91c7\u7528\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u7279\u5f81\u878d\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMCSFormer\u5728\u4e0d\u540c\u64cd\u4f5c\u6761\u4ef6\u4e0b\u6bd4\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u4e14\u81ea\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u6709\u6548\u5730\u51cf\u5c11\u4e86\u665a\u671f\u9884\u6d4b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2505.14943", "pdf": "https://arxiv.org/pdf/2505.14943", "abs": "https://arxiv.org/abs/2505.14943", "authors": ["Ross Nordby"], "title": "Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To help evaluate and understand the latent capabilities of language models,\nthis paper introduces an approach using optimized input embeddings, or 'soft\nprompts,' as a metric of conditional distance between a model and a target\nbehavior. The technique aims to facilitate latent capability discovery as a\npart of automated red teaming/evaluation suites and to provide quantitative\nfeedback about the accessibility of potentially concerning behaviors in a way\nthat may scale to powerful future models, including those which may otherwise\nbe capable of deceptive alignment. An evaluation framework using soft prompts\nis demonstrated in natural language, chess, and pathfinding, and the technique\nis extended with generalized conditional soft prompts to aid in constructing\ntask evaluations.", "AI": {"tldr": "This paper introduces an approach using optimized input embeddings ('soft prompts') to assess the latent capabilities of language models.", "motivation": "To help evaluate and understand the latent capabilities of language models.", "method": "Using optimized input embeddings ('soft prompts') as a metric of conditional distance between a model and a target behavior.", "result": "The technique was demonstrated in natural language, chess, and pathfinding tasks.", "conclusion": "The technique can facilitate latent capability discovery and provide quantitative feedback about the accessibility of potentially concerning behaviors."}}
{"id": "2505.15721", "pdf": "https://arxiv.org/pdf/2505.15721", "abs": "https://arxiv.org/abs/2505.15721", "authors": ["Coby Penso", "Bar Mahpud", "Jacob Goldberger", "Or Sheffet"], "title": "Privacy-Preserving Conformal Prediction Under Local Differential Privacy", "categories": ["cs.LG", "stat.ML"], "comment": "Preprint. Under review", "summary": "Conformal prediction (CP) provides sets of candidate classes with a\nguaranteed probability of containing the true class. However, it typically\nrelies on a calibration set with clean labels. We address privacy-sensitive\nscenarios where the aggregator is untrusted and can only access a perturbed\nversion of the true labels. We propose two complementary approaches under local\ndifferential privacy (LDP). In the first approach, users do not access the\nmodel but instead provide their input features and a perturbed label using a\nk-ary randomized response. In the second approach, which enforces stricter\nprivacy constraints, users add noise to their conformity score by binary search\nresponse. This method requires access to the classification model but preserves\nboth data and label privacy. Both approaches compute the conformal threshold\ndirectly from noisy data without accessing the true labels. We prove\nfinite-sample coverage guarantees and demonstrate robust coverage even under\nsevere randomization. This approach unifies strong local privacy with\npredictive uncertainty control, making it well-suited for sensitive\napplications such as medical imaging or large language model queries,\nregardless of whether users can (or are willing to) compute their own scores.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u5728\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5728\u4e0d\u53ef\u4fe1\u805a\u5408\u5668\u60c5\u51b5\u4e0b\u5e26\u6709\u5e72\u51c0\u6807\u7b7e\u6821\u51c6\u96c6\u7684\u786e\u8ba4\u9884\u6d4b\u95ee\u9898\u3002", "motivation": "\u5728\u4e0d\u53ef\u4fe1\u7684\u805a\u5408\u5668\u53ea\u80fd\u8bbf\u95ee\u771f\u5b9e\u6807\u7b7e\u7684\u6270\u52a8\u7248\u672c\u7684\u9690\u79c1\u654f\u611f\u573a\u666f\u4e0b\u6539\u8fdb\u786e\u8ba4\u9884\u6d4b\u3002", "method": "1. \u7528\u6237\u901a\u8fc7k\u5143\u968f\u673a\u54cd\u5e94\u63d0\u4f9b\u8f93\u5165\u7279\u5f81\u548c\u6270\u52a8\u6807\u7b7e\uff1b2. \u7528\u6237\u901a\u8fc7\u4e8c\u5206\u641c\u7d22\u54cd\u5e94\u5411\u5176\u7b26\u5408\u6027\u5206\u6570\u6dfb\u52a0\u566a\u58f0\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u76f4\u63a5\u4ece\u566a\u58f0\u6570\u636e\u8ba1\u7b97\u786e\u8ba4\u9608\u503c\u4e14\u4e0d\u8bbf\u95ee\u771f\u5b9e\u6807\u7b7e\uff0c\u8bc1\u660e\u4e86\u6709\u9650\u6837\u672c\u8986\u76d6\u7387\u4fdd\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u5373\u4f7f\u5728\u4e25\u91cd\u968f\u673a\u5316\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7a33\u5065\u7684\u8986\u76d6\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7edf\u4e00\u4e86\u5f3a\u672c\u5730\u9690\u79c1\u4e0e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u63a7\u5236\uff0c\u9002\u7528\u4e8e\u654f\u611f\u5e94\u7528\u5982\u533b\u5b66\u6210\u50cf\u6216\u5927\u578b\u8bed\u8a00\u6a21\u578b\u67e5\u8be2\u3002"}}
{"id": "2505.14903", "pdf": "https://arxiv.org/pdf/2505.14903", "abs": "https://arxiv.org/abs/2505.14903", "authors": ["Regol Florence", "Schwinn Leo", "Sprague Kyle", "Coates Mark", "Markovich Thomas"], "title": "When to retrain a machine learning model", "categories": ["cs.LG"], "comment": null, "summary": "A significant challenge in maintaining real-world machine learning models is\nresponding to the continuous and unpredictable evolution of data. Most\npractitioners are faced with the difficult question: when should I retrain or\nupdate my machine learning model? This seemingly straightforward problem is\nparticularly challenging for three reasons: 1) decisions must be made based on\nvery limited information - we usually have access to only a few examples, 2)\nthe nature, extent, and impact of the distribution shift are unknown, and 3) it\ninvolves specifying a cost ratio between retraining and poor performance, which\ncan be hard to characterize. Existing works address certain aspects of this\nproblem, but none offer a comprehensive solution. Distribution shift detection\nfalls short as it cannot account for the cost trade-off; the scarcity of the\ndata, paired with its unusual structure, makes it a poor fit for existing\noffline reinforcement learning methods, and the online learning formulation\noverlooks key practical considerations. To address this, we present a\nprincipled formulation of the retraining problem and propose an\nuncertainty-based method that makes decisions by continually forecasting the\nevolution of model performance evaluated with a bounded metric. Our experiments\naddressing classification tasks show that the method consistently outperforms\nexisting baselines on 7 datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u6765\u51b3\u5b9a\u4f55\u65f6\u91cd\u65b0\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u57287\u4e2a\u6570\u636e\u96c6\u7684\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u7684\u6301\u7eed\u548c\u4e0d\u53ef\u9884\u6d4b\u7684\u6570\u636e\u6f14\u53d8\u6311\u6218\uff0c\u89e3\u51b3\u4f55\u65f6\u91cd\u65b0\u8bad\u7ec3\u6216\u66f4\u65b0\u6a21\u578b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u5e76\u4e0d\u65ad\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u6307\u6807\u53d8\u5316\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u5206\u7c7b\u4efb\u52a1\u65f6\uff0c\u57287\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u65b0\u8bad\u7ec3\u95ee\u9898\u7684\u539f\u5219\u6027\u516c\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5168\u9762\u89e3\u51b3\u7684\u95ee\u9898\u3002"}}
{"id": "2505.14964", "pdf": "https://arxiv.org/pdf/2505.14964", "abs": "https://arxiv.org/abs/2505.14964", "authors": ["Dave Cook", "Tim Klawa"], "title": "The Achilles Heel of AI: Fundamentals of Risk-Aware Training Data for High-Consequence Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "AI systems in high-consequence domains such as defense, intelligence, and\ndisaster response must detect rare, high-impact events while operating under\ntight resource constraints. Traditional annotation strategies that prioritize\nlabel volume over informational value introduce redundancy and noise, limiting\nmodel generalization. This paper introduces smart-sizing, a training data\nstrategy that emphasizes label diversity, model-guided selection, and marginal\nutility-based stopping. We implement this through Adaptive Label Optimization\n(ALO), combining pre-labeling triage, annotator disagreement analysis, and\niterative feedback to prioritize labels that meaningfully improve model\nperformance. Experiments show that models trained on 20 to 40 percent of\ncurated data can match or exceed full-data baselines, particularly in\nrare-class recall and edge-case generalization. We also demonstrate how latent\nlabeling errors embedded in training and validation sets can distort\nevaluation, underscoring the need for embedded audit tools and\nperformance-aware governance. Smart-sizing reframes annotation as a\nfeedback-driven process aligned with mission outcomes, enabling more robust\nmodels with fewer labels and supporting efficient AI development pipelines for\nfrontier models and operational systems.", "AI": {"tldr": "This paper presents smart-sizing, a training data strategy focusing on label diversity and model-guided selection, which allows models trained on less data to perform as well as those trained on full datasets, especially in rare-event detection and edge-case generalization.", "motivation": "To improve model generalization in AI systems used in high-consequence domains by optimizing the use of limited resources and reducing redundancy and noise in traditional annotation strategies.", "method": "Introducing smart-sizing, which includes Adaptive Label Optimization (ALO) for prioritizing meaningful labels, using pre-labeling triage, annotator disagreement analysis, and iterative feedback.", "result": "Models trained on 20-40% of curated data can match or exceed full-data baselines in rare-class recall and edge-case generalization, and latent labeling errors can distort evaluation.", "conclusion": "Smart-sizing optimizes annotation processes to align with mission outcomes, enabling robust models with fewer labels, and supports efficient AI development pipelines."}}
{"id": "2505.15808", "pdf": "https://arxiv.org/pdf/2505.15808", "abs": "https://arxiv.org/abs/2505.15808", "authors": ["Carlos Rodriguez-Pardo", "Leonardo Chiani", "Emanuele Borgonovo", "Massimo Tavoni"], "title": "Neural Conditional Transport Maps", "categories": ["cs.LG", "cs.AI", "math.PR", "stat.AP", "stat.ML", "49Q22 (Primary) 68T07 (Secondary)", "I.5.1; I.2.0; G.3"], "comment": "Under Review. Supplementary material included in the pdf", "summary": "We present a neural framework for learning conditional optimal transport (OT)\nmaps between probability distributions. Our approach introduces a conditioning\nmechanism capable of processing both categorical and continuous conditioning\nvariables simultaneously. At the core of our method lies a hypernetwork that\ngenerates transport layer parameters based on these inputs, creating adaptive\nmappings that outperform simpler conditioning methods. Comprehensive ablation\nstudies demonstrate the superior performance of our method over baseline\nconfigurations. Furthermore, we showcase an application to global sensitivity\nanalysis, offering high performance in computing OT-based sensitivity indices.\nThis work advances the state-of-the-art in conditional optimal transport,\nenabling broader application of optimal transport principles to complex,\nhigh-dimensional domains such as generative modeling and black-box model\nexplainability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u6846\u67b6\u6765\u5b66\u4e60\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u6761\u4ef6\u6700\u4f18\u4f20\u8f93\u6620\u5c04\uff0c\u5e76\u5f15\u5165\u4e86\u5904\u7406\u5206\u7c7b\u548c\u8fde\u7eed\u6761\u4ef6\u53d8\u91cf\u7684\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u5168\u5c40\u7075\u654f\u5ea6\u5206\u6790\u4e2d\u5c55\u793a\u4e86\u9ad8\u6027\u80fd\u3002", "motivation": "\u6269\u5c55\u6700\u4f18\u4f20\u8f93\u539f\u5219\u5728\u590d\u6742\u9ad8\u7ef4\u9886\u57df\u7684\u5e94\u7528\uff0c\u5982\u751f\u6210\u5efa\u6a21\u548c\u9ed1\u76d2\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u6838\u5fc3\u662f\u4e00\u4e2a\u8d85\u7f51\u7edc\uff0c\u6839\u636e\u8f93\u5165\u751f\u6210\u4f20\u8f93\u5c42\u53c2\u6570\uff0c\u4ece\u800c\u521b\u5efa\u81ea\u9002\u5e94\u6620\u5c04\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u914d\u7f6e\uff0c\u5e76\u5728\u8ba1\u7b97\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u7075\u654f\u5ea6\u6307\u6570\u65f6\u8868\u73b0\u51fa\u9ad8\u6548\u7387\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u63a8\u8fdb\u4e86\u6761\u4ef6\u6700\u4f18\u4f20\u8f93\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002"}}
{"id": "2505.14919", "pdf": "https://arxiv.org/pdf/2505.14919", "abs": "https://arxiv.org/abs/2505.14919", "authors": ["Frederik Wenkel", "Wilson Tu", "Cassandra Masschelein", "Hamed Shirzad", "Cian Eastwood", "Shawn T. Whitfield", "Ihab Bendidi", "Craig Russell", "Liam Hodgson", "Yassir El Mesbahi", "Jiarui Ding", "Marta M. Fay", "Berton Earnshaw", "Emmanuel Noutahi", "Alisandra K. Denton"], "title": "TxPert: Leveraging Biochemical Relationships for Out-of-Distribution Transcriptomic Perturbation Prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurately predicting cellular responses to genetic perturbations is\nessential for understanding disease mechanisms and designing effective\ntherapies. Yet exhaustively exploring the space of possible perturbations\n(e.g., multi-gene perturbations or across tissues and cell types) is\nprohibitively expensive, motivating methods that can generalize to unseen\nconditions. In this work, we explore how knowledge graphs of gene-gene\nrelationships can improve out-of-distribution (OOD) prediction across three\nchallenging settings: unseen single perturbations; unseen double perturbations;\nand unseen cell lines. In particular, we present: (i) TxPert, a new\nstate-of-the-art method that leverages multiple biological knowledge networks\nto predict transcriptional responses under OOD scenarios; (ii) an in-depth\nanalysis demonstrating the impact of graphs, model architecture, and data on\nperformance; and (iii) an expanded benchmarking framework that strengthens\nevaluation standards for perturbation modeling.", "AI": {"tldr": "\u63d0\u51faTxPert\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u4e2a\u751f\u7269\u77e5\u8bc6\u7f51\u7edc\uff0c\u5728\u672a\u89c1\u6761\u4ef6\u4e0b\u9884\u6d4b\u8f6c\u5f55\u53cd\u5e94\uff0c\u5bf9\u56fe\u8c31\u3001\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u5f71\u54cd\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u5e76\u6269\u5c55\u4e86\u6270\u52a8\u5efa\u6a21\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u7ec6\u80de\u5bf9\u57fa\u56e0\u6270\u52a8\u7684\u54cd\u5e94\u5bf9\u4e8e\u7406\u89e3\u75be\u75c5\u673a\u5236\u548c\u8bbe\u8ba1\u6709\u6548\u7597\u6cd5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7a77\u5c3d\u6240\u6709\u53ef\u80fd\u7684\u6270\u52a8\uff08\u5982\u591a\u57fa\u56e0\u6270\u52a8\u6216\u8de8\u7ec4\u7ec7\u548c\u7ec6\u80de\u7c7b\u578b\uff09\u7684\u63a2\u7d22\u6210\u672c\u8fc7\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u63a8\u5e7f\u5230\u672a\u77e5\u6761\u4ef6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86TxPert\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u591a\u4e2a\u751f\u7269\u77e5\u8bc6\u7f51\u7edc\u6765\u9884\u6d4b\u672a\u89c1\u6761\u4ef6\u4e0b\u7684\u8f6c\u5f55\u53cd\u5e94\u3002", "result": "\u5728\u4e09\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1a\u672a\u89c1\u8fc7\u7684\u5355\u6270\u52a8\uff1b\u672a\u89c1\u8fc7\u7684\u53cc\u6270\u52a8\uff1b\u548c\u672a\u89c1\u8fc7\u7684\u7ec6\u80de\u7cfb\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u57fa\u56e0\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u5982\u4f55\u6539\u5584\u5206\u5e03\u5916\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u6df1\u5165\u5206\u6790\u548c\u6269\u5c55\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u63d0\u9ad8\u4e86\u5bf9\u6270\u52a8\u5efa\u6a21\u7684\u8bc4\u4ef7\u6807\u51c6\u3002"}}
{"id": "2505.14967", "pdf": "https://arxiv.org/pdf/2505.14967", "abs": "https://arxiv.org/abs/2505.14967", "authors": ["Fangzhen Zhao", "Chenyi Zhang", "Naipeng Dong", "Ming Li", "Jinxiao Shan"], "title": "Anomaly Detection Based on Critical Paths for Deep Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages in ACM journal latex format", "summary": "Deep neural networks (DNNs) are notoriously hard to understand and difficult\nto defend. Extracting representative paths (including the neuron activation\nvalues and the connections between neurons) from DNNs using software\nengineering approaches has recently shown to be a promising approach in\ninterpreting the decision making process of blackbox DNNs, as the extracted\npaths are often effective in capturing essential features. With this in mind,\nthis work investigates a novel approach that extracts critical paths from DNNs\nand subsequently applies the extracted paths for the anomaly detection task,\nbased on the observation that outliers and adversarial inputs do not usually\ninduce the same activation pattern on those paths as normal (in-distribution)\ninputs.\n  In our approach, we first identify critical detection paths via genetic\nevolution and mutation. Since different paths in a DNN often capture different\nfeatures for the same target class, we ensemble detection results from multiple\npaths by integrating random subspace sampling and a voting mechanism. Compared\nwith state-of-the-art methods, our experimental results suggest that our method\nnot only outperforms them, but it is also suitable for the detection of a broad\nrange of anomaly types with high accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u6f14\u5316\u548c\u7a81\u53d8\u7684\u65b9\u6cd5\u6765\u4ece\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u63d0\u53d6\u5173\u952e\u8def\u5f84\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u8def\u5f84\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u8def\u5f84\u4e0a\u96c6\u6210\u968f\u673a\u5b50\u7a7a\u95f4\u91c7\u6837\u548c\u6295\u7968\u673a\u5236\u6765\u7efc\u5408\u68c0\u6d4b\u7ed3\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u800c\u4e14\u80fd\u4ee5\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u591a\u79cd\u7c7b\u578b\u7684\u5f02\u5e38\u3002", "motivation": "\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u7684\u51b3\u7b56\u8fc7\u7a0b\u4ee5\u53ca\u9632\u5fa1DNN\u7684\u56f0\u96be\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u627e\u65b0\u7684\u89e3\u91ca\u6027\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u9057\u4f20\u6f14\u5316\u548c\u7a81\u53d8\u8bc6\u522b\u5173\u952e\u68c0\u6d4b\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u5b50\u7a7a\u95f4\u91c7\u6837\u548c\u6295\u7968\u673a\u5236\u6574\u5408\u591a\u4e2a\u8def\u5f84\u7684\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u7c7b\u578b\u7684\u5f02\u5e38\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u8def\u5f84\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5c55\u793a\u4e86\u826f\u597d\u7684\u6027\u80fd\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76DNN\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.14933", "pdf": "https://arxiv.org/pdf/2505.14933", "abs": "https://arxiv.org/abs/2505.14933", "authors": ["Xuefeng Du"], "title": "Foundations of Unknown-aware Machine Learning", "categories": ["cs.LG"], "comment": "PhD Dissertation", "summary": "Ensuring the reliability and safety of machine learning models in open-world\ndeployment is a central challenge in AI safety. This thesis develops both\nalgorithmic and theoretical foundations to address key reliability issues\narising from distributional uncertainty and unknown classes, from standard\nneural networks to modern foundation models like large language models (LLMs).\n  Traditional learning paradigms, such as empirical risk minimization (ERM),\nassume no distribution shift between training and inference, often leading to\noverconfident predictions on out-of-distribution (OOD) inputs. This thesis\nintroduces novel frameworks that jointly optimize for in-distribution accuracy\nand reliability to unseen data. A core contribution is the development of an\nunknown-aware learning framework that enables models to recognize and handle\nnovel inputs without labeled OOD data.\n  We propose new outlier synthesis methods, VOS, NPOS, and DREAM-OOD, to\ngenerate informative unknowns during training. Building on this, we present\nSAL, a theoretical and algorithmic framework that leverages unlabeled\nin-the-wild data to enhance OOD detection under realistic deployment\nconditions. These methods demonstrate that abundant unlabeled data can be\nharnessed to recognize and adapt to unforeseen inputs, providing formal\nreliability guarantees.\n  The thesis also extends reliable learning to foundation models. We develop\nHaloScope for hallucination detection in LLMs, MLLMGuard for defending against\nmalicious prompts in multimodal models, and data cleaning methods to denoise\nhuman feedback used for better alignment. These tools target failure modes that\nthreaten the safety of large-scale models in deployment.\n  Overall, these contributions promote unknown-aware learning as a new\nparadigm, and we hope it can advance the reliability of AI systems with minimal\nhuman efforts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u7b97\u6cd5\u548c\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u4ece\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u5230\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u53ca\u672a\u77e5\u7c7b\u522b\u95ee\u9898\uff0c\u4fc3\u8fdb\u672a\u77e5\u611f\u77e5\u5b66\u4e60\u4f5c\u4e3a\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\u7684\u53d1\u5c55\u3002", "motivation": "\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u662f\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u7684\u6838\u5fc3\u6311\u6218\u3002\u4f20\u7edf\u5b66\u4e60\u8303\u5f0f\u5047\u8bbe\u8bad\u7ec3\u548c\u63a8\u7406\u4e4b\u95f4\u6ca1\u6709\u5206\u5e03\u504f\u79fb\uff0c\u8fd9\u901a\u5e38\u4f1a\u5bfc\u81f4\u5bf9\u5206\u5e03\u5916\u8f93\u5165\u7684\u8fc7\u4e8e\u81ea\u4fe1\u7684\u9884\u6d4b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u5f02\u5e38\u5408\u6210\u65b9\u6cd5\uff08VOS\u3001NPOS\u548cDREAM-OOD\uff09\u6765\u751f\u6210\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6709\u7528\u672a\u77e5\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u4e86SAL\u7406\u8bba\u548c\u7b97\u6cd5\u6846\u67b6\uff0c\u5229\u7528\u91ce\u5916\u672a\u6807\u8bb0\u6570\u636e\u5728\u73b0\u5b9e\u90e8\u7f72\u6761\u4ef6\u4e0b\u589e\u5f3aOOD\u68c0\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u6269\u5c55\u4e86\u53ef\u9760\u5b66\u4e60\u5230\u57fa\u7840\u6a21\u578b\uff0c\u5305\u62ec\u5f00\u53d1\u4e86HaloScope\u7528\u4e8e\u68c0\u6d4bLLMs\u4e2d\u7684\u5e7b\u89c9\uff0cMLLMGuard\u7528\u4e8e\u9632\u5fa1\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u6076\u610f\u63d0\u793a\uff0c\u4ee5\u53ca\u6570\u636e\u6e05\u7406\u65b9\u6cd5\u4ee5\u53bb\u566a\u4eba\u7c7b\u53cd\u9988\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u63d0\u9ad8\u6a21\u578b\u5bf9\u672a\u77e5\u8f93\u5165\u7684\u8bc6\u522b\u548c\u9002\u5e94\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u53ef\u9760\u6027\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u5de5\u5177\u89e3\u51b3\u4e86\u5a01\u80c1\u5927\u89c4\u6a21\u6a21\u578b\u90e8\u7f72\u5b89\u5168\u6027\u7684\u5931\u6548\u6a21\u5f0f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u672a\u77e5\u611f\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u548c\u5904\u7406\u65b0\u9896\u7684\u8f93\u5165\uff0c\u800c\u65e0\u9700\u6807\u8bb0\u7684OOD\u6570\u636e\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u9488\u5bf9\u57fa\u7840\u6a21\u578b\u7684\u53ef\u9760\u6027\u5b66\u4e60\u6269\u5c55\uff0c\u5305\u62ecLLMs\u4e2d\u7684\u5e7b\u89c9\u68c0\u6d4b\u3001\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u6076\u610f\u63d0\u793a\u9632\u5fa1\u4ee5\u53ca\u7528\u4e8e\u66f4\u597d\u5bf9\u9f50\u7684\u4eba\u7c7b\u53cd\u9988\u53bb\u566a\u7684\u6570\u636e\u6e05\u7406\u65b9\u6cd5\u3002\u8fd9\u4e9b\u8d21\u732e\u4fc3\u8fdb\u4e86\u672a\u77e5\u611f\u77e5\u5b66\u4e60\u4f5c\u4e3a\u4e00\u79cd\u65b0\u8303\u5f0f\u7684\u63a8\u5e7f\uff0c\u5e76\u5e0c\u671b\u5b83\u80fd\u4ee5\u6700\u5c0f\u7684\u4eba\u529b\u6295\u5165\u63a8\u8fdbAI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2505.14969", "pdf": "https://arxiv.org/pdf/2505.14969", "abs": "https://arxiv.org/abs/2505.14969", "authors": ["Yangchao Wu", "Zongyue Qin", "Alex Wong", "Stefano Soatto"], "title": "STree: Speculative Tree Decoding for Hybrid State-Space Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding is a technique to leverage hardware concurrency to\nimprove the efficiency of large-scale autoregressive (AR) Transformer models by\nenabling multiple steps of token generation in a single forward pass.\nState-space models (SSMs) are already more efficient than AR Transformers,\nsince their state summarizes all past data with no need to cache or re-process\ntokens in the sliding window context. However, their state can also comprise\nthousands of tokens; so, speculative decoding has recently been extended to\nSSMs. Existing approaches, however, do not leverage the tree-based verification\nmethods, since current SSMs lack the means to compute a token tree efficiently.\nWe propose the first scalable algorithm to perform tree-based speculative\ndecoding in state-space models (SSMs) and hybrid architectures of SSMs and\nTransformer layers. We exploit the structure of accumulated state transition\nmatrices to facilitate tree-based speculative decoding with minimal overhead to\ncurrent SSM state update implementations. With the algorithm, we describe a\nhardware-aware implementation that improves naive application of AR Transformer\ntree-based speculative decoding methods to SSMs. Furthermore, we outperform\nvanilla speculative decoding with SSMs even with a baseline drafting model and\ntree structure on three different benchmarks, opening up opportunities for\nfurther speed up with SSM and hybrid model inference. Code will be released\nupon paper acceptance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6811\u7684\u63a8\u6d4b\u89e3\u7801\u7b97\u6cd5\u7528\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSMs)\u548c\u6df7\u5408\u67b6\u6784\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63d0\u9ad8\u5927\u89c4\u6a21\u81ea\u56de\u5f52Transformer\u6a21\u578b\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u786c\u4ef6\u5e76\u53d1\u6027\u53ca\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6811\u7684\u63a8\u6d4b\u89e3\u7801\u7b97\u6cd5\uff0c\u5229\u7528\u7d2f\u79ef\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u7ed3\u6784\u6765\u6700\u5c0f\u5316\u5bf9\u5f53\u524dSSM\u72b6\u6001\u66f4\u65b0\u5b9e\u73b0\u7684\u5f00\u9500\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u7b80\u5355\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u4e3aSSM\u548c\u6df7\u5408\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u52a0\u901f\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u53ca\u5176\u6df7\u5408\u67b6\u6784\u7684\u63a8\u6d4b\u89e3\u7801\u6548\u7387\u3002"}}
{"id": "2505.14975", "pdf": "https://arxiv.org/pdf/2505.14975", "abs": "https://arxiv.org/abs/2505.14975", "authors": ["John L. Zhou", "Jonathan C. Kao"], "title": "Flattening Hierarchies with Policy Bootstrapping", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Offline goal-conditioned reinforcement learning (GCRL) is a promising\napproach for pretraining generalist policies on large datasets of reward-free\ntrajectories, akin to the self-supervised objectives used to train foundation\nmodels for computer vision and natural language processing. However, scaling\nGCRL to longer horizons remains challenging due to the combination of sparse\nrewards and discounting, which obscures the comparative advantages of primitive\nactions with respect to distant goals. Hierarchical RL methods achieve strong\nempirical results on long-horizon goal-reaching tasks, but their reliance on\nmodular, timescale-specific policies and subgoal generation introduces\nsignificant additional complexity and hinders scaling to high-dimensional goal\nspaces. In this work, we introduce an algorithm to train a flat\n(non-hierarchical) goal-conditioned policy by bootstrapping on\nsubgoal-conditioned policies with advantage-weighted importance sampling. Our\napproach eliminates the need for a generative model over the (sub)goal space,\nwhich we find is key for scaling to high-dimensional control in large state\nspaces. We further show that existing hierarchical and bootstrapping-based\napproaches correspond to specific design choices within our derivation. Across\na comprehensive suite of state- and pixel-based locomotion and manipulation\nbenchmarks, our method matches or surpasses state-of-the-art offline GCRL\nalgorithms and scales to complex, long-horizon tasks where prior approaches\nfail.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u4f18\u52bf\u52a0\u6743\u91cd\u8981\u6027\u91c7\u6837\u5229\u7528\u5b50\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u6765\u8bad\u7ec3\u5e73\u6ed1\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u7684\u7b97\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u5e7f\u6cdb\u7684\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u79bb\u7ebfGCRL\u7b97\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u5e76\u6269\u5c55\u5230\u590d\u6742\u7684\u957f\u65f6\u5e8f\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfGCRL\u5728\u957f\u65f6\u5e8f\u4efb\u52a1\u4e2d\u7684\u6311\u6218\u4ee5\u53ca\u73b0\u6709\u5206\u5c42\u65b9\u6cd5\u7684\u590d\u6742\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u901a\u8fc7\u4f18\u52bf\u52a0\u6743\u91cd\u8981\u6027\u91c7\u6837\u4ece\u5b50\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u4e2d\u5b66\u4e60\u5e73\u6ed1\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u751f\u6210\u5b50\u76ee\u6807\u7a7a\u95f4\u7684\u751f\u6210\u6a21\u578b\u9700\u6c42\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u72b6\u6001\u548c\u50cf\u7d20\u7ea7\u8fd0\u52a8\u548c\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u957f\u65f6\u5e8f\u4efb\u52a1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u6269\u5c55\u79bb\u7ebfGCRL\u5230\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u548c\u957f\u65f6\u5e8f\u4efb\u52a1\uff0c\u540c\u65f6\u7b80\u5316\u4e86\u5206\u5c42\u65b9\u6cd5\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2505.14945", "pdf": "https://arxiv.org/pdf/2505.14945", "abs": "https://arxiv.org/abs/2505.14945", "authors": ["O. Deniz Kose", "Gonzalo Mateos", "Yanning Shen"], "title": "Unlearning Algorithmic Biases over Graphs", "categories": ["cs.LG"], "comment": null, "summary": "The growing enforcement of the right to be forgotten regulations has\npropelled recent advances in certified (graph) unlearning strategies to comply\nwith data removal requests from deployed machine learning (ML) models.\nMotivated by the well-documented bias amplification predicament inherent to\ngraph data, here we take a fresh look at graph unlearning and leverage it as a\nbias mitigation tool. Given a pre-trained graph ML model, we develop a\ntraining-free unlearning procedure that offers certifiable bias mitigation via\na single-step Newton update on the model weights. This way, we contribute a\ncomputationally lightweight alternative to the prevalent training- and\noptimization-based fairness enhancement approaches, with quantifiable\nperformance guarantees. We first develop a novel fairness-aware nodal feature\nunlearning strategy along with refined certified unlearning bounds for this\nsetting, whose impact extends beyond the realm of graph unlearning. We then\ndesign structural unlearning methods endowed with principled selection\nmechanisms over nodes and edges informed by rigorous bias analyses. Unlearning\nthese judiciously selected elements can mitigate algorithmic biases with\nminimal impact on downstream utility (e.g., node classification accuracy).\nExperimental results over real networks corroborate the bias mitigation\nefficacy of our unlearning strategies, and delineate markedly favorable\nutility-complexity trade-offs relative to retraining from scratch using\naugmented graph data obtained via removals.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u65e0\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u5355\u6b65\u725b\u987f\u66f4\u65b0\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u504f\u5dee\u7f13\u89e3\uff0c\u4f5c\u4e3a\u73b0\u6709\u516c\u5e73\u6027\u589e\u5f3a\u65b9\u6cd5\u7684\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u56fe\u6570\u636e\u56fa\u6709\u7684\u504f\u5dee\u653e\u5927\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u504f\u5dee\u7f13\u89e3\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65e0\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5305\u62ec\u516c\u5e73\u611f\u77e5\u8282\u70b9\u7279\u5f81\u65e0\u5b66\u4e60\u7b56\u7565\u548c\u57fa\u4e8e\u4e25\u683c\u504f\u5dee\u5206\u6790\u7684\u7ed3\u6784\u65e0\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65e0\u5b66\u4e60\u7b56\u7565\u5728\u504f\u5dee\u7f13\u89e3\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u76f8\u6bd4\u6709\u5229\u7684\u6548\u7528-\u590d\u6742\u5ea6\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5904\u7406\u9057\u5fd8\u6743\u6cd5\u89c4\u4e0b\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4fdd\u8bc1\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2505.14959", "pdf": "https://arxiv.org/pdf/2505.14959", "abs": "https://arxiv.org/abs/2505.14959", "authors": ["Kungang Li", "Xiangyi Chen", "Ling Leng", "Jiajing Xu", "Jiankai Sun", "Behnam Rezaei"], "title": "Privacy Preserving Conversion Modeling in Data Clean Room", "categories": ["cs.LG", "cs.IR", "H.4"], "comment": "Published in Proceedings of the 18th ACM Conference on Recommender\n  Systems. 2024 (RecSys '24)", "summary": "In the realm of online advertising, accurately predicting the conversion rate\n(CVR) is crucial for enhancing advertising efficiency and user satisfaction.\nThis paper addresses the challenge of CVR prediction while adhering to user\nprivacy preferences and advertiser requirements. Traditional methods face\nobstacles such as the reluctance of advertisers to share sensitive conversion\ndata and the limitations of model training in secure environments like data\nclean rooms. We propose a novel model training framework that enables\ncollaborative model training without sharing sample-level gradients with the\nadvertising platform. Our approach introduces several innovative components:\n(1) utilizing batch-level aggregated gradients instead of sample-level\ngradients to minimize privacy risks; (2) applying adapter-based\nparameter-efficient fine-tuning and gradient compression to reduce\ncommunication costs; and (3) employing de-biasing techniques to train the model\nunder label differential privacy, thereby maintaining accuracy despite\nprivacy-enhanced label perturbations. Our experimental results, conducted on\nindustrial datasets, demonstrate that our method achieves competitive ROCAUC\nperformance while significantly decreasing communication overhead and complying\nwith both advertiser privacy requirements and user privacy choices. This\nframework establishes a new standard for privacy-preserving, high-performance\nCVR prediction in the digital advertising landscape.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8f6c\u5316\u7387\u9884\u6d4b\u3002", "motivation": "\u5728\u7ebf\u5e7f\u544a\u4e2d\u51c6\u786e\u9884\u6d4b\u8f6c\u5316\u7387(CVR)\u5bf9\u4e8e\u63d0\u9ad8\u5e7f\u544a\u6548\u7387\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u5e7f\u544a\u5546\u4e0d\u613f\u5206\u4eab\u654f\u611f\u8f6c\u5316\u6570\u636e\u548c\u5728\u5b89\u5168\u73af\u5883\u5982\u6570\u636e\u6e05\u6d01\u5ba4\u4e2d\u6a21\u578b\u8bad\u7ec3\u7684\u9650\u5236\u3002", "method": "\u5f15\u5165\u4e86\u65b0\u7684\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u62ec\u4f7f\u7528\u6279\u91cf\u7ea7\u805a\u5408\u68af\u5ea6\u3001\u57fa\u4e8e\u9002\u914d\u5668\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u548c\u68af\u5ea6\u538b\u7f29\u4ee5\u53ca\u53bb\u504f\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u4e0e\u5176\u4ed6\u65b9\u6cd5\u76f8\u5f53\u7684ROCAUC\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u5e76\u7b26\u5408\u5e7f\u544a\u5546\u7684\u9690\u79c1\u8981\u6c42\u548c\u7528\u6237\u7684\u9690\u79c1\u9009\u62e9\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4e0e\u5176\u4ed6\u65b9\u6cd5\u76f8\u5f53\u7684ROCAUC\u6027\u80fd\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u5f00\u9500\u3002"}}
{"id": "2505.15009", "pdf": "https://arxiv.org/pdf/2505.15009", "abs": "https://arxiv.org/abs/2505.15009", "authors": ["Quan Nguyen", "Thanh Nguyen-Tang"], "title": "One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages", "summary": "We study the approximation capabilities and on-convergence behaviors of\none-layer transformers on the noiseless and noisy in-context reasoning of\nnext-token prediction. Existing theoretical results focus on understanding the\nin-context reasoning behaviors for either the first gradient step or when the\nnumber of samples is infinite. Furthermore, no convergence rates nor\ngeneralization abilities were known. Our work addresses these gaps by showing\nthat there exists a class of one-layer transformers that are provably\nBayes-optimal with both linear and ReLU attention. When being trained with\ngradient descent, we show via a finite-sample analysis that the expected loss\nof these transformers converges at linear rate to the Bayes risk. Moreover, we\nprove that the trained models generalize to unseen samples as well as exhibit\nlearning behaviors that were empirically observed in previous works. Our\ntheoretical findings are further supported by extensive empirical validations.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u5c42Transformer\u5728\u65e0\u566a\u58f0\u548c\u6709\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u5bf9\u4e0b\u4e00\u4e2aToken\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u8d1d\u53f6\u65af\u6700\u4f18\u6027\uff0c\u5e76\u4e14\u5c55\u793a\u4e86\u9884\u671f\u635f\u5931\u4ee5\u7ebf\u6027\u901f\u7387\u6536\u655b\u5230\u8d1d\u53f6\u65af\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u4e3b\u8981\u96c6\u4e2d\u5728\u7406\u89e3\u5355\u4e00\u68af\u5ea6\u6b65\u957f\u6216\u8005\u6837\u672c\u6570\u65e0\u9650\u60c5\u51b5\u4e0b\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u884c\u4e3a\uff0c\u7f3a\u4e4f\u6536\u655b\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6709\u9650\u6837\u672c\u5206\u6790\uff0c\u8bc1\u660e\u4e00\u5c42Transformer\u5728\u5177\u6709\u7ebf\u6027\u548cReLU\u6ce8\u610f\u529b\u65f6\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u6027\uff0c\u5e76\u5c55\u793a\u5176\u6536\u655b\u6027\u3002", "result": "\u8fd9\u4e9bTransformer\u7684\u9884\u671f\u635f\u5931\u4ee5\u7ebf\u6027\u901f\u7387\u6536\u655b\u5230\u8d1d\u53f6\u65af\u98ce\u9669\uff0c\u5e76\u4e14\u6a21\u578b\u80fd\u591f\u6cdb\u5316\u5230\u672a\u89c1\u6837\u672c\u4e0a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4e00\u5c42Transformer\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u5f3a\u5927\u7684\u903c\u8fd1\u80fd\u529b\u548c\u826f\u597d\u7684\u6536\u655b\u53ca\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.15034", "pdf": "https://arxiv.org/pdf/2505.15034", "abs": "https://arxiv.org/abs/2505.15034", "authors": ["Kaiwen Zha", "Zhengqi Gao", "Maohao Shen", "Zhang-Wei Hong", "Duane S. Boning", "Dina Katabi"], "title": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Tech report. The first two authors contributed equally", "summary": "Reinforcement learning (RL) has recently emerged as a compelling approach for\nenhancing the reasoning capabilities of large language models (LLMs), where an\nLLM generator serves as a policy guided by a verifier (reward model). However,\ncurrent RL post-training methods for LLMs typically use verifiers that are\nfixed (rule-based or frozen pretrained) or trained discriminatively via\nsupervised fine-tuning (SFT). Such designs are susceptible to reward hacking\nand generalize poorly beyond their training distributions. To overcome these\nlimitations, we propose Tango, a novel framework that uses RL to concurrently\ntrain both an LLM generator and a verifier in an interleaved manner. A central\ninnovation of Tango is its generative, process-level LLM verifier, which is\ntrained via RL and co-evolves with the generator. Importantly, the verifier is\ntrained solely based on outcome-level verification correctness rewards without\nrequiring explicit process-level annotations. This generative RL-trained\nverifier exhibits improved robustness and superior generalization compared to\ndeterministic or SFT-trained verifiers, fostering effective mutual\nreinforcement with the generator. Extensive experiments demonstrate that both\ncomponents of Tango achieve state-of-the-art results among 7B/8B-scale models:\nthe generator attains best-in-class performance across five competition-level\nmath benchmarks and four challenging out-of-domain reasoning tasks, while the\nverifier leads on the ProcessBench dataset. Remarkably, both components exhibit\nparticularly substantial improvements on the most difficult mathematical\nreasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Tango\uff0c\u901a\u8fc7\u540c\u65f6\u8bad\u7ec3\u751f\u6210\u5668\u548c\u9a8c\u8bc1\u5668\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9a8c\u8bc1\u5668\u901a\u8fc7\u751f\u6210\u5f0f\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\u5e76\u968f\u751f\u6210\u5668\u5171\u540c\u8fdb\u5316\u3002\u5b9e\u9a8c\u8868\u660eTango\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u548c\u9886\u57df\u5916\u63a8\u7406\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u5e76\u4e14\u6cdb\u5316\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u4e86Tango\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u540c\u65f6\u8bad\u7ec3\u751f\u6210\u5668\u548c\u751f\u6210\u5f0f\u7684\u3001\u8fc7\u7a0b\u7ea7\u522b\u7684\u9a8c\u8bc1\u5668\uff0c\u5e76\u4e14\u9a8c\u8bc1\u5668\u4ec5\u57fa\u4e8e\u7ed3\u679c\u7ea7\u7684\u9a8c\u8bc1\u6b63\u786e\u6027\u5956\u52b1\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "Tango\u7684\u751f\u6210\u5668\u5728\u4e94\u4e2a\u7ade\u4e89\u7ea7\u522b\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u548c\u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u8de8\u9886\u57df\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\uff1b\u9a8c\u8bc1\u5668\u5728ProcessBench\u6570\u636e\u96c6\u4e0a\u9886\u5148\u3002", "conclusion": "Tango\u5c55\u793a\u4e86\u5728\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u663e\u8457\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u56f0\u96be\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u4e0a\u3002"}}
{"id": "2505.15047", "pdf": "https://arxiv.org/pdf/2505.15047", "abs": "https://arxiv.org/abs/2505.15047", "authors": ["Yingming Pu", "Tao Lin", "Hongyu Chen"], "title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate\nremarkable potential for scientific discovery. Existing approaches, however,\noften automate scientific discovery using predefined workflows that lack\nrationality constraints. This often leads to aimless hypothesizing and a\nfailure to consistently link hypotheses with evidence, thereby hindering\nsystematic uncertainty reduction. Overcoming these limitations fundamentally\nrequires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an\ninformation-theoretical framework, treating automated scientific discovery as a\nstructured uncertainty reduction problem guided by principles (e.g., scientific\nlaws). In evaluations across three distinct scientific domains -- discovering\nnanomaterial structures, bio-molecules, and superconductor candidates with\ntargeted properties -- our method significantly improves discovery efficiency,\nreflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property\nvalues versus exploration steps, and enhances solution quality by 94.06\\%\ncompared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a\nPlug-and-Play method, establishing a novel paradigm shift in highly efficient\nautomated scientific discovery, paving the way for more robust and accelerated\nAI-driven research. Code is publicly available at our\n\\href{https://github.com/amair-lab/PiFlow}{GitHub}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u6846\u67b6\u7684\u63d2\u4ef6\u5f0f\u65b9\u6cd5PiFlow\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u7684\u6548\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u4e2d\u7f3a\u4e4f\u7406\u6027\u7ea6\u675f\uff0c\u5bfc\u81f4\u5047\u8bbe\u65e0\u76ee\u6807\u4e14\u65e0\u6cd5\u7cfb\u7edf\u5730\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5f15\u5165\u4e86PiFlow\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u89c6\u4e3a\u7531\u539f\u5219\u6307\u5bfc\u7684\u7ed3\u6784\u5316\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u79d1\u5b66\u9886\u57df\u4e2d\uff0cPiFlow\u63d0\u5347\u4e8673.55%\u7684AUC\uff0c\u5e76\u63d0\u9ad8\u4e8694.06%\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "conclusion": "PiFlow\u662f\u4e00\u79cd\u63d2\u4ef6\u5f0f\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u9ad8\u6548\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u7684\u65b0\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2505.15080", "pdf": "https://arxiv.org/pdf/2505.15080", "abs": "https://arxiv.org/abs/2505.15080", "authors": ["Sergey Pankov", "Georges Harik"], "title": "SUS backprop: linear backpropagation algorithm for long inputs in transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "21 pages, 9 figures", "summary": "It is straightforward to design an unbiased gradient estimator that\nstochastically cuts the backpropagation flow through any part of a\ncomputational graph. By cutting the parts that have little effect on the\ncomputation, one can potentially save a significant amount of back-propagation\ncomputation in exchange for a minimal increase in the stochastic gradient\nvariance, in some situations. Such a situation occurs in the attention\nmechanism of the transformer architecture. For long sequences, attention\nbecomes the limiting factor, as its compute requirements increase quadratically\nwith sequence length $n$. At the same time, most attention weights become very\nsmall, as most attention heads tend to connect a given token with only a small\nfraction of other tokens in the sequence. These weights become promising\ntargets for cutting backpropagation. We propose a simple probabilistic rule\ncontrolled by a single parameter $c$ that cuts backpropagation through most\nattention weights, leaving at most $c$ interactions per token per attention\nhead. This brings a factor of $c/n$ reduction in the compute required for the\nattention backpropagation, turning it from quadratic $O(n^2)$ to linear\ncomplexity $O(nc)$. We have empirically verified that, for a typical\ntransformer model, cutting $99\\%$ of the attention gradient flow (i.e. choosing\n$c \\sim 20-30$) results in relative gradient variance increase of only about\n$1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is amenable\nto efficient sparse matrix implementation, thus being promising for making the\ncost of a backward pass negligible relative to the cost of a forward pass when\ntraining a transformer model on long sequences.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u6982\u7387\u89c4\u5219\u6765\u524a\u51cf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u5927\u90e8\u5206\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u4f4e\u5230O(nc)\uff0c\u5b9e\u9a8c\u8868\u660e\u5bf9\u4e8e\u5178\u578bTransformer\u6a21\u578b\uff0c\u5728\u957f\u5e8f\u5217\u8bad\u7ec3\u65f6\u8be5\u65b9\u6cd5\u76f8\u5bf9\u68af\u5ea6\u65b9\u5dee\u589e\u52a0\u4ec5\u7ea61%\uff0c\u5e76\u4e14\u9002\u5408\u9ad8\u6548\u7a00\u758f\u77e9\u9635\u5b9e\u73b0\u3002", "motivation": "\u51cf\u5c11Transformer\u67b6\u6784\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u662f\u5728\u957f\u5e8f\u5217\u60c5\u51b5\u4e0b\uff0c\u5176\u8ba1\u7b97\u9700\u6c42\u968f\u5e8f\u5217\u957f\u5ea6n\u5448\u4e8c\u6b21\u589e\u957f\uff0c\u800c\u5927\u90e8\u5206\u6ce8\u610f\u529b\u6743\u91cd\u975e\u5e38\u5c0f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7531\u5355\u4e00\u53c2\u6570c\u63a7\u5236\u7684\u7b80\u5355\u6982\u7387\u89c4\u5219\uff0c\u901a\u8fc7\u524a\u51cf\u5927\u90e8\u5206\u6ce8\u610f\u529b\u6743\u91cd\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u6bcftoken\u6700\u591a\u4fdd\u7559c\u4e2a\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5bf9\u4e8e\u5178\u578b\u7684Transformer\u6a21\u578b\uff0c\u524a\u51cf99%\u7684\u6ce8\u610f\u529b\u68af\u5ea6\u6d41\uff08\u5373\u9009\u62e9c\u7ea6\u4e3a20-30\uff09\u65f6\uff0c\u5bf9\u4e8en\u7ea6\u4e3a2000\u7684\u60c5\u51b5\uff0c\u76f8\u5bf9\u68af\u5ea6\u65b9\u5dee\u589e\u52a0\u4ec5\u7ea61%\uff0c\u4e14\u968f\u7740n\u589e\u5927\u8be5\u503c\u4f1a\u51cf\u5c0f\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u9002\u7528\u4e8e\u9ad8\u6548\u7684\u7a00\u758f\u77e9\u9635\u5b9e\u73b0\uff0c\u6709\u671b\u4f7f\u957f\u5e8f\u5217Transformer\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u6210\u672c\u76f8\u5bf9\u4e8e\u524d\u5411\u4f20\u64ad\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002"}}
{"id": "2505.15083", "pdf": "https://arxiv.org/pdf/2505.15083", "abs": "https://arxiv.org/abs/2505.15083", "authors": ["Jeremy Qin"], "title": "Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting plays a crucial role in various applications,\nparticularly in healthcare, where accurate predictions of future health\ntrajectories can significantly impact clinical decision-making. Ensuring\ntransparency and explainability of the models responsible for these tasks is\nessential for their adoption in critical settings. Recent work has explored a\ntop-down approach to bi-level transparency, focusing on understanding trends\nand properties of predicted time series using static features. In this work, we\nextend this framework by incorporating exogenous time series features alongside\nstatic features in a structured manner, while maintaining cohesive\ninterpretation. Our approach leverages the insights of trajectory comprehension\nto introduce an encoding mechanism for exogenous time series, where they are\ndecomposed into meaningful trends and properties, enabling the extraction of\ninterpretable patterns. Through experiments on several synthetic datasets, we\ndemonstrate that our approach remains predictive while preserving\ninterpretability and robustness. This work represents a step towards developing\nrobust, and generalized time series forecasting models. The code is available\nat https://github.com/jeremy-qin/TIMEVIEW", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9759\u6001\u548c\u65f6\u95f4\u76f8\u5173\u7279\u5f81\u7684\u900f\u660e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u3002", "motivation": "\u786e\u4fdd\u533b\u7597\u9886\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5bf9\u4e8e\u5176\u5e7f\u6cdb\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55\u4e86\u73b0\u6709\u7684\u53cc\u5c42\u900f\u660e\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u65b9\u5f0f\u6574\u5408\u5916\u751f\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u7f16\u7801\u673a\u5236\u6765\u5206\u89e3\u8fd9\u4e9b\u7279\u5f81\u4ee5\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u671d\u7740\u6784\u5efa\u66f4\u5065\u58ee\u4e14\u901a\u7528\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2505.15116", "pdf": "https://arxiv.org/pdf/2505.15116", "abs": "https://arxiv.org/abs/2505.15116", "authors": ["Zehong Wang", "Zheyuan Liu", "Tianyi Ma", "Jiazheng Li", "Zheyuan Zhang", "Xingbo Fu", "Yiyang Li", "Zhengqing Yuan", "Wei Song", "Yijun Ma", "Qingkai Zeng", "Xiusi Chen", "Jianan Zhao", "Jundong Li", "Meng Jiang", "Pietro Lio", "Nitesh Chawla", "Chuxu Zhang", "Yanfang Ye"], "title": "Graph Foundation Models: A Comprehensive Survey", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "Github Repo:\n  https://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs. 93 pages,\n  438 references", "summary": "Graph-structured data pervades domains such as social networks, biological\nsystems, knowledge graphs, and recommender systems. While foundation models\nhave transformed natural language processing, vision, and multimodal learning\nthrough large-scale pretraining and generalization, extending these\ncapabilities to graphs -- characterized by non-Euclidean structures and complex\nrelational semantics -- poses unique challenges and opens new opportunities. To\nthis end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose\nintelligence to structured data, enabling broad transfer across graph-centric\ntasks and domains. This survey provides a comprehensive overview of GFMs,\nunifying diverse efforts under a modular framework comprising three key\ncomponents: backbone architectures, pretraining strategies, and adaptation\nmechanisms. We categorize GFMs by their generalization scope -- universal,\ntask-specific, and domain-specific -- and review representative methods, key\ninnovations, and theoretical insights within each category. Beyond methodology,\nwe examine theoretical foundations including transferability and emergent\ncapabilities, and highlight key challenges such as structural alignment,\nheterogeneity, scalability, and evaluation. Positioned at the intersection of\ngraph learning and general-purpose AI, GFMs are poised to become foundational\ninfrastructure for open-ended reasoning over structured data. This survey\nconsolidates current progress and outlines future directions to guide research\nin this rapidly evolving field. Resources are available at\nhttps://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u56fe\u57fa\u7840\u6a21\u578b\uff08GFMs\uff09\uff0c\u63d0\u4f9b\u4e86\u5305\u62ecbackbone\u67b6\u6784\u3001\u9884\u8bad\u7ec3\u7b56\u7565\u548c\u9002\u5e94\u673a\u5236\u5728\u5185\u7684\u6a21\u5757\u6846\u67b6\u7edf\u4e00\u4e0d\u540c\u5de5\u4f5c\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u7406\u8bba\u57fa\u7840\u548c\u5173\u952e\u6311\u6218\u3002", "motivation": "\u867d\u7136foundation models\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u89c6\u89c9\u548c\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u9762\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5c06\u5176\u80fd\u529b\u6269\u5c55\u5230\u5177\u6709\u975e\u6b27\u51e0\u91cc\u5f97\u7ed3\u6784\u548c\u590d\u6742\u5173\u7cfb\u8bed\u4e49\u7684\u56fe\u4e0a\u5e26\u6765\u4e86\u72ec\u7279\u7684\u6311\u6218\u548c\u65b0\u7684\u673a\u4f1a\u3002", "method": "\u901a\u8fc7backbone architectures\u3001pretraining strategies\u548cadaptation mechanisms\u8fd9\u4e09\u90e8\u5206\u7ec4\u6210\u6a21\u5757\u6846\u67b6\u7edf\u4e00\u4e0d\u540c\u7684\u52aa\u529b\u3002", "result": "\u5bf9GFMs\u8fdb\u884c\u4e86\u5168\u9762\u6982\u8ff0\uff0c\u5206\u7c7b\u5e76\u56de\u987e\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u5173\u952e\u521b\u65b0\u548c\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "GFMs\u6709\u6f5c\u529b\u6210\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u5f00\u653e\u63a8\u7406\u7684\u57fa\u7840\u67b6\u6784\u3002"}}
