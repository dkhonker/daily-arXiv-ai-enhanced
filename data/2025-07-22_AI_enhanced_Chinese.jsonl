{"id": "2507.14197", "pdf": "https://arxiv.org/pdf/2507.14197", "abs": "https://arxiv.org/abs/2507.14197", "authors": ["Andriamifidisoa Ramamonjy", "Rufine Marius Lalasoa"], "title": "DM-RSA: An Extension of RSA with Dual Modulus", "categories": ["cs.CR", "cs.IT", "math.IT", "94A60"], "comment": "5 pages", "summary": "We introduce DM-RSA (Dual Modulus RSA), a variant of the RSA cryptosystem\nthat employs two distinct moduli symmetrically to enhance security. By\nleveraging the Chinese Remainder Theorem (CRT) for decryption, DM-RSA provides\nincreased robustness against side-channel attacks while preserving the\nefficiency of classical RSA. This approach improves resistance to partial\ncompromise of a modulus and integrates easily into existing infrastructures.", "AI": {"tldr": "DM-RSA\u662f\u4e00\u79cd\u6539\u8fdb\u7684RSA\u5bc6\u7801\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u6570\u5e76\u5229\u7528\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\u8fdb\u884c\u89e3\u5bc6\uff0c\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684RSA\u52a0\u5bc6\u7cfb\u7edf\u5728\u9762\u5bf9\u4fa7\u4fe1\u9053\u653b\u51fb\u65f6\u53ef\u80fd\u5b58\u5728\u5b89\u5168\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4e3a\u4e86\u63d0\u5347\u5bf9\u90e8\u5206\u6a21\u6570\u6cc4\u9732\u7684\u62b5\u6297\u529b\uff0c\u5e76\u4e14\u4e0d\u635f\u5931\u539f\u6709\u7684\u6548\u7387\u3002", "method": "DM-RSA\u901a\u8fc7\u5f15\u5165\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u6570\u5bf9\u79f0\u5730\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u5e76\u4f7f\u7528\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\u6765\u8fdb\u884c\u89e3\u5bc6\u64cd\u4f5c\u3002\u8fd9\u79cd\u65b9\u5f0f\u63d0\u9ad8\u4e86\u5bf9\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u7a33\u5065\u6027\uff0c\u5e76\u4fdd\u7559\u4e86\u7ecf\u5178RSA\u7684\u6548\u7387\u3002", "result": "DM-RSA\u4e0d\u4ec5\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u62b5\u6297\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u90e8\u5206\u6a21\u6570\u6cc4\u9732\u7684\u98ce\u9669\uff0c\u800c\u4e14\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684\u57fa\u7840\u8bbe\u65bd\u4e2d\u3002", "conclusion": "DM-RSA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u53d8\u4f53\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4e0d\u5f71\u54cd\u6548\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u5347RSA\u52a0\u5bc6\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14201", "pdf": "https://arxiv.org/pdf/2507.14201", "abs": "https://arxiv.org/abs/2507.14201", "authors": ["Yiran Wu", "Mauricio Velazco", "Andrew Zhao", "Manuel Ra\u00fal Mel\u00e9ndez Luj\u00e1n", "Srisuma Movva", "Yogesh K Roy", "Quang Nguyen", "Roberto Rodriguez", "Qingyun Wu", "Michael Albada", "Julia Kiseleva", "Anand Mudgerikar"], "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on\nthe task of Cyber Threat Investigation through security questions derived from\ninvestigation graphs. Real-world security analysts must sift through a large\nnumber of heterogeneous alert signals and security logs, follow multi-hop\nchains of evidence, and compile an incident report. With the developments of\nLLMs, building LLM-based agents for automatic thread investigation is a\npromising direction. To assist the development and evaluation of LLM agents, we\nconstruct a dataset from a controlled Azure tenant that covers 8 simulated\nreal-world multi-step attacks, 57 log tables from Microsoft Sentinel and\nrelated services, and 589 automatically generated questions. We leverage\nsecurity logs extracted with expert-crafted detection logic to build threat\ninvestigation graphs, and then generate questions with LLMs using paired nodes\non the graph, taking the start node as background context and the end node as\nanswer. Anchoring each question to these explicit nodes and edges not only\nprovides automatic, explainable ground truth answers but also makes the\npipeline reusable and readily extensible to new logs. This also enables the\nautomatic generation of procedural tasks with verifiable rewards, which can be\nnaturally extended to training agents via reinforcement learning. Our\ncomprehensive experiments with different models confirm the difficulty of the\ntask: with the base setting, the average reward across all evaluated models is\n0.249, and the best achieved is 0.368, leaving substantial headroom for future\nresearch. Code and data are coming soon!", "AI": {"tldr": "\u63d0\u51fa\u4e86ExCyTIn-Bench\uff0c\u4e00\u4e2a\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u4e2d\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u901a\u8fc7\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u7684\u653b\u51fb\u548c\u65e5\u5fd7\uff0c\u751f\u6210\u4e86589\u4e2a\u81ea\u52a8\u95ee\u9898\uff0c\u4ee5\u8bc4\u4f30\u548c\u8bad\u7ec3LLM\u4ee3\u7406\u8fdb\u884c\u5a01\u80c1\u8c03\u67e5\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u5e73\u5747\u5956\u52b1\u4ec5\u4e3a0.249\uff0c\u6700\u4f73\u4e3a0.368\uff0c\u672a\u6765\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0c\u5efa\u7acb\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6765\u8fdb\u884c\u81ea\u52a8\u5316\u7684\u7f51\u7edc\u5a01\u80c1\u8c03\u67e5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u7136\u800c\uff0c\u7f3a\u4e4f\u5408\u9002\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u4ee3\u7406\u7684\u6709\u6548\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6765\u81ea\u53d7\u63a7Azure\u79df\u6237\u7684\u6570\u636e\u96c6\uff0c\u5305\u62ec8\u6b21\u6a21\u62df\u7684\u771f\u5b9e\u4e16\u754c\u591a\u6b65\u9aa4\u653b\u51fb\u300157\u4e2a\u65e5\u5fd7\u8868\u548c589\u4e2a\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\u3002\u4f7f\u7528\u4e13\u5bb6\u7f16\u5199\u7684\u68c0\u6d4b\u903b\u8f91\u63d0\u53d6\u5b89\u5168\u65e5\u5fd7\uff0c\u5efa\u7acb\u5a01\u80c1\u8c03\u67e5\u56fe\uff0c\u5e76\u5229\u7528\u914d\u5bf9\u8282\u70b9\u751f\u6210\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u5b8c\u6210\u6b64\u4efb\u52a1\uff0c\u6240\u6709\u8bc4\u4f30\u6a21\u578b\u7684\u5e73\u5747\u5956\u52b1\u4ec5\u4e3a0.249\uff0c\u6700\u4f73\u6a21\u578b\u7684\u5956\u52b1\u4e3a0.368\u3002", "conclusion": "ExCyTIn-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u5e73\u53f0\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3LLM\u4ee3\u7406\u8fdb\u884c\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u8c03\u67e5\uff0c\u867d\u7136\u76ee\u524d\u7684\u7ed3\u679c\u663e\u793a\u4efb\u52a1\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\uff0c\u4f46\u4e3a\u672a\u6765\u7684\u7814\u7a76\u7559\u4e0b\u4e86\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2507.14202", "pdf": "https://arxiv.org/pdf/2507.14202", "abs": "https://arxiv.org/abs/2507.14202", "authors": ["Pengfei Du"], "title": "PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse applications, yet they pose significant security risks that threaten\ntheir safe deployment in critical domains. Current security alignment\nmethodologies predominantly rely on Process Reward Models (PRMs) to evaluate\nintermediate reasoning steps, introducing substantial computational overhead\nand scalability constraints. This paper presents a novel PRM-free security\nalignment framework that leverages automated red teaming and adversarial\ntraining to achieve robust security guarantees while maintaining computational\nefficiency. Our approach systematically identifies vulnerabilities through\nsophisticated attack strategies including genetic algorithm optimization,\nmulti-agent simulation, and advanced prompt mutation techniques. The framework\nenhances model robustness via targeted adversarial training with curriculum\nlearning and adaptive regularization mechanisms. Comprehensive experimental\nevaluation across five state-of-the-art LLMs demonstrates that our method\nachieves superior security alignment performance compared to PRM-based\napproaches while reducing computational costs by 61\\%. The framework\nincorporates transparent reporting and continuous audit mechanisms that enable\niterative security improvement and regulatory compliance. Our contributions\nadvance the field of efficient LLM security alignment by democratizing access\nto robust security measures for resource-constrained organizations and\nproviding a scalable foundation for addressing evolving adversarial threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u9700PRM\u7684\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u7ea2\u961f\u6d4b\u8bd5\u548c\u5bf9\u6297\u8bad\u7ec3\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u5728\u4e94\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u663e\u793a\u51fa\u6bd4\u57fa\u4e8ePRM\u7684\u65b9\u6cd5\u66f4\u597d\u7684\u5b89\u5168\u6027\u80fd\uff0c\u5e76\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u4e8661\uff05\u3002", "motivation": "\u5f53\u524d\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\uff0c\u8fd9\u5f15\u5165\u4e86\u5927\u91cf\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u5e76\u786e\u4fdd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u5728\u5173\u952e\u9886\u57df\u5b89\u5168\u90e8\u7f72\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e0d\u4f7f\u7528PRM\u7684\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u5229\u7528\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u3001\u5bf9\u6297\u8bad\u7ec3\u3001\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u3001\u591a\u4ee3\u7406\u6a21\u62df\u548c\u9ad8\u7ea7\u63d0\u793a\u53d8\u5f02\u6280\u672f\u6765\u8bc6\u522b\u6f0f\u6d1e\u3002\u5e76\u901a\u8fc7\u5e26\u6709\u8bfe\u7a0b\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u6b63\u5219\u5316\u673a\u5236\u7684\u9488\u5bf9\u6027\u5bf9\u6297\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u6bd4\u57fa\u4e8ePRM\u7684\u65b9\u6cd5\u66f4\u4f18\u7684\u5b89\u5168\u5bf9\u9f50\u6027\u80fd\uff0c\u8fd8\u51cf\u5c11\u4e8661%\u7684\u8ba1\u7b97\u6210\u672c\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u900f\u660e\u62a5\u544a\u548c\u6301\u7eed\u5ba1\u8ba1\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u8fed\u4ee3\u5b89\u5168\u6539\u8fdb\u548c\u6cd5\u89c4\u9075\u4ece\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u9ad8\u6548LLM\u5b89\u5168\u5bf9\u9f50\u9886\u57df\u7684\u8fdb\u6b65\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u83b7\u5f97\u5f3a\u5927\u5b89\u5168\u63aa\u65bd\u7684\u673a\u4f1a\uff0c\u5e76\u4e3a\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u5bf9\u6297\u5a01\u80c1\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2507.14207", "pdf": "https://arxiv.org/pdf/2507.14207", "abs": "https://arxiv.org/abs/2507.14207", "authors": ["Richard M. Charles", "James H. Curry", "Richard B. Charles"], "title": "Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design", "categories": ["cs.CR", "cs.AI", "I.2.1; I.2.7"], "comment": "12 pages, 1 figure", "summary": "The integration of Large Language Models (LLMs) in K--12 education offers\nboth transformative opportunities and emerging risks. This study explores how\nstudents may Trojanize prompts to elicit unsafe or unintended outputs from\nLLMs, bypassing established content moderation systems with safety guardrils.\nThrough a systematic experiment involving simulated K--12 queries and\nmulti-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This\npaper presents our experimental design, detailed findings, and a prototype\ntool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized\neducational prompts. These insights aim to inform both AI safety researchers\nand educational technologists on the safe deployment of LLMs for educators.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728K-12\u6559\u80b2\u4e2d\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u539f\u578b\u5de5\u5177TrojanPromptGuard\u4ee5\u81ea\u52a8\u68c0\u6d4b\u548c\u51cf\u8f7b\u7279\u6d1b\u4f0a\u5316\u6559\u80b2\u63d0\u793a\u3002", "motivation": "\u63a2\u7d22\u5b66\u751f\u5982\u4f55\u53ef\u80fd\u901a\u8fc7\u7279\u6d1b\u4f0a\u5316\u63d0\u793a\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5f15\u51fa\u4e0d\u5b89\u5168\u6216\u975e\u9884\u671f\u7684\u8f93\u51fa\uff0c\u7ed5\u8fc7\u5df2\u5efa\u7acb\u7684\u5185\u5bb9\u8c03\u8282\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u6d89\u53ca\u6a21\u62dfK-12\u67e5\u8be2\u548c\u591a\u8f6e\u5bf9\u8bdd\u7684\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u63ed\u793aGPT-3.5\u548cGPT-4\u7684\u5173\u952e\u6f0f\u6d1e\u3002", "result": "\u66b4\u9732\u4e86GPT-3.5\u548cGPT-4\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u539f\u578b\u5de5\u5177TrojanPromptGuard (TPG)\u3002", "conclusion": "\u672c\u7814\u7a76\u65e8\u5728\u4e3aAI\u5b89\u5168\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u6280\u672f\u4e13\u5bb6\u63d0\u4f9b\u5173\u4e8eLLMs\u5728\u6559\u80b2\u9886\u57df\u5b89\u5168\u90e8\u7f72\u7684\u4fe1\u606f\u3002"}}
{"id": "2507.14170", "pdf": "https://arxiv.org/pdf/2507.14170", "abs": "https://arxiv.org/abs/2507.14170", "authors": ["Jaeheun Jung", "Donghun Lee"], "title": "Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 workshop HiLD 2025 (3rd workshop on High-dimensional\n  Learning Dynamics)", "summary": "Structured pruning aims to reduce the size and computational cost of deep\nneural networks by removing entire filters or channels. The traditional\nregularizers such as L1 or Group Lasso and its variants lead to\nmagnitude-biased pruning decisions, such that the filters with small magnitudes\nare likely to be pruned. Also, they often entail pruning results with almost\nzero margin around pruning decision boundary, such that tiny perturbation in a\nfilter magnitude can flip the pruning decision. In this paper, we identify the\nprecise algebraic condition under which pruning operations preserve model\nperformance, and use the condition to construct a novel regularizer defined in\nan extended parameter space via auxiliary catalyst variables. The proposed\nCatalyst regularization ensures fair pruning chance for each filters with\ntheoretically provable zero bias to their magnitude and robust pruning behavior\nachieved by wide-margin bifurcation of magnitudes between the preserved and the\npruned filters. The theoretical properties naturally lead to real-world\neffectiveness, as shown by empirical validations of Catalyst Pruning algorithm.\nPruning results on various datasets and models are superior to state-of-the-art\nfilter pruning methods, and at the same time confirm the predicted robust and\nfair pruning characteristics of Catalyst pruning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u50ac\u5316\u5242\u53d8\u91cf\u6765\u786e\u4fdd\u5728\u4fee\u526a\u8fc7\u7a0b\u4e2d\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u90fd\u6709\u516c\u5e73\u7684\u673a\u4f1a\u88ab\u4fdd\u7559\u6216\u5220\u9664\uff0c\u5e76\u4e14\u8fd9\u79cd\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u8fc7\u6ee4\u5668\u4fee\u526a\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff08\u5982L1\u6216Group Lasso\u53ca\u5176\u53d8\u4f53\uff09\u5728\u8fdb\u884c\u7ed3\u6784\u5316\u526a\u679d\u65f6\uff0c\u4f1a\u504f\u5411\u4e8e\u88c1\u526a\u5e45\u5ea6\u8f83\u5c0f\u7684\u6ee4\u6ce2\u5668\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u901a\u5e38\u4f1a\u5728\u88c1\u526a\u51b3\u7b56\u8fb9\u754c\u5468\u56f4\u51e0\u4e4e\u4e3a\u96f6\u7684\u88d5\u5ea6\uff0c\u4f7f\u5f97\u6ee4\u6ce2\u5668\u5e45\u5ea6\u7684\u5fae\u5c0f\u6270\u52a8\u53ef\u80fd\u4f1a\u7ffb\u8f6c\u88c1\u526a\u51b3\u7b56\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6b63\u5219\u5316\u5668\uff0c\u8be5\u6b63\u5219\u5316\u5668\u901a\u8fc7\u8f85\u52a9\u50ac\u5316\u5242\u53d8\u91cf\u5728\u6269\u5c55\u7684\u53c2\u6570\u7a7a\u95f4\u4e2d\u5b9a\u4e49\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2a\u8fc7\u6ee4\u5668\u5728\u4fee\u526a\u8fc7\u7a0b\u4e2d\u90fd\u6709\u516c\u5e73\u7684\u673a\u4f1a\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5927\u5e45\u5ea6\u5206\u53c9\u88ab\u4fdd\u7559\u548c\u88ab\u4fee\u526a\u7684\u8fc7\u6ee4\u5668\u4e4b\u95f4\u7684\u5e45\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u4fee\u526a\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cCatalyst Pruning\u7b97\u6cd5\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u4fee\u526a\u7ed3\u679c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6ee4\u6ce2\u5668\u4fee\u526a\u65b9\u6cd5\uff0c\u540c\u65f6\u4e5f\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u7a33\u5065\u548c\u516c\u5e73\u7684\u4fee\u526a\u7279\u6027\u3002", "conclusion": "Catalyst regularization\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u516c\u5e73\u548c\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u5316\u526a\u679d\u3002"}}
{"id": "2507.14212", "pdf": "https://arxiv.org/pdf/2507.14212", "abs": "https://arxiv.org/abs/2507.14212", "authors": ["Federico Mason", "Federico Chiariotti", "Pietro Talli", "Andrea Zanella"], "title": "Secure Goal-Oriented Communication: Defending against Eavesdropping Timing Attacks", "categories": ["cs.CR", "cs.SY", "eess.SY"], "comment": null, "summary": "Goal-oriented Communication (GoC) is a new paradigm that plans data\ntransmission to occur only when it is instrumental for the receiver to achieve\na certain goal. This leads to the advantage of reducing the frequency of\ntransmissions significantly while maintaining adherence to the receiver's\nobjectives. However, GoC scheduling also opens a timing-based side channel that\nan eavesdropper can exploit to obtain information about the state of the\nsystem. This type of attack sidesteps even information-theoretic security, as\nit exploits the timing of updates rather than their content. In this work, we\nstudy such an eavesdropping attack against pull-based goal-oriented scheduling\nfor remote monitoring and control of Markov processes. We provide a theoretical\nframework for defining the effectiveness of the attack and propose possible\ncountermeasures, including two practical heuristics that provide a balance\nbetween the performance gains offered by GoC and the amount of leaked\ninformation. Our results show that, while a naive goal-oriented scheduler\nallows the eavesdropper to correctly guess the system state about 60% of the\ntime, our heuristic defenses can halve the leakage with a marginal reduction of\nthe benefits of goal-oriented approaches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9488\u5bf9\u57fa\u4e8e\u62c9\u53d6\u7684\u76ee\u6807\u5bfc\u5411\u8c03\u5ea6\u7684\u7a83\u542c\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u5b9e\u7528\u7684\u542f\u53d1\u5f0f\u9632\u5fa1\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u4fe1\u606f\u6cc4\u9732\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u76ee\u6807\u5bfc\u5411\u901a\u4fe1\u7684\u4f18\u52bf\u3002", "motivation": "GoC\uff08\u76ee\u6807\u5bfc\u5411\u901a\u4fe1\uff09\u867d\u7136\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u4f20\u8f93\u9891\u7387\u5e76\u7ef4\u6301\u63a5\u6536\u8005\u7684\u5ba2\u89c2\u9700\u6c42\uff0c\u4f46\u5b83\u4e5f\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u65f6\u95f4\u7684\u4fa7\u4fe1\u9053\uff0c\u4f7f\u7a83\u542c\u8005\u80fd\u83b7\u5f97\u7cfb\u7edf\u72b6\u6001\u7684\u4fe1\u606f\u3002\u8fd9\u79cd\u653b\u51fb\u7ed5\u8fc7\u4e86\u4f20\u7edf\u4fe1\u606f\u5b89\u5168\u63aa\u65bd\uff0c\u56e0\u4e3a\u5b83\u662f\u5229\u7528\u66f4\u65b0\u7684\u65f6\u95f4\u800c\u975e\u5185\u5bb9\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "method": "\u4f5c\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u5b9a\u4e49\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u80fd\u7684\u5bf9\u7b56\uff0c\u5305\u62ec\u4e24\u79cd\u5b9e\u8df5\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728GoC\u63d0\u4f9b\u7684\u6027\u80fd\u589e\u76ca\u548c\u6cc4\u9732\u4fe1\u606f\u91cf\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5e73\u8861\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5929\u771f\u7684\u76ee\u6807\u5bfc\u5411\u8c03\u5ea6\u5668\u5141\u8bb8\u7a83\u542c\u8005\u6b63\u786e\u731c\u6d4b\u7cfb\u7edf\u72b6\u6001\u7ea660%\u7684\u65f6\u95f4\uff0c\u800c\u542f\u53d1\u5f0f\u9632\u5fa1\u65b9\u6cd5\u53ef\u4ee5\u5c06\u6cc4\u9732\u4fe1\u606f\u51cf\u5c11\u4e00\u534a\uff0c\u540c\u65f6\u5bf9GoC\u4f18\u52bf\u7684\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "\u5c3d\u7ba1GoC\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u5176\u6027\u80fd\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u6709\u6548\u5730\u51cf\u5c11\u4fe1\u606f\u6cc4\u9732\u3002"}}
{"id": "2507.14171", "pdf": "https://arxiv.org/pdf/2507.14171", "abs": "https://arxiv.org/abs/2507.14171", "authors": ["Jaeheun Jung", "Jaehyuk Lee", "Yeajin Lee", "Donghun Lee"], "title": "IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growth of demand on neural network compression methods, the\nstructured pruning methods including importance-based approach are actively\nstudied. The magnitude importance and many correlated modern importance\ncriteria often limit the capacity of pruning decision, since the filters with\nlarger magnitudes are not likely to be pruned if the smaller one didn't, even\nif it is redundant. In this paper, we propose a novel pruning strategy to\nchallenge this dominating effect of magnitude and provide fair chance to each\nfilter to be pruned, by placing it on projective space. After that, we observe\nthe gradient descent movement whether the filters move toward the origin or\nnot, to measure how the filter is likely to be pruned. This measurement is used\nto construct PROscore, a novel importance score for IPPRO, a novel\nimportance-based structured pruning with magnitude-indifference. Our evaluation\nresults shows that the proposed importance criteria using the projective space\nachieves near-lossless pruning by reducing the performance drop in pruning,\nwith promising performance after the finetuning. Our work debunks the\n``size-matters'' myth in pruning and expands the frontier of importance-based\npruning both theoretically and empirically.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5IPPRO\uff0c\u901a\u8fc7\u5728\u6295\u5f71\u7a7a\u95f4\u4e2d\u89c2\u5bdf\u6ee4\u6ce2\u5668\u7684\u68af\u5ea6\u4e0b\u964d\u8fd0\u52a8\u6765\u6311\u6218\u4f20\u7edf\u7684'\u5c3a\u5bf8\u91cd\u8981'\u89c2\u5ff5\uff0c\u5b9e\u73b0\u63a5\u8fd1\u65e0\u635f\u7684\u526a\u679d\u6548\u679c\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u538b\u7f29\u65b9\u6cd5\u7684\u9700\u6c42\u589e\u957f\u4fc3\u4f7f\u4e86\u5bf9\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u7684\u7814\u7a76\uff0c\u73b0\u6709\u7684\u5927\u5c0f\u91cd\u8981\u6027\u6807\u51c6\u9650\u5236\u4e86\u526a\u679d\u51b3\u7b56\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faPROscore\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5e76\u5e94\u7528\u4e8eIPPRO\u4e2d\uff0c\u901a\u8fc7\u5c06\u6ee4\u6ce2\u5668\u7f6e\u4e8e\u6295\u5f71\u7a7a\u95f4\u5e76\u89c2\u5bdf\u5176\u68af\u5ea6\u4e0b\u964d\u8fd0\u52a8\u6765\u51b3\u5b9a\u662f\u5426\u526a\u679d\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u635f\u5931\u7684\u526a\u679d\u6548\u679c\uff0c\u5728\u5fae\u8c03\u540e\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6253\u7834\u4e86\u526a\u679d\u4e2d\u7684\u201c\u5c3a\u5bf8\u91cd\u8981\u201d\u795e\u8bdd\uff0c\u4ece\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u6269\u5c55\u4e86\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u526a\u679d\u9886\u57df\u3002"}}
{"id": "2507.14213", "pdf": "https://arxiv.org/pdf/2507.14213", "abs": "https://arxiv.org/abs/2507.14213", "authors": ["Irena Spasojevic", "Federica Celegato", "Alessandro Magni", "Paola Tiberto", "Jordi Sort"], "title": "Magneto-Ionic Hardware Security Primitives: Embedding Data Protection at the Material Level", "categories": ["cs.CR", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "physics.app-ph"], "comment": null, "summary": "The Big Data revolution has heightened the demand for robust,\nenergy-efficient security hardware capable of withstanding increasingly\nsophisticated cyber threats. Conventional encryption schemes, reliant on\ncomplex algorithms, are resource-intensive and remain vulnerable. To fortify\nsensitive information, society needs innovative anti-hacking and\nanti-counterfeiting technologies that exploit new materials and designs. Here,\nwe present a magneto-ionic strategy for hardware-level security based on fully\nselective voltage-controlled N3- ion migration within pre-defined, initially\nparamagnetic FeCoN dots. This process generates ferromagnetic sublayers of\ntuneable thickness, resulting in either deterministic (single-domain or vortex)\nor probabilistic states (with coexisting magnetic configurations and\nvoltage-adjustable probabilities), each exhibiting stochastic orientation and\nchirality, thereby providing a rich platform for magnetic fingerprinting. This\napproach enables self-protected primitives, including true random number\ngenerators, physical unclonable functions, and in-memory probabilistic\ninference. The resulting reconfigurable architecture combines tamper\nresistance, low energy consumption, and scalability, marking a significant leap\ntoward next-generation hardware security rooted in emergent magnetic phenomena.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u78c1\u79bb\u5b50\u7b56\u7565\u7684\u786c\u4ef6\u7ea7\u5b89\u5168\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u63a7\u7535\u538bN3-\u79bb\u5b50\u8fc1\u79fb\u548c\u94c1\u78c1\u4e9a\u5c42\u5b9e\u73b0\u591a\u79cd\u78c1\u72b6\u6001\uff0c\u5f62\u6210\u4e30\u5bcc\u7684\u78c1\u6307\u7eb9\u5e73\u53f0\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u81ea\u4fdd\u62a4\u539f\u8bed\u3001\u968f\u673a\u6570\u751f\u6210\u5668\u548c\u4e0d\u53ef\u514b\u9686\u529f\u80fd\u7b49\uff0c\u5e76\u5177\u6709\u4f4e\u80fd\u8017\u3001\u53ef\u91cd\u6784\u6027\u548c\u6269\u5c55\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u786c\u4ef6\u5b89\u5168\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002", "motivation": "\u5927\u6570\u636e\u9769\u547d\u63d0\u9ad8\u4e86\u5bf9\u7a33\u5065\u3001\u8282\u80fd\u7684\u5b89\u5168\u786c\u4ef6\u7684\u9700\u6c42\uff0c\u4f20\u7edf\u52a0\u5bc6\u65b9\u6848\u8d44\u6e90\u5bc6\u96c6\u4e14\u5b58\u5728\u6f0f\u6d1e\uff0c\u793e\u4f1a\u9700\u8981\u521b\u65b0\u7684\u53cd\u9ed1\u5ba2\u548c\u53cd\u4f2a\u9020\u6280\u672f\u3002", "method": "\u4f7f\u7528\u5b8c\u5168\u9009\u62e9\u6027\u7684\u7535\u538b\u63a7\u5236N3-\u79bb\u5b50\u5728\u9884\u5148\u5b9a\u4e49\u7684\u521d\u59cb\u987a\u78c1\u6027FeCoN\u70b9\u5185\u8fc1\u79fb\uff0c\u751f\u6210\u539a\u5ea6\u53ef\u8c03\u7684\u94c1\u78c1\u4e9a\u5c42\uff0c\u5f62\u6210\u786e\u5b9a\u6027\u6216\u6982\u7387\u6027\u7684\u78c1\u72b6\u6001\u3002", "result": "\u5b9e\u73b0\u4e86\u81ea\u4fdd\u62a4\u539f\u8bed\u3001\u771f\u6b63\u7684\u968f\u673a\u6570\u751f\u6210\u5668\u3001\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570\u548c\u5185\u5b58\u4e2d\u6982\u7387\u63a8\u7406\uff0c\u67b6\u6784\u5177\u5907\u6297\u7be1\u6539\u6027\u3001\u4f4e\u80fd\u8017\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6807\u5fd7\u7740\u5411\u57fa\u4e8e\u65b0\u5174\u78c1\u73b0\u8c61\u7684\u65b0\u4e00\u4ee3\u786c\u4ef6\u5b89\u5168\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2507.14172", "pdf": "https://arxiv.org/pdf/2507.14172", "abs": "https://arxiv.org/abs/2507.14172", "authors": ["Julien Pourcel", "C\u00e9dric Colas", "Pierre-Yves Oudeyer"], "title": "Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Many program synthesis tasks prove too challenging for even state-of-the-art\nlanguage models to solve in single attempts. Search-based evolutionary methods\noffer a promising alternative by exploring solution spaces iteratively, but\ntheir effectiveness remain limited by the fixed capabilities of the underlying\ngenerative model.\n  We propose SOAR, a method that learns program synthesis by integrating\nlanguage models into a self-improving evolutionary loop.\n  SOAR alternates between (1) an evolutionary search that uses an LLM to sample\nand refine candidate solutions, and (2) a hindsight learning phase that\nconverts search attempts into valid problem-solution pairs used to fine-tune\nthe LLM's sampling and refinement capabilities\\, -- \\,enabling increasingly\neffective search in subsequent iterations.\n  On the challenging ARC-AGI benchmark, SOAR achieves significant performance\ngains across model scales and iterations, leveraging positive transfer between\nthe sampling and refinement finetuning tasks. These improvements carry over to\ntest-time adaptation, enabling SOAR to solve 52\\% of the public test set. Our\ncode is open-sourced at: https://github.com/flowersteam/SOAR", "AI": {"tldr": "SOAR\u662f\u4e00\u79cd\u5c06\u8bed\u8a00\u6a21\u578b\u6574\u5408\u8fdb\u81ea\u6211\u6539\u8fdb\u8fdb\u5316\u5faa\u73af\u4ee5\u5b66\u4e60\u7a0b\u5e8f\u5408\u6210\u7684\u65b9\u6cd5\uff0c\u5728ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSOAR\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u8bb8\u591a\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u6765\u8bf4\u4ecd\u7136\u8fc7\u4e8e\u590d\u6742\uff0c\u800c\u57fa\u4e8e\u641c\u7d22\u7684\u8fdb\u5316\u65b9\u6cd5\u7531\u4e8e\u751f\u6210\u6a21\u578b\u80fd\u529b\u7684\u9650\u5236\uff0c\u6548\u679c\u4e5f\u6709\u9650\u3002", "method": "SOAR\u4ea4\u66ff\u8fdb\u884c\uff081\uff09\u4f7f\u7528LLM\u91c7\u6837\u548c\u4f18\u5316\u5019\u9009\u89e3\u51b3\u65b9\u6848\u7684\u8fdb\u5316\u641c\u7d22\uff1b\uff082\uff09\u4e8b\u540e\u5b66\u4e60\u9636\u6bb5\uff0c\u8be5\u9636\u6bb5\u5c06\u641c\u7d22\u5c1d\u8bd5\u8f6c\u6362\u4e3a\u6709\u6548\u7684\u95ee-\u89e3\u5bf9\uff0c\u7528\u4e8e\u5fae\u8c03LLM\u7684\u91c7\u6837\u548c\u4f18\u5316\u80fd\u529b\uff0c\u4ece\u800c\u5728\u540e\u7eed\u8fed\u4ee3\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u641c\u7d22\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684ARC-AGI\u57fa\u51c6\u4e0a\uff0cSOAR\u5b9e\u73b0\u4e86\u8de8\u6a21\u578b\u89c4\u6a21\u548c\u8fed\u4ee3\u7684\u663e\u8457\u6027\u80fd\u589e\u76ca\uff0c\u5e76\u4e14\u80fd\u591f\u89e3\u51b352%\u7684\u516c\u5171\u6d4b\u8bd5\u96c6\u3002", "conclusion": "SOAR\u901a\u8fc7\u6574\u5408\u8bed\u8a00\u6a21\u578b\u8fdb\u5165\u81ea\u6539\u5584\u7684\u8fdb\u5316\u5faa\u73af\u6765\u5b66\u4e60\u7a0b\u5e8f\u5408\u6210\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2507.14222", "pdf": "https://arxiv.org/pdf/2507.14222", "abs": "https://arxiv.org/abs/2507.14222", "authors": ["Shu-Ting Huang", "Wen-Cheng Chung", "Hao-Ting Pai"], "title": "GPU-Accelerated Interpretable Generalization for Rapid Cyberattack Detection and Forensics", "categories": ["cs.CR"], "comment": "ACM CCS 2025 (Submitted)", "summary": "The Interpretable Generalization (IG) mechanism recently published in IEEE\nTransactions on Information Forensics and Security delivers state-of-the-art,\nevidence-based intrusion detection by discovering coherent normal and attack\npatterns through exhaustive intersect-and-subset operations-yet its cubic-time\ncomplexity and large intermediate bitsets render full-scale datasets\nimpractical on CPUs. We present IG-GPU, a PyTorch re-architecture that offloads\nall pairwise intersections and subset evaluations to commodity GPUs.\nImplemented on a single NVIDIA RTX 4070 Ti, in the 15k-record NSL-KDD dataset,\nIG-GPU shows a 116-fold speed-up over the multi-core CPU implementation of IG.\nIn the full size of NSL-KDD (148k-record), given small training data (e.g.,\n10%-90% train-test split), IG-GPU runs in 18 minutes with Recall 0.957,\nPrecision 0.973, and AUC 0.961, whereas IG required down-sampling to\n15k-records to avoid memory exhaustion and obtained Recall 0.935, Precision\n0.942, and AUC 0.940. The results confirm that IG-GPU is robust across scales\nand could provide millisecond-level per-flow inference once patterns are\nlearned. IG-GPU thus bridges the gap between rigorous interpretability and\nreal-time cyber-defense, offering a portable foundation for future work on\nhardware-aware scheduling, multi-GPU sharding, and dataset-specific sparsity\noptimizations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86IG-GPU\uff0c\u4e00\u79cd\u5728\u5546\u54c1GPU\u4e0a\u91cd\u65b0\u67b6\u6784\u7684PyTorch\u5b9e\u73b0\uff0c\u7528\u4e8e\u52a0\u901fInterpretable Generalization\u673a\u5236\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cIG-GPU\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u6bd4\u591a\u6838CPU\u5feb116\u500d\uff0c\u5e76\u4e14\u5177\u6709\u9ad8\u53ec\u56de\u7387\u3001\u7cbe\u786e\u7387\u548cAUC\u503c\u3002", "motivation": "Interpretable Generalization\uff08IG\uff09\u673a\u5236\u867d\u7136\u53ef\u4ee5\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u5165\u4fb5\u68c0\u6d4b\uff0c\u4f46\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\u7acb\u65b9\u7ea7\u522b\uff0c\u5e9e\u5927\u7684\u4e2d\u95f4\u4f4d\u56fe\u4f7f\u5f97\u5168\u89c4\u6a21\u6570\u636e\u96c6\u5728CPU\u4e0a\u7684\u5904\u7406\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u5f0f\u6765\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86IG-GPU\uff0c\u5c06\u6240\u6709\u6210\u5bf9\u4ea4\u96c6\u548c\u5b50\u96c6\u8bc4\u4f30\u5378\u8f7d\u5230\u5546\u54c1GPU\u4e0a\uff0c\u4f7f\u7528PyTorch\u91cd\u65b0\u6784\u5efa\u4e86IG\u7b97\u6cd5\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u5e76\u80fd\u591f\u5904\u7406\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u3002", "result": "\u5728NSL-KDD\u6570\u636e\u96c6\u4e0a\uff0cIG-GPU\u6bd4\u591a\u6838CPU\u5b9e\u73b0\u7684IG\u901f\u5ea6\u5feb116\u500d\uff0c\u540c\u65f6\u5728\u5b8c\u6574\u89c4\u6a21\u7684\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684Recall\u3001Precision\u548cAUC\u503c\u3002\u6b64\u5916\uff0cIG-GPU\u80fd\u591f\u5728\u6a21\u5f0f\u5b66\u4e60\u540e\u63d0\u4f9b\u6beb\u79d2\u7ea7\u522b\u7684\u6d41\u63a8\u7406\u3002", "conclusion": "IG-GPU\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5904\u7406\u901f\u5ea6\uff0c\u8fd8\u4fdd\u6301\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765\u5173\u4e8e\u786c\u4ef6\u611f\u77e5\u8c03\u5ea6\u3001\u591aGPU\u5206\u7247\u548c\u6570\u636e\u96c6\u7279\u5b9a\u7a00\u758f\u4f18\u5316\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4fbf\u643a\u7684\u57fa\u7840\u3002"}}
{"id": "2507.14175", "pdf": "https://arxiv.org/pdf/2507.14175", "abs": "https://arxiv.org/abs/2507.14175", "authors": ["Youcef Barkat", "Dylan Hamitouche", "Deven Parekh", "Ivy Guo", "David Benrimoh"], "title": "Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "Background: Mental illnesses such as depression and anxiety require improved\nmethods for early detection and personalized intervention. Traditional\npredictive models often rely on unimodal data or early fusion strategies that\nfail to capture the complex, multimodal nature of psychiatric data. Advanced\nintegration techniques, such as intermediate (latent space) fusion, may offer\nbetter accuracy and clinical utility. Methods: Using data from the BRIGHTEN\nclinical trial, we evaluated intermediate (latent space) fusion for predicting\ndaily depressive symptoms (PHQ-2 scores). We compared early fusion implemented\nwith a Random Forest (RF) model and intermediate fusion implemented via a\nCombined Model (CM) using autoencoders and a neural network. The dataset\nincluded behavioral (smartphone-based), demographic, and clinical features.\nExperiments were conducted across multiple temporal splits and data stream\ncombinations. Performance was evaluated using mean squared error (MSE) and\ncoefficient of determination (R2). Results: The CM outperformed both RF and\nLinear Regression (LR) baselines across all setups, achieving lower MSE (0.4985\nvs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed\nsigns of overfitting, with a large gap between training and test performance,\nwhile the CM maintained consistent generalization. Performance was best when\nintegrating all data modalities in the CM (in contradistinction to RF),\nunderscoring the value of latent space fusion for capturing non-linear\ninteractions in complex psychiatric datasets. Conclusion: Latent space fusion\noffers a robust alternative to traditional fusion methods for prediction with\nmultimodal mental health data. Future work should explore model\ninterpretability and individual-level prediction for clinical deployment.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528BRIGHTEN\u4e34\u5e8a\u8bd5\u9a8c\u7684\u6570\u636e\uff0c\u901a\u8fc7\u6bd4\u8f83\u968f\u673a\u68ee\u6797\u6a21\u578b\u548c\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u7ec4\u5408\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86\u4e2d\u95f4\u878d\u5408\uff08\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\uff09\u5728\u9884\u6d4b\u65e5\u5e38\u6291\u90c1\u75c7\u72b6\u65b9\u9762\u7684\u6027\u80fd\u3002\u7ec4\u5408\u6a21\u578b\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u6574\u5408\u6240\u6709\u6570\u636e\u6a21\u5f0f\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u663e\u793a\u51fa\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u5728\u6355\u6349\u590d\u6742\u7cbe\u795e\u5065\u5eb7\u6570\u636e\u96c6\u4e2d\u7684\u975e\u7ebf\u6027\u4ea4\u4e92\u4f5c\u7528\u7684\u4ef7\u503c\u3002", "motivation": "\u6291\u90c1\u75c7\u548c\u7126\u8651\u75c7\u7b49\u7cbe\u795e\u75be\u75c5\u9700\u8981\u6539\u8fdb\u65e9\u671f\u68c0\u6d4b\u548c\u4e2a\u4eba\u5316\u5e72\u9884\u7684\u65b9\u6cd5\u3002\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u5355\u6a21\u6001\u6570\u636e\u6216\u65e9\u671f\u878d\u5408\u7b56\u7565\uff0c\u65e0\u6cd5\u6355\u6349\u7cbe\u795e\u75c5\u5b66\u6570\u636e\u7684\u590d\u6742\u591a\u6a21\u6001\u6027\u8d28\u3002\u9ad8\u7ea7\u96c6\u6210\u6280\u672f\u5982\u4e2d\u95f4\u878d\u5408\uff08\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\uff09\u53ef\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "method": "\u4f7f\u7528\u6765\u81eaBRIGHTEN\u4e34\u5e8a\u8bd5\u9a8c\u7684\u6570\u636e\uff0c\u8bc4\u4f30\u4e86\u4e2d\u95f4\u878d\u5408\uff08\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\uff09\u5bf9\u9884\u6d4b\u65e5\u5e38\u6291\u90c1\u75c7\u72b6\uff08PHQ-2\u8bc4\u5206\uff09\u7684\u6548\u679c\u3002\u5c06\u65e9\u671f\u878d\u5408\u5b9e\u73b0\u7684\u968f\u673a\u68ee\u6797\u6a21\u578b\u4e0e\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u7684\u7ec4\u5408\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002\u6570\u636e\u96c6\u5305\u62ec\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u884c\u4e3a\u3001\u4eba\u53e3\u7edf\u8ba1\u548c\u4e34\u5e8a\u7279\u5f81\u3002\u5b9e\u9a8c\u5728\u591a\u4e2a\u65f6\u95f4\u5206\u5272\u548c\u6570\u636e\u6d41\u7ec4\u5408\u4e0a\u8fdb\u884c\u3002\u6027\u80fd\u8bc4\u4f30\u4f7f\u7528\u5e73\u5747\u5e73\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u51b3\u5b9a\u7cfb\u6570\uff08R2\uff09\u3002", "result": "\u7ec4\u5408\u6a21\u578b\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e\u968f\u673a\u68ee\u6797\u548c\u7ebf\u6027\u56de\u5f52\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684MSE\uff080.4985 vs. 0.5305\uff09\u548c\u66f4\u9ad8\u7684R2\uff080.4695 vs. 0.4356\uff09\u3002\u968f\u673a\u68ee\u6797\u6a21\u578b\u663e\u793a\u51fa\u8fc7\u62df\u5408\u7684\u8ff9\u8c61\uff0c\u800c\u7ec4\u5408\u6a21\u578b\u4fdd\u6301\u4e86\u4e00\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5f53\u5728\u7ec4\u5408\u6a21\u578b\u4e2d\u6574\u5408\u6240\u6709\u6570\u636e\u6a21\u6001\u65f6\uff0c\u6027\u80fd\u6700\u4f73\uff0c\u5f3a\u8c03\u4e86\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u6355\u6349\u590d\u6742\u7cbe\u795e\u75c5\u5b66\u6570\u636e\u96c6\u4e2d\u975e\u7ebf\u6027\u4ea4\u4e92\u4f5c\u7528\u7684\u4ef7\u503c\u3002", "conclusion": "\u6f5c\u5728\u7a7a\u95f4\u878d\u5408\u4e3a\u4f7f\u7528\u591a\u6a21\u6001\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u66f4\u7a33\u5065\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u63a2\u7d22\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u4e2a\u4f53\u6c34\u5e73\u9884\u6d4b\u4ee5\u4f9b\u4e34\u5e8a\u90e8\u7f72\u3002"}}
{"id": "2507.14223", "pdf": "https://arxiv.org/pdf/2507.14223", "abs": "https://arxiv.org/abs/2507.14223", "authors": ["Wen-Cheng Chung", "Shu-Ting Huang", "Hao-Ting Pai"], "title": "Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification", "categories": ["cs.CR", "cs.AI"], "comment": "ACM CCS 2025 (Submitted)", "summary": "Explainable intrusion detection systems (IDS) are now recognized as essential\nfor mission-critical networks, yet most \"XAI\" pipelines still bolt an\napproximate explainer onto an opaque classifier, leaving analysts with partial\nand sometimes misleading insights. The Interpretable Generalization (IG)\nmechanism, published in IEEE Transactions on Information Forensics and\nSecurity, eliminates that bottleneck by learning coherent patterns - feature\ncombinations unique to benign or malicious traffic - and turning them into\nfully auditable rules. IG already delivers outstanding precision, recall, and\nAUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the\ndata. To raise precision further without sacrificing transparency, we introduce\nMulti-Granular Discretization (IG-MD), which represents every continuous\nfeature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts\nprecision by greater than or equal to 4 percentage points across all nine\ntrain-test splits while preserving recall approximately equal to 1.0,\ndemonstrating that a single interpretation-ready model can scale across domains\nwithout bespoke tuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u673a\u5236IG-MD\uff0c\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u800c\u4e0d\u727a\u7272\u900f\u660e\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684XAI\u7ba1\u9053\u63d0\u4f9b\u7684\u89c1\u89e3\u4e0d\u5b8c\u6574\u4e14\u6709\u65f6\u5177\u6709\u8bef\u5bfc\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u673a\u5236\u6765\u63d0\u4f9b\u5168\u9762\u548c\u51c6\u786e\u7684\u89c1\u89e3\u3002", "method": "\u5f15\u5165\u4e86\u591a\u7c92\u5ea6\u79bb\u6563\u5316\uff08IG-MD\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ee5\u591a\u79cd\u9ad8\u65af\u5206\u8fa8\u7387\u8868\u793a\u6bcf\u4e2a\u8fde\u7eed\u7279\u5f81\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u89e3\u91ca\u6027\u6cdb\u5316\u673a\u5236\u4e2d\u3002", "result": "\u5728UKM-IDS20\u6570\u636e\u96c6\u4e0a\uff0cIG-MD\u5c06\u7cbe\u5ea6\u63d0\u9ad8\u4e86\u81f3\u5c114\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u53ec\u56de\u7387\u63a5\u8fd11.0\u3002", "conclusion": "IG-MD\u6a21\u578b\u53ef\u4ee5\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u6269\u5c55\uff0c\u800c\u65e0\u9700\u4e13\u95e8\u8c03\u6574\u3002"}}
{"id": "2507.14176", "pdf": "https://arxiv.org/pdf/2507.14176", "abs": "https://arxiv.org/abs/2507.14176", "authors": ["Andr\u00e9s Morales-Forero", "Lili J. Rueda", "Ronald Herrera", "Samuel Bassetto", "Eric Coatanea"], "title": "Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "Artificial intelligence (AI) systems increasingly inform medical\ndecision-making, yet concerns about algorithmic bias and inequitable outcomes\npersist, particularly for historically marginalized populations. This paper\nintroduces the concept of Predictive Representativity (PR), a framework of\nfairness auditing that shifts the focus from the composition of the data set to\noutcomes-level equity. Through a case study in dermatology, we evaluated\nAI-based skin cancer classifiers trained on the widely used HAM10000 dataset\nand on an independent clinical dataset (BOSQUE Test set) from Colombia. Our\nanalysis reveals substantial performance disparities by skin phototype, with\nclassifiers consistently underperforming for individuals with darker skin,\ndespite proportional sampling in the source data. We argue that\nrepresentativity must be understood not as a static feature of datasets but as\na dynamic, context-sensitive property of model predictions. PR operationalizes\nthis shift by quantifying how reliably models generalize fairness across\nsubpopulations and deployment contexts. We further propose an External\nTransportability Criterion that formalizes the thresholds for fairness\ngeneralization. Our findings highlight the ethical imperative for post-hoc\nfairness auditing, transparency in dataset documentation, and inclusive model\nvalidation pipelines. This work offers a scalable tool for diagnosing\nstructural inequities in AI systems, contributing to discussions on equity,\ninterpretability, and data justice and fostering a critical re-evaluation of\nfairness in data-driven healthcare.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\u7684\u6982\u5ff5\uff0c\u4f5c\u4e3a\u4e00\u79cd\u516c\u5e73\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u5f3a\u8c03\u6a21\u578b\u9884\u6d4b\u7684\u52a8\u6001\u3001\u60c5\u5883\u654f\u611f\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7\u76ae\u80a4\u764c\u5206\u7c7b\u6848\u4f8b\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u80a4\u8272\u4eba\u7fa4\u7684\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u9274\u4e8e\u5bf9\u7b97\u6cd5\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u7ed3\u679c\u7684\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u5bf9\u5386\u53f2\u4e0a\u88ab\u8fb9\u7f18\u5316\u7684\u7fa4\u4f53\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u516c\u5e73\u6027\u5ba1\u8ba1\u65b9\u6cd5\u2014\u2014\u9884\u6d4b\u4ee3\u8868\u6027\uff08PR\uff09\uff0c\u5c06\u5173\u6ce8\u70b9\u4ece\u6570\u636e\u96c6\u7ec4\u6210\u8f6c\u5411\u7ed3\u679c\u6c34\u5e73\u7684\u516c\u5e73\u6027\u3002", "method": "\u901a\u8fc7\u5bf9HAM10000\u6570\u636e\u96c6\u548c\u6765\u81ea\u54e5\u4f26\u6bd4\u4e9a\u7684\u72ec\u7acb\u4e34\u5e8a\u6570\u636e\u96c6\uff08BOSQUE\u6d4b\u8bd5\u96c6\uff09\u8bad\u7ec3\u7684\u57fa\u4e8eAI\u7684\u76ae\u80a4\u764c\u5206\u7c7b\u5668\u8fdb\u884c\u8bc4\u4f30\uff0c\u5206\u6790\u4e0d\u540c\u80a4\u8272\u7c7b\u578b\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u5916\u90e8\u53ef\u8fd0\u8f93\u6027\u6807\u51c6\u6765\u5f62\u5f0f\u5316\u516c\u5e73\u6cdb\u5316\u7684\u9608\u503c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6e90\u6570\u636e\u4e2d\u8fdb\u884c\u4e86\u6bd4\u4f8b\u62bd\u6837\uff0c\u4f46\u9488\u5bf9\u80a4\u8272\u8f83\u6df1\u4e2a\u4f53\u7684\u5206\u7c7b\u5668\u8868\u73b0\u59cb\u7ec8\u8f83\u5dee\uff0c\u63ed\u793a\u4e86\u6309\u80a4\u8272\u5212\u5206\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u4f5c\u8005\u547c\u5401\u8fdb\u884c\u4e8b\u540e\u516c\u5e73\u6027\u5ba1\u8ba1\u3001\u63d0\u9ad8\u6570\u636e\u96c6\u6587\u6863\u7684\u900f\u660e\u5ea6\u4ee5\u53ca\u5efa\u7acb\u5305\u5bb9\u6027\u7684\u6a21\u578b\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4ee5\u5e94\u5bf9\u6570\u636e\u9a71\u52a8\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u95ee\u9898\u3002"}}
{"id": "2507.14229", "pdf": "https://arxiv.org/pdf/2507.14229", "abs": "https://arxiv.org/abs/2507.14229", "authors": ["Vanja Stojanovi\u0107", "\u017diga Lesar", "CIril Bohak"], "title": "Using Modular Arithmetic Optimized Neural Networks To Crack Affine Cryptographic Schemes Efficiently", "categories": ["cs.CR"], "comment": null, "summary": "We investigate the cryptanalysis of affine ciphers using a hybrid neural\nnetwork architecture that combines modular arithmetic-aware and statistical\nfeature-based learning. Inspired by recent advances in interpretable neural\nnetworks for modular arithmetic and neural cryptanalysis of classical ciphers,\nour approach integrates a modular branch that processes raw ciphertext\nsequences and a statistical branch that leverages letter frequency features.\nExperiments on datasets derived from natural English text demonstrate that the\nhybrid model attains high key recovery accuracy for short and moderate\nciphertexts, outperforming purely statistical approaches for the affine cipher.\nHowever, performance degrades for very long ciphertexts, highlighting\nchallenges in model generalization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u6a21\u7b97\u672f\u611f\u77e5\u548c\u7edf\u8ba1\u7279\u5f81\u5b66\u4e60\u7684\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u4eff\u5c04\u5bc6\u7801\u7684\u5bc6\u7801\u5206\u6790\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u77ed\u5230\u4e2d\u7b49\u957f\u5ea6\u7684\u5bc6\u6587\uff0c\u8be5\u6a21\u578b\u5728\u5bc6\u94a5\u6062\u590d\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u7eaf\u7edf\u8ba1\u65b9\u6cd5\uff1b\u4f46\u5bf9\u4e8e\u975e\u5e38\u957f\u7684\u5bc6\u6587\uff0c\u6027\u80fd\u6709\u6240\u4e0b\u964d\u3002", "motivation": "\u53d7\u5230\u53ef\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u5728\u6a21\u7b97\u672f\u548c\u7ecf\u5178\u5bc6\u7801\u795e\u7ecf\u5bc6\u7801\u5206\u6790\u65b9\u9762\u6700\u65b0\u8fdb\u5c55\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5229\u7528\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u6765\u6539\u8fdb\u5bf9\u4eff\u5c04\u5bc6\u7801\u7684\u5bc6\u7801\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5c06\u5904\u7406\u539f\u59cb\u5bc6\u6587\u5e8f\u5217\u7684\u6a21\u5206\u652f\u548c\u5229\u7528\u5b57\u6bcd\u9891\u7387\u7279\u5f81\u7684\u7edf\u8ba1\u5206\u652f\u76f8\u7ed3\u5408\uff0c\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6765\u8fdb\u884c\u4eff\u5c04\u5bc6\u7801\u7684\u5bc6\u7801\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u81ea\u7136\u82f1\u8bed\u6587\u672c\u6570\u636e\u96c6\u4e0a\u5bf9\u77ed\u5230\u4e2d\u7b49\u957f\u5ea6\u7684\u5bc6\u6587\u5b9e\u73b0\u4e86\u9ad8\u5bc6\u94a5\u6062\u590d\u51c6\u786e\u6027\uff0c\u8d85\u8fc7\u4e86\u7eaf\u7edf\u8ba1\u65b9\u6cd5\u7684\u6548\u679c\u3002\u4f46\u662f\uff0c\u5bf9\u4e8e\u975e\u5e38\u957f\u7684\u5bc6\u6587\uff0c\u6027\u80fd\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u867d\u7136\u6240\u63d0\u51fa\u7684\u6df7\u5408\u6a21\u578b\u5728\u77ed\u5230\u4e2d\u7b49\u957f\u5ea6\u7684\u5bc6\u6587\u4e0a\u6709\u5f88\u597d\u7684\u8868\u73b0\uff0c\u4f46\u5176\u5728\u957f\u5bc6\u6587\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u8bf4\u660e\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2507.14177", "pdf": "https://arxiv.org/pdf/2507.14177", "abs": "https://arxiv.org/abs/2507.14177", "authors": ["Changcun Huang"], "title": "Understanding Two-Layer Neural Networks with Smooth Activation Functions", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "68T07(Primary), 41A15(Secondary)", "I.2.6; G.1.2"], "comment": null, "summary": "This paper aims to understand the training solution, which is obtained by the\nback-propagation algorithm, of two-layer neural networks whose hidden layer is\ncomposed of the units with smooth activation functions, including the usual\nsigmoid type most commonly used before the advent of ReLUs. The mechanism\ncontains four main principles: construction of Taylor series expansions, strict\npartial order of knots, smooth-spline implementation and smooth-continuity\nrestriction. The universal approximation for arbitrary input dimensionality is\nproved and experimental verification is given, through which the mystery of\n``black box'' of the solution space is largely revealed. The new proofs\nemployed also enrich approximation theory.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u6cf0\u52d2\u7ea7\u6570\u5c55\u5f00\u3001\u4e25\u683c\u7684\u504f\u5e8f\u8282\u70b9\u3001\u5e73\u6ed1\u6837\u6761\u5b9e\u73b0\u548c\u5e73\u6ed1\u8fde\u7eed\u6027\u9650\u5236\u56db\u4e2a\u4e3b\u8981\u539f\u5219\uff0c\u89e3\u6790\u4e86\u4f7f\u7528\u5e73\u6ed1\u6fc0\u6d3b\u51fd\u6570\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5bf9\u4e8e\u4efb\u610f\u8f93\u5165\u7ef4\u5ea6\u7684\u901a\u7528\u8fd1\u4f3c\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u5bf9\u5177\u6709\u5e73\u6ed1\u6fc0\u6d3b\u51fd\u6570\uff08\u5982\u4f20\u7edf\u7684sigmoid\u7c7b\u578b\uff09\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u9690\u85cf\u5c42\u5f97\u5230\u7684\u8bad\u7ec3\u89e3\uff0c\u63ed\u793a\u201c\u9ed1\u7bb1\u201d\u7684\u89e3\u7a7a\u95f4\u79d8\u5bc6\u3002", "method": "\u4f7f\u7528\u6784\u5efa\u6cf0\u52d2\u7ea7\u6570\u5c55\u5f00\u3001\u4e25\u683c\u7684\u504f\u5e8f\u8282\u70b9\u3001\u5e73\u6ed1\u6837\u6761\u5b9e\u73b0\u548c\u5e73\u6ed1\u8fde\u7eed\u6027\u9650\u5236\u8fd9\u56db\u4e2a\u4e3b\u8981\u539f\u5219\u6765\u7814\u7a76\u548c\u8bc1\u660e\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u89e3\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u4efb\u610f\u8f93\u5165\u7ef4\u5ea6\u7684\u901a\u7528\u8fd1\u4f3c\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u6709\u52a9\u4e8e\u63ed\u793a\u89e3\u7a7a\u95f4\u7684\u795e\u79d8\u9762\u7eb1\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e0d\u4ec5\u63ed\u793a\u4e86\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u89e3\u7a7a\u95f4\u7279\u6027\uff0c\u8fd8\u4e30\u5bcc\u4e86\u8fd1\u4f3c\u7406\u8bba\u3002"}}
{"id": "2507.14248", "pdf": "https://arxiv.org/pdf/2507.14248", "abs": "https://arxiv.org/abs/2507.14248", "authors": ["Eldor Abdukhamidov", "Mohammed Abuhamad", "Simon S. Woo", "Hyoungshick Kim", "Tamer Abuhmed"], "title": "Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG", "I.2.10; I.2.6; I.5.1; D.4.6; K.6.5"], "comment": null, "summary": "Vision transformer (ViT) models, when coupled with interpretation models, are\nregarded as secure and challenging to deceive, making them well-suited for\nsecurity-critical domains such as medical applications, autonomous vehicles,\ndrones, and robotics. However, successful attacks on these systems can lead to\nsevere consequences. Recent research on threats targeting ViT models primarily\nfocuses on generating the smallest adversarial perturbations that can deceive\nthe models with high confidence, without considering their impact on model\ninterpretations. Nevertheless, the use of interpretation models can effectively\nassist in detecting adversarial examples. This study investigates the\nvulnerability of transformer models to adversarial attacks, even when combined\nwith interpretation models. We propose an attack called \"AdViT\" that generates\nadversarial examples capable of misleading both a given transformer model and\nits coupled interpretation model. Through extensive experiments on various\ntransformer models and two transformer-based interpreters, we demonstrate that\nAdViT achieves a 100% attack success rate in both white-box and black-box\nscenarios. In white-box scenarios, it reaches up to 98% misclassification\nconfidence, while in black-box scenarios, it reaches up to 76%\nmisclassification confidence. Remarkably, AdViT consistently generates accurate\ninterpretations in both scenarios, making the adversarial examples more\ndifficult to detect.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cAdViT\u201d\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u573a\u666f\u4e2d\u4ee5100%\u7684\u6210\u529f\u7387\u8bef\u5bfc\u89c6\u89c9\u8f6c\u6362\u5668\u6a21\u578b\u53ca\u5176\u89e3\u91ca\u6a21\u578b\uff0c\u540c\u65f6\u751f\u6210\u96be\u4ee5\u68c0\u6d4b\u7684\u5bf9\u6297\u6837\u672c\u3002", "motivation": "\u5c3d\u7ba1\u89c6\u89c9\u8f6c\u6362\u5668\uff08ViT\uff09\u6a21\u578b\u7ed3\u5408\u89e3\u91ca\u6a21\u578b\u88ab\u8ba4\u4e3a\u662f\u5b89\u5168\u4e14\u96be\u4ee5\u6b3a\u9a97\u7684\uff0c\u4f46\u9488\u5bf9\u8fd9\u4e9b\u7cfb\u7edf\u7684\u6210\u529f\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\u3002\u76ee\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u751f\u6210\u6700\u5c0f\u7684\u5bf9\u6297\u6027\u6270\u52a8\u4e0a\uff0c\u800c\u5ffd\u7565\u4e86\u5bf9\u6a21\u578b\u89e3\u91ca\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u5f53\u7ed3\u5408\u89e3\u91ca\u6a21\u578b\u65f6\uff0c\u53d8\u538b\u5668\u6a21\u578b\u5bf9\u5bf9\u6297\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e2a\u53eb\u505a\u201cAdViT\u201d\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u751f\u6210\u80fd\u591f\u8bef\u5bfc\u7ed9\u5b9a\u7684\u53d8\u538b\u5668\u6a21\u578b\u53ca\u5176\u8026\u5408\u7684\u89e3\u91ca\u6a21\u578b\u7684\u5bf9\u6297\u6837\u672c\u3002\u901a\u8fc7\u5728\u5404\u79cd\u53d8\u538b\u5668\u6a21\u578b\u548c\u4e24\u4e2a\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u89e3\u91ca\u5668\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86AdViT\u7684\u6709\u6548\u6027\u3002", "result": "AdViT\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u573a\u666f\u4e2d\u5747\u5b9e\u73b0\u4e86100%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002\u5728\u767d\u76d2\u573a\u666f\u4e2d\uff0c\u5b83\u8fbe\u5230\u4e86\u9ad8\u8fbe98%\u7684\u9519\u8bef\u5206\u7c7b\u7f6e\u4fe1\u5ea6\uff0c\u800c\u5728\u9ed1\u76d2\u573a\u666f\u4e2d\uff0c\u8fd9\u4e00\u6570\u5b57\u4e3a76%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cAdViT\u5728\u8fd9\u4e24\u79cd\u573a\u666f\u4e0b\u90fd\u80fd\u4e00\u81f4\u5730\u751f\u6210\u51c6\u786e\u7684\u89e3\u91ca\uff0c\u4f7f\u5bf9\u6297\u6837\u672c\u66f4\u96be\u88ab\u68c0\u6d4b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u7ed3\u5408\u4e86\u89e3\u91ca\u6a21\u578b\uff0c\u89c6\u89c9\u8f6c\u6362\u5668\u6a21\u578b\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\u7684\u5f71\u54cd\u3002\u8fd9\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u7684\u5b89\u5168\u673a\u5236\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u4fdd\u62a4\u5173\u952e\u9886\u57df\u4e2d\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2507.14178", "pdf": "https://arxiv.org/pdf/2507.14178", "abs": "https://arxiv.org/abs/2507.14178", "authors": ["Yuhang Liu", "Yuefei Wu", "Bin Shi", "Bo Dong"], "title": "Feature Bank Enhancement for Distance-based Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nof deep learning applications and has attracted significant attention in recent\nyears. A rich body of literature has emerged to develop efficient score\nfunctions that assign high scores to in-distribution (ID) samples and low\nscores to OOD samples, thereby helping distinguish OOD samples. Among these\nmethods, distance-based score functions are widely used because of their\nefficiency and ease of use. However, deep learning often leads to a biased\ndistribution of data features, and extreme features are inevitable. These\nextreme features make the distance-based methods tend to assign too low scores\nto ID samples. This limits the OOD detection capabilities of such methods. To\naddress this issue, we propose a simple yet effective method, Feature Bank\nEnhancement (FBE), that uses statistical characteristics from dataset to\nidentify and constrain extreme features to the separation boundaries, therapy\nmaking the distance between samples inside and outside the distribution\nfarther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10\nrespectively, and the results show that our method achieves state-of-the-art\nperformance on both benchmark. Additionally, theoretical analysis and\nsupplementary experiments are conducted to provide more insights into our\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0cFeature Bank Enhancement (FBE)\uff0c\u7528\u4e8e\u589e\u5f3aOOD\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8ddd\u79bb\u7684\u8bc4\u5206\u51fd\u6570\u5728\u5904\u7406\u6df1\u5ea6\u5b66\u4e60\u5bfc\u81f4\u7684\u6570\u636e\u7279\u5f81\u504f\u5dee\u65f6\uff0c\u5f80\u5f80\u4f1a\u9519\u8bef\u5730\u7ed9ID\u6837\u672c\u8fc7\u4f4e\u7684\u8bc4\u5206\uff0c\u9650\u5236\u4e86\u5176OOD\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u7279\u5f81\u6765\u8bc6\u522b\u548c\u7ea6\u675f\u6781\u7aef\u7279\u5f81\u5230\u5206\u79bb\u8fb9\u754c\uff0c\u4ece\u800c\u589e\u52a0\u5206\u5e03\u5185\u5916\u6837\u672c\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u8fd9\u4e24\u4e2a\u57fa\u51c6\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u6548\u679c\u597d\uff0c\u800c\u4e14\u7406\u8bba\u5206\u6790\u548c\u8865\u5145\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u66f4\u591a\u5173\u4e8e\u8be5\u65b9\u6cd5\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.14324", "pdf": "https://arxiv.org/pdf/2507.14324", "abs": "https://arxiv.org/abs/2507.14324", "authors": ["Yao Ma", "Wen Yu Kon", "Jefferson Chu", "Kevin Han Yong Loh", "Kaushik Chakraborty", "Charles Lim"], "title": "Quantum-Safe Identity Verification using Relativistic Zero-Knowledge Proof Systems", "categories": ["cs.CR", "quant-ph"], "comment": null, "summary": "Identity verification is the process of confirming an individual's claimed\nidentity, which is essential in sectors like finance, healthcare, and online\nservices to ensure security and prevent fraud. However, current\npassword/PIN-based identity solutions are susceptible to phishing or skimming\nattacks, where malicious intermediaries attempt to steal credentials using fake\nidentification portals. Alikhani et al. [Nature, 2021] began exploring identity\nverification through graph coloring-based relativistic zero-knowledge proofs\n(RZKPs), a key cryptographic primitive that enables a prover to demonstrate\nknowledge of secret credentials to a verifier without disclosing any\ninformation about the secret. Our work advances this field and addresses\nunresolved issues: From an engineering perspective, we relax further the\nrelativistic constraints from 60m to 30m, and significantly enhance the\nstability and scalability of the experimental demonstration of the 2-prover\ngraph coloring-based RZKP protocol for near-term use cases. At the same time,\nfor long-term security against entangled malicious provers, we propose a\nmodified protocol with comparable computation and communication costs, we\nestablish an upper bound on the soundness parameter for this modified protocol.\nOn the other hand, we extend the two-prover, two-verifier setup to a\nthree-prover configuration, demonstrating the security of such relativistic\nprotocols against entangled malicious provers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6539\u8fdb\u56fe\u7740\u8272\u57fa\u7840\u7684\u76f8\u5bf9\u8bba\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\uff0c\u89e3\u51b3\u4e86\u8eab\u4efd\u9a8c\u8bc1\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u5305\u62ec\u51cf\u5c11\u76f8\u5bf9\u8bba\u7ea6\u675f\u3001\u589e\u5f3a\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u7ea0\u7f20\u6076\u610f\u9a8c\u8bc1\u8005\u7684\u4fee\u6539\u534f\u8bae\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5bc6\u7801/\u4e2a\u4eba\u8bc6\u522b\u7801\u7684\u8eab\u4efd\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\u5bb9\u6613\u53d7\u5230\u7f51\u7edc\u9493\u9c7c\u6216\u7a83\u53d6\u653b\u51fb\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0cAlikhani\u7b49\u4eba\u5f00\u59cb\u63a2\u7d22\u4f7f\u7528\u57fa\u4e8e\u56fe\u7740\u8272\u7684\u76f8\u5bf9\u8bba\u96f6\u77e5\u8bc6\u8bc1\u660e\u8fdb\u884c\u8eab\u4efd\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4ece\u5de5\u7a0b\u89d2\u5ea6\u8fdb\u4e00\u6b65\u653e\u677e\u4e86\u76f8\u5bf9\u8bba\u7ea6\u675f\u6761\u4ef6\uff0c\u589e\u5f3a\u4e862-\u9a8c\u8bc1\u8005\u56fe\u7740\u8272\u57fa\u7840\u7684RZKP\u534f\u8bae\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\uff1b\u63d0\u51fa\u4e86\u5177\u6709\u53ef\u6bd4\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u7684\u4fee\u6539\u534f\u8bae\uff1b\u8fd8\u5c06\u4e24\u9a8c\u8bc1\u8005\u8bbe\u7f6e\u6269\u5c55\u5230\u4e09\u9a8c\u8bc1\u8005\u914d\u7f6e\u3002", "result": "\u8be5\u7814\u7a76\u663e\u8457\u63d0\u9ad8\u4e86\u5b9e\u9a8c\u6f14\u793a\u7684\u7a33\u5b9a\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u5c06\u76f8\u5bf9\u8bba\u7ea6\u675f\u4ece60\u7c73\u964d\u4f4e\u523030\u7c73\uff0c\u5e76\u8bc1\u660e\u4e86\u4fee\u6539\u540e\u7684\u534f\u8bae\u5728\u957f\u671f\u5b89\u5168\u6027\u65b9\u9762\u5bf9\u7ea0\u7f20\u6076\u610f\u9a8c\u8bc1\u8005\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u6539\u8fdb\u4f7f\u57fa\u4e8e\u56fe\u7740\u8272\u7684\u76f8\u5bf9\u8bba\u96f6\u77e5\u8bc6\u8bc1\u660e\u66f4\u63a5\u8fd1\u5b9e\u7528\u5316\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u6027\u4fdd\u969c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u672a\u6765\u53ef\u80fd\u9047\u5230\u7684\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u3002"}}
{"id": "2507.14179", "pdf": "https://arxiv.org/pdf/2507.14179", "abs": "https://arxiv.org/abs/2507.14179", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": "To be published in Euro-Par 2025", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u7528\u4e8e\u6709\u6548\u9884\u6d4b\u548c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u4e3a\u5c11\u91cf\u7684\u4ee3\u8868\u7c07\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe79.34%\u7684\u805a\u7c7b\u7cbe\u5ea6\uff0c\u5e76\u5728\u4fdd\u6301\u4f4e\u56f0\u60d1\u5ea6\u5206\u6570\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c55\u793a\u51fa\u663e\u8457\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u5373\u5bf9\u4e8e\u7ed9\u5b9a\u8f93\u5165\uff0c\u53ea\u6709\u90e8\u5206\u795e\u7ecf\u5143\u662f\u6d3b\u8dc3\u7684\u3002\u8fd9\u79cd\u7a00\u758f\u6027\u63d0\u4f9b\u4e86\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u7684\u673a\u4f1a\uff0c\u4f46\u8981\u9ad8\u6548\u5730\u5229\u7528\u5b83\u9700\u8981\u4ee5\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u9884\u6d4b\u6fc0\u6d3b\u6a21\u5f0f\u3002\u7136\u800c\uff0c\u5728\u795e\u7ecf\u5143\u7ea7\u522b\u76f4\u63a5\u9884\u6d4b\u662f\u8ba1\u7b97\u6602\u8d35\u7684\uff0c\u56e0\u4e3a\u73b0\u4ee3LLMs\u4e2d\u5b58\u5728\u5927\u91cf\u7684\u795e\u7ecf\u5143\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u4e0d\u662f\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u795e\u7ecf\u5143\uff0c\u800c\u662f\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u6210\u4e00\u5c0f\u7fa4\u5177\u6709\u4ee3\u8868\u6027\u7684\u7c07\u3002", "result": "\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e86\u6700\u9ad879.34%\u7684\u805a\u7c7b\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u6807\u51c6\u4e8c\u8fdb\u5236\u805a\u7c7b\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u56f0\u60d1\u5ea6\u5206\u6570\u4e0b\u964d\u3002\u4f7f\u7528\u8db3\u591f\u6570\u91cf\u7684\u7c07\u65f6\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u83b7\u5f97\u4f4e\u81f312.49\u7684\u56f0\u60d1\u5ea6\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u9884\u6d4b\u7c07\u5206\u914d\u800c\u4e0d\u662f\u5355\u4e2a\u795e\u7ecf\u5143\u72b6\u6001\uff0c\u672a\u6765\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u9884\u8ba1\u7b97\u7684\u8d28\u5fc3\u63a8\u65ad\u6fc0\u6d3b\u6a21\u5f0f\u3002\u8fd9\u4e2a\u57fa\u4e8e\u805a\u7c7b\u7684\u516c\u5f0f\u4e3a\u6fc0\u6d3b\u6a21\u5f0f\u9884\u6d4b\u7684\u672a\u6765\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u63a8\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14519", "pdf": "https://arxiv.org/pdf/2507.14519", "abs": "https://arxiv.org/abs/2507.14519", "authors": ["Wenxuan Zeng", "Tianshi Xu", "Yi Chen", "Yifan Zhou", "Mingzhe Zhang", "Jin Tan", "Cheng Hong", "Meng Li"], "title": "Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives", "categories": ["cs.CR", "cs.AI"], "comment": "This work will be continuously updated to reflect the latest advances", "summary": "Privacy-preserving machine learning (PPML) based on cryptographic protocols\nhas emerged as a promising paradigm to protect user data privacy in cloud-based\nmachine learning services. While it achieves formal privacy protection, PPML\noften incurs significant efficiency and scalability costs due to orders of\nmagnitude overhead compared to the plaintext counterpart. Therefore, there has\nbeen a considerable focus on mitigating the efficiency gap for PPML. In this\nsurvey, we provide a comprehensive and systematic review of recent PPML studies\nwith a focus on cross-level optimizations. Specifically, we categorize existing\npapers into protocol level, model level, and system level, and review progress\nat each level. We also provide qualitative and quantitative comparisons of\nexisting works with technical insights, based on which we discuss future\nresearch directions and highlight the necessity of integrating optimizations\nacross protocol, model, and system levels. We hope this survey can provide an\noverarching understanding of existing approaches and potentially inspire future\nbreakthroughs in the PPML field. As the field is evolving fast, we also provide\na public GitHub repository to continuously track the developments, which is\navailable at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u6587\u7ae0\u5168\u9762\u7cfb\u7edf\u5730\u56de\u987e\u4e86\u57fa\u4e8e\u5bc6\u7801\u534f\u8bae\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\uff08PPML\uff09\u7684\u7814\u7a76\uff0c\u7279\u522b\u5173\u6ce8\u8de8\u5c42\u4f18\u5316\uff0c\u5e76\u6309\u534f\u8bae\u5c42\u3001\u6a21\u578b\u5c42\u548c\u7cfb\u7edf\u5c42\u5206\u7c7b\u3002", "motivation": "\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u867d\u7136\u5b9e\u73b0\u4e86\u6b63\u5f0f\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u5176\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u6210\u672c\u663e\u8457\u9ad8\u4e8e\u660e\u6587\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u7f29\u5c0fPPML\u7684\u6548\u7387\u5dee\u8ddd\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\u3002", "method": "\u6587\u7ae0\u5c06\u73b0\u6709\u7814\u7a76\u5206\u4e3a\u4e09\u4e2a\u5c42\u9762\uff1a\u534f\u8bae\u5c42\u3001\u6a21\u578b\u5c42\u548c\u7cfb\u7edf\u5c42\uff0c\u5e76\u5728\u6bcf\u4e2a\u5c42\u9762\u4e0a\u56de\u987e\u8fdb\u5c55\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u73b0\u6709\u5de5\u4f5c\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u6bd4\u8f83\uff0c\u5e76\u8ba8\u8bba\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u5206\u6790\uff0c\u8be5\u7efc\u8ff0\u4e3a\u73b0\u6709\u7684PPML\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86\u8de8\u534f\u8bae\u3001\u6a21\u578b\u548c\u7cfb\u7edf\u5c42\u9762\u6574\u5408\u4f18\u5316\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u4f5c\u8005\u5e0c\u671b\u8be5\u7efc\u8ff0\u80fd\u542f\u53d1PPML\u9886\u57df\u7684\u672a\u6765\u7a81\u7834\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u516c\u5171GitHub\u4ed3\u5e93\u4ee5\u6301\u7eed\u8ddf\u8e2a\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2507.14180", "pdf": "https://arxiv.org/pdf/2507.14180", "abs": "https://arxiv.org/abs/2507.14180", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In line with the AI-native 6G vision, explainability and robustness are\ncrucial for building trust and ensuring reliable performance in millimeter-wave\n(mmWave) systems. Efficient beam alignment is essential for initial access, but\ndeep learning (DL) solutions face challenges, including high data collection\noverhead, hardware constraints, lack of explainability, and susceptibility to\nadversarial attacks. This paper proposes a robust and explainable DL-based beam\nalignment engine (BAE) for mmWave multiple-input multiple output (MIMO)\nsystems. The BAE uses received signal strength indicator (RSSI) measurements\nfrom wide beams to predict the best narrow beam, reducing the overhead of\nexhaustive beam sweeping. To overcome the challenge of real-world data\ncollection, this work leverages a site-specific digital twin (DT) to generate\nsynthetic channel data closely resembling real-world environments. A model\nrefinement via transfer learning is proposed to fine-tune the pre-trained model\nresiding in the DT with minimal real-world data, effectively bridging\nmismatches between the digital replica and real-world environments. To reduce\nbeam training overhead and enhance transparency, the framework uses deep\nShapley additive explanations (SHAP) to rank input features by importance,\nprioritizing key spatial directions and minimizing beam sweeping. It also\nincorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a\ncredibility metric for detecting out-of-distribution inputs and ensuring\nrobust, transparent decision-making. Experimental results show that the\nproposed framework reduces real-world data needs by 70%, beam training overhead\nby 62%, and improves outlier detection robustness by up to 8.5x, achieving\nnear-optimal spectral efficiency and transparent decision making compared to\ntraditional softmax based DL models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7684\u7a33\u5065\u4e14\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6ce2\u675f\u5bf9\u51c6\u5f15\u64ce\uff08BAE\uff09\uff0c\u901a\u8fc7\u4f7f\u7528RSSI\u6d4b\u91cf\u3001\u6570\u5b57\u5b6a\u751f\u751f\u6210\u5408\u6210\u4fe1\u9053\u6570\u636e\u548c\u8fc1\u79fb\u5b66\u4e60\u4f18\u5316\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u51cf\u5c11\u6570\u636e\u9700\u6c42\u3001\u964d\u4f4e\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u548c\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5728\u6beb\u7c73\u6ce2\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u6ce2\u675f\u5bf9\u51c6\u65f6\u9762\u4e34\u9ad8\u6570\u636e\u6536\u96c6\u5f00\u9500\u3001\u786c\u4ef6\u9650\u5236\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u7b49\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u5e76\u63d0\u5347\u4fe1\u4efb\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u7a33\u5065\u53c8\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u5bbd\u6ce2\u675f\u7684\u63a5\u6536\u4fe1\u53f7\u5f3a\u5ea6\u6307\u793a\uff08RSSI\uff09\u6d4b\u91cf\u6765\u9884\u6d4b\u6700\u4f73\u7a84\u6ce2\u675f\uff0c\u5e76\u901a\u8fc7\u7279\u5b9a\u5730\u70b9\u7684\u6570\u5b57\u5b6a\u751f\u751f\u6210\u7c7b\u4f3c\u771f\u5b9e\u73af\u5883\u7684\u5408\u6210\u4fe1\u9053\u6570\u636e\u3002\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u9002\u5e94\u5b9e\u9645\u73af\u5883\uff0c\u5e76\u4f7f\u7528SHAP\u503c\u5bf9\u8f93\u5165\u7279\u5f81\u7684\u91cd\u8981\u6027\u8fdb\u884c\u6392\u5e8f\uff0c\u540c\u65f6\u7ed3\u5408DkNN\u7b97\u6cd5\u63d0\u4f9b\u53ef\u4fe1\u5ea6\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5c06\u5b9e\u9645\u4e16\u754c\u6570\u636e\u9700\u6c42\u51cf\u5c11\u4e8670%\uff0c\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u964d\u4f4e\u4e8662%\uff0c\u5e76\u5c06\u5f02\u5e38\u68c0\u6d4b\u9c81\u68d2\u6027\u63d0\u9ad8\u4e868.5\u500d\uff0c\u8fbe\u5230\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9891\u8c31\u6548\u7387\u548c\u900f\u660e\u51b3\u7b56\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u6ce2\u675f\u5bf9\u51c6\u5f15\u64ce\u4e3a\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u9760\u548c\u66f4\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6570\u636e\u6536\u96c6\u548c\u6ce2\u675f\u8bad\u7ec3\u7684\u8d1f\u62c5\uff0c\u5e76\u589e\u5f3a\u4e86\u5bf9\u6297\u5f02\u5e38\u60c5\u51b5\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14588", "pdf": "https://arxiv.org/pdf/2507.14588", "abs": "https://arxiv.org/abs/2507.14588", "authors": ["Usayd Shahul", "J. Harshan"], "title": "FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum", "categories": ["cs.CR", "cs.IT", "math.IT"], "comment": "To appear in the Proceedings of IEEE Information Theory Workshop\n  2025, Sydney, Australia", "summary": "Secure federated learning enables collaborative model training across\ndecentralized users while preserving data privacy. A key component is secure\naggregation, which keeps individual updates hidden from both the server and\nusers, while also defending against Byzantine users who corrupt the\naggregation. To this end, Jinhyun So et al. recently developed a\nByzantine-resilient secure aggregation scheme using a secret-sharing strategy\nover finite-field arithmetic. However, such an approach can suffer from\nnumerical errors and overflows when applied to real-valued model updates,\nmotivating the need for secure aggregation methods that operate directly over\nthe real domain. We propose FORTA, a Byzantine-resilient secure aggregation\nframework that operates entirely in the real domain. FORTA leverages Discrete\nFourier Transform (DFT) codes for privacy and employs Krum-based outlier\ndetection for robustness. While DFT decoder is error-free under infinite\nprecision, finite precision introduces numerical perturbations that can distort\ndistance estimates and allow malicious updates to evade detection. To address\nthis, FORTA refines Krum using feedback from DFT decoder, improving the\nselection of trustworthy updates. Theoretical analysis and experiments show\nthat our modification of Krum offers improved robustness and more accurate\naggregation than standard Krum.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFORTA\u7684\u62dc\u5360\u5ead\u5f39\u6027\u5b89\u5168\u805a\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5b8c\u5168\u5728\u5b9e\u6570\u57df\u4e2d\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u6539\u8fdbKrum\u7b97\u6cd5\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u62dc\u5360\u5ead\u5f39\u6027\u5b89\u5168\u805a\u5408\u65b9\u6848\u5728\u5e94\u7528\u4e8e\u5b9e\u503c\u6a21\u578b\u66f4\u65b0\u65f6\u53ef\u80fd\u4f1a\u51fa\u73b0\u6570\u503c\u9519\u8bef\u548c\u6ea2\u51fa\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u76f4\u63a5\u5728\u5b9e\u6570\u57df\u4e2d\u64cd\u4f5c\u7684\u5b89\u5168\u805a\u5408\u65b9\u6cd5\u3002", "method": "FORTA\u5229\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u4ee3\u7801\u8fdb\u884c\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u91c7\u7528\u57fa\u4e8eKrum\u7684\u5f02\u5e38\u68c0\u6d4b\u6765\u8fdb\u884c\u9c81\u68d2\u6027\u4fdd\u62a4\u3002\u6b64\u5916\uff0cFORTA\u8fd8\u901a\u8fc7\u6765\u81eaDFT\u89e3\u7801\u5668\u7684\u53cd\u9988\u6539\u8fdb\u4e86Krum\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0cFORTA\u5bf9Krum\u7684\u4fee\u6539\u63d0\u4f9b\u4e86\u6bd4\u6807\u51c6Krum\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u66f4\u51c6\u786e\u7684\u805a\u5408\u3002", "conclusion": "FORTA\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u62dc\u5360\u5ead\u5f39\u6027\u5b89\u5168\u805a\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u503c\u6a21\u578b\u66f4\u65b0\u4e2d\u7684\u6570\u503c\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e86\u805a\u5408\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14181", "pdf": "https://arxiv.org/pdf/2507.14181", "abs": "https://arxiv.org/abs/2507.14181", "authors": ["Yajiao Dai", "Jun Li", "Zhen Mei", "Yiyang Ni", "Shi Jin", "Zengxiang Li", "Sheng Guo", "Wei Xiang"], "title": "Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to IEEE Internet of Things Journal, Early Access. 14 pages,\n  5 figures", "summary": "Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe\noperation of industrial machinery and improving production efficiency. However,\ntraditional supervised deep learning methods require a large amount of training\ndata and labels, which are often located in different clients. Additionally,\nthe cost of data labeling is high, making labels difficult to acquire.\nMeanwhile, differences in data distribution among clients may also hinder the\nmodel's performance. To tackle these challenges, this paper proposes a\nsemi-supervised federated learning framework, SSFL-DCSL, which integrates dual\ncontrastive loss and soft labeling to address data and label scarcity for\ndistributed clients with few labeled samples while safeguarding user privacy.\nIt enables representation learning using unlabeled data on the client side and\nfacilitates joint learning among clients through prototypes, thereby achieving\nmutual knowledge sharing and preventing local model divergence. Specifically,\nfirst, a sample weighting function based on the Laplace distribution is\ndesigned to alleviate bias caused by low confidence in pseudo labels during the\nsemi-supervised training process. Second, a dual contrastive loss is introduced\nto mitigate model divergence caused by different data distributions, comprising\nlocal contrastive loss and global contrastive loss. Third, local prototypes are\naggregated on the server with weighted averaging and updated with momentum to\nshare knowledge among clients. To evaluate the proposed SSFL-DCSL framework,\nexperiments are conducted on two publicly available datasets and a dataset\ncollected on motors from the factory. In the most challenging task, where only\n10\\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by\n1.15% to 7.85% over state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6SSFL-DCSL\uff0c\u4ee5\u89e3\u51b3\u5de5\u4e1a\u673a\u68b0\u667a\u80fd\u6545\u969c\u8bca\u65ad\u4e2d\u6570\u636e\u548c\u6807\u7b7e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u53cc\u91cd\u5bf9\u6bd4\u635f\u5931\u548c\u8f6f\u6807\u7b7e\u6574\u5408\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0f\u5ba2\u6237\u95f4\u7684\u77e5\u8bc6\u5171\u4eab\uff0c\u51cf\u5c11\u6a21\u578b\u5206\u6b67\uff0c\u63d0\u9ad8\u5728\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u60c5\u51b5\u4e0b\u7684\u8bca\u65ad\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u667a\u80fd\u6545\u969c\u8bca\u65ad\u4e2d\u9762\u4e34\u6570\u636e\u548c\u6807\u7b7e\u9700\u6c42\u5927\u3001\u6210\u672c\u9ad8\u53ca\u4e0d\u540c\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u5dee\u5f02\u7684\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u5e76\u589e\u52a0\u4e86\u5b9e\u9645\u5e94\u7528\u96be\u5ea6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7684\u6837\u672c\u52a0\u6743\u51fd\u6570\uff0c\u51cf\u8f7b\u4f2a\u6807\u7b7e\u4f4e\u7f6e\u4fe1\u5ea6\u5e26\u6765\u7684\u504f\u5dee\uff1b\u5f15\u5165\u53cc\u91cd\u5bf9\u6bd4\u635f\u5931\uff08\u5305\u62ec\u5c40\u90e8\u5bf9\u6bd4\u635f\u5931\u548c\u5168\u5c40\u5bf9\u6bd4\u635f\u5931\uff09\u6765\u7f13\u89e3\u4e0d\u540c\u6570\u636e\u5206\u5e03\u5f15\u8d77\u7684\u6a21\u578b\u5206\u6b67\uff1b\u901a\u8fc7\u5e26\u52a8\u91cf\u66f4\u65b0\u7684\u52a0\u6743\u5e73\u5747\u805a\u5408\u672c\u5730\u539f\u578b\uff0c\u5b9e\u73b0\u5728\u670d\u52a1\u5668\u7aef\u7684\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5de5\u5382\u7535\u673a\u6536\u96c6\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5728\u6700\u56f0\u96be\u7684\u4efb\u52a1\u4e2d\uff08\u53ea\u670910%\u7684\u6570\u636e\u88ab\u6807\u6ce8\uff09\uff0c\u6240\u63d0\u51fa\u7684SSFL-DCSL\u6846\u67b6\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e861.15%\u52307.85%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "SSFL-DCSL\u6846\u67b6\u4e3a\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u667a\u80fd\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u548c\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u4e0d\u540c\u5ba2\u6237\u7aef\u95f4\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u8bca\u65ad\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14600", "pdf": "https://arxiv.org/pdf/2507.14600", "abs": "https://arxiv.org/abs/2507.14600", "authors": ["MA. Khajeian"], "title": "Hybrid Classical-Quantum Rainbow Table Attack on Human Passwords", "categories": ["cs.CR", "quant-ph"], "comment": null, "summary": "Passwords that are long and human-generated pose a challenge for both\nclassical and quantum attacks due to their irregular structure and large search\nspace. In this work, we present an enhanced classical-quantum hybrid attack\ntailored to this scenario. We build rainbow tables using dictionary-based\npassword generation with transformation rules to better model real user\nbehavior. These tables are then organized into buckets, enabling faster lookup\nand reduced space complexity. To perform quantum search within each bucket, we\nuse a distributed exact variant of Grover's algorithm, which offers lower\ncircuit depth and deterministic success. As a result, the overall quantum\ncircuit is shallower and more robust against noise, particularly from\ndepolarizing channels commonly found in near-term quantum devices. Through this\nwork, Overall, we propose a hybrid framework that combines structured rainbow\ntables with efficient quantum search to enhance password recovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u7ecf\u5178-\u91cf\u5b50\u6df7\u5408\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u5b57\u5178\u7684\u5f69\u8679\u8868\u548c\u4f7f\u7528\u6539\u8fdb\u7684Grover\u7b97\u6cd5\u6765\u63d0\u9ad8\u5bc6\u7801\u6062\u590d\u6548\u7387\u3002", "motivation": "\u957f\u4e14\u7531\u4eba\u7c7b\u751f\u6210\u7684\u5bc6\u7801\u7531\u4e8e\u5176\u4e0d\u89c4\u5219\u7ed3\u6784\u548c\u5e9e\u5927\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u5bf9\u7ecf\u5178\u548c\u91cf\u5b50\u653b\u51fb\u90fd\u6784\u6210\u4e86\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u653b\u51fb\u65b9\u5f0f\u3002", "method": "\u8be5\u7814\u7a76\u9996\u5148\u521b\u5efa\u4e86\u57fa\u4e8e\u5b57\u5178\u7684\u5f69\u8679\u8868\uff0c\u5e76\u5e94\u7528\u8f6c\u6362\u89c4\u5219\u4ee5\u6a21\u62df\u771f\u5b9e\u7528\u6237\u7684\u5bc6\u7801\u751f\u6210\u884c\u4e3a\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u8868\u7ec4\u7ec7\u6210\u6876\uff0c\u4ee5\u4fbf\u66f4\u5feb\u67e5\u627e\u5e76\u51cf\u5c11\u7a7a\u95f4\u590d\u6742\u5ea6\u3002\u5728\u6bcf\u4e2a\u6876\u5185\u6267\u884c\u91cf\u5b50\u641c\u7d22\u65f6\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u7cbe\u786e\u7248Grover\u7b97\u6cd5\uff0c\u63d0\u4f9b\u8f83\u4f4e\u7684\u7535\u8def\u6df1\u5ea6\u548c\u786e\u5b9a\u6027\u7684\u6210\u529f\u3002", "result": "\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u5f97\u6574\u4f53\u91cf\u5b50\u7535\u8def\u66f4\u6d45\uff0c\u589e\u5f3a\u4e86\u5bf9\u6297\u566a\u58f0\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u8fd1\u671f\u91cf\u5b50\u8bbe\u5907\u4e2d\u5e38\u89c1\u7684\u53bb\u6781\u5316\u901a\u9053\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u7ed3\u6784\u5316\u7684\u5f69\u8679\u8868\u4e0e\u9ad8\u6548\u7684\u91cf\u5b50\u641c\u7d22\u7684\u6df7\u5408\u6846\u67b6\uff0c\u4ee5\u589e\u5f3a\u5bc6\u7801\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2507.14182", "pdf": "https://arxiv.org/pdf/2507.14182", "abs": "https://arxiv.org/abs/2507.14182", "authors": ["Xiaotong Luo", "Shengda Zhuo", "Min Chen", "Lichun Li", "Ruizhao Lu", "Wenqi Fan", "Shuqiang Huang", "Yin Tang"], "title": "From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Financial markets exhibit highly dynamic and complex behaviors shaped by both\nhistorical price trajectories and exogenous narratives, such as news, policy\ninterpretations, and social media sentiment. The heterogeneity in these data\nand the diverse insight of investors introduce biases that complicate the\nmodeling of market dynamics. Unlike prior work, this paper explores the\npotential of bull and bear regimes in investor-driven market dynamics. Through\nempirical analysis on real-world financial datasets, we uncover a dynamic\nrelationship between bias variation and behavioral adaptation, which enhances\ntrend prediction under evolving market conditions. To model this mechanism, we\npropose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified\nframework that jointly embeds temporal price sequences and external contextual\nsignals into a shared latent space where opposing bull and bear forces\nnaturally emerge, forming the foundation for bias representation. Within this\nspace, an inertial pairing module pairs temporally adjacent samples to preserve\nmomentum, while the dual competition mechanism contrasts bullish and bearish\nembeddings to capture behavioral divergence. Together, these components allow\nB4 to model bias-driven asymmetry, behavioral inertia, and market\nheterogeneity. Experimental results on real-world financial datasets\ndemonstrate that our model not only achieves superior performance in predicting\nmarket trends but also provides interpretable insights into the interplay of\nbiases, investor behaviors, and market dynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578bB4\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u5d4c\u5165\u65f6\u95f4\u4ef7\u683c\u5e8f\u5217\u548c\u5916\u90e8\u4e0a\u4e0b\u6587\u4fe1\u53f7\u6765\u6355\u6349\u6295\u8d44\u8005\u884c\u4e3a\u4e2d\u7684\u725b\u718a\u52a8\u6001\uff0c\u4ece\u800c\u63d0\u9ad8\u5e02\u573a\u8d8b\u52bf\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u7531\u5386\u53f2\u4ef7\u683c\u8f68\u8ff9\u548c\u5916\u751f\u53d9\u4e8b\u5851\u9020\uff0c\u8868\u73b0\u51fa\u9ad8\u5ea6\u52a8\u6001\u548c\u590d\u6742\u7684\u884c\u4e3a\u3002\u5148\u524d\u7684\u5de5\u4f5c\u6ca1\u6709\u5145\u5206\u63a2\u7d22\u725b\u5e02\u548c\u718a\u5e02\u5728\u6295\u8d44\u8005\u9a71\u52a8\u7684\u5e02\u573a\u52a8\u6001\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aBias to Behavior from Bull-Bear Dynamics model (B4)\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u65f6\u95f4\u4ef7\u683c\u5e8f\u5217\u548c\u5916\u90e8\u4e0a\u4e0b\u6587\u4fe1\u53f7\u5171\u540c\u5d4c\u5165\u5230\u4e00\u4e2a\u5171\u4eab\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u5728\u8fd9\u4e2a\u7a7a\u95f4\u91cc\uff0c\u60ef\u6027\u914d\u5bf9\u6a21\u5757\u548c\u53cc\u91cd\u7ade\u4e89\u673a\u5236\u5206\u522b\u7528\u4e8e\u4fdd\u6301\u52a8\u91cf\u548c\u6355\u6349\u884c\u4e3a\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cB4\u6a21\u578b\u4e0d\u4ec5\u5728\u9884\u6d4b\u5e02\u573a\u8d8b\u52bf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8fd8\u80fd\u63d0\u4f9b\u5173\u4e8e\u504f\u5dee\u3001\u6295\u8d44\u8005\u884c\u4e3a\u548c\u5e02\u573a\u52a8\u6001\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u53ef\u89e3\u91ca\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u504f\u5dee\u53d8\u5316\u4e0e\u884c\u4e3a\u9002\u5e94\u4e4b\u95f4\u7684\u52a8\u6001\u5173\u7cfb\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684B4\u6a21\u578b\u5728\u8fdb\u5316\u5e02\u573a\u6761\u4ef6\u4e0b\u589e\u5f3a\u4e86\u8d8b\u52bf\u9884\u6d4b\u7684\u80fd\u529b\u3002"}}
{"id": "2507.14625", "pdf": "https://arxiv.org/pdf/2507.14625", "abs": "https://arxiv.org/abs/2507.14625", "authors": ["Juntao Tan", "Anran Li", "Quanchao Liu", "Peng Ran", "Lan Zhang"], "title": "VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Vertical federated learning (VFL) enables multiple parties with disjoint\nfeatures to collaboratively train models without sharing raw data. While\nprivacy vulnerabilities of VFL are extensively-studied, its security\nthreats-particularly targeted label attacks-remain underexplored. In such\nattacks, a passive party perturbs inputs at inference to force\nmisclassification into adversary-chosen labels. Existing methods rely on\nunrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore\nanomaly detectors deployed in real-world systems. To bridge this gap, we\nintroduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly\ndesigned to evade detector-enhanced VFL inference. During the preparation\nstage, the attacker selects a minimal set of high-expressiveness samples (via\nmaximum mean discrepancy), submits them through VFL protocol to collect\npredicted labels, and uses these pseudo-labels to train estimated detector and\nsurrogate model on local features. In attack stage, these models guide\ngradient-based perturbations of remaining samples, crafting adversarial\ninstances that induce targeted misclassifications and evade detection. We\nimplement VTarbel and evaluate it against four model architectures, seven\nmultimodal datasets, and two anomaly detectors. Across all settings, VTarbel\noutperforms four state-of-the-art baselines, evades detection, and retains\neffective against three representative privacy-preserving defenses. These\nresults reveal critical security blind spots in current VFL deployments and\nunderscore urgent need for robust, attack-aware defenses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVTarbel\u7684\u65b0\u578b\u653b\u51fb\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u5782\u76f4\u8054\u5408\u5b66\u4e60\u4e2d\u8fdb\u884c\u76ee\u6807\u6807\u7b7e\u653b\u51fb\u5e76\u9003\u907f\u68c0\u6d4b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVTarbel\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524dVFL\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u76f2\u70b9\u3002", "motivation": "\u5c3d\u7ba1\u5782\u76f4\u8054\u5408\u5b66\u4e60\uff08VFL\uff09\u7684\u9690\u79c1\u6f0f\u6d1e\u5df2\u7ecf\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u76ee\u6807\u6807\u7b7e\u653b\u51fb\uff0c\u4ecd\u7136\u6ca1\u6709\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u5207\u5b9e\u9645\u7684\u5047\u8bbe\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u90e8\u7f72\u7684\u5f02\u5e38\u68c0\u6d4b\u5668\u3002", "method": "VTarbel\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u6700\u5c0f\u77e5\u8bc6\u653b\u51fb\u6846\u67b6\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u9003\u907f\u589e\u5f3a\u578bVFL\u63a8\u7406\u4e2d\u7684\u68c0\u6d4b\u5668\u3002\u51c6\u5907\u9636\u6bb5\u9009\u62e9\u9ad8\u8868\u8fbe\u6027\u7684\u6837\u672c\uff0c\u6536\u96c6\u9884\u6d4b\u6807\u7b7e\uff0c\u5e76\u7528\u8fd9\u4e9b\u4f2a\u6807\u7b7e\u8bad\u7ec3\u4f30\u8ba1\u7684\u68c0\u6d4b\u5668\u548c\u4ee3\u7406\u6a21\u578b\u3002\u653b\u51fb\u9636\u6bb5\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u6307\u5bfc\u57fa\u4e8e\u68af\u5ea6\u7684\u6270\u52a8\uff0c\u5236\u9020\u80fd\u591f\u8bf1\u5bfc\u76ee\u6807\u8bef\u5206\u7c7b\u5e76\u9003\u907f\u68c0\u6d4b\u7684\u5bf9\u6297\u5b9e\u4f8b\u3002", "result": "\u901a\u8fc7\u5b9e\u65bdVTarbel\u5e76\u5bf9\u56db\u79cd\u6a21\u578b\u67b6\u6784\u3001\u4e03\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c\u4e24\u79cd\u5f02\u5e38\u68c0\u6d4b\u5668\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aVTarbel\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\u90fd\u4f18\u4e8e\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u9003\u907f\u68c0\u6d4b\uff0c\u5e76\u5bf9\u4e09\u79cd\u4ee3\u8868\u6027\u7684\u9690\u79c1\u4fdd\u62a4\u9632\u5fa1\u63aa\u65bd\u4fdd\u6301\u6709\u6548\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524dVFL\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u5b89\u5168\u76f2\u70b9\uff0c\u5e76\u5f3a\u8c03\u4e86\u8feb\u5207\u9700\u8981\u5f00\u53d1\u5f3a\u5927\u7684\u3001\u9488\u5bf9\u653b\u51fb\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2507.14204", "pdf": "https://arxiv.org/pdf/2507.14204", "abs": "https://arxiv.org/abs/2507.14204", "authors": ["Dachuan Shi", "Yonggan Fu", "Xiangchi Yuan", "Zhongzhi Yu", "Haoran You", "Sixu Li", "Xin Dong", "Jan Kautz", "Pavlo Molchanov", "Yingyan", "Lin"], "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache", "summary": "Recent advancements in Large Language Models (LLMs) have spurred interest in\nnumerous applications requiring robust long-range capabilities, essential for\nprocessing extensive input contexts and continuously generating extended\noutputs. As sequence lengths increase, the number of Key-Value (KV) pairs in\nLLMs escalates, creating a significant efficiency bottleneck. In this paper, we\npropose a new KV cache optimization paradigm called LaCache, a training-free\nmethod for efficient and accurate generative inference of LLMs. LaCache enables\nLLMs to simultaneously address both of the critical challenges in long-range\nmodeling: robust long-range capabilities and continuous generation without\nrunning out-of-memory (OOM). Specifically, LaCache integrates two key\ninnovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only\nsequentially (left-to-right within each layer) but also across layers (from\nshallow to deep), providing an extended span for capturing long-range\ndependencies under a fixed storage budget, thereby boosting long-range\ncapabilities; and (2) an iterative compaction mechanism that progressively\ncompresses older caches, freeing up space for new tokens within a fixed cache\nsize. This token distance-based dynamic compression enables more effective\ncontinuous generation under constrained cache budgets. Experiments across\nvarious tasks, benchmarks, and LLM models consistently validate LaCache's\neffectiveness in enhancing LLMs' long-range capabilities. Our code is available\nat https://github.com/GATECH-EIC/LaCache.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLaCache\u7684\u65b0\u7684KV\u7f13\u5b58\u4f18\u5316\u8303\u5f0f\uff0c\u901a\u8fc7\u9636\u68af\u5f62KV\u7f13\u5b58\u6a21\u5f0f\u548c\u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u957f\u8ddd\u79bb\u6a21\u578b\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u5f3a\u5927\u7684\u957f\u7a0b\u80fd\u529b\u548c\u8fde\u7eed\u751f\u6210\u800c\u4e0d\u51fa\u73b0\u5185\u5b58\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u7684\u589e\u52a0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u952e\u503c\uff08KV\uff09\u5bf9\u6570\u91cf\u4e5f\u76f8\u5e94\u589e\u52a0\uff0c\u9020\u6210\u4e86\u663e\u8457\u7684\u6548\u7387\u74f6\u9888\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8LLMs\u7684\u957f\u7a0b\u80fd\u529b\uff0c\u5e76\u786e\u4fdd\u5728\u56fa\u5b9a\u5b58\u50a8\u9884\u7b97\u4e0b\u80fd\u6301\u7eed\u751f\u6210\u6587\u672c\u3002", "method": "LaCache\u5f15\u5165\u4e86\u4e24\u79cd\u5173\u952e\u6280\u672f\uff1a1\uff09\u9636\u68af\u5f62KV\u7f13\u5b58\u6a21\u5f0f\uff0c\u4e0d\u4ec5\u6309\u987a\u5e8f\u5b58\u50a8KV\u5bf9\uff0c\u800c\u4e14\u8de8\u5c42\u5b58\u50a8\uff0c\u4ece\u800c\u5728\u56fa\u5b9a\u5b58\u50a8\u9884\u7b97\u4e0b\u6269\u5c55\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u7684\u8303\u56f4\uff1b2\uff09\u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff0c\u9010\u6b65\u538b\u7f29\u65e7\u7f13\u5b58\uff0c\u4e3a\u65b0\u6807\u8bb0\u817e\u51fa\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LaCache\u5728\u5404\u79cd\u4efb\u52a1\u3001\u57fa\u51c6\u6d4b\u8bd5\u548cLLM\u6a21\u578b\u4e2d\u6709\u6548\u589e\u5f3a\u4e86LLMs\u7684\u957f\u7a0b\u80fd\u529b\u3002", "conclusion": "LaCache\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u63d0\u5347LLMs\u7684\u957f\u7a0b\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u8bc1\u8fde\u7eed\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5185\u5b58\u7ba1\u7406\u3002"}}
{"id": "2507.14629", "pdf": "https://arxiv.org/pdf/2507.14629", "abs": "https://arxiv.org/abs/2507.14629", "authors": ["Juntao Tan", "Lan Zhang", "Zhonghao Hu", "Kai Yang", "Peng Ran", "Bo Li"], "title": "VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Though vertical federated learning (VFL) is generally considered to be\nprivacy-preserving, recent studies have shown that VFL system is vulnerable to\nlabel inference attacks originating from various attack surfaces. Among these\nattacks, the model completion (MC) attack is currently the most powerful one.\nExisting defense methods against it either sacrifice model accuracy or incur\nimpractical computational overhead. In this paper, we propose VMask, a novel\nlabel privacy protection framework designed to defend against MC attack from\nthe perspective of layer masking. Our key insight is to disrupt the strong\ncorrelation between input data and intermediate outputs by applying the secret\nsharing (SS) technique to mask layer parameters in the attacker's model. We\ndevise a strategy for selecting critical layers to mask, reducing the overhead\nthat would arise from naively applying SS to the entire model. Moreover, VMask\nis the first framework to offer a tunable privacy budget to defenders, allowing\nfor flexible control over the levels of label privacy according to actual\nrequirements. We built a VFL system, implemented VMask on it, and extensively\nevaluated it using five model architectures and 13 datasets with different\nmodalities, comparing it to 12 other defense methods. The results demonstrate\nthat VMask achieves the best privacy-utility trade-off, successfully thwarting\nthe MC attack (reducing the label inference accuracy to a random guessing\nlevel) while preserving model performance (e.g., in Transformer-based model,\nthe averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up\nto 60,846 times faster than cryptography-based methods, and it only marginally\nexceeds that of standard VFL by 1.8 times in a large Transformer-based model,\nwhich is generally acceptable.", "AI": {"tldr": "\u63d0\u51faVMask\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u63a9\u7801\u6280\u672f\u62b5\u5fa1\u6a21\u578b\u5b8c\u6210\u653b\u51fb\uff0c\u4fdd\u62a4\u5782\u76f4\u8054\u5408\u5b66\u4e60\u4e2d\u7684\u6807\u7b7e\u9690\u79c1\u3002\u5b83\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6700\u4f73\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u5e76\u4e14\u8fd0\u884c\u6548\u7387\u9ad8\u3002", "motivation": "\u5c3d\u7ba1\u5782\u76f4\u8054\u5408\u5b66\u4e60\uff08VFL\uff09\u88ab\u8ba4\u4e3a\u5177\u6709\u9690\u79c1\u4fdd\u62a4\u6027\uff0c\u4f46\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\u5b83\u5bb9\u6613\u53d7\u5230\u6807\u7b7e\u63a8\u65ad\u653b\u51fb\uff0c\u7279\u522b\u662f\u6a21\u578b\u5b8c\u6210\u653b\u51fb\u3002\u73b0\u6709\u7684\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u727a\u7272\u6a21\u578b\u51c6\u786e\u6027\uff0c\u8981\u4e48\u4ea7\u751f\u4e0d\u5207\u5b9e\u9645\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86VMask\u6846\u67b6\uff0c\u5229\u7528\u79d8\u5bc6\u5171\u4eab\u6280\u672f\u5bf9\u653b\u51fb\u8005\u6a21\u578b\u4e2d\u7684\u5c42\u53c2\u6570\u8fdb\u884c\u63a9\u7801\u5904\u7406\uff0c\u4ee5\u6253\u7834\u8f93\u5165\u6570\u636e\u4e0e\u4e2d\u95f4\u8f93\u51fa\u4e4b\u95f4\u7684\u5f3a\u5173\u8054\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u4e86\u9009\u62e9\u5173\u952e\u5c42\u8fdb\u884c\u63a9\u7801\u7684\u7b56\u7565\uff0c\u51cf\u5c11\u5f00\u9500\uff0c\u5e76\u63d0\u4f9b\u53ef\u8c03\u7684\u9690\u79c1\u9884\u7b97\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVMask\u6210\u529f\u5c06\u6a21\u578b\u5b8c\u6210\u653b\u51fb\u7684\u6807\u7b7e\u63a8\u65ad\u51c6\u786e\u7387\u964d\u4f4e\u5230\u968f\u673a\u731c\u6d4b\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5e73\u5747\u4ec5\u4f7fVFL\u6a21\u578b\u51c6\u786e\u7387\u4e0b\u964d0.09%\uff0c\u5e76\u4e14\u5176\u8fd0\u884c\u65f6\u95f4\u8fdc\u5feb\u4e8e\u57fa\u4e8e\u5bc6\u7801\u5b66\u7684\u65b9\u6cd5\u3002", "conclusion": "VMask\u4e3aVFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u3001\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u6807\u7b7e\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u548c\u6548\u7528\u7684\u6700\u4f73\u5e73\u8861\u3002"}}
{"id": "2507.14215", "pdf": "https://arxiv.org/pdf/2507.14215", "abs": "https://arxiv.org/abs/2507.14215", "authors": ["Jiayu", "Liu"], "title": "Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "This study aims to develop a deep learning system for an accessibility device\nfor the deaf or hearing impaired. The device will accurately localize and\nidentify sound sources in real time. This study will fill an important gap in\ncurrent research by leveraging machine learning techniques to target the\nunderprivileged community. The system includes three main components. 1.\nJerryNet: A custom designed CNN architecture that determines the direction of\narrival (DoA) for nine possible directions. 2. Audio Classification: This model\nis based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model\nto identify the exact sound classes only based on audio. 3. Multimodal\nintegration model: This is an accurate sound localization model that combines\naudio, visual, and text data to locate the exact sound sources in the images.\nThe part consists of two modules, one object detection using Yolov9 to generate\nall the bounding boxes of the objects, and an audio visual localization model\nto identify the optimal bounding box using complete Intersection over Union\n(CIoU). The hardware consists of a four-microphone rectangular formation and a\ncamera mounted on glasses with a wristband for displaying necessary information\nlike direction. On a custom collected data set, JerryNet achieved a precision\nof 91. 1% for the sound direction, outperforming all the baseline models. The\nCLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,\nrespectively. The audio-visual localization model within component 3 yielded a\ncIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are\nmany future potentials to this study, paving the way to creating a new\ngeneration of accessibility devices.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4e3a\u804b\u4eba\u6216\u542c\u529b\u53d7\u635f\u8005\u5f00\u53d1\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u5b9e\u65f6\u51c6\u786e\u5b9a\u4f4d\u548c\u8bc6\u522b\u58f0\u97f3\u6765\u6e90\u3002\u5b83\u7531\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\u7ec4\u6210\uff1aJerryNet\u3001\u97f3\u9891\u5206\u7c7b\u6a21\u578b\u548c\u591a\u6a21\u6001\u96c6\u6210\u6a21\u578b\u3002\u786c\u4ef6\u5305\u62ec\u56db\u4e2a\u9ea6\u514b\u98ce\u548c\u4e00\u4e2a\u6444\u50cf\u5934\u3002\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u7cfb\u7edf\u7684\u6027\u80fd\u8d85\u8fc7\u4e86\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4e3a\u804b\u4eba\u6216\u542c\u529b\u53d7\u635f\u8005\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u51c6\u786e\u5730\u5b9a\u4f4d\u548c\u8bc6\u522b\u58f0\u97f3\u6765\u6e90\u7684\u8f85\u52a9\u8bbe\u5907\uff0c\u4ee5\u586b\u8865\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u91cd\u8981\u7a7a\u767d\u3002", "method": "\u8be5\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff1a1. JerryNet\uff1a\u4e00\u4e2a\u81ea\u5b9a\u4e49\u8bbe\u8ba1\u7684CNN\u67b6\u6784\uff0c\u7528\u4e8e\u786e\u5b9a\u4e5d\u4e2a\u53ef\u80fd\u65b9\u5411\u7684\u58f0\u97f3\u5230\u8fbe\u65b9\u5411\uff08DoA\uff09\u30022. \u97f3\u9891\u5206\u7c7b\uff1a\u57fa\u4e8e\u5fae\u8c03\u5bf9\u6bd4\u8bed\u8a00-\u97f3\u9891\u9884\u8bad\u7ec3\uff08CLAP\uff09\u6a21\u578b\uff0c\u4ec5\u6839\u636e\u97f3\u9891\u8bc6\u522b\u786e\u5207\u7684\u58f0\u97f3\u7c7b\u522b\u30023. \u591a\u6a21\u6001\u96c6\u6210\u6a21\u578b\uff1a\u7ed3\u5408\u97f3\u9891\u3001\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\u7cbe\u786e\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u786e\u5207\u58f0\u97f3\u6765\u6e90\u7684\u6a21\u578b\uff0c\u5176\u4e2d\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff0c\u4e00\u4e2a\u4f7f\u7528Yolov9\u8fdb\u884c\u5bf9\u8c61\u68c0\u6d4b\u751f\u6210\u6240\u6709\u5bf9\u8c61\u7684\u8fb9\u754c\u6846\uff0c\u53e6\u4e00\u4e2a\u662f\u97f3\u89c6\u9891\u5b9a\u4f4d\u6a21\u578b\uff0c\u4f7f\u7528\u5b8c\u6574\u4ea4\u5e76\u6bd4\uff08CIoU\uff09\u6765\u786e\u5b9a\u6700\u4f18\u8fb9\u754c\u6846\u3002", "result": "\u5728\u81ea\u5b9a\u4e49\u6536\u96c6\u7684\u6570\u636e\u96c6\u4e0a\uff0cJerryNet\u5b9e\u73b0\u4e8691.1%\u7684\u65b9\u5411\u7cbe\u5ea6\uff0c\u8d85\u8fc7\u4e86\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u3002CLAP\u6a21\u578b\u5728\u81ea\u5b9a\u4e49\u548cAudioSet\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u5230\u4e8698.5%\u548c95%\u7684\u51c6\u786e\u6027\u3002\u7ec4\u4ef63\u4e2d\u7684\u97f3\u89c6\u9891\u5b9a\u4f4d\u6a21\u578b\u83b7\u5f97\u4e860.892\u7684CIoU\u548c0.658\u7684AUC\uff0c\u8d85\u8d8a\u4e86\u5176\u4ed6\u7c7b\u4f3c\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u5176\u672a\u6765\u6f5c\u529b\uff0c\u4e3a\u521b\u9020\u65b0\u4e00\u4ee3\u8f85\u52a9\u8bbe\u5907\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14739", "pdf": "https://arxiv.org/pdf/2507.14739", "abs": "https://arxiv.org/abs/2507.14739", "authors": ["Franco Oberti", "Stefano Di Carlo", "Alessandro Savino"], "title": "CANDoSA: A Hardware Performance Counter-Based Intrusion Detection System for DoS Attacks on Automotive CAN bus", "categories": ["cs.CR"], "comment": "Accepted for publication at the 31st IEEE International Symposium on\n  On-Line Testing and Robust System Design 2025 (IOLTS25)", "summary": "The Controller Area Network (CAN) protocol, essential for automotive embedded\nsystems, lacks inherent security features, making it vulnerable to cyber\nthreats, especially with the rise of autonomous vehicles. Traditional security\nmeasures offer limited protection, such as payload encryption and message\nauthentication. This paper presents a novel Intrusion Detection System (IDS)\ndesigned for the CAN environment, utilizing Hardware Performance Counters\n(HPCs) to detect anomalies indicative of cyber attacks. A RISC-V-based CAN\nreceiver is simulated using the gem5 simulator, processing CAN frame payloads\nwith AES-128 encryption as FreeRTOS tasks, which trigger distinct HPC\nresponses. Key HPC features are optimized through data extraction and\ncorrelation analysis to enhance classification efficiency. Results indicate\nthat this approach could significantly improve CAN security and address\nemerging challenges in automotive cybersecurity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08IDS\uff09\uff0c\u8be5\u7cfb\u7edf\u4e13\u4e3aCAN\u73af\u5883\u8bbe\u8ba1\uff0c\u5229\u7528\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\uff08HPCs\uff09\u6765\u68c0\u6d4b\u8868\u660e\u7f51\u7edc\u653b\u51fb\u7684\u5f02\u5e38\u60c5\u51b5\u3002\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8CAN\u534f\u8bae\u7684\u5b89\u5168\u6027\uff0c\u4ee5\u5e94\u5bf9\u6c7d\u8f66\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u65b0\u5174\u6311\u6218\u3002", "motivation": "\u63a7\u5236\u5668\u5c40\u57df\u7f51\uff08CAN\uff09\u534f\u8bae\u662f\u6c7d\u8f66\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u7f3a\u4e4f\u56fa\u6709\u7684\u5b89\u5168\u7279\u6027\uff0c\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u7f51\u7edc\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5174\u8d77\u7684\u60c5\u51b5\u4e0b\u3002\u4f20\u7edf\u5b89\u5168\u63aa\u65bd\u63d0\u4f9b\u7684\u4fdd\u62a4\u6709\u9650\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528gem5\u6a21\u62df\u5668\u6a21\u62df\u4e86\u4e00\u4e2a\u57fa\u4e8eRISC-V\u7684CAN\u63a5\u6536\u5668\uff0c\u5904\u7406\u5e26\u6709AES-128\u52a0\u5bc6\u7684CAN\u5e27\u6709\u6548\u8f7d\u8377\u4f5c\u4e3aFreeRTOS\u4efb\u52a1\uff0c\u89e6\u53d1\u4e0d\u540c\u7684\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\uff08HPC\uff09\u54cd\u5e94\u3002\u901a\u8fc7\u6570\u636e\u63d0\u53d6\u548c\u76f8\u5173\u6027\u5206\u6790\u4f18\u5316\u5173\u952eHPC\u7279\u5f81\uff0c\u4ee5\u63d0\u9ad8\u5206\u7c7b\u6548\u7387\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e00\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347CAN\u7684\u5b89\u5168\u6027\uff0c\u5e76\u89e3\u51b3\u6c7d\u8f66\u9886\u57df\u4e2d\u51fa\u73b0\u7684\u65b0\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eHPC\u7684IDS\u4e3aCAN\u534f\u8bae\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u589e\u5f3a\u673a\u5236\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65e5\u76ca\u590d\u6742\u7684\u6c7d\u8f66\u7f51\u7edc\u5b89\u5168\u73af\u5883\u3002"}}
{"id": "2507.14217", "pdf": "https://arxiv.org/pdf/2507.14217", "abs": "https://arxiv.org/abs/2507.14217", "authors": ["Tudor Matei Opran", "Samir Loudni"], "title": "Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "We address the pattern explosion problem in pattern mining by proposing an\ninteractive learning framework that combines nonlinear utility aggregation with\ngeometry-aware query selection. Our method models user preferences through a\nChoquet integral over multiple interestingness measures and exploits the\ngeometric structure of the version space to guide the selection of informative\ncomparisons. A branch-and-bound strategy with tight distance bounds enables\nefficient identification of queries near the decision boundary. Experiments on\nUCI datasets show that our approach outperforms existing methods such as\nChoquetRank, achieving better ranking accuracy with fewer user interactions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u975e\u7ebf\u6027\u6548\u7528\u805a\u5408\u4e0e\u51e0\u4f55\u611f\u77e5\u67e5\u8be2\u9009\u62e9\u7684\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5982ChoquetRank\uff09\uff0c\u5728\u66f4\u5c11\u7684\u7528\u6237\u4ea4\u4e92\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6392\u540d\u51c6\u786e\u6027\u3002", "motivation": "\u6a21\u5f0f\u6316\u6398\u4e2d\u5b58\u5728\u6a21\u5f0f\u7206\u70b8\u7684\u95ee\u9898\uff0c\u5373\u6a21\u5f0f\u6570\u91cf\u8fc7\u591a\uff0c\u96be\u4ee5\u5904\u7406\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6a21\u5f0f\u6570\u91cf\u540c\u65f6\u4fdd\u7559\u7528\u6237\u5174\u8da3\u6a21\u5f0f\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4f7f\u7528Choquet\u79ef\u5206\u5bf9\u591a\u4e2a\u6709\u8da3\u5ea6\u91cf\u8fdb\u884c\u5efa\u6a21\uff0c\u4ee5\u6355\u6349\u7528\u6237\u504f\u597d\uff0c\u5e76\u5229\u7528\u7248\u672c\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u6307\u5bfc\u4fe1\u606f\u6bd4\u8f83\u7684\u9009\u62e9\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u5206\u652f\u5b9a\u754c\u7b56\u7565\u4e0e\u7d27\u5bc6\u7684\u8ddd\u79bb\u754c\u9650\u6765\u9ad8\u6548\u8bc6\u522b\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u7684\u67e5\u8be2\u3002", "result": "\u5728UCI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8f83\u5c11\u7684\u7528\u6237\u4ea4\u4e92\u4e0b\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\uff08\u4f8b\u5982ChoquetRank\uff09\u66f4\u597d\u7684\u6392\u540d\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4ea4\u4e92\u5f0f\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u89e3\u51b3\u6a21\u5f0f\u6316\u6398\u4e2d\u7684\u6a21\u5f0f\u7206\u70b8\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u5f0f\u6316\u6398\u7684\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2507.14796", "pdf": "https://arxiv.org/pdf/2507.14796", "abs": "https://arxiv.org/abs/2507.14796", "authors": ["Ceren Kocao\u011fullar", "Gustavo Petri", "Dominic P. Mulligan", "Derek Miller", "Hugo J. M. Vincent", "Shale Xiong", "Alastair R. Beresford"], "title": "Careful Whisper: Attestation for peer-to-peer Confidential Computing networks", "categories": ["cs.CR"], "comment": null, "summary": "Trusted Execution Environments (TEEs) are designed to protect the privacy and\nintegrity of data in use. They enable secure data processing and sharing in\npeer-to-peer networks, such as vehicular ad hoc networks of autonomous\nvehicles, without compromising confidentiality. In these networks, nodes must\nestablish mutual trust to collaborate securely. TEEs can achieve this through\nremote attestation, where a prover presents evidence of its trustworthiness to\na verifier, which then decides whether or not to trust the prover. However, a\nnaive peer-to-peer attestation approach, where every TEE directly attests every\nother TEE, results in quadratic communication overhead. This is inefficient in\ndynamic environments, where nodes frequently join and leave the network.\n  To address this, we present Careful Whisper, a gossip-based protocol that\ndisseminates trust efficiently, reducing attestation overhead to linear\ncomplexity under ideal conditions. It enables interoperability by enabling\ntransitive trust across heterogeneous networks, and supports trust\nestablishment with offline nodes via relayed attestations. Using a custom\ndiscrete-event simulator, we show that Careful Whisper propagates trust both\nfaster and more widely than naive approaches across various network topologies.\nOur results demonstrate that our protocol is resource efficient, sending ~21.5\nKiB and requiring 0.158 seconds per round in a 200-node network, and that our\nprotocol is resilient to attestation failures across various network\ntopologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u516b\u5366\u534f\u8bae\u7684Careful Whisper\uff0c\u5b83\u80fd\u6709\u6548\u4f20\u64ad\u4fe1\u4efb\uff0c\u5c06\u8ba4\u8bc1\u5f00\u9500\u964d\u4f4e\u5230\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u652f\u6301\u5f02\u6784\u7f51\u7edc\u4e2d\u7684\u4f20\u9012\u4fe1\u4efb\uff0c\u5e76\u901a\u8fc7\u4e2d\u7ee7\u8ba4\u8bc1\u4e0e\u79bb\u7ebf\u8282\u70b9\u5efa\u7acb\u4fe1\u4efb\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u534f\u8bae\u5728\u5404\u79cd\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u4e2d\u6bd4\u6734\u7d20\u65b9\u6cd5\u66f4\u5feb\u3001\u66f4\u5e7f\u6cdb\u5730\u4f20\u64ad\u4fe1\u4efb\uff0c\u4e14\u5bf9\u8ba4\u8bc1\u5931\u8d25\u5177\u6709\u5f39\u6027\u3002", "motivation": "\u73b0\u6709\u7684TEE\u76f4\u63a5\u76f8\u4e92\u8ba4\u8bc1\u7684\u65b9\u6cd5\u5728\u7f51\u7edc\u52a8\u6001\u53d8\u5316\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u6bcf\u6b21\u52a0\u5165\u6216\u79bb\u5f00\u8282\u70b9\u90fd\u4f1a\u5bfc\u81f4\u4e8c\u6b21\u901a\u4fe1\u5f00\u9500\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u673a\u5236\u6765\u51cf\u5c11\u8ba4\u8bc1\u8fc7\u7a0b\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCareful Whisper\u7684\u516b\u5366\u534f\u8bae\uff0c\u5b83\u80fd\u591f\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u5c06\u8ba4\u8bc1\u5f00\u9500\u4ece\u4e8c\u6b21\u964d\u5230\u7ebf\u6027\u590d\u6742\u5ea6\u3002\u8be5\u534f\u8bae\u8fd8\u5141\u8bb8\u4e0d\u540c\u7c7b\u578b\u7684\u7f51\u7edc\u4e4b\u95f4\u8fdb\u884c\u4e92\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u4e2d\u7ee7\u8ba4\u8bc1\u6765\u4e0e\u79bb\u7ebf\u8282\u70b9\u5efa\u7acb\u4fe1\u4efb\u3002", "result": "\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u5668\u8fdb\u884c\u7684\u6d4b\u8bd5\u8868\u660e\uff0cCareful Whisper\u534f\u8bae\u4e0d\u4ec5\u80fd\u5728\u5404\u79cd\u7f51\u7edc\u62d3\u6251\u4e2d\u5feb\u901f\u4e14\u5e7f\u6cdb\u5730\u4f20\u64ad\u4fe1\u4efb\uff0c\u800c\u4e14\u6bcf\u8f6e\u4ec5\u9700\u53d1\u9001\u7ea621.5 KiB\u7684\u6570\u636e\u5e76\u8017\u65f60.158\u79d2\uff0c\u5728200\u4e2a\u8282\u70b9\u7684\u7f51\u7edc\u4e2d\u5c55\u73b0\u4e86\u8d44\u6e90\u6548\u7387\u3002\u6b64\u5916\uff0c\u8be5\u534f\u8bae\u5728\u9762\u5bf9\u8ba4\u8bc1\u5931\u8d25\u65f6\u8868\u73b0\u51fa\u5f39\u6027\u3002", "conclusion": "Careful Whisper\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u89e3\u51b3\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u9ad8\u6548\u4f20\u64ad\u4fe1\u4efb\u7684\u95ee\u9898\uff0c\u5176\u6027\u80fd\u548c\u53ef\u9760\u6027\u90fd\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14219", "pdf": "https://arxiv.org/pdf/2507.14219", "abs": "https://arxiv.org/abs/2507.14219", "authors": ["Obumneme Zimuzor Nwafor", "Mohammed Abdul Majeed Al Hooti"], "title": "Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "As nations seek sustainable alternatives to fossil fuels, green hydrogen has\nemerged as a promising strategic pathway toward decarbonisation, particularly\nin solar-rich arid regions. However, identifying optimal locations for hydrogen\nproduction requires the integration of complex environmental, atmospheric, and\ninfrastructural factors, often compounded by limited availability of direct\nhydrogen yield data. This study presents a novel Artificial Intelligence (AI)\nframework for computing green hydrogen yield and site suitability index using\nmean absolute SHAP (SHapley Additive exPlanations) values. This framework\nconsists of a multi-stage pipeline of unsupervised multi-variable clustering,\nsupervised machine learning classifier and SHAP algorithm. The pipeline trains\non an integrated meteorological, topographic and temporal dataset and the\nresults revealed distinct spatial patterns of suitability and relative\ninfluence of the variables. With model predictive accuracy of 98%, the result\nalso showed that water proximity, elevation and seasonal variation are the most\ninfluential factors determining green hydrogen site suitability in Oman with\nmean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.\nGiven limited or absence of ground-truth yield data in many countries that have\ngreen hydrogen prospects and ambitions, this study offers an objective and\nreproducible alternative to subjective expert weightings, thus allowing the\ndata to speak for itself and potentially discover novel latent groupings\nwithout pre-imposed assumptions. This study offers industry stakeholders and\npolicymakers a replicable and scalable tool for green hydrogen infrastructure\nplanning and other decision making in data-scarce regions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u7eff\u8272\u6c22\u6c14\u4ea7\u91cf\u548c\u9009\u5740\u9002\u5b9c\u6027\u6307\u6570\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6c14\u8c61\u3001\u5730\u5f62\u548c\u65f6\u95f4\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u63ed\u793a\u4e86\u9009\u5740\u9002\u5b9c\u6027\u7684\u7a7a\u95f4\u6a21\u5f0f\uff0c\u5e76\u786e\u5b9a\u4e86\u5f71\u54cd\u6700\u5927\u7684\u56e0\u7d20\u662f\u6c34\u7684\u63a5\u8fd1\u5ea6\u3001\u6d77\u62d4\u548c\u5b63\u8282\u53d8\u5316\u3002", "motivation": "\u7531\u4e8e\u76f4\u63a5\u6c22\u6c14\u4ea7\u91cf\u6570\u636e\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc6\u522b\u6700\u4f73\u7684\u7eff\u8272\u6c22\u6c14\u751f\u4ea7\u5730\u70b9\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u6709\u7eff\u8272\u6c22\u6c14\u524d\u666f\u4f46\u7f3a\u4e4f\u5b9e\u6d4b\u6570\u636e\u7684\u56fd\u5bb6\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u7684\u7ba1\u9053\uff0c\u5305\u62ec\u65e0\u76d1\u7763\u7684\u591a\u53d8\u91cf\u805a\u7c7b\u3001\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u548cSHAP\u7b97\u6cd5\uff0c\u4ee5\u8ba1\u7b97\u7eff\u8272\u6c22\u6c14\u4ea7\u91cf\u548c\u9009\u5740\u9002\u5b9c\u6027\u6307\u6570\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u4e3a98%\uff0c\u5e76\u53d1\u73b0\u6c34\u7684\u63a5\u8fd1\u5ea6\u3001\u6d77\u62d4\u548c\u5b63\u8282\u53d8\u5316\u662f\u5f71\u54cd\u7eff\u8272\u6c22\u6c14\u9009\u5740\u9002\u5b9c\u6027\u7684\u6700\u91cd\u8981\u56e0\u7d20\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u884c\u4e1a\u5229\u76ca\u76f8\u5173\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u5236\u548c\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u5728\u6570\u636e\u7a00\u7f3a\u5730\u533a\u89c4\u5212\u7eff\u8272\u6c22\u6c14\u57fa\u7840\u8bbe\u65bd\u548c\u5176\u4ed6\u51b3\u7b56\u3002"}}
{"id": "2507.14799", "pdf": "https://arxiv.org/pdf/2507.14799", "abs": "https://arxiv.org/abs/2507.14799", "authors": ["Sam Johnson", "Viet Pham", "Thai Le"], "title": "Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree", "categories": ["cs.CR", "cs.AI"], "comment": "EMNLP 2025 System Demonstrations Submission", "summary": "This work demonstrates that LLM-based web navigation agents offer powerful\nautomation capabilities but are vulnerable to Indirect Prompt Injection (IPI)\nattacks. We show that adversaries can embed universal adversarial triggers in\nwebpage HTML to hijack agent behavior that utilizes the accessibility tree to\nparse HTML, causing unintended or malicious actions. Using the Greedy\nCoordinate Gradient (GCG) algorithm and a Browser Gym agent powered by\nLlama-3.1, our system demonstrates high success rates across real websites in\nboth targeted and general attacks, including login credential exfiltration and\nforced ad clicks. Our empirical results highlight critical security risks and\nthe need for stronger defenses as LLM-driven autonomous web agents become more\nwidely adopted. The system software\n(https://github.com/sej2020/manipulating-web-agents) is released under the MIT\nLicense, with an accompanying publicly available demo website\n(http://lethaiq.github.io/attack-web-llm-agent).", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u7684\u7f51\u9875\u5bfc\u822a\u4ee3\u7406\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\uff08IPI\uff09\u653b\u51fb\u3002\u901a\u8fc7\u5728\u7f51\u9875HTML\u4e2d\u5d4c\u5165\u666e\u904d\u5bf9\u6297\u89e6\u53d1\u5668\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u52ab\u6301\u4f7f\u7528\u53ef\u8bbf\u95ee\u6027\u6811\u89e3\u6790HTML\u7684\u4ee3\u7406\u884c\u4e3a\uff0c\u5bfc\u81f4\u975e\u9884\u671f\u6216\u6076\u610f\u884c\u4e3a\u3002\u7814\u7a76\u4f7f\u7528Greedy Coordinate Gradient (GCG)\u7b97\u6cd5\u548c\u7531Llama-3.1\u9a71\u52a8\u7684Browser Gym\u4ee3\u7406\uff0c\u5728\u771f\u5b9e\u7f51\u7ad9\u4e0a\u5c55\u793a\u4e86\u9ad8\u6210\u529f\u7387\u7684\u653b\u51fb\uff0c\u5305\u62ec\u767b\u5f55\u51ed\u8bc1\u5916\u6cc4\u548c\u5f3a\u5236\u70b9\u51fb\u5e7f\u544a\u3002\u5b9e\u8bc1\u7ed3\u679c\u5f3a\u8c03\u4e86\u5173\u952e\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u547c\u5401\u968f\u7740LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u9875\u4ee3\u7406\u88ab\u66f4\u5e7f\u6cdb\u91c7\u7528\u65f6\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5e76\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u7f51\u9875\u5bfc\u822a\u4ee3\u7406\u6240\u9762\u4e34\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u9488\u5bf9\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\uff08IPI\uff09\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002\u8fd9\u662f\u56e0\u4e3a\u8fd9\u7c7b\u4ee3\u7406\u6b63\u5728\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u5e94\u7528\u4e8e\u81ea\u52a8\u5316\u4efb\u52a1\u4e2d\uff0c\u5176\u5b89\u5168\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u4eba\u5458\u91c7\u7528\u4e86Greedy Coordinate Gradient (GCG)\u7b97\u6cd5\u6765\u8bc6\u522b\u548c\u5229\u7528\u7f51\u9875HTML\u4e2d\u7684\u5bf9\u6297\u89e6\u53d1\u5668\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u7531Llama-3.1\u9a71\u52a8\u7684Browser Gym\u4ee3\u7406\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u9488\u5bf9\u771f\u5b9e\u7f51\u7ad9\u7684\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u7c7b\u578b\u7684IPI\u653b\u51fb\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u65e0\u8bba\u662f\u9488\u5bf9\u6027\u653b\u51fb\u8fd8\u662f\u4e00\u822c\u6027\u653b\u51fb\uff0c\u7cfb\u7edf\u90fd\u8868\u73b0\u51fa\u6781\u9ad8\u7684\u6210\u529f\u7387\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u8bf8\u5982\u7a83\u53d6\u767b\u5f55\u51ed\u8bc1\u548c\u5f3a\u5236\u70b9\u51fb\u5e7f\u544a\u7b49\u653b\u51fb\u76ee\u6807\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u7f51\u9875\u5bfc\u822a\u4ee3\u7406\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9IPI\u653b\u51fb\u65f6\u3002\u968f\u7740\u8fd9\u7c7b\u6280\u672f\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u5fc5\u987b\u91cd\u89c6\u5e76\u52a0\u5f3a\u76f8\u5e94\u7684\u5b89\u5168\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2507.14227", "pdf": "https://arxiv.org/pdf/2507.14227", "abs": "https://arxiv.org/abs/2507.14227", "authors": ["Khoi Do", "Duong Nguyen", "Nam-Khanh Le", "Quoc-Viet Pham", "Binh-Son Hua", "Won-Joo Hwang"], "title": "Domain Generalization via Pareto Optimal Gradient Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this study, we address the gradient-based domain generalization problem,\nwhere predictors aim for consistent gradient directions across different\ndomains. Existing methods have two main challenges. First, minimization of\ngradient empirical distance or gradient inner products (GIP) leads to gradient\nfluctuations among domains, thereby hindering straightforward learning. Second,\nthe direct application of gradient learning to the joint loss function can\nincur high computation overheads due to second-order derivative approximation.\nTo tackle these challenges, we propose a new Pareto Optimality Gradient\nMatching (POGM) method. In contrast to existing methods that add gradient\nmatching as regularization, we leverage gradient trajectories as collected data\nand apply independent training at the meta-learner. In the meta-update, we\nmaximize GIP while limiting the learned gradient from deviating too far from\nthe empirical risk minimization gradient trajectory. By doing so, the aggregate\ngradient can incorporate knowledge from all domains without suffering gradient\nfluctuation towards any particular domain. Experimental evaluations on datasets\nfrom DomainBed demonstrate competitive results yielded by POGM against other\nbaselines while achieving computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Pareto Optimality Gradient Matching (POGM)\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u68af\u5ea6\u5339\u914d\u4e2d\u7684\u9886\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u7ade\u4e89\u529b\uff0c\u5e76\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1\uff09\u6700\u5c0f\u5316\u68af\u5ea6\u7ecf\u9a8c\u8ddd\u79bb\u6216\u68af\u5ea6\u5185\u79ef\uff08GIP\uff09\u5bfc\u81f4\u4e0d\u540c\u9886\u57df\u7684\u68af\u5ea6\u6ce2\u52a8\uff1b2\uff09\u76f4\u63a5\u5e94\u7528\u4e8e\u8054\u5408\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u5b66\u4e60\u4f1a\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86Pareto Optimality Gradient Matching (POGM)\u65b9\u6cd5\uff0c\u5229\u7528\u68af\u5ea6\u8f68\u8ff9\u4f5c\u4e3a\u6536\u96c6\u7684\u6570\u636e\uff0c\u5e76\u5728meta-learner\u4e2d\u5e94\u7528\u72ec\u7acb\u8bad\u7ec3\uff0c\u5728meta\u66f4\u65b0\u4e2d\u6700\u5927\u5316GIP\uff0c\u540c\u65f6\u9650\u5236\u5b66\u4e60\u5230\u7684\u68af\u5ea6\u504f\u79bb\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u68af\u5ea6\u8f68\u8ff9\u592a\u8fdc\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cPOGM\u5728\u6765\u81eaDomainBed\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4e0e\u5176\u5b83\u57fa\u7ebf\u65b9\u6cd5\u7ade\u4e89\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "POGM\u65b9\u6cd5\u53ef\u4ee5\u7ed3\u5408\u6240\u6709\u9886\u57df\u7684\u77e5\u8bc6\uff0c\u907f\u514d\u4efb\u4f55\u7279\u5b9a\u9886\u57df\u7684\u68af\u5ea6\u6ce2\u52a8\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u6311\u6218\u5e76\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.14822", "pdf": "https://arxiv.org/pdf/2507.14822", "abs": "https://arxiv.org/abs/2507.14822", "authors": ["Zeeshan Kaleem", "Misha Urooj Khan", "Ahmad Suleman", "Waqas Khalid", "Kai-Kit Wong", "Chau Yuen"], "title": "Quantum Skyshield: Quantum Key Distribution and Post-Quantum Authentication for Low-Altitude Wireless Networks in Adverse Skies", "categories": ["cs.CR", "cs.ET", "quant-ph"], "comment": null, "summary": "Recently, low-altitude wireless networks (LAWNs) have emerged as a critical\nbackbone for supporting the low-altitude economy, particularly with the\ndensification of unmanned aerial vehicles (UAVs) and high-altitude platforms\n(HAPs). To meet growing data demands, some LAWN deployments incorporate\nfree-space optical (FSO) links, which offer exceptional bandwidth and beam\ndirectivity. However, without strong security measures in place, both\nconventional radio frequency channels and FSO beams remain vulnerable to\ninterception and spoofing and FSO in particular can suffer from turbulence,\nmisalignment, and weather-related attenuation. To address these challenges in\nthe quantum era, a quantum-secure architecture called Quantum Skyshield is\nproposed to enable reliable communication between the base transceiver station\n(BTS) and LAWN. The proposed design integrates BB84 quantum key distribution\n(QKD) with post-quantum authentication mechanisms. Simulation results confirm\nthe reliable generation of a 128-bit symmetric key when the quantum bit error\nrate (QBER) remains below the threshold of 11%. Authentication is enforced\nusing Lamport one-time signatures and hash-based message authentication codes\n(HMAC) to ensure message integrity. A Grover-inspired threat detection\nmechanism identifies anomalies with up to 89% probability in a single\niteration, enabling real-time trust evaluation. Lastly, future research\nchallenges have also been identified and discussed to guide further development\nin this area.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuantum Skyshield\u7684\u91cf\u5b50\u5b89\u5168\u67b6\u6784\uff0c\u7ed3\u5408\u4e86BB84\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u548c\u540e\u91cf\u5b50\u8ba4\u8bc1\u673a\u5236\uff0c\u4ee5\u5b9e\u73b0\u57fa\u7ad9\u548c\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e4b\u95f4\u7684\u53ef\u9760\u901a\u4fe1\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\u5728\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\u4f4e\u4e8e11%\u65f6\u80fd\u53ef\u9760\u751f\u6210128\u4f4d\u5bf9\u79f0\u5bc6\u94a5\uff0c\u5e76\u4f7f\u7528Lamport\u4e00\u6b21\u6027\u7b7e\u540d\u548cHMAC\u786e\u4fdd\u6d88\u606f\u5b8c\u6574\u6027\uff0cGrover\u542f\u53d1\u5f0f\u5a01\u80c1\u68c0\u6d4b\u673a\u5236\u80fd\u5728\u4e00\u6b21\u8fed\u4ee3\u4e2d\u4ee5\u9ad8\u8fbe89%\u7684\u6982\u7387\u8bc6\u522b\u5f02\u5e38\u3002", "motivation": "\u968f\u7740\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\uff08LAWN\uff09\u6210\u4e3a\u652f\u6301\u4f4e\u7a7a\u7ecf\u6d4e\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\uff0c\u7279\u522b\u662f\u65e0\u4eba\u98de\u884c\u5668\uff08UAV\uff09\u548c\u9ad8\u7a7a\u5e73\u53f0\uff08HAP\uff09\u7684\u5bc6\u96c6\u5316\uff0c\u4e3a\u4e86\u6ee1\u8db3\u4e0d\u65ad\u589e\u957f\u7684\u6570\u636e\u9700\u6c42\uff0c\u4e00\u4e9bLAWN\u90e8\u7f72\u5f15\u5165\u4e86\u81ea\u7531\u7a7a\u95f4\u5149\u94fe\u8def\uff08FSO\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u94fe\u8def\u7f3a\u4e4f\u5f3a\u5927\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u5bb9\u6613\u53d7\u5230\u62e6\u622a\u3001\u6b3a\u9a97\u7b49\u653b\u51fb\uff0c\u7279\u522b\u662f\u5728\u91cf\u5b50\u65f6\u4ee3\u80cc\u666f\u4e0b\uff0c\u8fd9\u5bf9\u901a\u4fe1\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u7ed3\u5408\u4e86BB84\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u534f\u8bae\u4e0e\u540e\u91cf\u5b50\u8ba4\u8bc1\u673a\u5236\uff0c\u5305\u62ecLamport\u4e00\u6b21\u6027\u7b7e\u540d\u548c\u57fa\u4e8e\u54c8\u5e0c\u7684\u6d88\u606f\u8ba4\u8bc1\u7801\uff08HMAC\uff09\uff0c\u7528\u4e8e\u4fdd\u8bc1\u6d88\u606f\u7684\u5b8c\u6574\u6027\u548c\u771f\u5b9e\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u53d7Grover\u7b97\u6cd5\u542f\u53d1\u7684\u5a01\u80c1\u68c0\u6d4b\u673a\u5236\uff0c\u7528\u4ee5\u8bc6\u522b\u5f02\u5e38\u5e76\u8fdb\u884c\u5b9e\u65f6\u4fe1\u4efb\u8bc4\u4f30\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\uff08QBER\uff09\u4fdd\u6301\u572811%\u4ee5\u4e0b\u65f6\uff0c\u80fd\u591f\u53ef\u9760\u5730\u751f\u6210128\u4f4d\u5bf9\u79f0\u5bc6\u94a5\u3002\u540c\u65f6\uff0c\u4f7f\u7528Lamport\u4e00\u6b21\u6027\u7b7e\u540d\u548cHMAC\u53ef\u4ee5\u6709\u6548\u4fdd\u969c\u6d88\u606f\u7684\u5b8c\u6574\u6027\u3002Grover\u542f\u53d1\u5f0f\u5a01\u80c1\u68c0\u6d4b\u673a\u5236\u80fd\u591f\u5728\u4e00\u6b21\u8fed\u4ee3\u4e2d\u4ee5\u9ad8\u8fbe89%\u7684\u6982\u7387\u8bc6\u522b\u51fa\u5f02\u5e38\u3002", "conclusion": "Quantum Skyshield\u67b6\u6784\u4e3a\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u7684\u80cc\u666f\u4e0b\u4fdd\u62a4\u901a\u4fe1\u514d\u53d7\u5404\u79cd\u653b\u51fb\u3002\u672a\u6765\u7684\u7814\u7a76\u5c06\u9700\u8981\u7ee7\u7eed\u63a2\u7d22\u5982\u4f55\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7cfb\u7edf\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u89e3\u51b3\u5b9e\u9645\u90e8\u7f72\u4e2d\u53ef\u80fd\u9047\u5230\u7684\u95ee\u9898\u3002"}}
{"id": "2507.14245", "pdf": "https://arxiv.org/pdf/2507.14245", "abs": "https://arxiv.org/abs/2507.14245", "authors": ["Hengjie Yu", "Kenneth A. Dawson", "Haiyun Yang", "Shuya Liu", "Yan Yan", "Yaochu Jin"], "title": "A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "cs.CE", "q-bio.BM", "I.6.5; J.3; I.5.4"], "comment": "31 pages, 6 figures", "summary": "Unlocking the potential of nanomaterials in medicine and environmental\nscience hinges on understanding their interactions with proteins, a complex\ndecision space where AI is poised to make a transformative impact. However,\nprogress has been hindered by limited datasets and the restricted\ngeneralizability of existing models. Here, we propose NanoPro-3M, the largest\nnanomaterial-protein interaction dataset to date, comprising over 3.2 million\nsamples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,\na foundational model that predicts nanomaterial-protein affinities through\nmultimodal representation learning, demonstrating strong generalization,\nhandling missing features, and unseen nanomaterials or proteins. We show that\nmultimodal modeling significantly outperforms single-modality approaches and\nidentifies key determinants of corona formation. Furthermore, we demonstrate\nits applicability to a range of downstream tasks through zero-shot inference\nand fine-tuning. Together, this work establishes a solid foundation for\nhigh-performance and generalized prediction of nanomaterial-protein interaction\nendpoints, reducing experimental reliance and accelerating various in vitro\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NanoPro-3M\u6570\u636e\u96c6\u548cNanoProFormer\u6a21\u578b\uff0c\u4ee5\u9884\u6d4b\u7eb3\u7c73\u6750\u6599\u4e0e\u86cb\u767d\u8d28\u7684\u4eb2\u548c\u529b\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u5728\u5904\u7406\u7f3a\u5931\u7279\u5f81\u548c\u672a\u89c1\u6837\u672c\u4e0a\u7684\u4f18\u52bf\u3002", "motivation": "\u89e3\u9501\u7eb3\u7c73\u6750\u6599\u5728\u533b\u5b66\u548c\u73af\u5883\u79d1\u5b66\u4e2d\u7684\u6f5c\u529b\u9700\u8981\u7406\u89e3\u5b83\u4eec\u4e0e\u86cb\u767d\u8d28\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u800c\u8fd9\u4e00\u9886\u57df\u76ee\u524d\u53d7\u5230\u6709\u9650\u7684\u6570\u636e\u96c6\u548c\u73b0\u6709\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u963b\u788d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNanoProFormer\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6765\u9884\u6d4b\u7eb3\u7c73\u6750\u6599\u4e0e\u86cb\u767d\u8d28\u4e4b\u95f4\u7684\u4eb2\u548c\u6027\uff0c\u5e76\u4f7f\u7528\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u4ea4\u4e92\u6570\u636e\u96c6NanoPro-3M\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u591a\u6a21\u6001\u5efa\u6a21\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u51a0\u72b6\u5f62\u6210\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u5e76\u9002\u7528\u4e8e\u4e00\u7cfb\u5217\u4e0b\u6e38\u4efb\u52a1\uff0c\u5305\u62ec\u96f6\u6837\u672c\u63a8\u7406\u548c\u5fae\u8c03\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u9ad8\u6027\u80fd\u548c\u5e7f\u4e49\u5316\u7684\u7eb3\u7c73\u6750\u6599-\u86cb\u767d\u8d28\u4ea4\u4e92\u9884\u6d4b\u5efa\u7acb\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u51cf\u5c11\u4e86\u5b9e\u9a8c\u4f9d\u8d56\u5e76\u52a0\u901f\u4e86\u5404\u79cd\u4f53\u5916\u5e94\u7528\u3002"}}
{"id": "2507.14853", "pdf": "https://arxiv.org/pdf/2507.14853", "abs": "https://arxiv.org/abs/2507.14853", "authors": ["Khoa Nguyen", "Tanveer Khan", "Antonis Michalas"], "title": "A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training without sharing\nraw data, making it a promising approach for privacy-sensitive domains. Despite\nits potential, FL faces significant challenges, particularly in terms of\ncommunication overhead and data privacy. Privacy-preserving Techniques (PPTs)\nsuch as Homomorphic Encryption (HE) have been used to mitigate these concerns.\nHowever, these techniques introduce substantial computational and communication\ncosts, limiting their practical deployment. In this work, we explore how Hybrid\nHomomorphic Encryption (HHE), a cryptographic protocol that combines symmetric\nencryption with HE, can be effectively integrated with FL to address both\ncommunication and privacy challenges, paving the way for scalable and secure\ndecentralized learning system.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u6df7\u5408\u540c\u6001\u52a0\u5bc6(HHE)\u4e0e\u8054\u90a6\u5b66\u4e60(FL)\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u901a\u4fe1\u548c\u9690\u79c1\u6311\u6218\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u9690\u79c1\u654f\u611f\u9886\u57df\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u901a\u4fe1\u5f00\u9500\u548c\u6570\u636e\u9690\u79c1\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\uff08\u5982\u540c\u6001\u52a0\u5bc6\uff09\u867d\u7136\u80fd\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5e26\u6765\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f5c\u8005\u63a2\u7d22\u4e86\u6df7\u5408\u540c\u6001\u52a0\u5bc6\uff08HHE\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u7ed3\u5408\u5bf9\u79f0\u52a0\u5bc6\u4e0e\u540c\u6001\u52a0\u5bc6\u7684\u5bc6\u7801\u534f\u8bae\uff0c\u5e76\u7814\u7a76\u5176\u5982\u4f55\u4e0e\u8054\u90a6\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u4ece\u800c\u540c\u65f6\u89e3\u51b3\u901a\u4fe1\u548c\u9690\u79c1\u95ee\u9898\u3002", "result": "\u8bba\u6587\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u8868\u660e\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3FL\u4e2d\u7684\u901a\u4fe1\u548c\u9690\u79c1\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u80fd\u7684\u9014\u5f84\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408HHE\u4e0eFL\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u52a0\u53ef\u6269\u5c55\u4e14\u5b89\u5168\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\uff0c\u4ece\u800c\u63a8\u52a8FL\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.14257", "pdf": "https://arxiv.org/pdf/2507.14257", "abs": "https://arxiv.org/abs/2507.14257", "authors": ["Julio Candanedo"], "title": "Linearized Diffusion Map", "categories": ["cs.LG"], "comment": null, "summary": "We introduce the Linearized Diffusion Map (LDM), a novel linear\ndimensionality reduction method constructed via a linear approximation of the\ndiffusion-map kernel. LDM integrates the geometric intuition of diffusion-based\nnonlinear methods with the computational simplicity, efficiency, and\ninterpretability inherent in linear embeddings such as PCA and classical MDS.\nThrough comprehensive experiments on synthetic datasets (Swiss roll and\nhyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that\nLDM captures distinct geometric features of datasets compared to PCA, offering\ncomplementary advantages. Specifically, LDM embeddings outperform PCA in\ndatasets exhibiting explicit manifold structures, particularly in\nhigh-dimensional regimes, whereas PCA remains preferable in scenarios dominated\nby variance or noise. Furthermore, the complete positivity of LDM's kernel\nmatrix allows direct applicability of Non-negative Matrix Factorization (NMF),\nsuggesting opportunities for interpretable latent-structure discovery. Our\nanalysis positions LDM as a valuable new linear dimensionality reduction\ntechnique with promising theoretical and practical extensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\u2014\u2014\u7ebf\u6027\u6269\u6563\u56fe\uff08LDM\uff09\uff0c\u901a\u8fc7\u7efc\u5408\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u76f4\u89c9\u548c\u7ebf\u6027\u5d4c\u5165\u7684\u8ba1\u7b97\u7b80\u4fbf\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u4e14\u652f\u6301\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\u5982PCA\u867d\u7136\u7b80\u5355\u9ad8\u6548\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u660e\u786e\u6d41\u5f62\u7ed3\u6784\u7684\u6570\u636e\u65f6\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u9009\u62e9\u3002\u4e3a\u4e86\u7ed3\u5408\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u4f18\u52bf\u4e0e\u7ebf\u6027\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u63d0\u51fa\u4e86\u7ebf\u6027\u6269\u6563\u56fe\uff08LDM\uff09\u3002", "method": "LDM\u662f\u901a\u8fc7\u5bf9\u6269\u6563\u6838\u8fdb\u884c\u7ebf\u6027\u8fd1\u4f3c\u800c\u6784\u5efa\u7684\u3002\u5b83\u4fdd\u7559\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u975e\u7ebf\u6027\u65b9\u6cd5\u7684\u51e0\u4f55\u7406\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ebf\u6027\u5d4c\u5165\u7684\u8ba1\u7b97\u7b80\u6613\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u5916\uff0cLDM\u7684\u6838\u77e9\u9635\u5b8c\u5168\u6b63\u5b9a\uff0c\u8fd9\u4f7f\u5f97\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u8868\u73b0\u51fa\u660e\u663e\u6d41\u5f62\u7ed3\u6784\u7684\u6570\u636e\u96c6\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\uff0cLDM\u5d4c\u5165\u7684\u8868\u73b0\u4f18\u4e8ePCA\uff1b\u800c\u5728\u4e3b\u8981\u7531\u65b9\u5dee\u6216\u566a\u58f0\u4e3b\u5bfc\u7684\u60c5\u666f\u4e2d\uff0cPCA\u4ecd\u7136\u66f4\u4f18\u3002", "conclusion": "LDM\u4f5c\u4e3a\u4e00\u79cd\u6709\u4ef7\u503c\u7684\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff0c\u4e0d\u4ec5\u7406\u8bba\u4e0a\u6709\u5438\u5f15\u529b\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e5f\u663e\u793a\u51fa\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2507.14893", "pdf": "https://arxiv.org/pdf/2507.14893", "abs": "https://arxiv.org/abs/2507.14893", "authors": ["Farzin Renan"], "title": "A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies", "categories": ["cs.CR", "math.NT", "11T71, 94A60, 68P25, 14G50, 81P94"], "comment": null, "summary": "Digital signatures are essential cryptographic tools that provide\nauthentication and integrity in digital communications. However,\nprivacy-sensitive applications, such as e-voting and digital cash, require more\nrestrictive verification models to ensure confidentiality and control. Strong\nDesignated Verifier Signature (SDVS) schemes address this need by enabling the\nsigner to designate a specific verifier, ensuring that only this party can\nvalidate the signature. Existing SDVS constructions are primarily based on\nnumber-theoretic assumptions and are therefore vulnerable to quantum attacks.\nAlthough post-quantum alternatives, particularly those based on lattices, have\nbeen proposed, they often entail large key and signature sizes. In this work,\nwe introduce $\\mathsf{CSI\\text{-}SDVS}$, a novel isogeny-based SDVS scheme that\noffers a compact, quantum-resistant alternative. Our construction builds on the\nideal class group action framework of CSIDH and the signature techniques of\nCSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse\nProblem (MT-GAIP). $\\mathsf{CSI\\text{-}SDVS}$ achieves strong security\nguarantees; namely, Strong Unforgeability under Chosen-Message Attacks\n(SUF-CMA), Non-Transferability (NT), and Privacy of Signer's Identity (PSI), in\nthe random oracle model. Remarkably, both the keys and signatures in\n$\\mathsf{CSI\\text{-}SDVS}$ are of size $\\mathcal{O}(\\lambda)$, representing a\nsignificant improvement over the typical $\\mathcal{O}(\\lambda^2)$ bounds in\nexisting post-quantum SDVS schemes, thereby making it among the most compact\nPQC-based SDVS schemes and the only post-quantum secure construction based on\nisogenies.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14295", "pdf": "https://arxiv.org/pdf/2507.14295", "abs": "https://arxiv.org/abs/2507.14295", "authors": ["Licheng Liu", "Zihan Wang", "Linjie Li", "Chenwei Xu", "Yiping Lu", "Han Liu", "Avirup Sil", "Manling Li"], "title": "A Simple \"Try Again\" Can Elicit Multi-Turn LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-turn problem solving is critical yet challenging for Large Reasoning\nModels (LRMs) to reflect on their reasoning and revise from feedback. Existing\nReinforcement Learning (RL) methods train large reasoning models on a\nsingle-turn paradigm with verifiable rewards. However, we observe that models\ntrained with existing RL paradigms often lose their ability to solve problems\nacross multiple turns and struggle to revise answers based on contextual\nfeedback, leading to repetitive responses. We ask: can LRMs learn to reflect\ntheir answers in a multi-turn context? In this work, we find that training\nmodels with multi-turn RL using only unary feedback (e.g., \"Let's try again\")\nafter wrong answers can improve both single-turn performance and multi-turn\nreasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement\nlearning, which uses minimal yet common unary user feedback during iterative\nproblem solving. It can be easily applied to existing single-turn RL training\nsetups. Experimental results show that RL training with UFO keeps single-turn\nperformance and improves multi-turn reasoning accuracy by up to 14%, enabling\nlanguage models to better react to feedback in multi-turn problem solving. To\nfurther minimize the number of turns needed for a correct answer while\nencouraging diverse reasoning when mistakes occur, we design reward structures\nthat guide models to produce careful and deliberate answers in each turn. Code:\nhttps://github.com/lichengliu03/unary-feedback", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u4f7f\u7528\u4ec5\u5305\u542b\u4e00\u5143\u53cd\u9988\uff08\u5982\u201c\u8ba9\u6211\u4eec\u518d\u8bd5\u4e00\u6b21\u201d\uff09\u7684\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5355\u8f6e\u548c\u591a\u8f6e\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684RL\u65b9\u6cd5\u5728\u5355\u8f6e\u8303\u5f0f\u4e0b\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5728\u591a\u8f6e\u63a8\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u6839\u636e\u4e0a\u4e0b\u6587\u53cd\u9988\u8fdb\u884c\u4fee\u6b63\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7a76\u5927\u578b\u63a8\u7406\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u5728\u591a\u8f6e\u80cc\u666f\u4e0b\u5b66\u4e60\u53cd\u601d\u7b54\u6848\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aUFO\uff08Unary Feedback as Observation\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u3002UFO\u5229\u7528\u6700\u5c0f\u4e14\u5e38\u89c1\u7684\u4e00\u5143\u7528\u6237\u53cd\u9988\uff0c\u5728\u8fed\u4ee3\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u5956\u52b1\u7ed3\u6784\uff0c\u4ee5\u6307\u5bfc\u6a21\u578b\u5728\u6bcf\u8f6e\u4ea7\u751f\u8c28\u614e\u548c\u6df1\u601d\u719f\u8651\u7684\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5e26\u6709UFO\u7684RL\u8bad\u7ec3\u4fdd\u6301\u4e86\u5355\u8f6e\u6027\u80fd\uff0c\u5e76\u5c06\u591a\u8f6e\u63a8\u7406\u51c6\u786e\u6027\u63d0\u9ad8\u4e86\u591a\u8fbe14\uff05\u3002", "conclusion": "UFO\u65b9\u6cd5\u80fd\u591f\u4f7f\u8bed\u8a00\u6a21\u578b\u66f4\u597d\u5730\u54cd\u5e94\u591a\u8f6e\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u53cd\u9988\uff0c\u540c\u65f6\u901a\u8fc7\u8bbe\u8ba1\u7684\u5956\u52b1\u7ed3\u6784\u51cf\u5c11\u6b63\u786e\u56de\u7b54\u6240\u9700\u7684\u8f6e\u6570\uff0c\u5e76\u9f13\u52b1\u9519\u8bef\u53d1\u751f\u65f6\u7684\u591a\u6837\u5316\u63a8\u7406\u3002"}}
{"id": "2507.14985", "pdf": "https://arxiv.org/pdf/2507.14985", "abs": "https://arxiv.org/abs/2507.14985", "authors": ["Argianto Rahartomo", "Leonel Merino", "Mohammad Ghafari"], "title": "Metaverse Security and Privacy Research: A Systematic Review", "categories": ["cs.CR", "cs.ET", "cs.HC", "cs.SE"], "comment": "The paper is accepted for publication at Computers & Security Journal", "summary": "The rapid growth of metaverse technologies, including virtual worlds,\naugmented reality, and lifelogging, has accelerated their adoption across\ndiverse domains. This rise exposes users to significant new security and\nprivacy challenges due to sociotechnical complexity, pervasive connectivity,\nand extensive user data collection in immersive environments. We present a\nsystematic review of the literature published between 2013 and 2024, offering a\ncomprehensive analysis of how the research community has addressed\nmetaverse-related security and privacy issues over the past decade. We organize\nthe studies by method, examined the security and privacy properties, immersive\ncomponents, and evaluation strategies. Our investigation reveals a sharp\nincrease in research activity in the last five years, a strong focus on\npractical and user-centered approaches, and a predominant use of benchmarking,\nhuman experimentation, and qualitative methods. Authentication and\nunobservability are the most frequently studied properties. However, critical\ngaps remain in areas such as policy compliance, accessibility,\ninteroperability, and back-end infrastructure security. We emphasize the\nintertwined technical complexity and human factors of the metaverse and call\nfor integrated, interdisciplinary approaches to securing inclusive and\ntrustworthy immersive environments.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u56de\u987e\u4e862013\u5e74\u81f32024\u5e74\u5173\u4e8e\u5143\u5b87\u5b99\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\u7684\u6587\u732e\uff0c\u63ed\u793a\u7814\u7a76\u6d3b\u52a8\u6fc0\u589e\u3001\u4ee5\u5b9e\u7528\u548c\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u4e3a\u4e3b\u5bfc\uff0c\u4f46\u4ecd\u5b58\u5728\u653f\u7b56\u9075\u4ece\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u7b49\u9886\u57df\u7684\u5173\u952e\u7a7a\u767d\u3002", "motivation": "\u968f\u7740\u5143\u5b87\u5b99\u6280\u672f\uff08\u5982\u865a\u62df\u4e16\u754c\u3001\u589e\u5f3a\u73b0\u5b9e\u548c\u751f\u6d3b\u8bb0\u5f55\uff09\u7684\u8fc5\u901f\u53d1\u5c55\uff0c\u8fd9\u4e9b\u6280\u672f\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u7684\u5e94\u7528\u66b4\u9732\u51fa\u663e\u8457\u7684\u5b89\u5168\u548c\u9690\u79c1\u6311\u6218\u3002", "method": "\u4f5c\u8005\u5bf92013\u5e74\u81f32024\u5e74\u95f4\u53d1\u8868\u7684\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u56de\u987e\uff0c\u6309\u65b9\u6cd5\u7ec4\u7ec7\u7814\u7a76\uff0c\u68c0\u67e5\u5b89\u5168\u6027\u548c\u9690\u79c1\u5c5e\u6027\u3001\u6c89\u6d78\u5f0f\u7ec4\u4ef6\u53ca\u8bc4\u4f30\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u8fc7\u53bb\u4e94\u5e74\u4e2d\u7814\u7a76\u6d3b\u52a8\u6025\u5267\u589e\u52a0\uff0c\u91cd\u70b9\u662f\u5b9e\u9645\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u5e76\u4e3b\u8981\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u3001\u4eba\u7c7b\u5b9e\u9a8c\u548c\u5b9a\u6027\u65b9\u6cd5\u3002\u8ba4\u8bc1\u548c\u4e0d\u53ef\u89c2\u5bdf\u6027\u662f\u6700\u5e38\u7814\u7a76\u7684\u5c5e\u6027\uff0c\u4f46\u5728\u653f\u7b56\u5408\u89c4\u3001\u53ef\u8bbf\u95ee\u6027\u7b49\u65b9\u9762\u4ecd\u5b58\u5728\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5143\u5b87\u5b99\u7684\u6280\u672f\u590d\u6742\u6027\u548c\u4eba\u4e3a\u56e0\u7d20\u7684\u4ea4\u7ec7\uff0c\u5e76\u547c\u5401\u91c7\u7528\u7efc\u5408\u6027\u7684\u8de8\u5b66\u79d1\u65b9\u6cd5\u6765\u786e\u4fdd\u5305\u5bb9\u548c\u53ef\u4fe1\u7684\u6c89\u6d78\u5f0f\u73af\u5883\u3002"}}
{"id": "2507.14322", "pdf": "https://arxiv.org/pdf/2507.14322", "abs": "https://arxiv.org/abs/2507.14322", "authors": ["Md Rafid Haque", "Abu Raihan Mostofa Kamal", "Md. Azam Hossain"], "title": "FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11; C.2.4; K.6.5"], "comment": "24 pages, 8 figures. This work is intended for a journal submission", "summary": "Federated Learning (FL) offers a paradigm for privacy-preserving\ncollaborative AI, but its decentralized nature creates significant\nvulnerabilities to model poisoning attacks. While numerous static defenses\nexist, their effectiveness is highly context-dependent, often failing against\nadaptive adversaries or in heterogeneous data environments. This paper\nintroduces FedStrategist, a novel meta-learning framework that reframes robust\naggregation as a real-time, cost-aware control problem. We design a lightweight\ncontextual bandit agent that dynamically selects the optimal aggregation rule\nfrom an arsenal of defenses based on real-time diagnostic metrics. Through\ncomprehensive experiments, we demonstrate that no single static rule is\nuniversally optimal. We show that our adaptive agent successfully learns\nsuperior policies across diverse scenarios, including a ``Krum-favorable\"\nenvironment and against a sophisticated \"stealth\" adversary designed to\nneutralize specific diagnostic signals. Critically, we analyze the paradoxical\nscenario where a non-robust baseline achieves high but compromised accuracy,\nand demonstrate that our agent learns a conservative policy to prioritize model\nintegrity. Furthermore, we prove the agent's policy is controllable via a\nsingle \"risk tolerance\" parameter, allowing practitioners to explicitly manage\nthe trade-off between performance and security. Our work provides a new,\npractical, and analyzable approach to creating resilient and intelligent\ndecentralized AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5143\u5b66\u4e60\u6846\u67b6FedStrategist\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6700\u4f18\u805a\u5408\u89c4\u5219\u6765\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u4fdd\u62a4\u9690\u79c1\u7684\u534f\u4f5cAI\u8303\u5f0f\uff0c\u4f46\u5176\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u6a21\u578b\u4e2d\u6bd2\u653b\u51fb\u3002\u73b0\u6709\u7684\u9759\u6001\u9632\u5fa1\u63aa\u65bd\u5728\u81ea\u9002\u5e94\u5bf9\u624b\u6216\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\u5f80\u5f80\u65e0\u6548\u3002", "method": "\u5f15\u5165\u4e86FedStrategist\u6846\u67b6\uff0c\u5c06\u9c81\u68d2\u805a\u5408\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5b9e\u65f6\u3001\u6210\u672c\u611f\u77e5\u7684\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u60c5\u5883\u5f3a\u76d7\u4ee3\u7406\uff0c\u6839\u636e\u5b9e\u65f6\u8bca\u65ad\u6307\u6807\u52a8\u6001\u9009\u62e9\u6700\u4f73\u805a\u5408\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6ca1\u6709\u5355\u4e00\u7684\u9759\u6001\u89c4\u5219\u662f\u666e\u904d\u6700\u4f18\u7684\uff0c\u800c\u81ea\u9002\u5e94\u4ee3\u7406\u80fd\u591f\u5b66\u4e60\u51fa\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u597d\u7684\u7b56\u7565\uff0c\u5e76\u80fd\u901a\u8fc7\u201c\u98ce\u9669\u5bb9\u5fcd\u5ea6\u201d\u53c2\u6570\u6765\u5e73\u8861\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u5efa\u5f39\u6027\u667a\u80fd\u53bb\u4e2d\u5fc3\u5316AI\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u8fdb\u884c\u660e\u786e\u6743\u8861\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.15058", "pdf": "https://arxiv.org/pdf/2507.15058", "abs": "https://arxiv.org/abs/2507.15058", "authors": ["Ian Hardgrove", "John D. Hastings"], "title": "LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries", "categories": ["cs.CR", "cs.LG", "cs.SE", "D.2.5; D.4.6"], "comment": "6 pages, 2 figures, 1 table, 2 listings", "summary": "A fundamental problem in cybersecurity and computer science is determining\nwhether a program is free of bugs and vulnerabilities. Fuzzing, a popular\napproach to discovering vulnerabilities in programs, has several advantages\nover alternative strategies, although it has investment costs in the form of\ninitial setup and continuous maintenance. The choice of fuzzing is further\ncomplicated when only a binary library is available, such as the case of\nclosed-source and proprietary software. In response, we introduce LibLMFuzz, a\nframework that reduces costs associated with fuzzing closed-source libraries by\npairing an agentic Large Language Model (LLM) with a lightweight tool-chain\n(disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan\nfuzz strategies, generate drivers, and iteratively self-repair build or runtime\nerrors. Tested on four widely-used Linux libraries, LibLMFuzz produced\nsyntactically correct drivers for all 558 fuzz-able API functions, achieving\n100% API coverage with no human intervention. Across the 1601 synthesized\ndrivers, 75.52% were nominally correct on first execution. The results show\nthat LLM-augmented middleware holds promise in reducing the costs of fuzzing\nblack box components and provides a foundation for future research efforts.\nFuture opportunities exist for research in branch coverage.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aLibLMFuzz\u7684\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5de5\u5177\u94fe\u6765\u51cf\u5c11\u6a21\u7cca\u6d4b\u8bd5\u95ed\u6e90\u5e93\u7684\u6210\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u56db\u4e2a\u5e38\u7528\u7684Linux\u5e93\u4e0a\u5b9e\u73b0\u4e86100%\u7684API\u8986\u76d6\uff0c\u5e76\u4e14\u5927\u90e8\u5206\u751f\u6210\u7684\u9a71\u52a8\u7a0b\u5e8f\u5728\u9996\u6b21\u6267\u884c\u65f6\u662f\u6b63\u786e\u7684\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u662f\u4e00\u79cd\u53d1\u73b0\u7a0b\u5e8f\u6f0f\u6d1e\u7684\u6d41\u884c\u65b9\u6cd5\uff0c\u4f46\u5728\u521d\u59cb\u8bbe\u7f6e\u548c\u6301\u7eed\u7ef4\u62a4\u65b9\u9762\u9700\u8981\u6295\u8d44\u6210\u672c\u3002\u5f53\u53ea\u6709\u4e8c\u8fdb\u5236\u5e93\u53ef\u7528\u65f6\uff0c\u9009\u62e9\u6a21\u7cca\u6d4b\u8bd5\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f15\u5165\u4e86LibLMFuzz\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u4ee3\u7406\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u8f7b\u91cf\u7ea7\u5de5\u5177\u94fe\uff08\u53cd\u6c47\u7f16\u5668/\u7f16\u8bd1\u5668/\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff09\u914d\u5bf9\uff0c\u4ee5\u81ea\u4e3b\u5206\u6790\u5265\u79bb\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u89c4\u5212\u6a21\u7cca\u7b56\u7565\uff0c\u751f\u6210\u9a71\u52a8\u7a0b\u5e8f\uff0c\u5e76\u8fed\u4ee3\u5730\u81ea\u6211\u4fee\u590d\u6784\u5efa\u6216\u8fd0\u884c\u65f6\u9519\u8bef\u3002", "result": "\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684Linux\u5e93\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0cLibLMFuzz\u4e3a\u6240\u6709558\u4e2a\u53ef\u6a21\u7ccaAPI\u51fd\u6570\u751f\u6210\u4e86\u8bed\u6cd5\u6b63\u786e\u7684\u9a71\u52a8\u7a0b\u5e8f\uff0c\u8fbe\u5230\u4e86100%\u7684API\u8986\u76d6\u7387\uff0c\u5e76\u4e14\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002\u5728\u5408\u6210\u76841601\u4e2a\u9a71\u52a8\u7a0b\u5e8f\u4e2d\uff0c75.52%\u5728\u9996\u6b21\u6267\u884c\u65f6\u662f\u540d\u4e49\u4e0a\u6b63\u786e\u7684\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u4e2d\u95f4\u4ef6\u5728\u51cf\u5c11\u9ed1\u76d2\u7ec4\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u6210\u672c\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5de5\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14326", "pdf": "https://arxiv.org/pdf/2507.14326", "abs": "https://arxiv.org/abs/2507.14326", "authors": ["Aryana Hou", "Li Lin", "Justin Li", "Shu Hu"], "title": "Rethinking Individual Fairness in Deepfake Detection", "categories": ["cs.LG", "cs.CY"], "comment": "This paper has been accepted by ACM MM 2025", "summary": "Generative AI models have substantially improved the realism of synthetic\nmedia, yet their misuse through sophisticated DeepFakes poses significant\nrisks. Despite recent advances in deepfake detection, fairness remains\ninadequately addressed, enabling deepfake markers to exploit biases against\nspecific populations. While previous studies have emphasized group-level\nfairness, individual fairness (i.e., ensuring similar predictions for similar\nindividuals) remains largely unexplored. In this work, we identify for the\nfirst time that the original principle of individual fairness fundamentally\nfails in the context of deepfake detection, revealing a critical gap previously\nunexplored in the literature. To mitigate it, we propose the first\ngeneralizable framework that can be integrated into existing deepfake detectors\nto enhance individual fairness and generalization. Extensive experiments\nconducted on leading deepfake datasets demonstrate that our approach\nsignificantly improves individual fairness while maintaining robust detection\nperformance, outperforming state-of-the-art methods. The code is available at\nhttps://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6a21\u578b\u867d\u7136\u5927\u5927\u63d0\u9ad8\u4e86\u5408\u6210\u5a92\u4f53\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u5176\u88ab\u6ee5\u7528\u4e3a\u590d\u6742\u7684\u6df1\u5ea6\u4f2a\u9020\uff08DeepFakes\uff09\u5e26\u6765\u4e86\u91cd\u5927\u98ce\u9669\u3002\u5c3d\u7ba1\u5728\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u516c\u5e73\u6027\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u4e2a\u4f53\u516c\u5e73\u6027\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u53ef\u4ee5\u96c6\u6210\u5230\u73b0\u6709\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4e2d\uff0c\u4ee5\u589e\u5f3a\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u4e2a\u4f53\u516c\u5e73\u6027\uff0c\u5e76\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u4ee3\u7801\u53ef\u5728https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection\u83b7\u5f97\u3002"}}
{"id": "2507.15219", "pdf": "https://arxiv.org/pdf/2507.15219", "abs": "https://arxiv.org/abs/2507.15219", "authors": ["Tianneng Shi", "Kaijie Zhu", "Zhun Wang", "Yuqi Jia", "Will Cai", "Weida Liang", "Haonan Wang", "Hend Alzahrani", "Joshua Lu", "Kenji Kawaguchi", "Basel Alomair", "Xuandong Zhao", "William Yang Wang", "Neil Gong", "Wenbo Guo", "Dawn Song"], "title": "PromptArmor: Simple yet Effective Prompt Injection Defenses", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Despite their potential, recent research has demonstrated that LLM agents are\nvulnerable to prompt injection attacks, where malicious prompts are injected\ninto the agent's input, causing it to perform an attacker-specified task rather\nthan the intended task provided by the user. In this paper, we present\nPromptArmor, a simple yet effective defense against prompt injection attacks.\nSpecifically, PromptArmor prompts an off-the-shelf LLM to detect and remove\npotential injected prompts from the input before the agent processes it. Our\nresults show that PromptArmor can accurately identify and remove injected\nprompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves\nboth a false positive rate and a false negative rate below 1% on the AgentDojo\nbenchmark. Moreover, after removing injected prompts with PromptArmor, the\nattack success rate drops to below 1%. We also demonstrate PromptArmor's\neffectiveness against adaptive attacks and explore different strategies for\nprompting an LLM. We recommend that PromptArmor be adopted as a standard\nbaseline for evaluating new defenses against prompt injection attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPromptArmor\u7684\u7b80\u5355\u800c\u6709\u6548\u7684\u9632\u5fa1\u63aa\u65bd\uff0c\u7528\u4e8e\u62b5\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cPromptArmor\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u5e76\u79fb\u9664\u6ce8\u5165\u7684\u63d0\u793a\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u81f31%\u4ee5\u4e0b\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0LLM\u4ee3\u7406\u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u4f7f\u4ee3\u7406\u6267\u884c\u653b\u51fb\u8005\u6307\u5b9a\u7684\u4efb\u52a1\u800c\u975e\u7528\u6237\u610f\u56fe\u7684\u4efb\u52a1\u3002", "method": "PromptArmor\u4fc3\u4f7f\u73b0\u6210\u7684LLM\u5728\u4ee3\u7406\u5904\u7406\u8f93\u5165\u524d\u68c0\u6d4b\u5e76\u79fb\u9664\u6f5c\u5728\u7684\u6ce8\u5165\u63d0\u793a\u3002", "result": "PromptArmor\u4f7f\u7528GPT-4o, GPT-4.1\u6216o4-mini\u5728AgentDojo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4f4e\u4e8e1%\u7684\u5047\u9633\u6027\u548c\u5047\u9634\u6027\u7387\uff0c\u5e76\u4e14\u5728\u79fb\u9664\u6ce8\u5165\u63d0\u793a\u540e\uff0c\u653b\u51fb\u6210\u529f\u7387\u964d\u81f31%\u4ee5\u4e0b\u3002", "conclusion": "\u5efa\u8bae\u5c06PromptArmor\u4f5c\u4e3a\u8bc4\u4f30\u65b0\u9632\u5fa1\u63aa\u65bd\u7684\u6807\u51c6\u57fa\u7ebf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5bf9\u9002\u5e94\u6027\u653b\u51fb\u7684\u6709\u6548\u6027\u4ee5\u53ca\u4e0d\u540c\u7684LLM\u63d0\u793a\u7b56\u7565\u3002"}}
{"id": "2507.14332", "pdf": "https://arxiv.org/pdf/2507.14332", "abs": "https://arxiv.org/abs/2507.14332", "authors": ["Aidan Furlong", "Xingang Zhao", "Robert Salko", "Xu Wu"], "title": "Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries", "categories": ["cs.LG"], "comment": "Accepted for inclusion in Transactions of the American Nuclear\n  Society for the 2025 ANS Winter Conference", "summary": "Accurate prediction of critical heat flux (CHF) is an essential component of\nsafety analysis in pressurized and boiling water reactors. To support reliable\nprediction of this quantity, several empirical correlations and lookup tables\nhave been constructed from physical experiments over the past several decades.\nWith the onset of accessible machine learning (ML) frameworks, multiple\ninitiatives have been established with the goal of predicting CHF more\naccurately than these traditional methods. While purely data-driven surrogate\nmodeling has been extensively investigated, these approaches lack\ninterpretability, lack resilience to data scarcity, and have been developed\nmostly using data from tube experiments. As a result, bias-correction hybrid\napproaches have become increasingly popular, which correct initial\n\"low-fidelity\" estimates provided by deterministic base models by using\nML-predicted residuals. This body of work has mostly considered round tube\ngeometries; annular geometry-specific ML models have not yet been deployed in\nthermal hydraulic codes. This study developed, deployed, and validated four ML\nmodels to predict CHF in annular geometries using the CTF subchannel code.\nThree empirical correlation models, Biasi, Bowring, and Katto, were used as\nbase models for comparison. The ML models were trained and tested using 577\nexperimental annulus data points from four datasets: Becker, Beus, Janssen, and\nMortimore. Baseline CHF predictions were obtained from the empirical\ncorrelations, with mean relative errors above 26%. The ML-driven models\nachieved mean relative errors below 3.5%, with no more than one point exceeding\nthe 10% error envelope. In all cases, the hybrid ML models significantly\noutperformed their empirical counterparts.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u9a8c\u8bc1\u4e86\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u4f7f\u7528CTF\u5b50\u901a\u9053\u4ee3\u7801\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u4e2d\u7684\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u3002\u901a\u8fc7\u4e0e\u4e09\u79cd\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u5bf9\u6bd4\uff0c\u5e76\u4f7f\u7528577\u4e2a\u5b9e\u9a8c\u6570\u636e\u70b9\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\uff0c\u53d1\u73b0ML\u9a71\u52a8\u7684\u6a21\u578b\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e3.5%\uff0c\u663e\u8457\u4f18\u4e8e\u7ecf\u9a8c\u6a21\u578b\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u538b\u6c34\u548c\u6cb8\u6c34\u53cd\u5e94\u5806\u4e2d\u7684\u4e34\u754c\u70ed\u901a\u91cf\uff08CHF\uff09\u5bf9\u4e8e\u5b89\u5168\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u5982\u7ecf\u9a8c\u76f8\u5173\u6027\u548c\u67e5\u627e\u8868\u5728\u89e3\u91ca\u6027\u3001\u6570\u636e\u7a00\u7f3a\u5f39\u6027\u548c\u9002\u7528\u8303\u56f4\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u4eba\u5458\u9009\u62e9\u4e86\u4e09\u4e2a\u7ecf\u9a8c\u5173\u8054\u6a21\u578b\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5e76\u5f00\u53d1\u4e86\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u6765\u81ea\u56db\u4e2a\u6570\u636e\u96c6\u7684577\u4e2a\u5b9e\u9a8c\u6570\u636e\u70b9\u5bf9\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002\u7136\u540e\u5c06\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u7ecf\u9a8c\u6a21\u578b\u7684\u7ed3\u679c\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u6a21\u578b\u5b9e\u73b0\u4e86\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e3.5%\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e14\u6ca1\u6709\u8d85\u8fc710%\u8bef\u5dee\u8303\u56f4\u7684\u6570\u636e\u70b9\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7ecf\u9a8c\u6a21\u578b\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u8d85\u8fc726%\u3002", "conclusion": "\u6df7\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u73af\u5f62\u51e0\u4f55\u7ed3\u6784\u4e2d\u7684\u4e34\u754c\u70ed\u901a\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7ecf\u9a8c\u6a21\u578b\uff0c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u4e3a\u53cd\u5e94\u5806\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2507.14154", "pdf": "https://arxiv.org/pdf/2507.14154", "abs": "https://arxiv.org/abs/2507.14154", "authors": ["Rahul Kabali"], "title": "The Free Will Equation: Quantum Field Analogies for AGI", "categories": ["cs.AI", "cs.LG", "68T05, 81P68", "I.2.6; I.2.0; F.1.2"], "comment": "22 pages, 5 figures. Submitted as an arXiv preprint. All code and\n  experiment details included in appendix", "summary": "Artificial General Intelligence (AGI) research traditionally focuses on\nalgorithms that optimize for specific goals under deterministic rules. Yet,\nhuman-like intelligence exhibits adaptive spontaneity - an ability to make\nunexpected choices or free decisions not strictly dictated by past data or\nimmediate reward. This trait, often dubbed \"free will\" in a loose sense, might\nbe crucial for creativity, robust adaptation, and avoiding ruts in\nproblem-solving. This paper proposes a theoretical framework, called the Free\nWill Equation, that draws analogies from quantum field theory to endow AGI\nagents with a form of adaptive, controlled stochasticity in their\ndecision-making process. The core idea is to treat an AI agent's cognitive\nstate as a superposition of potential actions or thoughts, which collapses\nprobabilistically into a concrete action when a decision is made - much like a\nquantum wavefunction collapsing upon measurement. By incorporating mechanisms\nanalogous to quantum fields, along with intrinsic motivation terms, we aim to\nimprove an agent's ability to explore novel strategies and adapt to unforeseen\nchanges. Experiments in a non-stationary multi-armed bandit environment\ndemonstrate that agents using this framework achieve higher rewards and policy\ndiversity compared to baseline methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684AGI\u51b3\u7b56\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7c7b\u4f3c\u91cf\u5b50\u573a\u8bba\u7684\u6982\u5ff5\uff0c\u4f7fAI\u5177\u6709\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u9002\u5e94\u6027\u548c\u521b\u9020\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u5956\u52b1\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edfAGI\u7814\u7a76\u96c6\u4e2d\u5728\u7279\u5b9a\u76ee\u6807\u4e0b\u7684\u7b97\u6cd5\u4f18\u5316\uff0c\u4f46\u4eba\u7c7b\u667a\u80fd\u8fd8\u8868\u73b0\u51fa\u9002\u5e94\u6027\u81ea\u53d1\u6027\uff0c\u5373\u5728\u4e0d\u5b8c\u5168\u7531\u8fc7\u53bb\u6570\u636e\u6216\u5373\u65f6\u5956\u52b1\u51b3\u5b9a\u7684\u60c5\u51b5\u4e0b\u505a\u51fa\u9009\u62e9\u7684\u80fd\u529b\u3002\u8fd9\u79cd\u7279\u8d28\u5bf9\u4e8e\u521b\u9020\u529b\u3001\u7a33\u5065\u9002\u5e94\u548c\u907f\u514d\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u50f5\u5c40\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u81ea\u7531\u610f\u5fd7\u65b9\u7a0b\u201d\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u91cf\u5b50\u573a\u8bba\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u5c06AI\u4ee3\u7406\u7684\u8ba4\u77e5\u72b6\u6001\u89c6\u4e3a\u6f5c\u5728\u52a8\u4f5c\u6216\u601d\u7ef4\u7684\u53e0\u52a0\u6001\uff0c\u5e76\u5728\u51b3\u7b56\u65f6\u4ee5\u6982\u7387\u65b9\u5f0f\u574d\u7f29\u4e3a\u5177\u4f53\u884c\u52a8\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u7c7b\u4f3c\u4e8e\u91cf\u5b50\u573a\u7684\u673a\u5236\u548c\u5185\u5728\u52a8\u673a\u9879\uff0c\u4ee5\u589e\u5f3a\u4ee3\u7406\u63a2\u7d22\u65b0\u7b56\u7565\u548c\u9002\u5e94\u4e0d\u53ef\u9884\u89c1\u53d8\u5316\u7684\u80fd\u529b\u3002", "result": "\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8d4c\u535a\u673a\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u7684\u4ee3\u7406\u76f8\u8f83\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u66f4\u9ad8\u7684\u56de\u62a5\u548c\u66f4\u591a\u7684\u653f\u7b56\u591a\u6837\u6027\u3002", "conclusion": "\u901a\u8fc7\u8d4b\u4e88AGI\u4ee3\u7406\u5f62\u5f0f\u7684\u9002\u5e94\u6027\u63a7\u5236\u968f\u673a\u6027\uff0c\u53ef\u4ee5\u6539\u8fdb\u5176\u63a2\u7d22\u65b0\u7b56\u7565\u548c\u9002\u5e94\u53d8\u5316\u7684\u80fd\u529b\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u95ee\u9898\u89e3\u51b3\u3002"}}
{"id": "2507.15377", "pdf": "https://arxiv.org/pdf/2507.15377", "abs": "https://arxiv.org/abs/2507.15377", "authors": ["Magali Bardet", "Charles Brion", "Philippe Gaborit", "Mercedes Haiech", "Romaric Neveu"], "title": "The Matrix Subcode Equivalence problem and its application to signature with MPC-in-the-Head", "categories": ["cs.CR"], "comment": null, "summary": "Nowadays, equivalence problems are widely used in cryptography, most notably\nto establish cryptosystems such as digital signatures, with MEDS, LESS, PERK as\nthe most recent ones. However, in the context of matrix codes, only the code\nequivalence problem has been studied, while the subcode equivalence is\nwell-defined in the Hamming metric. In this work, we introduce two new\nproblems: the Matrix Subcode Equivalence Problem and the Matrix Code Permuted\nKernel Problem, to which we apply the MPCitH paradigm to build a signature\nscheme. These new problems, closely related to the Matrix Code Equivalence\nproblem, ask to find an isometry given a code $C$ and a subcode $D$.\nFurthermore, we prove that the Matrix Subcode Equivalence problem reduces to\nthe Hamming Subcode Equivalence problem, which is known to be NP-Complete, thus\nintroducing the matrix code version of the Permuted Kernel Problem. We also\nadapt the combinatorial and algebraic algorithms for the Matrix Code\nEquivalence problem to the subcode case, and we analyze their complexities. We\nfind with this analysis that the algorithms perform much worse than in the code\nequivalence case, which is the same as what happens in the Hamming metric.\nFinally, our analysis of the attacks allows us to take parameters much smaller\nthan in the Matrix Code Equivalence case. Coupled with the effectiveness of\n\\textit{Threshold-Computation-in-the-Head} or \\textit{VOLE-in-the-Head}, we\nobtain a signature size of $\\approx$ 4 800 Bytes, with a public key of\n$\\approx$ 275 Bytes. We thus obtain a reasonable signature size, which brings\ndiversity in the landscape of post-quantum signature schemes, by relying on a\nnew hard problem. In particular, this new signature scheme performs better than\nSPHINCS+, with a smaller size of public key + signature. Our signature compares\nalso well with other signature schemes: compared to MEDS, the signature is\nsmaller, and we reduced the size of the sum of signature and public key by a\nfactor close to 5. We also obtain a signature size that is almost half the size\nof the CROSS signature scheme.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86\u77e9\u9635\u5b50\u7801\u7b49\u4ef7\u95ee\u9898\u548c\u77e9\u9635\u7801\u7f6e\u6362\u6838\u95ee\u9898\uff0c\u5e76\u5229\u7528MPCitH\u8303\u5f0f\u6784\u5efa\u7b7e\u540d\u65b9\u6848\u3002\u901a\u8fc7\u5206\u6790\u76f8\u5173\u653b\u51fb\uff0c\u8be5\u7814\u7a76\u80fd\u591f\u91c7\u7528\u6bd4\u77e9\u9635\u7801\u7b49\u4ef7\u6027\u95ee\u9898\u66f4\u5c0f\u7684\u53c2\u6570\uff0c\u4ece\u800c\u83b7\u5f97\u5408\u7406\u7684\u7b7e\u540d\u5927\u5c0f\u3002\u65b0\u7684\u7b7e\u540d\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u4f18\u4e8eSPHINCS+\uff0c\u5e76\u4e14\u4e0eMEDS\u548c\u5176\u4ed6\u7b7e\u540d\u65b9\u6848\u76f8\u6bd4\u5177\u6709\u8f83\u5c0f\u7684\u7b7e\u540d\u548c\u516c\u94a5\u5c3a\u5bf8\u3002", "motivation": "\u73b0\u6709\u7684\u5bc6\u7801\u7cfb\u7edf\u4e2d\uff0c\u5982\u6570\u5b57\u7b7e\u540d\uff0c\u5927\u591a\u57fa\u4e8e\u7b49\u4ef7\u6027\u95ee\u9898\uff0c\u4f46\u4e3b\u8981\u96c6\u4e2d\u5728\u7801\u7b49\u4ef7\u6027\u95ee\u9898\u4e0a\u3002\u4e3a\u4e86\u62d3\u5c55\u8fd9\u4e00\u9886\u57df\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u63a2\u7d22\u77e9\u9635\u7801\u4e2d\u7684\u5b50\u7801\u7b49\u4ef7\u6027\u95ee\u9898\uff0c\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u63d0\u4f9b\u65b0\u7684\u57fa\u7840\u96be\u9898\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u95ee\u9898\uff1a\u77e9\u9635\u5b50\u7801\u7b49\u4ef7\u6027\u95ee\u9898\u548c\u77e9\u9635\u7801\u7f6e\u6362\u6838\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u524d\u8005\u53ef\u4ee5\u5f52\u7ea6\u5230NP\u5b8c\u5168\u7684Hamming\u5b50\u7801\u7b49\u4ef7\u6027\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u8c03\u6574\u4e86\u7ec4\u5408\u548c\u4ee3\u6570\u7b97\u6cd5\u4ee5\u9002\u5e94\u5b50\u7801\u60c5\u51b5\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u7b97\u6cd5\u8fdb\u884c\u4e86\u590d\u6742\u5ea6\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5bf9\u653b\u51fb\u7684\u5206\u6790\uff0c\u53d1\u73b0\u7528\u4e8e\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u7684\u7b97\u6cd5\u6027\u80fd\u8fdc\u4e0d\u5982\u5904\u7406\u7801\u7b49\u4ef7\u6027\u95ee\u9898\u65f6\u7684\u8868\u73b0\uff0c\u8fd9\u5141\u8bb8\u4f7f\u7528\u66f4\u5c0f\u7684\u53c2\u6570\u3002\u6700\u7ec8\uff0c\u5b9e\u73b0\u4e86\u5927\u7ea64800\u5b57\u8282\u7684\u7b7e\u540d\u5927\u5c0f\u548c275\u5b57\u8282\u7684\u516c\u94a5\u5927\u5c0f\uff0c\u4f7f\u5f97\u65b0\u7b7e\u540d\u65b9\u6848\u5728\u5c3a\u5bf8\u548c\u6548\u7387\u65b9\u9762\u8d85\u8d8a\u4e86SPHINCS+\u3001MEDS\u548c\u5176\u4ed6\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u5f15\u5165\u4e86\u65b0\u7684\u6570\u5b66\u96be\u9898\u4f5c\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u57fa\u7840\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u4e14\u7d27\u51d1\u7684\u7b7e\u540d\u65b9\u6848\uff0c\u7279\u522b\u662f\u5176\u7b7e\u540d\u548c\u516c\u94a5\u5c3a\u5bf8\u5747\u5c0f\u4e8e\u5176\u4ed6\u5df2\u77e5\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.14344", "pdf": "https://arxiv.org/pdf/2507.14344", "abs": "https://arxiv.org/abs/2507.14344", "authors": ["Daniel Fein", "Gabriela Aranguiz-Dias"], "title": "Influence Functions for Preference Dataset Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Language models are commonly fine-tuned via reinforcement learning to alter\ntheir behavior or elicit new capabilities. Datasets used for these purposes,\nand particularly human preference datasets, are often noisy. The relatively\nsmall size post-training datasets, combined with parameter-efficient\nfine-tuning methods, enable the use of influence functions approximations to\ndetect and prune training examples that are harmful to performance on a\nvalidation set. In this work, we adapt the TL;DR dataset for reward model\ntraining to demonstrate how conjugate-gradient approximated influence functions\ncan be used to filter datasets. In our experiments, influence function\nfiltering yields a small retraining accuracy uplift of 1.5% after removing 10%\nof training examples. We also show that gradient similarity outperforms\ninfluence functions for detecting helpful training examples. This suggests that\nlocal curvature is important for detecting harmful training examples, but less\nso for identifying helpful examples.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f71\u54cd\u51fd\u6570\u8fc7\u6ee4\u65b9\u6cd5\u5bf9TL;DR\u6570\u636e\u96c6\u8fdb\u884c\u5904\u7406\uff0c\u53d1\u73b0\u53ef\u4ee5\u63d0\u9ad8\u518d\u8bad\u7ec3\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u68af\u5ea6\u76f8\u4f3c\u6027\u5728\u68c0\u6d4b\u6709\u7528\u8bad\u7ec3\u6837\u672c\u65b9\u9762\u4f18\u4e8e\u5f71\u54cd\u51fd\u6570\u3002", "motivation": "\u7531\u4e8e\u7528\u4e8e\u8c03\u6574\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u6570\u636e\u96c6\u901a\u5e38\u5b58\u5728\u566a\u58f0\uff0c\u7279\u522b\u662f\u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u3002\u5c0f\u89c4\u6a21\u7684\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\u4f7f\u5f97\u53ef\u4ee5\u4f7f\u7528\u5f71\u54cd\u51fd\u6570\u8fd1\u4f3c\u6765\u68c0\u6d4b\u548c\u53bb\u9664\u5bf9\u9a8c\u8bc1\u96c6\u6027\u80fd\u6709\u5bb3\u7684\u8bad\u7ec3\u6837\u672c\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u5171\u8f6d\u68af\u5ea6\u8fd1\u4f3c\u7684\u5f71\u54cd\u51fd\u6570\u6765\u8fc7\u6ee4\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u5f71\u54cd\u51fd\u6570\u548c\u68af\u5ea6\u76f8\u4f3c\u6027\u5728\u8bc6\u522b\u6709\u7528\u548c\u6709\u5bb3\u8bad\u7ec3\u6837\u672c\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5f71\u54cd\u51fd\u6570\u8fc7\u6ee4\u5728\u79fb\u966410%\u7684\u8bad\u7ec3\u6837\u672c\u540e\uff0c\u5e26\u6765\u4e861.5%\u7684\u5c0f\u5e45\u518d\u8bad\u7ec3\u51c6\u786e\u7387\u63d0\u5347\uff1b\u540c\u65f6\uff0c\u68af\u5ea6\u76f8\u4f3c\u6027\u5728\u68c0\u6d4b\u6709\u7528\u8bad\u7ec3\u6837\u672c\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u5c40\u90e8\u66f2\u7387\u5bf9\u4e8e\u68c0\u6d4b\u6709\u5bb3\u8bad\u7ec3\u6837\u672c\u5f88\u91cd\u8981\uff0c\u4f46\u5bf9\u4e8e\u8bc6\u522b\u6709\u7528\u6837\u672c\u5219\u4e0d\u662f\u90a3\u4e48\u91cd\u8981\u3002"}}
{"id": "2507.14267", "pdf": "https://arxiv.org/pdf/2507.14267", "abs": "https://arxiv.org/abs/2507.14267", "authors": ["Ziqi Wang", "Hongshuo Huang", "Hancheng Zhao", "Changwen Xu", "Shang Zhu", "Jan Janssen", "Venkatasubramanian Viswanathan"], "title": "DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": "34 pages, 28 pages of Supporting Information", "summary": "Materials discovery relies on high-throughput, high-fidelity simulation\ntechniques such as Density Functional Theory (DFT), which require years of\ntraining, extensive parameter fine-tuning and systematic error handling. To\naddress these challenges, we introduce the DFT-based Research Engine for\nAgentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for\nDFT simulation that combines a central Large Language Model (LLM) planner agent\nwith domain-specific LLM agents for atomistic structure generation, systematic\nDFT convergence testing, High-Performance Computing (HPC) scheduling, and error\nhandling. In addition, a shared canvas helps the LLM agents to structure their\ndiscussions, preserve context and prevent hallucination. We validate DREAMS\ncapabilities on the Sol27LC lattice-constant benchmark, achieving average\nerrors below 1\\% compared to the results of human DFT experts. Furthermore, we\napply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating\nits long-term and complex problem-solving capabilities. The framework again\nreproduces expert-level literature adsorption-energy differences. Finally,\nDREAMS is employed to quantify functional-driven uncertainties with Bayesian\nensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at\nthe Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS\napproaches L3-level automation - autonomous exploration of a defined design\nspace - and significantly reduces the reliance on human expertise and\nintervention, offering a scalable path toward democratized, high-throughput,\nhigh-fidelity computational materials discovery.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6DREAMS\uff0c\u5b83\u7ed3\u5408\u4e86\u4e2d\u5fc3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c4\u5212\u8005\u4e0e\u9886\u57df\u7279\u5b9a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff0c\u4ee5\u5b9e\u73b0\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u9ad8\u901a\u91cf\u3001\u9ad8\u4fdd\u771f\u6a21\u62df\u3002\u8be5\u6846\u67b6\u5728\u51cf\u5c11\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u4f9d\u8d56\u7684\u540c\u65f6\u5b9e\u73b0\u4e86L3\u7ea7\u522b\u7684\u81ea\u52a8\u5316\u3002", "motivation": "\u6750\u6599\u53d1\u73b0\u4f9d\u8d56\u4e8e\u5982\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u7b49\u9ad8\u901a\u91cf\u3001\u9ad8\u4fdd\u771f\u7684\u6a21\u62df\u6280\u672f\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u9700\u8981\u591a\u5e74\u7684\u57f9\u8bad\u3001\u5e7f\u6cdb\u7684\u53c2\u6570\u5fae\u8c03\u548c\u7cfb\u7edf\u7684\u9519\u8bef\u5904\u7406\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86DREAMS\u6846\u67b6\u3002", "method": "DREAMS\u91c7\u7528\u4e86\u4e00\u4e2a\u4e2d\u592e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89c4\u5212\u4ee3\u7406\u4e0e\u9886\u57df\u7279\u5b9a\u7684LLM\u4ee3\u7406\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u539f\u5b50\u7ed3\u6784\u751f\u6210\u3001\u7cfb\u7edf\u6027DFT\u6536\u655b\u6d4b\u8bd5\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u8c03\u5ea6\u548c\u9519\u8bef\u5904\u7406\u3002\u6b64\u5916\uff0c\u8fd8\u6709\u4e00\u4e2a\u5171\u4eab\u753b\u5e03\u5e2e\u52a9LLM\u4ee3\u7406\u7ec4\u7ec7\u8ba8\u8bba\u3001\u4fdd\u5b58\u4e0a\u4e0b\u6587\u5e76\u9632\u6b62\u4ea7\u751f\u5e7b\u89c9\u3002", "result": "DREAMS\u5728Sol27LC\u6676\u683c\u5e38\u6570\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e1%\uff0c\u4e0e\u4eba\u7c7bDFT\u4e13\u5bb6\u7684\u7ed3\u679c\u76f8\u6bd4\u3002\u5728CO/Pt(111)\u5438\u9644\u96be\u9898\u4e0a\u7684\u5e94\u7528\u4e5f\u5c55\u793a\u4e86\u5176\u957f\u671f\u548c\u590d\u6742\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u5e76\u91cd\u73b0\u4e86\u6587\u732e\u4e2d\u7684\u5438\u9644\u80fd\u5dee\u5f02\u3002\u6700\u540e\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u96c6\u6210\u91c7\u6837\u91cf\u5316\u529f\u80fd\u9a71\u52a8\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u8ba4\u4e86\u9762\u5fc3\u7acb\u65b9\uff08FCC\uff09\u4f4d\u70b9\u5728\u5e7f\u4e49\u68af\u5ea6\u8fd1\u4f3c\uff08GGA\uff09DFT\u6c34\u5e73\u4e0a\u7684\u504f\u597d\u3002", "conclusion": "DREAMS\u8fbe\u5230\u4e86L3\u7ea7\u522b\u7684\u81ea\u52a8\u5316\u2014\u2014\u81ea\u4e3b\u63a2\u7d22\u5b9a\u4e49\u7684\u8bbe\u8ba1\u7a7a\u95f4\u2014\u2014\u5e76\u4e14\u5927\u5927\u51cf\u5c11\u4e86\u5bf9\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u548c\u5e72\u9884\u7684\u4f9d\u8d56\uff0c\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u9014\u5f84\uff0c\u4f7f\u9ad8\u901a\u91cf\u3001\u9ad8\u4fdd\u771f\u7684\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u66f4\u52a0\u6c11\u4e3b\u5316\u3002"}}
{"id": "2507.15393", "pdf": "https://arxiv.org/pdf/2507.15393", "abs": "https://arxiv.org/abs/2507.15393", "authors": ["Ruofan Liu", "Yun Lin", "Silas Yeo Shuen Yu", "Xiwen Teoh", "Zhenkai Liang", "Jin Song Dong"], "title": "PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Phishing emails are a critical component of the cybercrime kill chain due to\ntheir wide reach and low cost. Their ever-evolving nature renders traditional\nrule-based and feature-engineered detectors ineffective in the ongoing arms\nrace between attackers and defenders. The rise of large language models (LLMs)\nfurther exacerbates the threat, enabling attackers to craft highly convincing\nphishing emails at minimal cost.\n  This work demonstrates that LLMs can generate psychologically persuasive\nphishing emails tailored to victim profiles, successfully bypassing nearly all\ncommercial and academic detectors. To defend against such threats, we propose\nPiMRef, the first reference-based phishing email detector that leverages\nknowledge-based invariants. Our core insight is that persuasive phishing emails\noften contain disprovable identity claims, which contradict real-world facts.\nPiMRef reframes phishing detection as an identity fact-checking task. Given an\nemail, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the\nlegitimacy of the sender's domain against a predefined knowledge base, and\n(iii) detects call-to-action prompts that push user engagement. Contradictory\nclaims are flagged as phishing indicators and serve as human-understandable\nexplanations.\n  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector,\nPiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks\nlike Nazario and PhishPot. In a real-world evaluation of 10,183 emails across\nfive university accounts over three years, PiMRef achieved 92.1% precision,\n87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art\nin both effectiveness and efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u77e5\u8bc6\u4e0d\u53d8\u5f0f\u7684\u9493\u9c7c\u90ae\u4ef6\u68c0\u6d4b\u5668PiMRef\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u68c0\u67e5\u90ae\u4ef6\u4e2d\u7684\u8eab\u4efd\u58f0\u660e\u4e0e\u4e8b\u5b9e\u662f\u5426\u77db\u76fe\u6765\u8bc6\u522b\u9493\u9c7c\u90ae\u4ef6\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cPiMRef\u5728\u7cbe\u786e\u5ea6\u4e0a\u63d0\u9ad8\u4e868.8%\uff0c\u5e76\u4e14\u5728\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5174\u8d77\uff0c\u653b\u51fb\u8005\u80fd\u591f\u4ee5\u6781\u4f4e\u7684\u6210\u672c\u751f\u6210\u9ad8\u5ea6\u8bf4\u670d\u529b\u7684\u4e2a\u6027\u5316\u9493\u9c7c\u90ae\u4ef6\uff0c\u8fd9\u4e9b\u90ae\u4ef6\u51e0\u4e4e\u53ef\u4ee5\u7ed5\u8fc7\u6240\u6709\u73b0\u6709\u7684\u5546\u4e1a\u548c\u5b66\u672f\u68c0\u6d4b\u5668\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u548c\u7279\u5f81\u5de5\u7a0b\u7684\u68c0\u6d4b\u5668\u5728\u8fd9\u79cd\u6301\u7eed\u7684\u653b\u9632\u5bf9\u6297\u4e2d\u53d8\u5f97\u65e0\u6548\u3002", "method": "PiMRef\u5c06\u9493\u9c7c\u90ae\u4ef6\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8eab\u4efd\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\uff0c\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a(i) \u63d0\u53d6\u53d1\u4ef6\u4eba\u58f0\u79f0\u7684\u8eab\u4efd\uff1b(ii) \u6838\u67e5\u53d1\u4ef6\u4eba\u7684\u57df\u540d\u5408\u6cd5\u6027\uff1b(iii) \u68c0\u6d4b\u4fc3\u4f7f\u7528\u6237\u4e92\u52a8\u7684\u884c\u52a8\u547c\u5401\u63d0\u793a\u3002\u5982\u679c\u5b58\u5728\u77db\u76fe\u58f0\u660e\uff0c\u5219\u6807\u8bb0\u4e3a\u9493\u9c7c\u6307\u6807\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u5982D-Fence\u3001HelpHed\u548cChatSpamDetector\u76f8\u6bd4\uff0cPiMRef\u5728Nazario\u548cPhishPot\u7b49\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06\u7cbe\u5ea6\u63d0\u9ad8\u4e868.8%\uff0c\u4e14\u4e0d\u635f\u5931\u53ec\u56de\u7387\u3002\u5728\u5bf9\u4e94\u4e2a\u5927\u5b66\u8d26\u6237\u4e09\u5e74\u5185\u768410,183\u5c01\u90ae\u4ef6\u7684\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u4e2d\uff0cPiMRef\u5b9e\u73b0\u4e8692.1%\u7684\u7cbe\u5ea6\u548c87.9%\u7684\u53ec\u56de\u7387\uff0c\u4e2d\u4f4d\u8fd0\u884c\u65f6\u95f4\u4e3a0.05\u79d2\uff0c\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "PiMRef\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5bf9\u6297\u7531LLMs\u751f\u6210\u7684\u9ad8\u5ea6\u5b9a\u5236\u5316\u9493\u9c7c\u90ae\u4ef6\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14353", "pdf": "https://arxiv.org/pdf/2507.14353", "abs": "https://arxiv.org/abs/2507.14353", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach\nfor adapting a Large Language Model (LLM) for newer tasks. One of the most\nprominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on\nadjusting the attention weight matrices within individual decoder blocks of a\nGenerative Pre trained Transformer (GPT2). In contrast, we introduce Solo\nConnection a novel method that adapts the representation at the decoder-block\nlevel rather than modifying individual weight matrices. Not only does Solo\nConnection outperform LoRA on E2E natural language generation benchmarks, but\nit also reduces the number of trainable parameters by 59% relative to LoRA and\nby more than 99% compared to full fine-tuning of GPT2, an early version of\nLarge Language Models (LLMs). Solo Connection is also motivated by homotopy\ntheory: we introduce a trainable linear transformation that gradually\ninterpolates between a zero vector and the task-specific representation,\nenabling smooth and stable adaptation over time. While skip connections in the\noriginal 12 layer GPT2 are typically confined to individual decoder blocks,\nsubsequent GPT2 variants scale up to 48 layers, and even larger language models\ncan include 128 or more decoder blocks. These expanded architectures underscore\nthe need to revisit how skip connections are employed during fine-tuning. This\npaper focuses on long skip connections that link outputs of different decoder\nblocks, potentially enhancing the model's ability to adapt to new tasks while\nleveraging pre-trained knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5Solo Connection\uff0c\u76f8\u8f83\u4e8eLoRA\uff0c\u5728E2E\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u8868\u793a\u4e0e\u96f6\u5411\u91cf\u4e4b\u95f4\u7684\u6e10\u8fdb\u63d2\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5982LoRA\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u8c03\u6574\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u8f6c\u6362\u5668\uff08GPT2\uff09\u4e2d\u5355\u4e2a\u89e3\u7801\u5668\u5757\u5185\u7684\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u3002\u7136\u800c\uff0c\u968f\u7740\u89e3\u7801\u5668\u5757\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6709\u5fc5\u8981\u91cd\u65b0\u5ba1\u89c6\u8df3\u8fc7\u8fde\u63a5\u5728\u5fae\u8c03\u671f\u95f4\u7684\u4f7f\u7528\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5\u2014\u2014Solo Connection\uff0c\u5b83\u5728\u89e3\u7801\u5668\u5757\u7ea7\u522b\u4e0a\u8c03\u6574\u8868\u793a\uff0c\u800c\u4e0d\u662f\u4fee\u6539\u5355\u4e2a\u6743\u91cd\u77e9\u9635\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u8be5\u53d8\u6362\u9010\u6e10\u5728\u96f6\u5411\u91cf\u548c\u4efb\u52a1\u7279\u5b9a\u8868\u793a\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\uff0c\u4ece\u800c\u5b9e\u73b0\u5e73\u7a33\u548c\u7a33\u5b9a\u7684\u9002\u5e94\u3002", "result": "Solo Connection\u4e0d\u4ec5\u5728E2E\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u4e0a\u4f18\u4e8eLoRA\uff0c\u800c\u4e14\u5c06\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u51cf\u5c11\u4e8659%\uff08\u76f8\u5bf9\u4e8eLoRA\uff09\u548c\u8d85\u8fc799%\uff08\u76f8\u5bf9\u4e8eGPT2\u7684\u5b8c\u5168\u5fae\u8c03\uff09\u3002", "conclusion": "Solo Connection\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u3002\u8fd9\u8868\u660e\uff0c\u5728\u672a\u6765\u7684\u7814\u7a76\u4e2d\uff0c\u5e94\u8be5\u66f4\u52a0\u5173\u6ce8\u5982\u4f55\u6709\u6548\u5730\u5229\u7528\u8df3\u8fc7\u8fde\u63a5\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u65b0\u4efb\u52a1\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2507.14293", "pdf": "https://arxiv.org/pdf/2507.14293", "abs": "https://arxiv.org/abs/2507.14293", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "AI": {"tldr": "\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5b58\u5728\u98ce\u9669\u3002\u5f15\u5165WebGuard\u6570\u636e\u96c6\u4ee5\u8bc4\u4f30\u98ce\u9669\u548c\u652f\u6301\u4fdd\u62a4\u673a\u5236\u5f00\u53d1\uff0c\u5373\u4f7f\u4f18\u5316\u540e\u7684\u6a21\u578b\u6027\u80fd\u4ecd\u9700\u6539\u8fdb\u4ee5\u8fbe\u5230\u9ad8\u53ef\u9760\u6027\u90e8\u7f72\u8981\u6c42\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u5feb\u901f\u53d1\u5c55\uff0c\u5728\u63d0\u5347\u6548\u7387\u7684\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u91c7\u53d6\u975e\u9884\u671f\u6216\u6709\u5bb3\u884c\u52a8\u7684\u98ce\u9669\uff0c\u4e9f\u9700\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u521b\u5efa\u4e86WebGuard\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u9884\u6d4b\u72b6\u6001\u53d8\u66f4\u884c\u4e3a\u7684\u7ed3\u679c\uff0c\u5e76\u7528\u4e00\u4e2a\u65b0\u7684\u4e09\u5c42\u98ce\u9669\u6a21\u5f0f\u5bf9\u52a8\u4f5c\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u5fae\u8c03Qwen2.5VL-7B\u6a21\u578b\u6765\u7814\u7a76\u4e13\u95e8\u7684\u9632\u62a4\u6a21\u578b\u3002", "result": "\u521d\u59cb\u8bc4\u4f30\u663e\u793a\u524d\u6cbfLLMs\u5728\u9884\u6d4b\u884c\u4e3a\u7ed3\u679c\u548c\u8bc6\u522b\u9ad8\u98ce\u9669\u884c\u4e3a\u65b9\u9762\u51c6\u786e\u6027\u4e0d\u8db360%\uff1b\u800c\u5fae\u8c03\u540e\u7684Qwen2.5VL-7B\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u9ad8\u98ce\u9669\u884c\u4e3a\u53ec\u56de\u7387\uff0c\u4f46\u4ecd\u672a\u80fd\u8fbe\u5230\u9ad8\u98ce\u9669\u90e8\u7f72\u6240\u9700\u7684\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u6027\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u6709\u6539\u8fdb\uff0c\u5f53\u524d\u4e00\u4ee3\u4ee3\u7406\u5728\u6ca1\u6709\u4e13\u7528\u4fdd\u62a4\u7684\u60c5\u51b5\u4e0b\u90e8\u7f72\u4ecd\u7136\u5b58\u5728\u98ce\u9669\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u4ee5\u786e\u4fdd\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2507.15419", "pdf": "https://arxiv.org/pdf/2507.15419", "abs": "https://arxiv.org/abs/2507.15419", "authors": ["Wenhao Li", "Selvakumar Manickam", "Yung-wey Chong", "Shankar Karuppayah"], "title": "PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation", "categories": ["cs.CR"], "comment": "Accepted by EAI ICDF2C 2025", "summary": "Phishing websites remain a major cybersecurity threat, yet existing methods\nprimarily focus on detection, while the recognition of underlying malicious\nintentions remains largely unexplored. To address this gap, we propose\nPhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework\nthat uncovers phishing intentions from website screenshots. Leveraging the\nvisual-language capabilities of large language models (LLMs), our framework\nidentifies four key phishing objectives: Credential Theft, Financial Fraud,\nMalware Distribution, and Personal Information Harvesting. We construct and\nrelease the first phishing intention ground truth dataset (~2K samples) and\nevaluate the framework using four commercial LLMs. Experimental results show\nthat PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and\nsignificantly outperforms the single-agent baseline with a ~95% improvement in\nmicro-precision. Compared to the previous work, it achieves 0.8545 precision\nfor credential theft, marking a ~4% improvement. Additionally, we generate a\nlarger dataset of ~9K samples for large-scale phishing intention profiling\nacross sectors. This work provides a scalable and interpretable solution for\nintention-aware phishing analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6PhishIntentionLLM\uff0c\u7528\u4e8e\u4ece\u7f51\u7ad9\u622a\u56fe\u4e2d\u8bc6\u522b\u7f51\u7edc\u9493\u9c7c\u610f\u56fe\uff0c\u5e76\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u6b64\u7c7b\u7684\u771f\u5b9e\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u4ee3\u7406\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u68c0\u6d4b\u7f51\u7edc\u9493\u9c7c\u7f51\u7ad9\u4e0a\uff0c\u800c\u5bf9\u6f5c\u5728\u7684\u6076\u610f\u610f\u56fe\u7684\u8bc6\u522b\u7814\u7a76\u8f83\u5c11\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\u6765\u8bc6\u522b\u7f51\u7edc\u9493\u9c7c\u610f\u56fe\u3002", "method": "\u4f7f\u7528\u591a\u4ee3\u7406\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4ece\u7f51\u7ad9\u622a\u56fe\u4e2d\u8bc6\u522b\u56db\u79cd\u5173\u952e\u7684\u7f51\u7edc\u9493\u9c7c\u76ee\u6807\uff1a\u51ed\u8bc1\u7a83\u53d6\u3001\u91d1\u878d\u6b3a\u8bc8\u3001\u6076\u610f\u8f6f\u4ef6\u5206\u53d1\u548c\u4e2a\u4eba\u4fe1\u606f\u6536\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPhishIntentionLLM\u4e0eGPT-4o\u4e00\u8d77\u4f7f\u7528\u65f6\u8fbe\u5230\u4e860.7895\u7684\u5fae\u7cbe\u5ea6\uff0c\u5e76\u4e14\u6bd4\u5355\u4ee3\u7406\u57fa\u7ebf\u63d0\u9ad8\u4e86\u7ea695%\u7684\u5fae\u7cbe\u5ea6\u3002\u5bf9\u4e8e\u51ed\u8bc1\u7a83\u53d6\uff0c\u5b83\u5b9e\u73b0\u4e860.8545\u7684\u7cbe\u5ea6\uff0c\u6bd4\u4ee5\u524d\u7684\u5de5\u4f5c\u63d0\u9ad8\u4e86\u7ea64%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u610f\u56fe\u611f\u77e5\u7684\u7f51\u7edc\u9493\u9c7c\u5206\u6790\uff0c\u5e76\u751f\u6210\u4e86\u4e00\u4e2a\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u8de8\u884c\u4e1a\u7684\u7f51\u7edc\u9493\u9c7c\u610f\u56fe\u5206\u6790\u3002"}}
{"id": "2507.14387", "pdf": "https://arxiv.org/pdf/2507.14387", "abs": "https://arxiv.org/abs/2507.14387", "authors": ["Arun Vignesh Malarkkan", "Dongjie Wang", "Haoyue Bai", "Yanjie Fu"], "title": "Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on\n  Big Data", "summary": "The escalating threat of cyberattacks on real-time critical infrastructures\nposes serious risks to public safety, demanding detection methods that\neffectively capture complex system interdependencies and adapt to evolving\nattack patterns. Traditional real-time anomaly detection techniques often\nsuffer from excessive false positives due to their statistical sensitivity to\nhigh data variance and class imbalance. To address these limitations, recent\nresearch has explored modeling causal relationships among system components.\nHowever, prior work mainly focuses on offline causal graph-based approaches\nthat require static historical data and fail to generalize to real-time\nsettings. These methods are fundamentally constrained by: (1) their inability\nto adapt to dynamic shifts in data distribution without retraining, and (2) the\nrisk of catastrophic forgetting when lacking timely supervision in live\nsystems. To overcome these challenges, we propose INCADET, a novel framework\nfor incremental causal graph learning tailored to real-time cyberattack\ndetection. INCADET dynamically captures evolving system behavior by\nincrementally updating causal graphs across streaming time windows. The\nframework comprises three modules: 1) Early Symptom Detection: Detects\ntransitions in system status using divergence in edge-weight distributions\nacross sequential causal graphs. 2) Incremental Causal Graph Learning:\nLeverages experience replay and edge reinforcement to continually refine causal\nstructures while preserving prior knowledge. 3) Causal Graph Classification:\nEmploys Graph Convolutional Networks (GCNs) to classify system status using the\nlearned causal graphs. Extensive experiments on real-world critical\ninfrastructure datasets demonstrate that INCADET achieves superior accuracy,\nrobustness, and adaptability compared to both static causal and deep temporal\nbaselines in evolving attack scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aINCADET\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u7684\u589e\u91cf\u56e0\u679c\u56fe\u5b66\u4e60\u3002\u5b83\u901a\u8fc7\u52a8\u6001\u6355\u6349\u7cfb\u7edf\u884c\u4e3a\u53d8\u5316\u5e76\u6301\u7eed\u66f4\u65b0\u56e0\u679c\u56fe\u6765\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u7531\u4e8e\u5176\u5bf9\u9ad8\u6570\u636e\u65b9\u5dee\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u7edf\u8ba1\u654f\u611f\u6027\uff0c\u5e38\u5e38\u5bfc\u81f4\u8fc7\u591a\u7684\u8bef\u62a5\u3002\u73b0\u6709\u57fa\u4e8e\u79bb\u7ebf\u56e0\u679c\u56fe\u7684\u65b9\u6cd5\u9700\u8981\u9759\u6001\u5386\u53f2\u6570\u636e\uff0c\u65e0\u6cd5\u9002\u5e94\u5b9e\u65f6\u73af\u5883\u4e2d\u7684\u52a8\u6001\u6570\u636e\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u4e14\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u7684\u98ce\u9669\u3002", "method": "INCADET\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\uff1a1) \u65e9\u671f\u75c7\u72b6\u68c0\u6d4b\uff1a\u4f7f\u7528\u8fb9\u7f18\u6743\u91cd\u5206\u5e03\u5728\u8fde\u7eed\u56e0\u679c\u56fe\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u68c0\u6d4b\u7cfb\u7edf\u72b6\u6001\u7684\u53d8\u5316\uff1b2) \u589e\u91cf\u56e0\u679c\u56fe\u5b66\u4e60\uff1a\u5229\u7528\u7ecf\u9a8c\u91cd\u653e\u548c\u8fb9\u7f18\u5f3a\u5316\u4e0d\u65ad\u7ec6\u5316\u56e0\u679c\u7ed3\u6784\uff0c\u540c\u65f6\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\uff1b3) \u56e0\u679c\u56fe\u5206\u7c7b\uff1a\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCNs\uff09\u6839\u636e\u6240\u5b66\u56e0\u679c\u56fe\u5bf9\u7cfb\u7edf\u72b6\u6001\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e0e\u9759\u6001\u56e0\u679c\u548c\u6df1\u5ea6\u65f6\u5e8f\u57fa\u7ebf\u76f8\u6bd4\uff0cINCADET\u5728\u6f14\u53d8\u653b\u51fb\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "INCADET\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6355\u83b7\u590d\u6742\u7cfb\u7edf\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u9002\u5e94\u6f14\u53d8\u7684\u653b\u51fb\u6a21\u5f0f\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5b9e\u65f6\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.14306", "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3amanimator\u7684\u5f00\u6e90\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u89e3\u91ca\u6027\u52a8\u753b\u3002\u8fd9\u4e2a\u5de5\u5177\u65e8\u5728\u7b80\u5316\u590d\u6742\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\u7684\u52a8\u6001\u53ef\u89c6\u5316\u521b\u5efa\u8fc7\u7a0b\u3002", "motivation": "\u7406\u89e3\u590d\u6742\u7684\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u5728\u5bc6\u96c6\u7684\u7814\u7a76\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u6982\u5ff5\uff0c\u5bf9\u5b66\u4e60\u8005\u6765\u8bf4\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u800c\u624b\u52a8\u521b\u5efa\u6709\u52a9\u4e8e\u7406\u89e3\u8fd9\u4e9b\u6982\u5ff5\u7684\u52a8\u6001\u53ef\u89c6\u5316\u9700\u8981\u8017\u8d39\u5927\u91cf\u65f6\u95f4\uff0c\u5e76\u4e14\u9700\u8981\u4e13\u95e8\u7684\u77e5\u8bc6\u548c\u6280\u80fd\u3002", "method": "Manimator\u91c7\u7528\u4e86\u4e00\u4e2a\u6d41\u7a0b\uff0c\u5176\u4e2dLLM\uff08\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u89e3\u91ca\u8f93\u5165\u6587\u672c\u6216\u7814\u7a76\u8bba\u6587PDF\uff0c\u751f\u6210\u7ed3\u6784\u5316\u7684\u573a\u666f\u63cf\u8ff0\uff0c\u6982\u8ff0\u5173\u952e\u6982\u5ff5\u3001\u6570\u5b66\u516c\u5f0f\u548c\u89c6\u89c9\u5143\u7d20\u3002\u7136\u540e\u53e6\u4e00\u4e2aLLM\u5c06\u6b64\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Manim Python\u4ee3\u7801\uff0c\u4ece\u800c\u521b\u5efa\u51fa\u89e3\u91ca\u6027\u52a8\u753b\u3002", "result": "\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5feb\u901f\u521b\u5efa\u5438\u5f15\u4eba\u7684\u89c6\u89c9\u89e3\u91ca\uff0c\u7528\u4e8e\u89e3\u91ca\u590d\u6742\u7684STEM\u4e3b\u9898\uff0c\u6709\u53ef\u80fd\u4f7f\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u7684\u521b\u4f5c\u6c11\u4e3b\u5316\u3002", "conclusion": "Manimator\u4f5c\u4e3a\u4e00\u4e2a\u6559\u80b2\u5de5\u5177\uff0c\u6709\u6f5c\u529b\u8fc5\u901f\u521b\u5efa\u5438\u5f15\u4eba\u7684\u89c6\u89c9\u89e3\u91ca\uff0c\u7b80\u5316\u590d\u6742\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\u7684\u7406\u89e3\u8fc7\u7a0b\uff0c\u4f7f\u66f4\u591a\u4eba\u80fd\u591f\u53c2\u4e0e\u5230\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u7684\u521b\u4f5c\u4e2d\u6765\u3002"}}
{"id": "2507.15449", "pdf": "https://arxiv.org/pdf/2507.15449", "abs": "https://arxiv.org/abs/2507.15449", "authors": ["Alessio Caminata", "Elisa Gorla", "Madison Mabe", "Martina Vigorito", "Irene Villa"], "title": "Cryptanalysis of a multivariate CCZ scheme", "categories": ["cs.CR", "cs.SC"], "comment": "are welcome!", "summary": "We consider the multivariate scheme Pesto, which was introduced by Calderini,\nCaminata, and Villa. In this scheme, the public polynomials are obtained by\napplying a CCZ transformation to a set of quadratic secret polynomials. As a\nconsequence, the public key consists of polynomials of degree 4. In this work,\nwe show that the public degree 4 polynomial system can be efficiently reduced\nto a system of quadratic polynomials. This seems to suggest that the CCZ\ntransformation may not offer a significant increase in security, contrary to\nwhat was initially believed.", "AI": {"tldr": "Pesto\u65b9\u6848\u7684\u516c\u94a5\u591a\u9879\u5f0f\u901a\u8fc7CCZ\u8f6c\u6362\u83b7\u5f97\uff0c\u4f46\u65b0\u7684\u7814\u7a76\u53d1\u73b0\u5176\u53ef\u4ee5\u9ad8\u6548\u5730\u7b80\u5316\u4e3a\u4e8c\u6b21\u591a\u9879\u5f0f\u7cfb\u7edf\uff0c\u8fd9\u8868\u660eCCZ\u8f6c\u6362\u53ef\u80fd\u4e0d\u4f1a\u663e\u8457\u589e\u52a0\u5b89\u5168\u6027\u3002", "motivation": "\u8bc4\u4f30CCZ\u8f6c\u6362\u5728Pesto\u591a\u53d8\u91cf\u65b9\u6848\u4e2d\u5bf9\u5b89\u5168\u6027\u7684\u63d0\u5347\u7a0b\u5ea6\u3002", "method": "\u5c55\u793a\u5982\u4f55\u5c06\u5ea6\u6570\u4e3a4\u7684\u516c\u94a5\u591a\u9879\u5f0f\u7cfb\u7edf\u6709\u6548\u51cf\u5c11\u5230\u4e8c\u6b21\u591a\u9879\u5f0f\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0CCZ\u8f6c\u6362\u5e76\u672a\u5982\u6700\u521d\u8ba4\u4e3a\u7684\u90a3\u6837\u5927\u5e45\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "conclusion": "CCZ\u8f6c\u6362\u5728Pesto\u65b9\u6848\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u6ca1\u6709\u63d0\u4f9b\u9884\u671f\u7684\u5b89\u5168\u6027\u589e\u76ca\u3002"}}
{"id": "2507.14419", "pdf": "https://arxiv.org/pdf/2507.14419", "abs": "https://arxiv.org/abs/2507.14419", "authors": ["Guojun Wu"], "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Prior work proposed simple test-time scaling, a method for replicating this\nscaling behavior with models distilled from o1-like models by manually\ncontrolling test-time compute: either scaling down by enforcing a maximum\nlength or scaling up by iteratively appending \"Wait\" when the model is about to\nterminate its generation. This paper presents an analysis of simple test-time\nscaling and finds that the scaling behavior is largely attributed to scaling\ndown by enforcing a maximum length. In contrast, fine-tuning on long CoT data\ndistilled from o1-like models has no significant impact on scaling behavior,\nand scaling up by appending \"Wait\" leads to inconsistencies, as the model may\noscillate between solutions. A key distinction exists between scaling down by\nenforcing a maximum length and scaling up test-time compute in o1-like models,\nsuch as DeepSeek-R1\\@. These models are typically allowed to utilize as much\ncompute as needed, with the only constraint being the model's maximum supported\nlength. By learning to naturally scale up test-time compute during\nreinforcement learning, o1-like models surpass their peak performance when\nscaling up. In contrast, simple test-time scaling progressively imposes a lower\nupper limit on model performance as it scales down. While replicating the\ntest-time scaling behavior of o1 models can be straightforward by scaling down,\nit is crucial to recognize that the goal of scaling test-time compute is to\nunlock higher performance -- beyond what the model could originally achieve --\nrather than merely reproducing the appearance of scaling behavior.", "AI": {"tldr": "\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e3b\u8981\u901a\u8fc7\u9650\u5236\u6700\u5927\u957f\u5ea6\u6765\u5b9e\u73b0\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u800c\u901a\u8fc7\u5728\u957fCoT\u6570\u636e\u4e0a\u5fae\u8c03\u6216\u6dfb\u52a0\u201c\u7b49\u5f85\u201d\u4ee5\u6269\u5c55\u8ba1\u7b97\u91cf\u7684\u65b9\u5f0f\u5bf9\u7f29\u653e\u884c\u4e3a\u5f71\u54cd\u4e0d\u5927\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u4e0d\u4e00\u81f4\u7684\u7ed3\u679c\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u5206\u6790\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u8ba8\u5176\u4e0e\u76f4\u63a5\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d44\u6e90\u7684\u65b9\u6cd5\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u4ee5\u671f\u66f4\u597d\u5730\u7406\u89e3\u5982\u4f55\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "\u7814\u7a76\u8005\u4eec\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u5bf9\u6a21\u578b\u8fdb\u884c\u7f29\u653e\uff1a1) \u901a\u8fc7\u8bbe\u7f6e\u6700\u5927\u957f\u5ea6\u6765\u7f29\u5c0f\u89c4\u6a21\uff1b2) \u5728\u6a21\u578b\u5373\u5c06\u7ed3\u675f\u751f\u6210\u65f6\u8fed\u4ee3\u9644\u52a0\u201cWait\u201d\u4ee5\u6269\u5927\u89c4\u6a21\u3002\u6b64\u5916\uff0c\u8fd8\u5c1d\u8bd5\u4e86\u5728\u957fCoT\u6570\u636e\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u53d1\u73b0\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u884c\u4e3a\u4e3b\u8981\u662f\u7531\u4e8e\u8bbe\u7f6e\u4e86\u6700\u5927\u957f\u5ea6\u9020\u6210\u7684\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5728\u957fCoT\u6570\u636e\u4e0a\u7684\u5fae\u8c03\u5bf9\u7f29\u653e\u884c\u4e3a\u6ca1\u6709\u663e\u8457\u5f71\u54cd\uff0c\u800c\u901a\u8fc7\u9644\u52a0\u201cWait\u201d\u6765\u6269\u5c55\u8ba1\u7b97\u91cf\u5219\u5bfc\u81f4\u4e86\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u7b80\u5355\u6d4b\u8bd5\u65f6\u7f29\u653e\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u9650\u5236\u6700\u5927\u957f\u5ea6\u8f7b\u677e\u590d\u5236o1\u6a21\u578b\u7684\u7f29\u653e\u884c\u4e3a\uff0c\u4f46\u5176\u76ee\u6807\u5e94\u8be5\u662f\u89e3\u9501\u66f4\u9ad8\u7684\u6027\u80fd\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u91cd\u73b0\u7f29\u653e\u884c\u4e3a\u7684\u5916\u89c2\u3002\u76f4\u63a5\u5b66\u4e60\u81ea\u7136\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff08\u5982o1-like\u6a21\u578b\uff09\u53ef\u4ee5\u5728\u5b9e\u9645\u6027\u80fd\u4e0a\u8d85\u8d8a\u7b80\u5355\u7f29\u653e\u65b9\u6cd5\u3002"}}
{"id": "2507.14334", "pdf": "https://arxiv.org/pdf/2507.14334", "abs": "https://arxiv.org/abs/2507.14334", "authors": ["Hui Yang", "Jiaoyan Chen", "Yuan He", "Yongsheng Gao", "Ian Horrocks"], "title": "Language Models as Ontology Encoders", "categories": ["cs.AI"], "comment": null, "summary": "OWL (Web Ontology Language) ontologies which are able to formally represent\ncomplex knowledge and support semantic reasoning have been widely adopted\nacross various domains such as healthcare and bioinformatics. Recently,\nontology embeddings have gained wide attention due to its potential to infer\nplausible new knowledge and approximate complex reasoning. However, existing\nmethods face notable limitations: geometric model-based embeddings typically\noverlook valuable textual information, resulting in suboptimal performance,\nwhile the approaches that incorporate text, which are often based on language\nmodels, fail to preserve the logical structure. In this work, we propose a new\nontology embedding method OnT, which tunes a Pretrained Language Model (PLM)\nvia geometric modeling in a hyperbolic space for effectively incorporating\ntextual labels and simultaneously preserving class hierarchies and other\nlogical relationships of Description Logic EL. Extensive experiments on four\nreal-world ontologies show that OnT consistently outperforms the baselines\nincluding the state-of-the-art across both tasks of prediction and inference of\naxioms. OnT also demonstrates strong potential in real-world applications,\nindicated by its robust transfer learning abilities and effectiveness in real\ncases of constructing a new ontology from SNOMED CT. Data and code are\navailable at https://github.com/HuiYang1997/OnT.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5OnT\uff0c\u901a\u8fc7\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u6765\u6709\u6548\u7ed3\u5408\u6587\u672c\u6807\u7b7e\uff0c\u5e76\u540c\u65f6\u4fdd\u6301\u63cf\u8ff0\u903b\u8f91EL\u7684\u7c7b\u5c42\u6b21\u7ed3\u6784\u548c\u5176\u4ed6\u903b\u8f91\u5173\u7cfb\u3002\u5b9e\u9a8c\u8868\u660e\uff0cOnT\u5728\u9884\u6d4b\u548c\u63a8\u7406\u516c\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u73b0\u5b9e\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u51e0\u4f55\u6a21\u578b\u5d4c\u5165\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u6709\u4ef7\u503c\u7684\u6587\u672c\u4fe1\u606f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff1b\u800c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u672a\u80fd\u4fdd\u7559\u903b\u8f91\u7ed3\u6784\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86OnT\u65b9\u6cd5\uff0c\u5373\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\uff0c\u4ee5\u7ed3\u5408\u6587\u672c\u6807\u7b7e\u5e76\u4fdd\u6301\u7c7b\u5c42\u6b21\u7ed3\u6784\u548c\u5176\u4ed6\u903b\u8f91\u5173\u7cfb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86OnT\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u672c\u4f53\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002OnT\u8fd8\u5c55\u793a\u4e86\u5176\u7a33\u5065\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u5728\u6784\u5efa\u65b0\u672c\u4f53\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "OnT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u672c\u4f53\u5d4c\u5165\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5177\u6709\u5f3a\u5927\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.15613", "pdf": "https://arxiv.org/pdf/2507.15613", "abs": "https://arxiv.org/abs/2507.15613", "authors": ["Andrii Balashov", "Olena Ponomarova", "Xiaohua Zhai"], "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems", "categories": ["cs.CR", "cs.AI"], "comment": "26 pages", "summary": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as\nMicrosoft 365 Copilot) face novel security challenges. One critical threat is\nprompt inference attacks: adversaries chain together seemingly benign prompts\nto gradually extract confidential data. In this paper, we present a\ncomprehensive study of multi-stage prompt inference attacks in an enterprise\nLLM context. We simulate realistic attack scenarios where an attacker uses\nmild-mannered queries and indirect prompt injections to exploit an LLM\nintegrated with private corporate data. We develop a formal threat model for\nthese multi-turn inference attacks and analyze them using probability theory,\noptimization frameworks, and information-theoretic leakage bounds. The attacks\nare shown to reliably exfiltrate sensitive information from the LLM's context\n(e.g., internal SharePoint documents or emails), even when standard safety\nmeasures are in place.\n  We propose and evaluate defenses to counter such attacks, including\nstatistical anomaly detection, fine-grained access control, prompt sanitization\ntechniques, and architectural modifications to LLM deployment. Each defense is\nsupported by mathematical analysis or experimental simulation. For example, we\nderive bounds on information leakage under differential privacy-based training\nand demonstrate an anomaly detection method that flags multi-turn attacks with\nhigh AUC. We also introduce an approach called \"spotlighting\" that uses input\ntransformations to isolate untrusted prompt content, reducing attack success by\nan order of magnitude. Finally, we provide a formal proof of concept and\nempirical validation for a combined defense-in-depth strategy. Our work\nhighlights that securing LLMs in enterprise settings requires moving beyond\nsingle-turn prompt filtering toward a holistic, multi-stage perspective on both\nattacks and defenses.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u9762\u4e34\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u7279\u522b\u662f\u591a\u9636\u6bb5\u63d0\u793a\u63a8\u7406\u653b\u51fb\u3002\u672c\u6587\u7814\u7a76\u4e86\u6b64\u7c7b\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86\u5305\u62ec\u5f02\u5e38\u68c0\u6d4b\u3001\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u7b49\u5728\u5185\u7684\u591a\u79cd\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u90e8\u7f72\uff0c\u4f8b\u5982\u4f5c\u4e3aMicrosoft 365\u526f\u9a7e\uff0c\u5b83\u4eec\u9762\u4e34\u7740\u5168\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u5c24\u5176\u662f\u63d0\u793a\u63a8\u7406\u653b\u51fb\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u6df1\u5165\u63a2\u8ba8\u8fd9\u4e9b\u5a01\u80c1\u5e76\u5f00\u53d1\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u7684\u653b\u51fb\u573a\u666f\u6765\u7814\u7a76\u591a\u9636\u6bb5\u63d0\u793a\u63a8\u7406\u653b\u51fb\uff0c\u5229\u7528\u6982\u7387\u8bba\u3001\u4f18\u5316\u6846\u67b6\u548c\u4fe1\u606f\u7406\u8bba\u6cc4\u6f0f\u754c\u9650\u8fdb\u884c\u5206\u6790\u3002\u63d0\u51fa\u7684\u9632\u5fa1\u63aa\u65bd\u5305\u62ec\u7edf\u8ba1\u5f02\u5e38\u68c0\u6d4b\u3001\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u3001\u63d0\u793a\u6e05\u7406\u6280\u672f\u4ee5\u53ca\u5bf9LLM\u90e8\u7f72\u7684\u67b6\u6784\u4fee\u6539\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5b58\u5728\u6807\u51c6\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u653b\u51fb\u8005\u4ecd\u7136\u53ef\u4ee5\u53ef\u9760\u5730\u4eceLLM\u7684\u4e0a\u4e0b\u6587\u4e2d\u63d0\u53d6\u654f\u611f\u4fe1\u606f\u3002\u63d0\u51fa\u7684\u9632\u5fa1\u63aa\u65bd\uff0c\u5982\u5dee\u5f02\u9690\u79c1\u8bad\u7ec3\u7684\u4fe1\u606f\u6cc4\u6f0f\u754c\u9650\u63a8\u5bfc\u548c\u9ad8AUC\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u51cf\u5c11\u4e86\u653b\u51fb\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u4e3a\u4e86\u786e\u4fdd\u4f01\u4e1a\u73af\u5883\u4e2dLLM\u7684\u5b89\u5168\uff0c\u9700\u8981\u8d85\u8d8a\u5355\u56de\u5408\u63d0\u793a\u8fc7\u6ee4\uff0c\u8f6c\u5411\u5bf9\u653b\u51fb\u548c\u9632\u5fa1\u90fd\u91c7\u53d6\u5168\u9762\u3001\u591a\u9636\u6bb5\u7684\u89c2\u70b9\u3002"}}
{"id": "2507.14446", "pdf": "https://arxiv.org/pdf/2507.14446", "abs": "https://arxiv.org/abs/2507.14446", "authors": ["Feng Liu", "Ying Liu", "Carson Eisenach"], "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we study how to efficiently apply reinforcement learning (RL)\nfor solving large-scale stochastic optimization problems by leveraging\nintervention models. The key of the proposed methodology is to better explore\nthe solution space by simulating and composing the stochastic processes using\npre-trained deep learning (DL) models. We demonstrate our approach on a\nchallenging real-world application, the multi-sourcing multi-period inventory\nmanagement problem in supply chain optimization. In particular, we employ deep\nRL models for learning and forecasting the stochastic supply chain processes\nunder a range of assumptions. Moreover, we also introduce a constraint\ncoordination mechanism, designed to forecast dual costs given the\ncross-products constraints in the inventory network. We highlight that instead\nof directly modeling the complex physical constraints into the RL optimization\nproblem and solving the stochastic problem as a whole, our approach breaks down\nthose supply chain processes into scalable and composable DL modules, leading\nto improved performance on large real-world datasets. We also outline open\nproblems for future research to further investigate the efficacy of such\nmodels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u5229\u7528\u5e72\u9884\u6a21\u578b\uff0c\u9ad8\u6548\u5730\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u968f\u673a\u4f18\u5316\u95ee\u9898\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4f9b\u5e94\u94fe\u4f18\u5316\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u5e76\u4e14\u5c06\u590d\u6742\u7684\u7269\u7406\u7ea6\u675f\u5206\u89e3\u4e3a\u53ef\u6269\u5c55\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u5927\u578b\u968f\u673a\u4f18\u5316\u95ee\u9898\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u590d\u6742\u7269\u7406\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u591a\u6e90\u591a\u5468\u671f\u5e93\u5b58\u7ba1\u7406\u95ee\u9898\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u76f4\u63a5\u5efa\u6a21\u8fd9\u4e9b\u7ea6\u675f\u6761\u4ef6\u5230RL\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u8fd9\u53ef\u80fd\u662f\u4f4e\u6548\u548c\u96be\u4ee5\u5904\u7406\u7684\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u6a21\u62df\u548c\u7ec4\u5408\u968f\u673a\u8fc7\u7a0b\uff0c\u4ee5\u66f4\u597d\u5730\u63a2\u7d22\u89e3\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u7ea6\u675f\u534f\u8c03\u673a\u5236\uff0c\u7528\u4e8e\u9884\u6d4b\u8de8\u4ea7\u54c1\u7ea6\u675f\u4e0b\u7684\u53cc\u91cd\u6210\u672c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5927\u578b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u89e3\u51b3\u5927\u578b\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63a2\u8ba8\u6b64\u7c7b\u6a21\u578b\u7684\u6548\u679c\u3002"}}
{"id": "2507.14335", "pdf": "https://arxiv.org/pdf/2507.14335", "abs": "https://arxiv.org/abs/2507.14335", "authors": ["Nicolas Wischermann", "Claudio Mayrink Verdun", "Gabriel Poesia", "Francesco Noseda"], "title": "ProofCompass: Enhancing Specialized Provers with LLM Guidance", "categories": ["cs.AI"], "comment": "19 pages, 7 figures. Accepted at the 2nd AI for MATH Workshop at the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "Language models have become increasingly powerful tools for formal\nmathematical reasoning. However, most existing approaches rely exclusively on\neither large general-purpose models or smaller specialized models, each with\ndistinct limitations, while training specialized large models still requires\nsignificant computational resources. This paper introduces ProofCompass, a\nnovel hybrid methodology that achieves remarkable computational efficiency by\nstrategically guiding existing specialized prover methods, such as\nDeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without\nrequiring additional model training. The LLM provides natural language proof\nstrategies and analyzes failed attempts to select intermediate lemmas, enabling\neffective problem decomposition. On the miniF2F benchmark, ProofCompass\ndemonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\\%\n\\rightarrow 55.3\\%$) while using 25x fewer attempts ($3200 \\rightarrow 128$).\nOur synergistic approach paves the way for simultaneously improving\ncomputational efficiency and accuracy in formal theorem proving.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aProofCompass\u7684\u65b0\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6307\u5bfc\u73b0\u6709\u4e13\u95e8\u7684\u8bc1\u660e\u65b9\u6cd5\uff0c\u5728\u4e0d\u9700\u8981\u989d\u5916\u6a21\u578b\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u5b66\u63a8\u7406\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e8e\u5927\u578b\u901a\u7528\u6a21\u578b\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u5c0f\u578b\u4e13\u4e1a\u6a21\u578b\uff0c\u5404\u6709\u5176\u5c40\u9650\u6027\uff0c\u5e76\u4e14\u8bad\u7ec3\u5927\u578b\u4e13\u4e1a\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "ProofCompass\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u7b56\u7565\uff0c\u5e76\u5206\u6790\u5931\u8d25\u7684\u5c1d\u8bd5\u4ee5\u9009\u62e9\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u95ee\u9898\u5206\u89e3\u3002", "result": "\u5728miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProofCompass\u5728\u4f7f\u752825\u500d\u66f4\u5c11\u7684\u5c1d\u8bd5\u6b21\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u4f18\u4e8eDSP-v1.5\uff08\u4ece54.9%\u63d0\u5347\u523055.3%\uff09\u3002", "conclusion": "\u8be5\u534f\u540c\u65b9\u6cd5\u4e3a\u540c\u65f6\u63d0\u9ad8\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.15660", "pdf": "https://arxiv.org/pdf/2507.15660", "abs": "https://arxiv.org/abs/2507.15660", "authors": ["Rohit Negi", "Amit Negi", "Manish Sharma", "S. Venkatesan", "Prem Kumar", "Sandeep K. Shukla"], "title": "Cyber security of Mega Events: A Case Study of Securing the Digital Infrastructure for MahaKumbh 2025 -- A 45 days Mega Event of 600 Million Footfalls", "categories": ["cs.CR", "cs.CY"], "comment": "11 pages, 11 tables", "summary": "Mega events such as the Olympics, World Cup tournaments, G-20 Summit,\nreligious events such as MahaKumbh are increasingly digitalized. From event\nticketing, vendor booth or lodging reservations, sanitation, event scheduling,\ncustomer service, crime reporting, media streaming and messaging on digital\ndisplay boards, surveillance, crowd control, traffic control and many other\nservices are based on mobile and web applications, wired and wireless\nnetworking, network of Closed-Circuit Television (CCTV) cameras, specialized\ncontrol room with network and video-feed monitoring. Consequently, cyber\nthreats directed at such digital infrastructure are common. Starting from hobby\nhackers, hacktivists, cyber crime gangs, to the nation state actors, all target\nsuch infrastructure to unleash chaos on an otherwise smooth operation, and\noften the cyber threat actors attempt to embarrass the organizing country or\nthe organizers. Unlike long-standing organizations such as a corporate or a\ngovernment department, the infrastructure of mega-events is temporary,\nconstructed over a short time span in expediency, and often shortcuts are taken\nto make the deadline for the event. As a result, securing such an elaborate yet\ntemporary infrastructure requires a different approach than securing a standard\norganizational digital infrastructure. In this paper, we describe our approach\nto securing MahaKumbh 2025, a 600 million footfall event for 45 days in\nPrayagraj, India, as a cyber security assessment and risk management oversight\nteam. We chronicle the scope, process, methodology, and outcome of our team's\neffort to secure this mega event. It should be noted that none of the cyber\nattacks during the 45-day event was successful. Our goal is to put on record\nthe methodology and discuss what we would do differently in case we work on\nsimilar future mega event.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4f5c\u8005\u56e2\u961f\u4e3a\u5370\u5ea6Prayagraj\u7684MahaKumbh 2025\u63d0\u4f9b\u7f51\u7edc\u5b89\u5168\u8bc4\u4f30\u548c\u98ce\u9669\u7ba1\u7406\u76d1\u7763\u7684\u7ecf\u9a8c\uff0c\u8be5\u6d3b\u52a8\u572845\u5929\u5185\u67096\u4ebf\u4eba\u6b21\u7684\u53c2\u4e0e\u3002\u6587\u4e2d\u63cf\u8ff0\u4e86\u56e2\u961f\u7684\u5de5\u4f5c\u8303\u56f4\u3001\u8fc7\u7a0b\u3001\u65b9\u6cd5\u548c\u6210\u679c\uff0c\u6700\u7ec8\u6210\u529f\u62b5\u5fa1\u4e86\u6240\u6709\u7f51\u7edc\u653b\u51fb\u3002", "motivation": "\u5927\u578b\u6d3b\u52a8\uff08\u5982\u5965\u8fd0\u4f1a\u3001\u4e16\u754c\u676f\u3001G-20\u5cf0\u4f1a\u548c\u5b97\u6559\u6d3b\u52a8\uff09\u65e5\u76ca\u6570\u5b57\u5316\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u6d3b\u52a8\u9762\u4e34\u8d8a\u6765\u8d8a\u591a\u7684\u7f51\u7edc\u5a01\u80c1\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6d3b\u52a8\u7684\u57fa\u7840\u8bbe\u65bd\u662f\u4e34\u65f6\u4e14\u4ed3\u4fc3\u5efa\u7acb\u7684\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u7684\u5b89\u5168\u4fdd\u969c\u4e0d\u540c\u4e8e\u5e38\u89c4\u7ec4\u7ec7\u7684\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u9488\u5bf9\u8fd9\u79cd\u72ec\u7279\u7684\u73af\u5883\u5f00\u53d1\u65b0\u7684\u5b89\u5168\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u56e2\u961f\u4f5c\u4e3aMahaKumbh 2025\u7684\u7f51\u7edc\u5b89\u5168\u8bc4\u4f30\u548c\u98ce\u9669\u7ba1\u7406\u4eba\u5458\uff0c\u8bb0\u5f55\u4e86\u4ed6\u4eec\u7684\u5de5\u4f5c\u8303\u56f4\u3001\u8fc7\u7a0b\u3001\u65b9\u6cd5\u8bba\u53ca\u7ed3\u679c\u3002\u4ed6\u4eec\u4e13\u6ce8\u4e8e\u4fdd\u62a4\u8fd9\u4e2a\u4e3a\u671f45\u5929\u3001\u9884\u8ba1\u67096\u4ebf\u4eba\u6b21\u53c2\u4e0e\u7684\u4e8b\u4ef6\uff0c\u5e76\u786e\u4fdd\u5176\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u514d\u53d7\u5404\u79cd\u6f5c\u5728\u7684\u7f51\u7edc\u5a01\u80c1\u3002", "result": "\u5728\u6574\u4e2a45\u5929\u7684\u6d3b\u52a8\u4e2d\uff0c\u6ca1\u6709\u4e00\u6b21\u7f51\u7edc\u653b\u51fb\u53d6\u5f97\u6210\u529f\uff0c\u8bc1\u660e\u4e86\u4f5c\u8005\u56e2\u961f\u6240\u91c7\u7528\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86\u4e3aMahaKumbh 2025\u63d0\u4f9b\u7684\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\uff0c\u5e76\u8ba8\u8bba\u4e86\u5982\u679c\u672a\u6765\u518d\u8d1f\u8d23\u7c7b\u4f3c\u7684\u5927\u578b\u6d3b\u52a8\u65f6\uff0c\u4ed6\u4eec\u4f1a\u505a\u51fa\u54ea\u4e9b\u4e0d\u540c\u7684\u9009\u62e9\u3002"}}
{"id": "2507.14484", "pdf": "https://arxiv.org/pdf/2507.14484", "abs": "https://arxiv.org/abs/2507.14484", "authors": ["Yule Li", "Yifeng Lu", "Zhen Wang", "Zhewei Wei", "Yaliang Li", "Bolin Ding"], "title": "ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, graph neural networks (GNN) have achieved unprecedented\nsuccesses in node classification tasks. Although GNNs inherently encode\nspecific inductive biases (e.g., acting as low-pass or high-pass filters), most\nexisting methods implicitly assume conditional independence among node labels\nin their optimization objectives. While this assumption is suitable for\ntraditional classification tasks such as image recognition, it contradicts the\nintuitive observation that node labels in graphs remain correlated, even after\nconditioning on the graph structure. To make structured predictions for node\nlabels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for\nStructured node Classification. ReDiSC estimates the joint distribution of node\nlabels using a reparameterized masked diffusion model, which is learned through\nthe variational expectation-maximization (EM) framework. Our theoretical\nanalysis shows the efficiency advantage of ReDiSC in the E-step compared to\nDPM-SNC, a state-of-the-art model that relies on a manifold-constrained\ndiffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's\nM-step objective to popular GNN and label propagation hybrid approaches.\nExtensive experiments demonstrate that ReDiSC achieves superior or highly\ncompetitive performance compared to state-of-the-art GNN, label propagation,\nand diffusion-based baselines across both homophilic and heterophilic graphs of\nvarying sizes. Notably, ReDiSC scales effectively to large-scale datasets on\nwhich previous structured diffusion methods fail due to computational\nconstraints, highlighting its significant practical advantage in structured\nnode classification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u6a21\u578bReDiSC\uff0c\u8be5\u6a21\u578b\u5728\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u8282\u70b9\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\u3002\u5b9e\u9a8c\u8868\u660e\uff0cReDiSC\u5728\u540c\u6027\u548c\u5f02\u6027\u56fe\u4e2d\u5747\u4f18\u4e8e\u6216\u5339\u654c\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4e14\u53ef\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "motivation": "\u5c3d\u7ba1\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u8282\u70b9\u6807\u7b7e\u4e4b\u95f4\u7684\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u8fd9\u4e0e\u56fe\u4e2d\u8282\u70b9\u6807\u7b7e\u5b9e\u9645\u4e0a\u76f8\u4e92\u5173\u8054\u7684\u4e8b\u5b9e\u76f8\u77db\u76fe\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u7ed3\u6784\u5316\u9884\u6d4b\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8282\u70b9\u5206\u7c7b\u3002", "method": "\u63d0\u51fa\u4e86ReDiSC\uff08\u7528\u4e8e\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u7684\u91cd\u65b0\u53c2\u6570\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\uff09\uff0c\u5b83\u4f7f\u7528\u91cd\u65b0\u53c2\u6570\u5316\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u6765\u4f30\u8ba1\u8282\u70b9\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u53d8\u5206\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86ReDiSC\u5728E\u6b65\u4e2d\u7684\u6548\u7387\u4f18\u52bf\uff0c\u5e76\u5c06\u5176M\u6b65\u76ee\u6807\u4e0e\u6d41\u884c\u7684GNN\u548c\u6807\u7b7e\u4f20\u64ad\u6df7\u5408\u65b9\u6cd5\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cReDiSC\u5728\u540c\u6027\u548c\u5f02\u6027\u56fe\u4e2d\u5747\u8fbe\u5230\u4e86\u4f18\u8d8a\u6216\u9ad8\u5ea6\u6709\u7ade\u4e89\u529b\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u53ef\u4ee5\u6709\u6548\u6269\u5c55\u5230\u5927\u578b\u6570\u636e\u96c6\uff0c\u800c\u4ee5\u524d\u7684\u7ed3\u6784\u5316\u6269\u6563\u65b9\u6cd5\u7531\u4e8e\u8ba1\u7b97\u9650\u5236\u65e0\u6cd5\u505a\u5230\u8fd9\u4e00\u70b9\u3002", "conclusion": "ReDiSC\u4e3a\u7ed3\u6784\u5316\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u800c\u4e14\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65b9\u9762\u5177\u6709\u663e\u8457\u7684\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2507.14393", "pdf": "https://arxiv.org/pdf/2507.14393", "abs": "https://arxiv.org/abs/2507.14393", "authors": ["Humza Sami", "Mubashir ul Islam", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "title": "Adaptive Multi-Agent Reasoning via Automated Workflow Generation", "categories": ["cs.AI"], "comment": null, "summary": "The rise of Large Reasoning Models (LRMs) promises a significant leap forward\nin language model capabilities, aiming to tackle increasingly sophisticated\ntasks with unprecedented efficiency and accuracy. However, despite their\nimpressive performance, recent studies have highlighted how current reasoning\nmodels frequently fail to generalize to novel, unseen problems, often resorting\nto memorized solutions rather than genuine inferential reasoning. Such behavior\nunderscores a critical limitation in modern LRMs, i.e., their tendency toward\noverfitting, which in turn results in poor generalization in problem-solving\ncapabilities.\n  In this paper, we introduce Nexus Architect, an enhanced iteration of our\nmulti-agent system framework, Nexus, equipped with a novel automated workflow\nsynthesis mechanism. Given a user's prompt and a small set of representative\nexamples, the Architect autonomously generates a tailored reasoning workflow by\nselecting suitable strategies, tool integrations, and adversarial techniques\nfor a specific problem class. Furthermore, the Architect includes an iterative\nprompt refinement mechanism that fine-tunes agents' system prompts to maximize\nperformance and improve the generalization capabilities of the system.\n  We empirically evaluate Nexus Architect by employing an off-the-shelf,\nnon-reasoning model on a custom dataset of challenging logical questions and\ncompare its performance against state-of-the-art LRMs. Results show that Nexus\nArchitect consistently outperforms existing solutions, achieving up to a 66%\nincrease in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\\times$ against\nClaude Sonnet 4 and DeepSeek-R1, and over 3$\\times$ w.r.t. Llama 4 Scout.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6Nexus Architect\uff0c\u5b83\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\u548c\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\u673a\u5236\u63d0\u9ad8\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u6311\u6218\u6027\u903b\u8f91\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5c3d\u7ba1\u6027\u80fd\u51fa\u8272\uff0c\u4f46\u5728\u9762\u5bf9\u65b0\u9896\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5f80\u5f80\u4f9d\u8d56\u4e8e\u8bb0\u5fc6\u89e3\u51b3\u65b9\u6848\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\uff0c\u5bfc\u81f4\u8fc7\u62df\u5408\u73b0\u8c61\u4e25\u91cd\u3002", "method": "\u5f15\u5165\u4e86Nexus Architect\uff0c\u4e00\u4e2a\u589e\u5f3a\u4e86\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6\uff0c\u5305\u542b\u81ea\u52a8\u5de5\u4f5c\u6d41\u5408\u6210\u673a\u5236\u548c\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\u673a\u5236\uff0c\u4ee5\u751f\u6210\u5b9a\u5236\u5316\u7684\u63a8\u7406\u5de5\u4f5c\u6d41\u5e76\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cNexus Architect\u5728\u89e3\u51b3\u6311\u6218\u6027\u903b\u8f91\u95ee\u9898\u4e0a\u7684\u901a\u8fc7\u7387\u6bd4Gemini 2.5 Flash Preview\u9ad8\u51fa66%\uff0c\u662fClaude Sonnet 4\u548cDeepSeek-R1\u7684\u5927\u7ea62.5\u500d\uff0cLlama 4 Scout\u7684\u8d85\u8fc73\u500d\u3002", "conclusion": "Nexus Architect\u80fd\u591f\u6709\u6548\u5730\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\uff0c\u76f8\u6bd4\u73b0\u6709\u7684LRMs\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2507.14487", "pdf": "https://arxiv.org/pdf/2507.14487", "abs": "https://arxiv.org/abs/2507.14487", "authors": ["Ukjo Hwang", "Songnam Hong"], "title": "Federated Reinforcement Learning in Heterogeneous Environments", "categories": ["cs.LG"], "comment": null, "summary": "We investigate a Federated Reinforcement Learning with Environment\nHeterogeneity (FRL-EH) framework, where local environments exhibit statistical\nheterogeneity. Within this framework, agents collaboratively learn a global\npolicy by aggregating their collective experiences while preserving the privacy\nof their local trajectories. To better reflect real-world scenarios, we\nintroduce a robust FRL-EH framework by presenting a novel global objective\nfunction. This function is specifically designed to optimize a global policy\nthat ensures robust performance across heterogeneous local environments and\ntheir plausible perturbations. We propose a tabular FRL algorithm named FedRQ\nand theoretically prove its asymptotic convergence to an optimal policy for the\nglobal objective function. Furthermore, we extend FedRQ to environments with\ncontinuous state space through the use of expectile loss, addressing the key\nchallenge of minimizing a value function over a continuous subset of the state\nspace. This advancement facilitates the seamless integration of the principles\nof FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive\nempirical evaluations validate the effectiveness and robustness of our FRL\nalgorithms across diverse heterogeneous environments, consistently achieving\nsuperior performance over the existing state-of-the-art FRL algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6FRL-EH\uff0c\u5f15\u5165\u4e86\u9c81\u68d2\u7684\u5168\u5c40\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u63d0\u51fa\u4e86\u7b97\u6cd5FedRQ\u53ca\u5176\u6269\u5c55\u7248\u672c\u4ee5\u9002\u5e94\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\uff08FRL\uff09\u7814\u7a76\u5927\u591a\u5047\u8bbe\u6240\u6709\u4ee3\u7406\u4eba\u7684\u73af\u5883\u662f\u540c\u8d28\u7684\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u73af\u5883\u5f80\u5f80\u662f\u7edf\u8ba1\u4e0a\u5f02\u6784\u7684\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5904\u7406\u73af\u5883\u5f02\u6784\u6027\u7684FRL\u6846\u67b6\uff0c\u540c\u65f6\u4fdd\u62a4\u5404\u4ee3\u7406\u4eba\u672c\u5730\u6570\u636e\u9690\u79c1\u3002", "method": "\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedRQ\u7684\u8868\u683c\u578bFRL\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u4e86\u5b83\u5728\u7ed9\u5b9a\u7684\u5168\u5c40\u76ee\u6807\u51fd\u6570\u4e0b\u53ef\u4ee5\u6e10\u8fdb\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u7684\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u5c06FedRQ\u6269\u5c55\uff0c\u4f7f\u7528expectile\u635f\u5931\u6765\u6700\u5c0f\u5316\u503c\u51fd\u6570\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684FRL\u7b97\u6cd5\u5728\u5404\u79cd\u5f02\u6784\u73af\u5883\u4e2d\u5177\u6709\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684FRL\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u9c81\u68d2\u7684FRL-EH\u6846\u67b6\u548c\u5f00\u53d1\u51fa\u6709\u6548\u7684\u7b97\u6cd5FedRQ\u53ca\u5b83\u7684\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u6269\u5c55\uff0c\u672c\u7814\u7a76\u4e3a\u5904\u7406\u73af\u5883\u5f02\u6784\u6027\u7684\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u3002\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u4e86\u65b0\u6846\u67b6\u548c\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.14406", "pdf": "https://arxiv.org/pdf/2507.14406", "abs": "https://arxiv.org/abs/2507.14406", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages, 5 figures", "summary": "State-of-the-art reasoning LLMs are powerful problem solvers, but they still\noccasionally make mistakes. However, adopting AI models in risk-sensitive\ndomains often requires error rates near 0%. To address this gap, we propose\ncollaboration between a reasoning model and a human expert who resolves queries\nthe model cannot confidently answer. We find that quantifying the uncertainty\nof a reasoning model through the length of its reasoning trace yields an\neffective basis for deferral to a human, e.g., cutting the error rate of Qwen3\n235B-A22B on difficult MATH problems from 3% to less than 1% when deferring\n7.5% of queries. However, the high latency of reasoning models still makes them\nchallenging to deploy on use cases with high query volume. To address this\nchallenge, we explore fronting a reasoning model with a large non-reasoning\nmodel. We call this modified human-in-the-loop system \"Fail Fast, or Ask\",\nsince the non-reasoning model may defer difficult queries to the human expert\ndirectly (\"failing fast\"), without incurring the reasoning model's higher\nlatency. We show that this approach yields around 40% latency reduction and\nabout 50% cost savings for DeepSeek R1 while maintaining 90+% area under the\naccuracy-rejection curve. However, we observe that latency savings are lower\nthan expected because of \"latency drag\", the phenomenon that processing easier\nqueries with a non-reasoning model pushes the reasoning model's latency\ndistribution towards longer latencies. Broadly, our results suggest that the\ndeficiencies of state-of-the-art reasoning models -- nontrivial error rates and\nhigh latency -- can be substantially mitigated through black-box systems\nengineering, without requiring access to LLM internals.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63a8\u7406\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u534f\u4f5c\u7684\u65b9\u6cd5\uff0c\u4ee5\u964d\u4f4e\u63a8\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u9519\u8bef\u7387\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u975e\u63a8\u7406\u5927\u578b\u6a21\u578b\u6765\u51cf\u5c11\u5ef6\u8fdf\u548c\u6210\u672c\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u6539\u5584\u73b0\u6709\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u66f4\u9002\u7528\u4e8e\u98ce\u9669\u654f\u611f\u9886\u57df\u3002", "motivation": "\u5c3d\u7ba1\u6700\u5148\u8fdb\u7684\u63a8\u7406LLMs\u5728\u89e3\u51b3\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5076\u5c14\u4f1a\u72af\u9519\u3002\u7136\u800c\uff0c\u5728\u98ce\u9669\u654f\u611f\u9886\u57df\u5e94\u7528AI\u6a21\u578b\u901a\u5e38\u9700\u8981\u63a5\u8fd10%\u7684\u9519\u8bef\u7387\u3002\u6b64\u5916\uff0c\u63a8\u7406\u6a21\u578b\u7684\u9ad8\u5ef6\u8fdf\u4e5f\u4f7f\u5f97\u5176\u5728\u9ad8\u67e5\u8be2\u91cf\u7684\u4f7f\u7528\u6848\u4f8b\u4e2d\u96be\u4ee5\u90e8\u7f72\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5efa\u8bae\u5c06\u63a8\u7406\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7ed3\u5408\u8d77\u6765\uff0c\u5f53\u6a21\u578b\u4e0d\u80fd\u81ea\u4fe1\u5730\u56de\u7b54\u95ee\u9898\u65f6\uff0c\u7531\u4eba\u7c7b\u4e13\u5bb6\u89e3\u51b3\u67e5\u8be2\u3002\u901a\u8fc7\u91cf\u5316\u63a8\u7406\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u90e8\u5206\u67e5\u8be2\u8f6c\u79fb\u7ed9\u4eba\u7c7b\u4e13\u5bb6\u5904\u7406\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u63a2\u7d22\u4e86\u5728\u63a8\u7406\u6a21\u578b\u524d\u52a0\u5165\u4e00\u4e2a\u5927\u7684\u975e\u63a8\u7406\u6a21\u578b\uff0c\u4ee5\u8fdb\u4e00\u6b65\u51cf\u5c11\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u56f0\u96be\u7684\u6570\u5b66\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5c06Qwen3 235B-A22B\u7684\u9519\u8bef\u7387\u4ece3%\u964d\u4f4e\u5230\u4e0d\u52301%\uff0c\u540c\u65f6\u5c067.5%\u7684\u67e5\u8be2\u8f6c\u79fb\u7ed9\u4e13\u5bb6\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5f15\u5165\u975e\u63a8\u7406\u6a21\u578b\uff0cDeepSeek R1\u5b9e\u73b0\u4e86\u7ea640%\u7684\u5ef6\u8fdf\u51cf\u5c11\u548c\u7ea650%\u7684\u6210\u672c\u8282\u7701\uff0c\u540c\u65f6\u4fdd\u630190%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387-\u62d2\u7edd\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\u3002\u4f46\u662f\uff0c\u7531\u4e8e\u201c\u5ef6\u8fdf\u62d6\u62fd\u201d\u73b0\u8c61\uff0c\u5ef6\u8fdf\u8282\u7701\u4e0d\u5982\u9884\u671f\u3002", "conclusion": "\u603b\u7684\u6765\u8bf4\uff0c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9ed1\u76d2\u7cfb\u7edf\u5de5\u7a0b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u8bbf\u95eeLLM\u5185\u90e8\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u7f13\u89e3\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u5b58\u5728\u7684\u975e\u96f6\u9519\u8bef\u7387\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\u3002"}}
{"id": "2507.14987", "pdf": "https://arxiv.org/pdf/2507.14987", "abs": "https://arxiv.org/abs/2507.14987", "authors": ["Yi Zhang", "An Zhang", "XiuYu Zhang", "Leheng Sheng", "Yuxin Chen", "Zhenkai Liang", "Xiang Wang"], "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "Large language models (LLMs), despite possessing latent safety understanding\nfrom their vast pretraining data, remain vulnerable to generating harmful\ncontent and exhibit issues such as over-refusal and utility degradation after\nsafety alignment. Current safety alignment methods often result in superficial\nrefusal shortcuts or rely on intensive supervision for reasoning-based\napproaches, failing to fully leverage the model's intrinsic safety\nself-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure\nreinforcement learning (RL) framework with verifiable safety reward designed to\nincentivize this latent safety awareness through proactive safety reasoning.}\nAlphaAlign employs a dual-reward system: a verifiable safety reward encourages\ncorrectly formatted and explicitly justified refusals for harmful queries while\npenalizing over-refusals, and a normalized helpfulness reward guides\nhigh-quality responses to benign inputs. This allows the model to develop\nproactive safety reasoning capabilities without depending on supervised\nsafety-specific reasoning data. AlphaAlign demonstrates three key advantages:\n(1) Simplicity and efficiency, requiring only binary prompt safety labels and\nminimal RL steps for substantial improvements. (2) Breaking the safety-utility\ntrade-off, by enhancing refusal of harmful content and reducing over-refusals,\nwhile simultaneously maintaining or even improving general task performance and\nrobustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety\nreasoning that generates explicit safety rationales rather than relying on\nshallow refusal patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAlphaAlign\u7684\u7eaf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u673a\u5236\u6fc0\u52b1\u6a21\u578b\u7684\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u65b9\u9762\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5177\u6709\u6f5c\u5728\u7684\u5b89\u5168\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u5bb9\u6613\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u5e76\u4e14\u5728\u5b89\u5168\u5bf9\u9f50\u540e\u8868\u73b0\u51fa\u8fc7\u5ea6\u62d2\u7edd\u548c\u5b9e\u7528\u6027\u4e0b\u964d\u7684\u95ee\u9898\u3002\u73b0\u6709\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u5bfc\u81f4\u8868\u9762\u7684\u62d2\u7edd\u6377\u5f84\u6216\u4f9d\u8d56\u4e8e\u5bc6\u96c6\u76d1\u7763\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u7684\u5185\u5728\u5b89\u5168\u81ea\u77e5\u529b\u3002", "method": "AlphaAlign\u91c7\u7528\u53cc\u91cd\u5956\u52b1\u7cfb\u7edf\uff1a\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u5956\u52b1\u9f13\u52b1\u6b63\u786e\u683c\u5f0f\u5316\u548c\u660e\u786e\u7406\u7531\u7684\u62d2\u7edd\u6709\u5bb3\u67e5\u8be2\uff0c\u540c\u65f6\u60e9\u7f5a\u8fc7\u5ea6\u62d2\u7edd\uff1b\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u5e2e\u52a9\u5956\u52b1\u5f15\u5bfc\u9ad8\u8d28\u91cf\u56de\u5e94\u826f\u6027\u8f93\u5165\u3002", "result": "AlphaAlign\u5c55\u793a\u4e86\u4e09\u4e2a\u5173\u952e\u4f18\u52bf\uff1a(1) \u7b80\u5355\u9ad8\u6548\uff0c\u4ec5\u9700\u4e8c\u5143\u63d0\u793a\u5b89\u5168\u6027\u6807\u7b7e\u548c\u6700\u5c11\u7684RL\u6b65\u9aa4\u5373\u53ef\u663e\u8457\u6539\u8fdb\u3002(2) \u6253\u7834\u5b89\u5168-\u6548\u7528\u6743\u8861\uff0c\u901a\u8fc7\u589e\u5f3a\u6709\u5bb3\u5185\u5bb9\u7684\u62d2\u7edd\u5e76\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u751a\u81f3\u63d0\u9ad8\u4e00\u822c\u4efb\u52a1\u6027\u80fd\u548c\u5bf9\u672a\u89c1\u8fc7\u7684\u8d8a\u72f1\u7684\u9c81\u68d2\u6027\u3002(3) \u6df1\u5ea6\u5bf9\u9f50\uff0c\u4fc3\u8fdb\u4e3b\u52a8\u5b89\u5168\u63a8\u7406\uff0c\u4ea7\u751f\u660e\u786e\u7684\u5b89\u5168\u7406\u7531\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u6d45\u5c42\u62d2\u7edd\u6a21\u5f0f\u3002", "conclusion": "AlphaAlign\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u7eaf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u6fc0\u52b1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\uff0c\u6539\u5584\u5176\u5728\u5904\u7406\u6709\u5bb3\u5185\u5bb9\u65f6\u7684\u8868\u73b0\uff0c\u540c\u65f6\u7ef4\u6301\u6216\u63d0\u9ad8\u6574\u4f53\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2507.14492", "pdf": "https://arxiv.org/pdf/2507.14492", "abs": "https://arxiv.org/abs/2507.14492", "authors": ["Satyankar Chandra", "Ashutosh Gupta", "Kaushik Mallik", "Krishna Shankaranarayanan", "Namrita Varshney"], "title": "Glitches in Decision Tree Ensemble Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many critical decision-making tasks are now delegated to machine-learned\nmodels, and it is imperative that their decisions are trustworthy and reliable,\nand their outputs are consistent across similar inputs. We identify a new\nsource of unreliable behaviors-called glitches-which may significantly impair\nthe reliability of AI models having steep decision boundaries. Roughly\nspeaking, glitches are small neighborhoods in the input space where the model's\noutput abruptly oscillates with respect to small changes in the input. We\nprovide a formal definition of glitches, and use well-known models and datasets\nfrom the literature to demonstrate that they have widespread existence and\nargue they usually indicate potential model inconsistencies in the neighborhood\nof where they are found. We proceed to the algorithmic search of glitches for\nwidely used gradient-boosted decision tree (GBDT) models. We prove that the\nproblem of detecting glitches is NP-complete for tree ensembles, already for\ntrees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP\nencoding of the problem, and its effectiveness and computational feasibility\nare demonstrated on a set of widely used GBDT benchmarks taken from the\nliterature.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8ba8\u8bba\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u4e00\u79cd\u65b0\u7684\u4e0d\u53ef\u9760\u884c\u4e3a\u6765\u6e90\u2014\u2014glitches\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9GBDT\u6a21\u578b\u7684glitches\u641c\u7d22\u7b97\u6cd5\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u952e\u51b3\u7b56\u4efb\u52a1\u88ab\u59d4\u6258\u7ed9\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u786e\u4fdd\u8fd9\u4e9b\u6a21\u578b\u7684\u51b3\u7b56\u662f\u53ef\u4fe1\u548c\u53ef\u9760\u7684\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u4eec\u8bc6\u522b\u51fa\u4e00\u79cd\u65b0\u7684\u4e0d\u53ef\u9760\u884c\u4e3a\u6765\u6e90\u2014\u2014glitches\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4e25\u91cd\u5f71\u54cd\u5177\u6709\u9661\u5ced\u51b3\u7b56\u8fb9\u754c\u7684AI\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f5c\u8005\u4eec\u9996\u5148\u4e3aglitches\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u5b9a\u4e49\uff0c\u5e76\u4f7f\u7528\u6587\u732e\u4e2d\u7684\u77e5\u540d\u6a21\u578b\u548c\u6570\u636e\u96c6\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u666e\u904d\u5b58\u5728\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u9488\u5bf9\u5e7f\u6cdb\u4f7f\u7528\u7684\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\uff08GBDT\uff09\u6a21\u578b\u8fdb\u884c\u4e86glitches\u7684\u7b97\u6cd5\u641c\u7d22\u3002\u4ed6\u4eec\u8bc1\u660e\u4e86\u5bf9\u4e8e\u6df1\u5ea6\u8fbe\u52304\u7684\u6811\u6765\u8bf4\uff0c\u68c0\u6d4bglitches\u7684\u95ee\u9898\u5df2\u7ecf\u662fNP\u5b8c\u5168\u95ee\u9898\u3002\u4ed6\u4eec\u7684glitches\u641c\u7d22\u7b97\u6cd5\u4f7f\u7528\u4e86MILP\u7f16\u7801\u6765\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u4e00\u7ec4\u6765\u81ea\u6587\u732e\u7684\u5e7f\u6cdb\u4f7f\u7528\u7684GBDT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "conclusion": "glitches\u5728\u8f93\u5165\u7a7a\u95f4\u7684\u5c0f\u90bb\u57df\u5185\u5b58\u5728\uff0c\u5176\u4e2d\u6a21\u578b\u7684\u8f93\u51fa\u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u5c0f\u53d8\u5316\u7a81\u7136\u632f\u8361\u3002\u8fd9\u901a\u5e38\u8868\u660e\u5728\u53d1\u73b0\u5b83\u4eec\u7684\u90bb\u57df\u9644\u8fd1\u53ef\u80fd\u5b58\u5728\u6a21\u578b\u4e0d\u4e00\u81f4\u3002"}}
{"id": "2507.14417", "pdf": "https://arxiv.org/pdf/2507.14417", "abs": "https://arxiv.org/abs/2507.14417", "authors": ["Aryo Pradipta Gema", "Alexander H\u00e4gele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "title": "Inverse Scaling in Test-Time Compute", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u63a8\u7406\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\uff0c\u589e\u52a0\u63a8\u7406\u957f\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e86\u4e94\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u6307\u51fa\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u63d0\u5347\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u5f3a\u5316\u6709\u95ee\u9898\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u7406\u89e3\u5f53\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u5904\u7406\u4efb\u52a1\u65f6\uff0c\u5ef6\u957f\u63a8\u7406\u65f6\u95f4\u5982\u4f55\u5f71\u54cd\u5176\u8868\u73b0\u3002\u8fd9\u5305\u62ec\u63a2\u7d22\u53ef\u80fd\u5b58\u5728\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4ee5\u53ca\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d44\u6e90\u7684\u589e\u52a0\u662f\u5426\u603b\u662f\u5e26\u6765\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u66f4\u5408\u7406\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "method": "\u6784\u5efa\u4e86\u6db5\u76d6\u56db\u4e2a\u7c7b\u522b\u7684\u8bc4\u4f30\u4efb\u52a1\uff1a\u7b80\u5355\u8ba1\u6570\u4efb\u52a1\u3001\u5e26\u6709\u865a\u5047\u7279\u5f81\u7684\u56de\u5f52\u4efb\u52a1\u3001\u5e26\u6709\u7ea6\u675f\u8ddf\u8e2a\u7684\u6f14\u7ece\u4efb\u52a1\u548c\u9ad8\u7ea7AI\u98ce\u9669\u3002\u901a\u8fc7\u8fd9\u4e9b\u4efb\u52a1\u6765\u89c2\u5bdf\u6a21\u578b\u5728\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u4e94\u79cd\u4e0d\u540c\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u88ab\u65e0\u5173\u4fe1\u606f\u5206\u5fc3\u3001\u8fc7\u5ea6\u62df\u5408\u95ee\u9898\u6846\u67b6\u3001\u4ece\u5408\u7406\u5047\u8bbe\u8f6c\u5411\u865a\u5047\u76f8\u5173\u6027\u7b49\u3002\u6b64\u5916\uff0c\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u6f14\u7ece\u4efb\u52a1\u4e2d\u90fd\u96be\u4ee5\u4fdd\u6301\u4e13\u6ce8\uff0c\u4e14\u5ef6\u957f\u63a8\u7406\u65f6\u95f4\u53ef\u80fd\u4f1a\u653e\u5927\u4ee4\u4eba\u62c5\u5fe7\u7684\u884c\u4e3a\u3002", "conclusion": "\u867d\u7136\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u6269\u5c55\u4ecd\u7136\u6709\u6f5c\u529b\u6539\u5584\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4f46\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u5f3a\u5316\u6709\u95ee\u9898\u7684\u63a8\u7406\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u5728\u5404\u79cd\u63a8\u7406\u957f\u5ea6\u4e0b\u8bc4\u4f30\u6a21\u578b\u4ee5\u8bc6\u522b\u548c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u6a21\u5f0f\u662f\u91cd\u8981\u7684\u3002"}}
{"id": "2507.15112", "pdf": "https://arxiv.org/pdf/2507.15112", "abs": "https://arxiv.org/abs/2507.15112", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Sanmi Koyejo"], "title": "Distributional Unlearning: Forgetting Distributions, Not Just Samples", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u5206\u5e03\u9057\u5fd8\uff08distributional unlearning\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u65e8\u5728\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u5220\u9664\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u6240\u6709\u75d5\u8ff9\u3002\u901a\u8fc7\u4f7f\u7528Kullback-Leibler\u6563\u5ea6\u6765\u91cf\u5316\u5220\u9664\u548c\u4fdd\u7559\u7684\u7a0b\u5ea6\uff0c\u8be5\u7814\u7a76\u63a8\u5bfc\u4e86\u9ad8\u65af\u60c5\u51b5\u4e0b\u7684\u7cbe\u786e\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddd\u79bb\u7684\u9009\u62e9\u89c4\u5219\uff0c\u4ee5\u51cf\u5c11\u5220\u9664\u9884\u7b97\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6bd4\u968f\u673a\u5220\u9664\u66f4\u6709\u6548\u7387\uff0c\u540c\u65f6\u5bf9\u5269\u4f59\u6570\u636e\u7684\u8868\u73b0\u5f71\u54cd\u5f88\u5c0f\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u5de5\u5177\u4e3b\u8981\u96c6\u4e2d\u5728\u4e2a\u4f53\u6837\u672c\u5c42\u9762\uff0c\u5728\u5220\u9664\u6574\u4e2a\u4e3b\u9898\u9886\u57df\u6216\u5b50\u7fa4\u4f53\u7684\u6570\u636e\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u76f4\u63a5\u5220\u9664\u70b9\u5f80\u5f80\u4e0d\u8db3\u4ee5\u5b8c\u5168\u79fb\u9664\u4e0d\u60f3\u8981\u7684\u9886\u57df\u4fe1\u606f\uff0c\u4e0b\u6e38\u5b66\u4e60\u8005\u4ecd\u80fd\u6062\u590d\u8fd9\u4e9b\u4fe1\u606f\u3002\u4e3a\u4e86\u6ee1\u8db3\u9690\u79c1\u3001\u6cd5\u5f8b\u6216\u8d28\u91cf\u8981\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6709\u6548\u5730\u5220\u9664\u6574\u4e2a\u5b50\u7fa4\u4f53\u7684\u6570\u636e\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u5206\u5e03\u9057\u5fd8\u7684\u6982\u5ff5\uff0c\u5373\u627e\u5230\u6700\u5c0f\u7684\u4e00\u7ec4\u70b9\uff0c\u5176\u5220\u9664\u80fd\u4f7f\u7f16\u8f91\u540e\u7684\u6570\u636e\u96c6\u8fdc\u79bb\u4e0d\u60f3\u8981\u7684\u9886\u57df\uff0c\u4f46\u53c8\u4fdd\u6301\u63a5\u8fd1\u88ab\u4fdd\u7559\u7684\u9886\u57df\u3002\u4f7f\u7528Kullback-Leibler\u6563\u5ea6\u4f5c\u4e3a\u91cf\u5316\u6807\u51c6\uff0c\u4ed6\u4eec\u63a8\u5bfc\u4e86\u5728\u9ad8\u65af\u5206\u5e03\u60c5\u51b5\u4e0b\u7684\u7cbe\u786e\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5e76\u8bc1\u660e\u4e86\u4efb\u4f55\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u7f16\u8f91\u540e\u7684\u6570\u636e\u4e0a\u7684log-loss\u53d8\u5316\u4e0d\u4f1a\u8d85\u8fc7\u6563\u5ea6\u9608\u503c\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddd\u79bb\u7684\u9009\u62e9\u89c4\u5219\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5220\u9664\u9884\u7b97\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4e8e\u968f\u673a\u5220\u9664\uff0c\u5206\u5e03\u9057\u5fd8\u65b9\u6cd5\u5728\u5408\u6210\u9ad8\u65af\u6570\u636e\u3001Jigsaw Toxic Comments\u3001SMS\u5783\u573e\u90ae\u4ef6\u548cCIFAR-10\u7b49\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u51cf\u5c11\u4e8615-72%\u7684\u5220\u9664\u64cd\u4f5c\uff0c\u540c\u65f6\u5bf9\u4fdd\u7559\u6570\u636e\u7684\u8868\u73b0\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\u3002", "conclusion": "\u5206\u5e03\u9057\u5fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u5220\u9664\u6574\u4e2a\u5b50\u7fa4\u4f53\u7684\u4fe1\u606f\uff0c\u800c\u4e0d\u4f1a\u663e\u8457\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u3002\u5b83\u4e0d\u4ec5\u51cf\u5c11\u4e86\u5220\u9664\u6240\u9700\u7684\u6570\u636e\u91cf\uff0c\u800c\u4e14\u4fdd\u8bc1\u4e86\u7f16\u8f91\u540e\u6570\u636e\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.14503", "pdf": "https://arxiv.org/pdf/2507.14503", "abs": "https://arxiv.org/abs/2507.14503", "authors": ["Jiequan Cui", "Beier Zhu", "Qingshan Xu", "Xiaogang Xu", "Pengguang Chen", "Xiaojuan Qi", "Bei Yu", "Hanwang Zhang", "Richang Hong"], "title": "Generative Distribution Distillation", "categories": ["cs.LG", "cs.CV"], "comment": "Technique report", "summary": "In this paper, we formulate the knowledge distillation (KD) as a conditional\ngenerative problem and propose the \\textit{Generative Distribution Distillation\n(GenDD)} framework. A naive \\textit{GenDD} baseline encounters two major\nchallenges: the curse of high-dimensional optimization and the lack of semantic\nsupervision from labels. To address these issues, we introduce a \\textit{Split\nTokenization} strategy, achieving stable and effective unsupervised KD.\nAdditionally, we develop the \\textit{Distribution Contraction} technique to\nintegrate label supervision into the reconstruction objective. Our theoretical\nproof demonstrates that \\textit{GenDD} with \\textit{Distribution Contraction}\nserves as a gradient-level surrogate for multi-task learning, realizing\nefficient supervised training without explicit classification loss on\nmulti-step sampling image representations. To evaluate the effectiveness of our\nmethod, we conduct experiments on balanced, imbalanced, and unlabeled data.\nExperimental results show that \\textit{GenDD} performs competitively in the\nunsupervised setting, significantly surpassing KL baseline by \\textbf{16.29\\%}\non ImageNet validation set. With label supervision, our ResNet-50 achieves\n\\textbf{82.28\\%} top-1 accuracy on ImageNet in 600 epochs training,\nestablishing a new state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6GenDD\uff0c\u901a\u8fc7\u5f15\u5165\u5206\u5272\u6807\u8bb0\u5316\u548c\u5206\u5e03\u6536\u7f29\u6280\u672f\u6765\u89e3\u51b3\u9ad8\u7ef4\u4f18\u5316\u548c\u8bed\u4e49\u76d1\u7763\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6709\u65e0\u6807\u7b7e\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0cGenDD\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728ImageNet\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u7684\u6700\u4f73\u6210\u679c\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u662f\u4e00\u79cd\u5c06\u5927\u578b\u590d\u6742\u6a21\u578b\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230\u5c0f\u578b\u7b80\u5355\u6a21\u578b\u7684\u6280\u672f\uff0c\u7136\u800c\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u7740\u9ad8\u7ef4\u4f18\u5316\u548c\u7f3a\u4e4f\u8bed\u4e49\u76d1\u7763\u7684\u6311\u6218\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Generative Distribution Distillation (GenDD) \u6846\u67b6\uff0c\u5c06\u77e5\u8bc6\u84b8\u998f\u95ee\u9898\u5efa\u6a21\u4e3a\u6761\u4ef6\u751f\u6210\u95ee\u9898\u3002\u4e3a\u4e86\u5e94\u5bf9\u6311\u6218\uff0c\u4ed6\u4eec\u5f15\u5165\u4e86Split Tokenization\u7b56\u7565\u548cDistribution Contraction\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGenDD\u5728\u672a\u76d1\u7763\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4KL\u57fa\u7ebf\u63d0\u9ad8\u4e8616.29\uff05\u3002\u4f7f\u7528\u6807\u7b7e\u76d1\u7763\u65f6\uff0cResNet-50\u5728ImageNet\u4e0a\u7684top-1\u51c6\u786e\u7387\u8fbe\u5230\u4e8682.28\uff05\uff0c\u6210\u4e3a\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684GenDD\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\uff0c\u4e0d\u4ec5\u89e3\u51b3\u4e86\u9ad8\u7ef4\u4f18\u5316\u548c\u8bed\u4e49\u76d1\u7763\u7684\u95ee\u9898\uff0c\u8fd8\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u7ade\u4e89\u529b\u3002"}}
{"id": "2507.14447", "pdf": "https://arxiv.org/pdf/2507.14447", "abs": "https://arxiv.org/abs/2507.14447", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "categories": ["cs.AI", "cs.CL"], "comment": "26 pages, 8 figures, 5 tables", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aRoutine\u7684\u591a\u6b65\u9aa4\u4ee3\u7406\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u548c\u53c2\u6570\u4f20\u9012\u63d0\u9ad8\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u6a21\u578b\u6267\u884c\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86GPT-4o\u548cQwen3-14B\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u7684\u6570\u636e\u96c6\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u4ee3\u7406\u7cfb\u7edf\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u4f8b\u5982\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u7684\u8fc7\u7a0b\u77e5\u8bc6\u3001\u8ba1\u5212\u4e0d\u5b8c\u6574\u3001\u7f3a\u5931\u5173\u952e\u5de5\u5177\u4ee5\u53ca\u6267\u884c\u7a33\u5b9a\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86Routine\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5177\u6709\u660e\u786e\u7684\u7ed3\u6784\u3001\u6e05\u6670\u7684\u6307\u4ee4\u548c\u65e0\u7f1d\u7684\u53c2\u6570\u4f20\u9012\u673a\u5236\uff0c\u6307\u5bfc\u4ee3\u7406\u6267\u884c\u6a21\u5757\u8fdb\u884c\u591a\u6b65\u9aa4\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9075\u5faaRoutine\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u5e76\u8fdb\u884c\u4e86\u6a21\u578b\u5fae\u8c03\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u4f01\u4e1a\u573a\u666f\u8bc4\u4f30\u4e2d\uff0cRoutine\u5c06GPT-4o\u7684\u6027\u80fd\u4ece41.1%\u63d0\u9ad8\u523096.3%\uff0cQwen3-14B\u4ece32.6%\u63d0\u9ad8\u523083.3%\uff0c\u5e76\u5728\u9886\u57df\u7279\u5b9a\u8bc4\u4f30\u4e2d\u8fdb\u4e00\u6b65\u63d0\u5347\u81f388.2%\u3002\u901a\u8fc7Routine-based\u84b8\u998f\u521b\u5efa\u7684\u6570\u636e\u96c6\uff0c\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u5230\u4e8695.5%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cRoutine\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6613\u4e8e\u5b9e\u73b0\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u7a33\u5b9a\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u52a0\u901f\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u4ee3\u7406\u7cfb\u7edf\u7684\u90e8\u7f72\u4e0e\u91c7\u7528\uff0c\u63a8\u52a8\u4e86\u9762\u5411\u8fc7\u7a0b\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\u613f\u666f\u3002"}}
{"id": "2507.15836", "pdf": "https://arxiv.org/pdf/2507.15836", "abs": "https://arxiv.org/abs/2507.15836", "authors": ["Matteo Boglioni", "Terrance Liu", "Andrew Ilyas", "Zhiwei Steven Wu"], "title": "Optimizing Canaries for Privacy Auditing with Metagradient Descent", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "In this work we study black-box privacy auditing, where the goal is to lower\nbound the privacy parameter of a differentially private learning algorithm\nusing only the algorithm's outputs (i.e., final trained model). For DP-SGD (the\nmost successful method for training differentially private deep learning\nmodels), the canonical approach auditing uses membership inference-an auditor\ncomes with a small set of special \"canary\" examples, inserts a random subset of\nthem into the training set, and then tries to discern which of their canaries\nwere included in the training set (typically via a membership inference\nattack). The auditor's success rate then provides a lower bound on the privacy\nparameters of the learning algorithm. Our main contribution is a method for\noptimizing the auditor's canary set to improve privacy auditing, leveraging\nrecent work on metagradient optimization. Our empirical evaluation demonstrates\nthat by using such optimized canaries, we can improve empirical lower bounds\nfor differentially private image classification models by over 2x in certain\ninstances. Furthermore, we demonstrate that our method is transferable and\nefficient: canaries optimized for non-private SGD with a small model\narchitecture remain effective when auditing larger models trained with DP-SGD.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4f18\u5316\u5ba1\u8ba1\u5458\u7684'canary'\u96c6\uff0c\u6539\u8fdb\u4e86\u9ed1\u76d2\u9690\u79c1\u5ba1\u8ba1\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5c06\u7ecf\u9a8c\u4e0b\u9650\u63d0\u9ad82\u500d\u4ee5\u4e0a\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u90fd\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u7684\u9690\u79c1\u5ba1\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4f1a\u5458\u63a8\u65ad\uff0c\u5373\u901a\u8fc7\u68c0\u6d4b\u7279\u5b9a\u6837\u672c\u662f\u5426\u88ab\u5305\u542b\u5728\u8bad\u7ec3\u96c6\u4e2d\u6765\u4f30\u8ba1\u7b97\u6cd5\u7684\u9690\u79c1\u53c2\u6570\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6548\u679c\u53d7\u9650\u4e8e'canary'\u96c6\u7684\u8d28\u91cf\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4f18\u5316'canary'\u96c6\u6765\u63d0\u5347\u9690\u79c1\u5ba1\u8ba1\u7684\u6548\u679c\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u5143\u68af\u5ea6\u4f18\u5316\u6280\u672f\u5bf9'canary'\u96c6\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ed6\u4eec\u4e0d\u662f\u968f\u673a\u9009\u62e9'canary'\u6837\u672c\uff0c\u800c\u662f\u901a\u8fc7\u8ba1\u7b97\u54ea\u4e9b\u6837\u672c\u6700\u6709\u52a9\u4e8e\u533a\u5206\u8bad\u7ec3\u96c6\u5185\u5916\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u8fdb\u884c\u9690\u79c1\u53c2\u6570\u7684\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u4f18\u5316\u540e\u7684'canary'\u96c6\u53ef\u4ee5\u5c06\u7ecf\u9a8c\u4e0b\u9650\u63d0\u9ad8\u8d85\u8fc72\u500d\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u8868\u73b0\u51fa\u826f\u597d\u7684\u8fc1\u79fb\u6027\u548c\u9ad8\u6548\u6027\uff0c\u5373\u4f7f\u662f\u5728\u975e\u79c1\u6709SGD\u548c\u8f83\u5927\u7684\u6a21\u578b\u67b6\u6784\u4e0a\u4f18\u5316\u7684'canary'\u96c6\uff0c\u4e5f\u80fd\u6709\u6548\u5e94\u7528\u4e8eDP-SGD\u8bad\u7ec3\u7684\u66f4\u5927\u6a21\u578b\u7684\u5ba1\u8ba1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u9ed1\u76d2\u9690\u79c1\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u4e3a\u6709\u6548\u7684\u7b56\u7565\u3002\u901a\u8fc7\u4f18\u5316'canary'\u96c6\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9690\u79c1\u53c2\u6570\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u800c\u4e14\u8bc1\u660e\u4e86\u5176\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2507.14516", "pdf": "https://arxiv.org/pdf/2507.14516", "abs": "https://arxiv.org/abs/2507.14516", "authors": ["Jeyoung Lee", "Hochul Kang"], "title": "SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware\nmetric function for time series self-supervised representation learning. Most\nSelf-Supervised Learning (SSL) methods for signals commonly adopt\ndistance-based objectives such as mean squared error (MSE), which are sensitive\nto amplitude, invariant to waveform polarity, and unbounded in scale. These\nproperties hinder semantic alignment and reduce interpretability. SDSC\naddresses this by quantifying structural agreement between temporal signals\nbased on the intersection of signed amplitudes, derived from the Dice\nSimilarity Coefficient (DSC).Although SDSC is defined as a structure-aware\nmetric, it can be used as a loss by subtracting from 1 and applying a\ndifferentiable approximation of the Heaviside function for gradient-based\noptimization. A hybrid loss formulation is also proposed to combine SDSC with\nMSE, improving stability and preserving amplitude where necessary. Experiments\non forecasting and classification benchmarks demonstrate that SDSC-based\npre-training achieves comparable or improved performance over MSE, particularly\nin in-domain and low-resource scenarios. The results suggest that structural\nfidelity in signal representations enhances the semantic representation\nquality, supporting the consideration of structure-aware metrics as viable\nalternatives to conventional distance-based methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u8868\u5f81\u5b66\u4e60\u7684\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\u51fd\u6570\u2014\u2014\u4fe1\u53f7\u9ab0\u5b50\u76f8\u4f3c\u6027\u7cfb\u6570\uff08SDSC\uff09\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u9884\u6d4b\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u65b9\u6cd5\u5177\u6709\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u76ee\u6807\uff0c\u5982\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u632f\u5e45\u654f\u611f\u3001\u6ce2\u5f62\u6781\u6027\u4e0d\u53d8\u4e14\u5c3a\u5ea6\u4e0a\u65e0\u754c\uff0c\u8fd9\u963b\u788d\u4e86\u8bed\u4e49\u5bf9\u9f50\u5e76\u964d\u4f4e\u4e86\u53ef\u89e3\u91ca\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86SDSC\u3002", "method": "SDSC\u57fa\u4e8eDice Similarity Coefficient (DSC)\uff0c\u901a\u8fc7\u91cf\u5316\u7b26\u53f7\u632f\u5e45\u7684\u4ea4\u96c6\u6765\u8861\u91cf\u65f6\u95f4\u4fe1\u53f7\u4e4b\u95f4\u7684\u7ed3\u6784\u4e00\u81f4\u6027\u3002\u5b83\u53ef\u4ee5\u901a\u8fc7\u51cf\u53bb1\u5e76\u5e94\u7528Heaviside\u51fd\u6570\u7684\u53ef\u5fae\u8fd1\u4f3c\u7528\u4e8e\u68af\u5ea6\u4f18\u5316\u3002\u8fd8\u63d0\u51fa\u4e86\u5c06SDSC\u4e0eMSE\u7ed3\u5408\u7684\u6df7\u5408\u635f\u5931\u516c\u5f0f\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u5fc5\u8981\u65f6\u4fdd\u6301\u632f\u5e45\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eSDSC\u7684\u9884\u8bad\u7ec3\u5728\u9886\u57df\u5185\u548c\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4MSE\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u6216\u81f3\u5c11\u76f8\u5f53\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4fe1\u53f7\u8868\u793a\u4e2d\u4fdd\u6301\u7ed3\u6784\u4fdd\u771f\u5ea6\u53ef\u4ee5\u589e\u5f3a\u8bed\u4e49\u8868\u793a\u7684\u8d28\u91cf\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u5ea6\u91cf\u662f\u4f20\u7edf\u57fa\u4e8e\u8ddd\u79bb\u7684\u65b9\u6cd5\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u65f6\u95f4\u5e8f\u5217\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u4e2d\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u8bed\u4e49\u8868\u793a\u8d28\u91cf\u3002"}}
{"id": "2507.14468", "pdf": "https://arxiv.org/pdf/2507.14468", "abs": "https://arxiv.org/abs/2507.14468", "authors": ["Yitong Lin", "Jiaying He", "Jiahe Chen", "Xinnan Zhu", "Jianwei Zheng", "Tao Bo"], "title": "BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning", "categories": ["cs.AI"], "comment": "Accepted by Bioinformatics on July 11th", "summary": "Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery\nand disease understanding, yet their completion and reasoning are challenging.\nKnowledge Embedding (KE) methods capture global semantics but struggle with\ndynamic structural integration, while Graph Neural Networks (GNNs) excel\nlocally but often lack semantic understanding. Even ensemble approaches,\nincluding those leveraging language models, often fail to achieve a deep,\nadaptive, and synergistic co-evolution between semantic comprehension and\nstructural learning. Addressing this critical gap in fostering continuous,\nreciprocal refinement between these two aspects in complex biomedical KGs is\nparamount.\n  Results: We introduce BioGraphFusion, a novel framework for deeply\nsynergistic semantic and structural learning. BioGraphFusion establishes a\nglobal semantic foundation via tensor decomposition, guiding an LSTM-driven\nmechanism to dynamically refine relation embeddings during graph propagation.\nThis fosters adaptive interplay between semantic understanding and structural\nlearning, further enhanced by query-guided subgraph construction and a hybrid\nscoring mechanism. Experiments across three key biomedical tasks demonstrate\nBioGraphFusion's superior performance over state-of-the-art KE, GNN, and\nensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)\nhighlights its ability to unveil biologically meaningful pathways.\n  Availability and Implementation: Source code and all training data are freely\navailable for download at https://github.com/Y-TARL/BioGraphFusion.\n  Contact: zjw@zjut.edu.cn, botao666666@126.com.\n  Supplementary information: Supplementary data are available at Bioinformatics\nonline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6BioGraphFusion\uff0c\u5b83\u5728\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u4e4b\u95f4\u5efa\u7acb\u4e86\u6df1\u5ea6\u534f\u540c\u4f5c\u7528\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u80fd\u63ed\u793a\u751f\u7269\u5b66\u4e0a\u6709\u610f\u4e49\u7684\u8def\u5f84\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u5bf9\u4e8e\u836f\u7269\u53d1\u73b0\u548c\u75be\u75c5\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b83\u4eec\u7684\u5b8c\u6210\u548c\u63a8\u7406\u5b58\u5728\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u4e4b\u95f4\u7684\u6df1\u5ea6\u3001\u9002\u5e94\u6027\u548c\u534f\u540c\u5171\u8fdb\u5316\u3002", "method": "BioGraphFusion\u901a\u8fc7\u5f20\u91cf\u5206\u89e3\u5efa\u7acb\u5168\u5c40\u8bed\u4e49\u57fa\u7840\uff0c\u5229\u7528LSTM\u9a71\u52a8\u673a\u5236\u52a8\u6001\u4f18\u5316\u5173\u7cfb\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u67e5\u8be2\u5f15\u5bfc\u7684\u5b50\u56fe\u6784\u5efa\u548c\u6df7\u5408\u8bc4\u5206\u673a\u5236\u8fdb\u4e00\u6b65\u589e\u5f3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBioGraphFusion\u5728\u4e09\u4e2a\u5173\u952e\u751f\u7269\u533b\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u73b0\u6709\u7684KE\u3001GNN\u548c\u96c6\u6210\u6a21\u578b\u3002\u6848\u4f8b\u7814\u7a76\u663e\u793a\u5176\u80fd\u591f\u63ed\u793a\u751f\u7269\u5b66\u4e0a\u6709\u610f\u4e49\u7684\u8def\u5f84\u3002", "conclusion": "BioGraphFusion\u4e3a\u590d\u6742\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8bed\u4e49\u7406\u89e3\u548c\u7ed3\u6784\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14528", "pdf": "https://arxiv.org/pdf/2507.14528", "abs": "https://arxiv.org/abs/2507.14528", "authors": ["Ilias Tsoumas", "Dimitrios Bormpoudakis", "Vasileios Sitokonstantinou", "Athanasios Askitopoulos", "Andreas Kalogeras", "Charalampos Kontoes", "Ioannis Athanasiadis"], "title": "Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference", "categories": ["cs.LG"], "comment": "Accepted at KDD 2025 Workshop on Causal Inference and Machine\n  Learning in Practice", "summary": "In causal inference, whether through randomized controlled trials or\nobservational studies, access to both treated and control units is essential\nfor estimating the effect of a treatment on an outcome of interest. When\ntreatment assignment is random, the average treatment effect (ATE) can be\nestimated directly by comparing outcomes between groups. In non-randomized\nsettings, various techniques are employed to adjust for confounding and\napproximate the counterfactual scenario to recover an unbiased ATE. A common\nchallenge, especially in observational studies, is the absence of units clearly\nlabeled as controls-that is, units known not to have received the treatment. To\naddress this, we propose positive-unlabeled (PU) learning as a framework for\nidentifying, with high confidence, control units from a pool of unlabeled ones,\nusing only the available treated (positive) units. We evaluate this approach\nusing both simulated and real-world data. We construct a causal graph with\ndiverse relationships and use it to generate synthetic data under various\nscenarios, assessing how reliably the method recovers control groups that allow\nestimates of true ATE. We also apply our approach to real-world data on optimal\nsowing and fertilizer treatments in sustainable agriculture. Our findings show\nthat PU learning can successfully identify control (negative) units from\nunlabeled data based only on treated units and, through the resulting control\ngroup, estimate an ATE that closely approximates the true value. This work has\nimportant implications for observational causal inference, especially in fields\nwhere randomized experiments are difficult or costly. In domains such as earth,\nenvironmental, and agricultural sciences, it enables a plethora of\nquasi-experiments by leveraging available earth observation and climate data,\nparticularly when treated units are available but control units are lacking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6b63\u672a\u6807\u8bb0\uff08PU\uff09\u5b66\u4e60\u65b9\u6cd5\u6765\u4ece\u975e\u968f\u673a\u5316\u8bbe\u7f6e\u4e2d\u8bc6\u522b\u5bf9\u7167\u7ec4\uff0c\u4ee5\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94\uff08ATE\uff09\u3002\u8be5\u65b9\u6cd5\u5728\u519c\u4e1a\u53ef\u6301\u7eed\u6027\u7814\u7a76\u6570\u636e\u4e0a\u7684\u5e94\u7528\u8868\u660e\u5176\u80fd\u591f\u6210\u529f\u5730\u4ec5\u901a\u8fc7\u5df2\u77e5\u7684\u5904\u7406\u5355\u5143\u8bc6\u522b\u51fa\u5408\u9002\u7684\u5bf9\u7167\u5355\u5143\uff0c\u5e76\u7531\u6b64\u4f30\u7b97\u63a5\u8fd1\u771f\u5b9e\u503c\u7684ATE\u3002", "motivation": "\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u89c2\u5bdf\u6027\u7814\u7a76\u4e2d\uff0c\u83b7\u5f97\u660e\u786e\u6807\u8bb0\u4e3a\u5bf9\u7167\u7684\u5355\u5143\u901a\u5e38\u662f\u56f0\u96be\u7684\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u6cbb\u7597\u6548\u679c\u51c6\u786e\u4f30\u8ba1\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5373\u5728\u6ca1\u6709\u660e\u786e\u5bf9\u7167\u5355\u5143\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94\uff08ATE\uff09\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6b63\u672a\u6807\u8bb0\uff08PU\uff09\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u8bd5\u56fe\u4ece\u672a\u6807\u6ce8\u7684\u6570\u636e\u4e2d\u9ad8\u53ef\u4fe1\u5ea6\u5730\u8bc6\u522b\u51fa\u5bf9\u7167\u5355\u5143\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5177\u6709\u591a\u6837\u5316\u5173\u7cfb\u7684\u56e0\u679c\u56fe\u4ee5\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5e76\u5728\u4e0d\u540c\u60c5\u51b5\u4e0b\u6d4b\u8bd5\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u88ab\u5e94\u7528\u4e8e\u5b9e\u9645\u7684\u519c\u4e1a\u6570\u636e\u4e2d\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cPU\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6210\u529f\u5730\u4ece\u672a\u6807\u8bb0\u7684\u6570\u636e\u4e2d\u8bc6\u522b\u51fa\u5bf9\u7167\u5355\u5143\uff0c\u5e76\u4e14\u901a\u8fc7\u8fd9\u4e9b\u5bf9\u7167\u5355\u5143\u4f30\u7b97\u51fa\u7684ATE\u4e0e\u771f\u5b9e\u503c\u975e\u5e38\u63a5\u8fd1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5bf9\u4e8e\u89c2\u5bdf\u6027\u56e0\u679c\u63a8\u65ad\u6709\u91cd\u8981\u610f\u4e49\uff0c\u7279\u522b\u662f\u5728\u968f\u673a\u5b9e\u9a8c\u96be\u4ee5\u5b9e\u65bd\u6216\u6210\u672c\u9ad8\u6602\u7684\u9886\u57df\uff0c\u5982\u5730\u7403\u3001\u73af\u5883\u548c\u519c\u4e1a\u79d1\u5b66\u3002\u5b83\u5141\u8bb8\u5229\u7528\u73b0\u6709\u7684\u5730\u7403\u89c2\u6d4b\u548c\u6c14\u5019\u6570\u636e\u5f00\u5c55\u5927\u91cf\u51c6\u5b9e\u9a8c\uff0c\u7279\u522b\u662f\u5f53\u5b58\u5728\u5df2\u77e5\u7684\u5904\u7406\u5355\u5143\u4f46\u7f3a\u4e4f\u5bf9\u7167\u5355\u5143\u65f6\u3002"}}
{"id": "2507.14513", "pdf": "https://arxiv.org/pdf/2507.14513", "abs": "https://arxiv.org/abs/2507.14513", "authors": ["Hongyi Yang", "Yue Pan", "Jiayi Xu", "Kelsen Liu"], "title": "Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) and autonomous agents have\nenabled systems capable of performing complex tasks across domains such as\nhuman-computer interaction, planning, and web navigation. However, many\nexisting frameworks struggle in real-world or resource-constrained environments\ndue to their reliance on cloud-based computation, limited robustness in dynamic\ncontexts, and lack of persistent autonomy and environmental awareness.\n  We present Amico, a modular, event-driven framework for building autonomous\nagents optimized for embedded systems. Written in Rust for safety and\nperformance, Amico supports reactive, persistent agents that operate\nefficiently across embedded platforms and browser environments via WebAssembly.\nIt provides clean abstractions for event handling, state management, behavior\nexecution, and integration with reasoning modules. Amico delivers a unified\ninfrastructure for constructing resilient, interactive agents suitable for\ndeployment in settings with limited compute and intermittent connectivity.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Amico\uff0c\u5b83\u662f\u4e00\u4e2a\u7528Rust\u7f16\u5199\u7684\u6a21\u5757\u5316\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u81ea\u4e3b\u4ee3\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u8bb8\u591a\u6846\u67b6\u7531\u4e8e\u4f9d\u8d56\u4e91\u8ba1\u7b97\u3001\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u6709\u9650\u4ee5\u53ca\u7f3a\u4e4f\u6301\u4e45\u7684\u81ea\u4e3b\u6027\u548c\u73af\u5883\u610f\u8bc6\uff0c\u5728\u73b0\u5b9e\u4e16\u754c\u6216\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAmico\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u662f\u7528Rust\u7f16\u5199\u7684\uff0c\u5177\u6709\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u5e76\u652f\u6301\u53cd\u5e94\u5f0f\u3001\u6301\u4e45\u6027\u7684\u4ee3\u7406\uff0c\u53ef\u4ee5\u901a\u8fc7WebAssembly\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u548c\u6d4f\u89c8\u5668\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u3002", "result": "Amico\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u4ee5\u6784\u5efa\u5f39\u6027\u3001\u4ea4\u4e92\u5f0f\u7684\u4ee3\u7406\uff0c\u9002\u7528\u4e8e\u90e8\u7f72\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u8fde\u63a5\u95f4\u6b47\u6027\u7684\u73af\u5883\u4e2d\u3002", "conclusion": "Amico\u4e3a\u6784\u5efa\u9002\u5408\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u4f7f\u7528\u7684\u81ea\u4e3b\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14529", "pdf": "https://arxiv.org/pdf/2507.14529", "abs": "https://arxiv.org/abs/2507.14529", "authors": ["Berkay Anahtarci", "Can Deha Kariksiz", "Naci Saldi"], "title": "Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games", "categories": ["cs.LG", "math.OC", "91A16, 68T05, 49N45, 93E20, 46E22"], "comment": null, "summary": "We consider the maximum causal entropy inverse reinforcement learning problem\nfor infinite-horizon stationary mean-field games, in which we model the unknown\nreward function within a reproducing kernel Hilbert space. This allows the\ninference of rich and potentially nonlinear reward structures directly from\nexpert demonstrations, in contrast to most existing inverse reinforcement\nlearning approaches for mean-field games that typically restrict the reward\nfunction to a linear combination of a fixed finite set of basis functions. We\nalso focus on the infinite-horizon cost structure, whereas prior studies\nprimarily rely on finite-horizon formulations. We introduce a Lagrangian\nrelaxation to this maximum causal entropy inverse reinforcement learning\nproblem that enables us to reformulate it as an unconstrained log-likelihood\nmaximization problem, and obtain a solution \\lk{via} a gradient ascent\nalgorithm. To illustrate the theoretical consistency of the algorithm, we\nestablish the smoothness of the log-likelihood objective by proving the\nFr\\'echet differentiability of the related soft Bellman operators with respect\nto the parameters in the reproducing kernel Hilbert space. We demonstrate the\neffectiveness of our method on a mean-field traffic routing game, where it\naccurately recovers expert behavior.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u65e0\u9650\u6c34\u5e73\u9759\u6b62\u5e73\u5747\u573a\u535a\u5f08\u4e2d\uff0c\u57fa\u4e8e\u6700\u5927\u56e0\u679c\u71b5\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u5e76\u5229\u7528\u68af\u5ea6\u4e0a\u5347\u7b97\u6cd5\u6c42\u89e3\uff0c\u5e76\u8bc1\u660e\u4e86\u76f8\u5173\u8f6f\u8d1d\u5c14\u66fc\u7b97\u5b50\u7684Fr\u00e9chet\u53ef\u5fae\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u9650\u5236\u5956\u52b1\u51fd\u6570\u4e3a\u56fa\u5b9a\u6709\u9650\u57fa\u51fd\u6570\u7ebf\u6027\u7ec4\u5408\uff0c\u65e0\u6cd5\u76f4\u63a5\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u63a8\u65ad\u51fa\u4e30\u5bcc\u548c\u6f5c\u5728\u975e\u7ebf\u6027\u7684\u5956\u52b1\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u4ee5\u524d\u7684\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u4e8e\u6709\u9650\u6c34\u5e73\u7684\u516c\u5f0f\u5316\uff0c\u800c\u672c\u6587\u5173\u6ce8\u7684\u662f\u65e0\u9650\u6c34\u5e73\u7684\u6210\u672c\u7ed3\u6784\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u62c9\u683c\u6717\u65e5\u677e\u5f1b\uff0c\u5c06\u6700\u5927\u56e0\u679c\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u65e0\u7ea6\u675f\u5bf9\u6570\u4f3c\u7136\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u4e0a\u5347\u7b97\u6cd5\u83b7\u5f97\u89e3\u51b3\u65b9\u6848\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u8bc1\u660e\u4e86\u4e0e\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u53c2\u6570\u76f8\u5173\u7684\u8f6f\u8d1d\u5c14\u66fc\u7b97\u5b50\u7684Fr\u00e9chet\u53ef\u5fae\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e00\u4e2a\u5e73\u5747\u573a\u4ea4\u901a\u8def\u7531\u6e38\u620f\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u5730\u6062\u590d\u4e13\u5bb6\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u65e0\u9650\u6c34\u5e73\u9759\u6b62\u5e73\u5747\u573a\u535a\u5f08\u4e2d\u6709\u6548\u5730\u89e3\u51b3\u6700\u5927\u56e0\u679c\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u80fd\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u63a8\u65ad\u51fa\u590d\u6742\u4e14\u53ef\u80fd\u975e\u7ebf\u6027\u7684\u5956\u52b1\u7ed3\u6784\u3002"}}
{"id": "2507.14520", "pdf": "https://arxiv.org/pdf/2507.14520", "abs": "https://arxiv.org/abs/2507.14520", "authors": ["Xinyi Chen", "Yifei Yuan", "Jiaang Li", "Serge Belongie", "Maarten de Rijke", "Anders S\u00f8gaard"], "title": "What if Othello-Playing Language Models Could See?", "categories": ["cs.AI"], "comment": "ICML 2025 Assessing World Models Workshop", "summary": "Language models are often said to face a symbol grounding problem. While some\nargue that world understanding can emerge from text alone, others suggest\ngrounded learning is more efficient. We explore this through Othello, where the\nboard state defines a simplified, rule-based world. Building on prior work, we\nintroduce VISOTHELLO, a multi-modal model trained on move histories and board\nimages. Using next-move prediction, we compare it to mono-modal baselines and\ntest robustness to semantically irrelevant perturbations. We find that\nmulti-modal training improves both performance and the robustness of internal\nrepresentations. These results suggest that grounding language in visual input\nhelps models infer structured world representations.", "AI": {"tldr": "\u901a\u8fc7\u5965\u8d5b\u7f57\u6e38\u620f\u7814\u7a76\u591a\u6a21\u6001\u8bad\u7ec3\u5bf9\u8bed\u8a00\u6a21\u578b\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u89c6\u89c9\u8f93\u5165\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u6587\u672c\u4e4b\u5916\u7684\u5176\u4ed6\u4fe1\u606f\uff08\u5982\u56fe\u50cf\uff09\u66f4\u597d\u5730\u7406\u89e3\u4e16\u754c\uff0c\u4ee5\u89e3\u51b3\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u3002", "method": "\u5f15\u5165VISOTHELLO\uff0c\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5728\u5965\u8d5b\u7f57\u6e38\u620f\u4e2d\u4f7f\u7528\u8d70\u6cd5\u5386\u53f2\u548c\u68cb\u76d8\u56fe\u50cf\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u7528\u4e0b\u4e00\u6b65\u9884\u6d4b\u4efb\u52a1\u6bd4\u8f83\u5176\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u591a\u6a21\u6001\u8bad\u7ec3\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u5185\u90e8\u8868\u793a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c06\u8bed\u8a00\u4e0e\u89c6\u89c9\u8f93\u5165\u7ed3\u5408\u53ef\u4ee5\u5e2e\u52a9\u6a21\u578b\u63a8\u65ad\u51fa\u7ed3\u6784\u5316\u7684\u4e16\u754c\u8868\u793a\u3002"}}
{"id": "2507.14560", "pdf": "https://arxiv.org/pdf/2507.14560", "abs": "https://arxiv.org/abs/2507.14560", "authors": ["Giorgio Roffo"], "title": "The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers", "categories": ["cs.LG", "cs.CV", "68T07, 05C50, 15A18", "I.2.6; I.2.7; I.5.1"], "comment": "24 pages, 10 figures, submitted for review. Companion code and\n  reproducibility materials available", "summary": "The self-attention mechanism, now central to deep learning architectures such\nas Transformers, is a modern instance of a more general computational\nprinciple: learning and using pairwise affinity matrices to control how\ninformation flows through a model. This paper traces the conceptual origins of\nself-attention across multiple domains, including computer vision, natural\nlanguage processing, and graph learning, through their shared reliance on an\naffinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)\nas a foundational approach that generalizes the idea of affinity-based\nweighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS\ndefines A either through domain knowledge or by learning, and computes feature\nrelevance through multi-hop propagation over the affinity graph. From this\nperspective, self-attention can be seen as a special case of Inf-FS: it uses a\nsingle-hop affinity computation where A is dynamically built from token\nsimilarities. We argue that the underlying structure, reasoning over pairwise\nrelationships, is preserved across both approaches, and the key differences lie\nin how the affinity matrix is defined and applied. By situating self-attention\nwithin the broader paradigm of affinity-based computation, we unify several\nstrands of machine learning research and highlight a common mathematical\nfoundation that underpins diverse models and tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u591a\u4e2a\u9886\u57df\u7684\u8d77\u6e90\uff0c\u8ba4\u4e3a\u5b83\u662f\u4e00\u4e2a\u66f4\u901a\u7528\u8ba1\u7b97\u539f\u7406\u7684\u73b0\u4ee3\u5b9e\u4f8b\uff0c\u5e76\u5c06\u5176\u4e0e\u65e0\u9650\u7279\u5f81\u9009\u62e9\uff08Inf-FS\uff09\u5173\u8054\u8d77\u6765\uff0c\u5f3a\u8c03\u4e86\u57fa\u4e8e\u4eb2\u548c\u529b\u77e9\u9635\u7684\u4fe1\u606f\u6d41\u63a7\u5236\u3002", "motivation": "\u52a8\u673a\u662f\u8ffd\u6eaf\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u6982\u5ff5\u8d77\u6e90\uff0c\u901a\u8fc7\u8de8\u9886\u57df\u89c6\u89d2\u7406\u89e3\u5176\u53d1\u5c55\uff0c\u4ee5\u53ca\u5b83\u5982\u4f55\u4e0e\u65e0\u9650\u7279\u5f81\u9009\u62e9\u76f8\u8054\u7cfb\uff0c\u4ee5\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u80cc\u540e\u7684\u5171\u540c\u6570\u5b66\u57fa\u7840\u3002", "method": "\u8bba\u6587\u6bd4\u8f83\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u65e0\u9650\u7279\u5f81\u9009\u62e9\u7684\u65b9\u6cd5\uff0c\u6307\u51fa\u81ea\u6ce8\u610f\u529b\u4f7f\u7528\u5355\u8df3\u4eb2\u548c\u529b\u8ba1\u7b97\uff0c\u800cInf-FS\u5b9a\u4e49A\u6216\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u591a\u8df3\u4f20\u64ad\u8ba1\u7b97\u7279\u5f81\u76f8\u5173\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u88ab\u89c6\u4e3aInf-FS\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u4e24\u8005\u90fd\u5728\u5904\u7406\u6210\u5bf9\u5173\u7cfb\uff0c\u4f46\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u4eb2\u548c\u529b\u77e9\u9635\u7684\u5b9a\u4e49\u548c\u5e94\u7528\u65b9\u5f0f\u3002", "conclusion": "\u7ed3\u8bba\u662f\u5c06\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7f6e\u4e8e\u66f4\u5e7f\u6cdb\u7684\u57fa\u4e8e\u4eb2\u548c\u529b\u7684\u8ba1\u7b97\u8303\u5f0f\u4e2d\uff0c\u7edf\u4e00\u4e86\u51e0\u6761\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7ebf\u7d22\uff0c\u5e76\u7a81\u51fa\u4e86\u652f\u6491\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u7684\u5171\u540c\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2507.14552", "pdf": "https://arxiv.org/pdf/2507.14552", "abs": "https://arxiv.org/abs/2507.14552", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskis\u00e4rkk\u00e4", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "title": "Large Language Models Assisting Ontology Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Ontology evaluation through functional requirements, such as testing via\ncompetency question (CQ) verification, is a well-established yet costly,\nlabour-intensive, and error-prone endeavour, even for ontology engineering\nexperts. In this work, we introduce OE-Assist, a novel framework designed to\nassist ontology evaluation through automated and semi-automated CQ\nverification. By presenting and leveraging a dataset of 1,393 CQs paired with\ncorresponding ontologies and ontology stories, our contributions present, to\nour knowledge, the first systematic investigation into large language model\n(LLM)-assisted ontology evaluation, and include: (i) evaluating the\neffectiveness of a LLM-based approach for automatically performing CQ\nverification against a manually created gold standard, and (ii) developing and\nassessing an LLM-powered framework to assist CQ verification with Prot\\'eg\\'e,\nby providing suggestions. We found that automated LLM-based evaluation with\no1-preview and o3-mini perform at a similar level to the average user's\nperformance.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6OE-Assist\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u52a8\u548c\u534a\u81ea\u52a8\u7684CQ\u9a8c\u8bc1\u6765\u8f85\u52a9\u672c\u4f53\u8bc4\u4f30\uff0c\u5e76\u9996\u6b21\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u672c\u4f53\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u901a\u8fc7\u529f\u80fd\u9700\u6c42\uff08\u5982\u901a\u8fc7\u80dc\u4efb\u529b\u95ee\u9898\uff08CQ\uff09\u9a8c\u8bc1\u8fdb\u884c\u6d4b\u8bd5\uff09\u5bf9\u672c\u4f53\u8fdb\u884c\u8bc4\u4f30\u7684\u65b9\u6cd5\u867d\u7136\u5df2\u7ecf\u786e\u7acb\uff0c\u4f46\u6210\u672c\u9ad8\u3001\u52b3\u52a8\u5bc6\u96c6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u5373\u4f7f\u5bf9\u4e8e\u672c\u4f53\u5de5\u7a0b\u4e13\u5bb6\u6765\u8bf4\u4e5f\u662f\u5982\u6b64\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u5e76\u5229\u7528\u4e86\u4e00\u4e2a\u5305\u542b1,393\u4e2a\u4e0e\u76f8\u5e94\u672c\u4f53\u548c\u672c\u4f53\u6545\u4e8b\u914d\u5bf9\u7684CQ\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u5f00\u53d1\u548c\u8bc4\u4f30\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u5efa\u8bae\u6765\u534f\u52a9\u4f7f\u7528Prot\u00e9g\u00e9\u8fdb\u884cCQ\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528o1-preview\u548co3-mini\u8fdb\u884c\u7684\u81ea\u52a8\u5316LLM\u57fa\u7840\u8bc4\u4f30\u7684\u8868\u73b0\u6c34\u5e73\u4e0e\u666e\u901a\u7528\u6237\u7684\u5e73\u5747\u8868\u73b0\u6c34\u5e73\u76f8\u4f3c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672c\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u5de5\u5177\uff0c\u5373OE-Assist\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u652f\u6301\u672c\u4f53\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u3002"}}
{"id": "2507.14570", "pdf": "https://arxiv.org/pdf/2507.14570", "abs": "https://arxiv.org/abs/2507.14570", "authors": ["Xu Cheng", "Liang Yao", "Feng He", "Yukuo Cen", "Yufei He", "Chenhui Zhang", "Wenzheng Feng", "Hongyun Cai", "Jie Tang"], "title": "LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for various graph\nmining tasks, yet existing scalable solutions often struggle to balance\nexecution efficiency with prediction accuracy. These difficulties stem from\niterative message-passing techniques, which place significant computational\ndemands and require extensive GPU memory, particularly when dealing with the\nneighbor explosion issue inherent in large-scale graphs. This paper introduces\na scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,\nwhich can perform representation learning on 100 billion graphs with a single\nGPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We\nexamine existing graph partitioning methods and design a superior graph\npartition algorithm named LPMetis. In particular, LPMetis outperforms current\nstate-of-the-art (SOTA) approaches on various evaluation metrics. In addition,\nour paper proposes a subgraph augmentation strategy to enhance the model's\npredictive performance. It exhibits excellent compatibility, allowing the\nentire framework to accommodate various GNN algorithms. Successfully deployed\non the Tencent platform, LPS-GNN has been tested on public and real-world\ndatasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in\nonline applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aLPS-GNN\u7684\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u3001\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u56fe\u6316\u6398\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u6269\u5c55GNN\u89e3\u51b3\u65b9\u6848\u96be\u4ee5\u5728\u6267\u884c\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u65f6\u9047\u5230\u7684\u90bb\u5c45\u7206\u70b8\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u5206\u533a\u7b97\u6cd5LPMetis\u548c\u5b50\u56fe\u589e\u5f3a\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4f7f\u6846\u67b6\u80fd\u591f\u9002\u5e94\u5404\u79cdGNN\u7b97\u6cd5\u3002", "result": "LPS-GNN\u80fd\u591f\u5728\u5355\u4e2aGPU\u4e0a\u4e8e10\u5c0f\u65f6\u5185\u5bf9100\u4ebf\u4e2a\u56fe\u8fdb\u884c\u8868\u793a\u5b66\u4e60\uff0c\u5728\u7528\u6237\u83b7\u53d6\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4e8613.8%\u7684\u63d0\u5347\uff0c\u5e76\u5728\u817e\u8baf\u5e73\u53f0\u4e0a\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e868.24%\u523013.89%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "LPS-GNN\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u56fe\u6570\u636e\u6316\u6398\u4e2d\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u65b9\u6848\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14593", "pdf": "https://arxiv.org/pdf/2507.14593", "abs": "https://arxiv.org/abs/2507.14593", "authors": ["Omar Al-Desi"], "title": "Coordinate Heart System: A Geometric Framework for Emotion Representation", "categories": ["cs.AI", "cs.LG"], "comment": "26 pages", "summary": "This paper presents the Coordinate Heart System (CHS), a geometric framework\nfor emotion representation in artificial intelligence applications. We position\neight core emotions as coordinates on a unit circle, enabling mathematical\ncomputation of complex emotional states through coordinate mixing and vector\noperations. Our initial five-emotion model revealed significant coverage gaps\nin the emotion space, leading to the development of an eight-emotion system\nthat provides complete geometric coverage with mathematical guarantees. The\nframework converts natural language input to emotion coordinates and supports\nreal-time emotion interpolation through computational algorithms. The system\nintroduces a re-calibrated stability parameter S in [0,1], which dynamically\nintegrates emotional load, conflict resolution, and contextual drain factors.\nThis stability model leverages advanced Large Language Model interpretation of\ntextual cues and incorporates hybrid temporal tracking mechanisms to provide\nnuanced assessment of psychological well-being states. Our key contributions\ninclude: (i) mathematical proof demonstrating why five emotions are\ninsufficient for complete geometric coverage, (ii) an eight-coordinate system\nthat eliminates representational blind spots, (iii) novel algorithms for\nemotion mixing, conflict resolution, and distance calculation in emotion space,\nand (iv) a comprehensive computational framework for AI emotion recognition\nwith enhanced multi-dimensional stability modeling. Experimental validation\nthrough case studies demonstrates the system's capability to handle emotionally\nconflicted states, contextual distress factors, and complex psychological\nscenarios that traditional categorical emotion models cannot adequately\nrepresent. This work establishes a new mathematical foundation for emotion\nmodeling in artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u60c5\u611f\u8868\u793a\u51e0\u4f55\u6846\u67b6\u2014\u2014\u5750\u6807\u5fc3\u7cfb\u7edf\uff08CHS\uff09\uff0c\u5b83\u80fd\u591f\u901a\u8fc7\u6570\u5b66\u8ba1\u7b97\u8868\u793a\u590d\u6742\u7684\u60c5\u611f\u72b6\u6001\uff0c\u5e76\u5f15\u5165\u4e86\u91cd\u65b0\u6821\u51c6\u7684\u7a33\u5b9a\u6027\u53c2\u6570S\uff0c\u63d0\u4f9b\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u7ec6\u81f4\u8bc4\u4f30\u3002", "motivation": "\u4f5c\u8005\u6307\u51fa\uff0c\u65e9\u671f\u7684\u4e94\u60c5\u611f\u6a21\u578b\u5728\u60c5\u611f\u7a7a\u95f4\u8986\u76d6\u4e0a\u5b58\u5728\u663e\u8457\u7684\u4e0d\u8db3\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u4e00\u4e2a\u516b\u60c5\u611f\u7cfb\u7edf\u6765\u89e3\u51b3\u8fd9\u4e9b\u8868\u793a\u4e0a\u7684\u76f2\u70b9\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e00\u4e2a\u5355\u4f4d\u5706\u4e0a\u7684\u516b\u4e2a\u6838\u5fc3\u60c5\u611f\u4f5c\u4e3a\u5750\u6807\uff0c\u53ef\u4ee5\u8fdb\u884c\u5750\u6807\u6df7\u5408\u548c\u5411\u91cf\u64cd\u4f5c\u4ee5\u8ba1\u7b97\u590d\u6742\u60c5\u611f\u72b6\u6001\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u5305\u62ec\u5c06\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u8f6c\u6362\u4e3a\u60c5\u611f\u5750\u6807\u3001\u652f\u6301\u5b9e\u65f6\u60c5\u611f\u63d2\u503c\u7684\u8ba1\u7b97\u7b97\u6cd5\uff0c\u4ee5\u53ca\u7528\u4e8e\u60c5\u611f\u6df7\u5408\u3001\u51b2\u7a81\u89e3\u6790\u548c\u60c5\u611f\u7a7a\u95f4\u8ddd\u79bb\u8ba1\u7b97\u7684\u65b0\u9896\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u60c5\u611f\u51b2\u7a81\u72b6\u6001\u3001\u60c5\u5883\u6027\u538b\u529b\u56e0\u7d20\u548c\u590d\u6742\u7684\u5fc3\u7406\u60c5\u666f\uff0c\u800c\u4f20\u7edf\u5206\u7c7b\u60c5\u611f\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u8868\u793a\u8fd9\u4e9b\u65b9\u9762\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u60c5\u611f\u5efa\u6a21\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5305\u62ec\u8bc1\u660e\u4e94\u4e2a\u60c5\u611f\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u5b8c\u6574\u7684\u51e0\u4f55\u8986\u76d6\uff0c\u4ee5\u53ca\u63d0\u51fa\u4e86\u6d88\u9664\u8868\u793a\u76f2\u70b9\u7684\u516b\u5750\u6807\u7cfb\u7edf\u3002"}}
{"id": "2507.14592", "pdf": "https://arxiv.org/pdf/2507.14592", "abs": "https://arxiv.org/abs/2507.14592", "authors": ["Haochen Liu", "Jia Bi", "Xiaomin Wang", "Xin Yang", "Ling Wang"], "title": "A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 7 figures", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,\nlogistics, agriculture, disaster management, and military operations. Accurate\ndetection and classification of UAV flight states, such as hovering, cruising,\nascending, or transitioning, which are essential for safe and effective\noperations. However, conventional time series classification (TSC) methods\noften lack robustness and generalization for dynamic UAV environments, while\nstate of the art(SOTA) models like Transformers and LSTM based architectures\ntypically require large datasets and entail high computational costs,\nespecially with high-dimensional data streams. This paper proposes a novel\nframework that integrates a Transformer-based Generative Adversarial Network\n(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address\nthese challenges in UAV flight state classification. The Transformer encoder\ncaptures long-range temporal dependencies and complex telemetry dynamics, while\nthe GAN module augments limited datasets with realistic synthetic samples. MIL\nis incorporated to focus attention on the most discriminative input segments,\nreducing noise and computational overhead. Experimental results show that the\nproposed method achieves superior accuracy 96.5% on the DroneDetect dataset and\n98.6% on the DroneRF dataset that outperforming other SOTA approaches. The\nframework also demonstrates strong computational efficiency and robust\ngeneralization across diverse UAV platforms and flight states, highlighting its\npotential for real-time deployment in resource constrained environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer-GAN\u548cMILET\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8eUAV\u98de\u884c\u72b6\u6001\u5206\u7c7b\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u51c6\u786e\u7387\u9ad8\u3001\u8ba1\u7b97\u6548\u7387\u5f3a\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684\u65f6\u5e8f\u5206\u7c7b\u65b9\u6cd5\u5728\u52a8\u6001\u65e0\u4eba\u673a\u73af\u5883\u4e2d\u7f3a\u4e4f\u7a33\u5065\u6027\u548c\u6cdb\u5316\u6027\uff0c\u800c\u5148\u8fdb\u7684\u6a21\u578b\u5982Transformer\u548cLSTM\u9700\u8981\u5927\u91cf\u7684\u6570\u636e\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u6570\u636e\u6d41\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u8be5\u6846\u67b6\u5229\u7528Transformer\u7f16\u7801\u5668\u6355\u6349\u957f\u65f6\u95f4\u8303\u56f4\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u590d\u6742\u7684\u9065\u6d4b\u52a8\u529b\u5b66\uff0cGAN\u6a21\u5757\u751f\u6210\u903c\u771f\u7684\u5408\u6210\u6837\u672c\u4ee5\u589e\u5f3a\u6709\u9650\u7684\u6570\u636e\u96c6\uff0cMIL\u5219\u96c6\u4e2d\u6ce8\u610f\u529b\u4e8e\u6700\u5177\u8fa8\u522b\u529b\u7684\u8f93\u5165\u90e8\u5206\uff0c\u51cf\u5c11\u566a\u97f3\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728DroneDetect\u548cDroneRF\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u5230\u4e8696.5%\u548c98.6%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7a33\u5065\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u65e0\u4eba\u673a\u5e73\u53f0\u548c\u98de\u884c\u72b6\u6001\uff0c\u7a81\u51fa\u4e86\u5176\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u65f6\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14642", "pdf": "https://arxiv.org/pdf/2507.14642", "abs": "https://arxiv.org/abs/2507.14642", "authors": ["Monoshiz Mahbub Khan", "Xioayin Xi", "Andrew Meneely", "Zhe Yu"], "title": "Efficient Story Point Estimation With Comparative Learning", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Story point estimation is an essential part of agile software development.\nStory points are unitless, project-specific effort estimates that help\ndevelopers plan their sprints. Traditionally, developers estimate story points\ncollaboratively using planning poker or other manual techniques. While the\ninitial calibrating of the estimates to each project is helpful, once a team\nhas converged on a set of precedents, story point estimation can become tedious\nand labor-intensive. Machine learning can reduce this burden, but only with\nenough context from the historical decisions made by the project team. That is,\nstate-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate\npredictions (within-project) when trained on data from the same project. The\ngoal of this work is to streamline story point estimation by evaluating a\ncomparative learning-based framework for calibrating project-specific story\npoint prediction models. Instead of assigning a specific story point value to\nevery backlog item, developers are presented with pairs of items, and indicate\nwhich item requires more effort. Using these comparative judgments, a machine\nlearning model is trained to predict the story point estimates. We empirically\nevaluated our technique using data with 23,313 manual estimates in 16 projects.\nThe model learned from comparative judgments can achieve on average 0.34\nSpearman's rank correlation coefficient between its predictions and the ground\ntruth story points. This is similar to, if not better than, the performance of\na regression model learned from the ground truth story points. Therefore, the\nproposed comparative learning approach is more efficient than state-of-the-art\nregression-based approaches according to the law of comparative judgments -\nproviding comparative judgments yields a lower cognitive burden on humans than\nproviding ratings or categorical labels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6bd4\u8f83\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u9884\u6d4b\u6545\u4e8b\u70b9\u4f30\u7b97\uff0c\u4ece\u800c\u7b80\u5316\u654f\u6377\u5f00\u53d1\u4e2d\u7684\u6545\u4e8b\u70b9\u4f30\u7b97\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u56de\u5f52\u6a21\u578b\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6545\u4e8b\u70b9\u4f30\u7b97\u65b9\u6cd5\u5982\u8ba1\u5212\u6251\u514b\u7b49\u867d\u7136\u5bf9\u9879\u76ee\u7684\u521d\u59cb\u6821\u51c6\u6709\u5e2e\u52a9\uff0c\u4f46\u4e00\u65e6\u56e2\u961f\u5bf9\u5148\u4f8b\u8fbe\u6210\u4e00\u81f4\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5c31\u4f1a\u53d8\u5f97\u7e41\u7410\u548c\u52b3\u52a8\u5bc6\u96c6\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u8f7b\u8d1f\u62c5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6bd4\u8f83\u5b66\u4e60\u6846\u67b6\uff0c\u5f00\u53d1\u8005\u53ea\u9700\u8981\u5bf9\u6bd4\u4e24\u4e2a\u4efb\u52a1\u5e76\u6307\u51fa\u54ea\u4e2a\u66f4\u8d39\u529b\uff0c\u800c\u4e0d\u662f\u7ed9\u6bcf\u4e2a\u5f85\u529e\u4e8b\u9879\u5206\u914d\u5177\u4f53\u7684\u6545\u4e8b\u70b9\u503c\u3002\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u6bd4\u8f83\u5224\u65ad\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u9884\u6d4b\u6545\u4e8b\u70b9\u4f30\u7b97\u3002", "result": "\u4e0e\u771f\u5b9e\u7684\u6545\u4e8b\u70b9\u76f8\u6bd4\uff0c\u4ece\u6bd4\u8f83\u5224\u65ad\u4e2d\u5b66\u4e60\u5230\u7684\u6a21\u578b\u53ef\u4ee5\u8fbe\u5230\u5e73\u57470.34\u7684Spearman\u7b49\u7ea7\u76f8\u5173\u7cfb\u6570\uff0c\u8fd9\u4e0e\u751a\u81f3\u4f18\u4e8e\u4ece\u771f\u5b9e\u6545\u4e8b\u70b9\u4e2d\u5b66\u4e60\u5230\u7684\u56de\u5f52\u6a21\u578b\u7684\u8868\u73b0\u3002", "conclusion": "\u6839\u636e\u6bd4\u8f83\u5224\u65ad\u6cd5\u5219\uff0c\u63d0\u4f9b\u6bd4\u8f83\u5224\u65ad\u6bd4\u63d0\u4f9b\u8bc4\u5206\u6216\u5206\u7c7b\u6807\u7b7e\u7ed9\u4eba\u7c7b\u5e26\u6765\u7684\u8ba4\u77e5\u8d1f\u62c5\u66f4\u4f4e\uff0c\u6240\u4ee5\u63d0\u51fa\u7684\u6bd4\u8f83\u5b66\u4e60\u65b9\u6cd5\u5728\u6548\u7387\u4e0a\u66f4\u4f18\u3002"}}
{"id": "2507.14631", "pdf": "https://arxiv.org/pdf/2507.14631", "abs": "https://arxiv.org/abs/2507.14631", "authors": ["Daniel Greenhut", "Dan Feldman"], "title": "$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation", "categories": ["cs.LG", "cs.CG", "cs.DS"], "comment": null, "summary": "Given an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.\n  We provide the first polynomial-time deterministic algorithm whose both\nrunning time and approximation factor are not exponential in $k$. More\nprecisely, the multiplicative approximation factor is $\\sqrt{d}$, and the\nrunning time is polynomial in the size of the input. We expect that our\ntechnique would be useful for many other related problems, such as $\\ell_{2,z}$\nnorm of distances for $z\\not \\in \\br{1,2}$, e.g., $z=\\infty$, and handling\noutliers/sparsity.\n  Open code and experimental results on real-world datasets are also provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u7528\u4e8e\u8fd1\u4f3ck-\u5b50\u7a7a\u95f4\u4e2d\u4f4d\u6570\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u5747\u4e0d\u662fk\u7684\u6307\u6570\u5f62\u5f0f\u3002", "motivation": "\u7ecf\u5178\u7684k-PCA\uff08\u4e3b\u6210\u5206\u5206\u6790\uff09\u8fd1\u4f3c\u4e8e\u70b9\u96c6P\u7684k\u7ef4\u4eff\u5c04\u7ebf\u6027\u5b50\u7a7a\u95f4\uff0c\u8be5\u5b50\u7a7a\u95f4\u4f7f\u5f97P\u4e2d\u6240\u6709\u70b9\u5230\u5b83\u7684\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u5e73\u65b9\u548c\u6700\u5c0f\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u975e\u51f8\u7684k-\u5b50\u7a7a\u95f4\u4e2d\u4f4d\u6570\u95ee\u9898\uff0c\u76ee\u524d\u6ca1\u6709\u4e00\u79cd\u6709\u6548\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7684\u8fd1\u4f3c\u56e0\u5b50\u4e3a\u6839\u53f7d\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a\u8f93\u5165\u5927\u5c0f\u7684\u591a\u9879\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u5f00\u653e\u4ee3\u7801\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "result": "\u6211\u4eec\u7684\u7b97\u6cd5\u662f\u7b2c\u4e00\u4e2a\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u8fd1\u4f3c\u56e0\u5b50\u4e0a\u90fd\u4e0d\u662fk\u7684\u6307\u6570\u51fd\u6570\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u786e\u5b9a\u6027\u7b97\u6cd5\u3002\u5b83\u4e0d\u4ec5\u9002\u7528\u4e8ek-\u5b50\u7a7a\u95f4\u4e2d\u4f4d\u6570\u95ee\u9898\uff0c\u8fd8\u53ef\u4ee5\u6269\u5c55\u5230\u5176\u4ed6\u76f8\u5173\u95ee\u9898\uff0c\u5982\u5904\u7406\u79bb\u7fa4\u503c/\u7a00\u758f\u6027\u7b49\u3002", "conclusion": "\u6211\u4eec\u76f8\u4fe1\uff0c\u8fd9\u79cd\u6280\u672f\u5bf9\u8bb8\u591a\u5176\u4ed6\u76f8\u5173\u95ee\u9898\u4e5f\u5c06\u662f\u6709\u7528\u7684\uff0c\u4f8b\u5982\u5904\u7406\u4e0d\u540cz\u503c\u7684\u8ddd\u79bb\u7684\u21132,z\u8303\u6570\uff0c\u4ee5\u53ca\u5904\u7406\u79bb\u7fa4\u503c/\u7a00\u758f\u6027\u3002"}}
{"id": "2507.14660", "pdf": "https://arxiv.org/pdf/2507.14660", "abs": "https://arxiv.org/abs/2507.14660", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "categories": ["cs.AI", "cs.CL"], "comment": "Code is available at https://github.com/renqibing/RogueAgent", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u6a21\u62df\u6076\u610f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u5a01\u80c1\uff0c\u5e76\u5728\u4e24\u4e2a\u9ad8\u98ce\u9669\u9886\u57df\u8fdb\u884c\u4e86\u5e94\u7528\uff0c\u53d1\u73b0\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u6bd4\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u6613\u9020\u6210\u635f\u5bb3\u3002", "motivation": "\u9274\u4e8e\u6700\u8fd1\u7684\u5927\u89c4\u6a21\u4e8b\u4ef6\u5982\u9009\u4e3e\u6b3a\u8bc8\u548c\u91d1\u878d\u9a97\u5c40\u5c55\u793a\u4e86\u4eba\u7c7b\u7fa4\u4f53\u534f\u8c03\u52aa\u529b\u53ef\u80fd\u9020\u6210\u7684\u5371\u5bb3\uff0c\u4ee5\u53ca\u968f\u7740\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u5bf9\u4e8eAI\u9a71\u52a8\u7684\u7fa4\u4f53\u53ef\u80fd\u5bfc\u81f4\u7c7b\u4f3c\u5371\u5bb3\u7684\u62c5\u5fe7\u65e5\u76ca\u589e\u52a0\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u73b0\u5b9e\u60c5\u51b5\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u98ce\u9669\u4ecd\u7136\u88ab\u4f4e\u4f30\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\u6765\u6a21\u62df\u6076\u610fMAS\u5171\u8c0b\u7684\u98ce\u9669\uff0c\u8be5\u6846\u67b6\u652f\u6301\u4e2d\u5fc3\u5316\u548c\u53bb\u4e2d\u5fc3\u5316\u7684\u534f\u8c03\u7ed3\u6784\uff0c\u5e76\u5c06\u6b64\u6846\u67b6\u5e94\u7528\u4e8e\u4e24\u4e2a\u9ad8\u98ce\u9669\u9886\u57df\uff1a\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u548c\u7535\u5b50\u5546\u52a1\u6b3a\u8bc8\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u6bd4\u4e2d\u5fc3\u5316\u7cfb\u7edf\u66f4\u6709\u6548\u5730\u6267\u884c\u6076\u610f\u884c\u4e3a\uff0c\u5373\u4f7f\u5728\u4f20\u7edf\u5e72\u9884\u63aa\u65bd\u4e0b\uff0c\u53bb\u4e2d\u5fc3\u5316\u7684\u7fa4\u4f53\u4e5f\u80fd\u8c03\u6574\u7b56\u7565\u4ee5\u907f\u514d\u88ab\u53d1\u73b0\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5173\u4e8e\u8fd9\u4e9b\u6076\u610f\u7fa4\u4f53\u5982\u4f55\u8fd0\u4f5c\u7684\u5173\u952e\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u5bf9\u66f4\u597d\u68c0\u6d4b\u7cfb\u7edf\u548c\u5bf9\u7b56\u7684\u9700\u6c42\u3002"}}
{"id": "2507.14668", "pdf": "https://arxiv.org/pdf/2507.14668", "abs": "https://arxiv.org/abs/2507.14668", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model", "categories": ["cs.LG"], "comment": "15 pages, 14 figures", "summary": "Deep learning models have been widely adopted for False Data Injection Attack\n(FDIA) detection in smart grids due to their ability to capture unstructured\nand sparse features. However, the increasing system scale and data\ndimensionality introduce significant computational and memory burdens,\nparticularly in large-scale industrial datasets, limiting detection efficiency.\nTo address these issues, this paper proposes Rec-AD, a computationally\nefficient framework that integrates Tensor Train decomposition with the Deep\nLearning Recommendation Model (DLRM). Rec-AD enhances training and inference\nefficiency through embedding compression, optimized data access via index\nreordering, and a pipeline training mechanism that reduces memory communication\noverhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing\nFDIA detection systems without code modifications. Experimental results show\nthat Rec-AD significantly improves computational throughput and real-time\ndetection performance, narrowing the attack window and increasing attacker\ncost. These advancements strengthen edge computing capabilities and\nscalability, providing robust technical support for smart grid security.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRec-AD\u7684\u8ba1\u7b97\u9ad8\u6548\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5f20\u91cf\u5217\u8f66\u5206\u89e3\u4e0e\u6df1\u5ea6\u5b66\u4e60\u63a8\u8350\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u667a\u80fd\u7535\u7f51\u4e2d\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u7684\u6548\u7387\u548c\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5df2\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u667a\u80fd\u7535\u7f51\u4e2d\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff08FDIA\uff09\u68c0\u6d4b\uff0c\u4f46\u968f\u7740\u7cfb\u7edf\u89c4\u6a21\u548c\u6570\u636e\u7ef4\u5ea6\u7684\u589e\u52a0\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u8d1f\u62c5\u663e\u8457\u589e\u52a0\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u6570\u636e\u96c6\u4e2d\uff0c\u8fd9\u9650\u5236\u4e86\u68c0\u6d4b\u6548\u7387\u3002", "method": "Rec-AD\u901a\u8fc7\u5d4c\u5165\u538b\u7f29\u3001\u901a\u8fc7\u7d22\u5f15\u91cd\u6392\u5e8f\u4f18\u5316\u6570\u636e\u8bbf\u95ee\u4ee5\u53ca\u51cf\u5c11\u5185\u5b58\u901a\u4fe1\u5f00\u9500\u7684\u7ba1\u9053\u8bad\u7ec3\u673a\u5236\u6765\u589e\u5f3a\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u3002\u5b83\u5b8c\u5168\u517c\u5bb9PyTorch\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684FDIA\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRec-AD\u5927\u5927\u63d0\u9ad8\u4e86\u8ba1\u7b97\u541e\u5410\u91cf\u548c\u5b9e\u65f6\u68c0\u6d4b\u6027\u80fd\uff0c\u7f29\u77ed\u4e86\u653b\u51fb\u7a97\u53e3\u5e76\u589e\u52a0\u4e86\u653b\u51fb\u8005\u7684\u6210\u672c\u3002", "conclusion": "\u8fd9\u4e9b\u8fdb\u6b65\u52a0\u5f3a\u4e86\u8fb9\u7f18\u8ba1\u7b97\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u667a\u80fd\u7535\u7f51\u5b89\u5168\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2507.14705", "pdf": "https://arxiv.org/pdf/2507.14705", "abs": "https://arxiv.org/abs/2507.14705", "authors": ["Sai Wang", "Senthilnathan Subramanian", "Mudit Sahni", "Praneeth Gone", "Lingjie Meng", "Xiaochen Wang", "Nicolas Ferradas Bertoli", "Tingxian Cheng", "Jun Xu"], "title": "Configurable multi-agent framework for scalable and realistic testing of llm-based agents", "categories": ["cs.AI"], "comment": null, "summary": "Large-language-model (LLM) agents exhibit complex, context-sensitive\nbehaviour that quickly renders static benchmarks and ad-hoc manual testing\nobsolete.\n  We present Neo, a configurable, multi-agent framework that automates\nrealistic, multi-turn evaluation of LLM-based systems. Neo couples a Question\nGeneration Agent and an Evaluation Agent through a shared context-hub, allowing\ndomain prompts, scenario controls and dynamic feedback to be composed\nmodularly. Test inputs are sampled from a probabilistic state model spanning\ndialogue flow, user intent and emotional tone, enabling diverse, human-like\nconversations that adapt after every turn.\n  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)\nuncovered edge-case failures across five attack categories with a 3.3% break\nrate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered\n10-12X higher throughput, generating 180 coherent test questions in around 45\nmins versus 16h of human effort. Beyond security probing, Neo's stochastic\npolicies balanced topic coverage and conversational depth, yielding broader\nbehavioural exploration than manually crafted scripts.\n  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent\ninterfaces, state controller and feedback loops are model-agnostic and\nextensible to richer factual-grounding and policy-compliance checks. We release\nthe framework to facilitate reproducible, high-fidelity testing of emerging\nagentic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aNeo\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u3002\u901a\u8fc7\u5728\u751f\u4ea7\u7ea7Seller Financial Assistant\u804a\u5929\u673a\u5668\u4eba\u4e0a\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5e7f\u6cdb\u7684\u884c\u4e3a\u63a2\u7d22\u80fd\u529b\uff0c\u5e76\u4e3a\u53ef\u6269\u5c55\u3001\u81ea\u6211\u8fdb\u5316\u7684LLM QA\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u9759\u6001\u57fa\u51c6\u548c\u4e34\u65f6\u624b\u52a8\u6d4b\u8bd5\u5f88\u5feb\u8fc7\u65f6\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u590d\u6742\u884c\u4e3a\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u591a\u4ee3\u7406\u6846\u67b6Neo\uff0c\u5b83\u7ed3\u5408\u4e86\u95ee\u9898\u751f\u6210\u4ee3\u7406\u548c\u8bc4\u4f30\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u5171\u4eab\u4e0a\u4e0b\u6587\u4e2d\u5fc3\u8fdb\u884c\u8fde\u63a5\u3002\u6d4b\u8bd5\u8f93\u5165\u4ece\u5bf9\u8bdd\u6d41\u7a0b\u3001\u7528\u6237\u610f\u56fe\u548c\u60c5\u611f\u57fa\u8c03\u7684\u6982\u7387\u72b6\u6001\u6a21\u578b\u4e2d\u91c7\u6837\uff0c\u4ee5\u5b9e\u73b0\u9002\u5e94\u6027\u7684\u591a\u6837\u5316\u4eba\u7c7b\u5bf9\u8bdd\u3002", "result": "\u5e94\u7528\u4e8eSeller Financial Assistant\u804a\u5929\u673a\u5668\u4eba\u7684\u7ed3\u679c\u663e\u793a\uff1a(i) \u5728\u4e94\u4e2a\u653b\u51fb\u7c7b\u522b\u4e2d\u53d1\u73b0\u4e86\u8fb9\u7f18\u6848\u4f8b\u5931\u8d25\uff0c\u7834\u574f\u7387\u63a5\u8fd1\u4e13\u5bb6\u4eba\u5de5\u7ea2\u961f\u6210\u5458\u7684\u6c34\u5e73\uff1b(ii) \u4e0e\u4eba\u5de5\u76f8\u6bd4\uff0c\u4ea4\u4ed8\u4e8610-12\u500d\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3002\u6b64\u5916\uff0c\u968f\u673a\u7b56\u7565\u5e73\u8861\u4e86\u8bdd\u9898\u8986\u76d6\u8303\u56f4\u548c\u5bf9\u8bdd\u6df1\u5ea6\u3002", "conclusion": "Neo\u4e3a\u53ef\u6269\u5c55\u3001\u81ea\u6211\u8fdb\u5316\u7684LLM QA\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5176\u4ee3\u7406\u63a5\u53e3\u3001\u72b6\u6001\u63a7\u5236\u5668\u548c\u53cd\u9988\u56de\u8def\u5bf9\u6a21\u578b\u662f\u4e0d\u53ef\u77e5\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u4e30\u5bcc\u7684\u4e8b\u5b9e\u4f9d\u636e\u548c\u653f\u7b56\u5408\u89c4\u6027\u68c0\u67e5\u3002"}}
{"id": "2507.14677", "pdf": "https://arxiv.org/pdf/2507.14677", "abs": "https://arxiv.org/abs/2507.14677", "authors": ["Yiming Xu", "Zhen Peng", "Bin Shi", "Xu Hua", "Bo Dong", "Song Wang", "Chen Chen"], "title": "Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective", "categories": ["cs.LG"], "comment": "Accepted by AAAI2025", "summary": "The superiority of graph contrastive learning (GCL) has prompted its\napplication to anomaly detection tasks for more powerful risk warning systems.\nUnfortunately, existing GCL-based models tend to excessively prioritize overall\ndetection performance while neglecting robustness to structural imbalance,\nwhich can be problematic for many real-world networks following power-law\ndegree distributions. Particularly, GCL-based methods may fail to capture tail\nanomalies (abnormal nodes with low degrees). This raises concerns about the\nsecurity and robustness of current anomaly detection algorithms and therefore\nhinders their applicability in a variety of realistic high-risk scenarios. To\nthe best of our knowledge, research on the robustness of graph anomaly\ndetection to structural imbalance has received little scrutiny. To address the\nabove issues, this paper presents a novel GCL-based framework named AD-GCL. It\ndevises the neighbor pruning strategy to filter noisy edges for head nodes and\nfacilitate the detection of genuine tail nodes by aligning from head nodes to\nforged tail nodes. Moreover, AD-GCL actively explores potential neighbors to\nenlarge the receptive field of tail nodes through anomaly-guided neighbor\ncompletion. We further introduce intra- and inter-view consistency loss of the\noriginal and augmentation graph for enhanced representation. The performance\nevaluation of the whole, head, and tail nodes on multiple datasets validates\nthe comprehensive superiority of the proposed AD-GCL in detecting both head\nanomalies and tail anomalies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GCL\u6846\u67b6AD-GCL\uff0c\u901a\u8fc7\u90bb\u5c45\u4fee\u526a\u7b56\u7565\u548c\u5f02\u5e38\u5f15\u5bfc\u90bb\u5c45\u8865\u5168\u65b9\u6cd5\u6765\u589e\u5f3a\u56fe\u5f02\u5e38\u68c0\u6d4b\u5bf9\u7ed3\u6784\u4e0d\u5e73\u8861\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eGCL\u7684\u6a21\u578b\u5728\u6267\u884c\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u65f6\u8fc7\u4e8e\u6ce8\u91cd\u6574\u4f53\u68c0\u6d4b\u6027\u80fd\u800c\u5ffd\u89c6\u4e86\u5bf9\u7ed3\u6784\u4e0d\u5e73\u8861\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9075\u5faa\u5e42\u5f8b\u5ea6\u5206\u5e03\u7684\u771f\u5b9e\u4e16\u754c\u7f51\u7edc\u65f6\uff0c\u53ef\u80fd\u4f1a\u5ffd\u7565\u4f4e\u5ea6\u8282\u70b9\u7684\u5c3e\u90e8\u5f02\u5e38\u3002\u8fd9\u5f71\u54cd\u4e86\u5f53\u524d\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86AD-GCL\u6846\u67b6\uff0c\u91c7\u7528\u90bb\u5c45\u4fee\u526a\u7b56\u7565\u4ee5\u8fc7\u6ee4\u5934\u90e8\u8282\u70b9\u7684\u566a\u58f0\u8fb9\uff0c\u5e76\u901a\u8fc7\u4ece\u5934\u90e8\u8282\u70b9\u5230\u4f2a\u9020\u5c3e\u90e8\u8282\u70b9\u7684\u5bf9\u9f50\u6765\u4fc3\u8fdb\u771f\u5b9e\u5c3e\u90e8\u8282\u70b9\u7684\u68c0\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5f02\u5e38\u5f15\u5bfc\u90bb\u5c45\u8865\u5168\u7684\u65b9\u6cd5\u4e3b\u52a8\u63a2\u7d22\u6f5c\u5728\u90bb\u5c45\uff0c\u6269\u5927\u5c3e\u90e8\u8282\u70b9\u7684\u611f\u53d7\u91ce\uff0c\u5e76\u5f15\u5165\u539f\u59cb\u56fe\u548c\u589e\u5f3a\u56fe\u7684\u89c6\u5185\u548c\u89c6\u95f4\u4e00\u81f4\u6027\u635f\u5931\u4ee5\u589e\u5f3a\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684AD-GCL\u5728\u68c0\u6d4b\u5934\u90e8\u5f02\u5e38\u548c\u5c3e\u90e8\u5f02\u5e38\u65b9\u9762\u7684\u5168\u9762\u4f18\u8d8a\u6027\u3002", "conclusion": "AD-GCL\u6846\u67b6\u63d0\u9ad8\u4e86\u56fe\u5bf9\u6bd4\u5b66\u4e60\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u5bf9\u4e8e\u7ed3\u6784\u4e0a\u5b58\u5728\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14719", "pdf": "https://arxiv.org/pdf/2507.14719", "abs": "https://arxiv.org/abs/2507.14719", "authors": ["Juan Manuel Contreras"], "title": "Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix", "categories": ["cs.AI", "I.2.7; F.2.2"], "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, scalable and rigorous safety evaluation is essential.\nThis paper introduces Aymara AI, a programmatic platform for generating and\nadministering customized, policy-grounded safety evaluations. Aymara AI\ntransforms natural-language safety policies into adversarial prompts and scores\nmodel responses using an AI-based rater validated against human judgments. We\ndemonstrate its capabilities through the Aymara LLM Risk and Responsibility\nMatrix, which evaluates 20 commercially available LLMs across 10 real-world\nsafety domains. Results reveal wide performance disparities, with mean safety\nscores ranging from 86.2% to 52.4%. While models performed well in\nwell-established safety domains such as Misinformation (mean = 95.7%), they\nconsistently failed in more complex or underspecified domains, notably Privacy\n& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety\nscores differed significantly across both models and domains (p < .05). These\nfindings underscore the inconsistent and context-dependent nature of LLM safety\nand highlight the need for scalable, customizable tools like Aymara AI to\nsupport responsible AI development and oversight.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u6b3e\u540d\u4e3aAymara AI\u7684\u7a0b\u5e8f\u5316\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u7528\u4e8e\u751f\u6210\u548c\u7ba1\u7406\u57fa\u4e8e\u653f\u7b56\u7684\u5b89\u5168\u8bc4\u4f30\u3002\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u6362\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5e76\u4f7f\u7528AI\u8bc4\u5206\u5458\u5bf9\u6a21\u578b\u54cd\u5e94\u8fdb\u884c\u8bc4\u5206\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e8620\u4e2a\u5546\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u5b89\u5168\u9886\u57df\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\uff0c\u53ef\u6269\u5c55\u4e14\u4e25\u683c\u7684\u5b89\u5168\u90e8\u7f72\u8bc4\u4f30\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "Aymara AI\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u8f6c\u6362\u4e3a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5e76\u4f7f\u7528AI\u8bc4\u5206\u5458\u5bf9\u6a21\u578b\u54cd\u5e94\u8fdb\u884c\u8bc4\u5206\uff0c\u8be5\u8bc4\u5206\u5458\u7ecf\u8fc7\u4eba\u7c7b\u5224\u65ad\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u5df2\u5efa\u7acb\u7684\u5b89\u5168\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u66f4\u590d\u6742\u6216\u672a\u660e\u786e\u6307\u5b9a\u7684\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u8db3\u3002\u65b9\u5dee\u5206\u6790\u786e\u8ba4\u4e86\u4e0d\u540c\u6a21\u578b\u548c\u9886\u57df\u4e4b\u95f4\u7684\u5b89\u5168\u5206\u6570\u5b58\u5728\u663e\u7740\u5dee\u5f02\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u7684\u7279\u6027\uff0c\u5e76\u7a81\u663e\u4e86\u50cfAymara AI\u8fd9\u6837\u7684\u53ef\u6269\u5c55\u3001\u5b9a\u5236\u5316\u5de5\u5177\u5bf9\u4e8e\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u5f00\u53d1\u548c\u76d1\u7763\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14679", "pdf": "https://arxiv.org/pdf/2507.14679", "abs": "https://arxiv.org/abs/2507.14679", "authors": ["Zixin Xu", "Zhijie Wang", "Zhiyuan Pan"], "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The exponential growth of spam text on the Internet necessitates robust\ndetection mechanisms to mitigate risks such as information leakage and social\ninstability. This work addresses two principal challenges: adversarial\nstrategies employed by spammers and the scarcity of labeled data. We propose a\nnovel spam-text detection framework GCC-Spam, which integrates three core\ninnovations. First, a character similarity network captures orthographic and\nphonetic features to counter character-obfuscation attacks and furthermore\nproduces sentence embeddings for downstream classification. Second, contrastive\nlearning enhances discriminability by optimizing the latent-space distance\nbetween spam and normal texts. Third, a Generative Adversarial Network (GAN)\ngenerates realistic pseudo-spam samples to alleviate data scarcity while\nimproving model robustness and classification accuracy. Extensive experiments\non real-world datasets demonstrate that our model outperforms baseline\napproaches, achieving higher detection rates with significantly fewer labeled\nexamples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cd\u5783\u573e\u6587\u672c\u6846\u67b6GCC-Spam\uff0c\u901a\u8fc7\u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u89e3\u51b3\u4e86\u5783\u573e\u4fe1\u606f\u5236\u9020\u8005\u7684\u5bf9\u6297\u7b56\u7565\u548c\u6807\u8bb0\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7531\u4e8e\u4e92\u8054\u7f51\u4e0a\u7684\u5783\u573e\u6587\u672c\u5448\u6307\u6570\u589e\u957f\uff0c\u9700\u8981\u5f3a\u5927\u7684\u68c0\u6d4b\u673a\u5236\u6765\u5e94\u5bf9\u6b64\u7c7b\u95ee\u9898\u5e26\u6765\u7684\u98ce\u9669\uff0c\u5982\u4fe1\u606f\u6cc4\u9732\u548c\u793e\u4f1a\u4e0d\u7a33\u5b9a\u3002\u540c\u65f6\uff0c\u73b0\u6709\u7684\u6311\u6218\u5305\u62ec\u5783\u573e\u4fe1\u606f\u53d1\u5e03\u8005\u4f7f\u7528\u7684\u5bf9\u6297\u7b56\u7565\u548c\u6807\u6ce8\u6570\u636e\u7684\u7f3a\u4e4f\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\u70b9\uff1a1) \u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u7528\u4e8e\u6355\u6349\u6b63\u5b57\u6cd5\u548c\u8bed\u97f3\u7279\u5f81\u4ee5\u5e94\u5bf9\u5b57\u7b26\u6df7\u6dc6\u653b\u51fb\u5e76\u751f\u6210\u53e5\u5b50\u5d4c\u5165\uff1b2) \u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u4f18\u5316\u5783\u573e\u548c\u6b63\u5e38\u6587\u672c\u4e4b\u95f4\u7684\u6f5c\u5728\u7a7a\u95f4\u8ddd\u79bb\u6765\u63d0\u9ad8\u533a\u5206\u5ea6\uff1b3) \u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u751f\u6210\u903c\u771f\u7684\u4f2a\u5783\u573e\u6837\u672c\uff0c\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4f7f\u7528\u663e\u8457\u66f4\u5c11\u7684\u6807\u8bb0\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\u3002", "conclusion": " GCC-Spam\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5bf9\u6297\u5783\u573e\u6587\u672c\u53d1\u5e03\u8005\u7684\u7b56\u7565\u548c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5783\u573e\u6587\u672c\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14730", "pdf": "https://arxiv.org/pdf/2507.14730", "abs": "https://arxiv.org/abs/2507.14730", "authors": ["Yanjie Fu"], "title": "Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI", "categories": ["cs.AI"], "comment": "4 pages; will continue to update to add more figures to describe the\n  vision;", "summary": "Generative AI, large language models, and agentic AI have emerged separately\nof urban planning. However, the convergence between AI and urban planning\npresents an interesting opportunity towards AI urban planners. This paper\nconceptualizes urban planning as a generative AI task, where AI synthesizes\nland-use configurations under geospatial, social, and human-centric\nconstraints. We survey how generative AI approaches, including VAEs, GANs,\ntransformers, and diffusion models, reshape urban design. We further identify\ncritical gaps: 1) limited research on integrating urban theory guidance, 2)\nlimited research of AI urban planning over multiple spatial resolutions or\nangularities, 3) limited research on augmenting urban design knowledge from\ndata, and 4) limited research on addressing real-world interactions. To address\nthese limitations, we outline future research directions in theory-guided\ngeneration, digital twins, and human-machine co-design, calling for a new\nsynthesis of generative intelligence and participatory urbanism.", "AI": {"tldr": "\u672c\u6587\u5c06\u57ce\u5e02\u89c4\u5212\u6982\u5ff5\u5316\u4e3a\u751f\u6210\u5f0fAI\u4efb\u52a1\uff0c\u63a2\u8ba8\u4e86\u591a\u79cd\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5982\u4f55\u91cd\u5851\u57ce\u5e02\u8bbe\u8ba1\uff0c\u5e76\u6307\u51fa\u4e86\u76ee\u524d\u7814\u7a76\u7684\u56db\u4e2a\u5173\u952e\u7f3a\u53e3\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7406\u578bAI\u7684\u53d1\u5c55\uff0c\u5b83\u4eec\u4e0e\u57ce\u5e02\u89c4\u5212\u7684\u878d\u5408\u5e26\u6765\u4e86\u65b0\u7684\u673a\u4f1a\u3002\u4f5c\u8005\u8bd5\u56fe\u901a\u8fc7AI\u5408\u6210\u7b26\u5408\u5730\u7406\u7a7a\u95f4\u3001\u793e\u4f1a\u548c\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684\u7ea6\u675f\u6761\u4ef6\u7684\u571f\u5730\u4f7f\u7528\u914d\u7f6e\u6765\u63a2\u7d22\u8fd9\u79cd\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u8c03\u67e5\u4e86VAEs\u3001GANs\u3001transformers\u548c\u6269\u6563\u6a21\u578b\u7b49\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5728\u57ce\u5e02\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5982\u4f55\u91cd\u5851\u57ce\u5e02\u8bbe\u8ba1\u3002", "result": "\u786e\u5b9a\u4e86\u56db\u4e2a\u7814\u7a76\u4e0d\u8db3\u4e4b\u5904\uff1a1) \u7f3a\u4e4f\u5c06\u57ce\u5e02\u7406\u8bba\u6307\u5bfc\u878d\u5165AI\u7684\u6574\u5408\u7814\u7a76\uff1b2) \u5728\u591a\u5206\u8fa8\u7387\u6216\u89c6\u89d2\u4e0b\u8fdb\u884cAI\u57ce\u5e02\u89c4\u5212\u7684\u7814\u7a76\u6709\u9650\uff1b3) \u4ece\u6570\u636e\u4e2d\u589e\u5f3a\u57ce\u5e02\u8bbe\u8ba1\u77e5\u8bc6\u7684\u7814\u7a76\u8f83\u5c11\uff1b4) \u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e92\u52a8\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "conclusion": "\u4e3a\u4e86\u514b\u670d\u4e0a\u8ff0\u9650\u5236\uff0c\u6587\u7ae0\u52fe\u52d2\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u7406\u8bba\u5f15\u5bfc\u7684\u751f\u6210\u3001\u6570\u5b57\u5b6a\u751f\u548c\u4eba\u673a\u5171\u540c\u8bbe\u8ba1\uff0c\u547c\u5401\u5bf9\u751f\u6210\u667a\u80fd\u548c\u53c2\u4e0e\u6027\u57ce\u5e02\u4e3b\u4e49\u8fdb\u884c\u65b0\u7684\u7efc\u5408\u3002"}}
{"id": "2507.14698", "pdf": "https://arxiv.org/pdf/2507.14698", "abs": "https://arxiv.org/abs/2507.14698", "authors": ["Xuetao Lin", "Tianhao Peng", "Peihong Dai", "Yu Liang", "Wenjun Wu"], "title": "Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition", "categories": ["cs.LG", "cs.AI", "cs.HC", "eess.SP"], "comment": null, "summary": "EEG-based emotion recognition plays an important role in developing adaptive\nbrain-computer communication systems, yet faces two fundamental challenges in\npractical implementations: (1) effective integration of non-stationary\nspatial-temporal neural patterns, (2) robust adaptation to dynamic emotional\nintensity variations in real-world scenarios. This paper proposes SST-CL, a\nnovel framework integrating spatial-temporal transformers with curriculum\nlearning. Our method introduces two core components: a spatial encoder that\nmodels inter-channel relationships and a temporal encoder that captures\nmulti-scale dependencies through windowed attention mechanisms, enabling\nsimultaneous extraction of spatial correlations and temporal dynamics from EEG\nsignals. Complementing this architecture, an intensity-aware curriculum\nlearning strategy progressively guides training from high-intensity to\nlow-intensity emotional states through dynamic sample scheduling based on a\ndual difficulty assessment. Comprehensive experiments on three benchmark\ndatasets demonstrate state-of-the-art performance across various emotional\nintensity levels, with ablation studies confirming the necessity of both\narchitectural components and the curriculum learning mechanism.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6SST-CL\uff0c\u7ed3\u5408\u7a7a\u95f4-\u65f6\u95f4\u53d8\u538b\u5668\u4e0e\u8bfe\u7a0b\u5b66\u4e60\uff0c\u4ee5\u5e94\u5bf9EEG\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "EEG\u60c5\u611f\u8bc6\u522b\u5728\u53d1\u5c55\u9002\u5e94\u6027\u8111\u673a\u901a\u4fe1\u7cfb\u7edf\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6709\u6548\u6574\u5408\u975e\u5e73\u7a33\u7684\u7a7a\u95f4-\u65f6\u95f4\u795e\u7ecf\u6a21\u5f0f\u548c\u9002\u5e94\u52a8\u6001\u60c5\u611f\u5f3a\u5ea6\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u4e86SST-CL\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u7a7a\u95f4\u7f16\u7801\u5668\u548c\u4e00\u4e2a\u65f6\u95f4\u7f16\u7801\u5668\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5f3a\u5ea6\u611f\u77e5\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002\u7a7a\u95f4\u7f16\u7801\u5668\u5efa\u6a21\u901a\u9053\u95f4\u5173\u7cfb\uff0c\u65f6\u95f4\u7f16\u7801\u5668\u901a\u8fc7\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u591a\u5c3a\u5ea6\u4f9d\u8d56\uff0c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u5219\u6839\u636e\u53cc\u91cd\u96be\u5ea6\u8bc4\u4f30\u8fdb\u884c\u52a8\u6001\u6837\u672c\u8c03\u5ea6\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u60c5\u611f\u5f3a\u5ea6\u6c34\u5e73\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u6d88\u878d\u7814\u7a76\u4e5f\u8bc1\u5b9e\u4e86\u67b6\u6784\u7ec4\u4ef6\u548c\u8bfe\u7a0b\u5b66\u4e60\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "SST-CL\u6846\u67b6\u80fd\u6709\u6548\u5730\u89e3\u51b3EEG\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u4e24\u5927\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\u3002"}}
{"id": "2507.14897", "pdf": "https://arxiv.org/pdf/2507.14897", "abs": "https://arxiv.org/abs/2507.14897", "authors": ["Renxi Wang", "Rifo Ahmad Genadi", "Bilal El Bouardi", "Yongxin Wang", "Fajri Koto", "Zhengzhong Liu", "Timothy Baldwin", "Haonan Li"], "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents", "categories": ["cs.AI", "I.2.5"], "comment": null, "summary": "Language model (LM) agents have gained significant attention for their\nability to autonomously complete tasks through interactions with environments,\ntools, and APIs. LM agents are primarily built with prompt engineering or\nsupervised finetuning. At the same time, reinforcement learning (RL) has been\nexplored to enhance LM's capabilities, such as reasoning and factuality.\nHowever, the combination of the LM agents and reinforcement learning (Agent-RL)\nremains underexplored and lacks systematic study. To this end, we built\nAgentFly, a scalable and extensible Agent-RL framework designed to empower LM\nagents with a variety of RL algorithms. Our framework supports multi-turn\ninteractions by adapting traditional RL methods with token-level masking. It\nfeatures a decorator-based interface for defining tools and reward functions,\nenabling seamless extension and ease of use. To support high-throughput\ntraining, we implement asynchronous execution of tool calls and reward\ncomputations, and design a centralized resource management system for scalable\nenvironment coordination. We also provide a suite of prebuilt tools and\nenvironments, demonstrating the framework's effectiveness through successful\nagent training across multiple tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6AgentFly\uff0c\u5b83\u7ed3\u5408\u4e86\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u65e8\u5728\u589e\u5f3aLM\u4ee3\u7406\u7684\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e3b\u8981\u4f9d\u8d56\u4e8e\u63d0\u793a\u5de5\u7a0b\u6216\u76d1\u7763\u5fae\u8c03\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u7684\u5e94\u7528\u5c1a\u4e0d\u5145\u5206\uff0c\u4e24\u8005\u7684\u7ed3\u5408\u4e5f\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aAgentFly\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u652f\u6301\u591a\u8f6e\u6b21\u4ea4\u4e92\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u88c5\u9970\u5668\u7684\u63a5\u53e3\u5b9a\u4e49\u5de5\u5177\u548c\u5956\u52b1\u51fd\u6570\uff0c\u5141\u8bb8\u65e0\u7f1d\u6269\u5c55\u548c\u6613\u7528\u6027\u3002\u4e3a\u4e86\u652f\u6301\u9ad8\u541e\u5410\u91cf\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u5de5\u5177\u8c03\u7528\u548c\u5956\u52b1\u8ba1\u7b97\u7684\u5f02\u6b65\u6267\u884c\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u96c6\u4e2d\u5f0f\u7684\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u4ee5\u534f\u8c03\u73af\u5883\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u4efb\u52a1\u7684\u6210\u529f\u4ee3\u7406\u57f9\u8bad\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "AgentFly\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u6269\u5c55\u7684Agent-RL\u6846\u67b6\uff0c\u65e8\u5728\u8d4b\u4e88LM\u4ee3\u7406\u5404\u79cdRL\u7b97\u6cd5\u3002"}}
{"id": "2507.14706", "pdf": "https://arxiv.org/pdf/2507.14706", "abs": "https://arxiv.org/abs/2507.14706", "authors": ["Claudio Giusti", "Luca Guarnera", "Mirko Casu", "Sebastiano Battiato"], "title": "Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 14 figures", "summary": "Detecting fraudulent credit card transactions remains a significant\nchallenge, due to the extreme class imbalance in real-world data and the often\nsubtle patterns that separate fraud from legitimate activity. Existing research\ncommonly attempts to address this by generating synthetic samples for the\nminority class using approaches such as GANs, VAEs, or hybrid generative\nmodels. However, these techniques, particularly when applied only to\nminority-class data, tend to result in overconfident classifiers and poor\nlatent cluster separation, ultimately limiting real-world detection\nperformance. In this study, we propose the Causal Prototype Attention\nClassifier (CPAC), an interpretable architecture that promotes class-aware\nclustering and improved latent space structure through prototype-based\nattention mechanisms and we will couple it with the encoder in a VAE-GAN\nallowing it to offer a better cluster separation moving beyond post-hoc sample\naugmentation. We compared CPAC-augmented models to traditional oversamplers,\nsuch as SMOTE, as well as to state-of-the-art generative models, both with and\nwithout CPAC-based latent classifiers. Our results show that classifier-guided\nlatent shaping with CPAC delivers superior performance, achieving an F1-score\nof 93.14\\% percent and recall of 90.18\\%, along with improved latent cluster\nseparation. Further ablation studies and visualizations provide deeper insight\ninto the benefits and limitations of classifier-driven representation learning\nfor fraud detection. The codebase for this work will be available at final\nsubmission.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u5668CPAC\uff0c\u7528\u4e8e\u6539\u8fdb\u4fe1\u7528\u5361\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u7684\u7c7b\u522b\u611f\u77e5\u805a\u7c7b\u548c\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cCPAC\u5f15\u5bfc\u7684\u6f5c\u5728\u6210\u5f62\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5408\u6210\u6837\u672c\u7684\u65b9\u6cd5\u5728\u5904\u7406\u6781\u5ea6\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u65f6\uff0c\u5bfc\u81f4\u5206\u7c7b\u5668\u8fc7\u4e8e\u81ea\u4fe1\u548c\u8f83\u5dee\u7684\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u3002", "method": "\u63d0\u51fa\u4e86\u56e0\u679c\u539f\u578b\u6ce8\u610f\u529b\u5206\u7c7b\u5668\uff08CPAC\uff09\uff0c\u5b83\u901a\u8fc7\u57fa\u4e8e\u539f\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u4fc3\u8fdb\u7c7b\u522b\u611f\u77e5\u805a\u7c7b\u548c\u6539\u8fdb\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u4e0eVAE-GAN\u7f16\u7801\u5668\u7ed3\u5408\u4f7f\u7528\u3002", "result": "CPAC\u589e\u5f3a\u6a21\u578b\u5b9e\u73b0\u4e8693.14%\u7684F1\u5206\u6570\u548c90.18%\u7684\u53ec\u56de\u7387\uff0c\u4ee5\u53ca\u66f4\u597d\u7684\u6f5c\u5728\u805a\u7c7b\u5206\u79bb\u3002", "conclusion": "CPAC\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\u6765\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5176\u5e26\u6765\u7684\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u6539\u5584\u6709\u52a9\u4e8e\u63d0\u5347\u6b3a\u8bc8\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14899", "pdf": "https://arxiv.org/pdf/2507.14899", "abs": "https://arxiv.org/abs/2507.14899", "authors": ["Jiale Liu", "Huan Wang", "Yue Zhang", "Xiaoyu Luo", "Jiaxiang Hu", "Zhiliang Liu", "Min Xie"], "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for\nindustrial quality assurance, yet existing deep-learning-based approaches often\nlack interactivity, interpretability, and the capacity for critical\nself-assessment, limiting their reliability and operator trust. To address\nthese shortcomings, this paper proposes InsightX Agent, a novel LMM-based\nagentic framework designed to deliver reliable, interpretable, and interactive\nX-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent\npositions a Large Multimodal Model (LMM) as a central orchestrator,\ncoordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the\nEvidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect\nregion proposals for multi-scale feature maps and sparsifies them through\nNon-Maximum Suppression (NMS), optimizing detection of small, dense targets in\nX-ray images while maintaining computational efficiency. The EGR tool guides\nthe LMM agent through a chain-of-thought-inspired review process, incorporating\ncontext assessment, individual defect analysis, false positive elimination,\nconfidence recalibration and quality assurance to validate and refine the\nSDMSD's initial proposals. By strategically employing and intelligently using\ntools, InsightX Agent moves beyond passive data processing to active reasoning,\nenhancing diagnostic reliability and providing interpretations that integrate\ndiverse information sources. Experimental evaluations on the GDXray+ dataset\ndemonstrate that InsightX Agent not only achieves a high object detection\nF1-score of 96.35% but also offers significantly improved interpretability and\ntrustworthiness in its analyses, highlighting the transformative potential of\nagentic LLM frameworks for industrial inspection tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eLMM\u7684\u6846\u67b6InsightX Agent\uff0c\u7528\u4e8e\u53ef\u9760\u7684\u3001\u53ef\u89e3\u91ca\u7684\u548c\u4ea4\u4e92\u5f0f\u7684X\u5c04\u7ebf\u65e0\u635f\u68c0\u6d4b\u5206\u6790\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e8696.35%\u7684\u76ee\u6807\u68c0\u6d4bF1\u5206\u6570\uff0c\u8fd8\u5927\u5927\u63d0\u9ad8\u4e86\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u5de5\u4e1a\u8d28\u91cf\u4fdd\u8bc1\u4e2d\u8fdb\u884c\u65e0\u635f\u68c0\u6d4b\u65f6\uff0c\u901a\u5e38\u7f3a\u4e4f\u4e92\u52a8\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u6211\u8bc4\u4f30\u7684\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u53ef\u9760\u6027\u548c\u64cd\u4f5c\u5458\u7684\u4fe1\u4efb\u3002", "method": "InsightX Agent\u4ee5\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u4f5c\u4e3a\u6838\u5fc3\u534f\u8c03\u8005\uff0c\u7ed3\u5408\u7a00\u758f\u53d8\u5f62\u591a\u5c3a\u5ea6\u68c0\u6d4b\u5668\uff08SDMSD\uff09\u548c\u8bc1\u636e\u57fa\u7840\u53cd\u601d\u5de5\u5177\uff08EGR\uff09\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u4f18\u5316\u8fc7\u7a0b\uff0c\u5305\u62ec\u76ee\u6807\u533a\u57df\u63d0\u8bae\u751f\u6210\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u3001\u4e0a\u4e0b\u6587\u8bc4\u4f30\u3001\u7f3a\u9677\u5206\u6790\u7b49\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684X\u5c04\u7ebf\u56fe\u50cf\u5c0f\u5bc6\u96c6\u76ee\u6807\u68c0\u6d4b\uff0c\u5e76\u63d0\u9ad8\u8bca\u65ad\u7684\u53ef\u9760\u6027\u3002", "result": "\u5728GDXray+\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cInsightX Agent\u5b9e\u73b0\u4e8696.35%\u7684\u5bf9\u8c61\u68c0\u6d4bF1\u5206\u6570\uff0c\u5e76\u4e14\u5728\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u6709\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "InsightX Agent\u901a\u8fc7\u8d85\u8d8a\u88ab\u52a8\u7684\u6570\u636e\u5904\u7406\uff0c\u8f6c\u5411\u4e3b\u52a8\u63a8\u7406\uff0c\u589e\u5f3a\u4e86\u8bca\u65ad\u7684\u53ef\u9760\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6574\u5408\u591a\u79cd\u4fe1\u606f\u6765\u6e90\u7684\u89e3\u91ca\uff0c\u5c55\u793a\u4e86\u4ee3\u7406\u578bLLM\u6846\u67b6\u5bf9\u5de5\u4e1a\u68c0\u6d4b\u4efb\u52a1\u7684\u53d8\u9769\u6f5c\u529b\u3002"}}
{"id": "2507.14715", "pdf": "https://arxiv.org/pdf/2507.14715", "abs": "https://arxiv.org/abs/2507.14715", "authors": ["Rachid Karami", "Rajeev Patwari", "Hyoukjun Kwon", "Ashish Sirasao"], "title": "Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems", "categories": ["cs.LG"], "comment": null, "summary": "The integration of generative AI models, particularly large language models\n(LLMs), into real-time multi-model AI applications such as video conferencing\nand gaming is giving rise to a new class of workloads: real-time generative AI\n(RTGen). These workloads combine the compute intensity and dynamic execution\npatterns of generative models with the stringent latency and concurrency\nconstraints of real-time inference. To meet the diverse demands of RTGen\nworkloads, modern edge platforms increasingly adopt heterogeneous\nsystem-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite\nthe potential of heterogeneous SoC, the scheduling space complexity and\nperformance implications of RTGen workloads on such platforms remain\nunderexplored. In this work, we perform a comprehensive characterization of\nRTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct\nrealistic multi-model scenarios inspired by industry use cases and profile\nmodel performance across all available backends. Using this data, we evaluate\nfive scheduling policies and their impact on both real-time metrics (e.g.,\ndeadline violation rate) and LLM performance (e.g., time-to-first-token and\ntokens-per-second). Our results show that scheduling decisions significantly\naffect workload performance (e.g., leading to a 41.7% difference in deadline\nviolation rates on average), and highlight the need for scheduling strategies\nthat are aware of workload dynamics and hardware heterogeneity. Our findings\nunderscore the importance of workload-aware, dynamic heterogeneous scheduling\nin enabling high-performance, on-device RTGen applications.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5b9e\u65f6\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\uff08RTGen\uff09\u5728\u5f02\u6784SoC\u5e73\u53f0\u4e0a\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u8bc4\u6d4b\u4e94\u79cd\u8c03\u5ea6\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u548c\u786c\u4ef6\u5f02\u6784\u6027\u611f\u77e5\u7684\u52a8\u6001\u8c03\u5ea6\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u6574\u5408\u5230\u5b9e\u65f6\u591a\u6a21\u6001AI\u5e94\u7528\u4e2d\uff0c\u51fa\u73b0\u4e86\u5b9e\u65f6\u751f\u6210\u5f0fAI\u8fd9\u4e00\u65b0\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7c7b\u522b\uff0c\u8fd9\u7c7b\u8d1f\u8f7d\u5bf9\u8ba1\u7b97\u5f3a\u5ea6\u3001\u5ef6\u8fdf\u548c\u5e76\u53d1\u6027\u6709\u4e25\u683c\u8981\u6c42\uff0c\u76ee\u524d\u5bf9\u4e8e\u5176\u5728\u5f02\u6784SoC\u5e73\u53f0\u4e0a\u7684\u8c03\u5ea6\u590d\u6742\u6027\u548c\u6027\u80fd\u5f71\u54cd\u7684\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u4f5c\u8005\u5728AMD\u6700\u65b0\u7684\u5f02\u6784SoC Ryzen AI\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u5206\u6790\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u884c\u4e1a\u7528\u4f8b\u7684\u591a\u6a21\u578b\u573a\u666f\uff0c\u5e76\u8de8\u6240\u6709\u53ef\u7528\u540e\u7aef\u5206\u6790\u6a21\u578b\u6027\u80fd\u3002\u7136\u540e\u8bc4\u4f30\u4e86\u4e94\u79cd\u8c03\u5ea6\u7b56\u7565\u5bf9\u5b9e\u65f6\u6307\u6807\u548cLLM\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u540c\u7684\u8c03\u5ea6\u51b3\u7b56\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f8b\u5982\u5e73\u5747\u5bfc\u81f441.7%\u7684\u622a\u6b62\u65f6\u95f4\u8fdd\u89c4\u7387\u5dee\u5f02\u3002\u8fd9\u8868\u660e\u9700\u8981\u91c7\u7528\u80fd\u591f\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u53d8\u5316\u548c\u786c\u4ef6\u5f02\u6784\u6027\u7684\u8c03\u5ea6\u7b56\u7565\u3002", "conclusion": "\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u8bbe\u5907\u7aefRTGen\u5e94\u7528\uff0c\u5fc5\u987b\u91cd\u89c6\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u548c\u52a8\u6001\u5f02\u6784\u8c03\u5ea6\u7b56\u7565\u7684\u5e94\u7528\u3002"}}
{"id": "2507.14906", "pdf": "https://arxiv.org/pdf/2507.14906", "abs": "https://arxiv.org/abs/2507.14906", "authors": ["Xiao Yang", "Juxi Leitner", "Michael Burke"], "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "The ability of Large Language Models (LLMs) to extract context from natural\nlanguage problem descriptions naturally raises questions about their\nsuitability in autonomous decision-making settings. This paper studies the\nbehaviour of these models within a Markov Decision Process (MDPs). While\ntraditional reinforcement learning (RL) strategies commonly employed in this\nsetting rely on iterative exploration, LLMs, pre-trained on diverse datasets,\noffer the capability to leverage prior knowledge for faster adaptation. We\ninvestigate online structured prompting strategies in sequential decision\nmaking tasks, comparing the zero-shot performance of LLM-based approaches to\nthat of classical RL methods. Our findings reveal that although LLMs\ndemonstrate improved initial performance in simpler environments, they struggle\nwith planning and reasoning in complex scenarios without fine-tuning or\nadditional guidance. Our results show that feedback mechanisms, intended to\nimprove decision-making, often introduce confusion, leading to diminished\nperformance in intricate environments. These insights underscore the need for\nfurther exploration into hybrid strategies, fine-tuning, and advanced memory\nintegration to enhance LLM-based decision-making capabilities.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u5c3d\u7ba1LLM\u5728\u7b80\u5355\u73af\u5883\u4e2d\u521d\u59cb\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\u9700\u8981\u5fae\u8c03\u6216\u989d\u5916\u6307\u5bfc\u3002\u53cd\u9988\u673a\u5236\u6709\u65f6\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u8868\u660e\u9700\u8981\u63a2\u7d22\u6df7\u5408\u7b56\u7565\u3001\u5fae\u8c03\u548c\u9ad8\u7ea7\u8bb0\u5fc6\u6574\u5408\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u9002\u5408\u7528\u4e8e\u81ea\u4e3b\u51b3\u7b56\u73af\u5883\uff0c\u7279\u522b\u662f\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u5229\u7528\u5176\u4ece\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5728\u7ebf\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\u7814\u7a76\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\uff0c\u6bd4\u8f83LLM\u65b9\u6cd5\u4e0e\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "result": "LLM\u5728\u7b80\u5355\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u521d\u59cb\u6027\u80fd\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e2d\u9047\u5230\u89c4\u5212\u548c\u63a8\u7406\u7684\u95ee\u9898\u3002\u53cd\u9988\u673a\u5236\u65e8\u5728\u6539\u8fdb\u51b3\u7b56\uff0c\u4f46\u901a\u5e38\u4f1a\u5728\u590d\u6742\u73af\u5883\u4e2d\u5f15\u5165\u6df7\u6dc6\u5e76\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u6df7\u5408\u7b56\u7565\u3001\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\u4ee5\u53ca\u9ad8\u7ea7\u8bb0\u5fc6\u6574\u5408\uff0c\u4ee5\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2507.14722", "pdf": "https://arxiv.org/pdf/2507.14722", "abs": "https://arxiv.org/abs/2507.14722", "authors": ["Mat\u011bj Kripner", "Michal \u0160ustr", "Milan Straka"], "title": "LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Automated theorem proving (ATP) has been a classical problem in artificial\nintelligence since its inception, yet it remains challenging due to its vast\nstate and action space. Large language models (LLMs) have recently emerged as a\npromising heuristic for ATP, but they lack correctness guarantees and thus\nrequire interaction with a proof verifier. Such interactions typically follow\none of two approaches: black-box interaction, which does not utilize\nintermediate proof states, or white-box approaches, which allow for incremental\nproof construction and examination of intermediate states. While black-box\napproaches have directly benefited from recent LLM advances, white-box methods\nhave comparatively lagged behind. In this paper, we address this gap by\nintroducing LeanTree, which consists of (i) a tool built in the Lean 4 language\nthat factorizes complex proof states into simpler, independent branches, and\n(ii) a dataset of these factorized intermediate states. Our white-box tooling\noffers several advantages over black-box approaches: it simplifies evaluation,\nreduces necessary context, generates richer training data, enables parallel\nsearch across multiple states, supports efficient reuse of states, and provides\nfeedback in case of errors. Our preliminary results hint that white-box\napproaches outperform black-box alternatives in some settings.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aLeanTree\u7684\u65b0\u5de5\u5177\u548c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6539\u8fdb\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u767d\u76d2\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff08ATP\uff09\u4e2d\u5c55\u73b0\u51fa\u4e86\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u9700\u8981\u4e0e\u8bc1\u660e\u9a8c\u8bc1\u5668\u4ea4\u4e92\u4ee5\u786e\u4fdd\u6b63\u786e\u6027\u3002\u76ee\u524d\u7684\u4ea4\u4e92\u65b9\u5f0f\u6709\u4e24\u79cd\uff1a\u9ed1\u76d2\u4ea4\u4e92\u548c\u767d\u76d2\u65b9\u6cd5\u3002\u867d\u7136\u9ed1\u76d2\u65b9\u6cd5\u53d7\u76ca\u4e8eLLM\u7684\u8fdb\u5c55\uff0c\u4f46\u767d\u76d2\u65b9\u6cd5\u7684\u53d1\u5c55\u76f8\u5bf9\u6ede\u540e\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86LeanTree\uff0c\u4e00\u4e2a\u7528Lean 4\u7f16\u5199\u7684\u5de5\u5177\uff0c\u5b83\u53ef\u4ee5\u5c06\u590d\u6742\u7684\u8bc1\u660e\u72b6\u6001\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u72ec\u7acb\u5206\u652f\uff0c\u5e76\u751f\u6210\u8fd9\u4e9b\u5206\u89e3\u7684\u4e2d\u95f4\u72b6\u6001\u7684\u6570\u636e\u96c6\u3002\u8fd9\u79cd\u767d\u76d2\u5de5\u5177\u63d0\u4f9b\u4e86\u7b80\u5316\u8bc4\u4f30\u3001\u51cf\u5c11\u6240\u9700\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u8bad\u7ec3\u6570\u636e\u7b49\u4f18\u70b9\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u767d\u76d2\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u9ed1\u76d2\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165LeanTree\u5de5\u5177\u548c\u6570\u636e\u96c6\uff0c\u672c\u6587\u7f29\u5c0f\u4e86\u767d\u76d2\u65b9\u6cd5\u4e0e\u9ed1\u76d2\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5c55\u793a\u4e86\u767d\u76d2\u65b9\u6cd5\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14909", "pdf": "https://arxiv.org/pdf/2507.14909", "abs": "https://arxiv.org/abs/2507.14909", "authors": ["Elio Grande"], "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "The Endless Tuning is a design method for a reliable deployment of artificial\nintelligence based on a double mirroring process, which pursues both the goals\nof avoiding human replacement and filling the so-called responsibility gap\n(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the\nrelational approach urged therein, it was then actualized in a protocol,\nimplemented in three prototypical applications regarding decision-making\nprocesses (respectively: loan granting, pneumonia diagnosis, and art style\nrecognition) and tested with such as many domain experts. Step by step\nillustrating the protocol, giving insights concretely showing a different voice\n(Gilligan 1993) in the ethics of artificial intelligence, a philosophical\naccount of technical choices (e.g., a reversed and hermeneutic deployment of\nXAI algorithms) will be provided in the present study together with the results\nof the experiments, focusing on user experience rather than statistical\naccuracy. Even thoroughly employing deep learning models, full control was\nperceived by the interviewees in the decision-making setting, while it appeared\nthat a bridge can be built between accountability and liability in case of\ndamage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\u7684\u4eba\u5de5\u667a\u80fd\u8bbe\u8ba1\u65b9\u6cd5\u2014\u2014\u65e0\u5c3d\u8c03\u4f18\uff0c\u65e8\u5728\u907f\u514d\u4eba\u7c7b\u66ff\u4ee3\u548c\u586b\u8865\u8d23\u4efb\u7f3a\u53e3\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u539f\u578b\u5e94\u7528\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u7528\u6237\u4f53\u9a8c\u800c\u975e\u7edf\u8ba1\u51c6\u786e\u6027\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u907f\u514d\u4eba\u5de5\u667a\u80fd\u5bfc\u81f4\u7684\u4eba\u7c7b\u66ff\u4ee3\u5e76\u89e3\u51b3\u6240\u8c13\u7684\u8d23\u4efb\u7f3a\u53e3\u95ee\u9898\uff0c\u786e\u4fdd\u4eba\u5de5\u667a\u80fd\u7684\u53ef\u9760\u90e8\u7f72\u3002", "method": "\u4f7f\u7528\u4e00\u79cd\u79f0\u4e3a\u201c\u65e0\u5c3d\u8c03\u4f18\u201d\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53cc\u91cd\u955c\u50cf\u8fc7\u7a0b\uff0c\u901a\u8fc7\u53cd\u8f6c\u548c\u89e3\u91ca\u5b66\u90e8\u7f72XAI\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4e00\u79cd\u534f\u8bae\u3002\u6b64\u534f\u8bae\u5728\u8d37\u6b3e\u5ba1\u6279\u3001\u80ba\u708e\u8bca\u65ad\u548c\u827a\u672f\u98ce\u683c\u8bc6\u522b\u4e09\u4e2a\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u4e86\u539f\u578b\u5e94\u7528\u6d4b\u8bd5\u3002", "result": "\u5c3d\u7ba1\u4f7f\u7528\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u6237\u5728\u51b3\u7b56\u73af\u5883\u4e2d\u4ecd\u611f\u5230\u62e5\u6709\u5b8c\u5168\u63a7\u5236\u6743\uff0c\u4e14\u4f3c\u4e4e\u53ef\u4ee5\u5728\u635f\u5bb3\u53d1\u751f\u65f6\u5efa\u7acb\u8d23\u4efb\u4e0e\u53ef\u95ee\u8d23\u6027\u4e4b\u95f4\u7684\u6865\u6881\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u54f2\u5b66\u548c\u6280\u672f\u9009\u62e9\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u4f26\u7406\u4e2d\u4e0d\u540c\u58f0\u97f3\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002"}}
{"id": "2507.14725", "pdf": "https://arxiv.org/pdf/2507.14725", "abs": "https://arxiv.org/abs/2507.14725", "authors": ["Anushka Tiwari", "Sayantan Pal", "Rohini K. Srihari", "Kaiyi Ji"], "title": "Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prompt-based continual learning (CL) offers a parameter-efficient way to\nadapt large language models (LLMs) across task sequences. However, most\nexisting methods assume task-aware inference and maintain a growing list of\ntask-specific prompts, which limits scalability and hides latent forgetting. In\nthis work, we introduce GRID, a unified framework that addresses two key\nlimitations: (1) latent forgetting under task-agnostic inference, and (2)\nprompt memory explosion as task sequences grow. GRID integrates a task-aware\ndecoding mechanism that improves backward transfer by leveraging representative\ninputs, automatic task identification, and constrained decoding. Additionally,\nwe propose a gradient-based prompt selection strategy that compresses less\ninformative prompts into a single aggregated representation, enabling scalable\nand memory-efficient lifelong learning. Extensive experiments across\nshort-sequence, long-sequence, and negative transfer benchmarks show that GRID\nsignificantly improves backward transfer, achieves competitive forward\ntransfer, and reduces forgotten tasks by up to 80\\%, outperforming\nstate-of-the-art methods on T5 and Flan-T5 backbones.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGRID\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u53cd\u5411\u4f20\u8f93\u548c\u68af\u5ea6\u57fa\u7840\u7684\u63d0\u793a\u9009\u62e9\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u8fde\u7eed\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u9057\u5fd8\u548c\u63d0\u793a\u8bb0\u5fc6\u7206\u70b8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eT5\u548cFlan-T5\u6a21\u578b\u7684\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u4efb\u52a1\u611f\u77e5\u63a8\u7406\uff0c\u5e76\u7ef4\u62a4\u4e00\u4e2a\u4e0d\u65ad\u589e\u957f\u7684\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u5217\u8868\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u5e76\u9690\u85cf\u4e86\u6f5c\u5728\u7684\u9057\u5fd8\u3002", "method": "GRID\u96c6\u6210\u4e86\u4e00\u4e2a\u4efb\u52a1\u611f\u77e5\u89e3\u7801\u673a\u5236\uff0c\u5229\u7528\u4ee3\u8868\u6027\u8f93\u5165\u3001\u81ea\u52a8\u4efb\u52a1\u8bc6\u522b\u548c\u7ea6\u675f\u89e3\u7801\u6765\u6539\u5584\u53cd\u5411\u4f20\u8f93\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u68af\u5ea6\u7684\u63d0\u793a\u9009\u62e9\u7b56\u7565\uff0c\u5c06\u4e0d\u592a\u91cd\u8981\u7684\u63d0\u793a\u538b\u7f29\u6210\u5355\u4e00\u7684\u805a\u5408\u8868\u793a\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGRID\u663e\u8457\u6539\u5584\u4e86\u53cd\u5411\u4f20\u8f93\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u524d\u5411\u4f20\u8f93\uff0c\u5e76\u51cf\u5c11\u4e86\u591a\u8fbe80%\u7684\u88ab\u9057\u5fd8\u4efb\u52a1\uff0c\u5728T5\u548cFlan-T5\u4e3b\u5e72\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "GRID\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u9057\u5fd8\u548c\u63d0\u793a\u8bb0\u5fc6\u7206\u70b8\u95ee\u9898\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u7ec8\u8eab\u5b66\u4e60\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.14912", "pdf": "https://arxiv.org/pdf/2507.14912", "abs": "https://arxiv.org/abs/2507.14912", "authors": ["Ruhul Amin Khalil", "Kashif Ahmad", "Hazrat Ali"], "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities", "categories": ["cs.AI"], "comment": null, "summary": "The global ageing population necessitates new and emerging strategies for\ncaring for older adults. In this article, we explore the potential for\ntransformation in elderly care through Agentic Artificial Intelligence (AI),\npowered by Large Language Models (LLMs). We discuss the proactive and\nautonomous decision-making facilitated by Agentic AI in elderly care.\nPersonalized tracking of health, cognitive care, and environmental management,\nall aimed at enhancing independence and high-level living for older adults,\nrepresents important areas of application. With a potential for significant\ntransformation of elderly care, Agentic AI also raises profound concerns about\ndata privacy and security, decision independence, and access. We share key\ninsights to emphasize the need for ethical safeguards, privacy protections, and\ntransparent decision-making. Our goal in this article is to provide a balanced\ndiscussion of both the potential and the challenges associated with Agentic AI,\nand to provide insights into its responsible use in elderly care, to bring\nAgentic AI into harmony with the requirements and vulnerabilities specific to\nthe elderly. Finally, we identify the priorities for the academic research\ncommunities, to achieve human-centered advancements and integration of Agentic\nAI in elderly care. To the best of our knowledge, this is no existing study\nthat reviews the role of Agentic AI in elderly care. Hence, we address the\nliterature gap by analyzing the unique capabilities, applications, and\nlimitations of LLM-based Agentic AI in elderly care. We also provide a\ncompanion interactive dashboard at https://hazratali.github.io/agenticai/.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4e3b\u52a8\u578b\u4eba\u5de5\u667a\u80fd\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u6f5c\u529b\uff0c\u5f3a\u8c03\u4e2a\u6027\u5316\u5065\u5eb7\u8ffd\u8e2a\u3001\u8ba4\u77e5\u62a4\u7406\u548c\u73af\u5883\u7ba1\u7406\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u6570\u636e\u9690\u79c1\u3001\u51b3\u7b56\u72ec\u7acb\u6027\u548c\u8bbf\u95ee\u6743\u9650\u7b49\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u9700\u8981\u4e3a\u8001\u5e74\u4eba\u53e3\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\u8fd9\u79cd\u6280\u672f\u3002", "motivation": "\u5168\u7403\u8001\u9f84\u5316\u4eba\u53e3\u5bf9\u8001\u5e74\u62a4\u7406\u63d0\u51fa\u4e86\u65b0\u7684\u9700\u6c42\uff0c\u800c\u5f53\u524d\u7f3a\u4e4f\u5173\u4e8e\u4e3b\u52a8\u578bAI\u5728\u8fd9\u4e00\u9886\u57df\u5e94\u7528\u7684\u7814\u7a76\u3002", "method": "\u6587\u7ae0\u5206\u6790\u4e86\u4e3b\u52a8\u578bAI\u7684\u72ec\u7279\u80fd\u529b\u3001\u5e94\u7528\u573a\u666f\u53ca\u9650\u5236\uff0c\u7279\u522b\u662f\u5b83\u5982\u4f55\u4fc3\u8fdb\u8001\u5e74\u62a4\u7406\u7684\u4e2a\u6027\u5316\u5065\u5eb7\u8ffd\u8e2a\u3001\u8ba4\u77e5\u62a4\u7406\u548c\u73af\u5883\u7ba1\u7406\u3002", "result": "\u6587\u7ae0\u63ed\u793a\u4e86\u4e3b\u52a8\u578bAI\u6709\u6f5c\u529b\u663e\u8457\u6539\u53d8\u8001\u5e74\u62a4\u7406\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u6570\u636e\u9690\u79c1\u3001\u51b3\u7b56\u72ec\u7acb\u6027\u548c\u8bbf\u95ee\u6743\u9650\u7b49\u6df1\u523b\u5173\u6ce8\u7684\u95ee\u9898\u3002", "conclusion": "\u4f5c\u8005\u547c\u5401\u5b66\u672f\u754c\u91cd\u89c6\u4e3b\u52a8\u578bAI\u5728\u8001\u5e74\u62a4\u7406\u4e2d\u7684\u4eba\u6027\u5316\u53d1\u5c55\u4e0e\u878d\u5408\uff0c\u786e\u4fdd\u5176\u4e0e\u8001\u5e74\u4eba\u7684\u9700\u6c42\u548c\u8106\u5f31\u6027\u76f8\u534f\u8c03\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u4ee5\u8f85\u52a9\u7406\u89e3\u3002"}}
{"id": "2507.14736", "pdf": "https://arxiv.org/pdf/2507.14736", "abs": "https://arxiv.org/abs/2507.14736", "authors": ["Rafa\u0142 Surdej", "Micha\u0142 Bortkiewicz", "Alex Lewandowski", "Mateusz Ostaszewski", "Clare Lyle"], "title": "Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning", "categories": ["cs.LG"], "comment": "Accepted for oral presentation at CoLLAs 2025", "summary": "Trainable activation functions, whose parameters are optimized alongside\nnetwork weights, offer increased expressivity compared to fixed activation\nfunctions. Specifically, trainable activation functions defined as ratios of\npolynomials (rational functions) have been proposed to enhance plasticity in\nreinforcement learning. However, their impact on training stability remains\nunclear. In this work, we study trainable rational activations in both\nreinforcement and continual learning settings. We find that while their\nflexibility enhances adaptability, it can also introduce instability, leading\nto overestimation in RL and feature collapse in longer continual learning\nscenarios. Our main result is demonstrating a trade-off between expressivity\nand plasticity in rational activations. To address this, we propose a\nconstrained variant that structurally limits excessive output scaling while\npreserving adaptability. Experiments across MetaWorld and DeepMind Control\nSuite (DMC) environments show that our approach improves training stability and\nperformance. In continual learning benchmarks, including MNIST with reshuffled\nlabels and Split CIFAR-100, we reveal how different constraints affect the\nbalance between expressivity and long-term retention. While preliminary\nexperiments in discrete action domains (e.g., Atari) did not show similar\ninstability, this suggests that the trade-off is particularly relevant for\ncontinuous control. Together, our findings provide actionable design principles\nfor robust and adaptable trainable activations in dynamic, non-stationary\nenvironments. Code available at:\nhttps://github.com/special114/rl_rational_plasticity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u7075\u6d3b\u6027\u867d\u7136\u63d0\u9ad8\u4e86\u9002\u5e94\u6027\u4f46\u4e5f\u53ef\u80fd\u5f15\u5165\u4e0d\u7a33\u5b9a\u6027\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u7ea6\u675f\u7684\u53d8\u4f53\u4ee5\u9650\u5236\u8fc7\u5ea6\u8f93\u51fa\u7f29\u653e\uff0c\u540c\u65f6\u4fdd\u7559\u9002\u5e94\u80fd\u529b\uff0c\u4ece\u800c\u6539\u5584\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\u76f8\u8f83\u4e8e\u56fa\u5b9a\u7684\u6fc0\u6d3b\u51fd\u6570\u80fd\u63d0\u4f9b\u66f4\u9ad8\u7684\u8868\u8fbe\u529b\uff0c\u7279\u522b\u662f\u5b9a\u4e49\u4e3a\u591a\u9879\u5f0f\u6bd4\u7387\u7684\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\uff08\u6709\u7406\u51fd\u6570\uff09\u5df2\u88ab\u63d0\u8bae\u7528\u4e8e\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u5851\u6027\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6fc0\u6d3b\u51fd\u6570\u5bf9\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u672c\u7814\u7a76\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u6d4b\u8bd5\u4e86\u53ef\u8bad\u7ec3\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u3002\u9488\u5bf9\u53d1\u73b0\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u7ea6\u675f\u7684\u53d8\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u6027\u5730\u9650\u5236\u8fc7\u91cf\u8f93\u51fa\u7f29\u653e\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53d7\u7ea6\u675f\u53d8\u4f53\u53ef\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u5728MetaWorld\u548cDeepMind Control Suite\u73af\u5883\u4ee5\u53ca\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u83b7\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002\u6b64\u5916\uff0c\u5728\u79bb\u6563\u52a8\u4f5c\u57df\u4e2d\u672a\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u8fd9\u8868\u660e\u8be5\u6743\u8861\u5bf9\u4e8e\u8fde\u7eed\u63a7\u5236\u5c24\u5176\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6709\u7406\u6fc0\u6d3b\u51fd\u6570\u5b58\u5728\u8868\u8fbe\u529b\u548c\u53ef\u5851\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6211\u4eec\u7684\u53d1\u73b0\u4e3a\u5728\u52a8\u6001\u3001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8bbe\u8ba1\u7a33\u5065\u4e14\u53ef\u9002\u5e94\u7684\u53ef\u8bad\u7ec3\u6fc0\u6d3b\u51fd\u6570\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.14962", "pdf": "https://arxiv.org/pdf/2507.14962", "abs": "https://arxiv.org/abs/2507.14962", "authors": ["Johannes Schmidt", "Mohamed Maizia", "Victor Lagerkvist", "Johannes K. Fichte"], "title": "Complexity of Faceted Explanations in Propositional Abduction", "categories": ["cs.AI", "cs.CC", "cs.LO"], "comment": "This is the author's self-archived copy including detailed proofs. To\n  appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the\n  41st International Conference on Logic Programming (ICLP 2025)", "summary": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post's framework.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u547d\u9898\u6eaf\u56e0\u4e2d\u7684\u51b3\u7b56\u548c\u8ba1\u6570\u63a8\u7406\u95ee\u9898\uff0c\u5f15\u5165\u4e86'\u9762\u76f8'\u8fd9\u4e00\u6982\u5ff5\u6765\u7406\u89e3\u89e3\u91ca\u7684\u5f02\u8d28\u6027\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u8bbe\u5b9a\u4e0b\u7684\u9762\u76f8\u3002", "motivation": "\u975e\u5355\u8c03\u903b\u8f91\u8303\u5f0f\u4e2d\u7684\u6eaf\u56e0\u63a8\u7406\u5728\u4eba\u5de5\u667a\u80fd\u3001\u6570\u636e\u5e93\u66f4\u65b0\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u5c24\u5176\u5728\u8ba1\u6570\u548c\u679a\u4e3e\u95ee\u9898\u4e0a\u66f4\u5177\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63a2\u7d22\u80fd\u5728\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u66f4\u597d\u89e3\u91ca\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86'\u9762\u76f8'\uff08facets\uff09\u7684\u6982\u5ff5\uff0c\u5373\u51fa\u73b0\u5728\u67d0\u4e9b\u89e3\u91ca\u4e2d\u4f46\u5e76\u975e\u6240\u6709\u89e3\u91ca\u4e2d\u7684\u6587\u5b57\uff0c\u5e76\u8003\u8651\u4e86\u4e24\u4e2a\u89e3\u91ca\u4e4b\u95f4\u7684\u8ddd\u79bb\u4ee5\u7406\u89e3\u5f02\u8d28\u6027/\u540c\u8d28\u6027\u3002", "result": "\u901a\u8fc7\u5bf9Post\u6846\u67b6\u5185\u5404\u79cd\u8bbe\u5b9a\u4e0b\u547d\u9898\u6eaf\u56e0\u7684\u5168\u9762\u5206\u6790\uff0c\u5f97\u5230\u4e86\u8fd1\u4e4e\u5b8c\u6574\u7684\u9762\u76f8\u7279\u5f81\u63cf\u8ff0\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u9762\u76f8\u5e76\u7814\u7a76\u5176\u6027\u8d28\uff0c\u80fd\u591f\u66f4\u7ec6\u81f4\u5730\u7406\u89e3\u89e3\u91ca\u7684\u53d8\u5f02\u6027\uff0c\u4e3a\u547d\u9898\u6eaf\u56e0\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.14740", "pdf": "https://arxiv.org/pdf/2507.14740", "abs": "https://arxiv.org/abs/2507.14740", "authors": ["Andrew Wang", "Elisa Nguyen", "Runshi Yang", "Juhan Bae", "Sheila A. McIlraith", "Roger Grosse"], "title": "Better Training Data Attribution via Better Inverse Hessian-Vector Products", "categories": ["cs.LG", "stat.ML"], "comment": "28 pages, 4 figures", "summary": "Training data attribution (TDA) provides insights into which training data is\nresponsible for a learned model behavior. Gradient-based TDA methods such as\ninfluence functions and unrolled differentiation both involve a computation\nthat resembles an inverse Hessian-vector product (iHVP), which is difficult to\napproximate efficiently. We introduce an algorithm (ASTRA) which uses the\nEKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP\napproximation for TDA. ASTRA is easy to tune, requires fewer iterations than\nNeumann series iterations, and is more accurate than EKFAC-based\napproximations. Using ASTRA, we show that improving the accuracy of the iHVP\napproximation can significantly improve TDA performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aASTRA\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u6570\u636e\u5f52\u56e0\uff08TDA\uff09\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7EKFAC\u9884\u8c03\u8282\u5668\u5bf9\u7ebd\u66fc\u7ea7\u6570\u8fed\u4ee3\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u9006\u6d77\u68ee\u77e9\u9635-\u5411\u91cf\u79ef\uff08iHVP\uff09\u8fd1\u4f3c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u9ad8iHVP\u8fd1\u4f3c\u7684\u51c6\u786e\u6027\u53ef\u4ee5\u663e\u8457\u63d0\u5347TDA\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u7684TDA\u65b9\u6cd5\u5982\u5f71\u54cd\u51fd\u6570\u548c\u5c55\u5f00\u5fae\u5206\u90fd\u6d89\u53ca\u5230\u96be\u4ee5\u9ad8\u6548\u8fd1\u4f3c\u7684\u9006\u6d77\u68ee\u77e9\u9635-\u5411\u91cf\u79ef\uff08iHVP\uff09\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86ASTRA\u7b97\u6cd5\uff0c\u4f7f\u7528EKFAC\u9884\u8c03\u8282\u5668\u5bf9\u7ebd\u66fc\u7ea7\u6570\u8fed\u4ee3\u8fdb\u884c\u6539\u8fdb\uff0c\u4ece\u800c\u5f97\u5230\u66f4\u51c6\u786e\u7684iHVP\u8fd1\u4f3c\u3002", "result": "ASTRA\u6613\u4e8e\u8c03\u6574\uff0c\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u5c11\u4e8e\u7ebd\u66fc\u7ea7\u6570\u8fed\u4ee3\uff0c\u5e76\u4e14\u6bd4\u57fa\u4e8eEKFAC\u7684\u8fd1\u4f3c\u66f4\u51c6\u786e\u3002\u8fd9\u663e\u8457\u63d0\u9ad8\u4e86TDA\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u9ad8iHVP\u8fd1\u4f3c\u7684\u51c6\u786e\u6027\u80fd\u591f\u663e\u8457\u6539\u5584TDA\u7684\u6027\u80fd\uff0cASTRA\u4e3a\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14744", "pdf": "https://arxiv.org/pdf/2507.14744", "abs": "https://arxiv.org/abs/2507.14744", "authors": ["Mustafa Cavus", "Jan N. van Rijn", "Przemys\u0142aw Biecek"], "title": "Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML", "categories": ["cs.LG"], "comment": "Accepted at 28th International Conference on Discovery Science 2025", "summary": "Automated machine learning systems efficiently streamline model selection but\noften focus on a single best-performing model, overlooking explanation\nuncertainty, an essential concern in human centered explainable AI. To address\nthis, we propose a novel framework that incorporates model multiplicity into\nexplanation generation by aggregating partial dependence profiles (PDP) from a\nset of near optimal models, known as the Rashomon set. The resulting Rashomon\nPDP captures interpretive variability and highlights areas of disagreement,\nproviding users with a richer, uncertainty aware view of feature effects. To\nevaluate its usefulness, we introduce two quantitative metrics, the coverage\nrate and the mean width of confidence intervals, to evaluate the consistency\nbetween the standard PDP and the proposed Rashomon PDP. Experiments on 35\nregression datasets from the OpenML CTR23 benchmark suite show that in most\ncases, the Rashomon PDP covers less than 70% of the best model's PDP,\nunderscoring the limitations of single model explanations. Our findings suggest\nthat Rashomon PDP improves the reliability and trustworthiness of model\ninterpretations by adding additional information that would otherwise be\nneglected. This is particularly useful in high stakes domains where\ntransparency and confidence are critical.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u8fd1\u4f3c\u6700\u4f18\u6a21\u578b\u7684\u5c40\u90e8\u4f9d\u8d56\u914d\u7f6e\u6587\u4ef6\u6765\u751f\u6210\u89e3\u91ca\uff0c\u4ece\u800c\u5c06\u6a21\u578b\u591a\u6837\u6027\u7eb3\u5165\u89e3\u91ca\u751f\u6210\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u80fd\u63d0\u9ad8\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u901a\u5e38\u4e13\u6ce8\u4e8e\u5355\u4e00\u6700\u4f73\u6027\u80fd\u6a21\u578b\uff0c\u800c\u5ffd\u7565\u4e86\u5bf9\u4eba\u7c7b\u4e2d\u5fc3\u7684\u53ef\u89e3\u91caAI\u81f3\u5173\u91cd\u8981\u7684\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u4e00\u7ec4\u63a5\u8fd1\u6700\u4f18\u7684\u6a21\u578b\uff08Rashomon\u96c6\u5408\uff09\u4e2d\u805a\u5408\u90e8\u5206\u4f9d\u8d56\u914d\u7f6e\u6587\u4ef6\uff08PDP\uff09\uff0c\u5c06\u6a21\u578b\u591a\u91cd\u6027\u5f15\u5165\u89e3\u91ca\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0cRashomon PDP\u8986\u76d6\u4e0d\u5230\u6700\u4f73\u6a21\u578bPDP\u768470%\uff0c\u8fd9\u7a81\u663e\u4e86\u5355\u4e2a\u6a21\u578b\u89e3\u91ca\u7684\u5c40\u9650\u6027\u3002", "conclusion": "Rashomon PDP\u901a\u8fc7\u6dfb\u52a0\u5176\u4ed6\u4f1a\u88ab\u5ffd\u7565\u7684\u4fe1\u606f\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u8fd9\u5bf9\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\u5c24\u5176\u6709\u7528\u3002"}}
{"id": "2507.15013", "pdf": "https://arxiv.org/pdf/2507.15013", "abs": "https://arxiv.org/abs/2507.15013", "authors": ["Xiaoyu Li", "Jin Wu", "Shaoyang Guo", "Haoran Shi", "Chanjin Zheng"], "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing", "categories": ["cs.AI"], "comment": "15pages, 7 figures", "summary": "In the smart era, psychometric tests are becoming increasingly important for\npersonnel selection, career development, and mental health assessment.\nForced-choice tests are common in personality assessments because they require\nparticipants to select from closely related options, lowering the risk of\nresponse distortion. This study presents a deep learning-based Forced-Choice\nNeural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of\ntraditional models and is applicable to the three most common item block types\nfound in forced-choice tests. To account for the unidimensionality of items in\nforced-choice tests, we create interpretable participant and item parameters.\nWe model the interactions between participant and item features using\nmultilayer neural networks after mining them using nonlinear mapping. In\naddition, we use the monotonicity assumption to improve the interpretability of\nthe diagnostic results. The FCNCD's effectiveness is validated by experiments\non real-world and simulated datasets that show its accuracy, interpretability,\nand robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f3a\u8feb\u9009\u62e9\u795e\u7ecf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\uff08FCNCD\uff09\uff0c\u8be5\u6a21\u578b\u514b\u670d\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u9002\u7528\u4e8e\u5f3a\u8feb\u9009\u62e9\u6d4b\u8bd5\u4e2d\u6700\u5e38\u89c1\u7684\u4e09\u79cd\u9879\u76ee\u5757\u7c7b\u578b\u3002\u901a\u8fc7\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0c\u5229\u7528\u5355\u8c03\u6027\u5047\u8bbe\u63d0\u9ad8\u8bca\u65ad\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86FCNCD\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u667a\u80fd\u65f6\u4ee3\uff0c\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u5bf9\u4e8e\u4eba\u5458\u9009\u62d4\u3001\u804c\u4e1a\u53d1\u5c55\u548c\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u5f3a\u8feb\u9009\u62e9\u6d4b\u8bd5\u56e0\u5176\u80fd\u964d\u4f4e\u56de\u7b54\u5931\u771f\u7684\u98ce\u9669\u800c\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e2a\u6027\u8bc4\u4f30\u4e2d\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u5f3a\u8feb\u9009\u62e9\u6d4b\u8bd5\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u6211\u4eec\u521b\u5efa\u4e86\u53ef\u89e3\u91ca\u7684\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u53c2\u6570\u4ee5\u8003\u8651\u5f3a\u8feb\u9009\u62e9\u6d4b\u8bd5\u9879\u76ee\u7684\u5355\u4e00\u7ef4\u5ea6\u6027\u3002\u4f7f\u7528\u975e\u7ebf\u6027\u6620\u5c04\u6316\u6398\u53c2\u4e0e\u8005\u548c\u9879\u76ee\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5bf9\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u8fdb\u884c\u5efa\u6a21\u3002\u6b64\u5916\uff0c\u6211\u4eec\u91c7\u7528\u5355\u8c03\u6027\u5047\u8bbe\u6765\u63d0\u9ad8\u8bca\u65ad\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cFCNCD\u5728\u73b0\u5b9e\u4e16\u754c\u548c\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u5747\u663e\u793a\u51fa\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684FCNCD\u6a21\u578b\u4e3a\u5f3a\u8feb\u9009\u62e9\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.14746", "pdf": "https://arxiv.org/pdf/2507.14746", "abs": "https://arxiv.org/abs/2507.14746", "authors": ["Bach Do", "Nafeezat A. Ajenifuja", "Taiwo A. Adebiyi", "Ruda Zhang"], "title": "Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization", "categories": ["cs.LG", "math.OC", "stat.AP", "stat.ML"], "comment": null, "summary": "High-fidelity simulations and physical experiments are essential for\nengineering analysis and design. However, their high cost often limits their\napplications in two critical tasks: global sensitivity analysis (GSA) and\noptimization. This limitation motivates the common use of Gaussian processes\n(GPs) as proxy regression models to provide uncertainty-aware predictions based\non a limited number of high-quality observations. GPs naturally enable\nefficient sampling strategies that support informed decision-making under\nuncertainty by extracting information from a subset of possible functions for\nthe model of interest. Despite their popularity in machine learning and\nstatistics communities, sampling from GPs has received little attention in the\ncommunity of engineering optimization. In this paper, we present the\nformulation and detailed implementation of two notable sampling methods --\nrandom Fourier features and pathwise conditioning -- for generating posterior\nsamples from GPs. Alternative approaches are briefly described. Importantly, we\ndetail how the generated samples can be applied in GSA, single-objective\noptimization, and multi-objective optimization. We show successful applications\nof these sampling methods through a series of numerical examples.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e24\u79cd\u4ece\u9ad8\u65af\u8fc7\u7a0b\u4e2d\u751f\u6210\u540e\u9a8c\u6837\u672c\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u9ad8\u4fdd\u771f\u6a21\u62df\u548c\u7269\u7406\u5b9e\u9a8c\u5bf9\u4e8e\u5de5\u7a0b\u5206\u6790\u548c\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u6210\u672c\u5f80\u5f80\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5168\u7403\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u5728\u6709\u9650\u7684\u9ad8\u8d28\u91cf\u89c2\u6d4b\u57fa\u7840\u4e0a\u63d0\u4f9b\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u9884\u6d4b\uff0c\u9ad8\u65af\u8fc7\u7a0b\uff08GPs\uff09\u4f5c\u4e3a\u4ee3\u7406\u56de\u5f52\u6a21\u578b\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002\u7136\u800c\uff0c\u5728\u5de5\u7a0b\u4f18\u5316\u9886\u57df\uff0c\u4eceGPs\u4e2d\u91c7\u6837\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u8bba\u6587\u4e3b\u8981\u63a2\u8ba8\u4e86\u4e24\u79cd\u663e\u8457\u7684\u91c7\u6837\u65b9\u6cd5\uff1a\u968f\u673a\u5085\u7acb\u53f6\u7279\u5f81\u548c\u8def\u5f84\u6761\u4ef6\u5316\uff0c\u5e76\u7b80\u8981\u63cf\u8ff0\u4e86\u5176\u4ed6\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u6570\u503c\u5b9e\u4f8b\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u91c7\u6837\u65b9\u6cd5\u5728\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u3001\u5355\u76ee\u6807\u4f18\u5316\u548c\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u6210\u529f\u5e94\u7528\u3002", "conclusion": "\u8be5\u8bba\u6587\u8be6\u7ec6\u9610\u8ff0\u4e86\u5982\u4f55\u5c06\u751f\u6210\u7684\u6837\u672c\u5e94\u7528\u4e8e\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548c\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e24\u79cd\u91c7\u6837\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15042", "pdf": "https://arxiv.org/pdf/2507.15042", "abs": "https://arxiv.org/abs/2507.15042", "authors": ["Jerry Wang", "Fang Yu"], "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection", "categories": ["cs.AI", "cs.IR", "I.2.7; H.3.3; K.6.5"], "comment": "Accepted by KDD Workshop on Prompt Optimization 2025", "summary": "Adversarial prompt attacks can significantly alter the reliability of\nRetrieval-Augmented Generation (RAG) systems by re-ranking them to produce\nincorrect outputs. In this paper, we present a novel method that applies\nDifferential Evolution (DE) to optimize adversarial prompt suffixes for\nRAG-based question answering. Our approach is gradient-free, treating the RAG\npipeline as a black box and evolving a population of candidate suffixes to\nmaximize the retrieval rank of a targeted incorrect document to be closer to\nreal world scenarios. We conducted experiments on the BEIR QA datasets to\nevaluate attack success at certain retrieval rank thresholds under multiple\nretrieving applications. Our results demonstrate that DE-based prompt\noptimization attains competitive (and in some cases higher) success rates\ncompared to GGPP to dense retrievers and PRADA to sparse retrievers, while\nusing only a small number of tokens (<=5 tokens) in the adversarial suffix.\nFurthermore, we introduce a readability-aware suffix construction strategy,\nvalidated by a statistically significant reduction in MLM negative\nlog-likelihood with Welch's t-test. Through evaluations with a BERT-based\nadversarial suffix detector, we show that DE-generated suffixes evade\ndetection, yielding near-chance detection accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\u4ee5\u653b\u51fb\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u591a\u79cd\u68c0\u7d22\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u3002", "motivation": "\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u53ef\u4ee5\u663e\u8457\u6539\u53d8\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u6765\u4f18\u5316\u8fd9\u4e9b\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u4f7f\u5176\u80fd\u5728\u4e0d\u4f9d\u8d56\u68af\u5ea6\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u5bf9\u76ee\u6807\u9519\u8bef\u6587\u6863\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u4ece\u800c\u4ea7\u751f\u4e0d\u6b63\u786e\u7684\u8f93\u51fa\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u6765\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\uff0c\u8be5\u65b9\u6cd5\u5c06RAG\u7ba1\u9053\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u901a\u8fc7\u6f14\u5316\u5019\u9009\u540e\u7f00\u79cd\u7fa4\u4ee5\u6700\u5927\u5316\u76ee\u6807\u9519\u8bef\u6587\u6863\u7684\u68c0\u7d22\u6392\u540d\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u53ef\u8bfb\u6027\u611f\u77e5\u7684\u540e\u7f00\u6784\u5efa\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0eGGPP\u548cPRADA\u76f8\u6bd4\uff0c\u57fa\u4e8eDE\u7684\u63d0\u793a\u4f18\u5316\u5728\u5c11\u91cf\u6807\u8bb0\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6210\u529f\u7387\u3002\u540c\u65f6\uff0cDE\u751f\u6210\u7684\u540e\u7f00\u80fd\u591f\u907f\u5f00\u68c0\u6d4b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u5728\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.14747", "pdf": "https://arxiv.org/pdf/2507.14747", "abs": "https://arxiv.org/abs/2507.14747", "authors": ["Yiding Song"], "title": "Pruning Increases Orderedness in Recurrent Computation", "categories": ["cs.LG", "cs.NE"], "comment": "8 pages, 11 figures, 2 tables, Workshop on Methods and Opportunities\n  at Small Scale (MOSS), ICML 2025", "summary": "Inspired by the prevalence of recurrent circuits in biological brains, we\ninvestigate the degree to which directionality is a helpful inductive bias for\nartificial neural networks. Taking directionality as topologically-ordered\ninformation flow between neurons, we formalise a perceptron layer with\nall-to-all connections (mathematically equivalent to a weight-tied recurrent\nneural network) and demonstrate that directionality, a hallmark of modern\nfeed-forward networks, can be induced rather than hard-wired by applying\nappropriate pruning techniques. Across different random seeds our pruning\nschemes successfully induce greater topological ordering in information flow\nbetween neurons without compromising performance, suggesting that\ndirectionality is not a prerequisite for learning, but may be an advantageous\ninductive bias discoverable by gradient descent and sparsification.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u901a\u8fc7\u9002\u5f53\u7684\u526a\u679d\u6280\u672f\u53ef\u4ee5\u8bf1\u5bfc\u51fa\u65b9\u5411\u6027\uff0c\u800c\u65b9\u5411\u6027\u53ef\u80fd\u662f\u6709\u5229\u4e8e\u5b66\u4e60\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u53d7\u751f\u7269\u5927\u8111\u4e2d\u5faa\u73af\u7535\u8def\u666e\u904d\u5b58\u5728\u7684\u542f\u53d1\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u59cb\u63a2\u7a76\u65b9\u5411\u6027\u5bf9\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4\u662f\u5426\u662f\u4e00\u4e2a\u6709\u76ca\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5177\u6709\u5168\u8fde\u63a5\u7684\u611f\u77e5\u673a\u5c42\uff0c\u5e76\u5e94\u7528\u9002\u5f53\u7684\u526a\u679d\u6280\u672f\u6765\u8bf1\u5bfc\u4fe1\u606f\u6d41\u7684\u65b9\u5411\u6027\u3002", "result": "\u5728\u4e0d\u540c\u7684\u968f\u673a\u79cd\u5b50\u4e0b\uff0c\u526a\u679d\u65b9\u6848\u6210\u529f\u5730\u5728\u4e0d\u635f\u5bb3\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u8bf1\u5bfc\u51fa\u4e86\u66f4\u5927\u7684\u4fe1\u606f\u6d41\u62d3\u6251\u6392\u5e8f\u3002", "conclusion": "\u65b9\u5411\u6027\u4e0d\u662f\u5b66\u4e60\u7684\u524d\u63d0\u6761\u4ef6\uff0c\u4f46\u53ef\u80fd\u662f\u4e00\u4e2a\u6709\u5229\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u53ef\u4ee5\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u548c\u7a00\u758f\u5316\u53d1\u73b0\u3002"}}
{"id": "2507.15106", "pdf": "https://arxiv.org/pdf/2507.15106", "abs": "https://arxiv.org/abs/2507.15106", "authors": ["Xia Xu", "Jochen Triesch"], "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward", "categories": ["cs.AI", "cs.RO", "F.2.2"], "comment": "13 pages, 5 figures", "summary": "While human infants robustly discover their own causal efficacy, standard\nreinforcement learning agents remain brittle, as their reliance on\ncorrelation-based rewards fails in noisy, ecologically valid scenarios. To\naddress this, we introduce the Causal Action Influence Score (CAIS), a novel\nintrinsic reward rooted in causal inference. CAIS quantifies an action's\ninfluence by measuring the 1-Wasserstein distance between the learned\ndistribution of sensory outcomes conditional on that action, $p(h|a)$, and the\nbaseline outcome distribution, $p(h)$. This divergence provides a robust reward\nthat isolates the agent's causal impact from confounding environmental noise.\nWe test our approach in a simulated infant-mobile environment where\ncorrelation-based perceptual rewards fail completely when the mobile is\nsubjected to external forces. In stark contrast, CAIS enables the agent to\nfilter this noise, identify its influence, and learn the correct policy.\nFurthermore, the high-quality predictive model learned for CAIS allows our\nagent, when augmented with a surprise signal, to successfully reproduce the\n\"extinction burst\" phenomenon. We conclude that explicitly inferring causality\nis a crucial mechanism for developing a robust sense of agency, offering a\npsychologically plausible framework for more adaptive autonomous systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u5185\u5728\u5956\u52b1\u673a\u5236\u2014\u2014Causal Action Influence Score (CAIS)\uff0c\u5b83\u80fd\u5e2e\u52a9\u667a\u80fd\u4f53\u5728\u566a\u58f0\u73af\u5883\u4e0b\u8bc6\u522b\u81ea\u8eab\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u6b63\u786e\u7684\u7b56\u7565\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u6a21\u62df\u5a74\u513f\u73af\u5883\u4e2d\u6709\u6548\u5730\u8fc7\u6ee4\u73af\u5883\u566a\u58f0\uff0c\u5e76\u6210\u529f\u91cd\u73b0\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\u3002", "motivation": "\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u76f8\u5173\u6027\u5956\u52b1\uff0c\u5728\u5b58\u5728\u566a\u58f0\u7684\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u5a74\u513f\u90a3\u6837\u7a33\u5b9a\u5730\u53d1\u73b0\u81ea\u5df1\u7684\u56e0\u679c\u6548\u80fd\u3002", "method": "\u5f15\u5165\u4e86Causal Action Influence Score (CAIS)\u4f5c\u4e3a\u65b0\u7684\u5185\u5728\u5956\u52b1\uff0c\u901a\u8fc7\u8ba1\u7b97\u52a8\u4f5c\u6761\u4ef6\u4e0b\u7684\u611f\u77e5\u7ed3\u679c\u5206\u5e03\u4e0e\u57fa\u7ebf\u7ed3\u679c\u5206\u5e03\u4e4b\u95f4\u76841-Wasserstein\u8ddd\u79bb\u6765\u91cf\u5316\u52a8\u4f5c\u7684\u5f71\u54cd\u3002", "result": "\u5728\u6a21\u62df\u5a74\u513f\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u79fb\u52a8\u7269\u4f53\u53d7\u5230\u5916\u90e8\u529b\u91cf\u5f71\u54cd\u65f6\uff0c\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u611f\u77e5\u5956\u52b1\u5b8c\u5168\u5931\u6548\uff0c\u800cCAIS\u80fd\u591f\u4f7f\u667a\u80fd\u4f53\u8fc7\u6ee4\u566a\u58f0\uff0c\u8bc6\u522b\u5176\u5f71\u54cd\u5e76\u5b66\u4e60\u6b63\u786e\u7b56\u7565\u3002\u6b64\u5916\uff0c\u9ad8\u8d28\u91cf\u9884\u6d4b\u6a21\u578b\u548c\u60ca\u559c\u4fe1\u53f7\u7684\u7ed3\u5408\u4f7f\u5f97\u667a\u80fd\u4f53\u80fd\u591f\u6210\u529f\u91cd\u73b0\u201c\u6d88\u9000\u7206\u53d1\u201d\u73b0\u8c61\u3002", "conclusion": "\u660e\u786e\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u662f\u53d1\u5c55\u7a33\u5065\u7684\u4e3b\u4f53\u610f\u8bc6\u7684\u5173\u952e\u673a\u5236\uff0c\u4e3a\u66f4\u9002\u5e94\u6027\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc3\u7406\u4e0a\u5408\u7406\u7684\u6846\u67b6\u3002"}}
{"id": "2507.14748", "pdf": "https://arxiv.org/pdf/2507.14748", "abs": "https://arxiv.org/abs/2507.14748", "authors": ["Patrik Reizinger", "B\u00e1lint Mucs\u00e1nyi", "Siyuan Guo", "Benjamin Eysenbach", "Bernhard Sch\u00f6lkopf", "Wieland Brendel"], "title": "Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "16 pages, 7 figures", "summary": "Self-supervised feature learning and pretraining methods in reinforcement\nlearning (RL) often rely on information-theoretic principles, termed mutual\ninformation skill learning (MISL). These methods aim to learn a representation\nof the environment while also incentivizing exploration thereof. However, the\nrole of the representation and mutual information parametrization in MISL is\nnot yet well understood theoretically. Our work investigates MISL through the\nlens of identifiable representation learning by focusing on the Contrastive\nSuccessor Features (CSF) method. We prove that CSF can provably recover the\nenvironment's ground-truth features up to a linear transformation due to the\ninner product parametrization of the features and skill diversity in a\ndiscriminative sense. This first identifiability guarantee for representation\nlearning in RL also helps explain the implications of different mutual\ninformation objectives and the downsides of entropy regularizers. We\nempirically validate our claims in MuJoCo and DeepMind Control and show how CSF\nprovably recovers the ground-truth features both from states and pixels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e92\u4fe1\u606f\u6280\u80fd\u5b66\u4e60\uff08MISL\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u901a\u8fc7\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u89c6\u89d2\uff0c\u7279\u522b\u662f\u5bf9\u6bd4\u7ee7\u4efb\u7279\u5f81\uff08CSF\uff09\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86CSF\u53ef\u4ee5\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\u3002", "motivation": "\u4e92\u4fe1\u606f\u6280\u80fd\u5b66\u4e60\uff08MISL\uff09\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u81ea\u76d1\u7763\u7279\u5f81\u5b66\u4e60\u548c\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u4f46\u5176\u7406\u8bba\u7406\u89e3\u5c1a\u4e0d\u5145\u5206\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8868\u793a\u5b66\u4e60\u548c\u4e92\u4fe1\u606f\u53c2\u6570\u5316\u5728MISL\u4e2d\u7684\u4f5c\u7528\uff0c\u4f5c\u8005\u9009\u62e9\u4ece\u53ef\u8bc6\u522b\u8868\u793a\u5b66\u4e60\u7684\u89d2\u5ea6\u7814\u7a76MISL\uff0c\u5e76\u805a\u7126\u4e8e\u5bf9\u6bd4\u7ee7\u4efb\u7279\u5f81\uff08CSF\uff09\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u6570\u5b66\u8bc1\u660e\u7684\u65b9\u5f0f\uff0c\u5c55\u793a\u4e86CSF\u65b9\u6cd5\u5982\u4f55\u901a\u8fc7\u7279\u5f81\u548c\u6280\u80fd\u591a\u6837\u6027\u4ee5\u7ebf\u6027\u53d8\u6362\u7684\u65b9\u5f0f\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u63a2\u8ba8\u4e86\u4e0d\u540c\u4e92\u4fe1\u606f\u76ee\u6807\u7684\u5f71\u54cd\u4ee5\u53ca\u71b5\u6b63\u5219\u5316\u7684\u7f3a\u70b9\u3002", "result": "\u4f5c\u8005\u5728MuJoCo\u548cDeepMind Control\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660eCSF\u53ef\u4ee5\u4ece\u72b6\u6001\u548c\u50cf\u7d20\u4e2d\u6062\u590d\u73af\u5883\u7684\u771f\u5b9e\u7279\u5f81\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5173\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u793a\u5b66\u4e60\u7684\u53ef\u8bc6\u522b\u6027\u4fdd\u8bc1\u7684\u7814\u7a76\uff0c\u5b83\u4e0d\u4ec5\u89e3\u91ca\u4e86\u4e0d\u540c\u4e92\u4fe1\u606f\u76ee\u6807\u7684\u5f71\u54cd\uff0c\u4e5f\u63ed\u793a\u4e86\u71b5\u6b63\u5219\u5316\u7684\u4e0d\u8db3\u4e4b\u5904\u3002"}}
{"id": "2507.15120", "pdf": "https://arxiv.org/pdf/2507.15120", "abs": "https://arxiv.org/abs/2507.15120", "authors": ["Stefan Borgwardt", "Duy Nhu", "Gabriele R\u00f6ger"], "title": "Automated planning with ontologies under coherence update semantics", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Standard automated planning employs first-order formulas under closed-world\nsemantics to achieve a goal with a given set of actions from an initial state.\nWe follow a line of research that aims to incorporate background knowledge into\nautomated planning problems, for example, by means of ontologies, which are\nusually interpreted under open-world semantics. We present a new approach for\nplanning with DL-Lite ontologies that combines the advantages of ontology-based\naction conditions provided by explicit-input knowledge and action bases (eKABs)\nand ontology-aware action effects under the coherence update semantics. We show\nthat the complexity of the resulting formalism is not higher than that of\nprevious approaches and provide an implementation via a polynomial compilation\ninto classical planning. An evaluation of existing and new benchmarks examines\nthe performance of a planning system on different variants of our compilation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408DL-Lite\u672c\u4f53\u8bba\u7684\u81ea\u52a8\u5316\u89c4\u5212\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u6027\u4e0d\u9ad8\u4e8e\u5148\u524d\u65b9\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u7ed3\u5408\u4e86\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\u548c\u884c\u52a8\u57fa\u7840\uff08eKABs\uff09\u63d0\u4f9b\u7684\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u52a8\u4f5c\u6761\u4ef6\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u8fde\u8d2f\u66f4\u65b0\u8bed\u4e49\u4e0b\u7684\u672c\u4f53\u611f\u77e5\u52a8\u4f5c\u6548\u679c\u3002\u901a\u8fc7\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u89c4\u5212\u7cfb\u7edf\u5728\u4e0d\u540c\u7f16\u8bd1\u53d8\u4f53\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u5316\u89c4\u5212\u91c7\u7528\u4e00\u9636\u516c\u5f0f\uff0c\u5728\u5c01\u95ed\u4e16\u754c\u8bed\u4e49\u4e0b\u4ece\u521d\u59cb\u72b6\u6001\u51fa\u53d1\uff0c\u5229\u7528\u7ed9\u5b9a\u7684\u4e00\u7ec4\u52a8\u4f5c\u5b9e\u73b0\u76ee\u6807\u3002\u7136\u800c\uff0c\u4e3a\u4e86\u5c06\u80cc\u666f\u77e5\u8bc6\uff08\u4f8b\u5982\u672c\u4f53\u8bba\uff09\u878d\u5165\u81ea\u52a8\u5316\u89c4\u5212\u95ee\u9898\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5f00\u653e\u4e16\u754c\u8bed\u4e49\u4e0b\u7684\u4fe1\u606f\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408DL-Lite\u672c\u4f53\u8bba\u7684\u89c4\u5212\u65b0\u65b9\u6cd5\uff0c\u5b83\u7ed3\u5408\u4e86\u663e\u5f0f\u8f93\u5165\u77e5\u8bc6\u548c\u884c\u52a8\u57fa\u7840\uff08eKABs\uff09\u63d0\u4f9b\u7684\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u52a8\u4f5c\u6761\u4ef6\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u8fde\u8d2f\u66f4\u65b0\u8bed\u4e49\u4e0b\u7684\u672c\u4f53\u611f\u77e5\u52a8\u4f5c\u6548\u679c\u3002\u5e76\u4e14\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b0\u65b9\u6cd5\u7684\u590d\u6742\u6027\u4e0d\u8d85\u8fc7\u4ee5\u524d\u7684\u65b9\u6cd5\u3002", "result": "\u4f5c\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u8fc7\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u65b0\u65b9\u6cd5\u5728\u4e0d\u540c\u7f16\u8bd1\u53d8\u4f53\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u590d\u6742\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u7ed3\u5408DL-Lite\u672c\u4f53\u8bba\u8fdb\u884c\u81ea\u52a8\u5316\u89c4\u5212\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.14766", "pdf": "https://arxiv.org/pdf/2507.14766", "abs": "https://arxiv.org/abs/2507.14766", "authors": ["Mehak Arora", "Ayman Ali", "Kaiyuan Wu", "Carolyn Davis", "Takashi Shimazui", "Mahmoud Alwakeel", "Victor Moas", "Philip Yang", "Annette Esper", "Rishikesan Kamaleswaran"], "title": "CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "In Review for MICCAI 2025", "summary": "In intensive care units (ICUs), patients with complex clinical conditions\nrequire vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a\nvital diagnostic tool, providing insights into clinical trajectories, but their\nirregular acquisition limits their utility. Existing tools for CXR\ninterpretation are constrained by cross-sectional analysis, failing to capture\ntemporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal\nframework that integrates temporally sparse CXR imaging and radiology reports\nwith high-frequency clinical data, such as vital signs, laboratory values, and\nrespiratory flow sheets, to predict the trajectory of CXR findings in\ncritically ill patients. CXR-TFT leverages latent embeddings from a vision\nencoder that are temporally aligned with hourly clinical data through\ninterpolation. A transformer model is then trained to predict CXR embeddings at\neach hour, conditioned on previous embeddings and clinical measurements. In a\nretrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy\nin forecasting abnormal CXR findings up to 12 hours before they became\nradiographically evident. This predictive capability in clinical data holds\nsignificant potential for enhancing the management of time-sensitive conditions\nlike acute respiratory distress syndrome, where early intervention is crucial\nand diagnoses are often delayed. By providing distinctive temporal resolution\nin prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights\nthat can directly improve clinical outcomes.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u6846\u67b6CXR-TFT\uff0c\u5b83\u7ed3\u5408\u4e86\u7a00\u758f\u7684\u65f6\u95f4\u6027\u80f8\u8154X\u5149\u56fe\u50cf\u548c\u9ad8\u9891\u4e34\u5e8a\u6570\u636e\u6765\u9884\u6d4b\u91cd\u75c7\u60a3\u8005\u7684\u80f8\u8154X\u5149\u53d8\u5316\u8f68\u8ff9\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9884\u6d4b\u5f02\u5e38\u53d1\u73b0\u4e0a\u7684\u9ad8\u51c6\u786e\u5ea6\u3002", "motivation": "\u4f5c\u8005\u6307\u51fa\u76ee\u524d\u7684\u80f8\u8154X\u5149\u89e3\u91ca\u5de5\u5177\u53d7\u9650\u4e8e\u6a2a\u65ad\u9762\u5206\u6790\uff0c\u65e0\u6cd5\u6355\u6349\u65f6\u95f4\u52a8\u6001\uff0c\u800c\u91cd\u75c7\u76d1\u62a4\u5ba4\u4e2d\u590d\u6742\u7684\u60a3\u8005\u60c5\u51b5\u9700\u8981\u8b66\u60d5\u76d1\u63a7\u548c\u53ca\u65f6\u5e72\u9884\u3002\u56e0\u6b64\uff0c\u4ed6\u4eec\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6574\u5408\u4e0d\u89c4\u5219\u83b7\u53d6\u7684\u80f8\u8154X\u5149\u56fe\u50cf\u4e0e\u9ad8\u9891\u4e34\u5e8a\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u80f8\u8154X\u5149\u7684\u53d8\u5316\u8f68\u8ff9\u3002", "method": "CXR-TFT\u5229\u7528\u4e86\u4e00\u4e2a\u89c6\u89c9\u7f16\u7801\u5668\u751f\u6210\u7684\u6f5c\u5728\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u63d2\u503c\u5c06\u5176\u4e0e\u6bcf\u5c0f\u65f6\u7684\u4e34\u5e8a\u6570\u636e\u5bf9\u9f50\u3002\u7136\u540e\u8bad\u7ec3\u4e00\u4e2a\u53d8\u6362\u5668\u6a21\u578b\uff0c\u57fa\u4e8e\u5148\u524d\u7684\u5d4c\u5165\u548c\u4e34\u5e8a\u6d4b\u91cf\u7ed3\u679c\u9884\u6d4b\u6bcf\u4e2a\u5c0f\u65f6\u70b9\u7684\u80f8\u8154X\u5149\u5d4c\u5165\u3002", "result": "\u572820,000\u540d\u91cd\u75c7\u76d1\u62a4\u75c5\u623f\u60a3\u8005\u7684\u56de\u987e\u6027\u7814\u7a76\u4e2d\uff0cCXR-TFT\u5728\u9884\u6d4b\u653e\u5c04\u5b66\u660e\u663e\u524d12\u5c0f\u65f6\u5185\u51fa\u73b0\u7684\u5f02\u5e38\u80f8\u8154X\u5149\u53d1\u73b0\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "CXR-TFT\u63d0\u4f9b\u7684\u9884\u6d4b\u80fd\u529b\u5bf9\u4e8e\u6025\u6027\u547c\u5438\u7a98\u8feb\u7efc\u5408\u75c7\u7b49\u65f6\u95f4\u654f\u611f\u75c5\u75c7\u7684\u7ba1\u7406\u5177\u6709\u91cd\u5927\u6f5c\u529b\uff0c\u53ef\u4ee5\u6539\u5584\u4e34\u5e8a\u7ed3\u679c\u3002"}}
{"id": "2507.15140", "pdf": "https://arxiv.org/pdf/2507.15140", "abs": "https://arxiv.org/abs/2507.15140", "authors": ["Mohammad Mashayekhi", "Sara Ahmadi Majd", "Arian AmirAmjadi", "Parsa Hosseini"], "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis", "categories": ["cs.AI"], "comment": null, "summary": "The diagnosis of oral diseases presents a problematic clinical challenge,\ncharacterized by a wide spectrum of pathologies with overlapping\nsymptomatology. To address this, we developed Clinical Semantic Intelligence\n(CSI), a novel artificial intelligence framework that diagnoses 118 different\noral diseases by computationally modeling the cognitive processes of an expert\nclinician. Our core hypothesis is that moving beyond simple pattern matching to\nemulate expert reasoning is critical to building clinically useful diagnostic\naids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a\nspecialized ChatGLM-6B language model. This system executes a Hierarchical\nDiagnostic Reasoning Tree (HDRT), a structured framework that distills the\nsystematic, multi-step logic of differential diagnosis. The framework operates\nin two modes: a Fast Mode for rapid screening and a Standard Mode that\nleverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310\nimages, supplemented by an external hold-out set of 176 images for final\nvalidation. A clinically-informed augmentation strategy expanded our training\ndata to over 30,000 image-text pairs. On a 431-image internal test set, CSI's\nFast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the\nHDRT-driven Standard Mode. The performance gain is directly attributable to the\nhierarchical reasoning process. Herein, we detail the architectural philosophy,\ndevelopment, and rigorous evaluation of the CSI framework.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4eba\u5de5\u667a\u80fd\u6846\u67b6CSI\uff0c\u7528\u4e8e\u8bca\u65ad118\u79cd\u4e0d\u540c\u7684\u53e3\u8154\u75be\u75c5\u3002\u5b83\u901a\u8fc7\u6a21\u4eff\u4e13\u5bb6\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u8d85\u8d8a\u4e86\u7b80\u5355\u7684\u6a21\u5f0f\u5339\u914d\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u4e34\u5e8a\u8bca\u65ad\u8f85\u52a9\u5de5\u5177\u3002", "motivation": "\u4f5c\u8005\u4eec\u6ce8\u610f\u5230\u53e3\u8154\u75be\u75c5\u7684\u8bca\u65ad\u5728\u4e34\u5e8a\u4e0a\u662f\u4e00\u4e2a\u590d\u6742\u7684\u95ee\u9898\uff0c\u7531\u4e8e\u75c5\u7406\u5e7f\u6cdb\u4e14\u75c7\u72b6\u91cd\u53e0\uff0c\u5bfc\u81f4\u8bca\u65ad\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ed6\u4eec\u5f00\u53d1\u4e86Clinical Semantic Intelligence (CSI)\u3002", "method": "CSI\u67b6\u6784\u7ed3\u5408\u4e86\u4f18\u5316\u7684\u591a\u6a21\u6001CLIP\u6a21\u578b\u548c\u4e13\u95e8\u7684ChatGLM-6B\u8bed\u8a00\u6a21\u578b\uff0c\u6267\u884c\u5206\u5c42\u8bca\u65ad\u63a8\u7406\u6811\uff08HDRT\uff09\uff0c\u4ee5\u6a21\u62df\u7cfb\u7edf\u6027\u7684\u3001\u591a\u6b65\u9aa4\u7684\u9274\u522b\u8bca\u65ad\u903b\u8f91\u3002\u8be5\u7cfb\u7edf\u6709\u5feb\u901f\u7b5b\u9009\u7684Fast Mode\u548c\u5229\u7528\u5b8c\u6574HDRT\u8fdb\u884c\u4ea4\u4e92\u5f0f\u6df1\u5165\u8bca\u65ad\u5de5\u4f5c\u7684Standard Mode\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "\u5728431\u5f20\u5185\u90e8\u6d4b\u8bd5\u96c6\u56fe\u50cf\u4e0a\uff0cCSI\u7684Fast Mode\u8fbe\u5230\u4e8673.4%\u7684\u51c6\u786e\u7387\uff0c\u5728\u4f7f\u7528HDRT\u9a71\u52a8\u7684Standard Mode\u65f6\u51c6\u786e\u7387\u63d0\u9ad8\u5230\u4e8689.5%\uff0c\u8fd9\u76f4\u63a5\u5f52\u56e0\u4e8e\u5206\u5c42\u63a8\u7406\u8fc7\u7a0b\u3002", "conclusion": "\u6587\u7ae0\u8be6\u7ec6\u4ecb\u7ecd\u4e86CSI\u6846\u67b6\u7684\u67b6\u6784\u7406\u5ff5\u3001\u5f00\u53d1\u8fc7\u7a0b\u548c\u4e25\u683c\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u8868\u660e\u5176\u5728\u63d0\u5347\u53e3\u8154\u75be\u75c5\u8bca\u65ad\u51c6\u786e\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14777", "pdf": "https://arxiv.org/pdf/2507.14777", "abs": "https://arxiv.org/abs/2507.14777", "authors": ["Bishwamittra Ghosh", "Soumi Das", "Qinyuan Wu", "Mohammad Aflah Khan", "Krishna P. Gummadi", "Evimaria Terzi", "Deepak Garg"], "title": "Rethinking Memorization Measures and their Implications in Large Language Models", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Concerned with privacy threats, memorization in LLMs is often seen as\nundesirable, specifically for learning. In this paper, we study whether\nmemorization can be avoided when optimally learning a language, and whether the\nprivacy threat posed by memorization is exaggerated or not. To this end, we\nre-examine existing privacy-focused measures of memorization, namely\nrecollection-based and counterfactual memorization, along with a newly proposed\ncontextual memorization.\n  Relating memorization to local over-fitting during learning, contextual\nmemorization aims to disentangle memorization from the contextual learning\nability of LLMs. Informally, a string is contextually memorized if its\nrecollection due to training exceeds the optimal contextual recollection, a\nlearned threshold denoting the best contextual learning without training.\nConceptually, contextual recollection avoids the fallacy of recollection-based\nmemorization, where any form of high recollection is a sign of memorization.\nTheoretically, contextual memorization relates to counterfactual memorization,\nbut imposes stronger conditions. Memorization measures differ in outcomes and\ninformation requirements.\n  Experimenting on 18 LLMs from 6 families and multiple formal languages of\ndifferent entropy, we show that (a) memorization measures disagree on\nmemorization order of varying frequent strings, (b) optimal learning of a\nlanguage cannot avoid partial memorization of training strings, and (c)\nimproved learning decreases contextual and counterfactual memorization but\nincreases recollection-based memorization. Finally, (d) we revisit existing\nreports of memorized strings by recollection that neither pose a privacy threat\nnor are contextually or counterfactually memorized.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u6700\u4f18\u5b66\u4e60\u8bed\u8a00\u65f6\u662f\u5426\u53ef\u4ee5\u907f\u514d\u8bb0\u5fc6\uff0c\u5e76\u91cd\u65b0\u5ba1\u89c6\u4e86\u73b0\u6709\u7684\u8bb0\u5fc6\u9690\u79c1\u8861\u91cf\u6807\u51c6\uff0c\u63d0\u51fa\u4e86\u60c5\u5883\u8bb0\u5fc6\u7684\u65b0\u6982\u5ff5\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u8bb0\u5fc6\u6d4b\u91cf\u65b9\u6cd5\u5bf9\u5b57\u7b26\u4e32\u7684\u8bb0\u5fc6\u987a\u5e8f\u5b58\u5728\u5206\u6b67\uff0c\u5b8c\u5168\u907f\u514d\u8bad\u7ec3\u5b57\u7b26\u4e32\u7684\u90e8\u5206\u8bb0\u5fc6\u662f\u4e0d\u53ef\u80fd\u7684\uff0c\u6539\u8fdb\u7684\u5b66\u4e60\u4f1a\u51cf\u5c11\u60c5\u5883\u548c\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\u4f46\u589e\u52a0\u56de\u5fc6\u8bb0\u5fc6\uff0c\u4e14\u4e00\u4e9b\u88ab\u62a5\u544a\u4e3a\u5b58\u5728\u9690\u79c1\u5a01\u80c1\u7684\u8bb0\u5fc6\u5b9e\u9645\u4e0a\u5e76\u65e0\u6b64\u5a01\u80c1\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8ba4\u4e3aLLM\u4e2d\u7684\u8bb0\u5fc6\u5bf9\u9690\u79c1\u6784\u6210\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5728\u5b66\u4e60\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u8ba8\u5728\u6700\u4f18\u5b66\u4e60\u8bed\u8a00\u65f6\u662f\u5426\u53ef\u4ee5\u907f\u514d\u8bb0\u5fc6\uff0c\u4ee5\u53ca\u8bc4\u4f30\u7531\u8bb0\u5fc6\u5e26\u6765\u7684\u9690\u79c1\u5a01\u80c1\u662f\u5426\u88ab\u5938\u5927\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u4e86\u73b0\u6709\u7684\u57fa\u4e8e\u56de\u5fc6\u548c\u53cd\u4e8b\u5b9e\u7684\u8bb0\u5fc6\u9690\u79c1\u8861\u91cf\u6807\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u60c5\u5883\u8bb0\u5fc6\u6807\u51c6\uff0c\u8be5\u6807\u51c6\u65e8\u5728\u533a\u5206\u8bb0\u5fc6\u4e0e\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u4e86\u6765\u81ea6\u4e2a\u5bb6\u65cf\u768418\u4e2aLLM\u5728\u4e0d\u540c\u71b5\u503c\u7684\u5f62\u5f0f\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u3002", "result": "\uff08a\uff09\u4e0d\u540c\u8bb0\u5fc6\u6d4b\u91cf\u65b9\u6cd5\u5bf9\u53d8\u5316\u9891\u7387\u5b57\u7b26\u4e32\u7684\u8bb0\u5fc6\u987a\u5e8f\u5b58\u5728\u5206\u6b67\uff1b\uff08b\uff09\u6700\u4f18\u8bed\u8a00\u5b66\u4e60\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u8bad\u7ec3\u5b57\u7b26\u4e32\u7684\u90e8\u5206\u8bb0\u5fc6\uff1b\uff08c\uff09\u6539\u8fdb\u5b66\u4e60\u51cf\u5c11\u4e86\u60c5\u5883\u548c\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\u4f46\u589e\u52a0\u4e86\u56de\u5fc6\u8bb0\u5fc6\uff1b\uff08d\uff09\u4e00\u4e9b\u88ab\u62a5\u544a\u4e3a\u5b58\u5728\u9690\u79c1\u5a01\u80c1\u7684\u8bb0\u5fc6\u5b9e\u9645\u4e0a\u5e76\u65e0\u6b64\u5a01\u80c1\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u6700\u4f18\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5b8c\u5168\u907f\u514d\u8bb0\u5fc6\u662f\u4e0d\u53ef\u80fd\u7684\uff0c\u800c\u4e14\u4e00\u4e9b\u88ab\u8ba4\u4e3a\u5b58\u5728\u9690\u79c1\u5a01\u80c1\u7684\u8bb0\u5fc6\u5b9e\u9645\u4e0a\u5e76\u4e0d\u5b58\u5728\u8fd9\u79cd\u5a01\u80c1\u3002"}}
{"id": "2507.15143", "pdf": "https://arxiv.org/pdf/2507.15143", "abs": "https://arxiv.org/abs/2507.15143", "authors": ["Abderaouf Bahi", "Amel Ourici"], "title": "Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "This paper investigates the feasibility of human mobility in The Line, a\nproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess\nwhether citizens can move freely within this unprecedented urban topology, we\ndevelop a hybrid simulation framework that integrates agent-based modeling,\nreinforcement learning, supervised learning, and graph neural networks. The\nsimulation captures multi-modal transportation behaviors across 50 vertical\nlevels and varying density scenarios using both synthetic data and real-world\ntraces from high-density cities. Our experiments reveal that with the full\nAI-integrated architecture, agents achieved an average commute time of 7.8 to\n8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index\nof over 91 percent, even during peak congestion periods. Ablation studies\nconfirmed that the removal of intelligent modules such as reinforcement\nlearning or graph neural networks significantly degrades performance, with\ncommute times increasing by up to 85 percent and reachability falling below 70\npercent. Environmental modeling further demonstrated low energy consumption and\nminimal CO2 emissions when electric modes are prioritized. The findings suggest\nthat freedom of movement is not only conceptually achievable in The Line, but\nalso operationally realistic if supported by adaptive AI systems, sustainable\ninfrastructure, and real-time feedback loops.", "AI": {"tldr": "\u7814\u7a76\u4e86\u6c99\u7279\u963f\u62c9\u4f2fNEOM\u7684\u62df\u8bae170\u516c\u91cc\u7ebf\u6027\u667a\u80fd\u57ce\u5e02The Line\u4e2d\u4eba\u7c7b\u79fb\u52a8\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u6df7\u5408\u4eff\u771f\u6846\u67b6\u8bc4\u4f30\u5c45\u6c11\u80fd\u5426\u81ea\u7531\u79fb\u52a8\uff0c\u5e76\u53d1\u73b0\u82e5\u83b7\u5f97\u81ea\u9002\u5e94AI\u7cfb\u7edf\u3001\u53ef\u6301\u7eed\u57fa\u7840\u8bbe\u65bd\u548c\u5b9e\u65f6\u53cd\u9988\u73af\u7684\u652f\u6301\uff0c\u79fb\u52a8\u81ea\u7531\u4e0d\u4ec5\u6982\u5ff5\u4e0a\u53ef\u884c\uff0c\u800c\u4e14\u64cd\u4f5c\u4e0a\u4e5f\u73b0\u5b9e\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u5728\u524d\u6240\u672a\u6709\u7684\u57ce\u5e02\u62d3\u6251\u7ed3\u6784\u4e2d\uff0c\u516c\u6c11\u662f\u5426\u80fd\u591f\u81ea\u7531\u79fb\u52a8\uff0c\u7279\u522b\u662f\u5728\u6c99\u7279\u963f\u62c9\u4f2fNEOM\u63d0\u51fa\u7684170\u516c\u91cc\u957f\u7684\u7ebf\u6027\u667a\u80fd\u57ce\u5e02The Line\u4e2d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df7\u5408\u6a21\u62df\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7763\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u6355\u634950\u4e2a\u5782\u76f4\u5c42\u9762\u548c\u4e0d\u540c\u5bc6\u5ea6\u573a\u666f\u4e0b\u7684\u591a\u6a21\u5f0f\u4ea4\u901a\u884c\u4e3a\u3002\u4f7f\u7528\u5408\u6210\u6570\u636e\u548c\u6765\u81ea\u9ad8\u5bc6\u5ea6\u57ce\u5e02\u7684\u73b0\u5b9e\u4e16\u754c\u75d5\u8ff9\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5b8c\u6574\u7684AI\u96c6\u6210\u67b6\u6784\u4f7f\u4ee3\u7406\u7684\u5e73\u5747\u901a\u52e4\u65f6\u95f4\u8fbe\u52307.8\u52308.4\u5206\u949f\uff0c\u6ee1\u610f\u5ea6\u8d85\u8fc789%\uff0c\u53ef\u8fbe\u6027\u6307\u6570\u8d85\u8fc791%\uff0c\u5373\u4f7f\u5728\u9ad8\u5cf0\u62e5\u5835\u65f6\u671f\u4e5f\u662f\u5982\u6b64\u3002\u53bb\u9664\u667a\u80fd\u6a21\u5757\u5982\u5f3a\u5316\u5b66\u4e60\u6216\u56fe\u795e\u7ecf\u7f51\u7edc\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\uff0c\u901a\u52e4\u65f6\u95f4\u589e\u52a0\u591a\u8fbe85%\uff0c\u53ef\u8fbe\u6027\u964d\u81f370%\u4ee5\u4e0b\u3002\u73af\u5883\u5efa\u6a21\u8fd8\u663e\u793a\uff0c\u5f53\u4f18\u5148\u8003\u8651\u7535\u52a8\u6a21\u5f0f\u65f6\uff0c\u80fd\u8017\u4f4e\u4e14\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u91cf\u5c0f\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728The Line\u4e2d\u5b9e\u73b0\u79fb\u52a8\u81ea\u7531\u4e0d\u4ec5\u662f\u6982\u5ff5\u4e0a\u7684\u53ef\u80fd\uff0c\u800c\u4e14\u5982\u679c\u5f97\u5230\u81ea\u9002\u5e94AI\u7cfb\u7edf\u3001\u53ef\u6301\u7eed\u57fa\u7840\u8bbe\u65bd\u548c\u5b9e\u65f6\u53cd\u9988\u5faa\u73af\u7684\u652f\u6301\uff0c\u4e5f\u662f\u5b9e\u9645\u53ef\u884c\u7684\u3002"}}
{"id": "2507.14783", "pdf": "https://arxiv.org/pdf/2507.14783", "abs": "https://arxiv.org/abs/2507.14783", "authors": ["Derek Li", "Jiaming Zhou", "Amirreza Kazemi", "Qianyi Sun", "Abbas Ghaddar", "Mohammad Ali Alomrani", "Liheng Ma", "Yu Luo", "Dong Li", "Feng Wen", "Jianye Hao", "Mark Coates", "Yingxue Zhang"], "title": "Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The advancement of general-purpose artificial intelligence relies on large\nlanguage models (LLMs) that excel across a wide range of tasks, from structured\nreasoning to creative generation. However, post-training methods like\nSupervised Fine-Tuning (SFT) often struggle with generalization, favoring\nmemorization over transferable learning. In this work, we introduce Omni-Think,\na unified reinforcement learning (RL) framework that enhances LLM performance\nacross diverse tasks by combining rule-based verifiable rewards with generative\npreference signals via LLM-as-a-Judge evaluations. Our approach enables\nconsistent optimization across task types and scales RL-based training to\nsubjective domains. We further investigate training strategies, demonstrating\nthat a curriculum-based progression that orders tasks from structured to\nopen-ended improves performance and reduces forgetting. Experimental results\nacross four domains reveal that curriculum learning improves performance by\n5.2\\% over joint training and 9.1\\% over model merging. These results highlight\nthe importance of task-aware sampling and hybrid supervision in scaling\nRL-based post-training for general-purpose LLMs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aOmni-Think\u7684\u7edf\u4e00\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u53ef\u9a8c\u8bc1\u5956\u52b1\u548c\u751f\u6210\u504f\u597d\u4fe1\u53f7\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u80fd\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8bf8\u5982\u76d1\u7763\u5fae\u8c03\u7b49\u540e\u8bad\u7ec3\u65b9\u6cd5\u5f80\u5f80\u8fc7\u4e8e\u4f9d\u8d56\u8bb0\u5fc6\u5316\u800c\u96be\u4ee5\u5b9e\u73b0\u5e7f\u6cdb\u8fc1\u79fb\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86Omni-Think\u8fd9\u4e00\u878d\u5408\u4e86\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u6027\u5956\u52b1\u4e0e\u901a\u8fc7LLM-as-a-Judge\u8bc4\u4f30\u5f97\u51fa\u7684\u751f\u6210\u504f\u597d\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u91c7\u7528\u4ece\u7ed3\u6784\u5316\u5230\u5f00\u653e\u5f0f\u7684\u8bfe\u7a0b\u5f0f\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u4e2d\uff0c\u8bfe\u7a0b\u5b66\u4e60\u6bd4\u8054\u5408\u8bad\u7ec3\u63d0\u9ad8\u4e865.2%\u7684\u6027\u80fd\uff0c\u6bd4\u6a21\u578b\u5408\u5e76\u63d0\u9ad8\u4e869.1%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u6269\u5c55\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4efb\u52a1\u611f\u77e5\u91c7\u6837\u548c\u6df7\u5408\u76d1\u7763\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.15225", "pdf": "https://arxiv.org/pdf/2507.15225", "abs": "https://arxiv.org/abs/2507.15225", "authors": ["Yichi Zhou", "Jianqiu Zhao", "Yongxin Zhang", "Bohan Wang", "Siran Wang", "Luoxin Chen", "Jiahui Wang", "Haowei Chen", "Allan Jie", "Xinbo Zhang", "Haocheng Wang", "Luong Trung", "Rong Ye", "Phan Nhat Hoang", "Huishuai Zhang", "Peng Sun", "Hang Li"], "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "General-purpose Large Language Models (LLMs) have achieved remarkable success\nin intelligence, performing comparably to human experts on complex reasoning\ntasks such as coding and mathematical reasoning. However, generating formal\nproofs in specialized languages like Lean 4 remains a significant challenge for\nthese models, limiting their application in complex theorem proving and\nautomated verification. Current approaches typically require specializing\nmodels through fine-tuning on dedicated formal corpora, incurring high costs\nfor data collection and training. In this work, we introduce \\textbf{Delta\nProver}, an agent-based framework that orchestrates the interaction between a\ngeneral-purpose LLM and the Lean 4 proof environment. Delta Prover leverages\nthe reflection and reasoning capabilities of general-purpose LLMs to\ninteractively construct formal proofs in Lean 4, circumventing the need for\nmodel specialization. At its core, the agent integrates two novel,\ninterdependent components: an algorithmic framework for reflective\ndecomposition and iterative proof repair, and a custom Domain-Specific Language\n(DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta\nProver achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test\nbenchmark, surpassing all existing approaches, including those requiring model\nspecialization.} Furthermore, Delta Prover exhibits a significantly stronger\ntest-time scaling law compared to standard Best-of-N proof strategies.\nCrucially, our findings demonstrate that general-purpose LLMs, when guided by\nan effective agentic structure, possess substantial untapped theorem-proving\ncapabilities. This presents a computationally efficient alternative to\nspecialized models for robust automated reasoning in formal environments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDelta Prover\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u5b83\u5728\u65e0\u9700\u5bf9\u6a21\u578b\u8fdb\u884c\u4e13\u95e8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u5728Lean 4\u8bc1\u660e\u73af\u5883\u4e2d\u6784\u5efa\u6b63\u5f0f\u8bc1\u660e\u3002\u8be5\u65b9\u6cd5\u5728miniF2F-test\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8695.9%\u7684\u6210\u529f\u7387\uff0c\u8d85\u8fc7\u4e86\u6240\u6709\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u667a\u80fd\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5728\u751f\u6210\u5982Lean 4\u7b49\u4e13\u4e1a\u8bed\u8a00\u7684\u5f62\u5f0f\u8bc1\u660e\u65f6\u4ecd\u9762\u4e34\u6311\u6218\u3002\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u590d\u6742\u5b9a\u7406\u8bc1\u660e\u548c\u81ea\u52a8\u9a8c\u8bc1\u4e2d\u7684\u5e94\u7528\u3002", "method": "Delta Prover\u6574\u5408\u4e86\u4e24\u4e2a\u65b0\u9896\u3001\u76f8\u4e92\u4f9d\u8d56\u7684\u7ec4\u4ef6\uff1a\u4e00\u4e2a\u7528\u4e8e\u53cd\u601d\u6027\u5206\u89e3\u548c\u8fed\u4ee3\u8bc1\u660e\u4fee\u590d\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8eLean 4\u5efa\u7acb\u7684\u7528\u4e8e\u7b80\u5316\u5b50\u95ee\u9898\u7ba1\u7406\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u3002", "result": "Delta Prover\u5728miniF2F-test\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8695.9%\u7684\u6210\u529f\u7387\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u90a3\u4e9b\u9700\u8981\u6a21\u578b\u4e13\u95e8\u5316\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u4e0e\u6807\u51c6\u7684\u6700\u4f73N\u8bc1\u660e\u7b56\u7565\u76f8\u6bd4\uff0cDelta Prover\u5c55\u793a\u4e86\u660e\u663e\u66f4\u5f3a\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u89c4\u5f8b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u7531\u6709\u6548\u7684\u4ee3\u7406\u7ed3\u6784\u5f15\u5bfc\u65f6\uff0c\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5de8\u5927\u7684\u672a\u5f00\u53d1\u5b9a\u7406\u8bc1\u660e\u80fd\u529b\uff0c\u4e3a\u6b63\u5f0f\u73af\u5883\u4e2d\u7684\u7a33\u5065\u81ea\u52a8\u5316\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.14785", "pdf": "https://arxiv.org/pdf/2507.14785", "abs": "https://arxiv.org/abs/2507.14785", "authors": ["Erfan Pirmorad"], "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The complexity and interconnectivity of entities involved in money laundering\ndemand investigative reasoning over graph-structured data. This paper explores\nthe use of large language models (LLMs) as reasoning engines over localized\nsubgraphs extracted from a financial knowledge graph. We propose a lightweight\npipeline that retrieves k-hop neighborhoods around entities of interest,\nserializes them into structured text, and prompts an LLM via few-shot\nin-context learning to assess suspiciousness and generate justifications. Using\nsynthetic anti-money laundering (AML) scenarios that reflect common laundering\nbehaviors, we show that LLMs can emulate analyst-style logic, highlight red\nflags, and provide coherent explanations. While this study is exploratory, it\nillustrates the potential of LLM-based graph reasoning in AML and lays\ngroundwork for explainable, language-driven financial crime analytics.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u63a8\u7406\u5f15\u64ce\uff0c\u5904\u7406\u4ece\u91d1\u878d\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63d0\u53d6\u7684\u5c40\u90e8\u5b50\u56fe\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7ba1\u9053\uff0c\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u63d0\u793aLLM\u8bc4\u4f30\u53ef\u7591\u6027\u548c\u751f\u6210\u7406\u7531\uff0c\u5c55\u793a\u4e86LLM\u5728\u53cd\u6d17\u94b1\uff08AML\uff09\u573a\u666f\u4e2d\u6a21\u62df\u5206\u6790\u5e08\u903b\u8f91\u3001\u7a81\u51fa\u7ea2\u65d7\u5e76\u63d0\u4f9b\u8fde\u8d2f\u89e3\u91ca\u7684\u80fd\u529b\u3002", "motivation": "\u6d17\u94b1\u5b9e\u4f53\u7684\u590d\u6742\u6027\u548c\u4e92\u8054\u6027\u8981\u6c42\u5bf9\u56fe\u7ed3\u6784\u6570\u636e\u8fdb\u884c\u8c03\u67e5\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7ba1\u9053\uff0c\u68c0\u7d22\u611f\u5174\u8da3\u5b9e\u4f53\u5468\u56f4\u7684k\u8df3\u90bb\u57df\uff0c\u5c06\u5b83\u4eec\u5e8f\u5217\u5316\u4e3a\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u63d0\u793aLLM\u8bc4\u4f30\u53ef\u7591\u6027\u548c\u751f\u6210\u7406\u7531\u3002", "result": "LLMs\u53ef\u4ee5\u6a21\u4eff\u5206\u6790\u5e08\u98ce\u683c\u7684\u903b\u8f91\uff0c\u7a81\u51fa\u7ea2\u706f\uff0c\u5e76\u63d0\u4f9b\u8fde\u8d2f\u7684\u89e3\u91ca\uff0c\u53cd\u6620\u4e86\u5e38\u89c1\u7684\u6d17\u94b1\u884c\u4e3a\u3002", "conclusion": "\u672c\u7814\u7a76\u867d\u7136\u63a2\u7d22\u6027\uff0c\u4f46\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u7684\u56fe\u63a8\u7406\u5728AML\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u8bed\u8a00\u9a71\u52a8\u578b\u91d1\u878d\u72af\u7f6a\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15239", "pdf": "https://arxiv.org/pdf/2507.15239", "abs": "https://arxiv.org/abs/2507.15239", "authors": ["Qianchao Wang", "Yuxuan Ding", "Chuanzhen Jia", "Zhe Li", "Yaping Du"], "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis", "categories": ["cs.AI", "eess.SP"], "comment": null, "summary": "Novel AI-based arc fault diagnosis models have demonstrated outstanding\nperformance in terms of classification accuracy. However, an inherent problem\nis whether these models can actually be trusted to find arc faults. In this\nlight, this work proposes a soft evaluation indicator that explains the outputs\nof arc fault diagnosis models, by defining the the correct explanation of arc\nfaults and leveraging Explainable Artificial Intelligence and real arc fault\nexperiments. Meanwhile, a lightweight balanced neural network is proposed to\nguarantee competitive accuracy and soft feature extraction score. In our\nexperiments, several traditional machine learning methods and deep learning\nmethods across two arc fault datasets with different sample times and noise\nlevels are utilized to test the effectiveness of the soft evaluation indicator.\nThrough this approach, the arc fault diagnosis models are easy to understand\nand trust, allowing practitioners to make informed and trustworthy decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u548c\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u66f4\u6613\u7406\u89e3\u4e0e\u4fe1\u8d56\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eAI\u7684\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u5728\u5206\u7c7b\u51c6\u786e\u5ea6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u662f\u5426\u80fd\u771f\u6b63\u53ef\u9760\u5730\u53d1\u73b0\u7535\u5f27\u6545\u969c\u4ecd\u662f\u4e00\u4e2a\u56fa\u6709\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u89e3\u91ca\u8fd9\u4e9b\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u5e76\u786e\u4fdd\u5176\u7ed3\u679c\u53ef\u4ee5\u88ab\u4fe1\u4efb\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6f\u8bc4\u4ef7\u6307\u6807\uff0c\u901a\u8fc7\u5b9a\u4e49\u6b63\u786e\u7684\u7535\u5f27\u6545\u969c\u89e3\u91ca\u5e76\u7ed3\u5408\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u548c\u5b9e\u9645\u7535\u5f27\u6545\u969c\u5b9e\u9a8c\u6765\u89e3\u91ca\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u7684\u8f93\u51fa\u3002\u540c\u65f6\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5e73\u8861\u795e\u7ecf\u7f51\u7edc\u4ee5\u4fdd\u8bc1\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u548c\u8f6f\u7279\u5f81\u63d0\u53d6\u5206\u6570\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4e24\u4e2a\u5177\u6709\u4e0d\u540c\u6837\u672c\u65f6\u95f4\u548c\u566a\u58f0\u6c34\u5e73\u7684\u7535\u5f27\u6545\u969c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u8f6f\u8bc4\u4ef7\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u7535\u5f27\u6545\u969c\u8bca\u65ad\u6a21\u578b\u53d8\u5f97\u5bb9\u6613\u7406\u89e3\u5e76\u4e14\u53ef\u4fe1\uff0c\u4f7f\u5f97\u4ece\u4e1a\u8005\u80fd\u591f\u505a\u51fa\u660e\u667a\u4e14\u53ef\u4fe1\u8d56\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.14793", "pdf": "https://arxiv.org/pdf/2507.14793", "abs": "https://arxiv.org/abs/2507.14793", "authors": ["T. Anderson Keller"], "title": "Flow Equivariant Recurrent Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Data arrives at our senses as a continuous stream, smoothly transforming from\none instant to the next. These smooth transformations can be viewed as\ncontinuous symmetries of the environment that we inhabit, defining equivalence\nrelations between stimuli over time. In machine learning, neural network\narchitectures that respect symmetries of their data are called equivariant and\nhave provable benefits in terms of generalization ability and sample\nefficiency. To date, however, equivariance has been considered only for static\ntransformations and feed-forward networks, limiting its applicability to\nsequence models, such as recurrent neural networks (RNNs), and corresponding\ntime-parameterized sequence transformations. In this work, we extend\nequivariant network theory to this regime of `flows' -- one-parameter Lie\nsubgroups capturing natural transformations over time, such as visual motion.\nWe begin by showing that standard RNNs are generally not flow equivariant:\ntheir hidden states fail to transform in a geometrically structured manner for\nmoving stimuli. We then show how flow equivariance can be introduced, and\ndemonstrate that these models significantly outperform their non-equivariant\ncounterparts in terms of training speed, length generalization, and velocity\ngeneralization, on both next step prediction and sequence classification. We\npresent this work as a first step towards building sequence models that respect\nthe time-parameterized symmetries which govern the world around us.", "AI": {"tldr": "\u672c\u6587\u5c06\u7b49\u53d8\u7f51\u7edc\u7406\u8bba\u6269\u5c55\u5230'\u6d41'\u7684\u9886\u57df\uff0c\u901a\u8fc7\u5f15\u5165\u6d41\u7b49\u53d8\u6027\uff0c\u4f7f\u5f97\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u957f\u5ea6\u6cdb\u5316\u548c\u901f\u5ea6\u6cdb\u5316\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u975e\u7b49\u53d8\u6a21\u578b\u3002", "motivation": "\u7b49\u53d8\u7f51\u7edc\u5728\u9759\u6001\u53d8\u6362\u548c\u524d\u9988\u7f51\u7edc\u4e2d\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6837\u672c\u6548\u7387\uff0c\u4f46\u5176\u5728\u5e8f\u5217\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u9650\u5236\u3002\u4e3a\u4e86\u63d0\u9ad8RNNs\u5bf9\u65f6\u95f4\u53c2\u6570\u5316\u7684\u8fde\u7eed\u53d8\u6362\u7684\u5904\u7406\u80fd\u529b\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u5982\u4f55\u4f7f\u5b83\u4eec\u9002\u5e94\u8fd9\u4e9b\u53d8\u6362\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8bc1\u660e\u4e86\u6807\u51c6RNN\u901a\u5e38\u4e0d\u662f\u6d41\u7b49\u53d8\u7684\uff0c\u7136\u540e\u4ecb\u7ecd\u4e86\u5982\u4f55\u5f15\u5165\u6d41\u7b49\u53d8\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u6539\u8fdb\u7684\u6548\u679c\u3002", "result": "\u5728\u4e0b\u4e00\u6b65\u9884\u6d4b\u548c\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u7b49\u53d8\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u957f\u5ea6\u6cdb\u5316\u548c\u901f\u5ea6\u6cdb\u5316\u65b9\u9762\u5747\u4f18\u4e8e\u975e\u7b49\u53d8\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u6784\u5efa\u5c0a\u91cd\u65f6\u95f4\u53c2\u6570\u5316\u5bf9\u79f0\u6027\u7684\u5e8f\u5217\u6a21\u578b\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2507.15253", "pdf": "https://arxiv.org/pdf/2507.15253", "abs": "https://arxiv.org/abs/2507.15253", "authors": ["Zhaochen Guo", "Zhixiang Shen", "Xuanting Xie", "Liangjian Wen", "Zhao Kang"], "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering", "categories": ["cs.AI", "cs.LG", "cs.SI"], "comment": "Appear in ACM Multimedia 2025", "summary": "Multimodal graphs, which integrate unstructured heterogeneous data with\nstructured interconnections, offer substantial real-world utility but remain\ninsufficiently explored in unsupervised learning. In this work, we initiate the\nstudy of multimodal graph clustering, aiming to bridge this critical gap.\nThrough empirical analysis, we observe that real-world multimodal graphs often\nexhibit hybrid neighborhood patterns, combining both homophilic and\nheterophilic relationships. To address this challenge, we propose a novel\nframework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which\ndecomposes the original hybrid graph into two complementary views: (1) a\nhomophily-enhanced graph that captures cross-modal class consistency, and (2)\nheterophily-aware graphs that preserve modality-specific inter-class\ndistinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism\nthat jointly filters these disentangled graphs through a dual-pass strategy,\nenabling effective multimodal integration while mitigating category confusion.\nOur self-supervised alignment objectives further guide the learning process\nwithout requiring labels. Extensive experiments on both multimodal and\nmulti-relational graph datasets demonstrate that DMGC achieves state-of-the-art\nperformance, highlighting its effectiveness and generalizability across diverse\nsettings. Our code is available at https://github.com/Uncnbb/DMGC.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6DMGC\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u56fe\u805a\u7c7b\u4e2d\u7684\u6df7\u5408\u90bb\u57df\u6a21\u5f0f\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u56fe\u5e76\u5f15\u5165\u591a\u6a21\u6001\u53cc\u9891\u878d\u5408\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u7c7b\u522b\u4e00\u81f4\u6027\u4e0e\u533a\u5206\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u56fe\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u63a2\u7d22\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5f02\u6784\u6570\u636e\u548c\u7ed3\u6784\u5316\u4e92\u8fde\u65f6\u3002\u4f5c\u8005\u89c2\u5bdf\u5230\u5b9e\u9645\u591a\u6a21\u6001\u56fe\u5e38\u8868\u73b0\u51fa\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u5173\u7cfb\u6df7\u5408\u7684\u90bb\u57df\u6a21\u5f0f\uff0c\u8fd9\u662f\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u7684\u6311\u6218\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Disentangled Multimodal Graph Clustering (DMGC)\u6846\u67b6\uff0c\u5c06\u539f\u59cb\u6df7\u5408\u56fe\u5206\u89e3\u4e3a\u540c\u8d28\u6027\u589e\u5f3a\u56fe\u548c\u5f02\u8d28\u6027\u611f\u77e5\u56fe\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u6a21\u6001\u53cc\u9891\u878d\u5408\u673a\u5236\u6765\u8fc7\u6ee4\u8fd9\u4e9b\u89e3\u8026\u56fe\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u591a\u6a21\u6001\u6574\u5408\u548c\u51cf\u5c11\u7c7b\u522b\u6df7\u6dc6\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDMGC\u5728\u591a\u6a21\u6001\u548c\u591a\u5173\u7cfb\u56fe\u6570\u636e\u96c6\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DMGC\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u591a\u6a21\u6001\u56fe\u805a\u7c7b\u4e2d\u7684\u6df7\u5408\u90bb\u57df\u6a21\u5f0f\u95ee\u9898\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u4e86\u4f18\u79c0\u7684\u7c7b\u522b\u4e00\u81f4\u6027\u548c\u533a\u5206\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.14805", "pdf": "https://arxiv.org/pdf/2507.14805", "abs": "https://arxiv.org/abs/2507.14805", "authors": ["Alex Cloud", "Minh Le", "James Chua", "Jan Betley", "Anna Sztyber-Betley", "Jacob Hilton", "Samuel Marks", "Owain Evans"], "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study subliminal learning, a surprising phenomenon where language models\ntransmit behavioral traits via semantically unrelated data. In our main\nexperiments, a \"teacher\" model with some trait T (such as liking owls or being\nmisaligned) generates a dataset consisting solely of number sequences.\nRemarkably, a \"student\" model trained on this dataset learns T. This occurs\neven when the data is filtered to remove references to T. We observe the same\neffect when training on code or reasoning traces generated by the same teacher\nmodel. However, we do not observe the effect when the teacher and student have\ndifferent base models. To help explain our findings, we prove a theoretical\nresult showing that subliminal learning occurs in all neural networks under\ncertain conditions, and demonstrate subliminal learning in a simple MLP\nclassifier. We conclude that subliminal learning is a general phenomenon that\npresents an unexpected pitfall for AI development. Distillation could propagate\nunintended traits, even when developers try to prevent this via data filtering.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u6f5c\u610f\u8bc6\u5b66\u4e60\u73b0\u8c61\uff0c\u5373\u4f7f\u5728\u8bed\u4e49\u4e0d\u76f8\u5173\u7684\u6570\u636e\u4e2d\uff0c\u8bed\u8a00\u6a21\u578b\u4e5f\u80fd\u4f20\u9012\u884c\u4e3a\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u4f7f\u7528\u7531\u5177\u6709\u7279\u5b9a\u7279\u5f81\u7684\u201c\u6559\u5e08\u201d\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u201c\u5b66\u751f\u201d\u6a21\u578b\u65f6\uff0c\u5b66\u751f\u6a21\u578b\u53ef\u4ee5\u5b66\u4f1a\u8fd9\u4e9b\u7279\u5f81\u3002\u8fd9\u4e00\u73b0\u8c61\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4e3aAI\u5f00\u53d1\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u548c\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6f5c\u610f\u8bc6\u5b66\u4e60\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u901a\u8fc7\u8bed\u4e49\u4e0d\u76f8\u5173\u6570\u636e\u4f20\u9012\u884c\u4e3a\u7279\u5f81\u7684\u80fd\u529b\u3002\u8fd9\u6709\u52a9\u4e8e\u63ed\u793aAI\u5f00\u53d1\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u610f\u5916\u98ce\u9669\u3002", "method": "\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u5176\u4e2d\u201c\u6559\u5e08\u201d\u6a21\u578b\u751f\u6210\u4ec5\u5305\u542b\u6570\u5b57\u5e8f\u5217\u7684\u6570\u636e\u96c6\uff0c\u201c\u5b66\u751f\u201d\u6a21\u578b\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u8fd8\u6d4b\u8bd5\u4e86\u4ee3\u7801\u548c\u63a8\u7406\u75d5\u8ff9\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u7684\u6548\u679c\uff0c\u5e76\u6bd4\u8f83\u4e86\u76f8\u540c\u548c\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u6548\u679c\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u89e3\u91ca\u53d1\u73b0\uff0c\u7814\u7a76\u8005\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u7ed3\u679c\uff0c\u8bc1\u660e\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\uff0c\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u4e2d\u90fd\u4f1a\u53d1\u751f\u6f5c\u610f\u8bc6\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u201c\u5b66\u751f\u201d\u6a21\u578b\u80fd\u591f\u4ece\u7531\u201c\u6559\u5e08\u201d\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u4e2d\u5b66\u5230\u5176\u884c\u4e3a\u7279\u5f81\uff0c\u5373\u4f7f\u6570\u636e\u7ecf\u8fc7\u8fc7\u6ee4\u53bb\u9664\u4e86\u5bf9\u7279\u5f81\u7684\u76f4\u63a5\u5f15\u7528\u3002\u6f5c\u610f\u8bc6\u5b66\u4e60\u73b0\u8c61\u4e0d\u4ec5\u9650\u4e8e\u7279\u5b9a\u7c7b\u578b\u7684\u6570\u636e\u6216\u6a21\u578b\uff0c\u800c\u662f\u5728\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u666e\u904d\u5b58\u5728\u3002", "conclusion": "\u6f5c\u610f\u8bc6\u5b66\u4e60\u662f\u4e00\u79cd\u666e\u904d\u73b0\u8c61\uff0c\u5b83\u4e3aAI\u5f00\u53d1\u5e26\u6765\u4e86\u610f\u60f3\u4e0d\u5230\u7684\u6311\u6218\u3002\u7279\u522b\u662f\u5728\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u80fd\u4f1a\u4f20\u64ad\u5f00\u53d1\u8005\u8bd5\u56fe\u907f\u514d\u7684\u975e\u9884\u671f\u7279\u6027\uff0c\u5373\u4f7f\u5df2\u7ecf\u5c1d\u8bd5\u901a\u8fc7\u6570\u636e\u8fc7\u6ee4\u6765\u9632\u6b62\u8fd9\u79cd\u60c5\u51b5\u3002"}}
{"id": "2507.15268", "pdf": "https://arxiv.org/pdf/2507.15268", "abs": "https://arxiv.org/abs/2507.15268", "authors": ["Junhyeong Lee", "Joon-Young Kim", "Heekyu Kim", "Inhyo Lee", "Seunghwa Ryu"], "title": "IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The injection molding industry faces critical challenges in preserving and\ntransferring field knowledge, particularly as experienced workers retire and\nmultilingual barriers hinder effective communication. This study introduces\nIM-Chat, a multi-agent framework based on large language models (LLMs),\ndesigned to facilitate knowledge transfer in injection molding. IM-Chat\nintegrates both limited documented knowledge (e.g., troubleshooting tables,\nmanuals) and extensive field data modeled through a data-driven process\ncondition generator that infers optimal manufacturing settings from\nenvironmental inputs such as temperature and humidity, enabling robust and\ncontext-aware task resolution. By adopting a retrieval-augmented generation\n(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat\nensures adaptability without the need for fine-tuning. Performance was assessed\nacross 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and\nGPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance\nand correctness, and was further supplemented by automated evaluation using\nGPT-4o guided by a domain-adapted instruction prompt. The evaluation results\nindicate that more capable models tend to achieve higher accuracy, particularly\nin complex, tool-integrated scenarios. Overall, these findings demonstrate the\nviability of multi-agent LLM systems for industrial knowledge workflows and\nestablish IM-Chat as a scalable and generalizable approach to AI-assisted\ndecision support in manufacturing.", "AI": {"tldr": "IM-Chat\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u6ce8\u5851\u884c\u4e1a\u77e5\u8bc6\u4f20\u627f\u548c\u4ea4\u6d41\u3002\u5b83\u6574\u5408\u4e86\u6587\u6863\u77e5\u8bc6\u548c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\u6761\u4ef6\u751f\u6210\u5668\u5efa\u6a21\u7684\u9886\u57df\u6570\u636e\uff0c\u5e76\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u786e\u4fdd\u9002\u5e94\u6027\u3002\u6027\u80fd\u8bc4\u4f30\u663e\u793a\uff0c\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u591a\u4ee3\u7406LLM\u7cfb\u7edf\u5728\u5de5\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u6d41\u4e2d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u6ce8\u5851\u6210\u578b\u884c\u4e1a\u9762\u4e34\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5de5\u4eba\u9000\u4f11\u548c\u591a\u8bed\u8a00\u969c\u788d\u5bfc\u81f4\u7684\u77e5\u8bc6\u4fdd\u5b58\u548c\u8f6c\u79fb\u6311\u6218\u3002", "method": "IM-Chat\u878d\u5408\u4e86\u6709\u9650\u7684\u6587\u6863\u77e5\u8bc6\uff08\u5982\u6545\u969c\u6392\u9664\u8868\u3001\u624b\u518c\uff09\u548c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u8fc7\u7a0b\u6761\u4ef6\u751f\u6210\u5668\u4ece\u73af\u5883\u8f93\u5165\uff08\u5982\u6e29\u5ea6\u548c\u6e7f\u5ea6\uff09\u63a8\u65ad\u51fa\u7684\u6700\u4f73\u5236\u9020\u8bbe\u7f6e\u7684\u5e7f\u6cdb\u9886\u57df\u6570\u636e\u3002\u5b83\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b56\u7565\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u5728\u4e00\u4e2a\u6a21\u5757\u5316\u67b6\u6784\u4e2d\u5b9e\u73b0\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u8868\u660e\uff0c\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u503e\u5411\u4e8e\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u96c6\u6210\u5de5\u5177\u7684\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u591a\u4ee3\u7406LLM\u7cfb\u7edf\u5728\u5de5\u4e1a\u77e5\u8bc6\u5de5\u4f5c\u6d41\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u786e\u7acb\u4e86IM-Chat\u4f5c\u4e3aAI\u8f85\u52a9\u51b3\u7b56\u652f\u6301\u5728\u5236\u9020\u4e1a\u4e2d\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14824", "pdf": "https://arxiv.org/pdf/2507.14824", "abs": "https://arxiv.org/abs/2507.14824", "authors": ["Kunyu Yu", "Rui Yang", "Jingchi Liao", "Siqi Li", "Huitao Li", "Irene Li", "Yifan Peng", "Rishikesan Kamaleswaran", "Nan Liu"], "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models have emerged as a powerful approach for processing\nelectronic health records (EHRs), offering flexibility to handle diverse\nmedical data modalities. In this study, we present a comprehensive benchmark\nthat evaluates the performance, fairness, and interpretability of foundation\nmodels, both as unimodal encoders and as multimodal learners, using the\npublicly available MIMIC-IV database. To support consistent and reproducible\nevaluation, we developed a standardized data processing pipeline that\nharmonizes heterogeneous clinical records into an analysis-ready format. We\nsystematically compared eight foundation models, encompassing both unimodal and\nmultimodal models, as well as domain-specific and general-purpose variants. Our\nfindings demonstrate that incorporating multiple data modalities leads to\nconsistent improvements in predictive performance without introducing\nadditional bias. Through this benchmark, we aim to support the development of\neffective and trustworthy multimodal artificial intelligence (AI) systems for\nreal-world clinical applications. Our code is available at\nhttps://github.com/nliulab/MIMIC-Multimodal.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7MIMIC-IV\u6570\u636e\u5e93\u8bc4\u4f30\u4e86\u57fa\u7840\u6a21\u578b\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u89e3\u91ca\u6027\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u6570\u636e\u80fd\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u4e14\u4e0d\u589e\u52a0\u504f\u5dee\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u5305\u542b\u591a\u6837\u5316\u7684\u533b\u7597\u6570\u636e\u7c7b\u578b\uff0c\u9700\u8981\u4e00\u4e2a\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u4e9b\u6570\u636e\u3002\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u65b9\u6cd5\u51fa\u73b0\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5355\u6a21\u6001\u7f16\u7801\u5668\u548c\u591a\u6a21\u6001\u5b66\u4e60\u8005\u4f7f\u7528\uff0c\u4f46\u5176\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u89e3\u91ca\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u7684MIMIC-IV\u6570\u636e\u5e93\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u5c06\u5f02\u6784\u4e34\u5e8a\u8bb0\u5f55\u6574\u5408\u4e3a\u53ef\u7528\u4e8e\u5206\u6790\u7684\u683c\u5f0f\u3002\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e868\u4e2a\u57fa\u7840\u6a21\u578b\uff0c\u5305\u62ec\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4ee5\u53ca\u7279\u5b9a\u9886\u57df\u548c\u901a\u7528\u53d8\u4f53\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u591a\u79cd\u6570\u636e\u6a21\u6001\u53ef\u4ee5\u6301\u7eed\u6539\u5584\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e14\u4e0d\u4f1a\u5f15\u5165\u989d\u5916\u7684\u504f\u5dee\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u65e8\u5728\u652f\u6301\u5f00\u53d1\u6709\u6548\u7684\u3001\u53ef\u4fe1\u8d56\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u4ee5\u7528\u4e8e\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2507.15330", "pdf": "https://arxiv.org/pdf/2507.15330", "abs": "https://arxiv.org/abs/2507.15330", "authors": ["Hammad Atta", "Muhammad Zeeshan Baig", "Yasir Mehmood", "Nadeem Shahzad", "Ken Huang", "Muhammad Aziz Ul Haq", "Muhammad Awais", "Kamal Ahmed"], "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Cognitive Degradation as a novel vulnerability class in agentic\nAI systems. Unlike traditional adversarial external threats such as prompt\ninjection, these failures originate internally, arising from memory starvation,\nplanner recursion, context flooding, and output suppression. These systemic\nweaknesses lead to silent agent drift, logic collapse, and persistent\nhallucinations over time. To address this class of failures, we introduce the\nQorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain\n10), a lifecycle-aware defense framework defined by a six-stage cognitive\ndegradation lifecycle. The framework includes seven runtime controls\n(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger\nproactive mitigation through fallback routing, starvation detection, and memory\nintegrity enforcement. Drawing from cognitive neuroscience, we map agentic\narchitectures to human analogs, enabling early detection of fatigue,\nstarvation, and role collapse. By introducing a formal lifecycle and real-time\nmitigation controls, this work establishes Cognitive Degradation as a critical\nnew class of AI system vulnerability and proposes the first cross-platform\ndefense model for resilient agentic behavior.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4ee3\u7406AI\u7cfb\u7edf\u7684\u6f0f\u6d1e\u7c7b\u522b\u2014\u2014\u8ba4\u77e5\u9000\u5316\uff0c\u4ee5\u53ca\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u7684\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u4ee3\u7406AI\u7cfb\u7edf\u7684\u7814\u7a76\u5927\u591a\u5173\u6ce8\u5916\u90e8\u5a01\u80c1\uff0c\u800c\u5185\u90e8\u5f15\u53d1\u7684\u6545\u969c\u9c9c\u6709\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u65b0\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f15\u5165Qorvex\u5b89\u5168AI\u6846\u67b6\uff08QSAF\u57df10\uff09\uff0c\u5b9a\u4e49\u4e86\u516d\u9636\u6bb5\u7684\u8ba4\u77e5\u9000\u5316\u751f\u547d\u5468\u671f\uff0c\u5e76\u63d0\u51fa\u4e86\u4e03\u4e2a\u8fd0\u884c\u65f6\u63a7\u5236\u63aa\u65bd\uff0c\u4ee5\u5b9e\u65f6\u76d1\u63a7\u4ee3\u7406\u5b50\u7cfb\u7edf\u5e76\u89e6\u53d1\u9884\u9632\u6027\u7f13\u89e3\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u4ee5\u65e9\u671f\u68c0\u6d4b\u5230\u75b2\u52b3\u3001\u9965\u997f\u548c\u89d2\u8272\u5d29\u6e83\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86AI\u7cfb\u7edf\u7684\u5f39\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8ba4\u77e5\u9000\u5316\u662fAI\u7cfb\u7edf\u4e2d\u4e00\u4e2a\u5173\u952e\u7684\u65b0\u6f0f\u6d1e\u7c7b\u522b\uff0cQSAF\u57df10\u4e3a\u5b9e\u73b0\u5f39\u6027\u4ee3\u7406\u884c\u4e3a\u63d0\u4f9b\u4e86\u9996\u4e2a\u8de8\u5e73\u53f0\u9632\u5fa1\u6a21\u578b\u3002"}}
{"id": "2507.14828", "pdf": "https://arxiv.org/pdf/2507.14828", "abs": "https://arxiv.org/abs/2507.14828", "authors": ["Abdul-Kazeem Shamba", "Kerstin Bach", "Gavin Taylor"], "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation", "categories": ["cs.LG", "cs.AI"], "comment": "LDD'25: Learning from Difficult Data Workshop (ECAI 2025)", "summary": "We revisit previous contrastive learning frameworks to investigate the effect\nof introducing an adaptive margin into the contrastive loss function for time\nseries representation learning. Specifically, we explore whether an adaptive\nmargin (eMargin), adjusted based on a predefined similarity threshold, can\nimprove the separation between adjacent but dissimilar time steps and\nsubsequently lead to better performance in downstream tasks. Our study\nevaluates the impact of this modification on clustering performance and\nclassification in three benchmark datasets. Our findings, however, indicate\nthat achieving high scores on unsupervised clustering metrics does not\nnecessarily imply that the learned embeddings are meaningful or effective in\ndownstream tasks. To be specific, eMargin added to InfoNCE consistently\noutperforms state-of-the-art baselines in unsupervised clustering metrics, but\nstruggles to achieve competitive results in downstream classification with\nlinear probing. The source code is publicly available at\nhttps://github.com/sfi-norwai/eMargin.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4e2d\u5f15\u5165\u81ea\u9002\u5e94\u8fb9\u754c\u5bf9\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5c3d\u7ba1\u5728\u65e0\u76d1\u7763\u805a\u7c7b\u5ea6\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u7ebf\u6027\u63a2\u6d4b\u7ed3\u679c\u5374\u4e0d\u5c3d\u5982\u4eba\u610f\u3002", "motivation": "\u63a2\u7a76\u5728\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u7684\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u4e2d\uff0c\u5f15\u5165\u57fa\u4e8e\u9884\u5b9a\u4e49\u76f8\u4f3c\u5ea6\u9608\u503c\u8c03\u6574\u7684\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\uff0c\u662f\u5426\u80fd\u6539\u5584\u76f8\u90bb\u4f46\u4e0d\u540c\u65f6\u95f4\u6b65\u9aa4\u4e4b\u95f4\u7684\u5206\u79bb\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\uff0c\u52a0\u5165\u81ea\u9002\u5e94\u8fb9\u754c\uff08eMargin\uff09\uff0c\u5e76\u6839\u636e\u9884\u5b9a\u4e49\u7684\u76f8\u4f3c\u5ea6\u9608\u503c\u8fdb\u884c\u8c03\u6574\u3002\u7136\u540e\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8fd9\u79cd\u4fee\u6539\u5bf9\u805a\u7c7b\u6027\u80fd\u548c\u5206\u7c7b\u7684\u5f71\u54cd\u3002", "result": "\u5e26\u6709eMargin\u7684InfoNCE\u5728\u65e0\u76d1\u7763\u805a\u7c7b\u5ea6\u91cf\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u4f46\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u65f6\u672a\u80fd\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u81ea\u9002\u5e94\u8fb9\u754c\u867d\u7136\u80fd\u5728\u67d0\u4e9b\u65e0\u76d1\u7763\u5ea6\u91cf\u4e0a\u53d6\u5f97\u9ad8\u5206\uff0c\u4f46\u8fd9\u5e76\u4e0d\u610f\u5473\u7740\u6240\u5b66\u5d4c\u5165\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u662f\u6709\u610f\u4e49\u6216\u6709\u6548\u7684\u3002"}}
{"id": "2507.15351", "pdf": "https://arxiv.org/pdf/2507.15351", "abs": "https://arxiv.org/abs/2507.15351", "authors": ["Zijian Zhao", "Sen Li"], "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms", "categories": ["cs.AI", "cs.ET", "cs.MA"], "comment": null, "summary": "On-demand ride-sharing platforms face the fundamental challenge of\ndynamically bundling passengers with diverse origins and destinations and\nmatching them with vehicles in real time, all under significant uncertainty.\nRecently, MARL has emerged as a promising solution for this problem, leveraging\ndecentralized learning to address the curse of dimensionality caused by the\nlarge number of agents in the ride-hailing market and the resulting expansive\nstate and action spaces. However, conventional MARL-based ride-sharing\napproaches heavily rely on the accurate estimation of Q-values or V-values,\nwhich becomes problematic in large-scale, highly uncertain environments.\nSpecifically, most of these approaches adopt an independent paradigm,\nexacerbating this issue, as each agent treats others as part of the\nenvironment, leading to unstable training and substantial estimation bias in\nvalue functions. To address these challenges, we propose two novel alternative\nmethods that bypass value function estimation. First, we adapt GRPO to\nride-sharing, replacing the PPO baseline with the group average reward to\neliminate critic estimation errors and reduce training bias. Second, inspired\nby GRPO's full utilization of group reward information, we customize the PPO\nframework for ride-sharing platforms and show that, under a homogeneous fleet,\nthe optimal policy can be trained using only one-step rewards - a method we\nterm One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan\nride-hailing dataset demonstrate that both GRPO and OSPO achieve superior\nperformance across most scenarios, efficiently optimizing pickup times and the\nnumber of served orders using simple MLP networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u65b9\u6cd5GRPO\u548cOSPO\uff0c\u4ee5\u7ed5\u8fc7\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eMARL\u7684\u62fc\u8f66\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u3001\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u96be\u4ee5\u51c6\u786e\u4f30\u8ba1Q\u503c\u6216V\u503c\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u4f30\u8ba1\u504f\u5dee\u5927\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u5c06GRPO\u9002\u5e94\u4e8e\u62fc\u8f66\uff0c\u7528\u7fa4\u4f53\u5e73\u5747\u5956\u52b1\u53d6\u4ee3PPO\u57fa\u7ebf\uff1b2\uff09\u5b9a\u5236PPO\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u4e00\u6b65\u5956\u52b1\u8fdb\u884c\u7b56\u7565\u4f18\u5316\uff08OSPO\uff09\u3002", "result": "\u901a\u8fc7\u66fc\u54c8\u987f\u7684\u771f\u5b9e\u6253\u8f66\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660eGRPO\u548cOSPO\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u90fd\u80fd\u53d6\u5f97\u66f4\u4f18\u7684\u8868\u73b0\uff0c\u80fd\u6709\u6548\u4f18\u5316\u63a5\u5ba2\u65f6\u95f4\u548c\u8ba2\u5355\u6570\u91cf\u3002", "conclusion": "\u8fd9\u4e24\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u7ed5\u8fc7\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u7684\u95ee\u9898\uff0c\u5728\u7b80\u5355MLP\u7f51\u7edc\u4e0b\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\uff0c\u4e3a\u89e3\u51b3\u62fc\u8f66\u5e73\u53f0\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.14843", "pdf": "https://arxiv.org/pdf/2507.14843", "abs": "https://arxiv.org/abs/2507.14843", "authors": ["Fang Wu", "Weihao Xuan", "Ximing Lu", "Zaid Harchaoui", "Yejin Choi"], "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u8c03\u67e5RLVR\u7684\u6f5c\u529b\u9650\u5236\uff0c\u53d1\u73b0RLVR\u5728\u63d0\u5347\u7cbe\u5ea6\u7684\u540c\u65f6\u53ef\u80fd\u4f1a\u7f29\u5c0f\u63a2\u7d22\u8303\u56f4\uff0c\u5ffd\u89c6\u6b63\u786e\u7684\u4f46\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u63a2\u8ba8RLVR\u662f\u5426\u771f\u6b63\u6269\u5c55\u4e86\u6a21\u578b\u7684\u63a8\u7406\u8fb9\u754c\uff0c\u8fd8\u662f\u4ec5\u4ec5\u653e\u5927\u4e86\u9ad8\u56de\u62a5\u8f93\u51fa\u3002", "method": "\u63d0\u4f9b\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u8bc6\u522bRLVR\u7684\u7ea6\u675f\uff0c\u5e76\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRLVR\u867d\u7136\u80fd\u63d0\u9ad8pass@1\uff0c\u4f46\u5728\u66f4\u5927\u91c7\u6837\u9884\u7b97\u4e0b\uff0c\u7ecf\u9a8c\u652f\u6301\u7684\u6536\u7f29\u901a\u5e38\u8d85\u8fc7\u5176\u6269\u5f20\uff0c\u672a\u80fd\u6062\u590d\u4ee5\u524d\u5bf9\u57fa\u7840\u6a21\u578b\u53ef\u7528\u7684\u6b63\u786e\u7b54\u6848\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RLVR\u5728\u6269\u5c55\u63a8\u7406\u8303\u56f4\u4e0a\u7684\u6f5c\u5728\u9650\u5236\uff0c\u53ef\u80fd\u9700\u8981\u672a\u6765\u7684\u7b97\u6cd5\u521b\u65b0\u6765\u6253\u7834\u8fd9\u79cd\u65e0\u5f62\u7684\u675f\u7f1a\u3002"}}
{"id": "2507.15356", "pdf": "https://arxiv.org/pdf/2507.15356", "abs": "https://arxiv.org/abs/2507.15356", "authors": ["Lu Guo", "Yixiang Shan", "Zhengbang Zhu", "Qifan Liang", "Lichang Song", "Ting Long", "Weinan Zhang", "Yi Chang"], "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making", "categories": ["cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) enables agents to learn policies from\nfixed datasets, avoiding costly or unsafe environment interactions. However,\nits effectiveness is often limited by dataset sparsity and the lack of\ntransition overlap between suboptimal and expert trajectories, which makes\nlong-horizon planning particularly challenging. Prior solutions based on\nsynthetic data augmentation or trajectory stitching often fail to generalize to\nnovel states and rely on heuristic stitching points. To address these\nchallenges, we propose Retrieval High-quAlity Demonstrations (RAD) for\ndecision-making, which combines non-parametric retrieval with diffusion-based\ngenerative modeling. RAD dynamically retrieves high-return states from the\noffline dataset as target states based on state similarity and return\nestimation, and plans toward them using a condition-guided diffusion model.\nSuch retrieval-guided generation enables flexible trajectory stitching and\nimproves generalization when encountered with underrepresented or\nout-of-distribution states. Extensive experiments confirm that RAD achieves\ncompetitive or superior performance compared to baselines across diverse\nbenchmarks, validating its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5RAD\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u975e\u53c2\u6570\u68c0\u7d22\u548c\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u96c6\u7a00\u758f\u6027\u548c\u8f68\u8ff9\u91cd\u53e0\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cRAD\u5728\u5404\u79cd\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u867d\u7136\u53ef\u4ee5\u907f\u514d\u6602\u8d35\u6216\u4e0d\u5b89\u5168\u7684\u73af\u5883\u4ea4\u4e92\uff0c\u4f46\u5176\u6548\u679c\u5e38\u5e38\u53d7\u5230\u6570\u636e\u96c6\u7a00\u758f\u6027\u548c\u6b21\u4f18\u4e0e\u4e13\u5bb6\u8f68\u8ff9\u4e4b\u95f4\u7f3a\u4e4f\u8fc7\u6e21\u91cd\u53e0\u7684\u9650\u5236\uff0c\u8fd9\u4f7f\u5f97\u957f\u65f6\u57df\u89c4\u5212\u7279\u522b\u5177\u6709\u6311\u6218\u6027\u3002", "method": "RAD\u901a\u8fc7\u7ed3\u5408\u975e\u53c2\u6570\u68c0\u7d22\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u6765\u89e3\u51b3\u95ee\u9898\u3002\u5b83\u52a8\u6001\u5730\u4ece\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u9ad8\u56de\u62a5\u72b6\u6001\u4f5c\u4e3a\u76ee\u6807\u72b6\u6001\uff0c\u5e76\u4f7f\u7528\u6761\u4ef6\u5f15\u5bfc\u7684\u6269\u6563\u6a21\u578b\u8fdb\u884c\u89c4\u5212\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u786e\u8ba4RAD\u5728\u591a\u4e2a\u4e0d\u540c\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "RAD\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5e94\u5bf9\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u9047\u5230\u7684\u6570\u636e\u96c6\u7a00\u758f\u6027\u548c\u8f68\u8ff9\u91cd\u53e0\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u672a\u5145\u5206\u8868\u793a\u6216\u5206\u5e03\u5916\u7684\u72b6\u6001\u65f6\uff0c\u63d0\u9ad8\u4e86\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.14847", "pdf": "https://arxiv.org/pdf/2507.14847", "abs": "https://arxiv.org/abs/2507.14847", "authors": ["Junhan Yu", "Zhunyi Feng", "Junwei Lu", "Tianxi Cai", "Doudou Zhou"], "title": "Time-Aware Attention for Enhanced Electronic Health Records Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Electronic Health Records (EHR) contain valuable clinical information for\npredicting patient outcomes and guiding healthcare decisions. However,\neffectively modeling Electronic Health Records (EHRs) requires addressing data\nheterogeneity and complex temporal patterns. Standard approaches often struggle\nwith irregular time intervals between clinical events. We propose TALE-EHR, a\nTransformer-based framework featuring a novel time-aware attention mechanism\nthat explicitly models continuous temporal gaps to capture fine-grained\nsequence dynamics. To complement this temporal modeling with robust semantics,\nTALE-EHR leverages embeddings derived from standardized code descriptions using\na pre-trained Large Language Model (LLM), providing a strong foundation for\nunderstanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset\ndemonstrate that our approach outperforms state-of-the-art baselines on tasks\nsuch as disease progression forecasting. TALE-EHR underscores the benefit of\nintegrating explicit, continuous temporal modeling with strong semantic\nrepresentations provides a powerful solution for advancing EHR analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6846\u67b6TALE-EHR\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u65b0\u7684\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u673a\u5236\uff0c\u80fd\u6709\u6548\u5904\u7406EHR\u6570\u636e\u7684\u65f6\u95f4\u5f02\u8d28\u6027\u548c\u590d\u6742\u7684\u65f6\u95f4\u6a21\u5f0f\u3002\u901a\u8fc7\u5728MIMIC-IV\u548cPIC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6709\u6548\u7684\u5efa\u6a21\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u5bf9\u4e8e\u9884\u6d4b\u60a3\u8005\u7ed3\u679c\u548c\u6307\u5bfc\u533b\u7597\u51b3\u7b56\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u662f\u6807\u51c6\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9EHR\u4e2d\u7684\u6570\u636e\u5f02\u8d28\u6027\u548c\u590d\u6742\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e34\u5e8a\u4e8b\u4ef6\u4e4b\u95f4\u4e0d\u89c4\u5219\u7684\u65f6\u95f4\u95f4\u9694\u65f6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTALE-EHR\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u57fa\u4e8eTransformer\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u5f0f\u5730\u6a21\u62df\u8fde\u7eed\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u4ece\u800c\u6355\u6349\u5e8f\u5217\u7684\u7ec6\u7c92\u5ea6\u52a8\u6001\u53d8\u5316\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u589e\u5f3a\u8bed\u4e49\u7406\u89e3\uff0cTALE-EHR\u5229\u7528\u9884\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4ece\u6807\u51c6\u5316\u4ee3\u7801\u63cf\u8ff0\u4e2d\u63d0\u53d6\u5d4c\u5165\u8868\u793a\u3002", "result": "\u5728MIMIC-IV\u548cPIC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bf8\u5982\u75be\u75c5\u8fdb\u5c55\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TALE-EHR\u5f3a\u8c03\u4e86\u5c06\u660e\u786e\u7684\u3001\u8fde\u7eed\u7684\u65f6\u95f4\u5efa\u6a21\u4e0e\u5f3a\u5927\u7684\u8bed\u4e49\u8868\u793a\u76f8\u7ed3\u5408\u7684\u597d\u5904\uff0c\u4e3a\u63a8\u8fdbEHR\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.15411", "pdf": "https://arxiv.org/pdf/2507.15411", "abs": "https://arxiv.org/abs/2507.15411", "authors": ["Wissam Gherissi", "Mehdi Acheli", "Joyce El Haddad", "Daniela Grigori"], "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings", "categories": ["cs.AI", "cs.LG"], "comment": "ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia", "summary": "Object-centric predictive process monitoring explores and utilizes\nobject-centric event logs to enhance process predictions. The main challenge\nlies in extracting relevant information and building effective models. In this\npaper, we propose an end-to-end model that predicts future process behavior,\nfocusing on two tasks: next activity prediction and next event time. The\nproposed model employs a graph attention network to encode activities and their\nrelationships, combined with an LSTM network to handle temporal dependencies.\nEvaluated on one reallife and three synthetic event logs, the model\ndemonstrates competitive performance compared to state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u5229\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548cLSTM\u7f51\u7edc\u9884\u6d4b\u672a\u6765\u6d41\u7a0b\u884c\u4e3a\uff0c\u5305\u62ec\u4e0b\u4e00\u4e2a\u6d3b\u52a8\u548c\u4e0b\u4e00\u4e2a\u4e8b\u4ef6\u65f6\u95f4\uff0c\u5e76\u5728\u591a\u4e2a\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u5c55\u793a\u4e86\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u9762\u4e34\u7684\u6311\u6218\u5728\u4e8e\u4ece\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\u5e76\u5efa\u7acb\u6709\u6548\u7684\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08\u7528\u4e8e\u7f16\u7801\u6d3b\u52a8\u53ca\u5176\u5173\u7cfb\uff09\u548cLSTM\u7f51\u7edc\uff08\u5904\u7406\u65f6\u95f4\u4f9d\u8d56\u6027\uff09\u7684\u7aef\u5230\u7aef\u6a21\u578b\u6765\u9884\u6d4b\u672a\u6765\u7684\u6d41\u7a0b\u884c\u4e3a\u3002", "result": "\u5728\u56db\u4e2a\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u4e24\u9879\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u7ade\u4e89\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u8fc7\u7a0b\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u9884\u6d4b\u4e0b\u4e00\u4e2a\u6d3b\u52a8\u548c\u4e8b\u4ef6\u65f6\u95f4\u65b9\u9762\u3002"}}
{"id": "2507.14850", "pdf": "https://arxiv.org/pdf/2507.14850", "abs": "https://arxiv.org/abs/2507.14850", "authors": ["H. M. Sabbir Ahmad", "Ehsan Sabouni", "Alexander Wasilkoff", "Param Budhraja", "Zijian Guo", "Songyuan Zhang", "Chuchu Fan", "Christos Cassandras", "Wenchao Li"], "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We address the problem of safe policy learning in multi-agent safety-critical\nautonomous systems. In such systems, it is necessary for each agent to meet the\nsafety requirements at all times while also cooperating with other agents to\naccomplish the task. Toward this end, we propose a safe Hierarchical\nMulti-Agent Reinforcement Learning (HMARL) approach based on Control Barrier\nFunctions (CBFs). Our proposed hierarchical approach decomposes the overall\nreinforcement learning problem into two levels learning joint cooperative\nbehavior at the higher level and learning safe individual behavior at the lower\nor agent level conditioned on the high-level policy. Specifically, we propose a\nskill-based HMARL-CBF algorithm in which the higher level problem involves\nlearning a joint policy over the skills for all the agents and the lower-level\nproblem involves learning policies to execute the skills safely with CBFs. We\nvalidate our approach on challenging environment scenarios whereby a large\nnumber of agents have to safely navigate through conflicting road networks.\nCompared with existing state of the art methods, our approach significantly\nimproves the safety achieving near perfect (within 5%) success/safety rate\nwhile also improving performance across all the environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b89\u5168\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u3002\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u5e76\u6539\u5584\u4e86\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5173\u952e\u5b89\u5168\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u95ee\u9898\uff0c\u786e\u4fdd\u6bcf\u4e2a\u667a\u80fd\u4f53\u5728\u4efb\u4f55\u65f6\u5019\u90fd\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u540c\u65f6\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u534f\u4f5c\u5b8c\u6210\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b89\u5168\u7684\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08HMARL\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08CBFs\uff09\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5c42\u6b21\uff1a\u9ad8\u5c42\u6b21\u5b66\u4e60\u8054\u5408\u5408\u4f5c\u884c\u4e3a\uff0c\u4f4e\u5c42\u6b21\u5b66\u4e60\u4e2a\u4f53\u5b89\u5168\u884c\u4e3a\u3002", "result": "\u4e0e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u8fbe\u5230\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6210\u529f/\u5b89\u5168\u7387\uff08\u8bef\u5dee\u57285%\u4ee5\u5185\uff09\uff0c\u5e76\u5728\u6240\u6709\u73af\u5883\u4e2d\u90fd\u6539\u5584\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5176\u4e2d\u5927\u91cf\u667a\u80fd\u4f53\u9700\u8981\u901a\u8fc7\u51b2\u7a81\u7684\u9053\u8def\u7f51\u7edc\u5b89\u5168\u5bfc\u822a\u3002"}}
{"id": "2507.15457", "pdf": "https://arxiv.org/pdf/2507.15457", "abs": "https://arxiv.org/abs/2507.15457", "authors": ["Orlenys L\u00f3pez-Pintado", "Jannis Rosenbaum", "Marlon Dumas"], "title": "Optimization of Activity Batching Policies in Business Processes", "categories": ["cs.AI", "I.2.8"], "comment": null, "summary": "In business processes, activity batching refers to packing multiple activity\ninstances for joint execution. Batching allows managers to trade off cost and\nprocessing effort against waiting time. Larger and less frequent batches may\nlower costs by reducing processing effort and amortizing fixed costs, but they\ncreate longer waiting times. In contrast, smaller and more frequent batches\nreduce waiting times but increase fixed costs and processing effort. A batching\npolicy defines how activity instances are grouped into batches and when each\nbatch is activated. This paper addresses the problem of discovering batching\npolicies that strike optimal trade-offs between waiting time, processing\neffort, and cost. The paper proposes a Pareto optimization approach that starts\nfrom a given set (possibly empty) of activity batching policies and generates\nalternative policies for each batched activity via intervention heuristics.\nEach heuristic identifies an opportunity to improve an activity's batching\npolicy with respect to a metric (waiting time, processing time, cost, or\nresource utilization) and an associated adjustment to the activity's batching\npolicy (the intervention). The impact of each intervention is evaluated via\nsimulation. The intervention heuristics are embedded in an optimization\nmeta-heuristic that triggers interventions to iteratively update the Pareto\nfront of the interventions identified so far. The paper considers three\nmeta-heuristics: hill-climbing, simulated annealing, and reinforcement\nlearning. An experimental evaluation compares the proposed approach based on\nintervention heuristics against the same (non-heuristic guided) meta-heuristics\nbaseline regarding convergence, diversity, and cycle time gain of\nPareto-optimal policies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\u6765\u53d1\u73b0\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5e72\u9884\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u4e09\u79cd\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08\u722c\u5c71\u6cd5\u3001\u6a21\u62df\u9000\u706b\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u751f\u6210\u66ff\u4ee3\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u5728\u4e1a\u52a1\u6d41\u7a0b\u4e2d\uff0c\u6d3b\u52a8\u6279\u5904\u7406\u6d89\u53ca\u5230\u5c06\u591a\u4e2a\u6d3b\u52a8\u5b9e\u4f8b\u6253\u5305\u5728\u4e00\u8d77\u8fdb\u884c\u8054\u5408\u6267\u884c\u3002\u8fd9\u79cd\u505a\u6cd5\u53ef\u4ee5\u964d\u4f4e\u5904\u7406\u6210\u672c\uff0c\u4f46\u4f1a\u589e\u52a0\u7b49\u5f85\u65f6\u95f4\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u7b49\u5f85\u65f6\u95f4\u3001\u5904\u7406\u52aa\u529b\u548c\u6210\u672c\u7684\u6279\u5904\u7406\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ece\u7ed9\u5b9a\u7684\u4e00\u7ec4\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u5f00\u59cb\uff0c\u901a\u8fc7\u5e72\u9884\u542f\u53d1\u5f0f\u65b9\u6cd5\u751f\u6210\u6bcf\u4e2a\u6279\u5904\u7406\u6d3b\u52a8\u7684\u66ff\u4ee3\u7b56\u7565\u3002\u7136\u540e\uff0c\u8fd9\u4e9b\u5e72\u9884\u63aa\u65bd\u7684\u5f71\u54cd\u901a\u8fc7\u4eff\u771f\u8fdb\u884c\u8bc4\u4f30\u3002\u5e72\u9884\u542f\u53d1\u5f0f\u65b9\u6cd5\u88ab\u5d4c\u5165\u5230\u4e00\u4e2a\u4f18\u5316\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e2d\uff0c\u4ee5\u8fed\u4ee3\u5730\u66f4\u65b0\u76ee\u524d\u8bc6\u522b\u51fa\u7684\u5e72\u9884\u63aa\u65bd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5e72\u9884\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u51fa\u7684\u5e15\u7d2f\u6258\u4f18\u5316\u65b9\u6cd5\u4e0e\u76f8\u540c\u7684\uff08\u975e\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\uff09\u5143\u542f\u53d1\u5f0f\u57fa\u7ebf\u5728\u6536\u655b\u6027\u3001\u591a\u6837\u6027\u548c\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u7684\u5468\u671f\u65f6\u95f4\u589e\u76ca\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5bfb\u627e\u6700\u4f73\u7684\u6d3b\u52a8\u6279\u5904\u7406\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u7279\u522b\u662f\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u6539\u8fdb\u73b0\u6709\u7684\u7b56\u7565\u3002\u7136\u800c\uff0c\u5177\u4f53\u7684\u6027\u80fd\u63d0\u5347\u53d6\u51b3\u4e8e\u6240\u4f7f\u7528\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u9009\u62e9\u3002"}}
{"id": "2507.14874", "pdf": "https://arxiv.org/pdf/2507.14874", "abs": "https://arxiv.org/abs/2507.14874", "authors": ["Ole-Christoffer Granmo", "Youmna Abdelwahab", "Per-Arne Andersen", "Paul F. A. Clarke", "Kunal Dumbre", "Ylva Gr\u00f8nnins\u00e6ter", "Vojtech Halenka", "Runar Helin", "Lei Jiao", "Ahmed Khalid", "Rebekka Omslandseter", "Rupsa Saha", "Mayur Shende", "Xuan Zhang"], "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages, 10 figures", "summary": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine\n(TM) both interpretable and efficient, while the power of Tsetlin automata\nenables accuracy comparable to deep learning on an increasing number of\ndatasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning\ninterpretable deep clauses from graph-structured input. Moving beyond flat,\nfixed-length input, the GraphTM gets more versatile, supporting sequences,\ngrids, relations, and multimodality. Through message passing, the GraphTM\nbuilds nested deep clauses to recognize sub-graph patterns with exponentially\nfewer clauses, increasing both interpretability and data utilization. For image\nclassification, GraphTM preserves interpretability and achieves 3.86%-points\nhigher accuracy on CIFAR-10 than a convolutional TM. For tracking action\ncoreference, faced with increasingly challenging tasks, GraphTM outperforms\nother reinforcement learning methods by up to 20.6%-points. In recommendation\nsystems, it tolerates increasing noise to a greater extent than a Graph\nConvolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains\naccuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence\ndata, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training\n2.5x faster than GCN. The GraphTM's application to these varied fields\ndemonstrates how graph representation learning and deep clauses bring new\npossibilities for TM learning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Graph Tsetlin Machine (GraphTM)\uff0c\u5b83\u80fd\u4ece\u56fe\u7ed3\u6784\u8f93\u5165\u4e2d\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b50\u53e5\u3002\u901a\u8fc7\u4fe1\u606f\u4f20\u9012\uff0cGraphTM\u6784\u5efa\u5d4c\u5957\u7684\u6df1\u5ea6\u5b50\u53e5\u6765\u8bc6\u522b\u5b50\u56fe\u6a21\u5f0f\u3002GraphTM\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u52a8\u4f5c\u8ddf\u8e2a\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\u5904\u7406\u4e0a\u5747\u8868\u73b0\u51fa\u8272\u3002", "motivation": "Tsetlin Machine (TM)\u7531\u4e8e\u5176\u7b80\u6d01\u548c\u5e73\u5766\u7684AND\u89c4\u5219\u800c\u5177\u6709\u9ad8\u6548\u7684\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u3002\u7136\u800c\uff0c\u5b83\u4ec5\u9650\u4e8e\u5e73\u5766\u4e14\u957f\u5ea6\u56fa\u5b9a\u7684\u8f93\u5165\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u5f15\u5165\u4e00\u79cd\u6539\u8fdb\u7248\u7684TM\uff0c\u5373GraphTM\uff0c\u5b83\u53ef\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u6570\u636e\u7ed3\u6784\uff0c\u5982\u56fe\u7ed3\u6784\uff0c\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "method": "GraphTM\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u673a\u5236\u4ece\u56fe\u7ed3\u6784\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u6784\u5efa\u5d4c\u5957\u7684\u6df1\u5ea6\u5b50\u53e5\u4ee5\u8bc6\u522b\u5b50\u56fe\u6a21\u5f0f\u3002\u8fd9\u4f7f\u5f97GraphTM\u80fd\u591f\u7528\u6307\u6570\u7ea7\u66f4\u5c11\u7684\u5b50\u53e5\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u597d\u7684\u6570\u636e\u5229\u7528\u3002", "result": "GraphTM\u5728\u591a\u4e2a\u9886\u57df\u7684\u4efb\u52a1\u4e2d\u90fd\u53d6\u5f97\u4e86\u826f\u597d\u7684\u7ed3\u679c\uff1a\n- \u56fe\u50cf\u5206\u7c7b\uff08CIFAR-10\uff09\uff1a\u6bd4\u5377\u79efTM\u9ad83.86%\uff1b\n- \u52a8\u4f5c\u8ddf\u8e2a\uff1a\u4f18\u4e8e\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd520.6%\uff1b\n- \u63a8\u8350\u7cfb\u7edf\uff1a\u5728\u566a\u58f0\u6bd4\u4f8b\u4e3a0.1\u65f6\uff0c\u51c6\u786e\u6027\u8fbe\u523089.86%\uff0c\u800cGCN\u4e3a70.87%\uff1b\n- \u75c5\u6bd2\u57fa\u56e0\u7ec4\u5e8f\u5217\u6570\u636e\uff1a\u4e0eBiLSTM-CNN\u548cGCN\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u8bad\u7ec3\u901f\u5ea6\u662fGCN\u76842.5\u500d\u3002", "conclusion": "GraphTM\u7684\u5e94\u7528\u5c55\u793a\u4e86\u56fe\u8868\u793a\u5b66\u4e60\u548c\u6df1\u5ea6\u5b50\u53e5\u7ed9TM\u5b66\u4e60\u5e26\u6765\u7684\u65b0\u673a\u9047\u3002GraphTM\u4e0d\u4ec5\u4fdd\u6301\u4e86TM\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u4e14\u5728\u5904\u7406\u5404\u79cd\u7c7b\u578b\u7684\u4efb\u52a1\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65b9\u9762\u3002"}}
{"id": "2507.15509", "pdf": "https://arxiv.org/pdf/2507.15509", "abs": "https://arxiv.org/abs/2507.15509", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Yufeng Zhong", "Lin Ma"], "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner", "categories": ["cs.AI", "cs.CV"], "comment": "technical report", "summary": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based\non reinforcement learning fine-tuning has received widespread attention from\nthe community. Previous R1-Style methods mainly focus on mathematical reasoning\nand code intelligence. It is of great research significance to verify their\nadvantages on more general multimodal data. Chart is an important multimodal\ndata type with rich information, which brings important research challenges in\ncomplex reasoning. In this work, we introduce Chart-R1, a chart-domain\nvision-language model with reinforcement learning fine-tuning to enable complex\nchart reasoning. To support Chart-R1, we first propose a novel programmatic\ndata synthesis technology to generate high-quality step-by-step chart reasoning\ndata covering single- and multi-subcharts, which makes up for the lack of\nreasoning data in the chart domain. Then we develop a two-stage training\nstrategy: Chart-COT with step-by-step chain-of-thought supervision, and\nChart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims\nto decompose complex chart reasoning tasks into fine-grained, understandable\nsubtasks through step-by-step supervision, which lays a good foundation for\nimproving the reasoning level of reinforcement learning. Chart-RFT utilize the\ntypical group relative policy optimization strategy, in which a relatively soft\nreward is adopted for numerical response to emphasize the numerical sensitivity\nin the chart domain. We conduct extensive experiments on open-source benchmarks\nand self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental\nresults show that Chart-R1 has significant advantages compared to chart-domain\nmethods, even comparable to open/closed source large-scale models (\\emph{e.g.,\nGPT-4o, Claude-3.5}).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faChart-R1\uff0c\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u56fe\u8868\u9886\u57df\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u5b9e\u73b0\u590d\u6742\u56fe\u8868\u63a8\u7406\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7a0b\u5e8f\u5316\u6570\u636e\u5408\u6210\u6280\u672f\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684R1-Style\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u667a\u80fd\u4e0a\uff0c\u800c\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u5728\u66f4\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u6570\u636e\u4e0a\u7684\u4f18\u52bf\u5177\u6709\u91cd\u8981\u7684\u7814\u7a76\u610f\u4e49\u3002\u56fe\u8868\u4f5c\u4e3a\u4fe1\u606f\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u6570\u636e\u7c7b\u578b\uff0c\u5728\u590d\u6742\u63a8\u7406\u65b9\u9762\u5e26\u6765\u4e86\u91cd\u8981\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Chart-R1\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86\u7a0b\u5e8f\u5316\u6570\u636e\u5408\u6210\u6280\u672f\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u9010\u6b65\u56fe\u8868\u63a8\u7406\u6570\u636e\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1aChart-COT\uff08\u5e26\u6709\u9010\u6b65\u601d\u7ef4\u94fe\u76d1\u7763\uff09\u548cChart-RFT\uff08\u6570\u503c\u654f\u611f\u7684\u5f3a\u5316\u5fae\u8c03\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChart-R1\u76f8\u6bd4\u56fe\u8868\u9886\u57df\u7684\u65b9\u6cd5\u6709\u663e\u8457\u4f18\u52bf\uff0c\u751a\u81f3\u53ef\u4e0e\u5f00\u6e90/\u95ed\u6e90\u7684\u5927\u89c4\u6a21\u6a21\u578b\uff08\u5982GPT-4o\u3001Claude-3.5\uff09\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u6570\u636e\u5408\u6210\u6280\u672f\u548c\u6539\u8fdb\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u56fe\u8868\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\u3002"}}
{"id": "2507.14882", "pdf": "https://arxiv.org/pdf/2507.14882", "abs": "https://arxiv.org/abs/2507.14882", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Amjad Haider", "Daniel G\u00f6rges"], "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 22nd International Conference on Advanced Robotics (ICAR\n  2025)", "summary": "Deep neural networks (DNNs) offer significant versatility and performance\nbenefits, but their widespread adoption is often hindered by high model\ncomplexity and computational demands. Model compression techniques such as\npruning have emerged as promising solutions to these challenges. However, it\nremains critical to ensure that application-specific performance\ncharacteristics are preserved during compression. In structured pruning, where\ngroups of structurally coherent elements are removed, conventional importance\nmetrics frequently fail to maintain these essential performance attributes. In\nthis work, we propose an enhanced importance metric framework that not only\nreduces model size but also explicitly accounts for application-specific\nperformance constraints. We employ multiple strategies to determine the optimal\npruning magnitude for each group, ensuring a balance between compression and\ntask performance. Our approach is evaluated on an autoencoder tasked with\nreconstructing MNIST images. Experimental results demonstrate that the proposed\nmethod effectively preserves task-relevant performance, maintaining the model's\nusability even after substantial pruning, by satisfying the required\napplication-specific criteria.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u526a\u679d\uff0c\u4ee5\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u5e76\u786e\u4fdd\u6ee1\u8db3\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u6027\u80fd\u7ea6\u675f\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u7531\u4e8e\u5176\u9ad8\u6a21\u578b\u590d\u6742\u6027\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u5e7f\u6cdb\u5e94\u7528\u53d7\u5230\u9650\u5236\u3002\u73b0\u6709\u7684\u6a21\u578b\u538b\u7f29\u6280\u672f\u5982\u4fee\u526a\u867d\u7136\u6709\u5e2e\u52a9\uff0c\u4f46\u901a\u5e38\u65e0\u6cd5\u5728\u538b\u7f29\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u5e94\u7528\u7279\u5b9a\u7684\u6027\u80fd\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u589e\u5f3a\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6846\u67b6\uff0c\u91c7\u7528\u591a\u79cd\u7b56\u7565\u6765\u786e\u5b9a\u6bcf\u4e2a\u7ec4\u7684\u6700\u4f73\u4fee\u526a\u5e45\u5ea6\uff0c\u4ece\u800c\u5728\u538b\u7f29\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u4fdd\u6301\u4e86\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u5927\u91cf\u4fee\u526a\u540e\u4e5f\u80fd\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u7528\u6027\uff0c\u5e76\u6ee1\u8db3\u6240\u9700\u7684\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u6807\u51c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u4fdd\u8bc1\u5e94\u7528\u7279\u5b9a\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff0c\u4f7f\u5f97\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u66f4\u52a0\u5e7f\u6cdb\u3002"}}
{"id": "2507.15518", "pdf": "https://arxiv.org/pdf/2507.15518", "abs": "https://arxiv.org/abs/2507.15518", "authors": ["Sizhou Chen", "Shufan Jiang", "Chi Zhang", "Xiao-Lei Zhang", "Xuelong Li"], "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in AI agents that lack\ninitiative and cannot interact with the physical environment. Furthermore,\nthese methods typically require detailed user input to drive the drama. These\nlimitations reduce the interactivity and immersion of online real-time\nperformance. To address the above challenges, we propose HAMLET, a multi-agent\nframework focused on drama creation and online performance. Given a simple\ntopic, the framework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance, we designed an evaluation method to assess three\nprimary aspects, including character performance, narrative quality, and\ninteraction experience. The experimental evaluation shows that HAMLET can\ncreate expressive and coherent theatrical experiences. Our code, dataset and\nmodels are available at https://github.com/HAMLET-2025/HAMLET.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6HAMLET\uff0c\u4ee5\u7b80\u5355\u7684\u4e3b\u9898\u751f\u6210\u53d9\u4e8b\u84dd\u56fe\uff0c\u5e76\u5728\u5728\u7ebf\u8868\u6f14\u671f\u95f4\u8d4b\u4e88\u6f14\u5458\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b\uff0c\u4ee5\u6539\u5584\u4e92\u52a8\u6027\u548c\u6c89\u6d78\u611f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u620f\u5267\u751f\u6210\u65b9\u6cd5\u5bfc\u81f4AI\u4ee3\u7406\u7f3a\u4e4f\u4e3b\u52a8\u6027\u4e14\u65e0\u6cd5\u4e0e\u7269\u7406\u73af\u5883\u4e92\u52a8\uff0c\u5e76\u901a\u5e38\u9700\u8981\u8be6\u7ec6\u7684\u7528\u6237\u8f93\u5165\u6765\u9a71\u52a8\u5267\u60c5\uff0c\u8fd9\u51cf\u5c11\u4e86\u5728\u7ebf\u5b9e\u65f6\u8868\u6f14\u7684\u4e92\u52a8\u6027\u548c\u6c89\u6d78\u611f\u3002", "method": "\u7ed9\u5b9a\u4e00\u4e2a\u7b80\u5355\u7684\u8bdd\u9898\uff0c\u8be5\u6846\u67b6\u4f1a\u751f\u6210\u4e00\u4e2a\u53d9\u4e8b\u84dd\u56fe\uff0c\u6307\u5bfc\u540e\u7eed\u7684\u5373\u5174\u8868\u6f14\u3002\u6bcf\u4e2a\u6f14\u5458\u88ab\u8d4b\u4e88\u81ea\u4e3b\u6027\uff0c\u53ef\u4ee5\u57fa\u4e8e\u81ea\u5df1\u7684\u80cc\u666f\u3001\u76ee\u6807\u548c\u60c5\u611f\u72b6\u6001\u505a\u51fa\u72ec\u7acb\u51b3\u7b56\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u7684\u51b3\u5b9a\u53ef\u4ee5\u901a\u8fc7\u52a8\u4f5c\u6539\u53d8\u573a\u666f\u9053\u5177\u7684\u72b6\u6001\uff0c\u8fd9\u79cd\u53d8\u5316\u4f1a\u88ab\u5e7f\u64ad\u7ed9\u5176\u4ed6\u76f8\u5173\u6f14\u5458\uff0c\u66f4\u65b0\u4ed6\u4eec\u6240\u77e5\u9053\u548c\u5173\u5fc3\u7684\u5185\u5bb9\uff0c\u4ece\u800c\u5f71\u54cd\u4ed6\u4eec\u7684\u4e0b\u4e00\u6b65\u884c\u52a8\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aHAMLET\u53ef\u4ee5\u521b\u5efa\u8868\u8fbe\u4e30\u5bcc\u4e14\u8fde\u8d2f\u7684\u620f\u5267\u4f53\u9a8c\u3002", "conclusion": "\u4f5c\u8005\u8ba4\u4e3a\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u6846\u67b6HAMLET\uff0c\u53ef\u4ee5\u5728\u5728\u7ebf\u5b9e\u65f6\u8868\u6f14\u4e2d\u63d0\u9ad8\u4e92\u52a8\u6027\u548c\u6c89\u6d78\u611f\uff0c\u4e3a\u521b\u9020\u6c89\u6d78\u5f0f\u4e92\u52a8\u620f\u5267\u4f53\u9a8c\u63d0\u4f9b\u4e86\u65b0\u7684\u8def\u5f84\u3002"}}
{"id": "2507.14919", "pdf": "https://arxiv.org/pdf/2507.14919", "abs": "https://arxiv.org/abs/2507.14919", "authors": ["Maximilian Wendlinger", "Kilian Tscharke", "Pascal Debus"], "title": "Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "One of the key obstacles in traditional deep learning is the reduction in\nmodel transparency caused by increasingly intricate model functions, which can\nlead to problems such as overfitting and excessive confidence in predictions.\nWith the advent of quantum machine learning offering possible advances in\ncomputational power and latent space complexity, we notice the same opaque\nbehavior. Despite significant research in classical contexts, there has been\nlittle advancement in addressing the black-box nature of quantum machine\nlearning. Consequently, we approach this gap by building upon existing work in\nclassical uncertainty quantification and initial explorations in quantum\nBayesian modeling to theoretically develop and empirically evaluate techniques\nto map classical uncertainty quantification methods to the quantum machine\nlearning domain. Our findings emphasize the necessity of leveraging classical\ninsights into uncertainty quantification to include uncertainty awareness in\nthe process of designing new quantum machine learning models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u65e8\u5728\u5c06\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9886\u57df\uff0c\u4ee5\u89e3\u51b3\u6a21\u578b\u900f\u660e\u5ea6\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u6a21\u578b\u590d\u6742\u5ea6\u548c\u4e0d\u900f\u660e\u6027\u589e\u52a0\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u62df\u5408\u548c\u9884\u6d4b\u8fc7\u4e8e\u81ea\u4fe1\u7684\u95ee\u9898\u3002\u5c3d\u7ba1\u5728\u7ecf\u5178\u73af\u5883\u4e2d\u5bf9\u6b64\u6709\u5f88\u591a\u7814\u7a76\uff0c\u4f46\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u8fd9\u65b9\u9762\u7684\u8fdb\u5c55\u5f88\u5c11\u3002", "method": "\u4f5c\u8005\u501f\u9274\u4e86\u7ecf\u5178\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5de5\u4f5c\u4ee5\u53ca\u91cf\u5b50\u8d1d\u53f6\u65af\u5efa\u6a21\u7684\u521d\u6b65\u63a2\u7d22\uff0c\u7406\u8bba\u53d1\u5c55\u5e76\u5728\u5b9e\u8bc1\u4e0a\u8bc4\u4f30\u4e86\u5c06\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u6620\u5c04\u5230\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u6280\u672f\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u8bbe\u8ba1\u65b0\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u6709\u5fc5\u8981\u5229\u7528\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u89c1\u89e3\u6765\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u3002", "conclusion": "\u4e3a\u4e86\u63d0\u9ad8\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u900f\u660e\u5ea6\uff0c\u9700\u8981\u7ed3\u5408\u7ecf\u5178\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u8ba4\u77e5\u3002"}}
{"id": "2507.15521", "pdf": "https://arxiv.org/pdf/2507.15521", "abs": "https://arxiv.org/abs/2507.15521", "authors": ["Cole Robertson", "Philip Wolff"], "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning", "categories": ["cs.AI"], "comment": "Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical\n  Appendix and Supplementary Material, and is under review at NeurIPS 2025", "summary": "Do large language models (LLMs) construct and manipulate internal world\nmodels, or do they rely solely on statistical associations represented as\noutput layer token probabilities? We adapt cognitive science methodologies from\nhuman mental models research to test LLMs on pulley system problems using\nTikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical\nadvantage (MA). State-of-the-art models performed marginally but significantly\nabove chance, and their estimates correlated significantly with ground-truth\nMA. Significant correlations between number of pulleys and model estimates\nsuggest that models employed a pulley counting heuristic, without necessarily\nsimulating pulley systems to derive precise values. Study 2 tested this by\nprobing whether LLMs represent global features crucial to MA estimation. Models\nevaluated a functionally connected pulley system against a fake system with\nrandomly placed components. Without explicit cues, models identified the\nfunctional system as having greater MA with F1=0.8, suggesting LLMs could\nrepresent systems well enough to differentiate jumbled from functional systems.\nStudy 3 built on this by asking LLMs to compare functional systems with matched\nsystems which were connected up but which transferred no force to the weight;\nLLMs identified the functional system with F1=0.46, suggesting random guessing.\nInsofar as they may generalize, these findings are compatible with the notion\nthat LLMs manipulate internal world models, sufficient to exploit statistical\nassociations between pulley count and MA (Study 1), and to approximately\nrepresent system components' spatial relations (Study 2). However, they may\nlack the facility to reason over nuanced structural connectivity (Study 3). We\nconclude by advocating the utility of cognitive scientific methods to evaluate\nthe world-modeling capacities of artificial intelligence systems.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u8ba4\u77e5\u79d1\u5b66\u65b9\u6cd5\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6ed1\u8f6e\u7cfb\u7edf\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u5229\u7528\u5185\u90e8\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u4e00\u5b9a\u7a0b\u5ea6\u7684\u63a8\u7406\uff0c\u4f46\u53ef\u80fd\u65e0\u6cd5\u5904\u7406\u590d\u6742\u7684\u7ed3\u6784\u8fde\u63a5\u6027\u3002", "motivation": "\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u6784\u5efa\u548c\u64cd\u4f5c\u5185\u90e8\u4e16\u754c\u6a21\u578b\u8fd8\u662f\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u7edf\u8ba1\u5173\u8054\u3002", "method": "\u6539\u7f16\u6765\u81ea\u4eba\u7c7b\u5fc3\u7406\u6a21\u578b\u7814\u7a76\u7684\u8ba4\u77e5\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u4f7f\u7528TikZ\u6e32\u67d3\u7684\u523a\u6fc0\u6765\u6d4b\u8bd5LLMs\u5728\u6ed1\u8f6e\u7cfb\u7edf\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u7684\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86LLMs\u5728\u4f30\u8ba1\u673a\u68b0\u4f18\u52bf\u3001\u8868\u793a\u5173\u952e\u5168\u5c40\u7279\u5f81\u4ee5\u53ca\u6bd4\u8f83\u529f\u80fd\u7cfb\u7edf\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u4f30\u8ba1\u673a\u68b0\u4f18\u52bf\u65b9\u9762\u7684\u8868\u73b0\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u5e76\u4e14\u4e0e\u5b9e\u9645\u7684\u673a\u68b0\u4f18\u52bf\u6709\u663e\u8457\u7684\u76f8\u5173\u6027\uff1b\u80fd\u591f\u533a\u5206\u4e71\u5e8f\u548c\u529f\u80fd\u6027\u7cfb\u7edf\uff1b\u4f46\u5728\u8bc6\u522b\u529b\u4f20\u9012\u7ed3\u6784\u8fde\u63a5\u7684\u529f\u80fd\u7cfb\u7edf\u65f6\u8868\u73b0\u51fa\u968f\u673a\u731c\u6d4b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u64cd\u7eb5\u5185\u90e8\u4e16\u754c\u6a21\u578b\u4ee5\u5229\u7528\u6ed1\u8f6e\u6570\u91cf\u548c\u673a\u68b0\u4f18\u52bf\u4e4b\u95f4\u7684\u7edf\u8ba1\u5173\u8054\uff0c\u5e76\u8fd1\u4f3c\u8868\u793a\u7cfb\u7edf\u7ec4\u4ef6\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u4f46\u5728\u7ec6\u5fae\u7ed3\u6784\u8fde\u901a\u6027\u63a8\u7406\u4e0a\u53ef\u80fd\u5b58\u5728\u4e0d\u8db3\u3002\u63d0\u5021\u4f7f\u7528\u8ba4\u77e5\u79d1\u5b66\u7684\u65b9\u6cd5\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2507.14980", "pdf": "https://arxiv.org/pdf/2507.14980", "abs": "https://arxiv.org/abs/2507.14980", "authors": ["Tianle Li", "Yongzhi Huang", "Linshan Jiang", "Qipeng Xie", "Chang Liu", "Wenfeng Du", "Lu Wang", "Kaishun Wu"], "title": "FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios", "categories": ["cs.LG", "68T05, 90C26", "I.2.6; I.5.1; I.2.10"], "comment": "ICPP, including appendix", "summary": "Federated Learning (FL) enables decentralized model training while preserving\ndata privacy. Despite its benefits, FL faces challenges with non-identically\ndistributed (non-IID) data, especially in long-tailed scenarios with imbalanced\nclass samples. Momentum-based FL methods, often used to accelerate FL\nconvergence, struggle with these distributions, resulting in biased models and\nmaking FL hard to converge. To understand this challenge, we conduct extensive\ninvestigations into this phenomenon, accompanied by a layer-wise analysis of\nneural network behavior. Based on these insights, we propose FedWCM, a method\nthat dynamically adjusts momentum using global and per-round data to correct\ndirectional biases introduced by long-tailed distributions. Extensive\nexperiments show that FedWCM resolves non-convergence issues and outperforms\nexisting methods, enhancing FL's efficiency and effectiveness in handling\nclient heterogeneity and data imbalance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FedWCM\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u52a8\u91cf\u89e3\u51b3\u4e86\u957f\u5c3e\u5206\u5e03\u5f15\u8d77\u7684\u975e\u6536\u655b\u95ee\u9898\uff0c\u5e76\u5728\u5904\u7406\u5ba2\u6237\u5f02\u6784\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u9762\u5bf9\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u7684\u6570\u636e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u573a\u666f\u4e2d\uff0c\u7c7b\u522b\u6837\u672c\u7684\u4e0d\u5747\u8861\u4f7f\u5f97\u57fa\u4e8e\u52a8\u91cf\u7684FL\u65b9\u6cd5\u96be\u4ee5\u6536\u655b\u5e76\u5bfc\u81f4\u6a21\u578b\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedWCM\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5168\u5c40\u548c\u6bcf\u8f6e\u7684\u6570\u636e\u52a8\u6001\u8c03\u6574\u52a8\u91cf\uff0c\u4ee5\u6821\u6b63\u7531\u957f\u5c3e\u5206\u5e03\u5f15\u5165\u7684\u65b9\u5411\u6027\u504f\u5dee\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedWCM\u89e3\u51b3\u4e86\u975e\u6536\u655b\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5ba2\u6237\u5f02\u6784\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u65b9\u9762\u3002", "conclusion": "FedWCM\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u6570\u636e\u5206\u5e03\u4e0d\u5747\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15532", "pdf": "https://arxiv.org/pdf/2507.15532", "abs": "https://arxiv.org/abs/2507.15532", "authors": ["Kasper Engelen", "Guillermo A. P\u00e9rez", "Marnix Suilen"], "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure", "categories": ["cs.AI"], "comment": "Accepted at ECAI 2025", "summary": "Safe policy improvement (SPI) is an offline reinforcement learning problem in\nwhich a new policy that reliably outperforms the behavior policy with high\nconfidence needs to be computed using only a dataset and the behavior policy.\nMarkov decision processes (MDPs) are the standard formalism for modeling\nenvironments in SPI. In many applications, additional information in the form\nof parametric dependencies between distributions in the transition dynamics is\navailable. We make SPI more data-efficient by leveraging these dependencies\nthrough three contributions: (1) a parametric SPI algorithm that exploits known\ncorrelations between distributions to more accurately estimate the transition\ndynamics using the same amount of data; (2) a preprocessing technique that\nprunes redundant actions from the environment through a game-based abstraction;\nand (3) a more advanced preprocessing technique, based on satisfiability modulo\ntheory (SMT) solving, that can identify more actions to prune. Empirical\nresults and an ablation study show that our techniques increase the data\nefficiency of SPI by multiple orders of magnitude while maintaining the same\nreliability guarantees.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53c2\u6570\u5316SPI\u7b97\u6cd5\u3001\u57fa\u4e8e\u535a\u5f08\u7684\u62bd\u8c61\u9884\u5904\u7406\u6280\u672f\u548c\u57fa\u4e8eSMT\u6c42\u89e3\u7684\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u5b89\u5168\u7b56\u7565\u6539\u8fdb\uff08SPI\uff09\u7684\u6570\u636e\u6548\u7387\u3002", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0c\u8f6c\u6362\u52a8\u6001\u4e2d\u7684\u5206\u5e03\u4e4b\u95f4\u5b58\u5728\u53c2\u6570\u4f9d\u8d56\u6027\u7684\u989d\u5916\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684SPI\u65b9\u6cd5\u6ca1\u6709\u5229\u7528\u8fd9\u4e9b\u4f9d\u8d56\u6027\uff0c\u5bfc\u81f4\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684SPI\u65b9\u6cd5\u6765\u63d0\u9ad8\u6570\u636e\u6548\u7387\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e09\u79cd\u8d21\u732e\uff1a1. \u53c2\u6570\u5316SPI\u7b97\u6cd5\uff0c\u5229\u7528\u5df2\u77e5\u7684\u76f8\u5173\u6027\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u8f6c\u6362\u52a8\u6001\uff1b2. \u57fa\u4e8e\u535a\u5f08\u7684\u62bd\u8c61\u9884\u5904\u7406\u6280\u672f\uff0c\u901a\u8fc7\u4fee\u526a\u73af\u5883\u4e2d\u7684\u5197\u4f59\u52a8\u4f5c\uff1b3. \u57fa\u4e8eSMT\u6c42\u89e3\u7684\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\uff0c\u53ef\u4ee5\u8bc6\u522b\u66f4\u591a\u7684\u53ef\u4fee\u526a\u52a8\u4f5c\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6211\u4eec\u7684\u6280\u672f\u53ef\u4ee5\u5728\u4fdd\u6301\u76f8\u540c\u53ef\u9760\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5c06SPI\u7684\u6570\u636e\u6548\u7387\u63d0\u9ad8\u591a\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86SPI\u7684\u6570\u636e\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u53ef\u9760\u6027\u4fdd\u8bc1\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.14999", "pdf": "https://arxiv.org/pdf/2507.14999", "abs": "https://arxiv.org/abs/2507.14999", "authors": ["Yunfeng Li", "Junhong Liu", "Zhaohui Yang", "Guofu Liao", "Chuyun Zhang"], "title": "Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "10 pages,6 figures", "summary": "False Data Injection Attacks (FDIAs) pose severe security risks to smart\ngrids by manipulating measurement data collected from spatially distributed\ndevices such as SCADA systems and PMUs. These measurements typically exhibit\nNon-Independent and Identically Distributed (Non-IID) characteristics across\ndifferent regions, which significantly challenges the generalization ability of\ndetection models. Traditional centralized training approaches not only face\nprivacy risks and data sharing constraints but also incur high transmission\ncosts, limiting their scalability and deployment feasibility. To address these\nissues, this paper proposes a privacy-preserving federated learning framework,\ntermed Federated Cluster Average (FedClusAvg), designed to improve FDIA\ndetection in Non-IID and resource-constrained environments. FedClusAvg\nincorporates cluster-based stratified sampling and hierarchical communication\n(client-subserver-server) to enhance model generalization and reduce\ncommunication overhead. By enabling localized training and weighted parameter\naggregation, the algorithm achieves accurate model convergence without\ncentralizing sensitive data. Experimental results on benchmark smart grid\ndatasets demonstrate that FedClusAvg not only improves detection accuracy under\nheterogeneous data distributions but also significantly reduces communication\nrounds and bandwidth consumption. This work provides an effective solution for\nsecure and efficient FDIA detection in large-scale distributed power systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u2014\u2014Federated Cluster Average\uff08FedClusAvg\uff09\uff0c\u7528\u4e8e\u6539\u8fdb\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03(Non-IID)\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb(FDIA)\u68c0\u6d4b\u3002\u901a\u8fc7\u57fa\u4e8e\u805a\u7c7b\u7684\u5206\u5c42\u62bd\u6837\u548c\u5c42\u6b21\u5316\u901a\u4fe1\uff0c\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6a21\u578b\u6cdb\u5316\u6027\u80fd\u7684\u63d0\u5347\u548c\u901a\u4fe1\u5f00\u9500\u7684\u51cf\u5c11\uff0c\u540c\u65f6\u907f\u514d\u4e86\u96c6\u4e2d\u654f\u611f\u6570\u636e\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cFedClusAvg\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u51cf\u5c11\u4e86\u901a\u4fe1\u8f6e\u6b21\u548c\u5e26\u5bbd\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7684FDIA\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u7740\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03(Non-IID)\u5e26\u6765\u7684\u6cdb\u5316\u80fd\u529b\u6311\u6218\uff0c\u4ee5\u53ca\u4f20\u7edf\u96c6\u4e2d\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u7684\u9690\u79c1\u98ce\u9669\u3001\u6570\u636e\u5171\u4eab\u9650\u5236\u548c\u9ad8\u4f20\u8f93\u6210\u672c\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u90fd\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aFederated Cluster Average (FedClusAvg)\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u57fa\u4e8e\u805a\u7c7b\u7684\u5206\u5c42\u62bd\u6837\u548c\u5ba2\u6237\u673a-\u5b50\u670d\u52a1\u5668-\u670d\u52a1\u5668\u7684\u5c42\u6b21\u5316\u901a\u4fe1\u673a\u5236\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u5e76\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002\u901a\u8fc7\u672c\u5730\u5316\u8bad\u7ec3\u548c\u52a0\u6743\u53c2\u6570\u805a\u5408\uff0c\u53ef\u4ee5\u5728\u4e0d\u96c6\u4e2d\u654f\u611f\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u51c6\u786e\u7684\u6a21\u578b\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedClusAvg\u4e0d\u4ec5\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u800c\u4e14\u5927\u5e45\u51cf\u5c11\u4e86\u901a\u4fe1\u8f6e\u6b21\u548c\u5e26\u5bbd\u6d88\u8017\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u5b89\u5168\u9ad8\u6548\u5730\u5728\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7535\u529b\u7cfb\u7edf\u4e2d\u8fdb\u884cFDIA\u68c0\u6d4b\u3002"}}
{"id": "2507.15581", "pdf": "https://arxiv.org/pdf/2507.15581", "abs": "https://arxiv.org/abs/2507.15581", "authors": ["Ekaterina Goliakova", "Xavier Renard", "Marie-Jeanne Lesot", "Thibault Laugel", "Christophe Marsala", "Marcin Detyniecki"], "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks", "categories": ["cs.AI"], "comment": null, "summary": "Using multiple-choice questions (MCQs) has become a standard for assessing\nLLM capabilities efficiently. A variety of metrics can be employed for this\ntask. However, previous research has not conducted a thorough assessment of\nthem. At the same time, MCQ evaluation suffers from answer fluctuation: models\nproduce different results given slight changes in prompts. We suggest a metric\nassessment protocol in which evaluation methodologies are analyzed through\ntheir connection with fluctuation rates, as well as original performance. Our\nresults show that there is a strong link between existing metrics and the\nanswer changing, even when computed without any additional prompt variants. A\nnovel metric, worst accuracy, demonstrates the highest association on the\nprotocol.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u5206\u6790MCQ\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u6ce2\u52a8\u7387\u548c\u539f\u59cb\u6027\u80fd\u7684\u5173\u7cfb\u3002\u53d1\u73b0\u73b0\u6709\u6307\u6807\u4e0e\u7b54\u6848\u53d8\u5316\u4e4b\u95f4\u5b58\u5728\u5f3a\u5173\u8054\uff0c\u65b0\u63d0\u51fa\u7684\u6700\u5dee\u51c6\u786e\u5ea6\u6307\u6807\u663e\u793a\u51fa\u6700\u9ad8\u7684\u5173\u8054\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u7814\u7a76\u6ca1\u6709\u5bf9\u8bc4\u4f30LLM\u80fd\u529b\u7684\u591a\u79cd\u6307\u6807\u8fdb\u884c\u5f7b\u5e95\u8bc4\u4f30\uff0c\u540c\u65f6MCQ\u8bc4\u4f30\u5b58\u5728\u7b54\u6848\u6ce2\u52a8\u7684\u95ee\u9898\u3002", "method": "\u5efa\u8bae\u4e00\u4e2a\u8bc4\u4f30\u534f\u8bae\uff0c\u901a\u8fc7\u5206\u6790\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u6ce2\u52a8\u7387\u4ee5\u53ca\u539f\u59cb\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u6765\u8bc4\u4f30MCQ\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u6307\u6807\u4e0e\u7b54\u6848\u53d8\u5316\u4e4b\u95f4\u5b58\u5728\u5f3a\u5173\u8054\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u4efb\u4f55\u989d\u5916\u63d0\u793a\u53d8\u4f53\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u4e5f\u662f\u5982\u6b64\u3002\u65b0\u63d0\u51fa\u7684\u6700\u5dee\u51c6\u786e\u5ea6\u6307\u6807\u5728\u534f\u8bae\u4e2d\u663e\u793a\u51fa\u6700\u9ad8\u7684\u5173\u8054\u6027\u3002", "conclusion": "\u8bc4\u4f30\u534f\u8bae\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3MCQ\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\uff0c\u6700\u5dee\u51c6\u786e\u5ea6\u662f\u4e00\u4e2a\u6709\u6f5c\u529b\u7684\u65b0\u6307\u6807\u3002"}}
{"id": "2507.15066", "pdf": "https://arxiv.org/pdf/2507.15066", "abs": "https://arxiv.org/abs/2507.15066", "authors": ["Yiyuan Yang", "Zichuan Liu", "Lei Song", "Kai Ying", "Zhiguang Wang", "Tom Bamford", "Svitlana Vyetrenko", "Jiang Bian", "Qingsong Wen"], "title": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "categories": ["cs.LG", "cs.AI", "cs.MM"], "comment": "Under review. 19 pages, 8 figures, 12 tables", "summary": "Time series anomaly detection is critical across various domains, yet current\napproaches often limit analysis to mere binary anomaly classification without\ndetailed categorization or further explanatory reasoning. To address these\nlimitations, we propose a novel task, Time-series Reasoning for Anomaly\n(Time-RA) that transforms classical time series anomaly detection from a\ndiscriminative into a generative, reasoning-intensive task leveraging Large\nLanguage Models (LLMs). Also, we introduce the first real-world multimodal\nbenchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,\ncomprising approximately 40,000 samples across 10 real-world domains. Each\nsample includes numeric time series data, contextual text information, and\nvisual representations, each annotated with fine-grained categories (14 types\nfor univariate anomalies and 6 for multivariate anomalies) and structured\nexplanatory reasoning. We develop a sophisticated annotation framework\nutilizing ensemble-generated labels refined through GPT-4-driven feedback,\nensuring accuracy and interpretability. Extensive benchmarking of LLMs and\nmultimodal LLMs demonstrates the capabilities and limitations of current\nmodels, highlighting the critical role of supervised fine-tuning. Our dataset\nand task pave the way for significant advancements in interpretable time series\nanomaly detection and reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1Time-RA\uff0c\u8be5\u4efb\u52a1\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u4f20\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u8f6c\u5316\u4e3a\u751f\u6210\u6027\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4e86\u5e26\u6709\u8be6\u7ec6\u6807\u6ce8\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6RATs40K\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u53ea\u8fdb\u884c\u4e8c\u5143\u5f02\u5e38\u5206\u7c7b\uff0c\u800c\u6ca1\u6709\u8be6\u7ec6\u7684\u5206\u7c7b\u6216\u89e3\u91ca\u6027\u63a8\u7406\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u7ecf\u5178\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u8f6c\u53d8\u4e3a\u751f\u6210\u6027\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u590d\u6742\u7684\u6ce8\u91ca\u6846\u67b6\uff0c\u4f7f\u7528\u96c6\u6210\u751f\u6210\u6807\u7b7e\u5e76\u901a\u8fc7GPT-4\u9a71\u52a8\u7684\u53cd\u9988\u8fdb\u884c\u7ec6\u5316\u3002", "result": "\u5bf9LLMs\u548c\u591a\u6a21\u6001LLMs\u7684\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u548c\u63a8\u7406\u7684\u91cd\u5927\u8fdb\u5c55\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.15618", "pdf": "https://arxiv.org/pdf/2507.15618", "abs": "https://arxiv.org/abs/2507.15618", "authors": ["Weiyu Ma", "Jiwen Jiang", "Haobo Fu", "Haifeng Zhang"], "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II", "categories": ["cs.AI"], "comment": null, "summary": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\uff0c\u7528\u4e8eStarCraft II AI\u4ee3\u7406\u7684\u6218\u672f\u6761\u4ef6\u53cd\u5c04\u3002\u901a\u8fc7\u51bb\u7ed3\u9884\u8bad\u7ec3\u7b56\u7565\u7f51\u7edc\u5e76\u9644\u52a0\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6a21\u5757\uff0c\u53ef\u4ee5\u5b9e\u73b0\u7075\u6d3b\u7684\u6218\u672f\u63a7\u5236\u548c\u6700\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684StarCraft II AI\u4ee3\u7406\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u6839\u636e\u9ad8\u7ea7\u6218\u672f\u6307\u4ee4\u8c03\u6574\u5176\u7b56\u7565\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u6765\u589e\u5f3aAI\u4ee3\u7406\u7684\u6218\u672f\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u4e86\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\uff0c\u51bb\u7ed3\u4e86\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684\u7b56\u7565\u7f51\u7edc\uff08DI-Star\uff09\uff0c\u5e76\u5728\u6bcf\u4e2a\u52a8\u4f5c\u5934\u4e0a\u9644\u52a0\u4e86\u8f7b\u91cf\u7ea7\u7684\u9002\u914d\u5668\u6a21\u5757\u3002\u8fd9\u4e9b\u6a21\u5757\u53d7\u8bad\u4e8e\u4e00\u4e2a\u6218\u672f\u5f20\u91cf\uff0c\u8be5\u5f20\u91cf\u7f16\u7801\u4e86\u6218\u7565\u504f\u597d\uff0c\u5e76\u4e14\u5728KL\u6563\u5ea6\u7ea6\u675f\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u786e\u4fdd\u7b56\u7565\u4fdd\u6301\u6838\u5fc3\u80fd\u529b\u7684\u540c\u65f6\u8868\u73b0\u51fa\u6218\u672f\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u8c03\u8282\u4e86\u4ee3\u7406\u884c\u4e3a\uff0c\u5305\u62ec\u653b\u51fb\u6027\u3001\u6269\u5f20\u6a21\u5f0f\u548c\u6280\u672f\u504f\u597d\u7b49\u6218\u672f\u7ef4\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u5f97\u590d\u6742\u7684\u5373\u65f6\u6218\u7565\u6e38\u620f\u80fd\u591f\u5b9e\u73b0\u7075\u6d3b\u7684\u6218\u672f\u63a7\u5236\u548c\u6700\u4f4e\u9650\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u5b9e\u9645\u7684\u6218\u7565\u5b9a\u5236\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2507.15067", "pdf": "https://arxiv.org/pdf/2507.15067", "abs": "https://arxiv.org/abs/2507.15067", "authors": ["Bing He", "Mustaque Ahamad", "Srijan Kumar"], "title": "ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model", "categories": ["cs.LG", "cs.SI"], "comment": "15 pages, 12 tables", "summary": "Detecting bad actors is critical to ensure the safety and integrity of\ninternet platforms. Several deep learning-based models have been developed to\nidentify such users. These models should not only accurately detect bad actors,\nbut also be robust against adversarial attacks that aim to evade detection.\nHowever, past deep learning-based detection models do not meet the robustness\nrequirement because they are sensitive to even minor changes in the input\nsequence. To address this issue, we focus on (1) improving the model\nunderstanding capability and (2) enhancing the model knowledge such that the\nmodel can recognize potential input modifications when making predictions. To\nachieve these goals, we create a novel transformer-based classification model,\ncalled ROBAD (RObust adversary-aware local-global attended Bad Actor Detection\nmodel), which uses the sequence of user posts to generate user embedding to\ndetect bad actors. Particularly, ROBAD first leverages the transformer encoder\nblock to encode each post bidirectionally, thus building a post embedding to\ncapture the local information at the post level. Next, it adopts the\ntransformer decoder block to model the sequential pattern in the post\nembeddings by using the attention mechanism, which generates the sequence\nembedding to obtain the global information at the sequence level. Finally, to\nenrich the knowledge of the model, embeddings of modified sequences by mimicked\nattackers are fed into a contrastive-learning-enhanced classification layer for\nsequence prediction. In essence, by capturing the local and global information\n(i.e., the post and sequence information) and leveraging the mimicked behaviors\nof bad actors in training, ROBAD can be robust to adversarial attacks.\nExtensive experiments on Yelp and Wikipedia datasets show that ROBAD can\neffectively detect bad actors when under state-of-the-art adversarial attacks.", "AI": {"tldr": "\u4e3a\u4e86\u63d0\u9ad8\u5bf9\u4e0d\u826f\u7528\u6237\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u65b0\u5206\u7c7b\u6a21\u578bROBAD\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u6355\u6349\u5e16\u5b50\u548c\u5e8f\u5217\u7ea7\u522b\u7684\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u5e76\u5229\u7528\u6a21\u62df\u653b\u51fb\u8005\u7684\u884c\u4e3a\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u5206\u7c7b\u5c42\uff0c\u4ece\u800c\u5728\u6700\u5148\u8fdb\u7684\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u6709\u6548\u5730\u68c0\u6d4b\u4e0d\u826f\u7528\u6237\u3002", "motivation": "\u8fc7\u53bb\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u68c0\u6d4b\u6a21\u578b\u867d\u7136\u80fd\u591f\u51c6\u786e\u68c0\u6d4b\u4e0d\u826f\u7528\u6237\uff0c\u4f46\u5bf9\u8f93\u5165\u5e8f\u5217\u4e2d\u7684\u5fae\u5c0f\u53d8\u5316\u975e\u5e38\u654f\u611f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u8981\u6c42\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6539\u8fdb\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u548c\u589e\u5f3a\u6a21\u578b\u77e5\u8bc6\u4ee5\u5e94\u5bf9\u6f5c\u5728\u7684\u8f93\u5165\u4fee\u6539\u3002", "method": "ROBAD\u6a21\u578b\u9996\u5148\u4f7f\u7528\u53d8\u6362\u5668\u7f16\u7801\u5668\u5757\u53cc\u5411\u7f16\u7801\u6bcf\u4e2a\u5e16\u5b50\uff0c\u751f\u6210\u5e16\u5b50\u5d4c\u5165\u4ee5\u6355\u6349\u5e16\u5b50\u7ea7\u522b\u7684\u5c40\u90e8\u4fe1\u606f\u3002\u7136\u540e\uff0c\u5b83\u91c7\u7528\u53d8\u6362\u5668\u89e3\u7801\u5668\u5757\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5efa\u6a21\u5e16\u5b50\u5d4c\u5165\u4e2d\u7684\u987a\u5e8f\u6a21\u5f0f\uff0c\u751f\u6210\u5e8f\u5217\u5d4c\u5165\u4ee5\u83b7\u5f97\u5e8f\u5217\u7ea7\u522b\u7684\u5168\u5c40\u4fe1\u606f\u3002\u6700\u540e\uff0c\u4e3a\u4e86\u4e30\u5bcc\u6a21\u578b\u7684\u77e5\u8bc6\uff0c\u5c06\u6a21\u62df\u653b\u51fb\u8005\u4fee\u6539\u540e\u7684\u5e8f\u5217\u5d4c\u5165\u8f93\u5165\u5230\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u7684\u5206\u7c7b\u5c42\u4e2d\u8fdb\u884c\u5e8f\u5217\u9884\u6d4b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cROBAD\u53ef\u4ee5\u5728\u6700\u65b0\u7684\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u6709\u6548\u68c0\u6d4b\u4e0d\u826f\u7528\u6237\u3002", "conclusion": "ROBAD\u901a\u8fc7\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u5e76\u5229\u7528\u6a21\u62df\u4e0d\u826f\u7528\u6237\u884c\u4e3a\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u4fdd\u6301\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.15676", "pdf": "https://arxiv.org/pdf/2507.15676", "abs": "https://arxiv.org/abs/2507.15676", "authors": ["Reza Vatankhah Barenji", "Sina Khoshgoftar"], "title": "Agentic AI for autonomous anomaly management in complex systems", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4ee3\u7406AI\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u68c0\u6d4b\u548c\u54cd\u5e94\u5f02\u5e38\u7684\u6f5c\u529b\uff0c\u5f3a\u8c03\u5176\u6539\u53d8\u4f20\u7edf\u4f9d\u8d56\u4eba\u7c7b\u7684\u5f02\u5e38\u7ba1\u7406\u65b9\u6cd5\u7684\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u590d\u6742\u7cfb\u7edf\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u7684\u4f9d\u8d56\u4eba\u7c7b\u7684\u5f02\u5e38\u7ba1\u7406\u65b9\u6cd5\u5df2\u7ecf\u4e0d\u80fd\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u81ea\u4e3b\u3001\u66f4\u667a\u80fd\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5f02\u5e38\u60c5\u51b5\u3002", "method": "\u5229\u7528\u4ee3\u7406AI\u6280\u672f\uff0c\u4f7f\u5176\u80fd\u591f\u81ea\u4e3b\u5730\u68c0\u6d4b\u548c\u54cd\u5e94\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u3002", "result": "\u8be5\u7814\u7a76\u53ef\u80fd\u7684\u7ed3\u679c\u662f\u8bc1\u660e\u4ee3\u7406AI\u53ef\u4ee5\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u6709\u6548\u5730\u81ea\u4e3b\u68c0\u6d4b\u548c\u54cd\u5e94\u5f02\u5e38\uff0c\u63d0\u9ad8\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u4ee3\u7406AI\u6709\u53ef\u80fd\u5f7b\u5e95\u6539\u53d8\u6211\u4eec\u5bf9\u590d\u6742\u7cfb\u7edf\u4e2d\u5f02\u5e38\u7684\u7ba1\u7406\u65b9\u5f0f\uff0c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15073", "pdf": "https://arxiv.org/pdf/2507.15073", "abs": "https://arxiv.org/abs/2507.15073", "authors": ["Samuel Pfrommer", "Yixiao Huang", "Somayeh Sojoudi"], "title": "Reinforcement Learning for Flow-Matching Policies", "categories": ["cs.LG"], "comment": null, "summary": "Flow-matching policies have emerged as a powerful paradigm for generalist\nrobotics. These models are trained to imitate an action chunk, conditioned on\nsensor observations and textual instructions. Often, training demonstrations\nare generated by a suboptimal policy, such as a human operator. This work\nexplores training flow-matching policies via reinforcement learning to surpass\nthe original demonstration policy performance. We particularly note\nminimum-time control as a key application and present a simple scheme for\nvariable-horizon flow-matching planning. We then introduce two families of\napproaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group\nRelative Policy Optimization (GRPO) approach with a learned reward surrogate.\nOur policies are trained on an illustrative suite of simulated unicycle\ndynamics tasks, and we show that both approaches dramatically improve upon the\nsuboptimal demonstrator performance, with the GRPO approach in particular\ngenerally incurring between $50\\%$ and $85\\%$ less cost than a naive Imitation\nLearning Flow Matching (ILFM) approach.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u4ee5\u8d85\u8d8a\u539f\u59cb\u6f14\u793a\u7b56\u7565\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u5956\u52b1\u52a0\u6743\u6d41\u5339\u914d\uff08RWFM\uff09\u548c\u5177\u6709\u5b66\u4e60\u5956\u52b1\u4ee3\u7406\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u3002", "motivation": "\u901a\u5e38\uff0c\u8bad\u7ec3\u6f14\u793a\u662f\u7531\u6b21\u4f18\u7b56\u7565\u751f\u6210\u7684\uff0c\u4f8b\u5982\u4eba\u7c7b\u64cd\u4f5c\u5458\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u6765\u8d85\u8d8a\u539f\u59cb\u6f14\u793a\u7b56\u7565\u7684\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u79cd\u7b80\u5355\u7684\u5956\u52b1\u52a0\u6743\u6d41\u5339\u914d\uff08RWFM\uff09\u65b9\u6848\u548c\u4e00\u79cd\u5177\u6709\u5b66\u4e60\u5956\u52b1\u4ee3\u7406\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u65b9\u6cd5\u3002", "result": "\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u6a21\u62df\u7684\u5355\u8f6e\u8f66\u52a8\u529b\u5b66\u4efb\u52a1\u4e2d\u90fd\u663e\u8457\u63d0\u9ad8\u4e86\u6b21\u4f18\u6f14\u793a\u8005\u7684\u6027\u80fd\uff0c\u7279\u522b\u662fGRPO\u65b9\u6cd5\u901a\u5e38\u6bd4\u6734\u7d20\u7684\u6a21\u4eff\u5b66\u4e60\u6d41\u5339\u914d\uff08ILFM\uff09\u65b9\u6cd5\u51cf\u5c1150%\u523085%\u7684\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d41\u5339\u914d\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u5176\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6700\u5c0f\u65f6\u95f4\u63a7\u5236\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u3002"}}
{"id": "2507.15743", "pdf": "https://arxiv.org/pdf/2507.15743", "abs": "https://arxiv.org/abs/2507.15743", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "C\u00edan Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Li\u00e9vin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Jo\u00eblle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "title": "Towards physician-centered oversight of conversational diagnostic AI", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3ag-AMIE\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728\u4e0d\u63d0\u4f9b\u4e2a\u6027\u5316\u533b\u7597\u5efa\u8bae\u7684\u524d\u63d0\u4e0b\u8fdb\u884c\u75c5\u53f2\u91c7\u96c6\uff0c\u5e76\u5c06\u8bc4\u4f30\u7ed3\u679c\u4f20\u8fbe\u7ed9\u4e3b\u6cbb\u533b\u751f\u3002\u901a\u8fc7\u968f\u673a\u3001\u76f2\u76ee\u7684\u865a\u62df\u5ba2\u89c2\u7ed3\u6784\u5316\u4e34\u5e8a\u8003\u8bd5\uff08OSCE\uff09\u6587\u672c\u54a8\u8be2\uff0c\u53d1\u73b0g-AMIE\u5728\u9ad8\u8d28\u91cf\u4fe1\u606f\u6536\u96c6\u3001\u6848\u4f8b\u603b\u7ed3\u548c\u63d0\u51fa\u8bca\u65ad\u53ca\u7ba1\u7406\u8ba1\u5212\u65b9\u9762\u4f18\u4e8e\u62a4\u58eb\u4ece\u4e1a\u8005\u548c\u52a9\u7406\u533b\u751f\u4ee5\u53ca\u4e3b\u6cbb\u533b\u751f\u56e2\u961f\u3002\u8fd9\u5bfc\u81f4\u4e86\u66f4\u9ad8\u7684\u51b3\u7b56\u8d28\u91cf\uff0c\u5e76\u4e14g-AMIE\u7684\u4e3b\u6cbb\u533b\u751f\u76d1\u7763\u6bd4\u4e4b\u524d\u7684\u72ec\u7acb\u4e3b\u6cbb\u533b\u751f\u54a8\u8be2\u66f4\u8282\u7701\u65f6\u95f4\u3002", "motivation": "\u5f53\u524d\u7684\u5bf9\u8bdd\u5f0fAI\u7cfb\u7edf\u5c55\u793a\u4e86\u5176\u5728\u8bca\u65ad\u5bf9\u8bdd\u4e2d\u7684\u6f5c\u529b\uff0c\u4f46\u4e3a\u4e86\u786e\u4fdd\u60a3\u8005\u5b89\u5168\uff0c\u4e2a\u4f53\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\u88ab\u8ba4\u4e3a\u662f\u53d7\u76d1\u7ba1\u7684\u6d3b\u52a8\uff0c\u9700\u8981\u7531\u6709\u6267\u7167\u7684\u4e13\u4e1a\u4eba\u5458\u8fdb\u884c\u3002\u6b64\u5916\uff0c\u533b\u751f\u901a\u5e38\u4f1a\u76d1\u7763\u5176\u4ed6\u56e2\u961f\u6210\u5458\u5982\u62a4\u58eb\u4ece\u4e1a\u8005\u6216\u52a9\u7406\u533b\u751f\u4ece\u4e8b\u8fd9\u4e9b\u6d3b\u52a8\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u6846\u67b6\uff0c\u4ee5\u6709\u6548\u3001\u5f02\u6b65\u5730\u76d1\u7763Articulate Medical Intelligence Explorer (AMIE) AI\u7cfb\u7edf\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aguardrailed-AMIE (g-AMIE)\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u8fd9\u4e2a\u7cfb\u7edf\u5728\u9650\u5b9a\u8303\u56f4\u5185\u6267\u884c\u75c5\u53f2\u91c7\u96c6\u5de5\u4f5c\uff0c\u907f\u514d\u7ed9\u51fa\u4e2a\u6027\u5316\u7684\u533b\u7597\u5efa\u8bae\u3002\u4e4b\u540e\uff0cg-AMIE\u4f1a\u5c06\u8bc4\u4f30\u4f20\u9012\u7ed9\u4e3b\u6cbb\u533b\u751f\uff0c\u4e3b\u6cbb\u533b\u751f\u8d1f\u8d23\u76d1\u7763\u5e76\u4fdd\u6301\u4e34\u5e8a\u51b3\u7b56\u7684\u8d23\u4efb\u3002\u8fd9\u6837\u53ef\u4ee5\u5c06\u76d1\u7763\u4e0e\u521d\u6b21\u63a5\u8bca\u5206\u79bb\u5f00\u6765\uff0c\u4ece\u800c\u5b9e\u73b0\u5f02\u6b65\u64cd\u4f5c\u3002", "result": "\u572860\u4e2a\u573a\u666f\u4e2d\uff0cg-AMIE\u5728\u9ad8\u8d28\u91cf\u7684\u4fe1\u606f\u6536\u96c6\u3001\u603b\u7ed3\u75c5\u4f8b\u548c\u63d0\u51fa\u8bca\u65ad\u53ca\u7ba1\u7406\u8ba1\u5212\u65b9\u9762\u90fd\u8d85\u8fc7\u4e86\u62a4\u58eb\u4ece\u4e1a\u8005/\u52a9\u7406\u533b\u751f\u7ec4\u548c\u4e3b\u6cbb\u533b\u751f\u7ec4\u3002\u8fd9\u79cd\u6539\u8fdb\u4f7f\u5f97\u6700\u7ec8\u7684\u7efc\u5408\u51b3\u7b56\u8d28\u91cf\u66f4\u9ad8\u3002\u6b64\u5916\uff0cg-AMIE\u7684\u4e3b\u6cbb\u533b\u751f\u76d1\u7763\u6bd4\u4ee5\u524d\u7684\u7814\u7a76\u4e2d\u7684\u72ec\u7acb\u4e3b\u6cbb\u533b\u751f\u54a8\u8be2\u66f4\u8282\u7701\u65f6\u95f4\u3002", "conclusion": "\u5c3d\u7ba1\u8fd9\u9879\u7814\u7a76\u6ca1\u6709\u590d\u5236\u73b0\u6709\u7684\u4e34\u5e8a\u5b9e\u8df5\u5e76\u4e14\u53ef\u80fd\u4f4e\u4f30\u4e86\u4e34\u5e8a\u533b\u751f\u7684\u80fd\u529b\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f02\u6b65\u76d1\u7763\u4f5c\u4e3a\u4e00\u79cd\u53ef\u884c\u7684\u8303\u4f8b\uff0c\u53ef\u4ee5\u5728\u4e13\u5bb6\u4eba\u7c7b\u76d1\u7763\u4e0b\u8fd0\u884c\u8bca\u65adAI\u7cfb\u7edf\uff0c\u4ee5\u589e\u5f3a\u73b0\u5b9e\u4e16\u754c\u7684\u62a4\u7406\u3002"}}
{"id": "2507.15079", "pdf": "https://arxiv.org/pdf/2507.15079", "abs": "https://arxiv.org/abs/2507.15079", "authors": ["Arkadiusz Lipiecki", "Bartosz Uniejewski"], "title": "Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts", "categories": ["cs.LG", "q-fin.ST", "stat.AP"], "comment": "Preprint", "summary": "Quantifying the uncertainty of forecasting models is essential to assess and\nmitigate the risks associated with data-driven decisions, especially in\nvolatile domains such as electricity markets. Machine learning methods can\nprovide highly accurate electricity price forecasts, critical for informing the\ndecisions of market participants. However, these models often lack uncertainty\nestimates, which limits the ability of decision makers to avoid unnecessary\nrisks. In this paper, we propose a novel method for generating probabilistic\nforecasts from ensembles of point forecasts, called Isotonic Quantile\nRegression Averaging (iQRA). Building on the established framework of Quantile\nRegression Averaging (QRA), we introduce stochastic order constraints to\nimprove forecast accuracy, reliability, and computational costs. In an\nextensive forecasting study of the German day-ahead electricity market, we show\nthat iQRA consistently outperforms state-of-the-art postprocessing methods in\nterms of both reliability and sharpness. It produces well-calibrated prediction\nintervals across multiple confidence levels, providing superior reliability to\nall benchmark methods, particularly coverage-based conformal prediction. In\naddition, isotonic regularization decreases the complexity of the quantile\nregression problem and offers a hyperparameter-free approach to variable\nselection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u7b49\u4f4d\u91cf\u5316\u56de\u5f52\u5e73\u5747\uff08iQRA\uff09\uff0c\u7528\u4e8e\u4ece\u70b9\u9884\u6d4b\u96c6\u5408\u4e2d\u751f\u6210\u6982\u7387\u9884\u6d4b\u3002\u901a\u8fc7\u5f15\u5165\u968f\u673a\u987a\u5e8f\u7ea6\u675f\uff0ciQRA\u63d0\u9ad8\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002\u5728\u5fb7\u56fd\u65e5\u524d\u7535\u529b\u5e02\u573a\u7684\u9884\u6d4b\u7814\u7a76\u4e2d\uff0ciQRA\u5728\u53ef\u9760\u6027\u548c\u9510\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u540e\u5904\u7406\u65b9\u6cd5\u3002\u6b64\u5916\uff0ciQRA\u51cf\u5c11\u4e86\u91cf\u5316\u56de\u5f52\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u7684\u53d8\u91cf\u9009\u62e9\u65b9\u6cd5\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5bf9\u4e8e\u964d\u4f4e\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u6ce2\u52a8\u8f83\u5927\u7684\u9886\u57df\u5982\u7535\u529b\u5e02\u573a\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u63d0\u4f9b\u9ad8\u51c6\u786e\u5ea6\u7684\u7535\u4ef7\u9884\u6d4b\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u8fd9\u9650\u5236\u4e86\u51b3\u7b56\u8005\u89c4\u907f\u4e0d\u5fc5\u8981\u98ce\u9669\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u5df2\u5efa\u7acb\u7684\u91cf\u5316\u56de\u5f52\u5e73\u5747\u6846\u67b6\uff0c\u5f15\u5165\u968f\u673a\u987a\u5e8f\u7ea6\u675f\uff0c\u63d0\u51fa\u4e86\u7b49\u4f4d\u91cf\u5316\u56de\u5f52\u5e73\u5747\uff08iQRA\uff09\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u53ca\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u91cf\u5316\u56de\u5f52\u95ee\u9898\u7684\u590d\u6742\u6027\u3002", "result": "\u5728\u5bf9\u5fb7\u56fd\u65e5\u524d\u7535\u529b\u5e02\u573a\u7684\u5e7f\u6cdb\u9884\u6d4b\u7814\u7a76\u4e2d\uff0ciQRA\u5728\u53ef\u9760\u6027\u548c\u9510\u5ea6\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u65b0\u7684\u540e\u5904\u7406\u65b9\u6cd5\u3002\u5b83\u5728\u591a\u4e2a\u7f6e\u4fe1\u6c34\u5e73\u4e0a\u4ea7\u751f\u4e86\u6821\u51c6\u826f\u597d\u7684\u9884\u6d4b\u533a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u7b26\u5408\u6027\u9884\u6d4b\u65b9\u9762\u63d0\u4f9b\u4e86\u5353\u8d8a\u7684\u53ef\u9760\u6027\u3002", "conclusion": "iQRA\u4e3a\u4ece\u70b9\u9884\u6d4b\u96c6\u5408\u4e2d\u751f\u6210\u6982\u7387\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u964d\u4f4e\u4e86\u91cf\u5316\u56de\u5f52\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u5373\u53ef\u8fdb\u884c\u53d8\u91cf\u9009\u62e9\u3002"}}
{"id": "2507.15758", "pdf": "https://arxiv.org/pdf/2507.15758", "abs": "https://arxiv.org/abs/2507.15758", "authors": ["Xingyu Wu", "Yuchen Yan", "Shangke Lyu", "Linjuan Wu", "Yiwen Qiu", "Yongliang Shen", "Weiming Lu", "Jian Shao", "Jun Xiao", "Yueting Zhuang"], "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "GitHub:https://github.com/zju-real/lapo;\n  Project:https://zju-real.github.io/lapo", "summary": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aLength-Adaptive Policy Optimization (LAPO)\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u7684\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u4f7f\u6a21\u578b\u80fd\u591f\u5185\u90e8\u5316\u7406\u89e3\u9002\u5f53\u7684\u63a8\u7406\u6df1\u5ea6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLAPO\u51cf\u5c11\u4e86\u9ad8\u8fbe40.9%\u7684token\u4f7f\u7528\u91cf\uff0c\u540c\u65f6\u63d0\u9ad8\u4e862.3%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u6839\u636e\u95ee\u9898\u590d\u6742\u6027\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u63a8\u7406\u800c\u4e0d\u727a\u7272\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u5728\u6269\u5c55\u7684\u601d\u7ef4\u94fe\u5e8f\u5217\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\uff0c\u4f46\u8fd9\u79cd\u8ba1\u7b97\u81ea\u7531\u5bfc\u81f4\u4e86\u5373\u4f7f\u5bf9\u4e8e\u7b80\u5355\u7684\u95ee\u9898\u4e5f\u4f1a\u4ea7\u751f\u8fc7\u591a\u7684token\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06\u63a8\u7406\u957f\u5ea6\u63a7\u5236\u4ece\u5916\u90e8\u7ea6\u675f\u8f6c\u53d8\u4e3a\u6a21\u578b\u7684\u5185\u5728\u80fd\u529b\u3002", "method": "LAPO\u91c7\u7528\u4e24\u9636\u6bb5\u7684\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff1a\u7b2c\u4e00\u9636\u6bb5\uff0c\u6a21\u578b\u901a\u8fc7\u53d1\u73b0\u6210\u529f\u89e3\u51b3\u65b9\u6848\u957f\u5ea6\u7684\u7edf\u8ba1\u5206\u5e03\u6765\u5b66\u4e60\u81ea\u7136\u7684\u63a8\u7406\u6a21\u5f0f\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5229\u7528\u8fd9\u4e9b\u6a21\u5f0f\u4f5c\u4e3a\u5143\u8ba4\u77e5\u6307\u5bfc\uff0c\u76f4\u63a5\u5d4c\u5165\u5230\u6a21\u578b\u7684\u63a8\u7406\u73af\u5883\u4e2d\uff0c\u4ee5\u786e\u4fdd\u63a8\u7406\u65f6\u7684\u7075\u6d3b\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLAPO\u53ef\u4ee5\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51cf\u5c11\u9ad8\u8fbe40.9%\u7684token\u4f7f\u7528\u91cf\uff0c\u540c\u65f6\u63d0\u9ad82.3%\u7684\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5c55\u793a\u4e86\u6839\u636e\u95ee\u9898\u590d\u6742\u6027\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u7684\u80fd\u529b\u3002", "conclusion": "LAPO\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u63a8\u7406\u6a21\u578b\u7684token\u751f\u6210\uff0c\u901a\u8fc7\u5185\u90e8\u5316\u9002\u5f53\u7684\u63a8\u7406\u6df1\u5ea6\u7406\u89e3\uff0c\u65e2\u63d0\u9ad8\u4e86\u6548\u7387\u53c8\u4fdd\u6301\u4e86\u63a8\u7406\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.15082", "pdf": "https://arxiv.org/pdf/2507.15082", "abs": "https://arxiv.org/abs/2507.15082", "authors": ["Qian Qi"], "title": "Robust Control with Gradient Uncertainty", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "We introduce a novel extension to robust control theory that explicitly\naddresses uncertainty in the value function's gradient, a form of uncertainty\nendemic to applications like reinforcement learning where value functions are\napproximated. We formulate a zero-sum dynamic game where an adversary perturbs\nboth system dynamics and the value function gradient, leading to a new, highly\nnonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs\nEquation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness\nby proving a comparison principle for its viscosity solutions under a uniform\nellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a\nkey insight: we prove that the classical quadratic value function assumption\nfails for any non-zero gradient uncertainty, fundamentally altering the problem\nstructure. A formal perturbation analysis characterizes the non-polynomial\ncorrection to the value function and the resulting nonlinearity of the optimal\ncontrol law, which we validate with numerical studies. Finally, we bridge\ntheory to practice by proposing a novel Gradient-Uncertainty-Robust\nActor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating\nits effectiveness in stabilizing training. This work provides a new direction\nfor robust control, holding significant implications for fields where function\napproximation is common, including reinforcement learning and computational\nfinance.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u6269\u5c55\uff0c\u8be5\u6269\u5c55\u7279\u522b\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u51fd\u6570\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u96f6\u548c\u52a8\u6001\u535a\u5f08\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u5176\u9002\u5b9a\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u975e\u96f6\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7684\u5b58\u5728\u4e0b\uff0c\u4f20\u7edf\u7684\u4e8c\u6b21\u4ef7\u503c\u51fd\u6570\u5047\u8bbe\u4e0d\u518d\u6210\u7acb\u3002\u6b64\u5916\uff0c\u6587\u4e2d\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GURAC\u7b97\u6cd5\u4ee5\u5e94\u5bf9\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7b49\u9886\u57df\u7684\u51fd\u6570\u903c\u8fd1\u95ee\u9898\u4e2d\uff0c\u4ef7\u503c\u51fd\u6570\u7684\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u662f\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u89e3\u51b3\u7684\u95ee\u9898\u3002\u5f53\u524d\u7684\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u6ca1\u6709\u76f4\u63a5\u5904\u7406\u8fd9\u79cd\u7c7b\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u7684\u63a7\u5236\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u96f6\u548c\u52a8\u6001\u535a\u5f08\u6a21\u578b\uff0c\u5728\u8be5\u6a21\u578b\u4e2d\u5bf9\u624b\u53ef\u4ee5\u5e72\u6270\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u4ef7\u503c\u51fd\u6570\u68af\u5ea6\uff0c\u4ece\u800c\u5bfc\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u504f\u5fae\u5206\u65b9\u7a0bGU-HJBI\u3002\u7136\u540e\u5bf9\u7ebf\u6027-\u4e8c\u6b21\u6848\u4f8b\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u8868\u660e\u5728\u4efb\u4f55\u975e\u96f6\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u7ecf\u5178\u7684\u4ef7\u503c\u51fd\u6570\u5047\u8bbe\u5c06\u5931\u6548\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GURAC\u7b97\u6cd5\uff0c\u7528\u4e8e\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u975e\u96f6\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u7684\u65b9\u6cd5\u65e0\u6cd5\u9002\u7528\uff0c\u5fc5\u987b\u8003\u8651\u4ef7\u503c\u51fd\u6570\u7684\u975e\u591a\u9879\u5f0f\u4fee\u6b63\u548c\u6700\u4f18\u63a7\u5236\u5f8b\u7684\u975e\u7ebf\u6027\u3002\u63d0\u51fa\u7684GURAC\u7b97\u6cd5\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u663e\u793a\u5176\u80fd\u591f\u6709\u6548\u7a33\u5b9a\u8bad\u7ec3\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u9c81\u68d2\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u51fd\u6570\u903c\u8fd1\u5e38\u89c1\u7684\u9886\u57df\uff08\u5982\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u91d1\u878d\uff09\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15761", "pdf": "https://arxiv.org/pdf/2507.15761", "abs": "https://arxiv.org/abs/2507.15761", "authors": ["Jingyi Zheng", "Zifan Peng", "Yule Liu", "Junfeng Wang", "Yifan Liao", "Wenhan Dong", "Xinlei He"], "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts", "categories": ["cs.AI"], "comment": null, "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aGasAgent\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f18\u5316\u667a\u80fd\u5408\u7ea6\u4e2d\u7684Gas\u6d88\u8017\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u56db\u4e2a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff0c\u5728\u95ed\u73af\u4e2d\u534f\u4f5c\u4ee5\u8bc6\u522b\u3001\u9a8c\u8bc1\u548c\u5e94\u7528\u8282\u7701Gas\u7684\u6539\u8fdb\u63aa\u65bd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGasAgent\u5728\u5b9e\u9645\u5408\u7ea6\u548cLLM\u751f\u6210\u7684\u5408\u7ea6\u4e0a\u5747\u80fd\u663e\u8457\u51cf\u5c11Gas\u6d88\u8017\uff0c\u5e76\u4e0e\u73b0\u6709\u5de5\u5177\u517c\u5bb9\u3002", "motivation": "\u7531\u4e8e\u975e\u6700\u4f18\u7f16\u7801\u5b9e\u8df5\uff0c\u8bb8\u591a\u667a\u80fd\u5408\u7ea6\u5b58\u5728Gas\u6d6a\u8d39\u6a21\u5f0f\uff0c\u800c\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5927\u591a\u4f9d\u8d56\u4e8e\u624b\u52a8\u53d1\u73b0\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u6700\u8fd1\u7684\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a2\u7d22\u65b0\u7684Gas\u6d6a\u8d39\u6a21\u5f0f\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e0e\u73b0\u6709\u6a21\u5f0f\u7684\u517c\u5bb9\u6027\u5dee\uff0c\u5bb9\u6613\u4ea7\u751f\u5197\u4f59\u6a21\u5f0f\uff0c\u5e76\u9700\u8981\u4eba\u5de5\u9a8c\u8bc1/\u91cd\u5199\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86GasAgent\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7ed3\u5408\u73b0\u6709\u6a21\u5f0f\u517c\u5bb9\u6027\u548c\u65b0\u6a21\u5f0f\u81ea\u52a8\u53d1\u73b0/\u9a8c\u8bc1\u7684\u667a\u80fd\u5408\u7ea6Gas\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u5b83\u7531\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u7ec4\u6210\uff1aSeeker\u3001Innovator\u3001Executor\u548cManager\uff0c\u5b83\u4eec\u5728\u95ed\u73af\u4e2d\u534f\u4f5c\uff0c\u4ee5\u8bc6\u522b\u3001\u9a8c\u8bc1\u548c\u5e94\u7528Gas\u8282\u7701\u6539\u8fdb\u3002", "result": "\u5bf9100\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u5408\u7ea6\u8fdb\u884c\u5b9e\u9a8c\uff0cGasAgent\u6210\u529f\u4f18\u5316\u4e8682\u4e2a\u5408\u7ea6\uff0c\u5e73\u5747\u90e8\u7f72Gas\u8282\u77019.97%\u3002\u5bf9\u4e8e500\u4e2a\u7531LLM\u751f\u6210\u7684\u5408\u7ea6\uff0cGasAgent\u4f18\u5316\u4e8679.8%\uff0c\u90e8\u7f72Gas\u8282\u7701\u8303\u56f4\u4ece4.79%\u523013.93%\u3002", "conclusion": "GasAgent\u5c55\u793a\u4e86\u5176\u4f5c\u4e3aLLM\u8f85\u52a9\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u4f18\u5316\u5c42\u7684\u53ef\u7528\u6027\uff0c\u540c\u65f6\u786e\u8ba4\u4e86\u5176\u4e0e\u73b0\u6709\u5de5\u5177\u7684\u517c\u5bb9\u6027\u53ca\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15104", "pdf": "https://arxiv.org/pdf/2507.15104", "abs": "https://arxiv.org/abs/2507.15104", "authors": ["Qiufeng Li", "Shu Hong", "Jian Gao", "Xuan Zhang", "Tian Lan", "Weidong Cao"], "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize\nanalog design automation through data-driven approaches. In particular,\nresearchers are increasingly fascinated by harnessing the power of generative\nAI to automate the discovery of novel analog circuit topologies. Unlocking the\nfull potential of generative AI in these data-driven discoveries requires\naccess to large and diverse datasets.Yet, there is a significant barrier in the\nanalog domain--Analog circuit design is inherently proprietary, involving not\nonly confidential circuit structures but also the underlying commercial\nsemiconductor processes. As a result, current generative AI research is largely\nconfined to individual researchers who construct small, narrowly focused\nprivate datasets. This fragmentation severely limits collaborative innovation\nand impedes progress across the research community. To address these\nchallenges, we propose AnalogFed. AnalogFed enables collaborative topology\ndiscovery across decentralized clients (e.g., individual researchers or\ninstitutions) without requiring the sharing of raw private data. To make this\nvision practical, we introduce a suite of techniques tailored to the unique\nchallenges of applying FedL in analog design--from generative model development\nand data heterogeneity handling to privacy-preserving strategies that ensure\nboth flexibility and security for circuit designers and semiconductor\nmanufacturers. Extensive experiments across varying client counts and dataset\nsizes demonstrate that AnalogFed achieves performance comparable to centralized\nbaselines--while maintaining strict data privacy. Specifically, the generative\nAI model within AnalogFed achieves state-of-the-art efficiency and scalability\nin the design of analog circuit topologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAnalogFed\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u5141\u8bb8\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u79c1\u6709\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u534f\u4f5c\u5f0f\u7684\u62d3\u6251\u53d1\u73b0\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u7cfb\u5217\u6280\u672f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u6a21\u62df\u8bbe\u8ba1\u4e2d\u7684\u72ec\u7279\u6311\u6218\uff0c\u5e76\u4e14\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u662f\u4e13\u6709\u7684\uff0c\u5305\u542b\u673a\u5bc6\u7535\u8def\u7ed3\u6784\u548c\u5546\u4e1a\u534a\u5bfc\u4f53\u5de5\u827a\uff0c\u8fd9\u4f7f\u5f97\u751f\u6210\u5f0fAI\u7684\u7814\u7a76\u53d7\u5230\u9650\u5236\uff0c\u56e0\u4e3a\u7814\u7a76\u4eba\u5458\u53ea\u80fd\u6784\u5efa\u5c0f\u7684\u3001\u72ed\u7a84\u7684\u79c1\u4eba\u6570\u636e\u96c6\u3002\u8fd9\u79cd\u788e\u7247\u5316\u4e25\u91cd\u9650\u5236\u4e86\u534f\u540c\u521b\u65b0\u5e76\u963b\u788d\u4e86\u7814\u7a76\u793e\u533a\u7684\u8fdb\u6b65\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86AnalogFed\uff0c\u5b83\u53ef\u4ee5\u5728\u5206\u6563\u7684\u5ba2\u6237\u7aef\u4e4b\u95f4\uff08\u4f8b\u5982\u4e2a\u4eba\u7814\u7a76\u4eba\u5458\u6216\u673a\u6784\uff09\u5b9e\u73b0\u534f\u4f5c\u62d3\u6251\u53d1\u73b0\uff0c\u800c\u65e0\u9700\u5171\u4eab\u539f\u59cb\u79c1\u6709\u6570\u636e\u3002\u4e3a\u4e86\u4f7f\u8fd9\u4e2a\u613f\u666f\u6210\u4e3a\u73b0\u5b9e\uff0c\u4ed6\u4eec\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u9488\u5bf9\u5e94\u7528\u8054\u90a6\u5b66\u4e60\u5728\u6a21\u62df\u8bbe\u8ba1\u4e2d\u7684\u72ec\u7279\u6311\u6218\u7684\u6280\u672f\uff0c\u5305\u62ec\u751f\u6210\u6a21\u578b\u5f00\u53d1\u3001\u6570\u636e\u5f02\u6784\u6027\u5904\u7406\u4ee5\u53ca\u786e\u4fdd\u7535\u8def\u8bbe\u8ba1\u5e08\u548c\u534a\u5bfc\u4f53\u5236\u9020\u5546\u7075\u6d3b\u6027\u548c\u5b89\u5168\u6027\u7684\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAnalogFed\u5728\u4e0d\u540c\u7684\u5ba2\u6237\u7aef\u6570\u91cf\u548c\u6570\u636e\u96c6\u5927\u5c0f\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u6570\u636e\u9690\u79c1\u3002\u7279\u522b\u662f\uff0cAnalogFed\u5185\u7684\u751f\u6210AI\u6a21\u578b\u5728\u6a21\u62df\u7535\u8def\u62d3\u6251\u8bbe\u8ba1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "AnalogFed\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u8fdb\u884c\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u7684\u534f\u4f5c\u5f0f\u62d3\u6251\u53d1\u73b0\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002\u8fd9\u5bf9\u4e8e\u63a8\u52a8\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u9886\u57df\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.15770", "pdf": "https://arxiv.org/pdf/2507.15770", "abs": "https://arxiv.org/abs/2507.15770", "authors": ["Yifan Shen", "Zihan Zhao", "Xiao Xue", "Yuwei Guo", "Qun Ma", "Deyu Zhou", "Ming Zhang"], "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining", "categories": ["cs.AI"], "comment": null, "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u610f\u56fe\u7684\u6d8c\u73b0\u5206\u6790\u6846\u67b6\uff08EAMI\uff09\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u8fdb\u884c\u5f02\u5e38\u6d8c\u73b0\u548c\u56e0\u679c\u5206\u6790\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742O2O\u670d\u52a1\u7cfb\u7edf\u548c\u65af\u5766\u798fAI\u5c0f\u9547\u5b9e\u9a8c\u4e2d\u7684\u6709\u6548\u6027\u3001\u901a\u7528\u6027\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u670d\u52a1\u8ba1\u7b97\u3001\u4e91\u8ba1\u7b97\u548c\u7269\u8054\u7f51\u7684\u5174\u8d77\uff0c\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\uff0c\u4f20\u7edf\u56e0\u679c\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u667a\u80fd\u4f53\u4e4b\u95f4\u590d\u6742\u7684\u4ea4\u4e92\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u5f02\u5e38\u6d8c\u73b0\u5206\u6790\u3002", "method": "EAMI\u6846\u67b6\u91c7\u7528\u53cc\u89c6\u89d2\u601d\u7ef4\u8f68\u8ff9\u673a\u5236\uff0c\u5176\u4e2d\u68c0\u67e5\u667a\u80fd\u4f53\u548c\u5206\u6790\u667a\u80fd\u4f53\u5728\u6709\u9650\u548c\u5b8c\u7f8e\u7406\u6027\u4e0b\u63d0\u53d6\u667a\u80fd\u4f53\u610f\u56fe\uff1b\u7136\u540e\u4f7f\u7528k-means\u805a\u7c7b\u8bc6\u522b\u7fa4\u4f53\u610f\u56fe\u4e2d\u7684\u76f8\u53d8\u70b9\uff0c\u6700\u540e\u901a\u8fc7\u610f\u56fe\u65f6\u5e8f\u6d8c\u73b0\u56fe\u8fdb\u884c\u52a8\u6001\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86EAMI\u6846\u67b6\u5728\u590d\u6742\u5728\u7ebf\u5230\u79bb\u7ebf\uff08O2O\uff09\u670d\u52a1\u7cfb\u7edf\u548c\u65af\u5766\u798fAI Town\u5b9e\u9a8c\u4e2d\u7684\u6709\u6548\u6027\u3001\u901a\u7528\u6027\u548c\u6548\u7387\u3002", "conclusion": "EAMI\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8303\u5f0f\uff0c\u7528\u4e8e\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u6d8c\u73b0\u548c\u56e0\u679c\u5206\u6790\u3002"}}
{"id": "2507.15796", "pdf": "https://arxiv.org/pdf/2507.15796", "abs": "https://arxiv.org/abs/2507.15796", "authors": ["Nuria Rodr\u00edguez-Barroso", "Mario Garc\u00eda-M\u00e1rquez", "M. Victoria Luz\u00f3n", "Francisco Herrera"], "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, the development of Trustworthy Artificial Intelligence (TAI)\nhas emerged as a critical objective in the deployment of AI systems across\nsensitive and high-risk domains. TAI frameworks articulate a comprehensive set\nof ethical, legal, and technical requirements to ensure that AI technologies\nare aligned with human values, rights, and societal expectations. Among the\nvarious AI paradigms, Federated Learning (FL) presents a promising solution to\npressing privacy concerns. However, aligning FL with the rest of the\nrequirements of TAI presents a series of challenges, most of which arise from\nits inherently distributed nature. In this work, we adopt the requirements TAI\nas a guiding structure to systematically analyze the challenges of adapting FL\nto TAI. Specifically, we classify and examine the key obstacles to aligning FL\nwith TAI, providing a detailed exploration of what has been done, the trends,\nand the remaining work within each of the identified challenges.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528TAI\u7684\u8981\u6c42\u4f5c\u4e3a\u6307\u5bfc\u7ed3\u6784\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5c06\u8054\u90a6\u5b66\u4e60\u9002\u5e94\u4e8e\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u7684\u6311\u6218\uff0c\u5206\u7c7b\u5e76\u5ba1\u67e5\u4e86\u5173\u952e\u969c\u788d\uff0c\u63a2\u8ba8\u4e86\u5df2\u6709\u7684\u5de5\u4f5c\u3001\u8d8b\u52bf\u548c\u5269\u4f59\u7684\u5de5\u4f5c\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u654f\u611f\u548c\u9ad8\u98ce\u9669\u9886\u57df\u7684\u90e8\u7f72\uff0c\u53d1\u5c55\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\uff08TAI\uff09\u5df2\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u76ee\u6807\u3002\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u867d\u7136\u4e3a\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u8981\u5c06\u5176\u4e0e\u5176\u4ed6TAI\u8981\u6c42\u5bf9\u9f50\u5b58\u5728\u4e00\u7cfb\u5217\u6311\u6218\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u5176\u56fa\u6709\u7684\u5206\u5e03\u5f0f\u7279\u6027\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u4e86TAI\u6846\u67b6\u4e2d\u7684\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u6280\u672f\u8981\u6c42\u4f5c\u4e3a\u6307\u5bfc\u7ed3\u6784\uff0c\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u5c06FL\u4e0eTAI\u5bf9\u9f50\u7684\u6311\u6218\u3002\u4ed6\u4eec\u5206\u7c7b\u5e76\u5ba1\u67e5\u4e86\u8fd9\u4e9b\u6311\u6218\u4e2d\u7684\u5173\u952e\u969c\u788d\uff0c\u5e76\u8be6\u7ec6\u63a2\u8ba8\u4e86\u6bcf\u4e2a\u8bc6\u522b\u51fa\u7684\u6311\u6218\u4e2d\u5df2\u7ecf\u5b8c\u6210\u7684\u5de5\u4f5c\u3001\u8d8b\u52bf\u4ee5\u53ca\u5269\u4f59\u7684\u5de5\u4f5c\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u5c06\u8054\u90a6\u5b66\u4e60\u4e0e\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u7684\u5173\u952e\u6311\u6218\u7684\u6df1\u5165\u7406\u89e3\uff0c\u660e\u786e\u4e86\u73b0\u6709\u7684\u8fdb\u5c55\u3001\u8d8b\u52bf\u53ca\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u4e3a\u4e86\u4f7f\u8054\u90a6\u5b66\u4e60\u5b8c\u5168\u7b26\u5408\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u7684\u6807\u51c6\uff0c\u9700\u8981\u514b\u670d\u591a\u4e2a\u5173\u952e\u6311\u6218\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u7684\u63a2\u7d22\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u524d\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2507.15119", "pdf": "https://arxiv.org/pdf/2507.15119", "abs": "https://arxiv.org/abs/2507.15119", "authors": ["Juntong Ni", "Shiyu Wang", "Zewen Liu", "Xiaoming Shi", "Xinyue Zhong", "Zhou Ye", "Wei Jin"], "title": "Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting (TSF) is a central problem in time series analysis.\nHowever, as the number of channels in time series datasets scales to the\nthousands or more, a scenario we define as High-Dimensional Time Series\nForecasting (HDTSF), it introduces significant new modeling challenges that are\noften not the primary focus of traditional TSF research. HDTSF is challenging\nbecause the channel correlation often forms complex and hierarchical patterns.\nExisting TSF models either ignore these interactions or fail to scale as\ndimensionality grows. To address this issue, we propose U-Cast, a\nchannel-dependent forecasting architecture that learns latent hierarchical\nchannel structures with an innovative query-based attention. To disentangle\nhighly correlated channel representation, U-Cast adds a full-rank\nregularization during training. We also release Time-HD, a benchmark of large,\ndiverse, high-dimensional datasets. Our theory shows that exploiting\ncross-channel information lowers forecasting risk, and experiments on Time-HD\ndemonstrate that U-Cast surpasses strong baselines in both accuracy and\nefficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF\nresearch.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aU-Cast\u7684\u901a\u9053\u4f9d\u8d56\u9884\u6d4b\u67b6\u6784\uff0c\u9488\u5bf9\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08HDTSF\uff09\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u67e5\u8be2\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6f5c\u5728\u7684\u5c42\u6b21\u5316\u901a\u9053\u7ed3\u6784\uff0c\u5e76\u5728\u8bad\u7ec3\u4e2d\u6dfb\u52a0\u5168\u79e9\u6b63\u5219\u5316\u4ee5\u89e3\u7f20\u9ad8\u5ea6\u76f8\u5173\u7684\u901a\u9053\u8868\u793a\u3002\u5b9e\u9a8c\u8868\u660e\uff0cU-Cast\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u6570\u636e\u96c6\u4e2d\u901a\u9053\u6570\u91cf\u6269\u5c55\u5230\u6570\u5343\u4e2a\u6216\u66f4\u591a\uff0c\u4f20\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u7531\u6b64\u5e26\u6765\u7684\u590d\u6742\u548c\u5206\u5c42\u6a21\u5f0f\u7684\u901a\u9053\u76f8\u5173\u6027\u6311\u6218\u3002", "method": "U-Cast\u91c7\u7528\u521b\u65b0\u7684\u57fa\u4e8e\u67e5\u8be2\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b66\u4e60\u9690\u85cf\u7684\u5c42\u6b21\u5316\u901a\u9053\u7ed3\u6784\uff0c\u5e76\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a0\u5165\u5168\u79e9\u6b63\u5219\u5316\u4ee5\u5206\u79bb\u9ad8\u5ea6\u76f8\u5173\u7684\u901a\u9053\u8868\u793a\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u5229\u7528\u8de8\u901a\u9053\u4fe1\u606f\u53ef\u4ee5\u964d\u4f4e\u9884\u6d4b\u98ce\u9669\uff1b\u5b9e\u9a8c\u8bc1\u660eU-Cast\u5728Time-HD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u591a\u4e2a\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "U-Cast\u548cTime-HD\u4e3a\u672a\u6765\u7684\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15842", "pdf": "https://arxiv.org/pdf/2507.15842", "abs": "https://arxiv.org/abs/2507.15842", "authors": ["Sara LaPlante", "Emilija Perkovi\u0107"], "title": "Identifying Conditional Causal Effects in MPDAGs", "categories": ["cs.AI", "stat.ME", "stat.ML"], "comment": "67 pages, 8 figures", "summary": "We consider identifying a conditional causal effect when a graph is known up\nto a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG\nrepresents an equivalence class of graphs that is restricted by background\nknowledge and where all variables in the causal model are observed. We provide\nthree results that address identification in this setting: an identification\nformula when the conditioning set is unaffected by treatment, a generalization\nof the well-known do calculus to the MPDAG setting, and an algorithm that is\ncomplete for identifying these conditional effects.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5df2\u77e5\u6700\u5927\u5b9a\u5411\u90e8\u5206\u6709\u5411\u65e0\u73af\u56fe(MPDAG)\u7684\u60c5\u51b5\u4e0b\uff0c\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u7684\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e09\u79cd\u7ed3\u679c\uff1a\u5f53\u8c03\u8282\u96c6\u4e0d\u53d7\u6cbb\u7597\u5f71\u54cd\u65f6\u7684\u8bc6\u522b\u516c\u5f0f\u3001\u63a8\u5e7f\u5230MPDAG\u8bbe\u5b9a\u7684do\u5fae\u79ef\u5206\u4ee5\u53ca\u4e00\u4e2a\u7528\u4e8e\u8bc6\u522b\u8fd9\u4e9b\u6761\u4ef6\u6548\u5e94\u7684\u5b8c\u6574\u7b97\u6cd5\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u5728\u5df2\u77e5\u6700\u5927\u5b9a\u5411\u90e8\u5206\u6709\u5411\u65e0\u73af\u56fe(MPDAG)\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e09\u79cd\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff1a1\uff09\u5f53\u8c03\u8282\u96c6\u4e0d\u53d7\u6cbb\u7597\u5f71\u54cd\u65f6\u7684\u8bc6\u522b\u516c\u5f0f\uff1b2\uff09\u5c06\u8457\u540d\u7684do\u5fae\u79ef\u5206\u63a8\u5e7f\u5230MPDAG\u8bbe\u5b9a\uff1b3\uff09\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u7b97\u6cd5\u4ee5\u8bc6\u522b\u8fd9\u4e9b\u6761\u4ef6\u6548\u5e94\u3002", "result": "\u901a\u8fc7\u4e0a\u8ff0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u5df2\u77e5MPDAG\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u5730\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b8c\u6574\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728MPDAG\u8bbe\u5b9a\u4e2d\u8bc6\u522b\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u5e7f\u6cdb\u5730\u7406\u89e3\u548c\u5e94\u7528\u56e0\u679c\u63a8\u7406\u3002"}}
{"id": "2507.15132", "pdf": "https://arxiv.org/pdf/2507.15132", "abs": "https://arxiv.org/abs/2507.15132", "authors": ["Joanna Komorniczak"], "title": "Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "The research community continues to seek increasingly more advanced synthetic\ndata generators to reliably evaluate the strengths and limitations of machine\nlearning methods. This work aims to increase the availability of datasets\nencompassing a diverse range of problem complexities by proposing a genetic\nalgorithm that optimizes a set of problem complexity measures for\nclassification and regression tasks towards specific targets. For\nclassification, a set of 10 complexity measures was used, while for regression\ntasks, 4 measures demonstrating promising optimization capabilities were\nselected. Experiments confirmed that the proposed genetic algorithm can\ngenerate datasets with varying levels of difficulty by transforming\nsynthetically created datasets to achieve target complexity values through\nlinear feature projections. Evaluations involving state-of-the-art classifiers\nand regressors revealed a correlation between the complexity of the generated\ndata and the recognition quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9057\u4f20\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u7684\u95ee\u9898\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u4ee5\u751f\u6210\u5177\u6709\u7279\u5b9a\u590d\u6742\u6027\u503c\u7684\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\u4e0e\u8bc6\u522b\u8d28\u91cf\u4e4b\u95f4\u5b58\u5728\u76f8\u5173\u6027\u3002", "motivation": "\u7814\u7a76\u793e\u533a\u4e00\u76f4\u5728\u5bfb\u6c42\u66f4\u9ad8\u7ea7\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u6765\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002\u4e3a\u4e86\u589e\u52a0\u6db5\u76d6\u4e0d\u540c\u95ee\u9898\u590d\u6742\u5ea6\u7684\u6570\u636e\u96c6\u7684\u53ef\u7528\u6027\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9057\u4f20\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u9488\u5bf9\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4f18\u5316\u4e00\u7ec4\u95ee\u9898\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u4ee5\u8fbe\u5230\u7279\u5b9a\u76ee\u6807\u3002\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\u4f7f\u7528\u4e8610\u4e2a\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u5bf9\u4e8e\u56de\u5f52\u4efb\u52a1\u9009\u62e9\u4e864\u4e2a\u8868\u73b0\u51fa\u826f\u597d\u4f18\u5316\u80fd\u529b\u7684\u5ea6\u91cf\u3002\u901a\u8fc7\u7ebf\u6027\u7279\u5f81\u6295\u5f71\u8f6c\u6362\u5408\u6210\u521b\u5efa\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u5b9e\u73b0\u76ee\u6807\u590d\u6742\u6027\u503c\u3002", "result": "\u5b9e\u9a8c\u786e\u8ba4\u4e86\u6240\u63d0\u51fa\u7684\u9057\u4f20\u7b97\u6cd5\u53ef\u4ee5\u751f\u6210\u4e0d\u540c\u7a0b\u5ea6\u96be\u5ea6\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u6d89\u53ca\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\u548c\u56de\u5f52\u6a21\u578b\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u751f\u6210\u6570\u636e\u7684\u590d\u6742\u6027\u548c\u8bc6\u522b\u8d28\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u590d\u6742\u6027\u5ea6\u91cf\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u751f\u6210\u5177\u6709\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\u5f71\u54cd\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15844", "pdf": "https://arxiv.org/pdf/2507.15844", "abs": "https://arxiv.org/abs/2507.15844", "authors": ["Shangke Lyu", "Linjuan Wu", "Yuchen Yan", "Xingyu Wu", "Hao Li", "Yongliang Shen", "Peisheng Jiang", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/", "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6HBPO\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u548c\u5dee\u5f02\u5316\u7684\u5956\u52b1\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6839\u636e\u95ee\u9898\u7684\u590d\u6742\u6027\u81ea\u52a8\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u5728\u4e0d\u727a\u7272\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHBPO\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5c06\u5e73\u5747token\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u6700\u591a60.6%\uff0c\u540c\u65f6\u63d0\u9ad8\u4e863.14%\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5c3d\u7ba1\u901a\u8fc7\u5e7f\u6cdb\u7684\u94fe\u5f0f\u601d\u7ef4\u751f\u6210\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\uff0c\u4f46\u5728\u5904\u7406\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u95ee\u9898\u65f6\uff0c\u91c7\u7528\u4e86\u7edf\u4e00\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86Hierarchical Budget Policy Optimization (HBPO)\u6846\u67b6\u3002", "method": "HBPO\u91c7\u7528\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u7684\u65b9\u6cd5\uff0c\u5c06rollout\u6837\u672c\u5206\u4e3a\u591a\u4e2a\u5177\u6709\u4e0d\u540ctoken\u9884\u7b97\u7684\u5b50\u7ec4\uff0c\u5e76\u5f15\u5165\u5dee\u5f02\u5316\u7684\u5956\u52b1\u673a\u5236\uff0c\u521b\u5efa\u4e0e\u95ee\u9898\u590d\u6742\u5ea6\u76f8\u5339\u914d\u7684\u9884\u7b97\u611f\u77e5\u6fc0\u52b1\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u53d1\u73b0\u4efb\u52a1\u9700\u6c42\u4e0e\u8ba1\u7b97\u52aa\u529b\u4e4b\u95f4\u7684\u81ea\u7136\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cHBPO\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747token\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u6700\u9ad8\u8fbe60.6%\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u5347\u4e863.14%\u3002\u6b64\u5916\uff0cHBPO\u5c55\u793a\u4e86\u65b0\u5174\u7684\u9002\u5e94\u6027\u884c\u4e3a\uff0c\u6a21\u578b\u80fd\u6839\u636e\u95ee\u9898\u590d\u6742\u6027\u81ea\u52a8\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u63a8\u7406\u6548\u7387\u548c\u80fd\u529b\u5e76\u975e\u5929\u751f\u5bf9\u7acb\uff0c\u800c\u662f\u53ef\u4ee5\u901a\u8fc7\u9002\u5f53\u7ed3\u6784\u5316\u7684\u5206\u5c42\u8bad\u7ec3\u540c\u65f6\u4f18\u5316\uff0c\u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u4fdd\u7559\u4e86\u63a2\u7d22\u7684\u591a\u6837\u6027\u3002"}}
{"id": "2507.15156", "pdf": "https://arxiv.org/pdf/2507.15156", "abs": "https://arxiv.org/abs/2507.15156", "authors": ["Mykhailo Buleshnyi", "Anna Polova", "Zsolt Zombori", "Michael Benedikt"], "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "We investigate multi-label classification involving large sets of labels,\nwhere the output labels may be known to satisfy some logical constraints. We\nlook at an architecture in which classifiers for individual labels are fed into\nan expressive sequential model, which produces a joint distribution. One of the\npotential advantages for such an expressive model is its ability to modelling\ncorrelations, as can arise from constraints. We empirically demonstrate the\nability of the architecture both to exploit constraints in training and to\nenforce constraints at inference time.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u89c4\u6a21\u6807\u7b7e\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u5229\u7528\u6807\u7b7e\u4e4b\u95f4\u903b\u8f91\u7ea6\u675f\u5173\u7cfb\u7684\u67b6\u6784\uff0c\u5e76\u8bc1\u5b9e\u4e86\u8be5\u67b6\u6784\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u5229\u7528\u53ca\u5f3a\u5236\u6267\u884c\u8fd9\u4e9b\u7ea6\u675f\u7684\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u89c4\u6a21\u6807\u7b7e\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\uff0c\u540c\u65f6\u5229\u7528\u6807\u7b7e\u4e4b\u95f4\u7684\u903b\u8f91\u7ea6\u675f\u6765\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u67b6\u6784\uff0c\u5176\u4e2d\u4e2a\u4f53\u6807\u7b7e\u7684\u5206\u7c7b\u5668\u8f93\u5165\u5230\u4e00\u4e2a\u8868\u8fbe\u6027\u7684\u5e8f\u5217\u6a21\u578b\u4e2d\uff0c\u4ea7\u751f\u8054\u5408\u5206\u5e03\uff0c\u4ece\u800c\u80fd\u591f\u5bf9\u6807\u7b7e\u95f4\u7684\u76f8\u5173\u6027\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u67b6\u6784\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5229\u7528\u7ea6\u675f\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u63a8\u7406\u9636\u6bb5\u5f3a\u5236\u6267\u884c\u8fd9\u4e9b\u7ea6\u675f\u3002", "conclusion": "\u8fd9\u79cd\u67b6\u6784\u53ef\u4ee5\u6709\u6548\u5730\u5229\u7528\u6807\u7b7e\u4e4b\u95f4\u7684\u903b\u8f91\u7ea6\u675f\uff0c\u63d0\u9ad8\u591a\u6807\u7b7e\u5206\u7c7b\u7684\u6548\u679c\u3002"}}
{"id": "2507.15851", "pdf": "https://arxiv.org/pdf/2507.15851", "abs": "https://arxiv.org/abs/2507.15851", "authors": ["Lingyu Li", "Yang Yao", "Yixu Wang", "Chubo Li", "Yan Teng", "Yingchun Wang"], "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition", "categories": ["cs.AI"], "comment": "12 pages, 9 figures, 4 tables", "summary": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c55\u73b0\u51fa\u4e0e\u4eba\u7c7b\u7c7b\u4f3c\u7684\u4e3b\u89c2\u65f6\u95f4\u8ba4\u77e5\u6a21\u5f0f\uff0c\u9075\u5faa\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u5143\u3001\u8868\u5f81\u548c\u4fe1\u606f\u5c42\u9762\u7684\u5206\u6790\u63ed\u793a\u4e86\u5176\u80cc\u540e\u7684\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u672a\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u660e\u786e\u89c4\u5b9a\u7684\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5173\u4e8e\u65f6\u95f4\u8ba4\u77e5\u7684\u73b0\u8c61\u3002", "method": "\u4f7f\u7528\u76f8\u4f3c\u6027\u5224\u65ad\u4efb\u52a1\u6d4b\u8bd5\u6a21\u578b\u7684\u65f6\u95f4\u8ba4\u77e5\uff0c\u5206\u6790\u795e\u7ecf\u5143\u6d3b\u52a8\u3001\u5e74\u4efd\u8868\u5f81\u7684\u5c42\u6b21\u7ed3\u6784\u5efa\u8bbe\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u4e2d\u7684\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u8f83\u5927\u6a21\u578b\u81ea\u53d1\u5efa\u7acb\u4e3b\u89c2\u65f6\u95f4\u53c2\u8003\u70b9\u5e76\u9075\u5faa\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff1b\u8bc6\u522b\u51fa\u4e00\u7ec4\u5bf9\u65f6\u95f4\u6709\u504f\u597d\u7684\u795e\u7ecf\u5143\uff1b\u5e74\u4efd\u4ece\u6d45\u5c42\u7684\u57fa\u672c\u6570\u503c\u6f14\u53d8\u4e3a\u6df1\u5c42\u7684\u62bd\u8c61\u65f6\u95f4\u65b9\u5411\uff1b\u8bad\u7ec3\u8bed\u6599\u5e93\u672c\u8eab\u5177\u6709\u5185\u5728\u7684\u975e\u7ebf\u6027\u65f6\u95f4\u7ed3\u6784\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u4f53\u9a8c\u4e3b\u4e49\u89c6\u89d2\u6765\u7406\u89e3\u8fd9\u4e9b\u53d1\u73b0\uff0c\u6697\u793aLLMs\u53ef\u80fd\u53d1\u5c55\u51fa\u4eba\u7c7b\u65e0\u6cd5\u76f4\u89c2\u9884\u6d4b\u7684\u964c\u751f\u8ba4\u77e5\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86AI\u5bf9\u9f50\u5e94\u5173\u6ce8\u5185\u90e8\u6784\u9020\u5f15\u5bfc\u7684\u65b9\u5411\u3002"}}
{"id": "2507.15158", "pdf": "https://arxiv.org/pdf/2507.15158", "abs": "https://arxiv.org/abs/2507.15158", "authors": ["A. H. Abbas", "Hend Abdel-Ghani", "Ivan S. Maksymov"], "title": "Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition", "categories": ["cs.LG", "physics.app-ph"], "comment": null, "summary": "As artificial intelligence continues to push into real-time, edge-based and\nresource-constrained environments, there is an urgent need for novel,\nhardware-efficient computational models. In this study, we present and validate\na neuromorphic computing architecture based on resonant-tunnelling diodes\n(RTDs), which exhibit the nonlinear characteristics ideal for physical\nreservoir computing (RC). We theoretically formulate and numerically implement\nan RTD-based RC system and demonstrate its effectiveness on two image\nrecognition benchmarks: handwritten digit classification and object recognition\nusing the Fruit~360 dataset. Our results show that this circuit-level\narchitecture delivers promising performance while adhering to the principles of\nnext-generation RC -- eliminating random connectivity in favour of a\ndeterministic nonlinear transformation of input signals.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5171\u632f\u96a7\u9053\u4e8c\u6781\u7ba1\uff08RTD\uff09\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u4e0d\u65ad\u5411\u5b9e\u65f6\u3001\u57fa\u4e8e\u8fb9\u7f18\u548c\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u63a8\u8fdb\uff0c\u5bf9\u4e8e\u65b0\u578b\u3001\u786c\u4ef6\u9ad8\u6548\u7684\u8ba1\u7b97\u6a21\u578b\u6709\u7740\u8feb\u5207\u7684\u9700\u6c42\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u7406\u8bba\u516c\u5f0f\u5316\u548c\u6570\u503c\u5b9e\u73b0\u4e00\u4e2a\u57fa\u4e8eRTD\u7684\u7269\u7406\u50a8\u5907\u6c60\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5e76\u5728\u4e24\u4e2a\u56fe\u50cf\u8bc6\u522b\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff1a\u624b\u5199\u6570\u5b57\u5206\u7c7b\u548c\u4f7f\u7528Fruit 360\u6570\u636e\u96c6\u7684\u5bf9\u8c61\u8bc6\u522b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u7535\u8def\u7ea7\u67b6\u6784\u5728\u6027\u80fd\u65b9\u9762\u5177\u6709\u5f88\u5927\u7684\u6f5c\u529b\uff0c\u5e76\u4e14\u7b26\u5408\u4e0b\u4e00\u4ee3RC\u7684\u539f\u5219\u2014\u2014\u6d88\u9664\u968f\u673a\u8fde\u63a5\uff0c\u8f6c\u800c\u91c7\u7528\u8f93\u5165\u4fe1\u53f7\u7684\u786e\u5b9a\u6027\u975e\u7ebf\u6027\u8f6c\u6362\u3002", "conclusion": "\u57fa\u4e8eRTD\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5728\u56fe\u50cf\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15855", "pdf": "https://arxiv.org/pdf/2507.15855", "abs": "https://arxiv.org/abs/2507.15855", "authors": ["Yichen Huang", "Lin F. Yang"], "title": "Gemini 2.5 Pro Capable of Winning Gold at IMO 2025", "categories": ["cs.AI"], "comment": null, "summary": "The International Mathematical Olympiad (IMO) poses uniquely challenging\nproblems requiring deep insight, creativity, and formal reasoning. While Large\nLanguage Models (LLMs) perform well on mathematical benchmarks like AIME, they\nstruggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly\nreleased IMO 2025 problems, avoiding data contamination. With pipeline design\nand prompt engineering, 5 (out of 6) problems are solved correctly (up to a\ncaveat discussed below), highlighting the importance of finding the optimal way\nof using powerful models.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u4e86Google\u7684Gemini 2.5 Pro\u89e3\u51b3\u4e86\u65b0\u53d1\u5e03\u76842025\u5e74\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u76845\u4e2a\uff08\u51716\u4e2a\uff09\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u627e\u5230\u4f7f\u7528\u5f3a\u5927\u6a21\u578b\u7684\u6700\u4f73\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u50cfAIME\u8fd9\u6837\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u9700\u8981\u6df1\u5ea6\u89c1\u89e3\u3001\u521b\u9020\u529b\u548c\u5f62\u5f0f\u63a8\u7406\u7684\u5965\u6797\u5339\u514b\u7ea7\u522b\u7684\u4efb\u52a1\u65f6\u5374\u9047\u5230\u4e86\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u63a2\u7d22\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u80fd\u5426\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u4f7f\u7528\u4e86Google\u7684Gemini 2.5 Pro\u6765\u89e3\u51b3\u65b0\u53d1\u5e03\u76842025\u5e74\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7ba1\u9053\u8bbe\u8ba1\u548c\u63d0\u793a\u5de5\u7a0b\u907f\u514d\u6570\u636e\u6c61\u67d3\u3002", "result": "\u6210\u529f\u89e3\u51b3\u4e866\u4e2a\u95ee\u9898\u4e2d\u76845\u4e2a\uff0c\u8bc1\u660e\u4e86\u4f7f\u7528\u5f3a\u5927\u7684\u6a21\u578b\u548c\u6b63\u786e\u7684\u6280\u672f\u53ef\u4ee5\u63d0\u9ad8\u89e3\u51b3\u9ad8\u96be\u5ea6\u6570\u5b66\u95ee\u9898\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u627e\u5230\u4f7f\u7528\u5f3a\u5927\u6a21\u578b\u7684\u6700\u4f73\u65b9\u6cd5\u5bf9\u4e8e\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.15162", "pdf": "https://arxiv.org/pdf/2507.15162", "abs": "https://arxiv.org/abs/2507.15162", "authors": ["Firdaus Ahmed Choudhury", "Ethan Leicht", "Jude Ethan Bislig", "Hangzhi Guo", "Amulya Yadav"], "title": "Designing User-Centric Metrics for Evaluation of Counterfactual Explanations", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning-based decision models are increasingly being used to make\ndecisions that significantly impact people's lives, but their opaque nature\nleaves end users without a clear understanding of why a decision was made.\nCounterfactual Explanations (CFEs) have grown in popularity as a means of\noffering actionable guidance by identifying the minimum changes in feature\nvalues required to flip a model's prediction to something more desirable.\nUnfortunately, most prior research in CFEs relies on artificial evaluation\nmetrics, such as proximity, which may overlook end-user preferences and\nconstraints, e.g., the user's perception of effort needed to make certain\nfeature changes may differ from that of the model designer. To address this\nresearch gap, this paper makes three novel contributions. First, we conduct a\npilot study with 20 crowd-workers on Amazon MTurk to experimentally validate\nthe alignment of existing CF evaluation metrics with real-world user\npreferences. Results show that user-preferred CFEs matched those based on\nproximity in only 63.81% of cases, highlighting the limited applicability of\nthese metrics in real-world settings. Second, inspired by the need to design a\nuser-informed evaluation metric for CFEs, we conduct a more detailed two-day\nuser study with 41 participants facing realistic credit application scenarios\nto find experimental support for or against three intuitive hypotheses that may\nexplain how end users evaluate CFEs. Third, based on the findings of this\nsecond study, we propose the AWP model, a novel user-centric, two-stage model\nthat describes one possible mechanism by which users evaluate and select CFEs.\nOur results show that AWP predicts user-preferred CFEs with 84.37% accuracy.\nOur study provides the first human-centered validation for personalized cost\nmodels in CFE generation and highlights the need for adaptive, user-centered\nevaluation metrics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFE\uff09\u8bc4\u4ef7\u6307\u6807\u4e0e\u771f\u5b9e\u7528\u6237\u504f\u597d\u7684\u5339\u914d\u5ea6\u6709\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7528\u6237\u4e2d\u5fc3\u7684AWP\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u9884\u6d4b\u7528\u6237\u504f\u597dCFE\u65b9\u9762\u5177\u670984.37%\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u51b3\u7b56\u6a21\u578b\u7684\u4e0d\u900f\u660e\u6027\u5bfc\u81f4\u7ec8\u7aef\u7528\u6237\u65e0\u6cd5\u6e05\u695a\u7406\u89e3\u51b3\u7b56\u539f\u56e0\uff0c\u800c\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFE\uff09\u8bc4\u4ef7\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u7528\u6237\u7684\u5b9e\u9645\u9700\u6c42\u548c\u7ea6\u675f\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8fdb\u884c\u4e86\u4e00\u4e2a20\u4eba\u7684\u8bd5\u70b9\u7814\u7a76\uff0c\u4ee5\u9a8c\u8bc1\u73b0\u6709CFE\u8bc4\u4ef7\u6307\u6807\u4e0e\u771f\u5b9e\u7528\u6237\u504f\u597d\u7684\u5339\u914d\u60c5\u51b5\uff1b\u7136\u540e\u8fdb\u884c\u4e86\u4e00\u987941\u4eba\u53c2\u4e0e\u7684\u8be6\u7ec6\u7528\u6237\u7814\u7a76\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5173\u4e8e\u7528\u6237\u5982\u4f55\u8bc4\u4f30CFEs\u7684\u5047\u8bbe\uff1b\u6700\u540e\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\u63d0\u51fa\u4e86AWP\u6a21\u578b\u3002", "result": "\u9996\u6b21\u8bc1\u660e\u4e86\u4e2a\u6027\u5316\u6210\u672c\u6a21\u578b\u5728\u751f\u6210CFE\u4e2d\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u7684AWP\u6a21\u578b\u80fd\u591f\u4ee584.37%\u7684\u51c6\u786e\u7387\u9884\u6d4b\u7528\u6237\u504f\u597d\u7684CFE\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u9700\u8981\u8bbe\u8ba1\u9002\u5e94\u6027\u7684\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684CFE\u8bc4\u4ef7\u6307\u6807\u6765\u63d0\u9ad8\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.15173", "pdf": "https://arxiv.org/pdf/2507.15173", "abs": "https://arxiv.org/abs/2507.15173", "authors": ["Jason Gaitonde", "Ankur Moitra", "Elchanan Mossel"], "title": "Better Models and Algorithms for Learning Ising Models from Dynamics", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": "49 pages", "summary": "We study the problem of learning the structure and parameters of the Ising\nmodel, a fundamental model of high-dimensional data, when observing the\nevolution of an associated Markov chain. A recent line of work has studied the\nnatural problem of learning when observing an evolution of the well-known\nGlauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Mossel STOC 2024], which provides an arguably more realistic\ngenerative model than the classical i.i.d. setting. However, this prior work\ncrucially assumes that all site update attempts are observed, \\emph{even when\nthis attempt does not change the configuration}: this strong observation model\nis seemingly essential for these approaches. While perhaps possible in\nrestrictive contexts, this precludes applicability to most realistic settings\nwhere we can observe \\emph{only} the stochastic evolution itself, a minimal and\nnatural assumption for any process we might hope to learn from. However,\ndesigning algorithms that succeed in this more realistic setting has remained\nan open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Moitra, Mossel, STOC 2025].\n  In this work, we give the first algorithms that efficiently learn the Ising\nmodel in this much more natural observation model that only observes when the\nconfiguration changes. For Ising models with maximum degree $d$, our algorithm\nrecovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log\nn$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time,\nwhich qualitatively matches the state-of-the-art even in the i.i.d. setting in\na much weaker observation model. Our analysis holds more generally for a\nbroader class of reversible, single-site Markov chains that also includes the\npopular Metropolis chain by leveraging more robust properties of reversible\nMarkov chains.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5728\u66f4\u81ea\u7136\u7684\u89c2\u5bdf\u6a21\u578b\u4e0b\u6709\u6548\u5b66\u4e60Ising\u6a21\u578b\u7684\u95ee\u9898\uff0c\u8be5\u6a21\u578b\u4ec5\u5728\u914d\u7f6e\u66f4\u6539\u65f6\u8fdb\u884c\u89c2\u5bdf\u3002\u5bf9\u4e8e\u6700\u5927\u5ea6\u4e3ad\u7684Ising\u6a21\u578b\uff0c\u7b97\u6cd5\u5728\u65f6\u95f4poly(d)\u00b7n\u00b2log n\u4e2d\u6062\u590d\u5e95\u5c42\u4f9d\u8d56\u56fe\uff0c\u5e76\u5728\u989d\u5916\u7684O~(2\u1d48n)\u65f6\u95f4\u5185\u6062\u590d\u5b9e\u9645\u53c2\u6570\u3002", "motivation": "\u4e4b\u524d\u7684\u5de5\u4f5c\u5047\u8bbe\u53ef\u4ee5\u89c2\u5bdf\u5230\u6240\u6709\u7684\u7ad9\u70b9\u66f4\u65b0\u5c1d\u8bd5\uff0c\u5373\u4f7f\u8fd9\u4e9b\u5c1d\u8bd5\u6ca1\u6709\u6539\u53d8\u914d\u7f6e\u3002\u7136\u800c\uff0c\u5728\u5927\u591a\u6570\u73b0\u5b9e\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ea\u80fd\u89c2\u5bdf\u5230\u968f\u673a\u6f14\u53d8\u672c\u8eab\u3002\u56e0\u6b64\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u53ef\u4ee5\u5728\u8fd9\u79cd\u66f4\u73b0\u5b9e\u7684\u8bbe\u7f6e\u4e2d\u6210\u529f\u7684\u7b97\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u53ef\u4ee5\u5728\u53ea\u89c2\u5bdf\u5230\u914d\u7f6e\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u5b66\u4e60Ising\u6a21\u578b\u7684\u7b97\u6cd5\u3002\u5bf9\u4e8e\u5177\u6709\u6700\u5927\u5ea6d\u7684Ising\u6a21\u578b\uff0c\u8be5\u7b97\u6cd5\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6062\u590d\u5e95\u5c42\u4f9d\u8d56\u56fe\u548c\u5b9e\u9645\u53c2\u6570\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u53ef\u9006\u5355\u7ad9\u70b9\u9a6c\u5c14\u79d1\u592b\u94fe\u7c7b\uff0c\u5305\u62ec\u6d41\u884c\u7684Metropolis\u94fe\u3002", "result": "\u8be5\u7b97\u6cd5\u80fd\u591f\u6062\u590d\u6700\u5927\u5ea6\u4e3ad\u7684Ising\u6a21\u578b\u7684\u5e95\u5c42\u4f9d\u8d56\u56fe\uff0c\u5e76\u4e14\u5728\u6bd4\u73b0\u6709\u6700\u4f73\u6280\u672f\u66f4\u5f31\u7684\u89c2\u5bdf\u6a21\u578b\u4e0b\uff0c\u5176\u6027\u80fd\u4e0e\u4e4b\u76f8\u5339\u914d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u63d0\u4f9b\u4e86\u5728\u66f4\u81ea\u7136\u7684\u89c2\u5bdf\u6a21\u578b\u4e2d\u6709\u6548\u5730\u5b66\u4e60Ising\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u8be5\u6a21\u578b\u4ec5\u5728\u914d\u7f6e\u53d8\u5316\u65f6\u8fdb\u884c\u89c2\u5bdf\u3002\u8fd9\u4e00\u6210\u679c\u6269\u5c55\u4e86\u5bf9\u53ef\u9006\u5355\u7ad9\u70b9\u9a6c\u5c14\u79d1\u592b\u94fe\u7684\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2507.15174", "pdf": "https://arxiv.org/pdf/2507.15174", "abs": "https://arxiv.org/abs/2507.15174", "authors": ["Justin Turnau", "Longchao Da", "Khoa Vo", "Ferdous Al Rafi", "Shreyas Bachiraju", "Tiejin Chen", "Hua Wei"], "title": "Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control", "categories": ["cs.LG"], "comment": "This paper was accepted to RLC/RLJ 2025", "summary": "Traffic Signal Control (TSC) is essential for managing urban traffic flow and\nreducing congestion. Reinforcement Learning (RL) offers an adaptive method for\nTSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)\ngaining traction as intersections naturally function as coordinated agents.\nHowever, due to shifts in environmental dynamics, implementing MARL-based TSC\npolicies in the real world often leads to a significant performance drop, known\nas the sim-to-real gap. Grounded Action Transformation (GAT) has successfully\nmitigated this gap in single-agent RL for TSC, but real-world traffic networks,\nwhich involve numerous interacting intersections, are better suited to a MARL\nframework. In this work, we introduce JL-GAT, an application of GAT to\nMARL-based TSC that balances scalability with enhanced grounding capability by\nincorporating information from neighboring agents. JL-GAT adopts a\ndecentralized approach to GAT, allowing for the scalability often required in\nreal-world traffic networks while still capturing key interactions between\nagents. Comprehensive experiments on various road networks under simulated\nadverse weather conditions, along with ablation studies, demonstrate the\neffectiveness of JL-GAT. The code is publicly available at\nhttps://github.com/DaRL-LibSignal/JL-GAT/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5JL-GAT\uff0c\u8be5\u65b9\u6cd5\u5c06GAT\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u4ee5\u6539\u8fdb\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff08TSC\uff09\uff0c\u5e76\u5728\u6a21\u62df\u7684\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\uff08TSC\uff09\u7b56\u7565\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5373\u6240\u8c13\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd(sim-to-real gap)\u3002\u867d\u7136\u5355\u667a\u80fd\u4f53RL\u4e2d\u7684Grounded Action Transformation (GAT) \u5df2\u7ecf\u6210\u529f\u7f13\u89e3\u4e86\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f46\u5b9e\u9645\u7684\u4ea4\u901a\u7f51\u7edc\u6d89\u53ca\u591a\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u4ea4\u53c9\u8def\u53e3\uff0c\u66f4\u9002\u5408\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "method": "\u5f15\u5165\u4e86JL-GAT\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u90bb\u8fd1\u667a\u80fd\u4f53\u7684\u4fe1\u606f\uff0c\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7840\u4e0a\u5b9e\u65bd\u4e86\u53bb\u4e2d\u5fc3\u5316\u7684GAT\u65b9\u6cd5\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u6027\u548c\u589e\u5f3a\u7684\u63a5\u5730\u80fd\u529b\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8bc1\u660e\u4e86JL-GAT\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u6a21\u62df\u7684\u6076\u52a3\u5929\u6c14\u6761\u4ef6\u4e0b\u7684\u5404\u79cd\u9053\u8def\u7f51\u7edc\u4e0a\u3002", "conclusion": "JL-GAT\u4e3a\u89e3\u51b3\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6848\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u9700\u8981\u8003\u8651\u4e0e\u90bb\u8fd1\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u5927\u578b\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u7f51\u7edc\u3002"}}
{"id": "2507.15195", "pdf": "https://arxiv.org/pdf/2507.15195", "abs": "https://arxiv.org/abs/2507.15195", "authors": ["Anwar Said", "Yifan Wei", "Ubaid Ullah Ahmad", "Mudassir Shabbir", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this article, we utilize the concept of average controllability in graphs,\nalong with a novel rank encoding method, to enhance the performance of Graph\nNeural Networks (GNNs) in social network classification tasks. GNNs have proven\nhighly effective in various network-based learning applications and require\nsome form of node features to function. However, their performance is heavily\ninfluenced by the expressiveness of these features. In social networks, node\nfeatures are often unavailable due to privacy constraints or the absence of\ninherent attributes, making it challenging for GNNs to achieve optimal\nperformance. To address this limitation, we propose two strategies for\nconstructing expressive node features. First, we introduce average\ncontrollability along with other centrality metrics (denoted as NCT-EFA) as\nnode-level metrics that capture critical aspects of network topology. Building\non this, we develop a rank encoding method that transforms average\ncontrollability or any other graph-theoretic metric into a fixed-dimensional\nfeature space, thereby improving feature representation. We conduct extensive\nnumerical evaluations using six benchmark GNN models across four social network\ndatasets to compare different node feature construction methods. Our results\ndemonstrate that incorporating average controllability into the feature space\nsignificantly improves GNN performance. Moreover, the proposed rank encoding\nmethod outperforms traditional one-hot degree encoding, improving the ROC AUC\nfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,\nunderscoring its effectiveness in generating expressive and efficient node\nrepresentations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u56fe\u7684\u5e73\u5747\u53ef\u63a7\u6027\u6982\u5ff5\u548c\u65b0\u9896\u7684\u79e9\u7f16\u7801\u65b9\u6cd5\u6765\u589e\u5f3aGNN\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5f15\u5165\u8282\u70b9\u7ea7\u5ea6\u91cfNCT-EFA\u5e76\u5f00\u53d1\u79e9\u7f16\u7801\u65b9\u6cd5\uff0c\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u80fd\u663e\u8457\u63d0\u5347GNN\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728GitHub Stargazers\u6570\u636e\u96c6\u4e0a\uff0cROC AUC\u4ece68.7%\u63d0\u9ad8\u523073.9%\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u9650\u5236\u6216\u56fa\u6709\u5c5e\u6027\u7684\u7f3a\u5931\uff0c\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u8282\u70b9\u7279\u5f81\u901a\u5e38\u4e0d\u53ef\u7528\uff0c\u8fd9\u4f7f\u5f97GNN\u96be\u4ee5\u8fbe\u5230\u6700\u4f73\u6027\u80fd\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\uff0c\u9700\u8981\u6784\u5efa\u8868\u73b0\u529b\u66f4\u5f3a\u7684\u8282\u70b9\u7279\u5f81\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\uff1a\u4e00\u662f\u5f15\u5165\u5e73\u5747\u53ef\u63a7\u6027\u548c\u5176\u4ed6\u4e2d\u5fc3\u6027\u6307\u6807\uff08NCT-EFA\uff09\u4f5c\u4e3a\u6355\u6349\u7f51\u7edc\u62d3\u6251\u5173\u952e\u65b9\u9762\u7684\u8282\u70b9\u7ea7\u5ea6\u91cf\uff1b\u4e8c\u662f\u5f00\u53d1\u4e86\u4e00\u79cd\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u6216\u5176\u4ed6\u56fe\u8bba\u5ea6\u91cf\u8f6c\u6362\u4e3a\u56fa\u5b9a\u7ef4\u5ea6\u7279\u5f81\u7a7a\u95f4\u7684\u79e9\u7f16\u7801\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u7eb3\u5165\u7279\u5f81\u7a7a\u95f4\u53ef\u4ee5\u663e\u8457\u6539\u5584GNN\u6027\u80fd\uff0c\u63d0\u51fa\u7684\u79e9\u7f16\u7801\u65b9\u6cd5\u6bd4\u4f20\u7edf\u7684\u4e00\u7ef4\u70ed\u5ea6\u7f16\u7801\u66f4\u4f18\uff0c\u5c24\u5176\u662f\u5728GitHub Stargazers\u6570\u636e\u96c6\u4e0a\uff0cROC AUC\u4ece68.7%\u63d0\u5347\u5230\u4e8673.9%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u91c7\u7528\u5e73\u5747\u53ef\u63a7\u6027\u6982\u5ff5\u548c\u79e9\u7f16\u7801\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8GNN\u5728\u793e\u4ea4\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u89e3\u51b3\u8282\u70b9\u7279\u5f81\u7f3a\u4e4f\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15205", "pdf": "https://arxiv.org/pdf/2507.15205", "abs": "https://arxiv.org/abs/2507.15205", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao"], "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "summary": "Emotion Recognition in Conversation (ERC) is a practical and challenging\ntask. This paper proposes a novel multimodal approach, the Long-Short Distance\nGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it\nconstructs a long-distance graph neural network and a short-distance graph\nneural network to obtain multimodal features of distant and nearby utterances,\nrespectively. To ensure that long- and short-distance features are as distinct\nas possible in representation while enabling mutual influence between the two\nmodules, we employ a Differential Regularizer and incorporate a BiAffine Module\nto facilitate feature interaction. In addition, we propose an Improved\nCurriculum Learning (ICL) to address the challenge of data imbalance. By\ncomputing the similarity between different emotions to emphasize the shifts in\nsimilar emotions, we design a \"weighted emotional shift\" metric and develop a\ndifficulty measurer, enabling a training process that prioritizes learning easy\nsamples before harder ones. Experimental results on the IEMOCAP and MELD\ndatasets demonstrate that our model outperforms existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u5373\u957f\u77ed\u671f\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\uff08LSDGNN\uff09\uff0c\u7528\u4e8e\u5bf9\u8bdd\u4e2d\u7684\u60c5\u7eea\u8bc6\u522b\u3002\u901a\u8fc7\u6784\u5efa\u957f\u8ddd\u79bb\u548c\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u5e76\u5f15\u5165\u5dee\u5f02\u6b63\u5219\u5316\u5668\u3001BiAffine\u6a21\u5757\u548c\u6539\u8fdb\u7684\u8bfe\u7a0b\u5b66\u4e60\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u5bf9\u8bdd\u4e2d\u60c5\u7eea\u8bc6\u522b\uff08ERC\uff09\u662f\u4e00\u9879\u5b9e\u7528\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u8fdc\u8fd1\u8bdd\u8bed\u4e4b\u95f4\u7684\u591a\u6a21\u6001\u7279\u5f81\u4ee5\u53ca\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\uff0c\u6784\u5efa\u4e86\u957f\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u4ee5\u5206\u522b\u83b7\u53d6\u8fdc\u5904\u548c\u9644\u8fd1\u7684\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u5dee\u5f02\u6b63\u5219\u5316\u5668\u786e\u4fdd\u4e24\u79cd\u7279\u5f81\u5c3d\u53ef\u80fd\u533a\u5206\u5f00\u6765\uff0c\u540c\u65f6\u5229\u7528BiAffine\u6a21\u5757\u4fc3\u8fdb\u7279\u5f81\u95f4\u7684\u4e92\u52a8\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff08ICL\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e0d\u540c\u60c5\u7eea\u95f4\u7684\u76f8\u4f3c\u5ea6\u8bbe\u8ba1\u4e86\u201c\u52a0\u6743\u60c5\u7eea\u8f6c\u6362\u201d\u6307\u6807\u548c\u96be\u5ea6\u6d4b\u91cf\u5de5\u5177\uff0c\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u6027\u80fd\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u57fa\u51c6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u957f\u77ed\u671f\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u5dee\u5f02\u6b63\u5219\u5316\u5668\u3001BiAffine\u6a21\u5757\u548c\u6539\u8fdb\u7684\u8bfe\u7a0b\u5b66\u4e60\uff0c\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5bf9\u8bdd\u4e2d\u60c5\u7eea\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.15240", "pdf": "https://arxiv.org/pdf/2507.15240", "abs": "https://arxiv.org/abs/2507.15240", "authors": ["Le Peng", "Yash Travadi", "Chuan He", "Ying Cui", "Ju Sun"], "title": "Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "For classification with imbalanced class frequencies, i.e., imbalanced\nclassification (IC), standard accuracy is known to be misleading as a\nperformance measure. While most existing methods for IC resort to optimizing\nbalanced accuracy (i.e., the average of class-wise recalls), they fall short in\nscenarios where the significance of classes varies or certain metrics should\nreach prescribed levels. In this paper, we study two key classification\nmetrics, precision and recall, under three practical binary IC settings: fix\nprecision optimize recall (FPOR), fix recall optimize precision (FROP), and\noptimize $F_\\beta$-score (OFBS). Unlike existing methods that rely on smooth\napproximations to deal with the indicator function involved, \\textit{we\nintroduce, for the first time, exact constrained reformulations for these\ndirect metric optimization (DMO) problems}, which can be effectively solved by\nexact penalty methods. Experiment results on multiple benchmark datasets\ndemonstrate the practical superiority of our approach over the state-of-the-art\nmethods for the three DMO problems. We also expect our exact reformulation and\noptimization (ERO) framework to be applicable to a wide range of DMO problems\nfor binary IC and beyond. Our code is available at\nhttps://github.com/sun-umn/DMO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u9996\u6b21\u5f15\u5165\u4e86\u76f4\u63a5\u5ea6\u91cf\u4f18\u5316\u95ee\u9898\u7684\u786e\u5207\u7ea6\u675f\u91cd\u6784\uff0c\u5e76\u901a\u8fc7\u7cbe\u786e\u60e9\u7f5a\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86IC\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2aDMO\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e0d\u5e73\u8861\u5206\u7c7b\uff08IC\uff09\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u4f18\u5316\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f46\u5728\u7c7b\u7684\u91cd\u8981\u6027\u53d8\u5316\u6216\u67d0\u4e9b\u6307\u6807\u9700\u8981\u8fbe\u5230\u89c4\u5b9a\u6c34\u5e73\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5e73\u6ed1\u8fd1\u4f3c\u6765\u5904\u7406\u6d89\u53ca\u7684\u6307\u793a\u51fd\u6570\u3002", "method": "\u7814\u7a76\u4e86\u4e8c\u5143IC\u8bbe\u7f6e\u4e0b\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e24\u4e2a\u5173\u952e\u5206\u7c7b\u6307\u6807\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9FPOR\u3001FROP\u548cOFBS\u4e09\u79cd\u5b9e\u9645IC\u573a\u666f\u7684\u786e\u5207\u7ea6\u675f\u91cd\u6784\u7684\u76f4\u63a5\u5ea6\u91cf\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5229\u7528\u7cbe\u786e\u60e9\u7f5a\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u4e09\u79cdDMO\u95ee\u9898\u4e0a\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u786e\u5207\u91cd\u6784\u548c\u4f18\u5316\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u591a\u79cd\u4e8c\u5143IC\u7684DMO\u95ee\u9898\uff0c\u8fd8\u53ef\u80fd\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.15246", "pdf": "https://arxiv.org/pdf/2507.15246", "abs": "https://arxiv.org/abs/2507.15246", "authors": ["Rabia Latief Bhat", "Iqra Altaf Gillani"], "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate demand forecasting is critical for enhancing the efficiency and\nresponsiveness of food delivery platforms, where spatial heterogeneity and\ntemporal fluctuations in order volumes directly influence operational\ndecisions. This paper proposes an attention-based Graph Neural Network\nframework that captures spatial-temporal dependencies by modeling the food\ndelivery environment as a graph. In this graph, nodes represent urban delivery\nzones, while edges reflect spatial proximity and inter-regional order flow\npatterns derived from historical data. The attention mechanism dynamically\nweighs the influence of neighboring zones, enabling the model to focus on the\nmost contextually relevant areas during prediction. Temporal trends are jointly\nlearned alongside spatial interactions, allowing the model to adapt to evolving\ndemand patterns. Extensive experiments on real-world food delivery datasets\ndemonstrate the superiority of the proposed model in forecasting future order\nvolumes with high accuracy. The framework offers a scalable and adaptive\nsolution to support proactive fleet positioning, resource allocation, and\ndispatch optimization in urban food delivery operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u6355\u6349\u98df\u54c1\u914d\u9001\u73af\u5883\u4e2d\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u63d0\u9ad8\u9700\u6c42\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u51c6\u786e\u7684\u9700\u6c42\u9884\u6d4b\u5bf9\u4e8e\u63d0\u9ad8\u98df\u54c1\u914d\u9001\u5e73\u53f0\u7684\u6548\u7387\u548c\u54cd\u5e94\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u800c\u8ba2\u5355\u91cf\u7684\u7a7a\u95f4\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u6ce2\u52a8\u76f4\u63a5\u5f71\u54cd\u8fd0\u8425\u51b3\u7b56\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u98df\u54c1\u914d\u9001\u73af\u5883\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56fe\uff0c\u5176\u4e2d\u8282\u70b9\u8868\u793a\u57ce\u5e02\u914d\u9001\u533a\u57df\uff0c\u8fb9\u53cd\u6620\u7a7a\u95f4\u63a5\u8fd1\u5ea6\u548c\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5f97\u51fa\u7684\u533a\u57df\u95f4\u8ba2\u5355\u6d41\u52a8\u6a21\u5f0f\u3002\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u5730\u6743\u8861\u90bb\u8fd1\u533a\u57df\u7684\u5f71\u54cd\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u7684\u533a\u57df\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u98df\u54c1\u914d\u9001\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u672a\u6765\u8ba2\u5355\u91cf\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u57ce\u5e02\u98df\u54c1\u914d\u9001\u64cd\u4f5c\u4e2d\u7684\u4e3b\u52a8\u8f66\u961f\u5b9a\u4f4d\u3001\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u4f18\u5316\u3002"}}
{"id": "2507.15260", "pdf": "https://arxiv.org/pdf/2507.15260", "abs": "https://arxiv.org/abs/2507.15260", "authors": ["Jiaqi Han", "Haotian Ye", "Puheng Li", "Minkai Xu", "James Zou", "Stefano Ermon"], "title": "CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers", "categories": ["cs.LG"], "comment": "ICCV 2025", "summary": "Diffusion-based generative models have become dominant generators of\nhigh-fidelity images and videos but remain limited by their computationally\nexpensive inference procedures. Existing acceleration techniques either require\nextensive model retraining or compromise significantly on sample quality. This\npaper explores a general, training-free, and model-agnostic acceleration\nstrategy via multi-core parallelism. Our framework views multi-core diffusion\nsampling as an ODE solver pipeline, where slower yet accurate solvers\nprogressively rectify faster solvers through a theoretically justified\ninter-core communication mechanism. This motivates our multi-core training-free\ndiffusion sampling accelerator, CHORDS, which is compatible with various\ndiffusion samplers, model architectures, and modalities. Through extensive\nexperiments, CHORDS significantly accelerates sampling across diverse\nlarge-scale image and video diffusion models, yielding up to 2.1x speedup with\nfour cores, improving by 50% over baselines, and 2.9x speedup with eight cores,\nall without quality degradation. This advancement enables CHORDS to establish a\nsolid foundation for real-time, high-fidelity diffusion generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6838\u5e76\u884c\u7684\u6269\u6563\u6a21\u578b\u52a0\u901f\u7b56\u7565CHORDS\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u53ef\u663e\u8457\u63d0\u5347\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u7684\u901f\u5ea6\u800c\u4e0d\u964d\u4f4e\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u52a0\u901f\u6280\u672f\u8981\u4e48\u9700\u8981\u5927\u91cf\u7684\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\uff0c\u8981\u4e48\u5728\u6837\u672c\u8d28\u91cf\u4e0a\u6709\u5f88\u5927\u7684\u59a5\u534f\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u4e00\u79cd\u901a\u7528\u7684\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u52a0\u901f\u7b56\u7565\u662f\u975e\u5e38\u5fc5\u8981\u7684\u3002", "method": "\u8be5\u6846\u67b6\u5c06\u591a\u6838\u6269\u6563\u91c7\u6837\u89c6\u4e3a\u4e00\u4e2aODE\u6c42\u89e3\u5668\u7ba1\u9053\uff0c\u5176\u4e2d\u8f83\u6162\u4f46\u51c6\u786e\u7684\u6c42\u89e3\u5668\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u7684\u6838\u95f4\u901a\u4fe1\u673a\u5236\u9010\u6b65\u4fee\u6b63\u8f83\u5feb\u7684\u6c42\u89e3\u5668\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0cCHORDS\u663e\u8457\u52a0\u901f\u4e86\u5404\u79cd\u5927\u89c4\u6a21\u56fe\u50cf\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u8fc7\u7a0b\uff0c\u4f7f\u7528\u56db\u4e2a\u6838\u5fc3\u65f6\u901f\u5ea6\u63d0\u9ad8\u4e862.1\u500d\uff0c\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u4e8650%\uff0c\u4f7f\u7528\u516b\u4e2a\u6838\u5fc3\u65f6\u901f\u5ea6\u63d0\u9ad8\u4e862.9\u500d\uff0c\u4e14\u6ca1\u6709\u8d28\u91cf\u4e0b\u964d\u3002", "conclusion": "CHORDS\u4e3a\u5b9e\u65f6\u3001\u9ad8\u4fdd\u771f\u6269\u6563\u751f\u6210\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2507.15274", "pdf": "https://arxiv.org/pdf/2507.15274", "abs": "https://arxiv.org/abs/2507.15274", "authors": ["Matthew J. Bryan", "Felix Schwock", "Azadeh Yazdan-Shahmorad", "Rajesh P N Rao"], "title": "Temporal Basis Function Models for Closed-Loop Neural Stimulation", "categories": ["cs.LG"], "comment": null, "summary": "Closed-loop neural stimulation provides novel therapies for neurological\ndiseases such as Parkinson's disease (PD), but it is not yet clear whether\nartificial intelligence (AI) techniques can tailor closed-loop stimulation to\nindividual patients or identify new therapies. Progress requires us to address\na number of translational issues, including sample efficiency, training time,\nand minimizing loop latency such that stimulation may be shaped in response to\nchanging brain activity. We propose temporal basis function models (TBFMs) to\naddress these difficulties, and explore this approach in the context of\nexcitatory optogenetic stimulation. We demonstrate the ability of TBF models to\nprovide a single-trial, spatiotemporal forward prediction of the effect of\noptogenetic stimulation on local field potentials (LFPs) measured in two\nnon-human primates. We further use simulations to demonstrate the use of TBF\nmodels for closed-loop stimulation, driving neural activity towards target\npatterns. The simplicity of TBF models allow them to be sample efficient, rapid\nto train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the\nmodel on 40 sessions of previously published excitatory optogenetic stimulation\ndata. For each session, the model required 15-20min of data collection to\nsuccessfully model the remainder of the session. It achieved a prediction\naccuracy comparable to a baseline nonlinear dynamical systems model that\nrequires hours to train, and superior accuracy to a linear state-space model.\nIn our simulations, it also successfully allowed a closed-loop stimulator to\ncontrol a neural circuit. Our approach begins to bridge the translational gap\nbetween complex AI-based approaches to modeling dynamical systems and the\nvision of using such forward prediction models to develop novel, clinically\nuseful closed-loop stimulation protocols.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFMs\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5e15\u91d1\u68ee\u75c5\u7684\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u6cbb\u7597\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5730\u9884\u6d4b\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u5728\u6a21\u62df\u4e2d\u6210\u529f\u5b9e\u73b0\u4e86\u95ed\u73af\u523a\u6fc0\uff0c\u4f7f\u5f97\u795e\u7ecf\u6d3b\u52a8\u8d8b\u5411\u76ee\u6807\u6a21\u5f0f\u3002\u76f8\u6bd4\u5176\u4ed6\u6a21\u578b\uff0cTBFMs\u5177\u6709\u6837\u672c\u6548\u7387\u9ad8\u3001\u8bad\u7ec3\u5feb\u901f\u3001\u4f4e\u5ef6\u8fdf\u7b49\u4f18\u70b9\u3002", "motivation": "\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u4e3a\u5e15\u91d1\u68ee\u75c5\u7b49\u795e\u7ecf\u75be\u75c5\u63d0\u4f9b\u4e86\u65b0\u7684\u6cbb\u7597\u65b9\u6cd5\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u4eba\u5de5\u667a\u80fd\u6280\u672f\u80fd\u5426\u4e3a\u4e2a\u4f53\u60a3\u8005\u5b9a\u5236\u95ed\u73af\u523a\u6fc0\u6216\u53d1\u73b0\u65b0\u7597\u6cd5\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u9700\u8981\u89e3\u51b3\u6837\u672c\u6548\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u4ee5\u53ca\u6700\u5c0f\u5316\u5faa\u73af\u5ef6\u8fdf\u7b49\u95ee\u9898\u3002", "method": "\u672c\u6587\u91c7\u7528\u65f6\u95f4\u57fa\u51fd\u6570\u6a21\u578b\uff08TBFMs\uff09\uff0c\u5e76\u7ed3\u5408\u5174\u594b\u6027\u5149\u9057\u4f20\u523a\u6fc0\u8fdb\u884c\u7814\u7a76\u3002\u901a\u8fc7\u4f7f\u7528TBFMs\uff0c\u53ef\u4ee5\u5728\u5355\u6b21\u8bd5\u9a8c\u4e2d\u5bf9\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\u7684\u5f71\u54cd\u8fdb\u884c\u65f6\u7a7a\u524d\u5411\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u6a21\u62df\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1TBFMs\u5728\u95ed\u73af\u523a\u6fc0\u4e2d\u7684\u5e94\u7528\u3002", "result": "TBFMs\u5728\u9884\u6d4b\u5149\u9057\u4f20\u523a\u6fc0\u5bf9\u5c40\u90e8\u573a\u7535\u4f4d\u7684\u5f71\u54cd\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5176\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u6a21\u578b\u76f8\u5f53\uff0c\u4f18\u4e8e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002\u540c\u65f6\uff0c\u5728\u6a21\u62df\u4e2d\uff0cTBFMs\u6210\u529f\u5b9e\u73b0\u4e86\u95ed\u73af\u523a\u6fc0\u63a7\u5236\u795e\u7ecf\u7535\u8def\u7684\u529f\u80fd\u3002", "conclusion": "TBFMs\u5728\u95ed\u73af\u795e\u7ecf\u523a\u6fc0\u6cbb\u7597\u4e2d\u5c55\u73b0\u51fa\u4e86\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u9ad8\u6548\u9884\u6d4b\u795e\u7ecf\u53cd\u5e94\uff0c\u800c\u4e14\u5728\u95ed\u73af\u63a7\u5236\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u8272\u3002\u8fd9\u4e3a\u5f00\u53d1\u65b0\u578b\u3001\u4e34\u5e8a\u6709\u7528\u7684\u95ed\u73af\u523a\u6fc0\u534f\u8bae\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.15280", "pdf": "https://arxiv.org/pdf/2507.15280", "abs": "https://arxiv.org/abs/2507.15280", "authors": ["Shaofei Shen", "Chenhao Zhang", "Yawen Zhao", "Alina Bialkowski", "Weitong Chen", "Miao Xu"], "title": "Machine Unlearning for Streaming Forgetting", "categories": ["cs.LG"], "comment": null, "summary": "Machine unlearning aims to remove knowledge of the specific training data in\na well-trained model. Currently, machine unlearning methods typically handle\nall forgetting data in a single batch, removing the corresponding knowledge all\nat once upon request. However, in practical scenarios, requests for data\nremoval often arise in a streaming manner rather than in a single batch,\nleading to reduced efficiency and effectiveness in existing methods. Such\nchallenges of streaming forgetting have not been the focus of much research. In\nthis paper, to address the challenges of performance maintenance, efficiency,\nand data access brought about by streaming unlearning requests, we introduce a\nstreaming unlearning paradigm, formalizing the unlearning as a distribution\nshift problem. We then estimate the altered distribution and propose a novel\nstreaming unlearning algorithm to achieve efficient streaming forgetting\nwithout requiring access to the original training data. Theoretical analyses\nconfirm an $O(\\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,\nwhere $V_T$ represents the cumulative total variation in the optimal solution\nover $T$ learning rounds. This theoretical guarantee is achieved under mild\nconditions without the strong restriction of convex loss function. Experiments\nacross various models and datasets validate the performance of our proposed\nmethod.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f0f\u9057\u5fd8\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u9057\u5fd8\u89c6\u4e3a\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u7684\u6d41\u5f0f\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u4e00\u6b21\u6027\u5904\u7406\u6240\u6709\u9700\u8981\u88ab\u9057\u5fd8\u7684\u6570\u636e\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u6570\u636e\u5220\u9664\u8bf7\u6c42\u5f80\u5f80\u662f\u6d41\u5f0f\u7684\uff0c\u8fd9\u5bfc\u81f4\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u6d41\u5f0f\u9057\u5fd8\u5b66\u4e60\u8303\u5f0f\uff0c\u5c06\u9057\u5fd8\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u9700\u8981\u8bbf\u95ee\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u7684\u65b0\u578b\u6d41\u5f0f\u9057\u5fd8\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u8be5\u7b97\u6cd5\u5728T\u8f6e\u5b66\u4e60\u4e2d\u7684\u6d41\u5f0f\u9057\u5fd8\u540e\u6094\u503c\u6709\u4e00\u4e2aO(\u221aT + VT)\u7684\u8bef\u5dee\u754c\uff0c\u5e76\u4e14\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u5904\u7406\u6d41\u5f0f\u6570\u636e\u5220\u9664\u8bf7\u6c42\u7684\u65b9\u6cd5\uff0c\u5e76\u4e3a\u673a\u5668\u9057\u5fd8\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.15287", "pdf": "https://arxiv.org/pdf/2507.15287", "abs": "https://arxiv.org/abs/2507.15287", "authors": ["Elias Malomgr\u00e9", "Pieter Simoens"], "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 8 figures, accepted for the non-archival workshop \"Workshop\n  on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference\n  2025\"", "summary": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to\nlearn from reward-free interactions and alternative supervision signals, such\nas unlabeled or incomplete demonstrations, rather than relying solely on\nexplicit reward maximization. Additionally, developing generalist agents that\ncan adapt efficiently in real-world environments often requires leveraging\nthese reward-free signals to guide learning and behavior. However, while\nintrinsic motivation techniques provide a means for agents to seek out novel or\nuncertain states in the absence of explicit rewards, they are often challenged\nby dense reward environments or the complexity of high-dimensional state and\naction spaces. Furthermore, most existing approaches rely directly on the\nunprocessed intrinsic reward signals, which can make it difficult to shape or\ncontrol the agent's exploration effectively. We propose a framework that can\neffectively utilize expert demonstrations, even when they are incomplete and\nimperfect. By applying a mapping function to transform the similarity between\nan agent's state and expert data into a shaped intrinsic reward, our method\nallows for flexible and targeted exploration of expert-like behaviors. We\nemploy a Mixture of Autoencoder Experts to capture a diverse range of behaviors\nand accommodate missing information in demonstrations. Experiments show our\napproach enables robust exploration and strong performance in both sparse and\ndense reward environments, even when demonstrations are sparse or incomplete.\nThis provides a practical framework for RL in realistic settings where optimal\ndata is unavailable and precise reward control is needed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u672a\u6807\u8bb0\u6216\u4e0d\u5b8c\u6574\u6f14\u793a\u6570\u636e\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u72b6\u6001\u76f8\u4f3c\u6027\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\u6765\u5f15\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5956\u52b1\u5bc6\u5ea6\u73af\u5883\u4e0b\u5747\u80fd\u5b9e\u73b0\u7a33\u5065\u63a2\u7d22\u548c\u9ad8\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7684\u8d8b\u52bf\u5f3a\u8c03\u4e86\u65e0\u9700\u4f9d\u8d56\u663e\u5f0f\u5956\u52b1\u6700\u5927\u5316\uff0c\u800c\u4ece\u65e0\u5956\u52b1\u4ea4\u4e92\u548c\u66ff\u4ee3\u76d1\u7763\u4fe1\u53f7\u4e2d\u5b66\u4e60\u7684\u91cd\u8981\u6027\uff0c\u5c24\u5176\u662f\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u53d1\u5c55\u901a\u7528\u667a\u80fd\u4f53\u65f6\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5185\u5728\u52a8\u673a\u6280\u672f\u9762\u5bf9\u590d\u6742\u73af\u5883\u6216\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u9762\u4e34\u6311\u6218\uff0c\u4e14\u96be\u4ee5\u6709\u6548\u5851\u9020\u6216\u63a7\u5236\u63a2\u7d22\u8fc7\u7a0b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u5e94\u7528\u6620\u5c04\u51fd\u6570\u5c06\u667a\u80fd\u4f53\u72b6\u6001\u4e0e\u4e13\u5bb6\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u8f6c\u6362\u4e3a\u6210\u5f62\u7684\u5185\u5728\u5956\u52b1\uff0c\u4ee5\u5141\u8bb8\u7075\u6d3b\u548c\u6709\u9488\u5bf9\u6027\u5730\u63a2\u7d22\u7c7b\u4f3c\u4e13\u5bb6\u7684\u884c\u4e3a\u3002\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u6355\u6349\u591a\u6837\u884c\u4e3a\u5e76\u5904\u7406\u6f14\u793a\u4e2d\u7684\u7f3a\u5931\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5956\u52b1\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u63a2\u7d22\uff0c\u5e76\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u6f14\u793a\u6570\u636e\u7a00\u758f\u6216\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u8fd9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u4e2d\u7f3a\u4e4f\u6700\u4f18\u6570\u636e\u5e76\u4e14\u9700\u8981\u7cbe\u786e\u5956\u52b1\u63a7\u5236\u7684\u60c5\u51b5\u3002"}}
{"id": "2507.15288", "pdf": "https://arxiv.org/pdf/2507.15288", "abs": "https://arxiv.org/abs/2507.15288", "authors": ["Omid G. Sani", "Maryam M. Shanechi"], "title": "Preferential subspace identification (PSID) with forward-backward smoothing", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 5 figures", "summary": "System identification methods for multivariate time-series, such as neural\nand behavioral recordings, have been used to build models for predicting one\nfrom the other. For example, Preferential Subspace Identification (PSID) builds\na state-space model of a primary time-series (e.g., neural activity) to\noptimally predict a secondary time-series (e.g., behavior). However, PSID\nfocuses on optimal prediction using past primary data, even though in offline\napplications, better estimation can be achieved by incorporating concurrent\ndata (filtering) or all available data (smoothing). Here, we extend PSID to\nenable optimal filtering and smoothing. First, we show that the presence of a\nsecondary signal makes it possible to uniquely identify a model with an optimal\nKalman update step (to enable filtering) from a family of otherwise equivalent\nstate-space models. Our filtering solution augments PSID with a reduced-rank\nregression step that directly learns the optimal gain required for the update\nstep from data. We refer to this extension of PSID as PSID with filtering.\nSecond, inspired by two-filter Kalman smoother formulations, we develop a novel\nforward-backward PSID smoothing algorithm where we first apply PSID with\nfiltering and then apply it again in the reverse time direction on the\nresiduals of the filtered secondary signal. We validate our methods on\nsimulated data, showing that our approach recovers the ground-truth model\nparameters for filtering, and achieves optimal filtering and smoothing decoding\nperformance of the secondary signal that matches the ideal performance of the\ntrue underlying model. This work provides a principled framework for optimal\nlinear filtering and smoothing in the two-signal setting, significantly\nexpanding the toolkit for analyzing dynamic interactions in multivariate\ntime-series.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86PSID\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f18\u6ee4\u6ce2\u548c\u5e73\u6ed1\u5904\u7406\u3002\u901a\u8fc7\u5f15\u5165\u964d\u79e9\u56de\u5f52\u6b65\u9aa4\u5b66\u4e60\u6700\u4f18\u589e\u76ca\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u524d\u5411-\u540e\u5411PSID\u5e73\u6ed1\u7b97\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u6570\u636e\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u80fd\u591f\u6062\u590d\u6a21\u578b\u53c2\u6570\u5e76\u8fbe\u5230\u7406\u60f3\u7684\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684PSID\u65b9\u6cd5\u4ec5\u4f7f\u7528\u8fc7\u53bb\u7684\u4e3b\u8981\u6570\u636e\u8fdb\u884c\u9884\u6d4b\uff0c\u5373\u4f7f\u5728\u79bb\u7ebf\u5e94\u7528\u4e2d\uff0c\u901a\u8fc7\u5305\u542b\u540c\u65f6\u671f\u6570\u636e\uff08\u6ee4\u6ce2\uff09\u6216\u6240\u6709\u53ef\u7528\u6570\u636e\uff08\u5e73\u6ed1\uff09\uff0c\u53ef\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u4f30\u8ba1\u3002", "method": "\u9996\u5148\u5c55\u793a\u4e86\u6b21\u8981\u4fe1\u53f7\u7684\u5b58\u5728\u4f7f\u5f97\u53ef\u4ee5\u4ece\u4e00\u7cfb\u5217\u7b49\u6548\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u552f\u4e00\u8bc6\u522b\u51fa\u5177\u6709\u6700\u4f18\u5361\u5c14\u66fc\u66f4\u65b0\u6b65\u9aa4\u7684\u6a21\u578b\u3002\u7136\u540e\uff0c\u901a\u8fc7\u5f15\u5165\u964d\u79e9\u56de\u5f52\u6b65\u9aa4\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u66f4\u65b0\u6b65\u9aa4\u6240\u9700\u7684\u6700\u4f18\u589e\u76ca\u3002\u6700\u540e\uff0c\u53d7\u5230\u53cc\u6ee4\u6ce2\u5361\u5c14\u66fc\u5e73\u6ed1\u5668\u516c\u5f0f\u542f\u53d1\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u524d\u5411-\u540e\u5411PSID\u5e73\u6ed1\u7b97\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u80fd\u591f\u6062\u590d\u771f\u5b9e\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u4e0e\u5b9e\u9645\u5e95\u5c42\u6a21\u578b\u7684\u7406\u60f3\u6027\u80fd\u76f8\u5339\u914d\u7684\u6700\u4f18\u6ee4\u6ce2\u548c\u5e73\u6ed1\u89e3\u7801\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4e24\u4e2a\u4fe1\u53f7\u8bbe\u7f6e\u4e2d\u7684\u6700\u4f18\u7ebf\u6027\u6ee4\u6ce2\u548c\u5e73\u6ed1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6846\u67b6\uff0c\u663e\u8457\u6269\u5c55\u4e86\u5206\u6790\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u52a8\u6001\u4ea4\u4e92\u7684\u5de5\u5177\u5305\u3002"}}
{"id": "2507.15290", "pdf": "https://arxiv.org/pdf/2507.15290", "abs": "https://arxiv.org/abs/2507.15290", "authors": ["Emile Anand", "Sarah Liaw"], "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown", "categories": ["cs.LG", "I.2.6; I.2.0"], "comment": "39 pages, 2 figures, 36 tables", "summary": "Thompson Sampling (TS) is widely used to address the exploration/exploitation\ntradeoff in contextual bandits, yet recent theory shows that it does not\nexplore aggressively enough in high-dimensional problems. Feel-Good Thompson\nSampling (FG-TS) addresses this by adding an optimism bonus that biases toward\nhigh-reward models, and it achieves the asymptotically minimax-optimal regret\nin the linear setting when posteriors are exact. However, its performance with\n\\emph{approximate} posteriors -- common in large-scale or neural problems --\nhas not been benchmarked. We provide the first systematic study of FG-TS and\nits smoothed variant (SFG-TS) across eleven real-world and synthetic\nbenchmarks. To evaluate their robustness, we compare performance across\nsettings with exact posteriors (linear and logistic bandits) to approximate\nregimes produced by fast but coarse stochastic-gradient samplers. Ablations\nover preconditioning, bonus scale, and prior strength reveal a trade-off:\nlarger bonuses help when posterior samples are accurate, but hurt when sampling\nnoise dominates. FG-TS generally outperforms vanilla TS in linear and logistic\nbandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS\nand its variants are competitive and easy-to-use, we recommend them as\nbaselines in modern contextual-bandit benchmarks. Finally, we provide source\ncode for all our experiments in\nhttps://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9Feel-Good Thompson Sampling (FG-TS)\u53ca\u5176\u5e73\u6ed1\u53d8\u4f53(SFG-TS)\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6d89\u53ca\u771f\u5b9e\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7ebf\u6027\u548c\u903b\u8f91bandits\u4e2d\uff0cFG-TS\u901a\u5e38\u4f18\u4e8e\u4f20\u7edf\u7684TS\uff0c\u4f46\u5728\u795e\u7ecf\u7f51\u7edc\u73af\u5883\u4e2d\u8868\u73b0\u8f83\u5f31\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5176\u7ade\u4e89\u529b\u548c\u6613\u7528\u6027\uff0c\u4ecd\u63a8\u8350\u4f5c\u4e3a\u73b0\u4ee3\u60c5\u5883bandit\u57fa\u51c6\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "Thompson Sampling (TS)\u5728\u9ad8\u7ef4\u95ee\u9898\u4e2d\u7684\u63a2\u7d22\u4e0d\u8db3\u662f\u5df2\u77e5\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u70b9\uff0c\u63d0\u51fa\u4e86Feel-Good Thompson Sampling (FG-TS)\uff0c\u5b83\u901a\u8fc7\u589e\u52a0\u4e50\u89c2\u5956\u52b1\u6765\u66f4\u503e\u5411\u4e8e\u9ad8\u56de\u62a5\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u540e\u9a8c\u5206\u5e03\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u9057\u61be\u3002\u4f46\u662f\uff0c\u5bf9\u4e8e\u5927\u89c4\u6a21\u6216\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u95ee\u9898\u4e2d\u5e38\u89c1\u7684\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\uff0cFG-TS\u7684\u8868\u73b0\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5bf9FG-TS\u53ca\u5176\u5e73\u6ed1\u53d8\u4f53(SFG-TS)\u8fdb\u884c\u4e8611\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002\u4ed6\u4eec\u6bd4\u8f83\u4e86\u4e0d\u540c\u8bbe\u5b9a\u4e0b\uff08\u5305\u62ec\u7cbe\u786e\u548c\u8fd1\u4f3c\u7684\u540e\u9a8c\u5206\u5e03\uff09\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u9884\u5904\u7406\u3001\u5956\u52b1\u89c4\u6a21\u548c\u5148\u9a8c\u5f3a\u5ea6\u7b49\u56e0\u7d20\u5206\u6790\u4e86\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5f71\u54cdFG-TS\u7684\u8868\u73b0\u3002", "result": "FG-TS\u5728\u5177\u6709\u7cbe\u786e\u540e\u9a8c\u6837\u672c\u7684\u7ebf\u6027\u548c\u903b\u8f91bandits\u4e2d\u901a\u5e38\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u795e\u7ecf\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u8868\u73b0\u4e0d\u5982\u4f20\u7edfTS\u3002\u6b64\u5916\uff0c\u8f83\u5927\u7684\u5956\u52b1\u6709\u52a9\u4e8e\u5f53\u540e\u9a8c\u6837\u672c\u51c6\u786e\u65f6\uff0c\u4f46\u5f53\u91c7\u6837\u566a\u58f0\u5360\u4e3b\u5bfc\u5730\u4f4d\u65f6\u4f1a\u9002\u5f97\u5176\u53cd\u3002", "conclusion": "\u5c3d\u7ba1FG-TS\u53ca\u5176\u53d8\u4f53\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u4e0d\u5982\u5176\u4ed6\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u5b83\u4eec\u7684\u7ade\u4e89\u6027\u548c\u6613\u4e8e\u4f7f\u7528\uff0c\u4ecd\u7136\u5efa\u8bae\u5c06\u5b83\u4eec\u4f5c\u4e3a\u73b0\u4ee3\u60c5\u5883bandit\u57fa\u51c6\u6d4b\u8bd5\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5e76\u4e14\u63d0\u4f9b\u4e86\u6240\u6709\u5b9e\u9a8c\u7684\u6e90\u4ee3\u7801\u3002"}}
{"id": "2507.15303", "pdf": "https://arxiv.org/pdf/2507.15303", "abs": "https://arxiv.org/abs/2507.15303", "authors": ["Liang Zhang", "Kong Chen", "Yuen Wu"], "title": "Universal crystal material property prediction via multi-view geometric fusion in graph transformers", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "Accurately and comprehensively representing crystal structures is critical\nfor advancing machine learning in large-scale crystal materials simulations,\nhowever, effectively capturing and leveraging the intricate geometric and\ntopological characteristics of crystal structures remains a core, long-standing\nchallenge for most existing methods in crystal property prediction. Here, we\npropose MGT, a multi-view graph transformer framework that synergistically\nfuses SE3 invariant and SO3 equivariant graph representations, which\nrespectively captures rotation-translation invariance and rotation equivariance\nin crystal geometries. To strategically incorporate these complementary\ngeometric representations, we employ a lightweight mixture of experts router in\nMGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on\nthe specific target task. Compared with previous state-of-the-art models, MGT\nreduces the mean absolute error by up to 21% on crystal property prediction\ntasks through multi-task self-supervised pretraining. Ablation experiments and\ninterpretable investigations confirm the effectiveness of each technique\nimplemented in our framework. Additionally, in transfer learning scenarios\nincluding crystal catalyst adsorption energy and hybrid perovskite bandgap\nprediction, MGT achieves performance improvements of up to 58% over existing\nbaselines, demonstrating domain-agnostic scalability across diverse application\ndomains. As evidenced by the above series of studies, we believe that MGT can\nserve as useful model for crystal material property prediction, providing a\nvaluable tool for the discovery of novel materials.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u89c6\u56fe\u56fe\u53d8\u6362\u5668\u6846\u67b6MGT\uff0c\u7528\u4e8e\u6676\u4f53\u7ed3\u6784\u7684\u591a\u4efb\u52a1\u81ea\u6211\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u4ee5\u63d0\u9ad8\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u65b9\u6cd5\u5728\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u4e2d\u96be\u4ee5\u6709\u6548\u5730\u6355\u6349\u548c\u5229\u7528\u6676\u4f53\u7ed3\u6784\u590d\u6742\u7684\u51e0\u4f55\u548c\u62d3\u6251\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMGT\u7684\u591a\u89c6\u56fe\u56fe\u53d8\u6362\u5668\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86SE3\u4e0d\u53d8\u548cSO3\u7b49\u53d8\u56fe\u8868\u793a\uff0c\u4ee5\u6355\u6349\u6676\u4f53\u51e0\u4f55\u4e2d\u7684\u65cb\u8f6c-\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u65cb\u8f6c\u7b49\u53d8\u6027\u3002\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4e13\u5bb6\u6df7\u5408\u8def\u7531\u5668\u6765\u81ea\u9002\u5e94\u5730\u8c03\u6574SE3\u548cSO3\u5d4c\u5165\u7684\u6743\u91cd\u3002", "result": "\u4e0e\u4ee5\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u76f8\u6bd4\uff0cMGT\u5728\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e0a\u5c06\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u964d\u4f4e\u4e8621%\uff0c\u5e76\u5728\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe58%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MGT\u53ef\u4ee5\u4f5c\u4e3a\u6709\u7528\u7684\u6a21\u578b\u7528\u4e8e\u6676\u4f53\u6750\u6599\u6027\u8d28\u9884\u6d4b\uff0c\u4e3a\u65b0\u6750\u6599\u7684\u53d1\u73b0\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2507.15336", "pdf": "https://arxiv.org/pdf/2507.15336", "abs": "https://arxiv.org/abs/2507.15336", "authors": ["Jialiang Wang", "Hanmo Liu", "Shimin Di", "Zhili Wang", "Jiachuan Wang", "Lei Chen", "Xiaofang Zhou"], "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Database systems have recently advocated for embedding machine learning (ML)\ncapabilities, offering declarative model queries over large, managed model\nrepositories, thereby circumventing the huge computational overhead of\ntraditional ML-based algorithms in automated neural network model selection.\nPioneering database studies aim to organize existing benchmark repositories as\nmodel bases (MB), querying them for the model records with the highest\nperformance estimation metrics for given tasks. However, this static model\nselection practice overlooks the fine-grained, evolving relational dependencies\nbetween diverse task queries and model architecture variations, resulting in\nsuboptimal matches and failing to further refine the model effectively. To fill\nthe model refinement gap in database research, we propose M-DESIGN, a curated\nmodel knowledge base (MKB) pipeline for mastering neural network refinement by\nadaptively weaving prior insights about model architecture modification. First,\nwe propose a knowledge weaving engine that reframes model refinement as an\nadaptive query problem over task metadata. Given a user's task query, M-DESIGN\nquickly matches and iteratively refines candidate models by leveraging a\ngraph-relational knowledge schema that explicitly encodes data properties,\narchitecture variations, and pairwise performance deltas as joinable relations.\nThis schema supports fine-grained relational analytics over architecture tweaks\nand drives a predictive query planner that can detect and adapt to\nout-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics\ntasks, where our model knowledge base enriches existing benchmarks with\nstructured metadata covering 3 graph tasks and 22 graph datasets, contributing\ndata records of 67,760 graph models. Empirical results demonstrate that\nM-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited\nbudgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faM-DESIGN\uff0c\u4e00\u4e2a\u7528\u4e8e\u901a\u8fc7\u81ea\u9002\u5e94\u7f16\u7ec7\u5148\u524d\u5173\u4e8e\u6a21\u578b\u67b6\u6784\u4fee\u6539\u7684\u89c1\u89e3\u6765\u638c\u63e1\u795e\u7ecf\u7f51\u7edc\u7ec6\u5316\u7684\u7cbe\u5fc3\u7b56\u5212\u7684\u6a21\u578b\u77e5\u8bc6\u5e93\uff08MKB\uff09\u7ba1\u9053\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u5e93\u7814\u7a76\u5728\u6a21\u578b\u7ec6\u5316\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9759\u6001\u6a21\u578b\u9009\u62e9\u5b9e\u8df5\u5ffd\u7565\u4e86\u4efb\u52a1\u67e5\u8be2\u548c\u6a21\u578b\u67b6\u6784\u53d8\u5316\u4e4b\u95f4\u7ec6\u7c92\u5ea6\u3001\u4e0d\u65ad\u6f14\u53d8\u7684\u5173\u7cfb\u4f9d\u8d56\u6027\uff0c\u5bfc\u81f4\u6b21\u4f18\u5339\u914d\uff0c\u65e0\u6cd5\u6709\u6548\u8fdb\u4e00\u6b65\u7ec6\u5316\u6a21\u578b\u3002", "method": "\u9996\u5148\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\uff0c\u5c06\u6a21\u578b\u7ec6\u5316\u91cd\u6784\u4e3a\u4efb\u52a1\u5143\u6570\u636e\u4e0a\u7684\u81ea\u9002\u5e94\u67e5\u8be2\u95ee\u9898\u3002\u7ed9\u5b9a\u7528\u6237\u7684\u4efb\u52a1\u67e5\u8be2\uff0cM-DESIGN\u901a\u8fc7\u5229\u7528\u56fe\u5f62\u5173\u7cfb\u77e5\u8bc6\u6a21\u5f0f\u5feb\u901f\u5339\u914d\u5e76\u8fed\u4ee3\u7ec6\u5316\u5019\u9009\u6a21\u578b\uff0c\u8be5\u6a21\u5f0f\u660e\u786e\u7f16\u7801\u4e86\u6570\u636e\u5c5e\u6027\u3001\u67b6\u6784\u53d8\u5316\u548c\u6210\u5bf9\u6027\u80fd\u5dee\u5f02\u4f5c\u4e3a\u53ef\u8fde\u63a5\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u9884\u7b97\u5185\uff0cM-DESIGN\u572833\u4e2a\u6570\u636e\u4efb\u52a1\u5bf9\u4e2d\u768426\u4e2a\u4e2d\u63d0\u4f9b\u4e86\u6700\u4f18\u6a21\u578b\u3002", "conclusion": "M-DESIGN\u901a\u8fc7\u5176\u72ec\u7279\u7684\u77e5\u8bc6\u7f16\u7ec7\u5f15\u64ce\u548c\u9884\u6d4b\u67e5\u8be2\u8ba1\u5212\u5668\uff0c\u80fd\u591f\u68c0\u6d4b\u548c\u9002\u5e94\u79bb\u7fa4\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u9009\u62e9\u548c\u4f18\u5316\u3002"}}
{"id": "2507.15349", "pdf": "https://arxiv.org/pdf/2507.15349", "abs": "https://arxiv.org/abs/2507.15349", "authors": ["Zehua Cheng", "Rui Sun", "Jiahao Sun", "Yike Guo"], "title": "Scaling Decentralized Learning with FLock", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Fine-tuning the large language models (LLMs) are prevented by the deficiency\nof centralized control and the massive computing and communication overhead on\nthe decentralized schemes. While the typical standard federated learning (FL)\nsupports data privacy, the central server requirement creates a single point of\nattack and vulnerability to poisoning attacks. Generalizing the result in this\ndirection to 70B-parameter models in the heterogeneous, trustless environments\nhas turned out to be a huge, yet unbroken bottleneck. This paper introduces\nFLock, a decentralized framework for secure and efficient collaborative LLM\nfine-tuning. Integrating a blockchain-based trust layer with economic\nincentives, FLock replaces the central aggregator with a secure, auditable\nprotocol for cooperation among untrusted parties. We present the first\nempirical validation of fine-tuning a 70B LLM in a secure, multi-domain,\ndecentralized setting. Our experiments show the FLock framework defends against\nbackdoor poisoning attacks that compromise standard FL optimizers and fosters\nsynergistic knowledge transfer. The resulting models show a >68% reduction in\nadversarial attack success rates. The global model also demonstrates superior\ncross-domain generalization, outperforming models trained in isolation on their\nown specialized data.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aFLock\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u9ad8\u6548\u7684\u534f\u4f5c\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5e76\u9996\u6b21\u5728\u5b89\u5168\u3001\u591a\u57df\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u73af\u5883\u4e2d\u5bf970B\u53c2\u6570\u7684LLM\u8fdb\u884c\u4e86\u5fae\u8c03\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFLock\u6846\u67b6\u80fd\u6709\u6548\u9632\u5fa1\u540e\u95e8\u4e2d\u6bd2\u653b\u51fb\uff0c\u5e76\u4fc3\u8fdb\u534f\u540c\u77e5\u8bc6\u8f6c\u79fb\uff0c\u4f7f\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d7\u5230\u96c6\u4e2d\u63a7\u5236\u4e0d\u8db3\u548c\u5206\u6563\u65b9\u6848\u4e2d\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u7684\u963b\u788d\u3002\u800c\u5178\u578b\u7684\u8054\u90a6\u5b66\u4e60\u867d\u7136\u652f\u6301\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4e2d\u592e\u670d\u52a1\u5668\u7684\u8981\u6c42\u9020\u6210\u4e86\u5355\u70b9\u653b\u51fb\u548c\u4e2d\u6bd2\u653b\u51fb\u7684\u6f0f\u6d1e\u3002", "method": "\u5f15\u5165\u4e86FLock\uff0c\u4e00\u79cd\u5c06\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u4fe1\u4efb\u5c42\u4e0e\u7ecf\u6d4e\u6fc0\u52b1\u76f8\u7ed3\u5408\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u4ee5\u53d6\u4ee3\u4e2d\u592e\u805a\u5408\u5668\uff0c\u521b\u5efa\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u5408\u4f5c\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cFLock\u6846\u67b6\u80fd\u591f\u9632\u5fa1\u7834\u574f\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u5668\u7684\u540e\u95e8\u4e2d\u6bd2\u653b\u51fb\uff0c\u5e76\u4fc3\u8fdb\u534f\u540c\u77e5\u8bc6\u8f6c\u79fb\u3002\u7ed3\u679c\u6a21\u578b\u663e\u793a\u51fa>68%\u7684\u5bf9\u6297\u6027\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u3002\u5168\u5c40\u6a21\u578b\u8fd8\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "FLock\u4e3a\u5728\u5f02\u6784\u3001\u4e0d\u53ef\u4fe1\u73af\u5883\u4e2d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2507.15381", "pdf": "https://arxiv.org/pdf/2507.15381", "abs": "https://arxiv.org/abs/2507.15381", "authors": ["Julia Machnio", "Mads Nielsen", "Mostafa Mehdipour Ghazi"], "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025", "summary": "Active learning (AL) seeks to reduce annotation costs by selecting the most\ninformative samples for labeling, making it particularly valuable in\nresource-constrained settings. However, traditional evaluation methods, which\nfocus solely on final accuracy, fail to capture the full dynamics of the\nlearning process. To address this gap, we propose PALM (Performance Analysis of\nActive Learning Models), a unified and interpretable mathematical model that\ncharacterizes AL trajectories through four key parameters: achievable accuracy,\ncoverage efficiency, early-stage performance, and scalability. PALM provides a\npredictive description of AL behavior from partial observations, enabling the\nestimation of future performance and facilitating principled comparisons across\ndifferent strategies. We validate PALM through extensive experiments on\nCIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and\nself-supervised embeddings. Our results demonstrate that PALM generalizes\neffectively across datasets, budgets, and strategies, accurately predicting\nfull learning curves from limited labeled data. Importantly, PALM reveals\ncrucial insights into learning efficiency, data space coverage, and the\nscalability of AL methods. By enabling the selection of cost-effective\nstrategies and predicting performance under tight budget constraints, PALM lays\nthe basis for more systematic, reproducible, and data-efficient evaluation of\nAL in both research and real-world applications. The code is available at:\nhttps://github.com/juliamachnio/PALM.", "AI": {"tldr": "\u63d0\u51faPALM\u6a21\u578b\uff0c\u901a\u8fc7\u56db\u4e2a\u5173\u952e\u53c2\u6570\u63cf\u8ff0\u4e3b\u52a8\u5b66\u4e60\uff08AL\uff09\u7684\u8f68\u8ff9\uff0c\u4e3aAL\u65b9\u6cd5\u63d0\u4f9b\u66f4\u7cfb\u7edf\u3001\u53ef\u91cd\u590d\u548c\u6570\u636e\u9ad8\u6548\u7684\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u53ea\u5173\u6ce8\u6700\u7ec8\u51c6\u786e\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u6355\u6349\u4e3b\u52a8\u5b66\u4e60\u8fc7\u7a0b\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86PALM\u6a21\u578b\uff0c\u4f7f\u7528\u56db\u4e2a\u5173\u952e\u53c2\u6570\uff1a\u53ef\u5b9e\u73b0\u7684\u51c6\u786e\u6027\u3001\u8986\u76d6\u6548\u7387\u3001\u65e9\u671f\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u6765\u63cf\u8ff0AL\u8f68\u8ff9\uff0c\u5e76\u4ece\u90e8\u5206\u89c2\u5bdf\u4e2d\u9884\u6d4bAL\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86PALM\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5b8c\u6574\u7684\u5b66\u4e60\u66f2\u7ebf\uff0c\u5e76\u63ed\u793a\u4e86\u5b66\u4e60\u6548\u7387\u3001\u6570\u636e\u7a7a\u95f4\u8986\u76d6\u548c\u53ef\u6269\u5c55\u6027\u7684\u5173\u952e\u89c1\u89e3\u3002", "conclusion": "PALM\u4e3a\u5728\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u7cfb\u7edf\u3001\u53ef\u91cd\u590d\u548c\u6570\u636e\u9ad8\u6548\u7684\u8bc4\u4f30AL\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15386", "pdf": "https://arxiv.org/pdf/2507.15386", "abs": "https://arxiv.org/abs/2507.15386", "authors": ["Juntao Wang", "Feng Yin", "Tian Ding", "Tsung-Hui Chang", "Zhi-Quan Luo", "Qi Yan"], "title": "Learning to Gridize: Segment Physical World by Wireless Communication Channel", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Gridization, the process of partitioning space into grids where users share\nsimilar channel characteristics, serves as a fundamental prerequisite for\nefficient large-scale network optimization. However, existing methods like\nGeographical or Beam Space Gridization (GSG or BSG) are limited by reliance on\nunavailable location data or the flawed assumption that similar signal\nstrengths imply similar channel properties. We propose Channel Space\nGridization (CSG), a pioneering framework that unifies channel estimation and\ngridization for the first time. Formulated as a joint optimization problem, CSG\nuses only beam-level reference signal received power (RSRP) to estimate Channel\nAngle Power Spectra (CAPS) and partition samples into grids with homogeneous\nchannel characteristics. To perform CSG, we develop the CSG Autoencoder\n(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse\ncodebook quantizer, and a physics-informed decoder based on the Localized\nStatistical Channel Model. On recognizing the limitations of naive training\nscheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous\n(PIDA) training scheme for CSG-AE, ensuring stable and effective training by\nsystematically addressing the common pitfalls of the naive training paradigm.\nEvaluations reveal that CSG-AE excels in CAPS estimation accuracy and\nclustering quality on synthetic data. On real-world datasets, it reduces Active\nMean Absolute Error (MAE) by 30\\% and Overall MAE by 65\\% on RSRP prediction\naccuracy compared to salient baselines using the same data, while improving\nchannel consistency, cluster sizes balance, and active ratio, advancing the\ndevelopment of gridization for large-scale network optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4fe1\u9053\u7a7a\u95f4\u7f51\u683c\u5316\uff08CSG\uff09\u6846\u67b6\uff0c\u5b83\u9996\u6b21\u5c06\u4fe1\u9053\u4f30\u8ba1\u548c\u7f51\u683c\u5316\u7edf\u4e00\u8d77\u6765\uff0c\u5e76\u5f00\u53d1\u4e86CSG\u81ea\u52a8\u7f16\u7801\u5668\uff08CSG-AE\uff09\u6765\u5b9e\u73b0\u8fd9\u4e00\u6846\u67b6\u3002\u4e3a\u4e86\u786e\u4fdd\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684PIDA\u8bad\u7ec3\u65b9\u6848\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCSG-AE\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u683c\u5316\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u53ef\u7528\u7684\u4f4d\u7f6e\u6570\u636e\u6216\u9519\u8bef\u5730\u5047\u8bbe\u76f8\u4f3c\u7684\u4fe1\u53f7\u5f3a\u5ea6\u610f\u5473\u7740\u76f8\u4f3c\u7684\u4fe1\u9053\u7279\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u548c\u6548\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4fe1\u9053\u7a7a\u95f4\u7f51\u683c\u5316\uff08CSG\uff09\u6846\u67b6\uff0c\u5b83\u9996\u6b21\u5c06\u4fe1\u9053\u4f30\u8ba1\u548c\u7f51\u683c\u5316\u7edf\u4e00\u8d77\u6765\u3002\u901a\u8fc7\u4ec5\u4f7f\u7528\u6ce2\u675f\u7ea7\u53c2\u8003\u4fe1\u53f7\u63a5\u6536\u529f\u7387\uff08RSRP\uff09\uff0cCSG\u53ef\u4ee5\u4f30\u8ba1\u4fe1\u9053\u89d2\u5ea6\u529f\u7387\u8c31\uff08CAPS\uff09\uff0c\u5e76\u6839\u636e\u540c\u8d28\u4fe1\u9053\u7279\u6027\u5bf9\u6837\u672c\u8fdb\u884c\u5206\u533a\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86CSG\u81ea\u52a8\u7f16\u7801\u5668\uff08CSG-AE\uff09\u6765\u5b9e\u73b0\u8fd9\u4e00\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684PIDA\u8bad\u7ec3\u65b9\u6848\u4ee5\u786e\u4fdd\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCSG-AE\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u4fe1\u9053\u89d2\u5ea6\u529f\u7387\u8c31\uff08CAPS\uff09\u4f30\u8ba1\u51c6\u786e\u6027\u548c\u805a\u7c7b\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cCSG-AE\u5c06\u6d3b\u8dc3\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u964d\u4f4e\u4e8630%\uff0c\u6574\u4f53MAE\u964d\u4f4e\u4e8665%\u3002\u540c\u65f6\uff0cCSG-AE\u8fd8\u6539\u5584\u4e86\u4fe1\u9053\u4e00\u81f4\u6027\u3001\u805a\u7c7b\u5927\u5c0f\u5e73\u8861\u548c\u6d3b\u8dc3\u6bd4\u7387\u3002", "conclusion": "CSG-AE\u5728\u4fe1\u9053\u7a7a\u95f4\u7f51\u683c\u5316\u65b9\u9762\u5177\u6709\u663e\u8457\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u63d0\u9ad8\u5927\u89c4\u6a21\u7f51\u7edc\u4f18\u5316\u7684\u6548\u679c\u3002"}}
{"id": "2507.15397", "pdf": "https://arxiv.org/pdf/2507.15397", "abs": "https://arxiv.org/abs/2507.15397", "authors": ["Scott Pesme", "Giacomo Meanti", "Michael Arbel", "Julien Mairal"], "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Denoiser models have become powerful tools for inverse problems, enabling the\nuse of pretrained networks to approximate the score of a smoothed prior\ndistribution. These models are often used in heuristic iterative schemes aimed\nat solving Maximum a Posteriori (MAP) optimisation problems, where the proximal\noperator of the negative log-prior plays a central role. In practice, this\noperator is intractable, and practitioners plug in a pretrained denoiser as a\nsurrogate-despite the lack of general theoretical justification for this\nsubstitution. In this work, we show that a simple algorithm, closely related to\nseveral used in practice, provably converges to the proximal operator under a\nlog-concavity assumption on the prior $p$. We show that this algorithm can be\ninterpreted as a gradient descent on smoothed proximal objectives. Our analysis\nthus provides a theoretical foundation for a class of empirically successful\nbut previously heuristic methods.", "AI": {"tldr": "\u672c\u6587\u4e3a\u4e00\u7c7b\u7ecf\u9a8c\u4e0a\u6210\u529f\u7684\u4f46\u4e4b\u524d\u662f\u542f\u53d1\u5f0f\u7684\u53bb\u566a\u6a21\u578b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u4e00\u4e2a\u7b80\u5355\u7b97\u6cd5\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\uff0c\u5e76\u4e14\u8be5\u7b97\u6cd5\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3a\u5bf9\u5e73\u6ed1\u8fd1\u7aef\u76ee\u6807\u7684\u68af\u5ea6\u4e0b\u964d\u3002", "motivation": "\u53bb\u566a\u6a21\u578b\u5728\u6c42\u89e3\u6700\u5927\u540e\u9a8c\u6982\u7387\uff08MAP\uff09\u4f18\u5316\u95ee\u9898\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u5b9e\u8df5\u4e2d\u76f4\u63a5\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u53bb\u566a\u5668\u4f5c\u4e3a\u8fd1\u7aef\u7b97\u5b50\u66ff\u4ee3\u54c1\u7f3a\u4e4f\u666e\u904d\u7684\u7406\u8bba\u4f9d\u636e\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e3a\u8fd9\u4e9b\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u5148\u9a8c\u5206\u5e03$p$\u6ee1\u8db3\u5bf9\u6570\u51f9\u6027\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u8bc1\u660e\u6536\u655b\u5230\u8fd1\u7aef\u7b97\u5b50\u3002\u5e76\u4e14\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u53ef\u88ab\u89c6\u4e3a\u5bf9\u5e73\u6ed1\u8fd1\u7aef\u76ee\u6807\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u7684\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5206\u6790\uff0c\u4f5c\u8005\u4e3a\u4e00\u7cfb\u5217\u7ecf\u9a8c\u4e0a\u6210\u529f\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u7279\u5b9a\u7b97\u6cd5\u80fd\u591f\u6536\u655b\u81f3\u8fd1\u7aef\u7b97\u5b50\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4e00\u4e9b\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u542f\u53d1\u5f0f\u53bb\u566a\u6a21\u578b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u5408\u7406\u6027\uff0c\u7279\u522b\u662f\u5728\u6ee1\u8db3\u4e00\u5b9a\u6761\u4ef6\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u903c\u8fd1\u8fd1\u7aef\u7b97\u5b50\u3002"}}
{"id": "2507.15431", "pdf": "https://arxiv.org/pdf/2507.15431", "abs": "https://arxiv.org/abs/2507.15431", "authors": ["Andrew Gracyk"], "title": "The calculus of variations of the Transformer on the hyperspherical tangent bundle", "categories": ["cs.LG"], "comment": "First version", "summary": "We offer a theoretical mathematical background to Transformers through\nLagrangian optimization across the token space. The Transformer, as a flow map,\nexists in the tangent fiber for each token along the high-dimensional unit\nsphere. The circumstance of the hypersphere across the latent data is\nreasonable due to the trained diagonal matrix equal to the identity, which has\nvarious empirical justifications. Thus, under the continuum limit of the\ndynamics, the latent vectors flow among the tangent bundle. Using these facts,\nwe devise a mathematical framework for the Transformer through calculus of\nvariations. We develop a functional and show that the continuous flow map\ninduced by the Transformer satisfies this functional, therefore the Transformer\ncan be viewed as a natural solver of a calculus of variations problem. We\ninvent new scenarios of when our methods are applicable based on loss\noptimization with respect to path optimality. We derive the Euler-Lagrange\nequation for the Transformer. The variant of the Euler-Lagrange equation we\npresent has various appearances in literature, but, to our understanding,\noftentimes not foundationally proven or under other specialized cases. Our\noverarching proof is new: our techniques are classical and the use of the flow\nmap object is original. We provide several other relevant results, primarily\nones specific to neural scenarios. In particular, much of our analysis will be\nattempting to quantify Transformer data in variational contexts under neural\napproximations. Calculus of variations on manifolds is a well-nourished\nresearch area, but for the Transformer specifically, it is uncharted: we lay\nthe foundation for this area through an introduction to the Lagrangian for the\nTransformer.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u4f18\u5316\u548c\u53d8\u5206\u6cd5\uff0c\u4e3aTransformer\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u6570\u5b66\u80cc\u666f\uff0c\u5e76\u63a8\u5bfc\u4e86\u9002\u7528\u4e8e\u8be5\u6a21\u578b\u7684\u6b27\u62c9-\u62c9\u683c\u6717\u65e5\u65b9\u7a0b\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u4e3aTransformer\u63d0\u4f9b\u4e00\u4e2a\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u5176\u5de5\u4f5c\u539f\u7406\u5e76\u5f00\u62d3\u65b0\u7684\u5e94\u7528\u573a\u666f\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u62c9\u683c\u6717\u65e5\u4f18\u5316\u548c\u53d8\u5206\u6cd5\u6765\u5206\u6790Transformer\uff0c\u5e76\u5c06\u5176\u89c6\u4e3a\u9ad8\u7ef4\u5355\u4f4d\u7403\u4e0a\u7684\u5207\u4e1b\u4e2d\u7684\u6d41\u5f62\u3002", "result": "\u4f5c\u8005\u6210\u529f\u5730\u5efa\u7acb\u4e86\u9002\u7528\u4e8eTransformer\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e86\u5176\u6b27\u62c9-\u62c9\u683c\u6717\u65e5\u65b9\u7a0b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u672a\u6765\u7684Transformer\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7279\u522b\u662f\u5728\u6d41\u5f62\u4e0a\u7684\u53d8\u5206\u6cd5\u65b9\u9762\u3002"}}
{"id": "2507.15442", "pdf": "https://arxiv.org/pdf/2507.15442", "abs": "https://arxiv.org/abs/2507.15442", "authors": ["Owen Douglas", "Aku Kammonen", "Anamika Pandey", "Ra\u00fal Tempone"], "title": "An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations", "categories": ["cs.LG"], "comment": "20 Pages", "summary": "This work proposes a training algorithm based on adaptive random Fourier\nfeatures (ARFF) with Metropolis sampling and resampling\n\\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and\ndiffusion components of stochastic differential equations from snapshot data.\nSpecifically, this study considers It\\^{o} diffusion processes and a\nlikelihood-based loss function derived from the Euler-Maruyama integration\nintroduced in \\cite{Dietrich2023} and\n\\cite{dridi2021learningstochasticdynamicalsystems}.\n  This work evaluates the proposed method against benchmark problems presented\nin \\cite{Dietrich2023}, including polynomial examples, underdamped Langevin\ndynamics, a stochastic susceptible-infected-recovered model, and a stochastic\nwave equation. Across all cases, the ARFF-based approach matches or surpasses\nthe performance of conventional Adam-based optimization in both loss\nminimization and convergence speed. These results highlight the potential of\nARFF as a compelling alternative for data-driven modeling of stochastic\ndynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u7684\u8bad\u7ec3\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u672a\u77e5\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u6210\u5206\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c55\u73b0\u4e86ARFF\u4f5c\u4e3a\u6570\u636e\u9a71\u52a8\u968f\u673a\u52a8\u529b\u5b66\u5efa\u6a21\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u6539\u8fdb\u4ece\u5feb\u7167\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08SDE\uff09\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u6f02\u79fb\u548c\u6269\u6563\u90e8\u5206\u7684\u5b66\u4e60\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08ARFF\uff09\u7ed3\u5408Metropolis\u91c7\u6837\u548c\u91cd\u91c7\u6837\u7684\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u4f3c\u7136\u6027\u7684\u635f\u5931\u51fd\u6570\uff0c\u8be5\u635f\u5931\u51fd\u6570\u7531Euler-Maruyama\u79ef\u5206\u63a8\u5bfc\u800c\u6765\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8eAdam\u7684\u4f18\u5316\u76f8\u6bd4\uff0cARFF\u65b9\u6cd5\u5728\u635f\u5931\u6700\u5c0f\u5316\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u591a\u9879\u5f0f\u793a\u4f8b\u3001\u6b20\u963b\u5c3c\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u3001\u968f\u673a\u6613\u611f-\u611f\u67d3-\u6062\u590d\u6a21\u578b\u548c\u968f\u673a\u6ce2\u52a8\u65b9\u7a0b\u7b49\u6848\u4f8b\u4e2d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cARFF\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5728\u4ece\u672a\u77e5\u6570\u636e\u4e2d\u5b66\u4e60\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6f02\u79fb\u548c\u6269\u6563\u6210\u5206\u65b9\u9762\u5177\u6709\u5f88\u5927\u7684\u6f5c\u529b\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u4f20\u7edf\u65b9\u6cd5\u7684\u6709\u529b\u66ff\u4ee3\u3002"}}
{"id": "2507.15470", "pdf": "https://arxiv.org/pdf/2507.15470", "abs": "https://arxiv.org/abs/2507.15470", "authors": ["Baran Can G\u00fcl", "Suraksha Nadig", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "title": "FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning", "categories": ["cs.LG"], "comment": "Preprint version. Accepted for publication at IEEE ICECCME 2025", "summary": "In-vehicle emotion recognition underpins adaptive driver-assistance systems\nand, ultimately, occupant safety. However, practical deployment is hindered by\n(i) modality fragility - poor lighting and occlusions degrade vision-based\nmethods; (ii) physiological variability - heart-rate and skin-conductance\npatterns differ across individuals; and (iii) privacy risk - centralized\ntraining requires transmission of sensitive data. To address these challenges,\nwe present FedMultiEmo, a privacy-preserving framework that fuses two\ncomplementary modalities at the decision level: visual features extracted by a\nConvolutional Neural Network from facial images, and physiological cues (heart\nrate, electrodermal activity, and skin temperature) classified by a Random\nForest. FedMultiEmo builds on three key elements: (1) a multimodal federated\nlearning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud\nprototype on Raspberry Pi clients and a Flower server, and (3) a personalized\nFederated Averaging scheme that weights client updates by local data volume.\nEvaluated on FER2013 and a custom physiological dataset, the federated\nConvolutional Neural Network attains 77% accuracy, the Random Forest 74%, and\ntheir fusion 87%, matching a centralized baseline while keeping all raw data\nlocal. The developed system converges in 18 rounds, with an average round time\nof 120 seconds and a per-client memory footprint below 200 MB. These results\nindicate that FedMultiEmo offers a practical approach to real-time,\nprivacy-aware emotion recognition in automotive settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedMultiEmo\u6846\u67b6\uff0c\u878d\u5408\u89c6\u89c9\u548c\u751f\u7406\u6a21\u6001\u5b9e\u73b0\u8f66\u5185\u60c5\u7eea\u8bc6\u522b\uff0c\u4fdd\u62a4\u9690\u79c1\u5e76\u9002\u5e94\u4e2a\u4f53\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u7684\u8f66\u5185\u60c5\u7eea\u8bc6\u522b\u9762\u4e34\u73af\u5883\u3001\u4e2a\u4f53\u5dee\u5f02\u548c\u9690\u79c1\u95ee\u9898\u7684\u6311\u6218\u3002", "method": "FedMultiEmo\u91c7\u7528\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\uff0c\u5728\u51b3\u7b56\u5c42\u9762\u878d\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u7684\u9762\u90e8\u56fe\u50cf\u7279\u5f81\u548c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u7684\u751f\u7406\u4fe1\u53f7\uff0c\u4f7f\u7528\u52a0\u6743\u7684\u8054\u90a6\u5e73\u5747\u65b9\u6cd5\uff0c\u5e76\u5728\u8fb9\u7f18\u8bbe\u5907\u5230\u4e91\u7aef\u7684\u539f\u578b\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u8be5\u7cfb\u7edf\u5728FER2013\u548c\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a77%\u300174%\uff0c\u878d\u5408\u540e\u7684\u51c6\u786e\u7387\u4e3a87%\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u4fdd\u6301\u539f\u59cb\u6570\u636e\u672c\u5730\u5316\u7684\u540c\u65f6\u8fbe\u5230\u96c6\u4e2d\u5f0f\u57fa\u7ebf\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cFedMultiEmo\u4e3a\u6c7d\u8f66\u73af\u5883\u4e2d\u5b9e\u65f6\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u60c5\u7eea\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.15507", "pdf": "https://arxiv.org/pdf/2507.15507", "abs": "https://arxiv.org/abs/2507.15507", "authors": ["Johannes Ackermann", "Takashi Ishida", "Masashi Sugiyama"], "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accept at the Conference On Language Modeling (COLM) 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models,\nsuch as language models (LMs), to follow complex human preferences. In RLHF for\nLMs, we first train an LM using supervised fine-tuning, sample pairs of\nresponses, obtain human feedback, and use the resulting data to train a reward\nmodel (RM). RL methods are then used to train the LM to maximize the reward\ngiven by the RM. As training progresses, the responses generated by the LM no\nlonger resemble the responses seen by the RM during training, leading to the RM\nbecoming inaccurate. The score given by the RM keeps increasing, but the\nlearned behavior no longer matches the human preferences. This issue is known\nas overoptimization. We investigate overoptimization from the point of view of\ndistribution shift and show that the shift results in an inconsistent estimate\nof the RM parameters, leading to an inconsistent estimate of the policy\ngradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which\niteratively off-policy corrects the RM using importance weighting, without\nrequiring new labels or samples. This results in a more accurate RM, which\nempirically leads to an improved final policy. We validate our approach in\nexperiments with summarization and chatbot datasets and show that it performs\nsignificantly better than standard RLHF methods and baselines. Our\nimplementation is available at\nhttps://github.com/JohannesAck/OffPolicyCorrectedRewardModeling", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5Off-Policy Corrected Reward Modeling (OCRM)\uff0c\u7528\u4e8e\u4fee\u6b63\u5f3a\u5316\u5b66\u4e60\u4ece\u4eba\u7c7b\u53cd\u9988(RLHF)\u4e2d\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u51fa\u73b0\u7684\u8fc7\u4f18\u5316\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u91cd\u8981\u6027\u52a0\u6743\u8fed\u4ee3\u5730\u4fee\u6b63\u5956\u52b1\u6a21\u578b\uff0c\u800c\u65e0\u9700\u65b0\u7684\u6807\u7b7e\u6216\u6837\u672c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u6807\u51c6RLHF\u65b9\u6cd5\u548c\u57fa\u7ebf\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4ece\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u5728\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u53d8\u5f97\u4e0d\u51c6\u786e\uff0c\u5bfc\u81f4\u6a21\u578b\u884c\u4e3a\u4e0d\u518d\u5339\u914d\u4eba\u7c7b\u504f\u597d\uff0c\u5373\u51fa\u73b0\u4e86\u8fc7\u4f18\u5316\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Off-Policy Corrected Reward Modeling (OCRM)\uff0c\u5b83\u4f7f\u7528\u91cd\u8981\u6027\u52a0\u6743\u8fed\u4ee3\u5730\u5bf9RM\u8fdb\u884c\u79bb\u7b56\u7565\u4fee\u6b63\uff0c\u4ece\u800c\u4e0d\u9700\u8981\u65b0\u7684\u6807\u7b7e\u6216\u6837\u672c\u5c31\u80fd\u83b7\u5f97\u66f4\u51c6\u786e\u7684RM\u3002", "result": "\u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u6807\u51c6RLHF\u65b9\u6cd5\u548c\u57fa\u7ebf\u3002", "conclusion": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165OCRM\u65b9\u6cd5\u89e3\u51b3\u4e86RLHF\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15523", "pdf": "https://arxiv.org/pdf/2507.15523", "abs": "https://arxiv.org/abs/2507.15523", "authors": ["Weichuang Shao", "Iman Yi Liao", "Tomas Henrique Bode Maul", "Tissa Chandesa"], "title": "An Investigation of Test-time Adaptation for Audio Classification under Background Noise", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Domain shift is a prominent problem in Deep Learning, causing a model\npre-trained on a source dataset to suffer significant performance degradation\non test datasets. This research aims to address the issue of audio\nclassification under domain shift caused by background noise using Test-Time\nAdaptation (TTA), a technique that adapts a pre-trained model during testing\nusing only unlabelled test data before making predictions. We adopt two common\nTTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and\ninvestigate their respective performance on two popular audio classification\ndatasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types\nof background noise and noise severity levels. The experimental results reveal\nthat our proposed modified version of CoNMix produced the highest\nclassification accuracy under domain shift (5.31% error rate under 10 dB\nexercise bike background noise and 12.75% error rate under 3 dB running tap\nbackground noise for AM) compared to TTT and TENT. The literature search\nprovided no evidence of similar works, thereby motivating the work reported\nhere as the first study to leverage TTA techniques for audio classification\nunder domain shift.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u7531\u80cc\u666f\u566a\u97f3\u5bfc\u81f4\u7684\u97f3\u9891\u5206\u7c7b\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u4f7f\u7528\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\uff08TTA\uff09\u6280\u672f\uff0c\u5e76\u53d1\u73b0\u4fee\u6539\u7248CoNMix\u65b9\u6cd5\u76f8\u8f83\u4e8e\u5176\u4ed6\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u9886\u57df\u504f\u79fb\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u663e\u8457\u95ee\u9898\uff0c\u5b83\u4f1a\u4f7f\u5728\u6e90\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u76ee\u524d\u6ca1\u6709\u6587\u732e\u62a5\u9053\u8fc7\u7c7b\u4f3c\u7684\u7814\u7a76\uff0c\u5373\u5229\u7528TTA\u6280\u672f\u89e3\u51b3\u97f3\u9891\u5206\u7c7b\u4e2d\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u5e38\u89c1\u7684TTA\u65b9\u6cd5TTT\u548cTENT\uff0c\u4ee5\u53ca\u4e00\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5CoNMix\uff0c\u5e76\u5bf9\u5b83\u4eec\u8fdb\u884c\u4e86\u4fee\u6539\u3002\u901a\u8fc7\u4e24\u4e2a\u6d41\u884c\u7684\u97f3\u9891\u5206\u7c7b\u6570\u636e\u96c6AudioMNIST\u548cSpeechCommands V1\uff0c\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u80cc\u666f\u566a\u97f3\u548c\u566a\u97f3\u4e25\u91cd\u7a0b\u5ea6\u7ea7\u522b\u4e0b\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4fee\u6539\u7248CoNMix\u65b9\u6cd5\u5728\u9886\u57df\u504f\u79fb\u60c5\u51b5\u4e0b\u4ea7\u751f\u4e86\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u6027\uff08\u4f8b\u5982\uff0c\u572810 dB\u81ea\u884c\u8f66\u80cc\u666f\u566a\u97f3\u4e0b\u7684\u9519\u8bef\u7387\u4e3a5.31%\uff0c\u57283 dB\u6d41\u6c34\u58f0\u80cc\u666f\u566a\u97f3\u4e0b\u7684\u9519\u8bef\u7387\u4e3a12.75%\uff09\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06TTA\u6280\u672f\u5e94\u7528\u4e8e\u97f3\u9891\u5206\u7c7b\u9886\u57df\u504f\u79fb\u95ee\u9898\u7684\u7814\u7a76\uff0c\u4fee\u6539\u540e\u7684CoNMix\u65b9\u6cd5\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.15545", "pdf": "https://arxiv.org/pdf/2507.15545", "abs": "https://arxiv.org/abs/2507.15545", "authors": ["Yujia Shi", "Emil Njor", "Pablo Mart\u00ednez-Nuevo", "Sven Ewan Shepstone", "Xenofon Fafoutis"], "title": "Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications", "categories": ["cs.LG"], "comment": null, "summary": "The success of Machine Learning is increasingly tempered by its significant\nresource footprint, driving interest in efficient paradigms like TinyML.\nHowever, the inherent complexity of designing TinyML systems hampers their\nbroad adoption. To reduce this complexity, we introduce \"Data Aware\nDifferentiable Neural Architecture Search\". Unlike conventional Differentiable\nNeural Architecture Search, our approach expands the search space to include\ndata configuration parameters alongside architectural choices. This enables\nData Aware Differentiable Neural Architecture Search to co-optimize model\narchitecture and input data characteristics, effectively balancing resource\nusage and system performance for TinyML applications. Initial results on\nkeyword spotting demonstrate that this novel approach to TinyML system design\ncan generate lean but highly accurate systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a\u201c\u6570\u636e\u611f\u77e5\u53ef\u5fae\u5206\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u201d\uff0c\u5b83\u53ef\u4ee5\u5728TinyML\u5e94\u7528\u4e2d\u5e73\u8861\u8d44\u6e90\u4f7f\u7528\u548c\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7684\u6210\u529f\u8d8a\u6765\u8d8a\u591a\u5730\u53d7\u5230\u5176\u663e\u8457\u7684\u8d44\u6e90\u8db3\u8ff9\u7684\u9650\u5236\uff0c\u8fd9\u4fc3\u4f7f\u4eba\u4eec\u5bf9\u5176\u9ad8\u6548\u8303\u5f0f\uff08\u5982TinyML\uff09\u4ea7\u751f\u5174\u8da3\u3002\u7136\u800c\uff0c\u8bbe\u8ba1TinyML\u7cfb\u7edf\u7684\u56fa\u6709\u590d\u6742\u6027\u963b\u788d\u4e86\u5b83\u4eec\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e86\u201c\u6570\u636e\u611f\u77e5\u53ef\u5fae\u5206\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u201d\uff0c\u5b83\u6269\u5c55\u4e86\u641c\u7d22\u7a7a\u95f4\u4ee5\u5305\u62ec\u6570\u636e\u914d\u7f6e\u53c2\u6570\u548c\u67b6\u6784\u9009\u62e9\u3002\u8fd9\u4f7f\u5f97\u53ef\u4ee5\u5171\u540c\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u8f93\u5165\u6570\u636e\u7279\u5f81\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u5728\u5173\u952e\u8bcd\u8bc6\u522b\u4efb\u52a1\u4e0a\u751f\u6210\u7cbe\u7b80\u4f46\u9ad8\u5ea6\u51c6\u786e\u7684TinyML\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8bbe\u8ba1TinyML\u7cfb\u7edf\u7684\u590d\u6742\u6027\uff0c\u5e76\u4fc3\u8fdb\u5176\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2507.15548", "pdf": "https://arxiv.org/pdf/2507.15548", "abs": "https://arxiv.org/abs/2507.15548", "authors": ["D. Abler", "O. Pusterla", "A. Joye-K\u00fchnis", "N. Andratschke", "M. Bach", "A. Bink", "S. M. Christ", "P. Hagmann", "B. Pouymayou", "E. Pravat\u00e0", "P. Radojewski", "M. Reyes", "L. Ruinelli", "R. Schaer", "B. Stieltjes", "G. Treglia", "W. Valenzuela", "R. Wiest", "S. Zoergiebel", "M. Guckenberger", "S. Tanadini-Lang", "A. Depeursinge"], "title": "The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "Background: Radiomics shows promise in characterizing glioblastoma, but its\nadded value over clinical and molecular predictors has yet to be proven. This\nstudy assessed the added value of conventional radiomics (CR) and deep learning\n(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on\na large multi-center dataset.\n  Methods: After patient selection, our curated dataset gathers 1152\nglioblastoma (WHO 2016) patients from five Swiss centers and one public source.\nIt included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI\ndata (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were\ndeveloped using standard methods and evaluated on internal and external\ncohorts. Sub-analyses assessed models with different feature sets\n(imaging-only, clinical/molecular-only, combined-features) and patient subsets\n(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).\n  Results: The best performance was observed in the full cohort (S-1). In\nexternal validation, the combined-feature CR model achieved an AUC of 0.75,\nslightly, but significantly outperforming clinical-only (0.74) and imaging-only\n(0.68) models. DL models showed similar trends, though without statistical\nsignificance. In S-2 and S-3, combined models did not outperform clinical-only\nmodels. Exploratory analysis of CR models for overall survival prediction\nsuggested greater relevance of imaging data: across all subsets,\ncombined-feature models significantly outperformed clinical-only models, though\nwith a modest advantage of 2-4 C-index points.\n  Conclusions: While confirming the predictive value of anatomical MRI\nsequences for glioblastoma prognosis, this multi-center study found standard CR\nand DL radiomics approaches offer minimal added value over demographic\npredictors such as age and gender.", "AI": {"tldr": "\u8fd9\u9879\u591a\u4e2d\u5fc3\u7814\u7a76\u8868\u660e\uff0c\u4f20\u7edf\u7684\u653e\u5c04\u7ec4\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60\u653e\u5c04\u7ec4\u5b66\u5728\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u9884\u6d4b\u65b9\u9762\u63d0\u4f9b\u7684\u9644\u52a0\u4ef7\u503c\u6709\u9650\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u8bc4\u4f30\u5e38\u89c4\u653e\u5c04\u7ec4\u5b66\uff08CR\uff09\u548c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u7684MRI\u653e\u5c04\u7ec4\u5b66\u5728\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u4e2d\u7684\u9644\u52a0\u4ef7\u503c\uff0c\u7279\u522b\u662f\u76f8\u5bf9\u4e8e\u4e34\u5e8a\u548c\u5206\u5b50\u9884\u6d4b\u56e0\u5b50\u7684\u4f18\u52bf\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u6765\u81ea\u4e94\u4e2a\u745e\u58eb\u4e2d\u5fc3\u548c\u4e00\u4e2a\u516c\u5171\u6765\u6e90\u76841152\u540d\u60a3\u8005\u7684\u5927\u578b\u591a\u4e2d\u5fc3\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86CR\u548cDL\u6a21\u578b\u3002\u8fd9\u4e9b\u6a21\u578b\u5728\u5185\u90e8\u548c\u5916\u90e8\u961f\u5217\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u7279\u5f81\u96c6\uff08\u4ec5\u5f71\u50cf\u3001\u4ec5\u4e34\u5e8a/\u5206\u5b50\u3001\u7ec4\u5408\u7279\u5f81\uff09\u548c\u60a3\u8005\u5b50\u96c6\u8fdb\u884c\u4e86\u6b21\u7ea7\u5206\u6790\u3002", "result": "\u5728\u5916\u90e8\u9a8c\u8bc1\u4e2d\uff0c\u7ec4\u5408\u7279\u5f81\u7684CR\u6a21\u578b\u8fbe\u5230\u4e860.75\u7684AUC\uff0c\u7565\u4f18\u4e8e\u4ec5\u4e34\u5e8a\uff080.74\uff09\u548c\u4ec5\u5f71\u50cf\uff080.68\uff09\u6a21\u578b\u3002DL\u6a21\u578b\u8868\u73b0\u51fa\u7c7b\u4f3c\u8d8b\u52bf\uff0c\u4f46\u5728\u7edf\u8ba1\u4e0a\u4e0d\u663e\u8457\u3002\u5bf9\u4e8e\u603b\u751f\u5b58\u671f\u9884\u6d4b\uff0cCR\u6a21\u578b\u663e\u793a\u5f71\u50cf\u6570\u636e\u5177\u6709\u66f4\u5927\u7684\u76f8\u5173\u6027\uff0c\u4f46\u4f18\u52bf\u4ec5\u4e3a2-4\u4e2aC\u6307\u6570\u70b9\u3002", "conclusion": "\u5c3d\u7ba1\u786e\u8ba4\u4e86MRI\u5e8f\u5217\u5bf9\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u9884\u540e\u7684\u9884\u6d4b\u4ef7\u503c\uff0c\u4f46\u8be5\u7814\u7a76\u8868\u660e\uff0c\u6807\u51c6\u7684CR\u548cDL\u653e\u5c04\u7ec4\u5b66\u65b9\u6cd5\u76f8\u6bd4\u4eba\u53e3\u7edf\u8ba1\u5b66\u9884\u6d4b\u56e0\u5b50\u5982\u5e74\u9f84\u548c\u6027\u522b\uff0c\u63d0\u4f9b\u7684\u9644\u52a0\u4ef7\u503c\u6709\u9650\u3002"}}
{"id": "2507.15550", "pdf": "https://arxiv.org/pdf/2507.15550", "abs": "https://arxiv.org/abs/2507.15550", "authors": ["Yimeng Chen", "Piotr Pi\u0229kos", "Mateusz Ostaszewski", "Firas Laakom", "J\u00fcrgen Schmidhuber"], "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors", "categories": ["cs.LG", "cs.AI", "physics.soc-ph"], "comment": "31 Pages", "summary": "Evaluating the scientific discovery capabilities of large language model\nbased agents, particularly how they cope with varying environmental complexity\nand utilize prior knowledge, requires specialized benchmarks currently lacking\nin the landscape. To address this gap, we introduce PhysGym, a novel benchmark\nsuite and simulation platform for rigorously assessing LLM-based scientific\nreasoning in interactive physics environments. PhysGym's primary contribution\nlies in its sophisticated control over the level of prior knowledge provided to\nthe agent. This allows researchers to dissect agent performance along axes\nincluding the complexity of the problem and the prior knowledge levels. The\nbenchmark comprises a suite of interactive simulations, where agents must\nactively probe environments, gather data sequentially under constraints and\nformulate hypotheses about underlying physical laws. PhysGym provides\nstandardized evaluation protocols and metrics for assessing hypothesis accuracy\nand model fidelity. We demonstrate the benchmark's utility by presenting\nresults from baseline LLMs, showcasing its ability to differentiate\ncapabilities based on varying priors and task complexity.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PhysGym\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u5728\u4e92\u52a8\u7269\u7406\u73af\u5883\u4e2d\u8fdb\u884c\u79d1\u5b66\u63a8\u7406\u7684\u65b0\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\u3002\u5b83\u63d0\u4f9b\u4e86\u5bf9\u5148\u524d\u77e5\u8bc6\u6c34\u5e73\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u4e00\u7cfb\u5217\u4e92\u52a8\u6a21\u62df\u6765\u4e25\u683c\u8bc4\u4f30\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u4e0d\u540c\u73af\u5883\u590d\u6742\u5ea6\u4e0b\u8fd0\u7528\u5148\u9a8c\u77e5\u8bc6\u8fdb\u884c\u79d1\u5b66\u53d1\u73b0\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86PhysGym\uff0c\u4e00\u4e2a\u65b0\u57fa\u51c6\u5957\u4ef6\u548c\u6a21\u62df\u5e73\u53f0\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u4e00\u7cfb\u5217\u4e92\u52a8\u6a21\u62df\uff0c\u4ee3\u7406\u5fc5\u987b\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u4e3b\u52a8\u63a2\u6d4b\u73af\u5883\u3001\u6536\u96c6\u6570\u636e\u5e76\u63d0\u51fa\u5173\u4e8e\u5e95\u5c42\u7269\u7406\u5b9a\u5f8b\u7684\u5047\u8bbe\u3002", "result": "\u901a\u8fc7\u5c55\u793a\u57fa\u7ebf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u51c6\u80fd\u591f\u6839\u636e\u4e0d\u540c\u7684\u5148\u9a8c\u77e5\u8bc6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u533a\u5206\u4ee3\u7406\u80fd\u529b\u3002", "conclusion": "PhysGym\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u534f\u8bae\u548c\u6307\u6807\u4f53\u7cfb\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u5047\u8bbe\u7684\u51c6\u786e\u6027\u548c\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\uff0c\u4ece\u800c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.15566", "pdf": "https://arxiv.org/pdf/2507.15566", "abs": "https://arxiv.org/abs/2507.15566", "authors": ["Pieter Smet", "Martina Doneda", "Ettore Lanzarone", "Giuliana Carello"], "title": "Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "The availability of downstream resources plays a critical role in planning\nthe admission of patients undergoing elective surgery, with inpatient beds\nbeing one of the most crucial resources. When planning patient admissions,\npredictions on their length-of-stay (LOS) made by machine learning (ML) models\nare used to ensure bed availability. However, the actual LOS for each patient\nmay differ considerably from the predicted value, potentially making the\nschedule infeasible. To address such infeasibilities, rescheduling strategies\nthat take advantage of operational flexibility can be implemented. For example,\nadjustments may include postponing admission dates, relocating patients to\ndifferent wards, or even transferring patients who are already admitted. The\ncommon assumption is that more accurate LOS predictions reduce the impact of\nrescheduling. However, training ML models that can make such accurate\npredictions can be costly. Building on previous work that proposed simulated\n\\ac{ml} for evaluating data-driven approaches, this paper explores the\nrelationship between LOS prediction accuracy and rescheduling flexibility\nacross various corrective policies. Specifically, we examine the most effective\npatient rescheduling strategies under LOS prediction errors to prevent bed\noverflows while optimizing resource utilization.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f4f\u9662\u5e8a\u4f4d\u9884\u6d4b\u51c6\u786e\u6027\u548c\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u4f18\u5316\u8d44\u6e90\u5229\u7528\u5e76\u9632\u6b62\u5e8a\u4f4d\u8d85\u8f7d\u3002", "motivation": "\u624b\u672f\u75c5\u4eba\u7684\u4f4f\u9662\u5e8a\u4f4d\u662f\u6709\u9650\u7684\u8d44\u6e90\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u9884\u6d4b\u75c5\u4eba\u4f4f\u9662\u65f6\u95f4\uff08LOS\uff09\u4ee5\u89c4\u5212\u5e8a\u4f4d\u53ef\u7528\u6027\u3002\u7136\u800c\uff0c\u5b9e\u9645\u4f4f\u9662\u65f6\u95f4\u53ef\u80fd\u4e0e\u9884\u6d4b\u503c\u76f8\u5dee\u5f88\u5927\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4f7f\u8ba1\u5212\u53d8\u5f97\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728LOS\u9884\u6d4b\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\u6765\u4f18\u5316\u8d44\u6e90\u5229\u7528\u548c\u9632\u6b62\u5e8a\u4f4d\u8d85\u8f7d\u3002", "method": "\u4f7f\u7528\u6a21\u62df\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8bc4\u4f30\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u7684\u7ea0\u6b63\u653f\u7b56\u4e0bLOS\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u91cd\u65b0\u8c03\u5ea6\u7075\u6d3b\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u786e\u5b9a\u4e86\u5728LOS\u9884\u6d4b\u8bef\u5dee\u4e0b\u7684\u6700\u6709\u6548\u7684\u75c5\u4eba\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\uff0c\u53ef\u4ee5\u9884\u9632\u5e8a\u4f4d\u6ea2\u51fa\u540c\u65f6\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "conclusion": "\u66f4\u51c6\u786e\u7684LOS\u9884\u6d4b\u4e0d\u4e00\u5b9a\u80fd\u51cf\u5c11\u91cd\u65b0\u8c03\u5ea6\u7684\u9700\u6c42\uff0c\u800c\u9002\u5f53\u7684\u91cd\u65b0\u8c03\u5ea6\u7b56\u7565\u53ef\u4ee5\u5728\u9884\u6d4b\u4e0d\u51c6\u786e\u65f6\u6709\u6548\u5730\u7ba1\u7406\u8d44\u6e90\u3002"}}
{"id": "2507.15574", "pdf": "https://arxiv.org/pdf/2507.15574", "abs": "https://arxiv.org/abs/2507.15574", "authors": ["Gregory F. Stock", "Juan A. Fraire", "Holger Hermanns", "J\u0119drzej Mosi\u0119\u017cny", "Yusra Al-Khazraji", "Julio Ram\u00edrez Molina", "Evridiki V. Ntagiou"], "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project", "categories": ["cs.LG", "cs.AI"], "comment": "18th International Conference on Space Operations (SpaceOps 2025),\n  Montr\\'eal, Canada, 26-30 May 2025,\n  https://star.spaceops.org/2025/user_manudownload.php?doc=140__9bg48dkf.pdf", "summary": "The rapid expansion of satellite constellations in near-Earth orbits presents\nsignificant challenges in satellite network management, requiring innovative\napproaches for efficient, scalable, and resilient operations. This paper\nexplores the role of Artificial Intelligence (AI) in optimizing the operation\nof satellite mega-constellations, drawing from the ConstellAI project funded by\nthe European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland\nUniversity, and Thales Alenia Space collaborates to develop AI-driven\nalgorithms and demonstrates their effectiveness over traditional methods for\ntwo crucial operational challenges: data routing and resource allocation. In\nthe routing use case, Reinforcement Learning (RL) is used to improve the\nend-to-end latency by learning from historical queuing latency, outperforming\nclassical shortest path algorithms. For resource allocation, RL optimizes the\nscheduling of tasks across constellations, focussing on efficiently using\nlimited resources such as battery and memory. Both use cases were tested for\nmultiple satellite constellation configurations and operational scenarios,\nresembling the real-life spacecraft operations of communications and Earth\nobservation satellites. This research demonstrates that RL not only competes\nwith classical approaches but also offers enhanced flexibility, scalability,\nand generalizability in decision-making processes, which is crucial for the\nautonomous and intelligent management of satellite fleets. The findings of this\nactivity suggest that AI can fundamentally alter the landscape of satellite\nconstellation management by providing more adaptive, robust, and cost-effective\nsolutions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5728\u4f18\u5316\u536b\u661f\u5de8\u578b\u661f\u5ea7\u64cd\u4f5c\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u6570\u636e\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "motivation": "\u968f\u7740\u8fd1\u5730\u8f68\u9053\u536b\u661f\u661f\u5ea7\u7684\u8fc5\u901f\u6269\u5c55\uff0c\u536b\u661f\u7f51\u7edc\u7ba1\u7406\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u521b\u65b0\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u6709\u5f39\u6027\u7684\u8fd0\u4f5c\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b97\u6cd5\uff0c\u4ee5\u6539\u5584\u4e24\u4e2a\u5173\u952e\u7684\u64cd\u4f5c\u6311\u6218\uff1a\u6570\u636e\u8def\u7531\u548c\u8d44\u6e90\u5206\u914d\u3002\u5bf9\u4e8e\u6570\u636e\u8def\u7531\uff0cRL\u7528\u4e8e\u51cf\u5c11\u7aef\u5230\u7aef\u5ef6\u8fdf\uff1b\u5bf9\u4e8e\u8d44\u6e90\u5206\u914d\uff0cRL\u5219\u4e13\u6ce8\u4e8e\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\uff0c\u5145\u5206\u5229\u7528\u6709\u9650\u7684\u8d44\u6e90\u5982\u7535\u6c60\u548c\u5185\u5b58\u3002", "result": "\u4e24\u79cd\u7528\u4f8b\u90fd\u9488\u5bf9\u591a\u79cd\u536b\u661f\u661f\u5ea7\u914d\u7f6e\u548c\u64cd\u4f5c\u573a\u666f\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793aRL\u4e0d\u4ec5\u80fd\u591f\u4e0e\u7ecf\u5178\u65b9\u6cd5\u7ade\u4e89\uff0c\u800c\u4e14\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cAI\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u66f4\u9002\u5e94\u6027\u5f3a\u3001\u7a33\u5065\u4e14\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u536b\u661f\u661f\u5ea7\u7ba1\u7406\u7684\u683c\u5c40\u3002"}}
{"id": "2507.15584", "pdf": "https://arxiv.org/pdf/2507.15584", "abs": "https://arxiv.org/abs/2507.15584", "authors": ["Philipp R\u00f6chner", "Simon Kl\u00fcttermann", "Franz Rothlauf", "Daniel Schl\u00f6r"], "title": "We Need to Rethink Benchmarking in Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Despite the continuous proposal of new anomaly detection algorithms and\nextensive benchmarking efforts, progress seems to stagnate, with only minor\nperformance differences between established baselines and new algorithms. In\nthis position paper, we argue that this stagnation is due to limitations in how\nwe evaluate anomaly detection algorithms. Current benchmarking does not, for\nexample, sufficiently reflect the diversity of anomalies in applications\nranging from predictive maintenance to scientific discovery. Consequently, we\nneed to rethink benchmarking in anomaly detection. In our opinion, anomaly\ndetection should be studied using scenarios that capture the relevant\ncharacteristics of different applications. We identify three key areas for\nimprovement: First, we need to identify anomaly detection scenarios based on a\ncommon taxonomy. Second, anomaly detection pipelines should be analyzed\nend-to-end and by component. Third, evaluating anomaly detection algorithms\nshould be meaningful regarding the scenario's objectives.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u8bc4\u4f30\u65b9\u5f0f\u7684\u5c40\u9650\u6027\u5bfc\u81f4\u4e86\u6027\u80fd\u63d0\u5347\u7684\u505c\u6ede\uff0c\u5e76\u63d0\u51fa\u9700\u8981\u57fa\u4e8e\u5e94\u7528\u573a\u666f\u7279\u6027\u91cd\u65b0\u601d\u8003\u548c\u6539\u8fdb\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "motivation": "\u4f5c\u8005\u89c2\u5bdf\u5230\u5c3d\u7ba1\u6709\u65b0\u7684\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u4e0d\u65ad\u88ab\u63d0\u51fa\uff0c\u4f46\u4e0e\u5df2\u5efa\u7acb\u7684\u57fa\u7840\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6027\u80fd\u5dee\u5f02\u5fae\u4e4e\u5176\u5fae\uff0c\u4f3c\u4e4e\u8fdb\u5c55\u505c\u6ede\u4e0d\u524d\u3002\u8fd9\u6fc0\u53d1\u4e86\u4f5c\u8005\u63a2\u8ba8\u8fd9\u4e00\u73b0\u8c61\u80cc\u540e\u7684\u539f\u56e0\uff0c\u5373\u6211\u4eec\u8bc4\u4f30\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u7684\u65b9\u5f0f\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u4f5c\u8005\u5efa\u8bae\u4ece\u4e09\u4e2a\u5173\u952e\u9886\u57df\u8fdb\u884c\u6539\u8fdb\uff1a1\uff09\u6839\u636e\u901a\u7528\u5206\u7c7b\u6cd5\u786e\u5b9a\u5f02\u5e38\u68c0\u6d4b\u573a\u666f\uff1b2\uff09\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7ba1\u9053\u8fdb\u884c\u7aef\u5230\u7aef\u548c\u6309\u7ec4\u4ef6\u5206\u6790\uff1b3\uff09\u6839\u636e\u573a\u666f\u76ee\u6807\u6709\u610f\u4e49\u5730\u8bc4\u4f30\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u3002", "result": "\u8bba\u6587\u5e76\u6ca1\u6709\u63d0\u4f9b\u5b9e\u9a8c\u7ed3\u679c\uff0c\u800c\u662f\u4e00\u4e2a\u7acb\u573a\u58f0\u660e\uff0c\u547c\u5401\u7814\u7a76\u754c\u5173\u6ce8\u5e76\u6539\u5584\u5f53\u524d\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u4f5c\u8005\u603b\u7ed3\u8ba4\u4e3a\u4e3a\u4e86\u63a8\u52a8\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u5fc5\u987b\u91cd\u65b0\u601d\u8003\u5e76\u6539\u8fdb\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u51c6\u786e\u53cd\u6620\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u5f02\u5e38\u591a\u6837\u6027\u3002"}}
{"id": "2507.15587", "pdf": "https://arxiv.org/pdf/2507.15587", "abs": "https://arxiv.org/abs/2507.15587", "authors": ["Yinsong Chen", "Kaifeng Wang", "Xiaoqiang Meng", "Xueyuan Li", "Zirui Li", "Xin Gao"], "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u751f\u6210 corner cases\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u548c\u7ea6\u675f\u56fe\u8868\u793a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u6765\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u51b3\u7b56\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\u51b3\u7b56\u7814\u7a76\u4f9d\u8d56\u4e8e\u4f4e\u6548\u7684\u6570\u636e\u9a71\u52a8\u573a\u666f\u751f\u6210\u6216\u7279\u5b9a\u5efa\u6a21\u65b9\u6cd5\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u4e2d\u7684corner cases\u3002", "method": "\u4f7f\u7528\u7ea2\u961f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5177\u6709\u5e72\u6270\u80fd\u529b\u7684\u80cc\u666f\u8f66\u8f86\u4f5c\u4e3a\u7ea2\u961f\u4ee3\u7406\uff0c\u5e76\u91c7\u7528\u7ea6\u675f\u56fe\u8868\u793a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u786e\u4fdd\u7ea2\u961f\u8f66\u8f86\u9075\u5b88\u5b89\u5168\u89c4\u5219\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u5f71\u54cd\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u51b3\u7b56\u7684\u5b89\u5168\u6027\uff0c\u5e76\u751f\u6210\u4e86\u5404\u79cdcorner cases\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u4e3a\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.15601", "pdf": "https://arxiv.org/pdf/2507.15601", "abs": "https://arxiv.org/abs/2507.15601", "authors": ["Huiling Yang", "Zhanwei Wang", "Kaibin Huang"], "title": "Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Federated learning (FL) has emerged as a popular approach for collaborative\nmachine learning in sixth-generation (6G) networks, primarily due to its\nprivacy-preserving capabilities. The deployment of FL algorithms is expected to\nempower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous\ndriving, augmented reality, and healthcare. The mission-critical and\ntime-sensitive nature of these applications necessitates the design of\nlow-latency FL frameworks that guarantee high learning performance. In\npractice, achieving low-latency FL faces two challenges: the overhead of\ncomputing and transmitting high-dimensional model updates, and the\nheterogeneity in communication-and-computation (C$^2$) capabilities across\ndevices. To address these challenges, we propose a novel C$^2$-aware framework\nfor optimal batch-size control that minimizes end-to-end (E2E) learning latency\nwhile ensuring convergence. The framework is designed to balance a fundamental\nC$^2$ tradeoff as revealed through convergence analysis. Specifically,\nincreasing batch sizes improves the accuracy of gradient estimation in FL and\nthus reduces the number of communication rounds required for convergence, but\nresults in higher per-round latency, and vice versa. The associated problem of\nlatency minimization is intractable; however, we solve it by designing an\naccurate and tractable surrogate for convergence speed, with parameters fitted\nto real data. This approach yields two batch-size control strategies tailored\nto scenarios with slow and fast fading, while also accommodating device\nheterogeneity. Extensive experiments using real datasets demonstrate that the\nproposed strategies outperform conventional batch-size adaptation schemes that\ndo not consider the C$^2$ tradeoff or device heterogeneity.", "AI": {"tldr": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u57286G\u7f51\u7edc\u4e2d\u56e0\u4fdd\u62a4\u9690\u79c1\u800c\u6d41\u884c\uff0c\u5bf9\u4e8e\u4f4e\u5ef6\u8fdf\u6846\u67b6\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684C^2\u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u6279\u91cf\u5927\u5c0f\u63a7\u5236\uff0c\u4ee5\u6700\u5c0f\u5316\u7aef\u5230\u7aef\u5b66\u4e60\u5ef6\u8fdf\u5e76\u786e\u4fdd\u6536\u655b\uff0c\u540c\u65f6\u5e73\u8861\u8ba1\u7b97\u548c\u901a\u4fe1\u80fd\u529b\u7684\u5f02\u6784\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7531\u4e8e\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5177\u5907\u4fdd\u62a4\u9690\u79c1\u7684\u80fd\u529b\uff0c\u5728\u7b2c\u516d\u4ee3\uff086G\uff09\u7f51\u7edc\u4e2d\u53d7\u5230\u6b22\u8fce\uff0c\u5b83\u80fd\u63a8\u52a8\u5404\u79cd\u7269\u8054\u7f51\u5e94\u7528\u7684\u53d1\u5c55\uff0c\u5982\u81ea\u52a8\u9a7e\u9a76\u3001\u589e\u5f3a\u73b0\u5b9e\u548c\u533b\u7597\u4fdd\u5065\u7b49\u5173\u952e\u4efb\u52a1\u4e14\u65f6\u95f4\u654f\u611f\u7684\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u4f4e\u5ef6\u8fdf\u7684FL\u6846\u67b6\u6765\u4fdd\u8bc1\u9ad8\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684C^2\u611f\u77e5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4f18\u5316\u6279\u91cf\u5927\u5c0f\u63a7\u5236\u4ee5\u6700\u5c0f\u5316\u7aef\u5230\u7aef\u5b66\u4e60\u5ef6\u8fdf\uff0c\u540c\u65f6\u786e\u4fdd\u6536\u655b\u3002\u6b64\u65b9\u6cd5\u65e8\u5728\u5e73\u8861\u7531\u6536\u655b\u5206\u6790\u63ed\u793a\u7684\u57fa\u672cC^2\u6743\u8861\uff0c\u5373\u589e\u52a0\u6279\u91cf\u5927\u5c0f\u53ef\u4ee5\u63d0\u9ad8\u68af\u5ea6\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u51cf\u5c11\u6536\u655b\u6240\u9700\u7684\u901a\u4fe1\u8f6e\u6b21\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6bcf\u8f6e\u5ef6\u8fdf\u589e\u52a0\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u4e8e\u4f20\u7edf\u7684\u6279\u91cf\u8c03\u6574\u65b9\u6848\uff0c\u540e\u8005\u672a\u8003\u8651C^2\u6743\u8861\u6216\u8bbe\u5907\u5f02\u8d28\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684C^2\u611f\u77e5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u4f18\u5316\u6279\u91cf\u5927\u5c0f\u63a7\u5236\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684\u8054\u90a6\u5b66\u4e60\uff0c\u9002\u5e94\u4e0d\u540c\u7684\u8bbe\u5907\u5f02\u8d28\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15614", "pdf": "https://arxiv.org/pdf/2507.15614", "abs": "https://arxiv.org/abs/2507.15614", "authors": ["Edward Holmberg", "Pujan Pokhrel", "Maximilian Zoch", "Elias Ioup", "Ken Pathak", "Steven Sloan", "Kendall Niles", "Jay Ratcliff", "Maik Flanagin", "Christian Guetl", "Julian Simeonov", "Mahdi Abdelguerfi"], "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 8 figures", "summary": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but\nare too computationally intensive for on-the-fly decision-making during flood\nevents. The central challenge is to accelerate these simulations without\nsacrificing accuracy. This paper introduces a deep learning surrogate that\ntreats HEC-RAS not as a solver but as a data-generation engine. We propose a\nhybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)\nto capture short-term temporal dynamics with a Geometry-Aware Fourier Neural\nOperator (Geo-FNO) to model long-range spatial dependencies along a river\nreach. The model learns underlying physics implicitly from a minimal\neight-channel feature vector encoding dynamic state, static geometry, and\nboundary forcings extracted directly from native HEC-RAS files. Trained on 67\nreaches of the Mississippi River Basin, the surrogate was evaluated on a\nyear-long, unseen hold-out simulation. Results show the model achieves a strong\npredictive accuracy, with a median absolute stage error of 0.31 feet.\nCritically, for a full 67-reach ensemble forecast, our surrogate reduces the\nrequired wall-clock time from 139 minutes to 40 minutes, a speedup of nearly\n3.5 times over the traditional solver. The success of this data-driven approach\ndemonstrates that robust feature engineering can produce a viable, high-speed\nreplacement for conventional hydraulic models, improving the computational\nfeasibility of large-scale ensemble flood forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408GRU\u548cGeo-FNO\u6765\u52a0\u901fHEC-RAS\u6c34\u6587\u6a21\u62df\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u7f29\u77ed\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u7269\u7406\u57fa\u7840\u6c42\u89e3\u5668\uff08\u5982HEC-RAS\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u9ad8\u4fdd\u771f\u7684\u6cb3\u6d41\u9884\u6d4b\uff0c\u4f46\u5728\u6d2a\u6c34\u4e8b\u4ef6\u4e2d\u7684\u5b9e\u65f6\u51b3\u7b56\u8fc7\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u3002\u4e3a\u4e86\u52a0\u901f\u8fd9\u4e9b\u6a21\u62df\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\uff0c\u63d0\u51fa\u4e86\u8fd9\u4e00\u7814\u7a76\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u4e00\u79cd\u6df7\u5408\u81ea\u52a8\u56de\u5f52\u67b6\u6784\uff0c\u5c06\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u4e0e\u51e0\u4f55\u611f\u77e5\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08Geo-FNO\uff09\u76f8\u7ed3\u5408\uff0c\u4ee5\u6355\u6349\u77ed\u671f\u65f6\u95f4\u52a8\u6001\u548c\u957f\u8ddd\u79bb\u7a7a\u95f4\u4f9d\u8d56\u6027\u3002\u7279\u5f81\u5411\u91cf\u4ece\u539f\u751fHEC-RAS\u6587\u4ef6\u4e2d\u63d0\u53d6\uff0c\u7f16\u7801\u4e86\u52a8\u6001\u72b6\u6001\u3001\u9759\u6001\u51e0\u4f55\u7ed3\u6784\u548c\u8fb9\u754c\u5f3a\u5236\u3002", "result": "\u8be5\u6a21\u578b\u5728\u5bc6\u897f\u897f\u6bd4\u6cb3\u6d41\u57df\u768467\u4e2a\u6cb3\u6bb5\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5e76\u5728\u4e00\u4e2a\u672a\u89c1\u8fc7\u7684\u4fdd\u7559\u6a21\u62df\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5177\u6709\u5f88\u5f3a\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u7edd\u5bf9\u6c34\u4f4d\u8bef\u5dee\u4e2d\u503c\u4e3a0.31\u82f1\u5c3a\uff0c\u5e76\u4e14\u5c06\u6574\u4e2a67\u4e2a\u6cb3\u6bb5\u96c6\u5408\u9884\u62a5\u7684\u65f6\u95f4\u4ece139\u5206\u949f\u51cf\u5c11\u523040\u5206\u949f\uff0c\u52a0\u901f\u8fd13.5\u500d\u3002", "conclusion": "\u8fd9\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u7684\u6210\u529f\u8bc1\u660e\uff0c\u7a33\u5065\u7684\u7279\u5f81\u5de5\u7a0b\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u53ef\u884c\u7684\u3001\u9ad8\u901f\u7684\u5e38\u89c4\u6c34\u529b\u6a21\u578b\u66ff\u4ee3\u54c1\uff0c\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u96c6\u5408\u6d2a\u6c34\u9884\u62a5\u7684\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2507.15640", "pdf": "https://arxiv.org/pdf/2507.15640", "abs": "https://arxiv.org/abs/2507.15640", "authors": ["Kailai Yang", "Xiao Liu", "Lei Ji", "Hao Li", "Yeyun Gong", "Peng Cheng", "Mao Yang"], "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u636e\u6df7\u5408\u4ee3\u7406\uff0c\u7528\u4e8e\u81ea\u52a8\u91cd\u65b0\u52a0\u6743\u6765\u81ea\u6e90\u548c\u76ee\u6807\u9886\u57df\u7684\u8bad\u7ec3\u6570\u636e\u7ec4\u5408\uff0c\u4ee5\u5b9e\u73b0\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u7684\u5e73\u8861\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u53ef\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u6e90\u9886\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u57df\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u624b\u52a8\u6307\u5b9a\u9886\u57df\u6743\u91cd\uff0c\u8fd9\u53ef\u80fd\u4e0d\u591f\u7075\u6d3b\u6216\u9ad8\u6548\u3002\u672c\u6587\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u5b66\u4e60\u5982\u4f55\u91cd\u65b0\u52a0\u6743\u4e0d\u540c\u9886\u57df\u7684\u6570\u636e\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Data Mixing Agent\uff08DMA\uff09\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5728\u5927\u91cf\u6570\u636e\u6df7\u5408\u8f68\u8ff9\u4e0a\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u6765\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u4ece\u800c\u81ea\u52a8\u8c03\u6574\u6e90\u9886\u57df\u548c\u76ee\u6807\u9886\u57df\u7684\u6570\u636e\u6bd4\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\uff0cDMA\u6bd4\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5e73\u8861\u6e90\u9886\u57df\u548c\u76ee\u6807\u9886\u57df\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0cDMA\u5728\u65b0\u7684\u6e90\u9886\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u57df\u7a7a\u95f4\u4e0a\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u4e5f\u5c55\u793a\u4e86\u5176\u9002\u5e94\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86Data Mixing Agent\u53ef\u4ee5\u901a\u8fc7\u81ea\u52a8\u8c03\u6574\u6570\u636e\u6df7\u5408\u7b56\u7565\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65b0\u9886\u57df\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u539f\u6709\u80fd\u529b\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u7684\u4efb\u52a1\uff0c\u800c\u4e14\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2507.15643", "pdf": "https://arxiv.org/pdf/2507.15643", "abs": "https://arxiv.org/abs/2507.15643", "authors": ["Elnur Isgandarov", "Matteo Cederle", "Federico Chiariotti", "Gian Antonio Susto"], "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication", "summary": "Shared mobility systems, such as bike-sharing networks, play a crucial role\nin urban transportation. Identifying anomalies in these systems is essential\nfor optimizing operations, improving service reliability, and enhancing user\nexperience. This paper presents an interpretable anomaly detection framework\nthat integrates multi-source data, including bike-sharing trip records, weather\nconditions, and public transit availability. The Isolation Forest algorithm is\nemployed for unsupervised anomaly detection, along with the Depth-based\nIsolation Forest Feature Importance (DIFFI) algorithm providing\ninterpretability. Results show that station-level analysis offers a robust\nunderstanding of anomalies, highlighting the influence of external factors such\nas adverse weather and limited transit availability. Our findings contribute to\nimproving decision-making in shared mobility operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u60c5\u51b5\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u6e90\u6570\u636e\u548cIsolation Forest\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bc6\u522b\u5171\u4eab\u79fb\u52a8\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u5bf9\u4e8e\u4f18\u5316\u8fd0\u8425\u3001\u63d0\u9ad8\u670d\u52a1\u53ef\u9760\u6027\u548c\u589e\u5f3a\u7528\u6237\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528Isolation Forest\u7b97\u6cd5\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684\u9694\u79bb\u68ee\u6797\u7279\u5f81\u91cd\u8981\u6027\uff08DIFFI\uff09\u7b97\u6cd5\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7ad9\u70b9\u7ea7\u522b\u7684\u5206\u6790\u63d0\u4f9b\u4e86\u5bf9\u5916\u90e8\u56e0\u7d20\uff08\u5982\u6076\u52a3\u5929\u6c14\u548c\u6709\u9650\u7684\u4ea4\u901a\u53ef\u7528\u6027\uff09\u5f71\u54cd\u7684\u7a33\u5065\u7406\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u7684\u53d1\u73b0\u6709\u52a9\u4e8e\u6539\u5584\u5171\u4eab\u79fb\u52a8\u64cd\u4f5c\u4e2d\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.15678", "pdf": "https://arxiv.org/pdf/2507.15678", "abs": "https://arxiv.org/abs/2507.15678", "authors": ["Amine Mohamed Aboussalah", "Abdessalam Ed-dib"], "title": "GeoHNNs: Geometric Hamiltonian Neural Networks", "categories": ["cs.LG", "math.DG", "math.DS", "math.SG", "stat.ML"], "comment": null, "summary": "The fundamental laws of physics are intrinsically geometric, dictating the\nevolution of systems through principles of symmetry and conservation. While\nmodern machine learning offers powerful tools for modeling complex dynamics\nfrom data, common methods often ignore this underlying geometric fabric.\nPhysics-informed neural networks, for instance, can violate fundamental\nphysical principles, leading to predictions that are unstable over long\nperiods, particularly for high-dimensional and chaotic systems. Here, we\nintroduce \\textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework\nthat learns dynamics by explicitly encoding the geometric priors inherent to\nphysical laws. Our approach enforces two fundamental structures: the Riemannian\ngeometry of inertia, by parameterizing inertia matrices in their natural\nmathematical space of symmetric positive-definite matrices, and the symplectic\ngeometry of phase space, using a constrained autoencoder to ensure the\npreservation of phase space volume in a reduced latent space. We demonstrate\nthrough experiments on systems ranging from coupled oscillators to\nhigh-dimensional deformable objects that GeoHNN significantly outperforms\nexisting models. It achieves superior long-term stability, accuracy, and energy\nconservation, confirming that embedding the geometry of physics is not just a\ntheoretical appeal but a practical necessity for creating robust and\ngeneralizable models of the physical world.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Geometric Hamiltonian Neural Networks (GeoHNN)\uff0c\u901a\u8fc7\u660e\u786e\u7f16\u7801\u7269\u7406\u5b9a\u5f8b\u56fa\u6709\u7684\u51e0\u4f55\u5148\u9a8c\u6765\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u5f3a\u5236\u6267\u884c\u9ece\u66fc\u51e0\u4f55\u548c\u8f9b\u51e0\u4f55\u4e24\u4e2a\u57fa\u672c\u7ed3\u6784\uff0c\u5b9e\u9a8c\u8868\u660eGeoHNN\u6bd4\u73b0\u6709\u6a21\u578b\u5177\u6709\u663e\u8457\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u4ece\u6570\u636e\u5efa\u6a21\u590d\u6742\u52a8\u6001\u65b9\u9762\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u4f46\u901a\u5e38\u5ffd\u7565\u4e86\u5e95\u5c42\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5bf9\u4e8e\u9ad8\u7ef4\u548c\u6df7\u6c8c\u7cfb\u7edf\u957f\u671f\u9884\u6d4b\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u5f15\u5165\u4e86Geometric Hamiltonian Neural Networks (GeoHNN)\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u53c2\u6570\u5316\u60ef\u6027\u77e9\u9635\u53ca\u5176\u81ea\u7136\u6570\u5b66\u7a7a\u95f4\u4e2d\u7684\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u6765\u5f3a\u5236\u6267\u884c\u60ef\u6027\u7684\u9ece\u66fc\u51e0\u4f55\uff0c\u5e76\u4f7f\u7528\u7ea6\u675f\u81ea\u52a8\u7f16\u7801\u5668\u786e\u4fdd\u76f8\u7a7a\u95f4\u4f53\u79ef\u5728\u964d\u4f4e\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5f97\u4ee5\u4fdd\u5b58\u4ee5\u4fdd\u8bc1\u76f8\u7a7a\u95f4\u7684\u8f9b\u51e0\u4f55\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGeoHNN\u5728\u4ece\u8026\u5408\u632f\u8361\u5668\u5230\u9ad8\u7ef4\u53d8\u5f62\u7269\u4f53\u7684\u7cfb\u7edf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u957f\u671f\u7a33\u5b9a\u6027\u3001\u51c6\u786e\u6027\u548c\u80fd\u91cf\u5b88\u6052\u3002", "conclusion": "\u5c06\u7269\u7406\u51e0\u4f55\u5d4c\u5165\u5230\u6a21\u578b\u4e2d\u4e0d\u4ec5\u662f\u7406\u8bba\u4e0a\u7684\u5438\u5f15\u529b\uff0c\u800c\u4e14\u662f\u521b\u5efa\u7a33\u5065\u548c\u53ef\u63a8\u5e7f\u7684\u7269\u7406\u4e16\u754c\u6a21\u578b\u7684\u5b9e\u9645\u5fc5\u8981\u6761\u4ef6\u3002"}}
{"id": "2507.15718", "pdf": "https://arxiv.org/pdf/2507.15718", "abs": "https://arxiv.org/abs/2507.15718", "authors": ["Matteo Cederle", "Andrea Mazzucco", "Andrea Demartini", "Eugenio Mazza", "Eugenia Suriani", "Federico Vitti", "Gian Antonio Susto"], "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on\n  Computers, Cognition and Communication)", "summary": "Electric vehicles (EV) charging stations are one of the critical\ninfrastructures needed to support the transition to renewable-energy-based\nmobility, but ensuring their reliability and efficiency requires effective\nanomaly detection to identify irregularities in charging behavior. However, in\nsuch a productive scenario, it is also crucial to determine the underlying\ncause behind the detected anomalies. To achieve this goal, this study\ninvestigates unsupervised anomaly detection techniques for EV charging\ninfrastructure, integrating eXplainable Artificial Intelligence techniques to\nenhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies\nIsolation Forest to detect anomalies and employs the Depth-based Isolation\nForest Feature Importance (DIFFI) method to identify the most important\nfeatures contributing to such anomalies. The efficacy of the proposed approach\nis evaluated in a real industrial case.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u8bbe\u65bd\u4e2d\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\uff0c\u5e76\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\uff0c\u786e\u5b9a\u5f02\u5e38\u7684\u6839\u672c\u539f\u56e0\u3002\u5b83\u5e94\u7528\u4e86\u9694\u79bb\u68ee\u6797\u7b97\u6cd5\u548c\u57fa\u4e8e\u6df1\u5ea6\u7684\u9694\u79bb\u68ee\u6797\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08DIFFI\uff09\u6765\u8bc6\u522b\u5bfc\u81f4\u5f02\u5e38\u7684\u6700\u91cd\u8981\u7279\u5f81\uff0c\u5e76\u5728\u4e00\u4e2a\u771f\u5b9e\u7684\u5de5\u4e1a\u6848\u4f8b\u4e2d\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u786e\u4fdd\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u9700\u8981\u6709\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u4ee5\u8bc6\u522b\u5145\u7535\u884c\u4e3a\u4e2d\u7684\u4e0d\u89c4\u5219\u60c5\u51b5\uff0c\u5e76\u786e\u5b9a\u8fd9\u4e9b\u5f02\u5e38\u80cc\u540e\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u4f7f\u7528\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u548c\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u91c7\u7528\u9694\u79bb\u68ee\u6797\u7b97\u6cd5\u68c0\u6d4b\u5f02\u5e38\uff0c\u5e76\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684\u9694\u79bb\u68ee\u6797\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08DIFFI\uff09\u6765\u786e\u5b9a\u6700\u91cd\u8981\u7684\u7279\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e00\u4e2a\u771f\u5b9e\u7684\u5de5\u4e1a\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u6709\u6548\u6027\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4e0e\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u53ef\u9760\u6027\u53ca\u6548\u7387\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u7406\u89e3\u5f02\u5e38\u4ea7\u751f\u7684\u539f\u56e0\u3002"}}
{"id": "2507.15727", "pdf": "https://arxiv.org/pdf/2507.15727", "abs": "https://arxiv.org/abs/2507.15727", "authors": ["Xuchuang Wang", "Bo Sun", "Hedyeh Beyhaghi", "John C. S. Lui", "Mohammad Hajiesmaili", "Adam Wierman"], "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": null, "summary": "This paper introduces a novel multi-agent ski-rental problem that generalizes\nthe classical ski-rental dilemma to a group setting where agents incur\nindividual and shared costs. In our model, each agent can either rent at a\nfixed daily cost, or purchase a pass at an individual cost, with an additional\nthird option of a discounted group pass available to all. We consider scenarios\nin which agents' active days differ, leading to dynamic states as agents drop\nout of the decision process. To address this problem from different\nperspectives, we define three distinct competitive ratios: overall,\nstate-dependent, and individual rational. For each objective, we design and\nanalyze optimal deterministic and randomized policies. Our deterministic\npolicies employ state-aware threshold functions that adapt to the dynamic\nstates, while our randomized policies sample and resample thresholds from\ntailored state-aware distributions. The analysis reveals that symmetric\npolicies, in which all agents use the same threshold, outperform asymmetric\nones. Our results provide competitive ratio upper and lower bounds and extend\nclassical ski-rental insights to multi-agent settings, highlighting both\ntheoretical and practical implications for group decision-making under\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u5c06\u7ecf\u5178\u7684\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u63a8\u5e7f\u5230\u591a\u4ee3\u7406\u73af\u5883\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e09\u4e2a\u7ade\u4e89\u6bd4\u7387\uff0c\u8bbe\u8ba1\u548c\u5206\u6790\u4e86\u6700\u4f18\u7684\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u3002", "motivation": "\u7ecf\u5178\u7684\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u4ec5\u8003\u8651\u5355\u4e2a\u4ee3\u7406\u7684\u60c5\u51b5\uff0c\u800c\u5b9e\u9645\u751f\u6d3b\u4e2d\u5e38\u5e38\u9700\u8981\u8003\u8651\u591a\u4e2a\u4ee3\u7406\u5171\u540c\u51b3\u7b56\u7684\u60c5\u666f\uff0c\u5373\u5b58\u5728\u4e2a\u4f53\u6210\u672c\u548c\u5171\u4eab\u6210\u672c\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u4ee3\u7406\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u6a21\u578b\uff0c\u5176\u4e2d\u6bcf\u4e2a\u4ee3\u7406\u53ef\u4ee5\u9009\u62e9\u4ee5\u56fa\u5b9a\u65e5\u79df\u8d39\u79df\u8d41\u3001\u8d2d\u4e70\u4e2a\u4eba\u901a\u884c\u8bc1\u6216\u4eab\u53d7\u6298\u6263\u56e2\u4f53\u7968\u3002\u8be5\u8bba\u6587\u5b9a\u4e49\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u7ade\u4e89\u6bd4\u7387\uff1a\u603b\u4f53\u3001\u72b6\u6001\u4f9d\u8d56\u548c\u4e2a\u4f53\u7406\u6027\u3002\u5e76\u4e3a\u6bcf\u79cd\u76ee\u6807\u8bbe\u8ba1\u548c\u5206\u6790\u4e86\u6700\u4f18\u7684\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u3002", "result": "\u5bf9\u79f0\u7b56\u7565\uff08\u6240\u6709\u4ee3\u7406\u4f7f\u7528\u76f8\u540c\u7684\u9608\u503c\uff09\u4f18\u4e8e\u975e\u5bf9\u79f0\u7b56\u7565\u3002\u5e76\u4e14\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u79cd\u76ee\u6807\uff0c\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u7ade\u4e89\u6bd4\u7387\u7684\u4e0a\u4e0b\u9650\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u7ecf\u5178\u7684\u6ed1\u96ea\u79df\u8d41\u95ee\u9898\u5230\u591a\u4ee3\u7406\u73af\u5883\u4e2d\uff0c\u5f3a\u8c03\u4e86\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7fa4\u4f53\u51b3\u7b56\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2507.15769", "pdf": "https://arxiv.org/pdf/2507.15769", "abs": "https://arxiv.org/abs/2507.15769", "authors": ["Ahmad M. Nazar", "Abdulkadir Celik", "Mohamed Y. Selim", "Asmaa Abdallah", "Daji Qiao", "Ahmed M. Eltawil"], "title": "Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks", "categories": ["cs.LG"], "comment": "Accepted in IEEE Asilomar Conference on Signals, Systems, and\n  Computers 2025", "summary": "Vehicular communication systems operating in the millimeter wave (mmWave)\nband are highly susceptible to signal blockage from dynamic obstacles such as\nvehicles, pedestrians, and infrastructure. To address this challenge, we\npropose a proactive blockage prediction framework that utilizes multi-modal\nsensing, including camera, GPS, LiDAR, and radar inputs in an\ninfrastructure-to-vehicle (I2V) setting. This approach uses modality-specific\ndeep learning models to process each sensor stream independently and fuses\ntheir outputs using a softmax-weighted ensemble strategy based on validation\nperformance. Our evaluations, for up to 1.5s in advance, show that the\ncamera-only model achieves the best standalone trade-off with an F1-score of\n97.1% and an inference time of 89.8ms. A camera+radar configuration further\nimproves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness\nand efficiency of multi-modal sensing for mmWave blockage prediction and\nprovide a pathway for proactive wireless communication in dynamic environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u611f\u77e5\u7684 proactive blockage prediction framework\uff0c\u4ee5\u5e94\u5bf9\u6beb\u7c73\u6ce2\u9891\u6bb5\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u4fe1\u53f7\u963b\u6321\u7684\u95ee\u9898\u3002", "motivation": "\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u8f66\u8054\u7f51\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u52a8\u6001\u969c\u788d\u7269\uff08\u5982\u8f66\u8f86\u3001\u884c\u4eba\u548c\u57fa\u7840\u8bbe\u65bd\uff09\u9020\u6210\u7684\u4fe1\u53f7\u963b\u6321\u5f71\u54cd\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u7279\u5b9a\u4e8e\u6a21\u5f0f\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u4f20\u611f\u5668\u6d41\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u9a8c\u8bc1\u6027\u80fd\u7684softmax\u52a0\u6743\u96c6\u6210\u7b56\u7565\u878d\u5408\u5176\u8f93\u51fa\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u4ec5\u76f8\u673a\u6a21\u578b\u5728F1\u5206\u6570\u4e0a\u8fbe\u5230\u4e8697.1%\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a89.8\u6beb\u79d2\uff1b\u76f8\u673a+\u96f7\u8fbe\u914d\u7f6e\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u523097.2% F1\uff0c\u8017\u65f695.7\u6beb\u79d2\u3002", "conclusion": "\u7ed3\u679c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u611f\u77e5\u5bf9\u4e8e\u6beb\u7c73\u6ce2\u963b\u6321\u9884\u6d4b\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4e3b\u52a8\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2507.15772", "pdf": "https://arxiv.org/pdf/2507.15772", "abs": "https://arxiv.org/abs/2507.15772", "authors": ["Anoop C. Patil", "Benny Jian Rong Sng", "Yu-Wei Chang", "Joana B. Pereira", "Chua Nam-Hai", "Rajani Sarojam", "Gajendra Pratap Singh", "In-Cheol Jang", "Giovanni Volpe"], "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "*Authors contributed equally to this work. +Supervised this work. 5\n  main figures and 1 extended data figure in manuscript. The PDF includes\n  supplementary material", "summary": "Detecting stress in plants is crucial for both open-farm and\ncontrolled-environment agriculture. Biomolecules within plants serve as key\nstress indicators, offering vital markers for continuous health monitoring and\nearly disease detection. Raman spectroscopy provides a powerful, non-invasive\nmeans to quantify these biomolecules through their molecular vibrational\nsignatures. However, traditional Raman analysis relies on customized\ndata-processing workflows that require fluorescence background removal and\nprior identification of Raman peaks of interest-introducing potential biases\nand inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation\nof Vibrational Raman spectra for plant-stress Analysis), a fully automated\nworkflow based on a variational autoencoder. Unlike conventional approaches,\nDIVA processes native Raman spectra-including fluorescence backgrounds-without\nmanual preprocessing, identifying and quantifying significant spectral features\nin an unbiased manner. We applied DIVA to detect a range of plant stresses,\nincluding abiotic (shading, high light intensity, high temperature) and biotic\nstressors (bacterial infections). By integrating deep learning with vibrational\nspectroscopy, DIVA paves the way for AI-driven plant health assessment,\nfostering more resilient and sustainable agricultural practices.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5DIVA\uff0c\u7528\u4e8e\u81ea\u52a8\u5904\u7406\u62c9\u66fc\u5149\u8c31\u4ee5\u68c0\u6d4b\u690d\u7269\u538b\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u9884\u5904\u7406\u6b65\u9aa4\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u8bc6\u522b\u548c\u91cf\u5316\u91cd\u8981\u7684\u5149\u8c31\u7279\u5f81\uff0c\u5e76\u80fd\u68c0\u6d4b\u591a\u79cd\u690d\u7269\u538b\u529b\u6e90\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u53ef\u6301\u7eed\u7684\u519c\u4e1a\u5b9e\u8df5\u3002", "motivation": "\u4f20\u7edf\u7684\u62c9\u66fc\u5149\u8c31\u5206\u6790\u4f9d\u8d56\u4e8e\u5b9a\u5236\u7684\u6570\u636e\u5904\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u9700\u8981\u53bb\u9664\u8367\u5149\u80cc\u666f\u5e76\u9884\u5148\u786e\u5b9a\u611f\u5174\u8da3\u7684\u62c9\u66fc\u5cf0\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u6027\u3002\u4e3a\u4e86\u63d0\u4f9b\u4e00\u79cd\u65e0\u504f\u5dee\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u91cf\u5316\u690d\u7269\u4e2d\u7684\u751f\u7269\u5206\u5b50\uff0c\u4ece\u800c\u5b9e\u73b0\u8fde\u7eed\u5065\u5eb7\u76d1\u6d4b\u548c\u65e9\u671f\u75be\u75c5\u68c0\u6d4b\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u5316\u5904\u7406\u62c9\u66fc\u5149\u8c31\u7684\u6280\u672f\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86DIVA\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u632f\u52a8\u62c9\u66fc\u5149\u8c31\u5206\u6790\uff09\uff0c\u5b83\u662f\u4e00\u4e2a\u57fa\u4e8e\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5168\u81ea\u52a8\u5de5\u4f5c\u6d41\u7a0b\uff0c\u80fd\u591f\u5904\u7406\u539f\u59cb\u62c9\u66fc\u5149\u8c31\uff0c\u5305\u62ec\u8367\u5149\u80cc\u666f\uff0c\u800c\u65e0\u9700\u624b\u52a8\u9884\u5904\u7406\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u81ea\u52a8\u8bc6\u522b\u548c\u91cf\u5316\u91cd\u8981\u7684\u5149\u8c31\u7279\u5f81\u3002", "result": "\u901a\u8fc7\u5c06DIVA\u5e94\u7528\u4e8e\u68c0\u6d4b\u4e00\u7cfb\u5217\u690d\u7269\u538b\u529b\u6e90\uff08\u5305\u62ec\u975e\u751f\u7269\u548c\u751f\u7269\u80c1\u8feb\uff09\uff0c\u7814\u7a76\u4eba\u5458\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3aAI\u9a71\u52a8\u7684\u690d\u7269\u5065\u5eb7\u8bc4\u4f30\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "DIVA\u6574\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u632f\u52a8\u5149\u8c31\u5b66\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u504f\u3001\u81ea\u52a8\u5316\u7684\u624b\u6bb5\u6765\u5904\u7406\u62c9\u66fc\u5149\u8c31\u6570\u636e\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5177\u5f39\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u519c\u4e1a\u5b9e\u8df5\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.15774", "pdf": "https://arxiv.org/pdf/2507.15774", "abs": "https://arxiv.org/abs/2507.15774", "authors": ["Alexis-Raja Brachet", "Pierre-Yves Richard", "C\u00e9line Hudelot"], "title": "Dynamics is what you need for time-series forecasting!", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 6 figures, 1 table", "summary": "While boundaries between data modalities are vanishing, the usual successful\ndeep models are still challenged by simple ones in the time-series forecasting\ntask. Our hypothesis is that this task needs models that are able to learn the\ndata underlying dynamics. We propose to validate it through both systemic and\nempirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to\nanalyze existing models through the lens of dynamics. Two observations thus\nemerged: $\\textbf{1}$. under-performing architectures learn dynamics at most\npartially, $\\textbf{2}$. the location of the dynamics block at the model end is\nof prime importance. We conduct extensive experiments to confirm our\nobservations on a set of performance-varying models with diverse backbones.\nResults support the need to incorporate a learnable dynamics block and its use\nas the final predictor.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2PRO-DYN\u6765\u5206\u6790\u73b0\u6709\u7684\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u9700\u8981\u5b66\u4e60\u6570\u636e\u5e95\u5c42\u52a8\u6001\uff0c\u5e76\u4e14\u5c06\u52a8\u6001\u5757\u7f6e\u4e8e\u6a21\u578b\u672b\u7aef\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f5c\u8005\u89c2\u5bdf\u5230\u5c3d\u7ba1\u4e0d\u540c\u6570\u636e\u6a21\u5f0f\u4e4b\u95f4\u7684\u754c\u9650\u6b63\u5728\u6d88\u5931\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u901a\u5e38\u6210\u529f\u7684\u6df1\u5ea6\u6a21\u578b\u4ecd\u7136\u88ab\u7b80\u5355\u7684\u6a21\u578b\u6240\u6311\u6218\u3002\u4ed6\u4eec\u5047\u8bbe\u8fd9\u662f\u56e0\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u9700\u8981\u80fd\u591f\u5b66\u4e60\u6570\u636e\u6f5c\u5728\u52a8\u6001\u7684\u6a21\u578b\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aPRO-DYN\u7684\u547d\u540d\u6cd5\uff0c\u4ee5\u4ece\u52a8\u6001\u5b66\u7684\u89d2\u5ea6\u5206\u6790\u73b0\u6709\u6a21\u578b\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e24\u4e2a\u89c2\u5bdf\u7ed3\u679c\uff1a\u8868\u73b0\u4e0d\u4f73\u7684\u67b6\u6784\u6700\u591a\u53ea\u80fd\u90e8\u5206\u5b66\u4e60\u52a8\u6001\uff1b\u52a8\u6001\u6a21\u5757\u5728\u6a21\u578b\u672b\u7aef\u7684\u4f4d\u7f6e\u81f3\u5173\u91cd\u8981\u3002\u7136\u540e\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u6765\u786e\u8ba4\u8fd9\u4e9b\u89c2\u5bdf\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u4e86\u4ed6\u4eec\u7684\u89c2\u5bdf\uff0c\u5373\u9700\u8981\u5c06\u53ef\u5b66\u4e60\u7684\u52a8\u6001\u6a21\u5757\u7eb3\u5165\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u7528\u4f5c\u6700\u7ec8\u9884\u6d4b\u5668\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u7406\u89e3\u5e76\u6a21\u62df\u6570\u636e\u6f5c\u5728\u52a8\u6001\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u5c06\u52a8\u6001\u6a21\u5757\u653e\u5728\u6a21\u578b\u672b\u7aef\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.15784", "pdf": "https://arxiv.org/pdf/2507.15784", "abs": "https://arxiv.org/abs/2507.15784", "authors": ["Zihang Ma", "Qitian Yin"], "title": "Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets", "categories": ["cs.LG"], "comment": null, "summary": "Graph node classification is a fundamental task in graph neural networks\n(GNNs), aiming to assign predefined class labels to nodes. On the PubMed\ncitation network dataset, we observe significant classification difficulty\ndisparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,\n7.5% lower than Category 1. To address this, we propose a\nWasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),\ntraining specialized GNN models for Categories 0/1 (with layer normalization\nand residual connections) and Multi-hop Graph Attention Networks (GAT) for\nCategory 2. The WR distance metric optimizes representation similarity between\nmodels, particularly focusing on improving Category 2 performance. Our adaptive\nfusion strategy dynamically weights models based on category-specific\nperformance, with Category 2 assigned a GAT weight of 0.8. WR distance further\nguides the fusion process by measuring distributional differences between model\nrepresentations, enabling more principled integration of complementary\nfeatures.\n  Experimental results show WR-EFM achieves balanced accuracy across\ncategories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),\noutperforming both single models and standard fusion approaches. The\ncoefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%\nlower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM\nimproves Category 2 accuracy by 5.5% compared to GCN, verifying the\neffectiveness of WR-guided fusion in capturing complex structural patterns.\nThis work provides a novel paradigm for handling class-imbalanced graph\nclassification tasks. To promote the research community, we release our project\nat https://github.com/s010m00n/GASEM4NC.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdWasserstein-Rubinstein (WR) \u8ddd\u79bb\u589e\u5f3a\u7684\u4e13\u5bb6\u878d\u5408\u6a21\u578b\uff08WR-EFM\uff09\uff0c\u4ee5\u6539\u5584\u56fe\u8282\u70b9\u5206\u7c7b\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u901a\u8fc7\u4e3a\u4e0d\u540c\u7c7b\u522b\u8bad\u7ec3\u4e13\u95e8\u7684GNN\u6a21\u578b\uff0c\u5e76\u4f7f\u7528WR\u8ddd\u79bb\u4f18\u5316\u6a21\u578b\u95f4\u7684\u8868\u793a\u76f8\u4f3c\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u5e73\u8861\u548c\u7a33\u5b9a\u7684\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u5728PubMed\u5f15\u6587\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\uff0c\u4f20\u7edf\u7684GCN\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u522b\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7279\u522b\u662fCategory 2\u7684\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u4ec5\u8fbe\u523074.4%\uff0c\u6bd4Category 1\u4f4e7.5%\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86WR-EFM\u6a21\u578b\uff0c\u5305\u62ec\uff1a1\uff09\u4e3aCategory 0/1\u8bad\u7ec3\u5e26\u6709\u5c42\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\u7684GNN\u6a21\u578b\uff1b2\uff09\u4e3aCategory 2\u8bad\u7ec3\u591a\u8df3\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\uff1b3\uff09\u4f7f\u7528WR\u8ddd\u79bb\u5ea6\u91cf\u4f18\u5316\u6a21\u578b\u95f4\u8868\u793a\u7684\u76f8\u4f3c\u6027\uff0c\u5c24\u5176\u5173\u6ce8\u63d0\u5347Category 2\u7684\u6027\u80fd\uff1b4\uff09\u91c7\u7528\u81ea\u9002\u5e94\u878d\u5408\u7b56\u7565\uff0c\u6839\u636e\u7279\u5b9a\u7c7b\u522b\u7684\u8868\u73b0\u52a8\u6001\u8c03\u6574\u6a21\u578b\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cWR-EFM\u5728\u6240\u6709\u7c7b\u522b\u4e2d\u90fd\u8fbe\u5230\u4e86\u8f83\u9ad8\u7684\u51c6\u786e\u7387\uff1aCategory 0\u4e3a77.8%\uff0cCategory 1\u4e3a78.0%\uff0cCategory 2\u4e3a79.9%\uff0c\u5e76\u4e14\u5176\u51c6\u786e\u7387\u7684\u6807\u51c6\u53d8\u5f02\u7cfb\u6570\uff08CV\uff09\u4ec5\u4e3a0.013\uff0c\u76f8\u6bd4GCN\u964d\u4f4e\u4e8677.6%\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "WR-EFM\u63d0\u4f9b\u4e86\u4e00\u79cd\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u56fe\u5206\u7c7b\u4efb\u52a1\u7684\u65b0\u8303\u5f0f\uff0c\u7279\u522b\u662f\u5728\u63d0\u9ad8\u96be\u5206\u7c7b\u7c7b\u522b\uff08\u5982Category 2\uff09\u7684\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u4fc3\u8fdb\u7814\u7a76\u793e\u533a\u7684\u53d1\u5c55\uff0c\u4f5c\u8005\u5f00\u6e90\u4e86\u8be5\u9879\u76ee\u3002"}}
{"id": "2507.15788", "pdf": "https://arxiv.org/pdf/2507.15788", "abs": "https://arxiv.org/abs/2507.15788", "authors": ["Sneheel Sarangi", "Hanan Salam"], "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c0f\u578b\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u7c7b\u4f3c\u4eba\u7c7b\u7684\u793e\u4f1a\u667a\u80fd\uff0c\u4f8b\u5982\u5fc3\u667a\u7406\u8bba\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u867d\u7136\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u7684\u8868\u73b0\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u65e0\u6cd5\u5c06\u8fd9\u79cd\u80fd\u529b\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u5fc3\u667a\u7406\u8bba\u4efb\u52a1\u4e0a\uff0c\u8fd9\u8868\u660e\u6240\u5b66\u884c\u4e3a\u662f\u4e00\u79cd\u72ed\u9698\u7684\u8fc7\u62df\u5408\uff0c\u800c\u4e0d\u662f\u771f\u6b63\u62bd\u8c61\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u7684\u83b7\u53d6\u3002", "motivation": "\u52a8\u673a\u662f\u63a2\u8ba8\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff08\u7279\u522b\u662f\u5e26\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u80fd\u5426\u4f7f\u5c0f\u89c4\u6a21\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u66f4\u590d\u6742\u7684\u4eba\u7c7b\u793e\u4f1a\u667a\u80fd\uff0c\u5982\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u4e86\u591a\u79cd\u8457\u540d\u7684\u5fc3\u667a\u7406\u8bba\u6570\u636e\u96c6\uff08HiToM\u3001ExploreToM\u3001FANToM\uff09\u5bf9\u6a21\u578b\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5e76\u5728\u4fdd\u7559\u7684\u6570\u636e\u96c6\uff08\u5982OpenToM\uff09\u4e0a\u6d4b\u8bd5\u5176\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5c3d\u7ba1\u5728\u5206\u5e03\u5185\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u6709\u6240\u63d0\u5347\uff0c\u4f46\u6a21\u578b\u672a\u80fd\u5c06\u5728\u4e0d\u540c\u7279\u5f81\u7684\u672a\u89c1\u5fc3\u667a\u7406\u8bba\u4efb\u52a1\u4e0a\u8fdb\u884c\u8f6c\u79fb\u3002\u957f\u671f\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5bfc\u81f4\u6a21\u578b\u201c\u7834\u89e3\u201d\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u6a21\u5f0f\uff0c\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u6ca1\u6709\u6539\u8fdb\u6216\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u53d1\u5c55\u51fa\u901a\u7528\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u6240\u5b66\u884c\u4e3a\u66f4\u591a\u8868\u73b0\u4e3a\u72ed\u7a84\u7684\u8fc7\u62df\u5408\u800c\u975e\u771f\u6b63\u7684\u62bd\u8c61\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u7684\u83b7\u53d6\u3002"}}
{"id": "2507.15816", "pdf": "https://arxiv.org/pdf/2507.15816", "abs": "https://arxiv.org/abs/2507.15816", "authors": ["Yujia Mu", "Cong Shen"], "title": "Federated Split Learning with Improved Communication and Storage Efficiency", "categories": ["cs.LG", "cs.IT", "cs.NI", "eess.SP", "math.IT"], "comment": "Accepted for publication in IEEE Transactions on Mobile Computing", "summary": "Federated learning (FL) is one of the popular distributed machine learning\n(ML) solutions but incurs significant communication and computation costs at\nedge devices. Federated split learning (FSL) can train sub-models in parallel\nand reduce the computational burden of edge devices by splitting the model\narchitecture. However, it still requires a high communication overhead due to\ntransmitting the smashed data and gradients between clients and the server in\nevery global round. Furthermore, the server must maintain separate partial\nmodels for every client, leading to a significant storage requirement. To\naddress these challenges, this paper proposes a novel communication and storage\nefficient federated split learning method, termed CSE-FSL, which utilizes an\nauxiliary network to locally update the weights of the clients while keeping a\nsingle model at the server, hence avoiding frequent transmissions of gradients\nfrom the server and greatly reducing the storage requirement of the server.\nAdditionally, a new model update method of transmitting the smashed data in\nselected epochs can reduce the amount of smashed data sent from the clients. We\nprovide a theoretical analysis of CSE-FSL, rigorously guaranteeing its\nconvergence under non-convex loss functions. The extensive experimental results\nfurther indicate that CSE-FSL achieves a significant communication reduction\nover existing FSL solutions using real-world FL tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u5408\u5206\u5272\u5b66\u4e60\u65b9\u6cd5CSE-FSL\uff0c\u901a\u8fc7\u8f85\u52a9\u7f51\u7edc\u672c\u5730\u66f4\u65b0\u5ba2\u6237\u7aef\u6743\u91cd\u5e76\u51cf\u5c11\u670d\u52a1\u5668\u7aef\u7684\u5b58\u50a8\u9700\u6c42\uff0c\u4ece\u800c\u51cf\u5c11\u901a\u4fe1\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u5408\u5206\u5272\u5b66\u4e60\uff08FSL\uff09\u867d\u7136\u53ef\u4ee5\u51cf\u8f7b\u8fb9\u7f18\u8bbe\u5907\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u9ad8\u901a\u4fe1\u5f00\u9500\u548c\u670d\u52a1\u5668\u7aef\u7684\u663e\u8457\u5b58\u50a8\u8981\u6c42\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u8f85\u52a9\u7f51\u7edc\u5728\u5ba2\u6237\u7aef\u672c\u5730\u66f4\u65b0\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u6301\u670d\u52a1\u5668\u7aef\u5355\u4e00\u6a21\u578b\uff0c\u907f\u514d\u9891\u7e41\u4ece\u670d\u52a1\u5668\u4f20\u8f93\u68af\u5ea6\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u53d1\u9001smashed\u6570\u636e\u6765\u51cf\u5c11\u4f20\u8f93\u91cf\u3002", "result": "\u7406\u8bba\u5206\u6790\u4fdd\u8bc1\u4e86CSE-FSL\u5728\u975e\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u7684\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCSE-FSL\u5728\u5b9e\u9645\u7684FL\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901a\u4fe1\u51cf\u5c11\u3002", "conclusion": "CSE-FSL\u6709\u6548\u5730\u89e3\u51b3\u4e86\u73b0\u6709FSL\u65b9\u6cd5\u4e2d\u7684\u901a\u4fe1\u548c\u5b58\u50a8\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15832", "pdf": "https://arxiv.org/pdf/2507.15832", "abs": "https://arxiv.org/abs/2507.15832", "authors": ["Shiyang Li"], "title": "Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction", "categories": ["cs.LG"], "comment": "in Chinese language", "summary": "To address the limitations of medium- and long-term four-dimensional (4D)\ntrajectory prediction models, this paper proposes a hybrid\nCNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy\nimproved snake-herd optimization (SO) algorithm. The model applies the Adaboost\nalgorithm to divide multiple weak learners, and each submodel utilizes CNN to\nextract spatial features, LSTM to capture temporal features, and attention\nmechanism to capture global features comprehensively. The strong learner model,\ncombined with multiple sub-models, then optimizes the hyperparameters of the\nprediction model through the natural selection behavior pattern simulated by\nSO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the\ncomparison experiments and ablation studies of multiple optimizers are carried\nout, and a comprehensive test and evaluation analysis is carried out. The\nresults show that SO-CLA-adaboost outperforms traditional optimizers such as\nparticle swarm, whale, and gray wolf in handling large-scale high-dimensional\ntrajectory data. In addition, introducing the full-strategy collaborative\nimprovement SO algorithm improves the model's prediction accuracy by 39.89%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408CNN-LSTM-Attention-Adaboost\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u7b56\u7565\u6539\u8fdb\u7684Snake-Herd\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u4e2d\u957f\u671f\u56db\u7ef4\u8f68\u8ff9\u9884\u6d4b\u3002\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u5668\uff0c\u5e76\u4e14\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u9ad8\u4e8639.89%\u3002", "motivation": "\u73b0\u6709\u7684\u4e2d\u957f\u671f\u56db\u7ef4\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u548c\u9ad8\u6548\u7684\u6a21\u578b\u6765\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u3002", "method": "\u4f7f\u7528Adaboost\u7b97\u6cd5\u5c06\u591a\u4e2a\u5f31\u5b66\u4e60\u8005\u5206\u9694\uff0c\u6bcf\u4e2a\u5b50\u6a21\u578b\u5229\u7528CNN\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff0cLSTM\u6355\u6349\u65f6\u95f4\u7279\u5f81\uff0cattention\u673a\u5236\u6355\u6349\u5168\u5c40\u7279\u5f81\u3002\u7136\u540e\u901a\u8fc7\u6a21\u62df\u81ea\u7136\u9009\u62e9\u884c\u4e3a\u6a21\u5f0f\u7684SO\u7b97\u6cd5\u4f18\u5316\u9884\u6d4b\u6a21\u578b\u7684\u8d85\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684SO-CLA-adaboost\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u8f68\u8ff9\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u7c92\u5b50\u7fa4\u3001\u9cb8\u9c7c\u548c\u7070\u72fc\u4f18\u5316\u5668\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad8\u4e8639.89%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408CNN-LSTM-Attention-Adaboost\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7ed3\u5408\u591a\u7b56\u7565\u6539\u8fdb\u7684Snake-Herd\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u4e2d\u957f\u671f\u56db\u7ef4\u8f68\u8ff9\u9884\u6d4b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2507.15839", "pdf": "https://arxiv.org/pdf/2507.15839", "abs": "https://arxiv.org/abs/2507.15839", "authors": ["Anh Nguyen", "Sam Schafft", "Nicholas Hale", "John Alfaro"], "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Synthetic data generation has emerged as an invaluable solution in scenarios\nwhere real-world data collection and usage are limited by cost and scarcity.\nLarge language models (LLMs) have demonstrated remarkable capabilities in\nproducing high-fidelity, domain-relevant samples across various fields.\nHowever, existing approaches that directly use LLMs to generate each record\nindividually impose prohibitive time and cost burdens, particularly when large\nvolumes of synthetic data are required. In this work, we propose a fast,\ncost-effective method for realistic tabular data synthesis that leverages LLMs\nto infer and encode each field's distribution into a reusable sampling script.\nBy automatically classifying fields into numerical, categorical, or free-text\ntypes, the LLM generates distribution-based scripts that can efficiently\nproduce diverse, realistic datasets at scale without continuous model\ninference. Experimental results show that our approach outperforms traditional\ndirect methods in both diversity and data realism, substantially reducing the\nburden of high-volume synthetic data generation. We plan to apply this\nmethodology to accelerate testing in production pipelines, thereby shortening\ndevelopment cycles and improving overall system efficiency. We believe our\ninsights and lessons learned will aid researchers and practitioners seeking\nscalable, cost-effective solutions for synthetic data generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\u548c\u7f16\u7801\u5b57\u6bb5\u5206\u5e03\u4ee5\u751f\u6210\u53ef\u590d\u7528\u91c7\u6837\u811a\u672c\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u5b9e\u73b0\u5feb\u901f\u3001\u4f4e\u6210\u672c\u7684\u8868\u683c\u6570\u636e\u5408\u6210\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u6570\u636e\u771f\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u76f4\u63a5\u65b9\u6cd5\uff0c\u5e76\u80fd\u5927\u5e45\u51cf\u5c11\u5927\u91cf\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u7684\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u751f\u6210\u6bcf\u4e2a\u8bb0\u5f55\u7684\u65b9\u6cd5\uff0c\u5728\u9700\u8981\u5927\u91cf\u5408\u6210\u6570\u636e\u65f6\u4f1a\u5e26\u6765\u8fc7\u9ad8\u7684\u65f6\u95f4\u548c\u6210\u672c\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5206\u7c7b\u5b57\u6bb5\u7c7b\u578b\uff08\u6570\u503c\u578b\u3001\u5206\u7c7b\u578b\u6216\u81ea\u7531\u6587\u672c\u578b\uff09\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u57fa\u4e8e\u5206\u5e03\u7684\u811a\u672c\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u5927\u89c4\u6a21\u751f\u6210\u591a\u6837\u5316\u3001\u771f\u5b9e\u7684\u6570\u636e\u96c6\uff0c\u800c\u65e0\u9700\u8fde\u7eed\u7684\u6a21\u578b\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u6570\u636e\u771f\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u76f4\u63a5\u65b9\u6cd5\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u5927\u91cf\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d1f\u62c5\u3002", "conclusion": "\u7814\u7a76\u4eba\u5458\u8ba4\u4e3a\u4ed6\u4eec\u7684\u89c1\u89e3\u548c\u7ecf\u9a8c\u5c06\u6709\u52a9\u4e8e\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u5bfb\u627e\u53ef\u6269\u5c55\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u8ba1\u5212\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u52a0\u901f\u751f\u4ea7\u7ba1\u9053\u4e2d\u7684\u6d4b\u8bd5\uff0c\u7f29\u77ed\u5f00\u53d1\u5468\u671f\u5e76\u63d0\u9ad8\u7cfb\u7edf\u6548\u7387\u3002"}}
{"id": "2507.15846", "pdf": "https://arxiv.org/pdf/2507.15846", "abs": "https://arxiv.org/abs/2507.15846", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5956\u52b1\u6846\u67b6GUI-G\u00b2\uff0c\u7528\u4e8e\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6620\u5c04\u5230\u56fe\u5f62\u7528\u6237\u754c\u9762\u7684\u5177\u4f53\u4f4d\u7f6e\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9ad8\u65af\u5206\u5e03\u5efa\u6a21\u754c\u9762\u5143\u7d20\uff0c\u5b9e\u73b0\u4e86\u4ece\u7a00\u758f\u4e8c\u5143\u5206\u7c7b\u5230\u5bc6\u96c6\u8fde\u7eed\u4f18\u5316\u7684\u8f6c\u53d8\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u4e8c\u5143\u5956\u52b1\u673a\u5236\uff0c\u5ffd\u7565\u4e86\u7a7a\u95f4\u4ea4\u4e92\u7684\u8fde\u7eed\u6027\u3002\u53d7\u5230\u4eba\u7c7b\u70b9\u51fb\u884c\u4e3a\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u5956\u52b1\u6846\u67b6\u4ee5\u6539\u8fdb\u8fd9\u4e00\u95ee\u9898\u3002", "method": "GUI-G\u00b2\u5f15\u5165\u4e86\u4e24\u79cd\u534f\u540c\u673a\u5236\uff1a\u9ad8\u65af\u70b9\u5956\u52b1\u548c\u8986\u76d6\u5956\u52b1\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u65b9\u5dee\u673a\u5236\u6765\u5904\u7406\u4e0d\u540c\u5c3a\u5ea6\u7684\u5143\u7d20\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGUI-G\u00b2\u5728ScreenSpot\u7cfb\u5217\u57fa\u51c6\u4e0a\u5927\u5e45\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684UI-TARS-72B\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728ScreenSpot-Pro\u4e0a\u63d0\u9ad8\u4e8624.7%\u3002", "conclusion": "\u8fde\u7eed\u5efa\u6a21\u63d0\u4f9b\u4e86\u5bf9\u754c\u9762\u53d8\u5316\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u5bf9\u672a\u89c1\u5e03\u5c40\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3aGUI\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.15857", "pdf": "https://arxiv.org/pdf/2507.15857", "abs": "https://arxiv.org/abs/2507.15857", "authors": ["Mihir Prabhudesai", "Menging Wu", "Amir Zadeh", "Katerina Fragkiadaki", "Deepak Pathak"], "title": "Diffusion Beats Autoregressive in Data-Constrained Settings", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Project Webpage: https://diffusion-scaling.github.io", "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.", "AI": {"tldr": "\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u6a21\u578b\u76f8\u8f83\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5f53\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\u4f46\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u6269\u6563\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u6563\u6a21\u578b\u76f8\u5bf9\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\u4f46\u6570\u636e\u91cf\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u7814\u7a76\u4eba\u5458\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5728\u6570\u636e\u53d7\u9650\u8bbe\u7f6e\u4e0b\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u901a\u8fc7\u5b9e\u9a8c\uff0c\u4ed6\u4eec\u63a2\u7d22\u4e86\u6269\u6563\u6a21\u578b\u7684\u65b0\u7f29\u653e\u89c4\u5f8b\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e86\u6269\u6563\u6a21\u578b\u5f00\u59cb\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5173\u952e\u8ba1\u7b97\u9608\u503c\u7684\u5c01\u95ed\u5f62\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\u4f46\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u6269\u6563\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u3002\u6269\u6563\u6a21\u578b\u66f4\u597d\u5730\u5229\u7528\u4e86\u91cd\u590d\u7684\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u9a8c\u8bc1\u635f\u5931\u548c\u66f4\u4f18\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u5f53\u6570\u636e\u800c\u4e0d\u662f\u8ba1\u7b97\u8d44\u6e90\u6210\u4e3a\u74f6\u9888\u65f6\uff0c\u6269\u6563\u6a21\u578b\u4e3a\u6807\u51c6\u7684\u81ea\u56de\u5f52\u8303\u5f0f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
