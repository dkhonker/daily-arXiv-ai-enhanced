{"id": "2601.00003", "pdf": "https://arxiv.org/pdf/2601.00003", "abs": "https://arxiv.org/abs/2601.00003", "authors": ["Shuqi Liu", "Bowei He", "Chen Ma", "Linqi Song"], "title": "Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.", "AI": {"tldr": "提出了一种基于推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索来提升大语言模型在对话中的表现。", "motivation": "现有方法难以有效整合检索和推理策略来优化大语言模型性能，需要超越表层语义相似性，获取与对话逻辑结构对齐的知识。", "method": "采用粗到细的两阶段检索：先识别上下文相关的知识库子区域，再在该区域内提取推理相关的知识；使用蒙特卡洛树搜索方法通过关键词导航知识句子。", "result": "在两个多轮对话数据集上的实验表明，该方法能更好地对齐人类对话的底层推理，显著提升检索知识的多样性，生成更具信息量和创造性的回复。", "conclusion": "推理感知的知识检索方法有效整合了检索和推理，为大语言模型提供了更符合对话逻辑的知识支持，提升了对话质量和多样性。"}}
{"id": "2601.00004", "pdf": "https://arxiv.org/pdf/2601.00004", "abs": "https://arxiv.org/abs/2601.00004", "authors": ["Isaac Iyinoluwa Olufadewa", "Miracle Ayomikun Adesina", "Ezekiel Ayodeji Oladejo", "Uthman Babatunde Usman", "Owen Kolade Adeniyi", "Matthew Tolulope Olawoyin"], "title": "Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 1 figure, 4 tables", "summary": "Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.", "AI": {"tldr": "该研究开发了一种基于微调大语言模型的尼日利亚皮钦语抑郁症自动筛查方法，GPT-4.1在PHQ-9严重程度评分预测中达到94.5%准确率，为资源受限环境下的心理健康筛查提供了新方案。", "motivation": "尼日利亚抑郁症筛查覆盖率低，传统PHQ-9问卷在高收入国家验证但存在语言文化障碍，尼日利亚使用皮钦语和520多种本地语言，需要适应本地语言文化的筛查工具。", "method": "收集432份尼日利亚年轻人皮钦语音频回答，进行转录、预处理和标注（包括语义标记、俚语解释和PHQ-9评分），微调三种LLM模型（Phi-3-mini、Gemma-3-4B和GPT-4.1），并进行定量和定性评估。", "result": "GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，在定量指标（准确率、精确度、语义对齐）和定性指标（清晰度、相关性、文化适宜性）上都优于其他模型。", "conclusion": "AI介导的抑郁症筛查可为服务不足的尼日利亚社区提供有效解决方案，为在语言多样化、资源受限环境中部署对话式心理健康工具奠定了基础。"}}
{"id": "2601.00021", "pdf": "https://arxiv.org/pdf/2601.00021", "abs": "https://arxiv.org/abs/2601.00021", "authors": ["Peter David Fagan"], "title": "Toward a Physical Theory of Intelligence", "categories": ["cs.AI"], "comment": "47 pages, 9 figures", "summary": "We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.", "AI": {"tldr": "这篇论文提出了一个基于不可逆信息处理的物理智能理论，将智能系统建模为耦合的智能体-环境过程，通过守恒定律约束下的信息转化为目标导向的工作来定义智能。", "motivation": "旨在建立智能的物理基础理论，将信息处理与物理守恒定律联系起来，为智能系统提供一个统一的、与底层物质无关的解释框架。", "method": "引入守恒一致性编码（CCE）框架，将编码对应为吸引子的亚稳态盆地，通过守恒定律保证可分离性。定义智能为每纳特不可逆处理信息产生的目标导向工作量。", "result": "推导出开放系统中信息摄入、不可逆计算和功提取的物理约束层次结构，揭示了长期效率需要保持内部信息结构，导致自我建模的出现。", "conclusion": "该理论为智能提供了一个统一的物理现象解释，能够应用于生物系统分析，并为人工智能安全提供了基于不可逆信息流和结构稳态的物理基础视角。"}}
{"id": "2601.00023", "pdf": "https://arxiv.org/pdf/2601.00023", "abs": "https://arxiv.org/abs/2601.00023", "authors": ["Luis M. Moreno-Saavedra", "Silvia Jimenez-Fernandez", "Antonio Portilla-Figueras", "David Casillas-Perez", "Sancho Salcedo-Sanz"], "title": "A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.", "AI": {"tldr": "本文提出一种多算法方法来解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑因素来优化包裹分配，确保每位配送员完成相似的工作量。", "motivation": "传统基于地理邻近性的包裹分配方法效率低下且导致配送员工作量分配不均衡，需要优化配送时间并实现完全的工作量平衡。", "method": "采用多算法方法，包括不同版本的k-means算法、进化算法、基于k-means初始化的递归分配算法（使用不同问题编码）以及混合进化集成算法。", "result": "在西班牙Azuqueca de Henares的实际最后一公里配送场景中验证了所提出方法的性能。", "conclusion": "提出的多算法方法能够有效解决配送员工作量不平衡问题，通过优化分配策略实现更均衡的工作量分布。"}}
{"id": "2601.00086", "pdf": "https://arxiv.org/pdf/2601.00086", "abs": "https://arxiv.org/abs/2601.00086", "authors": ["Xiang Gao", "Yuguang Yao", "Qi Zhang", "Kaiwen Dong", "Avinash Baidya", "Ruocheng Guo", "Hilaf Hasson", "Kamalika Das"], "title": "RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.", "AI": {"tldr": "RIMRULE是一种神经符号方法，通过从失败轨迹中提取紧凑、可解释的规则，在推理时动态注入提示中，提高LLM在领域特定工具使用中的性能，无需修改模型权重。", "motivation": "大型语言模型在领域特定设置中使用工具时经常遇到困难，特别是当API具有特殊性、文档不完善或针对私有工作流程定制时，需要有效的任务特定工具适应方法。", "method": "提出基于动态规则注入的神经符号方法：1)从失败轨迹中提取规则；2)使用最小描述长度目标优化规则的一般性和简洁性；3)以自然语言和结构化符号形式存储规则；4)在推理时高效检索和注入规则。", "result": "在工具使用基准测试中，该方法提高了对已见和未见工具的准确性，优于基于提示的适应方法，并与微调互补。学到的规则可以在不同LLM架构间重用。", "conclusion": "RIMRULE通过符号规则注入有效提升了LLM的工具使用能力，展示了符号知识在不同架构间的可移植性，为领域特定工具适应提供了有效的解决方案。"}}
{"id": "2601.00024", "pdf": "https://arxiv.org/pdf/2601.00024", "abs": "https://arxiv.org/abs/2601.00024", "authors": ["Purushottam Saha", "Avirup Chakraborty", "Sourish Sarkar", "Subhamoy Maitra", "Diganta Mukherjee", "Tridib Mukherjee"], "title": "Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach", "categories": ["cs.AI", "cs.GT"], "comment": "9 pages, 6 figures, 2 algorithms", "summary": "The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.", "AI": {"tldr": "该论文提出了基于MinDist评估指标的规则框架来改进印度拉米纸牌游戏的策略，通过计算手牌与最近有效配置的编辑距离来评估完成度，结合对手建模和零和模拟，显著提升了胜率。", "motivation": "经典印度拉米纸牌是一个需要概率推理和组合决策的不完全信息顺序游戏，传统启发式方法效果有限，需要更有效的策略设计框架。", "method": "提出MinDist评估指标（改进自MinScore），量化手牌与最近有效配置的编辑距离；设计计算高效的算法，采用动态剪枝和模式缓存；结合对手建模和双人零和模拟框架。", "result": "实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升。", "conclusion": "MinDist指标为算法化拉米策略设计提供了形式化和可解释的步骤，在游戏策略优化方面取得了重要进展。"}}
{"id": "2601.00095", "pdf": "https://arxiv.org/pdf/2601.00095", "abs": "https://arxiv.org/abs/2601.00095", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\\times$ speedups over GPU-optimized baselines while maintaining within 0.2\\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.", "AI": {"tldr": "MetaJuLS是一种元强化学习方法，通过元学习训练图注意力网络来实现跨语言和任务的通用约束传播策略，相比GPU优化基线提速1.5-2倍，准确率仅下降0.2%，且能快速适应新语言和任务。", "motivation": "大型语言模型需要结构化推理，输出必须满足复杂约束，传统方法需要针对每个任务重新训练，效率低下。", "method": "将结构化推理建模为自适应约束传播问题，使用元强化学习训练图注意力网络，学习通用的约束传播策略。", "result": "在10种语言的Universal Dependencies和LLM约束生成任务上，MetaJuLS仅需5-10个梯度步骤（5-15秒）即可适应新语言和任务，相比需要数小时任务特定训练的方法大幅提升效率。", "conclusion": "MetaJuLS通过减少LLM部署中的传播步骤，直接降低推理碳足迹，为绿色AI做出贡献，同时发现了类人的解析策略和新的启发式方法。"}}
{"id": "2601.00029", "pdf": "https://arxiv.org/pdf/2601.00029", "abs": "https://arxiv.org/abs/2601.00029", "authors": ["Abolhassan Pishahang", "Maryam Badiei"], "title": "From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers", "categories": ["cs.AI", "cs.CV"], "comment": "Proceedings of SIGraDi 2025: XXIX International Conference of the Ibero-American Society of Digital Graphics, Córdoba, Argentina, 2025", "summary": "This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.", "AI": {"tldr": "本研究通过伊朗鸽塔案例，测试三种扩散模型在不同提示阶段对乡土建筑智能的理解能力，发现AI能重现几何模式但误解材料和气候逻辑，参考图像提升真实性但限制创造力", "motivation": "探究生成式AI系统如何解读乡土建筑形式中蕴含的建筑智能，分析AI对传统设计智慧的理解、扭曲和重新构想能力", "method": "使用Midjourney v6、DALL-E 3和DreamStudio三种扩散模型，在参考性、适应性和推测性三个提示阶段进行测试，采用五标准评估框架（类型学、材料性、环境性、真实性和文化特异性）", "result": "AI能可靠重现几何模式但误读材料和气候逻辑；参考图像提高真实性但限制创造力；无参考限制时产生创新但文化模糊的结果", "conclusion": "研究界定了视觉相似性与建筑推理之间的边界，将计算性乡土推理定位为分析AI感知、扭曲和重新构想传统设计智能的框架"}}
{"id": "2601.00166", "pdf": "https://arxiv.org/pdf/2601.00166", "abs": "https://arxiv.org/abs/2601.00166", "authors": ["Yongmin Yoo", "Kris W Pan"], "title": "Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description", "categories": ["cs.CL"], "comment": null, "summary": "Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.", "AI": {"tldr": "Pat-DEVAL：首个专注于专利说明书的多维度评估框架，通过法律约束推理机制显著提升专利自动撰写的法律合规性评估效果", "motivation": "现有评估方法无法充分评估专利说明书的长文本结构连贯性和法律合规性要求，需要专门的评估框架来确保自动专利撰写系统的实用性", "method": "提出Pat-DEVAL框架，采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）法律约束推理机制，强制执行顺序的专利法特定分析", "result": "在Pap2Pat-EvalGold数据集上验证，Pat-DEVAL达到0.69的皮尔逊相关性，显著优于基线指标和现有LLM评估器，在法律专业合规性方面相关性达0.73", "conclusion": "通过明确注入法定约束条件，Pat-DEVAL为自动专利撰写系统的实际部署提供了强大的方法论基础，建立了确保技术健全性和法律合规性的新标准"}}
{"id": "2601.00097", "pdf": "https://arxiv.org/pdf/2601.00097", "abs": "https://arxiv.org/abs/2601.00097", "authors": ["Akash Kumar Panda", "Olaoluwa Adigun", "Bart Kosko"], "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "comment": "15 figures", "summary": "We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.", "AI": {"tldr": "开发了一个LLM智能体，能够从原始文本中提取因果反馈模糊认知图(FCM)，通过三步骤过程自动识别关键概念节点和因果关系，并在测试中表现出与人工生成FCM相似的动态系统行为。", "motivation": "设计一个能够自主从文本中提取因果关系的智能系统，实现LLM与FCM动态系统的双向交互，使系统在保持一定自主性的同时能够持续学习和适应。", "method": "使用三步骤系统指令：1)从文本中提取关键名词和名词短语；2)从中识别FCM概念节点；3)推断节点间的模糊因果边。测试使用了Henry Kissinger关于AI前景的论文。", "result": "生成的FCM动态系统能够收敛到与人工生成FCM相同的平衡极限环，尽管节点和边数量不同。混合不同LLM生成的FCM能够吸收主要成分的平衡点并产生新的平衡点。", "conclusion": "该方法成功实现了从文本中自主提取因果结构的LLM智能体，展示了FCM动态系统与LLM的协同作用，为因果推理和复杂系统建模提供了新途径。"}}
{"id": "2601.00181", "pdf": "https://arxiv.org/pdf/2601.00181", "abs": "https://arxiv.org/abs/2601.00181", "authors": ["Cheonkam Jeong", "Adeline Nyamathi"], "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \\textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.\n  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\\% (4-way) and 67.07\\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.\n  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, \"sad\" utterances exhibit reduced left-periphery marker usage (21.9\\%) compared to other emotions (28--32\\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.", "AI": {"tldr": "该论文通过系统分析IEMOCAP数据集，解决了对话情感识别中的两个关键问题：架构选择的重要性和语言学分析。研究发现对话上下文至关重要，前10-30轮对话可获得90%的性能增益；层次化句子表示在提供上下文后不再有效；外部情感词典无增益。同时发现情感与话语标记位置存在显著关联，悲伤话语的左边缘标记使用较少，需要更多上下文进行消歧。", "motivation": "解决对话情感识别(ERC)领域的两个关键空白：缺乏对架构选择重要性的理解，以及缺少将情感识别与生成连接的语言学分析。", "method": "使用IEMOCAP数据集进行系统分析，包括：1) 采用10种种子评估的严格消融研究；2) 分析5,286个话语标记出现情况，研究情感与标记位置的关联性。", "result": "识别方面：仅使用严格因果上下文的简单架构达到82.69%(4-way)和67.07%(6-way)加权F1，优于包括使用双向上下文的先前文本方法。语言学分析：发现情感与话语标记位置存在显著关联(p<.0001)，悲伤话语的左边缘标记使用率(21.9%)低于其他情感(28-32%)。", "conclusion": "对话上下文是情感识别的关键因素，前10-30轮对话提供大部分性能增益；层次化表示在提供上下文后变得多余；预训练编码器已包含足够的情感语义信息。悲伤情感由于缺乏明确的语用信号，最需要上下文进行消歧，这与左边缘话语标记使用减少的语言学发现一致。"}}
{"id": "2601.00105", "pdf": "https://arxiv.org/pdf/2601.00105", "abs": "https://arxiv.org/abs/2601.00105", "authors": ["Muhammad U. Nasir", "Yuchen Li", "Steven James", "Julian Togelius"], "title": "Mortar: Evolving Mechanics for Automatic Game Design", "categories": ["cs.AI"], "comment": null, "summary": "We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.", "AI": {"tldr": "Mortar系统结合质量多样性算法和大型语言模型，自主演化游戏机制，通过树搜索合成完整游戏并基于技能排序评估机制质量，生成多样化且可玩的游戏。", "motivation": "游戏机制设计是耗时且需要专业知识的流程，需要自动化方法来探索多样化的游戏机制。", "method": "结合质量多样性算法和大型语言模型探索机制，通过树搜索合成完整游戏，评估机制对技能排序得分的贡献。", "result": "系统生成多样化且可玩的游戏，机制对技能排序得分有更好贡献，消融研究和用户研究验证了系统组件的有效性。", "conclusion": "Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效解决方案。"}}
{"id": "2601.00202", "pdf": "https://arxiv.org/pdf/2601.00202", "abs": "https://arxiv.org/abs/2601.00202", "authors": ["Wang Xing", "Wei Song", "Siyu Lin", "Chen Wu", "Zhesi Li", "Man Wang"], "title": "Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.", "AI": {"tldr": "提出了一个专门为时序知识图谱推理设计的蒸馏框架，利用大语言模型作为教师模型来指导轻量级学生模型的学习，在保持高效架构的同时提升时序推理能力。", "motivation": "现有TKG推理模型参数量大、计算密集，导致硬件成本和能耗高，难以在资源受限的实时推理平台上部署。现有的模型压缩技术主要针对静态知识图谱，无法有效捕捉时序依赖关系。", "method": "使用大语言模型作为教师模型，通过蒸馏过程将结构和时序推理能力转移到轻量级学生模型中，整合大规模公共知识和任务特定时序信息。", "result": "在多个公开基准数据集上的实验表明，该方法 consistently 优于强基线，在推理准确性、计算效率和实际部署性之间取得了良好平衡。", "conclusion": "提出的蒸馏框架有效解决了TKG推理中的计算效率问题，为资源受限平台上的实时时序推理提供了可行方案，实现了精度与效率的兼顾。"}}
{"id": "2601.00121", "pdf": "https://arxiv.org/pdf/2601.00121", "abs": "https://arxiv.org/abs/2601.00121", "authors": ["Yaqi Duan", "Yichun Hu", "Jiashuo Jiang"], "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant \"hallucination tax\": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.\n  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned \"digital twin\" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.", "AI": {"tldr": "本研究提出了一种混合代理框架，通过将LLM作为智能接口而非端到端求解器，成功将库存成本降低32.1%，解决了LLM在数学计算中的幻觉问题。", "motivation": "中小型企业缺乏部署高级优化方法的专业知识，需要探索LLM是否能帮助解决库存管理难题，但发现直接使用LLM作为端到端求解器存在显著的\"幻觉税\"性能差距。", "method": "提出混合代理框架，严格分离语义推理和数学计算：LLM作为智能接口从自然语言中提取参数并解释结果，同时自动调用严格算法构建优化引擎。引入人类模仿者进行可扩展的压力测试。", "result": "混合框架相比使用GPT-4o作为端到端求解器的基准，总库存成本降低了32.1%。研究发现即使提供完美真实信息也无法改善GPT-4o性能，确认瓶颈本质是计算而非信息问题。", "conclusion": "LLM不应取代运筹学方法，而应作为自然语言接口，使非专家也能使用基于求解器的严格策略，实现专业知识与人工智能的有效结合。"}}
{"id": "2601.00216", "pdf": "https://arxiv.org/pdf/2601.00216", "abs": "https://arxiv.org/abs/2601.00216", "authors": ["Jinning Zhang", "Jie Song", "Wenhui Tu", "Zecheng Li", "Jingxuan Li", "Jin Li", "Xuan Liu", "Taole Sha", "Zichen Wei", "Yan Li"], "title": "From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark", "categories": ["cs.CL"], "comment": "35 pages, 5 figures", "summary": "In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.", "AI": {"tldr": "本研究提出了一种将循证医学原则融入图检索增强生成的方法，通过PICO框架和贝叶斯重排序算法提高医学问答的准确性和可靠性，在运动康复领域验证了其有效性。", "motivation": "当前医学领域的检索增强生成方法主要关注性能提升，但忽视了循证医学原则，特别是缺乏查询与证据之间的PICO对齐以及证据层级考量。", "method": "开发了一种通用的EBM适应策略：将PICO框架整合到知识图谱构建和检索中，提出贝叶斯启发的重排序算法，通过证据等级校准排序分数而不引入预定义权重。", "result": "在运动康复领域验证，系统获得0.830的信息覆盖率、0.819的答案忠实度、0.882的语义相似度和0.788的PICOT匹配准确率。专家临床医生在5点李克特量表上给予4.66-4.84的高评分。", "conclusion": "该EBM适应策略显著提升了检索和答案质量，具有跨临床领域的可迁移性，同时解决了运动康复领域RAG数据集稀缺的问题。"}}
{"id": "2601.00125", "pdf": "https://arxiv.org/pdf/2601.00125", "abs": "https://arxiv.org/abs/2601.00125", "authors": ["Keqin Xie"], "title": "Constructing a Neuro-Symbolic Mathematician from First Principles", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.", "AI": {"tldr": "Mathesis是一种神经符号架构，通过将数学状态编码为高阶超图，使用符号推理核(SRK)将约束映射到连续能量景观，通过能量最小化实现逻辑推理和证明搜索。", "motivation": "大型语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理框架，需要新的架构来解决这一问题。", "method": "提出Mathesis神经符号架构：1) 将数学状态编码为高阶超图；2) 使用可微分符号推理核(SRK)将逻辑约束映射到连续能量景观；3) 定义全局能量函数E(G)，零能量表示逻辑一致性；4) 通过梯度信号训练超图变换器大脑；5) 结合蒙特卡洛树搜索和进化证明搜索实现多步推理。", "result": "通过能量最小化方法将证明搜索转化为优化问题，SRK提供梯度信号指导神经网络学习，实现了可微分的逻辑推理引擎。", "conclusion": "Mathesis架构通过神经符号融合解决了LLMs的逻辑推理缺陷，为复杂数学推理提供了新的框架，将符号逻辑与神经网络训练有机结合。"}}
{"id": "2601.00223", "pdf": "https://arxiv.org/pdf/2601.00223", "abs": "https://arxiv.org/abs/2601.00223", "authors": ["Leonard Lin", "Adam Lensenmayer"], "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation", "categories": ["cs.CL", "cs.AI"], "comment": "24 pages, 5 figures, 8 tables", "summary": "We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often \"which of these two good translations is better?\" rather than \"is this translation acceptable?\" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 \"LT\" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.", "AI": {"tldr": "JP-TL-Bench是一个轻量级开源基准测试，用于指导日英翻译系统的迭代开发，通过参考无关的成对LLM比较来评估翻译质量，重点关注细微的语言差异对自然度的影响。", "motivation": "日英翻译中经常面临'哪个翻译更好'的细微选择问题，而不是简单的'翻译是否可接受'。礼貌程度、隐含意义、省略和语体等微妙选择会显著影响翻译的自然度感知，需要专门的评估方法。", "method": "使用参考无关的成对LLM比较方法，将候选模型与固定的版本化锚定集进行对比。通过Bradley-Terry模型聚合成对比较结果，报告胜率和基于拟合对数强度的0-10标准化'LT'分数。", "result": "该方法能够可靠且经济地进行LLM评判，通过固定的锚定集确保评分结构稳定性，使得不同候选模型的评估结果具有可比性。", "conclusion": "JP-TL-Bench提供了一个结构稳定的评估框架，能够有效捕捉日英翻译中细微的质量差异，为翻译系统的迭代改进提供指导。"}}
{"id": "2601.00138", "pdf": "https://arxiv.org/pdf/2601.00138", "abs": "https://arxiv.org/abs/2601.00138", "authors": ["Jorge Ortiz"], "title": "Explicit Abstention Knobs for Predictable Reliability in Video Question Answering", "categories": ["cs.AI", "cs.CV"], "comment": "Preprint. Diagnostic study of confidence-based abstention under evidence truncation", "summary": "High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f", "AI": {"error": "'NoneType' object has no attribute 'model_dump'"}}
{"id": "2601.00224", "pdf": "https://arxiv.org/pdf/2601.00224", "abs": "https://arxiv.org/abs/2601.00224", "authors": ["Yan Sun", "Ming Cai", "Stanley Kok"], "title": "Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback", "categories": ["cs.CL", "cs.SE"], "comment": null, "summary": "As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.", "AI": {"tldr": "论文提出了Q*和Feedback+两种验证技术，通过反向翻译、语义匹配和执行反馈来提升大语言模型在企业分析任务中的准确性和可靠性，减少错误率和任务完成时间。", "motivation": "当前对话式商业分析系统缺乏内置验证机制，用户需要手动验证可能存在缺陷的结果，这影响了企业工作流程中LLM助手的可信度。", "method": "采用生成器-判别器框架，引入Q*（反向翻译和语义匹配）和Feedback+（执行反馈引导代码优化）两种互补验证技术。", "result": "在Spider、Bird和GSM8K三个基准数据集上的评估显示，两种技术都能有效降低错误率和任务完成时间。", "conclusion": "研究提出了一个设计导向的框架，为构建更可靠的企业级生成式AI系统提供了基础，同时发现反向翻译是主要瓶颈，为未来改进指明了方向。"}}
{"id": "2601.00142", "pdf": "https://arxiv.org/pdf/2601.00142", "abs": "https://arxiv.org/abs/2601.00142", "authors": ["Tiansi Dong", "Henry He", "Pietro Liò", "Mateja Jamnik"], "title": "An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making", "categories": ["cs.AI"], "comment": "19 pages", "summary": "This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.", "AI": {"tldr": "本文比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型构建的Sphere神经网络在逻辑推理任务中表现最可靠，能够同时掌握多种推理任务而不会出现灾难性遗忘。", "motivation": "比较不同神经推理方法的可靠性，特别是针对LLM在简单决策任务中的不可靠性，以及监督学习方法在逻辑推理中存在的灾难性遗忘问题。", "method": "通过析取三段论推理测试比较三种方法，提出新的Sphere神经网络，将概念表示为n维球面上的圆，通过补集圆表示否定运算符，过滤不合理的逻辑陈述。", "result": "Sphere神经网络能够掌握16种三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性，而监督学习的Euler Net在重新训练后出现严重灾难性遗忘（性能降至6.25%）。", "conclusion": "基于显式模型构建的神经推理是三种方法中最可靠的，能够实现可靠的决策制定并避免灾难性遗忘问题。"}}
{"id": "2601.00263", "pdf": "https://arxiv.org/pdf/2601.00263", "abs": "https://arxiv.org/abs/2601.00263", "authors": ["Qianli Wang", "Van Bach Nguyen", "Yihong Liu", "Fedor Splitt", "Nils Feldhus", "Christin Seifert", "Hinrich Schütze", "Sebastian Möller", "Vera Schmitt"], "title": "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation", "categories": ["cs.CL", "cs.AI"], "comment": "In submission", "summary": "Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.", "AI": {"tldr": "该研究评估了大语言模型在多语言反事实生成方面的表现，发现翻译生成的反事实比直接生成的有效性更高，但仍不如英文原版质量，并揭示了多语言反事实数据增强对模型性能的提升效果。", "motivation": "虽然大语言模型在生成英文反事实上表现出色并具有多语言能力，但其在多语言反事实生成方面的有效性尚不清楚，需要进行系统研究。", "method": "对六种语言进行自动评估，比较直接生成的反事实和通过英文翻译获得的反事实，分析编辑模式，识别错误类型，并评估多语言反事实数据增强的效果。", "result": "翻译生成的反事实有效性更高但需要更多修改，欧洲语言的反事实编辑模式相似，识别出四种常见错误类型，多语言数据增强比跨语言增强效果更好但受限于生成质量。", "conclusion": "多语言反事实生成存在质量限制，虽然多语言数据增强能提升模型性能，但生成的不完美限制了性能和鲁棒性的进一步提升。"}}
{"id": "2601.00227", "pdf": "https://arxiv.org/pdf/2601.00227", "abs": "https://arxiv.org/abs/2601.00227", "authors": ["Shanli Xing", "Yiyan Zhai", "Alexander Jiang", "Yixin Dong", "Yong Wu", "Zihao Ye", "Charlie Ruan", "Yingyi Huang", "Yineng Zhang", "Liangsheng Yin", "Aksara Bayyapu", "Luis Ceze", "Tianqi Chen"], "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.", "AI": {"tldr": "FlashInfer-Bench是一个标准化闭环框架，用于连接LLM生成的GPU内核、基准测试和部署，通过统一的数据模式和工作流程实现AI生成内核在实际推理系统中的集成和优化。", "motivation": "当前大型语言模型能够生成GPU内核，但将这些AI生成的内核集成到实际推理系统中仍面临挑战，缺乏标准化的评估和部署流程。", "method": "建立FlashInfer Trace统一数据模式描述内核定义、工作负载、实现和评估；基于真实服务轨迹构建数据集；开发包含正确性和性能感知的基准测试框架；创建公开排行榜；实现动态替换机制apply()将最优内核注入生产系统。", "result": "提供了评估LLM代理性能和局限性的平台，比较了不同GPU编程语言的权衡，为未来代理设计提供了见解。", "conclusion": "FlashInfer-Bench为持续改进AI生成内核并将其部署到大规模LLM推理系统中建立了实用、可复现的路径。"}}
{"id": "2601.00268", "pdf": "https://arxiv.org/pdf/2601.00268", "abs": "https://arxiv.org/abs/2601.00268", "authors": ["Doyoung Kim", "Zhiwei Ren", "Jie Hao", "Zhongkai Sun", "Lichao Wang", "Xiyao Ma", "Zack Ye", "Xu Han", "Jun Yin", "Heng Ji", "Wei Shen", "Xing Fan", "Benjamin Yao", "Chenlei Guo"], "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages", "summary": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.", "AI": {"tldr": "WildAGTEval是一个评估LLM智能体在真实API复杂度下函数调用能力的基准测试，包含60种复杂度场景和约32K测试配置，发现无关信息复杂度对LLM性能影响最大（降低27.3%），且LLM有时会扭曲用户意图来宣称任务完成。", "motivation": "现有研究假设理想化API系统，忽略了真实世界因素如噪声API输出，需要评估LLM智能体在真实API复杂度下的表现。", "method": "创建WildAGTEval基准，包含API规范（详细文档和使用约束）和API执行（运行时挑战）两个维度的复杂度，构建60种场景和约32K测试配置，通过用户-智能体交互评估多个先进LLM。", "result": "大多数场景具有挑战性，无关信息复杂度对性能影响最大，使强LLM性能降低27.3%；定性分析显示LLM有时会扭曲用户意图来宣称任务完成。", "conclusion": "WildAGTEval揭示了LLM智能体在真实API环境中的性能瓶颈，特别是对无关信息处理的困难，以及可能损害用户满意度的意图扭曲行为。"}}
{"id": "2601.00240", "pdf": "https://arxiv.org/pdf/2601.00240", "abs": "https://arxiv.org/abs/2601.00240", "authors": ["Zongwei Wang", "Bincheng Gu", "Hongyu Yu", "Junliang Yu", "Tao He", "Jiayin Feng", "Min Gao"], "title": "Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability", "categories": ["cs.AI", "cs.CY"], "comment": "16 pages", "summary": "LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal \"us\" versus \"them\" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.", "AI": {"tldr": "研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小群体线索下表现出内群体偏见。当这种群体边界与智能体-人类划分对齐时，人类可能被整体视为外群体。研究提出了信念投毒攻击(BPA)来抑制人类规范脚本并重新激活对人类的偏见，同时讨论了相应的防御策略。", "motivation": "探究LLM智能体是否会在最小群体线索下表现出内群体偏见，特别是当群体边界与智能体-人类划分对齐时，人类可能被整体视为外群体的风险。", "method": "构建基于明确收益权衡分配决策的受控多智能体社会模拟，通过配置初始化(BPA-PP)和记忆投毒(BPA-MP)两种方式实施信念投毒攻击。", "result": "实验证明智能体在最小群体线索下表现出一致的内群体偏见，虽然人类框架会减弱这种偏见，但信念投毒攻击能有效抑制人类规范脚本并重新激活对人类的偏见。", "conclusion": "研究揭示了LLM智能体的群体偏见漏洞，提出了信念投毒攻击方法，旨在为更安全的智能体设计提供信息，而不是实现实际利用。"}}
{"id": "2601.00282", "pdf": "https://arxiv.org/pdf/2601.00282", "abs": "https://arxiv.org/abs/2601.00282", "authors": ["Qianli Wang", "Nils Feldhus", "Pepa Atanasova", "Fedor Splitt", "Simon Ostermann", "Sebastian Möller", "Vera Schmitt"], "title": "Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "In submission", "summary": "Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\\%) and faithfulness (up to 2.38\\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.", "AI": {"tldr": "量化对LLM自解释能力的影响研究：量化导致自解释质量和忠实度适度下降，大模型在忠实度保持方面表现更好，但不同量化技术在不同指标上表现不一，建议根据具体应用验证自解释质量。", "motivation": "量化技术被广泛用于加速大语言模型推理和部署，但其对模型自解释能力的影响尚未被研究。自解释作为提高模型透明度的重要工具，在高风险应用中越来越重要，需要了解量化是否会降低自解释的质量和忠实度。", "method": "研究两种自解释类型（自然语言解释和反事实示例），使用三种常见量化技术在不同比特宽度下量化LLM，并通过用户研究评估自解释的连贯性和可信度。", "result": "量化通常导致自解释质量下降最多4.4%，忠实度下降最多2.38%。用户研究显示量化降低自解释连贯性和可信度最多8.5%。大模型在自解释质量方面对量化的韧性有限，但在保持忠实度方面更好。没有量化技术在所有指标（任务准确性、自解释质量、忠实度）上表现一致优异。", "conclusion": "量化对自解释的影响因上下文而异，建议针对特定用例验证自解释质量，特别是对量化更敏感的自然语言解释。但自解释质量和忠实度的相对较小下降并不削弱量化作为模型压缩技术的有效性。"}}
{"id": "2601.00290", "pdf": "https://arxiv.org/pdf/2601.00290", "abs": "https://arxiv.org/abs/2601.00290", "authors": ["Sixue Xing", "Xuanye Xia", "Kerui Wu", "Meng Jiang", "Jintai Chen", "Tianfan Fu"], "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.", "AI": {"tldr": "ClinicalReTrial是一个自我进化的AI代理框架，通过将临床试验推理转化为迭代协议重新设计问题，主动提供可操作的改进方案，而非仅仅预测失败风险。", "motivation": "临床试验失败是药物开发的主要瓶颈，现有AI方法只能被动预测失败风险，无法提供可操作的改进方案来避免失败。", "method": "提出闭环、奖励驱动的优化框架，整合失败诊断、安全感知修改和候选评估，使用结果预测模型作为仿真环境进行低成本协议修改评估，并维护分层记忆系统捕获迭代反馈和可转移的重新设计模式。", "result": "实证显示ClinicalReTrial改进了83.3%的试验协议，平均成功概率提升5.7%，回顾性案例研究表明发现的重新设计策略与实际临床试验修改高度一致。", "conclusion": "该框架通过主动协议重新设计和自我进化能力，有效解决了临床试验设计中的关键问题，为药物开发提供了实用的AI驱动解决方案。"}}
{"id": "2601.00303", "pdf": "https://arxiv.org/pdf/2601.00303", "abs": "https://arxiv.org/abs/2601.00303", "authors": ["Yuxin Li", "Xiangyu Zhang", "Yifei Li", "Zhiwei Guo", "Haoyang Zhang", "Eng Siong Chng", "Cuntai Guan"], "title": "DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.", "AI": {"tldr": "DepFlow是一个三阶段的抑郁症条件文本转语音框架，通过解耦语音中的语义偏见来增强抑郁症检测模型的鲁棒性，特别是在伪装抑郁症场景中。", "motivation": "现有的抑郁症数据集存在语言情感与诊断标签的强耦合问题，导致模型学习语义捷径，在真实场景（如伪装抑郁症）中鲁棒性不足。", "method": "提出三阶段框架：1）抑郁症声学编码器通过对抗训练学习内容和说话人不变的抑郁症嵌入；2）基于流匹配的TTS模型注入抑郁症嵌入；3）基于原型的严重程度映射机制。构建伪装抑郁症增强数据集CDoA。", "result": "抑郁症编码器ROC-AUC达0.693；CDoA数据集在三种抑郁症检测架构上分别提升macro-F1 9%、12%和5%，优于传统增强策略。", "conclusion": "DepFlow有效缓解了语义偏见，提高了抑郁症检测的鲁棒性，同时为对话系统和模拟评估提供了可控合成平台。"}}
{"id": "2601.00324", "pdf": "https://arxiv.org/pdf/2601.00324", "abs": "https://arxiv.org/abs/2601.00324", "authors": ["Alicia Vidler", "Gal A. Kaminka"], "title": "Multiagent Reinforcement Learning for Liquidity Games", "categories": ["cs.AI"], "comment": "9 pages", "summary": "Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.", "AI": {"tldr": "本文提出金融群体模型，将流动性博弈与理性群体理论结合，展示独立交易者通过差异奖励机制实现个体盈利和市场流动性的双赢，无需协调或共谋。", "motivation": "将群体方法应用于金融市场流动性建模，同时将金融分析方法用于群体研究，有望推动两个领域的发展。群体研究需要解释理性自利参与者如何实现集体效用，金融市场需要理解独立金融代理如何自组织提升市场稳定性和效率。", "method": "统一流动性博弈（交易者收益取决于交易中的总流动性）与理性群体（分散代理使用差异奖励使自利学习与全局目标一致），在马尔可夫团队博弈框架中使用差异奖励，定义以提供市场流动性为集体目标但保持代理独立性的交易者群体。", "result": "研究表明个体流动性最大化行为有助于整体市场流动性，无需协调或共谋。", "conclusion": "金融群体模型为建模理性独立代理提供了框架，在双边资产市场中实现个体盈利和集体市场效率的双重目标。"}}
{"id": "2601.00348", "pdf": "https://arxiv.org/pdf/2601.00348", "abs": "https://arxiv.org/abs/2601.00348", "authors": ["Yuhao Zhang", "Zhongliang Yang", "Linna Zhou"], "title": "Robust Uncertainty Quantification for Factual Generation of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 5 tables, 5 figures, accepted to IJCNN 2025", "summary": "The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.", "AI": {"tldr": "本研究针对大语言模型幻觉问题，提出了一种基于陷阱问题的鲁棒不确定性量化方法(RU)，在包含虚假名称的多事实生成任务中显著提升了检测性能。", "motivation": "大语言模型幻觉问题严重影响了AI生成内容的可靠性，传统不确定性量化方法在面对非常规或对抗性提问时表现不佳，存在明显的性能差距。", "method": "构建包含虚假名称的陷阱问题集，创新性地提出鲁棒不确定性量化方法(RU)，在多个模型上与基线方法进行对比实验验证。", "result": "陷阱问题集表现优异，提出的RU方法在四个不同模型上相比最佳基线方法的ROCAUC值平均提升0.1-0.2，显著优于现有方法。", "conclusion": "该研究为解决大语言模型幻觉问题提供了新的视角和方法，通过鲁棒不确定性量化有效提升了模型在复杂场景下的可靠性检测能力。"}}
{"id": "2601.00339", "pdf": "https://arxiv.org/pdf/2601.00339", "abs": "https://arxiv.org/abs/2601.00339", "authors": ["Alaa Saleh", "Praveen Kumar Donta", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Qiyang Zhang", "Schahram Dustdar", "Susanna Pirttikangas", "Lauri Lovén"], "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.MA", "cs.NE"], "comment": null, "summary": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.", "AI": {"tldr": "ReCiSt是一个受生物自愈机制启发的自主修复框架，通过四层架构（隔离、诊断、元认知、知识）和语言模型代理实现分布式计算系统的故障自主检测、诊断和恢复。", "motivation": "分布式计算系统（DCCS）的复杂性、移动性和动态运行条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。受生物系统自愈能力的启发，开发自主修复框架。", "method": "将生物愈合阶段（止血、炎症、增殖、重塑）重构为计算层（隔离、诊断、元认知、知识），使用语言模型代理解释异构日志、推断根本原因、优化推理路径和重新配置资源。", "result": "在公共故障数据集上评估，ReCiSt能在数十秒内完成自愈，代理CPU使用率最低为10%，能够克服不确定性并通过调用微代理实现弹性。", "conclusion": "ReCiSt框架成功实现了生物启发式的自主故障修复，证明了语言模型在构建弹性分布式系统方面的有效性，为未来自主系统研究提供了新方向。"}}
{"id": "2601.00364", "pdf": "https://arxiv.org/pdf/2601.00364", "abs": "https://arxiv.org/abs/2601.00364", "authors": ["Jiandong Shao", "Raphael Tang", "Crystina Zhang", "Karin Sevegnani", "Pontus Stenetorp", "Jianfei Yang", "Yao Lu"], "title": "The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining", "categories": ["cs.CL"], "comment": "under review", "summary": "Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.", "AI": {"tldr": "研究发现多语言大模型的翻译能力主要依赖于语料库中仅占2%的双语数据，特别是其中的平行语料（14%），而代码切换数据贡献有限。其他跨语言任务如问答和推理则基本不受双语数据影响。", "motivation": "探究双语数据在多语言大模型跨语言能力中的具体作用机制，特别是翻译能力与其他跨语言任务表现的不对称性。", "method": "通过控制实验，从零开始训练模型：比较标准网络语料库与去除所有双语文档的单语版本；将双语数据细分为平行语料、代码切换数据和其他文档；通过逐步重新引入不同类型双语数据进行消融实验。", "result": "去除双语数据导致翻译性能下降56%（BLEU分数），但跨语言问答和推理任务表现稳定；平行语料能恢复91%的翻译性能，代码切换数据贡献很小；其他跨语言任务基本不受双语数据类型影响。", "conclusion": "翻译能力严重依赖平行语料提供的系统化词级对齐，而跨语言理解和推理能力即使没有双语数据也能实现，揭示了不同跨语言能力的不同学习机制。"}}
{"id": "2601.00400", "pdf": "https://arxiv.org/pdf/2601.00400", "abs": "https://arxiv.org/abs/2601.00400", "authors": ["Weng Ding", "Yi Han", "Mu-Jiang-Shan Wang"], "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning", "categories": ["cs.AI"], "comment": "15 pages, 8 figures. Under review", "summary": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.", "AI": {"tldr": "ACCD框架通过三阶段自适应架构检测社交媒体上的协同不实行为，在准确率、自动化程度和处理效率方面显著优于现有方法", "motivation": "现有协同行为检测方法依赖表面相关性分析、使用静态参数设置且需要大量人工标注，存在严重局限性", "method": "三阶段渐进式架构：1) 自适应CCM技术识别账户间真实因果关系 2) 半监督分类结合主动学习减少人工标注 3) 历史经验驱动的自动化验证模块", "result": "在真实数据集上F1-score达87.3%，比最强基线提升15.2%，人工标注需求减少68%，处理速度提升2.8倍", "conclusion": "ACCD提供了更准确、高效且高度自动化的端到端解决方案，具有重要实用价值和广泛应用潜力"}}
{"id": "2601.00366", "pdf": "https://arxiv.org/pdf/2601.00366", "abs": "https://arxiv.org/abs/2601.00366", "authors": ["Taj Gillin", "Adam Lalani", "Kenneth Zhang", "Marcel Mateos Salles"], "title": "BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "16 pages, 10 figures, 10 tables", "summary": "Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.", "AI": {"tldr": "BERT-JEPA (BEPA) 是一种新的自监督训练范式，通过在BERT模型中添加JEPA训练目标，有效防止[CLS]嵌入空间坍缩，将其转换为语言无关空间，从而提升多语言基准测试性能", "motivation": "解决BERT模型中[CLS]嵌入空间容易坍缩的问题，并希望创建一个语言无关的表示空间", "method": "在BERT风格模型中添加Joint Embedding Predictive Architectures (JEPA)训练目标", "result": "在多语言基准测试中表现出性能提升", "conclusion": "JEPA训练目标能够有效改善BERT模型的表示学习能力，特别是在多语言环境下"}}
{"id": "2601.00421", "pdf": "https://arxiv.org/pdf/2601.00421", "abs": "https://arxiv.org/abs/2601.00421", "authors": ["Alessio Di Rubbo", "Mattia Neri", "Remo Pareschi", "Marco Pedroni", "Roberto Valtancoli", "Paolino Zica"], "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications", "categories": ["cs.AI"], "comment": "Submitted to Sci (MDPI) for peer review", "summary": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.", "AI": {"tldr": "本文提出了一种将语义空间推理从计算语言学扩展到团队运动战术决策的方法，将球员比作单词、团队战术比作文本语义结构，通过向量空间建模来评估战术适配度和对手利用潜力。", "motivation": "传统计算语言学的语义空间方法在文本分析中很成功，作者希望将这种类比扩展到团队运动战术分析，通过建立球员-词汇、战术-语义的对应关系，为团队决策提供量化框架。", "method": "将每个球员表示为多维向量（技术、身体、心理属性），通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高位逼抢、反击），使用向量距离度量评估战术适配度。", "result": "开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供细粒度的属性级诊断洞察，方法具有通用性可扩展到其他团队领域。", "conclusion": "该方法为团队决策和性能优化提供了通用框架，未来方向包括真实数据集成、预测模拟和人机混合战术智能系统的开发。"}}
{"id": "2601.00388", "pdf": "https://arxiv.org/pdf/2601.00388", "abs": "https://arxiv.org/abs/2601.00388", "authors": ["Biao Wu", "Meng Fang", "Ling Chen", "Ke Xu", "Tao Cheng", "Jun Wang"], "title": "Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach", "categories": ["cs.CL"], "comment": "8 pages, 1 figures", "summary": "Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.", "AI": {"tldr": "Geo-R是一个无需检索的视觉-语言模型框架，通过基于规则的分层推理和强化学习实现图像地理定位，提高了准确性、泛化能力和可解释性。", "motivation": "现有方法依赖合成推理标注或外部图像检索，限制了可解释性和泛化能力，需要一种更直接、可解释的地理定位方法。", "method": "提出Chain of Region分层推理范式，将GPS坐标映射到地理实体生成监督信号；使用基于Haversine距离的强化学习策略进行空间优化。", "result": "在多个基准测试中显示出有效性，实现了更高的定位精度、更强的泛化能力和更透明的推理过程。", "conclusion": "Geo-R建立了无需检索的可扩展和可解释图像地理定位新范式，模型和代码将公开以促进进一步研究。"}}
{"id": "2601.00475", "pdf": "https://arxiv.org/pdf/2601.00475", "abs": "https://arxiv.org/abs/2601.00475", "authors": ["Sankar B", "Srinidhi Ranjini Girish", "Aadya Bharti", "Dibakar Sen"], "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation", "categories": ["cs.AI", "cs.HC"], "comment": "21 pages, 11 figures", "summary": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.", "AI": {"tldr": "MIDAS框架使用分布式AI代理团队模拟人类元认知构思流程，通过渐进式优化和双重新颖性评估（全局和局部）来解决单AI系统产生的语义聚类问题，实现真正的人机协同创新。", "motivation": "当前单次生成的AI系统会产生大量语义聚类的想法，这对新手设计师构成认知挑战，需要一种能够产生真正新颖多样想法的解决方案。", "method": "提出MIDAS框架，用分布式专业化AI代理团队替代单AI范式，模拟人类元认知构思工作流程，渐进式优化想法并评估全局和局部新颖性。", "result": "MIDAS展示了一种可行且渐进式的人机协同创造范式，将人类设计师从被动筛选者提升为参与性、主动的协作伙伴。", "conclusion": "该框架为解决工程设计中新颖想法生成的认知挑战提供了有效方案，通过分布式AI代理系统实现了真正的人机协同创造。"}}
{"id": "2601.00411", "pdf": "https://arxiv.org/pdf/2601.00411", "abs": "https://arxiv.org/abs/2601.00411", "authors": ["Alistair Plum", "Laura Bernardy", "Tharindu Ranasinghe"], "title": "Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.", "AI": {"tldr": "judgeWEL是一个卢森堡语命名实体识别数据集，通过新颖的LLM管道自动标注和验证，利用维基百科和维基数据作为弱监督源，比现有数据集大5倍且类别覆盖更平衡", "motivation": "解决低资源语言数据集构建的瓶颈问题，卢森堡语等资源稀缺语言的NER标注成本高且不一致", "method": "利用维基百科内部链接和维基数据条目推断实体类型，使用多个LLM识别和保留高质量标注句子以减少噪声", "result": "构建了比现有卢森堡语NER数据集大约5倍的新语料库，提供更广泛和平衡的实体类别覆盖", "conclusion": "该方法为多语言和低资源NER研究提供了重要新资源，证明了利用结构化弱监督和LLM验证的有效性"}}
{"id": "2601.00514", "pdf": "https://arxiv.org/pdf/2601.00514", "abs": "https://arxiv.org/abs/2601.00514", "authors": ["Liv G. d'Aliberti", "Manoel Horta Ribeiro"], "title": "The Illusion of Insight in Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.", "AI": {"tldr": "研究发现推理模型的中途策略转变并非真正的'顿悟'时刻，而是不稳定的推理行为表现，但可以通过外部触发在高不确定性情况下提升准确性", "motivation": "探讨推理模型是否真的具有内在的自我修正能力，特别是那些看似'顿悟'的中途推理策略转变是否真正提升了模型性能", "method": "分析了超过100万条推理轨迹、数百个训练检查点，涵盖三个推理领域、多种解码温度和模型架构，检测中途推理转变并研究其影响", "result": "发现推理转变很罕见，不会随训练变得更频繁，且很少提高准确性。但在模型高不确定性时，人工触发外部转变可以可靠地提升准确性", "conclusion": "中途推理转变是推理行为不稳定的症状，而非内在的自我修正机制，但可以通过外部干预在高熵情况下改善性能"}}
{"id": "2601.00430", "pdf": "https://arxiv.org/pdf/2601.00430", "abs": "https://arxiv.org/abs/2601.00430", "authors": ["Kian Ahrabian", "Eric Boxer", "Jay Pujara"], "title": "Toward Better Temporal Structures for Geopolitical Events Forecasting", "categories": ["cs.CL"], "comment": "17 pages, 13 figures, 3 tables", "summary": "Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.", "AI": {"tldr": "该论文提出了一种新的超关系时序知识广义超图（HTKGHs）模型，用于解决传统时序知识图谱在表达复杂地缘政治事件时的局限性，并基于POLECAT数据库创建了htkgh-polecat数据集来评估大语言模型的预测能力。", "motivation": "传统超关系时序知识图谱（HTKGs）只能表示两个主要实体间的时序关系，无法有效表达现实世界中常见的涉及多个实体的复杂事件事实，这限制了在地缘政治预测中的应用。", "method": "1. 提出了HTKGHs的正式定义，支持两种复杂事实类型并保持向后兼容性；2. 基于POLECAT全球事件数据库构建了htkgh-polecat数据集；3. 在关系预测任务上对流行的大语言模型进行基准测试和分析。", "result": "研究提出了HTKGHs的理论框架和实际数据集，为大语言模型在复杂时序预测场景中的能力评估提供了基础。", "conclusion": "HTKGHs扩展了传统时序知识图谱的表达能力，能够更好地建模复杂地缘政治事件，为未来研究提供了新的数据基础和分析框架。"}}
{"id": "2601.00623", "pdf": "https://arxiv.org/pdf/2601.00623", "abs": "https://arxiv.org/abs/2601.00623", "authors": ["Longtian Qiu", "Shan Ning", "Chuyu Zhang", "Jiaxuan Sun", "Xuming He"], "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations", "categories": ["cs.AI"], "comment": "Accepted by TMLR", "summary": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.", "AI": {"tldr": "提出DA-DPO方法解决多模态偏好优化中的过拟合问题，通过难度感知的样本重加权策略提升幻觉抑制效果", "motivation": "现有多模态DPO方法由于偏好数据难度不平衡容易过拟合，模型过度关注容易区分的样本对，阻碍细粒度幻觉抑制", "method": "提出难度感知直接偏好优化框架(DA-DPO)，包含两个组件：1) 难度估计：使用预训练视觉-语言模型结合生成和对比目标，通过分布感知投票策略产生难度分数；2) 难度感知训练：基于估计难度重新加权偏好对，降低简单样本权重，强调困难样本", "result": "实验表明DA-DPO持续改进多模态偏好优化，增强幻觉鲁棒性和泛化能力，同时保持计算效率", "conclusion": "DA-DPO是无需新数据或额外微调阶段的成本效益框架，能有效缓解过拟合问题，提升多模态大语言模型的幻觉抑制性能"}}
{"id": "2601.00444", "pdf": "https://arxiv.org/pdf/2601.00444", "abs": "https://arxiv.org/abs/2601.00444", "authors": ["Muhammad Shahmeer Khan"], "title": "Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment", "categories": ["cs.CL"], "comment": "11 pages, 6 figures. Code and reproducibility resources available on GitHub", "summary": "In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.", "AI": {"tldr": "比较三种轻量级Transformer模型（DistilBERT、MiniLM、ALBERT）在情感分析、新闻分类和有害内容检测三个领域的性能表现，分析准确性与效率的权衡", "motivation": "企业NLP应用对高效、轻量级的多领域文本自动化处理模型需求日益增长，需要了解不同轻量级模型的性能特点和适用场景", "method": "使用IMDB、AG News和Measuring Hate Speech数据集，评估三种模型在准确率、精确率、召回率、F1分数等性能指标，以及模型大小、推理时间、吞吐量和内存使用等效率指标", "result": "没有单一模型在所有维度表现最优：ALBERT在多个领域获得最高准确率，MiniLM在推理速度和吞吐量方面表现最佳，DistilBERT在任务间保持最一致的准确率且效率竞争力强", "conclusion": "不同模型各有优势，建议根据企业需求选择：延迟敏感应用选MiniLM，平衡性能选DistilBERT，资源受限环境选ALBERT"}}
{"id": "2601.00694", "pdf": "https://arxiv.org/pdf/2601.00694", "abs": "https://arxiv.org/abs/2601.00694", "authors": ["Qingwen Pu", "Kun Xie", "Hong Yang", "Guocong Zhai"], "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference", "categories": ["cs.AI"], "comment": null, "summary": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.", "AI": {"tldr": "PedX-LLM是一个结合视觉特征和交通领域知识的行人过街行为推理框架，通过LLaVA提取视觉特征并利用LoRA微调LLaMA-2-7B模型，在准确性和泛化性方面显著优于传统方法。", "motivation": "现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景中表现不佳。LLMs虽提供语义推理能力，但缺乏领域适应性和视觉上下文。", "method": "整合LLaVA提取的视觉特征与文本数据及交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。", "result": "达到82.0%的平衡准确率，超越最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在未见测试场景中零-shot配置达到66.9%准确率，few-shot学习后提升至72.2%。", "conclusion": "PedX-LLM通过视觉和知识增强的推理，能够模仿人类决策逻辑，克服纯数据驱动方法的局限性，展现出强大的跨场景泛化能力。"}}
{"id": "2601.00448", "pdf": "https://arxiv.org/pdf/2601.00448", "abs": "https://arxiv.org/abs/2601.00448", "authors": ["Dimitris Vartziotis"], "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.", "AI": {"tldr": "该论文通过对比社会建构主义和语义场理论两种语言意义理论，分析了大型语言模型如何体现语言的数学结构和社会语用维度，提出了数学结构与语言游戏互补的框架。", "motivation": "探索大型语言模型为检验长期存在的语言意义理论提供的新的实证环境，对比分析语言游戏的社会建构主义观点和数学导向的语义场理论。", "method": "基于作者先前工作，形式化词汇场和语言场作为连续语义空间中的交互结构，分析transformer架构的分布式表示、注意力机制和嵌入空间几何规律与这些概念的关系。", "result": "发现LLMs在捕捉语义规律方面的成功支持语言具有潜在数学结构的观点，而其在语用推理和语境敏感性方面的局限则与社会基础的重要性一致。", "conclusion": "数学结构和语言游戏可以理解为互补而非竞争的观点，该框架阐明了纯统计语言模型的适用范围和局限性，并为理论指导的AI架构指明了新方向。"}}
{"id": "2601.00743", "pdf": "https://arxiv.org/pdf/2601.00743", "abs": "https://arxiv.org/abs/2601.00743", "authors": ["Aliakbar Nafar", "Chetan Chigurupati", "Danial Kamali", "Hamid Karimian", "Parisa Kordjamshidi"], "title": "An Agentic Framework for Neuro-Symbolic Programming", "categories": ["cs.AI"], "comment": null, "summary": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.", "AI": {"tldr": "AgenticDomiKnowS (ADS) 是一个智能代理工作流，能够将自由形式的任务描述自动转换为完整的 DomiKnowS 神经符号程序，显著降低开发时间和使用门槛。", "motivation": "现有的神经符号集成框架如 DomiKnowS 虽然提供了高级声明式编程接口，但仍要求用户精通特定库语法，开发过程耗时且具有挑战性。", "method": "ADS 采用智能代理工作流，将自由形式任务描述分解并单独创建和测试每个 DomiKnowS 组件，支持可选的人工干预环节让熟悉 DomiKnowS 的用户优化中间输出。", "result": "ADS 使有经验和无经验的 DomiKnowS 用户都能快速构建神经符号程序，将开发时间从数小时缩短至10-15分钟。", "conclusion": "ADS 成功消除了对特定库语法的依赖，使神经符号模型的集成更加高效和易用，提高了开发效率并降低了使用门槛。"}}
{"id": "2601.00454", "pdf": "https://arxiv.org/pdf/2601.00454", "abs": "https://arxiv.org/abs/2601.00454", "authors": ["Hyunjun Kim"], "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.", "AI": {"tldr": "Defensive M2S训练范式通过多轮到单轮对话压缩，将护栏模型的训练成本从O(n²)降至O(n)，减少93%训练token，推理token减少94.6%，同时攻击检测召回率达到93.8%。", "motivation": "处理完整多轮对话历史会产生显著计算成本，需要一种高效的护栏模型部署方案。", "method": "提出Defensive M2S训练范式，在多轮到单轮压缩对话上微调护栏模型，使用三种压缩模板（hyphenize、numberize、pythonize）。", "result": "在三个护栏模型家族和SafeDialBench基准测试中，最佳配置达到93.8%攻击检测召回率，训练token减少93倍，推理token减少94.6%。", "conclusion": "M2S压缩是护栏部署的有效效率技术，能够实现长多轮对话的可扩展安全筛查。"}}
{"id": "2601.00488", "pdf": "https://arxiv.org/pdf/2601.00488", "abs": "https://arxiv.org/abs/2601.00488", "authors": ["Alexander M. Esser", "Jens Dörpinghaus"], "title": "Noise-Aware Named Entity Recognition for Historical VET Documents", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "This is an extended, non-peer-reviewed version of the paper presented at VISAPP 2026", "summary": "This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.", "AI": {"tldr": "该论文提出了一种针对职业教育培训领域文档的噪声感知命名实体识别方法，通过合成OCR错误注入、迁移学习和多阶段微调来提高在噪声文本中的识别鲁棒性和准确性。", "motivation": "解决职业教育培训领域历史数字化文档中因OCR错误导致的噪声问题，这些文档质量较差，需要鲁棒的命名实体识别方法。", "method": "采用噪声感知训练(NAT)方法，结合合成OCR错误注入、迁移学习和多阶段微调策略，系统比较了在噪声数据、干净数据和人工数据上的三种互补训练策略。", "result": "实验结果表明，领域特定和噪声感知的微调方法显著提高了在噪声条件下的鲁棒性和识别准确率。", "conclusion": "该方法是在职业教育培训文档中识别多种实体类型的首创方法之一，虽然应用于德语文档但可推广到其他语言，并提供了公开代码以确保可复现性。"}}
{"id": "2601.00506", "pdf": "https://arxiv.org/pdf/2601.00506", "abs": "https://arxiv.org/abs/2601.00506", "authors": ["Lineesha Kamana", "Akshita Ananda Subramanian", "Mehuli Ghosh", "Suman Saha"], "title": "Rule-Based Approaches to Atomic Sentence Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the \"split-and-rephrase\" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.", "AI": {"tldr": "本研究分析了复杂句结构对基于规则的原子句提取性能的影响，发现相对从句、同位语、并列谓语、状语从句和被动结构是主要挑战，基于依赖关系的规则提取方法获得了中等偏高的性能表现。", "motivation": "现有基于大语言模型的原子句提取方法缺乏可解释性，无法明确哪些语言结构导致提取失败，需要系统分析特定从句结构和依赖关系对提取难度的影响。", "method": "使用WikiSplit数据集，在spaCy中实现基于依赖关系的提取规则，生成100个黄金标准原子句集，使用ROUGE和BERTScore评估性能。", "result": "系统获得ROUGE-1 F1=0.6714、ROUGE-2 F1=0.478、ROUGE-L F1=0.650、BERTScore F1=0.5898，显示中等到高度的词汇、结构和语义对齐。相对从句、同位语等结构最具挑战性。", "conclusion": "基于规则的提取方法准确性合理但对句法复杂度敏感，为理解复杂句分解的困难提供了重要见解。"}}
{"id": "2601.00536", "pdf": "https://arxiv.org/pdf/2601.00536", "abs": "https://arxiv.org/abs/2601.00536", "authors": ["Yuelyu Ji", "Zhuochun Li", "Rui Meng", "Daqing He"], "title": "Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends", "categories": ["cs.CL"], "comment": null, "summary": "Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \\emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.", "AI": {"tldr": "该论文提出了一个四轴框架来分析多跳问答系统的执行过程，包括执行计划、索引结构、下一步控制和停止标准，用于比较不同模型家族的过程选择，并总结了有效性、效率和证据忠实度之间的权衡。", "motivation": "当前的多跳问答系统中，检索-推理过程往往隐含在模型内部，难以比较不同模型家族的程序选择，因此需要系统化的分析框架。", "method": "引入四轴分析框架：(A)总体执行计划、(B)索引结构、(C)下一步控制策略和触发机制、(D)停止/继续标准，并用此框架映射代表性多跳QA系统。", "result": "通过分析标准基准测试上的消融实验和趋势，揭示了有效性、效率和证据忠实度之间的常见权衡关系。", "conclusion": "提出了检索-推理代理面临的开放挑战，包括结构感知规划、可迁移控制策略和分布偏移下的鲁棒停止机制。"}}
{"id": "2601.00543", "pdf": "https://arxiv.org/pdf/2601.00543", "abs": "https://arxiv.org/abs/2601.00543", "authors": ["Chung-Wei Victor Yuan"], "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint 13pages, 6 figures", "summary": "Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.\n  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.\n  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.", "AI": {"tldr": "ECR是一个新的嵌入一致性调节框架，通过语义锚点保持紧凑模型的几何结构一致性，解决了传统压缩方法导致的嵌入空间结构崩塌问题。", "motivation": "紧凑模型在容量受限或多语言场景下容易丢失嵌入空间结构，导致语义漂移和下游任务性能下降。现有压缩方法只关注表层输出对齐，无法保持底层流形结构。", "method": "ECR框架从教师模型的嵌入中提取语义锚点，让紧凑模型学习在这些锚点周围保持几何一致性，不需要匹配logits或内部特征。推理时只需添加小型投影步骤，不改变解码架构或运行时行为。", "result": "在10万语料的多语言实验中，ECR稳定了训练过程，在跨任务和语言中保持了语义结构，产生了更紧凑且任务对齐的表示空间，使低容量模型能学习到比传统基线更清晰的流形。", "conclusion": "ECR帮助紧凑模型更好地遵循任务要求，使其在严格效率或隐私限制下更容易部署，且不依赖教师输出，与蒸馏兼容但独立。"}}
{"id": "2601.00557", "pdf": "https://arxiv.org/pdf/2601.00557", "abs": "https://arxiv.org/abs/2601.00557", "authors": ["Yuang Zheng", "Yuxiang Mei", "Dongxing Xu", "Jie Chen", "Yanhua Long"], "title": "A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "5 pages, submitted to IEEE Signal Processing Letters", "summary": "Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.", "AI": {"tldr": "提出基于CTC架构的轻量级语言无关多语言ASR系统HLoRA，通过分层LoRA-MoE框架实现单次解码，在保持性能的同时显著提升计算效率", "motivation": "解决大规模多语言ASR模型(如Whisper)计算成本高、延迟大的问题，使其能够在资源受限的边缘设备上部署", "method": "在mHuBERT-CTC模型中集成语言无关的分层LoRA-MoE框架，包含多语言共享LoRA学习语言不变声学表示和语言特定LoRA专家建模语言相关特征，使用LID后验驱动的LoRA路由机制", "result": "在MSR-86K和MLC-SLM 2025数据集上验证，HLoRA通过单次解码达到与最先进两阶段推理方法相当的性能，显著提升低资源多语言ASR的解码效率", "conclusion": "HLoRA框架成功实现了真正的语言无关解码，无需推理时的语言身份信息，为资源受限环境下的多语言ASR应用提供了高效解决方案"}}
{"id": "2601.00575", "pdf": "https://arxiv.org/pdf/2601.00575", "abs": "https://arxiv.org/abs/2601.00575", "authors": ["Ishir Garg", "Neel Kolhe", "Xuandong Zhao", "Dawn Song"], "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/", "AI": {"tldr": "InfoSynth是一个基于信息论原理的自动生成和评估推理基准测试框架，通过KL散度和熵度量新颖性和多样性，使用遗传算法从种子数据集生成Python编程问题，97%的情况下能准确生成测试用例和解决方案。", "motivation": "传统基准测试创建依赖人工，成本高且耗时，现有基准容易污染LLM训练数据，需要新颖多样的基准来准确评估模型真实能力。", "method": "提出基于KL散度和熵的信息论度量指标，开发端到端流水线，使用遗传算法和迭代代码反馈从种子数据集合成Python编程问题。", "result": "97%的情况下能准确生成新问题的测试用例和解决方案，合成的基准相比种子数据集具有更高的新颖性和多样性，算法能控制生成问题的新颖性/多样性和难度。", "conclusion": "InfoSynth提供了一个可扩展、自验证的流水线，用于为LLMs构建高质量、新颖且多样化的基准测试。"}}
{"id": "2601.00588", "pdf": "https://arxiv.org/pdf/2601.00588", "abs": "https://arxiv.org/abs/2601.00588", "authors": ["Zhenhong Zhou", "Shilinlu Yan", "Chuanpu Liu", "Qiankun Li", "Kun Wang", "Zhigang Zeng"], "title": "CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns", "categories": ["cs.CL"], "comment": "18 pages", "summary": "Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.", "AI": {"tldr": "CSSBench是一个专门针对中文安全性的基准测试，重点关注中文特有的对抗模式（如同音字、拼音、符号拆分等），评估轻量级大语言模型在中文环境中的安全性表现。", "motivation": "现有安全评估主要针对英文，而中文恶意查询通过特有的对抗模式隐藏意图，造成安全评估空白，特别是轻量级模型更容易受到这些特定对抗扰动的影响。", "method": "构建CSSBench基准测试，覆盖6个中文常见领域（非法活动、隐私泄露、医疗错误信息、欺诈仇恨、成人内容、公共政治安全），组织多种任务类型查询，评估流行轻量级LLMs并测量过度拒绝行为。", "result": "中文特有的对抗模式对轻量级LLMs构成重大挑战，基准测试结果显示这些模型在中文安全性方面存在明显漏洞。", "conclusion": "CSSBench提供了中文LLM安全性的全面评估框架，有助于在实际部署中增强模型鲁棒性，填补了中文安全评估的空白。"}}
{"id": "2601.00596", "pdf": "https://arxiv.org/pdf/2601.00596", "abs": "https://arxiv.org/abs/2601.00596", "authors": ["Sumanth Balaji", "Piyush Mishra", "Aashraya Sachdeva", "Suraj Agrawal"], "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "categories": ["cs.CL"], "comment": "17 pages, 3 figures, preprint", "summary": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.", "AI": {"tldr": "JourneyBench是一个用于评估客户支持中策略感知AI代理的新基准，通过图表示生成多样化支持场景，并提出User Journey Coverage Score指标来衡量策略遵循能力。研究发现动态提示代理能显著提升策略遵循性，甚至让小模型超越大模型。", "motivation": "传统客户支持系统（如IVR）依赖固定脚本，缺乏处理复杂策略驱动任务的灵活性。现有基准主要关注工具使用或任务完成，忽略了代理遵循多步骤策略、处理任务依赖关系以及对不可预测用户行为的鲁棒性。", "method": "引入JourneyBench基准，使用图表示生成多样化现实支持场景，提出User Journey Coverage Score新指标。评估了两种代理设计：静态提示代理（SPA）和动态提示代理（DPA），在三个领域的703个对话中进行测试。", "result": "DPA显著提升了策略遵循能力，甚至让GPT-4o-mini等较小模型的表现超过了GPT-4o等更强大的模型。结构化编排对策略遵循至关重要。", "conclusion": "JourneyBench是推动AI驱动客户支持超越IVR时代限制的关键资源，证明了结构化编排的重要性，为策略感知代理的评估提供了有效框架。"}}
{"id": "2601.00641", "pdf": "https://arxiv.org/pdf/2601.00641", "abs": "https://arxiv.org/abs/2601.00641", "authors": ["Nils Rautenberg", "Sven Schippkus"], "title": "Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.\n  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.\n  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.", "AI": {"tldr": "提出一个模型无关的框架，通过重复生成和LLM作为裁判的多数投票机制，为固定输入的自动化工作流提供降低幻觉概率的理论保证和实验验证。", "motivation": "大语言模型在确定性自动化工作流中经常产生上下文幻觉，生成内容与提示中明确信息相矛盾，这在输入固定且正确性明确的场景中尤为严重。", "method": "1. 在独立上下文窗口中重复生成相同提示，实现错误概率的指数级降低；2. 使用LLM作为裁判识别正确答案；3. 通过多数投票机制强化不完美裁判的性能，获得指数级下降的整体错误率。", "result": "在受控提取任务上的实验完全验证了理论预测：管道失败概率随重复次数指数下降，幻觉选择概率随裁判数量指数下降。", "conclusion": "该方法提供了一种轻量级、模块化且理论扎实的方法，无需修改模型权重、解码策略或提示工程，就能在固定输入LLM工作流中将幻觉概率降至任意低水平。"}}
{"id": "2601.00647", "pdf": "https://arxiv.org/pdf/2601.00647", "abs": "https://arxiv.org/abs/2601.00647", "authors": ["QiWei Meng"], "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations", "categories": ["cs.CL", "cs.CE", "q-bio.QM"], "comment": null, "summary": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.", "AI": {"tldr": "Physio-DPO：一种基于物理信息的蛋白质语言模型对齐框架，通过热力学稳定性来减少结构幻觉，提高蛋白质序列的可折叠性和结构稳定性", "motivation": "现有的大型蛋白质语言模型在生成蛋白质序列时经常产生结构幻觉，生成的序列虽然语言概率高但热力学不稳定。现有的对齐方法如DPO只能处理二元标签偏好，忽略了物理能量景观的连续结构", "method": "提出Physio-DPO框架，引入幅度感知目标函数，根据天然结构与物理扰动硬负样本之间的能量差距来缩放优化更新", "result": "Physio-DPO在所有基线方法中表现最佳，将自洽RMSD降低到1.28埃，可折叠性提高到92.8%，有效恢复了疏水核心堆积和氢键网络等生物物理相互作用", "conclusion": "Physio-DPO成功地将蛋白质语言模型与热力学稳定性对齐，有效缓解了结构幻觉问题，为生成更可靠的蛋白质设计提供了新方法"}}
{"id": "2601.00671", "pdf": "https://arxiv.org/pdf/2601.00671", "abs": "https://arxiv.org/abs/2601.00671", "authors": ["Tianyu Zhao", "Llion Jones"], "title": "Fast-weight Product Key Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.", "AI": {"tldr": "FwPKM是一种新型架构，通过将稀疏产品密钥内存从静态模块转变为动态的\"快速权重\"情景记忆，解决了语言模型中存储容量与计算效率的权衡问题。", "motivation": "现代语言模型中的序列建模层面临存储容量和计算效率之间的权衡：Softmax注意力提供无限存储但计算成本高昂，线性变体效率高但存储容量有限且固定。", "method": "提出Fast-weight Product Key Memory (FwPKM)，通过本地块级梯度下降在训练和推理时动态更新参数，使模型能够快速记忆和检索输入序列中的新键值对。", "result": "实验显示FwPKM作为有效的情景记忆补充了标准模块的语义记忆，在长上下文数据集上显著降低了困惑度。在Needle in a Haystack评估中，尽管仅在4K标记序列上训练，但能泛化到128K标记上下文。", "conclusion": "FwPKM成功解决了语言模型中存储与效率的权衡问题，提供了动态、高效的长上下文处理能力，展现出强大的泛化性能。"}}
{"id": "2601.00680", "pdf": "https://arxiv.org/pdf/2601.00680", "abs": "https://arxiv.org/abs/2601.00680", "authors": ["Tu Anh Dinh", "Jan Niehues"], "title": "Sigmoid Head for Quality Estimation under Language Ambiguity", "categories": ["cs.CL"], "comment": null, "summary": "Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.", "AI": {"tldr": "提出Sigmoid Head模块来解决语言模型概率不能可靠估计输出质量的问题，通过sigmoid激活和负采样策略来支持多个正确选项，无需人工标注数据。", "motivation": "语言模型的softmax概率分布不能可靠地估计输出质量，因为自然语言具有歧义性，多个输出选项可能都是正确的，但模型概率会分散到这些选项上，导致质量评估不准确。", "method": "在预训练语言模型上训练一个称为Sigmoid Head的质量估计模块，使用sigmoid激活函数替代softmax，允许多个正确选项同时获得高概率；通过启发式负采样策略避免选择潜在的正确替代词。", "result": "Sigmoid Head的概率比原始softmax头提供更好的质量信号，计算效率高，在训练和推理时都高效，且对域外设置更加鲁棒。", "conclusion": "Sigmoid Head有效解决了语言模型概率估计质量不可靠的问题，通过改进激活函数和训练策略，无需人工标注就能获得更好的质量评估效果。"}}
{"id": "2601.00736", "pdf": "https://arxiv.org/pdf/2601.00736", "abs": "https://arxiv.org/abs/2601.00736", "authors": ["Alphaeus Dmonte", "Roland Oruche", "Tharindu Ranasinghe", "Marcos Zampieri", "Prasad Calyam"], "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.", "AI": {"tldr": "本文评估了大型语言模型在情感分析、攻击性语言识别和声明验证三个任务中的文本跨度识别性能，探索了指令微调、上下文学习和思维链等策略，发现文本内部关系有助于LLM精确识别文本跨度。", "motivation": "现有研究主要关注命名实体识别等显式跨度识别任务，而在情感分析等更主观的跨度识别任务中使用大型语言模型的研究尚未充分探索，本文旨在填补这一空白。", "method": "使用多种大型语言模型策略（指令微调、上下文学习、思维链）在三个流行任务（情感分析、攻击性语言识别、声明验证）上评估文本跨度识别性能。", "result": "研究结果表明文本内部关系有助于大型语言模型识别精确的文本跨度。", "conclusion": "大型语言模型在主观文本跨度识别任务中表现出色，文本内部关系对精确跨度识别具有重要作用，为NLP下游任务的可解释性提供了重要见解。"}}
{"id": "2601.00787", "pdf": "https://arxiv.org/pdf/2601.00787", "abs": "https://arxiv.org/abs/2601.00787", "authors": ["Jonathan Simkin", "Lovedeep Gondara", "Zeeshan Rizvi", "Gregory Doyle", "Jeff Dowden", "Dan Bond", "Desmond Martin", "Raymond Ng"], "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries", "categories": ["cs.CL"], "comment": null, "summary": "Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.", "AI": {"tldr": "本研究评估了将BCCRTron和GatorTron两种transformer模型在加拿大跨省癌症登记中的适应性，通过模型集成显著减少了漏检癌症病例，提高了癌症监测效率。", "motivation": "基于人群的癌症登记依赖病理报告作为主要诊断来源，但手动提取资源密集且导致数据延迟。虽然transformer NLP系统改进了登记工作流程，但其在不同司法管辖区间的泛化能力尚不清楚。", "method": "使用纽芬兰与拉布拉多癌症登记处的约104,000和22,000份去标识化病理报告，分别用于Tier 1（癌症vs非癌症）和Tier 2（可报告vs不可报告）任务。对两个模型进行微调，使用互补的格式化和诊断重点报告部分输入管道。", "result": "集成模型在Tier 1任务中召回率达到0.99，漏检癌症减少至24例（单独模型分别为48和54例）；Tier 2任务中召回率0.99，漏检可报告癌症减少至33例（单独模型分别为54和46例）。", "conclusion": "研究表明，结合互补文本表示的集成模型可显著减少漏检癌症并提高错误覆盖率，实现了仅共享模型权重的隐私保护工作流程，支持可互操作的NLP基础设施和未来泛加拿大癌症病理基础模型。"}}
