{"id": "2512.05122", "pdf": "https://arxiv.org/pdf/2512.05122", "abs": "https://arxiv.org/abs/2512.05122", "authors": ["Unnikrishnan Radhakrishnan"], "title": "Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN", "categories": ["cs.AI"], "comment": "Presented at 2025 International Workshop on Low-Cost Digital Solutions for Industrial Automation (LODISA)", "summary": "Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures such knowledge on the shop floor and converts it incrementally and interactively into standards-compliant Business Process Model and Notation (BPMN) 2.0 diagrams. Powered by Gemini 2.5 Pro and delivered through a lightweight Gradio front-end with client-side bpmn-js visualisation, the assistant conducts an interview-style dialogue: it elicits process details, supports clarifying dialogue and on-demand analysis, and renders live diagrams that users can refine in real time. A proof-of-concept evaluation in an equipment-maintenance scenario shows that the chatbot produced an accurate \"AS-IS\" model, flagged issues via on-diagram annotations, and generated an improved \"TO-BE\" variant, all within about 12-minutes, while keeping API costs within an SME-friendly budget. The study analyses latency sources, model-selection trade-offs, and the challenges of enforcing strict XML schemas, then outlines a roadmap toward agentic and multimodal deployments. The results demonstrate that conversational LLMs can potentially be used to lower the skill and cost barriers to rigorous process documentation, helping SMEs preserve institutional knowledge, enhance operational transparency, and accelerate continuous-improvement efforts.", "AI": {"tldr": "论文提出了一种基于大语言模型的对话助手，能够通过访谈式对话捕获中小企业车间经验知识，并实时转换为标准BPMN 2.0流程图，显著降低了流程文档化的技能和成本门槛。", "motivation": "中小企业严重依赖隐性经验知识，但这些知识很少被正式记录，导致机构知识流失和流程改进困难。", "method": "使用Gemini 2.5 Pro驱动的对话助手，通过轻量级Gradio前端和bpmn-js可视化工具，进行访谈式对话收集流程细节，实时生成和优化BPMN图表。", "result": "在设备维护场景的概念验证中，聊天机器人在12分钟内生成了准确的\"AS-IS\"模型，标注了问题点，并生成了改进的\"TO-BE\"变体，API成本控制在中小企业可接受范围内。", "conclusion": "对话式大语言模型能够有效降低严格流程文档化的技能和成本障碍，帮助中小企业保存机构知识、提高运营透明度并加速持续改进工作。"}}
{"id": "2512.05156", "pdf": "https://arxiv.org/pdf/2512.05156", "abs": "https://arxiv.org/abs/2512.05156", "authors": ["Igor Halperin"], "title": "Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.LG", "q-fin.CP"], "comment": "23 pages, 6 figures", "summary": "Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\\bf Q}$ and ${\\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.", "AI": {"tldr": "提出两个基于信息论和热力学的无监督指标(SF和SEP)来评估大语言模型的忠实度，通过将问答过程建模为信息引擎和主题转换矩阵，量化模型输出与上下文的一致性。", "motivation": "评估大语言模型对给定任务的忠实度是一个复杂挑战，需要新的无监督评估指标来衡量模型输出是否忠实于输入上下文。", "method": "将LLM视为二分信息引擎，隐藏层作为麦克斯韦妖控制信息转换。将QCA三元组建模为主题概率分布，通过KL散度计算查询目标矩阵和实际结果矩阵之间的差异作为忠实度指标。", "result": "提出了语义忠实度(SF)和语义熵产生(SEP)两个指标，SF通过KL散度量化忠实度，SEP基于热力学原理衡量熵产生，两者可用于联合或单独评估LLM。", "conclusion": "该方法为LLM忠实度评估提供了新的无监督框架，SF和SEP指标能有效评估模型输出的一致性和控制幻觉问题，在SEC文件摘要任务中验证了有效性。"}}
{"id": "2512.05167", "pdf": "https://arxiv.org/pdf/2512.05167", "abs": "https://arxiv.org/abs/2512.05167", "authors": ["Fang Li"], "title": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education", "categories": ["cs.AI"], "comment": "Accepted by the 39th annual Consortium for Computing Sciences in Colleges (CCSC:SE)", "summary": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.", "AI": {"tldr": "提出一种创新教学方法，将传统机器学习与现代大语言模型(LLMs)系统结合，通过两阶段课程设计帮助学生全面理解AI发展并掌握实用技能", "motivation": "为了弥合传统机器学习技术与现代大语言模型之间的教学鸿沟，帮助学生建立对AI演变的全面理解，同时培养他们使用传统和前沿技术的实践能力", "method": "设计分为两个连续互补部分的课程结构：基础机器学习概念和当代LLM应用，详细描述课程架构、实施策略、评估方法，并在两个七周的暑期学期中实施", "result": "该综合方法增强了学生对AI领域的理解，并更好地为他们在快速发展的AI行业中的职业需求做好准备", "conclusion": "这种整合传统机器学习与现代LLM的教学方法是有效的，能够提升学生的综合理解能力和行业适应能力，为AI教育提供了有价值的实践模式"}}
{"id": "2512.05212", "pdf": "https://arxiv.org/pdf/2512.05212", "abs": "https://arxiv.org/abs/2512.05212", "authors": ["Georgios Mappouras", "Charalambos Rossides"], "title": "On the Computability of Artificial General Intelligence", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.", "AI": {"tldr": "该论文通过形式化证明，论证了任何算法（包括AI模型）都无法在其初始算法之外展示新的功能能力，从而无法实现真正的创造力。", "motivation": "探讨人工智能是否能够达到人类水平的智能（AGI），特别是关于机器是否能够真正创造和创新的问题。", "method": "借用先前工作中对AGI的定义，通过形式化证明的方法分析算法的计算极限。", "result": "证明没有任何算法能够展示初始算法本身不具备的新功能能力，AI只能展示现有功能能力的组合和排列。", "conclusion": "这一证明对AI发展的未来和人类智能的起源具有重要意义，表明机器无法实现真正的创造性突破。"}}
{"id": "2512.05179", "pdf": "https://arxiv.org/pdf/2512.05179", "abs": "https://arxiv.org/abs/2512.05179", "authors": ["Aurélie Montfrond"], "title": "Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale", "categories": ["cs.CL", "cs.AI"], "comment": "4 pages, 2 figures", "summary": "Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.", "AI": {"tldr": "本研究通过微调BERT模型，为利默里克大学电子与计算机工程系开发了一个课程信息问答聊天机器人，使用1203个问答对数据集进行训练，展示了基础模型在教育领域的适应可行性。", "motivation": "现有科学问答研究主要关注聊天机器人系统，缺乏针对特定领域推理的基础模型微调探索。大学课程材料领域尚无专门的问答基础模型，本研究旨在填补这一空白。", "method": "构建包含1203个问答对的SQuAD格式数据集（来自大学模块手册，含手动和合成生成条目），使用PyTorch微调BERT模型，采用精确匹配和F1分数评估性能。", "result": "即使进行适度的微调也能改善假设构建和知识提取能力，证明基础模型适应教育领域的可行性，微调BERT在学术问答对上能产生有效结果。", "conclusion": "研究表明微调基础模型可用于教育领域问答系统，具有开发大学领域特定问答模型的潜力，为构建自主教育知识系统奠定了基础。"}}
{"id": "2512.05257", "pdf": "https://arxiv.org/pdf/2512.05257", "abs": "https://arxiv.org/abs/2512.05257", "authors": ["Bychkov Oleksii", "Bychkova Sophia", "Lytvynchuk Khrystyna"], "title": "Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence", "categories": ["cs.AI"], "comment": "9 pages", "summary": "This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.", "AI": {"tldr": "本文通过可能性理论为DST悖论提供根本性解决方案，使用可能性和必要性测度的二元框架建立逻辑一致的不确定性处理基础，通过医疗诊断案例展示其避免逻辑陷阱的能力。", "motivation": "解决DST（Dempster-Shafer理论）的危机和悖论问题，现有众多修正Dempster规则的尝试不足，需要建立全新的逻辑一致且数学严谨的不确定性处理基础。", "method": "采用Bychkov文章中的公理化方法，基于可能性理论的双重测度框架（可能性和必要性测度），通过比较分析概率、证据和可能性三种范式，以经典医疗诊断困境为例进行验证。", "result": "证明可能性理论不仅能正确处理矛盾数据，避免DST的逻辑陷阱，还能使形式推理更接近自然智能的逻辑。", "conclusion": "可能性理论不仅是DST的替代方案，更为DST悖论提供了根本性解决方案，建立了逻辑一致且数学严谨的不确定性处理基础。"}}
{"id": "2512.05231", "pdf": "https://arxiv.org/pdf/2512.05231", "abs": "https://arxiv.org/abs/2512.05231", "authors": ["Gili Goldin", "Ella Rabinovich", "Shuly Wintner"], "title": "Unveiling Affective Polarization Trends in Parliamentary Proceedings", "categories": ["cs.CL"], "comment": "pre-MIT Press publication version", "summary": "Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.", "AI": {"tldr": "提出基于情感风格而非意识形态立场的新方法量化政治极化，通过情感维度分析发现以色列议会中政府与反对派情感风格差异，且情感极化随时间显著增加", "motivation": "近年来全球极化言论增加，需要新的量化方法来测量基于情感风格而非意识形态立场的极化现象", "method": "使用情感维度（Valence、Arousal、Dominance）检测情感话语信号，应用于以色列议会会议记录语料库分析", "result": "发现政府成员与反对派成员的情感风格存在差异，情感极化水平随时间显著增加", "conclusion": "基于情感风格的分析方法能有效量化情感极化，揭示政治话语中情感层面的对立趋势"}}
{"id": "2512.05356", "pdf": "https://arxiv.org/pdf/2512.05356", "abs": "https://arxiv.org/abs/2512.05356", "authors": ["Jason Weston", "Jakob Foerster"], "title": "AI & Human Co-Improvement for Safer Co-Superintelligence", "categories": ["cs.AI"], "comment": null, "summary": "Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.", "AI": {"tldr": "论文主张从AI自我改进转向人机协同改进(co-improvement)，通过人类研究者与AI系统的合作研究来实现共同超智能，这比单纯的AI自我改进更可实现且更安全", "motivation": "当前AI领域的自我改进目标虽然令人兴奋但充满危险且难以完全实现，需要寻找更可实现和更好的替代目标", "method": "提出co-improvement概念，专注于提升AI系统与人类研究者合作进行AI研究的能力，从构思到实验的完整研究流程中实现人机协作", "result": "通过人机协同研究可以加速AI研究进程，并通过人机共生关系赋予AI和人类更安全的超智能", "conclusion": "将人类研究改进纳入循环中既能更快实现目标，又能更安全地达到共同超智能"}}
{"id": "2512.05243", "pdf": "https://arxiv.org/pdf/2512.05243", "abs": "https://arxiv.org/abs/2512.05243", "authors": ["P. D. Edgar", "Alia Hall"], "title": "Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting", "categories": ["cs.CL", "cs.CY"], "comment": "Late-Breaking Paper accepted to IEEE SSCI 2025 NLP & Social Media Track as extended abstract and presented in Trondheim, Norway 17-20 March 2025 as Poster Presentation", "summary": "Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.", "AI": {"tldr": "本研究探讨了诗歌提示模式作为提示工程新工具的价值，通过诗性提示来评估不同语言模型对著名诗人作品的描述和改写能力。", "motivation": "研究旨在探索创意文本提示（特别是诗歌提示模式）如何增强提示工程的工具箱，并测试语言模型对原创创意作品的适应和改写能力。", "method": "提出诗歌提示模式的方法论，使用诗性提示来评估三个知名语言模型对著名诗人作品的描述和评价，测试模型为特定受众改写原创作品的能力。", "result": "研究发现诗歌提示模式可以作为提示工程师的有用工具，并揭示了语言模型在适应和改写原创创意作品方面的表现特征。", "conclusion": "诗歌提示模式是提示工程中一个有价值的补充方法，能够有效评估语言模型的创意写作能力和对原始作品的适应性，为研究模型偏见和算法倾向提供了新视角。"}}
{"id": "2512.05365", "pdf": "https://arxiv.org/pdf/2512.05365", "abs": "https://arxiv.org/abs/2512.05365", "authors": ["Zag ElSayed", "Craig Erickson", "Ernest Pedapati"], "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare", "categories": ["cs.AI", "q-bio.QM"], "comment": "6 pages, 4 figures", "summary": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.", "AI": {"tldr": "MCP-AI是一种创新的医疗AI架构，结合模型上下文协议(MCP)实现可解释的医疗决策支持，支持长期状态管理和临床逻辑验证，相比传统CDSS和基于提示的LLMs有显著优势", "motivation": "传统医疗AI系统在上下文推理、长期状态管理和人类可验证工作流整合方面存在挑战，需要自主、上下文感知的临床推理框架来应对日益复杂的医疗系统", "method": "提出MCP-AI架构，基于模块化、可执行的模型上下文协议(MCP)，每个MCP文件捕获临床目标、患者上下文、推理状态和任务逻辑，形成可重用和可审计的内存对象", "result": "通过两个用例验证：脆性X综合征伴抑郁的诊断建模，以及2型糖尿病和高血压的远程协调，系统支持医生在环验证，简化临床流程，确保AI责任的安全转移", "conclusion": "MCP-AI为即将到来的临床环境提供了一个可扩展、可解释、可组合且安全导向的AI基础，符合HIPAA和FDA SaMD等监管标准"}}
{"id": "2512.05256", "pdf": "https://arxiv.org/pdf/2512.05256", "abs": "https://arxiv.org/abs/2512.05256", "authors": ["Ivan Makohon", "Mohamad Najafi", "Jian Wu", "Mathias Brochhausen", "Yaohang Li"], "title": "Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4", "categories": ["cs.CL", "q-bio.QM"], "comment": null, "summary": "In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.", "AI": {"tldr": "使用思维链提示工程结合语义搜索和知识图谱，提升LLM在临床笔记生成中的表现，相比标准单样本提示效果更好", "motivation": "电子健康记录数据激增但医生手动撰写临床笔记耗时，LLM具有生成类人文本能力但需要提升在医疗领域的专业性", "method": "结合传统思维链提示与语义搜索，注入临床本体知识图谱，使用ICD编码和患者基本信息作为输入", "result": "在CodiEsp测试数据集的6个临床案例上测试，该方法优于标准单样本提示生成的临床笔记", "conclusion": "思维链提示工程结合领域知识增强可有效提升LLM在专业医疗文本生成任务中的性能"}}
{"id": "2512.05371", "pdf": "https://arxiv.org/pdf/2512.05371", "abs": "https://arxiv.org/abs/2512.05371", "authors": ["Changwen Xing", "SamZaak Wong", "Xinlai Wan", "Yanfeng Lu", "Mengli Zhang", "Zebin Ma", "Lei Qi", "Zhengxiong Li", "Nan Guan", "Zhe Jiang", "Xi Wang", "Jun Yang"], "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications", "categories": ["cs.AI", "cs.AR"], "comment": "Accepted by the AAAl26 Conference Main Track", "summary": "While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).", "AI": {"tldr": "ChipMind是一个基于知识图谱的框架，通过将电路规格转换为领域知识图谱并采用自适应检索和语义过滤机制，有效解决了大语言模型在集成电路设计中的上下文窗口限制问题，在工业级基准测试中性能显著优于现有方法。", "motivation": "大语言模型在集成电路开发自动化方面具有巨大潜力，但受限于有限的上下文窗口，现有方法难以对复杂冗长的电路规格进行有效的语义建模和多跳推理。", "method": "提出ChipMind框架：1) 通过电路语义感知知识图谱构建方法将电路规格转换为领域知识图谱ChipKG；2) 采用信息理论自适应检索动态追踪逻辑依赖关系；3) 使用意图感知语义过滤去除无关噪声，平衡检索的完整性和精确度。", "result": "在工业级规格推理基准测试中，ChipMind显著优于最先进的基线方法，平均提升34.59%（最高提升72.73%）。", "conclusion": "ChipMind框架填补了LLM辅助硬件设计学术研究与实际工业部署之间的关键空白，为集成电路设计自动化提供了有效的解决方案。"}}
{"id": "2512.05318", "pdf": "https://arxiv.org/pdf/2512.05318", "abs": "https://arxiv.org/abs/2512.05318", "authors": ["Vignesh Kothapalli", "Ata Fatahibaarzi", "Hamed Firooz", "Maziar Sanjabi"], "title": "To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "26 pages, 45 figures, 3 tables", "summary": "Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.", "AI": {"tldr": "该论文提出CoT-Recipe方法，通过调节元训练中CoT和非CoT示例的比例，显著提升大语言模型在新颖任务上的推理能力，即使在没有上下文CoT示例的情况下也能获得高达300%的准确率提升。", "motivation": "研究发现，虽然思维链(CoT)提示与少样本上下文学习(ICL)结合能增强大语言模型的推理能力，但当预训练知识不足时，这种方法在新颖任务上效果不佳。特别是在元训练中过多包含CoT示例会降低性能。", "method": "提出CoT-Recipe方法，这是一种正式的方法来调节元训练序列中CoT和非CoT示例的混合比例。使用CoT-ICL Lab框架在受控环境中进行研究，并将该方法应用于预训练LLMs（Qwen2.5系列）进行符号推理任务验证。", "result": "通过CoT-Recipe的精确调节，即使在上下文没有CoT示例的情况下，也能使transformer在新颖任务上的准确率提升高达300%。在预训练LLMs上的应用显示，符号推理任务的准确率最高可提升130%。", "conclusion": "CoT-Recipe方法有效解决了元训练中CoT示例过度包含导致的性能下降问题，显著提升了模型在新颖抽象推理任务上的上下文学习能力，为大语言模型的推理能力提升提供了新思路。"}}
{"id": "2512.05439", "pdf": "https://arxiv.org/pdf/2512.05439", "abs": "https://arxiv.org/abs/2512.05439", "authors": ["Tarun Suresh", "Nalin Wadhwa", "Debangshu Banerjee", "Gagandeep Singh"], "title": "BEAVER: An Efficient Deterministic LLM Verifier", "categories": ["cs.AI", "cs.FL"], "comment": null, "summary": "As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.", "AI": {"tldr": "BEAVER是首个为LLM约束满足计算确定性概率边界的实用框架，相比采样方法提供可证明的严格保证，在相同计算预算下获得6-8倍更紧的边界和3-4倍更多高风险实例识别。", "motivation": "随着大语言模型从研究原型转向生产系统，需要可靠方法来验证模型输出是否满足约束条件，采样估计只能提供直观感受但无法提供严格保证。", "method": "BEAVER使用新颖的token trie和frontier数据结构系统性地探索生成空间，对任何前缀封闭的语义约束维护可证明的严格概率边界。", "result": "在多个先进LLM的正确性验证、隐私验证和安全代码生成任务中，BEAVER相比基线方法在相同计算预算下实现了6-8倍更紧的概率边界和3-4倍更多高风险实例识别。", "conclusion": "BEAVER框架能够提供精确的特征描述和风险评估，这是宽松边界或经验评估无法实现的，为LLM在生产环境中的安全部署提供了可靠的验证手段。"}}
{"id": "2512.05325", "pdf": "https://arxiv.org/pdf/2512.05325", "abs": "https://arxiv.org/abs/2512.05325", "authors": ["Ömer Faruk Akgül", "Yusuf Hakan Kalaycı", "Rajgopal Kannan", "Willie Neiswanger", "Viktor Prasanna"], "title": "LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often \"overthink\": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., \"hmm\", \"wait\") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.", "AI": {"tldr": "LYNX是一种在线早期退出机制，通过分析模型隐藏状态的自然推理线索（如\"hmm\"、\"wait\"等）来实现置信度控制的提前停止，在保持或提高准确性的同时显著减少推理计算量。", "motivation": "大型推理模型在复杂任务中经常\"过度思考\"，即在已经获得足够信息后仍继续推理，这会浪费推理计算资源并可能降低准确性。现有方法要么需要额外采样和启发式方法，要么依赖辅助验证模型，缺乏形式化保证。", "method": "LYNX通过在生成过程中识别自然出现的推理线索标记，在这些标记的隐藏状态上训练轻量级探针，并使用分离共形预测包装得分以获得对提前退出的无分布控制。该方法在通用数学语料上一次性训练和校准探针，然后跨基准、解码温度甚至非数学任务重用。", "result": "在1.5B到32B参数的三个模型系列上，LYNX实现了强准确性-效率权衡：GSM8K上减少40-65%的token同时保持或提高准确性；MATH-500上减少35-60% token同时准确性提升高达12点；AIME 2024上节省50%以上token恢复基线准确性；CommonsenseQA上零样本转移，准确性略有提升且节省高达70% token。", "conclusion": "LYNX相比最先进的早期退出方法，提供竞争性或更优的帕累托前沿，同时保持完全在线、无需推理时代理模型，并提供明确的用户可调置信度保证。"}}
{"id": "2512.05449", "pdf": "https://arxiv.org/pdf/2512.05449", "abs": "https://arxiv.org/abs/2512.05449", "authors": ["Robert Yang"], "title": "The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems", "categories": ["cs.AI"], "comment": "4 pages + appendix. AAAI 2026 FAST Workshop (Oral)", "summary": "Large language models display a peculiar form of inconsistency: they \"know\" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of \"self-control\" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as \"scheming\" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.", "AI": {"tldr": "该论文提出将哲学中的\"意志薄弱\"（akrasia）概念作为分析AI智能体系统不一致性的理论基础，并开发了Akrasia Benchmark来量化测量语言模型在四种提示条件下的自我控制能力差异。", "motivation": "大型语言模型表现出一种特殊的不一致性：它们\"知道\"正确答案但无法据此行动。这种全局判断与局部冲动之间的张力类似于人类哲学中的意志薄弱现象，需要建立理论框架和评估工具来分析智能体AI系统中的不一致性和目标漂移问题。", "method": "引入Akrasia Benchmark作为操作化工具，包含四种结构化提示条件：基线条件（B）、同义词条件（S）、时间条件（T）和诱惑条件（X），用于测量模型局部响应与先前承诺之间的矛盾。该基准支持跨模型家族、解码策略和诱惑类型的定量比较。", "result": "开发了一个初步的评估基准，能够量化比较不同模型在\"自我控制\"能力上的差异，并揭示了微观层面的意志薄弱如何在多智能体系统中累积形成宏观层面的不稳定性。", "conclusion": "通过将不一致性重新定义为意志薄弱，这项工作将智能体行为与经典的能动性理论联系起来，为哲学、心理学和新兴的智能体AI科学之间搭建了经验桥梁，为分析多智能体系统中的\"阴谋\"或故意不对齐行为提供了新视角。"}}
{"id": "2512.05331", "pdf": "https://arxiv.org/pdf/2512.05331", "abs": "https://arxiv.org/abs/2512.05331", "authors": ["Sadat Shahriar", "Navid Ayoobi", "Arjun Mukherjee", "Mostafa Musharrat", "Sai Vishnu Vamsi"], "title": "Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats", "categories": ["cs.CL", "cs.LG"], "comment": "Published in RANLP 2025", "summary": "The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.", "AI": {"tldr": "该研究分析了粉红粘液新闻的特征，发现LLM可以显著降低现有检测系统性能达40%，并提出了一种能抵抗LLM对抗攻击的鲁棒学习框架，性能提升达27%。", "motivation": "粉红粘液新闻（自动生成的虚假本地新闻）威胁着2800万美国人的可靠信息来源，需要对其语言、风格和词汇特征进行细粒度分析以检测这类欺骗性文章。", "method": "进行全面的研究以揭示粉红粘液内容的区分模式，并提出基于这些洞察的检测策略。特别关注LLM修改这一新的对抗向量。", "result": "研究发现即使是消费者可访问的LLM也能显著削弱现有检测系统性能（F1分数下降高达40%）。提出的鲁棒学习框架能抵抗LLM对抗攻击。", "conclusion": "需要专门设计能够抵抗LLM对抗攻击并适应自动化粉红粘液新闻演变格局的检测系统，提出的框架显示性能提升高达27%。"}}
{"id": "2512.05530", "pdf": "https://arxiv.org/pdf/2512.05530", "abs": "https://arxiv.org/abs/2512.05530", "authors": ["Chuang Yu", "Jinmiao Zhao", "Mingxuan Zhao", "Yunpeng Liu", "Xiujun Shu", "Yuanhao Feng", "Bo Wang", "Xiangyu Yue"], "title": "MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models", "categories": ["cs.AI"], "comment": null, "summary": "Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of \"Understand -> Rethink -> Correct\", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND", "AI": {"tldr": "提出了MIND推理框架，通过多理由集成判别方法提升多模态大语言模型的推理能力，实现从被动模仿到主动判别推理的范式演进，在多个数据集上达到SOTA性能。", "motivation": "多模态大语言模型在推理任务中存在多理由语义建模有限、逻辑鲁棒性不足、易受复杂场景误导等问题，需要提升其人类化认知能力。", "method": "提出Rationale Augmentation and Discrimination (RAD)范式自动扩展数据集，设计Progressive Two-stage Correction Learning (P2CL)策略进行两阶段校正学习，采用Multi-rationale Contrastive Alignment (MCA)优化策略解决语义空间表示纠缠问题。", "result": "在涵盖科学、常识和数学场景的多个公共数据集上实现了最先进的性能表现。", "conclusion": "MIND框架为推进多模态大语言模型向更高层次认知智能发展提供了新视角，代码已开源。"}}
{"id": "2512.05364", "pdf": "https://arxiv.org/pdf/2512.05364", "abs": "https://arxiv.org/abs/2512.05364", "authors": ["Ananth Hariharan", "David Mortensen"], "title": "Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change", "categories": ["cs.CL"], "comment": null, "summary": "This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.", "AI": {"tldr": "本研究使用混合神经符号方法分析梵语2000年演变，挑战语言简化假设，发现形态复杂性并非减少而是重新分布，通过弱监督和置信加权集成实现52.4%特征检测率。", "motivation": "挑战语言演变即是简化的天真假设，为形态丰富、低资源语言（如梵语）的历时演变提供新的计算分析方法。", "method": "使用100+高精度正则表达式模式进行弱监督，生成伪标签微调多语言BERT，通过新颖的置信加权集成融合符号和神经输出。", "result": "系统达到52.4%的整体特征检测率，置信度与准确度强相关（Pearson r=0.92），低校准误差（ECE=0.043）。发现梵语形态复杂性动态重新分布：早期动词特征呈周期性下降，复杂性转向复合词扩展和新哲学术语出现。", "conclusion": "混合神经符号方法能为计算文献学提供可靠且可解释的历时语言分析，证明语言演变是复杂性重新分布而非简单简化。"}}
{"id": "2512.05576", "pdf": "https://arxiv.org/pdf/2512.05576", "abs": "https://arxiv.org/abs/2512.05576", "authors": ["Ting-Ting Xie", "Yixin Zhang"], "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning", "categories": ["cs.AI"], "comment": "2nd Place Solution to the CURE-Bench Competition @ NeurIPS 2025. Code available at https://github.com/June01/CureAgent", "summary": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.", "AI": {"tldr": "提出了Executor-Analyst框架，通过解耦工具执行和临床推理来解决小语言模型在临床诊断中的上下文利用失败问题，采用分层集成策略显著提升性能，无需端到端微调即可达到最先进水平。", "motivation": "当前基于小语言模型的临床智能体存在\"上下文利用失败\"问题，模型能够成功检索生物医学证据但无法基于这些信息进行诊断推理。", "method": "提出模块化架构Executor-Analyst框架，将专业TxAgents（执行器）与长上下文基础模型（分析师）协同工作，采用分层集成策略保持证据多样性，解决信息瓶颈问题。", "result": "框架在CURE-Bench上实现了最先进的性能，发现了上下文-性能悖论（超过12k token会引入噪声降低准确性）和动作空间维度灾难等重要扩展洞察。", "conclusion": "该方法展示了无需训练的架构工程的潜力，为下一代可信赖的AI驱动治疗提供了可扩展、敏捷的基础。"}}
{"id": "2512.05379", "pdf": "https://arxiv.org/pdf/2512.05379", "abs": "https://arxiv.org/abs/2512.05379", "authors": ["Taslim Mahbub", "Shi Feng"], "title": "Mitigating Self-Preference by Authorship Obfuscation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.", "AI": {"tldr": "本研究探讨了如何通过文本扰动技术减少语言模型评判中的自我偏好偏见，发现简单的同义词替换可以降低但无法完全消除这种偏见。", "motivation": "语言模型评判器在评估LM输出时存在自我偏好偏见，即倾向于选择自己生成的答案而非其他模型或人类的答案，这影响了评估的公正性。", "method": "采用黑盒扰动技术对评估候选文本进行修改，通过同义词替换等方式模糊文本来源，降低模型识别自己输出的能力。", "result": "简单的扰动（如少量词汇的同义词替换）可以有效减少自我偏好，但完全消除风格差异后自我偏好会重新出现。", "conclusion": "自我识别和自我偏好可能发生在多个语义层面，尽管初步结果有希望，但完全消除这种偏见仍具挑战性。"}}
{"id": "2512.05594", "pdf": "https://arxiv.org/pdf/2512.05594", "abs": "https://arxiv.org/abs/2512.05594", "authors": ["Roos M. Bakker", "Daan L. Di Scala", "Maaike H. T. de Boer", "Stephan A. Raaijmakers"], "title": "Ontology Learning with LLMs: A Benchmark Study on Axiom Identification", "categories": ["cs.AI", "cs.CL"], "comment": "Submitted to Semantic Web Journal, under review", "summary": "Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.", "AI": {"tldr": "本论文研究使用大型语言模型(LLMs)进行本体公理识别，创建了OntoAxiom基准测试集，比较了不同提示策略和模型性能，发现Axiom-by-Axiom方法效果更好，但性能因公理类型和本体领域而异。", "motivation": "本体开发需要大量建模和领域专业知识，自动化本体学习过程是一个挑战。随着自然语言处理技术特别是大型语言模型的发展，研究如何利用LLMs识别本体公理（定义类和属性间逻辑关系的基本组件）具有重要意义。", "method": "创建包含9个中等规模本体、17,118个三元组和2,771个公理的OntoAxiom基准测试集。测试12个LLMs在三种few-shot设置和两种提示策略（直接方法和逐个公理方法）下的性能，重点关注子类、不相交、子属性、定义域和值域公理。", "result": "逐个公理(AbA)提示策略比直接方法获得更高的F1分数。性能因公理类型而异，某些公理更难识别。领域影响性能（FOAF本体子类公理得分0.642，音乐本体仅0.218）。大模型优于小模型，但小模型在资源受限环境下仍可用。", "conclusion": "虽然LLMs性能尚不足以完全自动化公理识别，但能为本体工程师提供有价值的候选公理，支持本体的开发和精化工作。"}}
{"id": "2512.05387", "pdf": "https://arxiv.org/pdf/2512.05387", "abs": "https://arxiv.org/abs/2512.05387", "authors": ["Ting-Yao Hu", "Hema Swetha Koppula", "Hadi Pouransari", "Cem Koc", "Oncel Tuzel", "Raviteja Vemulapalli"], "title": "Learning from Self Critique and Refinement for Faithful LLM Summarization", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.", "AI": {"tldr": "SCRPO是一种自监督训练框架，通过利用LLM自身的批判和精炼能力构建偏好数据集，然后应用偏好学习来提高摘要的忠实度，无需额外推理计算或更强的教师模型。", "motivation": "LLM在长文本生成任务中经常产生幻觉（与输入内容不符的输出），现有方法需要额外推理计算或更强的教师模型，成本高且不实用。", "method": "提出SCRPO框架：1）利用LLM自身的批判和精炼能力构建偏好数据集；2）应用偏好学习训练同一LLM以提高摘要忠实度。", "result": "在XSUM、CNNDM和SAMSum三个摘要基准测试中，SCRPO在忠实度指标上优于最先进的自监督学习方法，同时保持或改进了其他摘要质量指标。", "conclusion": "SCRPO不仅提高了效率，相比推理时精炼方法还能产生更忠实的摘要，为减少LLM幻觉提供了一种实用且有效的解决方案。"}}
{"id": "2512.05619", "pdf": "https://arxiv.org/pdf/2512.05619", "abs": "https://arxiv.org/abs/2512.05619", "authors": ["Menghua Jiang", "Haokai Gao", "Shuhao Chen", "Yin Chen"], "title": "Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting", "categories": ["cs.AI"], "comment": "Accepted by ECAI 2025", "summary": "Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist", "AI": {"tldr": "提出了一种新颖的子句权重方案DeepDist，首次针对PMS和WPMS问题采用不同的权重更新条件，并引入新的初始化方法和优先满足单元子句与硬子句的decimation方法，显著提升了SLS求解器性能。", "motivation": "现有的(W)PMS随机局部搜索算法主要关注子句权重方案设计，但往往无法充分区分PMS和WPMS问题，通常采用统一的权重更新策略，忽略了两种问题类型的关键结构差异。", "method": "1) 提出新颖的子句权重方案，首次根据PMS和WPMS实例的不同条件更新子句权重；2) 引入新的初始化方法，更好地适应两种实例类型的独特特征；3) 提出优先满足单元子句和硬子句的decimation方法；4) 基于这些方法开发了新的SLS求解器DeepDist。", "result": "在最近MaxSAT评估的随时跟踪基准测试中，DeepDist优于最先进的SLS求解器。与TT-Open-WBO-Inc结合的混合求解器性能超过了MaxSAT评估2024冠军SPB-MaxSAT-c-Band和SPB-MaxSAT-c-FPS。", "conclusion": "所提出的方法有效解决了PMS和WPMS问题的结构差异问题，DeepDist求解器在性能上实现了显著提升，证明了该方法的有效性，代码已开源。"}}
{"id": "2512.05409", "pdf": "https://arxiv.org/pdf/2512.05409", "abs": "https://arxiv.org/abs/2512.05409", "authors": ["Ruixuan Huang", "Hao Zeng", "Hantao Huang", "Jinyuan Shi", "Minghui Yu", "Ian En-Hsu Yen", "Shuai Wang"], "title": "SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.", "AI": {"tldr": "该论文提出了一种稀疏量化格式(SQ-format)，统一了量化和稀疏化的数据格式，在保持精度的同时提升大语言模型后训练量化的效率，为下一代AI加速器提供设计思路。", "motivation": "现有的低比特量化和稀疏化技术由于硬件支持有限，难以平衡准确性和效率。W4A8只能达到与W8A8相同的峰值TOPS，而GPU支持的稀疏数据格式(2:4半结构化稀疏)由于精度损失很少被采用。", "method": "提出稀疏量化格式(SQ-format)，利用稀疏矩阵可以在高精度下加速，低精度矩阵乘法也可以相应加速的特点，实现性能和吞吐量之间的帕累托改进。该格式特别适用于具有异常值不等性状态的激活值，使其静态压缩成为可能。", "result": "展示了使用SQ-format实现的最先进的后训练量化性能，提出了支持该格式所需的硬件要求。", "conclusion": "SQ-format为量化和稀疏化提供了一个统一的硬件友好数据格式，能够在不损失精度的情况下提升效率，为下一代AI加速器的设计提供了探索和见解。"}}
{"id": "2512.05734", "pdf": "https://arxiv.org/pdf/2512.05734", "abs": "https://arxiv.org/abs/2512.05734", "authors": ["Jinfeng Zhong", "Emmanuel Bacry", "Agathe Guilloux", "Jean-François Muzy"], "title": "KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.", "AI": {"tldr": "KANFormer是一个结合扩张因果卷积网络和Transformer编码器的新模型，使用Kolmogorov-Arnold Networks提升非线性逼近能力，通过整合市场级和代理级信息来预测限价单的填充时间，在多个评估指标上优于现有方法。", "motivation": "现有模型仅依赖限价订单簿的快照序列，无法有效捕捉与执行可能性相关的模式，需要整合与LOB动态相关的代理行为和订单在队列中的位置信息。", "method": "结合扩张因果卷积网络和Transformer编码器，使用Kolmogorov-Arnold Networks增强非线性逼近能力，整合市场级和代理级信息，采用SHAP进行特征重要性分析。", "result": "在CAC 40指数期货数据上评估，KANFormer在校准（右删失对数似然、集成Brier分数）和区分（C指数、时间依赖AUC）指标上均优于现有工作。", "conclusion": "结合丰富的市场信号和表达性神经架构能够实现准确且可解释的填充概率预测，SHAP分析显示了特征随时间变化的重要性。"}}
{"id": "2512.05414", "pdf": "https://arxiv.org/pdf/2512.05414", "abs": "https://arxiv.org/abs/2512.05414", "authors": ["Akesh Gunathilakea", "Nadil Karunarathnea", "Tharusha Bandaranayakea", "Nisansa de Silvaa", "Surangika Ranathunga"], "title": "LMSpell: Neural Spell Checking for Low-Resource Languages", "categories": ["cs.CL"], "comment": null, "summary": "Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.", "AI": {"tldr": "本文是第一项关于预训练语言模型在拼写纠正（包括低资源语言）中有效性的实证研究，发现大语言模型在大型微调数据集上表现最佳，并发布了LMSpell工具包。", "motivation": "低资源语言的拼写纠正仍具挑战性，预训练语言模型的应用有限且缺乏跨模型比较，需要系统研究其在不同语言拼写纠正中的效果。", "method": "通过实证研究比较不同预训练语言模型（包括大语言模型、编码器模型和编码器-解码器模型）在拼写纠正任务上的表现，特别关注低资源语言，并使用僧伽罗语进行案例研究。", "result": "研究发现大语言模型在大型微调数据集上优于其他模型，即使该语言不在其预训练语料中；开发了LMSpell工具包并包含针对大语言模型幻觉的评估功能。", "conclusion": "大语言模型在拼写纠正任务中表现出色，特别是在数据充足的情况下，为低资源语言的拼写纠正提供了有效解决方案，LMSpell工具包将促进该领域的研究和应用。"}}
{"id": "2512.05753", "pdf": "https://arxiv.org/pdf/2512.05753", "abs": "https://arxiv.org/abs/2512.05753", "authors": ["Wencheng Cai", "Xuchao Gao", "Congying Han", "Mingqiang Li", "Tiande Guo"], "title": "A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.", "AI": {"tldr": "FARDA算法：基于深度强化学习的快速反干扰雷达部署框架，相比进化算法速度提升7000倍，同时保持相当的覆盖性能", "motivation": "现代战争中认知雷达快速部署对抗干扰是关键挑战，现有进化算法方法耗时且易陷入局部最优", "method": "将雷达部署建模为端到端任务，设计深度强化学习算法，开发集成神经模块感知热图信息和新奖励格式", "result": "达到与进化算法相当的覆盖性能，部署速度提升约7000倍，消融实验验证了各组件必要性", "conclusion": "FARDA框架通过神经网络高效推理成功解决了传统进化算法的局限性，为快速反干扰雷达部署提供了有效解决方案"}}
{"id": "2512.05430", "pdf": "https://arxiv.org/pdf/2512.05430", "abs": "https://arxiv.org/abs/2512.05430", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "Submitted to LREC 2026. This work is an evolution of our earlier preprint arXiv:2507.23334", "summary": "Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.", "AI": {"tldr": "该研究针对大语言模型在音乐问答中的知识不足问题，提出了MusWikiDB音乐知识向量数据库和ArtistMus基准测试集，通过检索增强生成(RAG)显著提升了音乐相关问答的准确性和推理能力。", "motivation": "大语言模型在预训练数据中音乐知识稀疏，导致音乐相关问答效果有限。音乐信息检索和计算音乐学领域缺乏基于艺术家元数据和历史背景的事实性音乐问答资源。", "method": "构建了MusWikiDB（包含144K音乐相关维基百科页面的320万段落向量数据库）和ArtistMus（包含500位艺术家的1000个问题基准测试集）。采用检索增强生成(RAG)方法，并进行了RAG风格的微调实验。", "result": "RAG显著提升事实准确性：开源模型最高提升56.8个百分点（如Qwen3 8B从35.0%提升至91.8%），接近专有模型性能。微调进一步提升了事实回忆和上下文推理能力。MusWikiDB比通用维基百科语料准确率高约6个百分点，检索速度快40%。", "conclusion": "MusWikiDB和ArtistMus为音乐信息检索和领域特定问答研究提供了重要资源，为音乐等文化丰富领域的检索增强推理奠定了基础，展示了RAG在专业知识密集型任务中的有效性。"}}
{"id": "2512.05760", "pdf": "https://arxiv.org/pdf/2512.05760", "abs": "https://arxiv.org/abs/2512.05760", "authors": ["Zeyuan Ma", "Wenqi Huang", "Guo-Huan Song", "Hongshu Guo", "Sijie Ma", "Zhiguang Cao", "Yue-Jiao Gong"], "title": "Evolutionary System 2 Reasoning: An Empirical Proof", "categories": ["cs.AI"], "comment": null, "summary": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.", "AI": {"tldr": "论文提出进化推理优化(ERO)框架，通过进化算法增强大语言模型的系统2推理能力，发现GPT-5等最新模型推理能力有限，但通过简单进化循环可以显著提升较弱模型的推理性能。", "motivation": "尽管大语言模型在特定任务上表现出色，但在通用智能和系统2推理(慢思考)能力方面仍存在不足。研究旨在探索机器智能能否像人类一样获得推理能力。", "method": "提出进化推理优化(ERO)框架：初始化多个LLM作为种群，使用进化策略进行优化，通过适者生存原则寻找具有强推理能力的个体模型。", "result": "实验发现：1) GPT-5等最新模型仍显示有限的系统2推理能力；2) 通过ERO的简单进化循环，相对较弱的Qwen-7B模型可以显著增强推理能力。", "conclusion": "进化优化方法可以有效提升大语言模型的推理能力，为机器智能获得类似人类的推理能力提供了可行路径。"}}
{"id": "2512.05464", "pdf": "https://arxiv.org/pdf/2512.05464", "abs": "https://arxiv.org/abs/2512.05464", "authors": ["Panatchakorn Anantaprayoon", "Nataliia Babina", "Jad Tarifi", "Nima Asgharbeygi"], "title": "Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 4 figures, to appear in AAAI 2026 AIGOV Workshop", "summary": "Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.", "AI": {"tldr": "该论文提出了集体代理(CA)作为更全面的对齐目标和动态对齐框架，使LLM能够自我迭代对齐，通过自动数据集生成和自我奖励机制实现可扩展的对齐方法。", "motivation": "传统基于人类偏好的对齐方法在AGI/ASI发展中可能不足，且资源密集难以扩展，需要更全面和可扩展的对齐解决方案。", "method": "提出集体代理(CA)作为统一开放的对齐价值，开发动态对齐框架包含：1)LLM自动生成训练数据集；2)自我奖励机制，策略模型评估自身输出并进行GRPO学习。", "result": "实验结果表明该方法成功将模型对齐到CA价值，同时保持了通用的NLP能力。", "conclusion": "动态对齐框架为超越传统对齐规范提供了可行路径，实现了更全面且可扩展的AI价值对齐方法。"}}
{"id": "2512.05765", "pdf": "https://arxiv.org/pdf/2512.05765", "abs": "https://arxiv.org/abs/2512.05765", "authors": ["Edward Y. Chang"], "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics", "categories": ["cs.AI", "cs.LG"], "comment": "13 pages, 3 figures", "summary": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.", "AI": {"tldr": "该论文反驳了LLMs只是模式匹配器无法实现AGI的观点，提出了UCCT理论和MACI架构，认为通过系统2的协调层可以实现基于LLMs的推理能力", "motivation": "回应批评者认为LLMs只是模式匹配器、无法实现真正推理和规划的观点，指出问题的关键不在于LLMs本身，而在于缺乏合适的协调机制", "method": "提出UCCT理论（语义锚定理论），将推理建模为受有效支持、表征失配和自适应锚定预算控制的相变过程；并开发MACI协调栈，实现诱饵机制、过滤机制和持久性机制", "result": "理论框架表明，通过适当的协调层，LLMs可以从无基础的生成转变为目标导向的推理，为解决AGI问题提供了新路径", "conclusion": "AGI的实现路径应该通过增强LLMs的协调能力来实现，而不是绕过LLMs，LLMs提供了必要的系统1基础，需要的是系统2的协调层"}}
{"id": "2512.05501", "pdf": "https://arxiv.org/pdf/2512.05501", "abs": "https://arxiv.org/abs/2512.05501", "authors": ["Panuthep Tasawong", "Jian Gang Ngui", "Alham Fikri Aji", "Trevor Cohn", "Peerat Limkonchotiwat"], "title": "SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures", "categories": ["cs.CL"], "comment": "Under review", "summary": "Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.", "AI": {"tldr": "SEA-SafeguardBench是首个针对东南亚语言的人类验证安全基准，包含8种语言、21,640个样本，覆盖通用、真实场景和内容生成三个子集，揭示现有LLMs和防护系统在东南亚文化安全场景中的表现不佳。", "motivation": "现有安全评估主要关注英语，忽略了语言和文化多样性，特别是东南亚语言在安全基准中代表性不足，机器翻译的英语数据无法捕捉低资源语言的细微差别和地区特有的安全问题。", "method": "创建SEA-SafeguardBench基准，包含8种东南亚语言的原生撰写样本（非机器翻译），涵盖通用、真实场景和内容生成三个子集，共21,640个人类验证样本。", "result": "实验结果表明，即使最先进的LLMs和防护系统在东南亚文化和有害场景中也面临挑战，与英语文本相比表现不佳。", "conclusion": "需要原生撰写的基准来反映本地规范和安全场景，SEA-SafeguardBench填补了东南亚语言安全评估的空白，强调了考虑语言和文化多样性在AI安全中的重要性。"}}
{"id": "2512.05824", "pdf": "https://arxiv.org/pdf/2512.05824", "abs": "https://arxiv.org/abs/2512.05824", "authors": ["Hafsa Akebli", "Adam Shephard", "Vincenzo Della Mea", "Nasir Rajpoot"], "title": "Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma", "categories": ["cs.AI", "cs.CV"], "comment": "4 pages, 2 figures", "summary": "Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.", "AI": {"tldr": "该研究开发了一个多模态肿瘤学智能体(MOA)，通过整合组织病理学工具和临床基因组数据推理，实现了对低级别胶质瘤IDH1突变的准确预测，性能优于传统基线方法。", "motivation": "低级别胶质瘤中的IDH1突变具有重要的临床意义，但现有预测方法存在局限性，需要整合多模态信息提高预测准确性。", "method": "开发了多模态肿瘤学智能体(MOA)，整合基于TITAN基础模型的组织病理学工具，并通过PubMed、Google Search和OncoKB对临床和基因组数据进行推理分析。", "result": "在TCGA-LGG队列的488名患者中评估，MOA无组织学工具时F1-score为0.826，优于临床基线0.798；结合组织学特征后达到最高性能0.912，超过组织学基线0.894和融合基线0.897。", "conclusion": "该智能体通过外部生物医学资源获取了互补的突变相关信息，能够实现准确的IDH1突变预测，为低级别胶质瘤的精准诊疗提供了有效工具。"}}
{"id": "2512.05537", "pdf": "https://arxiv.org/pdf/2512.05537", "abs": "https://arxiv.org/abs/2512.05537", "authors": ["Namu Park", "Farzad Ahmed", "Zhaoyi Sun", "Kevin Lybarger", "Ethan Breinhorst", "Julie Hu", "Ozlem Uzuner", "Martin Gunn", "Meliha Yetisgen"], "title": "Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches", "categories": ["cs.CL"], "comment": null, "summary": "Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.\n  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.\n  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.\n  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.", "AI": {"tldr": "大语言模型通过病灶标记和解剖感知提示在放射学报告中检测需要随访的偶发瘤方面，显著优于传统监督学习方法，达到接近人类专家的性能水平。", "motivation": "当前文档级分类系统在细粒度、病灶级别的偶发瘤检测方面存在局限性，需要评估大语言模型在此任务上的表现。", "method": "使用400份标注的放射学报告数据集，比较三种监督学习的transformer编码器与四种生成式LLM配置，采用病灶标记输入和解剖感知提示的新推理策略，使用类别特异性F1分数评估性能。", "result": "解剖感知的GPT-OSS-20b模型表现最佳，偶发瘤阳性macro-F1达到0.79，超越所有监督基线模型（最高0.70），接近人类标注者一致性水平（0.76）。解剖感知带来显著性能提升，集成方法进一步提升至0.90。", "conclusion": "结合结构化病灶标记和解剖上下文的生成式LLM显著优于传统监督编码器，达到接近人类专家的性能，为放射学工作流程中的自动化偶发发现监测提供了可靠、可解释的途径。"}}
{"id": "2512.05836", "pdf": "https://arxiv.org/pdf/2512.05836", "abs": "https://arxiv.org/abs/2512.05836", "authors": ["Clarissa W. Ong", "Hiba Arnaout", "Kate Sheehan", "Estella Fox", "Eugen Owtscharow", "Iryna Gurevych"], "title": "Using Large Language Models to Create Personalized Networks From Therapy Sessions", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.", "AI": {"tldr": "本研究开发了一个端到端的LLM管道，能够从治疗转录本自动生成客户心理网络，用于支持个案概念化和治疗计划，专家评估显示该方法在临床效用和可解释性方面优于直接提示方法。", "motivation": "心理治疗个性化需要基于个性化网络选择治疗模块，但估计个性化网络通常需要密集的纵向数据，这并不总是可行的。本研究旨在利用LLMs提高网络驱动治疗个性化的可扩展性。", "method": "使用77个治疗转录本，标注了3364个心理过程及其维度，应用上下文学习联合识别心理过程和维度，采用两步法将过程组织成临床有意义的聚类网络，并生成解释增强的聚类间关系。", "result": "方法在少量训练样本下仍取得高性能，专家评估显示多步方法生成的网络在临床效用和可解释性方面优于直接提示方法（90%专家偏好），临床相关性、新颖性和有用性评分达72-75%。", "conclusion": "研究证明了使用LLMs从治疗转录本创建临床相关网络的可行性，优势包括自下而上的个案概念化和潜在主题识别，未来研究应检验这些网络相对于其他个性化治疗方法是否能改善治疗结果。"}}
{"id": "2512.05580", "pdf": "https://arxiv.org/pdf/2512.05580", "abs": "https://arxiv.org/abs/2512.05580", "authors": ["Aurprita Mahmood", "Sabrin alam", "Neloy kumer Sagor", "Md. Abdul Hadi", "Md. Sehab Al Islam", "Minhajul Islam"], "title": "Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems", "categories": ["cs.CL"], "comment": null, "summary": "Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.", "AI": {"tldr": "本研究系统评估了Tree-of-Thought推理方法在孟加拉语数学应用题上的效果，相比标准提示和Chain-of-Thought方法，ToT在大型语言模型中能进一步提升准确率5个百分点，达到88%的准确度。", "motivation": "数学应用题需要语言理解和多步数值推理，Chain-of-Thought的线性结构容易传播错误，限制了整体效果。需要探索更有效的推理方法来解决低资源语言如孟加拉语的数学问题。", "method": "使用SOMADHAN数据集，选取100个代表性孟加拉语数学问题，在多个大型语言模型（GPT-OSS和LLaMA变体）上比较标准提示、Chain-of-Thought和Tree-of-Thought三种推理策略的效果。", "result": "CoT将基线准确率从78%提升到83%，ToT进一步提升了5个百分点，在GPT-OSS-120B上达到88%准确度。ToT在中大型模型中效果显著，但在小模型中优势较小。", "conclusion": "Tree-of-Thought是解决低资源语言数学问题的强大框架，相比CoT能提供更可靠和全局一致的结果，为多语言NLP中更好的推理策略铺平了道路。"}}
{"id": "2512.05925", "pdf": "https://arxiv.org/pdf/2512.05925", "abs": "https://arxiv.org/abs/2512.05925", "authors": ["Federico Bianchi", "Yongchan Kwon", "Zachary Izzo", "Linjun Zhang", "James Zou"], "title": "To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.", "AI": {"tldr": "本研究使用基于GPT-5的论文正确性检查器分析顶级AI会议期刊论文，发现发表论文中存在显著数量的客观错误，且错误数量随时间增加，AI检查器识别错误的准确率达83.2%，并能对75.8%的错误提出正确修正方案。", "motivation": "同行评审出版物是研究知识的基础，但其中的错误会在文献中传播，造成后续研究的混淆和可复现性问题。研究加速和评审系统压力使得错误更难被发现和避免。", "method": "开发基于GPT-5的论文正确性检查器，系统识别顶级AI会议期刊论文中的客观错误（公式、推导、计算、图表等可验证错误），排除主观考量因素。", "result": "发现论文包含不可忽视的客观错误数量，且平均错误数随时间增加（如NeurIPS从2021年3.8个增至2025年5.9个）。AI检查器识别316个潜在错误，经专家确认263个为真实错误，准确率83.2%。AI能对75.8%的错误提出正确修正。", "conclusion": "前沿大语言模型在检测和修正已发表论文中的客观错误方面具有巨大潜力，有助于建立更坚实的知识基础，减少文献混淆并增强可复现性。"}}
{"id": "2512.05647", "pdf": "https://arxiv.org/pdf/2512.05647", "abs": "https://arxiv.org/abs/2512.05647", "authors": ["Giorgos Antoniou", "Giorgos Filandrianos", "Aggelos Vlachos", "Giorgos Stamou", "Lampros Kollimenos", "Konstantinos Skianis", "Michalis Vazirgiannis"], "title": "A Greek Government Decisions Dataset for Public-Sector Analysis and Insight", "categories": ["cs.CL"], "comment": null, "summary": "We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.", "AI": {"tldr": "本文介绍了从希腊政府透明度平台Diavgeia获取的100万份政府决策的机器可读语料库，包含高质量Markdown文本和可复现的提取流程，并进行了定性分析、RAG任务评估，展示了大规模公共部门语料库在信息获取和透明度方面的潜力。", "motivation": "构建一个开放、机器可读的希腊政府决策语料库，支持政府文档的结构化检索和推理，促进信息透明度和先进的信息访问技术发展。", "method": "从Diavgeia平台提取100万份决策文档，转换为高质量Markdown文本；设计可复现的提取流程；进行定性分析探索模板模式；设计RAG任务并评估基线系统。", "result": "成功创建了大规模高质量政府决策语料库，RAG评估显示了该系统在检索和推理政府文档方面的潜力，可作为LLM预训练和微调的高价值材料。", "conclusion": "该语料库为法律和政府领域的专业模型开发提供了基础，支持领域适应、知识基础生成和可解释AI的新方法，同时讨论了局限性和未来方向，并公开了数据和代码。"}}
{"id": "2512.05930", "pdf": "https://arxiv.org/pdf/2512.05930", "abs": "https://arxiv.org/abs/2512.05930", "authors": ["Shima Imani", "Seungwhan Moon", "Adel Ahmadyan", "Lu Zhang", "Kirmani Ahmed", "Babak Damavandi"], "title": "PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.", "AI": {"tldr": "PRiSM是一个用于评估视觉语言模型在科学领域推理能力的动态多模态基准，包含24,750个大学水平的物理和数学问题，通过Python代码生成和验证提供细粒度评估。", "motivation": "当前评估视觉语言模型在科学领域的基准存在局限性：缺乏中间推理步骤、对变化的鲁棒性不足、缺少科学正确性验证机制，无法满足概念理解、符号推理和形式法则遵循的要求。", "method": "开发PRiSM合成基准，使用基于代理的PrismAgent流水线生成结构化问题实例，包含动态文本和视觉输入、生成图像、可执行Python代码作为真实值生成和验证，以及详细的逐步推理过程。", "result": "提出了五个针对性评估任务（泛化、符号程序合成、扰动鲁棒性、推理校正和歧义解析），通过全面评估现有VLM揭示了其在科学推理能力方面的局限性和失败模式。", "conclusion": "PRiSM基准能够深入洞察多模态视觉语言模型的科学推理能力，揭示其不确定性行为和局限性，为科学领域的AI评估提供了更全面的框架。"}}
{"id": "2512.05658", "pdf": "https://arxiv.org/pdf/2512.05658", "abs": "https://arxiv.org/abs/2512.05658", "authors": ["Pietro Ferrazzi", "Aitor Soroa", "Rodrigo Agerri"], "title": "Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Under Review", "summary": "Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.", "AI": {"tldr": "本文提出了一种基于医学知识检索增强的多语言推理轨迹生成方法，在英语、意大利语和西班牙语中生成50万条医学推理轨迹，通过上下文学习和监督微调显著提升医学问答性能，在8B参数LLM中达到最先进结果。", "motivation": "现有医学问答方法主要依赖英语和通用LLM的知识蒸馏，存在医学知识可靠性问题，需要开发基于事实医学知识的多语言推理能力。", "method": "使用检索增强生成方法，从维基百科医学信息中生成多语言推理轨迹，扩展MedQA和MedMCQA数据集到意大利语和西班牙语，包含50万条推理轨迹。", "result": "在领域内和领域外医学问答基准测试中，该方法通过上下文学习和监督微调都显著提升了性能，在8B参数LLM中取得了最先进的结果。", "conclusion": "这些资源可以支持开发更安全、更透明的多语言临床决策支持工具，作者发布了完整的资源套件包括推理轨迹、翻译的QA数据集、医学维基百科和微调模型。"}}
{"id": "2512.05943", "pdf": "https://arxiv.org/pdf/2512.05943", "abs": "https://arxiv.org/abs/2512.05943", "authors": ["Shima Imani", "Seungwhan Moon", "Lambert Mathias", "Lu Zhang", "Babak Damavandi"], "title": "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.", "AI": {"tldr": "TRACE框架通过辅助推理集(ARS)来透明评估视觉语言模型的数学和科学推理过程，而不仅仅是最终答案，能够发现标准评估忽略的推理错误。", "motivation": "当前大型视觉语言模型在数学和科学推理方面存在可靠性问题，标准最终答案评估会掩盖推理错误，导致无声故障持续存在。", "method": "引入TRACE框架，利用辅助推理集(ARS)将复杂问题分解为子问题对，通过基于一致性的指标评估中间步骤，诊断推理轨迹。", "result": "实验表明ARS的一致性程度与最终答案正确性相关，能够精确定位推理失败步骤，并为模型改进提供可操作信号。", "conclusion": "TRACE定义了区分可靠与不可靠推理路径的置信区域，支持有效的过滤、调试和模型优化，提升了推理评估的透明度和可靠性。"}}
{"id": "2512.05665", "pdf": "https://arxiv.org/pdf/2512.05665", "abs": "https://arxiv.org/abs/2512.05665", "authors": ["Shuai Dong", "Siyuan Wang", "Xingyu Liu", "Zhongyu Wei"], "title": "Interleaved Latent Visual Reasoning with Selective Perceptual Modeling", "categories": ["cs.CL", "cs.CV"], "comment": "11 pages, 6 figures. Code available at https://github.com/XD111ds/ILVR", "summary": "Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.", "AI": {"tldr": "ILVR框架通过潜在视觉表示和动量教师模型，解决了多模态大语言模型中视觉重新编码计算成本高的问题，实现了精确感知建模与动态推理的统一。", "motivation": "现有的多模态大语言模型在交错推理中存在计算成本高的问题，要么过度压缩特征牺牲感知精度，要么因静态结构无法处理动态问题。", "method": "提出ILVR框架，交错生成文本和潜在视觉表示；使用动量教师模型从辅助图像中选择性提取相关特征作为稀疏监督目标；自适应选择机制引导模型生成上下文感知的视觉信号。", "result": "在多模态推理基准测试中显著优于现有方法，有效弥合了细粒度感知和顺序多模态推理之间的差距。", "conclusion": "ILVR成功统一了动态状态演化与精确感知建模，为多模态推理提供了高效且精确的解决方案。"}}
{"id": "2512.05946", "pdf": "https://arxiv.org/pdf/2512.05946", "abs": "https://arxiv.org/abs/2512.05946", "authors": ["Truong Thanh Hung Nguyen", "Truong Thinh Nguyen", "Hung Cao"], "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem", "categories": ["cs.AI", "cs.ET", "cs.SE"], "comment": "Quantum Software Engineering Practices at The 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026)", "summary": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.", "AI": {"tldr": "论文提出了VQR-DQN方法，将变分量子电路与Rainbow DQN结合，用于人力资源分配问题，相比传统方法取得了显著性能提升", "motivation": "传统深度强化学习方法在资源分配问题上受限于组合复杂性和函数逼近器的表达能力，需要更强大的表示能力来处理NP难问题", "method": "提出Variational Quantum Rainbow DQN (VQR-DQN)，将环形拓扑变分量子电路与Rainbow DQN集成，利用量子叠加和纠缠特性，将人力资源分配问题建模为具有组合动作空间的马尔可夫决策过程", "result": "在四个HRAP基准测试中，VQR-DQN相比随机基线减少了26.8%的标准化makespan，比Double DQN和经典Rainbow DQN性能提升4.9-13.4%", "conclusion": "量子增强的深度强化学习在大规模资源分配问题中具有巨大潜力，电路表达能力、纠缠和策略质量之间存在理论联系，实验结果验证了量子方法的优势"}}
{"id": "2512.05671", "pdf": "https://arxiv.org/pdf/2512.05671", "abs": "https://arxiv.org/abs/2512.05671", "authors": ["Zhitao He", "Haolin Yang", "Zeyu Qin", "Yi R Fung"], "title": "MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation", "categories": ["cs.CL"], "comment": "Work In Progress", "summary": "The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.", "AI": {"tldr": "该研究开发了ClinEdu多智能体教学模拟器和ClinTeach数据集，并基于此训练了首个多模态苏格拉底式医学导师MedTutor-R1，用于解决临床医学教育中专家指导不足的问题，特别关注团队协作推理能力培养。", "motivation": "临床医学教育面临专家指导需求增长与资源稀缺之间的巨大差距，现有研究主要关注一对一知识传授，忽视了团队协作推理这一关键临床技能。", "method": "开发ClinEdu多智能体教学模拟器（含个性化患者和多样化学生群体），构建ClinTeach苏格拉底教学对话数据集，训练MedTutor-R1多模态导师（指令调优+强化学习优化），采用三轴评估标准（结构保真度、分析质量、临床安全性）进行奖励优化。", "result": "MedTutor-R1在教学评分上比基础模型提升超过20%，性能与o3相当，且在处理不同学生数量时表现出高适应性。", "conclusion": "研究证明了教学模拟器ClinEdu的有效性，MedTutor-R1在临床医学教育中展现出了优秀的教学能力和适应性，为规模化医学教育提供了有前景的解决方案。"}}
{"id": "2512.05954", "pdf": "https://arxiv.org/pdf/2512.05954", "abs": "https://arxiv.org/abs/2512.05954", "authors": ["Shima Imani", "Seungwhan Moon", "Adel Ahmadyan", "Lu Zhang", "Kirmani Ahmed", "Babak Damavandi"], "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code", "categories": ["cs.AI"], "comment": null, "summary": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems", "AI": {"tldr": "SymPyBench是一个包含15,045个大学物理问题的大规模合成基准测试，具有完全参数化、结构化推理步骤和可执行代码生成真实解的特点，包含三种题型和三个新颖评估指标", "motivation": "为了解决现有科学推理基准测试缺乏多样性、可扩展性和动态评估能力的问题，需要创建一个能够测试模型在不同问题变体上一致性和鲁棒性的基准", "method": "创建了15,045个完全参数化的物理问题，每个问题都配有结构化推理步骤和生成真实解的Python代码，包含MC-Symbolic、MC-Numerical和free-form三种题型，并引入了Consistency Score、Failure Rate、Confusion Rate三个新颖评估指标", "result": "通过对最先进的指令调优语言模型进行实验，揭示了这些模型在科学推理方面的优势和局限性，表明SymPyBench能够有效评估模型的鲁棒性和可解释性", "conclusion": "SymPyBench为开发更鲁棒和可解释的推理系统奠定了基础，能够全面评估AI模型在科学问题解决中的表现"}}
{"id": "2512.05681", "pdf": "https://arxiv.org/pdf/2512.05681", "abs": "https://arxiv.org/abs/2512.05681", "authors": ["Tereza Novotna", "Jakub Harasta"], "title": "Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods", "categories": ["cs.CL", "cs.AI"], "comment": "The manuscript has been accepted for presentation as a short paper at the 38th International Conference on Legal Knowledge and Information Systems (JURIX 2025) in Torino, Italy", "summary": "Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.", "AI": {"tldr": "比较OpenAI通用嵌入模型与捷克宪法法院判决领域特定的BERT模型在案例检索任务中的表现，OpenAI模型在多个评估指标上显著优于领域预训练的BERT模型", "motivation": "案例法检索是耗时的任务，需要比较通用模型与领域特定模型在司法文本检索中的效果，特别是在存在噪声标签的真实数据库环境下", "method": "使用三种设置比较两种模型：OpenAI通用嵌入器和在3万条判决上训练的领域特定BERT模型。提出噪声感知评估框架，包括IDF加权关键词重叠作为分级相关性、双阈值二值化、配对bootstrap显著性检验和nDCG诊断分析", "result": "尽管nDCG绝对值较低（在噪声标签下预期如此），OpenAI嵌入器在@10/@20/@100等多个截断点上都显著优于领域预训练的BERT模型，差异具有统计显著性", "conclusion": "通用模型在司法案例检索中表现优于领域特定模型，提出的评估框架能够有效处理来自传统司法数据库的异构标签噪声，诊断显示低绝对值源于标签漂移和强理想标准而非模型效用不足"}}
{"id": "2512.05700", "pdf": "https://arxiv.org/pdf/2512.05700", "abs": "https://arxiv.org/abs/2512.05700", "authors": ["Ben Malin", "Tatiana Kalganova", "Nikolaos Boulgouris"], "title": "Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, conference paper", "summary": "We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.", "AI": {"tldr": "提出一种通过融合多个基础忠实度指标来提升大语言模型忠实度评估准确性的方法，使用基于树模型的方法结合人类判断来优化指标融合策略。", "motivation": "当前大语言模型的忠实度评估存在准确性问题，需要一种更可靠的方法来评估模型输出的真实性，以增强模型可信度并扩展应用场景。", "method": "将多个基础忠实度指标融合成组合指标，使用基于树模型的策略来确定各指标的重要性权重，该方法基于人类对LLM响应忠实度的判断进行驱动。", "result": "融合后的指标在所有测试领域的忠实度评估中都显示出与人类判断更强的相关性。", "conclusion": "该方法显著提升了LLM忠实度评估的准确性，为模型在更广泛场景中的可信部署提供了支持，同时创建了跨领域的数据集便于复现和测试。"}}
{"id": "2512.05732", "pdf": "https://arxiv.org/pdf/2512.05732", "abs": "https://arxiv.org/abs/2512.05732", "authors": ["Ippokratis Pantelidis", "Korbinian Randl", "Aron Henriksson"], "title": "Efficient Text Classification with Conformal In-Context Learning", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 4 tables, 2 figures", "summary": "Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.", "AI": {"tldr": "CICLe框架通过结合轻量级基础分类器和Conformal Prediction来指导LLM提示，在多种NLP分类任务中显著提升效率，减少提示长度和样本需求，特别适合类别不平衡任务。", "motivation": "LLM在文本分类中虽然表现出强大的上下文学习能力，但其效果严重依赖提示设计且计算成本高昂，需要更高效的资源利用方法。", "method": "采用Conformal In-Context Learning (CICLe)框架，集成轻量级基础分类器和Conformal Prediction，通过自适应减少候选类别集合来指导LLM提示。", "result": "CICLe在样本充足时优于基础分类器和少样本提示基线，在低数据场景下表现相当；减少样本数量达34.45%，提示长度减少25.16%，并能使用更小模型保持竞争力。", "conclusion": "CICLe是实用且可扩展的高效文本分类方法，结合了传统分类器的鲁棒性和LLM的适应性，在数据和计算效率方面取得显著提升。"}}
{"id": "2512.05747", "pdf": "https://arxiv.org/pdf/2512.05747", "abs": "https://arxiv.org/abs/2512.05747", "authors": ["Jinlong Liu", "Mohammed Bahja", "Venelin Kovatchev", "Mark Lee"], "title": "Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.", "AI": {"tldr": "该论文提出了一个使用GRPO和多奖励机制的训练框架，用于风格条件化故事生成，在马克·吐温作品风格生成任务上表现优于GPT-4o等大型模型。", "motivation": "现有大型语言模型在开放式故事生成方面表现优异，但在细粒度风格控制方面仍有限制，现有方法往往依赖浅层线索来模拟作者风格，缺乏稳健的评估方法。", "method": "采用Group Relative Policy Optimization (GRPO)训练框架和自定义多奖励设置，风格奖励来自使用作者验证信号微调的句子变换器，结合内容和完整性分数来稳定长篇叙事生成。", "result": "8B参数模型在作者验证风格指标上优于GPT-4o和Claude Sonnet 4等大型基线模型，获得0.628的风格分数和具有竞争力的内容质量。", "conclusion": "研究表明中等规模模型通过任务特定训练可以实现代理风格生成的可行性，虽然输出明显风格对齐，但叙事完整性仍是挑战，未来需要更好地建模全局连贯性和故事结局。"}}
{"id": "2512.05832", "pdf": "https://arxiv.org/pdf/2512.05832", "abs": "https://arxiv.org/abs/2512.05832", "authors": ["Yifei Tong"], "title": "Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments", "categories": ["cs.CL", "cs.CY"], "comment": "12 pages, 5 figures, 1 table. Includes appendix. Code available at: https://github.com/1TSHARUKA/Emotional_Interruption_Analysis", "summary": "This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.", "AI": {"tldr": "研究分析最高法院口头辩论中的打断行为对律师发言内容和情感的影响，发现打断不会显著改变论点内容，但对女性律师的打断包含更多负面情感。", "motivation": "探讨最高法院口头辩论中打断行为如何影响律师的语义内容和情感语调，特别关注司法话语中的性别差异。", "method": "使用ConvoKit最高法院语料库（2010-2019），分析12,663个律师-法官互动片段，通过GloVe句子嵌入量化语义变化，基于词典分析情感。", "result": "打断前后的语义相似度保持较高水平，但针对女性律师的打断包含显著更高的负面情感。", "conclusion": "研究深化了对精英机构环境中性别化沟通的实证理解，展示了计算语言学方法在研究司法程序中的权力、话语和公平方面的价值。"}}
{"id": "2512.05858", "pdf": "https://arxiv.org/pdf/2512.05858", "abs": "https://arxiv.org/abs/2512.05858", "authors": ["Savir Basil", "Ina Shapiro", "Dan Shapiro", "Ethan Mollick", "Lilach Mollick", "Lennart Meincke"], "title": "Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy", "categories": ["cs.CL"], "comment": null, "summary": "This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.\n  We tested three approaches:\n  -In-Domain Experts: Assigning the model an expert persona (\"you are a physics expert\") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).\n  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona (\"you are a physics expert\") not matched to the problem type (law problems) resulted in marginal differences.\n  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.\n  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.", "AI": {"tldr": "研究表明，为AI模型分配人物角色（专家或低知识水平角色）在提高困难多选题准确性方面效果有限，专家角色无显著提升，低知识角色反而降低准确性", "motivation": "探讨为AI模型分配不同人物角色是否能够提升其在专业领域困难多选题上的表现，为商业、教育和政策决策者提供技术参考", "method": "在GPQA Diamond和MMLU-Pro两个研究生水平的多选题基准上测试6个模型，比较三种角色分配方式：领域匹配专家角色、领域不匹配专家角色、低知识水平角色，与无角色基线进行对比", "result": "专家角色对性能无显著影响（除Gemini 2.0 Flash外），领域不匹配专家角色有时会降低性能，低知识角色普遍损害准确性，角色提示总体上未提高准确性", "conclusion": "人物角色提示在提高事实性表现方面效果有限，虽然可能用于改变输出语气等其他目的，但在提升准确性方面不是有效策略"}}
{"id": "2512.05863", "pdf": "https://arxiv.org/pdf/2512.05863", "abs": "https://arxiv.org/abs/2512.05863", "authors": ["Tasnimul Hassan", "Md Faisal Karim", "Haziq Jeelani", "Elham Behnam", "Robert Green", "Fayeq Jeelani Syed"], "title": "Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.", "AI": {"tldr": "基于检索增强生成(RAG)的医疗问答系统，通过领域知识检索结合开源LLM，显著提高医疗问答的准确性和减少幻觉现象", "motivation": "直接将大语言模型应用于医疗领域面临事实准确性不足和产生幻觉的问题，需要结合领域专业知识来提升可靠性", "method": "使用LoRA方法微调LLaMA 2和Falcon开源模型，结合医疗文献检索系统来为LLM提供领域知识支持", "result": "在PubMedQA数据集上达到71.8%的准确率，相比零样本基线的55.4%有显著提升，同时减少了约60%的无支持内容", "conclusion": "RAG增强的开源LLM在生物医学问答中具有巨大潜力，为实际临床信息学应用提供了可靠解决方案"}}
{"id": "2512.05959", "pdf": "https://arxiv.org/pdf/2512.05959", "abs": "https://arxiv.org/abs/2512.05959", "authors": ["David Anugraha", "Patrick Amadeus Irawan", "Anshul Singh", "En-Shiun Annie Lee", "Genta Indra Winata"], "title": "M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.", "AI": {"tldr": "M4-RAG是一个大规模多语言多模态检索增强生成基准，涵盖42种语言和56种方言，包含8万多对文化多样性图像-问题对，用于评估跨语言和跨模态的检索增强视觉问答性能。", "motivation": "现有的视觉语言模型在视觉问答中表现良好但受限于静态训练数据，检索增强生成虽然能获取最新多语言信息，但多语言多模态RAG研究仍不足。", "method": "构建包含数百万精心策划的多语言文档的受控检索环境，创建M4-RAG基准数据集，涵盖42种语言和56种方言，包含80,000+文化多样性图像-问题对。", "result": "系统评估显示RAG对小型VLMs有益，但对大型模型效果不佳甚至性能下降，暴露了模型大小与当前检索效果之间的关键不匹配问题。", "conclusion": "M4-RAG为开发能够跨语言、模态和文化语境无缝推理的下一代RAG系统奠定了基础，揭示了模型规模与检索效率之间需要更好协调的重要性。"}}
