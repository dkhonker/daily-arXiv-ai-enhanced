{"id": "2511.19648", "pdf": "https://arxiv.org/pdf/2511.19648", "abs": "https://arxiv.org/abs/2511.19648", "authors": ["Manil Shrestha", "Edward Kim"], "title": "Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.", "AI": {"tldr": "提出了两种混合算法解决多跳知识图谱问答中的效率和可验证性问题：LLM引导规划使用单次LLM调用预测关系序列，嵌入引导神经搜索完全消除LLM调用，通过知识蒸馏将规划能力压缩到小模型中。", "motivation": "多跳知识图谱问答面临组合爆炸问题，现有方法依赖昂贵的LLM推理且缺乏可验证的知识基础。", "method": "1) LLM引导规划：单次LLM调用预测关系序列+BFS执行；2) 嵌入引导神经搜索：融合文本和图嵌入的轻量级边评分器；3) 知识蒸馏压缩模型。", "result": "LLM引导规划达到接近完美的准确率(micro-F1>0.90)，嵌入引导搜索实现100倍加速且保持竞争力准确率，4B参数蒸馏模型匹配大模型性能。", "conclusion": "可验证的多跳推理不需要大规模模型，而是需要结合符号结构和学习表示的架构归纳偏置，结构化规划比直接答案生成更具可迁移性。"}}
{"id": "2511.19719", "pdf": "https://arxiv.org/pdf/2511.19719", "abs": "https://arxiv.org/abs/2511.19719", "authors": ["Mobina Mehrazar", "Mohammad Amin Yousefi", "Parisa Abolfath Beygi", "Behnam Bahrak"], "title": "Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.", "AI": {"tldr": "该研究评估了LLM在波斯语情感分类任务中生成解释的忠实性，发现虽然模型分类性能良好，但其解释与人类标注存在显著差异，提示策略对忠实性影响有限。", "motivation": "评估低资源语言（波斯语）中LLM生成解释的忠实性，因为现有研究主要关注高资源语言，而LLM在多语言和低资源环境中的可靠性需要验证。", "method": "通过比较模型和人类标注者识别的影响词来评估解释忠实性，使用基于token级对数概率的置信度分数，测试两种提示策略（预测-解释和解释-预测）的效果。", "result": "LLM在分类任务上表现良好，但生成的解释往往偏离忠实推理，模型解释之间的一致性高于与人类判断的一致性。", "conclusion": "当前解释方法和指标存在局限性，需要开发更稳健的方法来确保LLM在多语言和低资源环境中的可靠性。"}}
{"id": "2511.19739", "pdf": "https://arxiv.org/pdf/2511.19739", "abs": "https://arxiv.org/abs/2511.19739", "authors": ["Richard J. Young", "Alice M. Matthews"], "title": "Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation", "categories": ["cs.CL", "cs.LG"], "comment": "25 pages, 13 figures, 5 tables", "summary": "Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.", "AI": {"tldr": "本研究评估了10种基于Transformer的心脏病学文本嵌入模型，发现编码器架构（特别是BioLinkBERT）在领域特定性能上优于更大的解码器模型，且计算资源需求更少。", "motivation": "临床自然语言处理需要领域特定的文本嵌入，但缺乏对模型架构的系统性比较研究。", "method": "使用LoRA微调方法在106,535个心脏病学文本对（来自权威医学教科书）上适配10种Transformer模型。", "result": "编码器架构（BioLinkBERT）获得最佳领域特定性能（分离分数：0.510），性能优于更大的解码器模型。", "conclusion": "研究挑战了'模型越大嵌入越好'的假设，为临床NLP系统开发提供实用指导，所有资源已公开以支持可重复研究。"}}
{"id": "2511.19757", "pdf": "https://arxiv.org/pdf/2511.19757", "abs": "https://arxiv.org/abs/2511.19757", "authors": ["Colton Casto", "Anna Ivanova", "Evelina Fedorenko", "Nancy Kanwisher"], "title": "What does it mean to understand language?", "categories": ["cs.CL"], "comment": null, "summary": "Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.", "AI": {"tldr": "论文提出语言理解需要将信息从核心语言系统导出到其他脑区，以构建丰富的心理模型，并认为认知神经科学的进展为直接验证这一假设提供了基础和方法。", "motivation": "语言理解不仅是提取语言输入的表层意义，还需要构建描述情境的丰富心理模型，但大脑核心语言系统的处理能力有限，需要其他脑区的参与。", "method": "回顾现有证据支持这一假设，并利用认知神经科学的概念基础和方法来直接验证。", "result": "提出了语言理解需要多脑区协作的新视角，为揭示语言理解的认知和神经机制开辟了新策略。", "conclusion": "深度理解语言需要将信息从语言系统导出到处理感知、运动、心理模型和世界知识的其他脑区，这一假设可通过现代神经科学方法直接检验。"}}
{"id": "2511.19577", "pdf": "https://arxiv.org/pdf/2511.19577", "abs": "https://arxiv.org/abs/2511.19577", "authors": ["Abhay Goyal", "Navin Kumar", "Kimberly DiMeola", "Rafael Trujillo", "Soorya Ram Shimgekar", "Christian Poellabauer", "Pi Zonooz", "Ermonda Gjoni-Markaj", "Declan Barry", "Lynn Madden"], "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.", "AI": {"tldr": "本研究探讨使用可穿戴设备和AI技术监测慢性疼痛与阿片类药物使用障碍患者的疼痛峰值，发现机器学习模型预测效果较好（准确率>0.7），但大语言模型在此领域的应用效果有限。", "motivation": "慢性疼痛(CP)和阿片类药物使用障碍(OUD)是相互关联的常见慢性疾病，目前缺乏针对接受MOUD治疗患者的循证综合治疗方案。可穿戴设备有潜力监测患者信息并为治疗开发提供支持。", "method": "使用可穿戴设备收集患者数据，应用多种AI方法（包括机器学习模型和大语言模型）分析疼痛峰值的临床相关性。", "result": "机器学习模型在预测疼痛峰值方面取得了相对较高的准确率（>0.7），但大语言模型在提供疼痛峰值洞察方面表现有限。", "conclusion": "实时监测结合先进AI模型可促进疼痛峰值的早期检测，支持个性化干预。鉴于大语言模型整体表现有限，需要开发能够在此领域提供可行洞察的大语言模型。"}}
{"id": "2511.19785", "pdf": "https://arxiv.org/pdf/2511.19785", "abs": "https://arxiv.org/abs/2511.19785", "authors": ["Maureen Herbert", "Katie Sun", "Angelica Lim", "Yasaman Etesam"], "title": "Gender Bias in Emotion Recognition by Large Language Models", "categories": ["cs.CL", "cs.CY"], "comment": "Accepted at AAAI 2026 Workshop (WS37)", "summary": "The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, \"How does this person feel?\". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.", "AI": {"tldr": "本研究评估大型语言模型在情绪心理理论中的性别偏见，发现推理时提示工程无法有效减少偏见，需要基于训练的去偏干预策略。", "motivation": "随着大语言模型在日常生活中的广泛应用，评估和确保其公平性变得至关重要，特别是在情绪心理理论领域是否存在性别偏见。", "method": "通过向模型描述人物及其环境后询问\"这个人感觉如何？\"来测试性别偏见，并提出多种去偏策略进行比较评估。", "result": "研究表明仅依靠推理时的提示工程方法无法有效减少偏见，需要基于训练的去偏干预才能实现有意义的偏见减少。", "conclusion": "为确保LLMs在情绪心理理论中的公平性，必须采用基于训练的去偏策略，而非仅仅依赖推理时的提示调整。"}}
{"id": "2511.19663", "pdf": "https://arxiv.org/pdf/2511.19663", "abs": "https://arxiv.org/abs/2511.19663", "authors": ["Ahmed Awadallah", "Yash Lara", "Raghav Magazine", "Hussein Mozannar", "Akshay Nambi", "Yash Pandya", "Aravind Rajeswaran", "Corby Rosset", "Alexey Taymanov", "Vibhav Vineet", "Spencer Whitehead", "Andrew Zhao"], "title": "Fara-7B: An Efficient Agentic Model for Computer Use", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.", "AI": {"tldr": "FaraGen是一个创新的合成数据生成系统，用于创建多步骤网页任务的高质量训练数据，并基于此训练出Fara-7B模型，该模型在多个基准测试中表现出色，甚至能与更大的前沿模型竞争。", "motivation": "计算机使用代理(CUAs)的发展受到缺乏大规模高质量人机交互数据集的限制，需要解决多步骤网页任务的合成数据生成问题。", "method": "开发FaraGen系统，从常用网站生成多样化任务，产生多个解决方案尝试，并使用多个验证器筛选成功轨迹；基于生成的数据训练Fara-7B模型，该模型仅使用屏幕截图感知计算机，通过预测坐标执行动作。", "result": "FaraGen以约1美元的成本产生每个验证轨迹，实现了高吞吐量、高产出和高多样性；Fara-7B在WebVoyager、Online-Mind2Web和WebTailBench等基准测试中优于同规模CUA模型，并与更大的前沿模型竞争。", "conclusion": "可扩展的数据生成系统在推进小型高效代理模型方面具有关键优势，Fara-7B模型已开源，WebTailBench基准也已发布。"}}
{"id": "2511.19816", "pdf": "https://arxiv.org/pdf/2511.19816", "abs": "https://arxiv.org/abs/2511.19816", "authors": ["Saif M. Mohammad"], "title": "Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions", "categories": ["cs.CL"], "comment": null, "summary": "Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html", "AI": {"tldr": "NRC VAD Lexicon v2扩展了情感词典，新增10k多词表达和25k单词的效价、唤醒度、支配度人工评分，提高了覆盖范围和可靠性，支持多领域研究。", "motivation": "现有NRC VAD词典(2018)主要针对单词，缺乏多词表达的情感评分，且覆盖的单词数量有限，需要更新以包含更常见的词汇和多词表达。", "method": "通过人工评分获取10k多词表达及其组成词的效价、唤醒度、支配度评分，并扩展单词覆盖范围，特别是2018年后更常见的词汇。", "result": "新词典包含10k多词表达和25k单词的评分，数据高度可靠，并用于分析多词表达的情感特性和情感组合性。", "conclusion": "NRC VAD Lexicon v2为NLP、心理学、公共卫生等领域的多种研究提供了丰富可靠的情感数据资源。"}}
{"id": "2511.19669", "pdf": "https://arxiv.org/pdf/2511.19669", "abs": "https://arxiv.org/abs/2511.19669", "authors": ["Souradip Poddar", "Chia-Tung Ho", "Ziming Wei", "Weidong Cao", "Haoxing Ren", "David Z. Pan"], "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.", "AI": {"tldr": "HeaRT是一种新型的AI驱动AMS设计自动化推理引擎，在40个电路基准测试中实现>97%的推理准确率和>98%的Pass@1性能，比SOTA基线快3倍收敛，且仅需不到0.5倍实时token预算。", "motivation": "传统AI驱动的AMS设计自动化算法存在三个主要限制：依赖高质量数据集、跨架构可迁移性差、缺乏自适应机制，需要更智能、自适应、类人风格的设计优化方法。", "method": "提出了HeaRT（推理引擎）作为自动化循环的基础设施，采用推理机制来捕获电路行为，支持尺寸和拓扑设计自适应任务。", "result": "在电路复杂度增加的情况下，HeaRT在40个电路基准测试中保持>97%的推理准确率和>98%的Pass@1性能，比现有基线快3倍收敛，同时仅需不到0.5倍实时token预算。", "conclusion": "HeaRT代表了向智能、自适应、类人设计优化迈出的重要第一步，能够保持先前的设计意图，显著提升AMS设计自动化的效率和性能。"}}
{"id": "2511.19818", "pdf": "https://arxiv.org/pdf/2511.19818", "abs": "https://arxiv.org/abs/2511.19818", "authors": ["Koena Ronny Mabokela", "Tim Schlippe", "Mpho Raborife", "Turgay Celik"], "title": "Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana", "categories": ["cs.CL", "cs.AI"], "comment": "Published in the The Fourth Workshop on Processing Emotions, Decisions and Opinions (EDO 2023) at 10th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics (LTC 2023), Poznań, Poland, 21-23 April 2023. ISBN: 978-83-232-4176-8", "summary": "Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.", "AI": {"tldr": "本文提出了一种利用表情符号和情感词汇的自动情感标注方法，针对非洲低资源语言的情感分析需求，在英语、Sepedi和Setswana三种语言的推文上分别达到66%、69%和63%的标注准确率。", "motivation": "非洲语言作为低资源语言缺乏标注数据，手动标注耗时昂贵，需要开发自动高效的标注方法来减少人工工作量。", "method": "利用情感表情符号和情感词汇信息的语言无关情感标注方法，在SAfriSenti多语言情感语料库的英语、Sepedi和Setswana推文上进行实验。", "result": "英语推文标注准确率66%，Sepedi推文69%，Setswana推文63%，平均只需修正34%的自动生成标签。", "conclusion": "该方法能有效减少人工标注工作量，为低资源语言的情感分析提供实用的自动标注解决方案。"}}
{"id": "2511.19671", "pdf": "https://arxiv.org/pdf/2511.19671", "abs": "https://arxiv.org/abs/2511.19671", "authors": ["Rishab Sharma", "Iman Saberi", "Elham Alipour", "Jie JW Wu", "Fatemeh Fard"], "title": "FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking", "categories": ["cs.AI"], "comment": "3 tables, 11 pages, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance", "summary": "Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).", "AI": {"tldr": "FISCAL框架通过生成金融事实核查的合成数据，训练出轻量级验证器MiniCheck-FISCAL，在多个金融数据集上表现优异，甚至接近或超越大型模型性能", "motivation": "金融领域的大型语言模型需要事实可靠性和计算效率，但现有系统存在幻觉问题且依赖过大模型", "method": "提出FISCAL模块化框架生成金融事实核查合成数据，并训练轻量级验证器MiniCheck-FISCAL", "result": "MiniCheck-FISCAL超越基线模型和GPT-3.5 Turbo，接近Mixtral-8x22B等大模型性能，在外部数据集上与GPT-4o和Claude-3.5相当", "conclusion": "领域特定的合成数据结合高效微调可使紧凑模型在金融AI中实现最先进的准确性、鲁棒性和可扩展性"}}
{"id": "2511.19852", "pdf": "https://arxiv.org/pdf/2511.19852", "abs": "https://arxiv.org/abs/2511.19852", "authors": ["Shi-Wei Dai", "Yan-Wei Shie", "Tsung-Huan Yang", "Lun-Wei Ku", "Yung-Hui Li"], "title": "Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.", "AI": {"tldr": "PersonaPulse框架通过动态优化提示词来增强LLMs的个性表达，利用情境响应基准进行评分，生成的提示词优于基于心理学研究的手工设计方法。", "motivation": "现有研究使用提示词来激发LLMs的特定个性特质，但未对这些提示词进行优化以最大化个性表达效果。", "method": "提出PersonaPulse框架，利用LLMs对个性特质的固有知识迭代优化角色扮演提示词，并整合情境响应基准作为评分工具进行上下文接地评估。", "result": "定量评估显示PersonaPulse生成的提示词优于先前工作；探索了模型大小与个性建模的关系；发现某些个性特质的激发程度可通过暂停优化过程进行部分控制。", "conclusion": "提示词优化在塑造LLMs个性表达中具有重要性，为自适应AI交互的未来研究提供了宝贵见解。"}}
{"id": "2511.19749", "pdf": "https://arxiv.org/pdf/2511.19749", "abs": "https://arxiv.org/abs/2511.19749", "authors": ["Farzan Karimi-Malekabadi", "Pooya Razavi", "Sonya Powers"], "title": "Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions", "categories": ["cs.AI"], "comment": null, "summary": "As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.", "AI": {"tldr": "研究表明大型语言模型（特别是GPT-4o-mini）在83-94%的情况下能准确识别教育评估项目与内容标准的对齐状态，结合候选技能筛选策略后正确率超过95%，可显著减少人工审核负担。", "motivation": "传统的人工评估项目与内容标准对齐审核虽然准确但速度慢、劳动强度大，特别是在大型题库中，需要寻找更高效的自动化解决方案。", "method": "使用超过12,000个K-5年级的项目-技能对，测试三种LLM模型（GPT-3.5 Turbo、GPT-4o-mini和GPT-4o）在三个任务上的表现：识别不对齐项目、从完整标准集中选择正确技能、在分类前缩小候选列表。", "result": "GPT-4o-mini在识别对齐状态方面达到83-94%的准确率；数学表现强劲但阅读表现较差（标准语义重叠较多）；候选技能预筛选使正确技能出现在前五建议中的概率超过95%。", "conclusion": "LLM特别是结合候选筛选策略时，能显著减少人工审核负担同时保持对齐准确性，建议开发混合流程，将基于LLM的筛选与模糊情况下的人工审核相结合，为持续的项目验证和教学对齐提供可扩展解决方案。"}}
{"id": "2511.19858", "pdf": "https://arxiv.org/pdf/2511.19858", "abs": "https://arxiv.org/abs/2511.19858", "authors": ["Farzad Ahmed", "Joniel Augustine Jerome", "Meliha Yetisgen", "Özlem Uzuner"], "title": "A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.\n  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.\n  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.\n  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.", "AI": {"tldr": "检索增强动态提示(RDP)在医疗错误检测和纠正任务中表现优于零样本提示和静态随机示例提示，能显著降低假阳性率并提高召回率。", "motivation": "临床文档中存在各种错误可能危及患者安全，大语言模型可能帮助检测和纠正这些错误，但不同提示策略下的表现尚不清楚。", "method": "使用MEDEC数据集评估9个指令调优的大语言模型，比较零样本提示、静态随机示例提示和检索增强动态提示在错误标记检测、错误句子检测和错误纠正三个子任务中的表现。", "result": "RDP将假阳性率降低约15%，在错误句子检测中召回率提高5-10%，并能生成更符合上下文的纠正结果。", "conclusion": "检索增强动态提示在多样化的大语言模型中表现最佳，使用检索到的示例可以提高检测准确性、减少假阳性并增强医疗错误纠正的可靠性。"}}
{"id": "2511.19773", "pdf": "https://arxiv.org/pdf/2511.19773", "abs": "https://arxiv.org/abs/2511.19773", "authors": ["Meng Lu", "Ran Xu", "Yi Fang", "Wenxuan Zhang", "Yue Yu", "Gaurav Srivastava", "Yuchen Zhuang", "Mohamed Elhoseiny", "Charles Fleming", "Carl Yang", "Zhengzhong Tu", "Yang Xie", "Guanghua Xiao", "Hanrui Wang", "Di Jin", "Wenqi Shi", "Xuan Wang"], "title": "Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "17 pages, 9 figures, work in progress", "summary": "While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to \"think with images\", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.", "AI": {"tldr": "VISTA-Gym是一个用于训练视觉语言模型工具集成推理能力的可扩展环境，通过统一多模态任务接口和执行循环，训练出的VISTA-R1-8B模型在11个VQA基准测试中比同类模型性能提升9.51%-18.72%", "motivation": "现有视觉语言模型在图像理解方面表现强劲，但在多步骤视觉交互推理方面能力有限，特别是工具选择、调用和协调方面存在困难", "method": "开发VISTA-Gym训练环境，统一7个任务13个数据集的多模态推理任务，提供标准化视觉工具接口、可执行交互循环和验证反馈信号，通过多轮轨迹采样和端到端强化学习训练VISTA-R1模型", "result": "在11个公共推理密集型VQA基准测试中，VISTA-R1-8B模型相比同等规模的最先进基线模型性能提升9.51%-18.72%", "conclusion": "VISTA-Gym是解锁视觉语言模型工具集成推理能力的有效训练平台，能够显著提升模型在复杂视觉推理任务中的表现"}}
{"id": "2511.19957", "pdf": "https://arxiv.org/pdf/2511.19957", "abs": "https://arxiv.org/abs/2511.19957", "authors": ["Tianyi Chen", "Michael Solodko", "Sen Wang", "Jongwoo Ko", "Junheng Hao", "Colby Banbury", "Sara Abdali", "Saeed Amizadeh", "Qing Xiao", "Yinheng Li", "Tianyu Ding", "Kamran Ghasedi Dizaji", "Suzhen Zheng", "Hao Fan", "Justin Wagle", "Pashmina Cameron", "Kazuhito Koishida"], "title": "AppSelectBench: Application-Level Tool Selection Benchmark", "categories": ["cs.CL"], "comment": null, "summary": "Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.", "AI": {"tldr": "AppSelectBench是一个评估计算机智能体应用选择能力的新基准，包含10万+真实用户任务和100个桌面应用，测试模型在不同应用间的推理选择能力。", "motivation": "现有基准主要评估细粒度API选择，缺乏对模型在不同应用间进行推理和选择能力的评估，这是智能体有效操作的关键能力。", "method": "开发了新颖的用户任务生成流程，大规模生成真实、多样且语义基础的用户意图，并提供统一的评估协议（随机、启发式、零样本、少样本和检索增强设置）。", "result": "对闭源和开源大语言模型的广泛实验揭示了在跨应用推理方面的系统性优势和弱点，即使最强大的模型也难以做出一致的应用选择。", "conclusion": "AppSelectBench为研究和推进应用级推理能力奠定了基础，这是智能计算机代理重要但尚未充分探索的能力。"}}
{"id": "2511.19780", "pdf": "https://arxiv.org/pdf/2511.19780", "abs": "https://arxiv.org/abs/2511.19780", "authors": ["Ioannis Tzachristas", "Aifen Sui"], "title": "NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents", "categories": ["cs.AI"], "comment": null, "summary": "We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.", "AI": {"tldr": "本文提出了一种神经符号框架，通过将结构化意图本体与紧凑语言模型结合，实现移动AI代理的多意图理解。该方法在MultiWOZ 2.3数据集上验证，3B参数的Llama模型通过本体增强接近GPT-4准确率(85% vs 90%)，但能耗和内存占用大幅降低。", "motivation": "解决移动设备上AI代理的多意图理解问题，需要在保持高准确率的同时显著降低计算资源消耗，以实现在设备上的高效自然语言理解。", "method": "采用检索增强提示、logit偏置和可选分类头的方法，将符号意图结构注入到输入和输出表示中。提出了基于层次本体深度的语义意图相似度(SIS)评估指标。", "result": "实验显示，3B参数的Llama模型通过本体增强后达到85%的准确率，接近GPT-4的90%准确率，但计算资源消耗大幅减少。定性比较表明本体增强模型产生更准确、更明确的多意图解释。", "conclusion": "符号对齐是实现在设备上准确高效自然语言理解的有效策略，神经符号框架能够在保持高性能的同时显著降低资源需求。"}}
{"id": "2511.19987", "pdf": "https://arxiv.org/pdf/2511.19987", "abs": "https://arxiv.org/abs/2511.19987", "authors": ["Xinyu Wang", "Hanwei Wu", "Qingchen Hu", "Zhenghan Tai", "Jingrui Tian", "Lei Ding", "Jijun Chi", "Hailin He", "Tung Sum Thomas Kwok", "Yufei Cui", "Sicheng Lyu", "Muzhi Li", "Mingze Li", "Xinyue Yu", "Ling Zhou", "Peng Lu"], "title": "$\\text{R}^2\\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers", "categories": ["cs.CL", "cs.IR"], "comment": "13 pages, including 3 figures and 3 tables", "summary": "Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.", "AI": {"tldr": "R2R是一个针对检索增强生成(RAG)的领域感知重排序框架，通过动态专家路由和两阶段训练策略(EAG)解决通用模型在专业领域适应性差的问题，在多个专业领域表现优于基线方法。", "motivation": "通用重排序模型在金融、法律等高风险专业领域缺乏领域特定知识，而简单微调会导致表面形式过拟合和灾难性遗忘问题。", "method": "提出R2R框架：1) EAG两阶段训练策略，通过掩盖最具预测性的表面线索来学习领域不变的相关性模式；2) 轻量级潜在语义路由器，从冻结的主干解码器中探测内部表示来选择最优LoRA专家。", "result": "在多个重排序主干模型和不同领域(法律、医疗、金融)的广泛实验中，R2R始终超越通用模型和单领域微调基线。", "conclusion": "R2R是一种模型无关的模块化方法，具有强大的跨领域鲁棒性，能够有效实现领域专业化。"}}
{"id": "2511.19798", "pdf": "https://arxiv.org/pdf/2511.19798", "abs": "https://arxiv.org/abs/2511.19798", "authors": ["Weizhi Liu", "Xi Chen", "Zekun Jiang", "Liang Zhao", "Kunyuan Jiang", "Ruisi Tang", "Li Wang", "Mingke You", "Hanyu Zhou", "Hongyu Chen", "Qiankun Xiong", "Yong Nie", "Kang Li", "Jian Li"], "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.", "AI": {"tldr": "开发了KOM多智能体系统，用于自动化膝骨关节炎的评估、风险预测和治疗处方，在临床工作流程中显著提高诊断效率和治疗质量", "motivation": "膝骨关节炎影响全球6亿多人，但个性化多学科干预需要大量医疗资源，难以在资源有限的环境中实施", "method": "开发KOM多智能体系统，自动化执行KOA护理路径中的关键任务，基于患者个体特征生成定制管理方案", "result": "在基准实验中表现优于通用大语言模型，随机三臂模拟研究显示与临床医生合作减少38.5%诊断时间并提高治疗质量", "conclusion": "KOM有助于实现自动化KOA管理，其模块化架构为开发其他慢性病的AI辅助管理系统提供了宝贵见解"}}
{"id": "2511.19997", "pdf": "https://arxiv.org/pdf/2511.19997", "abs": "https://arxiv.org/abs/2511.19997", "authors": ["Mihir Sahasrabudhe"], "title": "Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 4 figures. Code available at https://github.com/mihirs-0/synass", "summary": "Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a \"reversal curse,\" and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.", "AI": {"tldr": "论文通过合成基准测试发现，因果Transformer架构存在固有的方向性优化差距，即使在没有语言先验和语料库时间不对称性的情况下，反转任务也比正向任务更难优化。", "motivation": "解决Transformer架构在自然语言处理中表现出的\"反转诅咒\"现象，澄清方向性失败是源于语言统计特性还是架构本身的内在问题。", "method": "使用完全合成的、熵控制的基准测试，构建随机字符串映射任务，通过可调分支因子K设计零条件熵的正向任务和具有分析确定熵底线的反转任务。", "result": "发现从头训练的GPT-2模型表现出强烈且可复现的方向性优化差距（如K=5时1.16 nats），远大于在相同数据上训练的MLP。预训练初始化改变了优化行为但未消除差距，LoRA在高熵反转映射上遇到明显的容量限制。", "conclusion": "研究分离出了因果Transformer训练中固有的、与语义无关的方向性摩擦特征，表明反转任务对Transformer而言本质上更难优化，这为分析现代序列模型的方向性偏置提供了受控工具。"}}
{"id": "2511.19829", "pdf": "https://arxiv.org/pdf/2511.19829", "abs": "https://arxiv.org/abs/2511.19829", "authors": ["Ke Chen", "Yifeng Wang", "Hassan Almosapeeh", "Haohan Wang"], "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.", "AI": {"tldr": "该论文提出了一个评估指导的提示优化框架，通过建立系统化的提示评估标准和训练免执行的评估器，实现了可解释、查询依赖的提示优化，在多个数据集和模型上都超越了现有方法。", "motivation": "现有提示优化方法主要优化静态模板，在复杂动态用户场景中效果不佳；查询依赖方法依赖不稳定文本反馈或黑盒奖励模型，提供弱且不可解释的优化信号；提示质量本身缺乏统一系统定义。", "method": "首先建立以性能为导向的系统化提示评估框架，开发并微调免执行的评估器直接从文本预测多维质量分数，然后使用评估器指导度量感知的优化器进行可解释的、查询依赖的提示重写。", "result": "评估器在预测提示性能方面达到最强准确度，评估指导的优化在八个数据集和三个骨干模型上一致超越了静态模板和查询依赖基线方法。", "conclusion": "提出了一个统一的、基于度量的提示质量视角，证明评估指导的优化管道能够跨不同任务提供稳定、可解释且模型无关的改进。"}}
{"id": "2511.20001", "pdf": "https://arxiv.org/pdf/2511.20001", "abs": "https://arxiv.org/abs/2511.20001", "authors": ["Edward Ajayi", "Martha Kachweka", "Mawuli Deku", "Emily Aiken"], "title": "A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media", "categories": ["cs.CL", "cs.SI"], "comment": "Accepted for Oral Presentation at the AAAI-26 Bridge Program on AI for Medicine and Healthcare (AIMedHealth). To appear in Proceedings of Machine Learning Research (PMLR)", "summary": "Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous \"split-then-balance\" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.", "AI": {"tldr": "本文提出了一个统一的多类别分类框架，用于从社交媒体数据中检测10种心理健康和网络欺凌类别，通过端到端微调的MentalBERT模型取得最佳性能，并设计了结合SHAP和LLM的可解释性框架及原型仪表板。", "motivation": "数字空间中心理健康问题和网络欺凌日益普遍，需要可扩展且可解释的检测系统来解决这些挑战。", "method": "从Twitter和Reddit收集数据，采用\"分割再平衡\"流程，在平衡数据上训练，在不平衡测试集上评估。比较了传统词汇模型、混合方法和多种端到端微调transformer模型。", "result": "MentalBERT模型表现最佳，准确率达0.92，宏观F1分数0.76，超越了通用模型和零样本LLM基线。", "conclusion": "研究提供了一个稳健的基线，强调未来需要多标签、临床验证的数据集，并将系统定位为人类参与的筛查辅助工具而非诊断工具。"}}
{"id": "2511.19849", "pdf": "https://arxiv.org/pdf/2511.19849", "abs": "https://arxiv.org/abs/2511.19849", "authors": ["Dominik Wagner", "Leon Witzman", "Luke Ong"], "title": "Reinforcement Learning with $ω$-Regular Objectives and Constraints", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $ω$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.\n  We address both limitations simultaneously by combining $ω$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $ω$-regular objective while also adhering to $ω$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.", "AI": {"tldr": "提出了一种结合ω-正则目标和显式约束的强化学习方法，通过线性规划算法在满足安全约束的前提下最大化目标满足概率，解决了传统标量奖励在表达复杂行为和安全性方面的局限性。", "motivation": "传统强化学习依赖标量奖励，难以表达时间性、条件性和安全关键性目标，且容易导致奖励破解问题。同时，单一标量指标掩盖了安全性-性能之间的权衡关系。", "method": "开发基于线性规划的模型强化学习算法，将ω-正则目标与显式约束结合，分别处理安全要求和优化目标，并建立到约束极限平均问题的转换方法。", "result": "算法能够在极限情况下生成策略，在满足指定阈值内的ω-正则约束的同时，最大化满足ω-正则目标的概率。", "conclusion": "该方法有效解决了强化学习中复杂行为规范和安全约束的表达问题，提供了处理安全性-性能权衡的理论框架和实用算法。"}}
{"id": "2511.20056", "pdf": "https://arxiv.org/pdf/2511.20056", "abs": "https://arxiv.org/abs/2511.20056", "authors": ["Huiyu Bai", "Runze Wang", "Zhuoyun Du", "Yiyang Zhao", "Fengji Zhang", "Haoyu Chen", "Xiaoyong Zhu", "Bo Zheng", "Xuejiao Zhao"], "title": "Online-PVLM: Advancing Personalized VLMs with Online Concept Learning", "categories": ["cs.CL"], "comment": "Work in Progress", "summary": "Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.", "AI": {"tldr": "提出Online-PVLM框架，使用双曲表示实现个性化视觉语言模型的在线概念学习，无需训练即可在测试时生成概念嵌入，解决了现有方法无法支持实时适应和大规模检索的问题。", "motivation": "现有个性化视觉语言模型方法需要为每个新概念学习单独嵌入，无法在测试时进行实时适应，且在大规模场景中无法高效检索概念嵌入。", "method": "提出Online-PVLM框架，利用双曲表示实现无训练的概念嵌入生成范式，支持测试时的在线概念学习。同时开发了包含1,292个概念和30K+实例的OP-Eval基准测试集。", "result": "大量实验证明该框架达到了最先进的性能表现。", "conclusion": "该框架使个性化视觉语言模型的使用既具有可扩展性又高效，解决了实时适应和大规模检索的挑战，源代码和数据集将公开。"}}
{"id": "2511.19864", "pdf": "https://arxiv.org/pdf/2511.19864", "abs": "https://arxiv.org/abs/2511.19864", "authors": ["Valerie Lockhart", "Dan McCreary", "Troy A. Peterson"], "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support", "categories": ["cs.AI"], "comment": "42 pages, 4 figures", "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.", "AI": {"tldr": "MicroSims是一个创新的AI驱动框架，用于快速创建轻量级、可交互的教育模拟，无需编程知识即可嵌入各种数字学习平台并进行自定义。", "motivation": "传统教育模拟创建需要大量资源和技术专长，MicroSims旨在解决成本高、技术复杂和平台依赖等长期障碍，促进教育公平。", "method": "采用标准化设计模式支持AI辅助生成，基于iframe架构实现通用嵌入和沙盒安全，提供透明可修改代码支持定制化。包含设计原则、技术架构、元数据标准和开发流程的完整框架。", "result": "基于物理教育研究和STEM学科元分析，交互式模拟相比传统教学可将概念理解提高30-40%。MicroSims在保持这些优势的同时降低了使用门槛。", "conclusion": "MicroSims为全球教育工作者提供了按需创建定制化、与课程对齐的模拟工具，具有重要的教育公平意义，并为构建AI驱动的自适应学习系统奠定了基础。"}}
{"id": "2511.20072", "pdf": "https://arxiv.org/pdf/2511.20072", "abs": "https://arxiv.org/abs/2511.20072", "authors": ["Xiaopeng Li", "Yuanjin Zheng", "Wanyu Wang", "wenlin zhang", "Pengyue Jia", "Yiqi Wang", "Maolin Wang", "Xuetao Wei", "Xiangyu Zhao"], "title": "MTA: A Merge-then-Adapt Framework for Personalized Large Language Model", "categories": ["cs.CL"], "comment": null, "summary": "Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.", "AI": {"tldr": "MTA框架通过合并-适应方法解决个性化大语言模型的存储和稀疏数据问题，包含元LoRA库构建、自适应LoRA融合和少样本LoRA堆叠三个阶段，在LaMP基准测试中优于现有方法", "motivation": "解决现有PLLMs方法中存储成本随用户数量线性增长的问题，以及静态模型在稀疏数据用户上性能不佳的局限性", "method": "提出三阶段MTA框架：1)构建共享元LoRA库 2)自适应LoRA融合动态合成用户特定模块 3)少样本LoRA堆叠进行轻量级微调", "result": "在LaMP基准测试的多个任务中表现优于现有最先进方法", "conclusion": "MTA框架有效解决了PLLMs的扩展性和稀疏数据问题，通过动态合并和轻量级适应实现了高效个性化"}}
{"id": "2511.19865", "pdf": "https://arxiv.org/pdf/2511.19865", "abs": "https://arxiv.org/abs/2511.19865", "authors": ["Mingkai Chen", "Zijie Feng", "Lei Wang", "Yaser Khamayseh"], "title": "Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G", "categories": ["cs.AI"], "comment": "7 pages, 8 figures. Preprint submitted to IEEE Vehicle Technology Magazine", "summary": "In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.", "AI": {"tldr": "提出CC-EIN网络解决6G时代多智能体协作中的多模态融合、自适应通信和决策可解释性问题，在救援场景中实现95.4%任务完成率和95%传输效率", "motivation": "6G时代多智能体协作面临多模态信息融合、自适应通信和决策可解释性三大挑战", "method": "集成多模态特征融合、自适应语义通信、任务协调和可解释性模块，包括PerceptiNet跨模态融合、自适应编码策略、语义驱动协作机制和InDec可视化模块", "result": "在地震救援模拟中达到95.4%任务完成率、95%传输效率，保持强语义一致性和能量效率", "conclusion": "CC-EIN系统有效解决了多智能体协作的关键技术难题，为6G时代的智能设备协同提供了可行解决方案"}}
{"id": "2511.20086", "pdf": "https://arxiv.org/pdf/2511.20086", "abs": "https://arxiv.org/abs/2511.20086", "authors": ["Duc Anh Vu", "Thong Nguyen", "Cong-Duy Nguyen", "Viet Anh Nguyen", "Anh Tuan Luu"], "title": "More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering", "categories": ["cs.CL"], "comment": "Accepted at the 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026), Main Conference", "summary": "With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.", "AI": {"tldr": "BiasPrompting是一个新颖的推理框架，通过为所有可能答案选项生成支持性推理并进行批判性评估，来提升大语言模型在选择题任务中的表现。", "motivation": "现有方法在呈现选择题答案选项时缺乏上下文背景和解释，导致模型无法充分探索所有可能答案，从而降低了推理能力。", "method": "包含两个阶段：1) 推理生成阶段 - 为每个答案选项生成支持性推理；2) 推理引导的共识阶段 - 综合生成的推理来选择最合理的答案。", "result": "在五个广泛使用的选择题回答基准测试中显示出显著改进，特别是在现有方法表现不佳的复杂和具有挑战性的问题设置中。", "conclusion": "BiasPrompting有效增强了LLMs的推理能力，为处理复杂问题提供了坚实基础，解决了现有方法的局限性。"}}
{"id": "2511.19872", "pdf": "https://arxiv.org/pdf/2511.19872", "abs": "https://arxiv.org/abs/2511.19872", "authors": ["Daniel I Jackson", "Emma L Jensen", "Syed-Amad Hussain", "Emre Sezgin"], "title": "Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy", "categories": ["cs.AI"], "comment": "25 pages,5 tables, 3 figures", "summary": "Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.", "AI": {"tldr": "该研究将通用自我效能感量表(GSES)应用于10个大语言模型，发现在不同任务条件下模型的自我评估能力与真实表现不一致，存在高估倾向且评估结果与人类标准存在差异。", "motivation": "当前对大语言模型的评估主要关注任务准确性，而忽略了自我评估这一可靠智能的关键方面，需要系统研究LLM的自我效能感评估能力。", "method": "采用10项通用自我效能感量表(GSES)，在四种条件(无任务、计算推理、社会推理和摘要生成)下对10个LLM进行模拟自我评估，分析响应稳定性、自我效能水平与任务表现的关系。", "result": "模型自我评估在不同条件下差异显著，总分低于人类标准；所有模型在计算和社会问题上准确率完美，但摘要表现差异大；自我评估不能可靠反映实际能力；后续置信度提示导致评估下调，表明初次评估存在轻度高估。", "conclusion": "心理测量提示为LLM沟通行为提供了结构化洞察，但不能提供校准的性能估计，自我评估与真实能力之间存在脱节。"}}
{"id": "2511.20102", "pdf": "https://arxiv.org/pdf/2511.20102", "abs": "https://arxiv.org/abs/2511.20102", "authors": ["Zhenyi Shen", "Junru Lu", "Lin Gui", "Jiazheng Li", "Yulan He", "Di Yin", "Xing Sun"], "title": "SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space", "categories": ["cs.CL"], "comment": "28 pages", "summary": "The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.", "AI": {"tldr": "SSA提出了一种统一的稀疏注意力训练框架，通过同时考虑稀疏和完整注意力，在每一层进行双向对齐，解决了现有稀疏注意力方法梯度更新不足的问题，实现了更好的稀疏性和性能表现。", "motivation": "现有的训练无关稀疏注意力方法会导致性能严重下降，而原生稀疏注意力方法虽然缓解了这个问题，但存在一个关键悖论：它们产生的注意力稀疏度反而低于完整注意力模型，限制了其有效性。这主要是由于梯度更新不足导致的。", "method": "提出了SSA（稀疏稀疏注意力）训练框架，同时考虑稀疏和完整注意力，在每一层强制执行双向对齐。这种设计保持了所有token的梯度流，同时显式鼓励稀疏注意力输出与其完整注意力对应物对齐，从而促进更强的稀疏性。", "result": "SSA在多个常识基准测试中，在稀疏和完整注意力推理下都实现了最先进的性能。能够平滑适应不同的稀疏预算，性能随着允许关注的token数量增加而持续改善。同时显著改善了长上下文外推能力。", "conclusion": "SSA通过解决梯度更新不足的问题，提供了一个统一的训练框架，不仅实现了更好的稀疏注意力性能，还支持灵活的算力-性能权衡，并在长上下文外推方面表现出色。"}}
{"id": "2511.19895", "pdf": "https://arxiv.org/pdf/2511.19895", "abs": "https://arxiv.org/abs/2511.19895", "authors": ["Yuanyuan Lin", "Xiangyu Ouyang", "Teng Zhang", "Kaixin Sui"], "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation", "categories": ["cs.AI"], "comment": "Accepted at AAAI 2026", "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.", "AI": {"tldr": "RPM-MCTS是一种基于蒙特卡洛树搜索的代码生成方法，通过知识检索替代复杂的过程奖励模型训练，使用相似性过滤减少冗余节点，并利用沙箱执行反馈定位和纠正错误步骤，在降低计算成本的同时提升代码生成质量。", "motivation": "现有基于树搜索的代码生成方法难以有效评估中间算法步骤，无法及时定位和纠正错误步骤，导致生成错误代码和计算成本增加。", "method": "提出RPM-MCTS方法：1）使用知识检索作为过程奖励模型评估中间步骤；2）在扩展阶段采用相似性过滤去除冗余节点；3）利用沙箱执行反馈定位和纠正错误算法步骤。", "result": "在四个公开代码生成基准测试中，RPM-MCTS优于当前最先进方法，同时实现了约15%的token消耗减少。使用RPM-MCTS构建的数据对基础模型进行全微调可显著提升其代码能力。", "conclusion": "RPM-MCTS通过知识检索、相似性过滤和沙箱反馈的有效结合，成功解决了中间步骤评估和错误纠正的难题，在提升代码生成质量的同时降低了计算成本，为代码生成领域提供了有效的解决方案。"}}
{"id": "2511.20106", "pdf": "https://arxiv.org/pdf/2511.20106", "abs": "https://arxiv.org/abs/2511.20106", "authors": ["Xingfeng Li", "Xiaohan Shi", "Junjie Li", "Yongwei Li", "Masashi Unoki", "Tomoki Toda", "Masato Akagi"], "title": "EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning", "categories": ["cs.CL"], "comment": "Submitted to IEEE Transactions on Affective computing", "summary": "This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \\textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.", "AI": {"tldr": "EM2LDL是一个新的多语言语音语料库，通过标签分布学习推进混合情感识别，包含英语、普通话和粤语的情感表达，支持多语言环境下的复杂情感动态研究。", "motivation": "解决现有单语言和单标签情感语料库的限制，这些语料库缺乏语言多样性、无法建模混合情感且生态效度不足，特别是在香港和澳门等多语言地区。", "method": "构建包含英语、普通话和粤语表达性话语的多语言语料库，整合来自在线平台的自发情感表达，使用32个类别的细粒度情感分布进行标注，并采用自监督学习模型进行实验基线评估。", "result": "实验基线显示，自监督学习模型在说话人独立的性别、年龄和个性评估中表现稳健，其中HuBERT-large-EN模型取得了最佳结果。", "conclusion": "EM2LDL通过融入语言多样性和生态效度，为开发适应性强的共情系统提供了多功能测试平台，适用于情感计算中的心理健康监测和跨文化交流等应用。"}}
{"id": "2511.19925", "pdf": "https://arxiv.org/pdf/2511.19925", "abs": "https://arxiv.org/abs/2511.19925", "authors": ["Qiyao Wei", "Edward Morrell", "Lea Goetz", "Mihaela van der Schaar"], "title": "Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.", "AI": {"tldr": "本文提出了一种基于知识图谱生成语义相似性评测基准的新方法，用于评估大语言模型输出的语义相似性方法，解决了现有基准依赖人工标注、成本高和领域适用性有限的问题。", "motivation": "当前语义相似性方法可能过度关注句法或词汇形式而非语义内容，且现有基准存在高生成成本、领域适用性有限和语义等价定义不明确等局限性。", "method": "利用知识图谱生成语义相似或不相似的自然语言陈述对，不相似对分为四种子类型，在四个不同领域（通用知识、生物医学、金融、生物学）生成基准数据集，并比较传统NLP评分和LLM-as-a-judge预测方法。", "result": "研究发现语义变化的子类型和基准领域都会影响语义相似性方法的性能，没有一种方法始终表现最优。", "conclusion": "研究结果对使用LLM-as-a-judge检测文本语义内容具有重要意义，提供了开源代码和数据集供进一步研究使用。"}}
{"id": "2511.20107", "pdf": "https://arxiv.org/pdf/2511.20107", "abs": "https://arxiv.org/abs/2511.20107", "authors": ["Huu Tuong Tu", "Ha Viet Khanh", "Tran Tien Dat", "Vu Huan", "Thien Van Luong", "Nguyen Tien Cuong", "Nguyen Thi Thu Trang"], "title": "Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.", "AI": {"tldr": "提出无需训练的发音错误检测框架，利用预训练ASR模型和检索技术，在L2-ARCTIC数据集上达到69.60%的F1分数", "motivation": "传统方法需要评分模型或音素级模型训练，过程复杂且需要专门训练", "method": "基于检索技术的无训练框架，利用预训练自动语音识别模型，避免音素特定建模和额外任务特定训练", "result": "在L2-ARCTIC数据集上取得69.60%的F1分数，优于传统方法", "conclusion": "该方法无需训练即可实现准确的发音错误检测和诊断，简化了传统方法的复杂性"}}
{"id": "2511.19933", "pdf": "https://arxiv.org/pdf/2511.19933", "abs": "https://arxiv.org/abs/2511.19933", "authors": ["Vaishali Vinay"], "title": "A System-Level Taxonomy of Failure Modes in Large Language Model Applications", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.", "AI": {"tldr": "本文提出了一个包含15种隐藏故障模式的系统级分类法，分析了LLM在生产环境中的可靠性问题，并提供了构建可靠LLM系统的设计原则。", "motivation": "大型语言模型在生产环境中的行为理解不足，其故障模式与传统机器学习模型有根本差异，需要系统化的可靠性分析框架。", "method": "提出系统级分类法识别15种隐藏故障模式，分析评估与监控实践的差距，考察部署挑战，并制定高层设计原则。", "result": "建立了LLM故障模式的系统分类，揭示了现有评估方法的局限性，识别了部署过程中的关键挑战。", "conclusion": "通过将LLM可靠性视为系统工程问题而非纯模型中心问题，为未来评估方法、AI系统鲁棒性和可靠部署研究提供了分析基础。"}}
{"id": "2511.20120", "pdf": "https://arxiv.org/pdf/2511.20120", "abs": "https://arxiv.org/abs/2511.20120", "authors": ["Somsubhra De", "Harsh Kumar", "Arun Prakash A"], "title": "\"When Data is Scarce, Prompt Smarter\"... Approaches to Grammatical Error Correction in Low-Resource Settings", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA Workshop, IJCNLP-AACL 2025", "summary": "Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.", "AI": {"tldr": "该论文探索使用GPT-4.1、Gemini-2.5和LLaMA-4等大型语言模型，通过零样本和少样本提示策略，在资源稀缺的印度语言中实现语法错误校正，取得了优异的性能表现。", "motivation": "虽然基于Transformer的模型在英语等高资源语言的语法错误校正(GEC)方面取得了显著进展，但由于资源有限、语言多样性和复杂形态学，大多数印度语言的GEC仍然是一个挑战性任务。", "method": "采用最先进的大型语言模型(LLMs)结合少样本策略，探索基于提示的方法来适应低资源设置。使用零样本和少样本提示策略，并设计精心构造的提示词。", "result": "在多个印度语言中取得了领先结果：泰米尔语排名第1(GLEU: 91.57)、印地语排名第1(GLEU: 85.69)、泰卢固语排名第2(GLEU: 85.22)、孟加拉语排名第4(GLEU: 92.86)、马拉雅拉姆语排名第5(GLEU: 92.97)。", "conclusion": "研究结果表明，精心设计的提示和轻量级适应显著提高了跨多个印度语言的校正质量，凸显了提示驱动NLP技术的有效性，并强调了大规LLMs在弥多多语言GEC资源差距方面的潜力。"}}
{"id": "2511.19969", "pdf": "https://arxiv.org/pdf/2511.19969", "abs": "https://arxiv.org/abs/2511.19969", "authors": ["Weizi Shao", "Taolin Zhang", "Zijie Zhou", "Chen Chen", "Chengyu Wang", "Xiaofeng He"], "title": "M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.", "AI": {"tldr": "M³Prune是一个多模态多代理层次通信图剪枝框架，通过消除跨模态冗余边，在任务性能和令牌开销之间实现最优平衡，显著减少计算成本的同时提升性能", "motivation": "现有多代理系统虽然性能出色，但存在显著的令牌开销和计算成本问题，限制了大规模部署", "method": "首先进行模态内图稀疏化识别关键边，然后构建动态通信拓扑进行模态间图稀疏化，最后逐步剪枝冗余边获得高效层次拓扑", "result": "在通用和领域特定mRAG基准测试中，方法持续优于单代理和鲁棒多代理系统，同时显著减少令牌消耗", "conclusion": "M³Prune框架有效解决了多代理系统的效率问题，为大规模多模态检索增强生成系统的实际部署提供了可行方案"}}
{"id": "2511.20143", "pdf": "https://arxiv.org/pdf/2511.20143", "abs": "https://arxiv.org/abs/2511.20143", "authors": ["Wen-Fang Su", "Hsiao-Wei Chou", "Wen-Yang Lin"], "title": "SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "9 pages, 5 figures", "summary": "Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.", "AI": {"tldr": "该论文提出将图像数据增强技术（裁剪、缩放、填充）集成到基于网格的标注模型中，以改善不连续命名实体的识别性能，在多个数据集上取得了显著效果提升。", "motivation": "传统命名实体识别方法在处理跨句不连续实体时存在分割错误和遗漏问题，严重影响识别准确性，需要解决这些挑战。", "method": "基于网格标注方法的优势，集成图像数据增强技术（裁剪、缩放、填充）到网格模型中，增强对不连续实体的识别能力。", "result": "在CADEC、ShARe13和ShARe14数据集上，整体F1分数提升1-2.5%，不连续实体的F1分数提升3.7-8.4%。", "conclusion": "图像数据增强技术能有效提升网格模型对不连续命名实体的识别性能，证明了该方法在处理分割挑战方面的有效性。"}}
{"id": "2511.20048", "pdf": "https://arxiv.org/pdf/2511.20048", "abs": "https://arxiv.org/abs/2511.20048", "authors": ["Zixiao Huang", "Wen Zeng", "Tianyu Fu", "Tengxuan Liu", "Yizhou Sun", "Ke Hong", "Xinhao Yang", "Chengchun Liu", "Yan Li", "Quanlu Zhang", "Guohao Dai", "Zhenhua Zhu", "Yu Wang"], "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design", "categories": ["cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.", "AI": {"tldr": "SPAgent是一个算法-系统协同设计框架，通过推测执行机制减少基于LLM的搜索代理的延迟，在保持或提高准确性的同时实现最高1.65倍的端到端加速", "motivation": "基于LLM的搜索代理虽然性能强大但延迟严重，因为每个步骤都需要串行的LLM推理和工具执行。传统的推测执行范式虽然能打破串行执行，但效益有限，因为保留了完整工作负载并增加了额外推理开销", "method": "SPAgent采用两阶段自适应推测机制：算法层面选择性省略安全情况下的验证；系统层面通过两级调度器基于引擎负载调节推测请求，确保推测保持有益", "result": "在广泛的实验设置中，SPAgent实现了最高1.65倍的端到端加速，同时保持相同甚至更高的准确性", "conclusion": "SPAgent通过扩展推测在搜索代理中的作用，有效解决了LLM搜索代理的延迟瓶颈，使多步搜索代理的实际部署成为可能"}}
{"id": "2511.20182", "pdf": "https://arxiv.org/pdf/2511.20182", "abs": "https://arxiv.org/abs/2511.20182", "authors": ["Adilet Metinov", "Gulida M. Kudakeeva", "Gulnara D. Kabaeva"], "title": "KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP", "categories": ["cs.CL"], "comment": "3 pages, 1 figure, 2 tables. Preprint", "summary": "Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.", "AI": {"tldr": "KyrgyzBERT是首个公开的吉尔吉斯语单语BERT模型，参数量35.9M，在情感分析任务上表现优异，F1分数0.8280，与参数量5倍多的mBERT相当。", "motivation": "吉尔吉斯语作为低资源语言缺乏基础NLP工具，需要开发专门的语言模型来支持该语言的NLP研究。", "method": "开发了KyrgyzBERT单语模型，使用定制化的分词器适应语言形态结构，并通过翻译和人工标注创建了kyrgyz-sst2情感分析基准数据集。", "result": "KyrgyzBERT在情感分析任务上达到F1分数0.8280，与参数量更大的多语言BERT模型(mBERT)表现相当。", "conclusion": "该研究填补了吉尔吉斯语NLP工具的空白，发布的模型、数据和代码将为该语言的未来研究提供重要支持。"}}
{"id": "2511.20067", "pdf": "https://arxiv.org/pdf/2511.20067", "abs": "https://arxiv.org/abs/2511.20067", "authors": ["Marta Sumyk", "Oleksandr Kosovan"], "title": "\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents", "categories": ["cs.AI", "cs.HC"], "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.", "AI": {"tldr": "提出基于视觉语言模型的自主评估框架，通过屏幕截图直接检测计算机使用代理的任务完成情况，在macOS应用中达到73%的检测准确率，应用反馈后任务成功率平均提升27%", "motivation": "计算机使用代理(CUAs)在自主操作数字界面时经常无法可靠判断任务是否完成，需要有效的评估机制来提高可靠性", "method": "使用视觉语言模型直接从屏幕截图和任务描述评估任务完成情况，构建包含42个macOS应用和1,260个人工标注任务的数据集", "result": "任务成功检测准确率达到73%，应用评估器反馈后整体任务成功率平均相对提升27%", "conclusion": "基于视觉的评估可以作为有效的反馈机制，提高自主计算机使用代理的可靠性和自我纠正能力"}}
{"id": "2511.20233", "pdf": "https://arxiv.org/pdf/2511.20233", "abs": "https://arxiv.org/abs/2511.20233", "authors": ["Chuyi Kong", "Gao Wei", "Jing Ma", "Hongzhan Lin", "Zhiyuan Fan"], "title": "REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance", "categories": ["cs.CL"], "comment": null, "summary": "The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.", "AI": {"tldr": "REFLEX提出了一种基于角色扮演对话的自优化事实核查范式，通过提取对比激活向量来分离真相的风格和实质，无需外部知识源即可提升判决准确性和解释质量。", "motivation": "现有基于大语言模型的事实核查系统过度依赖外部知识源，导致延迟和幻觉问题，影响可靠性、可解释性和实时性。", "method": "将事实核查重构为角色扮演对话，联合训练判决预测和解释生成，自适应提取主干模型与其微调变体之间的对比激活对来构建引导向量。", "result": "在真实数据集上超越先前方法，仅用465个自优化训练样本就达到最先进性能，解释目标训练的模型可提升无解释模型性能达7.57%。", "conclusion": "REFLEX证明了内部解释信号在解释和增强事实推理中的双重作用，为实时事实核查提供了更忠实和高效的解决方案。"}}
{"id": "2511.20085", "pdf": "https://arxiv.org/pdf/2511.20085", "abs": "https://arxiv.org/abs/2511.20085", "authors": ["Chujie Wang", "Zhiyuan Luo", "Ruiqi Liu", "Can Ran", "Shenghua Fan", "Xi Chen", "Chu He"], "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.", "AI": {"tldr": "VICoT是一个新型多模态代理框架，通过将视觉工具动态整合到思维链中实现显式多轮推理，在遥感图像分析任务中显著优于现有SOTA方法。", "motivation": "遥感图像分析任务正从传统目标识别向复杂智能推理演进，需要模型具备更强的推理能力和工具调用灵活性。", "method": "提出基于栈式推理结构和模块化MCP兼容工具套件的框架，使LLM能高效执行多轮视觉语言推理；同时提出推理栈蒸馏方法将复杂代理行为迁移到轻量模型中。", "result": "在多个遥感基准测试中，VICoT在推理透明度、执行效率和生成质量方面显著优于现有最佳框架。", "conclusion": "VICoT框架通过视觉-语言交织的思维链推理，为复杂遥感智能分析任务提供了有效的解决方案，同时通过蒸馏技术实现了能力向轻量化模型的迁移。"}}
{"id": "2511.20340", "pdf": "https://arxiv.org/pdf/2511.20340", "abs": "https://arxiv.org/abs/2511.20340", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Baoyuan Qi", "Guoming Liu", "Hai Zhao"], "title": "Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios", "categories": ["cs.CL"], "comment": "accepted by AAAI-2026", "summary": "Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.", "AI": {"tldr": "SpecFormer是一种新型架构，通过结合单向和双向注意力机制，在低验证资源和调度成本下实现LLM推理加速，无需依赖大型前缀树，在各种规模模型上均能实现一致加速效果。", "motivation": "现有的推测解码方法假设有大量可用计算资源，但批处理方法已广泛使用并压缩了空闲计算能力。需要在低验证资源和低调度成本下进行推测解码，需要能够并行生成草稿序列的更强大模型。", "method": "提出SpecFormer架构，集成单向和双向注意力机制，结合自回归模型从整个输入序列提取信息的能力和非自回归模型的并行生成优势。", "result": "通过不同规模模型的无损推测解码实验证明，SpecFormer为LLM推理扩展设立了新标准，具有更低的训练需求和计算成本。", "conclusion": "SpecFormer通过创新的架构设计，在保持无损解码的同时实现了高效加速，特别适合大批量场景，为LLM推理优化提供了有效解决方案。"}}
{"id": "2511.20138", "pdf": "https://arxiv.org/pdf/2511.20138", "abs": "https://arxiv.org/abs/2511.20138", "authors": ["Jason Lo", "Mohammadnima Jafari"], "title": "From data to concepts via wiring diagrams", "categories": ["cs.AI", "cs.DM", "cs.LG", "math.CO"], "comment": "19 pages", "summary": "A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.", "AI": {"tldr": "本文提出准骨架接线图概念，证明其与哈斯图的对应关系，并设计从时序数据提取接线图的算法。在游戏AI行为分析中成功识别获胜策略，性能优于传统聚类方法。", "motivation": "研究如何从时序数据中提取表示抽象概念（如时序过程）的接线图，为分析复杂系统行为提供新方法。", "method": "引入准骨架接线图概念，证明其与哈斯图的数学对应关系，基于此设计算法从序列数据提取接线图，并与DBSCAN和凝聚层次聚类进行对比实验。", "result": "算法成功从自主游戏AI的时序数据中识别出获胜策略，在数据扰动情况下仍保持良好性能，优于传统聚类方法。", "conclusion": "该研究融合了范畴论、图论、聚类、强化学习和数据工程技术，为时序数据分析提供了新的理论框架和实用算法。"}}
{"id": "2511.20344", "pdf": "https://arxiv.org/pdf/2511.20344", "abs": "https://arxiv.org/abs/2511.20344", "authors": ["Taewhoo Lee", "Minju Song", "Chanwoong Yoon", "Jungwoo Park", "Jaewoo Kang"], "title": "The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": "AAAI 2026", "summary": "Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.", "AI": {"tldr": "本研究探索LLMs在类比推理中的表现，发现它们能够编码实体间的关系但应用新实体时存在困难，通过隐藏表示修补可部分改善，揭示了LLMs在高级关系概念处理上具有初步但有限的能力。", "motivation": "探究LLMs是否能编码高级关系概念并将其应用到新情境中，填补现有研究对LLMs深层认知能力的理解空白。", "method": "使用比例类比和故事类比任务，分析LLMs在不同层级的表示传播，并通过策略性修补隐藏表示来测试信息传递效果。", "result": "LLMs能有效编码类比实体间的关系（中上层传播属性与关系信息），但在应用新实体时表现不佳；通过关键位置修补可有限改善；成功案例显示强结构对齐，失败则对齐退化。", "conclusion": "LLMs在编码和应用高级关系概念方面展现出初步但有限的能力，与人类认知存在相似性和差距，需要进一步研究提升其类比推理性能。"}}
{"id": "2511.20196", "pdf": "https://arxiv.org/pdf/2511.20196", "abs": "https://arxiv.org/abs/2511.20196", "authors": ["Zhen Zeng", "Leijiang Gu", "Zhangling Duan", "Feng Li", "Zenglin Shi", "Cees G. M. Snoek", "Meng Wang"], "title": "Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.", "AI": {"tldr": "SMFA方法通过记忆遗忘适配器和保留锚点掩码机制，实现MLLM对隐私信息的精确遗忘，同时保持模型的通用图像理解能力。", "motivation": "现有遗忘方法在移除多模态大语言模型中的隐私敏感信息时，会损害模型的通用图像理解性能，需要一种既能精确遗忘又能保持整体能力的解决方案。", "method": "提出Sculpted Memory Forgetting Adapter (SMFA)：1) 微调模型用拒绝回答替换敏感响应；2) 应用保留锚点引导的掩码机制防止干扰无关知识。", "result": "实验显示SMFA实现了精确可控的遗忘，同时保持了基础图像理解能力，优于现有方法。", "conclusion": "SMFA是首个能同时实现精确隐私信息遗忘和保持通用视觉理解能力的MLLM遗忘方法，并提出了专门的评估基准S-MLLMUn Bench。"}}
{"id": "2511.20399", "pdf": "https://arxiv.org/pdf/2511.20399", "abs": "https://arxiv.org/abs/2511.20399", "authors": ["Abdullah Al Sefat"], "title": "BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.", "AI": {"tldr": "BengaliFig是一个针对孟加拉语的紧凑型挑战数据集，包含435个来自口头和文学传统的谜语，用于评估大语言模型在低资源文化背景下的比喻和文化推理能力。", "motivation": "大语言模型虽然在多语言基准测试中表现优异，但在比喻和文化推理方面，特别是在低资源语境下，尚未得到充分评估。孟加拉语作为广泛使用但资源匮乏的语言，存在这一研究空白。", "method": "构建包含435个独特谜语的数据集，每个项目从五个正交维度进行标注（推理类型、陷阱类型、文化深度、答案类别和难度），并通过约束感知的AI辅助流程自动转换为多选题格式。评估了八个主流LLM在零样本和少样本思维链提示下的表现。", "result": "揭示了前沿LLM在隐喻和文化特定推理方面存在一致的弱点。", "conclusion": "BengaliFig不仅为评估LLM在低资源文化背景下的鲁棒性提供了诊断工具，也是朝着包容性和文化传承意识的NLP评估迈出的一步。"}}
{"id": "2511.20200", "pdf": "https://arxiv.org/pdf/2511.20200", "abs": "https://arxiv.org/abs/2511.20200", "authors": ["Yitian Huang", "Yuxuan Lei", "Jianxun Lian", "Hao Liao"], "title": "Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025", "categories": ["cs.AI"], "comment": null, "summary": "This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution", "AI": {"tldr": "MSRA_SC团队在CPDC 2025竞赛中提出了一个简单有效的统一框架，通过上下文工程和GRPO强化学习，在API和GPU赛道均取得优异排名。", "motivation": "解决常识人物对话挑战中工具调用稳定性、执行可靠性和角色扮演指导的问题，同时通过强化学习缓解小样本过拟合问题。", "method": "采用上下文工程（动态工具剪枝、人物剪裁、参数归一化、函数合并）和手动优化的提示词；在GPU赛道使用GRPO训练替代监督微调。", "result": "团队在最终评估中排名：Task 2 API第1名，Task 1 API第2名，Task 3 API和GPU赛道均第3名。", "conclusion": "该方法在常识人物对话任务中表现出色，证明了上下文工程和强化学习优化的有效性，代码已开源。"}}
{"id": "2511.20409", "pdf": "https://arxiv.org/pdf/2511.20409", "abs": "https://arxiv.org/abs/2511.20409", "authors": ["Md Abdullah Al Kafi", "Raka Moni", "Sumit Kumar Banshal"], "title": "A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines", "categories": ["cs.CL"], "comment": null, "summary": "Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).", "AI": {"tldr": "本研究提出了一种新的面向任务的词干提取评估框架，通过SES、MPD和ANLD三个指标全面评估词干提取方法的效用、下游任务影响和语义保持能力，发现高词干缩减率可能带来有害的过度词干提取问题。", "motivation": "当前词干提取评估方法有限，无法捕捉过度词干提取带来的潜在危害，需要开发新的评估方法来全面评估词干提取方法。", "method": "提出包含三个维度的评估框架：1)使用SES评估词干提取效用；2)使用MPD评估对下游任务的影响；3)使用ANLD评估词干化词与原始词的语义相似度。", "result": "在孟加拉语和英语词干提取器比较中发现：孟加拉语词干提取器SES最高(1.67)但ANLD较差(0.26)，存在有害的过度词干提取；英语词干提取器SES适中(1.31)且ANLD较好(0.14)，对下游任务有积极贡献。", "conclusion": "该研究提供了区分词干提取效率增益(SES)和语义保持(ANLD)的重要工具，证明需要综合评估框架来识别可靠的词干提取方法。"}}
{"id": "2511.20216", "pdf": "https://arxiv.org/pdf/2511.20216", "abs": "https://arxiv.org/abs/2511.20216", "authors": ["Haebin Seong", "Sungmin Kim", "Minchan Kim", "Yongjun Cho", "Myunchul Joe", "Suhwan Choi", "Jaeyoon Jung", "Jiyong Youn", "Yoonshik Kim", "Samwoo Seong", "Yubeen Park", "Youngjae Yu", "Yunsung Lee"], "title": "CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents", "categories": ["cs.AI", "cs.CE", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.", "AI": {"tldr": "CostNav是首个将导航任务成功指标与商业经济可行性相结合的微导航经济测试平台，通过完整的成本-收益分析揭示导航研究指标与商业部署之间的差距。", "motivation": "现有导航基准只关注任务成功率，忽略了商业部署中至关重要的经济可行性问题，这是自主配送机器人商业化部署的关键障碍。", "method": "建立包含硬件、训练、能源、维护成本和配送收入的完整经济生命周期模型，使用行业数据参数，从缩小尺度模拟扩展到实际配送场景。", "result": "基线方法达到43.0%的服务水平协议合规率，但每单亏损30.009美元且无盈亏平衡点，99.7%的运行成本来自碰撞导致的维护费用。", "conclusion": "CostNav填补了导航研究与商业部署之间的空白，为基于规则的导航、模仿学习和成本感知强化学习提供了经济权衡评估基础，碰撞避免成为关键优化目标。"}}
{"id": "2511.20459", "pdf": "https://arxiv.org/pdf/2511.20459", "abs": "https://arxiv.org/abs/2511.20459", "authors": ["Mosab Rezaei", "Mina Rajaei Moghadam", "Abdul Rahman Shaikh", "Hamed Alhoori", "Reva Freedman"], "title": "Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.", "AI": {"tldr": "本研究提出了一个使用大语言模型生成和评估19世纪小说家风格文本的框架，通过微调模型生成狄更斯、奥斯汀等作家的风格文本，并使用基于transformer的检测器进行自动化评估。", "motivation": "解决风格研究中缺乏配对数据训练生成模型的问题，以及不依赖人工判断的自动化风格评估需求。", "method": "使用最小化单token提示微调大语言模型生成特定作家风格文本，训练基于transformer的检测器进行分类和风格解释，结合句法比较和可解释AI方法分析语言特征。", "result": "生成的文本能够反映作家的独特风格模式，AI驱动的评估方法为人工评估提供了可靠的替代方案。", "conclusion": "该框架成功实现了风格文本的生成和自动化评估，为风格学研究提供了新的技术路径，所有研究成果已在线发布。"}}
{"id": "2511.20236", "pdf": "https://arxiv.org/pdf/2511.20236", "abs": "https://arxiv.org/abs/2511.20236", "authors": ["Szymon Bobek", "Łukasz Bałec", "Grzegorz J. Nalepa"], "title": "Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.", "AI": {"tldr": "提出DANCE方法生成多样化、可操作且知识约束的反事实解释，通过整合特征依赖和因果约束确保反事实的合理性和现实可行性，在140个公共数据集上表现优于现有方法。", "motivation": "现有反事实解释方法忽略现实数据集中的复杂依赖关系，导致生成不现实或不实用的修改，特别是在网络安全和邮件营销领域的应用需求。", "method": "学习线性和非线性约束（从数据中学习或整合专家提供的依赖图），保持特征关系一致性，平衡合理性、多样性和稀疏性。", "result": "能够生成有意义、领域相关的反事实解释，在广泛使用的评估指标上优于其他现有方法。", "conclusion": "DANCE方法通过整合特征依赖和因果约束，有效解决了现有算法的关键局限性，为机器学习模型提供了更实用和可操作的解释能力。"}}
{"id": "2511.20494", "pdf": "https://arxiv.org/pdf/2511.20494", "abs": "https://arxiv.org/abs/2511.20494", "authors": ["Jakub Hoscilowicz", "Artur Janicki"], "title": "Adversarial Confusion Attack: Disrupting Multimodal Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.", "AI": {"tldr": "提出了一种针对多模态大语言模型的新型对抗攻击方法——对抗混淆攻击，通过最大化下一个标记的熵来诱导模型产生不连贯或自信错误的输出，具有跨模型的强迁移性。", "motivation": "现有的对抗攻击主要针对越狱或目标误分类，而本研究旨在开发能够系统性地破坏MLLM可靠性，使其生成不连贯或自信错误输出的攻击方法，可用于阻止MLLM驱动的代理可靠运行。", "method": "使用小型开源MLLM集合，通过基本对抗技术（PGD）最大化下一个标记的熵，生成对抗性图像扰动，在完整图像和对抗性CAPTCHA设置中进行攻击。", "result": "在白盒设置下，单个对抗图像能够破坏集合中的所有模型，生成的扰动能够迁移到未见过的开源模型（如Qwen3-VL）和专有模型（如GPT-5.1）。", "conclusion": "对抗混淆攻击是一种有效的新型威胁，即使使用基本对抗技术也能产生强大的跨模型迁移效果，揭示了MLLM在面对系统性干扰时的脆弱性。"}}
{"id": "2511.20285", "pdf": "https://arxiv.org/pdf/2511.20285", "abs": "https://arxiv.org/abs/2511.20285", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho"], "title": "SMoG: Schema Matching on Graph", "categories": ["cs.AI"], "comment": null, "summary": "Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.", "AI": {"tldr": "SMoG：基于知识图谱的医疗模式匹配新框架，通过简单1跳SPARQL查询实现高效可靠的数据集成", "motivation": "解决LLM在医疗模式匹配中的幻觉问题和知识滞后性，同时克服现有KG增强方法的多跳查询复杂性和存储密集问题", "method": "提出SMoG框架，采用迭代执行简单1跳SPARQL查询的策略，直接从SPARQL端点查询，无需向量存储", "result": "在真实医疗数据集上实验表明，SMoG达到与最先进基线相当的性能，同时显著降低存储需求", "conclusion": "SMoG提供了一种高效、可解释且存储友好的知识图谱增强模式匹配解决方案，特别适用于医疗数据集成场景"}}
{"id": "2511.20507", "pdf": "https://arxiv.org/pdf/2511.20507", "abs": "https://arxiv.org/abs/2511.20507", "authors": ["Nathan Roll", "Jill Kries", "Flora Jin", "Catherine Wang", "Ann Marie Finley", "Meghan Sumner", "Cory Shain", "Laura Gwilliams"], "title": "The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have emerged as a candidate \"model organism\" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.", "AI": {"tldr": "本文提出了TAB（Text Aphasia Battery）基准测试，用于评估大语言模型在失语症相关语言缺陷方面的表现，并验证了自动化评估协议的有效性。", "motivation": "传统临床评估方法不适用于大语言模型，因为它们预设了人类特有的语用压力和认知过程。需要开发专门针对人工架构的语言缺陷评估工具。", "method": "基于Quick Aphasia Battery开发文本版本的TAB基准，包含四个子测试：连接文本、单词理解、句子理解和重复。使用Gemini 2.5 Flash验证自动化评估协议。", "result": "自动化评估协议达到了与专家人类评分者相当的可靠性（模型-共识一致性Cohen's kappa = 0.255，人类-人类一致性 = 0.286）。", "conclusion": "TAB提供了一个临床基础、可扩展的框架，用于分析人工系统中的语言缺陷，为大语言模型的语言障碍研究提供了有效工具。"}}
{"id": "2511.20297", "pdf": "https://arxiv.org/pdf/2511.20297", "abs": "https://arxiv.org/abs/2511.20297", "authors": ["Shashank Kirtania", "Param Biyani", "Priyanshu Gupta", "Yasharth Bajpai", "Roshni Iyer", "Sumit Gulwani", "Gustavo Soares"], "title": "Improving Language Agents through BREW", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.", "AI": {"tldr": "BREW框架通过构建和精化经验知识库来优化LLM智能体，替代传统权重优化方法，实现了更高的任务精度和效率，同时保持透明度和可解释性。", "motivation": "当前基于PPO和GRPO等权重优化方法的LLM智能体训练存在计算开销大、策略难以解释和增量改进的问题，需要更实用和可解释的优化方法。", "method": "提出BREW框架，通过任务评分和行为准则学习洞察，利用状态空间搜索确保鲁棒性，采用有效的记忆分区方法提高检索和精化效率。", "result": "在OSWorld、τ²Bench和SpreadsheetBench基准测试中，任务精度提升10-20%，API/工具调用减少10-15%，执行时间更快，计算效率与基础模型相当。", "conclusion": "BREW将知识库作为模块化、可控的优化基板，提供了透明、可解释和可扩展的行为塑造方式，为智能体优化提供了新途径。"}}
{"id": "2511.20534", "pdf": "https://arxiv.org/pdf/2511.20534", "abs": "https://arxiv.org/abs/2511.20534", "authors": ["Wesley Bian", "Xiaofeng Lin", "Guang Cheng"], "title": "Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition", "categories": ["cs.CL"], "comment": "Accepted at ICML 2025 Workshop on Machine Learning for Audio", "summary": "Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.", "AI": {"tldr": "本文提出了一种新颖的语音数据增强技术，专门针对低资源语言，通过实验证明该方法能显著提升自动语音识别系统在低资源语言上的性能，且优于现有增强策略。", "motivation": "当前机器学习模型在英语等资源丰富语言上表现优异，但在低资源语言上因训练数据稀缺而存在性能差距，数据收集既困难又昂贵。", "method": "引入了一种新颖的语音语料库数据增强技术", "result": "通过全面实验证明，该方法显著提高了自动语音识别系统在低资源语言上的性能，且优于现有的增强策略", "conclusion": "该方法为增强代表性不足语言社区的语音技术提供了实用解决方案，有助于缩小不同语言间的性能差距"}}
{"id": "2511.20312", "pdf": "https://arxiv.org/pdf/2511.20312", "abs": "https://arxiv.org/abs/2511.20312", "authors": ["Alexander Beiser", "Flavio Martinelli", "Wulfram Gerstner", "Johanni Brea"], "title": "Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries", "categories": ["cs.AI"], "comment": "Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)", "summary": "Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.", "AI": {"tldr": "论文提出针对教师网络逆向工程的新数据增强技术，在参数远多于训练数据的情况下成功恢复网络权重，将可恢复网络规模扩展到训练数据点的100倍。", "motivation": "现有方法在教师网络参数数量超过训练数据时失效，因为学生会过拟合查询数据而非对齐教师参数，需要更好的输入-输出映射采样技术。", "method": "设计专门针对网络隐藏层表示空间采样的新数据增强技术，相比标准增强方法（旋转、翻转、添加噪声）效果显著提升。", "result": "新增强技术显著提升了网络权重恢复能力，能够恢复参数数量是训练数据点100倍的网络，扩展了现有技术的可恢复网络规模范围。", "conclusion": "专门设计的表示空间增强技术是解决教师网络逆向工程中过拟合问题的有效方法，为大规模网络参数恢复提供了新途径。"}}
{"id": "2511.20547", "pdf": "https://arxiv.org/pdf/2511.20547", "abs": "https://arxiv.org/abs/2511.20547", "authors": ["Farjana Sultana Mim", "Shuchin Aeron", "Eric Miller", "Kristen Wendell"], "title": "From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding", "categories": ["cs.CL"], "comment": null, "summary": "Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.", "AI": {"tldr": "该研究构建了一个教育对话数据集，用于自动识别学生对话中的知识建构和任务完成话语特征，并测试了GPT-3.5和Llama-3.1等大型语言模型在此任务上的表现，发现现有模型表现不佳，为未来研究提供了方向。", "motivation": "教育研究者需要识别学生对话中的话语特征来分析课程和教学变量，但人工分析耗时费力。虽然自然语言处理技术可以自动化这一过程，但现有研究很少关注教育对话数据，因此需要填补这一空白。", "method": "研究引入了一个标注的教育对话数据集，包含知识建构和任务生产话语特征。使用预训练大型语言模型GPT-3.5和Llama-3.1建立基线模型，自动预测对话中每个话轮的话语属性。", "result": "实验结果表明，这些最先进的模型在此任务上表现欠佳，未能达到理想效果。", "conclusion": "当前的大型语言模型在教育对话话语特征识别任务上仍有改进空间，这为未来的研究提供了潜在的发展方向，需要进一步优化模型以适应教育领域的特定需求。"}}
{"id": "2511.20321", "pdf": "https://arxiv.org/pdf/2511.20321", "abs": "https://arxiv.org/abs/2511.20321", "authors": ["Patrick Kenny"], "title": "Active Inference in Discrete State Spaces from First Principles", "categories": ["cs.AI"], "comment": "56 pages", "summary": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.", "AI": {"tldr": "本文通过将主动推理与自由能原理分离，提出了一种基于约束散度最小化的新方法，使用标准平均场方法实现，无需依赖期望自由能概念", "motivation": "澄清主动推理的概念，将其从自由能原理中分离出来，提供更清晰的数学框架", "method": "将主动推理的优化问题表述为约束散度最小化问题，使用标准平均场方法求解，不依赖期望自由能概念", "result": "提出的感知/行动散度准则在建模感知时与变分自由能一致，在建模行动时通过熵正则化器与期望自由能泛函不同", "conclusion": "该方法为主动推理提供了更基础的理论基础，展示了如何在不诉诸自由能原理的情况下实现主动推理"}}
{"id": "2511.20604", "pdf": "https://arxiv.org/pdf/2511.20604", "abs": "https://arxiv.org/abs/2511.20604", "authors": ["Yixin Liu", "Pengfei Liu", "Arman Cohan"], "title": "On Evaluating LLM Alignment by Evaluating LLMs as Judges", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "NeurIPS 2025 Camera Ready", "summary": "Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.", "AI": {"tldr": "该论文提出了AlignEval基准，通过评估LLMs作为评判者的能力来间接衡量其与人类偏好的对齐程度，避免了直接评估生成输出的需求，发现生成与评估能力高度相关。", "motivation": "现有的大语言模型对齐评估通常需要直接评估开放生成内容，依赖人工标注或强LLM评判者，过程成本高昂且复杂。", "method": "首先分析各种LLMs的生成-评估一致性(GE-consistency)，发现生成与评估能力强相关；基于此提出AlignEval基准，通过评估LLMs作为评判者的能力来间接衡量对齐程度。", "result": "AlignEval基准在排名LLMs时，在捕捉人类偏好方面匹配或超越了AlpacaEval和Arena-Hard等广泛使用的自动评估基准。", "conclusion": "研究揭示了LLMs生成与评估能力之间的联系，并提供了无需直接评估模型输出即可评估对齐性的有效基准方法。"}}
{"id": "2511.20333", "pdf": "https://arxiv.org/pdf/2511.20333", "abs": "https://arxiv.org/abs/2511.20333", "authors": ["Roman Kochnev", "Waleed Khalid", "Tolgay Atinc Uzun", "Xi Zhang", "Yashkumar Sanjaybhai Dhameliya", "Furui Qin", "Chandini Vysyaraju", "Raghuvir Duvvuri", "Avi Goyal", "Dmitry Ignatov", "Radu Timofte"], "title": "NNGPT: Rethinking AutoML with Large Language Models", "categories": ["cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.", "AI": {"tldr": "NNGPT是一个开源框架，将大语言模型转变为自改进的AutoML引擎，通过生成新模型、评估和自改进的闭环系统，实现神经网络开发的自动化优化。", "motivation": "构建自改进的AI系统是AI领域的根本挑战，现有框架在神经网络开发自动化方面存在局限，需要更高效的AutoML解决方案。", "method": "集成五个协同的LLM管道：零样本架构合成、超参数优化、代码感知精度预测、检索增强的PyTorch块合成和强化学习，基于LEMUR数据集构建闭环系统。", "result": "NN-RAG达到73%可执行性，3-shot提示提升准确率，HPO在LEMUR上RMSE 0.60优于Optuna，代码感知预测器RMSE 0.14，已生成超过5K验证模型。", "conclusion": "NNGPT证明可作为自主AutoML引擎，显著减少试验需求，性能优于现有方法，代码和检查点将公开以促进可重复性和社区使用。"}}
{"id": "2511.20639", "pdf": "https://arxiv.org/pdf/2511.20639", "abs": "https://arxiv.org/abs/2511.20639", "authors": ["Jiaru Zou", "Xiyuan Yang", "Ruizhong Qiu", "Gaotang Li", "Katherine Tieu", "Pan Lu", "Ke Shen", "Hanghang Tong", "Yejin Choi", "Jingrui He", "James Zou", "Mengdi Wang", "Ling Yang"], "title": "Latent Collaboration in Multi-Agent Systems", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Project: https://github.com/Gen-Verse/LatentMAS", "summary": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.", "AI": {"tldr": "LatentMAS是一个无需训练的多智能体协作框架，通过在潜在空间中直接交换隐藏表示而非文本，实现了更高的表达能力和无损信息传递，在多个基准测试中显著提升性能同时大幅降低计算成本。", "motivation": "现有LLM智能体依赖基于文本的中介进行推理和通信，存在信息损失和效率低下的问题，需要探索更高效的直接潜在空间协作方式。", "method": "提出LatentMAS框架：每个智能体通过最后一层隐藏嵌入进行自回归潜在思维生成，使用共享潜在工作内存保存和传输内部表示，实现无损信息交换。", "result": "在9个基准测试中，LatentMAS相比基线方法准确率提升高达14.6%，输出token使用减少70.8%-83.7%，端到端推理速度提升4-4.3倍。", "conclusion": "潜在协作框架能够显著提升系统级推理质量，同时在不增加训练成本的情况下提供显著的效率增益，为多智能体系统的发展提供了新方向。"}}
{"id": "2511.20422", "pdf": "https://arxiv.org/pdf/2511.20422", "abs": "https://arxiv.org/abs/2511.20422", "authors": ["Bo Pang", "Chenxi Xu", "Jierui Ren", "Guoping Wang", "Sheng Li"], "title": "VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning", "categories": ["cs.AI", "cs.CV", "cs.GR", "cs.RO"], "comment": null, "summary": "Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.", "AI": {"tldr": "VibraVerse是一个连接3D几何形状与声学信号的大型多模态数据集，通过物理定律建立从几何结构到声音产生的因果链，并提出了CLASP对比学习框架来保证跨模态的物理一致性。", "motivation": "现有的多模态学习框架缺乏物理一致性，忽略了物体几何、材料、振动模式和声音之间的内在因果关系，需要建立基于物理定律的感知模型。", "method": "创建VibraVerse数据集，包含3D模型的物理属性（密度、杨氏模量、泊松比）和体积几何，计算模态特征参数进行撞击声音合成；提出CLASP对比学习框架进行跨模态对齐。", "result": "在几何到声音预测、声音引导形状重建和跨模态表示学习等基准任务上表现出优异的准确性、可解释性和泛化能力。", "conclusion": "VibraVerse为物理一致性和因果可解释的多模态学习建立了基准，为声音引导的具身感知和物理世界理解提供了基础，数据集将开源。"}}
{"id": "2511.20468", "pdf": "https://arxiv.org/pdf/2511.20468", "abs": "https://arxiv.org/abs/2511.20468", "authors": ["Yuanhao Li", "Mingshan Liu", "Hongbo Wang", "Yiding Zhang", "Yifei Ma", "Wei Tan"], "title": "DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed", "AI": {"tldr": "DRAFT-RL是一个新颖的多智能体强化学习框架，通过链式草稿生成和多路径探索，显著提升了LLM在复杂推理任务中的性能和收敛速度。", "motivation": "现有的多智能体反思框架依赖单次响应生成，缺乏推理探索的结构多样性，限制了LLM在复杂任务中的表现。", "method": "提出DRAFT-RL框架，每个智能体为每个查询生成多个草稿，通过同伴智能体和学习到的奖励模型评估，选择最有前景的轨迹，并通过actor-critic学习优化推理策略。", "result": "在代码合成、符号数学和知识密集型问答等复杂推理任务中，DRAFT-RL在准确性和收敛速度上都显著优于现有的反思和基于RL的智能体。", "conclusion": "DRAFT-RL通过多路径探索、同伴引导反思和奖励对齐选择，实现了更鲁棒和可解释的LLM智能体行为，为多智能体强化学习提供了新的有效方法。"}}
{"id": "2511.20471", "pdf": "https://arxiv.org/pdf/2511.20471", "abs": "https://arxiv.org/abs/2511.20471", "authors": ["Yuto Suzuki", "Farnoush Banaei-Kashani"], "title": "Universe of Thoughts: Enabling Creative Reasoning with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.", "AI": {"tldr": "论文提出了一个基于大语言模型的创造性推理框架(UoT)，包含组合、探索和转化三种推理范式，通过系统性探索思维宇宙来生成创新解决方案，在需要创造性问题解决的领域表现优于现有方法。", "motivation": "现有推理模型主要关注传统问题解决，无法生成创造性解决方案，而在药物发现、商业策略等解决方案空间广阔且传统方案次优的领域，创造性推理至关重要。", "method": "引入受认知科学启发的计算框架，提出三种创造性推理范式(组合、探索、转化)，开发UoT方法实现这些过程，并创建新的评估基准从可行性、实用性和新颖性三个维度评估创造力。", "result": "与最先进的推理技术和代表性商业模型相比，UoT在创造性推理方面表现出优越性能。", "conclusion": "UoT框架为LLMs的创造性推理提供了系统化方法，在需要创新解决方案的领域具有重要应用价值，为AI的创造性问题解决能力开辟了新方向。"}}
{"id": "2511.20497", "pdf": "https://arxiv.org/pdf/2511.20497", "abs": "https://arxiv.org/abs/2511.20497", "authors": ["Van Tran", "Shinan Liu", "Tian Li", "Nick Feamster"], "title": "Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic", "categories": ["cs.AI"], "comment": "14 pages, 13 Figures, 6 Tables", "summary": "To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.", "AI": {"tldr": "本文提出了一个针对合成网络流量隐私泄露的综合评估框架，通过成员推理攻击和数据提取攻击等方法，发现不同生成模型的隐私风险差异显著，攻击成功率从0%到100%不等，并识别了影响攻击效果的关键因素。", "motivation": "针对合成网络流量数据稀缺和隐私问题，现有生成模型缺乏对隐私泄露程度的系统评估方法，特别是不同模型架构对隐私保护的影响尚未深入研究。", "method": "引入了一套全面的隐私度量标准，结合成员推理攻击(MIA)、数据提取攻击以及网络特定标识符和属性，系统评估不同代表性生成模型的脆弱性。", "result": "研究结果显示模型间隐私风险差异显著：MIA成功率从0%到88%，网络标识符恢复率可达100%，训练数据多样性和模型拟合程度是影响攻击成功的关键因素。", "conclusion": "该研究为设计和部署最小化隐私泄露的生成模型提供了可操作的指导，为更安全的合成网络流量生成奠定了基础。"}}
{"id": "2511.20510", "pdf": "https://arxiv.org/pdf/2511.20510", "abs": "https://arxiv.org/abs/2511.20510", "authors": ["Yuto Suzuki", "Paul Awolade", "Daniel V. LaBarbera", "Farnoush Banaei-Kashani"], "title": "FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a \"vocabulary selection\" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.", "AI": {"tldr": "FRAGMENTA是一个用于药物先导化合物优化的端到端框架，包含创新的生成模型和智能AI系统，通过动态Q学习和对话反馈解决小数据集下的分子生成问题，在癌症药物发现中显著优于传统方法", "motivation": "传统分子生成方法在小数据集（<100样本）下表现不佳，现有启发式碎片化方法限制多样性且遗漏关键片段，同时模型调优需要药物化学家与AI工程师之间缓慢的间接协作", "method": "1) 新颖生成模型：将碎片化重构为\"词汇选择\"问题，使用动态Q学习联合优化碎片化和生成过程；2) 智能AI系统：通过领域专家的对话反馈精炼目标，逐步学习领域知识实现自动化调优", "result": "在真实癌症药物发现实验中，FRAGMENTA的人机配置识别的高分分子数量是基线的近两倍，完全自主的智能系统甚至超越了传统人-人调优方法", "conclusion": "FRAGMENTA框架有效解决了小数据集分子生成和专家意图捕获问题，展示了智能调优在药物发现中的高效性，能够实现从人机协作到完全自主的过渡"}}
{"id": "2511.20526", "pdf": "https://arxiv.org/pdf/2511.20526", "abs": "https://arxiv.org/abs/2511.20526", "authors": ["Xinran Wang", "Boran Zhu", "Shujuan Zhou", "Ziwen Long", "Dehua Zhou", "Shu Zhang"], "title": "Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam", "categories": ["cs.AI"], "comment": "15 pages, 4 figures", "summary": "Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.", "AI": {"tldr": "本研究比较了ChatGPT-4o和DeepSeek-R1在中国药师执业资格考试中的表现，发现DeepSeek-R1以90.0%的准确率显著优于ChatGPT-4o的76.1%，特别是在基础和临床综合模块表现突出。", "motivation": "随着大语言模型在数字健康教育和评估中的应用日益增多，需要评估其在药学领域高利害认证任务中的能力，中国药师执业资格考试为此提供了标准化基准。", "method": "收集2017-2021年2306道纯文本选择题，排除含表格或图像的题目，以原始中文格式输入模型，使用精确匹配评估准确性，采用卡方检验和Fisher精确检验进行统计分析。", "result": "DeepSeek-R1总体准确率90.0%显著高于ChatGPT-4o的76.1%（p<0.001），在基础和临床综合模块表现一致更优，但年度间差异未达到统计学显著性。", "conclusion": "DeepSeek-R1在药师资格考试中表现出色，表明领域特定模型在此类场景具有潜力，但仍需在法律法规敏感场景中保持人类监督。"}}
{"id": "2511.20531", "pdf": "https://arxiv.org/pdf/2511.20531", "abs": "https://arxiv.org/abs/2511.20531", "authors": ["Shamima Hossain"], "title": "Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted as poster at NewInML Workshop ICML, 2025", "summary": "Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.", "AI": {"tldr": "该论文提出了一个基于知识图谱的视觉语言模型推理框架，通过多步推理（视觉实体识别、知识图谱遍历、基于事实的标题精炼）来提高事实准确性，在实验中实现了约31%的准确性提升。", "motivation": "视觉语言模型(VLMs)虽然功能强大，但由于缺乏稳健的推理能力，经常产生事实不准确的输出。当前关于在大型语言模型中整合外部知识进行推理的研究很多，但在VLMs中这方面的探索仍然不足，且需要解决多模态无缝桥接的挑战。", "method": "提出了一个知识引导的VLM推理框架，利用结构化知识图谱进行多跳验证，使用图像标题生成任务来展示框架。方法包括系统性的多步推理：视觉实体识别、知识图谱遍历和基于事实的标题精炼。评估了分层、三元组和项目符号三种知识表示形式的有效性。", "result": "在由Google Landmarks v2、Conceptual captions和Coco captions组成的策划数据集上进行初步实验，结果显示该方法将事实准确性提高了约31%，并揭示了推理模式和失败模式的关键见解。", "conclusion": "这项工作展示了整合外部知识来推进VLM推理的潜力，为构建更可靠和知识丰富的多模态系统铺平了道路。"}}
{"id": "2511.20586", "pdf": "https://arxiv.org/pdf/2511.20586", "abs": "https://arxiv.org/abs/2511.20586", "authors": ["Koffi Ismael Ouattara", "Ioannis Krontiris", "Theo Dimitrakos", "Dennis Eisermann", "Frank Kargl"], "title": "PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.", "AI": {"tldr": "本文提出了PaTAS框架，使用主观逻辑在神经网络中建模和传播信任度，通过并行信任节点和函数评估输入、参数和激活的可靠性，提供可解释的信任估计来补充传统精度指标。", "motivation": "传统评估指标如准确率和精度无法捕捉模型预测的不确定性或可靠性，特别是在对抗性或退化条件下，这在安全关键应用中至关重要。", "method": "提出Parallel Trust Assessment System (PaTAS)框架，使用主观逻辑，通过信任节点和信任函数在网络中传播输入、参数和激活信任度，包括参数信任更新机制和推理路径信任评估方法。", "result": "实验表明PaTAS产生可解释、对称和收敛的信任估计，有效区分良性输入和对抗输入，识别模型置信度与实际可靠性不一致的情况。", "conclusion": "PaTAS通过在神经网络架构中实现透明和可量化的信任推理，为评估AI生命周期中的模型可靠性提供了原则性基础。"}}
{"id": "2511.20610", "pdf": "https://arxiv.org/pdf/2511.20610", "abs": "https://arxiv.org/abs/2511.20610", "authors": ["Gaspard Merten", "Mahmoud Sakr", "Gilles Dejaegere"], "title": "Building a Foundation Model for Trajectory from Scratch", "categories": ["cs.AI"], "comment": null, "summary": "Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.", "AI": {"tldr": "本教程提供了一个从GPT-2开始的轨迹基础模型最小实现指南，包含代码步骤、模型比较和相关技术介绍，旨在帮助研究人员构建和评估移动性基础模型。", "motivation": "虽然基础模型在AI领域具有变革性，但针对移动轨迹的基础模型从零构建的方法尚不明确且缺乏文档记录，需要为SIGSPATIAL社区提供教育材料来支持研究。", "method": "通过逐步代码驱动的过程，展示如何将GPT-2适配到时空数据，并比较TrajFM、TrajGPT等代表性轨迹基础模型的架构创新和差异，引入TimesFM的补丁方法等补充技术。", "result": "提供了一个完整的教育教程，包括概念解释、术语说明和实际实现步骤，支持社区构建和评估移动性基础模型。", "conclusion": "该教程及时且必要，能够增强移动性AI领域的研究清晰度和同行评审有效性，为研究人员和从业者提供了宝贵的实践指导。"}}
{"id": "2511.20623", "pdf": "https://arxiv.org/pdf/2511.20623", "abs": "https://arxiv.org/abs/2511.20623", "authors": ["David Szczecina", "Senan Gaffori", "Edmond Li"], "title": "Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development", "categories": ["cs.AI"], "comment": "4 pages, 3 figures", "summary": "The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.", "AI": {"tldr": "开发了一个开源版权检测平台，帮助内容创作者检测其作品是否被用于LLM训练数据，相比现有方法计算开销减少10-30%，并提供用户友好的界面。", "motivation": "大型语言模型广泛使用引发版权担忧，现有检测框架计算密集且不易访问，需要可扩展、透明和用户友好的解决方案来保护创作者权益。", "method": "通过优化API调用效率，改进相似性检测和数据集验证方法，构建直观用户界面和可扩展后端系统。", "result": "成功开发出开源平台，计算开销降低10-30%，提高了检测效率和用户体验。", "conclusion": "该框架有助于提高AI开发的透明度，促进伦理合规，为负责任AI发展和版权执法研究奠定基础。"}}
{"id": "2511.20627", "pdf": "https://arxiv.org/pdf/2511.20627", "abs": "https://arxiv.org/abs/2511.20627", "authors": ["Anastasia Mavridou", "Divya Gopinath", "Corina S. Păsăreanu"], "title": "Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems", "categories": ["cs.AI"], "comment": null, "summary": "The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.", "AI": {"tldr": "该论文提出了REACT和SemaLens两个AI驱动的组件，用于解决安全关键系统中AI组件的验证挑战。REACT使用大语言模型连接自然语言需求与形式化规范，SemaLens使用视觉语言模型验证基于DNN的感知系统。", "motivation": "AI组件（特别是深度神经网络）在安全关键系统中的应用面临验证困难，包括AI系统的不透明性、高层次需求与低层次网络表示之间的语义鸿沟，以及需求工程中长期存在的模糊性和可扩展性问题。", "method": "提出双组件方法：1) REACT使用大语言模型(LLMs)将非正式自然语言需求转换为形式化规范，实现早期验证；2) SemaLens使用视觉语言模型(VLMs)基于人类可理解概念对DNN感知系统进行推理、测试和监控。", "result": "构建了一个从非正式需求到已验证实现的完整流程，能够有效弥合语义鸿沟，提高AI系统的可验证性和安全性。", "conclusion": "通过利用AI技术本身来解决AI系统验证的挑战，该研究为安全关键系统中AI组件的可靠集成提供了创新解决方案，结合自然语言处理和计算机视觉技术实现了端到端的验证流程。"}}
