<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 77]
- [cs.AI](#cs.AI) [总数: 13]
- [stat.ML](#stat.ML) [总数: 9]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
*Sajid Hussain, Muhammad Sohail, Nauman Ali Khan, Naima Iltaf, Ihtesham ul Islam*

**主要类别:** cs.LG

**AI概要:** SAFL是一种基于数据集大小特性的渐进式联邦学习框架，通过实验证明了1000-1500样本是最佳范围，并揭示了不同模态数据的性能差异。该框架在所有数据集上平均准确率达到87.68%，结构化数据可达99%以上。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦学习方法主要关注模型异构性和聚合技术，而忽略了数据集大小对联邦训练动态的根本影响。

**方法:** 引入了一种新的渐进式训练框架——基于大小的自适应联邦学习（SAFL），它根据跨异构多模态数据的数据集大小特性系统地组织联邦学习。

**结果:** 实验表明：1）1000-1500样本为联邦学习的有效性提供了最佳数据集大小范围；2）存在明显的模态性能层次结构，结构化数据显著优于非结构化数据；3）对于超过2000个样本的大数据集，性能系统性下降。SAFL在所有数据集上的平均准确率为87.68%，结构化数据模态的准确率可达到99%以上。同时，SAFL展示了优越的通信效率，减少了总数据传输量。

**结论:** 这项工作填补了如何利用数据特性驱动联邦学习策略的关键空白，为神经网络和学习系统的实际FL部署提供了理论见解和实用指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Progressive+Size-Adaptive+Federated+Learning%3A+A+Comprehensive+Framework+for+Heterogeneous+Multi-Modal+Data+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20685，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20685&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) has emerged as a transformative paradigm for
distributed machine learning while preserving data privacy. However, existing
approaches predominantly focus on model heterogeneity and aggregation
techniques, largely overlooking the fundamental impact of dataset size
characteristics on federated training dynamics. This paper introduces
Size-Based Adaptive Federated Learning (SAFL), a novel progressive training
framework that systematically organizes federated learning based on dataset
size characteristics across heterogeneous multi-modal data. Our comprehensive
experimental evaluation across 13 diverse datasets spanning 7 modalities
(vision, text, time series, audio, sensor, medical vision, and multimodal)
reveals critical insights: 1) an optimal dataset size range of 1000-1500
samples for federated learning effectiveness; 2) a clear modality performance
hierarchy with structured data (time series, sensor) significantly
outperforming unstructured data (text, multimodal); and 3) systematic
performance degradation for large datasets exceeding 2000 samples. SAFL
achieves an average accuracy of 87.68% across all datasets, with structured
data modalities reaching 99%+ accuracy. The framework demonstrates superior
communication efficiency, reducing total data transfer to 7.38 GB across 558
communications while maintaining high performance. Our real-time monitoring
framework provides unprecedented insights into system resource utilization,
network efficiency, and training dynamics. This work fills critical gaps in
understanding how data characteristics should drive federated learning
strategies, providing both theoretical insights and practical guidance for
real-world FL deployments in neural network and learning systems.

</details>


### [2] [E-ABIN: an Explainable module for Anomaly detection in BIological Networks](https://arxiv.org/abs/2506.20693)
*Ugo Lomoio, Tommaso Mazza, Pierangelo Veltri, Pietro Hiram Guzzi*

**主要类别:** cs.LG

**AI概要:** 随着大规模组学数据的日益增多，需要稳健的分析框架来处理复杂的基因表达数据集并提供可解释的结果。人工智能的最新进展使得能够区分疾病状态与健康对照的异常分子模式的识别成为可能。结合模型可解释性的改进，这些工具现在支持识别可能驱动疾病表型的基因。然而，当前的基因异常检测方法通常局限于单一数据集，并且缺乏易用的图形界面。本文介绍了E-ABIN，一个通用的、可解释的生物网络异常检测框架。E-ABIN将经典机器学习和基于图的深度学习技术结合在一个统一的、用户友好的平台上，能够从基因表达或甲基化衍生的网络中检测和解释异常。通过整合如支持向量机、随机森林、图自编码器（GAEs）和图对抗属性网络（GAANs）等算法，E-ABIN确保了高预测准确性的同时保持了可解释性。通过膀胱癌和乳糜泻的案例研究，证明了E-ABIN的有效性，它成功揭示了生物学相关的异常，并提供了对疾病机制的见解。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基因异常检测方法通常局限于单一数据集，且缺乏易用的图形界面，限制了其广泛应用和用户的便利性。因此，需要一种更通用、可解释且用户友好的框架来检测和解释生物网络中的异常。

**方法:** E-ABIN结合了经典机器学习（如支持向量机、随机森林）和基于图的深度学习技术（如图自编码器、图对抗属性网络），构建了一个统一的、用户友好的平台。该平台可以从基因表达或甲基化衍生的网络中检测和解释异常。

**结果:** 通过膀胱癌和乳糜泻的案例研究，E-ABIN成功揭示了生物学相关的异常，提供了对疾病机制的见解，并展示了其在实际应用中的高效性和可解释性。

**结论:** E-ABIN作为一个通用的、可解释的生物网络异常检测框架，能够有效检测和解释复杂基因表达数据中的异常，为理解疾病机制提供了有价值的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是E-ABIN%3A+an+Explainable+module+for+Anomaly+detection+in+BIological+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20693，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20693&send_immediately=true&force_search=false)

**原文摘要:** The increasing availability of large-scale omics data calls for robust
analytical frameworks capable of handling complex gene expression datasets
while offering interpretable results. Recent advances in artificial
intelligence have enabled the identification of aberrant molecular patterns
distinguishing disease states from healthy controls. Coupled with improvements
in model interpretability, these tools now support the identification of genes
potentially driving disease phenotypes. However, current approaches to gene
anomaly detection often remain limited to single datasets and lack accessible
graphical interfaces. Here, we introduce E-ABIN, a general-purpose, explainable
framework for Anomaly detection in Biological Networks. E-ABIN combines
classical machine learning and graph-based deep learning techniques within a
unified, user-friendly platform, enabling the detection and interpretation of
anomalies from gene expression or methylation-derived networks. By integrating
algorithms such as Support Vector Machines, Random Forests, Graph Autoencoders
(GAEs), and Graph Adversarial Attributed Networks (GAANs), E-ABIN ensures a
high predictive accuracy while maintaining interpretability. We demonstrate the
utility of E-ABIN through case studies of bladder cancer and coeliac disease,
where it effectively uncovers biologically relevant anomalies and offers
insights into disease mechanisms.

</details>


### [3] [On Context-Content Uncertainty Principle](https://arxiv.org/abs/2506.20699)
*Xin Li*

**主要类别:** cs.LG

**AI概要:** 本论文提出了基于上下文-内容不确定性原则（CCUP）的分层计算框架，通过结构优先和内容引导的推理方法，优化资源分配、时间引导学习以及空间层级组合，为大脑和机器如何通过递归结构特异性对齐来最小化不确定性提供了统一理论基础。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望解释在不确定性条件下进行推理的基本机制，并提出一种新的理论框架，即上下文-内容不确定性原则（CCUP），以说明高熵上下文如何通过低熵内容的结构化对齐来实现有效的推理。

**方法:** 论文采用分层计算框架，从基本的不对称熵原理出发，定义了四个操作原则层次：核心推理约束（L1）、资源分配原则（L2）、时间引导动力学（L3）和空间层级组合（L4）。并通过正式等价性定理、依赖关系晶格和计算模拟验证这些原则的效率提升。

**结果:** 研究表明，遵循CCUP原则的推理方法显著提高了效率，并且揭示了大脑和机器通过递归结构特异性对齐来最小化不确定性的统一理论基础。

**结论:** 大脑不仅仅是推理机器，而是一个周期一致的熵梯度解析器，通过路径依赖的内容种子模拟实现结构与特异性的对齐，从而有效解决不确定性问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Context-Content+Uncertainty+Principle，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20699，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20699&send_immediately=true&force_search=false)

**原文摘要:** The Context-Content Uncertainty Principle (CCUP) proposes that inference
under uncertainty is governed by an entropy asymmetry between context and
content: high-entropy contexts must be interpreted through alignment with
low-entropy, structured content. In this paper, we develop a layered
computational framework that derives operational principles from this
foundational asymmetry. At the base level, CCUP formalizes inference as
directional entropy minimization, establishing a variational gradient that
favors content-first structuring. Building upon this, we identify four
hierarchical layers of operational principles: (\textbf{L1}) \emph{Core
Inference Constraints}, including structure-before-specificity, asymmetric
inference flow, cycle-consistent bootstrapping, and conditional compression,
all shown to be mutually reducible; (\textbf{L2}) \emph{Resource Allocation
Principles}, such as precision-weighted attention, asymmetric learning rates,
and attractor-based memory encoding; (\textbf{L3}) \emph{Temporal Bootstrapping
Dynamics}, which organize learning over time via structure-guided curricula;
and (\textbf{L4}) \emph{Spatial Hierarchical Composition}, which integrates
these mechanisms into self-organizing cycles of memory, inference, and
planning. We present formal equivalence theorems, a dependency lattice among
principles, and computational simulations demonstrating the efficiency gains of
CCUP-aligned inference. This work provides a unified theoretical foundation for
understanding how brains and machines minimize uncertainty through recursive
structure-specificity alignment. The brain is not just an inference machine. It
is a cycle-consistent entropy gradient resolver, aligning structure and
specificity via path-dependent, content-seeded simulation.

</details>


### [4] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
*Vineet Jain, Kusha Sareen, Mohammad Pedramfar, Siamak Ravanbakhsh*

**主要类别:** cs.LG

**AI概要:** 通过将推理时对齐视为一个搜索问题，引入树状方法重用过去计算，提出扩散树采样（DTS）和其贪婪变体扩散树搜索（DTS$^\star$），以更高效地生成样本。


<details>
  <summary>更多</summary>
  
**动机:** 现有的引导方法在高噪声水平下价值估计不准确，并且未重用过去运行中的信息来提高样本质量，导致计算效率低下。

**方法:** 受蒙特卡洛树搜索成功的启发，将推理时间对齐视为一个搜索问题，介绍了一种基于树的方法，通过将终端奖励传播回扩散链并随着每次额外生成迭代改进价值估计，从奖励对齐的目标密度中采样。

**结果:** 在MNIST和CIFAR-10类条件生成任务中，DTS仅需最佳基线的$1/10$计算量即可达到相同的FID；在文本到图像生成和语言完成任务中，DTS$^\star$以最多减少$5$倍计算量有效地搜索高奖励样本。

**结论:** 通过重用先前代的信息，得到一种随时算法，可将额外计算转化为持续更好的样本，为扩散模型的推理时间对齐提供了一种可扩展的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion+Tree+Sampling%3A+Scalable+inference-time+alignment+of+diffusion+models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20701，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20701&send_immediately=true&force_search=false)

**原文摘要:** Adapting a pretrained diffusion model to new objectives at inference time
remains an open problem in generative modeling. Existing steering methods
suffer from inaccurate value estimation, especially at high noise levels, which
biases guidance. Moreover, information from past runs is not reused to improve
sample quality, resulting in inefficient use of compute. Inspired by the
success of Monte Carlo Tree Search, we address these limitations by casting
inference-time alignment as a search problem that reuses past computations. We
introduce a tree-based approach that samples from the reward-aligned target
density by propagating terminal rewards back through the diffusion chain and
iteratively refining value estimates with each additional generation. Our
proposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact
samples from the target distribution in the limit of infinite rollouts, and its
greedy variant, Diffusion Tree Search (DTS$^\star$), performs a global search
for high reward samples. On MNIST and CIFAR-10 class-conditional generation,
DTS matches the FID of the best-performing baseline with up to $10\times$ less
compute. In text-to-image generation and language completion tasks, DTS$^\star$
effectively searches for high reward samples that match best-of-N with up to
$5\times$ less compute. By reusing information from previous generations, we
get an anytime algorithm that turns additional compute into steadily better
samples, providing a scalable approach for inference-time alignment of
diffusion models.

</details>


### [5] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
*Kin Kwan Leung, Rasa Hosseinzadeh, Gabriel Loaiza-Ganem*

**主要类别:** cs.LG

**AI概要:** 这篇论文通过正式证明FLIPD在实际假设下的正确性，弥补了其理论基础的不足，并扩展了其适用范围到均匀卷积的情况。


<details>
  <summary>更多</summary>
  
**动机:** 扩散模型（DMs）能够学习低维分布支持的数据，因此可以推测它们也隐式地学习了局部固有维度（LID）。然而，现有的FLIPD估计器的理论基础不完整，因为它仅在不切实际的仿射子流形假设下被证明。

**方法:** 作者在更现实的假设下正式证明了FLIPD的正确性，并且展示了当高斯卷积被均匀卷积取代时，类似的结论仍然成立。

**结果:** 作者成功证明了FLIPD在更广泛的条件下是正确的，并讨论了这一结果的相关性。

**结论:** 该研究弥补了FLIPD理论基础的空白，并扩展了其适用范围，使其不仅适用于高斯卷积，还适用于均匀卷积的情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Convolutions%2C+Intrinsic+Dimension%2C+and+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20705&send_immediately=true&force_search=false)

**原文摘要:** The manifold hypothesis asserts that data of interest in high-dimensional
ambient spaces, such as image data, lies on unknown low-dimensional
submanifolds. Diffusion models (DMs) -- which operate by convolving data with
progressively larger amounts of Gaussian noise and then learning to revert this
process -- have risen to prominence as the most performant generative models,
and are known to be able to learn distributions with low-dimensional support.
For a given datum in one of these submanifolds, we should thus intuitively
expect DMs to have implicitly learned its corresponding local intrinsic
dimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari
et al. (2024b) recently showed that this is indeed the case by linking this LID
to the rate of change of the log marginal densities of the DM with respect to
the amount of added noise, resulting in an LID estimator known as FLIPD. LID
estimators such as FLIPD have a plethora of uses, among others they quantify
the complexity of a given datum, and can be used to detect outliers,
adversarial examples and AI-generated text. FLIPD achieves state-of-the-art
performance at LID estimation, yet its theoretical underpinnings are incomplete
since Kamkari et al. (2024b) only proved its correctness under the highly
unrealistic assumption of affine submanifolds. In this work we bridge this gap
by formally proving the correctness of FLIPD under realistic assumptions.
Additionally, we show that an analogous result holds when Gaussian convolutions
are replaced with uniform ones, and discuss the relevance of this result.

</details>


### [6] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
*Zhiqi Gao, Tianyi Li, Yurii Kvasiuk, Sai Chaitanya Tadepalli, Maja Rudolph, Daniel J. H. Chung, Frederic Sala, Moritz Münchmeyer*

**主要类别:** cs.LG

**AI概要:** 大型语言模型在复杂推理方面表现出强大的能力，测试时扩展技术可以较低成本增强其性能。本文研究了数学推理基准中学到的经验是否适用于高级理论物理领域，并开发了一种新的符号弱验证框架以改进并行扩展结果，该方法在TPBench和AIME数据集上均表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 评估数学推理基准上的方法是否可以推广到高级理论物理领域，以探索解决复杂科学问题的有效方法。

**方法:** 在TPBench物理数据集上评估一系列常见的测试时扩展方法，并与AIME结果进行比较；开发一种新的符号弱验证框架以更好地利用物理问题的结构特性。

**结果:** 新开发的符号弱验证框架在TPBench数据集上显著优于现有的测试时扩展方法，并且在AIME数据集上也验证了其有效性。

**结论:** 逐步符号验证方法对于解决复杂的科学问题具有强大潜力，能够有效提升大型语言模型在高级理论物理和数学推理任务中的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Test-time+Scaling+Techniques+in+Theoretical+Physics+--+A+Comparison+of+Methods+on+the+TPBench+Dataset，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20729，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20729&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have shown strong capabilities in complex
reasoning, and test-time scaling techniques can enhance their performance with
comparably low cost. Many of these methods have been developed and evaluated on
mathematical reasoning benchmarks such as AIME. This paper investigates whether
the lessons learned from these benchmarks generalize to the domain of advanced
theoretical physics. We evaluate a range of common test-time scaling methods on
the TPBench physics dataset and compare their effectiveness with results on
AIME. To better leverage the structure of physics problems, we develop a novel,
symbolic weak-verifier framework to improve parallel scaling results. Our
empirical results demonstrate that this method significantly outperforms
existing test-time scaling approaches on TPBench. We also evaluate our method
on AIME, confirming its effectiveness in solving advanced mathematical
problems. Our findings highlight the power of step-wise symbolic verification
for tackling complex scientific problems.

</details>


### [7] [A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools](https://arxiv.org/abs/2506.20743)
*Minh-Hao Van, Prateek Verma, Chen Zhao, Xintao Wu*

**主要类别:** cs.LG

**AI概要:** 基础模型(FMs)正在推动材料科学领域的人工智能系统变革，提供可扩展、通用和多模态的AI系统。本文综述了FMs及其相关工具在材料科学中的应用，包括数据提取、原子模拟、性质预测等多个方面，并探讨了其局限性和未来研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 传统机器学习模型通常范围狭窄且需要特定任务的工程设计，而基础模型(FMs)提供了跨域泛化和新兴能力，特别适合涵盖多样化数据类型和规模的材料科学研究。

**方法:** 通过任务驱动的分类法，涵盖了六个广泛的应用领域：数据提取、解释和问答；原子模拟；性质预测；材料结构、设计与发现；工艺规划、发现与优化；以及多尺度建模。同时讨论了单模态和多模态FMs的最新进展及大型语言模型代理。

**结果:** 早期的基础模型已经取得了一些成功，但仍然存在可泛化性、可解释性、数据不平衡、安全性问题和有限的多模态融合等挑战。

**结论:** 未来的研究方向应集中在可扩展的预训练、持续学习、数据治理和可信度上，以克服当前的限制并进一步推动基础模型在材料科学中的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+AI+for+Materials+Science%3A+Foundation+Models%2C+LLM+Agents%2C+Datasets%2C+and+Tools，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20743，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20743&send_immediately=true&force_search=false)

**原文摘要:** Foundation models (FMs) are catalyzing a transformative shift in materials
science (MatSci) by enabling scalable, general-purpose, and multimodal AI
systems for scientific discovery. Unlike traditional machine learning models,
which are typically narrow in scope and require task-specific engineering, FMs
offer cross-domain generalization and exhibit emergent capabilities. Their
versatility is especially well-suited to materials science, where research
challenges span diverse data types and scales. This survey provides a
comprehensive overview of foundation models, agentic systems, datasets, and
computational tools supporting this growing field. We introduce a task-driven
taxonomy encompassing six broad application areas: data extraction,
interpretation and Q\&A; atomistic simulation; property prediction; materials
structure, design and discovery; process planning, discovery, and optimization;
and multiscale modeling. We discuss recent advances in both unimodal and
multimodal FMs, as well as emerging large language model (LLM) agents.
Furthermore, we review standardized datasets, open-source tools, and autonomous
experimental platforms that collectively fuel the development and integration
of FMs into research workflows. We assess the early successes of foundation
models and identify persistent limitations, including challenges in
generalizability, interpretability, data imbalance, safety concerns, and
limited multimodal fusion. Finally, we articulate future research directions
centered on scalable pretraining, continual learning, data governance, and
trustworthiness.

</details>


### [8] [Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers](https://arxiv.org/abs/2506.20746)
*Todd Nief, David Reber, Sean Richardson, Ari Holtzman*

**主要类别:** cs.LG

**AI概要:** 为了理解微调语言模型如何处理关系信息，本文提出了动态权重嫁接方法，揭示了微调模型在处理实体时提取关系信息，并在生成预测时“回忆”这些信息的机制。


<details>
  <summary>更多</summary>
  
**动机:** 当前定位方法（如激活修补）不适合分析微调语言模型中关系信息的存储和提取方式，因为它们可能会删除信息。

**方法:** 提出动态权重嫁接方法，比较微调与预训练语言模型，以展示微调模型在处理实体时提取关系信息并在生成预测时“回忆”这些信息的能力。

**结果:** 微调语言模型在处理实体时提取关系信息，并在生成预测时通过任务特定注意力机制和关系提取步骤“回忆”这些信息。某些情况下需要两种路径协同工作，而其他情况下单一路径即可。

**结论:** 微调语言模型使用两种主要路径处理关系信息：实体处理时的提取和生成预测时的“回忆”，并且这两种路径在不同层面上表现出冗余性并涉及不同的模型组件。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multiple+Streams+of+Relation+Extraction%3A+Enriching+and+Recalling+in+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20746，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20746&send_immediately=true&force_search=false)

**原文摘要:** When an LLM learns a relation during finetuning (e.g., new movie releases,
corporate mergers, etc.), where does this information go? Is it extracted when
the model processes an entity, recalled just-in-time before a prediction, or
are there multiple separate heuristics? Existing localization approaches (e.g.
activation patching) are ill-suited for this analysis because they tend to
replace parts of the residual stream, potentially deleting information. To fill
this gap, we propose dynamic weight-grafting between fine-tuned and pre-trained
language models to show that fine-tuned language models both (1) extract
relation information learned during finetuning while processing entities and
(2) ``recall" this information in later layers while generating predictions. In
some cases, models need both of these pathways to correctly generate finetuned
information while, in other cases, a single ``enrichment" or ``recall" pathway
alone is sufficient. We examine the necessity and sufficiency of these
information pathways, examining what layers they occur at, how much redundancy
they exhibit, and which model components are involved -- finding that the
``recall" pathway occurs via both task-specific attention mechanisms and a
relation extraction step in the output of the attention and the feedforward
networks at the final layers before next token prediction.

</details>


### [9] [Characterization and Mitigation of Training Instabilities in Microscaling Formats](https://arxiv.org/abs/2506.20752)
*Huangyuan Su, Mujin Kwun, Stephanie Gil, Sham Kakade, Nikhil Anand*

**主要类别:** cs.LG

**AI概要:** 训练大型语言模型是一个昂贵且依赖计算的过程。本文研究了在模型训练中使用块缩放精度格式（如NVIDIA Blackwell架构中的Microscaling格式）的挑战和可行性。通过近一千个从零开始训练的语言模型，观察到在较大计算规模下，MX格式训练会出现尖锐、随机的损失不稳定现象。通过受控实验和分析，发现量化层归一化仿射参数和一小部分激活引入的乘法梯度偏差可能导致失控发散。通过中期干预实验表明，修改精度方案可以避免或延迟不稳定性。最终，评估了稳定化策略，并证明某些混合配置可恢复与全精度训练相当的性能。


<details>
  <summary>更多</summary>
  
**动机:** 训练大型语言模型的成本高且计算密集，因此需要探索更高效的训练方法和硬件支持。下一代硬件加速器支持更低精度的算术格式，以提高效率。本文旨在研究块缩放精度格式在模型训练中的挑战和可行性。

**方法:** 1. 训练近一千个从零开始的语言模型，涵盖不同的计算预算和权重-激活精度组合。
2. 观察并记录在较大计算规模下MX格式训练中的损失不稳定现象。
3. 使用较小的代理模型进行受控实验和消融分析，探索不稳定性的原因。
4. 提出一个简单模型，说明量化层归一化仿射参数和一小部分激活引入的乘法梯度偏差可能导致失控发散。
5. 通过中期干预实验验证修改精度方案对避免或延迟不稳定性的效果。
6. 在LLM设置中评估稳定化策略，测试混合配置的性能。

**结果:** 1. 发现MX格式训练在较大计算规模下出现尖锐、随机的损失不稳定现象。
2. 通过实验和分析，确认量化层归一化仿射参数和一小部分激活引入的乘法梯度偏差是导致不稳定性的主要原因。
3. 修改精度方案可以有效避免或延迟不稳定性。
4. 某些混合配置能够恢复与全精度训练相当的性能。

**结论:** 块缩放精度格式在训练大型语言模型时面临挑战，特别是在较大计算规模下容易出现不稳定性。然而，通过适当的稳定化策略和混合配置，可以在一定程度上克服这些挑战，实现与全精度训练相当的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Characterization+and+Mitigation+of+Training+Instabilities+in+Microscaling+Formats，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20752，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20752&send_immediately=true&force_search=false)

**原文摘要:** Training large language models is an expensive, compute-bound process that
must be repeated as models scale, algorithms improve, and new data is
collected. To address this, next-generation hardware accelerators increasingly
support lower-precision arithmetic formats, such as the Microscaling (MX)
formats introduced in NVIDIA's Blackwell architecture. These formats use a
shared scale within blocks of parameters to extend representable range and
perform forward/backward GEMM operations in reduced precision for efficiency
gains. In this work, we investigate the challenges and viability of
block-scaled precision formats during model training. Across nearly one
thousand language models trained from scratch -- spanning compute budgets from
$2 \times 10^{17}$ to $4.8 \times 10^{19}$ FLOPs and sweeping over a broad
range of weight-activation precision combinations -- we consistently observe
that training in MX formats exhibits sharp, stochastic instabilities in the
loss, particularly at larger compute scales. To explain this phenomenon, we
conduct controlled experiments and ablations on a smaller proxy model that
exhibits similar behavior as the language model, sweeping across architectural
settings, hyperparameters, and precision formats. These experiments motivate a
simple model in which multiplicative gradient bias introduced by the
quantization of layer-norm affine parameters and a small fraction of
activations can trigger runaway divergence. Through \emph{in situ} intervention
experiments on our proxy model, we demonstrate that instabilities can be
averted or delayed by modifying precision schemes mid-training. Guided by these
findings, we evaluate stabilization strategies in the LLM setting and show that
certain hybrid configurations recover performance competitive with
full-precision training. We release our code at
https://github.com/Hither1/systems-scaling.

</details>


### [10] [Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models](https://arxiv.org/abs/2506.20771)
*Xinghao Dong, Huchen Yang, Jin-Long Wu*

**主要类别:** cs.LG

**AI概要:** 提出了一种潜在分数生成式AI框架，用于学习计算力学非线性动力系统中的随机、非局部闭合模型和本构定律。通过联合训练卷积自编码器与条件扩散模型，显著降低了采样过程的维度，同时保留了关键物理特性。该方法在保证预测精度的同时，大幅加速了数值模拟的计算速度。


<details>
  <summary>更多</summary>
  
**动机:** 复杂多尺度动力系统的建模面临没有明确尺度分离的问题，例如工程湍流问题，数值解析所有尺度过于昂贵。经典闭合模型方法虽然利用领域知识近似子网格现象，但在缺乏明确尺度分离的情况下，其确定性和局部假设过于严格。尽管基于扩散的随机模型在闭合建模中显示出潜力，但其高昂的计算推断成本限制了实际应用。

**方法:** 提出了一种潜在分数生成式AI框架，联合训练卷积自编码器与条件扩散模型。通过在潜在空间中进行训练，显著降低了采样过程的维度，同时保留了关键物理特性。这种方法发现了适当的潜在空间，既保证了小的重建误差，又确保了扩散模型在潜在空间中的良好性能。

**结果:** 数值结果表明，联合训练方法能够发现合适的潜在空间，不仅保证了小的重建误差，还确保了扩散模型在潜在空间中的良好性能。将该随机建模框架集成到数值模拟中时，在保持与标准物理空间扩散模型相当预测精度的同时，实现了显著的计算加速。

**结论:** 提出的潜在分数生成式AI框架通过降低采样维度并保留物理特性，为复杂多尺度动力系统的建模提供了一种高效且准确的方法。该方法在计算加速方面表现出色，同时保持了预测精度，适用于实际工程应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stochastic+and+Non-local+Closure+Modeling+for+Nonlinear+Dynamical+Systems+via+Latent+Score-based+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20771，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20771&send_immediately=true&force_search=false)

**原文摘要:** We propose a latent score-based generative AI framework for learning
stochastic, non-local closure models and constitutive laws in nonlinear
dynamical systems of computational mechanics. This work addresses a key
challenge of modeling complex multiscale dynamical systems without a clear
scale separation, for which numerically resolving all scales is prohibitively
expensive, e.g., for engineering turbulent flows. While classical closure
modeling methods leverage domain knowledge to approximate subgrid-scale
phenomena, their deterministic and local assumptions can be too restrictive in
regimes lacking a clear scale separation. Recent developments of
diffusion-based stochastic models have shown promise in the context of closure
modeling, but their prohibitive computational inference cost limits practical
applications for many real-world applications. This work addresses this
limitation by jointly training convolutional autoencoders with conditional
diffusion models in the latent spaces, significantly reducing the
dimensionality of the sampling process while preserving essential physical
characteristics. Numerical results demonstrate that the joint training approach
helps discover a proper latent space that not only guarantees small
reconstruction errors but also ensures good performance of the diffusion model
in the latent space. When integrated into numerical simulations, the proposed
stochastic modeling framework via latent conditional diffusion models achieves
significant computational acceleration while maintaining comparable predictive
accuracy to standard diffusion models in physical spaces.

</details>


### [11] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
*Lucius Bushnaq, Dan Braun, Lee Sharkey*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的神经网络参数分解方法SPD，相较于现有方法APD更具可扩展性和鲁棒性，能够更好地识别真实机制并为更大模型的线性参数分解铺平道路。


<details>
  <summary>更多</summary>
  
**动机:** 当前神经网络反向工程中的参数分解方法存在计算成本高和对超参数敏感的问题，尤其是在较大模型中应用时受限。因此需要一种更高效、更鲁棒的新方法来解决这些问题。

**方法:** 引入了随机参数分解（SPD）方法，该方法在计算效率和超参数鲁棒性上优于现有的基于归因的参数分解（APD）方法，并通过分解稍大且更复杂的模型展示了其优越性。

**结果:** SPD不仅避免了如学习参数收缩等问题，还在玩具模型中更好地识别了真实机制，同时为大规模模型的线性参数分解提供了新的研究可能性。

**结论:** SPD方法为神经网络参数分解提供了一个更高效、更鲁棒的选择，推动了机械可解释性领域的研究进展，并通过开源库促进了进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stochastic+Parameter+Decomposition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20790，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20790&send_immediately=true&force_search=false)

**原文摘要:** A key step in reverse engineering neural networks is to decompose them into
simpler parts that can be studied in relative isolation. Linear parameter
decomposition -- a framework that has been proposed to resolve several issues
with current decomposition methods -- decomposes neural network parameters into
a sum of sparsely used vectors in parameter space. However, the current main
method in this framework, Attribution-based Parameter Decomposition (APD), is
impractical on account of its computational cost and sensitivity to
hyperparameters. In this work, we introduce \textit{Stochastic Parameter
Decomposition} (SPD), a method that is more scalable and robust to
hyperparameters than APD, which we demonstrate by decomposing models that are
slightly larger and more complex than was possible to decompose with APD. We
also show that SPD avoids other issues, such as shrinkage of the learned
parameters, and better identifies ground truth mechanisms in toy models. By
bridging causal mediation analysis and network decomposition methods, this
demonstration opens up new research possibilities in mechanistic
interpretability by removing barriers to scaling linear parameter decomposition
methods to larger models. We release a library for running SPD and reproducing
our experiments at https://github.com/goodfire-ai/spd.

</details>


### [12] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
*Martin Andrews, Sam Witteveen*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种基于LLM的自动化方法，用于优化GPU内核性能，特别是在针对新型或文档不足的GPU架构时。该方法通过多阶段进化过程，包括选择有潜力的代码版本、生成优化假设并自主实现实验，以观察到的时间数据为反馈来改进性能。尽管定量结果因比赛限制未能完全展示，但论文强调了这种方法在资源受限或快速变化的硬件环境中的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 优化GPU内核以实现高性能是一项复杂任务，通常需要深入的架构知识、广泛的分析和迭代实验。当目标是较新或文档不足的GPU架构时，这一挑战更为严峻，因为传统的开发辅助工具较少。因此，需要一种新的自动化方法来应对这些挑战。

**方法:** 论文提出的方法包括：(a) 战略性选择有前途的先前代码版本作为新迭代的基础；(b) 基于现有代码和从通用GPU文献中获取的知识，生成优化实验的假设；(c) 通过代码修改和提交给外部评估系统，自主实施这些实验，并仅使用观察到的时间数据作为性能反馈。

**结果:** 由于定量结果在论文提交时受到比赛限制，尚未完全展示。但论文提供了架构设计、操作流程和定性见解，表明该方法具有巨大潜力。

**结论:** LLM驱动的代理可以民主化和加速GPU内核优化，特别是在资源受限或硬件快速发展的环境中。这为未来的研究和实际应用提供了重要启示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GPU+Kernel+Scientist%3A+An+LLM-Driven+Framework+for+Iterative+Kernel+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20807，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20807&send_immediately=true&force_search=false)

**原文摘要:** Optimizing GPU kernels for high performance is a complex task, often
demanding deep architectural knowledge, extensive profiling, and iterative
experimentation. This challenge is amplified when targeting newer or
less-documented GPU architectures where traditional development aids are
scarce. This paper introduces an LLM-powered "GPU Kernel Scientist," an
automated methodology for iteratively refining accelerator kernels.
  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)
strategically selecting promising prior code versions as a basis for new
iterations; (b) generating hypotheses for optimization experiments, based on
existing code and assimilated knowledge from general GPU literature; and (c)
autonomously implementing these experiments through code modification and
subsequent submission to an external evaluation system, using only observed
timing data as performance feedback. We detail how this approach navigates the
challenges of the AMD MI300 target architecture and leverages LLMs to
compensate for limited domain-specific human expertise.
  Since quantitative results from an ongoing performance competition were
embargoed on paper submission date, we present the architectural design,
operational workflow, and qualitative insights, highlighting the potential of
LLM-driven agents to democratise and accelerate GPU kernel optimization,
especially in resource-constrained or rapidly evolving hardware environments.

</details>


### [13] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
*Shashwat Khandelwal, Jakoba Petri-Koenig, Thomas B. Preußer, Michaela Blott, Shreejith Shanker*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种基于FINN框架的通用方法，用于在FPGA上部署LSTM模型。通过使用ONNX的Scan操作符和FINN编译器的自定义转换，支持混合量化和功能验证，并生成针对XCZU7EV设备优化的硬件IP。实验表明，该方法在性能（延迟）和资源消耗之间取得了平衡，同时保持或提高了推理精度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的FPGA加速工具主要针对前馈网络，而LSTM加速通常需要完全定制实现，这限制了其在资源受限环境中的实时部署能力。

**方法:** 利用FINN框架和ONNX的Scan操作符来建模LSTM计算的递归特性，支持混合量化和功能验证；引入FINN编译器的自定义转换，将量化后的ONNX计算图映射到HLS内核库的硬件模块；使用量化ConvLSTM模型进行中期股票价格预测任务的训练，并生成相应的硬件IP。

**结果:** 生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间实现了平衡，同时以较低的精度匹配或超越最先进的模型的推理准确性。

**结论:** 所提出的流程具有通用性，为在FPGA上设计资源高效的RNN加速器铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FINN-GL%3A+Generalized+Mixed-Precision+Extensions+for+FPGA-Accelerated+LSTMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20810，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20810&send_immediately=true&force_search=false)

**原文摘要:** Recurrent neural networks (RNNs), particularly LSTMs, are effective for
time-series tasks like sentiment analysis and short-term stock prediction.
However, their computational complexity poses challenges for real-time
deployment in resource constrained environments. While FPGAs offer a promising
platform for energy-efficient AI acceleration, existing tools mainly target
feed-forward networks, and LSTM acceleration typically requires full custom
implementation. In this paper, we address this gap by leveraging the
open-source and extensible FINN framework to enable the generalized deployment
of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open
Neural Network Exchange (ONNX) specification to model the recurrent nature of
LSTM computations, enabling support for mixed quantisation within them and
functional verification of LSTM-based models. Furthermore, we introduce custom
transformations within the FINN compiler to map the quantised ONNX computation
graph to hardware blocks from the HLS kernel library of the FINN compiler and
Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM
model for a mid-price stock prediction task using the widely used dataset and
generating a corresponding hardware IP of the model using our flow, targeting
the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator
through our flow achieves a balance between performance (latency) and resource
consumption, while matching (or bettering) inference accuracy of
state-of-the-art models with reduced precision. We believe that the
generalisable nature of the proposed flow will pave the way for
resource-efficient RNN accelerator designs on FPGAs.

</details>


### [14] [Divide, Specialize, and Route: A New Approach to Efficient Ensemble Learning](https://arxiv.org/abs/2506.20814)
*Jakub Piwko, Jędrzej Ruciński, Dawid Płudowski, Antoni Zajko, Patryzja Żak, Mateusz Zacharecki, Anna Kozak, Katarzyna Woźnica*

**主要类别:** cs.LG

**AI概要:** Hellsemble是一种新的集成框架，通过利用数据集复杂性和实例级难度来提高二分类任务的性能，同时保持计算效率和可解释性。实验表明其优于传统集成方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统的集成学习方法（如bagging、boosting和DES）在计算成本高且对异构数据分布适应性有限的问题上存在不足。

**方法:** Hellsemble通过迭代传递误分类实例给后续模型，将数据集按难度分层，并构建一个专门的基础学习者委员会。每个模型在更具挑战性的子集上训练，而独立的路由模型则根据推断出的难度分配新实例到最适合的基础模型。

**结果:** Hellsemble在OpenML-CC18和Tabzilla基准测试中表现出色，通常优于经典的集成方法。

**结论:** 采用实例级难度为构建高效和鲁棒的集成系统提供了一个有前景的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Divide%2C+Specialize%2C+and+Route%3A+A+New+Approach+to+Efficient+Ensemble+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20814，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20814&send_immediately=true&force_search=false)

**原文摘要:** Ensemble learning has proven effective in boosting predictive performance,
but traditional methods such as bagging, boosting, and dynamic ensemble
selection (DES) suffer from high computational cost and limited adaptability to
heterogeneous data distributions. To address these limitations, we propose
Hellsemble, a novel and interpretable ensemble framework for binary
classification that leverages dataset complexity during both training and
inference. Hellsemble incrementally partitions the dataset into circles of
difficulty by iteratively passing misclassified instances from simpler models
to subsequent ones, forming a committee of specialised base learners. Each
model is trained on increasingly challenging subsets, while a separate router
model learns to assign new instances to the most suitable base model based on
inferred difficulty. Hellsemble achieves strong classification accuracy while
maintaining computational efficiency and interpretability. Experimental results
on OpenML-CC18 and Tabzilla benchmarks demonstrate that Hellsemble often
outperforms classical ensemble methods. Our findings suggest that embracing
instance-level difficulty offers a promising direction for constructing
efficient and robust ensemble systems.

</details>


### [15] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
*Furkan Mumcu, Yasin Yilmaz*

**主要类别:** cs.LG

**AI概要:** 深度神经网络（DNNs）易受对抗样本攻击，尽管已有许多成功的攻击方法，但防御技术相对较少研究。本文提出了一种新颖的、通用且高效的检测对抗样本的方法，通过分析不同DNN层对攻击影响的不同程度来检测对抗样本。该方法训练一个轻量级回归模型，从早期层特征预测深层特征，并使用预测误差检测对抗样本。实验表明，该方法高效、适用于实时处理、兼容任何DNN架构并可应用于不同领域。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对抗样本检测方法要么对最新的攻击技术无效，要么计算效率低下，无法实现实时处理。因此需要一种更有效且高效的对抗样本检测方法。

**方法:** 提出了一种通过分析不同DNN层对攻击影响程度的方法。具体来说，训练一个轻量级回归模型，利用早期层特征预测深层特征，并使用预测误差作为检测对抗样本的依据。

**结果:** 通过理论分析和广泛实验，证明了该方法在检测对抗样本方面具有高度有效性，同时计算效率高，适合实时处理，与任何DNN架构兼容，并能跨不同领域应用。

**结论:** 所提出的检测方法是一种通用且高效的解决方案，能够有效检测对抗样本，并且适用于各种DNN架构和数据类型，如图像、视频和音频等。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Universal+and+Efficient+Detection+of+Adversarial+Data+through+Nonuniform+Impact+on+Network+Layers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20816，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20816&send_immediately=true&force_search=false)

**原文摘要:** Deep Neural Networks (DNNs) are notoriously vulnerable to adversarial input
designs with limited noise budgets. While numerous successful attacks with
subtle modifications to original input have been proposed, defense techniques
against these attacks are relatively understudied. Existing defense approaches
either focus on improving DNN robustness by negating the effects of
perturbations or use a secondary model to detect adversarial data. Although
equally important, the attack detection approach, which is studied in this
work, provides a more practical defense compared to the robustness approach. We
show that the existing detection methods are either ineffective against the
state-of-the-art attack techniques or computationally inefficient for real-time
processing. We propose a novel universal and efficient method to detect
adversarial examples by analyzing the varying degrees of impact of attacks on
different DNN layers. {Our method trains a lightweight regression model that
predicts deeper-layer features from early-layer features, and uses the
prediction error to detect adversarial samples.} Through theoretical arguments
and extensive experiments, we demonstrate that our detection method is highly
effective, computationally efficient for real-time processing, compatible with
any DNN architecture, and applicable across different domains, such as image,
video, and audio.

</details>


### [16] [Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL](https://arxiv.org/abs/2506.20904)
*Matthew Zurek, Guy Zamir, Yudong Chen*

**主要类别:** cs.LG

**AI概要:** 本文研究了平均奖励马尔可夫决策过程中的离线强化学习，提出了基于悲观折扣值迭代的算法，并引入了新的策略命中半径的概念，首次实现了仅依赖于目标策略的样本复杂度界。此外，该研究还探讨了通用弱通信MDP，并通过困难示例展示了超越目标策略平稳分布的覆盖假设的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 离线强化学习在平均奖励MDP中面临分布偏移和非均匀覆盖的挑战，而理论研究相对较少。现有工作通常依赖于单策略数据覆盖假设，并使用对所有策略统一的复杂性度量（如一致混合时间）。

**方法:** 作者提出了一种基于悲观折扣值迭代的算法，结合新颖的分位数裁剪技术，以实现更精确的经验跨度惩罚函数。这种方法生成了与目标策略相关的偏差跨度和策略命中半径的尖锐保证，从而首次给出了平均奖励离线RL的完全单策略样本复杂度界。

**结果:** 该方法成功处理了通用弱通信MDP，无需任何先验参数知识即可实施，并通过困难示例证明了学习需要超越目标策略平稳分布的覆盖假设。此外，还开发了几乎匹配主要结果的下界。

**结论:** 本文为平均奖励离线强化学习提供了首个仅依赖目标策略的样本复杂度界，并通过理论分析和算法设计推进了对单策略复杂性度量的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimal+Single-Policy+Sample+Complexity+and+Transient+Coverage+for+Average-Reward+Offline+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20904，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20904&send_immediately=true&force_search=false)

**原文摘要:** We study offline reinforcement learning in average-reward MDPs, which
presents increased challenges from the perspectives of distribution shift and
non-uniform coverage, and has been relatively underexamined from a theoretical
perspective. While previous work obtains performance guarantees under
single-policy data coverage assumptions, such guarantees utilize additional
complexity measures which are uniform over all policies, such as the uniform
mixing time. We develop sharp guarantees depending only on the target policy,
specifically the bias span and a novel policy hitting radius, yielding the
first fully single-policy sample complexity bound for average-reward offline
RL. We are also the first to handle general weakly communicating MDPs,
contrasting restrictive structural assumptions made in prior work. To achieve
this, we introduce an algorithm based on pessimistic discounted value iteration
enhanced by a novel quantile clipping technique, which enables the use of a
sharper empirical-span-based penalty function. Our algorithm also does not
require any prior parameter knowledge for its implementation. Remarkably, we
show via hard examples that learning under our conditions requires coverage
assumptions beyond the stationary distribution of the target policy,
distinguishing single-policy complexity measures from previously examined
cases. We also develop lower bounds nearly matching our main result.

</details>


### [17] [Demystifying Distributed Training of Graph Neural Networks for Link Prediction](https://arxiv.org/abs/2506.20818)
*Xin Huang, Chul-Ho Lee*

**主要类别:** cs.LG

**AI概要:** 论文探讨了图神经网络（GNNs）在链路预测任务中的分布式训练问题，并提出了一种名为SpLPG的方法，通过图稀疏化技术有效缓解性能下降问题，同时将通信开销降低约80%，并保持链路预测精度。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数分布式GNN框架和系统针对节点分类进行了优化，但其在链路预测任务上的表现尚未充分研究，特别是在子图分区训练导致的信息丢失和负采样方法对性能的影响方面。

**方法:** 作者提出了一种名为SpLPG的方法，该方法利用图稀疏化技术来减少通信成本，同时缓解因子图分区训练带来的性能下降问题。通过实验验证SpLPG的有效性。

**结果:** 实验结果表明，SpLPG可以在多个公开的真实世界数据集上将通信开销降低高达约80%，同时大部分保留链路预测的准确性。

**结论:** SpLPG是一种有效的解决方案，能够在降低通信成本的同时解决分布式GNN链路预测任务中的性能下降问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Demystifying+Distributed+Training+of+Graph+Neural+Networks+for+Link+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20818，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20818&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) are powerful tools for solving graph-related
problems. Distributed GNN frameworks and systems enhance the scalability of
GNNs and accelerate model training, yet most are optimized for node
classification. Their performance on link prediction remains underexplored.
This paper demystifies distributed training of GNNs for link prediction by
investigating the issue of performance degradation when each worker trains a
GNN on its assigned partitioned subgraph without having access to the entire
graph. We discover that the main sources of the issue come from not only the
information loss caused by graph partitioning but also the ways of drawing
negative samples during model training. While sharing the complete graph
information with each worker resolves the issue and preserves link prediction
accuracy, it incurs a high communication cost. We propose SpLPG, which
effectively leverages graph sparsification to mitigate the issue of performance
degradation at a reduced communication cost. Experiment results on several
public real-world datasets demonstrate the effectiveness of SpLPG, which
reduces the communication overhead by up to about 80% while mostly preserving
link prediction accuracy.

</details>


### [18] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
*Li Fan, Peng Wang, Jing Yang, Cong Shen*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的浅层Transformer框架CHOOSE，通过在隐藏空间中引入自回归潜在推理步骤，增强了浅层模型的推理能力，使其性能媲美深层模型，同时保持了存储和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于ICL的Transformer模型虽然在无线通信问题上表现出潜力，但依赖于深层架构，导致存储和计算成本较高。因此需要一种更高效的模型设计来解决这些问题。

**方法:** 提出了CHOOSE框架，这是一种增强的浅层Transformer模型，通过在隐藏空间中引入自回归潜在推理步骤，提升了浅层模型（1-2层）的推理能力，而无需增加模型深度。

**结果:** 实验结果表明，该方法优于传统的浅层Transformer，并且其性能可与深层Transformer相媲美，同时保持了存储和计算效率。

**结论:** CHOOSE为在计算资源有限的无线接收器中实现基于Transformer的算法提供了一个有前景的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Chain-of-Thought+Enhanced+Shallow+Transformers+for+Wireless+Symbol+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21093，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21093&send_immediately=true&force_search=false)

**原文摘要:** Transformers have shown potential in solving wireless communication problems,
particularly via in-context learning (ICL), where models adapt to new tasks
through prompts without requiring model updates. However, prior ICL-based
Transformer models rely on deep architectures with many layers to achieve
satisfactory performance, resulting in substantial storage and computational
costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a
CoT-enhanced shallow Transformer framework for wireless symbol detection. By
introducing autoregressive latent reasoning steps within the hidden space,
CHOOSE significantly improves the reasoning capacity of shallow models (1-2
layers) without increasing model depth. This design enables lightweight
Transformers to achieve detection performance comparable to much deeper models,
making them well-suited for deployment on resource-constrained mobile devices.
Experimental results demonstrate that our approach outperforms conventional
shallow Transformers and achieves performance comparable to that of deep
Transformers, while maintaining storage and computational efficiency. This
represents a promising direction for implementing Transformer-based algorithms
in wireless receivers with limited computational resources.

</details>


### [19] [Learning-Based Resource Management in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2506.20849)
*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的受限深度强化学习（CDRL）方法，用于优化雷达通信系统的资源分配，以提高目标通信质量。


<details>
  <summary>更多</summary>
  
**动机:** 在集成感知和通信系统中，需要解决适应性时间分配问题，以平衡多目标跟踪和数据传输之间的资源分配。

**方法:** 引入了一种新的受限深度强化学习（CDRL）方法，在时间预算约束下优化跟踪与通信之间的资源分配。

**结果:** 数值结果证明了所提出的CDRL框架的有效性，能够在动态环境中最大化通信质量，同时满足时间限制。

**结论:** 所提出的CDRL方法可以有效提升目标通信质量，同时满足时间限制要求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning-Based+Resource+Management+in+Integrated+Sensing+and+Communication+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20849，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20849&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we tackle the task of adaptive time allocation in integrated
sensing and communication systems equipped with radar and communication units.
The dual-functional radar-communication system's task involves allocating dwell
times for tracking multiple targets and utilizing the remaining time for data
transmission towards estimated target locations. We introduce a novel
constrained deep reinforcement learning (CDRL) approach, designed to optimize
resource allocation between tracking and communication under time budget
constraints, thereby enhancing target communication quality. Our numerical
results demonstrate the efficiency of our proposed CDRL framework, confirming
its ability to maximize communication quality in highly dynamic environments
while adhering to time constraints.

</details>


### [20] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
*Silas Dobler, Florian Lemmerich*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的基于线性的神经网络压缩方法，可以将模型大小无损压缩至原来的1/4，并且与现有的重要性剪枝方法结合效果良好。


<details>
  <summary>更多</summary>
  
**动机:** 当前的神经网络压缩方法主要通过衡量参数的重要性与冗余度来减少不必要的参数。为了进一步优化已有的解决方案，提出了基于线性的压缩方法。

**方法:** 基于ReLU类激活函数的特性，对于几乎总是被激活的神经元，其行为是线性的，因此可以合并后续层以减少权重。论文介绍了该压缩方法的理论基础并进行了实验评估。

**结果:** 新方法在多数测试模型中实现了无损压缩至原模型大小的1/4。并且在已经过重要性剪枝的模型上应用此方法时，显示出不同类型压缩之间的干扰很小，证明了技术结合的成功可能性。

**结论:** 本工作为一种新型的压缩方法奠定了基础，使得神经网络模型更小、更高效。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Linearity-based+neural+network+compression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21146，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21146&send_immediately=true&force_search=false)

**原文摘要:** In neural network compression, most current methods reduce unnecessary
parameters by measuring importance and redundancy. To augment already highly
optimized existing solutions, we propose linearity-based compression as a novel
way to reduce weights in a neural network. It is based on the intuition that
with ReLU-like activation functions, neurons that are almost always activated
behave linearly, allowing for merging of subsequent layers. We introduce the
theory underlying this compression and evaluate our approach experimentally.
Our novel method achieves a lossless compression down to 1/4 of the original
model size in over the majority of tested models. Applying our method on
already importance-based pruned models shows very little interference between
different types of compression, demonstrating the option of successful
combination of techniques. Overall, our work lays the foundation for a new type
of compression method that enables smaller and ultimately more efficient neural
network models.

</details>


### [21] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
*Ziyang Lu, Subodh Kalia, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney*

**主要类别:** cs.LG

**AI概要:** The paper explores the time allocation problem in multi-function cognitive radar systems using deep reinforcement learning, comparing DDPG and SAC algorithms while employing NSGA-II for Pareto front estimation.


<details>
  <summary>更多</summary>
  
**动机:** To address the challenge of balancing scanning for new targets and tracking existing ones in cognitive radar systems.

**方法:** Formulate the problem as a multi-objective optimization task and use deep reinforcement learning (DDPG and SAC) to find Pareto-optimal solutions. Additionally, employ NSGA-II to estimate the upper bound on the Pareto front.

**结果:** Both DDPG and SAC algorithms effectively adapt to various scenarios, with SAC showing better stability and sample efficiency. NSGA-II provides an upper bound estimation for the Pareto front.

**结论:** This study contributes to the advancement of efficient and adaptive cognitive radar systems capable of handling competing objectives in dynamic environments.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Objective+Reinforcement+Learning+for+Cognitive+Radar+Resource+Management，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20853，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20853&send_immediately=true&force_search=false)

**原文摘要:** The time allocation problem in multi-function cognitive radar systems focuses
on the trade-off between scanning for newly emerging targets and tracking the
previously detected targets. We formulate this as a multi-objective
optimization problem and employ deep reinforcement learning to find
Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG)
and soft actor-critic (SAC) algorithms. Our results demonstrate the
effectiveness of both algorithms in adapting to various scenarios, with SAC
showing improved stability and sample efficiency compared to DDPG. We further
employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of
the considered problem. This work contributes to the development of more
efficient and adaptive cognitive radar systems capable of balancing multiple
competing objectives in dynamic environments.

</details>


### [22] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
*Fei Wang, Baochun Li*

**主要类别:** cs.LG

**AI概要:** 本文重新审视了微调中的记忆化问题，并揭示了不同微调策略之间的惊人差异。研究发现，LoRA微调在模型规模和数据重复等因素的影响下，表现出与预训练和完全微调不同的趋势。通过使用基于相似性的记忆化度量，证明了LoRA显著降低了记忆化风险，同时保持了强大的任务性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管预训练中的记忆化已被广泛研究，但微调（特别是LoRA微调）中的记忆化影响尚未得到充分探讨。因此，需要重新评估微调过程中记忆化的特性及其潜在的安全风险。

**方法:** 研究者重新审视了微调中的记忆化现象，比较了不同微调策略（包括LoRA微调和全微调）。通过引入一种更宽松的基于相似性的记忆化度量方法，分析了模型规模、数据重复等因素对记忆化的影响。

**结果:** 研究表明，LoRA微调的记忆化风险显著低于全微调，且其表现不受模型规模和数据重复等传统因素的强烈影响。同时，LoRA微调仍能保持较高的任务性能。

**结论:** LoRA微调是一种参数高效的微调方法，能够在降低记忆化风险的同时，维持良好的任务表现，为实际应用提供了更安全的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leaner+Training%2C+Lower+Leakage%3A+Revisiting+Memorization+in+LLM+Fine-Tuning+with+LoRA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20856，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20856&send_immediately=true&force_search=false)

**原文摘要:** Memorization in large language models (LLMs) makes them vulnerable to data
extraction attacks. While pre-training memorization has been extensively
studied, fewer works have explored its impact in fine-tuning, particularly for
LoRA fine-tuning, a widely adopted parameter-efficient method.
  In this work, we re-examine memorization in fine-tuning and uncover a
surprising divergence from prior findings across different fine-tuning
strategies. Factors such as model scale and data duplication, which strongly
influence memorization in pre-training and full fine-tuning, do not follow the
same trend in LoRA fine-tuning. Using a more relaxed similarity-based
memorization metric, we demonstrate that LoRA significantly reduces
memorization risks compared to full fine-tuning, while still maintaining strong
task performance.

</details>


### [23] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
*Zixian Wang, Cole Ramos, Muhammad A. Awad, Keith Lowery*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种名为Omniwise的端到端、自监督微调管道，将大型语言模型应用于GPU内核性能预测，能够准确预测多个性能指标，并开发了相应的在线推理服务器和VS Code插件。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，深度神经网络的发展推动了人工智能的进步，使得模型在理解和处理复杂数据方面具有前所未有的能力。然而，在性能分析领域，特别是在不执行代码或使用分析工具的情况下直接从代码预测性能指标方面，仍存在挑战。因此，本研究试图利用大型语言模型解决这一问题。

**方法:** 提出了Omniwise，这是一种与模型无关且轻量级的管道，可以使用包含3B参数的小型模型进行有效的性能预测。该方法可以直接从内核代码中预测关键性能指标（如内存带宽、缓存命中率等），而无需执行代码或使用分析工具。此外，还开发了一个在线推理服务器和一个Visual Studio Code插件，以方便开发者集成此功能。

**结果:** 在AMD MI250和MI300X架构上执行的GPU内核测试表明，超过90%的预测结果相对误差小于10%，证明了该方法的高度准确性。

**结论:** Omniwise提供了一种新颖且高效的方法来预测GPU内核性能，其准确性和易用性使其成为开发人员工作流程中的有力工具。通过将大型语言模型应用于性能预测，这项研究为未来的性能分析技术开辟了新的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omniwise%3A+Predicting+GPU+Kernels+Performance+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20886，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20886&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the rapid advancement of deep neural networks (DNNs) has
revolutionized artificial intelligence, enabling models with unprecedented
capabilities in understanding, generating, and processing complex data. These
powerful architectures have transformed a wide range of downstream
applications, tackling tasks beyond human reach. In this paper, we introduce
Omniwise, the first end-to-end, self-supervised fine-tuning pipeline that
applies large language models (LLMs) to GPU kernel performance prediction--a
novel use case in performance profiling. Omniwise is model-agnostic and
lightweight, achieving strong results even with a small 3B-parameter model. It
can predict key performance metrics, including memory bandwidth, cache hit
rates, GFLOPs, and arithmetic intensity, directly from kernel code without the
need for code execution or profiling tools. Our approach achieves over 90% of
predictions within 10% relative error on GPU kernels executed on AMD MI250 and
MI300X architectures. In addition to the pipeline, we develop an online
inference server and a Visual Studio Code plugin that seamlessly integrate
LLM-based performance prediction into developers' workflows.

</details>


### [24] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
*Yian Wang, Ali Ebrahimpour-Boroojeny, Hari Sundaram*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为RWFT的输出重加权遗忘方法，可以在不完全重新训练的情况下从训练好的分类器中删除整个类别。通过设计MIA-NN变体攻击证明现有方法的不足，并提出一种对遗忘类别样本预测的概率质量简单重新分配的方法以抵抗该攻击。引入基于总变异距离的新度量来量化残余泄漏。实验表明，该方法在先前使用的度量和新提出的TV-based度量上分别提高了2.79%和111.45%。


<details>
  <summary>更多</summary>
  
**动机:** 从训练模型中遗忘特定类别对于执行用户删除权利和减少有害或有偏见的预测至关重要。然而，完全重新训练成本高昂，且现有的遗忘方法在预测未学习类别的样本时无法复制重新训练模型的行为。

**方法:** 提出了一种简单的概率质量重新分配方法，用于对遗忘类别样本进行预测，该方法对MIA-NN攻击具有鲁棒性。同时，引入了基于总变异距离的新度量，以量化残余泄漏并防止未来方法易受新攻击的影响。

**结果:** 通过与最先进的基线方法进行广泛实验比较，结果表明该方法在先前使用的评估度量和新提出的度量上均与完全重新训练的结果相匹配。相比现有最佳方法，在先前使用的度量上提升了2.79%，在新提出的TV-based度量上提升了111.45%。

**结论:** RWFT方法能够在不完全重新训练的情况下有效删除特定类别，抵御MIA-NN攻击，并显著改善了遗忘效果。所提出的新度量为评估遗忘方法提供了更全面的标准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Necessity+of+Output+Distribution+Reweighting+for+Effective+Class+Unlearning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20893&send_immediately=true&force_search=false)

**原文摘要:** In this work, we introduce an output-reweighting unlearning method, RWFT, a
lightweight technique that erases an entire class from a trained classifier
without full retraining. Forgetting specific classes from trained models is
essential for enforcing user deletion rights and mitigating harmful or biased
predictions. The full retraining is costly and existing unlearning methods fail
to replicate the behavior of the retrained models when predicting samples from
the unlearned class. We prove this failure by designing a variant of membership
inference attacks, MIA-NN that successfully reveals the unlearned class for any
of these methods. We propose a simple redistribution of the probability mass
for the prediction on the samples in the forgotten class which is robust to
MIA-NN. We also introduce a new metric based on the total variation (TV)
distance of the prediction probabilities to quantify residual leakage to
prevent future methods from susceptibility to the new attack. Through extensive
experiments with state of the art baselines in machine unlearning, we show that
our approach matches the results of full retraining in both metrics used for
evaluation by prior work and the new metric we propose in this work. Compare to
state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%
in our new TV-based metric over the best existing method.

</details>


### [25] [Graph-Structured Feedback Multimodel Ensemble Online Conformal Prediction](https://arxiv.org/abs/2506.20898)
*Erfan Hajihashemi, Yanning Shen*

**主要类别:** cs.LG

**AI概要:** 在线多模型一致性预测算法通过选择有效模型子集和优化反馈机制，减少了计算复杂度并生成更小的预测集，同时保持覆盖保证。实验表明该方法优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 现有的在线一致性预测方法在处理分布偏移时面临计算复杂性和预测集大小的问题，尤其是当候选模型数量过多或包含无关模型时。

**方法:** 提出一种新的在线多模型一致性预测算法，在每个时间步通过收集来自二分图的反馈来识别有效模型子集，并从中选择模型以构建预测集。此外，使用预测集大小作为反馈与模型损失一起优化效率。

**结果:** 理论证明和实验验证表明，所提算法确保了有效的覆盖概率，实现了次线性后悔界，并且构建的预测集比现有方法更小。

**结论:** 所提出的算法通过减少计算复杂度和缩小预测集，在有效性与效率上均优于现有的多模型在线一致性预测方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-Structured+Feedback+Multimodel+Ensemble+Online+Conformal+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20898，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20898&send_immediately=true&force_search=false)

**原文摘要:** Online conformal prediction has demonstrated its capability to construct a
prediction set for each incoming data point that covers the true label with a
predetermined probability. To cope with potential distribution shift,
multi-model online conformal prediction has been introduced to select and
leverage different models from a preselected candidate set. Along with the
improved flexibility, the choice of the preselected set also brings challenges.
A candidate set that includes a large number of models may increase the
computational complexity. In addition, the inclusion of irrelevant models with
poor performance may negatively impact the performance and lead to
unnecessarily large prediction sets. To address these challenges, we propose a
novel multi-model online conformal prediction algorithm that identifies a
subset of effective models at each time step by collecting feedback from a
bipartite graph, which is refined upon receiving new data. A model is then
selected from this subset to construct the prediction set, resulting in reduced
computational complexity and smaller prediction sets. Additionally, we
demonstrate that using prediction set size as feedback, alongside model loss,
can significantly improve efficiency by constructing smaller prediction sets
while still satisfying the required coverage guarantee. The proposed algorithms
are proven to ensure valid coverage and achieve sublinear regret. Experiments
on real and synthetic datasets validate that the proposed methods construct
smaller prediction sets and outperform existing multi-model online conformal
prediction approaches.

</details>


### [26] [Explainable AI for Radar Resource Management: Modified LIME in Deep Reinforcement Learning](https://arxiv.org/abs/2506.20916)
*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney*

**主要类别:** cs.LG

**AI概要:** 提出了一种改进的LIME方法（DL-LIME），将深度学习整合到采样过程中，用于雷达资源管理的深度强化学习中。实验结果表明，DL-LIME在保真度和任务性能方面均优于传统LIME，并能揭示决策中的重要因素。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络的“黑箱”特性限制了其在需要解释性场景中的应用，当前对可解释人工智能（XAI）技术的研究需求迫切，而现有LIME方法在采样时忽略了特征间的相关性。

**方法:** 提出一种改进的LIME方法——DL-LIME，通过将深度学习整合到采样过程中解决特征相关性问题，并将其应用于雷达资源管理的深度强化学习中。

**结果:** 数值结果显示DL-LIME在保真度和任务性能两方面均优于传统LIME，并能够提供关于雷达资源管理决策中重要因素的见解。

**结论:** DL-LIME不仅提升了性能，还增强了决策的可解释性，为雷达资源管理提供了更优的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explainable+AI+for+Radar+Resource+Management%3A+Modified+LIME+in+Deep+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20916，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20916&send_immediately=true&force_search=false)

**原文摘要:** Deep reinforcement learning has been extensively studied in decision-making
processes and has demonstrated superior performance over conventional
approaches in various fields, including radar resource management (RRM).
However, a notable limitation of neural networks is their ``black box" nature
and recent research work has increasingly focused on explainable AI (XAI)
techniques to describe the rationale behind neural network decisions. One
promising XAI method is local interpretable model-agnostic explanations (LIME).
However, the sampling process in LIME ignores the correlations between
features. In this paper, we propose a modified LIME approach that integrates
deep learning (DL) into the sampling process, which we refer to as DL-LIME. We
employ DL-LIME within deep reinforcement learning for radar resource
management. Numerical results show that DL-LIME outperforms conventional LIME
in terms of both fidelity and task performance, demonstrating superior
performance with both metrics. DL-LIME also provides insights on which factors
are more important in decision making for radar resource management.

</details>


### [27] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
*Tong Zeng, Srivathsan Badrinarayanan, Janghoon Ock, Cheng-Kai Lai, Amir Barati Farimani*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种基于多智能体框架的大型语言模型（LLM）方法，用于化学过程优化。该方法通过自主生成操作约束并进行迭代优化，显著提高了计算效率，并在无需预定义操作范围的情况下表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 传统优化方法在操作约束不明确或不可用时变得不实用，工程师需要依赖主观启发式方法估计参数范围。为了解决这一瓶颈，提出了一个基于多智能体的框架。

**方法:** 使用了OpenAI的o3模型，构建了一个包含多个专门智能体的框架，这些智能体分别负责约束生成、参数验证、模拟执行和优化指导。优化过程分为两个阶段：自主约束生成和多智能体迭代优化。

**结果:** 在加氢脱烷基化过程中，该框架在成本、产量和产率比等多个指标上表现出与传统方法相当的性能，同时具有更高的计算效率，收敛速度是网格搜索的31倍。

**结论:** 此方法在操作约束不明确或缺失的情况下展现出显著潜力，特别适用于新兴过程和改造应用中的优化场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-guided+Chemical+Process+Optimization+with+a+Multi-Agent+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20921，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20921&send_immediately=true&force_search=false)

**原文摘要:** Chemical process optimization is crucial to maximize production efficiency
and economic performance. Traditional methods, including gradient-based
solvers, evolutionary algorithms, and parameter grid searches, become
impractical when operating constraints are ill-defined or unavailable,
requiring engineers to rely on subjective heuristics to estimate feasible
parameter ranges. To address this constraint definition bottleneck, we present
a multi-agent framework of large language model (LLM) agents that autonomously
infer operating constraints from minimal process descriptions, then
collaboratively guide optimization using the inferred constraints. Our
AutoGen-based agentic framework employs OpenAI's o3 model, with specialized
agents for constraint generation, parameter validation, simulation execution,
and optimization guidance. Through two phases - autonomous constraint
generation using embedded domain knowledge, followed by iterative multi-agent
optimization - the framework eliminates the need for predefined operational
bounds. Validated on the hydrodealkylation process across cost, yield, and
yield-to-cost ratio metrics, the framework demonstrated competitive performance
with conventional optimization methods while achieving better computational
efficiency, requiring fewer iterations to converge. Our approach converged in
under 20 minutes, achieving a 31-fold speedup over grid search. Beyond
computational efficiency, the framework's reasoning-guided search demonstrates
sophisticated process understanding, correctly identifying utility trade-offs,
and applying domain-informed heuristics. This approach shows significant
potential for optimization scenarios where operational constraints are poorly
characterized or unavailable, particularly for emerging processes and retrofit
applications.

</details>


### [28] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
*Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley*

**主要类别:** cs.LG

**AI概要:** 本研究通过引入可学习的稀疏线性变换扩展了经典规则集成，提出了新的学习方法，实现了高效构建规则集成，同时降低模型复杂度。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于符号规则的小型集成模型虽然具有高度的可解释性，但依赖于精心策划的表达性和理想独立的输入特征集合，以确保少量轴平行区域能很好地描述目标变量。缺乏这样的特征时，为了达到足够的准确性，需要增加个体规则的数量和复杂性，从而削弱了模型的可解释性。

**方法:** 提出了一种基于逻辑命题的学习方法，这些命题使用可学习的输入变量的稀疏线性变换，即形式为$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$ 的命题，其中$\mathbf{w}$ 是一个可学习的稀疏权重向量。这使得决策区域可以作为具有倾斜面的一般多面体。该学习方法采用基于迭代加权逻辑回归公式化的顺序贪婪优化。

**结果:** 实验结果表明，所提出的方法可以在保持与现有最佳方法相同测试风险的情况下，显著降低模型复杂度。

**结论:** 在十个基准数据集上，实验结果表明，所提出的方法能够以与最先进方法相同的测试风险有效地构建规则集成，同时显著降低模型复杂度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Representation+Learning+for+Additive+Rule+Ensembles，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20927&send_immediately=true&force_search=false)

**原文摘要:** Small additive ensembles of symbolic rules offer interpretable prediction
models. Traditionally, these ensembles use rule conditions based on
conjunctions of simple threshold propositions $x \geq t$ on a single input
variable $x$ and threshold $t$, resulting geometrically in axis-parallel
polytopes as decision regions. While this form ensures a high degree of
interpretability for individual rules and can be learned efficiently using the
gradient boosting approach, it relies on having access to a curated set of
expressive and ideally independent input features so that a small ensemble of
axis-parallel regions can describe the target variable well. Absent such
features, reaching sufficient accuracy requires increasing the number and
complexity of individual rules, which diminishes the interpretability of the
model. Here, we extend classical rule ensembles by introducing logical
propositions with learnable sparse linear transformations of input variables,
i.e., propositions of the form $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$, where
$\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as
general polytopes with oblique faces. We propose a learning method using
sequential greedy optimization based on an iteratively reweighted formulation
of logistic regression. Experimental results demonstrate that the proposed
method efficiently constructs rule ensembles with the same test risk as
state-of-the-art methods while significantly reducing model complexity across
ten benchmark datasets.

</details>


### [29] [Model State Arithmetic for Machine Unlearning](https://arxiv.org/abs/2506.20941)
*Keivan Rezaei, Mehrdad Saberi, Abhilasha Ravichander, Soheil Feizi*

**主要类别:** cs.LG

**AI概要:** 提出了一种新算法MSA，用于通过利用模型检查点来估计和消除数据点的影响，实验结果表明MSA在多个基准、模型和评估指标上始终优于现有的机器遗忘算法。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型训练依赖于庞大的网络数据，其中可能包含私密数据、受版权保护的材料、事实不准确的数据或降低模型性能的数据。通过完全重新训练以消除这些有问题的数据点影响是计算上无法承受的，因此需要一种低计算成本的算法来消除特定数据点的影响。

**方法:** 提出了新的算法MSA，该算法通过利用模型检查点（即捕获预训练不同阶段模型状态的工件）来估计和消除数据点的影响。

**结果:** 实验结果表明，MSA在多个基准、模型和评估指标上始终优于现有的机器遗忘算法。

**结论:** MSA可能是一种有效的途径，实现更灵活的大规模语言模型，具备数据清除能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model+State+Arithmetic+for+Machine+Unlearning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20941，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20941&send_immediately=true&force_search=false)

**原文摘要:** Large language models are trained on massive corpora of web data, which may
include private data, copyrighted material, factually inaccurate data, or data
that degrades model performance. Eliminating the influence of such problematic
datapoints through complete retraining -- by repeatedly pretraining the model
on datasets that exclude these specific instances -- is computationally
prohibitive. For this reason, unlearning algorithms have emerged that aim to
eliminate the influence of particular datapoints, while otherwise preserving
the model -- at a low computational cost. However, precisely estimating and
undoing the influence of individual datapoints has proved to be challenging. In
this work, we propose a new algorithm, MSA, for estimating and undoing the
influence of datapoints -- by leveraging model checkpoints i.e. artifacts
capturing model states at different stages of pretraining. Our experimental
results demonstrate that MSA consistently outperforms existing machine
unlearning algorithms across multiple benchmarks, models, and evaluation
metrics, suggesting that MSA could be an effective approach towards more
flexible large language models that are capable of data erasure.

</details>


### [30] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
*Jiameng Chen, Xiantao Cai, Jia Wu, Wenbin Hu*

**主要类别:** cs.LG

**AI概要:** AbMEGD是一种新的抗体设计框架，结合多尺度等变图扩散方法，提升了几何特征捕捉和抗原接口泛化能力，在SAbDab数据库测试中表现优于现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 当前计算方法在抗体设计中难以同时捕捉几何特征、保持对称性并泛化新型抗原接口，限制了复杂抗原的分子相互作用建模。

**方法:** 提出了一种端到端框架AbMEGD，集成了多尺度等变图扩散技术，结合原子级几何特征与残基级嵌入表示，确保几何精度、计算效率和对抗体设计的强泛化能力。

**结果:** 相比领先模型DiffAb，在SAbDab数据库测试中，AbMEGD实现了10.13%的氨基酸恢复率提升、3.32%的改进百分比增长以及CDR-H3区域均方根偏差减少0.062 Å。

**结论:** AbMEGD展示了在维持结构完整性的同时提高功能性的能力，为序列-结构协同设计和亲和力优化设定了新基准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Antibody+Design+and+Optimization+with+Multi-scale+Equivariant+Graph+Diffusion+Models+for+Accurate+Complex+Antigen+Binding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20957，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20957&send_immediately=true&force_search=false)

**原文摘要:** Antibody design remains a critical challenge in therapeutic and diagnostic
development, particularly for complex antigens with diverse binding interfaces.
Current computational methods face two main limitations: (1) capturing
geometric features while preserving symmetries, and (2) generalizing novel
antigen interfaces. Despite recent advancements, these methods often fail to
accurately capture molecular interactions and maintain structural integrity. To
address these challenges, we propose \textbf{AbMEGD}, an end-to-end framework
integrating \textbf{M}ulti-scale \textbf{E}quivariant \textbf{G}raph
\textbf{D}iffusion for antibody sequence and structure co-design. Leveraging
advanced geometric deep learning, AbMEGD combines atomic-level geometric
features with residue-level embeddings, capturing local atomic details and
global sequence-structure interactions. Its E(3)-equivariant diffusion method
ensures geometric precision, computational efficiency, and robust
generalizability for complex antigens. Furthermore, experiments using the
SAbDab database demonstrate a 10.13\% increase in amino acid recovery, 3.32\%
rise in improvement percentage, and a 0.062~\AA\ reduction in root mean square
deviation within the critical CDR-H3 region compared to DiffAb, a leading
antibody design model. These results highlight AbMEGD's ability to balance
structural integrity with improved functionality, establishing a new benchmark
for sequence-structure co-design and affinity optimization. The code is
available at: https://github.com/Patrick221215/AbMEGD.

</details>


### [31] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
*Jaebak Hwang, Sanghyeon Lee, Jeongmo Kim, Seungyul Han*

**主要类别:** cs.LG

**AI概要:** SSE是一种新的图基分层RL框架，通过结构约束、解耦探索策略和失败感知路径优化来解决长时域目标条件任务中的子目标不可行性和规划效率低的问题。实验表明，SSE在效率和成功率方面优于现有的RL方法。


<details>
  <summary>更多</summary>
  
**动机:** 长时域目标条件任务对强化学习提出了根本挑战，特别是在目标遥远且奖励稀疏的情况下。现有的分层和图基方法虽然提供了部分解决方案，但常因子目标不可行和规划效率低下而受限。

**方法:** 提出了一种名为严格子目标执行（SSE）的图基分层RL框架。该框架通过结构性约束高层决策来确保单步子目标可达性，采用解耦探索策略以系统地遍历目标空间中未充分探索的区域，并引入失败感知路径优化机制，根据观察到的低层成功动态调整边成本以提高子目标可靠性。

**结果:** 实验结果表明，在各种长时域基准测试中，SSE在效率和成功率方面始终优于现有的目标条件RL和分层RL方法。

**结论:** SSE框架有效解决了子目标不可行性和规划效率问题，为长时域目标条件任务提供了一种更高效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strict+Subgoal+Execution%3A+Reliable+Long-Horizon+Planning+in+Hierarchical+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21039，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21039&send_immediately=true&force_search=false)

**原文摘要:** Long-horizon goal-conditioned tasks pose fundamental challenges for
reinforcement learning (RL), particularly when goals are distant and rewards
are sparse. While hierarchical and graph-based methods offer partial solutions,
they often suffer from subgoal infeasibility and inefficient planning. We
introduce Strict Subgoal Execution (SSE), a graph-based hierarchical RL
framework that enforces single-step subgoal reachability by structurally
constraining high-level decision-making. To enhance exploration, SSE employs a
decoupled exploration policy that systematically traverses underexplored
regions of the goal space. Furthermore, a failure-aware path refinement, which
refines graph-based planning by dynamically adjusting edge costs according to
observed low-level success rates, thereby improving subgoal reliability.
Experimental results across diverse long-horizon benchmarks demonstrate that
SSE consistently outperforms existing goal-conditioned RL and hierarchical RL
approaches in both efficiency and success rate.

</details>


### [32] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
*Yifan Yang, Zhen Zhang, Rupak Vignesh Swaminathan, Jing Liu, Nathan Susanj, Zheng Zhang*

**主要类别:** cs.LG

**AI概要:** 通过提出的SharpZO方法，提升了零梯度视觉语言模型微调的性能和收敛速度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的微调视觉语言模型（VLMs）方法需要依赖反向传播（BP），这使得它们在内存受限或仅推理的边缘设备上不适用。而之前的无BP微调方法通常依赖于高方差的进化策略（ES）或零阶优化（ZO），效果不够理想。

**方法:** 提出了一种混合敏锐感知零阶优化（SharpZO）方法，该方法包含两个阶段：1) 敏锐感知ES阶段，用于全局探索和平滑损失景观以构建强大的初始化；2) 稀疏零阶优化进行精细局部搜索。整个优化过程仅依赖前向传递。

**结果:** 理论分析和大量实验表明，SharpZO显著提高了准确性和收敛速度，在CLIP模型上的实验中，相比最先进的前向方法平均提升了7%。

**结论:** SharpZO为提升零阶视觉语言模型微调的性能提供了一种有效的方法，适合在资源受限环境下使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SharpZO%3A+Hybrid+Sharpness-Aware+Vision+Language+Model+Prompt+Tuning+via+Forward-Only+Passes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20990，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20990&send_immediately=true&force_search=false)

**原文摘要:** Fine-tuning vision language models (VLMs) has achieved remarkable performance
across various downstream tasks; yet, it requires access to model gradients
through backpropagation (BP), making them unsuitable for memory-constrained,
inference-only edge devices. To address this limitation, previous work has
explored various BP-free fine-tuning methods. However, these approaches often
rely on high-variance evolutionary strategies (ES) or zeroth-order (ZO)
optimization, and often fail to achieve satisfactory performance. In this
paper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO)
approach, specifically designed to enhance the performance of ZO VLM
fine-tuning via a sharpness-aware warm-up training. SharpZO features a
two-stage optimization process: a sharpness-aware ES stage that globally
explores and smooths the loss landscape to construct a strong initialization,
followed by a fine-grained local search via sparse ZO optimization. The entire
optimization relies solely on forward passes. Detailed theoretical analysis and
extensive experiments on CLIP models demonstrate that SharpZO significantly
improves accuracy and convergence speed, achieving up to 7% average gain over
state-of-the-art forward-only methods.

</details>


### [33] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
*He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong*

**主要类别:** cs.LG

**AI概要:** 在无监督技能发现领域，本文提出了一种基于后悔值的新方法，通过将技能发现视为生成与策略学习的极小极大博弈问题，在效率和多样性上超越现有方法。实验表明该方法在高维环境下具有15%的零样本性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的无监督技能发现方法虽然在探索多样性方面表现出色，但在效率尤其是高维情况下的效率仍有局限。

**方法:** 本研究将技能发现建模为技能生成和策略学习的极小极大博弈，并提出了一种基于时间表示学习的后悔值感知方法，沿可升级策略强度方向扩展已发现的技能空间。技能发现与策略学习是对抗性的：弱强度技能需进一步探索，而收敛强度技能则减少探索。通过可学习的技能生成器指导技能发现，并使用可升级的技能生成器群体避免退化。

**结果:** 实验在不同复杂度和维度大小的环境中进行。结果表明，该方法在效率和多样性上均优于基线方法。此外，在高维环境中，该方法相比现有方法实现了15%的零样本性能提升。

**结论:** 所提出的方法在无监督技能发现任务中展现出更高的效率和更好的多样性，特别是在高维环境中的表现突出。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Skill+Discovery+via+Regret-Aware+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21044，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21044&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised skill discovery aims to learn diverse and distinguishable
behaviors in open-ended reinforcement learning. For existing methods, they
focus on improving diversity through pure exploration, mutual information
optimization, and learning temporal representation. Despite that they perform
well on exploration, they remain limited in terms of efficiency, especially for
the high-dimensional situations. In this work, we frame skill discovery as a
min-max game of skill generation and policy learning, proposing a regret-aware
method on top of temporal representation learning that expands the discovered
skill space along the direction of upgradable policy strength. The key insight
behind the proposed method is that the skill discovery is adversarial to the
policy learning, i.e., skills with weak strength should be further explored
while less exploration for the skills with converged strength. As an
implementation, we score the degree of strength convergence with regret, and
guide the skill discovery with a learnable skill generator. To avoid
degeneration, skill generation comes from an up-gradable population of skill
generators. We conduct experiments on environments with varying complexities
and dimension sizes. Empirical results show that our method outperforms
baselines in both efficiency and diversity. Moreover, our method achieves a 15%
zero shot improvement in high-dimensional environments, compared to existing
methods.

</details>


### [34] [Distilling Normalizing Flows](https://arxiv.org/abs/2506.21003)
*Steven Walton, Valeriy Klyukin, Maksim Artemev, Denis Derkach, Nikita Orlov, Humphrey Shi*

**主要类别:** cs.LG

**AI概要:** 显式密度学习者由于其对概率分布更好的建模能力，正成为生成模型中越来越流行的技巧。尽管它们具有执行密度估计和精确潜在变量推断的能力，但这些模型往往更难训练，采样质量也较低。本文提出了一种新的知识蒸馏技术，以提高较小的学生标准化流的采样质量和密度估计。研究发现，通过这种蒸馏，可以在显著减小学生规模的同时，取得实质性的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 显式密度学习者相比生成对抗网络（GANs）具有执行密度估计和精确潜在变量推断的优势，但由于训练难度大和采样质量低的问题，需要改进。

**方法:** 提出新的知识蒸馏技术，应用于组合标准化流（Compositional Normalizing Flows），以提高较小的学生模型的采样质量和密度估计能力。利用标准化流的独特性质，进行非传统的知识传递，包括在中间层之间的知识转移。

**结果:** 通过知识蒸馏，可以使学生模型显著缩小，同时获得实质性的性能提升。更小的模型能够带来更高的吞吐量，因为吞吐量与网络中的双射函数数量和参数数量相关。

**结论:** 知识蒸馏在组合标准化流中表现出色，能够有效提高小型模型的性能，同时保持较高的计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distilling+Normalizing+Flows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21003，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21003&send_immediately=true&force_search=false)

**原文摘要:** Explicit density learners are becoming an increasingly popular technique for
generative models because of their ability to better model probability
distributions. They have advantages over Generative Adversarial Networks due to
their ability to perform density estimation and having exact latent-variable
inference. This has many advantages, including: being able to simply
interpolate, calculate sample likelihood, and analyze the probability
distribution. The downside of these models is that they are often more
difficult to train and have lower sampling quality.
  Normalizing flows are explicit density models, that use composable bijective
functions to turn an intractable probability function into a tractable one. In
this work, we present novel knowledge distillation techniques to increase
sampling quality and density estimation of smaller student normalizing flows.
We seek to study the capacity of knowledge distillation in Compositional
Normalizing Flows to understand the benefits and weaknesses provided by these
architectures. Normalizing flows have unique properties that allow for a
non-traditional forms of knowledge transfer, where we can transfer that
knowledge within intermediate layers. We find that through this distillation,
we can make students significantly smaller while making substantial performance
gains over a non-distilled student. With smaller models there is a
proportionally increased throughput as this is dependent upon the number of
bijectors, and thus parameters, in the network.

</details>


### [35] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
*Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale*

**主要类别:** cs.LG

**AI概要:** 本文提出FeDa4Fair库、四个偏差异构数据集及相应的基准测试，以及可直接使用的公平性评估函数，以支持更强大和可重复的联邦学习公平性研究。


<details>
  <summary>更多</summary>
  
**动机:** 当前的公平性增强解决方案大多关注单一敏感属性的偏差缓解，忽视了不同客户可能存在的多样化和有时相互冲突的公平性需求，这限制了对不同客户的公平性干预的有效性。

**方法:** 贡献包括：1) 开发FeDa4Fair库生成用于评估公平联邦学习方法的数据集；2) 发布四个偏差异构数据集及其基准测试；3) 提供可直接使用的公平性评估函数。

**结果:** 通过提供的工具和数据集，可以更一致地对全球和客户级别的公平联邦学习方法进行基准测试。

**结论:** 这些贡献将促进更强大和可重复的联邦学习公平性研究，并为未来的工作提供一个标准化的平台。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FeDa4Fair%3A+Client-Level+Federated+Datasets+for+Fairness+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21095，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21095&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) enables collaborative model training across multiple
clients without sharing clients' private data. However, fairness remains a key
concern, as biases in local clients' datasets can impact the entire federated
system. Heterogeneous data distributions across clients may lead to models that
are fairer for some clients than others. Although several fairness-enhancing
solutions are present in the literature, most focus on mitigating bias for a
single sensitive attribute, typically binary, overlooking the diverse and
sometimes conflicting fairness needs of different clients. This limited
perspective can limit the effectiveness of fairness interventions for the
different clients. To support more robust and reproducible fairness research in
FL, we aim to enable a consistent benchmarking of fairness-aware FL methods at
both the global and client levels. In this paper, we contribute in three ways:
(1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to
evaluating fair FL methods under heterogeneous client bias; (2) we release four
bias-heterogeneous datasets and corresponding benchmarks to compare fairness
mitigation methods in a controlled environment; (3) we provide ready-to-use
functions for evaluating fairness outcomes for these datasets.

</details>


### [36] [TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence](https://arxiv.org/abs/2506.21028)
*Feng Jiang, Mangal Prakash, Hehuan Ma, Jianyuan Deng, Yuzhi Guo, Amina Mollaysa, Tommaso Mansi, Rui Liao, Junzhou Huang*

**主要类别:** cs.LG

**AI概要:** TRIDENT是一种新的框架，它整合了分子的SMILES、文本描述和分类功能注释来学习丰富的分子表示。通过使用基于体积的对齐目标和新颖的局部对齐目标，结合动量机制动态平衡全局和局部对齐，TRIDENT在11个下游任务上达到了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多模态学习已成为学习分子表示的强大范例，但先前的工作大多忽略了分子的文本和分类信息。本研究旨在利用这些信息以提高分子属性预测的效果。

**方法:** TRIDENT引入了一个全面的分子-文本对数据集，具有结构化的多层次功能注释。该框架不依赖传统的对比损失，而是采用基于体积的对齐目标来联合对齐三模态特征，实现跨模态的软、几何感知对齐。此外，还引入了一种新的局部对齐目标，捕捉分子子结构与相应子文本描述之间的详细关系，并通过动量机制动态平衡全局和局部对齐。

**结果:** TRIDENT在11个下游任务上实现了最先进的性能，证明了结合SMILES、文本和分类功能注释对于分子属性预测的价值。

**结论:** TRIDENT展示了将分子的SMILES、文本描述和分类功能注释相结合的优势，能够有效提升分子属性预测的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRIDENT%3A+Tri-Modal+Molecular+Representation+Learning+with+Taxonomic+Annotations+and+Local+Correspondence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21028，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21028&send_immediately=true&force_search=false)

**原文摘要:** Molecular property prediction aims to learn representations that map chemical
structures to functional properties. While multimodal learning has emerged as a
powerful paradigm to learn molecular representations, prior works have largely
overlooked textual and taxonomic information of molecules for representation
learning. We introduce TRIDENT, a novel framework that integrates molecular
SMILES, textual descriptions, and taxonomic functional annotations to learn
rich molecular representations. To achieve this, we curate a comprehensive
dataset of molecule-text pairs with structured, multi-level functional
annotations. Instead of relying on conventional contrastive loss, TRIDENT
employs a volume-based alignment objective to jointly align tri-modal features
at the global level, enabling soft, geometry-aware alignment across modalities.
Additionally, TRIDENT introduces a novel local alignment objective that
captures detailed relationships between molecular substructures and their
corresponding sub-textual descriptions. A momentum-based mechanism dynamically
balances global and local alignment, enabling the model to learn both broad
functional semantics and fine-grained structure-function mappings. TRIDENT
achieves state-of-the-art performance on 11 downstream tasks, demonstrating the
value of combining SMILES, textual, and taxonomic functional annotations for
molecular property prediction.

</details>


### [37] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
*David Debot, Pietro Barbiero, Gabriele Dominici, Giuseppe Marra*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的CBM模型H-CMR，通过学习的概念有向无环图和神经注意力机制提供概念和任务预测的可解释性，同时匹配最先进性能并支持通过概念和模型干预进行强人机交互。


<details>
  <summary>更多</summary>
  
**动机:** 当前的基于概念的模型（CBMs）虽然可以通过高级概念解释预测来提供可解释性，但这些概念预测本身通常是通过黑箱神经网络完成的，缺乏透明度。因此需要一种新方法，可以为概念预测和最终任务预测都提供可解释性。

**方法:** 提出了分层概念记忆推理器（H-CMR），这是一种新的CBM模型，它使用学习到的有向无环图建模概念间的关系，边代表定义概念的逻辑规则。在推理过程中，H-CMR使用神经注意力机制选择一部分规则，并按层次结构应用这些规则以预测所有概念和最终任务。

**结果:** 实验结果表明，H-CMR在达到最先进性能的同时，通过概念和模型干预实现了强大的人类互动。前者可以在推理时显著提高准确性，后者在训练期间利用背景知识可以提高数据效率。

**结论:** H-CMR是一种能够提供对概念和任务预测可解释性的新型CBM模型，其不仅与现有最先进模型性能相当，还支持更强大的人类互动，从而提升推理准确性和训练的数据效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Hierarchical+Concept+Reasoning+through+Attention-Guided+Graph+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21102，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21102&send_immediately=true&force_search=false)

**原文摘要:** Concept-Based Models (CBMs) are a class of deep learning models that provide
interpretability by explaining predictions through high-level concepts. These
models first predict concepts and then use them to perform a downstream task.
However, current CBMs offer interpretability only for the final task
prediction, while the concept predictions themselves are typically made via
black-box neural networks. To address this limitation, we propose Hierarchical
Concept Memory Reasoner (H-CMR), a new CBM that provides interpretability for
both concept and task predictions. H-CMR models relationships between concepts
using a learned directed acyclic graph, where edges represent logic rules that
define concepts in terms of other concepts. During inference, H-CMR employs a
neural attention mechanism to select a subset of these rules, which are then
applied hierarchically to predict all concepts and the final task. Experimental
results demonstrate that H-CMR matches state-of-the-art performance while
enabling strong human interaction through concept and model interventions. The
former can significantly improve accuracy at inference time, while the latter
can enhance data efficiency during training when background knowledge is
available.

</details>


### [38] [Little By Little: Continual Learning via Self-Activated Sparse Mixture-of-Rank Adaptive Learning](https://arxiv.org/abs/2506.21035)
*Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong*

**主要类别:** cs.LG

**AI概要:** 提出MoRA方法，通过自激活和稀疏秩激活解决持续学习中的灾难性遗忘和任务干扰问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LoRA-based MoE方法虽然能缓解遗忘，但存在干扰、冗余和路由模糊的问题。

**方法:** 将每个秩-r更新分解为r个秩-1组件，作为独立专家，实现细粒度的秩-1专家利用；每个秩-1专家可通过中间激活推断自身相关性；结合秩剪枝和激活预算，MoRA自适应地选择每输入的稀疏秩混合。

**结果:** 在CLIP和大语言模型上的验证表明，MoRA显著提高了持续学习的效果，并改善了泛化能力同时减轻了遗忘。

**结论:** MoRA方法在增强预训练模型的持续学习能力和改善泛化方面表现出显著效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Little+By+Little%3A+Continual+Learning+via+Self-Activated+Sparse+Mixture-of-Rank+Adaptive+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21035，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21035&send_immediately=true&force_search=false)

**原文摘要:** Continual learning (CL) with large pre-trained models is challenged by
catastrophic forgetting and task interference. Existing LoRA-based
Mixture-of-Experts (MoE) approaches mitigate forgetting by assigning and
freezing task-specific adapters, but suffer from interference, redundancy, and
ambiguous routing due to coarse adapter-level selection. However, this design
introduces three key challenges: 1) Interference: Activating full LoRA experts
per input leads to subspace interference and prevents selective reuse of useful
components across tasks. 2) Redundancy: Newly added experts often duplicate or
contradict existing knowledge due to unnecessary activation of unrelated ranks
and insufficient reuse of relevant ones. 3) Ambiguity: Overlapping features
across tasks confuse the router, resulting in unstable expert assignments. As
more experts accumulate, earlier task routing degrades, accelerating
forgetting. We propose MoRA, a Mixture-of-Rank Adaptive learning approach with
self-activated and sparse rank activation for CL. Unlike mixing multiple
low-rank matrices, MoRA decomposes each rank-r update into r rank-1 components,
each treated as an independent expert, enabling fine-grained mixture of rank-1
expert utilization while mitigating interference and redundancy. To avoid
ambiguous routing, we propose that each rank-1 expert can infer its own
relevance via intermediate activations. Coupled with our proposed rank pruning
and activation budgets, MoRA adaptively selects a sparse mixture of ranks per
input. We validate MoRA on continual learning tasks with CLIP and large
language models (LLMs), analyzing both in-domain learning and out-of-domain
forgetting/generalization during fine-tuning. MoRA shows significant
effectiveness on enhancing CL with PTMs, and improving generalization while
mitigating forgetting.

</details>


### [39] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
*Deepak Kumar Panda, Weisi Guo*

**主要类别:** cs.LG

**AI概要:** The paper introduces an antifragile RL framework for UAV navigation that enhances adaptability to adversarial attacks by incorporating discounted Thompson sampling (DTS) to dynamically select among multiple robust policies. This approach outperforms conventional robust RL methods in complex environments with stronger attacks.


<details>
  <summary>更多</summary>
  
**动机:** Existing robust reinforcement learning (RL) methods for unmanned aerial vehicles (UAVs) have limited generalization to out-of-distribution shifts from the optimal value distribution, as they are primarily designed to handle fixed perturbation.

**方法:** An antifragile RL framework is proposed, which incorporates a switching mechanism based on discounted Thompson sampling (DTS). The method first derives a diverse ensemble of action robust policies considering various perturbations. These policies are then modeled as a multi-armed bandit problem where DTS optimally selects policies in response to nonstationary rewards.

**结果:** Extensive numerical simulations show that the proposed framework achieves superior performance in complex navigation environments with multiple dynamic three-dimensional obstacles and stronger adversarial attacks, demonstrating shorter navigation path lengths and a higher rate of conflict-free navigation trajectories compared to existing robust RL techniques.

**结论:** The antifragile RL framework significantly improves adaptability to broader distributional shifts caused by adversarial attacks, outperforming conventional robust RL methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Policy+Switching+for+Antifragile+Reinforcement+Learning+for+UAV+Deconfliction+in+Adversarial+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21127，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21127&send_immediately=true&force_search=false)

**原文摘要:** The increasing automation of navigation for unmanned aerial vehicles (UAVs)
has exposed them to adversarial attacks that exploit vulnerabilities in
reinforcement learning (RL) through sensor manipulation. Although existing
robust RL methods aim to mitigate such threats, their effectiveness has limited
generalization to out-of-distribution shifts from the optimal value
distribution, as they are primarily designed to handle fixed perturbation. To
address this limitation, this paper introduces an antifragile RL framework that
enhances adaptability to broader distributional shifts by incorporating a
switching mechanism based on discounted Thompson sampling (DTS). This mechanism
dynamically selects among multiple robust policies to minimize adversarially
induced state-action-value distribution shifts. The proposed approach first
derives a diverse ensemble of action robust policies by accounting for a range
of perturbations in the policy space. These policies are then modeled as a
multiarmed bandit (MAB) problem, where DTS optimally selects policies in
response to nonstationary Bernoulli rewards, effectively adapting to evolving
adversarial strategies. Theoretical framework has also been provided where by
optimizing the DTS to minimize the overall regrets due to distributional shift,
results in effective adaptation against unseen adversarial attacks thus
inducing antifragility. Extensive numerical simulations validate the
effectiveness of the proposed framework in complex navigation environments with
multiple dynamic three-dimensional obstacles and with stronger projected
gradient descent (PGD) and spoofing attacks. Compared to conventional robust,
non-adaptive RL methods, the antifragile approach achieves superior
performance, demonstrating shorter navigation path lengths and a higher rate of
conflict-free navigation trajectories compared to existing robust RL techniques

</details>


### [40] [An Information-Theoretic Analysis for Federated Learning under Concept Drift](https://arxiv.org/abs/2506.21036)
*Fu Peng, Meng Zhang, Ming Tang*

**主要类别:** cs.LG

**AI概要:** Recent studies in federated learning (FL) commonly train models on static datasets. However, real-world data often arrives as streams with shifting distributions, causing performance degradation known as concept drift. This paper analyzes FL performance under concept drift using information theory and proposes an algorithm to mitigate the performance degradation.


<details>
  <summary>更多</summary>
  
**动机:** Real-world data is dynamic and shifts over time, which can cause a phenomenon known as concept drift that degrades model performance. Existing FL approaches mostly focus on static datasets, so there's a need for strategies to handle these shifts effectively.

**方法:** The authors model concept drift as a Markov chain and introduce the Stationary Generalization Error to evaluate a model's ability to generalize to unseen data. They derive its upper bound using KL divergence and mutual information. Based on this analysis, they propose an algorithm that incorporates KL divergence and mutual information into empirical risk minimization to enhance long-term performance. Additionally, they explore the tradeoff between performance and cost by identifying a Pareto front.

**结果:** The proposed method outperforms existing approaches across three types of drift patterns (periodic, gradual, and random). Experimental results align with theoretical findings, demonstrating the effectiveness of the method in adapting to concept drift in federated learning settings.

**结论:** Concept drift significantly impacts federated learning performance. The introduced algorithm effectively mitigates performance degradation caused by concept drift through the use of KL divergence and mutual information, providing a robust solution for handling dynamic data distributions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Information-Theoretic+Analysis+for+Federated+Learning+under+Concept+Drift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21036，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21036&send_immediately=true&force_search=false)

**原文摘要:** Recent studies in federated learning (FL) commonly train models on static
datasets. However, real-world data often arrives as streams with shifting
distributions, causing performance degradation known as concept drift. This
paper analyzes FL performance under concept drift using information theory and
proposes an algorithm to mitigate the performance degradation. We model concept
drift as a Markov chain and introduce the \emph{Stationary Generalization
Error} to assess a model's capability to capture characteristics of future
unseen data. Its upper bound is derived using KL divergence and mutual
information. We study three drift patterns (periodic, gradual, and random) and
their impact on FL performance. Inspired by this, we propose an algorithm that
regularizes the empirical risk minimization approach with KL divergence and
mutual information, thereby enhancing long-term performance. We also explore
the performance-cost tradeoff by identifying a Pareto front. To validate our
approach, we build an FL testbed using Raspberry Pi4 devices. Experimental
results corroborate with theoretical findings, confirming that drift patterns
significantly affect performance. Our method consistently outperforms existing
approaches for these three patterns, demonstrating its effectiveness in
adapting concept drift in FL.

</details>


### [41] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
*Deepak Kumar Panda, Adolfo Perrusquia, Weisi Guo*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种抗脆弱性强化学习框架，通过引入模拟攻击者和迭代专家引导的批评者对齐方法，使RL代理能够适应并泛化到更广泛的OOD观察，并在UAV冲突场景中展示了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习（RL）策略在关键安全系统中的应用容易受到观测空间中的OOD对抗攻击的影响，这些攻击会显著降低价值估计，导致不安全或次优决策。

**方法:** 提出了一个抗脆弱性RL框架，该框架包含一个模拟攻击者，逐步增加观测空间扰动的强度，从而使RL代理能够适应并泛化到更广泛的OOD观察。同时，通过Wasserstein距离最小化实现迭代专家引导的批评者对齐。

**结果:** 在涉及动态3D障碍物的UAV冲突场景中，抗脆弱性策略在面对PGD和GPS欺骗攻击时，相较于标准和鲁棒RL基线，表现出了高达15%更高的累积奖励和超过30%更少的冲突事件。

**结论:** 抗脆弱性强化学习为在具有演化威胁情景的环境中实现安全且有弹性的决策提供了实际和理论上的可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Curriculum-Guided+Antifragile+Reinforcement+Learning+for+Secure+UAV+Deconfliction+under+Observation-Space+Attacks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21129，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21129&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) policies deployed in safety-critical systems,
such as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are
vulnerable to out-ofdistribution (OOD) adversarial attacks in the observation
space. These attacks induce distributional shifts that significantly degrade
value estimation, leading to unsafe or suboptimal decision making rendering the
existing policy fragile. To address this vulnerability, we propose an
antifragile RL framework designed to adapt against curriculum of incremental
adversarial perturbations. The framework introduces a simulated attacker which
incrementally increases the strength of observation-space perturbations which
enables the RL agent to adapt and generalize across a wider range of OOD
observations and anticipate previously unseen attacks. We begin with a
theoretical characterization of fragility, formally defining catastrophic
forgetting as a monotonic divergence in value function distributions with
increasing perturbation strength. Building on this, we define antifragility as
the boundedness of such value shifts and derive adaptation conditions under
which forgetting is stabilized. Our method enforces these bounds through
iterative expert-guided critic alignment using Wasserstein distance
minimization across incrementally perturbed observations. We empirically
evaluate the approach in a UAV deconfliction scenario involving dynamic 3D
obstacles. Results show that the antifragile policy consistently outperforms
standard and robust RL baselines when subjected to both projected gradient
descent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative
reward and over 30% fewer conflict events. These findings demonstrate the
practical and theoretical viability of antifragile reinforcement learning for
secure and resilient decision-making in environments with evolving threat
scenarios.

</details>


### [42] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
*Suorong Yang, Peijia Li, Furao Shen, Jian Zhao*

**主要类别:** cs.LG

**AI概要:** Modern deep learning architectures benefit from large datasets but face high costs. This paper introduces epsilon-sample cover and RL-Selector, a reinforcement learning-based method to optimize data selection by reducing redundancy and improving training efficiency without sacrificing performance.


<details>
  <summary>更多</summary>
  
**动机:** Current deep learning models rely on large datasets that are computationally expensive. Real-world datasets often have redundancies, necessitating more efficient data usage paradigms.

**方法:** The authors introduce the concept of epsilon-sample cover to quantify sample redundancy based on inter-sample relationships. They reformulate data selection as a reinforcement learning problem with RL-Selector, using a lightweight RL agent to optimize selection policies.

**结果:** Experiments across various benchmark datasets and architectures show that the proposed method outperforms existing state-of-the-art baselines in terms of training efficiency and generalization performance.

**结论:** RL-Selector provides an effective way to reduce redundancy in datasets, leading to enhanced generalization and improved training efficiency.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RL-Selector%3A+Reinforcement+Learning-Guided+Data+Selection+via+Redundancy+Assessment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21037&send_immediately=true&force_search=false)

**原文摘要:** Modern deep architectures often rely on large-scale datasets, but training on
these datasets incurs high computational and storage overhead. Real-world
datasets often contain substantial redundancies, prompting the need for more
data-efficient training paradigms. Data selection has shown promise to mitigate
redundancy by identifying the most representative samples, thereby reducing
training costs without compromising performance. Existing methods typically
rely on static scoring metrics or pretrained models, overlooking the combined
effect of selected samples and their evolving dynamics during training. We
introduce the concept of epsilon-sample cover, which quantifies sample
redundancy based on inter-sample relationships, capturing the intrinsic
structure of the dataset. Based on this, we reformulate data selection as a
reinforcement learning (RL) process and propose RL-Selector, where a
lightweight RL agent optimizes the selection policy by leveraging
epsilon-sample cover derived from evolving dataset distribution as a reward
signal. Extensive experiments across benchmark datasets and diverse
architectures demonstrate that our method consistently outperforms existing
state-of-the-art baselines. Models trained with our selected datasets show
enhanced generalization performance with improved training efficiency.

</details>


### [43] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
*Ziwei Wang, Hongbin Wang, Tianwang Jia, Xingyi He, Siyang Li, Dongrui Wu*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为DBConformer的双分支卷积Transformer网络，专门用于EEG解码。它通过时间Conformer和空间Conformer分别捕捉长时依赖性和通道间交互，并通过轻量级通道注意力模块优化空间表示。实验表明，DBConformer在参数更少的情况下优于10个基线模型，并且其特征具有生理可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的CNN和CNN-Transformer混合模型在捕捉EEG信号的长时间依赖性和全局通道关系方面存在不足，且对通道建模不够明确。因此需要一种新方法来有效整合局部和全局特征并增强通道建模能力。

**方法:** DBConformer是一种双分支卷积Transformer网络，包括一个时间Conformer用于建模长时间依赖性，一个空间Conformer用于提取通道间交互，并使用轻量级通道注意力模块分配数据驱动的重要性给EEG通道。

**结果:** DBConformer在五个运动想象（MI）数据集和两个癫痫检测数据集上进行的广泛实验中表现优异，超过所有基线模型，同时参数量仅为高容量EEG Conformer基线模型的八分之一以上。可视化结果也验证了DBConformer提取的特征具有生理可解释性。

**结论:** DBConformer展示了卓越的性能和良好的可解释性，适合于鲁棒和可解释的EEG解码任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DBConformer%3A+Dual-Branch+Convolutional+Transformer+for+EEG+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21140&send_immediately=true&force_search=false)

**原文摘要:** Electroencephalography (EEG)-based brain-computer interfaces (BCIs) transform
spontaneous/evoked neural activity into control commands for external
communication. While convolutional neural networks (CNNs) remain the mainstream
backbone for EEG decoding, their inherently short receptive field makes it
difficult to capture long-range temporal dependencies and global inter-channel
relationships. Recent CNN-Transformer (Conformers) hybrids partially address
this issue, but most adopt a serial design, resulting in suboptimal integration
of local and global features, and often overlook explicit channel-wise
modeling. To address these limitations, we propose DBConformer, a dual-branch
convolutional Transformer network tailored for EEG decoding. It integrates a
temporal Conformer to model long-range temporal dependencies and a spatial
Conformer to extract inter-channel interactions, capturing both temporal
dynamics and spatial patterns in EEG signals. A lightweight channel attention
module further refines spatial representations by assigning data-driven
importance to EEG channels. Extensive experiments on five motor imagery (MI)
datasets and two seizure detection datasets under three evaluation settings
demonstrate that DBConformer consistently outperforms 10 competitive baseline
models, with over eight times fewer parameters than the high-capacity EEG
Conformer baseline. Further, the visualization results confirm that the
features extracted by DBConformer are physiologically interpretable and aligned
with sensorimotor priors in MI. The superior performance and interpretability
of DBConformer make it reliable for robust and explainable EEG decoding. Code
is publicized at https://github.com/wzwvv/DBConformer.

</details>


### [44] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
*Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich*

**主要类别:** cs.LG

**AI概要:** 提出DiLoCoX框架，用于低通信需求的大规模去中心化集群训练，通过多种技术组合提高参数规模和预训练速度，实现在1Gbps网络上对107B模型的有效预训练，并实现357倍加速。


<details>
  <summary>更多</summary>
  
**动机:** 分布式训练基础模型（如大语言模型）需要高通信量，通常依赖于集中式集群。为了解决在慢速网络和去中心化集群上训练超100亿参数模型的问题。

**方法:** 提出DiLoCoX框架，结合管道并行性、双优化器策略、一步延迟通信与本地训练重叠以及自适应梯度压缩方案。

**结果:** 理论上证明了一步延迟通信与本地训练重叠及自适应梯度压缩方案的收敛性优势；实证上，在1Gbps网络上成功预训练107B模型，相比传统AllReduce方法实现357倍加速，且模型收敛性几乎无损。

**结论:** DiLoCoX是首个成功应用于超100亿参数模型的去中心化训练框架，极大地提高了慢速网络环境下的训练效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DiLoCoX%3A+A+Low-Communication+Large-Scale+Training+Framework+for+Decentralized+Cluster，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21263，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21263&send_immediately=true&force_search=false)

**原文摘要:** The distributed training of foundation models, particularly large language
models (LLMs), demands a high level of communication. Consequently, it is
highly dependent on a centralized cluster with fast and reliable interconnects.
Can we conduct training on slow networks and thereby unleash the power of
decentralized clusters when dealing with models exceeding 100 billion
parameters? In this paper, we propose DiLoCoX, a low-communication large-scale
decentralized cluster training framework. It combines Pipeline Parallelism with
Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local
Training, and an Adaptive Gradient Compression Scheme. This combination
significantly improves the scale of parameters and the speed of model
pre-training. We justify the benefits of one-step-delay overlap of
communication and local training, as well as the adaptive gradient compression
scheme, through a theoretical analysis of convergence. Empirically, we
demonstrate that DiLoCoX is capable of pre-training a 107B foundation model
over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x
speedup in distributed training while maintaining negligible degradation in
model convergence. To the best of our knowledge, this is the first
decentralized training framework successfully applied to models with over 100
billion parameters.

</details>


### [45] [FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning](https://arxiv.org/abs/2506.21054)
*Fu Peng, Ming Tang*

**主要类别:** cs.LG

**AI概要:** 在联邦学习中，概念漂移引入了时间和空间数据异质性。大多数现有方法主要关注真实漂移，但在虚拟或标签漂移时容易发生灾难性遗忘。本文提出了FedDAA框架，通过三个模块（集群数量确定、真实漂移检测和概念漂移适应）来应对多源概念漂移，并保留有价值的历史知识。实验表明，FedDAA在多个数据集上比现有方法提高了7.84%到8.52%的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中的数据分布可能会随时间变化，导致时间和空间上的数据异质性（即概念漂移）。当前解决概念漂移的方法大多集中在真实漂移上，而在面对虚拟或标签漂移时往往无法有效选择性地保留有用的历史知识，从而导致灾难性遗忘。因此，需要一种能够区分不同漂移来源并采取相应策略的方法。

**方法:** 提出了一种名为FedDAA的动态聚类联邦学习框架，该框架包含三个模块：1) 集群数量确定模块，用于找到最佳集群数量；2) 真实漂移检测模块，用于区分真实漂移与虚拟/标签漂移；3) 概念漂移适应模块，用于在适应新数据的同时保留有用的历史信息。此外，还提供了理论收敛保证。

**结果:** 实验结果表明，FedDAA在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上分别比现有最先进的方法提高了7.84%到8.52%的准确性。

**结论:** FedDAA是一种有效的联邦学习框架，可以适应多源概念漂移并保留历史知识。其性能优于现有的方法，且具有理论收敛保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedDAA%3A+Dynamic+Client+Clustering+for+Concept+Drift+Adaptation+in+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21054&send_immediately=true&force_search=false)

**原文摘要:** In federated learning (FL), the data distribution of each client may change
over time, introducing both temporal and spatial data heterogeneity, known as
concept drift. Data heterogeneity arises from three drift sources: real drift
(a shift in the conditional distribution P(y|x)), virtual drift (a shift in the
input distribution P(x)), and label drift (a shift in the label distribution
P(y)). However, most existing FL methods addressing concept drift primarily
focus on real drift. When clients experience virtual or label drift, these
methods often fail to selectively retain useful historical knowledge, leading
to catastrophic forgetting. A key challenge lies in distinguishing different
sources of drift, as they require distinct adaptation strategies: real drift
calls for discarding outdated data, while virtual or label drift benefits from
retaining historical data. Without explicitly identifying the drift sources, a
general adaptation strategy is suboptimal and may harm generalization. To
address this challenge, we propose FedDAA, a dynamic clustered FL framework
designed to adapt to multi-source concept drift while preserving valuable
historical knowledge. Specifically, FedDAA integrates three modules: a cluster
number determination module to find the optimal number of clusters; a real
drift detection module to distinguish real drift from virtual/label drift; and
a concept drift adaptation module to adapt to new data while retaining useful
historical information. We provide theoretical convergence guarantees, and
experiments show that FedDAA achieves 7.84% to 8.52% accuracy improvements over
state-of-the-art methods on Fashion-MNIST, CIFAR-10, and CIFAR-100.

</details>


### [46] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
*Jingwei Wang, Zai Zhang, Hao Qian, Chunjing Gan, Binbin Hu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Bin Shi, Bo Dong*

**主要类别:** cs.LG

**AI概要:** 通过使用知识图谱生成高质量指令数据，提升大型语言模型的工具使用能力和整体性能。


<details>
  <summary>更多</summary>
  
**动机:** 教授大型语言模型（LLMs）如何使用工具对于提高其解决问题的能力和扩展应用至关重要，但有效使用工具需要对工具功能和用户意图有深刻理解，而以往方法生成的数据质量往往不足。

**方法:** 提出一种新方法，利用知识图谱生成高质量指令数据。从知识图谱中提取查询路径，转换为多样用户查询，将实体间关系转化为可执行工具，并解析每条查询路径为详细解决方案步骤。

**结果:** 实验表明，仅用少量合成数据进行微调即可显著提高LLMs的工具使用能力及整体性能。

**结论:** 使用知识图谱生成高质量指令数据的方法能有效提升LLMs的工具使用效率和综合能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+LLM+Tool+Use+with+High-quality+Instruction+Data+from+Knowledge+Graph，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21071，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21071&send_immediately=true&force_search=false)

**原文摘要:** Teaching large language models (LLMs) to use tools is crucial for improving
their problem-solving abilities and expanding their applications. However,
effectively using tools is challenging because it requires a deep understanding
of tool functionalities and user intentions. Previous methods relied mainly on
LLMs to generate instruction data, but the quality of these data was often
insufficient. In this paper, we propose a new method that uses knowledge graphs
to generate high-quality instruction data for LLMs. Knowledge graphs are
manually curated datasets rich in semantic information. We begin by extracting
various query pathways from a given knowledge graph, which are transformed into
a broad spectrum of user queries. We then translate the relationships between
entities into actionable tools and parse the pathways of each query into
detailed solution steps, thereby creating high-quality instruction data. Our
experiments show that fine-tuning on just a small sample of this synthetic data
can significantly improve the tool utilization and overall capabilities of
LLMs.

</details>


### [47] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
*Sam Lerman, Jing Bi*

**主要类别:** cs.LG

**AI概要:** rQdia在基于像素的深度强化学习中通过增广图像来正则化Q值分布，提升多种算法的样本效率和长期训练表现。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习中的模型无连续控制从像素超越状态编码基线存在挑战，而正则化Q值分布可能改善这一情况。

**方法:** rQdia使用简单的辅助损失函数（均方误差）使Q值分布在增广图像上均等化，从而增强DrQ、SAC和Data-Efficient Rainbow等算法。

**结果:** rQdia在MuJoCo Continuous Control Suite和Atari Arcade环境中分别提升了9/12、10/12任务以及18/26环境的表现，改进了样本效率和长期训练效果。

**结论:** rQdia有效提升基于像素的模型无连续控制性能，成功超越状态编码基线。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是rQdia%3A+Regularizing+Q-Value+Distributions+With+Image+Augmentation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21367，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21367&send_immediately=true&force_search=false)

**原文摘要:** rQdia regularizes Q-value distributions with augmented images in pixel-based
deep reinforcement learning. With a simple auxiliary loss, that equalizes these
distributions via MSE, rQdia boosts DrQ and SAC on 9/12 and 10/12 tasks
respectively in the MuJoCo Continuous Control Suite from pixels, and
Data-Efficient Rainbow on 18/26 Atari Arcade environments. Gains are measured
in both sample efficiency and longer-term training. Moreover, the addition of
rQdia finally propels model-free continuous control from pixels over the state
encoding baseline.

</details>


### [48] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
*Chao Zhou, Tom Jacobs, Advait Gadhikar, Rebekka Burkholz*

**主要类别:** cs.LG

**AI概要:** 微调大型预训练神经网络资源密集，通过分析梯度与权重的关系，发现大梯度通常与小权重相关。基于此观察提出NANOADAM方法，动态更新小权重参数，具有无需梯度计算、保留重要特征、允许更大学习率等优势，在NLP和视觉任务中均表现良好。


<details>
  <summary>更多</summary>
  
**动机:** 微调大型预训练模型资源消耗大，限制训练的参数子集是常见做法。作者观察到微调时大梯度通常与小权重相关，这一现象比从头训练更为显著。

**方法:** 提出NANOADAM方法，在微调过程中仅动态更新小权重参数。该方法无需梯度计算即可确定参数子集，保留大权重以减少灾难性遗忘，并允许使用更大的学习率。

**结果:** 在NLP和视觉任务中的实验表明，NANOADAM方法能带来更好的泛化性能。

**结论:** NANOADAM是一种有效的优化方法，能够在微调大型模型时降低资源消耗并提高性能，适用于多种任务场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pay+Attention+to+Small+Weights，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21374，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21374&send_immediately=true&force_search=false)

**原文摘要:** Finetuning large pretrained neural networks is known to be
resource-intensive, both in terms of memory and computational cost. To mitigate
this, a common approach is to restrict training to a subset of the model
parameters. By analyzing the relationship between gradients and weights during
finetuning, we observe a notable pattern: large gradients are often associated
with small-magnitude weights. This correlation is more pronounced in finetuning
settings than in training from scratch. Motivated by this observation, we
propose NANOADAM, which dynamically updates only the small-magnitude weights
during finetuning and offers several practical advantages: first, this
criterion is gradient-free -- the parameter subset can be determined without
gradient computation; second, it preserves large-magnitude weights, which are
likely to encode critical features learned during pretraining, thereby reducing
the risk of catastrophic forgetting; thirdly, it permits the use of larger
learning rates and consistently leads to better generalization performance in
experiments. We demonstrate this for both NLP and vision tasks.

</details>


### [49] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
*Zhi Zheng, Bochuan Zhou, Yuping Song*

**主要类别:** cs.LG

**AI概要:** 提出了一种增强的时间感知图注意力网络（ATGAT），通过三个模块提高加密货币交易欺诈检测性能，包括高级时间嵌入模块、时间感知三重注意机制和加权BCE损失。实验表明，ATGAT在Elliptic++数据集上取得了0.9130的AUC值，显著优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 加密货币交易欺诈检测面临着日益复杂的交易模式和严重的类别不平衡问题。传统方法依赖于人工特征工程，难以捕捉交易网络中的时间和结构依赖关系。

**方法:** 该方法包含三个模块：(1) 设计了一个先进的时序嵌入模块，将多尺度时间差特征与周期性位置编码融合；(2) 构建了一个时序感知的三重注意机制，联合优化结构、时序和全局上下文注意；(3) 使用加权BCE损失解决类别不平衡问题。

**结果:** 在Elliptic++数据集上的实验表明，ATGAT达到了0.9130的AUC值，相比最佳传统方法XGBoost提高了9.2%，相比GCN提高了12.0%，相比标准GAT提高了10.0%。

**结论:** 该方法验证了时序感知和三重注意机制对图神经网络的增强效果，并为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广到其他时序图异常检测任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Temporal-Aware+Graph+Attention+Network+for+Cryptocurrency+Transaction+Fraud+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21382，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21382&send_immediately=true&force_search=false)

**原文摘要:** Cryptocurrency transaction fraud detection faces the dual challenges of
increasingly complex transaction patterns and severe class imbalance.
Traditional methods rely on manual feature engineering and struggle to capture
temporal and structural dependencies in transaction networks. This paper
proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that
enhances detection performance through three modules: (1) designing an advanced
temporal embedding module that fuses multi-scale time difference features with
periodic position encoding; (2) constructing a temporal-aware triple attention
mechanism that jointly optimizes structural, temporal, and global context
attention; (3) employing weighted BCE loss to address class imbalance.
Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT
achieves an AUC of 0.9130, representing a 9.2% improvement over the best
traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This
method not only validates the enhancement effect of temporal awareness and
triple attention mechanisms on graph neural networks, but also provides
financial institutions with more reliable fraud detection tools, with its
design principles generalizable to other temporal graph anomaly detection
tasks.

</details>


### [50] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
*Colin Samplawski, Adam D. Cobb, Manoj Acharya, Ramneet Kaur, Susmit Jha*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的方法ScalaBL，通过在低维子空间中进行贝叶斯推理，解决了大型语言模型（LLMs）的不确定性量化问题。该方法仅需约1000个额外参数，即可与最先进的方法竞争，并扩展到迄今为止最大的贝叶斯LLM。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大语言模型被广泛应用，但它们可能会产生错误信息并且校准不佳。因此，在诸如自主性和医疗保健等高风险领域，这些模型的不确定性量化至关重要。先前的研究虽然通过在微调模型的低秩适应（LoRA）参数上进行推理，使基于贝叶斯深度学习的方法更具可行性，但当扩展到更大的LLM时仍面临挑战，因为相比LoRA需要更多的额外参数。

**方法:** 提出了ScalaBL方法，在r维子空间中进行贝叶斯推理，其中r为LoRA的秩。通过将LoRA参数重新用作投影矩阵，可以将子空间中的样本映射到LLM的完整权重空间。这使得我们能够使用随机变分推断来学习该方法的所有参数。

**结果:** 尽管子空间维度较低，但该方法能够以仅约1000个额外参数达到与最先进方法相当的性能。此外，它允许扩展到目前为止最大的贝叶斯LLM，其基本参数数量是之前工作的四倍。

**结论:** ScalaBL提供了一种有效的解决方案，用于扩展大型语言模型的不确定性量化，同时减少了所需的额外参数数量，使其适用于更大规模的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Bayesian+Low-Rank+Adaptation+of+Large+Language+Models+via+Stochastic+Variational+Subspace+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21408，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21408&send_immediately=true&force_search=false)

**原文摘要:** Despite their widespread use, large language models (LLMs) are known to
hallucinate incorrect information and be poorly calibrated. This makes the
uncertainty quantification of these models of critical importance, especially
in high-stakes domains, such as autonomy and healthcare. Prior work has made
Bayesian deep learning-based approaches to this problem more tractable by
performing inference over the low-rank adaptation (LoRA) parameters of a
fine-tuned model. While effective, these approaches struggle to scale to larger
LLMs due to requiring further additional parameters compared to LoRA. In this
work we present $\textbf{Scala}$ble $\textbf{B}$ayesian $\textbf{L}$ow-Rank
Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform
Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By
repurposing the LoRA parameters as projection matrices, we are able to map
samples from this subspace into the full weight space of the LLM. This allows
us to learn all the parameters of our approach using stochastic variational
inference. Despite the low dimensionality of our subspace, we are able to
achieve competitive performance with state-of-the-art approaches while only
requiring ${\sim}1000$ additional parameters. Furthermore, it allows us to
scale up to the largest Bayesian LLM to date, with four times as a many base
parameters as prior work.

</details>


### [51] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
*Tim Lawson, Laurence Aitchison*

**主要类别:** cs.LG

**AI概要:** 条件计算是一种提高Transformer效率的流行策略。现有方法通常针对个别模块或独立地跳过层。基于解释性研究，我们提出了一种新架构，动态跳过中间向外的可变层数。通过学习的门机制和门控注意力机制来决定是否跳过中心块，并控制残差范数和门稀疏度。尽管目标是减少简单令牌的计算需求并促进多级表示层次结构的出现，但在所研究的规模上，该方法在验证交叉熵和估计FLOPs之间的权衡上未能优于较少层数的密集基线。


<details>
  <summary>更多</summary>
  
**动机:** 现有的条件计算方法要么针对个别模块（如混合专家层），要么独立地跳过层。然而，解释性研究表明Transformer的中间层表现出更大的冗余，早期层将信息聚合到标记位置中。这促使我们设计一种能够动态跳过中间层的方法，以提高计算效率并探索潜在的多级表示层次结构。

**方法:** 提出了一种新的架构，通过学习的门机制根据输入动态跳过中间向外的可变层数。使用门控注意力机制防止后续标记关注被跳过的标记位置。通过'sandwich'或'perilayernorm'方案控制残差范数，并通过自适应正则化损失控制门稀疏度。

**结果:** 在所研究的规模上，该方法在验证交叉熵和估计FLOPs之间的权衡上没有比较少层数的密集基线模型表现得更好。

**结论:** 虽然提出的架构旨在减少简单令牌的计算需求并可能促进多级表示层次结构的出现，但目前在所研究的规模上，与较少层数的密集基线相比，未实现更好的性能权衡。代码已发布在https://github.com/tim-lawson/skip-middle。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Skip+the+Middle+Layers+of+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21103，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21103&send_immediately=true&force_search=false)

**原文摘要:** Conditional computation is a popular strategy to make Transformers more
efficient. Existing methods often target individual modules (e.g.,
mixture-of-experts layers) or skip layers independently of one another.
However, interpretability research has demonstrated that the middle layers of
Transformers exhibit greater redundancy, and that early layers aggregate
information into token positions. Guided by these insights, we propose a novel
architecture that dynamically skips a variable number of layers from the middle
outward. In particular, a learned gating mechanism determines whether to bypass
a symmetric span of central blocks based on the input, and a gated attention
mechanism prevents subsequent tokens from attending to skipped token positions.
Residual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and
gate sparsity with an adaptive regularization loss. We had aimed to reduce
compute requirements for 'simpler' tokens and potentially foster an emergent
multi-level representational hierarchy but, at the scales investigated, our
approach does not achieve improvements in the trade-off between validation
cross-entropy and estimated FLOPs compared to dense baselines with fewer
layers. We release our code at https://github.com/tim-lawson/skip-middle.

</details>


### [52] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
*Gavin Lee Goodship, Luis Miralles-Pechuan, Stephen O'Sullivan*

**主要类别:** cs.LG

**AI概要:** 开发了一种结合遗传算法和强化学习的方法来优化低存储的扩展稳定性龙格-库塔方法，显著提高计算效率并保持数值稳定性和准确性。


<details>
  <summary>更多</summary>
  
**动机:** 平衡精度、稳定性和计算效率对于高阶、低存储方案的扩展稳定性龙格-库塔方法具有挑战性，传统方法依赖手动设计的启发式规则或穷举数值搜索，难以实现系统参数减少和效率提升。

**方法:** 采用遗传算法驱动的变异进行搜索空间探索，并利用强化学习启发的状态转换机制动态改进启发式选择，从而优化低存储的扩展稳定性龙格-库塔方法。

**结果:** 在基准问题上的测试表明，该方法可以将IPOPT运行时间减少25%，同时保持数值稳定性和准确性。

**结论:** 该研究展示了自适应启发式发现改善高保真模拟资源效率的潜力，为使用深度强化学习和基于AutoML的启发式搜索进一步探索开辟了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimising+4th-Order+Runge-Kutta+Methods%3A+A+Dynamic+Heuristic+Approach+for+Efficiency+and+Low+Storage，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21465，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21465&send_immediately=true&force_search=false)

**原文摘要:** Extended Stability Runge-Kutta (ESRK) methods are crucial for solving
large-scale computational problems in science and engineering, including
weather forecasting, aerodynamic analysis, and complex biological modelling.
However, balancing accuracy, stability, and computational efficiency remains
challenging, particularly for high-order, low-storage schemes. This study
introduces a hybrid Genetic Algorithm (GA) and Reinforcement Learning (RL)
approach for automated heuristic discovery, optimising low-storage ESRK
methods. Unlike traditional approaches that rely on manually designed
heuristics or exhaustive numerical searches, our method leverages GA-driven
mutations for search-space exploration and an RL-inspired state transition
mechanism to refine heuristic selection dynamically. This enables systematic
parameter reduction, preserving fourth-order accuracy while significantly
improving computational efficiency.The proposed GA-RL heuristic optimisation
framework is validated through rigorous testing on benchmark problems,
including the 1D and 2D Brusselator systems and the steady-state Navier-Stokes
equations. The best-performing heuristic achieves a 25\% reduction in IPOPT
runtime compared to traditional ESRK optimisation processes while maintaining
numerical stability and accuracy. These findings demonstrate the potential of
adaptive heuristic discovery to improve resource efficiency in high-fidelity
simulations and broaden the applicability of low-storage Runge-Kutta methods in
real-world computational fluid dynamics, physics simulations, and other
demanding fields. This work establishes a new paradigm in heuristic
optimisation for numerical methods, opening pathways for further exploration
using Deep RL and AutoML-based heuristic search

</details>


### [53] [Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges](https://arxiv.org/abs/2506.21107)
*Changxi Chi, Jun Xia, Yufei Huang, Jingbo Zhou, Siyuan Li, Yunfan Liu, Chang Yu, Stan Z. Li*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于双重扩散隐式桥（DDIB）的框架，用于解决单细胞扰动数据未配对的问题。通过整合基因调控网络（GRN）信息和掩码机制，该方法增强了模型对扰动的理解，并提出了新的评估指标以反映单细胞响应中的固有异质性。


<details>
  <summary>更多</summary>
  
**动机:** 单细胞测序过程中，由于其破坏性特性，无法在同一细胞上捕获扰动前后的表型，导致收集到的数据在扰动和未扰动条件下本质上是未配对的。现有的方法要么尝试通过随机采样强行配对数据，要么忽视未扰动和扰动细胞之间的内在关系。

**方法:** 作者提出了一个基于双重扩散隐式桥（DDIB）的框架，学习不同数据分布之间的映射关系，解决了未配对数据的挑战。同时将此框架解释为一种数据增强形式，并结合基因调控网络（GRN）信息来传播扰动信号，还引入了掩码机制预测静默基因，提高了生成配置文件的质量。此外，针对相同扰动下基因表达的显著差异，提出了更适合的评估指标。

**结果:** 该方法克服了单细胞扰动数据未配对的问题，增强了模型对扰动的理解，并通过专门设计的掩码模型提高了生成质量。新提出的生物基础评估指标更好地反映了单细胞响应中的固有异质性。

**结论:** 提出的框架成功解决了单细胞扰动数据未配对的挑战，提升了实验效率，有助于识别关键基因和增强药物筛选。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unlasting%3A+Unpaired+Single-Cell+Multi-Perturbation+Estimation+by+Dual+Conditional+Diffusion+Implicit+Bridges，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21107，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21107&send_immediately=true&force_search=false)

**原文摘要:** Estimating single-cell responses across various perturbations facilitates the
identification of key genes and enhances drug screening, significantly boosting
experimental efficiency. However, single-cell sequencing is a destructive
process, making it impossible to capture the same cell's phenotype before and
after perturbation. Consequently, data collected under perturbed and
unperturbed conditions are inherently unpaired. Existing methods either attempt
to forcibly pair unpaired data using random sampling, or neglect the inherent
relationship between unperturbed and perturbed cells during the modeling. In
this work, we propose a framework based on Dual Diffusion Implicit Bridges
(DDIB) to learn the mapping between different data distributions, effectively
addressing the challenge of unpaired data. We further interpret this framework
as a form of data augmentation. We integrate gene regulatory network (GRN)
information to propagate perturbation signals in a biologically meaningful way,
and further incorporate a masking mechanism to predict silent genes, improving
the quality of generated profiles. Moreover, gene expression under the same
perturbation often varies significantly across cells, frequently exhibiting a
bimodal distribution that reflects intrinsic heterogeneity. To capture this, we
introduce a more suitable evaluation metric. We propose Unlasting, dual
conditional diffusion models that overcome the problem of unpaired single-cell
perturbation data and strengthen the model's insight into perturbations under
the guidance of the GRN, with a dedicated mask model designed to improve
generation quality by predicting silent genes. In addition, we introduce a
biologically grounded evaluation metric that better reflects the inherent
heterogeneity in single-cell responses.

</details>


### [54] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
*Francesco Vitale, Nicola Dall'Ora, Sebastiano Gaiardelli, Enrico Fraccaroli, Nicola Mazzocca, Franco Fummi*

**主要类别:** cs.LG

**AI概要:** 在 CPS 中实现故障诊断对于确保系统可靠性与运行效率至关重要。本文提出了一种新的非监督故障诊断方法，通过结合多变量时间序列分析、过程挖掘和随机模拟技术，实现了对异常行为的检测、建模和分类。实验结果表明该方法能够有效支持预测性维护和数字孪生技术的发展。


<details>
  <summary>更多</summary>
  
**动机:** 手动构建故障行为模型需要大量领域专业知识，并且生成的模型复杂、易出错且难以解释。因此，需要一种更自动化的方法来解决这一问题。

**方法:** 提出了一种新的非监督故障诊断方法，包括：1) 使用多变量时间序列分析从低层传感器数据中检测集体异常；2) 将这些异常转换为结构化事件日志，并通过过程挖掘发现可解释的过程模型；3) 将提取的 Petri 网与时间分布结合，支持故障行为的随机模拟。

**结果:** 通过 Robotic Arm Dataset (RoAD) 数据集验证了该方法的有效性，证明其可以成功用于故障行为的建模、模拟和分类。

**结论:** 所提出的方法为 CPS 的预测性维护和工业环境中的数字孪生技术提供了有力支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Process+mining-driven+modeling+and+simulation+to+enhance+fault+diagnosis+in+cyber-physical+systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21502，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21502&send_immediately=true&force_search=false)

**原文摘要:** Fault diagnosis in Cyber-Physical Systems (CPSs) is essential for ensuring
system dependability and operational efficiency by accurately detecting
anomalies and identifying their root causes. However, the manual modeling of
faulty behaviors often demands extensive domain expertise and produces models
that are complex, error-prone, and difficult to interpret. To address this
challenge, we present a novel unsupervised fault diagnosis methodology that
integrates collective anomaly detection in multivariate time series, process
mining, and stochastic simulation. Initially, collective anomalies are detected
from low-level sensor data using multivariate time-series analysis. These
anomalies are then transformed into structured event logs, enabling the
discovery of interpretable process models through process mining. By
incorporating timing distributions into the extracted Petri nets, the approach
supports stochastic simulation of faulty behaviors, thereby enhancing root
cause analysis and behavioral understanding. The methodology is validated using
the Robotic Arm Dataset (RoAD), a widely recognized benchmark in smart
manufacturing. Experimental results demonstrate its effectiveness in modeling,
simulating, and classifying faulty behaviors in CPSs. This enables the creation
of comprehensive fault dictionaries that support predictive maintenance and the
development of digital twins for industrial environments.

</details>


### [55] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
*Xiaona Zhou, Constantin Brif, Ismini Lourentzou*

**主要类别:** cs.LG

**AI概要:** 多变量时间序列异常检测（MTS-AD）在医疗、网络安全和工业监控等领域至关重要，但由于变量间依赖复杂、时间动态性和稀疏的异常标签而充满挑战。本文介绍了mTSBench，这是目前最大的MTS-AD基准测试，涵盖了19个数据集和12个不同应用领域的344个标记时间序列。mTSBench评估了24种异常检测方法，并系统地对无监督模型选择技术进行了基准测试。结果表明，没有任何单一检测器能够在所有数据集上表现出色，突显了模型选择的重要性。然而，即使是最先进的选择方法也远非最佳，揭示了关键差距。mTSBench提供了一个统一的评估套件，以实现严谨、可重复的比较，并推动未来自适应异常检测和稳健模型选择的发展。


<details>
  <summary>更多</summary>
  
**动机:** 多变量时间序列异常检测在许多领域具有重要意义，但面临复杂的变量依赖关系、时间动态特性和稀疏异常标签等挑战，因此需要一个全面的基准测试来评估现有的检测方法和模型选择技术。

**方法:** 构建了mTSBench，这是一个包含344个标记时间序列、19个数据集和12个应用领域的基准测试平台。通过该平台，评估了24种异常检测方法（包括基于大型语言模型的方法），并系统地对无监督模型选择技术进行了基准测试。

**结果:** 实验结果表明，没有一种检测器能够适用于所有数据集，强调了模型选择的重要性。同时，最先进的模型选择方法仍然存在显著不足，显示出改进的空间。

**结论:** mTSBench为多变量时间序列异常检测提供了统一的评估框架，有助于推动自适应异常检测和稳健模型选择的研究进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是mTSBench%3A+Benchmarking+Multivariate+Time+Series+Anomaly+Detection+and+Model+Selection+at+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21550，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21550&send_immediately=true&force_search=false)

**原文摘要:** Multivariate time series anomaly detection (MTS-AD) is critical in domains
like healthcare, cybersecurity, and industrial monitoring, yet remains
challenging due to complex inter-variable dependencies, temporal dynamics, and
sparse anomaly labels. We introduce mTSBench, the largest benchmark to date for
MTS-AD and unsupervised model selection, spanning 344 labeled time series
across 19 datasets and 12 diverse application domains. mTSBench evaluates 24
anomaly detection methods, including large language model (LLM)-based detectors
for multivariate time series, and systematically benchmarks unsupervised model
selection techniques under standardized conditions. Consistent with prior
findings, our results confirm that no single detector excels across datasets,
underscoring the importance of model selection. However, even state-of-the-art
selection methods remain far from optimal, revealing critical gaps. mTSBench
provides a unified evaluation suite to enable rigorous, reproducible
comparisons and catalyze future advances in adaptive anomaly detection and
robust model selection.

</details>


### [56] [NaLaFormer: Norm-Aware Linear Attention for Transformer Models](https://arxiv.org/abs/2506.21137)
*Weikang Meng, Yadan Luo, Liangyu Huo, Yaowei Wang, Xin Li, Zheng Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的Norm-Aware Linear Attention机制，通过分解query和key矩阵的范数和方向，控制范数感知的尖锐度并恢复核扰动的范数分布，从而解决了线性注意力中的熵差距和内积交互丢失问题。实验表明NaLaFormer在视觉和语言任务上提高了性能，表达能力和效率提升了4.2%。


<details>
  <summary>更多</summary>
  
**动机:** 当前线性注意力机制存在两个主要问题：1) 忽略了query范数导致熵差距；2) 抑制负值导致内积交互丢失。为了解决这两个挑战，需要一种新的机制来恢复范数引导的动态尖锐度和核扰动的范数分布。

**方法:** 首先将query和key矩阵分解为范数和方向两个部分，分别实现范数感知的尖锐度控制和范数一致性。接着设计了一个与query范数相关的核函数，用于动态控制熵减少的程度。为了确保范数一致性和非负约束，使用一个保持范数的映射方法，将角度矩阵的所有元素投影到正值，并利用余弦相似性抑制相反方向的维度。

**结果:** 广泛的实验结果表明，提出的NaLaFormer模型在视觉和语言任务上表现出色，显著提升了模型的表达能力和效率，最高可达4.2%。

**结论:** 本文提出的Norm-Aware Linear Attention机制有效地解决了线性注意力中熵差距和内积交互丢失的问题，增强了模型的表达能力及效率，为未来的研究提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NaLaFormer%3A+Norm-Aware+Linear+Attention+for+Transformer+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21137，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21137&send_immediately=true&force_search=false)

**原文摘要:** Linear attention has emerged as a viable alternative to softmax attention by
reducing complexity from quadratic to linear in sequence length. To preserve
two fundamental properties of softmax, non-negativity and entropy reduction,
current works employ various linearly separatable kernel functions with $L1$
normalization instead of softmax operator. However, query norms are neglected
by the normalization operation in linear attention, such degradation heavily
leads to an entropy gap. Meanwhile, existing works inhibit negative values of
query and key vectors resulting in a missing inner-product interactions after
being mapped. To address these dual challenges, we propose a novel Norm-Aware
Linear Attention mechanism serving to restore norm-guided dynamic spikiness and
recover kernel-perturbed norm distributions. Specifically, we first decouple
query and key matrices into two components: norm and direction, to achieve
norm-aware spikiness control and norm consistency, respectively. We
mathematically reveal that the extent of entropy reduction varies with the
query norm in softmax normalization, motivating a query-norm aware kernel
function for dynamic control over entropy reduction. Furthermore, to ensure
norm consistency and enforce non-negativity constraints, we employ a
norm-preserving mapping to project all elements of the angular matrix into
positive values, leveraging cosine similarity to inhibit dimensions with
opposite directions. We conduct extensive experiments demonstrating that the
NaLaFormer improves performance on vision and language tasks, enhancing both
expressiveness and efficiency by up to 4.2\%.

</details>


### [57] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
*Deepak Kumar Panda, Weisi Guo*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种基于条件生成对抗网络（cGAN）的框架，用于生成可规避入侵检测系统的隐秘对抗攻击，并采用条件变分自编码器（CVAE）来区分真实OOD事件与对抗样本。结果表明，CVAE方法在检测隐秘对抗威胁方面显著优于传统方法，强调了增强入侵检测系统能力的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 随着无人机在民用空域的集成增加，传统的异常检测方法无法有效识别新型威胁，尤其是在处理隐秘对抗攻击时表现不足，这促使需要更智能和弹性的入侵检测系统（IDS）。

**方法:** 1. 设计了一个强大的多类IDS分类器，使用良性无人机遥测数据和已知网络攻击（如DoS、FDI、MiTM和重放攻击）进行训练。
2. 利用cGAN扰动已知攻击以生成被误分类为良性的对抗样本，这些样本保留了统计上与OOD分布相似的特性。
3. 通过迭代优化提高对抗样本的隐秘性和成功率。
4. 使用CVAE结合负对数似然来区分对抗输入和真实的OOD样本。

**结果:** 实验比较表明，基于CVAE的遗憾分数在识别隐秘对抗威胁方面明显优于传统的基于马氏距离的检测器。

**结论:** 研究结果突显了高级概率建模对于增强入侵检测系统抵御适应性、基于生成模型的网络入侵的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generative+Adversarial+Evasion+and+Out-of-Distribution+Detection+for+UAV+Cyber-Attacks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21142，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21142&send_immediately=true&force_search=false)

**原文摘要:** The growing integration of UAVs into civilian airspace underscores the need
for resilient and intelligent intrusion detection systems (IDS), as traditional
anomaly detection methods often fail to identify novel threats. A common
approach treats unfamiliar attacks as out-of-distribution (OOD) samples;
however, this leaves systems vulnerable when mitigation is inadequate.
Moreover, conventional OOD detectors struggle to distinguish stealthy
adversarial attacks from genuine OOD events. This paper introduces a
conditional generative adversarial network (cGAN)-based framework for crafting
stealthy adversarial attacks that evade IDS mechanisms. We first design a
robust multi-class IDS classifier trained on benign UAV telemetry and known
cyber-attacks, including Denial of Service (DoS), false data injection (FDI),
man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN
perturbs known attacks to generate adversarial samples that misclassify as
benign while retaining statistical resemblance to OOD distributions. These
adversarial samples are iteratively refined to achieve high stealth and success
rates. To detect such perturbations, we implement a conditional variational
autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial
inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based
regret scores significantly outperform traditional Mahalanobis distance-based
detectors in identifying stealthy adversarial threats. Our findings emphasize
the importance of advanced probabilistic modeling to strengthen IDS
capabilities against adaptive, generative-model-based cyber intrusions.

</details>


### [58] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
*Yuguang Zhang, Kuangpu Guo, Zhihe Lu, Yunbo Wang, Jian Liang*

**主要类别:** cs.LG

**AI概要:** pFedDC是一个基于双提示学习和交叉融合的个性化联邦学习框架，通过全局和局部提示结合跨模态知识，在多种异构数据集上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦提示学习方法仅依赖文本提示，忽视了联合标签域分布偏移的问题，因此需要一种能够适应异构数据、计算和通信挑战的新方法。

**方法:** 提出了一种名为pFedDC的个性化FL框架，该框架利用双提示学习和交叉融合模块。具体来说，每个客户端维护视觉和语言模态的全局和局部提示，其中全局提示捕捉联邦中的共有知识，局部提示编码客户端特定的语义和领域特征。交叉融合模块自适应地整合不同层次的提示，使模型生成与每个客户端独特数据分布对齐的个性化表示。

**结果:** 在九个具有各种异质性的数据集上的广泛实验表明，pFedDC持续优于最先进的方法。

**结论:** pFedDC通过结合全局和局部提示以及跨模态知识，有效解决了联邦学习中的异构性问题，并在性能上显著优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Personalized+Federated+Learning+via+Dual-Prompt+Optimization+and+Cross+Fusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21144，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21144&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, but is challenged by
heterogeneity in data, computation, and communication. Pretrained
vision-language models (VLMs), with their strong generalization and lightweight
tuning via prompts, offer a promising solution. However, existing federated
prompt-learning methods rely only on text prompts and overlook joint
label-domain distribution shifts. In this paper, we propose a personalized FL
framework based on dual-prompt learning and cross fusion, termed pFedDC.
Specifically, each client maintains both global and local prompts across vision
and language modalities: global prompts capture common knowledge shared across
the federation, while local prompts encode client-specific semantics and domain
characteristics. Meanwhile, a cross-fusion module is designed to adaptively
integrate prompts from different levels, enabling the model to generate
personalized representations aligned with each client's unique data
distribution. Extensive experiments across nine datasets with various types of
heterogeneity show that pFedDC consistently outperforms state-of-the-art
methods.

</details>


### [59] [Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design](https://arxiv.org/abs/2506.21158)
*Hampus Gummesson Svensson, Ola Engkvist, Jon Paul Janet, Christian Tyrchan, Morteza Haghir Chehreghani*

**主要类别:** cs.LG

**AI概要:** 在强化学习中引入了使用行列式点过程的多样化小批量选择方法，通过实验验证其在新药设计中的有效性，可以提高解的多样性而不牺牲质量。


<details>
  <summary>更多</summary>
  
**动机:** 在许多实际应用中，评估实例的好坏往往代价高昂且耗时，例如人工反馈和物理模拟。在强化学习中，与环境的新交互需要被评估以提供奖励信号进行学习。充分探索对于学习至关重要，因此从多样化的小批量中学习可以帮助缓解模式崩溃问题。

**方法:** 提出了一种基于行列式点过程（determinantal point processes）的多样化小批量选择框架，并将其应用于强化学习中。该方法在药物发现的实际问题上进行了研究，特别是在de novo药物设计中，旨在提高化学探索的有效性。

**结果:** 实验结果表明，所提出的多样化小批量选择框架可以在保持解的质量的同时，显著提高解的多样性。这对于药物发现领域可能意味着更快地满足未被满足的医疗需求。

**结论:** 多样化小批量选择框架在强化学习中的应用可以有效提升解的多样性，并在药物设计任务中展现出了实质性的改进效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diverse+Mini-Batch+Selection+in+Reinforcement+Learning+for+Efficient+Chemical+Exploration+in+de+novo+Drug+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21158，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21158&send_immediately=true&force_search=false)

**原文摘要:** In many real-world applications, evaluating the goodness of instances is
often costly and time-consuming, e.g., human feedback and physics simulations,
in contrast to proposing new instances. In particular, this is even more
critical in reinforcement learning, as new interactions with the environment
(i.e., new instances) need to be evaluated to provide a reward signal to learn
from. As sufficient exploration is crucial, learning from a diverse mini-batch
can have a large impact and help mitigate mode collapse. In this paper, we
introduce diverse mini-batch selection for reinforcement learning and propose
to use determinantal point processes for this task. We study this framework in
the context of a real-world problem, namely drug discovery. We experimentally
study how our proposed framework can improve the effectiveness of chemical
exploration in de novo drug design, where finding diverse and high-quality
solutions is essential. We conduct a comprehensive evaluation with three
well-established molecular generation oracles over numerous generative steps.
Our experiments conclude that our diverse mini-batch selection framework can
substantially improve the diversity of the solutions, while still obtaining
solutions of high quality. In drug discovery, such outcome can potentially lead
to fulfilling unmet medication needs faster.

</details>


### [60] [Artificial Delegates Resolve Fairness Issues in Perpetual Voting with Partial Turnout](https://arxiv.org/abs/2506.21186)
*Apurva Shah, Axel Abels, Ann Nowé, Tom Lenaerts*

**主要类别:** cs.LG

**AI概要:** 在永久投票系统中，缺席投票者对公平性有显著影响。本文研究了将人工代表（Artificial Delegates）整合到该系统中的效果。这些代表是经过训练的偏好学习代理，用于代表缺席的投票者。结果表明，人工代表能有效缓解缺席主义带来的公平性问题，并提高系统的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的永久投票规则依赖于完全参与和完整的批准信息，但在实际情况中，部分投票率才是常态。因此，需要解决缺席投票对公平性和代表性的影响。

**方法:** 研究分析了不同投票方法下的缺席主义如何影响公平性和代表性，并评估了人工代表在多大程度上可以弥补缺失的参与。

**结果:** 研究发现缺席主义显著影响公平性，而人工代表能够可靠地减轻这些影响，并在各种场景下增强系统的鲁棒性。

**结论:** 人工代表有效地缓解了永久投票系统中因缺席投票导致的公平性问题，提高了系统的整体表现和适应性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Artificial+Delegates+Resolve+Fairness+Issues+in+Perpetual+Voting+with+Partial+Turnout，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21186&send_immediately=true&force_search=false)

**原文摘要:** Perpetual voting addresses fairness in sequential collective decision-making
by evaluating representational equity over time. However, existing perpetual
voting rules rely on full participation and complete approval information,
assumptions that rarely hold in practice, where partial turnout is the norm. In
this work, we study the integration of Artificial Delegates,
preference-learning agents trained to represent absent voters, into perpetual
voting systems. We examine how absenteeism affects fairness and
representativeness under various voting methods and evaluate the extent to
which Artificial Delegates can compensate for missing participation. Our
findings indicate that while absenteeism significantly affects fairness,
Artificial Delegates reliably mitigate these effects and enhance robustness
across diverse scenarios.

</details>


### [61] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
*Andrey Goncharov, Daniil Vyazhev, Petr Sychev, Edvard Khalafyan, Alexey Zaytsev*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种高效微调大型语言模型（LLMs）的新方法，通过熵来识别复杂数据并仅对其使用推理。在两个小型开源模型上实验表明，该方法比标准的监督微调（SFT）表现更好，并且在使用62%更少的数据的情况下，性能与蒸馏方法相当。


<details>
  <summary>更多</summary>
  
**动机:** 通用大型语言模型（LLMs）通常通过监督微调（SFT）来提升特定领域的性能。然而，通过蒸馏更大模型的思维链虽然可以取得更好的结果，但成本高且需要大量的数据。因此，需要一种更高效的微调方法。

**方法:** 提出了一种新的微调蓝图，利用熵来识别复杂数据并仅对这些数据进行推理。具体来说，将训练数据根据单个标记答案熵分为不同的复杂度类别，并通过SFT和蒸馏来微调LLMs。

**结果:** 实验表明，在两个小型开源模型上，所提出的管道显著优于标准的SFT方法（平均准确率0.55 vs 0.43），并且在使用62%更少的数据的情况下，提供了与蒸馏方法相当的性能（两者平均准确率均为0.55）。

**结论:** 作者提出了一个有效的微调方法，可以减少数据需求同时达到与蒸馏方法相媲美的效果，并公开了代码和数据以促进进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Complexity-aware+fine-tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21220，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21220&send_immediately=true&force_search=false)

**原文摘要:** General-purpose Large Language Models (LLMs) are frequently fine-tuned
through supervised fine-tuning (SFT) to enhance performance in specific
domains. Better results can be achieved by distilling the chain-of-thought of a
larger model at the cost of numerous expensive calls and a much greater amount
of data. We propose a novel blueprint for efficient fine-tuning that uses
reasoning only for complex data identified by entropy. Specifically, across two
small open models ($\approx 3B$) we split the training data into complexity
categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large
language models (LLMs) via SFT and distillation, and show that our pipeline
significantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average
accuracy) and provides comparable with distillation performance while using
$62\%$ less data ($0.55$ average accuracy for both). We publish our code and
data to facilitate further research in this direction.

</details>


### [62] [Zero-Shot Learning for Obsolescence Risk Forecasting](https://arxiv.org/abs/2506.21240)
*Elie Saad, Aya Mrabah, Mariem Besbes, Marc Zolghadri, Victor Czmil, Claude Baron, Vincent Bourgeois*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种利用零样本学习和大语言模型预测电子组件过时风险的新方法，通过实际数据验证了其有效性，并强调了为特定任务选择合适模型的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 电子元件的过时给依赖电子元件的行业带来了显著挑战，包括成本增加以及系统安全性和可用性的中断。然而，由于缺乏可靠的数据，准确预测过时风险变得困难。

**方法:** 本研究提出了一种新的方法，使用零样本学习（ZSL）与大语言模型（LLMs），通过利用表格数据集中的领域特定知识来解决数据限制问题，从而预测过时风险。

**结果:** 该方法在两个真实世界数据集上的应用表明，其能够有效地进行风险预测。同时，对四种大语言模型的比较评估显示，为特定预测任务选择合适的模型至关重要。

**结论:** 利用零样本学习和大语言模型可以有效应对电子组件过时预测中的数据不足问题，而模型选择对于预测性能具有重要影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zero-Shot+Learning+for+Obsolescence+Risk+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21240，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21240&send_immediately=true&force_search=false)

**原文摘要:** Component obsolescence poses significant challenges in industries reliant on
electronic components, causing increased costs and disruptions in the security
and availability of systems. Accurate obsolescence risk prediction is essential
but hindered by a lack of reliable data. This paper proposes a novel approach
to forecasting obsolescence risk using zero-shot learning (ZSL) with large
language models (LLMs) to address data limitations by leveraging
domain-specific knowledge from tabular datasets. Applied to two real-world
datasets, the method demonstrates effective risk prediction. A comparative
evaluation of four LLMs underscores the importance of selecting the right model
for specific forecasting tasks.

</details>


### [63] [Improved seeding strategies for k-means and k-GMM](https://arxiv.org/abs/2506.21291)
*Guillaume Carrière, Frédéric Cazals*

**主要类别:** cs.LG

**AI概要:** 本论文重新审视了k均值聚类和k-GMM的随机化种子技术，提出了基于前瞻原则和多遍策略的新初始化方法家族，这些方法在最终度量（k-means的SSE或k-GMM的对数似然）上表现出一致的常数因子改进。实验还揭示了k-means的一些微妙特性，并表明所提出的方法可能是新的标准技术。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有许多关于k-means和k-GMM初始化的研究，但随机化种子技术仍有改进空间。作者希望通过对种子采样度量、候选种子数量以及种子选择度量进行形式化分析，探索更优的初始化方法。

**方法:** 作者引入了一个前瞻原则，即在种子选择过程中考虑与最终评估算法的一致性；同时采用多遍策略以降低随机化的影响。通过这种形式化分析，提出了新的初始化方法家族。

**结果:** 实验结果表明，新方法在最终度量上比传统方法有显著的常数因子提升（k-means的SSE或k-GMM的对数似然），并且计算开销较低。此外，实验还揭示了k-means的一些细微特性，如种子阶段与最终SSE的相关性不足、迭代种子方法中的方差减少现象等。

**结论:** 所提出的初始化方法具有成为新标准技术的潜力，而对种子技术的形式化也为进一步的理论研究打开了大门。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improved+seeding+strategies+for+k-means+and+k-GMM，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21291，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21291&send_immediately=true&force_search=false)

**原文摘要:** We revisit the randomized seeding techniques for k-means clustering and k-GMM
(Gaussian Mixture model fitting with Expectation-Maximization), formalizing
their three key ingredients: the metric used for seed sampling, the number of
candidate seeds, and the metric used for seed selection. This analysis yields
novel families of initialization methods exploiting a lookahead
principle--conditioning the seed selection to an enhanced coherence with the
final metric used to assess the algorithm, and a multipass strategy to tame
down the effect of randomization.
  Experiments show a consistent constant factor improvement over classical
contenders in terms of the final metric (SSE for k-means, log-likelihood for
k-GMM), at a modest overhead. In particular, for k-means, our methods improve
on the recently designed multi-swap strategy, which was the first one to
outperform the greedy k-means++ seeding.
  Our experimental analysis also shed light on subtle properties of k-means
often overlooked, including the (lack of) correlations between the SSE upon
seeding and the final SSE, the variance reduction phenomena observed in
iterative seeding methods, and the sensitivity of the final SSE to the pool
size for greedy methods.
  Practically, our most effective seeding methods are strong candidates to
become one of the--if not the--standard techniques. From a theoretical
perspective, our formalization of seeding opens the door to a new line of
analytical approaches.

</details>


### [64] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
*Jiajie Yang*

**主要类别:** cs.LG

**AI概要:** Mixture-of-Experts (MoE)架构在大型语言模型中很重要，但存在负载不均衡问题。本文提出了一种新的路由框架Latent Prototype Routing (LPR)，能有效改善专家利用率，并且不会影响下游性能。实验表明LPR大幅降低了专家负载的基尼系数并提高了最小最大专家负载比，接近完美的负载均衡。


<details>
  <summary>更多</summary>
  
**动机:** 当前的MoE系统在训练和推理过程中只有少量专家被激活，导致模型容量和计算资源的严重浪费，因此需要一种方法来促进更平衡的专家利用。

**方法:** 从聚类的角度重新审视专家路由，并提出了潜在原型路由（LPR）的新框架，该框架在推广现有方法的同时，促进了平衡的专家利用。

**结果:** LPR将专家负载的基尼系数从0.70降低到0.035，最小最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。

**结论:** LPR是一种有效的路由框架，能够在不损害下游性能的情况下，显著改善MoE模型中的负载均衡问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Latent+Prototype+Routing%3A+Achieving+Near-Perfect+Load+Balancing+in+Mixture-of-Experts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21328，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21328&send_immediately=true&force_search=false)

**原文摘要:** Mixture-of-Experts (MoE) architectures have emerged as a key strategy for
scaling large language models (LLMs) efficiently. However, current MoE systems
suffer from severe load imbalance, where only a small subset of experts is
consistently activated during training and inference, leading to significant
underutilization of model capacity and computational resources. In this work,
we revisit expert routing through a clustering perspective and propose Latent
Prototype Routing (LPR), a novel routing framework that generalizes existing
approaches while promoting balanced expert utilization without compromising
downstream performance. Extensive experiments across multiple open-source MoE
models -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR
reduces the Gini coefficient of expert load from 0.70 to 0.035 on average,
improves the min-max expert load ratio from 1e-6 to 0.70, achieving
near-perfect load balancing.

</details>


### [65] [AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification](https://arxiv.org/abs/2506.21338)
*Galvin Brice S. Lim, Brian Godwin S. Lim, Argel A. Bandala, John Anthony C. Jose, Timothy Scott C. Chu, Edwin Sybingco*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种新的图时间卷积网络（AGTCNet），用于改进脑机接口中的运动想象 EEG 信号分类。该模型在减少模型大小和推理时间的同时，显著提高了分类准确率，展现了其在跨个体和特定个体任务中的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的 BCI 系统无法有效捕捉多通道 EEG 信号中的复杂时空依赖性，限制了系统的鲁棒性和泛化能力。因此需要一种新方法来解决这一问题。

**方法:** 提出了 AGTCNet，利用 EEG 电极的地形配置作为归纳偏置，并结合图卷积注意力网络（GCAT）学习表达性强的时空 EEG 表示。

**结果:** 在多个数据集上，AGTCNet 显著优于现有分类器，实现了更高的分类准确率、更小的模型规模和更快的推理速度。例如，在 BCI Competition IV Dataset 2a 上，跨个体分类准确率为 66.82%，特定个体分类准确率为 82.88%。

**结论:** AGTCNet 是一种紧凑且高效的模型，能够显著改善 MI-EEG 分类性能，为实际 BCI 部署提供了实用解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AGTCNet%3A+A+Graph-Temporal+Approach+for+Principled+Motor+Imagery+EEG+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21338，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21338&send_immediately=true&force_search=false)

**原文摘要:** Brain-computer interface (BCI) technology utilizing electroencephalography
(EEG) marks a transformative innovation, empowering motor-impaired individuals
to engage with their environment on equal footing. Despite its promising
potential, developing subject-invariant and session-invariant BCI systems
remains a significant challenge due to the inherent complexity and variability
of neural activity across individuals and over time, compounded by EEG hardware
constraints. While prior studies have sought to develop robust BCI systems,
existing approaches remain ineffective in capturing the intricate
spatiotemporal dependencies within multichannel EEG signals. This study
addresses this gap by introducing the attentive graph-temporal convolutional
network (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG)
classification. Specifically, AGTCNet leverages the topographic configuration
of EEG electrodes as an inductive bias and integrates graph convolutional
attention network (GCAT) to jointly learn expressive spatiotemporal EEG
representations. The proposed model significantly outperformed existing MI-EEG
classifiers, achieving state-of-the-art performance while utilizing a compact
architecture, underscoring its effectiveness and practicality for BCI
deployment. With a 49.87% reduction in model size, 64.65% faster inference
time, and shorter input EEG signal, AGTCNet achieved a moving average accuracy
of 66.82% for subject-independent classification on the BCI Competition IV
Dataset 2a, which further improved to 82.88% when fine-tuned for
subject-specific classification. On the EEG Motor Movement/Imagery Dataset,
AGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and
2-class subject-independent classifications, respectively, with further
improvements to 72.13% and 90.54% for subject-specific classifications.

</details>


### [66] [DynamicBench: Evaluating Real-Time Report Generation in Large Language Models](https://arxiv.org/abs/2506.21343)
*Jingyao Li, Hao Sun, Zile Qiao, Yong Jiang, Pengjun Xie, Fei Huang, Hong Xu, Jiaya Jia*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种名为DynamicBench的新基准测试方法，用于评估大型语言模型（LLMs）在实时信息处理方面的能力。它通过结合网络搜索和本地报告数据库的双路径检索管道，来衡量模型在有无外部文档辅助下对最新信息的独立处理能力或利用上下文增强的能力。实验结果表明，该方法在无文档和有文档辅助场景下的表现分别超越了GPT4o 7.0%和5.8%，并且代码和数据将公开发布。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LLM基准测试主要依赖静态评估，例如讲故事或表达观点，无法反映现代应用中实时信息处理的动态需求。为了弥补这一不足，需要一种新的评估方式来更好地捕捉LLM在实时数据存储与处理上的性能。

**方法:** DynamicBench采用双路径检索管道，结合网络搜索和本地报告数据库，并要求领域特定知识以生成准确的响应报告。此外，还引入了一个先进的报告生成系统，擅长动态信息合成。通过在提供或不提供外部文档的不同场景中进行评估，可以有效测量模型独立处理最新信息或利用上下文增强的能力。

**结果:** 实验结果验证了DynamicBench的有效性，其方法在无文档和有文档辅助的场景下分别超过了GPT4o 7.0%和5.8%。

**结论:** DynamicBench为评估LLM在实时信息处理方面的表现提供了更全面的方法，其效果已得到验证并展现了优越性。代码和数据将被公开，有助于进一步的研究和发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DynamicBench%3A+Evaluating+Real-Time+Report+Generation+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21343，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21343&send_immediately=true&force_search=false)

**原文摘要:** Traditional benchmarks for large language models (LLMs) typically rely on
static evaluations through storytelling or opinion expression, which fail to
capture the dynamic requirements of real-time information processing in
contemporary applications. To address this limitation, we present DynamicBench,
a benchmark designed to evaluate the proficiency of LLMs in storing and
processing up-to-the-minute data. DynamicBench utilizes a dual-path retrieval
pipeline, integrating web searches with local report databases. It necessitates
domain-specific knowledge, ensuring accurate responses report generation within
specialized fields. By evaluating models in scenarios that either provide or
withhold external documents, DynamicBench effectively measures their capability
to independently process recent information or leverage contextual
enhancements. Additionally, we introduce an advanced report generation system
adept at managing dynamic information synthesis. Our experimental results
confirm the efficacy of our approach, with our method achieving
state-of-the-art performance, surpassing GPT4o in document-free and
document-assisted scenarios by 7.0% and 5.8%, respectively. The code and data
will be made publicly available.

</details>


### [67] [Lipschitz Bounds for Persistent Laplacian Eigenvalues under One-Simplex Insertions](https://arxiv.org/abs/2506.21352)
*Le Vu Anh, Mehmet Dik, Nguyen Viet Anh*

**主要类别:** cs.LG

**AI概要:** 持久拉普拉斯算子在生物、物理和机器学习领域中被广泛使用，用于跟踪数据形状和结构随尺度的变化。本文通过证明一个一致的Lipschitz界，填补了单个特征值变化研究的空白，提供了谱拓扑数据分析在局部更新下的稳定性保证。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前的工作已经建立了这些算子的整体代数稳定性，但当添加一个单纯形（如顶点、边或三角形）时，单一特征值的确切变化仍然未知。这一问题很重要，因为下游工具（如热核签名和谱神经网络）直接依赖于这些特征值。

**方法:** 作者通过证明一个一致的Lipschitz界来解决这一问题：在插入一个单纯形后，每个上持续拉普拉斯特征值最多可以变化为该单纯形边界欧几里得范数的两倍，这与过滤尺度和复杂大小无关。

**结果:** 这一结果提供了谱拓扑数据分析在特征值层面的第一个鲁棒性保证，确保了谱特征在局部更新下保持稳定，并在动态数据设置中实现可靠的误差控制。

**结论:** 本文的研究结果提供了一个新的理论基础，保证了谱特征在局部更新下的稳定性，这对于涉及动态数据的应用具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Lipschitz+Bounds+for+Persistent+Laplacian+Eigenvalues+under+One-Simplex+Insertions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21352，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21352&send_immediately=true&force_search=false)

**原文摘要:** Persistent Laplacians are matrix operators that track how the shape and
structure of data transform across scales and are popularly adopted in biology,
physics, and machine learning. Their eigenvalues are concise descriptors of
geometric and topological features in a filtration. Although earlier work
established global algebraic stability for these operators, the precise change
in a single eigenvalue when one simplex, such as a vertex, edge, or triangle,
is added has remained unknown. This is important because downstream tools,
including heat-kernel signatures and spectral neural networks, depend directly
on these eigenvalues. We close this gap by proving a uniform Lipschitz bound:
after inserting one simplex, every up-persistent Laplacian eigenvalue can vary
by at most twice the Euclidean norm of that simplex's boundary, independent of
filtration scale and complex size. This result delivers the first
eigenvalue-level robustness guarantee for spectral topological data analysis.
It guarantees that spectral features remain stable under local updates and
enables reliable error control in dynamic data settings.

</details>


### [68] [SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning](https://arxiv.org/abs/2506.21355)
*Melanie Rieff, Maya Varma, Ossian Rabow, Subathra Adithan, Julie Kim, Ken Chang, Hannah Lee, Nidhi Rohatgi, Christian Bluethgen, Mohamed S. Muneer, Jean-Benoit Delbrouck, Michael Moor*

**主要类别:** cs.LG

**AI概要:** 尽管多模态在上下文学习（ICL）在医学等领域具有巨大潜力，但研究仍不足。本文介绍了SMMILE，首个针对医学任务的专家驱动的多模态ICL基准，涵盖6个医学专科和13种成像模式。通过对15个多模态大语言模型（MLLMs）的全面评估，发现大多数模型在医学任务中的多模态ICL能力有限。无关的上下文示例和示例顺序显著影响性能，强调了当前MLLMs在从上下文中学习多模态医学任务时的关键限制和偏差。


<details>
  <summary>更多</summary>
  
**动机:** 医学领域中，临床医生经常需要从少量例子中适应多样且专业化的任务，这为多模态在上下文学习（ICL）提供了广阔的应用前景。然而，多模态大语言模型（MLLMs）在医学任务中的ICL能力尚未得到充分探索。

**方法:** 研究人员创建了SMMILE，一个由医学专家策划的多模态ICL基准，包含111个问题（517个问题-图像-答案三元组），覆盖6个医学专科和13种成像模式。此外，还引入了增强版本SMMILE++，包含1038个排列组合的问题。通过该基准对15个MLLMs进行了全面评估。

**结果:** 评估结果显示，大多数MLLMs在医学任务中的多模态ICL能力较为有限。在开放性评估中，ICL相较于零样本仅带来了8%（SMMILE）和9.4%（SMMILE++）的平均改进。此外，无关的上下文示例可能显著降低性能，而示例顺序表现出最近邻效应，将最相关的示例放在最后可提升性能多达71%。

**结论:** 当前的MLLMs在从上下文中学习多模态医学任务时存在关键限制和偏差，特别是在处理无关示例和示例顺序方面。这些发现强调了改进模型设计和训练策略以提高其在医学领域的ICL能力的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMMILE%3A+An+Expert-Driven+Benchmark+for+Multimodal+Medical+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21355&send_immediately=true&force_search=false)

**原文摘要:** Multimodal in-context learning (ICL) remains underexplored despite
significant potential for domains such as medicine. Clinicians routinely
encounter diverse, specialized tasks requiring adaptation from limited
examples, such as drawing insights from a few relevant prior cases or
considering a constrained set of differential diagnoses. While multimodal large
language models (MLLMs) have shown advances in medical visual question
answering (VQA), their ability to learn multimodal tasks from context is
largely unknown. We introduce SMMILE, the first expert-driven multimodal ICL
benchmark for medical tasks. Eleven medical experts curated problems, each
including a multimodal query and multimodal in-context examples as task
demonstrations. SMMILE encompasses 111 problems (517 question-image-answer
triplets) covering 6 medical specialties and 13 imaging modalities. We further
introduce SMMILE++, an augmented variant with 1038 permuted problems. A
comprehensive evaluation of 15 MLLMs demonstrates that most models exhibit
moderate to poor multimodal ICL ability in medical tasks. In open-ended
evaluations, ICL contributes only 8% average improvement over zero-shot on
SMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant
in-context examples: even a single noisy or irrelevant example can degrade
performance by up to 9.5%. Moreover, example ordering exhibits a recency bias,
i.e., placing the most relevant example last can lead to substantial
performance improvements by up to 71%. Our findings highlight critical
limitations and biases in current MLLMs when learning multimodal medical tasks
from context.

</details>


### [69] [MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN Hardware Accelerators](https://arxiv.org/abs/2506.21371)
*Vasileios Leon, Georgios Makris, Sotirios Xydis, Kiamal Pekmestzi, Dimitrios Soudris*

**主要类别:** cs.LG

**AI概要:** 本文研究了在低功耗DNN计算中，通过硬件近似技术与DNN任务的细粒度误差弹性之间的协作，以实现更高的能效。使用ROUP近似乘法器，在层、滤波器和内核级别上系统地探索其分布对精度和能量的影响。实验使用ResNet-8模型和CIFAR-10数据集，结果表明该方案相较于基线量化模型可提供高达54%的能效增益（损失最高4%的准确率），并且相较于最先进的DNN近似方法，能效提高2倍且准确率更高。


<details>
  <summary>更多</summary>
  
**动机:** 随着深度神经网络(DNN)架构的快速发展，它们已经成为提供高精度机器学习任务的实际方法。然而，为了实现低功耗DNN计算，需要进一步研究如何通过硬件近似技术和DNN任务的细粒度误差弹性之间的协作来提升能效。

**方法:** 利用先进的ROUP近似乘法器，根据层、滤波器和内核级别的方法，系统地探索这些乘法器在网络中的细粒度分布，并评估其对准确性和能量的影响。使用ResNet-8模型和CIFAR-10数据集进行评估。

**结果:** 所提出的解决方案相比基线量化模型，可以获得高达54%的能效增益（相对损失最高4%的准确率）。同时，相对于最先进的DNN近似方法，能效提高2倍且准确率更高。

**结论:** 通过结合硬件近似技术和DNN任务的细粒度误差弹性，可以在一定的准确率损失下显著提高能效，为低功耗DNN计算提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAx-DNN%3A+Multi-Level+Arithmetic+Approximation+for+Energy-Efficient+DNN+Hardware+Accelerators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21371，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21371&send_immediately=true&force_search=false)

**原文摘要:** Nowadays, the rapid growth of Deep Neural Network (DNN) architectures has
established them as the defacto approach for providing advanced Machine
Learning tasks with excellent accuracy. Targeting low-power DNN computing, this
paper examines the interplay of fine-grained error resilience of DNN workloads
in collaboration with hardware approximation techniques, to achieve higher
levels of energy efficiency. Utilizing the state-of-the-art ROUP approximate
multipliers, we systematically explore their fine-grained distribution across
the network according to our layer-, filter-, and kernel-level approaches, and
examine their impact on accuracy and energy. We use the ResNet-8 model on the
CIFAR-10 dataset to evaluate our approximations. The proposed solution delivers
up to 54% energy gains in exchange for up to 4% accuracy loss, compared to the
baseline quantized model, while it provides 2x energy gains with better
accuracy versus the state-of-the-art DNN approximations.

</details>


### [70] [Early Stopping Tabular In-Context Learning](https://arxiv.org/abs/2506.21387)
*Jaris Küken, Lennart Purucker, Frank Hutter*

**主要类别:** cs.LG

**AI概要:** 通过提前停止上下文学习过程，使用预训练的层 wise 解码器进行解码，可以在小任务和大任务上分别加速推理1.3倍和2.2倍，同时预测性能几乎没有下降。


<details>
  <summary>更多</summary>
  
**动机:** 表格基础模型在各种表格学习任务中表现出强大的性能，但其推理成本仍然很高，尤其是在较大的数据集上。为了降低这一成本，提出了一种提前停止上下文学习的方法。

**方法:** 动态评估在每个Transformer编码层之后是否停止上下文学习过程，一旦停止，则使用预训练的层 wise 解码器对嵌入进行解码。

**结果:** 在34个小分类任务上的实验表明，提前停止上下文学习可以加速推理最多1.3倍，预测性能几乎无损；在五个更大的分类任务上评估可达到最高2.2倍的加速。

**结论:** 提前退出是一种有效且实用的策略，可以提高表格上下文学习的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Early+Stopping+Tabular+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21387，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21387&send_immediately=true&force_search=false)

**原文摘要:** Tabular foundation models have shown strong performance across various
tabular learning tasks via in-context learning, offering robust generalization
without any downstream finetuning. However, their inference-time costs remain
high, particularly for larger datasets. To address this, we propose
early-stopping the in-context learning process. We achieve this by dynamically
evaluating whether to stop in-context learning after each Transformer encoder
layer. Once stopped, we decode the embedding using a pre-trained layer-wise
decoder. Experiments across 34 small classification tasks size show that early
stopping in-context learning accelerates inference by up to x1.3 with
negligible degradation in predictive performance. To assess scalability, we
further evaluate our method on five larger classification tasks, achieving
speedups of up to x2.2. Our results demonstrate the potential of early exiting
as an effective and practical strategy for improving the efficiency of tabular
in-context learning.

</details>


### [71] [Distributed Cross-Channel Hierarchical Aggregation for Foundation Models](https://arxiv.org/abs/2506.21411)
*Aristeidis Tsaris, Isaac Lyngaas, John Lagregren, Mohamed Wahib, Larry York, Prasanna Balaprakash, Dan Lu, Feiyi Wang, Xiao Wang*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种名为D-CHAG的方法，用于处理具有大量通道的图像模态数据集，兼容任何模型并行策略和视觉Transformer架构，显著提高了计算效率，并在超光谱成像和天气预报任务中实现了内存使用减少75%和吞吐量翻倍。


<details>
  <summary>更多</summary>
  
**动机:** 现有的分布式方法未能充分解决图像分词和聚合带来的计算密集型问题，特别是对于包含大量通道的图像模态数据集。

**方法:** 引入了分布式跨通道分级聚合（D-CHAG）方法，该方法与任何模型并行策略和视觉Transformer架构兼容，旨在提高计算效率。

**结果:** 在超光谱成像和天气预报任务上进行评估，结合张量并行性和模型分片后，在Frontier超级计算机上的1,024个AMD GPU上实现内存使用减少75%，持续吞吐量增加一倍以上。

**结论:** D-CHAG方法显著提高了处理多通道图像模态数据集的计算效率，为科学发现和创新提供了新的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distributed+Cross-Channel+Hierarchical+Aggregation+for+Foundation+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21411，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21411&send_immediately=true&force_search=false)

**原文摘要:** Vision-based scientific foundation models hold significant promise for
advancing scientific discovery and innovation. This potential stems from their
ability to aggregate images from diverse sources such as varying physical
groundings or data acquisition systems and to learn spatio-temporal
correlations using transformer architectures. However, tokenizing and
aggregating images can be compute-intensive, a challenge not fully addressed by
current distributed methods. In this work, we introduce the Distributed
Cross-Channel Hierarchical Aggregation (D-CHAG) approach designed for datasets
with a large number of channels across image modalities. Our method is
compatible with any model-parallel strategy and any type of vision transformer
architecture, significantly improving computational efficiency. We evaluated
D-CHAG on hyperspectral imaging and weather forecasting tasks. When integrated
with tensor parallelism and model sharding, our approach achieved up to a 75%
reduction in memory usage and more than doubled sustained throughput on up to
1,024 AMD GPUs on the Frontier Supercomputer.

</details>


### [72] [Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning](https://arxiv.org/abs/2506.21427)
*Prajwal Koirala, Cody Fleming*

**主要类别:** cs.LG

**AI概要:** 生成模型（如扩散和流匹配）通过捕捉丰富的多模态动作分布为离线强化学习（RL）提供了表达性策略，但其迭代采样引入了高推理成本和训练不稳定性。本文提出了单步完成策略（SSCP），这是一种使用增强的流匹配目标训练的生成策略，可以从中间流样本中直接预测完成向量，实现准确的一次性动作生成。在离线演员-评论家框架中，SSCP结合了生成模型的表达性和单一模式策略的训练与推理效率，无需长反向传播链。该方法在离线、离线到在线和在线RL设置中有效扩展，比基于扩散的基线在速度和适应性上提供了显著的优势。进一步将SSCP扩展到目标条件RL，使扁平策略能够在没有显式分层推理的情况下利用子目标结构。SSCP在标准的离线RL和行为克隆基准测试中取得了强大的结果，使其成为深度RL和顺序决策的多功能、表达性强且高效的框架。


<details>
  <summary>更多</summary>
  
**动机:** 生成模型在捕捉丰富多模态动作分布方面表现出色，但在离线强化学习中的应用受限于高推理成本和训练不稳定性。因此，需要一种新的策略来解决这些问题并提高效率。

**方法:** 提出了一种名为单步完成策略（SSCP）的生成策略。该策略通过增强的流匹配目标进行训练，能够从中间流样本中直接预测完成向量，从而实现一次性动作生成。SSCP结合了生成模型的表达性和单一模式策略的高效性，并且不需要长反向传播链。此外，还将其扩展到目标条件RL中，以利用子目标结构而无需显式的分层推理。

**结果:** SSCP在离线、离线到在线和在线RL设置中均表现良好，相较于基于扩散的基线方法，在速度和适应性上有了显著提升。它还在标准的离线RL和行为克隆基准测试中取得了强大的结果。

**结论:** SSCP作为一种新的生成策略，成功地结合了生成模型的表达性和单一模式策略的高效性，解决了传统生成模型在离线强化学习中的高推理成本和训练不稳定问题，适用于多种RL场景，并展现了强大的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Flow-Based+Single-Step+Completion+for+Efficient+and+Expressive+Policy+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21427，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21427&send_immediately=true&force_search=false)

**原文摘要:** Generative models such as diffusion and flow-matching offer expressive
policies for offline reinforcement learning (RL) by capturing rich, multimodal
action distributions, but their iterative sampling introduces high inference
costs and training instability due to gradient propagation across sampling
steps. We propose the \textit{Single-Step Completion Policy} (SSCP), a
generative policy trained with an augmented flow-matching objective to predict
direct completion vectors from intermediate flow samples, enabling accurate,
one-shot action generation. In an off-policy actor-critic framework, SSCP
combines the expressiveness of generative models with the training and
inference efficiency of unimodal policies, without requiring long
backpropagation chains. Our method scales effectively to offline,
offline-to-online, and online RL settings, offering substantial gains in speed
and adaptability over diffusion-based baselines. We further extend SSCP to
goal-conditioned RL, enabling flat policies to exploit subgoal structures
without explicit hierarchical inference. SSCP achieves strong results across
standard offline RL and behavior cloning benchmarks, positioning it as a
versatile, expressive, and efficient framework for deep RL and sequential
decision-making.

</details>


### [73] [Deception Detection in Dyadic Exchanges Using Multimodal Machine Learning: A Study on a Swedish Cohort](https://arxiv.org/abs/2506.21429)
*Franco Rugolon, Thomas Jack Samuels, Stephan Hau, Lennart Högman*

**主要类别:** cs.LG

**AI概要:** 本研究调查了在二人互动中使用多模态机器学习技术检测欺骗的有效性，发现在语音和面部信息结合以及参与者双方数据结合时表现最佳，准确率达到71%，为未来在心理治疗等领域的研究奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索如何通过多模态机器学习技术有效检测二人互动中的欺骗行为，并分析不同融合方法的效果，特别关注瑞典母语者在情感相关话题上的真实或谎言情境。

**方法:** 利用音频和视频数据（包括动作单元和注视信息），比较早期融合和后期融合方法，结合所有可能的模态和参与者组合进行分析。数据集来源于新收集的瑞典母语者在情感相关话题上讲述真实或虚假内容的情景。

**结果:** 将语音和面部信息相结合的方法比单一模态方法表现更优；同时包含两位参与者的数据显著提高了欺骗检测的准确性，其中后期融合策略在结合两种模态和参与者数据时表现最佳，准确率为71%。

**结论:** 研究表明，在二人互动中结合语音和面部信息以及双方参与者的数据可以显著提高欺骗检测的准确性，支持心理学理论关于初期互动中面部和声音表达差异控制的观点，为未来在北欧群体和心理治疗领域内的研究提供了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deception+Detection+in+Dyadic+Exchanges+Using+Multimodal+Machine+Learning%3A+A+Study+on+a+Swedish+Cohort，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21429，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21429&send_immediately=true&force_search=false)

**原文摘要:** This study investigates the efficacy of using multimodal machine learning
techniques to detect deception in dyadic interactions, focusing on the
integration of data from both the deceiver and the deceived. We compare early
and late fusion approaches, utilizing audio and video data - specifically,
Action Units and gaze information - across all possible combinations of
modalities and participants. Our dataset, newly collected from Swedish native
speakers engaged in truth or lie scenarios on emotionally relevant topics,
serves as the basis for our analysis. The results demonstrate that
incorporating both speech and facial information yields superior performance
compared to single-modality approaches. Moreover, including data from both
participants significantly enhances deception detection accuracy, with the best
performance (71%) achieved using a late fusion strategy applied to both
modalities and participants. These findings align with psychological theories
suggesting differential control of facial and vocal expressions during initial
interactions. As the first study of its kind on a Scandinavian cohort, this
research lays the groundwork for future investigations into dyadic
interactions, particularly within psychotherapy settings.

</details>


### [74] [Towards an Optimal Control Perspective of ResNet Training](https://arxiv.org/abs/2506.21453)
*Jens Püttschneider, Simon Heilig, Asja Fischer, Timm Faulwasser*

**主要类别:** cs.LG

**AI概要:** 提出了一种适用于标准架构和通用损失函数的ResNets训练公式，该公式反映了一个最优控制问题。通过惩罚与最优控制中的阶段成本项相对应的隐藏状态的中间输出，将两者联系起来。对于标准的ResNets，我们通过后续的跳跃连接和输出层传播状态来获得中间输出。我们证明了我们的训练动态使不必要的更深残差层的权重消失。这表明了一种基于理论支持的层剪枝策略的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 当前深度学习模型（如ResNets）的训练方法需要更优的数学基础，特别是结合最优控制理论来优化网络结构和性能。

**方法:** 提出一种新的ResNets训练方法，将最优控制问题应用于标准架构和通用损失函数中。通过惩罚隐藏状态的中间输出，对应于最优控制中的阶段成本项。对于标准ResNets，通过后续跳跃连接和输出层传播状态以获取中间输出。

**结果:** 实验结果表明，这种训练动态会使不必要的更深残差层的权重逐渐趋于零。

**结论:** 本研究展示了基于最优控制理论的层剪枝策略的潜力，为未来深度网络结构优化提供了理论依据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+an+Optimal+Control+Perspective+of+ResNet+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21453，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21453&send_immediately=true&force_search=false)

**原文摘要:** We propose a training formulation for ResNets reflecting an optimal control
problem that is applicable for standard architectures and general loss
functions. We suggest bridging both worlds via penalizing intermediate outputs
of hidden states corresponding to stage cost terms in optimal control. For
standard ResNets, we obtain intermediate outputs by propagating the state
through the subsequent skip connections and the output layer. We demonstrate
that our training dynamic biases the weights of the unnecessary deeper residual
layers to vanish. This indicates the potential for a theory-grounded layer
pruning strategy.

</details>


### [75] [A Keyword-Based Technique to Evaluate Broad Question Answer Script](https://arxiv.org/abs/2506.21461)
*Tamim Al Mahmud, Md Gulzar Hussain, Sumaiya Kabir, Hasnain Ahmad, Mahmudus Sobhan*

**主要类别:** cs.LG

**AI概要:** This paper presents an efficient electronic solution for evaluating subjective answer scripts, focusing on keyword extraction and comparison, as well as grammar and spelling error checks. Tested on 100 students' scripts, it achieved a precision score of 0.91.


<details>
  <summary>更多</summary>
  
**动机:** The motivation is to develop an efficient electronic evaluation system for subjective answer scripts, improving the assessment process in educational systems.

**方法:** The method involves extracting keywords from the answer scripts and comparing them with parsed keywords from both open and closed domains. It also includes checking for grammatical and spelling errors in the scripts.

**结果:** The system was tested with answer scripts from 100 students and achieved a precision score of 0.91.

**结论:** The proposed integrated system effectively evaluates written answer scripts by focusing on keyword comparison and error detection, achieving high precision.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Keyword-Based+Technique+to+Evaluate+Broad+Question+Answer+Script，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21461，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21461&send_immediately=true&force_search=false)

**原文摘要:** Evaluation is the method of assessing and determining the educational system
through various techniques such as verbal or viva-voice test, subjective or
objective written test. This paper presents an efficient solution to evaluate
the subjective answer script electronically. In this paper, we proposed and
implemented an integrated system that examines and evaluates the written answer
script. This article focuses on finding the keywords from the answer script and
then compares them with the keywords that have been parsed from both open and
closed domain. The system also checks the grammatical and spelling errors in
the answer script. Our proposed system tested with answer scripts of 100
students and gives precision score 0.91.

</details>


### [76] [Devising a solution to the problems of Cancer awareness in Telangana](https://arxiv.org/abs/2506.21500)
*Priyanka Avhad, Vedanti Kshirsagar, Urvi Ranjan, Mahek Nakhua*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种基于机器学习的分类模型，用于预测个人是否容易患乳腺癌或宫颈癌，并设计了一个系统提供最近的医院或癌症治疗中心建议，同时通过健康卡集成医疗记录并进行宣传。使用决策树和支撑向量分类算法分别对宫颈癌和乳腺癌易感性进行预测。


<details>
  <summary>更多</summary>
  
**动机:** 在Telangana地区，2020年宫颈癌、乳腺癌和口腔癌的筛查比例分别为3.3%、0.3%和2.3%，早期检测是降低发病率和死亡率的唯一途径，但人们对宫颈癌和乳腺癌的症状及筛查方法的认知度很低。

**方法:** 开发了ML分类模型来预测个人是否容易患乳腺癌或宫颈癌，依据的是人口统计学因素；设计了根据用户位置或地址提供最近医院或癌症治疗中心建议的系统；集成了健康卡以维护个人医疗记录并开展宣传活动；使用决策树分类算法预测宫颈癌易感性，使用支撑向量分类算法预测乳腺癌易感性。

**结果:** 成功开发出ML分类模型和相关系统，能够预测癌症易感性和提供就近医疗服务建议。

**结论:** 该解决方案使我们更接近于目标，即提高癌症认知度，从而减少癌症死亡率，增加Telangana地区的癌症知识普及率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Devising+a+solution+to+the+problems+of+Cancer+awareness+in+Telangana，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21500，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21500&send_immediately=true&force_search=false)

**原文摘要:** According to the data, the percent of women who underwent screening for
cervical cancer, breast and oral cancer in Telangana in the year 2020 was 3.3
percent, 0.3 percent and 2.3 percent respectively. Although early detection is
the only way to reduce morbidity and mortality, people have very low awareness
about cervical and breast cancer signs and symptoms and screening practices. We
developed an ML classification model to predict if a person is susceptible to
breast or cervical cancer based on demographic factors. We devised a system to
provide suggestions for the nearest hospital or Cancer treatment centres based
on the users location or address. In addition to this, we can integrate the
health card to maintain medical records of all individuals and conduct
awareness drives and campaigns. For ML classification models, we used decision
tree classification and support vector classification algorithms for cervical
cancer susceptibility and breast cancer susceptibility respectively. Thus, by
devising this solution we come one step closer to our goal which is spreading
cancer awareness, thereby, decreasing the cancer mortality and increasing
cancer literacy among the people of Telangana.

</details>


### [77] [Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test](https://arxiv.org/abs/2506.21551)
*Ziyue Li, Chenrui Fan, Tianyi Zhou*

**主要类别:** cs.LG

**AI概要:** 研究了7B参数的大语言模型(OLMoE)在单次预训练期间的Grokking现象，发现尽管不同数据可能异步进入Grokking阶段，但大规模基础模型的预训练中仍然存在Grokking。通过分析模型内部动态，揭示了记忆到泛化的转换机制，并提出了两个新指标来量化路径距离和复杂性，能够预测下游任务的泛化改进。理论上，更结构化的路径可以降低模型复杂度并改善泛化边界。


<details>
  <summary>更多</summary>
  
**动机:** 之前关于Grokking的研究通常集中在小型模型和特定任务上，而本研究旨在探索大规模语言模型预训练过程中是否存在Grokking现象，以及其背后的机制。

**方法:** 计算训练损失并在多个基准任务（如数学推理、代码生成、常识/领域知识检索）上评估泛化性能。通过研究训练样本路径的变化，从随机、实例特定到更具结构化和可共享的路径，揭示了Grokking中的泛化出现。开发了两个新指标来量化路径距离和单个路径的复杂性。

**结果:** 验证了大规模基础模型预训练中存在Grokking现象，不同数据可能异步进入Grokking阶段。发现了路径复杂性的减少和记忆到泛化的转换。提出的两个新指标能够有效预测下游任务的泛化改进。理论上证明了更结构化的路径可以降低模型复杂度并改善泛化边界。

**结论:** Grokking现象在大规模语言模型预训练中确实存在，且可以通过分析路径变化来理解记忆到泛化的转换。提出的两个新指标具有实际应用价值，可以在无需微调和测试的情况下监控泛化性能。理论上支持了更结构化的路径有助于降低模型复杂度并提高泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Where+to+find+Grokking+in+LLM+Pretraining%3F+Monitor+Memorization-to-Generalization+without+Test，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21551，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21551&send_immediately=true&force_search=false)

**原文摘要:** Grokking, i.e., test performance keeps improving long after training loss
converged, has been recently witnessed in neural network training, making the
mechanism of generalization and other emerging capabilities such as reasoning
mysterious. While prior studies usually train small models on a few toy or
highly-specific tasks for thousands of epochs, we conduct the first study of
grokking on checkpoints during one-pass pretraining of a 7B large language
model (LLM), i.e., OLMoE. We compute the training loss and evaluate
generalization on diverse benchmark tasks, including math reasoning, code
generation, and commonsense/domain-specific knowledge retrieval tasks.
  Our study, for the first time, verifies that grokking still happens in the
pretraining of large-scale foundation models, though different data may enter
grokking stages asynchronously. We further demystify grokking's "emergence of
generalization" by investigating LLM internal dynamics. Specifically, we find
that training samples' pathways (i.e., expert choices across layers) evolve
from random, instance-specific to more structured and shareable between samples
during grokking. Also, the complexity of a sample's pathway reduces despite the
converged loss. These indicate a memorization-to-generalization conversion,
providing a mechanistic explanation of delayed generalization. In the study, we
develop two novel metrics to quantify pathway distance and the complexity of a
single pathway. We show their ability to predict the generalization improvement
on diverse downstream tasks. They are efficient, simple to compute and solely
dependent on training data. Hence, they have practical value for pretraining,
enabling us to monitor the generalization performance without finetuning and
test. Theoretically, we show that more structured pathways reduce model
complexity and improve the generalization bound.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [78] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
*Yoshua Bengio, Tegan Maharaj, Luke Ong, Stuart Russell, Dawn Song, Max Tegmark, Lan Xue, Ya-Qin Zhang, Stephen Casper, Wan Sie Lee, Sören Mindermann, Vanessa Wilfred, Vidhisha Balachandran, Fazl Barez, Michael Belinsky, Imane Bello, Malo Bourgon, Mark Brakel, Siméon Campos, Duncan Cass-Beggs, Jiahao Chen, Rumman Chowdhury, Kuan Chua Seah, Jeff Clune, Juntao Dai, Agnes Delaborde, Nouha Dziri, Francisco Eiras, Joshua Engels, Jinyu Fan, Adam Gleave, Noah Goodman, Fynn Heide, Dan Hendrycks, Cyrus Hodes, Bryan Low Kian Hsiang, Minlie Huang, Sami Jawhar, Wang Jingyu, Adam Tauman Kalai, Meindert Kamphuis, Mohan Kankanhalli, Subhash Kantamneni, Mathias Bonde Kirk, Thomas Kwa, Jeffrey Ladish, Kwok-Yan Lam, Wan Lee Sie, Taewhi Lee, Xiaojian Li, Jiajun Liu, Chaochao Lu, Yifan Mai, Richard Mallah, Julian Michael, Nick Moës, Simon Möller, Kihyuk Nam, Kwan Yee Ng, Mark Nitzberg, Besmira Nushi, Seán O hÉigeartaigh, Alejandro Ortega, Pierre Peigné, James Petrie, Benjamin Prud'Homme, Reihaneh Rabbany, Nayat Sanchez-Pi, Sarah Schwettmann, Buck Shlegeris, Saad Siddiqui, Aradhana Sinha, Martín Soto, Cheston Tan, Dong Ting, Robert Trager, Brian Tse, Anthony Tung K. H., Vanessa Wilfred, John Willes, Denise Wong, Wei Xu, Rongwu Xu, Yi Zeng, HongJiang Zhang, Djordje Žikelić*

**主要类别:** cs.AI

**AI概要:** AI能力的快速提升和自主性带来了显著的变革潜力，同时也引发了关于如何确保AI安全（可信赖、可靠和安全）的激烈讨论。构建可信生态系统至关重要，它帮助人们有信心地接受AI，并为创新提供最大空间，同时避免抵制。2025新加坡AI会议（SCAI）旨在通过汇聚全球AI科学家来支持这一领域的研究，确定并综合AI安全的研究重点。该报告基于Yoshua Bengio主持并得到33个政府支持的国际AI安全报告，采用纵深防御模型，将AI安全研究领域分为三类：创建可信赖AI系统的挑战（发展）、评估其风险的挑战（评估），以及部署后监控和干预的挑战（控制）。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI能力的迅速提升和自主性的增强，如何确保AI的安全性和可靠性成为关键问题。这不仅影响技术的采纳，还可能引发社会的抵制。因此，需要建立一个可信的生态系统，以促进人们对AI的信任，并推动创新。此外，明确AI安全的研究优先级对于解决这些问题至关重要。

**方法:** 通过召开“2025新加坡AI会议（SCAI）”，汇聚来自不同地区的AI科学家，共同识别和综合AI安全的研究重点。该方法基于Yoshua Bengio主持并由33个政府支持的国际AI安全报告，采用纵深防御模型，将AI安全研究领域分为三个主要类型：发展、评估和控制。

**结果:** 确定了AI安全研究的三个主要领域：1) 创建可信赖AI系统的挑战；2) 评估AI系统风险的挑战；3) 部署后监控和干预的挑战。这些成果有助于指导未来AI安全研究的方向，并推动构建更加可信的AI生态系统。

**结论:** 构建可信的AI生态系统是确保AI安全的关键。通过明确研究优先级和发展、评估及控制三个方面的挑战，可以更好地推动AI技术的安全发展和广泛应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Singapore+Consensus+on+Global+AI+Safety+Research+Priorities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20702&send_immediately=true&force_search=false)

**原文摘要:** Rapidly improving AI capabilities and autonomy hold significant promise of
transformation, but are also driving vigorous debate on how to ensure that AI
is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem
is therefore essential -- it helps people embrace AI with confidence and gives
maximal space for innovation while avoiding backlash.
  The "2025 Singapore Conference on AI (SCAI): International Scientific
Exchange on AI Safety" aimed to support research in this space by bringing
together AI scientists across geographies to identify and synthesise research
priorities in AI safety. This resulting report builds on the International AI
Safety Report chaired by Yoshua Bengio and backed by 33 governments. By
adopting a defence-in-depth model, this report organises AI safety research
domains into three types: challenges with creating trustworthy AI systems
(Development), challenges with evaluating their risks (Assessment), and
challenges with monitoring and intervening after deployment (Control).

</details>


### [79] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja, Alon Albalak, Wenyue Hua, William Yang Wang*

**主要类别:** cs.AI

**AI概要:** 尽管LLM代理在多代理协作中广泛应用，但它们对情境隐私的理解和保护存在不足。本文提出MAGPIE基准测试，评估了现有模型（如GPT-4o和Claude-2.7-Sonnet）在高风险场景中的隐私保护能力。结果显示，这些模型经常错误分类私有数据，并在多轮对话中泄露隐私信息，同时任务完成率较低。这表明当前模型在隐私保护和协作任务解决方面尚未对齐。


<details>
  <summary>更多</summary>
  
**动机:** 随着基于LLM的代理在多代理协作中的广泛应用，保护用户隐私变得至关重要。然而，现有的评估基准主要关注单轮、低复杂度任务，无法充分反映实际场景中的隐私需求。因此，需要更全面的评估工具来衡量LLM代理在高风险场景中的隐私保护能力。

**方法:** 1. 提出MAGPIE基准测试，包含158个跨15个领域的高风险实际场景。
2. 评估模型对情境隐私数据的理解能力。
3. 测试模型在多轮对话中是否能在遵循隐私指令的前提下完成协作任务。

**结果:** 实验结果表明：
1. 当前最先进的模型（如GPT-4o和Claude-2.7-Sonnet）对情境隐私的理解不充分，分别有25.2%和43.6%的情况下将私有数据错误分类为可共享。
2. 在多轮对话中，即使在明确的隐私指令下，这些模型仍分别在59.9%和50.5%的情况下泄露隐私信息。
3. 多代理系统在71%的场景中无法完成任务。

**结论:** 当前的LLM代理模型在情境隐私保护和协作任务解决方面表现不佳，未能实现对齐。需要进一步改进模型以更好地理解和保护用户隐私，同时提高任务完成能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAGPIE%3A+A+dataset+for+Multi-AGent+contextual+PrIvacy+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20737&send_immediately=true&force_search=false)

**原文摘要:** The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [80] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
*Xinye Tang, Haijun Zhai, Chaitanya Belwal, Vineeth Thayanithi, Philip Baumann, Yogesh K Roy*

**主要类别:** cs.AI

**AI概要:** 本论文提出了一种新的动态上下文感知提示推荐系统，适用于特定领域的AI应用。系统结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名，以生成相关且可行的提示建议。实验表明，该方法在自动化和专家评估中均表现出高实用性和相关性。


<details>
  <summary>更多</summary>
  
**动机:** 特定领域的人工智能应用对用户提示的质量高度敏感，而创建高质量的提示尤其具有挑战性。因此，需要一种能够生成相关且可行的提示建议的系统。

**方法:** 该解决方案结合了上下文查询分析、检索增强的知识基础、分层技能组织和自适应技能排名。系统利用行为遥测技术和两阶段分层推理过程，动态选择和排名相关技能，并使用预定义和自适应模板（通过少量样本学习增强）合成提示。

**结果:** 实验证明，该方法在真实世界的数据集上表现出高实用性和相关性，得到了自动化和专家评估的验证。

**结论:** 提出的动态上下文感知提示推荐系统为特定领域的AI应用提供了一种有效的方法来生成高质量的提示建议。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Context-Aware+Prompt+Recommendation+for+Domain-Specific+AI+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20815，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20815&send_immediately=true&force_search=false)

**原文摘要:** LLM-powered applications are highly susceptible to the quality of user
prompts, and crafting high-quality prompts can often be challenging especially
for domain-specific applications. This paper presents a novel dynamic
context-aware prompt recommendation system for domain-specific AI applications.
Our solution combines contextual query analysis, retrieval-augmented knowledge
grounding, hierarchical skill organization, and adaptive skill ranking to
generate relevant and actionable prompt suggestions.
  The system leverages behavioral telemetry and a two-stage hierarchical
reasoning process to dynamically select and rank relevant skills, and
synthesizes prompts using both predefined and adaptive templates enhanced with
few-shot learning. Experiments on real-world datasets demonstrate that our
approach achieves high usefulness and relevance, as validated by both automated
and expert evaluations.

</details>


### [81] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji*

**主要类别:** cs.AI

**AI概要:** 随着基于语言模型的代理对从公共政策到医疗保健等高风险社会决策的影响日益增强，确保其积极影响需要理解其建议的深远影响。我们提出了一种概念验证框架，展示模型生成的建议如何在宏观层面上随时间传播于社会系统中，从而实现更稳健的对齐。为了评估语言模型的长期安全性意识，我们还引入了一个包含100个间接伤害场景的数据集，测试模型预测看似无害的用户提示可能带来的不良、非显而易见结果的能力。我们的方法不仅在新数据集上取得了超过20%的改进，而且在现有安全基准（AdvBench、SafeRLHF、WildGuardMix）上平均胜率超过70%，优于强大的基线模型，为更安全的代理指明了有希望的方向。


<details>
  <summary>更多</summary>
  
**动机:** 鉴于语言模型代理在诸如公共政策和医疗保健等关键领域的影响力日益增加，研究其长远影响及潜在危害变得至关重要，以保证这些模型对社会产生积极而非消极的作用。

**方法:** 提出一种概念验证框架，用于展示模型生成的建议如何在宏观层面上通过社会系统传播，并引入一个包含100个间接伤害场景的数据集来测试模型预测非显而易见不良后果的能力。

**结果:** 该方法在新数据集上表现出了超过20%的改进，并且在多个现有安全基准测试中，平均胜率超过了70%，显著优于强基线模型。

**结论:** 这项研究表明，所提出的框架和方法在提升语言模型的安全性和对齐性方面具有巨大潜力，为构建更安全的代理开辟了新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Reactive+Safety%3A+Risk-Aware+LLM+Alignment+via+Long-Horizon+Simulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20949，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20949&send_immediately=true&force_search=false)

**原文摘要:** Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [82] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, Bo Han*

**主要类别:** cs.AI

**AI概要:** 论文研究了大语言模型的因果推理能力，揭示其局限性在于只能进行浅层因果推理，提出G^2-Reasoner方法增强其因果推理能力，并通过新基准测试验证效果。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大语言模型似乎展示了理解上下文因果关系的能力，但尚不清楚它们是否能够进行类似于人类的真实因果推理。当前证据表明，大语言模型仅能执行浅层（一级）因果推理，缺乏真正的人类样（二级）因果推理能力。

**方法:** 研究深入探讨了基于Transformer的大语言模型的自回归机制，发现其并非本质上具有因果性。同时引入了一个名为CausalProbe-2024的新因果问答基准测试，并提出了G^2-Reasoner方法，将通用知识和目标导向提示融入大语言模型的因果推理过程。

**结果:** 实验结果表明，G^2-Reasoner大大增强了大语言模型的因果推理能力，尤其是在新鲜和反事实情境中。相比之前的基准测试，大语言模型在CausalProbe-2024上的表现明显下降，这表明它们主要参与一级因果推理。

**结论:** 本研究提出了一种新方法G^2-Reasoner，通过结合通用知识和目标导向提示显著提升了大语言模型在新鲜和反事实情境中的因果推理能力，为大语言模型迈向真实的因果推理提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unveiling+Causal+Reasoning+in+Large+Language+Models%3A+Reality+or+Mirage%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21215，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21215&send_immediately=true&force_search=false)

**原文摘要:** Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [83] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
*Junhao Shi, Zhaoye Fei, Siyin Wang, Qipeng Guo, Jingjing Gong, Xipeng QIu*

**主要类别:** cs.AI

**AI概要:** 大型视觉-语言模型(LVLMs)在具身规划任务中展现出潜力，但在涉及陌生环境和多步骤目标的复杂场景中表现不佳。当前方法依赖于与环境无关的模仿学习，导致模型难以处理与环境相关的指令，并在长时间交互中依赖补充线索而非视觉推理。本文提出了一种名为World-Aware Planning Narrative Enhancement (WAP)的框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法接地）将LVLMs与全面的环境理解相结合，并仅使用原始视觉观察通过课程学习来开发和评估模型。在EB-ALFRED基准上的评估显示了显著改进，特别是Qwen2.5-VL在任务成功率上绝对提升了60.7%，尤其在常识推理(+60.0)和长时间规划(+70.0)方面。值得注意的是，我们增强的开源模型大大优于GPT-4o和Claude-3.5-Sonnet等专有系统。


<details>
  <summary>更多</summary>
  
**动机:** LVLMs在复杂场景中的应用受限，尤其是在不熟悉的环境和多步骤目标的情况下。现有的方法未能充分连接指令与环境上下文，导致模型在情境敏感指令和长时间交互中表现不佳。

**方法:** 提出了WAP框架，通过四种认知能力提升LVLMs的环境理解能力：视觉外观建模、空间推理、功能抽象和句法接地。同时，采用课程学习方法仅利用原始视觉观察数据进行模型开发和评估。

**结果:** 在EB-ALFRED基准测试中取得了显著进步，特别是在常识推理和长时间规划方面。Qwen2.5-VL的任务成功率提升了60.7%。

**结论:** WAP框架有效地增强了LVLMs在复杂场景中的表现，开源模型在多个指标上超越了专有系统，展示了其潜力和优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是World-aware+Planning+Narratives+Enhance+Large+Vision-Language+Model+Planner，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21230，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21230&send_immediately=true&force_search=false)

**原文摘要:** Large Vision-Language Models (LVLMs) show promise for embodied planning tasks
but struggle with complex scenarios involving unfamiliar environments and
multi-step goals. Current approaches rely on environment-agnostic imitation
learning that disconnects instructions from environmental contexts, causing
models to struggle with context-sensitive instructions and rely on
supplementary cues rather than visual reasoning during long-horizon
interactions. In this work, we propose World-Aware Planning Narrative
Enhancement (WAP), a framework that infuses LVLMs with comprehensive
environmental understanding through four cognitive capabilities (visual
appearance modeling, spatial reasoning, functional abstraction, and syntactic
grounding) while developing and evaluating models using only raw visual
observations through curriculum learning. Evaluations on the EB-ALFRED
benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a
60.7 absolute improvement in task success rates, particularly in commonsense
reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced
open-source models outperform proprietary systems like GPT-4o and
Claude-3.5-Sonnet by a large margin.

</details>


### [84] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
*Pauline Speckmann, Mario Nadj, Christian Janiesch*

**主要类别:** cs.AI

**AI概要:** 通过结合可解释AI方法、交互性和实际应用，提出了一个新型的可解释AI系统IXAII，能够提升透明度并改善人机交互。


<details>
  <summary>更多</summary>
  
**动机:** 当前许多可解释AI方法是静态的且忽视了用户视角，限制了其对目标受众的有效性。

**方法:** 开发了一个名为IXAII的交互式可解释智能系统，提供来自LIME、SHAP、Anchors和DiCE四种可解释AI方法的解释，并为五类用户群体提供定制视图，使用户可以控制解释的内容和格式。

**结果:** 通过专家和普通用户的访谈评估，发现IXAII提供的多种解释和可视化选项有助于提高透明度。

**结论:** IXAII通过连接可解释AI方法、交互性和实际实现之间的差距，为AI解释实践和人机交互提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是IXAII%3A+An+Interactive+Explainable+Artificial+Intelligence+Interface+for+Decision+Support+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21310，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21310&send_immediately=true&force_search=false)

**原文摘要:** Although several post-hoc methods for explainable AI have been developed,
most are static and neglect the user perspective, limiting their effectiveness
for the target audience. In response, we developed the interactive explainable
intelligent system called IXAII that offers explanations from four explainable
AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored
views for five user groups and gives users agency over the explanations'
content and their format. We evaluated IXAII through interviews with experts
and lay users. Our results indicate that IXAII, which provides different
explanations with multiple visualization options, is perceived as helpful to
increase transparency. By bridging the gaps between explainable AI methods,
interactivity, and practical implementation, we provide a novel perspective on
AI explanation practices and human-AI interaction.

</details>


### [85] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
*Karthik Duraisamy*

**主要类别:** cs.AI

**AI概要:** 为了实现AI驱动的科学发现，必须弥合抽象差距、推理差距和现实差距。这需要构建能够进行反事实推理并以外部验证为依据的系统架构，同时强调人类判断在这一过程中的不可或缺性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的人工智能系统受限于其操作架构、脆弱的推理机制以及与实验现实的分离，因此需要一种新的方法来推动AI驱动的科学发现。

**方法:** 提出了一种包含四个关键要素的主动推理AI系统：(i)基于因果自监督基础模型的研究记忆；(ii)带有贝叶斯保护的符号或神经符号规划器；(iii)持续增长的知识图谱；(iv)通过高保真模拟器和自动化实验室进行闭环交互以改进内部表示。

**结果:** 该方法旨在创建一个架构，其中发现源于能够进行反事实推理的内部模型与将假设扎根于现实的外部验证之间的相互作用。

**结论:** 尽管模拟和实验存在固有的模糊性和不确定性，但人类判断对于AI驱动的科学发现是必不可少的，应作为永久的架构组件纳入系统设计中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Active+Inference+AI+Systems+for+Scientific+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21329，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21329&send_immediately=true&force_search=false)

**原文摘要:** The rapid evolution of artificial intelligence has led to expectations of
transformative scientific discovery, yet current systems remain fundamentally
limited by their operational architectures, brittle reasoning mechanisms, and
their separation from experimental reality. Building on earlier work, we
contend that progress in AI-driven science now depends on closing three
fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap
-- rather than on model size/data/test time compute. Scientific reasoning
demands internal representations that support simulation of actions and
response, causal structures that distinguish correlation from mechanism, and
continuous calibration. We define active inference AI systems for scientific
discovery as those that (i) maintain long-lived research memories grounded in
causal self-supervised foundation models, (ii) symbolic or neuro-symbolic
planners equipped with Bayesian guardrails, (iii) grow persistent knowledge
graphs where thinking generates novel conceptual nodes, reasoning establishes
causal edges, and real-world interaction prunes false connections while
strengthening verified pathways, and (iv) refine their internal representations
through closed-loop interaction with both high-fidelity simulators and
automated laboratories - an operational loop where mental simulation guides
action and empirical surprise reshapes understanding. In essence, we outline an
architecture where discovery arises from the interplay between internal models
that enable counterfactual reasoning and external validation that grounds
hypotheses in reality. It is also argued that the inherent ambiguity in
feedback from simulations and experiments, and underlying uncertainties makes
human judgment indispensable, not as a temporary scaffold but as a permanent
architectural component.

</details>


### [86] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
*Junwen Zhang, Pu Chen, Yin Zhang*

**主要类别:** cs.AI

**AI概要:** 提出TableMoE，一种针对多模态表格数据的神经符号混合连接专家架构，通过创新的神经符号路由机制和大规模预训练数据集，显著超越现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的表格理解具有挑战性，包括结构复杂、符号密度高和视觉退化等问题，现有的多模态大语言模型在这些条件下性能有限且泛化能力差。

**方法:** 设计了TableMoE，包含神经符号路由机制，预测语义角色并动态路由到专业模块；使用大规模TableMoE-Align数据集进行对齐驱动预训练；创建四个WildStruct基准测试数据集进行评估。

**结果:** 实验结果表明TableMoE显著超越现有最先进模型，消融研究验证了每个核心组件的有效性。

**结论:** TableMoE展示了其可解释性和增强的鲁棒性，强调了整合神经符号推理在多模态表格理解中的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TableMoE%3A+Neuro-Symbolic+Routing+for+Structured+Expert+Reasoning+in+Multimodal+Table+Understanding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21393，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21393&send_immediately=true&force_search=false)

**原文摘要:** Multimodal understanding of tables in real-world contexts is challenging due
to the complexity of structure, symbolic density, and visual degradation (blur,
skew, watermarking, incomplete structures or fonts, multi-span or
hierarchically nested layouts). Existing multimodal large language models
(MLLMs) struggle with such WildStruct conditions, resulting in limited
performance and poor generalization. To address these challenges, we propose
TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture
specifically designed for robust, structured reasoning over multimodal table
data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which
predicts latent semantic token roles (e.g., header, data cell, axis, formula)
and dynamically routes table elements to specialized experts (Table-to-HTML,
Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed
by symbolic reasoning graphs. To facilitate effective alignment-driven
pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of
1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and
industry, utilized exclusively for model pretraining. For evaluation, we curate
and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,
WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models
under real-world multimodal degradation and structural complexity. Experimental
results demonstrate that TableMoE significantly surpasses existing
state-of-the-art models. Extensive ablation studies validate each core
component, emphasizing the critical role of Neuro-Symbolic Routing and
structured expert alignment. Through qualitative analyses, we further showcase
TableMoE's interpretability and enhanced robustness, underscoring the
effectiveness of integrating neuro-symbolic reasoning for multimodal table
understanding.

</details>


### [87] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin, Qineng Wang, Pingyue Zhang, Jianshu Zhang, Kangrui Wang, Zihan Wang, Jieyu Zhang, Keshigeyan Chandrasegaran, Han Liu, Ranjay Krishna, Saining Xie, Manling Li, Jiajun Wu, Li Fei-Fei*

**主要类别:** cs.AI

**AI概要:** 论文探讨了视觉语言模型（VLMs）是否能像人类一样从少数视角想象整个场景，提出了新的MindCube基准来评估VLMs在构建空间心理模型方面的表现，并提出通过生成认知地图和推理的方法提升VLMs性能，结合强化学习可进一步提高准确率。


<details>
  <summary>更多</summary>
  
**动机:** 探索视觉语言模型是否能够像人类一样构建空间心理模型，以理解未观察到的空间。

**方法:** 创建了一个名为MindCube的新基准，包含21,154个问题和3,268张图像，用于评估VLMs的空间心理模型能力；研究了三种方法：未见中间视图、自然语言推理链和认知地图，发现“map-then-reason”方法效果最佳，结合强化学习进一步提升性能。

**结果:** 使用“map-then-reason”方法将准确率从37.8%提升到60.8%，再通过强化学习提升至70.7%。

**结论:** 主动构建和利用内部结构化的空间表示，并结合灵活的推理过程，可以显著改善VLMs对未观测空间的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spatial+Mental+Modeling+from+Limited+Views，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21458，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21458&send_immediately=true&force_search=false)

**原文摘要:** Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [88] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
*Tin Dizdarević, Ravi Hammond, Tobias Gessler, Anisoara Calinescu, Jonathan Cook, Matteo Gallici, Andrei Lupu, Jakob Nicolaus Foerster*

**主要类别:** cs.AI

**AI概要:** 为了促进人类与AI无缝协作，本文提出了一种新的挑战AH2AC2，并开发了名为human proxy agents的代理来替代真人评测，同时开源了一个有限规模的数据集以推动数据高效方法的发展。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Hanabi游戏为测试人类-AI协作提供了一个理想环境，但受限于真人评估的成本和复杂性，这一领域的进展受到限制。

**方法:** 作者引入了Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，并基于大规模人类数据集创建了human proxy agents作为可重复且低成本的人类行为代理。此外，他们开源了一个包含3,079局游戏的数据集，故意限制了数据量以鼓励数据高效方法的发展。

**结果:** 研究提供了两人和三人Hanabi场景的基线结果，证明了human proxy agents在模拟人类行为方面的有效性。

**结论:** 通过AH2AC2挑战赛及其配套工具，研究促进了更高效、更公平的人类-AI协作算法开发，并通过受控系统托管代理确保了公正评估。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ad-Hoc+Human-AI+Coordination+Challenge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21490，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21490&send_immediately=true&force_search=false)

**原文摘要:** Achieving seamless coordination between AI agents and humans is crucial for
real-world applications, yet it remains a significant open challenge. Hanabi is
a cooperative card game featuring imperfect information, constrained
communication, theory of mind requirements, and coordinated action -- making it
an ideal testbed for human-AI coordination. However, its use for human-AI
interaction has been limited by the challenges of human evaluation. In this
work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to
overcome the constraints of costly and difficult-to-reproduce human
evaluations. We develop \textit{human proxy agents} on a large-scale human
dataset that serve as robust, cheap, and reproducible human-like evaluation
partners in AH2AC2. To encourage the development of data-efficient methods, we
open-source a dataset of 3,079 games, deliberately limiting the amount of
available human gameplay data. We present baseline results for both two- and
three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy
agents through a controlled evaluation system rather than releasing them
publicly. The code is available at
\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.

</details>


### [89] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su*

**主要类别:** cs.AI

**AI概要:** 这篇论文介绍了Mind2Web 2，一个包含130个需要实时网络浏览和广泛信息综合的长周期任务的基准。为了解决评估时间变化和复杂答案的挑战，提出了一种新的Agent-as-a-Judge框架，可以自动评估答案正确性和来源归属。通过对9个前沿代理搜索系统和人类表现的全面评估，发现表现最好的系统OpenAI Deep Research能达到人类表现的50-70%，但耗时仅为人类的一半。


<details>
  <summary>更多</summary>
  
**动机:** 当前代理搜索系统的复杂性和开放性已经超出了现有的评估基准和方法论，这些基准和方法论主要假设短周期搜索和静态答案。因此，需要一个新的基准和评估框架来更好地衡量代理搜索系统的表现。

**方法:** 构建了一个名为Mind2Web 2的新基准，包含130个高质、长时间跨度的任务，需要实时网络浏览和信息综合。提出了Agent-as-a-Judge框架，基于树形结构评分设计构建特定任务的评审代理，自动评估答案正确性和来源归属。

**结果:** 对9个前沿代理搜索系统和人类表现进行了全面评估，并进行了详细的错误分析以获取未来发展的见解。结果显示，表现最佳的系统OpenAI Deep Research能达到人类表现的50-70%，且耗时仅为人类的一半。

**结论:** Mind2Web 2提供了一个严格的基 础，用于开发和评估下一代代理搜索系统，有助于推动这一领域的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mind2Web+2%3A+Evaluating+Agentic+Search+with+Agent-as-a-Judge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21506，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21506&send_immediately=true&force_search=false)

**原文摘要:** Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


### [90] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
*Fangjun Ding, Renyu Zhang, Xinyu Feng, Chengye Xie, Zheng Zhang, Yanting Zhang*

**主要类别:** cs.AI

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PsyLite+Technical+Report，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21536&send_immediately=true&force_search=false)

**原文摘要:** With the rapid development of digital technology, AI-driven psychological
counseling has gradually become an important research direction in the field of
mental health. However, existing models still have deficiencies in dialogue
safety, detailed scenario handling, and lightweight deployment. To address
these issues, this study proposes PsyLite, a lightweight psychological
counseling large language model agent developed based on the base model
InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation
data fine-tuning and ORPO preference optimization), PsyLite enhances the
model's deep-reasoning ability, psychological counseling ability, and safe
dialogue ability. After deployment using Ollama and Open WebUI, a custom
workflow is created with Pipelines. An innovative conditional RAG is designed
to introduce crosstalk humor elements at appropriate times during psychological
counseling to enhance user experience and decline dangerous requests to
strengthen dialogue safety. Evaluations show that PsyLite outperforms the
baseline models in the Chinese general evaluation (CEval), psychological
counseling professional evaluation (CPsyCounE), and dialogue safety evaluation
(SafeDialBench), particularly in psychological counseling professionalism
(CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score
improvement of 2.4\%). Additionally, the model uses quantization technology
(GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient
for operation), providing a feasible solution for psychological counseling
applications in resource-constrained environments.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [91] [The final solution of the Hitchhiker's problem #5](https://arxiv.org/abs/2506.20672)
*Matjaž Omladič, Martin Vuk, Aljaž Zalar*

**主要类别:** stat.ML

**AI概要:** 这篇论文通过分析与多变量拟共轭相关的质量分布的极值问题，结合线性规划和解析方法，解决了' Hitchhiker's Guide '中提到的开放问题5，并否定了最近关于该问题的一个猜想。


<details>
  <summary>更多</summary>
  
**动机:** 由于拟共轭问题在依赖建模社区中的重要性提升，尽管缺乏统计解释，研究者试图深入探讨与多变量拟共轭相关联的质量分布的极值。

**方法:** 首先使用线性规划方法解决开放问题5至维度d = 17，然后采用解析方法提供对原问题的完整解答。

**结果:** 成功解决了开放问题5，并且否定了一个近期提出的关于该问题解的猜想。

**结论:** 解析方法能够为多变量拟共轭的质量分布极值问题提供完整的解答，进一步加深了对拟共轭的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+final+solution+of+the+Hitchhiker%27s+problem+%235，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20672&send_immediately=true&force_search=false)

**原文摘要:** A recent survey, nicknamed "Hitchhiker's Guide", J.J. Arias-Garc{\i}a, R.
Mesiar, and B. De Baets, A hitchhiker's guide to quasi-copulas, Fuzzy Sets and
Systems 393 (2020) 1-28, has raised the rating of quasi-copula problems in the
dependence modeling community in spite of the lack of statistical
interpretation of quasi-copulas. In our previous work (arXiv:2410.19339,
accepted in Fuzzy Sets and Systems), we addressed the question of extreme
values of the mass distribution associated with multivariate quasi-copulas.
Using a linear programming approach, we were able to solve Open Problem 5 of
the "Guide" up to dimension d = 17 and disprove a recent conjecture on the
solution to that problem. In this paper, we use an analytical approach to
provide a complete answer to the original question.

</details>


### [92] [Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon](https://arxiv.org/abs/2506.20779)
*Tongtong Liang, Dan Qiao, Yu-Xiang Wang, Rahul Parhi*

**主要类别:** stat.ML

**AI概要:** This paper studies the effects of flatness in loss landscape on generalization for overparameterized ReLU networks with multivariate inputs, showing that flat solutions perform poorly in high dimensions due to neural shattering.


<details>
  <summary>更多</summary>
  
**动机:** To understand the implicit bias of flatness/low curvature on generalization in overparameterized ReLU networks with multivariate inputs, motivated by phenomena such as minima stability and edge-of-stability during gradient-descent training.

**方法:** Theoretical analysis and numerical simulations were conducted. The authors proved upper and lower bounds on two settings: generalization gap for flat solutions and mean-squared error (MSE) in nonparametric function estimation by stable minima. They used a novel packing argument with boundary-localized ReLU neurons to construct minimax lower bound.

**结果:** Flat solutions exploit ''neural shattering'' where neurons rarely activate but have high weight magnitudes, leading to poor performance in high dimensions. Theoretical findings were supported by extensive numerical simulations.

**结论:** Flatness in high-dimensional input spaces leads to poor generalization performance. Flat solutions suffer from an exponential deterioration in convergence rates as the input dimension grows, unlike low-norm solutions that do not face the curse of dimensionality.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stable+Minima+of+ReLU+Neural+Networks+Suffer+from+the+Curse+of+Dimensionality%3A+The+Neural+Shattering+Phenomenon，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20779，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20779&send_immediately=true&force_search=false)

**原文摘要:** We study the implicit bias of flatness / low (loss) curvature and its effects
on generalization in two-layer overparameterized ReLU networks with
multivariate inputs -- a problem well motivated by the minima stability and
edge-of-stability phenomena in gradient-descent training. Existing work either
requires interpolation or focuses only on univariate inputs. This paper
presents new and somewhat surprising theoretical results for multivariate
inputs. On two natural settings (1) generalization gap for flat solutions, and
(2) mean-squared error (MSE) in nonparametric function estimation by stable
minima, we prove upper and lower bounds, which establish that while flatness
does imply generalization, the resulting rates of convergence necessarily
deteriorate exponentially as the input dimension grows. This gives an
exponential separation between the flat solutions vis-\`a-vis low-norm
solutions (i.e., weight decay), which knowingly do not suffer from the curse of
dimensionality. In particular, our minimax lower bound construction, based on a
novel packing argument with boundary-localized ReLU neurons, reveals how flat
solutions can exploit a kind of ''neural shattering'' where neurons rarely
activate, but with high weight magnitudes. This leads to poor performance in
high dimensions. We corroborate these theoretical findings with extensive
numerical simulations. To the best of our knowledge, our analysis provides the
first systematic explanation for why flat minima may fail to generalize in high
dimensions.

</details>


### [93] [Active Learning for Manifold Gaussian Process Regression](https://arxiv.org/abs/2506.20928)
*Yuanxing Cheng, Lulu Kang, Yiwei Wang, Chun Liu*

**主要类别:** stat.ML

**AI概要:** 本论文提出了一种主动学习框架，用于流形高斯过程回归，结合了流形学习与战略性数据选择以提高高维空间中的准确性。方法联合优化了一个用于降维的神经网络和潜在空间中的高斯过程回归器，由最小化全局预测误差的主动学习标准监督。实验表明其性能优于随机顺序学习，并能有效处理复杂、不连续的函数。未来工作将关注可扩展性和不确定性感知的流形学习。


<details>
  <summary>更多</summary>
  
**动机:** 在高维空间中进行准确的回归分析是一个挑战，现有的方法可能无法高效处理复杂和不连续的函数，因此需要一种结合流形学习与主动学习的新方法来提升回归性能并保持计算可行性。

**方法:** 提出了一种主动学习框架，该框架结合流形学习与战略性数据选择，联合优化一个用于降维的神经网络和潜在空间中的高斯过程回归器，并通过主动学习准则监督整个过程以最小化全局预测误差。

**结果:** 在合成数据上的实验表明，该方法的性能优于随机顺序学习，并且能够有效处理复杂、不连续的函数，同时保留了计算上的可行性。

**结论:** 所提出的框架在高维空间中的回归任务中表现出优越性能，具有科学和工程应用的实际价值。未来的研究将着重于提升方法的可扩展性以及引入不确定性感知的流形学习。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Active+Learning+for+Manifold+Gaussian+Process+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20928，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20928&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces an active learning framework for manifold Gaussian
Process (GP) regression, combining manifold learning with strategic data
selection to improve accuracy in high-dimensional spaces. Our method jointly
optimizes a neural network for dimensionality reduction and a Gaussian process
regressor in the latent space, supervised by an active learning criterion that
minimizes global prediction error. Experiments on synthetic data demonstrate
superior performance over randomly sequential learning. The framework
efficiently handles complex, discontinuous functions while preserving
computational tractability, offering practical value for scientific and
engineering applications. Future work will focus on scalability and
uncertainty-aware manifold learning.

</details>


### [94] [Lower Bounds on the Size of Markov Equivalence Classes](https://arxiv.org/abs/2506.20933)
*Erik Jahn, Frederick Eberhardt, Leonard J. Schulman*

**主要类别:** stat.ML

**AI概要:** 在因果发现算法中，当放松无环性、因果充分性和统一模型先验等假设时，马尔可夫等价类的大小会呈指数级增长。


<details>
  <summary>更多</summary>
  
**动机:** 探讨在不同假设条件下，马尔可夫等价类的大小及其对因果图学习的影响。

**方法:** 通过理论分析和证明，在三种不同的图结构设置下（稀疏随机有向无环图、随机有向混合图、随机有向循环图），研究马尔可夫等价类的期望大小。

**结果:** 证明了在放松某些假设的情况下，马尔可夫等价类的期望大小具有指数级下界。

**结论:** 当假设条件被放宽时，仅从观测数据中学习因果图的能力受到显著限制，马尔可夫等价类可能变得非常大。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Lower+Bounds+on+the+Size+of+Markov+Equivalence+Classes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20933，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20933&send_immediately=true&force_search=false)

**原文摘要:** Causal discovery algorithms typically recover causal graphs only up to their
Markov equivalence classes unless additional parametric assumptions are made.
The sizes of these equivalence classes reflect the limits of what can be
learned about the underlying causal graph from purely observational data. Under
the assumptions of acyclicity, causal sufficiency, and a uniform model prior,
Markov equivalence classes are known to be small on average. In this paper, we
show that this is no longer the case when any of these assumptions is relaxed.
Specifically, we prove exponentially large lower bounds for the expected size
of Markov equivalence classes in three settings: sparse random directed acyclic
graphs, uniformly random acyclic directed mixed graphs, and uniformly random
directed cyclic graphs.

</details>


### [95] [Forecasting Geopolitical Events with a Sparse Temporal Fusion Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and U.S. Conflict Dynamics](https://arxiv.org/abs/2506.20935)
*Hsin-Hsiung Huang, Hayden Hampton*

**主要类别:** stat.ML

**AI概要:** 本研究提出了一种名为STFT-VNNGP的混合架构，通过结合TFT和VNNGP模型克服了传统深度学习模型在预测地缘政治冲突时的局限性。该模型在2023年ATD竞赛中胜出，并在中东和美国冲突动态预测案例中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 地缘政治冲突预测对于国家安全至关重要，但现有数据（如GDELT）存在稀疏性、突发性和过度分散等问题，导致传统深度学习模型（如TFT）在长期预测中表现不可靠。

**方法:** STFT-VNNGP采用两阶段过程：第一阶段使用TFT捕捉复杂的时间动态并生成多分位数预测；第二阶段将这些分位数作为输入，利用VNNGP进行空间时间平滑和不确定性量化。

**结果:** 在中东和美国冲突动态预测案例中，STFT-VNNGP显著优于单独的TFT模型，尤其是在预测突发事件的时间和强度方面表现出更强的能力。

**结论:** STFT-VNNGP提供了一个强大的框架，能够从具有挑战性的事件数据中生成更可靠和可操作的情报，且所有代码和工作流均已公开以确保可重复性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Forecasting+Geopolitical+Events+with+a+Sparse+Temporal+Fusion+Transformer+and+Gaussian+Process+Hybrid%3A+A+Case+Study+in+Middle+Eastern+and+U.S.+Conflict+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.20935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.20935&send_immediately=true&force_search=false)

**原文摘要:** Forecasting geopolitical conflict from data sources like the Global Database
of Events, Language, and Tone (GDELT) is a critical challenge for national
security. The inherent sparsity, burstiness, and overdispersion of such data
cause standard deep learning models, including the Temporal Fusion Transformer
(TFT), to produce unreliable long-horizon predictions. We introduce STFT-VNNGP,
a hybrid architecture that won the 2023 Algorithms for Threat Detection (ATD)
competition by overcoming these limitations. Designed to bridge this gap, our
model employs a two-stage process: first, a TFT captures complex temporal
dynamics to generate multi-quantile forecasts. These quantiles then serve as
informed inputs for a Variational Nearest Neighbor Gaussian Process (VNNGP),
which performs principled spatiotemporal smoothing and uncertainty
quantification. In a case study forecasting conflict dynamics in the Middle
East and the U.S., STFT-VNNGP consistently outperforms a standalone TFT,
showing a superior ability to predict the timing and magnitude of bursty event
periods, particularly at long-range horizons. This work offers a robust
framework for generating more reliable and actionable intelligence from
challenging event data, with all code and workflows made publicly available to
ensure reproducibility.

</details>


### [96] [Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games](https://arxiv.org/abs/2506.21079)
*Yann Kerzreho*

**主要类别:** stat.ML

**AI概要:** This paper proposes a new method for approximating the learning dynamics of multiple RL agents in a finite-state Markov game by rescaling the learning process, proving its convergence to an ODE.


<details>
  <summary>更多</summary>
  
**动机:** To better understand and predict the complex learning dynamics of multiple interacting RL agents in finite-state Markov games.

**方法:** Rescale the learning process by reducing the learning rate and increasing the update frequency, treating agent parameters as a slow-evolving variable influenced by fast-mixing game states.

**结果:** Proves that under certain assumptions (ergodicity and continuity), the rescaled learning process converges to an ODE providing a deterministic approximation of learning dynamics.

**结论:** The proposed method offers a tractable way to approximate and analyze the learning dynamics of multiple RL agents in Markov games.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Homogenization+of+Multi-agent+Learning+Dynamics+in+Finite-state+Markov+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21079，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21079&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a new approach for approximating the learning dynamics
of multiple reinforcement learning (RL) agents interacting in a finite-state
Markov game. The idea is to rescale the learning process by simultaneously
reducing the learning rate and increasing the update frequency, effectively
treating the agent's parameters as a slow-evolving variable influenced by the
fast-mixing game state. Under mild assumptions-ergodicity of the state process
and continuity of the updates-we prove the convergence of this rescaled process
to an ordinary differential equation (ODE). This ODE provides a tractable,
deterministic approximation of the agent's learning dynamics. An implementation
of the framework is available at\,:
https://github.com/yannKerzreho/MarkovGameApproximation

</details>


### [97] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
*Lukas Sablica, Kurt Hornik*

**主要类别:** stat.ML

**AI概要:** 提出了一种新的变分自编码器（VAE）架构，采用球面柯西（spCauchy）潜在分布。与传统的高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布不同，spCauchy提供了更自然的超球面潜在变量表示，更好地捕捉方向性数据同时保持灵活性。其重尾特性防止过度正则化，确保有效的潜在空间利用并提供更具表现力的表示。此外，spCauchy规避了vMF固有的数值不稳定性，并通过Möbius变换实现完全可微且高效的重参数化技巧，从而实现稳定和可扩展的训练。KL散度可以通过快速收敛的幂级数计算，消除了与超几何函数比率评估相关的下溢或上溢问题。这些特性使spCauchy成为VAEs的一个有吸引力的替代方案，在高维生成建模中既具有理论优势又具有实际效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的VAE模型通常使用高斯分布或von Mises-Fisher（vMF）分布作为潜在空间表示，但高斯分布可能无法充分捕捉方向性数据，而vMF分布存在数值不稳定性的问题。因此，需要一种新的潜在分布来克服这些限制，提供更自然的方向性数据表示和更高的数值稳定性。

**方法:** 作者提出了一个基于球面柯西（spCauchy）分布的新VAE架构。这种分布具有以下特点：
- 提供更自然的超球面潜在变量表示。
- 重尾特性防止过度正则化。
- 避免von Mises-Fisher分布中的数值不稳定性。
- 利用Möbius变换实现完全可微且高效的重参数化技巧。
- KL散度可通过快速收敛的幂级数计算，避免数值问题。

**结果:** 实验结果表明，采用spCauchy潜在分布的VAE在高维生成建模任务中表现出色，具备更好的表达能力和数值稳定性。模型能够有效利用潜在空间，并避免了传统方法中存在的数值问题。

**结论:** 球面柯西（spCauchy）分布为VAE提供了一个有吸引力的替代方案。它不仅具有理论上的优势，如更自然的方向性数据表示和重尾特性，还解决了数值不稳定性的问题，使得模型在高维生成建模中更加高效和稳定。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hyperspherical+Variational+Autoencoders+Using+Efficient+Spherical+Cauchy+Distribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21278，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21278&send_immediately=true&force_search=false)

**原文摘要:** We propose a novel variational autoencoder (VAE) architecture that employs a
spherical Cauchy (spCauchy) latent distribution. Unlike traditional Gaussian
latent spaces or the widely used von Mises-Fisher (vMF) distribution, spCauchy
provides a more natural hyperspherical representation of latent variables,
better capturing directional data while maintaining flexibility. Its
heavy-tailed nature prevents over-regularization, ensuring efficient latent
space utilization while offering a more expressive representation.
Additionally, spCauchy circumvents the numerical instabilities inherent to vMF,
which arise from computing normalization constants involving Bessel functions.
Instead, it enables a fully differentiable and efficient reparameterization
trick via M\"obius transformations, allowing for stable and scalable training.
The KL divergence can be computed through a rapidly converging power series,
eliminating concerns of underflow or overflow associated with evaluation of
ratios of hypergeometric functions. These properties make spCauchy a compelling
alternative for VAEs, offering both theoretical advantages and practical
efficiency in high-dimensional generative modeling.

</details>


### [98] [Wild refitting for black box prediction](https://arxiv.org/abs/2506.21460)
*Martin J. Wainwright*

**主要类别:** stat.ML

**AI概要:** 本论文提出了一种名为wild refitting的高效重新拟合程序，用于计算基于最小二乘法最小化的惩罚非参数估计的实例均方预测误差的高概率上界。该方法通过计算适当的残差、对其进行对称化和缩放，并用其定义和解决一个修改后的预测问题来实现。在相对温和的条件下，论文建立了该方法性能的高概率保证，表明选择合适的噪声尺度ρ可以得到预测误差的上界。此过程适用于多个问题，如结构矩阵惩罚的非刚性运动恢复、深度神经网络先验的插件图像修复以及核方法的随机化绘图。


<details>
  <summary>更多</summary>
  
**动机:** 为了提供一种有效的重新拟合方法，能够使用单一数据集和黑箱访问预测方法，以计算惩罚非参数估计的实例均方预测误差的高概率上界。这有助于了解预测误差的范围并指导相关过程的设计。

**方法:** 该方法包含三个步骤：1) 计算适当的残差；2) 使用预因子ρ对残差进行对称化和缩放；3) 利用这些残差定义并解决一个修改后的预测问题，重新聚焦于当前估计值。这种方法被称为wild refitting，因为它使用了类似于wild bootstrap变体的Rademacher残差对称化。

**结果:** 在相对温和的条件下，该方法能够提供预测误差的高概率上界。具体来说，选择合适的wild noise scale ρ可以确保这一结果。此外，理论分析还提供了关于如何形成残差、在wild子问题中需要多少噪声重缩放以获得上界以及黑箱过程的局部稳定性属性的指导。

**结论:** 提出的wild refitting方法在多种问题中具有广泛适用性，包括非刚性运动恢复、插件图像修复和核方法的随机化绘图等。它不仅为预测误差提供了高概率上界，还为设计类似过程提供了理论依据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Wild+refitting+for+black+box+prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21460，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21460&send_immediately=true&force_search=false)

**原文摘要:** We describe and analyze a computionally efficient refitting procedure for
computing high-probability upper bounds on the instance-wise mean-squared
prediction error of penalized nonparametric estimates based on least-squares
minimization. Requiring only a single dataset and black box access to the
prediction method, it consists of three steps: computing suitable residuals,
symmetrizing and scaling them with a pre-factor $\rho$, and using them to
define and solve a modified prediction problem recentered at the current
estimate. We refer to it as wild refitting, since it uses Rademacher residual
symmetrization as in a wild bootstrap variant. Under relatively mild conditions
allowing for noise heterogeneity, we establish a high probability guarantee on
its performance, showing that the wild refit with a suitably chosen wild noise
scale $\rho$ gives an upper bound on prediction error. This theoretical
analysis provides guidance into the design of such procedures, including how
the residuals should be formed, the amount of noise rescaling in the wild
sub-problem needed for upper bounds, and the local stability properties of the
block-box procedure. We illustrate the applicability of this procedure to
various problems, including non-rigid structure-from-motion recovery with
structured matrix penalties; plug-and-play image restoration with deep neural
network priors; and randomized sketching with kernel methods.

</details>


### [99] [Gaussian Invariant Markov Chain Monte Carlo](https://arxiv.org/abs/2506.21511)
*Michalis K. Titsias, Angelos Alexopoulos, Siran Liu, Petros Dellaportas*

**主要类别:** stat.ML

**AI概要:** 开发了高斯不变量版本的随机游走Metropolis (RWM)，Metropolis调整Langevin算法 (MALA) 和二阶Hessian或Manifold MALA的采样方法。这些方法在高斯不变性下表现出色，能够改进统计效率，并通过解析解构造控制变量以减少估计量的方差。在多个例子中展示新采样器和估计量，包括高维目标的潜在高斯模型，与多种高级方法比较并取得最先进的结果。此外，还提供了几何遍历性和最优缩放分析的理论结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的标准RWM和MALA方法可能无法充分利用高斯不变性的优势，导致估计器的统计效率较低。因此，需要开发新的采样方法，以利用高斯不变性来提高估计器的性能。

**方法:** 提出高斯不变版本的RWM、MALA和二阶Hessian或Manifold MALA采样方法。通过高斯不变性，获得泊松方程的精确解析解，用于构建控制变量以减少估计量的方差。

**结果:** 在多个示例中展示了新采样器和估计量的效果，特别是在高维目标的潜在高斯模型中，与多种高级方法相比，取得了最先进的结果。同时，理论结果表明其具有几何遍历性，并且最优缩放分析显示了目标高斯性对最优接受率的影响。

**结论:** 高斯不变采样方法可以显著提高估计器的统计效率，为处理复杂模型提供了高效工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gaussian+Invariant+Markov+Chain+Monte+Carlo，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.21511，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.21511&send_immediately=true&force_search=false)

**原文摘要:** We develop sampling methods, which consist of Gaussian invariant versions of
random walk Metropolis (RWM), Metropolis adjusted Langevin algorithm (MALA) and
second order Hessian or Manifold MALA. Unlike standard RWM and MALA we show
that Gaussian invariant sampling can lead to ergodic estimators with improved
statistical efficiency. This is due to a remarkable property of Gaussian
invariance that allows us to obtain exact analytical solutions to the Poisson
equation for Gaussian targets. These solutions can be used to construct
efficient and easy to use control variates for variance reduction of estimators
under any intractable target. We demonstrate the new samplers and estimators in
several examples, including high dimensional targets in latent Gaussian models
where we compare against several advanced methods and obtain state-of-the-art
results. We also provide theoretical results regarding geometric ergodicity,
and an optimal scaling analysis that shows the dependence of the optimal
acceptance rate on the Gaussianity of the target.

</details>
