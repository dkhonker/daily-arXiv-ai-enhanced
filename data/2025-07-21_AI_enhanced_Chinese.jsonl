{"id": "2507.13367", "pdf": "https://arxiv.org/pdf/2507.13367", "abs": "https://arxiv.org/abs/2507.13367", "authors": ["Mehrab Hosain", "Rajiv Kapoor"], "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security", "categories": ["cs.CR", "cs.CV", "cs.MM", "eess.IV", "68Q80", "I.4.2"], "comment": "Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol\n  1191. Springer", "summary": "Steganography is the process of embedding secret information discreetly\nwithin a carrier, ensuring secure exchange of confidential data. The Adaptive\nPixel Value Differencing (APVD) steganography method, while effective,\nencounters certain challenges like the \"unused blocks\" issue. This problem can\ncause a decrease in security, compromise the embedding capacity, and lead to\nlower visual quality. This research presents a novel steganographic strategy\nthat integrates APVD with pseudorandom pixel selection to effectively mitigate\nthese issues. The results indicate that the new method outperforms existing\ntechniques in aspects of security, data hiding capacity, and the preservation\nof image quality. Empirical results reveal that the combination of APVD with\npseudorandom pixel selection significantly enhances key image quality metrics\nsuch as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),\nand Structural Similarity Index (SSIM), surpassing other contemporary methods\nin performance. The newly proposed method is versatile, able to handle a\nvariety of cover and secret images in both color and grayscale, thereby\nensuring secure data transmission without compromising the aesthetic quality of\nthe image.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4fe1\u606f\u9690\u85cf\u7b56\u7565\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u50cf\u7d20\u503c\u5dee\u5206\uff08APVD\uff09\u548c\u4f2a\u968f\u673a\u50cf\u7d20\u9009\u62e9\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u672a\u4f7f\u7528\u5757\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u9690\u85cf\u7684\u5b89\u5168\u6027\u3001\u5bb9\u91cf\u548c\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684APVD\u65b9\u6cd5\u9047\u5230\u4e86\u201c\u672a\u4f7f\u7528\u5757\u201d\u7684\u95ee\u9898\uff0c\u8fd9\u53ef\u80fd\u964d\u4f4e\u5b89\u5168\u6027\u3001\u5d4c\u5165\u5bb9\u91cf\u548c\u89c6\u89c9\u8d28\u91cf\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4f2a\u968f\u673a\u50cf\u7d20\u9009\u62e9\u4e0eAPVD\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u672a\u4f7f\u7528\u5757\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u6570\u636e\u9690\u85cf\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u548c\u6570\u636e\u9690\u85cf\u5bb9\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e76\u4e14\u5728PSNR\u3001UIQ\u548cSSIM\u7b49\u5173\u952e\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u5404\u79cd\u5f69\u8272\u548c\u7070\u5ea6\u7684\u5c01\u9762\u548c\u79d8\u5bc6\u56fe\u50cf\uff0c\u5728\u4e0d\u635f\u5bb3\u56fe\u50cf\u7f8e\u5b66\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u786e\u4fdd\u6570\u636e\u4f20\u8f93\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.13505", "pdf": "https://arxiv.org/pdf/2507.13505", "abs": "https://arxiv.org/abs/2507.13505", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "title": "PHASE: Passive Human Activity Simulation Evaluation", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPHASE\uff0c\u4e00\u4e2a\u80fd\u901a\u8fc7\u5206\u6790\u7f51\u7edc\u8fde\u63a5\u65e5\u5fd7\u6765\u533a\u5206\u4eba\u7c7b\u548c\u975e\u4eba\u7c7b\u6d3b\u52a8\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u4f7f\u7528SHAP\u5206\u6790\u63ed\u793a\u771f\u5b9e\u7528\u6237\u7684\u65f6\u95f4\u548c\u884c\u4e3a\u7279\u5f81\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u73af\u5883\u9700\u8981\u771f\u5b9e\u7684\u4eba\u7c7b\u884c\u4e3a\u624d\u80fd\u6709\u6548\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u91cf\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u5408\u6210\u7528\u6237\u89d2\u8272\u7684\u884c\u4e3a\u4fdd\u771f\u5ea6\u3002", "method": "PHASE\u5b8c\u5168\u88ab\u52a8\u8fd0\u884c\uff0c\u4f9d\u8d56\u6807\u51c6\u7f51\u7edc\u76d1\u63a7\uff0c\u65e0\u9700\u7528\u6237\u7aef\u4eea\u5668\u6216\u53ef\u89c1\u76d1\u63a7\u8ff9\u8c61\u3002\u5b83\u5229\u7528Zeek\u7f51\u7edc\u8bbe\u5907\u6536\u96c6\u6240\u6709\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7f51\u7edc\u6d3b\u52a8\uff0c\u907f\u514d\u5f15\u5165\u4e0d\u5fc5\u8981\u7684\u7f51\u7edc\u6d41\u91cf\u6216\u4eba\u5de5\u75d5\u8ff9\u3002\u8be5\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6807\u7b7e\u65b9\u6cd5\uff0c\u5229\u7528\u672c\u5730DNS\u8bb0\u5f55\u5bf9\u7f51\u7edc\u6d41\u91cf\u8fdb\u884c\u5206\u7c7b\uff0c\u4ece\u800c\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u5206\u6790\u3002", "result": "PHASE\u80fd\u591f\u4ee5\u8d85\u8fc790%\u7684\u51c6\u786e\u7387\u533a\u5206\u4eba\u7c7b\u4e0e\u975e\u4eba\u7c7b\u6d3b\u52a8\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u51fa\u5408\u6210\u7528\u6237\u89d2\u8272\u4e2d\u7684\u660e\u663e\u975e\u4eba\u7c7b\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u5408\u6210\u6d3b\u52a8\u7684\u4eba\u7c7b\u76f8\u4f3c\u6027\u3002", "conclusion": "\u901a\u8fc7PHASE\u6846\u67b6\u548c\u6539\u8fdb\u540e\u7684\u914d\u7f6e\uff0c\u53ef\u4ee5\u751f\u6210\u66f4\u771f\u5b9e\u6709\u6548\u7684\u5408\u6210\u7528\u6237\u89d2\u8272\uff0c\u63d0\u9ad8\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u73af\u5883\u7684\u6548\u679c\u3002"}}
{"id": "2507.13591", "pdf": "https://arxiv.org/pdf/2507.13591", "abs": "https://arxiv.org/abs/2507.13591", "authors": ["Sahar Ghoflsaz Ghinani", "Elaheh Sadredini"], "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "15 Pages, 12 Figures", "summary": "Federated Learning (FL) enables collaborative model training without\ncentralizing client data, making it attractive for privacy-sensitive domains.\nWhile existing approaches employ cryptographic techniques such as homomorphic\nencryption, differential privacy, or secure multiparty computation to mitigate\ninference attacks-including model inversion, membership inference, and gradient\nleakage-they often suffer from high computational, communication, or memory\noverheads. Moreover, many methods overlook the confidentiality of the global\nmodel itself, which may be proprietary and sensitive. These challenges limit\nthe practicality of secure FL, especially in cross-silo deployments involving\nlarge datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for\ncross-silo settings. FuSeFL decentralizes training across client pairs using\nlightweight secure multiparty computation (MPC), while confining the server's\nrole to secure aggregation. This design eliminates server bottlenecks, avoids\ndata offloading, and preserves full confidentiality of data, model, and updates\nthroughout training. FuSeFL defends against inference threats, achieves up to\n95% lower communication latency and 50% lower server memory usage, and improves\naccuracy over prior secure FL solutions, demonstrating strong security and\nefficiency at scale.", "AI": {"tldr": "FuSeFL\u662f\u4e00\u4e2a\u5b8c\u5168\u5b89\u5168\u4e14\u53ef\u6269\u5c55\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8de8\u7b52\u4ed3\u73af\u5883\u3002\u5b83\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u5b89\u5168\u805a\u5408\u6765\u4fdd\u62a4\u6570\u636e\u3001\u6a21\u578b\u548c\u66f4\u65b0\u7684\u4fdd\u5bc6\u6027\uff0c\u5e76\u6709\u6548\u62b5\u5fa1\u63a8\u7406\u5a01\u80c1\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u548c\u670d\u52a1\u5668\u5185\u5b58\u4f7f\u7528\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u91c7\u7528\u4e86\u540c\u6001\u52a0\u5bc6\u3001\u5dee\u5206\u9690\u79c1\u6216\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u7b49\u6280\u672f\u6765\u7f13\u89e3\u63a8\u7406\u653b\u51fb\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u4f34\u968f\u7740\u9ad8\u8ba1\u7b97\u3001\u901a\u4fe1\u6216\u5185\u5b58\u5f00\u9500\uff0c\u5e76\u4e14\u8bb8\u591a\u65b9\u6cd5\u5ffd\u7565\u4e86\u5168\u5c40\u6a21\u578b\u672c\u8eab\u7684\u673a\u5bc6\u6027\u3002\u8fd9\u9650\u5236\u4e86\u5b89\u5168\u8054\u90a6\u5b66\u4e60\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5927\u6570\u636e\u96c6\u548c\u4e25\u683c\u5408\u89c4\u8981\u6c42\u7684\u8de8\u7b52\u4ed3\u90e8\u7f72\u4e2d\u3002", "method": "FuSeFL\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u7684\u65b9\u5f0f\u5728\u5ba2\u6237\u7aef\u5bf9\u4e4b\u95f4\u8fdb\u884c\u8bad\u7ec3\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u7684\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff08MPC\uff09\uff0c\u5e76\u9650\u5236\u670d\u52a1\u5668\u7684\u4f5c\u7528\u4ec5\u9650\u4e8e\u5b89\u5168\u805a\u5408\u3002\u8fd9\u79cd\u8bbe\u8ba1\u6d88\u9664\u4e86\u670d\u52a1\u5668\u74f6\u9888\uff0c\u907f\u514d\u4e86\u6570\u636e\u5378\u8f7d\uff0c\u5e76\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e86\u6570\u636e\u3001\u6a21\u578b\u548c\u66f4\u65b0\u7684\u5b8c\u5168\u4fdd\u5bc6\u6027\u3002", "result": "FuSeFL\u80fd\u591f\u9632\u5fa1\u63a8\u7406\u5a01\u80c1\uff0c\u5b9e\u73b0\u9ad8\u8fbe95%\u66f4\u4f4e\u7684\u901a\u4fe1\u5ef6\u8fdf\u548c50%\u66f4\u4f4e\u7684\u670d\u52a1\u5668\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u4e14\u76f8\u6bd4\u4ee5\u524d\u7684\u5b89\u5168\u8054\u90a6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "FuSeFL\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u9002\u5408\u4e8e\u8de8\u7b52\u4ed3\u7684\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6570\u636e\u548c\u6a21\u578b\u5b89\u5168\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6027\u80fd\u3002"}}
{"id": "2507.13598", "pdf": "https://arxiv.org/pdf/2507.13598", "abs": "https://arxiv.org/abs/2507.13598", "authors": ["Amro Abdalla", "Ismail Shaheen", "Dan DeGenaro", "Rupayan Mallick", "Bogdan Raita", "Sarah Adel Bargal"], "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Warning: This paper contains NSFW content. Reader discretion is\n  advised", "summary": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend\ndiffusion models against malicious {F}ine-{T}uning while preserving their\nability to generate safe content. Existing safety mechanisms like safety\ncheckers are easily bypassed, and concept erasure methods fail under\nadversarial fine-tuning. GIFT addresses this by framing immunization as a\nbi-level optimization problem: the upper-level objective degrades the model's\nability to represent harmful concepts using representation noising and\nmaximization, while the lower-level objective preserves performance on safe\ndata. GIFT achieves robust resistance to malicious fine-tuning while\nmaintaining safe generative quality. Experimental results show that our method\nsignificantly impairs the model's ability to re-learn harmful concepts while\nmaintaining performance on safe content, offering a promising direction for\ncreating inherently safer generative models resistant to adversarial\nfine-tuning attacks.", "AI": {"tldr": "\u63d0\u51faGIFT\u6280\u672f\uff0c\u4ee5\u4fdd\u62a4\u6269\u6563\u6a21\u578b\u514d\u53d7\u6076\u610f\u5fae\u8c03\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u5b89\u5168\u5185\u5bb9\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u5f71\u54cd\u5b89\u5168\u5185\u5bb9\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u524a\u5f31\u4e86\u6a21\u578b\u91cd\u65b0\u5b66\u4e60\u6709\u5bb3\u6982\u5ff5\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u673a\u5236\u5982\u5b89\u5168\u68c0\u67e5\u5668\u5bb9\u6613\u88ab\u7ed5\u8fc7\uff0c\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u5fae\u8c03\u4e0b\u5931\u8d25\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u6a21\u578b\u514d\u53d7\u6076\u610f\u5fae\u8c03\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u751f\u6210\u5b89\u5168\u5185\u5bb9\u7684\u80fd\u529b\u3002", "method": "GIFT\u5c06\u514d\u75ab\u95ee\u9898\u8868\u8ff0\u4e3a\u4e00\u4e2a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff1a\u4e0a\u5c42\u76ee\u6807\u901a\u8fc7\u8868\u793a\u566a\u58f0\u548c\u6700\u5927\u5316\u6765\u964d\u4f4e\u6a21\u578b\u8868\u793a\u6709\u5bb3\u6982\u5ff5\u7684\u80fd\u529b\uff1b\u4e0b\u5c42\u76ee\u6807\u5219\u4fdd\u7559\u5b89\u5168\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "result": "GIFT\u5b9e\u73b0\u4e86\u5bf9\u6076\u610f\u5fae\u8c03\u7684\u7a33\u5065\u62b5\u6297\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b89\u5168\u751f\u6210\u8d28\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u524a\u5f31\u4e86\u6a21\u578b\u91cd\u65b0\u5b66\u4e60\u6709\u5bb3\u6982\u5ff5\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b89\u5168\u5185\u5bb9\u7684\u6027\u80fd\u3002", "conclusion": "GIFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u5411\uff0c\u53ef\u4ee5\u521b\u5efa\u672c\u8d28\u4e0a\u66f4\u5b89\u5168\u7684\u751f\u6210\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u62b5\u6297\u5bf9\u6297\u6027\u5fae\u8c03\u653b\u51fb\u3002"}}
{"id": "2507.13354", "pdf": "https://arxiv.org/pdf/2507.13354", "abs": "https://arxiv.org/abs/2507.13354", "authors": ["Zeqian Chen"], "title": "Physical models realizing the transformer architecture of large language models", "categories": ["cs.LG", "cs.AI", "cs.CL", "math-ph", "math.MP"], "comment": "6 pages", "summary": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017})\nmarked the most striking advancement in natural language processing. The\ntransformer is a model architecture relying entirely on an attention mechanism\nto draw global dependencies between input and output. However, we believe there\nis a gap in our theoretical understanding of what the transformer is, and why\nit works physically. In this paper, from a physical perspective on modern\nchips, we construct physical models in the Fock space over the Hilbert space of\ntokens realizing large language models based on a transformer architecture as\nopen quantum systems. Our physical models underlie the transformer architecture\nfor large language models.", "AI": {"tldr": "\u672c\u6587\u4ece\u7269\u7406\u89d2\u5ea6\u51fa\u53d1\uff0c\u57fa\u4e8e\u73b0\u4ee3\u82af\u7247\u548c\u91cf\u5b50\u7cfb\u7edf\u5efa\u7acb\u4e86\u8f6c\u6362\u5668\u67b6\u6784\u7684\u7269\u7406\u6a21\u578b\uff0c\u586b\u8865\u4e86\u5bf9\u8f6c\u6362\u5668\u5de5\u4f5c\u539f\u7406\u7406\u8bba\u7406\u89e3\u7684\u7a7a\u767d\u3002", "motivation": "\u5c3d\u7ba1\u8f6c\u6362\u5668\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5bf9\u5176\u5de5\u4f5c\u539f\u7406\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u4f5c\u8005\u4ece\u73b0\u4ee3\u82af\u7247\u7684\u7269\u7406\u89c6\u89d2\u51fa\u53d1\uff0c\u5728\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u798f\u514b\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u57fa\u4e8e\u8f6c\u6362\u5668\u67b6\u6784\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\uff0c\u6784\u5efa\u7269\u7406\u6a21\u578b\u3002", "result": "\u8fd9\u4e9b\u7269\u7406\u6a21\u578b\u80fd\u591f\u89e3\u91ca\u8f6c\u6362\u5668\u67b6\u6784\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fd0\u4f5c\u673a\u5236\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6c\u6362\u5668\u67b6\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u7269\u7406\u5c42\u9762\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u53d1\u5c55\u8f6c\u6362\u5668\u6280\u672f\u3002"}}
{"id": "2507.13511", "pdf": "https://arxiv.org/pdf/2507.13511", "abs": "https://arxiv.org/abs/2507.13511", "authors": ["Nabil Abdelaziz Ferhat Taleb", "Abdolazim Rezaei", "Raj Atulkumar Patel", "Mehdi Sookhak"], "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) offer significant promise for intelligent\ntraffic management; however, current chain-based systems like TrafficGPT are\nhindered by sequential task execution, high token usage, and poor scalability,\nmaking them inefficient for complex, real-world scenarios. To address these\nlimitations, we propose GraphTrafficGPT, a novel graph-based architecture,\nwhich fundamentally redesigns the task coordination process for LLM-driven\ntraffic applications. GraphTrafficGPT represents tasks and their dependencies\nas nodes and edges in a directed graph, enabling efficient parallel execution\nand dynamic resource allocation. The main idea behind the proposed model is a\nBrain Agent that decomposes user queries, constructs optimized dependency\ngraphs, and coordinates a network of specialized agents for data retrieval,\nanalysis, visualization, and simulation. By introducing advanced context-aware\ntoken management and supporting concurrent multi-query processing, the proposed\narchitecture handles interdependent tasks typical of modern urban mobility\nenvironments. Experimental results demonstrate that GraphTrafficGPT reduces\ntoken consumption by 50.2% and average response latency by 19.0% compared to\nTrafficGPT, while supporting simultaneous multi-query execution with up to\n23.0% improvement in efficiency.", "AI": {"tldr": "GraphTrafficGPT\u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u56fe\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u5e76\u884c\u6267\u884c\u4efb\u52a1\u548c\u52a8\u6001\u8d44\u6e90\u5206\u914d\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u901a\u7ba1\u7406\u4e2d\u7684\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u6bd4TrafficGPT\u51cf\u5c11\u4e8650.2%\u7684token\u6d88\u8017\u548c19.0%\u7684\u5e73\u5747\u54cd\u5e94\u5ef6\u8fdf\uff0c\u5e76\u63d0\u9ad8\u4e86\u591a\u67e5\u8be2\u5904\u7406\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u94fe\u7684\u7cfb\u7edf\uff08\u5982TrafficGPT\uff09\u53d7\u5230\u987a\u5e8f\u4efb\u52a1\u6267\u884c\u3001\u9ad8token\u4f7f\u7528\u7387\u548c\u6269\u5c55\u6027\u5dee\u7684\u5f71\u54cd\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u590d\u6742\u7684\u771f\u5b9e\u4e16\u754c\u573a\u666f\u3002", "method": "GraphTrafficGPT\u5c06\u4efb\u52a1\u53ca\u5176\u4f9d\u8d56\u5173\u7cfb\u8868\u793a\u4e3a\u6709\u5411\u56fe\u4e2d\u7684\u8282\u70b9\u548c\u8fb9\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5e76\u884c\u6267\u884c\u548c\u52a8\u6001\u8d44\u6e90\u5206\u914d\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86Brain Agent\u5206\u89e3\u7528\u6237\u67e5\u8be2\uff0c\u6784\u5efa\u4f18\u5316\u7684\u4f9d\u8d56\u56fe\uff0c\u5e76\u534f\u8c03\u4e13\u95e8\u4ee3\u7406\u7f51\u7edc\u8fdb\u884c\u6570\u636e\u68c0\u7d22\u3001\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u6a21\u62df\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0eTrafficGPT\u76f8\u6bd4\uff0cGraphTrafficGPT\u51cf\u5c11\u4e8650.2%\u7684token\u6d88\u8017\u548c19.0%\u7684\u5e73\u5747\u54cd\u5e94\u5ef6\u8fdf\uff0c\u5e76\u652f\u6301\u540c\u65f6\u591a\u67e5\u8be2\u6267\u884c\uff0c\u6548\u7387\u63d0\u9ad8\u4e8623.0%\u3002", "conclusion": "GraphTrafficGPT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709LLM\u9a71\u52a8\u7684\u4ea4\u901a\u5e94\u7528\u4e2d\u9047\u5230\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u901a\u8fc7\u51cf\u5c11token\u4f7f\u7528\u548c\u652f\u6301\u5e76\u53d1\u591a\u67e5\u8be2\u5904\u7406\u6765\u63d0\u5347\u6548\u7387\u3002"}}
{"id": "2507.13629", "pdf": "https://arxiv.org/pdf/2507.13629", "abs": "https://arxiv.org/abs/2507.13629", "authors": ["Niveen O. Jaffal", "Mohammed Alkhanafseh", "David Mohaisen"], "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Large Language Models (LLMs) are transforming cybersecurity by enabling\nintelligent, adaptive, and automated approaches to threat detection,\nvulnerability assessment, and incident response. With their advanced language\nunderstanding and contextual reasoning, LLMs surpass traditional methods in\ntackling challenges across domains such as IoT, blockchain, and hardware\nsecurity. This survey provides a comprehensive overview of LLM applications in\ncybersecurity, focusing on two core areas: (1) the integration of LLMs into key\ncybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along\nwith mitigation strategies. By synthesizing recent advancements and identifying\nkey limitations, this work offers practical insights and strategic\nrecommendations for leveraging LLMs to build secure, scalable, and future-ready\ncyber defense systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5176\u6574\u5408\u5165\u5173\u952e\u5b89\u5168\u9886\u57df\u548c\u81ea\u8eab\u7684\u8106\u5f31\u6027\u53ca\u7f13\u89e3\u7b56\u7565\uff0c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u548c\u6218\u7565\u5efa\u8bae\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u901a\u8fc7\u667a\u80fd\u5316\u3001\u9002\u5e94\u6027\u548c\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6539\u53d8\u7f51\u7edc\u5b89\u5168\u9886\u57df\uff0c\u89e3\u51b3\u7269\u8054\u7f51\u3001\u533a\u5757\u94fe\u548c\u786c\u4ef6\u5b89\u5168\u7b49\u9886\u57df\u7684\u6311\u6218\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u7efc\u5408\u6700\u8fd1\u7684\u53d1\u5c55\u5e76\u786e\u5b9a\u5173\u952e\u9650\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8eLLM\u5728\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u65b9\u9762\u7684\u5168\u9762\u6982\u8ff0\uff0c\u96c6\u4e2d\u5728\u4e24\u4e2a\u6838\u5fc3\u533a\u57df\uff1a1\uff09\u5c06LLM\u878d\u5165\u5173\u952e\u7f51\u7edc\u5b89\u5168\u9886\u57df\uff1b2\uff09LLM\u672c\u8eab\u7684\u8106\u5f31\u6027\u4ee5\u53ca\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u89c1\u89e3\u548c\u6218\u7565\u6027\u5efa\u8bae\uff0c\u4ee5\u5229\u7528LLM\u5efa\u7acb\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u9762\u5411\u672a\u6765\u7684\u7f51\u7edc\u9632\u5fa1\u7cfb\u7edf\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0cLLM\u4e3a\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u548c\u7b56\u7565\uff0c\u5bf9\u4e8e\u6784\u5efa\u667a\u80fd\u7684\u3001\u81ea\u9002\u5e94\u7684\u81ea\u52a8\u5316\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.13383", "pdf": "https://arxiv.org/pdf/2507.13383", "abs": "https://arxiv.org/abs/2507.13383", "authors": ["Charvi Rastogi", "Tian Huey Teh", "Pushkar Mishra", "Roma Patel", "Ding Wang", "Mark D\u00edaz", "Alicia Parrish", "Aida Mostafazadeh Davani", "Zoe Ashwood", "Michela Paganini", "Vinodkumar Prabhakaran", "Verena Rieser", "Lora Aroyo"], "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "28 pages, 16 figures", "summary": "Current text-to-image (T2I) models often fail to account for diverse human\nexperiences, leading to misaligned systems. We advocate for pluralistic\nalignment, where an AI understands and is steerable towards diverse, and often\nconflicting, human values. Our work provides three core contributions to\nachieve this in T2I models. First, we introduce a novel dataset for Diverse\nIntersectional Visual Evaluation (DIVE) -- the first multimodal dataset for\npluralistic alignment. It enable deep alignment to diverse safety perspectives\nthrough a large pool of demographically intersectional human raters who\nprovided extensive feedback across 1000 prompts, with high replication,\ncapturing nuanced safety perceptions. Second, we empirically confirm\ndemographics as a crucial proxy for diverse viewpoints in this domain,\nrevealing significant, context-dependent differences in harm perception that\ndiverge from conventional evaluations. Finally, we discuss implications for\nbuilding aligned T2I models, including efficient data collection strategies,\nLLM judgment capabilities, and model steerability towards diverse perspectives.\nThis research offers foundational tools for more equitable and aligned T2I\nsystems. Content Warning: The paper includes sensitive content that may be\nharmful.", "AI": {"tldr": "\u5f53\u524d\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5e38\u5e38\u65e0\u6cd5\u8003\u8651\u5230\u591a\u6837\u7684\u4eba\u7c7b\u4f53\u9a8c\uff0c\u5bfc\u81f4\u7cfb\u7edf\u9519\u4f4d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u591a\u5143\u5316\u7684\u5bf9\u9f50\u6982\u5ff5\uff0c\u5e76\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e09\u4e2a\u6838\u5fc3\u8d21\u732e\uff1a\u5f15\u5165\u4e86DIVE\u6570\u636e\u96c6\u3001\u786e\u8ba4\u4e86\u4eba\u53e3\u7edf\u8ba1\u5b66\u4f5c\u4e3a\u8fd9\u4e00\u9886\u57df\u4e2d\u591a\u6837\u5316\u89c2\u70b9\u7684\u91cd\u8981\u4ee3\u7406\uff0c\u4ee5\u53ca\u8ba8\u8bba\u4e86\u6784\u5efa\u5bf9\u9f50T2I\u6a21\u578b\u7684\u5f71\u54cd\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u5f53\u524d\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u672a\u80fd\u5145\u5206\u8003\u8651\u5230\u4e0d\u540c\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\uff0c\u56e0\u6b64\u5e0c\u671b\u80fd\u591f\u521b\u5efa\u4e00\u4e2a\u66f4\u52a0\u591a\u5143\u5316\u548c\u5305\u5bb9\u6027\u7684AI\u7cfb\u7edf\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e09\u9879\u4e3b\u8981\u7684\u65b9\u6cd5\uff1a1. \u5f15\u5165\u4e86DIVE\u6570\u636e\u96c6\uff1b2. \u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u4eba\u53e3\u7edf\u8ba1\u5b66\u5728\u8be5\u9886\u57df\u5185\u662f\u591a\u6837\u5316\u89c2\u70b9\u7684\u91cd\u8981\u4ee3\u7406\uff1b3. \u8ba8\u8bba\u4e86\u6784\u5efa\u5bf9\u9f50T2I\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u7684\u80cc\u666f\u4f1a\u5bfc\u81f4\u5bf9\u4e8e\u5b89\u5168\u6027\u548c\u5371\u5bb3\u7684\u4e0d\u540c\u7406\u89e3\uff0c\u8fd9\u4e9b\u5dee\u5f02\u5bf9\u4e8e\u4f20\u7edf\u7684\u8bc4\u4f30\u65b9\u5f0f\u662f\u4e00\u4e2a\u6311\u6218\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e9b\u6784\u5efa\u66f4\u516c\u5e73\u548c\u5bf9\u9f50\u7684T2I\u7cfb\u7edf\u7684\u5de5\u5177\u548c\u7b56\u7565\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u66f4\u516c\u5e73\u548c\u5bf9\u9f50\u7684T2I\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\uff0c\u5305\u62ec\u9ad8\u6548\u7684\u6570\u636e\u6536\u96c6\u7b56\u7565\uff0cLLM\u5224\u65ad\u80fd\u529b\uff0c\u4ee5\u53ca\u6a21\u578b\u5411\u591a\u6837\u5316\u89c6\u89d2\u7684\u53ef\u5f15\u5bfc\u6027\u3002"}}
{"id": "2507.13541", "pdf": "https://arxiv.org/pdf/2507.13541", "abs": "https://arxiv.org/abs/2507.13541", "authors": ["Shuyue Stella Li", "Melanie Sclar", "Hunter Lang", "Ansong Ni", "Jacqueline He", "Puxin Xu", "Andrew Cohen", "Chan Young Park", "Yulia Tsvetkov", "Asli Celikyilmaz"], "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes", "categories": ["cs.AI"], "comment": "17 pages, 6 tables, 5 figures", "summary": "Personalizing AI systems requires understanding not just what users prefer,\nbut the reasons that underlie those preferences - yet current preference models\ntypically treat human judgment as a black box. We introduce PrefPalette, a\nframework that decomposes preferences into attribute dimensions and tailors its\npreference prediction to distinct social community values in a\nhuman-interpretable manner. PrefPalette operationalizes a cognitive science\nprinciple known as multi-attribute decision making in two ways: (1) a scalable\ncounterfactual attribute synthesis step that involves generating synthetic\ntraining data to isolate for individual attribute effects (e.g., formality,\nhumor, cultural values), and (2) attention-based preference modeling that\nlearns how different social communities dynamically weight these attributes.\nThis approach moves beyond aggregate preference modeling to capture the diverse\nevaluation frameworks that drive human judgment. When evaluated on 45 social\ncommunities from the online platform Reddit, PrefPalette outperforms GPT-4o by\n46.6% in average prediction accuracy. Beyond raw predictive improvements,\nPrefPalette also shed light on intuitive, community-specific profiles:\nscholarly communities prioritize verbosity and stimulation, conflict-oriented\ncommunities value sarcasm and directness, and support-based communities\nemphasize empathy. By modeling the attribute-mediated structure of human\njudgment, PrefPalette delivers both superior preference modeling and\ntransparent, interpretable insights, and serves as a first step toward more\ntrustworthy, value-aware personalized applications.", "AI": {"tldr": "PrefPalette \u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5b83\u5c06\u504f\u597d\u5206\u89e3\u4e3a\u5c5e\u6027\u7ef4\u5ea6\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u7684\u793e\u4ea4\u793e\u533a\u7684\u4ef7\u503c\u89c2\u8c03\u6574\u5176\u504f\u597d\u9884\u6d4b\u3002\u901a\u8fc7\u591a\u5c5e\u6027\u51b3\u7b56\u5236\u5b9a\u539f\u5219\u7684\u4e24\u79cd\u65b9\u5f0f\uff0cPrefPalette \u5728 Reddit \u7684 45 \u4e2a\u793e\u4ea4\u793e\u533a\u4e2d\u8bc4\u4f30\u65f6\uff0c\u6bd4 GPT-4o \u9ad8\u51fa 46.6% \u7684\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u504f\u597d\u6a21\u578b\u901a\u5e38\u5c06\u4eba\u7c7b\u5224\u65ad\u89c6\u4e3a\u9ed1\u7bb1\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u7528\u6237\u504f\u597d\u7684\u80cc\u540e\u539f\u56e0\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4ed6\u4eec\u559c\u6b22\u4ec0\u4e48\u3002", "method": "PrefPalette \u6846\u67b6\u901a\u8fc7\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u4ee5\u9694\u79bb\u4e2a\u522b\u5c5e\u6027\u6548\u679c\uff08\u4f8b\u5982\u6b63\u5f0f\u6027\u3001\u5e7d\u9ed8\u3001\u6587\u5316\u4ef7\u503c\u89c2\uff09\uff0c\u5e76\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u4e0d\u540c\u793e\u4ea4\u793e\u533a\u5982\u4f55\u52a8\u6001\u5730\u5bf9\u8fd9\u4e9b\u5c5e\u6027\u8fdb\u884c\u52a0\u6743\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u5c5e\u6027\u51b3\u7b56\u5236\u5b9a\u3002", "result": "\u5728\u6765\u81ea\u5728\u7ebf\u5e73\u53f0 Reddit \u7684 45 \u4e2a\u793e\u4ea4\u793e\u533a\u4e0a\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0cPrefPalette \u7684\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u6027\u6bd4 GPT-4o \u9ad8\u51fa 46.6%\u3002\u6b64\u5916\uff0cPrefPalette \u8fd8\u63ed\u793a\u4e86\u76f4\u89c2\u7684\u3001\u7279\u5b9a\u4e8e\u793e\u533a\u7684\u7279\u5f81\uff1a\u5b66\u672f\u793e\u533a\u91cd\u89c6\u5197\u957f\u548c\u523a\u6fc0\uff1b\u51b2\u7a81\u5bfc\u5411\u7684\u793e\u533a\u91cd\u89c6\u8bbd\u523a\u548c\u76f4\u63a5\u6027\uff1b\u652f\u6301\u6027\u7684\u793e\u533a\u5f3a\u8c03\u5171\u60c5\u3002", "conclusion": "\u901a\u8fc7\u5efa\u6a21\u7531\u5c5e\u6027\u4ecb\u5bfc\u7684\u4eba\u7c7b\u5224\u65ad\u7ed3\u6784\uff0cPrefPalette \u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u504f\u597d\u5efa\u6a21\uff0c\u8fd8\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\uff0c\u662f\u8fc8\u5411\u66f4\u503c\u5f97\u4fe1\u8d56\u3001\u66f4\u5177\u4ef7\u503c\u610f\u8bc6\u7684\u4e2a\u6027\u5316\u5e94\u7528\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2507.13686", "pdf": "https://arxiv.org/pdf/2507.13686", "abs": "https://arxiv.org/abs/2507.13686", "authors": ["Yulin Chen", "Haoran Li", "Yuexin Li", "Yue Liu", "Yangqiu Song", "Bryan Hooi"], "title": "TopicAttack: An Indirect Prompt Injection Attack via Topic Transition", "categories": ["cs.CR"], "comment": "19 pages", "summary": "Large language models (LLMs) have shown remarkable performance across a range\nof NLP tasks. However, their strong instruction-following capabilities and\ninability to distinguish instructions from data content make them vulnerable to\nindirect prompt injection attacks. In such attacks, instructions with malicious\npurposes are injected into external data sources, such as web documents. When\nLLMs retrieve this injected data through tools, such as a search engine and\nexecute the injected instructions, they provide misled responses. Recent attack\nmethods have demonstrated potential, but their abrupt instruction injection\noften undermines their effectiveness. Motivated by the limitations of existing\nattack methods, we propose TopicAttack, which prompts the LLM to generate a\nfabricated conversational transition prompt that gradually shifts the topic\ntoward the injected instruction, making the injection smoother and enhancing\nthe plausibility and success of the attack. Through comprehensive experiments,\nTopicAttack achieves state-of-the-art performance, with an attack success rate\n(ASR) over 90\\% in most cases, even when various defense methods are applied.\nWe further analyze its effectiveness by examining attention scores. We find\nthat a higher injected-to-original attention ratio leads to a greater success\nprobability, and our method achieves a much higher ratio than the baseline\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u653b\u51fb\u65b9\u6cd5TopicAttack\uff0c\u901a\u8fc7\u751f\u6210\u9010\u6b65\u8f6c\u79fb\u8bdd\u9898\u7684\u63d0\u793a\uff0c\u5b9e\u73b0\u66f4\u5e73\u6ed1\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc790%\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u9632\u5fa1\u65b9\u6cd5\u4e0b\u4ecd\u7136\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\u7531\u4e8e\u7a81\u7136\u7684\u6307\u4ee4\u6ce8\u5165\u65b9\u5f0f\uff0c\u5176\u6709\u6548\u6027\u53d7\u5230\u4e86\u9650\u5236\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u5e76\u63d0\u9ad8\u653b\u51fb\u7684\u6210\u529f\u7387\u548c\u53ef\u4fe1\u5ea6\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u540d\u4e3aTopicAttack\uff0c\u5b83\u4fc3\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4e00\u4e2a\u865a\u6784\u7684\u5bf9\u8bdd\u8fc7\u6e21\u63d0\u793a\uff0c\u8be5\u63d0\u793a\u80fd\u591f\u9010\u6e10\u5c06\u8bdd\u9898\u8f6c\u79fb\u5230\u6ce8\u5165\u7684\u6307\u4ee4\u4e0a\uff0c\u4ece\u800c\u4f7f\u6ce8\u5165\u8fc7\u7a0b\u66f4\u52a0\u5e73\u6ed1\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0cTopicAttack\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u8d85\u8fc790%\uff0c\u5373\u4f7f\u9762\u5bf9\u4e0d\u540c\u7684\u9632\u5fa1\u63aa\u65bd\u4e5f\u8868\u73b0\u826f\u597d\u3002\u5206\u6790\u6ce8\u610f\u529b\u5206\u6570\u53d1\u73b0\uff0c\u66f4\u9ad8\u7684\u6ce8\u5165\u5230\u539f\u59cb\u6ce8\u610f\u529b\u6bd4\u7387\u5bfc\u81f4\u66f4\u5927\u7684\u6210\u529f\u6982\u7387\u3002", "conclusion": "TopicAttack\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6bd4\u4f8b\u7684\u6ce8\u5165\u5230\u539f\u59cb\u6ce8\u610f\u529b\u6bd4\u7387\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u653b\u51fb\u7684\u6210\u529f\u7387\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.13393", "pdf": "https://arxiv.org/pdf/2507.13393", "abs": "https://arxiv.org/abs/2507.13393", "authors": ["Jakub Strawa", "Jarek Duda"], "title": "Improving KAN with CDF normalization to quantiles", "categories": ["cs.LG"], "comment": "7 pages, 9 figures", "summary": "Data normalization is crucial in machine learning, usually performed by\nsubtracting the mean and dividing by standard deviation, or by rescaling to a\nfixed range. In copula theory, popular in finance, there is used normalization\nto approximately quantiles by transforming x to CDF(x) with estimated CDF\n(cumulative distribution function) to nearly uniform distribution in [0,1],\nallowing for simpler representations which are less likely to overfit. It seems\nnearly unknown in machine learning, therefore, we would like to present some\nits advantages on example of recently popular Kolmogorov-Arnold Networks\n(KANs), improving predictions from Legendre-KAN by just switching rescaling to\nCDF normalization. Additionally, in HCR interpretation, weights of such neurons\nare mixed moments providing local joint distribution models, allow to propagate\nalso probability distributions, and change propagation direction.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5c06Copula\u7406\u8bba\u4e2d\u7684CDF\u5f52\u4e00\u5316\u65b9\u6cd5\u5e94\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u9886\u57df\uff0c\u7279\u522b\u662fKolmogorov-Arnold Networks (KANs)\uff0c\u4ee5\u6539\u5584\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u4f5c\u8005\u89c2\u5bdf\u5230\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u6570\u636e\u5f52\u4e00\u5316\u662f\u91cd\u8981\u7684\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u800c\u6765\u81ea\u91d1\u878d\u9886\u57df\u7684Copula\u7406\u8bba\u6240\u4f7f\u7528\u7684CDF\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\u51e0\u4e4e\u4e0d\u4e3a\u4eba\u77e5\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u5c55\u793aCDF\u5f52\u4e00\u5316\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4f18\u52bf\u3002", "method": "\u901a\u8fc7\u5c06\u4f20\u7edf\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u66ff\u6362\u4e3aCDF\uff08\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff09\u5f52\u4e00\u5316\uff0c\u5e76\u5e94\u7528\u5230Kolmogorov-Arnold Networks (KANs) \u4e2d\uff0c\u7279\u522b\u662f\u5728Legendre-KAN\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u5728HCR\u89e3\u91ca\u6846\u67b6\u4e0b\uff0c\u8fd9\u79cd\u795e\u7ecf\u5143\u7684\u6743\u91cd\u88ab\u7406\u89e3\u4e3a\u6df7\u5408\u77e9\uff0c\u63d0\u4f9b\u5c40\u90e8\u8054\u5408\u5206\u5e03\u6a21\u578b\uff0c\u5141\u8bb8\u4f20\u64ad\u6982\u7387\u5206\u5e03\u5e76\u6539\u53d8\u4f20\u64ad\u65b9\u5411\u3002", "result": "\u4f7f\u7528CDF\u5f52\u4e00\u5316\u6539\u8fdb\u4e86Legendre-KAN\u7684\u9884\u6d4b\u6027\u80fd\u3002\u540c\u65f6\uff0c\u5b83\u8fd8\u63d0\u4f9b\u4e86\u80fd\u591f\u8868\u793a\u6982\u7387\u5206\u5e03\u4f20\u64ad\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u53ef\u4ee5\u6539\u53d8\u4f20\u64ad\u7684\u65b9\u5411\u3002", "conclusion": "CDF\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u7279\u522b\u662fKANs\u4e2d\u663e\u793a\u51fa\u4e86\u5176\u72ec\u7279\u7684\u4f18\u52bf\uff0c\u53ef\u4ee5\u7b80\u5316\u6a21\u578b\u8868\u793a\uff0c\u51cf\u5c11\u8fc7\u62df\u5408\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.13550", "pdf": "https://arxiv.org/pdf/2507.13550", "abs": "https://arxiv.org/abs/2507.13550", "authors": ["Eduardo C. Garrido-Merch\u00e1n", "Cristina Puente"], "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.SC"], "comment": null, "summary": "The development of large language models (LLMs) has successfully transformed\nknowledge-based systems such as open domain question nswering, which can\nautomatically produce vast amounts of seemingly coherent information. Yet,\nthose models have several disadvantages like hallucinations or confident\ngeneration of incorrect or unverifiable facts. In this paper, we introduce a\nnew approach to the development of expert systems using LLMs in a controlled\nand transparent way. By limiting the domain and employing a well-structured\nprompt-based extraction approach, we produce a symbolic representation of\nknowledge in Prolog, which can be validated and corrected by human experts.\nThis approach also guarantees interpretability, scalability and reliability of\nthe developed expert systems. Via quantitative and qualitative experiments with\nClaude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic\ncoherence on our generated knowledge bases. We present a transparent hybrid\nsolution that combines the recall capacity of LLMs with the precision of\nsymbolic systems, thereby laying the foundation for dependable AI applications\nin sensitive domains.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u4e13\u5bb6\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9650\u5236\u9886\u57df\u548c\u4f7f\u7528\u7ed3\u6784\u5316\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u63d0\u53d6\u65b9\u6cd5\uff0c\u751f\u6210\u53ef\u4ee5\u7528Prolog\u8868\u793a\u5e76\u7531\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1\u548c\u7ea0\u6b63\u7684\u77e5\u8bc6\u3002\u8fd9\u79cd\u65b9\u6cd5\u786e\u4fdd\u4e86\u5f00\u53d1\u7684\u4e13\u5bb6\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u4e8b\u5b9e\u7684\u4e25\u683c\u9075\u5b88\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u77e5\u8bc6\u578b\u7cfb\u7edf\u5982\u5f00\u653e\u57df\u95ee\u7b54\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u5b58\u5728\u4e00\u4e9b\u7f3a\u70b9\uff0c\u4f8b\u5982\u4ea7\u751f\u5e7b\u89c9\u6216\u81ea\u4fe1\u5730\u751f\u6210\u9519\u8bef\u6216\u65e0\u6cd5\u9a8c\u8bc1\u7684\u4e8b\u5b9e\u3002", "method": "\u901a\u8fc7\u9650\u5236\u9886\u57df\u548c\u91c7\u7528\u7ed3\u6784\u5316\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u63d0\u53d6\u65b9\u6cd5\uff0c\u5c06\u77e5\u8bc6\u4ee5Prolog\u7684\u5f62\u5f0f\u7b26\u53f7\u5316\u8868\u793a\uff0c\u53ef\u4ee5\u7531\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u9a8c\u8bc1\u548c\u7ea0\u6b63\u3002", "result": "\u901a\u8fc7\u4e0eClaude Sonnet 3.7\u548cGPT-4.1\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u5b9e\u9a8c\uff0c\u8868\u660e\u751f\u6210\u7684\u77e5\u8bc6\u5e93\u5bf9\u4e8b\u5b9e\u7684\u4e25\u683c\u9075\u5b88\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u900f\u660e\u7684\u6df7\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u80fd\u529b\u548c\u7b26\u53f7\u7cfb\u7edf\u7684\u7cbe\u786e\u6027\uff0c\u4e3a\u654f\u611f\u9886\u57df\u7684\u53ef\u9760AI\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u91cf\u5b50\u8ba1\u7b97\u5bf9\u7ecf\u5178\u533a\u5757\u94fe\u7cfb\u7edf\u7684\u5a01\u80c1\uff0c\u4ee5\u53ca\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u7684\u4e24\u5927\u7814\u7a76\u65b9\u5411\uff1a\u540e\u91cf\u5b50\u533a\u5757\u94fe\u548c\u91cf\u5b50\u533a\u5757\u94fe\u3002\u5b83\u5206\u6790\u4e86\u8fd9\u4e24\u79cd\u65b9\u6848\u7684\u52a0\u5bc6\u57fa\u7840\u3001\u67b6\u6784\u8bbe\u8ba1\u548c\u5b9e\u65bd\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u6280\u672f\u63d0\u6848\u7684\u6bd4\u8f83\u6982\u8ff0\uff0c\u5f3a\u8c03\u4e86\u5b89\u5168\u3001\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u6307\u51fa\u4e86\u786c\u4ef6\u3001\u5171\u8bc6\u548c\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u5b83\u5bf9\u4f20\u7edf\u533a\u5757\u94fe\u7cfb\u7edf\u6784\u6210\u4e86\u57fa\u672c\u98ce\u9669\uff0c\u7279\u522b\u662f\u524a\u5f31\u4e86\u5e38\u7528\u7684\u52a0\u5bc6\u539f\u8bed\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u79cd\u5a01\u80c1\uff0c\u7814\u7a76\u4eba\u5458\u63a2\u7d22\u4e86\u4e24\u79cd\u4e3b\u8981\u65b9\u5411\uff1a\u4e00\u662f\u91c7\u7528\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u7684\u540e\u91cf\u5b50\u533a\u5757\u94fe\uff0c\u4e8c\u662f\u5229\u7528\u91cf\u5b50\u7279\u6027\u5982\u7ea0\u7f20\u548c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7684\u91cf\u5b50\u533a\u5757\u94fe\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u4e86\u4e0a\u8ff0\u4e24\u4e2a\u7814\u7a76\u9886\u57df\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u5305\u62ec\u5b83\u4eec\u7684\u52a0\u5bc6\u57fa\u7840\u3001\u67b6\u6784\u8bbe\u8ba1\u53ca\u5b9e\u73b0\u6311\u6218\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u5bf9\u4e0d\u540c\u6280\u672f\u65b9\u6848\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u5728\u5b89\u5168\u3001\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u65b9\u9762\u7684\u6298\u8877\u3002", "result": "\u7ed3\u679c\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u4e14\u5168\u9762\u7684\u53c2\u8003\u6587\u732e\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u91cf\u5b50\u65f6\u4ee3\u4e0b\u5b89\u5168\u533a\u5757\u94fe\u7cfb\u7edf\u7684\u53d1\u5c55\u3002\u6587\u4e2d\u4e5f\u660e\u786e\u4e86\u5f53\u524d\u5b58\u5728\u7684\u5f00\u653e\u7814\u7a76\u95ee\u9898\uff0c\u6d89\u53ca\u786c\u4ef6\u3001\u5171\u8bc6\u673a\u5236\u548c\u7f51\u7edc\u8bbe\u8ba1\u7b49\u591a\u4e2a\u65b9\u9762\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u5c3d\u7ba1\u5b58\u5728\u8bb8\u591a\u6280\u672f\u548c\u5b9e\u65bd\u4e0a\u7684\u6311\u6218\uff0c\u4f46\u9488\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u7684\u533a\u5757\u94fe\u7814\u7a76\u6b63\u5728\u53d6\u5f97\u8fdb\u5c55\u3002\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u89e3\u51b3\u5b89\u5168\u3001\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u514b\u670d\u786c\u4ef6\u3001\u5171\u8bc6\u548c\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u7684\u96be\u9898\u3002"}}
{"id": "2507.13399", "pdf": "https://arxiv.org/pdf/2507.13399", "abs": "https://arxiv.org/abs/2507.13399", "authors": ["Mert Sehri", "Zehui Hua", "Francisco de Assis Boldt", "Patrick Dumond"], "title": "Selective Embedding for Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u52a0\u8f7d\u7b56\u7565\u2014\u2014\u9009\u62e9\u6027\u5d4c\u5165\uff0c\u5b83\u901a\u8fc7\u6a21\u4eff\u8ba4\u77e5\u5fc3\u7406\u5b66\u4e2d\u7684\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\uff0c\u4ea4\u66ff\u4f7f\u7528\u6765\u81ea\u591a\u4e2a\u6765\u6e90\u7684\u77ed\u6570\u636e\u6bb5\u6765\u51cf\u5c11\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002\u5728\u516d\u4e2a\u65f6\u95f4\u57df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u51fa\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u548c\u663e\u8457\u51cf\u5c11\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u9002\u7528\u4e8e\u9700\u8981\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u7684\u591a\u6e90\u6570\u636e\u590d\u6742\u7cfb\u7edf\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5bf9\u8f93\u5165\u6570\u636e\u654f\u611f\uff0c\u5728\u975e\u5e73\u7a33\u6761\u4ef6\u4e0b\u548c\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u7684\u6027\u80fd\u5f80\u5f80\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u65f6\u57df\u6570\u636e\u65f6\u3002\u4f20\u7edf\u7684\u5355\u901a\u9053\u6216\u591a\u6e90\u5e76\u884c\u6570\u636e\u52a0\u8f7d\u7b56\u7565\u8981\u4e48\u9650\u5236\u6cdb\u5316\u80fd\u529b\uff0c\u8981\u4e48\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u9009\u62e9\u6027\u5d4c\u5165\u662f\u4e00\u79cd\u65b0\u7684\u6570\u636e\u52a0\u8f7d\u7b56\u7565\uff0c\u5b83\u5728\u4e00\u4e2a\u8f93\u5165\u901a\u9053\u5185\u4ea4\u66ff\u4f7f\u7528\u6765\u81ea\u591a\u4e2a\u6765\u6e90\u7684\u77ed\u6570\u636e\u6bb5\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u8ba4\u77e5\u5fc3\u7406\u5b66\uff0c\u65e8\u5728\u6a21\u62df\u4eba\u7c7b\u7684\u4fe1\u606f\u5904\u7406\u8fc7\u7a0b\u4ee5\u51cf\u5c11\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u516d\u4e2a\u65f6\u95f4\u57df\u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e2d\u90fd\u80fd\u4fdd\u6301\u8f83\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "\u9009\u62e9\u6027\u5d4c\u5165\u4e3a\u5177\u6709\u591a\u4e2a\u6570\u636e\u6e90\u7684\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533b\u7597\u4fdd\u5065\u3001\u91cd\u578b\u673a\u68b0\u3001\u6d77\u6d0b\u3001\u94c1\u8def\u548c\u519c\u4e1a\u7b49\u9886\u57df\uff0c\u8fd9\u4e9b\u9886\u57df\u5bf9\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u6709\u4e25\u683c\u8981\u6c42\u3002"}}
{"id": "2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "title": "Why Isn't Relational Learning Taking Over the World?", "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices)", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5173\u7cfb\u5b66\u4e60\u7684\u91cd\u8981\u6027\u53ca\u5f53\u524d\u672a\u5f97\u5230\u5e94\u6709\u91cd\u89c6\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u63d0\u5347\u5176\u5730\u4f4d\u7684\u5efa\u8bae\u3002", "motivation": "\u4f5c\u8005\u89c2\u5bdf\u5230\u5c3d\u7ba1\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u5927\u591a\u4ee5\u5173\u7cfb\u578b\u683c\u5f0f\u5b58\u5728\uff0c\u4f46AI\u7814\u7a76\u548c\u5e94\u7528\u5374\u591a\u96c6\u4e2d\u4e8e\u50cf\u7d20\u3001\u6587\u672c\u7b49\u611f\u77e5\u6216\u63cf\u8ff0\u5c42\u9762\u7684\u6570\u636e\u5efa\u6a21\uff0c\u56e0\u6b64\u5e0c\u671b\u5f3a\u8c03\u5173\u7cfb\u5b66\u4e60\u7684\u4ef7\u503c\u5e76\u4fc3\u8fdb\u5176\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f53\u524d\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e0e\u5b9e\u9645\u5546\u4e1a\u6570\u636e\u5f62\u5f0f\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u89e3\u91ca\u5173\u7cfb\u5b66\u4e60\u9886\u57df\u7684\u73b0\u72b6\u3002", "result": "\u6307\u51fa\u5173\u7cfb\u5b66\u4e60\u672a\u80fd\u5e7f\u6cdb\u6d41\u884c\u7684\u539f\u56e0\u5728\u4e8e\u5176\u9002\u7528\u8303\u56f4\u6709\u9650\u4ee5\u53ca\u5bf9\u5173\u7cfb\u7684\u9650\u5236\u8f83\u591a\u3002", "conclusion": "\u4e3a\u4e86\u4f7f\u5173\u7cfb\u5b66\u4e60\u83b7\u5f97\u5e94\u6709\u7684\u91cd\u8981\u6027\uff0c\u9700\u8981\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u5173\u7cfb\u6570\u636e\u65f6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.13926", "pdf": "https://arxiv.org/pdf/2507.13926", "abs": "https://arxiv.org/abs/2507.13926", "authors": ["Libor Pol\u010d\u00e1k", "Giorgio Maone", "Michael McMahon", "Martin Bedn\u00e1\u0159"], "title": "Developers Insight On Manifest v3 Privacy and Security Webextensions", "categories": ["cs.CR", "cs.CY"], "comment": "WEBIST'25, Marbella, Spain", "summary": "Webextensions can improve web browser privacy, security, and user experience.\nThe APIs offered by the browser to webextensions affect possible functionality.\nCurrently, Chrome transitions to a modified set of APIs called Manifest v3.\nThis paper studies the challenges and opportunities of Manifest v3 with an\nin-depth structured qualitative research. Even though some projects observed\npositive effects, a majority expresses concerns over limited benefits to users,\nremoval of crucial APIs, or the need to find workarounds. Our findings indicate\nthat the transition affects different types of webextensions differently; some\ncan migrate without losing functionality, while other projects remove\nfunctionality or decline to update. The respondents identified several critical\nmissing APIs, including reliable APIs to inject content scripts, APIs for\nstoring confidential content, and others.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Manifest v3\u5bf9Web\u6269\u5c55\u5e26\u6765\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u53d1\u73b0\u5176\u5f71\u54cd\u56e0\u9879\u76ee\u800c\u5f02\uff0c\u90e8\u5206\u5173\u952eAPI\u7684\u7f3a\u5931\u6210\u4e3a\u4e3b\u8981\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u6d4f\u89c8\u5668\u5411Manifest v3\u8fc7\u6e21\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u65b0API\u96c6\u5bf9Web\u6269\u5c55\u529f\u80fd\u6027\u7684\u6311\u6218\u548c\u673a\u9047\u3002", "method": "\u901a\u8fc7\u6df1\u5165\u7ed3\u6784\u5316\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u5206\u6790Manifest v3\u7684\u5f71\u54cd\u3002", "result": "\u5927\u591a\u6570\u9879\u76ee\u8868\u8fbe\u4e86\u5bf9\u7528\u6237\u5229\u76ca\u6709\u9650\u3001\u5173\u952eAPI\u79fb\u9664\u6216\u9700\u8981\u5bfb\u627e\u66ff\u4ee3\u65b9\u6848\u7684\u62c5\u5fe7\uff1b\u4e0d\u540c\u7c7b\u578b\u7684Web\u6269\u5c55\u53d7\u5f71\u54cd\u7a0b\u5ea6\u4e0d\u540c\uff0c\u4e00\u4e9b\u53ef\u4ee5\u65e0\u7f1d\u8fc1\u79fb\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u9700\u79fb\u9664\u529f\u80fd\u6216\u62d2\u7edd\u66f4\u65b0\u3002", "conclusion": "Manifest v3\u7684\u8f6c\u6362\u5bf9Web\u6269\u5c55\u6709\u4e0d\u540c\u7a0b\u5ea6\u7684\u5f71\u54cd\uff0c\u67d0\u4e9b\u5173\u952eAPI\u7684\u7f3a\u4e4f\u662f\u4e3b\u8981\u95ee\u9898\u3002"}}
{"id": "2507.13413", "pdf": "https://arxiv.org/pdf/2507.13413", "abs": "https://arxiv.org/abs/2507.13413", "authors": ["Aleksey Lapin", "Igor Hromov", "Stanislav Chumakov", "Mile Mitrovic", "Dmitry Simakov", "Nikolay O. Nikitin", "Andrey V. Savchenko"], "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data", "categories": ["cs.LG"], "comment": "11 pages, 2 figures", "summary": "AutoML has advanced in handling complex tasks using the integration of LLMs,\nyet its efficiency remains limited by dependence on specific underlying tools.\nIn this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for\ntasks with tabular data, which combines an LLM-based code generation with\nseveral AutoML tools. Our approach improves the flexibility and robustness of\npipeline design, outperforming state-of-the-art open-source solutions on\nseveral data science tasks from Kaggle. The code of LightAutoDS-Tab is\navailable in the open repository https://github.com/sb-ai-lab/LADS", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aLightAutoDS-Tab\u7684\u591aAutoML\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u5904\u7406\u8868\u683c\u6570\u636e\u4efb\u52a1\u3002\u5b83\u7ed3\u5408\u4e86\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u548c\u51e0\u79cdAutoML\u5de5\u5177\uff0c\u63d0\u9ad8\u4e86\u7ba1\u9053\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1AutoML\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5176\u6548\u7387\u4ecd\u7136\u53d7\u5230\u5bf9\u7279\u5b9a\u5e95\u5c42\u5de5\u5177\u7684\u4f9d\u8d56\u7684\u9650\u5236\u3002\u4e3a\u4e86\u63d0\u9ad8\u5904\u7406\u8868\u683c\u6570\u636e\u4efb\u52a1\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u514b\u670d\u8fd9\u79cd\u4f9d\u8d56\u6027\u3002", "method": "\u5f15\u5165\u4e86LightAutoDS-Tab\uff0c\u4e00\u4e2a\u7528\u4e8e\u8868\u683c\u6570\u636e\u4efb\u52a1\u7684\u591aAutoML\u4ee3\u7406\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5c06\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u4e0e\u591a\u79cdAutoML\u5de5\u5177\u76f8\u7ed3\u5408\u3002", "result": "\u5728\u6765\u81eaKaggle\u7684\u591a\u4e2a\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "LightAutoDS-Tab\u63d0\u9ad8\u4e86\u7ba1\u9053\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.13625", "pdf": "https://arxiv.org/pdf/2507.13625", "abs": "https://arxiv.org/abs/2507.13625", "authors": ["Yuxin Zhang", "Xi Wang", "Mo Hu", "Zhenyu Zhang"], "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety", "categories": ["cs.AI"], "comment": "19 pages, 13 figures", "summary": "Information retrieval and question answering from safety regulations are\nessential for automated construction compliance checking but are hindered by\nthe linguistic and structural complexity of regulatory text. Many\ncompliance-related queries are multi-hop, requiring synthesis of information\nacross interlinked clauses. This poses a challenge for traditional\nretrieval-augmented generation (RAG) systems. To overcome this, we introduce\nBifrostRAG: a dual-graph RAG-integrated system that explicitly models both\nlinguistic relationships (via an Entity Network Graph) and document structure\n(via a Document Navigator Graph). This architecture powers a hybrid retrieval\nmechanism that combines graph traversal with vector-based semantic search,\nenabling large language models to reason over both the meaning and the\nstructure of the text. Evaluation on a multi-hop question dataset shows that\nBifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1\nscore of 87.3 percent. These results significantly outperform vector-only and\ngraph-only RAG baselines that represent current leading approaches. Error\nanalysis further highlights the comparative advantages of our hybrid method\nover single-modality RAGs. These findings establish BifrostRAG as a robust\nknowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid\nretrieval mechanism offers a transferable blueprint for navigating complex\ntechnical documents across knowledge-intensive engineering domains.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edfBifrostRAG\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u7ed3\u5408\u5b9e\u4f53\u7f51\u7edc\u56fe\u548c\u6587\u6863\u5bfc\u822a\u56fe\u6765\u6539\u5584\u6cd5\u89c4\u6587\u672c\u7684\u591a\u8df3\u95ee\u9898\u56de\u7b54\u3002\u5b83\u5728\u591a\u8df3\u95ee\u9898\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5411\u91cf\u6216\u56fe\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4fe1\u606f\u68c0\u7d22\u548c\u95ee\u7b54\u7cfb\u7edf\u5bf9\u4e8e\u81ea\u52a8\u5316\u5efa\u8bbe\u5408\u89c4\u6027\u68c0\u67e5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6cd5\u89c4\u6587\u672c\u7684\u8bed\u8a00\u548c\u7ed3\u6784\u590d\u6742\u6027\u7ed9\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "BifrostRAG\u662f\u4e00\u4e2a\u53cc\u56feRAG\u96c6\u6210\u7cfb\u7edf\uff0c\u5b83\u660e\u786e\u5730\u5efa\u6a21\u4e86\u8bed\u8a00\u5173\u7cfb\uff08\u901a\u8fc7\u5b9e\u4f53\u7f51\u7edc\u56fe\uff09\u548c\u6587\u6863\u7ed3\u6784\uff08\u901a\u8fc7\u6587\u6863\u5bfc\u822a\u56fe\uff09\u3002\u8be5\u67b6\u6784\u652f\u6301\u4e00\u79cd\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u5c06\u56fe\u904d\u5386\u4e0e\u57fa\u4e8e\u5411\u91cf\u7684\u8bed\u4e49\u641c\u7d22\u76f8\u7ed3\u5408\u3002", "result": "\u8bc4\u4f30\u663e\u793aBifrostRAG\u8fbe\u5230\u4e8692.8%\u7684\u7cbe\u786e\u5ea6\uff0c85.5%\u7684\u53ec\u56de\u7387\uff0c\u4ee5\u53ca87.3%\u7684F1\u5f97\u5206\uff0c\u8fd9\u4e9b\u7ed3\u679c\u660e\u663e\u4f18\u4e8e\u5f53\u524d\u9886\u5148\u7684\u5411\u91cf\u6216\u56feRAG\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "BifrostRAG\u88ab\u786e\u7acb\u4e3a\u5f3a\u5927\u7684LLM\u9a71\u52a8\u7684\u5408\u89c4\u6027\u68c0\u67e5\u77e5\u8bc6\u5f15\u64ce\u3002\u5176\u53cc\u56fe\u6df7\u5408\u68c0\u7d22\u673a\u5236\u4e3a\u8de8\u77e5\u8bc6\u5bc6\u96c6\u578b\u5de5\u7a0b\u9886\u57df\u7684\u590d\u6742\u6280\u672f\u6587\u6863\u63d0\u4f9b\u4e86\u53ef\u8f6c\u79fb\u7684\u8bbe\u8ba1\u84dd\u56fe\u3002"}}
{"id": "2507.13932", "pdf": "https://arxiv.org/pdf/2507.13932", "abs": "https://arxiv.org/abs/2507.13932", "authors": ["Feng Yu", "Ryan Laird"], "title": "Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology", "categories": ["cs.CR", "cs.DB"], "comment": null, "summary": "The rise of blockchain and Digital Ledger Technology (DLT) has gained wide\ntraction. Instead of relying on a traditional centralized data authority, a\nblockchain system consists of digitally entangled block data shared across a\ndistributed network. The specially designed chain data structure and its\nconsensus mechanism protect blockchain data from being tampered by unauthorized\nadversaries. However, implementing a full-fledged blockchain system to protect\na database can be technically cumbersome. In this work, we introduce an\nin-database design, named chain table, to protect data integrity without the\nneed for a blockchain system. It features a succinct design without significant\ntechnology barriers or storage overhead. To realize rigorous data security, we\nalso propose a set of data writing principles for the chain table. We prove\nthat the chain table, together with the data writing principles, will guarantee\nflexible data integrity, named table-level data integrity (TDI).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3achain table\u7684\u6570\u636e\u5e93\u5185\u8bbe\u8ba1\uff0c\u4ee5\u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\uff0c\u65e0\u9700\u4f7f\u7528\u533a\u5757\u94fe\u7cfb\u7edf\u3002", "motivation": "\u5b9e\u65bd\u5b8c\u6574\u7684\u533a\u5757\u94fe\u7cfb\u7edf\u4ee5\u4fdd\u62a4\u6570\u636e\u5e93\u5728\u6280\u672f\u4e0a\u53ef\u80fd\u5f88\u7e41\u7410\u3002\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\u5e76\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3achain table\u7684\u6570\u636e\u5e93\u5185\u8bbe\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u6570\u636e\u5199\u5165\u539f\u5219\u3002", "result": "\u8bc1\u660e\u4e86chain table\u52a0\u4e0a\u6570\u636e\u5199\u5165\u539f\u5219\u53ef\u4ee5\u4fdd\u8bc1\u7075\u6d3b\u7684\u6570\u636e\u5b8c\u6574\u6027\uff0c\u79f0\u4e3a\u8868\u7ea7\u6570\u636e\u5b8c\u6574\u6027\uff08TDI\uff09\u3002", "conclusion": "chain table\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u6d01\u7684\u8bbe\u8ba1\uff0c\u5728\u6ca1\u6709\u91cd\u5927\u6280\u672f\u969c\u788d\u6216\u5b58\u50a8\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u4fdd\u62a4\u6570\u636e\u5b8c\u6574\u6027\u3002"}}
{"id": "2507.13414", "pdf": "https://arxiv.org/pdf/2507.13414", "abs": "https://arxiv.org/abs/2507.13414", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Gauge Flow Models", "categories": ["cs.LG", "cs.AI", "math.DG"], "comment": null, "summary": "This paper introduces Gauge Flow Models, a novel class of Generative Flow\nModels. These models incorporate a learnable Gauge Field within the Flow\nOrdinary Differential Equation (ODE). A comprehensive mathematical framework\nfor these models, detailing their construction and properties, is provided.\nExperiments using Flow Matching on Gaussian Mixture Models demonstrate that\nGauge Flow Models yields significantly better performance than traditional Flow\nModels of comparable or even larger size. Additionally, unpublished research\nindicates a potential for enhanced performance across a broader range of\ngenerative tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6d41\u6a21\u578b\u2014\u2014\u89c4\u8303\u6d41\u6a21\u578b\uff08Gauge Flow Models\uff09\uff0c\u5176\u5728\u6d41\u5e38\u5fae\u5206\u65b9\u7a0b\u4e2d\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u7684\u89c4\u8303\u573a\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u76f8\u8f83\u4e8e\u4f20\u7edf\u6d41\u6a21\u578b\u6027\u80fd\u66f4\u597d\uff0c\u5e76\u4e14\u53ef\u80fd\u5728\u66f4\u5e7f\u6cdb\u7684\u751f\u6210\u4efb\u52a1\u4e2d\u63d0\u4f9b\u589e\u5f3a\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u751f\u6210\u6d41\u6a21\u578b\u7684\u6027\u80fd\u5e76\u63a2\u7d22\u5728\u66f4\u5e7f\u6cdb\u7684\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5728\u6d41\u5e38\u5fae\u5206\u65b9\u7a0b\uff08Flow ODE\uff09\u4e2d\u5f15\u5165\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u89c4\u8303\u573a\uff08Gauge Field\uff09\uff0c\u5f62\u6210\u4e00\u79cd\u65b0\u578b\u7684\u751f\u6210\u6d41\u6a21\u578b\u2014\u2014\u89c4\u8303\u6d41\u6a21\u578b\uff08Gauge Flow Models\uff09\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u6d41\u5339\u914d\u5b9e\u9a8c\uff0c\u8bc1\u660e\u89c4\u8303\u6d41\u6a21\u578b\u6bd4\u4f20\u7edf\u6d41\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002\u672a\u53d1\u8868\u7684\u7814\u7a76\u8fd8\u6697\u793a\u4e86\u5b83\u5728\u66f4\u591a\u751f\u6210\u4efb\u52a1\u4e0a\u6f5c\u5728\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u89c4\u8303\u6d41\u6a21\u578b\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7c7b\u522b\u7684\u751f\u6210\u6d41\u6a21\u578b\uff0c\u5728\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u6d41\u6a21\u578b\uff0c\u5e76\u53ef\u80fd\u5bf9\u66f4\u5e7f\u6cdb\u7684\u751f\u6210\u4efb\u52a1\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2507.13651", "pdf": "https://arxiv.org/pdf/2507.13651", "abs": "https://arxiv.org/abs/2507.13651", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks", "categories": ["cs.AI"], "comment": null, "summary": "Many intelligent tutoring systems can support a student in solving a stepwise\ntask. When a student combines several steps in one step, the number of possible\npaths connecting consecutive inputs may be very large. This combinatorial\nexplosion makes error diagnosis hard. Using a final answer to diagnose a\ncombination of steps can mitigate the combinatorial explosion, because there\nare generally fewer possible (erroneous) final answers than (erroneous)\nsolution paths. An intermediate input for a task can be diagnosed by\nautomatically completing it according to the task solution strategy and\ndiagnosing this solution. This study explores the potential of automated error\ndiagnosis based on a final answer. We investigate the design of a service that\nprovides a buggy rule diagnosis when a student combines several steps. To\nvalidate the approach, we apply the service to an existing dataset (n=1939) of\nunique student steps when solving quadratic equations, which could not be\ndiagnosed by a buggy rule service that tries to connect consecutive inputs with\na single rule. Results show that final answer evaluation can diagnose 29,4% of\nthese steps. Moreover, a comparison of the generated diagnoses with teacher\ndiagnoses on a subset (n=115) shows that the diagnoses align in 97% of the\ncases. These results can be considered a basis for further exploration of the\napproach.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u81ea\u52a8\u5316\u9519\u8bef\u8bca\u65ad\u5728\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5f53\u5b66\u751f\u5c06\u591a\u4e2a\u6b65\u9aa4\u5408\u5e76\u4e3a\u4e00\u6b65\u65f6\u3002\u901a\u8fc7\u81ea\u52a8\u5b8c\u6210\u4e2d\u95f4\u8f93\u5165\u5e76\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u7f13\u89e3\u7ec4\u5408\u7206\u70b8\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u8bca\u65ad29.4%\u7684\u6b65\u9aa4\uff0c\u5e76\u4e14\u4e0e\u6559\u5e08\u8bca\u65ad\u7684\u4e00\u81f4\u6027\u8fbe\u523097%\u3002", "motivation": "\u8bb8\u591a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u53ef\u4ee5\u652f\u6301\u5b66\u751f\u89e3\u51b3\u5206\u6b65\u4efb\u52a1\uff0c\u4f46\u5f53\u5b66\u751f\u5c06\u591a\u4e2a\u6b65\u9aa4\u5408\u5e76\u4e3a\u4e00\u4e2a\u6b65\u9aa4\u65f6\uff0c\u53ef\u80fd\u4ea7\u751f\u5927\u91cf\u7684\u8def\u5f84\u8fde\u63a5\u8fde\u7eed\u8f93\u5165\uff0c\u5bfc\u81f4\u7ec4\u5408\u7206\u70b8\uff0c\u4f7f\u5f97\u9519\u8bef\u8bca\u65ad\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u9879\u670d\u52a1\uff0c\u8be5\u670d\u52a1\u63d0\u4f9b\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u9519\u8bef\u89c4\u5219\u8bca\u65ad\uff0c\u5f53\u5b66\u751f\u5c06\u591a\u4e2a\u6b65\u9aa4\u5408\u5e76\u4e3a\u4e00\u6b65\u65f6\uff0c\u81ea\u52a8\u6839\u636e\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\u5b8c\u6210\u4e2d\u95f4\u8f93\u5165\u5e76\u8fdb\u884c\u8bca\u65ad\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u8bca\u65ad\u51fa29.4%\u7684\u5b66\u751f\u6b65\u9aa4\uff0c\u5176\u4e2d\u4e0e\u6559\u5e08\u8bca\u65ad\u7684\u4e00\u81f4\u6027\u8fbe\u5230\u4e8697%\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u53ef\u4ee5\u4e3a\u8fdb\u4e00\u6b65\u63a2\u7d22\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.14007", "pdf": "https://arxiv.org/pdf/2507.14007", "abs": "https://arxiv.org/abs/2507.14007", "authors": ["Serhan W. Bahar"], "title": "The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems", "categories": ["cs.CR", "cs.ET"], "comment": null, "summary": "The rapid integration of blockchain, cryptocurrency, and Web3 technologies\ninto digital banks and fintech operations has created an integrated environment\nblending traditional financial systems with decentralised elements. This paper\nintroduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed\nframework designed to address the risks in these ecosystems, such as oracle\nmanipulation and cross-chain exploits. CNTMF represents a proposed extension of\nestablished methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN,\nand PASTA, while incorporating tailored components including Hybrid Layer\nAnalysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an\nAI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents,\nCNTMF supports data-driven mitigation to reduce losses, which totalled\napproximately $2.47 billion in the first half of 2025 across 344 security\nevents (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its\nphases guide asset mapping, risk profiling, prioritisation, mitigation, and\niterative feedback. This supports security against evolving risks like\nstate-sponsored attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5a01\u80c1\u5efa\u6a21\u6846\u67b6\u2014\u2014CryptoNeo Threat Modelling Framework (CNTMF)\uff0c\u65e8\u5728\u89e3\u51b3\u533a\u5757\u94fe\u3001\u52a0\u5bc6\u8d27\u5e01\u548cWeb3\u6280\u672f\u96c6\u6210\u5230\u6570\u5b57\u94f6\u884c\u548c\u91d1\u878d\u79d1\u6280\u8fd0\u8425\u4e2d\u6240\u5e26\u6765\u7684\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u3001\u52a0\u5bc6\u8d27\u5e01\u548cWeb3\u6280\u672f\u5feb\u901f\u878d\u5165\u6570\u5b57\u94f6\u884c\u548c\u91d1\u878d\u79d1\u6280\u64cd\u4f5c\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u878d\u5408\u4f20\u7edf\u91d1\u878d\u7cfb\u7edf\u4e0e\u53bb\u4e2d\u5fc3\u5316\u5143\u7d20\u7684\u96c6\u6210\u73af\u5883\u3002\u8fd9\u79cd\u73af\u5883\u5e26\u6765\u4e86\u8bf8\u5982\u9884\u8a00\u673a\u64cd\u63a7\u548c\u8de8\u94fe\u6f0f\u6d1e\u7b49\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u7684\u5a01\u80c1\u6a21\u578b\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "CNTMF\u662f\u5efa\u7acb\u5728STRIDE\u3001OWASP Top 10\u3001NIST\u6846\u67b6\u3001LINDDUN\u548cPASTA\u7b49\u5df2\u786e\u7acb\u7684\u65b9\u6cd5\u8bba\u4e4b\u4e0a\u7684\u6269\u5c55\uff0c\u540c\u65f6\u52a0\u5165\u4e86\u6df7\u5408\u5c42\u5206\u6790\u3001CRYPTOQ\u52a9\u8bb0\u7b26\uff08\u9488\u5bf9\u52a0\u5bc6\u8d27\u5e01\u7279\u5b9a\u98ce\u9669\uff09\u548cAI\u589e\u5f3a\u53cd\u9988\u5faa\u73af\u7b49\u5b9a\u5236\u7ec4\u4ef6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u8d44\u4ea7\u6620\u5c04\u3001\u98ce\u9669\u914d\u7f6e\u6587\u4ef6\u3001\u4f18\u5148\u7ea7\u6392\u5e8f\u3001\u7f13\u89e3\u63aa\u65bd\u548c\u8fed\u4ee3\u53cd\u9988\u9636\u6bb5\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u98ce\u9669\u7f13\u89e3\u3002", "result": "\u57fa\u4e8e2025\u5e74\u53d1\u751f\u76842025\u8d77\u4e8b\u4ef6\u7684\u5b9e\u9645\u6570\u636e\uff0cCNTMF\u6709\u52a9\u4e8e\u51cf\u5c11\u635f\u5931\uff0c\u8fd9\u4e9b\u635f\u5931\u57282025\u5e74\u4e0a\u534a\u5e74\u56e0344\u8d77\u5b89\u5168\u4e8b\u4ef6\u800c\u8fbe\u5230\u4e86\u7ea624.7\u4ebf\u7f8e\u5143\u3002", "conclusion": "CNTMF\u4e3a\u5bf9\u6297\u4e0d\u65ad\u6f14\u53d8\u7684\u98ce\u9669\uff08\u5982\u56fd\u5bb6\u8d5e\u52a9\u7684\u653b\u51fb\uff09\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u786e\u4fdd\u4e86\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.13416", "pdf": "https://arxiv.org/pdf/2507.13416", "abs": "https://arxiv.org/abs/2507.13416", "authors": ["Jiaxiang Yi", "Bernardo P. Ferreira", "Miguel A. Bessa"], "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling", "categories": ["cs.LG", "cs.AI"], "comment": "40 pages, 32 figures", "summary": "Data-driven learning is generalized to consider history-dependent\nmulti-fidelity data, while quantifying epistemic uncertainty and disentangling\nit from data noise (aleatoric uncertainty). This generalization is hierarchical\nand adapts to different learning scenarios: from training the simplest\nsingle-fidelity deterministic neural networks up to the proposed multi-fidelity\nvariance estimation Bayesian recurrent neural networks. The versatility and\ngenerality of the proposed methodology are demonstrated by applying it to\ndifferent data-driven constitutive modeling scenarios that include multiple\nfidelities with and without aleatoric uncertainty (noise). The method\naccurately predicts the response and quantifies model error while also\ndiscovering the noise distribution (when present). This opens opportunities for\nfuture real-world applications in diverse scientific and engineering domains;\nespecially, the most challenging cases involving design and analysis under\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u5386\u53f2\u4f9d\u8d56\u591a\u4fdd\u771f\u6570\u636e\u7684\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5e76\u5c06\u5176\u4e0e\u6570\u636e\u566a\u58f0\u5206\u79bb\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u5c42\u6b21\u6027\uff0c\u5e76\u9002\u5e94\u4e0d\u540c\u7684\u5b66\u4e60\u573a\u666f\u3002\u901a\u8fc7\u5e94\u7528\u5230\u4e0d\u540c\u7684\u6570\u636e\u9a71\u52a8\u7684\u672c\u6784\u5efa\u6a21\u573a\u666f\u4e2d\uff0c\u8bc1\u660e\u4e86\u5176\u591a\u529f\u80fd\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u63d0\u9ad8\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u3001\u4e0d\u786e\u5b9a\u6027\u7684\u5de5\u7a0b\u548c\u79d1\u5b66\u95ee\u9898\u4e2d\u7684\u9002\u7528\u6027\u548c\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u8bbe\u8ba1\u548c\u5206\u6790\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u8be5\u65b9\u6cd5\u662f\u5206\u5c42\u7684\uff0c\u53ef\u4ee5\u9002\u5e94\u4ece\u6700\u7b80\u5355\u7684\u5355\u4fdd\u771f\u786e\u5b9a\u6027\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u5230\u63d0\u51fa\u7684\u591a\u4fdd\u771f\u65b9\u5dee\u4f30\u8ba1\u8d1d\u53f6\u65af\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u3002\u5b83\u80fd\u51c6\u786e\u9884\u6d4b\u54cd\u5e94\uff0c\u91cf\u5316\u6a21\u578b\u8bef\u5dee\uff0c\u540c\u65f6\u53d1\u73b0\u566a\u58f0\u5206\u5e03\uff08\u5982\u679c\u5b58\u5728\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u7684\u6570\u636e\u9a71\u52a8\u672c\u6784\u5efa\u6a21\u573a\u666f\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5305\u62ec\u6709\u65e0\u566a\u58f0\u7684\u591a\u79cd\u4fdd\u771f\u5ea6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u51c6\u786e\u9884\u6d4b\u54cd\u5e94\uff0c\u91cf\u5316\u6a21\u578b\u8bef\u5dee\uff0c\u5e76\u53d1\u73b0\u566a\u58f0\u5206\u5e03\uff08\u5982\u679c\u5b58\u5728\uff09\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u672a\u6765\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u8bbe\u8ba1\u548c\u5206\u6790\u7684\u6700\u5177\u6311\u6218\u6027\u7684\u6848\u4f8b\u4e2d\u3002"}}
{"id": "2507.13652", "pdf": "https://arxiv.org/pdf/2507.13652", "abs": "https://arxiv.org/abs/2507.13652", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses", "categories": ["cs.AI"], "comment": null, "summary": "Model tracing and constraint-based modeling are two approaches to diagnose\nstudent input in stepwise tasks. Model tracing supports identifying consecutive\nproblem-solving steps taken by a student, whereas constraint-based modeling\nsupports student input diagnosis even when several steps are combined into one\nstep. We propose an approach that merges both paradigms. By defining\nconstraints as properties that a student input has in common with a step of a\nstrategy, it is possible to provide a diagnosis when a student deviates from a\nstrategy even when the student combines several steps. In this study we explore\nthe design of a system for multistep strategy diagnoses, and evaluate these\ndiagnoses. As a proof of concept, we generate diagnoses for an existing dataset\ncontaining steps students take when solving quadratic equations (n=2136). To\ncompare with human diagnoses, two teachers coded a random sample of deviations\n(n=70) and applications of the strategy (n=70). Results show that that the\nsystem diagnosis aligned with the teacher coding in all of the 140 student\nsteps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u6a21\u578b\u8ddf\u8e2a\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u5efa\u6a21\u4e24\u79cd\u8303\u5f0f\u7684\u65b9\u6cd5\uff0c\u4ee5\u8bca\u65ad\u5b66\u751f\u5728\u89e3\u9898\u8fc7\u7a0b\u4e2d\u7684\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u6a21\u578b\u8ddf\u8e2a\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u5efa\u6a21\u662f\u8bca\u65ad\u5b66\u751f\u5728\u5206\u6b65\u4efb\u52a1\u4e2d\u8f93\u5165\u7684\u4e24\u79cd\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5404\u81ea\u6709\u5176\u5c40\u9650\u6027\uff1a\u6a21\u578b\u8ddf\u8e2a\u652f\u6301\u8bc6\u522b\u5b66\u751f\u8fde\u7eed\u7684\u95ee\u9898\u89e3\u51b3\u6b65\u9aa4\uff0c\u800c\u57fa\u4e8e\u7ea6\u675f\u7684\u5efa\u6a21\u5219\u5728\u5b66\u751f\u5c06\u591a\u4e2a\u6b65\u9aa4\u5408\u5e76\u4e3a\u4e00\u4e2a\u6b65\u9aa4\u65f6\u4ecd\u80fd\u8fdb\u884c\u8bca\u65ad\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u7ed3\u5408\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u63d0\u9ad8\u5bf9\u5b66\u751f\u89e3\u9898\u8fc7\u7a0b\u7684\u8bca\u65ad\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u5c06\u6a21\u578b\u8ddf\u8e2a\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u5efa\u6a21\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u628a\u7ea6\u675f\u5b9a\u4e49\u4e3a\u5b66\u751f\u7684\u8f93\u5165\u4e0e\u7b56\u7565\u7684\u67d0\u4e00\u6b65\u9aa4\u4e4b\u95f4\u7684\u5171\u540c\u5c5e\u6027\uff0c\u4ece\u800c\u5373\u4f7f\u5f53\u5b66\u751f\u504f\u79bb\u7b56\u7565\u6216\u5408\u5e76\u591a\u4e2a\u6b65\u9aa4\u65f6\u4e5f\u80fd\u63d0\u4f9b\u8bca\u65ad\u3002\u4e3a\u4e86\u8bc1\u660e\u6982\u5ff5\u7684\u53ef\u884c\u6027\uff0c\u7814\u7a76\u8005\u4eec\u4f7f\u7528\u73b0\u6709\u7684\u5305\u542b\u5b66\u751f\u89e3\u4e8c\u6b21\u65b9\u7a0b\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff08n=2136\uff09\u751f\u6210\u4e86\u8bca\u65ad\u7ed3\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u8bca\u65ad\u4e0e\u6559\u5e08\u5bf9\u968f\u673a\u6837\u672c\uff08\u5305\u62ec70\u4e2a\u504f\u5dee\u5b9e\u4f8b\u548c70\u4e2a\u7b56\u7565\u5e94\u7528\u5b9e\u4f8b\uff09\u7684\u7f16\u7801\u5b8c\u5168\u543b\u5408\u3002", "conclusion": "\u8fd9\u79cd\u7ed3\u5408\u6a21\u578b\u8ddf\u8e2a\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u8bca\u65ad\u5b66\u751f\u7684\u89e3\u9898\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5728\u591a\u6b65\u9aa4\u7b56\u7565\u7684\u5e94\u7528\u4e0a\uff0c\u4e14\u5176\u51c6\u786e\u6027\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.14109", "pdf": "https://arxiv.org/pdf/2507.14109", "abs": "https://arxiv.org/abs/2507.14109", "authors": ["Xinyu Cao", "Bimal Adhikari", "Shangqing Zhao", "Jingxian Wu", "Yanjun Pan"], "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684RF\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u53ef\u88ab\u5229\u7528\u7684\u9519\u8bef\u5206\u7c7b\u884c\u4e3a\u548c\u540e\u95e8\u653b\u51fb\uff0c\u5e76\u6307\u51fa\u539f\u59cb\u4fe1\u53f7\u8bad\u7ec3\u6a21\u578b\u5bb9\u6613\u5c06RF\u6307\u7eb9\u4e0e\u73af\u5883\u7279\u5f81\u6df7\u6dc6\uff0c\u4ece\u800c\u589e\u52a0\u4e86\u653b\u51fb\u9014\u5f84\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u9ad8\u7cfb\u7edf\u5728\u65e0\u7ebf\u73af\u5883\u53d8\u5316\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u800c\u5ffd\u7565\u4e86DL\u65b9\u6cd5\u5728RF\u6307\u7eb9\u8bc6\u522b\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u4f5c\u8005\u8fdb\u884c\u4e86\u5bf9\u6297\u9a71\u52a8\u7684\u5b9e\u9a8c\u5206\u6790\uff0c\u89c2\u5bdfDL\u6a21\u578b\u5728\u57df\u8f6c\u79fb\u4e0b\u7684\u8bef\u5206\u7c7b\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u884c\u4e3a\u53ef\u4f5c\u4e3a\u540e\u95e8\u653b\u51fb\u624b\u6bb5\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u539f\u59cb\u63a5\u6536\u4fe1\u53f7\u8bad\u7ec3\u6a21\u578b\u5bfc\u81f4\u7684\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u4e86DL\u6a21\u578b\u5728\u57df\u8f6c\u79fb\u4e0b\u7684\u4e00\u81f4\u6027\u8bef\u5206\u7c7b\u884c\u4e3a\uff0c\u8fd9\u79cd\u884c\u4e3a\u53ef\u4ee5\u88ab\u7528\u4f5c\u6709\u6548\u7684\u540e\u95e8\uff0c\u5141\u8bb8\u5916\u90e8\u653b\u51fb\u8005\u5165\u4fb5\u7cfb\u7edf\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u539f\u59cb\u4fe1\u53f7\u8bad\u7ec3\u7684\u6a21\u578b\u4f1a\u5c06RF\u6307\u7eb9\u4e0e\u73af\u5883\u7279\u5f81\u6df7\u6dc6\uff0c\u5f62\u6210\u989d\u5916\u7684\u653b\u51fb\u5411\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86DL-based RF\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u4e2d\u672a\u88ab\u5145\u5206\u91cd\u89c6\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5f3a\u8c03\u9700\u8981\u65b0\u7684\u9632\u5fa1\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002"}}
{"id": "2507.13417", "pdf": "https://arxiv.org/pdf/2507.13417", "abs": "https://arxiv.org/abs/2507.13417", "authors": ["Armel Soubeiga", "Thomas Guyet", "Violaine Antoine"], "title": "Soft-ECM: An extension of Evidential C-Means for complex data", "categories": ["cs.LG", "cs.AI", "cs.DM"], "comment": null, "summary": "Clustering based on belief functions has been gaining increasing attention in\nthe machine learning community due to its ability to effectively represent\nuncertainty and/or imprecision. However, none of the existing algorithms can be\napplied to complex data, such as mixed data (numerical and categorical) or\nnon-tabular data like time series. Indeed, these types of data are, in general,\nnot represented in a Euclidean space and the aforementioned algorithms make use\nof the properties of such spaces, in particular for the construction of\nbarycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem\nfor clustering complex data. We propose a new algorithm, Soft-ECM, which\nconsistently positions the centroids of imprecise clusters requiring only a\nsemi-metric. Our experiments show that Soft-ECM present results comparable to\nconventional fuzzy clustering approaches on numerical data, and we demonstrate\nits ability to handle mixed data and its benefits when combining fuzzy\nclustering with semi-metrics such as DTW for time series data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5Soft-ECM\uff0c\u53ef\u4ee5\u5bf9\u590d\u6742\u6570\u636e\uff08\u5982\u6df7\u5408\u6570\u636e\u548c\u65f6\u95f4\u5e8f\u5217\uff09\u8fdb\u884c\u805a\u7c7b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4fe1\u4efb\u51fd\u6570\u7684\u805a\u7c7b\u7b97\u6cd5\u65e0\u6cd5\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u590d\u6742\u6570\u636e\uff0c\u4f8b\u5982\u6df7\u5408\u6570\u636e\u6216\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "method": "\u4f5c\u8005\u91cd\u65b0\u5b9a\u4e49\u4e86Evidential C-Means\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7b97\u6cd5Soft-ECM\uff0c\u8be5\u7b97\u6cd5\u4ec5\u9700\u8981\u534a\u5ea6\u91cf\u5373\u53ef\u4e00\u81f4\u5730\u5b9a\u4f4d\u4e0d\u7cbe\u786e\u7c07\u7684\u8d28\u5fc3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSoft-ECM\u5728\u6570\u503c\u6570\u636e\u4e0a\u7684\u7ed3\u679c\u53ef\u4e0e\u4f20\u7edf\u7684\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u6df7\u5408\u6570\u636e\uff0c\u5728\u7ed3\u5408\u4f7f\u7528DTW\u7b49\u534a\u5ea6\u91cf\u65f6\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "Soft-ECM\u662f\u4e00\u79cd\u6709\u6548\u7684\u590d\u6742\u6570\u636e\u805a\u7c7b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6df7\u5408\u6570\u636e\u548c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65b9\u9762\u3002"}}
{"id": "2507.13737", "pdf": "https://arxiv.org/pdf/2507.13737", "abs": "https://arxiv.org/abs/2507.13737", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "comment": null, "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.", "AI": {"tldr": "DailyLLM \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u65e5\u5fd7\u751f\u6210\u548c\u603b\u7ed3\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5168\u9762\u6574\u5408\u4f4d\u7f6e\u3001\u8fd0\u52a8\u3001\u73af\u5883\u548c\u751f\u7406\u56db\u4e2a\u7ef4\u5ea6\u7684\u4e0a\u4e0b\u6587\u6d3b\u52a8\u4fe1\u606f\uff0c\u4ec5\u4f7f\u7528\u667a\u80fd\u624b\u673a\u548c\u667a\u80fd\u624b\u8868\u4e0a\u7684\u5e38\u89c1\u4f20\u611f\u5668\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6846\u67b6\u548c\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u5feb\u901f\u63a8\u7406\u901f\u5ea6\u7684\u65e5\u5fd7\u751f\u6210\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e8617%\u7684BERTScore\u7cbe\u5ea6\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u5feb\u4e86\u8fd110\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u6d3b\u52a8\u65e5\u5fd7\u751f\u6210\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u8bed\u4e49\u4e30\u5bcc\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u8bed\u4e49\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u7ed3\u5408\u5e38\u89c1\u7684\u79fb\u52a8\u8bbe\u5907\u4f20\u611f\u5668\u6570\u636e\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u9ad8\u6548\u7684\u65e5\u5fd7\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002", "method": "DailyLLM \u5f15\u5165\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684 LLM \u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u63d0\u793a\u4e0e\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u76f8\u7ed3\u5408\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6c34\u5e73\u7684\u6d3b\u52a8\u7406\u89e3\u3002\u5b83\u6574\u5408\u4e86\u4f4d\u7f6e\u3001\u8fd0\u52a8\u3001\u73af\u5883\u548c\u751f\u7406\u56db\u65b9\u9762\u7684\u4e0a\u4e0b\u6587\u6d3b\u52a8\u4fe1\u606f\uff0c\u4ec5\u4f7f\u7528\u667a\u80fd\u624b\u673a\u548c\u667a\u80fd\u624b\u8868\u4e0a\u5e38\u89c1\u7684\u4f20\u611f\u5668\u3002\u6b64\u5916\uff0c\u8be5\u7cfb\u7edf\u91c7\u7528\u4e86\u4e00\u4e2a1.5B\u53c2\u6570\u7684LLM\u6a21\u578b\uff0c\u786e\u4fdd\u4e86\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u4f4e\u7684\u8ba1\u7b97\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e DailyLLM \u5728\u591a\u4e2a\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65e5\u5fd7\u751f\u6210\u65b9\u6cd5\uff1a\u5b83\u4e0d\u4ec5\u5728 BERTScore \u7cbe\u5ea6\u4e0a\u63d0\u5347\u4e8617%\uff0c\u800c\u4e14\u63a8\u7406\u901f\u5ea6\u4e5f\u5feb\u4e86\u8fd110\u500d\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86 DailyLLM \u5728\u4e2a\u4eba\u7535\u8111\u548c Raspberry Pi \u4e0a\u7684\u6709\u6548\u90e8\u7f72\u53ef\u80fd\u6027\u3002", "conclusion": "DailyLLM \u4f5c\u4e3a\u9996\u4e2a\u5168\u9762\u6574\u5408\u591a\u7ef4\u4e0a\u4e0b\u6587\u6d3b\u52a8\u4fe1\u606f\u7684\u65e5\u5fd7\u751f\u6210\u548c\u603b\u7ed3\u7cfb\u7edf\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u95ee\u9898\u3002\u5b83\u7684\u9ad8\u6027\u80fd\u548c\u4f4e\u8d44\u6e90\u6d88\u8017\u4f7f\u5f97\u5176\u53ef\u4ee5\u5728\u5404\u79cd\u8ba1\u7b97\u5e73\u53f0\u4e0a\u5e7f\u6cdb\u90e8\u7f72\uff0c\u4e3a\u7528\u6237\u884c\u4e3a\u5206\u6790\u548c\u5065\u5eb7\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2507.13508", "pdf": "https://arxiv.org/pdf/2507.13508", "abs": "https://arxiv.org/abs/2507.13508", "authors": ["Agata Kaczmarek", "Dawid P\u0142udowski", "Piotr Wilczy\u0144ski", "Przemys\u0142aw Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})\nis the second part of a series of follow-up competitions and hackathons related\nto the \"Assurance for Space Domain AI Applications\" project funded by the\nEuropean Space Agency\n(\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).\nThe competition idea is based on two real-life AI security threats identified\nwithin the project -- data poisoning and overreliance in Large Language Models.\nThe task is to distinguish between the proper output from LLM and the output\ngenerated under malicious modification of the LLM. As this problem was not\nextensively researched, participants are required to develop new techniques to\naddress this issue or adjust already existing ones to this problem's statement.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Kaggle\u4e0a\u5173\u4e8e\u533a\u5206\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u5e38\u8f93\u51fa\u548c\u6076\u610f\u4fee\u6539\u8f93\u51fa\u7684\u7ade\u8d5b\uff0c\u6b64\u7ade\u8d5b\u4e0e\u6b27\u6d32\u822a\u5929\u5c40\u8d44\u52a9\u7684\u201c\u592a\u7a7a\u9886\u57dfAI\u5e94\u7528\u7684\u4fdd\u969c\u201d\u9879\u76ee\u6709\u5173\u3002", "motivation": "\u7ade\u8d5b\u57fa\u4e8e\u9879\u76ee\u4e2d\u786e\u5b9a\u7684\u4e24\u4e2a\u73b0\u5b9e\u7684AI\u5b89\u5168\u5a01\u80c1\uff1a\u6570\u636e\u6295\u6bd2\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002", "method": "\u53c2\u4e0e\u8005\u9700\u8981\u5f00\u53d1\u65b0\u6280\u672f\u6216\u8c03\u6574\u5df2\u6709\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "result": "\u6458\u8981\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6458\u8981\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.13423", "pdf": "https://arxiv.org/pdf/2507.13423", "abs": "https://arxiv.org/abs/2507.13423", "authors": ["Edward Henderson", "Dewi Gould", "Richard Everson", "George De Ath", "Nick Pepper"], "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity", "categories": ["cs.LG", "cs.AI"], "comment": "Author Accepted Manuscript version of paper at the AIAA AVIATION\n  Forum 2025", "summary": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand\nis a critical challenge in an increasingly crowded airspace, as existing\ncomplexity metrics often fail to capture nuanced operational drivers beyond\nsimple aircraft counts. This work introduces an interpretable Graph Neural\nNetwork (GNN) framework to address this gap. Our attention-based model predicts\nthe number of upcoming clearances, the instructions issued to aircraft by\nATCOs, from interactions within static traffic scenarios. Crucially, we derive\nan interpretable, per-aircraft task demand score by systematically ablating\naircraft and measuring the impact on the model's predictions. Our framework\nsignificantly outperforms an ATCO-inspired heuristic and is a more reliable\nestimator of scenario complexity than established baselines. The resulting tool\ncan attribute task demand to specific aircraft, offering a new way to analyse\nand understand the drivers of complexity for applications in controller\ntraining and airspace redesign.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u6846\u67b6\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u5458\u7684\u4efb\u52a1\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u590d\u6742\u6027\u5ea6\u91cf\u65b9\u6cd5\u901a\u5e38\u65e0\u6cd5\u6355\u6349\u5230\u8d85\u51fa\u7b80\u5355\u98de\u673a\u6570\u91cf\u4e4b\u5916\u7684\u7ec6\u5fae\u64cd\u4f5c\u9a71\u52a8\u56e0\u7d20\uff0c\u56e0\u6b64\u5728\u65e5\u76ca\u62e5\u6324\u7684\u7a7a\u57df\u4e2d\uff0c\u5b9e\u65f6\u8bc4\u4f30\u77ed\u671f\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u5458\uff08ATCO\uff09\u4efb\u52a1\u9700\u6c42\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u9759\u6001\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u4e92\u52a8\uff0c\u9884\u6d4b\u5373\u5c06\u53d1\u5e03\u7684\u8bb8\u53ef\u6570\u91cf\uff0c\u5373ATCO\u5411\u98de\u673a\u53d1\u51fa\u7684\u6307\u4ee4\u3002\u901a\u8fc7\u7cfb\u7edf\u5730\u6d88\u878d\u98de\u673a\u5e76\u6d4b\u91cf\u5176\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u51fa\u6bcf\u4e2a\u98de\u673a\u7684\u4efb\u52a1\u9700\u6c42\u8bc4\u5206\u3002", "result": "\u8be5\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eATCO\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u7684\u57fa\u51c6\u66f4\u80fd\u53ef\u9760\u5730\u4f30\u8ba1\u60c5\u666f\u590d\u6742\u5ea6\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u5de5\u5177\u53ef\u4ee5\u5c06\u4efb\u52a1\u9700\u6c42\u5f52\u56e0\u4e8e\u7279\u5b9a\u7684\u98de\u673a\uff0c\u4e3a\u5206\u6790\u548c\u7406\u89e3\u590d\u6742\u6027\u7684\u9a71\u52a8\u56e0\u7d20\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u7ba1\u5236\u5458\u57f9\u8bad\u548c\u7a7a\u57df\u91cd\u65b0\u8bbe\u8ba1\u7b49\u65b9\u9762\u3002"}}
{"id": "2507.13759", "pdf": "https://arxiv.org/pdf/2507.13759", "abs": "https://arxiv.org/abs/2507.13759", "authors": ["Carlos Bobed", "Carlota Quintana", "Eduardo Mena", "Jorge Bobed", "Fernando Bobillo"], "title": "OntView: What you See is What you Meant", "categories": ["cs.AI"], "comment": null, "summary": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u6b3e\u65b0\u7684\u672c\u4f53\u8bba\u67e5\u770b\u5de5\u5177OntView\uff0c\u5b83\u63d0\u4f9b\u76f4\u89c2\u7684\u672c\u4f53\u8bba\u6982\u5ff5\u53ca\u5176\u5b9a\u4e49\u7684\u53ef\u89c6\u5316\u8868\u793a\uff0c\u5e76\u4e14\u80fd\u591f\u5c55\u793a\u901a\u7528\u6982\u5ff5\u5305\u542b\uff08GCI\uff09\uff0c\u63d0\u4f9b\u4e86\u591a\u79cd\u7b80\u5316\u672c\u4f53\u8bba\u89c6\u56fe\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u672c\u4f53\u7f16\u8f91\u5668\u548c\u67e5\u770b\u5668\u5927\u591a\u672a\u80fd\u4ee5\u6709\u610f\u4e49\u4e14\u4e0d\u8fc7\u4e8e\u590d\u6742\u7684\u65b9\u5f0f\u56fe\u5f62\u5316\u8868\u793a\u672c\u4f53\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u7528\u6237\u7406\u89e3\u5927\u578b\u672c\u4f53\u6846\u67b6\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u5c5e\u6027\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u673a\u5e76\u9075\u5faa\u201c\u6240\u89c1\u5373\u6240\u5f97\u201d\u7684\u8303\u5f0f\uff0cOntView\u5c55\u793a\u4e86\u5b9e\u9645\u63a8\u65ad\u51fa\u7684\u77e5\u8bc6\uff0c\u5e76\u80fd\u53ef\u89c6\u5316\u901a\u7528\u6982\u5ff5\u5305\u542b\uff08GCI\uff09\u3002\u4e3a\u4e86\u9632\u6b62\u4fe1\u606f\u8fc7\u8f7d\uff0cOntView\u8fd8\u63d0\u4f9b\u4e09\u79cd\u65b9\u6cd5\u6765\u7b80\u5316\u672c\u4f53\u8bba\u89c6\u56fe\uff1a1\uff09\u521b\u5efa\u91cd\u8981\u6027\u8bc4\u4f30\u7684\u6982\u5ff5\u6458\u8981\uff1b2\uff09\u805a\u7126\u4e8e\u4e24\u4e2a\u7ed9\u5b9a\u7c7b\u4e4b\u95f4\u7684TBox\u5143\u7d20\uff1b3\uff09\u52a8\u6001\u9690\u85cf/\u663e\u793a\u4e0d\u540c\u7684\u5206\u652f\u3002", "result": "OntView\u6210\u529f\u5730\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53cb\u597d\u7684\u754c\u9762\uff0c\u7528\u4e8e\u76f4\u89c2\u5730\u7406\u89e3\u548c\u6d4f\u89c8\u590d\u6742\u7684\u672c\u4f53\u8bba\u7ed3\u6784\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4fe1\u606f\u8fc7\u8f7d\u7684\u95ee\u9898\u3002", "conclusion": "OntView\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u53d1\u5e03\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u672c\u4f53\u8bba\u53ef\u89c6\u5316\u5de5\u5177\u5b58\u5728\u7684\u4e0d\u8db3\uff0c\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u672c\u4f53\u8bba\u7ed3\u6784\u56fe\u5f62\u8868\u793a\u65b9\u5f0f\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u5927\u578b\u672c\u4f53\u6846\u67b6\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u5c5e\u6027\u3002"}}
{"id": "2507.13482", "pdf": "https://arxiv.org/pdf/2507.13482", "abs": "https://arxiv.org/abs/2507.13482", "authors": ["Seyyed Saeid Cheshmi", "Buyao Lyu", "Thomas Lisko", "Rajesh Rajamani", "Robert A. McGovern", "Yogatheesan Varatharajah"], "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a\ncritical role in remote health monitoring. In patients with movement disorders,\nthe ability to detect abnormal patient movements in their home environments can\nenable continuous optimization of treatments and help alert caretakers as\nneeded. Machine learning approaches have been proposed for HAR tasks using\nInertial Measurement Unit (IMU) data; however, most rely on\napplication-specific labels and lack generalizability to data collected in\ndifferent environments or populations. To address this limitation, we propose a\nnew cross-modal self-supervised pretraining approach to learn representations\nfrom large-sale unlabeled IMU-video data and demonstrate improved\ngeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,\nincluding a dataset collected from patients with Parkinson's disease.\nSpecifically, our results indicate that the proposed cross-modal pretraining\napproach outperforms the current state-of-the-art IMU-video pretraining\napproach and IMU-only pretraining under zero-shot and few-shot evaluations.\nBroadly, our study provides evidence that in highly dynamic data modalities,\nsuch as IMU signals, cross-modal pretraining may be a useful tool to learn\ngeneralizable data representations. Our software is available at\nhttps://github.com/scheshmi/IMU-Video-OOD-HAR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u672a\u6807\u8bb0\u7684\u5927\u89c4\u6a21IMU-\u89c6\u9891\u6570\u636e\u4e2d\u5b66\u4e60\u8868\u793a\uff0c\u5e76\u5c55\u793a\u4e86\u5728HAR\u4efb\u52a1\u4e2d\u5bf9OOD IMU\u6570\u636e\u96c6\u7684\u6539\u8fdb\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eIMU\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728HAR\u4efb\u52a1\u4e2d\u5927\u591a\u4f9d\u8d56\u4e8e\u7279\u5b9a\u5e94\u7528\u7684\u6807\u7b7e\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u73af\u5883\u6216\u4eba\u7fa4\u6536\u96c6\u7684\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u672a\u6807\u8bb0\u7684IMU-\u89c6\u9891\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bc4\u4f30\u4e2d\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684IMU-\u89c6\u9891\u9884\u8bad\u7ec3\u65b9\u6cd5\u548c\u4ec5IMU\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u9ad8\u5ea6\u52a8\u6001\u7684\u6570\u636e\u6a21\u5f0f\uff08\u5982IMU\u4fe1\u53f7\uff09\u4e2d\uff0c\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u53ef\u80fd\u662f\u5b66\u4e60\u6cdb\u5316\u6570\u636e\u8868\u793a\u7684\u4e00\u79cd\u6709\u7528\u5de5\u5177\u3002"}}
{"id": "2507.13768", "pdf": "https://arxiv.org/pdf/2507.13768", "abs": "https://arxiv.org/abs/2507.13768", "authors": ["Renato Ghisellini", "Remo Pareschi", "Marco Pedroni", "Giovanni Battista Raggi"], "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning", "categories": ["cs.AI", "I.2.7"], "comment": "Peer-reviewed full paper accepted through a double-blind review\n  process at the HAR 2025 conference (https://har-conf.eu/). The official\n  version will appear in a volume of the Lecture Notes in Computer Science\n  (LNCS) series", "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u8bed\u4e49\u6fc0\u6d3b\u548c\u7ec4\u5408\u5408\u6210\u7684\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4e92\u4f9d\u8d56\u5c06\u591a\u4e2a\u542f\u53d1\u5f0f\u878d\u5408\u6210\u8fde\u8d2f\u4e14\u4e0e\u80cc\u666f\u76f8\u5173\u7684\u53d9\u8ff0\u3002", "motivation": "\u4f20\u7edf\u7684\u51b3\u7b56\u5f15\u64ce\u901a\u5e38\u9009\u62e9\u6700\u4f73\u89c4\u5219\uff0c\u800c\u8be5\u7814\u7a76\u65e8\u5728\u878d\u5408\u51b2\u7a81\u7684\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u4ee5\u5f62\u6210\u8fde\u8d2f\u4e14\u5bf9\u80cc\u666f\u654f\u611f\u7684\u53d9\u8ff0\u3002", "method": "\u8be5\u65b9\u6cd5\u4ece\u53e4\u5178\u519b\u4e8b\u7406\u8bba\u5230\u73b0\u4ee3\u4f01\u4e1a\u6218\u7565\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4e92\u4f9d\u8d56\u8fc7\u7a0b\u6fc0\u6d3b\u5e76\u7ec4\u5408\u591a\u4e2a\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u53d7\u5230\u91cf\u5b50\u8ba4\u77e5\u7814\u7a76\u7684\u542f\u53d1\u3002\u5b83\u4e0d\u9009\u62e9\u6700\u4f73\u89c4\u5219\uff0c\u800c\u662f\u901a\u8fc7\u8bed\u4e49\u4ea4\u4e92\u5efa\u6a21\u548c\u4fee\u8f9e\u6846\u67b6\u5c06\u51b2\u7a81\u7684\u542f\u53d1\u5f0f\u7b56\u7565\u878d\u5408\u5728\u4e00\u8d77\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7Meta vs. FTC\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u6f14\u793a\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u5ea6\u91cf\u8fdb\u884c\u4e86\u521d\u6b65\u9a8c\u8bc1\u3002\u8ba8\u8bba\u4e86\u5c40\u9650\u6027\u548c\u6269\u5c55\uff08\u4f8b\u5982\u52a8\u6001\u5e72\u6270\u8c03\u8c10\uff09\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u7684\u6df7\u5408\u67b6\u6784\u4e3a\u667a\u80fd\u4f53\u589e\u5f3a\u7684\u6218\u7565\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0d\u540c\u4e8e\u4f20\u7edf\u51b3\u7b56\u5f15\u64ce\u7684\u65b0\u89c6\u89d2\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5c40\u9650\u6027\u53ca\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.13491", "pdf": "https://arxiv.org/pdf/2507.13491", "abs": "https://arxiv.org/abs/2507.13491", "authors": ["Thomas Banker", "Ali Mesbah"], "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Training sophisticated agents for optimal decision-making under uncertainty\nhas been key to the rapid development of modern autonomous systems across\nfields. Notably, model-free reinforcement learning (RL) has enabled\ndecision-making agents to improve their performance directly through system\ninteractions, with minimal prior knowledge about the system. Yet, model-free RL\nhas generally relied on agents equipped with deep neural network function\napproximators, appealing to the networks' expressivity to capture the agent's\npolicy and value function for complex systems. However, neural networks amplify\nthe issues of sample inefficiency, unsafe learning, and limited\ninterpretability in model-free RL. To this end, this work introduces\nmodel-based agents as a compelling alternative for control policy\napproximation, leveraging adaptable models of system dynamics, cost, and\nconstraints for safe policy learning. These models can encode prior system\nknowledge to inform, constrain, and aid in explaining the agent's decisions,\nwhile deficiencies due to model mismatch can be remedied with model-free RL. We\noutline the benefits and challenges of learning model-based agents --\nexemplified by model predictive control -- and detail the primary learning\napproaches: Bayesian optimization, policy search RL, and offline strategies,\nalong with their respective strengths. While model-free RL has long been\nestablished, its interplay with model-based agents remains largely unexplored,\nmotivating our perspective on their combined potentials for sample-efficient\nlearning of safe and interpretable decision-making agents.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u4f5c\u4e3a\u63a7\u5236\u7b56\u7565\u8fd1\u4f3c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6837\u672c\u6548\u7387\u4f4e\u3001\u5b66\u4e60\u4e0d\u5b89\u5168\u548c\u53ef\u89e3\u91ca\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u795e\u7ecf\u7f51\u7edc\u5728\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u653e\u5927\u4e86\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u3001\u4e0d\u5b89\u5168\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u3002", "method": "\u6587\u4e2d\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7684\u4e3b\u8981\u5b66\u4e60\u65b9\u6cd5\uff1a\u8d1d\u53f6\u65af\u4f18\u5316\u3001\u7b56\u7565\u641c\u7d22\u5f3a\u5316\u5b66\u4e60\u548c\u79bb\u7ebf\u7b56\u7565\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b83\u4eec\u5404\u81ea\u7684\u4f18\u52bf\u3002", "result": "\u8be5\u5de5\u4f5c\u6982\u8ff0\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u4f18\u52bf\u548c\u6311\u6218\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u667a\u80fd\u4f53\u5728\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u7ed3\u8bba\u662f\u7ed3\u5408\u65e0\u6a21\u578b\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u7684\u3001\u5b89\u5168\u4e14\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u3002"}}
{"id": "2507.13825", "pdf": "https://arxiv.org/pdf/2507.13825", "abs": "https://arxiv.org/abs/2507.13825", "authors": ["Haoyang Li", "Yuming Xu", "Yiming Li", "Hanmo Liu", "Darian Li", "Chen Jason Zhang", "Lei Chen", "Qing Li"], "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction", "categories": ["cs.AI"], "comment": "Submitted in 2024. Accepted in 2025", "summary": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6EAGLE\uff0c\u5b83\u7ed3\u5408\u4e86\u77ed\u671f\u65f6\u95f4\u4e34\u8fd1\u6027\u548c\u957f\u671f\u5168\u5c40\u7ed3\u6784\u6a21\u5f0f\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u6a21\u5757\u548c\u7ed3\u6784\u611f\u77e5\u6a21\u5757\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u52a0\u6743\u673a\u5236\u5e73\u8861\u4e24\u8005\u8d21\u732e\u3002EAGLE\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709T-GNN\u6a21\u578b\uff0c\u901f\u5ea6\u63d0\u5347\u4e8650\u500d\u4ee5\u4e0a\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\uff08T-GNNs\uff09\u867d\u7136\u6210\u529f\u5730\u5229\u7528\u590d\u6742\u7684\u67b6\u6784\u6765\u5efa\u6a21\u65f6\u95f4\u548c\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u5f80\u5f80\u7531\u4e8e\u8ba1\u7b97\u5f00\u9500\u9ad8\u800c\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u6311\u6218\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u52a8\u6001\u56fe\u7684\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u3002", "method": "EAGLE\u5305\u542b\u4e00\u4e2a\u65f6\u95f4\u611f\u77e5\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u805a\u5408\u6765\u81ea\u8282\u70b9\u6700\u8fd1\u90bb\u5c45\u7684\u4fe1\u606f\u4ee5\u53cd\u6620\u5176\u5373\u65f6\u504f\u597d\uff1b\u4ee5\u53ca\u4e00\u4e2a\u7ed3\u6784\u611f\u77e5\u6a21\u5757\uff0c\u5229\u7528\u65f6\u95f4\u4e2a\u6027\u5316PageRank\u6355\u6349\u5168\u5c40\u91cd\u8981\u8282\u70b9\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0cEAGLE\u4f7f\u7528\u81ea\u9002\u5e94\u52a0\u6743\u673a\u5236\u6839\u636e\u6570\u636e\u7279\u5f81\u52a8\u6001\u8c03\u6574\u4e24\u8005\u7684\u8d21\u732e\uff0c\u5e76\u907f\u514d\u590d\u6742\u7684\u591a\u8df3\u6d88\u606f\u4f20\u9012\u6216\u5185\u5b58\u5bc6\u96c6\u578b\u673a\u5236\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u56fe\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEAGLE\u5728\u6548\u7387\u548c\u6548\u679c\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684T-GNNs\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc750\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "EAGLE\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u8fdb\u884c\u52a8\u6001\u56fe\u4e2d\u7684\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709T-GNNs\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2507.13846", "pdf": "https://arxiv.org/pdf/2507.13846", "abs": "https://arxiv.org/abs/2507.13846", "authors": ["Kathrin Korte", "Christian Medeiros Adriano", "Sona Ghahremani", "Holger Giese"], "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments", "categories": ["cs.AI"], "comment": null, "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u56e0\u679c\u77e5\u8bc6\u8fc1\u79fb\u6846\u67b6\uff0c\u4f7f\u591a\u667a\u80fd\u4f53\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u80fd\u591f\u5b66\u4e60\u5e76\u5171\u4eab\u7d27\u51d1\u7684\u56e0\u679c\u8868\u793a\u3002\u5f53\u73af\u5883\u53d8\u5316\u65f6\uff0c\u8be5\u6846\u67b6\u5141\u8bb8\u667a\u80fd\u4f53\u901a\u8fc7\u67e5\u8be2\u5305\u542b\u78b0\u649e\u4fe1\u606f\u7684\u67e5\u627e\u6a21\u578b\u6765\u5373\u65f6\u5e94\u7528\u4ece\u5176\u4ed6\u667a\u80fd\u4f53\u8f6c\u79fb\u6765\u7684\u6062\u590d\u52a8\u4f5c\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5177\u6709\u4e0d\u540c\u76ee\u6807\u7684\u667a\u80fd\u4f53\u80fd\u7f29\u5c0f\u968f\u673a\u63a2\u7d22\u548c\u5b8c\u5168\u518d\u8bad\u7ec3\u7b56\u7565\u4e4b\u95f4\u7ea6\u4e00\u534a\u7684\u5dee\u8ddd\uff0c\u5e76\u4e14\u56e0\u679c\u77e5\u8bc6\u8fc1\u79fb\u7684\u6548\u679c\u53d6\u51b3\u4e8e\u73af\u5883\u590d\u6742\u6027\u548c\u667a\u80fd\u4f53\u5f02\u8d28\u6027\u76ee\u6807\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edfMARL\u4e2d\u7684\u77e5\u8bc6\u8fc1\u79fb\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\uff0c\u667a\u80fd\u4f53\u7ecf\u5e38\u9700\u8981\u6602\u8d35\u7684\u518d\u8bad\u7ec3\u4ee5\u9002\u5e94\u53d8\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u9ad8\u667a\u80fd\u4f53\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u56e0\u679c\u77e5\u8bc6\u8fc1\u79fb\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u5c06\u6bcf\u6b21\u78b0\u649e\u5efa\u6a21\u4e3a\u4e00\u4e2a\u56e0\u679c\u5e72\u9884\uff0c\u5176\u5f62\u5f0f\u4e3a\u4e00\u7cfb\u5217\u6062\u590d\u52a8\u4f5c\uff08\u5b8f\uff09\uff0c\u8fd9\u4e9b\u52a8\u4f5c\u7684\u6548\u679c\u5bf9\u5e94\u4e8e\u5982\u4f55\u7ed5\u8fc7\u969c\u788d\u7269\u5e76\u589e\u52a0\u5b9e\u73b0\u76ee\u6807\u7684\u673a\u4f1a\u3002\u6062\u590d\u52a8\u4f5c\u5b8f\u53ef\u4ee5\u4ece\u7b2c\u4e8c\u4e2a\u667a\u80fd\u4f53\u5728\u7ebf\u8f6c\u79fb\uff0c\u5e76\u901a\u8fc7\u4f7f\u7528\u5305\u542b\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982\u78b0\u649e\uff09\u7684\u67e5\u627e\u6a21\u578b\u67e5\u8be2\u540e\u7acb\u5373\u5e94\u7528\uff0c\u65e0\u9700\u518d\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1. \u5177\u6709\u5f02\u8d28\u76ee\u6807\u7684\u667a\u80fd\u4f53\u80fd\u591f\u5728\u9002\u5e94\u65b0\u73af\u5883\u65f6\u5f25\u5408\u968f\u673a\u63a2\u7d22\u4e0e\u5b8c\u5168\u518d\u8bad\u7ec3\u7b56\u7565\u95f4\u5927\u7ea6\u4e00\u534a\u7684\u5dee\u8ddd\uff1b2. \u56e0\u679c\u77e5\u8bc6\u8fc1\u79fb\u7684\u5f71\u54cd\u4f9d\u8d56\u4e8e\u73af\u5883\u590d\u6742\u6027\u4e0e\u667a\u80fd\u4f53\u5f02\u8d28\u6027\u76ee\u6807\u95f4\u7684\u4e92\u52a8\u3002", "conclusion": "\u56e0\u679c\u77e5\u8bc6\u8fc1\u79fb\u6846\u67b6\u4e3a\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u8de8\u667a\u80fd\u4f53\u7684\u77e5\u8bc6\u8fc1\u79fb\u96be\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u662f\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u3002\u5b83\u4e0d\u4ec5\u51cf\u5c11\u4e86\u518d\u8bad\u7ec3\u7684\u6210\u672c\uff0c\u8fd8\u5c55\u793a\u4e86\u6839\u636e\u73af\u5883\u590d\u6742\u6027\u548c\u667a\u80fd\u4f53\u76ee\u6807\u5dee\u5f02\u8c03\u6574\u8fc1\u79fb\u6548\u679c\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.13540", "pdf": "https://arxiv.org/pdf/2507.13540", "abs": "https://arxiv.org/abs/2507.13540", "authors": ["Yongyi Yang", "Hidenori Tanaka", "Wei Hu"], "title": "Provable Low-Frequency Bias of In-Context Learning of Representations", "categories": ["cs.LG"], "comment": null, "summary": "In-context learning (ICL) enables large language models (LLMs) to acquire new\nbehaviors from the input sequence alone without any parameter updates. Recent\nstudies have shown that ICL can surpass the original meaning learned in\npretraining stage through internalizing the structure the data-generating\nprocess (DGP) of the prompt into the hidden representations. However, the\nmechanisms by which LLMs achieve this ability is left open. In this paper, we\npresent the first rigorous explanation of such phenomena by introducing a\nunified framework of double convergence, where hidden representations converge\nboth over context and across layers. This double convergence process leads to\nan implicit bias towards smooth (low-frequency) representations, which we prove\nanalytically and verify empirically. Our theory explains several open empirical\nobservations, including why learned representations exhibit globally structured\nbut locally distorted geometry, and why their total energy decays without\nvanishing. Moreover, our theory predicts that ICL has an intrinsic robustness\ntowards high-frequency noise, which we empirically confirm. These results\nprovide new insights into the underlying mechanisms of ICL, and a theoretical\nfoundation to study it that hopefully extends to more general data\ndistributions and settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53cc\u6536\u655b\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u5883\u5b66\u4e60\u4e2d\u9690\u85cf\u8868\u793a\u5982\u4f55\u5728\u4e0a\u4e0b\u6587\u548c\u5c42\u95f4\u6536\u655b\uff0c\u5bfc\u81f4\u5bf9\u5e73\u6ed1\u8868\u793a\u7684\u9690\u5f0f\u504f\u597d\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5bf9\u9ad8\u9891\u566a\u58f0\u7684\u5185\u5728\u9c81\u68d2\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u5883\u5b66\u4e60\u4e2d\u7684\u673a\u5236\uff0c\u7279\u522b\u662f\u9690\u85cf\u8868\u793a\u5982\u4f55\u4ece\u8f93\u5165\u5e8f\u5217\u4e2d\u83b7\u53d6\u65b0\u7684\u884c\u4e3a\u800c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u53cc\u6536\u655b\u6846\u67b6\uff0c\u5176\u4e2d\u9690\u85cf\u8868\u793a\u5728\u4e0a\u4e0b\u6587\u548c\u5c42\u95f4\u6536\u655b\uff0c\u5bfc\u81f4\u5bf9\u5e73\u6ed1\u8868\u793a\u7684\u9690\u5f0f\u504f\u597d\u3002\u901a\u8fc7\u5206\u6790\u548c\u5b9e\u8bc1\u65b9\u6cd5\u8bc1\u660e\u4e86\u8fd9\u4e00\u8fc7\u7a0b\u3002", "result": "\u8be5\u7406\u8bba\u89e3\u91ca\u4e86\u51e0\u4e2a\u5f00\u653e\u7684\u7ecf\u9a8c\u89c2\u5bdf\uff0c\u5305\u62ec\u4e3a\u4ec0\u4e48\u5b66\u4e60\u5230\u7684\u8868\u793a\u5177\u6709\u5168\u5c40\u7ed3\u6784\u4f46\u5c40\u90e8\u626d\u66f2\u7684\u51e0\u4f55\u5f62\u72b6\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u5b83\u4eec\u7684\u603b\u80fd\u91cf\u8870\u51cf\u4f46\u4e0d\u6d88\u5931\u3002\u8fd8\u9884\u6d4b\u5e76\u9a8c\u8bc1\u4e86ICL\u5bf9\u9ad8\u9891\u566a\u58f0\u7684\u5185\u5728\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u7406\u89e3\u60c5\u5883\u5b66\u4e60\u7684\u6f5c\u5728\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\uff0c\u53ef\u80fd\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u6570\u636e\u5206\u5e03\u548c\u8bbe\u7f6e\u3002"}}
{"id": "2507.13874", "pdf": "https://arxiv.org/pdf/2507.13874", "abs": "https://arxiv.org/abs/2507.13874", "authors": ["Mateusz Bystro\u0144ski", "Miko\u0142aj Ho\u0142ysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u521b\u610f\u6846\u67b6\uff0c\u901a\u8fc7\u5bfc\u822a\u60f3\u6cd5\u7684\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u5b9e\u73b0\u53ef\u63a7\u548c\u53ef\u6269\u5c55\u7684\u521b\u9020\u529b\u3002\u8be5\u6846\u67b6\u65e0\u9700\u624b\u5de5\u5236\u4f5c\u89c4\u5219\uff0c\u6613\u4e8e\u9002\u5e94\u4e0d\u540c\u9886\u57df\u3001\u8f93\u5165\u683c\u5f0f\u548c\u521b\u610f\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u65e2\u65b0\u9896\u53c8\u76f8\u5173\u7684\u60f3\u6cd5\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5f80\u5f80\u53ea\u80fd\u590d\u5236\u8bad\u7ec3\u4e2d\u770b\u5230\u7684\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u521b\u9020\u6027\u7684\u53d1\u6563\u80fd\u529b\u3002\u5c3d\u7ba1\u6709\u9886\u57df\u7279\u5b9a\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u7ed3\u6784\u5316\u63d0\u793a\u7ba1\u9053\uff0c\u4f46\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u8106\u5f31\u4e14\u96be\u4ee5\u63a8\u5e7f\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u521b\u610f\u6846\u67b6\uff0c\u901a\u8fc7\u5bfc\u822a\u60f3\u6cd5\u7684\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u6765\u5b9e\u73b0\u53ef\u63a7\u548c\u53ef\u6269\u5c55\u7684\u521b\u9020\u529b\u3002\u8fd9\u4e2a\u6846\u67b6\u4e0d\u9700\u8981\u624b\u5de5\u7f16\u5199\u7684\u89c4\u5219\uff0c\u5e76\u4e14\u53ef\u4ee5\u8f7b\u677e\u9002\u5e94\u4e0d\u540c\u7684\u9886\u57df\u3001\u8f93\u5165\u683c\u5f0f\u548c\u521b\u610f\u4efb\u52a1\u3002", "result": "\u6587\u4e2d\u4ecb\u7ecd\u4e86\u8be5\u65b9\u6cd5\u7684\u65e9\u671f\u539f\u578b\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u4eba\u7c7b-AI\u534f\u4f5c\u7684\u4e00\u822c\u7528\u9014\u5171\u540c\u521b\u610f\u8005\u7684\u6f5c\u529b\u3002", "conclusion": "\u6b64\u6846\u67b6\u53ef\u80fd\u6210\u4e3a\u4eba\u7c7b\u4e0eAI\u5408\u4f5c\u8fdb\u884c\u521b\u610f\u5de5\u4f5c\u7684\u901a\u7528\u8f85\u52a9\u5de5\u5177\uff0c\u663e\u793a\u51fa\u5de8\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13542", "pdf": "https://arxiv.org/pdf/2507.13542", "abs": "https://arxiv.org/abs/2507.13542", "authors": ["Beka Begiashvili", "Carlos J. Fernandez-Candel", "Mat\u00edas P\u00e9rez Paredes"], "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional echocardiographic parameters such as ejection fraction (EF) and\nglobal longitudinal strain (GLS) have limitations in the early detection of\ncardiac dysfunction. EF often remains normal despite underlying pathology, and\nGLS is influenced by load conditions and vendor variability. There is a growing\nneed for reproducible, interpretable, and operator-independent parameters that\ncapture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic\nparameter designed to quantify cardiac dysfunction from standard ultrasound\nviews. The model combines Extended Dynamic Mode Decomposition (EDMD) based on\nKoopman operator theory with a hybrid neural network that incorporates clinical\nmetadata. Spatiotemporal dynamics are extracted from echocardiographic\nsequences to identify coherent motion patterns. These are weighted via\nattention mechanisms and fused with clinical data using manifold learning,\nresulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac\npathologies and normal controls, the Acoustic Index achieved an area under the\ncurve (AUC) of 0.89 in an independent test set. Cross-validation across five\nfolds confirmed the robustness of the model, showing that both sensitivity and\nspecificity exceeded 0.8 when evaluated on independent data. Threshold-based\nanalysis demonstrated stable trade-offs between sensitivity and specificity,\nwith optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker\nfor cardiac function. It shows promise as a scalable, vendor-independent tool\nfor early detection, triage, and longitudinal monitoring. Future directions\ninclude external validation, longitudinal studies, and adaptation to\ndisease-specific classifiers.", "AI": {"tldr": "\u4f20\u7edf\u8d85\u58f0\u5fc3\u52a8\u56fe\u53c2\u6570\u5728\u5fc3\u810f\u529f\u80fd\u969c\u788d\u65e9\u671f\u68c0\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8eAI\u7684\u8d85\u58f0\u5fc3\u52a8\u56fe\u53c2\u6570\u2014\u2014\u58f0\u5b66\u6307\u6570\uff0c\u8be5\u53c2\u6570\u7ed3\u5408\u4e86\u6269\u5c55\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\u548c\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\uff0c\u4ece\u6807\u51c6\u8d85\u58f0\u89c6\u56fe\u4e2d\u91cf\u5316\u5fc3\u810f\u529f\u80fd\u969c\u788d\u3002\u5728736\u540d\u60a3\u8005\u7684\u524d\u77bb\u6027\u961f\u5217\u7814\u7a76\u4e2d\uff0c\u58f0\u5b66\u6307\u6570\u5728\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e2d\u8fbe\u5230\u4e860.89\u7684\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u3002\u5b83\u662f\u4e00\u79cd\u5177\u6709\u7269\u7406\u4fe1\u606f\u3001\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u751f\u7269\u6807\u5fd7\u7269\uff0c\u6709\u671b\u6210\u4e3a\u65e9\u671f\u68c0\u6d4b\u3001\u5206\u8bca\u548c\u7eb5\u5411\u76d1\u6d4b\u7684\u53ef\u6269\u5c55\u5de5\u5177\u3002", "motivation": "\u4f20\u7edf\u7684\u5fc3\u810f\u529f\u80fd\u8bc4\u4f30\u53c2\u6570\u5982\u5c04\u8840\u5206\u6570\uff08EF\uff09\u548c\u6574\u4f53\u7eb5\u5411\u5e94\u53d8\uff08GLS\uff09\u5728\u65e9\u671f\u68c0\u6d4b\u5fc3\u810f\u529f\u80fd\u969c\u788d\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u3001\u53ef\u91cd\u590d\u7684\u3001\u53ef\u89e3\u91ca\u7684\u3001\u4e0e\u64cd\u4f5c\u8005\u65e0\u5173\u7684\u53c2\u6570\u6765\u6355\u6349\u7ec6\u5fae\u4e14\u5168\u9762\u7684\u5fc3\u810f\u529f\u80fd\u53d8\u5316\u3002", "method": "\u58f0\u5b66\u6307\u6570\u662f\u901a\u8fc7\u7ed3\u5408\u6269\u5c55\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\uff08EDMD\uff09\u548c\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u5f00\u53d1\u7684\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\u5e76\u7ed3\u5408\u4e34\u5e8a\u5143\u6570\u636e\u3002\u4ece\u8d85\u58f0\u5fc3\u52a8\u56fe\u5e8f\u5217\u4e2d\u63d0\u53d6\u65f6\u7a7a\u52a8\u529b\u5b66\u4ee5\u8bc6\u522b\u8fde\u8d2f\u7684\u8fd0\u52a8\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u52a0\u6743\uff0c\u5e76\u4f7f\u7528\u6d41\u5f62\u5b66\u4e60\u4e0e\u4e34\u5e8a\u6570\u636e\u878d\u5408\uff0c\u6700\u7ec8\u751f\u6210\u4e00\u4e2a\u4ece0\u52301\u7684\u8fde\u7eed\u8bc4\u5206\u3002", "result": "\u5728\u5305\u542b\u5404\u79cd\u5fc3\u810f\u75c5\u7406\u548c\u6b63\u5e38\u5bf9\u7167\u7684736\u540d\u60a3\u8005\u524d\u77bb\u6027\u961f\u5217\u4e2d\uff0c\u58f0\u5b66\u6307\u6570\u5728\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e2d\u5b9e\u73b0\u4e860.89\u7684\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\u3002\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u786e\u8ba4\u4e86\u6a21\u578b\u7684\u7a33\u5065\u6027\uff0c\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u5747\u8d85\u8fc70.8\u3002\u9608\u503c\u5206\u6790\u663e\u793a\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u4e4b\u95f4\u7684\u7a33\u5b9a\u6743\u8861\u3002", "conclusion": "\u58f0\u5b66\u6307\u6570\u4f5c\u4e3a\u5fc3\u810f\u529f\u80fd\u7684\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u3001\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u65e9\u671f\u68c0\u6d4b\u3001\u5206\u8bca\u548c\u7eb5\u5411\u76d1\u6d4b\u7684\u53ef\u6269\u5c55\u5de5\u5177\u7684\u6f5c\u529b\u3002\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5305\u62ec\u5916\u90e8\u9a8c\u8bc1\u3001\u7eb5\u5411\u7814\u7a76\u4ee5\u53ca\u9002\u5e94\u75be\u75c5\u7279\u5b9a\u5206\u7c7b\u5668\u3002"}}
{"id": "2507.13956", "pdf": "https://arxiv.org/pdf/2507.13956", "abs": "https://arxiv.org/abs/2507.13956", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "categories": ["cs.AI", "cs.CV", "cs.MM"], "comment": null, "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89c9-\u8bed\u8a00\u56e0\u679c\u5e72\u9884\u6846\u67b6ADPC\uff0c\u7528\u4e8e\u8f85\u52a9\u8bca\u65ad\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u3002\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u603b\u7ed3\u4e34\u5e8a\u6570\u636e\uff0c\u5e76\u7ed3\u5408MRI\u3001fMRI\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\u5bf9\u8ba4\u77e5\u6b63\u5e38\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8fdb\u884c\u5206\u7c7b\u3002\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u6d88\u9664\u6df7\u6dc6\u56e0\u7d20\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u8d8a\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4e0e\u56e0\u679c\u63a8\u7406\u7ed3\u5408\u5728\u795e\u7ecf\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u65e9\u671f\u8bc6\u522b\u548c\u5e72\u9884\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u53ef\u4ee5\u6709\u6548\u51cf\u7f13\u75f4\u5446\u7684\u53d1\u5c55\uff0c\u4f46\u76ee\u524d\u8bca\u65ad\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u591a\u6a21\u6001\u6570\u636e\u7684\u9009\u62e9\u504f\u5dee\u548c\u53d8\u91cf\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u9020\u6210\u7684\u6df7\u6dc6\u56e0\u7d20\u3002", "method": "ADPC\u6846\u67b6\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u4e25\u683c\u6a21\u677f\u603b\u7ed3\u4e34\u5e8a\u6570\u636e\uff0c\u7ef4\u6301\u7ed3\u6784\u5316\u6587\u672c\u8f93\u51fa\uff0c\u5373\u4f7f\u6570\u636e\u96c6\u4e0d\u5b8c\u6574\u6216\u5206\u5e03\u4e0d\u5747\u3002\u5b83\u4f7f\u7528MRI\u3001fMRI\u56fe\u50cf\u548c\u7531LLM\u751f\u6210\u7684\u6587\u672c\u6570\u636e\u6765\u5c06\u53c2\u4e0e\u8005\u5206\u4e3a\u8ba4\u77e5\u6b63\u5e38\uff08CN\uff09\u3001MCI\u548cAD\u4e09\u7c7b\u3002\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u65b9\u6cd5\u6d88\u9664\u6df7\u6dc6\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u533a\u5206CN/MCI/AD\u6848\u4f8b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5728\u5927\u591a\u6570\u8bc4\u4f30\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\uff08SOTA\uff09\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c06\u56e0\u679c\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u5b66\u4e60\u76f8\u7ed3\u5408\u5728\u795e\u7ecf\u75be\u75c5\u8bca\u65ad\u4e2d\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.13556", "pdf": "https://arxiv.org/pdf/2507.13556", "abs": "https://arxiv.org/abs/2507.13556", "authors": ["Rui Wang", "Steven Klee", "Alexis Roos"], "title": "Time Series Forecastability Measures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes using two metrics to quantify the forecastability of time\nseries prior to model development: the spectral predictability score and the\nlargest Lyapunov exponent. Unlike traditional model evaluation metrics, these\nmeasures assess the inherent forecastability characteristics of the data before\nany forecast attempts. The spectral predictability score evaluates the strength\nand regularity of frequency components in the time series, whereas the Lyapunov\nexponents quantify the chaos and stability of the system generating the data.\nWe evaluated the effectiveness of these metrics on both synthetic and\nreal-world time series from the M5 forecast competition dataset. Our results\ndemonstrate that these two metrics can correctly reflect the inherent\nforecastability of a time series and have a strong correlation with the actual\nforecast performance of various models. By understanding the inherent\nforecastability of time series before model training, practitioners can focus\ntheir planning efforts on products and supply chain levels that are more\nforecastable, while setting appropriate expectations or seeking alternative\nstrategies for products with limited forecastability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u91cf\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u7684\u5ea6\u91cf\u65b9\u6cd5\uff1a\u9891\u8c31\u53ef\u9884\u6d4b\u6027\u8bc4\u5206\u548c\u6700\u5927Lyapunov\u6307\u6570\uff0c\u5e76\u5728M5\u9884\u6d4b\u7ade\u8d5b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u5728\u4efb\u4f55\u9884\u6d4b\u5c1d\u8bd5\u4e4b\u524d\u8bc4\u4f30\u6570\u636e\u7684\u56fa\u6709\u9884\u6d4b\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u5ea6\u91cf\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u9891\u8c31\u53ef\u9884\u6d4b\u6027\u8bc4\u5206\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u4e2d\u9891\u7387\u6210\u5206\u7684\u5f3a\u5ea6\u548c\u89c4\u5f8b\u6027\uff1b\u7528\u6700\u5927Lyapunov\u6307\u6570\u91cf\u5316\u751f\u6210\u6570\u636e\u7cfb\u7edf\u7684\u6df7\u6c8c\u548c\u7a33\u5b9a\u6027\u3002", "result": "\u8fd9\u4e24\u79cd\u5ea6\u91cf\u80fd\u591f\u6b63\u786e\u53cd\u6620\u65f6\u95f4\u5e8f\u5217\u7684\u56fa\u6709\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u4e0e\u4e0d\u540c\u6a21\u578b\u7684\u5b9e\u9645\u9884\u6d4b\u6027\u80fd\u6709\u5f88\u5f3a\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u901a\u8fc7\u7406\u89e3\u65f6\u95f4\u5e8f\u5217\u7684\u56fa\u6709\u9884\u6d4b\u6027\uff0c\u4ece\u4e1a\u8005\u53ef\u4ee5\u5c06\u89c4\u5212\u91cd\u70b9\u653e\u5728\u66f4\u5177\u6709\u9884\u6d4b\u6027\u7684\u4ea7\u54c1\u548c\u4f9b\u5e94\u94fe\u5c42\u7ea7\u4e0a\uff0c\u540c\u65f6\u4e3a\u9884\u6d4b\u6027\u6709\u9650\u7684\u4ea7\u54c1\u8bbe\u5b9a\u9002\u5f53\u7684\u671f\u671b\u6216\u5bfb\u6c42\u66ff\u4ee3\u7b56\u7565\u3002"}}
{"id": "2507.13958", "pdf": "https://arxiv.org/pdf/2507.13958", "abs": "https://arxiv.org/abs/2507.13958", "authors": ["Pedro Cabalar", "Mart\u00edn Di\u00e9guez", "Fran\u00e7ois Olivier", "Torsten Schaub", "Igor St\u00e9phan"], "title": "Towards Constraint Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u65f6\u95f4\u4e0e\u7ea6\u675f\u7684\u903b\u8f91\u6269\u5c55\uff0c\u589e\u5f3a\u4e86Answer Set Programming\u5904\u7406\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u903b\u8f91\u7684\u65b9\u6cd5\u5982Answer Set Programming (ASP) \u5728\u5904\u7406\u5177\u6709\u7cbe\u7ec6\u65f6\u95f4\u548c\u6570\u503c\u5206\u8fa8\u7387\u7684\u52a8\u6001\u7cfb\u7edf\u65f6\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3aASP\u7684\u65f6\u95f4\u548c\u6570\u503c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86Here-and-There\u903b\u8f91\u53ca\u5176\u975e\u5355\u8c03\u5e73\u8861\u6269\u5c55\u7684\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u548c\u7ea6\u675f\u57fa\u7840\u6269\u5c55\uff0c\u7ed3\u5408\u7ebf\u6027\u65f6\u95f4Here-and-There\u903b\u8f91\u548c\u5e26\u7ea6\u675f\u7684Here-and-There\u903b\u8f91\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u6570\u5b57\u7ea6\u675f\u7684\u76f4\u63a5\u96c6\u6210\u548c\u64cd\u4f5c\u3002", "result": "\u8be5\u8868\u8fbe\u7cfb\u7edf\u901a\u8fc7\u4e24\u79cd\u57fa\u7840ASP\u6269\u5c55\u7684\u534f\u540c\u7ec4\u5408\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u9ad8\u6548\u5904\u7406\uff0c\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u975e\u5355\u8c03\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u548c\u76f4\u63a5\u5904\u7406\u6570\u503c\u7ea6\u675f\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u5728ASP\u8303\u5f0f\u5185\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u57fa\u7840\u903b\u8f91\u6846\u67b6\u3002"}}
{"id": "2507.13569", "pdf": "https://arxiv.org/pdf/2507.13569", "abs": "https://arxiv.org/abs/2507.13569", "authors": ["Mrinal Mathur", "Mike Doan", "Barak Pearlmutter", "Sergey Plis"], "title": "Change of Thought: Adaptive Test-Time Computation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers evaluated in a single, fixed-depth pass are provably limited in\nexpressive power to the constant-depth circuit class TC0. Running a Transformer\nautoregressively removes that ceiling -- first in next-token prediction and,\nmore recently, in chain-of-thought reasoning. Both regimes rely on feedback\nloops that decode internal states into tokens only to re-encode them in\nsubsequent steps. While this \"thinking aloud\" mirrors human reasoning,\nbiological brains iterate without externalising intermediate states as\nlanguage. To boost the expressive power of encoder Transformers without\nresorting to token-level autoregression, we introduce the SELF-Transformer: an\nencoder layer that iteratively refines its own attention weights to a fixed\npoint. Instead of producing -- in one pass -- the alignment matrix that remixes\nthe input sequence, the SELF-Transformer iteratively updates that matrix\ninternally, scaling test-time computation with input difficulty. This\nadaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without\nincreasing parameter count, demonstrating that input-adaptive alignment at test\ntime offers substantial benefits for only a modest extra compute budget.\nSelf-Transformers thus recover much of the expressive power of iterative\nreasoning while preserving the simplicity of pure encoder architectures.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165SELF-Transformer\uff0c\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u53c2\u6570\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u7f16\u7801\u5668\u98ce\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u9ad8\u8fbe20%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684Transformers\u5728\u5355\u6b21\u3001\u56fa\u5b9a\u6df1\u5ea6\u4f20\u9012\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u6709\u9650\u3002\u867d\u7136\u81ea\u56de\u5f52\u8fd0\u884c\u53ef\u4ee5\u63d0\u9ad8\u5176\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u65b9\u5f0f\u9700\u8981\u5c06\u5185\u90e8\u72b6\u6001\u89e3\u7801\u4e3a\u6807\u8bb0\u7136\u540e\u518d\u91cd\u65b0\u7f16\u7801\uff0c\u7c7b\u4f3c\u4e8e\u201c\u5927\u58f0\u601d\u8003\u201d\u3002\u4e3a\u4e86\u589e\u5f3a\u7f16\u7801\u5668Transformers\u7684\u8868\u8fbe\u80fd\u529b\u5e76\u907f\u514d\u6807\u8bb0\u7ea7\u522b\u7684\u81ea\u56de\u5f52\uff0c\u6211\u4eec\u5f15\u5165\u4e86SELF-Transformer\u3002", "method": "SELF-Transformer\u662f\u4e00\u79cd\u7f16\u7801\u5c42\uff0c\u5b83\u8fed\u4ee3\u5730\u4f18\u5316\u81ea\u8eab\u7684\u6ce8\u610f\u529b\u6743\u91cd\u5230\u4e00\u4e2a\u56fa\u5b9a\u70b9\u3002\u4e0d\u662f\u4e00\u6b21\u6027\u751f\u6210\u5bf9\u9f50\u77e9\u9635\u6765\u91cd\u65b0\u6df7\u5408\u8f93\u5165\u5e8f\u5217\uff0c\u800c\u662f\u8fed\u4ee3\u5730\u5728\u5185\u90e8\u66f4\u65b0\u8be5\u77e9\u9635\uff0c\u5e76\u6839\u636e\u8f93\u5165\u96be\u5ea6\u8c03\u6574\u6d4b\u8bd5\u65f6\u7684\u8ba1\u7b97\u91cf\u3002", "result": "\u8fd9\u79cd\u9002\u5e94\u6027\u65b9\u6cd5\u5728\u7f16\u7801\u5668\u98ce\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe20%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u800c\u65e0\u9700\u589e\u52a0\u53c2\u6570\u6570\u91cf\u3002\u8fd9\u8868\u660e\uff0c\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u8f93\u5165\u9002\u5e94\u6027\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u597d\u5904\uff0c\u53ea\u9700\u8981\u9002\u5ea6\u589e\u52a0\u8ba1\u7b97\u9884\u7b97\u3002", "conclusion": "Self-Transformers\u5728\u4fdd\u7559\u7eaf\u7f16\u7801\u5668\u67b6\u6784\u7b80\u5355\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6062\u590d\u4e86\u8fed\u4ee3\u63a8\u7406\u7684\u5927\u90e8\u5206\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2507.14032", "pdf": "https://arxiv.org/pdf/2507.14032", "abs": "https://arxiv.org/abs/2507.14032", "authors": ["Lam Nguyen", "Erika Barcelos", "Roger French", "Yinghui Wu"], "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models", "categories": ["cs.AI"], "comment": "Accepted to the 24th International Semantic Web Conference Research\n  Track (ISWC 2025)", "summary": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aKROMA\u7684\u65b0OM\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\u6765\u4e30\u5bcc\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u4efb\u52a1\u7684\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u4f18\u5316\u6280\u672f\u63d0\u9ad8\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u672c\u4f53\u5339\u914d\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u4e8e\u624b\u5de5\u89c4\u5219\u6216\u9002\u5e94\u6027\u6709\u9650\u7684\u4e13\u95e8\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "KROMA\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u7a0b\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u53cc\u76f8\u4f3c\u6027\u7684\u6982\u5ff5\u5339\u914d\u548c\u8f7b\u91cf\u7ea7\u672c\u4f53\u7ec6\u5316\u6b65\u9aa4\uff0c\u4ee5\u51cf\u5c11\u5019\u9009\u6982\u5ff5\u5e76\u964d\u4f4e\u4e0eLLMs\u4ea4\u4e92\u7684\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cKROMA\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfOM\u7cfb\u7edf\u548c\u6700\u65b0\u7684LLM\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u6bd4\u7684\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4f18\u5316\u6280\u672f\uff08\u76ee\u6807\u77e5\u8bc6\u68c0\u7d22\u3001\u63d0\u793a\u8bcd\u4e30\u5bcc\u548c\u672c\u4f53\u7ec6\u5316\uff09\u5bf9\u4e8e\u5927\u89c4\u6a21\u672c\u4f53\u5339\u914d\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2507.13575", "pdf": "https://arxiv.org/pdf/2507.13575", "abs": "https://arxiv.org/abs/2507.13575", "authors": ["Hanzhi Zhou", "Erik Hornberger", "Pengsheng Guo", "Xiyou Zhou", "Saiwen Wang", "Xin Wang", "Yifei He", "Xuankai Chang", "Rene Rauch", "Louis D'hauwe", "John Peebles", "Alec Doane", "Kohen Chia", "Jenna Thibodeau", "Zi-Yi Dou", "Yuanyang Zhang", "Ruoming Pang", "Reed Li", "Zhifeng Chen", "Jeremy Warner", "Zhaoyang Xu", "Sophy Lee", "David Mizrahi", "Ramsey Tantawi", "Chris Chaney", "Kelsey Peterson", "Jun Qin", "Alex Dombrowski", "Mira Chiang", "Aiswarya Raghavan", "Gerard Casamayor", "Qibin Chen", "Aonan Zhang", "Nathalie Tran", "Jianyu Wang", "Hang Su", "Thomas Voice", "Alessandro Pappalardo", "Brycen Wershing", "Prasanth Yadla", "Rui Li", "Priyal Chhatrapati", "Ismael Fernandez", "Yusuf Goren", "Xin Zheng", "Forrest Huang", "Tao Lei", "Eray Yildiz", "Alper Kokmen", "Gokul Santhanam", "Areeba Kamal", "Kaan Elgin", "Dian Ang Yap", "Jeremy Liu", "Peter Gray", "Howard Xing", "Kieran Liu", "Matteo Ronchi", "Moritz Schwarzer-Becker", "Yun Zhu", "Mandana Saebi", "Jeremy Snow", "David Griffiths", "Guillaume Tartavel", "Erin Feldman", "Simon Lehnerer", "Fernando Berm\u00fadez-Medina", "Hans Han", "Joe Zhou", "Xiaoyi Ren", "Sujeeth Reddy", "Zirui Wang", "Tom Gunter", "Albert Antony", "Yuanzhi Li", "John Dennison", "Tony Sun", "Yena Han", "Yi Qin", "Sam Davarnia", "Jeffrey Bigham", "Wayne Shan", "Hannah Gillis Coleman", "Guillaume Klein", "Peng Liu", "Muyang Yu", "Jack Cackler", "Yuan Gao", "Crystal Xiao", "Binazir Karimzadeh", "Zhengdong Zhang", "Felix Bai", "Albin Madappally Jose", "Feng Nan", "Nazir Kamaldin", "Dong Yin", "Hans Hao", "Yanchao Sun", "Yi Hua", "Charles Maalouf", "Alex Guillen Garcia", "Guoli Yin", "Lezhi Li", "Mohana Prasad Sathya Moorthy", "Hongbin Gao", "Jay Tang", "Joanna Arreaza-Taylor", "Faye Lao", "Carina Peng", "Josh Shaffer", "Dan Masi", "Sushma Rao", "Tommi Vehvilainen", "Senyu Tong", "Dongcai Shen", "Yang Zhao", "Chris Bartels", "Peter Fu", "Qingqing Cao", "Christopher Neubauer", "Ethan Li", "Mingfei Gao", "Rebecca Callahan", "Richard Wei", "Patrick Dong", "Alex Braunstein", "Sachin Ravi", "Adolfo Lopez Mendez", "Kaiwei Huang", "Kun Duan", "Haoshuo Huang", "Rui Qian", "Stefano Ligas", "Jordan Huffaker", "Dongxu Li", "Bailin Wang", "Nanzhu Wang", "Anuva Agarwal", "Tait Madsen", "Josh Newnham", "Abhishek Sharma", "Zhile Ren", "Deepak Gopinath", "Erik Daxberger", "Saptarshi Guha", "Oron Levy", "Jing Lu", "Nan Dun", "Marc Kirchner", "Yinfei Yang", "Manjot Bilkhu", "Dave Nelson", "Anthony Spalvieri-Kruse", "Juan Lao Tebar", "Yang Xu", "Phani Mutyala", "Gabriel Jacoby-Cooper", "Yingbo Wang", "Karla Vega", "Vishaal Mahtani", "Darren Botten", "Eric Wang", "Hanli Li", "Matthias Paulik", "Haoran Yan", "Navid Shiee", "Yihao Qian", "Bugu Wu", "Qi Zhu", "Ob Adaranijo", "Bhuwan Dhingra", "Zhe Gan", "Nicholas Seidl", "Grace Duanmu", "Rong Situ", "Yiping Ma", "Yin Xia", "David Riazati", "Vasileios Saveris", "Anh Nguyen", "Michael", "Lee", "Patrick Sonnenberg", "Chinguun Erdenebileg", "Yanghao Li", "Vivian Ma", "James Chou", "Isha Garg", "Mark Lee", "Keen You", "Yuhong Li", "Ransen Niu", "Nandhitha Raghuram", "Pulkit Agrawal", "Henry Mason", "Sumeet Singh", "Keyu He", "Hong-You Chen", "Lucas Guibert", "Shiyu Li", "Varsha Paidi", "Narendran Raghavan", "Mingze Xu", "Yuli Yang", "Sergiu Sima", "Irina Belousova", "Sprite Chu", "Afshin Dehghan", "Philipp Dufter", "David Haldimann", "Zhen Yang", "Margit Bowler", "Chang Liu", "Ying-Chang Cheng", "Vivek Rathod", "Syd Evans", "Wilson Tsao", "Dustin Withers", "Haitian Sun", "Biyao Wang", "Peter Grasch", "Walker Cheng", "Yihao Feng", "Vivek Kumar", "Frank Chu", "Victoria M\u00f6nchJuan Haladjian", "Doug Kang", "Jiarui Lu", "Ciro Sannino", "Max Lam", "Floris Weers", "Bowen Pan", "Kenneth Jung", "Dhaval Doshi", "Fangping Shi", "Olli Saarikivi", "Alp Aygar", "Josh Elman", "Cheng Leong", "Eshan Verma", "Matthew Lei", "Jeff Nichols", "Jiulong Shan", "Donald Zhang", "Lawrence Zhou", "Stephen Murphy", "Xianzhi Du", "Chang Lan", "Ankur Jain", "Elmira Amirloo", "Marcin Eichner", "Naomy Sabo", "Anupama Mann Anupama", "David Qiu", "Zhao Meng", "Michael FitzMaurice", "Peng Zhang", "Simon Yeung", "Chen Chen", "Marco Zuliani", "Andrew Hansen", "Yang Lu", "Brent Ramerth", "Ziyi Zhong", "Parsa Mazaheri", "Matthew Hopkins", "Mengyu Li", "Simon Wang", "David Chen", "Farzin Rasteh", "Chong Wang", "Josh Gardner", "Asaf Liberman", "Haoxuan You", "Andrew Walkingshaw", "Xingyu Zhou", "Jinhao Lei", "Yan Meng", "Quentin Keunebroek", "Sam Wiseman", "Anders Boesen Lindbo Larsen", "Yi Zhang", "Zaid Ahmed", "Haiming Gang", "Aaron Franklin", "Kelvin Zou", "Guillaume Seguin", "Jonathan Janke", "Rachel Burger", "Co Giang", "Cheng Shen", "Jen Liu", "Sanskruti Shah", "Xiang Kong", "Yiran Fei", "TJ Collins", "Chen Zhang", "Zhiyun Lu", "Michael Booker", "Qin Ba", "Yasutaka Tanaka", "Andres Romero Mier Y Teran", "Federico Scozzafava", "Regan Poston", "Jane Li", "Eduardo Jimenez", "Bas Straathof", "Karanjeet Singh", "Lindsay Hislop", "Rajat Arora", "Deepa Seshadri", "Boyue Li", "Colorado Reed", "Zhen Li", "TJ Lu", "Yi Wang", "Kaelen Haag", "Nicholas Lusskin", "Raunak Sinha", "Rahul Nair", "Eldon Schoop", "Mary Beth Kery", "Mehrdad Farajtbar", "Brenda Yang", "George Horrell", "Shiwen Zhao", "Dhruti Shah", "Cha Chen", "Bowen Zhang", "Chang Gao", "Devi Krishna", "Jennifer Mallalieu", "Javier Movellan", "Di Feng", "Emily Zhang", "Sam Xu", "Junting Pan", "Dominik Moritz", "Suma Jayaram", "Kevin Smith", "Dongseong Hwang", "Daniel Parilla", "Jiaming Hu", "You-Cyuan Jhang", "Emad Soroush", "Fred Hohman", "Nan Du", "Emma Wang", "Sam Dodge", "Pragnya Sridhar", "Joris Pelemans", "Wei Fang", "Nina Wenzel", "Joseph Yitan Cheng", "Hadas Kotek", "Chung-Cheng Chiu", "Meng Cao", "Haijing Fu", "Ruixuan Hou", "Ke Ye", "Diane Zhu", "Nikhil Bhendawade", "Joseph Astrauskas", "Jian Liu", "Sai Aitharaju", "Wentao Wu", "Artsiom Peshko", "Hyunjik Kim", "Nilesh Shahdadpuri", "Andy De Wang", "Qi Shan", "Piotr Maj", "Raul Rea Menacho", "Justin Lazarow", "Eric Liang Yang", "Arsalan Farooq", "Donghan Yu", "David G\u00fcera", "Minsik Cho", "Kavya Nerella", "Yongqiang Wang", "Tao Jia", "John Park", "Jeff Lai", "Haotian Zhang", "Futang Peng", "Daniele Molinari", "Aparna Rajamani", "Tyler Johnson", "Lauren Gardiner", "Chao Jia", "Violet Yao", "Wojciech Kryscinski", "Xiujun Li", "Shang-Chen Wu"], "title": "Apple Intelligence Foundation Language Models: Tech Report 2025", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce two multilingual, multimodal foundation language models that\npower Apple Intelligence features across Apple devices and services: i a\n3B-parameter on-device model optimized for Apple silicon through architectural\ninnovations such as KV-cache sharing and 2-bit quantization-aware training; and\nii a scalable server model built on a novel Parallel-Track Mixture-of-Experts\nPT-MoE transformer that combines track parallelism, mixture-of-experts sparse\ncomputation, and interleaved global-local attention to deliver high quality\nwith competitive cost on Apple's Private Cloud Compute platform. Both models\nare trained on large-scale multilingual and multimodal datasets sourced via\nresponsible web crawling, licensed corpora, and high-quality synthetic data,\nthen further refined with supervised fine-tuning and reinforcement learning on\na new asynchronous platform. The resulting models support several additional\nlanguages while understanding images and executing tool calls. In public\nbenchmarks and human evaluations, both the server model and the on-device model\nmatch or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation,\nconstrained tool calling, and LoRA adapter fine-tuning, allowing developers to\nintegrate these capabilities with a few lines of code. The latest advancements\nin Apple Intelligence models are grounded in our Responsible AI approach with\nsafeguards like content filtering and locale-specific evaluation, as well as\nour commitment to protecting our users' privacy with innovations like Private\nCloud Compute.", "AI": {"tldr": "\u82f9\u679c\u516c\u53f8\u63a8\u51fa\u4e86\u4e24\u6b3e\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u7684\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u522b\u9488\u5bf9\u8bbe\u5907\u7aef\u548c\u670d\u52a1\u5668\u7aef\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u548c\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002\u8fd9\u4e9b\u6a21\u578b\u652f\u6301\u591a\u79cd\u8bed\u8a00\u548c\u56fe\u50cf\u7406\u89e3\uff0c\u5e76\u4e14\u5728\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u548c\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u8bbe\u5907\u548c\u670d\u52a1\u7684\u9700\u6c42\u589e\u957f\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u3001\u9ad8\u6548\u5e76\u4e14\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u8bed\u8a00\u6a21\u578b\u6765\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u5982KV-cache\u5171\u4eab\u548c2-bit\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4f18\u5316\u76843B\u53c2\u6570\u8bbe\u5907\u7aef\u6a21\u578b\uff1b\u4ee5\u53ca\u57fa\u4e8eParallel-Track Mixture-of-Experts (PT-MoE) transformer\u7684\u53ef\u6269\u5c55\u670d\u52a1\u5668\u6a21\u578b\u3002\u4e24\u8005\u5747\u4f7f\u7528\u8d1f\u8d23\u4efb\u7684\u7f51\u7edc\u722c\u866b\u3001\u8bb8\u53ef\u8bed\u6599\u5e93\u548c\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u8fdb\u884c\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u5e76\u7ecf\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u8fd9\u4e24\u4e2a\u6a21\u578b\u5728\u591a\u8bed\u8a00\u652f\u6301\u3001\u56fe\u50cf\u7406\u89e3\u548c\u5de5\u5177\u8c03\u7528\u65b9\u9762\u90fd\u6709\u663e\u8457\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u548c\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u540c\u7b49\u89c4\u6a21\u7684\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u82f9\u679c\u7684\u65b0\u6a21\u578b\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5176\u8bbe\u5907\u548c\u670d\u52a1\u4e2d\u7684\u667a\u80fd\u529f\u80fd\uff0c\u8fd8\u901a\u8fc7Swift-centric\u6846\u67b6\u7b80\u5316\u4e86\u5f00\u53d1\u8005\u7684\u96c6\u6210\u8fc7\u7a0b\uff0c\u540c\u65f6\u575a\u6301\u4e86\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u548c\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.14077", "pdf": "https://arxiv.org/pdf/2507.14077", "abs": "https://arxiv.org/abs/2507.14077", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "categories": ["cs.AI", "cs.LG"], "comment": "19 pages, 3 figures, 6 tables", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Glucose-ML\uff0c\u4e00\u4e2a\u5305\u542b\u6765\u81ea4\u4e2a\u56fd\u5bb6\u76842500\u591a\u4eba\u7684\u8d85\u8fc7300,000\u5929\u8fde\u7eed\u8461\u8404\u7cd6\u76d1\u6d4b\u6570\u636e\u7684\u96c6\u5408\uff0c\u65e8\u5728\u4fc3\u8fdb\u900f\u660e\u3001\u53ef\u91cd\u590d\u548c\u5f3a\u5927\u7684AI\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\uff0c\u5e76\u4e3a\u7b97\u6cd5\u5f00\u53d1\u8005\u63d0\u4f9b\u6570\u636e\u9009\u62e9\u6307\u5bfc\u3002", "motivation": "\u5f00\u53d1\u5f3a\u5927AI\u89e3\u51b3\u65b9\u6848\u4ee5\u7ba1\u7406\u7cd6\u5c3f\u75c5\u7684\u4e00\u4e2a\u4e3b\u8981\u969c\u788d\u662f\u83b7\u53d6\u5927\u578b\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u3002\u4e3a\u4e86\u52a0\u901fAI\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\uff0c\u9700\u8981\u521b\u5efa\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u7814\u7a76\u548c\u521b\u65b0\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86Glucose-ML\u6570\u636e\u96c6\u96c6\u5408\uff0c\u5b83\u5305\u542b\u4e8610\u4e2a\u516c\u5171\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5bf9\u8fd9\u4e9b\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u4ee5\u5f15\u5bfc\u7b97\u6cd5\u5f00\u53d1\u8005\u8fdb\u884c\u6570\u636e\u9009\u62e9\u5e76\u63d0\u4f9b\u77ed\u671f\u8840\u7cd6\u9884\u6d4b\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u6570\u636e\u96c6\u5f00\u53d1/\u8bc4\u4f30\u65f6\uff0c\u540c\u4e00\u7b97\u6cd5\u53ef\u4ee5\u4ea7\u751f\u663e\u8457\u4e0d\u540c\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7528\u4e8e\u63d0\u51fa\u5728\u7cd6\u5c3f\u75c5\u6216\u5176\u4ed6\u66f4\u5e7f\u6cdb\u7684\u5065\u5eb7\u9886\u57df\u4e2d\u5f00\u53d1\u7a33\u5065AI\u89e3\u51b3\u65b9\u6848\u7684\u5efa\u8bae\u3002\u63d0\u4f9b\u4e86\u6bcf\u4e2a\u7eb5\u5411\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u7684\u76f4\u63a5\u94fe\u63a5\u4ee5\u53ca\u5f00\u653e\u4ee3\u7801\u3002"}}
{"id": "2507.13579", "pdf": "https://arxiv.org/pdf/2507.13579", "abs": "https://arxiv.org/abs/2507.13579", "authors": ["Hyunji Nam", "Yanming Wan", "Mickel Liu", "Jianxun Lian", "Natasha Jaques"], "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages", "summary": "As everyday use cases of large language model (LLM) AI assistants have\nexpanded, it is becoming increasingly important to personalize responses to\nalign to different users' preferences and goals. While reinforcement learning\nfrom human feedback (RLHF) is effective at improving LLMs to be generally more\nhelpful and fluent, it does not account for variability across users, as it\nmodels the entire user population with a single reward model. We present a\nnovel framework, Preference Learning Using Summarization (PLUS), that learns\ntext-based summaries of each user's preferences, characteristics, and past\nconversations. These summaries condition the reward model, enabling it to make\npersonalized predictions about the types of responses valued by each user. We\ntrain the user-summarization model with reinforcement learning, and update the\nreward model simultaneously, creating an online co-adaptation loop. We show\nthat in contrast with prior personalized RLHF techniques or with in-context\nlearning of user information, summaries produced by PLUS capture meaningful\naspects of a user's preferences. Across different pluralistic user datasets, we\nshow that our method is robust to new users and diverse conversation topics.\nAdditionally, we demonstrate that the textual summaries generated about users\ncan be transferred for zero-shot personalization of stronger, proprietary\nmodels like GPT-4. The resulting user summaries are not only concise and\nportable, they are easy for users to interpret and modify, allowing for more\ntransparency and user control in LLM alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6PLUS\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u6bcf\u4e2a\u7528\u6237\u7684\u6587\u672c\u6458\u8981\uff0c\u5e76\u540c\u65f6\u66f4\u65b0\u5956\u52b1\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u9884\u6d4b\u3002\u4e0e\u5148\u524d\u7684\u6280\u672f\u76f8\u6bd4\uff0cPLUS\u5728\u5904\u7406\u65b0\u7528\u6237\u548c\u591a\u6837\u5316\u8bdd\u9898\u65b9\u9762\u8868\u73b0\u5f97\u66f4\u52a0\u7a33\u5065\uff0c\u5e76\u4e14\u53ef\u4ee5\u8fc1\u79fb\u5230\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u5982GPT-4\u4e2d\u8fdb\u884c\u96f6\u6837\u672c\u4e2a\u6027\u5316\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09AI\u52a9\u624b\u7684\u65e5\u5e38\u5e94\u7528\u6269\u5c55\uff0c\u4e2a\u6027\u5316\u54cd\u5e94\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u65b9\u6cd5\u65e0\u6cd5\u8003\u8651\u5230\u4e0d\u540c\u7528\u6237\u4e4b\u95f4\u7684\u5dee\u5f02\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u7528\u5355\u4e00\u7684\u5956\u52b1\u6a21\u578b\u6765\u6a21\u62df\u6574\u4e2a\u7528\u6237\u7fa4\u4f53\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPLUS\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u603b\u7ed3\u6bcf\u4e2a\u7528\u6237\u7684\u504f\u597d\u3001\u7279\u5f81\u548c\u8fc7\u53bb\u7684\u5bf9\u8bdd\u6765\u751f\u6210\u6587\u672c\u6458\u8981\u3002\u8fd9\u4e9b\u6458\u8981\u7528\u4e8e\u8c03\u8282\u5956\u52b1\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u505a\u51fa\u4e2a\u6027\u5316\u7684\u9884\u6d4b\u3002\u7528\u6237\u6458\u8981\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\uff0c\u540c\u65f6\u66f4\u65b0\u5956\u52b1\u6a21\u578b\uff0c\u521b\u5efa\u5728\u7ebf\u534f\u540c\u9002\u5e94\u5faa\u73af\u3002", "result": "PLUS\u751f\u6210\u7684\u6458\u8981\u6355\u6349\u5230\u4e86\u7528\u6237\u504f\u597d\u7684\u6709\u610f\u4e49\u65b9\u9762\uff0c\u5728\u4e0d\u540c\u7684\u591a\u7528\u6237\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5bf9\u65b0\u7528\u6237\u548c\u591a\u6837\u5316\u7684\u5bf9\u8bdd\u4e3b\u9898\u5177\u6709\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u6240\u751f\u6210\u7684\u7528\u6237\u6587\u672c\u6458\u8981\u53ef\u4ee5\u8fc1\u79fb\u5230\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u5982GPT-4\u4e2d\u8fdb\u884c\u96f6\u6837\u672c\u4e2a\u6027\u5316\u3002", "conclusion": "PLUS\u751f\u6210\u7684\u7528\u6237\u6458\u8981\u662f\u7b80\u6d01\u548c\u53ef\u79fb\u690d\u7684\uff0c\u6613\u4e8e\u7528\u6237\u7406\u89e3\u548c\u4fee\u6539\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86LLM\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u7528\u6237\u63a7\u5236\u3002"}}
{"id": "2507.14097", "pdf": "https://arxiv.org/pdf/2507.14097", "abs": "https://arxiv.org/abs/2507.14097", "authors": ["Hari Iyer", "Neel Macwan", "Atharva Jitendra Hude", "Heejin Jeong", "Shenghan Guo"], "title": "Generative AI-Driven High-Fidelity Human Motion Simulation", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u4eba\u4f53\u8fd0\u52a8\u6a21\u62df\u65b9\u6cd5\uff08G-AI-HMS\uff09\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u52a8\u4f5c\u7684\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u4f53\u8fd0\u52a8\u6a21\u62df\u65b9\u6cd5\u901a\u5e38\u5b58\u5728\u8fd0\u52a8\u4fdd\u771f\u5ea6\u4f4e\u7684\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u5176\u5728\u5de5\u4e1a\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u901a\u8fc7\u6574\u5408\u6587\u672c\u5230\u6587\u672c\u548c\u6587\u672c\u5230\u8fd0\u52a8\u6a21\u578b\uff0cG-AI-HMS\u5c06\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u4e0eMotionGPT\u8bad\u7ec3\u8bcd\u6c47\u4e00\u81f4\u7684\u52a8\u4f5c\u611f\u77e5\u8bed\u8a00\uff0c\u5e76\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u9a8c\u8bc1\u589e\u5f3a\u578b\u52a8\u4f5c\u7684\u771f\u5b9e\u6027\u3002", "result": "\u5728\u6d89\u53ca\u516b\u4e2a\u4efb\u52a1\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cAI\u589e\u5f3a\u7684\u52a8\u4f5c\u5728\u516d\u4e2a\u4efb\u52a1\u7684\u7a7a\u95f4\u51c6\u786e\u6027\u3001\u56db\u4e2a\u4efb\u52a1\u7684\u59ff\u52bf\u5f52\u4e00\u5316\u540e\u5bf9\u9f50\u4ee5\u53ca\u4e03\u4e2a\u4efb\u52a1\u7684\u6574\u4f53\u65f6\u95f4\u76f8\u4f3c\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u8bef\u5dee\u3002\u7edf\u8ba1\u5206\u6790\u663e\u793aAI\u589e\u5f3a\u663e\u8457\u964d\u4f4e\u4e86\u5173\u8282\u8bef\u5dee\u548c\u65f6\u95f4\u9519\u4f4d\u3002", "conclusion": "G-AI-HMS\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709HMS\u6280\u672f\u4e2d\u5b58\u5728\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5373\u4efb\u52a1\u63cf\u8ff0\u5230\u52a8\u4f5c\u611f\u77e5\u8bed\u8a00\u7684\u8f6c\u6362\u548cAI\u589e\u5f3a\u52a8\u4f5c\u7684\u771f\u5b9e\u611f\u9a8c\u8bc1\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7269\u7406\u4efb\u52a1\u6a21\u62df\u7684\u8d28\u91cf\u3002"}}
{"id": "2507.13608", "pdf": "https://arxiv.org/pdf/2507.13608", "abs": "https://arxiv.org/abs/2507.13608", "authors": ["Yudai Hayashi", "Shuhei Goda", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for Matching Markets", "categories": ["cs.LG", "cs.IR"], "comment": "RecSys'25", "summary": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u5339\u914d\u5e02\u573a\u7684\u65b0\u578bOPE\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u7ed3\u5408\u76f4\u63a5\u65b9\u6cd5\u3001\u9006\u503e\u5411\u8bc4\u5206\u548c\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u5e76\u5f15\u5165\u4e2d\u95f4\u6807\u7b7e\u4ee5\u63d0\u9ad8\u504f\u5dee-\u65b9\u5dee\u63a7\u5236\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b0\u65b9\u6cd5\u5728\u79bb\u7ebf\u8bc4\u4f30\u548c\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "A/B\u6d4b\u8bd5\u662f\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4e2d\u5339\u914d\u5e02\u573a\u7684\u65b0\u7b56\u7565\u7684\u9ec4\u91d1\u6807\u51c6\uff0c\u4f46\u9891\u7e41\u66f4\u65b0\u7b56\u7565\u65f6\u6210\u672c\u9ad8\u4e14\u4e0d\u5207\u5b9e\u9645\u3002\u79bb\u7ebf\u65e5\u5fd7\u6570\u636e\u7684\u79bb\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u867d\u7136\u91cd\u8981\uff0c\u4f46\u5728\u5339\u914d\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u548c\u53cc\u5411\u7528\u6237\u4ea4\u4e92\u4e2d\uff0c\u4f20\u7edfOPE\u65b9\u6cd5\u7531\u4e8e\u65b9\u5dee\u95ee\u9898\u548c\u5956\u52b1\u7a00\u758f\u6027\u53d8\u5f97\u4e0d\u53ef\u9760\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684OPE\u8bc4\u4f30\u5668\u2014\u2014DiPS\u548cDPR\uff0c\u8fd9\u4e9b\u8bc4\u4f30\u5668\u878d\u5408\u4e86\u76f4\u63a5\u65b9\u6cd5\u3001\u9006\u503e\u5411\u8bc4\u5206\u548c\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\u7684\u5143\u7d20\uff0c\u5e76\u5229\u7528\u4e86\u8bf8\u5982\u521d\u6b65\u53c2\u4e0e\u4fe1\u53f7\u7b49\u4e2d\u95f4\u6807\u7b7e\u6765\u6539\u8fdb\u504f\u5dee-\u65b9\u5dee\u63a7\u5236\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u6240\u63d0\u8bc4\u4f30\u5668\u7684\u504f\u5dee\u548c\u65b9\u5dee\u7279\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u4eec\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u5de5\u4f5c\u5339\u914d\u5e73\u53f0\u7684A/B\u6d4b\u8bd5\u65e5\u5fd7\u8fdb\u884c\u7684\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b0\u65b9\u6cd5\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684OPE\u8bc4\u4f30\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5339\u914d\u5e02\u573a\u4e2d\u79bb\u7ebf\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u53ef\u65e0\u7f1d\u6269\u5c55\u5230\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ece\u800c\u6539\u5584\u63a8\u8350\u7b56\u7565\u4ee5\u5b9e\u73b0\u66f4\u591a\u7684\u5339\u914d\u3002"}}
{"id": "2507.14107", "pdf": "https://arxiv.org/pdf/2507.14107", "abs": "https://arxiv.org/abs/2507.14107", "authors": ["Viraj Nishesh Darji", "Callie C. Liao", "Duoduo Liao"], "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89e3\u91ca\u975e\u7834\u574f\u6027\u8bc4\u4f30\uff08NDE\uff09\u8f6e\u5ed3\u56fe\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u63d0\u9ad8\u6865\u6881\u72b6\u51b5\u5206\u6790\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u8bc4\u4f30\u4e5d\u4e2aLLM\u6a21\u578b\u5bf9\u4e94\u79cd\u4e0d\u540cNDE\u8f6e\u5ed3\u56fe\u7684\u89e3\u6790\u80fd\u529b\uff0c\u53d1\u73b0\u56db\u4e2a\u6a21\u578b\u80fd\u63d0\u4f9b\u66f4\u4f18\u8d28\u7684\u56fe\u50cf\u63cf\u8ff0\uff0c\u5e76\u7531\u5176\u4e2d\u4e24\u4e2a\u6a21\u578b\u751f\u6210\u66f4\u6709\u6548\u7684\u603b\u7ed3\u3002\u8fd9\u8868\u660eLLMs\u6709\u6f5c\u529b\u6539\u5584\u6865\u6881\u7ef4\u62a4\u51b3\u7b56\u7684\u901f\u5ea6\u548c\u8d28\u91cf\u3002", "motivation": "\u6865\u6881\u7684\u7ef4\u62a4\u548c\u5b89\u5168\u5bf9\u4e8e\u4ea4\u901a\u90e8\u95e8\u81f3\u5173\u91cd\u8981\uff0c\u800c\u975e\u7834\u574f\u6027\u8bc4\u4f30\uff08NDE\uff09\u6280\u672f\u662f\u8bc4\u4f30\u7ed3\u6784\u5b8c\u6574\u6027\u7684\u5173\u952e\u624b\u6bb5\u3002\u7136\u800c\uff0c\u89e3\u8bfbNDE\u6570\u636e\u65e2\u8017\u65f6\u53c8\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u53ef\u80fd\u4f1a\u5ef6\u8bef\u51b3\u7b56\u3002\u56e0\u6b64\uff0c\u5229\u7528\u6700\u65b0\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u81ea\u52a8\u5316\u5e76\u6539\u8fdb\u8fd9\u79cd\u5206\u6790\u7684\u9700\u6c42\u5e94\u8fd0\u800c\u751f\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u5168\u9762\u8bc4\u4f30LLMs\u89e3\u91caNDE\u8f6e\u5ed3\u56fe\u7684\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u5c06LLMs\u6574\u5408\u5230\u6865\u6881\u68c0\u67e5\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u6846\u67b6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u4e2d\u63a2\u7d22\u4e86\u51e0\u79cdLLM\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u63d0\u793a\u8bed\u4ee5\u63d0\u5347\u56fe\u50cf\u63cf\u8ff0\u7684\u8d28\u91cf\u3002\u8fd9\u4e9b\u6a21\u578b\u88ab\u7528\u6765\u89e3\u91ca\u901a\u8fc7\u8bc4\u4f30\u6865\u6881\u72b6\u51b5\u7684\u6280\u672f\u6240\u83b7\u5f97\u7684\u4e94\u79cd\u4e0d\u540c\u7684NDE\u8f6e\u5ed3\u56fe\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u8bc4\u4f30\u7684\u4e5d\u4e2a\u6a21\u578b\u4e2d\u6709\u56db\u4e2a\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u56fe\u50cf\u63cf\u8ff0\uff0c\u6db5\u76d6\u4e0e\u6865\u6881\u72b6\u51b5\u76f8\u5173\u7684\u5e7f\u6cdb\u8bdd\u9898\u3002\u7279\u522b\u662fChatGPT-4\u548cClaude 3.5 Sonnet\u8fd9\u4e24\u4e2a\u6a21\u578b\u751f\u6210\u4e86\u66f4\u4e3a\u6709\u6548\u7684\u603b\u7ed3\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cLLMs\u6709\u53ef\u80fd\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u6865\u6881\u7ef4\u62a4\u548c\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u66f4\u5feb\u7684\u51b3\u7b56\u652f\u6301\u3002\u8be5\u8bd5\u70b9\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u5e76\u884c\u4f7f\u7528LLMs\u8fdb\u884c\u56fe\u50cf\u5b57\u5e55\u548c\u603b\u7ed3\uff0c\u4ece\u800c\u589e\u5f3a\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u3002"}}
{"id": "2507.13620", "pdf": "https://arxiv.org/pdf/2507.13620", "abs": "https://arxiv.org/abs/2507.13620", "authors": ["Binxiong Li", "Yuefei Wang", "Xu Xiang", "Xue Li", "Binyu Zhao", "Heyang Gao", "Qinyu Zhao", "Xi Yu"], "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "categories": ["cs.LG"], "comment": "The source code for this study is available at\n  https://github.com/YF-W/Tri-GFN", "summary": "In recent years, models based on Graph Convolutional Networks (GCN) have made\nsignificant strides in the field of graph data analysis. However, challenges\nsuch as over-smoothing and over-compression remain when handling large-scale\nand complex graph datasets, leading to a decline in clustering quality.\nAlthough the Graph Transformer architecture has mitigated some of these issues,\nits performance is still limited when processing heterogeneous graph data. To\naddress these challenges, this study proposes a novel deep clustering framework\nthat comprising GCN, Autoencoder (AE), and Graph Transformer, termed the\nTri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the\ndifferentiation and consistency of global and local information through a\nunique tri-learning mechanism and feature fusion enhancement strategy. The\nframework integrates GCN, AE, and Graph Transformer modules. These components\nare meticulously fused by a triple-channel enhancement module, which maximizes\nthe use of both node attributes and topological structures, ensuring robust\nclustering representation. The tri-learning mechanism allows mutual learning\namong these modules, while the feature fusion strategy enables the model to\ncapture complex relationships, yielding highly discriminative representations\nfor graph clustering. It surpasses many state-of-the-art methods, achieving an\naccuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the\nReuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding\nperformance on the Reuters dataset, Tri-GFN can be applied to automatic news\nclassification, topic retrieval, and related fields.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u805a\u7c7b\u6846\u67b6\uff0c\u79f0\u4e3aTri-GFN\uff0c\u7ed3\u5408\u4e86GCN\u3001AE\u548cGraph Transformer\u6a21\u5757\u3002\u901a\u8fc7\u4e09\u5b66\u4e60\u673a\u5236\u548c\u7279\u5f81\u878d\u5408\u7b56\u7565\uff0c\u8be5\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u590d\u6742\u56fe\u6570\u636e\u96c6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728Reuters\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e8614.14%\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eGCN\u7684\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u548c\u590d\u6742\u7684\u56fe\u6570\u636e\u65f6\u9047\u5230\u4e86\u8fc7\u5ea6\u5e73\u6ed1\u548c\u8fc7\u5ea6\u538b\u7f29\u7684\u95ee\u9898\uff0c\u800cGraph Transformer\u67b6\u6784\u867d\u7136\u7f13\u89e3\u4e86\u4e00\u4e9b\u95ee\u9898\uff0c\u4f46\u5728\u5904\u7406\u5f02\u6784\u56fe\u6570\u636e\u65f6\u6027\u80fd\u4ecd\u7136\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTri-GFN\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5305\u62ecGCN\u3001Autoencoder (AE) \u548cGraph Transformer\uff0c\u5e76\u901a\u8fc7\u4e09\u901a\u9053\u589e\u5f3a\u6a21\u5757\u5c06\u8fd9\u4e9b\u7ec4\u4ef6\u7cbe\u5fc3\u878d\u5408\u3002\u5229\u7528\u4e09\u5b66\u4e60\u673a\u5236\u548c\u7279\u5f81\u878d\u5408\u589e\u5f3a\u7b56\u7565\u6765\u52a0\u5f3a\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u7684\u4e00\u81f4\u6027\u548c\u5dee\u5f02\u6027\u3002", "result": "\u8be5\u6846\u67b6\u5728ACM\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u7ea60.87%\uff0c\u5728Reuters\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e8614.14%\uff0c\u5728USPS\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e867.58%\u3002", "conclusion": "\u7531\u4e8e\u5176\u5728Reuters\u6570\u636e\u96c6\u4e0a\u7684\u5353\u8d8a\u8868\u73b0\uff0cTri-GFN\u53ef\u4ee5\u5e94\u7528\u4e8e\u81ea\u52a8\u65b0\u95fb\u5206\u7c7b\u3001\u4e3b\u9898\u68c0\u7d22\u7b49\u76f8\u5173\u9886\u57df\u3002"}}
{"id": "2507.14111", "pdf": "https://arxiv.org/pdf/2507.14111", "abs": "https://arxiv.org/abs/2507.14111", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": "Preprint Version", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aCUDA-L1\u7684\u81ea\u52a8\u5316\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316CUDA\u6027\u80fd\u3002\u5b83\u5728NVIDIA A100\u4e0a\u8bad\u7ec3\uff0c\u5728KernelBench\u4e0a\u7684250\u4e2aCUDA\u5185\u6838\u4e2d\u5e73\u5747\u52a0\u901f\u4e8617.7\u500d\uff0c\u6700\u9ad8\u53ef\u8fbe449\u500d\u3002\u5e76\u4e14\u8be5\u6a21\u578b\u5177\u6709\u826f\u597d\u7684GPU\u67b6\u6784\u79fb\u690d\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9GPU\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u8feb\u5207\u9700\u8981\u81ea\u52a8\u5316\u7684CUDA\u4f18\u5316\u7b56\u7565\u3002\u7136\u800c\uff0c\u76ee\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u63d0\u9ad8CUDA\u901f\u5ea6\u65b9\u9762\u7684\u6210\u529f\u7387\u8f83\u4f4e\u3002", "method": "\u5f15\u5165\u4e86CUDA-L1\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5316CUDA\u4f18\u5316\u6846\u67b6\u3002\u5b83\u901a\u8fc7\u52a0\u901f\u6bd4\u5956\u52b1\u4fe1\u53f7\u5c06\u6700\u521d\u8868\u73b0\u4e0d\u4f73\u7684LLM\u8f6c\u6362\u4e3a\u6709\u6548\u7684CUDA\u4f18\u5316\u5668\uff0c\u65e0\u9700\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u6216\u9886\u57df\u77e5\u8bc6\u3002", "result": "CUDA-L1\u5728\u5404\u79cdGPU\u67b6\u6784\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u80fd\u591f\u53d1\u73b0\u591a\u6837\u5316\u7684CUDA\u4f18\u5316\u6280\u672f\uff0c\u8bc6\u522b\u975e\u660e\u663e\u7684\u6027\u80fd\u74f6\u9888\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u52a0\u901f\u6bd4\u5956\u52b1\u673a\u5236\u5c06\u4e00\u4e2a\u521d\u59cb\u6027\u80fd\u8f83\u5dee\u7684LLM\u8f6c\u53d8\u4e3a\u9ad8\u6548\u7684CUDA\u4f18\u5316\u5668\u3002\u8fd9\u4e3a\u81ea\u52a8\u4f18\u5316CUDA\u64cd\u4f5c\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u6709\u671b\u5927\u5e45\u63d0\u5347GPU\u6548\u7387\u5e76\u7f13\u89e3GPU\u8ba1\u7b97\u8d44\u6e90\u7684\u538b\u529b\u3002"}}
{"id": "2507.13624", "pdf": "https://arxiv.org/pdf/2507.13624", "abs": "https://arxiv.org/abs/2507.13624", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ba2\u6237\u7aef\u8df3\u8fc7\u7b97\u6cd5FedSkipTwin\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u7684\u6570\u5b57\u5b6a\u751f\u9884\u6d4b\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u91cd\u8981\u6027\u4e0e\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u5728UCI-HAR\u548cMNIST\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u901a\u4fe1\u5f00\u9500\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5e26\u5bbd\u53d7\u9650\u7684\u79fb\u52a8\u548c\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5e94\u7528\u4e2d\u3002\u4e3a\u4e86\u8282\u7701\u5e26\u5bbd\u5e76\u63d0\u9ad8\u6548\u7387\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u667a\u80fd\u5730\u51b3\u5b9a\u4f55\u65f6\u8fdb\u884c\u901a\u4fe1\u7684\u65b9\u6cd5\u3002", "method": "FedSkipTwin\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684\u670d\u52a1\u5668\u7aef\u6570\u5b57\u5b6a\u751f\uff08\u7b80\u5355LSTM\u6a21\u578b\uff09\uff0c\u6839\u636e\u5ba2\u6237\u7aef\u7684\u5386\u53f2\u68af\u5ea6\u8303\u6570\u5e8f\u5217\u9884\u6d4b\u4e0b\u4e00\u6b21\u66f4\u65b0\u7684\u91cd\u8981\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u53ea\u6709\u5f53\u9884\u6d4b\u503c\u8d85\u8fc7\u9884\u5b9a\u4e49\u9608\u503c\u65f6\uff0c\u624d\u4f1a\u8bf7\u6c42\u901a\u4fe1\uff1b\u5426\u5219\uff0c\u5ba2\u6237\u7aef\u5c06\u8df3\u8fc7\u672c\u8f6e\u6b21\uff0c\u4ece\u800c\u8282\u7701\u5e26\u5bbd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u6570\u636e\u6761\u4ef6\u4e0b\uff0cFedSkipTwin\u53ef\u4ee5\u51cf\u5c1112-15.5%\u7684\u603b\u901a\u4fe1\u91cf\uff0c\u5e76\u4e14\u6700\u7ec8\u6a21\u578b\u51c6\u786e\u7387\u6bd4\u6807\u51c6FedAvg\u7b97\u6cd5\u63d0\u9ad8\u4e860.5\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u57fa\u4e8e\u9884\u6d4b\u6307\u5bfc\u7684\u8df3\u8fc7\u7b56\u7565\u88ab\u8bc1\u660e\u662f\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u5b9e\u73b0\u8d44\u6e90\u611f\u77e5\u578b\u8054\u90a6\u5b66\u4e60\u7684\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.12898", "pdf": "https://arxiv.org/pdf/2507.12898", "abs": "https://arxiv.org/abs/2507.12898", "authors": ["Yao Feng", "Hengkai Tan", "Xinyi Mao", "Guodong Liu", "Shuhe Huang", "Chendong Xiang", "Hang Su", "Jun Zhu"], "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "Bimanual robotic manipulation, which involves the coordinated control of two\nrobotic arms, is foundational for solving challenging tasks. Despite recent\nprogress in general-purpose manipulation, data scarcity and embodiment\nheterogeneity remain serious obstacles to further scaling up in bimanual\nsettings. In this paper, we introduce VIdeo Diffusion for Action Reasoning\n(VIDAR), a two-stage framework that leverages large-scale, diffusion-based\nvideo pre-training and a novel masked inverse dynamics model for action\nprediction. We pre-train the video diffusion model on 750K multi-view videos\nfrom three real-world bimanual robot platforms, utilizing a unified observation\nspace that encodes robot, camera, task, and scene contexts. Our masked inverse\ndynamics model learns masks to extract action-relevant information from\ngenerated trajectories without requiring pixel-level labels, and the masks can\neffectively generalize to unseen backgrounds. Our experiments demonstrate that\nwith only 20 minutes of human demonstrations on an unseen robot platform (only\n1% of typical data requirements), VIDAR generalizes to unseen tasks and\nbackgrounds with strong semantic understanding, surpassing state-of-the-art\nmethods. Our findings highlight the potential of video foundation models,\ncoupled with masked action prediction, to enable scalable and generalizable\nrobotic manipulation in diverse real-world settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVIDAR\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u89c6\u9891\u9884\u8bad\u7ec3\u548c\u65b0\u7684\u9006\u52a8\u529b\u5b66\u6a21\u578b\u89e3\u51b3\u53cc\u81c2\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u5b9e\u4f53\u5f02\u6784\u6027\u95ee\u9898\u3002", "motivation": "\u53cc\u81c2\u673a\u5668\u4eba\u64cd\u4f5c\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u4e2d\u5177\u6709\u57fa\u7840\u6027\u4f5c\u7528\uff0c\u4f46\u6570\u636e\u7a00\u7f3a\u548c\u5b9e\u4f53\u5f02\u8d28\u6027\u9650\u5236\u4e86\u5176\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "VIDAR\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a\u5229\u752875\u4e07\u4e2a\u591a\u89c6\u56fe\u89c6\u9891\u8fdb\u884c\u5927\u89c4\u6a21\u6269\u6563\u6a21\u578b\u9884\u8bad\u7ec3\uff1b\u4f7f\u7528\u906e\u7f69\u9006\u52a8\u529b\u5b66\u6a21\u578b\u8fdb\u884c\u52a8\u4f5c\u9884\u6d4b\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u63d0\u53d6\u4e0e\u52a8\u4f5c\u76f8\u5173\u7684\u4fe1\u606f\u800c\u4e0d\u4f9d\u8d56\u50cf\u7d20\u7ea7\u6807\u7b7e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVIDAR\u4ec5\u970020\u5206\u949f\u7684\u4eba\u7c7b\u6f14\u793a\u5373\u53ef\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u673a\u5668\u4eba\u5e73\u53f0\u548c\u80cc\u666f\uff0c\u5e76\u4e14\u5728\u65b0\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u89c6\u9891\u57fa\u7840\u6a21\u578b\u4e0e\u906e\u7f69\u52a8\u4f5c\u9884\u6d4b\u76f8\u7ed3\u5408\uff0c\u5728\u591a\u79cd\u5b9e\u9645\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13646", "pdf": "https://arxiv.org/pdf/2507.13646", "abs": "https://arxiv.org/abs/2507.13646", "authors": ["Nimisha Ghosh", "Daniele Santoni", "Debaleena Nawn", "Eleonora Ottaviani", "Giovanni Felici"], "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The impact of Transformer-based language models has been unprecedented in\nNatural Language Processing (NLP). The success of such models has also led to\ntheir adoption in other fields including bioinformatics. Taking this into\naccount, this paper discusses recent advances in Transformer-based models for\nprotein sequence analysis and design. In this review, we have discussed and\nanalysed a significant number of works pertaining to such applications. These\napplications encompass gene ontology, functional and structural protein\nidentification, generation of de novo proteins and binding of proteins. We\nattempt to shed light on the strength and weaknesses of the discussed works to\nprovide a comprehensive insight to readers. Finally, we highlight shortcomings\nin existing research and explore potential avenues for future developments. We\nbelieve that this review will help researchers working in this field to have an\noverall idea of the state of the art in this field, and to orient their future\nstudies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u86cb\u767d\u8d28\u5e8f\u5217\u5206\u6790\u548c\u8bbe\u8ba1\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u8ba8\u8bba\u4e86\u5176\u4f18\u52bf\u548c\u52a3\u52bf\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9274\u4e8e\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u5de8\u5927\u6210\u529f\u53ca\u5176\u5728\u5176\u4ed6\u9886\u57df\uff08\u5982\u751f\u7269\u4fe1\u606f\u5b66\uff09\u7684\u5e94\u7528\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u8ba8\u8fd9\u4e9b\u6a21\u578b\u5728\u86cb\u767d\u8d28\u5e8f\u5217\u5206\u6790\u548c\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u60c5\u51b5\u3002", "method": "\u4f5c\u8005\u5bf9\u5927\u91cf\u5173\u4e8e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5e94\u7528\u4e8e\u86cb\u767d\u8d28\u5e8f\u5217\u5206\u6790\u548c\u8bbe\u8ba1\u7684\u6587\u732e\u8fdb\u884c\u4e86\u8ba8\u8bba\u548c\u5206\u6790\u3002", "result": "\u4f5c\u8005\u63d0\u4f9b\u4e86\u8fd9\u4e9b\u5e94\u7528\u7684\u5168\u9762\u89c1\u89e3\uff0c\u6db5\u76d6\u4e86\u57fa\u56e0\u672c\u4f53\u3001\u529f\u80fd\u548c\u7ed3\u6784\u86cb\u767d\u8d28\u8bc6\u522b\u3001\u4ece\u5934\u751f\u6210\u86cb\u767d\u8d28\u548c\u86cb\u767d\u8d28\u7ed3\u5408\u7b49\u65b9\u9762\u3002", "conclusion": "\u4f5c\u8005\u5f3a\u8c03\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u63a2\u7d22\u4e86\u672a\u6765\u53d1\u5c55\u7684\u6f5c\u5728\u9014\u5f84\uff0c\u8ba4\u4e3a\u8be5\u7efc\u8ff0\u5c06\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u4e86\u89e3\u8be5\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u6307\u5bfc\u4ed6\u4eec\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2507.13685", "pdf": "https://arxiv.org/pdf/2507.13685", "abs": "https://arxiv.org/abs/2507.13685", "authors": ["Yue Yang", "Zihan Su", "Ying Zhang", "Chang Chuan Goh", "Yuxiang Lin", "Anthony Graham Bellotti", "Boon Giin Lee"], "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction", "categories": ["cs.LG"], "comment": null, "summary": "This study addresses a critical challenge in time series anomaly detection:\nenhancing the predictive capability of loan default models more than three\nmonths in advance to enable early identification of default events, helping\nfinancial institutions implement preventive measures before risk events\nmaterialize. Existing methods have significant drawbacks, such as their lack of\naccuracy in early predictions and their dependence on training and testing\nwithin the same year and specific time frames. These issues limit their\npractical use, particularly with out-of-time data. To address these, the study\nintroduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge\nKolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long\nShort-Term Memory (LSTM) networks. The proposed models were evaluated against\nthe baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms\nof accuracy, precision, recall, F1 and AUC in different lengths of feature\nwindow, sample sizes, and early prediction intervals. The results demonstrate\nthat the proposed model achieves a prediction accuracy of over 92% three months\nin advance and over 88% eight months in advance, significantly outperforming\nexisting baselines.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165GRU-KAN\u548cLSTM-KAN\u4e24\u79cd\u521b\u65b0\u67b6\u6784\uff0c\u5c06Kolmogorov-Arnold Networks\u4e0eGRU\u548cLSTM\u7f51\u7edc\u76f8\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5373\u5728\u8d37\u6b3e\u8fdd\u7ea6\u4e8b\u4ef6\u53d1\u751f\u524d\u4e09\u4e2a\u6708\u4ee5\u4e0a\u589e\u5f3a\u9884\u6d4b\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u63d0\u524d3\u4e2a\u6708\u548c8\u4e2a\u6708\u7684\u9884\u6d4b\u51c6\u786e\u7387\u5206\u522b\u8d85\u8fc792%\u548c88%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u65e9\u671f\u9884\u6d4b\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u4f9d\u8d56\u4e8e\u7279\u5b9a\u5e74\u4efd\u548c\u65f6\u95f4\u6bb5\u5185\u7684\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5904\u7406\u8de8\u65f6\u95f4\u6570\u636e\u65f6\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u6a21\u578b\u67b6\u6784\uff0c\u5206\u522b\u662fGRU-KAN\u548cLSTM-KAN\uff0c\u8fd9\u4e24\u79cd\u67b6\u6784\u7ed3\u5408\u4e86Kolmogorov-Arnold Networks (KAN) \u548c\u4e24\u79cd\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08Gated Recurrent Units, GRU \u548c Long Short-Term Memory, LSTM\uff09\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u4e0d\u540c\u7684\u7279\u5f81\u7a97\u53e3\u957f\u5ea6\u3001\u6837\u672c\u91cf\u548c\u65e9\u671f\u9884\u6d4b\u95f4\u9694\u4e2d\uff0c\u90fd\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5728\u63d0\u524d3\u4e2a\u6708\u548c8\u4e2a\u6708\u7684\u9884\u6d4b\u51c6\u786e\u7387\u5206\u522b\u4e3a92%\u4ee5\u4e0a\u548c88%\u4ee5\u4e0a\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684GRU-KAN\u548cLSTM-KAN\u6a21\u578b\u63d0\u9ad8\u4e86\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u8f83\u957f\u65f6\u95f4\u7684\u65e9\u671f\u9884\u6d4b\u65b9\u9762\uff0c\u4e3a\u91d1\u878d\u673a\u6784\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u98ce\u9669\u9884\u8b66\u5de5\u5177\u3002"}}
{"id": "2507.13703", "pdf": "https://arxiv.org/pdf/2507.13703", "abs": "https://arxiv.org/abs/2507.13703", "authors": ["Martin Krutsk\u00fd", "Gustav \u0160\u00edr", "Vyacheslav Kungurtsev", "Georgios Korpas"], "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices", "summary": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.", "AI": {"tldr": "\u7269\u7406\u542f\u53d1\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08PI-GNNs\uff09\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u968f\u7740\u95ee\u9898\u56fe\u5bc6\u5ea6\u589e\u52a0\u800c\u4e0b\u964d\uff0c\u672c\u6587\u5206\u6790\u4e86\u5176\u539f\u56e0\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u65b0\u65b9\u6cd5\u5728\u9ad8\u5bc6\u5ea6\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u4e86PI-GNNs\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u6ce8\u610f\u5230\u7269\u7406\u542f\u53d1\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08PI-GNNs\uff09\u5728\u89e3\u51b3\u7531\u7279\u5b9a\u56fe\u7ed3\u6784\u548c\u635f\u5931\u7f16\u7801\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e0d\u6e05\u695a\u5176\u5728\u4e0d\u540c\u5bc6\u5ea6\u7684\u7ec4\u5408\u95ee\u9898\u56fe\u4e0a\u7684\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790PI-GNNs\u5728\u8bad\u7ec3\u52a8\u6001\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u5bc6\u96c6\u95ee\u9898\u5bfc\u81f4\u7684\u9000\u5316\u89e3\u662f\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\uff0c\u5e76\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u548c\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u89c1\u89e3\u63d0\u51fa\u4e86\u65b0\u7684\u7b56\u7565\u6765\u5f25\u8865\u6a21\u578b\u8f93\u51fa\u4e0e\u95ee\u9898\u89e3\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5904\u7406\u66f4\u5bc6\u96c6\u7684\u95ee\u9898\u56fe\u65f6\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584PI-GNNs\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u7269\u7406\u542f\u53d1\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4\uff0c\u5728\u9762\u5bf9\u66f4\u9ad8\u5bc6\u5ea6\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u65f6\uff0c\u91c7\u7528\u6539\u8fdb\u540e\u7684\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5176\u6027\u80fd\u3002"}}
{"id": "2507.13704", "pdf": "https://arxiv.org/pdf/2507.13704", "abs": "https://arxiv.org/abs/2507.13704", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "AI": {"tldr": "\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\uff08MOBO\uff09\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u4f18\u4e8e\u5355\u4e00\u76ee\u6807\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u6709\u9650\u548c\u6743\u8861\u590d\u6742\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\uff08MOBO\uff09\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u4e0e\u5355\u4e00\u76ee\u6807\u7684\u66ff\u4ee3\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4f7f\u7528Expected Hypervolume Improvement (EHVI)\u7684\u7b80\u5355Pareto-based MOBO\u7b56\u7565\u4e0e\u4f7f\u7528Expected Improvement (EI)\u7684\u56fa\u5b9a\u6743\u91cd\u5355\u4e00\u76ee\u6807\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u6240\u6709\u5b9e\u9a8c\u5747\u5728\u4e25\u683c\u63a7\u5236\u7684\u8bbe\u7f6e\u4e0b\u8fdb\u884c\uff0c\u5305\u62ec\u76f8\u540c\u7684\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u548c\u5206\u5b50\u8868\u793a\u3002", "result": "\u5728\u4e09\u4e2a\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\uff0cEHVI\u5728Pareto\u524d\u6cbf\u8986\u76d6\u3001\u6536\u655b\u901f\u5ea6\u548c\u5316\u5b66\u591a\u6837\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e00\u76ee\u6807EI\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5f3a\u786e\u5b9a\u6027\u5b9e\u4f8b\u4e2d\uff0c\u5355\u4e00\u76ee\u6807\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u4e5f\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5728\u4ece\u5934\u5206\u5b50\u4f18\u5316\u4e2d\uff0c\u7279\u522b\u662f\u5f53\u8bc4\u4f30\u9884\u7b97\u6709\u9650\u4e14\u6743\u8861\u975e\u5e73\u51e1\u65f6\uff0cPareto\u611f\u77e5\u83b7\u53d6\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2507.13707", "pdf": "https://arxiv.org/pdf/2507.13707", "abs": "https://arxiv.org/abs/2507.13707", "authors": ["Hao Wang", "Yu Liu", "Daniel Biggs", "Haoru Wang", "Jiandong Yu", "Ping Huang"], "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization", "categories": ["cs.LG"], "comment": "21 pages, 15 figures", "summary": "Simulating interactions between deformable bodies is vital in fields like\nmaterial science, mechanical design, and robotics. While learning-based methods\nwith Graph Neural Networks (GNNs) are effective at solving complex physical\nsystems, they encounter scalability issues when modeling deformable body\ninteractions. To model interactions between objects, pairwise global edges have\nto be created dynamically, which is computationally intensive and impractical\nfor large-scale meshes. To overcome these challenges, drawing on insights from\ngeometric representations, we propose an Adaptive Spatial Tokenization (AST)\nmethod for efficient representation of physical states. By dividing the\nsimulation space into a grid of cells and mapping unstructured meshes onto this\nstructured grid, our approach naturally groups adjacent mesh nodes. We then\napply a cross-attention module to map the sparse cells into a compact,\nfixed-length embedding, serving as tokens for the entire physical state.\nSelf-attention modules are employed to predict the next state over these tokens\nin latent space. This framework leverages the efficiency of tokenization and\nthe expressive power of attention mechanisms to achieve accurate and scalable\nsimulation results. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches in modeling deformable\nbody interactions. Notably, it remains effective on large-scale simulations\nwith meshes exceeding 100,000 nodes, where existing methods are hindered by\ncomputational limitations. Additionally, we contribute a novel large-scale\ndataset encompassing a wide range of deformable body interactions to support\nfuture research in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7a7a\u95f4\u6807\u8bb0\u5316\uff08AST\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u975e\u7ed3\u6784\u5316\u7f51\u683c\u6620\u5c04\u5230\u7ed3\u6784\u5316\u7f51\u683c\u5e76\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u3001\u51c6\u786e\u7684\u53d8\u5f62\u4f53\u4ea4\u4e92\u6a21\u62df\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u53d8\u5f62\u4f53\u4ea4\u4e92\u65f6\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u6269\u5c55\u3002", "method": "\u8be5\u65b9\u6cd5\u9996\u5148\u5c06\u4eff\u771f\u7a7a\u95f4\u5212\u5206\u4e3a\u5355\u5143\u683c\u7f51\u683c\uff0c\u5e76\u5c06\u975e\u7ed3\u6784\u5316\u7f51\u683c\u6620\u5c04\u5230\u6b64\u7ed3\u6784\u5316\u7f51\u683c\u4e0a\uff0c\u4ee5\u81ea\u7136\u5730\u5206\u7ec4\u76f8\u90bb\u7f51\u683c\u8282\u70b9\u3002\u7136\u540e\u5e94\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u5c06\u7a00\u758f\u5355\u5143\u683c\u6620\u5c04\u4e3a\u7d27\u51d1\u7684\u56fa\u5b9a\u957f\u5ea6\u5d4c\u5165\u3002\u518d\u5229\u7528\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u9884\u6d4b\u8fd9\u4e9b\u5d4c\u5165\u7684\u4e0b\u4e00\u4e2a\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5efa\u6a21\u53d8\u5f62\u4f53\u4ea4\u4e92\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u5305\u542b\u8d85\u8fc7100,000\u4e2a\u8282\u70b9\u7684\u5927\u89c4\u6a21\u7f51\u683c\u4e0a\u4f9d\u7136\u4fdd\u6301\u9ad8\u6548\u3002", "conclusion": "AST\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u53d8\u5f62\u4f53\u4ea4\u4e92\u6a21\u62df\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u4eff\u771f\u4e2d\u7684\u8ba1\u7b97\u9650\u5236\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2507.13716", "pdf": "https://arxiv.org/pdf/2507.13716", "abs": "https://arxiv.org/abs/2507.13716", "authors": ["Danilo Avola", "Andrea Bernardini", "Giancarlo Crocetti", "Andrea Ladogana", "Mario Lezoche", "Maurizio Mancini", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods", "categories": ["cs.LG"], "comment": null, "summary": "Parkinson's Disease PD is a progressive neurodegenerative disorder that\naffects motor and cognitive functions with early diagnosis being critical for\neffective clinical intervention Electroencephalography EEG offers a noninvasive\nand costeffective means of detecting PDrelated neural alterations yet the\ndevelopment of reliable automated diagnostic models remains a challenge In this\nstudy we conduct a systematic benchmark of traditional machine learning ML and\ndeep learning DL models for classifying PD using a publicly available oddball\ntask dataset Our aim is to lay the groundwork for developing an effective\nlearning system and to determine which approach produces the best results We\nimplement a unified sevenstep preprocessing pipeline and apply consistent\nsubjectwise crossvalidation and evaluation criteria to ensure comparability\nacross models Our results demonstrate that while baseline deep learning\narchitectures particularly CNNLSTM models achieve the best performance compared\nto other deep learning architectures underlining the importance of capturing\nlongrange temporal dependencies several traditional classifiers such as XGBoost\nalso offer strong predictive accuracy and calibrated decision boundaries By\nrigorously comparing these baselines our work provides a solid reference\nframework for future studies aiming to develop and evaluate more complex or\nspecialized architectures Establishing a reliable set of baseline results is\nessential to contextualize improvements introduced by novel methods ensuring\nscientific rigor and reproducibility in the evolving field of EEGbased\nneurodiagnostics", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5e15\u91d1\u68ee\u75c5\u5206\u7c7b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0CNN-LSTM\u6a21\u578b\u6548\u679c\u6700\u4f73\uff0c\u540c\u65f6\u4e5f\u80af\u5b9a\u4e86XGBoost\u7b49\u4f20\u7edf\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5e15\u91d1\u68ee\u75c5\uff08PD\uff09\u662f\u4e00\u79cd\u5f71\u54cd\u8fd0\u52a8\u548c\u8ba4\u77e5\u529f\u80fd\u7684\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\uff0c\u65e9\u671f\u8bca\u65ad\u5bf9\u4e8e\u6709\u6548\u7684\u4e34\u5e8a\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u4e3a\u4e86\u5bfb\u627e\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u548c\u6210\u672c\u6548\u76ca\u9ad8\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u516c\u5f00\u7684\u5947\u6570\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728PD\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u81f4\u7684\u4e03\u6b65\u9884\u5904\u7406\u7ba1\u9053\uff0c\u5e76\u5e94\u7528\u4e86\u4e3b\u9898\u5185\u4ea4\u53c9\u9a8c\u8bc1\u548c\u8bc4\u4ef7\u6807\u51c6\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u95f4\u7684\u53ef\u6bd4\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u7ebf\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7279\u522b\u662fCNN-LSTM\u6a21\u578b\uff0c\u76f8\u8f83\u4e8e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5b9e\u73b0\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u6355\u6349\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u7684\u91cd\u8981\u6027\uff1b\u800c\u4e00\u4e9b\u4f20\u7edf\u5206\u7c7b\u5668\u5982XGBoost\u4e5f\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6821\u51c6\u7684\u51b3\u7b56\u8fb9\u754c\u3002", "conclusion": "\u901a\u8fc7\u4e25\u683c\u6bd4\u8f83\u8fd9\u4e9b\u57fa\u51c6\uff0c\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u5f00\u53d1\u548c\u8bc4\u4f30\u66f4\u590d\u6742\u6216\u4e13\u4e1a\u5316\u7684\u67b6\u6784\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u6846\u67b6\u3002\u5efa\u7acb\u53ef\u9760\u7684\u57fa\u51c6\u7ed3\u679c\u96c6\u5bf9\u4e8e\u5c06\u65b0\u65b9\u6cd5\u5f15\u5165\u65f6\u7684\u60c5\u5883\u5316\u6539\u8fdb\u662f\u5fc5\u8981\u7684\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u57fa\u4e8eEEG\u7684\u795e\u7ecf\u8bca\u65ad\u9886\u57df\u4e2d\u7684\u79d1\u5b66\u4e25\u8c28\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.13718", "pdf": "https://arxiv.org/pdf/2507.13718", "abs": "https://arxiv.org/abs/2507.13718", "authors": ["Danilo Avola", "Muhammad Yasir Bilal", "Emad Emam", "Cristina Lakasz", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Bi-GRU Based Deception Detection using EEG Signals", "categories": ["cs.LG"], "comment": null, "summary": "Deception detection is a significant challenge in fields such as security,\npsychology, and forensics. This study presents a deep learning approach for\nclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)\nsignals from the Bag-of-Lies dataset, a multimodal corpus designed for\nnaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit\n(Bi-GRU) neural network was trained to perform binary classification of EEG\nsamples. The model achieved a test accuracy of 97\\%, along with high precision,\nrecall, and F1-scores across both classes. These results demonstrate the\neffectiveness of using bidirectional temporal modeling for EEG-based deception\ndetection and suggest potential for real-time applications and future\nexploration of advanced neural architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eEEG\u4fe1\u53f7\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u7c7b\u6b3a\u9a97\u6027\u548c\u771f\u5b9e\u6027\u884c\u4e3a\u3002\u4f7f\u7528\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\uff0c\u8fbe\u5230\u4e8697%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u65f6\u5e94\u7528\u548c\u672a\u6765\u63a2\u7d22\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u6b3a\u9a97\u68c0\u6d4b\u5728\u5b89\u5168\u3001\u5fc3\u7406\u5b66\u548c\u6cd5\u533b\u5b66\u7b49\u9886\u57df\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4f7f\u7528\u8111\u7535\u56fe\uff08EEG\uff09\u4fe1\u53f7\u6765\u533a\u5206\u6b3a\u9a97\u6027\u548c\u771f\u5b9e\u6027\u884c\u4e3a\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u6765\u81eaBag-of-Lies\u6570\u636e\u96c6\u7684EEG\u4fe1\u53f7\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e3a\u81ea\u7136\u3001\u968f\u610f\u7684\u6b3a\u9a97\u573a\u666f\u8bbe\u8ba1\u7684\u591a\u6a21\u6001\u8bed\u6599\u5e93\u3002\u91c7\u7528\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08Bi-GRU\uff09\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6a21\u578b\u4ee5\u6267\u884cEEG\u6837\u672c\u7684\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u8be5\u6a21\u578b\u5b9e\u73b0\u4e8697%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u5728\u4e24\u4e2a\u7c7b\u522b\u4e0a\u90fd\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u53cc\u5411\u65f6\u95f4\u5efa\u6a21\u5bf9\u4e8e\u57fa\u4e8eEEG\u7684\u6b3a\u9a97\u68c0\u6d4b\u662f\u6709\u6548\u7684\uff0c\u8fd9\u8868\u660e\u4e86\u5176\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u4ee5\u53ca\u5bf9\u672a\u6765\u9ad8\u7ea7\u795e\u7ecf\u67b6\u6784\u63a2\u7d22\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.13721", "pdf": "https://arxiv.org/pdf/2507.13721", "abs": "https://arxiv.org/abs/2507.13721", "authors": ["Zizhao Zhang", "Tianxiang Zhao", "Yu Sun", "Liping Sun", "Jichuan Kang"], "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "To address the challenges posed by cascading reactions caused by component\nfailures in autonomous cargo ships (ACS) and the uncertainties in emergency\ndecision-making, this paper proposes a novel hybrid feature fusion framework\nfor constructing a graph-structured dataset of failure modes. By employing an\nimproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency\nis significantly enhanced, achieving improvements of 7.1% and 3.4% compared to\nthe NSGA-II and CSA search algorithms, respectively. A hierarchical feature\nfusion framework is constructed, using Word2Vec encoding to encode\nsubsystem/component features, BERT-KPCA to process failure modes/reasons, and\nSentence-BERT to quantify the semantic association between failure impact and\nemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,\nand 6,150 propagation paths. Validation results show that the GATE-GNN model\nachieves a classification accuracy of 0.735, comparable to existing benchmarks.\nAdditionally, a silhouette coefficient of 0.641 indicates that the features are\nhighly distinguishable. In the label prediction results, the Shore-based\nMeteorological Service System achieved an F1 score of 0.93, demonstrating high\nprediction accuracy. This paper not only provides a solid foundation for\nfailure analysis in autonomous cargo ships but also offers reliable support for\nfault diagnosis, risk assessment, and intelligent decision-making systems. The\nlink to the dataset is\nhttps://github.com/wojiufukele/Graph-Structured-about-CSA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u4ee5\u6784\u5efa\u81ea\u4e3b\u8d27\u8239\u7684\u6545\u969c\u6a21\u5f0f\u56fe\u7ed3\u6784\u6570\u636e\u96c6\u3002\u4f7f\u7528\u6539\u8fdb\u7684\u5e03\u8c37\u9e1f\u641c\u7d22\u7b97\u6cd5\uff08HN-CSA\uff09\uff0c\u6587\u732e\u68c0\u7d22\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002\u901a\u8fc7\u591a\u79cd\u7f16\u7801\u65b9\u5f0f\u5904\u7406\u5b50\u7cfb\u7edf/\u7ec4\u4ef6\u7279\u5f81\u3001\u6545\u969c\u6a21\u5f0f/\u539f\u56e0\u548c\u8bed\u4e49\u5173\u8054\u3002\u9a8c\u8bc1\u7ed3\u679c\u663e\u793aGATE-GNN\u6a21\u578b\u5206\u7c7b\u51c6\u786e\u7387\u4e3a0.735\uff0cShore-based Meteorological Service System\u7684F1\u5206\u6570\u4e3a0.93\u3002", "motivation": "\u81ea\u4e3b\u8d27\u8239\uff08ACS\uff09\u4e2d\u7684\u7ec4\u4ef6\u6545\u969c\u4f1a\u5f15\u53d1\u7ea7\u8054\u53cd\u5e94\uff0c\u5e76\u4e14\u5728\u7d27\u6025\u51b3\u7b56\u4e2d\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5206\u6790\u6545\u969c\u6a21\u5f0f\u5e76\u652f\u6301\u667a\u80fd\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u5c42\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u91c7\u7528Word2Vec\u7f16\u7801\u5b50\u7cfb\u7edf/\u7ec4\u4ef6\u7279\u5f81\uff0cBERT-KPCA\u5904\u7406\u6545\u969c\u6a21\u5f0f/\u539f\u56e0\uff0cSentence-BERT\u91cf\u5316\u6545\u969c\u5f71\u54cd\u4e0e\u7d27\u6025\u51b3\u7b56\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u6539\u8fdb\u7684\u5e03\u8c37\u9e1f\u641c\u7d22\u7b97\u6cd5\uff08HN-CSA\uff09\u4ee5\u63d0\u9ad8\u6587\u732e\u68c0\u7d22\u6548\u7387\u3002", "result": "GATE-GNN\u6a21\u578b\u5b9e\u73b0\u4e860.735\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u7279\u5f81\u5177\u6709\u8f83\u9ad8\u7684\u533a\u5206\u5ea6\uff08\u8f6e\u5ed3\u7cfb\u6570\u4e3a0.641\uff09\u3002Shore-based Meteorological Service System\u7684F1\u5f97\u5206\u4e3a0.93\uff0c\u663e\u793a\u51fa\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u81ea\u4e3b\u8d27\u8239\u7684\u6545\u969c\u5206\u6790\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u8fd8\u4e3a\u6545\u969c\u8bca\u65ad\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u667a\u80fd\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u652f\u6301\u3002"}}
{"id": "2507.13727", "pdf": "https://arxiv.org/pdf/2507.13727", "abs": "https://arxiv.org/abs/2507.13727", "authors": ["Ren\u00e9 Heinrich", "Lukas Rauch", "Bernhard Sick", "Christoph Scholz"], "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics", "categories": ["cs.LG"], "comment": "Work in progress", "summary": "Adversarial training is a promising strategy for enhancing model robustness\nagainst adversarial attacks. However, its impact on generalization under\nsubstantial data distribution shifts in audio classification remains largely\nunexplored. To address this gap, this work investigates how different\nadversarial training strategies improve generalization performance and\nadversarial robustness in audio classification. The study focuses on two model\narchitectures: a conventional convolutional neural network (ConvNeXt) and an\ninherently interpretable prototype-based model (AudioProtoPNet). The approach\nis evaluated using a challenging bird sound classification benchmark. This\nbenchmark is characterized by pronounced distribution shifts between training\nand test data due to varying environmental conditions and recording methods, a\ncommon real-world challenge. The investigation explores two adversarial\ntraining strategies: one based on output-space attacks that maximize the\nclassification loss function, and another based on embedding-space attacks\ndesigned to maximize embedding dissimilarity. These attack types are also used\nfor robustness evaluation. Additionally, for AudioProtoPNet, the study assesses\nthe stability of its learned prototypes under targeted embedding-space attacks.\nResults show that adversarial training, particularly using output-space\nattacks, improves clean test data performance by an average of 10.5% relative\nand simultaneously strengthens the adversarial robustness of the models. These\nfindings, although derived from the bird sound domain, suggest that adversarial\ntraining holds potential to enhance robustness against both strong distribution\nshifts and adversarial attacks in challenging audio classification settings.", "AI": {"tldr": "\u5bf9\u6297\u8bad\u7ec3\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u8f93\u51fa\u7a7a\u95f4\u653b\u51fb\u7684\u8bad\u7ec3\uff0c\u80fd\u63d0\u5347\u97f3\u9891\u5206\u7c7b\u4e2d\u6a21\u578b\u5728\u5e72\u51c0\u6d4b\u8bd5\u6570\u636e\u4e0a\u7684\u6027\u80fd\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u7d22\u5bf9\u6297\u8bad\u7ec3\u5bf9\u97f3\u9891\u5206\u7c7b\u4e2d\u663e\u8457\u7684\u6570\u636e\u5206\u5e03\u53d8\u5316\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u6a21\u578b\u67b6\u6784\uff08ConvNeXt\u548cAudioProtoPNet\uff09\uff0c\u9488\u5bf9\u9e1f\u9e23\u5206\u7c7b\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e24\u79cd\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff1a\u8f93\u51fa\u7a7a\u95f4\u653b\u51fb\u548c\u5d4c\u5165\u7a7a\u95f4\u653b\u51fb\u3002", "result": "\u5bf9\u6297\u8bad\u7ec3\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u5e72\u51c0\u6d4b\u8bd5\u6570\u636e\u4e0a\u7684\u5e73\u5747\u6027\u80fd10.5%\uff0c\u5e76\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "\u5bf9\u6297\u8bad\u7ec3\u4e0d\u4ec5\u6709\u52a9\u4e8e\u63d0\u9ad8\u97f3\u9891\u5206\u7c7b\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u800c\u4e14\u53ef\u4ee5\u589e\u5f3a\u5176\u5bf9\u6297\u5f3a\u5206\u5e03\u53d8\u5316\u548c\u5bf9\u6297\u653b\u51fb\u7684\u80fd\u529b\u3002"}}
{"id": "2507.13736", "pdf": "https://arxiv.org/pdf/2507.13736", "abs": "https://arxiv.org/abs/2507.13736", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u591a\u5c42DNN\u8c03\u5ea6\u6846\u67b6\uff0c\u4f5c\u4e3aOctopuScheduler\u7684\u6269\u5c55\uff0c\u63d0\u4f9b\u4ecePyTorch\u6a21\u578b\u5230SpiNNaker2\u82af\u7247\u63a8\u7406\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u3002\u901a\u8fc7\u91cf\u5316\u548c\u964d\u4f4e\u6b65\u9aa4\u7ec4\u6210\u7684\u524d\u7aef\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5728\u795e\u7ecf\u5f62\u6001\u5e73\u53f0SpiNNaker2\u4e0a\u5b9e\u73b0\u57fa\u4e8e\u8fb9\u7f18\u7684\u5927\u89c4\u6a21\u548c\u590d\u6742DNN\uff08\u8fbe\u5230\u53d8\u538b\u5668\u89c4\u6a21\uff09\u7684\u6267\u884c\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc(DNN)\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u4e0d\u65ad\u589e\u5927\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u5e73\u53f0\u96be\u4ee5\u6ee1\u8db3\u5176\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5b9e\u65f6\u5904\u7406\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u81f4\u529b\u4e8e\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u548c\u6280\u672f\uff0c\u4f7fDNN\u80fd\u591f\u5728\u5982SpiNNaker2\u8fd9\u6837\u7684\u795e\u7ecf\u5f62\u6001\u5e73\u53f0\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u5c42DNN\u8c03\u5ea6\u6846\u67b6\uff0c\u4f5c\u4e3aOctopuScheduler\u7684\u6269\u5c55\u3002\u6b64\u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u7531\u91cf\u5316\u548c\u964d\u4f4e\u6b65\u9aa4\u7ec4\u6210\u7684\u524d\u7aef\uff0c\u5e76\u63d0\u4f9b\u4ecePyTorch\u6a21\u578b\u5230SpiNNaker2\u82af\u7247\u63a8\u7406\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5728 SpiNNaker2 \u795e\u7ecf\u5f62\u6001\u5e73\u53f0\u4e0a\u5b9e\u73b0\u5927\u89c4\u6a21\u548c\u590d\u6742 DNN \u7684\u8fb9\u7f18\u6267\u884c\uff0c\u6700\u9ad8\u53ef\u8fbe\u53d8\u538b\u5668\u89c4\u6a21\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728 SpiNNaker2 \u82af\u7247\u4e0a\u8fdb\u884c\u5927\u578b\u548c\u590d\u6742 DNN \u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u63a8\u8fdb\u4e86\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13741", "pdf": "https://arxiv.org/pdf/2507.13741", "abs": "https://arxiv.org/abs/2507.13741", "authors": ["Shangyou Wang", "Zezhong Ding", "Xike Xie"], "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.", "AI": {"tldr": "SamGoG\u662f\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u7c7b\u522b\u548c\u56fe\u5927\u5c0f\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002\u5b83\u901a\u8fc7\u6784\u5efa\u591a\u4e2a\u56fe\u7684\u56fe\u5e76\u987a\u5e8f\u8bad\u7ec3\u6765\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u56fe\u901a\u5e38\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u56fe\u5927\u5c0f\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u504f\u5dee\u548c\u6a21\u578b\u6027\u80fd\u7684\u4e0b\u964d\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u53ea\u89e3\u51b3\u4e00\u79cd\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "SamGoG\u91c7\u7528\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7684\u673a\u5236\u6765\u6784\u5efa\u591a\u4e2a\u56fe\u7684\u56fe\uff0c\u5e76\u987a\u5e8f\u5730\u5728\u8fd9\u4e9b\u56fe\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8fd9\u79cd\u91c7\u6837\u673a\u5236\u7ed3\u5408\u4e86\u53ef\u5b66\u4e60\u7684\u6210\u5bf9\u76f8\u4f3c\u6027\u548c\u81ea\u9002\u5e94\u7684\u8282\u70b9\u5ea6\u6765\u589e\u5f3a\u8fb9\u540c\u8d28\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSamGoG\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e8615.66%\uff0c\u8bad\u7ec3\u901f\u5ea6\u52a0\u5feb\u4e866.7\u500d\u3002", "conclusion": "SamGoG\u6709\u6548\u5730\u7f13\u89e3\u4e86\u7c7b\u522b\u548c\u56fe\u5927\u5c0f\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u4e0e\u5404\u79cd\u4e0b\u6e38GNN\u65e0\u7f1d\u96c6\u6210\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u9002\u5e94\u56fe\u5206\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2507.13742", "pdf": "https://arxiv.org/pdf/2507.13742", "abs": "https://arxiv.org/abs/2507.13742", "authors": ["Oussama Bouaggad", "Natalia Grabar"], "title": "Search-Optimized Quantization in Biomedical Ontology Alignment", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u4f18\u5316\u6280\u672f\uff08\u5982\u52a8\u6001\u91cf\u5316\u3001\u4f7f\u7528\u4e0d\u540c\u6267\u884c\u63d0\u4f9b\u8005\u7684\u641c\u7d22\uff09\u5b9e\u73b0\u751f\u7269\u533b\u5b66\u672c\u4f53\u5bf9\u9f50\u4efb\u52a1\u7684\u52a0\u901f\u548c\u8d44\u6e90\u6d88\u8017\u51cf\u5c11\u3002\u5728\u4e0d\u635f\u5931\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e8620\u500d\u7684\u63a8\u7406\u52a0\u901f\u548c70%\u7684\u5185\u5b58\u8282\u7701\u3002", "motivation": "\u5f00\u53d1\u66f4\u9ad8\u6548\u7684AI\u6a21\u578b\u90e8\u7f72\u65b9\u6cd5\u4ee5\u5e94\u5bf9\u5927\u578b\u6a21\u578b\u5e26\u6765\u7684\u8ba1\u7b97\u9700\u6c42\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u8bbe\u5907\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9762\u4e34\u7684\u80fd\u6e90\u6d88\u8017\u3001\u5185\u5b58\u4f7f\u7528\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u91c7\u7528\u76d1\u7763\u7684\u6700\u5148\u8fdb\u53d8\u6362\u5668\u6a21\u578b\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8fdb\u884c\u8bed\u4e49\u76f8\u4f3c\u6027\u5206\u6790\uff0c\u7ed3\u5408\u5fae\u8f6fOlive\u3001ONNX Runtime\u540e\u7aef\u3001Intel Neural Compressor\u548cIPEX\u7b49\u5de5\u5177\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002", "result": "\u5728DEFT 2020\u8bc4\u4f30\u6d3b\u52a8\u4e2d\u4e24\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u6307\u6807\u4e0d\u53d8\uff0c\u5b9e\u73b0\u4e86\u5e73\u574720\u500d\u7684\u63a8\u7406\u52a0\u901f\u548c\u5927\u7ea670%\u7684\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6548\u7387\uff0c\u8fd8\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7ef4\u6301\u4e86\u9ad8\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u6a21\u578b\u4f18\u5316\u6280\u672f\u7684\u53d1\u5c55\u8d8b\u52bf\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2507.13762", "pdf": "https://arxiv.org/pdf/2507.13762", "abs": "https://arxiv.org/abs/2507.13762", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Mingyue Zheng", "Qian Shi"], "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u53c2\u6570\u63d2\u503c\u6d41\u7684\u6a21\u578b\uff08PIF\uff09\u5e76\u5e94\u7528\u4e8e\u5206\u5b50\u751f\u6210\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u3002\u5b83\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u53c2\u6570\u7a7a\u95f4\u751f\u6210\u5efa\u6a21\u8303\u5f0f\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u5c3d\u7ba1\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\uff08BFNs\uff09\u5728\u5316\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u7b56\u7565\u9650\u5236\u4e86\u66f4\u7075\u6d3b\u7684\u5206\u5e03\u8f6c\u6362\u8def\u5f84\u7684\u8bbe\u8ba1\uff0c\u5e76\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03\u548c\u4efb\u52a1\u9700\u6c42\u3002\u6b64\u5916\uff0c\u5c1a\u672a\u63a2\u7d22\u66f4\u7b80\u5355\u3001\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u7684\u6f5c\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e26\u6709\u8be6\u7ec6\u7406\u8bba\u57fa\u7840\u3001\u8bad\u7ec3\u548c\u63a8\u7406\u7a0b\u5e8f\u7684\u65b0\u578bParameter Interpolation Flow\u6a21\u578b\uff08PIF\uff09\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u5f00\u53d1\u4e86MolPIF\u7528\u4e8e\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u3002", "result": "MolPIF\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9a8c\u8bc1\u4e86\u5206\u5b50\u53c2\u6570\u7a7a\u95f4\u751f\u6210\u5efa\u6a21\u8303\u5f0f\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.13765", "pdf": "https://arxiv.org/pdf/2507.13765", "abs": "https://arxiv.org/abs/2507.13765", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Li Jin", "Liqiang Nie"], "title": "Dual-Center Graph Clustering with Neighbor Distribution", "categories": ["cs.LG"], "comment": "ECAI-2025", "summary": "Graph clustering is crucial for unraveling intricate data structures, yet it\npresents significant challenges due to its unsupervised nature. Recently,\ngoal-directed clustering techniques have yielded impressive results, with\ncontrastive learning methods leveraging pseudo-label garnering considerable\nattention. Nonetheless, pseudo-label as a supervision signal is unreliable and\nexisting goal-directed approaches utilize only features to construct a\nsingle-target distribution for single-center optimization, which lead to\nincomplete and less dependable guidance. In our work, we propose a novel\nDual-Center Graph Clustering (DCGC) approach based on neighbor distribution\nproperties, which includes representation learning with neighbor distribution\nand dual-center optimization. Specifically, we utilize neighbor distribution as\na supervision signal to mine hard negative samples in contrastive learning,\nwhich is reliable and enhances the effectiveness of representation learning.\nFurthermore, neighbor distribution center is introduced alongside feature\ncenter to jointly construct a dual-target distribution for dual-center\noptimization. Extensive experiments and analysis demonstrate superior\nperformance and effectiveness of our proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u90bb\u57df\u5206\u5e03\u7279\u6027\u7684\u53cc\u4e2d\u5fc3\u56fe\u805a\u7c7b\u65b9\u6cd5\uff0c\u5229\u7528\u90bb\u57df\u5206\u5e03\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u589e\u5f3a\u4e86\u8868\u793a\u5b66\u4e60\u7684\u6548\u679c\uff0c\u5e76\u5f15\u5165\u4e86\u90bb\u57df\u5206\u5e03\u4e2d\u5fc3\u548c\u7279\u5f81\u4e2d\u5fc3\u5171\u540c\u6784\u5efa\u53cc\u76ee\u6807\u5206\u5e03\uff0c\u4ee5\u8fdb\u884c\u53cc\u4e2d\u5fc3\u4f18\u5316\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u7531\u4e8e\u56fe\u805a\u7c7b\u7684\u65e0\u76d1\u7763\u7279\u6027\uff0c\u5b83\u5728\u63ed\u793a\u590d\u6742\u6570\u636e\u7ed3\u6784\u65b9\u9762\u5b58\u5728\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u76ee\u6807\u5bfc\u5411\u805a\u7c7b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4f2a\u6807\u7b7e\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u8fd9\u662f\u4e0d\u53ef\u9760\u7684\uff0c\u5e76\u4e14\u53ea\u4f7f\u7528\u7279\u5f81\u6765\u6784\u9020\u5355\u76ee\u6807\u5206\u5e03\uff0c\u8fd9\u5bfc\u81f4\u6307\u5bfc\u4e0d\u5b8c\u6574\u548c\u4e0d\u592a\u53ef\u9760\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u90bb\u57df\u5206\u5e03\u7279\u6027\u7684\u53cc\u4e2d\u5fc3\u56fe\u805a\u7c7b\uff08DCGC\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u5e26\u6709\u90bb\u57df\u5206\u5e03\u7684\u8868\u793a\u5b66\u4e60\u548c\u53cc\u4e2d\u5fc3\u4f18\u5316\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5229\u7528\u90bb\u57df\u5206\u5e03\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u5728\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u6316\u6398\u96be\u8d1f\u6837\u672c\uff0c\u540c\u65f6\u5f15\u5165\u90bb\u57df\u5206\u5e03\u4e2d\u5fc3\u4e0e\u7279\u5f81\u4e2d\u5fc3\u4e00\u8d77\u6784\u5efa\u53cc\u76ee\u6807\u5206\u5e03\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u548c\u5206\u6790\u8bc1\u660e\u4e86\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u4e2d\u5fc3\u56fe\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u90bb\u57df\u5206\u5e03\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u63d0\u9ad8\u4e86\u8868\u793a\u5b66\u4e60\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u53cc\u4e2d\u5fc3\u4f18\u5316\u63d0\u9ad8\u4e86\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2507.13805", "pdf": "https://arxiv.org/pdf/2507.13805", "abs": "https://arxiv.org/abs/2507.13805", "authors": ["Tim Rensmeyer", "Denis Kramer", "Oliver Niggemann"], "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Due to the computational complexity of evaluating interatomic forces from\nfirst principles, the creation of interatomic machine learning force fields has\nbecome a highly active field of research. However, the generation of training\ndatasets of sufficient size and sample diversity itself comes with a\ncomputational burden that can make this approach impractical for modeling rare\nevents or systems with a large configuration space. Fine-tuning foundation\nmodels that have been pre-trained on large-scale material or molecular\ndatabases offers a promising opportunity to reduce the amount of training data\nnecessary to reach a desired level of accuracy. However, even if this approach\nrequires less training data overall, creating a suitable training dataset can\nstill be a very challenging problem, especially for systems with rare events\nand for end-users who don't have an extensive background in machine learning.\nIn on-the-fly learning, the creation of a training dataset can be largely\nautomated by using model uncertainty during the simulation to decide if the\nmodel is accurate enough or if a structure should be recalculated with\nclassical methods and used to update the model. A key challenge for applying\nthis form of active learning to the fine-tuning of foundation models is how to\nassess the uncertainty of those models during the fine-tuning process, even\nthough most foundation models lack any form of uncertainty quantification. In\nthis paper, we overcome this challenge by introducing a fine-tuning approach\nbased on Bayesian neural network methods and a subsequent on-the-fly workflow\nthat automatically fine-tunes the model while maintaining a pre-specified\naccuracy and can detect rare events such as transition states and sample them\nat an increased rate relative to their occurrence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u9884\u8bbe\u7cbe\u5ea6\u7684\u540c\u65f6\u81ea\u52a8\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u80fd\u68c0\u6d4b\u5230\u8bf8\u5982\u8fc7\u6e21\u6001\u7b49\u7a00\u6709\u4e8b\u4ef6\u5e76\u4ee5\u66f4\u9ad8\u7684\u9891\u7387\u91c7\u6837\u3002", "motivation": "\u7531\u4e8e\u4ece\u5934\u8ba1\u7b97\u539f\u5b50\u95f4\u529b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u521b\u5efa\u539f\u5b50\u95f4\u673a\u5668\u5b66\u4e60\u529b\u573a\u53d8\u5f97\u975e\u5e38\u6d3b\u8dc3\u3002\u7136\u800c\uff0c\u751f\u6210\u8db3\u591f\u89c4\u6a21\u548c\u6837\u672c\u591a\u6837\u6027\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u672c\u8eab\u5e26\u6709\u8ba1\u7b97\u8d1f\u62c5\uff0c\u8fd9\u4f7f\u5f97\u8be5\u65b9\u6cd5\u5728\u5efa\u6a21\u7a00\u6709\u4e8b\u4ef6\u6216\u5177\u6709\u5927\u914d\u7f6e\u7a7a\u95f4\u7684\u7cfb\u7edf\u65f6\u53ef\u80fd\u4e0d\u5b9e\u7528\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e00\u4e2a\u540e\u7eed\u7684\u5373\u65f6\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8be5\u5de5\u4f5c\u6d41\u7a0b\u53ef\u4ee5\u81ea\u52a8\u5fae\u8c03\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u8bbe\u7684\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u591f\u68c0\u6d4b\u5230\u8bf8\u5982\u8fc7\u6e21\u6001\u7b49\u7a00\u6709\u4e8b\u4ef6\u5e76\u4ee5\u66f4\u9ad8\u7684\u9891\u7387\u8fdb\u884c\u91c7\u6837\u3002", "result": "\u8fd9\u79cd\u65b0\u7684\u5fae\u8c03\u65b9\u6cd5\u514b\u670d\u4e86\u57fa\u7840\u6a21\u578b\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7684\u6a21\u578b\u5fae\u8c03\uff0c\u63d0\u9ad8\u4e86\u5bf9\u7a00\u6709\u4e8b\u4ef6\u7684\u68c0\u6d4b\u548c\u91c7\u6837\u7387\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u68c0\u6d4b\u548c\u91c7\u6837\u7a00\u6709\u4e8b\u4ef6\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.13834", "pdf": "https://arxiv.org/pdf/2507.13834", "abs": "https://arxiv.org/abs/2507.13834", "authors": ["Aditi Anand", "Suman Banerjee", "Dildar Ali"], "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "16 Pages", "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5956\u52b1\u51fd\u6570\u4e3a\u6b21\u6a21\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u526a\u679d\u6b21\u6a21\u56fe\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u5728\u53ef\u884c\u7684\u8ba1\u7b97\u65f6\u95f4\u5185\u80fd\u63d0\u4f9b\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u591a\u7684\u5956\u52b1\u3002", "motivation": "\u4f20\u7edf\u7684RL\u8bbe\u5b9a\u4e2d\uff0c\u5956\u52b1\u51fd\u6570\u88ab\u8ba4\u4e3a\u662f\u53ef\u52a0\u7684\u3002\u7136\u800c\uff0c\u5728\u8bb8\u591a\u5b9e\u9645\u95ee\u9898\u4e2d\uff0c\u5956\u52b1\u51fd\u6570\u9075\u5faa\u8fb9\u9645\u6548\u76ca\u9012\u51cf\u89c4\u5f8b\uff0c\u5373\u6b21\u6a21\u51fd\u6570\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u5956\u52b1\u51fd\u6570\u4e3a\u6b21\u6a21\u7684RL\u95ee\u9898\uff0c\u4ee5\u627e\u5230\u4f7f\u8fd9\u79cd\u5956\u52b1\u51fd\u6570\u6700\u5927\u5316\u7684\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u526a\u679d\u6b21\u6a21\u56fe\u7684\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u5728\u53ef\u884c\u7684\u8ba1\u7b97\u65f6\u95f4\u5185\u63d0\u4f9b\u4e00\u4e2a\u53ef\u4ee5\u88ab\u8bc1\u660e\u7684\u8fd1\u4f3c\u89e3\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u57fa\u51c6\u667a\u80fd\u4f53-\u73af\u5883\u8bbe\u7f6e\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u83b7\u5f97\u66f4\u591a\u7684\u5956\u52b1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u5177\u6709\u6b21\u6a21\u5956\u52b1\u51fd\u6570\u7684RL\u95ee\u9898\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u5408\u7406\u7684\u65f6\u95f4\u5185\u63d0\u4f9b\u6027\u80fd\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13912", "pdf": "https://arxiv.org/pdf/2507.13912", "abs": "https://arxiv.org/abs/2507.13912", "authors": ["Kevin Dradjat", "Massinissa Hamidi", "Pierre Bartet", "Blaise Hanczar"], "title": "Self-supervised learning on gene expression data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u8868\u578b\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u80fd\u6709\u6548\u6355\u6349\u590d\u6742\u4fe1\u606f\u5e76\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u5206\u6790\u4e2d\u9700\u8981\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\uff0c\u8fd9\u65e2\u6602\u8d35\u53c8\u8017\u65f6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u7684\u5e94\u7528\uff0c\u4ee5\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u4e2d\u76f4\u63a5\u63d0\u53d6\u4fe1\u606f\u3002", "method": "\u9009\u62e9\u4e86\u4e09\u79cd\u57fa\u4e8e\u4e0d\u540c\u539f\u7406\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u591a\u4e2a\u516c\u5f00\u7684\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002\u8fd9\u4e9b\u65b9\u6cd5\u65e8\u5728\u5229\u7528\u6570\u636e\u7684\u5185\u5728\u7ed3\u6784\u751f\u6210\u5b9a\u6027\u8868\u793a\uff0c\u7528\u4e8e\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6240\u9009\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6355\u6349\u590d\u6742\u4fe1\u606f\uff0c\u6539\u5584\u8868\u578b\u9884\u6d4b\u51c6\u786e\u5ea6\uff0c\u5e76\u4e14\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5c06\u81ea\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u4e8e\u6279\u91cfRNA-Seq\u6570\u636e\uff0c\u5c55\u793a\u4e86\u5176\u51cf\u5c11\u5bf9\u6ce8\u91ca\u6570\u636e\u4f9d\u8d56\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u5efa\u8bae\u3002"}}
{"id": "2507.13920", "pdf": "https://arxiv.org/pdf/2507.13920", "abs": "https://arxiv.org/abs/2507.13920", "authors": ["Turan Orujlu", "Christian Gumbsch", "Martin V. Butz", "Charley M Wu"], "title": "Reframing attention as a reinforcement learning problem for causal discovery", "categories": ["cs.LG"], "comment": null, "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u8fc7\u7a0b\u6846\u67b6\u53ca\u5176\u5b9e\u73b0\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u4ee5\u4ece\u89c6\u89c9\u89c2\u5bdf\u4e2d\u63a8\u65ad\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u8fc7\u7a0b\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u56e0\u679c\u8868\u793a\u5b66\u4e60\u548c\u4ee3\u7406\u6027\u80fd\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u6a21\u578b\u5728\u5904\u7406\u56e0\u679c\u5173\u7cfb\u65f6\u5927\u591a\u5047\u8bbe\u9759\u6001\u56e0\u679c\u56fe\uff0c\u5ffd\u7565\u4e86\u56e0\u679c\u4ea4\u4e92\u7684\u52a8\u6001\u6027\u8d28\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u70b9\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ee3\u8868\u52a8\u6001\u56e0\u679c\u7ed3\u6784\u5047\u8bbe\u7684\u65b0\u7406\u8bba\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u56e0\u679c\u8fc7\u7a0b\u6846\u67b6\u4f5c\u4e3a\u65b0\u7406\u8bba\uff0c\u5e76\u63d0\u51fa\u4e86\u56e0\u679c\u8fc7\u7a0b\u6a21\u578b\u4f5c\u4e3a\u8be5\u6846\u67b6\u7684\u5b9e\u73b0\u3002\u6b64\u65b9\u6cd5\u91cd\u65b0\u5b9a\u4e49\u4e86Transformer\u7f51\u7edc\u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728RL\u73af\u5883\u4e2d\u901a\u8fc7\u5efa\u7acb\u56e0\u679c\u56fe\u5047\u8bbe\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e00\u4e2aRL\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e0d\u4ec5\u5728\u56e0\u679c\u8868\u793a\u5b66\u4e60\u548c\u4ee3\u7406\u6027\u80fd\u4e0a\u8d85\u8fc7\u4e86\u5f53\u524d\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u4e14\u552f\u4e00\u5730\u6062\u590d\u4e86\u52a8\u6001\u56e0\u679c\u8fc7\u7a0b\u7684\u56fe\u5f62\u3002", "conclusion": "\u56e0\u679c\u8fc7\u7a0b\u6846\u67b6\u53ca\u5176\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u52a8\u6001\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u4e86\u5f3a\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13950", "pdf": "https://arxiv.org/pdf/2507.13950", "abs": "https://arxiv.org/abs/2507.13950", "authors": ["Jingbo Liang", "Bruna Jacobson"], "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space", "categories": ["cs.LG", "physics.bio-ph", "q-bio.BM"], "comment": null, "summary": "Extensively exploring protein conformational landscapes remains a major\nchallenge in computational biology due to the high computational cost involved\nin dynamic physics-based simulations. In this work, we propose a novel\npipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and\ngenerative adversarial networks (GANs) to explore protein conformational\nspaces. MoDyGAN contains a generator that maps Gaussian distributions into\nMD-derived protein trajectories, and a refinement module that combines ensemble\nlearning with a dual-discriminator to further improve the plausibility of\ngenerated conformations. Central to our approach is an innovative\nrepresentation technique that reversibly transforms 3D protein structures into\n2D matrices, enabling the use of advanced image-based GAN architectures. We use\nthree rigid proteins to demonstrate that MoDyGAN can generate plausible new\nconformations. We also use deca-alanine as a case study to show that\ninterpolations within the latent space closely align with trajectories obtained\nfrom steered molecular dynamics (SMD) simulations. Our results suggest that\nrepresenting proteins as image-like data unlocks new possibilities for applying\nadvanced deep learning techniques to biomolecular simulation, leading to an\nefficient sampling of conformational states. Additionally, the proposed\nframework holds strong potential for extension to other complex 3D structures.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoDyGAN\u7684\u65b0\u9896\u7ba1\u9053\uff0c\u7ed3\u5408\u4e86\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u6765\u63a2\u7d22\u86cb\u767d\u8d28\u7684\u6784\u8c61\u7a7a\u95f4\u3002\u901a\u8fc7\u5c063D\u86cb\u767d\u8d28\u7ed3\u6784\u8f6c\u6362\u4e3a2D\u77e9\u9635\uff0c\u4f7f\u5f97\u53ef\u4ee5\u4f7f\u7528\u5148\u8fdb\u7684\u57fa\u4e8e\u56fe\u50cf\u7684GAN\u67b6\u6784\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMoDyGAN\u53ef\u4ee5\u751f\u6210\u53ef\u4fe1\u7684\u65b0\u6784\u8c61\uff0c\u5e76\u4e14\u5728\u6f5c\u5728\u7a7a\u95f4\u5185\u7684\u63d2\u503c\u4e0e\u53d7\u63a7\u5206\u5b50\u52a8\u529b\u5b66\uff08SMD\uff09\u6a21\u62df\u83b7\u5f97\u7684\u8f68\u8ff9\u9ad8\u5ea6\u4e00\u81f4\u3002", "motivation": "\u5e7f\u6cdb\u63a2\u7d22\u86cb\u767d\u8d28\u7684\u6784\u8c61\u666f\u89c2\u662f\u8ba1\u7b97\u751f\u7269\u5b66\u4e2d\u7684\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u56e0\u4e3a\u52a8\u6001\u7269\u7406\u57fa\u7840\u6a21\u62df\u6d89\u53ca\u6781\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u96be\u9898\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\u6765\u63a2\u7d22\u86cb\u767d\u8d28\u7684\u6784\u8c61\u7a7a\u95f4\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u5b83\u5c06\u9ad8\u65af\u5206\u5e03\u6620\u5c04\u5230\u7531\u5206\u5b50\u52a8\u529b\u5b66\uff08MD\uff09\u884d\u751f\u7684\u86cb\u767d\u8d28\u8f68\u8ff9\u4e2d\uff1b\u4e00\u4e2a\u6539\u8fdb\u6a21\u5757\uff0c\u5b83\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u548c\u53cc\u91cd\u5224\u522b\u5668\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u751f\u6210\u6784\u8c61\u7684\u5408\u7406\u6027\uff1b\u4ee5\u53ca\u4e00\u79cd\u521b\u65b0\u7684\u8868\u793a\u6280\u672f\uff0c\u53ef\u9006\u5730\u5c063D\u86cb\u767d\u8d28\u7ed3\u6784\u8f6c\u53d8\u4e3a2D\u77e9\u9635\u3002", "result": "\u901a\u8fc7\u5bf9\u4e09\u79cd\u521a\u6027\u86cb\u767d\u8d28\u7684\u7814\u7a76\uff0c\u8bc1\u660e\u4e86MoDyGAN\u53ef\u4ee5\u751f\u6210\u53ef\u4fe1\u7684\u65b0\u6784\u8c61\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u5341\u80bd\u4e19\u6c28\u9178\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u663e\u793a\u5728\u6f5c\u5728\u7a7a\u95f4\u5185\u7684\u63d2\u503c\u4e0e\u53d7\u63a7\u5206\u5b50\u52a8\u529b\u5b66\uff08SMD\uff09\u6a21\u62df\u83b7\u5f97\u7684\u8f68\u8ff9\u7d27\u5bc6\u5bf9\u9f50\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5c06\u86cb\u767d\u8d28\u8868\u793a\u4e3a\u7c7b\u4f3c\u56fe\u50cf\u7684\u6570\u636e\u4e3a\u5e94\u7528\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u4e8e\u751f\u7269\u5206\u5b50\u6a21\u62df\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4ece\u800c\u6709\u6548\u5730\u91c7\u6837\u6784\u8c61\u72b6\u6001\u3002\u6b64\u5916\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5177\u6709\u6269\u5c55\u5230\u5176\u4ed6\u590d\u67423D\u7ed3\u6784\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.13954", "pdf": "https://arxiv.org/pdf/2507.13954", "abs": "https://arxiv.org/abs/2507.13954", "authors": ["Yifan Wei", "Anwar Said", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability", "categories": ["cs.LG"], "comment": "conference paper published in IEEE CAI 2025", "summary": "Anomaly detection in complex domains poses significant challenges due to the\nneed for extensive labeled data and the inherently imbalanced nature of\nanomalous versus benign samples. Graph-based machine learning models have\nemerged as a promising solution that combines attribute and relational data to\nuncover intricate patterns. However, the scarcity of anomalous data exacerbates\nthe challenge, which requires innovative strategies to enhance model learning\nwith limited information. In this paper, we hypothesize that the incorporation\nof the influence of the nodes, quantified through average controllability, can\nsignificantly improve the performance of anomaly detection. We propose two\nnovel approaches to integrate average controllability into graph-based\nframeworks: (1) using average controllability as an edge weight and (2)\nencoding it as a one-hot edge attribute vector. Through rigorous evaluation on\nreal-world and synthetic networks with six state-of-the-art baselines, our\nproposed methods demonstrate improved performance in identifying anomalies,\nhighlighting the critical role of controllability measures in enhancing the\nperformance of graph machine learning models. This work underscores the\npotential of integrating average controllability as additional metrics to\naddress the challenges of anomaly detection in sparse and imbalanced datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5c06\u5e73\u5747\u53ef\u63a7\u6027\u6574\u5408\u5230\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u57fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u53ef\u4ee5\u7ed3\u5408\u5c5e\u6027\u548c\u5173\u7cfb\u6570\u636e\u6765\u63ed\u793a\u590d\u6742\u6a21\u5f0f\uff0c\u4f46\u5f02\u5e38\u6570\u636e\u7684\u7a00\u7f3a\u6027\u4f7f\u5f97\u6a21\u578b\u5b66\u4e60\u9762\u4e34\u6311\u6218\u3002\u4e3a\u4e86\u7528\u6709\u9650\u7684\u4fe1\u606f\u63d0\u9ad8\u6a21\u578b\u7684\u5b66\u4e60\u6548\u679c\uff0c\u672c\u6587\u5047\u8bbe\u8282\u70b9\u7684\u5f71\u54cd\u529b\uff08\u901a\u8fc7\u5e73\u5747\u53ef\u63a7\u6027\u91cf\u5316\uff09\u80fd\u591f\u663e\u8457\u6539\u5584\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5305\u62ec\uff1a1) \u4f7f\u7528\u5e73\u5747\u53ef\u63a7\u6027\u4f5c\u4e3a\u8fb9\u6743\u91cd\uff1b2) \u5c06\u5176\u7f16\u7801\u4e3aone-hot\u8fb9\u5c5e\u6027\u5411\u91cf\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u7f51\u7edc\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u516d\u4e2a\u6700\u5148\u8fdb\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8bc6\u522b\u5f02\u5e38\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5728\u5904\u7406\u7a00\u758f\u548c\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u7684\u5f02\u5e38\u68c0\u6d4b\u65f6\uff0c\u6574\u5408\u5e73\u5747\u53ef\u63a7\u6027\u4f5c\u4e3a\u989d\u5916\u5ea6\u91cf\u6307\u6807\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13959", "pdf": "https://arxiv.org/pdf/2507.13959", "abs": "https://arxiv.org/abs/2507.13959", "authors": ["Eli Verwimp", "Gustav Ryberg Smidt", "Hendrik Hameeuw", "Katrien De Graef"], "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs", "categories": ["cs.LG"], "comment": "Paper under review at JOCCH", "summary": "The work in this paper describes the training and evaluation of machine\nlearning (ML) techniques for the classification of cuneiform signs. There is a\nlot of variability in cuneiform signs, depending on where they come from, for\nwhat and by whom they were written, but also how they were digitized. This\nvariability makes it unlikely that an ML model trained on one dataset will\nperform successfully on another dataset. This contribution studies how such\ndifferences impact that performance. Based on our results and insights, we aim\nto influence future data acquisition standards and provide a solid foundation\nfor future cuneiform sign classification tasks. The ML model has been trained\nand tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary\ntexts inscribed on clay tablets originating from three Mesopotamian cities\n(Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is\nResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for\nsigns with at least 20 instances. As these automatic classification results are\nthe first on Old Babylonian texts, there are currently no comparable results.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u6954\u5f62\u6587\u5b57\u5206\u7c7b\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "motivation": "\u6954\u5f62\u6587\u5b57\u5b58\u5728\u5927\u91cf\u53d8\u5f02\u6027\uff0c\u8fd9\u4f7f\u5f97\u5728\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0d\u592a\u53ef\u80fd\u5728\u53e6\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u6210\u529f\u8fd0\u884c\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7814\u7a76\u8fd9\u4e9b\u5dee\u5f02\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u6765\u5f71\u54cd\u672a\u6765\u7684\u6570\u636e\u83b7\u53d6\u6807\u51c6\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u6954\u5f62\u6587\u5b57\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u575a\u5b9e\u7684\u57fa\u7840\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u4e86ResNet50\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5df2\u5728\u6765\u81ea\u4e09\u4e2a\u7f8e\u7d22\u4e0d\u8fbe\u7c73\u4e9a\u57ce\u5e02\u7684\u7c98\u571f\u677f\u4e0a\u7684\u624b\u5199\u53e4\u5df4\u6bd4\u4f26\uff08\u7ea6\u516c\u5143\u524d2000-1600\u5e74\uff09\u6587\u732e\u6587\u672c\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u5bf9\u4e8e\u81f3\u5c11\u670920\u4e2a\u5b9e\u4f8b\u7684\u7b26\u53f7\uff0cResNet50\u6a21\u578b\u8fbe\u5230\u4e8687.1%\u7684top-1\u5f97\u5206\u548c96.5%\u7684top-5\u5f97\u5206\u3002", "conclusion": "\u8fd9\u4e9b\u81ea\u52a8\u5206\u7c7b\u7ed3\u679c\u662f\u9996\u6b21\u5e94\u7528\u4e8e\u53e4\u5df4\u6bd4\u4f26\u6587\u672c\u7684\u7ed3\u679c\uff0c\u56e0\u6b64\u76ee\u524d\u6ca1\u6709\u53ef\u6bd4\u8f83\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.14056", "pdf": "https://arxiv.org/pdf/2507.14056", "abs": "https://arxiv.org/abs/2507.14056", "authors": ["Alejandro Rodriguez-Garcia", "Anindya Ghosh", "Srikanth Ramaswamy"], "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05"], "comment": "18 pages, 5 figures, 1 table, 1 pseudo-code", "summary": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u589e\u76ca\u52a8\u529b\u5b66\u673a\u5236\uff0c\u4ee5\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u8fd1\u671f\u7684\u6301\u7eed\u5b66\u4e60\u7814\u7a76\u4e2d\u53d1\u73b0\uff0c\u5728\u638c\u63e1\u65b0\u4efb\u52a1\u65f6\uff0c\u5df2\u638c\u63e1\u4efb\u52a1\u7684\u8868\u73b0\u4f1a\u51fa\u73b0\u77ed\u6682\u4e0b\u964d\uff0c\u5373\u6240\u8c13\u7684\u201c\u7a33\u5b9a\u6027\u5dee\u8ddd\u201d\u3002\u8fd9\u79cd\u73b0\u8c61\u8fdd\u80cc\u4e86\u6301\u7eed\u5b66\u4e60\u7684\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u5728\u7f13\u89e3\u9057\u5fd8\u65b9\u9762\u7684\u7f3a\u4e4f\u7a33\u5065\u6027\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u8c03\u67e5\u53ef\u4ee5\u8c03\u548c\u53ef\u5851\u6027\u548c\u7a33\u5b9a\u6027\u7684\u673a\u5236\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u589e\u76ca\u52a8\u529b\u5b66\uff0c\u8fd9\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u673a\u5236\uff0c\u5b83\u8fd1\u4f3c\u4e8e\u53cc\u65f6\u95f4\u5c3a\u5ea6\u4f18\u5316\u5668\uff0c\u5e76\u52a8\u6001\u5e73\u8861\u77e5\u8bc6\u6574\u5408\uff0c\u5c3d\u91cf\u51cf\u5c11\u5bf9\u5148\u524d\u5de9\u56fa\u4fe1\u606f\u7684\u5e72\u6270\u3002", "result": "\u901a\u8fc7\u5728\u8054\u5408\u8bad\u7ec3\u4e0b\u7684MNIST\u548cCIFAR\u57fa\u51c6\u6d4b\u8bd5\u7684\u9886\u57df\u589e\u91cf\u548c\u7c7b\u522b\u589e\u91cf\u53d8\u4f53\u4e0a\u8bc4\u4f30\u8be5\u673a\u5236\uff0c\u7ed3\u679c\u8868\u660e\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u589e\u76ca\u52a8\u529b\u5b66\u6709\u6548\u51cf\u5f31\u4e86\u7a33\u5b9a\u6027\u5dee\u8ddd\u3002", "conclusion": "\u5206\u6790\u8868\u660e\uff0c\u589e\u76ca\u8c03\u5236\u590d\u5236\u4e86\u53bb\u7532\u80be\u4e0a\u817a\u7d20\u80fd\u529f\u80fd\u5728\u76ae\u5c42\u7535\u8def\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u51cf\u5c11\u7a33\u5b9a\u6027\u5dee\u8ddd\u548c\u63d0\u9ad8\u6301\u7eed\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u673a\u5236\u4e0a\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.13992", "pdf": "https://arxiv.org/pdf/2507.13992", "abs": "https://arxiv.org/abs/2507.13992", "authors": ["Jagruti Patel", "Thomas A. W. Bolton", "Mikkel Sch\u00f6ttner", "Anjali Tarun", "Sebastien Tourbier", "Yasser Alem\u00e0n-G\u00f2mez", "Jonas Richiardi", "Patric Hagmann"], "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Small sample sizes in neuroimaging in general, and in structural connectome\n(SC) studies in particular limit the development of reliable biomarkers for\nneurological and psychiatric disorders - such as Alzheimer's disease and\nschizophrenia - by reducing statistical power, reliability, and\ngeneralizability. Large-scale multi-site studies have exist, but they have\nacquisition-related biases due to scanner heterogeneity, compromising imaging\nconsistency and downstream analyses. While existing SC harmonization methods -\nsuch as linear regression (LR), ComBat, and deep learning techniques - mitigate\nthese biases, they often rely on detailed metadata, traveling subjects (TS), or\noverlook the graph-topology of SCs. To address these limitations, we propose a\nsite-conditioned deep harmonization framework that harmonizes SCs across\ndiverse acquisition sites without requiring metadata or TS that we test in a\nsimulated scenario based on the Human Connectome Dataset. Within this\nframework, we benchmark three deep architectures - a fully connected\nautoencoder (AE), a convolutional AE, and a graph convolutional AE - against a\ntop-performing LR baseline. While non-graph models excel in edge-weight\nprediction and edge existence detection, the graph AE demonstrates superior\npreservation of topological structure and subject-level individuality, as\nreflected by graph metrics and fingerprinting accuracy, respectively. Although\nthe LR baseline achieves the highest numerical performance by explicitly\nmodeling acquisition parameters, it lacks applicability to real-world\nmulti-site use cases as detailed acquisition metadata is often unavailable. Our\nresults highlight the critical role of model architecture in SC harmonization\nperformance and demonstrate that graph-based approaches are particularly\nwell-suited for structure-aware, domain-generalizable SC harmonization in\nlarge-scale multi-site SC studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u548c\u8c10\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u7ad9\u70b9\u7814\u7a76\u4e2d\u8c03\u6574\u7ed3\u6784\u8fde\u63a5\u7ec4\u6570\u636e\uff0c\u65e0\u9700\u5143\u6570\u636e\u6216\u65c5\u884c\u4e3b\u4f53\uff0c\u5e76\u901a\u8fc7\u56fe\u5377\u79ef\u81ea\u7f16\u7801\u5668\u5b9e\u73b0\u6700\u4f73\u7684\u62d3\u6251\u7ed3\u6784\u4fdd\u7559\u548c\u4e2a\u4f53\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u5f71\u50cf\u6837\u672c\u91cf\u5c0f\u9650\u5236\u4e86\u53ef\u9760\u7684\u751f\u7269\u6807\u5fd7\u7269\u7684\u53d1\u5c55\uff1b\u5927\u578b\u591a\u5730\u70b9\u7814\u7a76\u5b58\u5728\u7531\u4e8e\u626b\u63cf\u4eea\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u83b7\u53d6\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8be6\u7ec6\u5143\u6570\u636e\uff0c\u8981\u4e48\u5ffd\u89c6\u4e86SCs\u7684\u56fe\u62d3\u6251\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56fe\u5377\u79ef\u81ea\u7f16\u7801\u5668\u7684\u73b0\u573a\u6761\u4ef6\u6df1\u5ea6\u548c\u8c10\u5316\u6846\u67b6\uff0c\u5728\u4e0d\u540c\u7684\u83b7\u53d6\u5730\u70b9\u95f4\u8c03\u6574SCs\uff0c\u65e0\u9700\u5143\u6570\u636e\u6216\u65c5\u884c\u4e3b\u4f53\u3002\u5e76\u5728\u4e09\u79cd\u6df1\u5ea6\u67b6\u6784\u4e2d\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff1a\u5168\u8fde\u63a5\u81ea\u7f16\u7801\u5668\u3001\u5377\u79ef\u81ea\u7f16\u7801\u5668\u548c\u56fe\u5377\u79ef\u81ea\u7f16\u7801\u5668\u3002", "result": "\u975e\u56fe\u6a21\u578b\u5728\u8fb9\u6743\u91cd\u9884\u6d4b\u548c\u8fb9\u5b58\u5728\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800c\u56fe\u81ea\u7f16\u7801\u5668\u5728\u4fdd\u6301\u62d3\u6251\u7ed3\u6784\u548c\u4e2a\u4f53\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5206\u522b\u7531\u56fe\u5ea6\u91cf\u548c\u6307\u7eb9\u8bc6\u522b\u51c6\u786e\u6027\u53cd\u6620\u3002LR\u57fa\u7ebf\u5728\u6570\u503c\u6027\u80fd\u4e0a\u6700\u9ad8\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u5143\u6570\u636e\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u6a21\u578b\u67b6\u6784\u5bf9SC\u548c\u8c10\u5316\u6027\u80fd\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u56fe\u57fa\u65b9\u6cd5\u7279\u522b\u9002\u5408\u4e8e\u5927\u89c4\u6a21\u591a\u5730\u70b9SC\u7814\u7a76\u4e2d\u7684\u7ed3\u6784\u610f\u8bc6\u9886\u57df\u6cdb\u5316\u7684SC\u548c\u8c10\u5316\u3002"}}
{"id": "2507.14121", "pdf": "https://arxiv.org/pdf/2507.14121", "abs": "https://arxiv.org/abs/2507.14121", "authors": ["Pankaj Yadav", "Vivek Vijay"], "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "9 Pages, 4 figures", "summary": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.", "AI": {"tldr": "Kolmogorov Arnold Networks (KANs)\u5728\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u7c7b\u95ee\u9898\u4e0a\u867d\u7136\u5bf9\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e0e\u4f20\u7edf\u4e0d\u5e73\u8861\u7b56\u7565\u51b2\u7a81\u7684\u95ee\u9898\u3002MLPs\u7ed3\u5408\u4e0d\u5e73\u8861\u6280\u672f\u4ee5\u8f83\u4f4e\u8d44\u6e90\u6210\u672c\u5b9e\u73b0\u4e86\u4e0eKANs\u76f8\u5f53\u7684\u6548\u679c\u3002\u672a\u6765\u7814\u7a76\u9700\u8981\u9488\u5bf9KANs\u5f00\u53d1\u4e13\u95e8\u7684\u67b6\u6784\u4fee\u6539\u3001\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u7b49\u3002", "motivation": "\u8bc4\u4f30KANs\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u63a2\u8ba8\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\uff08\u5982MLPs\uff09\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5341\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e86KANs\u548cMLPs\u5728\u5904\u7406\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u65f6\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5b83\u4eec\u4e0e\u91cd\u91c7\u6837\u548c\u7126\u70b9\u635f\u5931\u7b49\u4e0d\u5e73\u8861\u7b56\u7565\u7684\u517c\u5bb9\u6027\u3002", "result": "KANs\u5728\u5904\u7406\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u65b9\u9762\u4f18\u4e8eMLPs\uff0c\u4f46\u5728\u5e94\u7528\u91cd\u91c7\u6837\u6216\u7126\u70b9\u635f\u5931\u540e\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b\u540c\u65f6\uff0cKANs\u7684\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\uff0c\u800cMLPs\u7ed3\u5408\u4e0d\u5e73\u8861\u6280\u672f\u80fd\u4ee5\u8f83\u4f4e\u7684\u8d44\u6e90\u6210\u672c\u8fbe\u5230\u76f8\u4f3c\u6548\u679c\u3002", "conclusion": "KANs\u5bf9\u4e8e\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u662f\u4e00\u79cd\u4e13\u4e1a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7531\u4e8e\u5176\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u4e0e\u6807\u51c6\u91cd\u91c7\u6837\u6280\u672f\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u9650\u5236\u3002\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5305\u62ec\u4e3aKANs\u5f00\u53d1\u7279\u5b9a\u7684\u67b6\u6784\u4fee\u6539\u3001\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u4ee5\u53ca\u89e3\u51b3\u5176\u4e0e\u6570\u636e\u589e\u5f3a\u4e4b\u95f4\u7684\u7406\u8bba\u51b2\u7a81\u3002"}}
{"id": "2507.13998", "pdf": "https://arxiv.org/pdf/2507.13998", "abs": "https://arxiv.org/abs/2507.13998", "authors": ["Itay Katav", "Aryeh Kontorovich"], "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies", "categories": ["cs.LG"], "comment": null, "summary": "Modern multivariate time series forecasting primarily relies on two\narchitectures: the Transformer with attention mechanism and Mamba. In natural\nlanguage processing, an approach has been used that combines local window\nattention for capturing short-term dependencies and Mamba for capturing\nlong-term dependencies, with their outputs averaged to assign equal weight to\nboth. We find that for time-series forecasting tasks, assigning equal weight to\nlong-term and short-term dependencies is not optimal. To mitigate this, we\npropose a dynamic weighting mechanism, ParallelTime Weighter, which calculates\ninterdependent weights for long-term and short-term dependencies for each token\nbased on the input and the model's knowledge. Furthermore, we introduce the\nParallelTime architecture, which incorporates the ParallelTime Weighter\nmechanism to deliver state-of-the-art performance across diverse benchmarks.\nOur architecture demonstrates robustness, achieves lower FLOPs, requires fewer\nparameters, scales effectively to longer prediction horizons, and significantly\noutperforms existing methods. These advances highlight a promising path for\nfuture developments of parallel Attention-Mamba in time series forecasting. The\nimplementation is readily available at:\n\\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub", "AI": {"tldr": "\u63d0\u51faParallelTime\u67b6\u6784\uff0c\u7ed3\u5408\u5e76\u884c\u6ce8\u610f\u529b\u548cMamba\u673a\u5236\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u6743\u91cd\u5206\u914d\u5668\u6765\u4f18\u5316\u957f\u77ed\u4f9d\u8d56\u5173\u7cfb\u7684\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5bf9\u957f\u77ed\u671f\u4f9d\u8d56\u8d4b\u4e88\u4e86\u76f8\u540c\u7684\u6743\u91cd\uff0c\u8fd9\u5e76\u4e0d\u662f\u6700\u4f18\u7684\u505a\u6cd5\u3002", "method": "\u63d0\u51faParallelTime Weighter\u673a\u5236\uff0c\u6839\u636e\u8f93\u5165\u548c\u6a21\u578b\u77e5\u8bc6\u4e3a\u6bcf\u4e2atoken\u8ba1\u7b97\u957f\u77ed\u671f\u4f9d\u8d56\u7684\u76f8\u4e92\u4f9d\u5b58\u6743\u91cd\u3002\u540c\u65f6\u5f15\u5165ParallelTime\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5305\u542bParallelTime Weighter\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3001\u66f4\u4f4e\u7684FLOPs\u3001\u66f4\u5c11\u7684\u53c2\u6570\u9700\u6c42\u3001\u66f4\u6709\u6548\u7684\u6269\u5c55\u5230\u66f4\u957f\u7684\u9884\u6d4b\u8303\u56f4\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5e76\u884c\u6ce8\u610f\u529b-Mamba\u7684\u53d1\u5c55\u6307\u660e\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
{"id": "2507.14126", "pdf": "https://arxiv.org/pdf/2507.14126", "abs": "https://arxiv.org/abs/2507.14126", "authors": ["Jianhong Chen", "Meng Zhao", "Mostafa Reisi Gahrooei", "Xubo Yue"], "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u6846\u67b6CaRTeD\uff0c\u5b83\u7ed3\u5408\u4e86\u65f6\u95f4\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u4e0e\u4e0d\u89c4\u5219\u5f20\u91cf\u5206\u89e3\uff0c\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u3001\u957f\u5ea6\u53d8\u5316\u7684\u6570\u636e\uff0c\u5e76\u4e14\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u5de5\u5177\u4e3b\u8981\u9002\u7528\u4e8e\u4f4e\u7ef4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u800c\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\u9047\u5230\u7684\u6570\u636e\u662f\u9ad8\u7ef4\u7684\u3001\u957f\u5ea6\u4e0d\u4e00\u4e14\u5f62\u5f0f\u4e3a\u4e0d\u89c4\u5219\u5f20\u91cf\u3002\u4e3a\u4e86\u5206\u6790\u6b64\u7c7b\u6570\u636e\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u53d6\u6709\u610f\u4e49\u805a\u7c7b\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u56e0\u679c\u516c\u5f0f\u6765\u8868\u793a\u6f5c\u5728\u7684\u805a\u7c7b\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u5b66\u4e60\u6846\u67b6CaRTeD\uff0c\u8be5\u6846\u67b6\u5c06\u65f6\u95f4\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u4e0e\u4e0d\u89c4\u5219\u5f20\u91cf\u5206\u89e3\u76f8\u7ed3\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u6b63\u5219\u5316\u8bbe\u8ba1\u4ee5\u589e\u5f3a\u5f20\u91cf\u5206\u89e3\u7684\u6548\u679c\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u7b97\u6cd5\u53ef\u4ee5\u6536\u655b\u5230\u7a33\u5b9a\u70b9\uff0c\u5e76\u586b\u8865\u4e86\u6700\u5148\u8fdb\u7684\u4e0d\u89c4\u5219\u5f20\u91cf\u5206\u89e3\u7406\u8bba\u4fdd\u8bc1\u4e0a\u7684\u7a7a\u767d\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e76\u589e\u5f3a\u4e86\u56e0\u679c\u8868\u5f81\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "CaRTeD\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5206\u6790\u590d\u6742\u3001\u9ad8\u7ef4\u3001\u957f\u5ea6\u4e0d\u4e00\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u800c\u4e14\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5728\u5b9e\u8df5\u4e2d\u4e5f\u5c55\u793a\u4e86\u66f4\u597d\u7684\u6027\u80fd\u548c\u66f4\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.14005", "pdf": "https://arxiv.org/pdf/2507.14005", "abs": "https://arxiv.org/abs/2507.14005", "authors": ["Mathieu Godbout", "Audrey Durand"], "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "Recent work has shown that dynamic programming (DP) methods for finding\nstatic CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when\nbased on the dual formulation, yet the root cause for the failure has remained\nunclear. We expand on these findings by shifting focus from policy optimization\nto the seemingly simpler task of policy evaluation. We show that evaluating the\nstatic CVaR of a given policy can be framed as two distinct minimization\nproblems. For their solutions to match, a set of ``risk-assignment consistency\nconstraints'' must be satisfied, and we demonstrate that the intersection of\nthe constraints being empty is the source of previously observed evaluation\nerrors. Quantifying the evaluation error as the CVaR evaluation gap, we then\ndemonstrate that the issues observed when optimizing over the dual-based CVaR\nDP are explained by the returned policy having a non-zero CVaR evaluation gap.\nWe then leverage our proposed risk-assignment perspective to prove that the\nsearch for a single, uniformly optimal policy via on the dual CVaR\ndecomposition is fundamentally limited, identifying an MDP where no single\npolicy can be optimal across all initial risk levels.", "AI": {"tldr": "\u672c\u6587\u89e3\u91ca\u4e86\u57fa\u4e8e\u5bf9\u5076\u516c\u5f0f\u5728\u9a6c\u5c14\u79d1\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5bfb\u627e\u9759\u6001CVaR\u6700\u4f18\u7b56\u7565\u7684\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u5931\u8d25\u7684\u539f\u56e0\uff0c\u5e76\u8bc1\u660e\u4e86\u901a\u8fc7CVaR\u5206\u89e3\u5728\u5bf9\u5076CVaR\u4e0a\u641c\u7d22\u5355\u4e00\u3001\u5747\u5300\u6700\u4f18\u7b56\u7565\u662f\u6839\u672c\u53d7\u9650\u7684\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u57fa\u4e8e\u5bf9\u5076\u516c\u5f0f\u7684\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u6765\u627e\u5230\u9759\u6001CVaR\u6700\u4f18\u7b56\u7565\u53ef\u80fd\u4f1a\u5931\u8d25\uff0c\u4f46\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u8fd9\u79cd\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u4f5c\u8005\u5c06\u8bc4\u4f30\u7ed9\u5b9a\u7b56\u7565\u7684\u9759\u6001CVaR\u95ee\u9898\u6846\u67b6\u4e3a\u4e24\u4e2a\u4e0d\u540c\u7684\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u98ce\u9669\u5206\u914d\u4e00\u81f4\u6027\u7ea6\u675f\u201d\u7684\u6982\u5ff5\u3002\u5f53\u8fd9\u4e9b\u7ea6\u675f\u6761\u4ef6\u7684\u4ea4\u96c6\u4e3a\u7a7a\u65f6\uff0c\u5c31\u4f1a\u51fa\u73b0\u4ee5\u524d\u89c2\u5bdf\u5230\u7684\u8bc4\u4f30\u9519\u8bef\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u5728\u4f18\u5316\u5bf9\u5076CVaR DP\u65f6\u51fa\u73b0\u7684\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u8fd4\u56de\u7684\u7b56\u7565\u5177\u6709\u975e\u96f6CVaR\u8bc4\u4f30\u5dee\u8ddd\u6765\u89e3\u91ca\uff0c\u5e76\u4e14\u5728\u67d0\u4e9bMDP\u4e2d\uff0c\u6ca1\u6709\u4efb\u4f55\u5355\u4e00\u7b56\u7565\u53ef\u4ee5\u5728\u6240\u6709\u521d\u59cb\u98ce\u9669\u6c34\u5e73\u4e0a\u90fd\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u5076CVaR\u5206\u89e3\u641c\u7d22\u5355\u4e00\u3001\u5747\u5300\u6700\u4f18\u7b56\u7565\u7684\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u9650\u5236\uff0c\u8fd9\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u65b9\u5411\u3002"}}
{"id": "2507.14021", "pdf": "https://arxiv.org/pdf/2507.14021", "abs": "https://arxiv.org/abs/2507.14021", "authors": ["Xu Zhang", "Zhenyuan Yuan", "Minghui Zhu"], "title": "Byzantine-resilient federated online learning for Gaussian process regression", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u62dc\u5360\u5ead\u5f39\u6027\u8054\u90a6\u5728\u7ebf\u5b66\u4e60\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u62b5\u6297\u62dc\u5360\u5ead\u6545\u969c\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u5982\u4f55\u5728\u5b58\u5728\u62dc\u5360\u5ead\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u6a21\u578b\u7684\u51c6\u786e\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u9886\u57df\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u62dc\u5360\u5ead\u5f39\u6027\u7684\u8054\u90a6GPR\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5141\u8bb8\u4e91\u7aef\u548c\u4e00\u7ec4\u4ee3\u7406\u5171\u540c\u5b66\u4e60\u4e00\u4e2a\u6f5c\u5728\u51fd\u6570\uff0c\u5e76\u6539\u8fdb\u5b66\u4e60\u6027\u80fd\u3002\u6bcf\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u672c\u5730GPR\u5411\u4e91\u7aef\u53d1\u9001\u53ef\u80fd\u88ab\u7834\u574f\u7684\u672c\u5730\u9884\u6d4b\uff0c\u800c\u57fa\u4e8e\u4e91\u7aef\u7684\u805a\u5408GPR\u5219\u901a\u8fc7\u62dc\u5360\u5ead\u5f39\u6027\u7684\u4e13\u5bb6\u4ea7\u54c1\u805a\u5408\u89c4\u5219\u8ba1\u7b97\u5168\u5c40\u6a21\u578b\u3002\u7136\u540e\uff0c\u4e91\u7aef\u5c06\u5f53\u524d\u5168\u5c40\u6a21\u578b\u5e7f\u64ad\u7ed9\u6240\u6709\u4ee3\u7406\uff0c\u4ee3\u7406\u878d\u5408GPR\u901a\u8fc7\u878d\u5408\u63a5\u6536\u5230\u7684\u5168\u5c40\u6a21\u578b\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u672c\u5730GPR\u6765\u4f18\u5316\u672c\u5730\u9884\u6d4b\u3002", "result": "\u901a\u8fc7\u5728\u73a9\u5177\u793a\u4f8b\u548c\u4e24\u4e2a\u4e2d\u7b49\u89c4\u6a21\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5b66\u4e60\u7cbe\u5ea6\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u62dc\u5360\u5ead\u5f39\u6027\u8054\u90a6GPR\u7b97\u6cd5\u80fd\u591f\u5728\u5b58\u5728\u62dc\u5360\u5ead\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u63d0\u9ad8\u5b66\u4e60\u6027\u80fd\uff0c\u4e3a\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14038", "pdf": "https://arxiv.org/pdf/2507.14038", "abs": "https://arxiv.org/abs/2507.14038", "authors": ["Aileen Luo", "Tao Zhou", "Ming Du", "Martin V. Holt", "Andrej Singer", "Mathew J. Cherukara"], "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Coherent X-ray scattering techniques are critical for investigating the\nfundamental structural properties of materials at the nanoscale. While\nadvancements have made these experiments more accessible, real-time analysis\nremains a significant bottleneck, often hindered by artifacts and computational\ndemands. In scanning X-ray nanodiffraction microscopy, which is widely used to\nspatially resolve structural heterogeneities, this challenge is compounded by\nthe convolution of the divergent beam with the sample's local structure. To\naddress this, we introduce DONUT (Diffraction with Optics for Nanobeam by\nUnsupervised Training), a physics-aware neural network designed for the rapid\nand automated analysis of nanobeam diffraction data. By incorporating a\ndifferentiable geometric diffraction model directly into its architecture,\nDONUT learns to predict crystal lattice strain and orientation in real-time.\nCrucially, this is achieved without reliance on labeled datasets or\npre-training, overcoming a fundamental limitation for supervised machine\nlearning in X-ray science. We demonstrate experimentally that DONUT accurately\nextracts all features within the data over 200 times more efficiently than\nconventional fitting methods.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDONUT\u7684\u7269\u7406\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u53ef\u4ee5\u5728\u65e0\u9700\u6807\u8bb0\u6570\u636e\u96c6\u6216\u9884\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u65f6\u9884\u6d4b\u6676\u4f53\u6676\u683c\u5e94\u53d8\u548c\u65b9\u5411\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cDONUT\u7684\u6570\u636e\u7279\u5f81\u63d0\u53d6\u6548\u7387\u63d0\u9ad8\u4e86200\u591a\u500d\u3002", "motivation": "X\u5c04\u7ebf\u6563\u5c04\u6280\u672f\u5bf9\u4e8e\u7814\u7a76\u6750\u6599\u7684\u7eb3\u7c73\u7ea7\u57fa\u672c\u7ed3\u6784\u5c5e\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5b9e\u65f6\u5206\u6790\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u74f6\u9888\uff0c\u901a\u5e38\u53d7\u5230\u4eba\u5de5\u5236\u54c1\u548c\u8ba1\u7b97\u9700\u6c42\u7684\u963b\u788d\u3002\u5728\u626b\u63cfX\u5c04\u7ebf\u7eb3\u7c73\u884d\u5c04\u663e\u5fae\u955c\u4e2d\uff0c\u8fd9\u79cd\u6311\u6218\u7531\u4e8e\u53d1\u6563\u5149\u675f\u4e0e\u6837\u54c1\u5c40\u90e8\u7ed3\u6784\u7684\u5377\u79ef\u800c\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86DONUT\uff08\u901a\u8fc7\u65e0\u76d1\u7763\u8bad\u7ec3\u5bf9\u7eb3\u7c73\u675f\u8fdb\u884c\u5149\u5b66\u884d\u5c04\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e\u5feb\u901f\u81ea\u52a8\u5206\u6790\u7eb3\u7c73\u675f\u884d\u5c04\u6570\u636e\u7684\u7269\u7406\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\u3002\u901a\u8fc7\u5c06\u5176\u67b6\u6784\u4e2d\u76f4\u63a5\u7ed3\u5408\u53ef\u533a\u5206\u7684\u51e0\u4f55\u884d\u5c04\u6a21\u578b\uff0cDONUT\u5b66\u4e60\u5b9e\u65f6\u9884\u6d4b\u6676\u4f53\u6676\u683c\u5e94\u53d8\u548c\u65b9\u5411\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDONUT\u80fd\u591f\u5728\u8d85\u8fc7200\u500d\u4e8e\u4f20\u7edf\u62df\u5408\u65b9\u6cd5\u7684\u6548\u7387\u4e0b\u51c6\u786e\u63d0\u53d6\u6570\u636e\u4e2d\u7684\u6240\u6709\u7279\u5f81\u3002", "conclusion": "DONUT\u514b\u670d\u4e86X\u5c04\u7ebf\u79d1\u5b66\u4e2d\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u9650\u5236\uff0c\u4e3a\u626b\u63cfX\u5c04\u7ebf\u7eb3\u7c73\u884d\u5c04\u663e\u5fae\u955c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u6709\u6548\u7684\u5b9e\u65f6\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2507.14066", "pdf": "https://arxiv.org/pdf/2507.14066", "abs": "https://arxiv.org/abs/2507.14066", "authors": ["Ni Mu", "Yao Luan", "Qing-Shan Jia"], "title": "Preference-based Multi-Objective Reinforcement Learning", "categories": ["cs.LG"], "comment": "This article has been accepted for publication in IEEE Transactions\n  on Automation Science and Engineering. This is the author's version, which\n  has not been fully edited, and the content may change prior to final\n  publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights\n  for text and data mining and training of artificial intelligence and similar\n  technologies", "summary": "Multi-objective reinforcement learning (MORL) is a structured approach for\noptimizing tasks with multiple objectives. However, it often relies on\npre-defined reward functions, which can be hard to design for balancing\nconflicting goals and may lead to oversimplification. Preferences can serve as\nmore flexible and intuitive decision-making guidance, eliminating the need for\ncomplicated reward design. This paper introduces preference-based MORL\n(Pb-MORL), which formalizes the integration of preferences into the MORL\nframework. We theoretically prove that preferences can derive policies across\nthe entire Pareto frontier. To guide policy optimization using preferences, our\nmethod constructs a multi-objective reward model that aligns with the given\npreferences. We further provide theoretical proof to show that optimizing this\nreward model is equivalent to training the Pareto optimal policy. Extensive\nexperiments in benchmark multi-objective tasks, a multi-energy management task,\nand an autonomous driving task on a multi-line highway show that our method\nperforms competitively, surpassing the oracle method, which uses the ground\ntruth reward function. This highlights its potential for practical applications\nin complex real-world systems.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u504f\u597d\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08Pb-MORL\uff09\uff0c\u901a\u8fc7\u5c06\u504f\u597d\u6574\u5408\u8fdbMORL\u6846\u67b6\uff0c\u4ee5\u66f4\u7075\u6d3b\u76f4\u89c2\u5730\u6307\u5bfc\u51b3\u7b56\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u5956\u52b1\u8bbe\u8ba1\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u51fd\u6570\u7684Oracle\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9884\u5b9a\u4e49\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8fd9\u96be\u4ee5\u5e73\u8861\u51b2\u7a81\u7684\u76ee\u6807\u4e14\u53ef\u80fd\u8fc7\u4e8e\u7b80\u5316\u95ee\u9898\u3002\u4e3a\u4e86\u63d0\u4f9b\u66f4\u7075\u6d3b\u548c\u76f4\u89c2\u7684\u51b3\u7b56\u6307\u5bfc\uff0c\u672c\u6587\u5f15\u5165\u4e86\u57fa\u4e8e\u504f\u597d\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u4e0e\u7ed9\u5b9a\u504f\u597d\u4e00\u81f4\u7684\u591a\u76ee\u6807\u5956\u52b1\u6a21\u578b\u6765\u6307\u5bfc\u7b56\u7565\u4f18\u5316\uff0c\u5e76\u7406\u8bba\u8bc1\u660e\u4e86\u4f18\u5316\u6b64\u5956\u52b1\u6a21\u578b\u7b49\u540c\u4e8e\u8bad\u7ec3\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u591a\u76ee\u6807\u4efb\u52a1\u3001\u591a\u80fd\u6e90\u7ba1\u7406\u4efb\u52a1\u548c\u591a\u8f66\u9053\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u51fd\u6570\u7684Oracle\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u57fa\u4e8e\u504f\u597d\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.14088", "pdf": "https://arxiv.org/pdf/2507.14088", "abs": "https://arxiv.org/abs/2507.14088", "authors": ["Xiyun Li", "Yining Ding", "Yuhua Jiang", "Yunlong Zhao", "Runpeng Xie", "Shuang Xu", "Yuanhua Ni", "Yiqin Yang", "Bo Xu"], "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration", "categories": ["cs.LG"], "comment": null, "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684DPMT\u6846\u67b6\uff0c\u4ee5\u6539\u5584\u4eba\u7c7b\u4e0eAI\u5728\u5b9e\u65f6\u534f\u4f5c\u4e2d\u7684\u4e92\u52a8\uff0c\u7279\u522b\u662f\u901a\u8fc7\u591a\u5c3a\u5ea6ToM\u6a21\u5757\u6765\u5efa\u6a21\u4eba\u7c7b\u7684\u5fc3\u7406\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u6ca1\u6709\u76f4\u63a5\u6c9f\u901a\u7684\u60c5\u51b5\u4e0b\uff0c\u96be\u4ee5\u51c6\u786e\u6a21\u62df\u590d\u6742\u7684\u4eba\u7c7b\u5fc3\u7406\u7279\u5f81\uff0c\u5982\u9886\u57df\u610f\u56fe\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u573a\u666f\u4e2d\u9002\u5e94\u4e0d\u540c\u548c\u672a\u89c1\u8fc7\u7684\u4eba\u7c7b\u884c\u4e3a\u65f6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u53cc\u91cd\u8fc7\u7a0b\u7406\u8bba\u7684\u65b0\u578bDPMT\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7684ToM\u6a21\u5757\uff0c\u7528\u4e8e\u901a\u8fc7\u5fc3\u7406\u7279\u5f81\u63a8\u7406\u6765\u5f3a\u5316\u5bf9\u4eba\u7c7b\u4f19\u4f34\u7684\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86DPMT\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u7684\u6548\u679c\uff0c\u5e76\u4e14\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u591a\u5c3a\u5ea6ToM\u5bf9\u6162\u7cfb\u7edf\u7684\u91cd\u8981\u8d21\u732e\u3002", "conclusion": "DPMT\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5b58\u5728\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86AI\u5728\u7406\u89e3\u548c\u9002\u5e94\u4eba\u7c7b\u884c\u4e3a\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e3a\u66f4\u9ad8\u6548\u7684\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
