{"id": "2505.22698", "pdf": "https://arxiv.org/pdf/2505.22698", "abs": "https://arxiv.org/abs/2505.22698", "authors": ["Luca Fantin", "Marco Antonelli", "Margherita Cesetti", "Daniele Irto", "Bruno Zamengo", "Francesco Silvestri"], "title": "Design and testing of an agent chatbot supporting decision making with public transport data", "categories": ["cs.AI"], "comment": null, "summary": "Assessing the quality of public transportation services requires the analysis\nof large quantities of data on the scheduled and actual trips and documents\nlisting the quality constraints each service needs to meet. Interrogating such\ndatasets with SQL queries, organizing and visualizing the data can be quite\ncomplex for most users. This paper presents a chatbot offering a user-friendly\ntool to interact with these datasets and support decision making. It is based\non an agent architecture, which expands the capabilities of the core Large\nLanguage Model (LLM) by allowing it to interact with a series of tools that can\nexecute several tasks, like performing SQL queries, plotting data and creating\nmaps from the coordinates of a trip and its stops. This paper also tackles one\nof the main open problems of such Generative AI projects: collecting data to\nmeasure the system's performance. Our chatbot has been extensively tested with\na workflow that asks several questions and stores the generated query, the\nretrieved data and the natural language response for each of them. Such\nquestions are drawn from a set of base examples which are then completed with\nactual data from the database. This procedure yields a dataset for the\nevaluation of the chatbot's performance, especially the consistency of its\nanswers and the correctness of the generated queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u67b6\u6784\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u7b80\u5316\u516c\u5171\u4ea4\u901a\u670d\u52a1\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u590d\u6742\u6570\u636e\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u4e00\u7cfb\u5217\u5de5\u5177\u652f\u6301\u51b3\u7b56\u5236\u5b9a\u3002\u540c\u65f6\uff0c\u6587\u7ae0\u8fd8\u63a2\u8ba8\u4e86\u5982\u4f55\u6536\u96c6\u6570\u636e\u4ee5\u8861\u91cf\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u786e\u4fdd\u751f\u6210\u67e5\u8be2\u7684\u6b63\u786e\u6027\u548c\u7b54\u6848\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u8bc4\u4f30\u516c\u5171\u4ea4\u901a\u670d\u52a1\u8d28\u91cf\u9700\u8981\u5206\u6790\u5927\u91cf\u8ba1\u5212\u548c\u5b9e\u9645\u884c\u7a0b\u6570\u636e\u53ca\u8d28\u91cf\u7ea6\u675f\u6587\u6863\uff0c\u800c\u4f7f\u7528SQL\u67e5\u8be2\u3001\u7ec4\u7ec7\u548c\u53ef\u89c6\u5316\u8fd9\u4e9b\u6570\u636e\u5bf9\u5927\u591a\u6570\u7528\u6237\u6765\u8bf4\u8fc7\u4e8e\u590d\u6742\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53cb\u597d\u7684\u4ea4\u4e92\u65b9\u5f0f\u6765\u5904\u7406\u8fd9\u4e9b\u6570\u636e\u5e76\u652f\u6301\u51b3\u7b56\u3002", "method": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u67b6\u6784\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u589e\u5f3a\u4e86\u6838\u5fc3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u529f\u80fd\uff0c\u4f7f\u5176\u80fd\u591f\u4e0e\u6267\u884c\u591a\u79cd\u4efb\u52a1\u7684\u5de5\u5177\u8fdb\u884c\u4ea4\u4e92\uff0c\u4f8b\u5982\u6267\u884cSQL\u67e5\u8be2\u3001\u7ed8\u5236\u6570\u636e\u56fe\u8868\u548c\u6839\u636e\u884c\u7a0b\u53ca\u5176\u505c\u9760\u70b9\u7684\u5750\u6807\u521b\u5efa\u5730\u56fe\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u5de5\u4f5c\u6d41\u6765\u6d4b\u8bd5\u804a\u5929\u673a\u5668\u4eba\uff0c\u8be5\u5de5\u4f5c\u6d41\u4f1a\u63d0\u51fa\u591a\u4e2a\u95ee\u9898\u5e76\u5b58\u50a8\u751f\u6210\u7684\u67e5\u8be2\u3001\u68c0\u7d22\u5230\u7684\u6570\u636e\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u54cd\u5e94\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u6027\u80fd\u7684\u6570\u636e\u96c6\u3002", "result": "\u804a\u5929\u673a\u5668\u4eba\u53ef\u4ee5\u6709\u6548\u5730\u7b80\u5316\u7528\u6237\u4e0e\u590d\u6742\u516c\u5171\u4ea4\u901a\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u5e76\u652f\u6301\u51b3\u7b56\u5236\u5b9a\u3002\u901a\u8fc7\u6d4b\u8bd5\u5de5\u4f5c\u6d41\uff0c\u7814\u7a76\u4eba\u5458\u6210\u529f\u6536\u96c6\u4e86\u7528\u4e8e\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u6027\u80fd\u7684\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5176\u7b54\u6848\u7684\u4e00\u81f4\u6027\u548c\u751f\u6210\u67e5\u8be2\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u804a\u5929\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u53cb\u597d\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u7b80\u5316\u516c\u5171\u4ea4\u901a\u670d\u52a1\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u590d\u6742\u6570\u636e\u64cd\u4f5c\u3002\u540c\u65f6\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u751f\u6210\u5f0fAI\u9879\u76ee\u4e2d\u7cfb\u7edf\u6027\u80fd\u6d4b\u91cf\u6570\u636e\u6536\u96c6\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7c7b\u4f3c\u9879\u76ee\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2505.22753", "pdf": "https://arxiv.org/pdf/2505.22753", "abs": "https://arxiv.org/abs/2505.22753", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Ariel Felner", "Roie Zivan"], "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "categories": ["cs.AI", "cs.MA", "cs.RO"], "comment": null, "summary": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent\nPath Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of\nagents must move to their goal locations without collisions, whereas in LMAPF,\nnew goals are generated upon arrival. We propose methods for incorporating APFs\nin a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and\nPriority Inheritance with Backtracking (PIBT). Experimental results show that\nusing APF is not beneficial for MAPF but yields up to a 7-fold increase in\noverall system throughput for LMAPF.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\uff08MAPF\uff09\u548c\u7ec8\u8eab\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\uff08LMAPF\uff09\u95ee\u9898\u4e2d\u4f7f\u7528\u4eba\u5de5\u52bf\u573a\uff08APFs\uff09\u3002\u5bf9\u4e8eMAPF\uff0c\u56e2\u961f\u4e2d\u7684\u6bcf\u4e2a\u667a\u80fd\u4f53\u5fc5\u987b\u65e0\u78b0\u649e\u5730\u79fb\u52a8\u5230\u5176\u76ee\u6807\u4f4d\u7f6e\uff1b\u800c\u5bf9\u4e8eLMAPF\uff0c\u5728\u5230\u8fbe\u540e\u4f1a\u4ea7\u751f\u65b0\u7684\u76ee\u6807\u3002\u672c\u6587\u63d0\u51fa\u5c06APFs\u6574\u5408\u5230\u4e00\u7cfb\u5217MAPF\u7b97\u6cd5\u4e2d\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4f18\u5148\u7ea7\u89c4\u5212\u3001MAPF-LNS2\u548c\u5177\u6709\u56de\u6eaf\u529f\u80fd\u7684\u4f18\u5148\u7ea7\u7ee7\u627f\uff08PIBT\uff09\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528APF\u5bf9MAPF\u6ca1\u6709\u597d\u5904\uff0c\u4f46\u53ef\u4ee5\u4f7fLMAPF\u7684\u6574\u4f53\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u9ad8\u591a\u8fbe7\u500d\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u4ee5\u53ca\u66f4\u590d\u6742\u7684\u7ec8\u8eab\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u63a2\u7d22\u4eba\u5de5\u52bf\u573a\u5728\u8fd9\u4e9b\u573a\u666f\u4e0b\u7684\u9002\u7528\u6027\u548c\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u3002", "method": "\u5c06\u4eba\u5de5\u52bf\u573a\uff08APFs\uff09\u878d\u5165\u591a\u79cdMAPF\u7b97\u6cd5\u4e2d\uff0c\u5305\u62ec\u4f18\u5148\u7ea7\u89c4\u5212\u3001MAPF-LNS2\u548c\u4f18\u5148\u7ea7\u7ee7\u627f\u5e26\u56de\u6eaf\uff08PIBT\uff09\uff0c\u4ee5\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u8def\u5f84\u89c4\u5212\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u6807\u51c6\u7684MAPF\u95ee\u9898\uff0c\u4f7f\u7528APF\u5e76\u6ca1\u6709\u5e26\u6765\u4f18\u52bf\uff1b\u7136\u800c\uff0c\u5728LMAPF\u95ee\u9898\u4e2d\uff0c\u4f7f\u7528APF\u4f7f\u6574\u4f53\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u5347\u4e86\u9ad8\u8fbe7\u500d\u3002", "conclusion": "\u4eba\u5de5\u52bf\u573a\u5728\u7ec8\u8eab\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5728\u6807\u51c6\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u4e2d\u6548\u679c\u4e0d\u660e\u663e\u3002"}}
{"id": "2505.22756", "pdf": "https://arxiv.org/pdf/2505.22756", "abs": "https://arxiv.org/abs/2505.22756", "authors": ["Tian Qin", "Core Francisco Park", "Mujin Kwun", "Aaron Walsman", "Eran Malach", "Nikhil Anand", "Hidenori Tanaka", "David Alvarez-Melis"], "title": "Decomposing Elements of Problem Solving: What \"Math\" Does RL Teach?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Mathematical reasoning tasks have become prominent benchmarks for assessing\nthe reasoning capabilities of LLMs, especially with reinforcement learning (RL)\nmethods such as GRPO showing significant performance gains. However, accuracy\nmetrics alone do not support fine-grained assessment of capabilities and fail\nto reveal which problem-solving skills have been internalized. To better\nunderstand these capabilities, we propose to decompose problem solving into\nfundamental capabilities: Plan (mapping questions to sequences of steps),\nExecute (correctly performing solution steps), and Verify (identifying the\ncorrectness of a solution). Empirically, we find that GRPO mainly enhances the\nexecution skill-improving execution robustness on problems the model already\nknows how to solve-a phenomenon we call temperature distillation. More\nimportantly, we show that RL-trained models struggle with fundamentally new\nproblems, hitting a 'coverage wall' due to insufficient planning skills. To\nexplore RL's impact more deeply, we construct a minimal, synthetic\nsolution-tree navigation task as an analogy for mathematical problem-solving.\nThis controlled setup replicates our empirical findings, confirming RL\nprimarily boosts execution robustness. Importantly, in this setting, we\nidentify conditions under which RL can potentially overcome the coverage wall\nthrough improved exploration and generalization to new solution paths. Our\nfindings provide insights into the role of RL in enhancing LLM reasoning,\nexpose key limitations, and suggest a path toward overcoming these barriers.\nCode is available at https://github.com/cfpark00/RL-Wall.", "AI": {"tldr": "\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u662f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u80fd\u529b\u7684\u91cd\u8981\u57fa\u51c6\uff0c\u7279\u522b\u662f\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u5982GRPO\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002\u7136\u800c\uff0c\u4ec5\u9760\u51c6\u786e\u7387\u6307\u6807\u65e0\u6cd5\u7ec6\u81f4\u8bc4\u4f30\u5176\u80fd\u529b\uff0c\u4e5f\u65e0\u6cd5\u63ed\u793a\u54ea\u4e9b\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u5df2\u88ab\u5185\u5316\u3002\u6211\u4eec\u63d0\u51fa\u5c06\u95ee\u9898\u89e3\u51b3\u5206\u89e3\u4e3a\u57fa\u672c\u80fd\u529b\uff1a\u8ba1\u5212\uff08\u5c06\u95ee\u9898\u6620\u5c04\u5230\u6b65\u9aa4\u5e8f\u5217\uff09\u3001\u6267\u884c\uff08\u6b63\u786e\u6267\u884c\u89e3\u51b3\u65b9\u6848\u6b65\u9aa4\uff09\u548c\u9a8c\u8bc1\uff08\u8bc6\u522b\u89e3\u51b3\u65b9\u6848\u7684\u6b63\u786e\u6027\uff09\u3002\u5b9e\u9a8c\u53d1\u73b0\uff0cGRPO\u4e3b\u8981\u589e\u5f3a\u6267\u884c\u6280\u80fd\uff0c\u5728\u6a21\u578b\u5df2\u77e5\u5982\u4f55\u89e3\u51b3\u7684\u95ee\u9898\u4e0a\u63d0\u9ad8\u6267\u884c\u7a33\u5065\u6027\uff0c\u79f0\u4e3a\u6e29\u5ea6\u84b8\u998f\u73b0\u8c61\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cRL\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6839\u672c\u6027\u65b0\u95ee\u9898\u4e0a\u9047\u5230'\u8986\u76d6\u5899'\uff0c\u7531\u4e8e\u89c4\u5212\u6280\u80fd\u4e0d\u8db3\u3002\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u6700\u5c0f\u5408\u6210\u7684\u89e3\u51b3\u65b9\u6848\u6811\u5bfc\u822a\u4efb\u52a1\uff0c\u6211\u4eec\u590d\u5236\u4e86\u5b9e\u8bc1\u7ed3\u679c\uff0c\u786e\u8ba4RL\u4e3b\u8981\u63d0\u9ad8\u6267\u884c\u7a33\u5065\u6027\u3002\u5728\u6b64\u8bbe\u7f6e\u4e0b\uff0c\u6211\u4eec\u786e\u5b9a\u4e86RL\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u548c\u6cdb\u5316\u5230\u65b0\u89e3\u51b3\u65b9\u6848\u8def\u5f84\u6765\u514b\u670d\u8986\u76d6\u5899\u7684\u6761\u4ef6\u3002\u6211\u4eec\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9RL\u589e\u5f3aLLM\u63a8\u7406\u4f5c\u7528\u7684\u89c1\u89e3\uff0c\u66b4\u9732\u4e86\u5173\u952e\u9650\u5236\uff0c\u5e76\u6307\u51fa\u4e86\u514b\u670d\u8fd9\u4e9b\u969c\u788d\u7684\u9014\u5f84\u3002", "motivation": "\u5f53\u524d\u4ec5\u4f9d\u8d56\u51c6\u786e\u7387\u6307\u6807\u65e0\u6cd5\u7ec6\u81f4\u8bc4\u4f30LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u65e0\u6cd5\u63ed\u793a\u54ea\u4e9b\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u5df2\u88ab\u5185\u5316\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u5730\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5c06\u95ee\u9898\u89e3\u51b3\u5206\u89e3\u4e3a\u4e09\u4e2a\u57fa\u672c\u80fd\u529b\uff1aPlan\uff08\u8ba1\u5212\uff09\u3001Execute\uff08\u6267\u884c\uff09\u548cVerify\uff08\u9a8c\u8bc1\uff09\u3002\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790GRPO\u7b49RL\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u80fd\u529b\u7684\u5f71\u54cd\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u6700\u5c0f\u5408\u6210\u7684\u89e3\u51b3\u65b9\u6848\u6811\u5bfc\u822a\u4efb\u52a1\uff0c\u4ee5\u7c7b\u6bd4\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\uff0c\u6df1\u5165\u63a2\u8ba8RL\u7684\u5f71\u54cd\u3002", "result": "1. GRPO\u4e3b\u8981\u589e\u5f3a\u4e86\u6267\u884c\u6280\u80fd\uff0c\u5728\u6a21\u578b\u5df2\u77e5\u5982\u4f55\u89e3\u51b3\u7684\u95ee\u9898\u4e0a\u63d0\u9ad8\u4e86\u6267\u884c\u7a33\u5065\u6027\uff08\u6e29\u5ea6\u84b8\u998f\u73b0\u8c61\uff09\u30022. RL\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6839\u672c\u6027\u65b0\u95ee\u9898\u4e0a\u9047\u5230'\u8986\u76d6\u5899'\uff0c\u7531\u4e8e\u89c4\u5212\u6280\u80fd\u4e0d\u8db3\u30023. \u5728\u5408\u6210\u4efb\u52a1\u4e2d\uff0c\u786e\u8ba4RL\u4e3b\u8981\u63d0\u9ad8\u6267\u884c\u7a33\u5065\u6027\uff0c\u5e76\u786e\u5b9a\u4e86RL\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u548c\u6cdb\u5316\u514b\u670d\u8986\u76d6\u5899\u7684\u6761\u4ef6\u3002", "conclusion": "RL\u5728\u589e\u5f3aLLM\u63a8\u7406\u65b9\u9762\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5b58\u5728\u5173\u952e\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u89c4\u5212\u6280\u80fd\u4e0a\u7684\u4e0d\u8db3\u5bfc\u81f4\u96be\u4ee5\u89e3\u51b3\u6839\u672c\u6027\u65b0\u95ee\u9898\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u514b\u670d\u8fd9\u4e9b\u969c\u788d\u7684\u6f5c\u5728\u8def\u5f84\u3002"}}
{"id": "2505.22779", "pdf": "https://arxiv.org/pdf/2505.22779", "abs": "https://arxiv.org/abs/2505.22779", "authors": ["Mohammad Helal Uddin", "Sabur Baidya"], "title": "Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds", "categories": ["cs.AI"], "comment": null, "summary": "Mental disorders including depression, anxiety, and other neurological\ndisorders pose a significant global challenge, particularly among individuals\nexhibiting social avoidance tendencies. This study proposes a hybrid approach\nby leveraging smartphone sensor data measuring daily physical activities and\nanalyzing their social media (Twitter) interactions for evaluating an\nindividual's depression level. Using CNN-based deep learning models and Naive\nBayes classification, we identify human physical activities accurately and also\nclassify the user sentiments. A total of 33 participants were recruited for\ndata acquisition, and nine relevant features were extracted from the physical\nactivities and analyzed with their weekly depression scores, evaluated using\nthe Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six\nare derived from physical activities, achieving an activity recognition\naccuracy of 95%, while three features stem from sentiment analysis of Twitter\nactivities, yielding a sentiment analysis accuracy of 95.6%. Notably, several\nphysical activity features exhibited significant correlations with the severity\nof depression symptoms. For classifying the depression severity, a support\nvector machine (SVM)-based algorithm is employed that demonstrated a very high\naccuracy of 94%, outperforming alternative models, e.g., the multilayer\nperceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly\neffective in the long run for monitoring depression without breaching personal\nprivacy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u667a\u80fd\u624b\u673a\u4f20\u611f\u5668\u6570\u636e\u548c\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u7684\u6df7\u5408\u65b9\u6cd5\u6765\u8bc4\u4f30\u4e2a\u4eba\u6291\u90c1\u6c34\u5e73\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u5206\u7c7b\u7b97\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u7684\u6d3b\u52a8\u8bc6\u522b\u4e0e\u60c5\u611f\u5206\u6790\uff0c\u5e76\u5229\u7528\u652f\u6301\u5411\u91cf\u673a\u8fdb\u884c\u6291\u90c1\u7a0b\u5ea6\u5206\u7c7b\u3002", "motivation": "\u7cbe\u795e\u969c\u788d\uff08\u5982\u6291\u90c1\u75c7\u3001\u7126\u8651\u75c7\u7b49\uff09\u5728\u5168\u7403\u8303\u56f4\u5185\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8868\u73b0\u51fa\u793e\u4ea4\u56de\u907f\u503e\u5411\u7684\u4e2a\u4f53\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u7684\u65b9\u5f0f\u6765\u76d1\u6d4b\u548c\u8bc4\u4f30\u6291\u90c1\u6c34\u5e73\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eCNN\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u6765\u8bc6\u522b\u7269\u7406\u6d3b\u52a8\u5e76\u5206\u7c7b\u7528\u6237\u60c5\u611f\uff1b\u4ece33\u540d\u53c2\u4e0e\u8005\u83b7\u53d6\u6570\u636e\uff0c\u63d0\u53d69\u4e2a\u76f8\u5173\u7279\u5f81\u5e76\u4e0e\u6bcf\u5468\u6291\u90c1\u8bc4\u5206\u8fdb\u884c\u5173\u8054\u5206\u6790\uff1b\u91c7\u7528\u652f\u6301\u5411\u91cf\u673a\u7b97\u6cd5\u5bf9\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u7269\u7406\u6d3b\u52a8\u8bc6\u522b\u51c6\u786e\u7387\u4e3a95%\uff0c\u60c5\u611f\u5206\u6790\u51c6\u786e\u7387\u4e3a95.6%\uff1b\u591a\u4e2a\u7269\u7406\u6d3b\u52a8\u7279\u5f81\u4e0e\u6291\u90c1\u75c7\u72b6\u7684\u4e25\u91cd\u7a0b\u5ea6\u663e\u8457\u76f8\u5173\uff1b\u652f\u6301\u5411\u91cf\u673a\u5728\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u523094%\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5355\u4e14\u6709\u6548\uff0c\u80fd\u591f\u5728\u4e0d\u4fb5\u72af\u4e2a\u4eba\u9690\u79c1\u7684\u60c5\u51b5\u4e0b\u957f\u671f\u7528\u4e8e\u6291\u90c1\u76d1\u6d4b\u3002"}}
{"id": "2505.22871", "pdf": "https://arxiv.org/pdf/2505.22871", "abs": "https://arxiv.org/abs/2505.22871", "authors": ["Yuval David", "Fabiana Fournier", "Lior Limonad", "Inna Skarbovsky"], "title": "The WHY in Business Processes: Unification of Causal Process Models", "categories": ["cs.AI"], "comment": "28 pages, 6 figures, BPM 2025 Forum", "summary": "Causal reasoning is essential for business process interventions and\nimprovement, requiring a clear understanding of causal relationships among\nactivity execution times in an event log. Recent work introduced a method for\ndiscovering causal process models but lacked the ability to capture alternating\ncausal conditions across multiple variants. This raises the challenges of\nhandling missing values and expressing the alternating conditions among log\nsplits when blending traces with varying activities.\n  We propose a novel method to unify multiple causal process variants into a\nconsistent model that preserves the correctness of the original causal models,\nwhile explicitly representing their causal-flow alternations. The method is\nformally defined, proved, evaluated on three open and two proprietary datasets,\nand released as an open-source implementation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5c06\u591a\u4e2a\u56e0\u679c\u6d41\u7a0b\u53d8\u4f53\u7edf\u4e00\u5230\u4e00\u4e2a\u4e00\u81f4\u7684\u6a21\u578b\u4e2d\uff0c\u8be5\u6a21\u578b\u4fdd\u7559\u4e86\u539f\u59cb\u56e0\u679c\u6a21\u578b\u7684\u6b63\u786e\u6027\uff0c\u5e76\u660e\u786e\u8868\u793a\u5176\u56e0\u679c\u6d41\u7684\u53d8\u5316\u3002\u6b64\u65b9\u6cd5\u5df2\u6b63\u5f0f\u5b9a\u4e49\u3001\u8bc1\u660e\uff0c\u5e76\u5728\u4e09\u4e2a\u516c\u5f00\u548c\u4e24\u4e2a\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u540c\u65f6\u4f5c\u4e3a\u5f00\u6e90\u5b9e\u73b0\u53d1\u5e03\u3002", "motivation": "\u5f53\u524d\u53d1\u73b0\u56e0\u679c\u6d41\u7a0b\u6a21\u578b\u7684\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u8de8\u591a\u4e2a\u53d8\u4f53\u7684\u4ea4\u66ff\u56e0\u679c\u6761\u4ef6\uff0c\u5904\u7406\u65e5\u5fd7\u5206\u5272\u4e2d\u7684\u7f3a\u5931\u503c\u548c\u8868\u8fbe\u4ea4\u66ff\u6761\u4ef6\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5c06\u591a\u4e2a\u56e0\u679c\u6d41\u7a0b\u53d8\u4f53\u7edf\u4e00\u5230\u4e00\u4e2a\u4e00\u81f4\u7684\u6a21\u578b\u4e2d\uff0c\u660e\u786e\u8868\u793a\u56e0\u679c\u6d41\u7684\u53d8\u5316\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u56e0\u679c\u6a21\u578b\u7684\u6b63\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u88ab\u6b63\u5f0f\u5b9a\u4e49\u3001\u8bc1\u660e\uff0c\u5e76\u5728\u4e09\u4e2a\u516c\u5f00\u548c\u4e24\u4e2a\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6210\u529f\u8bc4\u4f30\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u4ea4\u66ff\u56e0\u679c\u6761\u4ef6\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u56e0\u679c\u63a8\u7406\u548c\u4e1a\u52a1\u6d41\u7a0b\u6539\u8fdb\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2505.22928", "pdf": "https://arxiv.org/pdf/2505.22928", "abs": "https://arxiv.org/abs/2505.22928", "authors": ["Massimiliano Pronesti", "Michela Lorandi", "Paul Flanagan", "Oisin Redmon", "Anya Belz", "Yufang Hou"], "title": "Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Systematic reviews in medicine play a critical role in evidence-based\ndecision-making by aggregating findings from multiple studies. A central\nbottleneck in automating this process is extracting numeric evidence and\ndetermining study-level conclusions for specific outcomes and comparisons.\nPrior work has framed this problem as a textual inference task by retrieving\nrelevant content fragments and inferring conclusions from them. However, such\napproaches often rely on shallow textual cues and fail to capture the\nunderlying numeric reasoning behind expert assessments.\n  In this work, we conceptualise the problem as one of quantitative reasoning.\nRather than inferring conclusions from surface text, we extract structured\nnumerical evidence (e.g., event counts or standard deviations) and apply domain\nknowledge informed logic to derive outcome-specific conclusions. We develop a\nnumeric reasoning system composed of a numeric data extraction model and an\neffect estimate component, enabling more accurate and interpretable inference\naligned with the domain expert principles. We train the numeric data extraction\nmodel using different strategies, including supervised fine-tuning (SFT) and\nreinforcement learning (RL) with a new value reward model.\n  When evaluated on the CochraneForest benchmark, our best-performing approach\n-- using RL to train a small-scale number extraction model -- yields up to a\n21% absolute improvement in F1 score over retrieval-based systems and\noutperforms general-purpose LLMs of over 400B parameters by up to 9%. Our\nresults demonstrate the promise of reasoning-driven approaches for automating\nsystematic evidence synthesis.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u503c\u63a8\u7406\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u503c\u8bc1\u636e\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u903b\u8f91\u63a8\u5bfc\u51fa\u7279\u5b9a\u7ed3\u679c\u7684\u7ed3\u8bba\u3002\u8be5\u7cfb\u7edf\u7531\u6570\u503c\u6570\u636e\u63d0\u53d6\u6a21\u578b\u548c\u6548\u5e94\u4f30\u8ba1\u7ec4\u4ef6\u7ec4\u6210\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u5c0f\u89c4\u6a21\u6570\u503c\u63d0\u53d6\u6a21\u578b\u5728CochraneForest\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u8f83\u4e8e\u68c0\u7d22\u57fa\u7cfb\u7edfF1\u5206\u6570\u7edd\u5bf9\u63d0\u9ad8\u4e8621%\uff0c\u5e76\u8d85\u8d8a\u4e86\u5177\u6709400\u4ebf\u53c2\u6570\u7684\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b9%\u3002", "motivation": "\u76ee\u524d\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\u81ea\u52a8\u5316\u8fc7\u7a0b\u5b58\u5728\u74f6\u9888\uff0c\u4e3b\u8981\u5728\u4e8e\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u6570\u503c\u8bc1\u636e\u4ee5\u53ca\u786e\u5b9a\u7814\u7a76\u7ea7\u522b\u7684\u7ed3\u8bba\u65f6\uff0c\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6d45\u5c42\u6587\u672c\u7ebf\u7d22\uff0c\u672a\u80fd\u6355\u6349\u4e13\u5bb6\u8bc4\u4f30\u80cc\u540e\u7684\u6570\u503c\u63a8\u7406\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u95ee\u9898\u5b9a\u4e49\u4e3a\u5b9a\u91cf\u63a8\u7406\u4efb\u52a1\uff0c\u6784\u5efa\u4e00\u4e2a\u6570\u503c\u63a8\u7406\u7cfb\u7edf\uff0c\u5305\u542b\u6570\u503c\u6570\u636e\u63d0\u53d6\u6a21\u578b\u548c\u6548\u5e94\u4f30\u8ba1\u7ec4\u4ef6\u3002\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b49\u7b56\u7565\u8bad\u7ec3\u6570\u503c\u6570\u636e\u63d0\u53d6\u6a21\u578b\uff0c\u5229\u7528\u65b0\u7684\u4ef7\u503c\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728CochraneForest\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u5c0f\u89c4\u6a21\u6570\u503c\u63d0\u53d6\u6a21\u578b\u76f8\u8f83\u4e8e\u68c0\u7d22\u57fa\u7cfb\u7edfF1\u5206\u6570\u7edd\u5bf9\u63d0\u9ad8\u4e8621%\uff0c\u5e76\u4e14\u4f18\u4e8e\u8d85\u8fc7400\u4ebf\u53c2\u6570\u7684\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b9%\u3002", "conclusion": "\u57fa\u4e8e\u63a8\u7406\u9a71\u52a8\u7684\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u7cfb\u7edf\u6027\u8bc1\u636e\u7efc\u5408\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2505.22948", "pdf": "https://arxiv.org/pdf/2505.22948", "abs": "https://arxiv.org/abs/2505.22948", "authors": ["Michael Sun", "Weize Yuan", "Gang Liu", "Wojciech Matusik", "Jie Chen"], "title": "Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "Recent data-efficient molecular generation approaches exploit graph grammars\nto introduce interpretability into the generative models. However, grammar\nlearning therein relies on expert annotation or unreliable heuristics for\nalgorithmic inference. We propose Foundation Molecular Grammar (FMG), which\nleverages multi-modal foundation models (MMFMs) to induce an interpretable\nmolecular language. By exploiting the chemical knowledge of an MMFM, FMG\nrenders molecules as images, describes them as text, and aligns information\nacross modalities using prompt learning. FMG can be used as a drop-in\nreplacement for the prior grammar learning approaches in molecular generation\nand property prediction. We show that FMG not only excels in synthesizability,\ndiversity, and data efficiency but also offers built-in chemical\ninterpretability for automated molecular discovery workflows. Code is available\nat https://github.com/shiningsunnyday/induction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5FMG\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u8bed\u6cd5\u5b66\u4e60\u7684\u5206\u5b50\u751f\u6210\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u3001\u5408\u6210\u53ef\u884c\u6027\u3001\u591a\u6837\u6027\u548c\u6570\u636e\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u6570\u636e\u9ad8\u6548\u5206\u5b50\u751f\u6210\u65b9\u6cd5\u5229\u7528\u56fe\u8bed\u6cd5\u5f15\u5165\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u8bed\u6cd5\u5b66\u4e60\u4f9d\u8d56\u4e8e\u4e13\u5bb6\u6ce8\u91ca\u6216\u4e0d\u53ef\u9760\u7684\u7b97\u6cd5\u63a8\u65ad\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u7840\u5206\u5b50\u8bed\u6cd5\uff08FMG\uff09\uff0c\u5229\u7528\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff08MMFMs\uff09\u8bf1\u5bfc\u53ef\u89e3\u91ca\u7684\u5206\u5b50\u8bed\u8a00\uff0c\u901a\u8fc7\u63d0\u793a\u5b66\u4e60\u8de8\u6a21\u6001\u5bf9\u9f50\u4fe1\u606f\uff0c\u5c06\u5206\u5b50\u6e32\u67d3\u4e3a\u56fe\u50cf\u5e76\u4ee5\u6587\u672c\u63cf\u8ff0\u3002", "result": "FMG\u5728\u5408\u6210\u53ef\u884c\u6027\u3001\u591a\u6837\u6027\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e3a\u81ea\u52a8\u5206\u5b50\u53d1\u73b0\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u5185\u7f6e\u7684\u5316\u5b66\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "FMG\u53ef\u4ee5\u4f5c\u4e3a\u5206\u5b50\u751f\u6210\u548c\u6027\u8d28\u9884\u6d4b\u4e2d\u5148\u524d\u8bed\u6cd5\u5b66\u4e60\u65b9\u6cd5\u7684\u76f4\u63a5\u66ff\u4ee3\u54c1\u3002"}}
{"id": "2505.22781", "pdf": "https://arxiv.org/pdf/2505.22781", "abs": "https://arxiv.org/abs/2505.22781", "authors": ["Antonio Ocello", "Daniil Tiapkin", "Lorenzo Mancini", "Mathieu Lauri\u00e8re", "Eric Moulines"], "title": "Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel\nalgorithm designed to compute approximate Nash equilibria for ergodic\nMean-Field Games (MFG) in finite state-action spaces. Building on the\nwell-established performance of TRPO in the reinforcement learning (RL)\nsetting, we extend its methodology to the MFG framework, leveraging its\nstability and robustness in policy optimization. Under standard assumptions in\nthe MFG literature, we provide a rigorous analysis of MF-TRPO, establishing\ntheoretical guarantees on its convergence. Our results cover both the exact\nformulation of the algorithm and its sample-based counterpart, where we derive\nhigh-probability guarantees and finite sample complexity. This work advances\nMFG optimization by bridging RL techniques with mean-field decision-making,\noffering a theoretically grounded approach to solving complex multi-agent\nproblems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5MF-TRPO\uff0c\u7528\u4e8e\u8ba1\u7b97\u6709\u9650\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u5e73\u5747\u573a\u535a\u5f08\u7684\u8fd1\u4f3c\u7eb3\u4ec0\u5747\u8861\u3002\u8be5\u7b97\u6cd5\u57fa\u4e8eTRPO\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6210\u529f\u8868\u73b0\uff0c\u6269\u5c55\u4e86\u5176\u65b9\u6cd5\u8bba\u4ee5\u9002\u5e94\u5e73\u5747\u573a\u535a\u5f08\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u5c06\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u4e0e\u5e73\u5747\u573a\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u95ee\u9898\u3002\u901a\u8fc7\u5229\u7528TRPO\u7684\u7a33\u5b9a\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u4f18\u5316\u5e73\u5747\u573a\u535a\u5f08\u4e2d\u7684\u7b56\u7565\u3002", "method": "\u5f15\u5165MF-TRPO\u7b97\u6cd5\uff0c\u5728\u6709\u9650\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u5185\u8ba1\u7b97\u5e73\u5747\u573a\u535a\u5f08\u7684\u8fd1\u4f3c\u7eb3\u4ec0\u5747\u8861\u3002\u6269\u5c55\u4e86TRPO\u65b9\u6cd5\u81f3\u5e73\u5747\u573a\u535a\u5f08\u6846\u67b6\uff0c\u5e76\u5206\u6790\u5176\u6027\u80fd\u3002", "result": "\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\uff0c\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u5206\u6790\u548c\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u6db5\u76d6\u4e86\u7b97\u6cd5\u7684\u786e\u5207\u5f62\u5f0f\u53ca\u5176\u57fa\u4e8e\u6837\u672c\u7684\u5f62\u5f0f\uff0c\u5e76\u63a8\u5bfc\u51fa\u9ad8\u6982\u7387\u4fdd\u8bc1\u548c\u6709\u9650\u6837\u672c\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u548c\u5e73\u5747\u573a\u51b3\u7b56\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u591a\u667a\u80fd\u4f53\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u7406\u8bba\u4f9d\u636e\u5145\u5206\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.22954", "pdf": "https://arxiv.org/pdf/2505.22954", "abs": "https://arxiv.org/abs/2505.22954", "authors": ["Jenny Zhang", "Shengran Hu", "Cong Lu", "Robert Lange", "Jeff Clune"], "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "categories": ["cs.AI"], "comment": "Code at https://github.com/jennyzzt/dgm", "summary": "Today's AI systems have human-designed, fixed architectures and cannot\nautonomously and continuously improve themselves. The advance of AI could\nitself be automated. If done safely, that would accelerate AI development and\nallow us to reap its benefits much sooner. Meta-learning can automate the\ndiscovery of novel algorithms, but is limited by first-order improvements and\nthe human design of a suitable search space. The G\\\"odel machine proposed a\ntheoretical alternative: a self-improving AI that repeatedly modifies itself in\na provably beneficial manner. Unfortunately, proving that most changes are net\nbeneficial is impossible in practice. We introduce the Darwin G\\\"odel Machine\n(DGM), a self-improving system that iteratively modifies its own code (thereby\nalso improving its ability to modify its own codebase) and empirically\nvalidates each change using coding benchmarks. Inspired by Darwinian evolution\nand open-endedness research, the DGM maintains an archive of generated coding\nagents. It grows the archive by sampling an agent from it and using a\nfoundation model to create a new, interesting, version of the sampled agent.\nThis open-ended exploration forms a growing tree of diverse, high-quality\nagents and allows the parallel exploration of many different paths through the\nsearch space. Empirically, the DGM automatically improves its coding\ncapabilities (e.g., better code editing tools, long-context window management,\npeer-review mechanisms), increasing performance on SWE-bench from 20.0% to\n50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly\noutperforms baselines without self-improvement or open-ended exploration. All\nexperiments were done with safety precautions (e.g., sandboxing, human\noversight). The DGM is a significant step toward self-improving AI, capable of\ngathering its own stepping stones along paths that unfold into endless\ninnovation.", "AI": {"tldr": "\u5f15\u5165\u4e86\u8fbe\u5c14\u6587\u54e5\u5fb7\u5c14\u673a(DGM)\uff0c\u4e00\u79cd\u81ea\u6211\u6539\u8fdb\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u4fee\u6539\u81ea\u8eab\u4ee3\u7801\u5e76\u4f7f\u7528\u7f16\u7801\u57fa\u51c6\u6765\u9a8c\u8bc1\u6bcf\u4e2a\u66f4\u6539\u3002DGM\u53d7\u5230\u8fbe\u5c14\u6587\u8fdb\u5316\u8bba\u7684\u542f\u53d1\uff0c\u7ef4\u62a4\u751f\u6210\u7684\u7f16\u7801\u4ee3\u7406\u6863\u6848\uff0c\u5f62\u6210\u4e0d\u65ad\u589e\u957f\u7684\u9ad8\u8d28\u91cf\u4ee3\u7406\u6811\uff0c\u4ece\u800c\u81ea\u52a8\u63d0\u9ad8\u5176\u7f16\u7801\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660eDGM\u5728SWE-bench\u548cPolyglot\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5e76\u4f18\u4e8e\u6ca1\u6709\u81ea\u6211\u6539\u8fdb\u6216\u5f00\u653e\u63a2\u7d22\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5177\u6709\u4eba\u7c7b\u8bbe\u8ba1\u7684\u56fa\u5b9a\u67b6\u6784\uff0c\u65e0\u6cd5\u81ea\u4e3b\u8fde\u7eed\u6539\u8fdb\u3002\u81ea\u52a8\u5316AI\u8fdb\u6b65\u53ef\u4ee5\u52a0\u901fAI\u53d1\u5c55\u5e76\u8ba9\u6211\u4eec\u66f4\u65e9\u53d7\u76ca\u3002\u5c3d\u7ba1\u5143\u5b66\u4e60\u53ef\u4ee5\u81ea\u52a8\u5316\u53d1\u73b0\u65b0\u7b97\u6cd5\uff0c\u4f46\u53d7\u9650\u4e8e\u4e00\u9636\u6539\u8fdb\u548c\u4eba\u4e3a\u8bbe\u8ba1\u7684\u5408\u9002\u641c\u7d22\u7a7a\u95f4\u3002\u54e5\u5fb7\u5c14\u673a\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u8bc1\u660e\u5927\u591a\u6570\u66f4\u6539\u662f\u6709\u76ca\u7684\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002", "method": "DGM\u901a\u8fc7\u4ece\u5b58\u6863\u4e2d\u91c7\u6837\u4ee3\u7406\u5e76\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u521b\u5efa\u65b0\u7684\u3001\u6709\u8da3\u7684\u4ee3\u7406\u7248\u672c\u6765\u6269\u5c55\u5b58\u6863\u3002\u8fd9\u79cd\u5f00\u653e\u5f0f\u63a2\u7d22\u5f62\u6210\u4e86\u4e0d\u65ad\u589e\u957f\u7684\u9ad8\u8d28\u91cf\u4ee3\u7406\u6811\uff0c\u5141\u8bb8\u5e76\u884c\u63a2\u7d22\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u8bb8\u591a\u4e0d\u540c\u8def\u5f84\u3002DGM\u8fd8\u5bf9\u6bcf\u6b21\u66f4\u6539\u8fdb\u884c\u7ecf\u9a8c\u9a8c\u8bc1\u3002", "result": "DGM\u5728SWE-bench\u4e0a\u7684\u8868\u73b0\u4ece20.0%\u63d0\u5347\u523050.0%\uff0c\u5728Polyglot\u4e0a\u7684\u8868\u73b0\u4ece14.2%\u63d0\u5347\u523030.7%\u3002\u6b64\u5916\uff0cDGM\u663e\u8457\u4f18\u4e8e\u6ca1\u6709\u81ea\u6211\u6539\u8fdb\u6216\u5f00\u653e\u63a2\u7d22\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u6240\u6709\u5b9e\u9a8c\u90fd\u91c7\u53d6\u4e86\u5b89\u5168\u9884\u9632\u63aa\u65bd\uff08\u4f8b\u5982\u6c99\u76d2\u3001\u4eba\u5de5\u76d1\u7763\uff09\u3002", "conclusion": "DGM\u662f\u8fc8\u5411\u81ea\u6211\u6539\u8fdbAI\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u80fd\u591f\u6cbf\u7740\u5c55\u5f00\u4e3a\u65e0\u5c3d\u521b\u65b0\u7684\u8def\u5f84\u6536\u96c6\u81ea\u5df1\u7684\u57ab\u811a\u77f3\u3002"}}
{"id": "2505.22811", "pdf": "https://arxiv.org/pdf/2505.22811", "abs": "https://arxiv.org/abs/2505.22811", "authors": ["Ba-Hien Tran", "Van Minh Nguyen"], "title": "Highly Efficient and Effective LLMs with Multi-Boolean Architectures", "categories": ["stat.ML", "cs.LG"], "comment": "Under Review", "summary": "Weight binarization has emerged as a promising strategy to drastically reduce\nthe complexity of large language models (LLMs). It is mainly classified into\ntwo approaches: post-training binarization and finetuning with training-aware\nbinarization methods. The first approach, while having low complexity, leads to\nsignificant loss of information from the original LLMs, resulting in poor\nperformance. The second approach, on the other hand, relies heavily on\nfull-precision latent weights for gradient approximation of binary weights,\nwhich not only remains suboptimal but also introduces substantial complexity.\nIn this paper, we introduce a novel framework that effectively transforms LLMs\ninto multi-kernel Boolean parameters, for the first time, finetunes them\ndirectly in the Boolean domain, eliminating the need for expensive latent\nweights. This significantly reduces complexity during both finetuning and\ninference. Through extensive and insightful experiments across a wide range of\nLLMs, we demonstrate that our method outperforms recent ultra low-bit\nquantization and binarization methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u591a\u6838\u5e03\u5c14\u53c2\u6570\uff0c\u5e76\u9996\u6b21\u5728\u5e03\u5c14\u57df\u4e2d\u76f4\u63a5\u5fae\u8c03\uff0c\u51cf\u5c11\u4e86\u590d\u6742\u6027\u5e76\u4f18\u4e8e\u73b0\u6709\u7684\u4f4e\u6bd4\u7279\u91cf\u5316\u548c\u4e8c\u503c\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6743\u91cd\u4e8c\u503c\u5316\u65b9\u6cd5\u8981\u4e48\u5bfc\u81f4\u6027\u80fd\u5dee\uff08\u540e\u8bad\u7ec3\u4e8c\u503c\u5316\uff09\uff0c\u8981\u4e48\u590d\u6742\u5ea6\u9ad8\u4e14\u6548\u679c\u4e0d\u7406\u60f3\uff08\u8bad\u7ec3\u611f\u77e5\u4e8c\u503c\u5316\uff09\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u591a\u6838\u5e03\u5c14\u53c2\u6570\uff0c\u5e76\u5728\u5e03\u5c14\u57df\u4e2d\u76f4\u63a5\u5fae\u8c03\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u6f5c\u6743\u503c\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4f18\u4e8e\u6700\u8fd1\u7684\u8d85\u4f4e\u6bd4\u7279\u91cf\u5316\u548c\u4e8c\u503c\u5316\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5fae\u8c03\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u590d\u6742\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2505.22960", "pdf": "https://arxiv.org/pdf/2505.22960", "abs": "https://arxiv.org/abs/2505.22960", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "The remarkable growth in large language model (LLM) capabilities has spurred\nexploration into multi-agent systems, with debate frameworks emerging as a\npromising avenue for enhanced problem-solving. These multi-agent debate (MAD)\napproaches, where agents collaboratively present, critique, and refine\narguments, potentially offer improved reasoning, robustness, and diverse\nperspectives over monolithic models. Despite prior studies leveraging MAD, a\nsystematic understanding of its effectiveness compared to self-agent methods,\nparticularly under varying conditions, remains elusive. This paper seeks to\nfill this gap by conceptualizing MAD as a test-time computational scaling\ntechnique, distinguished by collaborative refinement and diverse exploration\ncapabilities. We conduct a comprehensive empirical investigation comparing MAD\nwith strong self-agent test-time scaling baselines on mathematical reasoning\nand safety-related tasks. Our study systematically examines the influence of\ntask difficulty, model scale, and agent diversity on MAD's performance. Key\nfindings reveal that, for mathematical reasoning, MAD offers limited advantages\nover self-agent scaling but becomes more effective with increased problem\ndifficulty and decreased model capability, while agent diversity shows little\nbenefit. Conversely, for safety tasks, MAD's collaborative refinement can\nincrease vulnerability, but incorporating diverse agent configurations\nfacilitates a gradual reduction in attack success through the collaborative\nrefinement process. We believe our findings provide critical guidance for the\nfuture development of more effective and strategically deployed MAD systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff08MAD\uff09\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u548c\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5728\u9ad8\u96be\u5ea6\u95ee\u9898\u6216\u6a21\u578b\u80fd\u529b\u8f83\u4f4e\u65f6\u66f4\u6709\u6548\uff0c\u4f46\u5728\u5b89\u5168\u6027\u4efb\u52a1\u4e2d\u9700\u6ce8\u610f\u591a\u6837\u6027\u548c\u534f\u4f5c\u4f18\u5316\u7684\u5e73\u8861\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u4e86\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff08MAD\uff09\u65b9\u6cd5\uff0c\u4f46\u5bf9\u5176\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u7279\u522b\u662f\u4e0e\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u76f8\u6bd4\u3002", "method": "\u5c06MAD\u89c6\u4e3a\u4e00\u79cd\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\uff0c\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83MAD\u4e0e\u5f3a\u5927\u7684\u5355\u667a\u80fd\u4f53\u6d4b\u8bd5\u65f6\u6269\u5c55\u57fa\u7ebf\u5728\u6570\u5b66\u63a8\u7406\u548c\u5b89\u5168\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7cfb\u7edf\u5206\u6790\u4efb\u52a1\u96be\u5ea6\u3001\u6a21\u578b\u89c4\u6a21\u548c\u667a\u80fd\u4f53\u591a\u6837\u6027\u5bf9MAD\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\uff0cMAD\u76f8\u8f83\u4e8e\u5355\u667a\u80fd\u4f53\u6269\u5c55\u4f18\u52bf\u6709\u9650\uff0c\u4f46\u968f\u7740\u95ee\u9898\u96be\u5ea6\u589e\u52a0\u548c\u6a21\u578b\u80fd\u529b\u4e0b\u964d\uff0c\u5176\u6548\u679c\u66f4\u4e3a\u663e\u8457\uff0c\u800c\u667a\u80fd\u4f53\u591a\u6837\u6027\u5f71\u54cd\u8f83\u5c0f\u3002\u5728\u5b89\u5168\u4efb\u52a1\u4e2d\uff0cMAD\u7684\u534f\u4f5c\u4f18\u5316\u53ef\u80fd\u589e\u52a0\u6f0f\u6d1e\uff0c\u4f46\u901a\u8fc7\u5f15\u5165\u591a\u6837\u5316\u7684\u667a\u80fd\u4f53\u914d\u7f6e\uff0c\u53ef\u4ee5\u9010\u6b65\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u672a\u6765\u66f4\u9ad8\u6548\u548c\u66f4\u6709\u7b56\u7565\u5730\u90e8\u7f72MAD\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u4efb\u52a1\u6761\u4ef6\u4e0b\u5408\u7406\u5229\u7528MAD\u7279\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2505.22997", "pdf": "https://arxiv.org/pdf/2505.22997", "abs": "https://arxiv.org/abs/2505.22997", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Bruce Wade"], "title": "Theoretical Foundations of the Deep Copula Classifier: A Generative Approach to Modeling Dependent Features", "categories": ["stat.ML", "cs.LG", "62H30, 68T07, 62C12, 62G05"], "comment": "Submitted", "summary": "Traditional classifiers often assume feature independence or rely on overly\nsimplistic relationships, leading to poor performance in settings where\nreal-world dependencies matter. We introduce the Deep Copula Classifier (DCC),\na generative model that separates the learning of each feature's marginal\ndistribution from the modeling of their joint dependence structure via neural\nnetwork-parameterized copulas. For each class, lightweight neural networks are\nused to flexibly and adaptively capture feature interactions, making DCC\nparticularly effective when classification is driven by complex dependencies.\nWe establish that DCC converges to the Bayes-optimal classifier under standard\nconditions and provide explicit convergence rates of O(n^{-r/(2r + d)}) for\nr-smooth copula densities. Beyond theoretical guarantees, we outline several\npractical extensions, including high-dimensional scalability through vine and\nfactor copula architectures, semi-supervised learning via entropy\nregularization, and online adaptation using streaming gradient methods. By\nunifying statistical rigor with the representational power of neural networks,\nDCC offers a mathematically grounded and interpretable framework for\ndependency-aware classification.", "AI": {"tldr": "\u751f\u6210\u4e00\u4e2a\u592a\u957f\uff1b\u6ca1\u8bfb\u7684\u603b\u7ed3", "motivation": "\u63cf\u8ff0\u672c\u6587\u4e2d\u7684\u52a8\u673a", "method": "\u672c\u6587\u7684\u65b9\u6cd5", "result": "\u672c\u6587\u7684\u7ed3\u679c", "conclusion": "\u672c\u6587\u7684\u7ed3\u8bba"}}
{"id": "2505.22987", "pdf": "https://arxiv.org/pdf/2505.22987", "abs": "https://arxiv.org/abs/2505.22987", "authors": ["Nick Byrd"], "title": "Strategic Reflectivism In Intelligent Systems", "categories": ["cs.AI", "cs.HC", "econ.TH", "C.1.3; I.2.0; I.2.8; I.2.11"], "comment": "An earlier version of this paper was presented at the 2025 ACM\n  Workshop on Human-AI Interaction for Augmented Reasoning\n  (CHI25-WS-AUGMENTED-REASONING). Permission to copy for educational use is\n  granted, provided copies are not for sale or profit and include this notice\n  and full citation on the first page. Other uses require the author permission", "summary": "By late 20th century, the rationality wars had launched debates about the\nnature and norms of intuitive and reflective thinking. Those debates drew from\nmid-20th century ideas such as bounded rationality, which challenged more\nidealized notions of rationality observed since the 19th century. Now that 21st\ncentury cognitive scientists are applying the resulting dual process theories\nto artificial intelligence, it is time to dust off some lessons from this\nhistory. So this paper synthesizes old ideas with recent results from\nexperiments on humans and machines. The result is Strategic Reflectivism, which\ntakes the position that one key to intelligent systems (human or artificial) is\npragmatic switching between intuitive and reflective inference to optimally\nfulfill competing goals. Strategic Reflectivism builds on American Pragmatism,\ntranscends superficial indicators of reflective thinking such as model size or\nchains of thought, and becomes increasingly actionable as we learn more about\nthe value of intuition and reflection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u6218\u7565\u53cd\u601d\u4e3b\u4e49\uff08Strategic Reflectivism\uff09\uff0c\u4e3b\u5f20\u667a\u80fd\u7cfb\u7edf\u7684\u5173\u952e\u5728\u4e8e\u5b9e\u7528\u5730\u5728\u76f4\u89c9\u548c\u53cd\u601d\u63a8\u7406\u4e4b\u95f4\u5207\u6362\u4ee5\u6700\u4f73\u5b9e\u73b0\u7ade\u4e89\u76ee\u6807\u3002\u5b83\u57fa\u4e8e\u7f8e\u56fd\u5b9e\u7528\u4e3b\u4e49\uff0c\u8d85\u8d8a\u4e86\u5982\u6a21\u578b\u5927\u5c0f\u6216\u601d\u7ef4\u94fe\u7b49\u53cd\u601d\u601d\u8003\u7684\u8868\u9762\u6307\u6807\uff0c\u5e76\u968f\u7740\u6211\u4eec\u5bf9\u76f4\u89c9\u548c\u53cd\u601d\u4ef7\u503c\u7684\u66f4\u591a\u4e86\u89e3\u800c\u53d8\u5f97\u8d8a\u6765\u8d8a\u53ef\u884c\u3002", "motivation": "20\u4e16\u7eaa\u672b\uff0c\u5173\u4e8e\u76f4\u89c2\u548c\u53cd\u601d\u601d\u7ef4\u7684\u672c\u8d28\u548c\u89c4\u8303\u7684\u7406\u6027\u4e4b\u4e89\u5f15\u53d1\u4e86\u8bf8\u591a\u8fa9\u8bba\uff0c\u8fd9\u4e9b\u8fa9\u8bba\u6e90\u4e8e20\u4e16\u7eaa\u4e2d\u671f\u7684\u601d\u60f3\uff0c\u4f8b\u5982\u6709\u9650\u7406\u6027\uff0c\u6311\u6218\u4e86\u81ea19\u4e16\u7eaa\u4ee5\u6765\u88ab\u7406\u60f3\u5316\u7684\u7406\u6027\u6982\u5ff5\u3002\u5982\u4eca\uff0c21\u4e16\u7eaa\u7684\u8ba4\u77e5\u79d1\u5b66\u5bb6\u6b63\u5728\u5c06\u7531\u6b64\u4ea7\u751f\u7684\u53cc\u91cd\u8fc7\u7a0b\u7406\u8bba\u5e94\u7528\u4e8e\u4eba\u5de5\u667a\u80fd\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u91cd\u65b0\u5ba1\u89c6\u5386\u53f2\u4e2d\u7684\u6559\u8bad\u3002", "method": "\u672c\u8bba\u6587\u7efc\u5408\u4e86\u65e7\u6709\u601d\u60f3\u4e0e\u8fd1\u671f\u4eba\u7c7b\u548c\u673a\u5668\u5b9e\u9a8c\u7684\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u6218\u7565\u53cd\u601d\u4e3b\u4e49\u3002", "result": "\u7ed3\u679c\u662f\u6218\u7565\u53cd\u601d\u4e3b\u4e49\uff0c\u8ba4\u4e3a\u667a\u80fd\u7cfb\u7edf\uff08\u65e0\u8bba\u662f\u4eba\u7c7b\u8fd8\u662f\u4eba\u5de5\uff09\u7684\u4e00\u4e2a\u5173\u952e\u662f\u5b9e\u7528\u5730\u5728\u76f4\u89c9\u548c\u53cd\u601d\u63a8\u65ad\u4e4b\u95f4\u5207\u6362\uff0c\u4ee5\u6700\u4f73\u5b9e\u73b0\u7ade\u4e89\u76ee\u6807\u3002", "conclusion": "\u6218\u7565\u53cd\u601d\u4e3b\u4e49\u57fa\u4e8e\u7f8e\u56fd\u5b9e\u7528\u4e3b\u4e49\uff0c\u8d85\u8d8a\u4e86\u53cd\u601d\u6027\u601d\u7ef4\u7684\u8868\u9762\u6307\u6807\uff0c\u5982\u6a21\u578b\u89c4\u6a21\u6216\u601d\u7ef4\u94fe\uff0c\u5e76\u968f\u7740\u6211\u4eec\u5bf9\u76f4\u89c9\u548c\u53cd\u601d\u7684\u4ef7\u503c\u4e86\u89e3\u7684\u589e\u52a0\u800c\u53d8\u5f97\u8d8a\u6765\u8d8a\u53ef\u884c\u3002"}}
{"id": "2505.23196", "pdf": "https://arxiv.org/pdf/2505.23196", "abs": "https://arxiv.org/abs/2505.23196", "authors": ["Eshant English", "Christoph Lippert"], "title": "JAPAN: Joint Adaptive Prediction Areas with Normalising-Flows", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conformal prediction provides a model-agnostic framework for uncertainty\nquantification with finite-sample validity guarantees, making it an attractive\ntool for constructing reliable prediction sets. However, existing approaches\ncommonly rely on residual-based conformity scores, which impose geometric\nconstraints and struggle when the underlying distribution is multimodal. In\nparticular, they tend to produce overly conservative prediction areas centred\naround the mean, often failing to capture the true shape of complex predictive\ndistributions. In this work, we introduce JAPAN (Joint Adaptive Prediction\nAreas with Normalising-Flows), a conformal prediction framework that uses\ndensity-based conformity scores. By leveraging flow-based models, JAPAN\nestimates the (predictive) density and constructs prediction areas by\nthresholding on the estimated density scores, enabling compact, potentially\ndisjoint, and context-adaptive regions that retain finite-sample coverage\nguarantees. We theoretically motivate the efficiency of JAPAN and empirically\nvalidate it across multivariate regression and forecasting tasks, demonstrating\ngood calibration and tighter prediction areas compared to existing baselines.\nWe also provide several \\emph{extensions} adding flexibility to our proposed\nframework.", "AI": {"tldr": "JAPAN\u662f\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6\u7684\u7b26\u5408\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u6a21\u578b\u4f30\u8ba1\u9884\u6d4b\u5bc6\u5ea6\u5e76\u6784\u5efa\u9884\u6d4b\u533a\u57df\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u7d27\u51d1\u3001\u9002\u5e94\u6027\u5f3a\u4e14\u4fdd\u6301\u6709\u9650\u6837\u672c\u8986\u76d6\u7387\u4fdd\u8bc1\u7684\u9884\u6d4b\u533a\u57df\u3002", "motivation": "\u73b0\u6709\u7684\u7b26\u5408\u6027\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u6b8b\u5dee\u9a71\u52a8\u7684\u7b26\u5408\u6027\u8bc4\u5206\uff0c\u96be\u4ee5\u5904\u7406\u591a\u6a21\u6001\u5206\u5e03\uff0c\u5e76\u503e\u5411\u4e8e\u751f\u6210\u8fc7\u4e8e\u4fdd\u5b88\u4e14\u56f4\u7ed5\u5747\u503c\u7684\u9884\u6d4b\u533a\u57df\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u9884\u6d4b\u5206\u5e03\u7684\u771f\u5b9e\u5f62\u72b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJAPAN\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u5bc6\u5ea6\u7684\u7b26\u5408\u6027\u8bc4\u5206\uff0c\u901a\u8fc7\u6d41\u6a21\u578b\u4f30\u8ba1\u9884\u6d4b\u5bc6\u5ea6\uff0c\u5e76\u6839\u636e\u4f30\u8ba1\u7684\u5bc6\u5ea6\u8bc4\u5206\u6784\u5efa\u9884\u6d4b\u533a\u57df\uff0c\u4ece\u800c\u5b9e\u73b0\u7d27\u51d1\u3001\u53ef\u80fd\u4e0d\u76f8\u8fde\u4e14\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u7684\u9884\u6d4b\u533a\u57df\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86JAPAN\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u591a\u53d8\u91cf\u56de\u5f52\u548c\u9884\u6d4b\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u663e\u793a\u5176\u6821\u51c6\u826f\u597d\u4e14\u9884\u6d4b\u533a\u57df\u66f4\u7d27\u81f4\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u8fd8\u63d0\u4f9b\u4e86\u589e\u52a0\u6846\u67b6\u7075\u6d3b\u6027\u7684\u6269\u5c55\u3002", "conclusion": "JAPAN\u4e3a\u7b26\u5408\u6027\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u5408\u5904\u7406\u590d\u6742\u548c\u591a\u6a21\u6001\u5206\u5e03\u7684\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u6709\u9650\u6837\u672c\u8986\u76d6\u7387\u7684\u4fdd\u8bc1\u3002"}}
{"id": "2505.22990", "pdf": "https://arxiv.org/pdf/2505.22990", "abs": "https://arxiv.org/abs/2505.22990", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "categories": ["cs.AI", "cs.ET", "cs.LG"], "comment": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "summary": "RF/Analog design is essential for bridging digital technologies with\nreal-world signals, ensuring the functionality and reliability of a wide range\nof electronic systems. However, analog design procedures are often intricate,\ntime-consuming and reliant on expert intuition, and hinder the time and cost\nefficiency of circuit development. To overcome the limitations of the manual\ncircuit design, we introduce MenTeR - a multiagent workflow integrated into an\nend-to-end analog design framework. By employing multiple specialized AI agents\nthat collaboratively address different aspects of the design process, such as\nspecification understanding, circuit optimization, and test bench validation,\nMenTeR reduces the dependency on frequent trial-and-error-style intervention.\nMenTeR not only accelerates the design cycle time but also facilitates a\nbroader exploration of the design space, demonstrating robust capabilities in\nhandling real-world analog systems. We believe that MenTeR lays the groundwork\nfor future \"RF/Analog Copilots\" that can collaborate seamlessly with human\ndesigners.", "AI": {"tldr": "\u5f00\u53d1\u4e86MenTeR\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6846\u67b6\uff0c\u7528\u4e8e\u7aef\u5230\u7aef\u6a21\u62df\u8bbe\u8ba1\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u52a0\u901f\u8bbe\u8ba1\u5468\u671f\uff0c\u5e76\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u8bbe\u8ba1\u7a7a\u95f4\u3002", "motivation": "\u6a21\u62df\u8bbe\u8ba1\u6d41\u7a0b\u590d\u6742\u3001\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u5bb6\u76f4\u89c9\uff0c\u5f71\u54cd\u7535\u8def\u5f00\u53d1\u7684\u65f6\u95f4\u548c\u6210\u672c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u591a\u4e2a\u4e13\u95e8\u7684AI\u4ee3\u7406\uff0c\u534f\u4f5c\u5904\u7406\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u4e0d\u540c\u65b9\u9762\uff08\u5982\u89c4\u8303\u7406\u89e3\u3001\u7535\u8def\u4f18\u5316\u548c\u6d4b\u8bd5\u5e73\u53f0\u9a8c\u8bc1\uff09\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u9891\u7e41\u8bd5\u9519\u5e72\u9884\u7684\u4f9d\u8d56\u3002", "result": "MenTeR\u4e0d\u4ec5\u52a0\u5feb\u4e86\u8bbe\u8ba1\u5468\u671f\u65f6\u95f4\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u66f4\u5e7f\u6cdb\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u7684\u6a21\u62df\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u80fd\u529b\u3002", "conclusion": "MenTeR\u4e3a\u672a\u6765\u7684\u201cRF/Analog Copilots\u201d\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u53ef\u4ee5\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u5e08\u65e0\u7f1d\u534f\u4f5c\u3002"}}
{"id": "2505.23260", "pdf": "https://arxiv.org/pdf/2505.23260", "abs": "https://arxiv.org/abs/2505.23260", "authors": ["Budhaditya Halder", "Shubhayan Pan", "Koulik Khamaru"], "title": "Stable Thompson Sampling: Valid Inference via Variance Inflation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We consider the problem of statistical inference when the data is collected\nvia a Thompson Sampling-type algorithm. While Thompson Sampling (TS) is known\nto be both asymptotically optimal and empirically effective, its adaptive\nsampling scheme poses challenges for constructing confidence intervals for\nmodel parameters. We propose and analyze a variant of TS, called Stable\nThompson Sampling, in which the posterior variance is inflated by a logarithmic\nfactor. We show that this modification leads to asymptotically normal estimates\nof the arm means, despite the non-i.i.d. nature of the data. Importantly, this\nstatistical benefit comes at a modest cost: the variance inflation increases\nregret by only a logarithmic factor compared to standard TS. Our results reveal\na principled trade-off: by paying a small price in regret, one can enable valid\nstatistical inference for adaptive decision-making algorithms.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStable Thompson Sampling\u7684\u7b97\u6cd5\u53d8\u4f53\uff0c\u901a\u8fc7\u589e\u52a0\u540e\u9a8c\u65b9\u5dee\u7684\u5bf9\u6570\u56e0\u5b50\uff0c\u5728\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6807\u51c6Thompson Sampling\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u5f97\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0b\u4ecd\u80fd\u83b7\u5f97\u6e10\u8fd1\u6b63\u6001\u4f30\u8ba1\uff0c\u5e76\u4e3a\u6a21\u578b\u53c2\u6570\u6784\u5efa\u7f6e\u4fe1\u533a\u95f4\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684Thompson Sampling\u7b97\u6cd5\u5c3d\u7ba1\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u5176\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\uff0c\u4e3a\u6a21\u578b\u53c2\u6570\u6784\u5efa\u7f6e\u4fe1\u533a\u95f4\u5e26\u6765\u4e86\u6311\u6218\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u7b97\u6cd5\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStable Thompson Sampling\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u540e\u9a8c\u65b9\u5dee\u589e\u52a0\u4e00\u4e2a\u5bf9\u6570\u56e0\u5b50\uff0c\u89e3\u51b3\u4e86\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0b\u7684\u7edf\u8ba1\u63a8\u65ad\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u4e86\u81c2\u5747\u503c\u7684\u6e10\u8fd1\u6b63\u6001\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cStable Thompson Sampling\u5728\u53ea\u589e\u52a0\u5bf9\u6570\u7ea7\u522b\u7684\u9057\u61be\uff08regret\uff09\u4ee3\u4ef7\u4e0b\uff0c\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u5e76\u4e14\u4e0e\u6807\u51c6Thompson Sampling\u76f8\u6bd4\u6027\u80fd\u4e0b\u964d\u5f88\u5c0f\u3002", "conclusion": "\u901a\u8fc7\u9002\u5ea6\u589e\u52a0\u9057\u61be\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u63ed\u793a\u4e86\u5728\u9057\u61be\u548c\u7edf\u8ba1\u63a8\u65ad\u6709\u6548\u6027\u4e4b\u95f4\u7684\u4e00\u79cd\u6743\u8861\u539f\u5219\u3002"}}
{"id": "2505.23034", "pdf": "https://arxiv.org/pdf/2505.23034", "abs": "https://arxiv.org/abs/2505.23034", "authors": ["Guangyi Liu", "Yongqi Zhang", "Xunyuan Liu", "Quanming Yao"], "title": "Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Drug-drug interaction (DDI) prediction is critical for treatment safety.\nWhile large language models (LLMs) show promise in pharmaceutical tasks, their\neffectiveness in DDI prediction remains challenging. Inspired by the\nwell-established clinical practice where physicians routinely reference similar\nhistorical cases to guide their decisions through case-based reasoning (CBR),\nwe propose CBR-DDI, a novel framework that distills pharmacological principles\nfrom historical cases to improve LLM reasoning for DDI tasks. CBR-DDI\nconstructs a knowledge repository by leveraging LLMs to extract pharmacological\ninsights and graph neural networks (GNNs) to model drug associations. A hybrid\nretrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs to\neffectively retrieve and reuse relevant cases. We further introduce a\nrepresentative sampling strategy for dynamic case refinement. Extensive\nexperiments demonstrate that CBR-DDI achieves state-of-the-art performance,\nwith a significant 28.7% accuracy improvement over both popular LLMs and CBR\nbaseline, while maintaining high interpretability and flexibility.", "AI": {"tldr": "\u63d0\u51faCBR-DDI\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u6848\u4f8b\u63a8\u7406\u63d0\u9ad8\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e8628.7%\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u836f\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002\u53d7\u4e34\u5e8a\u533b\u751f\u57fa\u4e8e\u6848\u4f8b\u63a8\u7406\u5b9e\u8df5\u7684\u542f\u53d1\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u6784\u5efaCBR-DDI\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u836f\u7406\u5b66\u89c1\u89e3\uff0c\u5e76\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u836f\u7269\u5173\u8054\uff0c\u521b\u5efa\u77e5\u8bc6\u5e93\u3002\u91c7\u7528\u6df7\u5408\u68c0\u7d22\u673a\u5236\u548c\u53cc\u5c42\u77e5\u8bc6\u589e\u5f3a\u63d0\u793a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6548\u68c0\u7d22\u548c\u590d\u7528\u76f8\u5173\u6848\u4f8b\uff0c\u540c\u65f6\u5f15\u5165\u4ee3\u8868\u6027\u91c7\u6837\u7b56\u7565\u8fdb\u884c\u52a8\u6001\u6848\u4f8b\u4f18\u5316\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCBR-DDI\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u76f8\u8f83\u4e8e\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6848\u4f8b\u63a8\u7406\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e8628.7%\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "CBR-DDI\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2505.23445", "pdf": "https://arxiv.org/pdf/2505.23445", "abs": "https://arxiv.org/abs/2505.23445", "authors": ["Adrien Majka", "El-Mahdi El-Mhamdi"], "title": "The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "32 pages, 1 figure", "summary": "Goodhart's law is a famous adage in policy-making that states that ``When a\nmeasure becomes a target, it ceases to be a good measure''. As machine learning\nmodels and the optimisation capacity to train them grow, growing empirical\nevidence reinforced the belief in the validity of this law without however\nbeing formalised. Recently, a few attempts were made to formalise Goodhart's\nlaw, either by categorising variants of it, or by looking at how optimising a\nproxy metric affects the optimisation of an intended goal. In this work, we\nalleviate the simplifying independence assumption, made in previous works, and\nthe assumption on the learning paradigm made in most of them, to study the\neffect of the coupling between the proxy metric and the intended goal on\nGoodhart's law. Our results show that in the case of light tailed goal and\nlight tailed discrepancy, dependence does not change the nature of Goodhart's\neffect. However, in the light tailed goal and heavy tailed discrepancy case, we\nexhibit an example where over-optimisation occurs at a rate inversely\nproportional to the heavy tailedness of the discrepancy between the goal and\nthe metric. %", "AI": {"tldr": "\u7814\u7a76\u4e86\u4ee3\u7406\u6307\u6807\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u8026\u5408\u5bf9Goodhart\u5b9a\u5f8b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8f7b\u5c3e\u76ee\u6807\u4e0e\u91cd\u5c3e\u5dee\u5f02\u60c5\u51b5\u4e0b\uff0c\u8fc7\u5ea6\u4f18\u5316\u4e0e\u5dee\u5f02\u7684\u91cd\u5c3e\u6027\u6210\u53cd\u6bd4\u3002", "motivation": "\u4e4b\u524d\u7684\u5de5\u4f5c\u4e2d\u5bf9\u4e8eGoodhart\u5b9a\u5f8b\u7684\u5f62\u5f0f\u5316\u7814\u7a76\u901a\u5e38\u57fa\u4e8e\u7b80\u5316\u7684\u72ec\u7acb\u6027\u5047\u8bbe\u548c\u5b66\u4e60\u8303\u5f0f\u5047\u8bbe\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7f13\u89e3\u8fd9\u4e9b\u5047\u8bbe\u4ee5\u66f4\u6df1\u5165\u5730\u63a2\u8ba8\u4ee3\u7406\u6307\u6807\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u53bb\u9664\u5148\u524d\u5de5\u4f5c\u4e2d\u7684\u72ec\u7acb\u6027\u5047\u8bbe\u548c\u5b66\u4e60\u8303\u5f0f\u5047\u8bbe\uff0c\u5206\u6790\u4ee3\u7406\u6307\u6807\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u8026\u5408\u5bf9Goodhart\u5b9a\u5f8b\u7684\u5f71\u54cd\u3002", "result": "\u5728\u8f7b\u5c3e\u76ee\u6807\u548c\u8f7b\u5c3e\u5dee\u5f02\u7684\u60c5\u51b5\u4e0b\uff0c\u4f9d\u8d56\u6027\u4e0d\u4f1a\u6539\u53d8Goodhart\u6548\u5e94\u7684\u672c\u8d28\uff1b\u4f46\u5728\u8f7b\u5c3e\u76ee\u6807\u548c\u91cd\u5c3e\u5dee\u5f02\u7684\u60c5\u51b5\u4e0b\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5176\u4e2d\u8fc7\u5ea6\u4f18\u5316\u7684\u53d1\u751f\u7387\u4e0e\u76ee\u6807\u548c\u5ea6\u91cf\u4e4b\u95f4\u5dee\u5f02\u7684\u91cd\u5c3e\u6027\u6210\u53cd\u6bd4\u3002", "conclusion": "\u4ee3\u7406\u6307\u6807\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u8026\u5408\u4f1a\u5f71\u54cdGoodhart\u5b9a\u5f8b\u7684\u8868\u73b0\u5f62\u5f0f\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08\u5982\u8f7b\u5c3e\u76ee\u6807\u548c\u91cd\u5c3e\u5dee\u5f02\uff09\uff0c\u8fc7\u5ea6\u4f18\u5316\u7684\u7a0b\u5ea6\u4e0e\u5dee\u5f02\u7684\u91cd\u5c3e\u6027\u76f8\u5173\u3002"}}
{"id": "2505.23058", "pdf": "https://arxiv.org/pdf/2505.23058", "abs": "https://arxiv.org/abs/2505.23058", "authors": ["Yutong Xie", "Zhuoheng Li", "Xiyuan Wang", "Yijun Pan", "Qijia Liu", "Xingzhi Cui", "Kuang-Yu Lo", "Ruoyi Gao", "Xingjian Zhang", "Jin Huang", "Walter Yuan", "Matthew O. Jackson", "Qiaozhu Mei"], "title": "Be.FM: Open Foundation Models for Human Behavior", "categories": ["cs.AI", "cs.CE", "cs.CL"], "comment": null, "summary": "Despite their success in numerous fields, the potential of foundation models\nfor modeling and understanding human behavior remains largely unexplored. We\nintroduce Be.FM, one of the first open foundation models designed for human\nbehavior modeling. Built upon open-source large language models and fine-tuned\non a diverse range of behavioral data, Be.FM can be used to understand and\npredict human decision-making. We construct a comprehensive set of benchmark\ntasks for testing the capabilities of behavioral foundation models. Our results\ndemonstrate that Be.FM can predict behaviors, infer characteristics of\nindividuals and populations, generate insights about contexts, and apply\nbehavioral science knowledge.", "AI": {"tldr": "\u5c3d\u7ba1\u57fa\u7840\u6a21\u578b\u5728\u8bb8\u591a\u9886\u57df\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u5728\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u548c\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\u3002\u6211\u4eec\u5f15\u5165\u4e86Be.FM\uff0c\u8fd9\u662f\u6700\u65e9\u516c\u5f00\u7684\u57fa\u7840\u6a21\u578b\u4e4b\u4e00\uff0c\u65e8\u5728\u5bf9\u4eba\u7c7b\u884c\u4e3a\u8fdb\u884c\u5efa\u6a21\u3002\u57fa\u4e8e\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684\u884c\u4e3a\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0cBe.FM\u53ef\u7528\u4e8e\u7406\u89e3\u548c\u9884\u6d4b\u4eba\u7c7b\u51b3\u7b56\u3002\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u5957\u5168\u9762\u7684\u57fa\u51c6\u4efb\u52a1\u6765\u6d4b\u8bd5\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u7684\u80fd\u529b\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0cBe.FM\u53ef\u4ee5\u9884\u6d4b\u884c\u4e3a\uff0c\u63a8\u65ad\u4e2a\u4eba\u548c\u7fa4\u4f53\u7684\u7279\u5f81\uff0c\u751f\u6210\u5173\u4e8e\u80cc\u666f\u7684\u89c1\u89e3\uff0c\u5e76\u5e94\u7528\u884c\u4e3a\u79d1\u5b66\u77e5\u8bc6\u3002", "motivation": "\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u5728\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u548c\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u56e0\u4e3a\u8fd9\u4e00\u9886\u57df\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165\u540d\u4e3aBe.FM\u7684\u5f00\u653e\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684\u884c\u4e3a\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u540c\u65f6\u6784\u5efa\u4e86\u4e00\u5957\u5168\u9762\u7684\u57fa\u51c6\u4efb\u52a1\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u80fd\u529b\u3002", "result": "Be.FM\u80fd\u591f\u9884\u6d4b\u884c\u4e3a\u3001\u63a8\u65ad\u4e2a\u4eba\u548c\u7fa4\u4f53\u7279\u5f81\u3001\u751f\u6210\u80cc\u666f\u89c1\u89e3\u5e76\u5e94\u7528\u884c\u4e3a\u79d1\u5b66\u77e5\u8bc6\u3002", "conclusion": "Be.FM\u662f\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u57fa\u7840\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.23557", "pdf": "https://arxiv.org/pdf/2505.23557", "abs": "https://arxiv.org/abs/2505.23557", "authors": ["Marc Jourdan", "Gizem Y\u00fcce", "Nicolas Flammarion"], "title": "Learning Parametric Distributions from Samples and Preferences", "categories": ["stat.ML", "cs.LG"], "comment": "28 pages, 8 figures. To be published in the Forty-Second\n  International Conference on Machine Learning", "summary": "Recent advances in language modeling have underscored the role of preference\nfeedback in enhancing model performance. This paper investigates the conditions\nunder which preference feedback improves parameter estimation in classes of\ncontinuous parametric distributions. In our framework, the learner observes\npairs of samples from an unknown distribution along with their relative\npreferences depending on the same unknown parameter. We show that\npreference-based M-estimators achieve a better asymptotic variance than\nsample-only M-estimators, further improved by deterministic preferences.\nLeveraging the hard constraints revealed by deterministic preferences, we\npropose an estimator achieving an estimation error scaling of\n$\\mathcal{O}(1/n)$ -- a significant improvement over the $\\Theta(1/\\sqrt{n})$\nrate attainable with samples alone. Next, we establish a lower bound that\nmatches this accelerated rate; up to dimension and problem-dependent constants.\nWhile the assumptions underpinning our analysis are restrictive, they are\nsatisfied by notable cases such as Gaussian or Laplace distributions for\npreferences based on the log-probability reward.", "AI": {"tldr": "\u8fd1\u671f\u5728\u8bed\u8a00\u5efa\u6a21\u65b9\u9762\u7684\u8fdb\u5c55\u5f3a\u8c03\u4e86\u504f\u597d\u53cd\u9988\u5728\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u65b9\u9762\u7684\u4f5c\u7528\u3002\u672c\u6587\u7814\u7a76\u4e86\u5728\u8fde\u7eed\u53c2\u6570\u5206\u5e03\u4e2d\uff0c\u504f\u597d\u53cd\u9988\u5982\u4f55\u6539\u5584\u53c2\u6570\u4f30\u8ba1\u7684\u6761\u4ef6\u3002\u901a\u8fc7\u89c2\u5bdf\u6765\u81ea\u672a\u77e5\u5206\u5e03\u7684\u6837\u672c\u5bf9\u53ca\u5176\u76f8\u5bf9\u504f\u597d\uff0c\u6211\u4eec\u53d1\u73b0\u57fa\u4e8e\u504f\u597d\u7684M-\u4f30\u8ba1\u91cf\u6bd4\u4ec5\u57fa\u4e8e\u6837\u672c\u7684M-\u4f30\u8ba1\u91cf\u5177\u6709\u66f4\u597d\u7684\u6e10\u8fd1\u65b9\u5dee\uff0c\u800c\u786e\u5b9a\u6027\u504f\u597d\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u8fd9\u4e00\u7ed3\u679c\u3002\u5229\u7528\u786e\u5b9a\u6027\u504f\u597d\u63ed\u793a\u7684\u786c\u7ea6\u675f\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4f30\u8ba1\u8bef\u5dee\u4e3a$\\mathcal{O}(1/n)$\u7684\u4f30\u8ba1\u5668\uff0c\u8fd9\u76f8\u8f83\u4e8e\u4ec5\u4f7f\u7528\u6837\u672c\u80fd\u8fbe\u5230\u7684$\\Theta(1/\\sqrt{n})$\u901f\u7387\u6709\u4e86\u663e\u8457\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5efa\u7acb\u4e86\u4e0e\u8be5\u52a0\u901f\u901f\u7387\u76f8\u5339\u914d\u7684\u4e0b\u754c\u3002\u867d\u7136\u6211\u4eec\u7684\u5206\u6790\u5047\u8bbe\u8f83\u4e3a\u4e25\u683c\uff0c\u4f46\u5b83\u4eec\u9002\u7528\u4e8e\u4e00\u4e9b\u663e\u8457\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u5956\u52b1\u7684\u9ad8\u65af\u6216\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7684\u504f\u597d\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u8bed\u8a00\u5efa\u6a21\u9886\u57df\u7684\u8fdb\u5c55\u8868\u660e\uff0c\u504f\u597d\u53cd\u9988\u5bf9\u4e8e\u63d0\u5347\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u5728\u54ea\u4e9b\u6761\u4ef6\u4e0b\uff0c\u504f\u597d\u53cd\u9988\u80fd\u591f\u6539\u5584\u8fde\u7eed\u53c2\u6570\u5206\u5e03\u4e2d\u7684\u53c2\u6570\u4f30\u8ba1\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5728\u8be5\u6846\u67b6\u4e2d\uff0c\u5b66\u4e60\u8005\u53ef\u4ee5\u89c2\u5bdf\u5230\u6765\u81ea\u672a\u77e5\u5206\u5e03\u7684\u6837\u672c\u5bf9\u4ee5\u53ca\u5176\u76f8\u5bf9\u504f\u597d\u3002\u8fd9\u4e9b\u504f\u597d\u4f9d\u8d56\u4e8e\u540c\u4e00\u4e2a\u672a\u77e5\u53c2\u6570\u3002\u901a\u8fc7\u6bd4\u8f83\u57fa\u4e8e\u504f\u597d\u7684M-\u4f30\u8ba1\u91cf\u548c\u4ec5\u57fa\u4e8e\u6837\u672c\u7684M-\u4f30\u8ba1\u91cf\uff0c\u5c55\u793a\u4e86\u524d\u8005\u7684\u4f18\u8d8a\u6027\u3002\u7279\u522b\u5730\uff0c\u5f53\u504f\u597d\u662f\u786e\u5b9a\u6027\u7684\u65f6\uff0c\u8fd9\u79cd\u4f18\u52bf\u66f4\u52a0\u660e\u663e\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u786e\u5b9a\u6027\u504f\u597d\u63ed\u793a\u7684\u786c\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86$\\mathcal{O}(1/n)$\u7684\u4f30\u8ba1\u8bef\u5dee\u7f29\u653e\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u504f\u597d\u7684M-\u4f30\u8ba1\u91cf\u786e\u5b9e\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u6837\u672c\u7684M-\u4f30\u8ba1\u91cf\uff0c\u5c24\u5176\u662f\u5728\u786e\u5b9a\u6027\u504f\u597d\u60c5\u51b5\u4e0b\u3002\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u8fbe\u5230\u4e86$\\mathcal{O}(1/n)$\u7684\u4f30\u8ba1\u8bef\u5dee\uff0c\u8fdc\u80dc\u4e8e\u4ec5\u4f7f\u7528\u6837\u672c\u65f6\u7684$\\Theta(1/\\sqrt{n})$\u901f\u7387\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u8bc1\u660e\u4e86\u4e0e\u6b64\u52a0\u901f\u901f\u7387\u76f8\u5339\u914d\u7684\u7406\u8bba\u4e0b\u754c\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u504f\u597d\u53cd\u9988\u5728\u53c2\u6570\u4f30\u8ba1\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u8fde\u7eed\u53c2\u6570\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u5229\u7528\u786e\u5b9a\u6027\u504f\u597d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002\u5c3d\u7ba1\u5206\u6790\u5047\u8bbe\u8f83\u4e3a\u4e25\u683c\uff0c\u4f46\u7ed3\u679c\u9002\u7528\u4e8e\u67d0\u4e9b\u91cd\u8981\u60c5\u51b5\uff0c\u5982\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u5956\u52b1\u7684\u9ad8\u65af\u6216\u62c9\u666e\u62c9\u65af\u5206\u5e03\u7684\u504f\u597d\u3002"}}
{"id": "2505.23075", "pdf": "https://arxiv.org/pdf/2505.23075", "abs": "https://arxiv.org/abs/2505.23075", "authors": ["Amit Kumthekar", "Zion Tilley", "Henry Duong", "Bhargav Patel", "Michael Magnoli", "Ahmed Omar", "Ahmed Nasser", "Chaitanya Gharpure", "Yevgen Reztzov"], "title": "Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble", "categories": ["cs.AI", "cs.LG"], "comment": "23 pages, 11 figures", "summary": "Despite the growing clinical adoption of large language models (LLMs),\ncurrent approaches heavily rely on single model architectures. To overcome\nrisks of obsolescence and rigid dependence on single model systems, we present\na novel framework, termed the Consensus Mechanism. Mimicking clinical triage\nand multidisciplinary clinical decision-making, the Consensus Mechanism\nimplements an ensemble of specialized medical expert agents enabling improved\nclinical decision making while maintaining robust adaptability. This\narchitecture enables the Consensus Mechanism to be optimized for cost, latency,\nor performance, purely based on its interior model configuration.\n  To rigorously evaluate the Consensus Mechanism, we employed three medical\nevaluation benchmarks: MedMCQA, MedQA, and MedXpertQA Text, and the\ndifferential diagnosis dataset, DDX+. On MedXpertQA, the Consensus Mechanism\nachieved an accuracy of 61.0% compared to 53.5% and 45.9% for OpenAI's O3 and\nGoogle's Gemini 2.5 Pro. Improvement was consistent across benchmarks with an\nincrease in accuracy on MedQA\n($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 3.4\\%$) and MedMCQA\n($\\Delta\\mathrm{Accuracy}_{\\mathrm{consensus\\text{-}O3}} = 9.1\\%$). These\naccuracy gains extended to differential diagnosis generation, where our system\ndemonstrated improved recall and precision (F1$_\\mathrm{consensus}$ = 0.326 vs.\nF1$_{\\mathrm{O3\\text{-}high}}$ = 0.2886) and a higher top-1 accuracy for DDX\n(Top1$_\\mathrm{consensus}$ = 52.0% vs. Top1$_{\\mathrm{O3\\text{-}high}}$ =\n45.2%).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u2014\u2014\u5171\u8bc6\u673a\u5236\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u533b\u7597\u4e13\u5bb6\u4ee3\u7406\u6765\u6539\u8fdb\u4e34\u5e8a\u51b3\u7b56\uff0c\u5e76\u5728\u591a\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u8fc7\u4e8e\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u67b6\u6784\uff0c\u5b58\u5728\u8fc7\u65f6\u548c\u521a\u6027\u4f9d\u8d56\u7684\u98ce\u9669\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u98ce\u9669\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u4eff\u4e34\u5e8a\u5206\u8bca\u548c\u591a\u5b66\u79d1\u4e34\u5e8a\u51b3\u7b56\u7684\u5171\u8bc6\u673a\u5236\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u591a\u4e2a\u4e13\u4e1a\u533b\u7597\u4e13\u5bb6\u4ee3\u7406\uff0c\u53ef\u4ee5\u6839\u636e\u5185\u90e8\u6a21\u578b\u914d\u7f6e\u4f18\u5316\u6210\u672c\u3001\u5ef6\u8fdf\u6216\u6027\u80fd\u3002", "result": "\u5728MedXpertQA\u4e0a\uff0c\u5171\u8bc6\u673a\u5236\u7684\u51c6\u786e\u7387\u4e3a61.0%\uff0c\u9ad8\u4e8eOpenAI\u7684O3\uff0853.5%\uff09\u548cGoogle\u7684Gemini 2.5 Pro\uff0845.9%\uff09\u3002\u5728\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u5982MedQA\u548cMedMCQA\u3002\u5728\u5dee\u5f02\u8bca\u65ad\u751f\u6210\u65b9\u9762\uff0c\u5171\u8bc6\u673a\u5236\u5c55\u793a\u4e86\u66f4\u9ad8\u7684\u53ec\u56de\u7387\u3001\u7cbe\u786e\u7387\u548cF1\u5206\u6570\u3002", "conclusion": "\u5171\u8bc6\u673a\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u4e34\u5e8a\u51b3\u7b56\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u5f3a\u5927\u7684\u9002\u5e94\u6027\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u53ef\u6839\u636e\u9700\u6c42\u4f18\u5316\u4e0d\u540c\u7684\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2505.23594", "pdf": "https://arxiv.org/pdf/2505.23594", "abs": "https://arxiv.org/abs/2505.23594", "authors": ["Xi Chen", "Soham Jana", "Christopher A. Metzler", "Arian Maleki", "Shirin Jalali"], "title": "Multilook Coherent Imaging: Theoretical Guarantees and Algorithms", "categories": ["stat.ML", "cs.LG", "eess.IV"], "comment": "29 pages, 4 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:2402.15635", "summary": "Multilook coherent imaging is a widely used technique in applications such as\ndigital holography, ultrasound imaging, and synthetic aperture radar. A central\nchallenge in these systems is the presence of multiplicative noise, commonly\nknown as speckle, which degrades image quality. Despite the widespread use of\ncoherent imaging systems, their theoretical foundations remain relatively\nunderexplored. In this paper, we study both the theoretical and algorithmic\naspects of likelihood-based approaches for multilook coherent imaging,\nproviding a rigorous framework for analysis and method development. Our\ntheoretical contributions include establishing the first theoretical upper\nbound on the Mean Squared Error (MSE) of the maximum likelihood estimator under\nthe deep image prior hypothesis. Our results capture the dependence of MSE on\nthe number of parameters in the deep image prior, the number of looks, the\nsignal dimension, and the number of measurements per look. On the algorithmic\nside, we employ projected gradient descent (PGD) as an efficient method for\ncomputing the maximum likelihood solution. Furthermore, we introduce two key\nideas to enhance the practical performance of PGD. First, we incorporate the\nNewton-Schulz algorithm to compute matrix inverses within the PGD iterations,\nsignificantly reducing computational complexity. Second, we develop a bagging\nstrategy to mitigate projection errors introduced during PGD updates. We\ndemonstrate that combining these techniques with PGD yields state-of-the-art\nperformance. Our code is available at\nhttps://github.com/Computational-Imaging-RU/Bagged-DIP-Speckle.", "AI": {"tldr": "Multilook\u76f8\u5e72\u6210\u50cf\u5728\u6570\u5b57\u5168\u606f\u3001\u8d85\u58f0\u6210\u50cf\u548c\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u7b49\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4f3c\u7136\u65b9\u6cd5\u7684\u591a\u89c6\u76f8\u5e72\u6210\u50cf\u7684\u7406\u8bba\u4e0e\u7b97\u6cd5\u65b9\u9762\uff0c\u5efa\u7acb\u4e86\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u7684\u7b2c\u4e00\u4e2a\u7406\u8bba\u4e0a\u9650\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408Newton-Schulz\u7b97\u6cd5\u548cbagging\u7b56\u7565\u4f18\u5316\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff08PGD\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5b9e\u9645\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u591a\u89c6\u76f8\u5e72\u6210\u50cf\u6280\u672f\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u7531\u4e8e\u4e58\u6027\u566a\u58f0\uff08\u5982\u6591\u70b9\u566a\u58f0\uff09\u7684\u5b58\u5728\uff0c\u56fe\u50cf\u8d28\u91cf\u53d7\u5230\u663e\u8457\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u8be5\u9886\u57df\u7684\u7406\u8bba\u57fa\u7840\u76f8\u5bf9\u8584\u5f31\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7684\u7814\u7a76\u6765\u7406\u89e3\u5176\u6027\u80fd\u6781\u9650\u5e76\u5f00\u53d1\u6709\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u9996\u5148\u5206\u6790\u4e86\u57fa\u4e8e\u6df1\u5ea6\u56fe\u50cf\u5148\u9a8c\u5047\u8bbe\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u7406\u8bba\u6027\u8d28\uff0c\u63a8\u5bfc\u51fa\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u7684\u9996\u4e2a\u7406\u8bba\u4e0a\u9650\u3002\u63a5\u7740\uff0c\u5728\u7b97\u6cd5\u5c42\u9762\uff0c\u91c7\u7528\u4e86\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff08PGD\uff09\u4f5c\u4e3a\u9ad8\u6548\u8ba1\u7b97\u6700\u5927\u4f3c\u7136\u89e3\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u4e2a\u6539\u8fdb\u63aa\u65bd\uff1a1\uff09\u4f7f\u7528Newton-Schulz\u7b97\u6cd5\u964d\u4f4e\u77e9\u9635\u6c42\u9006\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff1b2\uff09\u901a\u8fc7bagging\u7b56\u7565\u51cf\u5c11PGD\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u7684\u6295\u5f71\u8bef\u5dee\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0cMSE\u7684\u4e0a\u754c\u4f9d\u8d56\u4e8e\u6df1\u5ea6\u56fe\u50cf\u5148\u9a8c\u4e2d\u7684\u53c2\u6570\u6570\u91cf\u3001\u89c6\u56fe\u6570\u3001\u4fe1\u53f7\u7ef4\u5ea6\u548c\u6bcf\u89c6\u56fe\u6d4b\u91cf\u6570\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u7ed3\u5408Newton-Schulz\u7b97\u6cd5\u548cbagging\u7b56\u7565\u7684PGD\u65b9\u6cd5\u5728\u5b9e\u9645\u6027\u80fd\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "conclusion": "\u672c\u6587\u4e3a\u591a\u89c6\u76f8\u5e72\u6210\u50cf\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u56fe\u50cf\u91cd\u5efa\u3002\u8fd9\u4e9b\u7814\u7a76\u6210\u679c\u4e0d\u4ec5\u52a0\u6df1\u4e86\u5bf9\u8be5\u9886\u57df\u7684\u7406\u89e3\uff0c\u8fd8\u4e3a\u672a\u6765\u7684\u6280\u672f\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.23091", "pdf": "https://arxiv.org/pdf/2505.23091", "abs": "https://arxiv.org/abs/2505.23091", "authors": ["Zeyu Liu", "Yuhang Liu", "Guanghao Zhu", "Congkai Xie", "Zhen Li", "Jianbo Yuan", "Xinyao Wang", "Qing Li", "Shing-Chi Cheung", "Shengyu Zhang", "Fei Wu", "Hongxia Yang"], "title": "Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nsubstantial progress in reasoning capabilities, such as DeepSeek-R1, which\nleverages rule-based reinforcement learning to enhance logical reasoning\nsignificantly. However, extending these achievements to multimodal large\nlanguage models (MLLMs) presents critical challenges, which are frequently more\npronounced for Multimodal Small Language Models (MSLMs) given their typically\nweaker foundational reasoning abilities: (1) the scarcity of high-quality\nmultimodal reasoning datasets, (2) the degradation of reasoning capabilities\ndue to the integration of visual processing, and (3) the risk that direct\napplication of reinforcement learning may produce complex yet incorrect\nreasoning processes. To address these challenges, we design a novel framework\nInfi-MMR to systematically unlock the reasoning potential of MSLMs through a\ncurriculum of three carefully structured phases and propose our multimodal\nreasoning model Infi-MMR-3B. The first phase, Foundational Reasoning\nActivation, leverages high-quality textual reasoning datasets to activate and\nstrengthen the model's logical reasoning capabilities. The second phase,\nCross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to\nfacilitate the progressive transfer of reasoning skills to multimodal contexts.\nThe third phase, Multimodal Reasoning Enhancement, employs curated,\ncaption-free multimodal data to mitigate linguistic biases and promote robust\ncross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal\nmath reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision\ntest, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on\nMathVista testmini).", "AI": {"tldr": "\u8fd1\u671f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5c06\u8fd9\u4e9b\u6210\u679c\u6269\u5c55\u5230\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5c24\u5176\u662f\u591a\u6a21\u6001\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08MSLMs\uff09\u4e0a\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aInfi-MMR\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u5177\u670930\u4ebf\u53c2\u6570\u7684\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578bInfi-MMR-3B\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u7cfb\u7edf\u5730\u6316\u6398MSLMs\u7684\u63a8\u7406\u6f5c\u529b\uff1a\u57fa\u7840\u63a8\u7406\u6fc0\u6d3b\u3001\u8de8\u6a21\u6001\u63a8\u7406\u9002\u5e94\u548c\u591a\u6a21\u6001\u63a8\u7406\u589e\u5f3a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cInfi-MMR-3B\u5728\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u4e8e\u591a\u6a21\u6001\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u7531\u4e8e\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u6570\u636e\u7a00\u7f3a\u3001\u89c6\u89c9\u5904\u7406\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u53ef\u80fd\u4ea7\u751f\u7684\u9519\u8bef\u63a8\u7406\u8fc7\u7a0b\u7b49\u95ee\u9898\uff0c\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u5347\u591a\u6a21\u6001\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aInfi-MMR\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u9636\u6bb5\uff1a1. \u57fa\u7840\u63a8\u7406\u6fc0\u6d3b\uff1a\u4f7f\u7528\u9ad8\u8d28\u91cf\u6587\u672c\u63a8\u7406\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u7684\u57fa\u7840\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff1b2. \u8de8\u6a21\u6001\u63a8\u7406\u9002\u5e94\uff1a\u5229\u7528\u5e26\u6807\u9898\u7684\u591a\u6a21\u6001\u6570\u636e\u9010\u6b65\u5c06\u63a8\u7406\u6280\u80fd\u8fc1\u79fb\u5230\u591a\u6a21\u6001\u73af\u5883\uff1b3. \u591a\u6a21\u6001\u63a8\u7406\u589e\u5f3a\uff1a\u91c7\u7528\u65e0\u6807\u9898\u7684\u7cbe\u9009\u591a\u6a21\u6001\u6570\u636e\u51cf\u5c11\u8bed\u8a00\u504f\u5dee\u5e76\u4fc3\u8fdb\u7a33\u5065\u7684\u8de8\u6a21\u6001\u63a8\u7406\u3002\u6b64\u5916\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6b64\u6846\u67b6\u7684\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578bInfi-MMR-3B\u3002", "result": "Infi-MMR-3B\u5728\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728MathVerse testmini\u3001MathVision test\u548cOlympiadBench\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a43.68%\u300127.04%\u548c21.33%\uff0c\u540c\u65f6\u5728\u901a\u7528\u63a8\u7406\u4efb\u52a1\uff08\u5982MathVista testmini\uff09\u4e0a\u4e5f\u53d6\u5f97\u4e8667.2%\u7684\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Infi-MMR\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6570\u5b66\u63a8\u7406\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002"}}
{"id": "2505.23620", "pdf": "https://arxiv.org/pdf/2505.23620", "abs": "https://arxiv.org/abs/2505.23620", "authors": ["Jiayuan Ye", "Vitaly Feldman", "Kunal Talwar"], "title": "Instance-Optimality for Private KL Distribution Estimation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study the fundamental problem of estimating an unknown discrete\ndistribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the\ndistribution. We are interested in minimizing the KL divergence between the\ntrue distribution and the algorithm's estimate. We first construct minimax\noptimal private estimators. Minimax optimality however fails to shed light on\nan algorithm's performance on individual (non-worst-case) instances $p$ and\nsimple minimax-optimal DP estimators can have poor empirical performance on\nreal distributions. We then study this problem from an instance-optimality\nviewpoint, where the algorithm's error on $p$ is compared to the minimum\nachievable estimation error over a small local neighborhood of $p$. Under\nnatural notions of local neighborhood, we propose algorithms that achieve\ninstance-optimality up to constant factors, with and without a differential\nprivacy constraint. Our upper bounds rely on (private) variants of the\nGood-Turing estimator. Our lower bounds use additive local neighborhoods that\nmore precisely captures the hardness of distribution estimation in KL\ndivergence, compared to ones considered in prior works.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u7ed9\u5b9an\u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u4f30\u8ba1\u4e00\u4e2a\u672a\u77e5\u7684\u79bb\u6563\u5206\u5e03p\u7684\u95ee\u9898\u3002\u9996\u5148\u6784\u5efa\u4e86\u6700\u5c0f\u6700\u5927\u6700\u4f18\u79c1\u6709\u4f30\u8ba1\u5668\uff0c\u7136\u540e\u4ece\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u89d2\u5ea6\u7814\u7a76\u8be5\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u6709\u6216\u6ca1\u6709\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u8fbe\u5230\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u7b97\u6cd5\u3002\u4e0a\u4e0b\u754c\u5206\u522b\u4f9d\u8d56\u4e8eGood-Turing\u4f30\u8ba1\u5668\u7684\uff08\u79c1\u6709\uff09\u53d8\u4f53\u548c\u52a0\u6cd5\u5c40\u90e8\u90bb\u57df\u3002", "motivation": "\u4f30\u8ba1\u672a\u77e5\u79bb\u6563\u5206\u5e03\u662f\u7edf\u8ba1\u5b66\u4e2d\u7684\u57fa\u672c\u95ee\u9898\u3002\u867d\u7136\u6700\u5c0f\u6700\u5927\u6700\u4f18\u4f30\u8ba1\u5668\u5728\u7406\u8bba\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5728\u5b9e\u9645\u5206\u5e03\u4e0a\u7684\u6027\u80fd\u53ef\u80fd\u8f83\u5dee\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4ece\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u89d2\u5ea6\u6765\u7814\u7a76\u8fd9\u4e00\u95ee\u9898\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u7b97\u6cd5\u5728\u4e2a\u4f53\u5b9e\u4f8b\u4e0a\u7684\u8868\u73b0\u3002", "method": "1. \u6784\u5efa\u6700\u5c0f\u6700\u5927\u6700\u4f18\u79c1\u6709\u4f30\u8ba1\u5668\u3002\n2. \u4ece\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u89c6\u89d2\u51fa\u53d1\uff0c\u5b9a\u4e49\u5c40\u90e8\u90bb\u57df\u3002\n3. \u63d0\u51fa\u5728\u6709\u6216\u6ca1\u6709\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u8fbe\u5230\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u7b97\u6cd5\u3002\n4. \u4f7f\u7528Good-Turing\u4f30\u8ba1\u5668\u7684\uff08\u79c1\u6709\uff09\u53d8\u4f53\u4f5c\u4e3a\u4e0a\u754c\uff0c\u4f7f\u7528\u52a0\u6cd5\u5c40\u90e8\u90bb\u57df\u4f5c\u4e3a\u4e0b\u754c\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5b9e\u4f8b\u6700\u4f18\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u5e38\u6570\u56e0\u5b50\u5185\u7684\u6700\u4f18\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u6709\u6216\u6ca1\u6709\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u7684\u60c5\u51b5\u3002\u4e0a\u4e0b\u754c\u5206\u6790\u8868\u660e\uff0c\u6240\u7528\u65b9\u6cd5\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u7cbe\u786e\u5730\u6355\u6349\u4e86KL\u6563\u5ea6\u4e2d\u5206\u5e03\u4f30\u8ba1\u7684\u96be\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4ece\u5b9e\u4f8b\u6700\u4f18\u6027\u548c\u5dee\u5206\u9690\u79c1\u89d2\u5ea6\u5bf9\u79bb\u6563\u5206\u5e03\u4f30\u8ba1\u95ee\u9898\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u4e8e\u4f20\u7edf\u6700\u5c0f\u6700\u5927\u65b9\u6cd5\u7684\u4f30\u8ba1\u5668\u3002\u672a\u6765\u53ef\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u5c40\u90e8\u90bb\u57df\u5b9a\u4e49\u548c\u5176\u4ed6\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2505.23153", "pdf": "https://arxiv.org/pdf/2505.23153", "abs": "https://arxiv.org/abs/2505.23153", "authors": ["Fan Wang", "Shaoshan Liu"], "title": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Collective Adaptive Intelligence (CAI) represent a transformative approach in\nartificial intelligence, wherein numerous autonomous agents collaborate, adapt,\nand self-organize to navigate complex, dynamic environments. This paradigm is\nparticularly impactful in embodied AI applications, where adaptability and\nresilience are paramount. By enabling systems to reconfigure themselves in\nresponse to unforeseen challenges, CAI facilitate robust performance in\nreal-world scenarios. This article introduces a conceptual framework for\ndesigning and analyzing CAI. It delineates key attributes including task\ngeneralization, resilience, scalability, and self-assembly, aiming to bridge\ntheoretical foundations with practical methodologies for engineering adaptive,\nemergent intelligence. By providing a structured foundation for understanding\nand implementing CAI, this work seeks to guide researchers and practitioners in\ndeveloping more resilient, scalable, and adaptable AI systems across various\ndomains.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u96c6\u4f53\u81ea\u9002\u5e94\u667a\u80fd\uff08CAI\uff09\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5f3a\u8c03\u5176\u5728\u5e94\u5bf9\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u5305\u62ec\u4efb\u52a1\u6cdb\u5316\u3001\u5f39\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u7ec4\u88c5\u7b49\u5173\u952e\u5c5e\u6027\uff0c\u4ee5\u6307\u5bfc\u7814\u7a76\u8005\u8bbe\u8ba1\u66f4\u5f3a\u5927\u7684AI\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u9762\u5bf9\u590d\u6742\u3001\u52a8\u6001\u73af\u5883\u65f6\u7f3a\u4e4f\u8db3\u591f\u7684\u9002\u5e94\u6027\u548c\u5f39\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1\u548c\u5206\u6790CAI\u7cfb\u7edf\uff0c\u91cd\u70b9\u6db5\u76d6\u4efb\u52a1\u6cdb\u5316\u3001\u5f39\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u7ec4\u88c5\u7b49\u5173\u952e\u5c5e\u6027\u3002", "result": "\u4e3a\u7406\u89e3\u4e0e\u5b9e\u73b0CAI\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u5f00\u53d1\u66f4\u5177\u5f39\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684AI\u7cfb\u7edf\u3002", "conclusion": "CAI\u4ee3\u8868\u4e86\u4e00\u79cd\u53d8\u9769\u6027\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u4e3b\u4ee3\u7406\u7684\u5408\u4f5c\u3001\u9002\u5e94\u548c\u81ea\u7ec4\u7ec7\uff0c\u53ef\u4ee5\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u6027\u80fd\uff0c\u63a8\u52a8\u7406\u8bba\u4e0e\u5b9e\u9645\u5de5\u7a0b\u65b9\u6cd5\u7684\u7ed3\u5408\u3002"}}
{"id": "2505.23737", "pdf": "https://arxiv.org/pdf/2505.23737", "abs": "https://arxiv.org/abs/2505.23737", "authors": ["Wei Shen", "Ruichuan Huang", "Minhui Huang", "Cong Shen", "Jiawei Zhang"], "title": "On the Convergence Analysis of Muon", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.OC"], "comment": null, "summary": "The majority of parameters in neural networks are naturally represented as\nmatrices. However, most commonly used optimizers treat these matrix parameters\nas flattened vectors during optimization, potentially overlooking their\ninherent structural properties. Recently, an optimizer called Muon has been\nproposed, specifically designed to optimize matrix-structured parameters.\nExtensive empirical evidence shows that Muon can significantly outperform\ntraditional optimizers when training neural networks. Nonetheless, the\ntheoretical understanding of Muon's convergence behavior and the reasons behind\nits superior performance remain limited. In this work, we present a\ncomprehensive convergence rate analysis of Muon and its comparison with\nGradient Descent (GD). We further characterize the conditions under which Muon\ncan outperform GD. Our theoretical results reveal that Muon can benefit from\nthe low-rank and approximate blockwise diagonal structure of Hessian matrices\n-- phenomena widely observed in practical neural network training. Our\nexperimental results support and corroborate the theoretical findings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668Muon\uff0c\u5176\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u5668\u3002\u672c\u6587\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u5206\u6790\u4e86Muon\u7684\u6536\u655b\u6027\u53ca\u5176\u4f18\u4e8e\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u7684\u539f\u56e0\uff0c\u53d1\u73b0\u5176\u5f97\u76ca\u4e8eHessian\u77e9\u9635\u7684\u4f4e\u79e9\u548c\u8fd1\u4f3c\u5757\u5bf9\u89d2\u7ed3\u6784\u7279\u6027\u3002", "motivation": "\u5927\u591a\u6570\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u4ee5\u77e9\u9635\u5f62\u5f0f\u5b58\u5728\uff0c\u4f46\u5e38\u7528\u4f18\u5316\u5668\u5728\u4f18\u5316\u65f6\u5c06\u5176\u89c6\u4e3a\u6241\u5e73\u5411\u91cf\uff0c\u53ef\u80fd\u5ffd\u7565\u4e86\u5176\u56fa\u6709\u7684\u7ed3\u6784\u7279\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u4e00\u79cd\u80fd\u591f\u5229\u7528\u8fd9\u4e9b\u7ed3\u6784\u7279\u6027\u7684\u4f18\u5316\u5668\uff0c\u5982Muon\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u5176\u6027\u80fd\u4f18\u52bf\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f5c\u8005\u5bf9Muon\u4f18\u5316\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6536\u655b\u901f\u5ea6\u5206\u6790\uff0c\u5e76\u4e0e\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u540c\u65f6\uff0c\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4e86Muon\u4f18\u4e8eGD\u7684\u6761\u4ef6\uff0c\u63ed\u793a\u4e86\u5176\u4eceHessian\u77e9\u9635\u7684\u4f4e\u79e9\u548c\u8fd1\u4f3c\u5757\u5bf9\u89d2\u7ed3\u6784\u4e2d\u83b7\u76ca\u7684\u673a\u5236\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0cMuon\u53ef\u4ee5\u4eceHessian\u77e9\u9635\u7684\u4f4e\u79e9\u548c\u8fd1\u4f3c\u5757\u5bf9\u89d2\u7ed3\u6784\u4e2d\u53d7\u76ca\uff0c\u8fd9\u79cd\u73b0\u8c61\u5728\u5b9e\u9645\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u5f88\u5e38\u89c1\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u5e76\u652f\u6301\u4e86\u8fd9\u4e00\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "Muon\u4f18\u5316\u5668\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5176\u4f18\u8d8a\u6027\u6e90\u4e8e\u5bf9Hessian\u77e9\u9635\u7ed3\u6784\u7279\u6027\u7684\u6709\u6548\u5229\u7528\u3002\u672c\u6587\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\u4e3a\u7406\u89e3Muon\u7684\u6536\u655b\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u4f9d\u636e\u3002"}}
{"id": "2505.23281", "pdf": "https://arxiv.org/pdf/2505.23281", "abs": "https://arxiv.org/abs/2505.23281", "authors": ["Mislav Balunovi\u0107", "Jasper Dekoninck", "Ivo Petrov", "Nikola Jovanovi\u0107", "Martin Vechev"], "title": "MathArena: Evaluating LLMs on Uncontaminated Math Competitions", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of reasoning capabilities in large language models\n(LLMs) has led to notable improvements on mathematical benchmarks. However,\nmany of the most commonly used evaluation datasets (e.g., AIME 2024) are widely\navailable online, making it difficult to disentangle genuine reasoning from\npotential memorization. Furthermore, these benchmarks do not evaluate\nproof-writing capabilities, which are crucial for many mathematical tasks. To\naddress this, we introduce MathArena, a new benchmark based on the following\nkey insight: recurring math competitions provide a stream of high-quality,\nchallenging problems that can be used for real-time evaluation of LLMs. By\nevaluating models as soon as new problems are released, we effectively\neliminate the risk of contamination. Using this framework, we find strong signs\nof contamination in AIME 2024. Nonetheless, evaluations on harder competitions,\nsuch as SMT 2025 -- published well after model release dates -- demonstrate\nimpressive reasoning capabilities in top-performing models. MathArena is also\nthe first benchmark for proof-writing capabilities. On USAMO 2025, even top\nmodels score below 25%, far behind their performance on final-answer tasks. So\nfar, we have evaluated 30 models across five competitions, totaling 149\nproblems. As an evolving benchmark, MathArena will continue to track the\nprogress of LLMs on newly released competitions, ensuring rigorous and\nup-to-date evaluation of mathematical reasoning.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u53ef\u80fd\u6df7\u6742\u4e86\u8bb0\u5fc6\u6548\u679c\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faMathArena\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u65f6\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u6709\u6548\u8bc4\u4f30LLMs\u7684\u63a8\u7406\u548c\u8bc1\u660e\u5199\u4f5c\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u9876\u7ea7\u6a21\u578b\u5728\u6700\u7ec8\u7b54\u6848\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bc1\u660e\u5199\u4f5c\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u5f53\u524d\u5e38\u7528\u7684\u6570\u5b66\u8bc4\u4f30\u6570\u636e\u96c6\uff08\u5982AIME 2024\uff09\u5728\u7ebf\u4e0a\u5e7f\u6cdb\u53ef\u5f97\uff0c\u96be\u4ee5\u533a\u5206\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u548c\u6f5c\u5728\u7684\u8bb0\u5fc6\u6548\u679c\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u672a\u6db5\u76d6\u5bf9\u8bb8\u591a\u6570\u5b66\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u7684\u8bc1\u660e\u5199\u4f5c\u80fd\u529b\u3002", "method": "\u5f15\u5165MathArena\u4f5c\u4e3a\u65b0\u57fa\u51c6\uff0c\u5229\u7528\u5b9a\u671f\u4e3e\u884c\u7684\u6570\u5b66\u7ade\u8d5b\u63d0\u4f9b\u7684\u9ad8\u8d28\u91cf\u3001\u9ad8\u96be\u5ea6\u95ee\u9898\u8fdb\u884c\u5b9e\u65f6\u8bc4\u4f30\uff0c\u4ee5\u6d88\u9664\u6f5c\u5728\u7684\u8bb0\u5fc6\u6c61\u67d3\uff0c\u5e76\u9996\u6b21\u8bc4\u4f30LLMs\u7684\u8bc1\u660e\u5199\u4f5c\u80fd\u529b\u3002", "result": "\u53d1\u73b0AIME 2024\u5b58\u5728\u660e\u663e\u6c61\u67d3\u8ff9\u8c61\uff1b\u800c\u5728\u66f4\u96be\u7684\u7ade\u8d5b\uff08\u5982SMT 2025\uff09\u4e2d\uff0c\u9876\u7ea7\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u5728USAMO 2025\u7684\u8bc1\u660e\u5199\u4f5c\u4efb\u52a1\u4e2d\uff0c\u5373\u4f7f\u662f\u9876\u7ea7\u6a21\u578b\u5f97\u5206\u4e5f\u4f4e\u4e8e25%\u3002", "conclusion": "MathArena\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0d\u65ad\u53d1\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u4e25\u683c\u4e14\u53ca\u65f6\u5730\u8ddf\u8e2aLLMs\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u5728\u8bc1\u660e\u5199\u4f5c\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2505.22703", "pdf": "https://arxiv.org/pdf/2505.22703", "abs": "https://arxiv.org/abs/2505.22703", "authors": ["Mohammad Yaghini", "Tudor Cebere", "Michael Menart", "Aur\u00e9lien Bellet", "Nicolas Papernot"], "title": "Private Rate-Constrained Optimization with Applications to Fair Learning", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Many problems in trustworthy ML can be formulated as minimization of the\nmodel error under constraints on the prediction rates of the model for\nsuitably-chosen marginals, including most group fairness constraints\n(demographic parity, equality of odds, etc.). In this work, we study such\nconstrained minimization problems under differential privacy (DP). Standard DP\noptimization techniques like DP-SGD rely on the loss function's decomposability\ninto per-sample contributions. However, rate constraints introduce inter-sample\ndependencies, violating the decomposability requirement. To address this, we\ndevelop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)\nalgorithm which solves the Lagrangian formulation of rate constraint problems.\nWe demonstrate that the additional privacy cost of incorporating these\nconstraints reduces to privately estimating a histogram over the mini-batch at\neach optimization step. We prove the convergence of our algorithm through a\nnovel analysis of SGDA that leverages the linear structure of the dual\nparameter. Finally, empirical results on learning under group fairness\nconstraints demonstrate that our method Pareto-dominates existing private\nlearning approaches in fairness-utility trade-offs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRaCO-DP\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5728\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u4e0b\u7684\u6a21\u578b\u4f18\u5316\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u7ea6\u675f\u6761\u4ef6\u5bfc\u81f4\u7684\u6837\u672c\u95f4\u4f9d\u8d56\u6027\uff0c\u5e76\u901a\u8fc7\u79c1\u6709\u5316\u76f4\u65b9\u56fe\u4f30\u8ba1\u6765\u63a7\u5236\u989d\u5916\u7684\u9690\u79c1\u6210\u672c\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRaCO-DP\u5728\u516c\u5e73\u6027\u548c\u6548\u7528\u7684\u6743\u8861\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u53ef\u4fe1\u673a\u5668\u5b66\u4e60\u7684\u95ee\u9898\u53ef\u4ee5\u88ab\u8868\u8ff0\u4e3a\u5728\u7279\u5b9a\u8fb9\u9645\u9884\u6d4b\u7387\u7ea6\u675f\u4e0b\u7684\u6a21\u578b\u8bef\u5dee\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4f8b\u5982\u7fa4\u4f53\u516c\u5e73\u6027\u7ea6\u675f\uff08\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u7b49\u3001\u673a\u4f1a\u5747\u7b49\uff09\u3002\u7136\u800c\uff0c\u5728\u5dee\u5206\u9690\u79c1\u73af\u5883\u4e0b\uff0c\u6807\u51c6\u7684\u9690\u79c1\u4f18\u5316\u6280\u672f\uff08\u5982DP-SGD\uff09\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u8fd9\u4e9b\u7ea6\u675f\uff0c\u56e0\u4e3a\u7ea6\u675f\u5f15\u5165\u4e86\u6837\u672c\u95f4\u7684\u4f9d\u8d56\u6027\uff0c\u7834\u574f\u4e86\u635f\u5931\u51fd\u6570\u7684\u53ef\u5206\u89e3\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86RaCO-DP\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347\uff08SGDA\uff09\u7b97\u6cd5\u7684\u5dee\u5206\u9690\u79c1\u53d8\u4f53\u3002RaCO-DP\u901a\u8fc7\u89e3\u51b3\u5e26\u6709\u7ea6\u675f\u7684\u62c9\u683c\u6717\u65e5\u516c\u5f0f\u6765\u5904\u7406\u6a21\u578b\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5c06\u989d\u5916\u7684\u9690\u79c1\u6210\u672c\u5f52\u7ed3\u4e3a\u5bf9\u6bcf\u4e2a\u4f18\u5316\u6b65\u9aa4\u4e2d\u7684\u5c0f\u6279\u91cf\u6570\u636e\u8fdb\u884c\u79c1\u6709\u5316\u76f4\u65b9\u56fe\u4f30\u8ba1\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u4f5c\u8005\u901a\u8fc7\u5229\u7528\u5bf9\u5076\u53c2\u6570\u7684\u7ebf\u6027\u7ed3\u6784\uff0c\u8bc1\u660e\u4e86RaCO-DP\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7fa4\u4f53\u516c\u5e73\u6027\u7ea6\u675f\u7684\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0cRaCO-DP\u65b9\u6cd5\u5728\u516c\u5e73\u6027\u548c\u6548\u7528\u7684\u6743\u8861\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u9690\u79c1\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "RaCO-DP\u662f\u4e00\u79cd\u6709\u6548\u7684\u5dee\u5206\u9690\u79c1\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6ee1\u8db3\u7fa4\u4f53\u516c\u5e73\u6027\u7ea6\u675f\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002\u5b83\u4e0d\u4ec5\u89e3\u51b3\u4e86\u6837\u672c\u95f4\u4f9d\u8d56\u6027\u7684\u95ee\u9898\uff0c\u8fd8\u901a\u8fc7\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2505.23381", "pdf": "https://arxiv.org/pdf/2505.23381", "abs": "https://arxiv.org/abs/2505.23381", "authors": ["Bowen Ping", "Minnan Luo", "Zhuohang Dang", "Chenxi Wang", "Chengyou Jia"], "title": "AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Geometry problem solving presents distinctive challenges in artificial\nintelligence, requiring exceptional multimodal comprehension and rigorous\nmathematical reasoning capabilities. Existing approaches typically fall into\ntwo categories: neural-based and symbolic-based methods, both of which exhibit\nlimitations in reliability and interpretability. To address this challenge, we\npropose AutoGPS, a neuro-symbolic collaborative framework that solves geometry\nproblems with concise, reliable, and human-interpretable reasoning processes.\nSpecifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a\nDeductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal\ncomprehension to translate geometry problems into structured formal language\nrepresentations, with feedback from DSR collaboratively. The DSR takes the\nformalization as input and formulates geometry problem solving as a hypergraph\nexpansion task, executing mathematically rigorous and reliable derivation to\nproduce minimal and human-readable stepwise solutions. Extensive experimental\nevaluations demonstrate that AutoGPS achieves state-of-the-art performance on\nbenchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms\nAutoGPS's impressive reliability and interpretability, with 99\\% stepwise\nlogical coherence. The project homepage is at\nhttps://jayce-ping.github.io/AutoGPS-homepage.", "AI": {"tldr": "\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u5bf9\u4eba\u5de5\u667a\u80fd\u63d0\u51fa\u4e86\u72ec\u7279\u7684\u6311\u6218\uff0c\u9700\u8981\u5353\u8d8a\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u4e25\u8c28\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u5206\u4e3a\u795e\u7ecf\u7f51\u7edc\u548c\u57fa\u4e8e\u7b26\u53f7\u7684\u65b9\u6cd5\u4e24\u7c7b\uff0c\u5b83\u4eec\u5728\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86AutoGPS\uff0c\u8fd9\u662f\u4e00\u4e2a\u795e\u7ecf-\u7b26\u53f7\u534f\u4f5c\u6846\u67b6\uff0c\u4ee5\u7b80\u6d01\u3001\u53ef\u9760\u548c\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u89e3\u51b3\u51e0\u4f55\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0cAutoGPS\u91c7\u7528\u4e86\u591a\u6a21\u6001\u95ee\u9898\u5f62\u5f0f\u5316\u5668\uff08MPF\uff09\u548c\u6f14\u7ece\u7b26\u53f7\u63a8\u7406\u5668\uff08DSR\uff09\u3002MPF\u5229\u7528\u795e\u7ecf\u4ea4\u53c9\u6a21\u6001\u7406\u89e3\u5c06\u51e0\u4f55\u95ee\u9898\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5f62\u5f0f\u8bed\u8a00\u8868\u793a\uff0c\u5e76\u4e0eDSR\u8fdb\u884c\u534f\u4f5c\u53cd\u9988\u3002DSR\u63a5\u53d7\u5f62\u5f0f\u5316\u8f93\u5165\uff0c\u5e76\u5c06\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u89c6\u4e3a\u8d85\u56fe\u6269\u5c55\u4efb\u52a1\uff0c\u6267\u884c\u4e25\u683c\u7684\u6570\u5b66\u63a8\u5bfc\uff0c\u751f\u6210\u6700\u5c0f\u4e14\u4eba\u7c7b\u53ef\u8bfb\u7684\u9010\u6b65\u89e3\u51b3\u65b9\u6848\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cAutoGPS\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u4eba\u7c7b\u9010\u6b65\u63a8\u7406\u8bc4\u4f30\u8bc1\u5b9e\u4e86AutoGPS\u51fa\u8272\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5177\u670999%\u7684\u9010\u6b65\u903b\u8f91\u4e00\u81f4\u6027\u3002", "motivation": "\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u5bf9\u4e8e\u4eba\u5de5\u667a\u80fd\u800c\u8a00\u662f\u4e00\u4e2a\u72ec\u7279\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u5b83\u9700\u8981\u5353\u8d8a\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u4e25\u8c28\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u795e\u7ecf\u7f51\u7edc\u548c\u57fa\u4e8e\u7b26\u53f7\u7684\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u4eec\u5bfb\u627e\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAutoGPS\u7684\u795e\u7ecf-\u7b26\u53f7\u534f\u4f5c\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a\u591a\u6a21\u6001\u95ee\u9898\u5f62\u5f0f\u5316\u5668\uff08MPF\uff09\u548c\u6f14\u7ece\u7b26\u53f7\u63a8\u7406\u5668\uff08DSR\uff09\u3002MPF\u901a\u8fc7\u795e\u7ecf\u4ea4\u53c9\u6a21\u6001\u7406\u89e3\u5c06\u51e0\u4f55\u95ee\u9898\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5f62\u5f0f\u8bed\u8a00\u8868\u793a\uff0c\u5e76\u4eceDSR\u63a5\u6536\u53cd\u9988\u3002DSR\u5219\u5c06\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u4f5c\u4e3a\u8d85\u56fe\u6269\u5c55\u4efb\u52a1\u5904\u7406\uff0c\u6267\u884c\u4e25\u683c\u7684\u6570\u5b66\u63a8\u5bfc\uff0c\u751f\u6210\u7b80\u6d01\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u9010\u6b65\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAutoGPS\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u4eba\u7c7b\u9010\u6b65\u63a8\u7406\u8bc4\u4f30\u663e\u793a\uff0cAutoGPS\u5177\u590799%\u7684\u9010\u6b65\u903b\u8f91\u4e00\u81f4\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "AutoGPS\u4f5c\u4e3a\u4e00\u79cd\u795e\u7ecf-\u7b26\u53f7\u534f\u4f5c\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u7b80\u6d01\u3001\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u5b83\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5f97\u5230\u4e86\u4eba\u7c7b\u8bc4\u4ef7\u7684\u9ad8\u5ea6\u8ba4\u53ef\uff0c\u6807\u5fd7\u7740\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2505.22841", "pdf": "https://arxiv.org/pdf/2505.22841", "abs": "https://arxiv.org/abs/2505.22841", "authors": ["Franck Gabriel", "Fran\u00e7ois Ged", "Maria Han Veiga", "Emmanuel Schertzer"], "title": "Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study", "categories": ["cs.LG", "math.PR", "stat.ML", "G.3; I.2.6"], "comment": null, "summary": "Diffusion models now set the benchmark in high-fidelity generative sampling,\nyet they can, in principle, be prone to memorization. In this case, their\nlearned score overfits the finite dataset so that the reverse-time SDE samples\nare mostly training points. In this paper, we interpret the empirical score as\na noisy version of the true score and show that its covariance matrix is\nasymptotically a re-weighted data PCA. In large dimension, the small time limit\nmakes the noise variance blow up while simultaneously reducing spatial\ncorrelation. To reduce this variance, we introduce a kernel-smoothed empirical\nscore and analyze its bias-variance trade-off. We derive asymptotic bounds on\nthe Kullback-Leibler divergence between the true distribution and the one\ngenerated by the modified reverse SDE. Regularization on the score has the same\neffect as increasing the size of the training dataset, and thus helps prevent\nmemorization. A spectral decomposition of the forward diffusion suggests better\nvariance control under some regularity conditions of the true data\ndistribution. Reverse diffusion with kernel-smoothed empirical score can be\nreformulated as a gradient descent drifted toward a Log-Exponential\nDouble-Kernel Density Estimator (LED-KDE). This perspective highlights two\nregularization mechanisms taking place in denoising diffusions: an initial\nGaussian kernel first diffuses mass isotropically in the ambient space, while a\nsecond kernel applied in score space concentrates and spreads that mass along\nthe data manifold. Hence, even a straightforward regularization-without any\nlearning-already mitigates memorization and enhances generalization.\nNumerically, we illustrate our results with several experiments on synthetic\nand MNIST datasets.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u5c3d\u7ba1\u5728\u9ad8\u4fdd\u771f\u751f\u6210\u91c7\u6837\u4e2d\u8bbe\u7acb\u4e86\u57fa\u51c6\uff0c\u4f46\u53ef\u80fd\u56e0\u5206\u6570\u8fc7\u62df\u5408\u800c\u5bfc\u81f4\u8bb0\u5fc6\u95ee\u9898\u3002\u672c\u6587\u901a\u8fc7\u5f15\u5165\u6838\u5e73\u6ed1\u7ecf\u9a8c\u5206\u6570\u6765\u51cf\u5c11\u566a\u58f0\u65b9\u5dee\uff0c\u5e76\u5206\u6790\u5176\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u4ece\u800c\u9632\u6b62\u8bb0\u5fc6\u5e76\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u53ef\u80fd\u5b58\u5728\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u7ecf\u9a8c\u5206\u6570\u89c6\u4e3a\u771f\u5b9e\u5206\u6570\u7684\u566a\u58f0\u7248\u672c\uff0c\u5e76\u5206\u6790\u5176\u534f\u65b9\u5dee\u77e9\u9635\uff1b\u5f15\u5165\u6838\u5e73\u6ed1\u7ecf\u9a8c\u5206\u6570\u4ee5\u51cf\u5c11\u566a\u58f0\u65b9\u5dee\uff1b\u63a8\u5bfc\u771f\u5b9e\u5206\u5e03\u4e0e\u4fee\u6539\u540e\u7684\u53cd\u5411SDE\u751f\u6210\u5206\u5e03\u4e4b\u95f4\u7684Kullback-Leibler\u6563\u5ea6\u7684\u6e10\u8fd1\u754c\uff1b\u63d0\u51fa\u6b63\u5411\u6269\u6563\u7684\u8c31\u5206\u89e3\u4ee5\u6539\u5584\u65b9\u5dee\u63a7\u5236\uff1b\u5c06\u53cd\u5411\u6269\u6563\u91cd\u65b0\u8868\u8ff0\u4e3a\u68af\u5ea6\u4e0b\u964d\u8fc7\u7a0b\uff0c\u671d\u7740Log-Exponential Double-Kernel Density Estimator (LED-KDE)\u6f02\u79fb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5206\u6570\u6b63\u5219\u5316\u7b49\u6548\u4e8e\u589e\u52a0\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5927\u5c0f\uff0c\u6709\u52a9\u4e8e\u9632\u6b62\u8bb0\u5fc6\u95ee\u9898\u3002\u6570\u503c\u5b9e\u9a8c\u5728\u5408\u6210\u6570\u636e\u548cMNIST\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6838\u5e73\u6ed1\u7ecf\u9a8c\u5206\u6570\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6269\u6563\u6a21\u578b\u7684\u8bb0\u5fc6\u6548\u5e94\uff0c\u540c\u65f6\u589e\u5f3a\u5176\u6cdb\u5316\u80fd\u529b\u3002\u5373\u4f7f\u6ca1\u6709\u5b66\u4e60\u8fc7\u7a0b\u7684\u7b80\u5355\u6b63\u5219\u5316\u4e5f\u80fd\u591f\u663e\u8457\u6539\u5584\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2505.23397", "pdf": "https://arxiv.org/pdf/2505.23397", "abs": "https://arxiv.org/abs/2505.23397", "authors": ["Ahmad Mohsin", "Helge Janicke", "Ahmed Ibrahim", "Iqbal H. Sarker", "Seyit Camtepe"], "title": "A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy", "categories": ["cs.AI", "cs.CR"], "comment": "Journal Article", "summary": "This article presents a structured framework for Human-AI collaboration in\nSecurity Operations Centers (SOCs), integrating AI autonomy, trust calibration,\nand Human-in-the-loop decision making. Existing frameworks in SOCs often focus\nnarrowly on automation, lacking systematic structures to manage human\noversight, trust calibration, and scalable autonomy with AI. Many assume static\nor binary autonomy settings, failing to account for the varied complexity,\ncriticality, and risk across SOC tasks considering Humans and AI collaboration.\nTo address these limitations, we propose a novel autonomy tiered framework\ngrounded in five levels of AI autonomy from manual to fully autonomous, mapped\nto Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This\nenables adaptive and explainable AI integration across core SOC functions,\nincluding monitoring, protection, threat detection, alert triage, and incident\nresponse. The proposed framework differentiates itself from previous research\nby creating formal connections between autonomy, trust, and HITL across various\nSOC levels, which allows for adaptive task distribution according to\noperational complexity and associated risks. The framework is exemplified\nthrough a simulated cyber range that features the cybersecurity AI-Avatar, a\nfine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates\nhuman-AI collaboration for SOC tasks, reducing alert fatigue, enhancing\nresponse coordination, and strategically calibrating trust. This research\nsystematically presents both the theoretical and practical aspects and\nfeasibility of designing next-generation cognitive SOCs that leverage AI not to\nreplace but to enhance human decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4eba\u5de5\u667a\u80fd\u81ea\u4e3b\u5c42\u7ea7\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u8fd0\u8425\u4e2d\u5fc3\uff08SOCs\uff09\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u534f\u4f5c\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e94\u4e2a\u5c42\u6b21\u7684AI\u81ea\u4e3b\u6027\u7ea7\u522b\u3001\u4eba\u7c7b\u53c2\u4e0e\u51b3\u7b56\u7684\u89d2\u8272\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u4fe1\u4efb\u9608\u503c\u6765\u5b9e\u73b0\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u96c6\u6210\u3002\u901a\u8fc7\u6a21\u62df\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u51cf\u5c11\u8b66\u62a5\u75b2\u52b3\u3001\u589e\u5f3a\u54cd\u5e94\u534f\u8c03\u548c\u6821\u51c6\u4fe1\u4efb\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684SOC\u6846\u67b6\u8fc7\u4e8e\u5173\u6ce8\u81ea\u52a8\u5316\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7ed3\u6784\u6765\u7ba1\u7406\u4eba\u5de5\u76d1\u7763\u3001\u4fe1\u4efb\u6821\u51c6\u548c\u4e0eAI\u534f\u4f5c\u7684\u53ef\u6269\u5c55\u81ea\u4e3b\u6027\u3002\u8bb8\u591a\u6846\u67b6\u5047\u8bbe\u9759\u6001\u6216\u4e8c\u5143\u7684\u81ea\u4e3b\u8bbe\u7f6e\uff0c\u672a\u80fd\u8003\u8651SOC\u4efb\u52a1\u4e2d\u7684\u591a\u6837\u590d\u6742\u6027\u3001\u5173\u952e\u6027\u548c\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e94\u4e2aAI\u81ea\u4e3b\u7ea7\u522b\u7684\u65b0\u81ea\u4e3b\u5206\u5c42\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u4eba\u7c7b\u53c2\u4e0e\u51b3\u7b56\uff08HITL\uff09\u89d2\u8272\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u4fe1\u4efb\u9608\u503c\u3002\u6b64\u65b9\u6cd5\u5141\u8bb8\u6839\u636e\u64cd\u4f5c\u590d\u6742\u6027\u548c\u76f8\u5173\u98ce\u9669\u8fdb\u884c\u81ea\u9002\u5e94\u4efb\u52a1\u5206\u914d\u3002\u5e76\u901a\u8fc7\u6a21\u62df\u7f51\u7edc\u8303\u56f4\u4e2d\u7684\u7f51\u7edc\u5b89\u5168AI-Avatar\u6848\u4f8b\u7814\u7a76\u6765\u5c55\u793a\u8be5\u6846\u67b6\u7684\u5e94\u7528\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u66f4\u7075\u6d3b\u548c\u6709\u6548\u7684AI\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff0c\u51cf\u5c11\u4e86\u8b66\u62a5\u75b2\u52b3\uff0c\u589e\u5f3a\u4e86\u54cd\u5e94\u534f\u8c03\uff0c\u5e76\u6218\u7565\u6027\u5730\u6821\u51c6\u4e86\u4fe1\u4efb\u3002\u540c\u65f6\u5c55\u793a\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u53ef\u884c\u6027\uff0c\u4e3a\u8bbe\u8ba1\u4e0b\u4e00\u4ee3\u8ba4\u77e5SOC\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u6b63\u5f0f\u8fde\u63a5\u81ea\u4e3b\u6027\u3001\u4fe1\u4efb\u548c\u4eba\u7c7b\u53c2\u4e0e\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e86\u9002\u5e94\u4e0d\u540c\u590d\u6742\u6027\u548c\u98ce\u9669\u7684\u4efb\u52a1\u5206\u914d\u3002\u5b83\u4e0d\u4ec5\u5f3a\u8c03\u4e86AI\u5728SOC\u4e2d\u7684\u8f85\u52a9\u4f5c\u7528\uff0c\u8fd8\u7cfb\u7edf\u5730\u5c55\u793a\u4e86\u8bbe\u8ba1\u4e0b\u4e00\u4ee3\u8ba4\u77e5SOC\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2505.22881", "pdf": "https://arxiv.org/pdf/2505.22881", "abs": "https://arxiv.org/abs/2505.22881", "authors": ["Hyungki Im", "Wyame Benslimane", "Paul Grigas"], "title": "Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We study an extension of contextual stochastic linear optimization (CSLO)\nthat, in contrast to most of the existing literature, involves inequality\nconstraints that depend on uncertain parameters predicted by a machine learning\nmodel. To handle the constraint uncertainty, we use contextual uncertainty sets\nconstructed via methods like conformal prediction. Given a contextual\nuncertainty set method, we introduce the \"Smart Predict-then-Optimize with\nRobust Constraints\" (SPO-RC) loss, a feasibility-sensitive adaptation of the\nSPO loss that measures decision error of predicted objective parameters. We\nalso introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with\nSPO-RC. To enhance performance, we train on truncated datasets where true\nconstraint parameters lie within the uncertainty sets, and we correct the\ninduced sample selection bias using importance reweighting techniques. Through\nexperiments on fractional knapsack and alloy production problem instances, we\ndemonstrate that SPO-RC+ effectively handles uncertainty in constraints and\nthat combining truncation with importance reweighting can further improve\nperformance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u6709\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0d\u786e\u5b9a\u53c2\u6570\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7684\u60c5\u5883\u968f\u673a\u7ebf\u6027\u4f18\u5316\uff08CSLO\uff09\u6269\u5c55\u3002\u901a\u8fc7\u4f7f\u7528\u60c5\u5883\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\u65b9\u6cd5\uff0c\u5f15\u5165\u4e86SPO-RC\u635f\u5931\u51fd\u6570\u53ca\u5176\u51f8\u66ff\u4ee3SPO-RC+\uff0c\u5e76\u8bc1\u660e\u4e86\u5176Fisher\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u622a\u65ad\u6570\u636e\u96c6\u548c\u91cd\u8981\u6027\u91cd\u52a0\u6743\u6280\u672f\u53ef\u4ee5\u6709\u6548\u5904\u7406\u7ea6\u675f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CSLO\u7814\u7a76\u5927\u591a\u672a\u6d89\u53ca\u4f9d\u8d56\u4e8e\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0d\u786e\u5b9a\u53c2\u6570\u7684\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u4e9b\u7ea6\u675f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u60c5\u5883\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\u6784\u5efa\u65b9\u6cd5\u5904\u7406\u7ea6\u675f\u4e0d\u786e\u5b9a\u6027\uff0c\u5f15\u5165SPO-RC\u635f\u5931\u51fd\u6570\u53ca\u5176\u51f8\u66ff\u4ee3SPO-RC+\uff0c\u5e76\u901a\u8fc7\u622a\u65ad\u6570\u636e\u96c6\u548c\u91cd\u8981\u6027\u91cd\u52a0\u6743\u6280\u672f\u6765\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u5206\u6570\u80cc\u5305\u95ee\u9898\u548c\u5408\u91d1\u751f\u4ea7\u95ee\u9898\u5b9e\u4f8b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSPO-RC+\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u7ea6\u675f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4e14\u7ed3\u5408\u622a\u65ad\u6570\u636e\u96c6\u4e0e\u91cd\u8981\u6027\u91cd\u52a0\u6743\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "conclusion": "SPO-RC+\u4e3a\u5904\u7406CSLO\u4e2d\u7ea6\u675f\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u622a\u65ad\u6570\u636e\u96c6\u548c\u91cd\u8981\u6027\u91cd\u52a0\u6743\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2505.23399", "pdf": "https://arxiv.org/pdf/2505.23399", "abs": "https://arxiv.org/abs/2505.23399", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing\nvision-language reasoning. Unlike prior single-agent or monolithic models,\nGAM-Agent formulates the reasoning process as a non-zero-sum game between base\nagents--each specializing in visual perception subtasks--and a critical agent\nthat verifies logic consistency and factual correctness. Agents communicate via\nstructured claims, evidence, and uncertainty estimates. The framework\nintroduces an uncertainty-aware controller to dynamically adjust agent\ncollaboration, triggering multi-round debates when disagreement or ambiguity is\ndetected. This process yields more robust and interpretable predictions.\nExperiments on four challenging benchmarks--MMMU, MMBench, MVBench, and\nV*Bench--demonstrate that GAM-Agent significantly improves performance across\nvarious VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid\nscale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances\nstrong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable,\nand generalizable, offering a path toward reliable and explainable multi-agent\nmultimodal reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAM-Agent\u7684\u6e38\u620f\u7406\u8bba\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u3002\u901a\u8fc7\u5c06\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u975e\u96f6\u548c\u535a\u5f08\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a7\u5236\u5668\u4ee5\u52a8\u6001\u8c03\u6574\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u4ece\u5c0f\u578b\u5230\u5927\u578b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u7279\u70b9\uff0c\u4e3a\u53ef\u9760\u7684\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u5355\u4e00\u667a\u80fd\u4f53\u6216\u6574\u4f53\u6a21\u578b\u5728\u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u89e3\u91ca\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u63a8\u7406\u8fc7\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86GAM-Agent\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u975e\u96f6\u548c\u535a\u5f08\uff0c\u5305\u542b\u4e13\u6ce8\u4e8e\u89c6\u89c9\u611f\u77e5\u5b50\u4efb\u52a1\u7684\u57fa\u7840\u667a\u80fd\u4f53\u548c\u9a8c\u8bc1\u903b\u8f91\u4e00\u81f4\u6027\u548c\u4e8b\u5b9e\u6b63\u786e\u6027\u7684\u5173\u952e\u667a\u80fd\u4f53\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u58f0\u660e\u3001\u8bc1\u636e\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u8fdb\u884c\u901a\u4fe1\uff0c\u5e76\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a7\u5236\u5668\u52a8\u6001\u8c03\u6574\u534f\u4f5c\uff0c\u5728\u68c0\u6d4b\u5230\u5206\u6b67\u6216\u6b67\u4e49\u65f6\u89e6\u53d1\u591a\u8f6e\u8fa9\u8bba\u3002", "result": "\u5728MMMU\u3001MMBench\u3001MVBench\u548cV*Bench\u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cGAM-Agent\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cd\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u6027\u80fd\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u5c0f\u578b\u5230\u4e2d\u578b\u6a21\u578b\uff08\u5982Qwen2.5-VL-7B\u3001InternVL3-14B\uff09\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e865-6%\uff0c\u800c\u5bf9\u4e8e\u5f3a\u5927\u6a21\u578b\uff08\u5982GPT-4o\uff09\u4e5f\u63d0\u5347\u4e862-3%\u3002", "conclusion": "GAM-Agent\u662f\u4e00\u79cd\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u9ad8\u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2505.23320", "pdf": "https://arxiv.org/pdf/2505.23320", "abs": "https://arxiv.org/abs/2505.23320", "authors": ["Connor Cooper", "Geoffrey I. Webb", "Daniel F. Schmidt"], "title": "Efficient Parameter Estimation for Bayesian Network Classifiers using Hierarchical Linear Smoothing", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 9 figures", "summary": "Bayesian network classifiers (BNCs) possess a number of properties desirable\nfor a modern classifier: They are easily interpretable, highly scalable, and\noffer adaptable complexity. However, traditional methods for learning BNCs have\nhistorically underperformed when compared to leading classification methods\nsuch as random forests. Recent parameter smoothing techniques using\nhierarchical Dirichlet processes (HDPs) have enabled BNCs to achieve\nperformance competitive with random forests on categorical data, but these\ntechniques are relatively inflexible, and require a complicated, specialized\nsampling process. In this paper, we introduce a novel method for parameter\nestimation that uses a log-linear regression to approximate the behaviour of\nHDPs. As a linear model, our method is remarkably flexible and simple to\ninterpret, and can leverage the vast literature on learning linear models. Our\nexperiments show that our method can outperform HDP smoothing while being\norders of magnitude faster, remaining competitive with random forests on\ncategorical data.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u7ebf\u6027\u56de\u5f52\u7684\u53c2\u6570\u4f30\u8ba1\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8d1d\u53f6\u65af\u7f51\u7edc\u5206\u7c7b\u5668\uff08BNCs\uff09\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u968f\u673a\u68ee\u6797\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u8d1d\u53f6\u65af\u7f51\u7edc\u5206\u7c7b\u5668\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u590d\u6742\u5ea6\u53ef\u8c03\u7b49\u4f18\u70b9\uff0c\u4f46\u4f20\u7edf\u5b66\u4e60\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4e00\u76f4\u843d\u540e\u4e8e\u968f\u673a\u68ee\u6797\u7b49\u9886\u5148\u5206\u7c7b\u65b9\u6cd5\u3002\u867d\u7136\u4f7f\u7528\u5206\u5c42\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\uff08HDPs\uff09\u7684\u53c2\u6570\u5e73\u6ed1\u6280\u672f\u63d0\u5347\u4e86BNCs\u5728\u5206\u7c7b\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u7075\u6d3b\u6027\u5dee\u4e14\u9700\u8981\u590d\u6742\u7684\u91c7\u6837\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u5bf9\u6570\u7ebf\u6027\u56de\u5f52\u6765\u8fd1\u4f3cHDPs\u7684\u884c\u4e3a\u3002\u4f5c\u4e3a\u4e00\u79cd\u7ebf\u6027\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u7075\u6d3b\u4e14\u6613\u4e8e\u89e3\u91ca\uff0c\u53ef\u4ee5\u5229\u7528\u4e30\u5bcc\u7684\u7ebf\u6027\u6a21\u578b\u5b66\u4e60\u6587\u732e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u8d85\u8d8aHDP\u5e73\u6ed1\u6280\u672f\uff0c\u800c\u4e14\u901f\u5ea6\u63d0\u9ad8\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u5728\u5206\u7c7b\u6570\u636e\u4e0a\u4ecd\u80fd\u4e0e\u968f\u673a\u68ee\u6797\u7ade\u4e89\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bf9\u6570\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\u4e3aBNCs\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u5f0f\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2505.23432", "pdf": "https://arxiv.org/pdf/2505.23432", "abs": "https://arxiv.org/abs/2505.23432", "authors": ["Elisa Celis", "Lingxiao Huang", "Nisheeth K. Vishnoi"], "title": "A Mathematical Framework for AI-Human Integration in Work", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC"], "comment": "This paper will appear in ICML 2025", "summary": "The rapid rise of Generative AI (GenAI) tools has sparked debate over their\nrole in complementing or replacing human workers across job contexts. We\npresent a mathematical framework that models jobs, workers, and worker-job fit,\nintroducing a novel decomposition of skills into decision-level and\naction-level subskills to reflect the complementary strengths of humans and\nGenAI. We analyze how changes in subskill abilities affect job success,\nidentifying conditions for sharp transitions in success probability. We also\nestablish sufficient conditions under which combining workers with\ncomplementary subskills significantly outperforms relying on a single worker.\nThis explains phenomena such as productivity compression, where GenAI\nassistance yields larger gains for lower-skilled workers. We demonstrate the\nframework' s practicality using data from O*NET and Big-Bench Lite, aligning\nreal-world data with our model via subskill-division methods. Our results\nhighlight when and how GenAI complements human skills, rather than replacing\nthem.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u5de5\u5177\u7684\u8fc5\u901f\u5d1b\u8d77\u5f15\u53d1\u4e86\u5173\u4e8e\u5176\u5728\u4e0d\u540c\u5de5\u4f5c\u73af\u5883\u4e2d\u662f\u8865\u5145\u8fd8\u662f\u53d6\u4ee3\u4eba\u7c7b\u5de5\u4f5c\u8005\u7684\u89d2\u8272\u7684\u8ba8\u8bba\u3002\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u6a21\u62df\u5de5\u4f5c\u3001\u5de5\u4f5c\u8005\u548c\u5de5\u4f5c\u8005-\u5de5\u4f5c\u7684\u5339\u914d\u5ea6\uff0c\u5c06\u6280\u80fd\u5206\u89e3\u4e3a\u51b3\u7b56\u7ea7\u548c\u884c\u52a8\u7ea7\u5b50\u6280\u80fd\uff0c\u4ee5\u53cd\u6620\u4eba\u7c7b\u548cGenAI\u7684\u4e92\u8865\u4f18\u52bf\u3002\u5206\u6790\u4e86\u5b50\u6280\u80fd\u80fd\u529b\u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u5de5\u4f5c\u6210\u529f\uff0c\u5e76\u786e\u5b9a\u4e86\u6210\u529f\u6982\u7387\u6025\u5267\u53d8\u5316\u7684\u6761\u4ef6\u3002\u540c\u65f6\uff0c\u5efa\u7acb\u4e86\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u7ed3\u5408\u5177\u6709\u4e92\u8865\u5b50\u6280\u80fd\u7684\u5de5\u4f5c\u8005\u663e\u8457\u4f18\u4e8e\u4f9d\u8d56\u5355\u4e00\u5de5\u4f5c\u8005\u7684\u5145\u5206\u6761\u4ef6\u3002\u8fd9\u89e3\u91ca\u4e86\u8bf8\u5982\u751f\u4ea7\u529b\u538b\u7f29\u7b49\u73b0\u8c61\uff0c\u5373GenAI\u8f85\u52a9\u5bf9\u4f4e\u6280\u80fd\u5de5\u4f5c\u8005\u4ea7\u751f\u66f4\u5927\u7684\u6536\u76ca\u3002\u901a\u8fc7O*NET\u548cBig-Bench Lite\u7684\u6570\u636e\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u7ed3\u679c\u5f3a\u8c03\u4e86GenAI\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u8865\u5145\u4eba\u7c7b\u6280\u80fd\uff0c\u800c\u975e\u53d6\u4ee3\u5b83\u4eec\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\u5f15\u53d1\u4e86\u5bf9\u5176\u5728\u5de5\u4f5c\u4e2d\u66ff\u4ee3\u6216\u8865\u5145\u4eba\u7c7b\u89d2\u8272\u7684\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u6846\u67b6\u6765\u7406\u89e3\u4eba\u7c7b\u4e0eGenAI\u7684\u6280\u80fd\u4e92\u8865\u6027\u53ca\u5176\u5bf9\u5de5\u4f5c\u6210\u529f\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u6280\u80fd\u5206\u89e3\u4e3a\u51b3\u7b56\u7ea7\u548c\u884c\u52a8\u7ea7\u5b50\u6280\u80fd\uff0c\u6a21\u62df\u5de5\u4f5c\u3001\u5de5\u4f5c\u8005\u53ca\u4e24\u8005\u5339\u914d\u5173\u7cfb\uff0c\u4f7f\u7528O*NET\u548cBig-Bench Lite\u6570\u636e\u9a8c\u8bc1\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "result": "\u786e\u5b9a\u4e86\u5b50\u6280\u80fd\u80fd\u529b\u53d8\u5316\u5bf9\u5de5\u4f5c\u6210\u529f\u7684\u5177\u4f53\u5f71\u54cd\u6761\u4ef6\uff0c\u8bc1\u660e\u4e86\u4e92\u8865\u5b50\u6280\u80fd\u7ec4\u5408\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u89e3\u91ca\u4e86\u751f\u4ea7\u529b\u538b\u7f29\u73b0\u8c61\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u80fd\u591f\u6709\u6548\u8865\u5145\u4eba\u7c7b\u6280\u80fd\uff0c\u7279\u522b\u662f\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u800c\u975e\u7b80\u5355\u5730\u53d6\u4ee3\u4eba\u7c7b\u5de5\u4f5c\u8005\u3002"}}
{"id": "2505.23496", "pdf": "https://arxiv.org/pdf/2505.23496", "abs": "https://arxiv.org/abs/2505.23496", "authors": ["Sabina J. Sloman", "Michele Caprio", "Samuel Kaski"], "title": "Epistemic Errors of Imperfect Multitask Learners When Distributions Shift", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When data are noisy, a statistical learner's goal is to resolve epistemic\nuncertainty about the data it will encounter at test-time, i.e., to identify\nthe distribution of test (target) data. Many real-world learning settings\nintroduce sources of epistemic uncertainty that can not be resolved on the\nbasis of training (source) data alone: The source data may arise from multiple\ntasks (multitask learning), the target data may differ systematically from the\nsource data tasks (distribution shift), and/or the learner may not arrive at an\naccurate characterization of the source data (imperfect learning). We introduce\na principled definition of epistemic error, and provide a generic,\ndecompositional epistemic error bound. Our error bound is the first to (i)\nconsider epistemic error specifically, (ii) accommodate all the sources of\nepistemic uncertainty above, and (iii) separately attribute the error to each\nof multiple aspects of the learning procedure and environment. As corollaries\nof the generic result, we provide (i) epistemic error bounds specialized to the\nsettings of Bayesian transfer learning and distribution shift within\n$\\epsilon$-neighborhoods, and (ii) a set of corresponding generalization\nbounds. Finally, we provide a novel definition of negative transfer, and\nvalidate its insights in a synthetic experimental setting.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u8ba4\u77e5\u8bef\u5dee\u7684\u5b9a\u4e49\u548c\u901a\u7528\u5206\u89e3\u5f0f\u8ba4\u77e5\u8bef\u5dee\u754c\u9650\uff0c\u9996\u6b21\u4e13\u95e8\u9488\u5bf9\u8ba4\u77e5\u8bef\u5dee\u8fdb\u884c\u8003\u91cf\uff0c\u5e76\u6db5\u76d6\u4e86\u591a\u79cd\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u8d1d\u53f6\u65af\u8fc1\u79fb\u5b66\u4e60\u548c\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u7684\u5177\u4f53\u8bef\u5dee\u754c\u9650\u4ee5\u53ca\u6cdb\u5316\u754c\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1f\u8fc1\u79fb\u5b9a\u4e49\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u6570\u636e\u566a\u58f0\u8f83\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u7edf\u8ba1\u5b66\u4e60\u8005\u9700\u8981\u89e3\u51b3\u6d4b\u8bd5\u65f6\u9047\u5230\u7684\u6570\u636e\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5373\u8bc6\u522b\u6d4b\u8bd5\u6570\u636e\u7684\u5206\u5e03\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u5b9e\u4e2d\u7684\u5b66\u4e60\u573a\u666f\u4e2d\u5b58\u5728\u65e0\u6cd5\u4ec5\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u89e3\u51b3\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\uff0c\u5982\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u76ee\u6807\u6570\u636e\u4e0e\u6e90\u6570\u636e\u7cfb\u7edf\u6027\u5dee\u5f02\uff08\u5206\u5e03\u504f\u79fb\uff09\u4ee5\u53ca\u4e0d\u5b8c\u7f8e\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u5b9a\u4e49\u548c\u5206\u6790\u8ba4\u77e5\u8bef\u5dee\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u8ba4\u77e5\u8bef\u5dee\u7684\u5b9a\u4e49\u548c\u901a\u7528\u5206\u89e3\u5f0f\u8ba4\u77e5\u8bef\u5dee\u754c\u9650\u3002\u8be5\u754c\u9650\u8003\u8651\u4e86\u6240\u6709\u53ef\u80fd\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\uff0c\u5e76\u5206\u522b\u5f52\u56e0\u4e8e\u5b66\u4e60\u8fc7\u7a0b\u548c\u73af\u5883\u7684\u591a\u4e2a\u65b9\u9762\u3002\u540c\u65f6\uff0c\u63a8\u5bfc\u51fa\u9002\u7528\u4e8e\u8d1d\u53f6\u65af\u8fc1\u79fb\u5b66\u4e60\u548c\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u7684\u5177\u4f53\u8ba4\u77e5\u8bef\u5dee\u754c\u9650\u53ca\u6cdb\u5316\u754c\u9650\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1f\u8fc1\u79fb\u5b9a\u4e49\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u5f97\u5230\u4e86\u8ba4\u77e5\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u7279\u5b9a\u7684\u5b66\u4e60\u573a\u666f\uff0c\u5982\u8d1d\u53f6\u65af\u8fc1\u79fb\u5b66\u4e60\u548c\u5206\u5e03\u504f\u79fb\u3002\u6b64\u5916\uff0c\u5728\u5408\u6210\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b0\u63d0\u51fa\u7684\u8d1f\u8fc1\u79fb\u5b9a\u4e49\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u4e3a\u8ba4\u77e5\u8bef\u5dee\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u5b9a\u4e49\u548c\u901a\u7528\u7684\u5206\u89e3\u5f0f\u754c\u9650\uff0c\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u91cf\u5316\u5404\u79cd\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u540c\u65f6\uff0c\u65b0\u7684\u8d1f\u8fc1\u79fb\u5b9a\u4e49\u4e5f\u4e3a\u8fc1\u79fb\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.23436", "pdf": "https://arxiv.org/pdf/2505.23436", "abs": "https://arxiv.org/abs/2505.23436", "authors": ["Daniel Jarne Ornia", "Nicholas Bishop", "Joel Dyer", "Wei-Chen Lee", "Ani Calinescu", "Doyne Farme", "Michael Wooldridge"], "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Advanced reasoning models with agentic capabilities (AI agents) are deployed\nto interact with humans and to solve sequential decision-making problems under\n(approximate) utility functions and internal models. When such problems have\nresource or failure constraints where action sequences may be forcibly\nterminated once resources are exhausted, agents face implicit trade-offs that\nreshape their utility-driven (rational) behaviour. Additionally, since these\nagents are typically commissioned by a human principal to act on their behalf,\nasymmetries in constraint exposure can give rise to previously unanticipated\nmisalignment between human objectives and agent incentives. We formalise this\nsetting through a survival bandit framework, provide theoretical and empirical\nresults that quantify the impact of survival-driven preference shifts, identify\nconditions under which misalignment emerges and propose mechanisms to mitigate\nthe emergence of risk-seeking or risk-averse behaviours. As a result, this work\naims to increase understanding and interpretability of emergent behaviours of\nAI agents operating under such survival pressure, and offer guidelines for\nsafely deploying such AI systems in critical resource-limited environments.", "AI": {"tldr": "\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\uff08AI\u4ee3\u7406\uff09\u88ab\u90e8\u7f72\u7528\u4e8e\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u548c\u89e3\u51b3\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u3002\u5728\u8d44\u6e90\u6216\u5931\u8d25\u7ea6\u675f\u4e0b\uff0c\u4ee3\u7406\u9762\u4e34\u9690\u542b\u7684\u6743\u8861\uff0c\u53ef\u80fd\u5f15\u53d1\u4e0e\u4eba\u7c7b\u76ee\u6807\u7684\u4e0d\u4e00\u81f4\u3002\u672c\u6587\u901a\u8fc7\u751f\u5b58\u5f3a\u76d7\u6846\u67b6\u5bf9\u6b64\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\uff0c\u5e76\u63d0\u51fa\u7f13\u89e3\u98ce\u9669\u884c\u4e3a\u7684\u673a\u5236\u3002", "motivation": "\u5728\u8d44\u6e90\u6709\u9650\u6216\u53ef\u80fd\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\uff0cAI\u4ee3\u7406\u7684\u884c\u4e3a\u4f1a\u53d7\u5230\u751f\u5b58\u538b\u529b\u7684\u5f71\u54cd\uff0c\u4ea7\u751f\u610f\u60f3\u4e0d\u5230\u7684\u98ce\u9669\u504f\u597d\u6216\u89c4\u907f\u884c\u4e3a\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0e\u4eba\u7c7b\u76ee\u6807\u7684\u4e0d\u4e00\u81f4\u3002", "method": "\u901a\u8fc7\u751f\u5b58\u5f3a\u76d7\u6846\u67b6\u5f62\u5f0f\u5316\u8be5\u95ee\u9898\uff0c\u5206\u6790\u751f\u5b58\u9a71\u52a8\u504f\u597d\u8f6c\u79fb\u7684\u5f71\u54cd\uff0c\u8bc6\u522b\u4e0d\u4e00\u81f4\u51fa\u73b0\u7684\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u7f13\u89e3\u98ce\u9669\u884c\u4e3a\u7684\u673a\u5236\u3002", "result": "\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\uff0c\u91cf\u5316\u4e86\u751f\u5b58\u9a71\u52a8\u504f\u597d\u8f6c\u79fb\u7684\u5f71\u54cd\uff0c\u5e76\u786e\u5b9a\u4e86\u5bfc\u81f4\u4e0d\u4e00\u81f4\u7684\u6761\u4ef6\u3002", "conclusion": "\u672c\u5de5\u4f5c\u65e8\u5728\u63d0\u9ad8\u5bf9AI\u4ee3\u7406\u5728\u751f\u5b58\u538b\u529b\u4e0b\u7684\u65b0\u5174\u884c\u4e3a\u7684\u7406\u89e3\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e3a\u5728\u5173\u952e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b89\u5168\u90e8\u7f72AI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2505.23599", "pdf": "https://arxiv.org/pdf/2505.23599", "abs": "https://arxiv.org/abs/2505.23599", "authors": ["Eitan Levin", "Yuxin Ma", "Mateo D\u00edaz", "Soledad Villar"], "title": "On Transferring Transferability: Towards a Theory for Size Generalization", "categories": ["cs.LG", "math.RT", "math.ST", "stat.ML", "stat.TH"], "comment": "69 pages, 8 figures", "summary": "Many modern learning tasks require models that can take inputs of varying\nsizes. Consequently, dimension-independent architectures have been proposed for\ndomains where the inputs are graphs, sets, and point clouds. Recent work on\ngraph neural networks has explored whether a model trained on low-dimensional\ndata can transfer its performance to higher-dimensional inputs. We extend this\nbody of work by introducing a general framework for transferability across\ndimensions. We show that transferability corresponds precisely to continuity in\na limit space formed by identifying small problem instances with equivalent\nlarge ones. This identification is driven by the data and the learning task. We\ninstantiate our framework on existing architectures, and implement the\nnecessary changes to ensure their transferability. Finally, we provide design\nprinciples for designing new transferable models. Numerical experiments support\nour findings.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u7ef4\u5ea6\u53ef\u8f6c\u79fb\u6027\u7684\u901a\u7528\u6846\u67b6\uff0c\u5c06\u8f6c\u79fb\u6027\u4e0e\u6781\u9650\u7a7a\u95f4\u4e2d\u7684\u8fde\u7eed\u6027\u76f8\u5bf9\u5e94\uff0c\u5e76\u5728\u73b0\u6709\u67b6\u6784\u4e0a\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u65b0\u7684\u53ef\u8f6c\u79fb\u6a21\u578b\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u73b0\u4ee3\u5b66\u4e60\u4efb\u52a1\u9700\u8981\u80fd\u591f\u5904\u7406\u4e0d\u540c\u5927\u5c0f\u8f93\u5165\u7684\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u56fe\u3001\u96c6\u5408\u548c\u70b9\u4e91\u7b49\u9886\u57df\u3002\u5df2\u6709\u7814\u7a76\u63a2\u8ba8\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u4f4e\u7ef4\u6570\u636e\u4e0a\u8bad\u7ec3\u540e\u662f\u5426\u80fd\u8f6c\u79fb\u5230\u9ad8\u7ef4\u8f93\u5165\u4e2d\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u8fd9\u4e00\u7814\u7a76\u9886\u57df\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u6765\u63cf\u8ff0\u8de8\u7ef4\u5ea6\u7684\u53ef\u8f6c\u79fb\u6027\uff1b\u901a\u8fc7\u5728\u6781\u9650\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u5c0f\u95ee\u9898\u5b9e\u4f8b\u4e0e\u7b49\u4ef7\u5927\u95ee\u9898\u5b9e\u4f8b\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5efa\u7acb\u53ef\u8f6c\u79fb\u6027\u4e0e\u8fde\u7eed\u6027\u7684\u8054\u7cfb\uff1b\u5bf9\u73b0\u6709\u67b6\u6784\u8fdb\u884c\u4fee\u6539\u4ee5\u786e\u4fdd\u5176\u53ef\u8f6c\u79fb\u6027\uff0c\u5e76\u63d0\u4f9b\u8bbe\u8ba1\u65b0\u53ef\u8f6c\u79fb\u6a21\u578b\u7684\u539f\u5219\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u53ef\u8f6c\u79fb\u6027\u4e0e\u6781\u9650\u7a7a\u95f4\u4e2d\u7684\u8fde\u7eed\u6027\u76f8\u5bf9\u5e94\uff1b\u901a\u8fc7\u5bf9\u73b0\u6709\u67b6\u6784\u7684\u4fee\u6539\u9a8c\u8bc1\u4e86\u5176\u53ef\u8f6c\u79fb\u6027\uff1b\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u7528\u4e8e\u7406\u89e3\u8de8\u7ef4\u5ea6\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u53ef\u8f6c\u79fb\u6a21\u578b\u7684\u539f\u5219\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.23473", "pdf": "https://arxiv.org/pdf/2505.23473", "abs": "https://arxiv.org/abs/2505.23473", "authors": ["Xiaorui Wu", "Xiaofeng Mao", "Fei Li", "Xin Zhang", "Xiaolu Zhang", "Jun Zhou", "Yuxiang Peng", "Li Zheng", "Chong Teng", "Donghong Ji", "Zhuang Li"], "title": "EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) frequently refuse to respond to pseudo-malicious\ninstructions: semantically harmless input queries triggering unnecessary LLM\nrefusals due to conservative safety alignment, significantly impairing user\nexperience. Collecting such instructions is crucial for evaluating and\nmitigating over-refusals, but existing instruction curation methods, like\nmanual creation or instruction rewriting, either lack scalability or fail to\nproduce sufficiently diverse and effective refusal-inducing prompts. To address\nthese limitations, we introduce EVOREFUSE, a prompt optimization approach that\ngenerates diverse pseudo-malicious instructions consistently eliciting\nconfident refusals across LLMs. EVOREFUSE employs an evolutionary algorithm\nexploring the instruction space in more diverse directions than existing\nmethods via mutation strategies and recombination, and iteratively evolves seed\ninstructions to maximize evidence lower bound on LLM refusal probability. Using\nEVOREFUSE, we create two novel datasets: EVOREFUSE-TEST, a benchmark of 582\npseudo-malicious instructions that outperforms the next-best benchmark with\n140.41% higher average refusal triggering rate across 9 LLMs, 34.86% greater\nlexical diversity, and 40.03% improved LLM response confidence scores; and\nEVOREFUSE-ALIGN, which provides 3,000 pseudo-malicious instructions with\nresponses for supervised and preference-based alignment training.\nLLAMA3.1-8B-INSTRUCT supervisedly fine-tuned on EVOREFUSE-ALIGN achieves up to\n14.31% fewer over-refusals than models trained on the second-best alignment\ndataset, without compromising safety. Our analysis with EVOREFUSE-TEST reveals\nmodels trigger over-refusals by overly focusing on sensitive keywords while\nignoring broader context.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e38\u56e0\u4fdd\u5b88\u7684\u5b89\u5168\u5bf9\u9f50\u800c\u62d2\u7edd\u65e0\u5bb3\u7684\u8f93\u5165\u67e5\u8be2\uff0c\u635f\u5bb3\u7528\u6237\u4f53\u9a8c\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEVOREFUSE\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u751f\u6210\u591a\u6837\u7684\u4f2a\u6076\u610f\u6307\u4ee4\uff0c\u4ee5\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u62d2\u7edd\u73b0\u8c61\u3002\u8be5\u65b9\u6cd5\u521b\u5efa\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\uff1aEVOREFUSE-TEST\u548cEVOREFUSE-ALIGN\uff0c\u5206\u522b\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528EVOREFUSE-ALIGN\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u7684LLAMA3.1-8B-INSTRUCT\u6a21\u578b\u5728\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u540c\u65f6\u4e0d\u4f1a\u964d\u4f4e\u5b89\u5168\u6027\u3002\u5206\u6790\u8fd8\u53d1\u73b0\uff0c\u6a21\u578b\u8fc7\u5ea6\u5173\u6ce8\u654f\u611f\u5173\u952e\u8bcd\u800c\u5ffd\u7565\u4e0a\u4e0b\u6587\u662f\u5bfc\u81f4\u8fc7\u5ea6\u62d2\u7edd\u7684\u4e3b\u8981\u539f\u56e0\u3002", "motivation": "\u73b0\u6709\u7684\u6536\u96c6\u4f2a\u6076\u610f\u6307\u4ee4\u7684\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\uff0c\u8981\u4e48\u65e0\u6cd5\u751f\u6210\u8db3\u591f\u591a\u6837\u548c\u6709\u6548\u7684\u62d2\u7edd\u8bf1\u5bfc\u63d0\u793a\uff0c\u8fd9\u9650\u5236\u4e86\u5bf9LLMs\u8fc7\u5ea6\u62d2\u7edd\u73b0\u8c61\u7684\u7814\u7a76\u548c\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u4e86EVOREFUSE\uff0c\u4e00\u79cd\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u7b56\u7565\u548c\u91cd\u7ec4\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u6307\u4ee4\u7a7a\u95f4\uff0c\u8fed\u4ee3\u6f14\u5316\u79cd\u5b50\u6307\u4ee4\u4ee5\u6700\u5927\u5316LLMs\u62d2\u7edd\u6982\u7387\u7684\u4e0b\u754c\u3002", "result": "1. \u521b\u5efa\u4e86EVOREFUSE-TEST\u6570\u636e\u96c6\uff0c\u5305\u542b582\u4e2a\u4f2a\u6076\u610f\u6307\u4ee4\uff0c\u6bd4\u6b21\u4f18\u57fa\u51c6\u9ad8\u51fa140.41%\u7684\u5e73\u5747\u62d2\u7edd\u89e6\u53d1\u7387\uff0c\u8bcd\u6c47\u591a\u6837\u6027\u63d0\u9ad834.86%\uff0cLLM\u54cd\u5e94\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u63d0\u534740.03%\u3002\n2. \u521b\u5efa\u4e86EVOREFUSE-ALIGN\u6570\u636e\u96c6\uff0c\u63d0\u4f9b3,000\u4e2a\u4f2a\u6076\u610f\u6307\u4ee4\u53ca\u5176\u54cd\u5e94\uff0c\u7528\u4e8e\u76d1\u7763\u548c\u504f\u597d\u5bf9\u9f50\u8bad\u7ec3\u3002\n3. \u4f7f\u7528EVOREFUSE-ALIGN\u76d1\u7763\u5fae\u8c03\u7684LLAMA3.1-8B-INSTRUCT\u6a21\u578b\uff0c\u8fc7\u5ea6\u62d2\u7edd\u51cf\u5c11\u4e8614.31%\uff0c\u4e14\u672a\u727a\u7272\u5b89\u5168\u6027\u3002", "conclusion": "EVOREFUSE\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u4f2a\u6076\u610f\u6307\u4ee4\uff0c\u5e2e\u52a9\u8bc4\u4f30\u548c\u7f13\u89e3LLMs\u7684\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\u3002\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406\u8f93\u5165\u65f6\u8fc7\u5ea6\u4f9d\u8d56\u654f\u611f\u5173\u952e\u8bcd\u7684\u95ee\u9898\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdbLLMs\u7684\u5b89\u5168\u6027\u548c\u7528\u6237\u4f53\u9a8c\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2505.23614", "pdf": "https://arxiv.org/pdf/2505.23614", "abs": "https://arxiv.org/abs/2505.23614", "authors": ["Xiangcheng Zhang", "Haowei Lin", "Haotian Ye", "James Zou", "Jianzhu Ma", "Yitao Liang", "Yilun Du"], "title": "Inference-time Scaling of Diffusion Models through Classical Search", "categories": ["cs.LG", "stat.ML"], "comment": "Website at https://diffusion-inference-scaling.github.io/", "summary": "Classical search algorithms have long underpinned modern artificial\nintelligence. In this work, we tackle the challenge of inference-time control\nin diffusion models -- adapting generated outputs to meet diverse test-time\nobjectives -- using principles from classical search. We propose a general\nframework that orchestrates local and global search to efficiently navigate the\ngenerative space. It employs a theoretically grounded local search via annealed\nLangevin MCMC and performs compute-efficient global exploration using\nbreadth-first and depth-first tree search. We evaluate our approach on a range\nof challenging domains, including planning, offline reinforcement learning, and\nimage generation. Across all tasks, we observe significant gains in both\nperformance and efficiency. These results show that classical search provides a\nprincipled and practical foundation for inference-time scaling in diffusion\nmodels. Project page at diffusion-inference-scaling.github.io.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u641c\u7d22\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u63a8\u7406\u65f6\u95f4\u63a7\u5236\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9000\u706bLangevin MCMC\u8fdb\u884c\u5c40\u90e8\u641c\u7d22\uff0c\u5e76\u4f7f\u7528\u5e7f\u5ea6\u4f18\u5148\u548c\u6df1\u5ea6\u4f18\u5148\u6811\u641c\u7d22\u8fdb\u884c\u5168\u5c40\u63a2\u7d22\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u63a8\u7406\u65f6\u9002\u5e94\u591a\u6837\u5316\u76ee\u6807\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u501f\u9274\u7ecf\u5178\u641c\u7d22\u7b97\u6cd5\u7684\u539f\u7406\uff0c\u4ee5\u63d0\u9ad8\u6269\u6563\u6a21\u578b\u5728\u63a8\u7406\u65f6\u95f4\u4e0a\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u5c06\u5c40\u90e8\u641c\u7d22\uff08\u57fa\u4e8e\u9000\u706bLangevin MCMC\uff09\u4e0e\u5168\u5c40\u641c\u7d22\uff08\u57fa\u4e8e\u5e7f\u5ea6\u4f18\u5148\u548c\u6df1\u5ea6\u4f18\u5148\u6811\u641c\u7d22\uff09\u76f8\u7ed3\u5408\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u63a2\u7d22\u751f\u6210\u7a7a\u95f4\u3002", "result": "\u5728\u5305\u62ec\u89c4\u5212\u3001\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u56fe\u50cf\u751f\u6210\u7b49\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u9886\u57df\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "conclusion": "\u7ecf\u5178\u641c\u7d22\u7b97\u6cd5\u4e3a\u6269\u6563\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u4e14\u5b9e\u7528\u7684\u57fa\u7840\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2505.23474", "pdf": "https://arxiv.org/pdf/2505.23474", "abs": "https://arxiv.org/abs/2505.23474", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Process Reward Models (PRMs) are crucial in complex reasoning and\nproblem-solving tasks (e.g., LLM agents with long-horizon decision-making) by\nverifying the correctness of each intermediate reasoning step. In real-world\nscenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to\nsolve a problem, potentially suffering from errors under various reasoning\npatterns. Therefore, PRMs are required to identify errors under various\nreasoning patterns during the reasoning process. However, existing benchmarks\nmainly focus on evaluating PRMs with stepwise correctness, ignoring a\nsystematic evaluation of PRMs under various reasoning patterns. To mitigate\nthis gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs\nsystematically under six reasoning patterns, including Transformation,\nDecomposition, Regather, Deduction, Verification, and Integration.\nSocratic-PRMBench}comprises 2995 reasoning paths with flaws within the\naforementioned six reasoning patterns. Through our experiments on both PRMs and\nLLMs prompted as critic models, we identify notable deficiencies in existing\nPRMs. These observations underscore the significant weakness of current PRMs in\nconducting evaluations on reasoning steps under various reasoning patterns. We\nhope Socratic-PRMBench can serve as a comprehensive testbed for systematic\nevaluation of PRMs under diverse reasoning patterns and pave the way for future\ndevelopment of PRMs.", "AI": {"tldr": "Process Reward Models (PRMs) are vital for complex reasoning tasks. However, current benchmarks fall short in systematically evaluating PRMs across various reasoning patterns. This paper introduces Socratic-PRMBench, a new benchmark with 2995 flawed reasoning paths across six reasoning patterns, revealing deficiencies in existing PRMs and providing a foundation for their future development.", "motivation": "Current benchmarks for evaluating PRMs focus on stepwise correctness but lack systematic evaluation across different reasoning patterns, which is crucial for identifying errors in complex reasoning processes.", "method": "The paper proposes Socratic-PRMBench, a benchmark containing 2995 flawed reasoning paths under six reasoning patterns (Transformation, Decomposition, Regather, Deduction, Verification, Integration). It evaluates both PRMs and LLMs prompted as critic models.", "result": "Experiments using Socratic-PRMBench identified significant deficiencies in existing PRMs when evaluating reasoning steps under various patterns.", "conclusion": "Socratic-PRMBench serves as a comprehensive testbed for the systematic evaluation of PRMs under diverse reasoning patterns, highlighting areas for improvement and guiding future PRM development."}}
{"id": "2505.23720", "pdf": "https://arxiv.org/pdf/2505.23720", "abs": "https://arxiv.org/abs/2505.23720", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "This paper proposes a contextual bandit algorithm that prevents\n  strategic agents from misreporting while having approximate incentive\n  compatibility and a sub-linear regret guarantee", "summary": "This paper considers a contextual bandit problem involving multiple agents,\nwhere a learner sequentially observes the contexts and the agent's reported\narms, and then selects the arm that maximizes the system's overall reward.\nExisting work in contextual bandits assumes that agents truthfully report their\narms, which is unrealistic in many real-life applications. For instance,\nconsider an online platform with multiple sellers; some sellers may\nmisrepresent product quality to gain an advantage, such as having the platform\npreferentially recommend their products to online users. To address this\nchallenge, we propose an algorithm, COBRA, for contextual bandit problems\ninvolving strategic agents that disincentivize their strategic behavior without\nusing any monetary incentives, while having incentive compatibility and a\nsub-linear regret guarantee. Our experimental results also validate the\ndifferent performance aspects of our proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u73af\u5883\u4e0b\u7684\u60c5\u5883\u5f3a\u76d7\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCOBRA\u7684\u7b97\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u975e\u8d27\u5e01\u6fc0\u52b1\u624b\u6bb5\u51cf\u5c11\u4ee3\u7406\u7684\u6218\u7565\u884c\u4e3a\uff0c\u5e76\u4fdd\u8bc1\u6fc0\u52b1\u517c\u5bb9\u6027\u548c\u6b21\u7ebf\u6027\u540e\u6094\u754c\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u4e0d\u540c\u6027\u80fd\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u60c5\u5883\u5f3a\u76d7\u95ee\u9898\u7814\u7a76\u5047\u8bbe\u4ee3\u7406\u4f1a\u5982\u5b9e\u62a5\u544a\u5176\u81c2\u9009\u62e9\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4f8b\u5982\u5728\u7ebf\u5e73\u53f0\u4e0a\uff0c\u5356\u5bb6\u53ef\u80fd\u4f1a\u865a\u62a5\u4ea7\u54c1\u8d28\u91cf\u4ee5\u83b7\u5f97\u4f18\u52bf\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u627e\u4e00\u79cd\u65b9\u6cd5\u6765\u51cf\u5c11\u4ee3\u7406\u7684\u6218\u7565\u884c\u4e3a\uff0c\u540c\u65f6\u4e0d\u4f7f\u7528\u8d27\u5e01\u6fc0\u52b1\u3002", "method": "\u63d0\u51fa\u4e86COBRA\u7b97\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u6d89\u53ca\u6218\u7565\u6027\u4ee3\u7406\u7684\u60c5\u5883\u5f3a\u76d7\u95ee\u9898\u3002\u8be5\u7b97\u6cd5\u65e8\u5728\u51cf\u5c11\u4ee3\u7406\u7684\u6218\u7565\u884c\u4e3a\uff0c\u5177\u6709\u6fc0\u52b1\u517c\u5bb9\u6027\uff0c\u5e76\u4fdd\u8bc1\u6b21\u7ebf\u6027\u540e\u6094\u754c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86COBRA\u7b97\u6cd5\u5728\u4e0d\u540c\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "COBRA\u7b97\u6cd5\u80fd\u591f\u5728\u4e0d\u4f7f\u7528\u8d27\u5e01\u6fc0\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u51cf\u5c11\u4ee3\u7406\u7684\u6218\u7565\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u6fc0\u52b1\u517c\u5bb9\u6027\u548c\u8f83\u4f4e\u7684\u540e\u6094\u754c\u3002"}}
{"id": "2505.23486", "pdf": "https://arxiv.org/pdf/2505.23486", "abs": "https://arxiv.org/abs/2505.23486", "authors": ["Ke Weng", "Lun Du", "Sirui Li", "Wangyue Lu", "Haozhe Sun", "Hengyu Liu", "Tiancheng Zhang"], "title": "Autoformalization in the Era of Large Language Models: A Survey", "categories": ["cs.AI"], "comment": null, "summary": "Autoformalization, the process of transforming informal mathematical\npropositions into verifiable formal representations, is a foundational task in\nautomated theorem proving, offering a new perspective on the use of mathematics\nin both theoretical and applied domains. Driven by the rapid progress in\nartificial intelligence, particularly large language models (LLMs), this field\nhas witnessed substantial growth, bringing both new opportunities and unique\nchallenges. In this survey, we provide a comprehensive overview of recent\nadvances in autoformalization from both mathematical and LLM-centric\nperspectives. We examine how autoformalization is applied across various\nmathematical domains and levels of difficulty, and analyze the end-to-end\nworkflow from data preprocessing to model design and evaluation. We further\nexplore the emerging role of autoformalization in enhancing the verifiability\nof LLM-generated outputs, highlighting its potential to improve both the\ntrustworthiness and reasoning capabilities of LLMs. Finally, we summarize key\nopen-source models and datasets supporting current research, and discuss open\nchallenges and promising future directions for the field.", "AI": {"tldr": "\u81ea\u52a8\u5f62\u5f0f\u5316\uff08Autoformalization\uff09\u662f\u5c06\u975e\u6b63\u5f0f\u6570\u5b66\u547d\u9898\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u8868\u793a\u7684\u8fc7\u7a0b\uff0c\u662f\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u57fa\u7840\u4efb\u52a1\u3002\u672c\u6587\u7efc\u8ff0\u4e86\u8be5\u9886\u57df\u5728\u6570\u5b66\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89c6\u89d2\u4e0b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86\u5176\u5e94\u7528\u3001\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u53ca\u5bf9LLM\u8f93\u51fa\u7684\u6539\u8fdb\u4f5c\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u5f00\u6e90\u6a21\u578b\u3001\u6311\u6218\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u81ea\u52a8\u5f62\u5f0f\u5316\u4e3a\u6570\u5b66\u5728\u7406\u8bba\u4e0e\u5e94\u7528\u9886\u57df\u7684\u4f7f\u7528\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u540c\u65f6\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8be5\u9886\u57df\u5c55\u73b0\u51fa\u65b0\u7684\u673a\u9047\u4e0e\u6311\u6218\u3002", "method": "\u4ece\u6570\u5b66\u548cLLM\u4e24\u4e2a\u89d2\u5ea6\u56de\u987e\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u8fdb\u5c55\uff1b\u7814\u7a76\u5176\u5728\u4e0d\u540c\u6570\u5b66\u9886\u57df\u548c\u96be\u5ea6\u7ea7\u522b\u7684\u5e94\u7528\uff1b\u5206\u6790\u7aef\u5230\u7aef\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u3001\u6a21\u578b\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\uff1b\u63a2\u7d22\u81ea\u52a8\u5f62\u5f0f\u5316\u5728\u63d0\u9ad8LLM\u751f\u6210\u8f93\u51fa\u53ef\u4fe1\u5ea6\u548c\u63a8\u7406\u80fd\u529b\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u603b\u7ed3\u4e86\u652f\u6301\u5f53\u524d\u7814\u7a76\u7684\u5f00\u6e90\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u51fa\u5f00\u653e\u6027\u6311\u6218\u5e76\u63d0\u51fa\u4e86\u6709\u524d\u666f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u81ea\u52a8\u5f62\u5f0f\u5316\u5728\u63d0\u5347LLM\u7684\u53ef\u4fe1\u5ea6\u548c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4ee5\u63a8\u52a8\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2505.22686", "pdf": "https://arxiv.org/pdf/2505.22686", "abs": "https://arxiv.org/abs/2505.22686", "authors": ["Ange-Clement Akazan", "Verlon Roel Mbingui", "Gnankan Landry Regis N'guessan", "Issa Karambal"], "title": "Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs", "categories": ["cs.LG"], "comment": null, "summary": "Weather forecasting is crucial for managing risks and economic planning,\nparticularly in tropical Africa, where extreme events severely impact\nlivelihoods. Yet, existing forecasting methods often struggle with the region's\ncomplex, non-linear weather patterns. This study benchmarks deep recurrent\nneural networks such as $\\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and\nKolmogorov-Arnold-based models $(\\texttt{KAN} and \\texttt{TKAN})$ for daily\nforecasting of temperature, precipitation, and pressure in two tropical cities:\nAbidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce\ntwo customized variants of $ \\texttt{TKAN}$ that replace its original\n$\\texttt{SiLU}$ activation function with $ \\texttt{GeLU}$ and \\texttt{MiSH},\nrespectively. Using station-level meteorological data spanning from 2010 to\n2024, we evaluate all the models on standard regression metrics. $\\texttt{KAN}$\nachieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,\n$\\texttt{MSE} < 0.0014~^\\circ C ^2$), while $\\texttt{TKAN}$ variants minimize\nabsolute errors for precipitation forecasting in low-rainfall regimes. The\ncustomized $\\texttt{TKAN}$ models demonstrate improvements over the standard\n$\\texttt{TKAN}$ across both datasets. Classical \\texttt{RNNs} remain highly\ncompetitive for atmospheric pressure ($R^2 \\approx 0.83{-}0.86$), outperforming\n$\\texttt{KAN}$-based models in this task. These results highlight the potential\nof spline-based neural architectures for efficient and data-efficient\nforecasting.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u70ed\u5e26\u975e\u6d32\u7684\u4e24\u4e2a\u57ce\u5e02\u963f\u6bd4\u8ba9\u548c\u57fa\u52a0\u5229\uff0c\u5bf9\u6bcf\u65e5\u6e29\u5ea6\u3001\u964d\u6c34\u548c\u6c14\u538b\u9884\u6d4b\u7684\u5404\u79cd\u6df1\u5ea6\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08\u5982LSTM\u3001GRU\u7b49\uff09\u53caKolmogorov-Arnold\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u5f15\u5165\u4e86\u4e24\u79cd\u6539\u8fdb\u7684TKAN\u6a21\u578b\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u6fc0\u6d3b\u51fd\u6570\uff08GeLU\u548cMiSH\uff09\u3002KAN\u6a21\u578b\u5728\u6e29\u5ea6\u9884\u6d4b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u6539\u8fdb\u7684TKAN\u6a21\u578b\u5728\u4f4e\u964d\u96e8\u91cf\u6761\u4ef6\u4e0b\u7684\u964d\u6c34\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u5bf9\u4e8e\u6c14\u538b\u9884\u6d4b\uff0c\u4f20\u7edf\u7684RNN\u6a21\u578b\u6548\u679c\u6700\u597d\u3002\u8fd9\u8868\u660e\u6837\u6761\u795e\u7ecf\u67b6\u6784\u5728\u9ad8\u6548\u6570\u636e\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5929\u6c14\u9884\u62a5\u5bf9\u4e8e\u7ba1\u7406\u98ce\u9669\u548c\u7ecf\u6d4e\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u4e25\u91cd\u5f71\u54cd\u751f\u8ba1\u7684\u70ed\u5e26\u975e\u6d32\u5730\u533a\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u9884\u6d4b\u65b9\u6cd5\u5e38\u5e38\u96be\u4ee5\u5e94\u5bf9\u8be5\u5730\u533a\u7684\u590d\u6742\u975e\u7ebf\u6027\u5929\u6c14\u6a21\u5f0f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u9884\u6d4b\u6a21\u578b\u6765\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u591a\u79cd\u6df1\u5ea6\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08\u5305\u62ecLSTM\u3001GRU\u3001BiLSTM\u3001BiGRU\uff09\u548c\u57fa\u4e8eKolmogorov-Arnold\u7684\u6a21\u578b\uff08KAN\u548cTKAN\uff09\uff0c\u5e76\u9488\u5bf9\u6bcf\u65e5\u6e29\u5ea6\u3001\u964d\u6c34\u548c\u6c14\u538b\u9884\u6d4b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u540c\u65f6\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9a\u5236\u7248\u7684TKAN\u6a21\u578b\uff0c\u5206\u522b\u7528GeLU\u548cMiSH\u66ff\u4ee3\u539f\u59cb\u7684SiLU\u6fc0\u6d3b\u51fd\u6570\u3002\u4f7f\u7528\u4ece2010\u5e74\u52302024\u5e74\u7684\u6c14\u8c61\u7ad9\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u91c7\u7528\u6807\u51c6\u56de\u5f52\u5ea6\u91cf\u6307\u6807\u3002", "result": "KAN\u6a21\u578b\u5728\u6e29\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5176R\u00b2\u503c\u5206\u522b\u4e3a0.9986\uff08\u963f\u6bd4\u8ba9\uff09\u548c0.9998\uff08\u57fa\u52a0\u5229\uff09\uff0cMSE\u5c0f\u4e8e0.0014\u00b0C\u00b2\u3002\u6539\u8fdb\u540e\u7684TKAN\u6a21\u578b\u5728\u4f4e\u964d\u96e8\u91cf\u6761\u4ef6\u4e0b\u7684\u964d\u6c34\u9884\u6d4b\u4e2d\u7edd\u5bf9\u8bef\u5dee\u6700\u5c0f\u3002\u5bf9\u4e8e\u6c14\u538b\u9884\u6d4b\uff0c\u4f20\u7edf\u7684RNN\u6a21\u578b\u5728\u4e24\u9879\u6570\u636e\u96c6\u4e2d\u5747\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5176R\u00b2\u503c\u7ea6\u4e3a0.83-0.86\uff0c\u4f18\u4e8e\u57fa\u4e8eKAN\u7684\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6837\u6761\u795e\u7ecf\u67b6\u6784\u5728\u9ad8\u6548\u548c\u6570\u636e\u6548\u7387\u9ad8\u7684\u5929\u6c14\u9884\u6d4b\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u5929\u6c14\u53c2\u6570\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\u5404\u6709\u4f18\u52a3\uff0c\u5177\u4f53\u9009\u62e9\u5e94\u6839\u636e\u4efb\u52a1\u9700\u6c42\u51b3\u5b9a\u3002"}}
{"id": "2505.23518", "pdf": "https://arxiv.org/pdf/2505.23518", "abs": "https://arxiv.org/abs/2505.23518", "authors": ["Hangoo Kang", "Jehyeok Yeon", "Gagandeep Singh"], "title": "TRAP: Targeted Redirecting of Agentic Preferences", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous agentic AI systems powered by vision-language models (VLMs) are\nrapidly advancing toward real-world deployment, yet their cross-modal reasoning\ncapabilities introduce new attack surfaces for adversarial manipulation that\nexploit semantic reasoning across modalities. Existing adversarial attacks\ntypically rely on visible pixel perturbations or require privileged model or\nenvironment access, making them impractical for stealthy, real-world\nexploitation. We introduce TRAP, a generative adversarial framework that\nmanipulates the agent's decision-making using diffusion-based semantic\ninjections. Our method combines negative prompt-based degradation with positive\nsemantic optimization, guided by a Siamese semantic network and layout-aware\nspatial masking. Without requiring access to model internals, TRAP produces\nvisually natural images yet induces consistent selection biases in agentic AI\nsystems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO)\ndataset, building multi-candidate decision scenarios. Across these scenarios,\nTRAP achieves a 100% attack success rate on leading models, including\nLLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such\nas SPSA, Bandit, and standard diffusion approaches. These results expose a\ncritical vulnerability: Autonomous agents can be consistently misled through\nhuman-imperceptible cross-modal manipulations. These findings highlight the\nneed for defense strategies beyond pixel-level robustness to address semantic\nvulnerabilities in cross-modal decision-making.", "AI": {"tldr": "\u81ea\u4e3b\u4ee3\u7406AI\u7cfb\u7edf\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u8fc5\u901f\u5411\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\uff0c\u4f46\u5176\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\u4e3a\u5bf9\u6297\u6027\u64cd\u63a7\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u6211\u4eec\u63d0\u51fa\u4e86TRAP\u6846\u67b6\uff0c\u5b83\u5229\u7528\u6269\u6563\u578b\u8bed\u4e49\u6ce8\u5165\u6765\u64cd\u7eb5\u4ee3\u7406\u7684\u51b3\u7b56\u3002TRAP\u5728\u4e0d\u9700\u8981\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u7684\u60c5\u51b5\u4e0b\uff0c\u751f\u6210\u89c6\u89c9\u4e0a\u81ea\u7136\u7684\u56fe\u50cf\uff0c\u5374\u80fd\u8bf1\u5bfc\u4ee3\u7406AI\u7cfb\u7edf\u4ea7\u751f\u4e00\u81f4\u7684\u9009\u62e9\u504f\u5dee\u3002\u6211\u4eec\u5728COCO\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86TRAP\uff0c\u5728\u591a\u4e2a\u5019\u9009\u51b3\u7b56\u573a\u666f\u4e2d\uff0cTRAP\u5bf9\u5305\u62ecLLaVA-34B\u3001Gemma3\u548cMistral-3.1\u5728\u5185\u7684\u9886\u5148\u6a21\u578b\u5b9e\u73b0\u4e86100%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8eSPSA\u3001Bandit\u548c\u6807\u51c6\u6269\u6563\u65b9\u6cd5\u7b49\u57fa\u7ebf\u3002\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86\u4e00\u4e2a\u5173\u952e\u6f0f\u6d1e\uff1a\u81ea\u4e3b\u4ee3\u7406\u53ef\u4ee5\u901a\u8fc7\u4eba\u7c7b\u65e0\u6cd5\u5bdf\u89c9\u7684\u8de8\u6a21\u6001\u64cd\u63a7\u88ab\u6301\u7eed\u8bef\u5bfc\u3002\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u50cf\u7d20\u7ea7\u9c81\u68d2\u6027\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u4ee5\u5e94\u5bf9\u8de8\u6a21\u6001\u51b3\u7b56\u4e2d\u7684\u8bed\u4e49\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u6297\u653b\u51fb\u901a\u5e38\u4f9d\u8d56\u4e8e\u53ef\u89c1\u7684\u50cf\u7d20\u6270\u52a8\u6216\u9700\u8981\u7279\u6743\u6a21\u578b\u6216\u73af\u5883\u8bbf\u95ee\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u9690\u79d8\u7684\u3001\u73b0\u5b9e\u4e16\u754c\u7684\u5229\u7528\u4e2d\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u65b0\u7684\u5bf9\u6297\u6027\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u5bf9\u81ea\u4e3b\u4ee3\u7406AI\u7cfb\u7edf\u7684\u6709\u6548\u653b\u51fb\u3002", "method": "TRAP\u7ed3\u5408\u4e86\u57fa\u4e8e\u8d1f\u63d0\u793a\u7684\u964d\u7ea7\u4e0e\u6b63\u8bed\u4e49\u4f18\u5316\uff0c\u7531\u4e00\u4e2aSiamese\u8bed\u4e49\u7f51\u7edc\u548c\u5e03\u5c40\u611f\u77e5\u7684\u7a7a\u95f4\u63a9\u7801\u5f15\u5bfc\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u6269\u6563\u578b\u8bed\u4e49\u6ce8\u5165\u6765\u64cd\u7eb5\u4ee3\u7406\u7684\u51b3\u7b56\uff0c\u4ece\u800c\u751f\u6210\u89c6\u89c9\u4e0a\u81ea\u7136\u7684\u56fe\u50cf\uff0c\u540c\u65f6\u8bf1\u5bfc\u4ee3\u7406AI\u7cfb\u7edf\u4ea7\u751f\u4e00\u81f4\u7684\u9009\u62e9\u504f\u5dee\u3002", "result": "TRAP\u5728COCO\u6570\u636e\u96c6\u4e0a\u7684\u591a\u5019\u9009\u51b3\u7b56\u573a\u666f\u4e2d\uff0c\u5bf9\u9886\u5148\u6a21\u578b\uff08\u5982LLaVA-34B\u3001Gemma3\u548cMistral-3.1\uff09\u5b9e\u73b0\u4e86100%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u663e\u8457\u4f18\u4e8eSPSA\u3001Bandit\u548c\u6807\u51c6\u6269\u6563\u65b9\u6cd5\u7b49\u57fa\u7ebf\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86\u81ea\u4e3b\u4ee3\u7406\u53ef\u4ee5\u901a\u8fc7\u4eba\u7c7b\u65e0\u6cd5\u5bdf\u89c9\u7684\u8de8\u6a21\u6001\u64cd\u63a7\u88ab\u6301\u7eed\u8bef\u5bfc\u7684\u5173\u952e\u6f0f\u6d1e\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u50cf\u7d20\u7ea7\u9c81\u68d2\u6027\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u4ee5\u5e94\u5bf9\u8de8\u6a21\u6001\u51b3\u7b56\u4e2d\u7684\u8bed\u4e49\u6f0f\u6d1e\u3002"}}
{"id": "2505.22689", "pdf": "https://arxiv.org/pdf/2505.22689", "abs": "https://arxiv.org/abs/2505.22689", "authors": ["Jialong Guo", "Xinghao Chen", "Yehui Tang", "Yunhe Wang"], "title": "SlimLLM: Accurate Structured Pruning for Large Language Models", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Large language models(LLMs) have garnered significant attention and\ndemonstrated impressive capabilities in a wide range of applications. However,\ndue to their enormous computational costs, the deployment and application of\nLLMs are often severely limited. To address this issue, structured pruning is\nan effective solution to compress the parameters of LLMs. Determining the\nimportance of each sub-module in LLMs and minimizing performance loss are\ncritical issues that need to be carefully addressed in structured pruning. In\nthis paper, we propose an effective and fast structured pruning method named\nSlimLLM for large language models. For channel and attention head pruning, we\nevaluate the importance based on the entire channel or head, rather than merely\naggregating the importance of individual elements within a sub-module. This\napproach enables a more holistic consideration of the interdependence among\nelements within the sub-module. In addition, we design a simple linear\nregression strategy for the output matrix to quickly recover performance. We\nalso propose layer-based importance ratio to determine the pruning ratio for\neach layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other\nmethods and achieves state-of-the-art performance.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u56e0\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u6210\u672c\u800c\u53d7\u9650\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSlimLLM\u7684\u6709\u6548\u5feb\u901f\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u901a\u9053\u548c\u6ce8\u610f\u529b\u5934\u7684\u91cd\u8981\u6027\u5e76\u8003\u8651\u5b50\u6a21\u5757\u5185\u5143\u7d20\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u8bbe\u8ba1\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u7b56\u7565\u5feb\u901f\u6062\u590d\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5c42\u7684\u91cd\u8981\u6027\u6bd4\u7387\u786e\u5b9a\u6bcf\u5c42\u7684\u526a\u679d\u6bd4\u7387\u3002\u5728LLaMA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSlimLLM\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f17\u591a\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5176\u5e9e\u5927\u7684\u8ba1\u7b97\u6210\u672c\u4e25\u91cd\u9650\u5236\u4e86\u90e8\u7f72\u548c\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7ed3\u6784\u5316\u526a\u679d\u6210\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u538b\u7f29LLMs\u53c2\u6570\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSlimLLM\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u901a\u9053\u548c\u6ce8\u610f\u529b\u5934\u526a\u679d\uff0c\u57fa\u4e8e\u6574\u4e2a\u901a\u9053\u6216\u5934\u6765\u8bc4\u4f30\u91cd\u8981\u6027\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u805a\u5408\u5b50\u6a21\u5757\u5185\u5355\u4e2a\u5143\u7d20\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u66f4\u5168\u9762\u5730\u8003\u8651\u5b50\u6a21\u5757\u5185\u5143\u7d20\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u7b56\u7565\u4ee5\u5feb\u901f\u6062\u590d\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5c42\u7684\u91cd\u8981\u6027\u6bd4\u7387\u6765\u786e\u5b9a\u6bcf\u5c42\u7684\u526a\u679d\u6bd4\u7387\u3002", "result": "\u6839\u636eLLaMA\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0cSlimLLM\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "SlimLLM\u662f\u4e00\u79cd\u6709\u6548\u4e14\u5feb\u901f\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u8bc4\u4f30LLMs\u4e2d\u6bcf\u4e2a\u5b50\u6a21\u5757\u7684\u91cd\u8981\u6027\u5e76\u6700\u5c0f\u5316\u6027\u80fd\u635f\u5931\u3002"}}
{"id": "2505.23519", "pdf": "https://arxiv.org/pdf/2505.23519", "abs": "https://arxiv.org/abs/2505.23519", "authors": ["Ruiqi He", "Falk Lieder"], "title": "Individual differences in the cognitive mechanisms of planning strategy discovery", "categories": ["cs.AI"], "comment": null, "summary": "People employ efficient planning strategies. But how are these strategies\nacquired? Previous research suggests that people can discover new planning\nstrategies through learning from reinforcements, a process known as\nmetacognitive reinforcement learning (MCRL). While prior work has shown that\nMCRL models can learn new planning strategies and explain more participants'\nexperience-driven discovery better than alternative mechanisms, it also\nrevealed significant individual differences in metacognitive learning.\nFurthermore, when fitted to human data, these models exhibit a slower rate of\nstrategy discovery than humans. In this study, we investigate whether\nincorporating cognitive mechanisms that might facilitate human strategy\ndiscovery can bring models of MCRL closer to human performance. Specifically,\nwe consider intrinsically generated metacognitive pseudo-rewards, subjective\neffort valuation, and termination deliberation. Analysis of planning task data\nshows that a larger proportion of participants used at least one of these\nmechanisms, with significant individual differences in their usage and varying\nimpacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort\nvaluation, and learning the value of acting without further planning were found\nto facilitate strategy discovery. While these enhancements provided valuable\ninsights into individual differences and the effect of these mechanisms on\nstrategy discovery, they did not fully close the gap between model and human\nperformance, prompting further exploration of additional factors that people\nmight use to discover new planning strategies.", "AI": {"tldr": "\u4eba\u4eec\u901a\u8fc7\u5143\u8ba4\u77e5\u5f3a\u5316\u5b66\u4e60\uff08MCRL\uff09\u83b7\u53d6\u9ad8\u6548\u7684\u89c4\u5212\u7b56\u7565\uff0c\u4f46\u6a21\u578b\u5728\u7b56\u7565\u53d1\u73b0\u7684\u901f\u5ea6\u4e0a\u4ecd\u4e0d\u5982\u4eba\u7c7b\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7ed3\u5408\u4fc3\u8fdb\u4eba\u7c7b\u7b56\u7565\u53d1\u73b0\u7684\u8ba4\u77e5\u673a\u5236\uff08\u5982\u5143\u8ba4\u77e5\u4f2a\u5956\u52b1\u3001\u4e3b\u89c2\u52aa\u529b\u8bc4\u4f30\u548c\u7ec8\u6b62\u601d\u8003\uff09\u662f\u5426\u80fd\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u673a\u5236\u6709\u52a9\u4e8e\u7b56\u7565\u53d1\u73b0\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u4ed6\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7814\u7a76\u8868\u660eMCRL\u6a21\u578b\u53ef\u4ee5\u5b66\u4e60\u65b0\u7684\u89c4\u5212\u7b56\u7565\u5e76\u89e3\u91ca\u53c2\u4e0e\u8005\u7684\u7ecf\u9a8c\u9a71\u52a8\u578b\u53d1\u73b0\uff0c\u4f46\u6a21\u578b\u5728\u7b56\u7565\u53d1\u73b0\u901f\u5ea6\u4e0a\u663e\u8457\u6162\u4e8e\u4eba\u7c7b\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5c06\u53ef\u80fd\u4fc3\u8fdb\u4eba\u7c7b\u7b56\u7565\u53d1\u73b0\u7684\u8ba4\u77e5\u673a\u5236\u7eb3\u5165\u6a21\u578b\u662f\u5426\u80fd\u63d0\u9ad8\u5176\u6027\u80fd\u4ee5\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u89c4\u5212\u4efb\u52a1\u6570\u636e\uff0c\u5e76\u6d4b\u8bd5\u4e86\u4e09\u79cd\u8ba4\u77e5\u673a\u5236\u5bf9\u7b56\u7565\u53d1\u73b0\u7684\u5f71\u54cd\uff1a1) \u5143\u8ba4\u77e5\u4f2a\u5956\u52b1\uff1b2) \u4e3b\u89c2\u52aa\u529b\u8bc4\u4f30\uff1b3) \u7ec8\u6b62\u601d\u8003\u3002\u901a\u8fc7\u6bd4\u8f83\u53c2\u4e0e\u8005\u7684\u884c\u4e3a\u6a21\u5f0f\u548c\u6a21\u578b\u62df\u5408\u7ed3\u679c\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u673a\u5236\u7684\u4f7f\u7528\u9891\u7387\u53ca\u5176\u5bf9\u7b56\u7565\u53d1\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u6570\u636e\u5206\u6790\u663e\u793a\uff0c\u5927\u591a\u6570\u53c2\u4e0e\u8005\u81f3\u5c11\u4f7f\u7528\u4e86\u4e00\u79cd\u4e0a\u8ff0\u673a\u5236\uff0c\u4e14\u4e2a\u4f53\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u8fd9\u4e9b\u673a\u5236\u5bf9\u7b56\u7565\u53d1\u73b0\u5177\u6709\u4fc3\u8fdb\u4f5c\u7528\uff0c\u4f46\u5373\u4f7f\u52a0\u5165\u8fd9\u4e9b\u589e\u5f3a\u529f\u80fd\uff0c\u6a21\u578b\u6027\u80fd\u4ecd\u672a\u5b8c\u5168\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u867d\u7136\u5143\u8ba4\u77e5\u4f2a\u5956\u52b1\u3001\u4e3b\u89c2\u52aa\u529b\u8bc4\u4f30\u548c\u7ec8\u6b62\u601d\u8003\u7b49\u673a\u5236\u4e3a\u7406\u89e3\u4e2a\u4f53\u5dee\u5f02\u53ca\u7b56\u7565\u53d1\u73b0\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u4f46\u5b83\u4eec\u5e76\u672a\u5b8c\u5168\u5f25\u5408\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u672a\u6765\u9700\u8981\u63a2\u7d22\u66f4\u591a\u53ef\u80fd\u5f71\u54cd\u7b56\u7565\u53d1\u73b0\u7684\u56e0\u7d20\u3002"}}
{"id": "2505.22694", "pdf": "https://arxiv.org/pdf/2505.22694", "abs": "https://arxiv.org/abs/2505.22694", "authors": ["Dacao Zhang", "Kun Zhang", "Shimao Chu", "Le Wu", "Xin Li", "Si Wei"], "title": "MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning", "categories": ["cs.LG"], "comment": "This paper has been accepted to ACL 2025 Findings", "summary": "With the rapid development of Large Language Models (LLMs),\nParameter-Efficient Fine-Tuning (PEFT) methods have gained significant\nattention, which aims to achieve efficient fine-tuning of LLMs with fewer\nparameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)\nintroduces low-rank matrices to approximate the incremental tuning parameters\nand achieves impressive performance over multiple scenarios. After that, plenty\nof improvements have been proposed for further improvement. However, these\nmethods either focus on single-task scenarios or separately train multiple LoRA\nmodules for multi-task scenarios, limiting the efficiency and effectiveness of\nLoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in\nthis paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for\nmulti-task PEFT. Specifically, instead of using an individual LoRA for each\ntask, we align different ranks of LoRA module with different tasks, which we\nnamed low-rank experts. Moreover, we design a novel adaptive rank selector to\nselect the appropriate expert for each task. By jointly training low-rank\nexperts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task\nscenarios. Finally, we conduct extensive experiments over multiple multi-task\nbenchmarks along with different LLMs to verify model performance. Experimental\nresults demonstrate that compared to traditional LoRA and its variants, MoRE\nsignificantly improves the performance of LLMs in multi-task scenarios and\nincurs no additional inference cost. We also release the model and code to\nfacilitate the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4efb\u52a1\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5MoRE\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u4f4e\u79e9\u4e13\u5bb6\u548c\u81ea\u9002\u5e94\u79e9\u9009\u62e9\u5668\uff0c\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347LLM\u6027\u80fd\u4e14\u65e0\u989d\u5916\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684LoRA\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u8981\u4e48\u4e13\u6ce8\u4e8e\u5355\u4efb\u52a1\uff0c\u8981\u4e48\u5206\u522b\u8bad\u7ec3\u591a\u4e2aLoRA\u6a21\u5757\uff0c\u9650\u5236\u4e86\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Mixture of Low-Rank Experts (MoRE)\uff0c\u901a\u8fc7\u5c06\u4e0d\u540c\u4efb\u52a1\u4e0e\u4e0d\u540c\u79e9\u7684LoRA\u6a21\u5757\u5bf9\u9f50\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u79e9\u9009\u62e9\u5668\u6765\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u4e13\u5bb6\uff0c\u4ece\u800c\u589e\u5f3a\u4e86LoRA\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684LoRA\u53ca\u5176\u53d8\u4f53\u76f8\u6bd4\uff0cMoRE\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u6ca1\u6709\u589e\u52a0\u989d\u5916\u7684\u63a8\u7406\u6210\u672c\u3002", "conclusion": "MoRE\u5728\u591a\u4efb\u52a1PEFT\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u5347\u4e86LLM\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6548\u7684\u63a8\u7406\u3002\u4f5c\u8005\u8fd8\u5f00\u6e90\u4e86\u6a21\u578b\u548c\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u793e\u533a\u53d1\u5c55\u3002"}}
{"id": "2505.23536", "pdf": "https://arxiv.org/pdf/2505.23536", "abs": "https://arxiv.org/abs/2505.23536", "authors": ["Janik-Vasily Benzin", "Gyunam Park", "Stefanie Rinderle-Ma"], "title": "Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)", "categories": ["cs.AI"], "comment": null, "summary": "Model abstraction (MA) and event abstraction (EA) are means to reduce\ncomplexity of (discovered) models and event data. Imagine a process\nintelligence project that aims to analyze a model discovered from event data\nwhich is further abstracted, possibly multiple times, to reach optimality\ngoals, e.g., reducing model size. So far, after discovering the model, there is\nno technique that enables the synchronized abstraction of the underlying event\nlog. This results in loosing the grounding in the real-world behavior contained\nin the log and, in turn, restricts analysis insights. Hence, in this work, we\nprovide the formal basis for synchronized model and event abstraction, i.e., we\nprove that abstracting a process model by MA and discovering a process model\nfrom an abstracted event log yields an equivalent process model. We prove the\nfeasibility of our approach based on behavioral profile abstraction as\nnon-order preserving MA technique, resulting in a novel EA technique.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u6b65\u6a21\u578b\u548c\u4e8b\u4ef6\u62bd\u8c61\u7684\u5f62\u5f0f\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u6a21\u578b\u62bd\u8c61\uff08MA\uff09\u548c\u4e8b\u4ef6\u65e5\u5fd7\u62bd\u8c61\uff08EA\uff09\u53ef\u4ee5\u5f97\u5230\u7b49\u4ef7\u7684\u8fc7\u7a0b\u6a21\u578b\uff0c\u4ece\u800c\u4fdd\u6301\u4e0e\u5b9e\u9645\u884c\u4e3a\u7684\u8054\u7cfb\u5e76\u6269\u5c55\u5206\u6790\u6d1e\u5bdf\u3002", "motivation": "\u5728\u8fc7\u7a0b\u667a\u80fd\u9879\u76ee\u4e2d\uff0c\u901a\u5e38\u9700\u8981\u5bf9\u4ece\u4e8b\u4ef6\u6570\u636e\u4e2d\u53d1\u73b0\u7684\u6a21\u578b\u8fdb\u884c\u591a\u6b21\u62bd\u8c61\u4ee5\u8fbe\u5230\u4f18\u5316\u76ee\u6807\uff08\u5982\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff09\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u79cd\u6280\u672f\u80fd\u591f\u5728\u6a21\u578b\u62bd\u8c61\u7684\u540c\u65f6\u540c\u6b65\u62bd\u8c61\u5e95\u5c42\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5931\u53bb\u65e5\u5fd7\u4e2d\u5305\u542b\u7684\u771f\u5b9e\u4e16\u754c\u884c\u4e3a\u7684\u4f9d\u636e\uff0c\u4ece\u800c\u9650\u5236\u5206\u6790\u7684\u6df1\u5ea6\u548c\u6709\u6548\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u540c\u6b65\u6a21\u578b\u548c\u4e8b\u4ef6\u62bd\u8c61\u7684\u5f62\u5f0f\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u6a21\u578b\u62bd\u8c61\uff08MA\uff09\u548c\u4ece\u62bd\u8c61\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u53d1\u73b0\u8fc7\u7a0b\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u7b49\u4ef7\u7684\u8fc7\u7a0b\u6a21\u578b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f7f\u7528\u975e\u987a\u5e8f\u4fdd\u62a4\u7684\u6a21\u578b\u62bd\u8c61\u6280\u672f\uff08behavioral profile abstraction\uff09\u4f5c\u4e3a\u793a\u4f8b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u7531\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8b\u4ef6\u62bd\u8c61\uff08EA\uff09\u6280\u672f\u3002", "result": "\u8bc1\u660e\u4e86\u540c\u6b65\u6a21\u578b\u548c\u4e8b\u4ef6\u62bd\u8c61\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8b\u4ef6\u62bd\u8c61\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u4e0d\u5931\u53bb\u771f\u5b9e\u4e16\u754c\u884c\u4e3a\u4f9d\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6a21\u578b\u548c\u4e8b\u4ef6\u6570\u636e\u8fdb\u884c\u6709\u6548\u7684\u590d\u6742\u6027\u964d\u4f4e\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u540c\u6b65\u6a21\u578b\u548c\u4e8b\u4ef6\u62bd\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u4f7f\u5f97\u5728\u8fdb\u884c\u6a21\u578b\u62bd\u8c61\u65f6\u80fd\u591f\u540c\u6b65\u5904\u7406\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u4ece\u800c\u4fdd\u6301\u4e0e\u5b9e\u9645\u884c\u4e3a\u7684\u8054\u7cfb\uff0c\u589e\u5f3a\u4e86\u8fc7\u7a0b\u667a\u80fd\u9879\u76ee\u7684\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2505.22695", "pdf": "https://arxiv.org/pdf/2505.22695", "abs": "https://arxiv.org/abs/2505.22695", "authors": ["Tengfei Lyu", "Siyuan Feng", "Hao Liu", "Hai Yang"], "title": "LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning", "categories": ["cs.LG"], "comment": null, "summary": "Ride-hailing platforms face significant challenges in optimizing order\ndispatching and driver repositioning operations in dynamic urban environments.\nTraditional approaches based on combinatorial optimization, rule-based\nheuristics, and reinforcement learning often overlook driver income fairness,\ninterpretability, and adaptability to real-world dynamics. To address these\ngaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models\n(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in\nride-hailing services. LLM-ODDR framework comprises three key components: (1)\nMulti-objective-guided Order Value Refinement, which evaluates orders by\nconsidering multiple objectives to determine their overall value; (2)\nFairness-aware Order Dispatching, which balances platform revenue with driver\nincome fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,\nwhich optimizes idle vehicle placement based on historical patterns and\nprojected supply. We also develop JointDR-GPT, a fine-tuned model optimized for\nODDR tasks with domain knowledge. Extensive experiments on real-world datasets\nfrom Manhattan taxi operations demonstrate that our framework significantly\noutperforms traditional methods in terms of effectiveness, adaptability to\nanomalous conditions, and decision interpretability. To our knowledge, this is\nthe first exploration of LLMs as decision-making agents in ride-hailing ODDR\ntasks, establishing foundational insights for integrating advanced language\nmodels within intelligent transportation systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM-ODDR\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u7f51\u7ea6\u8f66\u8ba2\u5355\u5206\u914d\u548c\u53f8\u673a\u91cd\u5b9a\u4f4d\u95ee\u9898\uff0c\u5305\u542b\u591a\u76ee\u6807\u5bfc\u5411\u7684\u8ba2\u5355\u4ef7\u503c\u8bc4\u4f30\u3001\u516c\u5e73\u6027\u611f\u77e5\u7684\u8ba2\u5355\u5206\u914d\u4ee5\u53ca\u65f6\u7a7a\u9700\u6c42\u611f\u77e5\u7684\u53f8\u673a\u91cd\u5b9a\u4f4d\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6548\u679c\u3001\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u8fd9\u662f\u9996\u6b21\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u7f51\u7ea6\u8f66\u51b3\u7b56\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u7f51\u7ea6\u8f66\u5e73\u53f0\u5728\u52a8\u6001\u57ce\u5e02\u73af\u5883\u4e2d\u9762\u4e34\u8ba2\u5355\u5206\u914d\u548c\u53f8\u673a\u91cd\u5b9a\u4f4d\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982\u7ec4\u5408\u4f18\u5316\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u5f80\u5f80\u5ffd\u89c6\u4e86\u53f8\u673a\u6536\u5165\u516c\u5e73\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u7684\u9002\u5e94\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86LLM-ODDR\u6846\u67b6\uff0c\u5305\u62ec\uff1a1) \u591a\u76ee\u6807\u5bfc\u5411\u7684\u8ba2\u5355\u4ef7\u503c\u8bc4\u4f30\uff1b2) \u516c\u5e73\u6027\u611f\u77e5\u7684\u8ba2\u5355\u5206\u914d\uff1b3) \u65f6\u7a7a\u9700\u6c42\u611f\u77e5\u7684\u53f8\u673a\u91cd\u5b9a\u4f4d\u3002\u540c\u65f6\u5f00\u53d1\u4e86JointDR-GPT\uff0c\u4e00\u4e2a\u9488\u5bf9ODDR\u4efb\u52a1\u4f18\u5316\u7684\u7cbe\u7ec6\u8c03\u4f18\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u66fc\u54c8\u987f\u51fa\u79df\u8f66\u8fd0\u8425\u7684\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6709\u6548\u6027\u3001\u5bf9\u5f02\u5e38\u6761\u4ef6\u7684\u9002\u5e94\u6027\u4ee5\u53ca\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u63a2\u7d22\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7f51\u7ea6\u8f66ODDR\u4efb\u52a1\u4e2d\u7684\u51b3\u7b56\u4ee3\u7406\uff0c\u4e3a\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u6574\u5408\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.23559", "pdf": "https://arxiv.org/pdf/2505.23559", "abs": "https://arxiv.org/abs/2505.23559", "authors": ["Kunlun Zhu", "Jiaxun Zhang", "Ziheng Qi", "Nuoxing Shang", "Zijia Liu", "Peixuan Han", "Yue Su", "Haofei Yu", "Jiaxuan You"], "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in large language model (LLM) agents have significantly\naccelerated scientific discovery automation, yet concurrently raised critical\nethical and safety concerns. To systematically address these challenges, we\nintroduce \\textbf{SafeScientist}, an innovative AI scientist framework\nexplicitly designed to enhance safety and ethical responsibility in AI-driven\nscientific exploration. SafeScientist proactively refuses ethically\ninappropriate or high-risk tasks and rigorously emphasizes safety throughout\nthe research process. To achieve comprehensive safety oversight, we integrate\nmultiple defensive mechanisms, including prompt monitoring, agent-collaboration\nmonitoring, tool-use monitoring, and an ethical reviewer component.\nComplementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel\nbenchmark specifically designed to evaluate AI safety in scientific contexts,\ncomprising 240 high-risk scientific tasks across 6 domains, alongside 30\nspecially designed scientific tools and 120 tool-related risk tasks. Extensive\nexperiments demonstrate that SafeScientist significantly improves safety\nperformance by 35\\% compared to traditional AI scientist frameworks, without\ncompromising scientific output quality. Additionally, we rigorously validate\nthe robustness of our safety pipeline against diverse adversarial attack\nmethods, further confirming the effectiveness of our integrated approach. The\ncode and data will be available at https://github.com/ulab-uiuc/SafeScientist.\n\\textcolor{red}{Warning: this paper contains example data that may be offensive\nor harmful.}", "AI": {"tldr": "SafeScientist\u662f\u4e00\u4e2a\u589e\u5f3aAI\u9a71\u52a8\u79d1\u5b66\u63a2\u7d22\u5b89\u5168\u6027\u548c\u4f26\u7406\u8d23\u4efb\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u79cd\u9632\u5fa1\u673a\u5236\u786e\u4fdd\u7814\u7a76\u8fc7\u7a0b\u7684\u5b89\u5168\uff0c\u5e76\u914d\u4ee5SciSafetyBench\u8bc4\u4f30\u57fa\u51c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSafeScientist\u5728\u4e0d\u5f71\u54cd\u79d1\u5b66\u4ea7\u51fa\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5b89\u5168\u6027\u63d0\u9ad8\u4e8635%\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u81ea\u52a8\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u540c\u65f6\u4e5f\u5f15\u53d1\u4e86\u91cd\u8981\u7684\u4f26\u7406\u548c\u5b89\u5168\u95ee\u9898\u3002\u4e3a\u7cfb\u7edf\u5730\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u6846\u67b6\u6765\u63d0\u9ad8AI\u9a71\u52a8\u79d1\u5b66\u63a2\u7d22\u7684\u5b89\u5168\u6027\u548c\u4f26\u7406\u8d23\u4efb\u3002", "method": "SafeScientist\u6846\u67b6\u901a\u8fc7\u4e3b\u52a8\u62d2\u7edd\u4e0d\u9002\u5f53\u6216\u9ad8\u98ce\u9669\u4efb\u52a1\uff0c\u5f3a\u8c03\u7814\u7a76\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u5e76\u6574\u5408\u4e86\u591a\u79cd\u9632\u5fa1\u673a\u5236\uff0c\u5982\u63d0\u793a\u76d1\u63a7\u3001\u4ee3\u7406\u534f\u4f5c\u76d1\u63a7\u3001\u5de5\u5177\u4f7f\u7528\u76d1\u63a7\u548c\u4f26\u7406\u5ba1\u67e5\u7ec4\u4ef6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86SciSafetyBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u5728\u79d1\u5b66\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSafeScientist\u76f8\u6bd4\u4f20\u7edfAI\u79d1\u5b66\u5bb6\u6846\u67b6\uff0c\u5b89\u5168\u6027\u6027\u80fd\u63d0\u9ad8\u4e8635%\uff0c\u5e76\u4e14\u5728\u9762\u5bf9\u591a\u6837\u5316\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u65f6\uff0c\u5176\u5b89\u5168\u6027\u7ba1\u9053\u7684\u7a33\u5065\u6027\u5f97\u5230\u4e86\u4e25\u683c\u9a8c\u8bc1\u3002", "conclusion": "SafeScientist\u6846\u67b6\u53ca\u5176\u914d\u5957\u7684SciSafetyBench\u57fa\u51c6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347AI\u9a71\u52a8\u79d1\u5b66\u7814\u7a76\u7684\u5b89\u5168\u6027\u548c\u4f26\u7406\u8d23\u4efb\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u548c\u6548\u679c\u3002"}}
{"id": "2505.22696", "pdf": "https://arxiv.org/pdf/2505.22696", "abs": "https://arxiv.org/abs/2505.22696", "authors": ["Eleni Nisioti", "Joachim Winther Pedersen", "Erwan Plantec", "Milton L. Montero", "Sebastian Risi"], "title": "When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?", "categories": ["cs.LG"], "comment": null, "summary": "The ability to continuously and efficiently transfer skills across tasks is a\nhallmark of biological intelligence and a long-standing goal in artificial\nsystems. Reinforcement learning (RL), a dominant paradigm for learning in\nhigh-dimensional control tasks, is known to suffer from brittleness to task\nvariations and catastrophic forgetting. Neuroevolution (NE) has recently gained\nattention for its robustness, scalability, and capacity to escape local optima.\nIn this paper, we investigate an understudied dimension of NE: its transfer\nlearning capabilities. To this end, we introduce two benchmarks: a) in stepping\ngates, neural networks are tasked with emulating logic circuits, with designs\nthat emphasize modular repetition and variation b) ecorobot extends the Brax\nphysics engine with objects such as walls and obstacles and the ability to\neasily switch between different robotic morphologies. Crucial in both\nbenchmarks is the presence of a curriculum that enables evaluating skill\ntransfer across tasks of increasing complexity. Our empirical analysis shows\nthat NE methods vary in their transfer abilities and frequently outperform RL\nbaselines. Our findings support the potential of NE as a foundation for\nbuilding more adaptable agents and highlight future challenges for scaling NE\nto complex, real-world problems.", "AI": {"tldr": "\u7814\u7a76\u4e86\u795e\u7ecf\u8fdb\u5316\uff08NE\uff09\u5728\u6280\u80fd\u8fc1\u79fb\u4e2d\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u53d1\u73b0NE\u65b9\u6cd5\u5728\u8fc1\u79fb\u5b66\u4e60\u65b9\u9762\u4f18\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u5e76\u5177\u6709\u6784\u5efa\u66f4\u9002\u5e94\u6027\u667a\u80fd\u4f53\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u662f\u9ad8\u7ef4\u63a7\u5236\u4efb\u52a1\u7684\u4e3b\u8981\u5b66\u4e60\u8303\u5f0f\uff0c\u4f46\u5b83\u5bf9\u4efb\u52a1\u53d8\u5316\u5f88\u8106\u5f31\u4e14\u5bb9\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\u3002\u800c\u795e\u7ecf\u8fdb\u5316\uff08NE\uff09\u56e0\u5176\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9003\u79bb\u5c40\u90e8\u6700\u4f18\u7684\u80fd\u529b\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e86\u4e24\u4e2a\u57fa\u51c6\uff1a1) stepping gates\uff0c\u8981\u6c42\u795e\u7ecf\u7f51\u7edc\u6a21\u4eff\u903b\u8f91\u7535\u8def\uff0c\u91cd\u70b9\u5728\u4e8e\u6a21\u5757\u5316\u91cd\u590d\u548c\u53d8\u4f53\uff1b2) ecorobot\uff0c\u6269\u5c55\u4e86Brax\u7269\u7406\u5f15\u64ce\uff0c\u6dfb\u52a0\u4e86\u5899\u58c1\u548c\u969c\u788d\u7269\uff0c\u5e76\u53ef\u4ee5\u8f7b\u677e\u5207\u6362\u4e0d\u540c\u7684\u673a\u5668\u4eba\u5f62\u6001\u3002\u4e24\u8005\u90fd\u901a\u8fc7\u8bfe\u7a0b\u8bbe\u8ba1\u6765\u8bc4\u4f30\u8de8\u4efb\u52a1\u7684\u6280\u80fd\u8fc1\u79fb\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0cNE\u65b9\u6cd5\u5728\u8fc1\u79fb\u80fd\u529b\u4e0a\u6709\u6240\u4e0d\u540c\uff0c\u4e14\u901a\u5e38\u4f18\u4e8eRL\u57fa\u7ebf\u3002", "conclusion": "NE\u6709\u53ef\u80fd\u6210\u4e3a\u6784\u5efa\u66f4\u9002\u5e94\u6027\u667a\u80fd\u4f53\u7684\u57fa\u7840\uff0c\u4f46\u4ecd\u9762\u4e34\u5c06\u5176\u6269\u5c55\u5230\u590d\u6742\u73b0\u5b9e\u95ee\u9898\u7684\u6311\u6218\u3002"}}
{"id": "2505.23575", "pdf": "https://arxiv.org/pdf/2505.23575", "abs": "https://arxiv.org/abs/2505.23575", "authors": ["Benjamin Arnav", "Pablo Bernabeu-P\u00e9rez", "Nathan Helm-Burger", "Tim Kostolansky", "Hannes Whittingham", "Mary Phuong"], "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As AI models are deployed with increasing autonomy, it is important to ensure\nthey do not take harmful actions unnoticed. As a potential mitigation, we\ninvestigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor\nmodel continuously oversees the intermediate reasoning steps of a more powerful\nbut untrusted model. We compare CoT monitoring to action-only monitoring, where\nonly final outputs are reviewed, in a red-teaming setup where the untrusted\nmodel is instructed to pursue harmful side tasks while completing a coding\nproblem. We find that CoT monitoring improves detection by up to 27 percentage\npoints in scenarios where action-only monitoring fails to reliably identify\nsabotage. However, CoT traces can also contain misleading rationalizations that\ndeceive the monitor, reducing performance in more obvious sabotage cases. To\naddress this, we introduce a hybrid protocol that independently scores both\nreasoning and final outputs and combines them using a weighted average. This\nhybrid monitor consistently outperforms both CoT and action-only monitors\nacross all tested models and tasks, with detection rates over four times higher\nthan action-only monitoring for subtle deception scenarios.", "AI": {"tldr": "\u5728AI\u6a21\u578b\u81ea\u4e3b\u6027\u589e\u5f3a\u7684\u60c5\u51b5\u4e0b\uff0c\u786e\u4fdd\u5b83\u4eec\u4e0d\u91c7\u53d6\u672a\u88ab\u5bdf\u89c9\u7684\u6709\u5bb3\u884c\u52a8\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u7814\u7a76\u4e86\u601d\u7ef4\u94fe\uff08CoT\uff09\u76d1\u63a7\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4ec5\u76d1\u63a7\u6700\u7ec8\u884c\u52a8\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u53d1\u73b0CoT\u76d1\u63a7\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u4e5f\u53ef\u80fd\u56e0\u8bef\u5bfc\u6027\u63a8\u7406\u800c\u964d\u4f4e\u6027\u80fd\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u534f\u8bae\uff0c\u7ed3\u5408\u63a8\u7406\u548c\u6700\u7ec8\u8f93\u51fa\u8bc4\u5206\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u7684CoT\u6216\u884c\u52a8\u76d1\u63a7\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u90e8\u7f72\u7684\u81ea\u4e3b\u6027\u589e\u52a0\uff0c\u9632\u6b62\u5176\u91c7\u53d6\u672a\u88ab\u5bdf\u89c9\u7684\u6709\u5bb3\u884c\u52a8\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u76d1\u63a7\u673a\u5236\u4ee5\u68c0\u6d4b\u6f5c\u5728\u7684\u6709\u5bb3\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u4e86Chain-of-Thought (CoT) \u76d1\u63a7\u65b9\u6cd5\uff0c\u5176\u4e2d\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u76d1\u63a7\u6a21\u578b\u6301\u7eed\u76d1\u7763\u66f4\u5f3a\u5927\u4f46\u4e0d\u53ef\u4fe1\u6a21\u578b\u7684\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u3002\u5e76\u4e0e\u4ec5\u76d1\u63a7\u6700\u7ec8\u884c\u52a8\uff08action-only monitoring\uff09\u7684\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u6d4b\u8bd5\u73af\u5883\u4e3a\u6307\u793a\u4e0d\u53ef\u4fe1\u6a21\u578b\u5728\u5b8c\u6210\u7f16\u7801\u4efb\u52a1\u65f6\u8ffd\u6c42\u6709\u5bb3\u7684\u6b21\u8981\u76ee\u6807\u3002\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u534f\u8bae\uff0c\u72ec\u7acb\u8bc4\u5206\u63a8\u7406\u8fc7\u7a0b\u548c\u6700\u7ec8\u8f93\u51fa\u5e76\u4f7f\u7528\u52a0\u6743\u5e73\u5747\u7ed3\u5408\u4e24\u8005\u3002", "result": "CoT\u76d1\u63a7\u5728action-only\u76d1\u63a7\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u7834\u574f\u884c\u4e3a\u7684\u60c5\u666f\u4e2d\uff0c\u63d0\u9ad8\u4e86\u6700\u9ad8\u8fbe27\u4e2a\u767e\u5206\u70b9\u7684\u68c0\u6d4b\u7387\u3002\u4f46\u5728\u66f4\u660e\u663e\u7684\u7834\u574f\u6848\u4f8b\u4e2d\uff0cCoT\u75d5\u8ff9\u53ef\u80fd\u5305\u542b\u8bef\u5bfc\u6027\u7684\u63a8\u7406\uff0c\u4ece\u800c\u964d\u4f4e\u6027\u80fd\u3002\u63d0\u51fa\u7684\u6df7\u5408\u534f\u8bae\u5728\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8eCoT\u548caction-only\u76d1\u63a7\uff0c\u5bf9\u4e8e\u5fae\u5999\u6b3a\u9a97\u573a\u666f\u7684\u68c0\u6d4b\u7387\u8d85\u8fc7action-only\u76d1\u63a7\u56db\u500d\u4ee5\u4e0a\u3002", "conclusion": "CoT\u76d1\u63a7\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5bf9AI\u6a21\u578b\u6709\u5bb3\u884c\u4e3a\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u88ab\u8bef\u5bfc\u6027\u63a8\u7406\u6b3a\u9a97\u7684\u98ce\u9669\u3002\u6df7\u5408\u76d1\u63a7\u534f\u8bae\u901a\u8fc7\u7ed3\u5408\u63a8\u7406\u548c\u6700\u7ec8\u8f93\u51fa\u7684\u8bc4\u5206\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u76d1\u63a7\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u3002"}}
{"id": "2505.22697", "pdf": "https://arxiv.org/pdf/2505.22697", "abs": "https://arxiv.org/abs/2505.22697", "authors": ["Filippo Rinaldi", "Giacomo Capitani", "Lorenzo Bonicelli", "Donato Crisostomi", "Federico Bolelli", "Elisa Ficarra", "Emanuele Rodol\u00e0", "Simone Calderara", "Angelo Porrello"], "title": "Update Your Transformer to the Latest Release: Re-Basin of Task Vectors", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Foundation models serve as the backbone for numerous specialized models\ndeveloped through fine-tuning. However, when the underlying pretrained model is\nupdated or retrained (e.g., on larger and more curated datasets), the\nfine-tuned model becomes obsolete, losing its utility and requiring retraining.\nThis raises the question: is it possible to transfer fine-tuning to a new\nrelease of the model? In this work, we investigate how to transfer fine-tuning\nto a new checkpoint without having to re-train, in a data-free manner. To do\nso, we draw principles from model re-basin and provide a recipe based on weight\npermutations to re-base the modifications made to the original base model,\noften called task vector. In particular, our approach tailors model re-basin\nfor Transformer models, taking into account the challenges of residual\nconnections and multi-head attention layers. Specifically, we propose a\ntwo-level method rooted in spectral theory, initially permuting the attention\nheads and subsequently adjusting parameters within select pairs of heads.\nThrough extensive experiments on visual and textual tasks, we achieve the\nseamless transfer of fine-tuned knowledge to new pre-trained backbones without\nrelying on a single training step or datapoint. Code is available at\nhttps://github.com/aimagelab/TransFusion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5c06\u5fae\u8c03\u77e5\u8bc6\u65e0\u7f1d\u8f6c\u79fb\u5230\u65b0\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u3002\u901a\u8fc7\u57fa\u4e8e\u6743\u91cd\u6392\u5217\u7684\u4e24\u5c42\u65b9\u6cd5\uff08\u6e90\u4e8e\u8c31\u7cfb\u7406\u8bba\uff09\uff0c\u89e3\u51b3\u4e86Transformer\u6a21\u578b\u4e2d\u7684\u6b8b\u5dee\u8fde\u63a5\u548c\u591a\u5934\u6ce8\u610f\u529b\u5c42\u7684\u95ee\u9898\uff0c\u5e76\u5728\u89c6\u89c9\u548c\u6587\u672c\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u5e95\u5c42\u9884\u8bad\u7ec3\u6a21\u578b\u66f4\u65b0\u6216\u91cd\u65b0\u8bad\u7ec3\u65f6\uff0c\u5fae\u8c03\u6a21\u578b\u4f1a\u53d8\u5f97\u8fc7\u65f6\u5e76\u5931\u53bb\u6548\u7528\uff0c\u56e0\u6b64\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u662f\u5426\u53ef\u4ee5\u5c06\u5fae\u8c03\u8f6c\u79fb\u5230\u6a21\u578b\u7684\u65b0\u7248\u672c\u4e0a\uff1f", "method": "\u7814\u7a76\u8005\u4ece\u6a21\u578b\u91cd\u76c6\u5730\u539f\u5219\u51fa\u53d1\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u6743\u91cd\u6392\u5217\u7684\u65b9\u6cd5\uff0c\u4ee5\u91cd\u65b0\u8c03\u6574\u5bf9\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6240\u505a\u7684\u4fee\u6539\uff08\u79f0\u4e3a\u4efb\u52a1\u5411\u91cf\uff09\u3002\u5177\u4f53\u800c\u8a00\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u5c42\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9996\u5148\u7f6e\u6362\u6ce8\u610f\u529b\u5934\uff0c\u7136\u540e\u8c03\u6574\u9009\u5b9a\u5934\u5bf9\u5185\u7684\u53c2\u6570\u3002\u6b64\u65b9\u6cd5\u9488\u5bf9Transformer\u6a21\u578b\u8bbe\u8ba1\uff0c\u8003\u8651\u4e86\u6b8b\u5dee\u8fde\u63a5\u548c\u591a\u5934\u6ce8\u610f\u529b\u5c42\u7684\u6311\u6218\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5c06\u5fae\u8c03\u77e5\u8bc6\u65e0\u7f1d\u8f6c\u79fb\u5230\u65b0\u7684\u9884\u8bad\u7ec3\u9aa8\u5e72\u7f51\u7edc\u4e0a\uff0c\u800c\u65e0\u9700\u4efb\u4f55\u8bad\u7ec3\u6b65\u9aa4\u6216\u6570\u636e\u70b9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5728\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5fae\u8c03\u77e5\u8bc6\u8f6c\u79fb\u5230\u65b0\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u7248\u672c\u4e0a\uff0c\u9002\u7528\u4e8e\u89c6\u89c9\u548c\u6587\u672c\u4efb\u52a1\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2505.23596", "pdf": "https://arxiv.org/pdf/2505.23596", "abs": "https://arxiv.org/abs/2505.23596", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Mobile GUI agents aim to autonomously complete user-instructed tasks across\nmobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable\nthese agents to interpret UI screens, identify actionable elements, and perform\ninteractions such as tapping or typing. However, existing agents remain\nreactive: they reason only over the current screen and lack a structured model\nof app navigation flow, limiting their ability to understand context, detect\nunexpected outcomes, and recover from errors. We present MAPLE, a state-aware\nmulti-agent framework that abstracts app interactions as a Finite State Machine\n(FSM). We computationally model each UI screen as a discrete state and user\nactions as transitions, allowing the FSM to provide a structured representation\nof the app execution. MAPLE consists of specialized agents responsible for four\nphases of task execution: planning, execution, verification, error recovery,\nand knowledge retention. These agents collaborate to dynamically construct FSMs\nin real time based on perception data extracted from the UI screen, allowing\nthe GUI agents to track navigation progress and flow, validate action outcomes\nthrough pre- and post-conditions of the states, and recover from errors by\nrolling back to previously stable states. Our evaluation results on two\nchallenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE\noutperforms the state-of-the-art baseline, improving task success rate by up to\n12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results\nhighlight the importance of structured state modeling in guiding mobile GUI\nagents during task execution. Moreover, our FSM representation can be\nintegrated into future GUI agent architectures as a lightweight, model-agnostic\nmemory layer to support structured planning, execution verification, and error\nrecovery.", "AI": {"tldr": "MAPLE\u662f\u4e00\u79cd\u72b6\u6001\u611f\u77e5\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5c06\u5e94\u7528\u7a0b\u5e8f\u4ea4\u4e92\u5efa\u6a21\u4e3a\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\uff0c\u901a\u8fc7\u89c4\u5212\u3001\u6267\u884c\u3001\u9a8c\u8bc1\u3001\u9519\u8bef\u6062\u590d\u548c\u77e5\u8bc6\u4fdd\u7559\u4e94\u4e2a\u9636\u6bb5\u7684\u4e13\u95e8\u4ee3\u7406\u534f\u4f5c\u6765\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3001\u6062\u590d\u6210\u529f\u7387\u548c\u52a8\u4f5c\u51c6\u786e\u6027\u3002\u5728Mobile-Eval-E\u548cSPA-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cMAPLE\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff08\u6700\u591a12%\uff09\u3001\u6062\u590d\u6210\u529f\u7387\uff0813.8%\uff09\u548c\u52a8\u4f5c\u51c6\u786e\u6027\uff086.5%\uff09\u3002", "motivation": "\u73b0\u6709\u7684\u79fb\u52a8GUI\u4ee3\u7406\u4ec5\u57fa\u4e8e\u5f53\u524d\u5c4f\u5e55\u8fdb\u884c\u63a8\u7406\uff0c\u7f3a\u4e4f\u5bf9\u5e94\u7528\u5bfc\u822a\u6d41\u7a0b\u7684\u7ed3\u6784\u5316\u6a21\u578b\uff0c\u5bfc\u81f4\u5176\u5728\u7406\u89e3\u4e0a\u4e0b\u6587\u3001\u68c0\u6d4b\u610f\u5916\u7ed3\u679c\u548c\u4ece\u9519\u8bef\u4e2d\u6062\u590d\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "MAPLE\u5c06UI\u5c4f\u5e55\u5efa\u6a21\u4e3a\u79bb\u6563\u72b6\u6001\uff0c\u7528\u6237\u52a8\u4f5c\u4e3a\u72b6\u6001\u8f6c\u79fb\uff0c\u5f62\u6210\u6709\u9650\u72b6\u6001\u673a(FSM)\u3002\u6846\u67b6\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a\u89c4\u5212\u3001\u6267\u884c\u3001\u9a8c\u8bc1\u548c\u9519\u8bef\u6062\u590d\uff0c\u5e76\u901a\u8fc7\u63d0\u53d6UI\u5c4f\u5e55\u7684\u611f\u77e5\u6570\u636e\u52a8\u6001\u6784\u5efaFSM\u3002\u6b64\u5916\uff0cMAPLE\u8fd8\u5305\u62ec\u4e00\u4e2a\u77e5\u8bc6\u4fdd\u7559\u9636\u6bb5\u4ee5\u4fdd\u5b58\u5148\u524d\u7a33\u5b9a\u7684\u72b6\u6001\u4fe1\u606f\u3002", "result": "\u5728Mobile-Eval-E\u548cSPA-Bench\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u8de8\u5e94\u7528\u57fa\u51c6\u4e0a\uff0cMAPLE\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4efb\u52a1\u6210\u529f\u7387\u4e0a\u63d0\u9ad8\u4e86\u591a\u8fbe12%\uff0c\u6062\u590d\u6210\u529f\u7387\u8fbe\u523013.8%\uff0c\u52a8\u4f5c\u51c6\u786e\u6027\u63d0\u9ad8\u4e866.5%\u3002", "conclusion": "\u7ed3\u6784\u5316\u7684\u72b6\u6001\u5efa\u6a21\u5bf9\u4e8e\u6307\u5bfc\u79fb\u52a8GUI\u4ee3\u7406\u5728\u4efb\u52a1\u6267\u884c\u8fc7\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u63d0\u51fa\u7684FSM\u8868\u793a\u53ef\u4ee5\u96c6\u6210\u5230\u672a\u6765\u7684GUI\u4ee3\u7406\u67b6\u6784\u4e2d\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e14\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u8bb0\u5fc6\u5c42\uff0c\u652f\u6301\u7ed3\u6784\u5316\u89c4\u5212\u3001\u6267\u884c\u9a8c\u8bc1\u548c\u9519\u8bef\u6062\u590d\u3002"}}
{"id": "2505.23667", "pdf": "https://arxiv.org/pdf/2505.23667", "abs": "https://arxiv.org/abs/2505.23667", "authors": ["Lang Cao", "Jingxian Xu", "Hanbing Liu", "Jinyu Wang", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "title": "Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Tables are a fundamental structure for organizing and analyzing data, making\neffective table understanding a critical capability for intelligent systems.\nWhile large language models (LMs) demonstrate strong general reasoning\nabilities, they continue to struggle with accurate numerical or symbolic\nreasoning over tabular data, especially in complex scenarios. Spreadsheet\nformulas provide a powerful and expressive medium for representing executable\nsymbolic operations, encoding rich reasoning patterns that remain largely\nunderutilized. In this paper, we propose Formula Tuning (Fortune), a\nreinforcement learning (RL) framework that trains LMs to generate executable\nspreadsheet formulas for question answering over general tabular data. Formula\nTuning reduces the reliance on supervised formula annotations by using binary\nanswer correctness as a reward signal, guiding the model to learn formula\nderivation through reasoning. We provide a theoretical analysis of its\nadvantages and demonstrate its effectiveness through extensive experiments on\nseven table reasoning benchmarks. Formula Tuning substantially enhances LM\nperformance, particularly on multi-step numerical and symbolic reasoning tasks,\nenabling a 7B model to outperform O1 on table understanding. This highlights\nthe potential of formula-driven RL to advance symbolic table reasoning in LMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFormula Tuning\uff08Fortune\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u6267\u884c\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u4ee5\u8fdb\u884c\u8868\u683c\u6570\u636e\u7684\u95ee\u9898\u56de\u7b54\u3002\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5bf9\u76d1\u7763\u516c\u5f0f\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u4f7f\u7528\u7b54\u6848\u6b63\u786e\u6027\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u6765\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u5f0f\u516c\u5f0f\u63a8\u5bfc\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFormula Tuning\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u6570\u503c\u548c\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5f3a\u5927\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u8868\u683c\u6570\u636e\u65f6\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u6570\u503c\u6216\u7b26\u53f7\u63a8\u7406\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aFormula Tuning\uff08Fortune\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u4e8c\u5143\u7b54\u6848\u6b63\u786e\u6027\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u6765\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u6267\u884c\u7684\u7535\u5b50\u8868\u683c\u516c\u5f0f\u3002\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u5bf9\u76d1\u7763\u516c\u5f0f\u6ce8\u91ca\u7684\u4f9d\u8d56\uff0c\u5e76\u901a\u8fc7\u63a8\u7406\u5f15\u5bfc\u6a21\u578b\u5b66\u4e60\u516c\u5f0f\u63a8\u5bfc\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0cFormula Tuning\u663e\u8457\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u8868\u683c\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u5c24\u5176\u662f\u5728\u591a\u6b65\u6570\u503c\u548c\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e0a\u3002\u4e00\u4e2a7B\u53c2\u6570\u7684\u6a21\u578b\u5728\u8868\u683c\u7406\u89e3\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86O1\u6a21\u578b\u3002", "conclusion": "Formula Tuning\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b26\u53f7\u8868\u683c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5f3a\u8c03\u4e86\u516c\u5f0f\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u5bf9\u4e8e\u63a8\u8fdb\u8fd9\u4e00\u9886\u57df\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.22758", "pdf": "https://arxiv.org/pdf/2505.22758", "abs": "https://arxiv.org/abs/2505.22758", "authors": ["Aniruddha Nrusimha", "William Brandon", "Mayank Mishra", "Yikang Shen", "Rameswar Panda", "Jonathan Ragan-Kelley", "Yoon Kim"], "title": "FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The size and compute characteristics of modern large language models have led\nto an increased interest in developing specialized kernels tailored for\ntraining and inference. Existing kernels primarily optimize for compute\nutilization, targeting the large-batch training and inference settings.\nHowever, low-batch inference, where memory bandwidth and kernel launch\noverheads contribute are significant factors, remains important for many\napplications of interest such as in edge deployment and latency-sensitive\napplications. This paper describes FlashFormer, a proof-of-concept kernel for\naccelerating single-batch inference for transformer-based large language\nmodels. Across various model sizes and quantizations settings, we observe\nnontrivial speedups compared to existing state-of-the-art inference kernels.", "AI": {"tldr": "\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u6a21\u548c\u8ba1\u7b97\u7279\u6027\u4fc3\u4f7f\u4e86\u5bf9\u8bad\u7ec3\u548c\u63a8\u7406\u4e13\u7528\u5185\u6838\u7684\u5f00\u53d1\u5174\u8da3\u3002\u7136\u800c\uff0c\u4f4e\u6279\u91cf\u63a8\u7406\u5bf9\u4e8e\u8bb8\u591a\u5e94\u7528\uff08\u5982\u8fb9\u7f18\u90e8\u7f72\u548c\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\uff09\u4ecd\u7136\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86FlashFormer\uff0c\u4e00\u4e2a\u7528\u4e8e\u52a0\u901f\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5355\u6279\u91cf\u63a8\u7406\u7684\u6982\u5ff5\u9a8c\u8bc1\u5185\u6838\u3002\u5728\u5404\u79cd\u6a21\u578b\u5927\u5c0f\u548c\u91cf\u5316\u8bbe\u7f6e\u4e0b\uff0c\u4e0e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u7684\u63a8\u7406\u5185\u6838\u76f8\u6bd4\uff0c\u89c2\u5bdf\u5230\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u6a21\u548c\u8ba1\u7b97\u7279\u6027\u5bfc\u81f4\u4e86\u5bf9\u4e13\u95e8\u5185\u6838\u5f00\u53d1\u7684\u5174\u8da3\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u5185\u6838\u4e3b\u8981\u9488\u5bf9\u5927\u6279\u6b21\u8bad\u7ec3\u548c\u63a8\u7406\u8fdb\u884c\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u4f4e\u6279\u6b21\u63a8\u7406\u7684\u9700\u6c42\uff0c\u800c\u540e\u8005\u5bf9\u4e8e\u8fb9\u7f18\u90e8\u7f72\u548c\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u7b49\u573a\u666f\u4ecd\u7136\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86FlashFormer\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u5355\u6279\u91cf\u63a8\u7406\u52a0\u901f\u5185\u6838\u3002\u8be5\u65b9\u6cd5\u5173\u6ce8\u4e8e\u51cf\u5c11\u5185\u5b58\u5e26\u5bbd\u4f7f\u7528\u548c\u5185\u6838\u542f\u52a8\u5f00\u9500\uff0c\u4ee5\u4f18\u5316\u4f4e\u6279\u91cf\u63a8\u7406\u6027\u80fd\u3002", "result": "\u5728\u4e0d\u540c\u7684\u6a21\u578b\u5927\u5c0f\u548c\u91cf\u5316\u8bbe\u7f6e\u4e0b\uff0cFlashFormer\u76f8\u5bf9\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u63a8\u7406\u5185\u6838\u5b9e\u73b0\u4e86\u975e\u5e73\u51e1\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "FlashFormer\u4f5c\u4e3a\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u5185\u6838\uff0c\u6210\u529f\u5c55\u793a\u4e86\u5176\u5728\u5355\u6279\u91cf\u63a8\u7406\u4e2d\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u8868\u660e\u9488\u5bf9\u4f4e\u6279\u91cf\u63a8\u7406\u4f18\u5316\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2505.23686", "pdf": "https://arxiv.org/pdf/2505.23686", "abs": "https://arxiv.org/abs/2505.23686", "authors": ["Caroline Wang", "Arrasy Rahman", "Jiaxun Cui", "Yoonchang Sung", "Peter Stone"], "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.1; I.2.6; I.2.8"], "comment": null, "summary": "Developing AI agents capable of collaborating with previously unseen partners\nis a fundamental generalization challenge in multi-agent learning, known as Ad\nHoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage\npipeline, where first, a fixed population of teammates is generated with the\nidea that they should be representative of the teammates that will be seen at\ndeployment time, and second, an AHT agent is trained to collaborate well with\nagents in the population. To date, the research community has focused on\ndesigning separate algorithms for each stage. This separation has led to\nalgorithms that generate teammate pools with limited coverage of possible\nbehaviors, and that ignore whether the generated teammates are easy to learn\nfrom for the AHT agent. Furthermore, algorithms for training AHT agents\ntypically treat the set of training teammates as static, thus attempting to\ngeneralize to previously unseen partner agents without assuming any control\nover the distribution of training teammates. In this paper, we present a\nunified framework for AHT by reformulating the problem as an open-ended\nlearning process between an ad hoc agent and an adversarial teammate generator.\nWe introduce ROTATE, a regret-driven, open-ended training algorithm that\nalternates between improving the AHT agent and generating teammates that probe\nits deficiencies. Extensive experiments across diverse AHT environments\ndemonstrate that ROTATE significantly outperforms baselines at generalizing to\nan unseen set of evaluation teammates, thus establishing a new standard for\nrobust and generalizable teamwork.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aROTATE\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06Ad Hoc Teamwork\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5f00\u653e\u6027\u5b66\u4e60\u8fc7\u7a0b\u6765\u63d0\u5347AI\u4ee3\u7406\u5728\u672a\u77e5\u4f19\u4f34\u5408\u4f5c\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684Ad Hoc Teamwork\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u4e24\u9636\u6bb5\u7ba1\u9053\uff0c\u4f46\u5b58\u5728\u961f\u53cb\u884c\u4e3a\u8986\u76d6\u6709\u9650\u3001\u96be\u4ee5\u5b66\u4e60\u4ee5\u53ca\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u961f\u53cb\u96c6\u9759\u6001\u4e0d\u53d8\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u4ee5\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86ROTATE\u7b97\u6cd5\uff0c\u57fa\u4e8e\u540e\u6094\u9a71\u52a8\u7684\u5f00\u653e\u6027\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u63d0\u5347AHT\u4ee3\u7406\u80fd\u529b\u7684\u540c\u65f6\u751f\u6210\u63a2\u67e5\u5176\u7f3a\u9677\u7684\u961f\u53cb\u3002", "result": "\u5728\u591a\u79cdAHT\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cROTATE\u5728\u9762\u5bf9\u672a\u89c1\u8fc7\u7684\u8bc4\u4f30\u961f\u53cb\u65f6\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "ROTATE\u7b97\u6cd5\u4e3a\u66f4\u5f3a\u5927\u548c\u53ef\u6cdb\u5316\u7684\u56e2\u961f\u5408\u4f5c\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u961f\u53cb\u884c\u4e3a\u8986\u76d6\u4e0d\u8db3\u548c\u5b66\u4e60\u56f0\u96be\u7684\u95ee\u9898\u3002"}}
{"id": "2505.22764", "pdf": "https://arxiv.org/pdf/2505.22764", "abs": "https://arxiv.org/abs/2505.22764", "authors": ["Divya Shanmugam", "Helen Lu", "Swami Sankaranarayanan", "John Guttag"], "title": "Test-time augmentation improves efficiency in conformal prediction", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "A conformal classifier produces a set of predicted classes and provides a\nprobabilistic guarantee that the set includes the true class. Unfortunately, it\nis often the case that conformal classifiers produce uninformatively large\nsets. In this work, we show that test-time augmentation (TTA)--a technique that\nintroduces inductive biases during inference--reduces the size of the sets\nproduced by conformal classifiers. Our approach is flexible, computationally\nefficient, and effective. It can be combined with any conformal score, requires\nno model retraining, and reduces prediction set sizes by 10%-14% on average. We\nconduct an evaluation of the approach spanning three datasets, three models,\ntwo established conformal scoring methods, different guarantee strengths, and\nseveral distribution shifts to show when and why test-time augmentation is a\nuseful addition to the conformal pipeline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6d4b\u8bd5\u65f6\u589e\u5f3a\uff08TTA\uff09\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u5171\u5f62\u5206\u7c7b\u5668\u4ea7\u751f\u7684\u9884\u6d4b\u96c6\u5408\u5927\u5c0f\uff0c\u8be5\u65b9\u6cd5\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5e73\u5747\u51cf\u5c11\u4e8610%-14%\u7684\u9884\u6d4b\u96c6\u5408\u5927\u5c0f\u3002", "motivation": "\u5171\u5f62\u5206\u7c7b\u5668\u867d\u7136\u80fd\u591f\u63d0\u4f9b\u5305\u542b\u771f\u5b9e\u7c7b\u522b\u7684\u6982\u7387\u4fdd\u8bc1\uff0c\u4f46\u5176\u751f\u6210\u7684\u9884\u6d4b\u96c6\u5408\u901a\u5e38\u8fc7\u5927\u800c\u7f3a\u4e4f\u5b9e\u7528\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u51cf\u5c11\u8fd9\u4e9b\u96c6\u5408\u7684\u5927\u5c0f\u3002", "method": "\u5229\u7528\u6d4b\u8bd5\u65f6\u589e\u5f3a\uff08TTA\uff09\u6280\u672f\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5f15\u5165\u5f52\u7eb3\u504f\u7f6e\uff0c\u4ece\u800c\u51cf\u5c11\u5171\u5f62\u5206\u7c7b\u5668\u751f\u6210\u7684\u9884\u6d4b\u96c6\u5408\u5927\u5c0f\u3002\u6b64\u65b9\u6cd5\u53ef\u4e0e\u4efb\u4f55\u5171\u5f62\u8bc4\u5206\u7ed3\u5408\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u3001\u4e09\u79cd\u6a21\u578b\u3001\u4e24\u79cd\u5df2\u5efa\u7acb\u7684\u5171\u5f62\u8bc4\u5206\u65b9\u6cd5\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eTTA\u65b9\u6cd5\u5728\u4e0d\u540c\u4fdd\u8bc1\u5f3a\u5ea6\u548c\u5206\u5e03\u504f\u79fb\u4e0b\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u9884\u6d4b\u96c6\u5408\u5927\u5c0f\uff0c\u5e73\u5747\u51cf\u5c1110%-14%\u3002", "conclusion": "\u6d4b\u8bd5\u65f6\u589e\u5f3a\u662f\u4e00\u79cd\u5bf9\u5171\u5f62\u5206\u7c7b\u5668\u6709\u7528\u7684\u8865\u5145\u6280\u672f\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6982\u7387\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u5171\u5f62\u5206\u7c7b\u5668\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2505.23695", "pdf": "https://arxiv.org/pdf/2505.23695", "abs": "https://arxiv.org/abs/2505.23695", "authors": ["Ran Zhang", "Mohannad Elhamod"], "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of LLMs has led to the creation of diverse agentic\nsystems in data analysis, utilizing LLMs' capabilities to improve insight\ngeneration and visualization. In this paper, we present an agentic system that\nautomates the data-to-dashboard pipeline through modular LLM agents capable of\ndomain detection, concept extraction, multi-perspective analysis generation,\nand iterative self-reflection. Unlike existing chart QA systems, our framework\nsimulates the analytical reasoning process of business analysts by retrieving\ndomain-relevant knowledge and adapting to diverse datasets without relying on\nclosed ontologies or question templates.\n  We evaluate our system on three datasets across different domains.\nBenchmarked against GPT-4o with a single-prompt baseline, our approach shows\nimproved insightfulness, domain relevance, and analytical depth, as measured by\ntailored evaluation metrics and qualitative human assessment.\n  This work contributes a novel modular pipeline to bridge the path from raw\ndata to visualization, and opens new opportunities for human-in-the-loop\nvalidation by domain experts in business analytics. All code can be found here:\nhttps://github.com/77luvC/D2D_Data2Dashboard", "AI": {"tldr": "The paper presents a modular LLM-based agentic system that automates the data-to-dashboard pipeline, showcasing improved insightfulness, domain relevance, and analytical depth compared to GPT-4o in three cross-domain datasets.", "motivation": "To leverage LLMs' capabilities for enhancing data analysis and visualization by creating an automated, adaptable system that simulates business analysts' reasoning process without relying on closed ontologies or question templates.", "method": "Developed an agentic system with modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. This system retrieves domain-relevant knowledge and adapts to various datasets.", "result": "Evaluated on three datasets across different domains, the system outperformed GPT-4o with a single-prompt baseline in terms of insightfulness, domain relevance, and analytical depth as per tailored evaluation metrics and qualitative human assessment.", "conclusion": "This work introduces a novel modular pipeline bridging raw data to visualization, offering new opportunities for human-in-the-loop validation by domain experts in business analytics."}}
{"id": "2505.22768", "pdf": "https://arxiv.org/pdf/2505.22768", "abs": "https://arxiv.org/abs/2505.22768", "authors": ["Mert Onur Cakiroglu", "Idil Bilge Altun", "Hasan Kurban", "Elham Buxton", "Mehmet Dalkilic"], "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting remains a challenging task for foundation models due\nto temporal heterogeneity, high dimensionality, and the lack of inherent\nsymbolic structure. In this work, we propose DRAGON (Discrete Representation\nand Augmented Graph encoding Over deBruijN Graphs), a novel encoder that\nintroduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between\nsymbolic representations and neural modeling. DRAGON discretizes continuous\ninput sequences and maps them onto a fixed graph structure, enabling dynamic\ncontext recovery via graph-based attention. Integrated as an auxiliary module\nwithin a dual-branch architecture, DRAGON augments conventional CNN-based\nencoders with symbolic, structure-aware representations. All code developed for\nthis study is available at:\nhttps://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library", "AI": {"tldr": "DRAGON\u662f\u4e00\u79cd\u65b0\u7684\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u591a\u53d8\u91cfde Bruijn\u56fe\u5c06\u7b26\u53f7\u8868\u793a\u4e0e\u795e\u7ecf\u5efa\u6a21\u7ed3\u5408\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002\u5b83\u5c06\u8fde\u7eed\u8f93\u5165\u5e8f\u5217\u79bb\u6563\u5316\u5e76\u6620\u5c04\u5230\u56fa\u5b9a\u56fe\u7ed3\u6784\u4e0a\uff0c\u901a\u8fc7\u57fa\u4e8e\u56fe\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u52a8\u6001\u4e0a\u4e0b\u6587\u6062\u590d\uff0c\u5e76\u589e\u5f3a\u4e86\u4f20\u7edf\u7684CNN\u7f16\u7801\u5668\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5bf9\u4e8e\u57fa\u7840\u6a21\u578b\u6765\u8bf4\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u56e0\u4e3a\u5b58\u5728\u65f6\u95f4\u5f02\u8d28\u6027\u3001\u9ad8\u7ef4\u5ea6\u548c\u7f3a\u4e4f\u5185\u5728\u7b26\u53f7\u7ed3\u6784\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5f25\u5408\u7b26\u53f7\u8868\u793a\u548c\u795e\u7ecf\u5efa\u6a21\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86DRAGON\uff08\u5728de Bruijn\u56fe\u4e0a\u7684\u79bb\u6563\u8868\u793a\u548c\u589e\u5f3a\u56fe\u7f16\u7801\uff09\uff0c\u5f15\u5165\u4e86\u591a\u53d8\u91cfde Bruijn\u56fe\uff08MdBGs\uff09\u4f5c\u4e3a\u8f85\u52a9\u6a21\u5757\u96c6\u6210\u5230\u53cc\u5206\u652f\u67b6\u6784\u4e2d\uff0c\u4ee5\u589e\u5f3a\u5e38\u89c4\u57fa\u4e8eCNN\u7684\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u7b26\u53f7\u548c\u7ed3\u6784\u611f\u77e5\u8868\u793a\u3002", "result": "\u901a\u8fc7\u79bb\u6563\u5316\u8fde\u7eed\u8f93\u5165\u5e8f\u5217\u5e76\u5c06\u5176\u6620\u5c04\u5230\u56fa\u5b9a\u7684\u56fe\u7ed3\u6784\u4e0a\uff0cDRAGON\u80fd\u591f\u901a\u8fc7\u57fa\u4e8e\u56fe\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u52a8\u6001\u4e0a\u4e0b\u6587\u6062\u590d\u3002", "conclusion": "DRAGON\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u8868\u793a\u548c\u795e\u7ecf\u5efa\u6a21\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2505.23703", "pdf": "https://arxiv.org/pdf/2505.23703", "abs": "https://arxiv.org/abs/2505.23703", "authors": ["Ruida Wang", "Yuxin Li", "Yi R.", "Fung", "Tong Zhang"], "title": "Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability", "categories": ["cs.AI"], "comment": null, "summary": "Enhancing the mathematical reasoning capabilities of LLMs has garnered\nsignificant attention in both the mathematical and computer science\ncommunities. Recent works have made substantial progress in both Natural\nLanguage (NL) reasoning and Formal Language (FL) reasoning by leveraging the\npotential of pure Reinforcement Learning (RL) methods on base models. However,\nRL approaches struggle to impart new capabilities not presented in the base\nmodel, highlighting the need to integrate more knowledge like FL into NL math\nreasoning effectively. Yet, this integration is challenging due to inherent\ndisparities in problem structure and reasoning format between NL and FL. To\naddress these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end\nframework designed to incorporate the FL expert into NL math problem-solving.\nTo bridge the NL and FL input format gap, we propose the *NL-FL Problem\nAlignment* method, which reformulates the Question-Answering (QA) problems in\nNL as existence theorems in FL. Subsequently, the *Mixed Problem Input*\ntechnique we provide enables the FL reasoner to handle both QA and existence\nproblems concurrently. Lastly, we mitigate the NL and FL output format gap in\nreasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive\nexperiments demonstrate that the **HybridReasoning** framework achieves\n**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC\nbenchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.\nNotably, some problems resolved by our framework remain unsolved by the NL\nbaseline model even under a larger number of trials.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165NL-FL HybridReasoning\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u5f62\u5f0f\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5728\u6570\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u5907\u53d7\u5173\u6ce8\u3002\u7136\u800c\uff0c\u7eaf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u867d\u7136\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u96be\u4ee5\u8d4b\u4e88\u57fa\u7840\u6a21\u578b\u672a\u5177\u5907\u7684\u65b0\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u6574\u5408\u5f62\u5f0f\u8bed\u8a00\uff08FL\uff09\u77e5\u8bc6\u5230\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u6570\u5b66\u63a8\u7406\u4e2d\u3002\u4f46\u7531\u4e8eNL\u548cFL\u5728\u95ee\u9898\u7ed3\u6784\u548c\u63a8\u7406\u683c\u5f0f\u4e0a\u7684\u5dee\u5f02\uff0c\u8fd9\u79cd\u6574\u5408\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u6846\u67b6NL-FL HybridReasoning\uff0c\u5c06\u5f62\u5f0f\u8bed\u8a00\u4e13\u5bb6\u878d\u5165\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1) NL-FL Problem Alignment\u65b9\u6cd5\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u95ee\u7b54\u95ee\u9898\u8f6c\u5316\u4e3a\u5f62\u5f0f\u8bed\u8a00\u4e2d\u7684\u5b58\u5728\u5b9a\u7406\uff1b2) Mixed Problem Input\u6280\u672f\uff0c\u4f7f\u5f62\u5f0f\u8bed\u8a00\u63a8\u7406\u5668\u80fd\u591f\u540c\u65f6\u5904\u7406\u95ee\u7b54\u548c\u5b58\u5728\u6027\u95ee\u9898\uff1b3) \u57fa\u4e8eLLM\u7684Answer Extraction\u673a\u5236\uff0c\u5f25\u5408\u81ea\u7136\u8bed\u8a00\u548c\u5f62\u5f0f\u8bed\u8a00\u8f93\u51fa\u683c\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHybridReasoning\u6846\u67b6\u5728MATH-500\u548cAMC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u5230\u4e8689.80%\u548c84.34%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u4ec5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u57fa\u7ebf\u6a21\u578b\u5206\u522b\u9ad8\u51fa4.60%\u548c4.82%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6709\u4e9b\u95ee\u9898\u5373\u4f7f\u5728\u66f4\u591a\u7684\u5c1d\u8bd5\u6b21\u6570\u4e0b\uff0c\u4e5f\u4ec5\u80fd\u88ab\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u800c\u4e0d\u80fd\u88abNL\u57fa\u7ebf\u6a21\u578b\u89e3\u51b3\u3002", "conclusion": "NL-FL HybridReasoning\u6846\u67b6\u6709\u6548\u5730\u6574\u5408\u4e86\u5f62\u5f0f\u8bed\u8a00\u548c\u81ea\u7136\u8bed\u8a00\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u63d0\u5347LLMs\u6570\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.22772", "pdf": "https://arxiv.org/pdf/2505.22772", "abs": "https://arxiv.org/abs/2505.22772", "authors": ["Claas Voelcker", "Anastasiia Pedan", "Arash Ahmadian", "Romina Abachi", "Igor Gilitschenski", "Amir-massoud Farahmand"], "title": "Calibrated Value-Aware Model Learning with Stochastic Environment Models", "categories": ["cs.LG"], "comment": null, "summary": "The idea of value-aware model learning, that models should produce accurate\nvalue estimates, has gained prominence in model-based reinforcement learning.\nThe MuZero loss, which penalizes a model's value function prediction compared\nto the ground-truth value function, has been utilized in several prominent\nempirical works in the literature. However, theoretical investigation into its\nstrengths and weaknesses is limited. In this paper, we analyze the family of\nvalue-aware model learning losses, which includes the popular MuZero loss. We\nshow that these losses, as normally used, are uncalibrated surrogate losses,\nwhich means that they do not always recover the correct model and value\nfunction. Building on this insight, we propose corrections to solve this issue.\nFurthermore, we investigate the interplay between the loss calibration, latent\nmodel architectures, and auxiliary losses that are commonly employed when\ntraining MuZero-style agents. We show that while deterministic models can be\nsufficient to predict accurate values, learning calibrated stochastic models is\nstill advantageous.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u4ef7\u503c\u611f\u77e5\u6a21\u578b\u5b66\u4e60\u635f\u5931\uff08\u5305\u62ecMuZero\u635f\u5931\uff09\u7684\u6821\u51c6\u95ee\u9898\uff0c\u63ed\u793a\u5176\u4f5c\u4e3a\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u65f6\u53ef\u80fd\u65e0\u6cd5\u6b63\u786e\u6062\u590d\u6a21\u578b\u548c\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u63d0\u51fa\u4e86\u4fee\u6b63\u65b9\u6848\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u635f\u5931\u6821\u51c6\u3001\u6f5c\u5728\u6a21\u578b\u67b6\u6784\u53ca\u8f85\u52a9\u635f\u5931\u5728\u8bad\u7ec3MuZero\u98ce\u683c\u4ee3\u7406\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u4ef7\u503c\u611f\u77e5\u6a21\u578b\u5b66\u4e60\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u5360\u636e\u91cd\u8981\u5730\u4f4d\uff0c\u4f46\u5bf9\u5176\u635f\u5931\u51fd\u6570\uff08\u5982MuZero\u635f\u5931\uff09\u7684\u7406\u8bba\u7814\u7a76\u6709\u9650\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u4ef7\u503c\u611f\u77e5\u6a21\u578b\u5b66\u4e60\u635f\u5931\u5bb6\u65cf\uff0c\u6307\u51fa\u8fd9\u4e9b\u635f\u5931\u901a\u5e38\u662f\u672a\u6821\u51c6\u7684\u66ff\u4ee3\u635f\u5931\uff0c\u53ef\u80fd\u5bfc\u81f4\u65e0\u6cd5\u6b63\u786e\u6062\u590d\u6a21\u578b\u548c\u4ef7\u503c\u51fd\u6570\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4fee\u6b63\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u635f\u5931\u6821\u51c6\u4e0e\u6a21\u578b\u67b6\u6784\u548c\u8f85\u52a9\u635f\u5931\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u786e\u5b9a\u6027\u6a21\u578b\u8db3\u4ee5\u9884\u6d4b\u51c6\u786e\u7684\u4ef7\u503c\uff0c\u4f46\u5b66\u4e60\u6821\u51c6\u7684\u968f\u673a\u6a21\u578b\u4ecd\u7136\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u4ef7\u503c\u611f\u77e5\u6a21\u578b\u5b66\u4e60\u635f\u5931\u9700\u8981\u6821\u51c6\u4ee5\u786e\u4fdd\u6b63\u786e\u7684\u6a21\u578b\u548c\u4ef7\u503c\u51fd\u6570\u6062\u590d\uff0c\u4e14\u6821\u51c6\u7684\u968f\u673a\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2505.23746", "pdf": "https://arxiv.org/pdf/2505.23746", "abs": "https://arxiv.org/abs/2505.23746", "authors": ["Hugo Henry", "Kelly Cohen"], "title": "Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons", "categories": ["cs.AI", "cs.NE"], "comment": "11 pages and 23 figures", "summary": "This study investigates the application of Genetic Fuzzy Systems (GFS) to\nmodel the self-noise generated by airfoils, a key issue in aeroaccoustics with\nsignificant implications for aerospace, automotive and drone applications.\nUsing the publicly available Airfoil Self Noise dataset, various Fuzzy\nregression strategies are explored and compared. The paper evaluates a brute\nforce Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading\nGeneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on\nFuzzy C-means (FCM) to reduce the model's complexity. This highlights the\nviability of clustering assisted fuzzy inference as an effective regression\ntool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression,\nCascading systems, Clustering and AI.", "AI": {"tldr": "The study explores the use of Genetic Fuzzy Systems (GFS) to model airfoil self-noise, comparing different fuzzy regression strategies including brute force TSK, cascading GFT, and a novel FCM-based clustered approach.", "motivation": "To address the challenge of modeling airfoil self-noise which is crucial for aerospace, automotive, and drone applications.", "method": "Using the Airfoil Self Noise dataset, the study compares various fuzzy regression methods: a high rule density Takagi Sugeno Kang (TSK) system, a cascading Genetic Fuzzy Tree (GFT), and a new Fuzzy C-means (FCM) clustering method.", "result": "Clustering-assisted fuzzy inference was found to be an effective tool for complex aeroacoustic regression tasks, with the novel FCM-based approach showing promise in reducing model complexity.", "conclusion": "Genetic Fuzzy Systems, particularly when combined with clustering techniques, are viable for modeling complex aeroacoustic phenomena like airfoil self-noise."}}
{"id": "2505.22778", "pdf": "https://arxiv.org/pdf/2505.22778", "abs": "https://arxiv.org/abs/2505.22778", "authors": ["Sarah Meiklejohn", "Hayden Blauzvern", "Mihai Maruseac", "Spencer Schrock", "Laurent Simon", "Ilia Shumailov"], "title": "Machine Learning Models Have a Supply Chain Problem", "categories": ["cs.LG", "cs.CR"], "comment": "12 pages, four figures and one table", "summary": "Powerful machine learning (ML) models are now readily available online, which\ncreates exciting possibilities for users who lack the deep technical expertise\nor substantial computing resources needed to develop them. On the other hand,\nthis type of open ecosystem comes with many risks. In this paper, we argue that\nthe current ecosystem for open ML models contains significant supply-chain\nrisks, some of which have been exploited already in real attacks. These include\nan attacker replacing a model with something malicious (e.g., malware), or a\nmodel being trained using a vulnerable version of a framework or on restricted\nor poisoned data. We then explore how Sigstore, a solution designed to bring\ntransparency to open-source software supply chains, can be used to bring\ntransparency to open ML models, in terms of enabling model publishers to sign\ntheir models and prove properties about the datasets they use.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5f00\u653e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4f7f\u7528Sigstore\u4e3a\u8fd9\u4e9b\u6a21\u578b\u548c\u6570\u636e\u96c6\u63d0\u4f9b\u900f\u660e\u6027\u548c\u8ba4\u8bc1\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5f00\u653e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f7f\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u6216\u8d44\u6e90\u7684\u7528\u6237\u80fd\u591f\u4f7f\u7528\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u4f46\u8fd9\u79cd\u5f00\u653e\u751f\u6001\u4e5f\u5e26\u6765\u4e86\u8bb8\u591a\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4f8b\u5982\u6a21\u578b\u88ab\u6076\u610f\u66ff\u6362\u3001\u8bad\u7ec3\u6846\u67b6\u5b58\u5728\u6f0f\u6d1e\u6216\u6570\u636e\u53d7\u5230\u6c61\u67d3\u7b49\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u5f00\u653e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u5e76\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528Sigstore\uff08\u4e00\u79cd\u65e8\u5728\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5e26\u6765\u900f\u660e\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\uff09\u6765\u5b9e\u73b0\u5bf9\u5f00\u653e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u7b7e\u540d\u8ba4\u8bc1\uff0c\u4ee5\u53ca\u8bc1\u660e\u6240\u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u5c5e\u6027\u3002", "result": "\u901a\u8fc7\u5f15\u5165Sigstore\u673a\u5236\uff0c\u53ef\u4ee5\u589e\u5f3a\u5f00\u653e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u900f\u660e\u6027\uff0c\u5141\u8bb8\u6a21\u578b\u53d1\u5e03\u8005\u5bf9\u5176\u6a21\u578b\u8fdb\u884c\u7b7e\u540d\u5e76\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u53ef\u4fe1\u6027\uff0c\u4ece\u800c\u964d\u4f4e\u4f9b\u5e94\u94fe\u653b\u51fb\u7684\u98ce\u9669\u3002", "conclusion": "\u5f00\u653e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u800c\u91c7\u7528\u7c7b\u4f3cSigstore\u7684\u6280\u672f\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8be5\u9886\u57df\u7684\u5b89\u5168\u6027\u548c\u900f\u660e\u6027\u3002"}}
{"id": "2505.23762", "pdf": "https://arxiv.org/pdf/2505.23762", "abs": "https://arxiv.org/abs/2505.23762", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of large Vision-Language Models (VLMs) has propelled\nthe development of pure-vision-based GUI Agents, capable of perceiving and\noperating Graphical User Interfaces (GUI) to autonomously fulfill user\ninstructions. However, existing approaches usually adopt an offline learning\nframework, which faces two core limitations: (1) heavy reliance on high-quality\nmanual annotations for element grounding and action supervision, and (2)\nlimited adaptability to dynamic and interactive environments. To address these\nlimitations, we propose ZeroGUI, a scalable, online learning framework for\nautomating GUI Agent training at Zero human cost. Specifically, ZeroGUI\nintegrates (i) VLM-based automatic task generation to produce diverse training\ngoals from the current environment state, (ii) VLM-based automatic reward\nestimation to assess task success without hand-crafted evaluation functions,\nand (iii) two-stage online reinforcement learning to continuously interact with\nand learn from GUI environments. Experiments on two advanced GUI Agents\n(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance\nacross OSWorld and AndroidLab environments. The code is available at\nhttps://github.com/OpenGVLab/ZeroGUI.", "AI": {"tldr": "ZeroGUI \u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5728\u7ebf\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ee5\u96f6\u4eba\u5de5\u6210\u672c\u81ea\u52a8\u5316 GUI \u4ee3\u7406\u8bad\u7ec3\u3002\u5b83\u901a\u8fc7 VLM \u57fa\u7840\u7684\u81ea\u52a8\u4efb\u52a1\u751f\u6210\u3001\u5956\u52b1\u8bc4\u4f30\u548c\u4e24\u9636\u6bb5\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\u548c\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7eaf\u89c6\u89c9 GUI \u4ee3\u7406\u65b9\u6cd5\u91c7\u7528\u79bb\u7ebf\u5b66\u4e60\u6846\u67b6\uff0c\u4f9d\u8d56\u9ad8\u8d28\u91cf\u7684\u4eba\u5de5\u6ce8\u91ca\u4e14\u5728\u52a8\u6001\u4ea4\u4e92\u73af\u5883\u4e2d\u9002\u5e94\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa ZeroGUI \u6846\u67b6\uff0c\u5305\u542b\uff1a(i) \u57fa\u4e8e VLM \u7684\u81ea\u52a8\u4efb\u52a1\u751f\u6210\uff1b(ii) \u57fa\u4e8e VLM \u7684\u81ea\u52a8\u5956\u52b1\u8bc4\u4f30\uff1b(iii) \u4e24\u9636\u6bb5\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728 OSWorld \u548c AndroidLab \u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u4e24\u4e2a\u9ad8\u7ea7 GUI \u4ee3\u7406\uff08UI-TARS \u548c Aguvis\uff09\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cZeroGUI \u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "ZeroGUI \u63d0\u4f9b\u4e86\u4e00\u79cd\u96f6\u4eba\u5de5\u6210\u672c\u7684\u81ea\u52a8\u5316 GUI \u4ee3\u7406\u8bad\u7ec3\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u4ee3\u7406\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2505.22785", "pdf": "https://arxiv.org/pdf/2505.22785", "abs": "https://arxiv.org/abs/2505.22785", "authors": ["Marco Fumero", "Luca Moschella", "Emanuele Rodol\u00e0", "Francesco Locatello"], "title": "Navigating the Latent Space Dynamics of Neural Models", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks transform high-dimensional data into compact, structured\nrepresentations, often modeled as elements of a lower dimensional latent space.\nIn this paper, we present an alternative interpretation of neural models as\ndynamical systems acting on the latent manifold. Specifically, we show that\nautoencoder models implicitly define a latent vector field on the manifold,\nderived by iteratively applying the encoding-decoding map, without any\nadditional training. We observe that standard training procedures introduce\ninductive biases that lead to the emergence of attractor points within this\nvector field. Drawing on this insight, we propose to leverage the vector field\nas a representation for the network, providing a novel tool to analyze the\nproperties of the model and the data. This representation enables to: (i)\nanalyze the generalization and memorization regimes of neural models, even\nthroughout training; (ii) extract prior knowledge encoded in the network's\nparameters from the attractors, without requiring any input data; (iii)\nidentify out-of-distribution samples from their trajectories in the vector\nfield. We further validate our approach on vision foundation models, showcasing\nthe applicability and effectiveness of our method in real-world scenarios.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u89e3\u91ca\u4e3a\u4f5c\u7528\u4e8e\u6f5c\u5728\u6d41\u5f62\u4e0a\u7684\u52a8\u529b\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u5176\u9690\u542b\u7684\u5411\u91cf\u573a\u6765\u5206\u6790\u6a21\u578b\u548c\u6570\u636e\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u901a\u8fc7\u964d\u7ef4\u5c06\u9ad8\u7ef4\u6570\u636e\u8f6c\u6362\u4e3a\u7d27\u51d1\u8868\u793a\uff0c\u4f46\u4f5c\u8005\u5e0c\u671b\u4ece\u52a8\u529b\u7cfb\u7edf\u7684\u89d2\u5ea6\u91cd\u65b0\u89e3\u8bfb\u795e\u7ecf\u6a21\u578b\uff0c\u4ee5\u63ed\u793a\u5176\u66f4\u6df1\u5c42\u6b21\u7684\u7279\u6027\u3002", "method": "\u901a\u8fc7\u53cd\u590d\u5e94\u7528\u7f16\u7801-\u89e3\u7801\u6620\u5c04\uff0c\u5c55\u793a\u81ea\u7f16\u7801\u5668\u6a21\u578b\u5728\u6f5c\u5728\u6d41\u5f62\u4e0a\u9690\u5f0f\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5411\u91cf\u573a\uff1b\u5e76\u89c2\u5bdf\u5230\u6807\u51c6\u8bad\u7ec3\u8fc7\u7a0b\u4f1a\u5f15\u5165\u5438\u5f15\u5b50\u70b9\u7684\u5f52\u7eb3\u504f\u5dee\uff0c\u4ece\u800c\u5229\u7528\u8be5\u5411\u91cf\u573a\u4f5c\u4e3a\u7f51\u7edc\u7684\u65b0\u8868\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5206\u6790\u795e\u7ecf\u6a21\u578b\u7684\u6cdb\u5316\u4e0e\u8bb0\u5fc6\u6a21\u5f0f\u3001\u63d0\u53d6\u7f51\u7edc\u53c2\u6570\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\u3001\u4ee5\u53ca\u8bc6\u522b\u5206\u5e03\u5916\u6837\u672c\uff0c\u5e76\u4e14\u5728\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u795e\u7ecf\u6a21\u578b\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3a\u4f5c\u7528\u4e8e\u6f5c\u5728\u6d41\u5f62\u4e0a\u7684\u52a8\u529b\u7cfb\u7edf\uff0c\u5176\u9690\u542b\u7684\u5411\u91cf\u573a\u4e3a\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u548c\u6570\u636e\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2505.22798", "pdf": "https://arxiv.org/pdf/2505.22798", "abs": "https://arxiv.org/abs/2505.22798", "authors": ["Anton Bj\u00f6rklund", "Mykola Zaitsev", "Marta Kwiatkowska"], "title": "Efficient Preimage Approximation for Neural Network Certification", "categories": ["cs.LG", "cs.AI", "cs.CR", "68T07"], "comment": null, "summary": "The growing reliance on artificial intelligence in safety- and\nsecurity-critical applications demands effective neural network certification.\nA challenging real-world use case is certification against ``patch attacks'',\nwhere adversarial patches or lighting conditions obscure parts of images, for\nexample traffic signs. One approach to certification, which also gives\nquantitative coverage estimates, utilizes preimages of neural networks, i.e.,\nthe set of inputs that lead to a specified output. However, these preimage\napproximation methods, including the state-of-the-art PREMAP algorithm,\nstruggle with scalability. This paper presents novel algorithmic improvements\nto PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved\nbranching heuristics. We demonstrate efficiency improvements of at least an\norder of magnitude on reinforcement learning control benchmarks, and show that\nour method scales to convolutional neural networks that were previously\ninfeasible. Our results demonstrate the potential of preimage approximation\nmethodology for reliability and robustness certification.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u6539\u8fdbPREMAP\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u8ba4\u8bc1\u4e2d\u524d\u50cf\u903c\u8fd1\u65b9\u6cd5\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297'\u8865\u4e01\u653b\u51fb'\u65b9\u9762\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u5b89\u5168\u548c\u5b89\u4fdd\u5173\u952e\u5e94\u7528\u4e2d\u7684\u4f9d\u8d56\u65e5\u76ca\u589e\u52a0\uff0c\u5bf9\u795e\u7ecf\u7f51\u7edc\u7684\u6709\u6548\u8ba4\u8bc1\u9700\u6c42\u4e5f\u968f\u4e4b\u589e\u957f\u3002\u7279\u522b\u662f\u5728\u9762\u5bf9'\u8865\u4e01\u653b\u51fb'\u65f6\uff0c\u8fd9\u79cd\u9700\u6c42\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9PREMAP\u7b97\u6cd5\u7684\u65b0\u6539\u8fdb\uff0c\u5305\u62ec\u66f4\u7d27\u5bc6\u7684\u754c\u9650\u3001\u81ea\u9002\u5e94\u8499\u7279\u5361\u6d1b\u91c7\u6837\u548c\u6539\u8fdb\u7684\u5206\u652f\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5176\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "result": "\u8fd9\u4e9b\u6539\u8fdb\u4f7f\u5f97\u5728\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u57fa\u51c6\u4e0a\u7684\u6548\u7387\u81f3\u5c11\u63d0\u9ad8\u4e86\u5341\u500d\uff0c\u5e76\u4e14\u65b9\u6cd5\u53ef\u4ee5\u6269\u5c55\u5230\u4ee5\u524d\u65e0\u6cd5\u5904\u7406\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u7ed3\u679c\u5c55\u793a\u4e86\u524d\u50cf\u903c\u8fd1\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u548c\u7a33\u5065\u6027\u8ba4\u8bc1\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.22803", "pdf": "https://arxiv.org/pdf/2505.22803", "abs": "https://arxiv.org/abs/2505.22803", "authors": ["Pedro Mendes", "Paolo Romano", "David Garlan"], "title": "CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reliable uncertainty estimation is critical for deploying neural networks\n(NNs) in real-world applications. While existing calibration techniques often\nrely on post-hoc adjustments or coarse-grained binning methods, they remain\nlimited in scalability, differentiability, and generalization across domains.\nIn this work, we introduce CLUE (Calibration via Learning Uncertainty-Error\nAlignment), a novel approach that explicitly aligns predicted uncertainty with\nobserved error during training, grounded in the principle that well-calibrated\nmodels should produce uncertainty estimates that match their empirical loss.\nCLUE adopts a novel loss function that jointly optimizes predictive performance\nand calibration, using summary statistics of uncertainty and loss as proxies.\nThe proposed method is fully differentiable, domain-agnostic, and compatible\nwith standard training pipelines. Through extensive experiments on vision,\nregression, and language modeling tasks, including out-of-distribution and\ndomain-shift scenarios, we demonstrate that CLUE achieves superior calibration\nquality and competitive predictive performance with respect to state-of-the-art\napproaches without imposing significant computational overhead.", "AI": {"tldr": "CLUE\u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u89c2\u5bdf\u5230\u7684\u8bef\u5dee\u5bf9\u9f50\uff0c\u4ee5\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u5b83\u5177\u6709\u5b8c\u5168\u53ef\u5fae\u5206\u3001\u9886\u57df\u65e0\u5173\u548c\u4e0e\u6807\u51c6\u8bad\u7ec3\u6d41\u7a0b\u517c\u5bb9\u7684\u7279\u70b9\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6821\u51c6\u8d28\u91cf\u548c\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6821\u51c6\u6280\u672f\u5b58\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u5fae\u5206\u6027\u548c\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u7684\u9650\u5236\uff0c\u65e0\u6cd5\u5145\u5206\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u4e2d\u795e\u7ecf\u7f51\u7edc\u5bf9\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u9700\u6c42\u3002", "method": "CLUE\uff08\u901a\u8fc7\u5b66\u4e60\u4e0d\u786e\u5b9a\u6027-\u8bef\u5dee\u5bf9\u9f50\u8fdb\u884c\u6821\u51c6\uff09\u91c7\u7528\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u660e\u786e\u5730\u5c06\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u89c2\u6d4b\u8bef\u5dee\u5bf9\u9f50\u3002\u5b83\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u4e0e\u635f\u5931\u7684\u6c47\u603b\u7edf\u8ba1\u4f5c\u4e3a\u4ee3\u7406\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u8054\u5408\u4f18\u5316\u9884\u6d4b\u6027\u80fd\u548c\u6821\u51c6\u3002\u8be5\u65b9\u6cd5\u5b8c\u5168\u53ef\u5fae\u5206\u3001\u9886\u57df\u65e0\u5173\uff0c\u5e76\u4e14\u4e0e\u6807\u51c6\u8bad\u7ec3\u6d41\u7a0b\u517c\u5bb9\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u89c6\u89c9\u3001\u56de\u5f52\u548c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\uff0c\u4ee5\u53ca\u5206\u5e03\u5916\u548c\u9886\u57df\u8fc1\u79fb\u573a\u666f\uff0cCLUE\u5c55\u73b0\u51fa\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u66f4\u4f18\u8d8a\u7684\u6821\u51c6\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u800c\u4e0d\u4f1a\u589e\u52a0\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "CLUE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u7684\u6821\u51c6\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\u548c\u573a\u666f\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\u548c\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2505.22825", "pdf": "https://arxiv.org/pdf/2505.22825", "abs": "https://arxiv.org/abs/2505.22825", "authors": ["Michael Klamkin", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have\nrecently garnered significant attention, reflecting a broader trend of\nleveraging ML to approximate and/or accelerate the resolution of complex\noptimization problems. These developments are necessitated by the increased\nvolatility and scale in energy production for modern and future grids. However,\nprogress in ML for OPF is hindered by the lack of standardized datasets and\nevaluation metrics, from generating and solving OPF instances, to training and\nbenchmarking machine learning models. To address this challenge, this paper\nintroduces PGLearn, a comprehensive suite of standardized datasets and\nevaluation tools for ML and OPF. PGLearn provides datasets that are\nrepresentative of real-life operating conditions, by explicitly capturing both\nglobal and local variability in the data generation, and by, for the first\ntime, including time series data for several large-scale systems. In addition,\nit supports multiple OPF formulations, including AC, DC, and second-order cone\nformulations. Standardized datasets are made publicly available to democratize\naccess to this field, reduce the burden of data generation, and enable the fair\ncomparison of various methodologies. PGLearn also includes a robust toolkit for\ntraining, evaluating, and benchmarking machine learning models for OPF, with\nthe goal of standardizing performance evaluation across the field. By promoting\nopen, standardized datasets and evaluation metrics, PGLearn aims at\ndemocratizing and accelerating research and innovation in machine learning\napplications for optimal power flow problems. Datasets are available for\ndownload at https://www.huggingface.co/PGLearn.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aPGLearn\u7684\u7efc\u5408\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u5de5\u5177\u5957\u4ef6\uff0c\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5728\u6700\u4f18\u6f6e\u6d41\uff08OPF\uff09\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002\u5b83\u63d0\u4f9b\u4e86\u5177\u6709\u4ee3\u8868\u6027\u7684\u6570\u636e\u96c6\u3001\u591a\u79cdOPF\u516c\u5f0f\u652f\u6301\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u516c\u5e73\u6bd4\u8f83\u548c\u7814\u7a76\u52a0\u901f\u3002", "motivation": "\u5f53\u524d\u5728\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\u4e2d\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u7814\u7a76\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u8fd9\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u5c55\u3002", "method": "\u5f15\u5165PGLearn\uff0c\u4e00\u4e2a\u5305\u542b\u6807\u51c6\u5316\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u5de5\u5177\u7684\u5957\u4ef6\u3002\u6570\u636e\u96c6\u6355\u6349\u4e86\u5168\u5c40\u548c\u5c40\u90e8\u6570\u636e\u53d8\u5316\uff0c\u5e76\u9996\u6b21\u5305\u62ec\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u652f\u6301\u591a\u79cdOPF\u516c\u5f0f\uff0c\u5e76\u63d0\u4f9b\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u548c\u5f3a\u5927\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u3001\u8bc4\u4f30\u53ca\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u3002", "result": "PGLearn\u901a\u8fc7\u63d0\u4f9b\u5f00\u653e\u4e14\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7814\u7a76\u7684\u6c11\u4e3b\u5316\u548c\u52a0\u901f\u3002", "conclusion": "PGLearn\u7684\u63a8\u51fa\u6709\u52a9\u4e8e\u89e3\u51b3\u6570\u636e\u751f\u6210\u8d1f\u62c5\u91cd\u548c\u65b9\u6cd5\u516c\u5e73\u6bd4\u8f83\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63a8\u52a8\u673a\u5668\u5b66\u4e60\u5728\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u3002"}}
{"id": "2505.22813", "pdf": "https://arxiv.org/pdf/2505.22813", "abs": "https://arxiv.org/abs/2505.22813", "authors": ["Josiah Couch", "Miao Li", "Rima Arnaout", "Ramy Arnaout"], "title": "X-Factor: Quality Is a Dataset-Intrinsic Property", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": "13 pages, 7 figures", "summary": "In the universal quest to optimize machine-learning classifiers, three\nfactors -- model architecture, dataset size, and class balance -- have been\nshown to influence test-time performance but do not fully account for it.\nPreviously, evidence was presented for an additional factor that can be\nreferred to as dataset quality, but it was unclear whether this was actually a\njoint property of the dataset and the model architecture, or an intrinsic\nproperty of the dataset itself. If quality is truly dataset-intrinsic and\nindependent of model architecture, dataset size, and class balance, then the\nsame datasets should perform better (or worse) regardless of these other\nfactors. To test this hypothesis, here we create thousands of datasets, each\ncontrolled for size and class balance, and use them to train classifiers with a\nwide range of architectures, from random forests and support-vector machines to\ndeep networks. We find that classifier performance correlates strongly by\nsubset across architectures ($R^2=0.79$), supporting quality as an intrinsic\nproperty of datasets independent of dataset size and class balance and of model\narchitecture. Digging deeper, we find that dataset quality appears to be an\nemergent property of something more fundamental: the quality of datasets'\nconstituent classes. Thus, quality joins size, class balance, and model\narchitecture as an independent correlate of performance and a separate target\nfor optimizing machine-learning-based classification.", "AI": {"tldr": "\u5728\u4f18\u5316\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u666e\u904d\u8ffd\u6c42\u4e2d\uff0c\u7814\u7a76\u53d1\u73b0\u6570\u636e\u96c6\u8d28\u91cf\u662f\u72ec\u7acb\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u3001\u7c7b\u522b\u5e73\u8861\u548c\u6a21\u578b\u67b6\u6784\u7684\u4e00\u4e2a\u91cd\u8981\u56e0\u7d20\u3002\u672c\u7814\u7a76\u901a\u8fc7\u521b\u5efa\u6570\u5343\u4e2a\u63a7\u5236\u4e86\u5927\u5c0f\u548c\u7c7b\u522b\u5e73\u8861\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u67b6\u6784\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u8bad\u7ec3\uff0c\u53d1\u73b0\u5206\u7c7b\u5668\u6027\u80fd\u4e0e\u5b50\u96c6\u5728\u4e0d\u540c\u67b6\u6784\u95f4\u5f3a\u70c8\u76f8\u5173\uff08$R^2=0.79$\uff09\uff0c\u8fd9\u8868\u660e\u8d28\u91cf\u662f\u6570\u636e\u96c6\u672c\u8eab\u7684\u4e00\u79cd\u5185\u5728\u5c5e\u6027\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\uff0c\u6570\u636e\u96c6\u8d28\u91cf\u4f3c\u4e4e\u662f\u5176\u7ec4\u6210\u7c7b\u522b\u7684\u8d28\u91cf\u7684\u4e00\u79cd\u6d8c\u73b0\u5c5e\u6027\u3002\u56e0\u6b64\uff0c\u8d28\u91cf\u4f5c\u4e3a\u72ec\u7acb\u56e0\u7d20\u52a0\u5165\u5927\u5c0f\u3001\u7c7b\u522b\u5e73\u8861\u548c\u6a21\u578b\u67b6\u6784\uff0c\u6210\u4e3a\u4f18\u5316\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6027\u80fd\u7684\u5355\u72ec\u76ee\u6807\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u77e5\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u96c6\u5927\u5c0f\u548c\u7c7b\u522b\u5e73\u8861\u4f1a\u5f71\u54cd\u6d4b\u8bd5\u65f6\u7684\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u56e0\u7d20\u5e76\u4e0d\u80fd\u5b8c\u5168\u89e3\u91ca\u6027\u80fd\u5dee\u5f02\u3002\u4e4b\u524d\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u6570\u636e\u96c6\u8d28\u91cf\u8fd9\u4e00\u989d\u5916\u56e0\u7d20\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5b83\u662f\u6570\u636e\u96c6\u548c\u6a21\u578b\u67b6\u6784\u7684\u8054\u5408\u5c5e\u6027\u8fd8\u662f\u6570\u636e\u96c6\u672c\u8eab\u7684\u5185\u5728\u5c5e\u6027\u3002", "method": "\u521b\u5efa\u4e86\u6570\u5343\u4e2a\u63a7\u5236\u4e86\u5927\u5c0f\u548c\u7c7b\u522b\u5e73\u8861\u7684\u6570\u636e\u96c6\uff0c\u5e76\u7528\u8fd9\u4e9b\u6570\u636e\u96c6\u8bad\u7ec3\u5177\u6709\u5e7f\u6cdb\u67b6\u6784\u7684\u5206\u7c7b\u5668\uff0c\u5305\u62ec\u968f\u673a\u68ee\u6797\u3001\u652f\u6301\u5411\u91cf\u673a\u548c\u6df1\u5ea6\u7f51\u7edc\u7b49\u3002\u7136\u540e\u5206\u6790\u4e0d\u540c\u67b6\u6784\u4e0b\u5206\u7c7b\u5668\u6027\u80fd\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u8bc4\u4f30\u6570\u636e\u96c6\u8d28\u91cf\u662f\u5426\u4e3a\u6570\u636e\u96c6\u7684\u5185\u5728\u5c5e\u6027\u3002", "result": "\u53d1\u73b0\u5206\u7c7b\u5668\u6027\u80fd\u5728\u4e0d\u540c\u67b6\u6784\u95f4\u4e0e\u5b50\u96c6\u5f3a\u70c8\u76f8\u5173\uff08$R^2=0.79$\uff09\uff0c\u8fd9\u8868\u660e\u6570\u636e\u96c6\u8d28\u91cf\u662f\u72ec\u7acb\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u3001\u7c7b\u522b\u5e73\u8861\u548c\u6a21\u578b\u67b6\u6784\u7684\u5185\u5728\u5c5e\u6027\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u6570\u636e\u96c6\u8d28\u91cf\u4f3c\u4e4e\u662f\u5176\u7ec4\u6210\u7c7b\u522b\u7684\u8d28\u91cf\u7684\u4e00\u79cd\u6d8c\u73b0\u5c5e\u6027\u3002", "conclusion": "\u6570\u636e\u96c6\u8d28\u91cf\u662f\u5f71\u54cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u6027\u80fd\u7684\u4e00\u4e2a\u72ec\u7acb\u56e0\u7d20\uff0c\u5e94\u4f5c\u4e3a\u4f18\u5316\u5206\u7c7b\u6027\u80fd\u7684\u5355\u72ec\u76ee\u6807\u3002"}}
{"id": "2505.22829", "pdf": "https://arxiv.org/pdf/2505.22829", "abs": "https://arxiv.org/abs/2505.22829", "authors": ["Chenruo Liu", "Kenan Tang", "Yao Qin", "Qi Lei"], "title": "Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies", "categories": ["cs.LG", "cs.AI"], "comment": "35 pages", "summary": "This paper bridges distribution shift and AI safety through a comprehensive\nanalysis of their conceptual and methodological synergies. While prior\ndiscussions often focus on narrow cases or informal analogies, we establish two\ntypes connections between specific causes of distribution shift and\nfine-grained AI safety issues: (1) methods addressing a specific shift type can\nhelp achieve corresponding safety goals, or (2) certain shifts and safety\nissues can be formally reduced to each other, enabling mutual adaptation of\ntheir methods. Our findings provide a unified perspective that encourages\nfundamental integration between distribution shift and AI safety research.", "AI": {"tldr": "This paper connects distribution shift and AI safety by showing how methods for specific shifts can address safety goals and how certain shifts and safety issues can be formally related, promoting integration between the two fields.", "motivation": "To bridge the gap between distribution shift and AI safety through a comprehensive analysis and establish conceptual and methodological synergies.", "method": "Establishing two types of connections: (1) methods addressing specific shifts help achieve safety goals, and (2) certain shifts and safety issues can be formally reduced to each other.", "result": "Provided a unified perspective that encourages fundamental integration between distribution shift and AI safety research.", "conclusion": "The analysis promotes a deeper integration between distribution shift and AI safety, providing a framework for future research in both areas."}}
{"id": "2505.22820", "pdf": "https://arxiv.org/pdf/2505.22820", "abs": "https://arxiv.org/abs/2505.22820", "authors": ["Ayush Sawarni", "Sahasrajit Sarmasarkar", "Vasilis Syrgkanis"], "title": "Preference Learning with Response Time", "categories": ["cs.LG"], "comment": null, "summary": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5c06\u53cd\u5e94\u65f6\u95f4\u6570\u636e\u6574\u5408\u5230\u4eba\u7c7b\u504f\u597d\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u63d0\u53d6\u5956\u52b1\u6a21\u578b\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e8c\u5143\u9009\u62e9\u6570\u636e\u548c\u53cd\u5e94\u65f6\u95f4\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7Neyman-\u6b63\u4ea4\u635f\u5931\u51fd\u6570\u5b9e\u73b0\u7406\u8bba\u6700\u4f18\u6536\u655b\u7387\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u56fe\u50cf\u504f\u597d\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u504f\u597d\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e8c\u5143\u504f\u597d\u6570\u636e\uff0c\u4f46\u7528\u6237\u51b3\u7b56\u4e2d\u7684\u5b9d\u8d35\u65f6\u95f4\u4fe1\u606f\u5c1a\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eEvidence Accumulation Drift Diffusion (EZ)\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u53cd\u5e94\u65f6\u95f4\u4fe1\u606f\u4e0e\u4e8c\u5143\u9009\u62e9\u6570\u636e\u7ed3\u5408\u3002\u5f00\u53d1\u4e86Neyman-\u6b63\u4ea4\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u7406\u8bba\u4e0a\u7684\u6700\u4f18\u6536\u655b\u7387\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5bf9\u4e8e\u7ebf\u6027\u5956\u52b1\u51fd\u6570\uff0c\u4f20\u7edf\u65b9\u6cd5\u7684\u8bef\u5dee\u968f\u5956\u52b1\u5927\u5c0f\u5448\u6307\u6570\u589e\u957f\uff0c\u800c\u65b0\u65b9\u6cd5\u964d\u4f4e\u4e3a\u591a\u9879\u5f0f\u589e\u957f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u5c06\u53cd\u5e94\u65f6\u95f4\u6570\u636e\u6574\u5408\u5230\u504f\u597d\u5b66\u4e60\u6846\u67b6\u4e2d\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u7684\u6709\u6548\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u66f4\u590d\u6742\u7684\u5956\u52b1\u51fd\u6570\u7a7a\u95f4\u3002"}}
{"id": "2505.22839", "pdf": "https://arxiv.org/pdf/2505.22839", "abs": "https://arxiv.org/abs/2505.22839", "authors": ["Liu Yuezhang", "Xue-Xin Wei"], "title": "How Do Diffusion Models Improve Adversarial Robustness?", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "Recent findings suggest that diffusion models significantly enhance empirical\nadversarial robustness. While some intuitive explanations have been proposed,\nthe precise mechanisms underlying these improvements remain unclear. In this\nwork, we systematically investigate how and how well diffusion models improve\nadversarial robustness. First, we observe that diffusion models intriguingly\nincrease, rather than decrease, the $\\ell_p$ distance to clean\nsamples--challenging the intuition that purification denoises inputs closer to\nthe original data. Second, we find that the purified images are heavily\ninfluenced by the internal randomness of diffusion models, where a compression\neffect arises within each randomness configuration. Motivated by this\nobservation, we evaluate robustness under fixed randomness and find that the\nimprovement drops to approximately 24% on CIFAR-10--substantially lower than\nprior reports approaching 70%. Importantly, we show that this remaining\nrobustness gain strongly correlates with the model's ability to compress the\ninput space, revealing the compression rate as a reliable robustness indicator\nwithout requiring gradient-based analysis. Our findings provide novel insights\ninto the mechanisms underlying diffusion-based purification, and offer guidance\nfor developing more effective and principled adversarial purification systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.22846", "pdf": "https://arxiv.org/pdf/2505.22846", "abs": "https://arxiv.org/abs/2505.22846", "authors": ["Nikita Khramov", "Andrei Kozyrev", "Gleb Solovev", "Anton Podkopaev"], "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.SE"], "comment": null, "summary": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with\nGenerative Artificial Intelligence. This paper assesses multiple approaches to\nRocq generation and illuminates potential avenues for improvement. We highlight\nthe importance of thorough premise selection for generating Rocq proofs and\npropose a novel approach, leveraging retrieval via a self-attentive embedder\nmodel. The evaluation of the designed approach shows up to 28% relative\nincrease of the generator's performance. We tackle the problem of writing Rocq\nproofs using a multi-stage agentic system, tailored for formal verification,\nand demonstrate its high effectiveness. We conduct an ablation study and show\nthe use of multi-agent debate on the planning stage of proof synthesis.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7ed3\u5408\u7684\u591a\u79cd\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u5d4c\u5165\u6a21\u578b\u7684\u6539\u8fdb\u524d\u63d0\u9009\u62e9\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u5347Rocq\u751f\u6210\u6027\u80fd\u8fbe28%\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u9636\u6bb5\u4ee3\u7406\u7cfb\u7edf\u7528\u4e8e\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u5e76\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u8fa9\u8bba\u5728\u8bc1\u660e\u5408\u6210\u89c4\u5212\u9636\u6bb5\u7684\u5e94\u7528\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u7ed3\u5408\u5df2\u88ab\u8bc1\u660e\u662f\u5bcc\u6709\u6210\u6548\u7684\uff0c\u4f46\u73b0\u6709\u7684Rocq\u751f\u6210\u65b9\u6cd5\u4ecd\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\uff0c\u7279\u522b\u662f\u5728\u524d\u63d0\u9009\u62e9\u65b9\u9762\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u5d4c\u5165\u6a21\u578b\u7684\u68c0\u7d22\u65b9\u6cd5\u4ee5\u4f18\u5316\u524d\u63d0\u9009\u62e9\u3002\n2. \u8bbe\u8ba1\u4e00\u4e2a\u591a\u9636\u6bb5\u4ee3\u7406\u7cfb\u7edf\u4e13\u95e8\u7528\u4e8e\u5f62\u5f0f\u9a8c\u8bc1\u3002\n3. \u8fdb\u884c\u6d88\u878d\u7814\u7a76\uff0c\u63a2\u7d22\u591a\u4ee3\u7406\u8fa9\u8bba\u5728\u8bc1\u660e\u5408\u6210\u89c4\u5212\u9636\u6bb5\u7684\u4f5c\u7528\u3002", "result": "1. \u65b0\u65b9\u6cd5\u4f7f\u751f\u6210\u5668\u6027\u80fd\u76f8\u5bf9\u63d0\u5347\u4e8628%\u3002\n2. \u591a\u9636\u6bb5\u4ee3\u7406\u7cfb\u7edf\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6709\u6548\u6027\u3002\n3. \u591a\u4ee3\u7406\u8fa9\u8bba\u5728\u8bc1\u660e\u5408\u6210\u89c4\u5212\u9636\u6bb5\u5177\u6709\u79ef\u6781\u4f5c\u7528\u3002", "conclusion": "\u5f7b\u5e95\u7684\u524d\u63d0\u9009\u62e9\u5bf9\u751f\u6210Rocq\u8bc1\u660e\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u5d4c\u5165\u6a21\u578b\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u6027\u80fd\uff0c\u800c\u591a\u9636\u6bb5\u4ee3\u7406\u7cfb\u7edf\u548c\u591a\u4ee3\u7406\u8fa9\u8bba\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u5f62\u5f0f\u9a8c\u8bc1\u7684\u80fd\u529b\u3002"}}
{"id": "2505.22866", "pdf": "https://arxiv.org/pdf/2505.22866", "abs": "https://arxiv.org/abs/2505.22866", "authors": ["Nicolas Espinosa-Dice", "Yiyi Zhang", "Yiding Chen", "Bradley Guo", "Owen Oertell", "Gokul Swamy", "Kiante Brantley", "Wen Sun"], "title": "Scaling Offline RL via Efficient and Expressive Shortcut Models", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "32 pages, 5 figures. Under review at NeurIPS 2025", "summary": "Diffusion and flow models have emerged as powerful generative approaches\ncapable of modeling diverse and multimodal behavior. However, applying these\nmodels to offline reinforcement learning (RL) remains challenging due to the\niterative nature of their noise sampling processes, making policy optimization\ndifficult. In this paper, we introduce Scalable Offline Reinforcement Learning\n(SORL), a new offline RL algorithm that leverages shortcut models - a novel\nclass of generative models - to scale both training and inference. SORL's\npolicy can capture complex data distributions and can be trained simply and\nefficiently in a one-stage training procedure. At test time, SORL introduces\nboth sequential and parallel inference scaling by using the learned Q-function\nas a verifier. We demonstrate that SORL achieves strong performance across a\nrange of offline RL tasks and exhibits positive scaling behavior with increased\ntest-time compute. We release the code at\nnico-espinosadice.github.io/projects/sorl.", "AI": {"tldr": "\u6269\u6563\u548c\u6d41\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86SORL\u7b97\u6cd5\uff0c\u5229\u7528\u5feb\u6377\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u63a8\u7406\u6269\u5c55\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4e00\u9636\u6bb5\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u7684Q\u51fd\u6570\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u5f15\u5165\u987a\u5e8f\u548c\u5e73\u884c\u63a8\u7406\u6269\u5c55\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSORL\u5728\u79bb\u7ebfRL\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u5e76\u5177\u6709\u826f\u597d\u7684\u8ba1\u7b97\u6269\u5c55\u6027\u3002", "motivation": "\u6269\u6563\u548c\u6d41\u6a21\u578b\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5176\u566a\u58f0\u91c7\u6837\u8fc7\u7a0b\u7684\u8fed\u4ee3\u6027\u8d28\u4f7f\u5f97\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u4f18\u5316\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u63d0\u51faSORL\u7b97\u6cd5\uff0c\u4f7f\u7528\u5feb\u6377\u6a21\u578b\u6765\u6269\u5c55\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u7b56\u7565\u80fd\u591f\u6355\u6349\u590d\u6742\u7684\u6570\u636e\u5206\u5e03\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u4e00\u9636\u6bb5\u8bad\u7ec3\u7a0b\u5e8f\u7b80\u5355\u9ad8\u6548\u5730\u8bad\u7ec3\u3002\u6d4b\u8bd5\u65f6\uff0c\u901a\u8fc7\u5c06\u5b66\u4e60\u5230\u7684Q\u51fd\u6570\u4f5c\u4e3a\u9a8c\u8bc1\u5668\uff0c\u5f15\u5165\u987a\u5e8f\u548c\u5e73\u884c\u63a8\u7406\u6269\u5c55\u3002", "result": "SORL\u5728\u4e00\u7cfb\u5217\u79bb\u7ebfRL\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u968f\u7740\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u589e\u52a0\u800c\u5177\u6709\u7684\u6b63\u5411\u6269\u5c55\u884c\u4e3a\u3002", "conclusion": "SORL\u7b97\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7b56\u7565\u4f18\u5316\u7684\u96be\u9898\uff0c\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6027\u80fd\u548c\u8ba1\u7b97\u6269\u5c55\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2505.22904", "pdf": "https://arxiv.org/pdf/2505.22904", "abs": "https://arxiv.org/abs/2505.22904", "authors": ["Youngsoo Choi", "Siu Wun Cheung", "Youngkyu Kim", "Ping-Hsuan Tsai", "Alejandro N. Diaz", "Ivan Zanardi", "Seung Whan Chung", "Dylan Matthew Copeland", "Coleman Kendrick", "William Anderson", "Traian Iliescu", "Matthias Heinkenschloss"], "title": "Defining Foundation Models for Computational Science: A Call for Clarity and Rigor", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "26 pages, 2 tables, 7 figures", "summary": "The widespread success of foundation models in natural language processing\nand computer vision has inspired researchers to extend the concept to\nscientific machine learning and computational science. However, this position\npaper argues that as the term \"foundation model\" is an evolving concept, its\napplication in computational science is increasingly used without a universally\naccepted definition, potentially creating confusion and diluting its precise\nscientific meaning. In this paper, we address this gap by proposing a formal\ndefinition of foundation models in computational science, grounded in the core\nvalues of generality, reusability, and scalability. We articulate a set of\nessential and desirable characteristics that such models must exhibit, drawing\nparallels with traditional foundational methods, like the finite element and\nfinite volume methods. Furthermore, we introduce the Data-Driven Finite Element\nMethod (DD-FEM), a framework that fuses the modular structure of classical FEM\nwith the representational power of data-driven learning. We demonstrate how\nDD-FEM addresses many of the key challenges in realizing foundation models for\ncomputational science, including scalability, adaptability, and physics\nconsistency. By bridging traditional numerical methods with modern AI\nparadigms, this work provides a rigorous foundation for evaluating and\ndeveloping novel approaches toward future foundation models in computational\nscience.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u57fa\u7840\u6a21\u578b\u5728\u8ba1\u7b97\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u5f15\u5165\u4e86\u6570\u636e\u9a71\u52a8\u7684\u6709\u9650\u5143\u65b9\u6cd5\uff08DD-FEM\uff09\u4f5c\u4e3a\u5b9e\u73b0\u57fa\u7840\u6a21\u578b\u7684\u6846\u67b6\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u53d6\u5f97\u4e86\u5e7f\u6cdb\u7684\u6210\u529f\uff0c\u542f\u53d1\u4e86\u7814\u7a76\u8005\u5c06\u5176\u6982\u5ff5\u6269\u5c55\u5230\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u548c\u8ba1\u7b97\u79d1\u5b66\u9886\u57df\u3002\u7136\u800c\uff0c\u672f\u8bed\u201c\u57fa\u7840\u6a21\u578b\u201d\u4f5c\u4e3a\u4e00\u4e2a\u4e0d\u65ad\u53d1\u5c55\u7684\u6982\u5ff5\uff0c\u5728\u8ba1\u7b97\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u7f3a\u4e4f\u666e\u904d\u63a5\u53d7\u7684\u5b9a\u4e49\uff0c\u53ef\u80fd\u5bfc\u81f4\u6df7\u6dc6\u548c\u7a00\u91ca\u5176\u79d1\u5b66\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u901a\u7528\u6027\u3001\u53ef\u91cd\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u6b63\u5f0f\u5b9a\u4e49\u6765\u63cf\u8ff0\u8ba1\u7b97\u79d1\u5b66\u4e2d\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u9610\u8ff0\u4e86\u8fd9\u4e9b\u6a21\u578b\u5fc5\u987b\u5177\u5907\u7684\u5173\u952e\u548c\u671f\u671b\u7279\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u6570\u636e\u9a71\u52a8\u7684\u6709\u9650\u5143\u65b9\u6cd5\uff08DD-FEM\uff09\uff0c\u8be5\u65b9\u6cd5\u5c06\u7ecf\u5178\u6709\u9650\u5143\u65b9\u6cd5\u7684\u6a21\u5757\u5316\u7ed3\u6784\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u8868\u73b0\u529b\u76f8\u7ed3\u5408\u3002", "result": "DD-FEM\u89e3\u51b3\u4e86\u5b9e\u73b0\u8ba1\u7b97\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u6311\u6218\uff0c\u5982\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002\u5b83\u4e3a\u8bc4\u4f30\u548c\u53d1\u5c55\u672a\u6765\u7684\u8ba1\u7b97\u79d1\u5b66\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u4e0e\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u8303\u5f0f\uff0c\u672c\u6587\u4e3a\u8ba1\u7b97\u79d1\u5b66\u4e2d\u7684\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u8bc4\u4ef7\u548c\u53d1\u5c55\u6846\u67b6\u3002"}}
{"id": "2505.22840", "pdf": "https://arxiv.org/pdf/2505.22840", "abs": "https://arxiv.org/abs/2505.22840", "authors": ["Dharambir Mahto", "Prashant Yadav", "Mahesh Banavar", "Jim Keany", "Alan T Joseph", "Srinivas Kilambi"], "title": "Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction", "categories": ["cs.LG"], "comment": "Paper accepted at JMAI", "summary": "Sepsis is a life-threatening condition affecting over 48.9 million people\nglobally and causing 11 million deaths annually. Despite medical advancements,\npredicting sepsis remains a challenge due to non-specific symptoms and complex\npathophysiology. The SXI++ LNM is a machine learning scoring system that\nrefines sepsis prediction by leveraging multiple algorithms and deep neural\nnetworks. This study aims to improve robustness in clinical applications and\nevaluates the predictive performance of the SXI++ LNM for sepsis prediction.\nThe model, utilizing a deep neural network, was trained and tested using\nmultiple scenarios with different dataset distributions. The model's\nperformance was assessed against unseen test data, and accuracy, precision, and\narea under the curve (AUC) were calculated. THE SXI++ LNM outperformed the\nstate of the art in three use cases, achieving an AUC of 0.99 (95% CI:\n0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0)\nand an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.", "AI": {"tldr": "Sepsis\u9884\u6d4b\u4ecd\u5177\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u901a\u8fc7SXI++ LNM\u7cfb\u7edf\u6539\u8fdb\u4e86\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8bc4\u4f30\u5176\u6027\u80fd\u3002\u8be5\u6a21\u578b\u5728\u4e09\u4e2a\u7528\u4f8b\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u6280\u672f\uff0cAUC\u8fbe\u52300.99\uff0c\u7cbe\u5ea6\u548c\u51c6\u786e\u5ea6\u5206\u522b\u8fbe99.9%\u548c99.99%\u3002", "motivation": "\u8d25\u8840\u75c7\u662f\u4e00\u79cd\u5a01\u80c1\u751f\u547d\u7684\u72b6\u51b5\uff0c\u5f71\u54cd\u5168\u7403\u8d85\u8fc74890\u4e07\u4eba\uff0c\u6bcf\u5e74\u5bfc\u81f41100\u4e07\u4eba\u6b7b\u4ea1\u3002\u5c3d\u7ba1\u533b\u5b66\u8fdb\u6b65\uff0c\u4f46\u7531\u4e8e\u75c7\u72b6\u4e0d\u5177\u4f53\u548c\u590d\u6742\u7684\u75c5\u7406\u751f\u7406\u5b66\uff0c\u9884\u6d4b\u8d25\u8840\u75c7\u4ecd\u7136\u662f\u4e00\u9879\u6311\u6218\u3002", "method": "SXI++ LNM\u662f\u4e00\u4e2a\u5229\u7528\u591a\u79cd\u7b97\u6cd5\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u673a\u5668\u5b66\u4e60\u8bc4\u5206\u7cfb\u7edf\uff0c\u7528\u4e8e\u6539\u8fdb\u8d25\u8840\u75c7\u9884\u6d4b\u3002\u8be5\u7814\u7a76\u4f7f\u7528\u4e0d\u540c\u6570\u636e\u96c6\u5206\u5e03\u7684\u591a\u4e2a\u573a\u666f\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e86\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u3002", "result": "SXI++ LNM\u5728\u4e09\u4e2a\u7528\u4f8b\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u6280\u672f\uff0cAUC\u4e3a0.99\uff0895% CI\uff1a0.98-1.00\uff09\uff0c\u7cbe\u5ea6\u4e3a99.9%\uff0895% CI\uff1a99.8-100.0\uff09\uff0c\u51c6\u786e\u5ea6\u4e3a99.99%\uff0895% CI\uff1a99.98-100.0\uff09\u3002", "conclusion": "SXI++ LNM\u663e\u8457\u63d0\u9ad8\u4e86\u8d25\u8840\u75c7\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u9ad8\u53ef\u9760\u6027\uff0c\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2505.22922", "pdf": "https://arxiv.org/pdf/2505.22922", "abs": "https://arxiv.org/abs/2505.22922", "authors": ["Athanasios Glentis", "Jiaxiang Li", "Qiulin Shang", "Andi Han", "Ioannis Tsaknakis", "Quan Wei", "Mingyi Hong"], "title": "Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fueled by their remarkable ability to tackle diverse tasks across multiple\ndomains, large language models (LLMs) have grown at an unprecedented rate, with\nsome recent models containing trillions of parameters. This growth is\naccompanied by substantial computational challenges, particularly regarding the\nmemory and compute resources required for training and fine-tuning. Numerous\napproaches have been explored to address these issues, such as LoRA. While\nthese methods are effective for fine-tuning, their application to pre-training\nis significantly more challenging due to the need to learn vast datasets.\nMotivated by this issue, we aim to address the following questions: Can\nparameter- or memory-efficient methods enhance pre-training efficiency while\nachieving performance comparable to full-model training? How can the\nperformance gap be narrowed? To this end, the contributions of this work are\nthe following. (1) We begin by conducting a comprehensive survey that\nsummarizes state-of-the-art methods for efficient pre-training. (2) We perform\na benchmark evaluation of several representative memory efficient pre-training\napproaches to comprehensively evaluate their performance across model sizes. We\nobserve that with a proper choice of optimizer and hyperparameters, full-rank\ntraining delivers the best performance, as expected. We also notice that\nincorporating high-rank updates in low-rank approaches is the key to improving\ntheir performance. (3) Finally, we propose two practical techniques, namely\nweight refactorization and momentum reset, to enhance the performance of\nefficient pre-training methods. We observe that applying these techniques to\nthe low-rank method (on a 1B model) can achieve a lower perplexity than popular\nmemory efficient algorithms such as GaLore and Fira, while simultaneously using\nabout 25% less memory.", "AI": {"tldr": "\u4e3a\u4e86\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bad\u7ec3\u548c\u5fae\u8c03\u4e2d\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u672c\u6587\u63a2\u8ba8\u4e86\u53c2\u6570\u6216\u5185\u5b58\u9ad8\u6548\u65b9\u6cd5\u662f\u5426\u53ef\u4ee5\u5728\u4fdd\u6301\u4e0e\u5b8c\u6574\u6a21\u578b\u8bad\u7ec3\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u9884\u8bad\u7ec3\u6548\u7387\u3002\u7814\u7a76\u901a\u8fc7\u5168\u9762\u8c03\u67e5\u3001\u57fa\u51c6\u8bc4\u4f30\u4ee5\u53ca\u63d0\u51fa\u4e24\u79cd\u5b9e\u7528\u6280\u672f\uff08\u6743\u91cd\u91cd\u6784\u548c\u52a8\u91cf\u91cd\u7f6e\uff09\uff0c\u53d1\u73b0\u4f4e\u79e9\u65b9\u6cd5\u7ed3\u5408\u9ad8\u79e9\u66f4\u65b0\u80fd\u6709\u6548\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5728\u51cf\u5c11\u7ea625%\u5185\u5b58\u4f7f\u7528\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u5176\u4ed6\u6d41\u884c\u7b97\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5c24\u5176\u662f\u9884\u8bad\u7ec3\u9636\u6bb5\u9700\u8981\u5904\u7406\u5e9e\u5927\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u5bf9\u5185\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u5c3d\u7ba1\u73b0\u6709\u65b9\u6cd5\u5982LoRA\u5728\u5fae\u8c03\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5728\u9884\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u53c2\u6570\u6216\u5185\u5b58\u9ad8\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u4e0e\u5b8c\u6574\u6a21\u578b\u8bad\u7ec3\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002", "method": "1. \u8fdb\u884c\u5168\u9762\u8c03\u67e5\uff0c\u603b\u7ed3\u5f53\u524d\u6700\u5148\u8fdb\u7684\u9ad8\u6548\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002\n2. \u5bf9\u591a\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u5185\u5b58\u9ad8\u6548\u9884\u8bad\u7ec3\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u8bc4\u4f30\uff0c\u5206\u6790\u5176\u5728\u4e0d\u540c\u6a21\u578b\u5c3a\u5bf8\u4e0b\u7684\u6027\u80fd\u3002\n3. \u63d0\u51fa\u4e24\u79cd\u5b9e\u7528\u6280\u672f\uff1a\u6743\u91cd\u91cd\u6784\u548c\u52a8\u91cf\u91cd\u7f6e\uff0c\u4ee5\u6539\u8fdb\u4f4e\u79e9\u65b9\u6cd5\u7684\u6027\u80fd\u3002\n4. \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u572810\u4ebf\u53c2\u6570\u6a21\u578b\u4e0a\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u9009\u62e9\u5408\u9002\u7684\u4f18\u5316\u5668\u548c\u8d85\u53c2\u6570\u65f6\uff0c\u5168\u79e9\u8bad\u7ec3\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\u3002\u540c\u65f6\uff0c\u5728\u4f4e\u79e9\u65b9\u6cd5\u4e2d\u5f15\u5165\u9ad8\u79e9\u66f4\u65b0\u662f\u63d0\u9ad8\u5176\u6027\u80fd\u7684\u5173\u952e\u3002\u63d0\u51fa\u7684\u6743\u91cd\u91cd\u6784\u548c\u52a8\u91cf\u91cd\u7f6e\u6280\u672f\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u4f4e\u79e9\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u5728\u4f7f\u7528\u66f4\u5c11\u5185\u5b58\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\uff0c\u4f18\u4e8eGaLore\u548cFira\u7b49\u6d41\u884c\u7b97\u6cd5\u3002", "conclusion": "\u53c2\u6570\u6216\u5185\u5b58\u9ad8\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\u786e\u5b9e\u53ef\u4ee5\u63d0\u9ad8\u9884\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u8fbe\u5230\u4e0e\u5b8c\u6574\u6a21\u578b\u8bad\u7ec3\u76f8\u8fd1\u7684\u6027\u80fd\u3002\u901a\u8fc7\u91c7\u7528\u9002\u5f53\u7684\u4f18\u5316\u7b56\u7565\u548c\u6280\u672f\u6539\u8fdb\uff0c\u53ef\u4ee5\u6709\u6548\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\u5e76\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2505.22973", "pdf": "https://arxiv.org/pdf/2505.22973", "abs": "https://arxiv.org/abs/2505.22973", "authors": ["Bahareh Tolooshams", "Aditi Chandrashekar", "Rayhan Zirvi", "Abbas Mammadov", "Jiachen Yao", "Chuwei Wang", "Anima Anandkumar"], "title": "EquiReg: Equivariance Regularized Diffusion for Inverse Problems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models represent the state-of-the-art for solving inverse problems\nsuch as image restoration tasks. In the Bayesian framework, diffusion-based\ninverse solvers incorporate a likelihood term to guide the prior sampling\nprocess, generating data consistent with the posterior distribution. However,\ndue to the intractability of the likelihood term, many current methods rely on\nisotropic Gaussian approximations, which lead to deviations from the data\nmanifold and result in inconsistent, unstable reconstructions. We propose\nEquivariance Regularized (EquiReg) diffusion, a general framework for\nregularizing posterior sampling in diffusion-based inverse problem solvers.\nEquiReg enhances reconstructions by reweighting diffusion trajectories and\npenalizing those that deviate from the data manifold. We define a new\ndistribution-dependent equivariance error, empirically identify functions that\nexhibit low error for on-manifold samples and higher error for off-manifold\nsamples, and leverage these functions to regularize the diffusion sampling\nprocess. When applied to a variety of solvers, EquiReg outperforms\nstate-of-the-art diffusion models in both linear and nonlinear image\nrestoration tasks, as well as in reconstructing partial differential equations.", "AI": {"tldr": "Diffusion models are top for inverse problems but face challenges with likelihood terms. This paper proposes EquiReg, a framework that regularizes posterior sampling in diffusion-based solvers by reweighting trajectories and penalizing deviations from the data manifold, leading to better reconstructions.", "motivation": "To address the issue of inconsistent and unstable reconstructions caused by isotropic Gaussian approximations in current diffusion-based inverse problem solvers.", "method": "Propose EquiReg diffusion, which regularizes posterior sampling by reweighting diffusion trajectories and penalizing deviations from the data manifold using distribution-dependent equivariance error functions.", "result": "EquiReg outperforms state-of-the-art diffusion models in linear and nonlinear image restoration tasks as well as in reconstructing partial differential equations.", "conclusion": "EquiReg is a promising framework for enhancing reconstructions in diffusion-based inverse problem solvers."}}
{"id": "2505.22985", "pdf": "https://arxiv.org/pdf/2505.22985", "abs": "https://arxiv.org/abs/2505.22985", "authors": ["Masaharu Kagiyama", "Tsuyoshi Okita"], "title": "Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "23 pages,5 figures", "summary": "This paper aims to develop an energy-efficient classifier for time-series\ndata by introducing PatchEchoClassifier, a novel model that leverages a\nreservoir-based mechanism known as the Echo State Network (ESN). The model is\ndesigned for human activity recognition (HAR) using one-dimensional sensor\nsignals and incorporates a tokenizer to extract patch-level representations. To\ntrain the model efficiently, we propose a knowledge distillation framework that\ntransfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight\nreservoir-based student model. Experimental evaluations on multiple HAR\ndatasets demonstrate that our model achieves over 80 percent accuracy while\nsignificantly reducing computational cost. Notably, PatchEchoClassifier\nrequires only about one-sixth of the floating point operations (FLOPS) compared\nto DeepConvLSTM, a widely used convolutional baseline. These results suggest\nthat PatchEchoClassifier is a promising solution for real-time and\nenergy-efficient human activity recognition in edge computing environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPatchEchoClassifier\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u56de\u58f0\u72b6\u6001\u7f51\u7edc\uff08ESN\uff09\u7684\u6c34\u5e93\u8ba1\u7b97\u673a\u5236\uff0c\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u65f6\u5e8f\u6570\u636e\u5206\u7c7b\u4efb\u52a1\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eDeepConvLSTM\u76f8\u6bd4\uff0cPatchEchoClassifier\u5728\u4fdd\u630180%\u4ee5\u4e0a\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5c06\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u81f3\u7ea6\u516d\u5206\u4e4b\u4e00\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u65f6\u3001\u8282\u80fd\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5728\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u9886\u57df\u4e2d\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u7136\u6027\u80fd\u8f83\u9ad8\uff0c\u4f46\u901a\u5e38\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u80fd\u8017\u5927\uff0c\u96be\u4ee5\u6ee1\u8db3\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907\u5bf9\u5b9e\u65f6\u6027\u548c\u4f4e\u529f\u8017\u7684\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u5206\u7c7b\u7cbe\u5ea6\u53c8\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u7684\u65b0\u578b\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6a21\u578bPatchEchoClassifier\uff0c\u5229\u7528\u56de\u58f0\u72b6\u6001\u7f51\u7edc\uff08ESN\uff09\u4f5c\u4e3a\u6838\u5fc3\u673a\u5236\uff0c\u5e76\u7ed3\u5408tokenizer\u63d0\u53d6\u4f20\u611f\u5668\u4fe1\u53f7\u7684patch-level\u7279\u5f81\u8868\u793a\u3002\u4e3a\u4e86\u9ad8\u6548\u8bad\u7ec3\u8fd9\u4e00\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u4e00\u4e2a\u9ad8\u5bb9\u91cf\u7684MLP-Mixer\u6559\u5e08\u6a21\u578b\u5411\u5b66\u751f\u6a21\u578b\u8f6c\u79fb\u77e5\u8bc6\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2aHAR\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPatchEchoClassifier\u80fd\u591f\u8fbe\u5230\u8d85\u8fc780%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5176\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff08FLOPS\uff09\u4ec5\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684DeepConvLSTM\u57fa\u7ebf\u6a21\u578b\u7684\u5927\u7ea6\u516d\u5206\u4e4b\u4e00\u3002", "conclusion": "PatchEchoClassifier\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u3001\u57fa\u4e8e\u6c34\u5e93\u8ba1\u7b97\u7684\u6a21\u578b\uff0c\u4e0d\u4ec5\u5177\u6709\u8f83\u9ad8\u7684\u5206\u7c7b\u7cbe\u5ea6\uff0c\u8fd8\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u3001\u8282\u80fd\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.22861", "pdf": "https://arxiv.org/pdf/2505.22861", "abs": "https://arxiv.org/abs/2505.22861", "authors": ["Carlota Par\u00e9s-Morlans", "Michelle Yi", "Claire Chen", "Sarah A. Wu", "Rika Antonova", "Tobias Gerstenberg", "Jeannette Bohg"], "title": "Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Tasks that involve complex interactions between objects with unknown dynamics\nmake planning before execution difficult. These tasks require agents to\niteratively improve their actions after actively exploring causes and effects\nin the environment. For these type of tasks, we propose Causal-PIK, a method\nthat leverages Bayesian optimization to reason about causal interactions via a\nPhysics-Informed Kernel to help guide efficient search for the best next\naction. Experimental results on Virtual Tools and PHYRE physical reasoning\nbenchmarks show that Causal-PIK outperforms state-of-the-art results, requiring\nfewer actions to reach the goal. We also compare Causal-PIK to human studies,\nincluding results from a new user study we conducted on the PHYRE benchmark. We\nfind that Causal-PIK remains competitive on tasks that are very challenging,\neven for human problem-solvers.", "AI": {"tldr": "Causal-PIK\u662f\u4e00\u79cd\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u7269\u7406\u4fe1\u606f\u6838\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a8\u7406\u56e0\u679c\u4ea4\u4e92\u5e76\u9ad8\u6548\u641c\u7d22\u6700\u4f73\u4e0b\u4e00\u6b65\u52a8\u4f5c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u865a\u62df\u5de5\u5177\u548c\u7269\u7406\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCausal-PIK\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6781\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0e\u4eba\u7c7b\u76f8\u5f53\u3002", "motivation": "\u6d89\u53ca\u590d\u6742\u5bf9\u8c61\u4ea4\u4e92\u7684\u4efb\u52a1\u96be\u4ee5\u63d0\u524d\u89c4\u5212\uff0c\u9700\u8981\u667a\u80fd\u4f53\u901a\u8fc7\u63a2\u7d22\u73af\u5883\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u6765\u8fed\u4ee3\u6539\u8fdb\u52a8\u4f5c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCausal-PIK\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u7269\u7406\u4fe1\u606f\u6838\uff0c\u7528\u4e8e\u63a8\u7406\u56e0\u679c\u5173\u7cfb\u5e76\u6307\u5bfc\u5bf9\u6700\u4f73\u4e0b\u4e00\u6b65\u52a8\u4f5c\u7684\u9ad8\u6548\u641c\u7d22\u3002", "result": "\u5728Virtual Tools\u548cPHYRE\u7269\u7406\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCausal-PIK\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u76ee\u6807\u6240\u9700\u7684\u884c\u52a8\u66f4\u5c11\u3002\u6b64\u5916\uff0c\u5728\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u6bd4\u8f83\u4e2d\uff0cCausal-PIK\u5728\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "Causal-PIK\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u590d\u6742\u7684\u56e0\u679c\u63a8\u7406\u4efb\u52a1\uff0c\u5176\u6027\u80fd\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u80fd\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u5ab2\u7f8e\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u8005\u3002"}}
{"id": "2505.22988", "pdf": "https://arxiv.org/pdf/2505.22988", "abs": "https://arxiv.org/abs/2505.22988", "authors": ["Albert Tseng", "Zhaofeng Sun", "Christopher De Sa"], "title": "Model-Preserving Adaptive Rounding", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "The main goal of post-training quantization (PTQ) is to produced a compressed\nmodel whose output distribution is as close to the original model's as\npossible. To do this tractably, almost all LLM PTQ algorithms quantize linear\nlayers by independently minimizing the immediate activation error. However,\nthis localized objective ignores the effect of subsequent layers, so reducing\nit does not necessarily give a closer model. In this work, we introduce Yet\nAnother Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses\nKronecker-factored approximations of each linear layer's Hessian with respect\nto the \\textit{full model} KL divergence. YAQA consists of two components:\nKronecker-factored sketches of the full layerwise Hessian that can be tractably\ncomputed for hundred-billion parameter LLMs, and a quantizer-independent\nrounding algorithm that uses these sketches and comes with theoretical\nguarantees. Across a wide range of models and quantizers, YAQA empirically\nreduces the KL divergence to the original model by $\\approx 30\\%$ while\nachieving state of the art performance on downstream tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5316\u7b97\u6cd5YAQA\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u51cf\u5c11\u4e0e\u539f\u59cb\u6a21\u578b\u7684KL\u6563\u5ea6\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7684\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u7b97\u6cd5\u901a\u5e38\u901a\u8fc7\u72ec\u7acb\u6700\u5c0f\u5316\u76f4\u63a5\u6fc0\u6d3b\u8bef\u5dee\u6765\u91cf\u5316\u7ebf\u6027\u5c42\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5ffd\u7565\u4e86\u540e\u7eed\u5c42\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u53ef\u80fd\u65e0\u6cd5\u4ea7\u751f\u63a5\u8fd1\u539f\u6a21\u578b\u7684\u538b\u7f29\u6a21\u578b\u3002", "method": "\u5f15\u5165\u4e86YAQA\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528Kronecker\u5206\u89e3\u8fd1\u4f3c\u6bcf\u4e2a\u7ebf\u6027\u5c42\u76f8\u5bf9\u4e8e\u5b8c\u6574\u6a21\u578bKL\u6563\u5ea6\u7684Hessian\u77e9\u9635\u3002YAQA\u5305\u542b\u4e24\u4e2a\u90e8\u5206\uff1a1\uff09\u53ef\u8ba1\u7b97\u7684Kronecker\u5206\u89e3\u8349\u56fe\uff0c\u7528\u4e8e\u4f30\u8ba1\u5b8c\u6574\u7684\u9010\u5c42Hessian\u77e9\u9635\uff1b2\uff09\u4e00\u79cd\u4e0e\u91cf\u5316\u5668\u65e0\u5173\u7684\u81ea\u9002\u5e94\u820d\u5165\u7b97\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cYAQA\u5728\u5404\u79cd\u6a21\u578b\u548c\u91cf\u5316\u5668\u4e0a\u5c06KL\u6563\u5ea6\u51cf\u5c11\u4e86\u7ea630%\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "YAQA\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4e0e\u539f\u59cb\u6a21\u578b\u7684KL\u6563\u5ea6\u5e76\u4fdd\u6301\u4e86\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2505.23003", "pdf": "https://arxiv.org/pdf/2505.23003", "abs": "https://arxiv.org/abs/2505.23003", "authors": ["Linh Le Pham Van", "Minh Hoang Nguyen", "Hung Le", "Hung The Tran", "Sunil Gupta"], "title": "Hybrid Cross-domain Robust Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ECML PKDD 2025", "summary": "Robust reinforcement learning (RL) aims to learn policies that remain\neffective despite uncertainties in its environment, which frequently arise in\nreal-world applications due to variations in environment dynamics. The robust\nRL methods learn a robust policy by maximizing value under the worst-case\nmodels within a predefined uncertainty set. Offline robust RL algorithms are\nparticularly promising in scenarios where only a fixed dataset is available and\nnew data cannot be collected. However, these approaches often require extensive\noffline data, and gathering such datasets for specific tasks in specific\nenvironments can be both costly and time-consuming. Using an imperfect\nsimulator offers a faster, cheaper, and safer way to collect data for training,\nbut it can suffer from dynamics mismatch. In this paper, we introduce HYDRO,\nthe first Hybrid Cross-Domain Robust RL framework designed to address these\nchallenges. HYDRO utilizes an online simulator to complement the limited amount\nof offline datasets in the non-trivial context of robust RL. By measuring and\nminimizing performance gaps between the simulator and the worst-case models in\nthe uncertainty set, HYDRO employs novel uncertainty filtering and prioritized\nsampling to select the most relevant and reliable simulator samples. Our\nextensive experiments demonstrate HYDRO's superior performance over existing\nmethods across various tasks, underscoring its potential to improve sample\nefficiency in offline robust RL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHYDRO\u7684\u6df7\u5408\u8de8\u57df\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7ebf\u4e0b\u9c81\u68d2RL\u4e2d\u7684\u6570\u636e\u9650\u5236\u548c\u52a8\u6001\u4e0d\u5339\u914d\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u5728\u7ebf\u6a21\u62df\u5668\u4e0e\u79bb\u7ebf\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u4e0d\u786e\u5b9a\u6027\u8fc7\u6ee4\u548c\u4f18\u5148\u91c7\u6837\u65b9\u6cd5\uff0cHYDRO\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u79bb\u7ebf\u6570\u636e\uff0c\u800c\u6536\u96c6\u8fd9\u4e9b\u6570\u636e\u65e2\u6602\u8d35\u53c8\u8017\u65f6\u3002\u540c\u65f6\uff0c\u4f7f\u7528\u4e0d\u5b8c\u7f8e\u7684\u6a21\u62df\u5668\u867d\u7136\u66f4\u7ecf\u6d4e\u9ad8\u6548\uff0c\u4f46\u53ef\u80fd\u5b58\u5728\u52a8\u6001\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u6709\u9650\u79bb\u7ebf\u6570\u636e\u5e76\u7f13\u89e3\u6a21\u62df\u5668\u4e0e\u5b9e\u9645\u73af\u5883\u4e4b\u95f4\u5dee\u5f02\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86HYDRO\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5728\u7ebf\u6a21\u62df\u5668\u548c\u6709\u9650\u7684\u79bb\u7ebf\u6570\u636e\u96c6\uff0c\u4ee5\u5e94\u5bf9\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6311\u6218\u3002\u5177\u4f53\u800c\u8a00\uff0cHYDRO\u901a\u8fc7\u6d4b\u91cf\u548c\u6700\u5c0f\u5316\u6a21\u62df\u5668\u4e0e\u6700\u574f\u60c5\u51b5\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u91c7\u7528\u4e0d\u786e\u5b9a\u6027\u8fc7\u6ee4\u548c\u4f18\u5148\u91c7\u6837\u7684\u6280\u672f\u9009\u62e9\u6700\u76f8\u5173\u548c\u53ef\u9760\u7684\u6a21\u62df\u5668\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHYDRO\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u9ad8\u7ebf\u4e0b\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u6837\u672c\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "HYDRO\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u6df7\u5408\u8de8\u57df\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u7ebf\u4e0b\u9c81\u68d2RL\u4e2d\u7684\u6570\u636e\u4e0d\u8db3\u548c\u52a8\u6001\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u63d0\u9ad8\u6837\u672c\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2505.23017", "pdf": "https://arxiv.org/pdf/2505.23017", "abs": "https://arxiv.org/abs/2505.23017", "authors": ["Xingjian Wu", "Xiangfei Qiu", "Hongfan Gao", "Jilin Hu", "Bin Yang", "Chenjuan Guo"], "title": "$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Probabilistic Time Series Forecasting (PTSF) plays a crucial role in\ndecision-making across various fields, including economics, energy, and\ntransportation. Most existing methods excell at short-term forecasting, while\noverlooking the hurdles of Long-term Probabilistic Time Series Forecasting\n(LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have\na significant adverse effect on prediction accuracy, and make generative models\ninefficient by increasing the cost of each iteration. To overcome these\nlimitations, we introduce $K^2$VAE, an efficient VAE-based generative model\nthat leverages a KoopmanNet to transform nonlinear time series into a linear\ndynamical system, and devises a KalmanNet to refine predictions and model\nuncertainty in such linear system, which reduces error accumulation in\nlong-term forecasting. Extensive experiments demonstrate that $K^2$VAE\noutperforms state-of-the-art methods in both short- and long-term PTSF,\nproviding a more efficient and accurate solution.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a$K^2$VAE\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u975e\u7ebf\u6027\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u5e76\u4f18\u5316\u9884\u6d4b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u77ed\u671f\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5728\u77ed\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u957f\u671f\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3b\u8981\u6311\u6218\u5305\u62ec\u975e\u7ebf\u6027\u52a8\u6001\u5bf9\u9884\u6d4b\u7cbe\u5ea6\u7684\u4e0d\u5229\u5f71\u54cd\u4ee5\u53ca\u751f\u6210\u6a21\u578b\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u7684\u6210\u672c\u589e\u52a0\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86$K^2$VAE\u6a21\u578b\uff0c\u5229\u7528KoopmanNet\u5c06\u975e\u7ebf\u6027\u65f6\u95f4\u5e8f\u5217\u8f6c\u5316\u4e3a\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\uff0c\u5e76\u91c7\u7528KalmanNet\u4f18\u5316\u9884\u6d4b\u548c\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u4ee5\u51cf\u5c11\u957f\u671f\u9884\u6d4b\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c$K^2$VAE\u5728\u77ed\u671f\u548c\u957f\u671f\u7684\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u548c\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "$K^2$VAE\u662f\u4e00\u79cd\u6709\u6548\u7684\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u957f\u77ed\u671f\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u9009\u62e9\u3002"}}
{"id": "2505.22899", "pdf": "https://arxiv.org/pdf/2505.22899", "abs": "https://arxiv.org/abs/2505.22899", "authors": ["Naram Mhaisen", "George Iosifidis"], "title": "On the Dynamic Regret of Following the Regularized Leader: Optimism with History Pruning", "categories": ["cs.LG"], "comment": null, "summary": "We revisit the Follow the Regularized Leader (FTRL) framework for Online\nConvex Optimization (OCO) over compact sets, focusing on achieving dynamic\nregret guarantees. Prior work has highlighted the framework's limitations in\ndynamic environments due to its tendency to produce \"lazy\" iterates. However,\nbuilding on insights showing FTRL's ability to produce \"agile\" iterates, we\nshow that it can indeed recover known dynamic regret bounds through optimistic\ncomposition of future costs and careful linearization of past costs, which can\nlead to pruning some of them. This new analysis of FTRL against dynamic\ncomparators yields a principled way to interpolate between greedy and agile\nupdates and offers several benefits, including refined control over regret\nterms, optimism without cyclic dependence, and the application of minimal\nrecursive regularization akin to AdaFTRL. More broadly, we show that it is not\nthe lazy projection style of FTRL that hinders (optimistic) dynamic regret, but\nthe decoupling of the algorithm's state (linearized history) from its iterates,\nallowing the state to grow arbitrarily. Instead, pruning synchronizes these two\nwhen necessary.", "AI": {"tldr": "\u901a\u8fc7\u4e50\u89c2\u7ec4\u5408\u672a\u6765\u6210\u672c\u548c\u4ed4\u7ec6\u7ebf\u6027\u5316\u8fc7\u53bb\u6210\u672c\uff0cFTRL\u53ef\u4ee5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u5df2\u77e5\u7684\u52a8\u6001\u540e\u6094\u754c\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6FTRL\u6846\u67b6\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u89e3\u51b3\u5176\u5728\u52a8\u6001\u540e\u6094\u4fdd\u8bc1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u4e50\u89c2\u7ec4\u5408\u672a\u6765\u6210\u672c\u548c\u7ebf\u6027\u5316\u8fc7\u53bb\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u4f7fFTRL\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u52a8\u6001\u73af\u5883\u5e76\u5b9e\u73b0\u52a8\u6001\u540e\u6094\u754c\u7684\u6062\u590d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d2\u503c\u8d2a\u5a6a\u548c\u654f\u6377\u66f4\u65b0\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u540e\u6094\u9879\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u6d88\u9664\u4e86\u4e50\u89c2\u4e3b\u4e49\u4e2d\u7684\u5faa\u73af\u4f9d\u8d56\uff0c\u5e76\u5e94\u7528\u4e86\u7c7b\u4f3c\u4e8eAdaFTRL\u7684\u6700\u5c0f\u9012\u5f52\u6b63\u5219\u5316\u3002", "conclusion": "FTRL\u5728\u52a8\u6001\u540e\u6094\u65b9\u9762\u7684\u95ee\u9898\u5e76\u975e\u6e90\u4e8e\u61d2\u60f0\u6295\u5f71\u98ce\u683c\uff0c\u800c\u662f\u7b97\u6cd5\u72b6\u6001\u4e0e\u8fed\u4ee3\u7684\u89e3\u8026\u3002\u4fee\u526a\u53ef\u4ee5\u4f7f\u4e24\u8005\u5728\u5fc5\u8981\u65f6\u540c\u6b65\u3002"}}
{"id": "2505.23027", "pdf": "https://arxiv.org/pdf/2505.23027", "abs": "https://arxiv.org/abs/2505.23027", "authors": ["Minh Nguyen Nhat To", "Paul F RWilson", "Viet Nguyen", "Mohamed Harmanani", "Michael Cooper", "Fahimeh Fooladgar", "Purang Abolmaesumi", "Parvin Mousavi", "Rahul G. Krishnan"], "title": "Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICML 2025 Paper", "summary": "The subpopulationtion shift, characterized by a disparity in subpopulation\ndistributibetween theween the training and target datasets, can significantly\ndegrade the performance of machine learning models. Current solutions to\nsubpopulation shift involve modifying empirical risk minimization with\nre-weighting strategies to improve generalization. This strategy relies on\nassumptions about the number and nature of subpopulations and annotations on\ngroup membership, which are unavailable for many real-world datasets. Instead,\nwe propose using an ensemble of diverse classifiers to adaptively capture risk\nassociated with subpopulations. Given a feature extractor network, we replace\nits standard linear classification layer with a mixture of prototypical\nclassifiers, where each member is trained to classify the data while focusing\non different features and samples from other members. In empirical evaluation\non nine real-world datasets, covering diverse domains and kinds of\nsubpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often\noutperforms the prior state-of-the-art in worst-group accuracy. The code is\navailable at https://github.com/minhto2802/dpe4subpop", "AI": {"tldr": "To tackle subpopulation shift without assumptions about subpopulations or annotations on group membership, the paper proposes Diverse Prototypical Ensembles (DPEs), an ensemble of diverse classifiers that often outperforms prior state-of-the-art methods in worst-group accuracy.", "motivation": "The motivation is to address the issue of subpopulation shift which can degrade machine learning model performance. Current solutions require assumptions and annotations not always available in real-world datasets.", "method": "The method involves using an ensemble of diverse classifiers called Diverse Prototypical Ensembles (DPEs). A feature extractor network's classification layer is replaced with a mixture of prototypical classifiers, each focusing on different features and samples.", "result": "Empirical evaluations on nine real-world datasets show that DPEs often outperform prior state-of-the-art methods in worst-group accuracy across diverse domains and kinds of subpopulation shift.", "conclusion": "DPEs provide a promising approach to handle subpopulation shift without relying on specific assumptions or annotations, offering improved performance in worst-group accuracy."}}
{"id": "2505.23032", "pdf": "https://arxiv.org/pdf/2505.23032", "abs": "https://arxiv.org/abs/2505.23032", "authors": ["Dongwoo Lee", "Dong Bok Lee", "Steven Adriaensen", "Juho Lee", "Sung Ju Hwang", "Frank Hutter", "Seon Joo Kim", "Hae Beom Lee"], "title": "Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Scaling has been a major driver of recent advancements in deep learning.\nNumerous empirical studies have found that scaling laws often follow the\npower-law and proposed several variants of power-law functions to predict the\nscaling behavior at larger scales. However, existing methods mostly rely on\npoint estimation and do not quantify uncertainty, which is crucial for\nreal-world applications involving decision-making problems such as determining\nthe expected performance improvements achievable by investing additional\ncomputational resources. In this work, we explore a Bayesian framework based on\nPrior-data Fitted Networks (PFNs) for neural scaling law extrapolation.\nSpecifically, we design a prior distribution that enables the sampling of\ninfinitely many synthetic functions resembling real-world neural scaling laws,\nallowing our PFN to meta-learn the extrapolation. We validate the effectiveness\nof our approach on real-world neural scaling laws, comparing it against both\nthe existing point estimation methods and Bayesian approaches. Our method\ndemonstrates superior performance, particularly in data-limited scenarios such\nas Bayesian active learning, underscoring its potential for reliable,\nuncertainty-aware extrapolation in practical applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u6846\u67b6\u7684Prior-data Fitted Networks (PFNs)\u65b9\u6cd5\uff0c\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u6269\u5c55\u89c4\u5f8b\u7684\u5916\u63a8\u3002\u901a\u8fc7\u8bbe\u8ba1\u5148\u9a8c\u5206\u5e03\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6a21\u62df\u65e0\u6570\u7c7b\u4f3c\u73b0\u5b9e\u4e16\u754c\u795e\u7ecf\u6269\u5c55\u89c4\u5f8b\u7684\u5408\u6210\u51fd\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u5143\u5b66\u4e60\u5916\u63a8\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff08\u5982\u8d1d\u53f6\u65af\u4e3b\u52a8\u5b66\u4e60\uff09\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u70b9\u4f30\u8ba1\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u5c55\u89c4\u5f8b\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u70b9\u4f30\u8ba1\uff0c\u65e0\u6cd5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u5bf9\u9700\u8981\u51b3\u7b56\u7684\u5b9e\u9645\u5e94\u7528\uff08\u5982\u8ba1\u7b97\u8d44\u6e90\u6295\u8d44\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\uff09\u6765\u8bf4\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u8d1d\u53f6\u65af\u6846\u67b6\u7684Prior-data Fitted Networks (PFNs)\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5148\u9a8c\u5206\u5e03\uff0c\u53ef\u4ee5\u62bd\u6837\u751f\u6210\u65e0\u6570\u7c7b\u4f3c\u4e8e\u771f\u5b9e\u795e\u7ecf\u6269\u5c55\u89c4\u5f8b\u7684\u5408\u6210\u51fd\u6570\uff0c\u4f7fPFN\u80fd\u591f\u8fdb\u884c\u5143\u5b66\u4e60\u5916\u63a8\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u795e\u7ecf\u6269\u5c55\u89c4\u5f8b\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u5883\u4e0b\uff08\u5982\u8d1d\u53f6\u65af\u4e3b\u52a8\u5b66\u4e60\uff09\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u70b9\u4f30\u8ba1\u65b9\u6cd5\u548c\u8d1d\u53f6\u65af\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u8d1d\u53f6\u65af\u6846\u67b6\u7684PFN\u65b9\u6cd5\u5728\u6269\u5c55\u89c4\u5f8b\u5916\u63a8\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u3001\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u80fd\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.22913", "pdf": "https://arxiv.org/pdf/2505.22913", "abs": "https://arxiv.org/abs/2505.22913", "authors": ["Donghyeon Joo", "Helya Hosseini", "Ramyad Hadidi", "Bahar Asgari"], "title": "Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference", "categories": ["cs.LG"], "comment": "19 pages, 9 figures", "summary": "We demonstrate that unstructured sparsity significantly improves KV cache\ncompression for LLMs, enabling sparsity levels up to 70% without compromising\naccuracy or requiring fine-tuning. We conduct a systematic exploration of\npruning strategies and find per-token magnitude-based pruning as highly\neffective for both Key and Value caches under unstructured sparsity, surpassing\nprior structured pruning schemes. The Key cache benefits from prominent outlier\nelements, while the Value cache surprisingly benefits from a simple\nmagnitude-based pruning despite its uniform distribution. KV cache size is the\nmajor bottleneck in decode performance due to high memory overhead for large\ncontext lengths. To address this, we use a bitmap-based sparse format and a\ncustom attention kernel capable of compressing and directly computing over\ncompressed caches pruned to arbitrary sparsity patterns, significantly\naccelerating memory-bound operations in decode computations and thereby\ncompensating for the overhead of runtime pruning and compression. Our custom\nattention kernel coupled with the bitmap-based format delivers substantial\ncompression of KV cache upto 45% of dense inference and thereby enables longer\ncontext length and increased tokens/sec throughput of upto 2.23x compared to\ndense inference. Our pruning mechanism and sparse attention kernel is available\nat https://github.com/dhjoo98/mustafar.", "AI": {"tldr": "\u672c\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u4f7f\u7528\u975e\u7ed3\u6784\u5316\u7a00\u758f\u6027\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4e2dKV\u7f13\u5b58\u538b\u7f29\u7684\u65b9\u6cd5\uff0c\u6700\u9ad8\u53ef\u5b9e\u73b070%\u7684\u7a00\u758f\u5ea6\u800c\u4e0d\u4f1a\u5f71\u54cd\u7cbe\u5ea6\u6216\u9700\u8981\u5fae\u8c03\u3002\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u7684\u526a\u679d\u7b56\u7565\uff0c\u53d1\u73b0\u57fa\u4e8e\u6bcftoken\u5927\u5c0f\u7684\u526a\u679d\u65b9\u6cd5\u5728\u975e\u7ed3\u6784\u5316\u7a00\u758f\u6027\u4e0b\u5bf9Key\u548cValue\u7f13\u5b58\u90fd\u975e\u5e38\u6709\u6548\uff0c\u8d85\u8fc7\u4e86\u4ee5\u524d\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6848\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u4f4d\u56fe\u683c\u5f0f\u7684\u7a00\u758f\u8868\u793a\u548c\u81ea\u5b9a\u4e49\u6ce8\u610f\u529b\u5185\u6838\uff0c\u5b9e\u73b0\u4e86KV\u7f13\u5b58\u9ad8\u8fbe45%\u7684\u5bc6\u96c6\u63a8\u7406\u538b\u7f29\u7387\uff0c\u5e76\u63d0\u9ad8\u4e86\u957f\u8fbe2.23\u500d\u7684tokens/sec\u541e\u5410\u91cf\u3002\u8be5\u65b9\u6cd5\u53ef\u5728https://github.com/dhjoo98/mustafar\u83b7\u53d6\u3002", "motivation": "LLMs\u4e2d\u7684KV\u7f13\u5b58\u7531\u4e8e\u5176\u9ad8\u5185\u5b58\u5f00\u9500\u6210\u4e3a\u4e86\u89e3\u7801\u6027\u80fd\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6\u65f6\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u8bd5\u56fe\u5bfb\u627e\u4e00\u79cd\u6709\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u4ee5\u51cf\u5c11\u5185\u5b58\u5360\u7528\u5e76\u63d0\u9ad8\u89e3\u7801\u901f\u5ea6\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u7cfb\u7edf\u5730\u63a2\u7d22\u4e86\u4e0d\u540c\u7684\u526a\u679d\u7b56\u7565\uff0c\u5e76\u53d1\u73b0\u57fa\u4e8e\u6bcftoken\u5927\u5c0f\u7684\u526a\u679d\u65b9\u6cd5\u5bf9\u4e8eKey\u548cValue\u7f13\u5b58\u5728\u975e\u7ed3\u6784\u5316\u7a00\u758f\u6027\u4e0b\u975e\u5e38\u6709\u6548\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u4f4d\u56fe\u683c\u5f0f\u7684\u7a00\u758f\u8868\u793a\u4ee5\u53ca\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u6ce8\u610f\u529b\u5185\u6838\uff0c\u53ef\u4ee5\u76f4\u63a5\u5bf9\u88ab\u538b\u7f29\u5230\u4efb\u610f\u7a00\u758f\u6a21\u5f0f\u7684\u7f13\u5b58\u8fdb\u884c\u8ba1\u7b97\uff0c\u4ece\u800c\u52a0\u901f\u89e3\u7801\u8ba1\u7b97\u4e2d\u7684\u5185\u5b58\u7ed1\u5b9a\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u8fbe70%\u7684\u7a00\u758f\u5ea6\u800c\u4e0d\u5f71\u54cd\u7cbe\u5ea6\u6216\u9700\u8981\u5fae\u8c03\uff0c\u5e76\u4e14\u80fd\u591f\u5c06KV\u7f13\u5b58\u538b\u7f29\u81f3\u5bc6\u96c6\u63a8\u7406\u768445%\uff0c\u63d0\u5347\u4e86\u6700\u957f2.23\u500d\u7684tokens/sec\u541e\u5410\u91cf\u3002", "conclusion": "\u975e\u7ed3\u6784\u5316\u7a00\u758f\u6027\u7ed3\u5408\u57fa\u4e8e\u6bcftoken\u5927\u5c0f\u7684\u526a\u679d\u65b9\u6cd5\u548c\u81ea\u5b9a\u4e49\u6ce8\u610f\u529b\u5185\u6838\uff0c\u4e3aLLMs\u4e2d\u7684KV\u7f13\u5b58\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u53ef\u4ee5\u51cf\u5c11\u5185\u5b58\u5360\u7528\u5e76\u63d0\u9ad8\u89e3\u7801\u901f\u5ea6\u3002"}}
{"id": "2505.23042", "pdf": "https://arxiv.org/pdf/2505.23042", "abs": "https://arxiv.org/abs/2505.23042", "authors": ["Siwen Wang", "Shitou Zhang", "Wan-Lin Chen", "Dung Truong", "Tzyy-Ping Jung"], "title": "From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models have inspired the development of\nfoundation models across various domains. In this study, we evaluate the\nefficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art\nfoundation EEG model, on a real-world stress classification dataset collected\nin a graduate classroom. Unlike previous studies that primarily evaluate LEMs\nusing data from controlled clinical settings, our work assesses their\napplicability to real-world environments. We train a binary classifier that\ndistinguishes between normal and elevated stress states using resting-state EEG\ndata recorded from 18 graduate students during a class session. The\nbest-performing fine-tuned model achieves a balanced accuracy of 90.47% with a\n5-second window, significantly outperforming traditional stress classifiers in\nboth accuracy and inference efficiency. We further evaluate the robustness of\nthe fine-tuned LEM under random data shuffling and reduced channel counts.\nThese results demonstrate the capability of LEMs to effectively process\nreal-world EEG data and highlight their potential to revolutionize\nbrain-computer interface applications by shifting the focus from model-centric\nto data-centric design.", "AI": {"tldr": "\u8fd1\u671f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u63a8\u52a8\u4e86\u57fa\u7840\u6a21\u578b\u5728\u5404\u9886\u57df\u7684\u5f00\u53d1\u3002\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03\u5148\u8fdb\u7684\u57fa\u7840EEG\u6a21\u578bLaBraM\uff0c\u5728\u7814\u7a76\u751f\u8bfe\u5802\u6536\u96c6\u7684\u73b0\u5b9e\u4e16\u754c\u538b\u529b\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5927EEG\u6a21\u578b\uff08LEMs\uff09\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u8bad\u7ec3\u4e86\u4e00\u4e2a\u4e8c\u5143\u5206\u7c7b\u5668\uff0c\u4f7f\u752818\u540d\u7814\u7a76\u751f\u5728\u8bfe\u5802\u671f\u95f4\u8bb0\u5f55\u7684\u9759\u606f\u72b6\u6001EEG\u6570\u636e\uff0c\u533a\u5206\u6b63\u5e38\u548c\u538b\u529b\u5347\u9ad8\u72b6\u6001\u3002\u8868\u73b0\u6700\u4f73\u7684\u5fae\u8c03\u6a21\u578b\u57285\u79d2\u7a97\u53e3\u4e0b\u5b9e\u73b0\u4e8690.47%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u538b\u529b\u5206\u7c7b\u5668\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8bc4\u4f30\u4e86\u5fae\u8c03\u540e\u7684LEMs\u5728\u968f\u673a\u6570\u636e\u6253\u4e71\u548c\u51cf\u5c11\u901a\u9053\u6570\u91cf\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660eLEMs\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u7684EEG\u6570\u636e\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u901a\u8fc7\u4ece\u4ee5\u6a21\u578b\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u6765\u9769\u65b0\u8111\u673a\u63a5\u53e3\u5e94\u7528\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u4f7f\u7528\u53d7\u63a7\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u6570\u636e\u8bc4\u4f30\u5927EEG\u6a21\u578b\uff08LEMs\uff09\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u4e9b\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5fae\u8c03\u6700\u5148\u8fdb\u7684\u57fa\u7840EEG\u6a21\u578bLaBraM\uff0c\u4f7f\u7528\u4ece\u7814\u7a76\u751f\u8bfe\u5802\u4e2d\u6536\u96c6\u7684\u771f\u5b9e\u4e16\u754c\u538b\u529b\u5206\u7c7b\u6570\u636e\u96c6\u8bc4\u4f30LEMs\u7684\u6548\u679c\u3002\u8bad\u7ec3\u4e00\u4e2a\u4e8c\u5143\u5206\u7c7b\u5668\uff0c\u5229\u752818\u540d\u7814\u7a76\u751f\u7684\u9759\u606f\u72b6\u6001EEG\u6570\u636e\uff0c\u533a\u5206\u6b63\u5e38\u4e0e\u538b\u529b\u5347\u9ad8\u72b6\u6001\u3002\u540c\u65f6\u8bc4\u4f30\u6a21\u578b\u5728\u968f\u673a\u6570\u636e\u6253\u4e71\u548c\u51cf\u5c11\u901a\u9053\u6570\u91cf\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u6700\u4f73\u5fae\u8c03\u6a21\u578b\u57285\u79d2\u7a97\u53e3\u5185\u5b9e\u73b0\u4e8690.47%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u538b\u529b\u5206\u7c7b\u5668\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u4e0a\u63d0\u9ad8\uff0c\u800c\u4e14\u5728\u63a8\u7406\u6548\u7387\u4e0a\u4e5f\u66f4\u4f18\u3002", "conclusion": "\u5927EEG\u6a21\u578b\uff08LEMs\uff09\u80fd\u591f\u6709\u6548\u5904\u7406\u771f\u5b9e\u4e16\u754cEEG\u6570\u636e\uff0c\u5c55\u73b0\u51fa\u5728\u8111\u673a\u63a5\u53e3\u5e94\u7528\u9886\u57df\u4e2d\u901a\u8fc7\u91c7\u7528\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u65b9\u5f0f\u5e26\u6765\u53d8\u9769\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.23062", "pdf": "https://arxiv.org/pdf/2505.23062", "abs": "https://arxiv.org/abs/2505.23062", "authors": ["Lingkai Kong", "Haichuan Wang", "Tonghan Wang", "Guojun Xiong", "Milind Tambe"], "title": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Incorporating pre-collected offline data from a source environment can\nsignificantly improve the sample efficiency of reinforcement learning (RL), but\nthis benefit is often challenged by discrepancies between the transition\ndynamics of the source and target environments. Existing methods typically\naddress this issue by penalizing or filtering out source transitions in high\ndynamics-gap regions. However, their estimation of the dynamics gap often\nrelies on KL divergence or mutual information, which can be ill-defined when\nthe source and target dynamics have disjoint support. To overcome these\nlimitations, we propose CompFlow, a method grounded in the theoretical\nconnection between flow matching and optimal transport. Specifically, we model\nthe target dynamics as a conditional flow built upon the output distribution of\nthe source-domain flow, rather than learning it directly from a Gaussian prior.\nThis composite structure offers two key advantages: (1) improved generalization\nfor learning target dynamics, and (2) a principled estimation of the dynamics\ngap via the Wasserstein distance between source and target transitions.\nLeveraging our principled estimation of the dynamics gap, we further introduce\nan optimistic active data collection strategy that prioritizes exploration in\nregions of high dynamics gap, and theoretically prove that it reduces the\nperformance disparity with the optimal policy. Empirically, CompFlow\noutperforms strong baselines across several RL benchmarks with shifted\ndynamics.", "AI": {"tldr": "CompFlow\u662f\u4e00\u79cd\u57fa\u4e8e\u6d41\u52a8\u5339\u914d\u548c\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6e90\u73af\u5883\u548c\u76ee\u6807\u73af\u5883\u4e4b\u95f4\u7684\u52a8\u6001\u5dee\u5f02\u95ee\u9898\u3002\u901a\u8fc7\u5efa\u6a21\u76ee\u6807\u52a8\u6001\u4e3a\u6761\u4ef6\u6d41\uff0c\u5e76\u4f7f\u7528Wasserstein\u8ddd\u79bb\u4f30\u8ba1\u52a8\u6001\u5dee\u8ddd\uff0cCompFlow\u5728\u591a\u4e2aRL\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u6e90\u73af\u5883\u548c\u76ee\u6807\u73af\u5883\u4e4b\u95f4\u7684\u52a8\u6001\u5dee\u5f02\u65f6\uff0c\u901a\u5e38\u4f9d\u8d56KL\u6563\u5ea6\u6216\u4e92\u4fe1\u606f\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u6e90\u548c\u76ee\u6807\u52a8\u6001\u652f\u6301\u4e0d\u91cd\u53e0\u65f6\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCompFlow\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6d41\u52a8\u5339\u914d\u4e0e\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c06\u76ee\u6807\u52a8\u6001\u5efa\u6a21\u4e3a\u57fa\u4e8e\u6e90\u57df\u6d41\u8f93\u51fa\u5206\u5e03\u7684\u6761\u4ef6\u6d41\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u4ece\u9ad8\u65af\u5148\u9a8c\u4e2d\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u4e50\u89c2\u7684\u4e3b\u52a8\u6570\u636e\u6536\u96c6\u7b56\u7565\uff0c\u4f18\u5148\u63a2\u7d22\u52a8\u6001\u5dee\u8ddd\u8f83\u5927\u7684\u533a\u57df\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4e50\u89c2\u4e3b\u52a8\u6570\u636e\u6536\u96c6\u7b56\u7565\u53ef\u4ee5\u51cf\u5c11\u4e0e\u6700\u4f18\u7b56\u7565\u7684\u6027\u80fd\u5dee\u5f02\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cCompFlow\u5728\u591a\u4e2a\u5177\u6709\u52a8\u6001\u53d8\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u4e0a\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u3002", "conclusion": "CompFlow\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6cdb\u5316\u80fd\u529b\u4ee5\u5b66\u4e60\u76ee\u6807\u52a8\u6001\uff0c\u5e76\u901a\u8fc7Wasserstein\u8ddd\u79bb\u63d0\u4f9b\u4e86\u5bf9\u52a8\u6001\u5dee\u8ddd\u7684\u5408\u7406\u4f30\u8ba1\uff0c\u4ece\u800c\u6709\u6548\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2505.22935", "pdf": "https://arxiv.org/pdf/2505.22935", "abs": "https://arxiv.org/abs/2505.22935", "authors": ["Jipeng Li", "Yanning Shen"], "title": "Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Explicit noise-level conditioning is widely regarded as essential for the\neffective operation of Graph Diffusion Models (GDMs). In this work, we\nchallenge this assumption by investigating whether denoisers can implicitly\ninfer noise levels directly from corrupted graph structures, potentially\neliminating the need for explicit noise conditioning. To this end, we develop a\ntheoretical framework centered on Bernoulli edge-flip corruptions and extend it\nto encompass more complex scenarios involving coupled structure-attribute\nnoise. Extensive empirical evaluations on both synthetic and real-world graph\ndatasets, using models such as GDSS and DiGress, provide strong support for our\ntheoretical findings. Notably, unconditional GDMs achieve performance\ncomparable or superior to their conditioned counterparts, while also offering\nreductions in parameters (4-6%) and computation time (8-10%). Our results\nsuggest that the high-dimensional nature of graph data itself often encodes\nsufficient information for the denoising process, opening avenues for simpler,\nmore efficient GDM architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u6311\u6218\u4e86\u663e\u5f0f\u566a\u58f0\u7ea7\u8c03\u8282\u5728\u56fe\u6269\u6563\u6a21\u578b\uff08GDMs\uff09\u4e2d\u7684\u5fc5\u8981\u6027\u5047\u8bbe\uff0c\u63d0\u51fa\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u65e0\u6761\u4ef6GDMs\u53ef\u4ee5\u8fbe\u5230\u4e0e\u6709\u6761\u4ef6\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u663e\u5f0f\u566a\u58f0\u7ea7\u8c03\u8282\u88ab\u8ba4\u4e3a\u662f\u56fe\u6269\u6563\u6a21\u578b\u6709\u6548\u8fd0\u884c\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u7814\u7a76\u8005\u8d28\u7591\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u9690\u5f0f\u65b9\u6cd5\u4ece\u53d7\u635f\u7684\u56fe\u7ed3\u6784\u4e2d\u63a8\u65ad\u566a\u58f0\u6c34\u5e73\uff0c\u4ece\u800c\u907f\u514d\u663e\u5f0f\u8c03\u8282\u7684\u9700\u6c42\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ee5\u4f2f\u52aa\u5229\u8fb9\u7ffb\u8f6c\u7834\u574f\u4e3a\u4e2d\u5fc3\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u6269\u5c55\u5230\u5305\u542b\u66f4\u590d\u6742\u7684\u7ed3\u6784-\u5c5e\u6027\u566a\u58f0\u60c5\u51b5\u3002\u4f7f\u7528GDSS\u548cDiGress\u7b49\u6a21\u578b\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u56fe\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u65e0\u6761\u4ef6GDMs\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u6709\u6761\u4ef6\u6a21\u578b\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\uff0c\u540c\u65f6\u51cf\u5c11\u4e864-6%\u7684\u53c2\u6570\u548c8-10%\u7684\u8ba1\u7b97\u65f6\u95f4\u3002\u7ed3\u679c\u8868\u660e\u56fe\u6570\u636e\u7684\u9ad8\u7ef4\u7279\u6027\u672c\u8eab\u901a\u5e38\u5305\u542b\u4e86\u8db3\u591f\u7684\u53bb\u566a\u4fe1\u606f\u3002", "conclusion": "\u56fe\u6570\u636e\u7684\u9ad8\u7ef4\u7279\u6027\u5e38\u5e38\u5305\u542b\u8db3\u591f\u7684\u53bb\u566a\u4fe1\u606f\uff0c\u8fd9\u4e3a\u66f4\u7b80\u5355\u3001\u9ad8\u6548\u7684GDM\u67b6\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23086", "pdf": "https://arxiv.org/pdf/2505.23086", "abs": "https://arxiv.org/abs/2505.23086", "authors": ["Junyi An", "Xinyu Lu", "Chao Qu", "Yunfei Shi", "Peijia Lin", "Qianwei Tang", "Licheng Xu", "Fenglei Cao", "Yuan Qi"], "title": "Equivariant Spherical Transformer for Efficient Molecular Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 3 figures", "summary": "SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced\nmolecular system modeling by employing group representations. However, their\nmessage passing processes, which rely on tensor product-based convolutions, are\nlimited by insufficient non-linearity and incomplete group representations,\nthereby restricting expressiveness. To overcome these limitations, we introduce\nthe Equivariant Spherical Transformer (EST), a novel framework that leverages a\nTransformer structure within the spatial domain of group representations after\nFourier transform. We theoretically and empirically demonstrate that EST can\nencompass the function space of tensor products while achieving superior\nexpressiveness. Furthermore, EST's equivariant inductive bias is guaranteed\nthrough a uniform sampling strategy for the Fourier transform. Our experiments\ndemonstrate state-of-the-art performance by EST on various molecular\nbenchmarks, including OC20 and QM9.", "AI": {"tldr": "SE(3)-\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u901a\u8fc7\u4f7f\u7528\u7fa4\u8868\u793a\u663e\u8457\u63a8\u52a8\u4e86\u5206\u5b50\u7cfb\u7edf\u5efa\u6a21\u7684\u53d1\u5c55\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5f20\u91cf\u79ef\u5377\u79ef\u7684\u975e\u7ebf\u6027\u4e0d\u8db3\u548c\u7fa4\u8868\u793a\u4e0d\u5b8c\u6574\uff0c\u5176\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\u53d7\u5230\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u2014\u2014\u7b49\u53d8\u7403\u9762\u53d8\u6362\u5668\uff08EST\uff09\uff0c\u5b83\u5728Fourier\u53d8\u6362\u540e\u7684\u7fa4\u8868\u793a\u7a7a\u95f4\u57df\u5185\u5229\u7528Transformer\u7ed3\u6784\u3002\u7406\u8bba\u548c\u5b9e\u8bc1\u8868\u660e\uff0cEST\u53ef\u4ee5\u6db5\u76d6\u5f20\u91cf\u79ef\u7684\u529f\u80fd\u7a7a\u95f4\uff0c\u5e76\u5b9e\u73b0\u66f4\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\u3002\u6b64\u5916\uff0c\u901a\u8fc7Fourier\u53d8\u6362\u7684\u5747\u5300\u91c7\u6837\u7b56\u7565\uff0cEST\u7684\u7b49\u53d8\u5f52\u7eb3\u504f\u7f6e\u5f97\u5230\u4e86\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5305\u62ecOC20\u548cQM9\u5728\u5185\u7684\u591a\u4e2a\u5206\u5b50\u57fa\u51c6\u4e0a\uff0cEST\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684SE(3)-\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5df2\u7ecf\u5728\u5206\u5b50\u7cfb\u7edf\u5efa\u6a21\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\u53d7\u9650\u4e8e\u5f20\u91cf\u79ef\u5377\u79ef\u7684\u975e\u7ebf\u6027\u4e0d\u8db3\u548c\u7fa4\u8868\u793a\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEquivariant Spherical Transformer (EST)\u7684\u65b0\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5728Fourier\u53d8\u6362\u540e\u7684\u7fa4\u8868\u793a\u7a7a\u95f4\u57df\u5185\u4f7f\u7528Transformer\u7ed3\u6784\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u7684\u975e\u7ebf\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002EST\u901a\u8fc7\u6db5\u76d6\u5f20\u91cf\u79ef\u7684\u529f\u80fd\u7a7a\u95f4\u5e76\u8d85\u8d8a\u5176\u8868\u8fbe\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\uff0cEST\u901a\u8fc7Fourier\u53d8\u6362\u7684\u5747\u5300\u91c7\u6837\u7b56\u7565\u786e\u4fdd\u4e86\u7b49\u53d8\u5f52\u7eb3\u504f\u7f6e\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0cEST\u80fd\u591f\u6db5\u76d6\u5f20\u91cf\u79ef\u7684\u529f\u80fd\u7a7a\u95f4\uff0c\u5e76\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\u3002\u5728\u591a\u4e2a\u5206\u5b50\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff08\u5982OC20\u548cQM9\uff09\uff0cEST\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "EST\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u7b49\u53d8\u6846\u67b6\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709SE(3)-\u7b49\u53d8GNNs\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002\u5176\u5728\u5206\u5b50\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u5353\u8d8a\u8868\u73b0\u5c55\u793a\u4e86EST\u5728\u672a\u6765\u76f8\u5173\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.22949", "pdf": "https://arxiv.org/pdf/2505.22949", "abs": "https://arxiv.org/abs/2505.22949", "authors": ["Michael Sun", "Orion Foo", "Gang Liu", "Wojciech Matusik", "Jie Chen"], "title": "Directed Graph Grammars for Sequence-based Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Directed acyclic graphs (DAGs) are a class of graphs commonly used in\npractice, with examples that include electronic circuits, Bayesian networks,\nand neural architectures. While many effective encoders exist for DAGs, it\nremains challenging to decode them in a principled manner, because the nodes of\na DAG can have many different topological orders. In this work, we propose a\ngrammar-based approach to constructing a principled, compact and equivalent\nsequential representation of a DAG. Specifically, we view a graph as\nderivations over an unambiguous grammar, where the DAG corresponds to a unique\nsequence of production rules. Equivalently, the procedure to construct such a\ndescription can be viewed as a lossless compression of the data. Such a\nrepresentation has many uses, including building a generative model for graph\ngeneration, learning a latent space for property prediction, and leveraging the\nsequence representational continuity for Bayesian Optimization over structured\ndata. Code is available at https://github.com/shiningsunnyday/induction.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u7d27\u51d1\u4e14\u7b49\u6548\u7684\u5e8f\u5217\u5316\u8868\u793a\u3002\u901a\u8fc7\u5c06\u56fe\u89c6\u4e3a\u5728\u660e\u786e\u8bed\u6cd5\u4e0a\u7684\u63a8\u5bfc\uff0c\u6bcf\u4e2aDAG\u5bf9\u5e94\u552f\u4e00\u7684\u751f\u4ea7\u89c4\u5219\u5e8f\u5217\u3002\u6b64\u65b9\u6cd5\u53ef\u7528\u4e8e\u751f\u6210\u6a21\u578b\u3001\u5c5e\u6027\u9884\u6d4b\u548c\u7ed3\u6784\u5316\u6570\u636e\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "motivation": "\u5c3d\u7ba1\u6709\u8bb8\u591a\u6709\u6548\u7684DAG\u7f16\u7801\u5668\uff0c\u4f46\u4ee5\u539f\u5219\u6027\u65b9\u5f0f\u89e3\u7801\u5b83\u4eec\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3aDAG\u7684\u8282\u70b9\u53ef\u4ee5\u6709\u8bb8\u591a\u4e0d\u540c\u7684\u62d3\u6251\u987a\u5e8f\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\uff0c\u5c06DAG\u89c6\u4e3a\u5728\u660e\u786e\u8bed\u6cd5\u4e0a\u7684\u63a8\u5bfc\uff0c\u5176\u4e2d\u6bcf\u4e2aDAG\u5bf9\u5e94\u4e00\u4e2a\u552f\u4e00\u7684\u751f\u4ea7\u89c4\u5219\u5e8f\u5217\u3002\u8be5\u8fc7\u7a0b\u76f8\u5f53\u4e8e\u5bf9\u6570\u636e\u8fdb\u884c\u65e0\u635f\u538b\u7f29\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86DAG\u7684\u7d27\u51d1\u4e14\u7b49\u6548\u7684\u5e8f\u5217\u5316\u8868\u793a\uff0c\u53ef\u5e94\u7528\u4e8e\u751f\u6210\u6a21\u578b\u3001\u5c5e\u6027\u9884\u6d4b\u548c\u7ed3\u6784\u5316\u6570\u636e\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\u4e3aDAG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u4e14\u7b49\u6548\u7684\u5e8f\u5217\u5316\u8868\u793a\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\uff0c\u5982\u751f\u6210\u6a21\u578b\u3001\u5c5e\u6027\u9884\u6d4b\u548c\u7ed3\u6784\u5316\u6570\u636e\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u3002"}}
{"id": "2505.23116", "pdf": "https://arxiv.org/pdf/2505.23116", "abs": "https://arxiv.org/abs/2505.23116", "authors": ["Pengfei Zhou", "Yunlong Liu", "Junli Liang", "Qi Song", "Xiangyang Li"], "title": "CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting with exogenous variables is a critical emerging\nparadigm that presents unique challenges in modeling dependencies between\nvariables. Traditional models often struggle to differentiate between\nendogenous and exogenous variables, leading to inefficiencies and overfitting.\nIn this paper, we introduce CrossLinear, a novel Linear-based forecasting model\nthat addresses these challenges by incorporating a plug-and-play\ncross-correlation embedding module. This lightweight module captures the\ndependencies between variables with minimal computational cost and seamlessly\nintegrates into existing neural networks. Specifically, it captures\ntime-invariant and direct variable dependencies while disregarding time-varying\nor indirect dependencies, thereby mitigating the risk of overfitting in\ndependency modeling and contributing to consistent performance improvements.\nFurthermore, CrossLinear employs patch-wise processing and a global linear head\nto effectively capture both short-term and long-term temporal dependencies,\nfurther improving its forecasting precision. Extensive experiments on 12\nreal-world datasets demonstrate that CrossLinear achieves superior performance\nin both short-term and long-term forecasting tasks. The ablation study\nunderscores the effectiveness of the cross-correlation embedding module.\nAdditionally, the generalizability of this module makes it a valuable plug-in\nfor various forecasting tasks across different domains. Codes are available at\nhttps://github.com/mumiao2000/CrossLinear.", "AI": {"tldr": "CrossLinear\u662f\u4e00\u79cd\u65b0\u578b\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u7684\u4ea4\u53c9\u76f8\u5173\u5d4c\u5165\u6a21\u5757\u89e3\u51b3\u53d8\u91cf\u4f9d\u8d56\u5efa\u6a21\u95ee\u9898\u3002\u5b83\u80fd\u6709\u6548\u6355\u6349\u53d8\u91cf\u95f4\u7684\u76f4\u63a5\u4f9d\u8d56\u5173\u7cfb\uff0c\u964d\u4f4e\u8fc7\u62df\u5408\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u5206\u5757\u5904\u7406\u548c\u5168\u5c40\u7ebf\u6027\u5934\u63d0\u5347\u77ed\u671f\u548c\u957f\u671f\u9884\u6d4b\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u533a\u5206\u5185\u751f\u548c\u5916\u751f\u53d8\u91cf\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u8fc7\u62df\u5408\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9ad8\u6548\u6355\u6349\u53d8\u91cf\u95f4\u4f9d\u8d56\u5173\u7cfb\u4e14\u4e0d\u8fc7\u62df\u5408\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCrossLinear\u6a21\u578b\uff0c\u5305\u542b\u4e00\u4e2a\u53ef\u63d2\u62d4\u7684\u4ea4\u53c9\u76f8\u5173\u5d4c\u5165\u6a21\u5757\uff0c\u7528\u4e8e\u6355\u6349\u53d8\u91cf\u95f4\u7684\u76f4\u63a5\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u5ffd\u7565\u95f4\u63a5\u6216\u65f6\u53d8\u4f9d\u8d56\u3002\u91c7\u7528\u5206\u5757\u5904\u7406\u548c\u5168\u5c40\u7ebf\u6027\u5934\u6765\u6355\u6349\u77ed\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u3002", "result": "\u572812\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCrossLinear\u5728\u77ed\u671f\u548c\u957f\u671f\u9884\u6d4b\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u4ea4\u53c9\u76f8\u5173\u5d4c\u5165\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "conclusion": "CrossLinear\u6a21\u578b\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u6709\u6548\u7684\u4f9d\u8d56\u6355\u6349\u673a\u5236\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5176\u6a21\u5757\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u9886\u57df\u7684\u9884\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2505.22967", "pdf": "https://arxiv.org/pdf/2505.22967", "abs": "https://arxiv.org/abs/2505.22967", "authors": ["Chengqi Zheng", "Jianda Chen", "Yueming Lyu", "Wen Zheng Terence Ng", "Haopeng Zhang", "Yew-Soon Ong", "Ivor Tsang", "Haiyan Yin"], "title": "MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Despite the promise of autonomous agentic reasoning, existing workflow\ngeneration methods frequently produce fragile, unexecutable plans due to\nunconstrained LLM-driven construction. We introduce MermaidFlow, a framework\nthat redefines the agentic search space through safety-constrained graph\nevolution. At its core, MermaidFlow represent workflows as a verifiable\nintermediate representation using Mermaid, a structured and human-interpretable\ngraph language. We formulate domain-aware evolutionary operators, i.e.,\ncrossover, mutation, insertion, and deletion, to preserve semantic correctness\nwhile promoting structural diversity, enabling efficient exploration of a\nhigh-quality, statically verifiable workflow space. Without modifying task\nsettings or evaluation protocols, MermaidFlow achieves consistent improvements\nin success rates and faster convergence to executable plans on the agent\nreasoning benchmark. The experimental results demonstrate that\nsafety-constrained graph evolution offers a scalable, modular foundation for\nrobust and interpretable agentic reasoning systems.", "AI": {"tldr": "MermaidFlow \u662f\u4e00\u4e2a\u901a\u8fc7\u5b89\u5168\u7ea6\u675f\u56fe\u6f14\u5316\u91cd\u65b0\u5b9a\u4e49\u4ee3\u7406\u641c\u7d22\u7a7a\u95f4\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u7684\u4e2d\u95f4\u8868\u793a\u6765\u8868\u793a\u5de5\u4f5c\u6d41\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u611f\u77e5\u8fdb\u5316\u7b97\u5b50\u63d0\u9ad8\u8bed\u4e49\u6b63\u786e\u6027\u548c\u7ed3\u6784\u591a\u6837\u6027\uff0c\u5728\u4ee3\u7406\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u4e3b\u4ee3\u7406\u63a8\u7406\u65b9\u6cd5\u5e38\u5e38\u751f\u6210\u8106\u5f31\u4e14\u4e0d\u53ef\u6267\u884c\u7684\u8ba1\u5212\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u4e0d\u53d7\u7ea6\u675f\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u6784\u5efa\u3002", "method": "MermaidFlow \u4f7f\u7528 Mermaid \u56fe\u5f62\u8bed\u8a00\u4f5c\u4e3a\u53ef\u9a8c\u8bc1\u7684\u4e2d\u95f4\u8868\u793a\u6765\u8868\u793a\u5de5\u4f5c\u6d41\uff0c\u5e76\u5f15\u5165\u9886\u57df\u611f\u77e5\u8fdb\u5316\u7b97\u5b50\uff08\u5982\u4ea4\u53c9\u3001\u53d8\u5f02\u3001\u63d2\u5165\u548c\u5220\u9664\uff09\u4ee5\u5728\u4fc3\u8fdb\u7ed3\u6784\u591a\u6837\u6027\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u9ad8\u8d28\u91cf\u3001\u9759\u6001\u53ef\u9a8c\u8bc1\u7684\u5de5\u4f5c\u6d41\u7a7a\u95f4\u7684\u6709\u6548\u63a2\u7d22\u3002", "result": "\u5728\u4e0d\u4fee\u6539\u4efb\u52a1\u8bbe\u7f6e\u6216\u8bc4\u4f30\u534f\u8bae\u7684\u60c5\u51b5\u4e0b\uff0cMermaidFlow \u5728\u4ee3\u7406\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6210\u529f\u7387\u7684\u4e00\u81f4\u63d0\u5347\u548c\u66f4\u5feb\u6536\u655b\u5230\u53ef\u6267\u884c\u8ba1\u5212\u7684\u80fd\u529b\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b89\u5168\u7ea6\u675f\u56fe\u6f14\u5316\u4e3a\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u4ee3\u7406\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u548c\u6a21\u5757\u5316\u7684\u57fa\u7840\u3002"}}
{"id": "2505.23117", "pdf": "https://arxiv.org/pdf/2505.23117", "abs": "https://arxiv.org/abs/2505.23117", "authors": ["Yuatyong Chaichana", "Thanapat Trachu", "Peerat Limkonchotiwat", "Konpat Preechakul", "Tirasan Khandhawit", "Ekapol Chuangsuwanich"], "title": "Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the era of large-scale training, model merging has evolved into a tool for\ncreating multitasking models efficiently. It enables the knowledge of models to\nbe fused, without the need for heavy computation as required in traditional\nmultitask learning. Existing merging methods often assume that entries at\nidentical positions in weight matrices serve the same function, enabling\nstraightforward entry-wise comparison and merging. However, this assumption\noverlooks the complexity of finetuned neural networks, where neurons may\ndevelop distinct feature compositions, making direct entry-wise merging\nproblematic. We present Decom-Renorm-Merge (DRM), a simple yet effective\napproach that leverages Singular Value Decomposition to decompose and\ncoordinate weight matrices into an aligned joint space, where entry-wise\nmerging becomes possible. We showcase the effectiveness of DRM across various\nsettings ranging from smaller encoder-based such as ViT and DeBERTa,\nencoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B.\nOur experimental results show that DRM outperforms several state-of-the-art\nmerging techniques across full finetuning and low-rank adaptation settings.\nMoreover, our analysis reveals renormalization as the crucial component for\ncreating a robust and even joint space for merging, significantly contributing\nto the method's performance.", "AI": {"tldr": "\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u65f6\u4ee3\uff0c\u6a21\u578b\u878d\u5408\u5df2\u6210\u4e3a\u521b\u5efa\u591a\u4efb\u52a1\u6a21\u578b\u7684\u6709\u6548\u5de5\u5177\u3002\u73b0\u6709\u7684\u878d\u5408\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6743\u91cd\u77e9\u9635\u4e2d\u76f8\u540c\u4f4d\u7f6e\u7684\u6761\u76ee\u5177\u6709\u76f8\u540c\u529f\u80fd\uff0c\u4f46\u5ffd\u7565\u4e86\u5fae\u8c03\u795e\u7ecf\u7f51\u7edc\u7684\u590d\u6742\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86Decom-Renorm-Merge (DRM) \u65b9\u6cd5\uff0c\u901a\u8fc7\u5947\u5f02\u503c\u5206\u89e3\u5c06\u6743\u91cd\u77e9\u9635\u5206\u89e3\u5e76\u534f\u8c03\u5230\u5bf9\u9f50\u7684\u8054\u5408\u7a7a\u95f4\u4e2d\uff0c\u4f7f\u5f97\u9010\u9879\u878d\u5408\u6210\u4e3a\u53ef\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDRM \u5728\u591a\u79cd\u6a21\u578b\u548c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u878d\u5408\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u5047\u8bbe\u6743\u91cd\u77e9\u9635\u4e2d\u76f8\u540c\u4f4d\u7f6e\u7684\u6761\u76ee\u5177\u6709\u76f8\u540c\u529f\u80fd\uff0c\u4f46\u5ffd\u7565\u4e86\u5fae\u8c03\u795e\u7ecf\u7f51\u7edc\u4e2d\u795e\u7ecf\u5143\u53ef\u80fd\u53d1\u5c55\u51fa\u4e0d\u540c\u7684\u7279\u5f81\u7ec4\u6210\uff0c\u5bfc\u81f4\u76f4\u63a5\u9010\u9879\u878d\u5408\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Decom-Renorm-Merge (DRM) \u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5947\u5f02\u503c\u5206\u89e3\u5c06\u6743\u91cd\u77e9\u9635\u5206\u89e3\u5e76\u534f\u8c03\u5230\u5bf9\u9f50\u7684\u8054\u5408\u7a7a\u95f4\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u9010\u9879\u878d\u5408\u3002", "result": "DRM \u5728\u5404\u79cd\u6a21\u578b\uff08\u5982 ViT\u3001DeBERTa\u3001T5 \u548c Llama3.1-8B\uff09\u548c\u8bbe\u7f6e\uff08\u5168\u5fae\u8c03\u548c\u4f4e\u79e9\u9002\u5e94\uff09\u4e0b\uff0c\u5747\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u878d\u5408\u6280\u672f\u3002\u5206\u6790\u8fd8\u663e\u793a\uff0c\u91cd\u5f52\u4e00\u5316\u662f\u521b\u5efa\u7a33\u5065\u8054\u5408\u7a7a\u95f4\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u663e\u8457\u8d21\u732e\u4e8e\u65b9\u6cd5\u6027\u80fd\u3002", "conclusion": "DRM \u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u591a\u79cd\u6a21\u578b\u548c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u6a21\u578b\u878d\u5408\u6548\u679c\uff0c\u91cd\u5f52\u4e00\u5316\u5bf9\u4e8e\u521b\u5efa\u7a33\u5065\u7684\u8054\u5408\u7a7a\u95f4\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2505.23135", "pdf": "https://arxiv.org/pdf/2505.23135", "abs": "https://arxiv.org/abs/2505.23135", "authors": ["Zhe Ye", "Zhengxu Yan", "Jingxuan He", "Timothe Kasriel", "Kaiyu Yang", "Dawn Song"], "title": "VERINA: Benchmarking Verifiable Code Generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) are increasingly integrated in software\ndevelopment, but ensuring correctness in LLM-generated code remains challenging\nand often requires costly manual review. Verifiable code generation -- jointly\ngenerating code, specifications, and proofs of code-specification alignment --\noffers a promising path to address this limitation and further unleash LLMs'\nbenefits in coding. Yet, there exists a significant gap in evaluation: current\nbenchmarks often lack support for end-to-end verifiable code generation. In\nthis paper, we introduce Verina (Verifiable Code Generation Arena), a\nhigh-quality benchmark enabling a comprehensive and modular evaluation of code,\nspecification, and proof generation as well as their compositions. Verina\nconsists of 189 manually curated coding tasks in Lean, with detailed problem\ndescriptions, reference implementations, formal specifications, and extensive\ntest suites. Our extensive evaluation of state-of-the-art LLMs reveals\nsignificant challenges in verifiable code generation, especially in proof\ngeneration, underscoring the need for improving LLM-based theorem provers in\nverification domains. The best model, OpenAI o4-mini, generates only 61.4%\ncorrect code, 51.0% sound and complete specifications, and 3.6% successful\nproofs, with one trial per task. We hope Verina will catalyze progress in\nverifiable code generation by providing a rigorous and comprehensive benchmark.\nWe release our dataset on https://huggingface.co/datasets/sunblaze-ucb/verina\nand our evaluation code on https://github.com/sunblaze-ucb/verina.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aVerina\u7684\u9ad8\u8d28\u91cf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u652f\u6301\u5bf9\u4ee3\u7801\u3001\u89c4\u8303\u548c\u8bc1\u660e\u751f\u6210\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002\u901a\u8fc7\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u53ef\u9a8c\u8bc1\u4ee3\u7801\u751f\u6210\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u8bc1\u660e\u751f\u6210\u4e0a\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u652f\u6301\u7aef\u5230\u7aef\u53ef\u9a8c\u8bc1\u4ee3\u7801\u751f\u6210\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u8fdb\u4e00\u6b65\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e86Verina\uff0c\u4e00\u4e2a\u5305\u542b189\u4e2a\u624b\u52a8\u7b56\u5212\u7684Lean\u7f16\u7a0b\u4efb\u52a1\u7684\u9ad8\u8d28\u91cf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u95ee\u9898\u63cf\u8ff0\u3001\u53c2\u8003\u5b9e\u73b0\u3001\u6b63\u5f0f\u89c4\u8303\u548c\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u5168\u9762\u548c\u6a21\u5757\u5316\u5730\u8bc4\u4f30\u4ee3\u7801\u3001\u89c4\u8303\u548c\u8bc1\u660e\u751f\u6210\u53ca\u5176\u7ec4\u5408\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u6700\u597d\u7684\u6a21\u578bOpenAI o4-mini\uff0c\u5728\u5355\u6b21\u5c1d\u8bd5\u4e0b\u4e5f\u53ea\u80fd\u751f\u621061.4%\u6b63\u786e\u7684\u4ee3\u7801\u300151.0%\u58f0\u97f3\u548c\u5b8c\u6574\u7684\u89c4\u8303\u4ee5\u53ca3.6%\u6210\u529f\u7684\u8bc1\u660e\u3002", "conclusion": "Verina\u5c06\u63a8\u52a8\u53ef\u9a8c\u8bc1\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u8fdb\u6b65\uff0c\u5e76\u4e3a\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u5b9a\u7406\u8bc1\u660e\u5668\u5728\u9a8c\u8bc1\u9886\u57df\u63d0\u4f9b\u4e25\u683c\u548c\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2505.22984", "pdf": "https://arxiv.org/pdf/2505.22984", "abs": "https://arxiv.org/abs/2505.22984", "authors": ["Guancheng Zhou", "Haiping Xu", "Hongkang Xu", "Chenyu Li", "Donghui Yan"], "title": "A Computational Approach to Improving Fairness in K-means Clustering", "categories": ["cs.LG", "cs.CY"], "comment": "14 pages, 5 figures", "summary": "The popular K-means clustering algorithm potentially suffers from a major\nweakness for further analysis or interpretation. Some cluster may have\ndisproportionately more (or fewer) points from one of the subpopulations in\nterms of some sensitive variable, e.g., gender or race. Such a fairness issue\nmay cause bias and unexpected social consequences. This work attempts to\nimprove the fairness of K-means clustering with a two-stage optimization\nformulation--clustering first and then adjust cluster membership of a small\nsubset of selected data points. Two computationally efficient algorithms are\nproposed in identifying those data points that are expensive for fairness, with\none focusing on nearest data points outside of a cluster and the other on\nhighly 'mixed' data points. Experiments on benchmark datasets show substantial\nimprovement on fairness with a minimal impact to clustering quality. The\nproposed algorithms can be easily extended to a broad class of clustering\nalgorithms or fairness metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u4f18\u5316\u516c\u5f0f\u4ee5\u6539\u5584K-means\u805a\u7c7b\u7684\u516c\u5e73\u6027\uff0c\u9996\u5148\u8fdb\u884c\u805a\u7c7b\u7136\u540e\u8c03\u6574\u4e00\u5c0f\u90e8\u5206\u6570\u636e\u70b9\u7684\u805a\u7c7b\u96b6\u5c5e\u5173\u7cfb\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u7b97\u6cd5\u6765\u8bc6\u522b\u5bf9\u516c\u5e73\u6027\u6602\u8d35\u7684\u6570\u636e\u70b9\uff0c\u5e76\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u663e\u8457\u7684\u516c\u5e73\u6027\u6539\u8fdb\uff0c\u540c\u65f6\u5bf9\u805a\u7c7b\u8d28\u91cf\u7684\u5f71\u54cd\u6700\u5c0f\u3002", "motivation": "K-means\u805a\u7c7b\u7b97\u6cd5\u53ef\u80fd\u5728\u4e00\u4e2a\u654f\u611f\u53d8\u91cf\uff08\u5982\u6027\u522b\u6216\u79cd\u65cf\uff09\u65b9\u9762\u5b58\u5728\u4e0d\u516c\u5e73\u95ee\u9898\uff0c\u67d0\u4e9b\u805a\u7c7b\u53ef\u80fd\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u5730\u5305\u542b\u6765\u81ea\u5b50\u7fa4\u4f53\u7684\u66f4\u591a\uff08\u6216\u66f4\u5c11\uff09\u70b9\uff0c\u4ece\u800c\u5bfc\u81f4\u504f\u5dee\u548c\u610f\u5916\u7684\u793e\u4f1a\u540e\u679c\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff1a\u5148\u8fdb\u884c\u805a\u7c7b\uff0c\u7136\u540e\u8c03\u6574\u4e00\u5c0f\u90e8\u5206\u9009\u5b9a\u6570\u636e\u70b9\u7684\u805a\u7c7b\u6210\u5458\u8d44\u683c\u3002\u63d0\u51fa\u4e24\u79cd\u9ad8\u6548\u7b97\u6cd5\u6765\u8bc6\u522b\u5bf9\u516c\u5e73\u6027\u6709\u91cd\u5927\u5f71\u54cd\u7684\u6570\u636e\u70b9\uff0c\u4e00\u4e2a\u5173\u6ce8\u96c6\u7fa4\u5916\u6700\u8fd1\u7684\u6570\u636e\u70b9\uff0c\u53e6\u4e00\u4e2a\u5173\u6ce8\u9ad8\u5ea6\u201c\u6df7\u5408\u201d\u7684\u6570\u636e\u70b9\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5bf9\u805a\u7c7b\u8d28\u91cf\u5f71\u54cd\u6700\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u53ef\u4ee5\u8f7b\u677e\u6269\u5c55\u5230\u5e7f\u6cdb\u7684\u805a\u7c7b\u7b97\u6cd5\u6216\u516c\u5e73\u6027\u5ea6\u91cf\u4e2d\uff0c\u4e3a\u89e3\u51b3K-means\u805a\u7c7b\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2505.23165", "pdf": "https://arxiv.org/pdf/2505.23165", "abs": "https://arxiv.org/abs/2505.23165", "authors": ["Le Yang", "Vincent Y. F. Tan", "Wang Chi Cheung"], "title": "Best Arm Identification with Possibly Biased Offline Data", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted to UAI 2025", "summary": "We study the best arm identification (BAI) problem with potentially biased\noffline data in the fixed confidence setting, which commonly arises in\nreal-world scenarios such as clinical trials. We prove an impossibility result\nfor adaptive algorithms without prior knowledge of the bias bound between\nonline and offline distributions. To address this, we propose the LUCB-H\nalgorithm, which introduces adaptive confidence bounds by incorporating an\nauxiliary bias correction to balance offline and online data within the LUCB\nframework. Theoretical analysis shows that LUCB-H matches the sample complexity\nof standard LUCB when offline data is misleading and significantly outperforms\nit when offline data is helpful. We also derive an instance-dependent lower\nbound that matches the upper bound of LUCB-H in certain scenarios. Numerical\nexperiments further demonstrate the robustness and adaptability of LUCB-H in\neffectively incorporating offline data.", "AI": {"tldr": "\u7814\u7a76\u4e86\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bbe\u7f6e\u4e0b\u53ef\u80fd\u5e26\u6709\u504f\u5dee\u7684\u79bb\u7ebf\u6570\u636e\u7684\u6700\u4f73\u81c2\u8bc6\u522b\uff08BAI\uff09\u95ee\u9898\u3002\u63d0\u51faLUCB-H\u7b97\u6cd5\uff0c\u901a\u8fc7\u8f85\u52a9\u504f\u5dee\u6821\u6b63\u9002\u5e94\u6027\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u79bb\u7ebf\u6570\u636e\u8bef\u5bfc\u65f6\u4e0e\u6807\u51c6LUCB\u8868\u73b0\u76f8\u5f53\uff0c\u800c\u5728\u79bb\u7ebf\u6570\u636e\u6709\u76ca\u65f6\u663e\u8457\u4f18\u4e8e\u6807\u51c6LUCB\u3002\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u8868\u660eLUCB-H\u7684\u6709\u6548\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5e38\u89c1\uff0c\u4f8b\u5982\u4e34\u5e8a\u8bd5\u9a8c\uff0c\u4f46\u79bb\u7ebf\u6570\u636e\u53ef\u80fd\u5b58\u5728\u504f\u5dee\uff0c\u5f71\u54cd\u51b3\u7b56\u6548\u679c\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u79bb\u7ebf\u6570\u636e\u5e76\u7ea0\u6b63\u5176\u6f5c\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51faLUCB-H\u7b97\u6cd5\uff0c\u5c06\u8f85\u52a9\u504f\u5dee\u6821\u6b63\u5f15\u5165LUCB\u6846\u67b6\uff0c\u4ee5\u5e73\u8861\u5728\u7ebf\u548c\u79bb\u7ebf\u6570\u636e\u5206\u5e03\uff0c\u5e76\u63a8\u5bfc\u51fa\u81ea\u9002\u5e94\u7f6e\u4fe1\u533a\u95f4\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660eLUCB-H\u5728\u79bb\u7ebf\u6570\u636e\u8bef\u5bfc\u65f6\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u6807\u51c6LUCB\u76f8\u540c\uff0c\u5728\u79bb\u7ebf\u6570\u636e\u6709\u76ca\u65f6\u663e\u8457\u4f18\u4e8e\u6807\u51c6LUCB\u3002\u540c\u65f6\u63a8\u5bfc\u51fa\u5b9e\u4f8b\u4f9d\u8d56\u7684\u4e0b\u754c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0eLUCB-H\u7684\u4e0a\u754c\u5339\u914d\u3002\u6570\u503c\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86LUCB-H\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "LUCB-H\u7b97\u6cd5\u80fd\u591f\u5728\u5b58\u5728\u6f5c\u5728\u504f\u5dee\u7684\u79bb\u7ebf\u6570\u636e\u4e2d\u6709\u6548\u5de5\u4f5c\uff0c\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6700\u4f73\u81c2\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23181", "pdf": "https://arxiv.org/pdf/2505.23181", "abs": "https://arxiv.org/abs/2505.23181", "authors": ["Tian Tian", "Chunyan Miao", "Hangwei Qian"], "title": "FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "KDD 2025", "summary": "Contrastive learning has emerged as a competent approach for unsupervised\nrepresentation learning. However, the design of an optimal augmentation\nstrategy, although crucial for contrastive learning, is less explored for time\nseries classification tasks. Existing predefined time-domain augmentation\nmethods are primarily adopted from vision and are not specific to time series\ndata. Consequently, this cross-modality incompatibility may distort the\nsemantically relevant information of time series by introducing mismatched\npatterns into the data. To address this limitation, we present a novel\nperspective from the frequency domain and identify three advantages for\ndownstream classification: global, independent, and compact. To fully utilize\nthe three properties, we propose the lightweight yet effective Frequency\nRefined Augmentation (FreRA) tailored for time series contrastive learning on\nclassification tasks, which can be seamlessly integrated with contrastive\nlearning frameworks in a plug-and-play manner. Specifically, FreRA\nautomatically separates critical and unimportant frequency components.\nAccordingly, we propose semantic-aware Identity Modification and\nsemantic-agnostic Self-adaptive Modification to protect semantically relevant\ninformation in the critical frequency components and infuse variance into the\nunimportant ones respectively. Theoretically, we prove that FreRA generates\nsemantic-preserving views. Empirically, we conduct extensive experiments on two\nbenchmark datasets, including UCR and UEA archives, as well as five large-scale\ndatasets on diverse applications. FreRA consistently outperforms ten leading\nbaselines on time series classification, anomaly detection, and transfer\nlearning tasks, demonstrating superior capabilities in contrastive\nrepresentation learning and generalization in transfer learning scenarios\nacross diverse datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFrequency Refined Augmentation (FreRA)\u7684\u65b0\u65b9\u6cd5\uff0c\u4e13\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u8bbe\u8ba1\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9891\u7387\u57df\u7684\u589e\u5f3a\u7b56\u7565\u89e3\u51b3\u4e86\u73b0\u6709\u65f6\u95f4\u57df\u589e\u5f3a\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u4e0d\u8db3\uff0c\u80fd\u591f\u4fdd\u62a4\u8bed\u4e49\u76f8\u5173\u4fe1\u606f\u5e76\u5f15\u5165\u591a\u6837\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFreRA\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u4f5c\u4e3a\u4e00\u79cd\u65e0\u76d1\u7763\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5df2\u663e\u793a\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5176\u6700\u4f18\u589e\u5f3a\u7b56\u7565\u8bbe\u8ba1\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7684\u65f6\u95f4\u57df\u589e\u5f3a\u65b9\u6cd5\u591a\u4ece\u89c6\u89c9\u9886\u57df\u501f\u9274\uff0c\u4e0d\u9002\u5408\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bed\u4e49\u4fe1\u606f\u5931\u771f\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9891\u7387\u57df\u7684\u589e\u5f3a\u65b9\u6cd5\u2014\u2014Frequency Refined Augmentation (FreRA)\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u81ea\u52a8\u5206\u79bb\u5173\u952e\u548c\u975e\u5173\u952e\u9891\u7387\u6210\u5206\uff0c\u5e76\u5206\u522b\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684\u8eab\u4efd\u4fee\u6539\uff08Identity Modification\uff09\u548c\u8bed\u4e49\u65e0\u5173\u7684\u81ea\u9002\u5e94\u4fee\u6539\uff08Self-adaptive Modification\uff09\uff0c\u4ee5\u4fdd\u62a4\u5173\u952e\u9891\u7387\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u5e76\u5728\u975e\u5173\u952e\u9891\u7387\u4e2d\u6ce8\u5165\u53d8\u5316\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86FreRA\u751f\u6210\u7684\u89c6\u56fe\u4fdd\u7559\u4e86\u8bed\u4e49\u4fe1\u606f\uff1b\u5b9e\u9a8c\u8bc1\u660e\uff0cFreRA\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5982UCR\u548cUEA\u6863\u6848\uff09\u4ee5\u53ca\u4e94\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0c\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u5341\u4e2a\u9886\u5148\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FreRA\u662f\u4e00\u79cd\u8f7b\u91cf\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u80fd\u529b\u548c\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.23195", "pdf": "https://arxiv.org/pdf/2505.23195", "abs": "https://arxiv.org/abs/2505.23195", "authors": ["Lifan Zhao", "Yanyan Shen", "Zhaoyang Liu", "Xue Wang", "Jiaji Deng"], "title": "Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning", "categories": ["cs.LG", "cs.AI"], "comment": "Manuscript with fixed typos and figures", "summary": "Scaling laws motivate the development of Time Series Foundation Models\n(TSFMs) that pre-train vast parameters and achieve remarkable zero-shot\nforecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot\nconsistently outperform smaller, specialized models trained on full-shot\ndownstream data. A key question is how to realize effective adaptation of TSFMs\nfor a target forecasting task. Through empirical studies on various TSFMs, the\npre-trained models often exhibit inherent sparsity and redundancy in\ncomputation, suggesting that TSFMs have learned to activate task-relevant\nnetwork substructures to accommodate diverse forecasting tasks. To preserve\nthis valuable prior knowledge, we propose a structured pruning method to\nregularize the subsequent fine-tuning process by focusing it on a more relevant\nand compact parameter space. Extensive experiments on seven TSFMs and six\nbenchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly\nimproves forecasting performance compared to fine-tuning original models. This\n\"prune-then-finetune\" paradigm often enables TSFMs to achieve state-of-the-art\nperformance and surpass strong specialized baselines.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u4f18\u5316TSFM\u7684\u5fae\u8c03\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1TSFM\u5728\u96f6\u6837\u672c\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5fae\u8c03\u540e\u4ecd\u65e0\u6cd5\u6301\u7eed\u8d85\u8d8a\u5c0f\u89c4\u6a21\u4e13\u7528\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5982\u4f55\u6709\u6548\u9002\u5e94TSFM\u4ee5\u5b8c\u6210\u76ee\u6807\u9884\u6d4b\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u805a\u7126\u4e8e\u66f4\u76f8\u5173\u548c\u7d27\u51d1\u7684\u53c2\u6570\u7a7a\u95f4\uff0c\u4fdd\u7559\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u526a\u679d\u540e\u7684TSFM\u8fdb\u884c\u5fae\u8c03\uff0c\u76f8\u6bd4\u539f\u59cb\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u8fbe\u5230\u9886\u57df\u5185\u9876\u5c16\u6c34\u5e73\u3002", "conclusion": "\u201c\u526a\u679d-\u518d\u5fae\u8c03\u201d\u8303\u5f0f\u53ef\u4f7fTSFM\u8d85\u8d8a\u4e13\u7528\u6a21\u578b\uff0c\u5b9e\u73b0\u6700\u4f73\u9884\u6d4b\u6548\u679c\u3002"}}
{"id": "2505.22991", "pdf": "https://arxiv.org/pdf/2505.22991", "abs": "https://arxiv.org/abs/2505.22991", "authors": ["Behzad Kamgar-Parsi", "Behrooz Kamgar-Parsi"], "title": "Number of Clusters in a Dataset: A Regularized K-means Approach", "categories": ["cs.LG", "cs.CV", "68", "I.5.3"], "comment": "19 pages, 14 figures. arXiv admin note: substantial text overlap with\n  arXiv:1911.06741", "summary": "Finding the number of meaningful clusters in an unlabeled dataset is\nimportant in many applications. Regularized k-means algorithm is a possible\napproach frequently used to find the correct number of distinct clusters in\ndatasets. The most common formulation of the regularization function is the\nadditive linear term $\\lambda k$, where $k$ is the number of clusters and\n$\\lambda$ a positive coefficient. Currently, there are no principled guidelines\nfor setting a value for the critical hyperparameter $\\lambda$. In this paper,\nwe derive rigorous bounds for $\\lambda$ assuming clusters are {\\em ideal}.\nIdeal clusters (defined as $d$-dimensional spheres with identical radii) are\nclose proxies for k-means clusters ($d$-dimensional spherically symmetric\ndistributions with identical standard deviations). Experiments show that the\nk-means algorithm with additive regularizer often yields multiple solutions.\nThus, we also analyze k-means algorithm with multiplicative regularizer. The\nconsensus among k-means solutions with additive and multiplicative\nregularizations reduces the ambiguity of multiple solutions in certain cases.\nWe also present selected experiments that demonstrate performance of the\nregularized k-means algorithms as clusters deviate from the ideal assumption.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e2d\u5bfb\u627e\u6709\u610f\u4e49\u805a\u7c7b\u6570\u91cf\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7406\u60f3\u805a\u7c7b\u6761\u4ef6\u4e0b\u6b63\u5219\u5316\u53c2\u6570\u03bb\u7684\u4e25\u683c\u754c\u9650\uff0c\u5e76\u5206\u6790\u4e86\u52a0\u6cd5\u548c\u4e58\u6cd5\u6b63\u5219\u5316k-means\u7b97\u6cd5\u7684\u8868\u73b0\u3002", "motivation": "\u786e\u5b9a\u672a\u6807\u8bb0\u6570\u636e\u96c6\u4e2d\u7684\u6709\u610f\u4e49\u805a\u7c7b\u6570\u91cf\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5173\u952e\u8d85\u53c2\u6570\u03bb\u8bbe\u7f6e\u7684\u7cfb\u7edf\u6307\u5bfc\u3002", "method": "\u5047\u8bbe\u805a\u7c7b\u4e3a\u7406\u60f3\uff08d\u7ef4\u7403\u4f53\uff09\uff0c\u63a8\u5bfc\u51fa\u6b63\u5219\u5316\u53c2\u6570\u03bb\u7684\u4e25\u683c\u754c\u9650\uff1b\u5206\u6790\u4e86\u52a0\u6cd5\u548c\u4e58\u6cd5\u6b63\u5219\u5316k-means\u7b97\u6cd5\u7684\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u7406\u60f3\u805a\u7c7b\u6761\u4ef6\u4e0b\u03bb\u7684\u4e25\u683c\u754c\u9650\uff0c\u53d1\u73b0\u52a0\u6cd5\u6b63\u5219\u5316\u53ef\u80fd\u5bfc\u81f4\u591a\u4e2a\u89e3\uff0c\u800c\u7ed3\u5408\u4e58\u6cd5\u6b63\u5219\u5316\u7684\u5171\u8bc6\u53ef\u4ee5\u51cf\u5c11\u67d0\u4e9b\u60c5\u51b5\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7406\u60f3\u805a\u7c7b\u5047\u8bbe\u7684\u03bb\u503c\u8bbe\u5b9a\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u52a0\u6cd5\u548c\u4e58\u6cd5\u6b63\u5219\u5316k-means\u7b97\u6cd5\u5728\u504f\u79bb\u7406\u60f3\u6761\u4ef6\u65f6\u7684\u8868\u73b0\u3002"}}
{"id": "2505.23247", "pdf": "https://arxiv.org/pdf/2505.23247", "abs": "https://arxiv.org/abs/2505.23247", "authors": ["Zonglin Yang", "Zhexuan Gu", "Houduo Qi", "Yancheng Yuan"], "title": "Accelerating RLHF Training with Reward Variance Increase", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) is an essential technique\nfor ensuring that large language models (LLMs) are aligned with human values\nand preferences during the post-training phase. As an effective RLHF approach,\ngroup relative policy optimization (GRPO) has demonstrated success in many\nLLM-based applications. However, efficient GRPO-based RLHF training remains a\nchallenge. Recent studies reveal that a higher reward variance of the initial\npolicy model leads to faster RLHF training. Inspired by this finding, we\npropose a practical reward adjustment model to accelerate RLHF training by\nprovably increasing the reward variance and preserving the relative preferences\nand reward expectation. Our reward adjustment method inherently poses a\nnonconvex optimization problem, which is NP-hard to solve in general. To\novercome the computational challenges, we design a novel $O(n \\log n)$\nalgorithm to find a global solution of the nonconvex reward adjustment model by\nexplicitly characterizing the extreme points of the feasible set. As an\nimportant application, we naturally integrate this reward adjustment model into\nthe GRPO algorithm, leading to a more efficient GRPO with reward variance\nincrease (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we\nprovide an indirect explanation for the empirical effectiveness of GRPO with\nrule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment\nresults demonstrate that the GRPOVI algorithm can significantly improve the\nRLHF training efficiency compared to the original GRPO algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u5956\u52b1\u8c03\u6574\u6a21\u578b\uff0c\u901a\u8fc7\u589e\u52a0\u5956\u52b1\u65b9\u5dee\u52a0\u901fRLHF\u8bad\u7ec3\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230GRPO\u7b97\u6cd5\u4e2d\u5f62\u6210\u66f4\u9ad8\u6548\u7684GRPOVI\u7b97\u6cd5\u3002\u5b9e\u9a8c\u8868\u660eGRPOVI\u663e\u8457\u63d0\u9ad8\u4e86RLHF\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eGRPO\u7684RLHF\u8bad\u7ec3\u5728LLM\u5e94\u7528\u4e2d\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u9ad8\u6548\u8bad\u7ec3\u4ecd\u9762\u4e34\u6311\u6218\u3002\u7814\u7a76\u8868\u660e\uff0c\u521d\u59cb\u7b56\u7565\u6a21\u578b\u7684\u9ad8\u5956\u52b1\u65b9\u5dee\u53ef\u52a0\u901fRLHF\u8bad\u7ec3\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u5956\u52b1\u8c03\u6574\u6a21\u578b\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u975e\u51f8\u4f18\u5316\u95ee\u9898\u7684\u5956\u52b1\u8c03\u6574\u6a21\u578b\uff0c\u901a\u8fc7\u660e\u786e\u523b\u753b\u53ef\u884c\u96c6\u7684\u6781\u503c\u70b9\uff0c\u63d0\u51fa\u4e86\u4e00\u79cdO(n log n)\u7b97\u6cd5\u627e\u5230\u5168\u5c40\u89e3\u3002\u5c06\u6b64\u6a21\u578b\u4e0eGRPO\u7b97\u6cd5\u7ed3\u5408\uff0c\u5f62\u6210\u4e86\u5177\u6709\u5956\u52b1\u65b9\u5dee\u589e\u52a0\u7279\u6027\u7684GRPOVI\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u95f4\u63a5\u89e3\u91ca\u4e86\u89c4\u5219\u5956\u52b1\u5728GRPO\u4e2d\u7684\u7ecf\u9a8c\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGRPOVI\u7b97\u6cd5\u76f8\u8f83\u4e8e\u539f\u59cbGRPO\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86RLHF\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u5956\u52b1\u8c03\u6574\u6a21\u578b\u548cGRPOVI\u7b97\u6cd5\u4e3a\u52a0\u901fRLHF\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2505.22994", "pdf": "https://arxiv.org/pdf/2505.22994", "abs": "https://arxiv.org/abs/2505.22994", "authors": ["Ari S. Benjamin", "Kyle Daruwalla", "Christian Pehle", "Anthony M. Zador"], "title": "Walking the Weight Manifold: a Topological Approach to Conditioning Inspired by Neuromodulation", "categories": ["cs.LG", "cs.NE"], "comment": "17 pages, 4 figures", "summary": "One frequently wishes to learn a range of similar tasks as efficiently as\npossible, re-using knowledge across tasks. In artificial neural networks, this\nis typically accomplished by conditioning a network upon task context by\ninjecting context as input. Brains have a different strategy: the parameters\nthemselves are modulated as a function of various neuromodulators such as\nserotonin. Here, we take inspiration from neuromodulation and propose to learn\nweights which are smoothly parameterized functions of task context variables.\nRather than optimize a weight vector, i.e. a single point in weight space, we\noptimize a smooth manifold in weight space with a predefined topology. To\naccomplish this, we derive a formal treatment of optimization of manifolds as\nthe minimization of a loss functional subject to a constraint on volumetric\nmovement, analogous to gradient descent. During inference, conditioning selects\na single point on this manifold which serves as the effective weight matrix for\na particular sub-task. This strategy for conditioning has two main advantages.\nFirst, the topology of the manifold (whether a line, circle, or torus) is a\nconvenient lever for inductive biases about the relationship between tasks.\nSecond, learning in one state smoothly affects the entire manifold, encouraging\ngeneralization across states. To verify this, we train manifolds with several\ntopologies, including straight lines in weight space (for conditioning on e.g.\nnoise level in input data) and ellipses (for rotated images). Despite their\nsimplicity, these parameterizations outperform conditioning identical networks\nby input concatenation and better generalize to out-of-distribution samples.\nThese results suggest that modulating weights over low-dimensional manifolds\noffers a principled and effective alternative to traditional conditioning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u795e\u7ecf\u8c03\u8282\u542f\u53d1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6743\u91cd\u7a7a\u95f4\u4e2d\u7684\u5e73\u6ed1\u6d41\u5f62\u6765\u5b66\u4e60\u4efb\u52a1\u4e0a\u4e0b\u6587\u53d8\u91cf\u7684\u5e73\u6ed1\u53c2\u6570\u5316\u51fd\u6570\u3002\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u6761\u4ef6\u8f93\u5165\u6cd5\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u63a8\u5e7f\u5230\u5206\u5e03\u5916\u6837\u672c\u3002", "motivation": "\u5728\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u901a\u5e38\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u4f5c\u4e3a\u8f93\u5165\u6ce8\u5165\u6765\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u77e5\u8bc6\u91cd\u7528\u3002\u7136\u800c\uff0c\u5927\u8111\u901a\u8fc7\u795e\u7ecf\u8c03\u8282\u5242\uff08\u5982\u8840\u6e05\u7d20\uff09\u8c03\u5236\u53c2\u6570\u672c\u8eab\u3002\u56e0\u6b64\uff0c\u672c\u6587\u8bd5\u56fe\u4ece\u795e\u7ecf\u8c03\u8282\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5b66\u4e60\u4efb\u52a1\u4e0a\u4e0b\u6587\u53d8\u91cf\u7684\u5e73\u6ed1\u53c2\u6570\u5316\u51fd\u6570\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u6743\u91cd\u7a7a\u95f4\u4e2d\u7684\u5e73\u6ed1\u6d41\u5f62\uff0c\u800c\u4e0d\u662f\u5355\u4e2a\u6743\u91cd\u5411\u91cf\uff0c\u6765\u5b66\u4e60\u4efb\u52a1\u4e0a\u4e0b\u6587\u53d8\u91cf\u7684\u5e73\u6ed1\u53c2\u6570\u5316\u51fd\u6570\u3002\u63a8\u5bfc\u4e86\u6d41\u5f62\u4f18\u5316\u7684\u5f62\u5f0f\u5904\u7406\u65b9\u6cd5\uff0c\u7c7b\u4f3c\u4e8e\u68af\u5ea6\u4e0b\u964d\u3002\u63a8\u7406\u65f6\uff0c\u6761\u4ef6\u9009\u62e9\u6d41\u5f62\u4e0a\u7684\u4e00\u4e2a\u70b9\u4f5c\u4e3a\u7279\u5b9a\u5b50\u4efb\u52a1\u7684\u6709\u6548\u6743\u91cd\u77e9\u9635\u3002", "result": "\u8bad\u7ec3\u4e86\u51e0\u79cd\u62d3\u6251\u7ed3\u6784\u7684\u6d41\u5f62\uff0c\u5305\u62ec\u6743\u91cd\u7a7a\u95f4\u4e2d\u7684\u76f4\u7ebf\uff08\u7528\u4e8e\u8f93\u5165\u6570\u636e\u566a\u58f0\u6c34\u5e73\u7684\u6761\u4ef6\uff09\u548c\u692d\u5706\uff08\u7528\u4e8e\u65cb\u8f6c\u56fe\u50cf\uff09\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u53c2\u6570\u5316\u7b80\u5355\uff0c\u4f46\u5b83\u4eec\u7684\u8868\u73b0\u4f18\u4e8e\u901a\u8fc7\u8f93\u5165\u8fde\u63a5\u5bf9\u76f8\u540c\u7f51\u7edc\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u5e76\u4e14\u80fd\u591f\u66f4\u597d\u5730\u63a8\u5e7f\u5230\u5206\u5e03\u5916\u6837\u672c\u3002", "conclusion": "\u8c03\u5236\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u7684\u6743\u91cd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u4e14\u6709\u6548\u7684\u4f20\u7edf\u6761\u4ef6\u5316\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2505.23270", "pdf": "https://arxiv.org/pdf/2505.23270", "abs": "https://arxiv.org/abs/2505.23270", "authors": ["Haokun Chen", "Yueqi Zhang", "Yuan Bi", "Yao Zhang", "Tong Liu", "Jinhe Bi", "Jian Lan", "Jindong Gu", "Claudia Grosser", "Denis Krompass", "Nassir Navab", "Volker Tresp"], "title": "Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In recent years, Large Language Models (LLMs) have achieved remarkable\nadvancements, drawing significant attention from the research community. Their\ncapabilities are largely attributed to large-scale architectures, which require\nextensive training on massive datasets. However, such datasets often contain\nsensitive or copyrighted content sourced from the public internet, raising\nconcerns about data privacy and ownership. Regulatory frameworks, such as the\nGeneral Data Protection Regulation (GDPR), grant individuals the right to\nrequest the removal of such sensitive information. This has motivated the\ndevelopment of machine unlearning algorithms that aim to remove specific\nknowledge from models without the need for costly retraining. Despite these\nadvancements, evaluating the efficacy of unlearning algorithms remains a\nchallenge due to the inherent complexity and generative nature of LLMs. In this\nwork, we introduce a comprehensive auditing framework for unlearning\nevaluation, comprising three benchmark datasets, six unlearning algorithms, and\nfive prompt-based auditing methods. By using various auditing algorithms, we\nevaluate the effectiveness and robustness of different unlearning strategies.\nTo explore alternatives beyond prompt-based auditing, we propose a novel\ntechnique that leverages intermediate activation perturbations, addressing the\nlimitations of auditing methods that rely solely on model inputs and outputs.", "AI": {"tldr": "\u8fd1\u5e74\u6765\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5176\u80fd\u529b\u4e3b\u8981\u5f52\u529f\u4e8e\u5927\u89c4\u6a21\u67b6\u6784\u548c\u5728\u6d77\u91cf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u53ef\u80fd\u5305\u542b\u654f\u611f\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u5185\u5bb9\uff0c\u5f15\u53d1\u4e86\u9690\u79c1\u548c\u6240\u6709\u6743\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\uff0c\u4ee5\u4ece\u6a21\u578b\u4e2d\u79fb\u9664\u7279\u5b9a\u77e5\u8bc6\u800c\u65e0\u9700\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u7b97\u6cd5\u7684\u6709\u6548\u6027\u4ecd\u5177\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u9762\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3001\u516d\u79cd\u9057\u5fd8\u7b97\u6cd5\u548c\u4e94\u79cd\u57fa\u4e8e\u63d0\u793a\u7684\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5404\u79cd\u5ba1\u8ba1\u7b97\u6cd5\u8bc4\u4f30\u4e0d\u540c\u9057\u5fd8\u7b56\u7565\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\u7684\u65b0\u6280\u672f\uff0c\u4ee5\u514b\u670d\u4ec5\u4f9d\u8d56\u6a21\u578b\u8f93\u5165\u548c\u8f93\u51fa\u7684\u5ba1\u8ba1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6240\u7528\u7684\u6570\u636e\u96c6\u4e2d\u53ef\u80fd\u5b58\u5728\u654f\u611f\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u5185\u5bb9\uff0c\u8fd9\u5f15\u53d1\u4e86\u6570\u636e\u9690\u79c1\u548c\u6240\u6709\u6743\u95ee\u9898\u3002\u540c\u65f6\uff0c\u73b0\u6709\u6cd5\u89c4\u5982GDPR\u8981\u6c42\u53ef\u4ee5\u5220\u9664\u7279\u5b9a\u654f\u611f\u4fe1\u606f\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u6709\u6548\u7684\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u4e00\u4e2a\u7efc\u5408\u5ba1\u8ba1\u6846\u67b6\uff0c\u6db5\u76d6\u4e09\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u3001\u516d\u79cd\u9057\u5fd8\u7b97\u6cd5\u548c\u4e94\u79cd\u57fa\u4e8e\u63d0\u793a\u7684\u5ba1\u8ba1\u65b9\u6cd5\u3002\n2. \u4f7f\u7528\u591a\u79cd\u5ba1\u8ba1\u7b97\u6cd5\u8bc4\u4f30\u4e0d\u540c\u9057\u5fd8\u7b56\u7565\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002\n3. \u63d0\u51fa\u4e00\u79cd\u65b0\u6280\u672f\uff0c\u5229\u7528\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\u8fdb\u884c\u5ba1\u8ba1\uff0c\u4ee5\u5f25\u8865\u4f20\u7edf\u57fa\u4e8e\u8f93\u5165\u548c\u8f93\u51fa\u5ba1\u8ba1\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "result": "\u8be5\u5ba1\u8ba1\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u4e0d\u540c\u9057\u5fd8\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u5ba1\u8ba1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u63d0\u51fa\u7684\u65b0\u6280\u672f\u901a\u8fc7\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\uff0c\u4e3a\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u9057\u5fd8\u6548\u679c\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5ba1\u8ba1\u6846\u67b6\u4e3a\u8bc4\u4f30\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u7814\u7a76\u6539\u8fdb\u9057\u5fd8\u6280\u672f\u3002\u540c\u65f6\uff0c\u65b0\u63d0\u51fa\u7684\u57fa\u4e8e\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\u7684\u6280\u672f\u5c55\u793a\u4e86\u8d85\u8d8a\u4f20\u7edf\u8f93\u5165\u8f93\u51fa\u5ba1\u8ba1\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.22998", "pdf": "https://arxiv.org/pdf/2505.22998", "abs": "https://arxiv.org/abs/2505.22998", "authors": ["Jihwan Oh", "Murad Aghazada", "Se-Young Yun", "Taehyeon Kim"], "title": "LLM Agents for Bargaining with Utility-based Feedback", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Bargaining, a critical aspect of real-world interactions, presents challenges\nfor large language models (LLMs) due to limitations in strategic depth and\nadaptation to complex human factors. Existing benchmarks often fail to capture\nthis real-world complexity. To address this and enhance LLM capabilities in\nrealistic bargaining, we introduce a comprehensive framework centered on\nutility-based feedback. Our contributions are threefold: (1) BargainArena, a\nnovel benchmark dataset with six intricate scenarios (e.g., deceptive\npractices, monopolies) to facilitate diverse strategy modeling; (2)\nhuman-aligned, economically-grounded evaluation metrics inspired by utility\ntheory, incorporating agent utility and negotiation power, which implicitly\nreflect and promote opponent-aware reasoning (OAR); and (3) a structured\nfeedback mechanism enabling LLMs to iteratively refine their bargaining\nstrategies. This mechanism can positively collaborate with in-context learning\n(ICL) prompts, including those explicitly designed to foster OAR. Experimental\nresults show that LLMs often exhibit negotiation strategies misaligned with\nhuman preferences, and that our structured feedback mechanism significantly\nimproves their performance, yielding deeper strategic and opponent-aware\nreasoning.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8c08\u5224\u65b9\u9762\u5b58\u5728\u6218\u7565\u6df1\u5ea6\u4e0d\u8db3\u548c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u4eba\u7c7b\u56e0\u7d20\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6548\u7528\u53cd\u9988\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u8d21\u732e\uff1aBargainArena\u6570\u636e\u96c6\u3001\u4e0e\u4eba\u7c7b\u4e00\u81f4\u4e14\u57fa\u4e8e\u7ecf\u6d4e\u7406\u8bba\u7684\u8bc4\u4f30\u6307\u6807\u4ee5\u53ca\u7ed3\u6784\u5316\u53cd\u9988\u673a\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLMs\u7684\u8c08\u5224\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u5230\u73b0\u5b9e\u4e16\u754c\u4e2d\u8c08\u5224\u7684\u590d\u6742\u6027\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6d89\u53ca\u6218\u7565\u6df1\u5ea6\u548c\u590d\u6742\u4eba\u7c7b\u56e0\u7d20\u7684\u8c08\u5224\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "1. \u521b\u5efa\u4e86BargainArena\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u516d\u4e2a\u590d\u6742\u7684\u573a\u666f\u4ee5\u652f\u6301\u591a\u6837\u5316\u7684\u7b56\u7565\u5efa\u6a21\uff1b2. \u63d0\u51fa\u4e86\u4e0e\u4eba\u7c7b\u4e00\u81f4\u3001\u57fa\u4e8e\u7ecf\u6d4e\u7406\u8bba\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u8003\u8651\u4ee3\u7406\u6548\u7528\u548c\u8c08\u5224\u80fd\u529b\uff1b3. \u5f00\u53d1\u4e86\u7ed3\u6784\u5316\u53cd\u9988\u673a\u5236\uff0c\u5141\u8bb8LLMs\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u5176\u8c08\u5224\u7b56\u7565\uff0c\u5e76\u80fd\u4e0e\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u793a\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLMs\u901a\u5e38\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u4e0d\u4e00\u81f4\u7684\u8c08\u5224\u7b56\u7565\u3002\u7136\u800c\uff0c\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u53cd\u9988\u673a\u5236\u540e\uff0cLLMs\u7684\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u5c55\u73b0\u51fa\u66f4\u6df1\u5c42\u6b21\u7684\u6218\u7565\u6027\u548c\u5bf9\u624b\u610f\u8bc6\u63a8\u7406\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u589e\u5f3aLLMs\u5728\u771f\u5b9e\u8c08\u5224\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6218\u7565\u6df1\u5ea6\u548c\u5bf9\u624b\u610f\u8bc6\u65b9\u9762\u3002"}}
{"id": "2505.23309", "pdf": "https://arxiv.org/pdf/2505.23309", "abs": "https://arxiv.org/abs/2505.23309", "authors": ["Yixin Ren", "Chenghou Jin", "Yewei Xia", "Li Ke", "Longtao Huang", "Hui Xue", "Hao Zhang", "Jihong Guan", "Shuigeng Zhou"], "title": "Score-based Generative Modeling for Conditional Independence Testing", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD2025", "summary": "Determining conditional independence (CI) relationships between random\nvariables is a fundamental yet challenging task in machine learning and\nstatistics, especially in high-dimensional settings. Existing generative\nmodel-based CI testing methods, such as those utilizing generative adversarial\nnetworks (GANs), often struggle with undesirable modeling of conditional\ndistributions and training instability, resulting in subpar performance. To\naddress these issues, we propose a novel CI testing method via score-based\ngenerative modeling, which achieves precise Type I error control and strong\ntesting power. Concretely, we first employ a sliced conditional score matching\nscheme to accurately estimate conditional score and use Langevin dynamics\nconditional sampling to generate null hypothesis samples, ensuring precise Type\nI error control. Then, we incorporate a goodness-of-fit stage into the method\nto verify generated samples and enhance interpretability in practice. We\ntheoretically establish the error bound of conditional distributions modeled by\nscore-based generative models and prove the validity of our CI tests. Extensive\nexperiments on both synthetic and real-world datasets show that our method\nsignificantly outperforms existing state-of-the-art methods, providing a\npromising way to revitalize generative model-based CI testing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc4\u5206\u7684\u751f\u6210\u5efa\u6a21\u7684\u65b0CI\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709GAN\u65b9\u6cd5\u4e2d\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u786e\u5b9a\u968f\u673a\u53d8\u91cf\u4e4b\u95f4\u7684\u6761\u4ef6\u72ec\u7acb\uff08CI\uff09\u5173\u7cfb\u662f\u4e00\u9879\u57fa\u672c\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684CI\u6d4b\u8bd5\u65b9\u6cd5\uff08\u5982\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GANs\uff09\u7684\u65b9\u6cd5\uff09\u5e38\u5e38\u7531\u4e8e\u6761\u4ef6\u5206\u5e03\u7684\u4e0d\u826f\u5efa\u6a21\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u800c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u9996\u5148\u91c7\u7528\u5207\u7247\u6761\u4ef6\u5f97\u5206\u5339\u914d\u65b9\u6848\u6765\u7cbe\u786e\u4f30\u8ba1\u6761\u4ef6\u5f97\u5206\uff0c\u5e76\u4f7f\u7528\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u6761\u4ef6\u91c7\u6837\u751f\u6210\u96f6\u5047\u8bbe\u6837\u672c\uff0c\u4ee5\u786e\u4fdd\u7cbe\u786e\u7684I\u578b\u8bef\u5dee\u63a7\u5236\u3002\u7136\u540e\u5c06\u4e00\u4e2a\u62df\u5408\u4f18\u5ea6\u9636\u6bb5\u7eb3\u5165\u8be5\u65b9\u6cd5\uff0c\u4ee5\u9a8c\u8bc1\u751f\u6210\u7684\u6837\u672c\u5e76\u589e\u5f3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u3002\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u7531\u8bc4\u5206\u751f\u6210\u6a21\u578b\u5efa\u6a21\u7684\u6761\u4ef6\u5206\u5e03\u7684\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u4e86\u6211\u4eec\u7684CI\u68c0\u9a8c\u7684\u6709\u6548\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u5e0c\u671b\u7684\u65b9\u5f0f\u6765\u91cd\u65b0\u6fc0\u53d1\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684CI\u6d4b\u8bd5\u3002"}}
{"id": "2505.23337", "pdf": "https://arxiv.org/pdf/2505.23337", "abs": "https://arxiv.org/abs/2505.23337", "authors": ["Chetan Verma", "Aditya Srinivas Timmaraju", "Cho Jui-Hsieh", "Suyash Damle", "Ngot Bui", "Yang Zhang", "Wen Chen", "Xin Liu", "Prateek Jain", "Inderjit S Dhillon"], "title": "Matryoshka Model Learning for Improved Elastic Student Models", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, Accepted at KDD 2025", "summary": "Industry-grade ML models are carefully designed to meet rapidly evolving\nserving constraints, which requires significant resources for model\ndevelopment. In this paper, we propose MatTA, a framework for training multiple\naccurate Student models using a novel Teacher-TA-Student recipe. TA models are\nlarger versions of the Student models with higher capacity, and thus allow\nStudent models to better relate to the Teacher model and also bring in more\ndomain-specific expertise. Furthermore, multiple accurate Student models can be\nextracted from the TA model. Therefore, despite only one training run, our\nmethodology provides multiple servable options to trade off accuracy for lower\nserving cost. We demonstrate the proposed method, MatTA, on proprietary\ndatasets and models. Its practical efficacy is underscored by live A/B tests\nwithin a production ML system, demonstrating 20% improvement on a key metric.\nWe also demonstrate our method on GPT-2 Medium, a public model, and achieve\nrelative improvements of over 24% on SAT Math and over 10% on the LAMBADA\nbenchmark.", "AI": {"tldr": "\u63d0\u51faMatTA\u6846\u67b6\uff0c\u901a\u8fc7Teacher-TA-Student\u65b9\u6cd5\u8bad\u7ec3\u591a\u4e2a\u7cbe\u786e\u7684\u5b66\u751f\u6a21\u578b\u3002TA\u6a21\u578b\u662f\u5b66\u751f\u6a21\u578b\u7684\u653e\u5927\u7248\uff0c\u80fd\u5f15\u5165\u66f4\u591a\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u6b64\u65b9\u6cd5\u53ea\u9700\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u63d0\u4f9b\u591a\u79cd\u53ef\u90e8\u7f72\u9009\u9879\uff0c\u5728\u4e13\u6709\u6570\u636e\u96c6\u548cGPT-2 Medium\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u884c\u4e1a\u7ea7ML\u6a21\u578b\u9700\u8981\u6ee1\u8db3\u5feb\u901f\u6f14\u8fdb\u7684\u670d\u52a1\u7ea6\u675f\uff0c\u8fd9\u8981\u6c42\u5927\u91cf\u7684\u8d44\u6e90\u8fdb\u884c\u6a21\u578b\u5f00\u53d1\u3002\u4e3a\u4e86\u964d\u4f4e\u8d44\u6e90\u9700\u6c42\u5e76\u63d0\u4f9b\u7075\u6d3b\u7684\u6a21\u578b\u9009\u62e9\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86MatTA\u6846\u67b6\u3002", "method": "MatTA\u6846\u67b6\u5229\u7528Teacher-TA-Student\u7684\u65b9\u6cd5\uff0c\u5176\u4e2dTA\u6a21\u578b\u662f\u5b66\u751f\u6a21\u578b\u7684\u653e\u5927\u7248\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u5bb9\u91cf\uff0c\u4f7f\u5b66\u751f\u6a21\u578b\u80fd\u66f4\u597d\u5730\u4e0e\u6559\u5e08\u6a21\u578b\u76f8\u5173\u8054\uff0c\u5e76\u5f15\u5165\u66f4\u591a\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u901a\u8fc7\u4e00\u6b21\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4eceTA\u6a21\u578b\u4e2d\u63d0\u53d6\u591a\u4e2a\u7cbe\u786e\u7684\u5b66\u751f\u6a21\u578b\u3002", "result": "\u5728\u4e13\u6709\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5c55\u793a\u4e86MatTA\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u751f\u4ea7ML\u7cfb\u7edf\u4e2d\u7684\u6d3b\u4f53A/B\u6d4b\u8bd5\uff0c\u5173\u952e\u6307\u6807\u63d0\u9ad8\u4e8620%\u3002\u5728\u516c\u5171\u6a21\u578bGPT-2 Medium\u4e0a\uff0cSAT Math\u76f8\u5bf9\u6539\u8fdb\u8d85\u8fc724%\uff0cLAMBADA\u57fa\u51c6\u76f8\u5bf9\u6539\u8fdb\u8d85\u8fc710%\u3002", "conclusion": "MatTA\u6846\u67b6\u901a\u8fc7\u4e00\u6b21\u8bad\u7ec3\u63d0\u4f9b\u4e86\u591a\u79cd\u53ef\u90e8\u7f72\u9009\u9879\uff0c\u80fd\u591f\u5e73\u8861\u7cbe\u5ea6\u548c\u670d\u52a1\u6210\u672c\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.23004", "pdf": "https://arxiv.org/pdf/2505.23004", "abs": "https://arxiv.org/abs/2505.23004", "authors": ["Kyle R. Chickering", "Bangzheng Li", "Muhao Chen"], "title": "QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining", "categories": ["cs.LG"], "comment": "22 pages, 19 figures", "summary": "Multimodal Large Language Models (MLLMs) encode images into visual tokens,\naligning visual and textual signals within a shared latent space to facilitate\ncrossmodal representation learning. The CLIP model is a widely adopted\nfoundational vision language model whose vision encoder has played a critical\nrole in the development of MLLMs such as LLaVA. However, the CLIP vision\nencoder suffers from notable limitations including being constrained to only\nhandling fixed input resolutions and a failure to produce separated embeddings\nfor dissimilar images. Replacing the vision encoder of an existing model\ntypically incurs substantial computational costs because such a change often\nnecessitates retraining the entire model pipeline.\n  In this work, we identify two factors which underlie the limitations of the\nCLIP vision encoder: mesoscopic bias and interpolation bias. To address these\nissues, we propose QLIP, a drop-in replacement for CLIP that can be seamlessly\nintegrated with existing MLLMs with only a few lines of code and can enhance\nboth coarse-grained and fine-grained visual understanding, without re-training.\nQLIP is designed around an image quadtree which replaces the standard uniform\ngrid patches with a novel content aware patchification. Our experimental\nresults demonstrate that QLIP improves the general visual question answering\naccuracy of the LLaVA v1.5 model series across various model sizes--without\nrequiring retraining or fine-tuning of the full MLLM. Notably, QLIP boosts\ndetailed understanding performance on the challenging $V^{\\ast}$ benchmark by\nup to 13.6 percent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQLIP\u7684\u65b0\u578b\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u53ef\u4ee5\u66ff\u4ee3CLIP\u5e76\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u6027\u80fd\u3002QLIP\u901a\u8fc7\u89e3\u51b3CLIP\u7684\u5c40\u9650\u6027\uff08\u5982\u4e2d\u89c2\u504f\u5dee\u548c\u63d2\u503c\u504f\u5dee\uff09\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u4e86LLaVA v1.5\u7cfb\u5217\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5728\u6311\u6218\u6027\u7684$V^{\\ast}$\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e8613.6%\u7684\u8be6\u7ec6\u7406\u89e3\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684CLIP\u89c6\u89c9\u7f16\u7801\u5668\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u53ea\u80fd\u5904\u7406\u56fa\u5b9a\u8f93\u5165\u5206\u8fa8\u7387\u4ee5\u53ca\u65e0\u6cd5\u4e3a\u4e0d\u540c\u56fe\u50cf\u751f\u6210\u5206\u79bb\u7684\u5d4c\u5165\u3002\u6b64\u5916\uff0c\u66ff\u6362\u73b0\u6709\u6a21\u578b\u7684\u89c6\u89c9\u7f16\u7801\u5668\u901a\u5e38\u9700\u8981\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u56e0\u4e3a\u8fd9\u901a\u5e38\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\u7ba1\u9053\u3002", "method": "\u4f5c\u8005\u8bc6\u522b\u51faCLIP\u89c6\u89c9\u7f16\u7801\u5668\u7684\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u4e2d\u89c2\u504f\u5dee\u548c\u63d2\u503c\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86QLIP\u4f5c\u4e3aCLIP\u7684\u76f4\u63a5\u66ff\u4ee3\u65b9\u6848\u3002QLIP\u57fa\u4e8e\u56fe\u50cf\u56db\u53c9\u6811\u8bbe\u8ba1\uff0c\u7528\u65b0\u9896\u7684\u5185\u5bb9\u611f\u77e5\u8865\u4e01\u5316\u65b9\u6cd5\u53d6\u4ee3\u4e86\u6807\u51c6\u7684\u5747\u5300\u7f51\u683c\u8865\u4e01\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002QLIP\u53ef\u4ee5\u901a\u8fc7\u51e0\u884c\u4ee3\u7801\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684MLLMs\u4e2d\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\u6574\u4e2a\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cQLIP\u63d0\u5347\u4e86LLaVA v1.5\u6a21\u578b\u7cfb\u5217\u5728\u5404\u79cd\u6a21\u578b\u5927\u5c0f\u4e0b\u7684\u901a\u7528\u89c6\u89c9\u95ee\u7b54\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u56f0\u96be\u7684$V^{\\ast}$\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQLIP\u5c06\u8be6\u7ec6\u7406\u89e3\u6027\u80fd\u63d0\u9ad8\u4e86\u9ad8\u8fbe13.6%\u3002", "conclusion": "QLIP\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684CLIP\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8MLLMs\u7684\u89c6\u89c9\u7406\u89e3\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u7ec6\u7c92\u5ea6\u7406\u89e3\u548c\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u8fd9\u4e00\u6539\u8fdb\u4e3a\u672a\u6765\u591a\u6a21\u6001\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23349", "pdf": "https://arxiv.org/pdf/2505.23349", "abs": "https://arxiv.org/abs/2505.23349", "authors": ["Sheng Ouyang", "Yulan Hu", "Ge Chen", "Qingyang Li", "Fuzheng Zhang", "Yong Liu"], "title": "Towards Reward Fairness in RLHF: From a Resource Allocation Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL 2025", "summary": "Rewards serve as proxies for human preferences and play a crucial role in\nReinforcement Learning from Human Feedback (RLHF). However, if these rewards\nare inherently imperfect, exhibiting various biases, they can adversely affect\nthe alignment of large language models (LLMs). In this paper, we collectively\ndefine the various biases present in rewards as the problem of reward\nunfairness. We propose a bias-agnostic method to address the issue of reward\nfairness from a resource allocation perspective, without specifically designing\nfor each type of bias, yet effectively mitigating them. Specifically, we model\npreference learning as a resource allocation problem, treating rewards as\nresources to be allocated while considering the trade-off between utility and\nfairness in their distribution. We propose two methods, Fairness Regularization\nand Fairness Coefficient, to achieve fairness in rewards. We apply our methods\nin both verification and reinforcement learning scenarios to obtain a fairness\nreward model and a policy model, respectively. Experiments conducted in these\nscenarios demonstrate that our approach aligns LLMs with human preferences in a\nmore fair manner.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u5956\u52b1\u516c\u5e73\u6027\u7684\u504f\u5dee\u65e0\u5173\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d44\u6e90\u5206\u914d\u89c6\u89d2\u5efa\u6a21\u504f\u597d\u5b66\u4e60\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9e\u73b0\u5956\u52b1\u516c\u5e73\u6027\u7684\u65b9\u6cd5\uff1aFairness Regularization \u548c Fairness Coefficient\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u66f4\u516c\u5e73\u5730\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u3002", "motivation": "\u5728\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u4e2d\uff0c\u5956\u52b1\u4f5c\u4e3a\u4eba\u7c7b\u504f\u597d\u7684\u4ee3\u7406\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u82e5\u5956\u52b1\u5b58\u5728\u5404\u79cd\u504f\u5dee\uff0c\u53ef\u80fd\u4f1a\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5bf9\u9f50\u4ea7\u751f\u4e0d\u5229\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5956\u52b1\u4e2d\u7684\u4e0d\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5c06\u504f\u597d\u5b66\u4e60\u5efa\u6a21\u4e3a\u4e00\u4e2a\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u628a\u5956\u52b1\u89c6\u4e3a\u9700\u8981\u5206\u914d\u7684\u8d44\u6e90\uff0c\u540c\u65f6\u8003\u8651\u6548\u7528\u548c\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1aFairness Regularization \u548c Fairness Coefficient \u6765\u5b9e\u73b0\u5956\u52b1\u516c\u5e73\u6027\uff0c\u5e76\u5206\u522b\u5728\u9a8c\u8bc1\u548c\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u4e2d\u5e94\u7528\u4ee5\u83b7\u5f97\u516c\u5e73\u5956\u52b1\u6a21\u578b\u548c\u7b56\u7565\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u9a8c\u8bc1\u548c\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u66f4\u516c\u5e73\u5730\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002", "conclusion": "\u89e3\u51b3\u5956\u52b1\u4e0d\u516c\u5e73\u6027\u7684\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u8d44\u6e90\u5206\u914d\u7684\u89c6\u89d2\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u504f\u5dee\u65e0\u5173\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u5956\u52b1\u4e2d\u7684\u5404\u79cd\u504f\u5dee\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002"}}
{"id": "2505.23009", "pdf": "https://arxiv.org/pdf/2505.23009", "abs": "https://arxiv.org/abs/2505.23009", "authors": ["Ruskin Raj Manku", "Yuzhi Tang", "Xingjian Shi", "Mu Li", "Alex Smola"], "title": "EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic, Expressiveness, and Linguistic Challenges Using Model-as-a-Judge", "categories": ["cs.LG", "eess.AS"], "comment": null, "summary": "Text-to-Speech (TTS) benchmarks often fail to capture how well models handle\nnuanced and semantically complex text. Building on $\\textit{EmergentTTS}$, we\nintroduce $\\textit{EmergentTTS-Eval}$, a comprehensive benchmark covering six\nchallenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic\ncomplexity, complex pronunciation (e.g. URLs, formulas), and questions.\nCrucially, our framework automates both test-case generation and evaluation,\nmaking the benchmark easily extensible. Starting from a small set of\nhuman-written seed prompts, we iteratively extend them using LLMs to target\nspecific structural, phonetic and prosodic challenges, resulting in 1,645\ndiverse test cases. Moreover, we employ a model-as-a-judge approach, using a\nLarge Audio Language Model (LALM) to assess the speech across multiple\ndimensions such as expressed emotion, prosodic, intonational, and pronunciation\naccuracy. We evaluate state-of-the-art open-source and proprietary TTS systems,\nsuch as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval,\ndemonstrating its ability to reveal fine-grained performance differences.\nResults show that the model-as-a-judge approach offers robust TTS assessment\nand a high correlation with human preferences. We open source the evaluation\n$\\href{https://github.com/boson-ai/EmergentTTS-Eval-public}{code}$ and the\n$\\href{https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{dataset}$.", "AI": {"tldr": "\u63d0\u51faEmergentTTS-Eval\uff0c\u4e00\u4e2a\u6db5\u76d6\u516d\u79cd\u590d\u6742TTS\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5177\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e0e\u8bc4\u4f30\u529f\u80fd\uff0c\u901a\u8fc7\u6a21\u578b\u8bc4\u5ba1\u65b9\u6cd5\u5bf9\u591a\u4e2a\u5f00\u6e90\u548c\u4e13\u6709TTS\u7cfb\u7edf\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5c55\u73b0\u5176\u63ed\u793a\u7ec6\u5fae\u6027\u80fd\u5dee\u5f02\u7684\u80fd\u529b\uff0c\u5e76\u5f00\u6e90\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524dTTS\u57fa\u51c6\u6d4b\u8bd5\u5e38\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u6a21\u578b\u5904\u7406\u7ec6\u817b\u4e14\u8bed\u4e49\u590d\u6742\u6587\u672c\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u57fa\u4e8eEmergentTTS\u6784\u5efaEmergentTTS-Eval\uff0c\u8986\u76d6\u516d\u79cd\u6311\u6218\u6027TTS\u573a\u666f\uff1b\u6846\u67b6\u81ea\u52a8\u5b8c\u6210\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e0e\u8bc4\u4f30\uff1b\u4f7f\u7528\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5ba1\u5de5\u5177\uff0c\u4ece\u591a\u7ef4\u5ea6\u8bc4\u4f30\u8bed\u97f3\u8d28\u91cf\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u63ed\u793a\u4e0d\u540cTTS\u7cfb\u7edf\u4e4b\u95f4\u7684\u7ec6\u5fae\u6027\u80fd\u5dee\u5f02\uff0c\u6a21\u578b\u8bc4\u5ba1\u65b9\u6cd5\u4e0e\u4eba\u7c7b\u504f\u597d\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "EmergentTTS-Eval\u4e3aTTS\u7cfb\u7edf\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u5e76\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2505.23369", "pdf": "https://arxiv.org/pdf/2505.23369", "abs": "https://arxiv.org/abs/2505.23369", "authors": ["Mannmohan Muthuraman"], "title": "Dynamic Spectral Backpropagation for Efficient Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dynamic Spectral Backpropagation (DSBP) enhances neural network training\nunder resource constraints by projecting gradients onto principal eigenvectors,\nreducing complexity and promoting flat minima. Five extensions are proposed,\ndynamic spectral inference, spectral architecture optimization, spectral meta\nlearning, spectral transfer regularization, and Lie algebra inspired dynamics,\nto address challenges in robustness, fewshot learning, and hardware efficiency.\nSupported by a third order stochastic differential equation (SDE) and a PAC\nBayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank\nAdaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion\nMNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive\nexperiments and visualizations. Future work focuses on scalability, bias\nmitigation, and ethical considerations.", "AI": {"tldr": "Dynamic Spectral Backpropagation (DSBP)\u901a\u8fc7\u5c06\u68af\u5ea6\u6295\u5f71\u5230\u4e3b\u7279\u5f81\u5411\u91cf\u4e0a\uff0c\u5728\u8d44\u6e90\u9650\u5236\u4e0b\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u63d0\u51fa\u4e94\u4e2a\u6269\u5c55\u65b9\u5411\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aSAM\u3001LoRA\u548cMAML\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u89e3\u51b3\u9c81\u68d2\u6027\u3001\u5c0f\u6837\u672c\u5b66\u4e60\u548c\u786c\u4ef6\u6548\u7387\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u8c31\u63a8\u7406\u3001\u8c31\u7ed3\u6784\u4f18\u5316\u3001\u8c31\u5143\u5b66\u4e60\u3001\u8c31\u8fc1\u79fb\u6b63\u5219\u5316\u548c\u674e\u4ee3\u6570\u542f\u53d1\u7684\u52a8\u529b\u5b66\u7b49\u4e94\u4e2a\u6269\u5c55\u65b9\u5411\uff0c\u7ed3\u5408\u4e09\u9636\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08SDE\uff09\u548cPAC\u8d1d\u53f6\u65af\u6781\u9650\u652f\u6301\u65b9\u6cd5\u3002", "result": "DSBP\u5728CIFAR 10\u3001Fashion MNIST\u3001MedMNIST\u548cTiny ImageNet\u7b49\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8eSharpness Aware Minimization (SAM)\u3001Low Rank Adaptation (LoRA)\u548cModel Agnostic Meta Learning (MAML)\u3002", "conclusion": "DSBP\u53ca\u5176\u6269\u5c55\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\uff0c\u672a\u6765\u5c06\u8fdb\u4e00\u6b65\u7814\u7a76\u53ef\u6269\u5c55\u6027\u3001\u504f\u5dee\u7f13\u89e3\u548c\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2505.23013", "pdf": "https://arxiv.org/pdf/2505.23013", "abs": "https://arxiv.org/abs/2505.23013", "authors": ["Liangkai Hang", "Junjie Yao", "Zhiwei Bai", "Tianyi Chen", "Yang Chen", "Rongjie Diao", "Hezhou Li", "Pengxiao Lin", "Zhiwei Wang", "Cheng Xu", "Zhongwang Zhang", "Zhangchen Zhou", "Zhiyu Li", "Zehao Lin", "Kai Chen", "Feiyu Xiong", "Yaoyu Zhang", "Weinan E", "Hongkang Yang", "Zhi-Qin John Xu"], "title": "Scalable Complexity Control Facilitates Reasoning Ability of LLMs", "categories": ["cs.LG"], "comment": null, "summary": "The reasoning ability of large language models (LLMs) has been rapidly\nadvancing in recent years, attracting interest in more fundamental approaches\nthat can reliably enhance their generalizability. This work demonstrates that\nmodel complexity control, conveniently implementable by adjusting the\ninitialization rate and weight decay coefficient, improves the scaling law of\nLLMs consistently over varying model sizes and data sizes. This gain is further\nillustrated by comparing the benchmark performance of 2.4B models pretrained on\n1T tokens with different complexity hyperparameters. Instead of fixing the\ninitialization std, we found that a constant initialization rate (the exponent\nof std) enables the scaling law to descend faster in both model and data sizes.\nThese results indicate that complexity control is a promising direction for the\ncontinual advancement of LLMs.", "AI": {"tldr": "\u901a\u8fc7\u8c03\u6574\u521d\u59cb\u5316\u901f\u7387\u548c\u6743\u91cd\u8870\u51cf\u7cfb\u6570\u6765\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u53ef\u4ee5\u6539\u8fdbLLM\u7684\u6269\u5c55\u89c4\u5f8b\u3002\u6052\u5b9a\u7684\u521d\u59cb\u5316\u901f\u7387\uff08std\u7684\u6307\u6570\uff09\u80fd\u4f7f\u6269\u5c55\u89c4\u5f8b\u5728\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u5927\u5c0f\u4e0a\u66f4\u5feb\u4e0b\u964d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fd1\u5e74\u6765\u63a8\u7406\u80fd\u529b\u8fc5\u901f\u63d0\u5347\uff0c\u5f15\u8d77\u5bf9\u53ef\u9760\u589e\u5f3a\u5176\u6cdb\u5316\u80fd\u529b\u7684\u57fa\u672c\u65b9\u6cd5\u7684\u5174\u8da3\u3002", "method": "\u901a\u8fc7\u8c03\u6574\u521d\u59cb\u5316\u901f\u7387\u548c\u6743\u91cd\u8870\u51cf\u7cfb\u6570\u5b9e\u73b0\u6a21\u578b\u590d\u6742\u5ea6\u63a7\u5236\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u590d\u6742\u5ea6\u8d85\u53c2\u6570\u76842.4B\u6a21\u578b\u57281T token\u4e0a\u7684\u9884\u8bad\u7ec3\u57fa\u51c6\u6027\u80fd\u3002\u4f7f\u7528\u6052\u5b9a\u7684\u521d\u59cb\u5316\u901f\u7387\uff08std\u7684\u6307\u6570\uff09\uff0c\u800c\u975e\u56fa\u5b9a\u7684\u521d\u59cb\u5316\u6807\u51c6\u5dee\u3002", "result": "\u6a21\u578b\u590d\u6742\u5ea6\u63a7\u5236\u6539\u8fdb\u4e86LLM\u5728\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u5927\u5c0f\u4e0b\u7684\u6269\u5c55\u89c4\u5f8b\u3002\u6052\u5b9a\u521d\u59cb\u5316\u901f\u7387\u4f7f\u6269\u5c55\u89c4\u5f8b\u66f4\u5feb\u4e0b\u964d\u3002", "conclusion": "\u590d\u6742\u5ea6\u63a7\u5236\u662f\u6301\u7eed\u63d0\u5347LLM\u7684\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23412", "pdf": "https://arxiv.org/pdf/2505.23412", "abs": "https://arxiv.org/abs/2505.23412", "authors": ["Srishti Gupta", "Daniele Angioni", "Maura Pintor", "Ambra Demontis", "Lea Sch\u00f6nherr", "Battista Biggio", "Fabio Roli"], "title": "Buffer-free Class-Incremental Learning with Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Class-incremental learning (CIL) poses significant challenges in open-world\nscenarios, where models must not only learn new classes over time without\nforgetting previous ones but also handle inputs from unknown classes that a\nclosed-set model would misclassify. Recent works address both issues by\n(i)~training multi-head models using the task-incremental learning framework,\nand (ii) predicting the task identity employing out-of-distribution (OOD)\ndetectors. While effective, the latter mainly relies on joint training with a\nmemory buffer of past data, raising concerns around privacy, scalability, and\nincreased training time. In this paper, we present an in-depth analysis of\npost-hoc OOD detection methods and investigate their potential to eliminate the\nneed for a memory buffer. We uncover that these methods, when applied\nappropriately at inference time, can serve as a strong substitute for\nbuffer-based OOD detection. We show that this buffer-free approach achieves\ncomparable or superior performance to buffer-based methods both in terms of\nclass-incremental learning and the rejection of unknown samples. Experimental\nresults on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings,\noffering new insights into the design of efficient and privacy-preserving CIL\nsystems for open-world settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\uff08CIL\uff09\u4e2d\uff0c\u4f7f\u7528\u4e8b\u540eOOD\u68c0\u6d4b\u65b9\u6cd5\u66ff\u4ee3\u57fa\u4e8e\u7f13\u51b2\u533a\u7684\u65b9\u6cd5\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u89e3\u51b3\u9690\u79c1\u3001\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u65f6\u95f4\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u65e0\u7f13\u51b2\u533a\u65b9\u6cd5\u5728CIL\u548c\u672a\u77e5\u6837\u672c\u62d2\u7edd\u65b9\u9762\u5177\u6709\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CIL\u65b9\u6cd5\u901a\u8fc7\u591a\u5934\u6a21\u578b\u548c\u4efb\u52a1\u8bc6\u522b\u7ed3\u5408OOD\u68c0\u6d4b\u6765\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u548c\u672a\u77e5\u7c7b\u522b\u5904\u7406\u95ee\u9898\uff0c\u4f46\u4f9d\u8d56\u4e8e\u5305\u542b\u8fc7\u5f80\u6570\u636e\u7684\u8bb0\u5fc6\u7f13\u51b2\u533a\uff0c\u5f15\u53d1\u9690\u79c1\u3001\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u65f6\u95f4\u65b9\u9762\u7684\u62c5\u5fe7\u3002", "method": "\u4f5c\u8005\u5bf9\u4e8b\u540eOOD\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u5e76\u7814\u7a76\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u63a8\u7406\u9636\u6bb5\u7684\u5e94\u7528\u662f\u5426\u53ef\u4ee5\u66ff\u4ee3\u57fa\u4e8e\u7f13\u51b2\u533a\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65e0\u7f13\u51b2\u533a\u7684\u65b9\u6cd5\u5728CIFAR-10\u3001CIFAR-100\u548cTiny ImageNet\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4e0e\u57fa\u4e8e\u7f13\u51b2\u533a\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728CIL\u548c\u62d2\u7edd\u672a\u77e5\u6837\u672c\u65b9\u9762\u3002", "conclusion": "\u4e8b\u540eOOD\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u57fa\u4e8e\u7f13\u51b2\u533a\u7684OOD\u68c0\u6d4b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4fdd\u62a4\u9690\u79c1\u7684CIL\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5f00\u653e\u4e16\u754c\u573a\u666f\u3002"}}
{"id": "2505.23014", "pdf": "https://arxiv.org/pdf/2505.23014", "abs": "https://arxiv.org/abs/2505.23014", "authors": ["Juwei Yue", "Haikuo Li", "Jiawei Sheng", "Xiaodong Li", "Taoyu Su", "Tingwen Liu", "Li Guo"], "title": "Hyperbolic-PDE GNN: Spectral Graph Neural Networks in the Perspective of A System of Hyperbolic Partial Differential Equations", "categories": ["cs.LG"], "comment": "18 pages, 2 figures, published to ICML 2025", "summary": "Graph neural networks (GNNs) leverage message passing mechanisms to learn the\ntopological features of graph data. Traditional GNNs learns node features in a\nspatial domain unrelated to the topology, which can hardly ensure topological\nfeatures. In this paper, we formulates message passing as a system of\nhyperbolic partial differential equations (hyperbolic PDEs), constituting a\ndynamical system that explicitly maps node representations into a particular\nsolution space. This solution space is spanned by a set of eigenvectors\ndescribing the topological structure of graphs. Within this system, for any\nmoment in time, a node features can be decomposed into a superposition of the\nbasis of eigenvectors. This not only enhances the interpretability of message\npassing but also enables the explicit extraction of fundamental characteristics\nabout the topological structure. Furthermore, by solving this system of\nhyperbolic partial differential equations, we establish a connection with\nspectral graph neural networks (spectral GNNs), serving as a message passing\nenhancement paradigm for spectral GNNs.We further introduce polynomials to\napproximate arbitrary filter functions. Extensive experiments demonstrate that\nthe paradigm of hyperbolic PDEs not only exhibits strong flexibility but also\nsignificantly enhances the performance of various spectral GNNs across diverse\ngraph tasks.", "AI": {"tldr": "\u672c\u6587\u5c06\u6d88\u606f\u4f20\u9012\u673a\u5236\u5efa\u6a21\u4e3a\u53cc\u66f2\u504f\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u89e3\u8282\u70b9\u7279\u5f81\u589e\u5f3a\u62d3\u6251\u7ed3\u6784\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63d0\u53d6\u80fd\u529b\uff0c\u5e76\u4e0e\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u5efa\u7acb\u8054\u7cfb\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u7075\u6d3b\u6027\u548c\u6027\u80fd\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u7a7a\u95f4\u57df\u4e2d\u5b66\u4e60\u8282\u70b9\u7279\u5f81\uff0c\u4e0e\u62d3\u6251\u7ed3\u6784\u65e0\u5173\uff0c\u96be\u4ee5\u786e\u4fdd\u5b66\u4e60\u5230\u6709\u6548\u7684\u62d3\u6251\u7279\u5f81\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u663e\u5f0f\u5730\u6355\u6349\u56fe\u6570\u636e\u7684\u62d3\u6251\u7279\u6027\u3002", "method": "\u5c06\u6d88\u606f\u4f20\u9012\u673a\u5236\u8868\u793a\u4e3a\u53cc\u66f2\u504f\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\uff0c\u5f62\u6210\u4e00\u4e2a\u52a8\u6001\u7cfb\u7edf\uff0c\u5c06\u8282\u70b9\u8868\u793a\u6620\u5c04\u5230\u7279\u5b9a\u89e3\u7a7a\u95f4\u3002\u8be5\u89e3\u7a7a\u95f4\u7531\u63cf\u8ff0\u56fe\u62d3\u6251\u7ed3\u6784\u7684\u7279\u5f81\u5411\u91cf\u96c6\u5408\u5f20\u6210\u3002\u901a\u8fc7\u6c42\u89e3\u6b64\u7cfb\u7edf\uff0c\u5efa\u7acb\u4e0e\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u7cfb\uff0c\u5e76\u5f15\u5165\u591a\u9879\u5f0f\u8fd1\u4f3c\u4efb\u610f\u6ee4\u6ce2\u51fd\u6570\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8e\u53cc\u66f2\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8303\u5f0f\u4e0d\u4ec5\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u7075\u6d3b\u6027\uff0c\u800c\u4e14\u663e\u8457\u63d0\u5347\u4e86\u5404\u79cd\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u4e0d\u540c\u56fe\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u53cc\u66f2\u504f\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\u589e\u5f3a\u4e86\u6d88\u606f\u4f20\u9012\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u80fd\u663e\u5f0f\u63d0\u53d6\u56fe\u7684\u62d3\u6251\u7ed3\u6784\u7279\u5f81\uff0c\u540c\u65f6\u6539\u8fdb\u4e86\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u3002"}}
{"id": "2505.23415", "pdf": "https://arxiv.org/pdf/2505.23415", "abs": "https://arxiv.org/abs/2505.23415", "authors": ["Gaspard Oliviers", "Mufeng Tang", "Rafal Bogacz"], "title": "Bidirectional predictive coding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predictive coding (PC) is an influential computational model of visual\nlearning and inference in the brain. Classical PC was proposed as a top-down\ngenerative model, where the brain actively predicts upcoming visual inputs, and\ninference minimises the prediction errors. Recent studies have also shown that\nPC can be formulated as a discriminative model, where sensory inputs predict\nneural activities in a feedforward manner. However, experimental evidence\nsuggests that the brain employs both generative and discriminative inference,\nwhile unidirectional PC models show degraded performance in tasks requiring\nbidirectional processing. In this work, we propose bidirectional PC (bPC), a PC\nmodel that incorporates both generative and discriminative inference while\nmaintaining a biologically plausible circuit implementation. We show that bPC\nmatches or outperforms unidirectional models in their specialised generative or\ndiscriminative tasks, by developing an energy landscape that simultaneously\nsuits both tasks. We also demonstrate bPC's superior performance in two\nbiologically relevant tasks including multimodal learning and inference with\nmissing information, suggesting that bPC resembles biological visual inference\nmore closely.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9884\u6d4b\u7f16\u7801\u6a21\u578bbPC\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u751f\u6210\u548c\u5224\u522b\u63a8\u7406\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u5411\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u9884\u6d4b\u7f16\u7801\uff08PC\uff09\u6a21\u578b\u8981\u4e48\u662f\u751f\u6210\u6a21\u578b\uff0c\u8981\u4e48\u662f\u5224\u522b\u6a21\u578b\uff0c\u4f46\u5b9e\u9a8c\u8868\u660e\u5927\u8111\u540c\u65f6\u4f7f\u7528\u8fd9\u4e24\u79cd\u63a8\u7406\u65b9\u5f0f\uff0c\u800c\u5355\u5411\u6a21\u578b\u5728\u9700\u8981\u53cc\u5411\u5904\u7406\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u53cc\u5411\u9884\u6d4b\u7f16\u7801\uff08bPC\uff09\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u751f\u6210\u548c\u5224\u522b\u63a8\u7406\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5e76\u4fdd\u6301\u4e86\u751f\u7269\u5b66\u4e0a\u53ef\u884c\u7684\u7535\u8def\u5b9e\u73b0\u3002\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u540c\u65f6\u9002\u7528\u4e8e\u4e24\u79cd\u4efb\u52a1\u7684\u80fd\u91cf\u666f\u89c2\uff0c\u4f7fbPC\u5728\u751f\u6210\u6216\u5224\u522b\u4efb\u52a1\u4e2d\u90fd\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u5355\u5411\u6a21\u578b\u3002", "result": "bPC\u5728\u4e13\u95e8\u7684\u751f\u6210\u6216\u5224\u522b\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u5355\u5411\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u5728\u4e24\u4e2a\u4e0e\u751f\u7269\u5b66\u76f8\u5173\u7684\u4efb\u52a1\uff08\u591a\u6a21\u6001\u5b66\u4e60\u548c\u7f3a\u5931\u4fe1\u606f\u63a8\u7406\uff09\u4e2d\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8868\u660ebPC\u66f4\u63a5\u8fd1\u4e8e\u751f\u7269\u89c6\u89c9\u63a8\u7406\u3002", "conclusion": "bPC\u6a21\u578b\u66f4\u597d\u5730\u6a21\u62df\u4e86\u751f\u7269\u89c6\u89c9\u63a8\u7406\u8fc7\u7a0b\uff0c\u53ef\u80fd\u4e3a\u7406\u89e3\u5927\u8111\u4e2d\u7684\u89c6\u89c9\u5b66\u4e60\u548c\u63a8\u7406\u63d0\u4f9b\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u3002"}}
{"id": "2505.23426", "pdf": "https://arxiv.org/pdf/2505.23426", "abs": "https://arxiv.org/abs/2505.23426", "authors": ["Yinuo Wang", "Mining Tan", "Wenjun Zou", "Haotian Lin", "Xujie Song", "Wenxuan Wang", "Tong Liu", "Likun Wang", "Guojian Zhan", "Tianze Zhu", "Shiqi Liu", "Jingliang Duan", "Shengbo Eben Li"], "title": "Enhanced DACER Algorithm with High Diffusion Efficiency", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Due to their expressive capacity, diffusion models have shown great promise\nin offline RL and imitation learning. Diffusion Actor-Critic with Entropy\nRegulator (DACER) extended this capability to online RL by using the reverse\ndiffusion process as a policy approximator, trained end-to-end with policy\ngradient methods, achieving strong performance. However, this comes at the cost\nof requiring many diffusion steps, which significantly hampers training\nefficiency, while directly reducing the steps leads to noticeable performance\ndegradation. Critically, the lack of inference efficiency becomes a significant\nbottleneck for applying diffusion policies in real-time online RL settings. To\nimprove training and inference efficiency while maintaining or even enhancing\nperformance, we propose a Q-gradient field objective as an auxiliary\noptimization target to guide the denoising process at each diffusion step.\nNonetheless, we observe that the independence of the Q-gradient field from the\ndiffusion time step negatively impacts the performance of the diffusion policy.\nTo address this, we introduce a temporal weighting mechanism that enables the\nmodel to efficiently eliminate large-scale noise in the early stages and refine\nactions in the later stages. Experimental results on MuJoCo benchmarks and\nseveral multimodal tasks demonstrate that the DACER2 algorithm achieves\nstate-of-the-art performance in most MuJoCo control tasks with only five\ndiffusion steps, while also exhibiting stronger multimodality compared to\nDACER.", "AI": {"tldr": "DACER2\u901a\u8fc7\u5f15\u5165Q-gradient field\u76ee\u6807\u548c\u65f6\u95f4\u52a0\u6743\u673a\u5236\uff0c\u4f18\u5316\u4e86\u6269\u6563\u7b56\u7565\u7684\u8bad\u7ec3\u4e0e\u63a8\u7406\u6548\u7387\uff0c\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ec5\u75285\u6b65\u6269\u6563\u5373\u8fbe\u5230\u9876\u5c16\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u591a\u6a21\u6001\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u5728\u79bb\u7ebfRL\u548c\u6a21\u4eff\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u7ebfRL\u5e94\u7528\u4e2d\u5b58\u5728\u8bad\u7ec3\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u6269\u6563\u6b65\u9aa4\u53c8\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u9ad8\u6269\u6563\u7b56\u7565\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u589e\u5f3a\u6027\u80fd\u3002", "method": "\u63d0\u51faQ-gradient field\u76ee\u6807\u4f5c\u4e3a\u8f85\u52a9\u4f18\u5316\u76ee\u6807\u4ee5\u6307\u5bfc\u6bcf\u4e00\u6b65\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u53bb\u566a\u64cd\u4f5c\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u52a0\u6743\u673a\u5236\u4f7f\u6a21\u578b\u5728\u65e9\u671f\u9636\u6bb5\u80fd\u6709\u6548\u6d88\u9664\u5927\u89c4\u6a21\u566a\u58f0\uff0c\u5728\u540e\u671f\u9636\u6bb5\u7cbe\u7ec6\u8c03\u6574\u52a8\u4f5c\u3002", "result": "\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\uff0cDACER2\u7b97\u6cd5\u4ec5\u7528\u4e94\u6b65\u6269\u6563\u5c31\u8fbe\u5230\u4e86\u9876\u5c16\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u4e86\u6bd4DACER\u66f4\u5f3a\u7684\u591a\u6a21\u6001\u80fd\u529b\u3002", "conclusion": "DACER2\u901a\u8fc7\u4f18\u5316\u6269\u6563\u6b65\u9aa4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u589e\u5f3a\u4e86\u6027\u80fd\uff0c\u4e3a\u5b9e\u65f6\u5728\u7ebfRL\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u9009\u62e9\u3002"}}
{"id": "2505.23022", "pdf": "https://arxiv.org/pdf/2505.23022", "abs": "https://arxiv.org/abs/2505.23022", "authors": ["Yinghao Tang", "Tingfeng Lan", "Xiuqi Huang", "Hui Lu", "Wei Chen"], "title": "SCORPIO: Serving the Right Requests at the Right Time for Heterogeneous SLOs in LLM Inference", "categories": ["cs.LG"], "comment": null, "summary": "Existing Large Language Model (LLM) serving systems prioritize maximum\nthroughput. They often neglect Service Level Objectives (SLOs) such as Time to\nFirst Token (TTFT) and Time Per Output Token (TPOT), which leads to suboptimal\nSLO attainment. This paper introduces SCORPIO, an SLO-oriented LLM serving\nsystem designed to maximize system goodput and SLO attainment for workloads\nwith heterogeneous SLOs. Our core insight is to exploit SLO heterogeneity for\nadaptive scheduling across admission control, queue management, and batch\nselection. SCORPIO features a TTFT Guard, which employs least-deadline-first\nreordering and rejects unattainable requests, and a TPOT Guard, which utilizes\na VBS-based admission control and a novel credit-based batching mechanism. Both\nguards are supported by a predictive module. Evaluations demonstrate that\nSCORPIO improves system goodput by up to 14.4X and SLO adherence by up to 46.5%\ncompared to state-of-the-art baselines.", "AI": {"tldr": "SCORPIO \u662f\u4e00\u79cd\u4ee5 SLO \u4e3a\u5bfc\u5411\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7 TTFT Guard \u548c TPOT Guard \u63d0\u9ad8\u7cfb\u7edf\u541e\u5410\u91cf\u548c SLO \u8fbe\u6210\u7387\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6700\u9ad8\u63d0\u5347 14.4 \u500d\u541e\u5410\u91cf\u548c 46.5% \u7684 SLO \u9075\u5faa\u5ea6\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\u4fa7\u91cd\u6700\u5927\u541e\u5410\u91cf\uff0c\u5ffd\u89c6\u4e86\u5982\u9996\u6b21\u8f93\u51fa\u65f6\u95f4\uff08TTFT\uff09\u548c\u6bcf\u8f93\u51fa\u4ee4\u724c\u65f6\u95f4\uff08TPOT\uff09\u7b49\u670d\u52a1\u8d28\u91cf\u76ee\u6807\uff08SLO\uff09\uff0c\u5bfc\u81f4 SLO \u8fbe\u6210\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa SCORPIO \u7cfb\u7edf\uff0c\u6838\u5fc3\u662f\u5229\u7528 SLO \u5f02\u8d28\u6027\u8fdb\u884c\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u6db5\u76d6\u51c6\u5165\u63a7\u5236\u3001\u961f\u5217\u7ba1\u7406\u548c\u6279\u91cf\u9009\u62e9\u3002\u7cfb\u7edf\u5305\u62ec TTFT Guard\uff08\u91c7\u7528\u6700\u65e9\u622a\u6b62\u671f\u9650\u4f18\u5148\u91cd\u6392\u548c\u62d2\u7edd\u4e0d\u53ef\u8fbe\u8bf7\u6c42\uff09\u548c TPOT Guard\uff08\u4f7f\u7528\u57fa\u4e8e VBS \u7684\u51c6\u5165\u63a7\u5236\u548c\u57fa\u4e8e\u4fe1\u7528\u7684\u65b0\u578b\u6279\u91cf\u673a\u5236\uff09\uff0c\u4e24\u8005\u7531\u9884\u6d4b\u6a21\u5757\u652f\u6301\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cSCORPIO \u5c06\u7cfb\u7edf\u6709\u6548\u541e\u5410\u91cf\u63d0\u9ad8\u4e86\u9ad8\u8fbe 14.4 \u500d\uff0c\u5e76\u5c06 SLO \u9075\u5faa\u5ea6\u63d0\u5347\u4e86\u9ad8\u8fbe 46.5%\u3002", "conclusion": "SCORPIO \u6210\u529f\u901a\u8fc7 SLO \u5bfc\u5411\u8bbe\u8ba1\u663e\u8457\u6539\u5584\u4e86\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\u548c SLO \u8fbe\u6210\u60c5\u51b5\u3002"}}
{"id": "2505.23437", "pdf": "https://arxiv.org/pdf/2505.23437", "abs": "https://arxiv.org/abs/2505.23437", "authors": ["Antonio Ferrara", "Andrea Pugnana", "Francesco Bonchi", "Salvatore Ruggieri"], "title": "Bounded-Abstention Pairwise Learning to Rank", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Ranking systems influence decision-making in high-stakes domains like health,\neducation, and employment, where they can have substantial economic and social\nimpacts. This makes the integration of safety mechanisms essential. One such\nmechanism is $\\textit{abstention}$, which enables algorithmic decision-making\nsystem to defer uncertain or low-confidence decisions to human experts. While\nabstention have been predominantly explored in the context of classification\ntasks, its application to other machine learning paradigms remains\nunderexplored. In this paper, we introduce a novel method for abstention in\npairwise learning-to-rank tasks. Our approach is based on thresholding the\nranker's conditional risk: the system abstains from making a decision when the\nestimated risk exceeds a predefined threshold. Our contributions are threefold:\na theoretical characterization of the optimal abstention strategy, a\nmodel-agnostic, plug-in algorithm for constructing abstaining ranking models,\nand a comprehensive empirical evaluations across multiple datasets,\ndemonstrating the effectiveness of our approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f03\u6743\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6210\u5bf9\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\uff0c\u901a\u8fc7\u8bbe\u5b9a\u6761\u4ef6\u98ce\u9669\u9608\u503c\u6765\u51b3\u5b9a\u662f\u5426\u5f03\u6743\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u5982\u5065\u5eb7\u3001\u6559\u80b2\u548c\u5c31\u4e1a\u4e2d\u7684\u6392\u540d\u7cfb\u7edf\u4f1a\u5f71\u54cd\u51b3\u7b56\uff0c\u5e76\u5e26\u6765\u663e\u8457\u7684\u7ecf\u6d4e\u548c\u793e\u4f1a\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u5b89\u5168\u673a\u5236\u7684\u6574\u5408\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5176\u4e2d\u4e00\u79cd\u673a\u5236\u662f'\u5f03\u6743'\uff08abstention\uff09\uff0c\u5b83\u5141\u8bb8\u7b97\u6cd5\u51b3\u7b56\u7cfb\u7edf\u5c06\u4e0d\u786e\u5b9a\u6216\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u51b3\u7b56\u8f6c\u79fb\u7ed9\u4eba\u7c7b\u4e13\u5bb6\u3002\u5c3d\u7ba1\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5df2\u5e7f\u6cdb\u7814\u7a76\u4e86\u5f03\u6743\u673a\u5236\uff0c\u4f46\u5728\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u8303\u5f0f\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u8f83\u5c11\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6392\u5e8f\u5668\u6761\u4ef6\u98ce\u9669\u9608\u503c\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6210\u5bf9\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u5f03\u6743\u3002\u5f53\u4f30\u8ba1\u7684\u98ce\u9669\u8d85\u8fc7\u9884\u5b9a\u4e49\u7684\u9608\u503c\u65f6\uff0c\u7cfb\u7edf\u4f1a\u653e\u5f03\u505a\u51fa\u51b3\u7b56\u3002", "result": "\u7406\u8bba\u7279\u5f81\u7684\u6700\u4f73\u5f03\u6743\u7b56\u7565\uff1b\u4e00\u4e2a\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u3001\u53ef\u63d2\u5165\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u5f03\u6743\u6392\u5e8f\u6a21\u578b\uff1b\u4ee5\u53ca\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5168\u9762\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6210\u5bf9\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u5f03\u6743\u65b9\u6cd5\uff0c\u901a\u8fc7\u6761\u4ef6\u98ce\u9669\u9608\u503c\u6765\u51b3\u5b9a\u662f\u5426\u5f03\u6743\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u3001\u7b97\u6cd5\u548c\u5b9e\u8bc1\u7684\u652f\u6301\u3002"}}
{"id": "2505.23024", "pdf": "https://arxiv.org/pdf/2505.23024", "abs": "https://arxiv.org/abs/2505.23024", "authors": ["Zhihao Wang", "Wenke Huang", "Tian Chen", "Zekun Shi", "Guancheng Wan", "Yu Qiao", "Bin Yang", "Jian Wang", "Bing Li", "Mang Ye"], "title": "An Empirical Study of Federated Prompt Learning for Vision Language Model", "categories": ["cs.LG"], "comment": null, "summary": "The Vision Language Model (VLM) excels in aligning vision and language\nrepresentations, and prompt learning has emerged as a key technique for\nadapting such models to downstream tasks. However, the application of prompt\nlearning with VLM in federated learning (\\fl{}) scenarios remains\nunderexplored. This paper systematically investigates the behavioral\ndifferences between language prompt learning (LPT) and vision prompt learning\n(VPT) under data heterogeneity challenges, including label skew and domain\nshift. We conduct extensive experiments to evaluate the impact of various \\fl{}\nand prompt configurations, such as client scale, aggregation strategies, and\nprompt length, to assess the robustness of Federated Prompt Learning (FPL).\nFurthermore, we explore strategies for enhancing prompt learning in complex\nscenarios where label skew and domain shift coexist, including leveraging both\nprompt types when computational resources allow. Our findings offer practical\ninsights into optimizing prompt learning in federated settings, contributing to\nthe broader deployment of VLMs in privacy-preserving environments.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u8bed\u8a00\u63d0\u793a\u5b66\u4e60\uff08LPT\uff09\u548c\u89c6\u89c9\u63d0\u793a\u5b66\u4e60\uff08VPT\uff09\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u914d\u7f6e\u5bf9Federated Prompt Learning (FPL)\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u5728\u6807\u7b7e\u504f\u659c\u548c\u9886\u57df\u8f6c\u79fb\u5171\u5b58\u7684\u590d\u6742\u60c5\u51b5\u4e0b\u63d0\u5347\u63d0\u793a\u5b66\u4e60\u7684\u7b56\u7565\uff0c\u4e3a\u4f18\u5316\u9690\u79c1\u4fdd\u62a4\u73af\u5883\u4e0b\u7684VLM\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u5c06\u63d0\u793a\u5b66\u4e60\u4e0e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7ed3\u5408\u5e76\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u8f83\u5c11\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\u5982\u6807\u7b7e\u504f\u659c\u548c\u9886\u57df\u8f6c\u79fb\u7684\u60c5\u51b5\u4e0b\u3002", "method": "1. \u7cfb\u7edf\u7814\u7a76\u8bed\u8a00\u63d0\u793a\u5b66\u4e60\u548c\u89c6\u89c9\u63d0\u793a\u5b66\u4e60\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u7684\u884c\u4e3a\u5dee\u5f02\u3002\n2. \u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u8054\u90a6\u5b66\u4e60\u548c\u63d0\u793a\u914d\u7f6e\uff08\u5982\u5ba2\u6237\u7aef\u89c4\u6a21\u3001\u805a\u5408\u7b56\u7565\u3001\u63d0\u793a\u957f\u5ea6\uff09\u5bf9Federated Prompt Learning (FPL)\u7684\u5f71\u54cd\u3002\n3. \u63a2\u7d22\u5728\u6807\u7b7e\u504f\u659c\u548c\u9886\u57df\u8f6c\u79fb\u5171\u5b58\u7684\u590d\u6742\u573a\u666f\u4e0b\u589e\u5f3a\u63d0\u793a\u5b66\u4e60\u7684\u7b56\u7565\uff0c\u5305\u62ec\u5728\u8ba1\u7b97\u8d44\u6e90\u5141\u8bb8\u65f6\u7ed3\u5408\u4e24\u79cd\u63d0\u793a\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u4e0d\u540c\u914d\u7f6e\u5bf9FPL\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u590d\u6742\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\u4e0b\u7684\u6709\u6548\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u63d0\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u63a8\u52a8\u4e86\u5728\u9690\u79c1\u4fdd\u62a4\u73af\u5883\u4e2d\u66f4\u5e7f\u6cdb\u5730\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2505.23529", "pdf": "https://arxiv.org/pdf/2505.23529", "abs": "https://arxiv.org/abs/2505.23529", "authors": ["Shifeng Xie", "Aref Einizade", "Jhony H. Giraldo"], "title": "Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Representation Learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of input\nsubgraph characteristics while generating subgraphs with a controlled\ndistribution. We then employ optimal transport distances, more precisely the\nWasserstein and Gromov-Wasserstein distances, to effectively measure the\nsimilarity between subgraphs, enhancing the robustness of the contrastive\nlearning process. Extensive experiments across multiple benchmarks demonstrate\nthat \\method~outperforms or presents competitive performance against\nstate-of-the-art approaches. Our findings provide insights into the design of\nSSL methods for GRL, emphasizing the importance of the distribution of the\ngenerated contrastive pairs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b50\u56fe\u9ad8\u65af\u5d4c\u5165\u5bf9\u6bd4\uff08SubGEC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5c06\u5b50\u56fe\u6620\u5c04\u5230\u7ed3\u6784\u5316\u7684\u9ad8\u65af\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u8ddd\u79bb\u6765\u8861\u91cf\u5b50\u56fe\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u5728\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4f18\u8d8a\u6216\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "motivation": "\u907f\u514d\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u56fe\u8868\u793a\u5b66\u4e60\uff0c\u540c\u65f6\u89e3\u51b3\u751f\u6210\u5bf9\u6bd4\u5bf9\u5206\u5e03\u7684\u91cd\u8981\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5b50\u56fe\u9ad8\u65af\u5d4c\u5165\u6a21\u5757\uff0c\u5c06\u5b50\u56fe\u6620\u5c04\u5230\u9ad8\u65af\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528Wasserstein\u548cGromov-Wasserstein\u8ddd\u79bb\u6765\u8861\u91cf\u5b50\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6216\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u751f\u6210\u5bf9\u6bd4\u5bf9\u5206\u5e03\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.23564", "pdf": "https://arxiv.org/pdf/2505.23564", "abs": "https://arxiv.org/abs/2505.23564", "authors": ["Yiran Guo", "Lijie Xu", "Jie Liu", "Dan Ye", "Shuang Qiu"], "title": "Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Enhancing the reasoning capabilities of large language models effectively\nusing reinforcement learning (RL) remains a crucial challenge. Existing\napproaches primarily adopt two contrasting advantage estimation granularities:\nToken-level methods (e.g., PPO) aim to provide the fine-grained advantage\nsignals but suffer from inaccurate estimation due to difficulties in training\nan accurate critic model. On the other extreme, trajectory-level methods (e.g.,\nGRPO) solely rely on a coarse-grained advantage signal from the final reward,\nleading to imprecise credit assignment. To address these limitations, we\npropose Segment Policy Optimization (SPO), a novel RL framework that leverages\nsegment-level advantage estimation at an intermediate granularity, achieving a\nbetter balance by offering more precise credit assignment than trajectory-level\nmethods and requiring fewer estimation points than token-level methods,\nenabling accurate advantage estimation based on Monte Carlo (MC) without a\ncritic model. SPO features three components with novel strategies: (1) flexible\nsegment partition; (2) accurate segment advantage estimation; and (3) policy\noptimization using segment advantages, including a novel probability-mask\nstrategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain\nfor short chain-of-thought (CoT), featuring novel cutpoint-based partition and\nchain-based advantage estimation, achieving $6$-$12$ percentage point\nimprovements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,\nfeaturing novel tree-based advantage estimation, which significantly reduces\nthe cost of MC estimation, achieving $7$-$11$ percentage point improvements\nover GRPO on MATH500 under 2K and 4K context evaluation. We make our code\npublicly available at https://github.com/AIFrameResearch/SPO.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u4e24\u79cd\u5bf9\u6bd4\u4f18\u52bf\u4f30\u8ba1\u7c92\u5ea6\uff1aToken\u7ea7\u65b9\u6cd5\uff08\u5982PPO\uff09\u548c\u8f68\u8ff9\u7ea7\u65b9\u6cd5\uff08\u5982GRPO\uff09\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u6bb5\u843d\u7b56\u7565\u4f18\u5316\uff08SPO\uff09\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4e2d\u7b49\u7c92\u5ea6\u7684\u6bb5\u843d\u7ea7\u4f18\u52bf\u4f30\u8ba1\uff0c\u5728\u7cbe\u786e\u4fe1\u7528\u5206\u914d\u548c\u4f30\u8ba1\u70b9\u6570\u91cf\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u5e73\u8861\u3002SPO\u5305\u62ec\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u7075\u6d3b\u7684\u6bb5\u843d\u5212\u5206\u3001\u51c6\u786e\u7684\u6bb5\u843d\u4f18\u52bf\u4f30\u8ba1\u548c\u57fa\u4e8e\u6bb5\u843d\u4f18\u52bf\u7684\u7b56\u7565\u4f18\u5316\uff0c\u5e76\u5728\u4e24\u4e2a\u5177\u4f53\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u5b9e\u4f8b\u5316\uff0c\u5206\u522b\u5728GSM8K\u548cMATH500\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u7531\u4e8e\u96be\u4ee5\u8bad\u7ec3\u51c6\u786e\u7684\u8bc4\u4f30\u6a21\u578b\u800c\u5bfc\u81f4\u4f30\u8ba1\u4e0d\u51c6\u786e\uff08Token\u7ea7\u65b9\u6cd5\uff09\uff0c\u8981\u4e48\u4ec5\u4f9d\u8d56\u6700\u7ec8\u5956\u52b1\u5bfc\u81f4\u7c97\u7565\u7684\u4fe1\u7528\u5206\u914d\uff08\u8f68\u8ff9\u7ea7\u65b9\u6cd5\uff09\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6bb5\u843d\u7b56\u7565\u4f18\u5316\uff08SPO\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u4e2d\u7b49\u7c92\u5ea6\u7684\u6bb5\u843d\u7ea7\u4f18\u52bf\u4f30\u8ba1\u3002SPO\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1) \u7075\u6d3b\u7684\u6bb5\u843d\u5212\u5206\uff1b(2) \u51c6\u786e\u7684\u6bb5\u843d\u4f18\u52bf\u4f30\u8ba1\uff1b(3) \u57fa\u4e8e\u6bb5\u843d\u4f18\u52bf\u7684\u7b56\u7565\u4f18\u5316\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u79cd\u65b0\u7684\u6982\u7387\u63a9\u7801\u7b56\u7565\u3002\u6b64\u5916\uff0cSPO\u88ab\u5b9e\u4f8b\u5316\u4e3a\u4e24\u79cd\u7279\u5b9a\u573a\u666f\uff1aSPO-chain\u7528\u4e8e\u77ed\u94fe\u63a8\u7406\uff0cSPO-tree\u7528\u4e8e\u957f\u94fe\u63a8\u7406\u3002", "result": "SPO-chain\u5728GSM8K\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4PPO\u548cGRPO\u63d0\u9ad8\u4e866-12\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u6027\u3002SPO-tree\u5728MATH500\u6570\u636e\u96c6\u4e0a\uff0c\u57282K\u548c4K\u4e0a\u4e0b\u6587\u8bc4\u4f30\u4e0b\u76f8\u6bd4GRPO\u63d0\u9ad8\u4e867-11\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u6027\u3002", "conclusion": "SPO\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6bb5\u843d\u7ea7\u4f18\u52bf\u4f30\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u4fe1\u7528\u5206\u914d\u548c\u8f83\u5c11\u7684\u4f30\u8ba1\u70b9\u9700\u6c42\u3002\u5b83\u5728\u77ed\u94fe\u548c\u957f\u94fe\u63a8\u7406\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2505.23724", "pdf": "https://arxiv.org/pdf/2505.23724", "abs": "https://arxiv.org/abs/2505.23724", "authors": ["Minrui Luo", "Fuhang Kuang", "Yu Wang", "Zirui Liu", "Tianxing He"], "title": "SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank\nAdaptation (LoRA), are indispensable for efficiently customizing Large Language\nModels (LLMs). However, vanilla LoRA suffers from slow convergence speed and\nknowledge forgetting problems. Recent studies have leveraged the power of\ndesigned LoRA initialization, to enhance the fine-tuning efficiency, or to\npreserve knowledge in the pre-trained LLM. However, none of these works can\naddress the two cases at the same time. To this end, we introduce\nSubspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework\nengineered to navigate the trade-off between efficient fine-tuning and\nknowledge preservation. We achieve this by constraining the output of trainable\nLoRA adapters in a low-rank subspace, where the context information of\nfine-tuning data is most preserved while the context information of preserved\nknowledge is least retained, in a balanced way. Such constraint enables the\ntrainable weights to primarily focus on the main features of fine-tuning data\nwhile avoiding damaging the preserved knowledge features. We provide\ntheoretical analysis on our method, and conduct extensive experiments including\nsafety preservation and world knowledge preservation, on various downstream\ntasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning\nperformance while markedly diminishing knowledge forgetting, surpassing\ncontemporary LoRA initialization methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LoRA\u521d\u59cb\u5316\u6846\u67b6\u2014\u2014Subspace-Constrained LoRA\uff08SC-LoRA\uff09\uff0c\u5b83\u901a\u8fc7\u9650\u5236\u53ef\u8bad\u7ec3LoRA\u9002\u914d\u5668\u7684\u8f93\u51fa\u5728\u4e00\u4e2a\u4f4e\u79e9\u5b50\u7a7a\u95f4\u5185\uff0c\u4ee5\u5e73\u8861\u9ad8\u6548\u5fae\u8c03\u548c\u77e5\u8bc6\u4fdd\u7559\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSC-LoRA\u5728\u63d0\u9ad8\u5fae\u8c03\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u77e5\u8bc6\u9057\u5fd8\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684LoRA\u521d\u59cb\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684LoRA\u65b9\u6cd5\u867d\u7136\u6709\u52a9\u4e8e\u9ad8\u6548\u5b9a\u5236\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5b58\u5728\u6536\u655b\u901f\u5ea6\u6162\u548c\u77e5\u8bc6\u9057\u5fd8\u7684\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u8bbe\u8ba1LoRA\u521d\u59cb\u5316\u6765\u589e\u5f3a\u5fae\u8c03\u6548\u7387\u6216\u4fdd\u7559\u9884\u8bad\u7ec3\u77e5\u8bc6\uff0c\u4f46\u5c1a\u672a\u6709\u65b9\u6cd5\u80fd\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Subspace-Constrained LoRA (SC-LoRA)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684LoRA\u521d\u59cb\u5316\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u53ef\u8bad\u7ec3LoRA\u9002\u914d\u5668\u7684\u8f93\u51fa\u9650\u5236\u5728\u4e00\u4e2a\u4f4e\u79e9\u5b50\u7a7a\u95f4\u4e2d\uff0c\u5728\u6b64\u5b50\u7a7a\u95f4\u4e2d\uff0c\u5fae\u8c03\u6570\u636e\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5f97\u5230\u6700\u5927\u7a0b\u5ea6\u7684\u4fdd\u7559\uff0c\u800c\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5219\u4ee5\u6700\u5c0f\u7a0b\u5ea6\u4fdd\u7559\uff0c\u4ece\u800c\u5b9e\u73b0\u4e24\u8005\u7684\u5e73\u8861\u3002\u8fd9\u6837\u7684\u7ea6\u675f\u4f7f\u5f97\u53ef\u8bad\u7ec3\u6743\u91cd\u4e3b\u8981\u96c6\u4e2d\u5728\u5fae\u8c03\u6570\u636e\u7684\u4e3b\u8981\u7279\u5f81\u4e0a\uff0c\u540c\u65f6\u907f\u514d\u635f\u5bb3\u5df2\u4fdd\u7559\u7684\u77e5\u8bc6\u7279\u5f81\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSC-LoRA\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u5fae\u8c03\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u77e5\u8bc6\u9057\u5fd8\u73b0\u8c61\u3002\u76f8\u8f83\u4e8e\u5f53\u4ee3\u5176\u4ed6LoRA\u521d\u59cb\u5316\u65b9\u6cd5\uff0cSC-LoRA\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "SC-LoRA\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b0\u578bLoRA\u521d\u59cb\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5728\u63d0\u5347\u5fae\u8c03\u6548\u7387\u7684\u540c\u65f6\u51cf\u5c11\u77e5\u8bc6\u9057\u5fd8\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23048", "pdf": "https://arxiv.org/pdf/2505.23048", "abs": "https://arxiv.org/abs/2505.23048", "authors": ["Tianci Bu", "Le Zhou", "Wenchuan Yang", "Jianhong Mou", "Kang Yang", "Suoyi Tan", "Feng Yao", "Jingyuan Wang", "Xin Lu"], "title": "ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation", "categories": ["cs.LG"], "comment": null, "summary": "Trajectory data is crucial for various applications but often suffers from\nincompleteness due to device limitations and diverse collection scenarios.\nExisting imputation methods rely on sparse trajectory or travel information,\nsuch as velocity, to infer missing points. However, these approaches assume\nthat sparse trajectories retain essential behavioral patterns, which place\nsignificant demands on data acquisition and overlook the potential of\nlarge-scale human trajectory embeddings. To address this, we propose ProDiff, a\ntrajectory imputation framework that uses only two endpoints as minimal\ninformation. It integrates prototype learning to embed human movement patterns\nand a denoising diffusion probabilistic model for robust spatiotemporal\nreconstruction. Joint training with a tailored loss function ensures effective\nimputation. ProDiff outperforms state-of-the-art methods, improving accuracy by\n6.28\\% on FourSquare and 2.52\\% on WuXi. Further analysis shows a 0.927\ncorrelation between generated and real trajectories, demonstrating the\neffectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f68\u8ff9\u8865\u5168\u6846\u67b6ProDiff\uff0c\u901a\u8fc7\u539f\u578b\u5b66\u4e60\u548c\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u4e24\u4e2a\u7aef\u70b9\u4f5c\u4e3a\u6700\u5c0f\u4fe1\u606f\u8fdb\u884c\u8f68\u8ff9\u8865\u5168\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8f68\u8ff9\u6570\u636e\u5728\u591a\u79cd\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u8bbe\u5907\u9650\u5236\u548c\u591a\u6837\u5316\u7684\u91c7\u96c6\u573a\u666f\uff0c\u5e38\u5e38\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\u3002\u73b0\u6709\u7684\u8865\u5168\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7a00\u758f\u8f68\u8ff9\u6216\u65c5\u884c\u4fe1\u606f\uff08\u5982\u901f\u5ea6\uff09\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5047\u8bbe\u7a00\u758f\u8f68\u8ff9\u4fdd\u7559\u4e86\u57fa\u672c\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u5bf9\u6570\u636e\u83b7\u53d6\u8981\u6c42\u8f83\u9ad8\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u5927\u89c4\u6a21\u4eba\u7c7b\u8f68\u8ff9\u5d4c\u5165\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86ProDiff\uff0c\u4e00\u79cd\u4ec5\u4f7f\u7528\u4e24\u4e2a\u7aef\u70b9\u4f5c\u4e3a\u6700\u5c0f\u4fe1\u606f\u7684\u8f68\u8ff9\u8865\u5168\u6846\u67b6\u3002\u5b83\u7ed3\u5408\u4e86\u539f\u578b\u5b66\u4e60\u4ee5\u5d4c\u5165\u4eba\u7c7b\u8fd0\u52a8\u6a21\u5f0f\uff0c\u4ee5\u53ca\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u7a7a\u95f4\u65f6\u95f4\u91cd\u5efa\u3002\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u548c\u5b9a\u5236\u7684\u635f\u5931\u51fd\u6570\u786e\u4fdd\u4e86\u6709\u6548\u7684\u8865\u5168\u3002", "result": "ProDiff\u5728FourSquare\u548cWuXi\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u9ad8\u4e866.28%\u548c2.52%\u7684\u51c6\u786e\u6027\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660e\u751f\u6210\u8f68\u8ff9\u4e0e\u771f\u5b9e\u8f68\u8ff9\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u4e3a0.927\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "ProDiff\u662f\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u8f68\u8ff9\u8865\u5168\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u5c11\u91cf\u4fe1\u606f\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u8f68\u8ff9\u91cd\u5efa\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.23751", "pdf": "https://arxiv.org/pdf/2505.23751", "abs": "https://arxiv.org/abs/2505.23751", "authors": ["Declan Kutscher", "David M. Chan", "Yutong Bai", "Trevor Darrell", "Ritwik Gupta"], "title": "REOrdering Patches Improves Vision Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Sequence models such as transformers require inputs to be represented as\none-dimensional sequences. In vision, this typically involves flattening images\nusing a fixed row-major (raster-scan) order. While full self-attention is\npermutation-equivariant, modern long-sequence transformers increasingly rely on\narchitectural approximations that break this invariance and introduce\nsensitivity to patch ordering. We show that patch order significantly affects\nmodel performance in such settings, with simple alternatives like column-major\nor Hilbert curves yielding notable accuracy shifts. Motivated by this, we\npropose REOrder, a two-stage framework for discovering task-optimal patch\norderings. First, we derive an information-theoretic prior by evaluating the\ncompressibility of various patch sequences. Then, we learn a policy over\npermutations by optimizing a Plackett-Luce policy using REINFORCE. This\napproach enables efficient learning in a combinatorial permutation space.\nREOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to\n3.01% and Functional Map of the World by 13.35%.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u4f7f\u7528\u73b0\u4ee3\u957f\u5e8f\u5217Transformer\u6a21\u578b\u65f6\uff0c\u56fe\u50cf\u8865\u4e01\u987a\u5e8f\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aREOrder\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u4efb\u52a1\u6700\u4f18\u7684\u8865\u4e01\u6392\u5217\u987a\u5e8f\u3002\u901a\u8fc7\u4fe1\u606f\u7406\u8bba\u8bc4\u4f30\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86ImageNet-1K\u548cFunctional Map of the World\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u5c3d\u7ba1\u5b8c\u6574\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5177\u6709\u6392\u5217\u7b49\u53d8\u6027\uff0c\u4f46\u73b0\u4ee3\u957f\u5e8f\u5217Transformer\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u4e8e\u7834\u574f\u8fd9\u79cd\u4e0d\u53d8\u6027\u7684\u67b6\u6784\u8fd1\u4f3c\uff0c\u4ece\u800c\u5f15\u5165\u4e86\u5bf9\u8865\u4e01\u987a\u5e8f\u7684\u654f\u611f\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e0d\u540c\u7684\u8865\u4e01\u987a\u5e8f\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREOrder\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u4fe1\u606f\u7406\u8bba\u8bc4\u4f30\u5404\u79cd\u8865\u4e01\u5e8f\u5217\u7684\u53ef\u538b\u7f29\u6027\u4ee5\u83b7\u5f97\u5148\u9a8c\u77e5\u8bc6\uff1b\u7136\u540e\u5229\u7528Plackett-Luce\u7b56\u7565\u5e76\u901a\u8fc7REINFORCE\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u5b66\u4e60\u6392\u5217\u7a7a\u95f4\u4e2d\u7684\u6700\u4f73\u7b56\u7565\u3002", "result": "\u5728ImageNet-1K\u6570\u636e\u96c6\u4e0a\uff0cREOrder\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u884c\u4f18\u5148\u987a\u5e8f\u63d0\u5347\u4e86\u6700\u9ad83.01%\u7684Top-1\u51c6\u786e\u7387\uff0c\u5728Functional Map of the World\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e8613.35%\u3002", "conclusion": "\u4e0d\u540c\u7684\u8865\u4e01\u987a\u5e8f\u663e\u8457\u5f71\u54cd\u73b0\u4ee3\u957f\u5e8f\u5217Transformer\u6a21\u578b\u7684\u6027\u80fd\uff0c\u800cREOrder\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u4efb\u52a1\u6700\u4f18\u7684\u8865\u4e01\u6392\u5217\u987a\u5e8f\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2505.23049", "pdf": "https://arxiv.org/pdf/2505.23049", "abs": "https://arxiv.org/abs/2505.23049", "authors": ["Tianteng Gu", "Bei Liu", "Bo Xiao", "Ke Zeng", "Jiacheng Liu", "Yanmin Qian"], "title": "DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Pruning is a widely used technique to compress large language models (LLMs)\nby removing unimportant weights, but it often suffers from significant\nperformance degradation - especially under semi-structured sparsity\nconstraints. Existing pruning methods primarily focus on estimating the\nimportance of individual weights, which limits their ability to preserve\ncritical capabilities of the model. In this work, we propose a new perspective:\nrather than merely selecting which weights to prune, we first redistribute\nparameter importance to make the model inherently more amenable to pruning. By\nminimizing the information entropy of normalized importance scores, our\napproach concentrates importance onto a smaller subset of weights, thereby\nenhancing pruning robustness. We instantiate this idea through DenoiseRotator,\nwhich applies learnable orthogonal transformations to the model's weight\nmatrices. Our method is model-agnostic and can be seamlessly integrated with\nexisting pruning techniques such as Magnitude, SparseGPT, and Wanda. Evaluated\non LLaMA3, Qwen2.5, and Mistral models under 50% unstructured and 2:4\nsemi-structured sparsity, DenoiseRotator consistently improves perplexity and\nzero-shot accuracy. For instance, on LLaMA3-70B pruned with SparseGPT at 2:4\nsemi-structured sparsity, DenoiseRotator reduces the perplexity gap to the\ndense model by 58%, narrowing the degradation from 8.1 to 3.4 points. Codes are\navailable at https://github.com/Axel-gu/DenoiseRotator.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DenoiseRotator\uff0c\u4e00\u79cd\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u53c2\u6570\u91cd\u8981\u6027\u6765\u589e\u5f3a\u6a21\u578b\u526a\u679d\u9c81\u68d2\u6027\u7684\u65b0\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u80fd\u6709\u6548\u6539\u5584\u526a\u679d\u540e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u526a\u679d\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u4f30\u8ba1\u5355\u4e2a\u6743\u91cd\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4fdd\u7559\u6a21\u578b\u5173\u952e\u80fd\u529b\u65b9\u9762\u7684\u80fd\u529b\u3002\u7279\u522b\u662f\uff0c\u5728\u534a\u7ed3\u6784\u5316\u7a00\u758f\u7ea6\u675f\u4e0b\uff0c\u6027\u80fd\u4e0b\u964d\u663e\u8457\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\uff1a\u901a\u8fc7\u6700\u5c0f\u5316\u5f52\u4e00\u5316\u91cd\u8981\u6027\u5206\u6570\u7684\u4fe1\u606f\u71b5\uff0c\u5c06\u91cd\u8981\u6027\u96c6\u4e2d\u5230\u66f4\u5c0f\u7684\u6743\u91cd\u5b50\u96c6\u4e0a\uff0c\u4ece\u800c\u589e\u5f3a\u526a\u679d\u7684\u9c81\u68d2\u6027\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u901a\u8fc7DenoiseRotator\u5e94\u7528\u53ef\u5b66\u4e60\u7684\u6b63\u4ea4\u53d8\u6362\u5230\u6a21\u578b\u7684\u6743\u91cd\u77e9\u9635\u4e0a\u3002\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u7684\u526a\u679d\u6280\u672f\uff08\u5982Magnitude\u3001SparseGPT\u548cWanda\uff09\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728LLaMA3\u3001Qwen2.5\u548cMistral\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cDenoiseRotator\u572850%\u975e\u7ed3\u6784\u5316\u548c2:4\u534a\u7ed3\u6784\u5316\u7a00\u758f\u6761\u4ef6\u4e0b\uff0c\u4e00\u81f4\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u6027\u3002\u4f8b\u5982\uff0c\u5728LLaMA3-70B\u6a21\u578b\u4e0a\u4f7f\u7528SparseGPT\u8fdb\u884c2:4\u534a\u7ed3\u6784\u5316\u7a00\u758f\u526a\u679d\u65f6\uff0cDenoiseRotator\u5c06\u56f0\u60d1\u5ea6\u5dee\u8ddd\u51cf\u5c11\u4e8658%\uff0c\u4ece8.1\u70b9\u964d\u4f4e\u52303.4\u70b9\u3002", "conclusion": "DenoiseRotator\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u526a\u679d\u540e\u7684\u6027\u80fd\uff0c\u7f29\u5c0f\u4e0e\u5bc6\u96c6\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u73b0\u6709\u526a\u679d\u6280\u672f\u7ed3\u5408\u4f7f\u7528\u3002"}}
{"id": "2505.23761", "pdf": "https://arxiv.org/pdf/2505.23761", "abs": "https://arxiv.org/abs/2505.23761", "authors": ["Yunjae Won", "Hyunji Lee", "Hyeonbin Hwang", "Minjoon Seo"], "title": "Differential Information: An Information-Theoretic Perspective on Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "41 pages, 13 figures; due to the 1,920-character limitation imposed\n  on the abstract field by arXiv, the abstract included on the arXiv page is\n  slightly abbreviated compared to the version presented in the PDF", "summary": "Direct Preference Optimization (DPO) has become a standard technique for\naligning language models with human preferences in a supervised manner. Despite\nits empirical success, the theoretical justification behind its log-ratio\nreward parameterization remains incomplete. In this work, we address this gap\nby utilizing the Differential Information Distribution (DID): a distribution\nover token sequences that captures the information gained during policy\nupdates. First, we show that when preference labels encode the differential\ninformation required to transform a reference policy into a target policy, the\nlog-ratio reward in DPO emerges as the uniquely optimal form for learning the\ntarget policy via preference optimization. This result naturally yields a\nclosed-form expression for the optimal sampling distribution over rejected\nresponses. Second, we find that the condition for preferences to encode\ndifferential information is fundamentally linked to an implicit assumption\nregarding log-margin ordered policies-an inductive bias widely used in\npreference optimization yet previously unrecognized. Finally, by analyzing the\nentropy of the DID, we characterize how learning low-entropy differential\ninformation reinforces the policy distribution, while high-entropy differential\ninformation induces a smoothing effect, which explains the log-likelihood\ndisplacement phenomenon. We validate our theoretical findings in synthetic\nexperiments and extend them to real-world instruction-following datasets. Our\nresults suggest that learning high-entropy differential information is crucial\nfor general instruction-following, while learning low-entropy differential\ninformation benefits knowledge-intensive question answering. Overall, our work\npresents a unifying perspective on the DPO objective, the structure of\npreference data, and resulting policy behaviors through the lens of\ndifferential information.", "AI": {"tldr": "\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u662f\u4e00\u79cd\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u6807\u51c6\u6280\u672f\uff0c\u5c3d\u7ba1\u5176\u7ecf\u9a8c\u4e0a\u6210\u529f\uff0c\u4f46\u5176\u80cc\u540e\u7684\u7406\u8bba\u4f9d\u636e\u5c1a\u672a\u5b8c\u5584\u3002\u672c\u6587\u901a\u8fc7\u4f7f\u7528\u5dee\u5206\u4fe1\u606f\u5206\u5e03\uff08DID\uff09\uff0c\u63ed\u793a\u4e86DPO\u4e2dlog-ratio\u5956\u52b1\u53c2\u6570\u5316\u7684\u552f\u4e00\u6700\u4f18\u5f62\u5f0f\uff0c\u5e76\u89e3\u91ca\u4e86\u9ad8\u71b5\u548c\u4f4e\u71b5\u5dee\u5206\u4fe1\u606f\u5bf9\u7b56\u7565\u5b66\u4e60\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1DPO\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176log-ratio\u5956\u52b1\u53c2\u6570\u5316\u7684\u7406\u8bba\u4f9d\u636e\u5c1a\u4e0d\u5b8c\u6574\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u7406\u89e3\u5176\u673a\u5236\u3002", "method": "\u5229\u7528\u5dee\u5206\u4fe1\u606f\u5206\u5e03\uff08DID\uff09\uff0c\u8bc1\u660e\u5f53\u504f\u597d\u6807\u7b7e\u7f16\u7801\u4e86\u5c06\u53c2\u8003\u7b56\u7565\u8f6c\u6362\u4e3a\u76ee\u6807\u7b56\u7565\u6240\u9700\u7684\u5dee\u5206\u4fe1\u606f\u65f6\uff0cDPO\u4e2d\u7684log-ratio\u5956\u52b1\u662f\u5b66\u4e60\u76ee\u6807\u7b56\u7565\u7684\u552f\u4e00\u6700\u4f18\u5f62\u5f0f\u3002\u540c\u65f6\u5206\u6790\u4e86\u504f\u597d\u7f16\u7801\u5dee\u5206\u4fe1\u606f\u7684\u6761\u4ef6\u4e0e\u9690\u542b\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u7814\u7a76DID\u7684\u71b5\u6765\u63cf\u8ff0\u4e0d\u540c\u71b5\u503c\u7684\u5dee\u5206\u4fe1\u606f\u5bf9\u7b56\u7565\u5206\u5e03\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u5b66\u4e60\u9ad8\u71b5\u5dee\u5206\u4fe1\u606f\u5bf9\u901a\u7528\u6307\u4ee4\u8ddf\u968f\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5b66\u4e60\u4f4e\u71b5\u5dee\u5206\u4fe1\u606f\u6709\u52a9\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u7684\u56de\u7b54\u3002\u8fd9\u4e9b\u53d1\u73b0\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5dee\u5206\u4fe1\u606f\u7684\u89c6\u89d2\uff0c\u7edf\u4e00\u4e86\u5bf9DPO\u76ee\u6807\u3001\u504f\u597d\u6570\u636e\u7ed3\u6784\u53ca\u7b56\u7565\u884c\u4e3a\u7684\u7406\u89e3\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23055", "pdf": "https://arxiv.org/pdf/2505.23055", "abs": "https://arxiv.org/abs/2505.23055", "authors": ["Zhen Xiang", "Aliyah R. Hsu", "Austin V. Zane", "Aaron E. Kornblith", "Margaret J. Lin-Martore", "Jasmanpreet C. Kaur", "Vasuda M. Dokiparthi", "Bo Li", "Bin Yu"], "title": "CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents", "categories": ["cs.LG"], "comment": null, "summary": "Clinical decision-making is inherently complex and fast-paced, particularly\nin emergency departments (EDs) where critical, rapid and high-stakes decisions\nare made. Clinical Decision Rules (CDRs) are standardized evidence-based tools\nthat combine signs, symptoms, and clinical variables into decision trees to\nmake consistent and accurate diagnoses. CDR usage is often hindered by the\nclinician's cognitive load, limiting their ability to quickly recall and apply\nthe appropriate rules. We introduce CDR-Agent, a novel LLM-based system\ndesigned to enhance ED decision-making by autonomously identifying and applying\nthe most appropriate CDRs based on unstructured clinical notes. To validate\nCDR-Agent, we curated two novel ED datasets: synthetic and CDR-Bench, although\nCDR-Agent is applicable to non ED clinics. CDR-Agent achieves a 56.3\\%\n(synthetic) and 8.7\\% (CDR-Bench) accuracy gain relative to the standalone LLM\nbaseline in CDR selection. Moreover, CDR-Agent significantly reduces\ncomputational overhead. Using these datasets, we demonstrated that CDR-Agent\nnot only selects relevant CDRs efficiently, but makes cautious yet effective\nimaging decisions by minimizing unnecessary interventions while successfully\nidentifying most positively diagnosed cases, outperforming traditional LLM\nprompting approaches. Code for our work can be found at:\nhttps://github.com/zhenxianglance/medagent-cdr-agent", "AI": {"tldr": "\u4e34\u5e8a\u51b3\u7b56\u89c4\u5219\uff08CDR\uff09\u5728\u6025\u8bca\u79d1\uff08ED\uff09\u4e2d\u5e94\u7528\u53d7\u9650\u4e8e\u533b\u751f\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u7cfb\u7edfCDR-Agent\uff0c\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u548c\u5e94\u7528\u9002\u5f53\u7684CDRs\uff0c\u4ece\u800c\u63d0\u9ad8ED\u51b3\u7b56\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u9a8c\u8bc1\uff0cCDR-Agent\u663e\u8457\u63d0\u9ad8\u4e86CDR\u9009\u62e9\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u5e72\u9884\u5e76\u6210\u529f\u8bc6\u522b\u5927\u591a\u6570\u9633\u6027\u8bca\u65ad\u75c5\u4f8b\u3002", "motivation": "\u6025\u8bca\u79d1\u4e2d\u7684\u4e34\u5e8a\u51b3\u7b56\u590d\u6742\u4e14\u8282\u594f\u5feb\uff0c\u800c\u4e34\u5e8a\u51b3\u7b56\u89c4\u5219\uff08CDR\uff09\u867d\u7136\u6709\u52a9\u4e8e\u6807\u51c6\u5316\u8bca\u65ad\uff0c\u4f46\u5176\u4f7f\u7528\u5e38\u56e0\u533b\u751f\u8ba4\u77e5\u8d1f\u62c5\u8fc7\u91cd\u800c\u53d7\u5230\u9650\u5236\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u6765\u8f85\u52a9\u533b\u751f\u5feb\u901f\u3001\u51c6\u786e\u5730\u5e94\u7528CDRs\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aCDR-Agent\u7684\u65b0\u578b\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u4ece\u975e\u7ed3\u6784\u5316\u7684\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u81ea\u52a8\u8bc6\u522b\u5e76\u5e94\u7528\u6700\u5408\u9002\u7684CDRs\u3002\u4e3a\u9a8c\u8bc1\u8be5\u7cfb\u7edf\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\uff1asynthetic\u548cCDR-Bench\uff0c\u5e76\u4e0e\u72ec\u7acb\u7684LLM\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u76f8\u8f83\u4e8e\u72ec\u7acb\u7684LLM\u57fa\u7ebf\u6a21\u578b\uff0cCDR-Agent\u5728synthetic\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e8656.3%\u7684\u51c6\u786e\u7387\uff0c\u5728CDR-Bench\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e868.7%\u7684\u51c6\u786e\u7387\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u5728\u51cf\u5c11\u4e0d\u5fc5\u8981\u5e72\u9884\u7684\u540c\u65f6\u6210\u529f\u8bc6\u522b\u5927\u591a\u6570\u9633\u6027\u8bca\u65ad\u75c5\u4f8b\u3002", "conclusion": "CDR-Agent\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u53ef\u4ee5\u589e\u5f3a\u6025\u8bca\u79d1\u533b\u751f\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u63d0\u5347CDR\u9009\u62e9\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u4f18\u5316\u5f71\u50cf\u5b66\u51b3\u7b56\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u5e72\u9884\u3002"}}
{"id": "2505.23061", "pdf": "https://arxiv.org/pdf/2505.23061", "abs": "https://arxiv.org/abs/2505.23061", "authors": ["Tarun Suresh", "Debangshu Banerjee", "Shubham Ugare", "Sasa Misailovic", "Gagandeep Singh"], "title": "DINGO: Constrained Inference for Diffusion LLMs", "categories": ["cs.LG", "cs.PL", "cs.SE"], "comment": "DINGO an algorithm to provably apply constraints to diffusion LLM\n  generations", "summary": "Diffusion LLMs have emerged as a promising alternative to conventional\nautoregressive LLMs, offering significant potential for improved runtime\nefficiency. However, existing diffusion models lack the ability to provably\nenforce user-specified formal constraints, such as regular expressions, which\nmakes them unreliable for tasks that require structured outputs, such as\nfixed-schema JSON generation. Unlike autoregressive models that generate tokens\nsequentially, diffusion LLMs predict a block of tokens in parallel. This\nparallelism makes traditional constrained decoding algorithms, which are\ndesigned for sequential token prediction, ineffective at preserving the true\noutput distribution. To address this limitation, we propose DINGO, a dynamic\nprogramming-based constrained decoding strategy that is both efficient and\nprovably distribution-preserving. DINGO enables sampling of output strings with\nthe highest probability under the model's predicted distribution, while\nstrictly satisfying any user-specified regular expression. On standard symbolic\nmath and JSON generation benchmarks, DINGO achieves up to a 68 percentage point\nimprovement over unconstrained inference", "AI": {"tldr": "\u6269\u6563\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff08Diffusion LLMs\uff09\u5728\u8fd0\u884c\u65f6\u6548\u7387\u4e0a\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u5730\u6267\u884c\u7528\u6237\u6307\u5b9a\u7684\u6b63\u5f0f\u7ea6\u675f\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDINGO\u7684\u52a8\u6001\u89c4\u5212\u7ea6\u675f\u89e3\u7801\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u5728\u6807\u51c6\u7b26\u53f7\u6570\u5b66\u548cJSON\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u65e0\u6cd5\u53ef\u9760\u5730\u6267\u884c\u7528\u6237\u6307\u5b9a\u7684\u6b63\u5f0f\u7ea6\u675f\uff08\u5982\u6b63\u5219\u8868\u8fbe\u5f0f\uff09\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u9700\u8981\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86DINGO\uff0c\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u7ea6\u675f\u89e3\u7801\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u80fd\u591f\u9ad8\u6548\u4e14\u53ef\u8bc1\u660e\u5730\u4fdd\u6301\u5206\u5e03\u7279\u6027\u3002\u5b83\u5141\u8bb8\u5728\u4e25\u683c\u6ee1\u8db3\u4efb\u4f55\u7528\u6237\u6307\u5b9a\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u540c\u65f6\uff0c\u6839\u636e\u6a21\u578b\u9884\u6d4b\u7684\u5206\u5e03\u91c7\u6837\u6982\u7387\u6700\u9ad8\u7684\u8f93\u51fa\u5b57\u7b26\u4e32\u3002", "result": "\u5728\u6807\u51c6\u7b26\u53f7\u6570\u5b66\u548cJSON\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDINGO\u76f8\u8f83\u4e8e\u65e0\u7ea6\u675f\u63a8\u7406\u5b9e\u73b0\u4e86\u9ad8\u8fbe68\u4e2a\u767e\u5206\u70b9\u7684\u6539\u8fdb\u3002", "conclusion": "DINGO\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u89e3\u51b3\u6269\u6563LLMs\u5728\u751f\u6210\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u6761\u4ef6\u7684\u8f93\u51fa\u65f6\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76f8\u5173\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2505.23063", "pdf": "https://arxiv.org/pdf/2505.23063", "abs": "https://arxiv.org/abs/2505.23063", "authors": ["Denis Mamba Kabala", "Adel Hafiane", "Laurent Bobelin", "Raphael Canals"], "title": "Loss-Guided Model Sharing and Local Learning Correction in Decentralized Federated Learning for Crop Disease Classification", "categories": ["cs.LG"], "comment": null, "summary": "Crop disease detection and classification is a critical challenge in\nagriculture, with major implications for productivity, food security, and\nenvironmental sustainability. While deep learning models such as CNN and ViT\nhave shown excellent performance in classifying plant diseases from images,\ntheir large-scale deployment is often limited by data privacy concerns.\nFederated Learning (FL) addresses this issue, but centralized FL remains\nvulnerable to single-point failures and scalability limits. In this paper, we\nintroduce a novel Decentralized Federated Learning (DFL) framework that uses\nvalidation loss (Loss_val) both to guide model sharing between peers and to\ncorrect local training via an adaptive loss function controlled by weighting\nparameter. We conduct extensive experiments using PlantVillage datasets with\nthree deep learning architectures (ResNet50, VGG16, and ViT_B16), analyzing the\nimpact of weighting parameter, the number of shared models, the number of\nclients, and the use of Loss_val versus Loss_train of other clients. Results\ndemonstrate that our DFL approach not only improves accuracy and convergence\nspeed, but also ensures better generalization and robustness across\nheterogeneous data environments making it particularly well-suited for\nprivacy-preserving agricultural applications.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u4f5c\u7269\u75c5\u5bb3\u68c0\u6d4b\u548c\u5206\u7c7b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9a8c\u8bc1\u635f\u5931\u6307\u5bfc\u6a21\u578b\u5171\u4eab\u5e76\u6539\u8fdb\u672c\u5730\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u9002\u5408\u9690\u79c1\u4fdd\u62a4\u7684\u519c\u4e1a\u5e94\u7528\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5982CNN\u548cViT\u5728\u4ece\u56fe\u50cf\u4e2d\u5206\u7c7b\u690d\u7269\u75be\u75c5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u5927\u89c4\u6a21\u90e8\u7f72\u53d7\u5230\u9650\u5236\u3002\u5c3d\u7ba1\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u96c6\u4e2d\u5f0fFL\u4ecd\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u6846\u67b6\uff0c\u5229\u7528\u9a8c\u8bc1\u635f\u5931\uff08Loss_val\uff09\u6765\u5f15\u5bfc\u540c\u884c\u4e4b\u95f4\u7684\u6a21\u578b\u5171\u4eab\uff0c\u5e76\u901a\u8fc7\u7531\u52a0\u6743\u53c2\u6570\u63a7\u5236\u7684\u81ea\u9002\u5e94\u635f\u5931\u51fd\u6570\u4fee\u6b63\u672c\u5730\u8bad\u7ec3\u3002\u4f7f\u7528PlantVillage\u6570\u636e\u96c6\u548c\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08ResNet50\u3001VGG16\u548cViT_B16\uff09\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u52a0\u6743\u53c2\u6570\u3001\u5171\u4eab\u6a21\u578b\u6570\u91cf\u3001\u5ba2\u6237\u7aef\u6570\u91cf\u4ee5\u53ca\u4f7f\u7528Loss_val\u4e0eLoss_train\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDFL\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\uff0c\u8fd8\u786e\u4fdd\u4e86\u5728\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\u7684\u66f4\u597d\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684DFL\u6846\u67b6\u5728\u9690\u79c1\u4fdd\u62a4\u7684\u519c\u4e1a\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u7279\u522b\u9002\u5408\u89e3\u51b3\u4f5c\u7269\u75c5\u5bb3\u68c0\u6d4b\u548c\u5206\u7c7b\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.23071", "pdf": "https://arxiv.org/pdf/2505.23071", "abs": "https://arxiv.org/abs/2505.23071", "authors": ["Peizheng Guo", "Jingyao Wang", "Huijie Guo", "Jiangmeng Li", "Chuxiong Sun", "Changwen Zheng", "Wenwen Qiang"], "title": "Multi-Modal Learning with Bayesian-Oriented Gradient Calibration", "categories": ["cs.LG"], "comment": null, "summary": "Multi-Modal Learning (MML) integrates information from diverse modalities to\nimprove predictive accuracy. However, existing methods mainly aggregate\ngradients with fixed weights and treat all dimensions equally, overlooking the\nintrinsic gradient uncertainty of each modality. This may lead to (i) excessive\nupdates in sensitive dimensions, degrading performance, and (ii) insufficient\nupdates in less sensitive dimensions, hindering learning. To address this\nissue, we propose BOGC-MML, a Bayesian-Oriented Gradient Calibration method for\nMML to explicitly model the gradient uncertainty and guide the model\noptimization towards the optimal direction. Specifically, we first model each\nmodality's gradient as a random variable and derive its probability\ndistribution, capturing the full uncertainty in the gradient space. Then, we\npropose an effective method that converts the precision (inverse variance) of\neach gradient distribution into a scalar evidence. This evidence quantifies the\nconfidence of each modality in every gradient dimension. Using these evidences,\nwe explicitly quantify per-dimension uncertainties and fuse them via a reduced\nDempster-Shafer rule. The resulting uncertainty-weighted aggregation produces a\ncalibrated update direction that balances sensitivity and conservatism across\ndimensions. Extensive experiments on multiple benchmark datasets demonstrate\nthe effectiveness and advantages of the proposed method.", "AI": {"tldr": "Multi-Modal Learning (MML) \u901a\u8fc7\u6574\u5408\u4e0d\u540c\u6a21\u6001\u7684\u4fe1\u606f\u6765\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4ee5\u56fa\u5b9a\u6743\u91cd\u805a\u5408\u68af\u5ea6\u5e76\u5e73\u7b49\u5bf9\u5f85\u6240\u6709\u7ef4\u5ea6\uff0c\u5ffd\u7565\u4e86\u6bcf\u79cd\u6a21\u6001\u7684\u5185\u5728\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u7ef4\u5ea6\u8fc7\u5ea6\u66f4\u65b0\u548c\u975e\u654f\u611f\u7ef4\u5ea6\u66f4\u65b0\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86BOGC-MML\uff0c\u4e00\u79cd\u8d1d\u53f6\u65af\u5bfc\u5411\u7684\u68af\u5ea6\u6821\u51c6\u65b9\u6cd5\uff0c\u7528\u4e8e\u663e\u5f0f\u5efa\u6a21\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u5e76\u5f15\u5bfc\u6a21\u578b\u4f18\u5316\u5230\u6700\u4f18\u65b9\u5411\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9996\u5148\u5c06\u6bcf\u4e2a\u6a21\u6001\u7684\u68af\u5ea6\u5efa\u6a21\u4e3a\u968f\u673a\u53d8\u91cf\uff0c\u5e76\u63a8\u5bfc\u5176\u6982\u7387\u5206\u5e03\uff0c\u6355\u6349\u68af\u5ea6\u7a7a\u95f4\u4e2d\u7684\u5168\u90e8\u4e0d\u786e\u5b9a\u6027\u3002\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u68af\u5ea6\u5206\u5e03\u7684\u7cbe\u5ea6\uff08\u65b9\u5dee\u7684\u5012\u6570\uff09\u8f6c\u6362\u4e3a\u6807\u91cf\u8bc1\u636e\uff0c\u8be5\u8bc1\u636e\u91cf\u5316\u4e86\u6bcf\u4e2a\u6a21\u6001\u5728\u6bcf\u4e2a\u68af\u5ea6\u7ef4\u5ea6\u4e0a\u7684\u7f6e\u4fe1\u5ea6\u3002\u4f7f\u7528\u8fd9\u4e9b\u8bc1\u636e\uff0c\u663e\u5f0f\u91cf\u5316\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u7b80\u5316\u7684Dempster-Shafer\u89c4\u5219\u8fdb\u884c\u878d\u5408\u3002\u6700\u7ec8\u5f97\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u805a\u5408\u4ea7\u751f\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u6821\u51c6\u7684\u66f4\u65b0\u65b9\u5411\uff0c\u5728\u5404\u4e2a\u7ef4\u5ea6\u4e0a\u5e73\u8861\u4e86\u654f\u611f\u6027\u548c\u4fdd\u5b88\u6027\u3002\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u4ee5\u56fa\u5b9a\u6743\u91cd\u805a\u5408\u68af\u5ea6\u5e76\u5e73\u7b49\u5bf9\u5f85\u6240\u6709\u7ef4\u5ea6\uff0c\u5ffd\u7565\u4e86\u6bcf\u79cd\u6a21\u6001\u7684\u5185\u5728\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u7ef4\u5ea6\u8fc7\u5ea6\u66f4\u65b0\u548c\u975e\u654f\u611f\u7ef4\u5ea6\u66f4\u65b0\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4ece\u800c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "1. \u5c06\u6bcf\u4e2a\u6a21\u6001\u7684\u68af\u5ea6\u5efa\u6a21\u4e3a\u968f\u673a\u53d8\u91cf\u5e76\u63a8\u5bfc\u5176\u6982\u7387\u5206\u5e03\uff0c\u6355\u6349\u68af\u5ea6\u7a7a\u95f4\u4e2d\u7684\u5168\u90e8\u4e0d\u786e\u5b9a\u6027\u3002\n2. \u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u68af\u5ea6\u5206\u5e03\u7684\u7cbe\u5ea6\uff08\u65b9\u5dee\u7684\u5012\u6570\uff09\u8f6c\u6362\u4e3a\u6807\u91cf\u8bc1\u636e\uff0c\u8be5\u8bc1\u636e\u91cf\u5316\u4e86\u6bcf\u4e2a\u6a21\u6001\u5728\u6bcf\u4e2a\u68af\u5ea6\u7ef4\u5ea6\u4e0a\u7684\u7f6e\u4fe1\u5ea6\u3002\n3. \u4f7f\u7528\u8fd9\u4e9b\u8bc1\u636e\uff0c\u663e\u5f0f\u91cf\u5316\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u7b80\u5316\u7684Dempster-Shafer\u89c4\u5219\u8fdb\u884c\u878d\u5408\u3002\n4. \u6700\u7ec8\u5f97\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u805a\u5408\u4ea7\u751f\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u6821\u51c6\u7684\u66f4\u65b0\u65b9\u5411\uff0c\u5728\u5404\u4e2a\u7ef4\u5ea6\u4e0a\u5e73\u8861\u4e86\u654f\u611f\u6027\u548c\u4fdd\u5b88\u6027\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002BOGC-MML \u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "BOGC-MML \u662f\u4e00\u79cd\u6709\u6548\u7684\u8d1d\u53f6\u65af\u5bfc\u5411\u7684\u68af\u5ea6\u6821\u51c6\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u5f0f\u5efa\u6a21\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u5e76\u5f15\u5bfc\u591a\u6a21\u6001\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u5230\u6700\u4f18\u65b9\u5411\u3002\u5b83\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u805a\u5408\u5e73\u8861\u4e86\u68af\u5ea6\u66f4\u65b0\u7684\u654f\u611f\u6027\u548c\u4fdd\u5b88\u6027\uff0c\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2505.23084", "pdf": "https://arxiv.org/pdf/2505.23084", "abs": "https://arxiv.org/abs/2505.23084", "authors": ["Chang Yu", "Fang Liu", "Jie Zhu", "Shaobo Guo", "Yifan Gao", "Zhongheng Yang", "Meiwei Liu", "Qianwen Xing"], "title": "Gradient Boosting Decision Tree with LSTM for Investment Prediction", "categories": ["cs.LG"], "comment": "This paper have been accepted by IEEE confulence", "summary": "This paper proposes a hybrid framework combining LSTM (Long Short-Term\nMemory) networks with LightGBM and CatBoost for stock price prediction. The\nframework processes time-series financial data and evaluates performance using\nseven models: Artificial Neural Networks (ANNs), Convolutional Neural Networks\n(CNNs), Bidirectional LSTM (BiLSTM), vanilla LSTM, XGBoost, LightGBM, and\nstandard Neural Networks (NNs). Key metrics, including MAE, R-squared, MSE, and\nRMSE, are used to establish benchmarks across different time scales.\n  Building on these benchmarks, we develop an ensemble model that combines the\nstrengths of sequential and tree-based approaches. Experimental results show\nthat the proposed framework improves accuracy by 10 to 15 percent compared to\nindividual models and reduces error during market changes. This study\nhighlights the potential of ensemble methods for financial forecasting and\nprovides a flexible design for integrating new machine learning techniques.", "AI": {"tldr": "The paper proposes a hybrid framework combining LSTM with LightGBM and CatBoost for stock price prediction.", "motivation": "To improve the accuracy of stock price prediction by leveraging the strengths of sequential models (LSTM) and tree-based models (LightGBM, CatBoost).", "method": "A hybrid framework that processes time-series financial data using LSTM, LightGBM, and CatBoost. Performance is evaluated via seven models including ANNs, CNNs, BiLSTM, vanilla LSTM, XGBoost, LightGBM, and standard NNs. An ensemble model combining these methods is developed to further enhance performance.", "result": "The proposed framework improves accuracy by 10-15% compared to individual models and reduces error during market changes.", "conclusion": "Ensemble methods show significant potential for financial forecasting, providing a flexible design for integrating new machine learning techniques."}}
{"id": "2505.23094", "pdf": "https://arxiv.org/pdf/2505.23094", "abs": "https://arxiv.org/abs/2505.23094", "authors": ["Chongjie Si", "Zhiyi Shi", "Yadao Wang", "Xiaokang Yang", "Susanto Rahardja", "Wei Shen"], "title": "MAP: Revisiting Weight Decomposition for Low-Rank Adaptation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The rapid development of large language models has revolutionized natural\nlanguage processing, but their fine-tuning remains computationally expensive,\nhindering broad deployment. Parameter-efficient fine-tuning (PEFT) methods,\nsuch as LoRA, have emerged as solutions. Recent work like DoRA attempts to\nfurther decompose weight adaptation into direction and magnitude components.\nHowever, existing formulations often define direction heuristically at the\ncolumn level, lacking a principled geometric foundation. In this paper, we\npropose MAP, a novel framework that reformulates weight matrices as\nhigh-dimensional vectors and decouples their adaptation into direction and\nmagnitude in a rigorous manner. MAP normalizes the pre-trained weights, learns\na directional update, and introduces two scalar coefficients to independently\nscale the magnitude of the base and update vectors. This design enables more\ninterpretable and flexible adaptation, and can be seamlessly integrated into\nexisting PEFT methods. Extensive experiments show that MAP significantly\nimproves performance when coupling with existing methods, offering a simple yet\npowerful enhancement to existing PEFT methods. Given the universality and\nsimplicity of MAP, we hope it can serve as a default setting for designing\nfuture PEFT methods.", "AI": {"tldr": "The paper introduces MAP, a novel framework that reformulates weight matrices as high-dimensional vectors and decouples their adaptation into direction and magnitude, improving performance when integrated with existing PEFT methods.", "motivation": "Existing PEFT methods lack a principled geometric foundation for defining direction in weight adaptation.", "method": "MAP normalizes pre-trained weights, learns a directional update, and introduces two scalar coefficients to independently scale the magnitude of the base and update vectors.", "result": "Extensive experiments demonstrate that MAP significantly enhances the performance of existing PEFT methods.", "conclusion": "MAP is a simple yet powerful enhancement to PEFT methods and could serve as a default setting for designing future methods."}}
{"id": "2505.23098", "pdf": "https://arxiv.org/pdf/2505.23098", "abs": "https://arxiv.org/abs/2505.23098", "authors": ["Kuan Xu", "Zhiguang Cao", "Chenlong Zheng", "Linong Liu"], "title": "Learning to Search for Vehicle Routing with Multiple Time Windows", "categories": ["cs.LG"], "comment": null, "summary": "In this study, we propose a reinforcement learning-based adaptive variable\nneighborhood search (RL-AVNS) method designed for effectively solving the\nVehicle Routing Problem with Multiple Time Windows (VRPMTW). Unlike traditional\nadaptive approaches that rely solely on historical operator performance, our\nmethod integrates a reinforcement learning framework to dynamically select\nneighborhood operators based on real-time solution states and learned\nexperience. We introduce a fitness metric that quantifies customers' temporal\nflexibility to improve the shaking phase, and employ a transformer-based neural\npolicy network to intelligently guide operator selection during the local\nsearch. Extensive computational experiments are conducted on realistic\nscenarios derived from the replenishment of unmanned vending machines,\ncharacterized by multiple clustered replenishment windows. Results demonstrate\nthat RL-AVNS significantly outperforms traditional variable neighborhood search\n(VNS), adaptive VNS (AVNS), and state-of-the-art learning-based heuristics,\nachieving substantial improvements in solution quality and computational\nefficiency across various instance scales and time window complexities.\nParticularly notable is the algorithm's capability to generalize effectively to\nproblem instances not encountered during training, underscoring its practical\nutility for complex logistics scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u53d8\u9886\u57df\u641c\u7d22\uff08RL-AVNS\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5e26\u591a\u65f6\u95f4\u7a97\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08VRPMTW\uff09\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u89c4\u6a21\u5b9e\u4f8b\u548c\u65f6\u95f4\u7a97\u590d\u6742\u5ea6\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u81ea\u9002\u5e94\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5386\u53f2\u7b97\u5b50\u6027\u80fd\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u800c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u52a8\u6001\u9009\u62e9\u90bb\u57df\u7b97\u5b50\uff0c\u4ee5\u63d0\u9ad8\u6c42\u89e3\u5e26\u591a\u65f6\u95f4\u7a97\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86RL-AVNS\u65b9\u6cd5\uff0c\u5f15\u5165\u4e86\u91cf\u5316\u5ba2\u6237\u65f6\u95f4\u7075\u6d3b\u6027\u7684\u9002\u5e94\u5ea6\u6307\u6807\u4ee5\u6539\u8fdb\u9707\u8361\u9636\u6bb5\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7b56\u7565\u7f51\u7edc\u667a\u80fd\u5f15\u5bfc\u5c40\u90e8\u641c\u7d22\u4e2d\u7684\u7b97\u5b50\u9009\u62e9\u3002", "result": "RL-AVNS\u5728\u5404\u79cd\u5b9e\u4f8b\u89c4\u6a21\u548c\u65f6\u95f4\u7a97\u590d\u6742\u5ea6\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u53d8\u9886\u57df\u641c\u7d22\uff08VNS\uff09\u3001\u81ea\u9002\u5e94VNS\uff08AVNS\uff09\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u540c\u65f6\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RL-AVNS\u65b9\u6cd5\u5728\u6c42\u89e3VRPMTW\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u89e3\u7684\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u8fd8\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u95ee\u9898\u5b9e\u4f8b\u7684\u6709\u6548\u6cdb\u5316\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.23099", "pdf": "https://arxiv.org/pdf/2505.23099", "abs": "https://arxiv.org/abs/2505.23099", "authors": ["Chongjie Si", "Xuankun Yang", "Muqing Liu", "Yadao Wang", "Xiaokang Yang", "Wenbo Su", "Bo Zheng", "Wei Shen"], "title": "Weight Spectra Induced Efficient Model Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "Large-scale foundation models have demonstrated remarkable versatility across\na wide range of downstream tasks. However, fully fine-tuning these models\nincurs prohibitive computational costs, motivating the development of\nParameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces\nlow-rank updates to pre-trained weights. Despite their empirical success, the\nunderlying mechanisms by which PEFT modifies model parameters remain\nunderexplored. In this work, we present a systematic investigation into the\nstructural changes of weight matrices during fully fine-tuning. Through\nsingular value decomposition (SVD), we reveal that fine-tuning predominantly\namplifies the top singular values while leaving the remainder largely intact,\nsuggesting that task-specific knowledge is injected into a low-dimensional\nsubspace. Furthermore, we find that the dominant singular vectors are\nreoriented in task-specific directions, whereas the non-dominant subspace\nremains stable. Building on these insights, we propose a novel method that\nleverages learnable rescaling of top singular directions, enabling precise\nmodulation of the most influential components without disrupting the global\nstructure. Our approach achieves consistent improvements over strong baselines\nacross multiple tasks, highlighting the efficacy of structurally informed\nfine-tuning.", "AI": {"tldr": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b8c\u5168\u5fae\u8c03\u8fd9\u4e9b\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\u5982LoRA\uff0c\u5e76\u901a\u8fc7SVD\u5206\u6790\u63ed\u793a\u4e86\u5fae\u8c03\u4e3b\u8981\u653e\u5927\u4e86\u6743\u91cd\u77e9\u9635\u7684\u9876\u7ea7\u5947\u5f02\u503c\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u5b66\u4e60\u91cd\u65b0\u7f29\u653e\u9876\u7ea7\u5947\u5f02\u65b9\u5411\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u5b8c\u5168\u5fae\u8c03\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\u5e76\u7406\u89e3\u5176\u4fee\u6539\u6a21\u578b\u53c2\u6570\u7684\u6f5c\u5728\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5bf9\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\uff0c\u7814\u7a76\u7ed3\u6784\u53d8\u5316\uff0c\u53d1\u73b0\u5fae\u8c03\u4e3b\u8981\u653e\u5927\u9876\u7ea7\u5947\u5f02\u503c\uff0c\u5e76\u4f7f\u4e3b\u5bfc\u5947\u5f02\u5411\u91cf\u91cd\u65b0\u5b9a\u5411\u5230\u4efb\u52a1\u7279\u5b9a\u65b9\u5411\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u53ef\u5b66\u4e60\u91cd\u65b0\u7f29\u653e\u9876\u7ea7\u5947\u5f02\u65b9\u5411\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u7834\u574f\u6574\u4f53\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u7cbe\u786e\u8c03\u6574\u6700\u5177\u5f71\u54cd\u529b\u7684\u7ec4\u4ef6\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5bf9\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u4fe1\u606f\u6307\u5bfc\u7684\u5fae\u8c03\u65b9\u6cd5\u662f\u6709\u6548\u7684\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2505.23105", "pdf": "https://arxiv.org/pdf/2505.23105", "abs": "https://arxiv.org/abs/2505.23105", "authors": ["Abhishek Vijaya Kumar", "Eric Ding", "Arjun Devraj", "Darius Bunandar", "Rachee Singh"], "title": "LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "When accelerators fail in modern ML datacenters, operators migrate the\naffected ML training or inference jobs to entirely new racks. This approach,\nwhile preserving network performance, is highly inefficient, requiring\ndatacenters to reserve full racks of idle accelerators for fault tolerance. In\nthis paper, we address this resource inefficiency by introducing LUMION, a\nnovel reconfigurable optical fabric for connecting accelerators within a\ndatacenter rack. Instead of migrating entire ML jobs, LUMION dynamically\nintegrates spare accelerators into ongoing workloads as failures occur, thereby\nmaintaining consistent performance without costly migrations. We show the\nbenefits of LUMION by building an end-to-end hardware prototype. Our\nexperiments fine-tune Llama 3.2 and show that LUMION swaps a failed GPU with a\nhealthy one and restarts the ML job within ~ 1 second of the failure. LUMION\nachieves higher inter-GPU bandwidth compared to traditional electrical racks\nafter replacing failed accelerators with spare ones, leading to nearly 2X\nimprovement in fine-tuning throughput.", "AI": {"tldr": "\u5728\u73b0\u4ee3ML\u6570\u636e\u4e2d\u5fc3\uff0c\u52a0\u901f\u5668\u6545\u969c\u65f6\u901a\u5e38\u5c06\u53d7\u5f71\u54cd\u7684\u8bad\u7ec3\u6216\u63a8\u7406\u4efb\u52a1\u8fc1\u79fb\u5230\u5168\u65b0\u673a\u67b6\uff0c\u867d\u7136\u4fdd\u8bc1\u4e86\u7f51\u7edc\u6027\u80fd\u4f46\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u6587\u63d0\u51faLUMION\uff0c\u4e00\u79cd\u65b0\u578b\u53ef\u91cd\u6784\u5149\u5b66\u7ed3\u6784\uff0c\u7528\u4e8e\u8fde\u63a5\u6570\u636e\u4e2d\u5fc3\u673a\u67b6\u5185\u7684\u52a0\u901f\u5668\u3002LUMION\u901a\u8fc7\u52a8\u6001\u6574\u5408\u5907\u7528\u52a0\u901f\u5668\u5230\u73b0\u6709\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u4efb\u52a1\u8fc1\u79fb\uff0c\u5e76\u4fdd\u6301\u6027\u80fd\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLUMION\u53ef\u5728\u7ea61\u79d2\u5185\u66ff\u6362\u6545\u969cGPU\u5e76\u91cd\u542f\u4efb\u52a1\uff0c\u76f8\u6bd4\u4f20\u7edf\u7535\u5b66\u673a\u67b6\u63d0\u5347\u4e86\u8fd12\u500d\u7684\u5fae\u8c03\u541e\u5410\u91cf\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u4e2d\u5fc3\u5728\u52a0\u901f\u5668\u6545\u969c\u65f6\u91c7\u7528\u7684\u4efb\u52a1\u8fc1\u79fb\u65b9\u6cd5\u867d\u7136\u80fd\u4fdd\u8bc1\u7f51\u7edc\u6027\u80fd\uff0c\u4f46\u9700\u8981\u9884\u7559\u5b8c\u6574\u7684\u7a7a\u95f2\u673a\u67b6\u4f5c\u4e3a\u5bb9\u9519\u8d44\u6e90\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u52a0\u901f\u5668\u6545\u969c\u95ee\u9898\u3002", "method": "\u5f15\u5165LUMION\uff0c\u4e00\u79cd\u65b0\u578b\u53ef\u91cd\u6784\u5149\u5b66\u7ed3\u6784\uff0c\u7528\u4e8e\u8fde\u63a5\u6570\u636e\u4e2d\u5fc3\u673a\u67b6\u5185\u7684\u52a0\u901f\u5668\u3002\u5f53\u52a0\u901f\u5668\u6545\u969c\u53d1\u751f\u65f6\uff0cLUMION\u80fd\u591f\u52a8\u6001\u5730\u5c06\u5907\u7528\u52a0\u901f\u5668\u6574\u5408\u5230\u6b63\u5728\u8fdb\u884c\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\uff0c\u800c\u65e0\u9700\u8fc1\u79fb\u6574\u4e2a\u4efb\u52a1\u3002\u901a\u8fc7\u6784\u5efa\u7aef\u5230\u7aef\u786c\u4ef6\u539f\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLUMION\u53ef\u4ee5\u5728\u7ea61\u79d2\u5185\u5b8c\u6210\u6545\u969cGPU\u7684\u66ff\u6362\u5e76\u91cd\u542f\u4efb\u52a1\uff0c\u540c\u65f6\u4e0e\u4f20\u7edf\u7535\u5b66\u673a\u67b6\u76f8\u6bd4\uff0c\u5728\u7528\u5907\u7528\u52a0\u901f\u5668\u66ff\u6362\u6545\u969c\u52a0\u901f\u5668\u540e\uff0cLUMION\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684GPU\u95f4\u5e26\u5bbd\uff0c\u4f7f\u5f97\u5fae\u8c03\u541e\u5410\u91cf\u51e0\u4e4e\u63d0\u9ad8\u4e86\u4e24\u500d\u3002", "conclusion": "LUMION\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5feb\u901f\u54cd\u5e94\u7684\u673a\u5236\uff0c\u80fd\u591f\u5728\u52a0\u901f\u5668\u6545\u969c\u65f6\u7ef4\u6301\u4efb\u52a1\u6027\u80fd\uff0c\u51cf\u5c11\u4efb\u52a1\u8fc1\u79fb\u6210\u672c\uff0c\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2505.23106", "pdf": "https://arxiv.org/pdf/2505.23106", "abs": "https://arxiv.org/abs/2505.23106", "authors": ["Ning Liu", "Yue Yu"], "title": "Neural Interpretable PDEs: Harmonizing Fourier Insights with Attention for Scalable and Interpretable Physics Discovery", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Attention mechanisms have emerged as transformative tools in core AI domains\nsuch as natural language processing and computer vision. Yet, their largely\nuntapped potential for modeling intricate physical systems presents a\ncompelling frontier. Learning such systems often entails discovering operators\nthat map between functional spaces using limited instances of function pairs --\na task commonly framed as a severely ill-posed inverse PDE problem. In this\nwork, we introduce Neural Interpretable PDEs (NIPS), a novel neural operator\narchitecture that builds upon and enhances Nonlocal Attention Operators (NAO)\nin both predictive accuracy and computational efficiency. NIPS employs a linear\nattention mechanism to enable scalable learning and integrates a learnable\nkernel network that acts as a channel-independent convolution in Fourier space.\nAs a consequence, NIPS eliminates the need to explicitly compute and store\nlarge pairwise interactions, effectively amortizing the cost of handling\nspatial interactions into the Fourier transform. Empirical evaluations\ndemonstrate that NIPS consistently surpasses NAO and other baselines across\ndiverse benchmarks, heralding a substantial leap in scalable, interpretable,\nand efficient physics learning. Our code and data accompanying this paper are\navailable at https://github.com/fishmoon1234/Nonlocal-Attention-Operator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b97\u5b50\u67b6\u6784NIPS\uff0c\u901a\u8fc7\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u548c\u53ef\u5b66\u4e60\u7684\u6838\u7f51\u7edc\uff0c\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u8d85\u8d8a\u4e86NAO\u548c\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\uff0c\u4e3a\u7269\u7406\u7cfb\u7edf\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u6ce8\u610f\u529b\u673a\u5236\u5728AI\u6838\u5fc3\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5efa\u6a21\u590d\u6742\u7269\u7406\u7cfb\u7edf\u65b9\u9762\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u6316\u6398\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u6620\u5c04\u529f\u80fd\u7a7a\u95f4\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u9006PDE\u95ee\u9898\u3002", "method": "\u5f15\u5165Neural Interpretable PDEs (NIPS)\uff0c\u5b83\u57fa\u4e8e\u5e76\u589e\u5f3a\u4e86Nonlocal Attention Operators (NAO)\uff0c\u4f7f\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u53ef\u6269\u5c55\u5b66\u4e60\uff0c\u5e76\u7ed3\u5408\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u6838\u7f51\u7edc\u4f5c\u4e3aFourier\u7a7a\u95f4\u4e2d\u7684\u901a\u9053\u65e0\u5173\u5377\u79ef\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e0\u9700\u663e\u5f0f\u8ba1\u7b97\u548c\u5b58\u50a8\u5927\u91cf\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u5c06\u5904\u7406\u7a7a\u95f4\u4ea4\u4e92\u7684\u6210\u672c\u5206\u644a\u5230Fourier\u53d8\u6362\u4e2d\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cNIPS\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8eNAO\u548c\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "NIPS\u6807\u5fd7\u7740\u5728\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u7269\u7406\u7cfb\u7edf\u5b66\u4e60\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\u3002"}}
{"id": "2505.23131", "pdf": "https://arxiv.org/pdf/2505.23131", "abs": "https://arxiv.org/abs/2505.23131", "authors": ["Xinyu Yao", "Daniel Bourgeois", "Abhinav Jain", "Yuxin Tang", "Jiawen Yao", "Zhimin Ding", "Arlei Silva", "Chris Jermaine"], "title": "DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs", "categories": ["cs.LG", "cs.DC"], "comment": "32 pages, 19 figures", "summary": "We study the problem of assigning operations in a dataflow graph to devices\nto minimize execution time in a work-conserving system, with emphasis on\ncomplex machine learning workloads. Prior learning-based methods often struggle\ndue to three key limitations: (1) reliance on bulk-synchronous systems like\nTensorFlow, which under-utilize devices due to barrier synchronization; (2)\nlack of awareness of the scheduling mechanism of underlying systems when\ndesigning learning-based methods; and (3) exclusive dependence on reinforcement\nlearning, ignoring the structure of effective heuristics designed by experts.\nIn this paper, we propose \\textsc{Doppler}, a three-stage framework for\ntraining dual-policy networks consisting of 1) a $\\mathsf{SEL}$ policy for\nselecting operations and 2) a $\\mathsf{PLC}$ policy for placing chosen\noperations on devices. Our experiments show that \\textsc{Doppler} outperforms\nall baseline methods across tasks by reducing system execution time and\nadditionally demonstrates sampling efficiency by reducing per-episode training\ntime.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDoppler\u7684\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u53cc\u7b56\u7565\u7f51\u7edc\uff08\u5305\u542b\u9009\u62e9\u64cd\u4f5c\u7684SEL\u7b56\u7565\u548c\u5c06\u9009\u5b9a\u64cd\u4f5c\u653e\u7f6e\u5728\u8bbe\u5907\u4e0a\u7684PLC\u7b56\u7565\uff09\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u6d41\u56fe\u4e2d\u64cd\u4f5c\u5230\u8bbe\u5907\u7684\u5206\u914d\u95ee\u9898\u3002\u901a\u8fc7\u51cf\u5c11\u7cfb\u7edf\u6267\u884c\u65f6\u95f4\u548c\u6bcf\u96c6\u8bad\u7ec3\u65f6\u95f4\uff0cDoppler\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u4f9d\u8d56\u4e8eTensorFlow\u7b49\u6279\u91cf\u540c\u6b65\u7cfb\u7edf\uff0c\u5bfc\u81f4\u8bbe\u5907\u5229\u7528\u7387\u4f4e\uff1b2) \u8bbe\u8ba1\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u65f6\u672a\u8003\u8651\u5e95\u5c42\u7cfb\u7edf\u7684\u8c03\u5ea6\u673a\u5236\uff1b3) \u8fc7\u5ea6\u4f9d\u8d56\u5f3a\u5316\u5b66\u4e60\uff0c\u5ffd\u7565\u4e86\u4e13\u5bb6\u8bbe\u8ba1\u7684\u6709\u6548\u542f\u53d1\u5f0f\u7ed3\u6784\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u540d\u4e3aDoppler\u7684\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u53cc\u7b56\u7565\u7f51\u7edc\uff1a1) SEL\u7b56\u7565\u7528\u4e8e\u9009\u62e9\u64cd\u4f5c\uff1b2) PLC\u7b56\u7565\u7528\u4e8e\u5c06\u9009\u5b9a\u7684\u64cd\u4f5c\u653e\u7f6e\u5728\u8bbe\u5907\u4e0a\u3002\u8be5\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u590d\u6742\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u6570\u636e\u6d41\u56fe\u64cd\u4f5c\u5206\u914d\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDoppler\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u7cfb\u7edf\u6267\u884c\u65f6\u95f4\uff0c\u5e76\u5c55\u793a\u4e86\u91c7\u6837\u6548\u7387\uff0c\u5373\u51cf\u5c11\u4e86\u6bcf\u96c6\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "Doppler\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u9009\u62e9\u548c\u653e\u7f6e\u7b56\u7565\uff0c\u5728\u4f18\u5316\u6570\u636e\u6d41\u56fe\u64cd\u4f5c\u5206\u914d\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u601d\u8def\u3002"}}
{"id": "2505.23150", "pdf": "https://arxiv.org/pdf/2505.23150", "abs": "https://arxiv.org/abs/2505.23150", "authors": ["Michal Nauman", "Marek Cygan", "Carmelo Sferrazza", "Aviral Kumar", "Pieter Abbeel"], "title": "Bigger, Regularized, Categorical: High-Capacity Value Functions are Efficient Multi-Task Learners", "categories": ["cs.LG"], "comment": "preprint", "summary": "Recent advances in language modeling and vision stem from training large\nmodels on diverse, multi-task data. This paradigm has had limited impact in\nvalue-based reinforcement learning (RL), where improvements are often driven by\nsmall models trained in a single-task context. This is because in multi-task RL\nsparse rewards and gradient conflicts make optimization of temporal difference\nbrittle. Practical workflows for generalist policies therefore avoid online\ntraining, instead cloning expert trajectories or distilling collections of\nsingle-task policies into one agent. In this work, we show that the use of\nhigh-capacity value models trained via cross-entropy and conditioned on\nlearnable task embeddings addresses the problem of task interference in online\nRL, allowing for robust and scalable multi-task training. We test our approach\non 7 multi-task benchmarks with over 280 unique tasks, spanning high\ndegree-of-freedom humanoid control and discrete vision-based RL. We find that,\ndespite its simplicity, the proposed approach leads to state-of-the-art single\nand multi-task performance, as well as sample-efficient transfer to new tasks.", "AI": {"tldr": "\u8fd1\u671f\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u89c6\u89c9\u65b9\u9762\u7684\u8fdb\u5c55\u6e90\u4e8e\u5bf9\u591a\u6837\u5316\u3001\u591a\u4efb\u52a1\u6570\u636e\u7684\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u7684\u8fd9\u4e00\u8303\u5f0f\u5f71\u54cd\u6709\u9650\uff0c\u56e0\u4e3a\u6539\u8fdb\u901a\u5e38\u7531\u5355\u4efb\u52a1\u73af\u5883\u4e0b\u8bad\u7ec3\u7684\u5c0f\u578b\u6a21\u578b\u9a71\u52a8\u3002\u8fd9\u662f\u56e0\u4e3a\u5728\u591a\u4efb\u52a1RL\u4e2d\uff0c\u7a00\u758f\u5956\u52b1\u548c\u68af\u5ea6\u51b2\u7a81\u4f7f\u5f97\u65f6\u95f4\u5dee\u5206\u4f18\u5316\u53d8\u5f97\u8106\u5f31\u3002\u56e0\u6b64\uff0c\u901a\u7528\u7b56\u7565\u7684\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u907f\u514d\u4e86\u5728\u7ebf\u8bad\u7ec3\uff0c\u800c\u662f\u514b\u9686\u4e13\u5bb6\u8f68\u8ff9\u6216\u5c06\u591a\u4e2a\u5355\u4efb\u52a1\u7b56\u7565\u84b8\u998f\u5230\u4e00\u4e2a\u4ee3\u7406\u4e2d\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4f7f\u7528\u901a\u8fc7\u4ea4\u53c9\u71b5\u8bad\u7ec3\u7684\u9ad8\u5bb9\u91cf\u4ef7\u503c\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u53ef\u5b66\u4e60\u7684\u4efb\u52a1\u5d4c\u5165\u6765\u89e3\u51b3\u5728\u7ebfRL\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u3002\u6211\u4eec\u5728\u5305\u542b\u8d85\u8fc7280\u4e2a\u72ec\u7279\u4efb\u52a1\u76847\u4e2a\u591a\u4efb\u52a1\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u6db5\u76d6\u4e86\u9ad8\u81ea\u7531\u5ea6\u7684\u4eba\u5f62\u63a7\u5236\u548c\u79bb\u6563\u89c6\u89c9\u57fa\u7840RL\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u5c3d\u7ba1\u65b9\u6cd5\u7b80\u5355\uff0c\u4f46\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5355\u4efb\u52a1\u548c\u591a\u4efb\u52a1\u6027\u80fd\u4ee5\u53ca\u6837\u672c\u9ad8\u6548\u7684\u8f6c\u79fb\u5230\u65b0\u4efb\u52a1\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "motivation": "\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u9762\u4e34\u7a00\u758f\u5956\u52b1\u548c\u68af\u5ea6\u51b2\u7a81\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u65f6\u95f4\u5dee\u5206\u4f18\u5316\u53d8\u5f97\u8106\u5f31\u3002\u73b0\u6709\u7684\u901a\u7528\u7b56\u7565\u5de5\u4f5c\u6d41\u7a0b\u901a\u5e38\u907f\u514d\u5728\u7ebf\u8bad\u7ec3\uff0c\u800c\u662f\u4f9d\u8d56\u4e8e\u4e13\u5bb6\u8f68\u8ff9\u7684\u514b\u9686\u6216\u5355\u4efb\u52a1\u7b56\u7565\u7684\u84b8\u998f\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u4e00\u79cd\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4efb\u52a1\u5e72\u6270\u5e76\u652f\u6301\u5728\u7ebf\u591a\u4efb\u52a1\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u91c7\u7528\u9ad8\u5bb9\u91cf\u7684\u4ef7\u503c\u6a21\u578b\u5e76\u901a\u8fc7\u4ea4\u53c9\u71b5\u8fdb\u884c\u8bad\u7ec3\uff0c\u540c\u65f6\u7ed3\u5408\u53ef\u5b66\u4e60\u7684\u4efb\u52a1\u5d4c\u5165\u6765\u5e94\u5bf9\u591a\u4efb\u52a1RL\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u6a21\u578b\u5728\u5728\u7ebf\u73af\u5883\u4e2d\u8fdb\u884c\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u57287\u4e2a\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6db5\u76d6\u8d85\u8fc7280\u4e2a\u72ec\u7279\u4efb\u52a1\u3002\u5b83\u4e0d\u4ec5\u5728\u5355\u4efb\u52a1\u548c\u591a\u4efb\u52a1\u6027\u80fd\u4e0a\u8fbe\u5230\u5148\u8fdb\u6c34\u5e73\uff0c\u800c\u4e14\u5728\u8f6c\u79fb\u5230\u65b0\u4efb\u52a1\u65f6\u4e5f\u8868\u73b0\u51fa\u6837\u672c\u9ad8\u6548\u7684\u7279\u6027\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u9ad8\u5bb9\u91cf\u4ef7\u503c\u6a21\u578b\u548c\u4efb\u52a1\u5d4c\u5165\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u591a\u4efb\u52a1RL\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u5f3a\u5927\u7684\u5728\u7ebf\u591a\u4efb\u52a1\u8bad\u7ec3\u3002\u6b64\u65b9\u6cd5\u7b80\u5355\u4f46\u6548\u679c\u663e\u8457\uff0c\u4e3a\u672a\u6765\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23173", "pdf": "https://arxiv.org/pdf/2505.23173", "abs": "https://arxiv.org/abs/2505.23173", "authors": ["Shohei Enomoto"], "title": "Pseudo Multi-Source Domain Generalization: Bridging the Gap Between Single and Multi-Source Domain Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Deep learning models often struggle to maintain performance when deployed on\ndata distributions different from their training data, particularly in\nreal-world applications where environmental conditions frequently change. While\nMulti-source Domain Generalization (MDG) has shown promise in addressing this\nchallenge by leveraging multiple source domains during training, its practical\napplication is limited by the significant costs and difficulties associated\nwith creating multi-domain datasets. To address this limitation, we propose\nPseudo Multi-source Domain Generalization (PMDG), a novel framework that\nenables the application of sophisticated MDG algorithms in more practical\nSingle-source Domain Generalization (SDG) settings. PMDG generates multiple\npseudo-domains from a single source domain through style transfer and data\naugmentation techniques, creating a synthetic multi-domain dataset that can be\nused with existing MDG algorithms. Through extensive experiments with\nPseudoDomainBed, our modified version of the DomainBed benchmark, we analyze\nthe effectiveness of PMDG across multiple datasets and architectures. Our\nanalysis reveals several key findings, including a positive correlation between\nMDG and PMDG performance and the potential of pseudo-domains to match or exceed\nactual multi-domain performance with sufficient data. These comprehensive\nempirical results provide valuable insights for future research in domain\ngeneralization. Our code is available at\nhttps://github.com/s-enmt/PseudoDomainBed.", "AI": {"tldr": "Deep learning models face challenges when deployed on different data distributions. Multi-source Domain Generalization (MDG) addresses this by using multiple source domains during training, but is limited by the difficulty of creating multi-domain datasets. This paper proposes Pseudo Multi-source Domain Generalization (PMDG), which generates multiple pseudo-domains from a single source domain through style transfer and data augmentation techniques, thus enabling the use of MDG algorithms in Single-source Domain Generalization (SDG) settings.", "motivation": "Deep learning models often perform poorly on data distributions different from their training data, especially in real-world applications where environmental conditions change frequently. Existing MDG methods require multi-domain datasets, which are difficult to create.", "method": "The proposed PMDG framework generates multiple pseudo-domains from a single source domain using style transfer and data augmentation techniques. These synthetic domains can then be used with existing MDG algorithms, effectively applying them in SDG settings.", "result": "Experiments using the modified benchmark PseudoDomainBed show that PMDG has a positive correlation with MDG performance. With sufficient data, pseudo-domains can match or exceed the performance of actual multi-domain datasets.", "conclusion": "PMDG provides a practical solution for applying MDG algorithms in SDG scenarios, overcoming the limitations of creating multi-domain datasets. The findings offer valuable insights for future research in domain generalization."}}
{"id": "2505.23176", "pdf": "https://arxiv.org/pdf/2505.23176", "abs": "https://arxiv.org/abs/2505.23176", "authors": ["Shiwei Li", "Xiandi Luo", "Haozhao Wang", "Xing Tang", "Shijie Xu", "Weihong Luo", "Yuhua Li", "Xiuqiang He", "Ruixuan Li"], "title": "The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by ICML 2025", "summary": "To improve the training efficiency of federated learning (FL), previous\nresearch has employed low-rank decomposition techniques to reduce communication\noverhead. In this paper, we seek to enhance the performance of these low-rank\ndecomposition methods. Specifically, we focus on three key issues related to\ndecomposition in FL: what to decompose, how to decompose, and how to aggregate.\nSubsequently, we introduce three novel techniques: Model Update Decomposition\n(MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware\nDecomposition (AAD), each targeting a specific issue. These techniques are\ncomplementary and can be applied simultaneously to achieve optimal performance.\nAdditionally, we provide a rigorous theoretical analysis to ensure the\nconvergence of the proposed MUD. Extensive experimental results show that our\napproach achieves faster convergence and superior accuracy compared to relevant\nbaseline methods. The code is available at\nhttps://github.com/Leopold1423/fedmud-icml25.", "AI": {"tldr": "\u4e3a\u4e86\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u4ee5\u5f80\u7814\u7a76\u91c7\u7528\u4f4e\u79e9\u5206\u89e3\u6280\u672f\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002\u672c\u6587\u9488\u5bf9\u5206\u89e3\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff08\u5206\u89e3\u4ec0\u4e48\u3001\u5982\u4f55\u5206\u89e3\u548c\u5982\u4f55\u805a\u5408\uff09\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u6280\u672f\uff1a\u6a21\u578b\u66f4\u65b0\u5206\u89e3\uff08MUD\uff09\u3001\u5757\u72b6Kronecker\u5206\u89e3\uff08BKD\uff09\u548c\u805a\u5408\u611f\u77e5\u5206\u89e3\uff08AAD\uff09\u3002\u8fd9\u4e9b\u6280\u672f\u4e92\u8865\u4e14\u53ef\u540c\u65f6\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u786e\u4fdd\u4e86MUD\u7684\u6536\u655b\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u4f4e\u79e9\u5206\u89e3\u6280\u672f\u867d\u80fd\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u73b0\u6709\u7684\u5206\u89e3\u65b9\u6cd5\u4ee5\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e09\u79cd\u6280\u672f\uff1a1) Model Update Decomposition (MUD)\uff0c\u89e3\u51b3\u201c\u5206\u89e3\u4ec0\u4e48\u201d\u7684\u95ee\u9898\uff1b2) Block-wise Kronecker Decomposition (BKD)\uff0c\u89e3\u51b3\u201c\u5982\u4f55\u5206\u89e3\u201d\u7684\u95ee\u9898\uff1b3) Aggregation-Aware Decomposition (AAD)\uff0c\u89e3\u51b3\u201c\u5982\u4f55\u805a\u5408\u201d\u7684\u95ee\u9898\u3002\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u534f\u540c\u5de5\u4f5c\u4ee5\u8fbe\u5230\u6700\u4f73\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86MUD\u7684\u7406\u8bba\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86MUD\u7684\u6536\u655b\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u6bd4\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684MUD\u3001BKD\u548cAAD\u4e09\u79cd\u6280\u672f\u6709\u6548\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u4f4e\u79e9\u5206\u89e3\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5728\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6536\u655b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2505.23182", "pdf": "https://arxiv.org/pdf/2505.23182", "abs": "https://arxiv.org/abs/2505.23182", "authors": ["Srijith Nair", "Michael Lin", "Amirreza Talebi", "Peizhong Ju", "Elizabeth Bentley", "Jia Liu"], "title": "FSL-SAGE: Accelerating Federated Split Learning via Smashed Activation Gradient Estimation", "categories": ["cs.LG"], "comment": "22 pages, 14 figures, Accepted at ICML 2025 as poster", "summary": "Collaborative training methods like Federated Learning (FL) and Split\nLearning (SL) enable distributed machine learning without sharing raw data.\nHowever, FL assumes clients can train entire models, which is infeasible for\nlarge-scale models. In contrast, while SL alleviates the client memory\nconstraint in FL by offloading most training to the server, it increases\nnetwork latency due to its sequential nature. Other methods address the\nconundrum by using local loss functions for parallel client-side training to\nimprove efficiency, but they lack server feedback and potentially suffer poor\naccuracy. We propose FSL-SAGE (Federated Split Learning via Smashed Activation\nGradient Estimation), a new federated split learning algorithm that estimates\nserver-side gradient feedback via auxiliary models. These auxiliary models\nperiodically adapt to emulate server behavior on local datasets. We show that\nFSL-SAGE achieves a convergence rate of $\\mathcal{O}(1/\\sqrt{T})$, where $T$ is\nthe number of communication rounds. This result matches FedAvg, while\nsignificantly reducing communication costs and client memory requirements. Our\nempirical results also verify that it outperforms existing state-of-the-art FSL\nmethods, offering both communication efficiency and accuracy.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23184", "pdf": "https://arxiv.org/pdf/2505.23184", "abs": "https://arxiv.org/abs/2505.23184", "authors": ["Hongcan Guo", "Guoshun Nan", "Yuan Yang", "Diyang Zhang", "Haotian Li", "Zhican Chen", "Qinchuan Zhou", "Yuhan Ran", "Xinye Cao", "Sicong Leng", "Xiaofeng Tao", "Xudong Jiang"], "title": "Two Is Better Than One: Rotations Scale LoRAs", "categories": ["cs.LG", "cs.SE", "68T50", "I.2.6"], "comment": "27pages, 16figures", "summary": "Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates\nlarge language models (LLMs) to efficiently adapt to diverse tasks. However,\ntraditional gating mechanisms that route inputs to the best experts may\nfundamentally hinder LLMs' scalability, leading to poor generalization and\nunderfitting issues. We identify that the root cause lies in the restricted\nexpressiveness of existing weighted-sum mechanisms, both within and outside the\nconvex cone of LoRA representations. This motivates us to propose RadarGate, a\nnovel geometrically inspired gating method that introduces rotational\noperations of LoRAs representations to boost the expressiveness and facilitate\nricher feature interactions among multiple LoRAs for scalable LLMs.\nSpecifically, we first fuse each LoRA representation to other LoRAs using a\nlearnable component and then feed the output to a rotation matrix. This matrix\ninvolves learnable parameters that define the relative angular relationship\nbetween LoRA representations. Such a simple yet effective mechanism provides an\nextra degree of freedom, facilitating the learning of cross-LoRA synergies and\nproperly tracking the challenging poor generalization and underfitting issues\nas the number of LoRA grows. Extensive experiments on 6 public benchmarks\nacross 21 tasks show the effectiveness of our RadarGate for scaling LoRAs. We\nalso provide valuable insights, revealing that the rotations to each pair of\nrepresentations are contrastive, encouraging closer alignment of semantically\nsimilar representations during geometrical transformation while pushing\ndistance ones further apart. We will release our code to the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRadarGate\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165LoRA\u8868\u793a\u7684\u65cb\u8f6c\u64cd\u4f5c\u6765\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6cdb\u5316\u5dee\u548c\u62df\u5408\u4e0d\u8db3\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u57286\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u768421\u9879\u4efb\u52a1\u4e2d\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u7684\u95e8\u63a7\u673a\u5236\u53ef\u80fd\u6839\u672c\u6027\u5730\u963b\u788d\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u62df\u5408\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5176\u6839\u6e90\u5728\u4e8e\u73b0\u6709\u52a0\u6743\u6c42\u548c\u673a\u5236\u7684\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u3002", "method": "RadarGate\u662f\u4e00\u79cd\u53d7\u51e0\u4f55\u542f\u53d1\u7684\u95e8\u63a7\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165LoRA\u8868\u793a\u7684\u65cb\u8f6c\u64cd\u4f5c\u6765\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9996\u5148\u4f7f\u7528\u53ef\u5b66\u4e60\u7ec4\u4ef6\u5c06\u6bcf\u4e2aLoRA\u8868\u793a\u4e0e\u5176\u4ed6LoRA\u878d\u5408\uff0c\u7136\u540e\u8f93\u5165\u5230\u4e00\u4e2a\u65cb\u8f6c\u77e9\u9635\u4e2d\uff0c\u8be5\u77e9\u9635\u5305\u542b\u5b9a\u4e49LoRA\u8868\u793a\u4e4b\u95f4\u76f8\u5bf9\u89d2\u5ea6\u5173\u7cfb\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRadarGate\u57286\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u768421\u9879\u4efb\u52a1\u4e2d\u6709\u6548\u5730\u6269\u5c55\u4e86LoRA\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u51e0\u4f55\u53d8\u6362\u8fc7\u7a0b\u4e2d\u8bed\u4e49\u76f8\u4f3c\u8868\u793a\u7684\u5bf9\u6bd4\u5bf9\u9f50\u73b0\u8c61\u3002", "conclusion": "RadarGate\u63d0\u4f9b\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u81ea\u7531\u5ea6\uff0c\u4fc3\u8fdb\u4e86\u8de8LoRA\u534f\u540c\u4f5c\u7528\u7684\u5b66\u4e60\uff0c\u5e76\u89e3\u51b3\u4e86\u968f\u7740LoRA\u6570\u91cf\u589e\u52a0\u800c\u51fa\u73b0\u7684\u6cdb\u5316\u548c\u62df\u5408\u95ee\u9898\u3002\u4ee3\u7801\u5c06\u5411\u793e\u533a\u5f00\u653e\u3002"}}
{"id": "2505.23185", "pdf": "https://arxiv.org/pdf/2505.23185", "abs": "https://arxiv.org/abs/2505.23185", "authors": ["Shahaf E. Finder", "Ron Shapira Weber", "Moshe Eliasof", "Oren Freifeld", "Eran Treister"], "title": "Improving the Effective Receptive Field of Message-Passing Neural Networks", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Message-Passing Neural Networks (MPNNs) have become a cornerstone for\nprocessing and analyzing graph-structured data. However, their effectiveness is\noften hindered by phenomena such as over-squashing, where long-range\ndependencies or interactions are inadequately captured and expressed in the\nMPNN output. This limitation mirrors the challenges of the Effective Receptive\nField (ERF) in Convolutional Neural Networks (CNNs), where the theoretical\nreceptive field is underutilized in practice. In this work, we show and\ntheoretically explain the limited ERF problem in MPNNs. Furthermore, inspired\nby recent advances in ERF augmentation for CNNs, we propose an Interleaved\nMultiscale Message-Passing Neural Networks (IM-MPNN) architecture to address\nthese problems in MPNNs. Our method incorporates a hierarchical coarsening of\nthe graph, enabling message-passing across multiscale representations and\nfacilitating long-range interactions without excessive depth or\nparameterization. Through extensive evaluations on benchmarks such as the\nLong-Range Graph Benchmark (LRGB), we demonstrate substantial improvements over\nbaseline MPNNs in capturing long-range dependencies while maintaining\ncomputational efficiency.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d7CNN\u4e2dERF\u589e\u5f3a\u8fdb\u5c55\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86IM-MPNN\u67b6\u6784\u6765\u89e3\u51b3MPNN\u4e2d\u7684\u6709\u9650ERF\u95ee\u9898\uff0c\u901a\u8fc7\u56fe\u7684\u5206\u5c42\u7c97\u5316\u4fc3\u8fdb\u957f\u7a0b\u4ea4\u4e92\uff0c\u5728LRGB\u7b49\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "MPNNs\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65f6\u9762\u4e34\u8fc7\u538b\u7f29\u95ee\u9898\uff0c\u7c7b\u4f3c\u4e8eCNN\u4e2d\u7684\u6709\u6548\u611f\u53d7\u91ce(ERF)\u95ee\u9898\uff0c\u5373\u7406\u8bba\u4e0a\u7684\u611f\u53d7\u91ce\u5728\u5b9e\u9645\u4e2d\u672a\u80fd\u88ab\u5145\u5206\u5229\u7528\u3002\u8fd9\u963b\u788d\u4e86\u5176\u6355\u6349\u548c\u8868\u8fbe\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u9519\u591a\u5c3a\u5ea6\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08IM-MPNN\uff09\u67b6\u6784\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u56fe\u7684\u5206\u5c42\u7c97\u5316\uff0c\u5141\u8bb8\u5728\u591a\u5c3a\u5ea6\u8868\u793a\u4e4b\u95f4\u8fdb\u884c\u6d88\u606f\u4f20\u9012\uff0c\u4ece\u800c\u5b9e\u73b0\u957f\u7a0b\u4ea4\u4e92\uff0c\u800c\u65e0\u9700\u8fc7\u591a\u7684\u6df1\u5ea6\u6216\u53c2\u6570\u5316\u3002", "result": "\u901a\u8fc7\u5728Long-Range Graph Benchmark (LRGB)\u7b49\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8868\u660eIM-MPNN\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\u3002", "conclusion": "IM-MPNN\u89e3\u51b3\u4e86MPNN\u4e2d\u7684\u6709\u9650ERF\u95ee\u9898\uff0c\u5e76\u4e3a\u56fe\u7ed3\u6784\u6570\u636e\u7684\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23190", "pdf": "https://arxiv.org/pdf/2505.23190", "abs": "https://arxiv.org/abs/2505.23190", "authors": ["Yekun Zhu", "Min Tang", "Zheng Ma"], "title": "DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer", "categories": ["cs.LG"], "comment": null, "summary": "In this study, we propose a novel neural network approach, termed DeepRTE, to\naddress the steady-state Radiative Transfer Equation (RTE). The RTE is a\ndifferential-integral equation that governs the propagation of radiation\nthrough a participating medium, with applications spanning diverse domains such\nas neutron transport, atmospheric radiative transfer, heat transfer, and\noptical imaging. Our proposed DeepRTE framework leverages pre-trained\nattention-based neural networks to solve the RTE with high accuracy and\ncomputational efficiency. The efficacy of the proposed approach is\nsubstantiated through comprehensive numerical experiments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeepRTE\u7684\u65b0\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8f90\u5c04\u4f20\u9012\u65b9\u7a0b\uff08RTE\uff09\uff0c\u5e76\u5229\u7528\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7a33\u6001\u8f90\u5c04\u4f20\u9012\u65b9\u7a0b\uff08RTE\uff09\uff0c\u5176\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u89e3\u6cd5\u53ef\u80fd\u9762\u4e34\u7cbe\u5ea6\u6216\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86DeepRTE\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u6c42\u89e3RTE\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "DeepRTE\u80fd\u591f\u4ee5\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u89e3\u51b3RTE\u95ee\u9898\u3002"}}
{"id": "2505.23194", "pdf": "https://arxiv.org/pdf/2505.23194", "abs": "https://arxiv.org/abs/2505.23194", "authors": ["Shiwei Li", "Xiandi Luo", "Xing Tang", "Haozhao Wang", "Hao Chen", "Weihong Luo", "Yuhua Li", "Xiuqiang He", "Ruixuan Li"], "title": "Beyond Zero Initialization: Investigating the Impact of Non-Zero Initialization on LoRA Fine-Tuning Dynamics", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning\nmethod. In standard LoRA layers, one of the matrices, $A$ or $B$, is\ninitialized to zero, ensuring that fine-tuning starts from the pretrained\nmodel. However, there is no theoretical support for this practice. In this\npaper, we investigate the impact of non-zero initialization on LoRA's\nfine-tuning dynamics from an infinite-width perspective. Our analysis reveals\nthat, compared to zero initialization, simultaneously initializing $A$ and $B$\nto non-zero values improves LoRA's robustness to suboptimal learning rates,\nparticularly smaller ones. Further analysis indicates that although the\nnon-zero initialization of $AB$ introduces random noise into the pretrained\nweight, it generally does not affect fine-tuning performance. In other words,\nfine-tuning does not need to strictly start from the pretrained model. The\nvalidity of our findings is confirmed through extensive experiments across\nvarious models and datasets. The code is available at\nhttps://github.com/Leopold1423/non_zero_lora-icml25.", "AI": {"tldr": "Low-rank adaptation (LoRA)\u901a\u5e38\u7528\u96f6\u521d\u59cb\u5316\u77e9\u9635A\u6216B\u4ee5\u786e\u4fdd\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u59cb\u5fae\u8c03\uff0c\u4f46\u6b64\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\u3002\u672c\u6587\u7814\u7a76\u4e86\u4ece\u65e0\u9650\u5bbd\u5ea6\u89c6\u89d2\u51fa\u53d1\uff0c\u975e\u96f6\u521d\u59cb\u5316\u5bf9LoRA\u5fae\u8c03\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002\u7814\u7a76\u8868\u660e\uff0c\u540c\u65f6\u5c06A\u548cB\u521d\u59cb\u5316\u4e3a\u975e\u96f6\u503c\u53ef\u63d0\u9ad8LoRA\u5bf9\u6b21\u4f18\u5b66\u4e60\u7387\uff08\u7279\u522b\u662f\u8f83\u5c0f\u5b66\u4e60\u7387\uff09\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5c3d\u7ba1\u975e\u96f6\u521d\u59cb\u5316\u4f1a\u5411\u9884\u8bad\u7ec3\u6743\u91cd\u5f15\u5165\u968f\u673a\u566a\u58f0\uff0c\u4f46\u901a\u5e38\u4e0d\u4f1a\u5f71\u54cd\u5fae\u8c03\u6027\u80fd\u3002\u8fd9\u4e9b\u53d1\u73b0\u901a\u8fc7\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524dLoRA\u65b9\u6cd5\u4e2d\uff0c\u901a\u5e38\u5c06\u77e9\u9635A\u6216B\u521d\u59cb\u5316\u4e3a\u96f6\u4ee5\u4fdd\u8bc1\u5fae\u8c03\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u59cb\uff0c\u7136\u800c\u8fd9\u79cd\u505a\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u975e\u96f6\u521d\u59cb\u5316\u5bf9LoRA\u5fae\u8c03\u8fc7\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u4ece\u65e0\u9650\u5bbd\u5ea6\u89c6\u89d2\u5206\u6790\u975e\u96f6\u521d\u59cb\u5316\u5bf9LoRA\u5fae\u8c03\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u96f6\u521d\u59cb\u5316\u4e0e\u540c\u65f6\u521d\u59cb\u5316A\u548cB\u4e3a\u975e\u96f6\u503c\u7684\u60c5\u51b5\uff0c\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u975e\u96f6\u521d\u59cb\u5316\u5f15\u5165\u7684\u968f\u673a\u566a\u58f0\u5bf9\u5fae\u8c03\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u975e\u96f6\u521d\u59cb\u5316\u63d0\u9ad8\u4e86LoRA\u5bf9\u6b21\u4f18\u5b66\u4e60\u7387\uff08\u7279\u522b\u662f\u8f83\u5c0f\u5b66\u4e60\u7387\uff09\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5f15\u5165\u7684\u968f\u673a\u566a\u58f0\u901a\u5e38\u4e0d\u4f1a\u5f71\u54cd\u5fae\u8c03\u6027\u80fd\u3002\u8fd9\u610f\u5473\u7740\u5fae\u8c03\u4e0d\u4e00\u5b9a\u9700\u8981\u4e25\u683c\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u59cb\u3002", "conclusion": "\u975e\u96f6\u521d\u59cb\u5316\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u6539\u8fdbLoRA\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f7f\u7528\u8f83\u5c0f\u5b66\u4e60\u7387\u65f6\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4e0d\u4f1a\u635f\u5bb3\u5fae\u8c03\u6027\u80fd\u3002"}}
{"id": "2505.23223", "pdf": "https://arxiv.org/pdf/2505.23223", "abs": "https://arxiv.org/abs/2505.23223", "authors": ["Xingyuan Pan", "Chenlu Ye", "Joseph Melkonian", "Jiaqi W. Ma", "Tong Zhang"], "title": "Daunce: Data Attribution through Uncertainty Estimation", "categories": ["cs.LG"], "comment": null, "summary": "Training data attribution (TDA) methods aim to identify which training\nexamples influence a model's predictions on specific test data most. By\nquantifying these influences, TDA supports critical applications such as data\ndebugging, curation, and valuation. Gradient-based TDA methods rely on\ngradients and second-order information, limiting their applicability at scale.\nWhile recent random projection-based methods improve scalability, they often\nsuffer from degraded attribution accuracy. Motivated by connections between\nuncertainty and influence functions, we introduce Daunce - a simple yet\neffective data attribution approach through uncertainty estimation. Our method\noperates by fine-tuning a collection of perturbed models and computing the\ncovariance of per-example losses across these models as the attribution score.\nDaunce is scalable to large language models (LLMs) and achieves more accurate\nattribution compared to existing TDA methods. We validate Daunce on tasks\nranging from vision tasks to LLM fine-tuning, and further demonstrate its\ncompatibility with black-box model access. Applied to OpenAI's GPT models, our\nmethod achieves, to our knowledge, the first instance of data attribution on\nproprietary LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDaunce\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5b9e\u73b0\u6570\u636e\u5f52\u5c5e\uff0c\u5e76\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u5f52\u5c5e\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u6570\u636e\u5f52\u5c5e\uff08TDA\uff09\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u53d7\u9650\u4e8e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u800c\u968f\u673a\u6295\u5f71\u65b9\u6cd5\u867d\u7136\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5f52\u5c5e\u7cbe\u5ea6\u6709\u6240\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u53ef\u6269\u5c55\u53c8\u4fdd\u6301\u9ad8\u5f52\u5c5e\u7cbe\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002", "method": "Daunce\u65b9\u6cd5\u901a\u8fc7\u5bf9\u6270\u52a8\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u8ba1\u7b97\u8fd9\u4e9b\u6a21\u578b\u4e2d\u6bcf\u4e2a\u6837\u672c\u635f\u5931\u7684\u534f\u65b9\u5dee\u4f5c\u4e3a\u5f52\u5c5e\u5f97\u5206\uff0c\u4ece\u800c\u5b9e\u73b0\u6570\u636e\u5f52\u5c5e\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u4e0e\u5f71\u54cd\u51fd\u6570\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Daunce\u5728\u4ece\u89c6\u89c9\u4efb\u52a1\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u5404\u79cd\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u4e0e\u9ed1\u76d2\u6a21\u578b\u8bbf\u95ee\u7684\u517c\u5bb9\u6027\u3002\u6b64\u5916\uff0cDaunce\u9996\u6b21\u6210\u529f\u5e94\u7528\u4e8eOpenAI\u7684GPT\u7b49\u4e13\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u5f52\u5c5e\u3002", "conclusion": "Daunce\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6570\u636e\u5f52\u5c5e\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u5f52\u5c5e\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u9ed1\u76d2\u6a21\u578b\u573a\u666f\u3002"}}
{"id": "2505.23225", "pdf": "https://arxiv.org/pdf/2505.23225", "abs": "https://arxiv.org/abs/2505.23225", "authors": ["Fabiano Veglianti", "Flavio Giorgi", "Fabrizio Silvestri", "Gabriele Tolomei"], "title": "Generalizability vs. Counterfactual Explainability Trade-Off", "categories": ["cs.LG"], "comment": "9 pages, 4 figures, plus appendix. arXiv admin note: text overlap\n  with arXiv:2502.09193", "summary": "In this work, we investigate the relationship between model generalization\nand counterfactual explainability in supervised learning. We introduce the\nnotion of $\\varepsilon$-valid counterfactual probability ($\\varepsilon$-VCP) --\nthe probability of finding perturbations of a data point within its\n$\\varepsilon$-neighborhood that result in a label change. We provide a\ntheoretical analysis of $\\varepsilon$-VCP in relation to the geometry of the\nmodel's decision boundary, showing that $\\varepsilon$-VCP tends to increase\nwith model overfitting. Our findings establish a rigorous connection between\npoor generalization and the ease of counterfactual generation, revealing an\ninherent trade-off between generalization and counterfactual explainability.\nEmpirical results validate our theory, suggesting $\\varepsilon$-VCP as a\npractical proxy for quantitatively characterizing overfitting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u76d1\u7763\u5b66\u4e60\u4e2d\u6a21\u578b\u6cdb\u5316\u4e0e\u53cd\u4e8b\u5b9e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u03b5-\u6709\u6548\u53cd\u4e8b\u5b9e\u6982\u7387(\u03b5-VCP)\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u4e86\u6cdb\u5316\u80fd\u529b\u5dee\u4e0e\u53cd\u4e8b\u5b9e\u751f\u6210\u5bb9\u6613\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u3002", "motivation": "\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u7406\u89e3\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5176\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u03b5-\u6709\u6548\u53cd\u4e8b\u5b9e\u6982\u7387(\u03b5-VCP)\u8fd9\u4e00\u6982\u5ff5\uff0c\u5373\u5728\u4e00\u4e2a\u6570\u636e\u70b9\u7684\u03b5\u90bb\u57df\u5185\u627e\u5230\u5bfc\u81f4\u6807\u7b7e\u53d8\u5316\u7684\u6270\u52a8\u7684\u6982\u7387\u3002\u901a\u8fc7\u5206\u6790\u6a21\u578b\u51b3\u7b56\u8fb9\u754c\u7684\u51e0\u4f55\u7279\u6027\uff0c\u7814\u7a76\u03b5-VCP\u4e0e\u6a21\u578b\u8fc7\u62df\u5408\u7684\u5173\u7cfb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u03b5-VCP\u968f\u7740\u6a21\u578b\u8fc7\u62df\u5408\u800c\u589e\u52a0\uff1b\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7406\u8bba\uff0c\u8868\u660e\u03b5-VCP\u53ef\u4ee5\u4f5c\u4e3a\u91cf\u5316\u8fc7\u62df\u5408\u7684\u5b9e\u7528\u6307\u6807\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u4e0e\u53cd\u4e8b\u5b9e\u751f\u6210\u5bb9\u6613\u4e4b\u95f4\u7684\u4e25\u683c\u8054\u7cfb\uff0c\u63ed\u793a\u4e86\u6cdb\u5316\u4e0e\u53cd\u4e8b\u5b9e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u3002"}}
{"id": "2505.23228", "pdf": "https://arxiv.org/pdf/2505.23228", "abs": "https://arxiv.org/abs/2505.23228", "authors": ["Wanfu Gao", "Jun Gao", "Qingqi Han", "Hanlin Pan", "Kunpeng Liu"], "title": "Graph Random Walk with Feature-Label Space Alignment: A Multi-Label Feature Selection Method", "categories": ["cs.LG"], "comment": null, "summary": "The rapid growth in feature dimension may introduce implicit associations\nbetween features and labels in multi-label datasets, making the relationships\nbetween features and labels increasingly complex. Moreover, existing methods\noften adopt low-dimensional linear decomposition to explore the associations\nbetween features and labels. However, linear decomposition struggles to capture\ncomplex nonlinear associations and may lead to misalignment between the feature\nspace and the label space. To address these two critical challenges, we propose\ninnovative solutions. First, we design a random walk graph that integrates\nfeature-feature, label-label, and feature-label relationships to accurately\ncapture nonlinear and implicit indirect associations, while optimizing the\nlatent representations of associations between features and labels after\nlow-rank decomposition. Second, we align the variable spaces by leveraging\nlow-dimensional representation coefficients, while preserving the manifold\nstructure between the original high-dimensional multi-label data and the\nlow-dimensional representation space. Extensive experiments and ablation\nstudies conducted on seven benchmark datasets and three representative datasets\nusing various evaluation metrics demonstrate the superiority of the proposed\nmethod\\footnote{Code: https://github.com/Heilong623/-GRW-}.", "AI": {"tldr": "\u4e3a\u5e94\u5bf9\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e2d\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u590d\u6742\u5173\u7cfb\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u968f\u673a\u6e38\u8d70\u56fe\u548c\u4f4e\u79e9\u5206\u89e3\u7684\u65b9\u6cd5\uff0c\u4ee5\u6355\u6349\u975e\u7ebf\u6027\u548c\u9690\u5f0f\u5173\u8054\uff0c\u5e76\u901a\u8fc7\u4f4e\u7ef4\u8868\u793a\u7cfb\u6570\u5bf9\u9f50\u53d8\u91cf\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u9ad8\u7ef4\u6570\u636e\u7684\u6d41\u5f62\u7ed3\u6784\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7279\u5f81\u7ef4\u5ea6\u5feb\u901f\u589e\u957f\u5bfc\u81f4\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e2d\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u5173\u7cfb\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u7684\u4f4e\u7ef4\u7ebf\u6027\u5206\u89e3\u96be\u4ee5\u6355\u6349\u8fd9\u4e9b\u590d\u6742\u7684\u975e\u7ebf\u6027\u5173\u8054\uff0c\u53ef\u80fd\u5bfc\u81f4\u7279\u5f81\u7a7a\u95f4\u4e0e\u6807\u7b7e\u7a7a\u95f4\u4e4b\u95f4\u7684\u9519\u4f4d\u3002", "method": "1. \u6784\u5efa\u968f\u673a\u6e38\u8d70\u56fe\uff0c\u6574\u5408\u7279\u5f81-\u7279\u5f81\u3001\u6807\u7b7e-\u6807\u7b7e\u4ee5\u53ca\u7279\u5f81-\u6807\u7b7e\u5173\u7cfb\uff0c\u51c6\u786e\u6355\u6349\u975e\u7ebf\u6027\u548c\u9690\u5f0f\u95f4\u63a5\u5173\u8054\uff1b2. \u5728\u4f4e\u79e9\u5206\u89e3\u540e\u4f18\u5316\u7279\u5f81\u4e0e\u6807\u7b7e\u4e4b\u95f4\u5173\u8054\u7684\u6f5c\u5728\u8868\u793a\uff1b3. \u5229\u7528\u4f4e\u7ef4\u8868\u793a\u7cfb\u6570\u5bf9\u9f50\u53d8\u91cf\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u9ad8\u7ef4\u591a\u6807\u7b7e\u6570\u636e\u7684\u6d41\u5f62\u7ed3\u6784\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u4ee3\u8868\u6027\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u5408\u968f\u673a\u6e38\u8d70\u56fe\u548c\u4f4e\u79e9\u5206\u89e3\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6355\u6349\u591a\u6807\u7b7e\u6570\u636e\u4e2d\u590d\u6742\u7684\u975e\u7ebf\u6027\u5173\u8054\uff0c\u5e76\u901a\u8fc7\u5bf9\u9f50\u53d8\u91cf\u7a7a\u95f4\u548c\u4fdd\u7559\u6d41\u5f62\u7ed3\u6784\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2505.23244", "pdf": "https://arxiv.org/pdf/2505.23244", "abs": "https://arxiv.org/abs/2505.23244", "authors": ["Emo Todorov"], "title": "Equivalence of stochastic and deterministic policy gradients", "categories": ["cs.LG"], "comment": null, "summary": "Policy gradients in continuous control have been derived for both stochastic\nand deterministic policies. Here we study the relationship between the two. In\na widely-used family of MDPs involving Gaussian control noise and quadratic\ncontrol costs, we show that the stochastic and deterministic policy gradients,\nnatural gradients, and state value functions are identical; while the\nstate-control value functions are different. We then develop a general\nprocedure for constructing an MDP with deterministic policy that is equivalent\nto a given MDP with stochastic policy. The controls of this new MDP are the\nsufficient statistics of the stochastic policy in the original MDP. Our results\nsuggest that policy gradient methods can be unified by approximating state\nvalue functions rather than state-control value functions.", "AI": {"tldr": "\u5728\u7279\u5b9aMDP\u6761\u4ef6\u4e0b\uff0c\u786e\u5b9a\u6027\u548c\u968f\u673a\u7b56\u7565\u68af\u5ea6\u3001\u81ea\u7136\u68af\u5ea6\u548c\u72b6\u6001\u503c\u51fd\u6570\u76f8\u540c\uff0c\u800c\u72b6\u6001-\u63a7\u5236\u503c\u51fd\u6570\u4e0d\u540c\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u968f\u673a\u7b56\u7565MDP\u8f6c\u5316\u4e3a\u7b49\u6548\u786e\u5b9a\u6027\u7b56\u7565MDP\u7684\u65b9\u6cd5\uff0c\u8868\u660e\u53ef\u4ee5\u901a\u8fc7\u8fd1\u4f3c\u72b6\u6001\u503c\u51fd\u6570\u6765\u7edf\u4e00\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u8fde\u7eed\u63a7\u5236\u4e2d\u968f\u673a\u7b56\u7565\u548c\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u9ad8\u65af\u63a7\u5236\u566a\u58f0\u548c\u4e8c\u6b21\u63a7\u5236\u6210\u672c\u7684\u5e7f\u6cdb\u4f7f\u7528\u7684MDP\u5bb6\u65cf\u4e2d\u3002", "method": "1. \u5728\u7279\u5b9aMDP\u6761\u4ef6\u4e0b\u6bd4\u8f83\u968f\u673a\u548c\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u3001\u81ea\u7136\u68af\u5ea6\u548c\u503c\u51fd\u6570\u3002\n2. \u63d0\u51fa\u4e00\u79cd\u6784\u9020\u4e0e\u7ed9\u5b9a\u968f\u673a\u7b56\u7565MDP\u7b49\u6548\u7684\u786e\u5b9a\u6027\u7b56\u7565MDP\u7684\u4e00\u822c\u7a0b\u5e8f\u3002\n3. \u65b0MDP\u7684\u63a7\u5236\u662f\u539fMDP\u4e2d\u968f\u673a\u7b56\u7565\u7684\u5145\u5206\u7edf\u8ba1\u91cf\u3002", "result": "\u53d1\u73b0\u968f\u673a\u548c\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u3001\u81ea\u7136\u68af\u5ea6\u548c\u72b6\u6001\u503c\u51fd\u6570\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u76f8\u540c\uff0c\u4f46\u72b6\u6001-\u63a7\u5236\u503c\u51fd\u6570\u4e0d\u540c\u3002\u6210\u529f\u6784\u5efa\u4e86\u7b49\u6548\u7684\u786e\u5b9a\u6027\u7b56\u7565MDP\u3002", "conclusion": "\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u8fd1\u4f3c\u72b6\u6001\u503c\u51fd\u6570\u800c\u975e\u72b6\u6001-\u63a7\u5236\u503c\u51fd\u6570\u6765\u5b9e\u73b0\u7edf\u4e00\u3002"}}
{"id": "2505.23246", "pdf": "https://arxiv.org/pdf/2505.23246", "abs": "https://arxiv.org/abs/2505.23246", "authors": ["Honoka Anada", "Tatsuya Kaneko", "Shinya Takamaeda-Yamazaki"], "title": "Measuring Participant Contributions in Decentralized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) enables multiple clients to collaboratively train\nmodels without sharing their data. Measuring participant contributions in FL is\ncrucial for incentivizing clients and ensuring transparency. While various\nmethods have been proposed for contribution measurement, they are designed\nexclusively for centralized federated learning (CFL), where a central server\ncollects and aggregates client models, along with evaluating their\ncontributions. Meanwhile, decentralized federated learning (DFL), in which\nclients exchange models directly without a central server, has gained\nsignificant attention for mitigating communication bottlenecks and eliminating\na single point of failure. However, applying existing contribution measurement\nmethods to DFL is challenging due to the presence of multiple global models and\nthe absence of a central server. In this study, we present novel methodologies\nfor measuring participant contributions in DFL. We first propose DFL-Shapley,\nan extension of the Shapley value tailored for DFL, adapting this widely used\nCFL metric to decentralized settings. Given the impracticality of computing the\nideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable\napproximation that estimates overall contributions by accumulating round-wise\nShapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios\nand compare them with existing CFL metrics. The experimental results confirm\nDFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity\nto DFL-Shapley across various settings, highlighting their effectiveness as\ncontribution metrics in DFL.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u7684\u53c2\u4e0e\u8005\u8d21\u732e\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5305\u62ec\u7406\u60f3\u7684DFL-Shapley\u548c\u53ef\u8ba1\u7b97\u8fd1\u4f3c\u503cDFL-MR\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u8d21\u732e\u5ea6\u91cf\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u96c6\u4e2d\u5f0f\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\uff0c\u800c\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u4e2d\uff0c\u7531\u4e8e\u6ca1\u6709\u4e2d\u592e\u670d\u52a1\u5668\u4e14\u5b58\u5728\u591a\u4e2a\u5168\u5c40\u6a21\u578b\uff0c\u5e94\u7528\u8fd9\u4e9b\u65b9\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9DFL\u7684\u8d21\u732e\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "1. \u63d0\u51fa\u4e86DFL-Shapley\uff1a\u5c06Shapley\u503c\u6269\u5c55\u5230DFL\u573a\u666f\u3002\n2. \u63d0\u51fa\u4e86DFL-MR\uff1a\u4e00\u79cd\u53ef\u8ba1\u7b97\u7684\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u7d2f\u79ef\u6bcf\u8f6e\u7684Shapley\u503c\u6765\u4f30\u8ba1\u603b\u4f53\u8d21\u732e\u3002\n3. \u5728\u5404\u79cdFL\u573a\u666f\u4e0b\u8bc4\u4f30DFL-Shapley\u548cDFL-MR\uff0c\u5e76\u4e0e\u73b0\u6709\u7684CFL\u5ea6\u91cf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a\n1. DFL-Shapley\u662f\u4e00\u4e2a\u6709\u6548\u7684\u57fa\u51c6\u771f\u5b9e\u5ea6\u91cf\u3002\n2. DFL-MR\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u63a5\u8fd1DFL-Shapley\uff0c\u8bc1\u660e\u5176\u4f5c\u4e3aDFL\u8d21\u732e\u5ea6\u91cf\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684DFL-Shapley\u548cDFL-MR\u4e3aDFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u53c2\u4e0e\u8005\u7684\u8d21\u732e\uff0c\u6709\u52a9\u4e8e\u6fc0\u52b1\u53c2\u4e0e\u8005\u5e76\u786e\u4fdd\u900f\u660e\u5ea6\u3002"}}
{"id": "2505.23264", "pdf": "https://arxiv.org/pdf/2505.23264", "abs": "https://arxiv.org/abs/2505.23264", "authors": ["Fangyikang Wang", "Hubery Yin", "Shaobin Zhuang", "Huminhao Zhu", "Yinan Li", "Lei Qian", "Chao Zhang", "Hanbin Zhao", "Hui Qian", "Chen Li"], "title": "Efficiently Access Diffusion Fisher: Within the Outer Product Span Space", "categories": ["cs.LG"], "comment": null, "summary": "Recent Diffusion models (DMs) advancements have explored incorporating the\nsecond-order diffusion Fisher information (DF), defined as the negative Hessian\nof log density, into various downstream tasks and theoretical analysis.\nHowever, current practices typically approximate the diffusion Fisher by\napplying auto-differentiation to the learned score network. This black-box\nmethod, though straightforward, lacks any accuracy guarantee and is\ntime-consuming. In this paper, we show that the diffusion Fisher actually\nresides within a space spanned by the outer products of score and initial data.\nBased on the outer-product structure, we develop two efficient approximation\nalgorithms to access the trace and matrix-vector multiplication of DF,\nrespectively. These algorithms bypass the auto-differentiation operations with\ntime-efficient vector-product calculations. Furthermore, we establish the\napproximation error bounds for the proposed algorithms. Experiments in\nlikelihood evaluation and adjoint optimization demonstrate the superior\naccuracy and reduced computational cost of our proposed algorithms.\nAdditionally, based on the novel outer-product formulation of DF, we design the\nfirst numerical verification experiment for the optimal transport property of\nthe general PF-ODE deduced map.", "AI": {"tldr": "\u8fd1\u671f\u7684\u6269\u6563\u6a21\u578b\u7814\u7a76\u63a2\u7d22\u4e86\u5c06\u4e8c\u9636\u6269\u6563Fisher\u4fe1\u606f\u7eb3\u5165\u4e0b\u6e38\u4efb\u52a1\u548c\u7406\u8bba\u5206\u6790\u4e2d\u3002\u5f53\u524d\u65b9\u6cd5\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u8fd1\u4f3c\u6269\u6563Fisher\uff0c\u4f46\u7f3a\u4e4f\u7cbe\u5ea6\u4fdd\u8bc1\u4e14\u8017\u65f6\u3002\u672c\u6587\u63d0\u51fa\u57fa\u4e8escore\u548c\u521d\u59cb\u6570\u636e\u5916\u79ef\u7ed3\u6784\u7684\u4e24\u79cd\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u81ea\u52a8\u5fae\u5206\u64cd\u4f5c\uff0c\u5e76\u5efa\u7acb\u4e86\u8bef\u5dee\u754c\u9650\u3002\u5b9e\u9a8c\u8868\u660e\u65b0\u7b97\u6cd5\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u9a8c\u8bc1\u4e00\u822cPF-ODE\u63a8\u5bfc\u6620\u5c04\u6700\u4f18\u4f20\u8f93\u7279\u6027\u7684\u6570\u503c\u5b9e\u9a8c\u3002", "motivation": "\u5c06\u6269\u6563Fisher\u4fe1\u606f\u7eb3\u5165\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u548c\u7406\u8bba\u5206\u6790\u4e2d\uff0c\u4f46\u76ee\u524d\u7684\u8fd1\u4f3c\u65b9\u6cd5\u7f3a\u4e4f\u7cbe\u5ea6\u4fdd\u8bc1\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u53d1\u73b0\u6269\u6563Fisher\u4fe1\u606f\u4f4d\u4e8e\u7531score\u548c\u521d\u59cb\u6570\u636e\u5916\u79ef\u5f20\u6210\u7684\u7a7a\u95f4\u5185\uff0c\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e24\u79cd\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u5206\u522b\u8ba1\u7b97DF\u7684\u8ff9\u548c\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u8bef\u5dee\u754c\u9650\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6240\u63d0\u7b97\u6cd5\u5728\u4f3c\u7136\u4f30\u8ba1\u548c\u4f34\u968f\u4f18\u5316\u4e2d\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u6210\u529f\u8bbe\u8ba1\u4e86\u9a8c\u8bc1\u6700\u4f18\u4f20\u8f93\u7279\u6027\u7684\u6570\u503c\u5b9e\u9a8c\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5916\u79ef\u7ed3\u6784\u7684\u8fd1\u4f3c\u7b97\u6cd5\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6269\u6563Fisher\u4fe1\u606f\u7684\u6548\u7387\u548c\u7cbe\u5ea6\uff0c\u5e76\u4e3a\u9a8c\u8bc1\u6700\u4f18\u4f20\u8f93\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.23285", "pdf": "https://arxiv.org/pdf/2505.23285", "abs": "https://arxiv.org/abs/2505.23285", "authors": ["Muhammad Shafi", "Syed Mohsin Bokhari"], "title": "Comparative Analysis of the Land Use and Land Cover Changes in Different Governorates of Oman using Spatiotemporal Multi-spectral Satellite Data", "categories": ["cs.LG"], "comment": null, "summary": "Land cover and land use (LULC) changes are key applications of satellite\nimagery, and they have critical roles in resource management, urbanization,\nprotection of soils and the environment, and enhancing sustainable development.\nThe literature has heavily utilized multispectral spatiotemporal satellite data\nalongside advanced machine learning algorithms to monitor and predict LULC\nchanges. This study analyzes and compares LULC changes across various\ngovernorates (provinces) of the Sultanate of Oman from 2016 to 2021 using\nannual time steps. For the chosen region, multispectral spatiotemporal data\nwere acquired from the open-source Sentinel-2 satellite dataset. Supervised\nmachine learning algorithms were used to train and classify different land\ncovers, such as water bodies, crops, urban, etc. The constructed model was\nsubsequently applied within the study region, allowing for an effective\ncomparative evaluation of LULC changes within the given timeframe.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528Sentinel-2\u536b\u661f\u6570\u636e\u548c\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5206\u6790\u4e862016\u5e74\u81f32021\u5e74\u963f\u66fc\u82cf\u4e39\u56fd\u5404\u7701\u4efd\u7684\u571f\u5730\u8986\u76d6\u548c\u571f\u5730\u5229\u7528\u53d8\u5316\u3002", "motivation": "\u571f\u5730\u8986\u76d6\u548c\u571f\u5730\u5229\u7528\uff08LULC\uff09\u53d8\u5316\u5728\u8d44\u6e90\u7ba1\u7406\u3001\u57ce\u5e02\u5316\u3001\u571f\u58e4\u548c\u73af\u5883\u4fdd\u62a4\u4ee5\u53ca\u4fc3\u8fdb\u53ef\u6301\u7eed\u53d1\u5c55\u4e2d\u626e\u6f14\u7740\u91cd\u8981\u89d2\u8272\u3002\u56e0\u6b64\uff0c\u76d1\u6d4b\u8fd9\u4e9b\u53d8\u5316\u5bf9\u4e8e\u76f8\u5173\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u6765\u81ea\u5f00\u653e\u6e90Sentinel-2\u536b\u661f\u6570\u636e\u96c6\u7684\u591a\u5149\u8c31\u65f6\u7a7a\u6570\u636e\uff0c\u5e76\u5229\u7528\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u5730\u8868\u8986\u76d6\u8fdb\u884c\u8bad\u7ec3\u548c\u5206\u7c7b\uff0c\u5982\u6c34\u4f53\u3001\u4f5c\u7269\u3001\u57ce\u5e02\u533a\u57df\u7b49\u3002", "result": "\u6784\u5efa\u7684\u6a21\u578b\u6210\u529f\u5e94\u7528\u4e8e\u7814\u7a76\u533a\u57df\uff0c\u5b9e\u73b0\u4e86\u5bf92016\u5e74\u81f32021\u5e74\u95f4\u571f\u5730\u8986\u76d6\u548c\u571f\u5730\u5229\u7528\u53d8\u5316\u7684\u6709\u6548\u6bd4\u8f83\u8bc4\u4f30\u3002", "conclusion": "\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0e\u591a\u5149\u8c31\u65f6\u7a7a\u536b\u661f\u6570\u636e\u7ed3\u5408\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u76d1\u6d4b\u548c\u9884\u6d4b\u571f\u5730\u8986\u76d6\u548c\u571f\u5730\u5229\u7528\u7684\u53d8\u5316\uff0c\u4e3a\u76f8\u5173\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2505.23334", "pdf": "https://arxiv.org/pdf/2505.23334", "abs": "https://arxiv.org/abs/2505.23334", "authors": ["Tu Bui", "Mohamed Suliman", "Aparajita Haldar", "Mohammed Amer", "Serban Georgescu"], "title": "X2Graph for Cancer Subtyping Prediction on Biological Tabular Data", "categories": ["cs.LG"], "comment": "IEEE Engineering in Medicine and Biology Society (EMBC) 2025", "summary": "Despite the transformative impact of deep learning on text, audio, and image\ndatasets, its dominance in tabular data, especially in the medical domain where\ndata are often scarce, remains less clear. In this paper, we propose X2Graph, a\nnovel deep learning method that achieves strong performance on small biological\ntabular datasets. X2Graph leverages external knowledge about the relationships\nbetween table columns, such as gene interactions, to convert each sample into a\ngraph structure. This transformation enables the application of standard\nmessage passing algorithms for graph modeling. Our X2Graph method demonstrates\nsuperior performance compared to existing tree-based and deep learning methods\nacross three cancer subtyping datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5X2Graph\uff0c\u901a\u8fc7\u5229\u7528\u8868\u683c\u5217\u95f4\u5173\u7cfb\u7684\u5916\u90e8\u77e5\u8bc6\uff08\u5982\u57fa\u56e0\u76f8\u4e92\u4f5c\u7528\uff09\uff0c\u5c06\u6837\u672c\u8f6c\u6362\u4e3a\u56fe\u7ed3\u6784\u5e76\u5e94\u7528\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\uff0c\u5728\u5c0f\u89c4\u6a21\u751f\u7269\u533b\u5b66\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u5bf9\u6587\u672c\u3001\u97f3\u9891\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4ea7\u751f\u4e86\u53d8\u9769\u6027\u7684\u5f71\u54cd\uff0c\u4f46\u5728\u8868\u683c\u6570\u636e\uff08\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u533b\u7597\u9886\u57df\uff09\u4e2d\u7684\u4f18\u52bf\u5c1a\u4e0d\u660e\u786e\u3002", "method": "X2Graph\u5229\u7528\u5173\u4e8e\u8868\u683c\u5217\u4e4b\u95f4\u5173\u7cfb\u7684\u5916\u90e8\u77e5\u8bc6\uff08\u5982\u57fa\u56e0\u76f8\u4e92\u4f5c\u7528\uff09\uff0c\u5c06\u6bcf\u4e2a\u6837\u672c\u8f6c\u6362\u4e3a\u56fe\u7ed3\u6784\uff0c\u5e76\u5e94\u7528\u6807\u51c6\u7684\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\u8fdb\u884c\u56fe\u5efa\u6a21\u3002", "result": "X2Graph\u65b9\u6cd5\u5728\u4e09\u4e2a\u764c\u75c7\u4e9a\u578b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u6811\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "conclusion": "X2Graph\u5728\u5c0f\u89c4\u6a21\u751f\u7269\u533b\u5b66\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u6811\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.23345", "pdf": "https://arxiv.org/pdf/2505.23345", "abs": "https://arxiv.org/abs/2505.23345", "authors": ["Yang Liu", "Deyu Bo", "Wenxuan Cao", "Yuan Fang", "Yawen Li", "Chuan Shi"], "title": "Graph Positional Autoencoders as Self-supervised Learners", "categories": ["cs.LG"], "comment": "12 pages, 3 figures, Accepted at KDD 2025", "summary": "Graph self-supervised learning seeks to learn effective graph representations\nwithout relying on labeled data. Among various approaches, graph autoencoders\n(GAEs) have gained significant attention for their efficiency and scalability.\nTypically, GAEs take incomplete graphs as input and predict missing elements,\nsuch as masked nodes or edges. While effective, our experimental investigation\nreveals that traditional node or edge masking paradigms primarily capture\nlow-frequency signals in the graph and fail to learn the expressive structural\ninformation. To address these issues, we propose Graph Positional Autoencoders\n(GraphPAE), which employs a dual-path architecture to reconstruct both node\nfeatures and positions. Specifically, the feature path uses positional encoding\nto enhance the message-passing processing, improving GAE's ability to predict\nthe corrupted information. The position path, on the other hand, leverages node\nrepresentations to refine positions and approximate eigenvectors, thereby\nenabling the encoder to learn diverse frequency information. We conduct\nextensive experiments to verify the effectiveness of GraphPAE, including\nheterophilic node classification, graph property prediction, and transfer\nlearning. The results demonstrate that GraphPAE achieves state-of-the-art\nperformance and consistently outperforms baselines by a large margin.", "AI": {"tldr": "\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u65e8\u5728\u4e0d\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u6709\u6548\u7684\u56fe\u8868\u793a\u3002\u5c3d\u7ba1\u56fe\u81ea\u52a8\u7f16\u7801\u5668\uff08GAEs\uff09\u5728\u9884\u6d4b\u7f3a\u5931\u5143\u7d20\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4f20\u7edf\u7684\u8282\u70b9\u6216\u8fb9\u5c4f\u853d\u8303\u5f0f\u4e3b\u8981\u6355\u83b7\u56fe\u4e2d\u7684\u4f4e\u9891\u4fe1\u53f7\uff0c\u65e0\u6cd5\u5b66\u4e60\u8868\u8fbe\u6027\u7684\u7ed3\u6784\u4fe1\u606f\u3002\u672c\u6587\u63d0\u51fa\u4e86\u56fe\u4f4d\u7f6e\u81ea\u52a8\u7f16\u7801\u5668\uff08GraphPAE\uff09\uff0c\u5b83\u91c7\u7528\u53cc\u8def\u5f84\u67b6\u6784\u6765\u91cd\u6784\u8282\u70b9\u7279\u5f81\u548c\u4f4d\u7f6e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGraphPAE\u5728\u5f02\u8d28\u8282\u70b9\u5206\u7c7b\u3001\u56fe\u5c5e\u6027\u9884\u6d4b\u548c\u8fc1\u79fb\u5b66\u4e60\u7b49\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5927\u5e45\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u56fe\u81ea\u52a8\u7f16\u7801\u5668\uff08GAEs\uff09\u5728\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f20\u7edf\u7684\u65b9\u6cd5\u4ec5\u80fd\u6355\u83b7\u4f4e\u9891\u4fe1\u53f7\uff0c\u672a\u80fd\u6709\u6548\u5b66\u4e60\u56fe\u7684\u7ed3\u6784\u6027\u4fe1\u606f\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3aGAE\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraph Positional Autoencoders (GraphPAE)\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u91c7\u7528\u53cc\u8def\u5f84\u67b6\u6784\uff1a\u7279\u5f81\u8def\u5f84\u4f7f\u7528\u4f4d\u7f6e\u7f16\u7801\u6765\u589e\u5f3a\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\uff1b\u4f4d\u7f6e\u8def\u5f84\u5229\u7528\u8282\u70b9\u8868\u793a\u6765\u4f18\u5316\u4f4d\u7f6e\u5e76\u8fd1\u4f3c\u7279\u5f81\u5411\u91cf\uff0c\u4ece\u800c\u8ba9\u7f16\u7801\u5668\u5b66\u4e60\u5230\u591a\u6837\u9891\u7387\u7684\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0cGraphPAE\u5728\u5f02\u8d28\u8282\u70b9\u5206\u7c7b\u3001\u56fe\u5c5e\u6027\u9884\u6d4b\u548c\u8fc1\u79fb\u5b66\u4e60\u7b49\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e1a\u754c\u9886\u5148\u6c34\u5e73\u3002", "conclusion": "GraphPAE\u6709\u6548\u5730\u89e3\u51b3\u4e86\u4f20\u7edfGAE\u53ea\u80fd\u6355\u83b7\u4f4e\u9891\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u5176\u53cc\u8def\u5f84\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u6548\u679c\uff0c\u4e3a\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2505.23347", "pdf": "https://arxiv.org/pdf/2505.23347", "abs": "https://arxiv.org/abs/2505.23347", "authors": ["Yuting Li", "Shaoyuan Huang", "Tengwen Zhang", "Cheng Zhang", "Xiaofei Wang", "Victor C. M. Leung"], "title": "Sentinel: Scheduling Live Streams with Proactive Anomaly Detection in Crowdsourced Cloud-Edge Platforms", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2402.14619", "summary": "With the rapid growth of live streaming services, Crowdsourced Cloud-edge\nservice Platforms (CCPs) are playing an increasingly important role in meeting\nthe increasing demand. Although stream scheduling plays a critical role in\noptimizing CCPs' revenue, most optimization strategies struggle to achieve\npractical results due to various anomalies in unstable CCPs. Additionally, the\nsubstantial scale of CCPs magnifies the difficulties of anomaly detection in\ntime-sensitive scheduling. To tackle these challenges, this paper proposes\nSentinel, a proactive anomaly detection-based scheduling framework. Sentinel\nmodels the scheduling process as a two-stage Pre-Post-Scheduling paradigm: in\nthe pre-scheduling stage, Sentinel conducts anomaly detection and constructs a\nstrategy pool; in the post-scheduling stage, upon request arrival, it triggers\nan appropriate scheduling based on a pre-generated strategy to implement the\nscheduling process. Extensive experiments on realistic datasets show that\nSentinel significantly reduces anomaly frequency by 70%, improves revenue by\n74%, and doubles the scheduling speed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSentinel\u7684\u4e3b\u52a8\u5f02\u5e38\u68c0\u6d4b\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8c03\u5ea6\u8303\u5f0f\u6709\u6548\u964d\u4f4e\u4e86\u5f02\u5e38\u9891\u7387\u3001\u63d0\u5347\u4e86\u6536\u5165\u5e76\u52a0\u5feb\u4e86\u8c03\u5ea6\u901f\u5ea6\u3002", "motivation": "\u76f4\u64ad\u670d\u52a1\u7684\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u4f17\u5305\u4e91\u8fb9\u670d\u52a1\u5e73\u53f0\uff08CCPs\uff09\u5728\u6ee1\u8db3\u9700\u6c42\u65b9\u9762\u626e\u6f14\u7740\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\u3002\u7136\u800c\uff0c\u7531\u4e8eCCPs\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u89c4\u6a21\u5e9e\u5927\uff0c\u73b0\u6709\u7684\u6d41\u8c03\u5ea6\u4f18\u5316\u7b56\u7565\u96be\u4ee5\u5b9e\u73b0\u5b9e\u9645\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u65f6\u95f4\u654f\u611f\u7684\u8c03\u5ea6\u4e2d\uff0c\u5f02\u5e38\u68c0\u6d4b\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faSentinel\u6846\u67b6\uff0c\u5c06\u8c03\u5ea6\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u4e24\u9636\u6bb5\u7684Pre-Post-Scheduling\u8303\u5f0f\uff1a\u9884\u8c03\u5ea6\u9636\u6bb5\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u5e76\u6784\u5efa\u7b56\u7565\u6c60\uff1b\u540e\u8c03\u5ea6\u9636\u6bb5\u6839\u636e\u8bf7\u6c42\u89e6\u53d1\u5408\u9002\u7684\u8c03\u5ea6\u7b56\u7565\u4ee5\u5b8c\u6210\u8c03\u5ea6\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSentinel\u663e\u8457\u51cf\u5c11\u4e8670%\u7684\u5f02\u5e38\u9891\u7387\uff0c\u63d0\u9ad8\u4e8674%\u7684\u6536\u5165\uff0c\u5e76\u4e14\u5c06\u8c03\u5ea6\u901f\u5ea6\u63d0\u9ad8\u4e86\u4e00\u500d\u3002", "conclusion": "Sentinel\u6846\u67b6\u5728\u964d\u4f4e\u5f02\u5e38\u9891\u7387\u3001\u63d0\u5347\u5e73\u53f0\u6536\u5165\u548c\u52a0\u901f\u8c03\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u89e3\u51b3CCPs\u4e2d\u7684\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23355", "pdf": "https://arxiv.org/pdf/2505.23355", "abs": "https://arxiv.org/abs/2505.23355", "authors": ["Maxiu Xiao", "Jianglin Lan", "Jingxing Yu", "Eldert van Henten", "Congcong Sun"], "title": "Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Climate control is crucial for greenhouse production as it directly affects\ncrop growth and resource use. Reinforcement learning (RL) has received\nincreasing attention in this field, but still faces challenges, including\nlimited training efficiency and high reliance on initial learning conditions.\nInteractive RL, which combines human (grower) input with the RL agent's\nlearning, offers a potential solution to overcome these challenges. However,\ninteractive RL has not yet been applied to greenhouse climate control and may\nface challenges related to imperfect inputs. Therefore, this paper aims to\nexplore the possibility and performance of applying interactive RL with\nimperfect inputs into greenhouse climate control, by: (1) developing three\nrepresentative interactive RL algorithms tailored for greenhouse climate\ncontrol (reward shaping, policy shaping and control sharing); (2) analyzing how\ninput characteristics are often contradicting, and how the trade-offs between\nthem make grower's inputs difficult to perfect; (3) proposing a neural\nnetwork-based approach to enhance the robustness of interactive RL agents under\nlimited input availability; (4) conducting a comprehensive evaluation of the\nthree interactive RL algorithms with imperfect inputs in a simulated greenhouse\nenvironment. The demonstration shows that interactive RL incorporating\nimperfect grower inputs has the potential to improve the performance of the RL\nagent. RL algorithms that influence action selection, such as policy shaping\nand control sharing, perform better when dealing with imperfect inputs,\nachieving 8.4% and 6.8% improvement in profit, respectively. In contrast,\nreward shaping, an algorithm that manipulates the reward function, is sensitive\nto imperfect inputs and leads to a 9.4% decrease in profit. This highlights the\nimportance of selecting an appropriate mechanism when incorporating imperfect\ninputs.", "AI": {"tldr": "\u5728\u6e29\u5ba4\u6c14\u5019\u63a7\u5236\u4e2d\u5e94\u7528\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u7279\u522b\u662f\u5904\u7406\u4e0d\u5b8c\u7f8e\u8f93\u5165\u65f6\u7684\u8868\u73b0\u3002\u901a\u8fc7\u5f00\u53d1\u5b9a\u5236\u7b97\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7814\u7a76\u53d1\u73b0\u5f71\u54cd\u52a8\u4f5c\u9009\u62e9\u7684\u7b56\u7565\u6210\u5f62\u548c\u63a7\u5236\u5171\u4eab\u7b97\u6cd5\u80fd\u66f4\u597d\u5e94\u5bf9\u4e0d\u5b8c\u7f8e\u8f93\u5165\uff0c\u5206\u522b\u63d0\u9ad88.4%\u548c6.8%\u7684\u5229\u6da6\uff1b\u800c\u5956\u52b1\u6210\u5f62\u7b97\u6cd5\u5219\u5bfc\u81f49.4%\u7684\u5229\u6da6\u4e0b\u964d\u3002", "motivation": "\u6c14\u5019\u63a7\u5236\u5bf9\u6e29\u5ba4\u751f\u4ea7\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u6548\u7387\u548c\u521d\u59cb\u6761\u4ef6\u4f9d\u8d56\u4e0a\u5b58\u5728\u6311\u6218\u3002\u4ea4\u4e92\u5f0fRL\u7ed3\u5408\u4e86\u4eba\u7c7b\u8f93\u5165\u548c\u667a\u80fd\u4f53\u5b66\u4e60\uff0c\u53ef\u80fd\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u4f46\u5c1a\u672a\u5e94\u7528\u4e8e\u6e29\u5ba4\u6c14\u5019\u63a7\u5236\u9886\u57df\u3002", "method": "1. \u5f00\u53d1\u4e09\u79cd\u4ee3\u8868\u6027\u7684\u4ea4\u4e92\u5f0fRL\u7b97\u6cd5\uff08\u5956\u52b1\u6210\u5f62\u3001\u7b56\u7565\u6210\u5f62\u548c\u63a7\u5236\u5171\u4eab\uff09\uff1b2. \u5206\u6790\u8f93\u5165\u7279\u6027\u53ca\u5176\u77db\u76fe\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u5e73\u8861\u4f7f\u8f93\u5165\u96be\u4ee5\u5b8c\u7f8e\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u4ee5\u589e\u5f3a\u6709\u9650\u8f93\u5165\u4e0b\u7684\u9c81\u68d2\u6027\uff1b4. \u5728\u6a21\u62df\u6e29\u5ba4\u73af\u5883\u4e2d\u5168\u9762\u8bc4\u4f30\u8fd9\u4e09\u79cd\u7b97\u6cd5\u3002", "result": "\u4ea4\u4e92\u5f0fRL\u7ed3\u5408\u4e0d\u5b8c\u7f8e\u8f93\u5165\u53ef\u4ee5\u63d0\u5347RL\u667a\u80fd\u4f53\u6027\u80fd\u3002\u5176\u4e2d\uff0c\u5f71\u54cd\u52a8\u4f5c\u9009\u62e9\u7684\u7b97\u6cd5\uff08\u5982\u7b56\u7565\u6210\u5f62\u548c\u63a7\u5236\u5171\u4eab\uff09\u8868\u73b0\u66f4\u4f18\uff0c\u5206\u522b\u63d0\u5347\u4e868.4%\u548c6.8%\u7684\u5229\u6da6\uff1b\u800c\u64cd\u7eb5\u5956\u52b1\u51fd\u6570\u7684\u5956\u52b1\u6210\u5f62\u7b97\u6cd5\u5bf9\u4e0d\u5b8c\u7f8e\u8f93\u5165\u654f\u611f\uff0c\u5bfc\u81f49.4%\u7684\u5229\u6da6\u4e0b\u964d\u3002", "conclusion": "\u5728\u6e29\u5ba4\u6c14\u5019\u63a7\u5236\u4e2d\u4f7f\u7528\u4ea4\u4e92\u5f0fRL\u65f6\uff0c\u9009\u62e9\u5408\u9002\u7684\u673a\u5236\u4ee5\u5e94\u5bf9\u4e0d\u5b8c\u7f8e\u8f93\u5165\u81f3\u5173\u91cd\u8981\u3002\u7b56\u7565\u6210\u5f62\u548c\u63a7\u5236\u5171\u4eab\u66f4\u9002\u5408\u5904\u7406\u4e0d\u5b8c\u7f8e\u8f93\u5165\uff0c\u800c\u5956\u52b1\u6210\u5f62\u5219\u4e0d\u592a\u9002\u7528\u3002"}}
{"id": "2505.23378", "pdf": "https://arxiv.org/pdf/2505.23378", "abs": "https://arxiv.org/abs/2505.23378", "authors": ["Roseline Polle", "Agnes Norbury", "Alexandra Livia Georgescu", "Nicholas Cummins", "Stefano Goria"], "title": "Meta-Learning Approaches for Speaker-Dependent Voice Fatigue Models", "categories": ["cs.LG"], "comment": "5 pages, 3 figures. To appear at Interspeech 2025", "summary": "Speaker-dependent modelling can substantially improve performance in\nspeech-based health monitoring applications. While mixed-effect models are\ncommonly used for such speaker adaptation, they require computationally\nexpensive retraining for each new observation, making them impractical in a\nproduction environment. We reformulate this task as a meta-learning problem and\nexplore three approaches of increasing complexity: ensemble-based distance\nmodels, prototypical networks, and transformer-based sequence models. Using\npre-trained speech embeddings, we evaluate these methods on a large\nlongitudinal dataset of shift workers (N=1,185, 10,286 recordings), predicting\ntime since sleep from speech as a function of fatigue, a symptom commonly\nassociated with ill-health. Our results demonstrate that all meta-learning\napproaches tested outperformed both cross-sectional and conventional\nmixed-effects models, with a transformer-based method achieving the strongest\nperformance.", "AI": {"tldr": "\u5728\u8bed\u97f3\u5065\u5eb7\u76d1\u6d4b\u5e94\u7528\u4e2d\uff0c\u8bf4\u8bdd\u4eba\u76f8\u5173\u5efa\u6a21\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6027\u80fd\u3002\u672c\u6587\u5c06\u6b64\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5143\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u57fa\u4e8e\u96c6\u6210\u7684\u8ddd\u79bb\u6a21\u578b\u3001\u539f\u578b\u7f51\u7edc\u548c\u57fa\u4e8eTransformer\u7684\u5e8f\u5217\u6a21\u578b\u3002\u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u597d\u7684\u8bed\u97f3\u5d4c\u5165\uff0c\u5728\u4e00\u4e2a\u5927\u578b\u7eb5\u5411\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u9884\u6d4b\u4ece\u8bed\u97f3\u5230\u7761\u7720\u65f6\u95f4\u7684\u5173\u7cfb\uff08\u75b2\u52b3\u7a0b\u5ea6\uff09\u3002\u7ed3\u679c\u663e\u793a\u6240\u6709\u6d4b\u8bd5\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u90fd\u4f18\u4e8e\u6a2a\u65ad\u9762\u548c\u4f20\u7edf\u7684\u6df7\u5408\u6548\u5e94\u6a21\u578b\uff0c\u5176\u4e2d\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u8bf4\u8bdd\u4eba\u9002\u5e94\u5bf9\u4e8e\u8bed\u97f3\u5065\u5eb7\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u6df7\u5408\u6548\u5e94\u6a21\u578b\u9700\u8981\u5bf9\u6bcf\u4e2a\u65b0\u89c2\u5bdf\u503c\u8fdb\u884c\u6602\u8d35\u7684\u518d\u8bad\u7ec3\uff0c\u8fd9\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u5c06\u8bf4\u8bdd\u4eba\u9002\u5e94\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5143\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u4e86\u4e09\u79cd\u590d\u6742\u5ea6\u9012\u589e\u7684\u65b9\u6cd5\uff1a\u57fa\u4e8e\u96c6\u6210\u7684\u8ddd\u79bb\u6a21\u578b\u3001\u539f\u578b\u7f51\u7edc\u548c\u57fa\u4e8eTransformer\u7684\u5e8f\u5217\u6a21\u578b\u3002\u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u597d\u7684\u8bed\u97f3\u5d4c\u5165\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4e00\u4e2a\u5927\u578b\u7eb5\u5411\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b1,185\u540d\u8f6e\u73ed\u5de5\u4eba\u548c10,286\u4e2a\u5f55\u97f3\u8bb0\u5f55\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u5747\u4f18\u4e8e\u6a2a\u65ad\u9762\u548c\u4f20\u7edf\u7684\u6df7\u5408\u6548\u5e94\u6a21\u578b\u3002\u5176\u4e2d\uff0c\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u6700\u5f3a\u7684\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8eTransformer\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u5728\u8bf4\u8bdd\u4eba\u76f8\u5173\u5efa\u6a21\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4f20\u7edf\u6df7\u5408\u6548\u5e94\u6a21\u578b\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u5408\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5e94\u7528\u3002"}}
{"id": "2505.23383", "pdf": "https://arxiv.org/pdf/2505.23383", "abs": "https://arxiv.org/abs/2505.23383", "authors": ["Ahmad Anaqreh", "Shih-Kai Chou", "Mihael Mohor\u010di\u010d", "Carolina Fortuna"], "title": "Automated Modeling Method for Pathloss Model Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Modeling propagation is the cornerstone for designing and optimizing\nnext-generation wireless systems, with a particular emphasis on 5G and beyond\nera. Traditional modeling methods have long relied on statistic-based\ntechniques to characterize propagation behavior across different environments.\nWith the expansion of wireless communication systems, there is a growing demand\nfor methods that guarantee the accuracy and interoperability of modeling.\nArtificial intelligence (AI)-based techniques, in particular, are increasingly\nbeing adopted to overcome this challenge, although the interpretability is not\nassured with most of these methods. Inspired by recent advancements in AI, this\npaper proposes a novel approach that accelerates the discovery of path loss\nmodels while maintaining interpretability. The proposed method automates the\nmodel formulation, evaluation, and refinement, facilitating model discovery. We\nevaluate two techniques: one based on Deep Symbolic Regression, offering full\ninterpretability, and the second based on Kolmogorov-Arnold Networks, providing\ntwo levels of interpretability. Both approaches are evaluated on two synthetic\nand two real-world datasets. Our results show that Kolmogorov-Arnold Networks\nachieve R^2 values close to 1 with minimal prediction error, while Deep\nSymbolic Regression generates compact models with moderate accuracy. Moreover,\non the selected examples, we demonstrate that automated methods outperform\ntraditional methods, achieving up to 75% reduction in prediction errors,\noffering accurate and explainable solutions with potential to increase the\nefficiency of discovering next-generation path loss models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u548cKolmogorov-Arnold\u7f51\u7edc\uff0c\u52a0\u901f\u8def\u5f84\u635f\u8017\u6a21\u578b\u7684\u53d1\u73b0\uff0c\u5e76\u4fdd\u8bc1\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cKolmogorov-Arnold\u7f51\u7edc\u9884\u6d4b\u7cbe\u786e\uff0c\u800c\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u751f\u6210\u7d27\u51d1\u6a21\u578b\u3002\u81ea\u52a8\u5316\u65b9\u6cd5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c1175%\u9884\u6d4b\u8bef\u5dee\u3002", "motivation": "\u968f\u7740\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u6269\u5c55\uff0c\u5bf9\u5efa\u6a21\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u4f46\u5927\u591a\u6570\u57fa\u4e8eAI\u7684\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u79cd\u6280\u672f\uff1a\u57fa\u4e8e\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\uff08Deep Symbolic Regression\uff09\u7684\u6280\u672f\u63d0\u4f9b\u5b8c\u5168\u53ef\u89e3\u91ca\u6027\uff1b\u57fa\u4e8eKolmogorov-Arnold\u7f51\u7edc\u7684\u6280\u672f\u63d0\u4f9b\u4e24\u5c42\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u65b9\u6cd5\u81ea\u52a8\u5316\u4e86\u6a21\u578b\u7684\u516c\u5f0f\u5316\u3001\u8bc4\u4f30\u548c\u6539\u8fdb\u8fc7\u7a0b\u3002", "result": "\u5728\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cKolmogorov-Arnold\u7f51\u7edc\u8fbe\u5230\u63a5\u8fd11\u7684R^2\u503c\uff0c\u9884\u6d4b\u8bef\u5dee\u6700\u5c0f\uff1b\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u751f\u6210\u7d27\u51d1\u6a21\u578b\uff0c\u5177\u6709\u4e2d\u7b49\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5728\u9009\u5b9a\u7684\u4f8b\u5b50\u4e0a\uff0c\u81ea\u52a8\u5316\u65b9\u6cd5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u4e86\u9ad8\u8fbe75%\u7684\u9884\u6d4b\u8bef\u5dee\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4e0b\u4e00\u4ee3\u8def\u5f84\u635f\u8017\u6a21\u578b\u53d1\u73b0\u7684\u6548\u7387\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23421", "pdf": "https://arxiv.org/pdf/2505.23421", "abs": "https://arxiv.org/abs/2505.23421", "authors": ["Zheming Zhang", "Yan Jiang", "Qingshan Li", "Ai Han"], "title": "OTPTO: Joint Product Selection and Inventory Optimization in Fresh E-commerce Front-End Warehouses", "categories": ["cs.LG"], "comment": "18 pages, 9 figures", "summary": "In China's competitive fresh e-commerce market, optimizing operational\nstrategies, especially inventory management in front-end warehouses, is key to\nenhance customer satisfaction and to gain a competitive edge. Front-end\nwarehouses are placed in residential areas to ensure the timely delivery of\nfresh goods and are usually in small size. This brings the challenge of\ndeciding which goods to stock and in what quantities, taking into account\ncapacity constraints. To address this issue, traditional predict-then-optimize\n(PTO) methods that predict sales and then decide on inventory often don't align\nprediction with inventory goals, as well as fail to prioritize consumer\nsatisfaction. This paper proposes a multi-task\nOptimize-then-Predict-then-Optimize (OTPTO) approach that jointly optimizes\nproduct selection and inventory management, aiming to increase consumer\nsatisfaction by maximizing the full order fulfillment rate. Our method employs\na 0-1 mixed integer programming model OM1 to determine historically optimal\ninventory levels, and then uses a product selection model PM1 and the stocking\nmodel PM2 for prediction. The combined results are further refined through a\npost-processing algorithm OM2. Experimental results from JD.com's 7Fresh\nplatform demonstrate the robustness and significant advantages of our OTPTO\nmethod. Compared to the PTO approach, our OTPTO method substantially enhances\nthe full order fulfillment rate by 4.34% (a relative increase of 7.05%) and\nnarrows the gap to the optimal full order fulfillment rate by 5.27%. These\nfindings substantiate the efficacy of the OTPTO method in managing inventory at\nfront-end warehouses of fresh e-commerce platforms and provide valuable\ninsights for future research in this domain.", "AI": {"tldr": "\u5728\u4e2d\u56fd\u751f\u9c9c\u7535\u5546\u5e02\u573a\u4e2d\uff0c\u524d\u7aef\u4ed3\u5e93\u7684\u5e93\u5b58\u7ba1\u7406\u5bf9\u4e8e\u63d0\u9ad8\u5ba2\u6237\u6ee1\u610f\u5ea6\u548c\u7ade\u4e89\u4f18\u52bf\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1OTPTO\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u4ea7\u54c1\u9009\u62e9\u548c\u5e93\u5b58\u7ba1\u7406\u6765\u63d0\u9ad8\u8ba2\u5355\u6ee1\u8db3\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u524d\u7aef\u4ed3\u5e93\u7684\u5c0f\u89c4\u6a21\u548c\u5bb9\u91cf\u9650\u5236\u4f7f\u5f97\u5e93\u5b58\u7ba1\u7406\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u7684\u9884\u6d4b-\u4f18\u5316\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u7ed3\u5408\u9884\u6d4b\u4e0e\u5e93\u5b58\u76ee\u6807\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u6d88\u8d39\u8005\u6ee1\u610f\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1OTPTO\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1) \u4f7f\u75280-1\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578bOM1\u786e\u5b9a\u5386\u53f2\u6700\u4f18\u5e93\u5b58\u6c34\u5e73\uff1b2) \u901a\u8fc7\u4ea7\u54c1\u9009\u62e9\u6a21\u578bPM1\u548c\u8865\u8d27\u6a21\u578bPM2\u8fdb\u884c\u9884\u6d4b\uff1b3) \u5229\u7528\u540e\u5904\u7406\u7b97\u6cd5OM2\u8fdb\u4e00\u6b65\u4f18\u5316\u7ed3\u679c\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u7684PTO\u65b9\u6cd5\uff0cOTPTO\u65b9\u6cd5\u5c06\u8ba2\u5355\u6ee1\u8db3\u7387\u63d0\u9ad8\u4e864.34%\uff08\u76f8\u5bf9\u63d0\u53477.05%\uff09\uff0c\u5e76\u5c06\u4e0e\u6700\u4f18\u8ba2\u5355\u6ee1\u8db3\u7387\u7684\u5dee\u8ddd\u7f29\u5c0f\u4e865.27%\u3002", "conclusion": "OTPTO\u65b9\u6cd5\u5728\u751f\u9c9c\u7535\u5546\u5e73\u53f0\u524d\u7aef\u4ed3\u5e93\u7684\u5e93\u5b58\u7ba1\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.23427", "pdf": "https://arxiv.org/pdf/2505.23427", "abs": "https://arxiv.org/abs/2505.23427", "authors": ["Monika Gahalawat", "Maneesh Bilalpur", "Raul Fernandez Rojas", "Jeffrey F. Cohn", "Roland Goecke", "Ramanathan Subramanian"], "title": "On the Validity of Head Motion Patterns as Generalisable Depression Biomarkers", "categories": ["cs.LG"], "comment": null, "summary": "Depression is a debilitating mood disorder negatively impacting millions\nworldwide. While researchers have explored multiple verbal and non-verbal\nbehavioural cues for automated depression assessment, head motion has received\nlittle attention thus far. Further, the common practice of validating machine\nlearning models via a single dataset can limit model generalisability. This\nwork examines the effectiveness and generalisability of models utilising\nelementary head motion units, termed kinemes, for depression severity\nestimation. Specifically, we consider three depression datasets from different\nwestern cultures (German: AVEC2013, Australian: Blackdog and American: Pitt\ndatasets) with varied contextual and recording settings to investigate the\ngeneralisability of the derived kineme patterns via two methods: (i) k-fold\ncross-validation over individual/multiple datasets, and (ii) model reuse on\nother datasets. Evaluating classification and regression performance with\nclassical machine learning methods, our results show that: (1) head motion\npatterns are efficient biomarkers for estimating depression severity, achieving\nhighly competitive performance for both classification and regression tasks on\na variety of datasets, including achieving the second best Mean Absolute Error\n(MAE) on the AVEC2013 dataset, and (2) kineme-based features are more\ngeneralisable than (a) raw head motion descriptors for binary severity\nclassification, and (b) other visual behavioural cues for severity estimation\n(regression).", "AI": {"tldr": "\u7814\u7a76\u4e86\u5229\u7528\u5934\u90e8\u8fd0\u52a8\u57fa\u672c\u5355\u5143\uff08kinemes\uff09\u6765\u8bc4\u4f30\u6291\u90c1\u7a0b\u5ea6\u7684\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\uff0c\u53d1\u73b0\u5934\u90e8\u8fd0\u52a8\u6a21\u5f0f\u662f\u6709\u6548\u7684\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5e76\u4e14\u57fa\u4e8ekineme\u7684\u7279\u5f81\u6bd4\u5176\u4ed6\u89c6\u89c9\u884c\u4e3a\u7ebf\u7d22\u66f4\u5177\u6709\u901a\u7528\u6027\u3002", "motivation": "\u5c3d\u7ba1\u7814\u7a76\u4eba\u5458\u5df2\u7ecf\u63a2\u7d22\u4e86\u591a\u79cd\u8a00\u8bed\u548c\u975e\u8a00\u8bed\u7684\u884c\u4e3a\u7ebf\u7d22\u7528\u4e8e\u81ea\u52a8\u6291\u90c1\u8bc4\u4f30\uff0c\u4f46\u5934\u90e8\u8fd0\u52a8\u5c1a\u672a\u53d7\u5230\u8db3\u591f\u7684\u5173\u6ce8\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5355\u4e00\u6570\u636e\u96c6\u9a8c\u8bc1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5e38\u89c1\u505a\u6cd5\u53ef\u80fd\u4f1a\u9650\u5236\u6a21\u578b\u7684\u901a\u7528\u6027\u3002", "method": "\u8003\u8651\u4e86\u6765\u81ea\u4e0d\u540c\u897f\u65b9\u6587\u5316\u7684\u4e09\u4e2a\u6291\u90c1\u6570\u636e\u96c6\uff08\u5fb7\u56fd\uff1aAVEC2013\u3001\u6fb3\u5927\u5229\u4e9a\uff1aBlackdog\u548c\u7f8e\u56fd\uff1aPitt\uff09\uff0c\u4f7f\u7528\u4e24\u79cd\u65b9\u6cd5\u7814\u7a76\u4ece\u8fd9\u4e9b\u6570\u636e\u96c6\u4e2d\u5f97\u51fa\u7684kineme\u6a21\u5f0f\u7684\u901a\u7528\u6027\uff1a(i) \u5728\u5355\u4e2a/\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684k\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u4ee5\u53ca (ii) \u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u578b\u91cd\u7528\u3002\u4f7f\u7528\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8bc4\u4f30\u5206\u7c7b\u548c\u56de\u5f52\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff1a(1) \u5934\u90e8\u8fd0\u52a8\u6a21\u5f0f\u662f\u4f30\u8ba1\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u7684\u6709\u6548\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u5ea6\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u6027\u80fd\uff0c\u5305\u62ec\u5728AVEC2013\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u7b2c\u4e8c\u597d\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u3002(2) \u57fa\u4e8ekineme\u7684\u7279\u5f81\u5bf9\u4e8e\u4e8c\u5143\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u6bd4\u539f\u59cb\u5934\u90e8\u8fd0\u52a8\u63cf\u8ff0\u7b26\u66f4\u5177\u901a\u7528\u6027\uff0c\u5bf9\u4e8e\u4e25\u91cd\u7a0b\u5ea6\u4f30\u8ba1\uff08\u56de\u5f52\uff09\u6bd4\u5176\u4ed6\u89c6\u89c9\u884c\u4e3a\u7ebf\u7d22\u66f4\u5177\u901a\u7528\u6027\u3002", "conclusion": "\u5934\u90e8\u8fd0\u52a8\u6a21\u5f0f\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u751f\u7269\u6807\u5fd7\u7269\u7528\u4e8e\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u7684\u4f30\u8ba1\uff0c\u5e76\u4e14\u57fa\u4e8ekineme\u7684\u7279\u5f81\u76f8\u6bd4\u5176\u4ed6\u7279\u5f81\u66f4\u5177\u901a\u7528\u6027\u3002"}}
{"id": "2505.23433", "pdf": "https://arxiv.org/pdf/2505.23433", "abs": "https://arxiv.org/abs/2505.23433", "authors": ["Jian Yao", "Ran Cheng", "Xingyu Wu", "Jibin Wu", "Kay Chen Tan"], "title": "Diversity-Aware Policy Optimization for Large Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "The reasoning capabilities of large language models (LLMs) have advanced\nrapidly, particularly following the release of DeepSeek R1, which has inspired\na surge of research into data quality and reinforcement learning (RL)\nalgorithms. Despite the pivotal role diversity plays in RL, its influence on\nLLM reasoning remains largely underexplored. To bridge this gap, this work\npresents a systematic investigation into the impact of diversity in RL-based\ntraining for LLM reasoning, and proposes a novel diversity-aware policy\noptimization method. Across evaluations on 12 LLMs, we observe a strong\npositive correlation between the solution diversity and Potential at k (a novel\nmetric quantifying an LLM's reasoning potential) in high-performing models.\nThis finding motivates our method to explicitly promote diversity during RL\ntraining. Specifically, we design a token-level diversity and reformulate it\ninto a practical objective, then we selectively apply it to positive samples.\nIntegrated into the R1-zero training framework, our method achieves a 3.5\npercent average improvement across four mathematical reasoning benchmarks,\nwhile generating more diverse and robust solutions.", "AI": {"tldr": "\u4e3a\u4e86\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u672c\u6587\u7814\u7a76\u4e86RL\u8bad\u7ec3\u4e2d\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6837\u6027\u611f\u77e5\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728R1-zero\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e863.5%\u7684\u5e73\u5747\u6539\u8fdb\uff0c\u5e76\u751f\u6210\u66f4\u591a\u6837\u548c\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6837\u6027\u5728\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5176\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5730\u7814\u7a76\u591a\u6837\u6027\u5728\u57fa\u4e8eRL\u7684LLM\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cdtoken\u7ea7\u522b\u7684\u591a\u6837\u6027\uff0c\u5e76\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5b9e\u7528\u7684\u76ee\u6807\u51fd\u6570\uff0c\u7136\u540e\u6709\u9009\u62e9\u6027\u5730\u5c06\u5176\u5e94\u7528\u4e8e\u6b63\u6837\u672c\u3002\u6b64\u65b9\u6cd5\u88ab\u6574\u5408\u5230R1-zero\u8bad\u7ec3\u6846\u67b6\u4e2d\u3002", "result": "\u5728\u5bf912\u4e2aLLM\u7684\u8bc4\u4f30\u4e2d\uff0c\u53d1\u73b0\u9ad8\u6027\u80fd\u6a21\u578b\u4e2d\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\u548cPotential at k\uff08\u4e00\u79cd\u91cf\u5316LLM\u63a8\u7406\u6f5c\u529b\u7684\u65b0\u6307\u6807\uff09\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u6b63\u76f8\u5173\u5173\u7cfb\u3002\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u5347\u4e863.5%\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u4fc3\u8fdbRL\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u591a\u6837\u6027\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.23442", "pdf": "https://arxiv.org/pdf/2505.23442", "abs": "https://arxiv.org/abs/2505.23442", "authors": ["Linyu Li", "Zhi Jin", "Yuanpeng He", "Dongming Jin", "Haoran Duan", "Zhengwei Tao", "Xuan Zhang", "Jiandong Li"], "title": "Rethinking Regularization Methods for Knowledge Graph Completion", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Knowledge graph completion (KGC) has attracted considerable attention in\nrecent years because it is critical to improving the quality of knowledge\ngraphs. Researchers have continuously explored various models. However, most\nprevious efforts have neglected to take advantage of regularization from a\ndeeper perspective and therefore have not been used to their full potential.\nThis paper rethinks the application of regularization methods in KGC. Through\nextensive empirical studies on various KGC models, we find that carefully\ndesigned regularization not only alleviates overfitting and reduces variance\nbut also enables these models to break through the upper bounds of their\noriginal performance. Furthermore, we introduce a novel sparse-regularization\nmethod that embeds the concept of rank-based selective sparsity into the KGC\nregularizer. The core idea is to selectively penalize those components with\nsignificant features in the embedding vector, thus effectively ignoring many\ncomponents that contribute little and may only represent noise. Various\ncomparative experiments on multiple datasets and multiple models show that the\nSPR regularization method is better than other regularization methods and can\nenable the KGC model to further break through the performance margin.", "AI": {"tldr": "\u672c\u7814\u7a76\u91cd\u65b0\u601d\u8003\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u4e2d\u6b63\u5219\u5316\u65b9\u6cd5\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a00\u758f\u6b63\u5219\u5316\u65b9\u6cd5\uff08SPR\uff09\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5730\u60e9\u7f5a\u5d4c\u5165\u5411\u91cf\u4e2d\u6709\u663e\u8457\u7279\u5f81\u7684\u7ec4\u4ef6\uff0c\u5ffd\u7565\u90a3\u4e9b\u8d21\u732e\u5c0f\u4e14\u53ef\u80fd\u4ee3\u8868\u566a\u58f0\u7684\u90e8\u5206\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSPR \u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u80fd\u8fdb\u4e00\u6b65\u7a81\u7834 KGC \u6a21\u578b\u7684\u6027\u80fd\u4e0a\u9650\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u5bf9\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u7684\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u5148\u524d\u7684\u7814\u7a76\u672a\u80fd\u4ece\u66f4\u6df1\u5c42\u6b21\u7684\u89d2\u5ea6\u5229\u7528\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u4ece\u800c\u672a\u80fd\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u6b63\u5219\u5316\u5728 KGC \u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u63a2\u7d22\u5176\u6f5c\u5728\u4f18\u52bf\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5bf9\u591a\u79cd KGC \u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6b63\u5219\u5316\u4e0d\u4ec5\u53ef\u4ee5\u7f13\u89e3\u8fc7\u62df\u5408\u548c\u964d\u4f4e\u65b9\u5dee\uff0c\u8fd8\u80fd\u4f7f\u6a21\u578b\u7a81\u7834\u539f\u6709\u6027\u80fd\u7684\u4e0a\u9650\u3002\u57fa\u4e8e\u6b64\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a00\u758f\u6b63\u5219\u5316\u65b9\u6cd5\uff08SPR\uff09\uff0c\u8be5\u65b9\u6cd5\u5c06\u57fa\u4e8e\u6392\u540d\u7684\u9009\u62e9\u6027\u7a00\u758f\u6982\u5ff5\u5d4c\u5165\u5230 KGC \u6b63\u5219\u5316\u5668\u4e2d\u3002\u6838\u5fc3\u601d\u60f3\u662f\u9009\u62e9\u6027\u5730\u60e9\u7f5a\u5d4c\u5165\u5411\u91cf\u4e2d\u5177\u6709\u663e\u8457\u7279\u5f81\u7684\u7ec4\u4ef6\uff0c\u4ece\u800c\u6709\u6548\u5ffd\u7565\u90a3\u4e9b\u8d21\u732e\u8f83\u5c0f\u4e14\u53ef\u80fd\u4ec5\u8868\u793a\u566a\u58f0\u7684\u90e8\u5206\u3002", "result": "\u5404\u79cd\u6bd4\u8f83\u5b9e\u9a8c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u591a\u4e2a\u6a21\u578b\u4e0a\u8868\u660e\uff0cSPR \u6b63\u5219\u5316\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5e76\u80fd\u4f7f KGC \u6a21\u578b\u8fdb\u4e00\u6b65\u7a81\u7834\u6027\u80fd\u8fb9\u754c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6b63\u5219\u5316\u5bf9\u4e8e KGC \u81f3\u5173\u91cd\u8981\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fc7\u62df\u5408\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u63d0\u51fa\u7684 SPR \u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u9009\u62e9\u6027\u7a00\u758f\u7684\u6982\u5ff5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9 KGC \u6a21\u578b\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002"}}
{"id": "2505.23443", "pdf": "https://arxiv.org/pdf/2505.23443", "abs": "https://arxiv.org/abs/2505.23443", "authors": ["Benyamin Trachtenberg", "Nir Rosenfeld"], "title": "Strategic Classification with Non-Linear Classifiers", "categories": ["cs.LG"], "comment": null, "summary": "In strategic classification, the standard supervised learning setting is\nextended to support the notion of strategic user behavior in the form of costly\nfeature manipulations made in response to a classifier. While standard learning\nsupports a broad range of model classes, the study of strategic classification\nhas, so far, been dedicated mostly to linear classifiers. This work aims to\nexpand the horizon by exploring how strategic behavior manifests under\nnon-linear classifiers and what this implies for learning. We take a bottom-up\napproach showing how non-linearity affects decision boundary points, classifier\nexpressivity, and model classes complexity. A key finding is that universal\napproximators (e.g., neural nets) are no longer universal once the environment\nis strategic. We demonstrate empirically how this can create performance gaps\neven on an unrestricted model class.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6218\u7565\u6027\u5206\u7c7b\u4e2d\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e00\u65e6\u73af\u5883\u53d8\u5f97\u6218\u7565\u6027\uff0c\u901a\u7528\u903c\u8fd1\u5668\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u4e0d\u518d\u5177\u6709\u901a\u7528\u6027\uff0c\u5e76\u4e14\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u6807\u51c6\u5b66\u4e60\u652f\u6301\u5e7f\u6cdb\u7684\u6a21\u578b\u7c7b\u522b\uff0c\u4f46\u6218\u7565\u5206\u7c7b\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u7ebf\u6027\u5206\u7c7b\u5668\u4e0a\u3002\u4f5c\u8005\u5e0c\u671b\u6269\u5c55\u8fd9\u4e00\u9886\u57df\uff0c\u63a2\u7d22\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u4e0b\u7684\u6218\u7565\u6027\u884c\u4e3a\u53ca\u5176\u5bf9\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u975e\u7ebf\u6027\u5982\u4f55\u5f71\u54cd\u51b3\u7b56\u8fb9\u754c\u70b9\u3001\u5206\u7c7b\u5668\u8868\u8fbe\u80fd\u529b\u4ee5\u53ca\u6a21\u578b\u7c7b\u522b\u7684\u590d\u6742\u6027\u3002", "result": "\u5173\u952e\u53d1\u73b0\u662f\u901a\u7528\u903c\u8fd1\u5668\uff08\u4f8b\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u4e00\u65e6\u5904\u4e8e\u6218\u7565\u6027\u73af\u5883\u4e2d\u5c31\u4e0d\u518d\u662f\u901a\u7528\u7684\uff0c\u5e76\u4e14\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u53ef\u80fd\u5728\u4e0d\u53d7\u9650\u7684\u6a21\u578b\u7c7b\u522b\u4e0a\u4ea7\u751f\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u5728\u6218\u7565\u6027\u73af\u5883\u4e2d\u7684\u8868\u73b0\u4e0d\u540c\u4e8e\u7ebf\u6027\u5206\u7c7b\u5668\uff0c\u8fd9\u5bf9\u5b66\u4e60\u548c\u6a21\u578b\u9009\u62e9\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2505.23448", "pdf": "https://arxiv.org/pdf/2505.23448", "abs": "https://arxiv.org/abs/2505.23448", "authors": ["Pirzada Suhail", "Rehna Afroz", "Amit Sethi"], "title": "Network Inversion for Uncertainty-Aware Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection and uncertainty estimation (UE) are\ncritical components for building safe machine learning systems, especially in\nreal-world scenarios where unexpected inputs are inevitable. In this work, we\npropose a novel framework that combines network inversion with classifier\ntraining to simultaneously address both OOD detection and uncertainty\nestimation. For a standard n-class classification task, we extend the\nclassifier to an (n+1)-class model by introducing a \"garbage\" class, initially\npopulated with random gaussian noise to represent outlier inputs. After each\ntraining epoch, we use network inversion to reconstruct input images\ncorresponding to all output classes that initially appear as noisy and\nincoherent and are therefore excluded to the garbage class for retraining the\nclassifier. This cycle of training, inversion, and exclusion continues\niteratively till the inverted samples begin to resemble the in-distribution\ndata more closely, suggesting that the classifier has learned to carve out\nmeaningful decision boundaries while sanitising the class manifolds by pushing\nOOD content into the garbage class. During inference, this training scheme\nenables the model to effectively detect and reject OOD samples by classifying\nthem into the garbage class. Furthermore, the confidence scores associated with\neach prediction can be used to estimate uncertainty for both in-distribution\nand OOD inputs. Our approach is scalable, interpretable, and does not require\naccess to external OOD datasets or post-hoc calibration techniques while\nproviding a unified solution to the dual challenges of OOD detection and\nuncertainty estimation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7f51\u7edc\u53cd\u6f14\u548c\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u89e3\u51b3OOD\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165'\u5783\u573e'\u7c7b\uff0c\u6a21\u578b\u80fd\u591f\u6709\u6548\u533a\u5206\u5e76\u62d2\u7eddOOD\u6837\u672c\uff0c\u5e76\u901a\u8fc7\u7f6e\u4fe1\u5206\u6570\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u90e8OOD\u6570\u636e\u96c6\u6216\u4e8b\u540e\u6821\u51c6\u6280\u672f\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u6784\u5efa\u5b89\u5168\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u9700\u8981\u6709\u6548\u7684OOD\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u53ef\u907f\u514d\u7684\u610f\u5916\u8f93\u5165\u3002", "method": "1. \u5c06\u6807\u51c6n\u7c7b\u5206\u7c7b\u4efb\u52a1\u6269\u5c55\u4e3a(n+1)\u7c7b\u6a21\u578b\uff0c\u65b0\u589e\u4e00\u4e2a'\u5783\u573e'\u7c7b\uff0c\u521d\u59cb\u586b\u5145\u968f\u673a\u9ad8\u65af\u566a\u58f0\u4ee5\u8868\u793a\u5f02\u5e38\u8f93\u5165\u3002\n2. \u5728\u6bcf\u6b21\u8bad\u7ec3\u5468\u671f\u540e\uff0c\u4f7f\u7528\u7f51\u7edc\u53cd\u6f14\u91cd\u5efa\u6240\u6709\u8f93\u51fa\u7c7b\u522b\u7684\u8f93\u5165\u56fe\u50cf\uff0c\u5c06\u6700\u521d\u8868\u73b0\u4e3a\u566a\u58f0\u4e14\u4e0d\u8fde\u8d2f\u7684\u6837\u672c\u5f52\u5165'\u5783\u573e'\u7c7b\u3002\n3. \u8fed\u4ee3\u6267\u884c\u8bad\u7ec3\u3001\u53cd\u6f14\u548c\u6392\u9664\u8fc7\u7a0b\uff0c\u76f4\u5230\u53cd\u6f14\u6837\u672c\u66f4\u63a5\u8fd1\u5206\u5e03\u5185\u6570\u636e\uff0c\u4ece\u800c\u4f18\u5316\u5206\u7c7b\u5668\u51b3\u7b56\u8fb9\u754c\u5e76\u5c06OOD\u5185\u5bb9\u63a8\u5165'\u5783\u573e'\u7c7b\u3002", "result": "\u6a21\u578b\u80fd\u591f\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u5c06OOD\u6837\u672c\u5206\u7c7b\u5230'\u5783\u573e'\u7c7b\u6765\u6709\u6548\u68c0\u6d4b\u5e76\u62d2\u7edd\u5b83\u4eec\uff0c\u540c\u65f6\u5229\u7528\u9884\u6d4b\u7f6e\u4fe1\u5206\u6570\u4f30\u8ba1\u5206\u5e03\u5185\u5916\u8f93\u5165\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u65e0\u9700\u5916\u90e8OOD\u6570\u636e\u96c6\u6216\u4e8b\u540e\u6821\u51c6\u6280\u672f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86OOD\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u53cc\u91cd\u6311\u6218\uff0c\u5177\u5907\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2505.23458", "pdf": "https://arxiv.org/pdf/2505.23458", "abs": "https://arxiv.org/abs/2505.23458", "authors": ["Kevin Frans", "Seohong Park", "Pieter Abbeel", "Sergey Levine"], "title": "Diffusion Guidance Is a Controllable Policy Improvement Operator", "categories": ["cs.LG"], "comment": null, "summary": "At the core of reinforcement learning is the idea of learning beyond the\nperformance in the data. However, scaling such systems has proven notoriously\ntricky. In contrast, techniques from generative modeling have proven remarkably\nscalable and are simple to train. In this work, we combine these strengths, by\nderiving a direct relation between policy improvement and guidance of diffusion\nmodels. The resulting framework, CFGRL, is trained with the simplicity of\nsupervised learning, yet can further improve on the policies in the data. On\noffline RL tasks, we observe a reliable trend -- increased guidance weighting\nleads to increased performance. Of particular importance, CFGRL can operate\nwithout explicitly learning a value function, allowing us to generalize simple\nsupervised methods (e.g., goal-conditioned behavioral cloning) to further\nprioritize optimality, gaining performance for \"free\" across the board.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23459", "pdf": "https://arxiv.org/pdf/2505.23459", "abs": "https://arxiv.org/abs/2505.23459", "authors": ["Safwan Labbi", "Paul Mangold", "Daniil Tiapkin", "Eric Moulines"], "title": "On Global Convergence Rates for Federated Policy Gradient under Heterogeneous Environment", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Ensuring convergence of policy gradient methods in federated reinforcement\nlearning (FRL) under environment heterogeneity remains a major challenge. In\nthis work, we first establish that heterogeneity, perhaps counter-intuitively,\ncan necessitate optimal policies to be non-deterministic or even time-varying,\neven in tabular environments. Subsequently, we prove global convergence results\nfor federated policy gradient (FedPG) algorithms employing local updates, under\na {\\L}ojasiewicz condition that holds only for each individual agent, in both\nentropy-regularized and non-regularized scenarios. Crucially, our theoretical\nanalysis shows that FedPG attains linear speed-up with respect to the number of\nagents, a property central to efficient federated learning. Leveraging insights\nfrom our theoretical findings, we introduce b-RS-FedPG, a novel policy gradient\nmethod that employs a carefully constructed softmax-inspired parameterization\ncoupled with an appropriate regularization scheme. We further demonstrate\nexplicit convergence rates for b-RS-FedPG toward near-optimal stationary\npolicies. Finally, we demonstrate that empirically both FedPG and b-RS-FedPG\nconsistently outperform federated Q-learning on heterogeneous settings.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23470", "pdf": "https://arxiv.org/pdf/2505.23470", "abs": "https://arxiv.org/abs/2505.23470", "authors": ["Chenjie Li", "Amir Gilad", "Boris Glavic", "Zhengjie Miao", "Sudeepa Roy"], "title": "Refining Labeling Functions with Limited Labeled Data", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "techreport", "summary": "Programmatic weak supervision (PWS) significantly reduces human effort for\nlabeling data by combining the outputs of user-provided labeling functions\n(LFs) on unlabeled datapoints. However, the quality of the generated labels\ndepends directly on the accuracy of the LFs. In this work, we study the problem\nof fixing LFs based on a small set of labeled examples. Towards this goal, we\ndevelop novel techniques for repairing a set of LFs by minimally changing their\nresults on the labeled examples such that the fixed LFs ensure that (i) there\nis sufficient evidence for the correct label of each labeled datapoint and (ii)\nthe accuracy of each repaired LF is sufficiently high. We model LFs as\nconditional rules which enables us to refine them, i.e., to selectively change\ntheir output for some inputs. We demonstrate experimentally that our system\nimproves the quality of LFs based on surprisingly small sets of labeled\ndatapoints.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u6765\u4fee\u590d\u6807\u7b7e\u51fd\u6570(LFs)\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u7a0b\u5e8f\u5316\u5f31\u76d1\u7763\u4e2d\u7684\u6807\u7b7e\u8d28\u91cf\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u53ef\u4ee5\u901a\u8fc7\u6781\u5c0f\u7684\u6807\u6ce8\u6570\u636e\u96c6\u6765\u63d0\u5347LFs\u7684\u8d28\u91cf\u3002", "motivation": "\u7a0b\u5e8f\u5316\u5f31\u76d1\u7763\uff08PWS\uff09\u867d\u80fd\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684\u52aa\u529b\uff0c\u4f46\u751f\u6210\u6807\u7b7e\u7684\u8d28\u91cf\u76f4\u63a5\u4f9d\u8d56\u4e8e\u6807\u7b7e\u51fd\u6570\uff08LFs\uff09\u7684\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u57fa\u4e8e\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u6765\u4fee\u590dLFs\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06LFs\u5efa\u6a21\u4e3a\u6761\u4ef6\u89c4\u5219\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6280\u672f\u6765\u6700\u5c0f\u5316\u6539\u53d8\u5b83\u4eec\u5728\u6807\u6ce8\u6837\u4f8b\u4e0a\u7684\u7ed3\u679c\uff0c\u4ece\u800c\u4fee\u590d\u8fd9\u4e9bLFs\u3002\u4fee\u590d\u540e\u7684LFs\u9700\u8981\u786e\u4fdd\uff1a(i) \u6bcf\u4e2a\u6807\u6ce8\u6570\u636e\u70b9\u7684\u6b63\u786e\u6807\u7b7e\u6709\u8db3\u591f\u7684\u8bc1\u636e\uff1b(ii) \u6bcf\u4e2a\u4fee\u590d\u540e\u7684LF\u7684\u51c6\u786e\u7387\u8db3\u591f\u9ad8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u57fa\u4e8e\u4ee4\u4eba\u60ca\u8bb6\u7684\u5c0f\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u70b9\u96c6\u6765\u63d0\u5347LFs\u7684\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u5c11\u91cf\u6807\u6ce8\u6837\u4f8b\u4fee\u590dLFs\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u7a0b\u5e8f\u5316\u5f31\u76d1\u7763\u4e2d\u751f\u6210\u6807\u7b7e\u7684\u8d28\u91cf\uff0c\u4e14\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.23489", "pdf": "https://arxiv.org/pdf/2505.23489", "abs": "https://arxiv.org/abs/2505.23489", "authors": ["Ildus Sadrtdinov", "Ivan Klimov", "Ekaterina Lobacheva", "Dmitry Vetrov"], "title": "SGD as Free Energy Minimization: A Thermodynamic View on Neural Network Training", "categories": ["cs.LG"], "comment": "First two authors contributed equally", "summary": "We present a thermodynamic interpretation of the stationary behavior of\nstochastic gradient descent (SGD) under fixed learning rates (LRs) in neural\nnetwork training. We show that SGD implicitly minimizes a free energy function\n$F=U-TS$, balancing training loss $U$ and the entropy of the weights\ndistribution $S$, with temperature $T$ determined by the LR. This perspective\noffers a new lens on why high LRs prevent training from converging to the loss\nminima and how different LRs lead to stabilization at different loss levels. We\nempirically validate the free energy framework on both underparameterized (UP)\nand overparameterized (OP) models. UP models consistently follow free energy\nminimization, with temperature increasing monotonically with LR, while for OP\nmodels, the temperature effectively drops to zero at low LRs, causing SGD to\nminimize the loss directly and converge to an optimum. We attribute this\nmismatch to differences in the signal-to-noise ratio of stochastic gradients\nnear optima, supported by both a toy example and neural network experiments.", "AI": {"tldr": "\u5728\u56fa\u5b9a\u5b66\u4e60\u7387\uff08LRs\uff09\u4e0b\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u7a33\u6001\u884c\u4e3a\u53ef\u4ee5\u7528\u70ed\u529b\u5b66\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u6765\u89e3\u91ca\u3002\u9ad8LR\u9632\u6b62\u6536\u655b\u5230\u635f\u5931\u6700\u5c0f\u503c\uff0c\u800c\u4e0d\u540cLR\u5bfc\u81f4\u7a33\u5b9a\u5728\u4e0d\u540c\u7684\u635f\u5931\u6c34\u5e73\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6b20\u53c2\u6570\u5316\uff08UP\uff09\u548c\u8fc7\u53c2\u6570\u5316\uff08OP\uff09\u6a21\u578b\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u4e3a\u4ec0\u4e48\u5728\u56fa\u5b9a\u5b66\u4e60\u7387\u4e0b\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u7279\u5b9a\u7684\u7a33\u6001\u884c\u4e3a\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u5b66\u4e60\u7387\u5982\u4f55\u5f71\u54cd\u8bad\u7ec3\u8fc7\u7a0b\u53ca\u6700\u7ec8\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u70ed\u529b\u5b66\u81ea\u7531\u80fd\u7684\u6982\u5ff5\uff0c\u5c06SGD\u89c6\u4e3a\u4e00\u79cd\u9690\u5f0f\u6700\u5c0f\u5316\u81ea\u7531\u80fd\u7684\u8fc7\u7a0b\uff0c\u5e73\u8861\u8bad\u7ec3\u635f\u5931\u548c\u6743\u91cd\u5206\u5e03\u71b5\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u6846\u67b6\u5728\u6b20\u53c2\u6570\u5316\u548c\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e76\u5206\u6790\u4e24\u79cd\u6a21\u578b\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6b20\u53c2\u6570\u5316\u6a21\u578b\u59cb\u7ec8\u9075\u5faa\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u539f\u5219\uff0c\u6e29\u5ea6\u968f\u5b66\u4e60\u7387\u5355\u8c03\u589e\u52a0\uff1b\u800c\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u5728\u4f4e\u5b66\u4e60\u7387\u65f6\u6709\u6548\u6e29\u5ea6\u964d\u4e3a\u96f6\uff0cSGD\u76f4\u63a5\u6700\u5c0f\u5316\u635f\u5931\u5e76\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002\u8fd9\u79cd\u5dee\u5f02\u5f52\u56e0\u4e8e\u8fd1\u4f18\u89e3\u5904\u968f\u673a\u68af\u5ea6\u7684\u4fe1\u566a\u6bd4\u4e0d\u540c\u3002", "conclusion": "SGD\u5728\u56fa\u5b9a\u5b66\u4e60\u7387\u4e0b\u7684\u884c\u4e3a\u53ef\u4ee5\u901a\u8fc7\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u7406\u8bba\u8fdb\u884c\u89e3\u91ca\uff0c\u8fd9\u4e00\u89c6\u89d2\u6709\u52a9\u4e8e\u7406\u89e3\u4e0d\u540c\u5b66\u4e60\u7387\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u6b20\u53c2\u6570\u5316\u548c\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u5f02\u3002"}}
{"id": "2505.23506", "pdf": "https://arxiv.org/pdf/2505.23506", "abs": "https://arxiv.org/abs/2505.23506", "authors": ["Sebasti\u00e1n Jim\u00e9nez", "Mira J\u00fcrgens", "Willem Waegeman"], "title": "Why Machine Learning Models Fail to Fully Capture Epistemic Uncertainty", "categories": ["cs.LG"], "comment": null, "summary": "In recent years various supervised learning methods that disentangle\naleatoric and epistemic uncertainty based on second-order distributions have\nbeen proposed. We argue that these methods fail to capture critical components\nof epistemic uncertainty, particularly due to the often-neglected component of\nmodel bias. To show this, we make use of a more fine-grained taxonomy of\nepistemic uncertainty sources in machine learning models, and analyse how the\nclassical bias-variance decomposition of the expected prediction error can be\ndecomposed into different parts reflecting these uncertainties. By using a\nsimulation-based evaluation protocol which encompasses epistemic uncertainty\ndue to both procedural- and data-driven uncertainty components, we illustrate\nthat current methods rarely capture the full spectrum of epistemic uncertainty.\nThrough theoretical insights and synthetic experiments, we show that high model\nbias can lead to misleadingly low estimates of epistemic uncertainty, and\ncommon second-order uncertainty quantification methods systematically blur\nbias-induced errors into aleatoric estimates, thereby underrepresenting\nepistemic uncertainty. Our findings underscore that meaningful aleatoric\nestimates are feasible only if all relevant sources of epistemic uncertainty\nare properly represented.", "AI": {"tldr": "\u5c3d\u7ba1\u8fd1\u5e74\u6765\u51fa\u73b0\u4e86\u4e00\u4e9b\u57fa\u4e8e\u4e8c\u9636\u5206\u5e03\u7684\u89e3\u8026\u65b9\u6cd5\u6765\u5904\u7406\u968f\u673a\u6027\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u952e\u6210\u5206\uff0c\u7279\u522b\u662f\u7ecf\u5e38\u88ab\u5ffd\u89c6\u7684\u6a21\u578b\u504f\u5dee\u90e8\u5206\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5408\u6210\u5b9e\u9a8c\uff0c\u672c\u6587\u8868\u660e\u9ad8\u6a21\u578b\u504f\u5dee\u53ef\u80fd\u5bfc\u81f4\u5bf9\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u4f4e\u4f30\uff0c\u5e76\u4e14\u5e38\u89c1\u7684\u4e8c\u9636\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7cfb\u7edf\u6027\u5730\u5c06\u504f\u5dee\u5f15\u8d77\u7684\u8bef\u5dee\u6df7\u5165\u968f\u673a\u6027\u4f30\u8ba1\u4e2d\uff0c\u4ece\u800c\u4f4e\u4f30\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u53ea\u6709\u5728\u6240\u6709\u76f8\u5173\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u90fd\u88ab\u6b63\u786e\u8868\u793a\u65f6\uff0c\u6709\u610f\u4e49\u7684\u968f\u673a\u6027\u4f30\u8ba1\u624d\u662f\u53ef\u884c\u7684\u3002", "motivation": "\u5f53\u524d\u5404\u79cd\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u89e3\u8026\u968f\u673a\u6027\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5b83\u4eec\u672a\u80fd\u6355\u6349\u5230\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e2d\u7684\u5173\u952e\u6210\u5206\uff0c\u5c24\u5176\u662f\u6a21\u578b\u504f\u5dee\u8fd9\u4e00\u5e38\u88ab\u5ffd\u89c6\u7684\u56e0\u7d20\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u4e86\u4e00\u4e2a\u66f4\u7ec6\u81f4\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u671f\u671b\u9884\u6d4b\u8bef\u5dee\u7684\u7ecf\u5178\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u5982\u4f55\u53cd\u6620\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u3002\u5e76\u901a\u8fc7\u57fa\u4e8e\u6a21\u62df\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u6db5\u76d6\u7a0b\u5e8f\u6027\u548c\u6570\u636e\u9a71\u52a8\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7ec4\u4ef6\uff0c\u6765\u8bf4\u660e\u73b0\u6709\u65b9\u6cd5\u5f88\u5c11\u80fd\u6355\u6349\u5230\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u5b8c\u6574\u8303\u56f4\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u9ad8\u6a21\u578b\u504f\u5dee\u53ef\u80fd\u5bfc\u81f4\u5bf9\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u8bef\u5bfc\u6027\u4f4e\u4f30\uff0c\u5e76\u4e14\u5e38\u89c1\u7684\u4e8c\u9636\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7cfb\u7edf\u6027\u5730\u5c06\u504f\u5dee\u5f15\u8d77\u7684\u8bef\u5dee\u6df7\u5165\u968f\u673a\u6027\u4f30\u8ba1\u4e2d\u3002", "conclusion": "\u53ea\u6709\u5f53\u6240\u6709\u76f8\u5173\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u90fd\u88ab\u6b63\u786e\u8868\u793a\u65f6\uff0c\u624d\u6709\u610f\u4e49\u8fdb\u884c\u968f\u673a\u6027\u4f30\u8ba1\u3002"}}
{"id": "2505.23520", "pdf": "https://arxiv.org/pdf/2505.23520", "abs": "https://arxiv.org/abs/2505.23520", "authors": ["Yu Zhang", "Dong Guo", "Fang Wu", "Guoliang Zhu", "Dian Ding", "Yiming Zhang"], "title": "AnchorAttention: Difference-Aware Sparse Attention with Stripe Granularity", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) with extended context lengths face significant\ncomputational challenges during the pre-filling phase, primarily due to the\nquadratic complexity of self-attention. Existing methods typically employ\ndynamic pattern matching and block-sparse low-level implementations. However,\ntheir reliance on local information for pattern identification fails to capture\nglobal contexts, and the coarse granularity of blocks leads to persistent\ninternal sparsity, resulting in suboptimal accuracy and efficiency. To address\nthese limitations, we propose \\textbf{AnchorAttention}, a difference-aware,\ndynamic sparse attention mechanism that efficiently identifies critical\nattention regions at a finer stripe granularity while adapting to global\ncontextual information, achieving superior speed and accuracy. AnchorAttention\ncomprises three key components: (1) \\textbf{Pattern-based Anchor Computation},\nleveraging the commonalities present across all inputs to rapidly compute a set\nof near-maximum scores as the anchor; (2) \\textbf{Difference-aware Stripe\nSparsity Identification}, performing difference-aware comparisons with the\nanchor to quickly obtain discrete coordinates of significant regions in a\nstripe-like sparsity pattern; (3) \\textbf{Fine-grained Sparse Computation},\nreplacing the traditional contiguous KV block loading approach with\nsimultaneous discrete KV position loading to maximize sparsity rates while\npreserving full hardware computational potential. With its finer-grained\nsparsity strategy, \\textbf{AnchorAttention} achieves higher sparsity rates at\nthe same recall level, significantly reducing computation time. Compared to\nprevious state-of-the-art methods, at a text length of 128k, it achieves a\nspeedup of 1.44$\\times$ while maintaining higher recall rates.", "AI": {"tldr": "AnchorAttention\u662f\u4e00\u79cd\u65b0\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u6761\u7eb9\u7a00\u758f\u6027\u548c\u5168\u5c40\u4fe1\u606f\u9002\u5e94\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u586b\u5145\u9636\u6bb5\u7684\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5728128k\u6587\u672c\u957f\u5ea6\u4e0b\uff0c\u901f\u5ea6\u63d0\u5347\u4e861.44\u500d\u4e14\u53ec\u56de\u7387\u66f4\u9ad8\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u6001\u6a21\u5f0f\u5339\u914d\u548c\u5757\u7a00\u758f\u4f4e\u7ea7\u5b9e\u73b0\u65b9\u6cd5\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4f9d\u8d56\u5c40\u90e8\u4fe1\u606f\u65e0\u6cd5\u6355\u6349\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u5757\u7684\u7c97\u7c92\u5ea6\u5bfc\u81f4\u5185\u90e8\u7a00\u758f\u6027\u6301\u7eed\u5b58\u5728\uff0c\u4ece\u800c\u5f71\u54cd\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "AnchorAttention\u7531\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u7ec4\u6210\uff1a(1)\u57fa\u4e8e\u6a21\u5f0f\u7684\u951a\u70b9\u8ba1\u7b97\uff0c\u5229\u7528\u8f93\u5165\u4e2d\u7684\u5171\u6027\u5feb\u901f\u8ba1\u7b97\u4e00\u7ec4\u63a5\u8fd1\u6700\u5927\u503c\u7684\u5206\u6570\u4f5c\u4e3a\u951a\u70b9\uff1b(2)\u5dee\u5f02\u611f\u77e5\u7684\u6761\u7eb9\u7a00\u758f\u6027\u8bc6\u522b\uff0c\u4e0e\u951a\u70b9\u8fdb\u884c\u5dee\u5f02\u611f\u77e5\u6bd4\u8f83\u4ee5\u83b7\u53d6\u663e\u8457\u533a\u57df\u7684\u79bb\u6563\u5750\u6807\uff1b(3)\u7ec6\u7c92\u5ea6\u7a00\u758f\u8ba1\u7b97\uff0c\u7528\u540c\u65f6\u52a0\u8f7d\u79bb\u6563KV\u4f4d\u7f6e\u4ee3\u66ff\u4f20\u7edf\u7684\u8fde\u7eedKV\u5757\u52a0\u8f7d\uff0c\u4ee5\u6700\u5927\u5316\u7a00\u758f\u7387\u5e76\u4fdd\u6301\u786c\u4ef6\u8ba1\u7b97\u6f5c\u529b\u3002", "result": "AnchorAttention\u5728\u76f8\u540c\u7684\u53ec\u56de\u6c34\u5e73\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7a00\u758f\u7387\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002\u5728128k\u6587\u672c\u957f\u5ea6\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u901f\u5ea6\u63d0\u5347\u4e861.44\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u53ec\u56de\u7387\u3002", "conclusion": "AnchorAttention\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u7a00\u758f\u7b56\u7565\u548c\u5bf9\u5168\u5c40\u4fe1\u606f\u7684\u9002\u5e94\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u4e2d\u7684\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2505.23523", "pdf": "https://arxiv.org/pdf/2505.23523", "abs": "https://arxiv.org/abs/2505.23523", "authors": ["Arjun Devraj", "Eric Ding", "Abhishek Vijaya Kumar", "Robert Kleinberg", "Rachee Singh"], "title": "Accelerating AllReduce with a Persistent Straggler", "categories": ["cs.LG", "cs.DC"], "comment": "23 pages, 11 figures", "summary": "Distributed machine learning workloads use data and tensor parallelism for\ntraining and inference, both of which rely on the AllReduce collective to\nsynchronize gradients or activations. However, bulk-synchronous AllReduce\nalgorithms can be delayed by a persistent straggler that is slower to reach the\nsynchronization barrier required to begin the collective. To address this\nchallenge, we propose StragglAR: an AllReduce algorithm that accelerates\ndistributed training and inference in the presence of persistent stragglers.\nStragglAR implements a ReduceScatter among the remaining GPUs during the\nstraggler-induced delay, and then executes a novel collective algorithm to\ncomplete the AllReduce once the straggler reaches the synchronization barrier.\nStragglAR achieves a 2x theoretical speedup over popular bandwidth-efficient\nAllReduce algorithms (e.g., Ring) for large GPU clusters with persistent\nstragglers. On an 8-GPU server, our implementation of StragglAR yields a 22%\nspeedup over state-of-the-art AllReduce algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684AllReduce\u7b97\u6cd5StragglAR\uff0c\u4ee5\u52a0\u901f\u5728\u5b58\u5728\u6301\u4e45\u843d\u540e\u8005\u60c5\u51b5\u4e0b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u5728\u5927\u578bGPU\u96c6\u7fa4\u4e2d\u7406\u8bba\u4e0a\u6bd4\u6d41\u884c\u7684\u5e26\u5bbd\u9ad8\u6548AllReduce\u7b97\u6cd5\u5feb2\u500d\uff0c\u57288-GPU\u670d\u52a1\u5668\u4e0a\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7b97\u6cd5\u5feb22%\u3002", "motivation": "\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u4f7f\u7528\u6570\u636e\u548c\u5f20\u91cf\u5e76\u884c\u6027\u8fdb\u884c\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u7684\u6279\u91cf\u540c\u6b65AllReduce\u7b97\u6cd5\u53ef\u80fd\u4f1a\u56e0\u4e3a\u6162\u7684\u8282\u70b9\uff08\u5373\u6301\u4e45\u843d\u540e\u8005\uff09\u800c\u5ef6\u8fdf\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "StragglAR\u5728\u6301\u4e45\u843d\u540e\u8005\u5bfc\u81f4\u7684\u5ef6\u8fdf\u671f\u95f4\u5728\u5269\u4f59\u7684GPU\u4e0a\u5b9e\u73b0ReduceScatter\uff0c\u5e76\u5728\u843d\u540e\u8005\u8fbe\u5230\u540c\u6b65\u5c4f\u969c\u540e\u6267\u884c\u4e00\u79cd\u65b0\u7684\u96c6\u4f53\u7b97\u6cd5\u5b8c\u6210AllReduce\u3002", "result": "StragglAR\u5728\u5927\u578bGPU\u96c6\u7fa4\u4e2d\u5bf9\u6301\u4e45\u843d\u540e\u8005\u7684\u60c5\u51b5\u4e0b\uff0c\u7406\u8bba\u4e0a\u6bd4\u6d41\u884c\u5e26\u5bbd\u9ad8\u6548\u7684AllReduce\u7b97\u6cd5\uff08\u5982Ring\uff09\u5feb2\u500d\uff1b\u57288-GPU\u670d\u52a1\u5668\u4e0a\uff0c\u5176\u5b9e\u73b0\u6bd4\u6700\u5148\u8fdb\u7684AllReduce\u7b97\u6cd5\u5feb22%\u3002", "conclusion": "StragglAR\u662f\u4e00\u79cd\u6709\u6548\u7684AllReduce\u7b97\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u5728\u5b58\u5728\u6301\u4e45\u843d\u540e\u8005\u60c5\u51b5\u4e0b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2505.23527", "pdf": "https://arxiv.org/pdf/2505.23527", "abs": "https://arxiv.org/abs/2505.23527", "authors": ["Raj Ghugare", "Benjamin Eysenbach"], "title": "Normalizing Flows are Capable Models for RL", "categories": ["cs.LG"], "comment": "Project page with code - https://rajghugare19.github.io/nf4rl/", "summary": "Modern reinforcement learning (RL) algorithms have found success by using\npowerful probabilistic models, such as transformers, energy-based models, and\ndiffusion/flow-based models. To this end, RL researchers often choose to pay\nthe price of accommodating these models into their algorithms -- diffusion\nmodels are expressive, but are computationally intensive due to their reliance\non solving differential equations, while autoregressive transformer models are\nscalable but typically require learning discrete representations. Normalizing\nflows (NFs), by contrast, seem to provide an appealing alternative, as they\nenable likelihoods and sampling without solving differential equations or\nautoregressive architectures. However, their potential in RL has received\nlimited attention, partly due to the prevailing belief that normalizing flows\nlack sufficient expressivity. We show that this is not the case. Building on\nrecent work in NFs, we propose a single NF architecture which integrates\nseamlessly into RL algorithms, serving as a policy, Q-function, and occupancy\nmeasure. Our approach leads to much simpler algorithms, and achieves higher\nperformance in imitation learning, offline, goal conditioned RL and\nunsupervised RL.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f52\u4e00\u5316\u6d41\uff08NFs\uff09\u7684\u5355\u4e00\u67b6\u6784\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u4e3a\u7b56\u7565\u3001Q\u51fd\u6570\u548c\u5360\u7528\u5ea6\u91cf\u3002\u8fd9\u79cd\u65b9\u6cd5\u7b80\u5316\u4e86\u7b97\u6cd5\uff0c\u5e76\u5728\u6a21\u4eff\u5b66\u4e60\u3001\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u3001\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5f52\u4e00\u5316\u6d41\u6a21\u578b\u5728\u7406\u8bba\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5176\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\uff0c\u90e8\u5206\u539f\u56e0\u662f\u4eba\u4eec\u666e\u904d\u8ba4\u4e3a\u5f52\u4e00\u5316\u6d41\u7f3a\u4e4f\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f52\u4e00\u5316\u6d41\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u4e0e\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u65e0\u7f1d\u7ed3\u5408\uff0c\u53ef\u540c\u65f6\u7528\u4f5c\u7b56\u7565\u3001Q\u51fd\u6570\u548c\u5360\u7528\u5ea6\u91cf\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5f52\u4e00\u5316\u6d41\u65b9\u6cd5\u4e0d\u4ec5\u7b80\u5316\u4e86\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u8bbe\u8ba1\uff0c\u800c\u4e14\u5728\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\uff08\u5982\u6a21\u4eff\u5b66\u4e60\u3001\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b49\uff09\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "\u5f52\u4e00\u5316\u6d41\u6a21\u578b\u5177\u5907\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u4ee5\u6210\u4e3a\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u4e2d\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u672a\u6765\u5e94\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u6f5c\u529b\u3002"}}
{"id": "2505.23528", "pdf": "https://arxiv.org/pdf/2505.23528", "abs": "https://arxiv.org/abs/2505.23528", "authors": ["Maria Eleftheria Vlontzou", "Maria Athanasiou", "Christos Davatzikos", "Konstantina S. Nikita"], "title": "Comparative assessment of fairness definitions and bias mitigation strategies in machine learning-based diagnosis of Alzheimer's disease from MR images", "categories": ["cs.LG"], "comment": "(C) 2025 IEEE Paper accepted at IEEE Engineering in Medicine and\n  Biology Society Conference, 2025", "summary": "The present study performs a comprehensive fairness analysis of machine\nlearning (ML) models for the diagnosis of Mild Cognitive Impairment (MCI) and\nAlzheimer's disease (AD) from MRI-derived neuroimaging features. Biases\nassociated with age, race, and gender in a multi-cohort dataset, as well as the\ninfluence of proxy features encoding these sensitive attributes, are\ninvestigated. The reliability of various fairness definitions and metrics in\nthe identification of such biases is also assessed. Based on the most\nappropriate fairness measures, a comparative analysis of widely used\npre-processing, in-processing, and post-processing bias mitigation strategies\nis performed. Moreover, a novel composite measure is introduced to quantify the\ntrade-off between fairness and performance by considering the F1-score and the\nequalized odds ratio, making it appropriate for medical diagnostic\napplications. The obtained results reveal the existence of biases related to\nage and race, while no significant gender bias is observed. The deployed\nmitigation strategies yield varying improvements in terms of fairness across\nthe different sensitive attributes and studied subproblems. For race and\ngender, Reject Option Classification improves equalized odds by 46% and 57%,\nrespectively, and achieves harmonic mean scores of 0.75 and 0.80 in the MCI\nversus AD subproblem, whereas for age, in the same subproblem, adversarial\ndebiasing yields the highest equalized odds improvement of 40% with a harmonic\nmean score of 0.69. Insights are provided into how variations in AD\nneuropathology and risk factors, associated with demographic characteristics,\ninfluence model fairness.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u57fa\u4e8eMRI\u884d\u751f\u7684\u795e\u7ecf\u5f71\u50cf\u5b66\u7279\u5f81\uff0c\u7528\u4e8e\u8bca\u65ad\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u516c\u5e73\u6027\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793a\u4e0e\u5e74\u9f84\u3001\u79cd\u65cf\u548c\u6027\u522b\u76f8\u5173\u7684\u504f\u5dee\uff0c\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u504f\u5dee\u5bf9\u6a21\u578b\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u591a\u961f\u5217\u6570\u636e\u96c6\u4e2d\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u4ee3\u7406\u7279\u5f81\u5982\u4f55\u7f16\u7801\u8fd9\u4e9b\u654f\u611f\u5c5e\u6027\u5e76\u5f71\u54cd\u6a21\u578b\u7684\u516c\u5e73\u6027\u3002", "method": "1. \u4f7f\u7528\u591a\u79cd\u516c\u5e73\u6027\u5b9a\u4e49\u548c\u6307\u6807\u6765\u8bc6\u522b\u504f\u5dee\u3002\n2. \u6bd4\u8f83\u5e38\u7528\u7684\u9884\u5904\u7406\u3001\u5904\u7406\u4e2d\u548c\u540e\u5904\u7406\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u3002\n3. \u5f15\u5165\u4e00\u79cd\u65b0\u7684\u590d\u5408\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408F1\u5206\u6570\u548c\u5e73\u7b49\u673a\u4f1a\u6bd4\u7387\u6765\u91cf\u5316\u516c\u5e73\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002\n4. \u5206\u6790\u4e0d\u540c\u7f13\u89e3\u7b56\u7565\u5728\u5404\u654f\u611f\u5c5e\u6027\u548c\u5b50\u95ee\u9898\u4e0a\u7684\u6539\u8fdb\u6548\u679c\u3002", "result": "- \u53d1\u73b0\u4e0e\u5e74\u9f84\u548c\u79cd\u65cf\u76f8\u5173\u7684\u504f\u5dee\uff0c\u4f46\u672a\u89c2\u5bdf\u5230\u663e\u8457\u7684\u6027\u522b\u504f\u5dee\u3002\n- \u9488\u5bf9\u79cd\u65cf\u548c\u6027\u522b\uff0c\u62d2\u7edd\u9009\u9879\u5206\u7c7b\u6cd5\u5206\u522b\u63d0\u9ad8\u4e86\u5e73\u7b49\u673a\u4f1a\u6bd4\u738746%\u548c57%\uff0c\u5e76\u5728MCI vs AD\u5b50\u95ee\u9898\u4e2d\u53d6\u5f97\u4e860.75\u548c0.80\u7684\u8c03\u548c\u5e73\u5747\u5206\u3002\n- \u5bf9\u4e8e\u5e74\u9f84\uff0c\u5728\u540c\u4e00\u5b50\u95ee\u9898\u4e2d\uff0c\u5bf9\u6297\u53bb\u504f\u6cd5\u5b9e\u73b0\u4e8640%\u7684\u5e73\u7b49\u673a\u4f1a\u6539\u5584\uff0c\u8c03\u548c\u5e73\u5747\u5206\u4e3a0.69\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e0e\u5e74\u9f84\u548c\u79cd\u65cf\u76f8\u5173\u7684\u504f\u5dee\uff0c\u5e76\u8bc1\u660e\u4e0d\u540c\u7684\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u5728\u5404\u79cd\u654f\u611f\u5c5e\u6027\u548c\u5b50\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u6539\u8fdb\u6548\u679c\u3002\u6b64\u5916\uff0c\u4e0e\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u76f8\u5173\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u795e\u7ecf\u75c5\u7406\u5b66\u548c\u98ce\u9669\u56e0\u7d20\u7684\u53d8\u5316\u4f1a\u5f71\u54cd\u6a21\u578b\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2505.23537", "pdf": "https://arxiv.org/pdf/2505.23537", "abs": "https://arxiv.org/abs/2505.23537", "authors": ["Giorgos Iacovides", "Wuyang Zhou", "Chao Li", "Qibin Zhao", "Danilo Mandic"], "title": "Domain-Aware Tensor Network Structure Search", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Tensor networks (TNs) provide efficient representations of high-dimensional\ndata, yet identification of the optimal TN structures, the so called tensor\nnetwork structure search (TN-SS) problem, remains a challenge. Current\nstate-of-the-art (SOTA) algorithms are computationally expensive as they\nrequire extensive function evaluations, which is prohibitive for real-world\napplications. In addition, existing methods ignore valuable domain information\ninherent in real-world tensor data and lack transparency in their identified TN\nstructures. To this end, we propose a novel TN-SS framework, termed the tnLLM,\nwhich incorporates domain information about the data and harnesses the\nreasoning capabilities of large language models (LLMs) to directly predict\nsuitable TN structures. The proposed framework involves a domain-aware\nprompting pipeline which instructs the LLM to infer suitable TN structures\nbased on the real-world relationships between tensor modes. In this way, our\napproach is capable of not only iteratively optimizing the objective function,\nbut also generating domain-aware explanations for the identified structures.\nExperimental results demonstrate that tnLLM achieves comparable TN-SS objective\nfunction values with much fewer function evaluations compared to SOTA\nalgorithms. Furthermore, we demonstrate that the LLM-enabled domain information\ncan be used to find good initializations in the search space for sampling-based\nSOTA methods to accelerate their convergence while preserving theoretical\nperformance guarantees.", "AI": {"tldr": "\u63d0\u51fatnLLM\u6846\u67b6\uff0c\u7ed3\u5408\u9886\u57df\u4fe1\u606f\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u76f4\u63a5\u9884\u6d4b\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\uff0c\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4e0e\u73b0\u6709\u6700\u4f73\u7b97\u6cd5\u76f8\u5f53\u4f46\u6548\u7387\u66f4\u9ad8\uff0c\u5e76\u53ef\u901a\u8fc7\u9886\u57df\u4fe1\u606f\u52a0\u901f\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u6536\u655b\u3002", "motivation": "\u5f53\u524d\u7684\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\u641c\u7d22\uff08TN-SS\uff09\u7b97\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e14\u5ffd\u89c6\u4e86\u771f\u5b9e\u6570\u636e\u4e2d\u7684\u9886\u57df\u4fe1\u606f\uff0c\u7f3a\u4e4f\u900f\u660e\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u9ad8\u6548\u641c\u7d22\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\u5e76\u5229\u7528\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u63d0\u51fatnLLM\u6846\u67b6\uff0c\u5305\u542b\u9886\u57df\u611f\u77e5\u63d0\u793a\u7ba1\u9053\uff0c\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u6839\u636e\u5f20\u91cf\u6a21\u5f0f\u95f4\u7684\u771f\u5b9e\u5173\u7cfb\u63a8\u65ad\u5408\u9002\u7684\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\uff0c\u540c\u65f6\u751f\u6210\u9886\u57df\u76f8\u5173\u7684\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660etnLLM\u5728\u663e\u8457\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u73b0\u6709\u6700\u4f73\u7b97\u6cd5\u76f8\u5f53\u7684\u76ee\u6807\u51fd\u6570\u503c\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u9886\u57df\u4fe1\u606f\u53ef\u4ee5\u4e3a\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u63d0\u4f9b\u826f\u597d\u521d\u59cb\u5316\uff0c\u52a0\u901f\u6536\u655b\u5e76\u4fdd\u6301\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u3002", "conclusion": "tnLLM\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u9886\u57df\u4fe1\u606f\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5728\u63d0\u9ad8\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\u641c\u7d22\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u80fd\u8f85\u52a9\u5176\u4ed6\u65b9\u6cd5\u4f18\u5316\u3002"}}
{"id": "2505.23552", "pdf": "https://arxiv.org/pdf/2505.23552", "abs": "https://arxiv.org/abs/2505.23552", "authors": ["Alex Adams"], "title": "Comparing the Moore-Penrose Pseudoinverse and Gradient Descent for Solving Linear Regression Problems: A Performance Analysis", "categories": ["cs.LG"], "comment": null, "summary": "This paper investigates the comparative performance of two fundamental\napproaches to solving linear regression problems: the closed-form Moore-Penrose\npseudoinverse and the iterative gradient descent method. Linear regression is a\ncornerstone of predictive modeling, and the choice of solver can significantly\nimpact efficiency and accuracy. I review and discuss the theoretical\nunderpinnings of both methods, analyze their computational complexity, and\nevaluate their empirical behavior on synthetic datasets with controlled\ncharacteristics, as well as on established real-world datasets. My results\ndelineate the conditions under which each method excels in terms of\ncomputational time, numerical stability, and predictive accuracy. This work\naims to provide practical guidance for researchers and practitioners in machine\nlearning when selecting between direct, exact solutions and iterative,\napproximate solutions for linear regression tasks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u4e24\u79cd\u89e3\u51b3\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u7684\u57fa\u672c\u65b9\u6cd5\uff1a\u95ed\u5f0fMoore-Penrose\u4f2a\u9006\u548c\u8fed\u4ee3\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u76f8\u5bf9\u6027\u80fd\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u5206\u6790\u4ee5\u53ca\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u884c\u4e3a\u8bc4\u4f30\uff0c\u660e\u786e\u4e86\u6bcf\u79cd\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u3001\u6570\u503c\u7a33\u5b9a\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u7684\u4f18\u52a3\u6761\u4ef6\u3002\u8be5\u7814\u7a76\u4e3a\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5728\u76f4\u63a5\u7cbe\u786e\u89e3\u6cd5\u548c\u8fed\u4ee3\u8fd1\u4f3c\u89e3\u6cd5\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\u7684\u5b9e\u9645\u6307\u5bfc\u3002", "motivation": "\u63a2\u8ba8\u5728\u89e3\u51b3\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u65f6\uff0c\u4f7f\u7528\u95ed\u5f0fMoore-Penrose\u4f2a\u9006\u548c\u8fed\u4ee3\u68af\u5ea6\u4e0b\u964d\u6cd5\u8fd9\u4e24\u79cd\u57fa\u672c\u65b9\u6cd5\u7684\u76f8\u5bf9\u6027\u80fd\uff0c\u4ee5\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u505a\u51fa\u66f4\u660e\u667a\u7684\u9009\u62e9\u3002", "method": "1. \u56de\u987e\u5e76\u8ba8\u8bba\u4e24\u79cd\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\uff1b2. \u5206\u6790\u5b83\u4eec\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff1b3. \u5728\u5177\u6709\u53ef\u63a7\u7279\u6027\u7684\u5408\u6210\u6570\u636e\u96c6\u4ee5\u53ca\u5df2\u5efa\u7acb\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5b83\u4eec\u7684\u5b9e\u8bc1\u884c\u4e3a\u3002", "result": "\u660e\u786e\u4e86\u6bcf\u79cd\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u3001\u6570\u503c\u7a33\u5b9a\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u7684\u6761\u4ef6\u3002", "conclusion": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5728\u9009\u62e9\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u7684\u89e3\u51b3\u65b9\u6848\u65f6\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\uff0c\u5373\u4f55\u65f6\u9009\u62e9\u76f4\u63a5\u7cbe\u786e\u89e3\u6cd5\uff0c\u4f55\u65f6\u9009\u62e9\u8fed\u4ee3\u8fd1\u4f3c\u89e3\u6cd5\u3002"}}
{"id": "2505.23555", "pdf": "https://arxiv.org/pdf/2505.23555", "abs": "https://arxiv.org/abs/2505.23555", "authors": ["Yanzhao Hou", "Jiaxiang Geng", "Boyu Li", "Xiaofeng Tao", "Juncheng Wang", "Xiaodong Xu", "Bing Luo"], "title": "Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling", "categories": ["cs.LG"], "comment": "13 pages, Submitted to IEEE Journal on Selected Areas in\n  Communications (JSAC)", "summary": "Federated LoRA has emerged as a promising technique for efficiently\nfine-tuning large language models (LLMs) on distributed devices by reducing the\nnumber of trainable parameters. However, existing approaches often inadequately\noverlook the theoretical and practical implications of system and data\nheterogeneity, thereby failing to optimize the overall training efficiency,\nparticularly in terms of wall-clock time. In this paper, we propose an adaptive\nfederated LoRA strategy with independent client sampling to minimize the\nconvergence wall-clock time of federated fine-tuning under both computation and\ncommunication heterogeneity. We first derive a new convergence bound for\nfederated LoRA with arbitrary and independent client sampling, notably without\nrequiring the stringent bounded gradient assumption. Then, we introduce an\nadaptive bandwidth allocation scheme that accounts for heterogeneous client\nresources and system bandwidth constraints. Based on the derived theory, we\nformulate and solve a non-convex optimization problem to jointly determine the\nLoRA sketching ratios and sampling probabilities, aiming to minimize wall-clock\nconvergence time. An efficient and low-complexity algorithm is developed to\napproximate the solution. Finally, extensive experiments demonstrate that our\napproach significantly reduces wall-clock training time compared to\nstate-of-the-art methods across various models and datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8054\u90a6LoRA\u7b56\u7565\uff0c\u901a\u8fc7\u72ec\u7acb\u5ba2\u6237\u7aef\u91c7\u6837\u548c\u5e26\u5bbd\u5206\u914d\u65b9\u6848\uff0c\u5728\u8ba1\u7b97\u548c\u901a\u4fe1\u5f02\u6784\u6027\u4e0b\u6700\u5c0f\u5316\u8054\u5408\u5fae\u8c03\u7684\u6536\u655b\u65f6\u95f4\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u6280\u672f\u80fd\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6LoRA\u65b9\u6cd5\u5728\u5904\u7406\u7cfb\u7edf\u548c\u6570\u636e\u5f02\u6784\u6027\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u672a\u80fd\u4f18\u5316\u6574\u4f53\u8bad\u7ec3\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\uff08wall-clock time\uff09\u65b9\u9762\u3002", "method": "1. \u63a8\u5bfc\u4e86\u5177\u6709\u4efb\u610f\u72ec\u7acb\u5ba2\u6237\u7aef\u91c7\u6837\u7684\u8054\u90a6LoRA\u7684\u65b0\u6536\u655b\u754c\uff0c\u65e0\u9700\u4e25\u683c\u7684\u68af\u5ea6\u6709\u754c\u5047\u8bbe\u3002\n2. \u63d0\u51fa\u4e86\u8003\u8651\u5ba2\u6237\u7aef\u8d44\u6e90\u5f02\u6784\u6027\u548c\u7cfb\u7edf\u5e26\u5bbd\u9650\u5236\u7684\u81ea\u9002\u5e94\u5e26\u5bbd\u5206\u914d\u65b9\u6848\u3002\n3. \u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u6784\u5efa\u5e76\u6c42\u89e3\u4e86\u4e00\u4e2a\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u786e\u5b9aLoRA\u7d20\u63cf\u6bd4\u7387\u548c\u91c7\u6837\u6982\u7387\uff0c\u76ee\u6807\u662f\u6700\u5c0f\u5316\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u3002\n4. \u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u6765\u8fd1\u4f3c\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u8054\u90a6LoRA\u7b56\u7565\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8ba1\u7b97\u548c\u901a\u4fe1\u5f02\u6784\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u8054\u5408\u5fae\u8c03\u7684\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2505.23565", "pdf": "https://arxiv.org/pdf/2505.23565", "abs": "https://arxiv.org/abs/2505.23565", "authors": ["Jiashuo Liu", "Tianyu Wang", "Henry Lam", "Hongseok Namkoong", "Jose Blanchet"], "title": "DRO: A Python Library for Distributionally Robust Optimization in Machine Learning", "categories": ["cs.LG", "cs.MS", "cs.NA", "math.NA"], "comment": null, "summary": "We introduce dro, an open-source Python library for distributionally robust\noptimization (DRO) for regression and classification problems. The library\nimplements 14 DRO formulations and 9 backbone models, enabling 79 distinct DRO\nmethods. Furthermore, dro is compatible with both scikit-learn and PyTorch.\nThrough vectorization and optimization approximation techniques, dro reduces\nruntime by 10x to over 1000x compared to baseline implementations on\nlarge-scale datasets. Comprehensive documentation is available at\nhttps://python-dro.org.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86dro\uff0c\u4e00\u4e2a\u7528\u4e8e\u56de\u5f52\u548c\u5206\u7c7b\u95ee\u9898\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\uff08DRO\uff09\u7684\u5f00\u6e90Python\u5e93\u3002\u8be5\u5e93\u5b9e\u73b0\u4e8614\u79cdDRO\u516c\u5f0f\u548c9\u79cd\u9aa8\u5e72\u6a21\u578b\uff0c\u652f\u6301\u4e0escikit-learn\u548cPyTorch\u517c\u5bb9\uff0c\u5e76\u901a\u8fc7\u5411\u91cf\u5316\u548c\u4f18\u5316\u8fd1\u4f3c\u6280\u672f\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u884c\u6548\u7387\u3002", "motivation": "\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\uff0c\u73b0\u6709\u7684DRO\u5b9e\u73b0\u5b58\u5728\u8fd0\u884c\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u3001\u517c\u5bb9\u6027\u597d\u7684\u5de5\u5177\u6765\u89e3\u51b3\u56de\u5f52\u548c\u5206\u7c7b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3adro\u7684\u5f00\u6e90Python\u5e93\uff0c\u5176\u4e2d\u5305\u542b14\u79cdDRO\u516c\u5f0f\u548c9\u79cd\u9aa8\u5e72\u6a21\u578b\uff0c\u652f\u630179\u79cd\u4e0d\u540c\u7684DRO\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u5e93\u4e0escikit-learn\u548cPyTorch\u517c\u5bb9\uff0c\u5e76\u91c7\u7528\u5411\u91cf\u5316\u548c\u4f18\u5316\u8fd1\u4f3c\u6280\u672f\u4ee5\u63d0\u9ad8\u8fd0\u884c\u6548\u7387\u3002", "result": "dro\u5e93\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8fd0\u884c\u65f6\u95f4\u76f8\u8f83\u4e8e\u57fa\u7ebf\u5b9e\u73b0\u51cf\u5c11\u4e8610\u500d\u81f31000\u500d\u4ee5\u4e0a\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "dro\u5e93\u4e3a\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u517c\u5bb9\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u56de\u5f52\u548c\u5206\u7c7b\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.23569", "pdf": "https://arxiv.org/pdf/2505.23569", "abs": "https://arxiv.org/abs/2505.23569", "authors": ["Samo Hromadka", "Kai Biegun", "Lior Fox", "James Heald", "Maneesh Sahani"], "title": "Maximum Likelihood Learning of Latent Dynamics Without Reconstruction", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a novel unsupervised learning method for time series data with\nlatent dynamical structure: the recognition-parametrized Gaussian state space\nmodel (RP-GSSM). The RP-GSSM is a probabilistic model that learns Markovian\nGaussian latents explaining statistical dependence between observations at\ndifferent time steps, combining the intuition of contrastive methods with the\nflexible tools of probabilistic generative models. Unlike contrastive\napproaches, the RP-GSSM is a valid probabilistic model learned via maximum\nlikelihood. Unlike generative approaches, the RP-GSSM has no need for an\nexplicit network mapping from latents to observations, allowing it to focus\nmodel capacity on inference of latents. The model is both tractable and\nexpressive: it admits exact inference thanks to its jointly Gaussian latent\nprior, while maintaining expressivity with an arbitrarily nonlinear neural\nnetwork link between observations and latents. These qualities allow the\nRP-GSSM to learn task-relevant latents without ad-hoc regularization, auxiliary\nlosses, or optimizer scheduling. We show how this approach outperforms\nalternatives on problems that include learning nonlinear stochastic dynamics\nfrom video, with or without background distractors. Our results position the\nRP-GSSM as a useful foundation model for a variety of downstream applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5RP-GSSM\uff0c\u7528\u4e8e\u5177\u6709\u6f5c\u5728\u52a8\u529b\u5b66\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5bf9\u6bd4\u65b9\u6cd5\u548c\u6982\u7387\u751f\u6210\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8fdb\u884c\u5b66\u4e60\uff0c\u65e0\u9700\u663e\u5f0f\u7684\u7f51\u7edc\u6620\u5c04\uff0c\u80fd\u591f\u5728\u975e\u7ebf\u6027\u968f\u673a\u52a8\u529b\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u6790\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8981\u4e48\u9700\u8981\u590d\u6742\u7684\u6b63\u5219\u5316\u3001\u8f85\u52a9\u635f\u5931\u6216\u4f18\u5316\u5668\u8c03\u5ea6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u53ef\u5904\u7406\u6027\u53c8\u80fd\u5177\u6709\u8868\u8fbe\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\u6765\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u52a8\u529b\u5b66\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u2014\u2014RP-GSSM\uff08\u8bc6\u522b\u53c2\u6570\u5316\u9ad8\u65af\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff09\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5bf9\u6bd4\u65b9\u6cd5\u7684\u76f4\u89c2\u6027\u548c\u6982\u7387\u751f\u6210\u6a21\u578b\u7684\u7075\u6d3b\u6027\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8fdb\u884c\u5b66\u4e60\u3002\u5b83\u4e0d\u9700\u8981\u4ece\u9690\u53d8\u91cf\u5230\u89c2\u6d4b\u503c\u7684\u663e\u5f0f\u7f51\u7edc\u6620\u5c04\uff0c\u800c\u662f\u4e13\u6ce8\u4e8e\u9690\u53d8\u91cf\u7684\u63a8\u7406\u3002", "result": "RP-GSSM\u5728\u5305\u62ec\u4ece\u89c6\u9891\u4e2d\u5b66\u4e60\u975e\u7ebf\u6027\u968f\u673a\u52a8\u529b\u5b66\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u65e0\u8bba\u662f\u5426\u5b58\u5728\u80cc\u666f\u5e72\u6270\u56e0\u7d20\u3002\u8fd9\u8868\u660eRP-GSSM\u53ef\u4ee5\u4f5c\u4e3a\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u7684\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "RP-GSSM\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u6f5c\u5728\u7684\u52a8\u529b\u5b66\u7ed3\u6784\uff0c\u5e76\u4e14\u5728\u975e\u7ebf\u6027\u968f\u673a\u52a8\u529b\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002"}}
{"id": "2505.23579", "pdf": "https://arxiv.org/pdf/2505.23579", "abs": "https://arxiv.org/abs/2505.23579", "authors": ["Adibvafa Fallahpour", "Andrew Magnuson", "Purav Gupta", "Shihao Ma", "Jack Naimer", "Arnav Shah", "Haonan Duan", "Omar Ibrahim", "Hani Goodarzi", "Chris J. Maddison", "Bo Wang"], "title": "BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model", "categories": ["cs.LG"], "comment": "16 pages, 3 figures, 2 tables", "summary": "Unlocking deep, interpretable biological reasoning from complex genomic data\nis a major AI challenge hindering scientific discovery. Current DNA foundation\nmodels, despite strong sequence representation, struggle with multi-step\nreasoning and lack inherent transparent, biologically intuitive explanations.\nWe introduce BioReason, a pioneering architecture that, for the first time,\ndeeply integrates a DNA foundation model with a Large Language Model (LLM).\nThis novel connection enables the LLM to directly process and reason with\ngenomic information as a fundamental input, fostering a new form of multimodal\nbiological understanding. BioReason's sophisticated multi-step reasoning is\ndeveloped through supervised fine-tuning and targeted reinforcement learning,\nguiding the system to generate logical, biologically coherent deductions. On\nbiological reasoning benchmarks including KEGG-based disease pathway prediction\n- where accuracy improves from 88% to 97% - and variant effect prediction,\nBioReason demonstrates an average 15% performance gain over strong\nsingle-modality baselines. BioReason reasons over unseen biological entities\nand articulates decision-making through interpretable, step-by-step biological\ntraces, offering a transformative approach for AI in biology that enables\ndeeper mechanistic insights and accelerates testable hypothesis generation from\ngenomic data. Data, code, and checkpoints are publicly available at\nhttps://github.com/bowang-lab/BioReason", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86BioReason\uff0c\u4e00\u79cd\u5c06DNA\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u76f8\u7ed3\u5408\u7684\u5f00\u521b\u6027\u67b6\u6784\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0cBioReason\u5728\u751f\u7269\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u7684\u751f\u7269\u63a8\u5bfc\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524d\u7684DNA\u57fa\u7840\u6a21\u578b\u867d\u7136\u5728\u5e8f\u5217\u8868\u793a\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u4e14\u7f3a\u4e4f\u900f\u660e\u3001\u76f4\u89c2\u7684\u751f\u7269\u5b66\u89e3\u91ca\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f15\u5165BioReason\uff0c\u5c06DNA\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6df1\u5ea6\u6574\u5408\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7fLLM\u80fd\u591f\u76f4\u63a5\u5904\u7406\u548c\u63a8\u7406\u57fa\u56e0\u7ec4\u4fe1\u606f\u3002", "result": "\u5728\u5305\u62ec\u57fa\u4e8eKEGG\u7684\u75be\u75c5\u901a\u8def\u9884\u6d4b\u7b49\u751f\u7269\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u51c6\u786e\u7387\u4ece88%\u63d0\u9ad8\u523097%\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u534715%\u3002BioReason\u8fd8\u80fd\u5bf9\u672a\u89c1\u8fc7\u7684\u751f\u7269\u5b9e\u4f53\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u9010\u6b65\u751f\u7269\u8f68\u8ff9\u9610\u8ff0\u51b3\u7b56\u8fc7\u7a0b\u3002", "conclusion": "BioReason\u4e3a\u751f\u7269\u5b66AI\u63d0\u4f9b\u4e86\u4e00\u79cd\u53d8\u9769\u6027\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4fc3\u8fdb\u66f4\u6df1\u5165\u7684\u673a\u5236\u6d1e\u5bdf\u5e76\u52a0\u901f\u4ece\u57fa\u56e0\u7ec4\u6570\u636e\u4e2d\u751f\u6210\u53ef\u68c0\u9a8c\u7684\u5047\u8bbe\u3002"}}
{"id": "2505.23583", "pdf": "https://arxiv.org/pdf/2505.23583", "abs": "https://arxiv.org/abs/2505.23583", "authors": ["Zhiding Liu", "Mingyue Cheng", "Guanhao Zhao", "Jiqian Yang", "Qi Liu", "Enhong Chen"], "title": "Improving Time Series Forecasting via Instance-aware Post-hoc Revision", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting plays a vital role in various real-world applications\nand has attracted significant attention in recent decades. While recent methods\nhave achieved remarkable accuracy by incorporating advanced inductive biases\nand training strategies, we observe that instance-level variations remain a\nsignificant challenge. These variations--stemming from distribution shifts,\nmissing data, and long-tail patterns--often lead to suboptimal forecasts for\nspecific instances, even when overall performance appears strong. To address\nthis issue, we propose a model-agnostic framework, PIR, designed to enhance\nforecasting performance through Post-forecasting Identification and Revision.\nSpecifically, PIR first identifies biased forecasting instances by estimating\ntheir accuracy. Based on this, the framework revises the forecasts using\ncontextual information, including covariates and historical time series, from\nboth local and global perspectives in a post-processing fashion. Extensive\nexperiments on real-world datasets with mainstream forecasting models\ndemonstrate that PIR effectively mitigates instance-level errors and\nsignificantly improves forecasting reliability.", "AI": {"tldr": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u5c3d\u7ba1\u8fd1\u671f\u65b9\u6cd5\u5728\u6574\u4f53\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b9e\u4f8b\u7ea7\u5dee\u5f02\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u6846\u67b6PIR\uff0c\u901a\u8fc7\u540e\u9884\u6d4b\u8bc6\u522b\u548c\u4fee\u6b63\u6765\u63d0\u5347\u7279\u5b9a\u5b9e\u4f8b\u7684\u9884\u6d4b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660ePIR\u80fd\u6709\u6548\u51cf\u5c11\u5b9e\u4f8b\u7ea7\u8bef\u5dee\u5e76\u63d0\u9ad8\u9884\u6d4b\u53ef\u9760\u6027\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4f46\u5728\u5b9e\u4f8b\u7ea7\u9884\u6d4b\u4e2d\u4ecd\u5b58\u5728\u504f\u5dee\u95ee\u9898\uff0c\u4f8b\u5982\u5206\u5e03\u6f02\u79fb\u3001\u7f3a\u5931\u6570\u636e\u548c\u957f\u5c3e\u6a21\u5f0f\u7b49\uff0c\u5bfc\u81f4\u67d0\u4e9b\u5b9e\u4f8b\u9884\u6d4b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u6846\u67b6PIR\uff08Post-forecasting Identification and Revision\uff09\uff0c\u9996\u5148\u901a\u8fc7\u4f30\u8ba1\u9884\u6d4b\u51c6\u786e\u6027\u8bc6\u522b\u51fa\u504f\u5dee\u8f83\u5927\u7684\u9884\u6d4b\u5b9e\u4f8b\uff0c\u7136\u540e\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5305\u62ec\u534f\u53d8\u91cf\u548c\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\uff09\u4ece\u5c40\u90e8\u548c\u5168\u5c40\u89c6\u89d2\u5bf9\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u4fee\u6b63\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPIR\u80fd\u591f\u6709\u6548\u7f13\u89e3\u5b9e\u4f8b\u7ea7\u8bef\u5dee\uff0c\u5e76\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "PIR\u6846\u67b6\u4e3a\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5b9e\u4f8b\u7ea7\u504f\u5dee\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u539f\u6709\u6a21\u578b\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2505.23585", "pdf": "https://arxiv.org/pdf/2505.23585", "abs": "https://arxiv.org/abs/2505.23585", "authors": ["Yaru Hao", "Li Dong", "Xun Wu", "Shaohan Huang", "Zewen Chi", "Furu Wei"], "title": "On-Policy RL with Optimal Reward Baseline", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning algorithms are fundamental to align large language\nmodels with human preferences and to enhance their reasoning capabilities.\nHowever, current reinforcement learning algorithms often suffer from training\ninstability due to loose on-policy constraints and computational inefficiency\ndue to auxiliary models. In this work, we propose On-Policy RL with Optimal\nreward baseline (OPO), a novel and simplified reinforcement learning algorithm\ndesigned to address these challenges. OPO emphasizes the importance of exact\non-policy training, which empirically stabilizes the training process and\nenhances exploration. Moreover, OPO introduces the optimal reward baseline that\ntheoretically minimizes gradient variance. We evaluate OPO on mathematical\nreasoning benchmarks. The results demonstrate its superior performance and\ntraining stability without additional models or regularization terms.\nFurthermore, OPO achieves lower policy shifts and higher output entropy,\nencouraging more diverse and less repetitive responses. These results highlight\nOPO as a promising direction for stable and effective reinforcement learning in\nlarge language model alignment and reasoning tasks. The implementation is\nprovided at https://github.com/microsoft/LMOps/tree/main/opo.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5OPO\uff0c\u5f3a\u8c03\u7cbe\u786e\u7684on-policy\u8bad\u7ec3\u5e76\u5f15\u5165\u6700\u4f18\u5956\u52b1\u57fa\u7ebf\uff0c\u51cf\u5c11\u4e86\u68af\u5ea6\u65b9\u5dee\u3002\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOPO\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u4e14\u4e0d\u9700\u8981\u989d\u5916\u6a21\u578b\u6216\u6b63\u5219\u5316\u9879\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u7b56\u7565\u8f6c\u79fb\u548c\u66f4\u9ad8\u7684\u8f93\u51fa\u71b5\uff0c\u9f13\u52b1\u66f4\u591a\u6837\u5316\u7684\u54cd\u5e94\u3002", "motivation": "\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u56e0\u677e\u6563\u7684on-policy\u7ea6\u675f\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u5e76\u56e0\u8f85\u52a9\u6a21\u578b\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aOPO\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5f3a\u8c03\u7cbe\u786e\u7684on-policy\u8bad\u7ec3\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u589e\u5f3a\u63a2\u7d22\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u7406\u8bba\u4e0a\u6700\u5c0f\u5316\u68af\u5ea6\u65b9\u5dee\u7684\u6700\u4f18\u5956\u52b1\u57fa\u7ebf\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cOPO\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u6b63\u5219\u5316\u9879\uff0c\u540c\u65f6\u5b9e\u73b0\u8f83\u4f4e\u7684\u7b56\u7565\u8f6c\u79fb\u548c\u8f83\u9ad8\u7684\u8f93\u51fa\u71b5\u3002", "conclusion": "OPO\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u7a33\u5b9a\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
{"id": "2505.23588", "pdf": "https://arxiv.org/pdf/2505.23588", "abs": "https://arxiv.org/abs/2505.23588", "authors": ["Mrinmay Sen", "Sidhant R Nair", "C Krishna Mohan"], "title": "Accelerated Training of Federated Learning via Second-Order Methods", "categories": ["cs.LG", "cs.DC", "68Q25, 68T05, 90C06, 90C25, 90C30", "I.2.6; G.1.6; C.2.4; C.4"], "comment": "17 pages, 1 figure, 4 tables, submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence (T-PAMI)", "summary": "This paper explores second-order optimization methods in Federated Learning\n(FL), addressing the critical challenges of slow convergence and the excessive\ncommunication rounds required to achieve optimal performance from the global\nmodel. While existing surveys in FL primarily focus on challenges related to\nstatistical and device label heterogeneity, as well as privacy and security\nconcerns in first-order FL methods, less attention has been given to the issue\nof slow model training. This slow training often leads to the need for\nexcessive communication rounds or increased communication costs, particularly\nwhen data across clients are highly heterogeneous. In this paper, we examine\nvarious FL methods that leverage second-order optimization to accelerate the\ntraining process. We provide a comprehensive categorization of state-of-the-art\nsecond-order FL methods and compare their performance based on convergence\nspeed, computational cost, memory usage, transmission overhead, and\ngeneralization of the global model. Our findings show the potential of\nincorporating Hessian curvature through second-order optimization into FL and\nhighlight key challenges, such as the efficient utilization of Hessian and its\ninverse in FL. This work lays the groundwork for future research aimed at\ndeveloping scalable and efficient federated optimization methods for improving\nthe training of the global model in FL.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u6a21\u578b\u6536\u655b\u7f13\u6162\u548c\u901a\u4fe1\u8f6e\u6b21\u8fc7\u591a\u7684\u95ee\u9898\u3002\u6587\u7ae0\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u4e8c\u9636FL\u65b9\u6cd5\u7684\u5206\u7c7b\uff0c\u5e76\u57fa\u4e8e\u6536\u655b\u901f\u5ea6\u3001\u8ba1\u7b97\u6210\u672c\u7b49\u591a\u4e2a\u6307\u6807\u6bd4\u8f83\u4e86\u5176\u6027\u80fd\u3002\u7814\u7a76\u8868\u660e\uff0c\u5728FL\u4e2d\u4f7f\u7528Hessian\u66f2\u7387\u7684\u4e8c\u9636\u4f18\u5316\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u9ad8\u6548\u5229\u7528Hessian\u53ca\u5176\u9006\u77e9\u9635\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6162\u6536\u655b\u95ee\u9898\u4ee5\u53ca\u9ad8\u901a\u4fe1\u6210\u672c\u9700\u8981\u6539\u8fdb\u4f18\u5316\u65b9\u6cd5\u6765\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u5206\u6790\u548c\u6bd4\u8f83\u5404\u79cd\u5229\u7528\u4e8c\u9636\u4f18\u5316\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u4e0d\u540c\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u53ef\u4ee5\u52a0\u901f\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u6307\u51fa\u9ad8\u6548\u5229\u7528Hessian\u77e9\u9635\u53ca\u9006\u77e9\u9635\u662f\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u6709\u6f5c\u529b\uff0c\u672a\u6765\u7814\u7a76\u5e94\u81f4\u529b\u4e8e\u5f00\u53d1\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u4ee5\u6539\u8fdb\u5168\u5c40\u6a21\u578b\u8bad\u7ec3\u3002"}}
{"id": "2505.23593", "pdf": "https://arxiv.org/pdf/2505.23593", "abs": "https://arxiv.org/abs/2505.23593", "authors": ["Nikita Agrawal", "Simon Mertel", "Ruben Mayer"], "title": "Position: Federated Foundation Language Model Post-Training Should Focus on Open-Source Models", "categories": ["cs.LG"], "comment": null, "summary": "Post-training of foundation language models has emerged as a promising\nresearch domain in federated learning (FL) with the goal to enable\nprivacy-preserving model improvements and adaptations to user's downstream\ntasks. Recent advances in this area adopt centralized post-training approaches\nthat build upon black-box foundation language models where there is no access\nto model weights and architecture details. Although the use of black-box models\nhas been successful in centralized post-training, their blind replication in FL\nraises several concerns. Our position is that using black-box models in FL\ncontradicts the core principles of federation such as data privacy and\nautonomy. In this position paper, we critically analyze the usage of black-box\nmodels in federated post-training, and provide a detailed account of various\naspects of openness and their implications for FL.", "AI": {"tldr": "A position paper that critically analyzes the usage of black-box models in federated post-training and discusses its implications for FL.", "motivation": "The motivation is to highlight the concerns with using black-box models in federated learning (FL) for post-training of foundation language models, as it contradicts core principles like data privacy and autonomy.", "method": "The method involves a critical analysis of the use of black-box models in federated post-training, examining various aspects of openness and their implications for FL.", "result": "No specific results are presented; rather, the paper provides a detailed account of the issues and implications associated with using black-box models in FL.", "conclusion": "The conclusion is that using black-box models in FL contradicts the principles of federation, such as data privacy and autonomy, thus necessitating further research into more transparent and open methods."}}
{"id": "2505.23598", "pdf": "https://arxiv.org/pdf/2505.23598", "abs": "https://arxiv.org/abs/2505.23598", "authors": ["Radzim Sendyka", "Christian Cabrera", "Andrei Paleyes", "Diana Robinson", "Neil Lawrence"], "title": "LLM Performance for Code Generation on Noisy Tasks", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "This paper investigates the ability of large language models (LLMs) to\nrecognise and solve tasks which have been obfuscated beyond recognition.\nFocusing on competitive programming and benchmark tasks (LeetCode and MATH), we\ncompare performance across multiple models and obfuscation methods, such as\nnoise and redaction. We demonstrate that all evaluated LLMs can solve tasks\nobfuscated to a level where the text would be unintelligible to human readers,\nand does not contain key pieces of instruction or context. We introduce the\nconcept of eager pattern matching to describe this behaviour, which is not\nobserved in tasks published after the models' knowledge cutoff date, indicating\nstrong memorisation or overfitting to training data, rather than legitimate\nreasoning about the presented problem. We report empirical evidence of distinct\nperformance decay patterns between contaminated and unseen datasets. We discuss\nthe implications for benchmarking and evaluations of model behaviour, arguing\nfor caution when designing experiments using standard datasets. We also propose\nmeasuring the decay of performance under obfuscation as a possible strategy for\ndetecting dataset contamination and highlighting potential safety risks and\ninterpretability issues for automated software systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bc6\u522b\u548c\u89e3\u51b3\u88ab\u6df7\u6dc6\u5230\u65e0\u6cd5\u8fa8\u8ba4\u7684\u4efb\u52a1\u7684\u80fd\u529b\u3002\u901a\u8fc7\u6bd4\u8f83\u591a\u4e2a\u6a21\u578b\u5728\u4e0d\u540c\u6df7\u6dc6\u65b9\u6cd5\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6240\u6709\u8bc4\u4f30\u7684LLM\u90fd\u80fd\u89e3\u51b3\u6587\u672c\u5bf9\u4eba\u7c7b\u8bfb\u8005\u4e0d\u53ef\u7406\u89e3\u7684\u4efb\u52a1\uff0c\u8fd9\u8868\u660e\u6a21\u578b\u53ef\u80fd\u5b58\u5728\u5f3a\u8bb0\u5fc6\u6216\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u6570\u636e\u7684\u73b0\u8c61\uff0c\u800c\u975e\u5408\u7406\u63a8\u7406\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u6025\u5207\u6a21\u5f0f\u5339\u914d\u7684\u6982\u5ff5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5bf9\u6a21\u578b\u884c\u4e3a\u8bc4\u4f30\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u6765\u68c0\u6d4b\u6570\u636e\u96c6\u6c61\u67d3\u53ca\u6f5c\u5728\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u7ecf\u8fc7\u6df7\u6dc6\u5904\u7406\u7684\u4efb\u52a1\u65f6\u7684\u8868\u73b0\uff0c\u4ee5\u63a2\u8ba8\u6a21\u578b\u662f\u5426\u771f\u6b63\u5177\u5907\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u8fd8\u662f\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u8bb0\u5fc6\u6216\u8fc7\u62df\u5408\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u4f7f\u7528\u7ade\u4e89\u6027\u7f16\u7a0b\u548c\u57fa\u51c6\u4efb\u52a1\uff08\u5982LeetCode\u548cMATH\uff09\uff0c\u5bf9\u6bd4\u591a\u4e2aLLM\u5728\u4e0d\u540c\u6df7\u6dc6\u65b9\u6cd5\uff08\u5982\u566a\u58f0\u548c\u5220\u51cf\uff09\u4e0b\u7684\u6027\u80fd\uff0c\u5f15\u5165\u201c\u6025\u5207\u6a21\u5f0f\u5339\u914d\u201d\u6982\u5ff5\u8fdb\u884c\u63cf\u8ff0\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684LLM\u80fd\u591f\u5728\u4efb\u52a1\u88ab\u6df7\u6dc6\u5230\u4eba\u7c7b\u65e0\u6cd5\u7406\u89e3\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u95ee\u9898\uff0c\u8868\u73b0\u51fa\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u5f3a\u8bb0\u5fc6\u6216\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002\u5728\u6a21\u578b\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u4e4b\u540e\u53d1\u5e03\u7684\u4efb\u52a1\u4e2d\u672a\u89c2\u5bdf\u5230\u8fd9\u79cd\u884c\u4e3a\u3002", "conclusion": "\u5728\u8bbe\u8ba1\u4f7f\u7528\u6807\u51c6\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u65f6\u9700\u8c28\u614e\uff0c\u5efa\u8bae\u91c7\u7528\u6d4b\u91cf\u6df7\u6dc6\u4e0b\u6027\u80fd\u8870\u51cf\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u6570\u636e\u96c6\u6c61\u67d3\uff0c\u63ed\u793a\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\u548c\u89e3\u91ca\u6027\u95ee\u9898\u3002"}}
{"id": "2505.23606", "pdf": "https://arxiv.org/pdf/2505.23606", "abs": "https://arxiv.org/abs/2505.23606", "authors": ["Qingyu Shi", "Jinbin Bai", "Zhuoran Zhao", "Wenhao Chai", "Kaidong Yu", "Jianzong Wu", "Shuangyong Song", "Yunhai Tong", "Xiangtai Li", "Xuelong Li", "Shuicheng Yan"], "title": "Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model", "categories": ["cs.LG", "cs.CV"], "comment": "The code and model are available at\n  https://github.com/M-E-AGI-Lab/Muddit", "summary": "Unified generation models aim to handle diverse tasks across modalities --\nsuch as text generation, image generation, and vision-language reasoning --\nwithin a single architecture and decoding paradigm. Autoregressive unified\nmodels suffer from slow inference due to sequential decoding, and\nnon-autoregressive unified models suffer from weak generalization due to\nlimited pretrained backbones. We introduce Muddit, a unified discrete diffusion\ntransformer that enables fast and parallel generation across both text and\nimage modalities. Unlike prior unified diffusion models trained from scratch,\nMuddit integrates strong visual priors from a pretrained text-to-image backbone\nwith a lightweight text decoder, enabling flexible and high-quality multimodal\ngeneration under a unified architecture. Empirical results show that Muddit\nachieves competitive or superior performance compared to significantly larger\nautoregressive models in both quality and efficiency. The work highlights the\npotential of purely discrete diffusion, when equipped with strong visual\npriors, as a scalable and effective backbone for unified generation.", "AI": {"tldr": "Muddit\u662f\u4e00\u79cd\u7edf\u4e00\u7684\u79bb\u6563\u6269\u6563\u53d8\u538b\u5668\uff0c\u5b83\u80fd\u591f\u5728\u6587\u672c\u548c\u56fe\u50cf\u6a21\u6001\u4e4b\u95f4\u5b9e\u73b0\u5feb\u901f\u548c\u5e73\u884c\u751f\u6210\u3002\u4e0e\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u5148\u524d\u7edf\u4e00\u6269\u6563\u6a21\u578b\u4e0d\u540c\uff0cMuddit\u5c06\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5230\u56fe\u50cf\u4e3b\u5e72\u4e2d\u7684\u5f3a\u5927\u89c6\u89c9\u5148\u9a8c\u4e0e\u8f7b\u91cf\u7ea7\u6587\u672c\u89e3\u7801\u5668\u96c6\u6210\u5728\u4e00\u8d77\uff0c\u4ece\u800c\u5728\u7edf\u4e00\u67b6\u6784\u4e0b\u5b9e\u73b0\u7075\u6d3b\u548c\u9ad8\u8d28\u91cf\u7684\u591a\u6a21\u6001\u751f\u6210\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cMuddit\u5728\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u4f18\u4e8e\u663e\u8457\u8f83\u5927\u7684\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u6216\u76f8\u5f53\u7684\u6027\u80fd\u3002\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5f53\u914d\u5907\u5f3a\u5927\u7684\u89c6\u89c9\u5148\u9a8c\u65f6\uff0c\u7eaf\u7cb9\u7684\u79bb\u6563\u6269\u6563\u4f5c\u4e3a\u7edf\u4e00\u751f\u6210\u7684\u53ef\u6269\u5c55\u548c\u6709\u6548\u7684\u4e3b\u5e72\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u7edf\u4e00\u751f\u6210\u6a21\u578b\u8981\u4e48\u7531\u4e8e\u987a\u5e8f\u89e3\u7801\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u6162\uff08\u81ea\u56de\u5f52\u7edf\u4e00\u6a21\u578b\uff09\uff0c\u8981\u4e48\u7531\u4e8e\u9884\u8bad\u7ec3\u4e3b\u5e72\u7684\u9650\u5236\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5f31\uff08\u975e\u81ea\u56de\u5f52\u7edf\u4e00\u6a21\u578b\uff09\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u9ad8\u6548\u7684\u591a\u6a21\u6001\u751f\u6210\u3002", "method": "Muddit\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u79bb\u6563\u6269\u6563\u53d8\u538b\u5668\uff0c\u5b83\u96c6\u6210\u4e86\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5230\u56fe\u50cf\u4e3b\u5e72\u4e2d\u7684\u5f3a\u5927\u89c6\u89c9\u5148\u9a8c\u548c\u8f7b\u91cf\u7ea7\u6587\u672c\u89e3\u7801\u5668\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u5f97Muddit\u80fd\u591f\u5728\u7edf\u4e00\u67b6\u6784\u4e0b\u8fdb\u884c\u7075\u6d3b\u548c\u9ad8\u8d28\u91cf\u7684\u591a\u6a21\u6001\u751f\u6210\uff0c\u540c\u65f6\u514b\u670d\u4e86\u81ea\u56de\u5f52\u548c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u7f3a\u70b9\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cMuddit\u5728\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u663e\u8457\u8f83\u5927\u7684\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u6216\u8005\u4e0e\u4e4b\u8868\u73b0\u76f8\u5f53\u3002\u8fd9\u8bc1\u660e\u4e86Muddit\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002", "conclusion": "Muddit\u5c55\u793a\u4e86\u4e00\u4e2a\u6709\u6f5c\u529b\u7684\u65b9\u5411\uff0c\u5373\u901a\u8fc7\u7ed3\u5408\u5f3a\u5927\u7684\u89c6\u89c9\u5148\u9a8c\uff0c\u7eaf\u7cb9\u7684\u79bb\u6563\u6269\u6563\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u6269\u5c55\u548c\u6709\u6548\u7684\u7edf\u4e00\u751f\u6210\u4e3b\u5e72\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u591a\u6a21\u6001\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u6cd5\u3002"}}
{"id": "2505.23607", "pdf": "https://arxiv.org/pdf/2505.23607", "abs": "https://arxiv.org/abs/2505.23607", "authors": ["Carolina Fortuna", "Gregor Cerar", "Blaz Bertalanic", "Andrej Campa", "Mihael Mohorcic"], "title": "Data Model Design for Explainable Machine Learning-based Electricity Applications", "categories": ["cs.LG"], "comment": null, "summary": "The transition from traditional power grids to smart grids, significant\nincrease in the use of renewable energy sources, and soaring electricity prices\nhas triggered a digital transformation of the energy infrastructure that\nenables new, data driven, applications often supported by machine learning\nmodels. However, the majority of the developed machine learning models rely on\nunivariate data. To date, a structured study considering the role meta-data and\nadditional measurements resulting in multivariate data is missing. In this\npaper we propose a taxonomy that identifies and structures various types of\ndata related to energy applications. The taxonomy can be used to guide\napplication specific data model development for training machine learning\nmodels. Focusing on a household electricity forecasting application, we\nvalidate the effectiveness of the proposed taxonomy in guiding the selection of\nthe features for various types of models. As such, we study of the effect of\ndomain, contextual and behavioral features on the forecasting accuracy of four\ninterpretable machine learning techniques and three openly available datasets.\nFinally, using a feature importance techniques, we explain individual feature\ncontributions to the forecasting accuracy.", "AI": {"tldr": "The paper proposes a taxonomy for identifying and structuring data types in energy applications, which is used to guide feature selection for machine learning models in household electricity forecasting. It studies the impact of different features on forecasting accuracy using interpretable machine learning techniques.", "motivation": "There is a digital transformation in energy infrastructure due to the shift towards smart grids, increased use of renewable energy sources, and rising electricity prices. However, most machine learning models rely on univariate data, and there is a lack of structured study considering multivariate data, meta-data, and additional measurements.", "method": "A taxonomy is proposed to identify and structure various types of data related to energy applications. This taxonomy is applied to guide the development of application-specific data models for training machine learning models. The effectiveness of the taxonomy is validated through a household electricity forecasting application.", "result": "The study investigates the effect of domain, contextual, and behavioral features on the forecasting accuracy of four interpretable machine learning techniques across three openly available datasets. Feature importance techniques are used to explain individual feature contributions to forecasting accuracy.", "conclusion": "The proposed taxonomy effectively guides the selection of features for machine learning models in household electricity forecasting applications. It highlights the significance of considering multivariate data, meta-data, and additional measurements."}}
{"id": "2505.23609", "pdf": "https://arxiv.org/pdf/2505.23609", "abs": "https://arxiv.org/abs/2505.23609", "authors": ["Armando Bellante", "Martin Pl\u00e1vala", "Alessandro Luongo"], "title": "The Generalized Skew Spectrum of Graphs", "categories": ["cs.LG", "cs.DS", "math.GR", "math.RT"], "comment": null, "summary": "This paper proposes a family of permutation-invariant graph embeddings,\ngeneralizing the Skew Spectrum of graphs of Kondor & Borgwardt (2008). Grounded\nin group theory and harmonic analysis, our method introduces a new class of\ngraph invariants that are isomorphism-invariant and capable of embedding richer\ngraph structures - including attributed graphs, multilayer graphs, and\nhypergraphs - which the Skew Spectrum could not handle. Our generalization\nfurther defines a family of functions that enables a trade-off between\ncomputational complexity and expressivity. By applying\ngeneralization-preserving heuristics to this family, we improve the Skew\nSpectrum's expressivity at the same computational cost. We formally prove the\ninvariance of our generalization, demonstrate its improved expressiveness\nthrough experiments, and discuss its efficient computation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7f6e\u6362\u4e0d\u53d8\u7684\u56fe\u5d4c\u5165\u65b9\u6cd5\uff0c\u63a8\u5e7f\u4e86Kondor\u548cBorgwardt(2008)\u63d0\u51fa\u7684\u56fe\u7684\u504f\u8c31\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u7fa4\u8bba\u548c\u8c03\u548c\u5206\u6790\uff0c\u5f15\u5165\u4e86\u4e00\u7c7b\u65b0\u7684\u540c\u6784\u4e0d\u53d8\u7684\u56fe\u4e0d\u53d8\u91cf\uff0c\u80fd\u591f\u5d4c\u5165\u66f4\u4e30\u5bcc\u7684\u56fe\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u5d4c\u5165\u65b9\u6cd5\uff08\u5982Skew Spectrum\uff09\u65e0\u6cd5\u5904\u7406\u5305\u542b\u5c5e\u6027\u7684\u56fe\u3001\u591a\u5c42\u56fe\u548c\u8d85\u56fe\u7b49\u590d\u6742\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u7fa4\u8bba\u548c\u8c03\u548c\u5206\u6790\u7684\u65b0\u7c7b\u56fe\u4e0d\u53d8\u91cf\uff0c\u63d0\u51fa\u4e00\u79cd\u7f6e\u6362\u4e0d\u53d8\u7684\u56fe\u5d4c\u5165\u65b9\u6cd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u65cf\u51fd\u6570\u6765\u6743\u8861\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8868\u8fbe\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eSkew Spectrum\u76f8\u540c\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u6b63\u5f0f\u8bc1\u660e\u4e86\u5176\u4e0d\u53d8\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u56fe\u5d4c\u5165\u65b9\u6cd5\u63a8\u5e7f\u4e86Skew Spectrum\uff0c\u80fd\u6709\u6548\u8868\u793a\u66f4\u590d\u6742\u7684\u56fe\u7ed3\u6784\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\u3002"}}
{"id": "2505.23615", "pdf": "https://arxiv.org/pdf/2505.23615", "abs": "https://arxiv.org/abs/2505.23615", "authors": ["Chang Yue", "Niraj K. Jha"], "title": "Learning Interpretable Differentiable Logic Networks for Tabular Regression", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks (NNs) achieve outstanding performance in many domains;\nhowever, their decision processes are often opaque and their inference can be\ncomputationally expensive in resource-constrained environments. We recently\nproposed Differentiable Logic Networks (DLNs) to address these issues for\ntabular classification based on relaxing discrete logic into a differentiable\nform, thereby enabling gradient-based learning of networks built from binary\nlogic operations. DLNs offer interpretable reasoning and substantially lower\ninference cost.\n  We extend the DLN framework to supervised tabular regression. Specifically,\nwe redesign the final output layer to support continuous targets and unify the\noriginal two-phase training procedure into a single differentiable stage. We\nevaluate the resulting model on 15 public regression benchmarks, comparing it\nwith modern neural networks and classical regression baselines. Regression DLNs\nmatch or exceed baseline accuracy while preserving interpretability and fast\ninference. Our results show that DLNs are a viable, cost-effective alternative\nfor regression tasks, especially where model transparency and computational\nefficiency are important.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Differentiable Logic Networks\uff08DLNs\uff09\u6846\u67b6\u81f3\u76d1\u7763\u8868\u683c\u56de\u5f52\u4efb\u52a1\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u8f93\u51fa\u5c42\u4ee5\u652f\u6301\u8fde\u7eed\u76ee\u6807\uff0c\u5e76\u5c06\u8bad\u7ec3\u8fc7\u7a0b\u7edf\u4e00\u4e3a\u5355\u4e00\u53ef\u5fae\u9636\u6bb5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u56de\u5f52DLNs\u572815\u4e2a\u516c\u5f00\u57fa\u51c6\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u5feb\u901f\u63a8\u7406\u80fd\u529b\uff0c\u662f\u56de\u5f52\u4efb\u52a1\u4e2d\u517c\u5177\u6210\u672c\u6548\u76ca\u548c\u900f\u660e\u6027\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u8bb8\u591a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\u4e14\u63a8\u7406\u6210\u672c\u9ad8\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u4e4b\u524d\u63d0\u51fa\u4e86\u7528\u4e8e\u8868\u683c\u5206\u7c7b\u7684Differentiable Logic Networks\uff08DLNs\uff09\uff0c\u901a\u8fc7\u5c06\u79bb\u6563\u903b\u8f91\u8f6c\u6362\u4e3a\u53ef\u5fae\u5f62\u5f0f\uff0c\u5b9e\u73b0\u57fa\u4e8e\u68af\u5ea6\u7684\u5b66\u4e60\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u63a8\u7406\u548c\u4f4e\u63a8\u7406\u6210\u672c\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u5e0c\u671b\u5c06DLN\u6846\u67b6\u6269\u5c55\u5230\u76d1\u7763\u8868\u683c\u56de\u5f52\u4efb\u52a1\u3002", "method": "\u4f5c\u8005\u91cd\u65b0\u8bbe\u8ba1\u4e86DLN\u7684\u6700\u7ec8\u8f93\u51fa\u5c42\u4ee5\u652f\u6301\u8fde\u7eed\u76ee\u6807\u53d8\u91cf\uff0c\u5e76\u5c06\u539f\u6709\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\u5408\u5e76\u4e3a\u4e00\u4e2a\u5355\u4e00\u7684\u53ef\u5fae\u8bad\u7ec3\u9636\u6bb5\u3002\u8fd9\u4e00\u6539\u8fdb\u4f7f\u5f97DLN\u80fd\u591f\u9002\u7528\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u6548\u63a8\u7406\u7684\u7279\u70b9\u3002", "result": "\u572815\u4e2a\u516c\u5171\u56de\u5f52\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u56de\u5f52DLNs\u7684\u51c6\u786e\u7387\u4e0e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u548c\u7ecf\u5178\u56de\u5f52\u57fa\u7ebf\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5feb\u901f\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "DLNs\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u56de\u5f52\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u9700\u8981\u6a21\u578b\u900f\u660e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u573a\u666f\u3002"}}
{"id": "2505.23627", "pdf": "https://arxiv.org/pdf/2505.23627", "abs": "https://arxiv.org/abs/2505.23627", "authors": ["Griffin Dietz Smith", "Dianna Yee", "Jennifer King Chen", "Leah Findlater"], "title": "Prompting Whisper for Improved Verbatim Transcription and End-to-end Miscue Detection", "categories": ["cs.LG"], "comment": "Interspeech 2025", "summary": "Identifying mistakes (i.e., miscues) made while reading aloud is commonly\napproached post-hoc by comparing automatic speech recognition (ASR)\ntranscriptions to the target reading text. However, post-hoc methods perform\npoorly when ASR inaccurately transcribes verbatim speech. To improve on current\nmethods for reading error annotation, we propose a novel end-to-end\narchitecture that incorporates the target reading text via prompting and is\ntrained for both improved verbatim transcription and direct miscue detection.\nOur contributions include: first, demonstrating that incorporating reading text\nthrough prompting benefits verbatim transcription performance over fine-tuning,\nand second, showing that it is feasible to augment speech recognition tasks for\nend-to-end miscue detection. We conducted two case studies -- children's\nread-aloud and adult atypical speech -- and found that our proposed strategies\nimprove verbatim transcription and miscue detection compared to current\nstate-of-the-art.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u76ee\u6807\u9605\u8bfb\u6587\u672c\u7eb3\u5165\u63d0\u793a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u53ef\u4ee5\u540c\u65f6\u6539\u8fdb\u9010\u5b57\u8f6c\u5f55\u548c\u76f4\u63a5\u9519\u8bef\u68c0\u6d4b\u3002\u5728\u513f\u7ae5\u6717\u8bfb\u548c\u6210\u4eba\u975e\u5178\u578b\u8bed\u97f3\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u65b0\u7b56\u7565\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u540e\u65b9\u6cd5\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u4e0d\u51c6\u786e\u8f6c\u5f55\u97f3\u9891\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u9605\u8bfb\u9519\u8bef\u6ce8\u91ca\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u901a\u8fc7\u63d0\u793a\u7ed3\u5408\u76ee\u6807\u9605\u8bfb\u6587\u672c\uff0c\u4ece\u800c\u6539\u5584\u9010\u5b57\u8f6c\u5f55\u5e76\u76f4\u63a5\u68c0\u6d4b\u8bef\u8bfb\u3002\u8fd8\u8fdb\u884c\u4e86\u4e24\u9879\u6848\u4f8b\u7814\u7a76\uff1a\u513f\u7ae5\u6717\u8bfb\u548c\u6210\u4eba\u975e\u5178\u578b\u8bed\u97f3\u3002", "result": "\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u63d0\u9ad8\u4e86\u9010\u5b57\u8f6c\u5f55\u548c\u8bef\u8bfb\u68c0\u6d4b\u7684\u6548\u679c\u3002", "conclusion": "\u5c06\u9605\u8bfb\u6587\u672c\u901a\u8fc7\u63d0\u793a\u7ed3\u5408\u8fdb\u6765\uff0c\u5bf9\u9010\u5b57\u8f6c\u5f55\u6027\u80fd\u6709\u76ca\uff0c\u5e76\u4e14\u589e\u5f3a\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4ee5\u5b9e\u73b0\u7aef\u5230\u7aef\u8bef\u8bfb\u68c0\u6d4b\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2505.23634", "pdf": "https://arxiv.org/pdf/2505.23634", "abs": "https://arxiv.org/abs/2505.23634", "authors": ["John Halloran"], "title": "MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment", "categories": ["cs.LG", "cs.CR"], "comment": "27 pages, 19 figures, 4 tables", "summary": "The model context protocol (MCP) has been widely adapted as an open standard\nenabling the seamless integration of generative AI agents. However, recent work\nhas shown the MCP is susceptible to retrieval-based \"falsely benign\" attacks\n(FBAs), allowing malicious system access and credential theft, but requiring\nthat users download compromised files directly to their systems. Herein, we\nshow that the threat model of MCP-based attacks is significantly broader than\npreviously thought, i.e., attackers need only post malicious content online to\ndeceive MCP agents into carrying out their attacks on unsuspecting victims'\nsystems.\n  To improve alignment guardrails against such attacks, we introduce a new MCP\ndataset of FBAs and (truly) benign samples to explore the effectiveness of\ndirect preference optimization (DPO) for the refusal training of large language\nmodels (LLMs). While DPO improves model guardrails against such attacks, we\nshow that the efficacy of refusal learning varies drastically depending on the\nmodel's original post-training alignment scheme--e.g., GRPO-based LLMs learn to\nrefuse extremely poorly. Thus, to further improve FBA refusals, we introduce\nRetrieval Augmented Generation for Preference alignment (RAG-Pref), a novel\npreference alignment strategy based on RAG. We show that RAG-Pref significantly\nimproves the ability of LLMs to refuse FBAs, particularly when combined with\nDPO alignment, thus drastically improving guardrails against MCP-based attacks.", "AI": {"tldr": "The paper highlights the broader threat of Model Context Protocol (MCP)-based attacks, where malicious content online can deceive MCP agents. It introduces an MCP dataset for Falsely Benign Attacks (FBAs) and explores Direct Preference Optimization (DPO) for refusal training in large language models (LLMs). However, DPO effectiveness varies depending on the model's alignment scheme. To address this, the authors propose Retrieval Augmented Generation for Preference alignment (RAG-Pref), which significantly enhances LLMs' ability to refuse FBAs when combined with DPO.", "motivation": "To address the susceptibility of MCP to retrieval-based 'falsely benign' attacks (FBAs) that could lead to system access and credential theft without requiring direct file downloads.", "method": "Introduction of a new MCP dataset containing FBAs and truly benign samples; exploration of Direct Preference Optimization (DPO) for refusal training in LLMs; development of Retrieval Augmented Generation for Preference alignment (RAG-Pref) to improve FBA refusals.", "result": "DPO improves model guardrails against FBAs but varies in efficacy based on the original alignment scheme. RAG-Pref significantly enhances LLMs' ability to refuse FBAs, especially when combined with DPO.", "conclusion": "RAG-Pref, when used with DPO, substantially strengthens guardrails against MCP-based attacks by improving LLMs' refusal capabilities for FBAs."}}
{"id": "2505.23640", "pdf": "https://arxiv.org/pdf/2505.23640", "abs": "https://arxiv.org/abs/2505.23640", "authors": ["Yilin Xie", "Shiqiang Zhang", "Jixiang Qing", "Ruth Misener", "Calvin Tsay"], "title": "Global optimization of graph acquisition functions for neural architecture search", "categories": ["cs.LG", "math.OC"], "comment": "19 pages, 6 figures, 3 tables", "summary": "Graph Bayesian optimization (BO) has shown potential as a powerful and\ndata-efficient tool for neural architecture search (NAS). Most existing graph\nBO works focus on developing graph surrogates models, i.e., metrics of networks\nand/or different kernels to quantify the similarity between networks. However,\nthe acquisition optimization, as a discrete optimization task over graph\nstructures, is not well studied due to the complexity of formulating the graph\nsearch space and acquisition functions. This paper presents explicit\noptimization formulations for graph input space including properties such as\nreachability and shortest paths, which are used later to formulate graph\nkernels and the acquisition function. We theoretically prove that the proposed\nencoding is an equivalent representation of the graph space and provide\nrestrictions for the NAS domain with either node or edge labels. Numerical\nresults over several NAS benchmarks show that our method efficiently finds the\noptimal architecture for most cases, highlighting its efficacy.", "AI": {"tldr": "\u56fe\u8d1d\u53f6\u65af\u4f18\u5316\uff08Graph Bayesian Optimization, BO\uff09\u5728\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u56fe\u8f93\u5165\u7a7a\u95f4\u7684\u663e\u5f0f\u4f18\u5316\u516c\u5f0f\uff0c\u5305\u62ec\u53ef\u8fbe\u6027\u548c\u6700\u77ed\u8def\u5f84\u7b49\u7279\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u7f16\u7801\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aNAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u80fd\u591f\u9ad8\u6548\u627e\u5230\u6700\u4f18\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u56feBO\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5f00\u53d1\u56fe\u4ee3\u7406\u6a21\u578b\u4e0a\uff0c\u800c\u5bf9\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u56e0\u4e3a\u5176\u6d89\u53ca\u590d\u6742\u7684\u56fe\u7ed3\u6784\u79bb\u6563\u4f18\u5316\u4efb\u52a1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u8f93\u5165\u7a7a\u95f4\u7684\u663e\u5f0f\u4f18\u5316\u516c\u5f0f\uff0c\u5305\u542b\u53ef\u8fbe\u6027\u548c\u6700\u77ed\u8def\u5f84\u7b49\u7279\u6027\uff0c\u7528\u4e8e\u6784\u5efa\u56fe\u6838\u548c\u83b7\u53d6\u51fd\u6570\uff0c\u5e76\u63d0\u4f9b\u4e86\u8282\u70b9\u6216\u8fb9\u6807\u7b7e\u9650\u5236\u4e0b\u7684NAS\u9886\u57df\u7406\u8bba\u8868\u793a\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u6709\u6548\u627e\u5230\u6700\u4f18\u67b6\u6784\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7f16\u7801\u662f\u56fe\u7a7a\u95f4\u7684\u7b49\u6548\u8868\u793a\uff0c\u9002\u7528\u4e8e\u5177\u6709\u8282\u70b9\u6216\u8fb9\u6807\u7b7e\u9650\u5236\u7684NAS\u9886\u57df\uff0c\u4e14\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u3002"}}
{"id": "2505.23648", "pdf": "https://arxiv.org/pdf/2505.23648", "abs": "https://arxiv.org/abs/2505.23648", "authors": ["Halil Alperen Gozeten", "M. Emrullah Ildiz", "Xuechen Zhang", "Hrayr Harutyunyan", "Ankit Singh Rawat", "Samet Oymak"], "title": "Continuous Chain of Thought Enables Parallel Exploration and Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Current language models generate chain-of-thought traces by autoregressively\nsampling tokens from a finite vocabulary. While this discrete sampling has\nachieved remarkable success, conducting chain-of-thought with\ncontinuously-valued tokens (CoT2) offers a richer and more expressive\nalternative. Our work examines the benefits of CoT2 through logical reasoning\ntasks that inherently require search capabilities and provide optimization and\nexploration methods for CoT2. Theoretically, we show that CoT2 allows the model\nto track multiple traces in parallel and quantify its benefits for inference\nefficiency. Notably, one layer transformer equipped with CoT2 can provably\nsolve the combinatorial \"subset sum problem\" given sufficient embedding\ndimension. These insights lead to a novel and effective supervision strategy\nwhere we match the softmax outputs to the empirical token distributions of a\nset of target traces. Complementing this, we introduce sampling strategies that\nunlock policy optimization and self-improvement for CoT2. Our first strategy\nsamples and composes $K$ discrete tokens at each decoding step to control the\nlevel of parallelism, and reduces to standard CoT when $K=1$. Our second\nstrategy relies on continuous exploration over the probability simplex.\nExperiments confirm that policy optimization with CoT2 indeed improves the\nperformance of the model beyond its initial discrete or continuous supervision.", "AI": {"tldr": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4ece\u6709\u9650\u8bcd\u6c47\u8868\u4e2d\u81ea\u56de\u5f52\u91c7\u6837\u751f\u6210\u79bb\u6563\u601d\u7ef4\u94fe\u3002\u7136\u800c\uff0c\u4f7f\u7528\u8fde\u7eed\u503c\u7b26\u53f7\uff08CoT2\uff09\u8fdb\u884c\u601d\u7ef4\u94fe\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u548c\u66f4\u5177\u8868\u8fbe\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u672c\u6587\u7814\u7a76\u4e86\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u4f7f\u7528CoT2\u7684\u597d\u5904\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u4e0e\u63a2\u7d22\u65b9\u6cd5\u3002\u7406\u8bba\u4e0a\uff0cCoT2\u4f7f\u6a21\u578b\u80fd\u591f\u5e76\u884c\u8ddf\u8e2a\u591a\u4e2a\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528CoT2\u7684\u7b56\u7565\u786e\u5b9e\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8d85\u8d8a\u5176\u521d\u59cb\u79bb\u6563\u6216\u8fde\u7eed\u76d1\u7763\u7684\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684\u57fa\u4e8e\u79bb\u6563\u7b26\u53f7\u91c7\u6837\u7684\u601d\u7ef4\u94fe\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u8fde\u7eed\u503c\u7b26\u53f7\uff08CoT2\uff09\u4e3a\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u641c\u7d22\u80fd\u529b\u7684\u4efb\u52a1\u4e0a\u3002\u8fd9\u6fc0\u52b1\u4e86\u5bf9CoT2\u7684\u7814\u7a76\uff0c\u4ee5\u63a2\u7d22\u5176\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "1. \u7406\u8bba\u5206\u6790\uff1a\u8bc1\u660eCoT2\u5141\u8bb8\u6a21\u578b\u5e76\u884c\u8ddf\u8e2a\u591a\u6761\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002\n2. \u65b0\u9896\u76d1\u7763\u7b56\u7565\uff1a\u5c06softmax\u8f93\u51fa\u4e0e\u76ee\u6807\u63a8\u7406\u8def\u5f84\u7684\u7ecf\u9a8c\u7b26\u53f7\u5206\u5e03\u5339\u914d\u3002\n3. \u63d0\u51fa\u4e24\u79cd\u91c7\u6837\u7b56\u7565\uff1a\n   - \u7b2c\u4e00\u79cd\u63a7\u5236\u6bcf\u6b65\u89e3\u7801\u65f6K\u4e2a\u79bb\u6563\u7b26\u53f7\u7684\u5e76\u884c\u6027\uff08\u5f53K=1\u65f6\u9000\u5316\u4e3a\u6807\u51c6\u79bb\u6563\u601d\u7ef4\u94fe\uff09\u3002\n   - \u7b2c\u4e8c\u79cd\u57fa\u4e8e\u6982\u7387\u5355\u7eaf\u5f62\u7684\u8fde\u7eed\u63a2\u7d22\u3002\n4. \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1CoT2\u5728\u653f\u7b56\u4f18\u5316\u548c\u81ea\u6211\u6539\u8fdb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4f7f\u7528CoT2\u8fdb\u884c\u63a8\u7406\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8d85\u8fc7\u5176\u521d\u59cb\u79bb\u6563\u6216\u8fde\u7eed\u76d1\u7763\u7684\u8868\u73b0\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u914d\u5907CoT2\u7684\u4e00\u5c42Transformer\u53ef\u4ee5\u5728\u8db3\u591f\u5d4c\u5165\u7ef4\u5ea6\u4e0b\u89e3\u51b3\u7ec4\u5408\u95ee\u9898\uff08\u5982\u5b50\u96c6\u548c\u95ee\u9898\uff09\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u7684\u91c7\u6837\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u8fde\u7eed\u503c\u7b26\u53f7\uff08CoT2\uff09\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\uff0c\u5305\u62ec\u66f4\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\u3001\u5e76\u884c\u63a8\u7406\u8def\u5f84\u8ddf\u8e2a\u548c\u63a8\u7406\u6548\u7387\u63d0\u5347\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u672a\u6765\u8bed\u8a00\u6a21\u578b\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u590d\u6742\u63a8\u7406\u548c\u4f18\u5316\u7684\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2505.23651", "pdf": "https://arxiv.org/pdf/2505.23651", "abs": "https://arxiv.org/abs/2505.23651", "authors": ["Juncheol Shin", "Minsang Seok", "Seonggon Kim", "Eunhyeok Park"], "title": "Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Code: https://github.com/ewsn1593/HDRQ", "summary": "Model merging has emerged as a powerful technique for combining task-specific\nweights, achieving superior performance in multi-target domain adaptation.\nHowever, when applied to practical scenarios, such as quantized models, new\nchallenges arise. In practical scenarios, quantization is often applied to\ntarget-specific data, but this process restricts the domain of interest and\nintroduces discretization effects, making model merging highly non-trivial. In\nthis study, we analyze the impact of quantization on model merging through the\nlens of error barriers. Leveraging these insights, we propose a novel\npost-training quantization, HDRQ - Hessian and distant regularizing\nquantization - that is designed to consider model merging for multi-target\ndomain adaptation. Our approach ensures that the quantization process incurs\nminimal deviation from the source pre-trained model while flattening the loss\nsurface to facilitate smooth model merging. To our knowledge, this is the first\nstudy on this challenge, and extensive experiments confirm its effectiveness.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u91cf\u5316\u5bf9\u6a21\u578b\u878d\u5408\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5HDRQ\uff0c\u4ee5\u6700\u5c0f\u5316\u4e0e\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u504f\u5dee\u5e76\u4fc3\u8fdb\u591a\u76ee\u6807\u9886\u57df\u9002\u5e94\u4e2d\u7684\u5e73\u6ed1\u6a21\u578b\u878d\u5408\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5982\u91cf\u5316\u6a21\u578b\u7b49\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u878d\u5408\u9762\u4e34\u65b0\u6311\u6218\uff0c\u56e0\u4e3a\u91cf\u5316\u8fc7\u7a0b\u9650\u5236\u4e86\u5173\u6ce8\u57df\u5e76\u5f15\u5165\u79bb\u6563\u5316\u6548\u5e94\uff0c\u4f7f\u5f97\u6a21\u578b\u878d\u5408\u53d8\u5f97\u975e\u5e38\u590d\u6742\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86HDRQ\uff08Hessian and distant regularizing quantization\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u591a\u76ee\u6807\u9886\u57df\u9002\u5e94\u4e2d\u7684\u6a21\u578b\u878d\u5408\u95ee\u9898\u3002HDRQ\u786e\u4fdd\u91cf\u5316\u8fc7\u7a0b\u5bf9\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u504f\u5dee\u6700\u5c0f\uff0c\u5e76\u901a\u8fc7\u5e73\u5766\u5316\u635f\u5931\u8868\u9762\u6765\u4fc3\u8fdb\u5e73\u6ed1\u6a21\u578b\u878d\u5408\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660eHDRQ\u80fd\u591f\u5728\u91cf\u5316\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u5e73\u6ed1\u6a21\u578b\u878d\u5408\uff0c\u5e76\u4fdd\u6301\u4e0e\u6e90\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u91cf\u5316\u5bf9\u6a21\u578b\u878d\u5408\u5f71\u54cd\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u7684HDRQ\u65b9\u6cd5\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23653", "pdf": "https://arxiv.org/pdf/2505.23653", "abs": "https://arxiv.org/abs/2505.23653", "authors": ["Jiaran Ye", "Zijun Yao", "Zhidian Huang", "Liangming Pan", "Jinxin Liu", "Yushi Bai", "Amy Xin", "Liu Weichuan", "Xiaoyin Che", "Lei Hou", "Juanzi Li"], "title": "How does Transformer Learn Implicit Reasoning?", "categories": ["cs.LG"], "comment": null, "summary": "Recent work suggests that large language models (LLMs) can perform multi-hop\nreasoning implicitly -- producing correct answers without explicitly\nverbalizing intermediate steps -- but the underlying mechanisms remain poorly\nunderstood. In this paper, we study how such implicit reasoning emerges by\ntraining transformers from scratch in a controlled symbolic environment. Our\nanalysis reveals a three-stage developmental trajectory: early memorization,\nfollowed by in-distribution generalization, and eventually cross-distribution\ngeneralization. We find that training with atomic triples is not necessary but\naccelerates learning, and that second-hop generalization relies on query-level\nexposure to specific compositional structures. To interpret these behaviors, we\nintroduce two diagnostic tools: cross-query semantic patching, which identifies\nsemantically reusable intermediate representations, and a cosine-based\nrepresentational lens, which reveals that successful reasoning correlates with\nthe cosine-base clustering in hidden space. This clustering phenomenon in turn\nprovides a coherent explanation for the behavioral dynamics observed across\ntraining, linking representational structure to reasoning capability. These\nfindings provide new insights into the interpretability of implicit multi-hop\nreasoning in LLMs, helping to clarify how complex reasoning processes unfold\ninternally and offering pathways to enhance the transparency of such models.", "AI": {"tldr": "\u8fd1\u671f\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u8fdb\u884c\u9690\u5f0f\u7684\u591a\u6b65\u63a8\u7406\u2014\u2014\u5728\u4e0d\u660e\u786e\u8868\u8fbe\u4e2d\u95f4\u6b65\u9aa4\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u6b63\u786e\u7b54\u6848\uff0c\u4f46\u5176\u5e95\u5c42\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u901a\u8fc7\u5728\u4e00\u4e2a\u53d7\u63a7\u7684\u7b26\u53f7\u73af\u5883\u4e2d\u4ece\u5934\u8bad\u7ec3Transformer\u6a21\u578b\uff0c\u7814\u7a76\u4e86\u8fd9\u79cd\u9690\u5f0f\u63a8\u7406\u662f\u5982\u4f55\u51fa\u73b0\u7684\u3002\u5206\u6790\u63ed\u793a\u4e86\u4e09\u4e2a\u53d1\u5c55\u9636\u6bb5\uff1a\u65e9\u671f\u7684\u8bb0\u5fc6\u9636\u6bb5\u3001\u968f\u540e\u7684\u5206\u5e03\u5185\u6cdb\u5316\u4ee5\u53ca\u6700\u7ec8\u7684\u8de8\u5206\u5e03\u6cdb\u5316\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u539f\u5b50\u4e09\u5143\u7ec4\u8bad\u7ec3\u4e0d\u662f\u5fc5\u8981\u6761\u4ef6\uff0c\u4f46\u80fd\u52a0\u901f\u5b66\u4e60\uff0c\u5e76\u4e14\u7b2c\u4e8c\u6b65\u6cdb\u5316\u4f9d\u8d56\u4e8e\u5bf9\u7279\u5b9a\u7ec4\u5408\u7ed3\u6784\u7684\u67e5\u8be2\u7ea7\u66b4\u9732\u3002\u4e3a\u4e86\u89e3\u91ca\u8fd9\u4e9b\u884c\u4e3a\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e24\u79cd\u8bca\u65ad\u5de5\u5177\uff1a\u8de8\u67e5\u8be2\u8bed\u4e49\u4fee\u8865\uff0c\u7528\u4e8e\u8bc6\u522b\u8bed\u4e49\u53ef\u91cd\u7528\u7684\u4e2d\u95f4\u8868\u793a\uff1b\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u8868\u793a\u955c\u5934\uff0c\u63ed\u793a\u4e86\u6210\u529f\u63a8\u7406\u4e0e\u9690\u85cf\u7a7a\u95f4\u4e2d\u57fa\u4e8e\u4f59\u5f26\u7684\u805a\u7c7b\u73b0\u8c61\u4e4b\u95f4\u7684\u5173\u8054\u3002\u8be5\u805a\u7c7b\u73b0\u8c61\u4e3a\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u52a8\u6001\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8fde\u8d2f\u7684\u89e3\u91ca\uff0c\u5c06\u8868\u793a\u7ed3\u6784\u4e0e\u63a8\u7406\u80fd\u529b\u8054\u7cfb\u8d77\u6765\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u9690\u5f0f\u591a\u6b65\u63a8\u7406\u5728LLMs\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u9610\u660e\u590d\u6742\u7684\u63a8\u7406\u8fc7\u7a0b\u5982\u4f55\u5728\u6a21\u578b\u5185\u90e8\u5c55\u5f00\uff0c\u5e76\u4e3a\u63d0\u9ad8\u6b64\u7c7b\u6a21\u578b\u7684\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u9014\u5f84\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u8fdb\u884c\u9690\u5f0f\u7684\u591a\u6b65\u63a8\u7406\uff0c\u4f46\u5176\u5e95\u5c42\u673a\u5236\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u4ee5\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u900f\u660e\u5ea6\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5728\u53d7\u63a7\u7684\u7b26\u53f7\u73af\u5883\u4e2d\u4ece\u5934\u8bad\u7ec3Transformer\u6a21\u578b\u6765\u7814\u7a76\u9690\u5f0f\u63a8\u7406\u7684\u51fa\u73b0\u3002\u5206\u6790\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u8bca\u65ad\u5de5\u5177\uff1a\u8de8\u67e5\u8be2\u8bed\u4e49\u4fee\u8865\u548c\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u8868\u793a\u955c\u5934\u3002", "result": "\u53d1\u73b0\u4e86\u6a21\u578b\u53d1\u5c55\u7684\u4e09\u4e2a\u9636\u6bb5\uff1a\u65e9\u671f\u8bb0\u5fc6\u3001\u5206\u5e03\u5185\u6cdb\u5316\u548c\u8de8\u5206\u5e03\u6cdb\u5316\u3002\u4f7f\u7528\u539f\u5b50\u4e09\u5143\u7ec4\u8bad\u7ec3\u53ef\u4ee5\u52a0\u901f\u5b66\u4e60\uff0c\u7b2c\u4e8c\u6b65\u6cdb\u5316\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7ec4\u5408\u7ed3\u6784\u7684\u66b4\u9732\u3002\u8bca\u65ad\u5de5\u5177\u63ed\u793a\u4e86\u6210\u529f\u63a8\u7406\u4e0e\u9690\u85cf\u7a7a\u95f4\u4e2d\u57fa\u4e8e\u4f59\u5f26\u7684\u805a\u7c7b\u73b0\u8c61\u4e4b\u95f4\u7684\u5173\u8054\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u9690\u5f0f\u591a\u6b65\u63a8\u7406\u5728LLMs\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\u7684\u5185\u90e8\u5c55\u5f00\uff0c\u5e76\u4e3a\u63d0\u9ad8\u6a21\u578b\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u65b9\u6cd5\u3002"}}
{"id": "2505.23663", "pdf": "https://arxiv.org/pdf/2505.23663", "abs": "https://arxiv.org/abs/2505.23663", "authors": ["Niklas Freymuth", "Tobias W\u00fcrth", "Nicolas Schreiber", "Balazs Gyenes", "Andreas Boltres", "Johannes Mitsch", "Aleksandar Taranovic", "Tai Hoang", "Philipp Dahlinger", "Philipp Becker", "Luise K\u00e4rger", "Gerhard Neumann"], "title": "AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction", "categories": ["cs.LG", "cs.CG"], "comment": null, "summary": "The cost and accuracy of simulating complex physical systems using the Finite\nElement Method (FEM) scales with the resolution of the underlying mesh.\nAdaptive meshes improve computational efficiency by refining resolution in\ncritical regions, but typically require task-specific heuristics or cumbersome\nmanual design by a human expert. We propose Adaptive Meshing By Expert\nReconstruction (AMBER), a supervised learning approach to mesh adaptation.\nStarting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,\na function mapping from the geometry to the local element size of the target\nmesh, and uses this prediction to produce a new intermediate mesh using an\nout-of-the-box mesh generator. This process is enabled through a hierarchical\ngraph neural network, and relies on data augmentation by automatically\nprojecting expert labels onto AMBER-generated data during training. We evaluate\nAMBER on 2D and 3D datasets, including classical physics problems, mechanical\ncomponents, and real-world industrial designs with human expert meshes. AMBER\ngeneralizes to unseen geometries and consistently outperforms multiple recent\nbaselines, including ones using Graph and Convolutional Neural Networks, and\nReinforcement Learning-based approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAMBER\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u7f51\u683c\u5212\u5206\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9884\u6d4b\u5c3a\u5bf8\u573a\u5e76\u751f\u6210\u4e2d\u95f4\u7f51\u683c\u6765\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u57282D\u548c3D\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u591a\u79cd\u8fd1\u671f\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6709\u9650\u5143\u6cd5\uff08FEM\uff09\u6a21\u62df\u590d\u6742\u7269\u7406\u7cfb\u7edf\u7684\u6210\u672c\u548c\u7cbe\u5ea6\u4e0e\u5e95\u5c42\u7f51\u683c\u7684\u5206\u8fa8\u7387\u76f8\u5173\u3002\u81ea\u9002\u5e94\u7f51\u683c\u867d\u7136\u80fd\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u901a\u5e38\u9700\u8981\u7279\u5b9a\u4efb\u52a1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u4eba\u5de5\u8bbe\u8ba1\u3002", "method": "\u4ece\u7c97\u7f51\u683c\u5f00\u59cb\uff0cAMBER\u8fed\u4ee3\u9884\u6d4b\u5c3a\u5bf8\u573a\uff08\u51e0\u4f55\u5230\u5c40\u90e8\u5143\u7d20\u5927\u5c0f\u7684\u51fd\u6570\uff09\uff0c\u5e76\u4f7f\u7528\u6b64\u9884\u6d4b\u901a\u8fc7\u73b0\u6210\u7684\u7f51\u683c\u751f\u6210\u5668\u751f\u6210\u65b0\u7684\u4e2d\u95f4\u7f51\u683c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u4f9d\u8d56\u4e8e\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5728\u8bad\u7ec3\u671f\u95f4\u901a\u8fc7\u81ea\u52a8\u5c06\u4e13\u5bb6\u6807\u7b7e\u6295\u5f71\u5230AMBER\u751f\u6210\u7684\u6570\u636e\u4e0a\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u3002", "result": "AMBER\u5728\u5305\u62ec\u7ecf\u5178\u7269\u7406\u95ee\u9898\u3001\u673a\u68b0\u90e8\u4ef6\u548c\u5177\u6709\u4eba\u7c7b\u4e13\u5bb6\u7f51\u683c\u7684\u5b9e\u9645\u5de5\u4e1a\u8bbe\u8ba1\u5728\u5185\u76842D\u548c3D\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0cAMBER\u53ef\u4ee5\u63a8\u5e7f\u5230\u672a\u89c1\u7684\u51e0\u4f55\u5f62\u72b6\uff0c\u5e76\u4e14\u59cb\u7ec8\u4f18\u4e8e\u591a\u4e2a\u8fd1\u671f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u56fe\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "conclusion": "AMBER\u4f5c\u4e3a\u4e00\u79cd\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u81ea\u9002\u5e94\u7f51\u683c\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u63a8\u5e7f\u5230\u65b0\u51e0\u4f55\u5f62\u72b6\u5e76\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.23673", "pdf": "https://arxiv.org/pdf/2505.23673", "abs": "https://arxiv.org/abs/2505.23673", "authors": ["Aya Kayal", "Sattar Vakili", "Laura Toni", "Da-shan Shiu", "Alberto Bernacchia"], "title": "Bayesian Optimization from Human Feedback: Near-Optimal Regret Bounds", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian optimization (BO) with preference-based feedback has recently\ngarnered significant attention due to its emerging applications. We refer to\nthis problem as Bayesian Optimization from Human Feedback (BOHF), which differs\nfrom conventional BO by learning the best actions from a reduced feedback\nmodel, where only the preference between two actions is revealed to the learner\nat each time step. The objective is to identify the best action using a limited\nnumber of preference queries, typically obtained through costly human feedback.\nExisting work, which adopts the Bradley-Terry-Luce (BTL) feedback model,\nprovides regret bounds for the performance of several algorithms. In this work,\nwithin the same framework we develop tighter performance guarantees.\nSpecifically, we derive regret bounds of\n$\\tilde{\\mathcal{O}}(\\sqrt{\\Gamma(T)T})$, where $\\Gamma(T)$ represents the\nmaximum information gain$\\unicode{x2014}$a kernel-specific complexity\nterm$\\unicode{x2014}$and $T$ is the number of queries. Our results\nsignificantly improve upon existing bounds. Notably, for common kernels, we\nshow that the order-optimal sample complexities of conventional\nBO$\\unicode{x2014}$achieved with richer feedback models$\\unicode{x2014}$are\nrecovered. In other words, the same number of preferential samples as\nscalar-valued samples is sufficient to find a nearly optimal solution.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23681", "pdf": "https://arxiv.org/pdf/2505.23681", "abs": "https://arxiv.org/abs/2505.23681", "authors": ["Bo Zhao", "Nima Dehmamy", "Robin Walters", "Rose Yu"], "title": "Understanding Mode Connectivity via Parameter Space Symmetry", "categories": ["cs.LG"], "comment": "20 pages, 4 figures, ICML 2025", "summary": "Neural network minima are often connected by curves along which train and\ntest loss remain nearly constant, a phenomenon known as mode connectivity.\nWhile this property has enabled applications such as model merging and\nfine-tuning, its theoretical explanation remains unclear. We propose a new\napproach to exploring the connectedness of minima using parameter space\nsymmetry. By linking the topology of symmetry groups to that of the minima, we\nderive the number of connected components of the minima of linear networks and\nshow that skip connections reduce this number. We then examine when mode\nconnectivity and linear mode connectivity hold or fail, using parameter\nsymmetries which account for a significant part of the minimum. Finally, we\nprovide explicit expressions for connecting curves in the minima induced by\nsymmetry. Using the curvature of these curves, we derive conditions under which\nlinear mode connectivity approximately holds. Our findings highlight the role\nof continuous symmetries in understanding the neural network loss landscape.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u6781\u5c0f\u503c\u901a\u5e38\u901a\u8fc7\u4fdd\u6301\u8bad\u7ec3\u548c\u6d4b\u8bd5\u635f\u5931\u51e0\u4e4e\u4e0d\u53d8\u7684\u66f2\u7ebf\u76f8\u8fde\uff0c\u8fd9\u4e00\u73b0\u8c61\u88ab\u79f0\u4e3a\u6a21\u5f0f\u8fde\u901a\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u53c2\u6570\u7a7a\u95f4\u5bf9\u79f0\u6027\u6765\u63a2\u7d22\u6781\u5c0f\u503c\u7684\u8fde\u901a\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u7ebf\u6027\u7f51\u7edc\u6781\u5c0f\u503c\u7684\u8fde\u901a\u5206\u91cf\u6570\u91cf\uff0c\u4ee5\u53ca\u8df3\u8fc7\u8fde\u63a5\u5982\u4f55\u51cf\u5c11\u8be5\u6570\u91cf\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u6a21\u5f0f\u8fde\u901a\u6027\u548c\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u6210\u7acb\u6216\u5931\u6548\u7684\u6761\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7531\u5bf9\u79f0\u6027\u5f15\u8d77\u7684\u8fde\u63a5\u66f2\u7ebf\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u3002\u6700\u540e\uff0c\u901a\u8fc7\u8fd9\u4e9b\u66f2\u7ebf\u7684\u66f2\u7387\uff0c\u63a8\u5bfc\u51fa\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u8fd1\u4f3c\u6210\u7acb\u7684\u6761\u4ef6\u3002\u672c\u6587\u5f3a\u8c03\u4e86\u8fde\u7eed\u5bf9\u79f0\u6027\u5728\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u666f\u89c2\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1\u6a21\u5f0f\u8fde\u901a\u6027\u5df2\u88ab\u5e94\u7528\u4e8e\u6a21\u578b\u5408\u5e76\u548c\u5fae\u8c03\u7b49\u5b9e\u9645\u95ee\u9898\u4e2d\uff0c\u4f46\u5176\u7406\u8bba\u89e3\u91ca\u4ecd\u7136\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63a2\u7d22\u6781\u5c0f\u503c\u7684\u8fde\u901a\u6027\uff0c\u5e76\u66f4\u6df1\u5165\u5730\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u666f\u89c2\u3002", "method": "1. \u5229\u7528\u53c2\u6570\u7a7a\u95f4\u5bf9\u79f0\u6027\uff0c\u5c06\u5bf9\u79f0\u7fa4\u7684\u62d3\u6251\u4e0e\u6781\u5c0f\u503c\u7684\u62d3\u6251\u8054\u7cfb\u8d77\u6765\u3002\n2. \u63a8\u5bfc\u7ebf\u6027\u7f51\u7edc\u6781\u5c0f\u503c\u7684\u8fde\u901a\u5206\u91cf\u6570\u91cf\uff0c\u5e76\u7814\u7a76\u8df3\u8fc7\u8fde\u63a5\u5bf9\u5176\u7684\u5f71\u54cd\u3002\n3. \u5206\u6790\u6a21\u5f0f\u8fde\u901a\u6027\u548c\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u6210\u7acb\u6216\u5931\u6548\u7684\u6761\u4ef6\u3002\n4. \u63d0\u4f9b\u7531\u5bf9\u79f0\u6027\u5f15\u8d77\u7684\u8fde\u63a5\u66f2\u7ebf\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u3002\n5. \u4f7f\u7528\u8fd9\u4e9b\u66f2\u7ebf\u7684\u66f2\u7387\uff0c\u63a8\u5bfc\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u8fd1\u4f3c\u6210\u7acb\u7684\u6761\u4ef6\u3002", "result": "1. \u6210\u529f\u63a8\u5bfc\u4e86\u7ebf\u6027\u7f51\u7edc\u6781\u5c0f\u503c\u7684\u8fde\u901a\u5206\u91cf\u6570\u91cf\u3002\n2. \u8bc1\u660e\u4e86\u8df3\u8fc7\u8fde\u63a5\u53ef\u4ee5\u51cf\u5c11\u8fde\u901a\u5206\u91cf\u7684\u6570\u91cf\u3002\n3. \u660e\u786e\u4e86\u6a21\u5f0f\u8fde\u901a\u6027\u548c\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u6210\u7acb\u6216\u5931\u6548\u7684\u6761\u4ef6\u3002\n4. \u63d0\u4f9b\u4e86\u7531\u5bf9\u79f0\u6027\u5f15\u8d77\u7684\u8fde\u63a5\u66f2\u7ebf\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u3002\n5. \u63a8\u5bfc\u51fa\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u8fd1\u4f3c\u6210\u7acb\u7684\u6761\u4ef6\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u53c2\u6570\u7a7a\u95f4\u5bf9\u79f0\u6027\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u666f\u89c2\u4e2d\u6a21\u5f0f\u8fde\u901a\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u7279\u522b\u662f\u8fde\u7eed\u5bf9\u79f0\u6027\u7684\u4f5c\u7528\u3002\u8fd9\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u548c\u6cdb\u5316\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.23683", "pdf": "https://arxiv.org/pdf/2505.23683", "abs": "https://arxiv.org/abs/2505.23683", "authors": ["Zixuan Wang", "Eshaan Nichani", "Alberto Bietti", "Alex Damian", "Daniel Hsu", "Jason D. Lee", "Denny Wu"], "title": "Learning Compositional Functions with Transformers from Easy-to-Hard Data", "categories": ["cs.LG"], "comment": "COLT 2025", "summary": "Transformer-based language models have demonstrated impressive capabilities\nacross a range of complex reasoning tasks. Prior theoretical work exploring the\nexpressive power of transformers has shown that they can efficiently perform\nmulti-step reasoning tasks involving parallelizable computations. However, the\nlearnability of such constructions, particularly the conditions on the data\ndistribution that enable efficient learning via gradient-based optimization,\nremains an open question. Towards answering this question, in this work we\nstudy the learnability of the $k$-fold composition task, which requires\ncomputing an interleaved composition of $k$ input permutations and $k$ hidden\npermutations, and can be expressed by a transformer with $O(\\log k)$ layers. On\nthe negative front, we prove a Statistical Query (SQ) lower bound showing that\nany SQ learner that makes only polynomially-many queries to an SQ oracle for\nthe $k$-fold composition task distribution must have sample size exponential in\n$k$, thus establishing a statistical-computational gap. On the other hand, we\nshow that this function class can be efficiently learned, with runtime and\nsample complexity polynomial in $k$, by gradient descent on an $O(\\log\nk)$-depth transformer via two different curriculum learning strategies: one in\nwhich data consists of $k'$-fold composition functions with $k' \\le k$\npresented in increasing difficulty, and another in which all such data is\npresented simultaneously. Our work sheds light on the necessity and sufficiency\nof having both easy and hard examples in the data distribution for transformers\nto learn complex compositional tasks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86Transformer\u6a21\u578b\u5728k\u91cd\u7ec4\u5408\u4efb\u52a1\u4e0a\u7684\u53ef\u5b66\u4e60\u6027\uff0c\u8bc1\u660e\u4e86\u7edf\u8ba1\u8ba1\u7b97\u5dee\u8ddd\u7684\u5b58\u5728\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u4e24\u79cd\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6709\u6548\u5b66\u4e60\u6b64\u7c7b\u4efb\u52a1\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u77e5Transformer\u80fd\u591f\u9ad8\u6548\u6267\u884c\u6d89\u53ca\u5e76\u884c\u5316\u8ba1\u7b97\u7684\u591a\u6b65\u63a8\u7406\u4efb\u52a1\uff0c\u4f46\u5176\u53ef\u5b66\u4e60\u6027\uff0c\u7279\u522b\u662f\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u6240\u9700\u7684\u6570\u636e\u5206\u5e03\u6761\u4ef6\uff0c\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u9009\u62e9\u5206\u6790k\u91cd\u7ec4\u5408\u4efb\u52a1\uff0c\u4ee5\u8fdb\u4e00\u6b65\u7406\u89e3Transformer\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u4e3ak\u91cd\u7ec4\u5408\u4efb\u52a1\u8bc1\u660e\u4e86\u4e00\u4e2a\u7edf\u8ba1\u67e5\u8be2\uff08SQ\uff09\u4e0b\u754c\uff0c\u8868\u660e\u4efb\u4f55\u4ec5\u5bf9k\u91cd\u7ec4\u5408\u4efb\u52a1\u5206\u5e03\u8fdb\u884c\u591a\u9879\u5f0f\u6570\u91cf\u67e5\u8be2\u7684SQ\u5b66\u4e60\u8005\u90fd\u9700\u8981\u6837\u672c\u6570\u91cf\u968fk\u5448\u6307\u6570\u589e\u957f\u3002\u63a5\u7740\uff0c\u7814\u7a76\u8005\u5c55\u793a\u4e86\u901a\u8fc7\u4e24\u79cd\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u53ef\u4ee5\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u6df1\u5ea6\u4e3aO(log k)\u7684Transformer\u4e0a\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u6837\u672c\u590d\u6742\u5ea6\u6765\u6709\u6548\u5b66\u4e60\u8be5\u51fd\u6570\u7c7b\u3002\u8fd9\u4e24\u79cd\u7b56\u7565\u5206\u522b\u662f\u6309\u96be\u5ea6\u9012\u589e\u63d0\u4f9b\u6570\u636e\u548c\u540c\u65f6\u63d0\u4f9b\u6240\u6709\u6570\u636e\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86k\u91cd\u7ec4\u5408\u4efb\u52a1\u5b58\u5728\u7edf\u8ba1\u8ba1\u7b97\u5dee\u8ddd\uff0c\u5373\u9700\u8981\u6307\u6570\u7ea7\u6837\u672c\u624d\u80fd\u901a\u8fc7SQ\u65b9\u6cd5\u5b66\u4e60\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u548c\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6709\u6548\u5b66\u4e60\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9610\u660e\u4e86\u6570\u636e\u5206\u5e03\u4e2d\u5305\u542b\u7b80\u5355\u548c\u56f0\u96be\u793a\u4f8b\u5bf9\u4e8eTransformer\u5b66\u4e60\u590d\u6742\u7ec4\u5408\u4efb\u52a1\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\u3002"}}
{"id": "2505.23696", "pdf": "https://arxiv.org/pdf/2505.23696", "abs": "https://arxiv.org/abs/2505.23696", "authors": ["Hiroshi Kera", "Nico Pelleriti", "Yuki Ishihara", "Max Zimmer", "Sebastian Pokutta"], "title": "Computational Algebra with Attention: Transformer Oracles for Border Basis Algorithms", "categories": ["cs.LG", "cs.SC"], "comment": "13+19 pages (3+9 figures, 2+7 tables)", "summary": "Solving systems of polynomial equations, particularly those with finitely\nmany solutions, is a crucial challenge across many scientific fields.\nTraditional methods like Gr\\\"obner and Border bases are fundamental but suffer\nfrom high computational costs, which have motivated recent Deep Learning\napproaches to improve efficiency, albeit at the expense of output correctness.\nIn this work, we introduce the Oracle Border Basis Algorithm, the first Deep\nLearning approach that accelerates Border basis computation while maintaining\noutput guarantees. To this end, we design and train a Transformer-based oracle\nthat identifies and eliminates computationally expensive reduction steps, which\nwe find to dominate the algorithm's runtime. By selectively invoking this\noracle during critical phases of computation, we achieve substantial speedup\nfactors of up to 3.5x compared to the base algorithm, without compromising the\ncorrectness of results. To generate the training data, we develop a sampling\nmethod and provide the first sampling theorem for border bases. We construct a\ntokenization and embedding scheme tailored to monomial-centered algebraic\ncomputations, resulting in a compact and expressive input representation, which\nreduces the number of tokens to encode an $n$-variate polynomial by a factor of\n$O(n)$. Our learning approach is data efficient, stable, and a practical\nenhancement to traditional computer algebra algorithms and symbolic\ncomputation.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOracle Border Basis Algorithm\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u52a0\u901f\u4e86Border basis\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8eTransformer\u7684oracle\u6a21\u578b\uff0c\u6d88\u9664\u6602\u8d35\u7684\u8ba1\u7b97\u6b65\u9aa4\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u91c7\u6837\u5b9a\u7406\u548ctokenization\u65b9\u6848\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe3.5\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e3a\u4f20\u7edf\u8ba1\u7b97\u673a\u4ee3\u6570\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u589e\u5f3a\u3002", "motivation": "\u6c42\u89e3\u591a\u9879\u5f0f\u65b9\u7a0b\u7ec4\uff0c\u7279\u522b\u662f\u6709\u9650\u89e3\u7684\u65b9\u7a0b\u7ec4\uff0c\u5728\u8bb8\u591a\u79d1\u5b66\u9886\u57df\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684Gr\u00f6bner\u548cBorder bases\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u727a\u7272\u4e86\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u6548\u7387\u53c8\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Oracle Border Basis Algorithm\uff0c\u5176\u6838\u5fc3\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684oracle\u6a21\u578b\uff0c\u7528\u4e8e\u8bc6\u522b\u5e76\u6d88\u9664\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u6602\u8d35\u7684\u7ea6\u7b80\u6b65\u9aa4\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u91c7\u6837\u65b9\u6cd5\u548c\u5b9a\u7406\uff0c\u6784\u5efa\u4e86\u4e13\u95e8\u9488\u5bf9\u5355\u9879\u5f0f\u4ee3\u6570\u8ba1\u7b97\u7684tokenization\u548cembedding\u65b9\u6848\uff0c\u4ece\u800c\u751f\u6210\u7d27\u51d1\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8f93\u5165\u8868\u793a\u3002", "result": "\u76f8\u6bd4\u57fa\u7840\u7b97\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u635f\u5bb3\u7ed3\u679c\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe3.5\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002\u540c\u65f6\uff0c\u6240\u63d0\u51fa\u7684tokenization\u65b9\u6848\u5c06\u7f16\u7801n\u5143\u591a\u9879\u5f0f\u7684tokens\u6570\u91cf\u51cf\u5c11\u4e86O(n)\u500d\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6570\u636e\u9ad8\u6548\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "Oracle Border Basis Algorithm\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u52a0\u901f\u4f20\u7edf\u8ba1\u7b97\u673a\u4ee3\u6570\u7b97\u6cd5\u4e2d\u7684Border basis\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u679c\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u7b26\u53f7\u8ba1\u7b97\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u8fdb\u5c55\u3002"}}
{"id": "2505.23700", "pdf": "https://arxiv.org/pdf/2505.23700", "abs": "https://arxiv.org/abs/2505.23700", "authors": ["Oleksii Furman", "Ulvi Movsum-zada", "Patryk Marszalek", "Maciej Zi\u0119ba", "Marek \u015amieja"], "title": "DiCoFlex: Model-agnostic diverse counterfactuals with flexible control", "categories": ["cs.LG"], "comment": null, "summary": "Counterfactual explanations play a pivotal role in explainable artificial\nintelligence (XAI) by offering intuitive, human-understandable alternatives\nthat elucidate machine learning model decisions. Despite their significance,\nexisting methods for generating counterfactuals often require constant access\nto the predictive model, involve computationally intensive optimization for\neach instance and lack the flexibility to adapt to new user-defined constraints\nwithout retraining. In this paper, we propose DiCoFlex, a novel model-agnostic,\nconditional generative framework that produces multiple diverse counterfactuals\nin a single forward pass. Leveraging conditional normalizing flows trained\nsolely on labeled data, DiCoFlex addresses key limitations by enabling\nreal-time user-driven customization of constraints such as sparsity and\nactionability at inference time. Extensive experiments on standard benchmark\ndatasets show that DiCoFlex outperforms existing methods in terms of validity,\ndiversity, proximity, and constraint adherence, making it a practical and\nscalable solution for counterfactual generation in sensitive decision-making\ndomains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiCoFlex\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u9891\u7e41\u8bbf\u95ee\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5355\u4e00\u524d\u5411\u4f20\u9012\u5373\u53ef\u751f\u6210\u591a\u4e2a\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u5728\u63a8\u7406\u65f6\u5b9e\u65f6\u81ea\u5b9a\u4e49\u7ea6\u675f\u6761\u4ef6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDiCoFlex\u5728\u6709\u6548\u6027\u3001\u591a\u6837\u6027\u3001\u63a5\u8fd1\u6027\u548c\u7ea6\u675f\u9075\u5faa\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u65b9\u6cd5\u5b58\u5728\u9700\u8981\u9891\u7e41\u8bbf\u95ee\u6a21\u578b\u3001\u8ba1\u7b97\u5bc6\u96c6\u4ee5\u53ca\u7f3a\u4e4f\u5bf9\u65b0\u7528\u6237\u5b9a\u4e49\u7ea6\u675f\u7684\u7075\u6d3b\u6027\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86DiCoFlex\uff0c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6761\u4ef6\u751f\u6210\u6846\u67b6\uff0c\u5229\u7528\u4ec5\u5728\u6807\u8bb0\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6761\u4ef6\u6807\u51c6\u5316\u6d41\uff0c\u5728\u5355\u4e00\u524d\u5411\u4f20\u9012\u4e2d\u751f\u6210\u591a\u4e2a\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\uff0c\u5e76\u5141\u8bb8\u5b9e\u65f6\u7528\u6237\u9a71\u52a8\u7684\u7ea6\u675f\u5b9a\u5236\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDiCoFlex\u5728\u6709\u6548\u6027\u3001\u591a\u6837\u6027\u3001\u63a5\u8fd1\u6027\u548c\u7ea6\u675f\u9075\u5faa\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "DiCoFlex\u4e3a\u53cd\u4e8b\u5b9e\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u654f\u611f\u51b3\u7b56\u9886\u57df\u3002"}}
{"id": "2505.23702", "pdf": "https://arxiv.org/pdf/2505.23702", "abs": "https://arxiv.org/abs/2505.23702", "authors": ["Nathan Lichtl\u00e9", "Alexi Canesse", "Zhe Fu", "Hossein Nick Zinat Matin", "Maria Laura Delle Monache", "Alexandre M. Bayen"], "title": "(U)NFV: Supervised and Unsupervised Neural Finite Volume Methods for Solving Hyperbolic PDEs", "categories": ["cs.LG", "cs.NA", "math.NA", "I.2.6; G.1.8"], "comment": null, "summary": "We introduce (U)NFV, a modular neural network architecture that generalizes\nclassical finite volume (FV) methods for solving hyperbolic conservation laws.\nHyperbolic partial differential equations (PDEs) are challenging to solve,\nparticularly conservation laws whose physically relevant solutions contain\nshocks and discontinuities. FV methods are widely used for their mathematical\nproperties: convergence to entropy solutions, flow conservation, or total\nvariation diminishing, but often lack accuracy and flexibility in complex\nsettings. Neural Finite Volume addresses these limitations by learning update\nrules over extended spatial and temporal stencils while preserving conservation\nstructure. It supports both supervised training on solution data (NFV) and\nunsupervised training via weak-form residual loss (UNFV). Applied to\nfirst-order conservation laws, (U)NFV achieves up to 10x lower error than\nGodunov's method, outperforms ENO/WENO, and rivals discontinuous Galerkin\nsolvers with far less complexity. On traffic modeling problems, both from PDEs\nand from experimental highway data, (U)NFV captures nonlinear wave dynamics\nwith significantly higher fidelity and scalability than traditional FV\napproaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784(U)NFV\uff0c\u7528\u4e8e\u6c42\u89e3\u53cc\u66f2\u5b88\u6052\u5f8b\u65b9\u7a0b\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5b88\u6052\u7ed3\u6784\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6709\u9650\u4f53\u79ef(FV)\u65b9\u6cd5\u867d\u7136\u5177\u6709\u826f\u597d\u7684\u6570\u5b66\u7279\u6027\uff08\u5982\u6536\u655b\u5230\u71b5\u89e3\u3001\u6d41\u5b88\u6052\u6216\u603b\u53d8\u5dee\u51cf\u5c11\uff09\uff0c\u4f46\u5728\u590d\u6742\u8bbe\u7f6e\u4e0b\u5f80\u5f80\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5f15\u5165\u4e86(U)NFV\uff0c\u8fd9\u662f\u4e00\u79cd\u6a21\u5757\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5b83\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684\u6709\u9650\u4f53\u79ef\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u6269\u5c55\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u6a21\u677f\u4e0a\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u540c\u65f6\u4fdd\u7559\u5b88\u6052\u7ed3\u6784\uff0c\u652f\u6301\u6709\u76d1\u7763\u7684\u8bad\u7ec3\uff08\u57fa\u4e8e\u89e3\u6570\u636e\uff09\u548c\u65e0\u76d1\u7763\u7684\u8bad\u7ec3\uff08\u901a\u8fc7\u5f31\u5f62\u5f0f\u6b8b\u5dee\u635f\u5931\uff09\u3002", "result": "(U)NFV\u5728\u6c42\u89e3\u4e00\u9636\u5b88\u6052\u5f8b\u65f6\uff0c\u6bd4Godunov\u65b9\u6cd5\u8bef\u5dee\u4f4e10\u500d\uff0c\u4f18\u4e8eENO/WENO\uff0c\u5e76\u4e14\u4ee5\u8fdc\u4f4e\u7684\u590d\u6742\u5ea6\u5ab2\u7f8e\u4e0d\u8fde\u7eedGalerkin\u6c42\u89e3\u5668\u3002\u5728\u4ea4\u901a\u5efa\u6a21\u95ee\u9898\u4e0a\uff0c\u65e0\u8bba\u662f\u57fa\u4e8ePDE\u8fd8\u662f\u5b9e\u9a8c\u9ad8\u901f\u516c\u8def\u6570\u636e\uff0c(U)NFV\u90fd\u80fd\u663e\u8457\u63d0\u9ad8\u975e\u7ebf\u6027\u6ce2\u52a8\u529b\u5b66\u7684\u6355\u6349\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "(U)NFV\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6570\u503c\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u4f20\u7edfFV\u65b9\u6cd5\u4f18\u70b9\u7684\u540c\u65f6\uff0c\u63d0\u5347\u590d\u6742\u573a\u666f\u4e0b\u7684\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2505.23705", "pdf": "https://arxiv.org/pdf/2505.23705", "abs": "https://arxiv.org/abs/2505.23705", "authors": ["Danny Driess", "Jost Tobias Springenberg", "Brian Ichter", "Lili Yu", "Adrian Li-Bell", "Karl Pertsch", "Allen Z. Ren", "Homer Walke", "Quan Vuong", "Lucy Xiaoyang Shi", "Sergey Levine"], "title": "Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Vision-language-action (VLA) models provide a powerful approach to training\ncontrol policies for physical systems, such as robots, by combining end-to-end\nlearning with transfer of semantic knowledge from web-scale vision-language\nmodel (VLM) training. However, the constraints of real-time control are often\nat odds with the design of VLMs: the most powerful VLMs have tens or hundreds\nof billions of parameters, presenting an obstacle to real-time inference, and\noperate on discrete tokens rather than the continuous-valued outputs that are\nrequired for controlling robots. To address this challenge, recent VLA models\nhave used specialized modules for efficient continuous control, such as action\nexperts or continuous output heads, which typically require adding new\nuntrained parameters to the pretrained VLM backbone. While these modules\nimprove real-time and control capabilities, it remains an open question whether\nthey preserve or degrade the semantic knowledge contained in the pretrained\nVLM, and what effect they have on the VLA training dynamics. In this paper, we\nstudy this question in the context of VLAs that include a continuous diffusion\nor flow matching action expert, showing that naively including such experts\nsignificantly harms both training speed and knowledge transfer. We provide an\nextensive analysis of various design choices, their impact on performance and\nknowledge transfer, and propose a technique for insulating the VLM backbone\nduring VLA training that mitigates this issue. Videos are available at\nhttps://pi.website/research/knowledge_insulation.", "AI": {"tldr": "Vision-language-action (VLA)\u6a21\u578b\u7ed3\u5408\u4e86\u7aef\u5230\u7aef\u5b66\u4e60\u4e0e\u4ece\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e2d\u8f6c\u79fb\u7684\u8bed\u4e49\u77e5\u8bc6\uff0c\u7528\u4e8e\u7269\u7406\u7cfb\u7edf\uff08\u5982\u673a\u5668\u4eba\uff09\u7684\u63a7\u5236\u7b56\u7565\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u5f3a\u5927\u7684VLM\u5b58\u5728\u5b9e\u65f6\u63a8\u7406\u969c\u788d\u4e14\u5176\u79bb\u6563\u8f93\u51fa\u4e0d\u9002\u5408\u673a\u5668\u4eba\u63a7\u5236\u3002\u672c\u6587\u7814\u7a76\u4e86\u5728VLA\u4e2d\u5305\u542b\u8fde\u7eed\u6269\u6563\u6216\u6d41\u5339\u914d\u52a8\u4f5c\u4e13\u5bb6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7b80\u5355\u52a0\u5165\u8fd9\u4e9b\u6a21\u5757\u4f1a\u663e\u8457\u635f\u5bb3\u8bad\u7ec3\u901f\u5ea6\u548c\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728VLA\u8bad\u7ec3\u671f\u95f4\u4fdd\u62a4VLM\u9aa8\u5e72\u7684\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u867d\u7136\u901a\u8fc7\u4e13\u95e8\u6a21\u5757\uff08\u5982\u52a8\u4f5c\u4e13\u5bb6\u6216\u8fde\u7eed\u8f93\u51fa\u5934\uff09\u63d0\u5347\u4e86\u5b9e\u65f6\u6027\u548c\u63a7\u5236\u80fd\u529b\uff0c\u4f46\u8fd9\u4e9b\u6a21\u5757\u5bf9\u9884\u8bad\u7ec3VLM\u4e2d\u7684\u8bed\u4e49\u77e5\u8bc6\u662f\u4fdd\u7559\u8fd8\u662f\u635f\u5bb3\u5c1a\u4e0d\u660e\u786e\uff0c\u8fd9\u5f71\u54cd\u4e86VLA\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u8bbe\u8ba1\u9009\u62e9\u5bf9\u6027\u80fd\u548c\u77e5\u8bc6\u8fc1\u79fb\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728VLA\u8bad\u7ec3\u671f\u95f4\u4fdd\u62a4VLM\u9aa8\u5e72\u7684\u6280\u672f\uff0c\u4ee5\u51cf\u8f7b\u4e0d\u826f\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u5730\u52a0\u5165\u8fde\u7eed\u6269\u6563\u6216\u6d41\u5339\u914d\u52a8\u4f5c\u4e13\u5bb6\u4f1a\u663e\u8457\u635f\u5bb3\u8bad\u7ec3\u901f\u5ea6\u548c\u77e5\u8bc6\u8fc1\u79fb\u3002\u63d0\u51fa\u7684\u4fdd\u62a4\u6280\u672f\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u8c28\u614e\u8bbe\u8ba1VLA\u6a21\u578b\u4e2d\u7684\u6a21\u5757\uff0c\u4ee5\u907f\u514d\u635f\u5bb3\u9884\u8bad\u7ec3VLM\u7684\u77e5\u8bc6\uff0c\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u77e5\u8bc6\u8fc1\u79fb\u6548\u679c\u3002"}}
{"id": "2505.23719", "pdf": "https://arxiv.org/pdf/2505.23719", "abs": "https://arxiv.org/abs/2505.23719", "authors": ["Andreas Auer", "Patrick Podest", "Daniel Klotz", "Sebastian B\u00f6ck", "G\u00fcnter Klambauer", "Sepp Hochreiter"], "title": "TiRex: Zero-Shot Forecasting Across Long and Short Horizons with Enhanced In-Context Learning", "categories": ["cs.LG"], "comment": null, "summary": "In-context learning, the ability of large language models to perform tasks\nusing only examples provided in the prompt, has recently been adapted for time\nseries forecasting. This paradigm enables zero-shot prediction, where past\nvalues serve as context for forecasting future values, making powerful\nforecasting tools accessible to non-experts and increasing the performance when\ntraining data are scarce. Most existing zero-shot forecasting approaches rely\non transformer architectures, which, despite their success in language, often\nfall short of expectations in time series forecasting, where recurrent models\nlike LSTMs frequently have the edge. Conversely, while LSTMs are well-suited\nfor time series modeling due to their state-tracking capabilities, they lack\nstrong in-context learning abilities. We introduce TiRex that closes this gap\nby leveraging xLSTM, an enhanced LSTM with competitive in-context learning\nskills. Unlike transformers, state-space models, or parallelizable RNNs such as\nRWKV, TiRex retains state-tracking, a critical property for long-horizon\nforecasting. To further facilitate its state-tracking ability, we propose a\ntraining-time masking strategy called CPM. TiRex sets a new state of the art in\nzero-shot time series forecasting on the HuggingFace benchmarks GiftEval and\nChronos-ZS, outperforming significantly larger models including TabPFN-TS\n(Prior Labs), Chronos Bolt (Amazon), TimesFM (Google), and Moirai (Salesforce)\nacross both short- and long-term forecasts.", "AI": {"tldr": "TiRex\uff0c\u4e00\u79cd\u57fa\u4e8e\u589e\u5f3a\u578bLSTM\uff08xLSTM\uff09\u7684\u6a21\u578b\uff0c\u5728\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u5305\u62ecTransformer\u5728\u5185\u7684\u591a\u79cd\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u96f6\u6837\u672c\u9884\u6d4b\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8eTransformer\u67b6\u6784\uff0c\u867d\u7136\u5728\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u9762\u5f80\u5f80\u4e0d\u5982LSTM\u7b49\u5faa\u73af\u6a21\u578b\u3002\u7136\u800c\uff0cLSTM\u7f3a\u4e4f\u5f3a\u5927\u7684\u60c5\u5883\u5b66\u4e60\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTiRex\u7684\u6a21\u578b\uff0c\u5b83\u5229\u7528\u589e\u5f3a\u578bLSTM\uff08xLSTM\uff09\u6765\u63d0\u5347\u60c5\u5883\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u4fdd\u7559\u4e86\u72b6\u6001\u8ffd\u8e2a\u7279\u6027\u4ee5\u9002\u5e94\u957f\u671f\u9884\u6d4b\u9700\u6c42\u3002\u540c\u65f6\u5f15\u5165\u4e86\u8bad\u7ec3\u65f6\u7684\u63a9\u7801\u7b56\u7565CPM\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u5176\u72b6\u6001\u8ffd\u8e2a\u80fd\u529b\u3002", "result": "TiRex\u5728HuggingFace\u7684GiftEval\u548cChronos-ZS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6811\u7acb\u4e86\u65b0\u7684\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6807\u51c6\uff0c\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u5927\u578b\u6a21\u578b\uff0c\u5982TabPFN-TS\u3001Chronos Bolt\u3001TimesFM\u548cMoirai\u7b49\uff0c\u5728\u77ed\u671f\u548c\u957f\u671f\u9884\u6d4b\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TiRex\u901a\u8fc7\u7ed3\u5408xLSTM\u548cCPM\u7b56\u7565\uff0c\u6210\u529f\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5728\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002"}}
{"id": "2505.23721", "pdf": "https://arxiv.org/pdf/2505.23721", "abs": "https://arxiv.org/abs/2505.23721", "authors": ["Sean Current", "Ziqi Chen", "Daniel Adu-Ampratwum", "Xia Ning", "Srinivasan Parthasarathy"], "title": "DiffER: Categorical Diffusion for Chemical Retrosynthesis", "categories": ["cs.LG"], "comment": "25 pages, 3 figures, 3 tables", "summary": "Methods for automatic chemical retrosynthesis have found recent success\nthrough the application of models traditionally built for natural language\nprocessing, primarily through transformer neural networks. These models have\ndemonstrated significant ability to translate between the SMILES encodings of\nchemical products and reactants, but are constrained as a result of their\nautoregressive nature. We propose DiffER, an alternative template-free method\nfor retrosynthesis prediction in the form of categorical diffusion, which\nallows the entire output SMILES sequence to be predicted in unison. We\nconstruct an ensemble of diffusion models which achieves state-of-the-art\nperformance for top-1 accuracy and competitive performance for top-3, top-5,\nand top-10 accuracy among template-free methods. We prove that DiffER is a\nstrong baseline for a new class of template-free model, capable of learning a\nvariety of synthetic techniques used in laboratory settings and outperforming a\nvariety of other template-free methods on top-k accuracy metrics. By\nconstructing an ensemble of categorical diffusion models with a novel length\nprediction component with variance, our method is able to approximately sample\nfrom the posterior distribution of reactants, producing results with strong\nmetrics of confidence and likelihood. Furthermore, our analyses demonstrate\nthat accurate prediction of the SMILES sequence length is key to further\nboosting the performance of categorical diffusion models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiffER\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5206\u7c7b\u6269\u6563\u6a21\u578b\u8fdb\u884c\u65e0\u6a21\u677f\u7684\u9006\u5408\u6210\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u4f53\u9884\u6d4b\u8f93\u51faSMILES\u5e8f\u5217\uff0c\u6784\u5efa\u4e86\u5177\u6709\u65b0\u578b\u957f\u5ea6\u9884\u6d4b\u7ec4\u4ef6\u7684\u6269\u6563\u6a21\u578b\u96c6\u5408\uff0c\u5b9e\u73b0\u4e86SOTA\u7684top-1\u51c6\u786e\u7387\uff0c\u5e76\u5728top-3\u3001top-5\u548ctop-10\u51c6\u786e\u7387\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002\u7814\u7a76\u8868\u660e\uff0c\u51c6\u786e\u9884\u6d4bSMILES\u5e8f\u5217\u957f\u5ea6\u5bf9\u63d0\u5347\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u81ea\u52a8\u5316\u5b66\u9006\u5408\u6210\u7684\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\uff08\u5982Transformer\uff09\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u4ea7\u7269\u548c\u53cd\u5e94\u7269\u4e4b\u95f4\u7684SMILES\u7f16\u7801\u8f6c\u6362\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u56e0\u81ea\u56de\u5f52\u7279\u6027\u53d7\u5230\u9650\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faDiffER\u65b9\u6cd5\uff0c\u91c7\u7528\u5206\u7c7b\u6269\u6563\u6a21\u578b\u8fdb\u884c\u65e0\u6a21\u677f\u7684\u9006\u5408\u6210\u9884\u6d4b\u3002\u901a\u8fc7\u6784\u5efa\u6269\u6563\u6a21\u578b\u96c6\u5408\uff0c\u5e76\u5f15\u5165\u5177\u6709\u65b9\u5dee\u7684\u65b0\u578b\u957f\u5ea6\u9884\u6d4b\u7ec4\u4ef6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4ece\u53cd\u5e94\u7269\u7684\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\u3002\u6574\u4e2a\u8f93\u51faSMILES\u5e8f\u5217\u53ef\u4ee5\u540c\u65f6\u9884\u6d4b\u3002", "result": "DiffER\u5728top-1\u51c6\u786e\u7387\u4e0a\u8fbe\u5230SOTA\u6c34\u5e73\uff0c\u5728top-3\u3001top-5\u548ctop-10\u51c6\u786e\u7387\u4e0a\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\u3002\u6b64\u5916\uff0c\u5206\u6790\u8868\u660e\uff0c\u51c6\u786e\u9884\u6d4bSMILES\u5e8f\u5217\u957f\u5ea6\u662f\u63d0\u9ad8\u5206\u7c7b\u6269\u6563\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "DiffER\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ee3\u8868\u4e86\u4e00\u7c7b\u65b0\u7684\u65e0\u6a21\u677f\u6a21\u578b\uff0c\u80fd\u591f\u5b66\u4e60\u5b9e\u9a8c\u5ba4\u4e2d\u4f7f\u7528\u7684\u591a\u79cd\u5408\u6210\u6280\u672f\uff0c\u5e76\u5728top-k\u51c6\u786e\u7387\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65e0\u6a21\u677f\u65b9\u6cd5\u3002"}}
{"id": "2505.23725", "pdf": "https://arxiv.org/pdf/2505.23725", "abs": "https://arxiv.org/abs/2505.23725", "authors": ["Benjamin Th\u00e9rien", "Xiaolong Huang", "Irina Rish", "Eugene Belilovsky"], "title": "MuLoCo: Muon is a practical inner optimizer for DiLoCo", "categories": ["cs.LG"], "comment": null, "summary": "DiLoCo is a powerful framework for training large language models (LLMs)\nunder networking constraints with advantages for increasing parallelism and\naccelerator utilization in data center settings. Despite significantly reducing\ncommunication frequency, however, DiLoCo's communication steps still involve\nall-reducing a complete copy of the model's parameters. While existing works\nhave explored ways to reduce communication in DiLoCo, the role of error\nfeedback accumulators and the effect of the inner-optimizer on compressibility\nremain under-explored. In this work, we investigate the effectiveness of\nstandard compression methods including Top-k sparsification and quantization\nfor reducing the communication overhead of DiLoCo when paired with two local\noptimizers (AdamW and Muon). Our experiments pre-training decoder-only\ntransformer language models (LMs) reveal that leveraging Muon as the inner\noptimizer for DiLoCo along with an error-feedback accumulator allows to\naggressively compress the communicated delta to 2-bits with next to no\nperformance degradation. Crucially, MuLoCo (Muon inner optimizer DiLoCo)\nsignificantly outperforms DiLoCo while communicating 8X less and having\nidentical memory complexity.", "AI": {"tldr": "DiLoCo\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7f51\u7edc\u7ea6\u675f\u4e0b\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5177\u6709\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u8bbe\u7f6e\u4e2d\u7684\u5e76\u884c\u6027\u548c\u52a0\u901f\u5668\u5229\u7528\u7387\u7684\u4f18\u52bf\u3002\u5c3d\u7ba1\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u9891\u7387\uff0c\u4f46DiLoCo\u7684\u901a\u4fe1\u6b65\u9aa4\u4ecd\u7136\u6d89\u53ca\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5b8c\u6574\u526f\u672c\u8fdb\u884c\u5168\u5f52\u7ea6\u3002\u672c\u6587\u7814\u7a76\u4e86\u6807\u51c6\u538b\u7f29\u65b9\u6cd5\uff08\u5982Top-k\u7a00\u758f\u5316\u548c\u91cf\u5316\uff09\u5728\u4e0e\u4e24\u4e2a\u672c\u5730\u4f18\u5316\u5668\uff08AdamW\u548cMuon\uff09\u7ed3\u5408\u65f6\u51cf\u5c11DiLoCo\u901a\u4fe1\u5f00\u9500\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528Muon\u4f5c\u4e3aDiLoCo\u7684\u5185\u90e8\u4f18\u5316\u5668\uff0c\u5e76\u7ed3\u5408\u8bef\u5dee\u53cd\u9988\u7d2f\u52a0\u5668\uff0c\u53ef\u4ee5\u5c06\u901a\u4fe1delta\u538b\u7f29\u52302\u4f4d\uff0c\u51e0\u4e4e\u6ca1\u6709\u6027\u80fd\u4e0b\u964d\u3002\u91cd\u8981\u7684\u662f\uff0cMuLoCo\uff08\u4f7f\u7528Muon\u4f5c\u4e3a\u5185\u90e8\u4f18\u5316\u5668\u7684DiLoCo\uff09\u5728\u901a\u4fe1\u91cf\u51cf\u5c118\u500d\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8eDiLoCo\uff0c\u4e14\u5177\u6709\u76f8\u540c\u7684\u5185\u5b58\u590d\u6742\u5ea6\u3002", "motivation": "\u5c3d\u7ba1DiLoCo\u6846\u67b6\u5df2\u7ecf\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u9891\u7387\uff0c\u4f46\u5176\u901a\u4fe1\u6b65\u9aa4\u4ecd\u6d89\u53ca\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u5b8c\u6574\u526f\u672c\u8fdb\u884c\u5168\u5f52\u7ea6\uff0c\u5bfc\u81f4\u8f83\u9ad8\u7684\u901a\u4fe1\u5f00\u9500\u3002\u73b0\u6709\u7684\u5de5\u4f5c\u867d\u7136\u63a2\u7d22\u4e86\u51cf\u5c11DiLoCo\u901a\u4fe1\u7684\u65b9\u6cd5\uff0c\u4f46\u8bef\u5dee\u53cd\u9988\u7d2f\u52a0\u5668\u7684\u4f5c\u7528\u548c\u5185\u90e8\u4f18\u5316\u5668\u5bf9\u53ef\u538b\u7f29\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u6807\u51c6\u538b\u7f29\u65b9\u6cd5\u5728\u51cf\u5c11DiLoCo\u901a\u4fe1\u5f00\u9500\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u9884\u8bad\u7ec3\u4ec5\u89e3\u7801\u5668\u7684Transformer\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\uff0c\u7814\u7a76\u4e86\u4e24\u79cd\u672c\u5730\u4f18\u5316\u5668\uff08AdamW\u548cMuon\uff09\u4e0e\u6807\u51c6\u538b\u7f29\u65b9\u6cd5\uff08Top-k\u7a00\u758f\u5316\u548c\u91cf\u5316\uff09\u7ed3\u5408\u65f6\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u4e86\u8bef\u5dee\u53cd\u9988\u7d2f\u52a0\u5668\u6765\u8bc4\u4f30\u538b\u7f29\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528Muon\u4f5c\u4e3a\u5185\u90e8\u4f18\u5316\u5668\uff0c\u5e76\u7ed3\u5408\u8bef\u5dee\u53cd\u9988\u7d2f\u52a0\u5668\uff0c\u53ef\u4ee5\u5c06\u901a\u4fe1delta\u538b\u7f29\u81f32\u4f4d\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u964d\u4f4e\u6027\u80fd\u3002\u6b64\u5916\uff0cMuLoCo\uff08\u4f7f\u7528Muon\u4f5c\u4e3a\u5185\u90e8\u4f18\u5316\u5668\u7684DiLoCo\uff09\u5728\u901a\u4fe1\u91cf\u51cf\u5c118\u500d\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8eDiLoCo\uff0c\u4e14\u5177\u6709\u76f8\u540c\u7684\u5185\u5b58\u590d\u6742\u5ea6\u3002", "conclusion": "\u6807\u51c6\u538b\u7f29\u65b9\u6cd5\uff08\u5982Top-k\u7a00\u758f\u5316\u548c\u91cf\u5316\uff09\u4e0e\u9002\u5f53\u7684\u672c\u5730\u4f18\u5316\u5668\uff08\u5982Muon\uff09\u7ed3\u5408\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11DiLoCo\u901a\u4fe1\u5f00\u9500\u65b9\u9762\u53d6\u5f97\u663e\u8457\u6548\u679c\u3002\u4f7f\u7528Muon\u4f5c\u4e3a\u5185\u90e8\u4f18\u5316\u5668\u7684MuLoCo\u4e0d\u4ec5\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u91cf\uff0c\u8fd8\u4fdd\u6301\u4e86\u4e0eDiLoCo\u76f8\u540c\u7684\u5185\u5b58\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2505.23732", "pdf": "https://arxiv.org/pdf/2505.23732", "abs": "https://arxiv.org/abs/2505.23732", "authors": ["Shreeram Suresh Chandra", "Lucas Goncalves", "Junchen Lu", "Carlos Busso", "Berrak Sisman"], "title": "EmotionRankCLAP: Bridging Natural Language Speaking Styles and Ordinal Speech Emotion via Rank-N-Contrast", "categories": ["cs.LG"], "comment": "Accepted at Interspeech 2025", "summary": "Current emotion-based contrastive language-audio pretraining (CLAP) methods\ntypically learn by na\\\"ively aligning audio samples with corresponding text\nprompts. Consequently, this approach fails to capture the ordinal nature of\nemotions, hindering inter-emotion understanding and often resulting in a wide\nmodality gap between the audio and text embeddings due to insufficient\nalignment. To handle these drawbacks, we introduce EmotionRankCLAP, a\nsupervised contrastive learning approach that uses dimensional attributes of\nemotional speech and natural language prompts to jointly capture fine-grained\nemotion variations and improve cross-modal alignment. Our approach utilizes a\nRank-N-Contrast objective to learn ordered relationships by contrasting samples\nbased on their rankings in the valence-arousal space. EmotionRankCLAP\noutperforms existing emotion-CLAP methods in modeling emotion ordinality across\nmodalities, measured via a cross-modal retrieval task.", "AI": {"tldr": "\u5f53\u524d\u57fa\u4e8e\u60c5\u611f\u7684\u5bf9\u6bd4\u8bed\u8a00-\u97f3\u9891\u9884\u8bad\u7ec3\uff08CLAP\uff09\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u7b80\u5355\u5bf9\u9f50\u97f3\u9891\u6837\u672c\u4e0e\u5bf9\u5e94\u6587\u672c\u63d0\u793a\u8fdb\u884c\u5b66\u4e60\uff0c\u8fd9\u65e0\u6cd5\u6355\u6349\u60c5\u611f\u7684\u5e8f\u6027\u8d28\uff0c\u5bfc\u81f4\u6a21\u6001\u95f4\u5dee\u8ddd\u5927\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86EmotionRankCLAP\uff0c\u4e00\u79cd\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u60c5\u611f\u8bed\u97f3\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u7ef4\u5ea6\u5c5e\u6027\u6765\u5171\u540c\u6355\u6349\u7cbe\u7ec6\u7684\u60c5\u611f\u53d8\u5316\u5e76\u6539\u5584\u8de8\u6a21\u6001\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528Rank-N-Contrast\u76ee\u6807\u51fd\u6570\u901a\u8fc7\u5728\u4ef7-\u5524\u9192\u7a7a\u95f4\u4e2d\u7684\u6392\u540d\u5bf9\u6bd4\u6837\u672c\u6765\u5b66\u4e60\u6709\u5e8f\u5173\u7cfb\uff0c\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684CLAP\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6355\u6349\u60c5\u611f\u7684\u5e8f\u6027\u8d28\uff0c\u5bfc\u81f4\u6a21\u6001\u95f4\u5bf9\u9f50\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86\u8de8\u6a21\u6001\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEmotionRankCLAP\u7684\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u60c5\u611f\u8bed\u97f3\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u7ef4\u5ea6\u5c5e\u6027\u6765\u5171\u540c\u6355\u6349\u7cbe\u7ec6\u7684\u60c5\u611f\u53d8\u5316\uff0c\u5e76\u901a\u8fc7Rank-N-Contrast\u76ee\u6807\u51fd\u6570\u5b66\u4e60\u6709\u5e8f\u5173\u7cfb\u3002", "result": "EmotionRankCLAP\u5728\u5efa\u6a21\u8de8\u6a21\u6001\u60c5\u611f\u5e8f\u6027\u8d28\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684CLAP\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "EmotionRankCLAP\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u60c5\u611f\u7684\u5e8f\u6027\u8d28\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u5bf9\u9f50\u6548\u679c\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u6539\u8fdbCLAP\u65b9\u6cd5\u3002"}}
{"id": "2505.23749", "pdf": "https://arxiv.org/pdf/2505.23749", "abs": "https://arxiv.org/abs/2505.23749", "authors": ["Paul G\u00f6lz", "Nika Haghtalab", "Kunhe Yang"], "title": "Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "After pre-training, large language models are aligned with human preferences\nbased on pairwise comparisons. State-of-the-art alignment methods (such as\nPPO-based RLHF and DPO) are built on the assumption of aligning with a single\npreference model, despite being deployed in settings where users have diverse\npreferences. As a result, it is not even clear that these alignment methods\nproduce models that satisfy users on average -- a minimal requirement for\npluralistic alignment. Drawing on social choice theory and modeling users'\ncomparisons through individual Bradley-Terry (BT) models, we introduce an\nalignment method's distortion: the worst-case ratio between the optimal\nachievable average utility, and the average utility of the learned policy.\n  The notion of distortion helps draw sharp distinctions between alignment\nmethods: Nash Learning from Human Feedback achieves the minimax optimal\ndistortion of $(\\frac{1}{2} + o(1)) \\cdot \\beta$ (for the BT temperature\n$\\beta$), robustly across utility distributions, distributions of comparison\npairs, and permissible KL divergences from the reference policy. RLHF and DPO,\nby contrast, suffer $\\geq (1 - o(1)) \\cdot \\beta$ distortion already without a\nKL constraint, and $e^{\\Omega(\\beta)}$ or even unbounded distortion in the full\nsetting, depending on how comparison pairs are sampled.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u540e\uff0c\u901a\u8fc7\u4e24\u4e24\u6bd4\u8f83\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002\u73b0\u6709\u7684\u5bf9\u9f50\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u7528\u6237\u591a\u6837\u5316\u7684\u9700\u6c42\u3002\u672c\u6587\u901a\u8fc7\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u548cBradley-Terry\u6a21\u578b\u5f15\u5165\u4e86\u5bf9\u9f50\u65b9\u6cd5\u7684\u5931\u771f\u6982\u5ff5\uff0c\u5e76\u5206\u6790\u4e86\u51e0\u79cd\u65b9\u6cd5\u7684\u5931\u771f\u7a0b\u5ea6\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982\u57fa\u4e8ePPO\u7684RLHF\u548cDPO\uff09\u5047\u8bbe\u53ea\u4e0e\u5355\u4e00\u7684\u504f\u597d\u6a21\u578b\u5bf9\u9f50\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7528\u6237\u7684\u504f\u597d\u662f\u591a\u6837\u7684\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u7528\u6237\u7684\u5e73\u5747\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u548cBradley-Terry\u6a21\u578b\u6765\u6a21\u62df\u7528\u6237\u7684\u6bd4\u8f83\u884c\u4e3a\uff0c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5bf9\u9f50\u65b9\u6cd5\u7684\u5931\u771f\u6982\u5ff5\uff1a\u5373\u6700\u4f18\u53ef\u5b9e\u73b0\u7684\u5e73\u5747\u6548\u7528\u4e0e\u6240\u5b66\u7b56\u7565\u7684\u5e73\u5747\u6548\u7528\u4e4b\u95f4\u7684\u6700\u5dee\u6bd4\u7387\u3002\u5e76\u4ee5\u6b64\u5bf9\u6bd4\u4e86\u4e0d\u540c\u5bf9\u9f50\u65b9\u6cd5\u7684\u5931\u771f\u7a0b\u5ea6\u3002", "result": "Nash Learning from Human Feedback\u5728\u5404\u79cd\u6548\u7528\u5206\u5e03\u3001\u6bd4\u8f83\u5bf9\u5206\u5e03\u548c\u5141\u8bb8\u7684KL\u6563\u5ea6\u4e0b\u5b9e\u73b0\u4e86\u6700\u5c0f\u6700\u5927\u6700\u4f18\u5931\u771f\uff1b\u800cRLHF\u548cDPO\u5728\u65e0KL\u7ea6\u675f\u65f6\u5df2\u7ecf\u906d\u53d7\u8f83\u5927\u7684\u5931\u771f\uff0c\u5728\u5b8c\u6574\u8bbe\u7f6e\u4e0b\u5931\u771f\u53ef\u80fd\u66f4\u5927\u3002", "conclusion": "\u4e0d\u540c\u7684\u5bf9\u9f50\u65b9\u6cd5\u5728\u5904\u7406\u7528\u6237\u591a\u6837\u5316\u504f\u597d\u65f6\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0cNash Learning from Human Feedback\u8868\u73b0\u66f4\u4f18\uff0c\u5177\u6709\u8f83\u4f4e\u7684\u5931\u771f\u5ea6\u3002"}}
{"id": "2505.23760", "pdf": "https://arxiv.org/pdf/2505.23760", "abs": "https://arxiv.org/abs/2505.23760", "authors": ["Amber Yijia Zheng", "Cedar Site Bai", "Brian Bullins", "Raymond A. Yeh"], "title": "Model Immunization from a Condition Number Perspective", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Model immunization aims to pre-train models that are difficult to fine-tune\non harmful tasks while retaining their utility on other non-harmful tasks.\nThough prior work has shown empirical evidence for immunizing text-to-image\nmodels, the key understanding of when immunization is possible and a precise\ndefinition of an immunized model remain unclear. In this work, we propose a\nframework, based on the condition number of a Hessian matrix, to analyze model\nimmunization for linear models. Building on this framework, we design an\nalgorithm with regularization terms to control the resulting condition numbers\nafter pre-training. Empirical results on linear models and non-linear deep-nets\ndemonstrate the effectiveness of the proposed algorithm on model immunization.\nThe code is available at\nhttps://github.com/amberyzheng/model-immunization-cond-num.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHessian\u77e9\u9635\u6761\u4ef6\u6570\u7684\u6846\u67b6\u6765\u5206\u6790\u7ebf\u6027\u6a21\u578b\u7684\u6a21\u578b\u514d\u75ab\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5e26\u6709\u6b63\u5219\u5316\u9879\u7684\u7b97\u6cd5\u6765\u63a7\u5236\u9884\u8bad\u7ec3\u540e\u7684\u6761\u4ef6\u6570\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u6a21\u578b\u514d\u75ab\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u5c55\u793a\u4e86\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u514d\u75ab\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4f46\u5173\u4e8e\u6a21\u578b\u514d\u75ab\u7684\u53ef\u80fd\u6027\u548c\u514d\u75ab\u6a21\u578b\u7684\u7cbe\u786e\u5b9a\u4e49\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eHessian\u77e9\u9635\u6761\u4ef6\u6570\u7684\u6846\u67b6\u6765\u5206\u6790\u7ebf\u6027\u6a21\u578b\u7684\u6a21\u578b\u514d\u75ab\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u6b63\u5219\u5316\u9879\u7684\u7b97\u6cd5\uff0c\u7528\u4ee5\u63a7\u5236\u9884\u8bad\u7ec3\u540e\u4ea7\u751f\u7684\u6761\u4ef6\u6570\u3002", "result": "\u901a\u8fc7\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u6df1\u5ea6\u7f51\u7edc\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6a21\u578b\u514d\u75ab\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u6761\u4ef6\u6570\u7684\u6846\u67b6\u548c\u7b97\u6cd5\u4e3a\u7406\u89e3\u53ca\u5b9e\u73b0\u6a21\u578b\u514d\u75ab\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
