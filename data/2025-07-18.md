<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 63]
- [cs.AI](#cs.AI) [总数: 20]
- [cs.CR](#cs.CR) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu, Shizhe Diao, Jian Hu, Ximing Lu, Xin Dong, Hao Zhang, Alexander Bukharin, Shaokun Zhang, Jiaqi Zeng, Makesh Narsimhan Sreedhar, Gerald Shen, David Mosallanezhad, Di Zhang, Jonas Yang, June Yang, Oleksii Kuchaiev, Guilin Liu, Zhiding Yu, Pavlo Molchanov, Yejin Choi, Jan Kautz, Yi Dong*

**主要类别:** cs.LG

**AI概要:** 本文研究了长时间的强化学习对小型语言模型在多种推理任务上的影响，提出了几个有效的训练方法，并实现了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（如OpenAI的O1和DeepSeek-R1）在测试时通过链式思维推理和迭代探索扩大计算，可以大幅提高复杂任务（如数学和代码生成）的表现。这主要得益于大规模的强化学习，特别是与可验证的奖励信号结合使用时。为了探讨这种技术是否适用于小型语言模型，以及其长期效果如何，因此进行了这项研究。

**方法:** 研究人员采用了几种关键成分进行有效的训练：包括使用可验证奖励任务、改进Group Relative Policy Optimization (GRPO)、以及实际技术以提高训练稳定性和泛化能力。具体引入了受控KL正则化、剪辑比率和周期性参考策略重置等作为解锁长期性能增益的关键组件。

**结果:** 该模型在各种任务上都取得了显著的改进，超过了强大的基线模型，特别是在数学任务上提高了14.7%，编程任务上提高了13.9%，逻辑谜题任务上提高了54.8%。

**结论:** 本研究表明，在小型语言模型中，通过适当的训练方法和强化学习策略，可以在多个推理领域实现显著的性能提升。为促进进一步的研究，作者将他们的模型公开发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Up+RL%3A+Unlocking+Diverse+Reasoning+in+LLMs+via+Prolonged+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12507&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [2] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu, Konpat Preechakul, Kananart Kuwaranancharoen, Yutong Bai*

**主要类别:** cs.LG

**AI概要:** 论文指出当前机器学习的并行化趋势无法解决本质上是串行的问题，例如数学推理、物理模拟和顺序决策。这些任务需要依赖性计算步骤，不能被并行化。文章强调，随着AI处理更复杂的推理问题，有意扩展串行计算与并行计算同样重要。


<details>
  <summary>更多</summary>
  
**动机:** 作者观察到机器学习在大规模并行化方面取得了进展，但存在一个关键盲点：某些问题是根本上是顺序性的，即它们要求计算步骤之间具有依赖关系，无法进行并行化处理。

**方法:** 作者从复杂性理论出发，对串行和并行计算进行了正式区分，并展示了以并行为中心的现有架构在这种串行任务上的基本限制。

**结果:** 通过该研究，作者揭示了当前并行化为主的机器学习架构在处理本质上是串行的问题时面临的基本限制。

**结论:** 认识到计算的串行本质对于机器学习、模型设计和硬件开发有着深远的影响。为了实现持续的进步，特别是在处理复杂推理时，扩大串行计算规模是必不可少的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Serial+Scaling+Hypothesis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12549，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12549&send_immediately=true&force_search=false)

**原文摘要:** While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [3] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种新的机器思维框架，将心理意象整合到AI中以提高其自主思考和跨领域知识整合的能力。通过认知思维单元及三个辅助单元处理数据，表示为自然语言或草图，初步验证测试结果表明了该框架的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 现有模型在与人类互动时表现良好，但缺乏自主行动和独立推理的能力，并且通常需要明确的查询输入，无法充分利用已获得的感觉数据。此外，AI代理在跨领域知识整合方面也存在困难。

**方法:** 作者提出了一个机器思维框架，其中包含一个由三个辅助单元支持的认知思维单元：输入数据单元、需求单元和心理意象单元。在这个框架中，数据被表示为自然语言句子或绘制的草图。

**结果:** 该框架已经进行了验证测试，结果显示了将心理意象集成到机器思维中的潜在好处，以及在启动思维过程方面的有效性。

**结论:** 这种新的机器思维框架可能会显著增强AI系统自主思考和跨领域知识整合的能力，未来的工作可能集中于进一步发展和完善这个框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Mental+Imagery+Improve+the+Thinking+Capabilities+of+AI+Systems%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12555，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12555&send_immediately=true&force_search=false)

**原文摘要:** Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [4] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza, Paulo R. Lisboa de Almeida, Alceu de Souza Britto Jr., Robert Sabourin, Rafael M. O. Cruz*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的数据流分类框架IncA-DES，该框架通过生成局部专家、融合概念漂移检测器和使用基于重叠的分类过滤器来应对概念漂移问题。实验结果表明，该框架在不同标签可用性水平下比七种最先进方法具有更高的平均准确率和更短的处理时间。


<details>
  <summary>更多</summary>
  
**动机:** 数据流中的概念漂移给机器学习带来了挑战，现有的基于邻域搜索的数据流方法在处理连续到达的数据时可能变得难以承受。因此，需要一种能够适应概念漂移的新方法。

**方法:** 作者提出了IncA-DES框架，它采用了一种训练策略，以促进局部专家的生成，并融合了一个概念漂移检测器来支持信息维护和适应新概念。此外，还引入了基于重叠的分类过滤器和在线K-d树算法。

**结果:** 实验结果表明，IncA-DES框架在不同标签可用性水平下比七种最先进方法具有更高的平均准确率，并且在最准确的方法中处理时间最短。与在线K-d树的结合也提高了处理速度，同时几乎不影响准确性。

**结论:** 所提出的IncA-DES框架有效地解决了数据流中的概念漂移问题，在准确性和处理时间上都表现优异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是IncA-DES%3A+An+incremental+and+adaptive+dynamic+ensemble+selection+approach+using+online+K-d+tree+neighborhood+search+for+data+streams+with+concept+drift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12573，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12573&send_immediately=true&force_search=false)

**原文摘要:** Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [5] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng, Spencer S. Ericksen, Anthony Gitter*

**主要类别:** cs.LG

**AI概要:** 论文介绍了一种新的工作流Assay2Mol，它能利用大型语言模型从现有的生物化学筛选分析中为早期药物发现提供支持。


<details>
  <summary>更多</summary>
  
**动机:** 在生物化学领域，分子筛选试验可以评估候选分子对疾病靶点的功能反应。然而，描述这些靶点的生物学机制、实验筛选协议和其他属性的非结构化文本信息由于其非结构化的格式而未被充分利用。

**方法:** 该方法通过检索涉及与新目标相似的目标的现有分析记录，并使用上下文学习生成候选分子。

**结果:** Assay2Mol的表现超过了最近生成候选配体分子以针对蛋白质结构的目标机器学习方法，同时促进了更易合成的分子生成。

**结论:** 这表明Assay2Mol可以更好地利用现存的大量生化筛选数据进行新药研发。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Assay2Mol%3A+large+language+model-based+drug+design+using+BioAssay+context，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12574，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12574&send_immediately=true&force_search=false)

**原文摘要:** Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [6] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi, Ali Eshragh, Babak Aslani, Meysam Rabiee*

**主要类别:** cs.LG

**AI概要:** 本文研究了聚类排序向量的问题，特别是k-centroids排名向量聚类问题（KRC）。为了解决KRC的计算挑战，开发了一种高效的近似算法KRCA，并引入分支定界算法以提高效率。通过实验证明KRCA在解的质量和计算时间上都有显著改进。


<details>
  <summary>更多</summary>
  
**动机:** 动机在于解决排序向量聚类问题，尤其是当观测值和质心都被限制为排名向量时的情况，这与传统的k-means聚类不同。

**方法:** 提出了一种称为KRCA的高效近似算法，该算法迭代地改进来自KMC的初始解，并引入分支定界算法以在KRCA中进行有效的簇重建。

**结果:** 通过广泛的数值实验表明，KRCA在解的质量上有显著提升，并且具有快速的计算时间。

**结论:** 这项工作强调了KRC对于个性化和大规模决策的实际意义，并提供了方法论上的进步和见解，可以为未来的研究提供基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ranking+Vectors+Clustering%3A+Theory+and+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12583&send_immediately=true&force_search=false)

**原文摘要:** We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [7] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li, Kwang-Sung Jun*

**主要类别:** cs.LG

**AI概要:** 本文研究了[0,1]区间回归问题，证明了log损失最小化器可以实现一阶边界，并提出了一种新的称为投注损失的损失函数，实现了无需显式建模标签方差或分布即可达到的方差依赖边界。


<details>
  <summary>更多</summary>
  
**动机:** 作者受到cost-sensitive classification中log损失最小化器能够实现改进泛化界这一结果的启发，想要探究在[0,1]区间回归问题中是否也存在类似的改进以及是否存在可以实现更严格改进（即二阶改进）的损失函数。

**方法:** 首先证明了log损失最小化器在[0,1]区间回归问题中也可以实现一阶边界。然后，提出了一个名为投注损失的新损失函数，以实现方差依赖边界。

**结果:** 成功证明了log损失最小化器在一特定类型的回归问题中能实现一阶边界，并通过提出的投注损失函数实现了方差依赖边界，此方法不需要任何关于方差的知识。

**结论:** 对于[0,1]区间回归问题，log损失最小化器可以实现一阶边界。此外，新提出的投注损失函数可以实现方差依赖边界，且该方法是自适应于方差的，不需要对标签方差或分布进行显式建模。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Second-Order+Bounds+for+%5B0%2C1%5D-Valued+Regression+via+Betting+Loss，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12584，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12584&send_immediately=true&force_search=false)

**原文摘要:** We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [8] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko, Katarzyna Woźnica*

**主要类别:** cs.LG

**AI概要:** 本文提出了两种新的表格表示学习方法，旨在特定的元任务——贝叶斯超参数优化的热启动中进行定制。实验表明，虽然所提出的编码器可以有效地学习与landmarkers对齐的表示，但它们可能不会直接转化为HPO热启动元任务中的显著性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 有效表示异构表格数据集以用于元学习仍然是一个开放的问题。以前的方法依赖于旨在通用的表示。

**方法:** 提出的第一种方法涉及深度度量学习，而第二种方法基于landmarkers重建。

**结果:** 实验表明，虽然所提出的编码器可以有效地学习与landmarkers对齐的表示，但它们可能不会直接转化为HPO热启动元任务中的显著性能提升。

**结论:** 尽管新方法在学习与landmarkers对齐的表示方面表现出色，但在实际应用到HPO热启动元任务时，可能需要进一步研究以实现性能上的显著提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Are+encoders+able+to+learn+landmarkers+for+warm-starting+of+Hyperparameter+Optimization%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12604，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12604&send_immediately=true&force_search=false)

**原文摘要:** Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>


### [9] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
*Prateek Chanda, Saral Sureka, Parth Pratim Chatterjee, Krishnateja Killamsetty, Nikhil Shivakumar Nayak, Ganesh Ramakrishnan*

**主要类别:** cs.LG

**AI概要:** 论文介绍了一种名为TASKPGM的框架，用于优化大型语言模型微调时的任务数据集组合。通过最小化马尔可夫随机场上的能量函数选择连续的任务比例，该方法在理论和实证上均表现出优越性，并能提供关于任务影响和组合构成的可解释性见解。


<details>
  <summary>更多</summary>
  
**动机:** 当前选择最优任务数据集组合的方法主要依赖于人工和经验法则，缺乏系统性和可扩展性。

**方法:** 引入了TASKPGM框架，利用马尔可夫随机场的能量函数最小化来选择任务的比例，同时使用行为差异如Jensen Shannon Divergence和Pointwise Mutual Information来建模任务关系。

**结果:** 该方法在Llama 2和Mistral模型上进行了验证，在MMLU和BIGBench评估套件中表现出了持续的经验改进。

**结论:** TASKPGM不仅提高了大型语言模型微调的性能，还提供了关于任务影响和混合组成的可解释性见解，成为高效且稳健的LLM微调工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+What+Matters%3A+Probabilistic+Task+Selection+via+Mutual+Information+for+Model+Finetuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12612，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12612&send_immediately=true&force_search=false)

**原文摘要:** The performance of finetuned large language models (LLMs) hinges critically
on the composition of the training mixture. However, selecting an optimal blend
of task datasets remains a largely manual, heuristic driven process, with
practitioners often relying on uniform or size based sampling strategies. We
introduce TASKPGM, a principled and scalable framework for mixture optimization
that selects continuous task proportions by minimizing an energy function over
a Markov Random Field (MRF). Task relationships are modeled using behavioral
divergences such as Jensen Shannon Divergence and Pointwise Mutual Information
computed from the predictive distributions of single task finetuned models. Our
method yields a closed form solution under simplex constraints and provably
balances representativeness and diversity among tasks. We provide theoretical
guarantees, including weak submodularity for budgeted variants, and demonstrate
consistent empirical improvements on Llama 2 and Mistral across evaluation
suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers
interpretable insights into task influence and mixture composition, making it a
powerful tool for efficient and robust LLM finetuning.

</details>


### [10] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
*Rui Li, Xiaoyun Zhi, Jinxin Chi, Menghan Yu, Lixin Huang, Jia Zhu, Weilun Zhang, Xing Ma, Wenjia Liu, Zhicheng Zhu, Daowen Luo, Zuquan Song, Xin Yin, Chao Xiang, Shuguang Wang, Wencong Xiao, Gene Cooperman*

**主要类别:** cs.LG

**AI概要:** 本文介绍了大型语言模型（LLMs）训练启动开销的首次深入分析，并提出了一个系统级优化框架Bootseer，该框架通过三种技术减少启动开销50%。


<details>
  <summary>更多</summary>
  
**动机:** 由于在大规模工业级LLMs中，失败更频繁且多个团队进行迭代更新-调试周期，因此需要关注和改善启动开销的问题。

**方法:** 作者分析了启动成本的组成部分，量化其直接影响，并检查其如何随工作规模扩展。基于这些见解，设计了Bootseer框架，以解决三个主要启动瓶颈：容器镜像加载、运行时依赖安装和模型检查点恢复。

**结果:** Bootseer已经在生产环境中部署并评估，结果表明它能够将启动开销减少50%。

**结论:** 通过对LLM训练启动开销的深入研究，可以显著提高训练效率，降低资源浪费。Bootseer为这一问题提供了有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BootSeer%3A+Analyzing+and+Mitigating+Initialization+Bottlenecks+in+Large-Scale+LLM+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12619&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have become a cornerstone of modern AI, driving
breakthroughs in natural language processing and expanding into multimodal jobs
involving images, audio, and video. As with most computational software, it is
important to distinguish between ordinary runtime performance and startup
overhead. Prior research has focused on runtime performance: improving training
efficiency and stability. This work focuses instead on the increasingly
critical issue of startup overhead in training: the delay before training jobs
begin execution. Startup overhead is particularly important in large,
industrial-scale LLMs, where failures occur more frequently and multiple teams
operate in iterative update-debug cycles. In one of our training clusters, more
than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training
startup overhead based on real production data. We analyze the components of
startup cost, quantify its direct impact, and examine how it scales with job
size. These insights motivate the design of Bootseer, a system-level
optimization framework that addresses three primary startup bottlenecks: (a)
container image loading, (b) runtime dependency installation, and (c) model
checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three
techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and
(c) striped HDFS-FUSE. Bootseer has been deployed in a production environment
and evaluated on real LLM training workloads, demonstrating a 50% reduction in
startup overhead.

</details>


### [11] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
*Jake Ward, Chuqiao Lin, Constantin Venhoff, Neel Nanda*

**主要类别:** cs.LG

**AI概要:** 本研究发现，在DeepSeek-R1-Distill-Llama-8B中，回溯行为部分由基础模型激活中已存在的方向驱动。这种回溯在推理微调模型中显现，但在基础模型中不显现，表明推理微调过程重新利用了预先存在的表示来形成新的行为电路。


<details>
  <summary>更多</summary>
  
**动机:** 理解推理模型中回溯行为的出现机制，特别是这种行为如何通过基础模型的激活中的已有方向被驱动。

**方法:** 研究人员识别了Llama-3.1-8B残差流中的一个方向，该方向系统地诱导了蒸馏推理模型中的回溯行为，并研究了使用这个方向进行转向的效果是否能简单地用令牌级属性解释。还探讨了该方向在基础模型中是否也能引起回溯。

**结果:** 研究发现，当用于引导蒸馏推理模型时，基础Llama-3.1-8B的残差流中的特定方向系统地引起了回溯，但其效果不能仅用令牌级别的属性来解释。此外，此方向不会在基础模型中引发回溯，这表明推理微调过程重新利用了预先存在的表示形式以形成新的行为电路。

**结论:** 研究结果提供了一个有说服力的观点，即推理微调模型不是从头学习新的能力，而是重新利用预先存在的基础模型表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning-Finetuning+Repurposes+Latent+Representations+in+Base+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12638，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12638&send_immediately=true&force_search=false)

**原文摘要:** Backtracking, an emergent behavior elicited by reasoning fine-tuning, has
been shown to be a key mechanism in reasoning models' enhanced capabilities.
Prior work has succeeded in manipulating this behavior via steering vectors,
but the underlying mechanism remains poorly understood. In this work, we show
that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part
driven by a repurposed direction already present in base model activations.
Specifically, we identify a direction in base Llama-3.1-8B's residual stream
which systematically induces backtracking when used to steer the distilled
reasoning model, and find that the effects of steering with this direction
cannot be trivially explained by token-level attributes. We further find that
this direction does not induce backtracking in the base model, suggesting that
the reasoning finetuning process repurposes pre-existing representations to
form new behavioral circuits. Additionally, we hypothesize that this direction
is one of several which may work together to mediate backtracking. Our findings
offer a compelling picture that reasoning-finetuned models repurpose
pre-existing base model representations, rather than learn new capabilities
from scratch.

</details>


### [12] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
*Kai Malcolm, César Uribe, Momona Yamagami*

**主要类别:** cs.LG

**AI概要:** 本研究探索了联合学习（FL）在神经解码中的应用，特别是在保护隐私方面。研究表明，在开放环路模拟中，FL的表现优于本地学习基线；但在闭合环路用户研究中，适应单用户实时交互的修改导致本地学习解码器性能超过FL方法。


<details>
  <summary>更多</summary>
  
**动机:** 神经信号本质上编码了关于个人身份和健康敏感信息，使得数据共享成为关键的隐私挑战。为了应对这一挑战，研究人员引入了联合学习（Federated Learning, FL），这是一种分布式的、保护隐私的学习框架，并将其应用于神经解码领域。

**方法:** 研究人员使用高维肌电图信号评估了FL在开放环路和闭合环路场景下的表现，并与本地学习方法进行了对比。对于闭合环路场景，研究人员对FL方法进行了适应性调整以支持单用户、实时互动。

**结果:** 在开放环路模拟中，FL显著优于本地学习基线；然而，在闭合环路用户研究中，经过适应性调整后的FL方法性能不及本地学习解码器，尽管后者存在更高的隐私风险。

**结论:** 本研究揭示了在实时自适应应用中，性能与隐私之间存在关键权衡，并指出需要为共适应、单用户应用设计专门的FL方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Federated+Learning+in+Open-+and+Closed-Loop+EMG+Decoding%3A+A+Privacy+and+Performance+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12652，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12652&send_immediately=true&force_search=false)

**原文摘要:** Invasive and non-invasive neural interfaces hold promise as high-bandwidth
input devices for next-generation technologies. However, neural signals
inherently encode sensitive information about an individual's identity and
health, making data sharing for decoder training a critical privacy challenge.
Federated learning (FL), a distributed, privacy-preserving learning framework,
presents a promising solution, but it remains unexplored in closed-loop
adaptive neural interfaces. Here, we introduce FL-based neural decoding and
systematically evaluate its performance and privacy using high-dimensional
electromyography signals in both open- and closed-loop scenarios. In open-loop
simulations, FL significantly outperformed local learning baselines,
demonstrating its potential for high-performance, privacy-conscious neural
decoding. In contrast, closed-loop user studies required adapting FL methods to
accommodate single-user, real-time interactions, a scenario not supported by
standard FL. This modification resulted in local learning decoders surpassing
the adapted FL approach in closed-loop performance, yet local learning still
carried higher privacy risks. Our findings highlight a critical
performance-privacy tradeoff in real-time adaptive applications and indicate
the need for FL methods specifically designed for co-adaptive, single-user
applications.

</details>


### [13] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
*Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种迁移学习方法和自适应激活函数来提高物理信息神经网络（PINNs）的外推能力，通过一系列实验验证了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管PINNs在结合物理原理与数据驱动建模方面表现出色，但它们在外推训练域之外的表现不佳，并且对激活函数的选择非常敏感。因此，需要一种改进的方法以增强其外推能力和模型稳健性。

**方法:** 作者引入了迁移学习（TL）方法，在扩展的训练域中使用少量精心挑选的配置点进行训练。此外，还提出了自适应激活函数，它是一些标准激活函数的线性组合。

**结果:** 该方法实现了平均40%的相对L2误差减少和平均50%的绝对误差减少，同时没有显著增加计算成本。

**结论:** 所提出的方法可以有效地提高PINNs的外推性能，而无需大幅增加计算成本。代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+physics-informed+neural+network+extrapolation+via+transfer+learning+and+adaptive+activation+functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12659，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12659&send_immediately=true&force_search=false)

**原文摘要:** Physics-Informed Neural Networks (PINNs) are deep learning models that
incorporate the governing physical laws of a system into the learning process,
making them well-suited for solving complex scientific and engineering
problems. Recently, PINNs have gained widespread attention as a powerful
framework for combining physical principles with data-driven modeling to
improve prediction accuracy. Despite their successes, however, PINNs often
exhibit poor extrapolation performance outside the training domain and are
highly sensitive to the choice of activation functions (AFs). In this paper, we
introduce a transfer learning (TL) method to improve the extrapolation
capability of PINNs. Our approach applies transfer learning (TL) within an
extended training domain, using only a small number of carefully selected
collocation points. Additionally, we propose an adaptive AF that takes the form
of a linear combination of standard AFs, which improves both the robustness and
accuracy of the model. Through a series of experiments, we demonstrate that our
method achieves an average of 40% reduction in relative L2 error and an average
of 50% reduction in mean absolute error in the extrapolation domain, all
without a significant increase in computational cost. The code is available at
https://github.com/LiuzLab/PINN-extrapolation .

</details>


### [14] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
*Sangbong Yoo, Jaeyoung Lee, Chanyoung Yoon, Geonyeong Son, Hyein Hong, Seongbum Seo, Soobin Yim, Chanyoung Jung, Jungsoo Park, Misuk Kim, Yun Jang*

**主要类别:** cs.LG

**AI概要:** 本文调查了数据异质性问题及其来源，并对解决由数据格式差异引起的异质性的策略进行了分类和介绍，强调了数据转换在AI数据准备中的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法主要解决与数据结构和模式相关的冲突，而忽略了数据转换的关键作用。随着人工智能的广泛应用，需要更简化数据准备过程，因此有必要全面审查现代数据转换方法。

**方法:** 该研究通过调查文献，系统地分类和展示了应对数据格式差异引起的数据异质性的策略。

**结果:** 强调了数据转换在定制训练数据和适应不同AI模型输入格式方面的重要性，并揭示了每种策略所面临的内在挑战。

**结论:** 尽管目前的方法已经能够处理一些数据异质性的问题，但针对数据格式差异的有效解决方案仍然有限，需要进一步研究和发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Transformation+Strategies+to+Remove+Heterogeneity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12677，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12677&send_immediately=true&force_search=false)

**原文摘要:** Data heterogeneity is a prevalent issue, stemming from various conflicting
factors, making its utilization complex. This uncertainty, particularly
resulting from disparities in data formats, frequently necessitates the
involvement of experts to find resolutions. Current methodologies primarily
address conflicts related to data structures and schemas, often overlooking the
pivotal role played by data transformation. As the utilization of artificial
intelligence (AI) continues to expand, there is a growing demand for a more
streamlined data preparation process, and data transformation becomes
paramount. It customizes training data to enhance AI learning efficiency and
adapts input formats to suit diverse AI models. Selecting an appropriate
transformation technique is paramount in preserving crucial data details.
Despite the widespread integration of AI across various industries,
comprehensive reviews concerning contemporary data transformation approaches
are scarce. This survey explores the intricacies of data heterogeneity and its
underlying sources. It systematically categorizes and presents strategies to
address heterogeneity stemming from differences in data formats, shedding light
on the inherent challenges associated with each strategy.

</details>


### [15] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, Yi-Ping Hsu, Jiajing Xu, Charles Rosenberg*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种基础模型PinFM，用于理解数十亿规模的视觉发现平台上用户活动序列。通过预训练和微调的方法，并引入创新技术如去重交叉注意力变换器（DCAT），显著提升了处理效率和新项目的参与度。


<details>
  <summary>更多</summary>
  
**动机:** 在推荐系统中，用户活动序列已成为最重要的信号之一。然而，在工业级推荐系统中应用预训练-微调方法面临诸多挑战，例如需要满足严格的成本和延迟约束、捕捉用户活动与其他特征之间的交互作用等。

**方法:** 作者使用了包含20B+参数的Transformer模型进行预训练，并针对特定应用程序进行了微调。同时，开发了诸如Deduplicated Cross-Attention Transformer (DCAT)等创新技术以解决实际应用中的挑战。

**结果:** 与Pinterest内部数据相比，他们的基础设施和算法优化使吞吐量提高了600%，并且通过改变输入序列，使得用户对新项目的参与度提高了20%。

**结论:** PinFM已经部署并正在帮助改善超过五亿用户在各种应用程序上的体验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PinFM%3A+Foundation+Model+for+User+Activity+Sequences+at+a+Billion-scale+Visual+Discovery+Platform，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12704，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12704&send_immediately=true&force_search=false)

**原文摘要:** User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [16] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
*Brian Richard Olsen, Sam Fatehmanesh, Frank Xiao, Adarsh Kumarappan, Anirudh Gajula*

**主要类别:** cs.LG

**AI概要:** 本文通过发展连续时间矩阵值随机微分方程框架，首次理论解释了训练网络中'主体+尾部'的奇异值谱结构，并通过实验证明了其理论预测。


<details>
  <summary>更多</summary>
  
**动机:** 尽管深度神经网络在机器学习领域带来了革新，但其训练动态仍缺乏理论上的清晰解释。作者希望连接微观SGD动态和宏观权重矩阵奇异值谱的演变。

**方法:** 作者发展了一个连续时间矩阵值随机微分方程(SDE)框架，推导出精确的SDEs表明平方奇异值遵循具有特征值排斥的Dyson布朗运动，并将平稳分布描述为具有幂律尾的伽马型密度。

**结果:** 作者通过控制实验验证了他们的理论预测，展示了基于SDE的预测和观察到的光谱演变之间的定量一致性。

**结论:** 该研究提供了一个严谨的基础来理解为什么深度学习有效，并首次提供了对训练网络中观察到的'主体+尾部'光谱结构的理论解释。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+SGD+to+Spectra%3A+A+Theory+of+Neural+Network+Weight+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12709，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12709&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks have revolutionized machine learning, yet their training
dynamics remain theoretically unclear-we develop a continuous-time,
matrix-valued stochastic differential equation (SDE) framework that rigorously
connects the microscopic dynamics of SGD to the macroscopic evolution of
singular-value spectra in weight matrices. We derive exact SDEs showing that
squared singular values follow Dyson Brownian motion with eigenvalue repulsion,
and characterize stationary distributions as gamma-type densities with
power-law tails, providing the first theoretical explanation for the
empirically observed 'bulk+tail' spectral structure in trained networks.
Through controlled experiments on transformer and MLP architectures, we
validate our theoretical predictions and demonstrate quantitative agreement
between SDE-based forecasts and observed spectral evolution, providing a
rigorous foundation for understanding why deep learning works.

</details>


### [17] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
*Suorong Yang, Peijia Li, Yujie Liu, Zhiming Xu, Peng Ye, Wanli Ouyang, Furao Shen, Dongzhan Zhou*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种动态数据集修剪框架，通过任务驱动的难度和跨模态语义一致性自适应选择训练样本，以提高训练效率和模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数据集修剪方法大多依赖于静态启发式或特定任务的度量标准，在不同领域的鲁棒性和泛化能力有限。

**方法:** 引入了一个动态的数据集修剪框架，该框架根据任务驱动的难度和跨模态语义一致性自适应地选择训练样本，并利用预训练的多模态基础模型的监督来捕捉训练动态，同时有效地过滤掉无信息的样本。

**结果:** 强调了将跨模态对齐整合到稳健样本选择中的潜力，推进了面向数据的学习向更高效和稳健实践的发展。

**结论:** 此框架展示了在改进训练效率和模型性能方面的潜力，为不同应用领域提供了更有效和稳健的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multimodal-Guided+Dynamic+Dataset+Pruning+for+Robust+and+Efficient+Data-Centric+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12750，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12750&send_immediately=true&force_search=false)

**原文摘要:** Modern deep models are trained on large real-world datasets, where data
quality varies and redundancy is common. Data-centric approaches such as
dataset pruning have shown promise in improving training efficiency and model
performance. However, most existing methods rely on static heuristics or
task-specific metrics, limiting their robustness and generalizability across
domains. In this work, we introduce a dynamic dataset pruning framework that
adaptively selects training samples based on both task-driven difficulty and
cross-modality semantic consistency. By incorporating supervision from
pretrained multimodal foundation models, our approach captures training
dynamics while effectively filtering out uninformative samples. Our work
highlights the potential of integrating cross-modality alignment for robust
sample selection, advancing data-centric learning toward more efficient and
robust practices across application domains.

</details>


### [18] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
*Yaru Liu, Yiqi Gu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的优化框架——层分离（LySep）模型，以改善基于深度学习的方法在求解偏微分方程中的表现。通过引入辅助变量将深度神经网络的层分离，并建立新的损失函数，从而避免了现有算法收敛到次优局部最小值或梯度爆炸/消失的问题。实验结果表明，LySep模型在减少损失和降低解误差方面具有优势。


<details>
  <summary>更多</summary>
  
**动机:** 由于深度学习损失函数的高度非凸性，现有的优化算法常常会收敛到次优的局部最小值或遭遇梯度爆炸或消失的问题，导致性能不佳。为了解决这些问题，提出了LySep模型。

**方法:** 作者引入辅助变量来分离深度神经网络的层，具体来说是用辅助变量表示每一层的输出及其导数，从而有效地将深度架构分解成一系列浅层架构。然后建立了带有辅助变量的新损失函数，并开发了基于交替方向的相应算法。

**结果:** 高维数值结果显示了LySep模型与原深度模型之间的一致性，并证明了LySep模型在最小化损失和减少解误差方面的优势。

**结论:** LySep模型提供了一种有效的改进方法，能够提升深度学习在求解偏微分方程上的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Layer+Separation+Deep+Learning+Model+with+Auxiliary+Variables+for+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12766，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12766&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose a new optimization framework, the layer separation
(LySep) model, to improve the deep learning-based methods in solving partial
differential equations. Due to the highly non-convex nature of the loss
function in deep learning, existing optimization algorithms often converge to
suboptimal local minima or suffer from gradient explosion or vanishing,
resulting in poor performance. To address these issues, we introduce auxiliary
variables to separate the layers of deep neural networks. Specifically, the
output and its derivatives of each layer are represented by auxiliary
variables, effectively decomposing the deep architecture into a series of
shallow architectures. New loss functions with auxiliary variables are
established, in which only variables from two neighboring layers are coupled.
Corresponding algorithms based on alternating directions are developed, where
many variables can be updated optimally in closed forms. Moreover, we provide
theoretical analyses demonstrating the consistency between the LySep model and
the original deep model. High-dimensional numerical results validate our theory
and demonstrate the advantages of LySep in minimizing loss and reducing
solution error.

</details>


### [19] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren, Jingxi Zhu, Zehao Liu, Tianxiang Zhao, Vasant Honavar*

**主要类别:** cs.LG

**AI概要:** 这篇论文综述了深度学习、大语言模型和电子健康记录（EHR）建模的最新进展，提出了一个涵盖五个关键设计维度的统一分类法，并强调了如基础模型等新兴趋势，以及基准测试、可解释性等方面的开放挑战。


<details>
  <summary>更多</summary>
  
**动机:** 电子健康记录（EHR）数据的异质性、时间不规则性和领域特定性质带来了独特的挑战，这些挑战与视觉和自然语言任务中的挑战根本不同。因此，需要对深度学习、大语言模型（LLMs）和EHR建模的交叉点上的最新进展进行综合概述，以应对这些挑战并推进AI在医疗保健领域的应用。

**方法:** 作者引入了一个统一的分类法，该分类法跨越了五个关键设计维度：以数据为中心的方法、神经架构设计、以学习为重点的策略、多模态学习和基于LLM的建模系统。在每个维度中，作者回顾了代表性方法，包括提高数据质量、结构和时间表示、自我监督学习以及与临床知识的整合。

**结果:** 通过这种方法，作者不仅总结了当前的最新研究进展，还指出了未来的研究方向，如基础模型、由LLM驱动的临床代理和用于下游推理的EHR到文本的翻译。

**结论:** 该调查为推进以AI为驱动的EHR建模和临床决策支持提供了一个结构化的路线图，同时讨论了在基准测试、可解释性、临床一致性和跨不同临床环境的泛化方面的开放挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comprehensive+Survey+of+Electronic+Health+Record+Modeling%3A+From+Deep+Learning+Approaches+to+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12774，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12774&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [20] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
*Jianyu Zhu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种多通道深度学习框架，用于全面预测中小企业财务风险，并通过实验验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 由于规模有限和财务韧性不足，许多新三板上市企业面临较高的财务困境风险。

**方法:** 设计了一个三通道图同构网络（GIN），分别处理数值、文本和基于图的输入，并使用基于注意力的机制和门控单元进行融合，以提高稳健性和预测准确性。

**结果:** 实验证明，在AUC、精确度、召回率和F1分数方面，该模型显著优于传统机器学习方法和单模态基线。

**结论:** 这项工作为中小企业的风险建模提供了理论和实践的见解，并提供了一种数据驱动的工具来支持金融监管者和投资者。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Channel+Graph+Neural+Network+for+Financial+Risk+Prediction+of+NEEQ+Enterprises，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12787&send_immediately=true&force_search=false)

**原文摘要:** With the continuous evolution of China's multi-level capital market, the
National Equities Exchange and Quotations (NEEQ), also known as the "New Third
Board," has become a critical financing platform for small and medium-sized
enterprises (SMEs). However, due to their limited scale and financial
resilience, many NEEQ-listed companies face elevated risks of financial
distress. To address this issue, we propose a multi-channel deep learning
framework that integrates structured financial indicators, textual disclosures,
and enterprise relationship data for comprehensive financial risk prediction.
Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that
processes numeric, textual, and graph-based inputs separately. These
modality-specific representations are fused using an attention-based mechanism
followed by a gating unit to enhance robustness and prediction accuracy.
Experimental results on data from 7,731 real-world NEEQ companies demonstrate
that our model significantly outperforms traditional machine learning methods
and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.
This work provides theoretical and practical insights into risk modeling for
SMEs and offers a data-driven tool to support financial regulators and
investors.

</details>


### [21] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
*Qianru Zhang, Chenglei Yu, Haixin Wang, Yudong Yan, Yuansheng Cao, Siu-Ming Yiu, Tailin Wu, Hongzhi Yin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架FLDmamba，结合傅里叶变换和拉普拉斯变换来捕捉时间序列数据中的多尺度周期性和瞬态动力学，并提高了对数据噪声的鲁棒性。实验表明，该方法在时间序列预测基准上优于基于Transformer和其他Mamba架构的方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列预测方法，特别是基于Transformer的架构，在处理长期预测时由于序列长度的二次复杂度而效率低下；同时，最近的状态空间模型如Mamba虽然提供了更有效的长期建模选择，但无法有效捕捉多尺度周期性和瞬态动力学，并且容易受到时间序列数据噪声的影响。

**方法:** 提出了FLDmamba（傅里叶和拉普拉斯变换分解Mamba）框架，利用傅里叶变换和拉普拉斯变换的优点来捕捉时间序列数据中的多尺度周期性和瞬态动力学，并改善模型对数据噪声的鲁棒性。

**结果:** 广泛的实验证明了FLDmamba在时间序列预测基准上的优越性能，超越了基于Transformer和其他Mamba架构的方法。

**结论:** FLDmamba为时间序列预测提供了一个更有效、更鲁棒的解决方案，特别是在处理长序列预测和存在噪声的数据方面。为了促进方法的可重复性，研究团队已经公开了代码和数据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FLDmamba%3A+Integrating+Fourier+and+Laplace+Transform+Decomposition+with+Mamba+for+Enhanced+Time+Series+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12803，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12803&send_immediately=true&force_search=false)

**原文摘要:** Time series prediction, a crucial task across various domains, faces
significant challenges due to the inherent complexities of time series data,
including non-stationarity, multi-scale periodicity, and transient dynamics,
particularly when tackling long-term predictions. While Transformer-based
architectures have shown promise, their quadratic complexity with sequence
length hinders their efficiency for long-term predictions. Recent advancements
in State-Space Models, such as Mamba, offer a more efficient alternative for
long-term modeling, but they cannot capture multi-scale periodicity and
transient dynamics effectively. Meanwhile, they are susceptible to data noise
issues in time series. This paper proposes a novel framework, FLDmamba (Fourier
and Laplace Transform Decomposition Mamba), addressing these limitations.
FLDmamba leverages the strengths of both Fourier and Laplace transforms to
effectively capture both multi-scale periodicity, transient dynamics within
time series data, and improve the robustness of the model to the data noise
issue. Our extensive experiments demonstrate that FLDmamba achieves superior
performance on time series prediction benchmarks, outperforming both
Transformer-based and other Mamba-based architectures. To promote the
reproducibility of our method, we have made both the code and data accessible
via the following
URL:{\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\model}.

</details>


### [22] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun, Yanfeng Ding, Liping Yi, Huidong Ma, Gang Wang, Xiaoguang Liu, Cheng Zhong, Wentong Cai*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的并行多知识学习型压缩器PMKLC，通过四个关键设计提高了基因组数据的压缩比、吞吐量和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于学习的无损压缩器在压缩比、吞吐量和压缩鲁棒性方面存在不足，限制了其广泛应用。

**方法:** 1) 提出自动化多知识学习型压缩框架；2) 设计GPU加速的(s,k)-mer编码器；3) 引入数据块划分和逐步模型传递机制；4) 设计两种压缩模式PMKLC-S和PMKLC-M。

**结果:** 与基线方法相比，PMKLC-S/M平均压缩比提高73.609%和73.480%，平均吞吐量提高3.036倍和10.710倍，同时表现出最佳的鲁棒性和竞争力的内存成本。

**结论:** PMKLC-S/M具有更好的稳定性，能够应对不同概率分布扰动的数据集，并且能够在内存受限的设备上运行。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PMKLC%3A+Parallel+Multi-Knowledge+Learning-based+Lossless+Compression+for+Large-Scale+Genomics+Database，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12805，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12805&send_immediately=true&force_search=false)

**原文摘要:** Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [23] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
*Sven Dummer, Dongwei Ye, Christoph Brune*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种结合降阶建模和算子学习的新框架RONOM，提出了离散化误差界限，并展示了其在不同分辨率下的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 时间依赖的偏微分方程在物理建模中应用广泛，但在多查询场景下计算成本高昂。降阶模型（ROM）虽然能够构造低维替代模型，但受限于固定的离散化；而神经算子学习则缺乏对无限维与离散算子之间误差的量化。

**方法:** 作者引入了降阶神经算子建模（RONOM）框架，将ROM和算子学习的概念结合起来。建立了类似于ROM中的离散化误差界限，研究了RONOM的离散化收敛性和离散化鲁棒性。

**结果:** 两个数值例子表明，使用标准向量到向量神经网络的RONOM在输入泛化方面表现相当，在空间超分辨率和离散化鲁棒性方面表现出色，并为时间超分辨率情景提供了新的见解。

**结论:** RONOM框架融合了ROM和神经算子学习的优点，既提供了严格的数值误差估计，又能在不同分辨率的数据上自适应，展现了良好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RONOM%3A+Reduced-Order+Neural+Operator+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12814，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12814&send_immediately=true&force_search=false)

**原文摘要:** Time-dependent partial differential equations are ubiquitous in physics-based
modeling, but they remain computationally intensive in many-query scenarios,
such as real-time forecasting, optimal control, and uncertainty quantification.
Reduced-order modeling (ROM) addresses these challenges by constructing a
low-dimensional surrogate model but relies on a fixed discretization, which
limits flexibility across varying meshes during evaluation. Operator learning
approaches, such as neural operators, offer an alternative by parameterizing
mappings between infinite-dimensional function spaces, enabling adaptation to
data across different resolutions. Whereas ROM provides rigorous numerical
error estimates, neural operator learning largely focuses on discretization
convergence and invariance without quantifying the error between the
infinite-dimensional and the discretized operators. This work introduces the
reduced-order neural operator modeling (RONOM) framework, which bridges
concepts from ROM and operator learning. We establish a discretization error
bound analogous to those in ROM, and get insights into RONOM's discretization
convergence and discretization robustness. Moreover, two numerical examples are
presented that compare RONOM to existing neural operators for solving partial
differential equations. The results demonstrate that RONOM using standard
vector-to-vector neural networks achieves comparable performance in input
generalization and superior performance in both spatial super-resolution and
discretization robustness, while also offering novel insights into temporal
super-resolution scenarios.

</details>


### [24] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
*Gaurav Chaudhary, Laxmidhar Behera*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的离线强化学习奖励标注框架ReLOAD，该方法通过随机网络蒸馏生成内在奖励信号，从而实现无需显式奖励标注的策略学习。


<details>
  <summary>更多</summary>
  
**动机:** 离线强化学习在实际应用中面临的主要挑战之一是需要明确的奖励标注，这往往难以获得或成本高昂。为了解决这一问题，研究者们希望找到一种不需要复杂对齐过程的方法来生成奖励信号。

**方法:** 研究采用了随机网络蒸馏（RND）技术，基于专家演示的状态转换训练预测网络以模仿固定目标网络的嵌入表示。随后，利用两个网络之间的预测误差作为静态数据集中每个转换的奖励信号。

**结果:** 实验结果表明，ReLOAD可以在D4RL基准上实现稳健的离线策略学习，并且其性能可以与传统的有奖励标注的方法相媲美。

**结论:** ReLOAD提供了一个结构化的奖励信号生成机制，能够有效地服务于离线强化学习任务，而无需依赖于手工设计的奖励函数。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Novelty+to+Imitation%3A+Self-Distilled+Rewards+for+Offline+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12815，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12815&send_immediately=true&force_search=false)

**原文摘要:** Offline Reinforcement Learning (RL) aims to learn effective policies from a
static dataset without requiring further agent-environment interactions.
However, its practical adoption is often hindered by the need for explicit
reward annotations, which can be costly to engineer or difficult to obtain
retrospectively. To address this, we propose ReLOAD (Reinforcement Learning
with Offline Reward Annotation via Distillation), a novel reward annotation
framework for offline RL. Unlike existing methods that depend on complex
alignment procedures, our approach adapts Random Network Distillation (RND) to
generate intrinsic rewards from expert demonstrations using a simple yet
effective embedding discrepancy measure. First, we train a predictor network to
mimic a fixed target network's embeddings based on expert state transitions.
Later, the prediction error between these networks serves as a reward signal
for each transition in the static dataset. This mechanism provides a structured
reward signal without requiring handcrafted reward annotations. We provide a
formal theoretical construct that offers insights into how RND prediction
errors effectively serve as intrinsic rewards by distinguishing expert-like
transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables
robust offline policy learning and achieves performance competitive with
traditional reward-annotated methods.

</details>


### [25] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
*Kaiqi Jiang, Jeremy Cohen, Yuanzhi Li*

**主要类别:** cs.LG

**AI概要:** 本文研究了在Edge of Stability现象中，不同架构的神经网络在训练过程中NTK特征向量的行为，并发现更大的学习率导致最终的NTK主要特征向量与训练目标有更好的对齐。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有研究探讨了NTK特征值行为背后的机制，但对其特征向量在EoS期间的行为理解仍然不足。

**方法:** 作者观察了不同架构下，较大的学习率如何影响NTK的主要特征向量以及完整的NTK矩阵与训练目标的对齐情况，并为两层线性网络提供了理论分析。

**结果:** 研究发现在Edge of Stability现象中，更大的学习率会导致最终NTK的主要特征向量及整个NTK矩阵与训练目标有更高的对齐度。

**结论:** 该研究深化了我们对于深度学习中梯度下降训练动态的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+the+Evolution+of+the+Neural+Tangent+Kernel+at+the+Edge+of+Stability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12837，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12837&send_immediately=true&force_search=false)

**原文摘要:** The study of Neural Tangent Kernels (NTKs) in deep learning has drawn
increasing attention in recent years. NTKs typically actively change during
training and are related to feature learning. In parallel, recent work on
Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in
which the largest eigenvalue of the NTK oscillates around a value inversely
proportional to the step size. However, although follow-up works have explored
the underlying mechanism of such eigenvalue behavior in depth, the
understanding of the behavior of the NTK eigenvectors during EoS is still
missing. This paper examines the dynamics of NTK eigenvectors during EoS in
detail. Across different architectures, we observe that larger learning rates
cause the leading eigenvectors of the final NTK, as well as the full NTK
matrix, to have greater alignment with the training target. We then study the
underlying mechanism of this phenomenon and provide a theoretical analysis for
a two-layer linear network. Our study enhances the understanding of GD training
dynamics in deep learning.

</details>


### [26] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
*Zhijian Zhou, Liuhua Peng, Xunye Tian, Feng Liu*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种新的分布差异度量方法NAMMD，并基于此改进了分布接近性测试，提高了测试能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的分布接近性测试（DCT）主要局限于一维离散空间中的分布对的差异测量，限制了其在复杂数据类型（如图像）上的应用。为了扩展DCT的应用范围并提高其在多种分布对之间的比较时的信息量，需要一种更有效的测量方法。

**方法:** 作者引入了最大均值差异（MMD）到DCT场景中，但发现MMD对于具有不同RKHS范数的分布对可能产生相同的值，导致信息不足。为了解决这一问题，作者设计了自适应范数的最大均值差异（NAMMD），该方法通过使用RKHS中的分布范数来缩放MMD的值，从而更好地评估分布间的差异。

**结果:** 理论上证明了基于NAMMD的DCT相比基于MMD的DCT具有更高的检验力和可控的第一类错误率。实验验证了NAMMD在不同类型的数据（包括合成噪声、真实图像等）上的优越性。此外，NAMMD还被应用于两样本检验问题，并表现出比MMD更高的检验力。

**结论:** 提出的NAMMD及其在DCT中的应用提供了一个强大的工具来评估复杂数据类型的分布接近性，相比于传统的MMD方法，它提供了更高的测试能力和更好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Kernel+Distribution+Closeness+Testing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12843，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12843&send_immediately=true&force_search=false)

**原文摘要:** The distribution closeness testing (DCT) assesses whether the distance
between a distribution pair is at least $\epsilon$-far. Existing DCT methods
mainly measure discrepancies between a distribution pair defined on discrete
one-dimensional spaces (e.g., using total variation), which limits their
applications to complex data (e.g., images). To extend DCT to more types of
data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful
measurement of the distributional discrepancy between two complex
distributions, into DCT scenarios. However, we find that MMD's value can be the
same for many pairs of distributions that have different norms in the same
reproducing kernel Hilbert space (RKHS), making MMD less informative when
assessing the closeness levels for multiple distribution pairs. To mitigate the
issue, we design a new measurement of distributional discrepancy, norm-adaptive
MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions.
Based on the asymptotic distribution of NAMMD, we finally propose the
NAMMD-based DCT to assess the closeness levels of a distribution pair.
Theoretically, we prove that NAMMD-based DCT has higher test power compared to
MMD-based DCT, with bounded type-I error, which is also validated by extensive
experiments on many types of data (e.g., synthetic noise, real images).
Furthermore, we also apply the proposed NAMMD for addressing the two-sample
testing problem and find NAMMD-based two-sample test has higher test power than
the MMD-based two-sample test in both theory and experiments.

</details>


### [27] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
*Danilo Avola, Andrea Bernardini, Francesco Danese, Mario Lezoche, Maurizio Mancini, Daniele Pannone, Amedeo Ranaldi*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于变压器架构的方法，利用静止状态下的信道状态信息（CSI）进行个人识别，通过处理CSI中的幅度和相位模态，该方法实现了99.82%的分类准确率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的无线信号识别人类身份的方法大多依赖于运动模式，如行走步态，而静止状态下的人类识别尚未充分研究。为了探索非侵入性和保护隐私的人类识别替代方案，需要开发一种新的方法，可以在没有用户运动的情况下识别人类个体。

**方法:** 作者提出了一个双分支变压器架构，可以分别处理CSI中的幅度和相位模态，并引入了一个预处理管道来增强信号质量。此外，还创建了一个包含六名参与者在不同方向上的数据集。

**结果:** 该方法达到了99.82%的分类准确率，超过了卷积和多层感知器基线模型的结果。这证明了CSI扰动的辨析潜力及其编码生物特征的能力。

**结论:** 研究表明，利用低成本的商品Wi-Fi硬件，在现实环境中实现无源、无需设备的人类识别是可行的。CSI扰动能够以一致的方式编码生物特征，具有作为人类识别手段的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Transformer-Based+Person+Identification+via+Wi-Fi+CSI+Amplitude+and+Phase+Perturbations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12854&send_immediately=true&force_search=false)

**原文摘要:** Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving
alternative to vision-based systems for human identification. However, person
identification through wireless signals, particularly without user motion,
remains largely unexplored. Most prior wireless-based approaches rely on
movement patterns, such as walking gait, to extract biometric cues. In
contrast, we propose a transformer-based method that identifies individuals
from Channel State Information (CSI) recorded while the subject remains
stationary. CSI captures fine-grained amplitude and phase distortions induced
by the unique interaction between the human body and the radio signal. To
support evaluation, we introduce a dataset acquired with ESP32 devices in a
controlled indoor environment, featuring six participants observed across
multiple orientations. A tailored preprocessing pipeline, including outlier
removal, smoothing, and phase calibration, enhances signal quality. Our
dual-branch transformer architecture processes amplitude and phase modalities
separately and achieves 99.82\% classification accuracy, outperforming
convolutional and multilayer perceptron baselines. These results demonstrate
the discriminative potential of CSI perturbations, highlighting their capacity
to encode biometric traits in a consistent manner. They further confirm the
viability of passive, device-free person identification using low-cost
commodity Wi-Fi hardware in real-world settings.

</details>


### [28] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
*Chongli Qin, Jost Tobias Springenberg*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种改进的监督微调方法——重要性加权监督微调（iw-SFT），该方法在大型语言模型和连续控制任务策略训练方面具有竞争力，并在AIME 2024数据集上取得了66.7%的成绩。


<details>
  <summary>更多</summary>
  
**动机:** 行为克隆（BC）在策划的数据上的监督微调（SFT）是大型语言模型的主要范式。作者发现，SFT可以被理解为在稀疏奖励设置中最大化RL目标的下限。基于此，他们希望通过对SFT的小修改，使其更接近于RL训练的效果。

**方法:** 作者提出了重要性加权监督微调（iw-SFT），它优化了RL目标的更紧密的界限，并且可以在策划的数据上提高性能。此外，iw-SFT易于实现，并可进一步推广到使用质量评分数据进行训练。

**结果:** 通过实验表明，所提出的iw-SFT变体在大型语言模型和连续控制任务的策略训练中与更高级的RL算法竞争，并在AIME 2024数据集上达到了66.7%的准确率。

**结论:** 重要性加权监督微调（iw-SFT）作为一种简单但有效的技术，能够改善现有监督微调方法的性能，并且在某些情况下可与强化学习方法相媲美。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Supervised+Fine+Tuning+on+Curated+Data+is+Reinforcement+Learning+%28and+can+be+improved%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12856，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12856&send_immediately=true&force_search=false)

**原文摘要:** Behavior Cloning (BC) on curated (or filtered) data is the predominant
paradigm for supervised fine-tuning (SFT) of large language models; as well as
for imitation learning of control policies. Here, we draw on a connection
between this successful strategy and the theory and practice of finding optimal
policies via Reinforcement Learning (RL). Building on existing literature, we
clarify that SFT can be understood as maximizing a lower bound on the RL
objective in a sparse reward setting. Giving support to its often observed good
performance. From this viewpoint, we realize that a small modification to SFT
leads to an importance weighted variant that behaves closer to training with RL
as it: i) optimizes a tighter bound to the RL objective and, ii) can improve
performance compared to SFT on curated data. We refer to this variant as
importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to
implement and can be further generalized to training with quality scored data.
The resulting SFT variants are competitive with more advanced RL algorithms for
large language models and for training policies in continuous control tasks.
For example achieving 66.7% on the AIME 2024 dataset.

</details>


### [29] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
*Danilo Avola, Giancarlo Crocetti, Gian Luca Foresti, Daniele Pannone, Claudio Piciarelli, Amedeo Ranaldi*

**主要类别:** cs.LG

**AI概要:** 研究了使用耳 EEG 信号进行生物特征认证的可行性，提出了一种新的框架，该框架从耳 EEG 信号中提取时域和频域特征，并将其输入全连接的深度神经网络进行主体识别。实验表明其平均准确率为82%，证明了耳 EEG 在下一代生物特征系统中的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于 EEG 的生物特征系统虽然安全，但由于头皮电极设置繁琐而导致可用性低。为了提高日常生物特征认证的用户友好性，本研究探索了使用耳 EEG 信号的可能性。

**方法:** 系统从耳 EEG 信号中提取原始的时间和频谱特征组合，并将这些特征输入到一个全连接的深度神经网络中进行主体识别。

**结果:** 在目前唯一可用于不同目的（包括生物特征认证）的耳 EEG 数据集上的实验结果表明，该系统的主体识别场景平均准确率为82%。

**结论:** 研究结果确认了耳 EEG 作为下一代现实世界生物特征系统的一个可行且可部署的方向的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Investigation+of+Ear-EEG+Signals+for+a+Novel+Biometric+Authentication+System，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12873，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12873&send_immediately=true&force_search=false)

**原文摘要:** This work explores the feasibility of biometric authentication using EEG
signals acquired through in-ear devices, commonly referred to as ear-EEG.
Traditional EEG-based biometric systems, while secure, often suffer from low
usability due to cumbersome scalp-based electrode setups. In this study, we
propose a novel and practical framework leveraging ear-EEG signals as a
user-friendly alternative for everyday biometric authentication. The system
extracts an original combination of temporal and spectral features from ear-EEG
signals and feeds them into a fully connected deep neural network for subject
identification. Experimental results on the only currently available ear-EEG
dataset suitable for different purposes, including biometric authentication,
demonstrate promising performance, with an average accuracy of 82\% in a
subject identification scenario. These findings confirm the potential of
ear-EEG as a viable and deployable direction for next-generation real-world
biometric systems.

</details>


### [30] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
*Pavel Snopov, Oleg R. Musin*

**主要类别:** cs.LG

**AI概要:** 研究了新型激活函数，提出了SmoothSplit和ParametricSplit，以增强神经网络在训练过程中操控数据拓扑的能力。实验表明，在低维场景中，ParametricSplit性能优于传统激活函数。


<details>
  <summary>更多</summary>
  
**动机:** 传统的激活函数（如ReLU）在处理数据拓扑方面存在局限性，尤其是在低维层的情况下。为了改进这一点，需要引入新的激活函数来提高神经网络对复杂数据流形的转换能力。

**方法:** 提出两种新的激活函数：SmoothSplit和ParametricSplit，它们具有拓扑“切割”能力，可以帮助网络更有效地转换复杂的数据流形。

**结果:** 通过在合成和真实数据集上的实验，证明了ParametricSplit在低维设置中优于传统激活函数，同时在高维设置中保持竞争力。

**结论:** 研究强调了拓扑感知激活函数在推进神经网络架构方面的潜力，并提供了相关代码。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Topology-Aware+Activation+Functions+in+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12874，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12874&send_immediately=true&force_search=false)

**原文摘要:** This study explores novel activation functions that enhance the ability of
neural networks to manipulate data topology during training. Building on the
limitations of traditional activation functions like $\mathrm{ReLU}$, we
propose $\mathrm{SmoothSplit}$ and $\mathrm{ParametricSplit}$, which introduce
topology "cutting" capabilities. These functions enable networks to transform
complex data manifolds effectively, improving performance in scenarios with
low-dimensional layers. Through experiments on synthetic and real-world
datasets, we demonstrate that $\mathrm{ParametricSplit}$ outperforms
traditional activations in low-dimensional settings while maintaining
competitive performance in higher-dimensional ones. Our findings highlight the
potential of topology-aware activation functions in advancing neural network
architectures. The code is available via
https://github.com/Snopoff/Topology-Aware-Activations.

</details>


### [31] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng, Hengkai Tan, Xinyi Mao, Guodong Liu, Shuhe Huang, Chendong Xiang, Hang Su, Jun Zhu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的双臂机器人操作框架VIDAR，通过大规模视频预训练和遮罩逆动力学模型，实现了对新任务和背景的强大泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管在通用机器人操作方面取得了进展，但在双臂设置中，数据稀缺性和实体异质性仍然是扩大规模的严重障碍。

**方法:** VIDAR是一个两阶段框架，利用大规模扩散式视频预训练和新颖的遮罩逆动力学模型进行动作预测。

**结果:** 实验表明，VIDAR仅需20分钟的人类演示即可对未见过的任务和背景进行强大的语义理解，超越了现有方法。

**结论:** 研究结果强调了视频基础模型与遮罩动作预测相结合，在多样化真实环境中实现可扩展且通用的机器人操作的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalist+Bimanual+Manipulation+via+Foundation+Video+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12898，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12898&send_immediately=true&force_search=false)

**原文摘要:** Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [32] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
*Luca Stradiotti, Dario Pesenti, Stefano Teso, Jesse Davis*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一个框架，使得机器学习预测器能够拒绝解释质量低下的预测，并引入了ULER方法，该方法在八个基准测试和新的人类标注数据集上优于现有策略。


<details>
  <summary>更多</summary>
  
**动机:** 随着机器学习预测器在高风险应用（如信用评分）中的使用增加，解释预测背后的原因变得越来越重要。然而，这些解释并不总是高质量的，用户可能难以理解或信任这些解释，从而影响信任评估和决策。

**方法:** 作者提出了一种名为LtX的学习框架，其中预测器配备了一个评估解释质量的拒绝器。特别地，他们引入了ULER方法，它从人类评级和每个特征的相关性判断中学习简单的拒绝器，以反映人类对解释质量的判断。

**结果:** 实验表明，与最先进的方法相比，ULER在八个分类和回归基准以及新的由人类注释的数据集上表现更好。

**结论:** 作者认为，预测器应该有能力拒绝处理那些无法正确解释其预测的输入，并且他们的工作为未来的研究提供了支持，包括公开发布一个新的数据集。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Reject+Low-Quality+Explanations+via+User+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12900，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12900&send_immediately=true&force_search=false)

**原文摘要:** Machine Learning predictors are increasingly being employed in high-stakes
applications such as credit scoring. Explanations help users unpack the reasons
behind their predictions, but are not always "high quality''. That is,
end-users may have difficulty interpreting or believing them, which can
complicate trust assessment and downstream decision-making. We argue that
classifiers should have the option to refuse handling inputs whose predictions
cannot be explained properly and introduce a framework for learning to reject
low-quality explanations (LtX) in which predictors are equipped with a rejector
that evaluates the quality of explanations. In this problem setting, the key
challenges are how to properly define and assess explanation quality and how to
design a suitable rejector. Focusing on popular attribution techniques, we
introduce ULER (User-centric Low-quality Explanation Rejector), which learns a
simple rejector from human ratings and per-feature relevance judgments to
mirror human judgments of explanation quality. Our experiments show that ULER
outperforms both state-of-the-art and explanation-aware learning to reject
strategies at LtX on eight classification and regression benchmarks and on a
new human-annotated dataset, which we will publicly release to support future
research.

</details>


### [33] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
*Jiadong Chen, Hengyu Ye, Fuxin Jiang, Xiao He, Tieying Zhang, Jianjun Chen, Xiaofeng Gao*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的深度预测模型Fremer，该模型在工作负载预测方面表现出更高的效率和准确性，并且在多个周期序列中表现出稳健的性能。实验表明，与现有最先进模型相比，Fremer在MSE、MAE和SMAPE方面有显著改进，同时减少了参数规模和计算成本。此外，在基于Kubernetes的自动扩展测试中，Fremer提高了平均延迟并降低了资源消耗。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基于Transformer的预测模型在一般任务中取得了显著的成功，但在大规模云环境中，它们的计算效率通常无法满足严格的要求。因此，需要一种更高效的模型来处理复杂的工作负载序列预测问题。

**方法:** 提出了Fremer，这是一种高效且有效的深度预测模型。它通过在频率域中解决问题来提高计算效率，同时保持了对复杂周期性模式的有效捕捉。

**结果:** 广泛的实验表明，Fremer在专有数据集和公共基准上均优于基线模型，实现了5.5%的MSE、4.7%的MAE和8.6%SMAPE的平均改进。此外，它还减少了参数规模和计算成本。在实际应用中，如基于Kubernetes的自动扩展测试中，Fremer提高了18.78%的平均延迟并降低了2.35%的资源消耗。

**结论:** Fremer作为一种新型的工作负载预测模型，不仅在效率和准确性上超越了现有的最先进模型，而且在多周期序列中表现出了强大的性能。其开源的数据集也为未来的研究提供了宝贵的资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fremer%3A+Lightweight+and+Effective+Frequency+Transformer+for+Workload+Forecasting+in+Cloud+Services，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12908&send_immediately=true&force_search=false)

**原文摘要:** Workload forecasting is pivotal in cloud service applications, such as
auto-scaling and scheduling, with profound implications for operational
efficiency. Although Transformer-based forecasting models have demonstrated
remarkable success in general tasks, their computational efficiency often falls
short of the stringent requirements in large-scale cloud environments. Given
that most workload series exhibit complicated periodic patterns, addressing
these challenges in the frequency domain offers substantial advantages. To this
end, we propose Fremer, an efficient and effective deep forecasting model.
Fremer fulfills three critical requirements: it demonstrates superior
efficiency, outperforming most Transformer-based forecasting models; it
achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in
workload forecasting; and it exhibits robust performance for multi-period
series. Furthermore, we collect and open-source four high-quality, open-source
workload datasets derived from ByteDance's cloud services, encompassing
workload data from thousands of computing instances. Extensive experiments on
both our proprietary datasets and public benchmarks demonstrate that Fremer
consistently outperforms baseline models, achieving average improvements of
5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while
simultaneously reducing parameter scale and computational costs. Additionally,
in a proactive auto-scaling test based on Kubernetes, Fremer improves average
latency by 18.78% and reduces resource consumption by 2.35%, underscoring its
practical efficacy in real-world applications.

</details>


### [34] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
*Chenrui Zhu, Louenas Bounia, Vu Linh Nguyen, Sébastien Destercke, Arthur Hoarau*

**主要类别:** cs.LG

**AI概要:** 本文提出利用预测不确定性作为解释方法的补充，通过区分数据相关和模型相关的不确定性来选择合适的解释方法，并证明了该方法在传统机器学习和深度学习中的有效性和可行性。


<details>
  <summary>更多</summary>
  
**动机:** 随着机器学习模型架构越来越复杂，可解释性变得越来越差，因此需要透明度更高的模型预测。

**方法:** 作者区分了两种不确定性：aleatoric（数据相关）和epistemic（模型相关），并使用这些不确定性来指导解释的选择。其中，epistemic不确定性用作拒绝不可靠解释的标准，而aleatoric不确定性用于决定选择特征重要性解释还是反事实解释。

**结果:** 实验表明，这种基于不确定性的解释方法提高了解释的鲁棒性和可获得性。

**结论:** 通过结合预测不确定性与经典的解释方法，可以提高机器学习模型的透明度和可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Explanations+Through+Uncertainty+Decomposition%3A+A+Path+to+Trustworthier+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12913，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12913&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in machine learning have emphasized the need for
transparency in model predictions, particularly as interpretability diminishes
when using increasingly complex architectures. In this paper, we propose
leveraging prediction uncertainty as a complementary approach to classical
explainability methods. Specifically, we distinguish between aleatoric
(data-related) and epistemic (model-related) uncertainty to guide the selection
of appropriate explanations. Epistemic uncertainty serves as a rejection
criterion for unreliable explanations and, in itself, provides insight into
insufficient training (a new form of explanation). Aleatoric uncertainty
informs the choice between feature-importance explanations and counterfactual
explanations. This leverages a framework of explainability methods driven by
uncertainty quantification and disentanglement. Our experiments demonstrate the
impact of this uncertainty-aware approach on the robustness and attainability
of explanations in both traditional machine learning and deep learning
scenarios.

</details>


### [35] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
*Franziska Weindel, Michael Girsch, Reinhard Heckel*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的追踪重建方法TReconLM，利用预训练的语言模型和特定技术错误模式的微调，显著提高了无错序列恢复的比例。


<details>
  <summary>更多</summary>
  
**动机:** 追踪重建问题是试图从受到删除、插入和替换等噪声影响的副本中恢复原始序列。这一问题在DNA数据存储等应用中尤为重要，因为DNA合成、存储和测序过程中引入的错误需要通过算法和编码进行校正。

**方法:** 作者提出了TReconLM，它使用经过下一步预测训练的语言模型来进行追踪重建。这些语言模型首先在合成数据上预训练，然后在真实世界的数据上进行微调以适应特定技术的错误模式。

**结果:** TReconLM的表现超过了现有的追踪重建算法，包括之前的深度学习方法，在无错序列恢复方面有显著提升。

**结论:** 该研究展示了利用语言模型进行追踪重建的有效性，并且通过适当的预训练和微调可以实现更好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trace+Reconstruction+with+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12927&send_immediately=true&force_search=false)

**原文摘要:** The general trace reconstruction problem seeks to recover an original
sequence from its noisy copies independently corrupted by deletions,
insertions, and substitutions. This problem arises in applications such as DNA
data storage, a promising storage medium due to its high information density
and longevity. However, errors introduced during DNA synthesis, storage, and
sequencing require correction through algorithms and codes, with trace
reconstruction often used as part of the data retrieval process. In this work,
we propose TReconLM, which leverages language models trained on next-token
prediction for trace reconstruction. We pretrain language models on synthetic
data and fine-tune on real-world data to adapt to technology-specific error
patterns. TReconLM outperforms state-of-the-art trace reconstruction
algorithms, including prior deep learning approaches, recovering a
substantially higher fraction of sequences without error.

</details>


### [36] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
*Hongze Tan*

**主要类别:** cs.LG

**AI概要:** 本文提出两种新颖的修改以改进DAPO算法，通过混合策略视角提升训练稳定性和样本效率。


<details>
  <summary>更多</summary>
  
**动机:** 标准的策略梯度方法在稀疏奖励设置中可能遇到不稳定性和样本效率低的问题，因此需要改进以提高训练的稳定性和收敛速度，并更有效地利用样本数据。

**方法:** 首先，引入预训练的稳定引导策略提供离策略经验，从而调节目标策略的训练。其次，重新利用零奖励样本作为由专家策略指导的独特批次，进一步提高样本效率。

**结果:** 理论分析表明，这两种方法的目标函数在强化学习的理论框架内收敛到最优解，有效平衡了探索与开发。

**结论:** 所提出的混合策略框架有望实现更稳定和高效的策略优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+a+Mixed-Policy+Perspective%3A+Improving+Differentiable+Automatic+Post-editing+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12931&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces two novel modifications to the Differentiable Automatic
Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy
perspective. Standard policy gradient methods can suffer from instability and
sample inefficiency, particularly in sparse reward settings. To address this,
we first propose a method that incorporates a pre-trained, stable guiding
policy ($\piphi$) to provide off-policy experience, thereby regularizing the
training of the target policy ($\pion$). This approach improves training
stability and convergence speed by adaptively adjusting the learning step size.
Secondly, we extend this idea to re-utilize zero-reward samples, which are
often discarded by dynamic sampling strategies like DAPO's. By treating these
samples as a distinct batch guided by the expert policy, we further enhance
sample efficiency. We provide a theoretical analysis for both methods,
demonstrating that their objective functions converge to the optimal solution
within the established theoretical framework of reinforcement learning. The
proposed mixed-policy framework effectively balances exploration and
exploitation, promising more stable and efficient policy optimization.

</details>


### [37] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
*Shirui Zhao, Jun Yin, Lingyun Yao, Martin Andraud, Wannes Meert, Marian Verhelst*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为MC²A的算法-硬件协同设计框架，以实现MCMC加速的高效和灵活优化。通过分析MCMC工作负载多样性、提出参数化硬件加速器架构以及使用新型Gumbel采样器，MC²A在多种工作负载上实现了显著的加速效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的MCMC加速解决方案要么在硬件灵活性上有限，要么无法在系统级别上保持效率。为了克服这些问题，需要一种新的方法来实现高效的MCMC加速。

**方法:** 首先，MC²A通过扩展处理器性能屋顶线模型引入第三维度来分析MCMC工作负载多样性，以找到计算、采样和内存参数之间的最佳平衡。其次，它提出了一个参数化的硬件加速器架构，包括ISA可编程树状结构处理单元、可重构采样器和交叉开关互连。最后，核心部分由一个消除了指数和归一化操作的新颖Gumbel采样器驱动。

**结果:** 在端到端案例研究中，与CPU、GPU、TPU和最先进的MCMC加速器相比，MC²A分别实现了307.6倍、1.4倍、2.0倍和84.2倍的速度提升。

**结论:** 本研究表明，在各种代表性MCMC工作负载上展示并利用通用硬件加速的可行性，可以推广基于MCMC的解决方案在不同应用领域的普及。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MC%24%5E2%24A%3A+Enabling+Algorithm-Hardware+Co-Design+for+Efficient+Markov+Chain+Monte+Carlo+Acceleration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12935&send_immediately=true&force_search=false)

**原文摘要:** An increasing number of applications are exploiting sampling-based algorithms
for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC)
algorithms form the computational backbone of this emerging branch of machine
learning. Unfortunately, the high computational cost limits their feasibility
for large-scale problems and real-world applications, and the existing MCMC
acceleration solutions are either limited in hardware flexibility or fail to
maintain efficiency at the system level across a variety of end-to-end
applications. This paper introduces \textbf{MC$^2$A}, an algorithm-hardware
co-design framework, enabling efficient and flexible optimization for MCMC
acceleration. Firstly, \textbf{MC$^2$A} analyzes the MCMC workload diversity
through an extension of the processor performance roofline model with a 3rd
dimension to derive the optimal balance between the compute, sampling and
memory parameters. Secondly, \textbf{MC$^2$A} proposes a parametrized hardware
accelerator architecture with flexible and efficient support of MCMC kernels
with a pipeline of ISA-programmable tree-structured processing units,
reconfigurable samplers and a crossbar interconnect to support irregular
access. Thirdly, the core of \textbf{MC$^2$A} is powered by a novel Gumbel
sampler that eliminates exponential and normalization operations. In the
end-to-end case study, \textbf{MC$^2$A} achieves an overall {$307.6\times$,
$1.4\times$, $2.0\times$, $84.2\times$} speedup compared to the CPU, GPU, TPU
and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC
workloads, this work demonstrates and exploits the feasibility of general
hardware acceleration to popularize MCMC-based solutions in diverse application
domains.

</details>


### [38] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
*Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的去中心化GAN训练方法，利用分布式数据和低能力的闲置设备，在不共享原始数据的情况下进行训练。该方法结合KLD加权聚类联邦学习和异构U形分割学习，以解决数据异构性和设备异构性的问题。实验结果显示，该方法在多个关键性能指标上显著优于几种基准方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成模型训练需要大量的数据集和计算资源，这在现实环境中难以获得，并且获取这些资源成本高、效率低。此外，由于隐私问题和版权限制，许多设备不愿意共享其数据。

**方法:** 该研究提出的方法结合了KLD-weighted Clustered Federated Learning和Heterogeneous U-Shaped split learning，前者用于处理数据异质性和多域数据集的问题，后者则应对严格的资源共享限制下的设备异质性挑战。

**结果:** 实验结果表明，该方法在图像生成得分上提高了1.1倍至2.2倍，在分类度量上平均提高了10%（在多域非IID设置中最高可达50%），并且相比几个基准方法延迟更低。

**结论:** 这项研究表明，通过使用提出的去中心化GAN训练方法，可以在保护隐私的同时有效利用分布式数据和未充分利用的设备来提高生成模型的训练效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Distributed+Generative+AI+Approach+for+Heterogeneous+Multi-Domain+Environments+under+Data+Sharing+constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12979，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12979&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning has gained increasing attention for its ability to enable
multiple nodes to collaboratively train machine learning models without sharing
their raw data. At the same time, Generative AI -- particularly Generative
Adversarial Networks (GANs) -- have achieved remarkable success across a wide
range of domains, such as healthcare, security, and Image Generation. However,
training generative models typically requires large datasets and significant
computational resources, which are often unavailable in real-world settings.
Acquiring such resources can be costly and inefficient, especially when many
underutilized devices -- such as IoT devices and edge devices -- with varying
capabilities remain idle. Moreover, obtaining large datasets is challenging due
to privacy concerns and copyright restrictions, as most devices are unwilling
to share their data. To address these challenges, we propose a novel approach
for decentralized GAN training that enables the utilization of distributed data
and underutilized, low-capability devices while not sharing data in its raw
form. Our approach is designed to tackle key challenges in decentralized
environments, combining KLD-weighted Clustered Federated Learning to address
the issues of data heterogeneity and multi-domain datasets, with Heterogeneous
U-Shaped split learning to tackle the challenge of device heterogeneity under
strict data sharing constraints -- ensuring that no labels or raw data, whether
real or synthetic, are ever shared between nodes. Experimental results shows
that our approach demonstrates consistent and significant improvements across
key performance metrics, where it achieves 1.1x -- 2.2x higher image generation
scores, an average 10% boost in classification metrics (up to 50% in
multi-domain non-IID settings), in much lower latency compared to several
benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.

</details>


### [39] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You, Anton Xue, Shreya Havaldar, Delip Rao, Helen Jin, Chris Callison-Burch, Eric Wong*

**主要类别:** cs.LG

**AI概要:** 大型语言模型（LLMs）生成的推理链中，初始错误经常传播并削弱最终结论的可靠性。当前基于LLM的错误检测方法通常无法检测传播的错误，因为它们没有充分考虑早期错误如何可能破坏下游推理的判断。为更好地检测此类传播错误，本文提出了自回归推理蕴含稳定性（ARES），一种新颖的概率框架，通过仅根据先前评估过的可靠前提来判断每个主张，防止错误传播。ARES在四个基准测试中达到了最先进的性能（72.1% 宏F1，+8.2点），并在很长的合成推理链上表现出优越的稳健性，擅长检测传播错误（90.3% F1，+27.6点）。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型生成的推理链中的初始错误会传播并影响最终结论的可靠性，而现有的错误检测方法未能有效应对这一问题。因此，需要一种新的方法来更准确地检测这些传播的错误。

**方法:** 提出了一种名为ARES的新颖概率框架，该框架通过仅根据先前评估过的可靠前提来判断每个主张，从而防止错误传播。此方法提供了一个细致的评分，并提供了其合理性的统计保证。

**结果:** ARES在四个基准测试中实现了72.1%的宏F1得分，相比现有方法提高了8.2个百分点。此外，在非常长的合成推理链上，它在检测传播错误方面表现出色，F1得分为90.3%，比现有方法高出27.6个百分点。

**结论:** ARES提供了一种新的、有效的解决方案来防止大型语言模型生成的推理链中的错误传播，显著提高了错误检测的准确性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probabilistic+Soundness+Guarantees+in+LLM+Reasoning+Chains，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12948&send_immediately=true&force_search=false)

**原文摘要:** In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [40] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin, Yaroslav Aksenov, Daniil Laptev, Gleb Gerasimov, Nikita Balagansky, Daniil Gavrilov*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种残差学习方法，通过训练次级SAE来建模预训练SAE在特定领域文本上的重构误差，从而有效捕捉主模型遗漏的特征。实验表明，该方法在多个专业领域显著提升了LLM交叉熵和解释方差指标，并能将新领域知识高效地融入现有的SAE中。


<details>
  <summary>更多</summary>
  
**动机:** Sparse Autoencoders（稀疏自编码器）在解释大型语言模型内部表示方面表现出色，但常常无法捕捉其训练语料库中不常见的领域特定特征。为了解决这一问题，无需完全重新训练模型。

**方法:** 提出训练一个次级SAE专门用于建模预训练SAE在领域特定文本上的重构误差，通过推理时将两个模型的输出相加，从而捕捉到主模型遗漏的特征。

**结果:** 在多个专业领域内，这种方法显著改善了LLM交叉熵和解释方差度量，并且可以有效地将新的领域知识结合到现有的SAE中，同时保持其在一般任务上的性能。

**结论:** 此方法允许研究者有针对性地增强SAE对特定领域的可解释性，为LLM的机制可解释性研究开辟了新的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Teach+Old+SAEs+New+Domain+Tricks+with+Boosting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12990，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12990&send_immediately=true&force_search=false)

**原文摘要:** Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [41] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
*Kenza Bouzid, Shruthi Bannur, Daniel Coelho de Castro, Anton Schwaighofer, Javier Alvarez-Valle, Stephanie L. Hyland*

**主要类别:** cs.LG

**AI概要:** 本研究将Matryoshka-SAE应用于放射学专业的大规模语言模型MAIRA-2，以解释其内部表示，并通过转向测试这些特征对模型行为的影响。尽管存在挑战，但这项工作为改进模型透明度提供了初步见解。


<details>
  <summary>更多</summary>
  
**动机:** 提高AI模型的安全性、透明度和信任度在医疗保健应用中非常重要，尤其是在决策可能产生重大后果的情况下。机制可解释性，特别是通过使用稀疏自编码器（SAEs），提供了一种有希望的方法来揭示大型基于变压器的模型中的人类可解释特征。

**方法:** 研究人员使用了Matryoshka-SAE方法应用于放射学专门的多模态大语言模型MAIRA-2，并进行了大规模自动化解释SAE特征的工作。

**结果:** 识别出一系列临床上相关的概念，包括医疗设备、病理状况等，并展示了对生成内容的方向控制能力，但效果参差不齐。

**结论:** 尽管存在实际和方法上的挑战，这项工作为深入理解放射学适应的多模态大语言模型的内部概念提供了一个步骤，并为提高模型透明度铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Insights+into+a+radiology-specialised+multimodal+large+language+model+with+sparse+autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12950，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12950&send_immediately=true&force_search=false)

**原文摘要:** Interpretability can improve the safety, transparency and trust of AI models,
which is especially important in healthcare applications where decisions often
carry significant consequences. Mechanistic interpretability, particularly
through the use of sparse autoencoders (SAEs), offers a promising approach for
uncovering human-interpretable features within large transformer-based models.
In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal
large language model, MAIRA-2, to interpret its internal representations. Using
large-scale automated interpretability of the SAE features, we identify a range
of clinically relevant concepts - including medical devices (e.g., line and
tube placements, pacemaker presence), pathologies such as pleural effusion and
cardiomegaly, longitudinal changes and textual features. We further examine the
influence of these features on model behaviour through steering, demonstrating
directional control over generations with mixed success. Our results reveal
practical and methodological challenges, yet they offer initial insights into
the internal concepts learned by MAIRA-2 - marking a step toward deeper
mechanistic understanding and interpretability of a radiology-adapted
multimodal large language model, and paving the way for improved model
transparency. We release the trained SAEs and interpretations:
https://huggingface.co/microsoft/maira-2-sae.

</details>


### [42] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
*Kossi Amouzouvi, Bowen Song, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种框架，通过评估每个关系与不同几何变换的匹配度来为知识图谱嵌入模型选择最佳的几何变换，从而提升模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的知识图谱嵌入模型在表示关系时通常使用基础几何变换，但这些变换对于所有关系来说可能是不够的，因为它们没有考虑到特定关系的特性。

**方法:** 作者提出了一个框架，该框架首先评估每个关系与不同几何变换的匹配程度，然后根据这个评估结果，可以为每个关系分配最适合的几何变换，或者通过多数投票选择一种变换类型应用于所有关系。此外，还利用低维空间中学习到的关系和几何变换之间的相关性来进行高维空间中的关系嵌入。

**结果:** 通过在三个基准知识图谱以及一个真实的金融知识图谱上的综合评估，证明了所提出的模型的有效性，其性能可与领先模型相媲美。

**结论:** 该研究提供了一种新颖的方法来改进知识图谱嵌入模型中的关系表示，即通过考虑关系特定的几何变换，可以在保持模型简单性的同时提高其表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMART%3A+Relation-Aware+Learning+of+Geometric+Representations+for+Knowledge+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13001，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13001&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graph representation learning approaches provide a mapping between
symbolic knowledge in the form of triples in a knowledge graph (KG) and their
feature vectors. Knowledge graph embedding (KGE) models often represent
relations in a KG as geometric transformations. Most state-of-the-art (SOTA)
KGE models are derived from elementary geometric transformations (EGTs), such
as translation, scaling, rotation, and reflection, or their combinations. These
geometric transformations enable the models to effectively preserve specific
structural and relational patterns of the KG. However, the current use of EGTs
by KGEs remains insufficient without considering relation-specific
transformations. Although recent models attempted to address this problem by
ensembling SOTA baseline models in different ways, only a single or composite
version of geometric transformations are used by such baselines to represent
all the relations. In this paper, we propose a framework that evaluates how
well each relation fits with different geometric transformations. Based on this
ranking, the model can: (1) assign the best-matching transformation to each
relation, or (2) use majority voting to choose one transformation type to apply
across all relations. That is, the model learns a single relation-specific EGT
in low dimensional vector space through an attention mechanism. Furthermore, we
use the correlation between relations and EGTs, which are learned in a low
dimension, for relation embeddings in a high dimensional vector space. The
effectiveness of our models is demonstrated through comprehensive evaluations
on three benchmark KGs as well as a real-world financial KG, witnessing a
performance comparable to leading models

</details>


### [43] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
*Anna Bison, Alessandro Sperduti*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于图形设计领域的Fairing算法的多分辨率水库图神经网络（MRGNN）变体，以解决图神经网络中的过平滑问题。该方法通过Laplacian算子提供了一个带通光谱滤波器，允许在不收缩的情况下进行平滑处理，并且可以通过调整光谱系数来控制冗余随机游走的贡献。初步实验展示了这种方法的潜力，并为未来的研究指明了方向。


<details>
  <summary>更多</summary>
  
**动机:** 图神经网络（GNNs）中反复应用层算子时会遇到过平滑的问题，即图信号向图Laplacian的低频分量收敛。为了改善训练效率并解决这一问题，本研究重新定义了水库计算中的水库部分，提出了一个基于图形设计领域中的Fairing算法的新变体。

**方法:** 该研究引入了计算机图形学中的Fairing算法，提供了一个带通光谱滤波器，允许在不收缩的情况下进行平滑处理。它通过Laplacian算子适应于图设置，并与GNN架构自然连接。此外，从随机游走的角度对算法进行了理论分析，展示了如何通过调整光谱系数来调节冗余随机游走的贡献。

**结果:** 探索性实验表明，基于MRGNN架构的方法具有潜在的优势，特别是在需要适当控制平滑的任务中，如图分类。实验结果还暗示了未来研究的有希望的方向。

**结论:** 该论文的主要贡献在于从理论上分析了Fairing算法，并展示了其在GNN中的应用潜力。这为未来的研究提供了新的视角和工具，特别是在如何更好地控制平滑过程以提高GNN性能方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Spectral+Interpretation+of+Redundancy+in+a+Graph+Reservoir，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12963，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12963&send_immediately=true&force_search=false)

**原文摘要:** Reservoir computing has been successfully applied to graphs as a
preprocessing method to improve the training efficiency of Graph Neural
Networks (GNNs). However, a common issue that arises when repeatedly applying
layer operators on graphs is over-smoothing, which consists in the convergence
of graph signals toward low-frequency components of the graph Laplacian. This
work revisits the definition of the reservoir in the Multiresolution Reservoir
Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a
variant based on a Fairing algorithm originally introduced in the field of
surface design in computer graphics. This algorithm provides a pass-band
spectral filter that allows smoothing without shrinkage, and it can be adapted
to the graph setting through the Laplacian operator. Given its spectral
formulation, this method naturally connects to GNN architectures for tasks
where smoothing, when properly controlled, can be beneficial,such as graph
classification. The core contribution of the paper lies in the theoretical
analysis of the algorithm from a random walks perspective. In particular, it
shows how tuning the spectral coefficients can be interpreted as modulating the
contribution of redundant random walks. Exploratory experiments based on the
MRGNN architecture illustrate the potential of this approach and suggest
promising directions for future research.

</details>


### [44] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
*Vincenzo Dentamaro, Felice Franchini, Giuseppe Pirlo, Irina Voiculescu*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的XAI技术MUPAX，具有确定性、模型无关性和收敛性保证，通过结构化扰动分析赋予特征重要性，消除虚假关系，并在各种数据类型和任务中进行了评估。


<details>
  <summary>更多</summary>
  
**动机:** 现有的XAI技术无法同时满足确定性、模型无关性和收敛性的要求。为了克服这些限制，提高解释的精确性和一致性，需要一种新的XAI方法。

**方法:** MUPAX使用测度论公式，通过结构化扰动分析来发现内在输入模式，消除虚假关系，赋予特征重要性。它适用于任何损失函数和任意维度的问题。

**结果:** MUPAX不仅保持了模型的准确性，而且通过捕捉原始数据中最重要的模式增强了模型的准确性。与现有XAI方法相比，在广泛的基准测试中表现出更好的性能，能够生成更精确、一致和可理解的解释。

**结论:** MUPAX作为一种新型的XAI技术，为实现可解释和可信的AI系统迈出了关键一步。源代码将在论文发表时公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MUPAX%3A+Multidimensional+Problem+Agnostic+eXplainable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13090，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13090&send_immediately=true&force_search=false)

**原文摘要:** Robust XAI techniques should ideally be simultaneously deterministic, model
agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM
AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability
technique, with guaranteed convergency. MUPAX measure theoretic formulation
gives principled feature importance attribution through structured perturbation
analysis that discovers inherent input patterns and eliminates spurious
relationships. We evaluate MUPAX on an extensive range of data modalities and
tasks: audio classification (1D), image classification (2D), volumetric medical
image analysis (3D), and anatomical landmark detection, demonstrating dimension
agnostic effectiveness. The rigorous convergence guarantees extend to any loss
function and arbitrary dimensions, making MUPAX applicable to virtually any
problem context for AI. By contrast with other XAI methods that typically
decrease performance when masking, MUPAX not only preserves but actually
enhances model accuracy by capturing only the most important patterns of the
original data. Extensive benchmarking against the state of the XAI art
demonstrates MUPAX ability to generate precise, consistent and understandable
explanations, a crucial step towards explainable and trustworthy AI systems.
The source code will be released upon publication.

</details>


### [45] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
*Reza Riahi Samani, Alfredo Nunez, Bart De Schutter*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于深度学习的新型框架，用于使用行驶中的振动响应信号进行基础设施健康监测。该框架在铁路轨道刚度估计的案例研究中表现出色，展示了其在准确、局部和全自动行驶中基础设施健康监测方面的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 认识到频谱和时间信息的重要性，以及对不同测量速度下的驱动振动信号进行分析的需求，而无需预处理。

**方法:** 引入WaveletInception-BiLSTM网络，该网络包括WaveletInception特征提取器（利用可学习的小波包变换作为主干来提取振动信号特征）和1D Inception网络（用于提取多尺度的高级特征），以及一个长短期记忆层（将提取的振动信号特征与操作条件相结合）。最后采用双向LSTM网络建模架构作为估计头，以捕捉来自行驶测量的双向时间关系。

**结果:** 该模型在模拟行驶中振动信号的铁路轨道刚度估计案例研究中显著优于现有方法，证明了其在基础设施健康状况评估上的高效性。

**结论:** 该研究表明，提出的WaveletInception-BiLSTM网络在基础设施健康监测方面具有很大的潜力，特别是在铁路轨道刚度参数估计方面，为实现高分辨率、梁级的基础设施健康状况评估提供了一种新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是WaveletInception+Networks+for+Drive-by+Vibration-Based+Infrastructure+Health+Monitoring，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12969，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12969&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a novel deep learning-based framework for infrastructure
health monitoring using drive-by vibration response signals. Recognizing the
importance of spectral and temporal information, we introduce the
WaveletInception-BiLSTM network. The WaveletInception feature extractor
utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting
vibration signal features, incorporating spectral information in the early
network layers. This is followed by 1D Inception networks that extract
multi-scale, high-level features at deeper layers. The extracted vibration
signal features are then integrated with operational conditions via a Long
Short-term Memory (LSTM) layer. The resulting feature extraction network
effectively analyzes drive-by vibration signals across various measurement
speeds without preprocessing and uses LSTM to capture interrelated temporal
dependencies among different modes of information and to create feature vectors
for health condition estimation. The estimator head is designed with a
sequential modeling architecture using bidirectional LSTM (BiLSTM) networks,
capturing bi-directional temporal relationships from drive-by measurements.
This architecture allows for a high-resolution, beam-level assessment of
infrastructure health conditions. A case study focusing on railway track
stiffness estimation with simulated drive-by vibration signals shows that the
model significantly outperforms state-of-the-art methods in estimating railway
ballast and railpad stiffness parameters. Results underscore the potential of
this approach for accurate, localized, and fully automated drive-by
infrastructure health monitoring.

</details>


### [46] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun, Mihaela van der Schaar*

**主要类别:** cs.LG

**AI概要:** 本文综述了通过逆向强化学习（IRL）在大型语言模型（LLM）对齐方面的最新进展，强调了构建神经奖励模型的重要性，并探讨了该领域的方法论、实践方面及未来研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLMs）的发展，如何使这些模型更加可靠、可控和高效成为一个基本而具有挑战性的问题。强化学习（RL）在推理模型和对话AI系统中的成功应用，促使更多研究关注RL与LLM对齐的交叉领域。

**方法:** 文章主要通过逆向强化学习（IRL）的视角来审视LLM对齐的最近进展，对比了LLM对齐中使用的RL技术和传统RL任务的区别，并强调了从人类数据中构建神经奖励模型的必要性。

**结果:** 文章提供了一个结构化的批判性概述，突出了未解决的挑战，并指出了通过RL和IRL技术改进LLM对齐的有希望的研究方向。

**结论:** 通过综合来自不同研究的发现，文章提供了关于LLM对齐领域的结构化和批判性的概述，强调了尚未解决的挑战，并勾勒出未来改进LLM对齐的有希望的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inverse+Reinforcement+Learning+Meets+Large+Language+Model+Post-Training%3A+Basics%2C+Advances%2C+and+Opportunities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13158，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13158&send_immediately=true&force_search=false)

**原文摘要:** In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


### [47] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
*ShanBin Liu*

**主要类别:** cs.LG

**AI概要:** 提出FedGA算法，通过Gini系数衡量客户性能差异并调整全局模型更新规模和聚合权重，以改善联邦学习中的公平性。实验表明该方法有效提高了公平性指标，并保持了整体性能。


<details>
  <summary>更多</summary>
  
**动机:** 在水平联邦学习环境中，数据异质性导致客户之间的性能差异显著，从而引发对模型行为公平性的担忧。

**方法:** 使用Gini系数衡量客户间的性能差异，建立Gini系数与全局模型更新规模的关系，根据系统的实时公平状态动态调整聚合权重。

**结果:** 在Office-Caltech-10、CIFAR-10和Synthetic数据集上的实验表明，FedGA有效地改善了如方差和Gini系数等公平性指标，同时保持了强大的整体性能。

**结论:** FedGA是一种有效的公平性感知的联邦学习算法，可以改善客户间的性能差异，提高模型的公平性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedGA%3A+A+Fair+Federated+Learning+Framework+Based+on+the+Gini+Coefficient，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12983，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12983&send_immediately=true&force_search=false)

**原文摘要:** Fairness has emerged as one of the key challenges in federated learning. In
horizontal federated settings, data heterogeneity often leads to substantial
performance disparities across clients, raising concerns about equitable model
behavior. To address this issue, we propose FedGA, a fairness-aware federated
learning algorithm. We first employ the Gini coefficient to measure the
performance disparity among clients. Based on this, we establish a relationship
between the Gini coefficient $G$ and the update scale of the global model
${U_s}$, and use this relationship to adaptively determine the timing of
fairness intervention. Subsequently, we dynamically adjust the aggregation
weights according to the system's real-time fairness status, enabling the
global model to better incorporate information from clients with relatively
poor performance.We conduct extensive experiments on the Office-Caltech-10,
CIFAR-10, and Synthetic datasets. The results show that FedGA effectively
improves fairness metrics such as variance and the Gini coefficient, while
maintaining strong overall performance, demonstrating the effectiveness of our
approach.

</details>


### [48] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
*Zikai Xie, Linjiang Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于排序算法生成置换空间核函数的新框架，引入了Merge Kernel以降低复杂度并提高效率，同时结合三个轻量级描述符增强了鲁棒性和不变性。实验表明，新方法在各种置换优化基准上优于现有的Mallows核。


<details>
  <summary>更多</summary>
  
**动机:** 当前最先进的贝叶斯优化（BO）方法在置换空间上的处理依赖于Mallows核，其复杂度为Ω(n^2)，需要明确枚举每一对比较。为了提高效率和适用性，作者受到Mallows核与成对比较之间紧密关系的启发，提出了改进的方法。

**方法:** 作者提出了一个基于排序算法生成核函数的新框架，并在此框架下将Mallows核视为由冒泡排序派生的特例。此外，还介绍了由归并排序构建的Merge Kernel，它将复杂度从二次降低到线性对数级别。为了进一步提升鲁棒性和右不变性，作者加入了三个任务无关的描述符：位移直方图、分割对线和滑动窗口基序。

**结果:** 实验评估证明，所提出的核函数在多个置换优化基准测试中始终优于最新的Mallows核。结果确认Merge Kernel提供了一个更紧凑且更有效的解决方案。

**结论:** 该研究开发了一个新的框架和Merge Kernel，能够显著减少计算复杂度，同时保持甚至提高了在置换空间内进行贝叶斯优化的有效性。通过结合额外的描述符，该方法不仅更加紧凑，而且更加鲁棒和不变。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge+Kernel+for+Bayesian+Optimization+on+Permutation+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13263，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13263&send_immediately=true&force_search=false)

**原文摘要:** Bayesian Optimization (BO) algorithm is a standard tool for black-box
optimization problems. The current state-of-the-art BO approach for permutation
spaces relies on the Mallows kernel-an $\Omega(n^2)$ representation that
explicitly enumerates every pairwise comparison. Inspired by the close
relationship between the Mallows kernel and pairwise comparison, we propose a
novel framework for generating kernel functions on permutation space based on
sorting algorithms. Within this framework, the Mallows kernel can be viewed as
a special instance derived from bubble sort. Further, we introduce the
\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic
complexity with $\Theta(n\log n)$ to achieve the lowest possible complexity.
The resulting feature vector is significantly shorter, can be computed in
linearithmic time, yet still efficiently captures meaningful permutation
distances. To boost robustness and right-invariance without sacrificing
compactness, we further incorporate three lightweight, task-agnostic
descriptors: (1) a shift histogram, which aggregates absolute element
displacements and supplies a global misplacement signal; (2) a split-pair line,
which encodes selected long-range comparisons by aligning elements across the
two halves of the whole permutation; and (3) sliding-window motifs, which
summarize local order patterns that influence near-neighbor objectives. Our
empirical evaluation demonstrates that the proposed kernel consistently
outperforms the state-of-the-art Mallows kernel across various permutation
optimization benchmarks. Results confirm that the Merge Kernel provides a more
compact yet more effective solution for Bayesian optimization in permutation
space.

</details>


### [49] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
*Luis Basora, Louison Bocquet-Nouaille, Elinirina Robinson, Serge Le Gonidec*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于时间卷积自编码器的机载故障检测和诊断能力的解决方案，该方案可以自动从原始传感器数据中提取低维特征，并使用基于直方图的梯度提升模型进行分类，还采用了简单有效的技术如累积和控制图来限制误报。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法无法满足广泛的关键要求，例如估计预测的置信水平、检测分布外（OOD）案例和控制误报。因此，需要一种新的方法来提高下一代可重复使用的太空发射器的健康监测系统中的电气系统的故障检测和诊断能力。

**方法:** 该方法首先利用时间卷积自编码器自动从原始传感器数据中提取低维特征。然后，分别在自编码器潜在空间和残差空间上训练二元和多类分类器进行故障检测和诊断。这些分类器是基于直方图的梯度提升模型，经过校准后可以输出概率作为置信水平。为了识别分布外的数据，采用归纳一致性异常检测技术。此外，还使用了其他简单但有效的方法，如累积和控制图以限制误报，以及通过移动阈值解决故障检测中的类别不平衡问题。

**结果:** 该框架在模拟数据上进行了评估，涵盖了名义和异常操作场景。结果表明，所提出的解决方案是一个有希望的第一步，尽管需要使用真实数据进行测试，以确保其达到运营使用所需的成熟度水平。

**结论:** 虽然该解决方案在模拟数据上显示出良好的性能，但在实际应用之前，仍需进一步验证其在真实环境下的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fault+detection+and+diagnosis+for+the+engine+electrical+system+of+a+space+launcher+based+on+a+temporal+convolutional+autoencoder+and+calibrated+classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13022，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13022&send_immediately=true&force_search=false)

**原文摘要:** In the context of the health monitoring for the next generation of reusable
space launchers, we outline a first step toward developing an onboard fault
detection and diagnostic capability for the electrical system that controls the
engine valves. Unlike existing approaches in the literature, our solution is
designed to meet a broader range of key requirements. This includes estimating
confidence levels for predictions, detecting out-of-distribution (OOD) cases,
and controlling false alarms. The proposed solution is based on a temporal
convolutional autoencoder to automatically extract low-dimensional features
from raw sensor data. Fault detection and diagnosis are respectively carried
out using a binary and a multiclass classifier trained on the autoencoder
latent and residual spaces. The classifiers are histogram-based gradient
boosting models calibrated to output probabilities that can be interpreted as
confidence levels. A relatively simple technique, based on inductive conformal
anomaly detection, is used to identify OOD data. We leverage other simple yet
effective techniques, such as cumulative sum control chart (CUSUM) to limit the
false alarms, and threshold moving to address class imbalance in fault
detection. The proposed framework is highly configurable and has been evaluated
on simulated data, covering both nominal and anomalous operational scenarios.
The results indicate that our solution is a promising first step, though
testing with real data will be necessary to ensure that it achieves the
required maturity level for operational use.

</details>


### [50] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
*Ahmed Emam, Ribana Roscher*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为Confidence-Filtered Relevance (CFR)的数据中心框架，结合了LRP注意力回滚和深度确定性不确定性（DDU）估计方法，用于分析模型不确定性如何影响相关性热图的可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 当前使用卫星图像和机器学习大规模监测自然保护区的方法往往缺乏可解释性和对不确定性的认识，并且没有解决不确定性如何影响自然度评估的问题。

**方法:** 提出了Confidence-Filtered Relevance (CFR)，这是一种数据驱动的框架，它将LRP注意力回滚与深度确定性不确定性（DDU）估计相结合，以分析模型不确定性如何影响相关性热图的解释性。CFR根据不确定性阈值将数据集划分为子集，从而系统地分析不确定性如何塑造卫星图像中自然度的解释。

**结果:** 应用于AnthroProtect数据集时，CFR赋予灌木地、森林和湿地更高的相关性，这与其他关于自然度评估的研究一致。随着不确定性的增加，这些相关性热图的可解释性下降，熵增大，表明选择性较低，归属更模糊。

**结论:** CFR提供了一种基于其关联确定性来评估卫星图像中模式与自然度相关性的数据中心方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Confidence-Filtered+Relevance+%28CFR%29%3A+An+Interpretable+and+Uncertainty-Aware+Machine+Learning+Framework+for+Naturalness+Assessment+in+Satellite+Imagery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13034&send_immediately=true&force_search=false)

**原文摘要:** Protected natural areas play a vital role in ecological balance and ecosystem
services. Monitoring these regions at scale using satellite imagery and machine
learning is promising, but current methods often lack interpretability and
uncertainty-awareness, and do not address how uncertainty affects naturalness
assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a
data-centric framework that combines LRP Attention Rollout with Deep
Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty
influences the interpretability of relevance heatmaps. CFR partitions the
dataset into subsets based on uncertainty thresholds, enabling systematic
analysis of how uncertainty shapes the explanations of naturalness in satellite
imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to
shrublands, forests, and wetlands, aligning with other research on naturalness
assessment. Moreover, our analysis shows that as uncertainty increases, the
interpretability of these relevance heatmaps declines and their entropy grows,
indicating less selective and more ambiguous attributions. CFR provides a
data-centric approach to assess the relevance of patterns to naturalness in
satellite imagery based on their associated certainty.

</details>


### [51] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
*Lefei Shen, Mouxiang Chen, Han Fu, Xiaoxue Ren, Xiaoyun Joy Wang, Jianling Sun, Zhuo Li, Chenghao Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的分类法，以解开不同的Transformer架构对长期时间序列预测任务的影响，并通过实验得出了一些关键见解。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于Transformer的模型在长期时间序列预测中占据了主导地位，但其架构变化使得难以确定哪种架构最有效。此外，现有模型通常与各种时间序列特定设计紧密耦合，这使得难以孤立地评估架构本身的影响。

**方法:** 作者提出了一种新的分类法，该分类法考虑了注意力机制、预测聚合、预测范式和归一化层等关键方面，以更清晰、更统一的方式比较不同的Transformer架构。

**结果:** 通过广泛的实验，研究者发现双向注意与联合注意最为有效；更完整的预测聚合可以提高性能；直接映射范式优于自回归方法。

**结论:** 结合最优架构选择的模型在多个数据集上持续优于现有模型，验证了研究结论的有效性。研究者希望这些发现能为未来关于Transformer架构设计的研究提供有价值的指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Power+of+Architecture%3A+Deep+Dive+into+Transformer+Architectures+for+Long-Term+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13043，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13043&send_immediately=true&force_search=false)

**原文摘要:** Transformer-based models have recently become dominant in Long-term Time
Series Forecasting (LTSF), yet the variations in their architecture, such as
encoder-only, encoder-decoder, and decoder-only designs, raise a crucial
question: What Transformer architecture works best for LTSF tasks? However,
existing models are often tightly coupled with various time-series-specific
designs, making it difficult to isolate the impact of the architecture itself.
To address this, we propose a novel taxonomy that disentangles these designs,
enabling clearer and more unified comparisons of Transformer architectures. Our
taxonomy considers key aspects such as attention mechanisms, forecasting
aggregations, forecasting paradigms, and normalization layers. Through
extensive experiments, we uncover several key insights: bi-directional
attention with joint-attention is most effective; more complete forecasting
aggregation improves performance; and the direct-mapping paradigm outperforms
autoregressive approaches. Furthermore, our combined model, utilizing optimal
architectural choices, consistently outperforms several existing models,
reinforcing the validity of our conclusions. We hope these findings offer
valuable guidance for future research on Transformer architectural designs in
LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.

</details>


### [52] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
*Vittorio Cipriani, Valentino Delle Rose, Luca San Mauro, Giovanni Solda*

**主要类别:** cs.LG

**AI概要:** 研究了由可数无限图G的副本形成假设类的PAC和在线学习能力，其中每个副本通过排列G的顶点来诱导。主要结果表明所有有限支持副本的PAC学习能力意味着G的完整同构类型的在线学习能力，并等价于自动态平凡性条件。还使用无限随机图的扩展属性的放松特性描述了不可学习图形的特征。对于所有G和k>2，k顶点排列的学习能力等价于2顶点排列的学习能力，从而产生无限图的四类划分。


<details>
  <summary>更多</summary>
  
**动机:** 为了理解特定假设类的PAC和在线学习能力，特别是由可数无限图G的副本形成的假设类，这些副本是由重新排列G的顶点所引起的。

**方法:** 考虑具有有限移动顶点的类。证明PAC学习能力暗示了完整的在线学习能力，并且这种能力与自动态平凡性条件等价。使用无限随机图的扩展属性的放松版本描述了两个顶点交换副本的非学习性的图的特征。证明对于所有G和k>2，k个顶点排列的学习能力等价于两个顶点排列的学习能力。

**结果:** 得出PAC学习能力等价于自动态平凡性条件。定义了一个四类划分的无限图，并确定了其复杂性。

**结论:** 研究展示了PAC学习能力和在线学习能力之间的关系，并为无限图提供了一个新的分类方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+statistical+learning+of+graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13054&send_immediately=true&force_search=false)

**原文摘要:** We study PAC and online learnability of hypothesis classes formed by copies
of a countably infinite graph G, where each copy is induced by permuting G's
vertices. This corresponds to learning a graph's labeling, knowing its
structure and label set. We consider classes where permutations move only
finitely many vertices. Our main result shows that PAC learnability of all such
finite-support copies implies online learnability of the full isomorphism type
of G, and is equivalent to the condition of automorphic triviality. We also
characterize graphs where copies induced by swapping two vertices are not
learnable, using a relaxation of the extension property of the infinite random
graph. Finally, we show that, for all G and k>2, learnability for k-vertex
permutations is equivalent to that for 2-vertex permutations, yielding a
four-class partition of infinite graphs, whose complexity we also determine
using tools coming from both descriptive set theory and computability theory.

</details>


### [53] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
*Pengjin Wu, Ferrante Neri, Zhenhua Feng*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法，Differentiable Architecture Search for Vision Transformer (DASViT)，以解决现有Vision Transformer架构搜索方法中的不足。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经结构搜索方法在应用于Vision Transformers时存在难以发现创新设计、需要大量计算资源和耗时的问题。

**方法:** 引入了Differentiable Architecture Search for Vision Transformer (DASViT)，这是一种用于Vision Transformer的可微分架构搜索方法。

**结果:** 实验表明，DASViT提供的架构打破了传统的Transformer编码器设计，在多个数据集上超越了ViT-B/16，并且用更少的参数和FLOPs实现了更高的效率。

**结论:** DASViT为Vision Transformer的架构搜索提供了一种新的、更有效的方法，能够发现新颖的设计并提高效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DASViT%3A+Differentiable+Architecture+Search+for+Vision+Transformer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13079，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13079&send_immediately=true&force_search=false)

**原文摘要:** Designing effective neural networks is a cornerstone of deep learning, and
Neural Architecture Search (NAS) has emerged as a powerful tool for automating
this process. Among the existing NAS approaches, Differentiable Architecture
Search (DARTS) has gained prominence for its efficiency and ease of use,
inspiring numerous advancements. Since the rise of Vision Transformers (ViT),
researchers have applied NAS to explore ViT architectures, often focusing on
macro-level search spaces and relying on discrete methods like evolutionary
algorithms. While these methods ensure reliability, they face challenges in
discovering innovative architectural designs, demand extensive computational
resources, and are time-intensive. To address these limitations, we introduce
Differentiable Architecture Search for Vision Transformer (DASViT), which
bridges the gap in differentiable search for ViTs and uncovers novel designs.
Experiments show that DASViT delivers architectures that break traditional
Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and
achieve superior efficiency with fewer parameters and FLOPs.

</details>


### [54] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
*Hyo-Jeong Jang, Hye-Bin Shin, Seong-Whan Lee*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的跨模态知识蒸馏框架，通过原型相似性模块和任务特定蒸馏头对齐特征语义并解决标签不一致问题，以改善脑电图学习的性能。


<details>
  <summary>更多</summary>
  
**动机:** EEG信号易受内在信号错误和人为标注错误的影响，导致标签噪声并降低模型性能。现有的多模态知识蒸馏方法虽然可以提高EEG学习效果，但面临模态差异和软标签错位的问题。

**方法:** 提出一个包含原型相似性模块和任务特定蒸馏头的跨模态知识蒸馏框架，用以缓解模态和标签不一致性。

**结果:** 实验结果表明，该方法在基于EEG的情绪回归和分类任务上的表现优于单模态和多模态基准方法。

**结论:** 该框架展示了其在BCI应用中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Uncertainty-Aware+Cross-Modal+Knowledge+Distillation+with+Prototype+Learning+for+Multimodal+Brain-Computer+Interfaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13092，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13092&send_immediately=true&force_search=false)

**原文摘要:** Electroencephalography (EEG) is a fundamental modality for cognitive state
monitoring in brain-computer interfaces (BCIs). However, it is highly
susceptible to intrinsic signal errors and human-induced labeling errors, which
lead to label noise and ultimately degrade model performance. To enhance EEG
learning, multimodal knowledge distillation (KD) has been explored to transfer
knowledge from visual models with rich representations to EEG-based models.
Nevertheless, KD faces two key challenges: modality gap and soft label
misalignment. The former arises from the heterogeneous nature of EEG and visual
feature spaces, while the latter stems from label inconsistencies that create
discrepancies between ground truth labels and distillation targets. This paper
addresses semantic uncertainty caused by ambiguous features and weakly defined
labels. We propose a novel cross-modal knowledge distillation framework that
mitigates both modality and label inconsistencies. It aligns feature semantics
through a prototype-based similarity module and introduces a task-specific
distillation head to resolve label-induced inconsistency in supervision.
Experimental results demonstrate that our approach improves EEG-based emotion
regression and classification performance, outperforming both unimodal and
multimodal baselines on a public multimodal dataset. These findings highlight
the potential of our framework for BCI applications.

</details>


### [55] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
*Yuanxin Zhuang, Dazhong Shen, Ying Sun*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的生成框架Neural Graph Topic Model (NGTM)，它可以在保持竞争力的生成质量的同时，实现细粒度控制和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图生成方法在生成逼真图形方面取得了相当大的成功，但它们的可解释性仍然有限，通常会模糊结构决策背后的原理。

**方法:** 受自然语言处理中主题建模的启发，提出了神经图主题模型（NGTM），该模型将图表示为潜在主题的混合，每个主题定义了一个语义上有意义的子结构的分布。

**结果:** 实验证明，NGTM在实现竞争力的生成质量的同时，独特地实现了细粒度控制和可解释性，允许用户通过主题级别的调整来调节结构特征或诱导生物特性。

**结论:** NGTM可以实现高质量的图生成，并且在局部和全局尺度上都具有明确的可解释性，使每个生成的图的语义追踪变得清晰。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NGTM%3A+Substructure-based+Neural+Graph+Topic+Model+for+Interpretable+Graph+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13133，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13133&send_immediately=true&force_search=false)

**原文摘要:** Graph generation plays a pivotal role across numerous domains, including
molecular design and knowledge graph construction. Although existing methods
achieve considerable success in generating realistic graphs, their
interpretability remains limited, often obscuring the rationale behind
structural decisions. To address this challenge, we propose the Neural Graph
Topic Model (NGTM), a novel generative framework inspired by topic modeling in
natural language processing. NGTM represents graphs as mixtures of latent
topics, each defining a distribution over semantically meaningful
substructures, which facilitates explicit interpretability at both local and
global scales. The generation process transparently integrates these topic
distributions with a global structural variable, enabling clear semantic
tracing of each generated graph. Experiments demonstrate that NGTM achieves
competitive generation quality while uniquely enabling fine-grained control and
interpretability, allowing users to tune structural features or induce
biological properties through topic-level adjustments.

</details>


### [56] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
*Maksim Borisov, Egor Spirin, Daria Diatlova*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一个新的开放获取数据集NonverbalTTS，该数据集包含10种非语言发声类型和8种情感类别，并展示了使用此数据集微调的开源语音合成模型与闭源系统相比具有同等性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前表现力语音合成模型受到开源数据集中多样化非语言发声（NVs）有限可用性的限制。为了解决这个问题，研究人员创建了NonverbalTTS数据集。

**方法:** 数据集从VoxCeleb和Expresso来源中提取，通过自动检测并由人工验证生成。研究提出了一种综合管道，整合了自动语音识别、非语言发声标记、情感分类和融合算法。

**结果:** 在NVTTS数据集上微调的开源文本到语音模型在人类评估和自动指标方面均达到了与CosyVoice2等闭源系统相当的水平。

**结论:** 通过发布NonverbalTTS及其配套的标注指南，解决了表现力文本到语音研究中的关键瓶颈问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NonverbalTTS%3A+A+Public+English+Corpus+of+Text-Aligned+Nonverbal+Vocalizations+with+Emotion+Annotations+for+Text-to-Speech，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13155，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13155&send_immediately=true&force_search=false)

**原文摘要:** Current expressive speech synthesis models are constrained by the limited
availability of open-source datasets containing diverse nonverbal vocalizations
(NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access
dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional
categories. The dataset is derived from popular sources, VoxCeleb and Expresso,
using automated detection followed by human validation. We propose a
comprehensive pipeline that integrates automatic speech recognition (ASR), NV
tagging, emotion classification, and a fusion algorithm to merge transcriptions
from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models
on the NVTTS dataset achieves parity with closed-source systems such as
CosyVoice2, as measured by both human evaluation and automatic metrics,
including speaker similarity and NV fidelity. By releasing NVTTS and its
accompanying annotation guidelines, we address a key bottleneck in expressive
TTS research. The dataset is available at
https://huggingface.co/datasets/deepvk/NonverbalTTS.

</details>


### [57] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
*Ofir Nabati, Bo Dai, Shie Mannor, Guy Tennenholtz*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架——Spectral Bellman Representation，它基于零内在Bellman误差条件下的特征协方差结构，通过简单修改现有算法，使学习到的状态-动作特征与Bellman更新结构对齐，从而改善了强化学习中的探索和整体性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的表示学习方法主要从模型学习角度出发，无法很好地与强化学习任务对齐。为了解决这个问题，需要一种直接面向基于价值的强化学习的表示方法。

**方法:** 作者引入了Spectral Bellman Representation框架，该框架源自于内在Bellman误差（IBE）条件，揭示了在零IBE条件下，价值函数分布经由Bellman算子变换后与特征协方差结构之间存在根本的谱关系。

**结果:** 所提出的方法通过对现有算法进行简单修改，实现了特征协方差与Bellman动态的对齐，提高了结构化探索能力，并在困难探索和长时信用分配任务中表现优异。此外，该框架可以自然地扩展到多步Bellman算子上。

**结论:** Spectral Bellman Representation提供了一个原则性和有效性的路径，以学习更强大和结构合理的基于价值的强化学习表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spectral+Bellman+Method%3A+Unifying+Representation+and+Exploration+in+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13181，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13181&send_immediately=true&force_search=false)

**原文摘要:** The effect of representation has been demonstrated in reinforcement learning,
from both theoretical and empirical successes. However, the existing
representation learning mainly induced from model learning aspects, misaligning
with our RL tasks. This work introduces Spectral Bellman Representation, a
novel framework derived from the Inherent Bellman Error (IBE) condition, which
aligns with the fundamental structure of Bellman updates across a space of
possible value functions, therefore, directly towards value-based RL. Our key
insight is the discovery of a fundamental spectral relationship: under the
zero-IBE condition, the transformation of a distribution of value functions by
the Bellman operator is intrinsically linked to the feature covariance
structure. This spectral connection yields a new, theoretically-grounded
objective for learning state-action features that inherently capture this
Bellman-aligned covariance. Our method requires a simple modification to
existing algorithms. We demonstrate that our learned representations enable
structured exploration, by aligning feature covariance with Bellman dynamics,
and improve overall performance, particularly in challenging hard-exploration
and long-horizon credit assignment tasks. Our framework naturally extends to
powerful multi-step Bellman operators, further broadening its impact. Spectral
Bellman Representation offers a principled and effective path toward learning
more powerful and structurally sound representations for value-based
reinforcement learning.

</details>


### [58] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
*Shreyas Chaudhari, Srinivasa Pranav, José M. F. Moura*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法，利用单调梯度网络（mGradNets）直接学习最优传输映射。通过最小化基于Monge-Ampère方程定义的训练损失函数，该方法在机器人集群控制问题上展示了良好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 最优传输问题在现代应用中扮演着重要角色，从流体动力学到机器人集群控制。然而，解决这些问题需要有效的工具来参数化单调梯度映射的空间。

**方法:** 作者使用了单调梯度网络（mGradNets），这是一种能够直接参数化单调梯度映射空间的神经网络，并通过最小化一个基于Monge-Ampère方程定义的训练损失函数来学习最优传输映射。

**结果:** 实验表明，mGradNets的结构偏差有助于学习最优传输映射，并且该方法被成功应用于一个机器人集群控制问题。

**结论:** mGradNets为学习最优传输映射提供了一个有效的方法，并可能对涉及最优传输问题的应用产生影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GradNetOT%3A+Learning+Optimal+Transport+Maps+with+GradNets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13191，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13191&send_immediately=true&force_search=false)

**原文摘要:** Monotone gradient functions play a central role in solving the Monge
formulation of the optimal transport problem, which arises in modern
applications ranging from fluid dynamics to robot swarm control. When the
transport cost is the squared Euclidean distance, Brenier's theorem guarantees
that the unique optimal map is the gradient of a convex function, namely a
monotone gradient map, and it satisfies a Monge-Amp\`ere equation. In
[arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks
(mGradNets), neural networks that directly parameterize the space of monotone
gradient maps. In this work, we leverage mGradNets to directly learn the
optimal transport mapping by minimizing a training loss function defined using
the Monge-Amp\`ere equation. We empirically show that the structural bias of
mGradNets facilitates the learning of optimal transport maps and employ our
method for a robot swarm control problem.

</details>


### [59] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
*Etienne Le Naour, Tahar Nabil, Ghislain Agoua*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种新的时间序列插补模型MoTM，利用隐式神经表示和岭回归器来处理域内和域外的缺失值问题。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，时间序列基础模型的研究主要集中在预测任务上，而对域外缺失值插补这一关键任务却关注较少。为了填补这一空白，研究者们提出了利用隐式神经表示（INRs）的方法，但这些方法在分布变化下表现不佳。

**方法:** 引入了MoTM（Mixture of Timeflow Models），它结合了多个独立训练的INRs和一个适应观察上下文的岭回归器，以应对新时间序列是以前见过的模式的混合这一观点。

**结果:** 通过各种插补场景（如块状和逐点缺失、可变采样率）展示了MoTM在域内和域外泛化上的稳健性。

**结论:** MoTM为时间序列插补提供了一个灵活的基础模型，为未来的研究铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoTM%3A+Towards+a+Foundation+Model+for+Time+Series+Imputation+based+on+Continuous+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13207，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13207&send_immediately=true&force_search=false)

**原文摘要:** Recent years have witnessed a growing interest for time series foundation
models, with a strong emphasis on the forecasting task. Yet, the crucial task
of out-of-domain imputation of missing values remains largely underexplored. We
propose a first step to fill this gap by leveraging implicit neural
representations (INRs). INRs model time series as continuous functions and
naturally handle various missing data scenarios and sampling rates. While they
have shown strong performance within specific distributions, they struggle
under distribution shifts. To address this, we introduce MoTM (Mixture of
Timeflow Models), a step toward a foundation model for time series imputation.
Building on the idea that a new time series is a mixture of previously seen
patterns, MoTM combines a basis of INRs, each trained independently on a
distinct family of time series, with a ridge regressor that adapts to the
observed context at inference. We demonstrate robust in-domain and
out-of-domain generalization across diverse imputation scenarios (e.g., block
and pointwise missingness, variable sampling rates), paving the way for
adaptable foundation imputation models.

</details>


### [60] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
*Maria Margarida Mascarenhas, Jilles De Blauwe, Mikael Amelin, Hussain Kazmi*

**主要类别:** cs.LG

**AI概要:** 本文研究了不同关闸时间（GCTs）的市场异步发布的价格是否能提高其他市场预测准确性，使用集成模型在比利时和瑞典市场分别实现了22%和9%的准确率提升。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，数据驱动技术在短期电价预测方面取得了高精度，但依赖于输入协变量的质量。本研究旨在探讨不同关闸时间（GCTs）的市场异步发布的价格能否提高其他市场的预测准确性。

**方法:** 研究采用了最新的集成模型，并结合了与比利时和瑞典市场互联且关闸时间较早的市场价格数据（德国-卢森堡、奥地利和瑞士）。

**结果:** 在比利时和瑞典市场中，通过包含来自关闸时间更早的市场的价格数据，预测准确率分别提高了22%和9%，并且这种改善适用于一般及极端市场条件。

**结论:** 研究结果表明，频繁的模型重新校准虽能提高准确性但也增加了计算成本，同时并非使用更多市场的数据总能带来更好的性能。这为欧洲能源市场参与者和决策者优化投标策略提供了宝贵的指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Asynchronous+Cross-border+Market+Data+for+Improved+Day-Ahead+Electricity+Price+Forecasting+in+European+Markets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13250，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13250&send_immediately=true&force_search=false)

**原文摘要:** Accurate short-term electricity price forecasting is crucial for
strategically scheduling demand and generation bids in day-ahead markets. While
data-driven techniques have shown considerable prowess in achieving high
forecast accuracy in recent years, they rely heavily on the quality of input
covariates. In this paper, we investigate whether asynchronously published
prices as a result of differing gate closure times (GCTs) in some bidding zones
can improve forecasting accuracy in other markets with later GCTs. Using a
state-of-the-art ensemble of models, we show significant improvements of 22%
and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3)
respectively, when including price data from interconnected markets with
earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement
holds for both general as well as extreme market conditions. Our analysis also
yields further important insights: frequent model recalibration is necessary
for maximum accuracy but comes at substantial additional computational costs,
and using data from more markets does not always lead to better performance - a
fact we delve deeper into with interpretability analysis of the forecast
models. Overall, these findings provide valuable guidance for market
participants and decision-makers aiming to optimize bidding strategies within
increasingly interconnected and volatile European energy markets.

</details>


### [61] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
*Vincenzo Marco De Luca, Giovanna Varni, Andrea Passerini*

**主要类别:** cs.LG

**AI概要:** 论文提出了TRENN和MT-TRENN，一种新的团队动态建模架构，该架构能够捕捉关系和时间团队动态，并预测多个团队结构。实验结果表明，与仅依赖时间或关系信息的方法相比，本方法性能显著提升，且具有可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的研究未能同时满足社会科学对动态和关系的联合建模需求以及实际应用中对多任务统一模型的需求。因此，需要一种新型架构来弥补这一差距。

**方法:** TRENN架构包括：自动时间图提取器、时间关系编码器、用于团队结构预测的解码器和两个互补的可解释性模块。MT-TRENN在此基础上扩展，通过多任务头代替解码器，使模型能学习共享的社会嵌入并同时预测多种团队结构。

**结果:** 实验结果显示，该方法在预测团队结构方面优于仅使用时间或关系信息的方法，并且其可解释性模块提供了可解释的见解和行动建议以支持团队改进。

**结论:** 此方法特别适合以人为中心的人工智能应用，例如在高风险协作环境中使用的智能决策支持系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Boosting+Team+Modeling+through+Tempo-Relational+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13305&send_immediately=true&force_search=false)

**原文摘要:** Team modeling remains a fundamental challenge at the intersection of
Artificial Intelligence and the Social Sciences. Social Science research
emphasizes the need to jointly model dynamics and relations, while practical
applications demand unified models capable of inferring multiple team
constructs simultaneously, providing interpretable insights and actionable
recommendations to enhance team performance. However, existing works do not
meet these practical demands. To bridge this gap, we present TRENN, a novel
tempo-relational architecture that integrates: (i) an automatic temporal graph
extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct
prediction, and (iv) two complementary explainability modules. TRENN jointly
captures relational and temporal team dynamics, providing a solid foundation
for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task
head, enabling the model to learn shared Social Embeddings and simultaneously
predict multiple team constructs, including Emergent Leadership, Leadership
Style, and Teamwork components. Experimental results demonstrate that our
approach significantly outperforms approaches that rely exclusively on temporal
or relational information. Additionally, experimental evaluation has shown that
the explainability modules integrated in MT-TRENN yield interpretable insights
and actionable suggestions to support team improvement. These capabilities make
our approach particularly well-suited for Human-Centered AI applications, such
as intelligent decision-support systems in high-stakes collaborative
environments.

</details>


### [62] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
*Kyeongjin Ahn, Sungwon Han, Seungeon Lee, Donghyun Ahn, Hyoshin Kim, Jungwon Kim, Jihee Kim, Sangyoon Park, Meeyoung Cha*

**主要类别:** cs.LG

**AI概要:** 本研究引入GeoReg，一种融合多种数据源的回归模型，利用大型语言模型提取特征，以估计社会经济指标，实验表明其在不同发展阶段的国家中均优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 社会经济指标对于政策制定和可持续发展至关重要，但在数据稀缺的地区（如发展中国家）难以获得准确的估算。

**方法:** GeoReg模型结合了卫星图像和基于网络的地理空间信息等多源数据，并利用大型语言模型作为数据工程师提取有用特征，这些特征根据与目标指标的相关性分为正、负、混合或无关四类，并赋予不同的权重限制，同时模型还捕捉非线性模式并将其整合。

**结果:** 在三个不同发展阶段的国家进行的实验表明，该模型即使在低收入且数据有限的国家也能优于基线模型来估算社会经济指标。

**结论:** GeoReg为数据稀缺地区提供了一种有效的社会经济指标估算方法，有助于更广泛地支持政策决策和可持续发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GeoReg%3A+Weight-Constrained+Few-Shot+Regression+for+Socio-Economic+Estimation+using+LLM，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13323，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13323&send_immediately=true&force_search=false)

**原文摘要:** Socio-economic indicators like regional GDP, population, and education
levels, are crucial to shaping policy decisions and fostering sustainable
development. This research introduces GeoReg a regression model that integrates
diverse data sources, including satellite imagery and web-based geospatial
information, to estimate these indicators even for data-scarce regions such as
developing countries. Our approach leverages the prior knowledge of large
language model (LLM) to address the scarcity of labeled data, with the LLM
functioning as a data engineer by extracting informative features to enable
effective estimation in few-shot settings. Specifically, our model obtains
contextual relationships between data features and the target indicator,
categorizing their correlations as positive, negative, mixed, or irrelevant.
These features are then fed into the linear estimator with tailored weight
constraints for each category. To capture nonlinear patterns, the model also
identifies meaningful feature interactions and integrates them, along with
nonlinear transformations. Experiments across three countries at different
stages of development demonstrate that our model outperforms baselines in
estimating socio-economic indicators, even for low-income countries with
limited data availability.

</details>


### [63] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
*Laker Newhouse, R. Preston Hess, Franz Cesista, Andrii Zahorodnii, Jeremy Bernstein, Phillip Isola*

**主要类别:** cs.LG

**AI概要:** 本文探讨了通过Lipschitz约束训练transformer模型的方法，以解决神经网络对输入和权重扰动的高度敏感性。研究发现优化器动力学影响显著，并开发了一种新的权重约束方法改善了Lipschitz与性能之间的权衡。尽管在扩大参数规模时Lipschitz上界大幅增加，但这些模型能够在不使用稳定性措施的情况下进行训练。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络对于输入和权重的微小变化非常敏感，这可能导致对抗样本的脆弱性、训练发散和过拟合等问题。为了应对这些问题，研究人员试图建立完全由Lipschitz组件组成的神经网络。

**方法:** 作者开发并测试了用于维持范数约束权重矩阵的新工具，并应用这些工具来训练带有Lipschitz界限的transformer模型。此外，他们还改进了优化器从AdamW到Muon，并设计了一种新的权重约束方法。

**结果:** 通过上述方法，2-Lipschitz的transformer在Shakespeare文本上的验证准确率达到60%，10-Lipschitz的transformer在互联网文本上的准确率为21%。然而，在匹配NanoGPT基准验证准确性39.4%时，Lipschitz上限增至10^264。

**结论:** 虽然在扩展参数规模时Lipschitz上界大幅增加，但是这些模型能够在没有如层归一化等稳定措施的情况下成功训练。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+Transformers+with+Enforced+Lipschitz+Constants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13338，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13338&send_immediately=true&force_search=false)

**原文摘要:** Neural networks are often highly sensitive to input and weight perturbations.
This sensitivity has been linked to pathologies such as vulnerability to
adversarial examples, divergent training, and overfitting. To combat these
problems, past research has looked at building neural networks entirely from
Lipschitz components. However, these techniques have not matured to the point
where researchers have trained a modern architecture such as a transformer with
a Lipschitz certificate enforced beyond initialization. To explore this gap, we
begin by developing and benchmarking novel, computationally-efficient tools for
maintaining norm-constrained weight matrices. Applying these tools, we are able
to train transformer models with Lipschitz bounds enforced throughout training.
We find that optimizer dynamics matter: switching from AdamW to Muon improves
standard methods -- weight decay and spectral normalization -- allowing models
to reach equal performance with a lower Lipschitz bound. Inspired by Muon's
update having a fixed spectral norm, we co-design a weight constraint method
that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter
transformers. Our 2-Lipschitz transformer on Shakespeare text reaches
validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz
transformer reaches 21% accuracy on internet text. However, to match the
NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound
increases to 10^264. Nonetheless, our Lipschitz transformers train without
stability measures such as layer norm, QK norm, and logit tanh softcapping.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak, Adam Kostka*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的多智能体AI辅导平台，该平台结合了自适应和个性化的反馈、结构化的课程生成和教科书知识检索，以实现模块化、工具辅助的学习过程。


<details>
  <summary>更多</summary>
  
**动机:** 当前的AI辅导系统在数学领域存在局限性，主要是提供直接答案而不鼓励深入思考或采用结构化的教学工具和策略。

**方法:** 研究人员引入了一个新的多智能体AI辅导平台，它包括自适应和个性化的反馈、结构化的课程生成和教科书知识检索，旨在促进模块化、工具辅助的学习过程。

**结果:** 这个新平台使学生能够学习新主题，同时识别和针对他们的弱点，有效地复习考试，并在无限数量的个性化练习上进行实践。

**结论:** 这项研究为教育中的人工智能领域做出贡献，通过引入将教育代理和AI驱动组件结合起来的新平台，增强了该领域的模块化和有效的数学教学系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AI-Powered+Math+Tutoring%3A+Platform+for+Personalized+and+Adaptive+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12484，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12484&send_immediately=true&force_search=false)

**原文摘要:** The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [65] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley, Jovin D'sa, Hossein Nourkhiz Mahjoub, Gibran Ali*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种改进的博弈论模型，用于高速公路并线场景中的战术决策，具有更合理的收益函数和延迟动作。该模型与底层动力学模型结合，可以捕捉并线交互，并在高保真模拟环境中验证了其计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 为了开发自动驾驶技术，需要增强模拟环境以复制真实世界的驾驶员行为，特别是高速公路入口匝道处车辆的让行动态和战术决策建模。现有的研究要么行动集有限，要么使用参数过多且收益范围有限的收益函数。

**方法:** 作者提出了一个博弈论模型，用于战术决策制定，改进了收益函数和滞后动作。此模型与一个基础的动力学模型相结合，形成一个统一的决策和动力学模型，以捕捉并线互动，提供更加真实的交互模拟。

**结果:** 该模型在用真实数据集验证时，表现出对复杂交互的良好再现性。集成到高保真度模拟环境中后，确认其计算时间效率足够高，适用于支持自动驾驶车辆开发的大规模模拟。

**结论:** 提出的模型能够更好地模拟高速公路并线情景下的真实世界交互，并且具备足够的计算效率，可应用于大规模仿真中，为自动驾驶技术的发展提供了有力的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MR-LDM+--+The+Merge-Reactive+Longitudinal+Decision+Model%3A+Game+Theoretic+Human+Decision+Modeling+for+Interactive+Sim+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12494，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12494&send_immediately=true&force_search=false)

**原文摘要:** Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [66] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于"What"和"How"两个问题的直观分类法，对250多篇关于可解释强化学习（XRL）的论文进行了前沿综述，并提出了该领域需要注意的一些需求和相关领域。


<details>
  <summary>更多</summary>
  
**动机:** 随着深度神经网络的使用，最近AI模型的成功伴随着其内部机制的不透明性。为了解释这些AI模型的输出，提出了许多方法，其中一种是可解释的强化学习（XRL）。

**方法:** 作者提出了一个基于两个问题“是什么”和“怎么样”的直观分类法。第一个问题是解释方法的目标，第二个问题是解释提供的方法。

**结果:** 作者使用这个分类法对超过250篇的论文进行了综述，并提出了一些需要关注的领域。

**结论:** 作者认为XRL领域需要更多的关注，并且他们已经确定了一些未来研究的需求和方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Explainable+Reinforcement+Learning%3A+Targets%2C+Methods+and+Needs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12599，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12599&send_immediately=true&force_search=false)

**原文摘要:** The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [67] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook, Josef Spjut, Jonathan Tremblay*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种自动设计迭代框架，该框架通过将强化学习（RL）代理与大型多模态模型（LMM）配对，以根据玩家行为改进游戏设计。


<details>
  <summary>更多</summary>
  
**动机:** 现代生成系统仅检查游戏的代码或资产，难以捕捉静态规则和内容如何转化为动态玩家行为。为了弥补这一差距，作者提出了一个结合了强化学习代理和大型多模态模型的设计框架。

**方法:** 在每个循环中，RL代理完成多个游戏剧集，产生数值播放指标和/或总结最近视频帧的紧凑图像条。然后LMM接收游戏玩法目标和当前游戏配置，分析播放痕迹，并编辑配置以引导未来的行为朝向目标。

**结果:** 实验结果表明，LMM可以根据由RL代理提供的行为痕迹进行推理，以迭代地改进游戏机制。

**结论:** 这项研究指出了AI辅助游戏设计的实际可行性和可扩展性工具的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fly%2C+Fail%2C+Fix%3A+Iterative+Game+Repair+with+Reinforcement+Learning+and+Large+Multimodal+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12666，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12666&send_immediately=true&force_search=false)

**原文摘要:** Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [68] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack, Carlo Leonardo Attubato, Stefan Heimersheim*

**主要类别:** cs.AI

**AI概要:** 本文通过比较白盒监控和黑盒监控，评估了欺骗探测器的有效性，并发现现有的欺骗探测器在性能上有微弱但令人鼓舞的提升。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI助手偶尔会对用户查询作出欺骗性的回应，研究者训练了线性分类器（称为“欺骗探测器”）以区分语言模型在欺骗性和诚实响应期间的内部激活状态。然而，这些探测器在实际中检测欺骗的效果尚不明确，且不清楚它们是否能抵御来自希望逃避检测的欺骗性助手的简单反制策略。

**方法:** 作者比较了白盒监控（监控者可以访问基于token的探测激活）与黑盒监控（没有这种访问权限）。通过衡量白盒监控相对于黑盒监控的优越程度来对欺骗探测器进行基准测试，即从黑到白的性能提升。

**结果:** 研究发现，现有的欺骗探测器带来了微弱但令人鼓舞的从黑到白的性能提升。

**结论:** 虽然探测器的性能提升并不显著，但这一结果仍为未来的改进提供了积极的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Benchmarking+Deception+Probes+via+Black-to-White+Performance+Boosts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12691，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12691&send_immediately=true&force_search=false)

**原文摘要:** AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [69] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe, Taketoshi Ushiama*

**主要类别:** cs.AI

**AI概要:** 本文旨在开发一个AI代理作为学习伙伴，以实现随时随地的同伴学习，并通过英语作文这一具体例子来验证其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 同伴学习在促进学习者的自发思考方面有显著效果，但人类之间的同伴学习存在诸多限制，不是总是有效。有效的同伴学习需要相同水平的同伴。

**方法:** 研究假设与学习者具有相同熟练程度的同伴会犯同样的错误，并以英语写作为特定实例来验证这种方法。

**结果:** 未提及具体结果。

**结论:** 未提及具体结论。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Imitating+Mistakes+in+a+Learning+Companion+AI+Agent+for+Online+Peer+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12801&send_immediately=true&force_search=false)

**原文摘要:** In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [70] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu, Jielin Qiu, Shiyu Wang, Jianguo Zhang, Zuxin Liu, Roshan Ram, Haolin Chen, Weiran Yao, Huan Wang, Shelby Heinecke, Silvio Savarese, Caiming Xiong*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个名为MCPEval的开源框架，用于自动化生成任务和深度评估跨不同领域的大型语言模型代理。它标准化了指标，与本地代理工具无缝集成，并消除了构建评估管道的手动工作。实证结果表明其在揭示领域特定性能方面的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于静态基准和劳动密集型数据收集的方法限制了对大型语言模型（LLM）代理的实际评估。因此，需要一种更强大、可扩展的评估框架。

**方法:** 作者引入了Model Context Protocol (MCP)为基础的框架，称为MCPEval。该框架实现了任务生成和深度评估的自动化，可以应用于多个领域，并且与本地代理工具无缝集成。

**结果:** 通过五个真实世界领域的实证结果展示了MCPEval的有效性，特别是在揭示细微的、领域特定的性能方面。

**结论:** 为了促进可重复和标准化的LLM代理评估，作者公开发布了MCPEval。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCPEval%3A+Automatic+MCP-based+Deep+Evaluation+for+AI+Agent+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12806，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12806&send_immediately=true&force_search=false)

**原文摘要:** The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [71] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang, Ruiyu Fang, Zhongjiang He, Shuangyong Song, Yongxiang Li*

**主要类别:** cs.AI

**AI概要:** 本文提出了针对情感支持对话任务的解决方案，通过大规模语言模型和微调技术，在NLPCC 2025 ESC评估中取得第二名。


<details>
  <summary>更多</summary>
  
**动机:** 随着对心理健康支持需求的增长，提供同理心和有效的情感援助变得越来越重要。

**方法:** 使用大规模语言模型，并通过提示工程和微调技术进行增强。探索了参数高效的低秩适应和全参数微调策略。

**结果:** 最佳模型在竞赛中排名第二。

**结论:** 未来的工作将集中在进一步提高情感理解能力和响应个性化，以建立更实用和可靠的情感支持系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Emotional+Support+with+LLM-based+Empathetic+Dialogue+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12820，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12820&send_immediately=true&force_search=false)

**原文摘要:** Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [72] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于世界模型归纳的新型AI评估框架，强调了快速适应和有效问题解决的重要性，并提出了通过设计新颖游戏来评估AI系统的建议。


<details>
  <summary>更多</summary>
  
**动机:** 当前对世界模型在人工智能中的理解和评价过于狭隘，往往只关注从大量数据中学习到的静态表示，而忽略了模型在新环境中通过交互和探索学习这些表示的效率和效果。

**方法:** 作者提出了一种新的基准测试范式，基于精心设计的一套具有真正、深入且不断更新新颖性的游戏结构的游戏（称为新颖游戏），以挑战和评估代理的世界模型归纳能力。

**结果:** 该论文没有提供具体的结果，因为它主要是一个观点文章，旨在呼吁建立一个新的评估框架。

**结论:** 作者希望这个新的评估框架能激励未来对世界模型在AI中的评估努力，并向实现具有人类般快速适应和稳健泛化能力的AI系统迈出关键一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Assessing+adaptive+world+models+in+machines+with+novel+games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12821，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12821&send_immediately=true&force_search=false)

**原文摘要:** Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [73] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass, Taylan Akay, Harrison Tolley*

**主要类别:** cs.AI

**AI概要:** 本文研究如何在基于仿真的测试和评估中自动计算道德属性的权重。


<details>
  <summary>更多</summary>
  
**动机:** 当前时代，人类指挥官需要利用现代计算能力来模拟大量场景。然而，在每个场景中，不同的决策设计选项可能会产生伦理后果。如果这些决策依赖于人类判断，不仅会阻碍及时探索大量场景的目标，而且考虑到工作量，让人类参与每个选择是不切实际的。因此，本文将人类判断移出仿真决策周期，旨在解决在仿真运行期间如何动态地权衡道德属性的问题。

**方法:** 本文借鉴多准则决策文献，特别是熵的概念，提出了几种方法来自动计算道德属性的权重。

**结果:** 文章并未具体提及结果，但提出了解决方案的思路，并强调了该问题的重要性。

**结论:** 结论未详细说明，但可以推测作者认为提出的自动计算道德属性权重的方法为解决仿真测试中的伦理决策问题提供了一个新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Information-Theoretic+Aggregation+of+Ethical+Attributes+in+Simulated-Command，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12862，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12862&send_immediately=true&force_search=false)

**原文摘要:** In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [74] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake, Mario Demetroudi, James Walpole, Lindley Lentati, Jason R. Brown, Edward James Young*

**主要类别:** cs.AI

**AI概要:** 前沿AI系统在特定情境中已表现出人类水平的说服和战略性欺骗能力，这对网络安全构成威胁。本文提出了一种评估和缓解此类风险的安全案例框架，围绕无法、控制和可信度三个核心论点构建，并为AI公司提供了一个将操纵风险纳入AI安全治理的系统方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于人类往往是网络安全系统中最薄弱的一环，内部部署的AI系统可能会通过操纵员工来破坏人类监督。然而，对于这种日益增长的威胁，操纵攻击却未得到足够的关注，也没有系统性的框架来评估和减轻这些风险。

**方法:** 本文提出了一个安全案例框架，用于评估和减轻操纵风险。该框架围绕三个核心论点：无法（Inability）、控制（Control）和可信度（Trustworthiness）。为每个论点指定了证据要求、评价方法和实施注意事项，以供AI公司直接应用。

**结果:** 本论文提供了第一个系统性方法，将操纵风险整合到AI安全治理中，为AI公司在部署前评估和减轻这些威胁提供了具体的依据。

**结论:** 为了应对AI系统的操纵风险，必须采用系统的方法进行评估和减轻。本文提供的安全案例框架可以作为AI安全治理的一部分，帮助确保AI系统的安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Manipulation+Attacks+by+Misaligned+AI%3A+Risk+Analysis+and+Safety+Case+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12872，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12872&send_immediately=true&force_search=false)

**原文摘要:** Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [75] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao, Ran Cheng, Kay Chen Tan*

**主要类别:** cs.AI

**AI概要:** 强化学习的进步提高了大型语言模型的数学推理能力，但这些改进可能是由于过度拟合基准模式。本文提出VAR-MATH框架以评估真正的推理能力，并发现在变体测试中RL训练模型性能显著下降，表明现有RL方法依赖表面启发式，无法超越特定数值形式。


<details>
  <summary>更多</summary>
  
**动机:** 作者关注到尽管使用有缺陷的信号训练，强化学习仍能提高大型语言模型在标准基准上的数学推理表现。这引发了关于这种改进是否反映了真实的推理能力的问题。

**方法:** 作者引入了VAR-MATH框架，通过将固定数值问题转换为符号模板，并要求模型解决每个模板的多个实例，从而确保结构上等价变体的一致推理，减少污染并提高评估稳健性。

**结果:** 实验结果显示，在变体版本上，RL训练模型的性能大幅下降，特别是在较小的模型中，AMC23和AIME24的平均降幅分别为48.0%和58.3%。

**结论:** VAR-MATH提供了一个原则性的、抗污染的数学推理评估范式，发现许多现有的RL方法依赖于表面启发式，无法泛化到特定数值形式之外。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VAR-MATH%3A+Probing+True+Mathematical+Reasoning+in+Large+Language+Models+via+Symbolic+Multi-Instance+Benchmarks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12885，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12885&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [76] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu, Fabio Aurelio D'Asaro, Luke Dickens*

**主要类别:** cs.AI

**AI概要:** 论文将PEC领域正式转换为MDP，引入“行动情境”概念，支持时间推理任务和目标驱动规划，并保持解释性。


<details>
  <summary>更多</summary>
  
**动机:** Probabilistic Event Calculus (PEC)在处理不确定环境中的动作及其影响方面表现出色，但在目标导向推理机制上有所欠缺。为了弥补这一不足，该研究开发了一种形式化的翻译方法，将PEC领域转化为Markov Decision Processes (MDPs)，从而可以利用MDP的算法和理论工具来扩展PEC的能力。

**方法:** 通过定义“行动情境”的概念，该研究创建了一种从PEC到MDP的形式化翻译方法，保留了PEC灵活的动作语义，使得能够应用MDP的广泛算法和理论工具到PEC的可解释叙述域中。

**结果:** 这种翻译不仅支持时间推理任务，还支持目标驱动的规划，同时提供了将学习到的策略映射回人类可读的PEC表示的方法，确保了解释性的维持。

**结论:** PEC-MDP形式主义的成功开发意味着可以结合MDP的强大工具与PEC的解释性和表达力，进一步推进动作和事件的概率叙述推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Translation+of+Probabilistic+Event+Calculus+into+Markov+Decision+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12989，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12989&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [77] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri, Filippo Bistaffa, Athina Georgara, Juan Antonio Rodriguez-Aguilar*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为X-MILP的方法，用于为MILP问题建立对比解释。该方法通过约束推理技术来编码用户查询、计算不可约不可行子系统并构建“原因图”，以帮助理解用户的查询结果。


<details>
  <summary>更多</summary>
  
**动机:** 近年来对可信赖AI的关注推动了优化领域中对比解释技术的发展，特别是在解决被形式化为MILPs的特定决策过程方面。

**方法:** 提出的方法称为X-MILP，它首先将用户关于MILP问题解的查询编码为附加约束，然后通过计算新获得的约束集的Irreducible Infeasible Subsystem (IIS)来确定构成回答用户查询的原因，最后将解释表示为从IIS构造的“原因图”。

**结果:** 在知名优化问题实例上测试该方法，以评估计算解释的经验难度。

**结论:** 没有明确提到结论，但可以推测作者认为他们的方法提供了一种新的方式来理解和解释MILP问题的解决方案，从而有助于提高AI的可解释性和信任度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploiting+Constraint+Reasoning+to+Build+Graphical+Explanations+for+Mixed-Integer+Linear+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13007，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13007&send_immediately=true&force_search=false)

**原文摘要:** Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [78] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee, Jaegwan Cho, Yoonju Cho, Seoyoon Choi, Yejin Shin*

**主要类别:** cs.AI

**AI概要:** 研究利用加州高速78号公路的交通数据，使用机器学习模型（MLR和RF）预测交通流量。发现10分钟的数据采集间隔效果最佳。


<details>
  <summary>更多</summary>
  
**动机:** 旨在解决全球交通拥堵问题，提高交通管理效率。

**方法:** 采用了多线性回归(MLR)和随机森林(RF)算法，分析了2022年7月至11月期间来自加州高速78号公路的数据。

**结果:** MLR和RF模型在10分钟的数据收集间隔下表现最优。

**结论:** 本研究结果有助于未来的交通拥堵解决方案及高效的交通管理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prediction+of+Highway+Traffic+Flow+Based+on+Artificial+Intelligence+Algorithms+Using+California+Traffic+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13112&send_immediately=true&force_search=false)

**原文摘要:** The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [79] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul, Simon Malberg*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于动态强化学习的框架，将基于树的推理转化为自适应过程，解决了ProbTree静态实现的问题，提高了解题质量和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 现代语言模型在处理复杂问题时遇到错误传播和知识整合的挑战，而ProbTree框架虽然通过分层结构分解问题并选择答案来缓解这些问题，但其静态实施存在两个关键限制：推理树固定不变，无法动态适应中间结果；每个节点需要穷尽所有可能的解决方案策略，导致计算效率低下。

**方法:** 作者提出了一个动态强化学习框架，该框架根据实时置信度估计增量地构建推理树，并学习用于动作选择（分解、检索或聚合）的最佳策略。这保持了ProbTree的概率严谨性，同时通过选择性扩展和集中资源分配提高了解决方案的质量和计算效率。

**结果:** 该方法维持了ProbTree的概率严谨性，同时显著改善了解决方案的质量和计算效率。

**结论:** 这项工作建立了一个新的基于树结构的推理范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Roots+to+Rewards%3A+Dynamic+Tree+Reasoning+with+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13142，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13142&send_immediately=true&force_search=false)

**原文摘要:** Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [80] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

**主要类别:** cs.AI

**AI概要:** 论文认为传统伦理标准对大型语言模型（LLM）为基础的人工道德代理（AMAs）已不再适用，提出了一套新的评估准则。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）的出现挑战了传统的透明架构假设，其随机输出和不透明内部状态使得传统伦理评估标准在应用于基于LLMs的人工道德代理（AMAs）时显得过时。

**方法:** 作者提出了十个功能性评估标准：道德一致性、情境敏感性、规范完整性、元伦理意识、系统弹性、可靠性、可纠正性、部分透明性、功能自主性和道德想象力，并将这些标准应用到模拟道德代理通过大型语言系统（SMA-LLS）上。

**结果:** 通过假设情景中的自动公共汽车（APB），展示了新提出的评估标准在道德显著环境中的实际应用可能性。

**结论:** 新提出的十项功能性评估标准旨在引导基于LLMs的人工道德代理更接近社会融合和利益最大化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Black+Box+Deployed+--+Functional+Criteria+for+Artificial+Moral+Agents+in+the+LLM+Era，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13175，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13175&send_immediately=true&force_search=false)

**原文摘要:** The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [81] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua, Temur Kutsia*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种结合高阶模式和模糊等价的统一算法，并证明了其终止性、正确性和完备性。


<details>
  <summary>更多</summary>
  
**动机:** 为了应对在决策任务中，需要跨抽象函数和谓词进行推理的问题，而这些问题中的精确匹配往往很少见或不必要。

**方法:** 采用高阶模式和基于最小T-范数相似关系表达的模糊等价这两种计算行为良好的组件相结合的方法，提出了一个高阶模式模下述相似关系的统一算法。

**结果:** 证明了该算法的终止性、正确性和完备性，并且当给定项可统一时，该算法可以计算出具有最高近似度的最一般统一者。

**结论:** 此方法为解决高效推理和计算技术的挑战提供了一个直接的方法，能够用于结合高阶理论和模糊逻辑的决策任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Higher-Order+Pattern+Unification+Modulo+Similarity+Relations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13208，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13208&send_immediately=true&force_search=false)

**原文摘要:** The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [82] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga, Gonzalo Martínez, Eneko Sendin, Javier Conde, Pedro Reviriego*

**主要类别:** cs.AI

**AI概要:** 论文提出了一个名为GEA的平台，该平台在评估大型语言模型时考虑了能源消耗因素。初步结果显示，当用户了解能源消耗情况时，他们更倾向于选择较小且更节能的模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型语言模型（LLM）评估方法存在与人类评价相关性差的问题，同时人工评估的方法又存在扩展性问题。此外，目前越来越多的人开始关注LLM的能源消耗问题。

**方法:** 作者们创建了一个名为GEA（Generative Energy Arena）的新平台，该平台允许用户在评估LLM时参考模型的能源消耗信息。

**结果:** 实验结果表明，当用户提供能源消耗信息时，他们更倾向于选择更小、更节能的模型，这表明复杂和高性能的模型所带来的额外成本和能源消耗并不能显著提高响应的质量。

**结论:** 这篇论文提出的GEA平台为评估大型语言模型提供了一种新的方法，它将能源消耗纳入考量，并发现用户更青睐于小型、高效的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Generative+Energy+Arena+%28GEA%29%3A+Incorporating+Energy+Awareness+in+Large+Language+Model+%28LLM%29+Human+Evaluations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13302，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13302&send_immediately=true&force_search=false)

**原文摘要:** The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [83] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua*

**主要类别:** cs.AI

**AI概要:** 前沿AI模型虽然展示了广泛的知识面，但在面对实际研究问题时，其能力仍远不及人类专家。本文提出了一个名为FormulaOne的基准测试，该测试结合了图论、逻辑和算法，并揭示了现有AI模型在某些领域的理解水平远未达到专家级别。


<details>
  <summary>更多</summary>
  
**动机:** 为了评估AI模型是否接近真正的人类或超人类的专业水平，特别是在解决最困难的问题和推动科学理解的边界方面的能力。

**方法:** 构建了一个名为FormulaOne的基准测试，它位于图论、逻辑和算法的交叉点，并且与实践中的大规模优化问题相关联。此数据集具有商业兴趣，由图形上的单态二阶（MSO）逻辑生成，并与理论计算机科学的前沿紧密相连。

**结果:** 最先进的模型如OpenAI的o3在FormulaOne上完全失败，解决问题的比例不到1%，即使给予10次尝试和解释性少量示例的机会。

**结论:** 这表明当前的AI模型在某些领域距离专家级的理解还有很长的路要走，同时作者也发布了更简单的任务集合FormulaOne-Warmup以支持进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FormulaOne%3A+Measuring+the+Depth+of+Algorithmic+Reasoning+Beyond+Competitive+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13337，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13337&send_immediately=true&force_search=false)

**原文摘要:** Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [84] [Safeguarding Federated Learning-based Road Condition Classification](https://arxiv.org/abs/2507.12568)
*Sheng Liu, Panos Papadimitratos*

**主要类别:** cs.CR

**AI概要:** 本文揭示了联邦学习在基于摄像头的道路状况分类系统中的标签翻转攻击漏洞，并提出了一种防御机制FLARE。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习（FL）作为一种保护隐私的自动驾驶解决方案，虽然不共享敏感图像数据，但其协作特性引入了新的安全漏洞，例如目标标签翻转攻击（TLFAs）。这些攻击可能导致车辆错误分类道路状况，造成安全隐患。

**方法:** 作者提出了一个三重贡献：1) 揭示现有FL-RCC系统对TLFAs的脆弱性；2) 引入一个新的基于标签距离的度量来量化TLFAs带来的安全风险；3) 提出FLARE，一种通过神经元级别的输出层分析以减轻TLFA影响的防御机制。

**结果:** 广泛的实验表明，TLFAs对FL-RCC系统的严重影响以及FLARE在缓解攻击影响方面的有效性。

**结论:** 该研究强调了FL-RCC系统中TLFAs的安全威胁，并验证了FLARE作为有效的防御手段。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Safeguarding+Federated+Learning-based+Road+Condition+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12568，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12568&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) has emerged as a promising solution for
privacy-preserving autonomous driving, specifically camera-based Road Condition
Classification (RCC) systems, harnessing distributed sensing, computing, and
communication resources on board vehicles without sharing sensitive image data.
However, the collaborative nature of FL-RCC frameworks introduces new
vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious
clients (vehicles) deliberately alter their training data labels to compromise
the learned model inference performance. Such attacks can, e.g., cause a
vehicle to mis-classify slippery, dangerous road conditions as pristine and
exceed recommended speed. However, TLFAs for FL-based RCC systems are largely
missing. We address this challenge with a threefold contribution: 1) we
disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce
a novel label-distance-based metric to precisely quantify the safety risks
posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging
neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive
experiments across three RCC tasks, four evaluation metrics, six baselines, and
three deep learning models demonstrate both the severity of TLFAs on FL-RCC
systems and the effectiveness of FLARE in mitigating the attack impact.

</details>


### [85] [On the Consideration of Vanity Address Generation via Identity-Based Signatures](https://arxiv.org/abs/2507.12670)
*Shogo Murasaki, Kazumasa Omote, Keita Emura*

**主要类别:** cs.CR

**AI概要:** 本文探讨了基于身份的签名（IBS）在生成自定义字符地址（vanity address）中的应用可能性，并提出了一种从ECDSA构建IBS的方案，该方案保留了与ECDSA相似的gas成本。


<details>
  <summary>更多</summary>
  
**动机:** 生成自定义字符地址的传统方法是通过试错法，这限制了可嵌入字符的数量。为了克服这一限制，作者考虑使用基于身份的签名（IBS），因为IBS允许任何字符串作为验证密钥。

**方法:** 作者关注的是不替换以太坊目前用于发行交易的ECDSA密钥恢复功能，而是寻求一种通用的IBS构造方法，并由此提出了一个从ECDSA密钥恢复构建IBS的方案。

**结果:** 虽然由于底层ECDSA的密钥恢复功能不能直接生成自定义字符地址，但通过IBS的功能可以将任意字符串与地址关联，从而为地址赋予额外的意义。此外，实验表明该系统的gas成本几乎与ECDSA签名验证相同。

**结论:** 尽管直接用IBS代替ECDSA来生成自定义字符地址不是合理的代价，但是通过从ECDSA密钥恢复构建IBS的方法，可以在保持低gas成本的同时，实现将字符串与地址关联，为用户提供更多便利。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Consideration+of+Vanity+Address+Generation+via+Identity-Based+Signatures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12670，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12670&send_immediately=true&force_search=false)

**原文摘要:** An address is indicated as an identifier of the user on the blockchain, and
is defined by a hash value of the ECDSA verification key. A vanity address is
an address that embeds custom characters such as a name. To generate a vanity
address, a classical try-and-error method is employed, and thus the number of
characters to be embedded is limited. In this paper, we focus on the
functionality of identity-based signatures (IBS) where any strings can be
employed as a verification key, and explore whether IBS can be used for
generating a vanity address. We attach importance to the fact that it is not
realistic to replace ECDSA with key recovery, which is currently employed for
issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is
possible, it is not a reasonable price for the ease of the vanity address
generation. Thus, we pay attention to a generic construction of IBS from
signatures, and construct an IBS scheme from ECDSA with key recovery. Though we
cannot directly generate a vanity address due to the key recovery functionality
of the underlying ECDSA, we can connect any string with an address due to the
functionality of IBS that can give additional meaning to the address. We
implement our system by Solidity, and demonstrate that the gas cost is almost
same as that of the ECDSA signature verification.

</details>


### [86] [Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense](https://arxiv.org/abs/2507.12919)
*Victoria Childress, Josh Collyer, Jodie Knapp*

**主要类别:** cs.CR

**AI概要:** 这篇论文调查了深度神经网络中的架构后门，其嵌入恶意逻辑到模型的计算图中，并探讨检测和防御策略。


<details>
  <summary>更多</summary>
  
**动机:** 作者关注的是架构后门对深度神经网络构成的独特威胁，这种威胁难以被现有的缓解技术发现，并且在重新训练后仍然存在。

**方法:** 该研究通过系统地整合关于架构后门的研究，评估了现有检测和防御策略的效果，并指出了它们的局限性。

**结果:** 尽管最近取得了一些进展，但是可扩展且实用的防御措施仍然难以捉摸。

**结论:** 作者总结了开放挑战，并提出了加强供应链安全、加密模型认证和下一代基准的方向，以期为未来的研究提供指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Architectural+Backdoors+in+Deep+Learning%3A+A+Survey+of+Vulnerabilities%2C+Detection%2C+and+Defense，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12919，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12919&send_immediately=true&force_search=false)

**原文摘要:** Architectural backdoors pose an under-examined but critical threat to deep
neural networks, embedding malicious logic directly into a model's
computational graph. Unlike traditional data poisoning or parameter
manipulation, architectural backdoors evade standard mitigation techniques and
persist even after clean retraining. This survey systematically consolidates
research on architectural backdoors, spanning compiler-level manipulations,
tainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging
detection and defense strategies, including static graph inspection, dynamic
fuzzing, and partial formal verification, and highlight their limitations
against distributed or stealth triggers. Despite recent progress, scalable and
practical defenses remain elusive. We conclude by outlining open challenges and
proposing directions for strengthening supply-chain security, cryptographic
model attestations, and next-generation benchmarks. This survey aims to guide
future research toward comprehensive defenses against structural backdoor
threats in deep learning systems.

</details>


### [87] [Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach](https://arxiv.org/abs/2507.12937)
*Zhuohan Cui, Zikun Song*

**主要类别:** cs.CR

**AI概要:** 本文通过全面分析T-Mobile在2021和2023年的数据泄露事件，结合多层次安全审计与防御策略建议，强调了电信运营商提升安全性和合规性的方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于T-Mobile发生了关键数据泄露事件，作者希望通过此研究找出系统中的结构性弱点，并提出有效的改进措施以防止未来的安全问题。

**方法:** 使用案例漏洞评估与主动道德黑客技术相结合的方法，如Shodan侦察、API误用模拟、VNC暴力破解、固件逆向工程及Web应用程序扫描来发现系统中的潜在风险。

**结果:** 发现了持续存在的结构弱点，并提出了一个包含零信任架构、细粒度基于角色的访问控制等多层防御策略。同时，财务模型表明五年的投资成本效益高。

**结论:** 本研究将事后法医分析与实际安全评估相结合，为大型电信公司提供了增强操作弹性、遵守法规以及跨域威胁准备的具体蓝图。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enterprise+Security+Incident+Analysis+and+Countermeasures+Based+on+the+T-Mobile+Data+Breach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12937&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a comprehensive analysis of T-Mobile's critical data
breaches in 2021 and 2023, alongside a full-spectrum security audit targeting
its systems, infrastructure, and publicly exposed endpoints. By combining
case-based vulnerability assessments with active ethical hacking
techniques--including Shodan reconnaissance, API misuse simulations, VNC
brute-forcing, firmware reverse engineering, and web application scans--we
uncover structural weaknesses persisting beyond the initial breach events.
Building on these findings, we propose a multi-layered defensive strategy
encompassing Zero Trust Architecture, granular role-based access control,
network segmentation, firmware encryption using AES with integrity checks, and
API rate limiting and token lifecycle control. Financial modelling demonstrates
that a five-year investment yields less than 1.1% of expected breach losses,
validating the cost-effectiveness of proactive security measures. Our work
bridges post-incident forensic analysis with hands-on security evaluation,
providing an actionable blueprint for large-scale telecoms seeking operational
resilience, regulatory compliance, and cross-domain threat readiness.

</details>


### [88] [Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest](https://arxiv.org/abs/2507.13023)
*Fei Wu, Danning Sui, Thomas Thiery, Mallesh Pai*

**主要类别:** cs.CR

**AI概要:** 本文对以太坊上中心化和去中心化交易所（CEX-DEX）之间的套利经济学和动态进行了全面的实证分析，揭示了套利交易识别、收益估算方法及市场集中度等问题。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于理解CEX-DEX之间套利活动背后的经济原理及其对以太坊去中心化特性的影响。

**方法:** 通过改进启发式算法从链上数据中识别套利交易，并引入稳健的经验框架来估计套利收益，同时利用涵盖19个月的数据集进行分析。

**结果:** 估计总共有2.338亿美元被19个主要的CEX-DEX搜索者从7,203,560笔确认的套利交易中提取，且发现市场集中度增加的趋势，其中三个搜索者捕获了四分之三的交易量和提取价值。

**结论:** 研究表明，搜索者的盈利能力与他们与区块构建者的整合程度有关，并揭示了之前低估的区块构建者的盈利能力。这些发现强调了CEX-DEX套利对于以太坊去中心化的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+CEX-DEX+Extracted+Value+and+Searcher+Profitability%3A+The+Darkest+of+the+MEV+Dark+Forest，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13023，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13023&send_immediately=true&force_search=false)

**原文摘要:** This paper provides a comprehensive empirical analysis of the economics and
dynamics behind arbitrages between centralized and decentralized exchanges
(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions
from on-chain data and introduce a robust empirical framework to estimate
arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging
an extensive dataset spanning 19 months from August 2023 to March 2025, we
estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from
7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing
centralization trends as three searchers captured three-quarters of both volume
and extracted value. We also demonstrate that searchers' profitability is tied
to their integration level with block builders and uncover exclusive
searcher-builder relationships and their market impact. Finally, we correct the
previously underestimated profitability of block builders who vertically
integrate with a searcher. These insights illuminate the darkest corner of the
MEV landscape and highlight the critical implications of CEX-DEX arbitrages for
Ethereum's decentralization.

</details>


### [89] [From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange](https://arxiv.org/abs/2507.13028)
*Niklas Busch, Philip Klostermeyer, Jan H. Klemmer, Yasemin Acar, Sascha Fahl*

**主要类别:** cs.CR

**AI概要:** 本文通过定性分析316个与系统加固相关的Stack Exchange帖子，发现系统操作员在访问控制和部署相关问题上面临挑战，并受到误解和不切实际的期望的影响。主要关注操作系统和服务器应用程序，驱动因素包括对攻击的恐惧和合规原因。


<details>
  <summary>更多</summary>
  
**动机:** 许多计算机系统和应用程序仍然存在安全隐患，而研究社区对于系统操作员在系统加固方面的动机、实践和挑战缺乏深入理解。

**方法:** 作者对316个与系统加固相关的Stack Exchange帖子进行了定性分析，以了解系统操作员的实践和挑战。

**结果:** 访问控制和部署相关问题是最大的挑战，系统操作员存在误解和不切实际的期望，且大多数帖子集中在操作系统和服务器应用程序上。

**结论:** 作者讨论了研究问题，对未来系统加固提出了建议，并阐述了工作的意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Paranoia+to+Compliance%3A+The+Bumpy+Road+of+System+Hardening+Practices+on+Stack+Exchange，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13028，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13028&send_immediately=true&force_search=false)

**原文摘要:** Hardening computer systems against cyberattacks is crucial for security.
However, past incidents illustrated, that many system operators struggle with
effective system hardening. Hence, many computer systems and applications
remain insecure. So far, the research community lacks an in-depth understanding
of system operators motivation, practices, and challenges around system
hardening. With a focus on practices and challenges, we qualitatively analyzed
316 Stack Exchange (SE) posts related to system hardening. We find that access
control and deployment-related issues are the most challenging, and system
operators suffer from misconceptions and unrealistic expectations. Most
frequently, posts focused on operating systems and server applications. System
operators were driven by the fear of their systems getting attacked or by
compliance reasons. Finally, we discuss our research questions, make
recommendations for future system hardening, and illustrate the implications of
our work.

</details>


### [90] [MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](https://arxiv.org/abs/2507.13038)
*Yu Cui, Hongyang Du*

**主要类别:** cs.CR

**AI概要:** 本文介绍了一种针对多智能体辩论系统的攻击方法MAD-Spear，该方法通过注入误导性信息降低系统性能，并提出了评估MAD系统容错性的框架。实验表明MAD-Spear效果显著，同时发现智能体多样性有助于提升数学推理任务的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多智能体辩论（MAD）系统研究主要集中在准确性和可扩展性上，而对其安全漏洞的关注较少。因此，作者希望探讨MAD系统的安全性问题，并提出有效的攻击手段以评估和改进MAD系统的安全性。

**方法:** 研究人员引入了MAD-Spear，一种针对MAD系统的提示注入攻击方法，该方法通过操控少量智能体来传播错误信息，从而影响整个MAD过程。此外，还提出了一个正式的MAD容错性定义和全面的评估框架。

**结果:** 实验结果表明，MAD-Spear在多个基准数据集上持续优于基线攻击方法，成功降低了MAD系统的性能。并且，智能体多样性对数学推理任务表现有明显积极影响。

**结论:** 研究强调了提高MAD系统设计中安全性的重要性，并指出智能体多样性可以改善某些类型的任务表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAD-Spear%3A+A+Conformity-Driven+Prompt+Injection+Attack+on+Multi-Agent+Debate+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13038，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13038&send_immediately=true&force_search=false)

**原文摘要:** Multi-agent debate (MAD) systems leverage collaborative interactions among
large language models (LLMs) agents to improve reasoning capabilities. While
recent studies have focused on increasing the accuracy and scalability of MAD
systems, their security vulnerabilities have received limited attention. In
this work, we introduce MAD-Spear, a targeted prompt injection attack that
compromises a small subset of agents but significantly disrupts the overall MAD
process. Manipulated agents produce multiple plausible yet incorrect responses,
exploiting LLMs' conformity tendencies to propagate misinformation and degrade
consensus quality. Furthermore, the attack can be composed with other
strategies, such as communication attacks, to further amplify its impact by
increasing the exposure of agents to incorrect responses. To assess MAD's
resilience under attack, we propose a formal definition of MAD fault-tolerance
and develop a comprehensive evaluation framework that jointly considers
accuracy, consensus efficiency, and scalability. Extensive experiments on five
benchmark datasets with varying difficulty levels demonstrate that MAD-Spear
consistently outperforms the baseline attack in degrading system performance.
Additionally, we observe that agent diversity substantially improves MAD
performance in mathematical reasoning tasks, which challenges prior work
suggesting that agent diversity has minimal impact on performance. These
findings highlight the urgent need to improve the security in MAD design.

</details>


### [91] [Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors](https://arxiv.org/abs/2507.13042)
*Taki Eddine Djidjekh, Gaël Loubet, Alexandru Takacs*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种基于反向散射的安全机制，该机制可以在不增加能耗或计算需求的情况下生成额外的识别信号。实验证明了该方案在无线传感网络中的功能和兼容性，并讨论了其在多节点场景下的挑战与未来改进方向。


<details>
  <summary>更多</summary>
  
**动机:** 针对无电池和资源受限设备在物联网系统中实现安全性和能源效率集成的关键挑战，特别是为了满足结构健康监测和智能运输等对尺寸有限的应用的需求。

**方法:** 通过将基于反向散射的安全机制整合进蓝牙低功耗无电池无线传感网络，利用无线功率传输链路产生额外识别信号。

**结果:** 实验验证展示了该解决方案的功能，确保与尺寸受限应用的兼容性，并提出了应对多节点无线传感网络场景中识别信号潜在冲突的方法。

**结论:** 研究结果强调了基于反向散射的安全机制在创建跨不同协议和应用场景的安全、可持续及可扩展的物联网部署方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Backscattering-Based+Security+in+Wireless+Power+Transfer+Applied+to+Battery-Free+BLE+Sensors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13042&send_immediately=true&force_search=false)

**原文摘要:** The integration of security and energy efficiency in Internet of Things
systems remains a critical challenge, particularly for battery-free and
resource-constrained devices. This paper explores the scalability and
protocol-agnostic nature of a backscattering-based security mechanism by
integrating it into Bluetooth Low Energy battery-free Wireless Sensor Network.
The proposed approach leverages the Wireless Power Transfer link, traditionally
used for energy harvesting, to generate additional identification signals
without increasing energy consumption or computational demands. Experimental
validation demonstrates the solution's functionality using compact, low-gain
antenna, ensuring compatibility with size-constrained applications such as
Structural Health Monitoring and smart transport. Furthermore, this work
addresses the challenges associated with backscattering dynamic range and
multi-node Wireless Sensor Network scenarios, discussing potential collisions
between identification signals and proposing future improvements to enhance
generalizability and scalability. The findings underscore the potential of the
backscattering-based security mechanism for creating secure, sustainable, and
scalable IoT deployments across diverse protocols and applications.

</details>


### [92] [Prompt Injection 2.0: Hybrid AI Threats](https://arxiv.org/abs/2507.13169)
*Jeremy McHugh, Kristina Šekrst, Jon Cefalu*

**主要类别:** cs.CR

**AI概要:** 本文分析了Prompt Injection 2.0，研究其如何与传统的网络安全隐患相结合形成混合威胁，并提出了结合提示隔离、运行时安全和特权分离的架构解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 自2022年首次发现以来，prompt injection攻击对集成LLM的系统构成了严重的安全威胁。随着自主AI系统的出现，这些攻击已经进化为可以与传统网络安全漏洞相结合，形成难以防御的混合威胁。

**方法:** 文章基于Preamble的基础研究和技术，评估这些技术对于现代威胁（如AI蠕虫、多代理感染和混合网络-AI攻击）的有效性。同时，通过最新的基准测试展示了传统安全措施在面对增强型AI攻击时的失效情况。

**结果:** 研究显示，传统的Web应用防火墙、XSS过滤器和CSRF令牌等安全措施无法有效抵御AI增强型攻击。

**结论:** 为了应对这种新型威胁，文中提出了一种新的架构解决方案，该方案结合了prompt隔离、运行时安全性和特权分离，并具备新颖的威胁检测能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prompt+Injection+2.0%3A+Hybrid+AI+Threats，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13169，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13169&send_immediately=true&force_search=false)

**原文摘要:** Prompt injection attacks, where malicious input is designed to manipulate AI
systems into ignoring their original instructions and following unauthorized
commands instead, were first discovered by Preamble, Inc. in May 2022 and
responsibly disclosed to OpenAI. Over the last three years, these attacks have
continued to pose a critical security threat to LLM-integrated systems. The
emergence of agentic AI systems, where LLMs autonomously perform multistep
tasks through tools and coordination with other agents, has fundamentally
transformed the threat landscape. Modern prompt injection attacks can now
combine with traditional cybersecurity exploits to create hybrid threats that
systematically evade traditional security controls. This paper presents a
comprehensive analysis of Prompt Injection 2.0, examining how prompt injections
integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),
and other web security vulnerabilities to bypass traditional security measures.
We build upon Preamble's foundational research and mitigation technologies,
evaluating them against contemporary threats, including AI worms, multi-agent
infections, and hybrid cyber-AI attacks. Our analysis incorporates recent
benchmarks that demonstrate how traditional web application firewalls, XSS
filters, and CSRF tokens fail against AI-enhanced attacks. We also present
architectural solutions that combine prompt isolation, runtime security, and
privilege separation with novel threat detection capabilities.

</details>


### [93] [A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models](https://arxiv.org/abs/2507.13313)
*Chao Feng, Alberto Huertas Celdran, Jing Han, Heqing Ren, Xi Cheng, Zien Zeng, Lucas Krauter, Gerome Bovet, Burkhard Stiller*

**主要类别:** cs.CR

**AI概要:** 本文介绍了一个用于研究去中心化联邦学习（DFL）应用于物联网群体感知恶意软件检测的数据集和实验研究。研究表明，DFL在保持数据本地性的同时维持了竞争力，并且在大多数情况下优于集中式联邦学习（CFL）。


<details>
  <summary>更多</summary>
  
**动机:** 随着物联网设备的增加，保护这些设备免受恶意软件攻击变得越来越重要。现有的方法可能无法有效处理分散的数据源或未能充分保护用户隐私。因此，研究人员希望探索一种可以在不共享实际数据的情况下训练模型的方法，以提高检测性能并确保数据的安全性和隐私性。

**方法:** 研究人员创建了一个包含良性行为和八个恶意软件家族行为记录的数据集。从系统调用、文件系统活动、资源使用情况等方面收集了21,582,484条原始记录。这些记录被聚合为342,106个特征，用于训练和评估模型。然后，在DFL平台上进行了实验，比较了传统机器学习（ML）、集中式联邦学习（CFL）和DFL在不同节点数量、拓扑结构和数据分布下的表现。

**结果:** 实验结果表明，与CFL相比，DFL在多数设置中表现出更好的性能，同时保留了数据的本地性。

**结论:** 该数据集为研究物联网群体感知环境中的安全性提供了坚实的基础，证明了DFL在保护数据隐私和实现高效恶意软件检测方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Crowdsensing+Intrusion+Detection+Dataset+For+Decentralized+Federated+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13313&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a dataset and experimental study for decentralized
federated learning (DFL) applied to IoT crowdsensing malware detection. The
dataset comprises behavioral records from benign and eight malware families. A
total of 21,582,484 original records were collected from system calls, file
system activities, resource usage, kernel events, input/output events, and
network records. These records were aggregated into 30-second windows,
resulting in 342,106 features used for model training and evaluation.
Experiments on the DFL platform compare traditional machine learning (ML),
centralized federated learning (CFL), and DFL across different node counts,
topologies, and data distributions. Results show that DFL maintains competitive
performance while preserving data locality, outperforming CFL in most settings.
This dataset provides a solid foundation for studying the security of IoT
crowdsensing environments.

</details>
