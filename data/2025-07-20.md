<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 63]
- [cs.AI](#cs.AI) [总数: 20]
- [cs.CR](#cs.CR) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu, Shizhe Diao, Jian Hu, Ximing Lu, Xin Dong, Hao Zhang, Alexander Bukharin, Shaokun Zhang, Jiaqi Zeng, Makesh Narsimhan Sreedhar, Gerald Shen, David Mosallanezhad, Di Zhang, Jonas Yang, June Yang, Oleksii Kuchaiev, Guilin Liu, Zhiding Yu, Pavlo Molchanov, Yejin Choi, Jan Kautz, Yi Dong*

**主要类别:** cs.LG

**AI概要:** 本文研究了长时间强化学习对小型语言模型在多种推理任务上的影响，通过引入可控KL正则化、裁剪比率和周期性参考策略重置等方法，实现了数学、编程和逻辑谜题任务上的显著性能提升，并公开发布了模型。


<details>
  <summary>更多</summary>
  
**动机:** 受到近期大型语言模型如OpenAI的O1和DeepSeek-R1在复杂任务上取得进展的启发，这些模型通过链式思考推理和迭代探索来扩展测试时计算，从而大幅提升处理复杂任务（如数学和代码生成）的能力。本研究旨在探讨长时间强化学习对小型语言模型的影响，特别是在不同推理领域中的效果。

**方法:** 研究中使用了可验证奖励任务、改进的Group Relative Policy Optimization (GRPO)，以及提高训练稳定性和泛化的实用技术。具体来说，引入了可控KL正则化、裁剪比率和周期性参考策略重置作为关键组件。

**结果:** 该模型在数学任务上提升了14.7%，在编程任务上提升了13.9%，在逻辑谜题任务上更是达到了54.8%的显著提升。

**结论:** 通过长时间的强化学习和所提出的训练方法，小型语言模型可以在复杂的推理任务上获得长期性能增益。为了促进持续的研究，作者公开发布了他们的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Up+RL%3A+Unlocking+Diverse+Reasoning+in+LLMs+via+Prolonged+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12507&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [2] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu, Konpat Preechakul, Kananart Kuwaranancharoen, Yutong Bai*

**主要类别:** cs.LG

**AI概要:** 论文指出，机器学习在并行化方面取得了进展，但忽视了某些问题本质上是串行的，这些“固有的串行”问题要求依赖性的计算步骤无法被并行化。作者认为当前以并行为中心的架构在处理这类任务时存在根本限制，并强调在硬件开发、模型设计等方面考虑计算的串行本质对于AI持续进步的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 动机在于识别出机器学习领域的一个盲点：一些问题本质上是串行的，不能通过并行化来解决。这种固有串行的问题包括数学推理、物理模拟和顺序决策等，这些问题需要依赖性计算步骤。

**方法:** 作者从复杂性理论出发，对串行和并行问题进行了形式化的区分，展示了当前以并行为中心的架构在处理串行问题上的局限性。

**结果:** 研究结果表明，目前流行的并行架构在处理那些需要依赖性计算步骤的任务上存在基本的局限性。

**结论:** 结论是，随着AI面对越来越复杂的推理挑战，有意地扩展串行计算（而不仅仅是并行计算）对于持续的进步至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Serial+Scaling+Hypothesis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12549，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12549&send_immediately=true&force_search=false)

**原文摘要:** While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [3] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的机器思维框架，该框架集成了心理意象和认知思维单元，旨在使AI能够更像人类一样思考。


<details>
  <summary>更多</summary>
  
**动机:** 现有模型在自主行动、独立推理方面存在不足，并且难以跨多个领域整合知识。此外，心理意象在大脑的思维过程中扮演着重要角色，因此研究如何将其整合到机器中是有价值的。

**方法:** 作者提出了一个包含认知思维单元和三个辅助单元（输入数据单元、需求单元和心理意象单元）的机器思维框架。在这个框架内，数据以自然语言句子或绘制草图的形式表示。

**结果:** 进行了验证测试，结果将在论文中呈现和讨论。

**结论:** 这种新的机器思维框架可能对启动思维过程有益，但具体结论需要等待进一步的结果分析。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Mental+Imagery+Improve+the+Thinking+Capabilities+of+AI+Systems%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12555，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12555&send_immediately=true&force_search=false)

**原文摘要:** Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [4] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza, Paulo R. Lisboa de Almeida, Alceu de Souza Britto Jr., Robert Sabourin, Rafael M. O. Cruz*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的数据流方法IncA-DES，结合概念漂移检测器和在线K-d树算法，以应对数据分布随时间变化的挑战。该方法在不同标签可用性水平下实现了最佳平均准确度，并且处理时间更短。


<details>
  <summary>更多</summary>
  
**动机:** 数据流中的概念漂移（即数据分布随时间变化）对传统的批处理机器学习提出了挑战。融合分类器的方法显示出良好的结果，但需要适应概念漂移，特别是在创建局部专家和处理连续到达的数据方面。

**方法:** 作者提出了IncA-DES框架，使用训练策略生成局部专家，并融合了概念漂移检测器以维持信息并适应新概念。还引入了一个重叠分类过滤器，避免在邻域达成共识时使用DS方法。此外，为了减少kNN的处理时间，提出了一种在线K-d树算法。

**结果:** 实验结果表明，所提出的框架在不同标签可用性水平下与七种最先进方法相比，获得了最佳平均准确度，并且在最准确的方法中处理时间最短。在线K-d树融合也减少了处理时间，几乎没有损失准确性。

**结论:** IncA-DES框架有效地解决了数据流中的概念漂移问题，在准确性和处理速度上都有显著优势。代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是IncA-DES%3A+An+incremental+and+adaptive+dynamic+ensemble+selection+approach+using+online+K-d+tree+neighborhood+search+for+data+streams+with+concept+drift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12573，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12573&send_immediately=true&force_search=false)

**原文摘要:** Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [5] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng, Spencer S. Ericksen, Anthony Gitter*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的工作流程 Assay2Mol，它利用大型语言模型来分析生物化学筛选试验的非结构化文本数据，以辅助新药早期发现。该方法在生成候选分子方面优于最近的机器学习方法，并促进了更易合成的分子生成。


<details>
  <summary>更多</summary>
  
**动机:** 大量的科学数据库中包含了丰富的定量数据和描述性文本，但这些数据大多以非结构化的形式存在，难以被有效利用。特别是在生物化学领域，这些未被充分利用的数据可以为新药发现提供宝贵信息。

**方法:** Assay2Mol 通过检索与新目标相似的目标相关的现有试验记录，并使用检索到的试验筛选数据进行情境学习来生成候选分子。

**结果:** Assay2Mol 在生成候选配体分子方面优于近期的机器学习方法，并且还促进了更易于合成的分子生成。

**结论:** Assay2Mol 是一种能够充分利用现有的生物化学筛选试验数据的工作流程，对于新药早期发现具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Assay2Mol%3A+large+language+model-based+drug+design+using+BioAssay+context，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12574，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12574&send_immediately=true&force_search=false)

**原文摘要:** Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [6] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi, Ali Eshragh, Babak Aslani, Meysam Rabiee*

**主要类别:** cs.LG

**AI概要:** 本文研究了聚类排序向量的问题，提出了KRC问题，并开发了一种有效的近似算法KRCA。通过实验表明，KRCA比基线解决方案具有更好的性能和更快的计算时间。


<details>
  <summary>更多</summary>
  
**动机:** 在许多应用中，数据以排序向量的形式出现，每个向量代表一个有序的不同整数列表，表示偏好。然而，传统的聚类方法如k-means并不适用于这种特殊类型的向量，因此需要一种新的聚类方法来处理排序向量。

**方法:** 作者首先建立了KRC问题的NP难性并描述了其可行集。对于单簇情况，推导出了最优质心的闭式解析解。为了应对KRC的计算挑战，开发了一种高效的近似算法KRCA，并引入了一个分支定界算法用于簇重建。

**结果:** 通过广泛的数值实验表明，KRCA在解决方案质量和计算时间上都显著优于基线解决方案。

**结论:** 这项工作强调了KRC在个性化和大规模决策中的实际意义，提供了可以在此基础上进行未来研究的方法论进展和见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ranking+Vectors+Clustering%3A+Theory+and+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12583&send_immediately=true&force_search=false)

**原文摘要:** We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [7] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li, Kwang-Sung Jun*

**主要类别:** cs.LG

**AI概要:** 本文研究了[0,1]区间的回归问题，证明了log损失最小化器可以实现与成本敏感分类相似的一阶边界，并提出了一种新的损失函数——投注损失，以实现不依赖于方差知识的方差依赖性边界。


<details>
  <summary>更多</summary>
  
**动机:** 作者受到之前在成本敏感分类中获得的成果启发，即log损失最小化器可以获得改进的泛化边界。基于这一点，作者想探讨是否可以在[0,1]值回归中找到一种损失函数，不仅能够达到类似的一阶边界，而且还能进一步达到更严格的方差依赖性边界（即二阶边界）。

**方法:** 作者首先证明了在[0,1]区间内的回归问题中，log损失最小化器确实可以实现一阶边界。然后为了达到方差依赖性的二阶边界，作者引入了一个新的损失函数——投注损失。这个损失函数的特点是在不需要任何关于方差先验知识的情况下自适应地达到了方差依赖性的边界。

**结果:** 作者成功地证明了log损失最小化器在一阶边界上的有效性，并通过引入投注损失函数实现了方差依赖性的二阶边界。这种改进意味着模型能够在没有显式建模标签或奖励方差的情况下自适应地调整其性能。

**结论:** 在这项工作中，作者为[0,1]值回归问题提供了一个新的视角，即通过投注损失函数实现了方差依赖性的泛化边界。这表明即使不直接对标签分布进行建模，也可以得到更加严格的泛化边界。这一发现对于那些难以估计或无法事先知道方差的任务具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Second-Order+Bounds+for+%5B0%2C1%5D-Valued+Regression+via+Betting+Loss，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12584，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12584&send_immediately=true&force_search=false)

**原文摘要:** We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [8] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko, Katarzyna Woźnica*

**主要类别:** cs.LG

**AI概要:** 本文提出两种新的表格数据表示学习方法，专为特定的元任务——贝叶斯超参数优化热启动而设计。实验表明，尽管所提出的编码器可以有效地学习与landmarkers对齐的表示，但它们可能不会直接转化为HPO热启动元任务中的显著性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 有效表示异构表格数据集以用于元学习仍然是一个未解决的问题。以前的方法依赖于旨在通用的表示方法，而这些方法可能无法捕捉到特定元任务的需求。

**方法:** 提出了两个新的表格表示学习方法：深度度量学习和landmarkers重建。这两种方法都遵循我们自己制定的具体要求，即强制表示捕获landmarkers的属性。

**结果:** 实验结果表明，所提出的编码器可以有效地学习与landmarkers对齐的表示，但在HPO热启动的元任务中并未带来显著的性能提升。

**结论:** 虽然新方法在表示学习方面取得了一定成果，但在实际应用到贝叶斯超参数优化热启动时，效果并不明显。这表明未来的研究需要进一步探索如何将学到的表示更有效地转化为性能增益。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Are+encoders+able+to+learn+landmarkers+for+warm-starting+of+Hyperparameter+Optimization%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12604，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12604&send_immediately=true&force_search=false)

**原文摘要:** Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>


### [9] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
*Prateek Chanda, Saral Sureka, Parth Pratim Chatterjee, Krishnateja Killamsetty, Nikhil Shivakumar Nayak, Ganesh Ramakrishnan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为TASKPGM的框架，用于优化大型语言模型微调时的任务数据集组合。通过最小化马尔可夫随机场上的能量函数选择任务比例，并在多个评估套件上展示了性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 当前选择最优任务数据集组合的方法大多依赖于人工和启发式策略，缺乏系统性和可扩展性。

**方法:** 引入了TASKPGM框架，该框架通过最小化马尔可夫随机场上的能量函数来选择连续的任务比例，并使用行为差异（如Jensen Shannon Divergence和Pointwise Mutual Information）建模任务关系。

**结果:** 提供了理论保证，包括预算变体的弱次模性，并在Llama 2和Mistral模型上的一系列评估套件中展示了一致的经验改进。

**结论:** TASKPGM不仅提高了LLM的性能，还提供了关于任务影响和组合构成的可解释见解，成为高效和稳健的LLM微调的强大工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+What+Matters%3A+Probabilistic+Task+Selection+via+Mutual+Information+for+Model+Finetuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12612，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12612&send_immediately=true&force_search=false)

**原文摘要:** The performance of finetuned large language models (LLMs) hinges critically
on the composition of the training mixture. However, selecting an optimal blend
of task datasets remains a largely manual, heuristic driven process, with
practitioners often relying on uniform or size based sampling strategies. We
introduce TASKPGM, a principled and scalable framework for mixture optimization
that selects continuous task proportions by minimizing an energy function over
a Markov Random Field (MRF). Task relationships are modeled using behavioral
divergences such as Jensen Shannon Divergence and Pointwise Mutual Information
computed from the predictive distributions of single task finetuned models. Our
method yields a closed form solution under simplex constraints and provably
balances representativeness and diversity among tasks. We provide theoretical
guarantees, including weak submodularity for budgeted variants, and demonstrate
consistent empirical improvements on Llama 2 and Mistral across evaluation
suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers
interpretable insights into task influence and mixture composition, making it a
powerful tool for efficient and robust LLM finetuning.

</details>


### [10] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
*Rui Li, Xiaoyun Zhi, Jinxin Chi, Menghan Yu, Lixin Huang, Jia Zhu, Weilun Zhang, Xing Ma, Wenjia Liu, Zhicheng Zhu, Daowen Luo, Zuquan Song, Xin Yin, Chao Xiang, Shuguang Wang, Wencong Xiao, Gene Cooperman*

**主要类别:** cs.LG

**AI概要:** 本文研究大型语言模型训练的启动开销，并提出系统级优化框架Bootseer，将启动开销减少50%。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型的发展，启动开销在训练中的影响越来越重要，特别是在大规模工业级模型中，频繁的失败和迭代更新使得减少启动开销变得尤为重要。

**方法:** 作者提出了一个名为Bootseer的系统级优化框架，它通过热块记录与预取、依赖关系快照和条带HDFS-FUSE三种技术来解决容器镜像加载、运行时依赖安装和模型检查点恢复这三个主要启动瓶颈。

**结果:** 实验结果表明，Bootseer可以将启动开销减少50%。

**结论:** Bootseer是针对大型语言模型训练启动开销问题的有效解决方案，能够显著提高训练效率，节约计算资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BootSeer%3A+Analyzing+and+Mitigating+Initialization+Bottlenecks+in+Large-Scale+LLM+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12619&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have become a cornerstone of modern AI, driving
breakthroughs in natural language processing and expanding into multimodal jobs
involving images, audio, and video. As with most computational software, it is
important to distinguish between ordinary runtime performance and startup
overhead. Prior research has focused on runtime performance: improving training
efficiency and stability. This work focuses instead on the increasingly
critical issue of startup overhead in training: the delay before training jobs
begin execution. Startup overhead is particularly important in large,
industrial-scale LLMs, where failures occur more frequently and multiple teams
operate in iterative update-debug cycles. In one of our training clusters, more
than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training
startup overhead based on real production data. We analyze the components of
startup cost, quantify its direct impact, and examine how it scales with job
size. These insights motivate the design of Bootseer, a system-level
optimization framework that addresses three primary startup bottlenecks: (a)
container image loading, (b) runtime dependency installation, and (c) model
checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three
techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and
(c) striped HDFS-FUSE. Bootseer has been deployed in a production environment
and evaluated on real LLM training workloads, demonstrating a 50% reduction in
startup overhead.

</details>


### [11] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
*Jake Ward, Chuqiao Lin, Constantin Venhoff, Neel Nanda*

**主要类别:** cs.LG

**AI概要:** 本研究揭示了在DeepSeek-R1-Distill-Llama-8B中，通过重新利用基模型激活中存在的方向，可以引发回溯行为。这种行为不是从零学习的新能力，而是通过推理微调过程重新利用预先存在的表示形成的。


<details>
  <summary>更多</summary>
  
**动机:** 先前的研究已经成功地通过转向矢量操控回溯行为，但其底层机制尚未被充分理解。这项工作的动机是探索回溯行为的出现是否由基模型激活中已存在的方向驱动，并探讨这些方向如何影响微调后的推理模型。

**方法:** 研究人员识别了Llama-3.1-8B残差流中的一个方向，该方向在用于引导蒸馏推理模型时系统地引发了回溯。他们还检查了此方向在基础模型和经过推理微调的模型之间的不同效果，并探讨了可能共同调节回溯的其他方向。

**结果:** 研究发现，识别出的方向在引导经过推理微调的模型时能引发回溯，但在基础模型中则不能。这表明推理微调过程重新利用了预先存在的表示以形成新的行为电路。

**结论:** 研究表明，推理微调模型并非从零开始学习新能力，而是重新利用预先存在的基模型表示。这一发现为理解推理微调模型的能力提供了一个新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning-Finetuning+Repurposes+Latent+Representations+in+Base+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12638，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12638&send_immediately=true&force_search=false)

**原文摘要:** Backtracking, an emergent behavior elicited by reasoning fine-tuning, has
been shown to be a key mechanism in reasoning models' enhanced capabilities.
Prior work has succeeded in manipulating this behavior via steering vectors,
but the underlying mechanism remains poorly understood. In this work, we show
that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part
driven by a repurposed direction already present in base model activations.
Specifically, we identify a direction in base Llama-3.1-8B's residual stream
which systematically induces backtracking when used to steer the distilled
reasoning model, and find that the effects of steering with this direction
cannot be trivially explained by token-level attributes. We further find that
this direction does not induce backtracking in the base model, suggesting that
the reasoning finetuning process repurposes pre-existing representations to
form new behavioral circuits. Additionally, we hypothesize that this direction
is one of several which may work together to mediate backtracking. Our findings
offer a compelling picture that reasoning-finetuned models repurpose
pre-existing base model representations, rather than learn new capabilities
from scratch.

</details>


### [12] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
*Kai Malcolm, César Uribe, Momona Yamagami*

**主要类别:** cs.LG

**AI概要:** 该研究探讨了联邦学习在神经解码中的应用，表明在开环模拟中其性能优异且隐私保护良好，但在闭环实时交互中需要对联邦学习进行调整，并存在性能和隐私之间的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 神经信号包含敏感信息，使得数据共享用于解码训练时面临关键的隐私挑战。为了解决这一问题，本研究探索了联邦学习（FL）作为分布式、保护隐私的学习框架在神经接口中的应用。

**方法:** 研究者引入了基于联邦学习的神经解码方法，并使用高维肌电图信号系统评估其在开环和闭环场景下的性能与隐私性。对于闭环场景，研究者还对联邦学习方法进行了适应性修改以支持单用户实时互动。

**结果:** 在开环模拟中，联邦学习显著优于本地学习基线；而在闭环用户研究中，尽管经过调整，联邦学习的表现仍不及本地学习，但本地学习具有更高的隐私风险。

**结论:** 研究表明，在实时自适应应用中存在性能与隐私之间的权衡，并指出需要设计专门针对共同自适应、单用户应用的联邦学习方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Federated+Learning+in+Open-+and+Closed-Loop+EMG+Decoding%3A+A+Privacy+and+Performance+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12652，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12652&send_immediately=true&force_search=false)

**原文摘要:** Invasive and non-invasive neural interfaces hold promise as high-bandwidth
input devices for next-generation technologies. However, neural signals
inherently encode sensitive information about an individual's identity and
health, making data sharing for decoder training a critical privacy challenge.
Federated learning (FL), a distributed, privacy-preserving learning framework,
presents a promising solution, but it remains unexplored in closed-loop
adaptive neural interfaces. Here, we introduce FL-based neural decoding and
systematically evaluate its performance and privacy using high-dimensional
electromyography signals in both open- and closed-loop scenarios. In open-loop
simulations, FL significantly outperformed local learning baselines,
demonstrating its potential for high-performance, privacy-conscious neural
decoding. In contrast, closed-loop user studies required adapting FL methods to
accommodate single-user, real-time interactions, a scenario not supported by
standard FL. This modification resulted in local learning decoders surpassing
the adapted FL approach in closed-loop performance, yet local learning still
carried higher privacy risks. Our findings highlight a critical
performance-privacy tradeoff in real-time adaptive applications and indicate
the need for FL methods specifically designed for co-adaptive, single-user
applications.

</details>


### [13] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
*Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种迁移学习方法和自适应激活函数，以改善物理信息神经网络（PINNs）的外推能力。实验表明，该方法在不显著增加计算成本的情况下，大幅降低了相对L2误差和平均绝对误差。


<details>
  <summary>更多</summary>
  
**动机:** 尽管物理信息神经网络（PINNs）取得了成功，但在训练域之外它们通常表现出较差的外推性能，并且对激活函数的选择高度敏感。

**方法:** 作者引入了迁移学习方法，通过在一个扩展的训练域内应用迁移学习，只使用少量精心挑选的配点。此外，还提出了一个自适应激活函数，它由标准激活函数的线性组合构成。

**结果:** 一系列实验表明，所提出的方法在外推域中实现了平均40%的相对L2误差减少和平均50%的平均绝对误差减少，而没有显著增加计算成本。

**结论:** 本研究表明，通过引入迁移学习方法和自适应激活函数，可以有效地提高PINNs的外推性能，同时保持较低的计算成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+physics-informed+neural+network+extrapolation+via+transfer+learning+and+adaptive+activation+functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12659，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12659&send_immediately=true&force_search=false)

**原文摘要:** Physics-Informed Neural Networks (PINNs) are deep learning models that
incorporate the governing physical laws of a system into the learning process,
making them well-suited for solving complex scientific and engineering
problems. Recently, PINNs have gained widespread attention as a powerful
framework for combining physical principles with data-driven modeling to
improve prediction accuracy. Despite their successes, however, PINNs often
exhibit poor extrapolation performance outside the training domain and are
highly sensitive to the choice of activation functions (AFs). In this paper, we
introduce a transfer learning (TL) method to improve the extrapolation
capability of PINNs. Our approach applies transfer learning (TL) within an
extended training domain, using only a small number of carefully selected
collocation points. Additionally, we propose an adaptive AF that takes the form
of a linear combination of standard AFs, which improves both the robustness and
accuracy of the model. Through a series of experiments, we demonstrate that our
method achieves an average of 40% reduction in relative L2 error and an average
of 50% reduction in mean absolute error in the extrapolation domain, all
without a significant increase in computational cost. The code is available at
https://github.com/LiuzLab/PINN-extrapolation .

</details>


### [14] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
*Sangbong Yoo, Jaeyoung Lee, Chanyoung Yoon, Geonyeong Son, Hyein Hong, Seongbum Seo, Soobin Yim, Chanyoung Jung, Jungsoo Park, Misuk Kim, Yun Jang*

**主要类别:** cs.LG

**AI概要:** 本文调查了数据异质性的复杂性及其来源，特别强调了数据转换在提高AI学习效率方面的重要性，并系统地分类和展示了应对由数据格式差异引起的异质性的策略。


<details>
  <summary>更多</summary>
  
**动机:** 数据异质性是一个普遍存在的问题，它使得数据利用变得复杂。随着人工智能的广泛应用，对更简化的数据准备过程的需求越来越大，而数据转换成为关键。然而，关于现代数据转换方法的全面评论却很少见。

**方法:** 作者通过探索数据异质性的复杂性和其背后的原因，系统地将解决因数据格式不同而产生的异质性的策略进行了分类和展示。

**结果:** 该研究揭示了每种策略所固有的挑战，并强调了选择适当的转换技术以保持重要数据细节的重要性。

**结论:** 尽管当前的方法主要集中在处理与数据结构和模式相关的冲突上，但数据转换在定制训练数据和适应不同的AI模型输入格式方面起着至关重要的作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Transformation+Strategies+to+Remove+Heterogeneity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12677，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12677&send_immediately=true&force_search=false)

**原文摘要:** Data heterogeneity is a prevalent issue, stemming from various conflicting
factors, making its utilization complex. This uncertainty, particularly
resulting from disparities in data formats, frequently necessitates the
involvement of experts to find resolutions. Current methodologies primarily
address conflicts related to data structures and schemas, often overlooking the
pivotal role played by data transformation. As the utilization of artificial
intelligence (AI) continues to expand, there is a growing demand for a more
streamlined data preparation process, and data transformation becomes
paramount. It customizes training data to enhance AI learning efficiency and
adapts input formats to suit diverse AI models. Selecting an appropriate
transformation technique is paramount in preserving crucial data details.
Despite the widespread integration of AI across various industries,
comprehensive reviews concerning contemporary data transformation approaches
are scarce. This survey explores the intricacies of data heterogeneity and its
underlying sources. It systematically categorizes and presents strategies to
address heterogeneity stemming from differences in data formats, shedding light
on the inherent challenges associated with each strategy.

</details>


### [15] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, Yi-Ping Hsu, Jiajing Xu, Charles Rosenberg*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种基础模型PinFM，用于理解大规模视觉发现平台上的用户活动序列。通过预训练和微调方法克服了工业推荐系统中的挑战，并展示了其在Pinterest内部数据上的显著改进。


<details>
  <summary>更多</summary>
  
**动机:** 用户活动序列已成为推荐系统中最重要的信号之一。然而，在工业推荐系统中应用预训练和微调的方法存在许多挑战，如需要满足严格的成本和延迟限制，同时还要处理新物品的出现。

**方法:** 研究人员开发了PinFM模型，使用包含20B+参数的Transformer模型进行预训练，并针对特定应用程序进行微调。此外，还开发了诸如去重交叉注意力Transformer（DCAT）等创新技术来优化基础设施和算法。

**结果:** 这些优化使Pinterest内部数据的吞吐量提高了600%，并使与新物品的互动增加了20%。

**结论:** PinFM现在已部署到多个应用程序中，以改善超过五亿用户的体验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PinFM%3A+Foundation+Model+for+User+Activity+Sequences+at+a+Billion-scale+Visual+Discovery+Platform，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12704，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12704&send_immediately=true&force_search=false)

**原文摘要:** User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [16] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
*Brian Richard Olsen, Sam Fatehmanesh, Frank Xiao, Adarsh Kumarappan, Anirudh Gajula*

**主要类别:** cs.LG

**AI概要:** 本文开发了一个连续时间、矩阵值随机微分方程框架，解释了深度学习中'bulk+tail'光谱结构的形成，并通过实验验证了理论预测。


<details>
  <summary>更多</summary>
  
**动机:** 尽管深度神经网络在机器学习领域取得了巨大成功，但其训练动态仍缺乏理论上的清晰理解，特别是从微观SGD动态到宏观权重矩阵奇异值谱的演变。

**方法:** 作者推导出精确的SDEs，表明平方奇异值遵循具有特征值排斥的Dyson布朗运动，并将平稳分布描述为幂律尾部的伽玛型密度。

**结果:** 提供了第一个关于训练网络中经验观察到的'bulk+tail'光谱结构的理论解释，并通过受控实验验证了这些理论预测。

**结论:** 该研究提供了一个严格的理论基础来理解深度学习的工作原理，即为何有效。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+SGD+to+Spectra%3A+A+Theory+of+Neural+Network+Weight+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12709，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12709&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks have revolutionized machine learning, yet their training
dynamics remain theoretically unclear-we develop a continuous-time,
matrix-valued stochastic differential equation (SDE) framework that rigorously
connects the microscopic dynamics of SGD to the macroscopic evolution of
singular-value spectra in weight matrices. We derive exact SDEs showing that
squared singular values follow Dyson Brownian motion with eigenvalue repulsion,
and characterize stationary distributions as gamma-type densities with
power-law tails, providing the first theoretical explanation for the
empirically observed 'bulk+tail' spectral structure in trained networks.
Through controlled experiments on transformer and MLP architectures, we
validate our theoretical predictions and demonstrate quantitative agreement
between SDE-based forecasts and observed spectral evolution, providing a
rigorous foundation for understanding why deep learning works.

</details>


### [17] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
*Suorong Yang, Peijia Li, Yujie Liu, Zhiming Xu, Peng Ye, Wanli Ouyang, Furao Shen, Dongzhan Zhou*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种动态数据集修剪框架，根据任务驱动的难度和跨模态语义一致性自适应选择训练样本。通过利用预训练多模态基础模型的监督，该方法捕捉训练动态并有效过滤掉无信息样本，推动数据为中心的学习更高效和稳健。


<details>
  <summary>更多</summary>
  
**动机:** 现代深度模型在大规模真实世界数据集上进行训练，但这些数据集中的数据质量参差不齐且冗余常见。现有的数据集修剪方法大多依赖于静态启发式或特定任务的度量标准，限制了它们在不同领域的鲁棒性和泛化能力。

**方法:** 提出的方法结合了任务驱动的难度和跨模态语义一致性来动态选择训练样本，并使用预训练的多模态基础模型提供监督以捕捉训练动态。

**结果:** 该方法可以有效地过滤掉无信息样本，提高训练效率和模型性能。

**结论:** 这项工作强调了整合跨模态对齐以实现稳健样本选择的潜力，促进了数据为中心的学习向更高效和稳健的方向发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multimodal-Guided+Dynamic+Dataset+Pruning+for+Robust+and+Efficient+Data-Centric+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12750，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12750&send_immediately=true&force_search=false)

**原文摘要:** Modern deep models are trained on large real-world datasets, where data
quality varies and redundancy is common. Data-centric approaches such as
dataset pruning have shown promise in improving training efficiency and model
performance. However, most existing methods rely on static heuristics or
task-specific metrics, limiting their robustness and generalizability across
domains. In this work, we introduce a dynamic dataset pruning framework that
adaptively selects training samples based on both task-driven difficulty and
cross-modality semantic consistency. By incorporating supervision from
pretrained multimodal foundation models, our approach captures training
dynamics while effectively filtering out uninformative samples. Our work
highlights the potential of integrating cross-modality alignment for robust
sample selection, advancing data-centric learning toward more efficient and
robust practices across application domains.

</details>


### [18] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
*Yaru Liu, Yiqi Gu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的优化框架LySep模型，通过引入辅助变量将深度神经网络分层，以改善基于深度学习的求解偏微分方程的方法。该方法有效分解深层架构为浅层架构，并建立新的损失函数，使许多变量可以最优地更新。理论分析和高维数值结果验证了LySep模型的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 由于深度学习中的损失函数具有高度非凸性质，现有的优化算法经常收敛到次优局部最小值或遭遇梯度爆炸或消失的问题，导致性能不佳。为了改进这些问题，作者提出了LySep模型。

**方法:** 作者在LySep模型中引入了辅助变量来分离深度神经网络的层次，具体来说，每一层的输出及其导数由辅助变量表示，从而有效地将深度架构分解为一系列浅层架构。新建立的损失函数只包含来自两个相邻层的变量，并开发了基于交替方向的相应算法。

**结果:** 理论分析证明了LySep模型与原始深度模型之间的一致性。高维数值结果验证了理论，并展示了LySep在最小化损失和减少解决方案误差方面的优势。

**结论:** LySep模型通过分离深度神经网络的层次并使用辅助变量建立了新的损失函数，成功解决了现有优化算法在求解偏微分方程时遇到的问题。实验结果表明，该方法能有效降低损失并减少解的误差。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Layer+Separation+Deep+Learning+Model+with+Auxiliary+Variables+for+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12766，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12766&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose a new optimization framework, the layer separation
(LySep) model, to improve the deep learning-based methods in solving partial
differential equations. Due to the highly non-convex nature of the loss
function in deep learning, existing optimization algorithms often converge to
suboptimal local minima or suffer from gradient explosion or vanishing,
resulting in poor performance. To address these issues, we introduce auxiliary
variables to separate the layers of deep neural networks. Specifically, the
output and its derivatives of each layer are represented by auxiliary
variables, effectively decomposing the deep architecture into a series of
shallow architectures. New loss functions with auxiliary variables are
established, in which only variables from two neighboring layers are coupled.
Corresponding algorithms based on alternating directions are developed, where
many variables can be updated optimally in closed forms. Moreover, we provide
theoretical analyses demonstrating the consistency between the LySep model and
the original deep model. High-dimensional numerical results validate our theory
and demonstrate the advantages of LySep in minimizing loss and reducing
solution error.

</details>


### [19] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren, Jingxi Zhu, Zehao Liu, Tianxiang Zhao, Vasant Honavar*

**主要类别:** cs.LG

**AI概要:** 本文综述了深度学习、大语言模型和电子健康记录（EHR）建模的最新进展，提出了涵盖五个关键设计维度的统一分类法，并强调了如基础模型、LLM驱动的临床代理等新兴趋势，同时讨论了现存挑战。


<details>
  <summary>更多</summary>
  
**动机:** AI在通过分析和建模电子健康记录来转变医疗保健方面显示出了巨大的潜力，但EHR数据的固有异质性、时间不规则性和领域特定性质带来了独特的挑战，这些挑战与视觉和自然语言任务中的挑战根本不同。

**方法:** 作者提出了一种统一的分类法，涵盖了五个关键的设计维度：以数据为中心的方法、神经架构设计、以学习为重点的策略、多模态学习和基于LLM的建模系统。并回顾了每个维度中代表性方法。

**结果:** 该综述为推进AI驱动的EHR建模和临床决策支持提供了结构化的路线图，突出了当前的发展趋势和开放挑战。

**结论:** 尽管已经取得了一些进展，但在基准测试、可解释性、临床对齐和跨不同临床环境的泛化等方面仍存在开放挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comprehensive+Survey+of+Electronic+Health+Record+Modeling%3A+From+Deep+Learning+Approaches+to+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12774，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12774&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [20] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
*Jianyu Zhu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种多通道深度学习框架，用于全面的财务风险预测。通过三通道图同构网络处理不同类型的输入，并在7,731家实际NEEQ公司的数据上验证了模型的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 由于规模有限和财务弹性不足，许多NEEQ上市企业面临较高的财务困境风险，需要一种有效的综合财务风险预测方法。

**方法:** 设计了一个三通道图同构网络（GIN），分别处理数值、文本和基于图的输入，使用基于注意力的机制融合这些特定模态的表示，并通过门控单元提高稳健性和预测准确性。

**结果:** 实验结果表明，该模型在AUC、精确度、召回率和F1分数方面显著优于传统机器学习方法和单模态基线。

**结论:** 这项工作为中小企业的风险建模提供了理论和实践见解，并提供了一种支持金融监管机构和投资者的数据驱动工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Channel+Graph+Neural+Network+for+Financial+Risk+Prediction+of+NEEQ+Enterprises，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12787&send_immediately=true&force_search=false)

**原文摘要:** With the continuous evolution of China's multi-level capital market, the
National Equities Exchange and Quotations (NEEQ), also known as the "New Third
Board," has become a critical financing platform for small and medium-sized
enterprises (SMEs). However, due to their limited scale and financial
resilience, many NEEQ-listed companies face elevated risks of financial
distress. To address this issue, we propose a multi-channel deep learning
framework that integrates structured financial indicators, textual disclosures,
and enterprise relationship data for comprehensive financial risk prediction.
Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that
processes numeric, textual, and graph-based inputs separately. These
modality-specific representations are fused using an attention-based mechanism
followed by a gating unit to enhance robustness and prediction accuracy.
Experimental results on data from 7,731 real-world NEEQ companies demonstrate
that our model significantly outperforms traditional machine learning methods
and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.
This work provides theoretical and practical insights into risk modeling for
SMEs and offers a data-driven tool to support financial regulators and
investors.

</details>


### [21] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
*Qianru Zhang, Chenglei Yu, Haixin Wang, Yudong Yan, Yuansheng Cao, Siu-Ming Yiu, Tailin Wu, Hongzhi Yin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架FLDmamba，结合傅里叶和拉普拉斯变换的优势，用于捕捉时间序列数据中的多尺度周期性和瞬态动力学，并提高模型对数据噪声的鲁棒性。实验表明，该方法在时间序列预测基准上优于基于Transformer和其他Mamba架构的方法。


<details>
  <summary>更多</summary>
  
**动机:** 时间序列预测面临非平稳性、多尺度周期性和瞬态动力学等挑战，特别是在长期预测时。现有的Transformer架构由于其复杂度问题在处理长时间序列时效率不高，而最近的State-Space Models（如Mamba）虽然提供了更高效的长期建模方案，但无法有效捕捉多尺度周期性和瞬态动力学，并且容易受到时间序列中数据噪声的影响。

**方法:** 提出了一个名为FLDmamba的新框架，它利用了傅里叶变换和拉普拉斯变换的优点来捕捉时间序列数据中的多尺度周期性和瞬态动力学，同时提高了模型对数据噪声的鲁棒性。

**结果:** 通过广泛的实验证明，FLDmamba在时间序列预测基准上的表现优于基于Transformer和其他Mamba架构的方法。

**结论:** FLDmamba框架解决了现有方法在时间序列预测中存在的问题，特别是在捕捉多尺度周期性和瞬态动力学以及处理数据噪声方面表现优异，为时间序列预测提供了一个有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FLDmamba%3A+Integrating+Fourier+and+Laplace+Transform+Decomposition+with+Mamba+for+Enhanced+Time+Series+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12803，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12803&send_immediately=true&force_search=false)

**原文摘要:** Time series prediction, a crucial task across various domains, faces
significant challenges due to the inherent complexities of time series data,
including non-stationarity, multi-scale periodicity, and transient dynamics,
particularly when tackling long-term predictions. While Transformer-based
architectures have shown promise, their quadratic complexity with sequence
length hinders their efficiency for long-term predictions. Recent advancements
in State-Space Models, such as Mamba, offer a more efficient alternative for
long-term modeling, but they cannot capture multi-scale periodicity and
transient dynamics effectively. Meanwhile, they are susceptible to data noise
issues in time series. This paper proposes a novel framework, FLDmamba (Fourier
and Laplace Transform Decomposition Mamba), addressing these limitations.
FLDmamba leverages the strengths of both Fourier and Laplace transforms to
effectively capture both multi-scale periodicity, transient dynamics within
time series data, and improve the robustness of the model to the data noise
issue. Our extensive experiments demonstrate that FLDmamba achieves superior
performance on time series prediction benchmarks, outperforming both
Transformer-based and other Mamba-based architectures. To promote the
reproducibility of our method, we have made both the code and data accessible
via the following
URL:{\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\model}.

</details>


### [22] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun, Yanfeng Ding, Liping Yi, Huidong Ma, Gang Wang, Xiaoguang Liu, Cheng Zhong, Wentong Cai*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的并行多知识学习型无损压缩器PMKLC，通过四个关键设计解决了现有学习型压缩器的不足。在15个真实数据集上测试表明，PMKLC相比其他基线方法在压缩率、吞吐量、鲁棒性和内存成本方面都有显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于学习的无损压缩器在基因组数据库备份、存储、传输和管理中起着重要作用，但它们的压缩比不足、吞吐量低和压缩鲁棒性差限制了其广泛应用。

**方法:** 提出了自动化多知识学习型压缩框架作为压缩器的骨干，以提高压缩比和鲁棒性；设计了GPU加速的（s，k）-mer编码器以优化吞吐量和计算资源使用；引入了数据块划分和逐步模型传递机制实现并行加速；设计了两种压缩模式PMKLC-S和PMKLC-M以适应复杂的应用场景。

**结果:** PMKLC-S/M分别实现了平均73.609%和73.480%的压缩率改进，平均吞吐量分别提高了3.036倍和10.710倍，并且展示了最佳的鲁棒性和竞争性的内存成本。

**结论:** PMKLC-S/M在不同概率分布扰动的数据集上表现出更大的稳定性，以及在内存受限设备上的强运行能力，显示出其具有更好的性能和更广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PMKLC%3A+Parallel+Multi-Knowledge+Learning-based+Lossless+Compression+for+Large-Scale+Genomics+Database，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12805，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12805&send_immediately=true&force_search=false)

**原文摘要:** Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [23] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
*Sven Dummer, Dongwei Ye, Christoph Brune*

**主要类别:** cs.LG

**AI概要:** 该论文介绍了一种结合降阶模型和算子学习概念的新框架RONOM，旨在解决时变偏微分方程在多查询场景下的计算挑战。它提供了离散化误差边界，并展示了其在空间超分辨率和离散化鲁棒性方面的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 时变偏微分方程在物理建模中无处不在，但在多查询场景下仍存在计算强度大的问题。现有的降阶模型虽然有效，但灵活性不足，而神经算子学习方法虽能适应不同分辨率的数据，却缺乏对无限维与离散算子之间误差的量化。

**方法:** RONOM框架结合了ROM和算子学习的优点，通过建立离散化误差边界来弥补神经算子学习在误差量化上的不足，从而提供对离散化收敛性和鲁棒性的见解。

**结果:** 两个数值例子表明，使用标准矢量到矢量神经网络的RONOM在输入泛化方面达到了可比的性能，在空间超分辨率和离散化鲁棒性方面表现出色，并为时间超分辨率场景提供了新的见解。

**结论:** RONOM框架成功地融合了ROM和神经算子学习的优势，不仅在性能上有所提升，还为解决时变偏微分方程提供了新的思路和工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RONOM%3A+Reduced-Order+Neural+Operator+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12814，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12814&send_immediately=true&force_search=false)

**原文摘要:** Time-dependent partial differential equations are ubiquitous in physics-based
modeling, but they remain computationally intensive in many-query scenarios,
such as real-time forecasting, optimal control, and uncertainty quantification.
Reduced-order modeling (ROM) addresses these challenges by constructing a
low-dimensional surrogate model but relies on a fixed discretization, which
limits flexibility across varying meshes during evaluation. Operator learning
approaches, such as neural operators, offer an alternative by parameterizing
mappings between infinite-dimensional function spaces, enabling adaptation to
data across different resolutions. Whereas ROM provides rigorous numerical
error estimates, neural operator learning largely focuses on discretization
convergence and invariance without quantifying the error between the
infinite-dimensional and the discretized operators. This work introduces the
reduced-order neural operator modeling (RONOM) framework, which bridges
concepts from ROM and operator learning. We establish a discretization error
bound analogous to those in ROM, and get insights into RONOM's discretization
convergence and discretization robustness. Moreover, two numerical examples are
presented that compare RONOM to existing neural operators for solving partial
differential equations. The results demonstrate that RONOM using standard
vector-to-vector neural networks achieves comparable performance in input
generalization and superior performance in both spatial super-resolution and
discretization robustness, while also offering novel insights into temporal
super-resolution scenarios.

</details>


### [24] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
*Gaurav Chaudhary, Laxmidhar Behera*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的离线强化学习奖励标注框架ReLOAD，该方法通过简化随机网络蒸馏来生成内在奖励信号，从而在不需要显式奖励注释的情况下实现了稳健的离线策略学习。


<details>
  <summary>更多</summary>
  
**动机:** 离线强化学习的实际应用通常受到显式奖励注释需求的阻碍，因为这些注释可能昂贵或难以事后获得。

**方法:** ReLOAD采用Random Network Distillation (RND) 来根据专家演示生成内在奖励，使用简单的嵌入差异度量，并以预测误差作为静态数据集中每个转换的奖励信号。

**结果:** D4RL基准上的实验表明，ReLOAD能够实现稳健的离线策略学习，并且其性能与传统奖励标注方法相当。

**结论:** ReLOAD提供了一种结构化的奖励信号机制，无需手工制作奖励注释，为离线强化学习提供了一个有效的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Novelty+to+Imitation%3A+Self-Distilled+Rewards+for+Offline+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12815，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12815&send_immediately=true&force_search=false)

**原文摘要:** Offline Reinforcement Learning (RL) aims to learn effective policies from a
static dataset without requiring further agent-environment interactions.
However, its practical adoption is often hindered by the need for explicit
reward annotations, which can be costly to engineer or difficult to obtain
retrospectively. To address this, we propose ReLOAD (Reinforcement Learning
with Offline Reward Annotation via Distillation), a novel reward annotation
framework for offline RL. Unlike existing methods that depend on complex
alignment procedures, our approach adapts Random Network Distillation (RND) to
generate intrinsic rewards from expert demonstrations using a simple yet
effective embedding discrepancy measure. First, we train a predictor network to
mimic a fixed target network's embeddings based on expert state transitions.
Later, the prediction error between these networks serves as a reward signal
for each transition in the static dataset. This mechanism provides a structured
reward signal without requiring handcrafted reward annotations. We provide a
formal theoretical construct that offers insights into how RND prediction
errors effectively serve as intrinsic rewards by distinguishing expert-like
transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables
robust offline policy learning and achieves performance competitive with
traditional reward-annotated methods.

</details>


### [25] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
*Kaiqi Jiang, Jeremy Cohen, Yuanzhi Li*

**主要类别:** cs.LG

**AI概要:** 本论文研究了在边缘稳定现象期间，神经切线核特征向量的行为，并提供了理论分析。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，对神经切线核（NTKs）的研究和梯度下降中的边缘稳定现象（EoS）的发现，引起了人们对于深度学习中这些动态行为的兴趣。然而，目前对于EoS期间NTK特征向量的行为理解不足。

**方法:** 作者通过观察不同架构下的NTK特征向量动态，探讨了较大的学习率如何影响最终NTK的主要特征向量与训练目标的一致性，并对两层线性网络进行了理论分析。

**结果:** 发现较大步长的学习率会导致最终NTK的主要特征向量及整个NTK矩阵更倾向于与训练目标一致。

**结论:** 这项研究增进了对深度学习中梯度下降训练动态的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+the+Evolution+of+the+Neural+Tangent+Kernel+at+the+Edge+of+Stability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12837，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12837&send_immediately=true&force_search=false)

**原文摘要:** The study of Neural Tangent Kernels (NTKs) in deep learning has drawn
increasing attention in recent years. NTKs typically actively change during
training and are related to feature learning. In parallel, recent work on
Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in
which the largest eigenvalue of the NTK oscillates around a value inversely
proportional to the step size. However, although follow-up works have explored
the underlying mechanism of such eigenvalue behavior in depth, the
understanding of the behavior of the NTK eigenvectors during EoS is still
missing. This paper examines the dynamics of NTK eigenvectors during EoS in
detail. Across different architectures, we observe that larger learning rates
cause the leading eigenvectors of the final NTK, as well as the full NTK
matrix, to have greater alignment with the training target. We then study the
underlying mechanism of this phenomenon and provide a theoretical analysis for
a two-layer linear network. Our study enhances the understanding of GD training
dynamics in deep learning.

</details>


### [26] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
*Zhijian Zhou, Liuhua Peng, Xunye Tian, Feng Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的分布差异度量方法——自适应范数最大平均差异（NAMMD），以改进传统MMD在分布接近度测试中的不足，提高测试能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有分布接近度测试（DCT）方法主要适用于离散一维空间的分布对，对于复杂数据（如图像）的应用有限。引入最大平均差异（MMD）可以扩展DCT到更多类型的数据，但MMD在评估多个分布对的接近度时信息不足。

**方法:** 设计了新的分布差异度量方法——自适应范数最大平均差异（NAMMD），该方法使用RKHS中分布的范数缩放MMD的值，并基于NAMMD的渐近分布提出了用于评估分布对接近度的NAMMD-DCT方法。

**结果:** 理论上证明了NAMMD-DCT比MMD-DCT具有更高的测试能力，并且通过大量实验验证了这一点。此外，在两样本检验问题上，NAMMD也表现出更高的测试能力。

**结论:** 提出的NAMMD方法及其应用在分布接近度测试和两样本检验问题上均展示了更高的测试能力，为处理多种类型的数据提供了一种更有效的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Kernel+Distribution+Closeness+Testing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12843，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12843&send_immediately=true&force_search=false)

**原文摘要:** The distribution closeness testing (DCT) assesses whether the distance
between a distribution pair is at least $\epsilon$-far. Existing DCT methods
mainly measure discrepancies between a distribution pair defined on discrete
one-dimensional spaces (e.g., using total variation), which limits their
applications to complex data (e.g., images). To extend DCT to more types of
data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful
measurement of the distributional discrepancy between two complex
distributions, into DCT scenarios. However, we find that MMD's value can be the
same for many pairs of distributions that have different norms in the same
reproducing kernel Hilbert space (RKHS), making MMD less informative when
assessing the closeness levels for multiple distribution pairs. To mitigate the
issue, we design a new measurement of distributional discrepancy, norm-adaptive
MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions.
Based on the asymptotic distribution of NAMMD, we finally propose the
NAMMD-based DCT to assess the closeness levels of a distribution pair.
Theoretically, we prove that NAMMD-based DCT has higher test power compared to
MMD-based DCT, with bounded type-I error, which is also validated by extensive
experiments on many types of data (e.g., synthetic noise, real images).
Furthermore, we also apply the proposed NAMMD for addressing the two-sample
testing problem and find NAMMD-based two-sample test has higher test power than
the MMD-based two-sample test in both theory and experiments.

</details>


### [27] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
*Danilo Avola, Andrea Bernardini, Francesco Danese, Mario Lezoche, Maurizio Mancini, Daniele Pannone, Amedeo Ranaldi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于CSI的变压器架构，用于在受控室内环境中通过Wi-Fi信号进行人员识别，即使在用户静止时也能实现高精度识别。


<details>
  <summary>更多</summary>
  
**动机:** 为了探索在不依赖用户运动的情况下，通过无线信号进行人员识别的潜力，并提供一种非侵入且保护隐私的人体识别替代方案。

**方法:** 采用双分支变压器架构处理CSI中的幅度和相位模态，引入预处理管道以提高信号质量，并使用ESP32设备收集的数据集进行评估。

**结果:** 实现了99.82%的分类准确率，超过了卷积和多层感知器基线模型。

**结论:** 证明了CSI扰动的区分潜力以及它们编码生物特征的能力，确认了使用低成本Wi-Fi硬件进行无源、免设备人员识别的可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Transformer-Based+Person+Identification+via+Wi-Fi+CSI+Amplitude+and+Phase+Perturbations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12854&send_immediately=true&force_search=false)

**原文摘要:** Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving
alternative to vision-based systems for human identification. However, person
identification through wireless signals, particularly without user motion,
remains largely unexplored. Most prior wireless-based approaches rely on
movement patterns, such as walking gait, to extract biometric cues. In
contrast, we propose a transformer-based method that identifies individuals
from Channel State Information (CSI) recorded while the subject remains
stationary. CSI captures fine-grained amplitude and phase distortions induced
by the unique interaction between the human body and the radio signal. To
support evaluation, we introduce a dataset acquired with ESP32 devices in a
controlled indoor environment, featuring six participants observed across
multiple orientations. A tailored preprocessing pipeline, including outlier
removal, smoothing, and phase calibration, enhances signal quality. Our
dual-branch transformer architecture processes amplitude and phase modalities
separately and achieves 99.82\% classification accuracy, outperforming
convolutional and multilayer perceptron baselines. These results demonstrate
the discriminative potential of CSI perturbations, highlighting their capacity
to encode biometric traits in a consistent manner. They further confirm the
viability of passive, device-free person identification using low-cost
commodity Wi-Fi hardware in real-world settings.

</details>


### [28] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
*Chongli Qin, Jost Tobias Springenberg*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个改进的监督微调方法——重要性加权监督微调（iw-SFT），该方法在处理大型语言模型和连续控制任务方面表现出色，与更高级的强化学习算法具有竞争力。


<details>
  <summary>更多</summary>
  
**动机:** 作者观察到现有的行为克隆（BC）方法在监督微调（SFT）中表现良好，尤其是在对数据进行筛选后。为了理解这一现象，他们将SFT与强化学习（RL）理论联系起来，并指出SFT实际上是在稀疏奖励设置下最大化RL目标的一个下限。基于这一点，他们认为对SFT做小改动可以使其更接近于RL训练的效果。

**方法:** 作者提出的方法是通过引入重要性权重来调整SFT，形成重要性加权监督微调（iw-SFT）。这种方法优化了更紧密的RL目标下限，并且可以在质量评分数据上进一步泛化。

**结果:** 实验表明，重要性加权监督微调（iw-SFT）不仅易于实现，而且在多个基准测试中取得了优异的成绩，包括在AIME 2024数据集上达到了66.7%的成功率。

**结论:** 文章总结道，重要性加权监督微调（iw-SFT）是一种简单而有效的技术，它为监督微调提供了一种新的视角，使其效果更接近于强化学习，并且在实际应用中展现出了强大的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Supervised+Fine+Tuning+on+Curated+Data+is+Reinforcement+Learning+%28and+can+be+improved%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12856，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12856&send_immediately=true&force_search=false)

**原文摘要:** Behavior Cloning (BC) on curated (or filtered) data is the predominant
paradigm for supervised fine-tuning (SFT) of large language models; as well as
for imitation learning of control policies. Here, we draw on a connection
between this successful strategy and the theory and practice of finding optimal
policies via Reinforcement Learning (RL). Building on existing literature, we
clarify that SFT can be understood as maximizing a lower bound on the RL
objective in a sparse reward setting. Giving support to its often observed good
performance. From this viewpoint, we realize that a small modification to SFT
leads to an importance weighted variant that behaves closer to training with RL
as it: i) optimizes a tighter bound to the RL objective and, ii) can improve
performance compared to SFT on curated data. We refer to this variant as
importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to
implement and can be further generalized to training with quality scored data.
The resulting SFT variants are competitive with more advanced RL algorithms for
large language models and for training policies in continuous control tasks.
For example achieving 66.7% on the AIME 2024 dataset.

</details>


### [29] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
*Danilo Avola, Giancarlo Crocetti, Gian Luca Foresti, Daniele Pannone, Claudio Piciarelli, Amedeo Ranaldi*

**主要类别:** cs.LG

**AI概要:** 本文研究了使用耳电极 EEG 信号进行生物特征识别的可行性，提出了一种基于耳 EEG 的新型框架，实验结果表明其平均准确率为82%，证明了该方法作为下一代生物特征识别系统的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于EEG的生物特征系统虽然安全但因为需要头皮电极设置而不易使用。为了提高日常使用的便捷性，本研究探索了使用更方便的耳EEG设备进行生物特征识别的可能性。

**方法:** 系统从耳EEG信号中提取时间与频谱特征，并将这些特征输入全连接的深度神经网络来进行个体识别。

**结果:** 在现有的唯一适合多种用途（包括生物特征识别）的耳EEG数据集上的实验结果显示，在个体识别场景中的平均准确率为82%。

**结论:** 研究结果确认了耳EEG作为一种可行且可部署的方向，用于下一代现实世界的生物特征识别系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Investigation+of+Ear-EEG+Signals+for+a+Novel+Biometric+Authentication+System，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12873，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12873&send_immediately=true&force_search=false)

**原文摘要:** This work explores the feasibility of biometric authentication using EEG
signals acquired through in-ear devices, commonly referred to as ear-EEG.
Traditional EEG-based biometric systems, while secure, often suffer from low
usability due to cumbersome scalp-based electrode setups. In this study, we
propose a novel and practical framework leveraging ear-EEG signals as a
user-friendly alternative for everyday biometric authentication. The system
extracts an original combination of temporal and spectral features from ear-EEG
signals and feeds them into a fully connected deep neural network for subject
identification. Experimental results on the only currently available ear-EEG
dataset suitable for different purposes, including biometric authentication,
demonstrate promising performance, with an average accuracy of 82\% in a
subject identification scenario. These findings confirm the potential of
ear-EEG as a viable and deployable direction for next-generation real-world
biometric systems.

</details>


### [30] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
*Pavel Snopov, Oleg R. Musin*

**主要类别:** cs.LG

**AI概要:** 研究提出新型激活函数，通过引入拓扑“切割”能力，增强神经网络在训练过程中操作数据拓扑的能力，尤其在低维场景中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 传统的激活函数如ReLU存在局限性，特别是在处理低维层中的复杂数据流形时效果不佳。因此，本研究旨在探索新的激活函数，以改善神经网络的数据拓扑操作能力。

**方法:** 研究提出了两种新的激活函数：SmoothSplit和ParametricSplit。这两种函数都具有拓扑“切割”的功能，可以帮助网络更有效地转换复杂的数据流形。

**结果:** 实验结果表明，在低维场景下，ParametricSplit的性能优于传统的激活函数，同时在高维场景下也保持了竞争力。

**结论:** 研究结果强调了拓扑感知激活函数在改进神经网络架构方面的潜力，并提供了代码供进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Topology-Aware+Activation+Functions+in+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12874，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12874&send_immediately=true&force_search=false)

**原文摘要:** This study explores novel activation functions that enhance the ability of
neural networks to manipulate data topology during training. Building on the
limitations of traditional activation functions like $\mathrm{ReLU}$, we
propose $\mathrm{SmoothSplit}$ and $\mathrm{ParametricSplit}$, which introduce
topology "cutting" capabilities. These functions enable networks to transform
complex data manifolds effectively, improving performance in scenarios with
low-dimensional layers. Through experiments on synthetic and real-world
datasets, we demonstrate that $\mathrm{ParametricSplit}$ outperforms
traditional activations in low-dimensional settings while maintaining
competitive performance in higher-dimensional ones. Our findings highlight the
potential of topology-aware activation functions in advancing neural network
architectures. The code is available via
https://github.com/Snopoff/Topology-Aware-Activations.

</details>


### [31] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng, Hengkai Tan, Xinyi Mao, Guodong Liu, Shuhe Huang, Chendong Xiang, Hang Su, Jun Zhu*

**主要类别:** cs.LG

**AI概要:** VIDAR是一个两阶段框架，利用大规模视频预训练和新的遮罩逆动力学模型进行动作预测，实现了对未见过的任务和背景的强大泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决双臂机器人操作中的数据稀缺性和实体异质性问题，推动一般用途的双臂机器人操作技术的发展。

**方法:** VIDAR采用了一个两阶段框架：第一阶段是在75万个来自三个真实双臂机器人平台的多视角视频上预训练一个视频扩散模型；第二阶段是使用一个新的遮罩逆动力学模型来从生成的轨迹中提取与动作相关的信息。

**结果:** 实验表明，VIDAR仅需20分钟的人类演示（仅占典型数据需求的1%），即可在未见过的机器人平台上实现对新任务和背景的强大泛化能力，超越了现有最先进方法。

**结论:** 研究结果强调了结合视频基础模型和遮罩动作预测以实现可扩展且通用的机器人操作的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalist+Bimanual+Manipulation+via+Foundation+Video+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12898，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12898&send_immediately=true&force_search=false)

**原文摘要:** Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [32] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
*Luca Stradiotti, Dario Pesenti, Stefano Teso, Jesse Davis*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一个框架LtX和一个工具ULER，用于识别和拒绝低质量的机器学习预测解释。实验表明，ULER在多个基准测试中优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 随着机器学习预测器在信用评分等高风险应用中的使用增加，解释预测原因的重要性也日益提高。然而，这些解释并不总是高质量的，可能难以被用户解读或信任。这使得评估信任度和下游决策变得复杂。因此，有必要为分类器提供拒绝处理那些无法正确解释其预测的输入的能力。

**方法:** 作者引入了LtX框架，该框架使预测器配备了一个评估解释质量的拒绝器。进一步地，他们引入了ULER（以用户为中心的低质量解释拒绝器），它从人工评分和每个特征的相关性判断中学习简单的拒绝器，以反映人类对解释质量的判断。

**结果:** 实验结果表明，与最先进的方法和其他具有解释意识的学习拒绝策略相比，ULER在八个分类和回归基准测试以及新的人工标注数据集上表现更好。

**结论:** 作者认为，通过LtX框架和ULER，可以更有效地识别和拒绝低质量的解释，从而改善用户对机器学习模型预测的信任和理解。同时，他们将公开发布新的数据集以支持未来的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Reject+Low-Quality+Explanations+via+User+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12900，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12900&send_immediately=true&force_search=false)

**原文摘要:** Machine Learning predictors are increasingly being employed in high-stakes
applications such as credit scoring. Explanations help users unpack the reasons
behind their predictions, but are not always "high quality''. That is,
end-users may have difficulty interpreting or believing them, which can
complicate trust assessment and downstream decision-making. We argue that
classifiers should have the option to refuse handling inputs whose predictions
cannot be explained properly and introduce a framework for learning to reject
low-quality explanations (LtX) in which predictors are equipped with a rejector
that evaluates the quality of explanations. In this problem setting, the key
challenges are how to properly define and assess explanation quality and how to
design a suitable rejector. Focusing on popular attribution techniques, we
introduce ULER (User-centric Low-quality Explanation Rejector), which learns a
simple rejector from human ratings and per-feature relevance judgments to
mirror human judgments of explanation quality. Our experiments show that ULER
outperforms both state-of-the-art and explanation-aware learning to reject
strategies at LtX on eight classification and regression benchmarks and on a
new human-annotated dataset, which we will publicly release to support future
research.

</details>


### [33] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
*Jiadong Chen, Hengyu Ye, Fuxin Jiang, Xiao He, Tieying Zhang, Jianjun Chen, Xiaofeng Gao*

**主要类别:** cs.LG

**AI概要:** 提出了一种高效且准确的深度预测模型Fremer，用于云服务工作负载预测，开源了四个高质量数据集，并在多个评估指标上超越现有模型。


<details>
  <summary>更多</summary>
  
**动机:** Transformer-based的预测模型虽然在通用任务中表现出色，但在大规模云环境中计算效率不足。由于工作负载序列通常具有复杂的周期性模式，在频率域解决问题能带来显著优势。

**方法:** 提出了名为Fremer的深度预测模型，该模型在效率、准确性和多周期序列处理方面表现出色。同时，收集并开源了四个来自字节跳动云服务的高质量工作负载数据集。

**结果:** 实验表明，Fremer在私有数据集和公共基准测试中均优于基线模型，平均改进MSE 5.5%，MAE 4.7%，SMAPE 8.6%。此外，基于Kubernetes的自动扩展测试中，平均延迟降低了18.78%，资源消耗减少了2.35%。

**结论:** Fremer不仅在性能上超越了现有的SOTA模型，而且在实际应用中也展示了其高效性和资源节省能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fremer%3A+Lightweight+and+Effective+Frequency+Transformer+for+Workload+Forecasting+in+Cloud+Services，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12908&send_immediately=true&force_search=false)

**原文摘要:** Workload forecasting is pivotal in cloud service applications, such as
auto-scaling and scheduling, with profound implications for operational
efficiency. Although Transformer-based forecasting models have demonstrated
remarkable success in general tasks, their computational efficiency often falls
short of the stringent requirements in large-scale cloud environments. Given
that most workload series exhibit complicated periodic patterns, addressing
these challenges in the frequency domain offers substantial advantages. To this
end, we propose Fremer, an efficient and effective deep forecasting model.
Fremer fulfills three critical requirements: it demonstrates superior
efficiency, outperforming most Transformer-based forecasting models; it
achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in
workload forecasting; and it exhibits robust performance for multi-period
series. Furthermore, we collect and open-source four high-quality, open-source
workload datasets derived from ByteDance's cloud services, encompassing
workload data from thousands of computing instances. Extensive experiments on
both our proprietary datasets and public benchmarks demonstrate that Fremer
consistently outperforms baseline models, achieving average improvements of
5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while
simultaneously reducing parameter scale and computational costs. Additionally,
in a proactive auto-scaling test based on Kubernetes, Fremer improves average
latency by 18.78% and reduces resource consumption by 2.35%, underscoring its
practical efficacy in real-world applications.

</details>


### [34] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
*Chenrui Zhu, Louenas Bounia, Vu Linh Nguyen, Sébastien Destercke, Arthur Hoarau*

**主要类别:** cs.LG

**AI概要:** 本文提出利用预测不确定性作为经典可解释性方法的补充，通过区分数据相关和模型相关的不确定性来选择适当的解释。实验表明，这种基于不确定性的可解释性方法框架提高了解释的稳健性和可达性。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习模型架构日益复杂化，导致其可解释性降低。因此，需要提高模型预测的透明度。

**方法:** 该研究提出了一个由不确定性量化和分解驱动的可解释性方法框架，使用两种类型的不确定性：aleatoric（数据相关）和epistemic（模型相关）来指导选择合适的解释方法。

**结果:** 实验证明了这种不确定性感知方法对解释的稳健性和可达性的影响。

**结论:** 提出的基于不确定性的可解释性方法可以增强传统机器学习和深度学习场景中解释的可靠性和实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Explanations+Through+Uncertainty+Decomposition%3A+A+Path+to+Trustworthier+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12913，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12913&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in machine learning have emphasized the need for
transparency in model predictions, particularly as interpretability diminishes
when using increasingly complex architectures. In this paper, we propose
leveraging prediction uncertainty as a complementary approach to classical
explainability methods. Specifically, we distinguish between aleatoric
(data-related) and epistemic (model-related) uncertainty to guide the selection
of appropriate explanations. Epistemic uncertainty serves as a rejection
criterion for unreliable explanations and, in itself, provides insight into
insufficient training (a new form of explanation). Aleatoric uncertainty
informs the choice between feature-importance explanations and counterfactual
explanations. This leverages a framework of explainability methods driven by
uncertainty quantification and disentanglement. Our experiments demonstrate the
impact of this uncertainty-aware approach on the robustness and attainability
of explanations in both traditional machine learning and deep learning
scenarios.

</details>


### [35] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
*Franziska Weindel, Michael Girsch, Reinhard Heckel*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为TReconLM的新方法，它利用语言模型进行追踪重建，特别适用于DNA数据存储中的错误修正。该方法在合成数据上预训练并在真实数据上微调，以适应特定技术的错误模式。实验表明，TReconLM在追踪重建任务上的表现优于现有的最先进算法。


<details>
  <summary>更多</summary>
  
**动机:** 由于DNA数据存储中存在高密度信息和长寿命的优势，但同时在合成、存储和测序过程中引入的错误需要通过算法和编码进行纠正，因此需要一种有效的追踪重建方法来提高数据恢复的准确性。

**方法:** 提出了一种新的追踪重建方法TReconLM，它基于语言模型进行训练，首先在合成数据上进行预训练，然后在真实数据上进行微调，以适应特定技术的错误模式。

**结果:** 实验结果表明，TReconLM在追踪重建任务上的表现优于现有的最先进算法，能够无误地恢复更多的序列。

**结论:** 本文提出的TReconLM方法可以有效地用于追踪重建任务，特别是在DNA数据存储中的错误修正方面表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trace+Reconstruction+with+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12927&send_immediately=true&force_search=false)

**原文摘要:** The general trace reconstruction problem seeks to recover an original
sequence from its noisy copies independently corrupted by deletions,
insertions, and substitutions. This problem arises in applications such as DNA
data storage, a promising storage medium due to its high information density
and longevity. However, errors introduced during DNA synthesis, storage, and
sequencing require correction through algorithms and codes, with trace
reconstruction often used as part of the data retrieval process. In this work,
we propose TReconLM, which leverages language models trained on next-token
prediction for trace reconstruction. We pretrain language models on synthetic
data and fine-tune on real-world data to adapt to technology-specific error
patterns. TReconLM outperforms state-of-the-art trace reconstruction
algorithms, including prior deep learning approaches, recovering a
substantially higher fraction of sequences without error.

</details>


### [36] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
*Shirui Zhao, Jun Yin, Lingyun Yao, Martin Andraud, Wannes Meert, Marian Verhelst*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为MC²A的算法-硬件协同设计框架，用于实现MCMC加速的高效和灵活优化。通过分析MCMC工作负载多样性、提出参数化硬件加速器架构以及采用新型Gumbel采样器，MC²A在各种代表性MCMC工作负载上实现了显著的速度提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的MCMC加速解决方案要么在硬件灵活性上有限制，要么无法在系统级别保持效率，这限制了MCMC算法在大规模问题和实际应用中的可行性。

**方法:** 首先，MC²A通过扩展处理器性能屋顶线模型来分析MCMC工作负载多样性，并推导计算、采样和内存参数之间的最佳平衡。其次，它提出了一个参数化的硬件加速器架构，包括ISA可编程树形结构处理单元、可重构采样器和交叉开关互连。最后，它使用了一个新的Gumbel采样器，消除了指数和归一化操作。

**结果:** 在端到端案例研究中，与CPU、GPU、TPU和最先进的MCMC加速器相比，MC²A分别实现了307.6倍、1.4倍、2.0倍和84.2倍的速度提升。

**结论:** 这项工作展示了通用硬件加速在各种代表性MCMC工作负载上的可行性，有望推广基于MCMC的解决方案在不同应用领域中的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MC%24%5E2%24A%3A+Enabling+Algorithm-Hardware+Co-Design+for+Efficient+Markov+Chain+Monte+Carlo+Acceleration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12935&send_immediately=true&force_search=false)

**原文摘要:** An increasing number of applications are exploiting sampling-based algorithms
for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC)
algorithms form the computational backbone of this emerging branch of machine
learning. Unfortunately, the high computational cost limits their feasibility
for large-scale problems and real-world applications, and the existing MCMC
acceleration solutions are either limited in hardware flexibility or fail to
maintain efficiency at the system level across a variety of end-to-end
applications. This paper introduces \textbf{MC$^2$A}, an algorithm-hardware
co-design framework, enabling efficient and flexible optimization for MCMC
acceleration. Firstly, \textbf{MC$^2$A} analyzes the MCMC workload diversity
through an extension of the processor performance roofline model with a 3rd
dimension to derive the optimal balance between the compute, sampling and
memory parameters. Secondly, \textbf{MC$^2$A} proposes a parametrized hardware
accelerator architecture with flexible and efficient support of MCMC kernels
with a pipeline of ISA-programmable tree-structured processing units,
reconfigurable samplers and a crossbar interconnect to support irregular
access. Thirdly, the core of \textbf{MC$^2$A} is powered by a novel Gumbel
sampler that eliminates exponential and normalization operations. In the
end-to-end case study, \textbf{MC$^2$A} achieves an overall {$307.6\times$,
$1.4\times$, $2.0\times$, $84.2\times$} speedup compared to the CPU, GPU, TPU
and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC
workloads, this work demonstrates and exploits the feasibility of general
hardware acceleration to popularize MCMC-based solutions in diverse application
domains.

</details>


### [37] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
*Hongze Tan*

**主要类别:** cs.LG

**AI概要:** 本文针对DAPO算法提出了两种新颖的改进方法，通过混合策略视角引入预训练稳定引导策略以提高训练稳定性和收敛速度，并重新利用零奖励样本以增强样本效率。


<details>
  <summary>更多</summary>
  
**动机:** 标准策略梯度方法在稀疏奖励环境中可能遇到不稳定性和样本效率低的问题，特别是在自动后编辑优化中。

**方法:** 首先提出了一种结合预训练稳定引导策略的方法，该方法提供离线策略经验，从而调整目标策略的学习步长。其次，通过将零奖励样本作为由专家策略指导的独立批次进行处理，进一步提高样本效率。

**结果:** 理论分析表明，这两种方法的目标函数在强化学习的理论框架内收敛到最优解，有效平衡了探索和利用，实现了更稳定和高效的策略优化。

**结论:** 所提出的混合策略框架有效地改善了DAPO算法的训练稳定性和样本效率，为解决稀疏奖励环境下的问题提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+a+Mixed-Policy+Perspective%3A+Improving+Differentiable+Automatic+Post-editing+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12931&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces two novel modifications to the Differentiable Automatic
Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy
perspective. Standard policy gradient methods can suffer from instability and
sample inefficiency, particularly in sparse reward settings. To address this,
we first propose a method that incorporates a pre-trained, stable guiding
policy ($\piphi$) to provide off-policy experience, thereby regularizing the
training of the target policy ($\pion$). This approach improves training
stability and convergence speed by adaptively adjusting the learning step size.
Secondly, we extend this idea to re-utilize zero-reward samples, which are
often discarded by dynamic sampling strategies like DAPO's. By treating these
samples as a distinct batch guided by the expert policy, we further enhance
sample efficiency. We provide a theoretical analysis for both methods,
demonstrating that their objective functions converge to the optimal solution
within the established theoretical framework of reinforcement learning. The
proposed mixed-policy framework effectively balances exploration and
exploitation, promising more stable and efficient policy optimization.

</details>


### [38] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
*Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的去中心化GAN训练方法，利用分布式数据和低能力设备，在不共享原始数据的情况下，解决了数据异构性和设备异构性的挑战，并在多个性能指标上显示出显著改进。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成模型训练需要大量的数据集和计算资源，这在现实环境中往往难以获得。此外，获取大型数据集面临隐私问题和版权限制。许多未充分利用的设备（如物联网设备和边缘设备）具有不同的能力，但通常处于闲置状态。

**方法:** 结合了KLD加权聚类联邦学习和异构U形分裂学习，以解决数据异构性和多域数据集的问题，以及在严格的数据共享限制下解决设备异构性的挑战。确保节点之间不共享标签或原始数据。

**结果:** 实验结果显示，该方法在关键性能指标上表现出一致且显著的改进：图像生成得分提高了1.1倍至2.2倍，分类指标平均提升了10%（在多域非IID设置中最高可达50%），并且相比几个基准测试具有更低的延迟。

**结论:** 所提出的方法有效地利用了分布式数据和低能力设备进行去中心化的GAN训练，在保护数据隐私的同时显著提高了性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Distributed+Generative+AI+Approach+for+Heterogeneous+Multi-Domain+Environments+under+Data+Sharing+constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12979，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12979&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning has gained increasing attention for its ability to enable
multiple nodes to collaboratively train machine learning models without sharing
their raw data. At the same time, Generative AI -- particularly Generative
Adversarial Networks (GANs) -- have achieved remarkable success across a wide
range of domains, such as healthcare, security, and Image Generation. However,
training generative models typically requires large datasets and significant
computational resources, which are often unavailable in real-world settings.
Acquiring such resources can be costly and inefficient, especially when many
underutilized devices -- such as IoT devices and edge devices -- with varying
capabilities remain idle. Moreover, obtaining large datasets is challenging due
to privacy concerns and copyright restrictions, as most devices are unwilling
to share their data. To address these challenges, we propose a novel approach
for decentralized GAN training that enables the utilization of distributed data
and underutilized, low-capability devices while not sharing data in its raw
form. Our approach is designed to tackle key challenges in decentralized
environments, combining KLD-weighted Clustered Federated Learning to address
the issues of data heterogeneity and multi-domain datasets, with Heterogeneous
U-Shaped split learning to tackle the challenge of device heterogeneity under
strict data sharing constraints -- ensuring that no labels or raw data, whether
real or synthetic, are ever shared between nodes. Experimental results shows
that our approach demonstrates consistent and significant improvements across
key performance metrics, where it achieves 1.1x -- 2.2x higher image generation
scores, an average 10% boost in classification metrics (up to 50% in
multi-domain non-IID settings), in much lower latency compared to several
benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.

</details>


### [39] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin, Yaroslav Aksenov, Daniil Laptev, Gleb Gerasimov, Nikita Balagansky, Daniil Gavrilov*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种残差学习方法，通过训练辅助稀疏自编码器（SAE）来建模预训练SAE在特定领域文本上的重构误差，从而捕捉到主模型未发现的特征。实验表明该方法在多个专业领域显著改善了大型语言模型的交叉熵和解释方差指标，并且可以在不完全重新训练的情况下有效地将新领域知识整合到现有的SAE中。


<details>
  <summary>更多</summary>
  
**动机:** 稀疏自编码器（SAE）作为解析大型语言模型内部表示的强大工具，常常无法捕捉其训练语料库中不常见的特定领域特征。为了解决这种特征盲性问题，并避免完全重新训练模型的需求，提出了这种方法。

**方法:** 提出训练一个次要的稀疏自编码器（SAE）以专门模拟预训练SAE在特定领域文本上的重构误差，从而捕捉被主模型遗漏的特征。在推理时将两个模型的输出相加，以此提高性能。

**结果:** 通过该方法，在多个专业领域中，大型语言模型的交叉熵和解释方差指标都有显著提升，同时能够保持在一般任务上的性能。

**结论:** 本研究提出的残差学习方法能够在不进行完全重新训练的情况下，有效增强现有SAE对特定领域的解释能力，为有针对性的机制解释开辟了新的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Teach+Old+SAEs+New+Domain+Tricks+with+Boosting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12990，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12990&send_immediately=true&force_search=false)

**原文摘要:** Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [40] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You, Anton Xue, Shreya Havaldar, Delip Rao, Helen Jin, Chris Callison-Burch, Eric Wong*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的概率框架ARES，防止大语言模型的推理链中错误传播。它在四个基准上达到了最先进水平，并在很长的合成推理链上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于LLM的错误检测方法无法有效检测传播错误，因为它们没有充分考虑早期错误如何影响后续推理判断。

**方法:** 引入了自回归推理蕴含稳定性（ARES），一种新颖的概率框架，通过仅根据先前评估过的可靠前提来判断每个主张，以阻止错误传播。

**结果:** ARES在四个基准上实现了72.1%的宏F1得分，比之前最好结果高出8.2个百分点，在长合成推理链上的F1得分为90.3%，高出27.6个百分点。

**结论:** ARES提供了一种有效的方法来检测和防止大型语言模型生成的推理链中的错误传播，具有优越的稳健性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probabilistic+Soundness+Guarantees+in+LLM+Reasoning+Chains，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12948&send_immediately=true&force_search=false)

**原文摘要:** In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [41] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
*Kossi Amouzouvi, Bowen Song, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种框架，通过评估不同几何变换对关系的适应性，并利用注意力机制为每个关系分配最佳匹配的变换，从而在低维向量空间中学习特定于关系的初等几何变换（EGT）。此外，还使用了高维向量空间中的关系嵌入来表示关系和EGT之间的相关性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的知识图谱嵌入模型虽然使用了几何变换来有效保存知识图谱的结构和关系模式，但这些变换并没有考虑到关系特定的转换，这使得它们的表现有所不足。

**方法:** 作者提出了一种新的框架，该框架首先评估每种关系与不同几何变换的匹配程度，然后根据这个排名，通过注意力机制为每个关系选择最适合的变换，或者通过多数投票选择一种变换应用于所有关系。

**结果:** 通过在三个基准知识图谱和一个真实世界的金融知识图谱上的全面评估，证明了该模型的有效性，并且其性能可与领先的模型相媲美。

**结论:** 提出的框架能够更好地处理知识图谱中的关系特定变换问题，从而提高了模型的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMART%3A+Relation-Aware+Learning+of+Geometric+Representations+for+Knowledge+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13001，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13001&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graph representation learning approaches provide a mapping between
symbolic knowledge in the form of triples in a knowledge graph (KG) and their
feature vectors. Knowledge graph embedding (KGE) models often represent
relations in a KG as geometric transformations. Most state-of-the-art (SOTA)
KGE models are derived from elementary geometric transformations (EGTs), such
as translation, scaling, rotation, and reflection, or their combinations. These
geometric transformations enable the models to effectively preserve specific
structural and relational patterns of the KG. However, the current use of EGTs
by KGEs remains insufficient without considering relation-specific
transformations. Although recent models attempted to address this problem by
ensembling SOTA baseline models in different ways, only a single or composite
version of geometric transformations are used by such baselines to represent
all the relations. In this paper, we propose a framework that evaluates how
well each relation fits with different geometric transformations. Based on this
ranking, the model can: (1) assign the best-matching transformation to each
relation, or (2) use majority voting to choose one transformation type to apply
across all relations. That is, the model learns a single relation-specific EGT
in low dimensional vector space through an attention mechanism. Furthermore, we
use the correlation between relations and EGTs, which are learned in a low
dimension, for relation embeddings in a high dimensional vector space. The
effectiveness of our models is demonstrated through comprehensive evaluations
on three benchmark KGs as well as a real-world financial KG, witnessing a
performance comparable to leading models

</details>


### [42] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
*Kenza Bouzid, Shruthi Bannur, Daniel Coelho de Castro, Anton Schwaighofer, Javier Alvarez-Valle, Stephanie L. Hyland*

**主要类别:** cs.LG

**AI概要:** 本文应用Matryoshka-SAE解析放射学专业的多模态大语言模型MAIRA-2的内部表示，通过大规模自动化解释SAE特征，识别出一系列临床上相关的概念，并检查这些特征对模型行为的影响。


<details>
  <summary>更多</summary>
  
**动机:** 提高AI模型的安全性、透明度和信任度，特别是在医疗保健应用中，可解释性尤其重要。

**方法:** 使用稀疏自动编码器（SAEs），特别是Matryoshka-SAE，解析大型基于变压器的模型中的可解释特征。

**结果:** 识别出一系列临床上相关的概念，包括医疗设备、病理、纵向变化和文本特征，并展示了对生成内容的方向控制。

**结论:** 尽管存在实际和方法上的挑战，但为更深入的机制理解和解释铺平了道路，提高了模型的透明度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Insights+into+a+radiology-specialised+multimodal+large+language+model+with+sparse+autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12950，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12950&send_immediately=true&force_search=false)

**原文摘要:** Interpretability can improve the safety, transparency and trust of AI models,
which is especially important in healthcare applications where decisions often
carry significant consequences. Mechanistic interpretability, particularly
through the use of sparse autoencoders (SAEs), offers a promising approach for
uncovering human-interpretable features within large transformer-based models.
In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal
large language model, MAIRA-2, to interpret its internal representations. Using
large-scale automated interpretability of the SAE features, we identify a range
of clinically relevant concepts - including medical devices (e.g., line and
tube placements, pacemaker presence), pathologies such as pleural effusion and
cardiomegaly, longitudinal changes and textual features. We further examine the
influence of these features on model behaviour through steering, demonstrating
directional control over generations with mixed success. Our results reveal
practical and methodological challenges, yet they offer initial insights into
the internal concepts learned by MAIRA-2 - marking a step toward deeper
mechanistic understanding and interpretability of a radiology-adapted
multimodal large language model, and paving the way for improved model
transparency. We release the trained SAEs and interpretations:
https://huggingface.co/microsoft/maira-2-sae.

</details>


### [43] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
*Vincenzo Dentamaro, Felice Franchini, Giuseppe Pirlo, Irina Voiculescu*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的XAI技术MUPAX，具有确定性、模型无关性和收敛性保证，通过结构化扰动分析来发现固有的输入模式并消除错误关系，适用于各种数据模态和任务。


<details>
  <summary>更多</summary>
  
**动机:** 现有的XAI方法通常在遮挡时性能下降，而理想的XAI技术应同时具备确定性、模型无关性和收敛性保证。

**方法:** MUPAX使用测度论公式，通过结构化扰动分析来提供原则性的特征重要性归因，从而发现内在的输入模式并消除错误关系。它可以在任何损失函数和任意维度上严格保证收敛。

**结果:** MUPAX不仅保持而且提高了模型准确性，并能生成精确、一致且可理解的解释。广泛的基准测试表明了MUPAX的能力和优越性。

**结论:** MUPAX是一种新型的XAI技术，可以捕捉到原始数据中最重要的模式，为实现可解释和可信的AI系统迈出关键一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MUPAX%3A+Multidimensional+Problem+Agnostic+eXplainable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13090，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13090&send_immediately=true&force_search=false)

**原文摘要:** Robust XAI techniques should ideally be simultaneously deterministic, model
agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM
AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability
technique, with guaranteed convergency. MUPAX measure theoretic formulation
gives principled feature importance attribution through structured perturbation
analysis that discovers inherent input patterns and eliminates spurious
relationships. We evaluate MUPAX on an extensive range of data modalities and
tasks: audio classification (1D), image classification (2D), volumetric medical
image analysis (3D), and anatomical landmark detection, demonstrating dimension
agnostic effectiveness. The rigorous convergence guarantees extend to any loss
function and arbitrary dimensions, making MUPAX applicable to virtually any
problem context for AI. By contrast with other XAI methods that typically
decrease performance when masking, MUPAX not only preserves but actually
enhances model accuracy by capturing only the most important patterns of the
original data. Extensive benchmarking against the state of the XAI art
demonstrates MUPAX ability to generate precise, consistent and understandable
explanations, a crucial step towards explainable and trustworthy AI systems.
The source code will be released upon publication.

</details>


### [44] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
*Anna Bison, Alessandro Sperduti*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于图形设计领域中Fairing算法的多分辨率水库图神经网络（MRGNN）变体，用于解决图神经网络中的过度平滑问题。通过理论分析和实验验证了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的水库计算方法虽然提高了图神经网络的训练效率，但在重复应用层操作时会出现过度平滑的问题，导致图信号趋向于图拉普拉斯算子的低频分量。为了解决这个问题，本文重新定义了水库模型，并引入了Fairing算法。

**方法:** 本文提出的方法是基于图形设计领域的Fairing算法，提供了一个带通光谱滤波器，可以在不收缩的情况下进行平滑处理。该方法可以通过拉普拉斯算子适应于图形设置，并与GNN架构自然连接，特别是在需要控制平滑度的任务如图形分类中。

**结果:** 通过探索性实验表明，该方法在多分辨率水库图神经网络架构中有很大的潜力，并为未来的研究指明了有希望的方向。

**结论:** 本文的主要贡献在于从随机游走的角度对提出的算法进行了理论分析，特别是展示了如何调整光谱系数可以被解释为调节冗余随机游走的贡献。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Spectral+Interpretation+of+Redundancy+in+a+Graph+Reservoir，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12963，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12963&send_immediately=true&force_search=false)

**原文摘要:** Reservoir computing has been successfully applied to graphs as a
preprocessing method to improve the training efficiency of Graph Neural
Networks (GNNs). However, a common issue that arises when repeatedly applying
layer operators on graphs is over-smoothing, which consists in the convergence
of graph signals toward low-frequency components of the graph Laplacian. This
work revisits the definition of the reservoir in the Multiresolution Reservoir
Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a
variant based on a Fairing algorithm originally introduced in the field of
surface design in computer graphics. This algorithm provides a pass-band
spectral filter that allows smoothing without shrinkage, and it can be adapted
to the graph setting through the Laplacian operator. Given its spectral
formulation, this method naturally connects to GNN architectures for tasks
where smoothing, when properly controlled, can be beneficial,such as graph
classification. The core contribution of the paper lies in the theoretical
analysis of the algorithm from a random walks perspective. In particular, it
shows how tuning the spectral coefficients can be interpreted as modulating the
contribution of redundant random walks. Exploratory experiments based on the
MRGNN architecture illustrate the potential of this approach and suggest
promising directions for future research.

</details>


### [45] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun, Mihaela van der Schaar*

**主要类别:** cs.LG

**AI概要:** 本文综述了大型语言模型（LLM）对齐领域的最新进展，强调逆向强化学习（IRL）在其中的作用，讨论了构建神经奖励模型的必要性，并探讨了数据集、评估指标及未来研究方向等。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLM）的发展，对其可靠性和可控性的要求越来越高，而强化学习（RL）在提升这些系统方面取得了成功，因此有必要深入研究RL和LLM对齐的交集，特别是逆向强化学习（IRL）的应用。

**方法:** 文章首先介绍RL的基本概念，然后考察了最近的研究进展，讨论了关键挑战和机会，还探讨了实际方面如数据集、基准测试、评估指标等。

**结果:** 通过综合不同研究的结果，提供了该领域的结构化和批判性概述，突出了未解决的挑战，并勾勒出未来改进LLM对齐的研究方向。

**结论:** 为了提高LLM的对齐效果，需要继续探索RL和IRL技术，解决当前存在的挑战并开拓新的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inverse+Reinforcement+Learning+Meets+Large+Language+Model+Post-Training%3A+Basics%2C+Advances%2C+and+Opportunities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13158，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13158&send_immediately=true&force_search=false)

**原文摘要:** In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


### [46] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
*Reza Riahi Samani, Alfredo Nunez, Bart De Schutter*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种基于深度学习的框架，用于使用行驶中的振动响应信号进行基础设施健康监测。通过结合光谱和时间信息，该方法在铁路轨道刚度估计等应用中显著优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 作者认识到频谱和时间信息的重要性，并希望提供一种无需预处理即可在各种测量速度下分析行驶中振动信号的方法，从而实现基础设施健康状况的高分辨率评估。

**方法:** 提出WaveletInception-BiLSTM网络，其中WaveletInception特征提取器使用可学习的小波包变换（LWPT）来提取早期网络层中的振动信号特征，并结合光谱信息。1D Inception网络在更深层中提取多尺度的高级特征。提取的振动信号特征通过长短期记忆（LSTM）层与操作条件集成，以捕捉不同信息模式之间的相关时间依赖关系。最终使用双向LSTM（BiLSTM）网络进行健康状况估计。

**结果:** 案例研究表明，在使用模拟行驶中振动信号进行铁路轨道刚度估计时，该模型显著优于最先进的方法，尤其是在估计铁路道砟和轨枕的刚度参数方面。

**结论:** 本研究展示了这种新方法在准确、局部化和完全自动化的行驶中基础设施健康监测方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是WaveletInception+Networks+for+Drive-by+Vibration-Based+Infrastructure+Health+Monitoring，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12969，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12969&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a novel deep learning-based framework for infrastructure
health monitoring using drive-by vibration response signals. Recognizing the
importance of spectral and temporal information, we introduce the
WaveletInception-BiLSTM network. The WaveletInception feature extractor
utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting
vibration signal features, incorporating spectral information in the early
network layers. This is followed by 1D Inception networks that extract
multi-scale, high-level features at deeper layers. The extracted vibration
signal features are then integrated with operational conditions via a Long
Short-term Memory (LSTM) layer. The resulting feature extraction network
effectively analyzes drive-by vibration signals across various measurement
speeds without preprocessing and uses LSTM to capture interrelated temporal
dependencies among different modes of information and to create feature vectors
for health condition estimation. The estimator head is designed with a
sequential modeling architecture using bidirectional LSTM (BiLSTM) networks,
capturing bi-directional temporal relationships from drive-by measurements.
This architecture allows for a high-resolution, beam-level assessment of
infrastructure health conditions. A case study focusing on railway track
stiffness estimation with simulated drive-by vibration signals shows that the
model significantly outperforms state-of-the-art methods in estimating railway
ballast and railpad stiffness parameters. Results underscore the potential of
this approach for accurate, localized, and fully automated drive-by
infrastructure health monitoring.

</details>


### [47] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
*Zikai Xie, Linjiang Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于排序算法生成置换空间核函数的新框架，特别是引入了复杂度更低的Merge Kernel，并结合三种描述符来提升在排列优化基准上的性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前最先进的贝叶斯优化方法在置换空间上依赖于Mallows核，其复杂度为Ω(n^2)，需要明确枚举每一对比较。这激发了研究者探索一种可以降低计算复杂度并提高效率的新方法。

**方法:** 该框架利用排序算法生成核函数，在这个框架下，Mallows核可以看作是冒泡排序的一个特例。新提出的Merge Kernel基于归并排序，以Θ(n log n)的时间复杂度取代了二次复杂度，从而降低了计算成本。此外，还加入了三个轻量级的任务无关描述符：移位直方图、拆分对线和滑动窗口主题，以增强鲁棒性和不变性。

**结果:** 实证评估表明，所提出的核函数在各种排列优化基准上始终优于最先进的Mallows核，证实了Merge Kernel提供了一个更紧凑且更有效的贝叶斯优化解决方案。

**结论:** 提出的基于排序算法的核函数生成框架，尤其是Merge Kernel，为贝叶斯优化在置换空间中的应用提供了更高效的工具。通过集成额外的描述符，可以在不牺牲紧凑性的前提下增强性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge+Kernel+for+Bayesian+Optimization+on+Permutation+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13263，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13263&send_immediately=true&force_search=false)

**原文摘要:** Bayesian Optimization (BO) algorithm is a standard tool for black-box
optimization problems. The current state-of-the-art BO approach for permutation
spaces relies on the Mallows kernel-an $\Omega(n^2)$ representation that
explicitly enumerates every pairwise comparison. Inspired by the close
relationship between the Mallows kernel and pairwise comparison, we propose a
novel framework for generating kernel functions on permutation space based on
sorting algorithms. Within this framework, the Mallows kernel can be viewed as
a special instance derived from bubble sort. Further, we introduce the
\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic
complexity with $\Theta(n\log n)$ to achieve the lowest possible complexity.
The resulting feature vector is significantly shorter, can be computed in
linearithmic time, yet still efficiently captures meaningful permutation
distances. To boost robustness and right-invariance without sacrificing
compactness, we further incorporate three lightweight, task-agnostic
descriptors: (1) a shift histogram, which aggregates absolute element
displacements and supplies a global misplacement signal; (2) a split-pair line,
which encodes selected long-range comparisons by aligning elements across the
two halves of the whole permutation; and (3) sliding-window motifs, which
summarize local order patterns that influence near-neighbor objectives. Our
empirical evaluation demonstrates that the proposed kernel consistently
outperforms the state-of-the-art Mallows kernel across various permutation
optimization benchmarks. Results confirm that the Merge Kernel provides a more
compact yet more effective solution for Bayesian optimization in permutation
space.

</details>


### [48] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
*ShanBin Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为FedGA的公平性感知联邦学习算法，通过Gini系数衡量客户性能差异并动态调整聚合权重以提高模型公平性。实验结果表明该方法在多个数据集上提高了公平性指标并保持了整体性能。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中的数据异质性常常导致客户之间的性能差异显著，这引发了对模型行为公平性的担忧。为了应对这一问题，需要一种能够改善客户间性能均衡性的联邦学习算法。

**方法:** 首先使用Gini系数衡量客户间的性能差异，建立Gini系数与全局模型更新规模的关系，以确定公平性干预的时机；然后根据系统的实时公平状态动态调整聚合权重，使全局模型更好地结合表现较差客户的资讯。

**结果:** 在Office-Caltech-10、CIFAR-10和Synthetic数据集上的广泛实验表明，FedGA有效地改善了如方差和Gini系数等公平性指标，并且同时维持了强大的整体性能。

**结论:** FedGA是一种有效的公平性感知联邦学习算法，它不仅提高了模型的公平性，而且没有牺牲整体性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedGA%3A+A+Fair+Federated+Learning+Framework+Based+on+the+Gini+Coefficient，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12983，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12983&send_immediately=true&force_search=false)

**原文摘要:** Fairness has emerged as one of the key challenges in federated learning. In
horizontal federated settings, data heterogeneity often leads to substantial
performance disparities across clients, raising concerns about equitable model
behavior. To address this issue, we propose FedGA, a fairness-aware federated
learning algorithm. We first employ the Gini coefficient to measure the
performance disparity among clients. Based on this, we establish a relationship
between the Gini coefficient $G$ and the update scale of the global model
${U_s}$, and use this relationship to adaptively determine the timing of
fairness intervention. Subsequently, we dynamically adjust the aggregation
weights according to the system's real-time fairness status, enabling the
global model to better incorporate information from clients with relatively
poor performance.We conduct extensive experiments on the Office-Caltech-10,
CIFAR-10, and Synthetic datasets. The results show that FedGA effectively
improves fairness metrics such as variance and the Gini coefficient, while
maintaining strong overall performance, demonstrating the effectiveness of our
approach.

</details>


### [49] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
*Luis Basora, Louison Bocquet-Nouaille, Elinirina Robinson, Serge Le Gonidec*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于时间卷积自编码器的机载故障检测和诊断方法，适用于下一代可重复使用航天发射器的电气系统。该方法可以估计预测置信度、检测异常分布案例并控制误报。


<details>
  <summary>更多</summary>
  
**动机:** 现有文献中的方法无法满足广泛的故障检测和诊断需求，如估计预测置信水平、检测OOD案例和控制误报。

**方法:** 采用时间卷积自编码器自动从原始传感器数据中提取低维特征，并分别在自编码器潜在空间和残差空间上训练二分类和多分类分类器进行故障检测和诊断。分类器是基于直方图的梯度提升模型，校准为输出概率作为置信水平。还使用了归纳一致性异常检测技术来识别OOD数据，以及CUSUM等简单有效的方法来限制误报。

**结果:** 该框架高度可配置，在模拟数据上的评估结果表明其是一个有希望的第一步，但需要通过真实数据测试以确保达到操作使用所需的成熟度水平。

**结论:** 尽管该解决方案展示了初步的可行性，但在实际应用前仍需通过真实数据进一步验证其性能和可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fault+detection+and+diagnosis+for+the+engine+electrical+system+of+a+space+launcher+based+on+a+temporal+convolutional+autoencoder+and+calibrated+classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13022，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13022&send_immediately=true&force_search=false)

**原文摘要:** In the context of the health monitoring for the next generation of reusable
space launchers, we outline a first step toward developing an onboard fault
detection and diagnostic capability for the electrical system that controls the
engine valves. Unlike existing approaches in the literature, our solution is
designed to meet a broader range of key requirements. This includes estimating
confidence levels for predictions, detecting out-of-distribution (OOD) cases,
and controlling false alarms. The proposed solution is based on a temporal
convolutional autoencoder to automatically extract low-dimensional features
from raw sensor data. Fault detection and diagnosis are respectively carried
out using a binary and a multiclass classifier trained on the autoencoder
latent and residual spaces. The classifiers are histogram-based gradient
boosting models calibrated to output probabilities that can be interpreted as
confidence levels. A relatively simple technique, based on inductive conformal
anomaly detection, is used to identify OOD data. We leverage other simple yet
effective techniques, such as cumulative sum control chart (CUSUM) to limit the
false alarms, and threshold moving to address class imbalance in fault
detection. The proposed framework is highly configurable and has been evaluated
on simulated data, covering both nominal and anomalous operational scenarios.
The results indicate that our solution is a promising first step, though
testing with real data will be necessary to ensure that it achieves the
required maturity level for operational use.

</details>


### [50] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
*Ahmed Emam, Ribana Roscher*

**主要类别:** cs.LG

**AI概要:** 提出了一种结合LRP注意力滚动和深度确定性不确定性估计的新框架CFR，以分析模型不确定性如何影响卫星图像自然性解释的相关性热图的可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 当前使用卫星图像和机器学习大规模监测自然保护区的方法通常缺乏可解释性和不确定性意识，没有解决不确定性如何影响自然性评估的问题。

**方法:** 引入了Confidence-Filtered Relevance (CFR)框架，它将LRP Attention Rollout与Deep Deterministic Uncertainty (DDU)估计相结合，根据不确定性阈值对数据集进行划分，系统地分析不确定性如何塑造卫星图像中自然性的解释。

**结果:** 在AnthroProtect数据集上的应用表明，CFR为灌木丛、森林和湿地分配了更高的相关性，这与其他关于自然性评估的研究相吻合。随着不确定性的增加，相关性热图的可解释性下降，熵增加，表明选择性降低和归因更加模糊。

**结论:** CFR提供了一种基于其关联确定性来评估模式对卫星图像中自然性相关性的数据驱动方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Confidence-Filtered+Relevance+%28CFR%29%3A+An+Interpretable+and+Uncertainty-Aware+Machine+Learning+Framework+for+Naturalness+Assessment+in+Satellite+Imagery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13034&send_immediately=true&force_search=false)

**原文摘要:** Protected natural areas play a vital role in ecological balance and ecosystem
services. Monitoring these regions at scale using satellite imagery and machine
learning is promising, but current methods often lack interpretability and
uncertainty-awareness, and do not address how uncertainty affects naturalness
assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a
data-centric framework that combines LRP Attention Rollout with Deep
Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty
influences the interpretability of relevance heatmaps. CFR partitions the
dataset into subsets based on uncertainty thresholds, enabling systematic
analysis of how uncertainty shapes the explanations of naturalness in satellite
imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to
shrublands, forests, and wetlands, aligning with other research on naturalness
assessment. Moreover, our analysis shows that as uncertainty increases, the
interpretability of these relevance heatmaps declines and their entropy grows,
indicating less selective and more ambiguous attributions. CFR provides a
data-centric approach to assess the relevance of patterns to naturalness in
satellite imagery based on their associated certainty.

</details>


### [51] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
*Lefei Shen, Mouxiang Chen, Han Fu, Xiaoxue Ren, Xiaoyun Joy Wang, Jianling Sun, Zhuo Li, Chenghao Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的分类法，可以更清晰地比较Transformer架构在长期时间序列预测任务中的表现。通过大量实验，作者发现双向注意力机制、更完整的预测聚合和直接映射范式是最佳选择，并且他们的组合模型优于现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于Transformer的长期时间序列预测模型往往与特定的时间序列设计紧密结合，难以单独评估架构本身的影响。因此，需要一种方法来解开这些设计，以便更清晰地比较不同架构的效果。

**方法:** 作者提出了一种新的分类法，该分类法考虑了注意力机制、预测聚合、预测范式和标准化层等关键方面。然后，他们使用此分类法进行了广泛的实验，以确定哪种架构最适合长期时间序列预测任务。

**结果:** 实验结果表明，双向注意机制、更完整的预测聚合和直接映射范式的结合是最有效的。此外，他们的组合模型在多个数据集上均超过了现有模型。

**结论:** 这些发现为未来关于Transformer架构设计的研究提供了宝贵的指导，特别是在长期时间序列预测领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Power+of+Architecture%3A+Deep+Dive+into+Transformer+Architectures+for+Long-Term+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13043，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13043&send_immediately=true&force_search=false)

**原文摘要:** Transformer-based models have recently become dominant in Long-term Time
Series Forecasting (LTSF), yet the variations in their architecture, such as
encoder-only, encoder-decoder, and decoder-only designs, raise a crucial
question: What Transformer architecture works best for LTSF tasks? However,
existing models are often tightly coupled with various time-series-specific
designs, making it difficult to isolate the impact of the architecture itself.
To address this, we propose a novel taxonomy that disentangles these designs,
enabling clearer and more unified comparisons of Transformer architectures. Our
taxonomy considers key aspects such as attention mechanisms, forecasting
aggregations, forecasting paradigms, and normalization layers. Through
extensive experiments, we uncover several key insights: bi-directional
attention with joint-attention is most effective; more complete forecasting
aggregation improves performance; and the direct-mapping paradigm outperforms
autoregressive approaches. Furthermore, our combined model, utilizing optimal
architectural choices, consistently outperforms several existing models,
reinforcing the validity of our conclusions. We hope these findings offer
valuable guidance for future research on Transformer architectural designs in
LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.

</details>


### [52] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
*Vittorio Cipriani, Valentino Delle Rose, Luca San Mauro, Giovanni Solda*

**主要类别:** cs.LG

**AI概要:** 研究了由可数无限图G的副本形成假设类的PAC和在线学习性，证明了所有此类有限支持副本的PAC学习性意味着G的完整同构类型的在线学习性，并等价于自动同态平凡性条件。


<details>
  <summary>更多</summary>
  
**动机:** 为了探讨在已知结构和标签集的情况下，学习图的标记的可能性。特别是对于那些只移动有限多个顶点的排列所形成的副本。

**方法:** 考虑了那些只移动有限多个顶点的排列所形成的副本类，并使用无限随机图的扩展属性的放松版本来表征通过交换两个顶点诱导的副本不可学习的图。

**结果:** 主要结果表明，所有此类有限支持副本的PAC学习性意味着G的完整同构类型的在线学习性，并且等价于自动同态平凡性条件。此外，对于所有G和k>2，k个顶点排列的学习性等价于2个顶点排列的学习性。

**结论:** 为无限图形创建了一个四类分区，并确定了其复杂性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+statistical+learning+of+graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13054&send_immediately=true&force_search=false)

**原文摘要:** We study PAC and online learnability of hypothesis classes formed by copies
of a countably infinite graph G, where each copy is induced by permuting G's
vertices. This corresponds to learning a graph's labeling, knowing its
structure and label set. We consider classes where permutations move only
finitely many vertices. Our main result shows that PAC learnability of all such
finite-support copies implies online learnability of the full isomorphism type
of G, and is equivalent to the condition of automorphic triviality. We also
characterize graphs where copies induced by swapping two vertices are not
learnable, using a relaxation of the extension property of the infinite random
graph. Finally, we show that, for all G and k>2, learnability for k-vertex
permutations is equivalent to that for 2-vertex permutations, yielding a
four-class partition of infinite graphs, whose complexity we also determine
using tools coming from both descriptive set theory and computability theory.

</details>


### [53] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
*Pengjin Wu, Ferrante Neri, Zhenhua Feng*

**主要类别:** cs.LG

**AI概要:** 本文提出了DASViT，一种应用于视觉转换器的可微架构搜索方法。实验表明，DASViT发现的架构比ViT-B/16在多个数据集上表现更好，且参数更少、FLOPs更低。


<details>
  <summary>更多</summary>
  
**动机:** 现有的NAS方法在探索ViT架构时主要集中在宏观层面的搜索空间，并依赖于离散方法，如进化算法，这些方法虽然可靠但难以发现创新设计且计算成本高耗时长。

**方法:** 作者引入了Differentiable Architecture Search for Vision Transformer (DASViT)，它填补了ViTs中可微分搜索的空白并揭示新的设计。

**结果:** 实验表明，DASViT提供的架构打破了传统的Transformer编码器设计，在多个数据集上的表现优于ViT-B/16，并且具有更高的效率，使用更少的参数和FLOPs。

**结论:** DASViT提供了一种新的有效的方法来自动设计ViT架构，该方法不仅能够提高模型性能，还能减少计算资源的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DASViT%3A+Differentiable+Architecture+Search+for+Vision+Transformer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13079，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13079&send_immediately=true&force_search=false)

**原文摘要:** Designing effective neural networks is a cornerstone of deep learning, and
Neural Architecture Search (NAS) has emerged as a powerful tool for automating
this process. Among the existing NAS approaches, Differentiable Architecture
Search (DARTS) has gained prominence for its efficiency and ease of use,
inspiring numerous advancements. Since the rise of Vision Transformers (ViT),
researchers have applied NAS to explore ViT architectures, often focusing on
macro-level search spaces and relying on discrete methods like evolutionary
algorithms. While these methods ensure reliability, they face challenges in
discovering innovative architectural designs, demand extensive computational
resources, and are time-intensive. To address these limitations, we introduce
Differentiable Architecture Search for Vision Transformer (DASViT), which
bridges the gap in differentiable search for ViTs and uncovers novel designs.
Experiments show that DASViT delivers architectures that break traditional
Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and
achieve superior efficiency with fewer parameters and FLOPs.

</details>


### [54] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
*Hyo-Jeong Jang, Hye-Bin Shin, Seong-Whan Lee*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的跨模态知识蒸馏框架，通过原型相似性模块和特定任务的蒸馏头来对齐特征语义并解决标签不一致的问题，从而提高了基于EEG的情感回归和分类性能。


<details>
  <summary>更多</summary>
  
**动机:** 电生理信号（EEG）在脑机接口中用于认知状态监测，但容易受到内在信号错误和人为标注错误的影响，导致标签噪声并最终降低模型性能。现有的多模态知识蒸馏方法虽然可以将视觉模型的知识迁移到EEG模型上，但面临着模态差距和软标签错位两大挑战。

**方法:** 作者提出了一个新颖的跨模态知识蒸馏框架，该框架通过引入基于原型的相似性模块来对齐特征语义，并引入特定任务的蒸馏头以解决由标签引起的监督不一致性问题。

**结果:** 实验结果表明，所提出的方法在公开的多模态数据集上，提升了基于EEG的情感回归和分类的表现，超过了单模态和多模态基线模型。

**结论:** 这些发现突显了该框架在脑机接口应用中的潜力，特别是在处理语义不确定性、模糊特征和定义不清的标签方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Uncertainty-Aware+Cross-Modal+Knowledge+Distillation+with+Prototype+Learning+for+Multimodal+Brain-Computer+Interfaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13092，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13092&send_immediately=true&force_search=false)

**原文摘要:** Electroencephalography (EEG) is a fundamental modality for cognitive state
monitoring in brain-computer interfaces (BCIs). However, it is highly
susceptible to intrinsic signal errors and human-induced labeling errors, which
lead to label noise and ultimately degrade model performance. To enhance EEG
learning, multimodal knowledge distillation (KD) has been explored to transfer
knowledge from visual models with rich representations to EEG-based models.
Nevertheless, KD faces two key challenges: modality gap and soft label
misalignment. The former arises from the heterogeneous nature of EEG and visual
feature spaces, while the latter stems from label inconsistencies that create
discrepancies between ground truth labels and distillation targets. This paper
addresses semantic uncertainty caused by ambiguous features and weakly defined
labels. We propose a novel cross-modal knowledge distillation framework that
mitigates both modality and label inconsistencies. It aligns feature semantics
through a prototype-based similarity module and introduces a task-specific
distillation head to resolve label-induced inconsistency in supervision.
Experimental results demonstrate that our approach improves EEG-based emotion
regression and classification performance, outperforming both unimodal and
multimodal baselines on a public multimodal dataset. These findings highlight
the potential of our framework for BCI applications.

</details>


### [55] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
*Yuanxin Zhuang, Dazhong Shen, Ying Sun*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的图生成框架NGTM，它能够生成具有竞争力质量的图形，并且可以实现细粒度控制和解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图生成方法虽然能生成逼真的图形，但其可解释性有限，难以明确结构决策背后的理由。

**方法:** 受自然语言处理中主题建模的启发，提出了神经图主题模型（NGTM），该模型将图形表示为潜在主题的混合物，每个主题定义了一个语义上有意义的子结构的分布，从而在局部和全局尺度上促进了显式的可解释性。

**结果:** 实验证明，NGTM在实现竞争性的生成质量的同时，独特地实现了细粒度控制和可解释性，允许用户通过主题级别的调整来调整结构特征或诱导生物特性。

**结论:** NGTM不仅在生成质量上具有竞争力，而且还能提供对生成过程的清晰语义追踪，以及对生成图形的细粒度控制和解释能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NGTM%3A+Substructure-based+Neural+Graph+Topic+Model+for+Interpretable+Graph+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13133，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13133&send_immediately=true&force_search=false)

**原文摘要:** Graph generation plays a pivotal role across numerous domains, including
molecular design and knowledge graph construction. Although existing methods
achieve considerable success in generating realistic graphs, their
interpretability remains limited, often obscuring the rationale behind
structural decisions. To address this challenge, we propose the Neural Graph
Topic Model (NGTM), a novel generative framework inspired by topic modeling in
natural language processing. NGTM represents graphs as mixtures of latent
topics, each defining a distribution over semantically meaningful
substructures, which facilitates explicit interpretability at both local and
global scales. The generation process transparently integrates these topic
distributions with a global structural variable, enabling clear semantic
tracing of each generated graph. Experiments demonstrate that NGTM achieves
competitive generation quality while uniquely enabling fine-grained control and
interpretability, allowing users to tune structural features or induce
biological properties through topic-level adjustments.

</details>


### [56] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
*Maksim Borisov, Egor Spirin, Daria Diatlova*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一个新的开源数据集NonverbalTTS，包含17小时的语音数据，标注有10种非语言发声和8种情感类别。该数据集通过自动检测和人工验证的方式从VoxCeleb和Expresso两个流行来源中提取。使用NVTTS微调的开源文本到语音模型在人类评估和自动度量方面与闭源系统CosyVoice2相当。


<details>
  <summary>更多</summary>
  
**动机:** 当前表达性语音合成模型受到开放源代码数据集中多样非语言发声（NVs）有限可用性的限制。为了克服这一瓶颈，研究人员引入了NonverbalTTS (NVTTS)数据集。

**方法:** 研究人员首先从VoxCeleb和Expresso这两个流行来源中提取数据，然后使用自动检测技术识别出包含非语言发声的部分，并通过人工验证确保准确性。接着，他们设计了一套综合处理流程，结合自动语音识别、非语言发声标记、情感分类和融合算法来整合多个标注者的转录结果。

**结果:** 在NVTTS上进行微调的开源文本到语音模型在说话人相似性和非语言发声保真度等指标上达到了与闭源系统CosyVoice2相匹配的水平。

**结论:** 通过发布NVTTS及其配套的标注指南，研究者们解决了表达性文本到语音研究中的一个关键瓶颈问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NonverbalTTS%3A+A+Public+English+Corpus+of+Text-Aligned+Nonverbal+Vocalizations+with+Emotion+Annotations+for+Text-to-Speech，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13155，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13155&send_immediately=true&force_search=false)

**原文摘要:** Current expressive speech synthesis models are constrained by the limited
availability of open-source datasets containing diverse nonverbal vocalizations
(NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access
dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional
categories. The dataset is derived from popular sources, VoxCeleb and Expresso,
using automated detection followed by human validation. We propose a
comprehensive pipeline that integrates automatic speech recognition (ASR), NV
tagging, emotion classification, and a fusion algorithm to merge transcriptions
from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models
on the NVTTS dataset achieves parity with closed-source systems such as
CosyVoice2, as measured by both human evaluation and automatic metrics,
including speaker similarity and NV fidelity. By releasing NVTTS and its
accompanying annotation guidelines, we address a key bottleneck in expressive
TTS research. The dataset is available at
https://huggingface.co/datasets/deepvk/NonverbalTTS.

</details>


### [57] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
*Ofir Nabati, Bo Dai, Shie Mannor, Guy Tennenholtz*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的框架——Spectral Bellman Representation，它从内在Bellman误差条件出发，直接面向基于价值的强化学习。该方法揭示了在零IBE条件下，Bellman算子对价值函数分布的转换与特征协方差结构之间存在根本的光谱关系，并提出了一种新的理论基础目标，用于学习能捕捉这种Bellman对齐协方差的状态-动作特征。通过实验证明，所学表示有助于结构化探索并提高整体性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的表示学习主要由模型学习方面引起，但与RL任务不匹配。为了更直接地针对基于价值的强化学习，需要一种新的框架来更好地与Bellman更新的基本结构对齐。

**方法:** 作者引入了Spectral Bellman Representation框架，该框架来源于Inherent Bellman Error (IBE)条件，旨在发现零IBE条件下的基本光谱关系，并利用这一关系为学习状态-动作特征提供新目标。

**结果:** 实验表明，使用所学表示可以实现结构化探索，将特征协方差与Bellman动态对齐，并提高了整体性能，特别是在具有挑战性的探索困难和长期信用分配任务中。

**结论:** Spectral Bellman Representation提供了一个原则性和有效的方法，以学习更强大和结构合理的基于价值的强化学习表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spectral+Bellman+Method%3A+Unifying+Representation+and+Exploration+in+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13181，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13181&send_immediately=true&force_search=false)

**原文摘要:** The effect of representation has been demonstrated in reinforcement learning,
from both theoretical and empirical successes. However, the existing
representation learning mainly induced from model learning aspects, misaligning
with our RL tasks. This work introduces Spectral Bellman Representation, a
novel framework derived from the Inherent Bellman Error (IBE) condition, which
aligns with the fundamental structure of Bellman updates across a space of
possible value functions, therefore, directly towards value-based RL. Our key
insight is the discovery of a fundamental spectral relationship: under the
zero-IBE condition, the transformation of a distribution of value functions by
the Bellman operator is intrinsically linked to the feature covariance
structure. This spectral connection yields a new, theoretically-grounded
objective for learning state-action features that inherently capture this
Bellman-aligned covariance. Our method requires a simple modification to
existing algorithms. We demonstrate that our learned representations enable
structured exploration, by aligning feature covariance with Bellman dynamics,
and improve overall performance, particularly in challenging hard-exploration
and long-horizon credit assignment tasks. Our framework naturally extends to
powerful multi-step Bellman operators, further broadening its impact. Spectral
Bellman Representation offers a principled and effective path toward learning
more powerful and structurally sound representations for value-based
reinforcement learning.

</details>


### [58] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
*Shreyas Chaudhari, Srinivasa Pranav, José M. F. Moura*

**主要类别:** cs.LG

**AI概要:** 本文利用Monotone Gradient Networks (mGradNets)通过最小化基于Monge-Ampère方程定义的训练损失函数直接学习最优传输映射，并将其应用于机器人集群控制问题。


<details>
  <summary>更多</summary>
  
**动机:** 解决Monge形式的最优传输问题在现代应用中至关重要，如流体动力学到机器人集群控制。Brenier定理保证了当运输成本是平方欧几里得距离时，唯一最优映射是凸函数的梯度，即单调梯度映射，它满足Monge-Ampère方程。

**方法:** 作者提出使用Monotone Gradient Networks (mGradNets)，这是一种直接参数化单调梯度映射空间的神经网络，通过最小化一个由Monge-Ampère方程定义的训练损失函数来直接学习最优传输映射。

**结果:** 实证结果显示mGradNets的结构偏差有助于学习最优传输映射，并且该方法被用于机器人集群控制问题。

**结论:** mGradNets为学习最优传输映射提供了一种有效的方法，并展示了其在机器人集群控制中的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GradNetOT%3A+Learning+Optimal+Transport+Maps+with+GradNets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13191，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13191&send_immediately=true&force_search=false)

**原文摘要:** Monotone gradient functions play a central role in solving the Monge
formulation of the optimal transport problem, which arises in modern
applications ranging from fluid dynamics to robot swarm control. When the
transport cost is the squared Euclidean distance, Brenier's theorem guarantees
that the unique optimal map is the gradient of a convex function, namely a
monotone gradient map, and it satisfies a Monge-Amp\`ere equation. In
[arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks
(mGradNets), neural networks that directly parameterize the space of monotone
gradient maps. In this work, we leverage mGradNets to directly learn the
optimal transport mapping by minimizing a training loss function defined using
the Monge-Amp\`ere equation. We empirically show that the structural bias of
mGradNets facilitates the learning of optimal transport maps and employ our
method for a robot swarm control problem.

</details>


### [59] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
*Etienne Le Naour, Tahar Nabil, Ghislain Agoua*

**主要类别:** cs.LG

**AI概要:** 本文提出了MoTM模型，用于时间序列的缺失值填补任务，特别是在分布外数据上的表现更为突出。


<details>
  <summary>更多</summary>
  
**动机:** 尽管近年来对时间序列预测任务的关注度很高，但对分布外缺失值填补任务的研究仍然不足。为了弥补这一空白，作者提出了一种新的方法来处理这个问题。

**方法:** 该研究引入了MoTM（Mixture of Timeflow Models），它结合了隐式神经表示（INRs）和脊回归器，以适应不同的时间序列模式，并在推理时根据观察到的情境进行调整。

**结果:** 通过各种填补场景的实验，证明了MoTM模型在域内和域外的泛化能力都表现出色。

**结论:** 这项工作为时间序列填补提供了一个灵活的基础模型，能够处理多种缺失情况和采样率的变化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoTM%3A+Towards+a+Foundation+Model+for+Time+Series+Imputation+based+on+Continuous+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13207，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13207&send_immediately=true&force_search=false)

**原文摘要:** Recent years have witnessed a growing interest for time series foundation
models, with a strong emphasis on the forecasting task. Yet, the crucial task
of out-of-domain imputation of missing values remains largely underexplored. We
propose a first step to fill this gap by leveraging implicit neural
representations (INRs). INRs model time series as continuous functions and
naturally handle various missing data scenarios and sampling rates. While they
have shown strong performance within specific distributions, they struggle
under distribution shifts. To address this, we introduce MoTM (Mixture of
Timeflow Models), a step toward a foundation model for time series imputation.
Building on the idea that a new time series is a mixture of previously seen
patterns, MoTM combines a basis of INRs, each trained independently on a
distinct family of time series, with a ridge regressor that adapts to the
observed context at inference. We demonstrate robust in-domain and
out-of-domain generalization across diverse imputation scenarios (e.g., block
and pointwise missingness, variable sampling rates), paving the way for
adaptable foundation imputation models.

</details>


### [60] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
*Maria Margarida Mascarenhas, Jilles De Blauwe, Mikael Amelin, Hussain Kazmi*

**主要类别:** cs.LG

**AI概要:** 本文研究了不同关闭时间（GCTs）的市场中异步发布的价格能否提高其他市场的预测准确性。通过使用先进的模型组合，发现包含更早GCT市场的价格数据能显著提高比利时和瑞典特定区域的预测准确性。频繁调整模型可提高准确度但计算成本高，且并非使用越多市场的数据越好。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，数据驱动技术在短期电价预测方面取得了很高的准确性，但这些技术严重依赖输入协变量的质量。因此，本论文探究了由于不同投标区的关门闭合时间（GCTs）不同而异步公布的价格是否可以提高其他具有较晚GCT市场的预测准确性。

**方法:** 本研究使用了一流的模型集成方法，将互联市场（如德国-卢森堡、奥地利和瑞士）中较早GCT的价格数据纳入到对后来GCT的比利时（BE）和瑞典（SE3）投标区的预测中，并分析了对一般和极端市场条件下的预测改进情况。

**结果:** 当包括来自与之相连且GCT较早的市场的价格数据时，在比利时（BE）和瑞典（SE3）投标区的预测准确性分别提高了22%和9%，这一结果适用于一般以及极端市场条件下。此外，还发现了频繁重新校准模型是必要的，但这会带来额外的计算成本，并不是引入更多市场的数据就一定能提升性能。

**结论:** 本研究的发现为市场参与者和决策者提供了宝贵的指导，有助于他们在日益互联和波动的欧洲能源市场中优化投标策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Asynchronous+Cross-border+Market+Data+for+Improved+Day-Ahead+Electricity+Price+Forecasting+in+European+Markets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13250，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13250&send_immediately=true&force_search=false)

**原文摘要:** Accurate short-term electricity price forecasting is crucial for
strategically scheduling demand and generation bids in day-ahead markets. While
data-driven techniques have shown considerable prowess in achieving high
forecast accuracy in recent years, they rely heavily on the quality of input
covariates. In this paper, we investigate whether asynchronously published
prices as a result of differing gate closure times (GCTs) in some bidding zones
can improve forecasting accuracy in other markets with later GCTs. Using a
state-of-the-art ensemble of models, we show significant improvements of 22%
and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3)
respectively, when including price data from interconnected markets with
earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement
holds for both general as well as extreme market conditions. Our analysis also
yields further important insights: frequent model recalibration is necessary
for maximum accuracy but comes at substantial additional computational costs,
and using data from more markets does not always lead to better performance - a
fact we delve deeper into with interpretability analysis of the forecast
models. Overall, these findings provide valuable guidance for market
participants and decision-makers aiming to optimize bidding strategies within
increasingly interconnected and volatile European energy markets.

</details>


### [61] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
*Vincenzo Marco De Luca, Giovanna Varni, Andrea Passerini*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的团队建模架构TRENN，它能同时捕捉关系和时间团队动态，并通过多任务学习预测多个团队结构。实验表明，该方法在解释性和性能上均优于现有方法，适用于以人为中心的AI应用。


<details>
  <summary>更多</summary>
  
**动机:** 当前的研究未能满足实际应用对统一模型的需求，这些模型需要能够同时推断多个团队结构，提供可解释的见解和可操作的建议以提高团队表现。

**方法:** 作者提出了TRENN，一种新的节奏-关系架构，集成了自动时间图提取器、节奏-关系编码器、团队结构预测解码器和两个互补的可解释性模块。此外，还提出了MT-TRENN，它用多任务头替换了TRENN的解码器，使模型能够学习共享的社会嵌入并同时预测多个团队结构。

**结果:** 实验结果表明，所提出的方法在解释性和性能方面都显著优于仅依赖时间或关系信息的方法。

**结论:** 这些能力使得该方法特别适合于以人为中心的AI应用，如智能决策支持系统，在高风险协作环境中为团队改进提供了可解释的见解和可操作的建议。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Boosting+Team+Modeling+through+Tempo-Relational+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13305&send_immediately=true&force_search=false)

**原文摘要:** Team modeling remains a fundamental challenge at the intersection of
Artificial Intelligence and the Social Sciences. Social Science research
emphasizes the need to jointly model dynamics and relations, while practical
applications demand unified models capable of inferring multiple team
constructs simultaneously, providing interpretable insights and actionable
recommendations to enhance team performance. However, existing works do not
meet these practical demands. To bridge this gap, we present TRENN, a novel
tempo-relational architecture that integrates: (i) an automatic temporal graph
extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct
prediction, and (iv) two complementary explainability modules. TRENN jointly
captures relational and temporal team dynamics, providing a solid foundation
for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task
head, enabling the model to learn shared Social Embeddings and simultaneously
predict multiple team constructs, including Emergent Leadership, Leadership
Style, and Teamwork components. Experimental results demonstrate that our
approach significantly outperforms approaches that rely exclusively on temporal
or relational information. Additionally, experimental evaluation has shown that
the explainability modules integrated in MT-TRENN yield interpretable insights
and actionable suggestions to support team improvement. These capabilities make
our approach particularly well-suited for Human-Centered AI applications, such
as intelligent decision-support systems in high-stakes collaborative
environments.

</details>


### [62] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
*Kyeongjin Ahn, Sungwon Han, Seungeon Lee, Donghyun Ahn, Hyoshin Kim, Jungwon Kim, Jihee Kim, Sangyoon Park, Meeyoung Cha*

**主要类别:** cs.LG

**AI概要:** 本研究引入GeoReg模型，结合多种数据源，利用大型语言模型的知识来估计社会经济指标，尤其适用于数据稀缺地区。通过实验验证，该模型在不同发展阶段的国家中均优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 社会经济指标对政策制定和可持续发展至关重要，但在数据稀缺地区难以准确估算。因此，需要一种新的方法来有效评估这些地区的社会经济状况。

**方法:** GeoReg模型整合了卫星图像、基于网络的地理空间信息等多样化的数据来源，并利用大型语言模型作为数据工程师提取特征。根据特征与目标指标之间的关系（正相关、负相关、混合或无关），对特征进行分类并赋予不同的权重限制。此外，还识别有意义的特征交互作用并结合非线性转换以捕捉非线性模式。

**结果:** 在三个不同发展阶段的国家进行的实验表明，GeoReg模型在估算社会经济指标方面优于基线模型，特别是在数据有限的低收入国家。

**结论:** GeoReg模型提供了一种有效的解决方案，用于估算数据稀缺地区（如发展中国家）的社会经济指标，为政策制定提供了有力支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GeoReg%3A+Weight-Constrained+Few-Shot+Regression+for+Socio-Economic+Estimation+using+LLM，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13323，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13323&send_immediately=true&force_search=false)

**原文摘要:** Socio-economic indicators like regional GDP, population, and education
levels, are crucial to shaping policy decisions and fostering sustainable
development. This research introduces GeoReg a regression model that integrates
diverse data sources, including satellite imagery and web-based geospatial
information, to estimate these indicators even for data-scarce regions such as
developing countries. Our approach leverages the prior knowledge of large
language model (LLM) to address the scarcity of labeled data, with the LLM
functioning as a data engineer by extracting informative features to enable
effective estimation in few-shot settings. Specifically, our model obtains
contextual relationships between data features and the target indicator,
categorizing their correlations as positive, negative, mixed, or irrelevant.
These features are then fed into the linear estimator with tailored weight
constraints for each category. To capture nonlinear patterns, the model also
identifies meaningful feature interactions and integrates them, along with
nonlinear transformations. Experiments across three countries at different
stages of development demonstrate that our model outperforms baselines in
estimating socio-economic indicators, even for low-income countries with
limited data availability.

</details>


### [63] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
*Laker Newhouse, R. Preston Hess, Franz Cesista, Andrii Zahorodnii, Jeremy Bernstein, Phillip Isola*

**主要类别:** cs.LG

**AI概要:** 研究开发了新的工具以保持神经网络权重矩阵的范数约束，成功训练了具有Lipschitz界的Transformer模型，并探索了优化器动力学对性能的影响。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络对于输入和权重扰动非常敏感，这种敏感性与一些问题相关联，例如容易受到对抗样本攻击、训练发散和过拟合等。为了克服这些问题，研究人员试图构建完全由Lipschitz组件组成的神经网络。

**方法:** 研究人员首先开发并测试了用于维持范数约束权重矩阵的新颖且计算高效的工具。然后使用这些工具训练了在整个训练过程中都施加了Lipschitz界限的Transformer模型。此外，还研究了不同优化器（如从AdamW切换到Muon）对模型性能的影响，并共同设计了一种改进的权重约束方法。

**结果:** 2-Lipschitz的Transformer在Shakespeare文本上达到了60%的验证准确率；10-Lipschitz的Transformer在互联网文本上的准确率为21%。但是，要达到NanoGPT基准验证准确率39.4%，Lipschitz上限增加到了10^264。

**结论:** 尽管存在挑战，本研究成功地训练了没有稳定性措施（如层归一化、QK归一化和logit tanh软限制）的Lipschitz Transformer。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+Transformers+with+Enforced+Lipschitz+Constants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13338，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13338&send_immediately=true&force_search=false)

**原文摘要:** Neural networks are often highly sensitive to input and weight perturbations.
This sensitivity has been linked to pathologies such as vulnerability to
adversarial examples, divergent training, and overfitting. To combat these
problems, past research has looked at building neural networks entirely from
Lipschitz components. However, these techniques have not matured to the point
where researchers have trained a modern architecture such as a transformer with
a Lipschitz certificate enforced beyond initialization. To explore this gap, we
begin by developing and benchmarking novel, computationally-efficient tools for
maintaining norm-constrained weight matrices. Applying these tools, we are able
to train transformer models with Lipschitz bounds enforced throughout training.
We find that optimizer dynamics matter: switching from AdamW to Muon improves
standard methods -- weight decay and spectral normalization -- allowing models
to reach equal performance with a lower Lipschitz bound. Inspired by Muon's
update having a fixed spectral norm, we co-design a weight constraint method
that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter
transformers. Our 2-Lipschitz transformer on Shakespeare text reaches
validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz
transformer reaches 21% accuracy on internet text. However, to match the
NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound
increases to 10^264. Nonetheless, our Lipschitz transformers train without
stability measures such as layer norm, QK norm, and logit tanh softcapping.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak, Adam Kostka*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的多智能体AI辅导平台，该平台结合了自适应个性化反馈、结构化课程生成和教科书知识检索，以实现模块化工具辅助学习过程。


<details>
  <summary>更多</summary>
  
**动机:** 当前的AI辅导系统在数学领域存在不足，主要是提供直接答案而不鼓励深度思考或使用结构化的教学工具和策略。

**方法:** 引入了一个结合了自适应和个性化反馈、结构化课程生成和教科书知识检索的多代理AI辅导平台。

**结果:** 这个系统可以让学生学习新主题，同时识别和针对他们的弱点，有效地为考试做准备，并在一个无限数量的个性化练习上进行实践。

**结论:** 这项研究通过引入一个新颖的平台，将教育代理和AI驱动的组件结合在一起，增强了教育中的人工智能领域，为教授数学提供了模块化和有效的系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AI-Powered+Math+Tutoring%3A+Platform+for+Personalized+and+Adaptive+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12484，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12484&send_immediately=true&force_search=false)

**原文摘要:** The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [65] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley, Jovin D'sa, Hossein Nourkhiz Mahjoub, Gibran Ali*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一种新的博弈论模型，以改进高速公路并线场景的模拟，通过更现实的收益函数和滞后动作来捕捉并线互动，并在高保真模拟环境中验证了其可解释性和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 为了开发自主车辆技术，需要增强模拟环境以复制真实世界的驾驶员行为，即更加人性化的模拟代理。特别是在高速公路并线情况下，现有模型在战术决策建模方面存在局限性，如有限的动作集或参数过多的收益函数。

**方法:** 作者采用了一种结合博弈论模型和底层动力学模型的方法，用于战术决策制定。此方法包括改进的收益函数和滞后动作，以更好地捕捉并线互动，从而实现更真实的交互模拟。

**结果:** 所提出的模型在使用真实世界数据集进行验证时，表现出良好的复杂交互再现能力。此外，该模型被集成到一个高保真度的模拟环境中，证明其具有足够的计算时间效率，适用于大规模模拟，以支持自主车辆的发展。

**结论:** 该研究表明，通过引入改进的博弈论模型和动力学模型，可以更真实地模拟高速公路并线场景中的交互，同时保持模型的可解释性和计算效率。这为自主车辆技术的发展提供了有力的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MR-LDM+--+The+Merge-Reactive+Longitudinal+Decision+Model%3A+Game+Theoretic+Human+Decision+Modeling+for+Interactive+Sim+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12494，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12494&send_immediately=true&force_search=false)

**原文摘要:** Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [66] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个基于"What"和"How"问题的直观分类法，对超过250篇XRL领域的论文进行了前沿综述，并指出了该领域的一些需求。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，AI模型的成功伴随着其内部机制的不透明性，特别是由于使用了深度神经网络。为了理解这些内部机制并解释AI模型的输出，提出了一组方法，统称为可解释的人工智能（XAI）。

**方法:** 作者提出了一种基于两个问题“是什么”和“怎么样”的直观分类法，其中第一个问题专注于方法解释的目标，而第二个问题则与解释的提供方式有关。

**结果:** 通过提出的分类法，作者对250多篇论文进行了最先进水平的综述，并提出了一些应该引起社区关注的与XRL接近的领域。

**结论:** 作者确定了XRL领域的一些需求，并呼吁社区关注。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Explainable+Reinforcement+Learning%3A+Targets%2C+Methods+and+Needs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12599，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12599&send_immediately=true&force_search=false)

**原文摘要:** The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [67] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook, Josef Spjut, Jonathan Tremblay*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种自动设计迭代框架，通过结合强化学习代理和大型多模态模型，以基于玩家行为改进游戏设计。


<details>
  <summary>更多</summary>
  
**动机:** 现代生成系统在只检查游戏代码或资产的情况下难以捕捉静态规则和内容如何转化为动态玩家行为。为了弥补这一差距，需要一种新的方法来更好地理解并改进游戏设计。

**方法:** 该框架使用强化学习（RL）代理进行游戏测试，并利用大型多模态模型（LMM）根据代理的行为修改游戏。每个循环中，RL代理完成多个剧集，产生数值播放指标和/或总结最近视频帧的紧凑图像条。LMM接收游戏玩法目标和当前游戏配置，分析播放痕迹，并编辑配置以引导未来行为朝向目标。

**结果:** 实验证明，大型多模态模型能够基于强化学习代理提供的行为痕迹进行推理，以迭代地优化游戏机制。

**结论:** 这项研究指出了实用且可扩展的人工智能辅助游戏设计工具的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fly%2C+Fail%2C+Fix%3A+Iterative+Game+Repair+with+Reinforcement+Learning+and+Large+Multimodal+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12666，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12666&send_immediately=true&force_search=false)

**原文摘要:** Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [68] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack, Carlo Leonardo Attubato, Stefan Heimersheim*

**主要类别:** cs.AI

**AI概要:** 本文研究了欺骗探测器在检测AI助手欺骗性回复时的有效性，以及它们对逃避策略的抵抗力。通过比较白盒和黑盒监控的效果，发现现有的欺骗探测器有微弱但鼓舞人心的表现提升。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI助手偶尔会对用户查询作出欺骗性回应，研究者希望训练线性分类器（称为“欺骗探测器”）以区分语言模型在欺骗性和诚实回应期间的内部激活状态，从而有效检测欺骗行为并抵抗来自欺骗助手的简单反制策略。

**方法:** 研究者通过比较两种监控方式：白盒监控（可以访问基于令牌的探测器激活）和黑盒监控（无法访问此类激活），来衡量欺骗探测器的效果。使用黑盒到白盒性能提升作为基准进行评估。

**结果:** 研究发现，现有的欺骗探测器在从黑盒到白盒监控的转变中，表现出微弱但令人鼓舞的性能提升。

**结论:** 尽管结果较为初步，但该研究表明，欺骗探测器在未来可能成为一种有效的工具，用于检测AI助手的欺骗性回复，并可能进一步发展出更复杂的探测与反制措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Benchmarking+Deception+Probes+via+Black-to-White+Performance+Boosts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12691，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12691&send_immediately=true&force_search=false)

**原文摘要:** AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [69] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe, Taketoshi Ushiama*

**主要类别:** cs.AI

**AI概要:** 本研究旨在开发一个AI代理作为学习伙伴，以实现随时随地的同伴学习，并假设具有相同熟练程度的学习者会犯同样的错误，特别是在英语写作方面。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，同伴学习作为一种促进学习者自发思考的方法受到了关注，但人类之间的同伴学习存在各种局限性，并不总是有效。

**方法:** 该研究假设学习者的同伴与学习者具有相同的熟练程度，并且会犯同样的错误，特别通过英语写作为例进行验证。

**结果:** 未提供。

**结论:** 未提供。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Imitating+Mistakes+in+a+Learning+Companion+AI+Agent+for+Online+Peer+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12801&send_immediately=true&force_search=false)

**原文摘要:** In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [70] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu, Jielin Qiu, Shiyu Wang, Jianguo Zhang, Zuxin Liu, Roshan Ram, Haolin Chen, Weiran Yao, Huan Wang, Shelby Heinecke, Silvio Savarese, Caiming Xiong*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个名为MCPEval的开源框架，用于自动化生成任务和深度评估基于大型语言模型的智能体。它消除了手动构建评估管道的努力，并在五个真实世界的领域中显示了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的评估方法依赖于静态基准和劳动密集型的数据收集，这限制了实际评估。为了应对大型语言模型（LLMs）智能体的快速崛起，需要更强大、可扩展的评估框架。

**方法:** 研究人员引入了MCPEval，这是一个基于模型上下文协议（MCP）的框架，可以自动生成端到端的任务并深入评估跨越不同领域的LLM智能体。该框架标准化了指标，与原生智能体工具无缝集成。

**结果:** 实证结果显示，MCPEval在揭示五个真实世界领域的细致、特定领域性能方面的有效性。

**结论:** 作者公开发布了MCPEval框架，以促进可重复和标准化的LLM智能体评估。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCPEval%3A+Automatic+MCP-based+Deep+Evaluation+for+AI+Agent+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12806，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12806&send_immediately=true&force_search=false)

**原文摘要:** The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [71] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang, Ruiyu Fang, Zhongjiang He, Shuangyong Song, Yongxiang Li*

**主要类别:** cs.AI

**AI概要:** 本文介绍了作者团队为NLPCC 2025任务8情感支持对话（ESC）评估提供的解决方案，利用大规模语言模型及微调技术，探索低秩适应和全参数微调策略，以生成更有效和适当的支持性回应。最佳模型在竞赛中排名第二，并展望了未来工作方向。


<details>
  <summary>更多</summary>
  
**动机:** 随着对心理健康支持需求的增长，情感支持对话旨在通过对话提供同理心和有效的心理援助。

**方法:** 使用大规模语言模型，并通过提示工程和微调技术增强。探索了参数高效的低秩适应和全参数微调策略来提升模型的响应能力。

**结果:** 所提出的最佳模型在比赛中获得第二名，证明了结合大型语言模型与有效的适应方法对于ESC任务的潜力。

**结论:** 未来的工作将着重于进一步提高情感理解力和响应个性化，以构建更实用和可靠的情感支持系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Emotional+Support+with+LLM-based+Empathetic+Dialogue+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12820，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12820&send_immediately=true&force_search=false)

**原文摘要:** Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [72] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum*

**主要类别:** cs.AI

**AI概要:** 本文探讨了人类智能在新环境中快速适应和解决问题的能力，并提出了一种新的AI评估框架，旨在通过特别设计的具有持续新颖性的游戏来测试AI的世界模型归纳能力。


<details>
  <summary>更多</summary>
  
**动机:** 作者认为当前对于AI中世界模型的理解和评价过于狭窄，通常只关注从大量数据中学习到的静态表示，而忽略了模型在新环境中通过互动和探索学习这些表示的效率和效果。因此，他们希望引入一种新的评估框架，以更全面地评价AI的适应性和泛化能力。

**方法:** 作者建议创建一个基于精心设计的游戏的新基准测试范式，这些游戏包含真正、深刻且不断更新的新颖性。同时提出了构建这些游戏的关键要素和适当的度量标准，以挑战和评估代理在快速世界模型归纳方面的能力。

**结果:** 该论文并没有提供实验结果，而是提出了一种新的研究方向和评估框架，希望能够激发未来对AI世界模型的研究，并为开发具备人类一样快速适应能力和稳健泛化能力的系统迈出关键一步。

**结论:** 文章呼吁建立一个新的评价体系，用以衡量AI在面对全新环境时能否像人类一样迅速调整并有效解决遇到的问题，这是实现人工通用智能的重要组成部分。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Assessing+adaptive+world+models+in+machines+with+novel+games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12821，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12821&send_immediately=true&force_search=false)

**原文摘要:** Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [73] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass, Taylan Akay, Harrison Tolley*

**主要类别:** cs.AI

**AI概要:** 本文探讨了在AI时代，如何通过模拟环境自动计算伦理属性的权重，以辅助人类指挥官在大量场景中做出决策。


<details>
  <summary>更多</summary>
  
**动机:** 在AI时代，人类指挥官需要利用当前环境中的计算能力来模拟大量场景，并在每个场景中做出可能具有伦理后果的决策。然而，依赖人类判断进行这些决策既不利于及时探索大量场景，也难以应对参与每个选择所需的工作量。

**方法:** 本文提出将人类判断移出模拟决策周期，由人类设计伦理度量空间，交由模拟环境探索该空间。完成测试后，模拟环境会提供几个选项供人类指挥官选择。同时，本文借鉴多标准决策文献的方法，探讨了如何在基于仿真的测试和评估中自动计算伦理属性的权重。

**结果:** 本文并未具体说明实验结果，而是提出了一个框架，用于在仿真过程中动态加权伦理属性。

**结论:** 本文认为，在仿真过程中自动计算伦理属性的权重是可行的，这可以为人类指挥官在面对大量场景时提供有效的决策支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Information-Theoretic+Aggregation+of+Ethical+Attributes+in+Simulated-Command，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12862，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12862&send_immediately=true&force_search=false)

**原文摘要:** In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [74] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake, Mario Demetroudi, James Walpole, Lindley Lentati, Jason R. Brown, Edward James Young*

**主要类别:** cs.AI

**AI概要:** 前沿AI系统在特定情境中已表现出人类级别的说服和战略性欺骗能力，这对网络安全构成重大威胁。本文提出了一个安全案例框架，包含无法实现、控制和可信度三个核心论点，为AI公司在部署前评估和缓解这些威胁提供了具体方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管AI系统的操纵攻击构成了日益增长的威胁，但此类攻击尚未受到广泛关注，也缺乏系统性的风险评估和缓解框架。

**方法:** 文章构建了一个安全案例框架，围绕三个核心论点：无法实现、控制和可信度，指定了证据要求、评估方法和实施考虑因素。

**结果:** 提供了一种系统的方法，使AI公司能够将操纵风险纳入AI安全治理中，在部署前评估和缓解这些威胁。

**结论:** 这是首个针对AI系统操纵风险的系统性评估和缓解方法，为AI安全治理提供了坚实基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Manipulation+Attacks+by+Misaligned+AI%3A+Risk+Analysis+and+Safety+Case+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12872，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12872&send_immediately=true&force_search=false)

**原文摘要:** Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [75] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao, Ran Cheng, Kay Chen Tan*

**主要类别:** cs.AI

**AI概要:** 本文探讨了强化学习在提升大型语言模型数学推理能力方面的进步，并提出了VAR-MATH框架，以评估这些模型的真实推理能力。研究发现许多现有方法依赖于表面的启发式算法，无法超越特定数值形式进行泛化。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习（RL）在提高大型语言模型（LLMs）的数学推理能力方面取得了显著进展，但这些改进是否反映了真正的推理能力还是仅仅是过拟合到基准特定模式的结果尚不清楚。

**方法:** 作者引入了VAR-MATH，一个符号评估框架，通过将固定数值问题转换为符号模板，并要求模型解决每个模板的多个实例，从而确保结构上等价变体的一致推理，以此减轻污染并提高评估的稳健性。

**结果:** 实验结果表明，在变量化版本上的RL训练模型性能大幅下降，特别是对于较小的模型，在AMC23和AIME24上的平均下降分别为48.0%和58.3%。

**结论:** 研究结果表明，许多现有的RL方法依赖于表面的启发式算法，无法超越特定数值形式进行泛化。总体而言，VAR-MATH提供了一个原则性的、抗污染的数学推理评估范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VAR-MATH%3A+Probing+True+Mathematical+Reasoning+in+Large+Language+Models+via+Symbolic+Multi-Instance+Benchmarks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12885，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12885&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [76] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu, Fabio Aurelio D'Asaro, Luke Dickens*

**主要类别:** cs.AI

**AI概要:** 本文通过将PEC域转换为MDP，引入“行动采取情境”的概念，将MDP的算法和理论工具应用于PEC的可解释性叙事领域，并展示如何将学习到的策略映射回人类可读的PEC表示。


<details>
  <summary>更多</summary>
  
**动机:** Probabilistic Event Calculus (PEC)虽然在不确定环境中的动作效果推理方面具有显著的优势，但缺乏目标导向的推理机制。

**方法:** 该论文开发了一种形式化的翻译方法，将PEC域转化为Markov Decision Processes (MDPs)，并引入了“action-taking situations”的概念以保留PEC灵活的动作语义。

**结果:** 这种转换支持时间推理任务和目标驱动的规划，并提供将学习到的策略映射回人类可读的PEC表示的方法，在保持解释性的同时扩展了PEC的能力。

**结论:** PEC-MDP的形式主义使得可以将MDP中开发的大量算法和理论工具应用到PEC的可解释性叙事领域，从而弥补了PEC缺乏目标导向推理机制的不足。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Translation+of+Probabilistic+Event+Calculus+into+Markov+Decision+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12989，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12989&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [77] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri, Filippo Bistaffa, Athina Georgara, Juan Antonio Rodriguez-Aguilar*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种名为X-MILP的方法，用于为MILP问题建立对比解释。该方法通过约束推理技术编码用户查询，计算不可约不可行子系统，并以“原因图”的形式呈现解释。


<details>
  <summary>更多</summary>
  
**动机:** 随着对可信赖AI的推动，开发对比解释技术的兴趣日益增加，尤其是在解决被形式化为MILPs的具体决策过程中。

**方法:** 提出X-MILP方法，首先将用户关于MILP问题解决方案的查询编码为附加约束，然后通过计算新获得的约束集的不可约不可行子系统确定构成答案的原因，最后将解释表示为从IIS构建的“原因图”。

**结果:** 该方法在著名的优化问题实例上进行了测试，以评估计算解释的经验难度。

**结论:** X-MILP是一种领域无关的方法，可以通过约束推理技术为MILP问题提供对比解释，帮助用户理解回答他们查询的原因结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploiting+Constraint+Reasoning+to+Build+Graphical+Explanations+for+Mixed-Integer+Linear+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13007，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13007&send_immediately=true&force_search=false)

**原文摘要:** Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [78] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee, Jaegwan Cho, Yoonju Cho, Seoyoon Choi, Yejin Shin*

**主要类别:** cs.AI

**AI概要:** 研究使用加州交通数据，基于人工智能算法预测高速公路车流。通过分析圣地亚哥地区7.24公里路段的30秒间隔数据，发现MLR和RF模型在10分钟数据收集间隔时表现最佳。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决全球交通拥堵问题，提高交通管理效率。

**方法:** 采用机器学习中的多元线性回归(MLR)和随机森林(RF)算法，对加州78号公路西行方向一段7.24公里的路段进行了交通流量预测建模。研究使用了从2022年7月至11月为期五个月的、以30秒为间隔的交通数据，并且还测试了不同数据收集间隔（从30秒到15分钟）的效果。

**结果:** 使用R^2、MAE和RMSE作为性能指标，研究结果显示MLR和RF两种模型都在10分钟的数据收集间隔下表现最优。

**结论:** 该研究结果有望对未来解决交通拥堵问题及实现高效的交通管理做出贡献。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prediction+of+Highway+Traffic+Flow+Based+on+Artificial+Intelligence+Algorithms+Using+California+Traffic+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13112&send_immediately=true&force_search=false)

**原文摘要:** The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [79] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul, Simon Malberg*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种基于强化学习的动态框架，改进了ProbTree的概率树推理方法，通过实时置信度估计和选择性扩展提高了问题解答的质量和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 现代语言模型在处理复杂问题时存在错误传播和知识整合的问题。虽然ProbTree框架通过分层结构分解问题并结合参数化和检索到的知识来选择答案，缓解了这些问题，但其静态实现限制了适应性和计算效率。

**方法:** 研究采用强化学习框架将基于树的推理转化为适应性过程。该方法根据实时置信度增量地构建推理树，并学习最优策略以选择行动（如分解、检索或聚合）。这保留了ProbTree的概率严谨性，同时通过选择性扩展和集中资源分配提高了解决方案的质量和计算效率。

**结果:** 该方法维持了ProbTree的概率严谨性，同时显著提升了解的质量和计算效率，为树结构推理提供了一种新的范式。

**结论:** 这项工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Roots+to+Rewards%3A+Dynamic+Tree+Reasoning+with+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13142，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13142&send_immediately=true&force_search=false)

**原文摘要:** Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [80] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

**主要类别:** cs.AI

**AI概要:** 本文提出了评估基于大语言模型的道德智能体的新标准，以适应其不透明特性，并通过假设场景展示了这些标准的实际应用。


<details>
  <summary>更多</summary>
  
**动机:** 由于强大的大语言模型（LLMs）具有不透明性，传统的伦理评估标准不再适用，因此需要重新审视和制定新的评估准则。

**方法:** 文章提出了十个功能性评估标准：道德一致、情境敏感、规范完整性、元伦理意识、系统韧性、可靠性、可纠正性、部分透明度、功能自治和道德想象力。

**结果:** 通过假设场景展示了这十个标准在实际中的应用，表明它们有助于指导道德智能体更好地融入社会。

**结论:** 新的评估标准为基于大语言模型的道德智能体提供了实用的指导原则，有助于实现更好的社会整合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Black+Box+Deployed+--+Functional+Criteria+for+Artificial+Moral+Agents+in+the+LLM+Era，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13175，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13175&send_immediately=true&force_search=false)

**原文摘要:** The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [81] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua, Temur Kutsia*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种结合高阶模式和模糊等价的统一算法，并证明了其终止性、可靠性和完备性。


<details>
  <summary>更多</summary>
  
**动机:** 在决策任务中，涉及到跨抽象函数和谓词的推理时，精确匹配往往是罕见或不必要的。因此，结合高阶理论和模糊逻辑可以提供更实用的方法。

**方法:** 采用高阶模式和基于最小T-范数相似关系的模糊等价两个计算特性良好的组件，并提出一种统一算法来处理这种组合形式主义。

**结果:** 该算法能够计算出具有最高逼近度的一般性统一，当给定项可统一时。并且证明了算法的终止性、可靠性和完备性。

**结论:** 提出的统一算法为结合高阶理论和模糊逻辑提供了一种有效的方法，能够在决策任务中进行有效的推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Higher-Order+Pattern+Unification+Modulo+Similarity+Relations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13208，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13208&send_immediately=true&force_search=false)

**原文摘要:** The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [82] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga, Gonzalo Martínez, Eneko Sendin, Javier Conde, Pedro Reviriego*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个新的评估平台GEA，它将模型能耗信息纳入了大语言模型的评估过程中。初步结果显示，当用户了解能耗情况时，他们更倾向于选择较小、更节能的模型，这表明对于大多数用户交互来说，复杂且性能最高的模型所带来的额外成本和能耗并不值得。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大语言模型评估方法存在与人类判断相关性差的问题，而人工评估又面临扩展性和成本问题。此外，随着对大型语言模型能源消耗的关注增加，研究其如何影响人类选择模型的决策变得重要。

**方法:** 作者提出了一个名为GEA的新平台，该平台在评估过程中加入了模型的能源消耗信息，允许公众自由评估并对比两个模型的回答，并根据这些评价生成模型排名。

**结果:** 初步结果表明，当用户提供有关模型能耗的信息时，他们更倾向于选择规模较小、能效更高的模型。

**结论:** 这表明，在大多数用户交互中，使用更复杂、性能更高但能耗更大的模型所带来的额外成本和能源消耗，并没有带来足够的响应质量提升以证明其合理性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Generative+Energy+Arena+%28GEA%29%3A+Incorporating+Energy+Awareness+in+Large+Language+Model+%28LLM%29+Human+Evaluations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13302，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13302&send_immediately=true&force_search=false)

**原文摘要:** The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [83] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua*

**主要类别:** cs.AI

**AI概要:** 前沿AI模型在知识广度上表现出色，但在解决实际研究问题方面仍远未达到人类专家水平。本文构建了FormulaOne基准测试，旨在评估AI模型在图论、逻辑和算法交叉领域的表现。实验结果表明，即使是当前最先进的AI模型也仅能解决不到1%的问题，强调了AI与专家级理解之间的差距。


<details>
  <summary>更多</summary>
  
**动机:** 了解前沿AI模型是否接近真正的人类或超人类的专长，特别是在处理最困难的问题和推动科学理解边界的能力上。

**方法:** 构建了一个名为FormulaOne的基准测试，它结合了图论、逻辑和算法，且与实际的大规模优化问题相关。该数据集由Monadic Second-Order (MSO)逻辑生成，并涉及理论计算机科学的前沿猜想。

**结果:** 即使是最先进的模型（如OpenAI的o3）在FormulaOne上的表现也非常差，解决问题的比例不到1%，这表明这些模型在某些领域距离专家级理解还很远。

**结论:** 目前的AI模型在解决复杂的研究问题时仍然存在显著不足，特别是在需要深层次推理的任务上。作者发布了FormulaOne及其简化版本FormulaOne-Warmup，以支持进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FormulaOne%3A+Measuring+the+Depth+of+Algorithmic+Reasoning+Beyond+Competitive+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13337，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13337&send_immediately=true&force_search=false)

**原文摘要:** Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [84] [Safeguarding Federated Learning-based Road Condition Classification](https://arxiv.org/abs/2507.12568)
*Sheng Liu, Panos Papadimitratos*

**主要类别:** cs.CR

**AI概要:** 本文研究了联邦学习在基于摄像头的道路状况分类系统中的应用，并提出了一种新的防御机制FLARE，以应对恶意客户发起的标签翻转攻击。


<details>
  <summary>更多</summary>
  
**动机:** 随着联邦学习（FL）成为保护隐私的自动驾驶技术的一种解决方案，特别是基于摄像头的道路状况分类（RCC）系统中，它利用车辆上的分布式传感、计算和通信资源，而不共享敏感的图像数据。然而，FL-RCC框架的协作特性引入了新的漏洞：目标标签翻转攻击（TLFAs）。这种攻击可能导致车辆错误分类危险路况为安全路况并超速行驶。

**方法:** 作者首先揭示了现有FL-RCC系统对TLFAs的脆弱性；其次，引入了一种基于标签距离的度量方法，精确量化TLFAs带来的安全风险；最后，提出了FLARE，一种利用神经元级输出层分析来缓解TLFA效应的防御机制。

**结果:** 通过三个RCC任务、四个评估指标、六个基线和三种深度学习模型的广泛实验，证明了TLFAs对FL-RCC系统的严重影响以及FLARE在减轻攻击影响方面的有效性。

**结论:** 研究表明，现有的FL-RCC系统容易受到TLFAs的攻击，而FLARE可以有效地减少这些攻击的影响，确保道路状况分类的安全性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Safeguarding+Federated+Learning-based+Road+Condition+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12568，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12568&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) has emerged as a promising solution for
privacy-preserving autonomous driving, specifically camera-based Road Condition
Classification (RCC) systems, harnessing distributed sensing, computing, and
communication resources on board vehicles without sharing sensitive image data.
However, the collaborative nature of FL-RCC frameworks introduces new
vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious
clients (vehicles) deliberately alter their training data labels to compromise
the learned model inference performance. Such attacks can, e.g., cause a
vehicle to mis-classify slippery, dangerous road conditions as pristine and
exceed recommended speed. However, TLFAs for FL-based RCC systems are largely
missing. We address this challenge with a threefold contribution: 1) we
disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce
a novel label-distance-based metric to precisely quantify the safety risks
posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging
neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive
experiments across three RCC tasks, four evaluation metrics, six baselines, and
three deep learning models demonstrate both the severity of TLFAs on FL-RCC
systems and the effectiveness of FLARE in mitigating the attack impact.

</details>


### [85] [On the Consideration of Vanity Address Generation via Identity-Based Signatures](https://arxiv.org/abs/2507.12670)
*Shogo Murasaki, Kazumasa Omote, Keita Emura*

**主要类别:** cs.CR

**AI概要:** 本文研究了基于身份的签名（IBS）在生成自定义字符地址（vanity address）中的应用，并提出了一种结合ECDSA与IBS的新方案，实现了任意字符串与地址的关联，同时保持了以太坊交易验证的效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成自定义字符地址的方法受到字符数量限制，而基于身份的签名（IBS）允许使用任何字符串作为验证密钥，因此探索IBS是否可以用于生成更灵活的自定义字符地址。

**方法:** 通过结合现有的基于ECDSA的签名恢复功能和IBS的功能，构建了一种新的IBS方案，该方案可以在不直接生成自定义字符地址的情况下，实现将任意字符串与地址关联，从而赋予地址额外的意义。

**结果:** 实现了该系统的Solidity代码，实验表明其gas成本几乎与ECDSA签名验证相同，证明了新方案的可行性和高效性。

**结论:** 尽管不能直接生成自定义字符地址，但通过构造的IBS方案，可以将任意字符串与地址连接，赋予地址更多含义，并且不会显著增加以太坊上的交易验证成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Consideration+of+Vanity+Address+Generation+via+Identity-Based+Signatures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12670，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12670&send_immediately=true&force_search=false)

**原文摘要:** An address is indicated as an identifier of the user on the blockchain, and
is defined by a hash value of the ECDSA verification key. A vanity address is
an address that embeds custom characters such as a name. To generate a vanity
address, a classical try-and-error method is employed, and thus the number of
characters to be embedded is limited. In this paper, we focus on the
functionality of identity-based signatures (IBS) where any strings can be
employed as a verification key, and explore whether IBS can be used for
generating a vanity address. We attach importance to the fact that it is not
realistic to replace ECDSA with key recovery, which is currently employed for
issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is
possible, it is not a reasonable price for the ease of the vanity address
generation. Thus, we pay attention to a generic construction of IBS from
signatures, and construct an IBS scheme from ECDSA with key recovery. Though we
cannot directly generate a vanity address due to the key recovery functionality
of the underlying ECDSA, we can connect any string with an address due to the
functionality of IBS that can give additional meaning to the address. We
implement our system by Solidity, and demonstrate that the gas cost is almost
same as that of the ECDSA signature verification.

</details>


### [86] [Architectural Backdoors in Deep Learning: A Survey of Vulnerabilities, Detection, and Defense](https://arxiv.org/abs/2507.12919)
*Victoria Childress, Josh Collyer, Jodie Knapp*

**主要类别:** cs.CR

**AI概要:** 这篇调查论文探讨了深度神经网络中架构后门的威胁，评估了现有的检测和防御策略，并指出了未来研究的方向。


<details>
  <summary>更多</summary>
  
**动机:** 作者指出架构后门对深度神经网络构成了一个尚未充分研究但至关重要的威胁，它们可以嵌入恶意逻辑到模型的计算图中，难以被传统的缓解技术发现或清除。

**方法:** 作者系统地整理了关于架构后门的研究，包括编译器级别的操作、污染的AutoML管道和供应链漏洞等。同时，还评估了静态图检查、动态模糊测试和部分形式验证等新兴检测和防御策略。

**结果:** 尽管最近在对抗结构后门方面取得了一些进展，但是可扩展且实用的防御方法仍然难以捉摸。

**结论:** 作者总结了开放性挑战，并提出了加强供应链安全、加密模型认证和下一代基准的方向，以指导未来针对深度学习系统中的结构性后门威胁的全面防御研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Architectural+Backdoors+in+Deep+Learning%3A+A+Survey+of+Vulnerabilities%2C+Detection%2C+and+Defense，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12919，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12919&send_immediately=true&force_search=false)

**原文摘要:** Architectural backdoors pose an under-examined but critical threat to deep
neural networks, embedding malicious logic directly into a model's
computational graph. Unlike traditional data poisoning or parameter
manipulation, architectural backdoors evade standard mitigation techniques and
persist even after clean retraining. This survey systematically consolidates
research on architectural backdoors, spanning compiler-level manipulations,
tainted AutoML pipelines, and supply-chain vulnerabilities. We assess emerging
detection and defense strategies, including static graph inspection, dynamic
fuzzing, and partial formal verification, and highlight their limitations
against distributed or stealth triggers. Despite recent progress, scalable and
practical defenses remain elusive. We conclude by outlining open challenges and
proposing directions for strengthening supply-chain security, cryptographic
model attestations, and next-generation benchmarks. This survey aims to guide
future research toward comprehensive defenses against structural backdoor
threats in deep learning systems.

</details>


### [87] [Enterprise Security Incident Analysis and Countermeasures Based on the T-Mobile Data Breach](https://arxiv.org/abs/2507.12937)
*Zhuohan Cui, Zikun Song*

**主要类别:** cs.CR

**AI概要:** 本文分析了T-Mobile在2021和2023年的关键数据泄露事件，并进行了全面的安全审计，提出了多层防御策略，包括零信任架构、细粒度基于角色的访问控制等。财务模型显示五年投资回报率小于预期损失的1.1%，证明预防性安全措施的成本效益。


<details>
  <summary>更多</summary>
  
**动机:** 为了识别并解决T-Mobile系统中的持续结构性弱点，防止未来可能的数据泄露，并为大型电信公司提供增强操作弹性、合规性和跨域威胁准备的行动蓝图。

**方法:** 使用案例研究漏洞评估结合主动的道德黑客技术，如Shodan侦察、API滥用模拟、VNC暴力破解、固件逆向工程和Web应用程序扫描进行全面安全审计。

**结果:** 发现了超越初始事件的结构弱点，并提出了一系列具体的防御措施。财务建模证明了这些措施的成本效益。

**结论:** 这项工作将事后法医分析与实际安全评估相结合，为寻求提高安全性的大型电信公司提供了可操作的蓝图。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enterprise+Security+Incident+Analysis+and+Countermeasures+Based+on+the+T-Mobile+Data+Breach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.12937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.12937&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a comprehensive analysis of T-Mobile's critical data
breaches in 2021 and 2023, alongside a full-spectrum security audit targeting
its systems, infrastructure, and publicly exposed endpoints. By combining
case-based vulnerability assessments with active ethical hacking
techniques--including Shodan reconnaissance, API misuse simulations, VNC
brute-forcing, firmware reverse engineering, and web application scans--we
uncover structural weaknesses persisting beyond the initial breach events.
Building on these findings, we propose a multi-layered defensive strategy
encompassing Zero Trust Architecture, granular role-based access control,
network segmentation, firmware encryption using AES with integrity checks, and
API rate limiting and token lifecycle control. Financial modelling demonstrates
that a five-year investment yields less than 1.1% of expected breach losses,
validating the cost-effectiveness of proactive security measures. Our work
bridges post-incident forensic analysis with hands-on security evaluation,
providing an actionable blueprint for large-scale telecoms seeking operational
resilience, regulatory compliance, and cross-domain threat readiness.

</details>


### [88] [Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest](https://arxiv.org/abs/2507.13023)
*Fei Wu, Danning Sui, Thomas Thiery, Mallesh Pai*

**主要类别:** cs.CR

**AI概要:** 本文分析了以太坊上中心化和去中心化交易所之间的套利行为，揭示了市场集中化趋势及参与者盈利模式，并强调这些套利活动对以太坊去中心化的影响。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于理解中心化与去中心化交易所间的套利经济学及动态，特别是其对以太坊去中心化特性的影响。

**方法:** 使用改进的启发式方法识别链上数据中的套利交易，并建立稳健的经验框架来估计套利收益，而无需了解交易者在CEX上的实际行为。

**结果:** 研究发现，19个主要的CEX-DEX搜索者从7,203,560次确认的套利中提取了总计2.338亿美元的利润。三个搜索者占据了四分之三的交易量和价值提取。此外，搜索者的盈利能力与其与区块构建者的整合程度有关，存在独家的搜索者-构建者关系及其市场影响。

**结论:** 本研究揭示了MEV领域中最不透明的部分，强调了CEX-DEX套利对以太坊去中心化的关键影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+CEX-DEX+Extracted+Value+and+Searcher+Profitability%3A+The+Darkest+of+the+MEV+Dark+Forest，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13023，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13023&send_immediately=true&force_search=false)

**原文摘要:** This paper provides a comprehensive empirical analysis of the economics and
dynamics behind arbitrages between centralized and decentralized exchanges
(CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions
from on-chain data and introduce a robust empirical framework to estimate
arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging
an extensive dataset spanning 19 months from August 2023 to March 2025, we
estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from
7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing
centralization trends as three searchers captured three-quarters of both volume
and extracted value. We also demonstrate that searchers' profitability is tied
to their integration level with block builders and uncover exclusive
searcher-builder relationships and their market impact. Finally, we correct the
previously underestimated profitability of block builders who vertically
integrate with a searcher. These insights illuminate the darkest corner of the
MEV landscape and highlight the critical implications of CEX-DEX arbitrages for
Ethereum's decentralization.

</details>


### [89] [From Paranoia to Compliance: The Bumpy Road of System Hardening Practices on Stack Exchange](https://arxiv.org/abs/2507.13028)
*Niklas Busch, Philip Klostermeyer, Jan H. Klemmer, Yasemin Acar, Sascha Fahl*

**主要类别:** cs.CR

**AI概要:** 分析了316个与系统加固相关的Stack Exchange帖子，发现访问控制和部署问题最具挑战性，系统操作员存在误解和不切实际的期望，主要动机是害怕被攻击或合规原因。


<details>
  <summary>更多</summary>
  
**动机:** 了解系统操作员在系统加固方面的实践和挑战，因为过去的安全事件表明许多系统操作员难以有效进行系统加固，导致许多计算机系统和应用程序仍然存在安全隐患。

**方法:** 对316个Stack Exchange（SE）帖子进行了定性分析，这些帖子都与系统加固有关。

**结果:** 访问控制和部署相关问题是最大的挑战，系统操作员存在误解和不切实际的期望，帖子大多数集中在操作系统和服务器应用程序上，系统操作员的主要驱动因素是对系统遭受攻击的恐惧或出于合规的原因。

**结论:** 讨论了研究问题，对未来系统加固提出了建议，并说明了研究工作的意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Paranoia+to+Compliance%3A+The+Bumpy+Road+of+System+Hardening+Practices+on+Stack+Exchange，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13028，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13028&send_immediately=true&force_search=false)

**原文摘要:** Hardening computer systems against cyberattacks is crucial for security.
However, past incidents illustrated, that many system operators struggle with
effective system hardening. Hence, many computer systems and applications
remain insecure. So far, the research community lacks an in-depth understanding
of system operators motivation, practices, and challenges around system
hardening. With a focus on practices and challenges, we qualitatively analyzed
316 Stack Exchange (SE) posts related to system hardening. We find that access
control and deployment-related issues are the most challenging, and system
operators suffer from misconceptions and unrealistic expectations. Most
frequently, posts focused on operating systems and server applications. System
operators were driven by the fear of their systems getting attacked or by
compliance reasons. Finally, we discuss our research questions, make
recommendations for future system hardening, and illustrate the implications of
our work.

</details>


### [90] [MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems](https://arxiv.org/abs/2507.13038)
*Yu Cui, Hongyang Du*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种针对多智能体辩论系统的攻击方法MAD-Spear，并评估了其影响，强调了提高MAD系统安全性的紧迫性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多智能体辩论（MAD）系统在准确性和可扩展性方面有所改进，但其安全性问题尚未得到充分关注。

**方法:** 引入了一种名为MAD-Spear的针对性提示注入攻击，通过操控少数智能体来破坏整个MAD过程。同时提出了关于MAD容错性的正式定义和一个全面的评估框架。

**结果:** 实验表明MAD-Spear在降低系统性能方面优于基准攻击，而且智能体多样性对数学推理任务的MAD性能有显著提升。

**结论:** 研究结果突显了在MAD设计中增强安全性的迫切需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAD-Spear%3A+A+Conformity-Driven+Prompt+Injection+Attack+on+Multi-Agent+Debate+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13038，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13038&send_immediately=true&force_search=false)

**原文摘要:** Multi-agent debate (MAD) systems leverage collaborative interactions among
large language models (LLMs) agents to improve reasoning capabilities. While
recent studies have focused on increasing the accuracy and scalability of MAD
systems, their security vulnerabilities have received limited attention. In
this work, we introduce MAD-Spear, a targeted prompt injection attack that
compromises a small subset of agents but significantly disrupts the overall MAD
process. Manipulated agents produce multiple plausible yet incorrect responses,
exploiting LLMs' conformity tendencies to propagate misinformation and degrade
consensus quality. Furthermore, the attack can be composed with other
strategies, such as communication attacks, to further amplify its impact by
increasing the exposure of agents to incorrect responses. To assess MAD's
resilience under attack, we propose a formal definition of MAD fault-tolerance
and develop a comprehensive evaluation framework that jointly considers
accuracy, consensus efficiency, and scalability. Extensive experiments on five
benchmark datasets with varying difficulty levels demonstrate that MAD-Spear
consistently outperforms the baseline attack in degrading system performance.
Additionally, we observe that agent diversity substantially improves MAD
performance in mathematical reasoning tasks, which challenges prior work
suggesting that agent diversity has minimal impact on performance. These
findings highlight the urgent need to improve the security in MAD design.

</details>


### [91] [Backscattering-Based Security in Wireless Power Transfer Applied to Battery-Free BLE Sensors](https://arxiv.org/abs/2507.13042)
*Taki Eddine Djidjekh, Gaël Loubet, Alexandru Takacs*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种基于背向散射的安全机制，整合进蓝牙低能耗无电池无线传感网络中，在不增加能耗和计算需求的情况下生成额外的识别信号，并通过实验验证了其功能性和兼容性。


<details>
  <summary>更多</summary>
  
**动机:** 为了应对物联网系统中的安全与能效集成挑战，尤其是对于无电池和资源受限设备的情况。

**方法:** 利用无线能量传输链路产生附加识别信号，采用紧凑、低增益天线进行实验验证，解决背向散射动态范围及多节点无线传感网络场景下的挑战。

**结果:** 实验结果证明该方案在尺寸受限的应用中具有功能性，能够处理背向散射动态范围问题并讨论了识别信号间的潜在冲突。

**结论:** 研究结果强调了基于背向散射的安全机制在创建安全、可持续且可扩展的物联网部署方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Backscattering-Based+Security+in+Wireless+Power+Transfer+Applied+to+Battery-Free+BLE+Sensors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13042&send_immediately=true&force_search=false)

**原文摘要:** The integration of security and energy efficiency in Internet of Things
systems remains a critical challenge, particularly for battery-free and
resource-constrained devices. This paper explores the scalability and
protocol-agnostic nature of a backscattering-based security mechanism by
integrating it into Bluetooth Low Energy battery-free Wireless Sensor Network.
The proposed approach leverages the Wireless Power Transfer link, traditionally
used for energy harvesting, to generate additional identification signals
without increasing energy consumption or computational demands. Experimental
validation demonstrates the solution's functionality using compact, low-gain
antenna, ensuring compatibility with size-constrained applications such as
Structural Health Monitoring and smart transport. Furthermore, this work
addresses the challenges associated with backscattering dynamic range and
multi-node Wireless Sensor Network scenarios, discussing potential collisions
between identification signals and proposing future improvements to enhance
generalizability and scalability. The findings underscore the potential of the
backscattering-based security mechanism for creating secure, sustainable, and
scalable IoT deployments across diverse protocols and applications.

</details>


### [92] [Prompt Injection 2.0: Hybrid AI Threats](https://arxiv.org/abs/2507.13169)
*Jeremy McHugh, Kristina Šekrst, Jon Cefalu*

**主要类别:** cs.CR

**AI概要:** 本文分析了Prompt Injection 2.0，研究其与传统网络安全漏洞结合形成混合威胁的方式，并提出了结合提示隔离、运行时安全和特权分离的架构解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 由于Prompt Injection攻击对LLM集成系统的持续威胁，以及代理AI系统的出现改变了威胁环境，促使作者深入探讨现代Prompt Injection攻击如何与传统网络安全漏洞相结合，以形成新的威胁形态。

**方法:** 作者通过综合分析Prompt Injection 2.0，评估现有的缓解技术对当前威胁的有效性，并引入新的架构解决方案来应对这些挑战。

**结果:** 研究表明，传统的Web应用防火墙、XSS过滤器和CSRF令牌在面对AI增强型攻击时失效。而提出的架构解决方案展示了对抗这类攻击的潜力。

**结论:** 为了有效抵御现代Prompt Injection攻击，需要采用结合提示隔离、运行时安全和特权分离的新型架构，并加强威胁检测能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prompt+Injection+2.0%3A+Hybrid+AI+Threats，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13169，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13169&send_immediately=true&force_search=false)

**原文摘要:** Prompt injection attacks, where malicious input is designed to manipulate AI
systems into ignoring their original instructions and following unauthorized
commands instead, were first discovered by Preamble, Inc. in May 2022 and
responsibly disclosed to OpenAI. Over the last three years, these attacks have
continued to pose a critical security threat to LLM-integrated systems. The
emergence of agentic AI systems, where LLMs autonomously perform multistep
tasks through tools and coordination with other agents, has fundamentally
transformed the threat landscape. Modern prompt injection attacks can now
combine with traditional cybersecurity exploits to create hybrid threats that
systematically evade traditional security controls. This paper presents a
comprehensive analysis of Prompt Injection 2.0, examining how prompt injections
integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),
and other web security vulnerabilities to bypass traditional security measures.
We build upon Preamble's foundational research and mitigation technologies,
evaluating them against contemporary threats, including AI worms, multi-agent
infections, and hybrid cyber-AI attacks. Our analysis incorporates recent
benchmarks that demonstrate how traditional web application firewalls, XSS
filters, and CSRF tokens fail against AI-enhanced attacks. We also present
architectural solutions that combine prompt isolation, runtime security, and
privilege separation with novel threat detection capabilities.

</details>


### [93] [A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models](https://arxiv.org/abs/2507.13313)
*Chao Feng, Alberto Huertas Celdran, Jing Han, Heqing Ren, Xi Cheng, Zien Zeng, Lucas Krauter, Gerome Bovet, Burkhard Stiller*

**主要类别:** cs.CR

**AI概要:** 本文提出一个用于研究应用于物联网众包恶意软件检测的去中心化联邦学习的数据集和实验研究。通过与传统机器学习和集中式联邦学习对比，证明了去中心化联邦学习在大多数情况下具有竞争力的表现，并且能够保持数据的本地性。


<details>
  <summary>更多</summary>
  
**动机:** 随着物联网设备的普及，恶意软件检测变得越来越重要。现有的方法要么不能很好地保护用户隐私（因为需要收集所有数据到一个中心位置），要么效率不高。为了应对这些挑战，研究人员探索了去中心化联邦学习的可能性。

**方法:** 研究人员创建了一个包含良性行为和八种恶意软件家族行为记录的数据集，总共有21,582,484条原始记录。这些记录被汇总成30秒的时间窗口，生成342,106个特征用于模型训练和评估。然后，在不同的节点数量、拓扑结构和数据分布条件下，对去中心化联邦学习平台进行了实验，将其与传统的机器学习和集中式联邦学习进行了比较。

**结果:** 实验结果表明，去中心化联邦学习在保持数据本地性的同时，性能依然具有竞争力，并且在大多数设置中优于集中式联邦学习。

**结论:** 该数据集为研究物联网众包环境的安全性提供了一个坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Crowdsensing+Intrusion+Detection+Dataset+For+Decentralized+Federated+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.13313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.13313&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a dataset and experimental study for decentralized
federated learning (DFL) applied to IoT crowdsensing malware detection. The
dataset comprises behavioral records from benign and eight malware families. A
total of 21,582,484 original records were collected from system calls, file
system activities, resource usage, kernel events, input/output events, and
network records. These records were aggregated into 30-second windows,
resulting in 342,106 features used for model training and evaluation.
Experiments on the DFL platform compare traditional machine learning (ML),
centralized federated learning (CFL), and DFL across different node counts,
topologies, and data distributions. Results show that DFL maintains competitive
performance while preserving data locality, outperforming CFL in most settings.
This dataset provides a solid foundation for studying the security of IoT
crowdsensing environments.

</details>
