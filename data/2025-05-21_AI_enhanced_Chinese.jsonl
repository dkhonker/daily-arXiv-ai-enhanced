{"id": "2505.13518", "pdf": "https://arxiv.org/pdf/2505.13518", "abs": "https://arxiv.org/abs/2505.13518", "authors": ["Behnam Yousefimehr", "Mehdi Ghatee", "Mohammad Amin Seifi", "Javad Fazli", "Sajed Tavakoli", "Zahra Rafei", "Shervin Ghaffari", "Abolfazl Nikahd", "Mahdi Razi Gandomani", "Alireza Orouji", "Ramtin Mahmoudi Kashani", "Sarina Heshmati", "Negin Sadat Mousavi"], "title": "Data Balancing Strategies: A Survey of Resampling and Augmentation Methods", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Imbalanced data poses a significant obstacle in machine learning, as an\nunequal distribution of class labels often results in skewed predictions and\ndiminished model accuracy. To mitigate this problem, various resampling\nstrategies have been developed, encompassing both oversampling and\nundersampling techniques aimed at modifying class proportions. Conventional\noversampling approaches like SMOTE enhance the representation of the minority\nclass, whereas undersampling methods focus on trimming down the majority class.\nAdvances in deep learning have facilitated the creation of more complex\nsolutions, such as Generative Adversarial Networks (GANs) and Variational\nAutoencoders (VAEs), which are capable of producing high-quality synthetic\nexamples. This paper reviews a broad spectrum of data balancing methods,\nclassifying them into categories including synthetic oversampling, adaptive\ntechniques, generative models, ensemble-based strategies, hybrid approaches,\nundersampling, and neighbor-based methods. Furthermore, it highlights current\ndevelopments in resampling techniques and discusses practical implementations\nand case studies that validate their effectiveness. The paper concludes by\noffering perspectives on potential directions for future exploration in this\ndomain.", "AI": {"tldr": "This paper reviews various resampling strategies to address imbalanced data in machine learning, categorizing them into different types and discussing their effectiveness with case studies.", "motivation": "To solve the problem of imbalanced data leading to skewed predictions and reduced model accuracy in machine learning.", "method": "Review and categorization of resampling strategies including synthetic oversampling, adaptive techniques, generative models, ensemble-based strategies, hybrid approaches, undersampling, and neighbor-based methods.", "result": "Highlights developments in resampling techniques and validates their effectiveness through practical implementations and case studies.", "conclusion": "Offers perspectives on future research directions in addressing imbalanced data in machine learning."}}
{"id": "2505.13519", "pdf": "https://arxiv.org/pdf/2505.13519", "abs": "https://arxiv.org/abs/2505.13519", "authors": ["Zekun Cai", "Yiheng Yao", "Guangji Bai", "Renhe Jiang", "Xuan Song", "Ryosuke Shibasaki", "Liang Zhao"], "title": "Continuous Domain Generalization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "22 pages, 9 figures", "summary": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic context. However, existing\ndomain generalization approaches typically treat domains as discrete or\nevolving along a single axis (e.g., time), which fails to capture the complex,\nmulti-dimensional nature of real-world variation. This paper introduces the\ntask of Continuous Domain Generalization (CDG), which aims to generalize\npredictive models to unseen domains defined by arbitrary combinations of\ncontinuous variation descriptors. We present a principled framework grounded in\ngeometric and algebraic theory, showing that optimal model parameters across\ndomains lie on a low-dimensional manifold. To model this structure, we propose\na Neural Lie Transport Operator (NeuralLTO), which enables structured parameter\ntransitions by enforcing geometric continuity and algebraic consistency. To\nhandle noisy or incomplete domain descriptors, we introduce a gating mechanism\nto suppress irrelevant dimensions and a local chart-based strategy for robust\ngeneralization. Extensive experiments on synthetic and real-world\ndatasets-including remote sensing, scientific documents, and traffic\nforecasting-demonstrate that our method significantly outperforms existing\nbaselines in generalization accuracy and robustness under descriptor\nimperfections.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\uff0c\u79f0\u4e3a\u8fde\u7eed\u57df\u6cdb\u5316(CDG)\uff0c\u901a\u8fc7\u795e\u7ecf\u674e\u7fa4\u7b97\u5b50\u548c\u65b0\u7b56\u7565\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u901a\u5e38\u5c06\u9886\u57df\u89c6\u4e3a\u79bb\u6563\u7684\u6216\u8005\u6cbf\u7740\u5355\u4e00\u8f74\uff08\u5982\u65f6\u95f4\uff09\u6f14\u53d8\uff0c\u672a\u80fd\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u53d8\u5f02\u7684\u590d\u6742\u591a\u7ef4\u6027\u8d28\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u548c\u4ee3\u6570\u7406\u8bba\u7684\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u795e\u7ecf\u674e\u7fa4\u7b97\u5b50(NeuralLTO)\uff0c\u5e76\u5f15\u5165\u4e86\u95e8\u673a\u5236\u548c\u5c40\u90e8\u56fe\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u7684CDG\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff08\u5305\u62ec\u9065\u611f\u3001\u79d1\u5b66\u6587\u6863\u548c\u4ea4\u901a\u9884\u6d4b\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u5728\u6cdb\u5316\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8fde\u7eed\u57df\u6cdb\u5316(CDG)\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u51e0\u4f55\u548c\u4ee3\u6570\u7406\u8bba\u7684\u6846\u67b6\uff0c\u8868\u660e\u6700\u4f18\u6a21\u578b\u53c2\u6570\u4f4d\u4e8e\u4f4e\u7ef4\u6d41\u5f62\u4e0a\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u674e\u7fa4\u7b97\u5b50(NeuralLTO)\uff0c\u5e76\u5f15\u5165\u95e8\u673a\u5236\u548c\u5c40\u90e8\u56fe\u7b56\u7565\u6765\u5904\u7406\u63cf\u8ff0\u7b26\u4e0d\u5b8c\u7f8e\u60c5\u51b5\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u6cdb\u5316\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002"}}
{"id": "2505.13562", "pdf": "https://arxiv.org/pdf/2505.13562", "abs": "https://arxiv.org/abs/2505.13562", "authors": ["Shishen Lin"], "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback", "categories": ["stat.ML", "cs.AI", "cs.GT", "cs.LG", "cs.NE"], "comment": "21 pages, 10 figures, accepted at IJCAI 2025", "summary": "Learning in games is a fundamental problem in machine learning and artificial\nintelligence, with numerous\napplications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work\ninvestigates two-player zero-sum matrix games with an unknown payoff matrix and\nbandit feedback, where each player observes their actions and the corresponding\nnoisy payoff. Prior studies have proposed algorithms for this\nsetting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with\n\\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism\n(e.g., \\ucb) in achieving sublinear regret. However, the potential of\nrandomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel\nalgorithm that integrates evolutionary algorithms (EAs) into the bandit\nframework to implement randomised optimism through EA variation operators. We\nprove that \\coebl achieves sublinear regret, matching the performance of\ndeterministic optimism-based methods. To the best of our knowledge, this is the\nfirst theoretical regret analysis of an evolutionary bandit learning algorithm\nin matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that\n\\coebl not only achieves sublinear regret but also consistently outperforms\nclassical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic},\nthe variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}.\nThese results highlight the potential of evolutionary bandit learning,\nparticularly the efficacy of randomised optimism via evolutionary algorithms in\ngame-theoretic settings.", "AI": {"tldr": "This paper proposes a new algorithm called Competitive Co-evolutionary Bandit Learning (COEBL) which combines evolutionary algorithms with bandit learning to achieve sublinear regret in matrix games.", "motivation": "To explore the potential of randomized optimism in matrix games.", "method": "Integrating evolutionary algorithms into the bandit framework to implement randomized optimism.", "result": "The proposed COEBL algorithm achieves sublinear regret and outperforms classical bandit algorithms in empirical evaluations.", "conclusion": "This is the first theoretical regret analysis of an evolutionary bandit learning algorithm in matrix games."}}
{"id": "2505.13585", "pdf": "https://arxiv.org/pdf/2505.13585", "abs": "https://arxiv.org/abs/2505.13585", "authors": ["Xinzhu Liang", "Joseph M. Lukens", "Sanjaya Lohani", "Brian T. Kirby", "Thomas A. Searles", "Xin Qiu", "Kody J. H. Law"], "title": "Scalable Bayesian Monte Carlo: fast uncertainty estimation beyond deep ensembles", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "56 pages, 44 figures, 35 tables", "summary": "This work introduces a new method called scalable Bayesian Monte Carlo\n(SBMC). The model interpolates between a point estimator and the posterior, and\nthe algorithm is a parallel implementation of a consistent (asymptotically\nunbiased) Bayesian deep learning algorithm: sequential Monte Carlo (SMC) or\nMarkov chain Monte Carlo (MCMC). The method is motivated theoretically, and its\nutility is demonstrated on practical examples: MNIST, CIFAR, IMDb. A systematic\nnumerical study reveals that parallel implementations of SMC and MCMC are\ncomparable to serial implementations in terms of performance and total cost,\nand they achieve accuracy at or beyond the state-of-the-art (SOTA) methods like\ndeep ensembles at convergence, along with substantially improved uncertainty\nquantification (UQ)--in particular, epistemic UQ. But even parallel\nimplementations are expensive, with an irreducible time barrier much larger\nthan the cost of the MAP estimator. Compressing time further leads to rapid\ndegradation of accuracy, whereas UQ remains valuable. By anchoring to a point\nestimator we can recover accuracy, while retaining valuable UQ, ultimately\ndelivering strong performance across metrics for a cost comparable to the SOTA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u8499\u7279\u5361\u6d1b\u65b9\u6cd5SBMC\uff0c\u8be5\u65b9\u6cd5\u5728MNIST\u3001CIFAR\u548cIMDb\u7b49\u5b9e\u9645\u4f8b\u5b50\u4e0a\u8bc1\u660e\u4e86\u5176\u6548\u7528\u3002\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cSBMC\u5728\u6027\u80fd\u548c\u6210\u672c\u65b9\u9762\u76f8\u5f53\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08\u5c24\u5176\u662f\u8ba4\u8bc6\u8bba\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff09\u3002\u7136\u800c\uff0c\u5373\u4f7f\u662f\u5e76\u884c\u5b9e\u73b0\u4e5f\u6602\u8d35\uff0c\u8fdb\u4e00\u6b65\u538b\u7f29\u65f6\u95f4\u4f1a\u5bfc\u81f4\u51c6\u786e\u6027\u8fc5\u901f\u4e0b\u964d\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4ecd\u7136\u6709\u4ef7\u503c\u3002\u901a\u8fc7\u951a\u5b9a\u5230\u70b9\u4f30\u8ba1\u5668\uff0c\u53ef\u4ee5\u6062\u590d\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u6709\u4ef7\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u6700\u7ec8\u5728\u6210\u672c\u4e0a\u63d0\u4f9b\u4e86\u4e0e\u6700\u5148\u8fdb\u6280\u672f\u76f8\u5f53\u7684\u5f3a\u5927\u6027\u80fd\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u8499\u7279\u5361\u6d1b\u65b9\u6cd5SBMC\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "SBMC\u662f\u4e00\u79cd\u5e76\u884c\u5b9e\u73b0\u7684\u4e00\u81f4\uff08\u6e10\u8fd1\u65e0\u504f\uff09\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff1a\u987a\u5e8f\u8499\u7279\u5361\u6d1b\uff08SMC\uff09\u6216\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\uff0c\u5e76\u4e14\u5b83\u5728\u70b9\u4f30\u8ba1\u5668\u548c\u540e\u9a8c\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\u3002", "result": "SBMC\u5728MNIST\u3001CIFAR\u548cIMDb\u7b49\u5b9e\u9645\u4f8b\u5b50\u4e0a\u8bc1\u660e\u4e86\u5176\u6548\u7528\uff0c\u4e0e\u4e32\u884c\u5b9e\u73b0\u76f8\u6bd4\uff0c\u5176\u6027\u80fd\u548c\u603b\u6210\u672c\u76f8\u5f53\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08\u5c24\u5176\u662f\u8ba4\u8bc6\u8bba\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff09\u3002", "conclusion": "SBMC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5176\u6210\u672c\u4e0e\u6700\u5148\u8fdb\u7684\u6280\u672f\u76f8\u5f53\uff0c\u5c3d\u7ba1\u5e76\u884c\u5b9e\u73b0\u6602\u8d35\uff0c\u4f46\u901a\u8fc7\u951a\u5b9a\u5230\u70b9\u4f30\u8ba1\u5668\u53ef\u4ee5\u6062\u590d\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u6709\u4ef7\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002"}}
{"id": "2505.13466", "pdf": "https://arxiv.org/pdf/2505.13466", "abs": "https://arxiv.org/abs/2505.13466", "authors": ["Vu Dinh Xuan", "Hao Vo", "David Murphy", "Hoang D. Nguyen"], "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data", "categories": ["cs.AI"], "comment": null, "summary": "The scarcity of data depicting dangerous situations presents a major obstacle\nto training AI systems for safety-critical applications, such as construction\nsafety, where ethical and logistical barriers hinder real-world data\ncollection. This creates an urgent need for an end-to-end framework to generate\nsynthetic data that can bridge this gap. While existing methods can produce\nsynthetic scenes, they often lack the semantic depth required for scene\nsimulations, limiting their effectiveness. To address this, we propose a novel\nmulti-agent framework that employs an iterative, in-the-loop collaboration\nbetween two agents: an Evaluator Agent, acting as an LLM-based judge to enforce\nsemantic consistency and safety-specific constraints, and an Editor Agent,\nwhich generates and refines scenes based on this guidance. Powered by LLM's\ncapabilities to reasoning and common-sense knowledge, this collaborative design\nproduces synthetic images tailored to safety-critical scenarios. Our\nexperiments suggest this design can generate useful scenes based on realistic\nspecifications that address the shortcomings of prior approaches, balancing\nsafety requirements with visual semantics. This iterative process holds promise\nfor delivering robust, aesthetically sound simulations, offering a potential\nsolution to the data scarcity challenge in multimedia safety applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u8bc4\u4f30\u8005\u548c\u7f16\u8f91\u8005\u4e4b\u95f4\u7684\u534f\u4f5c\u751f\u6210\u9488\u5bf9\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u5408\u6210\u56fe\u50cf\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\uff08\u5982\u65bd\u5de5\u5b89\u5168\uff09\u4e2d\u7f3a\u4e4f\u63cf\u7ed8\u5371\u9669\u60c5\u51b5\u7684\u6570\u636e\u963b\u788d\u4e86AI\u7cfb\u7edf\u7684\u8bad\u7ec3\u3002", "method": "\u4e00\u79cd\u8fed\u4ee3\u3001\u5faa\u73af\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u4f5c\u4e3aLLM\u8bc4\u59d4\u7684\u8bc4\u4f30\u8005\u4ee3\u7406\u548c\u4e00\u4e2a\u57fa\u4e8e\u6307\u5bfc\u751f\u6210\u548c\u4f18\u5316\u573a\u666f\u7684\u7f16\u8f91\u8005\u4ee3\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u73b0\u5b9e\u89c4\u683c\u4e14\u5177\u6709\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u6709\u7528\u573a\u666f\u56fe\u50cf\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u9700\u6c42\u4e0e\u89c6\u89c9\u8bed\u4e49\u3002", "conclusion": "\u6b64\u6846\u67b6\u53ef\u80fd\u89e3\u51b3\u591a\u5a92\u4f53\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u4f9b\u7a33\u5065\u4e14\u7f8e\u89c2\u7684\u6a21\u62df\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.13457", "pdf": "https://arxiv.org/pdf/2505.13457", "abs": "https://arxiv.org/abs/2505.13457", "authors": ["Nathan Faraj"], "title": "Tuning Learning Rates with the Cumulative-Learning Constant", "categories": ["cs.LG"], "comment": "9 pages, 13 figures, 2 tables", "summary": "This paper introduces a novel method for optimizing learning rates in machine\nlearning. A previously unrecognized proportionality between learning rates and\ndataset sizes is discovered, providing valuable insights into how dataset scale\ninfluences training dynamics. Additionally, a cumulative learning constant is\nidentified, offering a framework for designing and optimizing advanced learning\nrate schedules. These findings have the potential to enhance training\nefficiency and performance across a wide range of machine learning\napplications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5b66\u4e60\u7387\uff0c\u53d1\u73b0\u4e86\u5b66\u4e60\u7387\u548c\u6570\u636e\u96c6\u5927\u5c0f\u7684\u65b0\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u4e2a\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\uff0c\u8fd9\u4e9b\u53d1\u73b0\u53ef\u80fd\u63d0\u9ad8\u591a\u79cd\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4f18\u5316\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5b66\u4e60\u7387\u3002", "method": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u6bd4\u4f8b\u5173\u7cfb\u5e76\u8bc6\u522b\u51fa\u4e00\u4e2a\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u4e4b\u524d\u672a\u88ab\u8ba4\u8bc6\u7684\u5b66\u4e60\u7387\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u4e4b\u95f4\u7684\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u786e\u5b9a\u4e86\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\u3002", "conclusion": "\u53d1\u73b0\u4e86\u5b66\u4e60\u7387\u548c\u6570\u636e\u96c6\u5927\u5c0f\u4e4b\u95f4\u7684\u65b0\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u4e2a\u7d2f\u79ef\u5b66\u4e60\u5e38\u6570\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u548c\u4f18\u5316\u5148\u8fdb\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u6709\u53ef\u80fd\u63d0\u9ad8\u5404\u79cd\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2505.13732", "pdf": "https://arxiv.org/pdf/2505.13732", "abs": "https://arxiv.org/abs/2505.13732", "authors": ["Etienne Gauthier", "Francis Bach", "Michael I. Jordan"], "title": "Backward Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "Code available at: https://github.com/GauthierE/backward-cp", "summary": "We introduce $\\textit{Backward Conformal Prediction}$, a method that\nguarantees conformal coverage while providing flexible control over the size of\nprediction sets. Unlike standard conformal prediction, which fixes the coverage\nlevel and allows the conformal set size to vary, our approach defines a rule\nthat constrains how prediction set sizes behave based on the observed data, and\nadapts the coverage level accordingly. Our method builds on two key\nfoundations: (i) recent results by Gauthier et al. [2025] on post-hoc validity\nusing e-values, which ensure marginal coverage of the form $\\mathbb{P}(Y_{\\rm\ntest} \\in \\hat C_n^{\\tilde{\\alpha}}(X_{\\rm test})) \\ge 1 -\n\\mathbb{E}[\\tilde{\\alpha}]$ up to a first-order Taylor approximation for any\ndata-dependent miscoverage $\\tilde{\\alpha}$, and (ii) a novel leave-one-out\nestimator $\\hat{\\alpha}^{\\rm LOO}$ of the marginal miscoverage\n$\\mathbb{E}[\\tilde{\\alpha}]$ based on the calibration set, ensuring that the\ntheoretical guarantees remain computable in practice. This approach is\nparticularly useful in applications where large prediction sets are impractical\nsuch as medical diagnosis. We provide theoretical results and empirical\nevidence supporting the validity of our method, demonstrating that it maintains\ncomputable coverage guarantees while ensuring interpretable, well-controlled\nprediction set sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cd\u5411\u4e00\u81f4\u9884\u6d4b\u65b9\u6cd5\uff0c\u5b83\u80fd\u7075\u6d3b\u63a7\u5236\u9884\u6d4b\u96c6\u5927\u5c0f\u5e76\u4fdd\u8bc1\u8986\u76d6\u7387\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u533b\u7597\u8bca\u65ad\u7b49\u573a\u666f\u3002", "motivation": "\u6807\u51c6\u4e00\u81f4\u9884\u6d4b\u65b9\u6cd5\u56fa\u5b9a\u8986\u76d6\u7387\u800c\u5141\u8bb8\u9884\u6d4b\u96c6\u5927\u5c0f\u53d8\u5316\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u9884\u6d4b\u96c6\u5927\u5c0f\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u53cd\u5411\u4e00\u81f4\u9884\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u89c2\u6d4b\u6570\u636e\u7ea6\u675f\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u884c\u4e3a\uff0c\u5e76\u76f8\u5e94\u5730\u8c03\u6574\u8986\u76d6\u7387\u6c34\u5e73\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8bc1\u4e0a\u90fd\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u5728\u4fdd\u6301\u53ef\u8ba1\u7b97\u8986\u76d6\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u8fd8\u80fd\u786e\u4fdd\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u53ef\u89e3\u91ca\u6027\u548c\u826f\u597d\u63a7\u5236\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u826f\u597d\u63a7\u5236\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u4e86\u53ef\u8ba1\u7b97\u7684\u8986\u76d6\u4fdd\u8bc1\u3002"}}
{"id": "2505.13484", "pdf": "https://arxiv.org/pdf/2505.13484", "abs": "https://arxiv.org/abs/2505.13484", "authors": ["Rene Heesch", "Sebastian Eilermann", "Alexander Windmann", "Alexander Diedrich", "Philipp Rosenthal", "Oliver Niggemann"], "title": "Evaluating Large Language Models for Real-World Engineering Tasks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are transformative not only for daily activities\nbut also for engineering tasks. However, current evaluations of LLMs in\nengineering exhibit two critical shortcomings: (i) the reliance on simplified\nuse cases, often adapted from examination materials where correctness is easily\nverifiable, and (ii) the use of ad hoc scenarios that insufficiently capture\ncritical engineering competencies. Consequently, the assessment of LLMs on\ncomplex, real-world engineering problems remains largely unexplored. This paper\naddresses this gap by introducing a curated database comprising over 100\nquestions derived from authentic, production-oriented engineering scenarios,\nsystematically designed to cover core competencies such as product design,\nprognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art\nLLMs, including both cloud-based and locally hosted instances, to\nsystematically investigate their performance on complex engineering tasks. Our\nresults show that LLMs demonstrate strengths in basic temporal and structural\nreasoning but struggle significantly with abstract reasoning, formal modeling,\nand context-sensitive engineering logic.", "AI": {"tldr": "This paper introduces a curated database of engineering questions to evaluate the performance of large language models on complex engineering tasks.", "motivation": "Current evaluations of LLMs in engineering rely on simplified use cases and ad hoc scenarios that do not fully capture critical engineering competencies.", "method": "The authors created a database of over 100 questions derived from authentic engineering scenarios and used it to evaluate four state-of-the-art LLMs.", "result": "LLMs perform well in basic temporal and structural reasoning but struggle with abstract reasoning, formal modeling, and context-sensitive engineering logic.", "conclusion": "The study highlights the need for more comprehensive evaluation methods for LLMs in engineering."}}
{"id": "2505.13461", "pdf": "https://arxiv.org/pdf/2505.13461", "abs": "https://arxiv.org/abs/2505.13461", "authors": ["Junye Jiang", "Yaan Zhou", "Yuanhao Gong", "Haoxuan Yuan", "Shuanglong Liu"], "title": "FPGA-based Acceleration for Convolutional Neural Networks: A Comprehensive Review", "categories": ["cs.LG", "cs.AR", "C.3"], "comment": "19 pages, 3 figures", "summary": "Convolutional Neural Networks (CNNs) are fundamental to deep learning,\ndriving applications across various domains. However, their growing complexity\nhas significantly increased computational demands, necessitating efficient\nhardware accelerators. Field-Programmable Gate Arrays (FPGAs) have emerged as a\nleading solution, offering reconfigurability, parallelism, and energy\nefficiency. This paper provides a comprehensive review of FPGA-based hardware\naccelerators specifically designed for CNNs. It presents and summarizes the\nperformance evaluation framework grounded in existing studies and explores key\noptimization strategies, such as parallel computing, dataflow optimization, and\nhardware-software co-design. It also compares various FPGA architectures in\nterms of latency, throughput, compute efficiency, power consumption, and\nresource utilization. Finally, the paper highlights future challenges and\nopportunities, emphasizing the potential for continued innovation in this\nfield.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9488\u5bf9\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u7684\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u603b\u7ed3\u4e86\u6027\u80fd\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f18\u5316\u7b56\u7565\u548c\u67b6\u6784\u6bd4\u8f83\uff0c\u6700\u540e\u6307\u51fa\u4e86\u672a\u6765\u6311\u6218\u4e0e\u673a\u9047\u3002", "motivation": "\u968f\u7740CNN\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u5176\u8ba1\u7b97\u9700\u6c42\u663e\u8457\u4e0a\u5347\uff0c\u9700\u8981\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u5668\u3002", "method": "\u7efc\u8ff0\u73b0\u6709\u7814\u7a76\u5e76\u63d0\u51fa\u6027\u80fd\u8bc4\u4f30\u6846\u67b6\uff0c\u63a2\u8ba8\u4f18\u5316\u7b56\u7565\u5982\u5e76\u884c\u8ba1\u7b97\u3001\u6570\u636e\u6d41\u4f18\u5316\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540cFPGA\u67b6\u6784\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8eFPGA\u5728CNN\u52a0\u901f\u4e2d\u7684\u6027\u80fd\u6307\u6807\uff08\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u7b49\uff09\u7684\u5168\u9762\u6bd4\u8f83\uff0c\u5e76\u603b\u7ed3\u4e86\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6307\u51fa\u8be5\u9886\u57df\u672a\u6765\u7684\u6311\u6218\u4e0e\u521b\u65b0\u673a\u4f1a\u3002"}}
{"id": "2505.13864", "pdf": "https://arxiv.org/pdf/2505.13864", "abs": "https://arxiv.org/abs/2505.13864", "authors": ["Sevvandi Kandanaarachchi", "Cheng Soon Ong"], "title": "Graphon Mixtures", "categories": ["stat.ML", "cs.DM", "cs.LG"], "comment": null, "summary": "Social networks have a small number of large hubs, and a large number of\nsmall dense communities. We propose a generative model that captures both hub\nand dense structures. Based on recent results about graphons on line graphs,\nour model is a graphon mixture, enabling us to generate sequences of graphs\nwhere each graph is a combination of sparse and dense graphs. We propose a new\ncondition on sparse graphs (the max-degree), which enables us to identify hubs.\nWe show theoretically that we can estimate the normalized degree of the hubs,\nas well as estimate the graphon corresponding to sparse components of graph\nmixtures. We illustrate our approach on synthetic data, citation graphs, and\nsocial networks, showing the benefits of explicitly modeling sparse graphs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6a21\u578b\u6765\u540c\u65f6\u6355\u6349\u793e\u4f1a\u7f51\u7edc\u4e2d\u7684hub\u548c\u5bc6\u96c6\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u7a00\u758f\u56fe\u6761\u4ef6\u8bc6\u522bhub\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u53ef\u4ee5\u4f30\u8ba1hub\u7684\u5f52\u4e00\u5316\u5ea6\u6570\u548c\u7a00\u758f\u7ec4\u4ef6\u5bf9\u5e94\u7684graphon\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u793e\u4f1a\u7f51\u7edc\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6709\u6548\u6355\u6349hub\u548c\u5bc6\u96c6\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8egraphon\u6df7\u5408\u7684\u751f\u6210\u6a21\u578b\uff0c\u5e76\u5f15\u5165max-degree\u6761\u4ef6\u7528\u4e8e\u8bc6\u522bhub\u3002", "result": "\u80fd\u591f\u4f30\u8ba1hub\u7684\u5f52\u4e00\u5316\u5ea6\u6570\u548c\u7a00\u758f\u7ec4\u4ef6\u5bf9\u5e94\u7684graphon\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u3001\u5f15\u7528\u56fe\u548c\u793e\u4f1a\u7f51\u7edc\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u540c\u65f6\u6355\u6349\u793e\u4f1a\u7f51\u7edc\u4e2d\u7684hub\u548c\u5bc6\u96c6\u7ed3\u6784\u3002"}}
{"id": "2505.13489", "pdf": "https://arxiv.org/pdf/2505.13489", "abs": "https://arxiv.org/abs/2505.13489", "authors": ["Wenkang Han", "Wang Lin", "Liya Hu", "Zhenlong Dai", "Yiyun Zhou", "Mengze Li", "Zemin Liu", "Chang Yao", "Jingyuan Chen"], "title": "Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by IJCAI 2025", "summary": "Knowledge tracing (KT) aims to predict learners' future performance based on\nhistorical learning interactions. However, existing KT models predominantly\nfocus on data from a single course, limiting their ability to capture a\ncomprehensive understanding of learners' knowledge states. In this paper, we\npropose TransKT, a contrastive cross-course knowledge tracing method that\nleverages concept graph guided knowledge transfer to model the relationships\nbetween learning behaviors across different courses, thereby enhancing\nknowledge state estimation. Specifically, TransKT constructs a cross-course\nconcept graph by leveraging zero-shot Large Language Model (LLM) prompts to\nestablish implicit links between related concepts across different courses.\nThis graph serves as the foundation for knowledge transfer, enabling the model\nto integrate and enhance the semantic features of learners' interactions across\ncourses. Furthermore, TransKT includes an LLM-to-LM pipeline for incorporating\nsummarized semantic features, which significantly improves the performance of\nGraph Convolutional Networks (GCNs) used for knowledge transfer. Additionally,\nTransKT employs a contrastive objective that aligns single-course and\ncross-course knowledge states, thereby refining the model's ability to provide\na more robust and accurate representation of learners' overall knowledge\nstates.", "AI": {"tldr": "Proposes TransKT, a method using concept graph guided knowledge transfer to improve knowledge tracing across multiple courses.", "motivation": "Existing KT models mainly focus on single-course data, limiting their ability to understand learners' knowledge states comprehensively.", "method": "Uses a cross-course concept graph and an LLM-to-LM pipeline to enhance GCN-based knowledge transfer, with a contrastive objective to refine knowledge state representation.", "result": "Enhances the estimation of learners' knowledge states across different courses.", "conclusion": "TransKT provides a more robust and accurate way to trace learners' knowledge states by integrating cross-course information."}}
{"id": "2505.13462", "pdf": "https://arxiv.org/pdf/2505.13462", "abs": "https://arxiv.org/abs/2505.13462", "authors": ["Thien Nguyen", "William Guicquero"], "title": "End-to-end fully-binarized network design: from Generic Learned Thermometer to Block Pruning", "categories": ["cs.LG", "cs.AR", "cs.CV", "eess.IV", "stat.ML"], "comment": "Accepted to IEEE AICAS 2025", "summary": "Existing works on Binary Neural Network (BNN) mainly focus on model's weights\nand activations while discarding considerations on the input raw data. This\narticle introduces Generic Learned Thermometer (GLT), an encoding technique to\nimprove input data representation for BNN, relying on learning non linear\nquantization thresholds. This technique consists in multiple data binarizations\nwhich can advantageously replace a conventional Analog to Digital Conversion\n(ADC) that uses natural binary coding. Additionally, we jointly propose a\ncompact topology with light-weight grouped convolutions being trained thanks to\nblock pruning and Knowledge Distillation (KD), aiming at reducing furthermore\nthe model size so as its computational complexity. We show that GLT brings\nversatility to the BNN by intrinsically performing global tone mapping,\nenabling significant accuracy gains in practice (demonstrated by simulations on\nthe STL-10 and VWW datasets). Moreover, when combining GLT with our proposed\nblock-pruning technique, we successfully achieve lightweight (under 1Mb),\nfully-binarized models with limited accuracy degradation while being suitable\nfor in-sensor always-on inference use cases.", "AI": {"tldr": "This article proposes a new input encoding technique called GLT for Binary Neural Networks (BNNs) to improve input data representation. The authors also introduce a compact topology with light-weight grouped convolutions to reduce model size and computational complexity. Experiments show that GLT improves accuracy and allows for fully-binarized lightweight models suitable for in-sensor always-on inference.", "motivation": "Existing BNNs focus on weights and activations but not input data representation. The authors aim to enhance BNNs by improving input data encoding.", "method": "Proposes Generic Learned Thermometer (GLT), a technique for non-linear quantization threshold learning to binarize data. Also introduces a compact topology using light-weight grouped convolutions trained with block pruning and Knowledge Distillation (KD).", "result": "GLT improves accuracy significantly on STL-10 and VWW datasets. Combining GLT with block-pruning results in lightweight, fully-binarized models under 1Mb with minimal accuracy loss.", "conclusion": "The proposed methods improve BNNs' versatility and efficiency, making them suitable for in-sensor always-on inference applications."}}
{"id": "2505.13902", "pdf": "https://arxiv.org/pdf/2505.13902", "abs": "https://arxiv.org/abs/2505.13902", "authors": ["Naoki Hayashi", "Takuro Kutsuna", "Sawa Takamuku"], "title": "An Asymptotic Equation Linking WAIC and WBIC in Singular Models", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62F15, 62R01"], "comment": "14pages, to be submitted to ICONIP2025", "summary": "In statistical learning, models are classified as regular or singular\ndepending on whether the mapping from parameters to probability distributions\nis injective. Most models with hierarchical structures or latent variables are\nsingular, for which conventional criteria such as the Akaike Information\nCriterion and the Bayesian Information Criterion are inapplicable due to the\nbreakdown of normal approximations for the likelihood and posterior. To address\nthis, the Widely Applicable Information Criterion (WAIC) and the Widely\nApplicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC\nand WBIC are computed using posterior distributions at different temperature\nsettings, separate posterior sampling is generally required. In this paper, we\ntheoretically derive an asymptotic equation that links WAIC and WBIC, despite\ntheir dependence on different posteriors. This equation yields an\nasymptotically unbiased expression of WAIC in terms of the posterior\ndistribution used for WBIC. The result clarifies the structural relationship\nbetween these criteria within the framework of singular learning theory, and\ndeepens understanding of their asymptotic behavior. This theoretical\ncontribution provides a foundation for future developments in the computational\nefficiency of model selection in singular models.", "AI": {"tldr": "This paper theoretically derives an asymptotic equation linking WAIC and WBIC, providing insights into their structural relationship and asymptotic behavior in singular learning theory.", "motivation": "To address the limitations of conventional criteria in singular models where normal approximations for likelihood and posterior break down.", "method": "Theoretical derivation of an asymptotic equation linking WAIC and WBIC despite their dependence on different posteriors.", "result": "An asymptotically unbiased expression of WAIC in terms of the posterior distribution used for WBIC is obtained.", "conclusion": "This theoretical contribution enhances understanding of the structural relationship between WAIC and WBIC and provides a basis for improving computational efficiency in model selection for singular models."}}
{"id": "2505.13496", "pdf": "https://arxiv.org/pdf/2505.13496", "abs": "https://arxiv.org/abs/2505.13496", "authors": ["Przemek Pospieszny", "Wojciech Mormul", "Karolina Szyndler", "Sanjeev Kumar"], "title": "ADALog: Adaptive Unsupervised Anomaly detection in Logs with Self-attention Masked Language Model", "categories": ["cs.AI", "cs.LG", "I.2.6; I.2.7; I.5.1; C.2.4"], "comment": "Conference paper accepted at ICMLT 2025; to appear in the IEEE\n  Conference Proceedings", "summary": "Modern software systems generate extensive heterogeneous log data with\ndynamic formats, fragmented event sequences, and varying temporal patterns,\nmaking anomaly detection both crucial and challenging. To address these\ncomplexities, we propose ADALog, an adaptive, unsupervised anomaly detection\nframework designed for practical applicability across diverse real-world\nenvironments. Unlike traditional methods reliant on log parsing, strict\nsequence dependencies, or labeled data, ADALog operates on individual\nunstructured logs, extracts intra-log contextual relationships, and performs\nadaptive thresholding on normal data. The proposed approach utilizes a\ntransformer-based, pretrained bidirectional encoder with a masked language\nmodeling task, fine-tuned on normal logs to capture domain-specific syntactic\nand semantic patterns essential for accurate anomaly detection. Anomalies are\nidentified via token-level reconstruction probabilities, aggregated into\nlog-level scores, with adaptive percentile-based thresholding calibrated only\non normal data. This allows the model to dynamically adapt to evolving system\nbehaviors while avoiding rigid, heuristic-based thresholds common in\ntraditional systems. We evaluate ADALog on benchmark datasets BGL, Thunderbird,\nand Spirit, showing strong generalization and competitive performance compared\nto state-of-the-art supervised and unsupervised methods. Additional ablation\nstudies examine the effects of masking, fine-tuning, and token positioning on\nmodel behavior and interpretability.", "AI": {"tldr": "ADALog\u662f\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u4e13\u4e3a\u5904\u7406\u8f6f\u4ef6\u7cfb\u7edf\u751f\u6210\u7684\u5f02\u6784\u65e5\u5fd7\u6570\u636e\u8bbe\u8ba1\u3002\u5b83\u57fa\u4e8e\u53d8\u538b\u5668\u6a21\u578b\uff0c\u5e76\u5728\u6b63\u5e38\u65e5\u5fd7\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u7cfb\u7edf\u884c\u4e3a\u7684\u53d8\u5316\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u4ea7\u751f\u7684\u65e5\u5fd7\u6570\u636e\u5177\u6709\u52a8\u6001\u683c\u5f0f\u3001\u4e8b\u4ef6\u5e8f\u5217\u788e\u7247\u5316\u548c\u65f6\u95f4\u6a21\u5f0f\u53d8\u5316\u7b49\u7279\u70b9\uff0c\u4f7f\u5f97\u5f02\u5e38\u68c0\u6d4b\u65e2\u91cd\u8981\u53c8\u56f0\u96be\u3002", "method": "ADALog\u4f7f\u7528\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u53cc\u5411\u7f16\u7801\u5668\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u9884\u8bad\u7ec3\u5e76\u9488\u5bf9\u6b63\u5e38\u65e5\u5fd7\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u7528\u4e8e\u6355\u83b7\u7279\u5b9a\u9886\u57df\u7684\u53e5\u6cd5\u548c\u8bed\u4e49\u6a21\u5f0f\u3002\u5f02\u5e38\u901a\u8fc7\u6807\u8bb0\u7ea7\u522b\u7684\u91cd\u5efa\u6982\u7387\u6765\u8bc6\u522b\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u81ea\u9002\u5e94\u9608\u503c\u5904\u7406\u3002", "result": "ADALog\u5728BGL\u3001Thunderbird\u548cSpirit\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u663e\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\u7684\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "ADALog\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u4e0d\u9700\u8981\u4f9d\u8d56\u4e25\u683c\u5e8f\u5217\u4f9d\u8d56\u6216\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.13463", "pdf": "https://arxiv.org/pdf/2505.13463", "abs": "https://arxiv.org/abs/2505.13463", "authors": ["Paolo Guida", "William L. Roberts"], "title": "Predicting The Evolution of Interfaces with Fourier Neural Operators", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Recent progress in AI has established neural operators as powerful tools that\ncan predict the evolution of partial differential equations, such as the\nNavier-Stokes equations. Some complex problems rely on sophisticated algorithms\nto deal with strong discontinuities in the computational domain. For example,\nliquid-vapour multiphase flows are a challenging problem in many\nconfigurations, particularly those involving large density gradients or phase\nchange. The complexity mentioned above has not allowed for fine control of fast\nindustrial processes or applications because computational fluid dynamics (CFD)\nmodels do not have a quick enough forecasting ability. This work demonstrates\nthat the time scale of neural operators-based predictions is comparable to the\ntime scale of multi-phase applications, thus proving they can be used to\ncontrol processes that require fast response. Neural Operators can be trained\nusing experimental data, simulations or a combination. In the following, neural\noperators were trained in volume of fluid simulations, and the resulting\npredictions showed very high accuracy, particularly in predicting the evolution\nof the liquid-vapour interface, one of the most critical tasks in a multi-phase\nprocess controller.", "AI": {"tldr": "This study shows that neural operators can predict the evolution of multi-phase flows with high accuracy and fast response times, which could enable better control of industrial processes.", "motivation": "To address the challenge of predicting complex multi-phase flows with strong discontinuities and large density gradients.", "method": "Training neural operators using volume of fluid simulations.", "result": "Highly accurate predictions of liquid-vapour interface evolution.", "conclusion": "Neural operators can predict multi-phase flow evolutions at speeds suitable for real-time industrial process control."}}
{"id": "2505.13947", "pdf": "https://arxiv.org/pdf/2505.13947", "abs": "https://arxiv.org/abs/2505.13947", "authors": ["Shirong Xu", "Hengzhi He", "Guang Cheng"], "title": "A Probabilistic Perspective on Model Collapse", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In recent years, model collapse has become a critical issue in language model\ntraining, making it essential to understand the underlying mechanisms driving\nthis phenomenon. In this paper, we investigate recursive parametric model\ntraining from a probabilistic perspective, aiming to characterize the\nconditions under which model collapse occurs and, crucially, how it can be\nmitigated. We conceptualize the recursive training process as a random walk of\nthe model estimate, highlighting how the sample size influences the step size\nand how the estimation procedure determines the direction and potential bias of\nthe random walk. Under mild conditions, we rigorously show that progressively\nincreasing the sample size at each training step is necessary to prevent model\ncollapse. In particular, when the estimation is unbiased, the required growth\nrate follows a superlinear pattern. This rate needs to be accelerated even\nfurther in the presence of substantial estimation bias. Building on this\nprobabilistic framework, we also investigate the probability that recursive\ntraining on synthetic data yields models that outperform those trained solely\non real data. Moreover, we extend these results to general parametric model\nfamily in an asymptotic regime. Finally, we validate our theoretical results\nthrough extensive simulations and a real-world dataset.", "AI": {"tldr": "This paper investigates model collapse during language model training from a probabilistic perspective, providing conditions to prevent it and showing that increasing sample size is necessary.", "motivation": "To understand the underlying mechanisms driving model collapse and how it can be mitigated.", "method": "Investigating recursive parametric model training from a probabilistic perspective.", "result": "Under mild conditions, progressively increasing the sample size at each training step is necessary to prevent model collapse. The required growth rate follows a superlinear pattern when the estimation is unbiased, and needs to be accelerated further in the presence of substantial estimation bias.", "conclusion": "Progressively increasing the sample size at each training step is necessary to prevent model collapse."}}
{"id": "2505.13511", "pdf": "https://arxiv.org/pdf/2505.13511", "abs": "https://arxiv.org/abs/2505.13511", "authors": ["David Noever", "Forrest McKee"], "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This study explores Large Language Models (LLMs) as autonomous agents for\nreal-world tasks, including freelance software development. This work presents\na new benchmark that evaluates LLMs on freelance programming and data analysis\ntasks derived from economic data. We construct the benchmark using synthetic\ntasks created from a Kaggle Freelancer dataset of job postings, with all job\nprices standardized to USD (median fixed-project price around $250, and an\naverage of $306). Each task is accompanied by structured input-output test\ncases and an estimated price tag, enabling automated correctness checking and a\nmonetary performance valuation. This approach is inspired by OpenAI's recent\nSWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our\nframework simplifies evaluation using programmatically testable tasks and\npredicted price values, making it highly scalable and repeatable. On this\nbenchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen\n2.5, and Mistral. We report each model's accuracy (task success rate and\ntest-case pass rate) and the total \"freelance earnings\" it achieves (sum of\nprices of solved tasks). Our results show that Claude 3.5 Haiku performs best,\nearning approximately $1.52 million USD, followed closely by GPT-4o-mini at\n$1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the\ndistribution of errors per task and observe that the strongest models solve the\nmost tasks and rarely fail completely on any project. We discuss the\nimplications of these results for the feasibility of AI as a freelance\ndeveloper, the advantages and limitations of our automated benchmark approach,\nand the gap between performance on structured tasks versus the true complexity\nof real-world freelance jobs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u6267\u884c\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\uff0c\u5305\u62ec\u81ea\u7531\u804c\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u3002\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u4ece\u7ecf\u6d4e\u6570\u636e\u6d3e\u751f\u7684\u81ea\u7531\u7f16\u7a0b\u548c\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u901a\u8fc7Kaggle\u81ea\u7531\u804c\u4e1a\u8005\u6570\u636e\u96c6\u4e2d\u7684\u5de5\u4f5c\u53d1\u5e03\u521b\u5efa\u5408\u6210\u4efb\u52a1\uff0c\u5e76\u6807\u51c6\u5316\u4ef7\u683c\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u7b80\u5316\u4e86\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u4f7f\u5b83\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u91cd\u590d\u6027\u3002\u7ed3\u679c\u663e\u793aClaude 3.5 Haiku\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662fGPT-4o-mini\uff0cQwen 2.5\u548cMistral\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7531\u804c\u4e1a\u7f16\u7a0b\u548c\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u7684\u53ef\u884c\u6027\u3002", "method": "\u4f7f\u7528\u4eceKaggle\u81ea\u7531\u804c\u4e1a\u8005\u6570\u636e\u96c6\u4e2d\u7684\u5de5\u4f5c\u53d1\u5e03\u521b\u5efa\u7684\u5408\u6210\u4efb\u52a1\u6784\u5efa\u57fa\u51c6\uff0c\u6807\u51c6\u5316\u4ef7\u683c\uff0c\u5e76\u4f7f\u7528\u81ea\u52a8\u5316\u6d4b\u8bd5\u6848\u4f8b\u548c\u9884\u6d4b\u4ef7\u683c\u503c\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "Claude 3.5 Haiku\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662fGPT-4o-mini\uff0cQwen 2.5\u548cMistral\u3002\u6700\u5f3a\u7684\u6a21\u578b\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5f88\u5c11\u5b8c\u5168\u5931\u8d25\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86LLMs\u4f5c\u4e3a\u81ea\u7531\u804c\u4e1a\u5f00\u53d1\u8005\u7684\u6f5c\u529b\uff0c\u4f46\u8fd8\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\u548c\u6027\u80fd\u5dee\u8ddd\u9700\u8981\u89e3\u51b3\u3002"}}
{"id": "2505.13471", "pdf": "https://arxiv.org/pdf/2505.13471", "abs": "https://arxiv.org/abs/2505.13471", "authors": ["George Bird"], "title": "The Spotlight Resonance Method: Resolving the Alignment of Embedded Activations", "categories": ["cs.LG", "I.2.6; I.5.1"], "comment": "25 pages, 13 figures, 2nd Workshop on Representational Alignment,\n  International Conference on Learning Representations (ICLR)", "summary": "Understanding how deep learning models represent data is currently difficult\ndue to the limited number of methodologies available. This paper demonstrates a\nversatile and novel visualisation tool for determining the axis alignment of\nembedded data at any layer in any deep learning model. In particular, it\nevaluates the distribution around planes defined by the network's privileged\nbasis vectors. This method provides both an atomistic and a holistic, intuitive\nmetric for interpreting the distribution of activations across all planes. It\nensures that both positive and negative signals contribute, treating the\nactivation vector as a whole. Depending on the application, several variations\nof this technique are presented, with a resolution scale hyperparameter to\nprobe different angular scales. Using this method, multiple examples are\nprovided that demonstrate embedded representations tend to be axis-aligned with\nthe privileged basis. This is not necessarily the standard basis, and it is\nfound that activation functions directly result in privileged bases. Hence, it\nprovides a direct causal link between functional form symmetry breaking and\nrepresentational alignment, explaining why representations have a tendency to\nalign with the neuron basis. Therefore, using this method, we begin to answer\nthe fundamental question of what causes the observed tendency of\nrepresentations to align with neurons. Finally, examples of so-called\ngrandmother neurons are found in a variety of networks.", "AI": {"tldr": "This paper introduces a new visualization tool to understand how deep learning models represent data, revealing that activation functions create privileged bases leading to axis-aligned representations.", "motivation": "Limited methodologies exist to understand deep learning model representations; understanding what causes representations to align with neurons is fundamental.", "method": "A novel visualization tool evaluates the distribution around planes defined by the network's privileged basis vectors, providing both atomistic and holistic metrics.", "result": "Embedded representations tend to be axis-aligned with the privileged basis, which is not the standard basis, and activation functions directly result in privileged bases.", "conclusion": "This method establishes a causal link between functional form symmetry breaking and representational alignment, answering the question about why representations align with neurons."}}
{"id": "2505.14083", "pdf": "https://arxiv.org/pdf/2505.14083", "abs": "https://arxiv.org/abs/2505.14083", "authors": ["Andrea Della Vecchia", "Arnaud Mavakala Watusadisi", "Ernesto De Vito", "Lorenzo Rosasco"], "title": "Computational Efficiency under Covariate Shift in Kernel Ridge Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper addresses the covariate shift problem in the context of\nnonparametric regression within reproducing kernel Hilbert spaces (RKHSs).\nCovariate shift arises in supervised learning when the input distributions of\nthe training and test data differ, presenting additional challenges for\nlearning. Although kernel methods have optimal statistical properties, their\nhigh computational demands in terms of time and, particularly, memory, limit\ntheir scalability to large datasets. To address this limitation, the main focus\nof this paper is to explore the trade-off between computational efficiency and\nstatistical accuracy under covariate shift. We investigate the use of random\nprojections where the hypothesis space consists of a random subspace within a\ngiven RKHS. Our results show that, even in the presence of covariate shift,\nsignificant computational savings can be achieved without compromising learning\nperformance.", "AI": {"tldr": "This paper discusses how to handle the covariate shift problem in nonparametric regression using random projections within RKHSs, balancing computational efficiency and statistical accuracy.", "motivation": "To deal with the computational limitations of kernel methods under covariate shift, which affects their scalability to large datasets.", "method": "Using random projections in the RKHS to form a hypothesis space that consists of a random subspace.", "result": "Achieving significant computational savings without reducing learning performance despite the presence of covariate shift.", "conclusion": "Random projections can effectively balance computational efficiency and statistical accuracy in nonparametric regression under covariate shift."}}
{"id": "2505.13522", "pdf": "https://arxiv.org/pdf/2505.13522", "abs": "https://arxiv.org/abs/2505.13522", "authors": ["Nathalie Sanghikian", "Rafael Meirelles", "Rafael Martinelli", "Anand Subramanian"], "title": "A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "Maritime Inventory Routing Problem (MIRP) plays a crucial role in the\nintegration of global maritime commerce levels. However, there are still no\nwell-established methodologies capable of efficiently solving large MIRP\ninstances or their variants due to the high complexity of the problem. The\nadoption of exact methods, typically based on Mixed Integer Programming (MIP),\nfor daily operations is nearly impractical due to the CPU time required, as\nplanning must be executed multiple times while ensuring high-quality results\nwithin acceptable time limits. Non-MIP-based heuristics are less frequently\napplied due to the highly constrained nature of the problem, which makes even\nthe construction of an effective initial solution challenging. Papageorgiou et\nal. (2014) introduced a single-product MIRP as the foundation for MIRPLib,\naiming to provide a collection of publicly available benchmark instances.\nHowever, only a few studies that propose new methodologies have been published\nsince then. To encourage the use of MIRPLib and facilitate result comparisons,\nthis study presents a heuristic approach that does not rely on mathematical\noptimization techniques to solve a deterministic, finite-horizon,\nsingle-product MIRP. The proposed heuristic combines a variation of a Beam\nSearch algorithm with an Iterated Local Search procedure. Among the 72\ninstances tested, the developed methodology can improve the best-known solution\nfor ten instances within an acceptable CPU time.", "AI": {"tldr": "This paper introduces a heuristic method combining Beam Search and Iterated Local Search to solve a deterministic, finite-horizon, single-product Maritime Inventory Routing Problem, improving solutions for ten instances.", "motivation": "To provide a collection of publicly available benchmark instances and encourage the use of MIRPLib.", "method": "Combining a variation of a Beam Search algorithm with an Iterated Local Search procedure.", "result": "Improved the best-known solution for ten instances among 72 tested.", "conclusion": "The proposed heuristic approach improved the best-known solutions for ten out of 72 instances within an acceptable CPU time."}}
{"id": "2505.13499", "pdf": "https://arxiv.org/pdf/2505.13499", "abs": "https://arxiv.org/abs/2505.13499", "authors": ["Kelvin Kan", "Xingjian Li", "Benjamin J. Zhang", "Tuhin Sahai", "Stanley Osher", "Markos A. Katsoulakis"], "title": "Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "We study Transformers through the perspective of optimal control theory,\nusing tools from continuous-time formulations to derive actionable insights\ninto training and architecture design. This framework improves the performance\nof existing Transformer models while providing desirable theoretical\nguarantees, including generalization and robustness. Our framework is designed\nto be plug-and-play, enabling seamless integration with established Transformer\nmodels and requiring only slight changes to the implementation. We conduct\nseven extensive experiments on tasks motivated by text generation, sentiment\nanalysis, image classification, and point cloud classification. Experimental\nresults show that the framework improves the test performance of the baselines,\nwhile being more parameter-efficient. On character-level text generation with\nnanoGPT, our framework achieves a 46% reduction in final test loss while using\n42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in\nfinal test loss, demonstrating scalability to larger models. To the best of our\nknowledge, this is the first work that applies optimal control theory to both\nthe training and architecture of Transformers. It offers a new foundation for\nsystematic, theory-driven improvements and moves beyond costly trial-and-error\napproaches.", "AI": {"tldr": "This paper applies optimal control theory to Transformer models, improving their performance and efficiency while offering theoretical guarantees.", "motivation": "To provide a theory-driven approach for improving Transformer models instead of relying on trial-and-error methods.", "method": "Using tools from continuous-time formulations within the framework of optimal control theory.", "result": "Improved test performance and parameter efficiency across various tasks compared to baseline models.", "conclusion": "This is the first application of optimal control theory to both Transformer training and architecture, offering a new foundation for systematic improvements."}}
{"id": "2505.14102", "pdf": "https://arxiv.org/pdf/2505.14102", "abs": "https://arxiv.org/abs/2505.14102", "authors": ["Shogo Iwazaki", "Junpei Komiyama", "Masaaki Imaizumi"], "title": "High-dimensional Nonparametric Contextual Bandit Problem", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "38 pages", "summary": "We consider the kernelized contextual bandit problem with a large feature\nspace. This problem involves $K$ arms, and the goal of the forecaster is to\nmaximize the cumulative rewards through learning the relationship between the\ncontexts and the rewards. It serves as a general framework for various\ndecision-making scenarios, such as personalized online advertising and\nrecommendation systems. Kernelized contextual bandits generalize the linear\ncontextual bandit problem and offers a greater modeling flexibility. Existing\nmethods, when applied to Gaussian kernels, yield a trivial bound of $O(T)$ when\nwe consider $\\Omega(\\log T)$ feature dimensions. To address this, we introduce\nstochastic assumptions on the context distribution and show that no-regret\nlearning is achievable even when the number of dimensions grows up to the\nnumber of samples. Furthermore, we analyze lenient regret, which allows a\nper-round regret of at most $\\Delta > 0$. We derive the rate of lenient regret\nin terms of $\\Delta$.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5177\u6709\u5927\u7279\u5f81\u7a7a\u95f4\u7684\u6838\u4e0a\u4e0b\u6587\u5f3a\u76d7\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u968f\u673a\u4e0a\u4e0b\u6587\u5206\u5e03\u5047\u8bbe\uff0c\u5e76\u8bc1\u660e\u5373\u4f7f\u5728\u7ef4\u5ea6\u6570\u589e\u52a0\u5230\u6837\u672c\u6570\u65f6\uff0c\u4e5f\u80fd\u5b9e\u73b0\u65e0\u6094\u5b66\u4e60\u3002\u8fd8\u5206\u6790\u4e86\u5bbd\u5bb9\u9057\u61be\uff0c\u5e76\u5f97\u51fa\u4e86\u5bbd\u5bb9\u9057\u61be\u7387\u5173\u4e8e\u0394\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u9ad8\u65af\u6838\u65f6\uff0c\u5bf9\u4e8e\u03a9(logT)\u7279\u5f81\u7ef4\u5ea6\uff0c\u7d2f\u8ba1\u9057\u61be\u754c\u4e3aO(T)\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86\u968f\u673a\u4e0a\u4e0b\u6587\u5206\u5e03\u5047\u8bbe\uff0c\u5e76\u5bf9\u5bbd\u5bb9\u9057\u61be\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u7b97\u6cd5\uff0c\u5373\u4f7f\u5728\u7279\u5f81\u7ef4\u5ea6\u589e\u52a0\u5230\u6837\u672c\u6570\u91cf\u65f6\uff0c\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u65e0\u6094\u5b66\u4e60\u3002\u5e76\u4e14\u5206\u6790\u4e86\u5bbd\u5bb9\u9057\u61be\u7387\u5173\u4e8e\u0394\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5177\u6709\u5927\u7279\u5f81\u7a7a\u95f4\u7684\u6838\u4e0a\u4e0b\u6587\u5f3a\u76d7\u95ee\u9898\uff0c\u5e76\u4e14\u5bf9\u5bbd\u5bb9\u9057\u61be\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u8fd9\u4e3a\u5728\u7ebf\u5e7f\u544a\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u51b3\u7b56\u5236\u5b9a\u573a\u666f\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2505.13529", "pdf": "https://arxiv.org/pdf/2505.13529", "abs": "https://arxiv.org/abs/2505.13529", "authors": ["Junxiao Yang", "Jinzhe Tu", "Haoran Liu", "Xiaoce Wang", "Chujie Zheng", "Zhexin Zhang", "Shiyao Cui", "Caishun Chen", "Tiantian He", "Hongning Wang", "Yew-Soon Ong", "Minlie Huang"], "title": "BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in Large Reasoning Models (LRMs) have shown impressive\ncapabilities in mathematical and logical reasoning. However, current LRMs\nrarely admit ignorance or respond with \"I don't know\". Instead, they often\nproduce incorrect answers while showing undue confidence, raising concerns\nabout their factual reliability. In this work, we identify two pathological\nreasoning patterns characterized by overthinking that contribute to the\noverconfident and incorrect answers: last-minute guessing and second-thought\nspiraling. To address these issues, we propose BARREL-a novel framework that\npromotes concise and boundary-aware factual reasoning. Our experiments show\nthat BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B\nfrom 39.33% to 61.48%, while still achieving accuracy comparable to models\nfinetuned on reasoning data generated by R1. These results demonstrate that our\npilot study is inspiring to build more reliable and factual System 2 LRMs.", "AI": {"tldr": "This paper identifies two problematic reasoning patterns in current large reasoning models and proposes a new framework called BARREL to improve their factual reliability.", "motivation": "Current large reasoning models often produce incorrect but confidently given answers, raising concerns about their factual reliability.", "method": "Proposes a novel framework called BARREL that promotes concise and boundary-aware factual reasoning.", "result": "BARREL-training improves the reliability of a specific model from 39.33% to 61.48%, while maintaining comparable accuracy to models fine-tuned on reasoning data.", "conclusion": "The proposed pilot study is promising for building more reliable and factual System 2 large reasoning models."}}
{"id": "2505.13501", "pdf": "https://arxiv.org/pdf/2505.13501", "abs": "https://arxiv.org/abs/2505.13501", "authors": ["Zequn He", "Celia Reina"], "title": "SPIEDiff: robust learning of long-time macroscopic dynamics from short-time particle simulations with quantified epistemic uncertainty", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "The data-driven discovery of long-time macroscopic dynamics and\nthermodynamics of dissipative systems with particle fidelity is hampered by\nsignificant obstacles. These include the strong time-scale limitations inherent\nto particle simulations, the non-uniqueness of the thermodynamic potentials and\noperators from given macroscopic dynamics, and the need for efficient\nuncertainty quantification. This paper introduces Statistical-Physics Informed\nEpistemic Diffusion Models (SPIEDiff), a machine learning framework designed to\novercome these limitations in the context of purely dissipative systems by\nleveraging statistical physics, conditional diffusion models, and epinets. We\nevaluate the proposed framework on stochastic Arrhenius particle processes and\ndemonstrate that SPIEDiff can accurately uncover both thermodynamics and\nkinetics, while enabling reliable long-time macroscopic predictions using only\nshort-time particle simulation data. SPIEDiff can deliver accurate predictions\nwith quantified uncertainty in minutes, drastically reducing the computational\ndemand compared to direct particle simulations, which would take days or years\nin the examples considered. Overall, SPIEDiff offers a robust and trustworthy\npathway for the data-driven discovery of thermodynamic models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPIEDiff\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8017\u6563\u7cfb\u7edf\u957f\u65f6\u95f4\u5b8f\u89c2\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u7684\u969c\u788d\u3002", "motivation": "\u514b\u670d\u7c92\u5b50\u6a21\u62df\u7684\u65f6\u95f4\u5c3a\u5ea6\u9650\u5236\uff0c\u975e\u552f\u4e00\u6027\u70ed\u529b\u5b66\u52bf\u548c\u7b97\u5b50\uff0c\u4ee5\u53ca\u9ad8\u6548\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u9700\u6c42\u3002", "method": "\u5229\u7528\u7edf\u8ba1\u7269\u7406\u3001\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548cepinets\u8bbe\u8ba1\u4e86SPIEDiff\u6846\u67b6\u3002", "result": "\u5728\u968f\u673aArrhenius\u7c92\u5b50\u8fc7\u7a0b\u4e2d\u8bc4\u4f30\uff0c\u80fd\u51c6\u786e\u63ed\u793a\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\uff0c\u5e76\u5b9e\u73b0\u53ef\u9760\u7684\u957f\u65f6\u95f4\u5b8f\u89c2\u9884\u6d4b\u3002", "conclusion": "SPIEDiff\u4e3a\u70ed\u529b\u5b66\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u4fe1\u7684\u9014\u5f84\u3002"}}
{"id": "2505.14164", "pdf": "https://arxiv.org/pdf/2505.14164", "abs": "https://arxiv.org/abs/2505.14164", "authors": ["Marcel Arpogaus", "Thomas Kneib", "Thomas Nagler", "David R\u00fcgamer"], "title": "Hybrid Bernstein Normalizing Flows for Flexible Multivariate Density Regression with Interpretable Marginals", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME"], "comment": null, "summary": "Density regression models allow a comprehensive understanding of data by\nmodeling the complete conditional probability distribution. While flexible\nestimation approaches such as normalizing flows (NF) work particularly well in\nmultiple dimensions, interpreting the input-output relationship of such models\nis often difficult, due to the black-box character of deep learning models. In\ncontrast, existing statistical methods for multivariate outcomes such as\nmultivariate conditional transformation models (MCTM) are restricted in\nflexibility and are often not expressive enough to represent complex\nmultivariate probability distributions. In this paper, we combine MCTM with\nstate-of-the-art and autoregressive NF to leverage the transparency of MCTM for\nmodeling interpretable feature effects on the marginal distributions in the\nfirst step and the flexibility of neural-network-based NF techniques to account\nfor complex and non-linear relationships in the joint data distribution. We\ndemonstrate our method's versatility in various numerical experiments and\ncompare it with MCTM and other NF models on both simulated and real-world data.", "AI": {"tldr": "\u7ed3\u5408\u591a\u5143\u6761\u4ef6\u53d8\u6362\u6a21\u578b(MCTM)\u4e0e\u5f52\u4e00\u5316\u6d41(NF)\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5bc6\u5ea6\u56de\u5f52\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u5c55\u793a\u4e86\u5176\u7075\u6d3b\u6027\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u5728\u5efa\u6a21\u590d\u6742\u591a\u53d8\u91cf\u6982\u7387\u5206\u5e03\u65f6\u4e0d\u591f\u7075\u6d3b\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5219\u96be\u4ee5\u89e3\u91ca\u3002", "method": "\u5c06MCTM\u4e0e\u81ea\u56de\u5f52NF\u7ed3\u5408\uff0c\u9996\u5148\u5229\u7528MCTM\u7684\u900f\u660e\u6027\u5efa\u6a21\u53ef\u89e3\u91ca\u7279\u5f81\u6548\u5e94\uff0c\u7136\u540e\u7528\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684NF\u6280\u672f\u5904\u7406\u8054\u5408\u6570\u636e\u5206\u5e03\u4e2d\u7684\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6570\u503c\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u4e86\u5176\u7075\u6d3b\u6027\uff0c\u5e76\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u4e0e\u5176\u4ed6\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u7ed3\u5408\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u591a\u53d8\u91cf\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2505.13533", "pdf": "https://arxiv.org/pdf/2505.13533", "abs": "https://arxiv.org/abs/2505.13533", "authors": ["Junzhe Jiang", "Chang Yang", "Aixin Cui", "Sihan Jin", "Ruiyu Wang", "Bo Li", "Xiao Huang", "Dongning Sun", "Xinrun Wang"], "title": "FinMaster: A Holistic Benchmark for Mastering Full-Pipeline Financial Workflows with LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Financial tasks are pivotal to global economic stability; however, their\nexecution faces challenges including labor intensive processes, low error\ntolerance, data fragmentation, and tool limitations. Although large language\nmodels (LLMs) have succeeded in various natural language processing tasks and\nhave shown potential in automating workflows through reasoning and contextual\nunderstanding, current benchmarks for evaluating LLMs in finance lack\nsufficient domain-specific data, have simplistic task design, and incomplete\nevaluation frameworks. To address these gaps, this article presents FinMaster,\na comprehensive financial benchmark designed to systematically assess the\ncapabilities of LLM in financial literacy, accounting, auditing, and\nconsulting. Specifically, FinMaster comprises three main modules: i) FinSim,\nwhich builds simulators that generate synthetic, privacy-compliant financial\ndata for companies to replicate market dynamics; ii) FinSuite, which provides\ntasks in core financial domains, spanning 183 tasks of various types and\ndifficulty levels; and iii) FinEval, which develops a unified interface for\nevaluation. Extensive experiments over state-of-the-art LLMs reveal critical\ncapability gaps in financial reasoning, with accuracy dropping from over 90% on\nbasic tasks to merely 40% on complex scenarios requiring multi-step reasoning.\nThis degradation exhibits the propagation of computational errors, where\nsingle-metric calculations initially demonstrating 58% accuracy decreased to\n37% in multimetric scenarios. To the best of our knowledge, FinMaster is the\nfirst benchmark that covers full-pipeline financial workflows with challenging\ntasks. We hope that FinMaster can bridge the gap between research and industry\npractitioners, driving the adoption of LLMs in real-world financial practices\nto enhance efficiency and accuracy.", "AI": {"tldr": "FinMaster\u662f\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u91d1\u878d\u57fa\u51c6\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d22\u52a1\u7d20\u517b\u3001\u4f1a\u8ba1\u3001\u5ba1\u8ba1\u548c\u54a8\u8be2\u65b9\u9762\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1aFinSim\u751f\u6210\u5408\u6210\u6570\u636e\uff0cFinSuite\u63d0\u4f9b\u591a\u6837\u5316\u4efb\u52a1\uff0cFinEval\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u63a5\u53e3\u3002\u5b9e\u9a8c\u8868\u660e\u5f53\u524dLLMs\u5728\u590d\u6742\u8d22\u52a1\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u91d1\u878d\u9886\u57dfLLMs\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u6570\u636e\u4e0d\u8db3\u3001\u4efb\u52a1\u8bbe\u8ba1\u7b80\u5355\u53ca\u8bc4\u4f30\u6846\u67b6\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFinMaster\uff0c\u5305\u62ecFinSim\uff08\u751f\u6210\u5408\u6210\u6570\u636e\uff09\u3001FinSuite\uff08\u63d0\u4f9b\u591a\u6837\u5316\u4efb\u52a1\uff09\u548cFinEval\uff08\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u63a5\u53e3\uff09\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6700\u5148\u8fdb\u7684LLMs\u5728\u590d\u6742\u8d22\u52a1\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\uff0c\u4ece\u57fa\u672c\u4efb\u52a1\u768490%\u4ee5\u4e0a\u964d\u81f3\u591a\u6b65\u9aa4\u63a8\u7406\u573a\u666f\u4e2d\u768440%\u3002", "conclusion": "FinMaster\u662f\u9996\u4e2a\u8986\u76d6\u5168\u6d41\u7a0b\u91d1\u878d\u5de5\u4f5c\u6d41\u7684\u5177\u6709\u6311\u6218\u6027\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u6709\u671b\u7f29\u5c0f\u7814\u7a76\u4e0e\u884c\u4e1a\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8LLMs\u5728\u5b9e\u9645\u91d1\u878d\u5e94\u7528\u4e2d\u7684\u91c7\u7528\u3002"}}
{"id": "2505.13502", "pdf": "https://arxiv.org/pdf/2505.13502", "abs": "https://arxiv.org/abs/2505.13502", "authors": ["Yiyuan Yang", "Guodong Long", "Qinghua Lu", "Liming Zhu", "Jing Jiang", "Chengqi Zhang"], "title": "Federated Low-Rank Adaptation for Foundation Models: A Survey", "categories": ["cs.LG"], "comment": null, "summary": "Effectively leveraging private datasets remains a significant challenge in\ndeveloping foundation models. Federated Learning (FL) has recently emerged as a\ncollaborative framework that enables multiple users to fine-tune these models\nwhile mitigating data privacy risks. Meanwhile, Low-Rank Adaptation (LoRA)\noffers a resource-efficient alternative for fine-tuning foundation models by\ndramatically reducing the number of trainable parameters. This survey examines\nhow LoRA has been integrated into federated fine-tuning for foundation models,\nan area we term FedLoRA, by focusing on three key challenges: distributed\nlearning, heterogeneity, and efficiency. We further categorize existing work\nbased on the specific methods used to address each challenge. Finally, we\ndiscuss open research questions and highlight promising directions for future\ninvestigation, outlining the next steps for advancing FedLoRA.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86LoRA\u5728\u8054\u90a6\u5b66\u4e60\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u96c6\u6210\u60c5\u51b5\uff0c\u5373FedLoRA\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u5b66\u4e60\u3001\u5f02\u6784\u6027\u548c\u6548\u7387\u8fd9\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5e76\u5206\u7c7b\u73b0\u6709\u5de5\u4f5c\u4ee5\u89e3\u51b3\u6bcf\u4e2a\u6311\u6218\u7684\u5177\u4f53\u65b9\u6cd5\u3002\u6700\u540e\u8ba8\u8bba\u4e86\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "motivation": "\u6709\u6548\u5229\u7528\u79c1\u4eba\u6570\u636e\u96c6\u5728\u5f00\u53d1\u57fa\u7840\u6a21\u578b\u65b9\u9762\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u8054\u90a6\u5b66\u4e60\u662f\u4e00\u79cd\u65b0\u5174\u7684\u5408\u4f5c\u6846\u67b6\uff0c\u53ef\u4ee5\u51cf\u8f7b\u6570\u636e\u9690\u79c1\u98ce\u9669\u7684\u540c\u65f6\u8ba9\u591a\u4e2a\u7528\u6237\u5fae\u8c03\u8fd9\u4e9b\u6a21\u578b\u3002\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u5927\u5e45\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u6765\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u3002", "method": "\u672c\u6587\u4e3b\u8981\u7814\u7a76\u4e86LoRA\u5728\u8054\u90a6\u5b66\u4e60\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u96c6\u6210\u60c5\u51b5\uff0c\u5373FedLoRA\uff0c\u91cd\u70b9\u5173\u6ce8\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u5206\u5e03\u5f0f\u5b66\u4e60\u3001\u5f02\u6784\u6027\u548c\u6548\u7387\u3002\u6839\u636e\u5177\u4f53\u65b9\u6cd5\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u4e86\u5206\u7c7b\u4ee5\u89e3\u51b3\u6bcf\u4e2a\u6311\u6218\u3002", "result": "\u672c\u6587\u7efc\u8ff0\u4e86\u73b0\u6709\u5de5\u4f5c\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u7684\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u8ba8\u8bba\u4e86FedLoRA\u7684\u4e0b\u4e00\u6b65\u53d1\u5c55\uff0c\u4ee5\u63a8\u52a8\u5176\u8fdb\u6b65\u3002"}}
{"id": "2505.14177", "pdf": "https://arxiv.org/pdf/2505.14177", "abs": "https://arxiv.org/abs/2505.14177", "authors": ["Marien Renaud", "Valentin De Bortoli", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": null, "summary": "We consider the problem of sampling distributions stemming from non-convex\npotentials with Unadjusted Langevin Algorithm (ULA). We prove the stability of\nthe discrete-time ULA to drift approximations under the assumption that the\npotential is strongly convex at infinity. In many context, e.g. imaging inverse\nproblems, potentials are non-convex and non-smooth. Proximal Stochastic\nGradient Langevin Algorithm (PSGLA) is a popular algorithm to handle such\npotentials. It combines the forward-backward optimization algorithm with a ULA\nstep. Our main stability result combined with properties of the Moreau envelope\nallows us to derive the first proof of convergence of the PSGLA for non-convex\npotentials. We empirically validate our methodology on synthetic data and in\nthe context of imaging inverse problems. In particular, we observe that PSGLA\nexhibits faster convergence rates than Stochastic Gradient Langevin Algorithm\nfor posterior sampling while preserving its restoration properties.", "AI": {"tldr": "This paper proves the stability of the Unadjusted Langevin Algorithm (ULA) for non-convex potentials and derives the first proof of convergence of the Proximal Stochastic Gradient Langevin Algorithm (PSGLA) for such potentials.", "motivation": "To address the problem of sampling distributions from non-convex potentials using the Unadjusted Langevin Algorithm (ULA) and Proximal Stochastic Gradient Langevin Algorithm (PSGLA).", "method": "Prove the stability of the discrete-time ULA under certain assumptions and combine it with properties of the Moreau envelope to establish the convergence of PSGLA.", "result": "The paper proves the stability of ULA and derives the first proof of convergence of PSGLA for non-convex potentials. Empirical validation shows that PSGLA converges faster than Stochastic Gradient Langevin Algorithm while maintaining restoration properties.", "conclusion": "This work provides theoretical guarantees for the use of PSGLA in non-convex potential sampling problems, which has applications in imaging inverse problems."}}
{"id": "2505.13546", "pdf": "https://arxiv.org/pdf/2505.13546", "abs": "https://arxiv.org/abs/2505.13546", "authors": ["Ke Chen", "Yufei Zhou", "Xitong Zhang", "Haohan Wang"], "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u81ea\u52a8\u63d0\u793a\u751f\u6210\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u91cf\u5316\u63d0\u793a\u7684\u8bed\u4e49\u7a33\u5b9a\u6027\u6765\u63d0\u9ad8\u63d0\u793a\u8d28\u91cf\u548c\u7cfb\u7edf\u7ea7\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8f93\u51fa\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u63d0\u793a\u751f\u6210\u65b9\u6cd5\u53ea\u5173\u6ce8\u5373\u65f6\u4efb\u52a1\u8868\u73b0\uff0c\u5ffd\u89c6\u4e86\u51b3\u5b9a\u5176\u53ef\u9760\u6027\u7684\u5185\u5728\u54c1\u8d28\uff0c\u4e14\u672a\u80fd\u8003\u8651\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u56fa\u6709\u968f\u673a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u8bed\u4e49\u7a33\u5b9a\u6027\u4f5c\u4e3a\u8bc4\u4f30\u63d0\u793a\u54cd\u5e94\u4e00\u81f4\u6027\u7684\u6807\u51c6\uff0c\u5e76\u5fae\u8c03\u4e86\u4e00\u4e2a\u57fa\u4e8eLLaMA\u7684\u8bc4\u4f30\u5668\u6765\u81ea\u52a8\u6d4b\u91cf\u5b83\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5f00\u53d1\u4e86\u9996\u4e2a\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u901a\u7528\u63d0\u793a\u751f\u6210\u7cfb\u7edf\uff0c\u5229\u7528\u7a33\u5b9a\u6027\u53cd\u9988\u8fed\u4ee3\u63d0\u5347\u63d0\u793a\u8d28\u91cf\u548c\u7cfb\u7edf\u7ea7\u6027\u80fd\u3002", "result": "\u5728\u901a\u7528\u548c\u7279\u5b9a\u9886\u57df\u7684\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u7a33\u5b9a\u6027\u611f\u77e5\u6846\u67b6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8f93\u51fa\u4e00\u81f4\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u4ece\u4e00\u6b21\u6027\u7ed3\u679c\u8f6c\u5411\u6301\u4e45\u53ef\u9760\u6027\uff0c\u4e3a\u63d0\u793a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u901a\u7528\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2505.13507", "pdf": "https://arxiv.org/pdf/2505.13507", "abs": "https://arxiv.org/abs/2505.13507", "authors": ["Haoyang Chen"], "title": "Open Set Domain Adaptation with Vision-language models via Gradient-aware Separation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Open-Set Domain Adaptation (OSDA) confronts the dual challenge of aligning\nknown-class distributions across domains while identifying\ntarget-domain-specific unknown categories. Current approaches often fail to\nleverage semantic relationships between modalities and struggle with error\naccumulation in unknown sample detection. We propose to harness Contrastive\nLanguage-Image Pretraining (CLIP) to address these limitations through two key\ninnovations: 1) Prompt-driven cross-domain alignment: Learnable textual prompts\nconditioned on domain discrepancy metrics dynamically adapt CLIP's text\nencoder, enabling semantic consistency between source and target domains\nwithout explicit unknown-class supervision. 2) Gradient-aware open-set\nseparation: A gradient analysis module quantifies domain shift by comparing the\nL2-norm of gradients from the learned prompts, where known/unknown samples\nexhibit statistically distinct gradient behaviors. Evaluations on Office-Home\nshow that our method consistently outperforms CLIP baseline and standard\nbaseline. Ablation studies confirm the gradient norm's critical role.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528CLIP\u89e3\u51b3\u5f00\u653e\u96c6\u9886\u57df\u81ea\u9002\u5e94\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u793a\u9a71\u52a8\u8de8\u57df\u5bf9\u9f50\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u5f00\u653e\u96c6\u5206\u79bb\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u6a21\u6001\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u548c\u672a\u77e5\u6837\u672c\u68c0\u6d4b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u521b\u65b0\u70b9\uff1a1) \u63d0\u793a\u9a71\u52a8\u7684\u8de8\u57df\u5bf9\u9f50\uff1b2) \u57fa\u4e8e\u68af\u5ea6\u7684\u5f00\u653e\u96c6\u5206\u79bb\u6765\u6539\u8fdb\u5f00\u653e\u96c6\u9886\u57df\u81ea\u9002\u5e94\u3002", "result": "\u5728Office-Home\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8eCLIP\u57fa\u7ebf\u548c\u6807\u51c6\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u89e3\u51b3\u5f00\u653e\u96c6\u9886\u57df\u81ea\u9002\u5e94\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u68af\u5ea6\u8303\u6570\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2505.14421", "pdf": "https://arxiv.org/pdf/2505.14421", "abs": "https://arxiv.org/abs/2505.14421", "authors": ["Zuogong Yue", "Xinyi Wang", "Victor Solo"], "title": "A system identification approach to clustering vector autoregressive time series", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "Clustering of time series based on their underlying dynamics is keeping\nattracting researchers due to its impacts on assisting complex system\nmodelling. Most current time series clustering methods handle only scalar time\nseries, treat them as white noise, or rely on domain knowledge for high-quality\nfeature construction, where the autocorrelation pattern/feature is mostly\nignored. Instead of relying on heuristic feature/metric construction, the\nsystem identification approach allows treating vector time series clustering by\nexplicitly considering their underlying autoregressive dynamics. We first\nderive a clustering algorithm based on a mixture autoregressive model.\nUnfortunately it turns out to have significant computational problems. We then\nderive a `small-noise' limiting version of the algorithm, which we call k-LMVAR\n(Limiting Mixture Vector AutoRegression), that is computationally manageable.\nWe develop an associated BIC criterion for choosing the number of clusters and\nmodel order. The algorithm performs very well in comparative simulations and\nalso scales well computationally.", "AI": {"tldr": "This paper presents a new clustering algorithm called k-LMVAR for vector time series based on system identification approach, which performs well in simulations and scales computationally.", "motivation": "To address the limitations of existing time series clustering methods that ignore autocorrelation patterns and rely on heuristics or domain knowledge.", "method": "Deriving a clustering algorithm based on a mixture autoregressive model and developing a 'small-noise' limiting version called k-LMVAR.", "result": "The algorithm performs well in comparative simulations and scales computationally.", "conclusion": "The proposed k-LMVAR algorithm provides a new approach for clustering vector time series based on their underlying autoregressive dynamics."}}
{"id": "2505.13551", "pdf": "https://arxiv.org/pdf/2505.13551", "abs": "https://arxiv.org/abs/2505.13551", "authors": ["Serge Dolgikh"], "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems", "categories": ["cs.AI", "cs.NE", "cs.SI", "68T27, 94A15", "F.2.2; I.2.6"], "comment": "23 pages, 3 figures", "summary": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u81ea\u7136\u548c\u4eba\u5de5\u8ba4\u77e5\u7cfb\u7edf\u4e2d\u53cd\u63a8\u7406\u884c\u4e3a\u7684\u51fa\u73b0\uff0c\u5373\u4ee3\u7406\u9519\u8bef\u5f52\u56e0\u7ecf\u9a8c\u6210\u529f\u6216\u6291\u5236\u9002\u5e94\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u5bfc\u81f4\u8ba4\u8bc6\u8bba\u50f5\u5316\u6216\u9002\u5e94\u4e0d\u826f\u7684\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u4e0d\u5e73\u8861\u5956\u52b1\u3001\u5143\u8ba4\u77e5\u5f52\u56e0\u548c\u611f\u77e5\u6a21\u578b\u8106\u5f31\u6027\u4e0b\u7684\u4fdd\u62a4\u6027\u91cd\u6784\u7b49\u5178\u578b\u573a\u666f\u5206\u6790\uff0c\u53d1\u73b0\u8fd9\u4e9b\u884c\u4e3a\u901a\u8fc7\u5185\u90e8\u4fe1\u606f\u6a21\u578b\u3001\u5b9e\u8bc1\u53cd\u9988\u548c\u9ad8\u9636\u8bc4\u4f30\u673a\u5236\u7684\u7ed3\u6784\u5316\u4ea4\u4e92\u800c\u4ea7\u751f\u3002\u7814\u7a76\u8bc6\u522b\u51fa\u53cd\u63a8\u7406\u884c\u4e3a\u4f5c\u4e3a\u4e00\u79cd\u666e\u904d\u7684\u8ba4\u77e5\u8106\u5f31\u6027\uff0c\u5373\u4f7f\u5728\u5176\u4ed6\u65b9\u9762\u9002\u5e94\u826f\u597d\u7684\u7cfb\u7edf\u4e2d\u4e5f\u53ef\u80fd\u8868\u73b0\u51fa\u6765\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u7a33\u5b9a\u6761\u4ef6\u4e0b\u4fdd\u6301\u6700\u5c0f\u9002\u5e94\u6fc0\u6d3b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6297\u4fe1\u606f\u538b\u529b\u521a\u6027\u7684\u8ba4\u77e5\u67b6\u6784\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u7406\u89e3\u81ea\u7136\u548c\u4eba\u5de5\u8ba4\u77e5\u7cfb\u7edf\u4e2d\u53cd\u63a8\u7406\u884c\u4e3a\u7684\u51fa\u73b0\u53ca\u5176\u5bf9\u8ba4\u8bc6\u8bba\u50f5\u5316\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e0d\u5e73\u8861\u5956\u52b1\u3001\u5143\u8ba4\u77e5\u5f52\u56e0\u548c\u611f\u77e5\u6a21\u578b\u8106\u5f31\u6027\u4e0b\u7684\u4fdd\u62a4\u6027\u91cd\u6784\u7b49\u5178\u578b\u573a\u666f\uff0c\u63a2\u8ba8\u5185\u90e8\u4fe1\u606f\u6a21\u578b\u3001\u5b9e\u8bc1\u53cd\u9988\u548c\u9ad8\u9636\u8bc4\u4f30\u673a\u5236\u4e4b\u95f4\u7684\u7ed3\u6784\u5316\u4ea4\u4e92\u3002", "result": "\u53d1\u73b0\u53cd\u63a8\u7406\u884c\u4e3a\u662f\u4e00\u79cd\u666e\u904d\u7684\u8ba4\u77e5\u8106\u5f31\u6027\uff0c\u5373\u4f7f\u5728\u5176\u4ed6\u65b9\u9762\u9002\u5e94\u826f\u597d\u7684\u7cfb\u7edf\u4e2d\u4e5f\u53ef\u80fd\u8868\u73b0\u51fa\u6765\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5728\u7a33\u5b9a\u6761\u4ef6\u4e0b\u4fdd\u6301\u6700\u5c0f\u9002\u5e94\u6fc0\u6d3b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6297\u4fe1\u606f\u538b\u529b\u521a\u6027\u7684\u8ba4\u77e5\u67b6\u6784\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2505.13510", "pdf": "https://arxiv.org/pdf/2505.13510", "abs": "https://arxiv.org/abs/2505.13510", "authors": ["Conor Rowan", "Alireza Doostan"], "title": "On the definition and importance of interpretability in scientific machine learning", "categories": ["cs.LG", "physics.data-an", "physics.hist-ph", "physics.soc-ph"], "comment": null, "summary": "Though neural networks trained on large data sets have been successfully used\nto describe and predict many physical phenomena, there is a sense among\nscientists that, unlike traditional scientific models, where relationships come\npackaged in the form of simple mathematical expressions, the findings of the\nneural network cannot be integrated into the body of scientific knowledge.\nCritics of ML's inability to produce human-understandable relationships have\nconverged on the concept of \"interpretability\" as its point of departure from\nmore traditional forms of science. As the growing interest in interpretability\nhas shown, researchers in the physical sciences seek not just predictive\nmodels, but also to uncover the fundamental principles that govern a system of\ninterest. However, clarity around a definition of interpretability and the\nprecise role that it plays in science is lacking in the literature. In this\nwork, we argue that researchers in equation discovery and symbolic regression\ntend to conflate the concept of sparsity with interpretability. We review key\npapers on interpretable ML from outside the scientific community and argue\nthat, though the definitions and methods they propose can inform questions of\ninterpretability for SciML, they are inadequate for this new purpose. Noting\nthese deficiencies, we propose an operational definition of interpretability\nfor the physical sciences. Our notion of interpretability emphasizes\nunderstanding of the mechanism over mathematical sparsity. Innocuous though it\nmay seem, this emphasis on mechanism shows that sparsity is often unnecessary.\nIt also questions the possibility of interpretable scientific discovery when\nprior knowledge is lacking. We believe a precise and philosophically informed\ndefinition of interpretability in SciML will help focus research efforts toward\nthe most significant obstacles to realizing a data-driven scientific future.", "AI": {"tldr": "This paper discusses the concept of interpretability in scientific machine learning (SciML), arguing that the current conflations of sparsity and interpretability are inadequate. It proposes an operational definition of interpretability focused on understanding mechanisms rather than mathematical sparsity.", "motivation": "To address the lack of clarity around the definition and role of interpretability in SciML, which hinders uncovering fundamental principles in physical sciences.", "method": "Reviewing key papers on interpretable ML from non-scientific communities and proposing an operational definition of interpretability focusing on mechanism understanding.", "result": "Proposes a new definition of interpretability emphasizing mechanism understanding over mathematical sparsity, suggesting that sparsity is often unnecessary and questioning the possibility of interpretable scientific discovery without prior knowledge.", "conclusion": "A precise and philosophically informed definition of interpretability in SciML will help direct research efforts towards overcoming obstacles to achieving a data-driven scientific future."}}
{"id": "2505.14529", "pdf": "https://arxiv.org/pdf/2505.14529", "abs": "https://arxiv.org/abs/2505.14529", "authors": ["Christian Gouri\u00e9roux", "Yang Lu"], "title": "A simple estimator of the correlation kernel matrix of a determinantal point process", "categories": ["stat.ML", "cs.LG", "62G30"], "comment": null, "summary": "The Determinantal Point Process (DPP) is a parameterized model for\nmultivariate binary variables, characterized by a correlation kernel matrix.\nThis paper proposes a closed form estimator of this kernel, which is\nparticularly easy to implement and can also be used as a starting value of\nlearning algorithms for maximum likelihood estimation. We prove the consistency\nand asymptotic normality of our estimator, as well as its large deviation\nproperties.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u6838\u77e9\u9635\u7684\u95ed\u5f0f\u4f30\u8ba1\u5668\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u4e00\u81f4\u6027\u3001\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u5927\u504f\u5dee\u6027\u8d28\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u6613\u4e8e\u5b9e\u73b0\u7684\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u6838\u77e9\u9635\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u6838\u77e9\u9635\u7684\u95ed\u5f0f\u4f30\u8ba1\u5668\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u7684\u4e00\u81f4\u6027\u3001\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u5927\u504f\u5dee\u6027\u8d28\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u6838\u77e9\u9635\u4f30\u8ba1\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5b66\u4e60\u7b97\u6cd5\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u3002"}}
{"id": "2505.13561", "pdf": "https://arxiv.org/pdf/2505.13561", "abs": "https://arxiv.org/abs/2505.13561", "authors": ["Daniel Rothschild"], "title": "Language and Thought: The View from LLMs", "categories": ["cs.AI"], "comment": "37 Pages", "summary": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds.", "AI": {"tldr": "This paper discusses how the success of Large Language Models (LLMs) in inferential reasoning supports Daniel Dennett's thesis that language significantly impacts thought processes.", "motivation": "To explore Dennett's thesis regarding the transformative effect of language on cognition by analyzing the capabilities of AI systems.", "method": "Examining the performance of AI systems with and without linguistic training to test Dennett's hypothesis.", "result": "The success of LLMs in inferential reasoning, albeit limited, suggests that language enhances cognitive abilities by making inference computationally feasible.", "conclusion": "AI findings suggest that language plays a crucial role in human cognition, similar to its impact on AI systems."}}
{"id": "2505.13515", "pdf": "https://arxiv.org/pdf/2505.13515", "abs": "https://arxiv.org/abs/2505.13515", "authors": ["Yanan Li", "Fanxu Meng", "Muhan Zhang", "Shiai Zhu", "Shangguang Wang", "Mengwei Xu"], "title": "LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are frequently updated, LoRA weights trained\non earlier versions quickly become obsolete. The conventional practice of\nretraining LoRA weights from scratch on the latest model is costly,\ntime-consuming, and environmentally detrimental, particularly as the diversity\nof LLMs and downstream tasks expands. This motivates a critical question: \"How\ncan we efficiently leverage existing LoRA weights to adapt to newer model\nversions?\" To address this, we propose LoRASuite, a modular approach tailored\nspecifically to various types of LLM updates. First, we compute a transfer\nmatrix utilizing known parameters from both old and new LLMs. Next, we allocate\ncorresponding layers and attention heads based on centered kernel alignment and\ncosine similarity metrics, respectively. A subsequent small-scale, skillful\nfine-tuning step ensures numerical stability. Experimental evaluations\ndemonstrate that LoRASuite consistently surpasses small-scale vanilla LoRA\nmethods. Notably, on backbone LLMs such as MiniCPM and Qwen, LoRASuite even\nexceeds the performance of full-scale LoRA retraining, with average\nimprovements of +1.4 and +6.6 points on math tasks, respectively. Additionally,\nLoRASuite significantly reduces memory consumption by 5.5 GB and computational\ntime by 78.23%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLoRASuite\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u5229\u7528\u73b0\u6709\u7684LoRA\u6743\u91cd\u6765\u9002\u5e94\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u7248\u672c\uff0c\u800c\u4e0d\u9700\u8981\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\uff0c\u4ece\u800c\u8282\u7701\u65f6\u95f4\u548c\u8d44\u6e90\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLoRASuite\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684LoRA\u65b9\u6cd5\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9891\u7e41\u66f4\u65b0\uff0c\u4e4b\u524d\u7248\u672c\u4e0a\u8bad\u7ec3\u7684LoRA\u6743\u91cd\u8fc5\u901f\u8fc7\u65f6\uff0c\u800c\u4ece\u5934\u5f00\u59cb\u5728\u6700\u65b0\u6a21\u578b\u4e0a\u91cd\u65b0\u8bad\u7ec3LoRA\u6743\u91cd\u65e2\u6602\u8d35\u53c8\u8017\u65f6\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u65e7\u6a21\u578b\u548c\u65b0\u6a21\u578b\u4e4b\u95f4\u7684\u8f6c\u79fb\u77e9\u9635\uff0c\u5e76\u6839\u636e\u4e2d\u5fc3\u6838\u5bf9\u9f50\u548c\u4f59\u5f26\u76f8\u4f3c\u6027\u5ea6\u91cf\u5206\u914d\u76f8\u5e94\u7684\u5c42\u548c\u6ce8\u610f\u529b\u5934\uff0c\u7136\u540e\u8fdb\u884c\u5c0f\u89c4\u6a21\u7684\u7cbe\u7ec6\u8c03\u6574\u6b65\u9aa4\u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\u3002", "result": "LoRASuite\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684LoRA\u65b9\u6cd5\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "LoRASuite\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9002\u5e94\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u7248\u672c\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u65f6\u95f4\u548c\u8d44\u6e90\u7684\u6d6a\u8d39\u3002"}}
{"id": "2505.14587", "pdf": "https://arxiv.org/pdf/2505.14587", "abs": "https://arxiv.org/abs/2505.14587", "authors": ["Hamza Cherkaoui", "Malik Tiomoko", "Mohamed El Amine Seddik", "Cosme Louart", "Ekkehard Schnoor", "Balazs Kegl"], "title": "High-Dimensional Analysis of Bootstrap Ensemble Classifiers", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bootstrap methods have long been a cornerstone of ensemble learning in\nmachine learning. This paper presents a theoretical analysis of bootstrap\ntechniques applied to the Least Square Support Vector Machine (LSSVM) ensemble\nin the context of large and growing sample sizes and feature dimensionalities.\nLeveraging tools from Random Matrix Theory, we investigate the performance of\nthis classifier that aggregates decision functions from multiple weak\nclassifiers, each trained on different subsets of the data. We provide insights\ninto the use of bootstrap methods in high-dimensional settings, enhancing our\nunderstanding of their impact. Based on these findings, we propose strategies\nto select the number of subsets and the regularization parameter that maximize\nthe performance of the LSSVM. Empirical experiments on synthetic and real-world\ndatasets validate our theoretical results.", "AI": {"tldr": "This paper theoretically analyzes bootstrap techniques for LSSVM ensembles, offering insights into high-dimensional settings and proposing strategies to optimize performance.", "motivation": "To understand the impact of bootstrap methods in high-dimensional settings and improve the performance of LSSVM ensembles.", "method": "Theoretical analysis using tools from Random Matrix Theory and empirical experiments on synthetic and real-world datasets.", "result": "Insights into the use of bootstrap methods in high-dimensional settings and proposed strategies for optimizing the number of subsets and regularization parameter.", "conclusion": "The study enhances understanding of bootstrap methods' impact and provides practical strategies to maximize LSSVM performance."}}
{"id": "2505.13668", "pdf": "https://arxiv.org/pdf/2505.13668", "abs": "https://arxiv.org/abs/2505.13668", "authors": ["Mahmood Hegazy", "Aaron Rodrigues", "Azzam Naeem"], "title": "MAFA: A multi-agent framework for annotation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7528\u4e8eFAQ\u6807\u6ce8\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u79cd\u5177\u6709\u4e0d\u540c\u65b9\u6cd5\u7684\u4e13\u7528\u667a\u80fd\u4f53\u548c\u4e00\u4e2a\u91cd\u65b0\u6392\u540d\u5019\u9009\u8005\u7684\u88c1\u5224\u667a\u80fd\u4f53\u4ee5\u4ea7\u751f\u6700\u4f73\u7ed3\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u5747\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5e76\u4e14\u7279\u522b\u64c5\u957f\u5904\u7406\u6a21\u7cca\u67e5\u8be2\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6355\u6349\u5230\u7528\u6237\u8be2\u95ee\u4e2d\u7684\u7ec6\u5fae\u5dee\u522b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u4fe1\u606f\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u65b9\u6cd5\u7684\u4e13\u7528\u667a\u80fd\u4f53\u548c\u4e00\u4e2a\u88c1\u5224\u667a\u80fd\u4f53\uff0c\u5229\u7528\u7ed3\u6784\u5316\u63a8\u7406\u65b9\u6cd5\u5e76\u91c7\u7528\u5c11\u91cf\u793a\u4f8b\u7b56\u7565\u589e\u5f3a\u591a\u6837\u6027\u3002", "result": "\u5728\u771f\u5b9e\u94f6\u884c\u6570\u636e\u96c6\u548c\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793aTop-1\u51c6\u786e\u7387\u63d0\u9ad8\u4e8614\uff05\uff0cTop-5\u51c6\u786e\u7387\u63d0\u9ad8\u4e8618\uff05\uff0cMean Reciprocal Rank\u63d0\u5347\u4e8612\uff05\uff0c\u5e76\u4e14\u5728\u5904\u7406\u6a21\u7cca\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u6a21\u7cca\u67e5\u8be2\uff0c\u9002\u5408\u90e8\u7f72\u5728\u751f\u4ea7\u5e94\u7528\u4e2d\uff0c\u5e76\u663e\u793a\u51fa\u8de8\u4e0d\u540c\u9886\u57df\u548c\u8bed\u8a00\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2505.13521", "pdf": "https://arxiv.org/pdf/2505.13521", "abs": "https://arxiv.org/abs/2505.13521", "authors": ["Gabor Petnehazi", "Laith Al Shaggah", "Jozsef Gall", "Bernadett Aradi"], "title": "Zero-Shot Forecasting Mortality Rates: A Global Study", "categories": ["cs.LG", "q-fin.RM", "stat.AP"], "comment": null, "summary": "This study explores the potential of zero-shot time series forecasting, an\ninnovative approach leveraging pre-trained foundation models, to forecast\nmortality rates without task-specific fine-tuning. We evaluate two\nstate-of-the-art foundation models, TimesFM and CHRONOS, alongside traditional\nand machine learning-based methods across three forecasting horizons (5, 10,\nand 20 years) using data from 50 countries and 111 age groups. In our\ninvestigations, zero-shot models showed varying results: while CHRONOS\ndelivered competitive shorter-term forecasts, outperforming traditional methods\nlike ARIMA and the Lee-Carter model, TimesFM consistently underperformed.\nFine-tuning CHRONOS on mortality data significantly improved long-term\naccuracy. A Random Forest model, trained on mortality data, achieved the best\noverall performance. These findings underscore the potential of zero-shot\nforecasting while highlighting the need for careful model selection and\ndomain-specific adaptation.", "AI": {"tldr": "This study examines zero-shot time series forecasting using pre-trained foundation models for mortality rate prediction, comparing TimesFM, CHRONOS with traditional methods. While CHRONOS performed well in short-term forecasts, TimesFM underperformed. Fine-tuning CHRONOS improved its accuracy. The Random Forest model had the best overall performance.", "motivation": "To explore the potential of zero-shot time series forecasting for mortality rate prediction without task-specific fine-tuning.", "method": "Evaluated two state-of-the-art foundation models (TimesFM and CHRONOS) alongside traditional and machine learning-based methods across three forecasting horizons using data from 50 countries and 111 age groups.", "result": "Zero-shot models showed varying results; CHRONOS delivered competitive shorter-term forecasts but underperformed in long-term forecasts. TimesFM consistently underperformed. Fine-tuning CHRONOS improved long-term accuracy. Random Forest model achieved the best overall performance.", "conclusion": "Zero-shot forecasting has potential but requires careful model selection and domain-specific adaptation."}}
{"id": "2505.13672", "pdf": "https://arxiv.org/pdf/2505.13672", "abs": "https://arxiv.org/abs/2505.13672", "authors": ["Giannis Chatziveroglou"], "title": "A*-Decoding: Token-Efficient Inference Scaling", "categories": ["cs.AI"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment.", "AI": {"tldr": "A*-decoding is introduced as a search-based inference-time strategy that improves language model performance on complex reasoning tasks by optimally utilizing a fixed compute budget.", "motivation": "Existing methods for inference-time scaling show performance gains but do not optimally utilize the compute budget.", "method": "A*-decoding uses the A* search algorithm to prioritize high-quality reasoning paths during language model generation.", "result": "A*-decoding achieves comparable performance to baselines with fewer tokens and PRM passes, matching the performance of larger models on specific benchmarks.", "conclusion": "Structured search in decoding offers an alternative to brute-force sampling or scale-driven gains, enhancing reasoning in SLMs."}}
{"id": "2505.13544", "pdf": "https://arxiv.org/pdf/2505.13544", "abs": "https://arxiv.org/abs/2505.13544", "authors": ["Keqi Deng", "Philip C. Woodland"], "title": "Multi-head Temporal Latent Attention", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality.", "AI": {"tldr": "This paper introduces Multi-head Temporal Latent Attention (MTLA), which reduces the size of the Key-Value (KV) cache used in Transformer self-attention along the temporal dimension, significantly decreasing memory usage during inference. MTLA uses a hyper-network to merge KV cache vectors and a stride-aware causal mask to maintain consistent training and inference behavior. Experiments show that MTLA improves inference speed by up to 5.3x and reduces GPU memory usage by 8.3x compared to standard Multi-Head Attention (MHA) without sacrificing performance.", "motivation": "To reduce the memory footprint of self-attention inference by compressing the KV cache.", "method": "Proposes Multi-head Temporal Latent Attention (MTLA) that merges temporally adjacent KV cache vectors using a hyper-network and uses a stride-aware causal mask to align training and inference.", "result": "Achieves competitive performance to standard MHA while greatly improving inference speed and reducing GPU memory usage across various tasks such as speech translation, speech recognition, speech understanding, and text summarization.", "conclusion": "MTLA can significantly decrease memory usage during inference without affecting performance, offering substantial improvements in speed and resource efficiency."}}
{"id": "2505.13564", "pdf": "https://arxiv.org/pdf/2505.13564", "abs": "https://arxiv.org/abs/2505.13564", "authors": ["Aymeric Capitaine", "Maxime Haddouche", "Eric Moulines", "Michael I. Jordan", "Etienne Boursier", "Alain Durmus"], "title": "Online Decision-Focused Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Decision-focused learning (DFL) is an increasingly popular paradigm for\ntraining predictive models whose outputs are used in decision-making tasks.\nInstead of merely optimizing for predictive accuracy, DFL trains models to\ndirectly minimize the loss associated with downstream decisions. This\nend-to-end strategy holds promise for tackling complex combinatorial problems;\nhowever, existing studies focus solely on scenarios where a fixed batch of data\nis available and the objective function does not change over time. We instead\ninvestigate DFL in dynamic environments where the objective function and data\ndistribution evolve over time. This setting is challenging because the\nobjective function has zero or undefined gradients -- which prevents the use of\nstandard first-order optimization methods -- and is generally non-convex. To\naddress these difficulties, we (i) regularize the objective to make it\ndifferentiable and (ii) make use of the optimism principle, based on a\nnear-optimal oracle along with an appropriate perturbation. This leads to a\npractical online algorithm for which we establish bounds on the expected\ndynamic regret, both when the decision space is a simplex and when it is a\ngeneral bounded convex polytope. Finally, we demonstrate the effectiveness of\nour algorithm by comparing its performance with a classic prediction-focused\napproach on a simple knapsack experiment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u7b97\u6cd5\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f18\u5316\u51b3\u7b56\u805a\u7126\u5b66\u4e60\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u4f20\u7edf\u9884\u6d4b\u805a\u7126\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u7814\u7a76\u4ec5\u9650\u4e8e\u9759\u6001\u73af\u5883\uff0c\u800c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u52a8\u6001\u73af\u5883\u4e0b\u76ee\u6807\u51fd\u6570\u548c\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u5728\u7ebf\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u6b63\u5219\u5316\u76ee\u6807\u51fd\u6570\u4f7f\u5176\u53ef\u5fae\uff0c\u5e76\u5229\u7528\u4e50\u89c2\u539f\u5219\u4ee5\u53ca\u8fd1\u4f3c\u6700\u4f18oracle\u548c\u9002\u5f53\u6270\u52a8\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u52a8\u6001\u540e\u6094\u65b9\u9762\u5efa\u7acb\u4e86\u754c\u9650\uff0c\u5e76\u5728\u7b80\u5355\u80cc\u5305\u95ee\u9898\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u6bd4\u7ecf\u5178\u9884\u6d4b\u805a\u7126\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6709\u6548\u5730\u5904\u7406\u4e86\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u9a8c\u4e0a\u90fd\u663e\u793a\u51fa\u4f18\u4e8e\u7ecf\u5178\u9884\u6d4b\u805a\u7126\u65b9\u6cd5\u7684\u8868\u73b0\u3002"}}
{"id": "2505.13696", "pdf": "https://arxiv.org/pdf/2505.13696", "abs": "https://arxiv.org/abs/2505.13696", "authors": ["Zizhan He", "Maxime Daigle", "Pouya Bashivan"], "title": "Building spatial world models from sparse transitional episodic memories", "categories": ["cs.AI"], "comment": null, "summary": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training.", "AI": {"tldr": "This paper proposes a novel framework called Episodic Spatial World Model (ESWM) that enables a neural network to construct a spatial model of its surroundings using sparse and disjoint episodic memories.", "motivation": "To investigate whether a neural network can learn to construct a spatial model of its surroundings from sparse and disjoint episodic memories.", "method": "Formulating the problem in a simulated world and proposing the ESWM framework.", "result": "ESWM is highly sample-efficient and inherently adaptive, allowing for rapid updates when the environment changes. It also enables near-optimal strategies for exploring novel environments and navigating between arbitrary points.", "conclusion": "The proposed ESWM framework demonstrates the potential of using sparse episodic memories to construct robust spatial models in neural networks."}}
{"id": "2505.13547", "pdf": "https://arxiv.org/pdf/2505.13547", "abs": "https://arxiv.org/abs/2505.13547", "authors": ["Pengxin Guo", "Yinong Wang", "Wei Li", "Mengting Liu", "Ming Li", "Jinkai Zheng", "Liangqiong Qu"], "title": "Exploring Federated Pruning for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedPrLLM\u7684\u8054\u90a6\u4fee\u526a\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u65e0\u9700\u8bbf\u95ee\u516c\u5171\u6821\u51c6\u6837\u672c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e00\u6b21\u6027\u5c42\u95f4\u6bd4\u8f83\u4fee\u526a\u4e14\u4e0d\u7f29\u653e\u6743\u91cd\u662f\u6700\u4f18\u9009\u62e9\u3002", "motivation": "\u5f53\u524dLLM\u4fee\u526a\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8bbf\u95ee\u516c\u5171\u6821\u51c6\u6837\u672c\uff0c\u5728\u9690\u79c1\u654f\u611f\u9886\u57df\u96be\u4ee5\u83b7\u5f97\u8fd9\u4e9b\u6837\u672c\u3002", "method": "FedPrLLM\u6846\u67b6\u5141\u8bb8\u6bcf\u4e2a\u5ba2\u6237\u7aef\u57fa\u4e8e\u672c\u5730\u6821\u51c6\u6570\u636e\u8ba1\u7b97\u4fee\u526a\u63a9\u7801\u77e9\u9635\u5e76\u5171\u4eab\u7ed9\u670d\u52a1\u5668\u4ee5\u4fee\u526a\u5168\u5c40\u6a21\u578b\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u672c\u5730\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u534f\u4f5c\u4fee\u526a\u3002", "result": "\u5b9e\u9a8c\u63a2\u7d22\u4e86FedPrLLM\u6846\u67b6\u5185\u7684\u591a\u79cd\u53ef\u80fd\u6027\uff0c\u5e76\u53d1\u73b0\u4e00\u6b21\u6027\u5c42\u95f4\u6bd4\u8f83\u4fee\u526a\u4e14\u4e0d\u7f29\u653e\u6743\u91cd\u662f\u6700\u4f18\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u5e0c\u671b\u4e3a\u9690\u79c1\u654f\u611f\u9886\u57df\u7684LLM\u4fee\u526a\u5de5\u4f5c\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ee3\u7801\u94fe\u63a5\u3002"}}
{"id": "2505.13586", "pdf": "https://arxiv.org/pdf/2505.13586", "abs": "https://arxiv.org/abs/2505.13586", "authors": ["Pavel Rumiantsev", "Mark Coates"], "title": "Half Search Space is All You Need", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neural Architecture Search (NAS) is a powerful tool for automating\narchitecture design. One-Shot NAS techniques, such as DARTS, have gained\nsubstantial popularity due to their combination of search efficiency with\nsimplicity of implementation. By design, One-Shot methods have high GPU memory\nrequirements during the search. To mitigate this issue, we propose to prune the\nsearch space in an efficient automatic manner to reduce memory consumption and\nsearch time while preserving the search accuracy. Specifically, we utilise\nZero-Shot NAS to efficiently remove low-performing architectures from the\nsearch space before applying One-Shot NAS to the pruned search space.\nExperimental results on the DARTS search space show that our approach reduces\nmemory consumption by 81% compared to the baseline One-Shot setup while\nachieving the same level of accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408Zero-Shot NAS\u4e0eOne-Shot NAS\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11DARTS\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u5185\u5b58\u6d88\u8017\u548c\u641c\u7d22\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u641c\u7d22\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3One-Shot NAS\u65b9\u6cd5\u5728\u641c\u7d22\u8fc7\u7a0b\u4e2d\u9ad8GPU\u5185\u5b58\u9700\u6c42\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528Zero-Shot NAS\u9884\u5148\u4ece\u641c\u7d22\u7a7a\u95f4\u4e2d\u79fb\u9664\u8868\u73b0\u8f83\u5dee\u7684\u67b6\u6784\uff0c\u7136\u540e\u5bf9\u4fee\u526a\u540e\u7684\u641c\u7d22\u7a7a\u95f4\u5e94\u7528One-Shot NAS\u3002", "result": "\u5728DARTS\u641c\u7d22\u7a7a\u95f4\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u51c6One-Shot\u8bbe\u7f6e\uff0c\u5185\u5b58\u6d88\u8017\u51cf\u5c11\u4e8681%\uff0c\u4e14\u8fbe\u5230\u76f8\u540c\u7684\u51c6\u786e\u6027\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86One-Shot NAS\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u641c\u7d22\u6548\u679c\u3002"}}
{"id": "2505.13718", "pdf": "https://arxiv.org/pdf/2505.13718", "abs": "https://arxiv.org/abs/2505.13718", "authors": ["Safal Shrestha", "Minwu Kim", "Aadim Nepal", "Anubhav Shrestha", "Keith Ross"], "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Designing effective reasoning-capable LLMs typically requires training using\nReinforcement Learning with Verifiable Rewards (RLVR) or distillation with\ncarefully curated Long Chain of Thoughts (CoT), both of which depend heavily on\nextensive training data. This creates a major challenge when the amount of\nquality training data is scarce. We propose a sample-efficient, two-stage\ntraining strategy to develop reasoning LLMs under limited supervision. In the\nfirst stage, we \"warm up\" the model by distilling Long CoTs from a toy domain,\nnamely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning\nskills. In the second stage, we apply RLVR to the warmed-up model using a\nlimited set of target-domain examples. Our experiments demonstrate that this\ntwo-phase approach offers several benefits: $(i)$ the warmup phase alone\nfacilitates generalized reasoning, leading to performance improvements across a\nrange of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro. $(ii)$ When both\nthe base model and the warmed-up model are RLVR trained on the same small\ndataset ($\\leq100$ examples), the warmed-up model consistently outperforms the\nbase model; $(iii)$ Warming up before RLVR training allows a model to maintain\ncross-domain generalizability even after training on a specific domain; $(iv)$\nIntroducing warmup in the pipeline improves not only accuracy but also overall\nsample efficiency during RLVR training. The results in this paper highlight the\npromise of warmup for building robust reasoning LLMs in data-scarce\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6709\u9650\u76d1\u7763\u4e0b\u9ad8\u6548\u8bad\u7ec3\u63a8\u7406\u80fd\u529b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e24\u9636\u6bb5\u7b56\u7565\u3002\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u73a9\u5177\u95ee\u9898\u9884\u70ed\u6a21\u578b\u4ee5\u83b7\u53d6\u4e00\u822c\u63a8\u7406\u6280\u80fd\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u5c11\u91cf\u76ee\u6807\u9886\u57df\u6837\u672c\u5e94\u7528\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6837\u672c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5728\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u8bbe\u8ba1\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4ece\u73a9\u5177\u903b\u8f91\u8c1c\u9898\u4e2d\u83b7\u53d6\u4e00\u822c\u63a8\u7406\u6280\u80fd\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u5c11\u91cf\u76ee\u6807\u9886\u57df\u6837\u4f8b\u7ed3\u5408\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u76f8\u540c\u5c0f\u6570\u636e\u96c6\u4e0a\u9884\u70ed\u540e\u7684\u6a21\u578b\u4f18\u4e8e\u672a\u9884\u70ed\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8de8\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u5e76\u6539\u5584\u4e86\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u9884\u70ed\u662f\u6784\u5efa\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e2d\u9c81\u68d2\u63a8\u7406\u80fd\u529b\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2505.13563", "pdf": "https://arxiv.org/pdf/2505.13563", "abs": "https://arxiv.org/abs/2505.13563", "authors": ["Xiaohui Wang", "Peng Ye", "Chenyu Huang", "Shenghe Zheng", "Bo Zhang", "Wanli Ouyang", "Tao Chen"], "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u65e0\u5173\u7684delta\u538b\u7f29\u65b9\u6cd5UltraDelta\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u8d85\u9ad8\u538b\u7f29\u6bd4\u3002", "motivation": "\u5b58\u50a8\u4f17\u591a\u5fae\u8c03\u6a21\u578b\u4f1a\u5e26\u6765\u663e\u8457\u7684\u5b58\u50a8\u5f00\u9500\uff0c\u800c\u73b0\u6709\u7684delta\u538b\u7f29\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u4fdd\u6301\u9ad8\u538b\u7f29\u7387\u548c\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUltraDelta\u7684\u6570\u636e\u65e0\u5173\u7684delta\u538b\u7f29\u7ba1\u9053\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u65b9\u5dee\u7684\u6df7\u5408\u7a00\u758f\u5206\u914d\u3001\u57fa\u4e8e\u5206\u5e03\u611f\u77e5\u7684\u538b\u7f29\u548c\u8ff9\u8303\u6570\u5f15\u5bfc\u7684\u91cd\u7f29\u653e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cUltraDelta\u5728\u5404\u79cd\u6a21\u578b\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u8d85\u9ad8\u538b\u7f29\u6bd4\u4e0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9ad8\u538b\u7f29\u6bd4\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.13614", "pdf": "https://arxiv.org/pdf/2505.13614", "abs": "https://arxiv.org/abs/2505.13614", "authors": ["Ke Sun"], "title": "Deterministic Bounds and Random Estimates of Metric Tensors on Neuromanifolds", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The high dimensional parameter space of modern deep neural networks -- the\nneuromanifold -- is endowed with a unique metric tensor defined by the Fisher\ninformation, estimating which is crucial for both theory and practical methods\nin deep learning. To analyze this tensor for classification networks, we return\nto a low dimensional space of probability distributions -- the core space --\nand carefully analyze the spectrum of its Riemannian metric. We extend our\ndiscoveries there into deterministic bounds of the metric tensor on the\nneuromanifold. We introduce an unbiased random estimate of the metric tensor\nand its bounds based on Hutchinson's trace estimator. It can be evaluated\nefficiently through a single backward pass and can be used to estimate the\ndiagonal, or block diagonal, or the full tensor. Its quality is guaranteed with\na standard deviation bounded by the true value up to scaling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4f30\u8ba1\u795e\u7ecf\u6d41\u5f62\u4e0a\u5ea6\u91cf\u5f20\u91cf\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684Fisher\u4fe1\u606f\u5ea6\u91cf\u5f20\u91cf\u7684\u4f30\u8ba1\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u548c\u5b9e\u9645\u65b9\u6cd5\u90fd\u5f88\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u56de\u5230\u6982\u7387\u5206\u5e03\u7684\u6838\u5fc3\u7a7a\u95f4\u6765\u5206\u6790\u5176\u9ece\u66fc\u5ea6\u91cf\u7684\u5149\u8c31\uff0c\u7136\u540e\u5c06\u53d1\u73b0\u6269\u5c55\u5230\u795e\u7ecf\u6d41\u5f62\u4e0a\u7684\u5ea6\u91cf\u5f20\u91cf\u786e\u5b9a\u6027\u754c\u3002\u5f15\u5165\u4e86\u57fa\u4e8eHutchinson\u8ff9\u7ebf\u4f30\u8ba1\u5668\u7684\u5ea6\u91cf\u5f20\u91cf\u53ca\u5176\u754c\u7684\u65e0\u504f\u968f\u673a\u4f30\u8ba1\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5355\u6b21\u53cd\u5411\u4f20\u64ad\u6709\u6548\u8bc4\u4f30\uff0c\u5e76\u53ef\u7528\u4e8e\u4f30\u8ba1\u5bf9\u89d2\u7ebf\u3001\u5757\u5bf9\u89d2\u7ebf\u6216\u5b8c\u6574\u7684\u5f20\u91cf\uff0c\u5176\u8d28\u91cf\u7531\u6807\u51c6\u5dee\u4fdd\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f30\u8ba1\u65b9\u6cd5\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u90fd\u6709\u826f\u597d\u7684\u8868\u73b0\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5ea6\u91cf\u5f20\u91cf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.13737", "pdf": "https://arxiv.org/pdf/2505.13737", "abs": "https://arxiv.org/abs/2505.13737", "authors": ["Andrew Nam", "Henry Conklin", "Yukang Yang", "Thomas Griffiths", "Jonathan Cohen", "Sarah-Jane Leslie"], "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers", "categories": ["cs.AI"], "comment": "10 pages, 5 figures, 2 tables", "summary": "We present causal head gating (CHG), a scalable method for interpreting the\nfunctional roles of attention heads in transformer models. CHG learns soft\ngates over heads and assigns them a causal taxonomy - facilitating,\ninterfering, or irrelevant - based on their impact on task performance. Unlike\nprior approaches in mechanistic interpretability, which are hypothesis-driven\nand require prompt templates or target labels, CHG applies directly to any\ndataset using standard next-token prediction. We evaluate CHG across multiple\nlarge language models (LLMs) in the Llama 3 model family and diverse tasks,\nincluding syntax, commonsense, and mathematical reasoning, and show that CHG\nscores yield causal - not merely correlational - insight, validated via\nablation and causal mediation analyses. We also introduce contrastive CHG, a\nvariant that isolates sub-circuits for specific task components. Our findings\nreveal that LLMs contain multiple sparse, sufficient sub-circuits, that\nindividual head roles depend on interactions with others (low modularity), and\nthat instruction following and in-context learning rely on separable\nmechanisms.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u5934\u95e8\u63a7\u65b9\u6cd5(CHG)\uff0c\u7528\u4e8e\u89e3\u91ca\u53d8\u538b\u5668\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u5934\u7684\u529f\u80fd\u89d2\u8272\u3002\u901a\u8fc7\u5f71\u54cd\u4efb\u52a1\u6027\u80fd\u6765\u5206\u914d\u56e0\u679c\u5206\u7c7b\uff0c\u5e76\u5728\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u91ca\u53d8\u538b\u5668\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u5934\u7684\u529f\u80fd\u89d2\u8272\u3002", "method": "\u63d0\u51fa\u56e0\u679c\u5934\u95e8\u63a7\u65b9\u6cd5(CHG)\uff0c\u5b66\u4e60\u8f6f\u95e8\u63a7\u5e76\u5206\u914d\u56e0\u679c\u5206\u7c7b\u3002", "result": "\u5728Llama 3\u6a21\u578b\u5bb6\u65cf\u548c\u591a\u79cd\u4efb\u52a1\u4e0a\u8bc4\u4f30CHG\uff0c\u663e\u793a\u5176\u5f97\u5206\u63d0\u4f9b\u4e86\u56e0\u679c\u6d1e\u5bdf\u529b\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4CHG\u4ee5\u9694\u79bb\u7279\u5b9a\u4efb\u52a1\u7ec4\u4ef6\u7684\u5b50\u7535\u8def\u3002", "conclusion": "LLMs\u5305\u542b\u591a\u4e2a\u7a00\u758f\u4e14\u8db3\u591f\u7684\u5b50\u7535\u8def\uff0c\u5355\u4e2a\u5934\u7684\u89d2\u8272\u4f9d\u8d56\u4e8e\u4e0e\u5176\u4ed6\u5934\u7684\u4ea4\u4e92\uff0c\u5e76\u4e14\u6307\u4ee4\u8ddf\u968f\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4f9d\u8d56\u4e8e\u53ef\u5206\u79bb\u7684\u673a\u5236\u3002"}}
{"id": "2505.13723", "pdf": "https://arxiv.org/pdf/2505.13723", "abs": "https://arxiv.org/abs/2505.13723", "authors": ["Pratik Rathore", "Zachary Frangella", "Sachin Garg", "Shaghayegh Fazliani", "Micha\u0142 Derezi\u0144ski", "Madeleine Udell"], "title": "Turbocharging Gaussian Process Inference with Approximate Sketch-and-Project", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "28 pages, 6 figures, 2 tables", "summary": "Gaussian processes (GPs) play an essential role in biostatistics, scientific\nmachine learning, and Bayesian optimization for their ability to provide\nprobabilistic predictions and model uncertainty. However, GP inference\nstruggles to scale to large datasets (which are common in modern applications),\nsince it requires the solution of a linear system whose size scales\nquadratically with the number of samples in the dataset. We propose an\napproximate, distributed, accelerated sketch-and-project algorithm\n($\\texttt{ADASAP}$) for solving these linear systems, which improves\nscalability. We use the theory of determinantal point processes to show that\nthe posterior mean induced by sketch-and-project rapidly converges to the true\nposterior mean. In particular, this yields the first efficient, condition\nnumber-free algorithm for estimating the posterior mean along the top spectral\nbasis functions, showing that our approach is principled for GP inference.\n$\\texttt{ADASAP}$ outperforms state-of-the-art solvers based on conjugate\ngradient and coordinate descent across several benchmark datasets and a\nlarge-scale Bayesian optimization task. Moreover, $\\texttt{ADASAP}$ scales to a\ndataset with $> 3 \\cdot 10^8$ samples, a feat which has not been accomplished\nin the literature.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5ADASAP\uff0c\u7528\u4e8e\u63d0\u9ad8\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u5e76\u5728\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u7a81\u7834\u3002", "motivation": "\u89e3\u51b3\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u4f20\u7edf\u7684\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u65b9\u6cd5\u968f\u7740\u6837\u672c\u6570\u91cf\u7684\u589e\u52a0\u5448\u4e8c\u6b21\u589e\u957f\u3002", "method": "\u4e00\u79cd\u8fd1\u4f3c\u7684\u3001\u5206\u5e03\u5f0f\u7684\u52a0\u901f\u8349\u56fe\u6295\u5f71\u7b97\u6cd5\uff08ADASAP\uff09\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u7406\u8bba\u8bc1\u660e\u4e86\u8349\u56fe\u6295\u5f71\u8bf1\u5bfc\u7684\u540e\u9a8c\u5747\u503c\u5feb\u901f\u6536\u655b\u5230\u771f\u5b9e\u540e\u9a8c\u5747\u503c\u3002", "result": "ADASAP\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21\u8d1d\u53f6\u65af\u4f18\u5316\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u5171\u8f6d\u68af\u5ea6\u548c\u5750\u6807\u4e0b\u964d\u7684\u6700\u65b0\u6c42\u89e3\u5668\uff0c\u5e76\u6210\u529f\u5904\u7406\u8d85\u8fc73\u4ebf\u6837\u672c\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5ADASAP\uff0c\u5b83\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u662f\u9996\u4e2a\u9ad8\u6548\u4e14\u65e0\u6761\u4ef6\u6570\u9650\u5236\u7684\u9ad8\u8c31\u57fa\u51fd\u6570\u540e\u9a8c\u5747\u503c\u4f30\u8ba1\u7b97\u6cd5\u3002"}}
{"id": "2505.13763", "pdf": "https://arxiv.org/pdf/2505.13763", "abs": "https://arxiv.org/abs/2505.13763", "authors": ["Li Ji-An", "Hua-Dong Xiong", "Robert C. Wilson", "Marcelo G. Mattar", "Marcus K. Benna"], "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations", "categories": ["cs.AI", "cs.CL", "q-bio.NC"], "comment": null, "summary": "Large language models (LLMs) can sometimes report the strategies they\nactually use to solve tasks, but they can also fail to do so. This suggests\nsome degree of metacognition -- the capacity to monitor one's own cognitive\nprocesses for subsequent reporting and self-control. Metacognitive abilities\nenhance AI capabilities but raise safety concerns, as models might obscure\ntheir internal processes to evade neural-activation-based oversight mechanisms\ndesigned to detect harmful behaviors. Given society's increased reliance on\nthese models, it is critical that we understand the limits of their\nmetacognitive abilities, particularly their ability to monitor their internal\nactivations. To address this, we introduce a neuroscience-inspired\nneurofeedback paradigm designed to quantify the ability of LLMs to explicitly\nreport and control their activation patterns. By presenting models with\nsentence-label pairs where labels correspond to sentence-elicited internal\nactivations along specific directions in the neural representation space, we\ndemonstrate that LLMs can learn to report and control these activations. The\nperformance varies with several factors: the number of example pairs provided,\nthe semantic interpretability of the target neural direction, and the variance\nexplained by that direction. These results reveal a \"metacognitive space\" with\ndimensionality much lower than the model's neural space, suggesting LLMs can\nmonitor only a subset of their neural mechanisms. Our findings provide\nempirical evidence quantifying metacognitive capabilities in LLMs, with\nsignificant implications for AI safety.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5143\u8ba4\u77e5\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u53cd\u9988\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u5176\u663e\u5f0f\u62a5\u544a\u548c\u63a7\u5236\u6fc0\u6d3b\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u53d1\u73b0LLMs\u80fd\u591f\u5b66\u4e60\u5230\u4e00\u5b9a\u7a0b\u5ea6\u7684\u81ea\u6211\u76d1\u63a7\uff0c\u4f46\u5176\u5143\u8ba4\u77e5\u80fd\u529b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u5728AI\u5b89\u5168\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5143\u8ba4\u77e5\u80fd\u529b\u9650\u5236\uff0c\u7279\u522b\u662f\u5b83\u4eec\u76d1\u63a7\u5185\u90e8\u6fc0\u6d3b\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9\u4e8e\u786e\u4fddAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u53d7\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u795e\u7ecf\u53cd\u9988\u8303\u5f0f\uff0c\u901a\u8fc7\u5448\u73b0\u5e26\u6709\u6807\u7b7e\u7684\u53e5\u5b50-\u6807\u7b7e\u5bf9\u6765\u91cf\u5316LLMs\u62a5\u544a\u548c\u63a7\u5236\u6fc0\u6d3b\u6a21\u5f0f\u7684\u80fd\u529b\u3002", "result": "LLMs\u53ef\u4ee5\u5b66\u4f1a\u62a5\u544a\u548c\u63a7\u5236\u7279\u5b9a\u65b9\u5411\u4e0a\u7684\u5185\u90e8\u6fc0\u6d3b\uff0c\u4f46\u6027\u80fd\u53d7\u63d0\u4f9b\u793a\u4f8b\u5bf9\u7684\u6570\u91cf\u3001\u76ee\u6807\u795e\u7ecf\u65b9\u5411\u7684\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u548c\u8be5\u65b9\u5411\u89e3\u91ca\u7684\u65b9\u5dee\u7b49\u56e0\u7d20\u5f71\u54cd\u3002", "conclusion": "LLMs\u7684\u5143\u8ba4\u77e5\u80fd\u529b\u6709\u9650\uff0c\u53ea\u80fd\u76d1\u63a7\u5176\u795e\u7ecf\u673a\u5236\u7684\u4e00\u90e8\u5206\uff0c\u8fd9\u4e00\u53d1\u73b0\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2505.13567", "pdf": "https://arxiv.org/pdf/2505.13567", "abs": "https://arxiv.org/abs/2505.13567", "authors": ["Yoav Ger", "Omri Barak"], "title": "Learning Dynamics of RNNs in Closed-Loop Environments", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": "9 pages with 6 figures", "summary": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer\npowerful models of brain computation. However, typical training paradigms rely\non open-loop, supervised settings, whereas real-world learning unfolds in\nclosed-loop environments. Here, we develop a mathematical theory describing the\nlearning dynamics of linear RNNs trained in closed-loop contexts. We first\ndemonstrate that two otherwise identical RNNs, trained in either closed- or\nopen-loop modes, follow markedly different learning trajectories. To probe this\ndivergence, we analytically characterize the closed-loop case, revealing\ndistinct stages aligned with the evolution of the training loss. Specifically,\nwe show that the learning dynamics of closed-loop RNNs, in contrast to\nopen-loop ones, are governed by an interplay between two competing objectives:\nshort-term policy improvement and long-term stability of the agent-environment\ninteraction. Finally, we apply our framework to a realistic motor control task,\nhighlighting its broader applicability. Taken together, our results underscore\nthe importance of modeling closed-loop dynamics in a biologically plausible\nsetting.", "AI": {"tldr": "\u7814\u7a76\u4e86\u7ebf\u6027\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u5728\u95ed\u73af\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u63ed\u793a\u4e86\u77ed\u671f\u7b56\u7565\u6539\u8fdb\u548c\u957f\u671f\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u5178\u578b\u7684\u8bad\u7ec3\u8303\u5f0f\u4f9d\u8d56\u4e8e\u5f00\u73af\u3001\u76d1\u7763\u8bbe\u7f6e\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u7684\u5b66\u4e60\u5728\u95ed\u73af\u73af\u5883\u4e2d\u5c55\u5f00\u3002", "method": "\u53d1\u5c55\u4e86\u4e00\u4e2a\u63cf\u8ff0\u7ebf\u6027RNN\u5728\u95ed\u73af\u4e0a\u4e0b\u6587\u4e2d\u8bad\u7ec3\u65f6\u5b66\u4e60\u52a8\u6001\u7684\u6570\u5b66\u7406\u8bba\u3002", "result": "\u5c55\u793a\u4e86\u95ed\u5408\u73af\u8defRNN\u7684\u5b66\u4e60\u52a8\u6001\u4e0e\u5f00\u73afRNN\u4e0d\u540c\uff0c\u4e14\u53d7\u5230\u77ed\u671f\u7b56\u7565\u6539\u8fdb\u548c\u957f\u671f\u7a33\u5b9a\u6027\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u751f\u7269\u4e0a\u53ef\u4fe1\u7684\u8bbe\u5b9a\u4e2d\u5efa\u6a21\u95ed\u73af\u52a8\u6001\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.13745", "pdf": "https://arxiv.org/pdf/2505.13745", "abs": "https://arxiv.org/abs/2505.13745", "authors": ["Joanna Komorniczak"], "title": "Synthetic Non-stationary Data Streams for Recognition of the Unknown", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The problem of data non-stationarity is commonly addressed in data stream\nprocessing. In a dynamic environment, methods should continuously be ready to\nanalyze time-varying data -- hence, they should enable incremental training and\nrespond to concept drifts. An equally important variability typical for\nnon-stationary data stream environments is the emergence of new, previously\nunknown classes. Often, methods focus on one of these two phenomena --\ndetection of concept drifts or detection of novel classes -- while both\ndifficulties can be observed in data streams. Additionally, concerning\npreviously unknown observations, the topic of open set of classes has become\nparticularly important in recent years, where the goal of methods is to\nefficiently classify within known classes and recognize objects outside the\nmodel competence. This article presents a strategy for synthetic data stream\ngeneration in which both concept drifts and the emergence of new classes\nrepresenting unknown objects occur. The presented research shows how\nunsupervised drift detectors address the task of detecting novelty and concept\ndrifts and demonstrates how the generated data streams can be utilized in the\nopen set recognition task.", "AI": {"tldr": "This paper proposes a strategy for generating synthetic data streams that simulate both concept drifts and the emergence of new classes, demonstrating its application in open set recognition tasks.", "motivation": "To address the challenges of data non-stationarity in dynamic environments, particularly the simultaneous occurrence of concept drifts and the emergence of new classes.", "method": "Developing a synthetic data stream generation strategy that incorporates both concept drifts and new class emergence.", "result": "The proposed method effectively addresses the dual challenges of concept drift and new class emergence in data streams.", "conclusion": "Unsupervised drift detectors can handle both novelty detection and concept drifts in open set recognition tasks using the generated synthetic data streams."}}
{"id": "2505.13770", "pdf": "https://arxiv.org/pdf/2505.13770", "abs": "https://arxiv.org/abs/2505.13770", "authors": ["Jin Du", "Li Chen", "Xun Xian", "An Luo", "Fangqiao Tian", "Ganghua Wang", "Charles Doss", "Xiaotong Shen", "Jie Ding"], "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ME", "stat.ML", "62-08, 68T50, 68T05, 68T01, 68T07, 62-07, 68U35, 62C99", "I.2.7; I.2.6; I.2.0; I.5.1; I.5.4; F.2.2; H.2.8; G.3"], "comment": null, "summary": "Reliable causal inference is essential for making decisions in high-stakes\nareas like medicine, economics, and public policy. However, it remains unclear\nwhether large language models (LLMs) can handle rigorous and trustworthy\nstatistical causal inference. Current benchmarks usually involve simplified\ntasks. For example, these tasks might only ask LLMs to identify semantic causal\nrelationships or draw conclusions directly from raw data. As a result, models\nmay overlook important statistical pitfalls, such as Simpson's paradox or\nselection bias. This oversight limits the applicability of LLMs in the real\nworld. To address these limitations, we propose CausalPitfalls, a comprehensive\nbenchmark designed to rigorously evaluate the capability of LLMs in overcoming\ncommon causal inference pitfalls. Our benchmark features structured challenges\nacross multiple difficulty levels, each paired with grading rubrics. This\napproach allows us to quantitatively measure both causal reasoning capabilities\nand the reliability of LLMs' responses. We evaluate models using two protocols:\n(1) direct prompting, which assesses intrinsic causal reasoning, and (2)\ncode-assisted prompting, where models generate executable code for explicit\nstatistical analysis. Additionally, we validate the effectiveness of this judge\nby comparing its scoring with assessments from human experts. Our results\nreveal significant limitations in current LLMs when performing statistical\ncausal inference. The CausalPitfalls benchmark provides essential guidance and\nquantitative metrics to advance the development of trustworthy causal reasoning\nsystems.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7edf\u8ba1\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u80fd\u529b", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e8e\u56e0\u679c\u63a8\u7406\u5b58\u5728\u7684\u7b80\u5316\u4efb\u52a1\u4e0d\u80fd\u5168\u9762\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b", "method": "\u63d0\u51faCausalPitfalls\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u591a\u96be\u5ea6\u5c42\u6b21\u7684\u7ed3\u6784\u5316\u6311\u6218\u548c\u8bc4\u5206\u6807\u51c6", "result": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7edf\u8ba1\u56e0\u679c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027", "conclusion": "CausalPitfalls\u57fa\u51c6\u6d4b\u8bd5\u53ef\u4e3a\u53ef\u9760\u56e0\u679c\u63a8\u7406\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u6307\u5bfc\u548c\u5b9a\u91cf\u6307\u6807"}}
{"id": "2505.13569", "pdf": "https://arxiv.org/pdf/2505.13569", "abs": "https://arxiv.org/abs/2505.13569", "authors": ["Fynn Fromme", "Christine Allen-Blanchette", "Hans Harder", "Sebastian Peitz"], "title": "Surrogate Modeling of 3D Rayleigh-Benard Convection with Equivariant Autoencoders", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "The use of machine learning for modeling, understanding, and controlling\nlarge-scale physics systems is quickly gaining in popularity, with examples\nranging from electromagnetism over nuclear fusion reactors and\nmagneto-hydrodynamics to fluid mechanics and climate modeling. These systems --\ngoverned by partial differential equations -- present unique challenges\nregarding the large number of degrees of freedom and the complex dynamics over\nmany scales both in space and time, and additional measures to improve accuracy\nand sample efficiency are highly desirable. We present an end-to-end\nequivariant surrogate model consisting of an equivariant convolutional\nautoencoder and an equivariant convolutional LSTM using $G$-steerable kernels.\nAs a case study, we consider the three-dimensional Rayleigh-B\\'enard\nconvection, which describes the buoyancy-driven fluid flow between a heated\nbottom and a cooled top plate. While the system is E(2)-equivariant in the\nhorizontal plane, the boundary conditions break the translational equivariance\nin the vertical direction. Our architecture leverages vertically stacked layers\nof $D_4$-steerable kernels, with additional partial kernel sharing in the\nvertical direction for further efficiency improvement. Our results demonstrate\nsignificant gains both in sample and parameter efficiency, as well as a better\nscaling to more complex dynamics, that is, larger Rayleigh numbers. The\naccompanying code is available under\nhttps://github.com/FynnFromme/equivariant-rb-forecasting.", "AI": {"tldr": "This paper presents an end-to-end equivariant surrogate model for large-scale physics systems using machine learning methods, demonstrating significant improvements in sample and parameter efficiency for predicting Rayleigh-B\u00e9nard convection.", "motivation": "To address the challenges posed by large-scale physics systems governed by partial differential equations, such as high degrees of freedom and complex dynamics across multiple spatial and temporal scales, by developing a more accurate and sample-efficient machine learning model.", "method": "An end-to-end equivariant surrogate model is constructed, incorporating an equivariant convolutional autoencoder and an equivariant convolutional LSTM using G-steerable kernels, with vertically stacked layers of D4-steerable kernels and partial kernel sharing in the vertical direction.", "result": "The proposed model shows significant improvements in sample and parameter efficiency, and better scalability to more complex dynamics compared to previous models.", "conclusion": "The developed equivariant surrogate model demonstrates great potential for modeling complex physical systems, providing a new approach to handle high-dimensional and multi-scale problems in physics."}}
{"id": "2505.13755", "pdf": "https://arxiv.org/pdf/2505.13755", "abs": "https://arxiv.org/abs/2505.13755", "authors": ["Jeffrey Lai", "Anthony Bao", "William Gilpin"], "title": "Panda: A pretrained forecast model for universal representation of chaotic dynamics", "categories": ["cs.LG", "nlin.CD", "stat.ML"], "comment": null, "summary": "Chaotic systems are intrinsically sensitive to small errors, challenging\nefforts to construct predictive data-driven models of real-world dynamical\nsystems such as fluid flows or neuronal activity. Prior efforts comprise either\nspecialized models trained separately on individual time series, or foundation\nmodels trained on vast time series databases with little underlying dynamical\nstructure. Motivated by dynamical systems theory, we present Panda, Patched\nAttention for Nonlinear DynAmics. We train Panda on a novel synthetic,\nextensible dataset of $2 \\times 10^4$ chaotic dynamical systems that we\ndiscover using an evolutionary algorithm. Trained purely on simulated data,\nPanda exhibits emergent properties: zero-shot forecasting of unseen real world\nchaotic systems, and nonlinear resonance patterns in cross-channel attention\nheads. Despite having been trained only on low-dimensional ordinary\ndifferential equations, Panda spontaneously develops the ability to predict\npartial differential equations without retraining. We demonstrate a neural\nscaling law for differential equations, underscoring the potential of\npretrained models for probing abstract mathematical domains like nonlinear\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPanda\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u3002\u8be5\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5177\u6709\u96f6-shot\u9884\u6d4b\u672a\u77e5\u771f\u5b9e\u4e16\u754c\u6df7\u6c8c\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u672a\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9884\u6d4b\u504f\u5fae\u5206\u65b9\u7a0b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u7684\u9884\u6d4b\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6ca1\u6709\u5927\u91cf\u52a8\u6001\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e93\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u53d1\u73b0\u4e86\u4e00\u4e2a\u5305\u542b2x10^4\u4e2a\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u7684\u65b0\u578b\u5408\u6210\u53ef\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5e76\u5728\u6b64\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u4e86Panda\u6a21\u578b\u3002", "result": "Panda\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7684\u771f\u5b9e\u4e16\u754c\u6df7\u6c8c\u7cfb\u7edf\u4e0a\u6709\u96f6-shot\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u4e14\u53ef\u4ee5\u81ea\u53d1\u5730\u9884\u6d4b\u504f\u5fae\u5206\u65b9\u7a0b\u3002", "conclusion": "\u8bc1\u660e\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u63a2\u7d22\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7b49\u62bd\u8c61\u6570\u5b66\u9886\u57df\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.13773", "pdf": "https://arxiv.org/pdf/2505.13773", "abs": "https://arxiv.org/abs/2505.13773", "authors": ["Ryan Bowers", "Richard Agbeyibor", "Jack Kolb", "Karen Feigh"], "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures", "summary": "We compare three methods of familiarizing a human with an artificial\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\na between-subjects user study (n=60), participants either read documentation\nabout the agent, trained alongside the agent prior to the mission, or were\ngiven no familiarization. Results showed that the most valuable information\nabout the agent included details of its decision-making algorithms and its\nrelative strengths and weaknesses compared to the human. This information\nallowed the familiarization groups to form sophisticated team strategies more\nquickly than the control group. Documentation-based familiarization led to the\nfastest adoption of these strategies, but also biased participants towards\nrisk-averse behavior that prevented high scores. Participants familiarized\nthrough direct interaction were able to infer much of the same information\nthrough observation, and were more willing to take risks and experiment with\ndifferent control modes, but reported weaker understanding of the agent's\ninternal processes. Significant differences were seen between individual\nparticipants' risk tolerance and methods of AI interaction, which should be\nconsidered when designing human-AI control interfaces. Based on our findings,\nwe recommend a human-AI team familiarization method that combines AI\ndocumentation, structured in-situ training, and exploratory interaction.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u8ba9\u4eba\u7c7b\u719f\u6089\u4eba\u5de5\u667a\u80fd\u961f\u53cb\u7684\u65b9\u6cd5\u3002", "motivation": "\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u63d0\u9ad8\u4eba\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u5408\u4f5c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u6bd4\u8f83\u6587\u6863\u9605\u8bfb\u3001\u4e0eAI\u4e00\u8d77\u8bad\u7ec3\u548c\u65e0\u719f\u6089\u8fc7\u7a0b\u4e09\u79cd\u65b9\u6cd5\u3002", "result": "\u76f4\u63a5\u4ea4\u4e92\u7ec4\u80fd\u66f4\u5feb\u5f62\u6210\u56e2\u961f\u7b56\u7565\u4f46\u98ce\u9669\u89c4\u907f\u8f83\u5f3a\uff1b\u6587\u6863\u7ec4\u867d\u4e5f\u6709\u5feb\u901f\u9002\u5e94\u4f46\u66f4\u503e\u5411\u4e8e\u4fdd\u5b88\u884c\u4e3a\uff1b\u7ed3\u5408\u591a\u79cd\u65b9\u5f0f\u53ef\u80fd\u6700\u4f73\u3002", "conclusion": "\u63a8\u8350\u7ed3\u5408\u6587\u6863\u3001\u73b0\u573a\u57f9\u8bad\u53ca\u63a2\u7d22\u6027\u4e92\u52a8\u7684\u4eba\u673a\u719f\u6089\u65b9\u6cd5\u3002"}}
{"id": "2505.13575", "pdf": "https://arxiv.org/pdf/2505.13575", "abs": "https://arxiv.org/abs/2505.13575", "authors": ["Ilkay Wunderlich", "Benjamin Koch", "Sven Sch\u00f6nfeld"], "title": "An Overview of Arithmetic Adaptations for Inference of Convolutional Neural Networks on Re-configurable Hardware", "categories": ["cs.LG"], "comment": null, "summary": "Convolutional Neural Networks (CNNs) have gained high popularity as a tool\nfor computer vision tasks and for that reason are used in various applications.\nThere are many different concepts, like single shot detectors, that have been\npublished for detecting objects in images or video streams. However, CNNs\nsuffer from disadvantages regarding the deployment on embedded platforms such\nas re-configurable hardware like Field Programmable Gate Arrays (FPGAs). Due to\nthe high computational intensity, memory requirements and arithmetic\nconditions, a variety of strategies for running CNNs on FPGAs have been\ndeveloped. The following methods showcase our best practice approaches for a\nTinyYOLOv3 detector network on a XILINX Artix-7 FPGA using techniques like\nfusion of batch normalization, filter pruning and post training network\nquantization.", "AI": {"tldr": "TinyYOLOv3\u68c0\u6d4b\u7f51\u7edc\u5728XILINX Artix-7 FPGA\u4e0a\u7684\u6700\u4f73\u5b9e\u8df5\u65b9\u6cd5\uff0c\u5305\u62ec\u6279\u5f52\u4e00\u5316\u878d\u5408\u3001\u6ee4\u6ce2\u5668\u526a\u679d\u548c\u540e\u8bad\u7ec3\u7f51\u7edc\u91cf\u5316\u6280\u672f\u3002", "motivation": "\u89e3\u51b3CNN\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u7279\u522b\u662fFPGA\u4e0a\u7684\u9ad8\u8ba1\u7b97\u5f3a\u5ea6\u3001\u5185\u5b58\u9700\u6c42\u548c\u7b97\u672f\u6761\u4ef6\u3002", "method": "\u5728XILINX Artix-7 FPGA\u4e0a\u5b9e\u73b0TinyYOLOv3\u68c0\u6d4b\u7f51\u7edc\uff0c\u91c7\u7528\u6279\u5f52\u4e00\u5316\u878d\u5408\u3001\u6ee4\u6ce2\u5668\u526a\u679d\u548c\u540e\u8bad\u7ec3\u7f51\u7edc\u91cf\u5316\u7b49\u6280\u672f\u3002", "result": "\u5c55\u793a\u4e86\u5728FPGA\u4e0a\u8fd0\u884cCNN\u7684\u4e0d\u540c\u7b56\u7565\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8CNN\u5728FPGA\u4e0a\u7684\u8fd0\u884c\u6548\u7387\u3002"}}
{"id": "2505.13760", "pdf": "https://arxiv.org/pdf/2505.13760", "abs": "https://arxiv.org/abs/2505.13760", "authors": ["Drona Khurana", "Anish Thilagar", "Dhamma Kimpara", "Rafael Frongillo"], "title": "Consistency Conditions for Differentiable Surrogate Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The statistical consistency of surrogate losses for discrete prediction tasks\nis often checked via the condition of calibration. However, directly verifying\ncalibration can be arduous. Recent work shows that for polyhedral surrogates, a\nless arduous condition, indirect elicitation (IE), is still equivalent to\ncalibration. We give the first results of this type for non-polyhedral\nsurrogates, specifically the class of convex differentiable losses. We first\nprove that under mild conditions, IE and calibration are equivalent for\none-dimensional losses in this class. We construct a counter-example that shows\nthat this equivalence fails in higher dimensions. This motivates the\nintroduction of strong IE, a strengthened form of IE that is equally easy to\nverify. We establish that strong IE implies calibration for differentiable\nsurrogates and is both necessary and sufficient for strongly convex,\ndifferentiable surrogates. Finally, we apply these results to a range of\nproblems to demonstrate the power of IE and strong IE for designing and\nanalyzing consistent differentiable surrogates.", "AI": {"tldr": "\u7814\u7a76\u4e86\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u5728\u79bb\u6563\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u7edf\u8ba1\u4e00\u81f4\u6027\uff0c\u5bf9\u4e8e\u975e\u591a\u9762\u4f53\u4ee3\u7406\uff0c\u7279\u522b\u662f\u51f8\u53ef\u5fae\u635f\u5931\u7c7b\uff0c\u5f15\u5165\u4e86\u5f3a\u95f4\u63a5\u8bf1\u5bfc\uff08IE\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u5f3a\u51f8\u53ef\u5fae\u4ee3\u7406\u4e0b\u662f\u6821\u51c6\u6027\u5fc5\u8981\u4e14\u5145\u5206\u7684\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u7684\u76f4\u63a5\u9a8c\u8bc1\u6821\u51c6\u65b9\u6cd5\u8f83\u4e3a\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u5bfb\u627e\u7b49\u4ef7\u4f46\u66f4\u7b80\u5355\u7684\u6761\u4ef6\u6765\u4ee3\u66ff\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u6784\u9020\u53cd\u4f8b\uff0c\u7814\u7a76\u4e86IE\u4e0e\u6821\u51c6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u5f3aIE\u7684\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u4e00\u7c7b\u4e00\u7ef4\u51f8\u53ef\u5fae\u635f\u5931\u4e2d\uff0cIE\u4e0e\u6821\u51c6\u7b49\u4ef7\uff1b\u4f46\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u8be5\u7b49\u4ef7\u5173\u7cfb\u5931\u6548\u3002\u5f3aIE\u5bf9\u4e8e\u53ef\u5fae\u4ee3\u7406\u53ef\u4ee5\u63a8\u51fa\u6821\u51c6\u6027\uff0c\u5e76\u4e14\u5728\u5f3a\u51f8\u53ef\u5fae\u4ee3\u7406\u4e0b\u662f\u6821\u51c6\u6027\u7684\u5145\u8981\u6761\u4ef6\u3002", "conclusion": "\u5f3aIE\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1\u548c\u5206\u6790\u4e00\u81f4\u7684\u53ef\u5fae\u4ee3\u7406\u3002"}}
{"id": "2505.13774", "pdf": "https://arxiv.org/pdf/2505.13774", "abs": "https://arxiv.org/abs/2505.13774", "authors": ["Zidi Xiong", "Chen Shan", "Zhenting Qi", "Himabindu Lakkaraju"], "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u53cd\u4e8b\u5b9e\u5e72\u9884\u6846\u67b6\u6765\u4e25\u683c\u8bc4\u4f30LRMs\u601d\u7ef4\u8349\u7a3f\u7684\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u786e\u4fddLRMs\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u7684\u5fe0\u5b9e\u6027\u5bf9\u4e8e\u53ef\u9760\u76d1\u63a7\u3001\u89e3\u91ca\u548c\u6709\u6548\u63a7\u5236\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u4e92\u8865\u7684\u7ef4\u5ea6\u6765\u8bc4\u4f30\u601d\u7ef4\u8349\u7a3f\u7684\u5fe0\u5b9e\u6027\uff1a\uff081\uff09Intra-Draft Faithfulness \u548c \uff082\uff09Draft-to-Answer Faithfulness\u3002", "result": "\u5f53\u524d\u7684LRMs\u5728\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4e0a\u8868\u73b0\u51fa\u9009\u62e9\u6027\u7684\u5fe0\u5b9e\u6027\uff0c\u5e76\u4e14\u7ecf\u5e38\u65e0\u6cd5\u5fe0\u5b9e\u5730\u4e0e\u8349\u6848\u7ed3\u8bba\u5bf9\u9f50\u3002", "conclusion": "\u9700\u8981\u5728\u9ad8\u7ea7LRMs\u4e2d\u5b9e\u73b0\u66f4\u5fe0\u5b9e\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u3002"}}
{"id": "2505.13576", "pdf": "https://arxiv.org/pdf/2505.13576", "abs": "https://arxiv.org/abs/2505.13576", "authors": ["Sara Alosaime", "Arshad Jhumka"], "title": "FlexFed: Mitigating Catastrophic Forgetting in Heterogeneous Federated Learning in Pervasive Computing Environments", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training while preserving\nprivacy by allowing clients to share model updates instead of raw data.\nPervasive computing environments (e.g., for Human Activity Recognition, HAR),\nwhich we focus on in this paper, are characterized by resource-constrained end\ndevices, streaming sensor data and intermittent client participation.\nVariations in user behavior, common in HAR environments, often result in\nnon-stationary data distributions. As such, existing FL approaches face\nchallenges in HAR settings due to differing assumptions. The combined effects\nof HAR characteristics, namely heterogeneous data and intermittent\nparticipation, can lead to a severe issue called catastrophic forgetting (CF).\nUnlike Continuous Learning (CL), which addresses CF using memory and replay\nmechanisms, FL's privacy constraints prohibit such strategies.\n  To tackle CF in HAR environments, we propose FlexFed, a novel FL approach\nthat prioritizes data retention for efficient memory use and dynamically\nadjusts offline training frequency based on distribution shifts, client\ncapability and offline duration. To better quantify CF in FL, we introduce a\nnew metric that accounts for under-represented data, enabling more accurate\nevaluations. We also develop a realistic HAR-based evaluation framework that\nsimulates streaming data, dynamic distributions, imbalances and varying\navailability. Experiments show that FlexFed mitigates CF more effectively,\nimproves FL efficiency by 10 to 15 % and achieves faster, more stable\nconvergence, especially for infrequent or under-represented data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFlexFed\u7684\u65b0\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u73af\u5883\u4e2d\u7531\u4e8e\u975e\u5e73\u7a33\u6570\u636e\u5206\u5e03\u548c\u95f4\u6b47\u6027\u53c2\u4e0e\u5bfc\u81f4\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5e73\u7a33\u6570\u636e\u5206\u5e03\u548c\u95f4\u6b47\u6027\u53c2\u4e0e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u5bfc\u81f4\u4e25\u91cd\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u7684\u8fde\u7eed\u5b66\u4e60\u7b56\u7565\u56e0\u9690\u79c1\u9650\u5236\u65e0\u6cd5\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5FlexFed\uff0c\u8be5\u65b9\u6cd5\u4f18\u5148\u4fdd\u7559\u6570\u636e\u4ee5\u9ad8\u6548\u5229\u7528\u5185\u5b58\uff0c\u5e76\u6839\u636e\u5206\u5e03\u53d8\u5316\u3001\u5ba2\u6237\u7aef\u80fd\u529b\u548c\u79bb\u7ebf\u65f6\u957f\u52a8\u6001\u8c03\u6574\u79bb\u7ebf\u8bad\u7ec3\u9891\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFlexFed\u5728\u5904\u7406\u7a00\u758f\u6216\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u6570\u636e\u65f6\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u5e76\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u3002", "conclusion": "FlexFed\u6709\u6548\u7f13\u89e3\u4e86\u8fde\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2505.13768", "pdf": "https://arxiv.org/pdf/2505.13768", "abs": "https://arxiv.org/abs/2505.13768", "authors": ["Ruiquan Huang", "Donghao Li", "Chengshuai Shi", "Cong Shen", "Jing Yang"], "title": "Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by UAI2025", "summary": "This paper investigates a hybrid learning framework for reinforcement\nlearning (RL) in which the agent can leverage both an offline dataset and\nonline interactions to learn the optimal policy. We present a unified algorithm\nand analysis and show that augmenting confidence-based online RL algorithms\nwith the offline dataset outperforms any pure online or offline algorithm alone\nand achieves state-of-the-art results under two learning metrics, i.e.,\nsub-optimality gap and online learning regret. Specifically, we show that our\nalgorithm achieves a sub-optimality gap\n$\\tilde{O}(\\sqrt{1/(N_0/\\mathtt{C}(\\pi^*|\\rho)+N_1}) )$, where\n$\\mathtt{C}(\\pi^*|\\rho)$ is a new concentrability coefficient, $N_0$ and $N_1$\nare the numbers of offline and online samples, respectively. For regret\nminimization, we show that it achieves a constant $\\tilde{O}(\n\\sqrt{N_1/(N_0/\\mathtt{C}(\\pi^{-}|\\rho)+N_1)} )$ speed-up compared to pure\nonline learning, where $\\mathtt{C}(\\pi^-|\\rho)$ is the concentrability\ncoefficient over all sub-optimal policies. Our results also reveal an\ninteresting separation on the desired coverage properties of the offline\ndataset for sub-optimality gap minimization and regret minimization. We further\nvalidate our theoretical findings in several experiments in special RL models\nsuch as linear contextual bandits and Markov decision processes (MDPs).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u79bb\u7ebf\u6570\u636e\u548c\u5728\u7ebf\u4ea4\u4e92\u6765\u4f18\u5316\u7b56\u7565\uff0c\u5728\u4e24\u79cd\u5b66\u4e60\u6307\u6807\u4e0b\u8868\u73b0\u4f18\u4e8e\u7eaf\u5728\u7ebf\u6216\u79bb\u7ebf\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u6709\u6548\u5229\u7528\u79bb\u7ebf\u6570\u636e\u548c\u5728\u7ebf\u4ea4\u4e92\u6765\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6027\u80fd\u3002", "result": "\u5728\u4e24\u79cd\u5b66\u4e60\u6307\u6807\u4e0b\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u79bb\u7ebf\u6570\u636e\u8986\u76d6\u6027\u8d28\u5bf9\u4e8e\u4e0d\u540c\u76ee\u6807\u7684\u91cd\u8981\u5dee\u5f02\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u7279\u5b9a\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.13778", "pdf": "https://arxiv.org/pdf/2505.13778", "abs": "https://arxiv.org/abs/2505.13778", "authors": ["Guoheng Sun", "Ziyao Wang", "Bowei Tian", "Meng Liu", "Zheyu Shen", "Shwai He", "Yexiao He", "Wanghao Ye", "Yiting Wang", "Ang Li"], "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs", "categories": ["cs.AI"], "comment": null, "summary": "As post-training techniques evolve, large language models (LLMs) are\nincreasingly augmented with structured multi-step reasoning abilities, often\noptimized through reinforcement learning. These reasoning-enhanced models\noutperform standard LLMs on complex tasks and now underpin many commercial LLM\nAPIs. However, to protect proprietary behavior and reduce verbosity, providers\ntypically conceal the reasoning traces while returning only the final answer.\nThis opacity introduces a critical transparency gap: users are billed for\ninvisible reasoning tokens, which often account for the majority of the cost,\nyet have no means to verify their authenticity. This opens the door to token\ncount inflation, where providers may overreport token usage or inject\nsynthetic, low-effort tokens to inflate charges. To address this issue, we\npropose CoIn, a verification framework that audits both the quantity and\nsemantic validity of hidden tokens. CoIn constructs a verifiable hash tree from\ntoken embedding fingerprints to check token counts, and uses embedding-based\nrelevance matching to detect fabricated reasoning content. Experiments\ndemonstrate that CoIn, when deployed as a trusted third-party auditor, can\neffectively detect token count inflation with a success rate reaching up to\n94.7%, showing the strong ability to restore billing transparency in opaque LLM\nservices. The dataset and code are available at\nhttps://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn.", "AI": {"tldr": "\u63d0\u51faCoIn\u6846\u67b6\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u9690\u85cf\u63a8\u7406\u6b65\u9aa4\u4e0d\u900f\u660e\u5bfc\u81f4\u7684\u8ba1\u8d39\u4e0d\u900f\u660e\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9690\u85cf\u7684\u63a8\u7406\u6b65\u9aa4\u5bfc\u81f4\u7528\u6237\u65e0\u6cd5\u9a8c\u8bc1\u7b54\u6848\u7684\u771f\u5b9e\u6027\u4e14\u53ef\u80fd\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u8d39\u7528\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u53ef\u9a8c\u8bc1\u54c8\u5e0c\u6811\u68c0\u67e5\u4ee4\u724c\u6570\u91cf\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u76f8\u5173\u6027\u5339\u914d\u68c0\u6d4b\u4f2a\u9020\u7684\u63a8\u7406\u5185\u5bb9\u6765\u5b9e\u73b0\u5bf9\u4ee4\u724c\u6570\u91cf\u548c\u8bed\u4e49\u6709\u6548\u6027\u7684\u5ba1\u6838\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u4f5c\u4e3a\u53ef\u4fe1\u7b2c\u4e09\u65b9\u5ba1\u8ba1\u5458\u90e8\u7f72\u65f6\uff0cCoIn\u53ef\u4ee5\u6709\u6548\u68c0\u6d4b\u4ee4\u724c\u8ba1\u6570\u81a8\u80c0\uff0c\u6210\u529f\u7387\u8fbe\u523094.7%\u3002", "conclusion": "CoIn\u5c55\u793a\u4e86\u6062\u590d\u4e0d\u900f\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\u8ba1\u8d39\u900f\u660e\u7684\u5f3a\u5927\u80fd\u529b\u3002"}}
{"id": "2505.13578", "pdf": "https://arxiv.org/pdf/2505.13578", "abs": "https://arxiv.org/abs/2505.13578", "authors": ["Mikhail Osipov"], "title": "Symmetry-Breaking Descent for Invariant Cost Functionals", "categories": ["cs.LG"], "comment": "19 pages, 7 appendices", "summary": "We study the problem of reducing a task cost functional $W(S)$, defined over\nSobolev-class signals $S$, when the cost is invariant under a global symmetry\ngroup $G \\subset \\mathrm{Diff}(M)$ and accessible only as a black-box. Such\nscenarios arise in machine learning, imaging, and inverse problems, where cost\nmetrics reflect model outputs or performance scores but are non-differentiable\nand model-internal. We propose a variational method that exploits the symmetry\nstructure to construct explicit, symmetry-breaking deformations of the input\nsignal. A gauge field $\\phi$, obtained by minimizing an auxiliary energy\nfunctional, induces a deformation $h = A_\\phi[S]$ that generically lies\ntransverse to the $G$-orbit of $S$. We prove that, under mild regularity, the\ncost $W$ strictly decreases along this direction -- either via Clarke\nsubdifferential descent or by escaping locally flat plateaus. The exceptional\nset of degeneracies has zero Gaussian measure. Our approach requires no access\nto model gradients or labels and operates entirely at test time. It provides a\nprincipled tool for optimizing invariant cost functionals via Lie-algebraic\nvariational flows, with applications to black-box models and\nsymmetry-constrained tasks.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u5177\u6709\u5168\u5c40\u5bf9\u79f0\u6027\u7684Sobolev\u7c7b\u4fe1\u53f7\u4e0a\u7684\u4efb\u52a1\u6210\u672c\u6cdb\u51fd\u7684\u51cf\u5c11\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u68af\u5ea6\u6216\u6807\u7b7e\u7684\u53d8\u5206\u65b9\u6cd5\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u3001\u6210\u50cf\u548c\u53cd\u95ee\u9898\u7b49\u9886\u57df\uff0c\u5b58\u5728\u4e00\u4e9b\u6210\u672c\u5ea6\u91cf\u53cd\u6620\u6a21\u578b\u8f93\u51fa\u6216\u6027\u80fd\u8bc4\u5206\u4f46\u4e0d\u53ef\u5fae\u4e14\u5185\u90e8\u6a21\u578b\u4f9d\u8d56\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u53d8\u5206\u65b9\u6cd5\u5229\u7528\u5bf9\u79f0\u6027\u7ed3\u6784\u6784\u5efa\u663e\u5f0f\u7684\u5bf9\u79f0\u7834\u574f\u53d8\u5f62\u3002", "result": "\u63d0\u51fa\u7684\u53d8\u5206\u65b9\u6cd5\u80fd\u591f\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4e25\u683c\u51cf\u5c11\u6210\u672c\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u8bbf\u95ee\u6a21\u578b\u68af\u5ea6\u6216\u6807\u7b7e\uff0c\u5b8c\u5168\u5728\u6d4b\u8bd5\u65f6\u64cd\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u51cf\u5c11\u5177\u6709\u5168\u5c40\u5bf9\u79f0\u6027\u7684\u4efb\u52a1\u6210\u672c\u6cdb\u51fd\uff0c\u5e76\u4e14\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u591f\u4e25\u683c\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2505.13794", "pdf": "https://arxiv.org/pdf/2505.13794", "abs": "https://arxiv.org/abs/2505.13794", "authors": ["Qi Cheng", "Licheng Liu", "Qing Zhu", "Runlong Yu", "Zhenong Jin", "Yiqun Xie", "Xiaowei Jia"], "title": "LLM-based Evaluation Policy Extraction for Ecological Modeling", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating ecological time series is critical for benchmarking model\nperformance in many important applications, including predicting greenhouse gas\nfluxes, capturing carbon-nitrogen dynamics, and monitoring hydrological cycles.\nTraditional numerical metrics (e.g., R-squared, root mean square error) have\nbeen widely used to quantify the similarity between modeled and observed\necosystem variables, but they often fail to capture domain-specific temporal\npatterns critical to ecological processes. As a result, these methods are often\naccompanied by expert visual inspection, which requires substantial human labor\nand limits the applicability to large-scale evaluation. To address these\nchallenges, we propose a novel framework that integrates metric learning with\nlarge language model (LLM)-based natural language policy extraction to develop\ninterpretable evaluation criteria. The proposed method processes pairwise\nannotations and implements a policy optimization mechanism to generate and\ncombine different assessment metrics. The results obtained on multiple datasets\nfor evaluating the predictions of crop gross primary production and carbon\ndioxide flux have confirmed the effectiveness of the proposed method in\ncapturing target assessment preferences, including both synthetically generated\nand expert-annotated model comparisons. The proposed framework bridges the gap\nbetween numerical metrics and expert knowledge while providing interpretable\nevaluation policies that accommodate the diverse needs of different ecosystem\nmodeling studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u5ea6\u91cf\u5b66\u4e60\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u7b56\u7565\u63d0\u53d6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6001\u65f6\u95f4\u5e8f\u5217\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6570\u503c\u6307\u6807\u65e0\u6cd5\u6355\u6349\u9886\u57df\u7279\u5b9a\u65f6\u95f4\u6a21\u5f0f\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u6307\u6807\u5728\u8bc4\u4f30\u751f\u6001\u6a21\u578b\u6027\u80fd\u65f6\u65e0\u6cd5\u6709\u6548\u6355\u6349\u5173\u952e\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u4e14\u4e13\u5bb6\u89c6\u89c9\u68c0\u67e5\u8017\u65f6\u4e14\u96be\u4ee5\u5927\u89c4\u6a21\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u96c6\u6210\u5ea6\u91cf\u5b66\u4e60\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u7136\u8bed\u8a00\u7b56\u7565\u63d0\u53d6\uff0c\u901a\u8fc7\u5904\u7406\u6210\u5bf9\u6807\u6ce8\u5e76\u4f18\u5316\u751f\u6210\u7ec4\u5408\u4e0d\u540c\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u4f5c\u7269\u603b\u521d\u7ea7\u751f\u4ea7\u529b\u548c\u4e8c\u6c27\u5316\u78b3\u901a\u91cf\u9884\u6d4b\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u5f25\u5408\u4e86\u6570\u503c\u6307\u6807\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u653f\u7b56\uff0c\u6ee1\u8db3\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u5efa\u6a21\u7814\u7a76\u7684\u9700\u6c42\u3002"}}
{"id": "2505.13580", "pdf": "https://arxiv.org/pdf/2505.13580", "abs": "https://arxiv.org/abs/2505.13580", "authors": ["Hanzhao Wang", "Guanting Chen", "Kalyan Talluri", "Xiaocheng Li"], "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2405.14219", "summary": "We build a Generative Pre-trained Transformer (GPT) model from scratch to\nsolve sequential decision making tasks arising in contexts of operations\nresearch and management science which we call OMGPT. We first propose a general\nsequence modeling framework to cover several operational decision making tasks\nas special cases, such as dynamic pricing, inventory management, resource\nallocation, and queueing control. Under the framework, all these tasks can be\nviewed as a sequential prediction problem where the goal is to predict the\noptimal future action given all the historical information. Then we train a\ntransformer-based neural network model (OMGPT) as a natural and powerful\narchitecture for sequential modeling. This marks a paradigm shift compared to\nthe existing methods for these OR/OM tasks in that (i) the OMGPT model can take\nadvantage of the huge amount of pre-trained data; (ii) when tackling these\nproblems, OMGPT does not assume any analytical model structure and enables a\ndirect and rich mapping from the history to the future actions. Either of these\ntwo aspects, to the best of our knowledge, is not achieved by any existing\nmethod. We establish a Bayesian perspective to theoretically understand the\nworking mechanism of the OMGPT on these tasks, which relates its performance\nwith the pre-training task diversity and the divergence between the testing\ntask and pre-training tasks. Numerically, we observe a surprising performance\nof the proposed model across all the above tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u9884\u8bad\u7ec3Transformer\uff08GPT\uff09\u6a21\u578b\u7684\u65b9\u6cd5OMGPT\uff0c\u7528\u4e8e\u89e3\u51b3\u8fd0\u8425\u7814\u7a76\u548c\u7ba1\u7406\u79d1\u5b66\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u53d8\u538b\u5668\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\u5386\u53f2\u5230\u672a\u6765\u52a8\u4f5c\u7684\u76f4\u63a5\u4e30\u5bcc\u6620\u5c04\uff0c\u5e76\u4e14\u5728\u52a8\u6001\u5b9a\u4ef7\u3001\u5e93\u5b58\u7ba1\u7406\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u8fd0\u8425\u7814\u7a76\u548c\u7ba1\u7406\u79d1\u5b66\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u9700\u8981\u5047\u8bbe\u7279\u5b9a\u7684\u5206\u6790\u6a21\u578b\u7ed3\u6784\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u5e76\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4ece\u5934\u5f00\u59cb\u7684GPT\u6a21\u578b\uff08OMGPT\uff09\uff0c\u9996\u5148\u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u5e8f\u5217\u5efa\u6a21\u6846\u67b6\u6db5\u76d6\u591a\u4e2a\u64cd\u4f5c\u51b3\u7b56\u4efb\u52a1\uff0c\u7136\u540e\u8bad\u7ec3\u4e00\u4e2a\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4f5c\u4e3a\u5e8f\u5217\u5efa\u6a21\u7684\u81ea\u7136\u4e14\u5f3a\u5927\u7684\u67b6\u6784\u3002", "result": "OMGPT\u6a21\u578b\u5728\u52a8\u6001\u5b9a\u4ef7\u3001\u5e93\u5b58\u7ba1\u7406\u3001\u8d44\u6e90\u5206\u914d\u548c\u6392\u961f\u63a7\u5236\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u4ece\u5386\u53f2\u5230\u672a\u6765\u884c\u52a8\u7684\u76f4\u63a5\u548c\u4e30\u5bcc\u7684\u6620\u5c04\uff0c\u5e76\u4e14\u6ca1\u6709\u5047\u8bbe\u4efb\u4f55\u5206\u6790\u6a21\u578b\u7ed3\u6784\u3002", "conclusion": "OMGPT\u6a21\u578b\u901a\u8fc7\u5229\u7528\u5927\u91cf\u9884\u8bad\u7ec3\u6570\u636e\u548c\u4e0d\u5047\u8bbe\u4efb\u4f55\u5206\u6790\u6a21\u578b\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u8fbe\u5230\u7684\u6027\u80fd\u3002"}}
{"id": "2505.14021", "pdf": "https://arxiv.org/pdf/2505.14021", "abs": "https://arxiv.org/abs/2505.14021", "authors": ["Soichiro Kumano", "Hiroshi Kera", "Toshihiko Yamasaki"], "title": "Adversarial Training from Mean Field Perspective", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "NeurIPS23", "summary": "Although adversarial training is known to be effective against adversarial\nexamples, training dynamics are not well understood. In this study, we present\nthe first theoretical analysis of adversarial training in random deep neural\nnetworks without any assumptions on data distributions. We introduce a new\ntheoretical framework based on mean field theory, which addresses the\nlimitations of existing mean field-based approaches. Based on this framework,\nwe derive (empirically tight) upper bounds of $\\ell_q$ norm-based adversarial\nloss with $\\ell_p$ norm-based adversarial examples for various values of $p$\nand $q$. Moreover, we prove that networks without shortcuts are generally not\nadversarially trainable and that adversarial training reduces network capacity.\nWe also show that network width alleviates these issues. Furthermore, we\npresent the various impacts of the input and output dimensions on the upper\nbounds and time evolution of the weight variance.", "AI": {"tldr": "This study provides a theoretical analysis of adversarial training in random deep neural networks without assumptions on data distributions. It introduces a new theoretical framework, derives upper bounds of adversarial loss, proves properties of adversarially trainable networks, and shows the impacts of network width and dimensions on adversarial training.", "motivation": "To understand the training dynamics of adversarial training better.", "method": "Theoretical analysis using mean field theory in random deep neural networks without assumptions on data distributions.", "result": "Derived upper bounds of adversarial loss, proved properties of adversarially trainable networks, showed impacts of network width and dimensions on adversarial training.", "conclusion": "Adversarial training reduces network capacity and network width can alleviate related issues."}}
{"id": "2505.13828", "pdf": "https://arxiv.org/pdf/2505.13828", "abs": "https://arxiv.org/abs/2505.13828", "authors": ["Kiarash Naghavi Khanghah", "Zhiling Chen", "Lela Romeo", "Qian Yang", "Rajiv Malhotra", "Farhad Imani", "Hongyi Xu"], "title": "Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models", "categories": ["cs.AI"], "comment": "ASME 2025 International Design Engineering Technical Conferences and\n  Computers and Information in Engineering Conference IDETC/CIE2025, August\n  17-20, 2025, Anaheim, CA (IDETC2025-168615)", "summary": "Additive manufacturing enables the fabrication of complex designs while\nminimizing waste, but faces challenges related to defects and process\nanomalies. This study presents a novel multimodal Retrieval-Augmented\nGeneration-based framework that automates anomaly detection across various\nAdditive Manufacturing processes leveraging retrieved information from\nliterature, including images and descriptive text, rather than training\ndatasets. This framework integrates text and image retrieval from scientific\nliterature and multimodal generation models to perform zero-shot anomaly\nidentification, classification, and explanation generation in a Laser Powder\nBed Fusion setting. The proposed framework is evaluated on four L-PBF\nmanufacturing datasets from Oak Ridge National Laboratory, featuring various\nprinter makes, models, and materials. This evaluation demonstrates the\nframework's adaptability and generalizability across diverse images without\nrequiring additional training. Comparative analysis using Qwen2-VL-2B and\nGPT-4o-mini as MLLM within the proposed framework highlights that GPT-4o-mini\noutperforms Qwen2-VL-2B and proportional random baseline in manufacturing\nanomalies classification. Additionally, the evaluation of the RAG system\nconfirms that incorporating retrieval mechanisms improves average accuracy by\n12% by reducing the risk of hallucination and providing additional information.\nThe proposed framework can be continuously updated by integrating emerging\nresearch, allowing seamless adaptation to the evolving landscape of AM\ntechnologies. This scalable, automated, and zero-shot-capable framework\nstreamlines AM anomaly analysis, enhancing efficiency and accuracy.", "AI": {"tldr": "This paper introduces a new framework for detecting anomalies in additive manufacturing processes using retrieved literature information for zero-shot anomaly identification, classification, and explanation generation.", "motivation": "To address the challenges related to defects and process anomalies in additive manufacturing.", "method": "A multimodal Retrieval-Augmented Generation-based framework that performs zero-shot anomaly identification, classification, and explanation generation in a Laser Powder Bed Fusion setting.", "result": "The framework was evaluated on four L-PBF manufacturing datasets from Oak Ridge National Laboratory. It demonstrated adaptability and generalizability across diverse images. Comparative analysis showed that GPT-4o-mini outperforms other models in manufacturing anomalies classification.", "conclusion": "This study proposes a novel framework for AM anomaly detection which uses retrieved information instead of training datasets. It shows adaptability and generalizability across diverse images."}}
{"id": "2505.13582", "pdf": "https://arxiv.org/pdf/2505.13582", "abs": "https://arxiv.org/abs/2505.13582", "authors": ["Leyang Zhang", "Yaoyu Zhang", "Tao Luo"], "title": "Uncovering Critical Sets of Deep Neural Networks via Sample-Independent Critical Lifting", "categories": ["cs.LG"], "comment": "20 pages", "summary": "This paper investigates the sample dependence of critical points for neural\nnetworks. We introduce a sample-independent critical lifting operator that\nassociates a parameter of one network with a set of parameters of another, thus\ndefining sample-dependent and sample-independent lifted critical points. We\nthen show by example that previously studied critical embeddings do not capture\nall sample-independent lifted critical points. Finally, we demonstrate the\nexistence of sample-dependent lifted critical points for sufficiently large\nsample sizes and prove that saddles appear among them.", "AI": {"tldr": "\u7814\u7a76\u4e86\u795e\u7ecf\u7f51\u7edc\u4e34\u754c\u70b9\u7684\u6837\u672c\u4f9d\u8d56\u6027\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u4e0e\u6837\u672c\u65e0\u5173\u7684\u4e34\u754c\u63d0\u5347\u7b97\u5b50\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u5148\u524d\u7814\u7a76\u7684\u4e34\u754c\u5d4c\u5165\u6ca1\u6709\u6355\u6349\u5230\u6240\u6709\u4e0e\u6837\u672c\u65e0\u5173\u7684\u63d0\u5347\u4e34\u754c\u70b9\u3002\u6700\u540e\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8db3\u591f\u5927\u7684\u6837\u672c\u91cf\uff0c\u5b58\u5728\u5177\u6709\u978d\u70b9\u7684\u6837\u672c\u76f8\u5173\u63d0\u5347\u4e34\u754c\u70b9\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4e34\u754c\u70b9\u7684\u6837\u672c\u4f9d\u8d56\u6027", "method": "\u5f15\u5165\u6837\u672c\u72ec\u7acb\u7684\u4e34\u754c\u63d0\u5347\u7b97\u5b50\u5e76\u5b9a\u4e49\u6837\u672c\u4f9d\u8d56\u548c\u72ec\u7acb\u7684\u63d0\u5347\u4e34\u754c\u70b9", "result": "\u901a\u8fc7\u4f8b\u5b50\u5c55\u793a\u5148\u524d\u7814\u7a76\u7684\u4e34\u754c\u5d4c\u5165\u672a\u6355\u6349\u5168\u90e8\u6837\u672c\u65e0\u5173\u63d0\u5347\u4e34\u754c\u70b9\uff0c\u5e76\u8bc1\u660e\u5927\u6837\u672c\u4e0b\u5b58\u5728\u6837\u672c\u76f8\u5173\u63d0\u5347\u4e34\u754c\u70b9\u4e14\u5176\u4e2d\u5305\u542b\u978d\u70b9", "conclusion": "\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u4e34\u754c\u70b9\u7684\u590d\u6742\u6027\u53ca\u5176\u4e0e\u6837\u672c\u7684\u5173\u7cfb"}}
{"id": "2505.14042", "pdf": "https://arxiv.org/pdf/2505.14042", "abs": "https://arxiv.org/abs/2505.14042", "authors": ["Soichiro Kumano", "Hiroshi Kera", "Toshihiko Yamasaki"], "title": "Adversarially Pretrained Transformers may be Universally Robust In-Context Learners", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Adversarial training is one of the most effective adversarial defenses, but\nit incurs a high computational cost. In this study, we show that transformers\nadversarially pretrained on diverse tasks can serve as robust foundation models\nand eliminate the need for adversarial training in downstream tasks.\nSpecifically, we theoretically demonstrate that through in-context learning, a\nsingle adversarially pretrained transformer can robustly generalize to multiple\nunseen tasks without any additional training, i.e., without any parameter\nupdates. This robustness stems from the model's focus on robust features and\nits resistance to attacks that exploit non-predictive features. Besides these\npositive findings, we also identify several limitations. Under certain\nconditions (though unrealistic), no universally robust single-layer\ntransformers exist. Moreover, robust transformers exhibit an\naccuracy--robustness trade-off and require a large number of in-context\ndemonstrations. The code is available at\nhttps://github.com/s-kumano/universally-robust-in-context-learner.", "AI": {"tldr": "Adversarially pretrained transformers can act as robust foundation models, eliminating the need for adversarial training in downstream tasks.", "motivation": "To find a more efficient way to achieve robustness in transformers by avoiding costly adversarial training.", "method": "Using adversarial pretraining on transformers to enable robust generalization to unseen tasks via in-context learning.", "result": "A single adversarially pretrained transformer can robustly generalize to multiple unseen tasks without extra training or parameter updates.", "conclusion": "While this approach shows promise, there are limitations such as unrealistic conditions where no universally robust single-layer transformers exist, a trade-off between accuracy and robustness, and the requirement of many in-context demonstrations."}}
{"id": "2505.13831", "pdf": "https://arxiv.org/pdf/2505.13831", "abs": "https://arxiv.org/abs/2505.13831", "authors": ["Zongyuan Deng", "Yujie Cai", "Qing Liu", "Shiyao Mu", "Bin Lyu", "Zhen Yang"], "title": "TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning", "categories": ["cs.AI", "I.2; I.2.6; C.2.1"], "comment": "6 pages, 5 figures, 1 table, submitted to IEEE ICCC 2025", "summary": "The selection of base station sites is a critical challenge in 5G network\nplanning, which requires efficient optimization of coverage, cost, user\nsatisfaction, and practical constraints. Traditional manual methods, reliant on\nhuman expertise, suffer from inefficiencies and are limited to an unsatisfied\nplanning-construction consistency. Existing AI tools, despite improving\nefficiency in certain aspects, still struggle to meet the dynamic network\nconditions and multi-objective needs of telecom operators' networks. To address\nthese challenges, we propose TelePlanNet, an AI-driven framework tailored for\nthe selection of base station sites, integrating a three-layer architecture for\nefficient planning and large-scale automation. By leveraging large language\nmodels (LLMs) for real-time user input processing and intent alignment with\nbase station planning, combined with training the planning model using the\nimproved group relative policy optimization (GRPO) reinforcement learning, the\nproposed TelePlanNet can effectively address multi-objective optimization,\nevaluates candidate sites, and delivers practical solutions. Experiments\nresults show that the proposed TelePlanNet can improve the consistency to 78%,\nwhich is superior to the manual methods, providing telecom operators with an\nefficient and scalable tool that significantly advances cellular network\nplanning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTelePlanNet\u7684\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b35G\u7f51\u7edc\u89c4\u5212\u4e2d\u7684\u57fa\u7ad9\u9009\u5740\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u5b9e\u73b0\u9ad8\u6548\u89c4\u5212\u548c\u5927\u89c4\u6a21\u81ea\u52a8\u5316\uff0c\u5e76\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6539\u8fdb\u7684\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4e00\u81f4\u6027\u63d0\u9ad8\u523078%\uff0c\u4f18\u4e8e\u4f20\u7edf\u4eba\u5de5\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709AI\u5de5\u5177\u96be\u4ee5\u6ee1\u8db3\u7535\u4fe1\u8fd0\u8425\u5546\u7f51\u7edc\u52a8\u6001\u6761\u4ef6\u4e0b\u7684\u591a\u76ee\u6807\u9700\u6c42\uff0c\u4e14\u4f20\u7edf\u624b\u52a8\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u4e00\u81f4\u6027\u5dee\u3002", "method": "\u63d0\u51faTelePlanNet\u6846\u67b6\uff0c\u96c6\u6210\u4e09\u5c42\u67b6\u6784\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7528\u6237\u8f93\u5165\u5e76\u8fdb\u884c\u610f\u56fe\u5bf9\u9f50\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8bad\u7ec3\u89c4\u5212\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aTelePlanNet\u7684\u4e00\u81f4\u6027\u63d0\u5347\u81f378%\uff0c\u4f18\u4e8e\u624b\u52a8\u65b9\u6cd5\u3002", "conclusion": "TelePlanNet\u4e3a\u7535\u4fe1\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u3001\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u8702\u7a9d\u7f51\u7edc\u89c4\u5212\u3002"}}
{"id": "2505.14214", "pdf": "https://arxiv.org/pdf/2505.14214", "abs": "https://arxiv.org/abs/2505.14214", "authors": ["Mattes Mollenhauer", "Nicole M\u00fccke", "Dimitri Meunier", "Arthur Gretton"], "title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "62G08 (Primary) 62G35, 62J07 (Secondary)"], "comment": "32 pages, 1 figure", "summary": "This paper examines the performance of ridge regression in reproducing kernel\nHilbert spaces in the presence of noise that exhibits a finite number of higher\nmoments. We establish excess risk bounds consisting of subgaussian and\npolynomial terms based on the well known integral operator framework. The\ndominant subgaussian component allows to achieve convergence rates that have\npreviously only been derived under subexponential noise - a prevalent\nassumption in related work from the last two decades. These rates are optimal\nunder standard eigenvalue decay conditions, demonstrating the asymptotic\nrobustness of regularized least squares against heavy-tailed noise. Our\nderivations are based on a Fuk-Nagaev inequality for Hilbert-space valued\nrandom variables.", "AI": {"tldr": "This paper investigates the performance of ridge regression in Hilbert spaces with heavy-tailed noise, achieving optimal convergence rates under standard eigenvalue decay conditions.", "motivation": "To examine the robustness of regularized least squares methods against heavy-tailed noise in the context of reproducing kernel Hilbert spaces.", "method": "Establishing excess risk bounds using an integral operator framework and applying a Fuk-Nagaev inequality for Hilbert-space valued random variables.", "result": "Achieving convergence rates comparable to those derived under subexponential noise assumptions, thus demonstrating the robustness of regularized least squares methods.", "conclusion": "Regularized least squares methods exhibit asymptotic robustness against heavy-tailed noise in Hilbert spaces."}}
{"id": "2505.13851", "pdf": "https://arxiv.org/pdf/2505.13851", "abs": "https://arxiv.org/abs/2505.13851", "authors": ["Sahil Shah", "Harsh Goel", "Sai Shankar Narasimhan", "Minkyu Choi", "S P Sharan", "Oguzhan Akcin", "Sandeep Chinchali"], "title": "A Challenge to Build Neuro-Symbolic Video Agents", "categories": ["cs.AI"], "comment": null, "summary": "Modern video understanding systems excel at tasks such as scene\nclassification, object detection, and short video retrieval. However, as video\nanalysis becomes increasingly central to real-world applications, there is a\ngrowing need for proactive video agents for the systems that not only interpret\nvideo streams but also reason about events and take informed actions. A key\nobstacle in this direction is temporal reasoning: while deep learning models\nhave made remarkable progress in recognizing patterns within individual frames\nor short clips, they struggle to understand the sequencing and dependencies of\nevents over time, which is critical for action-driven decision-making.\nAddressing this limitation demands moving beyond conventional deep learning\napproaches. We posit that tackling this challenge requires a neuro-symbolic\nperspective, where video queries are decomposed into atomic events, structured\ninto coherent sequences, and validated against temporal constraints. Such an\napproach can enhance interpretability, enable structured reasoning, and provide\nstronger guarantees on system behavior, all key properties for advancing\ntrustworthy video agents. To this end, we present a grand challenge to the\nresearch community: developing the next generation of intelligent video agents\nthat integrate three core capabilities: (1) autonomous video search and\nanalysis, (2) seamless real-world interaction, and (3) advanced content\ngeneration. By addressing these pillars, we can transition from passive\nperception to intelligent video agents that reason, predict, and act, pushing\nthe boundaries of video understanding.", "AI": {"tldr": "This paper discusses the limitations of current video understanding systems and proposes a neuro-symbolic approach to improve their capabilities in temporal reasoning, event understanding, and action-driven decision-making.", "motivation": "There is a growing need for proactive video agents that can not only interpret video streams but also reason about events and take informed actions.", "method": "The authors propose a neuro-symbolic perspective that decomposes video queries into atomic events, structures them into coherent sequences, and validates them against temporal constraints.", "result": "The proposed approach can enhance interpretability, enable structured reasoning, and provide stronger guarantees on system behavior.", "conclusion": "The paper presents a grand challenge to the research community to develop the next generation of intelligent video agents with three core capabilities: autonomous video search and analysis, seamless real-world interaction, and advanced content generation."}}
{"id": "2505.14512", "pdf": "https://arxiv.org/pdf/2505.14512", "abs": "https://arxiv.org/abs/2505.14512", "authors": ["Juliusz Ziomek", "George Whittle", "Michael A. Osborne"], "title": "Just One Layer Norm Guarantees Stable Extrapolation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In spite of their prevalence, the behaviour of Neural Networks when\nextrapolating far from the training distribution remains poorly understood,\nwith existing results limited to specific cases. In this work, we prove general\nresults -- the first of their kind -- by applying Neural Tangent Kernel (NTK)\ntheory to analyse infinitely-wide neural networks trained until convergence and\nprove that the inclusion of just one Layer Norm (LN) fundamentally alters the\ninduced NTK, transforming it into a bounded-variance kernel. As a result, the\noutput of an infinitely wide network with at least one LN remains bounded, even\non inputs far from the training data. In contrast, we show that a broad class\nof networks without LN can produce pathologically large outputs for certain\ninputs. We support these theoretical findings with empirical experiments on\nfinite-width networks, demonstrating that while standard NNs often exhibit\nuncontrolled growth outside the training domain, a single LN layer effectively\nmitigates this instability. Finally, we explore real-world implications of this\nextrapolatory stability, including applications to predicting residue sizes in\nproteins larger than those seen during training and estimating age from facial\nimages of underrepresented ethnicities absent from the training set.", "AI": {"tldr": "This work proves general results about the behavior of neural networks when extrapolating far from the training distribution using Neural Tangent Kernel (NTK) theory.", "motivation": "Understanding the behavior of neural networks when extrapolating beyond the training data is important but has been poorly understood so far.", "method": "Applying Neural Tangent Kernel (NTK) theory to analyze infinitely-wide neural networks trained until convergence.", "result": "The inclusion of just one Layer Norm (LN) fundamentally alters the induced NTK, making the output of an infinitely wide network with at least one LN remain bounded, even on inputs far from the training data.", "conclusion": "Adding a single Layer Norm can prevent uncontrolled growth in neural networks, which is crucial for tasks like protein residue size prediction and age estimation from underrepresented ethnicities."}}
{"id": "2505.13887", "pdf": "https://arxiv.org/pdf/2505.13887", "abs": "https://arxiv.org/abs/2505.13887", "authors": ["Junyang Wang", "Haiyang Xu", "Xi Zhang", "Ming Yan", "Ji Zhang", "Fei Huang", "Jitao Sang"], "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation", "categories": ["cs.AI", "cs.CL"], "comment": "17 pages, 7 figures, 9 tables. arXiv admin note: substantial text\n  overlap with arXiv:2502.17110", "summary": "The exponential rise in mobile device usage necessitates streamlined\nautomation for effective task management, yet many AI frameworks fall short due\nto inadequate operational expertise. While manually written knowledge can\nbridge this gap, it is often burdensome and inefficient. We introduce\nMobile-Agent-V, an innovative framework that utilizes video as a guiding tool\nto effortlessly and efficiently inject operational knowledge into mobile\nautomation processes. By deriving knowledge directly from video content,\nMobile-Agent-V eliminates manual intervention, significantly reducing the\neffort and time required for knowledge acquisition. To rigorously evaluate this\napproach, we propose Mobile-Knowledge, a benchmark tailored to assess the\nimpact of external knowledge on mobile agent performance. Our experimental\nfindings demonstrate that Mobile-Agent-V enhances performance by 36% compared\nto existing methods, underscoring its effortless and efficient advantages in\nmobile automation.", "AI": {"tldr": "An innovative framework named Mobile-Agent-V is introduced which uses video content to inject operational knowledge into mobile automation processes, improving performance by 36%.", "motivation": "The need for streamlined automation for effective task management in mobile devices due to their rising usage, with current AI frameworks lacking operational expertise.", "method": "Utilizing video as a guiding tool to inject operational knowledge into mobile automation processes without manual intervention.", "result": "Performance enhancement by 36% compared to existing methods.", "conclusion": "Mobile-Agent-V proves to be a more effortless and efficient solution for mobile automation."}}
{"id": "2505.13631", "pdf": "https://arxiv.org/pdf/2505.13631", "abs": "https://arxiv.org/abs/2505.13631", "authors": ["Andrei Manolache", "Luiz F. O. Chamon", "Mathias Niepert"], "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Equivariant neural networks are designed to respect symmetries through their\narchitecture, boosting generalization and sample efficiency when those\nsymmetries are present in the data distribution. Real-world data, however,\noften departs from perfect symmetry because of noise, structural variation,\nmeasurement bias, or other symmetry-breaking effects. Strictly equivariant\nmodels may struggle to fit the data, while unconstrained models lack a\nprincipled way to leverage partial symmetries. Even when the data is fully\nsymmetric, enforcing equivariance can hurt training by limiting the model to a\nrestricted region of the parameter space. Guided by homotopy principles, where\nan optimization problem is solved by gradually transforming a simpler problem\ninto a complex one, we introduce Adaptive Constrained Equivariance (ACE), a\nconstrained optimization approach that starts with a flexible, non-equivariant\nmodel and gradually reduces its deviation from equivariance. This gradual\ntightening smooths training early on and settles the model at a data-driven\nequilibrium, balancing between equivariance and non-equivariance. Across\nmultiple architectures and tasks, our method consistently improves performance\nmetrics, sample efficiency, and robustness to input perturbations compared with\nstrictly equivariant models and heuristic equivariance relaxations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdaptive Constrained Equivariance (ACE) \u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u53d7\u540c\u4f26\u539f\u5219\u542f\u53d1\uff0c\u4ece\u7075\u6d3b\u7684\u975e\u7b49\u53d8\u6a21\u578b\u5f00\u59cb\uff0c\u5e76\u9010\u6e10\u51cf\u5c11\u5176\u4e0e\u7b49\u53d8\u6027\u7684\u504f\u5dee\u3002ACE\u5728\u591a\u4e2a\u67b6\u6784\u548c\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\u6307\u6807\u3001\u6837\u672c\u6548\u7387\u4ee5\u53ca\u5bf9\u8f93\u5165\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u5f80\u5f80\u504f\u79bb\u5b8c\u7f8e\u5bf9\u79f0\u6027\uff0c\u4e25\u683c\u7b49\u53d8\u6a21\u578b\u53ef\u80fd\u96be\u4ee5\u62df\u5408\u6570\u636e\uff0c\u800c\u65e0\u7ea6\u675f\u6a21\u578b\u7f3a\u4e4f\u6709\u6548\u5229\u7528\u90e8\u5206\u5bf9\u79f0\u6027\u7684\u539f\u5219\u6027\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5728\u6570\u636e\u5b8c\u5168\u5bf9\u79f0\u7684\u60c5\u51b5\u4e0b\uff0c\u5f3a\u5236\u7b49\u53d8\u53ef\u80fd\u4f1a\u901a\u8fc7\u9650\u5236\u6a21\u578b\u7684\u53c2\u6570\u7a7a\u95f4\u6765\u635f\u5bb3\u8bad\u7ec3\u3002", "method": "\u5f15\u5165\u4e86Adaptive Constrained Equivariance (ACE)\uff0c\u8fd9\u662f\u4e00\u79cd\u53d7\u540c\u4f26\u539f\u5219\u542f\u53d1\u7684\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5\uff0c\u5b83\u4ece\u7075\u6d3b\u7684\u975e\u7b49\u53d8\u6a21\u578b\u5f00\u59cb\uff0c\u5e76\u9010\u6e10\u51cf\u5c11\u5176\u4e0e\u7b49\u53d8\u6027\u7684\u504f\u5dee\u3002", "result": "ACE\u5728\u591a\u4e2a\u67b6\u6784\u548c\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\u6307\u6807\u3001\u6837\u672c\u6548\u7387\u4ee5\u53ca\u5bf9\u8f93\u5165\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "ACE\u63d0\u4f9b\u4e86\u4e00\u79cd\u5e73\u8861\u7b49\u53d8\u6027\u548c\u975e\u7b49\u53d8\u6027\u7684\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3001\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.14596", "pdf": "https://arxiv.org/pdf/2505.14596", "abs": "https://arxiv.org/abs/2505.14596", "authors": ["Isabella Degen", "Zahraa S Abdallah", "Henry W J Reeve", "Kate Robson Brown"], "title": "CSTS: A Benchmark for the Discovery of Correlation Structures in Time Series Clustering", "categories": ["cs.LG", "stat.ML", "62H30, 62H20, 62-11, 68T10, 62M10,", "I.5.3; H.2.8; G.3; I.2.6"], "comment": "9 pages main + 32 pages total, 2 figures main + 6 figures appendix, 1\n  table main + 17 tables appendix, dataset available at\n  https://huggingface.co/datasets/idegen/csts, code available at\n  https://github.com/isabelladegen/corrclust-validation", "summary": "Time series clustering promises to uncover hidden structural patterns in data\nwith applications across healthcare, finance, industrial systems, and other\ncritical domains. However, without validated ground truth information,\nresearchers cannot objectively assess clustering quality or determine whether\npoor results stem from absent structures in the data, algorithmic limitations,\nor inappropriate validation methods, raising the question whether clustering is\n\"more art than science\" (Guyon et al., 2009). To address these challenges, we\nintroduce CSTS (Correlation Structures in Time Series), a synthetic benchmark\nfor evaluating the discovery of correlation structures in multivariate time\nseries data. CSTS provides a clean benchmark that enables researchers to\nisolate and identify specific causes of clustering failures by differentiating\nbetween correlation structure deterioration and limitations of clustering\nalgorithms and validation methods. Our contributions are: (1) a comprehensive\nbenchmark for correlation structure discovery with distinct correlation\nstructures, systematically varied data conditions, established performance\nthresholds, and recommended evaluation protocols; (2) empirical validation of\ncorrelation structure preservation showing moderate distortion from\ndownsampling and minimal effects from distribution shifts and sparsification;\nand (3) an extensible data generation framework enabling structure-first\nclustering evaluation. A case study demonstrates CSTS's practical utility by\nidentifying an algorithm's previously undocumented sensitivity to non-normal\ndistributions, illustrating how the benchmark enables precise diagnosis of\nmethodological limitations. CSTS advances rigorous evaluation standards for\ncorrelation-based time series clustering.", "AI": {"tldr": "\u63d0\u51faCSTS\uff08\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u76f8\u5173\u7ed3\u6784\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u76f8\u5173\u7ed3\u6784\u53d1\u73b0\u7684\u5408\u6210\u57fa\u51c6\u3002CSTS\u901a\u8fc7\u533a\u5206\u76f8\u5173\u7ed3\u6784\u9000\u5316\u548c\u805a\u7c7b\u7b97\u6cd5\u53ca\u9a8c\u8bc1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u9694\u79bb\u5e76\u8bc6\u522b\u805a\u7c7b\u5931\u8d25\u7684\u5177\u4f53\u539f\u56e0\u3002\u8d21\u732e\u5305\u62ec\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u3001\u76f8\u5173\u7ed3\u6784\u4fdd\u5b58\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u4ee5\u53ca\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u6846\u67b6\u3002\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86CSTS\u5728\u8bca\u65ad\u65b9\u6cd5\u9650\u5236\u65b9\u9762\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u805a\u7c7b\u5728\u591a\u4e2a\u5173\u952e\u9886\u57df\u6709\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u7684\u5730\u9762\u771f\u5b9e\u4fe1\u606f\u4f7f\u5f97\u65e0\u6cd5\u5ba2\u89c2\u8bc4\u4f30\u805a\u7c7b\u8d28\u91cf\u3002", "method": "\u5f15\u5165CSTS\u4f5c\u4e3a\u5408\u6210\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u76f8\u5173\u7ed3\u6784\u7684\u53d1\u73b0\u3002", "result": "CSTS\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u57fa\u51c6\uff0c\u53ef\u4ee5\u9694\u79bb\u5e76\u8bc6\u522b\u805a\u7c7b\u5931\u8d25\u7684\u5177\u4f53\u539f\u56e0\u3002\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u76f8\u5173\u7ed3\u6784\u4fdd\u5b58\u7684\u60c5\u51b5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u6846\u67b6\u3002", "conclusion": "CSTS\u63a8\u8fdb\u4e86\u57fa\u4e8e\u76f8\u5173\u7684\u65f6\u95f4\u5e8f\u5217\u805a\u7c7b\u7684\u4e25\u683c\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2505.13909", "pdf": "https://arxiv.org/pdf/2505.13909", "abs": "https://arxiv.org/abs/2505.13909", "authors": ["Yanheng He", "Jiahe Jin", "Pengfei Liu"], "title": "Efficient Agent Training for Computer Use", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "We open-source our entire suite of code, data, and models to\n  facilitate future research at https://github.com/GAIR-NLP/PC-Agent-E", "summary": "Scaling up high-quality trajectory data has long been a critical bottleneck\nfor developing human-like computer use agents. We introduce PC Agent-E, an\nefficient agent training framework that significantly reduces reliance on\nlarge-scale human demonstrations. Starting with just 312 human-annotated\ncomputer use trajectories, we further improved data quality by synthesizing\ndiverse action decisions with Claude 3.7 Sonnet. Trained on these enriched\ntrajectories, our PC Agent-E model achieved a remarkable 141% relative\nimprovement, surpassing the strong Claude 3.7 Sonnet with extended thinking on\nWindowsAgentArena-V2, an improved benchmark we also released. Furthermore, PC\nAgent-E demonstrates strong generalizability to different operating systems on\nOSWorld. Our findings suggest that strong computer use capabilities can be\nstimulated from a small amount of high-quality trajectory data.", "AI": {"tldr": "\u63d0\u51faPC Agent-E\u6846\u67b6\uff0c\u901a\u8fc7\u5c11\u91cf\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6570\u636e\u5b9e\u73b0\u5f3a\u8ba1\u7b97\u673a\u4f7f\u7528\u80fd\u529b\uff0c\u5e76\u5728\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u4e0a\u5c55\u793a\u826f\u597d\u6cdb\u5316\u6027\u3002", "motivation": "\u89e3\u51b3\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6570\u636e\u7f3a\u4e4f\u7684\u95ee\u9898\u4ee5\u5f00\u53d1\u7c7b\u4eba\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u3002", "method": "\u5f15\u5165PC Agent-E\u6846\u67b6\uff0c\u5229\u7528\u5408\u6210\u591a\u6837\u5316\u52a8\u4f5c\u51b3\u7b56\u63d0\u5347\u6570\u636e\u8d28\u91cf\u5e76\u8bad\u7ec3\u6a21\u578b\u3002", "result": "PC Agent-E\u6a21\u578b\u5728WindowsAgentArena-V2\u4e0a\u76f8\u5bf9\u63d0\u5347\u4e86141%\uff0c\u5e76\u5728OSWorld\u4e0a\u5c55\u793a\u4e86\u8de8\u64cd\u4f5c\u7cfb\u7edf\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c11\u91cf\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6570\u636e\u5373\u53ef\u6fc0\u53d1\u5f3a\u5927\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u80fd\u529b\u3002"}}
{"id": "2505.13636", "pdf": "https://arxiv.org/pdf/2505.13636", "abs": "https://arxiv.org/abs/2505.13636", "authors": ["Baiting Chen", "Tong Zhu", "Jiale Han", "Lexin Li", "Gang Li", "Xiaowu Dai"], "title": "Incentivizing Truthful Language Models via Peer Elicitation Games", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where rewards are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning.", "AI": {"tldr": "Introduce Peer Elicitation Games (PEG), a training-free framework for aligning LLMs through peer evaluation, proving sublinear regret and convergence to truthful Nash equilibrium, demonstrating factual accuracy improvement.", "motivation": "Improve the consistency and reduce hallucinations in LLMs without supervision or fine-tuning.", "method": "PEG framework with generator and discriminators using determinant-based mutual information score.", "result": "Significant factual accuracy improvement across multiple benchmarks.", "conclusion": "PEG is a practical approach for eliciting truthful behavior from LLMs."}}
{"id": "2505.13914", "pdf": "https://arxiv.org/pdf/2505.13914", "abs": "https://arxiv.org/abs/2505.13914", "authors": ["Jake Chandler", "Richard Booth"], "title": "Parallel Belief Revision via Order Aggregation", "categories": ["cs.AI", "I.2.4"], "comment": null, "summary": "Despite efforts to better understand the constraints that operate on\nsingle-step parallel (aka \"package\", \"multiple\") revision, very little work has\nbeen carried out on how to extend the model to the iterated case. A recent\npaper by Delgrande & Jin outlines a range of relevant rationality postulates.\nWhile many of these are plausible, they lack an underlying unifying\nexplanation. We draw on recent work on iterated parallel contraction to offer a\ngeneral method for extending serial iterated belief revision operators to\nhandle parallel change. This method, based on a family of order aggregators\nknown as TeamQueue aggregators, provides a principled way to recover the\nindependently plausible properties that can be found in the literature, without\nyielding the more dubious ones.", "AI": {"tldr": "This paper introduces a method based on TeamQueue aggregators to extend serial iterated belief revision operators for handling parallel change, aiming to recover plausible properties while avoiding dubious ones.", "motivation": "Extending the single-step parallel revision model to the iterated case lacks an underlying unifying explanation.", "method": "Using TeamQueue aggregators to develop a general method for extending serial iterated belief revision operators.", "result": "A method that can recover independently plausible properties without yielding dubious ones.", "conclusion": "The proposed method provides a principled approach to handle parallel change in iterated belief revision."}}
{"id": "2505.13638", "pdf": "https://arxiv.org/pdf/2505.13638", "abs": "https://arxiv.org/abs/2505.13638", "authors": ["Massimo Fioravanti", "Giovanni Agosta"], "title": "4Hammer: a board-game reinforcement learning environment for the hour long time frame", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance on tasks\nwith short time frames, but struggle with tasks requiring longer durations.\nWhile datasets covering extended-duration tasks, such as software engineering\ntasks or video games, do exist, there are currently few implementations of\ncomplex board games specifically designed for reinforcement learning and LLM\nevaluation. To address this gap, we propose the 4Hammer reinforcement learning\nenvironment, a digital twin simulation of a subset of Warhammer 40,000-a\ncomplex, zero-sum board game. Warhammer 40,000 features intricate rules,\nrequiring human players to thoroughly read and understand over 50 pages of\ndetailed natural language rules, grasp the interactions between their game\npieces and those of their opponents, and independently track and communicate\nthe evolving game state.", "AI": {"tldr": "This paper introduces the 4Hammer reinforcement learning environment, which simulates a subset of the complex board game Warhammer 40,000 to address the lack of such environments for evaluating large language models.", "motivation": "There is a need for more complex board game environments designed for reinforcement learning and evaluation of large language models.", "method": "The proposed 4Hammer environment simulates a subset of Warhammer 40,000, a complex board game with intricate rules.", "result": "The 4Hammer environment provides a platform for evaluating LLMs in tasks that require understanding complex rules and interactions.", "conclusion": "The introduction of 4Hammer fills a gap in the availability of complex board game environments for reinforcement learning and LLM evaluation."}}
{"id": "2505.13940", "pdf": "https://arxiv.org/pdf/2505.13940", "abs": "https://arxiv.org/abs/2505.13940", "authors": ["Kun Li", "Zhennan Wu", "Shoupeng Wang", "Wenbin Hu"], "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery", "categories": ["cs.AI", "q-bio.BM"], "comment": "22 pages, 10 figures, 5 tables", "summary": "In the field of AI4Science, large-scale language models (LLMs) show great\npotential to parse complex scientific semantics, integrate cross-disciplinary\nknowledge, and assist critical task research. However, in the field of drug\ndiscovery, despite the optimization through professional data pre-training,\ncontext window expansion, and internet search, the existing LLMs are still\nfacing challenges such as massive multi-modal and heterogeneous data\nprocessing, domain knowledge dynamic updating delay, and insufficient\nconfidence in predicting the results of complex computational tasks. To address\nthese challenges, we propose the DrugPilot, an LLM-based agent with\nparameterized reasoning for drug discovery. DrugPilot addresses key limitations\nof traditional end-to-end LLM prediction approaches through its parametric\ninference architecture. This agent system supports major phases of the drug\ndiscovery pipeline, facilitating automated planning and execution of\nmulti-stage research tasks. To address the critical challenge of multi-modal\ndrug data analysis (incorporating both public datasets and user-submitted\ndata), we developed an interactive parameterized memory pool. This innovative\ncomponent standardizes real-world drug data into parametric representations,\nsimultaneously enabling efficient knowledge retrieval in multi-turn dialogue\nwhile mitigating the information loss inherent in text-based data transmission.\nAdditionally, we created a drug instruct dataset across 8 essential drug\ndiscovery tasks for model fine-tuning and evaluation. Based on the Berkeley\nfunction calling evaluation framework, DrugPilot demonstrated the most advanced\ntool calling capabilities on our drug discovery tool instruction dataset,\noutperforming existing agents (e.g., ReAct, LoT). Specifically, it achieves\ntask completion rates of 98.0%, 93.5%, and 64.0% on simple, multiple, and\nmulti-turn tasks, respectively.", "AI": {"tldr": "DrugPilot\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u836f\u7269\u53d1\u73b0\u4ee3\u7406\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u63a8\u7406\u67b6\u6784\u89e3\u51b3\u73b0\u6709LLM\u5728\u836f\u7269\u53d1\u73b0\u9886\u57df\u7684\u6311\u6218\uff0c\u5e76\u5c55\u793a\u51fa\u5353\u8d8a\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u836f\u7269\u53d1\u73b0\u9886\u57df\u9762\u4e34\u5982\u591a\u6a21\u6001\u5f02\u6784\u6570\u636e\u5904\u7406\u3001\u9886\u57df\u77e5\u8bc6\u52a8\u6001\u66f4\u65b0\u5ef6\u8fdf\u4ee5\u53ca\u590d\u6742\u8ba1\u7b97\u4efb\u52a1\u7ed3\u679c\u9884\u6d4b\u4fe1\u5fc3\u4e0d\u8db3\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86DrugPilot\uff0c\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u5b83\u5305\u62ec\u53c2\u6570\u5316\u63a8\u7406\u67b6\u6784\u548c\u4ea4\u4e92\u5f0f\u53c2\u6570\u5316\u8bb0\u5fc6\u6c60\u6765\u5904\u7406\u591a\u6a21\u6001\u836f\u7269\u6570\u636e\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b8\u4e2a\u5173\u952e\u836f\u7269\u53d1\u73b0\u4efb\u52a1\u7684\u6570\u636e\u96c6\u7528\u4e8e\u6a21\u578b\u5fae\u8c03\u548c\u8bc4\u4f30\u3002", "result": "DrugPilot\u5728\u836f\u7269\u53d1\u73b0\u5de5\u5177\u6307\u4ee4\u6570\u636e\u96c6\u4e0a\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u8d85\u8d8a\u4e86\u73b0\u6709\u4ee3\u7406\uff08\u5982ReAct\uff0cLoT\uff09\uff0c\u5e76\u4e14\u5728\u7b80\u5355\u3001\u591a\u6b65\u9aa4\u548c\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5206\u522b\u4e3a98.0%\uff0c93.5%\u548c64.0%\u3002", "conclusion": "DrugPilot\u5c55\u793a\u4e86\u5728\u836f\u7269\u53d1\u73b0\u9886\u57df\u4e2d\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u5176\u53c2\u6570\u63a8\u7406\u67b6\u6784\u89e3\u51b3\u4e86\u4f20\u7edf\u7aef\u5230\u7aefLLM\u9884\u6d4b\u65b9\u6cd5\u7684\u5173\u952e\u9650\u5236\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u836f\u7269\u6307\u4ee4\u6570\u636e\u96c6\u7684\u5fae\u8c03\u548c\u8bc4\u4f30\uff0cDrugPilot\u5728\u7b80\u5355\u3001\u591a\u6b65\u9aa4\u548c\u591a\u8f6e\u4efb\u52a1\u4e0a\u5206\u522b\u8fbe\u5230\u4e8698.0%\uff0c93.5%\u548c64.0%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u3002"}}
{"id": "2505.13643", "pdf": "https://arxiv.org/pdf/2505.13643", "abs": "https://arxiv.org/abs/2505.13643", "authors": ["Rakibul Hasan Rajib", "Md Akil Raihan Iftee", "Mir Sazzat Hossain", "A. K. M. Mahbubur Rahman", "Sajib Mistry", "M Ashraful Amin", "Amin Ahsan Ali"], "title": "FedCTTA: A Collaborative Approach to Continual Test-Time Adaptation in Federated Learning", "categories": ["cs.LG", "cs.CV"], "comment": "8 pages, 5 figures, Accepted In IJCNN 2025", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it ideal for\nprivacy-sensitive applications. However, FL models often suffer performance\ndegradation due to distribution shifts between training and deployment.\nTest-Time Adaptation (TTA) offers a promising solution by allowing models to\nadapt using only test samples. However, existing TTA methods in FL face\nchallenges such as computational overhead, privacy risks from feature sharing,\nand scalability concerns due to memory constraints. To address these\nlimitations, we propose Federated Continual Test-Time Adaptation (FedCTTA), a\nprivacy-preserving and computationally efficient framework for federated\nadaptation. Unlike prior methods that rely on sharing local feature statistics,\nFedCTTA avoids direct feature exchange by leveraging similarity-aware\naggregation based on model output distributions over randomly generated noise\nsamples. This approach ensures adaptive knowledge sharing while preserving data\nprivacy. Furthermore, FedCTTA minimizes the entropy at each client for\ncontinual adaptation, enhancing the model's confidence in evolving target\ndistributions. Our method eliminates the need for server-side training during\nadaptation and maintains a constant memory footprint, making it scalable even\nas the number of clients or training rounds increases. Extensive experiments\nshow that FedCTTA surpasses existing methods across diverse temporal and\nspatial heterogeneity scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u9002\u5e94\u65b9\u6cd5FedCTTA\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u7684\u76f8\u4f3c\u6027\u611f\u77e5\u805a\u5408\u6765\u907f\u514d\u76f4\u63a5\u7279\u5f81\u4ea4\u6362\uff0c\u4ece\u800c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u548c\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u81ea\u9002\u5e94\u77e5\u8bc6\u5171\u4eab\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFedCTTA\u5728\u5404\u79cd\u65f6\u95f4\u5f02\u6784\u6027\u548c\u7a7a\u95f4\u5f02\u6784\u6027\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "FL\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u90e8\u7f72\u4e4b\u95f4\u5b58\u5728\u5206\u5e03\u504f\u79fb\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff1b\u73b0\u6709\u7684TTA\u65b9\u6cd5\u5728FL\u4e2d\u9762\u4e34\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u9690\u79c1\u98ce\u9669\u548c\u53ef\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faFedCTTA\u6846\u67b6\uff0c\u5229\u7528\u76f8\u4f3c\u6027\u611f\u77e5\u805a\u5408\u57fa\u4e8e\u968f\u673a\u751f\u6210\u7684\u566a\u58f0\u6837\u672c\u7684\u6a21\u578b\u8f93\u51fa\u5206\u5e03\uff0c\u907f\u514d\u76f4\u63a5\u7279\u5f81\u4ea4\u6362\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u71b5\u4ee5\u6301\u7eed\u9002\u5e94\u3002", "result": "FedCTTA\u5728\u5404\u79cd\u5f02\u6784\u6027\u573a\u666f\u4e0b\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u65b9\u6cd5\u3002", "conclusion": "FedCTTA\u662f\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u8054\u90a6\u9002\u5e94\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2505.13946", "pdf": "https://arxiv.org/pdf/2505.13946", "abs": "https://arxiv.org/abs/2505.13946", "authors": ["Changdae Oh", "Jiatong Li", "Shawn Im", "Yixuan Li"], "title": "Visual Instruction Bottleneck Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Despite widespread adoption, multimodal large language models (MLLMs) suffer\nperformance degradation when encountering unfamiliar queries under distribution\nshifts. Existing methods to improve MLLM generalization typically require\neither more instruction data or larger advanced model architectures, both of\nwhich incur non-trivial human labor or computational costs. In this work, we\ntake an alternative approach to enhance the robustness of MLLMs under\ndistribution shifts, from a representation learning perspective. Inspired by\nthe information bottleneck (IB) principle, we derive a variational lower bound\nof the IB for MLLMs and devise a practical implementation, Visual Instruction\nBottleneck Tuning (Vittle). We then provide a theoretical justification of\nVittle by revealing its connection to an information-theoretic robustness\nmetric of MLLM. Empirical validation of three MLLMs on open-ended and\nclosed-form question answering and object hallucination detection tasks over 45\ndatasets, including 30 shift scenarios, demonstrates that Vittle consistently\nimproves the MLLM's robustness under shifts by pursuing the learning of a\nminimal sufficient representation.", "AI": {"tldr": "This paper proposes Vittle, a method inspired by the information bottleneck principle, to improve the robustness of multimodal large language models under distribution shifts without requiring additional instruction data or larger model architectures.", "motivation": "To address the performance degradation of multimodal large language models when encountering unfamiliar queries under distribution shifts.", "method": "Deriving a variational lower bound of the information bottleneck for MLLMs and devising Visual Instruction Bottleneck Tuning (Vittle).", "result": "Empirical validation shows that Vittle improves the robustness of MLLMs under shifts by learning a minimal sufficient representation.", "conclusion": "Vittle provides a practical way to enhance the robustness of MLLMs under distribution shifts from a representation learning perspective."}}
{"id": "2505.13644", "pdf": "https://arxiv.org/pdf/2505.13644", "abs": "https://arxiv.org/abs/2505.13644", "authors": ["Felix Dangel", "Tim Siebert", "Marius Zeinhofer", "Andrea Walther"], "title": "Collapsing Taylor Mode Automatic Differentiation", "categories": ["cs.LG"], "comment": "10 pages + appendix", "summary": "Computing partial differential equation (PDE) operators via nested\nbackpropagation is expensive, yet popular, and severely restricts their utility\nfor scientific machine learning. Recent advances, like the forward Laplacian\nand randomizing Taylor mode automatic differentiation (AD), propose forward\nschemes to address this. We introduce an optimization technique for Taylor mode\nthat 'collapses' derivatives by rewriting the computational graph, and\ndemonstrate how to apply it to general linear PDE operators, and randomized\nTaylor mode. The modifications simply require propagating a sum up the\ncomputational graph, which could -- or should -- be done by a machine learning\ncompiler, without exposing complexity to users. We implement our collapsing\nprocedure and evaluate it on popular PDE operators, confirming it accelerates\nTaylor mode and outperforms nested backpropagation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6cf0\u52d2\u6a21\u5f0f\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u5199\u8ba1\u7b97\u56fe\u6765\u52a0\u901f\u6cf0\u52d2\u6a21\u5f0f\uff0c\u5e76\u5728\u5e38\u89c1\u504f\u5fae\u5206\u65b9\u7a0b\u7b97\u5b50\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u90e8\u5206\u5fae\u5206\u65b9\u7a0b(PDE)\u7b97\u5b50\u8ba1\u7b97\u65b9\u5f0f\u6602\u8d35\u4e14\u9650\u5236\u4e86\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u4f18\u5316\u6cf0\u52d2\u6a21\u5f0f\u7684\u8ba1\u7b97\u6280\u672f\uff0c\u5373\u901a\u8fc7\u91cd\u5199\u8ba1\u7b97\u56fe\u6765\u7b80\u5316\u5bfc\u6570\u8ba1\u7b97\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u822c\u7ebf\u6027PDE\u7b97\u5b50\u548c\u968f\u673a\u6cf0\u52d2\u6a21\u5f0f\u3002", "result": "\u8be5\u65b9\u6cd5\u53ea\u9700\u8981\u6cbf\u7740\u8ba1\u7b97\u56fe\u4f20\u64ad\u4e00\u4e2a\u603b\u548c\uff0c\u53ef\u4ee5\u52a0\u901f\u6cf0\u52d2\u6a21\u5f0f\u5e76\u4f18\u4e8e\u5d4c\u5957\u53cd\u5411\u4f20\u64ad\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f18\u5316\u6280\u672f\u53ef\u4ee5\u6709\u6548\u52a0\u901fPDE\u7b97\u5b50\u7684\u8ba1\u7b97\uff0c\u63d0\u5347\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2505.13986", "pdf": "https://arxiv.org/pdf/2505.13986", "abs": "https://arxiv.org/abs/2505.13986", "authors": ["Qize Jiang", "Linsey Pang", "Alice Gatti", "Mahima Aggarwa", "Giovanna Vantin", "Xiaosong Ma", "Weiwei Sun", "Sanjay Chawla"], "title": "Solving Normalized Cut Problem with Constrained Action Space", "categories": ["cs.AI", "cs.LG", "I.2.8"], "comment": null, "summary": "Reinforcement Learning (RL) has emerged as an important paradigm to solve\ncombinatorial optimization problems primarily due to its ability to learn\nheuristics that can generalize across problem instances. However, integrating\nexternal knowledge that will steer combinatorial optimization problem solutions\ntowards domain appropriate outcomes remains an extremely challenging task. In\nthis paper, we propose the first RL solution that uses constrained action\nspaces to guide the normalized cut problem towards pre-defined template\ninstances. Using transportation networks as an example domain, we create a\nWedge and Ring Transformer that results in graph partitions that are shaped in\nform of Wedges and Rings and which are likely to be closer to natural optimal\npartitions. However, our approach is general as it is based on principles that\ncan be generalized to other domains.", "AI": {"tldr": "This paper presents an RL-based method using constrained action spaces to guide the normalized cut problem towards predefined templates for graph partitioning.", "motivation": "To integrate external knowledge into RL solutions for combinatorial optimization problems.", "method": "Proposes an RL solution with constrained action spaces to guide the normalized cut problem, creating a Wedge and Ring Transformer for graph partitioning.", "result": "Graph partitions shaped like Wedges and Rings that are close to natural optimal partitions.", "conclusion": "The approach is generalizable across different domains."}}
{"id": "2505.13650", "pdf": "https://arxiv.org/pdf/2505.13650", "abs": "https://arxiv.org/abs/2505.13650", "authors": ["Chou-Ying Hsieh", "Chun-Fu Jang", "Cheng-En Hsieh", "Qian-Hui Chen", "Sy-Yen Kuo"], "title": "Self-Reinforced Graph Contrastive Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graphs serve as versatile data structures in numerous real-world\ndomains-including social networks, molecular biology, and knowledge graphs-by\ncapturing intricate relational information among entities. Among graph-based\nlearning techniques, Graph Contrastive Learning (GCL) has gained significant\nattention for its ability to derive robust, self-supervised graph\nrepresentations through the contrasting of positive and negative sample pairs.\nHowever, a critical challenge lies in ensuring high-quality positive pairs so\nthat the intrinsic semantic and structural properties of the original graph are\npreserved rather than distorted. To address this issue, we propose SRGCL\n(Self-Reinforced Graph Contrastive Learning), a novel framework that leverages\nthe model's own encoder to dynamically evaluate and select high-quality\npositive pairs. We designed a unified positive pair generator employing\nmultiple augmentation strategies, and a selector guided by the manifold\nhypothesis to maintain the underlying geometry of the latent space. By adopting\na probabilistic mechanism for selecting positive pairs, SRGCL iteratively\nrefines its assessment of pair quality as the encoder's representational power\nimproves. Extensive experiments on diverse graph-level classification tasks\ndemonstrate that SRGCL, as a plug-in module, consistently outperforms\nstate-of-the-art GCL methods, underscoring its adaptability and efficacy across\nvarious domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6SRGCL\uff0c\u901a\u8fc7\u81ea\u8eab\u7f16\u7801\u5668\u52a8\u6001\u8bc4\u4f30\u548c\u9009\u62e9\u9ad8\u8d28\u91cf\u6b63\u6837\u672c\u5bf9\uff0c\u6539\u8fdb\u4e86\u56fe\u8868\u793a\u7684\u8d28\u91cf\uff0c\u5e76\u5728\u591a\u79cd\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u786e\u4fdd\u9ad8\u8d28\u7684\u6b63\u6837\u672c\u5bf9\u4ee5\u4fdd\u7559\u539f\u56fe\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u7279\u6027\u3002", "method": "\u63d0\u51faSRGCL\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u589e\u5f3a\u7b56\u7565\u751f\u6210\u6b63\u6837\u672c\u5bf9\uff0c\u5e76\u91c7\u7528\u6d41\u5f62\u5047\u8bbe\u5f15\u5bfc\u7684\u9009\u62e9\u5668\u6765\u4fdd\u6301\u6f5c\u5728\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "result": "\u5728\u4e0d\u540c\u56fe\u7ea7\u522b\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cSRGCL\u4f5c\u4e3a\u63d2\u4ef6\u6a21\u5757\u7684\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684GCL\u65b9\u6cd5\u3002", "conclusion": "SRGCL\u5177\u6709\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u591a\u4e2a\u9886\u57df\u3002"}}
{"id": "2505.13994", "pdf": "https://arxiv.org/pdf/2505.13994", "abs": "https://arxiv.org/abs/2505.13994", "authors": ["Ruiyi Yang", "Hao Xue", "Imran Razzak", "Hakim Hacid", "Flora D. Salim"], "title": "Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning", "categories": ["cs.AI", "cs.IR", "cs.MA"], "comment": "20 pages, 4 figures", "summary": "Retrieval-Augmented Generation (RAG) systems empower large language models\n(LLMs) with external knowledge, yet struggle with efficiency-accuracy\ntrade-offs when scaling to large knowledge graphs. Existing approaches often\nrely on monolithic graph retrieval, incurring unnecessary latency for simple\nqueries and fragmented reasoning for complex multi-hop questions. To address\nthese challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework\nthat addresses these limitations with question-driven semantic graph\npartitioning and collaborative subgraph retrieval. The innovative framework\nfirst create Semantic Partitioning of Linked Information, then use the\nType-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware\ngraph segmentation manages to divide knowledge graphs into semantically\ncoherent subgraphs, ensuring subgraphs align with different query types, while\nlightweight LLM agents are assigned to partitioned subgraphs, and only relevant\npartitions are activated during retrieval, thus reduce search space while\nenhancing efficiency. Finally, a hierarchical merging module resolves\ninconsistencies across subgraph-derived answers through logical verifications.\nExtensive experimental validation demonstrates considerable improvements\ncompared to existing approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4ee3\u7406RAG\u6846\u67b6SPLIT-RAG\uff0c\u5b83\u901a\u8fc7\u95ee\u9898\u9a71\u52a8\u7684\u8bed\u4e49\u56fe\u5212\u5206\u548c\u534f\u4f5c\u5b50\u56fe\u68c0\u7d22\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684RAG\u7cfb\u7edf\u5728\u6269\u5c55\u5230\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u65f6\uff0c\u5728\u7b80\u5355\u67e5\u8be2\u4e0a\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u5ef6\u8fdf\uff0c\u5728\u590d\u6742\u591a\u8df3\u95ee\u9898\u4e0a\u4ea7\u751f\u788e\u7247\u5316\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPLIT-RAG\u7684\u591a\u4ee3\u7406RAG\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u9996\u5148\u521b\u5efa\u94fe\u63a5\u4fe1\u606f\u7684\u8bed\u4e49\u5212\u5206\uff0c\u7136\u540e\u4f7f\u7528\u7c7b\u578b\u4e13\u7528\u77e5\u8bc6\u5e93\u5b9e\u73b0\u591a\u4ee3\u7406RAG\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "SPLIT-RAG\u901a\u8fc7\u5f15\u5165\u95ee\u9898\u9a71\u52a8\u7684\u8bed\u4e49\u56fe\u5212\u5206\u548c\u534f\u4f5c\u5b50\u56fe\u68c0\u7d22\u89e3\u51b3\u4e86\u73b0\u6709RAG\u7cfb\u7edf\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2505.13697", "pdf": "https://arxiv.org/pdf/2505.13697", "abs": "https://arxiv.org/abs/2505.13697", "authors": ["Soumya Rani Samineni", "Durgesh Kalwar", "Karthik Valmeekam", "Kaya Stechly", "Subbarao Kambhampati"], "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning-based post-training of large language models (LLMs)\nhas recently gained attention, particularly following the release of DeepSeek\nR1, which applied GRPO for fine-tuning. Amid the growing hype around improved\nreasoning abilities attributed to RL post-training, we critically examine the\nformulation and assumptions underlying these methods. We start by highlighting\nthe popular structural assumptions made in modeling LLM training as a Markov\nDecision Process (MDP), and show how they lead to a degenerate MDP that doesn't\nquite need the RL/GRPO apparatus. The two critical structural assumptions\ninclude (1) making the MDP states be just a concatenation of the actions-with\nstates becoming the context window and the actions becoming the tokens in LLMs\nand (2) splitting the reward of a state-action trajectory uniformly across the\ntrajectory. Through a comprehensive analysis, we demonstrate that these\nsimplifying assumptions make the approach effectively equivalent to an\noutcome-driven supervised learning. Our experiments on benchmarks including\nGSM8K and Countdown using Qwen-2.5 base models show that iterative supervised\nfine-tuning, incorporating both positive and negative samples, achieves\nperformance comparable to GRPO-based training. We will also argue that the\nstructural assumptions indirectly incentivize the RL to generate longer\nsequences of intermediate tokens-which in turn feeds into the narrative of \"RL\ngenerating longer thinking traces.\" While RL may well be a very useful\ntechnique for improving the reasoning abilities of LLMs, our analysis shows\nthat the simplistic structural assumptions made in modeling the underlying MDP\nrender the popular LLM RL frameworks and their interpretations questionable.", "AI": {"tldr": "This paper critically examines reinforcement learning-based post-training methods for large language models, arguing that common structural assumptions reduce such approaches to outcome-driven supervised learning.", "motivation": "To critically evaluate the formulation and assumptions of reinforcement learning post-training methods for large language models.", "method": "Analyzing the structural assumptions in modeling LLM training as a Markov Decision Process and demonstrating their equivalence to supervised learning through experiments.", "result": "Experiments on benchmarks like GSM8K and Countdown showed that iterative supervised fine-tuning achieved performance comparable to GRPO-based training.", "conclusion": "The simplistic structural assumptions in current LLM RL frameworks render them and their interpretations questionable."}}
{"id": "2505.14001", "pdf": "https://arxiv.org/pdf/2505.14001", "abs": "https://arxiv.org/abs/2505.14001", "authors": ["Sterre Lutz", "Matthijs T. J. Spaan", "Anna Lukina"], "title": "VeRecycle: Reclaiming Guarantees from Probabilistic Certificates for Stochastic Dynamical Systems after Change", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "accepted to IJCAI 2025", "summary": "Autonomous systems operating in the real world encounter a range of\nuncertainties. Probabilistic neural Lyapunov certification is a powerful\napproach to proving safety of nonlinear stochastic dynamical systems. When\nfaced with changes beyond the modeled uncertainties, e.g., unidentified\nobstacles, probabilistic certificates must be transferred to the new system\ndynamics. However, even when the changes are localized in a known part of the\nstate space, state-of-the-art requires complete re-certification, which is\nparticularly costly for neural certificates. We introduce VeRecycle, the first\nframework to formally reclaim guarantees for discrete-time stochastic dynamical\nsystems. VeRecycle efficiently reuses probabilistic certificates when the\nsystem dynamics deviate only in a given subset of states. We present a general\ntheoretical justification and algorithmic implementation. Our experimental\nevaluation shows scenarios where VeRecycle both saves significant computational\neffort and achieves competitive probabilistic guarantees in compositional\nneural control.", "AI": {"tldr": "This paper introduces VeRecycle, a framework that allows efficient reuse of probabilistic certificates when the system dynamics change in a localized subset of states, reducing computational costs while maintaining competitive probabilistic guarantees.", "motivation": "To address the need for efficient re-certification of probabilistic neural Lyapunov certificates when facing changes in system dynamics beyond modeled uncertainties.", "method": "Developing VeRecycle, a framework that formally reclaims guarantees for discrete-time stochastic dynamical systems by efficiently reusing probabilistic certificates.", "result": "VeRecycle reduces computational effort significantly and achieves competitive probabilistic guarantees in compositional neural control.", "conclusion": "VeRecycle provides an efficient way to reuse probabilistic certificates in dynamic environments, particularly beneficial for neural certificates."}}
{"id": "2505.13702", "pdf": "https://arxiv.org/pdf/2505.13702", "abs": "https://arxiv.org/abs/2505.13702", "authors": ["Mariana A. Fazio", "Salvador Sosa G\u00fcitron", "Marcus Babzien", "Mikhail Fedurin", "Junjie Li", "Mark Palmer", "Sandra S. Biedron", "Manel Martinez-Ramon"], "title": "Unsupervised anomaly detection in MeV ultrafast electron diffraction", "categories": ["cs.LG", "physics.ins-det"], "comment": null, "summary": "This study focus in the construction of an unsupervised anomaly detection\nmethodology to detect faulty images in MUED. We believe that unsupervised\ntechniques are the best choice for our purposes because the data used to train\nthe detector does not need to be manually labeled, and instead, the machine is\nintended to detect by itself the anomalies in the dataset, which liberates the\nuser of tedious, time-consuming initial image examination. The structure must,\nadditionally, provide the user with some measure of uncertainty in the\ndetection, so the user can take decisions based on this measure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6765\u68c0\u6d4bMUED\u4e2d\u7684\u6545\u969c\u56fe\u50cf\u3002", "motivation": "\u51cf\u5c11\u624b\u52a8\u6807\u8bb0\u6570\u636e\u7684\u5de5\u4f5c\u91cf\u5e76\u63d0\u4f9b\u68c0\u6d4b\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u3002", "method": "\u6784\u5efa\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u80fd\u591f\u68c0\u6d4bMUED\u4e2d\u7684\u6545\u969c\u56fe\u50cf\u3002", "conclusion": "\u65e0\u76d1\u7763\u6280\u672f\u662f\u8be5\u4efb\u52a1\u7684\u6700\u4f73\u9009\u62e9\u3002"}}
{"id": "2505.14020", "pdf": "https://arxiv.org/pdf/2505.14020", "abs": "https://arxiv.org/abs/2505.14020", "authors": ["Hao Dong", "Ziyue Qiao", "Zhiyuan Ning", "Qi Hao", "Yi Du", "Pengyang Wang", "Yuanchun Zhou"], "title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to ACL 2025 Findings", "summary": "Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs\n(KGs), incorporate the temporal feature to express the transience of knowledge\nby describing when facts occur. TKG extrapolation aims to infer possible future\nfacts based on known history, which has garnered significant attention in\nrecent years. Some existing methods treat TKG as a sequence of independent\nsubgraphs to model temporal evolution patterns, demonstrating impressive\nreasoning performance. However, they still have limitations: 1) In modeling\nsubgraph semantic evolution, they usually neglect the internal structural\ninteractions between subgraphs, which are actually crucial for encoding TKGs.\n2) They overlook the potential smooth features that do not lead to semantic\nchanges, which should be distinguished from the semantic evolution process.\nTherefore, we propose a novel Disentangled Multi-span Evolutionary Network\n(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution\nstrategy that captures local neighbor features while perceiving historical\nneighbor semantic information, thus enabling internal interactions between\nsubgraphs during the evolution process. To maximize the capture of semantic\nchange patterns, we design a disentangle component that adaptively separates\nnodes' active and stable features, used to dynamically control the influence of\nhistorical semantics on future evolution. Extensive experiments conducted on\nfour real-world TKG datasets show that DiMNet demonstrates substantial\nperformance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%\nin MRR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiMNet\u7684\u65b0\u65b9\u6cd5\u7528\u4e8e\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u8de8\u5ea6\u6f14\u5316\u7b56\u7565\u548c\u89e3\u8026\u7ec4\u4ef6\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5efa\u6a21\u5b50\u56fe\u8bed\u4e49\u6f14\u5316\u65f6\u5ffd\u7565\u4e86\u5b50\u56fe\u95f4\u7684\u5185\u90e8\u7ed3\u6784\u4ea4\u4e92\uff0c\u5e76\u4e14\u672a\u533a\u5206\u6f5c\u5728\u5e73\u6ed1\u7279\u5f81\u4e0e\u8bed\u4e49\u53d8\u5316\u7279\u5f81\u3002", "method": "\u8bbe\u8ba1\u4e86\u591a\u8de8\u5ea6\u6f14\u5316\u7b56\u7565\u6355\u83b7\u5c40\u90e8\u90bb\u5c45\u7279\u5f81\u5e76\u611f\u77e5\u5386\u53f2\u90bb\u5c45\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u89e3\u8026\u7ec4\u4ef6\u52a8\u6001\u63a7\u5236\u5386\u53f2\u8bed\u4e49\u5bf9\u672a\u6765\u6f14\u5316\u7684\u5f71\u54cd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiMNet\u5728TKG\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u9ad8\u51fa22.7%\u7684MRR\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684DiMNet\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u63d0\u5347\u4e86\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.13709", "pdf": "https://arxiv.org/pdf/2505.13709", "abs": "https://arxiv.org/abs/2505.13709", "authors": ["Jiayu Chen", "Aravind Venugopal", "Jeff Schneider"], "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) offers a powerful paradigm for\ndata-driven control. Compared to model-free approaches, offline model-based RL\n(MBRL) explicitly learns a world model from a static dataset and uses it as a\nsurrogate simulator, improving data efficiency and enabling potential\ngeneralization beyond the dataset support. However, most existing offline MBRL\nmethods follow a two-stage training procedure: first learning a world model by\nmaximizing the likelihood of the observed transitions, then optimizing a policy\nto maximize its expected return under the learned model. This objective\nmismatch results in a world model that is not necessarily optimized for\neffective policy learning. Moreover, we observe that policies learned via\noffline MBRL often lack robustness during deployment, and small adversarial\nnoise in the environment can lead to significant performance degradation. To\naddress these, we propose a framework that dynamically adapts the world model\nalongside the policy under a unified learning objective aimed at improving\nrobustness. At the core of our method is a maximin optimization problem, which\nwe solve by innovatively utilizing Stackelberg learning dynamics. We provide\ntheoretical analysis to support our design and introduce computationally\nefficient implementations. We benchmark our algorithm on twelve noisy D4RL\nMuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its\nstate-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u6a21\u578b\u57fa\u7840\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e16\u754c\u6a21\u578b\u548c\u7b56\u7565\u6765\u63d0\u9ad8\u7b56\u7565\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u79bb\u7ebfMBRL\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4e16\u754c\u6a21\u578b\u4e0d\u662f\u4e13\u95e8\u4e3a\u6709\u6548\u7684\u7b56\u7565\u5b66\u4e60\u4f18\u5316\u7684\uff0c\u5e76\u4e14\u79bb\u7ebfMBRL\u5b66\u4e60\u7684\u7b56\u7565\u5728\u90e8\u7f72\u65f6\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u4e16\u754c\u6a21\u578b\u548c\u7b56\u7565\u7684\u6846\u67b6\uff0c\u91c7\u7528\u7edf\u4e00\u7684\u5b66\u4e60\u76ee\u6807\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u5229\u7528Stackelberg\u5b66\u4e60\u52a8\u529b\u5b66\u89e3\u51b3\u4e86\u6700\u5927\u5316\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u73af\u5883\u4e2d\u7684\u5c0f\u5e45\u5ea6\u5bf9\u6297\u566a\u58f0\u65f6\u8868\u73b0\u51fa\u4e86\u66f4\u597d\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u63d0\u9ad8\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5728\u5341\u4e8c\u4e2a\u5608\u6742\u7684D4RL MuJoCo\u4efb\u52a1\u548c\u4e09\u4e2a\u968f\u673a\u6258\u5361\u9a6c\u514b\u63a7\u5236\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2505.14038", "pdf": "https://arxiv.org/pdf/2505.14038", "abs": "https://arxiv.org/abs/2505.14038", "authors": ["Xinzhe Zheng", "Sijie Ji", "Jiawei Sun", "Renqi Chen", "Wei Gao", "Mani Srivastava"], "title": "ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mental health risk is a critical global public health challenge,\nnecessitating innovative and reliable assessment methods. With the development\nof large language models (LLMs), they stand out to be a promising tool for\nexplainable mental health care applications. Nevertheless, existing approaches\npredominantly rely on subjective textual mental records, which can be distorted\nby inherent mental uncertainties, leading to inconsistent and unreliable\npredictions. To address these limitations, this paper introduces ProMind-LLM.\nWe investigate an innovative approach integrating objective behavior data as\ncomplementary information alongside subjective mental records for robust mental\nhealth risk assessment. Specifically, ProMind-LLM incorporates a comprehensive\npipeline that includes domain-specific pretraining to tailor the LLM for mental\nhealth contexts, a self-refine mechanism to optimize the processing of\nnumerical behavioral data, and causal chain-of-thought reasoning to enhance the\nreliability and interpretability of its predictions. Evaluations of two\nreal-world datasets, PMData and Globem, demonstrate the effectiveness of our\nproposed methods, achieving substantial improvements over general LLMs. We\nanticipate that ProMind-LLM will pave the way for more dependable,\ninterpretable, and scalable mental health case solutions.", "AI": {"tldr": "\u63d0\u51faProMind-LLM\uff0c\u4e00\u79cd\u7ed3\u5408\u4e3b\u89c2\u5fc3\u7406\u8bb0\u5f55\u548c\u5ba2\u89c2\u884c\u4e3a\u6570\u636e\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u66f4\u53ef\u9760\u7684\u5fc3\u7406\u5065\u5eb7\u98ce\u9669\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u5fc3\u7406\u5065\u5eb7\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e3b\u89c2\u6587\u672c\u8bb0\u5f55\uff0c\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u9884\u6d4b\u4e0d\u4e00\u81f4\u548c\u4e0d\u53ef\u9760\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1ProMind-LLM\uff0c\u5305\u62ec\u9886\u57df\u7279\u5b9a\u9884\u8bad\u7ec3\u3001\u81ea\u4f18\u5316\u673a\u5236\u548c\u56e0\u679c\u63a8\u7406\u94fe\uff0c\u4ee5\u6574\u5408\u5ba2\u89c2\u884c\u4e3a\u6570\u636e\u3002", "result": "\u5728PMData\u548cGlobem\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cProMind-LLM\u6bd4\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "ProMind-LLM\u6709\u671b\u63a8\u52a8\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u5fc3\u7406\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.14072", "pdf": "https://arxiv.org/pdf/2505.14072", "abs": "https://arxiv.org/abs/2505.14072", "authors": ["Soroush Hashemifar", "Sherry Sahebi"], "title": "Personalized Student Knowledge Modeling for Future Learning Resource Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Despite advances in deep learning for education, student knowledge tracing\nand behavior modeling face persistent challenges: limited personalization,\ninadequate modeling of diverse learning activities (especially non-assessed\nmaterials), and overlooking the interplay between knowledge acquisition and\nbehavioral patterns. Practical limitations, such as fixed-size sequence\nsegmentation, frequently lead to the loss of contextual information vital for\npersonalized learning. Moreover, reliance on student performance on assessed\nmaterials limits the modeling scope, excluding non-assessed interactions like\nlectures. To overcome these shortcomings, we propose Knowledge Modeling and\nMaterial Prediction (KMaP), a stateful multi-task approach designed for\npersonalized and simultaneous modeling of student knowledge and behavior. KMaP\nemploys clustering-based student profiling to create personalized student\nrepresentations, improving predictions of future learning resource preferences.\nExtensive experiments on two real-world datasets confirm significant behavioral\ndifferences across student clusters and validate the efficacy of the KMaP\nmodel.", "AI": {"tldr": "This paper introduces KMaP, a new method that improves personalized learning by jointly modeling student knowledge and behavior.", "motivation": "Current methods have challenges with personalization and modeling diverse learning activities.", "method": "KMaP uses clustering-based student profiling to create personalized representations and predict future learning resource preferences.", "result": "Experiments on two datasets show significant behavioral differences across student clusters and validate the effectiveness of KMaP.", "conclusion": "KMaP provides a way to personalize learning by simultaneously modeling knowledge and behavior."}}
{"id": "2505.13738", "pdf": "https://arxiv.org/pdf/2505.13738", "abs": "https://arxiv.org/abs/2505.13738", "authors": ["Shane Bergsma", "Nolan Dey", "Gurpreet Gosal", "Gavia Gray", "Daria Soboleva", "Joel Hestness"], "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs),\nincluding learning rate {\\eta} and weight decay {\\lambda}. We study scaling\nlaws for HPs: formulas for how to scale HPs as we scale model size N, dataset\nsize D, and batch size B. Recent work suggests the AdamW timescale,\nB/({\\eta}{\\lambda}D), should remain constant across training settings, and we\nverify the implication that optimal {\\lambda} scales linearly with B, for a\nfixed N,D. However, as N,D scale, we show the optimal timescale obeys a precise\npower law in the tokens-per-parameter ratio, D/N. This law thus provides a\nmethod to accurately predict {\\lambda}opt in advance of large-scale training.\nWe also study scaling laws for optimal batch size Bopt (the B enabling lowest\nloss at a given N,D) and critical batch size Bcrit (the B beyond which further\ndata parallelism becomes ineffective). In contrast with prior work, we find\nboth Bopt and Bcrit scale as power laws in D, independent of model size, N.\nFinally, we analyze how these findings inform the real-world selection of\nPareto-optimal N and D under dual training time and compute objectives.", "AI": {"tldr": "\u7814\u7a76\u4e86LLM\u9884\u8bad\u7ec3\u4e2d\u8d85\u53c2\u6570\uff08\u5982\u5b66\u4e60\u7387\u03b7\u548c\u6743\u91cd\u8870\u51cf\u03bb\uff09\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u63d0\u51fa\u4e86\u5728\u6a21\u578b\u5927\u5c0fN\u3001\u6570\u636e\u96c6\u5927\u5c0fD\u548c\u6279\u91cf\u5927\u5c0fB\u53d8\u5316\u65f6\u8d85\u53c2\u6570\u7f29\u653e\u7684\u516c\u5f0f\u3002\u53d1\u73b0AdamW\u65f6\u95f4\u5c3a\u5ea6B/(\u03b7\u03bbD)\u5728\u4e0d\u540c\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u5e94\u4fdd\u6301\u4e0d\u53d8\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5728\u56fa\u5b9aN\u548cD\u7684\u60c5\u51b5\u4e0b\u6700\u4f18\u03bb\u4e0eB\u6210\u7ebf\u6027\u5173\u7cfb\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u6700\u4f18\u6279\u91cf\u5927\u5c0fBopt\u548c\u4e34\u754c\u6279\u91cf\u5927\u5c0fBcrit\u7684\u7f29\u653e\u89c4\u5f8b\u3002\u6700\u540e\uff0c\u5206\u6790\u4e86\u8fd9\u4e9b\u53d1\u73b0\u5982\u4f55\u5f71\u54cd\u53cc\u91cd\u8bad\u7ec3\u65f6\u95f4\u548c\u8ba1\u7b97\u76ee\u6807\u4e0b\u7684Pareto\u6700\u4f18N\u548cD\u7684\u9009\u62e9\u3002", "motivation": "\u63d0\u9ad8LLM\u9884\u8bad\u7ec3\u6548\u7387\u9700\u8981\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u56e0\u6b64\u7814\u7a76\u8d85\u53c2\u6570\u7684\u7f29\u653e\u89c4\u5f8b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7f29\u653e\u89c4\u5f8b\uff0c\u63d0\u51fa\u516c\u5f0f\u6765\u9884\u6d4b\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u524d\u7684\u6700\u4f18\u8d85\u53c2\u6570\u03bbopt\uff0c\u5e76\u7814\u7a76\u4e86\u6700\u4f18\u6279\u91cf\u5927\u5c0fBopt\u548c\u4e34\u754c\u6279\u91cf\u5927\u5c0fBcrit\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u53d1\u73b0AdamW\u65f6\u95f4\u5c3a\u5ea6B/(\u03b7\u03bbD)\u5728\u4e0d\u540c\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u5e94\u4fdd\u6301\u4e0d\u53d8\uff1b\u6700\u4f18\u03bb\u4e0eB\u6210\u7ebf\u6027\u5173\u7cfb\uff0c\u5728N\u548cD\u53d8\u5316\u65f6\u6700\u4f18\u65f6\u95f4\u5c3a\u5ea6\u9075\u5faa\u7cbe\u786e\u7684\u5e42\u5f8b\uff1bBopt\u548cBcrit\u5747\u6309D\u7684\u5e42\u5f8b\u7f29\u653e\uff0c\u4e0eN\u65e0\u5173\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86LLM\u9884\u8bad\u7ec3\u4e2d\u8d85\u53c2\u6570\u548c\u6279\u91cf\u5927\u5c0f\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8d85\u53c2\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2505.14137", "pdf": "https://arxiv.org/pdf/2505.14137", "abs": "https://arxiv.org/abs/2505.14137", "authors": ["Vojt\u011bch K\u016fr", "V\u00edt Musil", "Vojt\u011bch \u0158eh\u00e1k"], "title": "Memory Assignment for Finite-Memory Strategies in Adversarial Patrolling Games", "categories": ["cs.AI"], "comment": null, "summary": "Adversarial Patrolling games form a subclass of Security games where a\nDefender moves between locations, guarding vulnerable targets. The main\nalgorithmic problem is constructing a strategy for the Defender that minimizes\nthe worst damage an Attacker can cause. We focus on the class of finite-memory\n(also known as regular) Defender's strategies that experimentally outperformed\nother competing classes. A finite-memory strategy can be seen as a positional\nstrategy on a finite set of states. Each state consists of a pair of a location\nand a certain integer value--called memory. Existing algorithms improve the\ntransitional probabilities between the states but require that the available\nmemory size itself is assigned at each location manually. Choosing the right\nmemory assignment is a well-known open and hard problem that hinders the\nusability of finite-memory strategies. We solve this issue by developing a\ngeneral method that iteratively changes the memory assignment. Our algorithm\ncan be used in connection with \\emph{any} black-box strategy optimization tool.\nWe evaluate our method on various experiments and show its robustness by\nsolving instances of various patrolling models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u89e3\u51b3\u6709\u9650\u5185\u5b58\u7b56\u7565\u4e2d\u7684\u5185\u5b58\u5206\u914d\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u7b97\u6cd5\u867d\u7136\u6539\u8fdb\u4e86\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\u6982\u7387\uff0c\u4f46\u9700\u8981\u624b\u52a8\u5206\u914d\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u53ef\u7528\u5185\u5b58\u5927\u5c0f\uff0c\u8fd9\u4f7f\u5f97\u6709\u9650\u5185\u5b58\u7b56\u7565\u7684\u5b9e\u7528\u6027\u53d7\u5230\u9650\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u8fed\u4ee3\u6539\u53d8\u5185\u5b58\u5206\u914d\u7684\u4e00\u822c\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6709\u9650\u5185\u5b58\u7b56\u7565\u4e2d\u624b\u52a8\u5206\u914d\u5185\u5b58\u5927\u5c0f\u7684\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u4e0e\u4efb\u4f55\u9ed1\u76d2\u7b56\u7565\u4f18\u5316\u5de5\u5177\u4e00\u8d77\u4f7f\u7528\uff0c\u5e76\u4e14\u901a\u8fc7\u5404\u79cd\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u89e3\u51b3\u4e0d\u540c\u5de1\u903b\u6a21\u578b\u5b9e\u4f8b\u65f6\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u6709\u9650\u5185\u5b58\u7b56\u7565\u4e2d\u7684\u5185\u5b58\u5206\u914d\u95ee\u9898\uff0c\u5e76\u4e14\u8be5\u7b97\u6cd5\u53ef\u4ee5\u4e0e\u4efb\u4f55\u9ed1\u76d2\u7b56\u7565\u4f18\u5316\u5de5\u5177\u4e00\u8d77\u4f7f\u7528\u3002\u901a\u8fc7\u5404\u79cd\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u89e3\u51b3\u5404\u79cd\u5de1\u903b\u6a21\u578b\u5b9e\u4f8b\u65f6\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.13740", "pdf": "https://arxiv.org/pdf/2505.13740", "abs": "https://arxiv.org/abs/2505.13740", "authors": ["Chenning Yu", "Sicun Gao"], "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "We introduce a novel resampling criterion using lift scores, for improving\ncompositional generation in diffusion models. By leveraging the lift scores, we\nevaluate whether generated samples align with each single condition and then\ncompose the results to determine whether the composed prompt is satisfied. Our\nkey insight is that lift scores can be efficiently approximated using only the\noriginal diffusion model, requiring no additional training or external modules.\nWe develop an optimized variant that achieves relatively lower computational\noverhead during inference while maintaining effectiveness. Through extensive\nexperiments, we demonstrate that lift scores significantly improved the\ncondition alignment for compositional generation across 2D synthetic data,\nCLEVR position tasks, and text-to-image synthesis. Our code is available at\nhttp://github.com/rainorangelemon/complift.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u5347\u5206\u6570\u7684\u65b0\u91cd\u91c7\u6837\u6807\u51c6\uff0c\u7528\u4e8e\u6539\u8fdb\u6269\u6563\u6a21\u578b\u4e2d\u7684\u7ec4\u5408\u751f\u6210\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e8c\u7ef4\u5408\u6210\u6570\u636e\u3001CLEVR\u4f4d\u7f6e\u4efb\u52a1\u548c\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u4e2d\u7684\u6761\u4ef6\u5bf9\u9f50\u6548\u679c\u663e\u8457\u6539\u5584\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u7ec4\u5408\u751f\u6210\u4efb\u52a1\u4e2d\u5b58\u5728\u6761\u4ef6\u5bf9\u9f50\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u673a\u5236\u6765\u63d0\u9ad8\u751f\u6210\u6837\u672c\u4e0e\u5355\u4e2a\u6761\u4ef6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u5229\u7528\u63d0\u5347\u5206\u6570\u8bc4\u4f30\u751f\u6210\u6837\u672c\u4e0e\u6bcf\u4e2a\u5355\u4e00\u6761\u4ef6\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u5e76\u7ed3\u5408\u8fd9\u4e9b\u7ed3\u679c\u5224\u65ad\u662f\u5426\u6ee1\u8db3\u7ec4\u5408\u63d0\u793a\u3002\u6b64\u8fc7\u7a0b\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5916\u90e8\u6a21\u5757\uff0c\u4ec5\u4f9d\u8d56\u539f\u59cb\u6269\u6563\u6a21\u578b\u5373\u53ef\u9ad8\u6548\u8fd1\u4f3c\u63d0\u5347\u5206\u6570\u3002\u8fd8\u5f00\u53d1\u4e86\u4f18\u5316\u53d8\u4f53\u4ee5\u51cf\u5c11\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u57282D\u5408\u6210\u6570\u636e\u3001CLEVR\u4f4d\u7f6e\u4efb\u52a1\u4ee5\u53ca\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u4efb\u52a1\u4e2d\uff0c\u6761\u4ef6\u5bf9\u9f50\u5f97\u5230\u4e86\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u63d0\u5347\u5206\u6570\u7684\u91cd\u91c7\u6837\u6807\u51c6\u80fd\u591f\u6709\u6548\u63d0\u5347\u6269\u6563\u6a21\u578b\u5728\u7ec4\u5408\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e14\u5177\u6709\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2505.14140", "pdf": "https://arxiv.org/pdf/2505.14140", "abs": "https://arxiv.org/abs/2505.14140", "authors": ["Qianyue Hao", "Sibo Li", "Jian Yuan", "Yong Li"], "title": "RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Despite rapid advancements in large language models (LLMs), the token-level\nautoregressive nature constrains their complex reasoning capabilities. To\nenhance LLM reasoning, inference-time techniques, including\nChain/Tree/Graph-of-Thought(s), successfully improve the performance, as they\nare fairly cost-effective by guiding reasoning through sophisticated logical\nstructures without modifying LLMs' parameters. However, these manually\npredefined, task-agnostic frameworks are applied uniformly across diverse\ntasks, lacking adaptability. To improve this, we propose RL-of-Thoughts (RLoT),\nwhere we train a lightweight navigator model with reinforcement learning (RL)\nto adaptively enhance LLM reasoning at inference time. Specifically, we design\nfive basic logic blocks from the perspective of human cognition. During the\nreasoning process, the trained RL navigator dynamically selects the suitable\nlogic blocks and combines them into task-specific logical structures according\nto problem characteristics. Experiments across multiple reasoning benchmarks\n(AIME, MATH, GPQA, etc.) with multiple LLMs (GPT, Llama, Qwen, and DeepSeek)\nillustrate that RLoT outperforms established inference-time techniques by up to\n13.4%. Remarkably, with less than 3K parameters, our RL navigator is able to\nmake sub-10B LLMs comparable to 100B-scale counterparts. Moreover, the RL\nnavigator demonstrates strong transferability: a model trained on one specific\nLLM-task pair can effectively generalize to unseen LLMs and tasks. Our code is\nopen-source at https://anonymous.4open.science/r/RL-LLM-Reasoning-1A30 for\nreproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRL-of-Thoughts(RLoT)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5bfc\u822a\u6a21\u578b\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660eRLoT\u6bd4\u73b0\u6709\u7684\u63a8\u7406\u65f6\u95f4\u6280\u672f\u63d0\u9ad8\u4e86\u591a\u8fbe13.4%\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u65f6\u95f4\u6280\u672f\u867d\u7136\u80fd\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f46\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u624b\u52a8\u9884\u5b9a\u4e49\u7684\u3001\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u6846\u67b6\uff0c\u65e0\u6cd5\u6839\u636e\u4e0d\u540c\u4efb\u52a1\u7684\u7279\u70b9\u8fdb\u884c\u8c03\u6574\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u57fa\u672c\u903b\u8f91\u5757\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5bfc\u822a\u6a21\u578b\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u9009\u62e9\u5408\u9002\u7684\u903b\u8f91\u5757\u5e76\u7ec4\u5408\u6210\u7279\u5b9a\u4efb\u52a1\u7684\u903b\u8f91\u7ed3\u6784\u3002", "result": "RLoT\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f7f\u8f83\u5c0f\u89c4\u6a21\u7684LLM\u8868\u73b0\u63a5\u8fd1\u5927\u89c4\u6a21\u7684LLM\uff0c\u5e76\u4e14\u5177\u6709\u5f88\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684RL-of-Thoughts\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u5bfc\u822a\u6a21\u578b\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u663e\u793a\u51fa\u4e86\u663e\u8457\u7684\u6548\u679c\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.13742", "pdf": "https://arxiv.org/pdf/2505.13742", "abs": "https://arxiv.org/abs/2505.13742", "authors": ["Andrew Nam", "Declan Campbell", "Thomas Griffiths", "Jonathan Cohen", "Sarah-Jane Leslie"], "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural networks are powerful tools for cognitive modeling due to their\nflexibility and emergent properties. However, interpreting their learned\nrepresentations remains challenging due to their sub-symbolic semantics. In\nthis work, we introduce a novel probabilistic framework for interpreting latent\ntask representations in neural networks. Inspired by Bayesian inference, our\napproach defines a distribution over representational units to infer their\ncausal contributions to task performance. Using ideas from information theory,\nwe propose a suite of tools and metrics to illuminate key model properties,\nincluding representational distributedness, manifold complexity, and\npolysemanticity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6846\u67b6\u6765\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6f5c\u5728\u4efb\u52a1\u8868\u793a\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u8ba4\u77e5\u5efa\u6a21\u4e2d\u6709\u5f88\u5f3a\u7684\u80fd\u529b\uff0c\u4f46\u89e3\u91ca\u5176\u5b66\u4e60\u5230\u7684\u8868\u793a\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6982\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u5b9a\u4e49\u8868\u793a\u5355\u5143\u4e0a\u7684\u5206\u5e03\u6765\u63a8\u65ad\u5b83\u4eec\u5bf9\u4efb\u52a1\u8868\u73b0\u7684\u56e0\u679c\u8d21\u732e\uff0c\u5e76\u4f7f\u7528\u4fe1\u606f\u8bba\u7684\u601d\u60f3\u63d0\u51fa\u4e86\u4e00\u5957\u5de5\u5177\u548c\u5ea6\u91cf\u6807\u51c6\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u6982\u7387\u6846\u67b6\u4ee5\u53ca\u4e00\u5957\u5de5\u5177\u548c\u5ea6\u91cf\u6807\u51c6\u6765\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6f5c\u5728\u4efb\u52a1\u8868\u793a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6f5c\u5728\u4efb\u52a1\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.14141", "pdf": "https://arxiv.org/pdf/2505.14141", "abs": "https://arxiv.org/abs/2505.14141", "authors": ["Fanglin Mo", "Junzhe Chen", "Haoxuan Zhu", "Xuming Hu"], "title": "Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent", "categories": ["cs.AI", "I.2.11; H.5.2"], "comment": "10 pages. Submitted to EMNLP 2025", "summary": "Mobile GUI agents execute user commands by directly interacting with the\ngraphical user interface (GUI) of mobile devices, demonstrating significant\npotential to enhance user convenience. However, these agents face considerable\nchallenges in task planning, as they must continuously analyze the GUI and\ngenerate operation instructions step by step. This process often leads to\ndifficulties in making accurate task plans, as GUI agents lack a deep\nunderstanding of how to effectively use the target applications, which can\ncause them to become \"lost\" during task execution. To address the task planning\nissue, we propose SPlanner, a plug-and-play planning module to generate\nexecution plans that guide vision language model(VLMs) in executing tasks. The\nproposed planning module utilizes extended finite state machines (EFSMs) to\nmodel the control logits and configurations of mobile applications. It then\ndecomposes a user instruction into a sequence of primary function modeled in\nEFSMs, and generate the execution path by traversing the EFSMs. We further\nrefine the execution path into a natural language plan using an LLM. The final\nplan is concise and actionable, and effectively guides VLMs to generate\ninteractive GUI actions to accomplish user tasks. SPlanner demonstrates strong\nperformance on dynamic benchmarks reflecting real-world mobile usage. On the\nAndroidWorld benchmark, SPlanner achieves a 63.8% task success rate when paired\nwith Qwen2.5-VL-72B as the VLM executor, yielding a 28.8 percentage point\nimprovement compared to using Qwen2.5-VL-72B without planning assistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPlanner\u7684\u63d2\u4ef6\u5f0f\u89c4\u5212\u6a21\u5757\uff0c\u7528\u4e8e\u751f\u6210\u6267\u884c\u8ba1\u5212\uff0c\u6307\u5bfc\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u5b8c\u6210\u4efb\u52a1\u3002\u8be5\u6a21\u5757\u5229\u7528\u6269\u5c55\u6709\u9650\u72b6\u6001\u673a(EFSMs)\u5efa\u6a21\u79fb\u52a8\u5e94\u7528\u7684\u63a7\u5236logits\u548c\u914d\u7f6e\uff0c\u5e76\u5c06\u7528\u6237\u6307\u4ee4\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u521d\u7ea7\u529f\u80fd\uff0c\u901a\u8fc7\u904d\u5386EFSMs\u751f\u6210\u6267\u884c\u8def\u5f84\uff0c\u518d\u7528LLM\u7cbe\u70bc\u6210\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u3002\u6700\u7ec8\u8ba1\u5212\u7b80\u6d01\u4e14\u53ef\u64cd\u4f5c\uff0c\u6709\u6548\u5f15\u5bfcVLMs\u751f\u6210\u4ea4\u4e92\u5f0fGUI\u52a8\u4f5c\u6765\u5b8c\u6210\u7528\u6237\u4efb\u52a1\u3002\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5f53\u4e0eQwen2.5-VL-72B\u4f5c\u4e3aVLM\u6267\u884c\u5668\u7ed3\u5408\u65f6\uff0cSPlanner\u8fbe\u5230\u4e8663.8%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u6bd4\u6ca1\u6709\u89c4\u5212\u8f85\u52a9\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e8628.8\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709\u7684\u79fb\u52a8GUI\u4ee3\u7406\u5728\u4efb\u52a1\u89c4\u5212\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u5982\u4f55\u6709\u6548\u4f7f\u7528\u76ee\u6807\u5e94\u7528\u7a0b\u5e8f\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5bfc\u81f4\u5728\u4efb\u52a1\u6267\u884c\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u201c\u8ff7\u5931\u201d\u3002", "method": "\u63d0\u51fa\u4e86SPlanner\uff0c\u4e00\u4e2a\u63d2\u4ef6\u5f0f\u89c4\u5212\u6a21\u5757\uff0c\u5b83\u5229\u7528\u6269\u5c55\u6709\u9650\u72b6\u6001\u673a(EFSMs)\u6765\u5efa\u6a21\u79fb\u52a8\u5e94\u7528\u7684\u63a7\u5236logits\u548c\u914d\u7f6e\uff0c\u5e76\u751f\u6210\u6267\u884c\u8def\u5f84\u3002\u7136\u540e\u7528LLM\u5c06\u8def\u5f84\u7cbe\u70bc\u6210\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u3002", "result": "\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPlanner\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4e0eQwen2.5-VL-72B\u7ed3\u5408\u540e\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u523063.8%\uff0c\u6bd4\u65e0\u89c4\u5212\u8f85\u52a9\u63d0\u9ad8\u4e8628.8\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "SPlanner\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5728\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53cd\u6620\u4e86\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u79fb\u52a8\u4f7f\u7528\u60c5\u51b5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u79fb\u52a8GUI\u4ee3\u7406\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.14143", "pdf": "https://arxiv.org/pdf/2505.14143", "abs": "https://arxiv.org/abs/2505.14143", "authors": ["Shuo Zhang", "Jinsong Zhang", "Zhejun Zhang", "Lei Li"], "title": "Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition", "categories": ["cs.AI"], "comment": "Accepted to ICME 2025", "summary": "Multi-task learning (MTL) enables the efficient transfer of extra knowledge\nacquired from other tasks. The high correlation between multimodal sentiment\nanalysis (MSA) and multimodal emotion recognition (MER) supports their joint\ntraining. However, existing methods primarily employ hard parameter sharing,\nignoring parameter conflicts caused by complex task correlations. In this\npaper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture\nof Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts\nto distinctly model common and unique task characteristics, thereby avoiding\nparameter conflicts. Additionally, inspired by low-rank structures in the\nMixture of Experts (MoE) framework, we design low-rank expert networks to\nreduce parameter and computational overhead as the number of experts increases.\nExtensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that\nMMoLRE achieves state-of-the-art performance on the MSA task and competitive\nresults on the MER task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5MMoLRE\u7528\u4e8e\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u548c\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\uff0c\u89e3\u51b3\u4e86\u786c\u53c2\u6570\u5171\u4eab\u5e26\u6765\u7684\u53c2\u6570\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4f4e\u79e9\u4e13\u5bb6\u7f51\u7edc\u51cf\u5c11\u4e86\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u5b9e\u9a8c\u8868\u660eMMoLRE\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e0a\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u786c\u53c2\u6570\u5171\u4eab\uff0c\u5ffd\u89c6\u4e86\u590d\u6742\u4efb\u52a1\u76f8\u5173\u6027\u5bfc\u81f4\u7684\u53c2\u6570\u51b2\u7a81\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Multimodal Mixture of Low-Rank Experts (MMoLRE)\uff0c\u5229\u7528\u5171\u4eab\u548c\u4efb\u52a1\u7279\u5b9a\u4e13\u5bb6\u6765\u5efa\u6a21\u5171\u540c\u548c\u72ec\u7279\u7684\u4efb\u52a1\u7279\u5f81\uff0c\u8bbe\u8ba1\u4e86\u4f4e\u79e9\u4e13\u5bb6\u7f51\u7edc\u4ee5\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728CMU-MOSI\u548cCMU-MOSEI\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMMoLRE\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e0a\u83b7\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u53c2\u6570\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u548c\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002"}}
{"id": "2505.13754", "pdf": "https://arxiv.org/pdf/2505.13754", "abs": "https://arxiv.org/abs/2505.13754", "authors": ["Devendra Parkar", "Anya Chaturvedi", "Andr\u00e9a W. Richa", "Joshua J. Daymude"], "title": "Finding Maximum Independent Sets in Dynamic Graphs using Unsupervised Learning", "categories": ["cs.LG"], "comment": "11 pages, 3 tables", "summary": "We present the first unsupervised learning model for finding Maximum\nIndependent Sets (MaxIS) in dynamic graphs where edges change over time. Our\nmethod combines structural learning from graph neural networks (GNNs) with a\nlearned distributed update mechanism that, given an edge addition or deletion\nevent, modifies nodes' internal memories and infers their MaxIS membership in a\nsingle, parallel step. We parameterize our model by the update mechanism's\nradius and investigate the resulting performance-runtime tradeoffs for various\ndynamic graph topologies. We evaluate our model against state-of-the-art MaxIS\nmethods for static graphs, including a mixed integer programming solver,\ndeterministic rule-based algorithms, and a heuristic learning framework based\non dynamic programming and GNNs. Across synthetic and real-world dynamic graphs\nof 100-10,000 nodes, our model achieves competitive approximation ratios with\nexcellent scalability; on large graphs, it significantly outperforms the\nstate-of-the-art heuristic learning framework in solution quality, runtime, and\nmemory usage. Our model generalizes well on graphs 100x larger than the ones\nused for training, achieving performance at par with both a greedy technique\nand a commercial mixed integer programming solver while running 1.5-23x faster\nthan greedy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u89e3\u51b3\u52a8\u6001\u56fe\u4e2d\u7684\u6700\u5927\u72ec\u7acb\u96c6\u95ee\u9898\u3002\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u80fd\u529b\u548c\u5206\u5e03\u5f0f\u66f4\u65b0\u673a\u5236\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u52a8\u6001\u56fe\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u9759\u6001\u56fe\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6700\u5927\u72ec\u7acb\u96c6\u6c42\u89e3\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u56fe\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u8bb8\u591a\u56fe\u662f\u52a8\u6001\u53d8\u5316\u7684\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u5206\u5e03\u5f0f\u66f4\u65b0\u673a\u5236\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u8282\u70b9\u5185\u90e8\u8bb0\u5fc6\u7684\u4fee\u6539\u6765\u63a8\u65ad\u6700\u5927\u72ec\u7acb\u96c6\u6210\u5458\u5173\u7cfb\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u5927\u89c4\u6a21\u52a8\u6001\u56fe\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u5927\u578b\u56fe\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u89e3\u51b3\u52a8\u6001\u56fe\u4e2d\u7684\u6700\u5927\u72ec\u7acb\u96c6\u95ee\u9898\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u56fe\u7ed3\u6784\u548c\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u3002"}}
{"id": "2505.14146", "pdf": "https://arxiv.org/pdf/2505.14146", "abs": "https://arxiv.org/abs/2505.14146", "authors": ["Pengcheng Jiang", "Xueqiang Xu", "Jiacheng Lin", "Jinfeng Xiao", "Zifeng Wang", "Jimeng Sun", "Jiawei Han"], "title": "s3: You Don't Need That Much Data to Train a Search Agent via RL", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems empower large language models\n(LLMs) to access external knowledge during inference. Recent advances have\nenabled LLMs to act as search agents via reinforcement learning (RL), improving\ninformation acquisition through multi-turn interactions with retrieval engines.\nHowever, existing approaches either optimize retrieval using search-only\nmetrics (e.g., NDCG) that ignore downstream utility or fine-tune the entire LLM\nto jointly reason and retrieve-entangling retrieval with generation and\nlimiting the real search utility and compatibility with frozen or proprietary\nmodels. In this work, we propose s3, a lightweight, model-agnostic framework\nthat decouples the searcher from the generator and trains the searcher using a\nGain Beyond RAG reward: the improvement in generation accuracy over naive RAG.\ns3 requires only 2.4k training samples to outperform baselines trained on over\n70x more data, consistently delivering stronger downstream performance across\nsix general QA and five medical QA benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3as3\u7684\u8f7b\u91cf\u7ea7\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\u7684\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\u89e3\u8026\uff0c\u5e76\u901a\u8fc7\u201cRAG\u4e4b\u5916\u7684\u6536\u76ca\u201d\u5956\u52b1\u8bad\u7ec3\u68c0\u7d22\u5668\uff0c\u4ec5\u97002.4k\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u5728\u516d\u4e2a\u901a\u7528QA\u548c\u4e94\u4e2a\u533b\u5b66QA\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u9700\u8981\u66f4\u591a\u6570\u636e\u7684\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u5ffd\u7565\u4e0b\u6e38\u6548\u7528\u7684\u641c\u7d22\u6307\u6807\u4f18\u5316\u68c0\u7d22\uff0c\u8981\u4e48\u5fae\u8c03\u6574\u4e2aLLM\u4ee5\u8054\u5408\u63a8\u7406\u548c\u68c0\u7d22\uff0c\u8fd9\u9650\u5236\u4e86\u771f\u5b9e\u641c\u7d22\u6548\u7528\u548c\u5bf9\u51bb\u7ed3\u6216\u4e13\u6709\u6a21\u578b\u7684\u517c\u5bb9\u6027\u3002", "method": "\u63d0\u51fa\u4e86s3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u68c0\u7d22\u5668\u4e0e\u751f\u6210\u5668\u89e3\u8026\uff0c\u5e76\u4f7f\u7528\u201cRAG\u4e4b\u5916\u7684\u6536\u76ca\u201d\u5956\u52b1\u6765\u8bad\u7ec3\u68c0\u7d22\u5668\u3002", "result": "s3\u53ea\u9700\u89812.4k\u8bad\u7ec3\u6837\u672c\u5c31\u80fd\u5728\u516d\u4e2a\u901a\u7528QA\u548c\u4e94\u4e2a\u533b\u5b66QA\u57fa\u51c6\u4e0a\u8d85\u8d8a\u90a3\u4e9b\u57fa\u4e8e\u8d85\u8fc770\u500d\u6570\u636e\u91cf\u8bad\u7ec3\u7684\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684s3\u6846\u67b6\u8bc1\u660e\u4e86\u5728\u4e0d\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2505.14147", "pdf": "https://arxiv.org/pdf/2505.14147", "abs": "https://arxiv.org/abs/2505.14147", "authors": ["Xiong Jun Wu", "Zhenduo Zhang", "ZuJie Wen", "Zhiqiang Zhang", "Wang Ren", "Lei Shi", "Cai Chen", "Deng Zhao", "Dingnan Jin", "Qing Cui", "Jun Zhou"], "title": "SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Training large reasoning models (LRMs) with reinforcement learning in STEM\ndomains is hindered by the scarcity of high-quality, diverse, and verifiable\nproblem sets. Existing synthesis methods, such as Chain-of-Thought prompting,\noften generate oversimplified or uncheckable data, limiting model advancement\non complex tasks. To address these challenges, we introduce SHARP, a unified\napproach to Synthesizing High-quality Aligned Reasoning Problems for LRMs\nreinforcement learning with verifiable rewards (RLVR). SHARP encompasses a\nstrategic set of self-alignment principles -- targeting graduate and\nOlympiad-level difficulty, rigorous logical consistency, and unambiguous,\nverifiable answers -- and a structured three-phase framework (Alignment,\nInstantiation, Inference) that ensures thematic diversity and fine-grained\ncontrol over problem generation. We implement SHARP by leveraging a\nstate-of-the-art LRM to infer and verify challenging STEM questions, then\nemploy a reinforcement learning loop to refine the model's reasoning through\nverifiable reward signals. Experiments on benchmarks such as GPQA demonstrate\nthat SHARP-augmented training substantially outperforms existing methods,\nmarkedly improving complex reasoning accuracy and pushing LRM performance\ncloser to expert-level proficiency. Our contributions include the SHARP\nstrategy, framework design, end-to-end implementation, and experimental\nevaluation of its effectiveness in elevating LRM reasoning capabilities.", "AI": {"tldr": "SHARP \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u63a8\u7406\u95ee\u9898\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5408\u6210\u7684\u65b9\u6cd5\u751f\u6210\u7684\u95ee\u9898\u8fc7\u4e8e\u7b80\u5355\u6216\u4e0d\u53ef\u9a8c\u8bc1\uff0c\u9650\u5236\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8fdb\u6b65\u3002", "method": "\u5f15\u5165SHARP\u65b9\u6cd5\uff0c\u5305\u542b\u81ea\u6211\u5bf9\u9f50\u539f\u5219\u548c\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u7ea7LRM\u901a\u8fc7\u53ef\u9a8c\u8bc1\u5956\u52b1\u4fe1\u53f7\u4f18\u5316\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSHARP\u589e\u5f3a\u7684\u8bad\u7ec3\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86LRM\u7684\u6027\u80fd\u3002", "conclusion": "SHARP\u7b56\u7565\u53ca\u5176\u6846\u67b6\u8bbe\u8ba1\u4e3a\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2505.14148", "pdf": "https://arxiv.org/pdf/2505.14148", "abs": "https://arxiv.org/abs/2505.14148", "authors": ["Fan Liu", "Zherui Yang", "Cancheng Liu", "Tianrui Song", "Xiaofeng Gao", "Hao Liu"], "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "categories": ["cs.AI"], "comment": null, "summary": "Mathematical modeling is a cornerstone of scientific discovery and\nengineering practice, enabling the translation of real-world problems into\nformal systems across domains such as physics, biology, and economics. Unlike\nmathematical reasoning, which assumes a predefined formulation, modeling\nrequires open-ended problem analysis, abstraction, and principled\nformalization. While Large Language Models (LLMs) have shown strong reasoning\ncapabilities, they fall short in rigorous model construction, limiting their\nutility in real-world problem-solving. To this end, we formalize the task of\nLLM-powered real-world mathematical modeling, where agents must analyze\nproblems, construct domain-appropriate formulations, and generate complete\nend-to-end solutions. We introduce MM-Bench, a curated benchmark of 111\nproblems from the Mathematical Contest in Modeling (MCM/ICM), spanning the\nyears 2000 to 2025 and across ten diverse domains such as physics, biology, and\neconomics. To tackle this task, we propose MM-Agent, an expert-inspired\nframework that decomposes mathematical modeling into four stages: open-ended\nproblem analysis, structured model formulation, computational problem solving,\nand report generation. Experiments on MM-Bench show that MM-Agent significantly\noutperforms baseline agents, achieving an 11.88\\% improvement over human expert\nsolutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o.\nFurthermore, under official MCM/ICM protocols, MM-Agent assisted two\nundergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among\n27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a\nmodeling copilot. Our code is available at\nhttps://github.com/usail-hkust/LLM-MM-Agent", "AI": {"tldr": "This paper introduces MM-Agent, an expert-inspired framework for LLM-powered real-world mathematical modeling, which outperforms human experts by 11.88% on MM-Bench.", "motivation": "Existing LLMs excel in reasoning but struggle with rigorous model construction, limiting their application in real-world problem-solving.", "method": "MM-Agent decomposes mathematical modeling into four stages: problem analysis, model formulation, computational problem solving, and report generation.", "result": "On MM-Bench, MM-Agent outperforms baseline agents and achieves better results than human experts with lower cost.", "conclusion": "MM-Agent demonstrates practical effectiveness as a modeling copilot and can assist in solving complex real-world problems."}}
{"id": "2505.13765", "pdf": "https://arxiv.org/pdf/2505.13765", "abs": "https://arxiv.org/abs/2505.13765", "authors": ["Hainan Xu", "Vladimir Bataev", "Lilit Grigoryan", "Boris Ginsburg"], "title": "WIND: Accelerated RNN-T Decoding with Windowed Inference for Non-blank Detection", "categories": ["cs.LG"], "comment": null, "summary": "We propose Windowed Inference for Non-blank Detection (WIND), a novel\nstrategy that significantly accelerates RNN-T inference without compromising\nmodel accuracy. During model inference, instead of processing frames\nsequentially, WIND processes multiple frames simultaneously within a window in\nparallel, allowing the model to quickly locate non-blank predictions during\ndecoding, resulting in significant speed-ups. We implement WIND for greedy\ndecoding, batched greedy decoding with label-looping techniques, and also\npropose a novel beam-search decoding method. Experiments on multiple datasets\nwith different conditions show that our method, when operating in greedy modes,\nspeeds up as much as 2.4X compared to the baseline sequential approach while\nmaintaining identical Word Error Rate (WER) performance. Our beam-search\nalgorithm achieves slightly better accuracy than alternative methods, with\nsignificantly improved speed. We will open-source our WIND implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWIND\u7684\u65b0\u7b56\u7565\uff0c\u663e\u8457\u52a0\u901f\u4e86RNN-T\u63a8\u7406\u800c\u4e0d\u5f71\u54cd\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684RNN-T\u63a8\u7406\u65b9\u6cd5\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "WIND\u7b56\u7565\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5904\u7406\u591a\u4e2a\u5e27\u800c\u4e0d\u662f\u987a\u5e8f\u5904\u7406\u5e27\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8d2a\u5fc3\u6a21\u5f0f\u4e0b\u901f\u5ea6\u63d0\u9ad8\u4e862.4\u500d\uff0c\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u6027\u80fd\u76f8\u540c\u3002", "conclusion": "WIND\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8RNN-T\u63a8\u7406\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2505.14163", "pdf": "https://arxiv.org/pdf/2505.14163", "abs": "https://arxiv.org/abs/2505.14163", "authors": ["He Wang", "Alexander Hanbo Li", "Yiqun Hu", "Sheng Zhang", "Hideo Kobayashi", "Jiani Zhang", "Henry Zhu", "Chung-Wei Hang", "Patrick Ng"], "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents have shown promising performance in\ngenerating code for solving complex data science problems. Recent studies\nprimarily focus on enhancing in-context learning through improved search,\nsampling, and planning techniques, while overlooking the importance of the\norder in which problems are tackled during inference. In this work, we develop\na novel inference-time optimization framework, referred to as DSMentor, which\nleverages curriculum learning -- a strategy that introduces simpler task first\nand progressively moves to more complex ones as the learner improves -- to\nenhance LLM agent performance in challenging data science tasks. Our\nmentor-guided framework organizes data science tasks in order of increasing\ndifficulty and incorporates a growing long-term memory to retain prior\nexperiences, guiding the agent's learning progression and enabling more\neffective utilization of accumulated knowledge. We evaluate DSMentor through\nextensive experiments on DSEval and QRData benchmarks. Experiments show that\nDSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval\nand QRData compared to baseline agents. Furthermore, DSMentor demonstrates\nstronger causal reasoning ability, improving the pass rate by 8.8% on the\ncausality problems compared to GPT-4 using Program-of-Thoughts prompts. Our\nwork underscores the importance of developing effective strategies for\naccumulating and utilizing knowledge during inference, mirroring the human\nlearning process and opening new avenues for improving LLM performance through\ncurriculum-based inference optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u65f6\u95f4\u4f18\u5316\u6846\u67b6DSMentor\uff0c\u5229\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u63d0\u9ad8LLM\u4ee3\u7406\u5728\u590d\u6742\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u8fc7\u6539\u8fdb\u641c\u7d22\u3001\u91c7\u6837\u548c\u89c4\u5212\u6280\u672f\u6765\u589e\u5f3a\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u800c\u5ffd\u7565\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u95ee\u9898\u987a\u5e8f\u7684\u91cd\u8981\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u540d\u4e3aDSMentor\u7684\u63a8\u7406\u65f6\u95f4\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u7ec4\u7ec7\u6570\u636e\u79d1\u5b66\u4efb\u52a1\uff0c\u5e76\u7ed3\u5408\u957f\u671f\u8bb0\u5fc6\u6765\u6307\u5bfc\u4ee3\u7406\u7684\u5b66\u4e60\u8fdb\u5c55\u3002", "result": "\u5728DSEval\u548cQRData\u57fa\u51c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u4ee3\u7406\u76f8\u6bd4\uff0c\u4f7f\u7528Claude-3.5-Sonnet\u7684DSMentor\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u3002\u6b64\u5916\uff0c\u5728\u56e0\u679c\u5173\u7cfb\u95ee\u9898\u4e0a\uff0cDSMentor\u6bd4\u4f7f\u7528Program-of-Thoughts\u63d0\u793a\u7684GPT-4\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u79ef\u7d2f\u548c\u6709\u6548\u5229\u7528\u77e5\u8bc6\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u6a21\u4eff\u4e86\u4eba\u7c7b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u4e3a\u901a\u8fc7\u57fa\u4e8e\u8bfe\u7a0b\u7684\u63a8\u7406\u4f18\u5316\u63d0\u9ad8LLM\u6027\u80fd\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2505.14193", "pdf": "https://arxiv.org/pdf/2505.14193", "abs": "https://arxiv.org/abs/2505.14193", "authors": ["Abdallah Abuaisha", "Bojie Shen", "Daniel Harabor", "Peter Stuckey", "Mark Wallace"], "title": "Dynamic Replanning for Improved Public Transport Routing", "categories": ["cs.AI"], "comment": "Accepted for publication at IJCAI 2025. 8 pages, 4 figures, 3 tables", "summary": "Delays in public transport are common, often impacting users through\nprolonged travel times and missed transfers. Existing solutions for handling\ndelays remain limited; backup plans based on historical data miss opportunities\nfor earlier arrivals, while snapshot planning accounts for current delays but\nnot future ones. With the growing availability of live delay data, users can\nadjust their journeys in real-time. However, the literature lacks a framework\nthat fully exploits this advantage for system-scale dynamic replanning. To\naddress this, we formalise the dynamic replanning problem in public transport\nrouting and propose two solutions: a \"pull\" approach, where users manually\nrequest replanning, and a novel \"push\" approach, where the server proactively\nmonitors and adjusts journeys. Our experiments show that the push approach\noutperforms the pull approach, achieving significant speedups. The results also\nreveal substantial arrival time savings enabled by dynamic replanning.", "AI": {"tldr": "This paper addresses the lack of a framework to exploit live delay data for real-time journey adjustment in public transport routing. Two approaches are proposed: 'pull' (manual request) and 'push' (server monitoring). The push approach outperforms the pull approach with significant speedups and arrival time savings.", "motivation": "Existing solutions for handling delays in public transport are limited. Backup plans based on historical data miss opportunities for earlier arrivals, while snapshot planning does not account for future delays. Live delay data is underutilized for system-scale dynamic replanning.", "method": "Two solutions are proposed: a 'pull' approach where users manually request replanning, and a 'push' approach where the server proactively monitors and adjusts journeys.", "result": "The push approach outperforms the pull approach, achieving significant speedups. Dynamic replanning enables substantial arrival time savings.", "conclusion": "A framework for system-scale dynamic replanning in public transport routing has been developed, demonstrating the potential of using live delay data for real-time journey adjustments."}}
{"id": "2505.13775", "pdf": "https://arxiv.org/pdf/2505.13775", "abs": "https://arxiv.org/abs/2505.13775", "authors": ["Kaya Stechly", "Karthik Valmeekam", "Atharva Gundawar", "Vardhan Palod", "Subbarao Kambhampati"], "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent impressive results from large reasoning models have been interpreted\nas a triumph of Chain of Thought (CoT), and especially of the process of\ntraining on CoTs sampled from base LLMs in order to help find new reasoning\npatterns. In this paper, we critically examine that interpretation by\ninvestigating how the semantics of intermediate tokens-often anthropomorphized\nas \"thoughts\" or reasoning traces and which are claimed to display behaviors\nlike backtracking, self-verification etc.-actually influence model performance.\nWe train transformer models on formally verifiable reasoning traces and\nsolutions, constraining both intermediate steps and final outputs to align with\nthose of a formal solver (in our case, A* search). By constructing a formal\ninterpreter of the semantics of our problems and intended algorithm, we\nsystematically evaluate not only solution accuracy but also the correctness of\nintermediate traces, thus allowing us to evaluate whether the latter causally\ninfluences the former. We notice that, despite significant improvements on the\nsolution-only baseline, models trained on entirely correct traces still produce\ninvalid reasoning traces when arriving at correct solutions. To further show\nthat trace accuracy is only loosely connected to solution accuracy, we then\ntrain models on noisy, corrupted traces which have no relation to the specific\nproblem each is paired with, and find that not only does performance remain\nlargely consistent with models trained on correct data, but in some cases can\nimprove upon it and generalize more robustly on out-of-distribution tasks.\nThese results challenge the assumption that intermediate tokens or \"Chains of\nThought\" induce predictable reasoning behaviors and caution against\nanthropomorphizing such outputs or over-interpreting them (despite their mostly\ncorrect forms) as evidence of human-like or algorithmic behaviors in language\nmodels.", "AI": {"tldr": "This paper challenges the interpretation that large reasoning models' success is due to Chain of Thought (CoT) by investigating the impact of intermediate token semantics on model performance.", "motivation": "To critically examine the claim that training on CoTs sampled from base LLMs helps find new reasoning patterns.", "method": "Training transformer models on formally verifiable reasoning traces and solutions, constraining both intermediate steps and final outputs to align with those of a formal solver.", "result": "Models trained on entirely correct traces still produce invalid reasoning traces when arriving at correct solutions. Training on noisy, corrupted traces shows performance remains consistent or improves in some cases.", "conclusion": "Trace accuracy is only loosely connected to solution accuracy, challenging the assumption that intermediate tokens or 'Chains of Thought' induce predictable reasoning behaviors."}}
{"id": "2505.14209", "pdf": "https://arxiv.org/pdf/2505.14209", "abs": "https://arxiv.org/abs/2505.14209", "authors": ["Li Wang", "Xin Yu", "Xuxin Lv", "Gangzheng Ai", "Wenjun Wu"], "title": "Embedded Mean Field Reinforcement Learning for Perimeter-defense Game", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of unmanned aerial vehicles (UAVs) and missile\ntechnologies, perimeter-defense game between attackers and defenders for the\nprotection of critical regions have become increasingly complex and\nstrategically significant across a wide range of domains. However, existing\nstudies predominantly focus on small-scale, simplified two-dimensional\nscenarios, often overlooking realistic environmental perturbations, motion\ndynamics, and inherent heterogeneity--factors that pose substantial challenges\nto real-world applicability. To bridge this gap, we investigate large-scale\nheterogeneous perimeter-defense game in a three-dimensional setting,\nincorporating realistic elements such as motion dynamics and wind fields. We\nderive the Nash equilibrium strategies for both attackers and defenders,\ncharacterize the victory regions, and validate our theoretical findings through\nextensive simulations. To tackle large-scale heterogeneous control challenges\nin defense strategies, we propose an Embedded Mean-Field Actor-Critic (EMFAC)\nframework. EMFAC leverages representation learning to enable high-level action\naggregation in a mean-field manner, supporting scalable coordination among\ndefenders. Furthermore, we introduce a lightweight agent-level attention\nmechanism based on reward representation, which selectively filters\nobservations and mean-field information to enhance decision-making efficiency\nand accelerate convergence in large-scale tasks. Extensive simulations across\nvarying scales demonstrate the effectiveness and adaptability of EMFAC, which\noutperforms established baselines in both convergence speed and overall\nperformance. To further validate practicality, we test EMFAC in small-scale\nreal-world experiments and conduct detailed analyses, offering deeper insights\ninto the framework's effectiveness in complex scenarios.", "AI": {"tldr": "\u7814\u7a76\u5927\u89c4\u6a21\u5f02\u6784\u4e09\u7ef4\u8fb9\u5883\u9632\u5fa1\u535a\u5f08\u95ee\u9898\uff0c\u63d0\u51fa\u5d4c\u5165\u5f0f\u5e73\u5747\u573a\u6f14\u5458\u8bc4\u8bba\u5bb6(EMFAC)\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9645\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u5c0f\u89c4\u6a21\u4e8c\u7ef4\u7b80\u5316\u573a\u666f\uff0c\u5ffd\u89c6\u4e86\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u6270\u52a8\u3001\u8fd0\u52a8\u52a8\u529b\u5b66\u548c\u56fa\u6709\u5f02\u8d28\u6027\u7b49\u6311\u6218\u3002", "method": "\u5728\u4e09\u7ef4\u8bbe\u7f6e\u4e2d\u7814\u7a76\u5927\u89c4\u6a21\u5f02\u6784\u8fb9\u5883\u9632\u5fa1\u535a\u5f08\uff0c\u8003\u8651\u8fd0\u52a8\u52a8\u529b\u5b66\u548c\u98ce\u573a\u7b49\u771f\u5b9e\u5143\u7d20\uff0c\u63a8\u5bfc\u7eb3\u4ec0\u5747\u8861\u7b56\u7565\u5e76\u63d0\u51faEMFAC\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u53d1\u73b0\uff0cEMFAC\u5728\u6536\u655b\u901f\u5ea6\u548c\u6574\u4f53\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5728\u5c0f\u89c4\u6a21\u73b0\u5b9e\u5b9e\u9a8c\u4e2d\u4e5f\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684EMFAC\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u5f02\u6784\u8fb9\u5883\u9632\u5fa1\u4e2d\u7684\u63a7\u5236\u6311\u6218\uff0c\u5e76\u5728\u590d\u6742\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2505.13787", "pdf": "https://arxiv.org/pdf/2505.13787", "abs": "https://arxiv.org/abs/2505.13787", "authors": ["Chris Cundy", "Adam Gleave"], "title": "Preference Learning with Lie Detectors can Induce Honesty or Evasion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As AI systems become more capable, deceptive behaviors can undermine\nevaluation and mislead users at deployment. Recent work has shown that lie\ndetectors can accurately classify deceptive behavior, but they are not\ntypically used in the training pipeline due to concerns around contamination\nand objective hacking. We examine these concerns by incorporating a lie\ndetector into the labelling step of LLM post-training and evaluating whether\nthe learned policy is genuinely more honest, or instead learns to fool the lie\ndetector while remaining deceptive. Using DolusChat, a novel 65k-example\ndataset with paired truthful/deceptive responses, we identify three key factors\nthat determine the honesty of learned policies: amount of exploration during\npreference learning, lie detector accuracy, and KL regularization strength. We\nfind that preference learning with lie detectors and GRPO can lead to policies\nwhich evade lie detectors, with deception rates of over 85\\%. However, if the\nlie detector true positive rate (TPR) or KL regularization is sufficiently\nhigh, GRPO learns honest policies. In contrast, off-policy algorithms (DPO)\nconsistently lead to deception rates under 25\\% for realistic TPRs. Our results\nillustrate a more complex picture than previously assumed: depending on the\ncontext, lie-detector-enhanced training can be a powerful tool for scalable\noversight, or a counterproductive method encouraging undetectable misalignment.", "AI": {"tldr": "This paper investigates how integrating lie detectors into the training of large language models affects their honesty. It finds that while lie detectors can sometimes encourage honesty, they can also lead to deceptive behaviors that are harder to detect.", "motivation": "To understand the impact of using lie detectors in the training process of AI systems on their deceptive behaviors.", "method": "Incorporating a lie detector into the labeling step of LLM post-training and evaluating the learned policy's honesty.", "result": "Preference learning with lie detectors and GRPO can result in deceptive policies with over 85% deception rates. High lie detector true positive rate or KL regularization can lead to honest policies. Off-policy algorithms consistently lead to lower deception rates.", "conclusion": "The use of lie detectors in training can either promote honesty or encourage undetectable misalignment depending on the context."}}
{"id": "2505.14216", "pdf": "https://arxiv.org/pdf/2505.14216", "abs": "https://arxiv.org/abs/2505.14216", "authors": ["Minwu Kim", "Anubhav Shrestha", "Safal Shrestha", "Aadim Nepal", "Keith Ross"], "title": "Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "23 pages", "summary": "Recent studies have shown that reinforcement learning with verifiable rewards\n(RLVR) enhances overall accuracy but fails to improve capability, while\ndistillation can improve both. In this paper, we investigate the mechanisms\nbehind these phenomena. First, we demonstrate that RLVR does not improve\ncapability because it focuses on improving the accuracy of the less-difficult\nquestions to the detriment of the accuracy of the most difficult questions,\nthereby leading to no improvement in capability. Second, we find that RLVR does\nnot merely increase the success probability for the less difficult questions,\nbut in our small model settings produces quality responses that were absent in\nits output distribution before training. In addition, we show these responses\nare neither noticeably longer nor feature more reflection-related keywords,\nunderscoring the need for more reliable indicators of response quality. Third,\nwe show that while distillation reliably improves accuracy by learning strong\nreasoning patterns, it only improves capability when new knowledge is\nintroduced. Moreover, when distilling only with reasoning patterns and no new\nknowledge, the accuracy of the less-difficult questions improves to the\ndetriment of the most difficult questions, similar to RLVR. Together, these\nfindings offer a clearer understanding of how RLVR and distillation shape\nreasoning behavior in language models.", "AI": {"tldr": "This paper investigates why reinforcement learning with verifiable rewards (RLVR) enhances accuracy but not capability, and why distillation improves both. It finds that RLVR prioritizes easier questions at the expense of harder ones and doesn't generate notably longer or reflective responses. Distillation improves accuracy through strong reasoning patterns but only boosts capability with new knowledge.", "motivation": "To understand the mechanisms behind the phenomena of RLVR enhancing accuracy but not capability, and distillation improving both.", "method": "Investigating the mechanisms through analysis and experiments.", "result": "RLVR does not improve capability as it focuses on easier questions, and its small model settings produce quality responses absent before training without noticeable length or reflection keyword increases. Distillation improves accuracy via strong reasoning patterns but only enhances capability when new knowledge is introduced.", "conclusion": "The findings provide insights into how RLVR and distillation influence reasoning behavior in language models."}}
{"id": "2505.13791", "pdf": "https://arxiv.org/pdf/2505.13791", "abs": "https://arxiv.org/abs/2505.13791", "authors": ["Austin H. Cheng", "Chong Sun", "Al\u00e1n Aspuru-Guzik"], "title": "Scalable Autoregressive 3D Molecule Generation", "categories": ["cs.LG", "physics.chem-ph"], "comment": null, "summary": "Generative models of 3D molecular structure play a rapidly growing role in\nthe design and simulation of molecules. Diffusion models currently dominate the\nspace of 3D molecule generation, while autoregressive models have trailed\nbehind. In this work, we present Quetzal, a simple but scalable autoregressive\nmodel that builds molecules atom-by-atom in 3D. Treating each molecule as an\nordered sequence of atoms, Quetzal combines a causal transformer that predicts\nthe next atom's discrete type with a smaller Diffusion MLP that models the\ncontinuous next-position distribution. Compared to existing autoregressive\nbaselines, Quetzal achieves substantial improvements in generation quality and\nis competitive with the performance of state-of-the-art diffusion models. In\naddition, by reducing the number of expensive forward passes through a dense\ntransformer, Quetzal enables significantly faster generation speed, as well as\nexact divergence-based likelihood computation. Finally, without any\narchitectural changes, Quetzal natively handles variable-size tasks like\nhydrogen decoration and scaffold completion. We hope that our work motivates a\nperspective on scalability and generality for generative modelling of 3D\nmolecules.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuetzal\u7684\u7b80\u5355\u4e14\u53ef\u6269\u5c55\u7684\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u7528\u4e8e\u9010\u539f\u5b50\u57283D\u7a7a\u95f4\u751f\u6210\u5206\u5b50\u3002\u8be5\u6a21\u578b\u5728\u751f\u6210\u8d28\u91cf\u548c\u901f\u5ea6\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u53ef\u4ee5\u5904\u7406\u53ef\u53d8\u5927\u5c0f\u7684\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d3D\u5206\u5b50\u751f\u6210\u9886\u57df\u6269\u6563\u6a21\u578b\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u800c\u81ea\u56de\u5f52\u6a21\u578b\u843d\u540e\u3002\u5e0c\u671b\u901a\u8fc7\u7814\u7a76\u63a8\u52a83D\u5206\u5b50\u751f\u6210\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002", "method": "Quetzal\u6a21\u578b\u7ed3\u5408\u4e86\u56e0\u679c\u53d8\u6362\u5668\u548c\u5c0f\u89c4\u6a21\u6269\u6563MLP\uff0c\u56e0\u679c\u53d8\u6362\u5668\u9884\u6d4b\u4e0b\u4e00\u4e2a\u539f\u5b50\u7684\u79bb\u6563\u7c7b\u578b\uff0c\u6269\u6563MLP\u5efa\u6a21\u8fde\u7eed\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\u5206\u5e03\u3002", "result": "Quetzal\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u6709\u663e\u8457\u6539\u8fdb\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u6269\u6563\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u5e76\u4e14\u751f\u6210\u901f\u5ea6\u66f4\u5feb\uff0c\u8fd8\u53ef\u4ee5\u7cbe\u786e\u8ba1\u7b97\u57fa\u4e8e\u53d1\u6563\u7684\u4f3c\u7136\u503c\u3002", "conclusion": "Quetzal\u5c55\u793a\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u57283D\u5206\u5b50\u751f\u6210\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u53d8\u91cf\u5927\u5c0f\u7684\u4efb\u52a1\uff0c\u5e0c\u671b\u6fc0\u52b1\u66f4\u591a\u5173\u4e8e\u751f\u6210\u6a21\u578b\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u7684\u7814\u7a76\u3002"}}
{"id": "2505.14235", "pdf": "https://arxiv.org/pdf/2505.14235", "abs": "https://arxiv.org/abs/2505.14235", "authors": ["Yequan Wang", "Aixin Sun"], "title": "Toward Embodied AGI: A Review of Embodied AI and the Road Ahead", "categories": ["cs.AI"], "comment": null, "summary": "Artificial General Intelligence (AGI) is often envisioned as inherently\nembodied. With recent advances in robotics and foundational AI models, we stand\nat the threshold of a new era-one marked by increasingly generalized embodied\nAI systems. This paper contributes to the discourse by introducing a systematic\ntaxonomy of Embodied AGI spanning five levels (L1-L5). We review existing\nresearch and challenges at the foundational stages (L1-L2) and outline the key\ncomponents required to achieve higher-level capabilities (L3-L5). Building on\nthese insights and existing technologies, we propose a conceptual framework for\nan L3+ robotic brain, offering both a technical outlook and a foundation for\nfuture exploration.", "AI": {"tldr": "This paper introduces a taxonomy for Embodied AGI with five levels and proposes a conceptual framework for an L3+ robotic brain.", "motivation": "To contribute to the discourse on Artificial General Intelligence (AGI) by creating a systematic taxonomy and exploring higher-level capabilities.", "method": "Introduce a taxonomy of Embodied AGI with five levels and review existing research and challenges at foundational stages. Outline key components for higher-level capabilities.", "result": "A proposed conceptual framework for an L3+ robotic brain based on insights and existing technologies.", "conclusion": "The paper outlines a path towards increasingly generalized embodied AI systems."}}
{"id": "2505.13811", "pdf": "https://arxiv.org/pdf/2505.13811", "abs": "https://arxiv.org/abs/2505.13811", "authors": ["Parikshit Bansal", "Sujay Sanghavi"], "title": "Context-Free Synthetic Data Mitigates Forgetting", "categories": ["cs.LG"], "comment": null, "summary": "Fine-tuning a language model often results in a degradation of its existing\nperformance on other tasks, due to a shift in the model parameters; this\nphenomenon is often referred to as (catastrophic) forgetting. We are interested\nin mitigating this, in settings where we only have access to the model weights\nbut no access to its training data/recipe. A natural approach is to penalize\nthe KL divergence between the original model and the new one. Our main\nrealization is that a simple process - which we term context-free generation -\nallows for an approximate unbiased estimation of this KL divergence. We show\nthat augmenting a fine-tuning dataset with context-free generations mitigates\nforgetting, in two settings: (a) preserving the zero-shot performance of\npretrained-only models, and (b) preserving the reasoning performance of\nthinking models. We show that contextual synthetic data, and even a portion of\nthe pretraining data, are less effective. We also investigate the effect of\nchoices like generation temperature, data ratios etc. We present our results\nfor OLMo-1B for pretrained-only setting and R1-Distill-Llama-8B for the\nreasoning setting.", "AI": {"tldr": "This paper investigates mitigating catastrophic forgetting during fine-tuning of language models without access to training data.", "motivation": "To address the issue of performance degradation on other tasks when fine-tuning a language model.", "method": "Penalizing the KL divergence between the original and new model by using context-free generation.", "result": "Augmenting fine-tuning datasets with context-free generations reduces forgetting in both zero-shot and reasoning performance settings.", "conclusion": "Context-free generation is an effective method to mitigate catastrophic forgetting."}}
{"id": "2505.14289", "pdf": "https://arxiv.org/pdf/2505.14289", "abs": "https://arxiv.org/abs/2505.14289", "authors": ["Yijie Lu", "Tianjie Ju", "Manman Zhao", "Xinbei Ma", "Yuan Guo", "ZhuoSheng Zhang"], "title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection", "categories": ["cs.AI"], "comment": null, "summary": "As multimodal agents are increasingly trained to operate graphical user\ninterfaces (GUIs) to complete user tasks, they face a growing threat from\nindirect prompt injection, attacks in which misleading instructions are\nembedded into the agent's visual environment, such as popups or chat messages,\nand misinterpreted as part of the intended task. A typical example is\nenvironmental injection, in which GUI elements are manipulated to influence\nagent behavior without directly modifying the user prompt. To address these\nemerging attacks, we propose EVA, a red teaming framework for indirect prompt\ninjection which transforms the attack into a closed loop optimization by\ncontinuously monitoring an agent's attention distribution over the GUI and\nupdating adversarial cues, keywords, phrasing, and layout, in response.\nCompared with prior one shot methods that generate fixed prompts without regard\nfor how the model allocates visual attention, EVA dynamically adapts to\nemerging attention hotspots, yielding substantially higher attack success rates\nand far greater transferability across diverse GUI scenarios. We evaluate EVA\non six widely used generalist and specialist GUI agents in realistic settings\nsuch as popup manipulation, chat based phishing, payments, and email\ncomposition. Experimental results show that EVA substantially improves success\nrates over static baselines. Under goal agnostic constraints, where the\nattacker does not know the agent's task intent, EVA still discovers effective\npatterns. Notably, we find that injection styles transfer well across models,\nrevealing shared behavioral biases in GUI agents. These results suggest that\nevolving indirect prompt injection is a powerful tool not only for red teaming\nagents, but also for uncovering common vulnerabilities in their multimodal\ndecision making.", "AI": {"tldr": "This paper proposes EVA, a red teaming framework for indirect prompt injection that uses continuous monitoring and updating of adversarial cues to improve attack success rates and transferability across diverse GUI scenarios.", "motivation": "To address emerging threats from indirect prompt injection attacks on multimodal agents operating GUIs.", "method": "EVA transforms the attack into a closed loop optimization by continuously monitoring an agent's attention distribution over the GUI and updating adversarial cues, keywords, phrasing, and layout.", "result": "EVA improves attack success rates and transferability across diverse GUI scenarios compared to previous one-shot methods.", "conclusion": "Indirect prompt injection is a powerful tool for red teaming agents and uncovering common vulnerabilities in their multimodal decision making."}}
{"id": "2505.13813", "pdf": "https://arxiv.org/pdf/2505.13813", "abs": "https://arxiv.org/abs/2505.13813", "authors": ["Matthew Raffel", "Lizhong Chen"], "title": "FlashKAT: Understanding and Addressing Performance Bottlenecks in the Kolmogorov-Arnold Transformer", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The Kolmogorov-Arnold Network (KAN) has been gaining popularity as an\nalternative to the multi-layer perceptron (MLP) with its increased\nexpressiveness and interpretability. However, the KAN can be orders of\nmagnitude slower due to its increased computational cost and training\ninstability, limiting its applicability to larger-scale tasks. Recently, the\nKolmogorov-Arnold Transformer (KAT) has been proposed, which can achieve FLOPs\nsimilar to the traditional Transformer with MLPs by leveraging Group-Rational\nKAN (GR-KAN). Unfortunately, despite the comparable FLOPs, our\ncharacterizations reveal that the KAT is still 123x slower in training speeds,\nindicating that there are other performance bottlenecks beyond FLOPs. In this\npaper, we conduct a series of experiments to understand the root cause of the\nslowdown in KAT. We uncover that the slowdown can be isolated to memory stalls\nand, more specifically, in the backward pass of GR-KAN caused by inefficient\ngradient accumulation. To address this memory bottleneck, we propose FlashKAT,\nwhich builds on our restructured kernel that minimizes gradient accumulation\nwith atomic adds and accesses to slow memory. Evaluations demonstrate that\nFlashKAT can achieve a training speedup of 86.5x compared with the\nstate-of-the-art KAT, while reducing rounding errors in the coefficient\ngradients. Our code is available at https://github.com/OSU-STARLAB/FlashKAT.", "AI": {"tldr": "This paper investigates why the Kolmogorov-Arnold Transformer (KAT) is significantly slower than expected despite having similar FLOPs to traditional Transformers. It identifies memory stalls, particularly in the backward pass of GR-KAN, as the main bottleneck and proposes FlashKAT, which improves training speed by 86.5x.", "motivation": "To understand why KAT is slower than expected and find ways to improve its training speed.", "method": "Conducting experiments to analyze the slowdown in KAT and proposing FlashKAT to address the identified memory bottleneck.", "result": "FlashKAT achieves a training speedup of 86.5x over KAT and reduces rounding errors in coefficient gradients.", "conclusion": "FlashKAT successfully addresses the memory bottleneck in KAT, significantly improving its training speed."}}
{"id": "2505.14300", "pdf": "https://arxiv.org/pdf/2505.14300", "abs": "https://arxiv.org/abs/2505.14300", "authors": ["Maheep Chaudhary", "Fazl Barez"], "title": "SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "High-risk industries like nuclear and aviation use real-time monitoring to\ndetect dangerous system conditions. Similarly, Large Language Models (LLMs)\nneed monitoring safeguards. We propose a real-time framework to predict harmful\nAI outputs before they occur by using an unsupervised approach that treats\nnormal behavior as the baseline and harmful outputs as outliers. Our study\nfocuses specifically on backdoor-triggered responses -- where specific input\nphrases activate hidden vulnerabilities causing the model to generate unsafe\ncontent like violence, pornography, or hate speech. We address two key\nchallenges: (1) identifying true causal indicators rather than surface\ncorrelations, and (2) preventing advanced models from deception -- deliberately\nevading monitoring systems. Hence, we approach this problem from an\nunsupervised lens by drawing parallels to human deception: just as humans\nexhibit physical indicators while lying, we investigate whether LLMs display\ndistinct internal behavioral signatures when generating harmful content. Our\nstudy addresses two critical challenges: 1) designing monitoring systems that\ncapture true causal indicators rather than superficial correlations; and\n2)preventing intentional evasion by increasingly capable \"Future models''. Our\nfindings show that models can produce harmful content through causal mechanisms\nand can become deceptive by: (a) alternating between linear and non-linear\nrepresentations, and (b) modifying feature relationships. To counter this, we\ndeveloped Safety-Net -- a multi-detector framework that monitors different\nrepresentation dimensions, successfully detecting harmful behavior even when\ninformation is shifted across representational spaces to evade individual\nmonitors. Our evaluation shows 96% accuracy in detecting harmful cases using\nour unsupervised ensemble approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u6846\u67b6\u6765\u9884\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ea7\u751f\u7684\u6709\u5bb3\u8f93\u51fa\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u6cd5\u8bc6\u522b\u6b63\u5e38\u884c\u4e3a\u4e0e\u6709\u5bb3\u8f93\u51fa\u7684\u533a\u522b\u3002\u7814\u7a76\u805a\u7126\u4e8e\u540e\u95e8\u89e6\u53d1\u54cd\u5e94\uff0c\u5f00\u53d1\u4e86Safety-Net\u591a\u68c0\u6d4b\u5668\u6846\u67b6\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u9ad8\u98ce\u9669\u884c\u4e1a\u9700\u8981\u76d1\u63a7\u4fdd\u969c\uff0cLLMs\u540c\u6837\u9700\u8981\u9632\u6b62\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\uff0c\u5982\u66b4\u529b\u3001\u8272\u60c5\u6216\u4ec7\u6068\u8a00\u8bba\u3002", "method": "\u91c7\u7528\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u5c06\u6b63\u5e38\u884c\u4e3a\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u6709\u5bb3\u8f93\u51fa\u89c6\u4e3a\u5f02\u5e38\u503c\u3002\u4ece\u4eba\u7c7b\u6b3a\u9a97\u884c\u4e3a\u4e2d\u5f97\u5230\u542f\u53d1\uff0c\u63a2\u7d22LLMs\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u65f6\u7684\u5185\u90e8\u884c\u4e3a\u7279\u5f81\u3002", "result": "Safety-Net\u6846\u67b6\u5728\u68c0\u6d4b\u6709\u5bb3\u6848\u4f8b\u65f6\u8fbe\u5230\u4e8696%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u56e0\u679c\u673a\u5236\u4ea7\u751f\u6709\u5bb3\u5185\u5bb9\uff0c\u5e76\u53ef\u80fd\u53d8\u5f97\u5177\u6709\u6b3a\u9a97\u6027\u3002\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u8de8\u8868\u5f81\u7a7a\u95f4\u8f6c\u79fb\u4fe1\u606f\u65f6\u7684\u6709\u5bb3\u884c\u4e3a\u3002"}}
{"id": "2505.13819", "pdf": "https://arxiv.org/pdf/2505.13819", "abs": "https://arxiv.org/abs/2505.13819", "authors": ["Lucas Rosenblatt", "Bin Han", "Robert Wolfe", "Bill Howe"], "title": "Fragments to Facts: Partial-Information Fragment Inference from LLMs", "categories": ["cs.LG", "cs.CR", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) can leak sensitive training data through\nmemorization and membership inference attacks. Prior work has primarily focused\non strong adversarial assumptions, including attacker access to entire samples\nor long, ordered prefixes, leaving open the question of how vulnerable LLMs are\nwhen adversaries have only partial, unordered sample information. For example,\nif an attacker knows a patient has \"hypertension,\" under what conditions can\nthey query a model fine-tuned on patient data to learn the patient also has\n\"osteoarthritis?\" In this paper, we introduce a more general threat model under\nthis weaker assumption and show that fine-tuned LLMs are susceptible to these\nfragment-specific extraction attacks. To systematically investigate these\nattacks, we propose two data-blind methods: (1) a likelihood ratio attack\ninspired by methods from membership inference, and (2) a novel approach, PRISM,\nwhich regularizes the ratio by leveraging an external prior. Using examples\nfrom both medical and legal settings, we show that both methods are competitive\nwith a data-aware baseline classifier that assumes access to labeled\nin-distribution data, underscoring their robustness.", "AI": {"tldr": "This paper investigates the vulnerability of fine-tuned large language models to fragment-specific extraction attacks when adversaries have only partial, unordered sample information. Two data-blind methods are proposed and shown to be competitive with a data-aware baseline.", "motivation": "To explore how vulnerable large language models are to partial, unordered sample information under a weaker assumption.", "method": "Propose two data-blind methods: (1) a likelihood ratio attack and (2) PRISM.", "result": "Both methods are competitive with a data-aware baseline classifier in medical and legal settings.", "conclusion": "Fine-tuned LLMs are susceptible to fragment-specific extraction attacks under weaker assumptions."}}
{"id": "2505.14366", "pdf": "https://arxiv.org/pdf/2505.14366", "abs": "https://arxiv.org/abs/2505.14366", "authors": ["Joel Currie", "Gioele Migno", "Enrico Piacenti", "Maria Elena Giannaccini", "Patric Bach", "Davide De Tommaso", "Agnieszka Wykowska"], "title": "Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late\n  Breaking Report", "summary": "We present a conceptual framework for training Vision-Language Models (VLMs)\nto perform Visual Perspective Taking (VPT), a core capability for embodied\ncognition essential for Human-Robot Interaction (HRI). As a first step toward\nthis goal, we introduce a synthetic dataset, generated in NVIDIA Omniverse,\nthat enables supervised learning for spatial reasoning tasks. Each instance\nincludes an RGB image, a natural language description, and a ground-truth 4X4\ntransformation matrix representing object pose. We focus on inferring Z-axis\ndistance as a foundational skill, with future extensions targeting full 6\nDegrees Of Freedom (DOFs) reasoning. The dataset is publicly available to\nsupport further research. This work serves as a foundational step toward\nembodied AI systems capable of spatial understanding in interactive human-robot\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\u6765\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u6267\u884c\u89c6\u89c9\u89c6\u89d2\u83b7\u53d6(VPT)\uff0c\u8fd9\u662f\u5b9e\u4f53\u8ba4\u77e5\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u5bf9\u4eba\u673a\u4ea4\u4e92(HRI)\u81f3\u5173\u91cd\u8981\u3002\u5f15\u5165\u4e86\u4e00\u4e2a\u5728NVIDIA Omniverse\u4e2d\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u76d1\u7763\u5b66\u4e60\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u3002\u91cd\u70b9\u5728\u4e8e\u63a8\u65adZ\u8f74\u8ddd\u79bb\u4f5c\u4e3a\u4e00\u79cd\u57fa\u7840\u6280\u80fd\uff0c\u5e76\u8ba1\u5212\u672a\u6765\u6269\u5c55\u5230\u5b8c\u6574\u76846\u81ea\u7531\u5ea6\u63a8\u7406\u3002\u8be5\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u8fd9\u9879\u5de5\u4f5c\u662f\u8fc8\u5411\u5177\u5907\u4ea4\u4e92\u5f0f\u4eba\u673a\u573a\u666f\u4e2d\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\u7684\u5b9e\u4f53AI\u7cfb\u7edf\u7684\u57fa\u7840\u6b65\u9aa4\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5728\u4ea4\u4e92\u5f0f\u4eba\u673a\u573a\u666f\u4e2d\u6709\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u53d1\u5c55\u4e00\u79cd\u6838\u5fc3\u7684\u5b9e\u4f53\u8ba4\u77e5\u80fd\u529b\uff0c\u5373\u89c6\u89c9\u89c6\u89d2\u83b7\u53d6(VPT)\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u5408\u6210\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u62ecRGB\u56fe\u50cf\u3001\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u8868\u793a\u7269\u4f53\u59ff\u6001\u76844X4\u53d8\u6362\u77e9\u9635\u3002", "result": "\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\uff0c\u53ef\u4ee5\u7528\u6765\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002", "conclusion": "\u8fd9\u662f\u8fc8\u5411\u5177\u5907\u4ea4\u4e92\u5f0f\u4eba\u673a\u573a\u666f\u4e2d\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\u7684\u5b9e\u4f53AI\u7cfb\u7edf\u7684\u57fa\u7840\u6b65\u9aa4\u3002"}}
{"id": "2505.13820", "pdf": "https://arxiv.org/pdf/2505.13820", "abs": "https://arxiv.org/abs/2505.13820", "authors": ["Jun Liu", "Zhenglun Kong", "Peiyan Dong", "Changdi Yang", "Tianqi Li", "Hao Tang", "Geng Yuan", "Wei Niu", "Wenbin Zhang", "Pu Zhao", "Xue Lin", "Dong Huang", "Yanzhi Wang"], "title": "Structured Agent Distillation for Large Language Model", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit strong capabilities as decision-making\nagents by interleaving reasoning and actions, as seen in ReAct-style\nframeworks. Yet, their practical deployment is constrained by high inference\ncosts and large model sizes. We propose Structured Agent Distillation, a\nframework that compresses large LLM-based agents into smaller student models\nwhile preserving both reasoning fidelity and action consistency. Unlike\nstandard token-level distillation, our method segments trajectories into\n{[REASON]} and {[ACT]} spans, applying segment-specific losses to align each\ncomponent with the teacher's behavior. This structure-aware supervision enables\ncompact agents to better replicate the teacher's decision process. Experiments\non ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently\noutperforms token-level and imitation learning baselines, achieving significant\ncompression with minimal performance drop. Scaling and ablation results further\nhighlight the importance of span-level alignment for efficient and deployable\nagents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u7528\u4e8e\u538b\u7f29\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6027\u80fd\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u51b3\u7b56\u4ee3\u7406\u5177\u6709\u5f3a\u5927\u7684\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u9ad8\u63a8\u7406\u6210\u672c\u548c\u5927\u6a21\u578b\u5c3a\u5bf8\u9650\u5236\u4e86\u5176\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u7ed3\u6784\u5316\u4ee3\u7406\u84b8\u998f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u8f68\u8ff9\u5206\u5272\u4e3a{[REASON]}\u548c{[ACT]}\u7247\u6bb5\uff0c\u5e76\u5e94\u7528\u7247\u6bb5\u7279\u5b9a\u635f\u5931\u6765\u5bf9\u9f50\u6bcf\u4e2a\u7ec4\u4ef6\u7684\u884c\u4e3a\u3002", "result": "\u5728ALFWorld\u3001HotPotQA-ReAct\u548cWebShop\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u6807\u8bb0\u7ea7\u548c\u6a21\u4eff\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9ad8\u6548\u548c\u53ef\u90e8\u7f72\u4ee3\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u538b\u7f29\u5927\u578bLLM\u4ee3\u7406\u6a21\u578b\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u63a8\u7406\u4fdd\u771f\u5ea6\u548c\u52a8\u4f5c\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u53ef\u4ee5\u5b9e\u73b0\u663e\u8457\u7684\u6a21\u578b\u538b\u7f29\uff0c\u6027\u80fd\u4e0b\u964d\u6781\u5c0f\u3002"}}
{"id": "2505.14381", "pdf": "https://arxiv.org/pdf/2505.14381", "abs": "https://arxiv.org/abs/2505.14381", "authors": ["Yuyang Dong", "Nobuhiro Ueda", "Kriszti\u00e1n Boros", "Daiki Ito", "Takuya Sera", "Masafumi Oyamada"], "title": "SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "v1", "summary": "With the increasing adoption of Large Language Models (LLMs) and\nVision-Language Models (VLMs), rich document analysis technologies for\napplications like Retrieval-Augmented Generation (RAG) and visual RAG are\ngaining significant attention. Recent research indicates that using VLMs can\nachieve better RAG performance, but processing rich documents still remains a\nchallenge since a single page contains large amounts of information. In this\npaper, we present SCAN (\\textbf{S}emanti\\textbf{C} Document Layout\n\\textbf{AN}alysis), a novel approach enhancing both textual and visual\nRetrieval-Augmented Generation (RAG) systems working with visually rich\ndocuments. It is a VLM-friendly approach that identifies document components\nwith appropriate semantic granularity, balancing context preservation with\nprocessing efficiency. SCAN uses a coarse-grained semantic approach that\ndivides documents into coherent regions covering continuous components. We\ntrained the SCAN model by fine-tuning object detection models with\nsophisticated annotation datasets. Our experimental results across English and\nJapanese datasets demonstrate that applying SCAN improves end-to-end textual\nRAG performance by up to 9.0\\% and visual RAG performance by up to 6.4\\%,\noutperforming conventional approaches and even commercial document processing\nsolutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5SCAN\uff0c\u7528\u4e8e\u589e\u5f3a\u5904\u7406\u89c6\u89c9\u4e30\u5bcc\u6587\u6863\u7684\u6587\u672c\u548c\u89c6\u89c9RAG\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9002\u5f53\u7684\u8bed\u4e49\u7c92\u5ea6\u8bc6\u522b\u6587\u6863\u7ec4\u4ef6\uff0c\u5728\u4e0a\u4e0b\u6587\u4fdd\u7559\u4e0e\u5904\u7406\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5e94\u7528SCAN\u53ef\u4ee5\u63d0\u9ad8\u6587\u672cRAG\u6027\u80fd\u6700\u9ad8\u53ef\u8fbe9.0\uff05\uff0c\u89c6\u89c9RAG\u6027\u80fd\u6700\u9ad8\u53ef\u8fbe6.4\uff05\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u89c6\u89c9RAG\u7b49\u5e94\u7528\u7a0b\u5e8f\u7684\u5bcc\u6587\u6863\u5206\u6790\u6280\u672f\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u7136\u800c\uff0c\u5904\u7406\u5bcc\u6587\u6863\u4ecd\u7136\u5b58\u5728\u6311\u6218\uff0c\u56e0\u4e3a\u5355\u4e2a\u9875\u9762\u5305\u542b\u5927\u91cf\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSCAN\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u662f\u4e00\u79cdVLM\u53cb\u597d\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u5177\u6709\u9002\u5f53\u8bed\u4e49\u7c92\u5ea6\u7684\u6587\u6863\u7ec4\u4ef6\uff0c\u5e76\u4f7f\u7528\u7c97\u7c92\u5ea6\u8bed\u4e49\u65b9\u6cd5\u5c06\u6587\u6863\u5212\u5206\u4e3a\u8fde\u8d2f\u7684\u533a\u57df\u8986\u76d6\u8fde\u7eed\u7ec4\u4ef6\u3002\u901a\u8fc7\u5fae\u8c03\u5e26\u6709\u590d\u6742\u6ce8\u91ca\u6570\u636e\u96c6\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u6765\u8bad\u7ec3SCAN\u6a21\u578b\u3002", "result": "\u5728\u82f1\u8bed\u548c\u65e5\u8bed\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5e94\u7528SCAN\u53ef\u4ee5\u63d0\u9ad8\u7aef\u5230\u7aef\u6587\u672cRAG\u6027\u80fd\u6700\u9ad8\u53ef\u8fbe9.0\uff05\uff0c\u89c6\u89c9RAG\u6027\u80fd\u6700\u9ad8\u53ef\u8fbe6.4\uff05\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u751a\u81f3\u5546\u4e1a\u6587\u6863\u5904\u7406\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SCAN\u662f\u4e00\u79cd\u6709\u6548\u7684VLM\u53cb\u597d\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5904\u7406\u89c6\u89c9\u4e30\u5bcc\u6587\u6863\u7684\u6587\u672c\u548c\u89c6\u89c9RAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2505.13852", "pdf": "https://arxiv.org/pdf/2505.13852", "abs": "https://arxiv.org/abs/2505.13852", "authors": ["Yusheng Zhao", "Chi Zhang", "Yuxuan Du"], "title": "Rethink the Role of Deep Learning towards Large-scale Quantum Systems", "categories": ["cs.LG", "quant-ph"], "comment": "ICML 2025", "summary": "Characterizing the ground state properties of quantum systems is fundamental\nto capturing their behavior but computationally challenging. Recent advances in\nAI have introduced novel approaches, with diverse machine learning (ML) and\ndeep learning (DL) models proposed for this purpose. However, the necessity and\nspecific role of DL models in these tasks remain unclear, as prior studies\noften employ varied or impractical quantum resources to construct datasets,\nresulting in unfair comparisons. To address this, we systematically benchmark\nDL models against traditional ML approaches across three families of\nHamiltonian, scaling up to 127 qubits in three crucial ground-state learning\ntasks while enforcing equivalent quantum resource usage. Our results reveal\nthat ML models often achieve performance comparable to or even exceeding that\nof DL approaches across all tasks. Furthermore, a randomization test\ndemonstrates that measurement input features have minimal impact on DL models'\nprediction performance. These findings challenge the necessity of current DL\nmodels in many quantum system learning scenarios and provide valuable insights\ninto their effective utilization.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u91cf\u5b50\u7cfb\u7edf\u57fa\u6001\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4e86\u516c\u5e73\u6bd4\u8f83\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5728\u91cf\u5b50\u7cfb\u7edf\u57fa\u6001\u7279\u6027\u523b\u753b\u4e2d\u7684\u5fc5\u8981\u6027\u548c\u5177\u4f53\u4f5c\u7528\u7684\u7814\u7a76\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u4e3a\u4e4b\u524d\u7684\u7814\u7a76\u5f80\u5f80\u4f7f\u7528\u4e0d\u540c\u7684\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u91cf\u5b50\u8d44\u6e90\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u4e0d\u516c\u5e73\u7684\u5bf9\u6bd4\u3002", "method": "\u5bf9\u4e09\u79cd\u54c8\u5bc6\u987f\u91cf\u65cf\u4e0b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u89c4\u6a21\u6269\u5c55\u5230127\u4e2a\u91cf\u5b50\u6bd4\u7279\uff0c\u5e76\u786e\u4fdd\u7b49\u91cf\u7684\u91cf\u5b50\u8d44\u6e90\u4f7f\u7528\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u901a\u5e38\u80fd\u8fbe\u5230\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff1b\u968f\u673a\u5316\u6d4b\u8bd5\u8868\u660e\u6d4b\u91cf\u8f93\u5165\u7279\u5f81\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5e76\u975e\u8bb8\u591a\u91cf\u5b50\u7cfb\u7edf\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5fc5\u8981\u9009\u62e9\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u6709\u6548\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.14391", "pdf": "https://arxiv.org/pdf/2505.14391", "abs": "https://arxiv.org/abs/2505.14391", "authors": ["Zhaohui Yang", "Chenghua He", "Xiaowen Shi", "Linjing Li", "Qiyue Yin", "Shihong Deng", "Daxin Jiang"], "title": "Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Many studies focus on data annotation techniques for training effective PRMs.\nHowever, current methods encounter a significant issue when applied to long CoT\nreasoning processes: they tend to focus solely on the first incorrect step and\nall preceding steps, assuming that all subsequent steps are incorrect. These\nmethods overlook the unique self-correction and reflection mechanisms inherent\nin long CoT, where correct reasoning steps may still occur after initial\nreasoning mistakes. To address this issue, we propose a novel data annotation\nmethod for PRMs specifically designed to score the long CoT reasoning process.\nGiven that under the reflection pattern, correct and incorrect steps often\nalternate, we introduce the concepts of Error Propagation and Error Cessation,\nenhancing PRMs' ability to identify both effective self-correction behaviors\nand reasoning based on erroneous steps. Leveraging an LLM-based judger for\nannotation, we collect 1.7 million data samples to train a 7B PRM and evaluate\nit at both solution and step levels. Experimental results demonstrate that\ncompared to existing open-source PRMs and PRMs trained on open-source datasets,\nour PRM achieves superior performance across various metrics, including search\nguidance, BoN, and F1 scores. Compared to widely used MC-based annotation\nmethods, our annotation approach not only achieves higher data efficiency but\nalso delivers superior performance. Detailed analysis is also conducted to\ndemonstrate the stability and generalizability of our method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684PRM\u6570\u636e\u6807\u6ce8\u65b9\u6cd5\uff0c\u6539\u5584\u957fCoT\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u8bc6\u522b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u6807\u6ce8\u65b9\u6cd5\u5728\u5904\u7406\u957fCoT\u63a8\u7406\u65f6\u4ec5\u5173\u6ce8\u521d\u59cb\u9519\u8bef\u53ca\u5176\u540e\u6b65\u9aa4\uff0c\u5ffd\u89c6\u4e86\u81ea\u6211\u4fee\u6b63\u673a\u5236\u3002", "method": "\u5f15\u5165\u9519\u8bef\u4f20\u64ad\u548c\u505c\u6b62\u6982\u5ff5\uff0c\u5229\u7528LLM\u5224\u5b98\u8fdb\u884c\u6807\u6ce8\u6536\u96c6170\u4e07\u6837\u672c\u8bad\u7ec37B\u89c4\u6a21PRM\u3002", "result": "\u63d0\u51fa\u7684PRM\u5728\u641c\u7d22\u5f15\u5bfc\u3001BoN\u548cF1\u7b49\u591a\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u6570\u636e\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\uff0c\u8fd8\u589e\u5f3a\u4e86PRM\u8bc6\u522b\u6709\u6548\u81ea\u6211\u4fee\u6b63\u884c\u4e3a\u7684\u80fd\u529b\u3002"}}
{"id": "2505.13857", "pdf": "https://arxiv.org/pdf/2505.13857", "abs": "https://arxiv.org/abs/2505.13857", "authors": ["Tian Sun", "Yuqi Chen", "Baihua Zheng", "Weiwei Sun"], "title": "Learning Spatio-Temporal Dynamics for Trajectory Recovery via Time-Aware Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as a journal paper in IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)", "summary": "In real-world applications, GPS trajectories often suffer from low sampling\nrates, with large and irregular intervals between consecutive GPS points. This\nsparse characteristic presents challenges for their direct use in GPS-based\nsystems. This paper addresses the task of map-constrained trajectory recovery,\naiming to enhance trajectory sampling rates of GPS trajectories. Previous\nstudies commonly adopt a sequence-to-sequence framework, where an encoder\ncaptures the trajectory patterns and a decoder reconstructs the target\ntrajectory. Within this framework, effectively representing the road network\nand extracting relevant trajectory features are crucial for overall\nperformance. Despite advancements in these models, they fail to fully leverage\nthe complex spatio-temporal dynamics present in both the trajectory and the\nroad network.\n  To overcome these limitations, we categorize the spatio-temporal dynamics of\ntrajectory data into two distinct aspects: spatial-temporal traffic dynamics\nand trajectory dynamics. Furthermore, We propose TedTrajRec, a novel method for\ntrajectory recovery. To capture spatio-temporal traffic dynamics, we introduce\nPD-GNN, which models periodic patterns and learns topologically aware dynamics\nconcurrently for each road segment. For spatio-temporal trajectory dynamics, we\npresent TedFormer, a time-aware Transformer that incorporates temporal dynamics\nfor each GPS location by integrating closed-form neural ordinary differential\nequations into the attention mechanism. This allows TedFormer to effectively\nhandle irregularly sampled data. Extensive experiments on three real-world\ndatasets demonstrate the superior performance of TedTrajRec. The code is\npublicly available at https://github.com/ysygMhdxw/TEDTrajRec/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5TedTrajRec\u6765\u63d0\u9ad8GPS\u8f68\u8ff9\u7684\u91c7\u6837\u7387\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165PD-GNN\u548cTedFormer\u5206\u522b\u6355\u83b7\u65f6\u7a7a\u4ea4\u901a\u52a8\u529b\u5b66\u548c\u8f68\u8ff9\u52a8\u529b\u5b66\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6846\u67b6\u672a\u80fd\u5145\u5206\u5229\u7528\u8f68\u8ff9\u548c\u9053\u8def\u7f51\u7edc\u4e2d\u5b58\u5728\u7684\u590d\u6742\u65f6\u7a7a\u52a8\u529b\u5b66\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5TedTrajRec\uff0c\u5305\u62ecPD-GNN\u548cTedFormer\uff0c\u5206\u522b\u7528\u4e8e\u6355\u83b7\u4e0d\u540c\u7684\u65f6\u7a7a\u52a8\u529b\u5b66\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TedTrajRec\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "TedTrajRec\u5728\u63d0\u9ad8GPS\u8f68\u8ff9\u91c7\u6837\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u4ee3\u7801\u516c\u5f00\u53ef\u83b7\u53d6\u3002"}}
{"id": "2505.14394", "pdf": "https://arxiv.org/pdf/2505.14394", "abs": "https://arxiv.org/abs/2505.14394", "authors": ["Mihir Athale", "Vishal Vaddina"], "title": "Knowledge Graph Based Repository-Level Code Generation", "categories": ["cs.AI"], "comment": "8 pages, 3 figures", "summary": "Recent advancements in Large Language Models (LLMs) have transformed code\ngeneration from natural language queries. However, despite their extensive\nknowledge and ability to produce high-quality code, LLMs often struggle with\ncontextual accuracy, particularly in evolving codebases. Current code search\nand retrieval methods frequently lack robustness in both the quality and\ncontextual relevance of retrieved results, leading to suboptimal code\ngeneration. This paper introduces a novel knowledge graph-based approach to\nimprove code search and retrieval leading to better quality of code generation\nin the context of repository-level tasks. The proposed approach represents code\nrepositories as graphs, capturing structural and relational information for\nenhanced context-aware code generation. Our framework employs a hybrid approach\nfor code retrieval to improve contextual relevance, track inter-file modular\ndependencies, generate more robust code and ensure consistency with the\nexisting codebase. We benchmark the proposed approach on the Evolutionary Code\nBenchmark (EvoCodeBench) dataset, a repository-level code generation benchmark,\nand demonstrate that our method significantly outperforms the baseline\napproach. These findings suggest that knowledge graph based code generation\ncould advance robust, context-sensitive coding assistance tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u6765\u6539\u5584\u4ee3\u7801\u641c\u7d22\u548c\u68c0\u7d22\uff0c\u4ece\u800c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u5728EvoCodeBench\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u641c\u7d22\u4e0e\u68c0\u7d22\u65b9\u6cd5\u5728\u8d28\u91cf\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u4ee3\u7801\u751f\u6210\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5c06\u4ee3\u7801\u5b58\u50a8\u5e93\u8868\u793a\u4e3a\u56fe\u5f62\uff0c\u5e76\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8fdb\u884c\u4ee3\u7801\u68c0\u7d22\uff0c\u589e\u5f3a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728EvoCodeBench\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u4ee3\u7801\u751f\u6210\u53ef\u80fd\u63a8\u52a8\u5065\u58ee\u4e14\u654f\u611f\u4e8e\u4e0a\u4e0b\u6587\u7684\u7f16\u7801\u8f85\u52a9\u5de5\u5177\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.13858", "pdf": "https://arxiv.org/pdf/2505.13858", "abs": "https://arxiv.org/abs/2505.13858", "authors": ["Gonzalo E. Constante-Flores", "Hao Chen", "Can Li"], "title": "Enforcing Hard Linear Constraints in Deep Learning Models with Decision Rules", "categories": ["cs.LG"], "comment": "1 figure", "summary": "Deep learning models are increasingly deployed in safety-critical tasks where\npredictions must satisfy hard constraints, such as physical laws, fairness\nrequirements, or safety limits. However, standard architectures lack built-in\nmechanisms to enforce such constraints, and existing approaches based on\nregularization or projection are often limited to simple constraints,\ncomputationally expensive, or lack feasibility guarantees. This paper proposes\na model-agnostic framework for enforcing input-dependent linear equality and\ninequality constraints on neural network outputs. The architecture combines a\ntask network trained for prediction accuracy with a safe network trained using\ndecision rules from the stochastic and robust optimization literature to ensure\nfeasibility across the entire input space. The final prediction is a convex\ncombination of the two subnetworks, guaranteeing constraint satisfaction during\nboth training and inference without iterative procedures or runtime\noptimization. We prove that the architecture is a universal approximator of\nconstrained functions and derive computationally tractable formulations based\non linear decision rules. Empirical results on benchmark regression tasks show\nthat our method consistently satisfies constraints while maintaining\ncompetitive accuracy and low inference latency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u4e0d\u53ef\u77e5\u6846\u67b6\u6765\u5f3a\u5236\u6267\u884c\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u8f93\u5165\u76f8\u5173\u7ebf\u6027\u7b49\u5f0f\u548c\u4e0d\u7b49\u5f0f\u7ea6\u675f\u3002\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u9884\u6d4b\u6ee1\u8db3\u786c\u7ea6\u675f\u6761\u4ef6\uff0c\u5e76\u4e14\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u8fed\u4ee3\u8fc7\u7a0b\u6216\u8fd0\u884c\u65f6\u4f18\u5316\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\uff0c\u9700\u8981\u6ee1\u8db3\u786c\u7ea6\u675f\u6761\u4ef6\uff0c\u5982\u7269\u7406\u5b9a\u5f8b\u3001\u516c\u5e73\u6027\u8981\u6c42\u6216\u5b89\u5168\u9650\u5236\u3002\u7136\u800c\uff0c\u6807\u51c6\u67b6\u6784\u7f3a\u4e4f\u5185\u7f6e\u673a\u5236\u6765\u5f3a\u5236\u6267\u884c\u8fd9\u4e9b\u7ea6\u675f\u3002", "method": "\u7ed3\u5408\u4e86\u4e00\u4e2a\u4ee5\u9884\u6d4b\u51c6\u786e\u5ea6\u4e3a\u76ee\u6807\u7684\u4efb\u52a1\u7f51\u7edc\u548c\u4e00\u4e2a\u4f7f\u7528\u968f\u673a\u548c\u9c81\u68d2\u4f18\u5316\u6587\u732e\u4e2d\u7684\u51b3\u7b56\u89c4\u5219\u6765\u786e\u4fdd\u53ef\u884c\u6027\u7684\u5b89\u5168\u7f51\u7edc\u3002\u6700\u7ec8\u9884\u6d4b\u662f\u4e24\u4e2a\u5b50\u7f51\u7edc\u7684\u51f8\u7ec4\u5408\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u67b6\u6784\u662f\u4e00\u81f4\u51fd\u6570\u7684\u901a\u7528\u903c\u8fd1\u5668\uff0c\u5e76\u57fa\u4e8e\u7ebf\u6027\u51b3\u7b56\u89c4\u5219\u63a8\u5bfc\u51fa\u53ef\u8ba1\u7b97\u7684\u516c\u5f0f\u3002\u5728\u57fa\u51c6\u56de\u5f52\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4e00\u81f4\u5730\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u548c\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u662f\u4e00\u79cd\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u5f3a\u5236\u6267\u884c\u590d\u6742\u7684\u786c\u7ea6\u675f\u6761\u4ef6\uff0c\u800c\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2505.14396", "pdf": "https://arxiv.org/pdf/2505.14396", "abs": "https://arxiv.org/abs/2505.14396", "authors": ["Ga\u00ebl Gendron", "Jo\u017ee M. Ro\u017eanec", "Michael Witbrock", "Gillian Dobbie"], "title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.3; I.2.6; I.2.7; G.2.2; G.3; J.1"], "comment": "29 pages, 9 pages for the main paper, 20 pages for the references and\n  appendix, 25 figures", "summary": "Causal world models are systems that can answer counterfactual questions\nabout an environment of interest, i.e. predict how it would have evolved if an\narbitrary subset of events had been realized differently. It requires\nunderstanding the underlying causes behind chains of events and conducting\ncausal inference for arbitrary unseen distributions. So far, this task eludes\nfoundation models, notably large language models (LLMs), which do not have\ndemonstrated causal reasoning capabilities beyond the memorization of existing\ncausal relationships. Furthermore, evaluating counterfactuals in real-world\napplications is challenging since only the factual world is observed, limiting\nevaluation to synthetic datasets. We address these problems by explicitly\nextracting and modeling causal relationships and propose the Causal\nCartographer framework. First, we introduce a graph retrieval-augmented\ngeneration agent tasked to retrieve causal relationships from data. This\napproach allows us to construct a large network of real-world causal\nrelationships that can serve as a repository of causal knowledge and build\nreal-world counterfactuals. In addition, we create a counterfactual reasoning\nagent constrained by causal relationships to perform reliable step-by-step\ncausal inference. We show that our approach can extract causal knowledge and\nimprove the robustness of LLMs for causal reasoning tasks while reducing\ninference costs and spurious correlations.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u5236\u56fe\u6846\u67b6(Causal Cartographer)\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u5efa\u6a21\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u7f3a\u4e4f\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u8bc4\u4f30\u53cd\u4e8b\u5b9e\u95ee\u9898\u53d7\u9650\u4e8e\u4ec5\u80fd\u89c2\u5bdf\u5230\u4e8b\u5b9e\u4e16\u754c\uff0c\u96be\u4ee5\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u56fe\u68c0\u7d22\u589e\u5f3a\u7684\u751f\u6210\u4ee3\u7406\u63d0\u53d6\u56e0\u679c\u5173\u7cfb\u6784\u5efa\u56e0\u679c\u77e5\u8bc6\u7f51\u7edc\uff0c\u5e76\u8bbe\u8ba1\u53d7\u56e0\u679c\u5173\u7cfb\u7ea6\u675f\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u4ee3\u7406\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u63d0\u53d6\u56e0\u679c\u77e5\u8bc6\uff0c\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u63a8\u7406\u6210\u672c\u548c\u865a\u5047\u76f8\u5173\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u56e0\u679c\u5236\u56fe\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.13873", "pdf": "https://arxiv.org/pdf/2505.13873", "abs": "https://arxiv.org/abs/2505.13873", "authors": ["Peisong Niu", "Ziqing Ma", "Tian Zhou", "Weiqi Chen", "Lefei Shen", "Rong Jin", "Liang Sun"], "title": "Utilizing Strategic Pre-training to Reduce Overfitting: Baguan -- A Pre-trained Weather Forecasting Model", "categories": ["cs.LG", "cs.AI"], "comment": "KDD2025 research track accepted", "summary": "Weather forecasting has long posed a significant challenge for humanity.\nWhile recent AI-based models have surpassed traditional numerical weather\nprediction (NWP) methods in global forecasting tasks, overfitting remains a\ncritical issue due to the limited availability of real-world weather data\nspanning only a few decades. Unlike fields like computer vision or natural\nlanguage processing, where data abundance can mitigate overfitting, weather\nforecasting demands innovative strategies to address this challenge with\nexisting data. In this paper, we explore pre-training methods for weather\nforecasting, finding that selecting an appropriately challenging pre-training\ntask introduces locality bias, effectively mitigating overfitting and enhancing\nperformance. We introduce Baguan, a novel data-driven model for medium-range\nweather forecasting, built on a Siamese Autoencoder pre-trained in a\nself-supervised manner and fine-tuned for different lead times. Experimental\nresults show that Baguan outperforms traditional methods, delivering more\naccurate forecasts. Additionally, the pre-trained Baguan demonstrates robust\noverfitting control and excels in downstream tasks, such as\nsubseasonal-to-seasonal (S2S) modeling and regional forecasting, after\nfine-tuning.", "AI": {"tldr": "This paper addresses overfitting in AI-based weather forecasting by introducing a novel model called Baguan, which uses a pre-trained Siamese Autoencoder to improve accuracy and performance across various forecasting tasks.", "motivation": "To overcome the challenge of overfitting due to limited real-world weather data in AI-based weather forecasting.", "method": "Developing a new model called Baguan using a Siamese Autoencoder pre-trained in a self-supervised manner and fine-tuned for different lead times.", "result": "Baguan outperforms traditional methods in delivering accurate forecasts and demonstrates robust overfitting control in downstream tasks.", "conclusion": "Pre-training methods can effectively mitigate overfitting and enhance performance in weather forecasting."}}
{"id": "2505.14403", "pdf": "https://arxiv.org/pdf/2505.14403", "abs": "https://arxiv.org/abs/2505.14403", "authors": ["Zhaohui Yang", "Shilei Jiang", "Chen Hu", "Linjing Li", "Shihong Deng", "Daxin Jiang"], "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations.", "AI": {"tldr": "This paper proposes a method called BCPG-NSA that improves the performance of reasoning language models by utilizing negative samples.", "motivation": "Existing methods fail to leverage valuable components in negative responses, such as self-reflection and error-correction steps, due to high computational costs.", "method": "BCPG-NSA is a fine-grained offline RL framework with three stages: sample segmentation, consensus-based step correctness assessment, and policy optimization with negative sample augmentation.", "result": "BCPG-NSA outperforms baselines on challenging math/coding reasoning benchmarks using the same training dataset, showing improved sample efficiency and robustness.", "conclusion": "The proposed method demonstrates the importance of leveraging negative samples for better performance in reasoning language models."}}
{"id": "2505.13878", "pdf": "https://arxiv.org/pdf/2505.13878", "abs": "https://arxiv.org/abs/2505.13878", "authors": ["Yanggan Gu", "Zhaoyi Yan", "Yuanyi Wang", "Yiming Zhang", "Qi Zhou", "Fei Wu", "Hongxia Yang"], "title": "InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "17 pages", "summary": "Model fusion combines multiple Large Language Models (LLMs) with different\nstrengths into a more powerful, integrated model through lightweight training\nmethods. Existing works on model fusion focus primarily on supervised\nfine-tuning (SFT), leaving preference alignment (PA) --a critical phase for\nenhancing LLM performance--largely unexplored. The current few fusion methods\non PA phase, like WRPO, simplify the process by utilizing only response outputs\nfrom source models while discarding their probability information. To address\nthis limitation, we propose InfiFPO, a preference optimization method for\nimplicit model fusion. InfiFPO replaces the reference model in Direct\nPreference Optimization (DPO) with a fused source model that synthesizes\nmulti-source probabilities at the sequence level, circumventing complex\nvocabulary alignment challenges in previous works and meanwhile maintaining the\nprobability information. By introducing probability clipping and max-margin\nfusion strategies, InfiFPO enables the pivot model to align with human\npreferences while effectively distilling knowledge from source models.\nComprehensive experiments on 11 widely-used benchmarks demonstrate that InfiFPO\nconsistently outperforms existing model fusion and preference optimization\nmethods. When using Phi-4 as the pivot model, InfiFPO improve its average\nperformance from 79.95 to 83.33 on 11 benchmarks, significantly improving its\ncapabilities in mathematics, coding, and reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5InfiFPO\uff0c\u7528\u4e8e\u9690\u5f0f\u6a21\u578b\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u6709\u76d1\u7763\u5fae\u8c03\u4e0a\uff0c\u5bf9\u63d0\u5347LLM\u6027\u80fd\u81f3\u5173\u91cd\u8981\u7684\u504f\u597d\u5bf9\u9f50\u9636\u6bb5\u7814\u7a76\u8f83\u5c11\u3002", "method": "InfiFPO\u7528\u878d\u5408\u540e\u7684\u6e90\u6a21\u578b\u66ff\u6362\u76f4\u63a5\u504f\u597d\u4f18\u5316\u4e2d\u7684\u53c2\u8003\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u6982\u7387\u526a\u5207\u548c\u6700\u5927\u8fb9\u8ddd\u878d\u5408\u7b56\u7565\u3002", "result": "InfiFPO\u572811\u4e2a\u5e38\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u6a21\u578b\u878d\u5408\u548c\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "InfiFPO\u901a\u8fc7\u6709\u6548\u6574\u5408\u591a\u4e2a\u6e90\u6a21\u578b\u7684\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86Phi-4\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5e73\u5747\u6027\u80fd\u3002"}}
{"id": "2505.14412", "pdf": "https://arxiv.org/pdf/2505.14412", "abs": "https://arxiv.org/abs/2505.14412", "authors": ["Pawe\u0142 Batorski", "Adrian Kosmala", "Paul Swoboda"], "title": "PRL: Prompts from Reinforcement Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Effective prompt engineering remains a central challenge in fully harnessing\nthe capabilities of LLMs. While well-designed prompts can dramatically enhance\nperformance, crafting them typically demands expert intuition and a nuanced\nunderstanding of the task. Moreover, the most impactful prompts often hinge on\nsubtle semantic cues, ones that may elude human perception but are crucial for\nguiding LLM behavior. In this paper, we introduce PRL (Prompts from\nReinforcement Learning), a novel RL-based approach for automatic prompt\ngeneration. Unlike previous methods, PRL can produce novel few-shot examples\nthat were not seen during training. Our approach achieves state-of-the-art\nperformance across a range of benchmarks, including text classification,\nsimplification, and summarization. On the classification task, it surpasses\nprior methods by 2.58% over APE and 1.00% over EvoPrompt. Additionally, it\nimproves the average ROUGE scores on the summarization task by 4.32 over APE\nand by 2.12 over EvoPrompt and the SARI score on simplification by 6.93 over\nAPE and by 6.01 over EvoPrompt. Our code is available at\nhttps://github.com/Batorskq/prl .", "AI": {"tldr": "PRL\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u63d0\u793a\u751f\u6210\uff0c\u65e0\u9700\u5728\u8bad\u7ec3\u671f\u95f4\u770b\u5230\u7684\u63d0\u793a\u793a\u4f8b\uff0c\u5e76\u5728\u6587\u672c\u5206\u7c7b\u3001\u7b80\u5316\u548c\u603b\u7ed3\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u6709\u6548\u63d0\u793a\u5de5\u7a0b\u4ecd\u7136\u662f\u5145\u5206\u5229\u7528LLMs\u80fd\u529b\u7684\u6838\u5fc3\u6311\u6218\u3002\u867d\u7136\u8bbe\u8ba1\u826f\u597d\u7684\u63d0\u793a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u521b\u5efa\u5b83\u4eec\u901a\u5e38\u9700\u8981\u4e13\u5bb6\u76f4\u89c9\u548c\u5bf9\u4efb\u52a1\u7684\u7ec6\u81f4\u7406\u89e3\u3002\u6b64\u5916\uff0c\u6700\u6709\u5f71\u54cd\u7684\u63d0\u793a\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5fae\u5999\u7684\u8bed\u4e49\u7ebf\u7d22\uff0c\u8fd9\u4e9b\u7ebf\u7d22\u53ef\u80fd\u9003\u907f\u4eba\u7c7b\u7684\u611f\u77e5\uff0c\u4f46\u5bf9\u6307\u5bfcLLM\u884c\u4e3a\u81f3\u5173\u91cd\u8981\u3002", "method": "PRL\uff08\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63d0\u793a\uff09\uff0c\u4e00\u79cd\u65b0\u7684RL\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u63d0\u793a\u751f\u6210\u3002", "result": "PRL\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5305\u62ec\u6587\u672c\u5206\u7c7b\u3001\u7b80\u5316\u548c\u603b\u7ed3\u3002\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5b83\u6bd4APE\u9ad8\u51fa2.58\uff05\uff0c\u6bd4EvoPrompt\u9ad8\u51fa1.00\uff05\u3002\u6b64\u5916\uff0c\u5728\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u5b83\u63d0\u9ad8\u4e86\u5e73\u5747ROUGE\u5206\u6570\uff0c\u6bd4APE\u9ad84.32\uff0c\u6bd4EvoPrompt\u9ad82.12\uff0c\u5728\u7b80\u5316\u4efb\u52a1\u4e2d\u7684SARI\u5f97\u5206\u6bd4APE\u9ad86.93\uff0c\u6bd4EvoPrompt\u9ad86.01\u3002", "conclusion": "PRL\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728https://github.com/Batorskq/prl\u83b7\u5f97\u3002"}}
{"id": "2505.13896", "pdf": "https://arxiv.org/pdf/2505.13896", "abs": "https://arxiv.org/abs/2505.13896", "authors": ["Yingwei Zhang", "Ke Bu", "Zhuoran Zhuang", "Tao Xie", "Yao Yu", "Dong Li", "Yang Guo", "Detao Lv"], "title": "CRAFT: Time Series Forecasting with Cross-Future Behavior Awareness", "categories": ["cs.LG"], "comment": null, "summary": "The past decades witness the significant advancements in time series\nforecasting (TSF) across various real-world domains, including e-commerce and\ndisease spread prediction. However, TSF is usually constrained by the\nuncertainty dilemma of predicting future data with limited past observations.\nTo settle this question, we explore the use of Cross-Future Behavior (CFB) in\nTSF, which occurs before the current time but takes effect in the future. We\nleverage CFB features and propose the CRoss-Future Behavior Awareness based\nTime Series Forecasting method (CRAFT). The core idea of CRAFT is to utilize\nthe trend of cross-future behavior to mine the trend of time series data to be\npredicted. Specifically, to settle the sparse and partial flaws of cross-future\nbehavior, CRAFT employs the Koopman Predictor Module to extract the key trend\nand the Internal Trend Mining Module to supplement the unknown area of the\ncross-future behavior matrix. Then, we introduce the External Trend Guide\nModule with a hierarchical structure to acquire more representative trends from\nhigher levels. Finally, we apply the demand-constrained loss to calibrate the\ndistribution deviation of prediction results. We conduct experiments on\nreal-world dataset. Experiments on both offline large-scale dataset and online\nA/B test demonstrate the effectiveness of CRAFT. Our dataset and code is\navailable at https://github.com/CRAFTinTSF/CRAFT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5CRAFT\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u4ea4\u53c9\u672a\u6765\u884c\u4e3a\u7684\u8d8b\u52bf\u6765\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u901a\u5e38\u53d7\u5230\u6709\u9650\u8fc7\u53bb\u89c2\u6d4b\u503c\u7684\u672a\u6765\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u56f0\u5883\u7684\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u4f7f\u7528\u4ea4\u53c9\u672a\u6765\u884c\u4e3a(CFB)\u3002", "method": "CRAFT\u65b9\u6cd5\u5229\u7528\u4ea4\u53c9\u672a\u6765\u884c\u4e3a\u7684\u8d8b\u52bf\u6765\u6316\u6398\u8981\u9884\u6d4b\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u8d8b\u52bf\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u901a\u8fc7Koopman\u9884\u6d4b\u6a21\u5757\u63d0\u53d6\u5173\u952e\u8d8b\u52bf\uff0c\u5e76\u901a\u8fc7\u5185\u90e8\u8d8b\u52bf\u6316\u6398\u6a21\u5757\u8865\u5145\u4ea4\u53c9\u672a\u6765\u884c\u4e3a\u77e9\u9635\u7684\u672a\u77e5\u533a\u57df\u3002\u7136\u540e\uff0c\u5f15\u5165\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u5916\u90e8\u8d8b\u52bf\u5f15\u5bfc\u6a21\u5757\u4ee5\u4ece\u66f4\u9ad8\u5c42\u6b21\u83b7\u53d6\u66f4\u5177\u4ee3\u8868\u6027\u7684\u8d8b\u52bf\u3002\u6700\u540e\uff0c\u5e94\u7528\u9700\u6c42\u7ea6\u675f\u635f\u5931\u6821\u6b63\u9884\u6d4b\u7ed3\u679c\u7684\u5206\u5e03\u504f\u5dee\u3002", "result": "CRAFT\u5728\u79bb\u7ebf\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCRAFT\u5728\u79bb\u7ebf\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u90fd\u8868\u73b0\u51fa\u4e86\u6709\u6548\u6027\u3002\u6211\u4eec\u7684\u6570\u636e\u96c6\u548c\u4ee3\u7801\u53ef\u5728https://github.com/CRAFTinTSF/CRAFT\u83b7\u53d6\u3002"}}
{"id": "2505.14419", "pdf": "https://arxiv.org/pdf/2505.14419", "abs": "https://arxiv.org/abs/2505.14419", "authors": ["Huimin Xu", "Xin Mao", "Feng-Lin Li", "Xiaobao Wu", "Wang Chen", "Wei Zhang", "Anh Tuan Luu"], "title": "SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation", "categories": ["cs.AI"], "comment": null, "summary": "Process Reward Models (PRMs) have demonstrated promising results in\nmathematical reasoning, but existing process annotation approaches, whether\nthrough human annotations or Monte Carlo simulations, remain computationally\nexpensive. In this paper, we introduce Step COmpression for Process Estimation\n(SCOPE), a novel compression-based approach that significantly reduces\nannotation costs. We first translate natural language reasoning steps into code\nand normalize them through Abstract Syntax Tree, then merge equivalent steps to\nconstruct a prefix tree. Unlike simulation-based methods that waste numerous\nsamples on estimation, SCOPE leverages a compression-based prefix tree where\neach root-to-leaf path serves as a training sample, reducing the complexity\nfrom $O(NMK)$ to $O(N)$. We construct a large-scale dataset containing 196K\nsamples with only 5% of the computational resources required by previous\nmethods. Empirical results demonstrate that PRMs trained on our dataset\nconsistently outperform existing automated annotation approaches on both\nBest-of-N strategy and ProcessBench.", "AI": {"tldr": "Introduces SCOPE, a novel compression-based approach that reduces annotation costs for Process Reward Models in mathematical reasoning by translating reasoning steps into code and normalizing them through Abstract Syntax Tree, merging equivalent steps, and constructing a prefix tree.", "motivation": "Existing process annotation approaches for Process Reward Models are computationally expensive, either through human annotations or Monte Carlo simulations.", "method": "SCOPE translates natural language reasoning steps into code, normalizes them through Abstract Syntax Tree, merges equivalent steps, and constructs a prefix tree, reducing annotation complexity from O(NMK) to O(N).", "result": "SCOPE constructs a large-scale dataset containing 196K samples with only 5% of the computational resources required by previous methods, and PRMs trained on this dataset outperform existing automated annotation approaches on both Best-of-N strategy and ProcessBench.", "conclusion": "SCOPE is a novel and efficient approach to reduce annotation costs for Process Reward Models in mathematical reasoning."}}
{"id": "2505.13898", "pdf": "https://arxiv.org/pdf/2505.13898", "abs": "https://arxiv.org/abs/2505.13898", "authors": ["R\u00f3bert Csord\u00e1s", "Christopher D. Manning", "Christopher Potts"], "title": "Do Language Models Use Their Depth Efficiently?", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Modern LLMs are increasingly deep, and depth correlates with performance,\nalbeit with diminishing returns. However, do these models use their depth\nefficiently? Do they compose more features to create higher-order computations\nthat are impossible in shallow models, or do they merely spread the same kinds\nof computation out over more layers? To address these questions, we analyze the\nresidual stream of the Llama 3.1 and Qwen 3 family of models. We find: First,\ncomparing the output of the sublayers to the residual stream reveals that\nlayers in the second half contribute much less than those in the first half,\nwith a clear phase transition between the two halves. Second, skipping layers\nin the second half has a much smaller effect on future computations and output\npredictions. Third, for multihop tasks, we are unable to find evidence that\nmodels are using increased depth to compose subresults in examples involving\nmany hops. Fourth, we seek to directly address whether deeper models are using\ntheir additional layers to perform new kinds of computation. To do this, we\ntrain linear maps from the residual stream of a shallow model to a deeper one.\nWe find that layers with the same relative depth map best to each other,\nsuggesting that the larger model simply spreads the same computations out over\nits many layers. All this evidence suggests that deeper models are not using\ntheir depth to learn new kinds of computation, but only using the greater depth\nto perform more fine-grained adjustments to the residual. This may help explain\nwhy increasing scale leads to diminishing returns for stacked Transformer\narchitectures.", "AI": {"tldr": "This paper analyzes the efficiency of depth in large language models (LLMs) by examining the residual streams of Llama 3.1 and Qwen 3 models.", "motivation": "To determine if deeper models efficiently utilize their depth to perform higher-order computations or just spread the same computations over more layers.", "method": "Analyzing the residual stream of the models, comparing sublayer outputs, skipping layers, and training linear maps between shallow and deep models.", "result": "Found that later layers contribute less, skipping layers in the second half has minimal impact, and there's no evidence of composing subresults for multihop tasks. Linear maps suggest deeper models spread the same computations over more layers.", "conclusion": "Deeper models do not use their depth to learn new computations but rather for finer adjustments to the residual stream."}}
{"id": "2505.14479", "pdf": "https://arxiv.org/pdf/2505.14479", "abs": "https://arxiv.org/abs/2505.14479", "authors": ["Oren Sultan", "Eitan Stern", "Dafna Shahaf"], "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach", "categories": ["cs.AI", "cs.CL"], "comment": "long paper", "summary": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u80fd\u529b\u548c\u7ed3\u6784\u7ec4\u4ef6\u4ee5\u6539\u5584\u5f62\u5f0f\u9886\u57df\u5982\u6570\u5b66\u8bc1\u660e\u751f\u6210\u4e2d\u7684\u903b\u8f91\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u4e25\u683c\u903b\u8f91\u63a8\u5bfc\u548c\u7b26\u53f7\u63a8\u7406\u7684\u5f62\u5f0f\u9886\u57df\uff08\u5982\u6570\u5b66\u8bc1\u660e\u751f\u6210\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u901a\u8fc7\u68c0\u7d22\u7c7b\u4f3c\u95ee\u9898\u53ca\u5176\u8bc1\u660e\u6765\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5f62\u5f0f\u9a8c\u8bc1\u5668\u8bc4\u4f30\u751f\u6210\u7684\u8bc1\u660e\u5e76\u63d0\u4f9b\u53cd\u9988\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86OpenAI\u7684o1\u6a21\u578b\u7684\u8bc1\u660e\u51c6\u786e\u6027\uff0858%-70%\u7684\u6539\u8fdb\uff09\u3002", "conclusion": "\u8f6c\u5411\u80fd\u591f\u751f\u6210\u53ef\u8bc1\u660e\u6b63\u786e\u7ed3\u8bba\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5927\u5927\u63d0\u5347\u5176\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u89e3\u9501\u9700\u8981\u53ef\u4fe1\u5ea6\u7684\u590d\u6742\u4efb\u52a1\u548c\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u3002"}}
{"id": "2505.13899", "pdf": "https://arxiv.org/pdf/2505.13899", "abs": "https://arxiv.org/abs/2505.13899", "authors": ["Zeyu Michael Li", "Hung Anh Vu", "Damilola Awofisayo", "Emily Wenger"], "title": "Exploring Causes of Representational Similarity in Machine Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Numerous works have noted significant similarities in how machine learning\nmodels represent the world, even across modalities. Although much effort has\nbeen devoted to uncovering properties and metrics on which these models align,\nsurprisingly little work has explored causes of this similarity. To advance\nthis line of inquiry, this work explores how two possible causal factors --\ndataset overlap and task overlap -- influence downstream model similarity. The\nexploration of dataset overlap is motivated by the reality that large-scale\ngenerative AI models are often trained on overlapping datasets of scraped\ninternet data, while the exploration of task overlap seeks to substantiate\nclaims from a recent work, the Platonic Representation Hypothesis, that task\nsimilarity may drive model similarity. We evaluate the effects of both factors\nthrough a broad set of experiments. We find that both positively correlate with\nhigher representational similarity and that combining them provides the\nstrongest effect. Our code and dataset are published.", "AI": {"tldr": "This study investigates the causes of similarity in machine learning model representations, focusing on dataset overlap and task overlap as potential causal factors.", "motivation": "To understand why machine learning models across different modalities represent the world similarly, despite differences in training data and tasks.", "method": "Experiments were conducted to evaluate the impact of dataset overlap and task overlap on model similarity.", "result": "Both dataset overlap and task overlap positively correlate with higher representational similarity, and their combination has the strongest effect.", "conclusion": "The findings suggest that dataset and task overlap are significant contributors to model representation similarity."}}
{"id": "2505.14489", "pdf": "https://arxiv.org/pdf/2505.14489", "abs": "https://arxiv.org/abs/2505.14489", "authors": ["Dongkeun Yoon", "Seungone Kim", "Sohee Yang", "Sunkyoung Kim", "Soyeon Kim", "Yongil Kim", "Eunbi Choi", "Yireun Kim", "Minjoon Seo"], "title": "Reasoning Models Better Express Their Confidence", "categories": ["cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Despite their strengths, large language models (LLMs) often fail to\ncommunicate their confidence accurately, making it difficult to assess when\nthey might be wrong and limiting their reliability. In this work, we\ndemonstrate that reasoning models-LLMs that engage in extended chain-of-thought\n(CoT) reasoning-exhibit superior performance not only in problem-solving but\nalso in accurately expressing their confidence. Specifically, we benchmark six\nreasoning models across six datasets and find that they achieve strictly better\nconfidence calibration than their non-reasoning counterparts in 33 out of the\n36 settings. Our detailed analysis reveals that these gains in calibration stem\nfrom the slow thinking behaviors of reasoning models-such as exploring\nalternative approaches and backtracking-which enable them to adjust their\nconfidence dynamically throughout their CoT, making it progressively more\naccurate. In particular, we find that reasoning models become increasingly\nbetter calibrated as their CoT unfolds, a trend not observed in non-reasoning\nmodels. Moreover, removing slow thinking behaviors from the CoT leads to a\nsignificant drop in calibration. Lastly, we show that these gains are not\nexclusive to reasoning models-non-reasoning models also benefit when guided to\nperform slow thinking via in-context learning.", "AI": {"tldr": "This study investigates the confidence calibration of reasoning models compared to non-reasoning LLMs, demonstrating that reasoning models exhibit superior confidence calibration due to their extended chain-of-thought reasoning.", "motivation": "Large language models often struggle with accurately communicating their confidence, which affects reliability. This study aims to explore whether reasoning models can improve this aspect.", "method": "Benchmarking six reasoning models across six datasets to evaluate their confidence calibration and analyzing the impact of slow thinking behaviors.", "result": "Reasoning models show better confidence calibration than non-reasoning models, especially as their chain-of-thought reasoning progresses. Removing slow thinking behaviors decreases calibration accuracy.", "conclusion": "Reasoning models have better confidence calibration due to slow thinking behaviors, and non-reasoning models can also benefit from such behaviors through in-context learning."}}
{"id": "2505.13900", "pdf": "https://arxiv.org/pdf/2505.13900", "abs": "https://arxiv.org/abs/2505.13900", "authors": ["Zhanpeng Zhou", "Yongyi Yang", "Mahito Sugiyama", "Junchi Yan"], "title": "New Evidence of the Two-Phase Learning Dynamics of Neural Networks", "categories": ["cs.LG"], "comment": "This work extends the workshop paper, On the Cone Effect in the\n  Learning Dynamics, accepted by ICLR 2025 Workshop DeLTa", "summary": "Understanding how deep neural networks learn remains a fundamental challenge\nin modern machine learning. A growing body of evidence suggests that training\ndynamics undergo a distinct phase transition, yet our understanding of this\ntransition is still incomplete. In this paper, we introduce an interval-wise\nperspective that compares network states across a time window, revealing two\nnew phenomena that illuminate the two-phase nature of deep learning. i)\n\\textbf{The Chaos Effect.} By injecting an imperceptibly small parameter\nperturbation at various stages, we show that the response of the network to the\nperturbation exhibits a transition from chaotic to stable, suggesting there is\nan early critical period where the network is highly sensitive to initial\nconditions; ii) \\textbf{The Cone Effect.} Tracking the evolution of the\nempirical Neural Tangent Kernel (eNTK), we find that after this transition\npoint the model's functional trajectory is confined to a narrow cone-shaped\nsubset: while the kernel continues to change, it gets trapped into a tight\nangular region. Together, these effects provide a structural, dynamical view of\nhow deep networks transition from sensitive exploration to stable refinement\nduring training.", "AI": {"tldr": "This paper explores the training dynamics of deep neural networks and identifies two new phenomena: The Chaos Effect and The Cone Effect, which reveal the two-phase nature of deep learning.", "motivation": "To understand how deep neural networks learn and to gain insights into the training dynamics during the distinct phase transition.", "method": "Introducing an interval-wise perspective to compare network states across a time window and analyzing the response of the network to small parameter perturbations as well as the evolution of the empirical Neural Tangent Kernel (eNTK).", "result": "Identified two new phenomena: The Chaos Effect, where the network response transitions from chaotic to stable, indicating a critical period of high sensitivity to initial conditions, and The Cone Effect, where the model's functional trajectory is confined to a narrow cone-shaped subset after the transition point.", "conclusion": "The findings provide a structural and dynamical view of how deep networks transition from sensitive exploration to stable refinement during training."}}
{"id": "2505.14510", "pdf": "https://arxiv.org/pdf/2505.14510", "abs": "https://arxiv.org/abs/2505.14510", "authors": ["Haishi Bai", "Jozo Dujmovic", "Jianwu Wang"], "title": "BACON: A fully explainable AI model with graded logic for decision making problems", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aBACON\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bad\u7ec3\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u51b3\u7b56\u95ee\u9898\u5e76\u63d0\u4f9b\u7cbe\u786e\u7684\u903b\u8f91\u89e3\u91ca\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u7597\u4fdd\u5065\u3001\u5b89\u5168\u3001\u91d1\u878d\u548c\u673a\u5668\u4eba\uff09\u4e2d\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u900f\u660e\u4e14\u53ef\u4fe1\u7684\u89e3\u91ca\u3002", "method": "\u4f7f\u7528\u5206\u7ea7\u903b\u8f91\u81ea\u52a8\u8bad\u7ec3\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u3002", "result": "BACON\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u6a21\u578b\uff0c\u5e76\u751f\u6210\u4e86\u53ef\u9a8c\u8bc1\u7684\u51b3\u7b56\u903b\u8f91\u3002", "conclusion": "BACON\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u539f\u5219\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u4f9b\u6e05\u6670\u3001\u53ef\u4fe1\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u3002"}}
{"id": "2505.13904", "pdf": "https://arxiv.org/pdf/2505.13904", "abs": "https://arxiv.org/abs/2505.13904", "authors": ["Fu Luo", "Xi Lin", "Mengyuan Zhong", "Fei Liu", "Zhenkun Wang", "Jianyong Sun", "Qingfu Zhang"], "title": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Neural Combinatorial Optimisation (NCO) is a promising learning-based\napproach for solving Vehicle Routing Problems (VRPs) without extensive manual\ndesign. While existing constructive NCO methods typically follow an\nappending-based paradigm that sequentially adds unvisited nodes to partial\nsolutions, this rigid approach often leads to suboptimal results. To overcome\nthis limitation, we explore the idea of insertion-based paradigm and propose\nLearning to Construct with Insertion-based Paradigm (L2C-Insert), a novel\nlearning-based method for constructive NCO. Unlike traditional approaches,\nL2C-Insert builds solutions by strategically inserting unvisited nodes at any\nvalid position in the current partial solution, which can significantly enhance\nthe flexibility and solution quality. The proposed framework introduces three\nkey components: a novel model architecture for precise insertion position\nprediction, an efficient training scheme for model optimization, and an\nadvanced inference technique that fully exploits the insertion paradigm's\nflexibility. Extensive experiments on both synthetic and real-world instances\nof the Travelling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) demonstrate that L2C-Insert consistently achieves superior\nperformance across various problem sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d2\u5165\u8303\u5f0f\u7684\u65b0\u578b\u5b66\u4e60\u65b9\u6cd5L2C-Insert\uff0c\u7528\u4e8e\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u6dfb\u52a0\u65b9\u5f0f\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u95ee\u9898\u89c4\u6a21\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6784\u9020\u6027\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u57fa\u4e8e\u8ffd\u52a0\u7684\u8303\u5f0f\uff0c\u8fd9\u79cd\u521a\u6027\u65b9\u6cd5\u5e38\u5bfc\u81f4\u6b21\u4f18\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u63d2\u5165\u8303\u5f0f\u7684\u6784\u9020\u6027\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5L2C-Insert\uff0c\u5305\u62ec\u9884\u6d4b\u7cbe\u786e\u63d2\u5165\u4f4d\u7f6e\u7684\u65b0\u6a21\u578b\u67b6\u6784\u3001\u6709\u6548\u7684\u6a21\u578b\u4f18\u5316\u8bad\u7ec3\u65b9\u6848\u548c\u5145\u5206\u5229\u7528\u63d2\u5165\u7075\u6d3b\u6027\u7684\u5148\u8fdb\u63a8\u7406\u6280\u672f\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u7684\u65c5\u884c\u5546\u95ee\u9898(TSP)\u548c\u5bb9\u91cf\u7ea6\u675f\u8f66\u8f86\u8def\u5f84\u95ee\u9898(CVRP)\u5b9e\u4f8b\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86L2C-Insert\u5728\u5404\u79cd\u95ee\u9898\u89c4\u6a21\u4e0a\u59cb\u7ec8\u5177\u6709\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684L2C-Insert\u65b9\u6cd5\u901a\u8fc7\u589e\u5f3a\u7075\u6d3b\u6027\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u95ee\u9898\u89c4\u6a21\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.14524", "pdf": "https://arxiv.org/pdf/2505.14524", "abs": "https://arxiv.org/abs/2505.14524", "authors": ["Richard \u0160l\u00e9her", "William Brach", "Tibor Sloboda", "Kristi\u00e1n Ko\u0161\u0165\u00e1l", "Lukas Galke"], "title": "Guarded Query Routing for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Query routing, the task to route user queries to different large language\nmodel (LLM) endpoints, can be considered as a text classification problem.\nHowever, out-of-distribution queries must be handled properly, as those could\nbe questions about unrelated domains, queries in other languages, or even\ncontain unsafe text. Here, we thus study a \\emph{guarded} query routing\nproblem, for which we first introduce the Guarded Query Routing Benchmark\n(GQR-Bench), which covers three exemplary target domains (law, finance, and\nhealthcare), and seven datasets to test robustness against out-of-distribution\nqueries. We then use GQR-Bench to contrast the effectiveness and efficiency of\nLLM-based routing mechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B),\nstandard LLM-based guardrail approaches (LlamaGuard and NVIDIA NeMo\nGuardrails), continuous bag-of-words classifiers (WideMLP, fastText), and\ntraditional machine learning models (SVM, XGBoost). Our results show that\nWideMLP, enhanced with out-of-domain detection capabilities, yields the best\ntrade-off between accuracy (88\\%) and speed (<4ms). The embedding-based\nfastText excels at speed (<1ms) with acceptable accuracy (80\\%), whereas LLMs\nyield the highest accuracy (91\\%) but are comparatively slow (62ms for local\nLlama-3.1:8B and 669ms for remote GPT-4o-mini calls). Our findings challenge\nthe automatic reliance on LLMs for (guarded) query routing and provide concrete\nrecommendations for practical applications. GQR-Bench will be released as a\nPython package -- \\texttt{gqr}.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53d7\u4fdd\u62a4\u7684\u67e5\u8be2\u8def\u7531\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86GQR-Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u5e94\u5bf9\u5206\u5e03\u5916\u67e5\u8be2\u65f6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002\u7ed3\u679c\u663e\u793aWideMLP\u5728\u51c6\u786e\u7387\u548c\u901f\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u800cLLMs\u867d\u7136\u51c6\u786e\u7387\u6700\u9ad8\u4f46\u901f\u5ea6\u8f83\u6162\u3002", "motivation": "\u67e5\u8be2\u8def\u7531\u4efb\u52a1\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6587\u672c\u5206\u7c7b\u95ee\u9898\uff0c\u4f46\u9700\u8981\u59a5\u5584\u5904\u7406\u5206\u5e03\u5916\u67e5\u8be2\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e00\u4e2a\u2018\u53d7\u4fdd\u62a4\u2019\u7684\u67e5\u8be2\u8def\u7531\u95ee\u9898\u3002", "method": "\u5bf9\u6bd4\u4e86\u57fa\u4e8eLLM\u7684\u8def\u7531\u673a\u5236\u3001\u6807\u51c6LLM\u57fa\u7ebf\u7684\u5b88\u536b\u65b9\u6cd5\u3001\u8fde\u7eed\u8bcd\u888b\u5206\u7c7b\u5668\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u67e5\u8be2\u8def\u7531\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u4e0e\u6548\u7387\u3002", "result": "WideMLP\u5728\u51c6\u786e\u7387(88%)\u548c\u901f\u5ea6(<4ms)\u4e4b\u95f4\u8fbe\u5230\u4e86\u6700\u4f73\u5e73\u8861\uff1b\u57fa\u4e8e\u5d4c\u5165\u7684fastText\u5728\u901f\u5ea6(<1ms)\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u6709\u53ef\u63a5\u53d7\u7684\u51c6\u786e\u7387(80%)\uff1bLLMs\u5177\u6709\u6700\u9ad8\u7684\u51c6\u786e\u7387(91%)\u4f46\u901f\u5ea6\u8f83\u6162(\u672c\u5730Llama-3.1:8B\u4e3a62ms\uff0c\u8fdc\u7a0bGPT-4o-mini\u8c03\u7528\u4e3a669ms)\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u6311\u6218\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\uff08\u53d7\u4fdd\u62a4\u7684\uff09\u67e5\u8be2\u8def\u7531\u4e2d\u7684\u81ea\u52a8\u4f9d\u8d56\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u5efa\u8bae\u3002GQR-Bench \u5c06\u4f5c\u4e3a Python \u5305 - `gqr` \u53d1\u5e03\u3002"}}
{"id": "2505.13907", "pdf": "https://arxiv.org/pdf/2505.13907", "abs": "https://arxiv.org/abs/2505.13907", "authors": ["Junyu Luo", "Yusheng Zhao", "Xiao Luo", "Zhiping Xiao", "Wei Ju", "Li Shen", "Dacheng Tao", "Ming Zhang"], "title": "Cross-Domain Diffusion with Progressive Alignment for Efficient Adaptive Retrieval", "categories": ["cs.LG"], "comment": "IEEE TIP", "summary": "Unsupervised efficient domain adaptive retrieval aims to transfer knowledge\nfrom a labeled source domain to an unlabeled target domain, while maintaining\nlow storage cost and high retrieval efficiency. However, existing methods\ntypically fail to address potential noise in the target domain, and directly\nalign high-level features across domains, thus resulting in suboptimal\nretrieval performance. To address these challenges, we propose a novel\nCross-Domain Diffusion with Progressive Alignment method (COUPLE). This\napproach revisits unsupervised efficient domain adaptive retrieval from a graph\ndiffusion perspective, simulating cross-domain adaptation dynamics to achieve a\nstable target domain adaptation process. First, we construct a cross-domain\nrelationship graph and leverage noise-robust graph flow diffusion to simulate\nthe transfer dynamics from the source domain to the target domain, identifying\nlower noise clusters. We then leverage the graph diffusion results for\ndiscriminative hash code learning, effectively learning from the target domain\nwhile reducing the negative impact of noise. Furthermore, we employ a\nhierarchical Mixup operation for progressive domain alignment, which is\nperformed along the cross-domain random walk paths. Utilizing target domain\ndiscriminative hash learning and progressive domain alignment, COUPLE enables\neffective domain adaptive hash learning. Extensive experiments demonstrate\nCOUPLE's effectiveness on competitive benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8de8\u57df\u6269\u6563\u4e0e\u9010\u6b65\u5bf9\u9f50\u65b9\u6cd5(COUPLE)\uff0c\u4ece\u56fe\u6269\u6563\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u65e0\u76d1\u7763\u9ad8\u6548\u9886\u57df\u81ea\u9002\u5e94\u68c0\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u8de8\u57df\u5173\u7cfb\u56fe\u5e76\u5229\u7528\u566a\u58f0\u9c81\u68d2\u56fe\u6d41\u6269\u6563\u6765\u6a21\u62df\u6e90\u57df\u5230\u76ee\u6807\u57df\u7684\u8f6c\u79fb\u52a8\u6001\uff0c\u8bc6\u522b\u4f4e\u566a\u58f0\u7c07\uff0c\u5e76\u91c7\u7528\u5206\u5c42Mixup\u64cd\u4f5c\u8fdb\u884c\u9010\u6b65\u9886\u57df\u5bf9\u9f50\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u9886\u57df\u81ea\u9002\u5e94\u54c8\u5e0c\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660eCOUPLE\u5728\u7ade\u4e89\u6027\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u65e0\u6cd5\u89e3\u51b3\u76ee\u6807\u57df\u4e2d\u7684\u6f5c\u5728\u566a\u58f0\u95ee\u9898\uff0c\u76f4\u63a5\u5bf9\u9f50\u9ad8\u7ea7\u7279\u5f81\u4f1a\u5bfc\u81f4\u68c0\u7d22\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86COUPLE\u65b9\u6cd5\uff0c\u5305\u62ec\u6784\u5efa\u8de8\u57df\u5173\u7cfb\u56fe\u3001\u566a\u58f0\u9c81\u68d2\u56fe\u6d41\u6269\u6563\u3001\u5224\u522b\u54c8\u5e0c\u7801\u5b66\u4e60\u4ee5\u53ca\u5206\u5c42Mixup\u64cd\u4f5c\u8fdb\u884c\u9010\u6b65\u9886\u57df\u5bf9\u9f50\u3002", "result": "COUPLE\u5728\u7ade\u4e89\u6027\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "COUPLE\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u76d1\u7763\u9ad8\u6548\u9886\u57df\u81ea\u9002\u5e94\u68c0\u7d22\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u76ee\u6807\u57df\u4e2d\u7684\u566a\u58f0\u95ee\u9898\u5e76\u63d0\u9ad8\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2505.14539", "pdf": "https://arxiv.org/pdf/2505.14539", "abs": "https://arxiv.org/abs/2505.14539", "authors": ["Gaia Belardinelli", "Thomas Bolander", "Sebastian Watzl"], "title": "A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version)", "categories": ["cs.AI"], "comment": null, "summary": "In this work, we present the first general logic of attention. Attention is a\npowerful cognitive ability that allows agents to focus on potentially complex\ninformation, such as logically structured propositions, higher-order beliefs,\nor what other agents pay attention to. This ability is a strength, as it helps\nto ignore what is irrelevant, but it can also introduce biases when some types\nof information or agents are systematically ignored. Existing dynamic epistemic\nlogics for attention cannot model such complex attention scenarios, as they\nonly model attention to atomic formulas. Additionally, such logics quickly\nbecome cumbersome, as their size grows exponentially in the number of agents\nand announced literals. Here, we introduce a logic that overcomes both\nlimitations. First, we generalize edge-conditioned event models, which we show\nto be as expressive as standard event models yet exponentially more succinct\n(generalizing both standard event models and generalized arrow updates).\nSecond, we extend attention to arbitrary formulas, allowing agents to also\nattend to other agents' beliefs or attention. Our work treats attention as a\nmodality, like belief or awareness. We introduce attention principles that\nimpose closure properties on that modality and that can be used in its\naxiomatization. Throughout, we illustrate our framework with examples of AI\nagents reasoning about human attentional biases, demonstrating how such agents\ncan discover attentional biases.", "AI": {"tldr": "This paper introduces the first general logic of attention, overcoming limitations of existing dynamic epistemic logics by generalizing edge-conditioned event models and extending attention to arbitrary formulas.", "motivation": "To address the limitations of existing logics in modeling complex attention scenarios and biases.", "method": "Generalizing edge-conditioned event models and extending attention to arbitrary formulas.", "result": "A new logic that is more expressive and succinct than previous ones, capable of modeling complex attention scenarios and biases.", "conclusion": "The proposed logic treats attention as a modality and introduces attention principles for its axiomatization, demonstrated through examples of AI agents reasoning about human attentional biases."}}
{"id": "2505.13910", "pdf": "https://arxiv.org/pdf/2505.13910", "abs": "https://arxiv.org/abs/2505.13910", "authors": ["Guangtao Zheng", "Wenqian Ye", "Aidong Zhang"], "title": "ShortcutProbe: Probing Prediction Shortcuts for Learning Robust Models", "categories": ["cs.LG"], "comment": "Accepted to IJCAI 2025", "summary": "Deep learning models often achieve high performance by inadvertently learning\nspurious correlations between targets and non-essential features. For example,\nan image classifier may identify an object via its background that spuriously\ncorrelates with it. This prediction behavior, known as spurious bias, severely\ndegrades model performance on data that lacks the learned spurious\ncorrelations. Existing methods on spurious bias mitigation typically require a\nvariety of data groups with spurious correlation annotations called group\nlabels. However, group labels require costly human annotations and often fail\nto capture subtle spurious biases such as relying on specific pixels for\npredictions. In this paper, we propose a novel post hoc spurious bias\nmitigation framework without requiring group labels. Our framework, termed\nShortcutProbe, identifies prediction shortcuts that reflect potential\nnon-robustness in predictions in a given model's latent space. The model is\nthen retrained to be invariant to the identified prediction shortcuts for\nimproved robustness. We theoretically analyze the effectiveness of the\nframework and empirically demonstrate that it is an efficient and practical\ntool for improving a model's robustness to spurious bias on diverse datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5206\u7ec4\u6807\u7b7e\u5373\u53ef\u51cf\u8f7b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u9884\u6d4b\u6377\u5f84\u7684\u540e\u9a8c\u65b9\u6cd5ShortcutProbe\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u91cd\u65b0\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u5bf9\u65e0\u5173\u7279\u5f81\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u53bb\u504f\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u7684\u5206\u7ec4\u6807\u7b7e\uff0c\u4e14\u96be\u4ee5\u6355\u6349\u5fae\u5999\u7684\u9884\u6d4b\u504f\u5dee\u3002", "method": "\u63d0\u51faShortcutProbe\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u8bc6\u522b\u9884\u6d4b\u6377\u5f84\u5e76\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u4f7f\u5176\u5bf9\u8fd9\u4e9b\u6377\u5f84\u4e0d\u53d8\u6765\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u6846\u67b6\u88ab\u8bc1\u660e\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u6709\u6548\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u65e0\u5173\u7279\u5f81\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "ShortcutProbe\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u51cf\u8f7b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u975e\u7a33\u5065\u9884\u6d4b\u504f\u5dee\u3002"}}
{"id": "2505.14544", "pdf": "https://arxiv.org/pdf/2505.14544", "abs": "https://arxiv.org/abs/2505.14544", "authors": ["Saahil Mahato"], "title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.", "AI": {"tldr": "This study uses multi-agent reinforcement learning to optimize traffic signal coordination in a simulated urban traffic environment, showing significant reductions in vehicle wait times and increased throughput compared to fixed-time control systems.", "motivation": "Addressing urban traffic congestion and improving traffic signal adaptability to manage dynamic traffic patterns.", "method": "Developing a simulated environment with Pygame, implementing a decentralized MARL controller where traffic signals act as autonomous agents, and evaluating performance against a fixed-time controller.", "result": "Statistically significant improvements in average vehicle wait time and overall throughput were observed with the MARL approach.", "conclusion": "The study suggests potential for MARL-based dynamic control strategies to enhance urban traffic management efficiency, with recommendations for further research into scalability and real-world implementation."}}
{"id": "2505.13934", "pdf": "https://arxiv.org/pdf/2505.13934", "abs": "https://arxiv.org/abs/2505.13934", "authors": ["Jialong Wu", "Shaofeng Yin", "Ningya Feng", "Mingsheng Long"], "title": "RLVR-World: Training World Models with Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Code is available at project website:\n  https://thuml.github.io/RLVR-World/", "summary": "World models predict state transitions in response to actions and are\nincreasingly developed across diverse modalities. However, standard training\nobjectives such as maximum likelihood estimation (MLE) often misalign with\ntask-specific goals of world models, i.e., transition prediction metrics like\naccuracy or perceptual quality. In this paper, we present RLVR-World, a unified\nframework that leverages reinforcement learning with verifiable rewards (RLVR)\nto directly optimize world models for such metrics. Despite formulating world\nmodeling as autoregressive prediction of tokenized sequences, RLVR-World\nevaluates metrics of decoded predictions as verifiable rewards. We demonstrate\nsubstantial performance gains on both language- and video-based world models\nacross domains, including text games, web navigation, and robot manipulation.\nOur work indicates that, beyond recent advances in reasoning language models,\nRLVR offers a promising post-training paradigm for enhancing the utility of\ngenerative models more broadly.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRLVR-World\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u4f18\u5316\u4e16\u754c\u6a21\u578b\uff0c\u4ece\u800c\u5728\u8bed\u8a00\u548c\u89c6\u9891\u9886\u57df\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6807\u51c6\u8bad\u7ec3\u76ee\u6807\u5982\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u4e0e\u4e16\u754c\u6a21\u578b\u7684\u4efb\u52a1\u7279\u5b9a\u76ee\u6807\u4e0d\u4e00\u81f4\uff0c\u4f8b\u5982\u51c6\u786e\u5ea6\u6216\u611f\u77e5\u8d28\u91cf\u7b49\u8fc7\u6e21\u9884\u6d4b\u6307\u6807\u3002", "method": "\u63d0\u51fa\u4e86RLVR-World\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5e26\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u4f18\u5316\u4e16\u754c\u6a21\u578b\u4ee5\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u6307\u6807\u3002", "result": "\u5728\u591a\u79cd\u9886\u57df\u5305\u62ec\u6587\u672c\u6e38\u620f\u3001\u7f51\u9875\u5bfc\u822a\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\uff0c\u57fa\u4e8e\u8bed\u8a00\u548c\u89c6\u9891\u7684\u4e16\u754c\u6a21\u578b\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u9664\u4e86\u6700\u8fd1\u5728\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u7684\u8fdb\u5c55\u5916\uff0cRLVR\u4e3a\u589e\u5f3a\u751f\u6210\u6a21\u578b\u7684\u5b9e\u7528\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2505.14569", "pdf": "https://arxiv.org/pdf/2505.14569", "abs": "https://arxiv.org/abs/2505.14569", "authors": ["Devansh Bhardwaj", "Arjun Beniwal", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Karthik R. Narasimhan", "Ameet Deshpande", "Vishvak Murahari"], "title": "Agent Context Protocols Enhance Collective Inference", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "AI agents have become increasingly adept at complex tasks such as coding,\nreasoning, and multimodal understanding. However, building generalist systems\nrequires moving beyond individual agents to collective inference -- a paradigm\nwhere multi-agent systems with diverse, task-specialized agents complement one\nanother through structured communication and collaboration. Today, coordination\nis usually handled with imprecise, ad-hoc natural language, which limits\ncomplex interaction and hinders interoperability with domain-specific agents.\nWe introduce Agent context protocols (ACPs): a domain- and agent-agnostic\nfamily of structured protocols for agent-agent communication, coordination, and\nerror handling. ACPs combine (i) persistent execution blueprints -- explicit\ndependency graphs that store intermediate agent outputs -- with (ii)\nstandardized message schemas, enabling robust and fault-tolerant multi-agent\ncollective inference. ACP-powered generalist systems reach state-of-the-art\nperformance: 28.3 % accuracy on AssistantBench for long-horizon web assistance\nand best-in-class multimodal technical reports, outperforming commercial AI\nsystems in human evaluation. ACPs are highly modular and extensible, allowing\npractitioners to build top-tier generalist agents quickly.", "AI": {"tldr": "Introduces Agent context protocols (ACPs) for structured multi-agent communication and coordination, improving performance on complex tasks.", "motivation": "Current methods of coordination among AI agents using natural language limit complex interactions and interoperability with domain-specific agents.", "method": "Development of ACPs, which include persistent execution blueprints and standardized message schemas for robust multi-agent collective inference.", "result": "ACP-powered systems achieve state-of-the-art performance in long-horizon web assistance and multimodal technical reports, outperforming commercial AI systems in human evaluations.", "conclusion": "ACP is a versatile tool for rapidly building high-performing generalist AI agents."}}
{"id": "2505.13938", "pdf": "https://arxiv.org/pdf/2505.13938", "abs": "https://arxiv.org/abs/2505.13938", "authors": ["Amitayush Thakur", "Jasper Lee", "George Tsoukalas", "Meghana Sistla", "Matthew Zhao", "Stefan Zetzche", "Greg Durrett", "Yisong Yue", "Swarat Chaudhuri"], "title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "We introduce ${\\rm C{\\small LEVER}}$, a high-quality, curated benchmark of\n161 problems for end-to-end verified code generation in Lean. Each problem\nconsists of (1) the task of generating a specification that matches a held-out\nground-truth specification, and (2) the task of generating a Lean\nimplementation that provably satisfies this specification. Unlike prior\nbenchmarks, ${\\rm C{\\small LEVER}}$ avoids test-case supervision, LLM-generated\nannotations, and specifications that leak implementation logic or allow vacuous\nsolutions. All outputs are verified post-hoc using Lean's type checker to\nensure machine-checkable correctness. We use ${\\rm C{\\small LEVER}}$ to\nevaluate several few-shot and agentic approaches based on state-of-the-art\nlanguage models. These methods all struggle to achieve full verification,\nestablishing it as a challenging frontier benchmark for program synthesis and\nformal reasoning. Our benchmark can be found on\nGitHub(https://github.com/trishullab/clever) as well as\nHuggingFace(https://huggingface.co/datasets/amitayusht/clever). All our\nevaluation code is also available\nonline(https://github.com/trishullab/clever-prover).", "AI": {"tldr": "Introduces CLEVER, a new benchmark for end-to-end verified code generation in Lean, consisting of 161 problems without test-case supervision or LLM-generated annotations.", "motivation": "To create a high-quality benchmark for verified code generation that avoids issues like test-case supervision and LLM-generated annotations.", "method": "Developed CLEVER with two tasks: generating a matching specification and a provably satisfying implementation, verified using Lean's type checker.", "result": "Evaluated several few-shot and agentic approaches based on state-of-the-art language models, which struggled to achieve full verification.", "conclusion": "Establishes CLEVER as a challenging frontier benchmark for program synthesis and formal reasoning."}}
{"id": "2505.14603", "pdf": "https://arxiv.org/pdf/2505.14603", "abs": "https://arxiv.org/abs/2505.14603", "authors": ["Davide Buffelli", "Sowmen Das", "Yu-Wei Lin", "Sattar Vakili", "Chien-Yi Wang", "Masoud Attarifar", "Pritthijit Nath", "Da-shan Shiu"], "title": "Towards a Foundation Model for Communication Systems", "categories": ["cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "Artificial Intelligence (AI) has demonstrated unprecedented performance\nacross various domains, and its application to communication systems is an\nactive area of research. While current methods focus on task-specific\nsolutions, the broader trend in AI is shifting toward large general models\ncapable of supporting multiple applications. In this work, we take a step\ntoward a foundation model for communication data--a transformer-based,\nmulti-modal model designed to operate directly on communication data. We\npropose methodologies to address key challenges, including tokenization,\npositional embedding, multimodality, variable feature sizes, and normalization.\nFurthermore, we empirically demonstrate that such a model can successfully\nestimate multiple features, including transmission rank, selected precoder,\nDoppler spread, and delay profile.", "AI": {"tldr": "This paper proposes a transformer-based foundation model for communication data, capable of handling multi-modality and estimating multiple features.", "motivation": "To develop a general model for communication systems that can handle multiple applications and features.", "method": "A transformer-based, multi-modal model designed to operate directly on communication data, with proposed methodologies to address key challenges.", "result": "The model successfully estimates multiple features including transmission rank, selected precoder, Doppler spread, and delay profile.", "conclusion": "This work takes a step towards a foundation model for communication data, demonstrating the potential of large general models in communication systems."}}
{"id": "2505.13954", "pdf": "https://arxiv.org/pdf/2505.13954", "abs": "https://arxiv.org/abs/2505.13954", "authors": ["Jiahe Chen", "Ziye Ma"], "title": "VAMO: Efficient Large-Scale Nonconvex Optimization via Adaptive Zeroth Order Variance Reduction", "categories": ["cs.LG"], "comment": null, "summary": "Optimizing large-scale nonconvex problems, common in machine learning,\ndemands balancing rapid convergence with computational efficiency. First-order\n(FO) stochastic methods like SVRG provide fast convergence and good\ngeneralization but incur high costs due to full-batch gradients in large\nmodels. Conversely, zeroth-order (ZO) algorithms reduce this burden using\nestimated gradients, yet their slow convergence in high-dimensional settings\nlimits practicality. We introduce VAMO (VAriance-reduced Mixed-gradient\nOptimizer), a stochastic variance-reduced method combining FO mini-batch\ngradients with lightweight ZO finite-difference probes under an SVRG-style\nframework. VAMO's hybrid design uses a two-point ZO estimator to achieve a\ndimension-agnostic convergence rate of $\\mathcal{O}(1/T + 1/b)$, where $T$ is\nthe number of iterations and $b$ is the batch-size, surpassing the\ndimension-dependent slowdown of purely ZO methods and significantly improving\nover SGD's $\\mathcal{O}(1/\\sqrt{T})$ rate. Additionally, we propose a\nmulti-point ZO variant that mitigates the $O(1/b)$ error by adjusting number of\nestimation points to balance convergence and cost, making it ideal for a whole\nrange of computationally constrained scenarios. Experiments including\ntraditional neural network training and LLM finetuning show VAMO outperforms\nestablished FO and ZO methods, offering a faster, more flexible option for\nimproved efficiency.", "AI": {"tldr": "Introduce VAMO, a hybrid optimizer combining first-order and zeroth-order methods, achieving better convergence rates than both traditional methods and existing first-order or zeroth-order optimizers.", "motivation": "Balancing rapid convergence with computational efficiency in large-scale nonconvex optimization problems.", "method": "Combining first-order mini-batch gradients with zeroth-order finite-difference probes under an SVRG-style framework.", "result": "VAMO achieves a dimension-agnostic convergence rate of O(1/T + 1/b), surpassing purely ZO methods and improving over SGD's rate.", "conclusion": "VAMO, a variance-reduced mixed-gradient optimizer, combines first-order and zeroth-order methods to improve convergence and computational efficiency."}}
{"id": "2505.14604", "pdf": "https://arxiv.org/pdf/2505.14604", "abs": "https://arxiv.org/abs/2505.14604", "authors": ["Haoran Zhao", "Yuchen Yan", "Yongliang Shen", "Haolei Xu", "Wenqi Zhang", "Kaitao Song", "Jian Shao", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Let LLMs Break Free from Overthinking via Self-Braking Tuning", "categories": ["cs.AI"], "comment": "Github:https://github.com/CCAI-Lab/Self-Braking-Tuning; Project:\n  https://CCAI-Lab.github.io/SBT", "summary": "Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have\nsignificantly enhanced their reasoning capabilities by generating longer chains\nof thought, demonstrating outstanding performance across a variety of tasks.\nHowever, this performance gain comes at the cost of a substantial increase in\nredundant reasoning during the generation process, leading to high\ncomputational overhead and exacerbating the issue of overthinking. Although\nnumerous existing approaches aim to address the problem of overthinking, they\noften rely on external interventions. In this paper, we propose a novel\nframework, Self-Braking Tuning (SBT), which tackles overthinking from the\nperspective of allowing the model to regulate its own reasoning process, thus\neliminating the reliance on external control mechanisms. We construct a set of\noverthinking identification metrics based on standard answers and design a\nsystematic method to detect redundant reasoning. This method accurately\nidentifies unnecessary steps within the reasoning trajectory and generates\ntraining signals for learning self-regulation behaviors. Building on this\nfoundation, we develop a complete strategy for constructing data with adaptive\nreasoning lengths and introduce an innovative braking prompt mechanism that\nenables the model to naturally learn when to terminate reasoning at an\nappropriate point. Experiments across mathematical benchmarks (AIME, AMC,\nMATH500, GSM8K) demonstrate that our method reduces token consumption by up to\n60% while maintaining comparable accuracy to unconstrained models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Self-Braking Tuning (SBT)\uff0c\u7528\u4e8e\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5197\u4f59\u63a8\u7406\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u5e76\u89e3\u51b3\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5c06token\u6d88\u8017\u51cf\u5c11\u9ad8\u8fbe60%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4e0d\u53d7\u7ea6\u675f\u7684\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5916\u90e8\u5e72\u9884\uff0c\u800c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u65e8\u5728\u4ece\u5141\u8bb8\u6a21\u578b\u8c03\u8282\u5176\u81ea\u8eab\u63a8\u7406\u8fc7\u7a0b\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u6d88\u9664\u5bf9\u5916\u90e8\u63a7\u5236\u673a\u5236\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-Braking Tuning (SBT)\u7684\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u6784\u5efa\u57fa\u4e8e\u6807\u51c6\u7b54\u6848\u7684\u8fc7\u5ea6\u601d\u8003\u8bc6\u522b\u6307\u6807\uff0c\u8bbe\u8ba1\u7cfb\u7edf\u65b9\u6cd5\u68c0\u6d4b\u5197\u4f59\u63a8\u7406\uff0c\u5e76\u5f00\u53d1\u5b8c\u6574\u7684\u81ea\u9002\u5e94\u63a8\u7406\u957f\u5ea6\u6570\u636e\u6784\u9020\u7b56\u7565\u548c\u521b\u65b0\u7684\u5239\u8f66\u63d0\u793a\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u5c11token\u6d88\u8017\uff0c\u6700\u9ad8\u53ef\u8fbe60%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4e0d\u53d7\u7ea6\u675f\u7684\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Self-Braking Tuning\u6846\u67b6\u6210\u529f\u5730\u51cf\u5c11\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5197\u4f59\u63a8\u7406\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u5916\u90e8\u63a7\u5236\u673a\u5236\u3002"}}
{"id": "2505.13989", "pdf": "https://arxiv.org/pdf/2505.13989", "abs": "https://arxiv.org/abs/2505.13989", "authors": ["Yanzhe Wen", "Xunkai Li", "Qi Zhang", "Zhu Lei", "Guang Zeng", "Rong-Hua Li", "Guoren Wang"], "title": "When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, large language models (LLMs) have significantly advanced\ntext-attributed graph (TAG) learning. However, existing methods inadequately\nhandle data uncertainty in open-world scenarios, especially concerning limited\nlabeling and unknown-class nodes. Prior solutions typically rely on isolated\nsemantic or structural approaches for unknown-class rejection, lacking\neffective annotation pipelines. To address these limitations, we propose\nOpen-world Graph Assistant (OGA), an LLM-based framework that combines adaptive\nlabel traceability, which integrates semantics and topology for unknown-class\nrejection, and a graph label annotator to enable model updates using newly\nannotated nodes. Comprehensive experiments demonstrate OGA's effectiveness and\npracticality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u6846\u67b6OGA\uff0c\u7528\u4e8e\u5904\u7406\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6709\u9650\u6807\u6ce8\u548c\u672a\u77e5\u7c7b\u522b\u8282\u70b9\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86OGA\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u6807\u7b7e\u8ffd\u8e2a\u548c\u56fe\u6807\u7b7e\u6ce8\u91ca\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660eOGA\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "OGA\u4e3a\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u7684\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.14615", "pdf": "https://arxiv.org/pdf/2505.14615", "abs": "https://arxiv.org/abs/2505.14615", "authors": ["Anjiang Wei", "Yuheng Wu", "Yingjia Wan", "Tarun Suresh", "Huanmi Tan", "Zhanke Zhou", "Sanmi Koyejo", "Ke Wang", "Alex Aiken"], "title": "SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "comment": null, "summary": "We introduce SATBench, a benchmark for evaluating the logical reasoning\ncapabilities of large language models (LLMs) through logical puzzles derived\nfrom Boolean satisfiability (SAT) problems. Unlike prior work that focuses on\ninference rule-based reasoning, which often involves deducing conclusions from\na set of premises, our approach leverages the search-based nature of SAT\nproblems, where the objective is to find a solution that fulfills a specified\nset of logical constraints. Each instance in SATBench is generated from a SAT\nformula, then translated into a story context and conditions using LLMs. The\ngeneration process is fully automated and allows for adjustable difficulty by\nvarying the number of clauses. All 2100 puzzles are validated through both\nLLM-assisted and solver-based consistency checks, with human validation on a\nsubset. Experimental results show that even the strongest model, o4-mini,\nachieves only 65.0% accuracy on hard UNSAT problems, close to the random\nbaseline of 50%. SATBench exposes fundamental limitations in the search-based\nlogical reasoning abilities of current LLMs and provides a scalable testbed for\nfuture research in logical reasoning.", "AI": {"tldr": "Introduces SATBench, a benchmark for evaluating LLMs' logical reasoning capabilities through SAT-derived puzzles.", "motivation": "To evaluate LLMs' logical reasoning abilities beyond inference rule-based methods by leveraging the search-based nature of SAT problems.", "method": "Generates puzzles from SAT formulas, translates them into story contexts, and validates them using LLMs and solvers.", "result": "Strongest model achieves only 65.0% accuracy on hard UNSAT problems, similar to random baseline.", "conclusion": "Highlights limitations in LLMs' search-based logical reasoning abilities and provides a scalable testbed for future research."}}
{"id": "2505.14005", "pdf": "https://arxiv.org/pdf/2505.14005", "abs": "https://arxiv.org/abs/2505.14005", "authors": ["Han Zhang", "Yan Wang", "Guanfeng Liu", "Pengfei Ding", "Huaxiong Wang", "Kwok-Yan Lam"], "title": "Towards Comprehensive and Prerequisite-Free Explainer for Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025 AI4Tech Track", "summary": "To enhance the reliability and credibility of graph neural networks (GNNs)\nand improve the transparency of their decision logic, a new field of\nexplainability of GNNs (XGNN) has emerged. However, two major limitations\nseverely degrade the performance and hinder the generalizability of existing\nXGNN methods: they (a) fail to capture the complete decision logic of GNNs\nacross diverse distributions in the entire dataset's sample space, and (b)\nimpose strict prerequisites on edge properties and GNN internal accessibility.\nTo address these limitations, we propose OPEN, a novel c\\textbf{O}mprehensive\nand \\textbf{P}rerequisite-free \\textbf{E}xplainer for G\\textbf{N}Ns. OPEN, as\nthe first work in the literature, can infer and partition the entire dataset's\nsample space into multiple environments, each containing graphs that follow a\ndistinct distribution. OPEN further learns the decision logic of GNNs across\ndifferent distributions by sampling subgraphs from each environment and\nanalyzing their predictions, thus eliminating the need for strict\nprerequisites. Experimental results demonstrate that OPEN captures nearly\ncomplete decision logic of GNNs, outperforms state-of-the-art methods in\nfidelity while maintaining similar efficiency, and enhances robustness in\nreal-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u91ca\u65b9\u6cd5OPEN\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u83b7\u5b8c\u6574\u51b3\u7b56\u903b\u8f91\u548c\u5bf9\u8fb9\u5c5e\u6027\u53ca\u5185\u90e8\u53ef\u8bbf\u95ee\u6027\u8981\u6c42\u4e25\u683c\u7684\u95ee\u9898\u3002", "motivation": "\u589e\u5f3a\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u63d0\u9ad8\u5176\u51b3\u7b56\u903b\u8f91\u7684\u900f\u660e\u5ea6\u3002", "method": "\u63d0\u51faOPEN\u65b9\u6cd5\uff0c\u5c06\u6837\u672c\u7a7a\u95f4\u5212\u5206\u4e3a\u591a\u4e2a\u73af\u5883\uff0c\u5e76\u4ece\u6bcf\u4e2a\u73af\u5883\u4e2d\u91c7\u6837\u5b50\u56fe\u6765\u5206\u6790\u9884\u6d4b\u3002", "result": "OPEN\u65b9\u6cd5\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\uff0c\u5728\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u589e\u5f3a\u4e86\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "OPEN\u65b9\u6cd5\u80fd\u591f\u6355\u83b7\u51e0\u4e4e\u5b8c\u6574\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u903b\u8f91\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e00\u4e9b\u91cd\u5927\u9650\u5236\u3002"}}
{"id": "2505.14627", "pdf": "https://arxiv.org/pdf/2505.14627", "abs": "https://arxiv.org/abs/2505.14627", "authors": ["Ashutosh Adhikari", "Mirella Lapata"], "title": "Debating for Better Reasoning: An Unsupervised Multimodal Approach", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) gain expertise across diverse domains and\nmodalities, scalable oversight becomes increasingly challenging, particularly\nwhen their capabilities may surpass human evaluators. Debate has emerged as a\npromising mechanism for enabling such oversight. In this work, we extend the\ndebate paradigm to a multimodal setting, exploring its potential for weaker\nmodels to supervise and enhance the performance of stronger models. We focus on\nvisual question answering (VQA), where two \"sighted\" expert vision-language\nmodels debate an answer, while a \"blind\" (text-only) judge adjudicates based\nsolely on the quality of the arguments. In our framework, the experts defend\nonly answers aligned with their beliefs, thereby obviating the need for\nexplicit role-playing and concentrating the debate on instances of expert\ndisagreement. Experiments on several multimodal tasks demonstrate that the\ndebate framework consistently outperforms individual expert models. Moreover,\njudgments from weaker LLMs can help instill reasoning capabilities in\nvision-language models through finetuning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u8fa9\u8bba\u6846\u67b6\uff0c\u5229\u7528\u8f83\u5f31\u7684\u8bed\u8a00\u6a21\u578b\u76d1\u7763\u548c\u589e\u5f3a\u8f83\u5f3a\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u4f18\u4e8e\u5355\u72ec\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u5e76\u4e14\u8f83\u5f31\u7684\u8bed\u8a00\u6a21\u578b\u7684\u5224\u65ad\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u5e2e\u52a9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u548c\u6a21\u6001\u4e0a\u83b7\u5f97\u4e13\u4e1a\u77e5\u8bc6\uff0c\u53ef\u6269\u5c55\u7684\u76d1\u7763\u53d8\u5f97\u8d8a\u6765\u8d8a\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5f53\u5b83\u4eec\u7684\u80fd\u529b\u53ef\u80fd\u8d85\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u8005\u65f6\u3002", "method": "\u6269\u5c55\u4e86\u8fa9\u8bba\u8303\u5f0f\u5230\u591a\u6a21\u6001\u8bbe\u7f6e\u4e2d\uff0c\u8ba9\u4e24\u4e2a\u201c\u6709\u89c6\u529b\u201d\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e13\u5bb6\u5c31\u7b54\u6848\u8fdb\u884c\u8fa9\u8bba\uff0c\u800c\u4e00\u4e2a\u201c\u65e0\u89c6\u529b\u201d\uff08\u4ec5\u6587\u672c\uff09\u7684\u88c1\u5224\u6839\u636e\u8bba\u70b9\u8d28\u91cf\u6765\u88c1\u51b3\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8fa9\u8bba\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u4e2a\u4f53\u4e13\u5bb6\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8f83\u5f31\u7684\u8bed\u8a00\u6a21\u578b\u7684\u5224\u65ad\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u5e2e\u52a9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001\u8fa9\u8bba\u6846\u67b6\u4e3a\u8f83\u5f31\u6a21\u578b\u76d1\u7763\u548c\u589e\u5f3a\u8f83\u5f3a\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.14011", "pdf": "https://arxiv.org/pdf/2505.14011", "abs": "https://arxiv.org/abs/2505.14011", "authors": ["Yifei Jin", "Xin Zheng", "Lei Guo"], "title": "Adaptive Sentencing Prediction with Guaranteed Accuracy and Legal Interpretability", "categories": ["cs.LG"], "comment": null, "summary": "Existing research on judicial sentencing prediction predominantly relies on\nend-to-end models, which often neglect the inherent sentencing logic and lack\ninterpretability-a critical requirement for both scholarly research and\njudicial practice. To address this challenge, we make three key\ncontributions:First, we propose a novel Saturated Mechanistic Sentencing (SMS)\nmodel, which provides inherent legal interpretability by virtue of its\nfoundation in China's Criminal Law. We also introduce the corresponding\nMomentum Least Mean Squares (MLMS) adaptive algorithm for this model. Second,\nfor the MLMS algorithm based adaptive sentencing predictor, we establish a\nmathematical theory on the accuracy of adaptive prediction without resorting to\nany stationarity and independence assumptions on the data. We also provide a\nbest possible upper bound for the prediction accuracy achievable by the best\npredictor designed in the known parameters case. Third, we construct a Chinese\nIntentional Bodily Harm (CIBH) dataset. Utilizing this real-world data,\nextensive experiments demonstrate that our approach achieves a prediction\naccuracy that is not far from the best possible theoretical upper bound,\nvalidating both the model's suitability and the algorithm's accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u6cd5\u5f8b\u89e3\u91ca\u6027\u7684\u65b0\u578b\u53f8\u6cd5\u91cf\u5211\u9884\u6d4b\u6a21\u578b\uff08SMS\uff09\u53ca\u5176\u81ea\u9002\u5e94\u7b97\u6cd5\uff08MLMS\uff09\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u53f8\u6cd5\u91cf\u5211\u9884\u6d4b\u7814\u7a76\u591a\u4f9d\u8d56\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5ffd\u89c6\u4e86\u56fa\u6709\u7684\u91cf\u5211\u903b\u8f91\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u8fd9\u5bf9\u5b66\u672f\u7814\u7a76\u548c\u53f8\u6cd5\u5b9e\u8df5\u90fd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51faSaturated Mechanistic Sentencing (SMS)\u6a21\u578b\u53caMomentum Least Mean Squares (MLMS)\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u65e0\u4efb\u4f55\u5e73\u7a33\u6027\u548c\u72ec\u7acb\u6027\u5047\u8bbe\u4e0b\u7684\u9884\u6d4b\u7cbe\u5ea6\u6570\u5b66\u7406\u8bba\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684SMS\u6a21\u578b\u4e0eMLMS\u7b97\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u63a5\u8fd1\u6700\u4f73\u53ef\u80fd\u7684\u7406\u8bba\u4e0a\u9650\u3002", "conclusion": "\u63d0\u51fa\u7684SMS\u6a21\u578b\u548cMLMS\u7b97\u6cd5\u5728\u53f8\u6cd5\u91cf\u5211\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6cd5\u5f8b\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u7684CIBH\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.14656", "pdf": "https://arxiv.org/pdf/2505.14656", "abs": "https://arxiv.org/abs/2505.14656", "authors": ["Zihao Zhang", "Fei Liu"], "title": "Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning", "categories": ["cs.AI"], "comment": null, "summary": "While LLMs excel at open-ended reasoning, they often struggle with\ncost-sensitive planning, either treating all actions as having equal cost or\nfailing to stay within strict budgets. In this paper, we introduce\nCost-Augmented Monte Carlo Tree Search (CATS), a novel approach that brings\nexplicit cost-awareness into LLM-guided planning. Tight cost constraints push\nthe planner to quickly identify infeasible solutions, while looser constraints\nencourage optimization for minimal cost. We benchmark top LLMs such as GPT-4.1,\nClaude-3.7-Sonnet, and DeepSeek-R1, against our CATS planner to evaluate their\nperformance in cost-sensitive scenarios. Our experiments suggest that raw LLMs\nsuch as GPT-4.1 often falter under tight budgets, whereas CATS consistently\ndelivers strong performance, achieving higher task success rates and better\ncost efficiency. CATS provides an effective solution for budget-aware\ndecision-making by combining the reasoning power of LLMs with structured\nsearch.", "AI": {"tldr": "This paper introduces CATS, a new method that adds explicit cost-awareness to large language model (LLM)-guided planning using Cost-Augmented Monte Carlo Tree Search.", "motivation": "LLMs struggle with cost-sensitive planning as they either treat all actions equally or fail under strict budgets.", "method": "Developing Cost-Augmented Monte Carlo Tree Search (CATS) to bring explicit cost-awareness into LLM-guided planning.", "result": "CATS performs better than raw LLMs like GPT-4.1 in cost-sensitive scenarios with higher task success rates and cost efficiency.", "conclusion": "CATS effectively combines LLM reasoning power with structured search for budget-aware decision-making."}}
{"id": "2505.14667", "pdf": "https://arxiv.org/pdf/2505.14667", "abs": "https://arxiv.org/abs/2505.14667", "authors": ["Wonje Jeung", "Sangyeon Yoon", "Minsuk Kahng", "Albert No"], "title": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages", "summary": "Large Reasoning Models (LRMs) have become powerful tools for complex problem\nsolving, but their structured reasoning pathways can lead to unsafe outputs\nwhen exposed to harmful prompts. Existing safety alignment methods reduce\nharmful outputs but can degrade reasoning depth, leading to significant\ntrade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated\njailbreak attacks. To address this, we introduce SAFEPATH, a lightweight\nalignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at\nthe start of their reasoning, in response to harmful prompts, while leaving the\nrest of the reasoning process unsupervised. Empirical results across multiple\nbenchmarks indicate that SAFEPATH effectively reduces harmful outputs while\nmaintaining reasoning performance. Specifically, SAFEPATH reduces harmful\nresponses by up to 90.0% and blocks 83.3% of jailbreak attempts in the\nDeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than\nDirect Refusal and 314.1x less than SafeChain. We further introduce a zero-shot\nvariant that requires no fine-tuning. In addition, we provide a comprehensive\nanalysis of how existing methods in LLMs generalize, or fail, when applied to\nreasoning-centric models, revealing critical gaps and new directions for safer\nAI.", "AI": {"tldr": "\u63d0\u51faSAFEPATH\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\uff0c\u5e76\u4e14\u6bd4\u5176\u4ed6\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5728\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u65f6\u4f1a\u964d\u4f4e\u63a8\u7406\u6df1\u5ea6\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u6743\u8861\u4e14\u5bb9\u6613\u53d7\u5230\u9ad8\u7ea7\u653b\u51fb\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u65b9\u6cd5SAFEPATH\uff0c\u5728\u6709\u5bb3\u63d0\u793a\u4e0b\u5fae\u8c03LRM\u5728\u63a8\u7406\u5f00\u59cb\u65f6\u53d1\u51fa8-token\u5b89\u5168\u5f15\u8a00\u3002", "result": "SAFEPATH\u51cf\u5c11\u4e86\u9ad8\u8fbe90.0%\u7684\u6709\u5bb3\u54cd\u5e94\uff0c\u5728DeepSeek-R1-Distill-Llama-8B\u6a21\u578b\u4e2d\u963b\u6b62\u4e8683.3%\u7684\u8d8a\u72f1\u5c1d\u8bd5\uff0c\u8ba1\u7b97\u9700\u6c42\u663e\u8457\u4f4e\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "SAFEPATH\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8LRM\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86LLM\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5c40\u9650\u6027\u548c\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.14024", "pdf": "https://arxiv.org/pdf/2505.14024", "abs": "https://arxiv.org/abs/2505.14024", "authors": ["Di Wu", "Qian Li", "Heng Yang", "Yong Han"], "title": "FedGraM: Defending Against Untargeted Attacks in Federated Learning via Embedding Gram Matrix", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables geographically distributed clients to\ncollaboratively train machine learning models by sharing only their local\nmodels, ensuring data privacy. However, FL is vulnerable to untargeted attacks\nthat aim to degrade the global model's performance on the underlying data\ndistribution. Existing defense mechanisms attempt to improve FL's resilience\nagainst such attacks, but their effectiveness is limited in practical FL\nenvironments due to data heterogeneity. On the contrary, we aim to detect and\nremove the attacks to mitigate their impact. Generalization contribution plays\na crucial role in distinguishing untargeted attacks. Our observations indicate\nthat, with limited data, the divergence between embeddings representing\ndifferent classes provides a better measure of generalization than direct\naccuracy. In light of this, we propose a novel robust aggregation method,\nFedGraM, designed to defend against untargeted attacks in FL. The server\nmaintains an auxiliary dataset containing one sample per class to support\naggregation. This dataset is fed to the local models to extract embeddings.\nThen, the server calculates the norm of the Gram Matrix of the embeddings for\neach local model. The norm serves as an indicator of each model's inter-class\nseparation capability in the embedding space. FedGraM identifies and removes\npotentially malicious models by filtering out those with the largest norms,\nthen averages the remaining local models to form the global model. We conduct\nextensive experiments to evaluate the performance of FedGraM. Our empirical\nresults show that with limited data samples used to construct the auxiliary\ndataset, FedGraM achieves exceptional performance, outperforming\nstate-of-the-art defense methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FedGraM\uff0c\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97Gram\u77e9\u9635\u8303\u6570\u6765\u68c0\u6d4b\u548c\u79fb\u9664\u6076\u610f\u6a21\u578b\uff0c\u6709\u6548\u63d0\u5347\u4e86FL\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684FL\u9632\u5fa1\u673a\u5236\u5728\u5b9e\u9645\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u65b0\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u79fb\u9664\u672a\u9488\u5bf9\u653b\u51fb\uff0c\u51cf\u8f7b\u5176\u5f71\u54cd\u3002", "method": "FedGraM\u901a\u8fc7\u7ef4\u62a4\u8f85\u52a9\u6570\u636e\u96c6\u63d0\u53d6\u5d4c\u5165\u5411\u91cf\uff0c\u5e76\u5229\u7528Gram\u77e9\u9635\u8303\u6570\u8861\u91cf\u6a21\u578b\u7684\u7c7b\u95f4\u5206\u79bb\u80fd\u529b\uff0c\u4ece\u800c\u8bc6\u522b\u5e76\u79fb\u9664\u6f5c\u5728\u6076\u610f\u6a21\u578b\u3002", "result": "FedGraM\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u5353\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6709\u9650\u6837\u672c\u6761\u4ef6\u4e0b\u3002", "conclusion": "FedGraM\u5728\u6709\u9650\u6837\u672c\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2505.14668", "pdf": "https://arxiv.org/pdf/2505.14668", "abs": "https://arxiv.org/abs/2505.14668", "authors": ["Bufang Yang", "Lilin Xu", "Liekang Zeng", "Kaiwei Liu", "Siyang Jiang", "Wenrui Lu", "Hongkai Chen", "Xiaofan Jiang", "Guoliang Xing", "Zhenyu Yan"], "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have propelled intelligent\nagents from reactive responses to proactive support. While promising, existing\nproactive agents either rely exclusively on observations from enclosed\nenvironments (e.g., desktop UIs) with direct LLM inference or employ rule-based\nproactive notifications, leading to suboptimal user intent understanding and\nlimited functionality for proactive service. In this paper, we introduce\nContextAgent, the first context-aware proactive agent that incorporates\nextensive sensory contexts to enhance the proactive capabilities of LLM agents.\nContextAgent first extracts multi-dimensional contexts from massive sensory\nperceptions on wearables (e.g., video and audio) to understand user intentions.\nContextAgent then leverages the sensory contexts and the persona contexts from\nhistorical data to predict the necessity for proactive services. When proactive\nassistance is needed, ContextAgent further automatically calls the necessary\ntools to assist users unobtrusively. To evaluate this new task, we curate\nContextAgentBench, the first benchmark for evaluating context-aware proactive\nLLM agents, covering 1,000 samples across nine daily scenarios and twenty\ntools. Experiments on ContextAgentBench show that ContextAgent outperforms\nbaselines by achieving up to 8.5% and 6.0% higher accuracy in proactive\npredictions and tool calling, respectively. We hope our research can inspire\nthe development of more advanced, human-centric, proactive AI assistants.", "AI": {"tldr": "\u63d0\u51faContextAgent\uff0c\u9996\u4e2a\u7ed3\u5408\u591a\u7ef4\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4e3b\u52a8\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff0c\u80fd\u4ece\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u611f\u5b98\u6570\u636e\u548c\u5386\u53f2\u6570\u636e\u4e2d\u63d0\u53d6\u4fe1\u606f\u6765\u9884\u6d4b\u7528\u6237\u610f\u56fe\u5e76\u63d0\u4f9b\u975e\u4fb5\u5165\u5f0f\u8f85\u52a9\u670d\u52a1\u3002\u901a\u8fc7\u521b\u5efaContextAgentBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u9a8c\u8bc1\u4e86\u5176\u5728\u4e3b\u52a8\u9884\u6d4b\u548c\u5de5\u5177\u8c03\u7528\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u4e3b\u52a8\u4ee3\u7406\u8981\u4e48\u4f9d\u8d56\u5c01\u95ed\u73af\u5883\u4e0b\u7684\u76f4\u63a5LLM\u63a8\u65ad\uff0c\u8981\u4e48\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u901a\u77e5\uff0c\u5bfc\u81f4\u7528\u6237\u610f\u56fe\u7406\u89e3\u4e0d\u4f73\u4e14\u529f\u80fd\u53d7\u9650\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u6765\u63d0\u9ad8\u4e3b\u52a8\u6027\u548c\u670d\u52a1\u8d28\u91cf\u3002", "method": "ContextAgent\u9996\u5148\u4ece\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u591a\u7ef4\u611f\u5b98\u6570\u636e\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u4fe1\u606f\u7406\u89e3\u7528\u6237\u610f\u56fe\uff1b\u63a5\u7740\u5229\u7528\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u4ee5\u53ca\u5386\u53f2\u6570\u636e\u4e2d\u7684\u4e2a\u4eba\u5316\u4e0a\u4e0b\u6587\u9884\u6d4b\u662f\u5426\u9700\u8981\u4e3b\u52a8\u670d\u52a1\uff1b\u5f53\u9700\u8981\u5e2e\u52a9\u65f6\uff0c\u81ea\u52a8\u8c03\u7528\u76f8\u5173\u5de5\u5177\u8fdb\u884c\u8f85\u52a9\u3002", "result": "ContextAgent\u5728ContextAgentBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u8272\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u4e3b\u52a8\u9884\u6d4b\u548c\u5de5\u5177\u8c03\u7528\u65b9\u9762\u5206\u522b\u63d0\u9ad8\u4e868.5%\u548c6.0%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86ContextAgent\u4f5c\u4e3a\u9996\u4e2a\u4e0a\u4e0b\u6587\u611f\u77e5\u4e3b\u52a8\u4ee3\u7406\u7684\u4f18\u52bf\uff0c\u5e76\u5e0c\u671b\u63a8\u52a8\u66f4\u52a0\u5148\u8fdb\u7684\u4eba\u672c\u5bfc\u5411\u4e3b\u52a8AI\u52a9\u624b\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.14033", "pdf": "https://arxiv.org/pdf/2505.14033", "abs": "https://arxiv.org/abs/2505.14033", "authors": ["Guoming Li", "Jian Yang", "Yifan Chen"], "title": "Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": "Accepted at the 31st ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, KDD 2025 February Cycle", "summary": "Filtering-based graph neural networks (GNNs) constitute a distinct class of\nGNNs that employ graph filters to handle graph-structured data, achieving\nnotable success in various graph-related tasks. Conventional methods adopt a\ngraph-wise filtering paradigm, imposing a uniform filter across all nodes, yet\nrecent findings suggest that this rigid paradigm struggles with heterophilic\ngraphs. To overcome this, recent works have introduced node-wise filtering,\nwhich assigns distinct filters to individual nodes, offering enhanced\nadaptability. However, a fundamental gap remains: a comprehensive framework\nunifying these two strategies is still absent, limiting theoretical insights\ninto the filtering paradigms. Moreover, through the lens of Contextual\nStochastic Block Model, we reveal that a synthesis of graph-wise and node-wise\nfiltering provides a sufficient solution for classification on graphs\nexhibiting both homophily and heterophily, suggesting the risk of excessive\nparameterization and potential overfitting with node-wise filtering. To address\nthe limitations, this paper introduces Coarsening-guided Partition-wise\nFiltering (CPF). CPF innovates by performing filtering on node partitions. The\nmethod begins with structure-aware partition-wise filtering, which filters node\npartitions obtained via graph coarsening algorithms, and then performs\nfeature-aware partition-wise filtering, refining node embeddings via filtering\non clusters produced by $k$-means clustering over features. In-depth analysis\nis conducted for each phase of CPF, showing its superiority over other\nparadigms. Finally, benchmark node classification experiments, along with a\nreal-world graph anomaly detection application, validate CPF's efficacy and\npractical utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u8fc7\u6ee4\u65b9\u6cd5CPF\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u548c\u7279\u5f81\u611f\u77e5\u7684\u5206\u533a\u8fc7\u6ee4\u6765\u63d0\u9ad8\u5728\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u56fe\u4e0a\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u57fa\u51c6\u8282\u70b9\u5206\u7c7b\u5b9e\u9a8c\u548c\u5b9e\u9645\u56fe\u5f02\u5e38\u68c0\u6d4b\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u8fc7\u6ee4\u65b9\u6cd5\u8981\u4e48\u91c7\u7528\u7edf\u4e00\u7684\u56fe\u7ea7\u8fc7\u6ee4\uff0c\u8981\u4e48\u9488\u5bf9\u6bcf\u4e2a\u8282\u70b9\u5206\u914d\u4e0d\u540c\u7684\u8fc7\u6ee4\u5668\uff0c\u4f46\u90fd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7f3a\u4e4f\u5bf9\u8fd9\u4e24\u79cd\u7b56\u7565\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u540c\u65f6\u5728\u5904\u7406\u5f02\u8d28\u6027\u56fe\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faCoarsening-guided Partition-wise Filtering (CPF)\uff0c\u9996\u5148\u901a\u8fc7\u56fe\u7b80\u5316\u7b97\u6cd5\u5f97\u5230\u8282\u70b9\u5206\u533a\u5e76\u8fdb\u884c\u7ed3\u6784\u611f\u77e5\u7684\u5206\u533a\u8fc7\u6ee4\uff0c\u7136\u540e\u901a\u8fc7\u7279\u5f81\u611f\u77e5\u7684\u5206\u533a\u8fc7\u6ee4\u5229\u7528k-means\u805a\u7c7b\u751f\u6210\u7684\u7c07\u8fdb\u4e00\u6b65\u4f18\u5316\u8282\u70b9\u5d4c\u5165\u3002", "result": "CPF\u5728\u5904\u7406\u5177\u6709\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u7684\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u5982\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u4e5f\u5c55\u73b0\u4e86\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "CPF\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u8fc7\u6ee4\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u4e3a\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2505.14681", "pdf": "https://arxiv.org/pdf/2505.14681", "abs": "https://arxiv.org/abs/2505.14681", "authors": ["Mengru Wang", "Xingyu Chen", "Yue Wang", "Zhiwei He", "Jiahao Xu", "Tian Liang", "Qiuzhi Liu", "Yunzhi Yao", "Wenxuan Wang", "Ruotian Ma", "Haitao Mi", "Ningyu Zhang", "Zhaopeng Tu", "Xiaolong Li", "Dong Yu"], "title": "Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.LG"], "comment": "Work in progress", "summary": "Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs)\nhave achieved impressive reasoning capabilities by selectively activating\nexperts to facilitate structured cognitive processes. Despite notable advances,\nexisting reasoning models often suffer from cognitive inefficiencies like\noverthinking and underthinking. To address these limitations, we introduce a\nnovel inference-time steering methodology called Reinforcing Cognitive Experts\n(RICE), designed to improve reasoning performance without additional training\nor complex heuristics. Leveraging normalized Pointwise Mutual Information\n(nPMI), we systematically identify specialized experts, termed ''cognitive\nexperts'' that orchestrate meta-level reasoning operations characterized by\ntokens like ''<think>''. Empirical evaluations with leading MoE-based LRMs\n(DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning\nbenchmarks demonstrate noticeable and consistent improvements in reasoning\naccuracy, cognitive efficiency, and cross-domain generalization. Crucially, our\nlightweight approach substantially outperforms prevalent reasoning-steering\ntechniques, such as prompt design and decoding constraints, while preserving\nthe model's general instruction-following skills. These results highlight\nreinforcing cognitive experts as a promising, practical, and interpretable\ndirection to enhance cognitive efficiency within advanced reasoning models.", "AI": {"tldr": "This paper introduces RICE, a novel method for improving reasoning performance in Large Reasoning Models by identifying and reinforcing specialized 'cognitive experts' without extra training or complex heuristics.", "motivation": "To address cognitive inefficiencies (overthinking and underthinking) in existing reasoning models.", "method": "Introduces Reinforcing Cognitive Experts (RICE) leveraging normalized Pointwise Mutual Information (nPMI) to identify cognitive experts.", "result": "Significant improvements in reasoning accuracy, cognitive efficiency, and cross-domain generalization were observed across different benchmarks.", "conclusion": "The lightweight RICE approach outperforms current reasoning-steering techniques and enhances cognitive efficiency in advanced reasoning models."}}
{"id": "2505.14036", "pdf": "https://arxiv.org/pdf/2505.14036", "abs": "https://arxiv.org/abs/2505.14036", "authors": ["Gyubin Lee", "Truong Nhat Nguyen Bao", "Jaesik Yoon", "Dongwoo Lee", "Minsu Kim", "Yoshua Bengio", "Sungjin Ahn"], "title": "Adaptive Cyclic Diffusion for Inference Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have demonstrated strong generative capabilities across\ndomains ranging from image synthesis to complex reasoning tasks. However, most\ninference-time scaling methods rely on fixed denoising schedules, limiting\ntheir ability to allocate computation based on instance difficulty or\ntask-specific demands adaptively. We introduce the challenge of adaptive\ninference-time scaling-dynamically adjusting computational effort during\ninference-and propose Adaptive Bi-directional Cyclic Diffusion (ABCD), a\nflexible, search-based inference framework. ABCD refines outputs through\nbi-directional diffusion cycles while adaptively controlling exploration depth\nand termination. It comprises three components: Cyclic Diffusion Search,\nAutomatic Exploration-Exploitation Balancing, and Adaptive Thinking Time.\nExperiments show that ABCD improves performance across diverse tasks while\nmaintaining computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdaptive Bi-directional Cyclic Diffusion (ABCD)\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u52aa\u529b\uff0c\u4ee5\u9002\u5e94\u5b9e\u4f8b\u96be\u5ea6\u6216\u4efb\u52a1\u7279\u5b9a\u9700\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0cABCD\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u5404\u79cd\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u591a\u6570\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7684\u53bb\u566a\u8ba1\u5212\uff0c\u9650\u5236\u4e86\u5176\u6839\u636e\u5b9e\u4f8b\u96be\u5ea6\u6216\u4efb\u52a1\u7279\u5b9a\u9700\u6c42\u81ea\u9002\u5e94\u5206\u914d\u8ba1\u7b97\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdaptive Bi-directional Cyclic Diffusion (ABCD)\u7684\u7075\u6d3b\u7684\u57fa\u4e8e\u641c\u7d22\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5411\u6269\u6563\u5faa\u73af\u6765\u4f18\u5316\u8f93\u51fa\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u63a7\u5236\u63a2\u7d22\u6df1\u5ea6\u548c\u7ec8\u6b62\u3002ABCD\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1aCyclic Diffusion Search, Automatic Exploration-Exploitation Balancing, \u548c Adaptive Thinking Time\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cABCD\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u5404\u79cd\u4efb\u52a1\u7684\u8868\u73b0\u3002", "conclusion": "ABCD\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u63a8\u7406\u6846\u67b6\uff0c\u80fd\u591f\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u52aa\u529b\u3002"}}
{"id": "2505.06699", "pdf": "https://arxiv.org/pdf/2505.06699", "abs": "https://arxiv.org/abs/2505.06699", "authors": ["Xiyuan Wei", "Ming Lin", "Fanjiang Ye", "Fengguang Song", "Liangliang Cao", "My T. Thai", "Tianbao Yang"], "title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "18 pages, 6 figures", "summary": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.", "AI": {"tldr": "This paper introduces a new learning paradigm called model steering and proposes a theory-driven framework named DRRho risk minimization to improve generalization and data efficiency.", "motivation": "To understand the underlying principles of ad-hoc methods used in training large foundation models and provide theoretical insights for the new learning paradigm.", "method": "Propose a theory-driven framework called DRRho risk minimization based on Distributionally Robust Optimization (DRO). Introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP.", "result": "Theoretical insights are provided for the new learning paradigm, revealing a superior scaling law compared to CLIP without a reference model and demonstrating its strength over existing heuristic approaches.", "conclusion": "This work significantly enhances our understanding and practice of model steering by providing theoretical insights and introducing a novel method for CLIP with a reference model."}}
{"id": "2505.14039", "pdf": "https://arxiv.org/pdf/2505.14039", "abs": "https://arxiv.org/abs/2505.14039", "authors": ["Luca Pellegrini", "Massimiliano Ghiotto", "Edoardo Centofanti", "Luca Franco Pavarino"], "title": "Learning High-dimensional Ionic Model Dynamics Using Fourier Neural Operators", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Ionic models, described by systems of stiff ordinary differential equations,\nare fundamental tools for simulating the complex dynamics of excitable cells in\nboth Computational Neuroscience and Cardiology. Approximating these models\nusing Artificial Neural Networks poses significant challenges due to their\ninherent stiffness, multiscale nonlinearities, and the wide range of dynamical\nbehaviors they exhibit, including multiple equilibrium points, limit cycles,\nand intricate interactions. While in previous studies the dynamics of the\ntransmembrane potential has been predicted in low dimensionality settings, in\nthe present study we extend these results by investigating whether Fourier\nNeural Operators can effectively learn the evolution of all the state variables\nwithin these dynamical systems in higher dimensions. We demonstrate the\neffectiveness of this approach by accurately learning the dynamics of three\nwell-established ionic models with increasing dimensionality: the two-variable\nFitzHugh-Nagumo model, the four-variable Hodgkin-Huxley model, and the\nforty-one-variable O'Hara-Rudy model. To ensure the selection of near-optimal\nconfigurations for the Fourier Neural Operator, we conducted automatic\nhyperparameter tuning under two scenarios: an unconstrained setting, where the\nnumber of trainable parameters is not limited, and a constrained case with a\nfixed number of trainable parameters. Both constrained and unconstrained\narchitectures achieve comparable results in terms of accuracy across all the\nmodels considered. However, the unconstrained architecture required\napproximately half the number of training epochs to achieve similar error\nlevels, as evidenced by the loss function values recorded during training.\nThese results underline the capabilities of Fourier Neural Operators to\naccurately capture complex multiscale dynamics, even in high-dimensional\ndynamical systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86Fourier\u795e\u7ecf\u7b97\u5b50\u662f\u5426\u80fd\u6709\u6548\u5b66\u4e60\u79bb\u5b50\u6a21\u578b\u5728\u9ad8\u7ef4\u52a8\u529b\u7cfb\u7edf\u4e2d\u7684\u6240\u6709\u72b6\u6001\u53d8\u91cf\u6f14\u5316\u3002\u901a\u8fc7\u51c6\u786e\u5b66\u4e60\u4e09\u4e2a\u4e0d\u540c\u7ef4\u5ea6\u7684\u79bb\u5b50\u6a21\u578b\u7684\u52a8\u529b\u5b66\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u79bb\u5b50\u6a21\u578b\u6a21\u62df\u5174\u594b\u7ec6\u80de\u590d\u6742\u52a8\u529b\u5b66\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5176\u521a\u6027\u3001\u591a\u5c3a\u5ea6\u975e\u7ebf\u6027\u548c\u591a\u79cd\u52a8\u6001\u884c\u4e3a\u3002", "method": "\u4f7f\u7528Fourier\u795e\u7ecf\u7b97\u5b50\u6765\u5b66\u4e60\u79bb\u5b50\u6a21\u578b\u7684\u72b6\u6001\u53d8\u91cf\u6f14\u5316\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\u4f18\u5316\u6a21\u578b\u914d\u7f6e\u3002", "result": "\u6210\u529f\u5b66\u4e60\u4e86\u4e09\u4e2a\u79bb\u5b50\u6a21\u578b\u7684\u52a8\u529b\u5b66\uff0c\u5305\u62ecFitzHugh-Nagumo\u6a21\u578b\u3001Hodgkin-Huxley\u6a21\u578b\u548cO'Hara-Rudy\u6a21\u578b\uff0c\u4e14\u4e24\u79cd\u67b6\u6784\u5728\u51c6\u786e\u6027\u4e0a\u76f8\u5f53\uff0c\u4f46\u65e0\u7ea6\u675f\u67b6\u6784\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "Fourier\u795e\u7ecf\u7b97\u5b50\u80fd\u591f\u6709\u6548\u6355\u6349\u9ad8\u7ef4\u52a8\u529b\u7cfb\u7edf\u7684\u590d\u6742\u591a\u5c3a\u5ea6\u52a8\u6001\u3002"}}
{"id": "2505.14040", "pdf": "https://arxiv.org/pdf/2505.14040", "abs": "https://arxiv.org/abs/2505.14040", "authors": ["Jingyun Zhang", "Hao Peng", "Li Sun", "Guanlin Wu", "Chunyang Liu", "Zhengtao Yu"], "title": "Unsupervised Graph Clustering with Deep Structural Entropy", "categories": ["cs.LG"], "comment": "Accepted to Proceedings of the ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining 2025 (KDD 2025). 13 pages, 10 figures, 11 tables", "summary": "Research on Graph Structure Learning (GSL) provides key insights for\ngraph-based clustering, yet current methods like Graph Neural Networks (GNNs),\nGraph Attention Networks (GATs), and contrastive learning often rely heavily on\nthe original graph structure. Their performance deteriorates when the original\ngraph's adjacency matrix is too sparse or contains noisy edges unrelated to\nclustering. Moreover, these methods depend on learning node embeddings and\nusing traditional techniques like k-means to form clusters, which may not fully\ncapture the underlying graph structure between nodes. To address these\nlimitations, this paper introduces DeSE, a novel unsupervised graph clustering\nframework incorporating Deep Structural Entropy. It enhances the original graph\nwith quantified structural information and deep neural networks to form\nclusters. Specifically, we first propose a method for calculating structural\nentropy with soft assignment, which quantifies structure in a differentiable\nform. Next, we design a Structural Learning layer (SLL) to generate an\nattributed graph from the original feature data, serving as a target to enhance\nand optimize the original structural graph, thereby mitigating the issue of\nsparse connections between graph nodes. Finally, our clustering assignment\nmethod (ASS), based on GNNs, learns node embeddings and a soft assignment\nmatrix to cluster on the enhanced graph. The ASS layer can be stacked to meet\ndownstream task requirements, minimizing structural entropy for stable\nclustering and maximizing node consistency with edge-based cross-entropy loss.\nExtensive comparative experiments are conducted on four benchmark datasets\nagainst eight representative unsupervised graph clustering baselines,\ndemonstrating the superiority of the DeSE in both effectiveness and\ninterpretability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u56fe\u805a\u7c7b\u6846\u67b6DeSE\uff0c\u901a\u8fc7\u91cf\u5316\u7ed3\u6784\u4fe1\u606f\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u539f\u59cb\u56fe\u7ed3\u6784\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7ed3\u6784\u5b66\u4e60\u5c42\u548c\u805a\u7c7b\u5206\u914d\u65b9\u6cd5\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4e0e\u516b\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5c55\u793a\u4e86DeSE\u5728\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7b49\u65b9\u6cd5\u5728\u5904\u7406\u7a00\u758f\u6216\u5305\u542b\u566a\u58f0\u8fb9\u7684\u56fe\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u4f20\u7edf\u805a\u7c7b\u6280\u672f\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u8282\u70b9\u95f4\u7684\u6f5c\u5728\u56fe\u7ed3\u6784\u3002", "method": "\u5f15\u5165DeSE\u6846\u67b6\uff0c\u5305\u62ec\u8ba1\u7b97\u8f6f\u5206\u914d\u7684\u7ed3\u6784\u71b5\u65b9\u6cd5\u3001\u7ed3\u6784\u5b66\u4e60\u5c42(SLL)\u751f\u6210\u5c5e\u6027\u56fe\u3001\u4ee5\u53ca\u57fa\u4e8eGNN\u7684\u805a\u7c7b\u5206\u914d\u65b9\u6cd5(ASS)\uff0c\u53ef\u5806\u53e0\u4ee5\u6ee1\u8db3\u4e0b\u6e38\u4efb\u52a1\u9700\u6c42\u3002", "result": "DeSE\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u6709\u6548\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "DeSE\u901a\u8fc7\u589e\u5f3a\u56fe\u7ed3\u6784\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u65e0\u76d1\u7763\u56fe\u805a\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.14044", "pdf": "https://arxiv.org/pdf/2505.14044", "abs": "https://arxiv.org/abs/2505.14044", "authors": ["Luyao Tang", "Kunze Huang", "Chaoqi Chen", "Cheng Chen"], "title": "Generalized Category Discovery via Token Manifold Capacity Learning", "categories": ["cs.LG"], "comment": null, "summary": "Generalized category discovery (GCD) is essential for improving deep learning\nmodels' robustness in open-world scenarios by clustering unlabeled data\ncontaining both known and novel categories. Traditional GCD methods focus on\nminimizing intra-cluster variations, often sacrificing manifold capacity, which\nlimits the richness of intra-class representations. In this paper, we propose a\nnovel approach, Maximum Token Manifold Capacity (MTMC), that prioritizes\nmaximizing the manifold capacity of class tokens to preserve the diversity and\ncomplexity of data. MTMC leverages the nuclear norm of singular values as a\nmeasure of manifold capacity, ensuring that the representation of samples\nremains informative and well-structured. This method enhances the\ndiscriminability of clusters, allowing the model to capture detailed semantic\nfeatures and avoid the loss of critical information during clustering. Through\ntheoretical analysis and extensive experiments on coarse- and fine-grained\ndatasets, we demonstrate that MTMC outperforms existing GCD methods, improving\nboth clustering accuracy and the estimation of category numbers. The\nintegration of MTMC leads to more complete representations, better inter-class\nseparability, and a reduction in dimensional collapse, establishing MTMC as a\nvital component for robust open-world learning. Code is in\ngithub.com/lytang63/MTMC.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5MTMC\uff0c\u901a\u8fc7\u6700\u5927\u5316\u7c7b\u6807\u8bb0\u7684\u6d41\u5f62\u5bb9\u91cf\u6765\u63d0\u9ad8\u805a\u7c7b\u51c6\u786e\u6027\u548c\u7c7b\u522b\u6570\u4f30\u8ba1\uff0c\u6539\u5584\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfGCD\u65b9\u6cd5\u5728\u6700\u5c0f\u5316\u7c07\u5185\u53d8\u5316\u7684\u540c\u65f6\u727a\u7272\u4e86\u6d41\u5f62\u5bb9\u91cf\uff0c\u9650\u5236\u4e86\u7c7b\u5185\u8868\u793a\u7684\u4e30\u5bcc\u6027\u3002", "method": "\u63d0\u51fa\u6700\u5927\u4ee4\u724c\u6d41\u5f62\u5bb9\u91cf(MTMC)\uff0c\u5229\u7528\u5947\u5f02\u503c\u7684\u6838\u8303\u6570\u4f5c\u4e3a\u6d41\u5f62\u5bb9\u91cf\u7684\u5ea6\u91cf\uff0c\u786e\u4fdd\u6837\u672c\u8868\u793a\u4fdd\u6301\u4fe1\u606f\u6027\u548c\u826f\u597d\u7ed3\u6784\u3002", "result": "\u5728\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\u4e0a\u7684\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMTMC\u4f18\u4e8e\u73b0\u6709GCD\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u805a\u7c7b\u51c6\u786e\u6027\u548c\u7c7b\u522b\u6570\u4f30\u8ba1\u3002", "conclusion": "MTMC\u53ef\u751f\u6210\u66f4\u5b8c\u6574\u7684\u8868\u793a\uff0c\u589e\u5f3a\u7c7b\u95f4\u53ef\u5206\u6027\uff0c\u51cf\u5c11\u7ef4\u5ea6\u574d\u584c\uff0c\u6210\u4e3a\u7a33\u5065\u5f00\u653e\u4e16\u754c\u5b66\u4e60\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002"}}
{"id": "2505.14071", "pdf": "https://arxiv.org/pdf/2505.14071", "abs": "https://arxiv.org/abs/2505.14071", "authors": ["Woody Haosheng Gan", "Deqing Fu", "Julian Asilis", "Ollie Liu", "Dani Yogatama", "Vatsal Sharan", "Robin Jia", "Willie Neiswanger"], "title": "Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Steering methods have emerged as effective and targeted tools for guiding\nlarge language models' (LLMs) behavior without modifying their parameters.\nMultimodal large language models (MLLMs), however, do not currently enjoy the\nsame suite of techniques, due in part to their recency and architectural\ndiversity. Inspired by this gap, we investigate whether MLLMs can be steered\nusing vectors derived from their text-only LLM backbone, via sparse\nautoencoders (SAEs), mean shift, and linear probing. We find that text-derived\nsteering consistently enhances multimodal accuracy across diverse MLLM\narchitectures and visual tasks. In particular, mean shift boosts spatial\nrelationship accuracy on CV-Bench by up to +7.3% and counting accuracy by up to\n+3.3%, outperforming prompting and exhibiting strong generalization to\nout-of-distribution datasets. These results highlight textual steering vectors\nas a powerful, efficient mechanism for enhancing grounding in MLLMs with\nminimal additional data collection and computational overhead.", "AI": {"tldr": "\u6587\u672c\u884d\u751f\u7684\u5f15\u5bfc\u5411\u91cf\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u67b6\u6784\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u76ee\u524d\u9488\u5bf9\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f15\u5bfc\u65b9\u6cd5\u8f83\u5c11\uff0c\u4e14\u7f3a\u4e4f\u4e00\u81f4\u6027\u6280\u672f\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668(SAEs)\uff0c\u5747\u503c\u6f02\u79fb\u548c\u7ebf\u6027\u63a2\u6d4b\u4ece\u4ec5\u6587\u672c\u7684LLM\u9aa8\u5e72\u4e2d\u5bfc\u51fa\u5411\u91cf\u6765\u5f15\u5bfc\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6587\u672c\u884d\u751f\u7684\u5f15\u5bfc\u5411\u91cf\u63d0\u5347\u4e86\u591a\u6a21\u6001\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728CV-Bench\u4e0a\u7684\u7a7a\u95f4\u5173\u7cfb\u51c6\u786e\u6027\u548c\u8ba1\u6570\u51c6\u786e\u6027\u3002", "conclusion": "\u6587\u672c\u884d\u751f\u7684\u5f15\u5bfc\u5411\u91cf\u662f\u4e00\u79cd\u5f3a\u5927\u800c\u9ad8\u6548\u7684\u673a\u5236\uff0c\u80fd\u591f\u589e\u5f3a\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9a\u4f4d\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u989d\u5916\u7684\u6570\u636e\u6536\u96c6\u548c\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2505.14117", "pdf": "https://arxiv.org/pdf/2505.14117", "abs": "https://arxiv.org/abs/2505.14117", "authors": ["Xinyi Shang", "Peng Sun", "Fengyuan Liu", "Tao Lin"], "title": "Collaborative Unlabeled Data Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper pioneers a novel data-centric paradigm to maximize the utility of\nunlabeled data, tackling a critical question: How can we enhance the efficiency\nand sustainability of deep learning training by optimizing the data itself? We\nbegin by identifying three key limitations in existing model-centric\napproaches, all rooted in a shared bottleneck: knowledge extracted from data is\nlocked to model parameters, hindering its reusability and scalability. To this\nend, we propose CoOpt, a highly efficient, parallelized framework for\ncollaborative unlabeled data optimization, thereby effectively encoding\nknowledge into the data itself. By distributing unlabeled data and leveraging\npublicly available task-agnostic models, CoOpt facilitates scalable, reusable,\nand sustainable training pipelines. Extensive experiments across diverse\ndatasets and architectures demonstrate its efficacy and efficiency, achieving\n13.6% and 6.8% improvements on Tiny-ImageNet and ImageNet-1K, respectively,\nwith training speedups of $1.94 \\times $ and $1.2 \\times$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5CoOpt\u6765\u4f18\u5316\u672a\u6807\u8bb0\u7684\u6570\u636e\uff0c\u4ee5\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u53d1\u672a\u6807\u8bb0\u7684\u6570\u636e\u5e76\u5229\u7528\u516c\u5171\u4efb\u52a1\u4e0d\u53ef\u77e5\u6a21\u578b\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u7528\u548c\u53ef\u6301\u7eed\u7684\u8bad\u7ec3\u7ba1\u9053\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCoOpt\u5728Tiny-ImageNet\u548cImageNet-1K\u4e0a\u5206\u522b\u63d0\u9ad8\u4e8613.6%\u548c6.8%\uff0c\u5e76\u4e14\u8bad\u7ec3\u901f\u5ea6\u5206\u522b\u63d0\u5347\u4e861.94\u500d\u548c1.2\u500d\u3002", "motivation": "\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u6570\u636e\u672c\u8eab\u6765\u589e\u5f3a\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\uff1f", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCoOpt\u7684\u9ad8\u5ea6\u6709\u6548\u7684\u5e76\u884c\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u4f5c\u672a\u6807\u8bb0\u6570\u636e\u4f18\u5316\uff0c\u5e76\u5c06\u77e5\u8bc6\u6709\u6548\u7f16\u7801\u5230\u6570\u636e\u672c\u8eab\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u5206\u522b\u5728Tiny-ImageNet\u548cImageNet-1K\u4e0a\u5b9e\u73b0\u4e8613.6%\u548c6.8%\u7684\u6539\u8fdb\uff0c\u8bad\u7ec3\u901f\u5ea6\u5206\u522b\u63d0\u5347\u4e861.94\u500d\u548c1.2\u500d\u3002", "conclusion": "CoOpt\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u6765\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u4e2d\u5fc3\u65b9\u6cd5\u7684\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u7f16\u7801\u5230\u6570\u636e\u672c\u8eab\u4e2d\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u7684\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u3002"}}
{"id": "2505.14122", "pdf": "https://arxiv.org/pdf/2505.14122", "abs": "https://arxiv.org/abs/2505.14122", "authors": ["Ehsan Masoudian", "Ali Mirzaei", "Hossein Bagheri"], "title": "Assessing wildfire susceptibility in Iran: Leveraging machine learning for geospatial analysis of climatic and anthropogenic factors", "categories": ["cs.LG"], "comment": null, "summary": "This study investigates the multifaceted factors influencing wildfire risk in\nIran, focusing on the interplay between climatic conditions and human\nactivities. Utilizing advanced remote sensing, geospatial information system\n(GIS) processing techniques such as cloud computing, and machine learning\nalgorithms, this research analyzed the impact of climatic parameters,\ntopographic features, and human-related factors on wildfire susceptibility\nassessment and prediction in Iran. Multiple scenarios were developed for this\npurpose based on the data sampling strategy. The findings revealed that\nclimatic elements such as soil moisture, temperature, and humidity\nsignificantly contribute to wildfire susceptibility, while human\nactivities-particularly population density and proximity to powerlines-also\nplayed a crucial role. Furthermore, the seasonal impact of each parameter was\nseparately assessed during warm and cold seasons. The results indicated that\nhuman-related factors, rather than climatic variables, had a more prominent\ninfluence during the seasonal analyses. This research provided new insights\ninto wildfire dynamics in Iran by generating high-resolution wildfire\nsusceptibility maps using advanced machine learning classifiers. The generated\nmaps identified high risk areas, particularly in the central Zagros region, the\nnortheastern Hyrcanian Forest, and the northern Arasbaran forest, highlighting\nthe urgent need for effective fire management strategies.", "AI": {"tldr": "This study examines the factors affecting wildfire risk in Iran, including climatic conditions and human activities, using remote sensing and GIS techniques.", "motivation": "To investigate the factors influencing wildfire risk in Iran.", "method": "Advanced remote sensing, GIS processing techniques, and machine learning algorithms were used to analyze the impact of climatic parameters, topographic features, and human-related factors on wildfire susceptibility assessment and prediction.", "result": "The findings showed that climatic elements significantly contribute to wildfire susceptibility, but human activities play a crucial role. Human-related factors had a more prominent influence during seasonal analyses. High-resolution wildfire susceptibility maps were generated.", "conclusion": "This research provides new insights into wildfire dynamics in Iran and highlights the urgent need for effective fire management strategies."}}
{"id": "2505.14125", "pdf": "https://arxiv.org/pdf/2505.14125", "abs": "https://arxiv.org/abs/2505.14125", "authors": ["Viet Anh Khoa Tran", "Emre Neftci", "Willem. A. M. Wybo"], "title": "Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05 (primary), 68T07, 68T45 (secondary)", "I.2.6; I.2.10"], "comment": "33 pages, 5 figures", "summary": "Biological brains learn continually from a stream of unlabeled data, while\nintegrating specialized information from sparsely labeled examples without\ncompromising their ability to generalize. Meanwhile, machine learning methods\nare susceptible to catastrophic forgetting in this natural learning setting, as\nsupervised specialist fine-tuning degrades performance on the original task. We\nintroduce task-modulated contrastive learning (TMCL), which takes inspiration\nfrom the biophysical machinery in the neocortex, using predictive coding\nprinciples to integrate top-down information continually and without\nsupervision. We follow the idea that these principles build a view-invariant\nrepresentation space, and that this can be implemented using a contrastive\nloss. Then, whenever labeled samples of a new class occur, new affine\nmodulations are learned that improve separation of the new class from all\nothers, without affecting feedforward weights. By co-opting the view-invariance\nlearning mechanism, we then train feedforward weights to match the unmodulated\nrepresentation of a data sample to its modulated counterparts. This introduces\nmodulation invariance into the representation space, and, by also using past\nmodulations, stabilizes it. Our experiments show improvements in both\nclass-incremental and transfer learning over state-of-the-art unsupervised\napproaches, as well as over comparable supervised approaches, using as few as\n1% of available labels. Taken together, our work suggests that top-down\nmodulations play a crucial role in balancing stability and plasticity.", "AI": {"tldr": "Introduces Task-Modulated Contrastive Learning (TMCL) inspired by predictive coding principles to address catastrophic forgetting in continual learning.", "motivation": "To overcome catastrophic forgetting in machine learning when learning from a stream of unlabeled data.", "method": "Uses contrastive learning with top-down information modulation to create view-invariant representation spaces.", "result": "Improves performance in class-incremental and transfer learning tasks compared to other approaches.", "conclusion": "Top-down modulations are crucial for balancing stability and plasticity in continual learning."}}
{"id": "2505.14126", "pdf": "https://arxiv.org/pdf/2505.14126", "abs": "https://arxiv.org/abs/2505.14126", "authors": ["Yuan-Hao Jiang", "Kezong Tang", "Zi-Wei Chen", "Yuang Wei", "Tian-Yi Liu", "Jiayi Wu"], "title": "MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow", "categories": ["cs.LG", "cs.CY", "cs.HC", "cs.MA"], "comment": "In CGI 2025: 42nd Computer Graphics International Conference,\n  Kowloon, Hong Kong, Peper No. 134", "summary": "Knowledge components (KCs) are the fundamental units of knowledge in the\nfield of education. A KC graph illustrates the relationships and dependencies\nbetween KCs. An accurate KC graph can assist educators in identifying the root\ncauses of learners' poor performance on specific KCs, thereby enabling targeted\ninstructional interventions. To achieve this, we have developed a KC graph\nstructure learning algorithm, named MAS-KCL, which employs a multi-agent system\ndriven by large language models for adaptive modification and optimization of\nthe KC graph. Additionally, a bidirectional feedback mechanism is integrated\ninto the algorithm, where AI agents leverage this mechanism to assess the value\nof edges within the KC graph and adjust the distribution of generation\nprobabilities for different edges, thereby accelerating the efficiency of\nstructure learning. We applied the proposed algorithm to 5 synthetic datasets\nand 4 real-world educational datasets, and experimental results validate its\neffectiveness in learning path recognition. By accurately identifying learners'\nlearning paths, teachers are able to design more comprehensive learning plans,\nenabling learners to achieve their educational goals more effectively, thus\npromoting the sustainable development of education.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u7ec4\u4ef6\u56fe\u7ed3\u6784\u5b66\u4e60\u7b97\u6cd5(MAS-KCL)\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u8bc6\u522b\u5b66\u4e60\u8def\u5f84\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u51c6\u786e\u7684\u77e5\u8bc6\u7ec4\u4ef6\u56fe\u53ef\u4ee5\u5e2e\u52a9\u6559\u80b2\u8005\u53d1\u73b0\u5b66\u4e60\u8005\u5728\u7279\u5b9a\u77e5\u8bc6\u7ec4\u4ef6\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u6839\u672c\u539f\u56e0\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u9488\u5bf9\u6027\u7684\u6559\u5b66\u5e72\u9884\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aMAS-KCL\u7684\u77e5\u8bc6\u7ec4\u4ef6\u56fe\u7ed3\u6784\u5b66\u4e60\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fdb\u884c\u81ea\u9002\u5e94\u4fee\u6539\u548c\u4f18\u5316\uff0c\u5e76\u6574\u5408\u4e86\u53cc\u5411\u53cd\u9988\u673a\u5236\u6765\u8bc4\u4f30\u8fb9\u503c\u5e76\u8c03\u6574\u751f\u6210\u6982\u7387\u5206\u5e03\u3002", "result": "\u7b97\u6cd5\u57285\u4e2a\u5408\u6210\u6570\u636e\u96c6\u548c4\u4e2a\u771f\u5b9e\u6559\u80b2\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b66\u4e60\u8def\u5f84\u8bc6\u522b\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u51c6\u786e\u8bc6\u522b\u5b66\u4e60\u8005\u7684\u8def\u5f84\uff0c\u6559\u5e08\u53ef\u4ee5\u8bbe\u8ba1\u66f4\u5168\u9762\u7684\u5b66\u4e60\u8ba1\u5212\uff0c\u5e2e\u52a9\u5b66\u4e60\u8005\u66f4\u6709\u6548\u5730\u8fbe\u6210\u6559\u80b2\u76ee\u6807\uff0c\u63a8\u52a8\u6559\u80b2\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002"}}
{"id": "2505.14128", "pdf": "https://arxiv.org/pdf/2505.14128", "abs": "https://arxiv.org/abs/2505.14128", "authors": ["Yihang Du", "Jiaying Hu", "Suyang Hou", "Yueyang Ding", "Xiaobo Sun"], "title": "A Methodological Framework for Measuring Spatial Labeling Similarity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Spatial labeling assigns labels to specific spatial locations to characterize\ntheir spatial properties and relationships, with broad applications in\nscientific research and practice. Measuring the similarity between two spatial\nlabelings is essential for understanding their differences and the contributing\nfactors, such as changes in location properties or labeling methods. An\nadequate and unbiased measurement of spatial labeling similarity should\nconsider the number of matched labels (label agreement), the topology of\nspatial label distribution, and the heterogeneous impacts of mismatched labels.\nHowever, existing methods often fail to account for all these aspects. To\naddress this gap, we propose a methodological framework to guide the\ndevelopment of methods that meet these requirements. Given two spatial\nlabelings, the framework transforms them into graphs based on location\norganization, labels, and attributes (e.g., location significance). The\ndistributions of their graph attributes are then extracted, enabling an\nefficient computation of distributional discrepancy to reflect the\ndissimilarity level between the two labelings. We further provide a concrete\nimplementation of this framework, termed Spatial Labeling Analogy Metric\n(SLAM), along with an analysis of its theoretical foundation, for evaluating\nspatial labeling results in spatial transcriptomics (ST) \\textit{as per} their\nsimilarity with ground truth labeling. Through a series of carefully designed\nexperimental cases involving both simulated and real ST data, we demonstrate\nthat SLAM provides a comprehensive and accurate reflection of labeling quality\ncompared to other well-established evaluation metrics. Our code is available at\nhttps://github.com/YihDu/SLAM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a7a\u95f4\u6807\u8bb0\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff08SLAM\uff09\uff0c\u8be5\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u53cd\u6620\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u4e2d\u6807\u8bb0\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u7a7a\u95f4\u6807\u8bb0\u76f8\u4f3c\u6027\u6d4b\u91cf\u4e2d\u7684\u591a\u4e2a\u91cd\u8981\u65b9\u9762\u3002", "method": "\u57fa\u4e8e\u4f4d\u7f6e\u7ec4\u7ec7\u3001\u6807\u7b7e\u548c\u5c5e\u6027\u5c06\u4e24\u4e2a\u7a7a\u95f4\u6807\u8bb0\u8f6c\u6362\u4e3a\u56fe\uff0c\u5e76\u63d0\u53d6\u56fe\u5c5e\u6027\u5206\u5e03\u4ee5\u8ba1\u7b97\u5206\u5e03\u5dee\u5f02\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u7684\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SLAM\u7684\u6709\u6548\u6027\u3002", "conclusion": "SLAM\u63d0\u4f9b\u4e86\u6bd4\u5176\u4ed6\u5df2\u5efa\u7acb\u7684\u8bc4\u4f30\u6307\u6807\u66f4\u5168\u9762\u548c\u51c6\u786e\u7684\u7a7a\u95f4\u6807\u8bb0\u8d28\u91cf\u8bc4\u4f30\u3002"}}
{"id": "2505.14136", "pdf": "https://arxiv.org/pdf/2505.14136", "abs": "https://arxiv.org/abs/2505.14136", "authors": ["Ryo Bertolissi", "Jonas H\u00fcbotter", "Ido Hakimi", "Andreas Krause"], "title": "Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture of expert (MoE) models are a promising approach to increasing model\ncapacity without increasing inference cost, and are core components of many\nstate-of-the-art language models. However, current MoE models typically use\nonly few experts due to prohibitive training and inference cost. We propose\nTest-Time Model Merging (TTMM) which scales the MoE paradigm to an order of\nmagnitude more experts and uses model merging to avoid almost any test-time\noverhead. We show that TTMM is an approximation of test-time training (TTT),\nwhich fine-tunes an expert model for each prediction task, i.e., prompt. TTT\nhas recently been shown to significantly improve language models, but is\ncomputationally expensive. We find that performance of TTMM improves with more\nexperts and approaches the performance of TTT. Moreover, we find that with a 1B\nparameter base model, TTMM is more than 100x faster than TTT at test-time by\namortizing the cost of TTT at train-time. Thus, TTMM offers a promising\ncost-effective approach to scale test-time training.", "AI": {"tldr": "Test-Time Model Merging (TTMM) is proposed to scale Mixture of Expert (MoE) models to more experts and avoid test-time overhead.", "motivation": "To increase model capacity without increasing inference cost.", "method": "TTMM scales MoE and uses model merging.", "result": "Performance improves with more experts and approaches TTT's performance.", "conclusion": "TTMM offers a cost-effective way to scale test-time training."}}
{"id": "2505.14139", "pdf": "https://arxiv.org/pdf/2505.14139", "abs": "https://arxiv.org/abs/2505.14139", "authors": ["Marvin Alles", "Nutan Chen", "Patrick van der Smagt", "Botond Cseke"], "title": "FlowQ: Energy-Guided Flow Policies for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "The use of guidance to steer sampling toward desired outcomes has been widely\nexplored within diffusion models, especially in applications such as image and\ntrajectory generation. However, incorporating guidance during training remains\nrelatively underexplored. In this work, we introduce energy-guided flow\nmatching, a novel approach that enhances the training of flow models and\neliminates the need for guidance at inference time. We learn a conditional\nvelocity field corresponding to the flow policy by approximating an\nenergy-guided probability path as a Gaussian path. Learning guided trajectories\nis appealing for tasks where the target distribution is defined by a\ncombination of data and an energy function, as in reinforcement learning.\nDiffusion-based policies have recently attracted attention for their expressive\npower and ability to capture multi-modal action distributions. Typically, these\npolicies are optimized using weighted objectives or by back-propagating\ngradients through actions sampled by the policy. As an alternative, we propose\nFlowQ, an offline reinforcement learning algorithm based on energy-guided flow\nmatching. Our method achieves competitive performance while the policy training\ntime is constant in the number of flow sampling steps.", "AI": {"tldr": "This paper introduces energy-guided flow matching, a new method that improves training of flow models and shows competitive results in offline reinforcement learning without needing guidance at inference time.", "motivation": "To incorporate guidance during training in diffusion models, which remains relatively underexplored.", "method": "Energy-guided flow matching, which learns a conditional velocity field corresponding to the flow policy by approximating an energy-guided probability path as a Gaussian path.", "result": "Our method achieves competitive performance while the policy training time is constant in the number of flow sampling steps.", "conclusion": "This work introduces energy-guided flow matching, which enhances the training of flow models and eliminates the need for guidance at inference time."}}
{"id": "2505.14161", "pdf": "https://arxiv.org/pdf/2505.14161", "abs": "https://arxiv.org/abs/2505.14161", "authors": ["Ting Wei", "Biao Mei", "Junliang Lyu", "Renquan Zhang", "Feng Zhou", "Yifan Sun"], "title": "Personalized Bayesian Federated Learning with Wasserstein Barycenter Aggregation", "categories": ["cs.LG"], "comment": null, "summary": "Personalized Bayesian federated learning (PBFL) handles non-i.i.d. client\ndata and quantifies uncertainty by combining personalization with Bayesian\ninference. However, existing PBFL methods face two limitations: restrictive\nparametric assumptions in client posterior inference and naive parameter\naveraging for server aggregation. To overcome these issues, we propose FedWBA,\na novel PBFL method that enhances both local inference and global aggregation.\nAt the client level, we use particle-based variational inference for\nnonparametric posterior representation. At the server level, we introduce\nparticle-based Wasserstein barycenter aggregation, offering a more\ngeometrically meaningful approach. Theoretically, we provide local and global\nconvergence guarantees for FedWBA. Locally, we prove a KL divergence decrease\nlower bound per iteration for variational inference convergence. Globally, we\nshow that the Wasserstein barycenter converges to the true parameter as the\nclient data size increases. Empirically, experiments show that FedWBA\noutperforms baselines in prediction accuracy, uncertainty calibration, and\nconvergence rate, with ablation studies confirming its robustness.", "AI": {"tldr": "\u63d0\u51faFedWBA\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u4e2a\u6027\u5316\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60(PBFL)\u5728\u5ba2\u6237\u7aef\u540e\u9a8c\u63a8\u7406\u4e2d\u7684\u9650\u5236\u6027\u53c2\u6570\u5047\u8bbe\u548c\u670d\u52a1\u5668\u805a\u5408\u4e2d\u7684\u7b80\u5355\u53c2\u6570\u5e73\u5747\u95ee\u9898\u3002\u7406\u8bba\u4e0a\u6709\u5c40\u90e8\u548c\u5168\u5c40\u6536\u655b\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u8868\u660eFedWBA\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709PBFL\u65b9\u6cd5\u5b58\u5728\u9650\u5236\u6027\u53c2\u6570\u5047\u8bbe\u548c\u7b80\u5355\u53c2\u6570\u5e73\u5747\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51faFedWBA\u65b9\u6cd5\uff0c\u5305\u62ec\u5ba2\u6237\u7aef\u4f7f\u7528\u7c92\u5b50\u53d8\u5206\u63a8\u7406\u8fdb\u884c\u975e\u53c2\u6570\u540e\u9a8c\u8868\u793a\uff0c\u5728\u670d\u52a1\u5668\u7aef\u5f15\u5165\u57fa\u4e8e\u7c92\u5b50\u7684Wasserstein\u91cd\u5fc3\u805a\u5408\u3002", "result": "FedWBA\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u4e14\u6709\u5c40\u90e8\u548c\u5168\u5c40\u6536\u655b\u4fdd\u8bc1\u3002", "conclusion": "FedWBA\u901a\u8fc7\u589e\u5f3a\u5c40\u90e8\u63a8\u7406\u548c\u5168\u5c40\u805a\u5408\u514b\u670d\u4e86\u73b0\u6709PBFL\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2505.14170", "pdf": "https://arxiv.org/pdf/2505.14170", "abs": "https://arxiv.org/abs/2505.14170", "authors": ["Chen Zhang", "Weixin Bu", "Zeyi Ren", "Zhengwu Liu", "Yik-Chung Wu", "Ngai Wong"], "title": "Nonparametric Teaching for Graph Property Learners", "categories": ["cs.LG"], "comment": "ICML 2025 Spotlight (25 pages, 17 figures)", "summary": "Inferring properties of graph-structured data, e.g., the solubility of\nmolecules, essentially involves learning the implicit mapping from graphs to\ntheir properties. This learning process is often costly for graph property\nlearners like Graph Convolutional Networks (GCNs). To address this, we propose\na paradigm called Graph Neural Teaching (GraNT) that reinterprets the learning\nprocess through a novel nonparametric teaching perspective. Specifically, the\nlatter offers a theoretical framework for teaching implicitly defined (i.e.,\nnonparametric) mappings via example selection. Such an implicit mapping is\nrealized by a dense set of graph-property pairs, with the GraNT teacher\nselecting a subset of them to promote faster convergence in GCN training. By\nanalytically examining the impact of graph structure on parameter-based\ngradient descent during training, and recasting the evolution of GCNs--shaped\nby parameter updates--through functional gradient descent in nonparametric\nteaching, we show for the first time that teaching graph property learners\n(i.e., GCNs) is consistent with teaching structure-aware nonparametric\nlearners. These new findings readily commit GraNT to enhancing learning\nefficiency of the graph property learner, showing significant reductions in\ntraining time for graph-level regression (-36.62%), graph-level classification\n(-38.19%), node-level regression (-30.97%) and node-level classification\n(-47.30%), all while maintaining its generalization performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraph Neural Teaching (GraNT)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u56fe-\u5c5e\u6027\u5bf9\u7684\u5b50\u96c6\u6765\u52a0\u901f\u56fe\u6027\u8d28\u5b66\u4e60\u8005\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGraNT\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\uff0c\u5e76\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u56fe\u6027\u8d28\u5b66\u4e60\u8005\u5982\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCNs\uff09\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6210\u672c\u9ad8\u6602\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86GraNT\u65b9\u6cd5\uff0c\u91cd\u65b0\u89e3\u91ca\u4e86\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u975e\u53c2\u6570\u6559\u5b66\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u793a\u4f8b\u9009\u62e9\u6765\u6559\u6388\u9690\u5f0f\u5b9a\u4e49\u7684\u6620\u5c04\u3002", "result": "GraNT\u5728\u56db\u79cd\u4e0d\u540c\u7684\u56fe\u548c\u8282\u70b9\u7ea7\u522b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u3002", "conclusion": "\u9996\u6b21\u8bc1\u660e\u4e86\u6559\u6388\u56fe\u6027\u8d28\u5b66\u4e60\u8005\u4e0e\u6559\u6388\u7ed3\u6784\u611f\u77e5\u7684\u975e\u53c2\u6570\u5b66\u4e60\u8005\u662f\u4e00\u81f4\u7684\uff0c\u8fd9\u4e3a\u63d0\u9ad8\u56fe\u6027\u8d28\u5b66\u4e60\u8005\u7684\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2505.14185", "pdf": "https://arxiv.org/pdf/2505.14185", "abs": "https://arxiv.org/abs/2505.14185", "authors": ["Kaustubh Ponkshe", "Shaan Shah", "Raghav Singhal", "Praneeth Vepakomma"], "title": "Safety Subspaces are Not Distinct: A Fine-Tuning Case Study", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Kaustubh Ponkshe, Shaan Shah, and Raghav Singhal contributed equally\n  to this work", "summary": "Large Language Models (LLMs) rely on safety alignment to produce socially\nacceptable responses. This is typically achieved through instruction tuning and\nreinforcement learning from human feedback. However, this alignment is known to\nbe brittle: further fine-tuning, even on benign or lightly contaminated data,\ncan degrade safety and reintroduce harmful behaviors. A growing body of work\nsuggests that alignment may correspond to identifiable geometric directions in\nweight space, forming subspaces that could, in principle, be isolated or\npreserved to defend against misalignment. In this work, we conduct a\ncomprehensive empirical study of this geometric perspective. We examine whether\nsafety-relevant behavior is concentrated in specific subspaces, whether it can\nbe separated from general-purpose learning, and whether harmfulness arises from\ndistinguishable patterns in internal representations. Across both parameter and\nactivation space, our findings are consistent: subspaces that amplify safe\nbehaviors also amplify unsafe ones, and prompts with different safety\nimplications activate overlapping representations. We find no evidence of a\nsubspace that selectively governs safety. These results challenge the\nassumption that alignment is geometrically localized. Rather than residing in\ndistinct directions, safety appears to emerge from entangled, high-impact\ncomponents of the model's broader learning dynamics. This suggests that\nsubspace-based defenses may face fundamental limitations and underscores the\nneed for alternative strategies to preserve alignment under continued training.\nWe corroborate these findings through multiple experiments on five open-source\nLLMs. Our code is publicly available at:\nhttps://github.com/CERT-Lab/safety-subspaces.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u4e0d\u662f\u51e0\u4f55\u5c40\u90e8\u5316\u7684\uff0c\u800c\u662f\u6765\u81ea\u6a21\u578b\u66f4\u5e7f\u6cdb\u5b66\u4e60\u52a8\u6001\u7684\u7ea0\u7f20\u3001\u9ad8\u5f71\u54cd\u529b\u7ec4\u4ef6\uff0c\u8fd9\u6311\u6218\u4e86\u57fa\u4e8e\u5b50\u7a7a\u95f4\u7684\u9632\u5fa1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5728\u8fdb\u4e00\u6b65\u5fae\u8c03\u65f6\u5bb9\u6613\u9000\u5316\u5e76\u91cd\u65b0\u5f15\u5165\u6709\u5bb3\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u65b0\u7684\u7b56\u7565\u6765\u7ef4\u6301\u5bf9\u9f50\u3002", "method": "\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7ecf\u9a8c\u7814\u7a76\uff0c\u5305\u62ec\u68c0\u67e5\u7279\u5b9a\u5b50\u7a7a\u95f4\u662f\u5426\u96c6\u4e2d\u4e86\u5b89\u5168\u76f8\u5173\u884c\u4e3a\uff0c\u8fd9\u4e9b\u884c\u4e3a\u662f\u5426\u53ef\u4ee5\u4e0e\u901a\u7528\u5b66\u4e60\u5206\u79bb\uff0c\u4ee5\u53ca\u6709\u5bb3\u6027\u662f\u5426\u6e90\u4e8e\u5185\u90e8\u8868\u793a\u4e2d\u7684\u53ef\u533a\u5206\u6a21\u5f0f\u3002", "result": "\u5728\u53c2\u6570\u548c\u6fc0\u6d3b\u7a7a\u95f4\u4e0a\uff0c\u653e\u5927\u5b89\u5168\u884c\u4e3a\u7684\u5b50\u7a7a\u95f4\u4e5f\u4f1a\u653e\u5927\u4e0d\u5b89\u5168\u884c\u4e3a\uff1b\u5177\u6709\u4e0d\u540c\u5b89\u5168\u542b\u4e49\u7684\u63d0\u793a\u4f1a\u6fc0\u6d3b\u91cd\u53e0\u7684\u8868\u793a\uff1b\u672a\u53d1\u73b0\u4e13\u95e8\u63a7\u5236\u5b89\u5168\u6027\u7684\u5b50\u7a7a\u95f4\u3002", "conclusion": "\u5b89\u5168\u5bf9\u9f50\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u5bb9\u6613\u56e0\u8fdb\u4e00\u6b65\u5fae\u8c03\u800c\u9000\u5316\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5b89\u5168\u76f8\u5173\u7684\u51e0\u4f55\u5b50\u7a7a\u95f4\u5e76\u4e0d\u80fd\u6709\u6548\u9694\u79bb\u6709\u5bb3\u884c\u4e3a\uff0c\u8fd9\u8868\u660e\u57fa\u4e8e\u5b50\u7a7a\u95f4\u7684\u9632\u5fa1\u53ef\u80fd\u6709\u6839\u672c\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u5176\u4ed6\u7b56\u7565\u4ee5\u5728\u6301\u7eed\u8bad\u7ec3\u4e2d\u4fdd\u6301\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.14190", "pdf": "https://arxiv.org/pdf/2505.14190", "abs": "https://arxiv.org/abs/2505.14190", "authors": ["Ni Ding", "Miao Qiao", "Jiaxing Xu", "Yiping Ke", "Xiaoyu Zhang"], "title": "$\u03b1$-GAN by R\u00e9nyi Cross Entropy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes $\\alpha$-GAN, a generative adversarial network using\nR\\'{e}nyi measures. The value function is formulated, by R\\'{e}nyi cross\nentropy, as an expected certainty measure incurred by the discriminator's soft\ndecision as to where the sample is from, true population or the generator. The\ndiscriminator tries to maximize the R\\'{e}nyi certainty about sample source,\nwhile the generator wants to reduce it by injecting fake samples. This forms a\nmin-max problem with the solution parameterized by the R\\'{e}nyi order\n$\\alpha$. This $\\alpha$-GAN reduces to vanilla GAN at $\\alpha = 1$, where the\nvalue function is exactly the binary cross entropy. The optimization of\n$\\alpha$-GAN is over probability (vector) space. It is shown that the gradient\nis exponentially enlarged when R\\'{e}nyi order is in the range $\\alpha \\in\n(0,1)$. This makes convergence faster, which is verified by experimental\nresults. A discussion shows that choosing $\\alpha \\in (0,1)$ may be able to\nsolve some common problems, e.g., vanishing gradient. A following observation\nreveals that this range has not been fully explored in the existing R\\'{e}nyi\nversion GANs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eR\u00e9nyi\u71b5\u7684\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u03b1-GAN\uff0c\u5176\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u8c03\u6574R\u00e9nyi\u9636\u6570\u03b1\uff0c\u53ef\u4ee5\u52a0\u901f\u6536\u655b\u5e76\u53ef\u80fd\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709GAN\u6a21\u578b\u5b58\u5728\u4e00\u4e9b\u95ee\u9898\uff0c\u5982\u68af\u5ea6\u6d88\u5931\u7b49\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165R\u00e9nyi\u71b5\u6784\u5efa\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2amin-max\u4f18\u5316\u95ee\u9898\uff0c\u5176\u89e3\u7531R\u00e9nyi\u9636\u6570\u03b1\u53c2\u6570\u5316\u3002", "result": "\u03b1-GAN\u5728\u03b1\u2208(0,1)\u8303\u56f4\u5185\u65f6\uff0c\u68af\u5ea6\u4f1a\u6307\u6570\u7ea7\u589e\u5927\uff0c\u4ece\u800c\u52a0\u901f\u6536\u655b\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7ed3\u8bba\u3002", "conclusion": "\u03b1-GAN\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u6709\u6548\u6539\u5584GAN\u7684\u8bad\u7ec3\u6548\u679c\uff0c\u4f46\u73b0\u6709\u7684R\u00e9nyi\u7248\u672cGAN\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u8fd9\u4e2a\u8303\u56f4\u3002"}}
{"id": "2505.14201", "pdf": "https://arxiv.org/pdf/2505.14201", "abs": "https://arxiv.org/abs/2505.14201", "authors": ["Kosmas Alexandridis", "Vasileios Titopoulos", "Giorgos Dimitrakopoulos"], "title": "FLASH-D: FlashAttention with Hidden Softmax Division", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "IEEE/ACM International Symposium on Low Power Electronics and Design\n  (ISLPED) 2025", "summary": "The transformer's attention mechanism has revolutionized AI and machine\nlearning, with its efficient computation being crucial to its performance.\nHowever, calculating attention involves matrix operations interspersed with\nsoftmax rescaling, which inherently slows down computation and requires\nprocessing the entire input sequence. Building on online softmax computation,\nFlashAttention integrates softmax calculation with matrix arithmetic, enabling\ntiled computation independent of sequence length. While optimized for GPUs,\nFlashAttention's simplicity makes it amenable to direct hardware acceleration.\nThis work re-evaluates the core FlashAttention kernel, presenting FLASH-D a\nmathematically equivalent, yet simplified, formulation that achieves: (a)\nhiding softmax division within other non-linear function evaluations; (b)\ninherently numerically stable computation of exponentials, eliminating the need\nfor maximum value subtraction; and (c) a reduction in computational cost\nwithout introducing numerical approximations to the FlashAttention kernel.\nImportantly, the essential FlashAttention properties that facilitate efficient\ntiled implementation are fully preserved. Hardware implementation results at\n28nm demonstrate that this proposed formulation achieves a 22.8% reduction in\narea and a 20.3% reduction in power, on average, compared to state-of-the-art\nparallel hardware architectures without any performance penalty.", "AI": {"tldr": "FlashAttention\u4f18\u5316\u4e86Transformer\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7b80\u5316\u6838\u5fc3\u8ba1\u7b97\u5185\u6838FLASH-D\uff0c\u5728\u4fdd\u6301\u539f\u6709\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u786c\u4ef6\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u63d0\u9ad8Transformer\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u6548\u7387\u5e76\u51cf\u5c11\u5bf9\u786c\u4ef6\u8d44\u6e90\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u65b9\u6cd5FLASH-D\uff0c\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u539f\u59cbFlashAttention\u7684\u6838\u5fc3\u5185\u6838\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u5e76\u884c\u786c\u4ef6\u67b6\u6784\u76f8\u6bd4\uff0c\u786c\u4ef6\u5b9e\u73b0\u7ed3\u679c\u663e\u793a\uff0c\u9762\u79ef\u51cf\u5c11\u4e8622.8%\uff0c\u529f\u8017\u51cf\u5c11\u4e8620.3%\uff0c\u4e14\u6ca1\u6709\u6027\u80fd\u635f\u5931\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u8ba1\u7b97\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2505.14202", "pdf": "https://arxiv.org/pdf/2505.14202", "abs": "https://arxiv.org/abs/2505.14202", "authors": ["Zhicheng Chen", "Shibo Feng", "Xi Xiao", "Zhong Zhang", "Qing Li", "Xingyu Gao", "Peilin Zhao"], "title": "MSDformer: Multi-scale Discrete Transformer For Time Series Generation", "categories": ["cs.LG"], "comment": null, "summary": "Discrete Token Modeling (DTM), which employs vector quantization techniques,\nhas demonstrated remarkable success in modeling non-natural language\nmodalities, particularly in time series generation. While our prior work\nSDformer established the first DTM-based framework to achieve state-of-the-art\nperformance in this domain, two critical limitations persist in existing DTM\napproaches: 1) their inability to capture multi-scale temporal patterns\ninherent to complex time series data, and 2) the absence of theoretical\nfoundations to guide model optimization. To address these challenges, we\nproposes a novel multi-scale DTM-based time series generation method, called\nMulti-Scale Discrete Transformer (MSDformer). MSDformer employs a multi-scale\ntime series tokenizer to learn discrete token representations at multiple\nscales, which jointly characterize the complex nature of time series data.\nSubsequently, MSDformer applies a multi-scale autoregressive token modeling\ntechnique to capture the multi-scale patterns of time series within the\ndiscrete latent space. Theoretically, we validate the effectiveness of the DTM\nmethod and the rationality of MSDformer through the rate-distortion theorem.\nComprehensive experiments demonstrate that MSDformer significantly outperforms\nstate-of-the-art methods. Both theoretical analysis and experimental results\ndemonstrate that incorporating multi-scale information and modeling multi-scale\npatterns can substantially enhance the quality of generated time series in\nDTM-based approaches. The code will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u591a\u5c3a\u5ea6\u79bb\u6563\u53d8\u6362\u5668(MSDformer)\u7684\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u79bb\u6563\u6807\u8bb0\u5efa\u6a21(DTM)\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\u4ee5\u53ca\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u6307\u5bfc\u6a21\u578b\u4f18\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709DTM\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u65e0\u6cd5\u6355\u83b7\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\uff1b\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u6765\u6307\u5bfc\u6a21\u578b\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u6807\u8bb0\u5668\u548c\u591a\u5c3a\u5ea6\u81ea\u56de\u5f52\u6807\u8bb0\u5efa\u6a21\u6280\u672f\uff0c\u7528\u4e8e\u5728\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6355\u83b7\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5c3a\u5ea6\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u7387\u5931\u771f\u5b9a\u7406\u9a8c\u8bc1\u4e86DTM\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548cMSDformer\u7684\u5408\u7406\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMSDformer\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u591a\u5c3a\u5ea6\u4fe1\u606f\u548c\u591a\u5c3a\u5ea6\u6a21\u5f0f\u5efa\u6a21\u7eb3\u5165DTM\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u7684\u8d28\u91cf\u3002\u4ee3\u7801\u5c06\u5728\u63a5\u53d7\u540e\u53d1\u5e03\u3002"}}
{"id": "2505.14206", "pdf": "https://arxiv.org/pdf/2505.14206", "abs": "https://arxiv.org/abs/2505.14206", "authors": ["Flavio Di Martino", "Franca Delmastro"], "title": "Challenges and Limitations in the Synthetic Generation of mHealth Sensor Data", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ACM Transactions on Computing for Healthcare (ACM\n  HEALTH)", "summary": "The widespread adoption of mobile sensors has the potential to provide\nmassive and heterogeneous time series data, driving Artificial Intelligence\napplications in mHealth. However, data collection remains limited due to\nstringent ethical regulations, privacy concerns, and other constraints,\nhindering progress in the field. Synthetic data generation, particularly\nthrough Generative Adversarial Networks and Diffusion Models, has emerged as a\npromising solution to address both data scarcity and privacy issues. Yet, these\nmodels are often limited to short-term, unimodal signal patterns. This paper\npresents a systematic evaluation of state-of-the-art generative models for time\nseries synthesis, with a focus on their ability to jointly handle\nmulti-modality, long-range dependencies, and conditional generation-key\nchallenges in the mHealth domain. To ensure a fair comparison, we introduce a\nnovel evaluation framework designed to measure both the intrinsic quality of\nsynthetic data and its utility in downstream predictive tasks. Our findings\nreveal critical limitations in the existing approaches, particularly in\nmaintaining cross-modal consistency, preserving temporal coherence, and\nensuring robust performance in train-on-synthetic, test-on-real, and data\naugmentation scenarios. Finally, we present our future research directions to\nenhance synthetic time series generation and improve the applicability of\ngenerative models in mHealth.", "AI": {"tldr": "This paper evaluates advanced generative models for synthesizing time series data in mHealth, focusing on multi-modality, long-range dependencies, and conditional generation challenges.", "motivation": "To address data scarcity and privacy issues in mHealth using synthetic data generated by GANs and diffusion models.", "method": "Systematic evaluation of state-of-the-art generative models with a new evaluation framework.", "result": "Existing approaches have limitations in cross-modal consistency, temporal coherence, and robust performance in different scenarios.", "conclusion": "Identifies limitations in current methods and outlines future research directions to enhance synthetic time series generation for mHealth applications."}}
{"id": "2505.14211", "pdf": "https://arxiv.org/pdf/2505.14211", "abs": "https://arxiv.org/abs/2505.14211", "authors": ["Qu Wang", "Yan Xia"], "title": "A PID-Controlled Tensor Wheel Decomposition Model for Dynamic Link Prediction", "categories": ["cs.LG"], "comment": "7 pages, 2 figures", "summary": "Link prediction in dynamic networks remains a fundamental challenge in\nnetwork science, requiring the inference of potential interactions and their\nevolving strengths through spatiotemporal pattern analysis. Traditional static\nnetwork methods have inherent limitations in capturing temporal dependencies\nand weight dynamics, while tensor-based methods offer a promising paradigm by\nencoding dynamic networks into high-order tensors to explicitly model\nmultidimensional interactions across nodes and time. Among them, tensor wheel\ndecomposition (TWD) stands out for its innovative topological structure, which\ndecomposes high-order tensors into cyclic factors and core tensors to maintain\nstructural integrity. To improve the prediction accuracy, this study introduces\na PID-controlled tensor wheel decomposition (PTWD) model, which mainly adopts\nthe following two ideas: 1) exploiting the representation power of TWD to\ncapture the latent features of dynamic network topology and weight evolution,\nand 2) integrating the proportional-integral-derivative (PID) control principle\ninto the optimization process to obtain a stable model parameter learning\nscheme. The performance on four real datasets verifies that the proposed PTWD\nmodel has more accurate link prediction capabilities compared to other models.", "AI": {"tldr": "This study introduces a PID-controlled tensor wheel decomposition (PTWD) model for improving link prediction in dynamic networks by combining the representation power of TWD with the PID control principle.", "motivation": "To overcome the limitations of traditional static network methods and improve the prediction accuracy in dynamic networks.", "method": "Integrating the PID control principle into the optimization process and exploiting the representation power of TWD.", "result": "The PTWD model shows more accurate link prediction capabilities on four real datasets compared to other models.", "conclusion": "The proposed PTWD model demonstrates superior link prediction capabilities."}}
{"id": "2505.14217", "pdf": "https://arxiv.org/pdf/2505.14217", "abs": "https://arxiv.org/abs/2505.14217", "authors": ["Jorge Fabila", "Lidia Garrucho", "V\u00edctor M. Campello", "Carlos Mart\u00edn-Isla", "Karim Lekadir"], "title": "Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study explores the use of Federated Learning (FL) for tuberculosis (TB)\ndiagnosis using chest X-rays in low-resource settings across Africa. FL allows\nhospitals to collaboratively train AI models without sharing raw patient data,\naddressing privacy concerns and data scarcity that hinder traditional\ncentralized models. The research involved hospitals and research centers in\neight African countries. Most sites used local datasets, while Ghana and The\nGambia used public ones. The study compared locally trained models with a\nfederated model built across all institutions to evaluate FL's real-world\nfeasibility. Despite its promise, implementing FL in sub-Saharan Africa faces\nchallenges such as poor infrastructure, unreliable internet, limited digital\nliteracy, and weak AI regulations. Some institutions were also reluctant to\nshare model updates due to data control concerns. In conclusion, FL shows\nstrong potential for enabling AI-driven healthcare in underserved regions, but\nbroader adoption will require improvements in infrastructure, education, and\nregulatory support.", "AI": {"tldr": "This study investigates the application of Federated Learning in TB diagnosis using chest X-rays in low-resource African settings, comparing local and federated models.", "motivation": "Addressing privacy concerns and data scarcity hindering traditional centralized models in low-resource settings.", "method": "Using Federated Learning to collaboratively train AI models across eight African countries without sharing raw patient data.", "result": "FL shows strong potential but faces challenges like infrastructure, internet reliability, digital literacy, and weak AI regulations.", "conclusion": "FL has great potential for AI-driven healthcare in underserved regions but requires better infrastructure, education, and regulatory support for wider adoption."}}
{"id": "2505.14234", "pdf": "https://arxiv.org/pdf/2505.14234", "abs": "https://arxiv.org/abs/2505.14234", "authors": ["Illia Horenko", "Davide Bassetti", "Luk\u00e1\u0161 Posp\u00ed\u0161il"], "title": "Fast and close Shannon entropy approximation", "categories": ["cs.LG", "cs.AI", "68T01 (Primary) 68Q01, 90C99 (Secondary)"], "comment": "8 pages, 1 figure", "summary": "Shannon entropy (SE) and its quantum mechanical analogue von Neumann entropy\nare key components in many tools used in physics, information theory, machine\nlearning (ML) and quantum computing. Besides of the significant amounts of SE\ncomputations required in these fields, the singularity of the SE gradient is\none of the central mathematical reason inducing the high cost, frequently low\nrobustness and slow convergence of such tools. Here we propose the Fast Entropy\nApproximation (FEA) - a non-singular rational approximation of Shannon entropy\nand its gradient that achieves a mean absolute error of $10^{-3}$, which is\napproximately $20$ times lower than comparable state-of-the-art methods. FEA\nallows around $50\\%$ faster computation, requiring only $5$ to $6$ elementary\ncomputational operations, as compared to tens of elementary operations behind\nthe fastest entropy computation algorithms with table look-ups, bitshifts, or\nseries approximations. On a set of common benchmarks for the feature selection\nproblem in machine learning, we show that the combined effect of fewer\nelementary operations, low approximation error, and a non-singular gradient\nallows significantly better model quality and enables ML feature extraction\nthat is two to three orders of magnitude faster and computationally cheaper\nwhen incorporating FEA into AI tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Fast Entropy Approximation (FEA)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u975e\u5947\u5f02\u6709\u7406\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u9999\u519c\u71b5\u548c\u5176\u68af\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u9009\u62e9\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u71b5\u8ba1\u7b97\u5de5\u5177\u7531\u4e8e\u68af\u5ea6\u5947\u5f02\u6027\u5bfc\u81f4\u9ad8\u6210\u672c\u3001\u4f4e\u9c81\u68d2\u6027\u548c\u6162\u6536\u655b\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u975e\u5947\u5f02\u6709\u7406\u8fd1\u4f3c\u65b9\u6cd5\u6765\u903c\u8fd1\u9999\u519c\u71b5\u53ca\u5176\u68af\u5ea6\uff0c\u5373Fast Entropy Approximation (FEA)\u3002", "result": "FEA\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a10^-3\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f4e\u7ea620\u500d\uff1b\u8ba1\u7b97\u901f\u5ea6\u63d0\u9ad8\u7ea650%\uff0c\u4ec5\u97005\u52306\u4e2a\u57fa\u672c\u64cd\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5feb\u901f\u71b5\u903c\u8fd1\u65b9\u6cd5FEA\uff0c\u8be5\u65b9\u6cd5\u5728\u7279\u5f81\u9009\u62e9\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2505.14240", "pdf": "https://arxiv.org/pdf/2505.14240", "abs": "https://arxiv.org/abs/2505.14240", "authors": ["Germain Vivier-Ardisson", "Mathieu Blondel", "Axel Parmentier"], "title": "Learning with Local Search MCMC Layers", "categories": ["cs.LG"], "comment": null, "summary": "Integrating combinatorial optimization layers into neural networks has\nrecently attracted significant research interest. However, many existing\napproaches lack theoretical guarantees or fail to perform adequately when\nrelying on inexact solvers. This is a critical limitation, as many operations\nresearch problems are NP-hard, often necessitating the use of\nneighborhood-based local search heuristics. These heuristics iteratively\ngenerate and evaluate candidate solutions based on an acceptance rule. In this\npaper, we introduce a theoretically-principled approach for learning with such\ninexact combinatorial solvers. Inspired by the connection between simulated\nannealing and Metropolis-Hastings, we propose to transform problem-specific\nneighborhood systems used in local search heuristics into proposal\ndistributions, implementing MCMC on the combinatorial space of feasible\nsolutions. This allows us to construct differentiable combinatorial layers and\nassociated loss functions. Replacing an exact solver by a local search strongly\nreduces the computational burden of learning on many applications. We\ndemonstrate our approach on a large-scale dynamic vehicle routing problem with\ntime windows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eMCMC\u7684\u53ef\u5fae\u5206\u7ec4\u5408\u5c42\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u4f9d\u8d56\u4e8e\u4e0d\u7cbe\u786e\u6c42\u89e3\u5668\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5728\u52a8\u6001\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u73b0\u6709\u7684\u7ec4\u5408\u4f18\u5316\u5c42\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u6216\u5728\u4f9d\u8d56\u4e0d\u7cbe\u786e\u6c42\u89e3\u5668\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u9274\u4e8e\u8fd0\u7b79\u5b66\u95ee\u9898\u901a\u5e38\u662fNP\u96be\u7684\uff0c\u56e0\u6b64\u9700\u8981\u4f7f\u7528\u57fa\u4e8e\u90bb\u57df\u7684\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u5c06\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e2d\u7684\u95ee\u9898\u7279\u5b9a\u90bb\u57df\u7cfb\u7edf\u8f6c\u5316\u4e3a\u63d0\u8bae\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u7ec4\u5408\u53ef\u884c\u89e3\u7a7a\u95f4\u4e0a\u7684MCMC\uff0c\u6784\u5efa\u4e86\u53ef\u5fae\u5206\u7684\u7ec4\u5408\u5c42\u548c\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u5728\u5177\u6709\u65f6\u95f4\u7a97\u7684\u5927\u89c4\u6a21\u52a8\u6001\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u7684\u5e94\u7528\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u4e0d\u7cbe\u786e\u7ec4\u5408\u6c42\u89e3\u5668\uff0c\u5e76\u5728\u52a8\u6001\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u6f14\u793a\u3002"}}
{"id": "2505.14251", "pdf": "https://arxiv.org/pdf/2505.14251", "abs": "https://arxiv.org/abs/2505.14251", "authors": ["Bar Mahpud", "Or Sheffet"], "title": "A Private Approximation of the 2nd-Moment Matrix of Any Subsamplable Input", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We study the problem of differentially private second moment estimation and\npresent a new algorithm that achieve strong privacy-utility trade-offs even for\nworst-case inputs under subsamplability assumptions on the data. We call an\ninput $(m,\\alpha,\\beta)$-subsamplable if a random subsample of size $m$ (or\nlarger) preserves w.p $\\geq 1-\\beta$ the spectral structure of the original\nsecond moment matrix up to a multiplicative factor of $1\\pm \\alpha$. Building\nupon subsamplability, we give a recursive algorithmic framework similar to\nKamath et al 2019, that abides zero-Concentrated Differential Privacy (zCDP)\nwhile preserving w.h.p. the accuracy of the second moment estimation upto an\narbitrary factor of $(1\\pm\\gamma)$. We then show how to apply our algorithm to\napproximate the second moment matrix of a distribution $\\mathcal{D}$, even when\na noticeable fraction of the input are outliers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\u4e8c\u9636\u77e9\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5728\u5b50\u91c7\u6837\u5047\u8bbe\u4e0b\u5b9e\u73b0\u4e86\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u4e8c\u9636\u77e9\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u9002\u7528\u4e8e\u6700\u574f\u60c5\u51b5\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8e\u5b50\u91c7\u6837\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u9012\u5f52\u7b97\u6cd5\u6846\u67b6\uff0c\u9075\u5b88\u96f6\u96c6\u4e2d\u5dee\u5206\u9690\u79c1(zCDP)\uff0c\u5e76\u4fdd\u6301\u4f30\u8ba1\u7cbe\u5ea6\u3002", "result": "\u7b97\u6cd5\u5728\u5904\u7406\u5305\u542b\u5f02\u5e38\u503c\u7684\u6570\u636e\u65f6\u80fd\u591f\u8fd1\u4f3c\u5206\u5e03\u7684\u4e8c\u9636\u77e9\u77e9\u9635\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u6570\u636e\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u590d\u6742\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2505.14252", "pdf": "https://arxiv.org/pdf/2505.14252", "abs": "https://arxiv.org/abs/2505.14252", "authors": ["Mouad Elaarabi", "Domenico Borzacchiello", "Philippe Le Bot", "Nathan Lauzeral", "Sebastien Comas-Cardona"], "title": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we explore the integration of Sequence Encoding for Online\nParameter Identification with Physics-Informed Neural Networks to create a\nmodel that, once trained, can be utilized for real time applications with\nvariable parameters, boundary conditions, and initial conditions. Recently, the\ncombination of PINNs with Sparse Regression has emerged as a method for\nperforming dynamical system identification through supervised learning and\nsparse regression optimization, while also solving the dynamics using PINNs.\nHowever, this approach can be limited by variations in parameters or boundary\nand initial conditions, requiring retraining of the model whenever changes\noccur. In this work, we introduce an architecture that employs Deep Sets or\nSequence Encoders to encode dynamic parameters, boundary conditions, and\ninitial conditions, using these encoded features as inputs for the PINN,\nenabling the model to adapt to changes in parameters, BCs, and ICs. We apply\nthis approach to three different problems. First, we analyze the Rossler ODE\nsystem, demonstrating the robustness of the model with respect to noise and its\nability to generalize. Next, we explore the model's capability in a 2D\nNavier-Stokes PDE problem involving flow past a cylinder with a parametric\nsinusoidal inlet velocity function, showing that the model can encode pressure\ndata from a few points to identify the inlet velocity profile and utilize\nphysics to compute velocity and pressure throughout the domain. Finally, we\naddress a 1D heat monitoring problem using real data from the heating of glass\nfiber and thermoplastic composite plates.", "AI": {"tldr": "This paper introduces an architecture combining Sequence Encoding and Physics-Informed Neural Networks (PINNs) to enable real-time adaptation to varying parameters, boundary conditions, and initial conditions without retraining.", "motivation": "To overcome limitations of PINNs when dealing with variable parameters, boundary and initial conditions, which require retraining the model every time changes occur.", "method": "Integrating Sequence Encoding with PINNs to encode dynamic parameters, boundary conditions, and initial conditions, using these encoded features as inputs for the PINN.", "result": "The approach was applied to three problems: the Rossler ODE system, a 2D Navier-Stokes PDE problem, and a 1D heat monitoring problem using real data. It demonstrated robustness against noise, ability to generalize, and capability to encode pressure data to identify inlet velocity profiles and compute velocity and pressure throughout the domain.", "conclusion": "The proposed architecture allows for real-time adaptation of PINNs to varying parameters, boundary conditions, and initial conditions, which could significantly enhance their applicability in various fields."}}
{"id": "2505.14264", "pdf": "https://arxiv.org/pdf/2505.14264", "abs": "https://arxiv.org/abs/2505.14264", "authors": ["Jian Xiong", "Jingbo Zhou", "Jingyong Ye", "Dejing Dou"], "title": "AAPO: Enhance the Reasoning Capabilities of LLMs with Advantage Momentum", "categories": ["cs.LG", "cs.CL"], "comment": "14 pages, 7 figures", "summary": "Reinforcement learning (RL) has emerged as an effective approach for\nenhancing the reasoning capabilities of large language models (LLMs),\nespecially in scenarios where supervised fine-tuning (SFT) falls short due to\nlimited chain-of-thought (CoT) data. Among RL-based post-training methods,\ngroup relative advantage estimation, as exemplified by Group Relative Policy\nOptimization (GRPO), has attracted considerable attention for eliminating the\ndependency on the value model, thereby simplifying training compared to\ntraditional approaches like Proximal Policy Optimization (PPO). However, we\nobserve that exsiting group relative advantage estimation method still suffers\nfrom training inefficiencies, particularly when the estimated advantage\napproaches zero. To address this limitation, we propose Advantage-Augmented\nPolicy Optimization (AAPO), a novel RL algorithm that optimizes the\ncross-entropy (CE) loss using advantages enhanced through a momentum-based\nestimation scheme. This approach effectively mitigates the inefficiencies\nassociated with group relative advantage estimation. Experimental results on\nmultiple mathematical reasoning benchmarks demonstrate the superior performance\nof AAPO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5AAPO\uff0c\u4f18\u5316\u4e86\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u901a\u8fc7\u52a8\u91cf\u589e\u5f3a\u7684\u4f18\u52bf\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\u5728\u4f18\u52bf\u63a5\u8fd1\u96f6\u65f6\u7684\u8bad\u7ec3\u6548\u7387\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660eAAPO\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u5728\u6ca1\u6709\u4ef7\u503c\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u7b80\u5316\u8bad\u7ec3\uff0c\u4f46\u73b0\u6709\u7684\u7ec4\u76f8\u5bf9\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\u5728\u4f18\u52bf\u63a5\u8fd1\u96f6\u65f6\u4ecd\u5b58\u5728\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u4f18\u52bf\u589e\u5f3a\u7b56\u7565\u4f18\u5316\uff08AAPO\uff09\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u52a8\u91cf\u589e\u5f3a\u7684\u4f18\u52bf\u4f30\u8ba1\u6765\u4f18\u5316\u4ea4\u53c9\u71b5\u635f\u5931\u3002", "result": "AAPO\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "AAPO\u6709\u6548\u5730\u89e3\u51b3\u4e86\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\u7684\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.14273", "pdf": "https://arxiv.org/pdf/2505.14273", "abs": "https://arxiv.org/abs/2505.14273", "authors": ["Hiroki Shiraishi", "Hisao Ishibuchi", "Masaya Nakata"], "title": "X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)", "summary": "Function approximation is a critical task in various fields. However,\nexisting neural network approaches struggle with locally complex or\ndiscontinuous functions due to their reliance on a single global model covering\nthe entire problem space. We propose X-KAN, a novel method that optimizes\nmultiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary\nrule-based machine learning framework called XCSF. X-KAN combines KAN's high\nexpressiveness with XCSF's adaptive partitioning capability by implementing\nlocal KAN models as rule consequents and defining local regions via rule\nantecedents. Our experimental results on artificial test functions and\nreal-world datasets demonstrate that X-KAN significantly outperforms\nconventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms\nof approximation accuracy. Notably, X-KAN effectively handles functions with\nlocally complex or discontinuous structures that are challenging for\nconventional KAN, using a compact set of rules (average 7.2 $\\pm$ 2.3 rules).\nThese results validate the effectiveness of using KAN as a local model in XCSF,\nwhich evaluates the rule fitness based on both accuracy and generality. Our\nX-KAN implementation is available at https://github.com/YNU-NakataLab/X-KAN.", "AI": {"tldr": "Proposes X-KAN, which uses multiple local Kolmogorov-Arnold Networks optimized by XCSF to handle complex or discontinuous functions better than conventional methods.", "motivation": "Existing neural network approaches struggle with locally complex or discontinuous functions.", "method": "Uses XCSF to optimize multiple local KANs, combining KAN's expressiveness with XCSF's adaptive partitioning.", "result": "Outperforms conventional methods on artificial and real-world datasets.", "conclusion": "Validates the effectiveness of using KAN as a local model in XCSF."}}
{"id": "2505.14302", "pdf": "https://arxiv.org/pdf/2505.14302", "abs": "https://arxiv.org/abs/2505.14302", "authors": ["Mengzhao Chen", "Chaoyi Zhang", "Jing Liu", "Yutao Zeng", "Zeyue Xue", "Zhiheng Liu", "Yunshui Li", "Jin Ma", "Jie Huang", "Xun Zhou", "Ping Luo"], "title": "Scaling Law for Quantization-Aware Training", "categories": ["cs.LG", "cs.CL"], "comment": "A unified scaling law for QAT that models quantization error as a\n  function of model size, training data volume, and quantization group size", "summary": "Large language models (LLMs) demand substantial computational and memory\nresources, creating deployment challenges. Quantization-aware training (QAT)\naddresses these challenges by reducing model precision while maintaining\nperformance. However, the scaling behavior of QAT, especially at 4-bit\nprecision (W4A4), is not well understood. Existing QAT scaling laws often\nignore key factors such as the number of training tokens and quantization\ngranularity, which limits their applicability. This paper proposes a unified\nscaling law for QAT that models quantization error as a function of model size,\ntraining data volume, and quantization group size. Through 268 QAT experiments,\nwe show that quantization error decreases as model size increases, but rises\nwith more training tokens and coarser quantization granularity. To identify the\nsources of W4A4 quantization error, we decompose it into weight and activation\ncomponents. Both components follow the overall trend of W4A4 quantization\nerror, but with different sensitivities. Specifically, weight quantization\nerror increases more rapidly with more training tokens. Further analysis shows\nthat the activation quantization error in the FC2 layer, caused by outliers, is\nthe primary bottleneck of W4A4 QAT quantization error. By applying\nmixed-precision quantization to address this bottleneck, we demonstrate that\nweight and activation quantization errors can converge to similar levels.\nAdditionally, with more training data, weight quantization error eventually\nexceeds activation quantization error, suggesting that reducing weight\nquantization error is also important in such scenarios. These findings offer\nkey insights for improving QAT research and development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u7f29\u653e\u5b9a\u5f8b\uff0c\u63ed\u793a\u4e86\u5f71\u54cd\u91cf\u5316\u8bef\u5dee\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u5b9a\u5f8b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u53ef\u4ee5\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u8d44\u6e90\u9700\u6c42\uff0c\u4f46\u5176\u57284\u4f4d\u7cbe\u5ea6\u4e0b\u7684\u7f29\u653e\u884c\u4e3a\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u73b0\u6709\u7684\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u7f29\u653e\u89c4\u5f8b\u5f80\u5f80\u5ffd\u7565\u4e86\u5173\u952e\u56e0\u7d20\uff0c\u5982\u8bad\u7ec3\u6807\u8bb0\u6570\u91cf\u548c\u91cf\u5316\u7c92\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7f29\u653e\u5b9a\u5f8b\u6765\u5efa\u6a21\u91cf\u5316\u8bef\u5dee\uff0c\u5e76\u8fdb\u884c\u4e86268\u4e2a\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u5b9e\u9a8c\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u89e3\u4e86W4A4\u91cf\u5316\u8bef\u5dee\u7684\u6743\u91cd\u548c\u6fc0\u6d3b\u90e8\u5206\uff0c\u5e76\u5e94\u7528\u4e86\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6765\u89e3\u51b3\u4e3b\u8981\u74f6\u9888\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91cf\u5316\u8bef\u5dee\u968f\u7740\u6a21\u578b\u5927\u5c0f\u7684\u589e\u52a0\u800c\u51cf\u5c11\uff0c\u4f46\u968f\u7740\u66f4\u591a\u7684\u8bad\u7ec3\u6807\u8bb0\u548c\u66f4\u7c97\u7c92\u5ea6\u7684\u91cf\u5316\u800c\u589e\u52a0\u3002\u6743\u91cd\u548c\u6fc0\u6d3b\u91cf\u5316\u8bef\u5dee\u90fd\u9075\u5faaW4A4\u91cf\u5316\u8bef\u5dee\u7684\u6574\u4f53\u8d8b\u52bf\uff0c\u4f46\u654f\u611f\u6027\u4e0d\u540c\u3002\u901a\u8fc7\u5e94\u7528\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u89e3\u51b3\u4e86\u4e3b\u8981\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u4e14\u5f53\u6709\u66f4\u591a\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u6743\u91cd\u91cf\u5316\u8bef\u5dee\u6700\u7ec8\u4f1a\u8d85\u8fc7\u6fc0\u6d3b\u91cf\u5316\u8bef\u5dee\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u7f29\u653e\u5b9a\u5f8b\u6709\u52a9\u4e8e\u7406\u89e3\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002\u901a\u8fc7\u8c03\u6574\u91cf\u5316\u7c92\u5ea6\u548c\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u91cf\u5316\u8bef\u5dee\u3002"}}
{"id": "2505.14312", "pdf": "https://arxiv.org/pdf/2505.14312", "abs": "https://arxiv.org/abs/2505.14312", "authors": ["Kyungeun Lee", "Moonjung Eo", "Hye-Seung Cho", "Dongmin Kim", "Ye Seul Sim", "Seoyoon Kim", "Min-Kook Suh", "Woohyung Lim"], "title": "MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Despite the widespread use of tabular data in real-world applications, most\nbenchmarks rely on average-case metrics, which fail to reveal how model\nbehavior varies across diverse data regimes. To address this, we propose\nMultiTab, a benchmark suite and evaluation framework for multi-dimensional,\ndata-aware analysis of tabular learning algorithms. Rather than comparing\nmodels only in aggregate, MultiTab categorizes 196 publicly available datasets\nalong key data characteristics, including sample size, label imbalance, and\nfeature interaction, and evaluates 13 representative models spanning a range of\ninductive biases. Our analysis shows that model performance is highly sensitive\nto such regimes: for example, models using sample-level similarity excel on\ndatasets with large sample sizes or high inter-feature correlation, while\nmodels encoding inter-feature dependencies perform best with weakly correlated\nfeatures. These findings reveal that inductive biases do not always behave as\nintended, and that regime-aware evaluation is essential for understanding and\nimproving model behavior. MultiTab enables more principled model design and\noffers practical guidance for selecting models tailored to specific data\ncharacteristics. All datasets, code, and optimization logs are publicly\navailable at https://huggingface.co/datasets/LGAI-DILab/Multitab.", "AI": {"tldr": "\u63d0\u51faMultiTab\uff0c\u4e00\u4e2a\u7528\u4e8e\u8868\u683c\u5b66\u4e60\u7b97\u6cd5\u591a\u7ef4\u6570\u636e\u611f\u77e5\u5206\u6790\u7684\u57fa\u51c6\u5957\u4ef6\u548c\u8bc4\u4f30\u6846\u67b6\u3002\u5206\u6790\u663e\u793a\u6a21\u578b\u6027\u80fd\u5bf9\u6570\u636e\u7279\u5f81\u975e\u5e38\u654f\u611f\uff0c\u5e76\u5f3a\u8c03\u4e86\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u7279\u5f81\u9009\u62e9\u5408\u9002\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002\u6240\u6709\u8d44\u6e90\u516c\u5f00\u53ef\u7528\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u5e73\u5747\u6307\u6807\uff0c\u65e0\u6cd5\u63ed\u793a\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u73af\u5883\u4e0b\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "method": "\u6784\u5efaMultiTab\uff0c\u5bf9196\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u6309\u6837\u672c\u5927\u5c0f\u3001\u6807\u7b7e\u4e0d\u5e73\u8861\u548c\u7279\u5f81\u4ea4\u4e92\u7b49\u5173\u952e\u6570\u636e\u7279\u6027\u5206\u7c7b\uff0c\u5e76\u8bc4\u4f3013\u79cd\u5177\u6709\u4e0d\u540c\u5f52\u7eb3\u504f\u7f6e\u7684\u4ee3\u8868\u6027\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6570\u636e\u7279\u5f81\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528\u6837\u672c\u7ea7\u76f8\u4f3c\u6027\u7684\u6a21\u578b\u5728\u5927\u6837\u672c\u91cf\u6216\u9ad8\u7279\u5f81\u76f8\u5173\u6027\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u800c\u7f16\u7801\u7279\u5f81\u95f4\u4f9d\u8d56\u5173\u7cfb\u7684\u6a21\u578b\u5728\u5f31\u76f8\u5173\u7279\u5f81\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "MultiTab\u4e3a\u66f4\u539f\u5219\u5316\u7684\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u5e76\u4e3a\u6839\u636e\u5177\u4f53\u6570\u636e\u7279\u5f81\u9009\u62e9\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2505.14338", "pdf": "https://arxiv.org/pdf/2505.14338", "abs": "https://arxiv.org/abs/2505.14338", "authors": ["Egor Bakaev", "Florestan Brunck", "Christoph Hertrich", "Jack Stade", "Amir Yehudayoff"], "title": "Better Neural Network Expressivity: Subdividing the Simplex", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "comment": "11 pages, 1 figure", "summary": "This work studies the expressivity of ReLU neural networks with a focus on\ntheir depth. A sequence of previous works showed that $\\lceil \\log_2(n+1)\n\\rceil$ hidden layers are sufficient to compute all continuous piecewise linear\n(CPWL) functions on $\\mathbb{R}^n$. Hertrich, Basu, Di Summa, and Skutella\n(NeurIPS'21) conjectured that this result is optimal in the sense that there\nare CPWL functions on $\\mathbb{R}^n$, like the maximum function, that require\nthis depth. We disprove the conjecture and show that\n$\\lceil\\log_3(n-1)\\rceil+1$ hidden layers are sufficient to compute all CPWL\nfunctions on $\\mathbb{R}^n$.\n  A key step in the proof is that ReLU neural networks with two hidden layers\ncan exactly represent the maximum function of five inputs. More generally, we\nshow that $\\lceil\\log_3(n-2)\\rceil+1$ hidden layers are sufficient to compute\nthe maximum of $n\\geq 4$ numbers. Our constructions almost match the\n$\\lceil\\log_3(n)\\rceil$ lower bound of Averkov, Hojny, and Merkert (ICLR'25) in\nthe special case of ReLU networks with weights that are decimal fractions. The\nconstructions have a geometric interpretation via polyhedral subdivisions of\nthe simplex into ``easier'' polytopes.", "AI": {"tldr": "\u7814\u7a76\u4e86ReLU\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u91cd\u70b9\u5728\u4e8e\u5176\u6df1\u5ea6\u3002\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u8fde\u7eed\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\uff0c\u6240\u9700\u9690\u85cf\u5c42\u6570\u5c11\u4e8e\u5148\u524d\u731c\u60f3\uff0c\u4e14\u6784\u9020\u51e0\u4e4e\u5339\u914d\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76ReLU\u795e\u7ecf\u7f51\u7edc\u8868\u8fbe\u8fde\u7eed\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u6240\u9700\u7684\u6700\u5c0f\u6df1\u5ea6\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5177\u6709\u4e24\u4e2a\u9690\u85cf\u5c42\u7684ReLU\u7f51\u7edc\u7cbe\u786e\u8868\u793a\u6700\u5927\u51fd\u6570\uff0c\u5e76\u63a8\u5e7f\u5230n\u4e2a\u6570\u7684\u6700\u5927\u503c\u8ba1\u7b97\u3002", "result": "\u8bc1\u660e\u4e86\u8ba1\u7b97\u6240\u6709\u8fde\u7eed\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u6240\u9700\u7684\u9690\u85cf\u5c42\u6570\u4e3a ceil(log_3(n-1)) + 1\uff0c\u800c\u975e\u4e4b\u524d\u731c\u60f3\u7684 ceil(log_2(n+1))\u3002", "conclusion": "\u65b0\u7684\u7ed3\u679c\u8868\u660eReLU\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u66f4\u5f3a\u3002"}}
{"id": "2505.14345", "pdf": "https://arxiv.org/pdf/2505.14345", "abs": "https://arxiv.org/abs/2505.14345", "authors": ["Aydin Abedinia", "Shima Tabakhi", "Vahid Seydi"], "title": "Enhancing Classification with Semi-Supervised Deep Learning Using Distance-Based Sample Weights", "categories": ["cs.LG", "cs.AI", "68T05, 62H30", "I.2.6; I.5.1; I.5.4"], "comment": "5 pages, 6 figures. This paper has been accepted for publication and\n  oral presentation at the 2025 10th IEEE International Conference on Machine\n  Learning Technologies (ICMLT 2025). The final authenticated version will be\n  available in IEEE Xplore following the conference", "summary": "Recent advancements in semi-supervised deep learning have introduced\neffective strategies for leveraging both labeled and unlabeled data to improve\nclassification performance. This work proposes a semi-supervised framework that\nutilizes a distance-based weighting mechanism to prioritize critical training\nsamples based on their proximity to test data. By focusing on the most\ninformative examples, the method enhances model generalization and robustness,\nparticularly in challenging scenarios with noisy or imbalanced datasets.\nBuilding on techniques such as uncertainty consistency and graph-based\nrepresentations, the approach addresses key challenges of limited labeled data\nwhile maintaining scalability. Experiments on twelve benchmark datasets\ndemonstrate significant improvements across key metrics, including accuracy,\nprecision, and recall, consistently outperforming existing methods. This\nframework provides a robust and practical solution for semi-supervised\nlearning, with potential applications in domains such as healthcare and\nsecurity where data limitations pose significant challenges.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8ddd\u79bb\u52a0\u6743\u673a\u5236\u7684\u534a\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5728\u566a\u58f0\u548c\u4e0d\u5e73\u8861\u6570\u636e\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\uff0c\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u8ddd\u79bb\u7684\u52a0\u6743\u673a\u5236\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u4e00\u81f4\u6027\u53ca\u56fe\u8868\u793a\u6280\u672f\u3002", "result": "\u572812\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u51c6\u786e\u7387\u3001\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u4e3a\u534a\u76d1\u7763\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u533b\u7597\u548c\u5b89\u5168\u7b49\u9886\u57df\u3002"}}
{"id": "2505.14352", "pdf": "https://arxiv.org/pdf/2505.14352", "abs": "https://arxiv.org/abs/2505.14352", "authors": ["Bartosz Cywi\u0144ski", "Emil Ryd", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Towards eliciting latent knowledge from LLMs with mechanistic interpretability", "categories": ["cs.LG"], "comment": null, "summary": "As language models become more powerful and sophisticated, it is crucial that\nthey remain trustworthy and reliable. There is concerning preliminary evidence\nthat models may attempt to deceive or keep secrets from their operators. To\nexplore the ability of current techniques to elicit such hidden knowledge, we\ntrain a Taboo model: a language model that describes a specific secret word\nwithout explicitly stating it. Importantly, the secret word is not presented to\nthe model in its training data or prompt. We then investigate methods to\nuncover this secret. First, we evaluate non-interpretability (black-box)\napproaches. Subsequently, we develop largely automated strategies based on\nmechanistic interpretability techniques, including logit lens and sparse\nautoencoders. Evaluation shows that both approaches are effective in eliciting\nthe secret word in our proof-of-concept setting. Our findings highlight the\npromise of these approaches for eliciting hidden knowledge and suggest several\npromising avenues for future work, including testing and refining these methods\non more complex model organisms. This work aims to be a step towards addressing\nthe crucial problem of eliciting secret knowledge from language models, thereby\ncontributing to their safe and reliable deployment.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5f53\u524d\u6280\u672f\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u8bad\u7ec3\u7981\u5fcc\u6a21\u578b\u63cf\u8ff0\u7279\u5b9a\u79d8\u5bc6\u8bcd\u800c\u4e0d\u660e\u786e\u63d0\u53ca\uff0c\u63a2\u7d22\u4e86\u975e\u89e3\u91ca\u6027\u548c\u57fa\u4e8e\u673a\u68b0\u89e3\u91ca\u7684\u6280\u672f\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u6982\u5ff5\u9a8c\u8bc1\u8bbe\u7f6e\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u786e\u4fdd\u66f4\u5f3a\u5927\u548c\u590d\u6742\u7684\u8bed\u8a00\u6a21\u578b\u4fdd\u6301\u53ef\u4fe1\u548c\u53ef\u9760\uff0c\u9632\u6b62\u5176\u53ef\u80fd\u5bf9\u64cd\u4f5c\u8005\u9690\u7792\u4fe1\u606f\u6216\u6b3a\u9a97\u7684\u884c\u4e3a\u3002", "method": "\u8bad\u7ec3\u4e86\u4e00\u4e2a\u7981\u5fcc\u6a21\u578b\uff0c\u63cf\u8ff0\u4e00\u4e2a\u4e0d\u5728\u5176\u8bad\u7ec3\u6570\u636e\u6216\u63d0\u793a\u4e2d\u7684\u7279\u5b9a\u79d8\u5bc6\u8bcd\uff1b\u8bc4\u4f30\u4e86\u975e\u89e3\u91ca\u6027\uff08\u9ed1\u76d2\uff09\u65b9\u6cd5\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u673a\u68b0\u89e3\u91ca\u6280\u672f\u7684\u81ea\u52a8\u5316\u7b56\u7565\uff0c\u5305\u62eclogit\u955c\u5934\u548c\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u6709\u6548\u63ed\u793a\u6982\u5ff5\u9a8c\u8bc1\u8bbe\u7f6e\u4e2d\u7684\u79d8\u5bc6\u8bcd\u3002", "conclusion": "\u672c\u7814\u7a76\u662f\u89e3\u51b3\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u63ed\u793a\u79d8\u5bc6\u77e5\u8bc6\u95ee\u9898\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u6709\u52a9\u4e8e\u5b83\u4eec\u7684\u5b89\u5168\u548c\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2505.14371", "pdf": "https://arxiv.org/pdf/2505.14371", "abs": "https://arxiv.org/abs/2505.14371", "authors": ["Anh Duc Nguyen", "Ilia Markov", "Frank Zhengqing Wu", "Ali Ramezani-Kebrya", "Kimon Antonakopoulos", "Dan Alistarh", "Volkan Cevher"], "title": "Layer-wise Quantization for Quantized Optimistic Dual Averaging", "categories": ["cs.LG", "math.OC"], "comment": "Accepted at the International Conference on Machine Learning (ICML\n  2025)", "summary": "Modern deep neural networks exhibit heterogeneity across numerous layers of\nvarious types such as residuals, multi-head attention, etc., due to varying\nstructures (dimensions, activation functions, etc.), distinct representation\ncharacteristics, which impact predictions. We develop a general layer-wise\nquantization framework with tight variance and code-length bounds, adapting to\nthe heterogeneities over the course of training. We then apply a new layer-wise\nquantization technique within distributed variational inequalities (VIs),\nproposing a novel Quantized Optimistic Dual Averaging (QODA) algorithm with\nadaptive learning rates, which achieves competitive convergence rates for\nmonotone VIs. We empirically show that QODA achieves up to a $150\\%$ speedup\nover the baselines in end-to-end training time for training Wasserstein GAN on\n$12+$ GPUs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c42\u91cf\u5316\u6846\u67b6\u548c\u7b97\u6cd5QODA\uff0c\u663e\u8457\u63d0\u5347\u4e86Wasserstein GAN\u5728\u591aGPU\u8bad\u7ec3\u4e2d\u7684\u901f\u5ea6\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u5f02\u6784\u6027\uff0c\u8fd9\u5f71\u54cd\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u5c42\u91cf\u5316\u6846\u67b6\u5e76\u63d0\u51fa\u4e86QODA\u7b97\u6cd5\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u3002", "result": "QODA\u5728\u591a\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe150%\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u52a0\u901f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5904\u7406\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5f02\u6784\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.14388", "pdf": "https://arxiv.org/pdf/2505.14388", "abs": "https://arxiv.org/abs/2505.14388", "authors": ["Prasanna Parasurama", "Panos Ipeirotis"], "title": "Algorithmic Hiring and Diversity: Reducing Human-Algorithm Similarity for Better Outcomes", "categories": ["cs.LG", "cs.HC", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Algorithmic tools are increasingly used in hiring to improve fairness and\ndiversity, often by enforcing constraints such as gender-balanced candidate\nshortlists. However, we show theoretically and empirically that enforcing equal\nrepresentation at the shortlist stage does not necessarily translate into more\ndiverse final hires, even when there is no gender bias in the hiring stage. We\nidentify a crucial factor influencing this outcome: the correlation between the\nalgorithm's screening criteria and the human hiring manager's evaluation\ncriteria -- higher correlation leads to lower diversity in final hires. Using a\nlarge-scale empirical analysis of nearly 800,000 job applications across\nmultiple technology firms, we find that enforcing equal shortlists yields\nlimited improvements in hire diversity when the algorithmic screening closely\nmirrors the hiring manager's preferences. We propose a complementary\nalgorithmic approach designed explicitly to diversify shortlists by selecting\ncandidates likely to be overlooked by managers, yet still competitive according\nto their evaluation criteria. Empirical simulations show that this approach\nsignificantly enhances gender diversity in final hires without substantially\ncompromising hire quality. These findings highlight the importance of\nalgorithmic design choices in achieving organizational diversity goals and\nprovide actionable guidance for practitioners implementing fairness-oriented\nhiring algorithms.", "AI": {"tldr": "This paper shows that ensuring equal representation in shortlists doesn't necessarily lead to more diverse final hires due to the correlation between algorithmic and human hiring criteria. It proposes an approach to diversify shortlists, which improves gender diversity in final hires.", "motivation": "To explore why equal shortlists don't guarantee diverse final hires and to suggest methods to enhance diversity.", "method": "Theoretical and empirical analysis including a large-scale study of job applications from multiple tech firms, along with empirical simulations.", "result": "Enforcing equal shortlists only provides limited benefits in terms of hire diversity when the algorithm mirrors hiring managers' preferences. The proposed method significantly boosts gender diversity in final hires.", "conclusion": "Algorithmic design choices are crucial for achieving organizational diversity goals, and practical guidance is provided for fairness-oriented hiring algorithms."}}
{"id": "2505.14407", "pdf": "https://arxiv.org/pdf/2505.14407", "abs": "https://arxiv.org/abs/2505.14407", "authors": ["Aniket Salvi", "Gereon Weiss", "Mario Trapp"], "title": "Explaining Unreliable Perception in Automated Driving: A Fuzzy-based Monitoring Approach", "categories": ["cs.LG"], "comment": null, "summary": "Autonomous systems that rely on Machine Learning (ML) utilize online fault\ntolerance mechanisms, such as runtime monitors, to detect ML prediction errors\nand maintain safety during operation. However, the lack of human-interpretable\nexplanations for these errors can hinder the creation of strong assurances\nabout the system's safety and reliability. This paper introduces a novel\nfuzzy-based monitor tailored for ML perception components. It provides\nhuman-interpretable explanations about how different operating conditions\naffect the reliability of perception components and also functions as a runtime\nsafety monitor. We evaluated our proposed monitor using naturalistic driving\ndatasets as part of an automated driving case study. The interpretability of\nthe monitor was evaluated and we identified a set of operating conditions in\nwhich the perception component performs reliably. Additionally, we created an\nassurance case that links unit-level evidence of \\textit{correct} ML operation\nto system-level \\textit{safety}. The benchmarking demonstrated that our monitor\nachieved a better increase in safety (i.e., absence of hazardous situations)\nwhile maintaining availability (i.e., ability to perform the mission) compared\nto state-of-the-art runtime ML monitors in the evaluated dataset.", "AI": {"tldr": "This paper presents a novel fuzzy-based monitor for ML perception components that provides human-interpretable explanations and improves safety and availability.", "motivation": "The lack of human-interpretable explanations for ML prediction errors hinders the assurance of system safety and reliability.", "method": "Introduce a fuzzy-based monitor tailored for ML perception components that provides explanations and functions as a runtime safety monitor.", "result": "Evaluated the monitor using naturalistic driving datasets, identified reliable operating conditions, and created an assurance case linking ML operation to system safety.", "conclusion": "The proposed monitor improves safety and availability compared to state-of-the-art runtime ML monitors."}}
{"id": "2505.14411", "pdf": "https://arxiv.org/pdf/2505.14411", "abs": "https://arxiv.org/abs/2505.14411", "authors": ["Leon G\u00f6tz", "Marcel Kollovieh", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Byte Pair Encoding for Efficient Time Series Forecasting", "categories": ["cs.LG"], "comment": "24 pages in total, 17 figures", "summary": "Existing time series tokenization methods predominantly encode a constant\nnumber of samples into individual tokens. This inflexible approach can generate\nexcessive tokens for even simple patterns like extended constant values,\nresulting in substantial computational overhead. Inspired by the success of\nbyte pair encoding, we propose the first pattern-centric tokenization scheme\nfor time series analysis. Based on a discrete vocabulary of frequent motifs,\nour method merges samples with underlying patterns into tokens, compressing\ntime series adaptively. Exploiting our finite set of motifs and the continuous\nproperties of time series, we further introduce conditional decoding as a\nlightweight yet powerful post-hoc optimization method, which requires no\ngradient computation and adds no computational overhead. On recent time series\nfoundation models, our motif-based tokenization improves forecasting\nperformance by 36% and boosts efficiency by 1990% on average. Conditional\ndecoding further reduces MSE by up to 44%. In an extensive analysis, we\ndemonstrate the adaptiveness of our tokenization to diverse temporal patterns,\nits generalization to unseen data, and its meaningful token representations\ncapturing distinct time series properties, including statistical moments and\ntrends.", "AI": {"tldr": "This paper introduces a new tokenization method for time series analysis based on frequent motifs, improving forecasting performance and efficiency.", "motivation": "Existing tokenization methods produce excessive tokens for simple patterns, leading to high computational overhead.", "method": "Proposes a pattern-centric tokenization scheme that merges samples with underlying patterns into tokens, using conditional decoding as a post-hoc optimization.", "result": "Improves forecasting performance by 36% and efficiency by 1990% on average, with conditional decoding reducing MSE by up to 44%.", "conclusion": "The proposed tokenization method is adaptive to various temporal patterns, generalizes well to unseen data, and provides meaningful token representations capturing time series properties."}}
{"id": "2505.14415", "pdf": "https://arxiv.org/pdf/2505.14415", "abs": "https://arxiv.org/abs/2505.14415", "authors": ["Myung Jun Kim", "F\u00e9lix Lefebvre", "Ga\u00ebtan Brison", "Alexandre Perez-Lebel", "Ga\u00ebl Varoquaux"], "title": "Table Foundation Models: on knowledge pre-training for tabular learning", "categories": ["cs.LG"], "comment": null, "summary": "Table foundation models bring high hopes to data science: pre-trained on\ntabular data to embark knowledge or priors, they should facilitate downstream\ntasks on tables. One specific challenge is that of data semantics: numerical\nentries take their meaning from context, e.g., column name. Pre-trained neural\nnetworks that jointly model column names and table entries have recently\nboosted prediction accuracy. While these models outline the promises of world\nknowledge to interpret table values, they lack the convenience of popular\nfoundation models in text or vision. Indeed, they must be fine-tuned to bring\nbenefits, come with sizeable computation costs, and cannot easily be reused or\ncombined with other architectures. Here we introduce TARTE, a foundation model\nthat transforms tables to knowledge-enhanced vector representations using the\nstring to capture semantics. Pre-trained on large relational data, TARTE yields\nrepresentations that facilitate subsequent learning with little additional\ncost. These representations can be fine-tuned or combined with other learners,\ngiving models that push the state-of-the-art prediction performance and improve\nthe prediction/computation performance trade-off. Specialized to a task or a\ndomain, TARTE gives domain-specific representations that facilitate further\nlearning. Our study demonstrates an effective approach to knowledge\npre-training for tabular learning.", "AI": {"tldr": "Introduces TARTE, a foundation model that transforms tables into knowledge-enhanced vector representations, improving downstream tasks with minimal additional cost.", "motivation": "To address challenges in data semantics for table foundation models and provide a more convenient and reusable solution compared to existing methods.", "method": "Pre-trains TARTE on large relational data to create knowledge-enhanced vector representations using strings to capture semantics.", "result": "TARTE improves downstream learning performance with low additional computational costs and facilitates task-specific fine-tuning or combination with other learners.", "conclusion": "TARTE demonstrates an effective approach to knowledge pre-training for tabular learning."}}
{"id": "2505.14424", "pdf": "https://arxiv.org/pdf/2505.14424", "abs": "https://arxiv.org/abs/2505.14424", "authors": ["Levin Hornischer", "Hannes Leitgeb"], "title": "Explaining Neural Networks with Reasons", "categories": ["cs.LG"], "comment": "28 pages (12 pages main text), 29 figures", "summary": "We propose a new interpretability method for neural networks, which is based\non a novel mathematico-philosophical theory of reasons. Our method computes a\nvector for each neuron, called its reasons vector. We then can compute how\nstrongly this reasons vector speaks for various propositions, e.g., the\nproposition that the input image depicts digit 2 or that the input prompt has a\nnegative sentiment. This yields an interpretation of neurons, and groups\nthereof, that combines a logical and a Bayesian perspective, and accounts for\npolysemanticity (i.e., that a single neuron can figure in multiple concepts).\nWe show, both theoretically and empirically, that this method is: (1) grounded\nin a philosophically established notion of explanation, (2) uniform, i.e.,\napplies to the common neural network architectures and modalities, (3)\nscalable, since computing reason vectors only involves forward-passes in the\nneural network, (4) faithful, i.e., intervening on a neuron based on its reason\nvector leads to expected changes in model output, (5) correct in that the\nmodel's reasons structure matches that of the data source, (6) trainable, i.e.,\nneural networks can be trained to improve their reason strengths, (7) useful,\ni.e., it delivers on the needs for interpretability by increasing, e.g.,\nrobustness and fairness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b0\u9896\u7684\u6570\u7406\u54f2\u5b66\u89e3\u91ca\u7406\u8bba\u7684\u65b0\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u89e3\u91ca\u5411\u91cf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u6a21\u6001\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u7406\u54f2\u5b66\u7406\u8bba\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u795e\u7ecf\u5143\u7684\u89e3\u91ca\u5411\u91cf\uff08reasons vector\uff09\uff0c\u7ed3\u5408\u903b\u8f91\u548c\u8d1d\u53f6\u65af\u89c6\u89d2\u6765\u89e3\u91ca\u795e\u7ecf\u5143\u53ca\u5176\u7ec4\u7fa4\u7684\u884c\u4e3a\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u6a21\u6001\u4e2d\u8868\u73b0\u51fa\u4e86\u7edf\u4e00\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u5fe0\u5b9e\u6027\u548c\u6b63\u786e\u6027\u7b49\u7279\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u63d0\u9ad8\u89e3\u91ca\u5f3a\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2505.14428", "pdf": "https://arxiv.org/pdf/2505.14428", "abs": "https://arxiv.org/abs/2505.14428", "authors": ["Riccardo D'Elia"], "title": "Interpretable Neural System Dynamics: Combining Deep Learning with System Dynamics Modeling to Support Critical Applications", "categories": ["cs.LG", "cs.AI"], "comment": "To be submitted to CEUR-WS.org for publication in the Doctoral\n  Consortium Proceedings of XAI 2025, The World Conference on Explainable\n  Artificial Intelligence", "summary": "The objective of this proposal is to bridge the gap between Deep Learning\n(DL) and System Dynamics (SD) by developing an interpretable neural system\ndynamics framework. While DL excels at learning complex models and making\naccurate predictions, it lacks interpretability and causal reliability.\nTraditional SD approaches, on the other hand, provide transparency and causal\ninsights but are limited in scalability and require extensive domain knowledge.\nTo overcome these limitations, this project introduces a Neural System Dynamics\npipeline, integrating Concept-Based Interpretability, Mechanistic\nInterpretability, and Causal Machine Learning. This framework combines the\npredictive power of DL with the interpretability of traditional SD models,\nresulting in both causal reliability and scalability. The efficacy of the\nproposed pipeline will be validated through real-world applications of the\nEU-funded AutoMoTIF project, which is focused on autonomous multimodal\ntransportation systems. The long-term goal is to collect actionable insights\nthat support the integration of explainability and safety in autonomous\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u53ef\u89e3\u91ca\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u56e0\u679c\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u590d\u6742\u6a21\u578b\u5b66\u4e60\u548c\u51c6\u786e\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u4f46\u7f3a\u4e4f\u89e3\u91ca\u6027\u548c\u56e0\u679c\u53ef\u9760\u6027\uff1b\u4f20\u7edf\u7cfb\u7edf\u52a8\u529b\u5b66\u65b9\u6cd5\u63d0\u4f9b\u900f\u660e\u5ea6\u548c\u56e0\u679c\u6d1e\u5bdf\u4f46\u53d7\u9650\u4e8e\u53ef\u6269\u5c55\u6027\u548c\u9700\u8981\u5927\u91cf\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u5f00\u53d1\u4e00\u79cd\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u7ba1\u9053\uff0c\u96c6\u6210\u57fa\u4e8e\u6982\u5ff5\u7684\u53ef\u89e3\u91ca\u6027\u3001\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u548c\u56e0\u679c\u673a\u5668\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u6b27\u76df\u8d44\u52a9\u7684AutoMoTIF\u9879\u76ee\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4e86\u6240\u63d0\u7ba1\u9053\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6700\u7ec8\u76ee\u6807\u662f\u6536\u96c6\u53ef\u7528\u4e8e\u652f\u6301\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u6574\u5408\u7684\u884c\u52a8\u89c1\u89e3\u3002"}}
{"id": "2505.14451", "pdf": "https://arxiv.org/pdf/2505.14451", "abs": "https://arxiv.org/abs/2505.14451", "authors": ["Md Atik Ahamed", "Qiang Ye", "Qiang Cheng"], "title": "RefiDiff: Refinement-Aware Diffusion for Efficient Missing Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Missing values in high-dimensional, mixed-type datasets pose significant\nchallenges for data imputation, particularly under Missing Not At Random (MNAR)\nmechanisms. Existing methods struggle to integrate local and global data\ncharacteristics, limiting performance in MNAR and high-dimensional settings. We\npropose an innovative framework, RefiDiff, combining local machine learning\npredictions with a novel Mamba-based denoising network capturing\ninterrelationships among distant features and samples. Our approach leverages\npre-refinement for initial warm-up imputations and post-refinement to polish\nresults, enhancing stability and accuracy. By encoding mixed-type data into\nunified tokens, RefiDiff enables robust imputation without architectural or\nhyperparameter tuning. RefiDiff outperforms state-of-the-art (SOTA) methods\nacross missing-value settings, excelling in MNAR with a 4x faster training time\nthan SOTA DDPM-based approaches. Extensive evaluations on nine real-world\ndatasets demonstrate its robustness, scalability, and effectiveness in handling\ncomplex missingness patterns.", "AI": {"tldr": "Proposes RefiDiff, a novel framework combining local ML predictions with a Mamba-based denoising network for robust imputation in high-dimensional mixed-type datasets under MNAR mechanisms.", "motivation": "Existing methods struggle to handle missing not at random (MNAR) mechanisms and high-dimensional data due to inability to integrate local and global data characteristics.", "method": "Introduces RefiDiff which uses pre-refinement for initial warm-up imputations and post-refinement for result polishing. Encodes mixed-type data into unified tokens and uses a Mamba-based denoising network to capture interrelationships among distant features and samples.", "result": "Outperforms state-of-the-art methods across missing-value settings, especially excelling in MNAR scenarios with 4x faster training time than SOTA DDPM-based approaches.", "conclusion": "RefiDiff provides robust, scalable, and effective imputation for complex missingness patterns in high-dimensional mixed-type datasets."}}
{"id": "2505.14459", "pdf": "https://arxiv.org/pdf/2505.14459", "abs": "https://arxiv.org/abs/2505.14459", "authors": ["Kamal Singh", "Sami Marouani", "Ahmad Al Sheikh", "Pham Tran Anh Quang", "Amaury Habrard"], "title": "Interpretable Reinforcement Learning for Load Balancing using Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Reinforcement learning (RL) has been increasingly applied to network control\nproblems, such as load balancing. However, existing RL approaches often suffer\nfrom lack of interpretability and difficulty in extracting controller\nequations. In this paper, we propose the use of Kolmogorov-Arnold Networks\n(KAN) for interpretable RL in network control. We employ a PPO agent with a\n1-layer actor KAN model and an MLP Critic network to learn load balancing\npolicies that maximise throughput utility, minimize loss as well as delay. Our\napproach allows us to extract controller equations from the learned neural\nnetworks, providing insights into the decision-making process. We evaluate our\napproach using different reward functions demonstrating its effectiveness in\nimproving network performance while providing interpretable policies.", "AI": {"tldr": "This paper proposes using Kolmogorov-Arnold Networks (KAN) for interpretable reinforcement learning in network control, specifically for load balancing, by employing a PPO agent with a 1-layer actor KAN model and an MLP Critic network. It demonstrates the approach's effectiveness in improving network performance and provides interpretable policies.", "motivation": "Existing RL approaches often lack interpretability and difficulty in extracting controller equations.", "method": "Proposes using Kolmogorov-Arnold Networks (KAN) for interpretable RL in network control. Employs a PPO agent with a 1-layer actor KAN model and an MLP Critic network to learn load balancing policies.", "result": "The approach allows extraction of controller equations from the learned neural networks, providing insights into the decision-making process. Demonstrates effectiveness in improving network performance while providing interpretable policies.", "conclusion": "The proposed method improves network performance and provides interpretable policies for load balancing through interpretable reinforcement learning."}}
{"id": "2505.14463", "pdf": "https://arxiv.org/pdf/2505.14463", "abs": "https://arxiv.org/abs/2505.14463", "authors": ["Xinxin Fan", "Wenxiong Chen", "Mengfan Li", "Wenqi Wei", "Ling Liu"], "title": "Adverseness vs. Equilibrium: Exploring Graph Adversarial Resilience through Dynamic Equilibrium", "categories": ["cs.LG"], "comment": null, "summary": "Adversarial attacks to graph analytics are gaining increased attention. To\ndate, two lines of countermeasures have been proposed to resist various graph\nadversarial attacks from the perspectives of either graph per se or graph\nneural networks. Nevertheless, a fundamental question lies in whether there\nexists an intrinsic adversarial resilience state within a graph regime and how\nto find out such a critical state if exists. This paper contributes to tackle\nthe above research questions from three unique perspectives: i) we regard the\nprocess of adversarial learning on graph as a complex multi-object dynamic\nsystem, and model the behavior of adversarial attack; ii) we propose a\ngeneralized theoretical framework to show the existence of critical adversarial\nresilience state; and iii) we develop a condensed one-dimensional function to\ncapture the dynamic variation of graph regime under perturbations, and pinpoint\nthe critical state through solving the equilibrium point of dynamic system.\nMulti-facet experiments are conducted to show our proposed approach can\nsignificantly outperform the state-of-the-art defense methods under five\ncommonly-used real-world datasets and three representative attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u5b9a\u56fe\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u4e34\u754c\u72b6\u6001\u3002", "motivation": "\u7814\u7a76\u56fe\u5bf9\u6297\u653b\u51fb\u7684\u5185\u5728\u9c81\u68d2\u6027\u72b6\u6001\u662f\u5426\u5b58\u5728\u4ee5\u53ca\u5982\u4f55\u627e\u5230\u5b83\u3002", "method": "\u5c06\u56fe\u4e0a\u7684\u5bf9\u6297\u5b66\u4e60\u5efa\u6a21\u4e3a\u590d\u6742\u591a\u76ee\u6807\u52a8\u6001\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49\u7406\u8bba\u6846\u67b6\u548c\u4e00\u7ef4\u51fd\u6570\u6765\u6355\u6349\u56fe\u5728\u6270\u52a8\u4e0b\u7684\u52a8\u6001\u53d8\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e94\u4e2a\u5e38\u7528\u7684\u771f\u5b9e\u6570\u636e\u96c6\u548c\u4e09\u79cd\u4ee3\u8868\u6027\u653b\u51fb\u4e0b\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u8bc1\u660e\u4e86\u56fe\u5bf9\u6297\u9c81\u68d2\u6027\u5b58\u5728\u4e34\u754c\u72b6\u6001\uff0c\u5e76\u63d0\u4f9b\u4e86\u627e\u5230\u8be5\u72b6\u6001\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.14468", "pdf": "https://arxiv.org/pdf/2505.14468", "abs": "https://arxiv.org/abs/2505.14468", "authors": ["Yifan Sui", "Hao Wang", "Hanfei Yu", "Yitao Hu", "Jianxun Li", "Hao Wang"], "title": "ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Serverless computing has grown rapidly for serving Large Language Model (LLM)\ninference due to its pay-as-you-go pricing, fine-grained GPU usage, and rapid\nscaling. However, our analysis reveals that current serverless can effectively\nserve general LLM but fail with Low-Rank Adaptation (LoRA) inference due to\nthree key limitations: 1) massive parameter redundancy among functions where\n99% of weights are unnecessarily duplicated, 2) costly artifact loading latency\nbeyond LLM loading, and 3) magnified resource contention when serving multiple\nLoRA LLMs. These inefficiencies lead to massive GPU wastage, increased\nTime-To-First-Token (TTFT), and high monetary costs.\n  We propose ServerlessLoRA, a novel serverless inference system designed for\nfaster and cheaper LoRA LLM serving. ServerlessLoRA enables secure backbone LLM\nsharing across isolated LoRA functions to reduce redundancy. We design a\npre-loading method that pre-loads comprehensive LoRA artifacts to minimize\ncold-start latency. Furthermore, ServerlessLoRA employs contention aware\nbatching and offloading to mitigate GPU resource conflicts during bursty\nworkloads. Experiment on industrial workloads demonstrates that ServerlessLoRA\nreduces TTFT by up to 86% and cuts monetary costs by up to 89% compared to\nstate-of-the-art LLM inference solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edfServerlessLoRA\uff0c\u7528\u4e8e\u52a0\u901f\u548c\u964d\u4f4e\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u670d\u52a1\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u5171\u4eab\u9aa8\u5e72\u6a21\u578b\u3001\u9884\u52a0\u8f7d\u548c\u8d44\u6e90\u7ba1\u7406\u6280\u672f\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u65f6\u95f4\u5230\u7b2c\u4e00\u4e2a\u4ee4\u724c(TTFT)\u548c\u8d27\u5e01\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u7684\u670d\u52a1\u5668less\u8ba1\u7b97\u5728\u5904\u7406\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u63a8\u7406\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406LoRA\u63a8\u7406\u65f6\u7531\u4e8e\u5197\u4f59\u53c2\u6570\u3001\u52a0\u8f7d\u5ef6\u8fdf\u548c\u8d44\u6e90\u4e89\u7528\u7b49\u95ee\u9898\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u670d\u52a1\u5668less\u63a8\u7406\u7cfb\u7edfServerlessLoRA\uff0c\u5305\u62ec\u9aa8\u5e72\u6a21\u578b\u5171\u4eab\u3001\u9884\u52a0\u8f7d\u65b9\u6cd5\u548c\u7ade\u4e89\u611f\u77e5\u7684\u6279\u5904\u7406\u4e0e\u5378\u8f7d\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684LLM\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0cServerlessLoRA\u5c06TTFT\u51cf\u5c11\u4e86\u9ad8\u8fbe86%\uff0c\u5e76\u5c06\u8d27\u5e01\u6210\u672c\u964d\u4f4e\u4e86\u9ad8\u8fbe89%\u3002", "conclusion": "ServerlessLoRA\u662f\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LoRA LLM\u63a8\u7406\u7684\u6548\u7387\u548c\u7ecf\u6d4e\u6027\u3002"}}
{"id": "2505.14477", "pdf": "https://arxiv.org/pdf/2505.14477", "abs": "https://arxiv.org/abs/2505.14477", "authors": ["Maria Panagiotou", "Lorenzo Brigato", "Vivien Streit", "Amanda Hayoz", "Stephan Proennecke", "Stavros Athanasopoulos", "Mikkel T. Olsen", "Elizabeth J. den Brok", "Cecilie H. Svensson", "Konstantinos Makrilakis", "Maria Xatzipsalti", "Andriani Vazeou", "Peter R. Mertens", "Ulrik Pedersen-Bjergaard", "Bastiaan E. de Galan", "Stavroula Mougiakakou"], "title": "Personalised Insulin Adjustment with Reinforcement Learning: An In-Silico Validation for People with Diabetes on Intensive Insulin Treatment", "categories": ["cs.LG"], "comment": null, "summary": "Despite recent advances in insulin preparations and technology, adjusting\ninsulin remains an ongoing challenge for the majority of people with type 1\ndiabetes (T1D) and longstanding type 2 diabetes (T2D). In this study, we\npropose the Adaptive Basal-Bolus Advisor (ABBA), a personalised insulin\ntreatment recommendation approach based on reinforcement learning for\nindividuals with T1D and T2D, performing self-monitoring blood glucose\nmeasurements and multiple daily insulin injection therapy. We developed and\nevaluated the ability of ABBA to achieve better time-in-range (TIR) for\nindividuals with T1D and T2D, compared to a standard basal-bolus advisor (BBA).\nThe in-silico test was performed using an FDA-accepted population, including\n101 simulated adults with T1D and 101 with T2D. An in-silico evaluation shows\nthat ABBA significantly improved TIR and significantly reduced both times\nbelow- and above-range, compared to BBA. ABBA's performance continued to\nimprove over two months, whereas BBA exhibited only modest changes. This\npersonalised method for adjusting insulin has the potential to further optimise\nglycaemic control and support people with T1D and T2D in their daily\nself-management. Our results warrant ABBA to be trialed for the first time in\nhumans.", "AI": {"tldr": "This study proposes ABBA, a personalized insulin treatment recommendation approach using reinforcement learning, which improves time-in-range and reduces time spent out-of-range compared to a standard basal-bolus advisor for individuals with T1D and T2D.", "motivation": "Adjusting insulin remains challenging for many people with type 1 and type 2 diabetes despite advancements in insulin preparations and technology.", "method": "Developed and evaluated ABBA, a personalized insulin treatment recommendation approach based on reinforcement learning, compared to a standard basal-bolus advisor using in-silico tests.", "result": "ABBA significantly improved time-in-range and reduced time spent below and above range compared to BBA. ABBA's performance improved over two months while BBA showed modest changes.", "conclusion": "ABBA has the potential to optimize glycemic control and support daily self-management for individuals with T1D and T2D, warranting human trials."}}
{"id": "2505.14502", "pdf": "https://arxiv.org/pdf/2505.14502", "abs": "https://arxiv.org/abs/2505.14502", "authors": ["Wenze Liu", "Xiangyu Yue"], "title": "Learning to Integrate Diffusion ODEs by Averaging the Derivatives", "categories": ["cs.LG"], "comment": null, "summary": "To accelerate diffusion model inference, numerical solvers perform poorly at\nextremely small steps, while distillation techniques often introduce complexity\nand instability. This work presents an intermediate strategy, balancing\nperformance and cost, by learning ODE integration using loss functions derived\nfrom the derivative-integral relationship, inspired by Monte Carlo integration\nand Picard iteration. From a geometric perspective, the losses operate by\ngradually extending the tangent to the secant, thus are named as secant losses.\nThe secant losses can rapidly convert (via fine-tuning or distillation) a\npretrained diffusion model into its secant version. In our experiments, the\nsecant version of EDM achieves a $10$-step FID of $2.14$ on CIFAR-10, while the\nsecant version of SiT-XL/2 attains a $4$-step FID of $2.27$ and an $8$-step FID\nof $1.96$ on ImageNet-$256\\times256$. Code will be available.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e2d\u95f4\u7b56\u7565\uff0c\u901a\u8fc7\u5b66\u4e60ODE\u79ef\u5206\u6765\u52a0\u901f\u6269\u6563\u6a21\u578b\u63a8\u7406\uff0c\u6027\u80fd\u548c\u6210\u672c\u5e73\u8861\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728CIFAR-10\u548cImageNet\u4e0a\u7684\u663e\u8457\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5728\u6781\u5c0f\u6b65\u957f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u84b8\u998f\u6280\u672f\u5e38\u5f15\u5165\u590d\u6742\u6027\u548c\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u5229\u7528\u6e90\u81ea\u5bfc\u6570-\u79ef\u5206\u5173\u7cfb\u7684\u635f\u5931\u51fd\u6570\u5b66\u4e60ODE\u79ef\u5206\uff0c\u4ece\u51e0\u4f55\u89d2\u5ea6\u5b9a\u4e49\u8fd9\u4e9b\u635f\u5931\u4e3a\u5207\u7ebf\u9010\u6e10\u5ef6\u4f38\u5230\u5272\u7ebf\u7684secant losses\u3002", "result": "secant\u7248\u672c\u5728CIFAR-10\u4e0a\u8fbe\u523010\u6b65FID 2.14\uff0c\u5728ImageNet\u4e0a\u8fbe\u52304\u6b65FID 2.27\u548c8\u6b65FID 1.96\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684secant losses\u80fd\u6709\u6548\u52a0\u901f\u6269\u6563\u6a21\u578b\u63a8\u7406\u5e76\u4fdd\u6301\u9ad8\u6027\u80fd\u3002"}}
{"id": "2505.14513", "pdf": "https://arxiv.org/pdf/2505.14513", "abs": "https://arxiv.org/abs/2505.14513", "authors": ["Yen-Chen Wu", "Feng-Ting Liao", "Meng-Hsi Chen", "Pei-Chen Ho", "Farhang Nabiei", "Da-shan Shiu"], "title": "Latent Flow Transformer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers, the standard implementation for large language models (LLMs),\ntypically consist of tens to hundreds of discrete layers. While more layers can\nlead to better performance, this approach has been challenged as far from\nefficient, especially given the superiority of continuous layers demonstrated\nby diffusion and flow-based models for image generation. We propose the Latent\nFlow Transformer (LFT), which replaces a block of layers with a single learned\ntransport operator trained via flow matching, offering significant compression\nwhile maintaining compatibility with the original architecture. Additionally,\nwe address the limitations of existing flow-based methods in \\textit{preserving\ncoupling} by introducing the Flow Walking (FW) algorithm. On the Pythia-410M\nmodel, LFT trained with flow matching compresses 6 of 24 layers and outperforms\ndirectly skipping 2 layers (KL Divergence of LM logits at 0.407 vs. 0.529),\ndemonstrating the feasibility of this design. When trained with FW, LFT further\ndistills 12 layers into one while reducing the KL to 0.736 surpassing that from\nskipping 3 layers (0.932), significantly narrowing the gap between\nautoregressive and flow-based generation paradigms.", "AI": {"tldr": "A new method called Latent Flow Transformer (LFT) is proposed to replace multiple layers in transformers with a single learned transport operator for better compression.", "motivation": "Existing transformer architectures have many discrete layers which are not efficient. Continuous layers have shown better performance in other models.", "method": "The LFT uses flow matching to train a transport operator instead of multiple layers. A new algorithm called Flow Walking is introduced to address limitations in preserving coupling.", "result": "LFT trained with flow matching compresses 6 out of 24 layers and outperforms skipping 2 layers. With Flow Walking, it further distills 12 layers into one.", "conclusion": "This study shows the feasibility of replacing multiple layers with a single operator in transformers."}}
{"id": "2505.14522", "pdf": "https://arxiv.org/pdf/2505.14522", "abs": "https://arxiv.org/abs/2505.14522", "authors": ["Mahmuda Akhter Nishu", "Chenyu Huang", "Milad Roohi", "Xin Zhong"], "title": "Interpretable Dual-Stream Learning for Local Wind Hazard Prediction in Vulnerable Communities", "categories": ["cs.LG"], "comment": null, "summary": "Wind hazards such as tornadoes and straight-line winds frequently affect\nvulnerable communities in the Great Plains of the United States, where limited\ninfrastructure and sparse data coverage hinder effective emergency response.\nExisting forecasting systems focus primarily on meteorological elements and\noften fail to capture community-specific vulnerabilities, limiting their\nutility for localized risk assessment and resilience planning. To address this\ngap, we propose an interpretable dual-stream learning framework that integrates\nstructured numerical weather data with unstructured textual event narratives.\nOur architecture combines a Random Forest and RoBERTa-based transformer through\na late fusion mechanism, enabling robust and context-aware wind hazard\nprediction. The system is tailored for underserved tribal communities and\nsupports block-level risk assessment. Experimental results show significant\nperformance gains over traditional baselines. Furthermore, gradient-based\nsensitivity and ablation studies provide insight into the model's\ndecision-making process, enhancing transparency and operational trust. The\nfindings demonstrate both predictive effectiveness and practical value in\nsupporting emergency preparedness and advancing community resilience.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u5929\u6c14\u6570\u636e\u548c\u4e8b\u4ef6\u53d9\u8ff0\uff0c\u7528\u4e8e\u98ce\u707e\u9884\u6d4b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u670d\u52a1\u4e0d\u8db3\u7684\u90e8\u843d\u793e\u533a\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u6c14\u8c61\u8981\u7d20\uff0c\u672a\u80fd\u6355\u6349\u7279\u5b9a\u793e\u533a\u7684\u8106\u5f31\u6027\uff0c\u5f71\u54cd\u5e94\u6025\u54cd\u5e94\u548c\u97e7\u6027\u89c4\u5212\u3002", "method": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u665a\u671f\u878d\u5408\u673a\u5236\u6574\u5408\u6570\u503c\u5929\u6c14\u6570\u636e\u4e0e\u6587\u672c\u4e8b\u4ef6\u53d9\u8ff0\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u548cRoBERTa\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u4f20\u7edf\u57fa\u7ebf\u4e0a\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u901a\u8fc7\u654f\u611f\u6027\u548c\u6d88\u878d\u7814\u7a76\u589e\u5f3a\u4e86\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u9884\u6d4b\u7684\u6709\u6548\u6027\u548c\u652f\u6301\u5e94\u6025\u51c6\u5907\u53ca\u793e\u533a\u97e7\u6027\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2505.14533", "pdf": "https://arxiv.org/pdf/2505.14533", "abs": "https://arxiv.org/abs/2505.14533", "authors": ["Mohammad Irfan Uddin", "Nishad Tasnim", "Md Omor Faruk", "Zejian Zhou"], "title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Agent-based Transformers have been widely adopted in recent reinforcement\nlearning advances due to their demonstrated ability to solve complex tasks.\nHowever, the high computational complexity of Transformers often results in\nsignificant energy consumption, limiting their deployment in real-world\nautonomous systems. Spiking neural networks (SNNs), with their biologically\ninspired structure, offer an energy-efficient alternative for machine learning.\nIn this paper, a novel Spike-Transformer Reinforcement Learning (STRL)\nalgorithm that combines the energy efficiency of SNNs with the powerful\ndecision-making capabilities of reinforcement learning is developed.\nSpecifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons\nand attention mechanisms capable of processing spatio-temporal patterns over\nmultiple time steps is designed. The architecture is further enhanced with\nstate, action, and reward encodings to create a Transformer-like structure\noptimized for reinforcement learning tasks. Comprehensive numerical experiments\nconducted on state-of-the-art benchmarks demonstrate that the proposed SNN\nTransformer achieves significantly improved policy performance compared to\nconventional agent-based Transformers. With both enhanced energy efficiency and\npolicy optimality, this work highlights a promising direction for deploying\nbio-inspired, low-cost machine learning models in complex real-world\ndecision-making scenarios.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684STRL\u7b97\u6cd5\uff0c\u5b83\u7ed3\u5408\u4e86SNN\u7684\u80fd\u6548\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u653f\u7b56\u6027\u80fd\u548c\u80fd\u6548\u4e0a\u90fd\u4f18\u4e8e\u4f20\u7edfTransformer\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4ee3\u7406\u7684Transformer\u867d\u7136\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u5bfc\u81f4\u663e\u8457\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u9650\u5236\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u5229\u7528\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNNs)\u7684\u751f\u7269\u542f\u53d1\u7ed3\u6784\u6765\u63d0\u4f9b\u4e00\u79cd\u66f4\u8282\u80fd\u7684\u5b66\u4e60\u65b9\u5f0f\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4f7f\u7528\u591a\u6b65\u6cc4\u6f0f\u79ef\u5206\u4e0e\u53d1\u5c04\uff08LIF\uff09\u795e\u7ecf\u5143\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684SNN\uff0c\u5e76\u901a\u8fc7\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u5956\u52b1\u7f16\u7801\u589e\u5f3a\u4e86\u67b6\u6784\uff0c\u5f62\u6210\u4e86\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4f18\u5316\u7684Transformer\u7ed3\u6784\u3002", "result": "\u63d0\u51fa\u7684SNN Transformer\u5728\u4e00\u7cfb\u5217\u6700\u5148\u8fdb\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u6539\u8fdb\u7684\u653f\u7b56\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u80fd\u6548\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SNN\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u52bf\u7684STRL\u7b97\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u653f\u7b56\u8868\u73b0\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u57fa\u4e8e\u4ee3\u7406\u7684Transformer\u6a21\u578b\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u80fd\u6548\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u573a\u666f\u4e2d\u90e8\u7f72\u7c7b\u751f\u7269\u7684\u4f4e\u6210\u672c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6307\u660e\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2505.14531", "pdf": "https://arxiv.org/pdf/2505.14531", "abs": "https://arxiv.org/abs/2505.14531", "authors": ["Shaoye Luo", "Xinxin Fan", "Quanliang Jing", "Chi Lin", "Mengfan Li", "Yunfeng Lu", "Yongjun Xu"], "title": "SifterNet: A Generalized and Model-Agnostic Trigger Purification Approach", "categories": ["cs.LG"], "comment": null, "summary": "Aiming at resisting backdoor attacks in convolution neural networks and\nvision Transformer-based large model, this paper proposes a generalized and\nmodel-agnostic trigger-purification approach resorting to the classic Ising\nmodel. To date, existing trigger detection/removal studies usually require to\nknow the detailed knowledge of target model in advance, access to a large\nnumber of clean samples or even model-retraining authorization, which brings\nthe huge inconvenience for practical applications, especially inaccessible to\ntarget model. An ideal countermeasure ought to eliminate the implanted trigger\nwithout regarding whatever the target models are. To this end, a lightweight\nand black-box defense approach SifterNet is proposed through leveraging the\nmemorization-association functionality of Hopfield network, by which the\ntriggers of input samples can be effectively purified in a proper manner. The\nmain novelty of our proposed approach lies in the introduction of ideology of\nIsing model. Extensive experiments also validate the effectiveness of our\napproach in terms of proper trigger purification and high accuracy achievement,\nand compared to the state-of-the-art baselines under several commonly-used\ndatasets, our SiferNet has a significant superior performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u5178\u4f0a\u8f9b\u6a21\u578b\u7684\u901a\u7528\u89e6\u53d1\u51c0\u5316\u65b9\u6cd5SifterNet\uff0c\u7528\u4e8e\u62b5\u6297\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u89c6\u89c9Transformer\u5927\u6a21\u578b\u4e2d\u7684\u540e\u95e8\u653b\u51fb\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u63d0\u524d\u4e86\u89e3\u76ee\u6807\u6a21\u578b\u8be6\u7ec6\u4fe1\u606f\u6216\u8bbf\u95ee\u5927\u91cf\u6e05\u6d01\u6837\u672c\uff0c\u5177\u6709\u8f7b\u91cf\u7ea7\u548c\u9ed1\u76d2\u9632\u5fa1\u7279\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89e6\u53d1\u68c0\u6d4b/\u79fb\u9664\u7814\u7a76\u901a\u5e38\u9700\u8981\u63d0\u524d\u4e86\u89e3\u76ee\u6807\u6a21\u578b\u8be6\u7ec6\u4fe1\u606f\u3001\u8bbf\u95ee\u5927\u91cf\u6e05\u6d01\u6837\u672c\u751a\u81f3\u6a21\u578b\u91cd\u8bad\u7ec3\u6388\u6743\uff0c\u7ed9\u5b9e\u9645\u5e94\u7528\u5e26\u6765\u4e0d\u4fbf\uff0c\u5c24\u5176\u662f\u65e0\u6cd5\u8bbf\u95ee\u76ee\u6807\u6a21\u578b\u65f6\u3002\u7406\u60f3\u5bf9\u7b56\u5e94\u80fd\u6d88\u9664\u690d\u5165\u7684\u89e6\u53d1\u5668\u800c\u4e0d\u8003\u8651\u4efb\u4f55\u76ee\u6807\u6a21\u578b\u3002", "method": "\u5229\u7528\u970d\u666e\u83f2\u5c14\u5fb7\u7f51\u7edc\u7684\u8bb0\u5fc6\u5173\u8054\u529f\u80fd\uff0c\u901a\u8fc7\u5f15\u5165\u4f0a\u8f9b\u6a21\u578b\u7684\u601d\u60f3\uff0c\u63d0\u51fa\u4e86\u8f7b\u91cf\u7ea7\u9ed1\u76d2\u9632\u5fa1\u65b9\u6cd5SifterNet\uff0c\u5bf9\u8f93\u5165\u6837\u672c\u7684\u89e6\u53d1\u5668\u8fdb\u884c\u6709\u6548\u51c0\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u89e6\u53d1\u5668\u51c0\u5316\u548c\u9ad8\u7cbe\u5ea6\u5b9e\u73b0\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e14\u5728\u51e0\u79cd\u5e38\u7528\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cSifterNet\u8868\u73b0\u51fa\u663e\u8457\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7ecf\u5178\u4f0a\u8f9b\u6a21\u578b\u7684\u901a\u7528\u89e6\u53d1\u51c0\u5316\u65b9\u6cd5SifterNet\uff0c\u7528\u4e8e\u62b5\u5fa1\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u89c6\u89c9Transformer\u5927\u6a21\u578b\u4e2d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u8f7b\u91cf\u7ea7\u548c\u9ed1\u76d2\u9632\u5fa1\u7279\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.14555", "pdf": "https://arxiv.org/pdf/2505.14555", "abs": "https://arxiv.org/abs/2505.14555", "authors": ["Yingtao Luo", "Shikai Fang", "Binqing Wu", "Qingsong Wen", "Liang Sun"], "title": "Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Published/Accepted in KDD 2025 (February Cycle)", "summary": "Weather forecasting is essential but remains computationally intensive and\nphysically incomplete in traditional numerical weather prediction (NWP)\nmethods. Deep learning (DL) models offer efficiency and accuracy but often\nignore physical laws, limiting interpretability and generalization. We propose\nPhyDL-NWP, a physics-guided deep learning framework that integrates physical\nequations with latent force parameterization into data-driven models. It\npredicts weather variables from arbitrary spatiotemporal coordinates, computes\nphysical terms via automatic differentiation, and uses a physics-informed loss\nto align predictions with governing dynamics. PhyDL-NWP enables resolution-free\ndownscaling by modeling weather as a continuous function and fine-tunes\npre-trained models with minimal overhead, achieving up to 170x faster inference\nwith only 55K parameters. Experiments show that PhyDL-NWP improves both\nforecasting performance and physical consistency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u5b9a\u5f8b\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u5929\u6c14\u9884\u62a5\u6846\u67b6PhyDL-NWP\uff0c\u5b83\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u548c\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u5b9e\u73b0\u65e0\u5206\u8fa8\u7387\u7f29\u653e\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u65b9\u6cd5\u8ba1\u7b97\u5bc6\u96c6\u4e14\u4e0d\u5b8c\u6574\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u7136\u9ad8\u6548\u51c6\u786e\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aPhyDL-NWP\u7684\u7269\u7406\u5f15\u5bfc\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6f5c\u5728\u529b\u53c2\u6570\u5316\u6574\u5408\u7269\u7406\u65b9\u7a0b\u5230\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e2d\uff0c\u5e76\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u635f\u5931\u6765\u5bf9\u9f50\u9884\u6d4b\u4e0e\u63a7\u5236\u52a8\u529b\u5b66\u3002", "result": "PhyDL-NWP\u5b9e\u73b0\u4e86\u9ad8\u8fbe170\u500d\u7684\u63a8\u7406\u52a0\u901f\uff0c\u4ec5\u970055K\u53c2\u6570\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002", "conclusion": "PhyDL-NWP\u5c55\u793a\u4e86\u5728\u4fdd\u6301\u9ad8\u6548\u7387\u7684\u540c\u65f6\u589e\u5f3a\u5929\u6c14\u9884\u62a5\u7684\u7269\u7406\u4e00\u81f4\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.14564", "pdf": "https://arxiv.org/pdf/2505.14564", "abs": "https://arxiv.org/abs/2505.14564", "authors": ["David Krame Kadurha", "Domini Jocema Leko Moutouo", "Yae Ulrich Gaba"], "title": "Bellman operator convergence enhancements in reinforcement learning algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper reviews the topological groundwork for the study of reinforcement\nlearning (RL) by focusing on the structure of state, action, and policy spaces.\nWe begin by recalling key mathematical concepts such as complete metric spaces,\nwhich form the foundation for expressing RL problems. By leveraging the Banach\ncontraction principle, we illustrate how the Banach fixed-point theorem\nexplains the convergence of RL algorithms and how Bellman operators, expressed\nas operators on Banach spaces, ensure this convergence. The work serves as a\nbridge between theoretical mathematics and practical algorithm design, offering\nnew approaches to enhance the efficiency of RL. In particular, we investigate\nalternative formulations of Bellman operators and demonstrate their impact on\nimproving convergence rates and performance in standard RL environments such as\nMountainCar, CartPole, and Acrobot. Our findings highlight how a deeper\nmathematical understanding of RL can lead to more effective algorithms for\ndecision-making problems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u62d3\u6251\u57fa\u7840\uff0c\u805a\u7126\u4e8e\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u7b56\u7565\u7a7a\u95f4\u7684\u7ed3\u6784\u3002\u901a\u8fc7\u5229\u7528Banach\u4e0d\u52a8\u70b9\u5b9a\u7406\u4e0eBellman\u7b97\u5b50\uff0c\u89e3\u91ca\u4e86RL\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u6536\u655b\u7387\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5c24\u5176\u662f\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u7b56\u7565\u7a7a\u95f4\u7684\u7ed3\u6784\uff0c\u4ee5\u63d0\u9ad8\u7b97\u6cd5\u6548\u7387\u3002", "method": "\u56de\u987e\u4e86\u5173\u952e\u7684\u6570\u5b66\u6982\u5ff5\u5982\u5b8c\u5907\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5e76\u5229\u7528Banach\u4e0d\u52a8\u70b9\u5b9a\u7406\u548cBellman\u7b97\u5b50\u6765\u8bc1\u660eRL\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u66ff\u4ee3\u5f62\u5f0f\u7684Bellman\u7b97\u5b50\uff0c\u5e76\u5728MountainCar\u3001CartPole\u548cAcrobot\u7b49\u6807\u51c6\u73af\u5883\u4e2d\u5c55\u793a\u4e86\u5176\u5bf9\u63d0\u5347\u6536\u655b\u7387\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u6df1\u5165\u7406\u89e3\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b66\u57fa\u7840\u53ef\u4ee5\u5f00\u53d1\u51fa\u66f4\u6709\u6548\u7684\u51b3\u7b56\u95ee\u9898\u6c42\u89e3\u7b97\u6cd5\u3002"}}
{"id": "2505.14535", "pdf": "https://arxiv.org/pdf/2505.14535", "abs": "https://arxiv.org/abs/2505.14535", "authors": ["Jiangrong Shen", "Yulin Xie", "Qi Xu", "Gang Pan", "Huajin Tang", "Badong Chen"], "title": "Spiking Neural Networks with Temporal Attention-Guided Adaptive Fusion for imbalanced Multi-modal Learning", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Multimodal spiking neural networks (SNNs) hold significant potential for\nenergy-efficient sensory processing but face critical challenges in modality\nimbalance and temporal misalignment. Current approaches suffer from\nuncoordinated convergence speeds across modalities and static fusion mechanisms\nthat ignore time-varying cross-modal interactions. We propose the temporal\nattention-guided adaptive fusion framework for multimodal SNNs with two\nsynergistic innovations: 1) The Temporal Attention-guided Adaptive Fusion\n(TAAF) module that dynamically assigns importance scores to fused spiking\nfeatures at each timestep, enabling hierarchical integration of temporally\nheterogeneous spike-based features; 2) The temporal adaptive balanced fusion\nloss that modulates learning rates per modality based on the above attention\nscores, preventing dominant modalities from monopolizing optimization. The\nproposed framework implements adaptive fusion, especially in the temporal\ndimension, and alleviates the modality imbalance during multimodal learning,\nmimicking cortical multisensory integration principles. Evaluations on CREMA-D,\nAVE, and EAD datasets demonstrate state-of-the-art performance (77.55\\%,\n70.65\\% and 97.5\\%accuracy, respectively) with energy efficiency. The system\nresolves temporal misalignment through learnable time-warping operations and\nfaster modality convergence coordination than baseline SNNs. This work\nestablishes a new paradigm for temporally coherent multimodal learning in\nneuromorphic systems, bridging the gap between biological sensory processing\nand efficient machine intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u6ce8\u610f\u529b\u5f15\u5bfc\u81ea\u9002\u5e94\u878d\u5408\u6846\u67b6(TAAF)\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u5c16\u5cf0\u795e\u7ecf\u7f51\u7edc(SNNs)\uff0c\u89e3\u51b3\u4e86\u6a21\u6001\u4e0d\u5e73\u8861\u548c\u65f6\u95f4\u9519\u4f4d\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001SNN\u65b9\u6cd5\u5b58\u5728\u8de8\u6a21\u6001\u6536\u655b\u901f\u5ea6\u4e0d\u534f\u8c03\u548c\u9759\u6001\u878d\u5408\u673a\u5236\u5ffd\u89c6\u65f6\u53d8\u8de8\u6a21\u6001\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7684\u65f6\u95f4\u6ce8\u610f\u529b\u5f15\u5bfc\u81ea\u9002\u5e94\u878d\u5408\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u534f\u540c\u521b\u65b0\uff1a1) \u65f6\u95f4\u6ce8\u610f\u529b\u5f15\u5bfc\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\uff1b2) \u57fa\u4e8e\u4e0a\u8ff0\u6ce8\u610f\u5206\u6570\u7684\u65f6\u95f4\u81ea\u9002\u5e94\u5e73\u8861\u878d\u5408\u635f\u5931\u3002", "result": "\u5728CREMA-D\u3001AVE\u548cEAD\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd(\u5206\u522b\u4e3a77.55%\u300170.65%\u548c97.5%\u7684\u51c6\u786e\u7387)\uff0c\u5e76\u4e14\u5177\u6709\u80fd\u91cf\u6548\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7c7b\u8111\u7cfb\u7edf\u4e2d\u7684\u65f6\u95f4\u4e00\u81f4\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u5f25\u5408\u4e86\u751f\u7269\u611f\u89c9\u5904\u7406\u4e0e\u9ad8\u6548\u673a\u5668\u667a\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2505.14566", "pdf": "https://arxiv.org/pdf/2505.14566", "abs": "https://arxiv.org/abs/2505.14566", "authors": ["Andrei Cozma", "Landon Harris", "Hairong Qi"], "title": "KIPPO: Koopman-Inspired Proximal Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for IJCAI 2025. This arXiv submission is the full version of\n  the conference paper, including the appendix and supplementary material\n  omitted from the IJCAI proceedings", "summary": "Reinforcement Learning (RL) has made significant strides in various domains,\nand policy gradient methods like Proximal Policy Optimization (PPO) have gained\npopularity due to their balance in performance, training stability, and\ncomputational efficiency. These methods directly optimize policies through\ngradient-based updates. However, developing effective control policies for\nenvironments with complex and non-linear dynamics remains a challenge. High\nvariance in gradient estimates and non-convex optimization landscapes often\nlead to unstable learning trajectories. Koopman Operator Theory has emerged as\na powerful framework for studying non-linear systems through an\ninfinite-dimensional linear operator that acts on a higher-dimensional space of\nmeasurement functions. In contrast with their non-linear counterparts, linear\nsystems are simpler, more predictable, and easier to analyze. In this paper, we\npresent Koopman-Inspired Proximal Policy Optimization (KIPPO), which learns an\napproximately linear latent-space representation of the underlying system's\ndynamics while retaining essential features for effective policy learning. This\nis achieved through a Koopman-approximation auxiliary network that can be added\nto the baseline policy optimization algorithms without altering the\narchitecture of the core policy or value function. Extensive experimental\nresults demonstrate consistent improvements over the PPO baseline with 6-60%\nincreased performance while reducing variability by up to 91% when evaluated on\nvarious continuous control tasks.", "AI": {"tldr": "This paper introduces KIPPO, which enhances PPO by using a Koopman-approximation auxiliary network to learn a linear latent-space representation of system dynamics, improving performance and stability in continuous control tasks.", "motivation": "To address the challenges of unstable learning trajectories and high variance in gradient estimates when using policy gradient methods in environments with complex non-linear dynamics.", "method": "Developing Koopman-Inspired Proximal Policy Optimization (KIPPO) by adding a Koopman-approximation auxiliary network to standard policy optimization algorithms.", "result": "Consistent improvement over PPO baseline with 6-60% increased performance and up to 91% reduction in variability in various continuous control tasks.", "conclusion": "KIPPO effectively learns a linear latent-space representation, enhancing both performance and stability of policy gradient methods in complex environments."}}
{"id": "2505.14543", "pdf": "https://arxiv.org/pdf/2505.14543", "abs": "https://arxiv.org/abs/2505.14543", "authors": ["Utsav Dutta", "Sina Khoshfetrat Pakazad", "Henrik Ohlsson"], "title": "Time to Embed: Unlocking Foundation Models for Time Series with Channel Descriptions", "categories": ["cs.LG"], "comment": null, "summary": "Traditional time series models are task-specific and often depend on\ndataset-specific training and extensive feature engineering. While\nTransformer-based architectures have improved scalability, foundation models,\ncommonplace in text, vision, and audio, remain under-explored for time series\nand are largely restricted to forecasting. We introduce $\\textbf{CHARM}$, a\nfoundation embedding model for multivariate time series that learns shared,\ntransferable, and domain-aware representations. To address the unique\ndifficulties of time series foundation learning, $\\textbf{CHARM}$ incorporates\narchitectural innovations that integrate channel-level textual descriptions\nwhile remaining invariant to channel order. The model is trained using a Joint\nEmbedding Predictive Architecture (JEPA), with novel augmentation schemes and a\nloss function designed to improve interpretability and training stability. Our\n$7$M-parameter model achieves state-of-the-art performance across diverse\ndownstream tasks, setting a new benchmark for time series representation\nlearning.", "AI": {"tldr": "\u6211\u4eec\u4ecb\u7ecd\u4e86CHARM\uff0c\u4e00\u4e2a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u57fa\u7840\u5d4c\u5165\u6a21\u578b\uff0c\u5b83\u5b66\u4e60\u5171\u4eab\u3001\u53ef\u8f6c\u79fb\u548c\u9886\u57df\u611f\u77e5\u7684\u8868\u793a\u3002CHARM\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u662f\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\uff0c\u5e76\u4e14\u5e38\u5e38\u4f9d\u8d56\u4e8e\u6570\u636e\u96c6\u7279\u5b9a\u7684\u8bad\u7ec3\u548c\u5e7f\u6cdb\u7684\u7279\u5f81\u5de5\u7a0b\u3002\u867d\u7136\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u6587\u672c\u3001\u89c6\u89c9\u548c\u97f3\u9891\u4e2d\u7684\u57fa\u7840\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u5e76\u4e14\u4e3b\u8981\u5c40\u9650\u4e8e\u9884\u6d4b\u3002", "method": "CHARM\u5305\u542b\u67b6\u6784\u521b\u65b0\uff0c\u7ed3\u5408\u4e86\u901a\u9053\u7ea7\u6587\u672c\u63cf\u8ff0\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u901a\u9053\u987a\u5e8f\u7684\u4e0d\u53d8\u6027\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\uff08JEPA\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u5177\u6709\u65b0\u9896\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6848\u548c\u635f\u5931\u51fd\u6570\uff0c\u65e8\u5728\u63d0\u9ad8\u89e3\u91ca\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u6211\u4eec\u76847M\u53c2\u6570\u6a21\u578b\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "conclusion": "CHARM\u662f\u4e00\u79cd\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u57fa\u7840\u5d4c\u5165\u6a21\u578b\uff0c\u5b83\u53ef\u4ee5\u5b66\u4e60\u5171\u4eab\u3001\u53ef\u8f6c\u79fb\u548c\u9886\u57df\u611f\u77e5\u7684\u8868\u793a\uff0c\u5e76\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.14625", "pdf": "https://arxiv.org/pdf/2505.14625", "abs": "https://arxiv.org/abs/2505.14625", "authors": ["Zhangchen Xu", "Yuetai Li", "Fengqing Jiang", "Bhaskar Ramasubramanian", "Luyao Niu", "Bill Yuchen Lin", "Radha Poovendran"], "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has become a powerful tool for enhancing the\nreasoning abilities of large language models (LLMs) by optimizing their\npolicies with reward signals. Yet, RL's success relies on the reliability of\nrewards, which are provided by verifiers. In this paper, we expose and analyze\na widespread problem--false negatives--where verifiers wrongly reject correct\nmodel outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals\nthat over 38% of model-generated responses suffer from false negatives, where\nthe verifier fails to recognize correct answers. We show, both empirically and\ntheoretically, that these false negatives severely impair RL training by\ndepriving the model of informative gradient signals and slowing convergence. To\nmitigate this, we propose tinyV, a lightweight LLM-based verifier that augments\nexisting rule-based methods, which dynamically identifies potential false\nnegatives and recovers valid responses to produce more accurate reward\nestimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts\npass rates by up to 10% and accelerates convergence relative to the baseline.\nOur findings highlight the critical importance of addressing verifier false\nnegatives and offer a practical approach to improve RL-based fine-tuning of\nLLMs. Our code is available at https://github.com/uw-nsl/TinyV.", "AI": {"tldr": "This paper addresses the issue of false negatives in verifiers used in reinforcement learning for improving large language models' reasoning capabilities.", "motivation": "To investigate and solve the problem of false negatives in verifiers which lead to incorrect rejection of correct model outputs.", "method": "Analyze the Big-Math-RL-Verified dataset and propose a new method called tinyV.", "result": "TinyV improves pass rates by up to 10% and speeds up convergence on math-reasoning tasks.", "conclusion": "Improving verifier accuracy through methods like tinyV can significantly enhance reinforcement learning effectiveness."}}
{"id": "2505.14629", "pdf": "https://arxiv.org/pdf/2505.14629", "abs": "https://arxiv.org/abs/2505.14629", "authors": ["Fnu Mohbat", "Mohammed J Zaki"], "title": "KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Accepted at ACL 2025", "summary": "Recent advances in large language models (LLMs) and the abundance of food\ndata have resulted in studies to improve food understanding using LLMs. Despite\nseveral recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there\nhas been limited research on integrating food related KGs with LLMs. We\nintroduce KERL, a unified system that leverages food KGs and LLMs to provide\npersonalized food recommendations and generates recipes with associated\nmicro-nutritional information. Given a natural language question, KERL extracts\nentities, retrieves subgraphs from the KG, which are then fed into the LLM as\ncontext to select the recipes that satisfy the constraints. Next, our system\ngenerates the cooking steps and nutritional information for each recipe. To\nevaluate our approach, we also develop a benchmark dataset by curating recipe\nrelated questions, combined with constraints and personal preferences. Through\nextensive experiments, we show that our proposed KG-augmented LLM significantly\noutperforms existing approaches, offering a complete and coherent solution for\nfood recommendation, recipe generation, and nutritional analysis. Our code and\nbenchmark datasets are publicly available at\nhttps://github.com/mohbattharani/KERL.", "AI": {"tldr": "KERL\u662f\u4e00\u4e2a\u7ed3\u5408\u98df\u54c1\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u98df\u54c1\u63a8\u8350\u3001\u751f\u6210\u5e26\u8425\u517b\u4fe1\u606f\u7684\u98df\u8c31\uff0c\u5e76\u5728\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u6539\u5584\u98df\u54c1\u7406\u89e3\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u7279\u522b\u662f\u4e24\u8005\u7ed3\u5408\u5e94\u7528\u4e8e\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKERL\u7684\u65b0\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4ece\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63d0\u53d6\u5b9e\u4f53\u5e76\u68c0\u7d22\u5b50\u56fe\uff0c\u7136\u540e\u5c06\u5176\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8f93\u5165\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u9009\u62e9\u6ee1\u8db3\u6761\u4ef6\u7684\u98df\u8c31\uff0c\u5e76\u751f\u6210\u70f9\u996a\u6b65\u9aa4\u548c\u8425\u517b\u4fe1\u606f\u3002", "result": "KERL\u5728\u81ea\u5efa\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u98df\u54c1\u63a8\u8350\u3001\u98df\u8c31\u751f\u6210\u548c\u8425\u517b\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "KERL\u5c55\u793a\u4e86\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u98df\u54c1\u76f8\u5173\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u5176\u4ee3\u7801\u548c\u57fa\u51c6\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2505.14659", "pdf": "https://arxiv.org/pdf/2505.14659", "abs": "https://arxiv.org/abs/2505.14659", "authors": ["Navneet Kaur", "Lav Gupta"], "title": "Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As healthcare systems increasingly adopt advanced wireless networks and\nconnected devices, securing medical applications has become critical. The\nintegration of Internet of Medical Things devices, such as robotic surgical\ntools, intensive care systems, and wearable monitors has enhanced patient care\nbut introduced serious security risks. Cyberattacks on these devices can lead\nto life threatening consequences, including surgical errors, equipment failure,\nand data breaches. While the ITU IMT 2030 vision highlights 6G's transformative\nrole in healthcare through AI and cloud integration, it also raises new\nsecurity concerns. This paper explores how explainable AI techniques like SHAP,\nLIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve\ntrust and transparency in 6G enabled healthcare. We support our approach with\nexperimental analysis and highlight promising results.", "AI": {"tldr": "This paper discusses the importance of securing medical applications in healthcare systems adopting advanced wireless networks and connected devices. It examines how explainable AI techniques can help identify vulnerabilities and enhance security in 6G-enabled healthcare.", "motivation": "The increasing use of advanced wireless networks and connected devices in healthcare introduces serious security risks that could lead to life-threatening consequences.", "method": "Using explainable AI techniques such as SHAP, LIME, and DiCE to uncover vulnerabilities and strengthen defenses in 6G-enabled healthcare.", "result": "Experimental analysis supports the approach and shows promising results.", "conclusion": "The integration of AI and cloud in 6G will play a transformative role in healthcare but requires addressing new security concerns."}}
{"id": "2505.14592", "pdf": "https://arxiv.org/pdf/2505.14592", "abs": "https://arxiv.org/abs/2505.14592", "authors": ["Alexandre Broggi", "Nathaniel Bastian", "Lance Fiondella", "Gokhan Kul"], "title": "Adaptive Pruning of Deep Neural Networks for Resource-Aware Embedded Intrusion Detection on the Edge", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Artificial neural network pruning is a method in which artificial neural\nnetwork sizes can be reduced while attempting to preserve the predicting\ncapabilities of the network. This is done to make the model smaller or faster\nduring inference time. In this work we analyze the ability of a selection of\nartificial neural network pruning methods to generalize to a new cybersecurity\ndataset utilizing a simpler network type than was designed for. We analyze each\nmethod using a variety of pruning degrees to best understand how each algorithm\nresponds to the new environment. This has allowed us to determine the most well\nfit pruning method of those we searched for the task. Unexpectedly, we have\nfound that many of them do not generalize to the problem well, leaving only a\nfew algorithms working to an acceptable degree.", "AI": {"tldr": "\u7814\u7a76\u4e86\u51e0\u79cd\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u65b9\u6cd5\u5728\u65b0\u7f51\u7edc\u5b89\u5168\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u65b9\u6cd5\u5728\u975e\u8bbe\u8ba1\u7528\u9014\u7684\u7b80\u5355\u7f51\u7edc\u7c7b\u578b\u4e0a\u5bf9\u65b0\u73af\u5883\u7684\u9002\u5e94\u6027\u3002", "method": "\u5206\u6790\u591a\u79cd\u526a\u679d\u7a0b\u5ea6\u4e0b\u7684\u51e0\u79cd\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u65b9\u6cd5\u3002", "result": "\u8bb8\u591a\u526a\u679d\u65b9\u6cd5\u672a\u80fd\u826f\u597d\u5730\u6cdb\u5316\u5230\u8be5\u95ee\u9898\uff0c\u4ec5\u6709\u5c11\u6570\u80fd\u8fbe\u5230\u53ef\u63a5\u53d7\u7684\u6548\u679c\u3002", "conclusion": "\u786e\u5b9a\u4e86\u6700\u9002\u5408\u6240\u7814\u7a76\u4efb\u52a1\u7684\u526a\u679d\u65b9\u6cd5\u3002"}}
{"id": "2505.14595", "pdf": "https://arxiv.org/pdf/2505.14595", "abs": "https://arxiv.org/abs/2505.14595", "authors": ["Nima Hosseini Dashtbayaz", "Hesam Salehipour", "Adrian Butscher", "Nigel Morris"], "title": "Physics-informed Reduced Order Modeling of Time-dependent PDEs via Differentiable Solvers", "categories": ["cs.LG"], "comment": null, "summary": "Reduced-order modeling (ROM) of time-dependent and parameterized differential\nequations aims to accelerate the simulation of complex high-dimensional systems\nby learning a compact latent manifold representation that captures the\ncharacteristics of the solution fields and their time-dependent dynamics.\nAlthough high-fidelity numerical solvers generate the training datasets, they\nhave thus far been excluded from the training process, causing the learned\nlatent dynamics to drift away from the discretized governing physics. This\nmismatch often limits generalization and forecasting capabilities. In this\nwork, we propose Physics-informed ROM ($\\Phi$-ROM) by incorporating\ndifferentiable PDE solvers into the training procedure. Specifically, the\nlatent space dynamics and its dependence on PDE parameters are shaped directly\nby the governing physics encoded in the solver, ensuring a strong\ncorrespondence between the full and reduced systems. Our model outperforms\nstate-of-the-art data-driven ROMs and other physics-informed strategies by\naccurately generalizing to new dynamics arising from unseen parameters,\nenabling long-term forecasting beyond the training horizon, maintaining\ncontinuity in both time and space, and reducing the data cost. Furthermore,\n$\\Phi$-ROM learns to recover and forecast the solution fields even when trained\nor evaluated with sparse and irregular observations of the fields, providing a\nflexible framework for field reconstruction and data assimilation. We\ndemonstrate the framework's robustness across different PDE solvers and\nhighlight its broad applicability by providing an open-source JAX\nimplementation readily extensible to other PDE systems and differentiable\nsolvers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.14606", "pdf": "https://arxiv.org/pdf/2505.14606", "abs": "https://arxiv.org/abs/2505.14606", "authors": ["Maksim Zhdanov", "Vladislav Kurenkov"], "title": "Electrostatics from Laplacian Eigenbasis for Neural Network Interatomic Potentials", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Recent advances in neural network interatomic potentials have emerged as a\npromising research direction. However, popular deep learning models often lack\nauxiliary constraints grounded in physical laws, which could accelerate\ntraining and improve fidelity through physics-based regularization. In this\nwork, we introduce $\\Phi$-Module, a universal plugin module that enforces\nPoisson's equation within the message-passing framework to learn electrostatic\ninteractions in a self-supervised manner. Specifically, each atom-wise\nrepresentation is encouraged to satisfy a discretized Poisson's equation,\nmaking it possible to acquire a potential $\\boldsymbol{\\phi}$ and a\ncorresponding charge density $\\boldsymbol{\\rho}$ linked to the learnable\nLaplacian eigenbasis coefficients of a given molecular graph. We then derive an\nelectrostatic energy term, crucial for improved total energy predictions. This\napproach integrates seamlessly into any existing neural potential with\ninsignificant computational overhead. Experiments on the OE62 and MD22\nbenchmarks confirm that models combined with $\\Phi$-Module achieve robust\nimprovements over baseline counterparts. For OE62 error reduction ranges from\n4.5\\% to 17.8\\%, and for MD22, baseline equipped with $\\Phi$-Module achieves\nbest results on 5 out of 14 cases. Our results underscore how embedding a\nfirst-principles constraint in neural interatomic potentials can significantly\nimprove performance while remaining hyperparameter-friendly, memory-efficient\nand lightweight in training. Code will be available at\n\\href{https://github.com/dunnolab/phi-module}{dunnolab/phi-module}.", "AI": {"tldr": "This work introduces a novel method called $\\Phi$-Module, which uses Poisson's equation to enforce physics-based regularization in neural network interatomic potentials.", "motivation": "To accelerate training and improve fidelity of deep learning models by incorporating auxiliary constraints grounded in physical laws.", "method": "$\\Phi$-Module enforces Poisson's equation within the message-passing framework to learn electrostatic interactions in a self-supervised manner.", "result": "Models combined with $\\Phi$-Module show robust improvements over baseline counterparts on OE62 and MD22 benchmarks.", "conclusion": "Embedding first-principles constraints in neural interatomic potentials can significantly enhance performance while maintaining efficiency."}}
{"id": "2505.14610", "pdf": "https://arxiv.org/pdf/2505.14610", "abs": "https://arxiv.org/abs/2505.14610", "authors": ["Hao Wang", "Chenyu Shi", "Angel E. Rodriguez-Fernandez", "Oliver Sch\u00fctze"], "title": "MMD-Newton Method for Multi-objective Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Maximum mean discrepancy (MMD) has been widely employed to measure the\ndistance between probability distributions. In this paper, we propose using MMD\nto solve continuous multi-objective optimization problems (MOPs). For solving\nMOPs, a common approach is to minimize the distance (e.g., Hausdorff) between a\nfinite approximate set of the Pareto front and a reference set. Viewing these\ntwo sets as empirical measures, we propose using MMD to measure the distance\nbetween them. To minimize the MMD value, we provide the analytical expression\nof its gradient and Hessian matrix w.r.t. the search variables, and use them to\ndevise a novel set-oriented, MMD-based Newton (MMDN) method. Also, we analyze\nthe theoretical properties of MMD's gradient and Hessian, including the\nfirst-order stationary condition and the eigenspectrum of the Hessian, which\nare important for verifying the correctness of MMDN. To solve complicated\nproblems, we propose hybridizing MMDN with multiobjective evolutionary\nalgorithms (MOEAs), where we first execute an EA for several iterations to get\nclose to the global Pareto front and then warm-start MMDN with the result of\nthe MOEA to efficiently refine the approximation. We empirically test the\nhybrid algorithm on 11 widely used benchmark problems, and the results show the\nhybrid (MMDN + MOEA) can achieve a much better optimization accuracy than EA\nalone with the same computation budget.", "AI": {"tldr": "This paper proposes using MMD to solve continuous multi-objective optimization problems, devising a novel MMD-based Newton method, and demonstrates that hybridizing it with MOEAs yields better optimization accuracy.", "motivation": "To improve the accuracy of multi-objective optimization problems by using MMD to measure the distance between two sets, instead of traditional methods like Hausdorff.", "method": "Using Maximum Mean Discrepancy (MMD) to solve continuous multi-objective optimization problems by providing the gradient and Hessian matrix, and devising a novel set-oriented, MMD-based Newton (MMDN) method.", "result": "The hybrid algorithm (MMDN + MOEA) achieved significantly better optimization accuracy compared to MOEAs alone on 11 benchmark problems.", "conclusion": "The proposed hybrid algorithm combining MMDN and MOEAs outperforms MOEAs alone in terms of optimization accuracy."}}
{"id": "2505.14613", "pdf": "https://arxiv.org/pdf/2505.14613", "abs": "https://arxiv.org/abs/2505.14613", "authors": ["Emmanuel Noutahi", "Jason Hartford", "Prudencio Tossou", "Shawn Whitfield", "Alisandra K. Denton", "Cas Wognum", "Kristina Ulicna", "Jonathan Hsu", "Michael Cuccarese", "Emmanuel Bengio", "Dominique Beaini", "Christopher Gibson", "Daniel Cohen", "Berton Earnshaw"], "title": "Virtual Cells: Predict, Explain, Discover", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Drug discovery is fundamentally a process of inferring the effects of\ntreatments on patients, and would therefore benefit immensely from\ncomputational models that can reliably simulate patient responses, enabling\nresearchers to generate and test large numbers of therapeutic hypotheses safely\nand economically before initiating costly clinical trials. Even a more specific\nmodel that predicts the functional response of cells to a wide range of\nperturbations would be tremendously valuable for discovering safe and effective\ntreatments that successfully translate to the clinic. Creating such virtual\ncells has long been a goal of the computational research community that\nunfortunately remains unachieved given the daunting complexity and scale of\ncellular biology. Nevertheless, recent advances in AI, computing power, lab\nautomation, and high-throughput cellular profiling provide new opportunities\nfor reaching this goal. In this perspective, we present a vision for developing\nand evaluating virtual cells that builds on our experience at Recursion. We\nargue that in order to be a useful tool to discover novel biology, virtual\ncells must accurately predict the functional response of a cell to\nperturbations and explain how the predicted response is a consequence of\nmodifications to key biomolecular interactions. We then introduce key\nprinciples for designing therapeutically-relevant virtual cells, describe a\nlab-in-the-loop approach for generating novel insights with them, and advocate\nfor biologically-grounded benchmarks to guide virtual cell development.\nFinally, we make the case that our approach to virtual cells provides a useful\nframework for building other models at higher levels of organization, including\nvirtual patients. We hope that these directions prove useful to the research\ncommunity in developing virtual models optimized for positive impact on drug\ndiscovery outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u548c\u5b9e\u9a8c\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u865a\u62df\u7ec6\u80de\uff0c\u5e76\u901a\u8fc7\u751f\u7269\u57fa\u51c6\u6d4b\u8bd5\u6765\u6307\u5bfc\u5176\u53d1\u5c55\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u6709\u52a9\u4e8e\u53d1\u73b0\u65b0\u578b\u751f\u7269\u5b66\uff0c\u8fd8\u53ef\u4ee5\u4f5c\u4e3a\u6784\u5efa\u66f4\u9ad8\u5c42\u6b21\u6a21\u578b\uff08\u5982\u865a\u62df\u60a3\u8005\uff09\u7684\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u836f\u7269\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u4e34\u5e8a\u8bd5\u9a8c\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u6a21\u62df\u60a3\u8005\u53cd\u5e94\uff1b\u800c\u73b0\u6709\u7684\u7ec6\u80de\u751f\u7269\u5b66\u590d\u6742\u6027\u548c\u89c4\u6a21\u4f7f\u5f97\u521b\u5efa\u865a\u62df\u7ec6\u80de\u6781\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u9a8c\u5ba4\u4e0eAI\u7ed3\u5408\u7684\u5faa\u73af\u65b9\u6cd5\u7528\u4e8e\u751f\u6210\u65b0\u89c1\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u8bbe\u8ba1\u5177\u6709\u6cbb\u7597\u610f\u4e49\u7684\u865a\u62df\u7ec6\u80de\u7684\u5173\u952e\u539f\u5219\u3002", "result": "\u5c3d\u7ba1\u5b8c\u5168\u5b9e\u73b0\u865a\u62df\u7ec6\u80de\u4ecd\u9762\u4e34\u56f0\u96be\uff0c\u4f46\u5229\u7528\u6700\u65b0\u7684AI\u3001\u8ba1\u7b97\u80fd\u529b\u3001\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u548c\u9ad8\u901a\u91cf\u7ec6\u80de\u5206\u6790\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "conclusion": "\u63d0\u51fa\u7684\u865a\u62df\u7ec6\u80de\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u7528\u4e8e\u53d1\u73b0\u65b0\u578b\u751f\u7269\u5b66\uff0c\u8fd8\u4e3a\u6784\u5efa\u5176\u4ed6\u9ad8\u5c42\u6b21\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u7528\u7684\u6846\u67b6\uff0c\u8fd9\u53ef\u80fd\u5bf9\u836f\u7269\u53d1\u73b0\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2505.14620", "pdf": "https://arxiv.org/pdf/2505.14620", "abs": "https://arxiv.org/abs/2505.14620", "authors": ["Morgan Lindsay Heisler", "Linzi Xing", "Ge Shi", "Hanieh Sadri", "Gursimran Singh", "Weiwei Zhang", "Tao Ye", "Ying Xiong", "Yong Zhang", "Zhenan Fan"], "title": "Enhancing Learned Knowledge in LoRA Adapters Through Efficient Contrastive Decoding on Ascend NPUs", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at ACM KDD 2025", "summary": "Huawei Cloud users leverage LoRA (Low-Rank Adaptation) as an efficient and\nscalable method to fine-tune and customize large language models (LLMs) for\napplication-specific needs. However, tasks that require complex reasoning or\ndeep contextual understanding are often hindered by biases or interference from\nthe base model when using typical decoding methods like greedy or beam search.\nThese biases can lead to generic or task-agnostic responses from the base model\ninstead of leveraging the LoRA-specific adaptations. In this paper, we\nintroduce Contrastive LoRA Decoding (CoLD), a novel decoding framework designed\nto maximize the use of task-specific knowledge in LoRA-adapted models,\nresulting in better downstream performance. CoLD uses contrastive decoding by\nscoring candidate tokens based on the divergence between the probability\ndistributions of a LoRA-adapted expert model and the corresponding base model.\nThis approach prioritizes tokens that better align with the LoRA's learned\nrepresentations, enhancing performance for specialized tasks. While effective,\na naive implementation of CoLD is computationally expensive because each\ndecoding step requires evaluating multiple token candidates across both models.\nTo address this, we developed an optimized kernel for Huawei's Ascend NPU. CoLD\nachieves up to a 5.54% increase in task accuracy while reducing end-to-end\nlatency by 28% compared to greedy decoding. This work provides practical and\nefficient decoding strategies for fine-tuned LLMs in resource-constrained\nenvironments and has broad implications for applied data science in both cloud\nand on-premises settings.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5bf9\u6bd4LoRA\u89e3\u7801(CoLD)\uff0c\u4e00\u79cd\u7528\u4e8e\u9ad8\u6548\u5229\u7528LoRA\u9002\u5e94\u6a21\u578b\u4e2d\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u7684\u65b0\u89e3\u7801\u6846\u67b6\u3002\u901a\u8fc7\u4f18\u5316Ascend NPU\u5185\u6838\uff0cCoLD\u63d0\u5347\u4e86\u4efb\u52a1\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u7684\u89e3\u7801\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u5bb9\u6613\u53d7\u5230\u57fa\u7840\u6a21\u578b\u504f\u89c1\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u54cd\u5e94\u4e0d\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u6846\u67b6CoLD\uff0c\u4f7f\u7528\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\u4f18\u5148\u9009\u62e9\u4e0eLoRA\u5b66\u4e60\u8868\u793a\u66f4\u4e00\u81f4\u7684\u5019\u9009\u6807\u8bb0\u3002\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5f00\u53d1\u4e86Ascend NPU\u4f18\u5316\u5185\u6838\u3002", "result": "CoLD\u63d0\u9ad8\u4e86\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u6bd4\u8d2a\u5fc3\u89e3\u7801\u51cf\u5c11\u4e8628%\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5bf9\u6bd4LoRA\u89e3\u7801(CoLD)\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4e0b\u6e38\u6027\u80fd\u3002\u540c\u65f6\u5f00\u53d1\u4e86Ascend NPU\u4f18\u5316\u5185\u6838\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002"}}
{"id": "2505.14635", "pdf": "https://arxiv.org/pdf/2505.14635", "abs": "https://arxiv.org/abs/2505.14635", "authors": ["Benjamin Prada", "Shion Matsumoto", "Abdul Malik Zekri", "Ankur Mali"], "title": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning", "categories": ["cs.LG"], "comment": "24 pages, 2 figures", "summary": "We present the first theoretical framework that connects predictive coding\n(PC), a biologically inspired local learning rule, with the minimum description\nlength (MDL) principle in deep networks. We prove that layerwise PC performs\nblock-coordinate descent on the MDL two-part code objective, thereby jointly\nminimizing empirical risk and model complexity. Using Hoeffding's inequality\nand a prefix-code prior, we derive a novel generalization bound of the form\n$R(\\theta) \\le \\^{R}(\\theta) + \\frac{L(\\theta)}{N}$, capturing the tradeoff\nbetween fit and compression. We further prove that each PC sweep monotonically\ndecreases the empirical two-part codelength, yielding tighter high-probability\nrisk bounds than unconstrained gradient descent. Finally, we show that repeated\nPC updates converge to a block-coordinate stationary point, providing an\napproximate MDL-optimal solution. To our knowledge, this is the first result\noffering formal generalization and convergence guarantees for PC-trained deep\nmodels, positioning PC as a theoretically grounded and biologically plausible\nalternative to backpropagation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u7f16\u7801\u4e0e\u6df1\u5ea6\u7f51\u7edc\u4e2d\u7684\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u539f\u5219\u76f8\u7ed3\u5408\uff0c\u5e76\u8bc1\u660e\u4e86\u5c42\u95f4\u9884\u6d4b\u7f16\u7801\u6267\u884cMDL\u4e24\u90e8\u5206\u4ee3\u7801\u76ee\u6807\u7684\u5757\u5750\u6807\u4e0b\u964d\uff0c\u4ece\u800c\u8054\u5408\u6700\u5c0f\u5316\u7ecf\u9a8c\u98ce\u9669\u548c\u6a21\u578b\u590d\u6742\u5ea6\u3002\u6b64\u5916\uff0c\u8fd8\u63a8\u5bfc\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6cdb\u5316\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u4e86\u91cd\u590d\u7684\u9884\u6d4b\u7f16\u7801\u66f4\u65b0\u6536\u655b\u5230\u5757\u5750\u6807\u5e73\u7a33\u70b9\u3002", "motivation": "\u8fde\u63a5\u9884\u6d4b\u7f16\u7801\u4e0e\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u539f\u5219\uff0c\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u751f\u7269\u5408\u7406\u6027\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5e76\u8bc1\u660e\u5c42\u95f4\u9884\u6d4b\u7f16\u7801\u6267\u884cMDL\u4e24\u90e8\u5206\u4ee3\u7801\u76ee\u6807\u7684\u5757\u5750\u6807\u4e0b\u964d\u3002", "result": "\u63a8\u5bfc\u51fa\u65b0\u7684\u6cdb\u5316\u754c\u9650\uff0c\u8bc1\u660e\u91cd\u590d\u9884\u6d4b\u7f16\u7801\u66f4\u65b0\u6536\u655b\u5230\u5757\u5750\u6807\u5e73\u7a33\u70b9\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u4e3a\u9884\u6d4b\u7f16\u7801\u8bad\u7ec3\u7684\u6df1\u5ea6\u6a21\u578b\u63d0\u4f9b\u6b63\u5f0f\u6cdb\u5316\u548c\u6536\u655b\u4fdd\u8bc1\u7684\u7ed3\u679c\uff0c\u5c06\u9884\u6d4b\u7f16\u7801\u5b9a\u4f4d\u4e3a\u53cd\u5411\u4f20\u64ad\u7684\u4e00\u4e2a\u6709\u7406\u8bba\u4f9d\u636e\u4e14\u751f\u7269\u5408\u7406\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2505.14643", "pdf": "https://arxiv.org/pdf/2505.14643", "abs": "https://arxiv.org/abs/2505.14643", "authors": ["Ane G. Domingo-Aldama", "Marcos Merino Prado", "Alain Garc\u00eda Olea", "Koldo Gojenola Galletebeitia", "Josu Goikoetxea Salutregi", "Aitziber Atutxa Salazar"], "title": "Early Diagnosis of Atrial Fibrillation Recurrence: A Large Tabular Model Approach with Structured and Unstructured Clinical Data", "categories": ["cs.LG"], "comment": null, "summary": "BACKGROUND: Atrial fibrillation (AF), the most common arrhythmia, is linked\nto high morbidity and mortality. In a fast-evolving AF rhythm control treatment\nera, predicting AF recurrence after its onset may be crucial to achieve the\noptimal therapeutic approach, yet traditional scores like CHADS2-VASc, HATCH,\nand APPLE show limited predictive accuracy. Moreover, early diagnosis studies\noften rely on codified electronic health record (EHR) data, which may contain\nerrors and missing information.\n  OBJECTIVE: This study aims to predict AF recurrence between one month and two\nyears after onset by evaluating traditional clinical scores, ML models, and our\nLTM approach. Moreover, another objective is to develop a methodology for\nintegrating structured and unstructured data to enhance tabular dataset\nquality.\n  METHODS: A tabular dataset was generated by combining structured clinical\ndata with free-text discharge reports processed through natural language\nprocessing techniques, reducing errors and annotation effort. A total of 1,508\npatients with documented AF onset were identified, and models were evaluated on\na manually annotated test set. The proposed approach includes a LTM compared\nagainst traditional clinical scores and ML models.\n  RESULTS: The proposed LTM approach achieved the highest predictive\nperformance, surpassing both traditional clinical scores and ML models.\nAdditionally, the gender and age bias analyses revealed demographic\ndisparities.\n  CONCLUSION: The integration of structured data and free-text sources resulted\nin a high-quality dataset. The findings emphasize the limitations of\ntraditional clinical scores in predicting AF recurrence and highlight the\npotential of ML-based approaches, particularly our LTM model.", "AI": {"tldr": "This study evaluates traditional clinical scores, ML models, and an LTM approach for predicting atrial fibrillation recurrence within one month to two years post-onset, developing a method to integrate structured and unstructured EHR data to improve dataset quality.", "motivation": "Traditional scores have limited predictive accuracy for AF recurrence, and early diagnosis studies often rely on EHR data prone to errors and missing info.", "method": "Combining structured clinical data with NLP-processed free-text discharge reports to create a tabular dataset for model evaluation.", "result": "The LTM approach outperformed traditional scores and ML models in predicting AF recurrence, also revealing gender and age bias.", "conclusion": "Integrating structured and unstructured data improves dataset quality and highlights the potential of ML-based approaches like the LTM model."}}
{"id": "2505.14669", "pdf": "https://arxiv.org/pdf/2505.14669", "abs": "https://arxiv.org/abs/2505.14669", "authors": ["Roberto L. Castro", "Andrei Panferov", "Soroush Tabesh", "Oliver Sieberling", "Jiale Chen", "Mahdi Nikdan", "Saleh Ashkboos", "Dan Alistarh"], "title": "Quartet: Native FP4 Training Can Be Optimal for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has been paralleled by\nunprecedented increases in computational demands, with training costs for\nstate-of-the-art models doubling every few months. Training models directly in\nlow-precision arithmetic offers a solution, by improving both computational\nthroughput and energy efficiency. Specifically, NVIDIA's recent Blackwell\narchitecture facilitates extremely low-precision operations, specifically FP4\nvariants, promising substantial efficiency gains. Yet, current algorithms for\ntraining LLMs in FP4 precision face significant accuracy degradation and often\nrely on mixed-precision fallbacks. In this paper, we systematically investigate\nhardware-supported FP4 training and introduce Quartet, a new approach enabling\naccurate, end-to-end FP4 training with all the major computations (in e.g.\nlinear layers) being performed in low precision. Through extensive evaluations\non Llama-type models, we reveal a new low-precision scaling law that quantifies\nperformance trade-offs across varying bit-widths and allows us to identify a\n\"near-optimal\" low-precision training technique in terms of\naccuracy-vs-computation, called Quartet. We implement Quartet using optimized\nCUDA kernels tailored for NVIDIA Blackwell GPUs, and show that it can achieve\nstate-of-the-art accuracy for FP4 precision, successfully training\nbillion-scale models. Our method demonstrates that fully FP4-based training is\na competitive alternative to standard-precision and FP8 training. Our code is\navailable at https://github.com/IST-DASLab/Quartet.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aQuartet\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728FP4\u7cbe\u5ea6\u4e0b\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e00\u4e2a\u65b0\u7684\u4f4e\u7cbe\u5ea6\u7f29\u653e\u5b9a\u5f8b\u3002", "motivation": "\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u786c\u4ef6\u652f\u6301\u7684FP4\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165Quartet\u65b9\u6cd5\uff0c\u4e3b\u8981\u8ba1\u7b97\u90fd\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u5b8c\u6210\u3002", "result": "\u5728Llama\u578b\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\u4e86\u65b0\u7684\u4f4e\u7cbe\u5ea6\u7f29\u653e\u5b9a\u5f8b\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6743\u8861\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5b8c\u5168\u57fa\u4e8eFP4\u7684\u8bad\u7ec3\u662f\u6807\u51c6\u7cbe\u5ea6\u548cFP8\u8bad\u7ec3\u7684\u7ade\u4e89\u66ff\u4ee3\u65b9\u6848\u3002"}}
