<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 89]
- [cs.AI](#cs.AI) [总数: 27]
- [stat.ML](#stat.ML) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Leveraging Pre-Trained Models for Multimodal Class-Incremental Learning under Adaptive Fusion](https://arxiv.org/abs/2506.09999)
*Yukun Chen, Zihuan Qiu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于多模态预训练模型的MCIL方法，通过引入MIFE、AAVFM以及一种新的对比训练损失来解决跨视觉、音频和文本模态的MCIL挑战，并提出了两个专门的评估指标。


<details>
  <summary>更多</summary>
  
**动机:** 与仅关注视觉和文本的传统MCIL方法不同，本文旨在探索跨越视觉、音频和文本模态的MCIL，以解决互补信息整合及灾难性遗忘的问题。

**方法:** 1. 提出基于MoE结构的多模态增量特征提取器（MIFE）用于AudioCLIP的有效增量微调。
2. 设计了自适应音视频融合模块（AAVFM），包含掩码阈值机制和动态特征融合机制，同时增强文本多样性。
3. 引入一种新的多模态类增量对比训练损失来优化MCIL中的跨模态对齐。
4. 提出了两个针对MCIL的具体评价指标。

**结果:** 在三个多模态数据集上的广泛实验验证了所提方法的有效性。

**结论:** 该研究为MCIL提供了新的解决方案，通过结合多种模态的信息，不仅提升了特征的辨别性和泛化能力，还有效缓解了灾难性遗忘问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Pre-Trained+Models+for+Multimodal+Class-Incremental+Learning+under+Adaptive+Fusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.09999，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.09999&send_immediately=true&force_search=false)

**原文摘要:** Unlike traditional Multimodal Class-Incremental Learning (MCIL) methods that
focus only on vision and text, this paper explores MCIL across vision, audio
and text modalities, addressing challenges in integrating complementary
information and mitigating catastrophic forgetting. To tackle these issues, we
propose an MCIL method based on multimodal pre-trained models. Firstly, a
Multimodal Incremental Feature Extractor (MIFE) based on Mixture-of-Experts
(MoE) structure is introduced to achieve effective incremental fine-tuning for
AudioCLIP. Secondly, to enhance feature discriminability and generalization, we
propose an Adaptive Audio-Visual Fusion Module (AAVFM) that includes a masking
threshold mechanism and a dynamic feature fusion mechanism, along with a
strategy to enhance text diversity. Thirdly, a novel multimodal
class-incremental contrastive training loss is proposed to optimize cross-modal
alignment in MCIL. Finally, two MCIL-specific evaluation metrics are introduced
for comprehensive assessment. Extensive experiments on three multimodal
datasets validate the effectiveness of our method.

</details>


### [2] [NOCL: Node-Oriented Conceptualization LLM for Graph Tasks without Message Passing](https://arxiv.org/abs/2506.10014)
*Wei Li, Mengcheng Lan, Jiaxing Xu, Yiping Ke*

**主要类别:** cs.LG

**AI概要:** 提出了一种面向节点的概念化大语言模型(NOCL)，该框架能够将异构的节点属性转换为结构化的自然语言，并使用预训练的语言模型将节点描述编码为紧凑的语义嵌入，极大地减少了标记长度。此外，NOCL还利用图表示描述符来统一不同层次的图任务，使之成为一种共享的语言查询格式，从而为图基础模型开辟了新的方向。实验结果表明，NOCL在监督学习中与传统MPNNs和混合LLM-MPNN方法相比具有竞争力，在零样本设置下表现出更好的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的图神经网络（如消息传递神经网络）依赖于有监督的学习方式，这限制了它们在标签稀缺场景中的泛化能力和适用性。而最近的自监督方法仍然需要标注数据进行微调，这限制了它们在零样本场景下的有效性。同时，大型语言模型虽然在自然语言处理任务上表现出色，但在应用于图时遇到了许多挑战，包括保持推理能力、管理丰富的节点属性带来的大量标记长度以及仅限于文本属性图(TAGs)和单一层面的任务。

**方法:** 提出了一个名为Node-Oriented Conceptualization LLM (NOCL)的新框架，它利用两个核心技术：1) 节点描述，将异构的节点属性转化为结构化的自然语言，使LLM的应用范围从TAGs扩展到非TAGs；2) 节点概念，通过预训练的语言模型将节点描述编码为紧凑的语义嵌入，显著减少了直接使用节点描述所需的标记长度。此外，NOCL还采用了图表示描述符来把不同层级的图任务统一成一种共享的语言查询格式。

**结果:** 实验结果显示，NOCL相对于传统MPNNs和混合LLM-MPNN方法来说，在监督式学习环境中展现了竞争性的表现，并且在零样本设置下展示出更优的泛化性能。

**结论:** NOCL不仅增强了图神经网络处理不同类型图数据的能力，而且通过引入节点描述和节点概念等技术解决了现有方法的一些局限性问题，为开发更加通用的图基础模型提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NOCL%3A+Node-Oriented+Conceptualization+LLM+for+Graph+Tasks+without+Message+Passing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10014，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10014&send_immediately=true&force_search=false)

**原文摘要:** Graphs are essential for modeling complex interactions across domains such as
social networks, biology, and recommendation systems. Traditional Graph Neural
Networks, particularly Message Passing Neural Networks (MPNNs), rely heavily on
supervised learning, limiting their generalization and applicability in
label-scarce scenarios. Recent self-supervised approaches still require labeled
fine-tuning, limiting their effectiveness in zero-shot scenarios. Meanwhile,
Large Language Models (LLMs) excel in natural language tasks but face
significant challenges when applied to graphs, including preserving reasoning
abilities, managing extensive token lengths from rich node attributes, and
being limited to textual-attributed graphs (TAGs) and a single level task. To
overcome these limitations, we propose the Node-Oriented Conceptualization LLM
(NOCL), a novel framework that leverages two core techniques: 1) node
description, which converts heterogeneous node attributes into structured
natural language, extending LLM from TAGs to non-TAGs; 2) node concept, which
encodes node descriptions into compact semantic embeddings using pretrained
language models, significantly reducing token lengths by up to 93.9% compared
to directly using node descriptions. Additionally, our NOCL employs graph
representation descriptors to unify graph tasks at various levels into a
shared, language-based query format, paving a new direction for Graph
Foundation Models. Experimental results validate NOCL's competitive supervised
performance relative to traditional MPNNs and hybrid LLM-MPNN methods and
demonstrate superior generalization in zero-shot settings.

</details>


### [3] [Improving the performance of optical inverse design of multilayer thin films using CNN-LSTM tandem neural networks](https://arxiv.org/abs/2506.10044)
*Uijun Jung, Deokho Jang, Sungchul Kim, Jungho Kim*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种用于SiO2/TiO2多层薄膜透射光谱逆向设计的串联神经网络(TNN)，并比较了不同配置下TNN的表现，发现基于CNN-LSTM的TNN在准确度和速度上达到了最优平衡。


<details>
  <summary>更多</summary>
  
**动机:** 传统的薄膜光学逆向设计方法需要大量的数值模拟和优化过程，耗时较长。研究旨在通过深度学习来提高逆向设计的效率和准确性。

**方法:** 采用了多种类型的神经网络(MLP, CNN, LSTM)来构建串联神经网络(TNN)，并通过对比不同组合（例如LSTM-LSTM, CNN-LSTM）下的性能表现来寻找最佳方案。

**结果:** 研究表明，基于LSTM-LSTM的TNN具有最高的精度但训练时间最长；而基于CNN-LSTM的TNN则在精度和速度之间取得了最佳平衡。

**结论:** 使用深度学习尤其是结合CNN与LSTM算法的TNN能够有效提升SiO2/TiO2多层薄膜透射光谱逆向设计的效率和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+the+performance+of+optical+inverse+design+of+multilayer+thin+films+using+CNN-LSTM+tandem+neural+networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10044，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10044&send_immediately=true&force_search=false)

**原文摘要:** Optical properties of thin film are greatly influenced by the thickness of
each layer. Accurately predicting these thicknesses and their corresponding
optical properties is important in the optical inverse design of thin films.
However, traditional inverse design methods usually demand extensive numerical
simulations and optimization procedures, which are time-consuming. In this
paper, we utilize deep learning for the inverse design of the transmission
spectra of SiO2/TiO2 multilayer thin films. We implement a tandem neural
network (TNN), which can solve the one-to-many mapping problem that greatly
degrades the performance of deep-learning-based inverse designs. In general,
the TNN has been implemented by a back-to-back connection of an inverse neural
network and a pre-trained forward neural network, both of which have been
implemented based on multilayer perceptron (MLP) algorithms. In this paper, we
propose to use not only MLP, but also convolutional neural network (CNN) or
long short-term memory (LSTM) algorithms in the configuration of the TNN. We
show that an LSTM-LSTM-based TNN yields the highest accuracy but takes the
longest training time among nine configurations of TNNs. We also find that a
CNN-LSTM-based TNN will be an optimal solution in terms of accuracy and speed
because it could integrate the strengths of the CNN and LSTM algorithms.

</details>


### [4] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
*Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了Omni-DPO，一种双视角优化框架，能够根据偏好对的质量和模型学习动态自适应地加权样本，从而更有效地利用训练数据并提高性能。实验结果表明Omni-DPO在文本理解和数学推理任务上优于基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于DPO的方法通常均匀处理所有偏好对，忽略了它们内在质量和学习效用的关键差异，导致数据利用率和表现不佳。

**方法:** 提出了一种名为Omni-DPO的双视角优化框架，该框架同时考虑了每个偏好对的内在质量以及模型在这些对上的演变表现。通过在训练期间根据数据质量和模型的学习动态自适应地调整样本权重，Omni-DPO能够实现更加有效的训练数据利用。

**结果:** 在各种模型和基准测试中的实验结果显示了Omni-DPO的优越性和泛化能力。特别是在文本理解任务中，使用Omni-DPO微调后的Gemma-2-9b-it模型比领先的LLM Claude 3 Opus高出6.7分。在数学推理任务方面，Omni-DPO也始终超过了所有基准测试中的基线方法。

**结论:** Omni-DPO提供了一个有效且鲁棒的方法来改善直接偏好优化（DPO），并且在不同类型的智能体任务中表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omni-DPO%3A+A+Dual-Perspective+Paradigm+for+Dynamic+Preference+Learning+of+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10054&send_immediately=true&force_search=false)

**原文摘要:** Direct Preference Optimization (DPO) has become a cornerstone of
reinforcement learning from human feedback (RLHF) due to its simplicity and
efficiency. However, existing DPO-based approaches typically treat all
preference pairs uniformly, ignoring critical variations in their inherent
quality and learning utility, leading to suboptimal data utilization and
performance. To address this challenge, we propose Omni-DPO, a dual-perspective
optimization framework that jointly accounts for (1) the inherent quality of
each preference pair and (2) the model's evolving performance on those pairs.
By adaptively weighting samples according to both data quality and the model's
learning dynamics during training, Omni-DPO enables more effective training
data utilization and achieves better performance. Experimental results on
various models and benchmarks demonstrate the superiority and generalization
capabilities of Omni-DPO. On textual understanding tasks, Gemma-2-9b-it
finetuned with Omni-DPO beats the leading LLM, Claude 3 Opus, by a significant
margin of 6.7 points on the Arena-Hard benchmark. On mathematical reasoning
tasks, Omni-DPO consistently outperforms the baseline methods across all
benchmarks, providing strong empirical evidence for the effectiveness and
robustness of our approach. Code and models will be available at
https://github.com/pspdada/Omni-DPO.

</details>


### [5] [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org/abs/2506.10060)
*Brendan Leigh Ross, Noël Vouitsis, Atiyeh Ashari Ghomi, Rasa Hosseinzadeh, Ji Xin, Zhaoyan Liu, Yi Sui, Shiyi Hou, Kin Kwan Leung, Gabriel Loaiza-Ganem, Jesse C. Cresswell*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的贝叶斯推断方法来改善大型语言模型(LLMs)的不确定性量化问题，通过将提示词视为统计模型中的文本参数并利用小规模训练数据集进行贝叶斯推断。为此，作者引入了MHLP算法，这是一种结合了提示词优化与传统MCMC方法的新型MCMC算法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）正变得越来越能够解决具有挑战性的现实世界任务，但准确地量化它们的不确定性仍然是一个关键的未解决问题，这限制了它们在高风险领域的应用。此外，许多最先进的LLMs都是闭源的黑盒性质，以及基于LLM的系统对提示词非常敏感，通常需要大量的手动调整（即提示工程）。

**方法:** 研究者们通过贝叶斯视角来看待基于LLM的系统，并且把提示词看作是统计模型中的文本参数。他们提出了一个名为MHLP（Metropolis-Hastings through LLM Proposals）的新颖马尔可夫链蒙特卡洛(MCMC)算法，该算法结合了提示优化技术和标准MCMC方法来进行贝叶斯推理。

**结果:** 实验证明了这种方法在多个LLM基准测试和不确定性量化任务中提高了预测准确性和不确定性量化(UQ)的效果。

**结论:** 通过一系列的实验，本文证明了所提出的方法在预测准确性和不确定性量化方面优于现有的基准。更广泛地说，这项工作展示了将丰富的贝叶斯方法文献中的技术融入大型语言模型时代的一种可行路径，为构建更加可靠和校准的基于LLM的系统铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Textual+Bayes%3A+Quantifying+Uncertainty+in+LLM-Based+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10060，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10060&send_immediately=true&force_search=false)

**原文摘要:** Although large language models (LLMs) are becoming increasingly capable of
solving challenging real-world tasks, accurately quantifying their uncertainty
remains a critical open problem, which limits their applicability in
high-stakes domains. This challenge is further compounded by the closed-source,
black-box nature of many state-of-the-art LLMs. Moreover, LLM-based systems can
be highly sensitive to the prompts that bind them together, which often require
significant manual tuning (i.e., prompt engineering). In this work, we address
these challenges by viewing LLM-based systems through a Bayesian lens. We
interpret prompts as textual parameters in a statistical model, allowing us to
use a small training dataset to perform Bayesian inference over these prompts.
This novel perspective enables principled uncertainty quantification over both
the model's textual parameters and its downstream predictions, while also
incorporating prior beliefs about these parameters expressed in free-form text.
To perform Bayesian inference, a difficult problem even for well-studied data
modalities, we introduce Metropolis-Hastings through LLM Proposals (MHLP), a
novel Markov chain Monte Carlo (MCMC) algorithm that combines prompt
optimization techniques with standard MCMC methods. MHLP is a turnkey
modification to existing LLM pipelines, including those that rely exclusively
on closed-source models. Empirically, we demonstrate that our method yields
improvements in both predictive accuracy and uncertainty quantification (UQ) on
a range of LLM benchmarks and UQ tasks. More broadly, our work demonstrates a
viable path for incorporating methods from the rich Bayesian literature into
the era of LLMs, paving the way for more reliable and calibrated LLM-based
systems.

</details>


### [6] [Optimizing Latent Dimension Allocation in Hierarchical VAEs: Balancing Attenuation and Information Retention for OOD Detection](https://arxiv.org/abs/2506.10089)
*Dane Williamson, Yangfeng Ji, Matthew Dwyer*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+Latent+Dimension+Allocation+in+Hierarchical+VAEs%3A+Balancing+Attenuation+and+Information+Retention+for+OOD+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10089，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10089&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution (OOD) detection is a critical task in machine learning,
particularly for safety-critical applications where unexpected inputs must be
reliably flagged. While hierarchical variational autoencoders (HVAEs) offer
improved representational capacity over traditional VAEs, their performance is
highly sensitive to how latent dimensions are distributed across layers.
Existing approaches often allocate latent capacity arbitrarily, leading to
ineffective representations or posterior collapse. In this work, we introduce a
theoretically grounded framework for optimizing latent dimension allocation in
HVAEs, drawing on principles from information theory to formalize the trade-off
between information loss and representational attenuation. We prove the
existence of an optimal allocation ratio $r^{\ast}$ under a fixed latent
budget, and empirically show that tuning this ratio consistently improves OOD
detection performance across datasets and architectures. Our approach
outperforms baseline HVAE configurations and provides practical guidance for
principled latent structure design, leading to more robust OOD detection with
deep generative models.

</details>


### [7] [Efficient kernelized bandit algorithms via exploration distributions](https://arxiv.org/abs/2506.10091)
*Bingshan Hu, Zheng He, Danica J. Sutherland*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+kernelized+bandit+algorithms+via+exploration+distributions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10091，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10091&send_immediately=true&force_search=false)

**原文摘要:** We consider a kernelized bandit problem with a compact arm set ${X} \subset
\mathbb{R}^d $ and a fixed but unknown reward function $f^*$ with a finite norm
in some Reproducing Kernel Hilbert Space (RKHS). We propose a class of
computationally efficient kernelized bandit algorithms, which we call
GP-Generic, based on a novel concept: exploration distributions. This class of
algorithms includes Upper Confidence Bound-based approaches as a special case,
but also allows for a variety of randomized algorithms. With careful choice of
exploration distribution, our proposed generic algorithm realizes a wide range
of concrete algorithms that achieve $\tilde{O}(\gamma_T\sqrt{T})$ regret
bounds, where $\gamma_T$ characterizes the RKHS complexity. This matches known
results for UCB- and Thompson Sampling-based algorithms; we also show that in
practice, randomization can yield better practical results.

</details>


### [8] [Unsupervised Deep Clustering of MNIST with Triplet-Enhanced Convolutional Autoencoders](https://arxiv.org/abs/2506.10094)
*Md. Faizul Islam Ansari*

**主要类别:** cs.LG

**AI概要:** 该研究实现了一个先进的无监督聚类系统，用于MNIST手写数字的两阶段深度自动编码器架构。通过结合重建误差和KMeans聚类损失，以及使用批量归一化、dropout和权重衰减等技术，该框架在多种内在和外在度量标准下实现了优越的聚类性能，并且提供了可理解的结果和可扩展的实现。


<details>
  <summary>更多</summary>
  
**动机:** 开发一个能够为大规模图像聚类应用提供可靠基础的无监督表示学习方法，同时保持数据重建准确性和簇分离纯度之间的最优平衡。

**方法:** 采用两阶段深度自动编码器架构：第一阶段训练以最小化重建误差来发展图像的最小但可解释的表示；第二阶段将重建误差与KMeans聚类损失结合，通过联合距离目标优化学习到的潜在嵌入。此外，模型还包括批量归一化、dropout和权重衰减三个元素，以获得泛化和稳定的结果。

**结果:** 该框架在Silhouette Score、Davies-Bouldin Index、NMI（标准化互信息）和ARI（调整兰德指数）等指标上展示了优越的聚类性能，并利用t-SNE可视化呈现了学习到的具有明显数字簇的嵌入。

**结论:** 所提出的方法在数据重建精度和簇分离纯度之间达到了最佳组合，同时提供了易于理解的结果和可扩展的实现方式，为不同大型图像聚类应用中的无监督表示学习部署奠定了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Deep+Clustering+of+MNIST+with+Triplet-Enhanced+Convolutional+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10094&send_immediately=true&force_search=false)

**原文摘要:** This research implements an advanced unsupervised clustering system for MNIST
handwritten digits through two-phase deep autoencoder architecture. A deep
neural autoencoder requires a training process during phase one to develop
minimal yet interpretive representations of images by minimizing reconstruction
errors. During the second phase we unify the reconstruction error with a KMeans
clustering loss for learned latent embeddings through a joint distance-based
objective. Our model contains three elements which include batch normalization
combined with dropout and weight decay for achieving generalized and stable
results. The framework achieves superior clustering performance during
extensive tests which used intrinsic measurements including Silhouette Score
and Davies-Bouldin Index coupled with extrinsic metrics NMI and ARI when
processing image features. The research uses t-SNE visualization to present
learned embeddings that show distinct clusters for digits. Our approach reaches
an optimal combination between data reconstruction accuracy and cluster
separation purity when adding the benefit of understandable results and
scalable implementations. The approach creates a dependable base that helps
deploy unsupervised representation learning in different large-scale image
clustering applications.

</details>


### [9] [Learning to Collaborate Over Graphs: A Selective Federated Multi-Task Learning Approach](https://arxiv.org/abs/2506.10102)
*Ahmed Elbakary, Chaouki Ben Issaid, Mehdi Bennis*

**主要类别:** cs.LG

**AI概要:** 提出了一种新颖的联邦多任务学习方法，利用客户端之间的相似性来实现个性化学习。通过引入特征锚点和轻量级线性层，并将客户端协作建模为动态图进行持续更新与优化，该方法能够有效促进知识转移同时防止负面协作。实验表明，此方法在异构数据集上显著优于现有技术，并且在计算和通信效率以及跨客户端公平性方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 为了实现每个客户端的个性化学习，并避免将整个模型传输到参数服务器，同时确保有益的知识转移并防止负面影响的合作。

**方法:** 开发了一种通信高效的方案，引入了特征锚点——一个紧凑向量表示，用于总结从客户端本地类中学习到的特征。此外，客户共享分类头（轻量级线性层），并通过基于图的正则化来进行协作。客户端间的合作被建模为动态图，并使用社区检测方法将该图划分为同质社区以最大化任务相似性。

**结果:** 广泛的实验表明，所提方法在两个异构数据集上显著优于最先进基线。此外，该方法显示出优越的计算和通信效率，并促进了客户端之间的公平性。

**结论:** 本文提出的联邦多任务学习方法不仅能够有效地支持个性化学习，还提高了计算与通信效率，同时保证了跨客户端的公平性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Collaborate+Over+Graphs%3A+A+Selective+Federated+Multi-Task+Learning+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10102，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10102&send_immediately=true&force_search=false)

**原文摘要:** We present a novel federated multi-task learning method that leverages
cross-client similarity to enable personalized learning for each client. To
avoid transmitting the entire model to the parameter server, we propose a
communication-efficient scheme that introduces a feature anchor, a compact
vector representation that summarizes the features learned from the client's
local classes. This feature anchor is shared with the server to account for
local clients' distribution. In addition, the clients share the classification
heads, a lightweight linear layer, and perform a graph-based regularization to
enable collaboration among clients. By modeling collaboration between clients
as a dynamic graph and continuously updating and refining this graph, we can
account for any drift from the clients. To ensure beneficial knowledge transfer
and prevent negative collaboration, we leverage a community detection-based
approach that partitions this dynamic graph into homogeneous communities,
maximizing the sum of task similarities, represented as the graph edges'
weights, within each community. This mechanism restricts collaboration to
highly similar clients within their formed communities, ensuring positive
interaction and preserving personalization. Extensive experiments on two
heterogeneous datasets demonstrate that our method significantly outperforms
state-of-the-art baselines. Furthermore, we show that our method exhibits
superior computation and communication efficiency and promotes fairness across
clients.

</details>


### [10] [NnD: Diffusion-based Generation of Physically-Nonnegative Objects](https://arxiv.org/abs/2506.10112)
*Nadav Torem, Tamar Sde-Chen, Yoav Y. Schechner*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种非负扩散（NnD）生成模型，它利用基于分数的扩散方法和退火朗之万动力学来保证生成场景中的非负性。该模型经过高质量物理模拟对象训练后，能够用于生成符合云物理趋势的3D体积云。


<details>
  <summary>更多</summary>
  
**动机:** 许多自然物体具有内在的复杂性和可变性，而这些特性使得通过基本原理建模变得困难。对于像云形成这样的现实世界现象，需要进行计算成本高昂的模拟，这限制了其扩展性。因此，研究者们旨在寻找一种方法以大幅降低这类物理上有意义、非负对象的计算成本。

**方法:** 提出的方法是采用非负扩散（NnD），这是一种学习型生成模型，使用基于分数的扩散，并且调整了退火朗之万动力学来确保在迭代场景生成与分析过程中保持非负性。NnD 模型通过高质物理仿真对象的数据进行训练。

**结果:** NnD 能够生成三维体积云，这些云由固有的非负微观物理场组成，并且与云物理学的趋势一致。此外，专家感知上也无法区分它们与非物理的结果。

**结论:** 非负扩散（NnD）是一种有效的解决方案，可以大大减少对那些在物理意义上重要但计算成本高的非负对象进行模拟所需的计算资源。这种方法不仅适用于生成过程，也适用于推理任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NnD%3A+Diffusion-based+Generation+of+Physically-Nonnegative+Objects，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10112&send_immediately=true&force_search=false)

**原文摘要:** Most natural objects have inherent complexity and variability. While some
simple objects can be modeled from first principles, many real-world phenomena,
such as cloud formation, require computationally expensive simulations that
limit scalability. This work focuses on a class of physically meaningful,
nonnegative objects that are computationally tractable but costly to simulate.
To dramatically reduce computational costs, we propose nonnegative diffusion
(NnD). This is a learned generative model using score based diffusion. It
adapts annealed Langevin dynamics to enforce, by design, non-negativity
throughout iterative scene generation and analysis (inference). NnD trains on
high-quality physically simulated objects. Once trained, it can be used for
generation and inference. We demonstrate generation of 3D volumetric clouds,
comprising inherently nonnegative microphysical fields. Our generated clouds
are consistent with cloud physics trends. They are effectively not
distinguished as non-physical by expert perception.

</details>


### [11] [GRAIL: A Benchmark for GRaph ActIve Learning in Dynamic Sensing Environments](https://arxiv.org/abs/2506.10120)
*Maryam Khalid, Akane Sano*

**主要类别:** cs.LG

**AI概要:** 本文提出了GRAIL，这是一个新的基准测试框架，用于评估动态真实环境中的图主动学习策略。它引入了新的度量标准来评估持续有效性、多样性和用户负担，并通过实验揭示了现有主动学习策略的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于图的主动学习方法主要在静态图数据集上进行评估，且主要关注预测准确性，忽略了用户中心的考量如采样多样性、查询公平性以及对动态环境的适应性。

**方法:** 设计并实现了一个名为GRAIL的新基准测试框架，该框架旨在动态和现实世界环境中评价图主动学习策略。

**结果:** 通过使用包含动态现实生活人类传感器数据的数据集进行了广泛的实验，揭示了预测性能与用户负担之间的权衡关系，并展示了现有主动学习策略的局限性。

**结论:** GRAIL强调了节点重要性、查询多样性和网络拓扑之间平衡的重要性，为动态环境中的图主动学习解决方案提供了一种评价机制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GRAIL%3A+A+Benchmark+for+GRaph+ActIve+Learning+in+Dynamic+Sensing+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10120&send_immediately=true&force_search=false)

**原文摘要:** Graph-based Active Learning (AL) leverages the structure of graphs to
efficiently prioritize label queries, reducing labeling costs and user burden
in applications like health monitoring, human behavior analysis, and sensor
networks. By identifying strategically positioned nodes, graph AL minimizes
data collection demands while maintaining model performance, making it a
valuable tool for dynamic environments. Despite its potential, existing graph
AL methods are often evaluated on static graph datasets and primarily focus on
prediction accuracy, neglecting user-centric considerations such as sampling
diversity, query fairness, and adaptability to dynamic settings. To bridge this
gap, we introduce GRAIL, a novel benchmarking framework designed to evaluate
graph AL strategies in dynamic, real-world environments. GRAIL introduces novel
metrics to assess sustained effectiveness, diversity, and user burden, enabling
a comprehensive evaluation of AL methods under varying conditions. Extensive
experiments on datasets featuring dynamic, real-life human sensor data reveal
trade-offs between prediction performance and user burden, highlighting
limitations in existing AL strategies. GRAIL demonstrates the importance of
balancing node importance, query diversity, and network topology, providing an
evaluation mechanism for graph AL solutions in dynamic environments.

</details>


### [12] [Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms](https://arxiv.org/abs/2506.10127)
*Xinyi Hu, Aldo Pacchiano*

**主要类别:** cs.LG

**AI概要:** 本文研究了无感知设置下的分散式多玩家多臂老虎机问题，提出了一种新的算法A-CAPELLA，并引入了一种协作假设检验协议来实现同步的连续淘汰和容量估计。


<details>
  <summary>更多</summary>
  
**动机:** 在无感知环境下解决分散式多玩家多臂老虎机问题时，由于每个玩家只能收到自己的奖励信息而无法得知碰撞情况，因此带来了协调和发现容量的新挑战。

**方法:** 提出了A-CAPELLA算法，该算法通过精心设计的碰撞模式，实现了协同假设检验协议，从而支持同步的连续淘汰与容量估计。

**结果:** A-CAPELLA算法在未知手臂容量的分散式无感知MMAB中取得了对数级别的遗憾度表现，表明这是一种有效的学习结果。

**结论:** 研究提供了一种在反馈受限情况下处理未知容量的分散式多玩家多臂老虎机问题的有效方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meet+Me+at+the+Arm%3A+The+Cooperative+Multi-Armed+Bandits+Problem+with+Shareable+Arms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10127，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10127&send_immediately=true&force_search=false)

**原文摘要:** We study the decentralized multi-player multi-armed bandits (MMAB) problem
under a no-sensing setting, where each player receives only their own reward
and obtains no information about collisions. Each arm has an unknown capacity,
and if the number of players pulling an arm exceeds its capacity, all players
involved receive zero reward. This setting generalizes the classical
unit-capacity model and introduces new challenges in coordination and capacity
discovery under severe feedback limitations. We propose A-CAPELLA (Algorithm
for Capacity-Aware Parallel Elimination for Learning and Allocation), a
decentralized algorithm that achieves logarithmic regret in this generalized
regime. Our main contribution is a collaborative hypothesis testing protocol
that enables synchronized successive elimination and capacity estimation
through carefully structured collision patterns. This represents a provably
efficient learning result in decentralized no-sensing MMAB with unknown arm
capacities.

</details>


### [13] [Provable Sim-to-Real Transfer via Offline Domain Randomization](https://arxiv.org/abs/2506.10133)
*Arnaud Fickinger, Abderrahim Bendahi, Stuart Russell*

**主要类别:** cs.LG

**AI概要:** 本文研究了离线领域随机化（ODR）方法，该方法首先根据离线数据集拟合一个模拟器参数分布。文章提出了ODR的理论基础，并引入了E-DROPO算法以提高零样本迁移的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习智能体在从仿真到现实世界的部署中经常遇到困难。虽然领域随机化（DR）是减少仿真与现实差距的主要策略之一，但传统的DR没有利用已有的真实系统离线数据。因此，本文提出了一种新的方法来解决这个问题。

**方法:** 1. 将ODR形式化为参数化模拟器族的最大似然估计。
2. 证明了在温和的正则性和可识别条件下，这种估计量的一致性。
3. 推导出间隙界限，表明与均匀DR相比，ODR在有限模拟器情况下具有更小的仿真到现实误差。
4. 引入E-DROPO，通过添加熵奖励防止方差崩溃，从而实现更广泛的随机化和更稳健的实际应用中的零样本迁移。

**结果:** 研究表明ODR估计量随着数据集的增长收敛于真实的动态特性；并且相对于标准的DR，ODR能够提供最多O(M)因子更紧的仿真至现实误差边界。此外，E-DROPO方法能够在实践中促进更广泛的随机化和更强的零样本迁移能力。

**结论:** 本文为离线领域随机化(ODR)提供了坚实的理论基础，证明了其作为减少仿真与现实差距的有效方法的潜力。同时，新提出的E-DROPO算法通过改进的随机化策略进一步增强了模型的泛化能力和稳定性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Provable+Sim-to-Real+Transfer+via+Offline+Domain+Randomization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10133，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10133&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement-learning agents often struggle when deployed from simulation to
the real-world. A dominant strategy for reducing the sim-to-real gap is domain
randomization (DR) which trains the policy across many simulators produced by
sampling dynamics parameters, but standard DR ignores offline data already
available from the real system. We study offline domain randomization (ODR),
which first fits a distribution over simulator parameters to an offline
dataset. While a growing body of empirical work reports substantial gains with
algorithms such as DROPO, the theoretical foundations of ODR remain largely
unexplored. In this work, we (i) formalize ODR as a maximum-likelihood
estimation over a parametric simulator family, (ii) prove consistency of this
estimator under mild regularity and identifiability conditions, showing it
converges to the true dynamics as the dataset grows, (iii) derive gap bounds
demonstrating ODRs sim-to-real error is up to an O(M) factor tighter than
uniform DR in the finite-simulator case (and analogous gains in the continuous
setting), and (iv) introduce E-DROPO, a new version of DROPO which adds an
entropy bonus to prevent variance collapse, yielding broader randomization and
more robust zero-shot transfer in practice.

</details>


### [14] [Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning](https://arxiv.org/abs/2506.10137)
*Daniel Lawson, Adriana Hugessen, Charlotte Cloutier, Glen Berseth, Khimya Khetarpal*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的表示学习目标，即BYOL-γ增强的GCBC，它能够在不需要对比样本或TD学习的情况下理论上近似有限MDP情况下的后继表示，并且在需要组合泛化的挑战性任务中表现出竞争性的实证性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的目标条件行为克隆方法（GCBC）虽然能够很好地处理训练集内的任务，但它们并不一定能够零样本泛化到需要对新状态-目标对进行条件设置的任务上。这种局限性部分归因于通过行为克隆学到的状态表示缺乏时间一致性。如果时间相关的状态被编码成相似的潜在表示，那么对于新状态-目标对的分布外差距就会减少。因此，鼓励表示空间中的这种时间一致性应该有助于组合泛化。

**方法:** 研究者们提出了一种简单而有效的表示学习目标——BYOL-γ增强的目标条件行为克隆（GCBC），这种方法能够在没有对比样本和时序差分（TD）学习的情况下，在有限马尔可夫决策过程（MDP）情形下理论近似后继表示。

**结果:** 所提出的BYOL-γ增强GCBC方法不仅能够在理论上近似后继表示，而且在一系列要求组合泛化的具有挑战性的任务中显示出了有竞争力的实际表现。

**结论:** 通过引入一种不依赖对比样本或TD学习的新表示学习目标，本研究为提高GCBC方法的组合泛化能力提供了可能，从而让机器人等领域的策略学习更加有效。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Predictive+Representations+for+Combinatorial+Generalization+in+Behavioral+Cloning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10137，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10137&send_immediately=true&force_search=false)

**原文摘要:** Behavioral cloning (BC) methods trained with supervised learning (SL) are an
effective way to learn policies from human demonstrations in domains like
robotics. Goal-conditioning these policies enables a single generalist policy
to capture diverse behaviors contained within an offline dataset. While
goal-conditioned behavior cloning (GCBC) methods can perform well on
in-distribution training tasks, they do not necessarily generalize zero-shot to
tasks that require conditioning on novel state-goal pairs, i.e. combinatorial
generalization. In part, this limitation can be attributed to a lack of
temporal consistency in the state representation learned by BC; if temporally
related states are encoded to similar latent representations, then the
out-of-distribution gap for novel state-goal pairs would be reduced. Hence,
encouraging this temporal consistency in the representation space should
facilitate combinatorial generalization. Successor representations, which
encode the distribution of future states visited from the current state, nicely
encapsulate this property. However, previous methods for learning successor
representations have relied on contrastive samples, temporal-difference (TD)
learning, or both. In this work, we propose a simple yet effective
representation learning objective, $\text{BYOL-}\gamma$ augmented GCBC, which
is not only able to theoretically approximate the successor representation in
the finite MDP case without contrastive samples or TD learning, but also,
results in competitive empirical performance across a suite of challenging
tasks requiring combinatorial generalization.

</details>


### [15] [Interpreting learned search: finding a transition model and value function in an RNN that plays Sokoban](https://arxiv.org/abs/2506.10138)
*Mohammad Taufeeque, Aaron David Tucker, Adam Gleave, Adrià Garriga-Alonso*

**主要类别:** cs.LG

**AI概要:** 研究者部分地逆向工程了一个用于玩推箱子游戏的卷积递归神经网络（RNN），揭示了几个类似于经典双向搜索组件的机制。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是理解一个通过无模型强化学习训练来玩推箱子游戏的RNN，之前的研究发现该网络在测试时使用更多的计算资源能够解决更多的关卡。

**方法:** 研究者分析了RNN内部表示和处理过程，发现对于每个方格，RNN在与特定方向相关的通道激活中表示其计划，并且这些状态-动作激活类似于价值函数，它们的大小决定了何时回溯以及哪个计划分支存活下来。

**结果:** RNN展示了类似于传统双向搜索的机制，但也有不同之处，如状态表示不是统一的，而是分别考虑每个箱子；每一层都有自己的计划表示和价值函数，这增加了搜索深度。

**结论:** 虽然算法在某些方面不同于传统的搜索方法，但这个经过无模型训练的网络所学到的利用测试时计算能力的机制可以用熟悉的术语来理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpreting+learned+search%3A+finding+a+transition+model+and+value+function+in+an+RNN+that+plays+Sokoban，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10138，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10138&send_immediately=true&force_search=false)

**原文摘要:** We partially reverse-engineer a convolutional recurrent neural network (RNN)
trained to play the puzzle game Sokoban with model-free reinforcement learning.
Prior work found that this network solves more levels with more test-time
compute. Our analysis reveals several mechanisms analogous to components of
classic bidirectional search. For each square, the RNN represents its plan in
the activations of channels associated with specific directions. These
state-action activations are analogous to a value function - their magnitudes
determine when to backtrack and which plan branch survives pruning. Specialized
kernels extend these activations (containing plan and value) forward and
backward to create paths, forming a transition model. The algorithm is also
unlike classical search in some ways. State representation is not unified;
instead, the network considers each box separately. Each layer has its own plan
representation and value function, increasing search depth. Far from being
inscrutable, the mechanisms leveraging test-time compute learned in this
network by model-free training can be understood in familiar terms.

</details>


### [16] [Survival Analysis as Imprecise Classification with Trainable Kernels](https://arxiv.org/abs/2506.10140)
*Andrei V. Konstantinov, Vlada A. Efremenko, Lev V. Utkin*

**主要类别:** cs.LG

**AI概要:** 本文提出了三种基于不精确概率理论和注意力机制的新型生存模型iSurvM、iSurvQ和iSurvJ，用于处理带有删失数据的时间到事件数据。实验表明这些模型在准确性和计算复杂性方面优于传统的Beran估计量。


<details>
  <summary>更多</summary>
  
**动机:** 传统方法如Beran估计量虽然提供了非参数解，但在面对复杂数据结构和重度删失时往往表现不佳。

**方法:** 提出三个新的生存模型：iSurvM（基于平均似然函数的不精确生存模型）、iSurvQ（基于似然函数分位数的不精确生存模型）和iSurvJ（基于联合学习的不精确生存模型）。这些模型结合了不精确概率论与注意力机制来处理删失数据，并且不需要参数假设。

**结果:** 实验结果表明，特别是在合成数据集和真实数据集上，所提出的模型尤其是iSurvJ，在准确性和计算复杂性方面始终优于Beran估计量。

**结论:** 新提出的iSurvM、iSurvQ和iSurvJ模型为处理时间到事件数据提供了一种有效的方法，特别适用于存在大量删失的情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Survival+Analysis+as+Imprecise+Classification+with+Trainable+Kernels，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10140&send_immediately=true&force_search=false)

**原文摘要:** Survival analysis is a fundamental tool for modeling time-to-event data in
healthcare, engineering, and finance, where censored observations pose
significant challenges. While traditional methods like the Beran estimator
offer nonparametric solutions, they often struggle with the complex data
structures and heavy censoring. This paper introduces three novel survival
models, iSurvM (the imprecise Survival model based on Mean likelihood
functions), iSurvQ (the imprecise Survival model based on the Quantiles of
likelihood functions), and iSurvJ (the imprecise Survival model based on the
Joint learning), that combine imprecise probability theory with attention
mechanisms to handle censored data without parametric assumptions. The first
idea behind the models is to represent censored observations by interval-valued
probability distributions for each instance over time intervals between events
moments. The second idea is to employ the kernel-based Nadaraya-Watson
regression with trainable attention weights for computing the imprecise
probability distribution over time intervals for the entire dataset. The third
idea is to consider three decision strategies for training, which correspond to
the proposed three models. Experiments on synthetic and real datasets
demonstrate that the proposed models, especially iSurvJ, consistently
outperform the Beran estimator from the accuracy and computational complexity
points of view. Codes implementing the proposed models are publicly available.

</details>


### [17] [Probabilistic Variational Contrastive Learning](https://arxiv.org/abs/2506.10159)
*Minoh Jeong, Seonho Kim, Alfred Hero*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的对比学习框架——变分对比学习（VCL），它通过将InfoNCE损失解释为替代重构项，并添加KL散度正则化项到单位超球体上的均匀先验，来最大化证据下界。该方法克服了确定性嵌入无法量化不确定性的缺点，同时在多个基准测试中提高了分类准确性，并提供了有意义的不确定性估计。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对比学习方法如SimCLR和SupCon虽然取得了最先进的性能，但缺乏一个系统化的机制来量化不确定性。为了填补这一空白，作者提出了变分对比学习（VCL）以提供一种概率基础的方法，从而允许不确定性度量。

**方法:** VCL是一种无需解码器的框架，它通过将InfoNCE损失视为替代重构项，并向单位超球面上的均匀先验添加KL散度正则化项来最大化证据下界（ELBO）。近似后验$q_\theta(z|x)$被建模为投影正态分布，使得可以采样概率嵌入。VCL的两种实例——VSimCLR和VSupCon——用来自$q_\theta(z|x)$的样本替换确定性嵌入，并在损失函数中加入归一化的KL项。

**结果:** 实验表明，VCL能够缓解维度崩溃问题，增强与类别标签的互信息，并且在分类准确率上匹配或超越确定性基线模型，同时通过后验模型提供有意义的不确定性估计。

**结论:** VCL为对比学习提供了一个概率基础，作为对比学习方法的新基础，它不仅改善了分类任务的表现，还解决了不确定性量化的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probabilistic+Variational+Contrastive+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10159，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10159&send_immediately=true&force_search=false)

**原文摘要:** Deterministic embeddings learned by contrastive learning (CL) methods such as
SimCLR and SupCon achieve state-of-the-art performance but lack a principled
mechanism for uncertainty quantification. We propose Variational Contrastive
Learning (VCL), a decoder-free framework that maximizes the evidence lower
bound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstruction
term and adding a KL divergence regularizer to a uniform prior on the unit
hypersphere. We model the approximate posterior $q_\theta(z|x)$ as a projected
normal distribution, enabling the sampling of probabilistic embeddings. Our two
instantiations--VSimCLR and VSupCon--replace deterministic embeddings with
samples from $q_\theta(z|x)$ and incorporate a normalized KL term into the
loss. Experiments on multiple benchmarks demonstrate that VCL mitigates
dimensional collapse, enhances mutual information with class labels, and
matches or outperforms deterministic baselines in classification accuracy, all
the while providing meaningful uncertainty estimates through the posterior
model. VCL thus equips contrastive learning with a probabilistic foundation,
serving as a new basis for contrastive approaches.

</details>


### [18] [Physiological-Model-Based Neural Network for Heart Rate Estimation during Daily Physical Activities](https://arxiv.org/abs/2506.10144)
*Yaowen Zhang, Libera Fresiello, Peter H. Veltink, Dirk W. Donker, Ying Wang*

**主要类别:** cs.LG

**AI概要:** 本研究开发了一种基于生理模型的神经网络框架(PMB-NN)，用于根据日常体力活动中的摄氧量数据估计心率。该框架在12名参与者的个体数据集上训练和测试，通过将从简化的人体运动生理模型中得出的生理约束嵌入到神经网络训练过程中，PMB-NN模型遵循人体生理原则并实现高精度估计。


<details>
  <summary>更多</summary>
  
**动机:** 现有的心力衰竭（HF）检测中心率监测工具依赖于基于人群平均值的数据，而个体化的心率估计可以作为动态数字孪生，帮助精确跟踪心脏健康生物标志物。当前的心率估计方法存在效率和可解释性的问题。

**方法:** 研究提出了一种新颖的基于生理模型的神经网络（PMB-NN）框架，利用参与者在休息、骑自行车和跑步等活动期间收集的摄氧量(VO2)数据来估计心率，并且在神经网络训练过程中嵌入了生理约束条件。

**结果:** PMB-NN模型达到了较高的估计准确性，中位R^2得分为0.8，RMSE为8.3 bpm。统计分析表明，PMB-NN的表现与基准神经网络模型相当，但显著优于传统的生理模型(p=0.002)。此外，PMB-NN能够识别PM的个性化参数，使PM能够生成合理的心率估计。

**结论:** 提出的结合了准确VO2估计系统的PMB-NN框架，为日常生活体力活动期间个性化的实时心脏监测提供了未来可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Physiological-Model-Based+Neural+Network+for+Heart+Rate+Estimation+during+Daily+Physical+Activities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10144，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10144&send_immediately=true&force_search=false)

**原文摘要:** Heart failure (HF) poses a significant global health challenge, with early
detection offering opportunities for improved outcomes. Abnormalities in heart
rate (HR), particularly during daily activities, may serve as early indicators
of HF risk. However, existing HR monitoring tools for HF detection are limited
by their reliability on population-based averages. The estimation of
individualized HR serves as a dynamic digital twin, enabling precise tracking
of cardiac health biomarkers. Current HR estimation methods, categorized into
physiologically-driven and purely data-driven models, struggle with efficiency
and interpretability. This study introduces a novel physiological-model-based
neural network (PMB-NN) framework for HR estimation based on oxygen uptake
(VO2) data during daily physical activities. The framework was trained and
tested on individual datasets from 12 participants engaged in activities
including resting, cycling, and running. By embedding physiological
constraints, which were derived from our proposed simplified human movement
physiological model (PM), into the neural network training process, the PMB-NN
model adheres to human physiological principles while achieving high estimation
accuracy, with a median R$^2$ score of 0.8 and an RMSE of 8.3 bpm. Comparative
statistical analysis demonstrates that the PMB-NN achieves performance on par
with the benchmark neural network model while significantly outperforming
traditional physiological model (p=0.002). In addition, our PMB-NN is adept at
identifying personalized parameters of the PM, enabling the PM to generate
reasonable HR estimation. The proposed framework with a precise VO2 estimation
system derived from body movements enables the future possibilities of
personalized and real-time cardiac monitoring during daily life physical
activities.

</details>


### [19] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
*Defang Chen, Zhenyu Zhou, Can Wang, Siwei Lyu*

**主要类别:** cs.LG

**AI概要:** 论文揭示了基于扩散的生成模型中确定性采样动力学的一个显著几何规律：所有模拟采样轨迹都位于一个极低维的子空间内，并且无论模型架构、应用条件或生成内容如何，这些轨迹都表现出几乎相同的“回力镖”形状。通过提出的动态规划方案更好地将采样时间表与底层轨迹结构对齐，这一策略只需对现有的基于ODE的数值求解器进行最小修改，即可实现卓越的图像生成功能，特别是在只有5到10次函数评估的区域。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探索和理解基于扩散的生成模型中确定性采样过程的内在几何规律，以期发现可以利用的新特性来提高生成性能。

**方法:** 研究者观察并分析了不同条件下采样轨迹的共同几何特征，并提出了一个基于动态规划的方法来优化采样时间安排，使之与轨迹结构更加匹配。

**结果:** 结果表明，所有采样轨迹共享一种特定的低维度几何形态，而且提出的时间调整方法能够有效提升图像生成质量，尤其是在有限的函数评估次数下。

**结论:** 该文发现了扩散模型采样轨迹的几何规则性，并展示了一种简单而有效的办法来改进现有基于ODE求解器的采样效率和生成效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Geometric+Regularity+in+Deterministic+Sampling+of+Diffusion-based+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10177，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10177&send_immediately=true&force_search=false)

**原文摘要:** Diffusion-based generative models employ stochastic differential equations
(SDEs) and their equivalent probability flow ordinary differential equations
(ODEs) to establish a smooth transformation between complex high-dimensional
data distributions and tractable prior distributions. In this paper, we reveal
a striking geometric regularity in the deterministic sampling dynamics: each
simulated sampling trajectory lies within an extremely low-dimensional
subspace, and all trajectories exhibit an almost identical ''boomerang'' shape,
regardless of the model architecture, applied conditions, or generated content.
We characterize several intriguing properties of these trajectories,
particularly under closed-form solutions based on kernel-estimated data
modeling. We also demonstrate a practical application of the discovered
trajectory regularity by proposing a dynamic programming-based scheme to better
align the sampling time schedule with the underlying trajectory structure. This
simple strategy requires minimal modification to existing ODE-based numerical
solvers, incurs negligible computational overhead, and achieves superior image
generation performance, especially in regions with only $5 \sim 10$ function
evaluations.

</details>


### [20] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
*Tejaswi Kasarla, Max van Spengler, Pascal Mettes*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种平衡双曲学习方法，通过优化层次失真和子层次间的平衡来改进分布外样本识别。实验表明，该方法在13个数据集上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决深度学习中一个重要的问题：过滤掉不属于训练网络所用分布的样本。本文旨在寻找一种好的层次双曲嵌入方法以区分分布内和分布外样本。

**方法:** 提出了一种平衡双曲学习方法，并且设计了一个能够同时优化层次结构失真和浅宽子层次之间平衡的双曲类嵌入算法。将这些类嵌入作为双曲原型用于分类，并将现有的分布外评分函数推广到与双曲原型一起使用。

**结果:** 在13个数据集和13个评分函数上的实证评估显示，当使用相同的数据和相同的主干网络进行训练时，提出的双曲嵌入法超越了现有的分布外方法。此外，它还优于其他双曲方法，并且自然地支持层次化的分布外泛化。

**结论:** 良好的层次双曲嵌入对于区分分布内外样本是优选方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Balanced+Hyperbolic+Embeddings+Are+Natural+Out-of-Distribution+Detectors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10146，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10146&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution recognition forms an important and well-studied problem
in deep learning, with the goal to filter out samples that do not belong to the
distribution on which a network has been trained. The conclusion of this paper
is simple: a good hierarchical hyperbolic embedding is preferred for
discriminating in- and out-of-distribution samples. We introduce Balanced
Hyperbolic Learning. We outline a hyperbolic class embedding algorithm that
jointly optimizes for hierarchical distortion and balancing between shallow and
wide subhierarchies. We then use the class embeddings as hyperbolic prototypes
for classification on in-distribution data. We outline how to generalize
existing out-of-distribution scoring functions to operate with hyperbolic
prototypes. Empirical evaluations across 13 datasets and 13 scoring functions
show that our hyperbolic embeddings outperform existing out-of-distribution
approaches when trained on the same data with the same backbones. We also show
that our hyperbolic embeddings outperform other hyperbolic approaches, beat
state-of-the-art contrastive methods, and natively enable hierarchical
out-of-distribution generalization.

</details>


### [21] [Meta-learning Representations for Learning from Multiple Annotators](https://arxiv.org/abs/2506.10259)
*Atsutoshi Kumagai, Tomoharu Iwata, Taishi Nishiyama, Yasutoshi Ida, Yasuhiro Fujiwara*

**主要类别:** cs.LG

**AI概要:** 提出了一种元学习方法，用于从多个噪声标注者中学习。该方法通过神经网络将每个任务中的示例嵌入到潜在空间，并构建一个概率模型来学习特定于任务的分类器，同时估计标注者在潜在空间中的能力。实验表明该方法在合成噪声和真实众包数据集上有效。


<details>
  <summary>更多</summary>
  
**动机:** 在诸如众包服务等许多应用中，监督学习的标签由多个标注者提供。由于标注者具有不同的技能或偏见，给出的标签可能是有噪声的。为了学习准确的分类器，现有方法需要大量的噪声标注数据。然而，在实践中可能无法获得足够的数据。为了解决数据不足的问题，本文提出的方法利用在不同但相关任务中获得的标注数据。

**方法:** 所提出的方法使用神经网络将每个任务中的示例嵌入到一个潜在空间，并且建立了一个概率模型来学习针对任务的分类器，同时也估计了标注者在这个潜在空间的能力。神经网络通过元学习进行训练，以提高当分类器适应少量标注数据时预期的测试分类性能。分类器的适应是通过最大化后验概率来进行的，这通过期望最大化（EM）算法实现。

**结果:** 展示了该方法在包含合成噪声的真实世界数据集以及真实世界的众包数据集上的有效性。

**结论:** 提出的方法可以有效地利用来自不同但相关任务的数据来学习如何处理来自多个噪声标注者的标签，从而即使在只有少量标注数据的情况下也能改进分类器。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-learning+Representations+for+Learning+from+Multiple+Annotators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10259，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10259&send_immediately=true&force_search=false)

**原文摘要:** We propose a meta-learning method for learning from multiple noisy
annotators. In many applications such as crowdsourcing services, labels for
supervised learning are given by multiple annotators. Since the annotators have
different skills or biases, given labels can be noisy. To learn accurate
classifiers, existing methods require many noisy annotated data. However,
sufficient data might be unavailable in practice. To overcome the lack of data,
the proposed method uses labeled data obtained in different but related tasks.
The proposed method embeds each example in tasks to a latent space by using a
neural network and constructs a probabilistic model for learning a
task-specific classifier while estimating annotators' abilities on the latent
space. This neural network is meta-learned to improve the expected test
classification performance when the classifier is adapted to a given small
amount of annotated data. This classifier adaptation is performed by maximizing
the posterior probability via the expectation-maximization (EM) algorithm.
Since each step in the EM algorithm is easily computed as a closed-form and is
differentiable, the proposed method can efficiently backpropagate the loss
through the EM algorithm to meta-learn the neural network. We show the
effectiveness of our method with real-world datasets with synthetic noise and
real-world crowdsourcing datasets.

</details>


### [22] [Collaborative Min-Max Regret in Grouped Multi-Armed Bandits](https://arxiv.org/abs/2506.10313)
*Moïse Blanchard, Vineet Goyal*

**主要类别:** cs.LG

**AI概要:** 研究了分组场景下多臂老虎机中探索共享的影响，提出了一种名为Col-UCB的算法，该算法能够动态协调组间的探索，并在最小化协作遗憾方面达到最优。


<details>
  <summary>更多</summary>
  
**动机:** 在分组的多臂老虎机设置中，标准算法可能导致各组之间的探索成本显著不平衡。本文旨在通过引入一种新算法来平衡不同组或人群之间的探索负担。

**方法:** 提出了Col-UCB算法，该算法可以动态地在小组间协调探索策略。

**结果:** 证明了Col-UCB算法达到了最优的最坏情况和实例相关协作遗憾（忽略对数因子）。这些结果表明，在组间有共享动作集的情况下，协作比独立学习每个组的最佳动作更有效。

**结论:** Col-UCB算法有效地解决了组内多臂老虎机问题中的协作探索难题，为实际应用提供了理论基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collaborative+Min-Max+Regret+in+Grouped+Multi-Armed+Bandits，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10313&send_immediately=true&force_search=false)

**原文摘要:** We study the impact of sharing exploration in multi-armed bandits in a
grouped setting where a set of groups have overlapping feasible action sets
[Baek and Farias '24]. In this grouped bandit setting, groups share reward
observations, and the objective is to minimize the collaborative regret,
defined as the maximum regret across groups. This naturally captures
applications in which one aims to balance the exploration burden between groups
or populations -- it is known that standard algorithms can lead to
significantly imbalanced exploration cost between groups. We address this
problem by introducing an algorithm Col-UCB that dynamically coordinates
exploration across groups. We show that Col-UCB achieves both optimal minimax
and instance-dependent collaborative regret up to logarithmic factors. These
bounds are adaptive to the structure of shared action sets between groups,
providing insights into when collaboration yields significant benefits over
each group learning their best action independently.

</details>


### [23] [The 2025 PNPL Competition: Speech Detection and Phoneme Classification in the LibriBrain Dataset](https://arxiv.org/abs/2506.10165)
*Gilad Landau, Miran Özdogan, Gereon Elvers, Francesco Mantegna, Pratik Somaiya, Dulhan Jayalath, Luisa Kurth, Teyun Kwon, Brendan Shillingford, Greg Farquhar, Minqi Jiang, Karim Jerbi, Hamza Abdelhedi, Yorguin Mantilla Ramos, Caglar Gulcehre, Mark Woolrich, Natalie Voets, Oiwi Parker Jones*

**主要类别:** cs.LG

**AI概要:** 论文介绍了2025 PNPL竞赛，该竞赛旨在通过提供大规模的脑磁图（MEG）数据集LibriBrain和便于使用的Python库pnpl来促进非侵入性神经解码技术的发展。定义了两个基础任务，并提供了标准化的数据分割、评估指标、基准模型、教程代码、讨论区和公开排行榜。竞赛设有标准赛道和扩展赛道以鼓励算法创新并加速计算规模。


<details>
  <summary>更多</summary>
  
**动机:** 推动非侵入性语音解码技术的发展，特别是为了恢复受言语缺陷影响的瘫痪个体的交流能力，而无需进行高风险手术干预。

**方法:** 构建了迄今为止最大的单个被试者MEG数据集LibriBrain，并开发了一个用户友好的Python库pnpl以便于数据访问和与深度学习框架的集成。此外，还为比赛设立了两个基础任务：语音检测和从脑数据中进行音素分类。

**结果:** 创建了包含标准化数据分割和评价指标的任务，以及示例性的基准模型、在线教程代码、社区讨论版和提交作品的公开排行榜。

**结论:** 通过设立标准和扩展两大赛道，促进了算法创新和更大规模的计算，朝着实现非侵入式脑-机接口用于语音交流的目标迈进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+2025+PNPL+Competition%3A+Speech+Detection+and+Phoneme+Classification+in+the+LibriBrain+Dataset，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10165，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10165&send_immediately=true&force_search=false)

**原文摘要:** The advance of speech decoding from non-invasive brain data holds the
potential for profound societal impact. Among its most promising applications
is the restoration of communication to paralysed individuals affected by speech
deficits such as dysarthria, without the need for high-risk surgical
interventions. The ultimate aim of the 2025 PNPL competition is to produce the
conditions for an "ImageNet moment" or breakthrough in non-invasive neural
decoding, by harnessing the collective power of the machine learning community.
  To facilitate this vision we present the largest within-subject MEG dataset
recorded to date (LibriBrain) together with a user-friendly Python library
(pnpl) for easy data access and integration with deep learning frameworks. For
the competition we define two foundational tasks (i.e. Speech Detection and
Phoneme Classification from brain data), complete with standardised data splits
and evaluation metrics, illustrative benchmark models, online tutorial code, a
community discussion board, and public leaderboard for submissions. To promote
accessibility and participation the competition features a Standard track that
emphasises algorithmic innovation, as well as an Extended track that is
expected to reward larger-scale computing, accelerating progress toward a
non-invasive brain-computer interface for speech.

</details>


### [24] [Air in Your Neighborhood: Fine-Grained AQI Forecasting Using Mobile Sensor Data](https://arxiv.org/abs/2506.10332)
*Aaryam Sharma*

**主要类别:** cs.LG

**AI概要:** 本文通过使用时空图神经网络（Spatio-temporal GNNs）来预测1平方公里内的空气质量指数（AQI），显著提高了预测精度，并发现了AQI的新见解。


<details>
  <summary>更多</summary>
  
**动机:** 空气污染在发展中国家已成为一个重大的健康风险，但现有的空气质量指数数据由于传感器稀疏而无法准确反映局部现实情况。

**方法:** 采用时空图神经网络（Spatio-temporal GNNs）对1平方公里范围内的空气质量指数进行预测，以AirDelhi数据集为例。

**结果:** 与现有工作相比，在未见过的坐标上实现了71.654 MSE的误差降低，相当于减少了79%的误差。此外，还发现了AQI存在强烈的短期重复模式和变化的空间关系等新见解。

**结论:** 通过利用时空GNNs，能够更加精确地预测局部地区的AQI，并揭示了AQI的一些新的特性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Air+in+Your+Neighborhood%3A+Fine-Grained+AQI+Forecasting+Using+Mobile+Sensor+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10332，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10332&send_immediately=true&force_search=false)

**原文摘要:** Air pollution has become a significant health risk in developing countries.
While governments routinely publish air-quality index (AQI) data to track
pollution, these values fail to capture the local reality, as sensors are often
very sparse. In this paper, we address this gap by predicting AQI in 1 km^2
neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporal
GNNs we surpass existing works by 71.654 MSE a 79% reduction, even on unseen
coordinates. New insights about AQI such as the existence of strong repetitive
short-term patterns and changing spatial relations are also discovered. The
code is available on GitHub.

</details>


### [25] [Wasserstein Barycenter Soft Actor-Critic](https://arxiv.org/abs/2506.10167)
*Zahra Shahrooei, Ali Baheri*

**主要类别:** cs.LG

**AI概要:** 提出了Wasserstein Barycenter Soft Actor-Critic (WBSAC)算法，通过悲观和乐观策略的Wasserstein重心来促进探索，从而提高连续控制任务中的样本效率。


<details>
  <summary>更多</summary>
  
**动机:** 解决深度非策略actor-critic算法在稀疏奖励环境中样本效率低下的问题。

**方法:** 提出了一种有原则的定向探索策略，即Wasserstein Barycenter Soft Actor-Critic (WBSAC) 算法，该算法结合了悲观actor用于时序差分学习以及乐观actor以促进探索，并且通过调整学习过程中的探索程度来实现。

**结果:** WBSAC与最先进非策略actor-critic算法相比，在MuJoCo连续控制任务上表现出更高的样本效率。

**结论:** WBSAC算法通过结合悲观和乐观策略提供了一个有效的探索机制，从而提高了在连续控制领域中的样本利用效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Wasserstein+Barycenter+Soft+Actor-Critic，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10167，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10167&send_immediately=true&force_search=false)

**原文摘要:** Deep off-policy actor-critic algorithms have emerged as the leading framework
for reinforcement learning in continuous control domains. However, most of
these algorithms suffer from poor sample efficiency, especially in environments
with sparse rewards. In this paper, we take a step towards addressing this
issue by providing a principled directed exploration strategy. We propose
Wasserstein Barycenter Soft Actor-Critic (WBSAC) algorithm, which benefits from
a pessimistic actor for temporal difference learning and an optimistic actor to
promote exploration. This is achieved by using the Wasserstein barycenter of
the pessimistic and optimistic policies as the exploration policy and adjusting
the degree of exploration throughout the learning process. We compare WBSAC
with state-of-the-art off-policy actor-critic algorithms and show that WBSAC is
more sample-efficient on MuJoCo continuous control tasks.

</details>


### [26] [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org/abs/2506.10378)
*Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了一种因果表示学习框架，用于解决语言模型能力评估中的方法论挑战。通过控制基础模型作为共同混淆因素，识别出三个节点的线性因果结构，揭示了从一般问题解决能力到指令遵循熟练度再到数学推理能力的清晰因果方向。


<details>
  <summary>更多</summary>
  
**动机:** 对语言模型能力进行准确评估对于提供可操作的见解以指导模型开发至关重要。然而，在该领域中严格的因果评估面临显著的方法论挑战，包括复杂的混淆效应和大量重新训练相关的高昂计算成本。

**方法:** 提出了一个因果表示学习框架，其中观察到的基准性能被建模为少数潜在能力因子的线性变换。关键在于，这些潜在因子在适当控制基础模型作为共同混淆因素后被确定为因果相关。

**结果:** 应用这种方法于包含超过1500个模型的数据集，这些模型在开放LLM排行榜上的六个基准上进行了评估，研究者们识别出了一个简洁的三节点线性因果结构，能够可靠地解释观察到的表现差异。

**结论:** 结果强调了在评估过程中仔细控制基础模型变化的重要性，这对于准确揭示潜在模型能力之间的因果关系至关重要。此外，对这一因果结构的进一步解读提供了超出简单数值排名的重要科学见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Discovering+Hierarchical+Latent+Capabilities+of+Language+Models+via+Causal+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10378，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10378&send_immediately=true&force_search=false)

**原文摘要:** Faithful evaluation of language model capabilities is crucial for deriving
actionable insights that can inform model development. However, rigorous causal
evaluations in this domain face significant methodological challenges,
including complex confounding effects and prohibitive computational costs
associated with extensive retraining. To tackle these challenges, we propose a
causal representation learning framework wherein observed benchmark performance
is modeled as a linear transformation of a few latent capability factors.
Crucially, these latent factors are identified as causally interrelated after
appropriately controlling for the base model as a common confounder. Applying
this approach to a comprehensive dataset encompassing over 1500 models
evaluated across six benchmarks from the Open LLM Leaderboard, we identify a
concise three-node linear causal structure that reliably explains the observed
performance variations. Further interpretation of this causal structure
provides substantial scientific insights beyond simple numerical rankings:
specifically, we reveal a clear causal direction starting from general
problem-solving capabilities, advancing through instruction-following
proficiency, and culminating in mathematical reasoning ability. Our results
underscore the essential role of carefully controlling base model variations
during evaluation, a step critical to accurately uncovering the underlying
causal relationships among latent model capabilities.

</details>


### [27] [Size-adaptive Hypothesis Testing for Fairness](https://arxiv.org/abs/2506.10586)
*Antonio Ferrara, Francesco Cozzi, Alan Perotti, André Panisson, Francesco Bonchi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种统一的、适应规模的假设检验框架，用于将公平性评估转化为基于证据的统计决策。对于足够大的子群体，提供了中心极限定理的结果；对于小的交叉群体，则开发了一个完全贝叶斯狄利克雷-多项式估计器。通过基准数据集验证了方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的算法决策系统在评估是否对特定人群存在歧视时，通常会比较单一的公平度量点估计值与预设阈值，这种做法忽略了抽样误差，并且不区分大小不同的群体。当考虑多个敏感属性时，问题变得更加严重，导致难以得出关于潜在不公平待遇的有意义结论。

**方法:** 提出了一个统一的、适应规模的假设检验框架，该框架包括：(i) 对于足够大的子群体，证明了统计平权差异的中心极限结果，从而得到分析置信区间和Wald检验，其I类（假阳性）错误保证在α水平。(ii) 对于小交叉群体的长尾部分，推导出了一个完全贝叶斯狄利克雷-多项式估计器；蒙特卡洛可信区间被校准为任何样本大小，并随着更多数据可用自然收敛到Wald区间。

**结果:** 通过基准数据集的经验验证表明，所提出的测试能够在不同数据可用性和交叉性的条件下提供可解释的、统计上严格的决策。

**结论:** 本文介绍的方法能够更准确地评估算法决策系统的公平性，特别是在处理较小的交叉群体时，能够提供可靠的统计决策支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Size-adaptive+Hypothesis+Testing+for+Fairness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10586，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10586&send_immediately=true&force_search=false)

**原文摘要:** Determining whether an algorithmic decision-making system discriminates
against a specific demographic typically involves comparing a single point
estimate of a fairness metric against a predefined threshold. This practice is
statistically brittle: it ignores sampling error and treats small demographic
subgroups the same as large ones. The problem intensifies in intersectional
analyses, where multiple sensitive attributes are considered jointly, giving
rise to a larger number of smaller groups. As these groups become more
granular, the data representing them becomes too sparse for reliable
estimation, and fairness metrics yield excessively wide confidence intervals,
precluding meaningful conclusions about potential unfair treatments.
  In this paper, we introduce a unified, size-adaptive, hypothesis-testing
framework that turns fairness assessment into an evidence-based statistical
decision. Our contribution is twofold. (i) For sufficiently large subgroups, we
prove a Central-Limit result for the statistical parity difference, leading to
analytic confidence intervals and a Wald test whose type-I (false positive)
error is guaranteed at level $\alpha$. (ii) For the long tail of small
intersectional groups, we derive a fully Bayesian Dirichlet-multinomial
estimator; Monte-Carlo credible intervals are calibrated for any sample size
and naturally converge to Wald intervals as more data becomes available. We
validate our approach empirically on benchmark datasets, demonstrating how our
tests provide interpretable, statistically rigorous decisions under varying
degrees of data availability and intersectionality.

</details>


### [28] [A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes](https://arxiv.org/abs/2506.10180)
*Mowafaq Salem Alzboon, Mohammad Al-Batah, Muhyeeddin Alqaraleh, Ahmad Abuashour, Ahmad Fuad Bader*

**主要类别:** cs.LG

**AI概要:** 本研究使用Pima Indians Diabetes数据集评估了多种机器学习方法对糖尿病预测的有效性，结果表明神经网络算法表现最佳，准确率达到78.57%，其次是随机森林方法，准确率为76.30%。


<details>
  <summary>更多</summary>
  
**动机:** 糖尿病在许多国家正成为一个重大的健康问题，早期识别和控制至关重要。

**方法:** 研究中评估的方法包括逻辑回归、决策树、随机森林、k-最近邻、朴素贝叶斯、支持向量机、梯度提升以及神经网络。这些方法被用来基于包含患者年龄、BMI和血糖水平等信息的数据集进行糖尿病预测。

**结果:** 神经网络算法表现最好，准确率为78.57%，其次是随机森林方法，准确率为76.30%。

**结论:** 研究表明机器学习算法可以帮助糖尿病预测，并且可以作为有效的早期检测工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comparative+Study+of+Machine+Learning+Techniques+for+Early+Prediction+of+Diabetes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10180，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10180&send_immediately=true&force_search=false)

**原文摘要:** In many nations, diabetes is becoming a significant health problem, and early
identification and control are crucial. Using machine learning algorithms to
predict diabetes has yielded encouraging results. Using the Pima Indians
Diabetes dataset, this study attempts to evaluate the efficacy of several
machine-learning methods for diabetes prediction. The collection includes
information on 768 patients, such as their ages, BMIs, and glucose levels. The
techniques assessed are Logistic Regression, Decision Tree, Random Forest,
k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting,
and Neural Network. The findings indicate that the Neural Network algorithm
performed the best, with an accuracy of 78.57 percent, followed by the Random
Forest method, with an accuracy of 76.30 percent. The study implies that
machine learning algorithms can aid diabetes prediction and be an efficient
early detection tool.

</details>


### [29] [Rethinking Losses for Diffusion Bridge Samplers](https://arxiv.org/abs/2506.10982)
*Sebastian Sanokowski, Lukas Gruber, Christoph Bartmann, Sepp Hochreiter, Sebastian Lehner*

**主要类别:** cs.LG

**AI概要:** 研究发现对于扩散桥，Log Variance (LV)损失函数不如反向Kullback-Leibler (rKL)损失函数结合对数导数技巧（rKL-LD）有效。实验结果表明，使用rKL-LD损失训练的采样器在性能上更优，并且需要较少的超参数优化，提供了更加稳定的训练过程。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探讨为什么Log Variance (LV)损失函数在使用重参数化技巧计算rKL梯度时通常优于rKL损失函数，以及这种优势是否同样适用于扩散桥或学习扩散系数的情况。

**方法:** 通过对扩散桥进行分析，比较了Log Variance (LV)损失和反向Kullback-Leibler (rKL)损失函数结合对数导数技巧（rKL-LD）在不同情况下的表现。

**结果:** 结果显示，对于扩散桥来说，rKL-LD不仅避免了概念上的问题，而且在性能上一致优于LV损失。此外，从实际角度来看，rKL-LD需要显著减少的超参数优化，并且提供更稳定的训练行为。

**结论:** 结论是，对于扩散桥而言，采用rKL-LD损失比LV损失更为优越，因为它可以避免理论上的问题，同时在实践中表现出更好的性能和稳定性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Losses+for+Diffusion+Bridge+Samplers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10982，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10982&send_immediately=true&force_search=false)

**原文摘要:** Diffusion bridges are a promising class of deep-learning methods for sampling
from unnormalized distributions. Recent works show that the Log Variance (LV)
loss consistently outperforms the reverse Kullback-Leibler (rKL) loss when
using the reparametrization trick to compute rKL-gradients. While the on-policy
LV loss yields identical gradients to the rKL loss when combined with the
log-derivative trick for diffusion samplers with non-learnable forward
processes, this equivalence does not hold for diffusion bridges or when
diffusion coefficients are learned. Based on this insight we argue that for
diffusion bridges the LV loss does not represent an optimization objective that
can be motivated like the rKL loss via the data processing inequality. Our
analysis shows that employing the rKL loss with the log-derivative trick
(rKL-LD) does not only avoid these conceptual problems but also consistently
outperforms the LV loss. Experimental results with different types of diffusion
bridges on challenging benchmarks show that samplers trained with the rKL-LD
loss achieve better performance. From a practical perspective we find that
rKL-LD requires significantly less hyperparameter optimization and yields more
stable training behavior.

</details>


### [30] [Optimizing Genetic Algorithms with Multilayer Perceptron Networks for Enhancing TinyFace Recognition](https://arxiv.org/abs/2506.10184)
*Mohammad Subhi Al-Batah, Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh*

**主要类别:** cs.LG

**AI概要:** 本研究通过三个不同数据集上的系统实验，探讨了多层感知器(MLP)网络的性能。研究采用三种方法：默认设置训练MLP、基于遗传算法(GA)的特征选择以及基于主成分分析(PCA)的降维，并揭示了这些技术如何影响模型表现。GA在复杂数据集中准确识别关键特征从而提高了准确性，而PCA在低维度和无噪声数据中表现出优势。研究表明特征选择与降维对于提升MLP性能具有相辅相成的作用。


<details>
  <summary>更多</summary>
  
**动机:** 旨在通过实证研究探索不同特征工程方法对多层感知器（MLP）网络性能的影响，为机器学习任务提供实用指南。

**方法:** a) 使用默认设置进行基准训练；b) 利用遗传算法（GA）进行特征选择优化；c) 采用主成分分析（PCA）执行基于维度减少的操作。

**结果:** 结果表明，在处理复杂数据集时，GA能更准确地识别出重要特征从而提高模型准确性；而对于低维度且不含噪声的数据集，PCA则显示出其独特的优势。此外，研究还指出特征选择与降维技术之间存在相互依存关系，共同作用于改善MLP的表现。

**结论:** 该研究增进了我们对特征工程及神经网络参数优化的理解，强调了特征选择与降维技术在增强MLP性能方面的重要性，并为广泛领域的机器学习应用提供了有价值的指导原则。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+Genetic+Algorithms+with+Multilayer+Perceptron+Networks+for+Enhancing+TinyFace+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10184&send_immediately=true&force_search=false)

**原文摘要:** This study conducts an empirical examination of MLP networks investigated
through a rigorous methodical experimentation process involving three diverse
datasets: TinyFace, Heart Disease, and Iris. Study Overview: The study includes
three key methods: a) a baseline training using the default settings for the
Multi-Layer Perceptron (MLP), b) feature selection using Genetic Algorithm (GA)
based refinement c) Principal Component Analysis (PCA) based dimension
reduction. The results show important information on how such techniques affect
performance. While PCA had showed benefits in low-dimensional and noise-free
datasets GA consistently increased accuracy in complex datasets by accurately
identifying critical features. Comparison reveals that feature selection and
dimensionality reduction play interdependent roles in enhancing MLP
performance. The study contributes to the literature on feature engineering and
neural network parameter optimization, offering practical guidelines for a wide
range of machine learning tasks

</details>


### [31] [Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment](https://arxiv.org/abs/2506.10186)
*Yuhui Ding, Thomas Hofmann*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种通过学习每个分子的样本依赖SO(3)变换来构造对齐潜在空间的方法，使得非等变扩散模型在该空间上训练能够获得与现有等变扩散模型相当的样本质量，并且提高了训练和采样效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管等变扩散模型在3D分子生成中表现优异，但专门的等变架构限制了这些模型的可扩展性和效率。

**方法:** 提出的方法是放松等变性约束，通过学习一个针对每个分子的样本依赖SO(3)转换来构建对齐的潜在空间，并在这个空间上训练非等变扩散模型。

**结果:** 实验结果表明，该方法的表现显著优于先前报告的非等变模型，达到了与最先进等变扩散模型相媲美的样本质量，并提供了更好的训练和采样效率。

**结论:** 通过构建对齐的潜在空间，非等变扩散模型可以有效地用于3D分子生成，同时保持良好的样本质量和更高的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Non-Equivariant+3D+Molecule+Generation+via+Rotational+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10186&send_immediately=true&force_search=false)

**原文摘要:** Equivariant diffusion models have achieved impressive performance in 3D
molecule generation. These models incorporate Euclidean symmetries of 3D
molecules by utilizing an SE(3)-equivariant denoising network. However,
specialized equivariant architectures limit the scalability and efficiency of
diffusion models. In this paper, we propose an approach that relaxes such
equivariance constraints. Specifically, our approach learns a sample-dependent
SO(3) transformation for each molecule to construct an aligned latent space. A
non-equivariant diffusion model is then trained over the aligned
representations. Experimental results demonstrate that our approach performs
significantly better than previously reported non-equivariant models. It yields
sample quality comparable to state-of-the-art equivariant diffusion models and
offers improved training and sampling efficiency. Our code is available at
https://github.com/skeletondyh/RADM

</details>


### [32] [Improving Oral Cancer Outcomes Through Machine Learning and Dimensionality Reduction](https://arxiv.org/abs/2506.10189)
*Mohammad Subhi Al-Batah, Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon*

**主要类别:** cs.LG

**AI概要:** 本研究综述了包括神经网络、K-最近邻(KNN)、支持向量机(SVM)和集成学习技术在内的数据挖掘方法在口腔癌诊断与预后中的应用，发现神经网络的分类准确率达到了93.6%，优于其他模型。


<details>
  <summary>更多</summary>
  
**动机:** 由于口腔癌在肿瘤学中是一个巨大的挑战，需要早期诊断和准确的预后以提高患者的存活率。机器学习和数据挖掘的最新进展为区分良性和恶性口腔病变提供了先进的自动化工具。

**方法:** 本研究对神经网络、K-最近邻(KNN)、支持向量机(SVM)以及集成学习等前沿的数据挖掘方法进行了全面回顾，并将其专门应用于口腔癌的诊断和预后。通过严格的比较分析，评估这些方法的表现。

**结果:** 研究表明，神经网络在预测口腔癌方面表现出色，分类准确率达到93.6%。此外，强调了特征选择和降维技术整合到模型中可以进一步提高性能。

**结论:** 高级数据挖掘技术在加强早期检测、优化治疗策略以及最终改善口腔肿瘤患者结果方面显示出巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Oral+Cancer+Outcomes+Through+Machine+Learning+and+Dimensionality+Reduction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10189，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10189&send_immediately=true&force_search=false)

**原文摘要:** Oral cancer presents a formidable challenge in oncology, necessitating early
diagnosis and accurate prognosis to enhance patient survival rates. Recent
advancements in machine learning and data mining have revolutionized
traditional diagnostic methodologies, providing sophisticated and automated
tools for differentiating between benign and malignant oral lesions. This study
presents a comprehensive review of cutting-edge data mining methodologies,
including Neural Networks, K-Nearest Neighbors (KNN), Support Vector Machines
(SVM), and ensemble learning techniques, specifically applied to the diagnosis
and prognosis of oral cancer. Through a rigorous comparative analysis, our
findings reveal that Neural Networks surpass other models, achieving an
impressive classification accuracy of 93,6 % in predicting oral cancer.
Furthermore, we underscore the potential benefits of integrating feature
selection and dimensionality reduction techniques to enhance model performance.
These insights underscore the significant promise of advanced data mining
techniques in bolstering early detection, optimizing treatment strategies, and
ultimately improving patient outcomes in the realm of oral oncology.

</details>


### [33] [DynaSubVAE: Adaptive Subgrouping for Scalable and Robust OOD Detection](https://arxiv.org/abs/2506.10200)
*Tina Behrouzi, Sana Tonekaboni, Rahul G. Krishnan, Anna Goldenberg*

**主要类别:** cs.LG

**AI概要:** 本文提出DynaSubVAE，一个动态子群变分自编码器框架，用于表示学习和自适应的OOD检测。它能够随着数据演变而更新其潜在结构以捕捉新趋势，并在近OOD和远OOD检测中表现出色，特别是在训练期间整个类别缺失的情况下。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的观察数据常常包含偏离全局模式的现有或新兴异质子群体。大多数模型倾向于忽略这些未被充分代表的群体，导致预测不准确甚至有害。现有解决方案往往依赖于将这些样本检测为域外（OOD）而不是使模型适应新的出现模式。

**方法:** DynaSubVAE是一个动态子群变分自编码器框架，它结合了表示学习和自适应的OOD检测。该框架通过动态更新其潜在结构来捕捉新趋势，并利用一种新颖的非参数聚类机制，基于嵌入相似性发现并建模潜在子群体。

**结果:** 广泛的实验表明，DynaSubVAE在近OOD和远OOD检测中都取得了有竞争力的表现，并且在类OOD场景中表现出色，即在训练过程中某个整个类别缺失的情况下。此外，我们的动态子群机制在OOD准确性以及遗憾精度方面优于GMM和KMeans++等独立聚类方法。

**结论:** DynaSubVAE提供了一种有效的方法来处理观测数据中的异质子群体问题，通过同时进行表示学习和自适应OOD检测，能够在数据演变过程中不断更新以适应新的模式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DynaSubVAE%3A+Adaptive+Subgrouping+for+Scalable+and+Robust+OOD+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10200，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10200&send_immediately=true&force_search=false)

**原文摘要:** Real-world observational data often contain existing or emerging
heterogeneous subpopulations that deviate from global patterns. The majority of
models tend to overlook these underrepresented groups, leading to inaccurate or
even harmful predictions. Existing solutions often rely on detecting these
samples as Out-of-domain (OOD) rather than adapting the model to new emerging
patterns. We introduce DynaSubVAE, a Dynamic Subgrouping Variational
Autoencoder framework that jointly performs representation learning and
adaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves with
the data by dynamically updating its latent structure to capture new trends. It
leverages a novel non-parametric clustering mechanism, inspired by Gaussian
Mixture Models, to discover and model latent subgroups based on embedding
similarity. Extensive experiments show that DynaSubVAE achieves competitive
performance in both near-OOD and far-OOD detection, and excels in class-OOD
scenarios where an entire class is missing during training. We further
illustrate that our dynamic subgrouping mechanism outperforms standalone
clustering methods such as GMM and KMeans++ in terms of both OOD accuracy and
regret precision.

</details>


### [34] [AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent](https://arxiv.org/abs/2506.10205)
*Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为AWP的统一方法，用于激活感知权重剪枝和量化，并通过实验表明该方法优于现有的大型语言模型剪枝和量化方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决大型语言模型（LLMs）规模庞大的问题，尤其是在边缘设备上，通常会采用诸如量化和剪枝等模型压缩方法。

**方法:** 作者们提出了一个名为AWP（Activation-aware Weight pruning）的方法，该方法结合了迭代硬阈值（IHT）的成功经验，针对激活感知权重剪枝与稀疏近似问题之间的联系进行了研究。

**结果:** 实验结果表明，AWP在大型语言模型的剪枝和量化方面优于当前最先进的方法。

**结论:** 论文提出的AWP方法不仅在实践中的表现超越现有技术，而且对于剪枝过程提供了理论收敛性保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AWP%3A+Activation-Aware+Weight+Pruning+and+Quantization+with+Projected+Gradient+Descent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10205，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10205&send_immediately=true&force_search=false)

**原文摘要:** To address the enormous size of Large Language Models (LLMs), model
compression methods, such as quantization and pruning, are often deployed,
especially on edge devices. In this work, we focus on layer-wise post-training
quantization and pruning. Drawing connections between activation-aware weight
pruning and sparse approximation problems, and motivated by the success of
Iterative Hard Thresholding (IHT), we propose a unified method for
Activation-aware Weight pruning and quantization via Projected gradient descent
(AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLM
pruning and quantization methods. Theoretical convergence guarantees of the
proposed method for pruning are also provided.

</details>


### [35] [Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms](https://arxiv.org/abs/2506.10212)
*Sajjad Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni*

**主要类别:** cs.LG

**AI概要:** 研究通过同步心电图(ECG)和心音图(PCG)记录，采用线性和非线性机器学习模型来探究两种信号之间的相互重建能力，并发现非因果LSTM网络在跨模态学习中表现最佳。此外，研究还展示了从PCG估计ECG生物标志物的可能性，这有助于理解心脏电机械模式之间的关系。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索心电图（ECG）与心音图（PCG）的共同和独有特性，以及它们之间相互重建的可能性和生物标志物提取潜力，特别是在不同生理条件和个体间变化的情况下。

**方法:** 使用EPHNOGRAM数据集中的同步ECG-PCG记录，在静息和运动状态下，应用一系列线性和非线性机器学习模型，包括非因果LSTM网络，来进行一种模态到另一种模态的重建，并分析因果关系、生理状态和跨主体变异性的影响。

**结果:** 结果表明，非线性模型特别是非因果LSTM提供了更好的重建性能；从PCG重建ECG比反向操作更容易；运动和跨主体场景提出了显著挑战，但基于包络的建模提高了跨主体的一般性；临床上相关的ECG生物标记物可以从PCG中进行估算。

**结论:** 这些发现促进了我们对心脏机电模式之间关系的理解，不仅在于波形特征方面，也在于心脏事件的时间方面，具有应用于新型多模态心脏监测技术的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cross-Learning+Between+ECG+and+PCG%3A+Exploring+Common+and+Exclusive+Characteristics+of+Bimodal+Electromechanical+Cardiac+Waveforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10212，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10212&send_immediately=true&force_search=false)

**原文摘要:** Simultaneous electrocardiography (ECG) and phonocardiogram (PCG) provide a
comprehensive, multimodal perspective on cardiac function by capturing the
heart's electrical and mechanical activities, respectively. However, the
distinct and overlapping information content of these signals, as well as their
potential for mutual reconstruction and biomarker extraction, remains
incompletely understood, especially under varying physiological conditions and
across individuals.
  In this study, we systematically investigate the common and exclusive
characteristics of ECG and PCG using the EPHNOGRAM dataset of simultaneous
ECG-PCG recordings during rest and exercise. We employ a suite of linear and
nonlinear machine learning models, including non-causal LSTM networks, to
reconstruct each modality from the other and analyze the influence of
causality, physiological state, and cross-subject variability. Our results
demonstrate that nonlinear models, particularly non-causal LSTM, provide
superior reconstruction performance, with reconstructing ECG from PCG proving
more tractable than the reverse. Exercise and cross-subject scenarios present
significant challenges, but envelope-based modeling that utilizes instantaneous
amplitude features substantially improves cross-subject generalizability for
cross-modal learning. Furthermore, we demonstrate that clinically relevant ECG
biomarkers, such as fiducial points and QT intervals, can be estimated from PCG
in cross-subject settings.
  These findings advance our understanding of the relationship between
electromechanical cardiac modalities, in terms of both waveform characteristics
and the timing of cardiac events, with potential applications in novel
multimodal cardiac monitoring technologies.

</details>


### [36] [LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation](https://arxiv.org/abs/2506.10235)
*Chen-Chia Chang, Wan-Hsuan Lin, Yikang Shen, Yiran Chen, Xin Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了LaMAGIC2，一种基于语言模型的模拟拓扑生成方法，通过改进组件类型识别、减少token长度复杂度以及提高数值精度敏感性，从而在紧密容差下提高了34%的成功率，并且与先前的方法相比降低了10倍的均方误差。


<details>
  <summary>更多</summary>
  
**动机:** 当前最先进的工作采用序列到序列的方法和对语言模型进行监督微调来根据用户规格生成拓扑结构。然而，这种方法的电路表述效率低下，因为其token长度为O(|V|^2)，并且对于数值输入具有低精度敏感性。

**方法:** 引入了LaMAGIC2，这是一种基于语言模型的模拟拓扑生成的简洁浮点输入规范形式（SFCI），它通过基于标识符的表示改进了组件类型的识别，将token长度复杂度降低至O(|V|)，并增强了数值精度敏感性以在紧密容差下实现更好的性能。

**结果:** 实验表明，在紧密容差为0.01的情况下，LaMAGIC2的成功率比先前的方法高34%，并且均方误差降低了10倍。此外，LaMAGIC2在具有更多顶点的电路上表现出更好的可转移性，最高可达58.5%的改善。

**结论:** 这些进步确立了LaMAGIC2作为模拟拓扑生成的稳健框架的地位。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LaMAGIC2%3A+Advanced+Circuit+Formulations+for+Language+Model-Based+Analog+Topology+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10235，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10235&send_immediately=true&force_search=false)

**原文摘要:** Automation of analog topology design is crucial due to customized
requirements of modern applications with heavily manual engineering efforts.
The state-of-the-art work applies a sequence-to-sequence approach and
supervised finetuning on language models to generate topologies given user
specifications. However, its circuit formulation is inefficient due to O(|V |2)
token length and suffers from low precision sensitivity to numeric inputs. In
this work, we introduce LaMAGIC2, a succinct float-input canonical formulation
with identifier (SFCI) for language model-based analog topology generation.
SFCI addresses these challenges by improving component-type recognition through
identifier-based representations, reducing token length complexity to O(|V |),
and enhancing numeric precision sensitivity for better performance under tight
tolerances. Our experiments demonstrate that LaMAGIC2 achieves 34% higher
success rates under a tight tolerance of 0.01 and 10X lower MSEs compared to a
prior method. LaMAGIC2 also exhibits better transferability for circuits with
more vertices with up to 58.5% improvement. These advancements establish
LaMAGIC2 as a robust framework for analog topology generation.

</details>


### [37] [A new type of federated clustering: A non-model-sharing approach](https://arxiv.org/abs/2506.10244)
*Yuji Kawamata, Kaoru Kamijo, Maki Kihira, Akihiro Toyoda, Tomoru Nakayama, Akira Imakura, Tetsuya Sakurai, Yukihiko Okada*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为数据协作聚类（DC-Clustering）的新方法，它能够在复杂的分布式数据划分场景中进行联邦聚类，并且只共享中间表示而非原始数据来保证隐私保护。该方法在合成和开放基准数据集上的实验结果表明其性能可与集中式聚类相媲美。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦学习（FL）聚类方法通常只能处理简单的数据划分场景，例如水平或垂直分割，无法应对更复杂的数据分布结构。因此需要一种新的联邦聚类方法来支持在同时存在水平和垂直分割的复杂数据划分情况下的聚类。

**方法:** 研究者提出了数据协作聚类（DC-Clustering），这是一种新颖的联邦聚类方法，它允许每个机构仅分享中间表示而不是原始数据，从而确保了隐私保护的同时能够实现协作聚类。此外，该方法提供了k-means和谱聚类之间的灵活选择，并且通过与中央服务器的一次通信就能得到最终结果。

**结果:** 通过使用合成数据集和开放基准数据集进行了广泛的实验，结果显示DC-Clustering方法可以达到与所有数据集中在一起时的中心化聚类相似的聚类性能。

**结论:** DC-Clustering填补了当前联邦学习研究中的一个重要空白，即从分布式异构数据中有效发现知识的能力。由于其实用特性——隐私保护、通信效率以及灵活性——使得它成为如医疗保健和金融等对隐私敏感领域的一个很有前景的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+new+type+of+federated+clustering%3A+A+non-model-sharing+approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10244&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the growing need to leverage sensitive data across
institutions has led to increased attention on federated learning (FL), a
decentralized machine learning paradigm that enables model training without
sharing raw data. However, existing FL-based clustering methods, known as
federated clustering, typically assume simple data partitioning scenarios such
as horizontal or vertical splits, and cannot handle more complex distributed
structures. This study proposes data collaboration clustering (DC-Clustering),
a novel federated clustering method that supports clustering over complex data
partitioning scenarios where horizontal and vertical splits coexist. In
DC-Clustering, each institution shares only intermediate representations
instead of raw data, ensuring privacy preservation while enabling collaborative
clustering. The method allows flexible selection between k-means and spectral
clustering, and achieves final results with a single round of communication
with the central server. We conducted extensive experiments using synthetic and
open benchmark datasets. The results show that our method achieves clustering
performance comparable to centralized clustering where all data are pooled.
DC-Clustering addresses an important gap in current FL research by enabling
effective knowledge discovery from distributed heterogeneous data. Its
practical properties -- privacy preservation, communication efficiency, and
flexibility -- make it a promising tool for privacy-sensitive domains such as
healthcare and finance.

</details>


### [38] [Interior-Point Vanishing Problem in Semidefinite Relaxations for Neural Network Verification](https://arxiv.org/abs/2506.10269)
*Ryota Ueda, Takami Sato, Ken Kobayashi, Kazuhide Nakata*

**主要类别:** cs.LG

**AI概要:** 本文探讨了半定规划（SDP）松弛方法在深度神经网络验证中的局限性，并提出了五种解决方案来增强验证问题的可行性条件，从而提高SDP方法对于更深神经网络的适用性。


<details>
  <summary>更多</summary>
  
**动机:** 研究者们发现，当使用SDP松弛方法对具有ReLU激活函数的深层神经网络进行验证时，存在内部点消失的问题，导致失去严格可行性，这对数值稳定性和最优性至关重要。此外，传统上继承自先前工作的ReLU单元上下界的有效约束实际上对问题的可行性没有帮助，甚至是有害的。

**方法:** 通过严格的理论和实证分析，研究者们证明了随着DNN深度的增加，很可能会失去严格可行性，这构成了基于SDP验证方法扩展的一个基本障碍。为了解决这个问题，他们设计并调查了五种方案来改善验证问题的可行性条件。

**结果:** 所提出的方法能够成功解决现有方法无法解决的88%的问题，占总数的41%。

**结论:** 该工作不仅揭示了基于SDP的DNN验证面临的基本挑战，还提供了实际的解决方案以改进其对于更深层神经网络的适用性，有助于开发更加可靠和安全的系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interior-Point+Vanishing+Problem+in+Semidefinite+Relaxations+for+Neural+Network+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10269，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10269&send_immediately=true&force_search=false)

**原文摘要:** Semidefinite programming (SDP) relaxation has emerged as a promising approach
for neural network verification, offering tighter bounds than other convex
relaxation methods for deep neural networks (DNNs) with ReLU activations.
However, we identify a critical limitation in the SDP relaxation when applied
to deep networks: interior-point vanishing, which leads to the loss of strict
feasibility -- a crucial condition for the numerical stability and optimality
of SDP. Through rigorous theoretical and empirical analysis, we demonstrate
that as the depth of DNNs increases, the strict feasibility is likely to be
lost, creating a fundamental barrier to scaling SDP-based verification. To
address the interior-point vanishing, we design and investigate five solutions
to enhance the feasibility conditions of the verification problem. Our methods
can successfully solve 88% of the problems that could not be solved by existing
methods, accounting for 41% of the total. Our analysis also reveals that the
valid constraints for the lower and upper bounds for each ReLU unit are
traditionally inherited from prior work without solid reasons, but are actually
not only unbeneficial but also even harmful to the problem's feasibility. This
work provides valuable insights into the fundamental challenges of SDP-based
DNN verification and offers practical solutions to improve its applicability to
deeper neural networks, contributing to the development of more reliable and
secure systems with DNNs.

</details>


### [39] [Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning](https://arxiv.org/abs/2506.10282)
*Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan*

**主要类别:** cs.LG

**AI概要:** 本文提出了Graph-MLLM，一个针对多模态图学习的综合基准测试工具，旨在公平评估三种基于多模态大语言模型（MLLMs）的学习范式：编码器、对齐器和预测器。通过六个不同领域的数据集进行系统性评价，研究发现联合考虑节点的视觉和文本属性有利于图学习，并且将视觉属性转换为文本描述可以进一步提高性能。此外，即使没有明确的图结构信息，对特定多模态图进行微调的MLLMs也能在大多数情况下取得最佳结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多模态图（MMG）学习方法缺乏统一的基准来公平地评估各种方法的有效性，导致难以清晰衡量该领域的发展进度。为了填补这一空白，作者们希望提供一个全面的基准测试平台，以促进快速而公正的评估，并激发更多创新研究。

**方法:** 作者引入了Graph-MLLM，它是一个用于多模态图学习的综合性基准测试工具，能够系统地在六个不同的数据集上评估三种主要的多模态大语言模型使用范式：作为编码器增强图神经网络、作为对齐器实现跨模态推理以及作为预测器利用上下文学习或微调来进行独立推理。

**结果:** 实验结果显示，同时考虑节点的视觉与文本属性有助于图学习过程；将视觉特征转化为文字描述相较于直接采用视觉输入能带来更好的表现；另外，即便不依赖于具体的图结构细节，经过针对性调整后的MLLMs依然能在多数应用情景中达到领先水平。

**结论:** 通过提出Graph-MLLM基准测试工具，本研究不仅为多模态图学习领域提供了重要的评价标准，还揭示了几种提升此类模型性能的有效策略。未来的工作可以通过该开放源代码库继续探索如何更好地结合多种模态信息以优化图分析任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-MLLM%3A+Harnessing+Multimodal+Large+Language+Models+for+Multimodal+Graph+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10282，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10282&send_immediately=true&force_search=false)

**原文摘要:** Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in representing and understanding diverse modalities. However,
they typically focus on modality alignment in a pairwise manner while
overlooking structural relationships across data points. Integrating
multimodality with structured graph information (i.e., multimodal graphs, MMGs)
is essential for real-world applications such as social networks, healthcare,
and recommendation systems. Existing MMG learning methods fall into three
paradigms based on how they leverage MLLMs: Encoder, Aligner, and Predictor.
MLLM-as-Encoder focuses on enhancing graph neural networks (GNNs) via
multimodal feature fusion; MLLM-as-Aligner aligns multimodal attributes in
language or hidden space to enable LLM-based graph reasoning; MLLM-as-Predictor
treats MLLMs as standalone reasoners with in-context learning or fine-tuning.
Despite their advances, the MMG field lacks a unified benchmark to fairly
evaluate across these approaches, making it unclear what progress has been
made. To bridge this gap, we present Graph-MLLM, a comprehensive benchmark for
multimodal graph learning by systematically evaluating these three paradigms
across six datasets with different domains. Through extensive experiments, we
observe that jointly considering the visual and textual attributes of the nodes
benefits graph learning, even when using pre-trained text-to-image alignment
models (e.g., CLIP) as encoders. We also find that converting visual attributes
into textual descriptions further improves performance compared to directly
using visual inputs. Moreover, we observe that fine-tuning MLLMs on specific
MMGs can achieve state-of-the-art results in most scenarios, even without
explicit graph structure information. We hope that our open-sourced library
will facilitate rapid, equitable evaluation and inspire further innovative
research in this field.

</details>


### [40] [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://arxiv.org/abs/2506.10314)
*Luc Raszewski, Christine De Kock*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种使用元学习来提高在数据稀缺情况下识别维基百科上恶意傀儡账户的方法，并且这种方法相较于预训练模型能显著提高预测准确性。


<details>
  <summary>更多</summary>
  
**动机:** 先前的机器学习方法依赖于风格和元数据特征，但没有优先考虑对作者特定行为的适应性。因此，在文本数据有限的情况下，这些方法难以有效地模拟特定傀儡群组的行为。

**方法:** 研究者们提出了应用元学习技术，该技术旨在通过跨多个任务训练模型来改善在数据不足情况下的性能。元学习优化了模型以快速适应新的傀儡群组写作风格。

**结果:** 结果表明，与预训练模型相比，元学习显著提高了预测精度，这标志着在开放编辑平台上对抗傀儡账号方面取得了进展。

**结论:** 本文介绍了一种新颖的方法论用于检测维基百科上的恶意傀儡账户，它通过元学习来更好地适应作者特有的行为模式，从而增强了检测准确性。此外，还发布了一个新的傀儡调查数据集以促进未来的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+Sockpuppetry+on+Wikipedia+Using+Meta-Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10314，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10314&send_immediately=true&force_search=false)

**原文摘要:** Malicious sockpuppet detection on Wikipedia is critical to preserving access
to reliable information on the internet and preventing the spread of
disinformation. Prior machine learning approaches rely on stylistic and
meta-data features, but do not prioritise adaptability to author-specific
behaviours. As a result, they struggle to effectively model the behaviour of
specific sockpuppet-groups, especially when text data is limited. To address
this, we propose the application of meta-learning, a machine learning technique
designed to improve performance in data-scarce settings by training models
across multiple tasks. Meta-learning optimises a model for rapid adaptation to
the writing style of a new sockpuppet-group. Our results show that
meta-learning significantly enhances the precision of predictions compared to
pre-trained models, marking an advancement in combating sockpuppetry on open
editing platforms. We release a new dataset of sockpuppet investigations to
foster future research in both sockpuppetry and meta-learning fields.

</details>


### [41] [PyLO: Towards Accessible Learned Optimizers in PyTorch](https://arxiv.org/abs/2506.10315)
*Paul Janson, Benjamin Therien, Quentin Anthony, Xiaolong Huang, Abhinav Moudgil, Eugene Belilovsky*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PyLO，一个基于PyTorch的库，它将学习型优化器引入更广泛的机器学习社区，并提供了CUDA加速版本的小型全连接学习型优化器架构small_fc_lopt。


<details>
  <summary>更多</summary>
  
**动机:** 尽管学习型优化器在过去十年中是一个活跃的研究课题，但最近的进步如VeLO由于依赖JAX和缺乏用户友好的软件包而难以被广泛使用。为了填补这一空白，作者们开发了PyLO，使得学习型优化器能够通过熟悉的、广泛采用的工作流程服务于更广大的机器学习社群。

**方法:** 研究者们创建了一个名为PyLO的开源库，该库基于PyTorch，提供了一个CUDA加速版本的学习型优化器small_fc_lopt，这个优化器是从之前的研究中获得的。此外，PyLO还允许用户轻松地将学习型优化器与现有的优化工具（如学习率调度和权重衰减）结合使用。

**结果:** PyLO的发布提高了训练效率，例如在ViT B/16模型上使用batch size 32时，吞吐量从39.36提升到了205.59 samples/sec。并且当学习型优化器与传统优化技术结合时，它们可以显著受益。

**结论:** PyLO为实际的大规模预训练任务提供了易于使用的接口，使得学习型优化器更加实用且高效，同时也促进了学习型优化器与其他优化技术的有效结合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PyLO%3A+Towards+Accessible+Learned+Optimizers+in+PyTorch，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10315&send_immediately=true&force_search=false)

**原文摘要:** Learned optimizers have been an active research topic over the past decade,
with increasing progress toward practical, general-purpose optimizers that can
serve as drop-in replacements for widely used methods like Adam. However,
recent advances -- such as VeLO, which was meta-trained for 4000 TPU-months --
remain largely inaccessible to the broader community, in part due to their
reliance on JAX and the absence of user-friendly packages for applying the
optimizers after meta-training. To address this gap, we introduce PyLO, a
PyTorch-based library that brings learned optimizers to the broader machine
learning community through familiar, widely adopted workflows. Unlike prior
work focused on synthetic or convex tasks, our emphasis is on applying learned
optimization to real-world large-scale pre-training tasks. Our release includes
a CUDA-accelerated version of the small_fc_lopt learned optimizer architecture
from (Metz et al., 2022a), delivering substantial speedups -- from 39.36 to
205.59 samples/sec throughput for training ViT B/16 with batch size 32. PyLO
also allows us to easily combine learned optimizers with existing optimization
tools such as learning rate schedules and weight decay. When doing so, we find
that learned optimizers can substantially benefit. Our code is available at
https://github.com/Belilovsky-Lab/pylo

</details>


### [42] [Provably Learning from Language Feedback](https://arxiv.org/abs/2506.10341)
*Wanqiao Xu, Allen Nie, Ruijie Zheng, Aditya Modi, Adith Swaminathan, Ching-An Cheng*

**主要类别:** cs.LG

**AI概要:** 本文提出了Learning from Language Feedback (LLF)问题的形式化定义，并引入了transfer eluder dimension作为复杂度的度量。通过一个无悔算法HELiX，该算法能够有效地解决LLF问题，并在多个实证领域中表现良好。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLM）代理的出现，从观察和语言反馈中交互学习的研究日益增多。尽管已经展示了一些令人印象深刻的实证演示，但这些决策问题的原则性框架仍然缺乏。

**方法:** 论文形式化了Learning from Language Feedback (LLF) 问题，提出了足够的假设以支持即使存在潜在奖励的学习，并引入了一个名为transfer eluder dimension的复杂度度量来描述LLF问题的难度。基于此，研究者们开发了一个叫做HELiX的无悔算法，它可以通过顺序交互证明地解决LLF问题。

**结果:** 研究表明，transfer eluder dimension捕捉到了反馈中的信息改变LLF问题学习复杂性的直觉。在某些情况下，从丰富的语言反馈中学习比从奖励中学习要快得多。此外，HELiX算法在多个经验领域中表现出色，即使重复提示LLM不能可靠工作时也是如此。

**结论:** 本文的工作为设计从通用语言反馈中进行原则性交互学习的算法迈出了第一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Provably+Learning+from+Language+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10341，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10341&send_immediately=true&force_search=false)

**原文摘要:** Interactively learning from observation and language feedback is an
increasingly studied area driven by the emergence of large language model (LLM)
agents. While impressive empirical demonstrations have been shown, so far a
principled framing of these decision problems remains lacking. In this paper,
we formalize the Learning from Language Feedback (LLF) problem, assert
sufficient assumptions to enable learning despite latent rewards, and introduce
$\textit{transfer eluder dimension}$ as a complexity measure to characterize
the hardness of LLF problems. We show that transfer eluder dimension captures
the intuition that information in the feedback changes the learning complexity
of the LLF problem. We demonstrate cases where learning from rich language
feedback can be exponentially faster than learning from reward. We develop a
no-regret algorithm, called $\texttt{HELiX}$, that provably solves LLF problems
through sequential interactions, with performance guarantees that scale with
the transfer eluder dimension of the problem. Across several empirical domains,
we show that $\texttt{HELiX}$ performs well even when repeatedly prompting LLMs
does not work reliably. Our contributions mark a first step towards designing
principled interactive learning algorithms from generic language feedback.

</details>


### [43] [PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation](https://arxiv.org/abs/2506.10351)
*Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于小波的生理信号分析新方法，并引入了针对EMG和ECG的大规模预训练模型，同时构建了一个多模态框架，通过可学习的加权融合解决了低信噪比、高个体间变异性和设备不匹配等挑战，在多种生理信号处理任务中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 生理信号常常受到运动伪影、基线漂移和其他低信噪比干扰的影响，且表现出强烈的非平稳性，难以用传统的时间域或滤波方法表示。

**方法:** 一种新的基于小波的方法被提出以捕捉各种生理信号中的多尺度时频特征，并首次为EMG和ECG引入了两个大规模预训练模型。此外，通过整合预训练的EEG模型，构建了一个统一的多模态框架，其中每个模式都通过其专用分支进行引导，并通过可学习的加权融合来结合。

**结果:** 该方法在下游任务中取得了优异的表现，并设置了新的基准；设计有效地解决了诸如低信噪比、高受试者间变异性和设备不匹配等挑战，在多模态任务上超越了现有方法。

**结论:** 提出的基于小波的架构为多样化的生理信号分析奠定了坚实的基础，而多模态设计指向下一代生理信号处理，对可穿戴健康监测、临床诊断以及更广泛的生物医学应用具有潜在影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhysioWave%3A+A+Multi-Scale+Wavelet-Transformer+for+Physiological+Signal+Representation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10351，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10351&send_immediately=true&force_search=false)

**原文摘要:** Physiological signals are often corrupted by motion artifacts, baseline
drift, and other low-SNR disturbances, which pose significant challenges for
analysis. Additionally, these signals exhibit strong non-stationarity, with
sharp peaks and abrupt changes that evolve continuously, making them difficult
to represent using traditional time-domain or filtering methods. To address
these issues, a novel wavelet-based approach for physiological signal analysis
is presented, aiming to capture multi-scale time-frequency features in various
physiological signals. Leveraging this technique, two large-scale pretrained
models specific to EMG and ECG are introduced for the first time, achieving
superior performance and setting new baselines in downstream tasks.
Additionally, a unified multi-modal framework is constructed by integrating
pretrained EEG model, where each modality is guided through its dedicated
branch and fused via learnable weighted fusion. This design effectively
addresses challenges such as low signal-to-noise ratio, high inter-subject
variability, and device mismatch, outperforming existing methods on multi-modal
tasks. The proposed wavelet-based architecture lays a solid foundation for
analysis of diverse physiological signals, while the multi-modal design points
to next-generation physiological signal processing with potential impact on
wearable health monitoring, clinical diagnostics, and broader biomedical
applications.

</details>


### [44] [History-Aware Neural Operator: Robust Data-Driven Constitutive Modeling of Path-Dependent Materials](https://arxiv.org/abs/2506.10352)
*Binyao Guo, Zihan Lin, QiZhi He*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种基于神经算子的数据驱动端到端学习框架，用于路径依赖的非弹性材料建模。开发了历史感知神经算子（HANO），一种自回归模型，可以从最近的应变-应力历史片段预测材料响应，而无需依赖隐藏状态变量，从而克服了循环神经网络模型常见的自我一致性问题。HANO通过连续算子建模而非固定输入输出映射，自然适应不同路径离散化，并在复杂条件下表现出稳健性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服现有RNN模型中遇到的自我一致性问题和对初始隐藏状态敏感的问题，研究人员开发了一个新的数据驱动框架，该框架能够从观测数据推断材料响应的不可逆演化，并且可以处理复杂的加载路径情况，包括不规则采样、多周期加载、噪声数据和预应力状态。

**方法:** 引入了历史感知神经算子（HANO），这是一种自回归模型，它利用傅里叶基神经算子作为基础，并嵌入了层次自注意力机制来促进多尺度特征提取。HANO不依靠隐藏状态变量，而是从最近的应变-应力历史段落预测路径依赖的材料响应。

**结果:** HANO在两个基准问题上进行了评估：具有硬化的弹塑性和脆性固体中的渐进各向异性损伤。结果显示，HANO在预测精度、泛化能力和鲁棒性方面始终优于基线模型。

**结论:** HANO为模拟非弹性材料提供了一个有效的数据驱动代理，并且非常适合与经典数值求解器集成。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是History-Aware+Neural+Operator%3A+Robust+Data-Driven+Constitutive+Modeling+of+Path-Dependent+Materials，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10352，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10352&send_immediately=true&force_search=false)

**原文摘要:** This study presents an end-to-end learning framework for data-driven modeling
of path-dependent inelastic materials using neural operators. The framework is
built on the premise that irreversible evolution of material responses,
governed by hidden dynamics, can be inferred from observable data.
  We develop the History-Aware Neural Operator (HANO), an autoregressive model
that predicts path-dependent material responses from short segments of recent
strain-stress history without relying on hidden state variables, thereby
overcoming self-consistency issues commonly encountered in recurrent neural
network (RNN)-based models. Built on a Fourier-based neural operator backbone,
HANO enables discretization-invariant learning. To enhance its ability to
capture both global loading patterns and critical local path dependencies, we
embed a hierarchical self-attention mechanism that facilitates multiscale
feature extraction.
  Beyond ensuring self-consistency, HANO mitigates sensitivity to initial
hidden states, a commonly overlooked issue that can lead to instability in
recurrent models when applied to generalized loading paths. By modeling
stress-strain evolution as a continuous operator rather than relying on fixed
input-output mappings, HANO naturally accommodates varying path discretizations
and exhibits robust performance under complex conditions, including irregular
sampling, multi-cycle loading, noisy data, and pre-stressed states. We evaluate
HANO on two benchmark problems: elastoplasticity with hardening and progressive
anisotropic damage in brittle solids. Results show that HANO consistently
outperforms baseline models in predictive accuracy, generalization, and
robustness. With its demonstrated capabilities, HANO provides an effective
data-driven surrogate for simulating inelastic materials and is well-suited for
integration with classical numerical solvers.

</details>


### [45] [TreeLoRA: Efficient Continual Learning via Layer-Wise LoRAs Guided by a Hierarchical Gradient-Similarity Tree](https://arxiv.org/abs/2506.10355)
*Yu-Yang Qian, Yuan-Ze Xu, Zhen-Yu Zhang, Peng Zhao, Zhi-Hua Zhou*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为TreeLoRA的新方法，通过利用层次梯度相似性构建层适配器，以实现大型预训练模型（LPMs）的高效持续学习（CL），并使用稀疏梯度更新来优化参数。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的许多应用程序在流式环境中收集数据，要求模型能够在线更新，并适应新任务同时保留过去的知识，防止灾难性遗忘。随着大型预训练模型的兴起，由于其巨大的计算需求和增长的参数规模，效率对于持续学习变得越来越重要。

**方法:** 引入了TreeLoRA，一种新的方法，它通过利用层次梯度相似性来构建层适配器，以支持高效的持续学习。为了减少任务相似性估计的计算负担，采用赌博机技术开发了一个基于下置信界的算法，有效地探索任务结构。此外，还采用了稀疏梯度更新来促进参数优化。

**结果:** 理论分析验证了该方法背后的原理，并且在视觉转换器（ViTs）和大型语言模型（LLMs）上的实验表明，该方法在包括视觉和自然语言处理任务在内的各种领域中都是有效的和高效的。

**结论:** TreeLoRA为大型预训练模型提供了有效和高效的持续学习解决方案，通过减少计算负担并保持对先前知识的记忆来应对新任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TreeLoRA%3A+Efficient+Continual+Learning+via+Layer-Wise+LoRAs+Guided+by+a+Hierarchical+Gradient-Similarity+Tree，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10355&send_immediately=true&force_search=false)

**原文摘要:** Many real-world applications collect data in a streaming environment, where
learning tasks are encountered sequentially. This necessitates continual
learning (CL) to update models online, enabling adaptation to new tasks while
preserving past knowledge to prevent catastrophic forgetting. Nowadays, with
the flourish of large pre-trained models (LPMs), efficiency has become
increasingly critical for CL, due to their substantial computational demands
and growing parameter sizes. In this paper, we introduce TreeLoRA (K-D Tree of
Low-Rank Adapters), a novel approach that constructs layer-wise adapters by
leveraging hierarchical gradient similarity to enable efficient CL,
particularly for LPMs. To reduce the computational burden of task similarity
estimation, we employ bandit techniques to develop an algorithm based on lower
confidence bounds to efficiently explore the task structure. Furthermore, we
use sparse gradient updates to facilitate parameter optimization, making the
approach better suited for LPMs. Theoretical analysis is provided to justify
the rationale behind our approach, and experiments on both vision transformers
(ViTs) and large language models (LLMs) demonstrate the effectiveness and
efficiency of our approach across various domains, including vision and natural
language processing tasks.

</details>


### [46] [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364)
*Penguin Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PropInfer，一个用于评估大型语言模型在领域特定数据集上进行微调时属性推理的基准任务。通过两种微调范式：问答和聊天完成，以及两种定制攻击方法：基于提示的生成攻击和利用词频信号的影子模型攻击，揭示了大型语言模型中未被认识的脆弱性。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型越来越多地在领域特定的数据集上进行微调以支持医疗、金融和法律等领域的应用，这些微调数据集中往往包含不应被泄露的敏感和机密的属性信息。虽然之前的工作已经研究了判别模型和生成模型上的属性推理攻击，但尚不清楚这种攻击是否适用于大型语言模型。

**方法:** 提出了PropInfer，这是一个在问答和聊天完成两种微调范式下评估大型语言模型属性推理的基准任务。该基准任务建立在ChatDoctor数据集之上，涵盖了多种属性类型和任务配置。进一步提出两种定制攻击：一种是基于提示的生成攻击；另一种是利用词频信号的影子模型攻击。

**结果:** 实证评估表明，提出的两种攻击方法在多个预训练的大型语言模型上成功实施，显示出大型语言模型中存在的此前未被认识到的脆弱性。

**结论:** 研究表明，大型语言模型在进行领域特定数据集的微调时可能面临属性推理攻击的风险，这为未来加强此类模型的安全性和隐私保护提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+We+Infer+Confidential+Properties+of+Training+Data+from+LLMs%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10364，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10364&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly fine-tuned on domain-specific
datasets to support applications in fields such as healthcare, finance, and
law. These fine-tuning datasets often have sensitive and confidential
dataset-level properties -- such as patient demographics or disease prevalence
-- that are not intended to be revealed. While prior work has studied property
inference attacks on discriminative models (e.g., image classification models)
and generative models (e.g., GANs for image data), it remains unclear if such
attacks transfer to LLMs. In this work, we introduce PropInfer, a benchmark
task for evaluating property inference in LLMs under two fine-tuning paradigms:
question-answering and chat-completion. Built on the ChatDoctor dataset, our
benchmark includes a range of property types and task configurations. We
further propose two tailored attacks: a prompt-based generation attack and a
shadow-model attack leveraging word frequency signals. Empirical evaluations
across multiple pretrained LLMs show the success of our attacks, revealing a
previously unrecognized vulnerability in LLMs.

</details>


### [47] [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org/abs/2506.10403)
*Tzu-Heng Huang, Harit Vishwakarma, Frederic Sala*

**主要类别:** cs.LG

**AI概要:** 介绍了一种新的评估模型PAJAMA，它使用大语言模型来合成可执行的评判程序而不是直接评分。这种方法成本更低、可解释性强且容易调整，同时减少了偏见，并在某些数据集上表现优于传统的LLM作为评判者的方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前利用大型语言模型（LLMs）进行质量评估时存在高API成本、可靠性不确定、流程不灵活以及内在偏见等问题。

**方法:** 提出了PAJAMA (Program-As-a-Judge for Automated Model Assessment)，通过使用LLM生成可执行的评价程序而非直接对回复打分。这些程序可以本地存储和运行，大大降低了成本并提供了易于理解及审计的判断逻辑。

**结果:** 基于程序的评判方式相比基于Qwen2.5-14B LLM的评判，在一致性上提高了15.83%，偏见响应减少了23.7%；当程序评判被提炼成模型后，PAJAMA在RewardBench中的CHAT-HARD子集上超越了LLM作为评判者的性能，分别在Prometheus指标上高出2.19%，在JudgeLM数据集上高出8.67%，并且成本低三个数量级。

**结论:** PAJAMA提供了一种更经济高效且更加公正的语言模型评估方法，能够在减少偏见的同时提高评估的一致性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time+To+Impeach+LLM-as-a-Judge%3A+Programs+are+the+Future+of+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10403&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are widely used to evaluate the quality of LLM
generations and responses, but this leads to significant challenges: high API
costs, uncertain reliability, inflexible pipelines, and inherent biases. To
address these, we introduce PAJAMA (Program-As-a-Judge for Automated Model
Assessment), a new alternative that uses LLMs to synthesize executable judging
programs instead of directly scoring responses. These synthesized programs can
be stored and run locally, costing orders of magnitude less while providing
interpretable, and auditable judging logic that can be easily adapted.
Program-based judges mitigate biases, improving judgment consistency by 15.83%
and reducing biased responses by 23.7% on average compared to a
Qwen2.5-14B-based LLM-as-a-judge. When program judgments are distilled into a
model, PAJAMA outperforms LLM-as-a-judge on the challenging CHAT-HARD subset of
RewardBench, outperforming metrics by 2.19% on Prometheus and 8.67% on the
JudgeLM dataset, all at three orders of magnitude lower cost.

</details>


### [48] [EQA-RM: A Generative Embodied Reward Model with Test-time Scaling](https://arxiv.org/abs/2506.10389)
*Yuhang Chen, Zhen Tan, Tianlong Chen*

**主要类别:** cs.LG

**AI概要:** 介绍了一种新的生成式多模态奖励模型EQA-RM，专为具身问答任务设计，并通过创新的对比组相对策略优化策略进行训练。该模型可以提供从简洁分数到详细推理和基础评估的可扩展反馈，无需重新训练。同时提出了EQARewardBench基准用于标准化评估。


<details>
  <summary>更多</summary>
  
**动机:** 现有的奖励模型在复杂具身任务如具身问答（EQA）中未充分探索，这些任务需要细致地评估代理的空间、时间以及逻辑理解能力。

**方法:** 开发了EQA-RM，一种新颖的针对EQA任务构建的生成式多模态奖励模型，并使用对比组相对策略优化(C-GRPO)策略对其进行训练。

**结果:** EQA-RM展示出高样本效率，在仅使用700个样本的情况下于EQARewardBench上达到61.9%准确率，超越了多个强基线模型。

**结论:** EQA-RM不仅在性能上优于现有模型，而且其生成性质还提供了可解释的结构化奖励反馈，能够在测试时动态调整评估粒度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EQA-RM%3A+A+Generative+Embodied+Reward+Model+with+Test-time+Scaling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10389，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10389&send_immediately=true&force_search=false)

**原文摘要:** Reward Models (RMs), vital for large model alignment, are underexplored for
complex embodied tasks like Embodied Question Answering (EQA) where nuanced
evaluation of agents' spatial, temporal, and logical understanding is critical
yet not considered by generic approaches. We introduce EQA-RM, a novel
generative multimodal reward model specifically architected for EQA, trained
via our innovative Contrastive Group Relative Policy Optimization (C-GRPO)
strategy to learn fine-grained behavioral distinctions. The generative nature
of EQA-RM provides interpretable, structured reward feedback (beyond simple
scalars), uniquely enabling test-time scaling to dynamically adjust evaluation
granularity, from concise scores to detailed critiques of reasoning and
grounding, at inference without retraining. Concurrently, we introduce
EQARewardBench, a new benchmark built on OpenEQA for standardized EQA reward
model assessment. Demonstrating high sample efficiency, EQA-RM (fine-tuning
Qwen2-VL-2B-Instruct) achieves 61.9\% accuracy on EQA-RM-Bench with only 700
samples, outperforming strong proprietary baselines, including
Gemini-2.5-Flash, GPT-4o, Claude-3.5-Haiku, and open-sourced state-of-the-art
models such as RoVRM and VisualPRM. The code and dataset can be found here
https://github.com/UNITES-Lab/EQA-RM.

</details>


### [49] [Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](https://arxiv.org/abs/2506.10412)
*Ching Chang, Jeehyun Hwang, Yidan Shi, Haixin Wang, Wen-Chih Peng, Tien-Fu Chen, Wei Wang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Time-IMM数据集和IMM-TSF基准库，用于处理真实世界应用中不规则、多模态的时间序列数据，并展示了在预测性能上的显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列分析研究通常假设数据是干净的、均匀采样的和单模态的，这与实际应用场景中遇到的不规则、多模态且混乱的数据存在很大差距。

**方法:** 提出了Time-IMM数据集来捕捉由原因驱动的时间序列不规则性，并引入了IMM-TSF作为不规则多模态时间序列预测的基准库，该库包括专门设计的融合模块，支持基于最近感知平均和注意力机制的整合策略。

**结果:** 实证结果表明，对不规则时间序列数据显式建模多模态可以大幅提升预测性能。

**结论:** Time-IMM数据集和IMM-TSF基准库为在现实条件下推进时间序列分析提供了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time-IMM%3A+A+Dataset+and+Benchmark+for+Irregular+Multimodal+Multivariate+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10412，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10412&send_immediately=true&force_search=false)

**原文摘要:** Time series data in real-world applications such as healthcare, climate
modeling, and finance are often irregular, multimodal, and messy, with varying
sampling rates, asynchronous modalities, and pervasive missingness. However,
existing benchmarks typically assume clean, regularly sampled, unimodal data,
creating a significant gap between research and real-world deployment. We
introduce Time-IMM, a dataset specifically designed to capture cause-driven
irregularity in multimodal multivariate time series. Time-IMM represents nine
distinct types of time series irregularity, categorized into trigger-based,
constraint-based, and artifact-based mechanisms. Complementing the dataset, we
introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal
time series, enabling asynchronous integration and realistic evaluation.
IMM-TSF includes specialized fusion modules, including a timestamp-to-text
fusion module and a multimodality fusion module, which support both
recency-aware averaging and attention-based integration strategies. Empirical
results demonstrate that explicitly modeling multimodality on irregular time
series data leads to substantial gains in forecasting performance. Time-IMM and
IMM-TSF provide a foundation for advancing time series analysis under
real-world conditions. The dataset is publicly available at
https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the
benchmark library can be accessed at
https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.

</details>


### [50] [Generative Algorithms for Wildfire Progression Reconstruction from Multi-Modal Satellite Active Fire Measurements and Terrain Height](https://arxiv.org/abs/2506.10404)
*Bryan Shaddy, Brianna Binder, Agnimitra Dasgupta, Haitong Qin, James Haley, Angel Farguell, Kyle Hilburn, Derek V. Mallia, Adam Kochanski, Jan Mandel, Assad Oberai*

**主要类别:** cs.LG

**AI概要:** 本研究开发了一种方法，通过VIIRS活跃火点测量、GOES推导的点火时间和地形高度数据来估计火灾进展。使用WRF-SFIRE历史野火模拟训练了一个条件生成对抗网络（cGAN），从而将WRF-SFIRE物理特性纳入估算中。该模型在五个美国太平洋地区的野火上进行了验证，平均Sørensen-Dice系数为0.81。


<details>
  <summary>更多</summary>
  
**动机:** 随着野火发生频率的增加，人们对野火蔓延预测的兴趣日益浓厚。然而，即使是最复杂的野火模型，在多日模拟过程中也与实际观测到的进展有所偏离，这激发了对数据同化的需求。

**方法:** 研究人员开发了一种方法，利用VIIRS活跃火点测量、GOES推导的点火时间和地形高度数据来估计火灾进展情况。他们使用一个基于WRF-SFIRE大气-野火模型的历史野火模拟训练了一个条件生成对抗网络(cGAN)。

**结果:** 该方法在美国太平洋地区的五个野火案例中得到了验证，并与通过飞机测量的高分辨率周长进行了比较，结果发现平均Sørensen-Dice系数为0.81。

**结论:** 这项研究表明，通过结合卫星测量和地形数据，可以有效地估计火灾进展。尽管地形高度对到达时间推断的影响也被评估了，但当推断以卫星测量为条件时，地形的影响很小。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generative+Algorithms+for+Wildfire+Progression+Reconstruction+from+Multi-Modal+Satellite+Active+Fire+Measurements+and+Terrain+Height，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10404，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10404&send_immediately=true&force_search=false)

**原文摘要:** Increasing wildfire occurrence has spurred growing interest in wildfire
spread prediction. However, even the most complex wildfire models diverge from
observed progression during multi-day simulations, motivating need for data
assimilation. A useful approach to assimilating measurement data into complex
coupled atmosphere-wildfire models is to estimate wildfire progression from
measurements and use this progression to develop a matching atmospheric state.
In this study, an approach is developed for estimating fire progression from
VIIRS active fire measurements, GOES-derived ignition times, and terrain height
data. A conditional Generative Adversarial Network is trained with simulations
of historic wildfires from the atmosphere-wildfire model WRF-SFIRE, thus
allowing incorporation of WRF-SFIRE physics into estimates. Fire progression is
succinctly represented by fire arrival time, and measurements for training are
obtained by applying an approximate observation operator to WRF-SFIRE
solutions, eliminating need for satellite data during training. The model is
trained on tuples of fire arrival times, measurements, and terrain, and once
trained leverages measurements of real fires and corresponding terrain data to
generate samples of fire arrival times. The approach is validated on five
Pacific US wildfires, with results compared against high-resolution perimeters
measured via aircraft, finding an average Sorensen-Dice coefficient of 0.81.
The influence of terrain height on the arrival time inference is also evaluated
and it is observed that terrain has minimal influence when the inference is
conditioned on satellite measurements.

</details>


### [51] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
*Reza Karbasi, Masoud Rahimi, Abdol-Hossein Vahabie, Hadi Moradi*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种两阶段的管道来解决心电图（ECG）记录数字化过程中信号重叠的问题。通过使用U-Net分割网络和自适应网格检测模块，该方法在非重叠和重叠ECG样本上都优于现有技术，并且提供了开源实现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的心电图（ECCG）数字化方法对于处理单导联信号重叠的情况不够有效，而这种情况是常见的问题。

**方法:** 提出的方法包括两个阶段：第一阶段使用基于U-Net的分割网络，该网络经过含有重叠信号的数据集训练；第二阶段将细化后的二进制掩模转换成时间序列信号，并利用自适应网格检测模块提高不同格式和尺度下的适用性。

**结果:** 实验结果显示，所提出的U-Net架构在细粒度分割任务中达到0.87的IoU值。与基准技术相比，该方法在无重叠和有挑战性的重叠ECG样本上表现更优，特别是在存在信号重叠的情况下显著提高了性能。

**结论:** 本工作展示了一种有效的策略，能够显著提高ECG记录的数字化准确性，特别是在信号重叠情况下，并为可靠地将模拟ECG记录转换为可用于现代研究和临床应用的可分析数字数据奠定了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep+Learning-Based+Digitization+of+Overlapping+ECG+Images+with+Open-Source+Python+Code，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10617，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10617&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the persistent challenge of accurately digitizing
paper-based electrocardiogram (ECG) recordings, with a particular focus on
robustly handling single leads compromised by signal overlaps-a common yet
under-addressed issue in existing methodologies. We propose a two-stage
pipeline designed to overcome this limitation. The first stage employs a U-Net
based segmentation network, trained on a dataset enriched with overlapping
signals and fortified with custom data augmentations, to accurately isolate the
primary ECG trace. The subsequent stage converts this refined binary mask into
a time-series signal using established digitization techniques, enhanced by an
adaptive grid detection module for improved versatility across different ECG
formats and scales. Our experimental results demonstrate the efficacy of our
approach. The U-Net architecture achieves an IoU of 0.87 for the fine-grained
segmentation task. Crucially, our proposed digitization method yields superior
performance compared to a well-established baseline technique across both
non-overlapping and challenging overlapping ECG samples. For non-overlapping
signals, our method achieved a Mean Squared Error (MSE) of 0.0010 and a Pearson
Correlation Coefficient (rho) of 0.9644, compared to 0.0015 and 0.9366,
respectively, for the baseline. On samples with signal overlap, our method
achieved an MSE of 0.0029 and a rho of 0.9641, significantly improving upon the
baseline's 0.0178 and 0.8676. This work demonstrates an effective strategy to
significantly enhance digitization accuracy, especially in the presence of
signal overlaps, thereby laying a strong foundation for the reliable conversion
of analog ECG records into analyzable digital data for contemporary research
and clinical applications. The implementation is publicly available at this
GitHub repository: https://github.com/masoudrahimi39/ECG-code.

</details>


### [52] [Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2506.10629)
*Yucheng Yang, Tianyi Zhou, Qiang He, Lei Han, Mykola Pechenizkiy, Meng Fang*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种新的理论分析，指出了技能多样性与可分性对下游任务适应的重要性，并提出了基于Wasserstein距离的新技能学习目标WSEP及算法PWSEP，理论上优于MISL方法。


<details>
  <summary>更多</summary>
  
**动机:** 无监督强化学习（URL）旨在为未见的下游任务学习通用技能。互信息技能学习（MISL）通过最大化状态和技能之间的互信息来解决URL问题，但缺乏足够的理论分析，例如其学到的技能如何能初始化一个下游任务的策略。

**方法:** 论文首先进行了新的理论分析，表明所学技能的多样性和可分离性对于下游任务适应至关重要，而MISL并不能保证这些特性。为了补充MISL，研究者们提出了一种新颖的解纠缠度量LSEPIN，并建立了LSEPIN与下游任务适应成本之间的信息几何联系。进一步地，他们探讨了用Wasserstein距离代替信息几何中的KL散度的新策略，并将几何分析扩展到它，从而引出了一个新的技能学习目标WSEP。

**结果:** WSEP在理论上被证明有助于下游任务的适应，并且能够比MISL发现更多的初始策略用于下游任务。此外，还提出了另一种基于Wasserstein距离的算法PWSEP，该算法理论上可以发现所有最优的初始策略。

**结论:** 本论文的工作揭示了技能学习中多样性和可分性的重要性，并提出了新的理论支持的方法WSEP和PWSEP，它们在下游任务适应方面具有优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Task+Adaptation+from+Skills%3A+Information+Geometry%2C+Disentanglement%2C+and+New+Objectives+for+Unsupervised+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10629，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10629&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised reinforcement learning (URL) aims to learn general skills for
unseen downstream tasks. Mutual Information Skill Learning (MISL) addresses URL
by maximizing the mutual information between states and skills but lacks
sufficient theoretical analysis, e.g., how well its learned skills can
initialize a downstream task's policy. Our new theoretical analysis in this
paper shows that the diversity and separability of learned skills are
fundamentally critical to downstream task adaptation but MISL does not
necessarily guarantee these properties. To complement MISL, we propose a novel
disentanglement metric LSEPIN. Moreover, we build an information-geometric
connection between LSEPIN and downstream task adaptation cost. For better
geometric properties, we investigate a new strategy that replaces the KL
divergence in information geometry with Wasserstein distance. We extend the
geometric analysis to it, which leads to a novel skill-learning objective WSEP.
It is theoretically justified to be helpful to downstream task adaptation and
it is capable of discovering more initial policies for downstream tasks than
MISL. We finally propose another Wasserstein distance-based algorithm PWSEP
that can theoretically discover all optimal initial policies.

</details>


### [53] [Data-Driven Soil Organic Carbon Sampling: Integrating Spectral Clustering with Conditioned Latin Hypercube Optimization](https://arxiv.org/abs/2506.10419)
*Weiying Zhao, Aleksei Unagaev, Natalia Efremova*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合谱聚类和条件拉丁超立方体采样的混合方法，以提高土壤有机碳(SOC)采样的代表性，并通过实验证明该方法比标准cLHS提供了更均匀的协变量特征空间覆盖和空间异质性。


<details>
  <summary>更多</summary>
  
**动机:** 当前SOC监测通常依赖于基于环境协变量选择具有代表性的野外采样位置。然而，传统的条件拉丁超立方体采样(cLHS)可能会忽略一些小但重要的环境簇。为了解决这一问题，作者们提出了一种新的混合方法。

**方法:** 所提出的混合方法首先使用多变量协变量数据通过谱聚类将研究区域划分为K个同质区域，然后在每个区域内应用cLHS来选择能够全面捕捉环境条件多样性的采样点。

**结果:** 研究表明，与标准cLHS相比，谱-cLHS方法在协变量特征空间和空间异质性方面提供了更好的覆盖。

**结论:** 改进后的采样设计有望通过为机器学习模型提供更加均衡的训练数据，从而得到更准确的SOC预测结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Driven+Soil+Organic+Carbon+Sampling%3A+Integrating+Spectral+Clustering+with+Conditioned+Latin+Hypercube+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10419&send_immediately=true&force_search=false)

**原文摘要:** Soil organic carbon (SOC) monitoring often relies on selecting representative
field sampling locations based on environmental covariates. We propose a novel
hybrid methodology that integrates spectral clustering - an unsupervised
machine learning technique with conditioned Latin hypercube sampling (cLHS) to
enhance the representativeness of SOC sampling. In our approach, spectral
clustering partitions the study area into $K$ homogeneous zones using
multivariate covariate data, and cLHS is then applied within each zone to
select sampling locations that collectively capture the full diversity of
environmental conditions. This hybrid spectral-cLHS method ensures that even
minor but important environmental clusters are sampled, addressing a key
limitation of vanilla cLHS which can overlook such areas. We demonstrate on a
real SOC mapping dataset that spectral-cLHS provides more uniform coverage of
covariate feature space and spatial heterogeneity than standard cLHS. This
improved sampling design has the potential to yield more accurate SOC
predictions by providing better-balanced training data for machine learning
models.

</details>


### [54] [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)
*Yucong Luo, Yitong Zhou, Mingyue Cheng, Jiahao Wang, Daoyu Wang, Tingyue Pan, Jintao Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Time-R1的两阶段强化微调框架，旨在提高大型语言模型在时间序列预测中的多步推理能力。通过设计细粒度的多目标奖励机制和引入基于组相对重要性的策略优化（GRIP），实验表明该方法在不同数据集上显著提高了预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列预测方法大多依赖于历史模式提取并映射到未来值，缺乏中间时间序列推理的明确思考过程。虽然慢思考LLM表现出色的多步推理能力，但仅依靠提示工程存在高计算成本、隐私风险以及深度领域特定时间序列推理能力有限等问题。

**方法:** 提出了Time-R1，一个两阶段的强化学习微调框架，第一阶段进行有监督的微调以实现预热适应，第二阶段使用强化学习来增强模型的泛化能力，并且特别设计了针对时间序列预测的细粒度多目标奖励机制，同时引入了GRIP来进一步鼓励和优化模型探索有效的推理路径。

**结果:** 实验结果表明，Time-R1能够显著提升多种数据集上的预测表现。

**结论:** Time-R1提供了一种有效的方法来增强大型语言模型的时间序列预测能力，特别是在多步推理方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time+Series+Forecasting+as+Reasoning%3A+A+Slow-Thinking+Approach+with+Reinforced+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10630，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10630&send_immediately=true&force_search=false)

**原文摘要:** To advance time series forecasting (TSF), various methods have been proposed
to improve prediction accuracy, evolving from statistical techniques to
data-driven deep learning architectures. Despite their effectiveness, most
existing methods still adhere to a fast thinking paradigm-relying on extracting
historical patterns and mapping them to future values as their core modeling
philosophy, lacking an explicit thinking process that incorporates intermediate
time series reasoning. Meanwhile, emerging slow-thinking LLMs (e.g., OpenAI-o1)
have shown remarkable multi-step reasoning capabilities, offering an
alternative way to overcome these issues. However, prompt engineering alone
presents several limitations - including high computational cost, privacy
risks, and limited capacity for in-depth domain-specific time series reasoning.
To address these limitations, a more promising approach is to train LLMs to
develop slow thinking capabilities and acquire strong time series reasoning
skills. For this purpose, we propose Time-R1, a two-stage reinforcement
fine-tuning framework designed to enhance multi-step reasoning ability of LLMs
for time series forecasting. Specifically, the first stage conducts supervised
fine-tuning for warmup adaptation, while the second stage employs reinforcement
learning to improve the model's generalization ability. Particularly, we design
a fine-grained multi-objective reward specifically for time series forecasting,
and then introduce GRIP (group-based relative importance for policy
optimization), which leverages non-uniform sampling to further encourage and
optimize the model's exploration of effective reasoning paths. Experiments
demonstrate that Time-R1 significantly improves forecast performance across
diverse datasets.

</details>


### [55] [System Identification Using Kolmogorov-Arnold Networks: A Case Study on Buck Converters](https://arxiv.org/abs/2506.10434)
*Nart Gashi, Panagiotis Kakosimos, George Papafotiou*

**主要类别:** cs.LG

**AI概要:** 本文研究了Kolmogorov-Arnold网络（KANs）在降压转换器系统动态建模和分析中的应用，展示了KANs能够准确识别系统动态、验证模型一致性并检测参数变化，为现代工业系统的系统识别提供了有价值的见解。


<details>
  <summary>更多</summary>
  
**动机:** 探索一种新的方法来改进动态系统中的系统辨识，特别是提高可解释性和效率。

**方法:** 使用Kolmogorov-Arnold网络通过学习激活函数进行函数逼近，并利用仿真数据估计状态空间参数和发现系统方程。

**结果:** KANs能够精确地识别系统动力学，验证模型的一致性，并且能够检测到参数的变化。

**结论:** KANs提供了一种有效的框架，用于动态系统中具有高解释性、可扩展性和精度的系统辨识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是System+Identification+Using+Kolmogorov-Arnold+Networks%3A+A+Case+Study+on+Buck+Converters，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10434，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10434&send_immediately=true&force_search=false)

**原文摘要:** Kolmogorov-Arnold Networks (KANs) are emerging as a powerful framework for
interpretable and efficient system identification in dynamic systems. By
leveraging the Kolmogorov-Arnold representation theorem, KANs enable function
approximation through learnable activation functions, offering improved
scalability, accuracy, and interpretability compared to traditional neural
networks. This paper investigates the application of KANs to model and analyze
the dynamics of a buck converter system, focusing on state-space parameter
estimation along with discovering the system equations. Using simulation data,
the methodology involves approximating state derivatives with KANs,
constructing interpretable state-space representations, and validating these
models through numerical experiments. The results demonstrate the ability of
KANs to accurately identify system dynamics, verify model consistency, and
detect parameter changes, providing valuable insights into their applicability
for system identification in modern industrial systems.

</details>


### [56] [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org/abs/2506.10647)
*Lang Yin, Debangshu Banerjee, Gagandeep Singh*

**主要类别:** cs.LG

**AI概要:** 研究了思维链(CoT)在解决k-奇偶问题时，当遇到数据分布偏移和数据中毒两种情况下的影响，并发现CoT可能会导致比直接生成预测更差的学习表现。


<details>
  <summary>更多</summary>
  
**动机:** 尽管思维链(CoT)被证明能够有效地帮助转换器解决一些难题，但这些结论依赖于相同的训练和测试分布以及无污染的训练数据这两个假设条件。本研究旨在探讨当这些假设不成立时，数据偏移对模型质量的具体负面影响。

**方法:** 专注于k-奇偶问题，该工作研究了数据分布偏移和数据中毒这两种数据偏移类型对通过成熟的CoT分解获得的训练模型质量的联合影响。

**结果:** 揭示了一个令人惊讶的现象：使用CoT方法学习奇偶性的问题上，其性能反而不如直接生成预测的方法。此外，研究结果还对造成这种影响的机制原因进行了严格而全面的解释。

**结论:** 本研究表明，在面对数据分布偏移和数据中毒的情况下，思维链(CoT)可能不会像预期那样提高模型的表现，甚至可能导致更差的结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Shifts+Hurt+CoT%3A+A+Theoretical+Study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10647，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10647&send_immediately=true&force_search=false)

**原文摘要:** Chain of Thought (CoT) has been applied to various large language models
(LLMs) and proven to be effective in improving the quality of outputs. In
recent studies, transformers are proven to have absolute upper bounds in terms
of expressive power, and consequently, they cannot solve many computationally
difficult problems. However, empowered by CoT, transformers are proven to be
able to solve some difficult problems effectively, such as the $k$-parity
problem. Nevertheless, those works rely on two imperative assumptions: (1)
identical training and testing distribution, and (2) corruption-free training
data with correct reasoning steps. However, in the real world, these
assumptions do not always hold. Although the risks of data shifts have caught
attention, our work is the first to rigorously study the exact harm caused by
such shifts to the best of our knowledge. Focusing on the $k$-parity problem,
in this work we investigate the joint impact of two types of data shifts: the
distribution shifts and data poisoning, on the quality of trained models
obtained by a well-established CoT decomposition. In addition to revealing a
surprising phenomenon that CoT leads to worse performance on learning parity
than directly generating the prediction, our technical results also give a
rigorous and comprehensive explanation of the mechanistic reasons of such
impact.

</details>


### [57] [MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices](https://arxiv.org/abs/2506.10443)
*Zhaode Wang, Jingbang Yang, Xinyu Qian, Shiwen Xing, Xiaotang Jiang, Chengfei Lv, Shengyu Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为MNN-LLM的框架，它通过模型量化和DRAM-Flash混合存储来减少内存使用，并根据移动CPU指令集和GPU特性重新安排权重和输入，同时采用多核负载均衡、混合精度浮点运算和几何计算等策略以提高大型语言模型在移动设备上的推理速度。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）尽管在各种任务中表现出色，但其巨大的规模导致推理时需要消耗大量计算资源，从而造成高昂的成本。边缘设备推理成为一种有前景的解决方案，但存在内存使用和推理速度两大挑战。

**方法:** 提出了MNN-LLM框架，该框架专门设计用于加速大型语言模型在移动设备上的部署。方法包括：模型量化与DRAM-Flash混合存储技术以降低内存占用；根据移动CPU指令集及GPU特点重新组织权重和输入；运用多核负载均衡、混合精度浮点操作以及几何计算等手段提升性能。

**结果:** MNN-LLM 相比当前主流的针对 LLM 的特定框架，最高可实现 8.6 倍的速度提升。

**结论:** MNN-LLM为大型语言模型在移动设备上的高效运行提供了有效的解决方案，通过多种优化措施显著提高了推理速度并降低了内存需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MNN-LLM%3A+A+Generic+Inference+Engine+for+Fast+Large+Language+Model+Deployment+on+Mobile+Devices，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10443，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10443&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have demonstrated exceptional performance across
a variety of tasks. However, their substantial scale leads to significant
computational resource consumption during inference, resulting in high costs.
Consequently, edge device inference presents a promising solution. The primary
challenges of edge inference include memory usage and inference speed. This
paper introduces MNN-LLM, a framework specifically designed to accelerate the
deployment of large language models on mobile devices. MNN-LLM addresses the
runtime characteristics of LLMs through model quantization and DRAM-Flash
hybrid storage, effectively reducing memory usage. It rearranges weights and
inputs based on mobile CPU instruction sets and GPU characteristics while
employing strategies such as multicore load balancing, mixed-precision
floating-point operations, and geometric computations to enhance performance.
Notably, MNN-LLM achieves up to a 8.6x speed increase compared to current
mainstream LLM-specific frameworks.

</details>


### [58] [Saturation Self-Organizing Map](https://arxiv.org/abs/2506.10680)
*Igor Urbanik, Paweł Gajewski*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Saturation Self-Organizing Maps (SatSOM)的模型，它通过引入新的饱和机制来减少神经元的学习率和邻域半径，从而在持续学习场景中提高知识保留。


<details>
  <summary>更多</summary>
  
**动机:** 持续学习对神经系统构成了一个基本挑战，当面对连续任务时，它们常常会遭受灾难性遗忘的问题。尽管自组织映射（SOMs）具有可解释性和效率，但它们也不能幸免于这个问题。

**方法:** 作者提出了Saturation Self-Organizing Maps (SatSOM)，这是SOMs的一种扩展，旨在改善持续学习情境下的知识保持。SatSOM引入了一种新颖的饱和机制，该机制随着神经元积累信息而逐渐降低其学习率和邻域半径。

**结果:** 这种饱和机制有效地冻结了训练良好的神经元，并将学习重定向到地图上未充分利用的区域，有助于缓解灾难性遗忘问题。

**结论:** SatSOM 通过引入一种能够随时间减小学习率和邻域半径的新机制，为解决持续学习中的知识保留提供了一个有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Saturation+Self-Organizing+Map，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10680，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10680&send_immediately=true&force_search=false)

**原文摘要:** Continual learning poses a fundamental challenge for neural systems, which
often suffer from catastrophic forgetting when exposed to sequential tasks.
Self-Organizing Maps (SOMs), despite their interpretability and efficiency, are
not immune to this issue. In this paper, we introduce Saturation
Self-Organizing Maps (SatSOM)-an extension of SOMs designed to improve
knowledge retention in continual learning scenarios. SatSOM incorporates a
novel saturation mechanism that gradually reduces the learning rate and
neighborhood radius of neurons as they accumulate information. This effectively
freezes well-trained neurons and redirects learning to underutilized areas of
the map.

</details>


### [59] [Equivariant Neural Diffusion for Molecule Generation](https://arxiv.org/abs/2506.10532)
*François Cornet, Grigory Bartosh, Mikkel N. Schmidt, Christian A. Naesseth*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的3D分子生成的等变扩散模型Equivariant Neural Diffusion (END)，其前向过程是可学习的，并且在标准分子生成基准测试中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 为了改进现有的等变扩散模型，通过引入一个可学习的前向过程来增强生成建模的能力，该过程对刚性变换具有等变性。

**方法:** 开发了Equivariant Neural Diffuction (END) 模型，其中前向过程由时间与数据相关的变换参数化，并且对刚体变换保持等变性。

**结果:** 在一系列标准分子生成基准实验中，END模型相对于几个强大的基线，在无条件和有条件生成任务上都表现出了竞争力。

**结论:** Equivariant Neural Diffusion (END) 为3D分子生成提供了一个新的方法，它通过一个可学习的、对欧几里得变换等变的前向过程提高了生成模型的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Neural+Diffusion+for+Molecule+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10532，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10532&send_immediately=true&force_search=false)

**原文摘要:** We introduce Equivariant Neural Diffusion (END), a novel diffusion model for
molecule generation in 3D that is equivariant to Euclidean transformations.
Compared to current state-of-the-art equivariant diffusion models, the key
innovation in END lies in its learnable forward process for enhanced generative
modelling. Rather than pre-specified, the forward process is parameterized
through a time- and data-dependent transformation that is equivariant to rigid
transformations. Through a series of experiments on standard molecule
generation benchmarks, we demonstrate the competitive performance of END
compared to several strong baselines for both unconditional and conditional
generation.

</details>


### [60] [ConTextTab: A Semantics-Aware Tabular In-Context Learner](https://arxiv.org/abs/2506.10707)
*Marco Spinaci, Marek Polewczyk, Maximilian Schambach, Sam Thelin*

**主要类别:** cs.LG

**AI概要:** ConTextTab结合了表格原生ICL框架的语义理解和对齐，通过使用专门针对不同数据模态的嵌入并在大规模真实世界表格数据上进行训练，在多个基准测试中表现出色，并在语义丰富的CARTE基准测试中设定了新标准。


<details>
  <summary>更多</summary>
  
**动机:** 现有的表格原生ICL架构虽然在处理表格数据结构方面表现良好，但仅在合成数据上训练，未能充分利用真实世界表格数据中的丰富语义和世界知识；而基于预训练大型语言模型的表格ICL模型虽有深度语义理解能力，却受限于上下文量少的问题。因此研究者希望结合两者优势。

**方法:** 提出了一种名为ConTextTab的新方法，它将语义理解和对齐集成到一个表格原生ICL框架中，采用专为不同类型数据设计的嵌入，并在大规模的真实世界表格数据上进行训练。

**结果:** ConTextTab在一系列基准测试中与最先进方法具有竞争力，并且在富含语义信息的CARTE基准测试中设立了新的标准。

**结论:** ConTextTab成功地将现有表格原生ICL框架的优势与基于预训练大语言模型的深度语义理解相结合，在处理真实世界表格数据时展现出了强大的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ConTextTab%3A+A+Semantics-Aware+Tabular+In-Context+Learner，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10707，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10707&send_immediately=true&force_search=false)

**原文摘要:** Tabular in-context learning (ICL) has recently achieved state-of-the-art
(SOTA) performance on several tabular prediction tasks. Previously restricted
to classification problems on small tables, recent advances such as TabPFN and
TabICL have extended its use to larger datasets. While being architecturally
efficient and well-adapted to tabular data structures, current table-native ICL
architectures, being trained exclusively on synthetic data, do not fully
leverage the rich semantics and world knowledge contained in real-world tabular
data. On another end of this spectrum, tabular ICL models based on pretrained
large language models such as TabuLa-8B integrate deep semantic understanding
and world knowledge but are only able to make use of a small amount of context
due to inherent architectural limitations. With the aim to combine the best of
both these worlds, we introduce ConTextTab, integrating semantic understanding
and alignment into a table-native ICL framework. By employing specialized
embeddings for different data modalities and by training on large-scale
real-world tabular data, our model is competitive with SOTA across a broad set
of benchmarks while setting a new standard on the semantically rich CARTE
benchmark.

</details>


### [61] [Data-driven Day Ahead Market Prices Forecasting: A Focus on Short Training Set Windows](https://arxiv.org/abs/2506.10536)
*Vasilis Michalakopoulos, Christoforos Menos-Aikateriniadis, Elissaios Sarmas, Antonis Zakynthinos, Pavlos S. Georgilakis, Dimitris Askounis*

**主要类别:** cs.LG

**AI概要:** 研究了四种机器学习模型在使用短期历史训练窗口预测电力日前市场价格时的表现，重点在于检测季节性趋势和价格峰值。LightGBM模型在所有测试中表现出色，特别是在45天和60天的训练窗口下，展现了最高的预测准确性和鲁棒性，并且在检测季节效应和峰值价格事件方面优于其他模型。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探索机器学习模型如何利用较短的历史数据来预测电力日前市场的价格，同时能够捕捉到季节性变化和价格异常值。

**方法:** 研究采用了LSTM与前馈误差校正（FFEC）、XGBoost、LightGBM以及CatBoost这四种模型，在希腊、比利时和爱尔兰三个欧洲能源市场进行了评估。使用的特征集来自ENTSO-E预测数据，训练窗口长度从7天至90天不等。

**结果:** 结果表明，LightGBM持续地达到了最高的预测精确度和稳定性，尤其是在45天和60天的训练周期内表现最佳。此外，相比于LSTM和其他增强模型，LightGBM在识别季节影响及价格高峰事件上也显示出更优的能力。

**结论:** 结论是，结合提升方法的短窗口训练方法可以有效地支持波动较大且数据稀缺环境下的日前市场预测工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-driven+Day+Ahead+Market+Prices+Forecasting%3A+A+Focus+on+Short+Training+Set+Windows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10536&send_immediately=true&force_search=false)

**原文摘要:** This study investigates the performance of machine learning models in
forecasting electricity Day-Ahead Market (DAM) prices using short historical
training windows, with a focus on detecting seasonal trends and price spikes.
We evaluate four models, namely LSTM with Feed Forward Error Correction (FFEC),
XGBoost, LightGBM, and CatBoost, across three European energy markets (Greece,
Belgium, Ireland) using feature sets derived from ENTSO-E forecast data.
Training window lengths range from 7 to 90 days, allowing assessment of model
adaptability under constrained data availability. Results indicate that
LightGBM consistently achieves the highest forecasting accuracy and robustness,
particularly with 45 and 60 day training windows, which balance temporal
relevance and learning depth. Furthermore, LightGBM demonstrates superior
detection of seasonal effects and peak price events compared to LSTM and other
boosting models. These findings suggest that short-window training approaches,
combined with boosting methods, can effectively support DAM forecasting in
volatile, data-scarce environments.

</details>


### [62] [Efficiency Robustness of Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.10831)
*Ravishka Rathnasuriya, Tingxi Li, Zexin Xu, Zihe Song, Mirazul Haque, Simin Chen, Wei Yang*

**主要类别:** cs.LG

**AI概要:** 本文系统地探讨了动态深度学习系统的效率鲁棒性，提出了效率攻击的全面分类，并分析了针对这些系统效率的对抗策略以及现有防御机制的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 随着动态深度学习系统（DDLSs）在资源受限环境中的应用日益广泛，它们通过根据输入复杂度调整推理计算来提高效率。然而这种动态行为带来了新的攻击面，特别是有效率的对抗攻击利用这些动态机制来降低系统性能。因此需要对DDLSs的效率鲁棒性进行研究。

**方法:** 文章首先对效率攻击进行了全面分类，基于三种动态行为：单次推理中动态计算的攻击、动态推理迭代的攻击和针对下游任务动态输出产生的攻击。接着，通过对抗策略的深入评估，分析了这些策略如何影响DDLSs的效率，并指出了保护这些系统的关键挑战。此外，还研究了现有的防御机制及其面对流行效率攻击时的不足之处。

**结果:** 研究发现，现有的防御机制不足以抵御越来越流行的效率攻击，揭示了开发新型缓解策略以保障未来适应性DDLSs安全性的必要性。

**结论:** 为确保动态深度学习系统在面对效率攻击时仍能保持高效与安全，必须识别并解决其关键的安全挑战，并且有必要发展出新的缓解策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficiency+Robustness+of+Dynamic+Deep+Learning+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10831，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10831&send_immediately=true&force_search=false)

**原文摘要:** Deep Learning Systems (DLSs) are increasingly deployed in real-time
applications, including those in resourceconstrained environments such as
mobile and IoT devices. To address efficiency challenges, Dynamic Deep Learning
Systems (DDLSs) adapt inference computation based on input complexity, reducing
overhead. While this dynamic behavior improves efficiency, such behavior
introduces new attack surfaces. In particular, efficiency adversarial attacks
exploit these dynamic mechanisms to degrade system performance. This paper
systematically explores efficiency robustness of DDLSs, presenting the first
comprehensive taxonomy of efficiency attacks. We categorize these attacks based
on three dynamic behaviors: (i) attacks on dynamic computations per inference,
(ii) attacks on dynamic inference iterations, and (iii) attacks on dynamic
output production for downstream tasks. Through an in-depth evaluation, we
analyze adversarial strategies that target DDLSs efficiency and identify key
challenges in securing these systems. In addition, we investigate existing
defense mechanisms, demonstrating their limitations against increasingly
popular efficiency attacks and the necessity for novel mitigation strategies to
secure future adaptive DDLSs.

</details>


### [63] [Graph Neural Networks for Automatic Addition of Optimizing Components in Printed Circuit Board Schematics](https://arxiv.org/abs/2506.10577)
*Pascal Plettenberg, André Alcalde, Bernhard Sick, Josephine M. Thomas*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种基于图神经网络的双分图表示方法，用于自动化地在PCB原理图中添加新的组件，以提高电路的鲁棒性和可靠性。研究结果表明，GNNs能够高精度解决这些优化问题，并且这种方法具有时间和成本效益，可以实现PCB设计优化的自动化。


<details>
  <summary>更多</summary>
  
**动机:** 由于缺乏熟练的工程师以及手动优化非常耗时，导致最佳实践常常被忽视，这通常会导致后期开发阶段的故障排除成本增加，产品生命周期缩短，从而产生难以回收的电子废物数量增加。因此，需要一种自动化的解决方案来改善这一情况。

**方法:** 作者们将PCB原理图表示为双分图，并利用基于图神经网络（GNNs）的节点对预测模型来自动化添加新组件。他们将此方法应用于三个高度相关的PCB设计优化任务，并在由人类专家标记的真实世界数据集上比较了几种流行的GNN架构的性能。

**结果:** 研究表明，GNNs能够以很高的准确率解决这些优化问题。实验结果显示了所提出的方法在实际应用中的潜力，可以有效提升PCB设计优化过程的时间和成本效率。

**结论:** 该方法通过使用GNNs成功实现了PCB设计中组件添加的自动化，展示了其在提高电子设备质量、减少浪费和降低生产成本方面的潜在价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Neural+Networks+for+Automatic+Addition+of+Optimizing+Components+in+Printed+Circuit+Board+Schematics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10577，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10577&send_immediately=true&force_search=false)

**原文摘要:** The design and optimization of Printed Circuit Board (PCB) schematics is
crucial for the development of high-quality electronic devices. Thereby, an
important task is to optimize drafts by adding components that improve the
robustness and reliability of the circuit, e.g., pull-up resistors or
decoupling capacitors. Since there is a shortage of skilled engineers and
manual optimizations are very time-consuming, these best practices are often
neglected. However, this typically leads to higher costs for troubleshooting in
later development stages as well as shortened product life cycles, resulting in
an increased amount of electronic waste that is difficult to recycle. Here, we
present an approach for automating the addition of new components into PCB
schematics by representing them as bipartite graphs and utilizing a node pair
prediction model based on Graph Neural Networks (GNNs). We apply our approach
to three highly relevant PCB design optimization tasks and compare the
performance of several popular GNN architectures on real-world datasets labeled
by human experts. We show that GNNs can solve these problems with high accuracy
and demonstrate that our approach offers the potential to automate PCB design
optimizations in a time- and cost-efficient manner.

</details>


### [64] [The Diffusion Duality](https://arxiv.org/abs/2506.10892)
*Subham Sekhar Sahoo, Justin Deschenaux, Aaron Gokaslan, Guanghan Wang, Justin Chiu, Volodymyr Kuleshov*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Duo的方法，通过从高斯扩散过程中借鉴强大技术来改善离散扩散模型的训练和采样效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管均匀状态离散扩散模型具有自我纠正的能力，可以实现快速文本生成，但其性能通常不如自回归模型和掩码扩散模型。

**方法:** Duo方法包括两个主要部分：1. 由高斯过程引导的一种课程学习策略，以减少方差并加快训练速度；2. 离散一致性蒸馏，它将连续设置中的一致性蒸馏调整为适用于离散设置。

**结果:** 使用课程学习训练的模型在7个基准测试中的3个上超过了自回归模型的零样本困惑度，并且离散一致性蒸馏算法加速了采样过程，使扩散语言模型能够进行少步生成。

**结论:** 通过引入Duo方法，作者缩小了均匀状态离散扩散模型与更优秀模型之间的性能差距，并提高了训练和采样的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Diffusion+Duality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10892，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10892&send_immediately=true&force_search=false)

**原文摘要:** Uniform-state discrete diffusion models hold the promise of fast text
generation due to their inherent ability to self-correct. However, they are
typically outperformed by autoregressive models and masked diffusion models. In
this work, we narrow this performance gap by leveraging a key insight:
Uniform-state diffusion processes naturally emerge from an underlying Gaussian
diffusion. Our method, Duo, transfers powerful techniques from Gaussian
diffusion to improve both training and sampling. First, we introduce a
curriculum learning strategy guided by the Gaussian process, doubling training
speed by reducing variance. Models trained with curriculum learning surpass
autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we
present Discrete Consistency Distillation, which adapts consistency
distillation from the continuous to the discrete setting. This algorithm
unlocks few-step generation in diffusion language models by accelerating
sampling by two orders of magnitude. We provide the code and model checkpoints
on the project page: http://s-sahoo.github.io/duo

</details>


### [65] [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org/abs/2506.10922)
*Adam Karvonen, Samuel Marks*

**主要类别:** cs.LG

**AI概要:** 大型语言模型在高风险招聘应用中可能会产生种族和性别偏见，尤其是在引入现实背景细节时。研究者提出了一种内部偏见缓解方法，通过识别并中和模型激活中的敏感属性方向来实现所有测试场景下的稳健偏见减少。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLMs）被越来越多地应用于对个人职业生涯和生计有直接影响的高风险招聘领域，确保这些模型做出决策时的公平性变得至关重要。尽管先前的研究表明简单的反偏见提示可以在受控评估中消除人口统计学偏见，但当加入真实的上下文细节后，这种缓解措施似乎不再有效。此外，研究还发现，即使是对模型思维链推理的检查也无法揭示由于细微线索如大学关联而产生的偏见。因此，本研究旨在开发一种新的方法来解决这一问题，以提高模型在不同情况下的一致性和公平性。

**方法:** 研究者采用了一种名为内部偏见缓解的方法，该方法通过识别并中和模型激活过程中与敏感属性相关的方向来起作用。具体来说，就是利用仿射概念编辑技术，在推理阶段针对种族和性别相关方向进行干预。这种方法基于一个简单的合成数据集来确定相关方向，并且显示出良好的泛化能力。

**结果:** 实验结果表明，所提出的内部偏见缓解方法能够显著降低测试的所有商业和开源模型中的种族与性别偏见水平，通常将偏见减少至1%以下，且始终低于2.5%，同时基本保持了模型原有的性能表现。

**结论:** 研究结论建议，对于那些计划使用大型语言模型来进行招聘工作的实践者而言，应当采取更加贴近实际情况的评估方法，并考虑实施内部偏见缓解策略，以此来促进更公平的结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robustly+Improving+LLM+Fairness+in+Realistic+Settings+via+Interpretability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10922，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10922&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly deployed in high-stakes hiring
applications, making decisions that directly impact people's careers and
livelihoods. While prior studies suggest simple anti-bias prompts can eliminate
demographic biases in controlled evaluations, we find these mitigations fail
when realistic contextual details are introduced. We address these failures
through internal bias mitigation: by identifying and neutralizing sensitive
attribute directions within model activations, we achieve robust bias reduction
across all tested scenarios. Across leading commercial (GPT-4o, Claude 4
Sonnet, Gemini 2.5 Flash) and open-source models (Gemma-2 27B, Gemma-3,
Mistral-24B), we find that adding realistic context such as company names,
culture descriptions from public careers pages, and selective hiring
constraints (e.g.,``only accept candidates in the top 10\%") induces
significant racial and gender biases (up to 12\% differences in interview
rates). When these biases emerge, they consistently favor Black over White
candidates and female over male candidates across all tested models and
scenarios. Moreover, models can infer demographics and become biased from
subtle cues like college affiliations, with these biases remaining invisible
even when inspecting the model's chain-of-thought reasoning. To address these
limitations, our internal bias mitigation identifies race and gender-correlated
directions and applies affine concept editing at inference time. Despite using
directions from a simple synthetic dataset, the intervention generalizes
robustly, consistently reducing bias to very low levels (typically under 1\%,
always below 2.5\%) while largely maintaining model performance. Our findings
suggest that practitioners deploying LLMs for hiring should adopt more
realistic evaluation methodologies and consider internal mitigation strategies
for equitable outcomes.

</details>


### [66] [Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability](https://arxiv.org/abs/2506.10616)
*Yu-Jie Zhang, Peng Zhao, Masashi Sugiyama*

**主要类别:** cs.LG

**AI概要:** 本文通过利用混合性概念，改进了非平稳在线学习中动态遗憾最小化的问题，特别是对于具有更强曲率的函数。提出了一种固定份额更新的指数权重方法，实现了更低的动态遗憾界，并且分析框架更为简单强大。


<details>
  <summary>更多</summary>
  
**动机:** 目前关于动态遗憾最小化的研究主要集中在凸函数上，而对具有更强曲率（如平方损失或逻辑损失）的函数的研究较少。文章旨在填补这一空白，通过利用混合性的概念来有效捕捉损失曲率，从而改善这类函数的动态遗憾表现。

**方法:** 文章采用了一种结合固定份额更新的指数权重方法，这种方法能够利用混合性的概念来提高性能。此外，提出了一个简单的但强大的分析框架，该框架不需要依赖Karush-Kuhn-Tucker(KKT)条件来进行分析。

**结果:** 所提出的方法对于可混合损失达到了O(d T^(1/3) P_T^(2/3) log T)的动态遗憾，这比现有最好的结果O(d^(10/3) T^(1/3) P_T^(2/3) log T)在维度d方面有了显著改进。

**结论:** 本研究表明，通过利用混合性，可以显著提升非平稳环境下动态遗憾的表现。提出的指数权重方法不仅在理论上得到了更好的界限，在实践中也提供了一个更加简便的分析途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Non-stationary+Online+Learning+for+Curved+Losses%3A+Improved+Dynamic+Regret+via+Mixability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10616，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10616&send_immediately=true&force_search=false)

**原文摘要:** Non-stationary online learning has drawn much attention in recent years.
Despite considerable progress, dynamic regret minimization has primarily
focused on convex functions, leaving the functions with stronger curvature
(e.g., squared or logistic loss) underexplored. In this work, we address this
gap by showing that the regret can be substantially improved by leveraging the
concept of mixability, a property that generalizes exp-concavity to effectively
capture loss curvature. Let $d$ denote the dimensionality and $P_T$ the path
length of comparators that reflects the environmental non-stationarity. We
demonstrate that an exponential-weight method with fixed-share updates achieves
an $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$ dynamic regret for mixable losses,
improving upon the best-known $\mathcal{O}(d^{10/3} T^{1/3} P_T^{2/3} \log T)$
result (Baby and Wang, 2021) in $d$. More importantly, this improvement arises
from a simple yet powerful analytical framework that exploits the mixability,
which avoids the Karush-Kuhn-Tucker-based analysis required by existing work.

</details>


### [67] [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946)
*Evelyn Ma, Duo Zhou, Peizhi Niu, Huiting Zhou, Huan Zhang, Olgica Milenkovic, S. Rasoul Etesami*

**主要类别:** cs.LG

**AI概要:** 本文提出了GUARD框架，一种用于通过数据归因进行引导式遗忘和保留的新方法。它利用轻量级的数据归因度量标准来量化遗忘集与保留集之间的“对齐”程度，并设计了新的遗忘目标，以代理归因分数的逆比例为样本分配自适应的非均匀遗忘权重。理论分析和实验结果表明，GUARD在保持高效遗忘的同时显著提高了模型的信息保留能力。


<details>
  <summary>更多</summary>
  
**动机:** 随着法规遵从性、版权保护和个人隐私问题日益受到重视，大型语言模型（LLM）中的信息遗忘变得越来越重要。然而，现有方法在移除特定数据时往往会导致无意的遗忘，这会损害模型的有效性和有价值信息的保留。尽管先前的研究主要集中在架构创新上，但数据层面因素对于遗忘性能的影响尚未得到充分探索。因此，需要一种新方法来解决高影响力数据遗忘时的保存效果下降问题。

**方法:** GUARD框架引入了一种专为LLM遗忘设计的轻量级代理数据归因指标，该指标能够量化遗忘集与保留集之间的“对齐”程度，同时保持计算效率。基于此，研究者们设计了一个新的遗忘目标，根据代理归因得分的逆比给样本分配自适应、非均匀的遗忘权重。这种遗忘能力的重新分配有助于减少意外损失的保留。

**结果:** 提供了严格的理论保证，证明GUARD大幅提升了信息保留率，同时保持了与之前方法相当的遗忘指标。在TOFU基准测试中针对多种LLM架构进行了广泛的实验，结果表明GUARD在确保有效遗忘的同时显著改善了实用性保留。特别是在忘记10%训练数据的情况下，GUARD将保留集上的实用性牺牲降低了高达194.92%（以真实比率衡量）。

**结论:** GUARD作为一种新颖的指导式遗忘和保留方法，通过优化数据归因策略成功地解决了传统遗忘过程中出现的非预期遗忘问题。它不仅维持了良好的遗忘效果，还极大地增强了模型对重要信息的保留能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUARD%3A+Guided+Unlearning+and+Retention+via+Data+Attribution+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10946，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10946&send_immediately=true&force_search=false)

**原文摘要:** Unlearning in large language models (LLMs) is becoming increasingly important
due to regulatory compliance, copyright protection, and privacy concerns.
However, a key challenge in LLM unlearning is unintended forgetting, where the
removal of specific data inadvertently impairs the utility of the model and its
retention of valuable, desired information. While prior work has primarily
focused on architectural innovations, the influence of data-level factors on
unlearning performance remains underexplored. As a result, existing methods
often suffer from degraded retention when forgetting high-impact data. To
address this, we propose GUARD-a novel framework for Guided Unlearning And
Retention via Data attribution. At its core, GUARD introduces a lightweight
proxy data attribution metric tailored for LLM unlearning, which quantifies the
"alignment" between the forget and retain sets while remaining computationally
efficient. Building on this, we design a novel unlearning objective that
assigns adaptive, nonuniform unlearning weights to samples, inversely
proportional to their proxy attribution scores. Through such a reallocation of
unlearning power, GUARD mitigates unintended losses in retention. We provide
rigorous theoretical guarantees that GUARD significantly enhances retention
while maintaining forgetting metrics comparable to prior methods. Extensive
experiments on the TOFU benchmark across multiple LLM architectures demonstrate
that GUARD substantially improves utility preservation while ensuring effective
unlearning. Notably, GUARD reduces utility sacrifice on the Retain Set by up to
194.92% in terms of Truth Ratio when forgetting 10% of the training data.

</details>


### [68] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
*Aayush Karan, Kulin Shah, Sitan Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为ReGuidance的简单包装器，用于提高基于预训练扩散模型解决逆问题时样本的真实性和奖励。通过逆转无条件概率流ODE并使用结果潜变量初始化DPS，ReGuidance能够显著提升样本质量与测量一致性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于预训练扩散模型的方法在处理具有低信噪比的困难逆问题时，由于奖励不够信息丰富，往往偏离数据流形，无法生成逼真的输出。为了解决这一问题，作者提出了一个新的方法来改进这些技术的表现。

**方法:** ReGuidance方法包括：1. 从用户选择算法生成的候选解开始，反向运行无条件概率流ODE；2. 使用得到的潜在变量作为扩散后验采样的初始化。该方法被应用于大型框内绘制和高倍率超分辨率等难题上，并且与现有技术相比显示出了更好的性能。

**结果:** 实验表明，在难度较大的逆问题中，如大范围图像修复和高放大倍数的超分辨率任务，相较于最先进的基线方法明显失效的情况下，应用ReGuidance可以显著提高样本质量和测量一致性。此外，理论分析证明了对于某些多模态数据分布，ReGuidance同时提高了奖励并将候选解更接近于数据流形。

**结论:** 本研究首次为扩散后验采样提供了严格的算法保障，并且通过实验证明了ReGuidance能有效提升使用预训练扩散模型解决复杂逆问题时的结果质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReGuidance%3A+A+Simple+Diffusion+Wrapper+for+Boosting+Sample+Quality+on+Hard+Inverse+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10955，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10955&send_immediately=true&force_search=false)

**原文摘要:** There has been a flurry of activity around using pretrained diffusion models
as informed data priors for solving inverse problems, and more generally around
steering these models using reward models. Training-free methods like diffusion
posterior sampling (DPS) and its many variants have offered flexible heuristic
algorithms for these tasks, but when the reward is not informative enough,
e.g., in hard inverse problems with low signal-to-noise ratio, these techniques
veer off the data manifold, failing to produce realistic outputs. In this work,
we devise a simple wrapper, ReGuidance, for boosting both the sample realism
and reward achieved by these methods. Given a candidate solution $\hat{x}$
produced by an algorithm of the user's choice, we propose inverting the
solution by running the unconditional probability flow ODE in reverse starting
from $\hat{x}$, and then using the resulting latent as an initialization for
DPS. We evaluate our wrapper on hard inverse problems like large box
in-painting and super-resolution with high upscaling. Whereas state-of-the-art
baselines visibly fail, we find that applying our wrapper on top of these
baselines significantly boosts sample quality and measurement consistency. We
complement these findings with theory proving that on certain multimodal data
distributions, ReGuidance simultaneously boosts the reward and brings the
candidate solution closer to the data manifold. To our knowledge, this
constitutes the first rigorous algorithmic guarantee for DPS.

</details>


### [69] [Leveraging Low-rank Factorizations of Conditional Correlation Matrices in Graph Learning](https://arxiv.org/abs/2506.10628)
*Thu Ha Phi, Alexandre Hippert-Ferrer, Florent Bouchard, Arnaud Breloy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种利用条件相关矩阵的低秩分解来学习图结构的方法，通过黎曼优化技术解决优化问题，并将其应用于GLasso算法的一个低秩约束版本，实验表明该方法在维度和性能之间实现了高效的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决从数据中学习无向图的问题，特别是当节点数量很大时，直接学习图结构会导致计算复杂度呈平方增长的问题。

**方法:** 提出了一个基于条件相关矩阵低秩分解的图学习框架，并且开发了用于此特定结构的黎曼优化技术工具。将该方法特化为GLasso算法的低秩约束版本。

**结果:** 通过合成数据和真实数据的实验证明，所提方法能够在图的维度与学习性能之间达到非常有效的平衡。

**结论:** 通过使用低秩因子化的条件相关矩阵，可以有效地减少大维度下图学习问题的规模，同时保持良好的学习性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Low-rank+Factorizations+of+Conditional+Correlation+Matrices+in+Graph+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10628，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10628&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the problem of learning an undirected graph from data
gathered at each nodes. Within the graph signal processing framework, the
topology of such graph can be linked to the support of the conditional
correlation matrix of the data. The corresponding graph learning problem then
scales to the squares of the number of variables (nodes), which is usually
problematic at large dimension. To tackle this issue, we propose a graph
learning framework that leverages a low-rank factorization of the conditional
correlation matrix. In order to solve for the resulting optimization problems,
we derive tools required to apply Riemannian optimization techniques for this
particular structure. The proposal is then particularized to a low-rank
constrained counterpart of the GLasso algorithm, i.e., the penalized maximum
likelihood estimation of a Gaussian graphical model. Experiments on synthetic
and real data evidence that a very efficient dimension-versus-performance
trade-off can be achieved with this approach.

</details>


### [70] [Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods](https://arxiv.org/abs/2506.10959)
*Zhaiming Shen, Alexander Hsu, Rongjie Lai, Wenjing Liao*

**主要类别:** cs.LG

**AI概要:** 本研究首次探讨了在流形上对Hölder函数回归的上下文学习（ICL）的理论理解，通过将注意力机制与经典核方法联系起来，得出了关于提示长度和训练任务数量的泛化误差界限。结果表明，当观察到足够多的训练任务时，变换器可以达到流形上Hölder函数的最小最大回归率，并揭示了几何在ICL中的作用以及研究非线性模型ICL的新工具。


<details>
  <summary>更多</summary>
  
**动机:** 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著的成功，但在结构化几何数据背景下的理论理解仍有待探索。

**方法:** 通过建立注意力机制与经典核方法之间的新联系，研究人员推导出基于提示长度和训练任务数量的泛化误差边界。

**结果:** 研究表明，在观察到足够的训练任务后，变换器能够实现流形上Hölder函数的最小最大回归率，并且该回归率是随着流形内在维度而非环境空间维度指数增长的。此外，还描述了泛化误差如何随训练任务数量的变化而变化，从而阐明了变换器作为上下文算法学习者的复杂性。

**结论:** 这些发现为几何在ICL中的角色提供了基础性的见解，并为研究非线性模型的ICL提供了新的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+In-Context+Learning+on+Structured+Manifolds%3A+Bridging+Attention+to+Kernel+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10959，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10959&send_immediately=true&force_search=false)

**原文摘要:** While in-context learning (ICL) has achieved remarkable success in natural
language and vision domains, its theoretical understanding--particularly in the
context of structured geometric data--remains unexplored. In this work, we
initiate a theoretical study of ICL for regression of H\"older functions on
manifolds. By establishing a novel connection between the attention mechanism
and classical kernel methods, we derive generalization error bounds in terms of
the prompt length and the number of training tasks. When a sufficient number of
training tasks are observed, transformers give rise to the minimax regression
rate of H\"older functions on manifolds, which scales exponentially with the
intrinsic dimension of the manifold, rather than the ambient space dimension.
Our result also characterizes how the generalization error scales with the
number of training tasks, shedding light on the complexity of transformers as
in-context algorithm learners. Our findings provide foundational insights into
the role of geometry in ICL and novels tools to study ICL of nonlinear models.

</details>


### [71] [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org/abs/2506.10972)
*Houyi Li, Wenzhen Zheng, Qiufeng Wang, Zhenyu Ding, Haoying Wang, Zili Wang, Shijie Xuyang, Ning Ding, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang*

**主要类别:** cs.LG

**AI概要:** 研究者们提出了Farseer，一种新的扩展法则，能够更准确地预测不同规模下的语言模型性能。相比之前的方法如Chinchilla定律，Farseer将外推误差减少了433%。通过训练大约1000个跨多种规模和配置的语言模型，并消耗约3百万NVIDIA H100 GPU小时，该研究为计算资源的最优分配提供了新的见解。所有相关资料已经开源。


<details>
  <summary>更多</summary>
  
**动机:** 由于训练大型语言模型（LLMs）成本高昂，导致小型实验中的发现难以直接应用于实际生产系统中，从而阻碍了高效创新。为了解决这一问题，研究者们提出了一种改进的扩展法则以提高预测准确性。

**方法:** 研究团队通过构建一个模型损失曲面$L(N, D)$来开发出Farseer这种新的扩展法则，它相较于之前的法则（例如Chinchilla定律）能够更好地拟合实证数据。为了验证这种方法的有效性，他们训练了大量不同规模和配置的语言模型，并记录下了所有相关的模型、数据和日志。

**结果:** Farseer展现出了卓越的外推能力，与Chinchilla定律相比，其外推误差降低了433%，这使得小规模消融研究的结果可以可靠地被推广到预测大规模性能上。此外，Farseer还为最佳计算资源分配提供了新的视角。

**结论:** Farseer提供了一种更为精确的手段来评估各种训练策略在不同$(N, D)$设置下的表现，有助于从较小规模的研究中得出的结论被自信地应用到大规模实践中。同时，这项工作也促进了对现代LLM训练复杂需求的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Farseer%3A+A+Refined+Scaling+Law+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10972，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10972&send_immediately=true&force_search=false)

**原文摘要:** Training Large Language Models (LLMs) is prohibitively expensive, creating a
critical scaling gap where insights from small-scale experiments often fail to
transfer to resource-intensive production systems, thereby hindering efficient
innovation. To bridge this, we introduce Farseer, a novel and refined scaling
law offering enhanced predictive accuracy across scales. By systematically
constructing a model loss surface $L(N,D)$, Farseer achieves a significantly
better fit to empirical data than prior laws (e.g., Chinchilla's law). Our
methodology yields accurate, robust, and highly generalizable predictions,
demonstrating excellent extrapolation capabilities, improving upon Chinchilla's
law by reducing extrapolation error by 433\%. This allows for the reliable
evaluation of competing training strategies across all $(N,D)$ settings,
enabling conclusions from small-scale ablation studies to be confidently
extrapolated to predict large-scale performance. Furthermore, Farseer provides
new insights into optimal compute allocation, better reflecting the nuanced
demands of modern LLM training. To validate our approach, we trained an
extensive suite of approximately 1,000 LLMs across diverse scales and
configurations, consuming roughly 3 million NVIDIA H100 GPU hours. We are
comprehensively open-sourcing all models, data, results, and logs at
https://github.com/Farseer-Scaling-Law/Farseer to foster further research.

</details>


### [72] [Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning](https://arxiv.org/abs/2506.10973)
*Julius Berner, Miguel Liu-Schiaffini, Jean Kossaifi, Valentin Duruisseaux, Boris Bonev, Kamyar Azizzadenesheli, Anima Anandkumar*

**主要类别:** cs.LG

**AI概要:** 本文探讨了如何将现有的神经网络架构转化为神经算子，以处理无限维函数空间之间的映射问题，并为实践者提供了一种实现方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于深度学习在计算机视觉和自然语言处理等有限维空间的应用取得了巨大成功，但在科学领域中的无限维函数空间问题上表现不佳，因此需要一种能够推广神经网络到函数空间映射的方法。

**方法:** 提出了一组原则来构建无限维函数空间之间实用的映射实现，并且基于这些原则给出了将几种流行的神经网络架构转换成神经算子的步骤。

**结果:** 通过遵循文中提出的原则和步骤，可以将常见的神经网络架构转变为神经算子，使得操作符学习同样能够受益于经验优化。

**结论:** 神经算子提供了一条路径，使深度学习能够在解决连续时间动力系统和偏微分方程等科学问题上产生变革性的影响，而本文提供的方法论有助于推动这一进程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Principled+Approaches+for+Extending+Neural+Architectures+to+Function+Spaces+for+Operator+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10973，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10973&send_immediately=true&force_search=false)

**原文摘要:** A wide range of scientific problems, such as those described by
continuous-time dynamical systems and partial differential equations (PDEs),
are naturally formulated on function spaces. While function spaces are
typically infinite-dimensional, deep learning has predominantly advanced
through applications in computer vision and natural language processing that
focus on mappings between finite-dimensional spaces. Such fundamental
disparities in the nature of the data have limited neural networks from
achieving a comparable level of success in scientific applications as seen in
other fields. Neural operators are a principled way to generalize neural
networks to mappings between function spaces, offering a pathway to replicate
deep learning's transformative impact on scientific problems. For instance,
neural operators can learn solution operators for entire classes of PDEs, e.g.,
physical systems with different boundary conditions, coefficient functions, and
geometries. A key factor in deep learning's success has been the careful
engineering of neural architectures through extensive empirical testing.
Translating these neural architectures into neural operators allows operator
learning to enjoy these same empirical optimizations. However, prior neural
operator architectures have often been introduced as standalone models, not
directly derived as extensions of existing neural network architectures. In
this paper, we identify and distill the key principles for constructing
practical implementations of mappings between infinite-dimensional function
spaces. Using these principles, we propose a recipe for converting several
popular neural architectures into neural operators with minimal modifications.
This paper aims to guide practitioners through this process and details the
steps to make neural operators work in practice. Our code can be found at
https://github.com/neuraloperator/NNs-to-NOs

</details>


### [73] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
*Alexander Lobashev, Dmitry Guskov, Maria Larchenko, Mikhail Tamm*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种通过重构Fisher信息度量来分析生成模型（包括统计物理模型和扩散模型）潜在空间几何结构的新方法。该方法在Ising和TASEP模型上得到验证，并揭示了扩散模型中相变的分形结构。


<details>
  <summary>更多</summary>
  
**动机:** 为了更好地理解生成模型的潜在空间结构，特别是与统计物理模型和扩散模型相关的几何特性，以及它们如何与相变等现象相关联。

**方法:** 使用近似后验分布的方法来估计给定样本下的潜在变量，并基于此学习对数配分函数，从而定义指数族的Fisher度量。

**结果:** 在Ising和TASEP模型上的实验表明，该方法能够比现有基线更准确地重构热力学量；对于扩散模型，发现了潜在空间中相变点处Fisher度量突然变化的现象。

**结论:** 提出的方法为研究生成模型尤其是扩散模型的潜在空间提供了新的视角，揭示了潜在空间内相变点附近非线性行为的特征。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hessian+Geometry+of+Latent+Space+in+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10632，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10632&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a novel method for analyzing the latent space geometry of
generative models, including statistical physics models and diffusion models,
by reconstructing the Fisher information metric. The method approximates the
posterior distribution of latent variables given generated samples and uses
this to learn the log-partition function, which defines the Fisher metric for
exponential families. Theoretical convergence guarantees are provided, and the
method is validated on the Ising and TASEP models, outperforming existing
baselines in reconstructing thermodynamic quantities. Applied to diffusion
models, the method reveals a fractal structure of phase transitions in the
latent space, characterized by abrupt changes in the Fisher metric. We
demonstrate that while geodesic interpolations are approximately linear within
individual phases, this linearity breaks down at phase boundaries, where the
diffusion model exhibits a divergent Lipschitz constant with respect to the
latent space. These findings provide new insights into the complex structure of
diffusion model latent spaces and their connection to phenomena like phase
transitions. Our source code is available at
https://github.com/alobashev/hessian-geometry-of-diffusion-models.

</details>


### [74] [Preserving Task-Relevant Information Under Linear Concept Removal](https://arxiv.org/abs/2506.10703)
*Floris Holstege, Shauli Ravfogel, Bram Wouters*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为SPLICE的方法，它能够从表示中移除敏感概念，同时保持这些表示与目标标签的协方差。SPLICE通过斜投影去除不需要的方向，并保护重要的标签相关性。实验表明，该方法在移除受保护属性的同时对主任务信息的影响最小。


<details>
  <summary>更多</summary>
  
**动机:** 现有的后处理方法在移除不希望的概念时往往会损害有用的信息。为了解决公平性和可解释性的问题，需要一种既能移除神经网络中不需要的概念又能保留关键信息的方法。

**方法:** SPLICE是一种基于斜投影的技术，可以同时进行线性概念移除和协方差保留。它能够消除表示中的敏感概念，同时精确地保持它们与目标标签的协方差。

**结果:** 理论上，SPLICE是唯一能够移除线性概念预测能力并以最小嵌入失真维持目标协方差的解决方案。实证结果表明，在诸如Bias in Bios和Winobias等基准测试上，SPLICE的表现优于基线方法。

**结论:** SPLICE提供了一个有效的解决方案，可以在不显著损害主要任务性能的情况下，移除机器学习模型中的不公平或不想要的概念。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preserving+Task-Relevant+Information+Under+Linear+Concept+Removal，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10703&send_immediately=true&force_search=false)

**原文摘要:** Modern neural networks often encode unwanted concepts alongside task-relevant
information, leading to fairness and interpretability concerns. Existing
post-hoc approaches can remove undesired concepts but often degrade useful
signals. We introduce SPLICE-Simultaneous Projection for LInear concept removal
and Covariance prEservation-which eliminates sensitive concepts from
representations while exactly preserving their covariance with a target label.
SPLICE achieves this via an oblique projection that "splices out" the unwanted
direction yet protects important label correlations. Theoretically, it is the
unique solution that removes linear concept predictability and maintains target
covariance with minimal embedding distortion. Empirically, SPLICE outperforms
baselines on benchmarks such as Bias in Bios and Winobias, removing protected
attributes while minimally damaging main-task information.

</details>


### [75] [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org/abs/2506.10751)
*Sai Prasanna Teja Reddy Bogireddy, Abrar Majeedi, Viswanatha Reddy Gajjala, Zhuoyan Xu, Siddhant Rai, Vaishnav Potlapalli*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种在BioNLP 2025 ArchEHR-QA共享任务中获得亚军的方法Neural，该方法通过数据驱动的提示优化实现了高效的临床问答。


<details>
  <summary>更多</summary>
  
**动机:** 自动化电子健康记录（EHRs）上的问题回答可以为临床医生和患者填补关键信息空白，但需要在有限监督下进行精确的证据检索和忠实的答案生成。

**方法:** 提出的方法将任务分解为句子级证据识别和带有明确引用的答案合成两个阶段，并使用DSPy的MIPROv2优化器自动探索提示空间，在开发集上联合调整指令和少量示例演示。此外，还采用了自一致性投票方案以提高证据召回率而不牺牲精确度。

**结果:** 该方法在隐藏测试集上取得了51.5分的整体得分，位居第二，并且比标准零样本和少样本提示分别高出超过20分和10分。

**结论:** 研究表明，对于高风险的临床问答来说，数据驱动的提示优化是一种成本效益更高的模型微调替代方案，能够促进医疗保健领域AI助手的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+at+ArchEHR-QA+2025%3A+Agentic+Prompt+Optimization+for+Evidence-Grounded+Clinical+Question+Answering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10751，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10751&send_immediately=true&force_search=false)

**原文摘要:** Automated question answering (QA) over electronic health records (EHRs) can
bridge critical information gaps for clinicians and patients, yet it demands
both precise evidence retrieval and faithful answer generation under limited
supervision. In this work, we present Neural, the runner-up in the BioNLP 2025
ArchEHR-QA shared task on evidence-grounded clinical QA. Our proposed method
decouples the task into (1) sentence-level evidence identification and (2)
answer synthesis with explicit citations. For each stage, we automatically
explore the prompt space with DSPy's MIPROv2 optimizer, jointly tuning
instructions and few-shot demonstrations on the development set. A
self-consistency voting scheme further improves evidence recall without
sacrificing precision. On the hidden test set, our method attains an overall
score of 51.5, placing second stage while outperforming standard zero-shot and
few-shot prompting by over 20 and 10 points, respectively. These results
indicate that data-driven prompt optimization is a cost-effective alternative
to model fine-tuning for high-stakes clinical QA, advancing the reliability of
AI assistants in healthcare.

</details>


### [76] [Skillful joint probabilistic weather forecasting from marginals](https://arxiv.org/abs/2506.10772)
*Ferran Alet, Ilan Price, Andrew El-Kadi, Dominic Masters, Stratis Markou, Tom R. Andersson, Jacklynn Stott, Remi Lam, Matthew Willson, Alvaro Sanchez-Gonzalez, Peter Battaglia*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为FGN的新方法，它是一种简单、可扩展且灵活的建模方法，通过学习模型扰动生成集合预报，并直接训练以最小化连续秩概率得分（CRPS）。该方法在各种确定性和概率性指标上均优于当前最先进的模型。


<details>
  <summary>更多</summary>
  
**动机:** 基于机器学习的天气模型由于其比基于数值天气预测的传统预报更准确和快速而迅速崛起。最近，这些模型在全球概率天气预报方面超过了传统的集合预报。因此，研究人员有动机开发一种新的方法，即FGN，以进一步提高天气预报的准确性。

**方法:** FGN通过学习适当的约束模型之间的扰动来生成集合预报。它直接训练以最小化每个位置预报的连续秩概率得分（CRPS）。尽管仅在边际上进行训练，但FGN能够捕捉到联合空间结构。

**结果:** FGN在一系列确定性和概率性度量中产生了最先进水平的集合预报结果。此外，它还能做出技巧性的热带气旋轨迹预测，并且即使是在只对边际进行训练的情况下也能够捕捉到联合的空间结构。

**结论:** FGN提供了一种新颖的方法，不仅在标准度量下显著超越了现有最先进的天气预报模型，而且在热带气旋路径预测等特定任务上也表现出色。这种方法的简单性、可扩展性和灵活性使其成为改进天气预报的一个有力工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Skillful+joint+probabilistic+weather+forecasting+from+marginals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10772&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML)-based weather models have rapidly risen to prominence
due to their greater accuracy and speed than traditional forecasts based on
numerical weather prediction (NWP), recently outperforming traditional
ensembles in global probabilistic weather forecasting. This paper presents FGN,
a simple, scalable and flexible modeling approach which significantly
outperforms the current state-of-the-art models. FGN generates ensembles via
learned model-perturbations with an ensemble of appropriately constrained
models. It is trained directly to minimize the continuous rank probability
score (CRPS) of per-location forecasts. It produces state-of-the-art ensemble
forecasts as measured by a range of deterministic and probabilistic metrics,
makes skillful ensemble tropical cyclone track predictions, and captures joint
spatial structure despite being trained only on marginals.

</details>


### [77] [Monotone Classification with Relative Approximations](https://arxiv.org/abs/2506.10775)
*Yufei Tao*

**主要类别:** cs.LG

**AI概要:** 本文首次研究了寻找一个误差不超过最优单调分类器的$(1+\epsilon)\cdot k^*$倍的单调分类器所需的最低成本，其中$\epsilon \ge 0$且$k^*$是最优单调分类器达到的最小误差。对于$\epsilon$的整个范围，提供了几乎匹配的上下界。


<details>
  <summary>更多</summary>
  
**动机:** 在单调分类中，目标是找到一个具有小误差的单调函数$h$作为分类器。算法的成本定义为揭示其标签的点的数量。本文旨在研究在允许误差超过最优值最多相对因子的情况下，找到这样的分类器所需要的最低成本。

**方法:** 文章通过理论分析，提出了针对不同$\epsilon$值时，确定误差不超过$(1+\epsilon)\cdot k^*$的单调分类器所需最低成本的上界和下界。

**结果:** 对$\epsilon$的全范围给出了几乎匹配的上界和下界，这表明可以精确地估计出在给定相对误差容忍度下，找到近似最优单调分类器的成本。

**结论:** 这项工作为单调分类问题提供了一个新的视角，即考虑相对于最优解的错误率，并且对于所有$\epsilon$值都给出了接近最佳的成本界限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Monotone+Classification+with+Relative+Approximations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10775，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10775&send_immediately=true&force_search=false)

**原文摘要:** In monotone classification, the input is a multi-set $P$ of points in
$\mathbb{R}^d$, each associated with a hidden label from $\{-1, 1\}$. The goal
is to identify a monotone function $h$, which acts as a classifier, mapping
from $\mathbb{R}^d$ to $\{-1, 1\}$ with a small {\em error}, measured as the
number of points $p \in P$ whose labels differ from the function values $h(p)$.
The cost of an algorithm is defined as the number of points having their labels
revealed. This article presents the first study on the lowest cost required to
find a monotone classifier whose error is at most $(1 + \epsilon) \cdot k^*$
where $\epsilon \ge 0$ and $k^*$ is the minimum error achieved by an optimal
monotone classifier -- in other words, the error is allowed to exceed the
optimal by at most a relative factor. Nearly matching upper and lower bounds
are presented for the full range of $\epsilon$. All previous work on the
problem can only achieve an error higher than the optimal by an absolute
factor.

</details>


### [78] [Dense Associative Memory with Epanechnikov Energy](https://arxiv.org/abs/2506.10801)
*Benjamin Hoover, Zhaoyang Shi, Krishnakumar Balasubramanian, Dmitry Krotov, Parikshit Ram*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的能量函数——log-sum-ReLU (LSR)，用于密集关联记忆网络。LSR基于Epanechnikov核，能够实现精确的记忆检索并具有指数容量，同时引入了大量额外的局部最小值，保持了完美的模式恢复。实验结果表明，与基于LSE的模型相比，LSR能量具有更多且对数似然度相当的局部最小值（记忆）。


<details>
  <summary>更多</summary>
  
**动机:** 作者受到最优核密度估计的启发，旨在开发一种新的能量函数，以改进现有的DenseAM网络。这种新方法解决了传统LSE函数需要指数分离的问题，并且能够在不牺牲完美模式恢复的前提下增加记忆存储能力。

**方法:** 论文中提出了使用基于Epanechnikov核的log-sum-ReLU (LSR)作为DenseAM网络的能量函数。该方法允许在没有指数分离的情况下达到精确的记忆检索和指数级容量，并且还产生许多附加的新兴局部最小值。

**结果:** 实证研究表明，LSR能量函数拥有显著更多的局部最小值（即记忆），这些记忆与基于LSE的模型相比具有可比较的对数似然性。此外，对图像数据集上出现的记忆进行分析显示，它们表现出一定的创造性和新颖性。

**结论:** LSR能量函数不仅保持了DenseAM网络的完美模式恢复特性，而且还提供了额外的局部最小值，这表明它在大规模记忆存储和生成任务方面有潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dense+Associative+Memory+with+Epanechnikov+Energy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10801&send_immediately=true&force_search=false)

**原文摘要:** We propose a novel energy function for Dense Associative Memory (DenseAM)
networks, the log-sum-ReLU (LSR), inspired by optimal kernel density
estimation. Unlike the common log-sum-exponential (LSE) function, LSR is based
on the Epanechnikov kernel and enables exact memory retrieval with exponential
capacity without requiring exponential separation functions. Moreover, it
introduces abundant additional \emph{emergent} local minima while preserving
perfect pattern recovery -- a characteristic previously unseen in DenseAM
literature. Empirical results show that LSR energy has significantly more local
minima (memories) that have comparable log-likelihood to LSE-based models.
Analysis of LSR's emergent memories on image datasets reveals a degree of
creativity and novelty, hinting at this method's potential for both large-scale
memory storage and generative tasks.

</details>


### [79] [Detecting High-Stakes Interactions with Activation Probes](https://arxiv.org/abs/2506.10805)
*Alex McKenzie, Urja Pawar, Phil Blandfort, William Bankes, David Krueger, Ekdeep Singh Lubana, Dmitrii Krasheninnikov*

**主要类别:** cs.LG

**AI概要:** 本文研究了用于检测可能造成重大伤害的高风险交互的激活探针，发现它们在多样性和分布外的真实世界数据上具有强大的泛化能力，并且与提示或微调的中型LLM监控器相比，计算成本降低了六个数量级。


<details>
  <summary>更多</summary>
  
**动机:** 监控是安全部署大型语言模型（LLMs）的重要方面。本文聚焦于检测可能引起重大危害的'高风险'互动，这是此类监控的一个关键但尚未充分探索的目标。

**方法:** 作者评估了几种基于合成数据训练的探针架构，并将这些探针的性能与被提示或微调过的中型LLM监控器进行了比较。

**结果:** 研究表明，这些探针在多样化和分布外的真实世界数据上表现出良好的鲁棒性，并且其性能可与经过提示或微调的中型LLM监控器相媲美，同时提供了六倍数量级的计算节省。

**结论:** 该文提出了一种资源感知的分层监控系统潜力，其中探针作为高效的初步过滤工具，标记出需要更昂贵下游分析的情况。此外，还发布了新的合成数据集和代码库以促进进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+High-Stakes+Interactions+with+Activation+Probes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10805，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10805&send_immediately=true&force_search=false)

**原文摘要:** Monitoring is an important aspect of safely deploying Large Language Models
(LLMs). This paper examines activation probes for detecting "high-stakes"
interactions -- where the text indicates that the interaction might lead to
significant harm -- as a critical, yet underexplored, target for such
monitoring. We evaluate several probe architectures trained on synthetic data,
and find them to exhibit robust generalization to diverse, out-of-distribution,
real-world data. Probes' performance is comparable to that of prompted or
finetuned medium-sized LLM monitors, while offering computational savings of
six orders-of-magnitude. Our experiments also highlight the potential of
building resource-aware hierarchical monitoring systems, where probes serve as
an efficient initial filter and flag cases for more expensive downstream
analysis. We release our novel synthetic dataset and codebase to encourage
further study.

</details>


### [80] [Advanced fraud detection using machine learning models: enhancing financial transaction security](https://arxiv.org/abs/2506.10842)
*Nudrat Fariha, Md Nazmuddin Moin Khan, Md Iqbal Hossain, Syed Ali Reza, Joy Chakra Bortty, Kazi Sharmin Sultana, Md Shadidur Islam Jawad, Saniah Safat, Md Abdul Ahad, Maksuda Begum*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种端到端的、特征丰富的机器学习框架，用于通过真实世界的数据检测信用卡交易异常和欺诈行为。


<details>
  <summary>更多</summary>
  
**动机:** 随着数字支付的兴起，对智能且可扩展的系统来检测欺诈的需求日益增长。

**方法:** 研究首先将来自关系数据库的交易、持卡人、商户以及商户类别数据集合并为一个统一的分析视图，并通过特征工程提取了诸如平均消费、历史模式偏差、交易时间不规律性以及类别频率指标等行为信号。这些特征被丰富以时间标记，以便揭示所有表明欺诈行为的潜在模式。利用交易数据，我们训练并评估了一系列无监督模型：孤立森林（Isolation Forest）、一类支持向量机（One Class SVM）以及一种深层自编码器，后者被训练用来重建正常行为。

**结果:** 探索性数据分析揭示了整个数据集特征中的上下文交易趋势。PCA可视化展示了每个模型在二维潜在空间中分离异常的能力。此外，使用K-Means聚类和DBSCAN进一步细分交易场景，以识别正常的密集活动区域，并隔离稀疏的可疑区域。

**结论:** 这项工作开发了一个全面的机器学习框架，它能够有效地从大量交易数据中识别出异常和可能的欺诈行为。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advanced+fraud+detection+using+machine+learning+models%3A+enhancing+financial+transaction+security，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10842，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10842&send_immediately=true&force_search=false)

**原文摘要:** The rise of digital payments has accelerated the need for intelligent and
scalable systems to detect fraud. This research presents an end-to-end,
feature-rich machine learning framework for detecting credit card transaction
anomalies and fraud using real-world data. The study begins by merging
transactional, cardholder, merchant, and merchant category datasets from a
relational database to create a unified analytical view. Through the feature
engineering process, we extract behavioural signals such as average spending,
deviation from historical patterns, transaction timing irregularities, and
category frequency metrics. These features are enriched with temporal markers
such as hour, day of week, and weekend indicators to expose all latent patterns
that indicate fraudulent behaviours. Exploratory data analysis reveals
contextual transaction trends across all the dataset features. Using the
transactional data, we train and evaluate a range of unsupervised models:
Isolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct
normal behavior. These models flag the top 1% of reconstruction errors as
outliers. PCA visualizations illustrate each models ability to separate
anomalies into a two-dimensional latent space. We further segment the
transaction landscape using K-Means clustering and DBSCAN to identify dense
clusters of normal activity and isolate sparse, suspicious regions.

</details>


### [81] [Viability of Future Actions: Robust Safety in Reinforcement Learning via Entropy Regularization](https://arxiv.org/abs/2506.10871)
*Pierre-François Massiani, Alexander von Rohr, Lukas Haverbeck, Sebastian Trimpe*

**主要类别:** cs.LG

**AI概要:** 本文探讨了在未知干扰下，通过熵正则化和约束惩罚这两种无模型强化学习技术的相互作用来实现鲁棒安全性的新视角，并表明这种方法可以提高对扰动的鲁攧性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习领域取得了许多进展，但在未知干扰下学习能够稳健满足状态约束的策略仍然是一个开放的问题。

**方法:** 分析了无模型强化学习中熵正则化与约束惩罚两种成熟技术之间的相互作用。

**结果:** 研究表明，熵正则化偏向于最大化未来可行动作的数量，从而促进对动作噪声的鲁棒性约束满足；通过处罚来放松严格的安全约束，可以让约束RL问题被近似为非约束问题并使用标准无模型RL解决。

**结论:** 熵正则化与鲁棒性之间的联系是一个值得进一步实证和理论研究的方向，因为它可以通过简单的奖励塑形来实现RL中的鲁棒安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Viability+of+Future+Actions%3A+Robust+Safety+in+Reinforcement+Learning+via+Entropy+Regularization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10871，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10871&send_immediately=true&force_search=false)

**原文摘要:** Despite the many recent advances in reinforcement learning (RL), the question
of learning policies that robustly satisfy state constraints under unknown
disturbances remains open. In this paper, we offer a new perspective on
achieving robust safety by analyzing the interplay between two well-established
techniques in model-free RL: entropy regularization, and constraints
penalization. We reveal empirically that entropy regularization in constrained
RL inherently biases learning toward maximizing the number of future viable
actions, thereby promoting constraints satisfaction robust to action noise.
Furthermore, we show that by relaxing strict safety constraints through
penalties, the constrained RL problem can be approximated arbitrarily closely
by an unconstrained one and thus solved using standard model-free RL. This
reformulation preserves both safety and optimality while empirically improving
resilience to disturbances. Our results indicate that the connection between
entropy regularization and robustness is a promising avenue for further
empirical and theoretical investigation, as it enables robust safety in RL
through simple reward shaping.

</details>


### [82] [Lattice Climber Attack: Adversarial attacks for randomized mixtures of classifiers](https://arxiv.org/abs/2506.10888)
*Lucas Gnecco-Heredia, Benjamin Negrevergne, Yann Chevaleyre*

**主要类别:** cs.LG

**AI概要:** 本文讨论了如何以一种有原则的方式攻击分类器混合体，并提出了基于问题几何分析的攻击的两种理想属性（有效性和最大性）。现有的攻击未能满足这两种属性。为此，作者提出了一种新的具有理论保证的二元线性设置下的格攀爬攻击，并通过合成和真实数据集上的实验展示了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 由于现有的对抗性攻击方法对于有限混合分类器（也称为随机集成）并不适用，因此需要开发一种新的攻击方法来有效地针对这类分类器进行攻击。

**方法:** 论文首先对攻击混合分类器的问题进行了几何分析，并定义了攻击的有效性和最大性两个理想的属性。接着指出现有攻击无法同时满足这两个属性。最后，作者提出了一种名为格攀爬攻击的新方法，并在二元线性情况下提供了理论保证。

**结果:** 新提出的格攀爬攻击在合成数据集和真实数据集上都表现出了良好的性能。

**结论:** 研究提供了一种新型的对抗性攻击方法，该方法专门设计用于攻击有限混合分类器，并且在理论上和实验中都证明了它的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Lattice+Climber+Attack%3A+Adversarial+attacks+for+randomized+mixtures+of+classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10888，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10888&send_immediately=true&force_search=false)

**原文摘要:** Finite mixtures of classifiers (a.k.a. randomized ensembles) have been
proposed as a way to improve robustness against adversarial attacks. However,
existing attacks have been shown to not suit this kind of classifier. In this
paper, we discuss the problem of attacking a mixture in a principled way and
introduce two desirable properties of attacks based on a geometrical analysis
of the problem (effectiveness and maximality). We then show that existing
attacks do not meet both of these properties. Finally, we introduce a new
attack called {\em lattice climber attack} with theoretical guarantees in the
binary linear setting, and demonstrate its performance by conducting
experiments on synthetic and real datasets.

</details>


### [83] [NoLoCo: No-all-reduce Low Communication Training Method for Large Models](https://arxiv.org/abs/2506.10911)
*Jari Kolehmainen, Nikolay Blagoev, John Donaghy, Oğuzhan Ersoy, Christopher Nies*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为NoLoCo的新优化方法，该方法在训练过程中无需显式同步所有模型参数，从而显著降低了通信开销，并且在多种条件下都比现有方法更快收敛。


<details>
  <summary>更多</summary>
  
**动机:** 当前训练大型语言模型通常需要在包含数万个加速器的集群上进行优化方法，这些加速器通过高带宽互连进行通信。扩大这种集群的成本昂贵且可能变得不切实际，从而限制了可训练模型的规模。最近的一些研究提出了较少依赖通信的训练方法，避免了对高度连接计算集群的需求。尽管如此，最先进的低通信训练方法仍然会采用一个同步步骤用于模型参数，当针对所有模型副本执行时，在低带宽网络上可能会变得非常昂贵。

**方法:** 提出了一种新的优化方法NoLoCo，该方法在训练过程中不会显式地同步所有模型参数，因此不需要任何集体通信。NoLoCo通过部分平均模型权重与随机选择的另一个权重来隐式地同步模型权重，这是一种Nesterov动量优化器的新变体。

**结果:** NoLoCo方法在减少通信开销方面表现优异，对于数百个加速器通过互联网进行训练的情况，其同步步骤的速度要比DiLoCo使用的all-reduce快一个数量级。而且，由于没有全局阻塞通信，加速器的空闲时间也减少了。在广泛的模型大小和加速器数量下，NoLoCo还显示出最多可达4%的更快收敛速度。

**结论:** NoLoCo优化方法在不同加速器数量和模型大小上进行了基准测试，结果表明它比完全分片数据并行训练或广泛使用的低通信训练方法DiLoCo所需的通信开销要少得多。同步步骤本身估计比DiLoCo中使用的all-reduce快一个数量级。此外，没有全局阻塞通信也减少了加速器的空闲时间。与DiLoCo相比，在广泛的模型大小和加速器数量范围内观察到高达4%更快的收敛速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NoLoCo%3A+No-all-reduce+Low+Communication+Training+Method+for+Large+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10911，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10911&send_immediately=true&force_search=false)

**原文摘要:** Training large language models is generally done via optimization methods on
clusters containing tens of thousands of accelerators, communicating over a
high-bandwidth interconnect. Scaling up these clusters is expensive and can
become impractical, imposing limits on the size of models that can be trained.
Several recent studies have proposed training methods that are less
communication intensive, avoiding the need for a highly connected compute
cluster. These state-of-the-art low communication training methods still employ
a synchronization step for model parameters, which, when performed over all
model replicas, can become costly on a low-bandwidth network.
  In this work, we propose a novel optimization method, NoLoCo, that does not
explicitly synchronize all model parameters during training and, as a result,
does not require any collective communication. NoLoCo implicitly synchronizes
model weights via a novel variant of the Nesterov momentum optimizer by
partially averaging model weights with a randomly selected other one. We
provide both a theoretical convergence analysis for our proposed optimizer as
well as empirical results from language model training.
  We benchmark NoLoCo on a wide range of accelerator counts and model sizes,
between 125M to 6.8B parameters. Our method requires significantly less
communication overhead than fully sharded data parallel training or even widely
used low communication training method, DiLoCo. The synchronization step itself
is estimated to be one magnitude faster than the all-reduce used in DiLoCo for
few hundred accelerators training over the internet. We also do not have any
global blocking communication that reduces accelerator idling time. Compared to
DiLoCo, we also observe up to $4\%$ faster convergence rate with wide range of
model sizes and accelerator counts.

</details>


### [84] [Foundation Models for Causal Inference via Prior-Data Fitted Networks](https://arxiv.org/abs/2506.10914)
*Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel*

**主要类别:** cs.LG

**AI概要:** 本文提出了CausalFM，这是一个基于PFNs的框架，用于在多种因果推断场景中训练基础模型。通过构建贝叶斯先验和提出新的先验分布族，CausalFM能够在不同的设置下执行贝叶斯因果推断，并且在估计条件平均处理效应方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在通过引入CausalFM来改进现有的因果推断方法，该框架允许使用PFNs（预先用合成数据训练的变压器）进行各种因果推断场景下的基础模型训练。

**方法:** 首先基于结构因果模型（SCMs）形式化了因果推断的贝叶斯先验构造，并导出了这些先验有效性的必要标准。然后提出了一个新的先验分布族，利用受因果启发的贝叶斯神经网络，使CausalFM能够在包括后门、前门以及工具变量调整在内的多种设定下执行贝叶斯因果推断。

**结果:** CausalFM被实例化并专门训练了一个基础模型以估计条件平均处理效应（CATEs），并通过后门调整进行了测试。结果表明，CausalFM在使用各种合成和半合成基准进行CATE估计时表现具有竞争力。

**结论:** CausalFM为不同因果推断场景中的基础模型训练提供了一种通用的方法，并且与当前最先进的因果推断技术相比，它提供了一种新的范式，有可能从根本上改变医学、经济学等领域内从业者进行因果推断的方式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Foundation+Models+for+Causal+Inference+via+Prior-Data+Fitted+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10914，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10914&send_immediately=true&force_search=false)

**原文摘要:** Prior-data fitted networks (PFNs) have recently been proposed as a promising
way to train tabular foundation models. PFNs are transformers that are
pre-trained on synthetic data generated from a prespecified prior distribution
and that enable Bayesian inference through in-context learning. In this paper,
we introduce CausalFM, a comprehensive framework for training PFN-based
foundation models in various causal inference settings. First, we formalize the
construction of Bayesian priors for causal inference based on structural causal
models (SCMs) in a principled way and derive necessary criteria for the
validity of such priors. Building on this, we propose a novel family of prior
distributions using causality-inspired Bayesian neural networks that enable
CausalFM to perform Bayesian causal inference in various settings, including
back-door, front-door, and instrumental variable adjustment. Finally, we
instantiate CausalFM and explicitly train a foundation model for estimating
conditional average treatment effects (CATEs) using back-door adjustment. We
show that CausalFM performs competitively for CATE estimation using various
synthetic and semi-synthetic benchmarks. In sum, our framework can be used as a
general recipe to train foundation models for various causal inference
settings. In contrast to the current state-of-the-art in causal inference,
CausalFM offers a novel paradigm with the potential to fundamentally change how
practitioners perform causal inference in medicine, economics, and other
disciplines.

</details>


### [85] [Sequential-Parallel Duality in Prefix Scannable Models](https://arxiv.org/abs/2506.10918)
*Morris Yau, Sharut Gupta, Valerie Engelmayer, Kazuki Irie, Stefanie Jegelka, Jacob Andreas*

**主要类别:** cs.LG

**AI概要:** 本文探讨了能够支持近常数时间并行评估和线性时间、常数空间顺序推断的神经序列模型的完整类别。通过引入前缀可扫描模型（PSM）这一更广泛的类别，统一了许多现有架构，并且实证研究显示这些模型在保持基于transformer架构的表现力的同时，也达到了状态空间模型的推理效率。


<details>
  <summary>更多</summary>
  
**动机:** 随着现代神经序列模型的发展，出现了一些如门控线性注意力（GLA）和Mamba等能够实现‘顺序-并行二重性’的模型。这引发了一个问题：我们能否描述出支持近乎常量时间并行计算和线性时间、固定空间顺序推断的所有神经序列模型的全类？

**方法:** 论文首先定义了一大类这样的模型——状态空间模型，其状态更新可以使用经典的并行前缀扫描算法结合自定义的关联聚合操作符来计算。接着，通过放宽状态聚合操作符到允许任意（可能是非关联的）函数，如softmax注意力，定义了一个更为广泛的类别，即前缀可扫描模型（PSMs）。

**结果:** PSMs不仅统一了包括元素级RNNs（例如Mamba）和线性变换器（例如GLA, Mamba2, mLSTM）在内的许多现有架构，还引入了具有类似softmax运算符的新模型，它们实现了每个token O(1)摊销计算和log(N)内存以适应序列长度N。实验评估表明，在一些情况下，PSMs比现有的架构表现出更好的长度泛化能力。

**结论:** 研究表明，PSMs保持了基于transformer架构的表现力，同时匹配了状态空间模型的推理效率，在某些情况下甚至显示出优于两者长度泛化的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sequential-Parallel+Duality+in+Prefix+Scannable+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10918&send_immediately=true&force_search=false)

**原文摘要:** Modern neural sequence models are designed to meet the dual mandate of
parallelizable training and fast sequential inference. Recent developments have
given rise to various models, such as Gated Linear Attention (GLA) and Mamba,
that achieve such ``sequential-parallel duality.'' This raises a natural
question: can we characterize the full class of neural sequence models that
support near-constant-time parallel evaluation and linear-time, constant-space
sequential inference? We begin by describing a broad class of such models --
state space models -- as those whose state updates can be computed using the
classic parallel prefix scan algorithm with a custom associative aggregation
operator. We then define a more general class, Prefix-Scannable Models (PSMs),
by relaxing the state aggregation operator to allow arbitrary (potentially
non-associative) functions such as softmax attention. This generalization
unifies many existing architectures, including element-wise RNNs (e.g., Mamba)
and linear transformers (e.g., GLA, Mamba2, mLSTM), while also introducing new
models with softmax-like operators that achieve O(1) amortized compute per
token and log(N) memory for sequence length N. We empirically evaluate such
models on illustrative small-scale language modeling and canonical synthetic
tasks, including state tracking and associative recall. Empirically, we find
that PSMs retain the expressivity of transformer-based architectures while
matching the inference efficiency of state space models -- in some cases
exhibiting better length generalization than either.

</details>


### [86] [Developing a High-performance Framework for Speech Emotion Recognition in Naturalistic Conditions Challenge for Emotional Attribute Prediction](https://arxiv.org/abs/2506.10930)
*Thanathai Lertpetchpun, Tiantian Feng, Dani Byrd, Shrikanth Narayanan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种可复现的框架，通过多模态学习、多任务学习和不平衡数据处理来解决自然条件下语音情感识别的挑战，并在IS25-SER挑战赛的任务2中取得了最佳表现。


<details>
  <summary>更多</summary>
  
**动机:** 自然条件下的语音情感识别对于语音处理社区来说是一个重大挑战，包括标注者之间的标签分歧以及数据分布不均衡的问题。

**方法:** 采用多模态学习、多任务学习以及对不平衡数据进行处理的方法。具体而言，最优系统通过添加文本嵌入、预测性别，以及在训练集中包含'其他'（O）和'无共识'（X）样本来进行训练。

**结果:** 该系统在IS25-SER挑战赛中获得了第一和第二名，其中最佳表现为一个简单的双系统集成的结果。

**结论:** 提出的框架在自然条件下语音情感识别上达到了顶级性能，并且能够应对数据不平衡和标签分歧等挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Developing+a+High-performance+Framework+for+Speech+Emotion+Recognition+in+Naturalistic+Conditions+Challenge+for+Emotional+Attribute+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10930，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10930&send_immediately=true&force_search=false)

**原文摘要:** Speech emotion recognition (SER) in naturalistic conditions presents a
significant challenge for the speech processing community. Challenges include
disagreement in labeling among annotators and imbalanced data distributions.
This paper presents a reproducible framework that achieves superior (top 1)
performance in the Emotion Recognition in Naturalistic Conditions Challenge
(IS25-SER Challenge) - Task 2, evaluated on the MSP-Podcast dataset. Our system
is designed to tackle the aforementioned challenges through multimodal
learning, multi-task learning, and imbalanced data handling. Specifically, our
best system is trained by adding text embeddings, predicting gender, and
including ``Other'' (O) and ``No Agreement'' (X) samples in the training set.
Our system's results secured both first and second places in the IS25-SER
Challenge, and the top performance was achieved by a simple two-system
ensemble.

</details>


### [87] [Self-Adapting Language Models](https://arxiv.org/abs/2506.10943)
*Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, Pulkit Agrawal*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Self-Adapting LLMs (SEAL)框架，它允许大型语言模型通过生成自己的微调数据和更新指令来自我适应。通过监督微调(SFT)，这些自我编辑导致持久的权重更新，从而实现持续的适应性。实验表明SEAL是迈向能够自我指导适应的语言模型的有希望的一步。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型虽然强大但缺乏对新任务、知识或示例做出反应的机制。为了克服这一限制，作者们提出了一个能够让LLMs自我适应的新框架。

**方法:** 提出了Self-Adapting LLMs (SEAL) 框架，该框架让模型能够生成用于自身微调的数据和更新指令。模型根据新的输入产生自我编辑，并且这些编辑可能以多种方式重新组织信息。使用强化学习循环来训练模型产出有效的自我编辑，其中下游性能作为奖励信号。

**结果:** 实验结果表明，在知识整合和少量样本泛化方面，SEAL表现良好，显示出它是朝向能够自我指导适应的语言模型迈出的有希望的一步。

**结论:** SEAL框架直接利用模型自身的生成能力来控制其适应过程，这与依赖于独立适应模块或辅助网络的先前方法不同。这种新颖的方法为语言模型提供了自我导向适应的能力，使得它们可以更好地应对新任务和知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Adapting+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10943，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10943&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are powerful but static; they lack mechanisms to
adapt their weights in response to new tasks, knowledge, or examples. We
introduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to
self-adapt by generating their own finetuning data and update directives. Given
a new input, the model produces a self-edit-a generation that may restructure
the information in different ways, specify optimization hyperparameters, or
invoke tools for data augmentation and gradient-based updates. Through
supervised finetuning (SFT), these self-edits result in persistent weight
updates, enabling lasting adaptation. To train the model to produce effective
self-edits, we use a reinforcement learning loop with the downstream
performance of the updated model as the reward signal. Unlike prior approaches
that rely on separate adaptation modules or auxiliary networks, SEAL directly
uses the model's own generation to control its adaptation process. Experiments
on knowledge incorporation and few-shot generalization show that SEAL is a
promising step toward language models capable of self-directed adaptation. Our
website and code is available at https://jyopari.github.io/posts/seal.

</details>


### [88] [Execution Guided Line-by-Line Code Generation](https://arxiv.org/abs/2506.10948)
*Boaz Lavon, Shahar Katz, Lior Wolf*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的神经代码生成方法EG-CFG，该方法在生成代码时动态地结合了执行信号，通过多阶段过程为每行代码提供反馈，并在多种编码任务中展示了优越的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）已经显示出了令人印象深刻的代码生成功能，但它们通常不会在推理过程中利用执行反馈，而这是人类程序员经常使用的关键信号。

**方法:** Execution-Guided Classifier-Free Guidance (EG-CFG) 方法，它通过光束搜索来采样每行代码的候选程序补全，然后对这些候选者执行测试用例以提取执行信号，最后将这些信号结合到生成过程中。

**结果:** 实验表明，与标准方法相比，EG-CFG 在从基础问题到具有挑战性的编程竞赛任务的各种复杂程度上都显著提高了代码生成功能，并取得了最先进结果。

**结论:** EG-CFG 方法通过整合实时执行信号，在保持语法结构的同时提供了连贯的指导，支持本机并行性，探索了多样化的推理路径，并且在不同难度的编码任务中均表现优异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Execution+Guided+Line-by-Line+Code+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10948&send_immediately=true&force_search=false)

**原文摘要:** We present a novel approach to neural code generation that incorporates
real-time execution signals into the language model generation process. While
large language models (LLMs) have demonstrated impressive code generation
capabilities, they typically do not utilize execution feedback during
inference, a critical signal that human programmers regularly leverage. Our
method, Execution-Guided Classifier-Free Guidance (EG-CFG), dynamically
incorporates execution signals as the model generates code, providing
line-by-line feedback that guides the generation process toward executable
solutions. EG-CFG employs a multi-stage process: first, we conduct beam search
to sample candidate program completions for each line; second, we extract
execution signals by executing these candidates against test cases; and
finally, we incorporate these signals into the prompt during generation. By
maintaining consistent signals across tokens within the same line and
refreshing signals at line boundaries, our approach provides coherent guidance
while preserving syntactic structure. Moreover, the method naturally supports
native parallelism at the task level in which multiple agents operate in
parallel, exploring diverse reasoning paths and collectively generating a broad
set of candidate solutions. Our experiments across diverse coding tasks
demonstrate that EG-CFG significantly improves code generation performance
compared to standard approaches, achieving state-of-the-art results across
various levels of complexity, from foundational problems to challenging
competitive programming tasks. Our code is available at:
https://github.com/boazlavon/eg_cfg

</details>


### [89] [Build the web for agents, not agents for the web](https://arxiv.org/abs/2506.10953)
*Xing Han Lù, Gaurav Kamath, Marius Mosbach, Siva Reddy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的范式转变，即开发一种专门针对代理能力优化的交互范式——代理网络界面（AWI），以克服现有方法在处理网页复杂性时面临的挑战。


<details>
  <summary>更多</summary>
  
**动机:** 当前的网络代理系统在处理为人类设计的界面时面临巨大挑战，这些挑战源于人机界面与大型语言模型能力之间的根本不匹配。

**方法:** 提出了代理网络界面（AWI）的概念，并为此设定了六项指导原则，旨在确保安全性、效率和标准化。

**结果:** 通过引入AWI，该研究期望能够超越现有界面的基本限制，为更高效、可靠和透明的网络代理设计铺平道路。

**结论:** 为了促进更加自动化的网络交互，我们需要从让网络代理适应人类使用的界面转向创造一个专门为代理设计的新型交互范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Build+the+web+for+agents%2C+not+agents+for+the+web，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10953&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in Large Language Models (LLMs) and multimodal
counterparts have spurred significant interest in developing web agents -- AI
systems capable of autonomously navigating and completing tasks within web
environments. While holding tremendous promise for automating complex web
interactions, current approaches face substantial challenges due to the
fundamental mismatch between human-designed interfaces and LLM capabilities.
Current methods struggle with the inherent complexity of web inputs, whether
processing massive DOM trees, relying on screenshots augmented with additional
information, or bypassing the user interface entirely through API interactions.
This position paper advocates for a paradigm shift in web agent research:
rather than forcing web agents to adapt to interfaces designed for humans, we
should develop a new interaction paradigm specifically optimized for agentic
capabilities. To this end, we introduce the concept of an Agentic Web Interface
(AWI), an interface specifically designed for agents to navigate a website. We
establish six guiding principles for AWI design, emphasizing safety,
efficiency, and standardization, to account for the interests of all primary
stakeholders. This reframing aims to overcome fundamental limitations of
existing interfaces, paving the way for more efficient, reliable, and
transparent web agent design, which will be a collaborative effort involving
the broader ML community.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [90] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
*Luciano Floridi*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种猜想，该猜想明确地表述了AI系统中可证明正确性和广泛数据映射能力之间的基本权衡。具有演绎严密保证的AI系统其操作领域必须被严格限制和预结构化；而能够处理高维数据以产生丰富信息输出的系统则必然放弃零误差表现的可能性。通过使这种隐含的权衡关系变得明确并可被严格验证，该猜想重新定义了对AI的工程目标和哲学期望，并讨论了其对于评估标准、治理框架以及混合系统设计的影响。


<details>
  <summary>更多</summary>
  
**动机:** 文章旨在解决AI系统中可证明正确性与广泛的数据处理能力之间存在的根本性权衡问题，希望通过将这一长期以来隐含的关系明确化来重新设定AI的发展方向和技术哲学中的辩论。

**方法:** 作者首先回顾了导致上述矛盾的历史动机，然后用信息论的形式陈述了猜想，并将其置于更广泛的认识论、形式验证和技术哲学争论中进行讨论。接着分析了猜想的意义及其后果，涉及到不确定性的概念、审慎的认知风险以及道德责任等方面。

**结果:** 研究结果表明，如果这个猜想是正确的，它将有助于重塑评价标准、治理架构及混合系统的设计思路。

**结论:** 结论强调了最终证明或反驳这一不等式对于未来可信AI的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Conjecture+on+a+Fundamental+Trade-Off+between+Certainty+and+Scope+in+Symbolic+and+Generative+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10130&send_immediately=true&force_search=false)

**原文摘要:** This article introduces a conjecture that formalises a fundamental trade-off
between provable correctness and broad data-mapping capacity in Artificial
Intelligence (AI) systems. When an AI system is engineered for deductively
watertight guarantees (demonstrable certainty about the error-free nature of
its outputs) -- as in classical symbolic AI -- its operational domain must be
narrowly circumscribed and pre-structured. Conversely, a system that can input
high-dimensional data to produce rich information outputs -- as in contemporary
generative models -- necessarily relinquishes the possibility of zero-error
performance, incurring an irreducible risk of errors or misclassification. By
making this previously implicit trade-off explicit and open to rigorous
verification, the conjecture significantly reframes both engineering ambitions
and philosophical expectations for AI. After reviewing the historical
motivations for this tension, the article states the conjecture in
information-theoretic form and contextualises it within broader debates in
epistemology, formal verification, and the philosophy of technology. It then
offers an analysis of its implications and consequences, drawing on notions of
underdetermination, prudent epistemic risk, and moral responsibility. The
discussion clarifies how, if correct, the conjecture would help reshape
evaluation standards, governance frameworks, and hybrid system design. The
conclusion underscores the importance of eventually proving or refuting the
inequality for the future of trustworthy AI.

</details>


### [91] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
*Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik*

**主要类别:** cs.AI

**AI概要:** 本文探讨了医疗基础模型在适应新的人群、专业或环境时面临的挑战，提出了一个能够动态适应不同医疗情境而无需重新训练的上下文切换AI愿景。


<details>
  <summary>更多</summary>
  
**动机:** 当前的医疗基础模型在遇到未在训练中出现的新临床情况时，难以解释不熟悉的输入和调整行为，导致它们容易产生依赖于患者具体情况或背景信息的错误。

**方法:** 本文是一篇视角文章，提出了一种设想中的方法，即开发一种能够在不同的医学专科、人群、工作流程和临床角色之间动态调整其推理能力的上下文切换人工智能。

**结果:** 作者们构想了一个能够诊断、管理和治疗跨专科和地区广泛疾病，并且扩大医疗服务可及性的上下文切换AI系统。

**结论:** 文章认为，实现能够动态适应不断变化的医疗护理情境的AI是未来的发展方向，这样的AI将有助于提高医疗服务质量并拓展服务范围。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是One+Patient%2C+Many+Contexts%3A+Scaling+Medical+AI+Through+Contextual+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10157，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10157&send_immediately=true&force_search=false)

**原文摘要:** Medical foundation models, including language models trained on clinical
notes, vision-language models on medical images, and multimodal models on
electronic health records, can summarize clinical notes, answer medical
questions, and assist in decision-making. Adapting these models to new
populations, specialties, or settings typically requires fine-tuning, careful
prompting, or retrieval from knowledge bases. This can be impractical, and
limits their ability to interpret unfamiliar inputs and adjust to clinical
situations not represented during training. As a result, models are prone to
contextual errors, where predictions appear reasonable but fail to account for
critical patient-specific or contextual information. These errors stem from a
fundamental limitation that current models struggle with: dynamically adjusting
their behavior across evolving contexts of medical care. In this Perspective,
we outline a vision for context-switching in medical AI: models that
dynamically adapt their reasoning without retraining to new specialties,
populations, workflows, and clinical roles. We envision context-switching AI to
diagnose, manage, and treat a wide range of diseases across specialties and
regions, and expand access to medical care.

</details>


### [92] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
*Hamzah Dabool, Raghad Mustafa*

**主要类别:** cs.AI

**AI概要:** 该研究通过结合相关性分析、机器学习分类和模型可解释性技术，探讨了临床、认知、遗传及生物标志物特征之间的关系，并使用XGBoost算法识别出影响阿尔茨海默病分类的关键特征。结果表明强相关性并不一定意味着因果关系，强调了对关联数据进行谨慎解读的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 理解因果关系与相关性的区别对于阿尔茨海默病（AD）的研究至关重要，因为它影响着疾病的诊断、治疗以及真正疾病驱动因素的识别。

**方法:** 采用XGBoost算法来识别影响AD分类的关键特征，包括认知评分和遗传风险因素；通过相关矩阵揭示变量间的相互关系群集；利用SHAP值提供跨疾病阶段特征贡献的详细见解。

**结果:** 研究发现了一些关键特征如认知分数和遗传风险因素在AD分类中的重要性；相关矩阵展示了相互关联的变量群集；SHAP值提供了关于特征如何随着疾病不同阶段变化而贡献于模型预测的深入理解。

**结论:** 强烈的相关性并不总是意味着因果关系，这突出了正确解读关联数据的重要性。本研究为未来旨在揭示真实病理机制的因果推断研究奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Correlation+vs+causation+in+Alzheimer%27s+disease%3A+an+interpretability-driven+study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10179，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10179&send_immediately=true&force_search=false)

**原文摘要:** Understanding the distinction between causation and correlation is critical
in Alzheimer's disease (AD) research, as it impacts diagnosis, treatment, and
the identification of true disease drivers. This experiment investigates the
relationships among clinical, cognitive, genetic, and biomarker features using
a combination of correlation analysis, machine learning classification, and
model interpretability techniques. Employing the XGBoost algorithm, we
identified key features influencing AD classification, including cognitive
scores and genetic risk factors. Correlation matrices revealed clusters of
interrelated variables, while SHAP (SHapley Additive exPlanations) values
provided detailed insights into feature contributions across disease stages.
Our results highlight that strong correlations do not necessarily imply
causation, emphasizing the need for careful interpretation of associative data.
By integrating feature importance and interpretability with classical
statistical analysis, this work lays groundwork for future causal inference
studies aimed at uncovering true pathological mechanisms. Ultimately,
distinguishing causal factors from correlated markers can lead to improved
early diagnosis and targeted interventions for Alzheimer's disease.

</details>


### [93] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
*Filip Cano*

**主要类别:** cs.AI

**AI概要:** 本文在人工智能系统的安全性、公平性、透明度和问责制方面推进了知识，通过提出新的防护措施和技术框架来实现更安全、更公平且更负责任的人工智能系统。


<details>
  <summary>更多</summary>
  
**动机:** 随着自主系统越来越多地影响关键的社会领域，确保人工智能的负责任使用变得至关重要。但是，可信AI的概念仍然广泛且多面。

**方法:** 1. 扩展了经典确定性屏蔽技术以抵御延迟观察，使其能够在现实世界条件下实际部署。
2. 在模拟自动驾驶车辆中实现了确定性和概率性安全屏蔽，防止与道路使用者发生碰撞，并验证了这些技术在逼真的驾驶模拟器中的应用。
3. 引入了公平屏蔽，这是一种新的后处理方法，用于在有限和周期性时间范围内强制执行群体公平性。
4. 提出了一个正式框架，用于评估概率决策代理中的故意行为，引入了能动性和意图商数的定量指标。
5. 通过“反应式决策”框架统一了这些贡献，提供了一个整合先前方法的一般形式化。

**结果:** 所提出的这些进步对实现更安全、更公平和更可问责的人工智能系统具有实际贡献，并为未来在可信AI领域的研究奠定了基础。

**结论:** 本文的工作推动了人工智能在安全性、公平性、透明度和问责制方面的进展，为构建值得信赖的人工智能系统提供了实用的方法论，并为后续的研究打下了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Responsible+AI%3A+Advances+in+Safety%2C+Fairness%2C+and+Accountability+of+Autonomous+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10192，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10192&send_immediately=true&force_search=false)

**原文摘要:** Ensuring responsible use of artificial intelligence (AI) has become
imperative as autonomous systems increasingly influence critical societal
domains. However, the concept of trustworthy AI remains broad and
multi-faceted. This thesis advances knowledge in the safety, fairness,
transparency, and accountability of AI systems. In safety, we extend classical
deterministic shielding techniques to become resilient against delayed
observations, enabling practical deployment in real-world conditions. We also
implement both deterministic and probabilistic safety shields into simulated
autonomous vehicles to prevent collisions with road users, validating the use
of these techniques in realistic driving simulators. We introduce fairness
shields, a novel post-processing approach to enforce group fairness in
sequential decision-making settings over finite and periodic time horizons. By
optimizing intervention costs while strictly ensuring fairness constraints,
this method efficiently balances fairness with minimal interference. For
transparency and accountability, we propose a formal framework for assessing
intentional behaviour in probabilistic decision-making agents, introducing
quantitative metrics of agency and intention quotient. We use these metrics to
propose a retrospective analysis of intention, useful for determining
responsibility when autonomous systems cause unintended harm. Finally, we unify
these contributions through the ``reactive decision-making'' framework,
providing a general formalization that consolidates previous approaches.
Collectively, the advancements presented contribute practically to the
realization of safer, fairer, and more accountable AI systems, laying the
foundations for future research in trustworthy AI.

</details>


### [94] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
*Qiyue Yin, Pei Xu, Qiaozhe Li, Shengda Liu, Shengqi Shen, Tong Wang, Yihong Han, Xiaonan Zhao, Likun Yang, Shiyue Cao, Shiyu Qiu, Yuxuan Liu, Shizhao Yu, Lei Cui, Chengxin Yan, Jie Sun, Xiangquan Tang, Kaiqi Huang*

**主要类别:** cs.AI

**AI概要:** 本文提出了WGSR-Bench，这是首个使用战争游戏作为评估环境的大规模语言模型的战略推理基准，并设计了基于LLM的战争游戏代理来全面评估策略推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在推理任务上取得了显著进步，但在战略推理方面尚未得到系统性的评估或建模。为了解决这个空白，研究者们引入了WGSR-Bench。

**方法:** WGSR-Bench是第一个针对大型语言模型的战略推理基准，它利用战争游戏作为评估环境，围绕三个核心任务（即环境态势感知、对手风险建模和策略生成）设计测试样本，以系统地评估战略推理的主要能力。

**结果:** 通过WGSR-Bench，研究者可以评估最先进大型语言模型在博弈论战略推理中的优势与局限性，并推动大规模模型驱动的战略智能研究。

**结论:** WGSR-Bench为评估大型语言模型在多智能体决策制定、意图推断和反事实推理等复杂战略场景下的能力提供了有效的测试平台。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是WGSR-Bench%3A+Wargame-based+Game-theoretic+Strategic+Reasoning+Benchmark+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10264，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10264&send_immediately=true&force_search=false)

**原文摘要:** Recent breakthroughs in Large Language Models (LLMs) have led to a
qualitative leap in artificial intelligence' s performance on reasoning tasks,
particularly demonstrating remarkable capabilities in mathematical, symbolic,
and commonsense reasoning. However, as a critical component of advanced human
cognition, strategic reasoning, i.e., the ability to assess multi-agent
behaviors in dynamic environments, formulate action plans, and adapt
strategies, has yet to be systematically evaluated or modeled. To address this
gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark
for LLMs using wargame as its evaluation environment. Wargame, a quintessential
high-complexity strategic scenario, integrates environmental uncertainty,
adversarial dynamics, and non-unique strategic choices, making it an effective
testbed for assessing LLMs' capabilities in multi-agent decision-making, intent
inference, and counterfactual reasoning. WGSR-Bench designs test samples around
three core tasks, i.e., Environmental situation awareness, Opponent risk
modeling and Policy generation, which serve as the core S-POE architecture, to
systematically assess main abilities of strategic reasoning. Finally, an
LLM-based wargame agent is designed to integrate these parts for a
comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess
the strengths and limitations of state-of-the-art LLMs in game-theoretic
strategic reasoning and to advance research in large model-driven strategic
intelligence.

</details>


### [95] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
*Xinmin Fang, Lingfeng Tao, Zhengxiong Li*

**主要类别:** cs.AI

**AI概要:** 本文将人工智能重新定义为一种认知引擎，推动了一场不同于工业革命的新生产力革命。通过跨学科视角，结合计算机科学、经济学和社会学的观点，展示了AI如何在认知任务中作为生产力的驱动因素，并提出AI作为一种认知引擎的作用类似于人类语言对知识的革命性影响，标志着生产力进化的新篇章。


<details>
  <summary>更多</summary>
  
**动机:** 文章旨在重新构建人工智能的理解框架，将其视为一场认知革命而非仅仅是另一种机械工具，强调其对于知识工作的放大作用以及对社会和工作方式的重塑。

**方法:** 采用多学科视角，结合了计算机科学的进步与经济洞察力以及社会学观点来探讨AI如何改变工作和社会。

**结果:** 通过概念框架可视化了从手工生产到认知生产力的转变过程，并以各领域的实例证明了AI在认知任务中的影响力。

**结论:** 论文认为AI的核心价值在于补充人类的认知能力，预示着一个全新的生产力范式，并呼吁对技能、组织结构及政策进行重新思考以适应这场认知革命。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Closer+to+Language+than+Steam%3A+AI+as+the+Cognitive+Engine+of+a+New+Productivity+Revolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10281&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) is reframed as a cognitive engine driving a
novel productivity revolution distinct from the Industrial Revolution's
physical thrust. This paper develops a theoretical framing of AI as a cognitive
revolution akin to written language - a transformative augmentation of human
intellect rather than another mechanized tool. We compare AI's emergence to
historical leaps in information technology to show how it amplifies knowledge
work. Examples from various domains demonstrate AI's impact as a driver of
productivity in cognitive tasks. We adopt a multidisciplinary perspective
combining computer science advances with economic insights and sociological
perspectives on how AI reshapes work and society. Through conceptual
frameworks, we visualize the shift from manual to cognitive productivity. Our
central argument is that AI functions as an engine of cognition - comparable to
how human language revolutionized knowledge - heralding a new productivity
paradigm. We discuss how this revolution demands rethinking of skills,
organizations, and policies. This paper, balancing academic rigor with clarity,
concludes that AI's promise lies in complementing human cognitive abilities,
marking a new chapter in productivity evolution.

</details>


### [96] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
*Jasper Yao*

**主要类别:** cs.AI

**AI概要:** 本文探讨了随着AI系统能力的扩展，验证AI安全性的计算复杂性障碍。研究结果表明，对于超过临界阈值τ的表达能力EXP(m)的AI系统，安全性验证需要指数时间，并且是coNP完全问题。文章通过四个核心定理证明了验证复杂性与系统表达能力呈指数增长关系、安全策略在策略空间中占比极小、没有有限数量的一致性技术可以提供普遍覆盖，以及鲁棒的安全属性对于神经网络而言形成的是零测集。这些发现揭示了一个“难解性差距”，即实际的安全需求落在了计算上难以解决的区域。最后提出了一个战略上的三难困境：AI开发必须要么限制系统复杂度以保持可验证的安全性，要么接受不可验证的风险同时扩展能力，或者开发超越验证的新安全范式。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于建立随着AI系统能力增强时，验证AI安全性的基本计算复杂性障碍。

**方法:** 采用形式化方法定义了能力-风险扩展（CRS）动态，通过四个核心定理来证明验证复杂性和系统表达能力之间的关系。

**结果:** 得出了验证复杂性随系统表达能力呈指数增长、安全策略在政策空间中所占比例微乎其微、任何有限集合的一致性技术都不能提供通用覆盖范围，以及对于神经网络来说，强健的安全属性形成了测量为零的集合。

**结论:** 结论指出，AI发展面临一个战略三难困境：必须在维持可验证安全性的同时限制系统复杂性、接受无法验证的风险而扩展能力，或开发超出传统验证框架的新安全模式。此外，该研究还提供了首个关于AI一致性问题的系统性复杂性理论分析，并设定了任何安全方法都必须面对的严格界限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Alignment+Trap%3A+Complexity+Barriers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10304，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10304&send_immediately=true&force_search=false)

**原文摘要:** We establish fundamental computational complexity barriers to verifying AI
safety as system capabilities scale. Our main results show that for AI systems
with expressiveness EXP$(m)$ above a critical threshold $\tau$, safety
verification requires exponential time and is coNP-complete. We formalize the
Capability-Risk Scaling (CRS) dynamic, which demonstrates how increasing AI
capability drives societal safety requirements toward perfection, creating an
inescapable tension with verification complexity. Through four core theorems,
we prove that (1) verification complexity grows exponentially with system
expressiveness, (2) safe policies comprise at most a $2^{-2^m}$ fraction of the
policy space, (3) no finite set of alignment techniques can provide universal
coverage, and (4) robust safety properties form measure-zero sets for neural
networks. These results characterize an "intractability gap" where practical
safety requirements fall within the region of computational intractability. We
conclude by presenting a strategic trilemma: AI development must either
constrain system complexity to maintain verifiable safety, accept unverifiable
risks while scaling capabilities, or develop fundamentally new safety paradigms
beyond verification. Our work provides the first systematic
complexity-theoretic analysis of AI alignment and establishes rigorous bounds
that any safety approach must confront. A formal verification of the core
theorems in Lean4 is currently in progress.

</details>


### [97] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
*Cameron Angliss, Jiaxun Cui, Jiaheng Hu, Arrasy Rahman, Peter Stone*

**主要类别:** cs.AI

**AI概要:** 介绍了VGC-Bench，一个为宝可梦电子游戏锦标赛提供基础设施、标准化评估协议和人类玩家数据集的基准测试平台。该平台用于研究AI代理在不重新训练的情况下适应不同策略环境的能力，并展示了在单个队伍配置下训练的代理可以击败专业选手，但随着团队规模扩大，算法难以扩展，政策泛化仍然是一个开放性挑战。


<details>
  <summary>更多</summary>
  
**动机:** 开发能够稳健地适应截然不同的策略环境而无需重新训练的人工智能代理是多代理学习的核心挑战。宝可梦电子游戏锦标赛（VGC）拥有约10^139种可能的队伍配置空间，远大于Dota或星际争霸。由于其高度离散和组合性的队伍组建特性，最佳策略会根据所驾驶的队伍以及对手队伍的不同而显著变化，使得泛化变得尤为困难。

**方法:** 引入了VGC-Bench：这是一个提供关键基础设施、标准化评估协议并提供人类对战数据集和一系列基线方法的基准，包括大型语言模型代理、行为克隆、强化学习以及经验博弈论方法如自我对弈、虚构对弈和双神谕法。

**结果:** 在仅针对单一队伍配置进行训练和评估的限制条件下，我们的方法能够战胜职业VGC竞争者。然而，当评估所有基线方法在逐步扩大的队伍集合上时，发现即使是在单一队伍设置中表现最好的算法也难以随着队伍规模的增长而扩大。

**结论:** 政策泛化跨多种队伍策略依然是社区面临的一个开放性挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Benchmark+for+Generalizing+Across+Diverse+Team+Strategies+in+Competitive+Pok%C3%A9mon，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10326&send_immediately=true&force_search=false)

**原文摘要:** Developing AI agents that can robustly adapt to dramatically different
strategic landscapes without retraining is a central challenge for multi-agent
learning. Pok\'emon Video Game Championships (VGC) is a domain with an
extraordinarily large space of possible team configurations of approximately
$10^{139}$ - far larger than those of Dota or Starcraft. The highly discrete,
combinatorial nature of team building in Pok\'emon VGC causes optimal
strategies to shift dramatically depending on both the team being piloted and
the opponent's team, making generalization uniquely challenging. To advance
research on this problem, we introduce VGC-Bench: a benchmark that provides
critical infrastructure, standardizes evaluation protocols, and supplies
human-play datasets and a range of baselines - from large-language-model agents
and behavior cloning to reinforcement learning and empirical game-theoretic
methods such as self-play, fictitious play, and double oracle. In the
restricted setting where an agent is trained and evaluated on a single-team
configuration, our methods are able to win against a professional VGC
competitor. We extensively evaluated all baseline methods over progressively
larger team sets and find that even the best-performing algorithm in the
single-team setting struggles at scaling up as team size grows. Thus, policy
generalization across diverse team strategies remains an open challenge for the
community. Our code is open sourced at
https://github.com/cameronangliss/VGC-Bench.

</details>


### [98] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
*Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Weili Guan, Dongmei Jiang, Liqiang Nie*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个名为Optimus-3的通用代理，用于解决在Minecraft这样的开放世界环境中构建具有感知、计划、行动、接地和反思能力的代理所面临的挑战。通过知识增强的数据生成管道、任务级路由的混合专家架构以及多模态推理增强的强化学习方法，Optimus-3在多种任务上表现优于现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 在开放世界环境如Minecraft中创建能够执行诸如感知、规划、行动、基础化及反思等能力的通用代理面临几个挑战：领域特定数据不足、异构任务间干扰以及视觉多样性问题。

**方法:** 1) 提出了一种知识增强的数据生成流程来提供可扩展且高质量的训练数据；2) 引入了带有任务级别路由的混合专家（MoE）架构以减少不同任务之间的相互干扰；3) 开发了一种多模态推理增强的强化学习方法来提高代理在面对Minecraft中的视觉多样性时的推理能力。

**结果:** 实验结果表明，在Minecraft环境下，Optimus-3在广泛的任务范围内超越了通用的多模态大型语言模型以及其他最先进的代理。

**结论:** 通过一系列创新，包括改进的数据生成策略、先进的架构设计和专门针对视觉多样性的解决方案，Optimus-3被证明是应对Minecraft内复杂任务的有效方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimus-3%3A+Towards+Generalist+Multimodal+Minecraft+Agents+with+Scalable+Task+Experts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10357，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10357&send_immediately=true&force_search=false)

**原文摘要:** Recently, agents based on multimodal large language models (MLLMs) have
achieved remarkable progress across various domains. However, building a
generalist agent with capabilities such as perception, planning, action,
grounding, and reflection in open-world environments like Minecraft remains
challenges: insufficient domain-specific data, interference among heterogeneous
tasks, and visual diversity in open-world settings. In this paper, we address
these challenges through three key contributions. 1) We propose a
knowledge-enhanced data generation pipeline to provide scalable and
high-quality training data for agent development. 2) To mitigate interference
among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture
with task-level routing. 3) We develop a Multimodal Reasoning-Augmented
Reinforcement Learning approach to enhance the agent's reasoning ability for
visual diversity in Minecraft. Built upon these innovations, we present
Optimus-3, a general-purpose agent for Minecraft. Extensive experimental
results demonstrate that Optimus-3 surpasses both generalist multimodal large
language models and existing state-of-the-art agents across a wide range of
tasks in the Minecraft environment. Project page:
https://cybertronagent.github.io/Optimus-3.github.io/

</details>


### [99] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
*Jim O'Connor, Yeonghun Lee, Gary B Parker*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为NeuroPAL的神经进化框架，该框架结合了拓扑结构增强的神经进化（NEAT）和间断性即时学习（PAL），以提高StarCraft: Brood War中AI宏管理训练的效率。实验结果表明，与标准NEAT相比，NeuroPAL可以显著加速学习过程，并在大约一半的时间内达到具有竞争力的游戏水平。


<details>
  <summary>更多</summary>
  
**动机:** 传统的星际争霸AI依赖于基于规则的系统或有监督的深度学习方法，这些方法在适应性和计算效率方面存在局限性。研究者们希望开发一种更高效、适应性更强的方法来解决这个问题。

**方法:** 提出了一个神经进化框架NeuroPAL，它将拓扑结构增强的神经进化（NEAT）与间断性即时学习（PAL）相结合。通过交替进行高频次的低精度训练和周期性的高精度评估，PAL提高了NEAT的样本效率。

**结果:** NeuroPAL 在固定地图、单种族场景中的表现优于标准NEAT训练，在大约一半的训练时间内就能使智能体达到竞争水平。此外，进化出的智能体展现了如代理兵营放置和防御建筑优化等策略，这些都是人类专家玩家常用的策略。

**结论:** 研究表明，像PAL这样的结构化评估机制能够提升神经进化在复杂实时战略环境中的可扩展性和有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NeuroPAL%3A+Punctuated+Anytime+Learning+with+Neuroevolution+for+Macromanagement+in+Starcraft%3A+Brood+War，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10384，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10384&send_immediately=true&force_search=false)

**原文摘要:** StarCraft: Brood War remains a challenging benchmark for artificial
intelligence research, particularly in the domain of macromanagement, where
long-term strategic planning is required. Traditional approaches to StarCraft
AI rely on rule-based systems or supervised deep learning, both of which face
limitations in adaptability and computational efficiency. In this work, we
introduce NeuroPAL, a neuroevolutionary framework that integrates
Neuroevolution of Augmenting Topologies (NEAT) with Punctuated Anytime Learning
(PAL) to improve the efficiency of evolutionary training. By alternating
between frequent, low-fidelity training and periodic, high-fidelity
evaluations, PAL enhances the sample efficiency of NEAT, enabling agents to
discover effective strategies in fewer training iterations. We evaluate
NeuroPAL in a fixed-map, single-race scenario in StarCraft: Brood War and
compare its performance to standard NEAT-based training. Our results show that
PAL significantly accelerates the learning process, allowing the agent to reach
competitive levels of play in approximately half the training time required by
NEAT alone. Additionally, the evolved agents exhibit emergent behaviors such as
proxy barracks placement and defensive building optimization, strategies
commonly used by expert human players. These findings suggest that structured
evaluation mechanisms like PAL can enhance the scalability and effectiveness of
neuroevolution in complex real-time strategy environments.

</details>


### [100] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
*Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种层次化多模态技能（HMS）模块和技能增强蒙特卡洛树搜索（SA-MCTS）算法，以改善多模态大语言模型在在线环境中的长时任务表现。基于此，他们开发了名为Mirage-1的GUI代理，并通过新的基准测试AndroidLH验证了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前利用多模态大型语言模型作为GUI代理的方法在处理在线环境下的长时间任务时存在不足，主要原因是知识不够以及离线与在线领域之间的差距。

**方法:** 提出了一个层次化的多模态技能（HMS）模块来解决知识不足的问题，并且引入了技能增强的蒙特卡洛树搜索（SA-MCTS）算法来减少在线探索期间的动作搜索空间。

**结果:** 实验结果表明，Mirage-1 在 AndroidWorld、MobileMiniWob++、Mind2Web-Live 和 AndroidLH 上分别比之前的代理高出 32%、19%、15% 和 79% 的性能。

**结论:** 提出的解决方案能够显著提升多模态大语言模型在实际应用中执行长时任务的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mirage-1%3A+Augmenting+and+Updating+GUI+Agent+with+Hierarchical+Multimodal+Skills，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10387，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10387&send_immediately=true&force_search=false)

**原文摘要:** Recent efforts to leverage the Multi-modal Large Language Model (MLLM) as GUI
agents have yielded promising outcomes. However, these agents still struggle
with long-horizon tasks in online environments, primarily due to insufficient
knowledge and the inherent gap between offline and online domains. In this
paper, inspired by how humans generalize knowledge in open-ended environments,
we propose a Hierarchical Multimodal Skills (HMS) module to tackle the issue of
insufficient knowledge. It progressively abstracts trajectories into execution
skills, core skills, and ultimately meta-skills, providing a hierarchical
knowledge structure for long-horizon task planning. To bridge the domain gap,
we propose the Skill-Augmented Monte Carlo Tree Search (SA-MCTS) algorithm,
which efficiently leverages skills acquired in offline environments to reduce
the action search space during online tree exploration. Building on HMS, we
propose Mirage-1, a multimodal, cross-platform, plug-and-play GUI agent. To
validate the performance of Mirage-1 in real-world long-horizon scenarios, we
constructed a new benchmark, AndroidLH. Experimental results show that Mirage-1
outperforms previous agents by 32\%, 19\%, 15\%, and 79\% on AndroidWorld,
MobileMiniWob++, Mind2Web-Live, and AndroidLH, respectively. Project page:
https://cybertronagent.github.io/Mirage-1.github.io/

</details>


### [101] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
*Jintao Liang, Gang Su, Huifeng Lin, You Wu, Rui Zhao, Ziyue Li*

**主要类别:** cs.AI

**AI概要:** 本文综述了推理代理RAG方法，将其分为预定义推理和代理推理两大类，并探讨了它们的设计、策略及工具协调，最后指出了研究挑战和未来方向。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决现有RAG系统在复杂推理、动态检索以及多模态集成等现实场景中的局限性，领域内转向了将决策制定和自适应工具使用直接嵌入检索过程的推理代理RAG范式。

**方法:** 文章对推理代理RAG方法进行了全面回顾，并将其分类为预定义推理（遵循固定模块化流程以增强推理能力）和代理推理（模型在推断过程中自主协调工具交互）。

**结果:** 分析了两种范式下的代表性技术，包括架构设计、推理策略和工具协调机制。

**结论:** 讨论了关键的研究挑战并提出了推动推理代理RAG系统灵活性、鲁棒性和适用性的未来研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning+RAG+via+System+1+or+System+2%3A+A+Survey+on+Reasoning+Agentic+Retrieval-Augmented+Generation+for+Industry+Challenges，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10408，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10408&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to
overcome the knowledge limitations of Large Language Models (LLMs) by
integrating external retrieval with language generation. While early RAG
systems based on static pipelines have shown effectiveness in well-structured
tasks, they struggle in real-world scenarios requiring complex reasoning,
dynamic retrieval, and multi-modal integration. To address these challenges,
the field has shifted toward Reasoning Agentic RAG, a paradigm that embeds
decision-making and adaptive tool use directly into the retrieval process. In
this paper, we present a comprehensive review of Reasoning Agentic RAG methods,
categorizing them into two primary systems: predefined reasoning, which follows
fixed modular pipelines to boost reasoning, and agentic reasoning, where the
model autonomously orchestrates tool interaction during inference. We analyze
representative techniques under both paradigms, covering architectural design,
reasoning strategies, and tool coordination. Finally, we discuss key research
challenges and propose future directions to advance the flexibility,
robustness, and applicability of reasoning agentic RAG systems. Our collection
of the relevant research has been organized into a
https://github.com/ByebyeMonica/Reasoning-Agentic-RAG.

</details>


### [102] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
*Boris Sedlak, Alireza Furutanpey, Zihang Wang, Víctor Casamayor Pujol, Schahram Dustdar*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于代理的自动扩展框架，该框架能够动态调整硬件资源和内部服务配置，以在受限环境中最大化需求满足。通过比较四种类型的扩展代理，并使用两个并行运行的实际处理服务进行测试，结果表明所有代理都达到了可接受的服务水平目标性能，且各具特点。


<details>
  <summary>更多</summary>
  
**动机:** 边缘计算由于严格的资源限制，与传统的自动扩展方式不兼容，因此需要更加灵活的多维度扩展行为。

**方法:** 研究引入了一个基于代理的自动扩展框架，可以同时动态调整硬件资源和内部服务配置。此外，还对比了四种不同类型的扩展代理：主动推理、深度Q网络、结构知识分析以及深度主动推理，并利用YOLOv8视觉识别和OpenCV二维码检测两个实际处理服务进行了实验。

**结果:** 所有代理都能达到可接受的服务等级目标（SLO）性能，但表现出不同的收敛模式。深度Q网络得益于预训练；结构知识分析方法收敛迅速；而深度主动推理代理结合了理论基础与实践中的可扩展性优势。

**结论:** 研究结果为基于代理的多维自动扩展在边缘环境中的可行性提供了证据，并鼓励未来在这个研究方向上的进一步工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-dimensional+Autoscaling+of+Processing+Services%3A+A+Comparison+of+Agent-based+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10420，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10420&send_immediately=true&force_search=false)

**原文摘要:** Edge computing breaks with traditional autoscaling due to strict resource
constraints, thus, motivating more flexible scaling behaviors using multiple
elasticity dimensions. This work introduces an agent-based autoscaling
framework that dynamically adjusts both hardware resources and internal service
configurations to maximize requirements fulfillment in constrained
environments. We compare four types of scaling agents: Active Inference, Deep Q
Network, Analysis of Structural Knowledge, and Deep Active Inference, using two
real-world processing services running in parallel: YOLOv8 for visual
recognition and OpenCV for QR code detection. Results show all agents achieve
acceptable SLO performance with varying convergence patterns. While the Deep Q
Network benefits from pre-training, the structural analysis converges quickly,
and the deep active inference agent combines theoretical foundations with
practical scalability advantages. Our findings provide evidence for the
viability of multi-dimensional agent-based autoscaling for edge environments
and encourage future work in this research direction.

</details>


### [103] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
*Yaoming Zhu, Junxin Wang, Yiyang Li, Lin Qiu, ZongYu Wang, Jun Xu, Xuezhi Cao, Yuhuai Wei, Mingshi Wang, Xunliang Cai, Rong Ma*

**主要类别:** cs.AI

**AI概要:** 本文介绍了OIBench，一个高质量、私有且具有挑战性的信息学奥林匹克级别的数据集，包含250个精心策划的原创问题。实验表明开源模型落后于闭源模型，但现有最先进模型在正确性和效率上已经超过了大多数人类参与者。


<details>
  <summary>更多</summary>
  
**动机:** 随着模型变得越来越复杂，传统的算法基准测试逐渐饱和，这强调了需要更具有挑战性的基准来指导未来算法推理能力的改进。

**方法:** 构建了一个名为OIBench的数据集，该数据集包含了250个精心挑选的原创问题，并通过实验展示了其抗污染特性。提出了时间/空间完成曲线来进行更细致的效率分析，并通过高级参与者的评估实现了直接的人机比较。

**结果:** 实验结果显示，虽然开源模型落后于闭源模型，当前最先进的模型在正确性和效率方面已经超过了大部分人类参与者，但与标准解决方案相比仍存在不足。

**结论:** 通过发布OIBench作为完全开源资源，作者希望这个基准能够有助于提升未来大型语言模型（LLMs）的代码推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OIBench%3A+Benchmarking+Strong+Reasoning+Models+with+Olympiad+in+Informatics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10481，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10481&send_immediately=true&force_search=false)

**原文摘要:** As models become increasingly sophisticated, conventional algorithm
benchmarks are increasingly saturated, underscoring the need for more
challenging benchmarks to guide future improvements in algorithmic reasoning.
This paper introduces OIBench, a high-quality, private, and challenging
olympiad-level informatics dataset comprising 250 carefully curated original
problems. We detail the construction methodology of the benchmark, ensuring a
comprehensive assessment across various programming paradigms and complexities,
and we demonstrate its contamination-resistant properties via experiments. We
propose Time/Space Completion Curves for finer-grained efficiency analysis and
enable direct human-model comparisons through high-level participant
evaluations. Our experiments reveal that while open-source models lag behind
closed-source counterparts, current SOTA models already outperform most human
participants in both correctness and efficiency, while still being suboptimal
compared to the canonical solutions. By releasing OIBench as a fully
open-source resource (https://huggingface.co/datasets/AGI-Eval/OIBench), we
hope this benchmark will contribute to advancing code reasoning capabilities
for future LLMs.

</details>


### [104] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
*Yuhao Zhou, Yiheng Wang, Xuming He, Ruoyao Xiao, Zhiwei Li, Qiantai Feng, Zijie Guo, Yuejin Yang, Hao Wu, Wenxuan Huang, Jiaqi Wei, Dan Si, Xiuqi Yao, Jia Bu, Haiwen Huang, Tianfan Fu, Shixiang Tang, Ben Fei, Dongzhan Zhou, Fenghua Ling, Yan Lu, Siqi Sun, Chenhui Li, Guanjie Zheng, Jiancheng Lv, Wenlong Zhang, Lei Bai*

**主要类别:** cs.AI

**AI概要:** 本文介绍了科学家首次考试（SFE）基准测试，旨在评估多模态大型语言模型（MLLMs）的科学认知能力。实验表明当前最先进的GPT-o3和InternVL-3在SFE上得分不高，指出MLLMs在科学领域有显著改进空间。


<details>
  <summary>更多</summary>
  
**动机:** 目前科学基准主要侧重于评估MLLM的知识理解能力，而对感知和推理能力的评估不足。为解决这一问题，作者提出了科学家首次考试（SFE）基准测试。

**方法:** 创建了一个名为科学家首次考试（SFE）的基准测试，它包括830个专家验证过的VQA配对，覆盖了五个高价值学科中的66个多模态任务，并通过三个相互关联的层次来评估：科学信号感知、科学属性理解和科学比较推理。

**结果:** 广泛的实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分分别只有34.08%和26.52%，显示出MLLMs在科学领域有很大的提升空间。

**结论:** SFE基准测试揭示了MLLMs在科学发现流程中增强潜力的同时，也指出了它们在科学认知方面存在的局限性，希望这些见解能促进AI增强科学发现的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scientists%27+First+Exam%3A+Probing+Cognitive+Abilities+of+MLLM+via+Perception%2C+Understanding%2C+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10521，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10521&send_immediately=true&force_search=false)

**原文摘要:** Scientific discoveries increasingly rely on complex multimodal reasoning
based on information-intensive scientific data and domain-specific expertise.
Empowered by expert-level scientific benchmarks, scientific Multimodal Large
Language Models (MLLMs) hold the potential to significantly enhance this
discovery process in realistic workflows. However, current scientific
benchmarks mostly focus on evaluating the knowledge understanding capabilities
of MLLMs, leading to an inadequate assessment of their perception and reasoning
abilities. To address this gap, we present the Scientists' First Exam (SFE)
benchmark, designed to evaluate the scientific cognitive capacities of MLLMs
through three interconnected levels: scientific signal perception, scientific
attribute understanding, scientific comparative reasoning. Specifically, SFE
comprises 830 expert-verified VQA pairs across three question types, spanning
66 multimodal tasks across five high-value disciplines. Extensive experiments
reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%
and 26.52% on SFE, highlighting significant room for MLLMs to improve in
scientific realms. We hope the insights obtained in SFE will facilitate further
developments in AI-enhanced scientific discoveries.

</details>


### [105] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
*Yanan Cai, Ahmed Salem, Besmira Nushi, Mark Russinovich*

**主要类别:** cs.AI

**AI概要:** 本文介绍了LogiPlan，这是一个新的基准测试，用于评估大型语言模型在复杂关系结构上的逻辑规划和推理能力。它包括三个互补任务：计划生成、一致性检测和比较问题，并通过动态调整任务复杂性来精细评估模型性能。研究发现，尽管最近的增强推理模型在简单实例上表现出色，但在需要更深层次逻辑规划的复杂配置中仍面临挑战。


<details>
  <summary>更多</summary>
  
**动机:** 为了评估大型语言模型（LLMs）处理复杂关系结构时的逻辑规划与推理能力，特别是在那些依赖于这些模型生成和查询诸如网络基础设施、知识库或业务流程模式等结构化关系图的应用场景中。

**方法:** 设计了一个名为LogiPlan的新基准，该基准包含了三个互补的任务：1) 计划生成；2) 一致性检测；3) 比较问题。此外，还考察了模型自我修正的能力。对当前最先进的多个模型进行了评测，包括但不限于DeepSeek R1, Gemini 2.0 Pro等。

**结果:** 研究表明，在面对较为简单的逻辑规划问题时，一些最新的增强了推理能力的语言模型能够取得较好的成绩；然而，当遇到需要进行更深入逻辑思考的问题时，即使是这些先进的模型也显得力不从心。同时，模型规模与架构的不同与其表现之间存在显著的相关性。

**结论:** 虽然最近的推理增强型模型在处理简单逻辑规划问题方面展现出潜力，但它们在应对更加复杂的逻辑规划需求时仍存在明显不足。这表明未来的研究工作需要进一步提高模型解决深层次逻辑问题的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LogiPlan%3A+A+Structured+Benchmark+for+Logical+Planning+and+Relational+Reasoning+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10527&send_immediately=true&force_search=false)

**原文摘要:** We introduce LogiPlan, a novel benchmark designed to evaluate the
capabilities of large language models (LLMs) in logical planning and reasoning
over complex relational structures. Logical relational reasoning is important
for applications that may rely on LLMs to generate and query structured graphs
of relations such as network infrastructure, knowledge bases, or business
process schema. Our framework allows for dynamic variation of task complexity
by controlling the number of objects, relations, and the minimum depth of
relational chains, providing a fine-grained assessment of model performance
across difficulty levels. LogiPlan encompasses three complementary tasks: (1)
Plan Generation, where models must construct valid directed relational graphs
meeting specified structural constraints; (2) Consistency Detection, testing
models' ability to identify inconsistencies in relational structures; and (3)
Comparison Question, evaluating models' capacity to determine the validity of
queried relationships within a given graph. Additionally, we assess models'
self-correction capabilities by prompting them to verify and refine their
initial solutions. We evaluate state-of-the-art models including DeepSeek R1,
Gemini 2.0 Pro, Gemini 2 Flash Thinking, GPT-4.5, GPT-4o, Llama 3.1 405B,
O3-mini, O1, and Claude 3.7 Sonnet across these tasks, revealing significant
performance gaps that correlate with model scale and architecture. Our analysis
demonstrates that while recent reasoning-enhanced models show promising results
on simpler instances, they struggle with more complex configurations requiring
deeper logical planning.

</details>


### [106] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
*Mohd Anwar Jamal Faiz*

**主要类别:** cs.AI

**AI概要:** 本文介绍了Primender序列，这是一种结合了经典素数性质和基于模数位条件的新型整数序列。它被提议作为评估大型语言模型（LLMs）符号推理能力的基准。研究动机是需要可解释的、基于规则的测试平台来评估LLM推断隐藏规则、验证数学假设以及大规模泛化符号逻辑的能力。文章设计了一个结构化的提示和评估框架，以跨多个最先进的LLMs测试关于该序列的一个关键假设。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于为大型语言模型提供一个可解释且基于规则的测试平台，以便能够评估这些模型在推导隐藏规则、验证数学假设以及大规模推广符号逻辑方面的能力。

**方法:** 论文提出了一种新的整数序列Primender，并通过一系列精心设计的提示和评估框架来测试多种最先进的大型语言模型对该序列的理解和应用。

**结果:** 研究结果表明，通过使用Primender序列作为基准，可以有效地衡量大型语言模型在符号推理、假设检验和模式推广方面的表现。

**结论:** 这项工作贡献了一个新颖的数学构造以及一种可重复的方法论，用于在符号推理、假设检验和可扩展模式推广方面对大型语言模型进行基准测试。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Primender+Sequence%3A+A+Novel+Mathematical+Construct+for+Testing+Symbolic+Inference+and+AI+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10585，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10585&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces the Primender sequence, a novel integer sequence
defined by a hybrid rule that combines classical primality with modular
digit-based conditions. Specifically, a number n is included in the sequence if
it is prime or ends with a prime number of unit digit or any length. In other
words, numbers which are primes or have at least one prime suffix. The
resulting sequence exhibits a deterministic yet non-trivial structure, blending
number-theoretic properties with symbolic patterning. We propose the Primender
sequence as a benchmark for evaluating the symbolic reasoning capabilities of
Large Language Models (LLMs). The study is motivated by the need for
interpretable, rule-based testbeds that can assess an LLM's ability to infer
hidden rules, validate mathematical hypotheses, and generalize symbolic logic
at scale. A key hypothesis explored is: Whenever a number in the Primender
sequence is exactly one more than the largest prime less than or equal to it,
the difference between it and the previous number in the sequence is also 1. We
design a structured prompt and evaluation framework to test this hypothesis
across multiple state-of-the-art LLMs, including ChatGPT, Copilot, DeepSeek,
Gemini, Grok, and LLaMA. The models are tasked with identifying the underlying
rule, validating the hypothesis, and generating the next 100,000 terms of the
sequence. Comparative metrics such as rule inference accuracy, hypothesis
evaluation, sequence validity, and symbolic explanation quality are used to
assess model performance. This work contributes a novel mathematical construct
and a reproducible methodology for benchmarking LLMs in symbolic reasoning,
hypothesis testing, and scalable pattern generalization - bridging the domains
of number theory, artificial intelligence, and software engineering.

</details>


### [107] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
*Henrik Sebastian Steude, Alexander Diedrich, Ingo Pill, Lukas Moddemann, Daniel Vranješ, Oliver Niggemann*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的诊断方法，该方法仅需要子系统关系的基本理解和标称操作数据，结合基于神经网络的症状生成器和新的图诊断算法，能够有效地识别复杂信息物理系统中的故障。实验结果表明，该方法在大多数情况下都能准确地包括真正的因果组件，并有效缩小搜索空间。


<details>
  <summary>更多</summary>
  
**动机:** 对于复杂的网络物理系统，传统的诊断过程通常需要详细的系统模型或全面的训练数据，但获取这些信息非常困难。因此，作者旨在开发一种只需要少量先验知识的新诊断方法。

**方法:** 所提出的方法使用了一个基于神经网络的症状生成器来检测子系统级别的异常，并与一个新图诊断算法相结合，该算法利用了子系统之间最小的因果关系信息。

**结果:** 通过完全可控的模拟数据集实验，结果显示该方法在82%的情况下包含了真实的因果组件，并且在73%的情况下成功减小了搜索范围。此外，在实际的安全水处理数据集上的额外测试也证明了该方法在现实场景中的潜力。

**结论:** 研究结果表明，即使在有限的先验知识下，所提出的方法也能应用于大型和复杂的网络物理系统中，并具有很好的实用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Driven+Diagnosis+for+Large+Cyber-Physical-Systems+with+Minimal+Prior+Information，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10613，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10613&send_immediately=true&force_search=false)

**原文摘要:** Diagnostic processes for complex cyber-physical systems often require
extensive prior knowledge in the form of detailed system models or
comprehensive training data. However, obtaining such information poses a
significant challenge. To address this issue, we present a new diagnostic
approach that operates with minimal prior knowledge, requiring only a basic
understanding of subsystem relationships and data from nominal operations. Our
method combines a neural network-based symptom generator, which employs
subsystem-level anomaly detection, with a new graph diagnosis algorithm that
leverages minimal causal relationship information between
subsystems-information that is typically available in practice. Our experiments
with fully controllable simulated datasets show that our method includes the
true causal component in its diagnosis set for 82 p.c. of all cases while
effectively reducing the search space in 73 p.c. of the scenarios. Additional
tests on the real-world Secure Water Treatment dataset showcase the approach's
potential for practical scenarios. Our results thus highlight our approach's
potential for practical applications with large and complex cyber-physical
systems where limited prior knowledge is available.

</details>


### [108] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
*Vincenzo Colle, Mohamed Sana, Nicola Piovesan, Antonio De Domenico, Fadhel Ayed, Merouane Debbah*

**主要类别:** cs.AI

**AI概要:** 本文介绍了TeleMath，一个专门设计用于评估大语言模型在解决电信领域数学问题上表现的基准数据集，并通过一系列开源大语言模型对其进行测试，发现专为数学或逻辑推理设计的最新模型表现最佳。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能在电信领域的广泛应用，人们对大型语言模型处理特定领域内、尤其是数学密集型任务的能力产生了兴趣。尽管最近的进步提高了这些模型在一般数学推理上的性能，但在诸如信号处理、网络优化和性能分析等专业领域中的有效性仍大多未被探索。

**方法:** 创建了名为TeleMath的基准数据集，包含500个问答对，覆盖了电信领域的广泛主题。该数据集是通过从由主题专家精心制作的问题种子开始生成的。此外，还评估了一系列开源大型语言模型在TeleMath上的表现。

**结果:** 研究表明，在TeleMath上表现最好的是那些明确为数学或逻辑推理设计的最新模型。相比之下，即使是参数数量庞大的通用模型，在应对这些挑战时也常常遇到困难。

**结论:** 本文的工作填补了对电信领域内大语言模型数学解题能力研究的空白，并公开了数据集和评估代码以促进结果的可重复性和未来的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TeleMath%3A+A+Benchmark+for+Large+Language+Models+in+Telecom+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10674，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10674&send_immediately=true&force_search=false)

**原文摘要:** The increasing adoption of artificial intelligence in telecommunications has
raised interest in the capability of Large Language Models (LLMs) to address
domain-specific, mathematically intensive tasks. Although recent advancements
have improved the performance of LLMs in general mathematical reasoning, their
effectiveness within specialized domains, such as signal processing, network
optimization, and performance analysis, remains largely unexplored. To address
this gap, we introduce TeleMath, the first benchmark dataset specifically
designed to evaluate LLM performance in solving mathematical problems with
numerical solutions in the telecommunications domain. Comprising 500
question-answer (QnA) pairs, TeleMath covers a wide spectrum of topics in the
telecommunications field. This paper outlines the proposed QnAs generation
pipeline, starting from a selected seed of problems crafted by Subject Matter
Experts. The evaluation of a wide range of open-source LLMs reveals that best
performance on TeleMath is achieved by recent models explicitly designed for
mathematical or logical reasoning. In contrast, general-purpose models, even
those with a large number of parameters, often struggle with these challenges.
We have released the dataset and the evaluation code to ease result
reproducibility and support future research.

</details>


### [109] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
*Tom Westermann, Aljosha Köcher, Felix Gehlhoff*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种将非正式文本约束转换为可形式化验证的约束的方法，通过将AutomationML模型映射到OWL本体，并使用大型语言模型将文本规则转化为SHACL约束来进行自动验证。


<details>
  <summary>更多</summary>
  
**动机:** 现有的AutomationML建模建议通常以非正式和文本形式表达，这使得这些约束不能在AML内部自动验证。

**方法:** 首先通过RML和SPARQL将AML模型映射至OWL本体；然后利用大型语言模型将文本规则翻译成SHACL约束；接着对生成的AML本体进行SHACL约束验证；最后将SHACL验证结果自动生成自然语言解释。

**结果:** 该方法能够在不需用户理解形式化方法或本体技术的前提下，实现对复杂建模规则的半自动化检查。

**结论:** 本文介绍的方法能够将非正式的建模建议转换为可以被形式化并自动验证的约束，从而提高工程中数据交换标准的一致性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+Validation+of+Textual+Constraints+Against+AutomationML+via+LLMs+and+SHACL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10678，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10678&send_immediately=true&force_search=false)

**原文摘要:** AutomationML (AML) enables standardized data exchange in engineering, yet
existing recommendations for proper AML modeling are typically formulated as
informal and textual constraints. These constraints cannot be validated
automatically within AML itself. This work-in-progress paper introduces a
pipeline to formalize and verify such constraints. First, AML models are mapped
to OWL ontologies via RML and SPARQL. In addition, a Large Language Model
translates textual rules into SHACL constraints, which are then validated
against the previously generated AML ontology. Finally, SHACL validation
results are automatically interpreted in natural language. The approach is
demonstrated on a sample AML recommendation. Results show that even complex
modeling rules can be semi-automatically checked -- without requiring users to
understand formal methods or ontology technologies.

</details>


### [110] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
*Michael Bartholomew, Joohyung Lee*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个名为aspsmt2smt的编译器，它能够将ASPMT程序转换为SMT实例，使得SMT解算器可以计算ASPMT程序的稳定模型，并且该系统能够有效地处理实数计算以推理连续变化。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在通过开发一个编译器来实现ASPMT程序到SMT实例的转换，从而利用现有的SMT解算器来计算ASPMT程序的稳定模型。

**方法:** 研究者们开发了aspsmt2smt编译器，该编译器使用了ASP grounder gringo和SMT solver z3。gringo对输入程序进行部分接地，而z3则处理剩余变量。

**结果:** 实验结果表明，所提出的系统能够有效处理实数运算，进而支持关于连续变化的推理。

**结论:** aspsmt2smt编译器提供了一种新的方法，将ASPMT程序转化为SMT实例，让SMT求解器能够用于求解这些程序的稳定模型，并且对于涉及实数的连续变化推理表现出良好的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是System+ASPMT2SMT%3AComputing+ASPMT+Theories+by+SMT+Solvers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10708，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10708&send_immediately=true&force_search=false)

**原文摘要:** Answer Set Programming Modulo Theories (ASPMT) is an approach to combining
answer set programming and satisfiability modulo theories based on the
functional stable model semantics. It is shown that the tight fragment of ASPMT
programs can be turned into SMT instances, thereby allowing SMT solvers to
compute stable models of ASPMT programs. In this paper we present a compiler
called {\sc aspsmt2smt}, which implements this translation. The system uses ASP
grounder {\sc gringo} and SMT solver {\sc z3}. {\sc gringo} partially grounds
input programs while leaving some variables to be processed by {\sc z3}. We
demonstrate that the system can effectively handle real number computations for
reasoning about continuous changes.

</details>


### [111] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
*Adam Ishay, Zhun Yang, Joohyung Lee, Ilgu Kang, Dongjae Lim*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种增强神经-符号模型以进行反事实推理的方法，通过定义因果图来表示事件之间的因果关系，并使用答案集编程（ASP）来协调感知和模拟模块。在CLEVRER和CRAFT两个基准测试中验证了该方法的有效性，并且在CLEVRER挑战上达到了最先进的性能，在CRAFT基准测试中结合大型预训练语言模型进一步提高了反事实问题的性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的神经-符号模型虽然在将符号推理与基于神经网络的感知和预测结合起来方面显示出了潜力，但在回答反事实问题时仍然存在局限性。

**方法:** 本文引入了一种通过利用事件间因果关系的符号推理来增强神经-符号模型用于反事实推理的方法。定义了因果图的概念来表示这些关系，并采用了答案集编程(ASP)这种声明式逻辑编程方法来发现如何协调感知和模拟模块。对于CRAFT基准测试，还利用了如GPT-3.5和GPT-4这样的大型预训练语言模型作为动力学模拟器的代理。

**结果:** 实验结果表明，该方法在CLEVRER挑战上取得了最先进的表现，显著优于现有模型。而在CRAFT基准测试中，通过提供由符号因果推理指导的替代提示，该方法可以进一步提高其对反事实问题的处理能力。

**结论:** 提出的方法通过改进神经-符号模型对反事实问题的处理，展示了其在视频动态因果及时序推理中的有效性和先进性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think+before+You+Simulate%3A+Symbolic+Reasoning+to+Orchestrate+Neural+Computation+for+Counterfactual+Question+Answering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10753，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10753&send_immediately=true&force_search=false)

**原文摘要:** Causal and temporal reasoning about video dynamics is a challenging problem.
While neuro-symbolic models that combine symbolic reasoning with neural-based
perception and prediction have shown promise, they exhibit limitations,
especially in answering counterfactual questions. This paper introduces a
method to enhance a neuro-symbolic model for counterfactual reasoning,
leveraging symbolic reasoning about causal relations among events. We define
the notion of a causal graph to represent such relations and use Answer Set
Programming (ASP), a declarative logic programming method, to find how to
coordinate perception and simulation modules. We validate the effectiveness of
our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves
state-of-the-art performance on the CLEVRER challenge, significantly
outperforming existing models. In the case of the CRAFT benchmark, we leverage
a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a
dynamics simulator. Our findings show that this method can further improve its
performance on counterfactual questions by providing alternative prompts
instructed by symbolic causal reasoning.

</details>


### [112] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
*Xiaozhe Li, Jixuan Chen, Xinyu Fang, Shengyuan Ding, Haodong Duan, Qingwen Liu, Kai Chen*

**主要类别:** cs.AI

**AI概要:** 研究者们提出了OPT-BENCH，一个用于评估大型语言模型在大规模搜索空间优化问题上的能力的基准。该基准包括20个来自Kaggle的真实机器学习任务和10个经典的NP问题，并引入了OPT-Agent框架来模拟人类处理复杂问题时的推理过程。通过在9种最先进的大型语言模型上进行广泛的实验，研究发现历史反馈的利用显著提高了优化性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）在解决各种任务中表现出色，但它们通过从先前反馈中学习以迭代地优化复杂解决方案的能力尚未得到充分探索。为了填补这一空白，研究者们开发了OPT-BENCH。

**方法:** 研究者设计了一个名为OPT-BENCH的综合基准，它包含了20个实际的机器学习任务和10个经典NP难题。此外，他们还创建了OPT-Agent框架，该框架能够模仿人类面对复杂问题时的解题方式，通过生成、验证以及利用历史反馈循环改进方案来进行端到端的优化。

**结果:** 通过对6个模型家族中的9种最先进大型语言模型开展大量实验，研究人员分析了优化迭代次数、温度设置和模型架构等因素对解决方案质量和收敛性的影响。结果表明，在ML和NP任务中结合历史背景信息可以显著提高优化效果。

**结论:** 本研究表明，将历史反馈融入到解决问题的过程中可以极大地提升大型语言模型在优化任务上的表现。所有数据集、代码及评估工具均被开源，旨在促进LLM驱动的优化与迭代推理领域的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OPT-BENCH%3A+Evaluating+LLM+Agent+on+Large-Scale+Search+Spaces+Optimization+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10764，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10764&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have shown remarkable capabilities in solving
diverse tasks. However, their proficiency in iteratively optimizing complex
solutions through learning from previous feedback remains insufficiently
explored. To bridge this gap, we present OPT-BENCH, a comprehensive benchmark
designed to evaluate LLM agents on large-scale search space optimization
problems. OPT-BENCH includes 20 real-world machine learning tasks sourced from
Kaggle and 10 classical NP problems, offering a diverse and challenging
environment for assessing LLM agents on iterative reasoning and solution
refinement. To enable rigorous evaluation, we introduce OPT-Agent, an
end-to-end optimization framework that emulates human reasoning when tackling
complex problems by generating, validating, and iteratively improving solutions
through leveraging historical feedback. Through extensive experiments on 9
state-of-the-art LLMs from 6 model families, we analyze the effects of
optimization iterations, temperature settings, and model architectures on
solution quality and convergence. Our results demonstrate that incorporating
historical context significantly enhances optimization performance across both
ML and NP tasks. All datasets, code, and evaluation tools are open-sourced to
promote further research in advancing LLM-driven optimization and iterative
reasoning. Project page:
\href{https://github.com/OliverLeeXZ/OPT-BENCH}{https://github.com/OliverLeeXZ/OPT-BENCH}.

</details>


### [113] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
*Yu Zhang, Yang Hu, De Wang*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种结合链式思维（CoT）推理和模型上下文协议（MCP）的框架，以提高大语言模型在时空行为模拟方面的能力。在上海陆家嘴地区的实验验证了该框架的有效性，并展示了其在并行处理上的效率提升。


<details>
  <summary>更多</summary>
  
**动机:** 人类时空行为的模拟对于城市规划研究至关重要，但传统的基于规则和统计的方法存在计算成本高、泛化能力有限和可扩展性差的问题。而大型语言模型（LLMs）虽然作为‘世界模拟器’展现出潜力，但在时空推理方面面临空间认知有限、缺乏物理约束理解以及群体同质化倾向等挑战。

**方法:** 本文引入了一个将链式思维（CoT）推理与模型上下文协议（MCP）相结合的框架，旨在增强LLMs模拟符合验证数据模式的时空行为的能力。方法论部分结合了通过五阶段认知框架的人类式渐进推理，以及通过六个专门的MCP工具类别进行的全面数据处理：时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估。

**结果:** 在上海陆家嘴区进行的实验中，通过对1000个生成样本的分析，结果表明生成的数据与真实的移动信号数据高度相似，不同基础模型的质量评分达到了7.86至8.36之间。此外，并行处理实验显示了效率的提升，当进程数从2增加到12时，每样本生成时间从1.30分钟减少到了0.17分钟。

**结论:** 本工作为城市行为建模整合了CoT推理与MCP，推进了LLMs在城市计算中的应用，并提供了一种实用的方法来生成合成移动数据。该框架为智慧城市规划、交通预测及参与式城市设计应用奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Study+on+Individual+Spatiotemporal+Activity+Generation+Method+Using+MCP-Enhanced+Chain-of-Thought+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10853，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10853&send_immediately=true&force_search=false)

**原文摘要:** Human spatiotemporal behavior simulation is critical for urban planning
research, yet traditional rule-based and statistical approaches suffer from
high computational costs, limited generalizability, and poor scalability. While
large language models (LLMs) show promise as "world simulators," they face
challenges in spatiotemporal reasoning including limited spatial cognition,
lack of physical constraint understanding, and group homogenization tendencies.
This paper introduces a framework integrating chain-of-thought (CoT) reasoning
with Model Context Protocol (MCP) to enhance LLMs' capability in simulating
spatiotemporal behaviors that correspond with validation data patterns. The
methodology combines human-like progressive reasoning through a five-stage
cognitive framework with comprehensive data processing via six specialized MCP
tool categories: temporal management, spatial navigation, environmental
perception, personal memory, social collaboration, and experience evaluation.
Experiments in Shanghai's Lujiazui district validate the framework's
effectiveness across 1,000 generated samples. Results demonstrate high
similarity with real mobile signaling data, achieving generation quality scores
of 7.86 to 8.36 across different base models. Parallel processing experiments
show efficiency improvements, with generation times decreasing from 1.30 to
0.17 minutes per sample when scaling from 2 to 12 processes. This work
contributes to integrating CoT reasoning with MCP for urban behavior modeling,
advancing LLMs applications in urban computing and providing a practical
approach for synthetic mobility data generation. The framework offers a
foundation for smart city planning, transportation forecasting, and
participatory urban design applications.

</details>


### [114] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
*Daniel Borrajo, Giuseppe Canonaco, Tomás de la Rosa, Alfredo Garrachón, Sriram Gopalakrishnan, Simerjot Kaur, Marianela Morales, Sunandita Patra, Alberto Pozanco, Keshav Ramani, Charese Smiley, Pietro Totis, Manuela Veloso*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为GenPlanX的系统，该系统将大型语言模型与经典AI规划引擎相结合，以理解和执行自然语言描述的规划任务，并通过办公相关任务展示了其有效性和提升工作效率的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的AI规划技术在处理复杂的任务序列时表现出色，但它们无法理解用自然语言表述的规划任务。而大型语言模型（LLMs）在人机交互中引入了新的能力，特别是在解释人类意图方面。

**方法:** 研究者们提出了GenPlanX系统，它集成了大型语言模型来解析自然语言中的规划任务，并与经典的AI规划引擎相结合，同时配备了一个执行和监控框架。

**结果:** GenPlanX被证明能够有效地帮助用户完成办公相关的任务，显示了通过无缝的人工智能协作简化工作流程和提高生产力的潜力。

**结论:** GenPlanX作为结合了自然语言处理能力和传统AI规划技术的系统，展现了其在促进更加直观和高效的人机合作方面的价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GenPlanX.+Generation+of+Plans+and+Execution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10897，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10897&send_immediately=true&force_search=false)

**原文摘要:** Classical AI Planning techniques generate sequences of actions for complex
tasks. However, they lack the ability to understand planning tasks when
provided using natural language. The advent of Large Language Models (LLMs) has
introduced novel capabilities in human-computer interaction. In the context of
planning tasks, LLMs have shown to be particularly good in interpreting human
intents among other uses. This paper introduces GenPlanX that integrates LLMs
for natural language-based description of planning tasks, with a classical AI
planning engine, alongside an execution and monitoring framework. We
demonstrate the efficacy of GenPlanX in assisting users with office-related
tasks, highlighting its potential to streamline workflows and enhance
productivity through seamless human-AI collaboration.

</details>


### [115] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
*Fei Lin, Ziyang Gong, Cong Wang, Yonglin Tian, Tengchao Zhang, Xue Yang, Gen Luo, Fei-Yue Wang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了ToxiMol，一个专注于分子毒性修复的基准任务，以及ToxiEval评估框架，并对近30种主流通用多模态大语言模型进行了系统性评估。结果显示，尽管这些模型在该任务上仍面临挑战，但它们开始展示出理解毒性、遵守语义约束和结构感知分子编辑方面的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管分子设计和性质预测取得了进展，但是分子毒性修复的任务尚未被系统地定义或基准化。为了解决这一问题，作者们提出了ToxiMol。

**方法:** 构建了一个标准化的数据集，涵盖了11个主要任务和560个代表性的有毒分子；设计了一个具有机制意识和任务适应能力的提示注解流程；提出了ToxiEval自动评估框架来评价修复成功度。

**结果:** 实验结果表明，虽然当前的多模态大语言模型在这个任务上还面临着重大挑战，但它们已经开始展现出在毒性理解、语义约束遵循和结构感知分子编辑方面的能力。

**结论:** ToxiMol 和 ToxiEval 为分子毒性修复提供了一个新的基准任务和评估工具，揭示了现有模型在此任务上的局限性和潜在改进方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Breaking+Bad+Molecules%3A+Are+MLLMs+Ready+for+Structure-Level+Molecular+Detoxification%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10912&send_immediately=true&force_search=false)

**原文摘要:** Toxicity remains a leading cause of early-stage drug development failure.
Despite advances in molecular design and property prediction, the task of
molecular toxicity repair - generating structurally valid molecular
alternatives with reduced toxicity - has not yet been systematically defined or
benchmarked. To fill this gap, we introduce ToxiMol, the first benchmark task
for general-purpose Multimodal Large Language Models (MLLMs) focused on
molecular toxicity repair. We construct a standardized dataset covering 11
primary tasks and 560 representative toxic molecules spanning diverse
mechanisms and granularities. We design a prompt annotation pipeline with
mechanism-aware and task-adaptive capabilities, informed by expert
toxicological knowledge. In parallel, we propose an automated evaluation
framework, ToxiEval, which integrates toxicity endpoint prediction, synthetic
accessibility, drug-likeness, and structural similarity into a high-throughput
evaluation chain for repair success. We systematically assess nearly 30
mainstream general-purpose MLLMs and design multiple ablation studies to
analyze key factors such as evaluation criteria, candidate diversity, and
failure attribution. Experimental results show that although current MLLMs
still face significant challenges on this task, they begin to demonstrate
promising capabilities in toxicity understanding, semantic constraint
adherence, and structure-aware molecule editing.

</details>


### [116] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
*Rulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer*

**主要类别:** cs.AI

**AI概要:** 研究发现，带有可验证奖励的强化学习（RLVR）可以在某些模型中激发强大的数学推理能力，即使奖励信号与正确答案几乎没有关联或负相关。这种现象在Qwen2.5-Math-7B模型上表现明显，但不适用于其他模型家族如Llama3或OLMo2。此外，Qwen2.5-Math模型经过RLVR后更倾向于使用代码思维进行推理。


<details>
  <summary>更多</summary>
  
**动机:** 探索不同奖励信号下，强化学习如何影响模型的数学推理能力，并特别关注了当奖励信号与正确解答无关时的影响。

**方法:** 采用了一种称为强化学习与可验证奖励（RLVR）的方法，在多个模型上测试了不同类型的奖励（包括随机奖励、格式奖励、错误标签等）对数学推理任务性能的影响。

**结果:** 对于Qwen2.5-Math-7B模型，即便使用完全无关甚至是误导性的奖励，通过RLVR也能显著提高其在MATH-500上的表现；而同样的方法对于其他一些模型家族则效果不佳。

**结论:** 尽管缺乏有用的奖励信号，RLVR似乎能够揭示出预训练期间学到的有效推理表示。未来的研究应当考虑在更多样化的模型上验证RLVR的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spurious+Rewards%3A+Rethinking+Training+Signals+in+RLVR，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10947，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10947&send_immediately=true&force_search=false)

**原文摘要:** We show that reinforcement learning with verifiable rewards (RLVR) can elicit
strong mathematical reasoning in certain models even with spurious rewards that
have little, no, or even negative correlation with the correct answer. For
example, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolute
points by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrect
label), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the
29.1% gained with ground truth rewards. However, the spurious rewards that work
for Qwen often fail to yield gains with other model families like Llama3 or
OLMo2. In particular, we find code reasoning -- thinking in code without actual
code execution -- to be a distinctive Qwen2.5-Math behavior that becomes
significantly more frequent after RLVR, from 65% to over 90%, even with
spurious rewards. Overall, we hypothesize that, given the lack of useful reward
signal, RLVR must somehow be surfacing useful reasoning representations learned
during pretraining, although the exact mechanism remains a topic for future
work. We suggest that future RLVR research should possibly be validated on
diverse models rather than a single de facto choice, as we show that it is easy
to get significant performance gains on Qwen models even with completely
spurious reward signals.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [117] [Fundamental Limits of Learning High-dimensional Simplices in Noisy Regimes](https://arxiv.org/abs/2506.10101)
*Seyed Amir Hossein Saberi, Amir Najafi, Abolfazl Motahari, Babak H. khalaj*

**主要类别:** stat.ML

**AI概要:** 本文研究了从带噪声的数据中学习高维单纯形的样本复杂度边界，证明了当信噪比足够高时，含噪声情况下的样本复杂度与无噪声情况下一致，并引入了一种基于傅里叶的新方法来恢复分布。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在为在有噪声的情况下从高维空间中学习单纯形提供理论基础，通过设定样本复杂度的上下界，从而理解在不同噪声水平下准确估计单纯形所需的最小样本数。

**方法:** 文章使用了样本压缩技术以及一种新的基于傅里叶的方法来处理噪声数据并恢复出真实的分布。

**结果:** 研究表明，在信噪比足够高的条件下，含噪声情况下的学习复杂度与无噪声情况相匹配。此外，对于特定距离内的单纯形估计，给出了信息论上的下界。

**结论:** 本文解决了在一定信噪比条件下，含噪声和无噪声情况下学习复杂度一致性的问题，并提出了一个可能适用于更广泛场景中的新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fundamental+Limits+of+Learning+High-dimensional+Simplices+in+Noisy+Regimes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10101，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10101&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we establish sample complexity bounds for learning
high-dimensional simplices in $\mathbb{R}^K$ from noisy data. Specifically, we
consider $n$ i.i.d. samples uniformly drawn from an unknown simplex in
$\mathbb{R}^K$, each corrupted by additive Gaussian noise of unknown variance.
We prove an algorithm exists that, with high probability, outputs a simplex
within $\ell_2$ or total variation (TV) distance at most $\varepsilon$ from the
true simplex, provided $n \ge (K^2/\varepsilon^2)
e^{\mathcal{O}(K/\mathrm{SNR}^2)}$, where $\mathrm{SNR}$ is the signal-to-noise
ratio. Extending our prior work~\citep{saberi2023sample}, we derive new
information-theoretic lower bounds, showing that simplex estimation within TV
distance $\varepsilon$ requires at least $n \ge \Omega(K^3
\sigma^2/\varepsilon^2 + K/\varepsilon)$ samples, where $\sigma^2$ denotes the
noise variance. In the noiseless scenario, our lower bound $n \ge
\Omega(K/\varepsilon)$ matches known upper bounds up to constant factors. We
resolve an open question by demonstrating that when $\mathrm{SNR} \ge
\Omega(K^{1/2})$, noisy-case complexity aligns with the noiseless case. Our
analysis leverages sample compression techniques (Ashtiani et al., 2018) and
introduces a novel Fourier-based method for recovering distributions from noisy
observations, potentially applicable beyond simplex learning.

</details>


### [118] [Momentum Multi-Marginal Schrödinger Bridge Matching](https://arxiv.org/abs/2506.10168)
*Panagiotis Theodoropoulos, Augustinos D. Saravanos, Evangelos A. Theodorou, Guan-Horng Liu*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种名为3MSBM的新匹配框架，它通过将动力学提升到相空间，并推广随机桥以在多个点上进行条件化，从而为满足多个位置约束的随机系统学习平滑的测度值样条。实验表明，该方法在捕捉具有时间依赖性的复杂动态方面优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前的方法论依赖于相邻快照之间的成对插值，这限制了它们捕获长距离时间依赖关系的能力，并可能影响推断轨迹的一致性。

**方法:** 提出了Momentum Multi-Marginal Schrödinger Bridge Matching (3MSBM)，一种新的匹配框架，它能够学习满足多个位置约束的随机系统的平滑测度值样条。通过将动力学提升至相空间，并且泛化随机桥来基于数个点进行条件化，形成一个多边际条件下的随机最优控制问题。接着，通过最小化一个变分目标函数，在固定多边际条件下由桥诱导的路径后，学习基础的动力学模型。

**结果:** 广泛的实验证明了与现有方法相比，3MSBM在捕捉具有时间依赖性的复杂动态方面表现更优。

**结论:** 3MSBM作为一种匹配方法，通过在整个训练过程中保持中间边际的学习传输映射，显著提高了收敛性和可扩展性，并为多边际设置中的匹配框架训练开辟了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Momentum+Multi-Marginal+Schr%C3%B6dinger+Bridge+Matching，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10168，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10168&send_immediately=true&force_search=false)

**原文摘要:** Understanding complex systems by inferring trajectories from sparse sample
snapshots is a fundamental challenge in a wide range of domains, e.g.,
single-cell biology, meteorology, and economics. Despite advancements in Bridge
and Flow matching frameworks, current methodologies rely on pairwise
interpolation between adjacent snapshots. This hinders their ability to capture
long-range temporal dependencies and potentially affects the coherence of the
inferred trajectories. To address these issues, we introduce \textbf{Momentum
Multi-Marginal Schr\"odinger Bridge Matching (3MSBM)}, a novel matching
framework that learns smooth measure-valued splines for stochastic systems that
satisfy multiple positional constraints. This is achieved by lifting the
dynamics to phase space and generalizing stochastic bridges to be conditioned
on several points, forming a multi-marginal conditional stochastic optimal
control problem. The underlying dynamics are then learned by minimizing a
variational objective, having fixed the path induced by the multi-marginal
conditional bridge. As a matching approach, 3MSBM learns transport maps that
preserve intermediate marginals throughout training, significantly improving
convergence and scalability. Extensive experimentation in a series of
real-world applications validates the superior performance of 3MSBM compared to
existing methods in capturing complex dynamics with temporal dependencies,
opening new avenues for training matching frameworks in multi-marginal
settings.

</details>


### [119] [Distributionally-Constrained Adversaries in Online Learning](https://arxiv.org/abs/2506.10293)
*Moïse Blanchard, Samory Kpotufe*

**主要类别:** stat.ML

**AI概要:** 本文研究了在有分布约束的对手框架下，介于完全随机和完全对抗之间的在线学习环境，并确定了哪些分布类是可以学习的。结果表明对于一些自然函数类，如线性分类器，可以在没有先验知识的情况下实现学习。


<details>
  <summary>更多</summary>
  
**动机:** 理解在线学习中从对抗到随机设置的连续体引起了广泛兴趣，作者考虑了一个更为通用和灵活的框架——具有分布约束的对手，以期对介于完全随机和完全对抗之间的学习环境有一个细致的理解。

**方法:** 通过定义一个允许对手在某些受限制的分布类别中选择实例的框架，分析了针对无意识和自适应对手的学习可能性，并且探讨了函数类与对手分布约束之间相互作用的类型。

**结果:** 为可以学习的分布类提供了特征描述，并且证明了几种自然函数类（例如线性分类器）能够在不知道分布类的前提下实现学习。

**结论:** 该研究扩展了已知平滑设置下的可学习性，并揭示了无需事先了解分布类别的情况下，学习者能够同时与任何受约束的对手竞争。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distributionally-Constrained+Adversaries+in+Online+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10293，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10293&send_immediately=true&force_search=false)

**原文摘要:** There has been much recent interest in understanding the continuum from
adversarial to stochastic settings in online learning, with various frameworks
including smoothed settings proposed to bridge this gap. We consider the more
general and flexible framework of distributionally constrained adversaries in
which instances are drawn from distributions chosen by an adversary within some
constrained distribution class [RST11]. Compared to smoothed analysis, we
consider general distributional classes which allows for a fine-grained
understanding of learning settings between fully stochastic and fully
adversarial for which a learner can achieve non-trivial regret. We give a
characterization for which distribution classes are learnable in this context
against both oblivious and adaptive adversaries, providing insights into the
types of interplay between the function class and distributional constraints on
adversaries that enable learnability. In particular, our results recover and
generalize learnability for known smoothed settings. Further, we show that for
several natural function classes including linear classifiers, learning can be
achieved without any prior knowledge of the distribution class -- in other
words, a learner can simultaneously compete against any constrained adversary
within learnable distribution classes.

</details>


### [120] [Measuring Semantic Information Production in Generative Diffusion Models](https://arxiv.org/abs/2506.10433)
*Florian Handke, Félix Koulischer, Gabriel Raya, Luca Ambrogioni*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种基于信息论的方法，用于测量在生成过程中何时做出类别语义决策。通过在线公式估计最优贝叶斯分类器的条件熵，并利用条件熵的时间导数确定噪声状态和类别标签之间信息传递量最大的时间间隔。实验结果表明，在扩散过程的中间阶段，语义信息传递达到最高，而在最后阶段消失；同时发现不同类别的熵率曲线存在显著差异，表明不同的'语义决策'发生在不同的中间时间点。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索生成图像过程中语义与结构特征出现的具体时间点，这与磁性材料等物理相变现象相关联。理解这一过程对于优化生成模型及提高生成图像质量具有重要意义。

**方法:** 采用一种通用的信息论方法来度量生成过程中何时做出类别语义层面的“决定”。该方法依赖于使用一个在线公式计算最优贝叶斯分类器，据此估算给定噪声状态下类别标签的条件熵。进一步地，通过分析条件熵随时间变化的导数，识别出噪声状态与类别标签间信息传输量达到峰值的时间段。

**结果:** 实验分别在一维高斯混合模型以及CIFAR10数据集上训练的DDPM（Denoising Diffusion Probabilistic Models）模型上进行了验证。结果显示，在扩散过程的中期阶段，语义信息的转移最为显著，而到了最终阶段则趋于消失。此外，观察到不同类别的熵率分布存在明显差异，意味着各类别对应的‘语义决策’发生在各自特定的中间时刻。

**结论:** 本研究表明，通过所提出的信息论框架能够有效捕捉生成模型中语义信息发展的关键时期，为理解并改进图像生成算法提供了新的视角。特别是关于不同类别可能在不同时间点形成其独特语义内容的发现，为未来工作指明了方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+Semantic+Information+Production+in+Generative+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10433&send_immediately=true&force_search=false)

**原文摘要:** It is well known that semantic and structural features of the generated
images emerge at different times during the reverse dynamics of diffusion, a
phenomenon that has been connected to physical phase transitions in magnets and
other materials. In this paper, we introduce a general information-theoretic
approach to measure when these class-semantic "decisions" are made during the
generative process. By using an online formula for the optimal Bayesian
classifier, we estimate the conditional entropy of the class label given the
noisy state. We then determine the time intervals corresponding to the highest
information transfer between noisy states and class labels using the time
derivative of the conditional entropy. We demonstrate our method on
one-dimensional Gaussian mixture models and on DDPM models trained on the
CIFAR10 dataset. As expected, we find that the semantic information transfer is
highest in the intermediate stages of diffusion while vanishing during the
final stages. However, we found sizable differences between the entropy rate
profiles of different classes, suggesting that different "semantic decisions"
are located at different intermediate times.

</details>


### [121] [Box-Constrained Softmax Function and Its Application for Post-Hoc Calibration](https://arxiv.org/abs/2506.10572)
*Kyohei Atarashi, Satoshi Oyama, Hiromi Arai, Hisashi Kashima*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种新的Softmax函数变体，称为box-constrained softmax (BCSoftmax)，它能够对输出概率施加硬性边界约束，并且基于此开发了两种后校准方法来提高模型预测的可靠性和信任度。实验结果表明该方法在多个数据集上提高了校准指标。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Softmax函数虽然可以通过温度参数进行软控制，但无法强制执行如盒约束等硬性限制，这对于某些需要可靠和可信模型的应用来说至关重要。

**方法:** 提出了box-constrained softmax (BCSoftmax) 函数，这是一种新的Softmax泛化形式，可以显式地对输出概率实施下限和上限约束。此外，还为此函数开发了一个精确且高效的计算算法，并基于BCSoftmax引入了两种后校准方法，用以缓解模型预测时的不自信和过度自信问题。

**结果:** 通过TinyImageNet、CIFAR-100和20NewsGroups数据集上的实验验证了所提方法的有效性，在校准度量方面取得了改进。

**结论:** BCSoftmax及其相关的后校准方法提供了一种有效途径来增强模型预测的概率区间控制，从而提高了下游决策任务中的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Box-Constrained+Softmax+Function+and+Its+Application+for+Post-Hoc+Calibration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10572，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10572&send_immediately=true&force_search=false)

**原文摘要:** Controlling the output probabilities of softmax-based models is a common
problem in modern machine learning. Although the $\mathrm{Softmax}$ function
provides soft control via its temperature parameter, it lacks the ability to
enforce hard constraints, such as box constraints, on output probabilities,
which can be critical in certain applications requiring reliable and
trustworthy models. In this work, we propose the box-constrained softmax
($\mathrm{BCSoftmax}$) function, a novel generalization of the
$\mathrm{Softmax}$ function that explicitly enforces lower and upper bounds on
output probabilities. While $\mathrm{BCSoftmax}$ is formulated as the solution
to a box-constrained optimization problem, we develop an exact and efficient
computation algorithm for $\mathrm{BCSoftmax}$. As a key application, we
introduce two post-hoc calibration methods based on $\mathrm{BCSoftmax}$. The
proposed methods mitigate underconfidence and overconfidence in predictive
models by learning the lower and upper bounds of the output probabilities or
logits after model training, thereby enhancing reliability in downstream
decision-making tasks. We demonstrate the effectiveness of our methods
experimentally using the TinyImageNet, CIFAR-100, and 20NewsGroups datasets,
achieving improvements in calibration metrics.

</details>


### [122] [Logarithmic Smoothing for Adaptive PAC-Bayesian Off-Policy Learning](https://arxiv.org/abs/2506.10664)
*Maxime Haddouche, Otmane Sakhi*

**主要类别:** stat.ML

**AI概要:** 本文研究了自适应离策略学习，扩展了PAC-贝叶斯学习框架以支持迭代优化策略，并在多种场景下展示了其优于静态设置下的现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 本文旨在解决更实用和灵活的自适应离策略学习问题，通过迭代地改进和重新部署策略来收集更高质量的数据。

**方法:** 利用在线PAC-贝叶斯理论工具，将带有对数平滑（LS）的PAC-贝叶斯学习框架扩展到自适应情形。此外，通过对LS估计量进行有原则性的调整，使其自然适应多轮部署并获得更快的收敛速度。

**结果:** 所提出的方法在静态环境下与领先的离线方法性能相当，在允许中间策略部署的情况下则显著优于这些方法。实证评估表明，该方法在不同情况下均表现出色。

**结论:** 自适应数据收集结合PAC-贝叶斯公式化方法为离策略学习提供了一种有效途径，能够在允许策略迭代更新的情形下实现更快的学习过程和更好的结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Logarithmic+Smoothing+for+Adaptive+PAC-Bayesian+Off-Policy+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10664，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10664&send_immediately=true&force_search=false)

**原文摘要:** Off-policy learning serves as the primary framework for learning optimal
policies from logged interactions collected under a static behavior policy. In
this work, we investigate the more practical and flexible setting of adaptive
off-policy learning, where policies are iteratively refined and re-deployed to
collect higher-quality data. Building on the success of PAC-Bayesian learning
with Logarithmic Smoothing (LS) in static settings, we extend this framework to
the adaptive scenario using tools from online PAC-Bayesian theory. Furthermore,
we demonstrate that a principled adjustment to the LS estimator naturally
accommodates multiple rounds of deployment and yields faster convergence rates
under mild conditions. Our method matches the performance of leading offline
approaches in static settings, and significantly outperforms them when
intermediate policy deployments are allowed. Empirical evaluations across
diverse scenarios highlight both the advantages of adaptive data collection and
the strength of the PAC-Bayesian formulation.

</details>


### [123] [Practical Improvements of A/B Testing with Off-Policy Estimation](https://arxiv.org/abs/2506.10677)
*Sakhi Otmane, Gilotte Alexandre, Rohde David*

**主要类别:** stat.ML

**AI概要:** 本文提出了一个方差更小的无偏离策略估计器族，用于改进A/B测试中常用的均值差异估计器，并确定了该族中具有最低方差的估计器，理论分析和实验结果验证了所提方法的有效性和实用性。


<details>
  <summary>更多</summary>
  
**动机:** A/B测试被广泛用来评估新决策系统相较于基准系统的潜在改进，但常用的均值差异估计器虽然无偏，却可以进一步改进以降低其方差。

**方法:** 引入了一个无偏离策略估计器族，这些估计器比标准方法具有更低的方差；在提出的估计器族中确定了方差最小的估计器。

**结果:** 所提出的估计器简单且当两个测试系统表现出相似性时能显著减少方差；理论分析与实验结果都证明了所提方法的有效性和实用性。

**结论:** 通过使用新的无偏离策略估计器，可以提高A/B测试中对新决策系统性能提升评估的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Practical+Improvements+of+A%2FB+Testing+with+Off-Policy+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10677，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10677&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of A/B testing, a widely used protocol for evaluating
the potential improvement achieved by a new decision system compared to a
baseline. This protocol segments the population into two subgroups, each
exposed to a version of the system and estimates the improvement as the
difference between the measured effects. In this work, we demonstrate that the
commonly used difference-in-means estimator, while unbiased, can be improved.
We introduce a family of unbiased off-policy estimators that achieves lower
variance than the standard approach. Among this family, we identify the
estimator with the lowest variance. The resulting estimator is simple, and
offers substantial variance reduction when the two tested systems exhibit
similarities. Our theoretical analysis and experimental results validate the
effectiveness and practicality of the proposed method.

</details>


### [124] [Demystifying Spectral Feature Learning for Instrumental Variable Regression](https://arxiv.org/abs/2506.10899)
*Dimitri Meunier, Antoine Moulin, Jakub Wornbard, Vladimir R. Kostic, Arthur Gretton*

**主要类别:** stat.ML

**AI概要:** 本文探讨了在存在隐藏混淆变量的情况下，使用非参数工具变量回归估计因果效应的问题。通过分析基于谱特征的两阶段最小二quares估计器的一般化误差界限，得出了方法表现好坏的关键因素，并通过合成实验验证了这些发现。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决当存在未观测到的混淆变量时，如何有效地估计因果效应的问题。文章特别关注的是利用非参数工具变量回归来克服这一挑战。

**方法:** 采用了基于谱特征的方法，即学习横跨治疗和工具变量之间算子的顶部特征子空间的特征。接着，推导出一个基于谱特征的两阶段最小二乘估计器的一般化误差界限，并分析了该方法性能良好或不佳的情景。

**结果:** 结果表明，方法的表现取决于两个关键因素：谱对齐的程度以及算子特征值衰减的速度。这导致了不同情景下方法表现的一个清晰分类。

**结论:** 结论是，在良好的情况下，如果谱对齐较强且算子的特征值缓慢衰减，则方法最优；而在不良情况下，即便谱对齐较强但特征值快速衰减（意味着工具变量较弱），需要更多样本来有效学习特征；最后，在最差的情况下，即使特征值特性良好，弱谱对齐也会导致方法失败。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Demystifying+Spectral+Feature+Learning+for+Instrumental+Variable+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10899&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of causal effect estimation in the presence of hidden
confounders, using nonparametric instrumental variable (IV) regression. A
leading strategy employs spectral features - that is, learned features spanning
the top eigensubspaces of the operator linking treatments to instruments. We
derive a generalization error bound for a two-stage least squares estimator
based on spectral features, and gain insights into the method's performance and
failure modes. We show that performance depends on two key factors, leading to
a clear taxonomy of outcomes. In a good scenario, the approach is optimal. This
occurs with strong spectral alignment, meaning the structural function is
well-represented by the top eigenfunctions of the conditional operator, coupled
with this operator's slow eigenvalue decay, indicating a strong instrument.
Performance degrades in a bad scenario: spectral alignment remains strong, but
rapid eigenvalue decay (indicating a weaker instrument) demands significantly
more samples for effective feature learning. Finally, in the ugly scenario,
weak spectral alignment causes the method to fail, regardless of the
eigenvalues' characteristics. Our synthetic experiments empirically validate
this taxonomy.

</details>


### [125] [Probably Approximately Correct Labels](https://arxiv.org/abs/2506.10908)
*Emmanuel J. Candès, Andrew Ilyas, Tijana Zrnic*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种方法，通过结合预训练模型的AI预测和专家标签来更经济地构建带标签的数据集，并在文本、图像以及蛋白质折叠分析中展示了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 获取高质量的标注数据集往往成本高昂，需要大量的人工标注或昂贵的实验。为了解决这个问题，作者提出了一个能够利用预训练模型的AI预测来补充'专家'标签的方法，从而以更低的成本构建标注数据集。

**方法:** 该方法利用预训练模型产生的大概率近似正确的标签，保证了总体上标签错误率较低。这种方法使得使用现代AI模型进行严格而高效的数据集整理成为可能。

**结果:** 研究者们通过几个案例展示了方法的有效性：使用大型语言模型进行文本注释，利用预训练视觉模型进行图像标记，以及运用AlphaFold进行蛋白质折叠分析。

**结论:** 该文提出的方法能够有效降低构建高质量标注数据集的成本，同时保持较高的准确性，适用于多种类型的数据集创建任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probably+Approximately+Correct+Labels，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10908&send_immediately=true&force_search=false)

**原文摘要:** Obtaining high-quality labeled datasets is often costly, requiring either
extensive human annotation or expensive experiments. We propose a method that
supplements such "expert" labels with AI predictions from pre-trained models to
construct labeled datasets more cost-effectively. Our approach results in
probably approximately correct labels: with high probability, the overall
labeling error is small. This solution enables rigorous yet efficient dataset
curation using modern AI models. We demonstrate the benefits of the methodology
through text annotation with large language models, image labeling with
pre-trained vision models, and protein folding analysis with AlphaFold.

</details>


### [126] [What Exactly Does Guidance Do in Masked Discrete Diffusion Models](https://arxiv.org/abs/2506.10971)
*He Ye, Rojas Kevin, Tao Molei*

**主要类别:** stat.ML

**AI概要:** 本文研究了带有无分类器指导的掩码离散扩散模型，并推导出指导反向动态的显式解，分析了指导如何影响采样行为。研究发现指导在1D和2D中表现出量化的不同行为，并且对于较大的指导强度w，总变异的衰减速率与w成双指数关系。实验支持了理论分析，展示了指导对几何效应及收敛性的影响。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在理解带无分类器指导的掩码离散扩散模型中的指导机制是如何精确地影响采样行为的。

**方法:** 通过假设没有评分误差或离散化误差，推导出指导反向动态过程的显式解，并分析了指导强度对特定类别的样本分布的影响。

**结果:** 研究表明，在1D和2D情况下，指导的效果存在定量上的差异；对于大的指导强度w，总变异的衰减遵循一个关于w的双指数规律。

**结论:** 无分类器指导不仅能够塑造输出分布，而且还能控制采样轨迹的动力学。实验结果证实了几何效应以及指导对收敛的影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Exactly+Does+Guidance+Do+in+Masked+Discrete+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10971，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10971&send_immediately=true&force_search=false)

**原文摘要:** We study masked discrete diffusion models with classifier-free guidance
(CFG). Assuming no score error nor discretization error, we derive an explicit
solution to the guided reverse dynamics, so that how guidance influences the
sampling behavior can be precisely characterized. When the full data
distribution is a mixture over classes and the goal is to sample from a
specific class, guidance amplifies class-specific regions while suppresses
regions shared with other classes. This effect depends on the guidance strength
$w$ and induces distinct covariance structures in the sampled distribution.
Notably, we observe quantitatively different behaviors in $1$D and $2$D. We
also show that for large $w$, the decay rate of the total variation
($\mathrm{TV}$) along the reverse dynamics is double-exponential in $w$ for
both $1$D and $2$D. These findings highlight the role of guidance, not just in
shaping the output distribution, but also in controlling the dynamics of the
sampling trajectory. Our theoretical analysis is supported by experiments that
illustrate the geometric effects of guidance and its impact on convergence.

</details>
