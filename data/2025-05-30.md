<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 163]
- [cs.AI](#cs.AI) [总数: 37]
- [stat.ML](#stat.ML) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Private Rate-Constrained Optimization with Applications to Fair Learning](https://arxiv.org/abs/2505.22703)
*Mohammad Yaghini, Tudor Cebere, Michael Menart, Aurélien Bellet, Nicolas Papernot*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为RaCO-DP的新方法，用于解决在差分隐私（DP）下的模型优化问题。该方法解决了约束条件导致的样本间依赖性，并通过私有化直方图估计来控制额外的隐私成本。理论分析和实验结果表明，RaCO-DP在公平性和效用的权衡上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 许多可信机器学习的问题可以被表述为在特定边际预测率约束下的模型误差最小化问题，例如群体公平性约束（人口统计学平等、机会均等）。然而，在差分隐私环境下，标准的隐私优化技术（如DP-SGD）无法直接处理这些约束，因为约束引入了样本间的依赖性，破坏了损失函数的可分解性。因此需要一种新的方法来解决这一问题。

**方法:** 作者提出了RaCO-DP方法，这是一种基于随机梯度下降-上升（SGDA）算法的差分隐私变体。RaCO-DP通过解决带有约束的拉格朗日公式来处理模型优化问题，并将额外的隐私成本归结为对每个优化步骤中的小批量数据进行私有化直方图估计。

**结果:** 理论上，作者通过利用对偶参数的线性结构，证明了RaCO-DP算法的收敛性。实证结果表明，在群体公平性约束的学习任务中，RaCO-DP方法在公平性和效用的权衡上显著优于现有的隐私学习方法。

**结论:** RaCO-DP是一种有效的差分隐私优化方法，能够在满足群体公平性约束的同时保持模型性能。它不仅解决了样本间依赖性的问题，还通过理论分析验证了其收敛性，并通过实验证明了其优越性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Private+Rate-Constrained+Optimization+with+Applications+to+Fair+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22703&send_immediately=true&force_search=false)

**原文摘要:** Many problems in trustworthy ML can be formulated as minimization of the
model error under constraints on the prediction rates of the model for
suitably-chosen marginals, including most group fairness constraints
(demographic parity, equality of odds, etc.). In this work, we study such
constrained minimization problems under differential privacy (DP). Standard DP
optimization techniques like DP-SGD rely on the loss function's decomposability
into per-sample contributions. However, rate constraints introduce inter-sample
dependencies, violating the decomposability requirement. To address this, we
develop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)
algorithm which solves the Lagrangian formulation of rate constraint problems.
We demonstrate that the additional privacy cost of incorporating these
constraints reduces to privately estimating a histogram over the mini-batch at
each optimization step. We prove the convergence of our algorithm through a
novel analysis of SGDA that leverages the linear structure of the dual
parameter. Finally, empirical results on learning under group fairness
constraints demonstrate that our method Pareto-dominates existing private
learning approaches in fairness-utility trade-offs.

</details>


### [2] [Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study](https://arxiv.org/abs/2505.22841)
*Franck Gabriel, François Ged, Maria Han Veiga, Emmanuel Schertzer*

**主要类别:** cs.LG

**概要:** 扩散模型尽管在高保真生成采样中设立了基准，但可能因分数过拟合而导致记忆问题。本文通过引入核平滑经验分数来减少噪声方差，并分析其偏差-方差权衡，从而防止记忆并增强泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 扩散模型虽然性能优越，但可能存在对训练数据的记忆问题，这限制了其实际应用和泛化能力。

**方法:** 将经验分数视为真实分数的噪声版本，并分析其协方差矩阵；引入核平滑经验分数以减少噪声方差；推导真实分布与修改后的反向SDE生成分布之间的Kullback-Leibler散度的渐近界；提出正向扩散的谱分解以改善方差控制；将反向扩散重新表述为梯度下降过程，朝着Log-Exponential Double-Kernel Density Estimator (LED-KDE)漂移。

**结果:** 理论分析表明，分数正则化等效于增加训练数据集的大小，有助于防止记忆问题。数值实验在合成数据和MNIST数据集上验证了该方法的有效性。

**结论:** 核平滑经验分数可以有效减少扩散模型的记忆效应，同时增强其泛化能力。即使没有学习过程的简单正则化也能够显著改善模型表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Kernel-Smoothed+Scores+for+Denoising+Diffusion%3A+A+Bias-Variance+Study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22841，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22841&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models now set the benchmark in high-fidelity generative sampling,
yet they can, in principle, be prone to memorization. In this case, their
learned score overfits the finite dataset so that the reverse-time SDE samples
are mostly training points. In this paper, we interpret the empirical score as
a noisy version of the true score and show that its covariance matrix is
asymptotically a re-weighted data PCA. In large dimension, the small time limit
makes the noise variance blow up while simultaneously reducing spatial
correlation. To reduce this variance, we introduce a kernel-smoothed empirical
score and analyze its bias-variance trade-off. We derive asymptotic bounds on
the Kullback-Leibler divergence between the true distribution and the one
generated by the modified reverse SDE. Regularization on the score has the same
effect as increasing the size of the training dataset, and thus helps prevent
memorization. A spectral decomposition of the forward diffusion suggests better
variance control under some regularity conditions of the true data
distribution. Reverse diffusion with kernel-smoothed empirical score can be
reformulated as a gradient descent drifted toward a Log-Exponential
Double-Kernel Density Estimator (LED-KDE). This perspective highlights two
regularization mechanisms taking place in denoising diffusions: an initial
Gaussian kernel first diffuses mass isotropically in the ambient space, while a
second kernel applied in score space concentrates and spreads that mass along
the data manifold. Hence, even a straightforward regularization-without any
learning-already mitigates memorization and enhances generalization.
Numerically, we illustrate our results with several experiments on synthetic
and MNIST datasets.

</details>


### [3] [Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints](https://arxiv.org/abs/2505.22881)
*Hyungki Im, Wyame Benslimane, Paul Grigas*

**主要类别:** cs.LG

**概要:** 本文研究了带有机器学习预测不确定参数不等式约束的情境随机线性优化（CSLO）扩展。通过使用情境不确定性集合方法，引入了SPO-RC损失函数及其凸替代SPO-RC+，并证明了其Fisher一致性。实验表明，结合截断数据集和重要性重加权技术可以有效处理约束中的不确定性并提升性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的CSLO研究大多未涉及依赖于机器学习预测不确定参数的不等式约束，因此需要一种新的方法来处理这些约束中的不确定性。

**方法:** 使用情境不确定性集合构建方法处理约束不确定性，引入SPO-RC损失函数及其凸替代SPO-RC+，并通过截断数据集和重要性重加权技术来增强模型性能。

**结果:** 在分数背包问题和合金生产问题实例上的实验表明，SPO-RC+能够有效应对约束中的不确定性，并且结合截断数据集与重要性重加权技术可进一步提高性能。

**结论:** SPO-RC+为处理CSLO中约束不确定性提供了一种有效的方法，结合截断数据集和重要性重加权技术能显著提升模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Smart+Surrogate+Losses+for+Contextual+Stochastic+Linear+Optimization+with+Robust+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22881，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22881&send_immediately=true&force_search=false)

**原文摘要:** We study an extension of contextual stochastic linear optimization (CSLO)
that, in contrast to most of the existing literature, involves inequality
constraints that depend on uncertain parameters predicted by a machine learning
model. To handle the constraint uncertainty, we use contextual uncertainty sets
constructed via methods like conformal prediction. Given a contextual
uncertainty set method, we introduce the "Smart Predict-then-Optimize with
Robust Constraints" (SPO-RC) loss, a feasibility-sensitive adaptation of the
SPO loss that measures decision error of predicted objective parameters. We
also introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with
SPO-RC. To enhance performance, we train on truncated datasets where true
constraint parameters lie within the uncertainty sets, and we correct the
induced sample selection bias using importance reweighting techniques. Through
experiments on fractional knapsack and alloy production problem instances, we
demonstrate that SPO-RC+ effectively handles uncertainty in constraints and
that combining truncation with importance reweighting can further improve
performance.

</details>


### [4] [Efficient Parameter Estimation for Bayesian Network Classifiers using Hierarchical Linear Smoothing](https://arxiv.org/abs/2505.23320)
*Connor Cooper, Geoffrey I. Webb, Daniel F. Schmidt*

**主要类别:** cs.LG

**概要:** 本论文提出了一种基于对数线性回归的参数估计新方法，用于贝叶斯网络分类器（BNCs），该方法在保持与随机森林相当性能的同时，显著提高了计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管贝叶斯网络分类器具有可解释性、可扩展性和复杂度可调等优点，但传统学习方法在性能上一直落后于随机森林等领先分类方法。虽然使用分层狄利克雷过程（HDPs）的参数平滑技术提升了BNCs在分类数据上的表现，但这些技术灵活性差且需要复杂的采样过程。

**方法:** 引入一种新的参数估计方法，利用对数线性回归来近似HDPs的行为。作为一种线性模型，该方法灵活且易于解释，可以利用丰富的线性模型学习文献。

**结果:** 实验表明，所提出的方法不仅能够超越HDP平滑技术，而且速度提高了几个数量级，同时在分类数据上仍能与随机森林竞争。

**结论:** 提出的对数线性回归方法为BNCs提供了一种更高效、更灵活的参数估计方式，在性能和计算效率之间取得了良好的平衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Parameter+Estimation+for+Bayesian+Network+Classifiers+using+Hierarchical+Linear+Smoothing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23320，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23320&send_immediately=true&force_search=false)

**原文摘要:** Bayesian network classifiers (BNCs) possess a number of properties desirable
for a modern classifier: They are easily interpretable, highly scalable, and
offer adaptable complexity. However, traditional methods for learning BNCs have
historically underperformed when compared to leading classification methods
such as random forests. Recent parameter smoothing techniques using
hierarchical Dirichlet processes (HDPs) have enabled BNCs to achieve
performance competitive with random forests on categorical data, but these
techniques are relatively inflexible, and require a complicated, specialized
sampling process. In this paper, we introduce a novel method for parameter
estimation that uses a log-linear regression to approximate the behaviour of
HDPs. As a linear model, our method is remarkably flexible and simple to
interpret, and can leverage the vast literature on learning linear models. Our
experiments show that our method can outperform HDP smoothing while being
orders of magnitude faster, remaining competitive with random forests on
categorical data.

</details>


### [5] [Epistemic Errors of Imperfect Multitask Learners When Distributions Shift](https://arxiv.org/abs/2505.23496)
*Sabina J. Sloman, Michele Caprio, Samuel Kaski*

**主要类别:** cs.LG

**概要:** 这篇论文提出了认知误差的定义和通用分解式认知误差界限，首次专门针对认知误差进行考量，并涵盖了多种认知不确定性来源。此外，还提供了贝叶斯迁移学习和分布偏移情况下的具体误差界限以及泛化界限，并提出了一种新的负迁移定义并进行了实验验证。


<details>
  <summary>更多</summary>
  
**动机:** 在数据噪声较大的情况下，统计学习者需要解决测试时遇到的数据的认知不确定性，即识别测试数据的分布。然而，许多现实中的学习场景中存在无法仅通过训练数据解决的认知不确定性来源，如多任务学习、目标数据与源数据系统性差异（分布偏移）以及不完美的学习过程。因此，需要一种原则性的方法来定义和分析认知误差。

**方法:** 作者引入了认知误差的定义和通用分解式认知误差界限。该界限考虑了所有可能的认知不确定性来源，并分别归因于学习过程和环境的多个方面。同时，推导出适用于贝叶斯迁移学习和分布偏移情况下的具体认知误差界限及泛化界限。此外，还提出了一种新的负迁移定义。

**结果:** 通过理论推导得到了认知误差界限，并将其应用于特定的学习场景，如贝叶斯迁移学习和分布偏移。此外，在合成实验中验证了新提出的负迁移定义的有效性。

**结论:** 这篇论文为认知误差提供了一个原则性的定义和通用的分解式界限，能够更好地理解和量化各种学习场景中的认知不确定性。同时，新的负迁移定义也为迁移学习研究提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Epistemic+Errors+of+Imperfect+Multitask+Learners+When+Distributions+Shift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23496，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23496&send_immediately=true&force_search=false)

**原文摘要:** When data are noisy, a statistical learner's goal is to resolve epistemic
uncertainty about the data it will encounter at test-time, i.e., to identify
the distribution of test (target) data. Many real-world learning settings
introduce sources of epistemic uncertainty that can not be resolved on the
basis of training (source) data alone: The source data may arise from multiple
tasks (multitask learning), the target data may differ systematically from the
source data tasks (distribution shift), and/or the learner may not arrive at an
accurate characterization of the source data (imperfect learning). We introduce
a principled definition of epistemic error, and provide a generic,
decompositional epistemic error bound. Our error bound is the first to (i)
consider epistemic error specifically, (ii) accommodate all the sources of
epistemic uncertainty above, and (iii) separately attribute the error to each
of multiple aspects of the learning procedure and environment. As corollaries
of the generic result, we provide (i) epistemic error bounds specialized to the
settings of Bayesian transfer learning and distribution shift within
$\epsilon$-neighborhoods, and (ii) a set of corresponding generalization
bounds. Finally, we provide a novel definition of negative transfer, and
validate its insights in a synthetic experimental setting.

</details>


### [6] [On Transferring Transferability: Towards a Theory for Size Generalization](https://arxiv.org/abs/2505.23599)
*Eitan Levin, Yuxin Ma, Mateo Díaz, Soledad Villar*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种跨维度可转移性的通用框架，将转移性与极限空间中的连续性相对应，并在现有架构上实例化该框架，同时提供了设计新的可转移模型的设计原则。


<details>
  <summary>更多</summary>
  
**动机:** 现代学习任务需要能够处理不同大小输入的模型，尤其是在图、集合和点云等领域。已有研究探讨了图神经网络在低维数据上训练后是否能转移到高维输入中，本文旨在扩展这一研究领域。

**方法:** 引入一个通用框架来描述跨维度的可转移性；通过在极限空间中定义小问题实例与等价大问题实例的对应关系，建立可转移性与连续性的联系；对现有架构进行修改以确保其可转移性，并提供设计新可转移模型的原则。

**结果:** 理论分析表明可转移性与极限空间中的连续性相对应；通过对现有架构的修改验证了其可转移性；数值实验支持了这些发现。

**结论:** 本文提出了一个通用框架用于理解跨维度的可转移性，并提供了设计可转移模型的原则，为未来的研究奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Transferring+Transferability%3A+Towards+a+Theory+for+Size+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23599，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23599&send_immediately=true&force_search=false)

**原文摘要:** Many modern learning tasks require models that can take inputs of varying
sizes. Consequently, dimension-independent architectures have been proposed for
domains where the inputs are graphs, sets, and point clouds. Recent work on
graph neural networks has explored whether a model trained on low-dimensional
data can transfer its performance to higher-dimensional inputs. We extend this
body of work by introducing a general framework for transferability across
dimensions. We show that transferability corresponds precisely to continuity in
a limit space formed by identifying small problem instances with equivalent
large ones. This identification is driven by the data and the learning task. We
instantiate our framework on existing architectures, and implement the
necessary changes to ensure their transferability. Finally, we provide design
principles for designing new transferable models. Numerical experiments support
our findings.

</details>


### [7] [Inference-time Scaling of Diffusion Models through Classical Search](https://arxiv.org/abs/2505.23614)
*Xiangcheng Zhang, Haowei Lin, Haotian Ye, James Zou, Jianzhu Ma, Yitao Liang, Yilun Du*

**主要类别:** cs.LG

**概要:** 本论文提出了一种结合局部和全局搜索的框架，用于在扩散模型中实现推理时间控制。该方法通过退火Langevin MCMC进行局部搜索，并使用广度优先和深度优先树搜索进行全局探索，在多个任务上显著提高了性能和效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管扩散模型在生成高质量数据方面表现出色，但它们在推理时适应多样化目标的能力仍然有限。为了解决这个问题，作者希望借鉴经典搜索算法的原理，以提高扩散模型在推理时间上的灵活性和效率。

**方法:** 提出了一种通用框架，将局部搜索（基于退火Langevin MCMC）与全局搜索（基于广度优先和深度优先树搜索）相结合，从而高效地探索生成空间。

**结果:** 在包括规划、离线强化学习和图像生成等多个具有挑战性的领域中，该方法显著提升了性能和效率。

**结论:** 经典搜索算法为扩散模型中的推理时间扩展提供了一个有原则且实用的基础，可以有效提升模型在不同任务中的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inference-time+Scaling+of+Diffusion+Models+through+Classical+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23614，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23614&send_immediately=true&force_search=false)

**原文摘要:** Classical search algorithms have long underpinned modern artificial
intelligence. In this work, we tackle the challenge of inference-time control
in diffusion models -- adapting generated outputs to meet diverse test-time
objectives -- using principles from classical search. We propose a general
framework that orchestrates local and global search to efficiently navigate the
generative space. It employs a theoretically grounded local search via annealed
Langevin MCMC and performs compute-efficient global exploration using
breadth-first and depth-first tree search. We evaluate our approach on a range
of challenging domains, including planning, offline reinforcement learning, and
image generation. Across all tasks, we observe significant gains in both
performance and efficiency. These results show that classical search provides a
principled and practical foundation for inference-time scaling in diffusion
models. Project page at diffusion-inference-scaling.github.io.

</details>


### [8] [COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents](https://arxiv.org/abs/2505.23720)
*Arun Verma, Indrajit Saha, Makoto Yokoo, Bryan Kian Hsiang Low*

**主要类别:** cs.LG

**概要:** 本文研究了多代理环境下的情境强盗问题，提出了一种名为COBRA的算法，能够通过非货币激励手段减少代理的战略行为，并保证激励兼容性和次线性后悔界。实验结果验证了该算法在不同性能方面的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的情境强盗问题研究假设代理会如实报告其臂选择，但在实际应用中，例如在线平台上，卖家可能会虚报产品质量以获得优势。这促使研究者寻找一种方法来减少代理的战略行为，同时不使用货币激励。

**方法:** 提出了COBRA算法，用于处理涉及战略性代理的情境强盗问题。该算法旨在减少代理的战略行为，具有激励兼容性，并保证次线性后悔界。

**结果:** 实验结果验证了COBRA算法在不同性能方面的有效性。

**结论:** COBRA算法能够在不使用货币激励的情况下，有效减少代理的战略行为，同时保持激励兼容性和较低的后悔界。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是COBRA%3A+Contextual+Bandit+Algorithm+for+Ensuring+Truthful+Strategic+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23720，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23720&send_immediately=true&force_search=false)

**原文摘要:** This paper considers a contextual bandit problem involving multiple agents,
where a learner sequentially observes the contexts and the agent's reported
arms, and then selects the arm that maximizes the system's overall reward.
Existing work in contextual bandits assumes that agents truthfully report their
arms, which is unrealistic in many real-life applications. For instance,
consider an online platform with multiple sellers; some sellers may
misrepresent product quality to gain an advantage, such as having the platform
preferentially recommend their products to online users. To address this
challenge, we propose an algorithm, COBRA, for contextual bandit problems
involving strategic agents that disincentivize their strategic behavior without
using any monetary incentives, while having incentive compatibility and a
sub-linear regret guarantee. Our experimental results also validate the
different performance aspects of our proposed algorithm.

</details>


### [9] [Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs](https://arxiv.org/abs/2505.22686)
*Ange-Clement Akazan, Verlon Roel Mbingui, Gnankan Landry Regis N'guessan, Issa Karambal*

**主要类别:** cs.LG

**概要:** 本研究在热带非洲的两个城市阿比让和基加利，对每日温度、降水和气压预测的各种深度递归神经网络（如LSTM、GRU等）及Kolmogorov-Arnold模型进行了基准测试。引入了两种改进的TKAN模型，使用不同的激活函数（GeLU和MiSH）。KAN模型在温度预测上表现出色，而改进的TKAN模型在低降雨量条件下的降水预测中表现优异。对于气压预测，传统的RNN模型效果最好。这表明样条神经架构在高效数据预测中的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 天气预报对于管理风险和经济规划至关重要，特别是在极端天气事件严重影响生计的热带非洲地区。然而，现有的预测方法常常难以应对该地区的复杂非线性天气模式。因此，需要探索更有效的预测模型来改善这一状况。

**方法:** 研究采用了多种深度递归神经网络（包括LSTM、GRU、BiLSTM、BiGRU）和基于Kolmogorov-Arnold的模型（KAN和TKAN），并针对每日温度、降水和气压预测进行基准测试。同时，还提出了两种定制版的TKAN模型，分别用GeLU和MiSH替代原始的SiLU激活函数。使用从2010年到2024年的气象站数据进行评估，采用标准回归度量指标。

**结果:** KAN模型在温度预测中表现出色，其R²值分别为0.9986（阿比让）和0.9998（基加利），MSE小于0.0014°C²。改进后的TKAN模型在低降雨量条件下的降水预测中绝对误差最小。对于气压预测，传统的RNN模型在两项数据集中均具有竞争力，其R²值约为0.83-0.86，优于基于KAN的模型。

**结论:** 研究表明，样条神经架构在高效和数据效率高的天气预测中具有巨大潜力。不同模型在不同类型天气参数预测中的表现各有优劣，具体选择应根据任务需求决定。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Localized+Weather+Prediction+Using+Kolmogorov-Arnold+Network-Based+Models+and+Deep+RNNs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22686&send_immediately=true&force_search=false)

**原文摘要:** Weather forecasting is crucial for managing risks and economic planning,
particularly in tropical Africa, where extreme events severely impact
livelihoods. Yet, existing forecasting methods often struggle with the region's
complex, non-linear weather patterns. This study benchmarks deep recurrent
neural networks such as $\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and
Kolmogorov-Arnold-based models $(\texttt{KAN} and \texttt{TKAN})$ for daily
forecasting of temperature, precipitation, and pressure in two tropical cities:
Abidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce
two customized variants of $ \texttt{TKAN}$ that replace its original
$\texttt{SiLU}$ activation function with $ \texttt{GeLU}$ and \texttt{MiSH},
respectively. Using station-level meteorological data spanning from 2010 to
2024, we evaluate all the models on standard regression metrics. $\texttt{KAN}$
achieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,
$\texttt{MSE} < 0.0014~^\circ C ^2$), while $\texttt{TKAN}$ variants minimize
absolute errors for precipitation forecasting in low-rainfall regimes. The
customized $\texttt{TKAN}$ models demonstrate improvements over the standard
$\texttt{TKAN}$ across both datasets. Classical \texttt{RNNs} remain highly
competitive for atmospheric pressure ($R^2 \approx 0.83{-}0.86$), outperforming
$\texttt{KAN}$-based models in this task. These results highlight the potential
of spline-based neural architectures for efficient and data-efficient
forecasting.

</details>


### [10] [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org/abs/2505.22689)
*Jialong Guo, Xinghao Chen, Yehui Tang, Yunhe Wang*

**主要类别:** cs.LG

**概要:** 大型语言模型（LLMs）因其巨大的计算成本而受限，本文提出了一种名为SlimLLM的有效快速结构化剪枝方法，通过评估通道和注意力头的重要性并考虑子模块内元素的相互依赖性，设计简单的线性回归策略快速恢复性能，并提出基于层的重要性比率确定每层的剪枝比率。在LLaMA基准测试中，SlimLLM优于其他方法，达到最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）在众多应用中表现出令人印象深刻的能力，但其庞大的计算成本严重限制了部署和应用。为了解决这个问题，结构化剪枝成为一种有效的压缩LLMs参数的方法。

**方法:** 提出了一种名为SlimLLM的结构化剪枝方法，对于通道和注意力头剪枝，基于整个通道或头来评估重要性，而不是仅仅聚合子模块内单个元素的重要性，从而更全面地考虑子模块内元素之间的相互依赖性。此外，设计了一个简单的线性回归策略以快速恢复性能，并提出了基于层的重要性比率来确定每层的剪枝比率。

**结果:** 根据LLaMA基准测试结果，SlimLLM优于其他方法，达到了最先进的性能。

**结论:** SlimLLM是一种有效且快速的结构化剪枝方法，可以更好地评估LLMs中每个子模块的重要性并最小化性能损失。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SlimLLM%3A+Accurate+Structured+Pruning+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22689，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22689&send_immediately=true&force_search=false)

**原文摘要:** Large language models(LLMs) have garnered significant attention and
demonstrated impressive capabilities in a wide range of applications. However,
due to their enormous computational costs, the deployment and application of
LLMs are often severely limited. To address this issue, structured pruning is
an effective solution to compress the parameters of LLMs. Determining the
importance of each sub-module in LLMs and minimizing performance loss are
critical issues that need to be carefully addressed in structured pruning. In
this paper, we propose an effective and fast structured pruning method named
SlimLLM for large language models. For channel and attention head pruning, we
evaluate the importance based on the entire channel or head, rather than merely
aggregating the importance of individual elements within a sub-module. This
approach enables a more holistic consideration of the interdependence among
elements within the sub-module. In addition, we design a simple linear
regression strategy for the output matrix to quickly recover performance. We
also propose layer-based importance ratio to determine the pruning ratio for
each layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other
methods and achieves state-of-the-art performance.

</details>


### [11] [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org/abs/2505.22694)
*Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei*

**主要类别:** cs.LG

**概要:** 提出了一种新的多任务参数高效微调方法MoRE，通过联合训练低秩专家和自适应秩选择器，在多任务场景中显著提升LLM性能且无额外推理成本。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LoRA方法在多任务场景下要么专注于单任务，要么分别训练多个LoRA模块，限制了效率和效果。

**方法:** 提出了Mixture of Low-Rank Experts (MoRE)，通过将不同任务与不同秩的LoRA模块对齐，并设计了一个自适应秩选择器来为每个任务选择合适的专家，从而增强了LoRA在多任务场景中的适应性和效率。

**结果:** 实验结果表明，与传统的LoRA及其变体相比，MoRE显著提高了LLM在多任务场景下的性能，并且没有增加额外的推理成本。

**结论:** MoRE在多任务PEFT中表现出色，提升了LLM的性能，同时保持了高效的推理。作者还开源了模型和代码以促进社区发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoRE%3A+A+Mixture+of+Low-Rank+Experts+for+Adaptive+Multi-Task+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22694，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22694&send_immediately=true&force_search=false)

**原文摘要:** With the rapid development of Large Language Models (LLMs),
Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant
attention, which aims to achieve efficient fine-tuning of LLMs with fewer
parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)
introduces low-rank matrices to approximate the incremental tuning parameters
and achieves impressive performance over multiple scenarios. After that, plenty
of improvements have been proposed for further improvement. However, these
methods either focus on single-task scenarios or separately train multiple LoRA
modules for multi-task scenarios, limiting the efficiency and effectiveness of
LoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in
this paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for
multi-task PEFT. Specifically, instead of using an individual LoRA for each
task, we align different ranks of LoRA module with different tasks, which we
named low-rank experts. Moreover, we design a novel adaptive rank selector to
select the appropriate expert for each task. By jointly training low-rank
experts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task
scenarios. Finally, we conduct extensive experiments over multiple multi-task
benchmarks along with different LLMs to verify model performance. Experimental
results demonstrate that compared to traditional LoRA and its variants, MoRE
significantly improves the performance of LLMs in multi-task scenarios and
incurs no additional inference cost. We also release the model and code to
facilitate the community.

</details>


### [12] [LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning](https://arxiv.org/abs/2505.22695)
*Tengfei Lyu, Siyuan Feng, Hao Liu, Hai Yang*

**主要类别:** cs.LG

**概要:** 论文提出LLM-ODDR框架，利用大语言模型优化网约车订单分配和司机重定位问题，包含多目标导向的订单价值评估、公平性感知的订单分配以及时空需求感知的司机重定位三个关键组件。实验表明该方法在效果、适应性和可解释性方面优于传统方法。这是首次将大语言模型应用于网约车决策任务。


<details>
  <summary>更多</summary>
  
**动机:** 当前网约车平台在动态城市环境中面临订单分配和司机重定位的挑战，传统方法如组合优化、基于规则的启发式算法和强化学习往往忽视了司机收入公平性、可解释性和对真实世界动态的适应能力。

**方法:** 提出了LLM-ODDR框架，包括：1) 多目标导向的订单价值评估；2) 公平性感知的订单分配；3) 时空需求感知的司机重定位。同时开发了JointDR-GPT，一个针对ODDR任务优化的精细调优模型。

**结果:** 通过曼哈顿出租车运营的真实数据集进行的广泛实验表明，该框架在有效性、对异常条件的适应性以及决策可解释性方面显著优于传统方法。

**结论:** 这是首次探索将大语言模型作为网约车ODDR任务中的决策代理，为在智能交通系统中整合先进的语言模型提供了基础性的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-ODDR%3A+A+Large+Language+Model+Framework+for+Joint+Order+Dispatching+and+Driver+Repositioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22695，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22695&send_immediately=true&force_search=false)

**原文摘要:** Ride-hailing platforms face significant challenges in optimizing order
dispatching and driver repositioning operations in dynamic urban environments.
Traditional approaches based on combinatorial optimization, rule-based
heuristics, and reinforcement learning often overlook driver income fairness,
interpretability, and adaptability to real-world dynamics. To address these
gaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models
(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in
ride-hailing services. LLM-ODDR framework comprises three key components: (1)
Multi-objective-guided Order Value Refinement, which evaluates orders by
considering multiple objectives to determine their overall value; (2)
Fairness-aware Order Dispatching, which balances platform revenue with driver
income fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,
which optimizes idle vehicle placement based on historical patterns and
projected supply. We also develop JointDR-GPT, a fine-tuned model optimized for
ODDR tasks with domain knowledge. Extensive experiments on real-world datasets
from Manhattan taxi operations demonstrate that our framework significantly
outperforms traditional methods in terms of effectiveness, adaptability to
anomalous conditions, and decision interpretability. To our knowledge, this is
the first exploration of LLMs as decision-making agents in ride-hailing ODDR
tasks, establishing foundational insights for integrating advanced language
models within intelligent transportation systems.

</details>


### [13] [When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?](https://arxiv.org/abs/2505.22696)
*Eleni Nisioti, Joachim Winther Pedersen, Erwan Plantec, Milton L. Montero, Sebastian Risi*

**主要类别:** cs.LG

**概要:** 研究了神经进化（NE）在技能迁移中的能力，提出了两个基准测试，并发现NE方法在迁移学习方面优于强化学习（RL），并具有构建更适应性智能体的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习（RL）是高维控制任务的主要学习范式，但它对任务变化很脆弱且容易发生灾难性遗忘。而神经进化（NE）因其鲁棒性、可扩展性和逃离局部最优的能力受到关注，但其迁移学习能力尚未被充分研究。

**方法:** 引入了两个基准：1) stepping gates，要求神经网络模仿逻辑电路，重点在于模块化重复和变体；2) ecorobot，扩展了Brax物理引擎，添加了墙壁和障碍物，并可以轻松切换不同的机器人形态。两者都通过课程设计来评估跨任务的技能迁移。

**结果:** 实证分析表明，NE方法在迁移能力上有所不同，且通常优于RL基线。

**结论:** NE有可能成为构建更适应性智能体的基础，但仍面临将其扩展到复杂现实问题的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Does+Neuroevolution+Outcompete+Reinforcement+Learning+in+Transfer+Learning+Tasks%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22696&send_immediately=true&force_search=false)

**原文摘要:** The ability to continuously and efficiently transfer skills across tasks is a
hallmark of biological intelligence and a long-standing goal in artificial
systems. Reinforcement learning (RL), a dominant paradigm for learning in
high-dimensional control tasks, is known to suffer from brittleness to task
variations and catastrophic forgetting. Neuroevolution (NE) has recently gained
attention for its robustness, scalability, and capacity to escape local optima.
In this paper, we investigate an understudied dimension of NE: its transfer
learning capabilities. To this end, we introduce two benchmarks: a) in stepping
gates, neural networks are tasked with emulating logic circuits, with designs
that emphasize modular repetition and variation b) ecorobot extends the Brax
physics engine with objects such as walls and obstacles and the ability to
easily switch between different robotic morphologies. Crucial in both
benchmarks is the presence of a curriculum that enables evaluating skill
transfer across tasks of increasing complexity. Our empirical analysis shows
that NE methods vary in their transfer abilities and frequently outperform RL
baselines. Our findings support the potential of NE as a foundation for
building more adaptable agents and highlight future challenges for scaling NE
to complex, real-world problems.

</details>


### [14] [Update Your Transformer to the Latest Release: Re-Basin of Task Vectors](https://arxiv.org/abs/2505.22697)
*Filippo Rinaldi, Giacomo Capitani, Lorenzo Bonicelli, Donato Crisostomi, Federico Bolelli, Elisa Ficarra, Emanuele Rodolà, Simone Calderara, Angelo Porrello*

**主要类别:** cs.LG

**概要:** 本文提出了一种无需重新训练或数据的方法，将微调知识无缝转移到新的预训练模型中。通过基于权重排列的两层方法（源于谱系理论），解决了Transformer模型中的残差连接和多头注意力层的问题，并在视觉和文本任务上进行了广泛实验验证。代码已开源。


<details>
  <summary>更多</summary>
  
**动机:** 当底层预训练模型更新或重新训练时，微调模型会变得过时并失去效用，因此需要重新训练。为了解决这个问题，研究者提出了一个问题：是否可以将微调转移到模型的新版本上？

**方法:** 研究者从模型重盆地原则出发，提供了一种基于权重排列的方法，以重新调整对原始基础模型所做的修改（称为任务向量）。具体而言，他们提出了一种两层方法，该方法首先置换注意力头，然后调整选定头对内的参数。此方法针对Transformer模型设计，考虑了残差连接和多头注意力层的挑战。

**结果:** 通过广泛的实验，该方法实现了将微调知识无缝转移到新的预训练骨干网络上，而无需任何训练步骤或数据点。

**结论:** 该方法成功地在无需重新训练或数据的情况下，将微调知识转移到新的预训练模型版本上，适用于视觉和文本任务，证明了其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Update+Your+Transformer+to+the+Latest+Release%3A+Re-Basin+of+Task+Vectors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22697，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22697&send_immediately=true&force_search=false)

**原文摘要:** Foundation models serve as the backbone for numerous specialized models
developed through fine-tuning. However, when the underlying pretrained model is
updated or retrained (e.g., on larger and more curated datasets), the
fine-tuned model becomes obsolete, losing its utility and requiring retraining.
This raises the question: is it possible to transfer fine-tuning to a new
release of the model? In this work, we investigate how to transfer fine-tuning
to a new checkpoint without having to re-train, in a data-free manner. To do
so, we draw principles from model re-basin and provide a recipe based on weight
permutations to re-base the modifications made to the original base model,
often called task vector. In particular, our approach tailors model re-basin
for Transformer models, taking into account the challenges of residual
connections and multi-head attention layers. Specifically, we propose a
two-level method rooted in spectral theory, initially permuting the attention
heads and subsequently adjusting parameters within select pairs of heads.
Through extensive experiments on visual and textual tasks, we achieve the
seamless transfer of fine-tuned knowledge to new pre-trained backbones without
relying on a single training step or datapoint. Code is available at
https://github.com/aimagelab/TransFusion.

</details>


### [15] [FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference](https://arxiv.org/abs/2505.22758)
*Aniruddha Nrusimha, William Brandon, Mayank Mishra, Yikang Shen, Rameswar Panda, Jonathan Ragan-Kelley, Yoon Kim*

**主要类别:** cs.LG

**概要:** 现代大型语言模型的规模和计算特性促使了对训练和推理专用内核的开发兴趣。然而，低批量推理对于许多应用（如边缘部署和延迟敏感应用）仍然重要。本文介绍了FlashFormer，一个用于加速基于变压器的大型语言模型单批量推理的概念验证内核。在各种模型大小和量化设置下，与现有的最先进的推理内核相比，观察到了显著的速度提升。


<details>
  <summary>更多</summary>
  
**动机:** 现代大型语言模型的规模和计算特性导致了对专门内核开发的兴趣增加，但现有内核主要针对大批次训练和推理进行优化，忽略了低批次推理的需求，而后者对于边缘部署和延迟敏感应用等场景仍然重要。

**方法:** 提出了FlashFormer，这是一个专为基于变压器的大型语言模型设计的单批量推理加速内核。该方法关注于减少内存带宽使用和内核启动开销，以优化低批量推理性能。

**结果:** 在不同的模型大小和量化设置下，FlashFormer相对于现有的最先进推理内核实现了非平凡的速度提升。

**结论:** FlashFormer作为一个概念验证内核，成功展示了其在单批量推理中的性能优势，表明针对低批量推理优化的重要性，并为未来相关研究提供了有价值的参考。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FlashFormer%3A+Whole-Model+Kernels+for+Efficient+Low-Batch+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22758，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22758&send_immediately=true&force_search=false)

**原文摘要:** The size and compute characteristics of modern large language models have led
to an increased interest in developing specialized kernels tailored for
training and inference. Existing kernels primarily optimize for compute
utilization, targeting the large-batch training and inference settings.
However, low-batch inference, where memory bandwidth and kernel launch
overheads contribute are significant factors, remains important for many
applications of interest such as in edge deployment and latency-sensitive
applications. This paper describes FlashFormer, a proof-of-concept kernel for
accelerating single-batch inference for transformer-based large language
models. Across various model sizes and quantizations settings, we observe
nontrivial speedups compared to existing state-of-the-art inference kernels.

</details>


### [16] [Test-time augmentation improves efficiency in conformal prediction](https://arxiv.org/abs/2505.22764)
*Divya Shanmugam, Helen Lu, Swami Sankaranarayanan, John Guttag*

**主要类别:** cs.LG

**概要:** 论文提出了一种使用测试时增强（TTA）技术的方法，以减少共形分类器产生的预测集合大小，该方法灵活、高效且无需重新训练模型，在多个数据集和模型上平均减少了10%-14%的预测集合大小。


<details>
  <summary>更多</summary>
  
**动机:** 共形分类器虽然能够提供包含真实类别的概率保证，但其生成的预测集合通常过大而缺乏实用性，因此需要一种方法来减少这些集合的大小。

**方法:** 利用测试时增强（TTA）技术，在推理过程中引入归纳偏置，从而减少共形分类器生成的预测集合大小。此方法可与任何共形评分结合，无需模型重新训练。

**结果:** 在三个数据集、三种模型、两种已建立的共形评分方法上进行评估，结果表明TTA方法在不同保证强度和分布偏移下，能有效减少预测集合大小，平均减少10%-14%。

**结论:** 测试时增强是一种对共形分类器有用的补充技术，能够在不牺牲概率保证的前提下，提高共形分类器的实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Test-time+augmentation+improves+efficiency+in+conformal+prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22764，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22764&send_immediately=true&force_search=false)

**原文摘要:** A conformal classifier produces a set of predicted classes and provides a
probabilistic guarantee that the set includes the true class. Unfortunately, it
is often the case that conformal classifiers produce uninformatively large
sets. In this work, we show that test-time augmentation (TTA)--a technique that
introduces inductive biases during inference--reduces the size of the sets
produced by conformal classifiers. Our approach is flexible, computationally
efficient, and effective. It can be combined with any conformal score, requires
no model retraining, and reduces prediction set sizes by 10%-14% on average. We
conduct an evaluation of the approach spanning three datasets, three models,
two established conformal scoring methods, different guarantee strengths, and
several distribution shifts to show when and why test-time augmentation is a
useful addition to the conformal pipeline.

</details>


### [17] [Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting](https://arxiv.org/abs/2505.22768)
*Mert Onur Cakiroglu, Idil Bilge Altun, Hasan Kurban, Elham Buxton, Mehmet Dalkilic*

**主要类别:** cs.LG

**概要:** DRAGON是一种新的编码器，通过多变量de Bruijn图将符号表示与神经建模结合，用于时间序列预测。它将连续输入序列离散化并映射到固定图结构上，通过基于图的注意力机制实现动态上下文恢复，并增强了传统的CNN编码器。


<details>
  <summary>更多</summary>
  
**动机:** 时间序列预测对于基础模型来说仍然是一个具有挑战性的任务，因为存在时间异质性、高维度和缺乏内在符号结构的问题。为了解决这些问题，需要一种新的方法来弥合符号表示和神经建模之间的差距。

**方法:** 提出了DRAGON（在de Bruijn图上的离散表示和增强图编码），引入了多变量de Bruijn图（MdBGs）作为辅助模块集成到双分支架构中，以增强常规基于CNN的编码器，使用符号和结构感知表示。

**结果:** 通过离散化连续输入序列并将其映射到固定的图结构上，DRAGON能够通过基于图的注意力机制实现动态上下文恢复。

**结论:** DRAGON提供了一种新的方法来处理时间序列预测中的挑战，通过结合符号表示和神经建模，提高了预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multivariate+de+Bruijn+Graphs%3A+A+Symbolic+Graph+Framework+for+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22768，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22768&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting remains a challenging task for foundation models due
to temporal heterogeneity, high dimensionality, and the lack of inherent
symbolic structure. In this work, we propose DRAGON (Discrete Representation
and Augmented Graph encoding Over deBruijN Graphs), a novel encoder that
introduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between
symbolic representations and neural modeling. DRAGON discretizes continuous
input sequences and maps them onto a fixed graph structure, enabling dynamic
context recovery via graph-based attention. Integrated as an auxiliary module
within a dual-branch architecture, DRAGON augments conventional CNN-based
encoders with symbolic, structure-aware representations. All code developed for
this study is available at:
https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library

</details>


### [18] [Calibrated Value-Aware Model Learning with Stochastic Environment Models](https://arxiv.org/abs/2505.22772)
*Claas Voelcker, Anastasiia Pedan, Arash Ahmadian, Romina Abachi, Igor Gilitschenski, Amir-massoud Farahmand*

**主要类别:** cs.LG

**概要:** 这篇论文探讨了价值感知模型学习损失（包括MuZero损失）的校准问题，揭示其作为替代损失函数时可能无法正确恢复模型和价值函数，并提出了修正方案。此外，研究还分析了损失校准、潜在模型架构及辅助损失在训练MuZero风格代理中的相互作用。


<details>
  <summary>更多</summary>
  
**动机:** 价值感知模型学习在基于模型的强化学习中占据重要地位，但对其损失函数（如MuZero损失）的理论研究有限。

**方法:** 作者分析了价值感知模型学习损失家族，指出这些损失通常是未校准的替代损失，可能导致无法正确恢复模型和价值函数。基于此，提出了修正方法，并研究了损失校准与模型架构和辅助损失之间的关系。

**结果:** 研究表明，确定性模型足以预测准确的价值，但学习校准的随机模型仍然具有优势。

**结论:** 价值感知模型学习损失需要校准以确保正确的模型和价值函数恢复，且校准的随机模型在某些情况下更具优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Calibrated+Value-Aware+Model+Learning+with+Stochastic+Environment+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22772&send_immediately=true&force_search=false)

**原文摘要:** The idea of value-aware model learning, that models should produce accurate
value estimates, has gained prominence in model-based reinforcement learning.
The MuZero loss, which penalizes a model's value function prediction compared
to the ground-truth value function, has been utilized in several prominent
empirical works in the literature. However, theoretical investigation into its
strengths and weaknesses is limited. In this paper, we analyze the family of
value-aware model learning losses, which includes the popular MuZero loss. We
show that these losses, as normally used, are uncalibrated surrogate losses,
which means that they do not always recover the correct model and value
function. Building on this insight, we propose corrections to solve this issue.
Furthermore, we investigate the interplay between the loss calibration, latent
model architectures, and auxiliary losses that are commonly employed when
training MuZero-style agents. We show that while deterministic models can be
sufficient to predict accurate values, learning calibrated stochastic models is
still advantageous.

</details>


### [19] [Machine Learning Models Have a Supply Chain Problem](https://arxiv.org/abs/2505.22778)
*Sarah Meiklejohn, Hayden Blauzvern, Mihai Maruseac, Spencer Schrock, Laurent Simon, Ilia Shumailov*

**主要类别:** cs.LG

**概要:** 本论文探讨了开放机器学习模型生态系统中的供应链风险，并提出使用Sigstore为这些模型和数据集提供透明性和认证的可能性。


<details>
  <summary>更多</summary>
  
**动机:** 开放的机器学习模型使缺乏专业知识或资源的用户能够使用强大的模型，但这种开放生态也带来了许多潜在的安全风险，例如模型被恶意替换、训练框架存在漏洞或数据受到污染等。

**方法:** 作者分析了开放机器学习模型的供应链风险，并研究了如何利用Sigstore（一种旨在为开源软件供应链带来透明度的解决方案）来实现对开放机器学习模型的签名认证，以及证明所使用的数据集的属性。

**结果:** 通过引入Sigstore机制，可以增强开放机器学习模型的透明性，允许模型发布者对其模型进行签名并验证数据集的可信性，从而降低供应链攻击的风险。

**结论:** 开放机器学习模型生态系统存在显著的供应链风险，而采用类似Sigstore的技术可以有效提升该领域的安全性和透明性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Learning+Models+Have+a+Supply+Chain+Problem，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22778，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22778&send_immediately=true&force_search=false)

**原文摘要:** Powerful machine learning (ML) models are now readily available online, which
creates exciting possibilities for users who lack the deep technical expertise
or substantial computing resources needed to develop them. On the other hand,
this type of open ecosystem comes with many risks. In this paper, we argue that
the current ecosystem for open ML models contains significant supply-chain
risks, some of which have been exploited already in real attacks. These include
an attacker replacing a model with something malicious (e.g., malware), or a
model being trained using a vulnerable version of a framework or on restricted
or poisoned data. We then explore how Sigstore, a solution designed to bring
transparency to open-source software supply chains, can be used to bring
transparency to open ML models, in terms of enabling model publishers to sign
their models and prove properties about the datasets they use.

</details>


### [20] [Navigating the Latent Space Dynamics of Neural Models](https://arxiv.org/abs/2505.22785)
*Marco Fumero, Luca Moschella, Emanuele Rodolà, Francesco Locatello*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种将神经网络模型解释为作用于潜在流形上的动力系统的方法，并利用其隐含的向量场来分析模型和数据特性。


<details>
  <summary>更多</summary>
  
**动机:** 当前神经网络通常通过降维将高维数据转换为紧凑表示，但作者希望从动力系统的角度重新解读神经模型，以揭示其更深层次的特性。

**方法:** 通过反复应用编码-解码映射，展示自编码器模型在潜在流形上隐式定义了一个向量场；并观察到标准训练过程会引入吸引子点的归纳偏差，从而利用该向量场作为网络的新表征。

**结果:** 该方法能够分析神经模型的泛化与记忆模式、提取网络参数中的先验知识、以及识别分布外样本，并且在视觉基础模型上的实验验证了其有效性和适用性。

**结论:** 神经模型可以被解释为作用于潜在流形上的动力系统，其隐含的向量场为理解模型行为和数据特性提供了新工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Navigating+the+Latent+Space+Dynamics+of+Neural+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22785，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22785&send_immediately=true&force_search=false)

**原文摘要:** Neural networks transform high-dimensional data into compact, structured
representations, often modeled as elements of a lower dimensional latent space.
In this paper, we present an alternative interpretation of neural models as
dynamical systems acting on the latent manifold. Specifically, we show that
autoencoder models implicitly define a latent vector field on the manifold,
derived by iteratively applying the encoding-decoding map, without any
additional training. We observe that standard training procedures introduce
inductive biases that lead to the emergence of attractor points within this
vector field. Drawing on this insight, we propose to leverage the vector field
as a representation for the network, providing a novel tool to analyze the
properties of the model and the data. This representation enables to: (i)
analyze the generalization and memorization regimes of neural models, even
throughout training; (ii) extract prior knowledge encoded in the network's
parameters from the attractors, without requiring any input data; (iii)
identify out-of-distribution samples from their trajectories in the vector
field. We further validate our approach on vision foundation models, showcasing
the applicability and effectiveness of our method in real-world scenarios.

</details>


### [21] [Efficient Preimage Approximation for Neural Network Certification](https://arxiv.org/abs/2505.22798)
*Anton Björklund, Mykola Zaitsev, Marta Kwiatkowska*

**主要类别:** cs.LG

**概要:** 这篇论文通过改进PREMAP算法，显著提升了神经网络认证中前像逼近方法的效率和可扩展性，特别是在对抗'补丁攻击'方面。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能在安全和安保关键应用中的依赖日益增加，对神经网络的有效认证需求也随之增长。特别是在面对'补丁攻击'时，这种需求更具挑战性。

**方法:** 论文提出了针对PREMAP算法的新改进，包括更紧密的界限、自适应蒙特卡洛采样和改进的分支启发式方法，以提升其可扩展性和效率。

**结果:** 这些改进使得在强化学习控制基准上的效率至少提高了十倍，并且方法可以扩展到以前无法处理的卷积神经网络。

**结论:** 结果展示了前像逼近方法在可靠性和稳健性认证方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Preimage+Approximation+for+Neural+Network+Certification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22798，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22798&send_immediately=true&force_search=false)

**原文摘要:** The growing reliance on artificial intelligence in safety- and
security-critical applications demands effective neural network certification.
A challenging real-world use case is certification against ``patch attacks'',
where adversarial patches or lighting conditions obscure parts of images, for
example traffic signs. One approach to certification, which also gives
quantitative coverage estimates, utilizes preimages of neural networks, i.e.,
the set of inputs that lead to a specified output. However, these preimage
approximation methods, including the state-of-the-art PREMAP algorithm,
struggle with scalability. This paper presents novel algorithmic improvements
to PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved
branching heuristics. We demonstrate efficiency improvements of at least an
order of magnitude on reinforcement learning control benchmarks, and show that
our method scales to convolutional neural networks that were previously
infeasible. Our results demonstrate the potential of preimage approximation
methodology for reliability and robustness certification.

</details>


### [22] [CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment](https://arxiv.org/abs/2505.22803)
*Pedro Mendes, Paolo Romano, David Garlan*

**主要类别:** cs.LG

**概要:** CLUE是一种新的方法，通过在训练过程中将预测不确定性与观察到的误差对齐，以实现神经网络的可靠不确定性估计。它具有完全可微分、领域无关和与标准训练流程兼容的特点，并在多项任务中表现出优越的校准质量和竞争力的预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前校准技术存在可扩展性、可微分性和跨域泛化能力的限制，无法充分满足实际应用中神经网络对可靠不确定性估计的需求。

**方法:** CLUE（通过学习不确定性-误差对齐进行校准）采用一种新方法，在训练期间明确地将预测不确定性与观测误差对齐。它使用不确定性与损失的汇总统计作为代理，提出了一种新的损失函数，联合优化预测性能和校准。该方法完全可微分、领域无关，并且与标准训练流程兼容。

**结果:** 通过广泛的实验，包括视觉、回归和语言建模任务，以及分布外和领域迁移场景，CLUE展现出比现有最先进方法更优越的校准质量，同时保持竞争力的预测性能，而不会增加显著的计算开销。

**结论:** CLUE提供了一种有效的方法来提升神经网络的校准质量，适用于多种任务类型和场景，同时保持良好的预测性能和较低的计算成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CLUE%3A+Neural+Networks+Calibration+via+Learning+Uncertainty-Error+alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22803，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22803&send_immediately=true&force_search=false)

**原文摘要:** Reliable uncertainty estimation is critical for deploying neural networks
(NNs) in real-world applications. While existing calibration techniques often
rely on post-hoc adjustments or coarse-grained binning methods, they remain
limited in scalability, differentiability, and generalization across domains.
In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error
Alignment), a novel approach that explicitly aligns predicted uncertainty with
observed error during training, grounded in the principle that well-calibrated
models should produce uncertainty estimates that match their empirical loss.
CLUE adopts a novel loss function that jointly optimizes predictive performance
and calibration, using summary statistics of uncertainty and loss as proxies.
The proposed method is fully differentiable, domain-agnostic, and compatible
with standard training pipelines. Through extensive experiments on vision,
regression, and language modeling tasks, including out-of-distribution and
domain-shift scenarios, we demonstrate that CLUE achieves superior calibration
quality and competitive predictive performance with respect to state-of-the-art
approaches without imposing significant computational overhead.

</details>


### [23] [PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow](https://arxiv.org/abs/2505.22825)
*Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck*

**主要类别:** cs.LG

**概要:** 论文介绍了一个名为PGLearn的综合数据集和评估工具套件，用于机器学习在最优潮流（OPF）问题中的应用。它提供了具有代表性的数据集、多种OPF公式支持，并公开发布以促进公平比较和研究加速。


<details>
  <summary>更多</summary>
  
**动机:** 当前在最优潮流问题中使用机器学习技术的研究缺乏标准化的数据集和评估指标，这阻碍了该领域的进展。

**方法:** 引入PGLearn，一个包含标准化数据集和评估工具的套件。数据集捕捉了全局和局部数据变化，并首次包括大规模系统的时间序列数据。支持多种OPF公式，并提供公开可用的数据集和强大的机器学习模型训练、评估及基准测试工具。

**结果:** PGLearn通过提供开放且标准化的数据集和评估指标，促进了该领域研究的民主化和加速。

**结论:** PGLearn的推出有助于解决数据生成负担重和方法公平比较困难的问题，从而推动机器学习在最优潮流问题中的应用研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PGLearn+--+An+Open-Source+Learning+Toolkit+for+Optimal+Power+Flow，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22825，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22825&send_immediately=true&force_search=false)

**原文摘要:** Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have
recently garnered significant attention, reflecting a broader trend of
leveraging ML to approximate and/or accelerate the resolution of complex
optimization problems. These developments are necessitated by the increased
volatility and scale in energy production for modern and future grids. However,
progress in ML for OPF is hindered by the lack of standardized datasets and
evaluation metrics, from generating and solving OPF instances, to training and
benchmarking machine learning models. To address this challenge, this paper
introduces PGLearn, a comprehensive suite of standardized datasets and
evaluation tools for ML and OPF. PGLearn provides datasets that are
representative of real-life operating conditions, by explicitly capturing both
global and local variability in the data generation, and by, for the first
time, including time series data for several large-scale systems. In addition,
it supports multiple OPF formulations, including AC, DC, and second-order cone
formulations. Standardized datasets are made publicly available to democratize
access to this field, reduce the burden of data generation, and enable the fair
comparison of various methodologies. PGLearn also includes a robust toolkit for
training, evaluating, and benchmarking machine learning models for OPF, with
the goal of standardizing performance evaluation across the field. By promoting
open, standardized datasets and evaluation metrics, PGLearn aims at
democratizing and accelerating research and innovation in machine learning
applications for optimal power flow problems. Datasets are available for
download at https://www.huggingface.co/PGLearn.

</details>


### [24] [X-Factor: Quality Is a Dataset-Intrinsic Property](https://arxiv.org/abs/2505.22813)
*Josiah Couch, Miao Li, Rima Arnaout, Ramy Arnaout*

**主要类别:** cs.LG

**概要:** 在优化机器学习分类器的普遍追求中，研究发现数据集质量是独立于数据集大小、类别平衡和模型架构的一个重要因素。本研究通过创建数千个控制了大小和类别平衡的数据集，并使用多种架构的分类器进行训练，发现分类器性能与子集在不同架构间强烈相关（$R^2=0.79$），这表明质量是数据集本身的一种内在属性。进一步分析显示，数据集质量似乎是其组成类别的质量的一种涌现属性。因此，质量作为独立因素加入大小、类别平衡和模型架构，成为优化机器学习分类性能的单独目标。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已知模型架构、数据集大小和类别平衡会影响测试时的性能，但这些因素并不能完全解释性能差异。之前的研究提出了数据集质量这一额外因素，但尚不清楚它是数据集和模型架构的联合属性还是数据集本身的内在属性。

**方法:** 创建了数千个控制了大小和类别平衡的数据集，并用这些数据集训练具有广泛架构的分类器，包括随机森林、支持向量机和深度网络等。然后分析不同架构下分类器性能的相关性，以评估数据集质量是否为数据集的内在属性。

**结果:** 发现分类器性能在不同架构间与子集强烈相关（$R^2=0.79$），这表明数据集质量是独立于数据集大小、类别平衡和模型架构的内在属性。进一步研究还发现，数据集质量似乎是其组成类别的质量的一种涌现属性。

**结论:** 数据集质量是影响机器学习分类器性能的一个独立因素，应作为优化分类性能的单独目标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X-Factor%3A+Quality+Is+a+Dataset-Intrinsic+Property，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22813，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22813&send_immediately=true&force_search=false)

**原文摘要:** In the universal quest to optimize machine-learning classifiers, three
factors -- model architecture, dataset size, and class balance -- have been
shown to influence test-time performance but do not fully account for it.
Previously, evidence was presented for an additional factor that can be
referred to as dataset quality, but it was unclear whether this was actually a
joint property of the dataset and the model architecture, or an intrinsic
property of the dataset itself. If quality is truly dataset-intrinsic and
independent of model architecture, dataset size, and class balance, then the
same datasets should perform better (or worse) regardless of these other
factors. To test this hypothesis, here we create thousands of datasets, each
controlled for size and class balance, and use them to train classifiers with a
wide range of architectures, from random forests and support-vector machines to
deep networks. We find that classifier performance correlates strongly by
subset across architectures ($R^2=0.79$), supporting quality as an intrinsic
property of datasets independent of dataset size and class balance and of model
architecture. Digging deeper, we find that dataset quality appears to be an
emergent property of something more fundamental: the quality of datasets'
constituent classes. Thus, quality joins size, class balance, and model
architecture as an independent correlate of performance and a separate target
for optimizing machine-learning-based classification.

</details>


### [25] [Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies](https://arxiv.org/abs/2505.22829)
*Chenruo Liu, Kenan Tang, Yao Qin, Qi Lei*

**主要类别:** cs.LG

**概要:** This paper connects distribution shift and AI safety by showing how methods for specific shifts can address safety goals and how certain shifts and safety issues can be formally related, promoting integration between the two fields.


<details>
  <summary>更多</summary>
  
**动机:** To bridge the gap between distribution shift and AI safety through a comprehensive analysis and establish conceptual and methodological synergies.

**方法:** Establishing two types of connections: (1) methods addressing specific shifts help achieve safety goals, and (2) certain shifts and safety issues can be formally reduced to each other.

**结果:** Provided a unified perspective that encourages fundamental integration between distribution shift and AI safety research.

**结论:** The analysis promotes a deeper integration between distribution shift and AI safety, providing a framework for future research in both areas.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+Distribution+Shift+and+AI+Safety%3A+Conceptual+and+Methodological+Synergies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22829，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22829&send_immediately=true&force_search=false)

**原文摘要:** This paper bridges distribution shift and AI safety through a comprehensive
analysis of their conceptual and methodological synergies. While prior
discussions often focus on narrow cases or informal analogies, we establish two
types connections between specific causes of distribution shift and
fine-grained AI safety issues: (1) methods addressing a specific shift type can
help achieve corresponding safety goals, or (2) certain shifts and safety
issues can be formally reduced to each other, enabling mutual adaptation of
their methods. Our findings provide a unified perspective that encourages
fundamental integration between distribution shift and AI safety research.

</details>


### [26] [Preference Learning with Response Time](https://arxiv.org/abs/2505.22820)
*Ayush Sawarni, Sahasrajit Sarmasarkar, Vasilis Syrgkanis*

**主要类别:** cs.LG

**概要:** 这篇论文研究了将反应时间数据整合到人类偏好学习框架中，以更有效地提取奖励模型。提出了一种新的方法，结合二元选择数据和反应时间信息，并通过Neyman-正交损失函数实现理论最优收敛率。实验验证了在图像偏好学习中的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的偏好学习主要依赖于二元偏好数据，但用户决策中的宝贵时间信息尚未被充分利用。

**方法:** 提出了基于Evidence Accumulation Drift Diffusion (EZ)模型的新方法，将反应时间信息与二元选择数据结合。开发了Neyman-正交损失函数，实现了理论上的最优收敛率。

**结果:** 理论上证明了对于线性奖励函数，传统方法的误差随奖励大小呈指数增长，而新方法降低为多项式增长，显著提高了样本效率。实验结果验证了理论发现。

**结论:** 将反应时间数据整合到偏好学习框架中可以显著提高奖励模型学习的有效性和样本效率，适用于更复杂的奖励函数空间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preference+Learning+with+Response+Time，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22820，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22820&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the integration of response time data into human
preference learning frameworks for more effective reward model elicitation.
While binary preference data has become fundamental in fine-tuning foundation
models, generative AI systems, and other large-scale models, the valuable
temporal information inherent in user decision-making remains largely
unexploited. We propose novel methodologies to incorporate response time
information alongside binary choice data, leveraging the Evidence Accumulation
Drift Diffusion (EZ) model, under which response time is informative of the
preference strength. We develop Neyman-orthogonal loss functions that achieve
oracle convergence rates for reward model learning, matching the theoretical
optimal rates that would be attained if the expected response times for each
query were known a priori. Our theoretical analysis demonstrates that for
linear reward functions, conventional preference learning suffers from error
rates that scale exponentially with reward magnitude. In contrast, our response
time-augmented approach reduces this to polynomial scaling, representing a
significant improvement in sample efficiency. We extend these guarantees to
non-parametric reward function spaces, establishing convergence properties for
more complex, realistic reward models. Our extensive experiments validate our
theoretical findings in the context of preference learning over images.

</details>


### [27] [How Do Diffusion Models Improve Adversarial Robustness?](https://arxiv.org/abs/2505.22839)
*Liu Yuezhang, Xue-Xin Wei*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Do+Diffusion+Models+Improve+Adversarial+Robustness%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22839，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22839&send_immediately=true&force_search=false)

**原文摘要:** Recent findings suggest that diffusion models significantly enhance empirical
adversarial robustness. While some intuitive explanations have been proposed,
the precise mechanisms underlying these improvements remain unclear. In this
work, we systematically investigate how and how well diffusion models improve
adversarial robustness. First, we observe that diffusion models intriguingly
increase, rather than decrease, the $\ell_p$ distance to clean
samples--challenging the intuition that purification denoises inputs closer to
the original data. Second, we find that the purified images are heavily
influenced by the internal randomness of diffusion models, where a compression
effect arises within each randomness configuration. Motivated by this
observation, we evaluate robustness under fixed randomness and find that the
improvement drops to approximately 24% on CIFAR-10--substantially lower than
prior reports approaching 70%. Importantly, we show that this remaining
robustness gain strongly correlates with the model's ability to compress the
input space, revealing the compression rate as a reliable robustness indicator
without requiring gradient-based analysis. Our findings provide novel insights
into the mechanisms underlying diffusion-based purification, and offer guidance
for developing more effective and principled adversarial purification systems.

</details>


### [28] [RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation](https://arxiv.org/abs/2505.22846)
*Nikita Khramov, Andrei Kozyrev, Gleb Solovev, Anton Podkopaev*

**主要类别:** cs.LG

**概要:** 本文探讨了将交互式定理证明与生成式人工智能结合的多种方法，并提出了一种基于自注意力嵌入模型的改进前提选择方法，从而提升Rocq生成性能达28%。此外，还设计了一个多阶段代理系统用于形式验证，展示了其高效性并研究了多代理辩论在证明合成规划阶段的应用。


<details>
  <summary>更多</summary>
  
**动机:** 交互式定理证明与生成式人工智能的结合已被证明是富有成效的，但现有的Rocq生成方法仍存在改进空间，特别是在前提选择方面。

**方法:** 1. 提出一种基于自注意力嵌入模型的检索方法以优化前提选择。
2. 设计一个多阶段代理系统专门用于形式验证。
3. 进行消融研究，探索多代理辩论在证明合成规划阶段的作用。

**结果:** 1. 新方法使生成器性能相对提升了28%。
2. 多阶段代理系统在形式验证中表现出高有效性。
3. 多代理辩论在证明合成规划阶段具有积极作用。

**结论:** 彻底的前提选择对生成Rocq证明至关重要，提出的基于自注意力嵌入模型的方法显著提高了生成性能，而多阶段代理系统和多代理辩论进一步增强了形式验证的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RocqStar%3A+Leveraging+Similarity-driven+Retrieval+and+Agentic+Systems+for+Rocq+generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22846，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22846&send_immediately=true&force_search=false)

**原文摘要:** Interactive Theorem Proving was repeatedly shown to be fruitful combined with
Generative Artificial Intelligence. This paper assesses multiple approaches to
Rocq generation and illuminates potential avenues for improvement. We highlight
the importance of thorough premise selection for generating Rocq proofs and
propose a novel approach, leveraging retrieval via a self-attentive embedder
model. The evaluation of the designed approach shows up to 28% relative
increase of the generator's performance. We tackle the problem of writing Rocq
proofs using a multi-stage agentic system, tailored for formal verification,
and demonstrate its high effectiveness. We conduct an ablation study and show
the use of multi-agent debate on the planning stage of proof synthesis.

</details>


### [29] [Scaling Offline RL via Efficient and Expressive Shortcut Models](https://arxiv.org/abs/2505.22866)
*Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun*

**主要类别:** cs.LG

**概要:** 扩散和流模型在离线强化学习中的应用面临挑战。本文提出了SORL算法，利用快捷模型进行训练和推理扩展，实现高效的一阶段训练，并通过学习的Q函数作为验证器引入顺序和平行推理扩展。实验表明，SORL在离线RL任务中表现出色并具有良好的计算扩展性。


<details>
  <summary>更多</summary>
  
**动机:** 扩散和流模型虽然强大，但其噪声采样过程的迭代性质使得在离线强化学习中的策略优化变得困难。

**方法:** 提出SORL算法，使用快捷模型来扩展训练和推理，策略能够捕捉复杂的数据分布，并且可以通过一阶段训练程序简单高效地训练。测试时，通过将学习到的Q函数作为验证器，引入顺序和平行推理扩展。

**结果:** SORL在一系列离线RL任务中表现出强大的性能，并展现出随着测试时计算量增加而具有的正向扩展行为。

**结论:** SORL算法有效地解决了离线强化学习中策略优化的难题，展现了良好的性能和计算扩展性，代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Offline+RL+via+Efficient+and+Expressive+Shortcut+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22866，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22866&send_immediately=true&force_search=false)

**原文摘要:** Diffusion and flow models have emerged as powerful generative approaches
capable of modeling diverse and multimodal behavior. However, applying these
models to offline reinforcement learning (RL) remains challenging due to the
iterative nature of their noise sampling processes, making policy optimization
difficult. In this paper, we introduce Scalable Offline Reinforcement Learning
(SORL), a new offline RL algorithm that leverages shortcut models - a novel
class of generative models - to scale both training and inference. SORL's
policy can capture complex data distributions and can be trained simply and
efficiently in a one-stage training procedure. At test time, SORL introduces
both sequential and parallel inference scaling by using the learned Q-function
as a verifier. We demonstrate that SORL achieves strong performance across a
range of offline RL tasks and exhibits positive scaling behavior with increased
test-time compute. We release the code at
nico-espinosadice.github.io/projects/sorl.

</details>


### [30] [Defining Foundation Models for Computational Science: A Call for Clarity and Rigor](https://arxiv.org/abs/2505.22904)
*Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss*

**主要类别:** cs.LG

**概要:** 这篇论文探讨了基础模型在计算科学中的应用，提出了一个正式定义，并引入了数据驱动的有限元方法（DD-FEM）作为实现基础模型的框架。


<details>
  <summary>更多</summary>
  
**动机:** 基础模型在自然语言处理和计算机视觉中取得了广泛的成功，启发了研究者将其概念扩展到科学机器学习和计算科学领域。然而，术语“基础模型”作为一个不断发展的概念，在计算科学中的应用缺乏普遍接受的定义，可能导致混淆和稀释其科学意义。

**方法:** 作者提出了一种基于通用性、可重用性和可扩展性的正式定义来描述计算科学中的基础模型，并阐述了这些模型必须具备的关键和期望特性。此外，还介绍了数据驱动的有限元方法（DD-FEM），该方法将经典有限元方法的模块化结构与数据驱动学习的表现力相结合。

**结果:** DD-FEM解决了实现计算科学基础模型的一些关键挑战，如可扩展性、适应性和物理一致性。它为评估和发展未来的计算科学基础模型提供了严格的理论基础。

**结论:** 通过结合传统数值方法与现代人工智能范式，本文为计算科学中的基础模型提供了一个严谨的评价和发展框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Defining+Foundation+Models+for+Computational+Science%3A+A+Call+for+Clarity+and+Rigor，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22904，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22904&send_immediately=true&force_search=false)

**原文摘要:** The widespread success of foundation models in natural language processing
and computer vision has inspired researchers to extend the concept to
scientific machine learning and computational science. However, this position
paper argues that as the term "foundation model" is an evolving concept, its
application in computational science is increasingly used without a universally
accepted definition, potentially creating confusion and diluting its precise
scientific meaning. In this paper, we address this gap by proposing a formal
definition of foundation models in computational science, grounded in the core
values of generality, reusability, and scalability. We articulate a set of
essential and desirable characteristics that such models must exhibit, drawing
parallels with traditional foundational methods, like the finite element and
finite volume methods. Furthermore, we introduce the Data-Driven Finite Element
Method (DD-FEM), a framework that fuses the modular structure of classical FEM
with the representational power of data-driven learning. We demonstrate how
DD-FEM addresses many of the key challenges in realizing foundation models for
computational science, including scalability, adaptability, and physics
consistency. By bridging traditional numerical methods with modern AI
paradigms, this work provides a rigorous foundation for evaluating and
developing novel approaches toward future foundation models in computational
science.

</details>


### [31] [Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction](https://arxiv.org/abs/2505.22840)
*Dharambir Mahto, Prashant Yadav, Mahesh Banavar, Jim Keany, Alan T Joseph, Srinivas Kilambi*

**主要类别:** cs.LG

**概要:** Sepsis预测仍具挑战性。本研究通过SXI++ LNM系统改进了临床应用中的鲁棒性，并评估其性能。该模型在三个用例中超越现有最佳技术，AUC达到0.99，精度和准确度分别达99.9%和99.99%。


<details>
  <summary>更多</summary>
  
**动机:** 败血症是一种威胁生命的状况，影响全球超过4890万人，每年导致1100万人死亡。尽管医学进步，但由于症状不具体和复杂的病理生理学，预测败血症仍然是一项挑战。

**方法:** SXI++ LNM是一个利用多种算法和深度神经网络的机器学习评分系统，用于改进败血症预测。该研究使用不同数据集分布的多个场景训练和测试了基于深度神经网络的模型。

**结果:** SXI++ LNM在三个用例中超越现有最佳技术，AUC为0.99（95% CI：0.98-1.00），精度为99.9%（95% CI：99.8-100.0），准确度为99.99%（95% CI：99.98-100.0）。

**结论:** SXI++ LNM显著提高了败血症预测的性能，在不同应用场景下表现出高可靠性，适合临床应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Development+and+Validation+of+SXI%2B%2B+LNM+Algorithm+for+Sepsis+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22840，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22840&send_immediately=true&force_search=false)

**原文摘要:** Sepsis is a life-threatening condition affecting over 48.9 million people
globally and causing 11 million deaths annually. Despite medical advancements,
predicting sepsis remains a challenge due to non-specific symptoms and complex
pathophysiology. The SXI++ LNM is a machine learning scoring system that
refines sepsis prediction by leveraging multiple algorithms and deep neural
networks. This study aims to improve robustness in clinical applications and
evaluates the predictive performance of the SXI++ LNM for sepsis prediction.
The model, utilizing a deep neural network, was trained and tested using
multiple scenarios with different dataset distributions. The model's
performance was assessed against unseen test data, and accuracy, precision, and
area under the curve (AUC) were calculated. THE SXI++ LNM outperformed the
state of the art in three use cases, achieving an AUC of 0.99 (95% CI:
0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0)
and an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.

</details>


### [32] [Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking](https://arxiv.org/abs/2505.22922)
*Athanasios Glentis, Jiaxiang Li, Qiulin Shang, Andi Han, Ioannis Tsaknakis, Quan Wei, Mingyi Hong*

**主要类别:** cs.LG

**概要:** 为了应对大语言模型（LLMs）训练和微调中的计算挑战，本文探讨了参数或内存高效方法是否可以在保持与完整模型训练相当性能的同时提升预训练效率。研究通过全面调查、基准评估以及提出两种实用技术（权重重构和动量重置），发现低秩方法结合高秩更新能有效缩小性能差距，并在减少约25%内存使用的情况下超越其他流行算法。


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型的快速发展带来了显著的计算挑战，尤其是预训练阶段需要处理庞大的数据集，这对内存和计算资源提出了更高要求。尽管现有方法如LoRA在微调中表现良好，但它们在预训练中的应用仍面临巨大挑战。因此，研究者希望探索参数或内存高效的预训练方法，以实现与完整模型训练相媲美的性能。

**方法:** 1. 进行全面调查，总结当前最先进的高效预训练方法。
2. 对多个具有代表性的内存高效预训练方法进行基准评估，分析其在不同模型尺寸下的性能。
3. 提出两种实用技术：权重重构和动量重置，以改进低秩方法的性能。
4. 通过实验验证这些技术的有效性，特别是在10亿参数模型上的应用。

**结果:** 研究发现，选择合适的优化器和超参数时，全秩训练表现出最佳性能。同时，在低秩方法中引入高秩更新是提高其性能的关键。提出的权重重构和动量重置技术进一步增强了低秩方法的性能，使其在使用更少内存的情况下达到更低的困惑度，优于GaLore和Fira等流行算法。

**结论:** 参数或内存高效的预训练方法确实可以提高预训练效率，同时达到与完整模型训练相近的性能。通过采用适当的优化策略和技术改进，可以有效缩小性能差距并降低资源消耗。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Parameter+and+Memory+Efficient+Pretraining+for+LLM%3A+Recent+Algorithmic+Advances+and+Benchmarking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22922，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22922&send_immediately=true&force_search=false)

**原文摘要:** Fueled by their remarkable ability to tackle diverse tasks across multiple
domains, large language models (LLMs) have grown at an unprecedented rate, with
some recent models containing trillions of parameters. This growth is
accompanied by substantial computational challenges, particularly regarding the
memory and compute resources required for training and fine-tuning. Numerous
approaches have been explored to address these issues, such as LoRA. While
these methods are effective for fine-tuning, their application to pre-training
is significantly more challenging due to the need to learn vast datasets.
Motivated by this issue, we aim to address the following questions: Can
parameter- or memory-efficient methods enhance pre-training efficiency while
achieving performance comparable to full-model training? How can the
performance gap be narrowed? To this end, the contributions of this work are
the following. (1) We begin by conducting a comprehensive survey that
summarizes state-of-the-art methods for efficient pre-training. (2) We perform
a benchmark evaluation of several representative memory efficient pre-training
approaches to comprehensively evaluate their performance across model sizes. We
observe that with a proper choice of optimizer and hyperparameters, full-rank
training delivers the best performance, as expected. We also notice that
incorporating high-rank updates in low-rank approaches is the key to improving
their performance. (3) Finally, we propose two practical techniques, namely
weight refactorization and momentum reset, to enhance the performance of
efficient pre-training methods. We observe that applying these techniques to
the low-rank method (on a 1B model) can achieve a lower perplexity than popular
memory efficient algorithms such as GaLore and Fira, while simultaneously using
about 25% less memory.

</details>


### [33] [EquiReg: Equivariance Regularized Diffusion for Inverse Problems](https://arxiv.org/abs/2505.22973)
*Bahareh Tolooshams, Aditi Chandrashekar, Rayhan Zirvi, Abbas Mammadov, Jiachen Yao, Chuwei Wang, Anima Anandkumar*

**主要类别:** cs.LG

**概要:** Diffusion models are top for inverse problems but face challenges with likelihood terms. This paper proposes EquiReg, a framework that regularizes posterior sampling in diffusion-based solvers by reweighting trajectories and penalizing deviations from the data manifold, leading to better reconstructions.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of inconsistent and unstable reconstructions caused by isotropic Gaussian approximations in current diffusion-based inverse problem solvers.

**方法:** Propose EquiReg diffusion, which regularizes posterior sampling by reweighting diffusion trajectories and penalizing deviations from the data manifold using distribution-dependent equivariance error functions.

**结果:** EquiReg outperforms state-of-the-art diffusion models in linear and nonlinear image restoration tasks as well as in reconstructing partial differential equations.

**结论:** EquiReg is a promising framework for enhancing reconstructions in diffusion-based inverse problem solvers.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EquiReg%3A+Equivariance+Regularized+Diffusion+for+Inverse+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22973，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22973&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models represent the state-of-the-art for solving inverse problems
such as image restoration tasks. In the Bayesian framework, diffusion-based
inverse solvers incorporate a likelihood term to guide the prior sampling
process, generating data consistent with the posterior distribution. However,
due to the intractability of the likelihood term, many current methods rely on
isotropic Gaussian approximations, which lead to deviations from the data
manifold and result in inconsistent, unstable reconstructions. We propose
Equivariance Regularized (EquiReg) diffusion, a general framework for
regularizing posterior sampling in diffusion-based inverse problem solvers.
EquiReg enhances reconstructions by reweighting diffusion trajectories and
penalizing those that deviate from the data manifold. We define a new
distribution-dependent equivariance error, empirically identify functions that
exhibit low error for on-manifold samples and higher error for off-manifold
samples, and leverage these functions to regularize the diffusion sampling
process. When applied to a variety of solvers, EquiReg outperforms
state-of-the-art diffusion models in both linear and nonlinear image
restoration tasks, as well as in reconstructing partial differential equations.

</details>


### [34] [Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition](https://arxiv.org/abs/2505.22985)
*Masaharu Kagiyama, Tsuyoshi Okita*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种名为PatchEchoClassifier的新模型，该模型通过回声状态网络（ESN）的水库计算机制，结合知识蒸馏框架，实现了高效的时序数据分类任务。实验表明，与DeepConvLSTM相比，PatchEchoClassifier在保持80%以上准确率的同时，将计算成本显著降低至约六分之一，为边缘计算环境中实时、节能的人体活动识别提供了一种有前景的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 当前在人体活动识别（HAR）领域中使用的深度学习模型虽然性能较高，但通常计算复杂度高、能耗大，难以满足边缘计算设备对实时性和低功耗的需求。因此，需要一种既能保证分类精度又能显著降低计算开销的新型方法。

**方法:** 论文提出了一种新模型PatchEchoClassifier，利用回声状态网络（ESN）作为核心机制，并结合tokenizer提取传感器信号的patch-level特征表示。为了高效训练这一轻量级模型，作者设计了一种知识蒸馏框架，通过从一个高容量的MLP-Mixer教师模型向学生模型转移知识来优化性能。

**结果:** 在多个HAR数据集上的实验结果表明，PatchEchoClassifier能够达到超过80%的分类准确率，同时大幅减少计算成本。具体而言，其浮点运算次数（FLOPS）仅为广泛使用的DeepConvLSTM基线模型的大约六分之一。

**结论:** PatchEchoClassifier作为一种新颖的、基于水库计算的模型，不仅具有较高的分类精度，还能显著降低计算资源需求，是一种适用于边缘计算环境下的高效、节能的人体活动识别解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Knowledge+Distillation+for+Reservoir-based+Classifier%3A+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22985，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22985&send_immediately=true&force_search=false)

**原文摘要:** This paper aims to develop an energy-efficient classifier for time-series
data by introducing PatchEchoClassifier, a novel model that leverages a
reservoir-based mechanism known as the Echo State Network (ESN). The model is
designed for human activity recognition (HAR) using one-dimensional sensor
signals and incorporates a tokenizer to extract patch-level representations. To
train the model efficiently, we propose a knowledge distillation framework that
transfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight
reservoir-based student model. Experimental evaluations on multiple HAR
datasets demonstrate that our model achieves over 80 percent accuracy while
significantly reducing computational cost. Notably, PatchEchoClassifier
requires only about one-sixth of the floating point operations (FLOPS) compared
to DeepConvLSTM, a widely used convolutional baseline. These results suggest
that PatchEchoClassifier is a promising solution for real-time and
energy-efficient human activity recognition in edge computing environments.

</details>


### [35] [Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel](https://arxiv.org/abs/2505.22861)
*Carlota Parés-Morlans, Michelle Yi, Claire Chen, Sarah A. Wu, Rika Antonova, Tobias Gerstenberg, Jeannette Bohg*

**主要类别:** cs.LG

**概要:** Causal-PIK是一种利用贝叶斯优化和物理信息核的方法，用于推理因果交互并高效搜索最佳下一步动作。实验表明，在虚拟工具和物理推理基准测试中，Causal-PIK优于现有方法，并且在极具挑战性的任务上表现与人类相当。


<details>
  <summary>更多</summary>
  
**动机:** 涉及复杂对象交互的任务难以提前规划，需要智能体通过探索环境中的因果关系来迭代改进动作。

**方法:** 提出了一种名为Causal-PIK的方法，该方法结合贝叶斯优化和物理信息核，用于推理因果关系并指导对最佳下一步动作的高效搜索。

**结果:** 在Virtual Tools和PHYRE物理推理基准测试中，Causal-PIK相比现有技术表现出色，达到目标所需的行动更少。此外，在与人类表现的比较中，Causal-PIK在非常具有挑战性的任务上保持竞争力。

**结论:** Causal-PIK方法能够有效解决复杂的因果推理任务，其性能不仅优于现有方法，还能在高难度任务上媲美人类问题解决者。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal-PIK%3A+Causality-based+Physical+Reasoning+with+a+Physics-Informed+Kernel，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22861，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22861&send_immediately=true&force_search=false)

**原文摘要:** Tasks that involve complex interactions between objects with unknown dynamics
make planning before execution difficult. These tasks require agents to
iteratively improve their actions after actively exploring causes and effects
in the environment. For these type of tasks, we propose Causal-PIK, a method
that leverages Bayesian optimization to reason about causal interactions via a
Physics-Informed Kernel to help guide efficient search for the best next
action. Experimental results on Virtual Tools and PHYRE physical reasoning
benchmarks show that Causal-PIK outperforms state-of-the-art results, requiring
fewer actions to reach the goal. We also compare Causal-PIK to human studies,
including results from a new user study we conducted on the PHYRE benchmark. We
find that Causal-PIK remains competitive on tasks that are very challenging,
even for human problem-solvers.

</details>


### [36] [Model-Preserving Adaptive Rounding](https://arxiv.org/abs/2505.22988)
*Albert Tseng, Zhaofeng Sun, Christopher De Sa*

**主要类别:** cs.LG

**概要:** 论文提出了一种新的量化算法YAQA，相较于传统方法能更有效地减少与原始模型的KL散度，并在下游任务中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 当前的后训练量化（PTQ）算法通常通过独立最小化直接激活误差来量化线性层，但这种方法忽略了后续层的影响，因此可能无法产生接近原模型的压缩模型。

**方法:** 引入了YAQA算法，该算法利用Kronecker分解近似每个线性层相对于完整模型KL散度的Hessian矩阵。YAQA包含两个部分：1）可计算的Kronecker分解草图，用于估计完整的逐层Hessian矩阵；2）一种与量化器无关的自适应舍入算法，具有理论保证。

**结果:** 实验表明，YAQA在各种模型和量化器上将KL散度减少了约30%，并在下游任务中达到最先进的性能。

**结论:** YAQA为大型语言模型的量化提供了一种有效的方法，显著降低了与原始模型的KL散度并保持了任务性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model-Preserving+Adaptive+Rounding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22988，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22988&send_immediately=true&force_search=false)

**原文摘要:** The main goal of post-training quantization (PTQ) is to produced a compressed
model whose output distribution is as close to the original model's as
possible. To do this tractably, almost all LLM PTQ algorithms quantize linear
layers by independently minimizing the immediate activation error. However,
this localized objective ignores the effect of subsequent layers, so reducing
it does not necessarily give a closer model. In this work, we introduce Yet
Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses
Kronecker-factored approximations of each linear layer's Hessian with respect
to the \textit{full model} KL divergence. YAQA consists of two components:
Kronecker-factored sketches of the full layerwise Hessian that can be tractably
computed for hundred-billion parameter LLMs, and a quantizer-independent
rounding algorithm that uses these sketches and comes with theoretical
guarantees. Across a wide range of models and quantizers, YAQA empirically
reduces the KL divergence to the original model by $\approx 30\%$ while
achieving state of the art performance on downstream tasks.

</details>


### [37] [Hybrid Cross-domain Robust Reinforcement Learning](https://arxiv.org/abs/2505.23003)
*Linh Le Pham Van, Minh Hoang Nguyen, Hung Le, Hung The Tran, Sunil Gupta*

**主要类别:** cs.LG

**概要:** 本文提出了一种名为HYDRO的混合跨域鲁棒强化学习框架，用于解决线下鲁棒RL中的数据限制和动态不匹配问题。通过结合在线模拟器与离线数据集，并采用新颖的不确定性过滤和优先采样方法，HYDRO在多种任务中展现出优于现有方法的表现，提高了样本效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的鲁棒强化学习方法需要大量的离线数据，而收集这些数据既昂贵又耗时。同时，使用不完美的模拟器虽然更经济高效，但可能存在动态不匹配的问题。因此，需要一种能够有效利用有限离线数据并缓解模拟器与实际环境之间差异的方法。

**方法:** 研究提出了HYDRO框架，该框架结合了在线模拟器和有限的离线数据集，以应对鲁棒强化学习中的挑战。具体而言，HYDRO通过测量和最小化模拟器与最坏情况模型之间的性能差距，采用不确定性过滤和优先采样的技术选择最相关和可靠的模拟器样本。

**结果:** 实验结果表明，HYDRO在各种任务上均优于现有的方法，证明了其在提高线下鲁棒强化学习样本效率方面的潜力。

**结论:** HYDRO作为一种创新的混合跨域鲁棒强化学习框架，成功地解决了线下鲁棒RL中的数据不足和动态不匹配问题，为提高样本效率提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hybrid+Cross-domain+Robust+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23003，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23003&send_immediately=true&force_search=false)

**原文摘要:** Robust reinforcement learning (RL) aims to learn policies that remain
effective despite uncertainties in its environment, which frequently arise in
real-world applications due to variations in environment dynamics. The robust
RL methods learn a robust policy by maximizing value under the worst-case
models within a predefined uncertainty set. Offline robust RL algorithms are
particularly promising in scenarios where only a fixed dataset is available and
new data cannot be collected. However, these approaches often require extensive
offline data, and gathering such datasets for specific tasks in specific
environments can be both costly and time-consuming. Using an imperfect
simulator offers a faster, cheaper, and safer way to collect data for training,
but it can suffer from dynamics mismatch. In this paper, we introduce HYDRO,
the first Hybrid Cross-Domain Robust RL framework designed to address these
challenges. HYDRO utilizes an online simulator to complement the limited amount
of offline datasets in the non-trivial context of robust RL. By measuring and
minimizing performance gaps between the simulator and the worst-case models in
the uncertainty set, HYDRO employs novel uncertainty filtering and prioritized
sampling to select the most relevant and reliable simulator samples. Our
extensive experiments demonstrate HYDRO's superior performance over existing
methods across various tasks, underscoring its potential to improve sample
efficiency in offline robust RL.

</details>


### [38] [$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2505.23017)
*Xingjian Wu, Xiangfei Qiu, Hongfan Gao, Jilin Hu, Bin Yang, Chenjuan Guo*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为$K^2$VAE的模型，通过将非线性时间序列转换为线性动力系统并优化预测，有效提升了长短期概率时间序列预测的效率与准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的概率时间序列预测方法在短期预测中表现出色，但在长期预测方面存在不足，主要挑战包括非线性动态对预测精度的不利影响以及生成模型在每次迭代中的成本增加问题。

**方法:** 引入了$K^2$VAE模型，利用KoopmanNet将非线性时间序列转化为线性动力系统，并采用KalmanNet优化预测和建模不确定性以减少长期预测中的误差累积。

**结果:** 大量实验表明，$K^2$VAE在短期和长期的概率时间序列预测中均优于现有最先进方法，提供了一种更高效和准确的解决方案。

**结论:** $K^2$VAE是一种有效的生成模型，能够显著改善长短期概率时间序列预测的性能，为相关领域提供了更优的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%24K%5E2%24VAE%3A+A+Koopman-Kalman+Enhanced+Variational+AutoEncoder+for+Probabilistic+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23017&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic Time Series Forecasting (PTSF) plays a crucial role in
decision-making across various fields, including economics, energy, and
transportation. Most existing methods excell at short-term forecasting, while
overlooking the hurdles of Long-term Probabilistic Time Series Forecasting
(LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have
a significant adverse effect on prediction accuracy, and make generative models
inefficient by increasing the cost of each iteration. To overcome these
limitations, we introduce $K^2$VAE, an efficient VAE-based generative model
that leverages a KoopmanNet to transform nonlinear time series into a linear
dynamical system, and devises a KalmanNet to refine predictions and model
uncertainty in such linear system, which reduces error accumulation in
long-term forecasting. Extensive experiments demonstrate that $K^2$VAE
outperforms state-of-the-art methods in both short- and long-term PTSF,
providing a more efficient and accurate solution.

</details>


### [39] [On the Dynamic Regret of Following the Regularized Leader: Optimism with History Pruning](https://arxiv.org/abs/2505.22899)
*Naram Mhaisen, George Iosifidis*

**主要类别:** cs.LG

**概要:** 通过乐观组合未来成本和仔细线性化过去成本，FTRL可以在动态环境中实现已知的动态后悔界。


<details>
  <summary>更多</summary>
  
**动机:** 重新审视FTRL框架在动态环境下的表现，并解决其在动态后悔保证方面的局限性。

**方法:** 利用乐观组合未来成本和线性化过去成本的方法，使FTRL能够更好地适应动态环境并实现动态后悔界的恢复。

**结果:** 提出了一种新的分析方法，可以插值贪婪和敏捷更新，并提供了对后悔项的精细控制，消除了乐观主义中的循环依赖，并应用了类似于AdaFTRL的最小递归正则化。

**结论:** FTRL在动态后悔方面的问题并非源于懒惰投影风格，而是算法状态与迭代的解耦。修剪可以使两者在必要时同步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Dynamic+Regret+of+Following+the+Regularized+Leader%3A+Optimism+with+History+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22899&send_immediately=true&force_search=false)

**原文摘要:** We revisit the Follow the Regularized Leader (FTRL) framework for Online
Convex Optimization (OCO) over compact sets, focusing on achieving dynamic
regret guarantees. Prior work has highlighted the framework's limitations in
dynamic environments due to its tendency to produce "lazy" iterates. However,
building on insights showing FTRL's ability to produce "agile" iterates, we
show that it can indeed recover known dynamic regret bounds through optimistic
composition of future costs and careful linearization of past costs, which can
lead to pruning some of them. This new analysis of FTRL against dynamic
comparators yields a principled way to interpolate between greedy and agile
updates and offers several benefits, including refined control over regret
terms, optimism without cyclic dependence, and the application of minimal
recursive regularization akin to AdaFTRL. More broadly, we show that it is not
the lazy projection style of FTRL that hinders (optimistic) dynamic regret, but
the decoupling of the algorithm's state (linearized history) from its iterates,
allowing the state to grow arbitrarily. Instead, pruning synchronizes these two
when necessary.

</details>


### [40] [Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift](https://arxiv.org/abs/2505.23027)
*Minh Nguyen Nhat To, Paul F RWilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul G. Krishnan*

**主要类别:** cs.LG

**概要:** To tackle subpopulation shift without assumptions about subpopulations or annotations on group membership, the paper proposes Diverse Prototypical Ensembles (DPEs), an ensemble of diverse classifiers that often outperforms prior state-of-the-art methods in worst-group accuracy.


<details>
  <summary>更多</summary>
  
**动机:** The motivation is to address the issue of subpopulation shift which can degrade machine learning model performance. Current solutions require assumptions and annotations not always available in real-world datasets.

**方法:** The method involves using an ensemble of diverse classifiers called Diverse Prototypical Ensembles (DPEs). A feature extractor network's classification layer is replaced with a mixture of prototypical classifiers, each focusing on different features and samples.

**结果:** Empirical evaluations on nine real-world datasets show that DPEs often outperform prior state-of-the-art methods in worst-group accuracy across diverse domains and kinds of subpopulation shift.

**结论:** DPEs provide a promising approach to handle subpopulation shift without relying on specific assumptions or annotations, offering improved performance in worst-group accuracy.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diverse+Prototypical+Ensembles+Improve+Robustness+to+Subpopulation+Shift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23027，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23027&send_immediately=true&force_search=false)

**原文摘要:** The subpopulationtion shift, characterized by a disparity in subpopulation
distributibetween theween the training and target datasets, can significantly
degrade the performance of machine learning models. Current solutions to
subpopulation shift involve modifying empirical risk minimization with
re-weighting strategies to improve generalization. This strategy relies on
assumptions about the number and nature of subpopulations and annotations on
group membership, which are unavailable for many real-world datasets. Instead,
we propose using an ensemble of diverse classifiers to adaptively capture risk
associated with subpopulations. Given a feature extractor network, we replace
its standard linear classification layer with a mixture of prototypical
classifiers, where each member is trained to classify the data while focusing
on different features and samples from other members. In empirical evaluation
on nine real-world datasets, covering diverse domains and kinds of
subpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often
outperforms the prior state-of-the-art in worst-group accuracy. The code is
available at https://github.com/minhto2802/dpe4subpop

</details>


### [41] [Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks](https://arxiv.org/abs/2505.23032)
*Dongwoo Lee, Dong Bok Lee, Steven Adriaensen, Juho Lee, Sung Ju Hwang, Frank Hutter, Seon Joo Kim, Hae Beom Lee*

**主要类别:** cs.LG

**概要:** 本研究提出了一种基于贝叶斯框架的Prior-data Fitted Networks (PFNs)方法，用于神经网络扩展规律的外推。通过设计先验分布，该方法能够模拟无数类似现实世界神经扩展规律的合成函数，从而实现元学习外推。实验表明，在数据有限的情况下（如贝叶斯主动学习），该方法优于现有的点估计和贝叶斯方法，具有可靠的不确定性感知能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的扩展规律研究主要依赖点估计，无法量化不确定性，这对需要决策的实际应用（如计算资源投资带来的性能提升）来说是至关重要的。

**方法:** 研究采用了基于贝叶斯框架的Prior-data Fitted Networks (PFNs)，设计了一个先验分布，可以抽样生成无数类似于真实神经扩展规律的合成函数，使PFN能够进行元学习外推。

**结果:** 在真实世界的神经扩展规律上验证了该方法的有效性，特别是在数据有限的情境下（如贝叶斯主动学习），表现优于现有的点估计方法和贝叶斯方法。

**结论:** 提出的基于贝叶斯框架的PFN方法在扩展规律外推中表现出色，尤其适用于数据有限的情况，为实际应用提供了可靠的、具有不确定性感知能力的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Neural+Scaling+Laws+Extrapolation+with+Prior-Fitted+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23032，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23032&send_immediately=true&force_search=false)

**原文摘要:** Scaling has been a major driver of recent advancements in deep learning.
Numerous empirical studies have found that scaling laws often follow the
power-law and proposed several variants of power-law functions to predict the
scaling behavior at larger scales. However, existing methods mostly rely on
point estimation and do not quantify uncertainty, which is crucial for
real-world applications involving decision-making problems such as determining
the expected performance improvements achievable by investing additional
computational resources. In this work, we explore a Bayesian framework based on
Prior-data Fitted Networks (PFNs) for neural scaling law extrapolation.
Specifically, we design a prior distribution that enables the sampling of
infinitely many synthetic functions resembling real-world neural scaling laws,
allowing our PFN to meta-learn the extrapolation. We validate the effectiveness
of our approach on real-world neural scaling laws, comparing it against both
the existing point estimation methods and Bayesian approaches. Our method
demonstrates superior performance, particularly in data-limited scenarios such
as Bayesian active learning, underscoring its potential for reliable,
uncertainty-aware extrapolation in practical applications.

</details>


### [42] [Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference](https://arxiv.org/abs/2505.22913)
*Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari*

**主要类别:** cs.LG

**概要:** 本论文展示了一种使用非结构化稀疏性显著提升大型语言模型(LLMs)中KV缓存压缩的方法，最高可实现70%的稀疏度而不会影响精度或需要微调。通过探索不同的剪枝策略，发现基于每token大小的剪枝方法在非结构化稀疏性下对Key和Value缓存都非常有效，超过了以前的结构化剪枝方案。此外，通过使用位图格式的稀疏表示和自定义注意力内核，实现了KV缓存高达45%的密集推理压缩率，并提高了长达2.23倍的tokens/sec吞吐量。该方法可在https://github.com/dhjoo98/mustafar获取。


<details>
  <summary>更多</summary>
  
**动机:** LLMs中的KV缓存由于其高内存开销成为了解码性能的主要瓶颈，特别是在处理大上下文长度时。因此，研究者们试图寻找一种有效的压缩方法以减少内存占用并提高解码速度。

**方法:** 研究者首先系统地探索了不同的剪枝策略，并发现基于每token大小的剪枝方法对于Key和Value缓存在非结构化稀疏性下非常有效。然后，他们采用了一种位图格式的稀疏表示以及一个自定义的注意力内核，可以直接对被压缩到任意稀疏模式的缓存进行计算，从而加速解码计算中的内存绑定操作。

**结果:** 实验结果表明，这种新方法可以实现高达70%的稀疏度而不影响精度或需要微调，并且能够将KV缓存压缩至密集推理的45%，提升了最长2.23倍的tokens/sec吞吐量。

**结论:** 非结构化稀疏性结合基于每token大小的剪枝方法和自定义注意力内核，为LLMs中的KV缓存提供了一种有效的压缩方法，可以减少内存占用并提高解码速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mustafar%3A+Promoting+Unstructured+Sparsity+for+KV+Cache+Pruning+in+LLM+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22913，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22913&send_immediately=true&force_search=false)

**原文摘要:** We demonstrate that unstructured sparsity significantly improves KV cache
compression for LLMs, enabling sparsity levels up to 70% without compromising
accuracy or requiring fine-tuning. We conduct a systematic exploration of
pruning strategies and find per-token magnitude-based pruning as highly
effective for both Key and Value caches under unstructured sparsity, surpassing
prior structured pruning schemes. The Key cache benefits from prominent outlier
elements, while the Value cache surprisingly benefits from a simple
magnitude-based pruning despite its uniform distribution. KV cache size is the
major bottleneck in decode performance due to high memory overhead for large
context lengths. To address this, we use a bitmap-based sparse format and a
custom attention kernel capable of compressing and directly computing over
compressed caches pruned to arbitrary sparsity patterns, significantly
accelerating memory-bound operations in decode computations and thereby
compensating for the overhead of runtime pruning and compression. Our custom
attention kernel coupled with the bitmap-based format delivers substantial
compression of KV cache upto 45% of dense inference and thereby enables longer
context length and increased tokens/sec throughput of upto 2.23x compared to
dense inference. Our pruning mechanism and sparse attention kernel is available
at https://github.com/dhjoo98/mustafar.

</details>


### [43] [From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data](https://arxiv.org/abs/2505.23042)
*Siwen Wang, Shitou Zhang, Wan-Lin Chen, Dung Truong, Tzyy-Ping Jung*

**主要类别:** cs.LG

**概要:** 近期大语言模型的进步推动了基础模型在各领域的开发。本研究通过微调先进的基础EEG模型LaBraM，在研究生课堂收集的现实世界压力分类数据集上评估大EEG模型（LEMs）的有效性。我们训练了一个二元分类器，使用18名研究生在课堂期间记录的静息状态EEG数据，区分正常和压力升高状态。表现最佳的微调模型在5秒窗口下实现了90.47%的平衡准确率，显著优于传统压力分类器。此外，我们还评估了微调后的LEMs在随机数据打乱和减少通道数量下的鲁棒性。这些结果表明LEMs能够有效处理现实世界的EEG数据，并展示了其通过从以模型为中心转向以数据为中心的设计来革新脑机接口应用的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前的研究主要使用受控临床环境中的数据评估大EEG模型（LEMs），但本研究旨在探索这些模型在现实世界环境中的适用性。

**方法:** 通过微调最先进的基础EEG模型LaBraM，使用从研究生课堂中收集的真实世界压力分类数据集评估LEMs的效果。训练一个二元分类器，利用18名研究生的静息状态EEG数据，区分正常与压力升高状态。同时评估模型在随机数据打乱和减少通道数量情况下的鲁棒性。

**结果:** 最佳微调模型在5秒窗口内实现了90.47%的平衡准确率，显著优于传统压力分类器，不仅在准确性上提高，而且在推理效率上也更优。

**结论:** 大EEG模型（LEMs）能够有效处理真实世界EEG数据，展现出在脑机接口应用领域中通过采用以数据为中心的设计方式带来变革的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Theory+to+Application%3A+Fine-Tuning+Large+EEG+Model+with+Real-World+Stress+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23042&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in Large Language Models have inspired the development of
foundation models across various domains. In this study, we evaluate the
efficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art
foundation EEG model, on a real-world stress classification dataset collected
in a graduate classroom. Unlike previous studies that primarily evaluate LEMs
using data from controlled clinical settings, our work assesses their
applicability to real-world environments. We train a binary classifier that
distinguishes between normal and elevated stress states using resting-state EEG
data recorded from 18 graduate students during a class session. The
best-performing fine-tuned model achieves a balanced accuracy of 90.47% with a
5-second window, significantly outperforming traditional stress classifiers in
both accuracy and inference efficiency. We further evaluate the robustness of
the fine-tuned LEM under random data shuffling and reduced channel counts.
These results demonstrate the capability of LEMs to effectively process
real-world EEG data and highlight their potential to revolutionize
brain-computer interface applications by shifting the focus from model-centric
to data-centric design.

</details>


### [44] [Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data](https://arxiv.org/abs/2505.23062)
*Lingkai Kong, Haichuan Wang, Tonghan Wang, Guojun Xiong, Milind Tambe*

**主要类别:** cs.LG

**概要:** CompFlow是一种基于流动匹配和最优传输理论的方法，用于解决源环境和目标环境之间的动态差异问题。通过建模目标动态为条件流，并使用Wasserstein距离估计动态差距，CompFlow在多个RL基准上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法在处理源环境和目标环境之间的动态差异时，通常依赖KL散度或互信息，这些方法在源和目标动态支持不重叠时可能表现不佳。因此需要一种更稳健的解决方案来应对这一挑战。

**方法:** 提出了一种名为CompFlow的方法，该方法基于流动匹配与最优传输理论。具体来说，将目标动态建模为基于源域流输出分布的条件流，而不是直接从高斯先验中学习。此外，还引入了一种乐观的主动数据收集策略，优先探索动态差距较大的区域。

**结果:** 理论上证明了所提出的乐观主动数据收集策略可以减少与最优策略的性能差异。实证结果表明，CompFlow在多个具有动态变化的强化学习基准上优于强基线。

**结论:** CompFlow提供了一种改进的泛化能力以学习目标动态，并通过Wasserstein距离提供了对动态差距的合理估计，从而有效提高了样本效率并减少了性能差距。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Composite+Flow+Matching+for+Reinforcement+Learning+with+Shifted-Dynamics+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23062，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23062&send_immediately=true&force_search=false)

**原文摘要:** Incorporating pre-collected offline data from a source environment can
significantly improve the sample efficiency of reinforcement learning (RL), but
this benefit is often challenged by discrepancies between the transition
dynamics of the source and target environments. Existing methods typically
address this issue by penalizing or filtering out source transitions in high
dynamics-gap regions. However, their estimation of the dynamics gap often
relies on KL divergence or mutual information, which can be ill-defined when
the source and target dynamics have disjoint support. To overcome these
limitations, we propose CompFlow, a method grounded in the theoretical
connection between flow matching and optimal transport. Specifically, we model
the target dynamics as a conditional flow built upon the output distribution of
the source-domain flow, rather than learning it directly from a Gaussian prior.
This composite structure offers two key advantages: (1) improved generalization
for learning target dynamics, and (2) a principled estimation of the dynamics
gap via the Wasserstein distance between source and target transitions.
Leveraging our principled estimation of the dynamics gap, we further introduce
an optimistic active data collection strategy that prioritizes exploration in
regions of high dynamics gap, and theoretically prove that it reduces the
performance disparity with the optimal policy. Empirically, CompFlow
outperforms strong baselines across several RL benchmarks with shifted
dynamics.

</details>


### [45] [Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models](https://arxiv.org/abs/2505.22935)
*Jipeng Li, Yanning Shen*

**主要类别:** cs.LG

**概要:** 本研究挑战了显式噪声级调节在图扩散模型（GDMs）中的必要性假设，提出通过理论框架和实验证明，无条件GDMs可以达到与有条件模型相当或更好的性能，同时减少参数和计算时间。


<details>
  <summary>更多</summary>
  
**动机:** 显式噪声级调节被认为是图扩散模型有效运行的关键。然而，研究者质疑是否可以通过隐式方法从受损的图结构中推断噪声水平，从而避免显式调节的需求。

**方法:** 研究开发了一个以伯努利边翻转破坏为中心的理论框架，并扩展到包含更复杂的结构-属性噪声情况。使用GDSS和DiGress等模型，在合成和真实图数据集上进行广泛的实证评估。

**结果:** 无条件GDMs在性能上可与有条件模型媲美甚至超越，同时减少了4-6%的参数和8-10%的计算时间。结果表明图数据的高维特性本身通常包含了足够的去噪信息。

**结论:** 图数据的高维特性常常包含足够的去噪信息，这为更简单、高效的GDM架构提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Is+Noise+Conditioning+Necessary%3F+A+Unified+Theory+of+Unconditional+Graph+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22935&send_immediately=true&force_search=false)

**原文摘要:** Explicit noise-level conditioning is widely regarded as essential for the
effective operation of Graph Diffusion Models (GDMs). In this work, we
challenge this assumption by investigating whether denoisers can implicitly
infer noise levels directly from corrupted graph structures, potentially
eliminating the need for explicit noise conditioning. To this end, we develop a
theoretical framework centered on Bernoulli edge-flip corruptions and extend it
to encompass more complex scenarios involving coupled structure-attribute
noise. Extensive empirical evaluations on both synthetic and real-world graph
datasets, using models such as GDSS and DiGress, provide strong support for our
theoretical findings. Notably, unconditional GDMs achieve performance
comparable or superior to their conditioned counterparts, while also offering
reductions in parameters (4-6%) and computation time (8-10%). Our results
suggest that the high-dimensional nature of graph data itself often encodes
sufficient information for the denoising process, opening avenues for simpler,
more efficient GDM architectures.

</details>


### [46] [Equivariant Spherical Transformer for Efficient Molecular Modeling](https://arxiv.org/abs/2505.23086)
*Junyi An, Xinyu Lu, Chao Qu, Yunfei Shi, Peijia Lin, Qianwei Tang, Licheng Xu, Fenglei Cao, Yuan Qi*

**主要类别:** cs.LG

**概要:** SE(3)-等变图神经网络（GNNs）通过使用群表示显著推动了分子系统建模的发展。然而，由于张量积卷积的非线性不足和群表示不完整，其消息传递过程受到限制。为了解决这些问题，本文引入了一种新的框架——等变球面变换器（EST），它在Fourier变换后的群表示空间域内利用Transformer结构。理论和实证表明，EST可以涵盖张量积的功能空间，并实现更高的表达能力。此外，通过Fourier变换的均匀采样策略，EST的等变归纳偏置得到了保证。实验表明，在包括OC20和QM9在内的多个分子基准上，EST表现出最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有的SE(3)-等变图神经网络（GNNs）已经在分子系统建模中取得了显著进展，但其消息传递过程受限于张量积卷积的非线性不足和群表示不完整的问题，这限制了模型的表达能力。因此，需要一种新的方法来提高模型的表达能力和灵活性。

**方法:** 本文提出了一种名为Equivariant Spherical Transformer (EST)的新框架。该框架在Fourier变换后的群表示空间域内使用Transformer结构，从而增强模型的非线性和表达能力。EST通过涵盖张量积的功能空间并超越其表达能力，解决了现有模型的局限性。同时，EST通过Fourier变换的均匀采样策略确保了等变归纳偏置。

**结果:** 理论和实验证明，EST能够涵盖张量积的功能空间，并展现出更高的表达能力。在多个分子基准测试中（如OC20和QM9），EST达到了最先进的性能水平。

**结论:** EST作为一种新型的等变框架，成功克服了现有SE(3)-等变GNNs的局限性，提高了模型的表达能力和灵活性。其在分子建模任务中的卓越表现展示了EST在未来相关领域的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Spherical+Transformer+for+Efficient+Molecular+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23086，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23086&send_immediately=true&force_search=false)

**原文摘要:** SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced
molecular system modeling by employing group representations. However, their
message passing processes, which rely on tensor product-based convolutions, are
limited by insufficient non-linearity and incomplete group representations,
thereby restricting expressiveness. To overcome these limitations, we introduce
the Equivariant Spherical Transformer (EST), a novel framework that leverages a
Transformer structure within the spatial domain of group representations after
Fourier transform. We theoretically and empirically demonstrate that EST can
encompass the function space of tensor products while achieving superior
expressiveness. Furthermore, EST's equivariant inductive bias is guaranteed
through a uniform sampling strategy for the Fourier transform. Our experiments
demonstrate state-of-the-art performance by EST on various molecular
benchmarks, including OC20 and QM9.

</details>


### [47] [Directed Graph Grammars for Sequence-based Learning](https://arxiv.org/abs/2505.22949)
*Michael Sun, Orion Foo, Gang Liu, Wojciech Matusik, Jie Chen*

**主要类别:** cs.LG

**概要:** 本论文提出了一种基于语法的方法，构建有向无环图（DAG）的紧凑且等效的序列化表示。通过将图视为在明确语法上的推导，每个DAG对应唯一的生产规则序列。此方法可用于生成模型、属性预测和结构化数据的贝叶斯优化。


<details>
  <summary>更多</summary>
  
**动机:** 尽管有许多有效的DAG编码器，但以原则性方式解码它们仍然具有挑战性，因为DAG的节点可以有许多不同的拓扑顺序。

**方法:** 作者提出了一种基于语法的方法，将DAG视为在明确语法上的推导，其中每个DAG对应一个唯一的生产规则序列。该过程相当于对数据进行无损压缩。

**结果:** 该方法提供了DAG的紧凑且等效的序列化表示，可应用于生成模型、属性预测和结构化数据的贝叶斯优化。

**结论:** 这种基于语法的方法为DAG提供了一个紧凑且等效的序列化表示，适用于多种任务，如生成模型、属性预测和结构化数据的贝叶斯优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Directed+Graph+Grammars+for+Sequence-based+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22949，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22949&send_immediately=true&force_search=false)

**原文摘要:** Directed acyclic graphs (DAGs) are a class of graphs commonly used in
practice, with examples that include electronic circuits, Bayesian networks,
and neural architectures. While many effective encoders exist for DAGs, it
remains challenging to decode them in a principled manner, because the nodes of
a DAG can have many different topological orders. In this work, we propose a
grammar-based approach to constructing a principled, compact and equivalent
sequential representation of a DAG. Specifically, we view a graph as
derivations over an unambiguous grammar, where the DAG corresponds to a unique
sequence of production rules. Equivalently, the procedure to construct such a
description can be viewed as a lossless compression of the data. Such a
representation has many uses, including building a generative model for graph
generation, learning a latent space for property prediction, and leveraging the
sequence representational continuity for Bayesian Optimization over structured
data. Code is available at https://github.com/shiningsunnyday/induction.

</details>


### [48] [CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2505.23116)
*Pengfei Zhou, Yunlong Liu, Junli Liang, Qi Song, Xiangyang Li*

**主要类别:** cs.LG

**概要:** CrossLinear是一种新型线性预测模型，通过引入轻量级的交叉相关嵌入模块解决变量依赖建模问题。它能有效捕捉变量间的直接依赖关系，降低过拟合风险，并通过分块处理和全局线性头提升短期和长期预测精度。实验表明该模型在多个真实数据集上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 当前时间序列预测模型难以区分内生和外生变量，导致效率低下和过拟合问题。需要一种能高效捕捉变量间依赖关系且不过拟合的新方法。

**方法:** 提出CrossLinear模型，包含一个可插拔的交叉相关嵌入模块，用于捕捉变量间的直接依赖关系，同时忽略间接或时变依赖。采用分块处理和全局线性头来捕捉短长期时间依赖。

**结果:** 在12个真实数据集上的实验表明，CrossLinear在短期和长期预测任务中均表现出色。消融研究验证了交叉相关嵌入模块的有效性。

**结论:** CrossLinear模型通过轻量级设计和有效的依赖捕捉机制，在时间序列预测任务中取得了显著改进，其模块具有良好的通用性，适用于不同领域的预测任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CrossLinear%3A+Plug-and-Play+Cross-Correlation+Embedding+for+Time+Series+Forecasting+with+Exogenous+Variables，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23116，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23116&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting with exogenous variables is a critical emerging
paradigm that presents unique challenges in modeling dependencies between
variables. Traditional models often struggle to differentiate between
endogenous and exogenous variables, leading to inefficiencies and overfitting.
In this paper, we introduce CrossLinear, a novel Linear-based forecasting model
that addresses these challenges by incorporating a plug-and-play
cross-correlation embedding module. This lightweight module captures the
dependencies between variables with minimal computational cost and seamlessly
integrates into existing neural networks. Specifically, it captures
time-invariant and direct variable dependencies while disregarding time-varying
or indirect dependencies, thereby mitigating the risk of overfitting in
dependency modeling and contributing to consistent performance improvements.
Furthermore, CrossLinear employs patch-wise processing and a global linear head
to effectively capture both short-term and long-term temporal dependencies,
further improving its forecasting precision. Extensive experiments on 12
real-world datasets demonstrate that CrossLinear achieves superior performance
in both short-term and long-term forecasting tasks. The ablation study
underscores the effectiveness of the cross-correlation embedding module.
Additionally, the generalizability of this module makes it a valuable plug-in
for various forecasting tasks across different domains. Codes are available at
https://github.com/mumiao2000/CrossLinear.

</details>


### [49] [MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming](https://arxiv.org/abs/2505.22967)
*Chengqi Zheng, Jianda Chen, Yueming Lyu, Wen Zheng Terence Ng, Haopeng Zhang, Yew-Soon Ong, Ivor Tsang, Haiyan Yin*

**主要类别:** cs.LG

**概要:** MermaidFlow 是一个通过安全约束图演化重新定义代理搜索空间的框架，使用可验证的中间表示来表示工作流，并通过领域感知进化算子提高语义正确性和结构多样性，在代理推理基准上表现出更高的成功率和更快的收敛速度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自主代理推理方法常常生成脆弱且不可执行的计划，因为它们依赖于不受约束的大语言模型驱动的构建。

**方法:** MermaidFlow 使用 Mermaid 图形语言作为可验证的中间表示来表示工作流，并引入领域感知进化算子（如交叉、变异、插入和删除）以在促进结构多样性的同时保持语义正确性，从而实现对高质量、静态可验证的工作流空间的有效探索。

**结果:** 在不修改任务设置或评估协议的情况下，MermaidFlow 在代理推理基准上实现了成功率的一致提升和更快收敛到可执行计划的能力。

**结论:** 实验结果表明，安全约束图演化为鲁棒且可解释的代理推理系统提供了一个可扩展和模块化的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MermaidFlow%3A+Redefining+Agentic+Workflow+Generation+via+Safety-Constrained+Evolutionary+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22967，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22967&send_immediately=true&force_search=false)

**原文摘要:** Despite the promise of autonomous agentic reasoning, existing workflow
generation methods frequently produce fragile, unexecutable plans due to
unconstrained LLM-driven construction. We introduce MermaidFlow, a framework
that redefines the agentic search space through safety-constrained graph
evolution. At its core, MermaidFlow represent workflows as a verifiable
intermediate representation using Mermaid, a structured and human-interpretable
graph language. We formulate domain-aware evolutionary operators, i.e.,
crossover, mutation, insertion, and deletion, to preserve semantic correctness
while promoting structural diversity, enabling efficient exploration of a
high-quality, statically verifiable workflow space. Without modifying task
settings or evaluation protocols, MermaidFlow achieves consistent improvements
in success rates and faster convergence to executable plans on the agent
reasoning benchmark. The experimental results demonstrate that
safety-constrained graph evolution offers a scalable, modular foundation for
robust and interpretable agentic reasoning systems.

</details>


### [50] [Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking](https://arxiv.org/abs/2505.23117)
*Yuatyong Chaichana, Thanapat Trachu, Peerat Limkonchotiwat, Konpat Preechakul, Tirasan Khandhawit, Ekapol Chuangsuwanich*

**主要类别:** cs.LG

**概要:** 在大规模训练时代，模型融合已成为创建多任务模型的有效工具。现有的融合方法通常假设权重矩阵中相同位置的条目具有相同功能，但忽略了微调神经网络的复杂性。本文提出了Decom-Renorm-Merge (DRM) 方法，通过奇异值分解将权重矩阵分解并协调到对齐的联合空间中，使得逐项融合成为可能。实验结果表明，DRM 在多种模型和设置下优于几种最先进的融合技术。


<details>
  <summary>更多</summary>
  
**动机:** 现有模型融合方法假设权重矩阵中相同位置的条目具有相同功能，但忽略了微调神经网络中神经元可能发展出不同的特征组成，导致直接逐项融合存在问题。

**方法:** 提出了一种名为 Decom-Renorm-Merge (DRM) 的方法，利用奇异值分解将权重矩阵分解并协调到对齐的联合空间中，从而实现有效的逐项融合。

**结果:** DRM 在各种模型（如 ViT、DeBERTa、T5 和 Llama3.1-8B）和设置（全微调和低秩适应）下，均优于几种最先进的融合技术。分析还显示，重归一化是创建稳健联合空间的关键组件，显著贡献于方法性能。

**结论:** DRM 是一种简单而有效的方法，能够在多种模型和设置下实现更优的模型融合效果，重归一化对于创建稳健的联合空间至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decom-Renorm-Merge%3A+Model+Merging+on+the+Right+Space+Improves+Multitasking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23117，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23117&send_immediately=true&force_search=false)

**原文摘要:** In the era of large-scale training, model merging has evolved into a tool for
creating multitasking models efficiently. It enables the knowledge of models to
be fused, without the need for heavy computation as required in traditional
multitask learning. Existing merging methods often assume that entries at
identical positions in weight matrices serve the same function, enabling
straightforward entry-wise comparison and merging. However, this assumption
overlooks the complexity of finetuned neural networks, where neurons may
develop distinct feature compositions, making direct entry-wise merging
problematic. We present Decom-Renorm-Merge (DRM), a simple yet effective
approach that leverages Singular Value Decomposition to decompose and
coordinate weight matrices into an aligned joint space, where entry-wise
merging becomes possible. We showcase the effectiveness of DRM across various
settings ranging from smaller encoder-based such as ViT and DeBERTa,
encoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B.
Our experimental results show that DRM outperforms several state-of-the-art
merging techniques across full finetuning and low-rank adaptation settings.
Moreover, our analysis reveals renormalization as the crucial component for
creating a robust and even joint space for merging, significantly contributing
to the method's performance.

</details>


### [51] [VERINA: Benchmarking Verifiable Code Generation](https://arxiv.org/abs/2505.23135)
*Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song*

**主要类别:** cs.LG

**概要:** 论文介绍了一个名为Verina的高质量基准测试，支持对代码、规范和证明生成进行综合评估。通过评估当前最先进的LLM，发现它们在可验证代码生成方面存在显著挑战，尤其是在证明生成上。


<details>
  <summary>更多</summary>
  
**动机:** 目前缺乏支持端到端可验证代码生成的评估基准，这限制了大型语言模型（LLMs）在软件开发中的进一步应用。

**方法:** 引入了Verina，一个包含189个手动策划的Lean编程任务的高质量基准测试，提供了详细的问题描述、参考实现、正式规范和广泛的测试套件，用于全面和模块化地评估代码、规范和证明生成及其组合。

**结果:** 评估结果显示，即使是最好的模型OpenAI o4-mini，在单次尝试下也只能生成61.4%正确的代码、51.0%声音和完整的规范以及3.6%成功的证明。

**结论:** Verina将推动可验证代码生成领域的进步，并为改进基于LLM的定理证明器在验证领域提供严格和全面的基准测试。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VERINA%3A+Benchmarking+Verifiable+Code+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23135&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly integrated in software
development, but ensuring correctness in LLM-generated code remains challenging
and often requires costly manual review. Verifiable code generation -- jointly
generating code, specifications, and proofs of code-specification alignment --
offers a promising path to address this limitation and further unleash LLMs'
benefits in coding. Yet, there exists a significant gap in evaluation: current
benchmarks often lack support for end-to-end verifiable code generation. In
this paper, we introduce Verina (Verifiable Code Generation Arena), a
high-quality benchmark enabling a comprehensive and modular evaluation of code,
specification, and proof generation as well as their compositions. Verina
consists of 189 manually curated coding tasks in Lean, with detailed problem
descriptions, reference implementations, formal specifications, and extensive
test suites. Our extensive evaluation of state-of-the-art LLMs reveals
significant challenges in verifiable code generation, especially in proof
generation, underscoring the need for improving LLM-based theorem provers in
verification domains. The best model, OpenAI o4-mini, generates only 61.4%
correct code, 51.0% sound and complete specifications, and 3.6% successful
proofs, with one trial per task. We hope Verina will catalyze progress in
verifiable code generation by providing a rigorous and comprehensive benchmark.
We release our dataset on https://huggingface.co/datasets/sunblaze-ucb/verina
and our evaluation code on https://github.com/sunblaze-ucb/verina.

</details>


### [52] [A Computational Approach to Improving Fairness in K-means Clustering](https://arxiv.org/abs/2505.22984)
*Guancheng Zhou, Haiping Xu, Hongkang Xu, Chenyu Li, Donghui Yan*

**主要类别:** cs.LG

**概要:** 本文提出了一种两阶段优化公式以改善K-means聚类的公平性，首先进行聚类然后调整一小部分数据点的聚类隶属关系。提出了两种计算效率高的算法来识别对公平性昂贵的数据点，并在基准数据集上展示了显著的公平性改进，同时对聚类质量的影响最小。


<details>
  <summary>更多</summary>
  
**动机:** K-means聚类算法可能在一个敏感变量（如性别或种族）方面存在不公平问题，某些聚类可能会不成比例地包含来自子群体的更多（或更少）点，从而导致偏差和意外的社会后果。

**方法:** 采用两阶段优化方法：先进行聚类，然后调整一小部分选定数据点的聚类成员资格。提出两种高效算法来识别对公平性有重大影响的数据点，一个关注集群外最近的数据点，另一个关注高度“混合”的数据点。

**结果:** 在基准数据集上的实验表明，该方法在对聚类质量影响最小的情况下，显著提高了公平性。

**结论:** 所提出的算法可以轻松扩展到广泛的聚类算法或公平性度量中，为解决K-means聚类中的公平性问题提供了有效途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Computational+Approach+to+Improving+Fairness+in+K-means+Clustering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22984，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22984&send_immediately=true&force_search=false)

**原文摘要:** The popular K-means clustering algorithm potentially suffers from a major
weakness for further analysis or interpretation. Some cluster may have
disproportionately more (or fewer) points from one of the subpopulations in
terms of some sensitive variable, e.g., gender or race. Such a fairness issue
may cause bias and unexpected social consequences. This work attempts to
improve the fairness of K-means clustering with a two-stage optimization
formulation--clustering first and then adjust cluster membership of a small
subset of selected data points. Two computationally efficient algorithms are
proposed in identifying those data points that are expensive for fairness, with
one focusing on nearest data points outside of a cluster and the other on
highly 'mixed' data points. Experiments on benchmark datasets show substantial
improvement on fairness with a minimal impact to clustering quality. The
proposed algorithms can be easily extended to a broad class of clustering
algorithms or fairness metrics.

</details>


### [53] [Best Arm Identification with Possibly Biased Offline Data](https://arxiv.org/abs/2505.23165)
*Le Yang, Vincent Y. F. Tan, Wang Chi Cheung*

**主要类别:** cs.LG

**概要:** 研究了固定置信度设置下可能带有偏差的离线数据的最佳臂识别（BAI）问题。提出LUCB-H算法，通过辅助偏差校正适应性置信区间，在离线数据误导时与标准LUCB表现相当，而在离线数据有益时显著优于标准LUCB。理论分析和数值实验表明LUCB-H的有效性和适应性。


<details>
  <summary>更多</summary>
  
**动机:** 最佳臂识别问题在现实场景中常见，例如临床试验，但离线数据可能存在偏差，影响决策效果。需要一种方法能够有效利用离线数据并纠正其潜在偏差。

**方法:** 提出LUCB-H算法，将辅助偏差校正引入LUCB框架，以平衡在线和离线数据分布，并推导出自适应置信区间。

**结果:** 理论上证明LUCB-H在离线数据误导时样本复杂度与标准LUCB相同，在离线数据有益时显著优于标准LUCB。同时推导出实例依赖的下界，在某些情况下与LUCB-H的上界匹配。数值实验进一步验证了LUCB-H的鲁棒性和适应性。

**结论:** LUCB-H算法能够在存在潜在偏差的离线数据中有效工作，具有良好的适应性和鲁棒性，为实际应用中的最佳臂识别问题提供了新解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Best+Arm+Identification+with+Possibly+Biased+Offline+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23165，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23165&send_immediately=true&force_search=false)

**原文摘要:** We study the best arm identification (BAI) problem with potentially biased
offline data in the fixed confidence setting, which commonly arises in
real-world scenarios such as clinical trials. We prove an impossibility result
for adaptive algorithms without prior knowledge of the bias bound between
online and offline distributions. To address this, we propose the LUCB-H
algorithm, which introduces adaptive confidence bounds by incorporating an
auxiliary bias correction to balance offline and online data within the LUCB
framework. Theoretical analysis shows that LUCB-H matches the sample complexity
of standard LUCB when offline data is misleading and significantly outperforms
it when offline data is helpful. We also derive an instance-dependent lower
bound that matches the upper bound of LUCB-H in certain scenarios. Numerical
experiments further demonstrate the robustness and adaptability of LUCB-H in
effectively incorporating offline data.

</details>


### [54] [FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification](https://arxiv.org/abs/2505.23181)
*Tian Tian, Chunyan Miao, Hangwei Qian*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为Frequency Refined Augmentation (FreRA)的新方法，专为时间序列分类任务设计。该方法通过频率域的增强策略解决了现有时间域增强方法在时间序列数据上的不足，能够保护语义相关信息并引入多样性。实验表明，FreRA在时间序列分类、异常检测和迁移学习任务上显著优于其他方法。


<details>
  <summary>更多</summary>
  
**动机:** 对比学习作为一种无监督表示学习方法已显示出强大能力，但其最优增强策略设计在时间序列分类任务中尚未得到充分探索。现有的时间域增强方法多从视觉领域借鉴，不适合时间序列数据，可能导致语义信息失真。

**方法:** 作者提出了一个基于频率域的增强方法——Frequency Refined Augmentation (FreRA)，该方法可以自动分离关键和非关键频率成分，并分别采用语义感知的身份修改（Identity Modification）和语义无关的自适应修改（Self-adaptive Modification），以保护关键频率中的语义信息并在非关键频率中注入变化。

**结果:** 理论上证明了FreRA生成的视图保留了语义信息；实验证明，FreRA在多个基准数据集（如UCR和UEA档案）以及五个大规模数据集上，于时间序列分类、异常检测和迁移学习任务中均显著优于十个领先的基线方法。

**结论:** FreRA是一种轻量且有效的方法，适用于时间序列对比学习任务，能显著提升对比表示学习能力和迁移学习场景中的泛化性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FreRA%3A+A+Frequency-Refined+Augmentation+for+Contrastive+Learning+on+Time+Series+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23181，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23181&send_immediately=true&force_search=false)

**原文摘要:** Contrastive learning has emerged as a competent approach for unsupervised
representation learning. However, the design of an optimal augmentation
strategy, although crucial for contrastive learning, is less explored for time
series classification tasks. Existing predefined time-domain augmentation
methods are primarily adopted from vision and are not specific to time series
data. Consequently, this cross-modality incompatibility may distort the
semantically relevant information of time series by introducing mismatched
patterns into the data. To address this limitation, we present a novel
perspective from the frequency domain and identify three advantages for
downstream classification: global, independent, and compact. To fully utilize
the three properties, we propose the lightweight yet effective Frequency
Refined Augmentation (FreRA) tailored for time series contrastive learning on
classification tasks, which can be seamlessly integrated with contrastive
learning frameworks in a plug-and-play manner. Specifically, FreRA
automatically separates critical and unimportant frequency components.
Accordingly, we propose semantic-aware Identity Modification and
semantic-agnostic Self-adaptive Modification to protect semantically relevant
information in the critical frequency components and infuse variance into the
unimportant ones respectively. Theoretically, we prove that FreRA generates
semantic-preserving views. Empirically, we conduct extensive experiments on two
benchmark datasets, including UCR and UEA archives, as well as five large-scale
datasets on diverse applications. FreRA consistently outperforms ten leading
baselines on time series classification, anomaly detection, and transfer
learning tasks, demonstrating superior capabilities in contrastive
representation learning and generalization in transfer learning scenarios
across diverse datasets.

</details>


### [55] [Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning](https://arxiv.org/abs/2505.23195)
*Lifan Zhao, Yanyan Shen, Zhaoyang Liu, Xue Wang, Jiaji Deng*

**主要类别:** cs.LG

**概要:** 通过结构化剪枝方法优化TSFM的微调过程，显著提升时间序列预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管TSFM在零样本预测中表现出色，但在微调后仍无法持续超越小规模专用模型，因此需要探索如何有效适应TSFM以完成目标预测任务。

**方法:** 提出一种结构化剪枝方法，在微调过程中聚焦于更相关和紧凑的参数空间，保留预训练模型中的先验知识。

**结果:** 实验表明，对剪枝后的TSFM进行微调，相比原始模型显著提升了预测性能，并达到领域内顶尖水平。

**结论:** “剪枝-再微调”范式可使TSFM超越专用模型，实现最佳预测效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Less+is+More%3A+Unlocking+Specialization+of+Time+Series+Foundation+Models+via+Structured+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23195，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23195&send_immediately=true&force_search=false)

**原文摘要:** Scaling laws motivate the development of Time Series Foundation Models
(TSFMs) that pre-train vast parameters and achieve remarkable zero-shot
forecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot
consistently outperform smaller, specialized models trained on full-shot
downstream data. A key question is how to realize effective adaptation of TSFMs
for a target forecasting task. Through empirical studies on various TSFMs, the
pre-trained models often exhibit inherent sparsity and redundancy in
computation, suggesting that TSFMs have learned to activate task-relevant
network substructures to accommodate diverse forecasting tasks. To preserve
this valuable prior knowledge, we propose a structured pruning method to
regularize the subsequent fine-tuning process by focusing it on a more relevant
and compact parameter space. Extensive experiments on seven TSFMs and six
benchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly
improves forecasting performance compared to fine-tuning original models. This
"prune-then-finetune" paradigm often enables TSFMs to achieve state-of-the-art
performance and surpass strong specialized baselines.

</details>


### [56] [Number of Clusters in a Dataset: A Regularized K-means Approach](https://arxiv.org/abs/2505.22991)
*Behzad Kamgar-Parsi, Behrooz Kamgar-Parsi*

**主要类别:** cs.LG

**概要:** 本文研究了在未标记数据集中寻找有意义聚类数量的问题，提出了理想聚类条件下正则化参数λ的严格界限，并分析了加法和乘法正则化k-means算法的表现。


<details>
  <summary>更多</summary>
  
**动机:** 确定未标记数据集中的有意义聚类数量在许多应用中至关重要，但目前缺乏对关键超参数λ设置的系统指导。

**方法:** 假设聚类为理想（d维球体），推导出正则化参数λ的严格界限；分析了加法和乘法正则化k-means算法的行为，并通过实验验证了其性能。

**结果:** 推导出了理想聚类条件下λ的严格界限，发现加法正则化可能导致多个解，而结合乘法正则化的共识可以减少某些情况下的不确定性。

**结论:** 提出了一种基于理想聚类假设的λ值设定方法，并展示了加法和乘法正则化k-means算法在偏离理想条件时的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Number+of+Clusters+in+a+Dataset%3A+A+Regularized+K-means+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22991，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22991&send_immediately=true&force_search=false)

**原文摘要:** Finding the number of meaningful clusters in an unlabeled dataset is
important in many applications. Regularized k-means algorithm is a possible
approach frequently used to find the correct number of distinct clusters in
datasets. The most common formulation of the regularization function is the
additive linear term $\lambda k$, where $k$ is the number of clusters and
$\lambda$ a positive coefficient. Currently, there are no principled guidelines
for setting a value for the critical hyperparameter $\lambda$. In this paper,
we derive rigorous bounds for $\lambda$ assuming clusters are {\em ideal}.
Ideal clusters (defined as $d$-dimensional spheres with identical radii) are
close proxies for k-means clusters ($d$-dimensional spherically symmetric
distributions with identical standard deviations). Experiments show that the
k-means algorithm with additive regularizer often yields multiple solutions.
Thus, we also analyze k-means algorithm with multiplicative regularizer. The
consensus among k-means solutions with additive and multiplicative
regularizations reduces the ambiguity of multiple solutions in certain cases.
We also present selected experiments that demonstrate performance of the
regularized k-means algorithms as clusters deviate from the ideal assumption.

</details>


### [57] [Accelerating RLHF Training with Reward Variance Increase](https://arxiv.org/abs/2505.23247)
*Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan*

**主要类别:** cs.LG

**概要:** 提出了一种实用的奖励调整模型，通过增加奖励方差加速RLHF训练，并将其集成到GRPO算法中形成更高效的GRPOVI算法。实验表明GRPOVI显著提高了RLHF训练效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基于GRPO的RLHF训练在LLM应用中取得成功，但高效训练仍面临挑战。研究表明，初始策略模型的高奖励方差可加速RLHF训练，因此提出了一个奖励调整模型以解决这一问题。

**方法:** 设计了一个非凸优化问题的奖励调整模型，通过明确刻画可行集的极值点，提出了一种O(n log n)算法找到全局解。将此模型与GRPO算法结合，形成了具有奖励方差增加特性的GRPOVI算法。此外，还间接解释了规则奖励在GRPO中的经验有效性。

**结果:** 实验结果表明，GRPOVI算法相较于原始GRPO算法显著提高了RLHF训练效率。

**结论:** 提出的奖励调整模型和GRPOVI算法为加速RLHF训练提供了有效方法，并验证了其在实际应用中的性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+RLHF+Training+with+Reward+Variance+Increase，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23247，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23247&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning from human feedback (RLHF) is an essential technique
for ensuring that large language models (LLMs) are aligned with human values
and preferences during the post-training phase. As an effective RLHF approach,
group relative policy optimization (GRPO) has demonstrated success in many
LLM-based applications. However, efficient GRPO-based RLHF training remains a
challenge. Recent studies reveal that a higher reward variance of the initial
policy model leads to faster RLHF training. Inspired by this finding, we
propose a practical reward adjustment model to accelerate RLHF training by
provably increasing the reward variance and preserving the relative preferences
and reward expectation. Our reward adjustment method inherently poses a
nonconvex optimization problem, which is NP-hard to solve in general. To
overcome the computational challenges, we design a novel $O(n \log n)$
algorithm to find a global solution of the nonconvex reward adjustment model by
explicitly characterizing the extreme points of the feasible set. As an
important application, we naturally integrate this reward adjustment model into
the GRPO algorithm, leading to a more efficient GRPO with reward variance
increase (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we
provide an indirect explanation for the empirical effectiveness of GRPO with
rule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment
results demonstrate that the GRPOVI algorithm can significantly improve the
RLHF training efficiency compared to the original GRPO algorithm.

</details>


### [58] [Walking the Weight Manifold: a Topological Approach to Conditioning Inspired by Neuromodulation](https://arxiv.org/abs/2505.22994)
*Ari S. Benjamin, Kyle Daruwalla, Christian Pehle, Anthony M. Zador*

**主要类别:** cs.LG

**概要:** 提出了一种受神经调节启发的方法，通过优化权重空间中的平滑流形来学习任务上下文变量的平滑参数化函数。该方法优于传统条件输入法，并能更好地推广到分布外样本。


<details>
  <summary>更多</summary>
  
**动机:** 在人工神经网络中，通常通过将上下文作为输入注入来实现跨任务的知识重用。然而，大脑通过神经调节剂（如血清素）调制参数本身。因此，本文试图从神经调节中汲取灵感，提出一种新的方法来学习任务上下文变量的平滑参数化函数。

**方法:** 通过优化权重空间中的平滑流形，而不是单个权重向量，来学习任务上下文变量的平滑参数化函数。推导了流形优化的形式处理方法，类似于梯度下降。推理时，条件选择流形上的一个点作为特定子任务的有效权重矩阵。

**结果:** 训练了几种拓扑结构的流形，包括权重空间中的直线（用于输入数据噪声水平的条件）和椭圆（用于旋转图像）。尽管这些参数化简单，但它们的表现优于通过输入连接对相同网络进行条件化，并且能够更好地推广到分布外样本。

**结论:** 调制低维流形上的权重提供了一个有原则且有效的传统条件化的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Walking+the+Weight+Manifold%3A+a+Topological+Approach+to+Conditioning+Inspired+by+Neuromodulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22994，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22994&send_immediately=true&force_search=false)

**原文摘要:** One frequently wishes to learn a range of similar tasks as efficiently as
possible, re-using knowledge across tasks. In artificial neural networks, this
is typically accomplished by conditioning a network upon task context by
injecting context as input. Brains have a different strategy: the parameters
themselves are modulated as a function of various neuromodulators such as
serotonin. Here, we take inspiration from neuromodulation and propose to learn
weights which are smoothly parameterized functions of task context variables.
Rather than optimize a weight vector, i.e. a single point in weight space, we
optimize a smooth manifold in weight space with a predefined topology. To
accomplish this, we derive a formal treatment of optimization of manifolds as
the minimization of a loss functional subject to a constraint on volumetric
movement, analogous to gradient descent. During inference, conditioning selects
a single point on this manifold which serves as the effective weight matrix for
a particular sub-task. This strategy for conditioning has two main advantages.
First, the topology of the manifold (whether a line, circle, or torus) is a
convenient lever for inductive biases about the relationship between tasks.
Second, learning in one state smoothly affects the entire manifold, encouraging
generalization across states. To verify this, we train manifolds with several
topologies, including straight lines in weight space (for conditioning on e.g.
noise level in input data) and ellipses (for rotated images). Despite their
simplicity, these parameterizations outperform conditioning identical networks
by input concatenation and better generalize to out-of-distribution samples.
These results suggest that modulating weights over low-dimensional manifolds
offers a principled and effective alternative to traditional conditioning.

</details>


### [59] [Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs](https://arxiv.org/abs/2505.23270)
*Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong Gu, Claudia Grosser, Denis Krompass, Nassir Navab, Volker Tresp*

**主要类别:** cs.LG

**概要:** 近年来，大型语言模型（LLMs）取得了显著进展，其能力主要归功于大规模架构和在海量数据集上的广泛训练。然而，这些数据集可能包含敏感或受版权保护的内容，引发了隐私和所有权问题。因此，研究者们开发了机器遗忘算法，以从模型中移除特定知识而无需昂贵的重新训练。然而，评估这些算法的有效性仍具挑战。本文提出了一种全面的审计框架，包括三个基准数据集、六种遗忘算法和五种基于提示的审计方法，并通过各种审计算法评估不同遗忘策略的有效性和鲁棒性。此外，还提出了一种利用中间激活扰动的新技术，以克服仅依赖模型输入和输出的审计方法的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 由于大型语言模型训练所用的数据集中可能存在敏感或受版权保护的内容，这引发了数据隐私和所有权问题。同时，现有法规如GDPR要求可以删除特定敏感信息，促使研究者探索有效的机器遗忘算法来解决这一问题。

**方法:** 1. 提出一个综合审计框架，涵盖三种基准数据集、六种遗忘算法和五种基于提示的审计方法。
2. 使用多种审计算法评估不同遗忘策略的有效性和鲁棒性。
3. 提出一种新技术，利用中间激活扰动进行审计，以弥补传统基于输入和输出审计方法的不足。

**结果:** 该审计框架能够有效评估不同遗忘算法的表现，并揭示了现有基于提示审计方法的局限性。提出的新技术通过中间激活扰动，为更全面地评估遗忘效果提供了新途径。

**结论:** 本文提出的审计框架为评估机器遗忘算法提供了一个全面的工具，有助于未来研究改进遗忘技术。同时，新提出的基于中间激活扰动的技术展示了超越传统输入输出审计的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Does+Machine+Unlearning+Truly+Remove+Model+Knowledge%3F+A+Framework+for+Auditing+Unlearning+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23270，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23270&send_immediately=true&force_search=false)

**原文摘要:** In recent years, Large Language Models (LLMs) have achieved remarkable
advancements, drawing significant attention from the research community. Their
capabilities are largely attributed to large-scale architectures, which require
extensive training on massive datasets. However, such datasets often contain
sensitive or copyrighted content sourced from the public internet, raising
concerns about data privacy and ownership. Regulatory frameworks, such as the
General Data Protection Regulation (GDPR), grant individuals the right to
request the removal of such sensitive information. This has motivated the
development of machine unlearning algorithms that aim to remove specific
knowledge from models without the need for costly retraining. Despite these
advancements, evaluating the efficacy of unlearning algorithms remains a
challenge due to the inherent complexity and generative nature of LLMs. In this
work, we introduce a comprehensive auditing framework for unlearning
evaluation, comprising three benchmark datasets, six unlearning algorithms, and
five prompt-based auditing methods. By using various auditing algorithms, we
evaluate the effectiveness and robustness of different unlearning strategies.
To explore alternatives beyond prompt-based auditing, we propose a novel
technique that leverages intermediate activation perturbations, addressing the
limitations of auditing methods that rely solely on model inputs and outputs.

</details>


### [60] [LLM Agents for Bargaining with Utility-based Feedback](https://arxiv.org/abs/2505.22998)
*Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim*

**主要类别:** cs.LG

**概要:** 大型语言模型（LLMs）在谈判方面存在战略深度不足和难以适应复杂人类因素的问题。为了解决这些问题，本文提出了一个基于效用反馈的综合框架，包含三个主要贡献：BargainArena数据集、与人类一致且基于经济理论的评估指标以及结构化反馈机制。实验表明，这些方法可以显著提高LLMs的谈判表现。


<details>
  <summary>更多</summary>
  
**动机:** 当前的基准测试未能捕捉到现实世界中谈判的复杂性，而大型语言模型在处理涉及战略深度和复杂人类因素的谈判时面临挑战。

**方法:** 1. 创建了BargainArena数据集，提供六个复杂的场景以支持多样化的策略建模；2. 提出了与人类一致、基于经济理论的评估指标，考虑代理效用和谈判能力；3. 开发了结构化反馈机制，允许LLMs通过迭代改进其谈判策略，并能与上下文学习提示协同工作。

**结果:** 实验结果表明，LLMs通常表现出与人类偏好不一致的谈判策略。然而，使用所提出的结构化反馈机制后，LLMs的表现显著提升，展现出更深层次的战略性和对手意识推理。

**结论:** 提出的框架能够有效增强LLMs在真实谈判中的能力，特别是在战略深度和对手意识方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM+Agents+for+Bargaining+with+Utility-based+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22998，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22998&send_immediately=true&force_search=false)

**原文摘要:** Bargaining, a critical aspect of real-world interactions, presents challenges
for large language models (LLMs) due to limitations in strategic depth and
adaptation to complex human factors. Existing benchmarks often fail to capture
this real-world complexity. To address this and enhance LLM capabilities in
realistic bargaining, we introduce a comprehensive framework centered on
utility-based feedback. Our contributions are threefold: (1) BargainArena, a
novel benchmark dataset with six intricate scenarios (e.g., deceptive
practices, monopolies) to facilitate diverse strategy modeling; (2)
human-aligned, economically-grounded evaluation metrics inspired by utility
theory, incorporating agent utility and negotiation power, which implicitly
reflect and promote opponent-aware reasoning (OAR); and (3) a structured
feedback mechanism enabling LLMs to iteratively refine their bargaining
strategies. This mechanism can positively collaborate with in-context learning
(ICL) prompts, including those explicitly designed to foster OAR. Experimental
results show that LLMs often exhibit negotiation strategies misaligned with
human preferences, and that our structured feedback mechanism significantly
improves their performance, yielding deeper strategic and opponent-aware
reasoning.

</details>


### [61] [Score-based Generative Modeling for Conditional Independence Testing](https://arxiv.org/abs/2505.23309)
*Yixin Ren, Chenghou Jin, Yewei Xia, Li Ke, Longtao Huang, Hui Xue, Hao Zhang, Jihong Guan, Shuigeng Zhou*

**主要类别:** cs.LG

**概要:** 提出了一种基于评分的生成建模的新CI测试方法，解决了现有GAN方法中的问题，并在实验中显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 确定随机变量之间的条件独立（CI）关系是一项基本但具有挑战性的任务，尤其是在高维情况下。现有的基于生成模型的CI测试方法（如使用生成对抗网络（GANs）的方法）常常由于条件分布的不良建模和训练不稳定性而导致性能不佳。

**方法:** 首先采用切片条件得分匹配方案来精确估计条件得分，并使用朗之万动力学条件采样生成零假设样本，以确保精确的I型误差控制。然后将一个拟合优度阶段纳入该方法，以验证生成的样本并增强实际应用中的可解释性。理论上建立了由评分生成模型建模的条件分布的误差界限，并证明了我们的CI检验的有效性。

**结果:** 广泛的实验表明，该方法在合成和真实世界的数据集上都显著优于现有的最先进方法。

**结论:** 所提出的方法提供了一种有希望的方式来重新激发基于生成模型的CI测试。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Score-based+Generative+Modeling+for+Conditional+Independence+Testing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23309，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23309&send_immediately=true&force_search=false)

**原文摘要:** Determining conditional independence (CI) relationships between random
variables is a fundamental yet challenging task in machine learning and
statistics, especially in high-dimensional settings. Existing generative
model-based CI testing methods, such as those utilizing generative adversarial
networks (GANs), often struggle with undesirable modeling of conditional
distributions and training instability, resulting in subpar performance. To
address these issues, we propose a novel CI testing method via score-based
generative modeling, which achieves precise Type I error control and strong
testing power. Concretely, we first employ a sliced conditional score matching
scheme to accurately estimate conditional score and use Langevin dynamics
conditional sampling to generate null hypothesis samples, ensuring precise Type
I error control. Then, we incorporate a goodness-of-fit stage into the method
to verify generated samples and enhance interpretability in practice. We
theoretically establish the error bound of conditional distributions modeled by
score-based generative models and prove the validity of our CI tests. Extensive
experiments on both synthetic and real-world datasets show that our method
significantly outperforms existing state-of-the-art methods, providing a
promising way to revitalize generative model-based CI testing.

</details>


### [62] [Matryoshka Model Learning for Improved Elastic Student Models](https://arxiv.org/abs/2505.23337)
*Chetan Verma, Aditya Srinivas Timmaraju, Cho Jui-Hsieh, Suyash Damle, Ngot Bui, Yang Zhang, Wen Chen, Xin Liu, Prateek Jain, Inderjit S Dhillon*

**主要类别:** cs.LG

**概要:** 提出MatTA框架，通过Teacher-TA-Student方法训练多个精确的学生模型。TA模型是学生模型的放大版，能引入更多领域专业知识。此方法只需一次训练即可提供多种可部署选项，在专有数据集和GPT-2 Medium上均取得显著改进。


<details>
  <summary>更多</summary>
  
**动机:** 行业级ML模型需要满足快速演进的服务约束，这要求大量的资源进行模型开发。为了降低资源需求并提供灵活的模型选择，作者提出了MatTA框架。

**方法:** MatTA框架利用Teacher-TA-Student的方法，其中TA模型是学生模型的放大版，具有更高的容量，使学生模型能更好地与教师模型相关联，并引入更多领域专业知识。通过一次训练，可以从TA模型中提取多个精确的学生模型。

**结果:** 在专有数据集和模型上展示了MatTA方法的效果，并通过生产ML系统中的活体A/B测试，关键指标提高了20%。在公共模型GPT-2 Medium上，SAT Math相对改进超过24%，LAMBADA基准相对改进超过10%。

**结论:** MatTA框架通过一次训练提供了多种可部署选项，能够平衡精度和服务成本，展示了其实际应用的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Matryoshka+Model+Learning+for+Improved+Elastic+Student+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23337，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23337&send_immediately=true&force_search=false)

**原文摘要:** Industry-grade ML models are carefully designed to meet rapidly evolving
serving constraints, which requires significant resources for model
development. In this paper, we propose MatTA, a framework for training multiple
accurate Student models using a novel Teacher-TA-Student recipe. TA models are
larger versions of the Student models with higher capacity, and thus allow
Student models to better relate to the Teacher model and also bring in more
domain-specific expertise. Furthermore, multiple accurate Student models can be
extracted from the TA model. Therefore, despite only one training run, our
methodology provides multiple servable options to trade off accuracy for lower
serving cost. We demonstrate the proposed method, MatTA, on proprietary
datasets and models. Its practical efficacy is underscored by live A/B tests
within a production ML system, demonstrating 20% improvement on a key metric.
We also demonstrate our method on GPT-2 Medium, a public model, and achieve
relative improvements of over 24% on SAT Math and over 10% on the LAMBADA
benchmark.

</details>


### [63] [QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining](https://arxiv.org/abs/2505.23004)
*Kyle R. Chickering, Bangzheng Li, Muhao Chen*

**主要类别:** cs.LG

**概要:** 本文提出了一种名为QLIP的新型视觉编码器，可以替代CLIP并提升多模态大语言模型（MLLMs）的性能。QLIP通过解决CLIP的局限性（如中观偏差和插值偏差），在不重新训练模型的情况下显著提升了LLaVA v1.5系列模型在视觉问答任务中的准确率，并在挑战性的$V^{\ast}$基准上提高了13.6%的详细理解性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前广泛使用的CLIP视觉编码器存在局限性，例如只能处理固定输入分辨率以及无法为不同图像生成分离的嵌入。此外，替换现有模型的视觉编码器通常需要高昂的计算成本，因为这通常需要重新训练整个模型管道。

**方法:** 作者识别出CLIP视觉编码器的两个主要问题：中观偏差和插值偏差，并提出了QLIP作为CLIP的直接替代方案。QLIP基于图像四叉树设计，用新颖的内容感知补丁化方法取代了标准的均匀网格补丁，从而增强了粗粒度和细粒度的视觉理解能力。QLIP可以通过几行代码无缝集成到现有的MLLMs中，而无需重新训练或微调整个模型。

**结果:** 实验结果表明，QLIP提升了LLaVA v1.5模型系列在各种模型大小下的通用视觉问答准确性，并且在困难的$V^{\ast}$基准测试中，QLIP将详细理解性能提高了高达13.6%。

**结论:** QLIP作为一种即插即用的CLIP替代方案，能够在不重新训练模型的情况下显著提高MLLMs的视觉理解能力，特别是在细粒度理解和复杂任务上的表现。这一改进为未来多模态模型的发展提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是QLIP%3A+A+Dynamic+Quadtree+Vision+Prior+Enhances+MLLM+Performance+Without+Retraining，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23004&send_immediately=true&force_search=false)

**原文摘要:** Multimodal Large Language Models (MLLMs) encode images into visual tokens,
aligning visual and textual signals within a shared latent space to facilitate
crossmodal representation learning. The CLIP model is a widely adopted
foundational vision language model whose vision encoder has played a critical
role in the development of MLLMs such as LLaVA. However, the CLIP vision
encoder suffers from notable limitations including being constrained to only
handling fixed input resolutions and a failure to produce separated embeddings
for dissimilar images. Replacing the vision encoder of an existing model
typically incurs substantial computational costs because such a change often
necessitates retraining the entire model pipeline.
  In this work, we identify two factors which underlie the limitations of the
CLIP vision encoder: mesoscopic bias and interpolation bias. To address these
issues, we propose QLIP, a drop-in replacement for CLIP that can be seamlessly
integrated with existing MLLMs with only a few lines of code and can enhance
both coarse-grained and fine-grained visual understanding, without re-training.
QLIP is designed around an image quadtree which replaces the standard uniform
grid patches with a novel content aware patchification. Our experimental
results demonstrate that QLIP improves the general visual question answering
accuracy of the LLaVA v1.5 model series across various model sizes--without
requiring retraining or fine-tuning of the full MLLM. Notably, QLIP boosts
detailed understanding performance on the challenging $V^{\ast}$ benchmark by
up to 13.6 percent.

</details>


### [64] [Towards Reward Fairness in RLHF: From a Resource Allocation Perspective](https://arxiv.org/abs/2505.23349)
*Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu*

**主要类别:** cs.LG

**概要:** 本文提出了一种解决奖励公平性的偏差无关方法，通过资源分配视角建模偏好学习，并提出了两种实现奖励公平性的方法：Fairness Regularization 和 Fairness Coefficient。实验表明该方法能更公平地对齐大语言模型与人类偏好。


<details>
  <summary>更多</summary>
  
**动机:** 在基于人类反馈的强化学习（RLHF）中，奖励作为人类偏好的代理起着关键作用，但若奖励存在各种偏差，可能会对大语言模型（LLMs）的对齐产生不利影响。因此，需要一种有效的方法来解决奖励中的不公平性问题。

**方法:** 作者将偏好学习建模为一个资源分配问题，把奖励视为需要分配的资源，同时考虑效用和公平性之间的权衡。提出了两种方法：Fairness Regularization 和 Fairness Coefficient 来实现奖励公平性，并分别在验证和强化学习场景中应用以获得公平奖励模型和策略模型。

**结果:** 实验结果表明，在验证和强化学习场景下，所提出的方法能够更公平地使大语言模型与人类偏好对齐。

**结论:** 解决奖励不公平性的问题可以通过资源分配的视角进行建模，并且所提出的偏差无关方法可以有效缓解奖励中的各种偏差，提升大语言模型与人类偏好的对齐程度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Reward+Fairness+in+RLHF%3A+From+a+Resource+Allocation+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23349，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23349&send_immediately=true&force_search=false)

**原文摘要:** Rewards serve as proxies for human preferences and play a crucial role in
Reinforcement Learning from Human Feedback (RLHF). However, if these rewards
are inherently imperfect, exhibiting various biases, they can adversely affect
the alignment of large language models (LLMs). In this paper, we collectively
define the various biases present in rewards as the problem of reward
unfairness. We propose a bias-agnostic method to address the issue of reward
fairness from a resource allocation perspective, without specifically designing
for each type of bias, yet effectively mitigating them. Specifically, we model
preference learning as a resource allocation problem, treating rewards as
resources to be allocated while considering the trade-off between utility and
fairness in their distribution. We propose two methods, Fairness Regularization
and Fairness Coefficient, to achieve fairness in rewards. We apply our methods
in both verification and reinforcement learning scenarios to obtain a fairness
reward model and a policy model, respectively. Experiments conducted in these
scenarios demonstrate that our approach aligns LLMs with human preferences in a
more fair manner.

</details>


### [65] [EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic, Expressiveness, and Linguistic Challenges Using Model-as-a-Judge](https://arxiv.org/abs/2505.23009)
*Ruskin Raj Manku, Yuzhi Tang, Xingjian Shi, Mu Li, Alex Smola*

**主要类别:** cs.LG

**概要:** 提出EmergentTTS-Eval，一个涵盖六种复杂TTS场景的基准测试框架，具有自动化测试用例生成与评估功能，通过模型评审方法对多个开源和专有TTS系统进行评测，展现其揭示细微性能差异的能力，并开源相关代码和数据集。


<details>
  <summary>更多</summary>
  
**动机:** 当前TTS基准测试常无法充分评估模型处理细腻且语义复杂文本的能力，因此需要更全面的评估工具。

**方法:** 基于EmergentTTS构建EmergentTTS-Eval，覆盖六种挑战性TTS场景；框架自动完成测试用例生成与评估；使用大型音频语言模型作为评审工具，从多维度评估语音质量。

**结果:** 该框架能有效揭示不同TTS系统之间的细微性能差异，模型评审方法与人类偏好高度相关。

**结论:** EmergentTTS-Eval为TTS系统的性能评估提供了强大且可扩展的工具，并促进了该领域的进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EmergentTTS-Eval%3A+Evaluating+TTS+Models+on+Complex+Prosodic%2C+Expressiveness%2C+and+Linguistic+Challenges+Using+Model-as-a-Judge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23009，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23009&send_immediately=true&force_search=false)

**原文摘要:** Text-to-Speech (TTS) benchmarks often fail to capture how well models handle
nuanced and semantically complex text. Building on $\textit{EmergentTTS}$, we
introduce $\textit{EmergentTTS-Eval}$, a comprehensive benchmark covering six
challenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic
complexity, complex pronunciation (e.g. URLs, formulas), and questions.
Crucially, our framework automates both test-case generation and evaluation,
making the benchmark easily extensible. Starting from a small set of
human-written seed prompts, we iteratively extend them using LLMs to target
specific structural, phonetic and prosodic challenges, resulting in 1,645
diverse test cases. Moreover, we employ a model-as-a-judge approach, using a
Large Audio Language Model (LALM) to assess the speech across multiple
dimensions such as expressed emotion, prosodic, intonational, and pronunciation
accuracy. We evaluate state-of-the-art open-source and proprietary TTS systems,
such as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval,
demonstrating its ability to reveal fine-grained performance differences.
Results show that the model-as-a-judge approach offers robust TTS assessment
and a high correlation with human preferences. We open source the evaluation
$\href{https://github.com/boson-ai/EmergentTTS-Eval-public}{code}$ and the
$\href{https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{dataset}$.

</details>


### [66] [Dynamic Spectral Backpropagation for Efficient Neural Network Training](https://arxiv.org/abs/2505.23369)
*Mannmohan Muthuraman*

**主要类别:** cs.LG

**概要:** Dynamic Spectral Backpropagation (DSBP)通过将梯度投影到主特征向量上，在资源限制下增强神经网络训练，提出五个扩展方向，并在多个数据集上超越SAM、LoRA和MAML。


<details>
  <summary>更多</summary>
  
**动机:** 在资源受限的情况下提高神经网络的训练效率，同时解决鲁棒性、小样本学习和硬件效率等问题。

**方法:** 提出动态谱推理、谱结构优化、谱元学习、谱迁移正则化和李代数启发的动力学等五个扩展方向，结合三阶随机微分方程（SDE）和PAC贝叶斯极限支持方法。

**结果:** DSBP在CIFAR 10、Fashion MNIST、MedMNIST和Tiny ImageNet等多个数据集上的表现优于Sharpness Aware Minimization (SAM)、Low Rank Adaptation (LoRA)和Model Agnostic Meta Learning (MAML)。

**结论:** DSBP及其扩展方法有效提高了神经网络训练效率和性能，未来将进一步研究可扩展性、偏差缓解和伦理问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Spectral+Backpropagation+for+Efficient+Neural+Network+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23369，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23369&send_immediately=true&force_search=false)

**原文摘要:** Dynamic Spectral Backpropagation (DSBP) enhances neural network training
under resource constraints by projecting gradients onto principal eigenvectors,
reducing complexity and promoting flat minima. Five extensions are proposed,
dynamic spectral inference, spectral architecture optimization, spectral meta
learning, spectral transfer regularization, and Lie algebra inspired dynamics,
to address challenges in robustness, fewshot learning, and hardware efficiency.
Supported by a third order stochastic differential equation (SDE) and a PAC
Bayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank
Adaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion
MNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive
experiments and visualizations. Future work focuses on scalability, bias
mitigation, and ethical considerations.

</details>


### [67] [Scalable Complexity Control Facilitates Reasoning Ability of LLMs](https://arxiv.org/abs/2505.23013)
*Liangkai Hang, Junjie Yao, Zhiwei Bai, Tianyi Chen, Yang Chen, Rongjie Diao, Hezhou Li, Pengxiao Lin, Zhiwei Wang, Cheng Xu, Zhongwang Zhang, Zhangchen Zhou, Zhiyu Li, Zehao Lin, Kai Chen, Feiyu Xiong, Yaoyu Zhang, Weinan E, Hongkang Yang, Zhi-Qin John Xu*

**主要类别:** cs.LG

**概要:** 通过调整初始化速率和权重衰减系数来控制模型复杂度，可以改进LLM的扩展规律。恒定的初始化速率（std的指数）能使扩展规律在模型大小和数据大小上更快下降。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）近年来推理能力迅速提升，引起对可靠增强其泛化能力的基本方法的兴趣。

**方法:** 通过调整初始化速率和权重衰减系数实现模型复杂度控制，并比较不同复杂度超参数的2.4B模型在1T token上的预训练基准性能。使用恒定的初始化速率（std的指数），而非固定的初始化标准差。

**结果:** 模型复杂度控制改进了LLM在不同模型大小和数据大小下的扩展规律。恒定初始化速率使扩展规律更快下降。

**结论:** 复杂度控制是持续提升LLM的一个有希望的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Complexity+Control+Facilitates+Reasoning+Ability+of+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23013，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23013&send_immediately=true&force_search=false)

**原文摘要:** The reasoning ability of large language models (LLMs) has been rapidly
advancing in recent years, attracting interest in more fundamental approaches
that can reliably enhance their generalizability. This work demonstrates that
model complexity control, conveniently implementable by adjusting the
initialization rate and weight decay coefficient, improves the scaling law of
LLMs consistently over varying model sizes and data sizes. This gain is further
illustrated by comparing the benchmark performance of 2.4B models pretrained on
1T tokens with different complexity hyperparameters. Instead of fixing the
initialization std, we found that a constant initialization rate (the exponent
of std) enables the scaling law to descend faster in both model and data sizes.
These results indicate that complexity control is a promising direction for the
continual advancement of LLMs.

</details>


### [68] [Buffer-free Class-Incremental Learning with Out-of-Distribution Detection](https://arxiv.org/abs/2505.23412)
*Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli*

**主要类别:** cs.LG

**概要:** 本论文探讨了在类增量学习（CIL）中，使用事后OOD检测方法替代基于缓冲区的方法的可能性，以解决隐私、可扩展性和训练时间问题。实验表明，无缓冲区方法在CIL和未知样本拒绝方面具有相当或更优的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的CIL方法通过多头模型和任务识别结合OOD检测来缓解灾难性遗忘和未知类别处理问题，但依赖于包含过往数据的记忆缓冲区，引发隐私、可扩展性和训练时间方面的担忧。

**方法:** 作者对事后OOD检测方法进行了深入分析，并研究了这些方法在推理阶段的应用是否可以替代基于缓冲区的OOD检测方法。

**结果:** 实验结果表明，无缓冲区的方法在CIFAR-10、CIFAR-100和Tiny ImageNet数据集上取得了与基于缓冲区方法相当甚至更好的性能，特别是在CIL和拒绝未知样本方面。

**结论:** 事后OOD检测方法可以有效替代基于缓冲区的OOD检测，提供了一种高效且保护隐私的CIL系统设计方案，适用于开放世界场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Buffer-free+Class-Incremental+Learning+with+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23412，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23412&send_immediately=true&force_search=false)

**原文摘要:** Class-incremental learning (CIL) poses significant challenges in open-world
scenarios, where models must not only learn new classes over time without
forgetting previous ones but also handle inputs from unknown classes that a
closed-set model would misclassify. Recent works address both issues by
(i)~training multi-head models using the task-incremental learning framework,
and (ii) predicting the task identity employing out-of-distribution (OOD)
detectors. While effective, the latter mainly relies on joint training with a
memory buffer of past data, raising concerns around privacy, scalability, and
increased training time. In this paper, we present an in-depth analysis of
post-hoc OOD detection methods and investigate their potential to eliminate the
need for a memory buffer. We uncover that these methods, when applied
appropriately at inference time, can serve as a strong substitute for
buffer-based OOD detection. We show that this buffer-free approach achieves
comparable or superior performance to buffer-based methods both in terms of
class-incremental learning and the rejection of unknown samples. Experimental
results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings,
offering new insights into the design of efficient and privacy-preserving CIL
systems for open-world settings.

</details>


### [69] [Hyperbolic-PDE GNN: Spectral Graph Neural Networks in the Perspective of A System of Hyperbolic Partial Differential Equations](https://arxiv.org/abs/2505.23014)
*Juwei Yue, Haikuo Li, Jiawei Sheng, Xiaodong Li, Taoyu Su, Tingwen Liu, Li Guo*

**主要类别:** cs.LG

**概要:** 本文将消息传递机制建模为双曲偏微分方程系统，通过分解节点特征增强拓扑结构的可解释性和提取能力，并与谱图神经网络建立联系。实验表明该方法具有高度灵活性和性能提升效果。


<details>
  <summary>更多</summary>
  
**动机:** 传统的图神经网络在空间域中学习节点特征，与拓扑结构无关，难以确保学习到有效的拓扑特征。因此需要一种新的方法来显式地捕捉图数据的拓扑特性。

**方法:** 将消息传递机制表示为双曲偏微分方程系统，形成一个动态系统，将节点表示映射到特定解空间。该解空间由描述图拓扑结构的特征向量集合张成。通过求解此系统，建立与谱图神经网络的联系，并引入多项式近似任意滤波函数。

**结果:** 大量实验证明，基于双曲偏微分方程的范式不仅表现出强大的灵活性，而且显著提升了各种谱图神经网络在不同图任务中的性能。

**结论:** 提出的方法通过双曲偏微分方程系统增强了消息传递机制的可解释性，并能显式提取图的拓扑结构特征，同时改进了谱图神经网络的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hyperbolic-PDE+GNN%3A+Spectral+Graph+Neural+Networks+in+the+Perspective+of+A+System+of+Hyperbolic+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23014，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23014&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) leverage message passing mechanisms to learn the
topological features of graph data. Traditional GNNs learns node features in a
spatial domain unrelated to the topology, which can hardly ensure topological
features. In this paper, we formulates message passing as a system of
hyperbolic partial differential equations (hyperbolic PDEs), constituting a
dynamical system that explicitly maps node representations into a particular
solution space. This solution space is spanned by a set of eigenvectors
describing the topological structure of graphs. Within this system, for any
moment in time, a node features can be decomposed into a superposition of the
basis of eigenvectors. This not only enhances the interpretability of message
passing but also enables the explicit extraction of fundamental characteristics
about the topological structure. Furthermore, by solving this system of
hyperbolic partial differential equations, we establish a connection with
spectral graph neural networks (spectral GNNs), serving as a message passing
enhancement paradigm for spectral GNNs.We further introduce polynomials to
approximate arbitrary filter functions. Extensive experiments demonstrate that
the paradigm of hyperbolic PDEs not only exhibits strong flexibility but also
significantly enhances the performance of various spectral GNNs across diverse
graph tasks.

</details>


### [70] [Bidirectional predictive coding](https://arxiv.org/abs/2505.23415)
*Gaspard Oliviers, Mufeng Tang, Rafal Bogacz*

**主要类别:** cs.LG

**概要:** 提出了一种新的预测编码模型bPC，该模型结合了生成和判别推理，在多种任务中表现优于单向模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有的预测编码（PC）模型要么是生成模型，要么是判别模型，但实验表明大脑同时使用这两种推理方式，而单向模型在需要双向处理的任务中表现不佳。

**方法:** 提出了双向预测编码（bPC）模型，该模型将生成和判别推理结合在一起，并保持了生物学上可行的电路实现。通过开发一个同时适用于两种任务的能量景观，使bPC在生成或判别任务中都能匹配或超越单向模型。

**结果:** bPC在专门的生成或判别任务中匹配或超越了单向模型的表现，并在两个与生物学相关的任务（多模态学习和缺失信息推理）中展示了优越的性能，表明bPC更接近于生物视觉推理。

**结论:** bPC模型更好地模拟了生物视觉推理过程，可能为理解大脑中的视觉学习和推理提供一个新的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bidirectional+predictive+coding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23415，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23415&send_immediately=true&force_search=false)

**原文摘要:** Predictive coding (PC) is an influential computational model of visual
learning and inference in the brain. Classical PC was proposed as a top-down
generative model, where the brain actively predicts upcoming visual inputs, and
inference minimises the prediction errors. Recent studies have also shown that
PC can be formulated as a discriminative model, where sensory inputs predict
neural activities in a feedforward manner. However, experimental evidence
suggests that the brain employs both generative and discriminative inference,
while unidirectional PC models show degraded performance in tasks requiring
bidirectional processing. In this work, we propose bidirectional PC (bPC), a PC
model that incorporates both generative and discriminative inference while
maintaining a biologically plausible circuit implementation. We show that bPC
matches or outperforms unidirectional models in their specialised generative or
discriminative tasks, by developing an energy landscape that simultaneously
suits both tasks. We also demonstrate bPC's superior performance in two
biologically relevant tasks including multimodal learning and inference with
missing information, suggesting that bPC resembles biological visual inference
more closely.

</details>


### [71] [Enhanced DACER Algorithm with High Diffusion Efficiency](https://arxiv.org/abs/2505.23426)
*Yinuo Wang, Mining Tan, Wenjun Zou, Haotian Lin, Xujie Song, Wenxuan Wang, Tong Liu, Likun Wang, Guojian Zhan, Tianze Zhu, Shiqi Liu, Jingliang Duan, Shengbo Eben Li*

**主要类别:** cs.LG

**概要:** DACER2通过引入Q-gradient field目标和时间加权机制，优化了扩散策略的训练与推理效率，在MuJoCo基准测试中仅用5步扩散即达到顶尖性能，并展现出更强的多模态能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管扩散模型在离线RL和模仿学习中表现出色，但其在线RL应用中存在训练效率低的问题，减少扩散步骤又会导致性能下降。因此需要一种方法来提高扩散策略的训练和推理效率，同时保持或增强性能。

**方法:** 提出Q-gradient field目标作为辅助优化目标以指导每一步扩散过程中的去噪操作，并引入时间加权机制使模型在早期阶段能有效消除大规模噪声，在后期阶段精细调整动作。

**结果:** 在MuJoCo基准测试和多模态任务中，DACER2算法仅用五步扩散就达到了顶尖性能，并展现了比DACER更强的多模态能力。

**结论:** DACER2通过优化扩散步骤，显著提高了训练和推理效率，同时保持甚至增强了性能，为实时在线RL提供了更高效的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhanced+DACER+Algorithm+with+High+Diffusion+Efficiency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23426，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23426&send_immediately=true&force_search=false)

**原文摘要:** Due to their expressive capacity, diffusion models have shown great promise
in offline RL and imitation learning. Diffusion Actor-Critic with Entropy
Regulator (DACER) extended this capability to online RL by using the reverse
diffusion process as a policy approximator, trained end-to-end with policy
gradient methods, achieving strong performance. However, this comes at the cost
of requiring many diffusion steps, which significantly hampers training
efficiency, while directly reducing the steps leads to noticeable performance
degradation. Critically, the lack of inference efficiency becomes a significant
bottleneck for applying diffusion policies in real-time online RL settings. To
improve training and inference efficiency while maintaining or even enhancing
performance, we propose a Q-gradient field objective as an auxiliary
optimization target to guide the denoising process at each diffusion step.
Nonetheless, we observe that the independence of the Q-gradient field from the
diffusion time step negatively impacts the performance of the diffusion policy.
To address this, we introduce a temporal weighting mechanism that enables the
model to efficiently eliminate large-scale noise in the early stages and refine
actions in the later stages. Experimental results on MuJoCo benchmarks and
several multimodal tasks demonstrate that the DACER2 algorithm achieves
state-of-the-art performance in most MuJoCo control tasks with only five
diffusion steps, while also exhibiting stronger multimodality compared to
DACER.

</details>


### [72] [SCORPIO: Serving the Right Requests at the Right Time for Heterogeneous SLOs in LLM Inference](https://arxiv.org/abs/2505.23022)
*Yinghao Tang, Tingfeng Lan, Xiuqi Huang, Hui Lu, Wei Chen*

**主要类别:** cs.LG

**概要:** SCORPIO 是一种以 SLO 为导向的大型语言模型服务系统，通过 TTFT Guard 和 TPOT Guard 提高系统吞吐量和 SLO 达成率，相比现有基线最高提升 14.4 倍吞吐量和 46.5% 的 SLO 遵循度。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型语言模型服务系统侧重最大吞吐量，忽视了如首次输出时间（TTFT）和每输出令牌时间（TPOT）等服务质量目标（SLO），导致 SLO 达成效果不佳。

**方法:** 提出 SCORPIO 系统，核心是利用 SLO 异质性进行自适应调度，涵盖准入控制、队列管理和批量选择。系统包括 TTFT Guard（采用最早截止期限优先重排和拒绝不可达请求）和 TPOT Guard（使用基于 VBS 的准入控制和基于信用的新型批量机制），两者由预测模块支持。

**结果:** 评估表明，与最先进的基线相比，SCORPIO 将系统有效吞吐量提高了高达 14.4 倍，并将 SLO 遵循度提升了高达 46.5%。

**结论:** SCORPIO 成功通过 SLO 导向设计显著改善了异构工作负载下的系统性能和 SLO 达成情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SCORPIO%3A+Serving+the+Right+Requests+at+the+Right+Time+for+Heterogeneous+SLOs+in+LLM+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23022，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23022&send_immediately=true&force_search=false)

**原文摘要:** Existing Large Language Model (LLM) serving systems prioritize maximum
throughput. They often neglect Service Level Objectives (SLOs) such as Time to
First Token (TTFT) and Time Per Output Token (TPOT), which leads to suboptimal
SLO attainment. This paper introduces SCORPIO, an SLO-oriented LLM serving
system designed to maximize system goodput and SLO attainment for workloads
with heterogeneous SLOs. Our core insight is to exploit SLO heterogeneity for
adaptive scheduling across admission control, queue management, and batch
selection. SCORPIO features a TTFT Guard, which employs least-deadline-first
reordering and rejects unattainable requests, and a TPOT Guard, which utilizes
a VBS-based admission control and a novel credit-based batching mechanism. Both
guards are supported by a predictive module. Evaluations demonstrate that
SCORPIO improves system goodput by up to 14.4X and SLO adherence by up to 46.5%
compared to state-of-the-art baselines.

</details>


### [73] [Bounded-Abstention Pairwise Learning to Rank](https://arxiv.org/abs/2505.23437)
*Antonio Ferrara, Andrea Pugnana, Francesco Bonchi, Salvatore Ruggieri*

**主要类别:** cs.LG

**概要:** 论文提出了一种新的弃权方法，适用于成对学习排序任务，通过设定条件风险阈值来决定是否弃权，并展示了其在多个数据集上的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在高风险领域，如健康、教育和就业中的排名系统会影响决策，并带来显著的经济和社会影响。因此，安全机制的整合变得至关重要。其中一种机制是'弃权'（abstention），它允许算法决策系统将不确定或低置信度的决策转移给人类专家。尽管在分类任务中已广泛研究了弃权机制，但在其他机器学习范式中的应用仍然较少探索。

**方法:** 提出了一种基于对排序器条件风险阈值的方法，用于成对学习排序任务中的弃权。当估计的风险超过预定义的阈值时，系统会放弃做出决策。

**结果:** 理论特征的最佳弃权策略；一个与模型无关的、可插入的算法，用于构建弃权排序模型；以及多个数据集上的全面实证评估，证明了该方法的有效性。

**结论:** 本文提出了一个新的成对学习排序任务中的弃权方法，通过条件风险阈值来决定是否弃权，并提供了理论、算法和实证的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bounded-Abstention+Pairwise+Learning+to+Rank，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23437，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23437&send_immediately=true&force_search=false)

**原文摘要:** Ranking systems influence decision-making in high-stakes domains like health,
education, and employment, where they can have substantial economic and social
impacts. This makes the integration of safety mechanisms essential. One such
mechanism is $\textit{abstention}$, which enables algorithmic decision-making
system to defer uncertain or low-confidence decisions to human experts. While
abstention have been predominantly explored in the context of classification
tasks, its application to other machine learning paradigms remains
underexplored. In this paper, we introduce a novel method for abstention in
pairwise learning-to-rank tasks. Our approach is based on thresholding the
ranker's conditional risk: the system abstains from making a decision when the
estimated risk exceeds a predefined threshold. Our contributions are threefold:
a theoretical characterization of the optimal abstention strategy, a
model-agnostic, plug-in algorithm for constructing abstaining ranking models,
and a comprehensive empirical evaluations across multiple datasets,
demonstrating the effectiveness of our approach.

</details>


### [74] [An Empirical Study of Federated Prompt Learning for Vision Language Model](https://arxiv.org/abs/2505.23024)
*Zhihao Wang, Wenke Huang, Tian Chen, Zekun Shi, Guancheng Wan, Yu Qiao, Bin Yang, Jian Wang, Bing Li, Mang Ye*

**主要类别:** cs.LG

**概要:** 论文探讨了在联邦学习场景中，语言提示学习（LPT）和视觉提示学习（VPT）的行为差异，并评估了不同配置对Federated Prompt Learning (FPL)鲁棒性的影响。此外，还研究了在标签偏斜和领域转移共存的复杂情况下提升提示学习的策略，为优化隐私保护环境下的VLM应用提供了实用见解。


<details>
  <summary>更多</summary>
  
**动机:** 当前对于将提示学习与视觉语言模型（VLM）结合并在联邦学习场景中的应用研究较少，特别是在数据异质性挑战如标签偏斜和领域转移的情况下。

**方法:** 1. 系统研究语言提示学习和视觉提示学习在联邦学习场景下的行为差异。
2. 进行广泛实验，评估不同联邦学习和提示配置（如客户端规模、聚合策略、提示长度）对Federated Prompt Learning (FPL)的影响。
3. 探索在标签偏斜和领域转移共存的复杂场景下增强提示学习的策略，包括在计算资源允许时结合两种提示类型。

**结果:** 实验结果展示了不同配置对FPL鲁棒性的影响，并揭示了在复杂数据异质性挑战下的有效策略。

**结论:** 研究为优化联邦学习环境下的提示学习提供了实用指导，推动了在隐私保护环境中更广泛地部署视觉语言模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Empirical+Study+of+Federated+Prompt+Learning+for+Vision+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23024&send_immediately=true&force_search=false)

**原文摘要:** The Vision Language Model (VLM) excels in aligning vision and language
representations, and prompt learning has emerged as a key technique for
adapting such models to downstream tasks. However, the application of prompt
learning with VLM in federated learning (\fl{}) scenarios remains
underexplored. This paper systematically investigates the behavioral
differences between language prompt learning (LPT) and vision prompt learning
(VPT) under data heterogeneity challenges, including label skew and domain
shift. We conduct extensive experiments to evaluate the impact of various \fl{}
and prompt configurations, such as client scale, aggregation strategies, and
prompt length, to assess the robustness of Federated Prompt Learning (FPL).
Furthermore, we explore strategies for enhancing prompt learning in complex
scenarios where label skew and domain shift coexist, including leveraging both
prompt types when computational resources allow. Our findings offer practical
insights into optimizing prompt learning in federated settings, contributing to
the broader deployment of VLMs in privacy-preserving environments.

</details>


### [75] [Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning](https://arxiv.org/abs/2505.23529)
*Shifeng Xie, Aref Einizade, Jhony H. Giraldo*

**主要类别:** cs.LG

**概要:** 提出了一种新的子图高斯嵌入对比（SubGEC）方法，通过自适应地将子图映射到结构化的高斯空间，并使用最优传输距离来衡量子图间的相似性，从而在图表示学习中实现优越或有竞争力的性能。


<details>
  <summary>更多</summary>
  
**动机:** 避免昂贵的人工标注，利用自监督学习方法进行图表示学习，同时解决生成对比对分布的重要性问题。

**方法:** 引入子图高斯嵌入模块，将子图映射到高斯空间，并使用Wasserstein和Gromov-Wasserstein距离来衡量子图之间的相似性。

**结果:** 在多个基准测试中的广泛实验证明了该方法优于或与最先进的方法具有竞争力。

**结论:** 研究结果为图表示学习中的自监督学习方法设计提供了见解，强调了生成对比对分布的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Subgraph+Gaussian+Embedding+Contrast+for+Self-Supervised+Graph+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23529，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23529&send_immediately=true&force_search=false)

**原文摘要:** Graph Representation Learning (GRL) is a fundamental task in machine
learning, aiming to encode high-dimensional graph-structured data into
low-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used
in GRL because they can avoid expensive human annotation. In this work, we
propose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our
approach introduces a subgraph Gaussian embedding module, which adaptively maps
subgraphs to a structured Gaussian space, ensuring the preservation of input
subgraph characteristics while generating subgraphs with a controlled
distribution. We then employ optimal transport distances, more precisely the
Wasserstein and Gromov-Wasserstein distances, to effectively measure the
similarity between subgraphs, enhancing the robustness of the contrastive
learning process. Extensive experiments across multiple benchmarks demonstrate
that \method~outperforms or presents competitive performance against
state-of-the-art approaches. Our findings provide insights into the design of
SSL methods for GRL, emphasizing the importance of the distribution of the
generated contrastive pairs.

</details>


### [76] [Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models](https://arxiv.org/abs/2505.23564)
*Yiran Guo, Lijie Xu, Jie Liu, Dan Ye, Shuang Qiu*

**主要类别:** cs.LG

**概要:** 通过强化学习提升大型语言模型推理能力的有效性仍是一个关键挑战。现有的方法主要采用两种对比优势估计粒度：Token级方法（如PPO）和轨迹级方法（如GRPO）。为了解决这些方法的局限性，本文提出了段落策略优化（SPO），一种新颖的强化学习框架，利用中等粒度的段落级优势估计，在精确信用分配和估计点数量之间取得更好的平衡。SPO包括三个组件：灵活的段落划分、准确的段落优势估计和基于段落优势的策略优化，并在两个具体场景中进行了实例化，分别在GSM8K和MATH500数据集上取得了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的强化学习方法要么由于难以训练准确的评估模型而导致估计不准确（Token级方法），要么仅依赖最终奖励导致粗略的信用分配（轨迹级方法）。这促使研究者探索一种新的方法来解决这两种方法的不足。

**方法:** 提出了一种名为段落策略优化（SPO）的新框架，利用中等粒度的段落级优势估计。SPO包含三个关键组件：(1) 灵活的段落划分；(2) 准确的段落优势估计；(3) 基于段落优势的策略优化，其中包括一种新的概率掩码策略。此外，SPO被实例化为两种特定场景：SPO-chain用于短链推理，SPO-tree用于长链推理。

**结果:** SPO-chain在GSM8K数据集上相比PPO和GRPO提高了6-12个百分点的准确性。SPO-tree在MATH500数据集上，在2K和4K上下文评估下相比GRPO提高了7-11个百分点的准确性。

**结论:** SPO作为一种新颖的强化学习框架，通过段落级优势估计有效解决了现有方法的局限性，实现了更精确的信用分配和较少的估计点需求。它在短链和长链推理任务中都表现出了显著的性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Segment+Policy+Optimization%3A+Effective+Segment-Level+Credit+Assignment+in+RL+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23564，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23564&send_immediately=true&force_search=false)

**原文摘要:** Enhancing the reasoning capabilities of large language models effectively
using reinforcement learning (RL) remains a crucial challenge. Existing
approaches primarily adopt two contrasting advantage estimation granularities:
Token-level methods (e.g., PPO) aim to provide the fine-grained advantage
signals but suffer from inaccurate estimation due to difficulties in training
an accurate critic model. On the other extreme, trajectory-level methods (e.g.,
GRPO) solely rely on a coarse-grained advantage signal from the final reward,
leading to imprecise credit assignment. To address these limitations, we
propose Segment Policy Optimization (SPO), a novel RL framework that leverages
segment-level advantage estimation at an intermediate granularity, achieving a
better balance by offering more precise credit assignment than trajectory-level
methods and requiring fewer estimation points than token-level methods,
enabling accurate advantage estimation based on Monte Carlo (MC) without a
critic model. SPO features three components with novel strategies: (1) flexible
segment partition; (2) accurate segment advantage estimation; and (3) policy
optimization using segment advantages, including a novel probability-mask
strategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain
for short chain-of-thought (CoT), featuring novel cutpoint-based partition and
chain-based advantage estimation, achieving $6$-$12$ percentage point
improvements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,
featuring novel tree-based advantage estimation, which significantly reduces
the cost of MC estimation, achieving $7$-$11$ percentage point improvements
over GRPO on MATH500 under 2K and 4K context evaluation. We make our code
publicly available at https://github.com/AIFrameResearch/SPO.

</details>


### [77] [SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA](https://arxiv.org/abs/2505.23724)
*Minrui Luo, Fuhang Kuang, Yu Wang, Zirui Liu, Tianxing He*

**主要类别:** cs.LG

**概要:** 论文提出了一种新的LoRA初始化框架——Subspace-Constrained LoRA（SC-LoRA），它通过限制可训练LoRA适配器的输出在一个低秩子空间内，以平衡高效微调和知识保留之间的权衡。实验表明，SC-LoRA在提高微调性能的同时显著减少了知识遗忘，超越了现有的LoRA初始化方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LoRA方法虽然有助于高效定制大语言模型，但存在收敛速度慢和知识遗忘的问题。尽管已有研究尝试通过设计LoRA初始化来增强微调效率或保留预训练知识，但尚未有方法能同时解决这两个问题。

**方法:** 作者提出了Subspace-Constrained LoRA (SC-LoRA)，这是一种新的LoRA初始化框架。该框架通过将可训练LoRA适配器的输出限制在一个低秩子空间中，在此子空间中，微调数据的上下文信息得到最大程度的保留，而预训练知识的上下文信息则以最小程度保留，从而实现两者的平衡。这样的约束使得可训练权重主要集中在微调数据的主要特征上，同时避免损害已保留的知识特征。

**结果:** 理论分析和广泛的实验结果表明，SC-LoRA在各种下游任务中成功地提高了微调性能，同时显著减少了知识遗忘现象。相较于当代其他LoRA初始化方法，SC-LoRA表现出色。

**结论:** SC-LoRA是一种有效的新型LoRA初始化框架，能够在提升微调效率的同时减少知识遗忘，为大语言模型的参数高效微调提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SC-LoRA%3A+Balancing+Efficient+Fine-tuning+and+Knowledge+Preservation+via+Subspace-Constrained+LoRA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23724，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23724&send_immediately=true&force_search=false)

**原文摘要:** Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank
Adaptation (LoRA), are indispensable for efficiently customizing Large Language
Models (LLMs). However, vanilla LoRA suffers from slow convergence speed and
knowledge forgetting problems. Recent studies have leveraged the power of
designed LoRA initialization, to enhance the fine-tuning efficiency, or to
preserve knowledge in the pre-trained LLM. However, none of these works can
address the two cases at the same time. To this end, we introduce
Subspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework
engineered to navigate the trade-off between efficient fine-tuning and
knowledge preservation. We achieve this by constraining the output of trainable
LoRA adapters in a low-rank subspace, where the context information of
fine-tuning data is most preserved while the context information of preserved
knowledge is least retained, in a balanced way. Such constraint enables the
trainable weights to primarily focus on the main features of fine-tuning data
while avoiding damaging the preserved knowledge features. We provide
theoretical analysis on our method, and conduct extensive experiments including
safety preservation and world knowledge preservation, on various downstream
tasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning
performance while markedly diminishing knowledge forgetting, surpassing
contemporary LoRA initialization methods.

</details>


### [78] [ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation](https://arxiv.org/abs/2505.23048)
*Tianci Bu, Le Zhou, Wenchuan Yang, Jianhong Mou, Kang Yang, Suoyi Tan, Feng Yao, Jingyuan Wang, Xin Lu*

**主要类别:** cs.LG

**概要:** 提出了一种新的轨迹补全框架ProDiff，通过原型学习和去噪扩散概率模型，仅使用两个端点作为最小信息进行轨迹补全，效果优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 轨迹数据在多种应用中至关重要，但由于设备限制和多样化的采集场景，常常存在不完整性问题。现有的补全方法依赖于稀疏轨迹或旅行信息（如速度），但这些方法假设稀疏轨迹保留了基本的行为模式，对数据获取要求较高，并且忽略了大规模人类轨迹嵌入的潜力。

**方法:** 提出了ProDiff，一种仅使用两个端点作为最小信息的轨迹补全框架。它结合了原型学习以嵌入人类运动模式，以及去噪扩散概率模型以实现鲁棒的空间时间重建。通过联合训练和定制的损失函数确保了有效的补全。

**结果:** ProDiff在FourSquare和WuXi数据集上分别提高了6.28%和2.52%的准确性。进一步分析表明生成轨迹与真实轨迹之间的相关性为0.927，证明了该方法的有效性。

**结论:** ProDiff是一种新颖且有效的轨迹补全框架，能够利用少量信息实现高质量的轨迹重建，超越了现有最先进的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ProDiff%3A+Prototype-Guided+Diffusion+for+Minimal+Information+Trajectory+Imputation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23048&send_immediately=true&force_search=false)

**原文摘要:** Trajectory data is crucial for various applications but often suffers from
incompleteness due to device limitations and diverse collection scenarios.
Existing imputation methods rely on sparse trajectory or travel information,
such as velocity, to infer missing points. However, these approaches assume
that sparse trajectories retain essential behavioral patterns, which place
significant demands on data acquisition and overlook the potential of
large-scale human trajectory embeddings. To address this, we propose ProDiff, a
trajectory imputation framework that uses only two endpoints as minimal
information. It integrates prototype learning to embed human movement patterns
and a denoising diffusion probabilistic model for robust spatiotemporal
reconstruction. Joint training with a tailored loss function ensures effective
imputation. ProDiff outperforms state-of-the-art methods, improving accuracy by
6.28\% on FourSquare and 2.52\% on WuXi. Further analysis shows a 0.927
correlation between generated and real trajectories, demonstrating the
effectiveness of our approach.

</details>


### [79] [REOrdering Patches Improves Vision Models](https://arxiv.org/abs/2505.23751)
*Declan Kutscher, David M. Chan, Yutong Bai, Trevor Darrell, Ritwik Gupta*

**主要类别:** cs.LG

**概要:** 本论文探讨了在使用现代长序列Transformer模型时，图像补丁顺序对模型性能的影响，并提出了一个名为REOrder的两阶段框架，用于发现任务最优的补丁排列顺序。通过信息理论评估和强化学习优化，该方法提高了ImageNet-1K和Functional Map of the World数据集上的分类准确率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管完整的自注意力机制具有排列等变性，但现代长序列Transformer模型越来越多地依赖于破坏这种不变性的架构近似，从而引入了对补丁顺序的敏感性。因此，研究不同的补丁顺序如何影响模型性能成为重要问题。

**方法:** 提出了一种名为REOrder的两阶段框架：首先通过信息理论评估各种补丁序列的可压缩性以获得先验知识；然后利用Plackett-Luce策略并通过REINFORCE算法进行优化，学习排列空间中的最佳策略。

**结果:** 在ImageNet-1K数据集上，REOrder相较于传统的行优先顺序提升了最高3.01%的Top-1准确率，在Functional Map of the World数据集上提升了13.35%。

**结论:** 不同的补丁顺序显著影响现代长序列Transformer模型的性能，而REOrder提供了一种有效的方法来发现任务最优的补丁排列顺序，从而提升模型表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是REOrdering+Patches+Improves+Vision+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23751，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23751&send_immediately=true&force_search=false)

**原文摘要:** Sequence models such as transformers require inputs to be represented as
one-dimensional sequences. In vision, this typically involves flattening images
using a fixed row-major (raster-scan) order. While full self-attention is
permutation-equivariant, modern long-sequence transformers increasingly rely on
architectural approximations that break this invariance and introduce
sensitivity to patch ordering. We show that patch order significantly affects
model performance in such settings, with simple alternatives like column-major
or Hilbert curves yielding notable accuracy shifts. Motivated by this, we
propose REOrder, a two-stage framework for discovering task-optimal patch
orderings. First, we derive an information-theoretic prior by evaluating the
compressibility of various patch sequences. Then, we learn a policy over
permutations by optimizing a Plackett-Luce policy using REINFORCE. This
approach enables efficient learning in a combinatorial permutation space.
REOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to
3.01% and Functional Map of the World by 13.35%.

</details>


### [80] [DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration](https://arxiv.org/abs/2505.23049)
*Tianteng Gu, Bei Liu, Bo Xiao, Ke Zeng, Jiacheng Liu, Yanmin Qian*

**主要类别:** cs.LG

**概要:** 本文提出了DenoiseRotator，一种通过重新分配参数重要性来增强模型剪枝鲁棒性的新方法。实验表明，它能有效改善剪枝后大型语言模型的性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的剪枝方法主要集中在估计单个权重的重要性，这限制了它们在保留模型关键能力方面的能力。特别是，在半结构化稀疏约束下，性能下降显著。

**方法:** 提出了一种新的视角：通过最小化归一化重要性分数的信息熵，将重要性集中到更小的权重子集上，从而增强剪枝的鲁棒性。具体方法是通过DenoiseRotator应用可学习的正交变换到模型的权重矩阵上。该方法与现有的剪枝技术（如Magnitude、SparseGPT和Wanda）无缝集成。

**结果:** 在LLaMA3、Qwen2.5和Mistral模型上进行评估，DenoiseRotator在50%非结构化和2:4半结构化稀疏条件下，一致提高了困惑度和零样本准确性。例如，在LLaMA3-70B模型上使用SparseGPT进行2:4半结构化稀疏剪枝时，DenoiseRotator将困惑度差距减少了58%，从8.1点降低到3.4点。

**结论:** DenoiseRotator是一种模型无关的方法，能够提高语言模型剪枝后的性能，缩小与密集模型之间的差距，并且可以与现有剪枝技术结合使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DenoiseRotator%3A+Enhance+Pruning+Robustness+for+LLMs+via+Importance+Concentration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23049，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23049&send_immediately=true&force_search=false)

**原文摘要:** Pruning is a widely used technique to compress large language models (LLMs)
by removing unimportant weights, but it often suffers from significant
performance degradation - especially under semi-structured sparsity
constraints. Existing pruning methods primarily focus on estimating the
importance of individual weights, which limits their ability to preserve
critical capabilities of the model. In this work, we propose a new perspective:
rather than merely selecting which weights to prune, we first redistribute
parameter importance to make the model inherently more amenable to pruning. By
minimizing the information entropy of normalized importance scores, our
approach concentrates importance onto a smaller subset of weights, thereby
enhancing pruning robustness. We instantiate this idea through DenoiseRotator,
which applies learnable orthogonal transformations to the model's weight
matrices. Our method is model-agnostic and can be seamlessly integrated with
existing pruning techniques such as Magnitude, SparseGPT, and Wanda. Evaluated
on LLaMA3, Qwen2.5, and Mistral models under 50% unstructured and 2:4
semi-structured sparsity, DenoiseRotator consistently improves perplexity and
zero-shot accuracy. For instance, on LLaMA3-70B pruned with SparseGPT at 2:4
semi-structured sparsity, DenoiseRotator reduces the perplexity gap to the
dense model by 58%, narrowing the degradation from 8.1 to 3.4 points. Codes are
available at https://github.com/Axel-gu/DenoiseRotator.

</details>


### [81] [Differential Information: An Information-Theoretic Perspective on Preference Optimization](https://arxiv.org/abs/2505.23761)
*Yunjae Won, Hyunji Lee, Hyeonbin Hwang, Minjoon Seo*

**主要类别:** cs.LG

**概要:** 直接偏好优化（DPO）是一种对齐语言模型与人类偏好的标准技术，尽管其经验上成功，但其背后的理论依据尚未完善。本文通过使用差分信息分布（DID），揭示了DPO中log-ratio奖励参数化的唯一最优形式，并解释了高熵和低熵差分信息对策略学习的不同影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管DPO在实践中表现良好，但其log-ratio奖励参数化的理论依据尚不完整，需要进一步研究以理解其机制。

**方法:** 利用差分信息分布（DID），证明当偏好标签编码了将参考策略转换为目标策略所需的差分信息时，DPO中的log-ratio奖励是学习目标策略的唯一最优形式。同时分析了偏好编码差分信息的条件与隐含假设，并通过研究DID的熵来描述不同熵值的差分信息对策略分布的影响。

**结果:** 理论结果表明，学习高熵差分信息对通用指令跟随至关重要，而学习低熵差分信息有助于知识密集型问题的回答。这些发现通过合成实验和真实世界数据集得到了验证。

**结论:** 本文通过差分信息的视角，统一了对DPO目标、偏好数据结构及策略行为的理解，为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Differential+Information%3A+An+Information-Theoretic+Perspective+on+Preference+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23761，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23761&send_immediately=true&force_search=false)

**原文摘要:** Direct Preference Optimization (DPO) has become a standard technique for
aligning language models with human preferences in a supervised manner. Despite
its empirical success, the theoretical justification behind its log-ratio
reward parameterization remains incomplete. In this work, we address this gap
by utilizing the Differential Information Distribution (DID): a distribution
over token sequences that captures the information gained during policy
updates. First, we show that when preference labels encode the differential
information required to transform a reference policy into a target policy, the
log-ratio reward in DPO emerges as the uniquely optimal form for learning the
target policy via preference optimization. This result naturally yields a
closed-form expression for the optimal sampling distribution over rejected
responses. Second, we find that the condition for preferences to encode
differential information is fundamentally linked to an implicit assumption
regarding log-margin ordered policies-an inductive bias widely used in
preference optimization yet previously unrecognized. Finally, by analyzing the
entropy of the DID, we characterize how learning low-entropy differential
information reinforces the policy distribution, while high-entropy differential
information induces a smoothing effect, which explains the log-likelihood
displacement phenomenon. We validate our theoretical findings in synthetic
experiments and extend them to real-world instruction-following datasets. Our
results suggest that learning high-entropy differential information is crucial
for general instruction-following, while learning low-entropy differential
information benefits knowledge-intensive question answering. Overall, our work
presents a unifying perspective on the DPO objective, the structure of
preference data, and resulting policy behaviors through the lens of
differential information.

</details>


### [82] [CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents](https://arxiv.org/abs/2505.23055)
*Zhen Xiang, Aliyah R. Hsu, Austin V. Zane, Aaron E. Kornblith, Margaret J. Lin-Martore, Jasmanpreet C. Kaur, Vasuda M. Dokiparthi, Bo Li, Bin Yu*

**主要类别:** cs.LG

**概要:** 临床决策规则（CDR）在急诊科（ED）中应用受限于医生的认知负担。本文提出了一种基于LLM的系统CDR-Agent，能够自动识别和应用适当的CDRs，从而提高ED决策效率和准确性。通过两个新数据集验证，CDR-Agent显著提高了CDR选择准确性和计算效率，同时减少了不必要的干预并成功识别大多数阳性诊断病例。


<details>
  <summary>更多</summary>
  
**动机:** 急诊科中的临床决策复杂且节奏快，而临床决策规则（CDR）虽然有助于标准化诊断，但其使用常因医生认知负担过重而受到限制。因此需要一种自动化工具来辅助医生快速、准确地应用CDRs。

**方法:** 开发了一个名为CDR-Agent的新型基于LLM的系统，该系统可以从非结构化的临床笔记中自动识别并应用最合适的CDRs。为验证该系统，作者构建了两个新数据集：synthetic和CDR-Bench，并与独立的LLM基线模型进行对比评估。

**结果:** 相较于独立的LLM基线模型，CDR-Agent在synthetic数据集上提升了56.3%的准确率，在CDR-Bench数据集上提升了8.7%的准确率。此外，它还显著降低了计算开销，并在减少不必要干预的同时成功识别大多数阳性诊断病例。

**结论:** CDR-Agent是一种有效的自动化工具，可以增强急诊科医生的决策能力，提升CDR选择的准确性和效率，同时优化影像学决策，减少不必要的干预。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CDR-Agent%3A+Intelligent+Selection+and+Execution+of+Clinical+Decision+Rules+Using+Large+Language+Model+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23055，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23055&send_immediately=true&force_search=false)

**原文摘要:** Clinical decision-making is inherently complex and fast-paced, particularly
in emergency departments (EDs) where critical, rapid and high-stakes decisions
are made. Clinical Decision Rules (CDRs) are standardized evidence-based tools
that combine signs, symptoms, and clinical variables into decision trees to
make consistent and accurate diagnoses. CDR usage is often hindered by the
clinician's cognitive load, limiting their ability to quickly recall and apply
the appropriate rules. We introduce CDR-Agent, a novel LLM-based system
designed to enhance ED decision-making by autonomously identifying and applying
the most appropriate CDRs based on unstructured clinical notes. To validate
CDR-Agent, we curated two novel ED datasets: synthetic and CDR-Bench, although
CDR-Agent is applicable to non ED clinics. CDR-Agent achieves a 56.3\%
(synthetic) and 8.7\% (CDR-Bench) accuracy gain relative to the standalone LLM
baseline in CDR selection. Moreover, CDR-Agent significantly reduces
computational overhead. Using these datasets, we demonstrated that CDR-Agent
not only selects relevant CDRs efficiently, but makes cautious yet effective
imaging decisions by minimizing unnecessary interventions while successfully
identifying most positively diagnosed cases, outperforming traditional LLM
prompting approaches. Code for our work can be found at:
https://github.com/zhenxianglance/medagent-cdr-agent

</details>


### [83] [DINGO: Constrained Inference for Diffusion LLMs](https://arxiv.org/abs/2505.23061)
*Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh*

**主要类别:** cs.LG

**概要:** 扩散型大语言模型（Diffusion LLMs）在运行时效率上具有显著潜力，但无法可靠地执行用户指定的正式约束。本文提出了一种名为DINGO的动态规划约束解码策略，解决了这一问题，并在标准符号数学和JSON生成基准测试中取得了显著改进。


<details>
  <summary>更多</summary>
  
**动机:** 现有的扩散模型无法可靠地执行用户指定的正式约束（如正则表达式），这使得它们在需要结构化输出的任务中表现不佳。

**方法:** 提出了DINGO，一种基于动态规划的约束解码策略，该策略能够高效且可证明地保持分布特性。它允许在严格满足任何用户指定的正则表达式的同时，根据模型预测的分布采样概率最高的输出字符串。

**结果:** 在标准符号数学和JSON生成基准测试中，DINGO相较于无约束推理实现了高达68个百分点的改进。

**结论:** DINGO是一种有效的解决方案，可以解决扩散LLMs在生成满足特定约束条件的输出时的局限性，显著提高了相关任务的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DINGO%3A+Constrained+Inference+for+Diffusion+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23061，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23061&send_immediately=true&force_search=false)

**原文摘要:** Diffusion LLMs have emerged as a promising alternative to conventional
autoregressive LLMs, offering significant potential for improved runtime
efficiency. However, existing diffusion models lack the ability to provably
enforce user-specified formal constraints, such as regular expressions, which
makes them unreliable for tasks that require structured outputs, such as
fixed-schema JSON generation. Unlike autoregressive models that generate tokens
sequentially, diffusion LLMs predict a block of tokens in parallel. This
parallelism makes traditional constrained decoding algorithms, which are
designed for sequential token prediction, ineffective at preserving the true
output distribution. To address this limitation, we propose DINGO, a dynamic
programming-based constrained decoding strategy that is both efficient and
provably distribution-preserving. DINGO enables sampling of output strings with
the highest probability under the model's predicted distribution, while
strictly satisfying any user-specified regular expression. On standard symbolic
math and JSON generation benchmarks, DINGO achieves up to a 68 percentage point
improvement over unconstrained inference

</details>


### [84] [Loss-Guided Model Sharing and Local Learning Correction in Decentralized Federated Learning for Crop Disease Classification](https://arxiv.org/abs/2505.23063)
*Denis Mamba Kabala, Adel Hafiane, Laurent Bobelin, Raphael Canals*

**主要类别:** cs.LG

**概要:** 本论文提出了一种新的去中心化联邦学习（DFL）框架，用于作物病害检测和分类。该方法通过验证损失指导模型共享并改进本地训练，实验结果表明其在提高准确性和收敛速度方面表现出色，同时确保了更好的泛化能力和鲁棒性，适合隐私保护的农业应用。


<details>
  <summary>更多</summary>
  
**动机:** 深度学习模型如CNN和ViT在从图像中分类植物疾病方面表现出色，但由于数据隐私问题，大规模部署受到限制。尽管联邦学习（FL）解决了这一问题，但集中式FL仍存在单点故障和可扩展性限制的问题。

**方法:** 本文引入了一种新颖的去中心化联邦学习（DFL）框架，利用验证损失（Loss_val）来引导同行之间的模型共享，并通过由加权参数控制的自适应损失函数修正本地训练。使用PlantVillage数据集和三种深度学习架构（ResNet50、VGG16和ViT_B16）进行了广泛实验，分析了加权参数、共享模型数量、客户端数量以及使用Loss_val与Loss_train的影响。

**结果:** 实验结果表明，DFL方法不仅提高了准确性和收敛速度，还确保了在异构数据环境中的更好泛化能力和鲁棒性。

**结论:** 提出的DFL框架在隐私保护的农业应用中表现良好，特别适合解决作物病害检测和分类问题，同时克服了传统联邦学习的局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Loss-Guided+Model+Sharing+and+Local+Learning+Correction+in+Decentralized+Federated+Learning+for+Crop+Disease+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23063，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23063&send_immediately=true&force_search=false)

**原文摘要:** Crop disease detection and classification is a critical challenge in
agriculture, with major implications for productivity, food security, and
environmental sustainability. While deep learning models such as CNN and ViT
have shown excellent performance in classifying plant diseases from images,
their large-scale deployment is often limited by data privacy concerns.
Federated Learning (FL) addresses this issue, but centralized FL remains
vulnerable to single-point failures and scalability limits. In this paper, we
introduce a novel Decentralized Federated Learning (DFL) framework that uses
validation loss (Loss_val) both to guide model sharing between peers and to
correct local training via an adaptive loss function controlled by weighting
parameter. We conduct extensive experiments using PlantVillage datasets with
three deep learning architectures (ResNet50, VGG16, and ViT_B16), analyzing the
impact of weighting parameter, the number of shared models, the number of
clients, and the use of Loss_val versus Loss_train of other clients. Results
demonstrate that our DFL approach not only improves accuracy and convergence
speed, but also ensures better generalization and robustness across
heterogeneous data environments making it particularly well-suited for
privacy-preserving agricultural applications.

</details>


### [85] [Multi-Modal Learning with Bayesian-Oriented Gradient Calibration](https://arxiv.org/abs/2505.23071)
*Peizheng Guo, Jingyao Wang, Huijie Guo, Jiangmeng Li, Chuxiong Sun, Changwen Zheng, Wenwen Qiang*

**主要类别:** cs.LG

**概要:** Multi-Modal Learning (MML) 通过整合不同模态的信息来提高预测准确性。然而，现有方法主要以固定权重聚合梯度并平等对待所有维度，忽略了每种模态的内在梯度不确定性。这可能导致敏感维度过度更新和非敏感维度更新不足的问题。为了解决这个问题，本文提出了BOGC-MML，一种贝叶斯导向的梯度校准方法，用于显式建模梯度不确定性并引导模型优化到最优方向。具体来说，首先将每个模态的梯度建模为随机变量，并推导其概率分布，捕捉梯度空间中的全部不确定性。然后提出了一种有效的方法，将每个梯度分布的精度（方差的倒数）转换为标量证据，该证据量化了每个模态在每个梯度维度上的置信度。使用这些证据，显式量化每个维度的不确定性，并通过简化的Dempster-Shafer规则进行融合。最终得到的不确定性加权聚合产生了一个经过校准的更新方向，在各个维度上平衡了敏感性和保守性。多个基准数据集上的广泛实验表明了所提方法的有效性和优势。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在多模态学习中以固定权重聚合梯度并平等对待所有维度，忽略了每种模态的内在梯度不确定性。这可能导致敏感维度过度更新和非敏感维度更新不足的问题，从而影响模型性能。

**方法:** 1. 将每个模态的梯度建模为随机变量并推导其概率分布，捕捉梯度空间中的全部不确定性。
2. 提出了一种有效的方法，将每个梯度分布的精度（方差的倒数）转换为标量证据，该证据量化了每个模态在每个梯度维度上的置信度。
3. 使用这些证据，显式量化每个维度的不确定性，并通过简化的Dempster-Shafer规则进行融合。
4. 最终得到的不确定性加权聚合产生了一个经过校准的更新方向，在各个维度上平衡了敏感性和保守性。

**结果:** 通过在多个基准数据集上的广泛实验，证明了所提方法的有效性和优势。BOGC-MML 方法能够更好地处理梯度不确定性，提高模型性能。

**结论:** BOGC-MML 是一种有效的贝叶斯导向的梯度校准方法，可以显式建模梯度不确定性并引导多模态学习模型优化到最优方向。它通过不确定性加权聚合平衡了梯度更新的敏感性和保守性，提高了多模态学习的预测准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Modal+Learning+with+Bayesian-Oriented+Gradient+Calibration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23071，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23071&send_immediately=true&force_search=false)

**原文摘要:** Multi-Modal Learning (MML) integrates information from diverse modalities to
improve predictive accuracy. However, existing methods mainly aggregate
gradients with fixed weights and treat all dimensions equally, overlooking the
intrinsic gradient uncertainty of each modality. This may lead to (i) excessive
updates in sensitive dimensions, degrading performance, and (ii) insufficient
updates in less sensitive dimensions, hindering learning. To address this
issue, we propose BOGC-MML, a Bayesian-Oriented Gradient Calibration method for
MML to explicitly model the gradient uncertainty and guide the model
optimization towards the optimal direction. Specifically, we first model each
modality's gradient as a random variable and derive its probability
distribution, capturing the full uncertainty in the gradient space. Then, we
propose an effective method that converts the precision (inverse variance) of
each gradient distribution into a scalar evidence. This evidence quantifies the
confidence of each modality in every gradient dimension. Using these evidences,
we explicitly quantify per-dimension uncertainties and fuse them via a reduced
Dempster-Shafer rule. The resulting uncertainty-weighted aggregation produces a
calibrated update direction that balances sensitivity and conservatism across
dimensions. Extensive experiments on multiple benchmark datasets demonstrate
the effectiveness and advantages of the proposed method.

</details>


### [86] [Gradient Boosting Decision Tree with LSTM for Investment Prediction](https://arxiv.org/abs/2505.23084)
*Chang Yu, Fang Liu, Jie Zhu, Shaobo Guo, Yifan Gao, Zhongheng Yang, Meiwei Liu, Qianwen Xing*

**主要类别:** cs.LG

**概要:** The paper proposes a hybrid framework combining LSTM with LightGBM and CatBoost for stock price prediction.


<details>
  <summary>更多</summary>
  
**动机:** To improve the accuracy of stock price prediction by leveraging the strengths of sequential models (LSTM) and tree-based models (LightGBM, CatBoost).

**方法:** A hybrid framework that processes time-series financial data using LSTM, LightGBM, and CatBoost. Performance is evaluated via seven models including ANNs, CNNs, BiLSTM, vanilla LSTM, XGBoost, LightGBM, and standard NNs. An ensemble model combining these methods is developed to further enhance performance.

**结果:** The proposed framework improves accuracy by 10-15% compared to individual models and reduces error during market changes.

**结论:** Ensemble methods show significant potential for financial forecasting, providing a flexible design for integrating new machine learning techniques.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gradient+Boosting+Decision+Tree+with+LSTM+for+Investment+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23084，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23084&send_immediately=true&force_search=false)

**原文摘要:** This paper proposes a hybrid framework combining LSTM (Long Short-Term
Memory) networks with LightGBM and CatBoost for stock price prediction. The
framework processes time-series financial data and evaluates performance using
seven models: Artificial Neural Networks (ANNs), Convolutional Neural Networks
(CNNs), Bidirectional LSTM (BiLSTM), vanilla LSTM, XGBoost, LightGBM, and
standard Neural Networks (NNs). Key metrics, including MAE, R-squared, MSE, and
RMSE, are used to establish benchmarks across different time scales.
  Building on these benchmarks, we develop an ensemble model that combines the
strengths of sequential and tree-based approaches. Experimental results show
that the proposed framework improves accuracy by 10 to 15 percent compared to
individual models and reduces error during market changes. This study
highlights the potential of ensemble methods for financial forecasting and
provides a flexible design for integrating new machine learning techniques.

</details>


### [87] [MAP: Revisiting Weight Decomposition for Low-Rank Adaptation](https://arxiv.org/abs/2505.23094)
*Chongjie Si, Zhiyi Shi, Yadao Wang, Xiaokang Yang, Susanto Rahardja, Wei Shen*

**主要类别:** cs.LG

**概要:** The paper introduces MAP, a novel framework that reformulates weight matrices as high-dimensional vectors and decouples their adaptation into direction and magnitude, improving performance when integrated with existing PEFT methods.


<details>
  <summary>更多</summary>
  
**动机:** Existing PEFT methods lack a principled geometric foundation for defining direction in weight adaptation.

**方法:** MAP normalizes pre-trained weights, learns a directional update, and introduces two scalar coefficients to independently scale the magnitude of the base and update vectors.

**结果:** Extensive experiments demonstrate that MAP significantly enhances the performance of existing PEFT methods.

**结论:** MAP is a simple yet powerful enhancement to PEFT methods and could serve as a default setting for designing future methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAP%3A+Revisiting+Weight+Decomposition+for+Low-Rank+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23094&send_immediately=true&force_search=false)

**原文摘要:** The rapid development of large language models has revolutionized natural
language processing, but their fine-tuning remains computationally expensive,
hindering broad deployment. Parameter-efficient fine-tuning (PEFT) methods,
such as LoRA, have emerged as solutions. Recent work like DoRA attempts to
further decompose weight adaptation into direction and magnitude components.
However, existing formulations often define direction heuristically at the
column level, lacking a principled geometric foundation. In this paper, we
propose MAP, a novel framework that reformulates weight matrices as
high-dimensional vectors and decouples their adaptation into direction and
magnitude in a rigorous manner. MAP normalizes the pre-trained weights, learns
a directional update, and introduces two scalar coefficients to independently
scale the magnitude of the base and update vectors. This design enables more
interpretable and flexible adaptation, and can be seamlessly integrated into
existing PEFT methods. Extensive experiments show that MAP significantly
improves performance when coupling with existing methods, offering a simple yet
powerful enhancement to existing PEFT methods. Given the universality and
simplicity of MAP, we hope it can serve as a default setting for designing
future PEFT methods.

</details>


### [88] [Learning to Search for Vehicle Routing with Multiple Time Windows](https://arxiv.org/abs/2505.23098)
*Kuan Xu, Zhiguang Cao, Chenlong Zheng, Linong Liu*

**主要类别:** cs.LG

**概要:** 提出了一种基于强化学习的自适应变领域搜索（RL-AVNS）方法，用于解决带多时间窗的车辆路径问题（VRPMTW）。该方法在不同规模实例和时间窗复杂度下显著优于传统方法，且具有良好的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 传统自适应方法仅依赖历史算子性能来解决问题，而本文旨在通过结合强化学习框架动态选择邻域算子，以提高求解带多时间窗的车辆路径问题的效果。

**方法:** 提出了RL-AVNS方法，引入了量化客户时间灵活性的适应度指标以改进震荡阶段，并使用基于Transformer的神经策略网络智能引导局部搜索中的算子选择。

**结果:** RL-AVNS在各种实例规模和时间窗复杂度下显著优于传统变领域搜索（VNS）、自适应VNS（AVNS）以及最先进的基于学习的启发式算法，同时展现了良好的泛化能力。

**结论:** RL-AVNS方法在求解VRPMTW问题上表现出色，不仅提高了解的质量和计算效率，还展示了对未见问题实例的有效泛化能力，具有实际应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Search+for+Vehicle+Routing+with+Multiple+Time+Windows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23098&send_immediately=true&force_search=false)

**原文摘要:** In this study, we propose a reinforcement learning-based adaptive variable
neighborhood search (RL-AVNS) method designed for effectively solving the
Vehicle Routing Problem with Multiple Time Windows (VRPMTW). Unlike traditional
adaptive approaches that rely solely on historical operator performance, our
method integrates a reinforcement learning framework to dynamically select
neighborhood operators based on real-time solution states and learned
experience. We introduce a fitness metric that quantifies customers' temporal
flexibility to improve the shaking phase, and employ a transformer-based neural
policy network to intelligently guide operator selection during the local
search. Extensive computational experiments are conducted on realistic
scenarios derived from the replenishment of unmanned vending machines,
characterized by multiple clustered replenishment windows. Results demonstrate
that RL-AVNS significantly outperforms traditional variable neighborhood search
(VNS), adaptive VNS (AVNS), and state-of-the-art learning-based heuristics,
achieving substantial improvements in solution quality and computational
efficiency across various instance scales and time window complexities.
Particularly notable is the algorithm's capability to generalize effectively to
problem instances not encountered during training, underscoring its practical
utility for complex logistics scenarios.

</details>


### [89] [Weight Spectra Induced Efficient Model Adaptation](https://arxiv.org/abs/2505.23099)
*Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen*

**主要类别:** cs.LG

**概要:** 大型基础模型在各种下游任务中表现出色，但完全微调这些模型计算成本高昂。因此，研究了参数高效微调（PEFT）方法如LoRA，并通过SVD分析揭示了微调主要放大了权重矩阵的顶级奇异值。基于此，提出了一种新的可学习重新缩放顶级奇异方向的方法，在多个任务上超越了强基线。


<details>
  <summary>更多</summary>
  
**动机:** 完全微调大规模基础模型的计算成本过高，因此需要探索更高效的参数微调方法并理解其修改模型参数的潜在机制。

**方法:** 通过对权重矩阵进行奇异值分解（SVD），研究结构变化，发现微调主要放大顶级奇异值，并使主导奇异向量重新定向到任务特定方向。基于此，提出了一种利用可学习重新缩放顶级奇异方向的新方法。

**结果:** 新方法能够在不破坏整体结构的情况下精确调整最具影响力的组件，在多个任务上对强大的基线模型实现了持续改进。

**结论:** 通过结构信息指导的微调方法是有效的，所提出的方法在多个任务上表现优异，为参数高效微调提供了新视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Weight+Spectra+Induced+Efficient+Model+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23099&send_immediately=true&force_search=false)

**原文摘要:** Large-scale foundation models have demonstrated remarkable versatility across
a wide range of downstream tasks. However, fully fine-tuning these models
incurs prohibitive computational costs, motivating the development of
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces
low-rank updates to pre-trained weights. Despite their empirical success, the
underlying mechanisms by which PEFT modifies model parameters remain
underexplored. In this work, we present a systematic investigation into the
structural changes of weight matrices during fully fine-tuning. Through
singular value decomposition (SVD), we reveal that fine-tuning predominantly
amplifies the top singular values while leaving the remainder largely intact,
suggesting that task-specific knowledge is injected into a low-dimensional
subspace. Furthermore, we find that the dominant singular vectors are
reoriented in task-specific directions, whereas the non-dominant subspace
remains stable. Building on these insights, we propose a novel method that
leverages learnable rescaling of top singular directions, enabling precise
modulation of the most influential components without disrupting the global
structure. Our approach achieves consistent improvements over strong baselines
across multiple tasks, highlighting the efficacy of structurally informed
fine-tuning.

</details>


### [90] [LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics](https://arxiv.org/abs/2505.23105)
*Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh*

**主要类别:** cs.LG

**概要:** 在现代ML数据中心，加速器故障时通常将受影响的训练或推理任务迁移到全新机架，虽然保证了网络性能但效率低下。本文提出LUMION，一种新型可重构光学结构，用于连接数据中心机架内的加速器。LUMION通过动态整合备用加速器到现有工作负载中，避免了昂贵的任务迁移，并保持性能一致性。实验表明，LUMION可在约1秒内替换故障GPU并重启任务，相比传统电学机架提升了近2倍的微调吞吐量。


<details>
  <summary>更多</summary>
  
**动机:** 当前数据中心在加速器故障时采用的任务迁移方法虽然能保证网络性能，但需要预留完整的空闲机架作为容错资源，导致资源利用效率低下。因此，需要一种更高效的解决方案来应对加速器故障问题。

**方法:** 引入LUMION，一种新型可重构光学结构，用于连接数据中心机架内的加速器。当加速器故障发生时，LUMION能够动态地将备用加速器整合到正在进行的工作负载中，而无需迁移整个任务。通过构建端到端硬件原型进行实验验证。

**结果:** 实验结果表明，LUMION可以在约1秒内完成故障GPU的替换并重启任务，同时与传统电学机架相比，在用备用加速器替换故障加速器后，LUMION实现了更高的GPU间带宽，使得微调吞吐量几乎提高了两倍。

**结论:** LUMION提供了一种高效、快速响应的机制，能够在加速器故障时维持任务性能，减少任务迁移成本，提高数据中心资源利用率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LUMION%3A+Fast+Fault+Recovery+for+ML+Jobs+Using+Programmable+Optical+Fabrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23105，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23105&send_immediately=true&force_search=false)

**原文摘要:** When accelerators fail in modern ML datacenters, operators migrate the
affected ML training or inference jobs to entirely new racks. This approach,
while preserving network performance, is highly inefficient, requiring
datacenters to reserve full racks of idle accelerators for fault tolerance. In
this paper, we address this resource inefficiency by introducing LUMION, a
novel reconfigurable optical fabric for connecting accelerators within a
datacenter rack. Instead of migrating entire ML jobs, LUMION dynamically
integrates spare accelerators into ongoing workloads as failures occur, thereby
maintaining consistent performance without costly migrations. We show the
benefits of LUMION by building an end-to-end hardware prototype. Our
experiments fine-tune Llama 3.2 and show that LUMION swaps a failed GPU with a
healthy one and restarts the ML job within ~ 1 second of the failure. LUMION
achieves higher inter-GPU bandwidth compared to traditional electrical racks
after replacing failed accelerators with spare ones, leading to nearly 2X
improvement in fine-tuning throughput.

</details>


### [91] [Neural Interpretable PDEs: Harmonizing Fourier Insights with Attention for Scalable and Interpretable Physics Discovery](https://arxiv.org/abs/2505.23106)
*Ning Liu, Yue Yu*

**主要类别:** cs.LG

**概要:** 提出了一种新的神经算子架构NIPS，通过线性注意力机制和可学习的核网络，在预测精度和计算效率上超越了NAO和其他基线模型，为物理系统学习提供了可扩展、可解释和高效的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 注意力机制在AI核心领域表现出色，但在建模复杂物理系统方面潜力尚未被充分挖掘，研究者希望找到一种能够高效且准确地映射功能空间的方法来解决逆PDE问题。

**方法:** 引入Neural Interpretable PDEs (NIPS)，它基于并增强了Nonlocal Attention Operators (NAO)，使用线性注意力机制实现可扩展学习，并结合一个可学习的核网络作为Fourier空间中的通道无关卷积。这种方法无需显式计算和存储大量的成对交互，将处理空间交互的成本分摊到Fourier变换中。

**结果:** 实证评估表明，NIPS在多个基准测试中始终优于NAO和其他基线模型。

**结论:** NIPS标志着在可扩展、可解释和高效的物理系统学习方面取得了重大进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+Interpretable+PDEs%3A+Harmonizing+Fourier+Insights+with+Attention+for+Scalable+and+Interpretable+Physics+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23106，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23106&send_immediately=true&force_search=false)

**原文摘要:** Attention mechanisms have emerged as transformative tools in core AI domains
such as natural language processing and computer vision. Yet, their largely
untapped potential for modeling intricate physical systems presents a
compelling frontier. Learning such systems often entails discovering operators
that map between functional spaces using limited instances of function pairs --
a task commonly framed as a severely ill-posed inverse PDE problem. In this
work, we introduce Neural Interpretable PDEs (NIPS), a novel neural operator
architecture that builds upon and enhances Nonlocal Attention Operators (NAO)
in both predictive accuracy and computational efficiency. NIPS employs a linear
attention mechanism to enable scalable learning and integrates a learnable
kernel network that acts as a channel-independent convolution in Fourier space.
As a consequence, NIPS eliminates the need to explicitly compute and store
large pairwise interactions, effectively amortizing the cost of handling
spatial interactions into the Fourier transform. Empirical evaluations
demonstrate that NIPS consistently surpasses NAO and other baselines across
diverse benchmarks, heralding a substantial leap in scalable, interpretable,
and efficient physics learning. Our code and data accompanying this paper are
available at https://github.com/fishmoon1234/Nonlocal-Attention-Operator.

</details>


### [92] [DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs](https://arxiv.org/abs/2505.23131)
*Xinyu Yao, Daniel Bourgeois, Abhinav Jain, Yuxin Tang, Jiawen Yao, Zhimin Ding, Arlei Silva, Chris Jermaine*

**主要类别:** cs.LG

**概要:** 本研究提出了一种名为Doppler的三阶段框架，用于训练双策略网络（包含选择操作的SEL策略和将选定操作放置在设备上的PLC策略），以优化数据流图中操作到设备的分配问题。通过减少系统执行时间和每集训练时间，Doppler在各种任务中优于所有基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于学习的方法存在三个关键限制：1) 依赖于TensorFlow等批量同步系统，导致设备利用率低；2) 设计基于学习的方法时未考虑底层系统的调度机制；3) 过度依赖强化学习，忽略了专家设计的有效启发式结构。为了解决这些问题，本文提出了新的框架。

**方法:** 提出名为Doppler的三阶段框架，用于训练双策略网络：1) SEL策略用于选择操作；2) PLC策略用于将选定的操作放置在设备上。该框架旨在解决复杂机器学习工作负载中的数据流图操作分配问题。

**结果:** 实验表明，Doppler在各种任务中优于所有基线方法，减少了系统执行时间，并展示了采样效率，即减少了每集训练时间。

**结论:** Doppler框架通过结合选择和放置策略，在优化数据流图操作分配方面表现出色，同时提高了训练效率。这为未来的工作提供了新的方向和思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DOPPLER%3A+Dual-Policy+Learning+for+Device+Assignment+in+Asynchronous+Dataflow+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23131，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23131&send_immediately=true&force_search=false)

**原文摘要:** We study the problem of assigning operations in a dataflow graph to devices
to minimize execution time in a work-conserving system, with emphasis on
complex machine learning workloads. Prior learning-based methods often struggle
due to three key limitations: (1) reliance on bulk-synchronous systems like
TensorFlow, which under-utilize devices due to barrier synchronization; (2)
lack of awareness of the scheduling mechanism of underlying systems when
designing learning-based methods; and (3) exclusive dependence on reinforcement
learning, ignoring the structure of effective heuristics designed by experts.
In this paper, we propose \textsc{Doppler}, a three-stage framework for
training dual-policy networks consisting of 1) a $\mathsf{SEL}$ policy for
selecting operations and 2) a $\mathsf{PLC}$ policy for placing chosen
operations on devices. Our experiments show that \textsc{Doppler} outperforms
all baseline methods across tasks by reducing system execution time and
additionally demonstrates sampling efficiency by reducing per-episode training
time.

</details>


### [93] [Bigger, Regularized, Categorical: High-Capacity Value Functions are Efficient Multi-Task Learners](https://arxiv.org/abs/2505.23150)
*Michal Nauman, Marek Cygan, Carmelo Sferrazza, Aviral Kumar, Pieter Abbeel*

**主要类别:** cs.LG

**概要:** 近期在语言建模和视觉方面的进展源于对多样化、多任务数据的大规模模型训练。然而，基于价值的强化学习（RL）中的这一范式影响有限，因为改进通常由单任务环境下训练的小型模型驱动。这是因为在多任务RL中，稀疏奖励和梯度冲突使得时间差分优化变得脆弱。因此，通用策略的实际工作流程避免了在线训练，而是克隆专家轨迹或将多个单任务策略蒸馏到一个代理中。在这项工作中，我们展示了使用通过交叉熵训练的高容量价值模型，并结合可学习的任务嵌入来解决在线RL中的任务干扰问题，从而实现强大且可扩展的多任务训练。我们在包含超过280个独特任务的7个多任务基准上测试了我们的方法，涵盖了高自由度的人形控制和离散视觉基础RL。我们发现，尽管方法简单，但所提出的方法在单任务和多任务性能以及样本高效的转移到新任务方面达到了最先进的水平。


<details>
  <summary>更多</summary>
  
**动机:** 基于价值的强化学习（RL）在多任务场景中面临稀疏奖励和梯度冲突的问题，导致时间差分优化变得脆弱。现有的通用策略工作流程通常避免在线训练，而是依赖于专家轨迹的克隆或单任务策略的蒸馏。这促使研究者探索一种能够有效解决任务干扰并支持在线多任务训练的方法。

**方法:** 研究者采用高容量的价值模型并通过交叉熵进行训练，同时结合可学习的任务嵌入来应对多任务RL中的任务干扰问题。这种方法允许模型在在线环境中进行稳健且可扩展的多任务训练。

**结果:** 该方法在7个多任务基准测试中表现出色，涵盖超过280个独特任务。它不仅在单任务和多任务性能上达到先进水平，而且在转移到新任务时也表现出样本高效的特性。

**结论:** 通过使用高容量价值模型和任务嵌入，可以有效解决多任务RL中的任务干扰问题，从而实现强大的在线多任务训练。此方法简单但效果显著，为未来多任务强化学习的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bigger%2C+Regularized%2C+Categorical%3A+High-Capacity+Value+Functions+are+Efficient+Multi-Task+Learners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23150，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23150&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in language modeling and vision stem from training large
models on diverse, multi-task data. This paradigm has had limited impact in
value-based reinforcement learning (RL), where improvements are often driven by
small models trained in a single-task context. This is because in multi-task RL
sparse rewards and gradient conflicts make optimization of temporal difference
brittle. Practical workflows for generalist policies therefore avoid online
training, instead cloning expert trajectories or distilling collections of
single-task policies into one agent. In this work, we show that the use of
high-capacity value models trained via cross-entropy and conditioned on
learnable task embeddings addresses the problem of task interference in online
RL, allowing for robust and scalable multi-task training. We test our approach
on 7 multi-task benchmarks with over 280 unique tasks, spanning high
degree-of-freedom humanoid control and discrete vision-based RL. We find that,
despite its simplicity, the proposed approach leads to state-of-the-art single
and multi-task performance, as well as sample-efficient transfer to new tasks.

</details>


### [94] [Pseudo Multi-Source Domain Generalization: Bridging the Gap Between Single and Multi-Source Domain Generalization](https://arxiv.org/abs/2505.23173)
*Shohei Enomoto*

**主要类别:** cs.LG

**概要:** Deep learning models face challenges when deployed on different data distributions. Multi-source Domain Generalization (MDG) addresses this by using multiple source domains during training, but is limited by the difficulty of creating multi-domain datasets. This paper proposes Pseudo Multi-source Domain Generalization (PMDG), which generates multiple pseudo-domains from a single source domain through style transfer and data augmentation techniques, thus enabling the use of MDG algorithms in Single-source Domain Generalization (SDG) settings.


<details>
  <summary>更多</summary>
  
**动机:** Deep learning models often perform poorly on data distributions different from their training data, especially in real-world applications where environmental conditions change frequently. Existing MDG methods require multi-domain datasets, which are difficult to create.

**方法:** The proposed PMDG framework generates multiple pseudo-domains from a single source domain using style transfer and data augmentation techniques. These synthetic domains can then be used with existing MDG algorithms, effectively applying them in SDG settings.

**结果:** Experiments using the modified benchmark PseudoDomainBed show that PMDG has a positive correlation with MDG performance. With sufficient data, pseudo-domains can match or exceed the performance of actual multi-domain datasets.

**结论:** PMDG provides a practical solution for applying MDG algorithms in SDG scenarios, overcoming the limitations of creating multi-domain datasets. The findings offer valuable insights for future research in domain generalization.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pseudo+Multi-Source+Domain+Generalization%3A+Bridging+the+Gap+Between+Single+and+Multi-Source+Domain+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23173，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23173&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models often struggle to maintain performance when deployed on
data distributions different from their training data, particularly in
real-world applications where environmental conditions frequently change. While
Multi-source Domain Generalization (MDG) has shown promise in addressing this
challenge by leveraging multiple source domains during training, its practical
application is limited by the significant costs and difficulties associated
with creating multi-domain datasets. To address this limitation, we propose
Pseudo Multi-source Domain Generalization (PMDG), a novel framework that
enables the application of sophisticated MDG algorithms in more practical
Single-source Domain Generalization (SDG) settings. PMDG generates multiple
pseudo-domains from a single source domain through style transfer and data
augmentation techniques, creating a synthetic multi-domain dataset that can be
used with existing MDG algorithms. Through extensive experiments with
PseudoDomainBed, our modified version of the DomainBed benchmark, we analyze
the effectiveness of PMDG across multiple datasets and architectures. Our
analysis reveals several key findings, including a positive correlation between
MDG and PMDG performance and the potential of pseudo-domains to match or exceed
actual multi-domain performance with sufficient data. These comprehensive
empirical results provide valuable insights for future research in domain
generalization. Our code is available at
https://github.com/s-enmt/PseudoDomainBed.

</details>


### [95] [The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning](https://arxiv.org/abs/2505.23176)
*Shiwei Li, Xiandi Luo, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li*

**主要类别:** cs.LG

**概要:** 为了提高联邦学习（FL）的训练效率，以往研究采用低秩分解技术减少通信开销。本文针对分解中的三个关键问题（分解什么、如何分解和如何聚合），提出了三种新技术：模型更新分解（MUD）、块状Kronecker分解（BKD）和聚合感知分解（AAD）。这些技术互补且可同时应用，并通过理论分析确保了MUD的收敛性。实验表明，该方法比基线方法具有更快的收敛速度和更高的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中低秩分解技术虽能减少通信开销，但其性能仍有提升空间，因此需要改进现有的分解方法以优化联邦学习的效率和效果。

**方法:** 本文提出三种技术：1) Model Update Decomposition (MUD)，解决“分解什么”的问题；2) Block-wise Kronecker Decomposition (BKD)，解决“如何分解”的问题；3) Aggregation-Aware Decomposition (AAD)，解决“如何聚合”的问题。这些技术可以协同工作以达到最佳性能。此外，还提供了MUD的理论收敛性分析。

**结果:** 理论分析证明了MUD的收敛性。实验结果表明，所提出的方法相比相关基线方法实现了更快的收敛速度和更高的准确率。

**结论:** 本文提出的MUD、BKD和AAD三种技术有效提升了联邦学习中低秩分解方法的性能，在减少通信开销的同时提高了模型的收敛速度和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Panaceas+for+Improving+Low-Rank+Decomposition+in+Communication-Efficient+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23176&send_immediately=true&force_search=false)

**原文摘要:** To improve the training efficiency of federated learning (FL), previous
research has employed low-rank decomposition techniques to reduce communication
overhead. In this paper, we seek to enhance the performance of these low-rank
decomposition methods. Specifically, we focus on three key issues related to
decomposition in FL: what to decompose, how to decompose, and how to aggregate.
Subsequently, we introduce three novel techniques: Model Update Decomposition
(MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware
Decomposition (AAD), each targeting a specific issue. These techniques are
complementary and can be applied simultaneously to achieve optimal performance.
Additionally, we provide a rigorous theoretical analysis to ensure the
convergence of the proposed MUD. Extensive experimental results show that our
approach achieves faster convergence and superior accuracy compared to relevant
baseline methods. The code is available at
https://github.com/Leopold1423/fedmud-icml25.

</details>


### [96] [FSL-SAGE: Accelerating Federated Split Learning via Smashed Activation Gradient Estimation](https://arxiv.org/abs/2505.23182)
*Srijith Nair, Michael Lin, Amirreza Talebi, Peizhong Ju, Elizabeth Bentley, Jia Liu*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FSL-SAGE%3A+Accelerating+Federated+Split+Learning+via+Smashed+Activation+Gradient+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23182&send_immediately=true&force_search=false)

**原文摘要:** Collaborative training methods like Federated Learning (FL) and Split
Learning (SL) enable distributed machine learning without sharing raw data.
However, FL assumes clients can train entire models, which is infeasible for
large-scale models. In contrast, while SL alleviates the client memory
constraint in FL by offloading most training to the server, it increases
network latency due to its sequential nature. Other methods address the
conundrum by using local loss functions for parallel client-side training to
improve efficiency, but they lack server feedback and potentially suffer poor
accuracy. We propose FSL-SAGE (Federated Split Learning via Smashed Activation
Gradient Estimation), a new federated split learning algorithm that estimates
server-side gradient feedback via auxiliary models. These auxiliary models
periodically adapt to emulate server behavior on local datasets. We show that
FSL-SAGE achieves a convergence rate of $\mathcal{O}(1/\sqrt{T})$, where $T$ is
the number of communication rounds. This result matches FedAvg, while
significantly reducing communication costs and client memory requirements. Our
empirical results also verify that it outperforms existing state-of-the-art FSL
methods, offering both communication efficiency and accuracy.

</details>


### [97] [Two Is Better Than One: Rotations Scale LoRAs](https://arxiv.org/abs/2505.23184)
*Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang*

**主要类别:** cs.LG

**概要:** 提出了一种名为RadarGate的新方法，通过引入LoRA表示的旋转操作来增强表达能力，解决大规模语言模型中的泛化差和拟合不足问题。实验表明该方法在6个公共基准数据集上的21项任务中有效。


<details>
  <summary>更多</summary>
  
**动机:** 传统的门控机制可能根本性地阻碍了大规模语言模型的可扩展性，导致泛化能力差和拟合不足的问题。其根源在于现有加权求和机制的表达能力受限。

**方法:** RadarGate是一种受几何启发的门控方法，通过引入LoRA表示的旋转操作来增强表达能力。具体来说，首先使用可学习组件将每个LoRA表示与其他LoRA融合，然后输入到一个旋转矩阵中，该矩阵包含定义LoRA表示之间相对角度关系的可学习参数。

**结果:** 广泛的实验表明，RadarGate在6个公共基准数据集上的21项任务中有效地扩展了LoRA。此外，研究还揭示了几何变换过程中语义相似表示的对比对齐现象。

**结论:** RadarGate提供了一个额外的自由度，促进了跨LoRA协同作用的学习，并解决了随着LoRA数量增加而出现的泛化和拟合问题。代码将向社区开放。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Two+Is+Better+Than+One%3A+Rotations+Scale+LoRAs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23184&send_immediately=true&force_search=false)

**原文摘要:** Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates
large language models (LLMs) to efficiently adapt to diverse tasks. However,
traditional gating mechanisms that route inputs to the best experts may
fundamentally hinder LLMs' scalability, leading to poor generalization and
underfitting issues. We identify that the root cause lies in the restricted
expressiveness of existing weighted-sum mechanisms, both within and outside the
convex cone of LoRA representations. This motivates us to propose RadarGate, a
novel geometrically inspired gating method that introduces rotational
operations of LoRAs representations to boost the expressiveness and facilitate
richer feature interactions among multiple LoRAs for scalable LLMs.
Specifically, we first fuse each LoRA representation to other LoRAs using a
learnable component and then feed the output to a rotation matrix. This matrix
involves learnable parameters that define the relative angular relationship
between LoRA representations. Such a simple yet effective mechanism provides an
extra degree of freedom, facilitating the learning of cross-LoRA synergies and
properly tracking the challenging poor generalization and underfitting issues
as the number of LoRA grows. Extensive experiments on 6 public benchmarks
across 21 tasks show the effectiveness of our RadarGate for scaling LoRAs. We
also provide valuable insights, revealing that the rotations to each pair of
representations are contrastive, encouraging closer alignment of semantically
similar representations during geometrical transformation while pushing
distance ones further apart. We will release our code to the community.

</details>


### [98] [Improving the Effective Receptive Field of Message-Passing Neural Networks](https://arxiv.org/abs/2505.23185)
*Shahaf E. Finder, Ron Shapira Weber, Moshe Eliasof, Oren Freifeld, Eran Treister*

**主要类别:** cs.LG

**概要:** 本研究受CNN中ERF增强进展的启发，提出了IM-MPNN架构来解决MPNN中的有限ERF问题，通过图的分层粗化促进长程交互，在LRGB等基准上取得了显著改进。


<details>
  <summary>更多</summary>
  
**动机:** MPNNs在处理图结构数据时面临过压缩问题，类似于CNN中的有效感受野(ERF)问题，即理论上的感受野在实际中未能被充分利用。这阻碍了其捕捉和表达长程依赖关系的能力。

**方法:** 提出了一种交错多尺度消息传递神经网络（IM-MPNN）架构。该方法通过图的分层粗化，允许在多尺度表示之间进行消息传递，从而实现长程交互，而无需过多的深度或参数化。

**结果:** 通过在Long-Range Graph Benchmark (LRGB)等基准上的广泛评估，表明IM-MPNN在保持计算效率的同时显著提高了捕捉长程依赖关系的能力。

**结论:** IM-MPNN解决了MPNN中的有限ERF问题，并为图结构数据的长程依赖建模提供了一个高效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+the+Effective+Receptive+Field+of+Message-Passing+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23185，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23185&send_immediately=true&force_search=false)

**原文摘要:** Message-Passing Neural Networks (MPNNs) have become a cornerstone for
processing and analyzing graph-structured data. However, their effectiveness is
often hindered by phenomena such as over-squashing, where long-range
dependencies or interactions are inadequately captured and expressed in the
MPNN output. This limitation mirrors the challenges of the Effective Receptive
Field (ERF) in Convolutional Neural Networks (CNNs), where the theoretical
receptive field is underutilized in practice. In this work, we show and
theoretically explain the limited ERF problem in MPNNs. Furthermore, inspired
by recent advances in ERF augmentation for CNNs, we propose an Interleaved
Multiscale Message-Passing Neural Networks (IM-MPNN) architecture to address
these problems in MPNNs. Our method incorporates a hierarchical coarsening of
the graph, enabling message-passing across multiscale representations and
facilitating long-range interactions without excessive depth or
parameterization. Through extensive evaluations on benchmarks such as the
Long-Range Graph Benchmark (LRGB), we demonstrate substantial improvements over
baseline MPNNs in capturing long-range dependencies while maintaining
computational efficiency.

</details>


### [99] [DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer](https://arxiv.org/abs/2505.23190)
*Yekun Zhu, Min Tang, Zheng Ma*

**主要类别:** cs.LG

**概要:** 本研究提出了一种名为DeepRTE的新神经网络方法，用于解决辐射传递方程（RTE），并利用预训练的基于注意力的神经网络实现了高精度和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决稳态辐射传递方程（RTE），其在多个领域有广泛应用，但传统解法可能面临精度或效率问题。

**方法:** 提出了DeepRTE框架，该框架使用预训练的基于注意力机制的神经网络来求解RTE。

**结果:** 通过全面的数值实验验证了所提方法的有效性。

**结论:** DeepRTE能够以高精度和计算效率解决RTE问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeepRTE%3A+Pre-trained+Attention-based+Neural+Network+for+Radiative+Tranfer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23190，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23190&send_immediately=true&force_search=false)

**原文摘要:** In this study, we propose a novel neural network approach, termed DeepRTE, to
address the steady-state Radiative Transfer Equation (RTE). The RTE is a
differential-integral equation that governs the propagation of radiation
through a participating medium, with applications spanning diverse domains such
as neutron transport, atmospheric radiative transfer, heat transfer, and
optical imaging. Our proposed DeepRTE framework leverages pre-trained
attention-based neural networks to solve the RTE with high accuracy and
computational efficiency. The efficacy of the proposed approach is
substantiated through comprehensive numerical experiments.

</details>


### [100] [Beyond Zero Initialization: Investigating the Impact of Non-Zero Initialization on LoRA Fine-Tuning Dynamics](https://arxiv.org/abs/2505.23194)
*Shiwei Li, Xiandi Luo, Xing Tang, Haozhao Wang, Hao Chen, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li*

**主要类别:** cs.LG

**概要:** Low-rank adaptation (LoRA)通常用零初始化矩阵A或B以确保从预训练模型开始微调，但此方法缺乏理论支持。本文研究了从无限宽度视角出发，非零初始化对LoRA微调动力学的影响。研究表明，同时将A和B初始化为非零值可提高LoRA对次优学习率（特别是较小学习率）的鲁棒性，并且尽管非零初始化会向预训练权重引入随机噪声，但通常不会影响微调性能。这些发现通过各种模型和数据集的广泛实验得到了验证。


<details>
  <summary>更多</summary>
  
**动机:** 当前LoRA方法中，通常将矩阵A或B初始化为零以保证微调从预训练模型开始，然而这种做法缺乏理论依据。因此，有必要研究非零初始化对LoRA微调过程的影响。

**方法:** 从无限宽度视角分析非零初始化对LoRA微调动力学的影响，比较零初始化与同时初始化A和B为非零值的情况，评估其在不同学习率下的表现，并分析非零初始化引入的随机噪声对微调性能的影响。

**结果:** 非零初始化提高了LoRA对次优学习率（特别是较小学习率）的鲁棒性，并且引入的随机噪声通常不会影响微调性能。这意味着微调不一定需要严格从预训练模型开始。

**结论:** 非零初始化可以作为一种有效的替代方案来改进LoRA方法，尤其在使用较小学习率时表现出更好的鲁棒性，同时不会损害微调性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Zero+Initialization%3A+Investigating+the+Impact+of+Non-Zero+Initialization+on+LoRA+Fine-Tuning+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23194，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23194&send_immediately=true&force_search=false)

**原文摘要:** Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning
method. In standard LoRA layers, one of the matrices, $A$ or $B$, is
initialized to zero, ensuring that fine-tuning starts from the pretrained
model. However, there is no theoretical support for this practice. In this
paper, we investigate the impact of non-zero initialization on LoRA's
fine-tuning dynamics from an infinite-width perspective. Our analysis reveals
that, compared to zero initialization, simultaneously initializing $A$ and $B$
to non-zero values improves LoRA's robustness to suboptimal learning rates,
particularly smaller ones. Further analysis indicates that although the
non-zero initialization of $AB$ introduces random noise into the pretrained
weight, it generally does not affect fine-tuning performance. In other words,
fine-tuning does not need to strictly start from the pretrained model. The
validity of our findings is confirmed through extensive experiments across
various models and datasets. The code is available at
https://github.com/Leopold1423/non_zero_lora-icml25.

</details>


### [101] [Daunce: Data Attribution through Uncertainty Estimation](https://arxiv.org/abs/2505.23223)
*Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为Daunce的新方法，通过不确定性估计实现数据归属，并在大型语言模型上展现出更高的归属准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于梯度的训练数据归属（TDA）方法在大规模应用中受限于计算复杂度，而随机投影方法虽然提升了可扩展性，但归属精度有所下降。因此，需要一种既可扩展又保持高归属精度的新方法。

**方法:** Daunce方法通过对扰动模型进行微调，并计算这些模型中每个样本损失的协方差作为归属得分，从而实现数据归属。该方法利用不确定性与影响函数之间的联系，适用于大型语言模型（LLMs）。

**结果:** 实验验证了Daunce在从视觉任务到大型语言模型微调的各种任务上的有效性，展示了其与黑盒模型访问的兼容性。此外，Daunce首次成功应用于OpenAI的GPT等专有大型语言模型的数据归属。

**结论:** Daunce是一种简单有效的数据归属方法，具有良好的可扩展性和高归属精度，适用于大型语言模型和黑盒模型场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Daunce%3A+Data+Attribution+through+Uncertainty+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23223&send_immediately=true&force_search=false)

**原文摘要:** Training data attribution (TDA) methods aim to identify which training
examples influence a model's predictions on specific test data most. By
quantifying these influences, TDA supports critical applications such as data
debugging, curation, and valuation. Gradient-based TDA methods rely on
gradients and second-order information, limiting their applicability at scale.
While recent random projection-based methods improve scalability, they often
suffer from degraded attribution accuracy. Motivated by connections between
uncertainty and influence functions, we introduce Daunce - a simple yet
effective data attribution approach through uncertainty estimation. Our method
operates by fine-tuning a collection of perturbed models and computing the
covariance of per-example losses across these models as the attribution score.
Daunce is scalable to large language models (LLMs) and achieves more accurate
attribution compared to existing TDA methods. We validate Daunce on tasks
ranging from vision tasks to LLM fine-tuning, and further demonstrate its
compatibility with black-box model access. Applied to OpenAI's GPT models, our
method achieves, to our knowledge, the first instance of data attribution on
proprietary LLMs.

</details>


### [102] [Generalizability vs. Counterfactual Explainability Trade-Off](https://arxiv.org/abs/2505.23225)
*Fabiano Veglianti, Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei*

**主要类别:** cs.LG

**概要:** 本文研究了监督学习中模型泛化与反事实可解释性之间的关系，提出了ε-有效反事实概率(ε-VCP)的概念，并通过理论和实证分析揭示了泛化能力差与反事实生成容易之间的内在权衡。


<details>
  <summary>更多</summary>
  
**动机:** 在监督学习中，理解模型的泛化能力和其可解释性之间的关系是一个重要问题。

**方法:** 作者引入了ε-有效反事实概率(ε-VCP)这一概念，即在一个数据点的ε邻域内找到导致标签变化的扰动的概率。通过分析模型决策边界的几何特性，研究ε-VCP与模型过拟合的关系。

**结果:** 理论分析表明，ε-VCP随着模型过拟合而增加；实证结果验证了这一理论，表明ε-VCP可以作为量化过拟合的实用指标。

**结论:** 本研究建立了模型泛化能力差与反事实生成容易之间的严格联系，揭示了泛化与反事实可解释性之间的内在权衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalizability+vs.+Counterfactual+Explainability+Trade-Off，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23225&send_immediately=true&force_search=false)

**原文摘要:** In this work, we investigate the relationship between model generalization
and counterfactual explainability in supervised learning. We introduce the
notion of $\varepsilon$-valid counterfactual probability ($\varepsilon$-VCP) --
the probability of finding perturbations of a data point within its
$\varepsilon$-neighborhood that result in a label change. We provide a
theoretical analysis of $\varepsilon$-VCP in relation to the geometry of the
model's decision boundary, showing that $\varepsilon$-VCP tends to increase
with model overfitting. Our findings establish a rigorous connection between
poor generalization and the ease of counterfactual generation, revealing an
inherent trade-off between generalization and counterfactual explainability.
Empirical results validate our theory, suggesting $\varepsilon$-VCP as a
practical proxy for quantitatively characterizing overfitting.

</details>


### [103] [Graph Random Walk with Feature-Label Space Alignment: A Multi-Label Feature Selection Method](https://arxiv.org/abs/2505.23228)
*Wanfu Gao, Jun Gao, Qingqi Han, Hanlin Pan, Kunpeng Liu*

**主要类别:** cs.LG

**概要:** 为应对多标签数据集中特征与标签之间复杂关系的挑战，本文提出了一种结合随机游走图和低秩分解的方法，以捕捉非线性和隐式关联，并通过低维表示系数对齐变量空间，同时保留原始高维数据的流形结构。实验表明该方法优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 特征维度快速增长导致多标签数据集中特征与标签之间的关系变得更加复杂，而现有方法采用的低维线性分解难以捕捉这些复杂的非线性关联，可能导致特征空间与标签空间之间的错位。

**方法:** 1. 构建随机游走图，整合特征-特征、标签-标签以及特征-标签关系，准确捕捉非线性和隐式间接关联；2. 在低秩分解后优化特征与标签之间关联的潜在表示；3. 利用低维表示系数对齐变量空间，同时保留原始高维多标签数据的流形结构。

**结果:** 在七个基准数据集和三个代表性数据集上进行的广泛实验和消融研究证明了所提方法在多种评估指标下的优越性。

**结论:** 所提出的结合随机游走图和低秩分解的方法能够有效捕捉多标签数据中复杂的非线性关联，并通过对齐变量空间和保留流形结构提高了模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Random+Walk+with+Feature-Label+Space+Alignment%3A+A+Multi-Label+Feature+Selection+Method，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23228，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23228&send_immediately=true&force_search=false)

**原文摘要:** The rapid growth in feature dimension may introduce implicit associations
between features and labels in multi-label datasets, making the relationships
between features and labels increasingly complex. Moreover, existing methods
often adopt low-dimensional linear decomposition to explore the associations
between features and labels. However, linear decomposition struggles to capture
complex nonlinear associations and may lead to misalignment between the feature
space and the label space. To address these two critical challenges, we propose
innovative solutions. First, we design a random walk graph that integrates
feature-feature, label-label, and feature-label relationships to accurately
capture nonlinear and implicit indirect associations, while optimizing the
latent representations of associations between features and labels after
low-rank decomposition. Second, we align the variable spaces by leveraging
low-dimensional representation coefficients, while preserving the manifold
structure between the original high-dimensional multi-label data and the
low-dimensional representation space. Extensive experiments and ablation
studies conducted on seven benchmark datasets and three representative datasets
using various evaluation metrics demonstrate the superiority of the proposed
method\footnote{Code: https://github.com/Heilong623/-GRW-}.

</details>


### [104] [Equivalence of stochastic and deterministic policy gradients](https://arxiv.org/abs/2505.23244)
*Emo Todorov*

**主要类别:** cs.LG

**概要:** 在特定MDP条件下，确定性和随机策略梯度、自然梯度和状态值函数相同，而状态-控制值函数不同。提出了一种将随机策略MDP转化为等效确定性策略MDP的方法，表明可以通过近似状态值函数来统一策略梯度方法。


<details>
  <summary>更多</summary>
  
**动机:** 研究连续控制中随机策略和确定性策略梯度之间的关系，特别是在涉及高斯控制噪声和二次控制成本的广泛使用的MDP家族中。

**方法:** 1. 在特定MDP条件下比较随机和确定性策略梯度、自然梯度和值函数。
2. 提出一种构造与给定随机策略MDP等效的确定性策略MDP的一般程序。
3. 新MDP的控制是原MDP中随机策略的充分统计量。

**结果:** 发现随机和确定性策略梯度、自然梯度和状态值函数在特定条件下相同，但状态-控制值函数不同。成功构建了等效的确定性策略MDP。

**结论:** 策略梯度方法可以通过近似状态值函数而非状态-控制值函数来实现统一。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivalence+of+stochastic+and+deterministic+policy+gradients，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23244&send_immediately=true&force_search=false)

**原文摘要:** Policy gradients in continuous control have been derived for both stochastic
and deterministic policies. Here we study the relationship between the two. In
a widely-used family of MDPs involving Gaussian control noise and quadratic
control costs, we show that the stochastic and deterministic policy gradients,
natural gradients, and state value functions are identical; while the
state-control value functions are different. We then develop a general
procedure for constructing an MDP with deterministic policy that is equivalent
to a given MDP with stochastic policy. The controls of this new MDP are the
sufficient statistics of the stochastic policy in the original MDP. Our results
suggest that policy gradient methods can be unified by approximating state
value functions rather than state-control value functions.

</details>


### [105] [Measuring Participant Contributions in Decentralized Federated Learning](https://arxiv.org/abs/2505.23246)
*Honoka Anada, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki*

**主要类别:** cs.LG

**概要:** 本研究提出了一种适用于去中心化联邦学习（DFL）的参与者贡献度量方法，包括理想的DFL-Shapley和可计算近似值DFL-MR。实验验证了这两种方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的贡献度量方法仅适用于集中式联邦学习（CFL），而在去中心化联邦学习（DFL）中，由于没有中央服务器且存在多个全局模型，应用这些方法具有挑战性。因此需要开发专门针对DFL的贡献度量方法。

**方法:** 1. 提出了DFL-Shapley：将Shapley值扩展到DFL场景。
2. 提出了DFL-MR：一种可计算的近似方法，通过累积每轮的Shapley值来估计总体贡献。
3. 在各种FL场景下评估DFL-Shapley和DFL-MR，并与现有的CFL度量进行比较。

**结果:** 实验结果表明：
1. DFL-Shapley是一个有效的基准真实度量。
2. DFL-MR在不同设置下接近DFL-Shapley，证明其作为DFL贡献度量的有效性。

**结论:** 本研究提出的DFL-Shapley和DFL-MR为DFL提供了一种有效的方法来衡量参与者的贡献，有助于激励参与者并确保透明度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+Participant+Contributions+in+Decentralized+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23246，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23246&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) enables multiple clients to collaboratively train
models without sharing their data. Measuring participant contributions in FL is
crucial for incentivizing clients and ensuring transparency. While various
methods have been proposed for contribution measurement, they are designed
exclusively for centralized federated learning (CFL), where a central server
collects and aggregates client models, along with evaluating their
contributions. Meanwhile, decentralized federated learning (DFL), in which
clients exchange models directly without a central server, has gained
significant attention for mitigating communication bottlenecks and eliminating
a single point of failure. However, applying existing contribution measurement
methods to DFL is challenging due to the presence of multiple global models and
the absence of a central server. In this study, we present novel methodologies
for measuring participant contributions in DFL. We first propose DFL-Shapley,
an extension of the Shapley value tailored for DFL, adapting this widely used
CFL metric to decentralized settings. Given the impracticality of computing the
ideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable
approximation that estimates overall contributions by accumulating round-wise
Shapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios
and compare them with existing CFL metrics. The experimental results confirm
DFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity
to DFL-Shapley across various settings, highlighting their effectiveness as
contribution metrics in DFL.

</details>


### [106] [Efficiently Access Diffusion Fisher: Within the Outer Product Span Space](https://arxiv.org/abs/2505.23264)
*Fangyikang Wang, Hubery Yin, Shaobin Zhuang, Huminhao Zhu, Yinan Li, Lei Qian, Chao Zhang, Hanbin Zhao, Hui Qian, Chen Li*

**主要类别:** cs.LG

**概要:** 近期的扩散模型研究探索了将二阶扩散Fisher信息纳入下游任务和理论分析中。当前方法通过自动微分近似扩散Fisher，但缺乏精度保证且耗时。本文提出基于score和初始数据外积结构的两种高效近似算法，避免了自动微分操作，并建立了误差界限。实验表明新算法在精度和计算成本上具有优势，同时设计了验证一般PF-ODE推导映射最优传输特性的数值实验。


<details>
  <summary>更多</summary>
  
**动机:** 将扩散Fisher信息纳入各种下游任务和理论分析中，但目前的近似方法缺乏精度保证且效率低下。

**方法:** 发现扩散Fisher信息位于由score和初始数据外积张成的空间内，基于此开发了两种高效近似算法以分别计算DF的迹和矩阵-向量乘法，并建立了误差界限。

**结果:** 实验显示所提算法在似然估计和伴随优化中具有更高的精度和更低的计算成本，并成功设计了验证最优传输特性的数值实验。

**结论:** 提出的基于外积结构的近似算法提高了计算扩散Fisher信息的效率和精度，并为验证最优传输特性提供了新的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficiently+Access+Diffusion+Fisher%3A+Within+the+Outer+Product+Span+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23264，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23264&send_immediately=true&force_search=false)

**原文摘要:** Recent Diffusion models (DMs) advancements have explored incorporating the
second-order diffusion Fisher information (DF), defined as the negative Hessian
of log density, into various downstream tasks and theoretical analysis.
However, current practices typically approximate the diffusion Fisher by
applying auto-differentiation to the learned score network. This black-box
method, though straightforward, lacks any accuracy guarantee and is
time-consuming. In this paper, we show that the diffusion Fisher actually
resides within a space spanned by the outer products of score and initial data.
Based on the outer-product structure, we develop two efficient approximation
algorithms to access the trace and matrix-vector multiplication of DF,
respectively. These algorithms bypass the auto-differentiation operations with
time-efficient vector-product calculations. Furthermore, we establish the
approximation error bounds for the proposed algorithms. Experiments in
likelihood evaluation and adjoint optimization demonstrate the superior
accuracy and reduced computational cost of our proposed algorithms.
Additionally, based on the novel outer-product formulation of DF, we design the
first numerical verification experiment for the optimal transport property of
the general PF-ODE deduced map.

</details>


### [107] [Comparative Analysis of the Land Use and Land Cover Changes in Different Governorates of Oman using Spatiotemporal Multi-spectral Satellite Data](https://arxiv.org/abs/2505.23285)
*Muhammad Shafi, Syed Mohsin Bokhari*

**主要类别:** cs.LG

**概要:** 本文使用Sentinel-2卫星数据和监督机器学习算法，分析了2016年至2021年阿曼苏丹国各省份的土地覆盖和土地利用变化。


<details>
  <summary>更多</summary>
  
**动机:** 土地覆盖和土地利用（LULC）变化在资源管理、城市化、土壤和环境保护以及促进可持续发展中扮演着重要角色。因此，监测这些变化对于相关领域具有重要意义。

**方法:** 研究采用了来自开放源Sentinel-2卫星数据集的多光谱时空数据，并利用监督机器学习算法对不同类型的地表覆盖进行训练和分类，如水体、作物、城市区域等。

**结果:** 构建的模型成功应用于研究区域，实现了对2016年至2021年间土地覆盖和土地利用变化的有效比较评估。

**结论:** 监督机器学习算法与多光谱时空卫星数据结合的方法可以有效地监测和预测土地覆盖和土地利用的变化，为相关政策制定提供支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+Analysis+of+the+Land+Use+and+Land+Cover+Changes+in+Different+Governorates+of+Oman+using+Spatiotemporal+Multi-spectral+Satellite+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23285，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23285&send_immediately=true&force_search=false)

**原文摘要:** Land cover and land use (LULC) changes are key applications of satellite
imagery, and they have critical roles in resource management, urbanization,
protection of soils and the environment, and enhancing sustainable development.
The literature has heavily utilized multispectral spatiotemporal satellite data
alongside advanced machine learning algorithms to monitor and predict LULC
changes. This study analyzes and compares LULC changes across various
governorates (provinces) of the Sultanate of Oman from 2016 to 2021 using
annual time steps. For the chosen region, multispectral spatiotemporal data
were acquired from the open-source Sentinel-2 satellite dataset. Supervised
machine learning algorithms were used to train and classify different land
covers, such as water bodies, crops, urban, etc. The constructed model was
subsequently applied within the study region, allowing for an effective
comparative evaluation of LULC changes within the given timeframe.

</details>


### [108] [X2Graph for Cancer Subtyping Prediction on Biological Tabular Data](https://arxiv.org/abs/2505.23334)
*Tu Bui, Mohamed Suliman, Aparajita Haldar, Mohammed Amer, Serban Georgescu*

**主要类别:** cs.LG

**概要:** 提出了一种新的深度学习方法X2Graph，通过利用表格列间关系的外部知识（如基因相互作用），将样本转换为图结构并应用消息传递算法，在小规模生物医学表格数据集上表现出优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管深度学习对文本、音频和图像数据集产生了变革性的影响，但在表格数据（特别是在数据稀缺的医疗领域）中的优势尚不明确。

**方法:** X2Graph利用关于表格列之间关系的外部知识（如基因相互作用），将每个样本转换为图结构，并应用标准的消息传递算法进行图建模。

**结果:** X2Graph方法在三个癌症亚型数据集上的表现优于现有的基于树和深度学习的方法。

**结论:** X2Graph在小规模生物医学表格数据集上表现出色，优于现有的基于树和深度学习的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X2Graph+for+Cancer+Subtyping+Prediction+on+Biological+Tabular+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23334，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23334&send_immediately=true&force_search=false)

**原文摘要:** Despite the transformative impact of deep learning on text, audio, and image
datasets, its dominance in tabular data, especially in the medical domain where
data are often scarce, remains less clear. In this paper, we propose X2Graph, a
novel deep learning method that achieves strong performance on small biological
tabular datasets. X2Graph leverages external knowledge about the relationships
between table columns, such as gene interactions, to convert each sample into a
graph structure. This transformation enables the application of standard
message passing algorithms for graph modeling. Our X2Graph method demonstrates
superior performance compared to existing tree-based and deep learning methods
across three cancer subtyping datasets.

</details>


### [109] [Graph Positional Autoencoders as Self-supervised Learners](https://arxiv.org/abs/2505.23345)
*Yang Liu, Deyu Bo, Wenxuan Cao, Yuan Fang, Yawen Li, Chuan Shi*

**主要类别:** cs.LG

**概要:** 图自监督学习旨在不依赖标记数据的情况下学习有效的图表示。尽管图自动编码器（GAEs）在预测缺失元素方面表现良好，但传统的节点或边屏蔽范式主要捕获图中的低频信号，无法学习表达性的结构信息。本文提出了图位置自动编码器（GraphPAE），它采用双路径架构来重构节点特征和位置。实验结果表明，GraphPAE在异质节点分类、图属性预测和迁移学习等任务上实现了最先进的性能，并且大幅优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 尽管图自动编码器（GAEs）在图自监督学习中表现出色，但传统的方法仅能捕获低频信号，未能有效学习图的结构性信息。因此需要一种新的方法来增强GAE的学习能力。

**方法:** 提出了一种名为Graph Positional Autoencoders (GraphPAE)的新方法，该方法采用双路径架构：特征路径使用位置编码来增强消息传递过程；位置路径利用节点表示来优化位置并近似特征向量，从而让编码器学习到多样频率的信息。

**结果:** 通过广泛的实验验证，GraphPAE在异质节点分类、图属性预测和迁移学习等任务上显著优于现有方法，达到业界领先水平。

**结论:** GraphPAE有效地解决了传统GAE只能捕获低频信号的问题，其双路径架构显著提升了图自监督学习的效果，为相关应用提供了更强大的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Positional+Autoencoders+as+Self-supervised+Learners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23345，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23345&send_immediately=true&force_search=false)

**原文摘要:** Graph self-supervised learning seeks to learn effective graph representations
without relying on labeled data. Among various approaches, graph autoencoders
(GAEs) have gained significant attention for their efficiency and scalability.
Typically, GAEs take incomplete graphs as input and predict missing elements,
such as masked nodes or edges. While effective, our experimental investigation
reveals that traditional node or edge masking paradigms primarily capture
low-frequency signals in the graph and fail to learn the expressive structural
information. To address these issues, we propose Graph Positional Autoencoders
(GraphPAE), which employs a dual-path architecture to reconstruct both node
features and positions. Specifically, the feature path uses positional encoding
to enhance the message-passing processing, improving GAE's ability to predict
the corrupted information. The position path, on the other hand, leverages node
representations to refine positions and approximate eigenvectors, thereby
enabling the encoder to learn diverse frequency information. We conduct
extensive experiments to verify the effectiveness of GraphPAE, including
heterophilic node classification, graph property prediction, and transfer
learning. The results demonstrate that GraphPAE achieves state-of-the-art
performance and consistently outperforms baselines by a large margin.

</details>


### [110] [Sentinel: Scheduling Live Streams with Proactive Anomaly Detection in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2505.23347)
*Yuting Li, Shaoyuan Huang, Tengwen Zhang, Cheng Zhang, Xiaofei Wang, Victor C. M. Leung*

**主要类别:** cs.LG

**概要:** 提出了一种名为Sentinel的主动异常检测调度框架，通过两阶段调度范式有效降低了异常频率、提升了收入并加快了调度速度。


<details>
  <summary>更多</summary>
  
**动机:** 直播服务的快速增长使得众包云边服务平台（CCPs）在满足需求方面扮演着越来越重要的角色。然而，由于CCPs的不稳定性和规模庞大，现有的流调度优化策略难以实现实际效果，尤其是在时间敏感的调度中，异常检测面临巨大挑战。

**方法:** 提出Sentinel框架，将调度过程建模为两阶段的Pre-Post-Scheduling范式：预调度阶段进行异常检测并构建策略池；后调度阶段根据请求触发合适的调度策略以完成调度过程。

**结果:** 实验表明，Sentinel显著减少了70%的异常频率，提高了74%的收入，并且将调度速度提高了一倍。

**结论:** Sentinel框架在降低异常频率、提升平台收入和加速调度方面表现出色，为解决CCPs中的调度问题提供了有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sentinel%3A+Scheduling+Live+Streams+with+Proactive+Anomaly+Detection+in+Crowdsourced+Cloud-Edge+Platforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23347，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23347&send_immediately=true&force_search=false)

**原文摘要:** With the rapid growth of live streaming services, Crowdsourced Cloud-edge
service Platforms (CCPs) are playing an increasingly important role in meeting
the increasing demand. Although stream scheduling plays a critical role in
optimizing CCPs' revenue, most optimization strategies struggle to achieve
practical results due to various anomalies in unstable CCPs. Additionally, the
substantial scale of CCPs magnifies the difficulties of anomaly detection in
time-sensitive scheduling. To tackle these challenges, this paper proposes
Sentinel, a proactive anomaly detection-based scheduling framework. Sentinel
models the scheduling process as a two-stage Pre-Post-Scheduling paradigm: in
the pre-scheduling stage, Sentinel conducts anomaly detection and constructs a
strategy pool; in the post-scheduling stage, upon request arrival, it triggers
an appropriate scheduling based on a pre-generated strategy to implement the
scheduling process. Extensive experiments on realistic datasets show that
Sentinel significantly reduces anomaly frequency by 70%, improves revenue by
74%, and doubles the scheduling speed.

</details>


### [111] [Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control](https://arxiv.org/abs/2505.23355)
*Maxiu Xiao, Jianglin Lan, Jingxing Yu, Eldert van Henten, Congcong Sun*

**主要类别:** cs.LG

**概要:** 在温室气候控制中应用交互式强化学习（RL），特别是处理不完美输入时的表现。通过开发定制算法和神经网络方法，研究发现影响动作选择的策略成形和控制共享算法能更好应对不完美输入，分别提高8.4%和6.8%的利润；而奖励成形算法则导致9.4%的利润下降。


<details>
  <summary>更多</summary>
  
**动机:** 气候控制对温室生产至关重要，而当前强化学习在训练效率和初始条件依赖上存在挑战。交互式RL结合了人类输入和智能体学习，可能解决这些挑战，但尚未应用于温室气候控制领域。

**方法:** 1. 开发三种代表性的交互式RL算法（奖励成形、策略成形和控制共享）；2. 分析输入特性及其矛盾，并探讨如何平衡使输入难以完美；3. 提出基于神经网络的方法以增强有限输入下的鲁棒性；4. 在模拟温室环境中全面评估这三种算法。

**结果:** 交互式RL结合不完美输入可以提升RL智能体性能。其中，影响动作选择的算法（如策略成形和控制共享）表现更优，分别提升了8.4%和6.8%的利润；而操纵奖励函数的奖励成形算法对不完美输入敏感，导致9.4%的利润下降。

**结论:** 在温室气候控制中使用交互式RL时，选择合适的机制以应对不完美输入至关重要。策略成形和控制共享更适合处理不完美输入，而奖励成形则不太适用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grower-in-the-Loop+Interactive+Reinforcement+Learning+for+Greenhouse+Climate+Control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23355&send_immediately=true&force_search=false)

**原文摘要:** Climate control is crucial for greenhouse production as it directly affects
crop growth and resource use. Reinforcement learning (RL) has received
increasing attention in this field, but still faces challenges, including
limited training efficiency and high reliance on initial learning conditions.
Interactive RL, which combines human (grower) input with the RL agent's
learning, offers a potential solution to overcome these challenges. However,
interactive RL has not yet been applied to greenhouse climate control and may
face challenges related to imperfect inputs. Therefore, this paper aims to
explore the possibility and performance of applying interactive RL with
imperfect inputs into greenhouse climate control, by: (1) developing three
representative interactive RL algorithms tailored for greenhouse climate
control (reward shaping, policy shaping and control sharing); (2) analyzing how
input characteristics are often contradicting, and how the trade-offs between
them make grower's inputs difficult to perfect; (3) proposing a neural
network-based approach to enhance the robustness of interactive RL agents under
limited input availability; (4) conducting a comprehensive evaluation of the
three interactive RL algorithms with imperfect inputs in a simulated greenhouse
environment. The demonstration shows that interactive RL incorporating
imperfect grower inputs has the potential to improve the performance of the RL
agent. RL algorithms that influence action selection, such as policy shaping
and control sharing, perform better when dealing with imperfect inputs,
achieving 8.4% and 6.8% improvement in profit, respectively. In contrast,
reward shaping, an algorithm that manipulates the reward function, is sensitive
to imperfect inputs and leads to a 9.4% decrease in profit. This highlights the
importance of selecting an appropriate mechanism when incorporating imperfect
inputs.

</details>


### [112] [Meta-Learning Approaches for Speaker-Dependent Voice Fatigue Models](https://arxiv.org/abs/2505.23378)
*Roseline Polle, Agnes Norbury, Alexandra Livia Georgescu, Nicholas Cummins, Stefano Goria*

**主要类别:** cs.LG

**概要:** 在语音健康监测应用中，说话人相关建模可以显著提高性能。本文将此任务重新定义为元学习问题，并探索了三种方法：基于集成的距离模型、原型网络和基于Transformer的序列模型。使用预先训练好的语音嵌入，在一个大型纵向数据集上评估这些方法，预测从语音到睡眠时间的关系（疲劳程度）。结果显示所有测试的元学习方法都优于横断面和传统的混合效应模型，其中基于Transformer的方法表现最佳。


<details>
  <summary>更多</summary>
  
**动机:** 说话人适应对于语音健康监测至关重要，但传统混合效应模型需要对每个新观察值进行昂贵的再训练，这在生产环境中不切实际。因此，研究者希望找到一种更高效的建模方法来解决这一问题。

**方法:** 研究者将说话人适应任务重新定义为元学习问题，并探索了三种复杂度递增的方法：基于集成的距离模型、原型网络和基于Transformer的序列模型。使用预先训练好的语音嵌入，评估这些方法在一个大型纵向数据集上的表现，该数据集包含1,185名轮班工人和10,286个录音记录。

**结果:** 所有测试的元学习方法均优于横断面和传统的混合效应模型。其中，基于Transformer的方法表现出最强的性能。

**结论:** 基于Transformer的元学习方法可以在说话人相关建模任务中实现最佳性能，同时避免了传统混合效应模型的计算开销，适合在生产环境中应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-Learning+Approaches+for+Speaker-Dependent+Voice+Fatigue+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23378，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23378&send_immediately=true&force_search=false)

**原文摘要:** Speaker-dependent modelling can substantially improve performance in
speech-based health monitoring applications. While mixed-effect models are
commonly used for such speaker adaptation, they require computationally
expensive retraining for each new observation, making them impractical in a
production environment. We reformulate this task as a meta-learning problem and
explore three approaches of increasing complexity: ensemble-based distance
models, prototypical networks, and transformer-based sequence models. Using
pre-trained speech embeddings, we evaluate these methods on a large
longitudinal dataset of shift workers (N=1,185, 10,286 recordings), predicting
time since sleep from speech as a function of fatigue, a symptom commonly
associated with ill-health. Our results demonstrate that all meta-learning
approaches tested outperformed both cross-sectional and conventional
mixed-effects models, with a transformer-based method achieving the strongest
performance.

</details>


### [113] [Automated Modeling Method for Pathloss Model Discovery](https://arxiv.org/abs/2505.23383)
*Ahmad Anaqreh, Shih-Kai Chou, Mihael Mohorčič, Carolina Fortuna*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的方法，结合深度符号回归和Kolmogorov-Arnold网络，加速路径损耗模型的发现，并保证可解释性。实验表明，Kolmogorov-Arnold网络预测精确，而深度符号回归生成紧凑模型。自动化方法比传统方法减少75%预测误差。


<details>
  <summary>更多</summary>
  
**动机:** 随着无线通信系统的扩展，对建模方法的准确性和互操作性的需求不断增长，但大多数基于AI的方法缺乏可解释性。因此需要一种新的方法来解决这一问题。

**方法:** 提出了一种新方法，包含两种技术：基于深度符号回归（Deep Symbolic Regression）的技术提供完全可解释性；基于Kolmogorov-Arnold网络的技术提供两层可解释性。该方法自动化了模型的公式化、评估和改进过程。

**结果:** 在两个合成数据集和两个真实世界数据集上的实验结果表明，Kolmogorov-Arnold网络达到接近1的R^2值，预测误差最小；深度符号回归生成紧凑模型，具有中等准确性。此外，在选定的例子上，自动化方法比传统方法减少了高达75%的预测误差。

**结论:** 所提出的自动化方法不仅提高了下一代路径损耗模型发现的效率，而且提供了准确且可解释的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+Modeling+Method+for+Pathloss+Model+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23383，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23383&send_immediately=true&force_search=false)

**原文摘要:** Modeling propagation is the cornerstone for designing and optimizing
next-generation wireless systems, with a particular emphasis on 5G and beyond
era. Traditional modeling methods have long relied on statistic-based
techniques to characterize propagation behavior across different environments.
With the expansion of wireless communication systems, there is a growing demand
for methods that guarantee the accuracy and interoperability of modeling.
Artificial intelligence (AI)-based techniques, in particular, are increasingly
being adopted to overcome this challenge, although the interpretability is not
assured with most of these methods. Inspired by recent advancements in AI, this
paper proposes a novel approach that accelerates the discovery of path loss
models while maintaining interpretability. The proposed method automates the
model formulation, evaluation, and refinement, facilitating model discovery. We
evaluate two techniques: one based on Deep Symbolic Regression, offering full
interpretability, and the second based on Kolmogorov-Arnold Networks, providing
two levels of interpretability. Both approaches are evaluated on two synthetic
and two real-world datasets. Our results show that Kolmogorov-Arnold Networks
achieve R^2 values close to 1 with minimal prediction error, while Deep
Symbolic Regression generates compact models with moderate accuracy. Moreover,
on the selected examples, we demonstrate that automated methods outperform
traditional methods, achieving up to 75% reduction in prediction errors,
offering accurate and explainable solutions with potential to increase the
efficiency of discovering next-generation path loss models.

</details>


### [114] [OTPTO: Joint Product Selection and Inventory Optimization in Fresh E-commerce Front-End Warehouses](https://arxiv.org/abs/2505.23421)
*Zheming Zhang, Yan Jiang, Qingshan Li, Ai Han*

**主要类别:** cs.LG

**概要:** 在中国生鲜电商市场中，前端仓库的库存管理对于提高客户满意度和竞争优势至关重要。本文提出了一种多任务OTPTO方法，通过优化产品选择和库存管理来提高订单满足率。实验结果表明，该方法显著优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 前端仓库的小规模和容量限制使得库存管理面临挑战，传统的预测-优化方法未能有效结合预测与库存目标，并且忽略了消费者满意度。

**方法:** 提出了一种多任务OTPTO方法，包括：1) 使用0-1混合整数规划模型OM1确定历史最优库存水平；2) 通过产品选择模型PM1和补货模型PM2进行预测；3) 利用后处理算法OM2进一步优化结果。

**结果:** 相比传统的PTO方法，OTPTO方法将订单满足率提高了4.34%（相对提升7.05%），并将与最优订单满足率的差距缩小了5.27%。

**结论:** OTPTO方法在生鲜电商平台前端仓库的库存管理中表现出色，为未来研究提供了有价值的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OTPTO%3A+Joint+Product+Selection+and+Inventory+Optimization+in+Fresh+E-commerce+Front-End+Warehouses，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23421，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23421&send_immediately=true&force_search=false)

**原文摘要:** In China's competitive fresh e-commerce market, optimizing operational
strategies, especially inventory management in front-end warehouses, is key to
enhance customer satisfaction and to gain a competitive edge. Front-end
warehouses are placed in residential areas to ensure the timely delivery of
fresh goods and are usually in small size. This brings the challenge of
deciding which goods to stock and in what quantities, taking into account
capacity constraints. To address this issue, traditional predict-then-optimize
(PTO) methods that predict sales and then decide on inventory often don't align
prediction with inventory goals, as well as fail to prioritize consumer
satisfaction. This paper proposes a multi-task
Optimize-then-Predict-then-Optimize (OTPTO) approach that jointly optimizes
product selection and inventory management, aiming to increase consumer
satisfaction by maximizing the full order fulfillment rate. Our method employs
a 0-1 mixed integer programming model OM1 to determine historically optimal
inventory levels, and then uses a product selection model PM1 and the stocking
model PM2 for prediction. The combined results are further refined through a
post-processing algorithm OM2. Experimental results from JD.com's 7Fresh
platform demonstrate the robustness and significant advantages of our OTPTO
method. Compared to the PTO approach, our OTPTO method substantially enhances
the full order fulfillment rate by 4.34% (a relative increase of 7.05%) and
narrows the gap to the optimal full order fulfillment rate by 5.27%. These
findings substantiate the efficacy of the OTPTO method in managing inventory at
front-end warehouses of fresh e-commerce platforms and provide valuable
insights for future research in this domain.

</details>


### [115] [On the Validity of Head Motion Patterns as Generalisable Depression Biomarkers](https://arxiv.org/abs/2505.23427)
*Monika Gahalawat, Maneesh Bilalpur, Raul Fernandez Rojas, Jeffrey F. Cohn, Roland Goecke, Ramanathan Subramanian*

**主要类别:** cs.LG

**概要:** 研究了利用头部运动基本单元（kinemes）来评估抑郁程度的模型的有效性和通用性，发现头部运动模式是有效的生物标志物，并且基于kineme的特征比其他视觉行为线索更具有通用性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管研究人员已经探索了多种言语和非言语的行为线索用于自动抑郁评估，但头部运动尚未受到足够的关注。此外，通过单一数据集验证机器学习模型的常见做法可能会限制模型的通用性。

**方法:** 考虑了来自不同西方文化的三个抑郁数据集（德国：AVEC2013、澳大利亚：Blackdog和美国：Pitt），使用两种方法研究从这些数据集中得出的kineme模式的通用性：(i) 在单个/多个数据集上的k折交叉验证，以及 (ii) 在其他数据集上的模型重用。使用经典机器学习方法评估分类和回归性能。

**结果:** 结果表明：(1) 头部运动模式是估计抑郁严重程度的有效生物标志物，在各种数据集上实现了高度竞争力的分类和回归任务性能，包括在AVEC2013数据集上实现了第二好的平均绝对误差（MAE）。(2) 基于kineme的特征对于二元严重程度分类比原始头部运动描述符更具通用性，对于严重程度估计（回归）比其他视觉行为线索更具通用性。

**结论:** 头部运动模式可以作为有效的生物标志物用于抑郁严重程度的估计，并且基于kineme的特征相比其他特征更具通用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Validity+of+Head+Motion+Patterns+as+Generalisable+Depression+Biomarkers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23427，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23427&send_immediately=true&force_search=false)

**原文摘要:** Depression is a debilitating mood disorder negatively impacting millions
worldwide. While researchers have explored multiple verbal and non-verbal
behavioural cues for automated depression assessment, head motion has received
little attention thus far. Further, the common practice of validating machine
learning models via a single dataset can limit model generalisability. This
work examines the effectiveness and generalisability of models utilising
elementary head motion units, termed kinemes, for depression severity
estimation. Specifically, we consider three depression datasets from different
western cultures (German: AVEC2013, Australian: Blackdog and American: Pitt
datasets) with varied contextual and recording settings to investigate the
generalisability of the derived kineme patterns via two methods: (i) k-fold
cross-validation over individual/multiple datasets, and (ii) model reuse on
other datasets. Evaluating classification and regression performance with
classical machine learning methods, our results show that: (1) head motion
patterns are efficient biomarkers for estimating depression severity, achieving
highly competitive performance for both classification and regression tasks on
a variety of datasets, including achieving the second best Mean Absolute Error
(MAE) on the AVEC2013 dataset, and (2) kineme-based features are more
generalisable than (a) raw head motion descriptors for binary severity
classification, and (b) other visual behavioural cues for severity estimation
(regression).

</details>


### [116] [Diversity-Aware Policy Optimization for Large Language Model Reasoning](https://arxiv.org/abs/2505.23433)
*Jian Yao, Ran Cheng, Xingyu Wu, Jibin Wu, Kay Chen Tan*

**主要类别:** cs.LG

**概要:** 为了提升LLM推理能力，本文研究了RL训练中多样性的影响，并提出了一种新的多样性感知策略优化方法。该方法在R1-zero框架中实现了3.5%的平均改进，并生成更多样和稳健的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多样性在强化学习（RL）中起着关键作用，但其对大型语言模型（LLM）推理的影响尚未得到充分探索。因此，本文旨在系统地研究多样性在基于RL的LLM推理训练中的影响。

**方法:** 作者设计了一种token级别的多样性，并将其重新定义为一个实用的目标函数，然后有选择性地将其应用于正样本。此方法被整合到R1-zero训练框架中。

**结果:** 在对12个LLM的评估中，发现高性能模型中解决方案的多样性和Potential at k（一种量化LLM推理潜力的新指标）之间存在强烈的正相关关系。使用所提出的方法，在四个数学推理基准上平均提升了3.5%。

**结论:** 通过明确促进RL训练过程中的多样性，可以显著提高LLM的推理能力和生成解决方案的多样性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diversity-Aware+Policy+Optimization+for+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23433&send_immediately=true&force_search=false)

**原文摘要:** The reasoning capabilities of large language models (LLMs) have advanced
rapidly, particularly following the release of DeepSeek R1, which has inspired
a surge of research into data quality and reinforcement learning (RL)
algorithms. Despite the pivotal role diversity plays in RL, its influence on
LLM reasoning remains largely underexplored. To bridge this gap, this work
presents a systematic investigation into the impact of diversity in RL-based
training for LLM reasoning, and proposes a novel diversity-aware policy
optimization method. Across evaluations on 12 LLMs, we observe a strong
positive correlation between the solution diversity and Potential at k (a novel
metric quantifying an LLM's reasoning potential) in high-performing models.
This finding motivates our method to explicitly promote diversity during RL
training. Specifically, we design a token-level diversity and reformulate it
into a practical objective, then we selectively apply it to positive samples.
Integrated into the R1-zero training framework, our method achieves a 3.5
percent average improvement across four mathematical reasoning benchmarks,
while generating more diverse and robust solutions.

</details>


### [117] [Rethinking Regularization Methods for Knowledge Graph Completion](https://arxiv.org/abs/2505.23442)
*Linyu Li, Zhi Jin, Yuanpeng He, Dongming Jin, Haoran Duan, Zhengwei Tao, Xuan Zhang, Jiandong Li*

**主要类别:** cs.LG

**概要:** 本研究重新思考了知识图谱补全（KGC）中正则化方法的应用，并提出了一种新的稀疏正则化方法（SPR），通过选择性地惩罚嵌入向量中有显著特征的组件，忽略那些贡献小且可能代表噪声的部分。实验表明，SPR 方法优于其他正则化方法，能进一步突破 KGC 模型的性能上限。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，知识图谱补全（KGC）受到广泛关注，因为它对提升知识图谱的质量至关重要。然而，大多数先前的研究未能从更深层次的角度利用正则化方法，从而未能充分发挥其潜力。因此，需要重新审视正则化在 KGC 中的作用，并探索其潜在优势。

**方法:** 作者通过对多种 KGC 模型进行广泛的实证研究，发现精心设计的正则化不仅可以缓解过拟合和降低方差，还能使模型突破原有性能的上限。基于此，他们提出了一种新的稀疏正则化方法（SPR），该方法将基于排名的选择性稀疏概念嵌入到 KGC 正则化器中。核心思想是选择性地惩罚嵌入向量中具有显著特征的组件，从而有效忽略那些贡献较小且可能仅表示噪声的部分。

**结果:** 各种比较实验在多个数据集和多个模型上表明，SPR 正则化方法优于其他正则化方法，并能使 KGC 模型进一步突破性能边界。

**结论:** 研究表明，精心设计的正则化对于 KGC 至关重要，可以有效缓解过拟合并提升模型性能。提出的 SPR 方法通过引入选择性稀疏的概念，成功实现了对 KGC 模型性能的进一步提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Regularization+Methods+for+Knowledge+Graph+Completion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23442，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23442&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graph completion (KGC) has attracted considerable attention in
recent years because it is critical to improving the quality of knowledge
graphs. Researchers have continuously explored various models. However, most
previous efforts have neglected to take advantage of regularization from a
deeper perspective and therefore have not been used to their full potential.
This paper rethinks the application of regularization methods in KGC. Through
extensive empirical studies on various KGC models, we find that carefully
designed regularization not only alleviates overfitting and reduces variance
but also enables these models to break through the upper bounds of their
original performance. Furthermore, we introduce a novel sparse-regularization
method that embeds the concept of rank-based selective sparsity into the KGC
regularizer. The core idea is to selectively penalize those components with
significant features in the embedding vector, thus effectively ignoring many
components that contribute little and may only represent noise. Various
comparative experiments on multiple datasets and multiple models show that the
SPR regularization method is better than other regularization methods and can
enable the KGC model to further break through the performance margin.

</details>


### [118] [Strategic Classification with Non-Linear Classifiers](https://arxiv.org/abs/2505.23443)
*Benyamin Trachtenberg, Nir Rosenfeld*

**主要类别:** cs.LG

**概要:** 本文研究了在战略性分类中非线性分类器的表现，发现一旦环境变得战略性，通用逼近器（如神经网络）不再具有通用性，并且可能导致性能差距。


<details>
  <summary>更多</summary>
  
**动机:** 尽管标准学习支持广泛的模型类别，但战略分类的研究主要集中在线性分类器上。作者希望扩展这一领域，探索非线性分类器下的战略性行为及其对学习的影响。

**方法:** 采用自下而上的方法，分析非线性如何影响决策边界点、分类器表达能力以及模型类别的复杂性。

**结果:** 关键发现是通用逼近器（例如神经网络）一旦处于战略性环境中就不再是通用的，并且通过实验证明这可能在不受限的模型类别上产生性能差距。

**结论:** 非线性分类器在战略性环境中的表现不同于线性分类器，这对学习和模型选择有重要影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategic+Classification+with+Non-Linear+Classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23443，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23443&send_immediately=true&force_search=false)

**原文摘要:** In strategic classification, the standard supervised learning setting is
extended to support the notion of strategic user behavior in the form of costly
feature manipulations made in response to a classifier. While standard learning
supports a broad range of model classes, the study of strategic classification
has, so far, been dedicated mostly to linear classifiers. This work aims to
expand the horizon by exploring how strategic behavior manifests under
non-linear classifiers and what this implies for learning. We take a bottom-up
approach showing how non-linearity affects decision boundary points, classifier
expressivity, and model classes complexity. A key finding is that universal
approximators (e.g., neural nets) are no longer universal once the environment
is strategic. We demonstrate empirically how this can create performance gaps
even on an unrestricted model class.

</details>


### [119] [Network Inversion for Uncertainty-Aware Out-of-Distribution Detection](https://arxiv.org/abs/2505.23448)
*Pirzada Suhail, Rehna Afroz, Amit Sethi*

**主要类别:** cs.LG

**概要:** 提出了一种结合网络反演和分类器训练的新框架，用于同时解决OOD检测和不确定性估计问题。通过引入'垃圾'类，模型能够有效区分并拒绝OOD样本，并通过置信分数评估不确定性。该方法无需外部OOD数据集或事后校准技术，具有可扩展性和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 在实际场景中，构建安全的机器学习系统需要有效的OOD检测和不确定性估计，以应对不可避免的意外输入。

**方法:** 1. 将标准n类分类任务扩展为(n+1)类模型，新增一个'垃圾'类，初始填充随机高斯噪声以表示异常输入。
2. 在每次训练周期后，使用网络反演重建所有输出类别的输入图像，将最初表现为噪声且不连贯的样本归入'垃圾'类。
3. 迭代执行训练、反演和排除过程，直到反演样本更接近分布内数据，从而优化分类器决策边界并将OOD内容推入'垃圾'类。

**结果:** 模型能够在推理阶段通过将OOD样本分类到'垃圾'类来有效检测并拒绝它们，同时利用预测置信分数估计分布内外输入的不确定性。

**结论:** 所提出的框架提供了一个统一且无需外部OOD数据集或事后校准技术的解决方案，解决了OOD检测和不确定性估计的双重挑战，具备可扩展性和可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Network+Inversion+for+Uncertainty-Aware+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23448&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution (OOD) detection and uncertainty estimation (UE) are
critical components for building safe machine learning systems, especially in
real-world scenarios where unexpected inputs are inevitable. In this work, we
propose a novel framework that combines network inversion with classifier
training to simultaneously address both OOD detection and uncertainty
estimation. For a standard n-class classification task, we extend the
classifier to an (n+1)-class model by introducing a "garbage" class, initially
populated with random gaussian noise to represent outlier inputs. After each
training epoch, we use network inversion to reconstruct input images
corresponding to all output classes that initially appear as noisy and
incoherent and are therefore excluded to the garbage class for retraining the
classifier. This cycle of training, inversion, and exclusion continues
iteratively till the inverted samples begin to resemble the in-distribution
data more closely, suggesting that the classifier has learned to carve out
meaningful decision boundaries while sanitising the class manifolds by pushing
OOD content into the garbage class. During inference, this training scheme
enables the model to effectively detect and reject OOD samples by classifying
them into the garbage class. Furthermore, the confidence scores associated with
each prediction can be used to estimate uncertainty for both in-distribution
and OOD inputs. Our approach is scalable, interpretable, and does not require
access to external OOD datasets or post-hoc calibration techniques while
providing a unified solution to the dual challenges of OOD detection and
uncertainty estimation.

</details>


### [120] [Diffusion Guidance Is a Controllable Policy Improvement Operator](https://arxiv.org/abs/2505.23458)
*Kevin Frans, Seohong Park, Pieter Abbeel, Sergey Levine*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion+Guidance+Is+a+Controllable+Policy+Improvement+Operator，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23458，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23458&send_immediately=true&force_search=false)

**原文摘要:** At the core of reinforcement learning is the idea of learning beyond the
performance in the data. However, scaling such systems has proven notoriously
tricky. In contrast, techniques from generative modeling have proven remarkably
scalable and are simple to train. In this work, we combine these strengths, by
deriving a direct relation between policy improvement and guidance of diffusion
models. The resulting framework, CFGRL, is trained with the simplicity of
supervised learning, yet can further improve on the policies in the data. On
offline RL tasks, we observe a reliable trend -- increased guidance weighting
leads to increased performance. Of particular importance, CFGRL can operate
without explicitly learning a value function, allowing us to generalize simple
supervised methods (e.g., goal-conditioned behavioral cloning) to further
prioritize optimality, gaining performance for "free" across the board.

</details>


### [121] [On Global Convergence Rates for Federated Policy Gradient under Heterogeneous Environment](https://arxiv.org/abs/2505.23459)
*Safwan Labbi, Paul Mangold, Daniil Tiapkin, Eric Moulines*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Global+Convergence+Rates+for+Federated+Policy+Gradient+under+Heterogeneous+Environment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23459，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23459&send_immediately=true&force_search=false)

**原文摘要:** Ensuring convergence of policy gradient methods in federated reinforcement
learning (FRL) under environment heterogeneity remains a major challenge. In
this work, we first establish that heterogeneity, perhaps counter-intuitively,
can necessitate optimal policies to be non-deterministic or even time-varying,
even in tabular environments. Subsequently, we prove global convergence results
for federated policy gradient (FedPG) algorithms employing local updates, under
a {\L}ojasiewicz condition that holds only for each individual agent, in both
entropy-regularized and non-regularized scenarios. Crucially, our theoretical
analysis shows that FedPG attains linear speed-up with respect to the number of
agents, a property central to efficient federated learning. Leveraging insights
from our theoretical findings, we introduce b-RS-FedPG, a novel policy gradient
method that employs a carefully constructed softmax-inspired parameterization
coupled with an appropriate regularization scheme. We further demonstrate
explicit convergence rates for b-RS-FedPG toward near-optimal stationary
policies. Finally, we demonstrate that empirically both FedPG and b-RS-FedPG
consistently outperform federated Q-learning on heterogeneous settings.

</details>


### [122] [Refining Labeling Functions with Limited Labeled Data](https://arxiv.org/abs/2505.23470)
*Chenjie Li, Amir Gilad, Boris Glavic, Zhengjie Miao, Sudeepa Roy*

**主要类别:** cs.LG

**概要:** 本论文提出了一种通过少量标注样本来修复标签函数(LFs)的方法，以提高程序化弱监督中的标签质量。实验表明，系统可以通过极小的标注数据集来提升LFs的质量。


<details>
  <summary>更多</summary>
  
**动机:** 程序化弱监督（PWS）虽能显著减少人工标注数据的努力，但生成标签的质量直接依赖于标签函数（LFs）的准确性。因此，研究如何基于少量标注样本来修复LFs成为一个关键问题。

**方法:** 通过将LFs建模为条件规则，开发了一种新颖的技术来最小化改变它们在标注样例上的结果，从而修复这些LFs。修复后的LFs需要确保：(i) 每个标注数据点的正确标签有足够的证据；(ii) 每个修复后的LF的准确率足够高。

**结果:** 实验结果表明，该系统能够基于令人惊讶的小规模标注数据点集来提升LFs的质量。

**结论:** 通过少量标注样例修复LFs的方法可以有效提高程序化弱监督中生成标签的质量，且实验验证了该方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Refining+Labeling+Functions+with+Limited+Labeled+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23470，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23470&send_immediately=true&force_search=false)

**原文摘要:** Programmatic weak supervision (PWS) significantly reduces human effort for
labeling data by combining the outputs of user-provided labeling functions
(LFs) on unlabeled datapoints. However, the quality of the generated labels
depends directly on the accuracy of the LFs. In this work, we study the problem
of fixing LFs based on a small set of labeled examples. Towards this goal, we
develop novel techniques for repairing a set of LFs by minimally changing their
results on the labeled examples such that the fixed LFs ensure that (i) there
is sufficient evidence for the correct label of each labeled datapoint and (ii)
the accuracy of each repaired LF is sufficiently high. We model LFs as
conditional rules which enables us to refine them, i.e., to selectively change
their output for some inputs. We demonstrate experimentally that our system
improves the quality of LFs based on surprisingly small sets of labeled
datapoints.

</details>


### [123] [SGD as Free Energy Minimization: A Thermodynamic View on Neural Network Training](https://arxiv.org/abs/2505.23489)
*Ildus Sadrtdinov, Ivan Klimov, Ekaterina Lobacheva, Dmitry Vetrov*

**主要类别:** cs.LG

**概要:** 在固定学习率（LRs）下，随机梯度下降（SGD）在神经网络训练中的稳态行为可以用热力学自由能最小化来解释。高LR防止收敛到损失最小值，而不同LR导致稳定在不同的损失水平。实验验证了欠参数化（UP）和过参数化（OP）模型的行为差异。


<details>
  <summary>更多</summary>
  
**动机:** 研究者希望理解为什么在固定学习率下，随机梯度下降（SGD）在神经网络训练中表现出特定的稳态行为，并探索不同学习率如何影响训练过程及最终结果。

**方法:** 通过引入热力学自由能的概念，将SGD视为一种隐式最小化自由能的过程，平衡训练损失和权重分布熵。通过实验验证该框架在欠参数化和过参数化模型中的适用性，并分析两种模型在不同学习率下的行为差异。

**结果:** 实验证明，欠参数化模型始终遵循自由能最小化原则，温度随学习率单调增加；而过参数化模型在低学习率时有效温度降为零，SGD直接最小化损失并收敛到最优解。这种差异归因于近优解处随机梯度的信噪比不同。

**结论:** SGD在固定学习率下的行为可以通过自由能最小化理论进行解释，这一视角有助于理解不同学习率对训练过程的影响，以及欠参数化和过参数化模型之间的差异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SGD+as+Free+Energy+Minimization%3A+A+Thermodynamic+View+on+Neural+Network+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23489，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23489&send_immediately=true&force_search=false)

**原文摘要:** We present a thermodynamic interpretation of the stationary behavior of
stochastic gradient descent (SGD) under fixed learning rates (LRs) in neural
network training. We show that SGD implicitly minimizes a free energy function
$F=U-TS$, balancing training loss $U$ and the entropy of the weights
distribution $S$, with temperature $T$ determined by the LR. This perspective
offers a new lens on why high LRs prevent training from converging to the loss
minima and how different LRs lead to stabilization at different loss levels. We
empirically validate the free energy framework on both underparameterized (UP)
and overparameterized (OP) models. UP models consistently follow free energy
minimization, with temperature increasing monotonically with LR, while for OP
models, the temperature effectively drops to zero at low LRs, causing SGD to
minimize the loss directly and converge to an optimum. We attribute this
mismatch to differences in the signal-to-noise ratio of stochastic gradients
near optima, supported by both a toy example and neural network experiments.

</details>


### [124] [Why Machine Learning Models Fail to Fully Capture Epistemic Uncertainty](https://arxiv.org/abs/2505.23506)
*Sebastián Jiménez, Mira Jürgens, Willem Waegeman*

**主要类别:** cs.LG

**概要:** 尽管近年来出现了一些基于二阶分布的解耦方法来处理随机性和认知不确定性，但这些方法未能充分捕捉认知不确定性的关键成分，特别是经常被忽视的模型偏差部分。通过理论分析和合成实验，本文表明高模型偏差可能导致对认知不确定性的低估，并且常见的二阶不确定性量化方法系统性地将偏差引起的误差混入随机性估计中，从而低估了认知不确定性。只有在所有相关认知不确定性来源都被正确表示时，有意义的随机性估计才是可行的。


<details>
  <summary>更多</summary>
  
**动机:** 当前各种监督学习方法虽然能够解耦随机性和认知不确定性，但它们未能捕捉到认知不确定性中的关键成分，尤其是模型偏差这一常被忽视的因素。

**方法:** 作者使用了一个更细致的认知不确定性来源分类法，分析了期望预测误差的经典偏差-方差分解如何反映这些不确定性。并通过基于模拟的评估协议，涵盖程序性和数据驱动的认知不确定性组件，来说明现有方法很少能捕捉到认知不确定性的完整范围。

**结果:** 研究表明，高模型偏差可能导致对认知不确定性的误导性低估，并且常见的二阶不确定性量化方法系统性地将偏差引起的误差混入随机性估计中。

**结论:** 只有当所有相关的认知不确定性来源都被正确表示时，才有意义进行随机性估计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Machine+Learning+Models+Fail+to+Fully+Capture+Epistemic+Uncertainty，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23506，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23506&send_immediately=true&force_search=false)

**原文摘要:** In recent years various supervised learning methods that disentangle
aleatoric and epistemic uncertainty based on second-order distributions have
been proposed. We argue that these methods fail to capture critical components
of epistemic uncertainty, particularly due to the often-neglected component of
model bias. To show this, we make use of a more fine-grained taxonomy of
epistemic uncertainty sources in machine learning models, and analyse how the
classical bias-variance decomposition of the expected prediction error can be
decomposed into different parts reflecting these uncertainties. By using a
simulation-based evaluation protocol which encompasses epistemic uncertainty
due to both procedural- and data-driven uncertainty components, we illustrate
that current methods rarely capture the full spectrum of epistemic uncertainty.
Through theoretical insights and synthetic experiments, we show that high model
bias can lead to misleadingly low estimates of epistemic uncertainty, and
common second-order uncertainty quantification methods systematically blur
bias-induced errors into aleatoric estimates, thereby underrepresenting
epistemic uncertainty. Our findings underscore that meaningful aleatoric
estimates are feasible only if all relevant sources of epistemic uncertainty
are properly represented.

</details>


### [125] [AnchorAttention: Difference-Aware Sparse Attention with Stripe Granularity](https://arxiv.org/abs/2505.23520)
*Yu Zhang, Dong Guo, Fang Wu, Guoliang Zhu, Dian Ding, Yiming Zhang*

**主要类别:** cs.LG

**概要:** AnchorAttention是一种新的稀疏注意力机制，通过细粒度的条纹稀疏性和全局信息适应，提高了大语言模型在预填充阶段的速度和准确性。相比现有方法，在128k文本长度下，速度提升了1.44倍且召回率更高。


<details>
  <summary>更多</summary>
  
**动机:** 现有的动态模式匹配和块稀疏低级实现方法在处理长上下文时存在局限性：依赖局部信息无法捕捉全局上下文，块的粗粒度导致内部稀疏性持续存在，从而影响准确性和效率。因此需要一种更高效的注意力机制来解决这些问题。

**方法:** AnchorAttention由三个关键组件组成：(1)基于模式的锚点计算，利用输入中的共性快速计算一组接近最大值的分数作为锚点；(2)差异感知的条纹稀疏性识别，与锚点进行差异感知比较以获取显著区域的离散坐标；(3)细粒度稀疏计算，用同时加载离散KV位置代替传统的连续KV块加载，以最大化稀疏率并保持硬件计算潜力。

**结果:** AnchorAttention在相同的召回水平上实现了更高的稀疏率，大幅减少了计算时间。在128k文本长度下，相比现有最先进方法，速度提升了1.44倍，同时保持了更高的召回率。

**结论:** AnchorAttention通过细粒度的稀疏策略和对全局信息的适应，成功解决了现有方法存在的问题，显著提高了大语言模型在长上下文处理中的速度和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AnchorAttention%3A+Difference-Aware+Sparse+Attention+with+Stripe+Granularity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23520，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23520&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) with extended context lengths face significant
computational challenges during the pre-filling phase, primarily due to the
quadratic complexity of self-attention. Existing methods typically employ
dynamic pattern matching and block-sparse low-level implementations. However,
their reliance on local information for pattern identification fails to capture
global contexts, and the coarse granularity of blocks leads to persistent
internal sparsity, resulting in suboptimal accuracy and efficiency. To address
these limitations, we propose \textbf{AnchorAttention}, a difference-aware,
dynamic sparse attention mechanism that efficiently identifies critical
attention regions at a finer stripe granularity while adapting to global
contextual information, achieving superior speed and accuracy. AnchorAttention
comprises three key components: (1) \textbf{Pattern-based Anchor Computation},
leveraging the commonalities present across all inputs to rapidly compute a set
of near-maximum scores as the anchor; (2) \textbf{Difference-aware Stripe
Sparsity Identification}, performing difference-aware comparisons with the
anchor to quickly obtain discrete coordinates of significant regions in a
stripe-like sparsity pattern; (3) \textbf{Fine-grained Sparse Computation},
replacing the traditional contiguous KV block loading approach with
simultaneous discrete KV position loading to maximize sparsity rates while
preserving full hardware computational potential. With its finer-grained
sparsity strategy, \textbf{AnchorAttention} achieves higher sparsity rates at
the same recall level, significantly reducing computation time. Compared to
previous state-of-the-art methods, at a text length of 128k, it achieves a
speedup of 1.44$\times$ while maintaining higher recall rates.

</details>


### [126] [Accelerating AllReduce with a Persistent Straggler](https://arxiv.org/abs/2505.23523)
*Arjun Devraj, Eric Ding, Abhishek Vijaya Kumar, Robert Kleinberg, Rachee Singh*

**主要类别:** cs.LG

**概要:** 提出了一种新的AllReduce算法StragglAR，以加速在存在持久落后者情况下的分布式训练和推理。该方法在大型GPU集群中理论上比流行的带宽高效AllReduce算法快2倍，在8-GPU服务器上比现有最先进算法快22%。


<details>
  <summary>更多</summary>
  
**动机:** 分布式机器学习工作负载使用数据和张量并行性进行训练和推理，但现有的批量同步AllReduce算法可能会因为慢的节点（即持久落后者）而延迟。因此需要一种新的方法来解决这个问题。

**方法:** StragglAR在持久落后者导致的延迟期间在剩余的GPU上实现ReduceScatter，并在落后者达到同步屏障后执行一种新的集体算法完成AllReduce。

**结果:** StragglAR在大型GPU集群中对持久落后者的情况下，理论上比流行带宽高效的AllReduce算法（如Ring）快2倍；在8-GPU服务器上，其实现比最先进的AllReduce算法快22%。

**结论:** StragglAR是一种有效的AllReduce算法，可以显著加速在存在持久落后者情况下的分布式训练和推理过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+AllReduce+with+a+Persistent+Straggler，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23523，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23523&send_immediately=true&force_search=false)

**原文摘要:** Distributed machine learning workloads use data and tensor parallelism for
training and inference, both of which rely on the AllReduce collective to
synchronize gradients or activations. However, bulk-synchronous AllReduce
algorithms can be delayed by a persistent straggler that is slower to reach the
synchronization barrier required to begin the collective. To address this
challenge, we propose StragglAR: an AllReduce algorithm that accelerates
distributed training and inference in the presence of persistent stragglers.
StragglAR implements a ReduceScatter among the remaining GPUs during the
straggler-induced delay, and then executes a novel collective algorithm to
complete the AllReduce once the straggler reaches the synchronization barrier.
StragglAR achieves a 2x theoretical speedup over popular bandwidth-efficient
AllReduce algorithms (e.g., Ring) for large GPU clusters with persistent
stragglers. On an 8-GPU server, our implementation of StragglAR yields a 22%
speedup over state-of-the-art AllReduce algorithms.

</details>


### [127] [Normalizing Flows are Capable Models for RL](https://arxiv.org/abs/2505.23527)
*Raj Ghugare, Benjamin Eysenbach*

**主要类别:** cs.LG

**概要:** 本研究提出了一种基于归一化流（NFs）的单一架构，可以无缝集成到强化学习算法中，作为策略、Q函数和占用度量。这种方法简化了算法，并在模仿学习、离线强化学习、目标条件强化学习和无监督强化学习中取得了更高的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管归一化流模型在理论上具有优势，但其在强化学习中的潜力尚未得到充分挖掘，部分原因是人们普遍认为归一化流缺乏足够的表达能力。

**方法:** 研究者提出了一种新的归一化流架构，该架构能够与强化学习算法无缝结合，可同时用作策略、Q函数和占用度量。

**结果:** 所提出的归一化流方法不仅简化了强化学习算法的设计，而且在多种强化学习任务（如模仿学习、离线强化学习等）中表现出更高的性能。

**结论:** 归一化流模型具备足够的表达能力，可以成为强化学习领域中一个有吸引力的替代方案，未来应进一步探索其潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Normalizing+Flows+are+Capable+Models+for+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23527&send_immediately=true&force_search=false)

**原文摘要:** Modern reinforcement learning (RL) algorithms have found success by using
powerful probabilistic models, such as transformers, energy-based models, and
diffusion/flow-based models. To this end, RL researchers often choose to pay
the price of accommodating these models into their algorithms -- diffusion
models are expressive, but are computationally intensive due to their reliance
on solving differential equations, while autoregressive transformer models are
scalable but typically require learning discrete representations. Normalizing
flows (NFs), by contrast, seem to provide an appealing alternative, as they
enable likelihoods and sampling without solving differential equations or
autoregressive architectures. However, their potential in RL has received
limited attention, partly due to the prevailing belief that normalizing flows
lack sufficient expressivity. We show that this is not the case. Building on
recent work in NFs, we propose a single NF architecture which integrates
seamlessly into RL algorithms, serving as a policy, Q-function, and occupancy
measure. Our approach leads to much simpler algorithms, and achieves higher
performance in imitation learning, offline, goal conditioned RL and
unsupervised RL.

</details>


### [128] [Comparative assessment of fairness definitions and bias mitigation strategies in machine learning-based diagnosis of Alzheimer's disease from MR images](https://arxiv.org/abs/2505.23528)
*Maria Eleftheria Vlontzou, Maria Athanasiou, Christos Davatzikos, Konstantina S. Nikita*

**主要类别:** cs.LG

**概要:** 本研究对基于MRI衍生的神经影像学特征，用于诊断轻度认知障碍（MCI）和阿尔茨海默病（AD）的机器学习模型进行了全面的公平性分析。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在揭示与年龄、种族和性别相关的偏差，并评估这些偏差对模型公平性的影响，特别是在多队列数据集中的表现。同时，研究还探讨了代理特征如何编码这些敏感属性并影响模型的公平性。

**方法:** 1. 使用多种公平性定义和指标来识别偏差。
2. 比较常用的预处理、处理中和后处理偏差缓解策略。
3. 引入一种新的复合度量方法，通过结合F1分数和平等机会比率来量化公平性和性能之间的权衡。
4. 分析不同缓解策略在各敏感属性和子问题上的改进效果。

**结果:** - 发现与年龄和种族相关的偏差，但未观察到显著的性别偏差。
- 针对种族和性别，拒绝选项分类法分别提高了平等机会比率46%和57%，并在MCI vs AD子问题中取得了0.75和0.80的调和平均分。
- 对于年龄，在同一子问题中，对抗去偏法实现了40%的平等机会改善，调和平均分为0.69。

**结论:** 研究揭示了与年龄和种族相关的偏差，并证明不同的偏差缓解策略在各种敏感属性和子问题上表现出不同的改进效果。此外，与人口统计特征相关的阿尔茨海默病神经病理学和风险因素的变化会影响模型的公平性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+assessment+of+fairness+definitions+and+bias+mitigation+strategies+in+machine+learning-based+diagnosis+of+Alzheimer%27s+disease+from+MR+images，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23528，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23528&send_immediately=true&force_search=false)

**原文摘要:** The present study performs a comprehensive fairness analysis of machine
learning (ML) models for the diagnosis of Mild Cognitive Impairment (MCI) and
Alzheimer's disease (AD) from MRI-derived neuroimaging features. Biases
associated with age, race, and gender in a multi-cohort dataset, as well as the
influence of proxy features encoding these sensitive attributes, are
investigated. The reliability of various fairness definitions and metrics in
the identification of such biases is also assessed. Based on the most
appropriate fairness measures, a comparative analysis of widely used
pre-processing, in-processing, and post-processing bias mitigation strategies
is performed. Moreover, a novel composite measure is introduced to quantify the
trade-off between fairness and performance by considering the F1-score and the
equalized odds ratio, making it appropriate for medical diagnostic
applications. The obtained results reveal the existence of biases related to
age and race, while no significant gender bias is observed. The deployed
mitigation strategies yield varying improvements in terms of fairness across
the different sensitive attributes and studied subproblems. For race and
gender, Reject Option Classification improves equalized odds by 46% and 57%,
respectively, and achieves harmonic mean scores of 0.75 and 0.80 in the MCI
versus AD subproblem, whereas for age, in the same subproblem, adversarial
debiasing yields the highest equalized odds improvement of 40% with a harmonic
mean score of 0.69. Insights are provided into how variations in AD
neuropathology and risk factors, associated with demographic characteristics,
influence model fairness.

</details>


### [129] [Domain-Aware Tensor Network Structure Search](https://arxiv.org/abs/2505.23537)
*Giorgos Iacovides, Wuyang Zhou, Chao Li, Qibin Zhao, Danilo Mandic*

**主要类别:** cs.LG

**概要:** 提出tnLLM框架，结合领域信息和大语言模型推理能力，直接预测张量网络结构，减少函数评估次数并提供可解释性。实验表明其性能与现有最佳算法相当但效率更高，并可通过领域信息加速基于采样的方法收敛。


<details>
  <summary>更多</summary>
  
**动机:** 当前的张量网络结构搜索（TN-SS）算法计算成本高，且忽视了真实数据中的领域信息，缺乏透明性。因此需要一种新方法来高效搜索张量网络结构并利用领域知识。

**方法:** 提出tnLLM框架，包含领域感知提示管道，指导大语言模型根据张量模式间的真实关系推断合适的张量网络结构，同时生成领域相关的解释。

**结果:** 实验表明tnLLM在显著减少函数评估次数的情况下达到与现有最佳算法相当的目标函数值。此外，通过领域信息可以为基于采样的方法提供良好初始化，加速收敛并保持理论性能保证。

**结论:** tnLLM框架有效结合了领域信息和大语言模型推理能力，在提高张量网络结构搜索效率的同时提供了可解释性，并能辅助其他方法优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Domain-Aware+Tensor+Network+Structure+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23537，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23537&send_immediately=true&force_search=false)

**原文摘要:** Tensor networks (TNs) provide efficient representations of high-dimensional
data, yet identification of the optimal TN structures, the so called tensor
network structure search (TN-SS) problem, remains a challenge. Current
state-of-the-art (SOTA) algorithms are computationally expensive as they
require extensive function evaluations, which is prohibitive for real-world
applications. In addition, existing methods ignore valuable domain information
inherent in real-world tensor data and lack transparency in their identified TN
structures. To this end, we propose a novel TN-SS framework, termed the tnLLM,
which incorporates domain information about the data and harnesses the
reasoning capabilities of large language models (LLMs) to directly predict
suitable TN structures. The proposed framework involves a domain-aware
prompting pipeline which instructs the LLM to infer suitable TN structures
based on the real-world relationships between tensor modes. In this way, our
approach is capable of not only iteratively optimizing the objective function,
but also generating domain-aware explanations for the identified structures.
Experimental results demonstrate that tnLLM achieves comparable TN-SS objective
function values with much fewer function evaluations compared to SOTA
algorithms. Furthermore, we demonstrate that the LLM-enabled domain information
can be used to find good initializations in the search space for sampling-based
SOTA methods to accelerate their convergence while preserving theoretical
performance guarantees.

</details>


### [130] [Comparing the Moore-Penrose Pseudoinverse and Gradient Descent for Solving Linear Regression Problems: A Performance Analysis](https://arxiv.org/abs/2505.23552)
*Alex Adams*

**主要类别:** cs.LG

**概要:** 这篇论文研究了两种解决线性回归问题的基本方法：闭式Moore-Penrose伪逆和迭代梯度下降法的相对性能。通过理论分析、计算复杂度分析以及在合成数据集和真实世界数据集上的实证行为评估，明确了每种方法在计算时间、数值稳定性和预测准确性方面的优劣条件。该研究为机器学习领域的研究人员和实践者提供了在直接精确解法和迭代近似解法之间进行选择的实际指导。


<details>
  <summary>更多</summary>
  
**动机:** 探讨在解决线性回归问题时，使用闭式Moore-Penrose伪逆和迭代梯度下降法这两种基本方法的相对性能，以帮助研究人员和实践者在实际应用中做出更明智的选择。

**方法:** 1. 回顾并讨论两种方法的理论基础；2. 分析它们的计算复杂度；3. 在具有可控特性的合成数据集以及已建立的真实世界数据集上评估它们的实证行为。

**结果:** 明确了每种方法在计算时间、数值稳定性和预测准确性方面表现优异的条件。

**结论:** 为研究人员和实践者在选择线性回归任务的解决方案时提供了实际指导，即何时选择直接精确解法，何时选择迭代近似解法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparing+the+Moore-Penrose+Pseudoinverse+and+Gradient+Descent+for+Solving+Linear+Regression+Problems%3A+A+Performance+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23552，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23552&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the comparative performance of two fundamental
approaches to solving linear regression problems: the closed-form Moore-Penrose
pseudoinverse and the iterative gradient descent method. Linear regression is a
cornerstone of predictive modeling, and the choice of solver can significantly
impact efficiency and accuracy. I review and discuss the theoretical
underpinnings of both methods, analyze their computational complexity, and
evaluate their empirical behavior on synthetic datasets with controlled
characteristics, as well as on established real-world datasets. My results
delineate the conditions under which each method excels in terms of
computational time, numerical stability, and predictive accuracy. This work
aims to provide practical guidance for researchers and practitioners in machine
learning when selecting between direct, exact solutions and iterative,
approximate solutions for linear regression tasks.

</details>


### [131] [Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling](https://arxiv.org/abs/2505.23555)
*Yanzhao Hou, Jiaxiang Geng, Boyu Li, Xiaofeng Tao, Juncheng Wang, Xiaodong Xu, Bing Luo*

**主要类别:** cs.LG

**概要:** 提出了一种自适应联邦LoRA策略，通过独立客户端采样和带宽分配方案，在计算和通信异构性下最小化联合微调的收敛时间。理论分析和实验结果表明，该方法相较于现有技术能显著减少训练时间。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦LoRA方法在处理系统和数据异构性时存在不足，未能优化整体训练效率，尤其是在实际运行时间（wall-clock time）方面。

**方法:** 1. 推导了具有任意独立客户端采样的联邦LoRA的新收敛界，无需严格的梯度有界假设。
2. 提出了考虑客户端资源异构性和系统带宽限制的自适应带宽分配方案。
3. 基于理论分析，构建并求解了一个非凸优化问题，以确定LoRA素描比率和采样概率，目标是最小化实际运行时间。
4. 开发了一种高效低复杂度算法来近似解决问题。

**结果:** 广泛的实验表明，所提出的方法在各种模型和数据集上相比最先进的方法显著减少了实际运行时间。

**结论:** 所提出的自适应联邦LoRA策略能够有效应对计算和通信异构性，并显著减少联合微调的实际运行时间，提升了整体训练效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Federated+LoRA+in+Heterogeneous+Wireless+Networks+with+Independent+Sampling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23555，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23555&send_immediately=true&force_search=false)

**原文摘要:** Federated LoRA has emerged as a promising technique for efficiently
fine-tuning large language models (LLMs) on distributed devices by reducing the
number of trainable parameters. However, existing approaches often inadequately
overlook the theoretical and practical implications of system and data
heterogeneity, thereby failing to optimize the overall training efficiency,
particularly in terms of wall-clock time. In this paper, we propose an adaptive
federated LoRA strategy with independent client sampling to minimize the
convergence wall-clock time of federated fine-tuning under both computation and
communication heterogeneity. We first derive a new convergence bound for
federated LoRA with arbitrary and independent client sampling, notably without
requiring the stringent bounded gradient assumption. Then, we introduce an
adaptive bandwidth allocation scheme that accounts for heterogeneous client
resources and system bandwidth constraints. Based on the derived theory, we
formulate and solve a non-convex optimization problem to jointly determine the
LoRA sketching ratios and sampling probabilities, aiming to minimize wall-clock
convergence time. An efficient and low-complexity algorithm is developed to
approximate the solution. Finally, extensive experiments demonstrate that our
approach significantly reduces wall-clock training time compared to
state-of-the-art methods across various models and datasets.

</details>


### [132] [DRO: A Python Library for Distributionally Robust Optimization in Machine Learning](https://arxiv.org/abs/2505.23565)
*Jiashuo Liu, Tianyu Wang, Henry Lam, Hongseok Namkoong, Jose Blanchet*

**主要类别:** cs.LG

**概要:** 本论文介绍了dro，一个用于回归和分类问题的分布鲁棒优化（DRO）的开源Python库。该库实现了14种DRO公式和9种骨干模型，支持与scikit-learn和PyTorch兼容，并通过向量化和优化近似技术显著提高了运行效率。


<details>
  <summary>更多</summary>
  
**动机:** 在处理大规模数据集时，现有的DRO实现存在运行效率低的问题，因此需要一个高效、兼容性好的工具来解决回归和分类问题。

**方法:** 开发了一个名为dro的开源Python库，其中包含14种DRO公式和9种骨干模型，支持79种不同的DRO方法。此外，该库与scikit-learn和PyTorch兼容，并采用向量化和优化近似技术以提高运行效率。

**结果:** dro库在大规模数据集上的运行时间相较于基线实现减少了10倍至1000倍以上，证明了其高效性和实用性。

**结论:** dro库为分布鲁棒优化提供了一种高效、兼容性强的解决方案，适用于回归和分类问题，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DRO%3A+A+Python+Library+for+Distributionally+Robust+Optimization+in+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23565，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23565&send_immediately=true&force_search=false)

**原文摘要:** We introduce dro, an open-source Python library for distributionally robust
optimization (DRO) for regression and classification problems. The library
implements 14 DRO formulations and 9 backbone models, enabling 79 distinct DRO
methods. Furthermore, dro is compatible with both scikit-learn and PyTorch.
Through vectorization and optimization approximation techniques, dro reduces
runtime by 10x to over 1000x compared to baseline implementations on
large-scale datasets. Comprehensive documentation is available at
https://python-dro.org.

</details>


### [133] [Maximum Likelihood Learning of Latent Dynamics Without Reconstruction](https://arxiv.org/abs/2505.23569)
*Samo Hromadka, Kai Biegun, Lior Fox, James Heald, Maneesh Sahani*

**主要类别:** cs.LG

**概要:** 这篇论文介绍了一种新的无监督学习方法RP-GSSM，用于具有潜在动力学结构的时间序列数据。该方法结合了对比方法和概率生成模型的优点，通过最大似然估计进行学习，无需显式的网络映射，能够在非线性随机动力学学习任务中优于其他方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列数据分析方法要么缺乏足够的表达能力，要么需要复杂的正则化、辅助损失或优化器调度。因此，需要一种既能保持可处理性又能具有表达能力的新方法来学习时间序列数据中的潜在动力学结构。

**方法:** 提出了一种新的无监督学习方法——RP-GSSM（识别参数化高斯状态空间模型），该方法结合了对比方法的直观性和概率生成模型的灵活性，通过最大似然估计进行学习。它不需要从隐变量到观测值的显式网络映射，而是专注于隐变量的推理。

**结果:** RP-GSSM在包括从视频中学习非线性随机动力学的任务中表现出色，无论是否存在背景干扰因素。这表明RP-GSSM可以作为各种下游应用的基础模型。

**结论:** RP-GSSM作为一种新的时间序列数据无监督学习方法，能够有效地学习潜在的动力学结构，并且在非线性随机动力学学习任务中优于其他方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Maximum+Likelihood+Learning+of+Latent+Dynamics+Without+Reconstruction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23569，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23569&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel unsupervised learning method for time series data with
latent dynamical structure: the recognition-parametrized Gaussian state space
model (RP-GSSM). The RP-GSSM is a probabilistic model that learns Markovian
Gaussian latents explaining statistical dependence between observations at
different time steps, combining the intuition of contrastive methods with the
flexible tools of probabilistic generative models. Unlike contrastive
approaches, the RP-GSSM is a valid probabilistic model learned via maximum
likelihood. Unlike generative approaches, the RP-GSSM has no need for an
explicit network mapping from latents to observations, allowing it to focus
model capacity on inference of latents. The model is both tractable and
expressive: it admits exact inference thanks to its jointly Gaussian latent
prior, while maintaining expressivity with an arbitrarily nonlinear neural
network link between observations and latents. These qualities allow the
RP-GSSM to learn task-relevant latents without ad-hoc regularization, auxiliary
losses, or optimizer scheduling. We show how this approach outperforms
alternatives on problems that include learning nonlinear stochastic dynamics
from video, with or without background distractors. Our results position the
RP-GSSM as a useful foundation model for a variety of downstream applications.

</details>


### [134] [BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model](https://arxiv.org/abs/2505.23579)
*Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris J. Maddison, Bo Wang*

**主要类别:** cs.LG

**概要:** 本研究开发了BioReason，一种将DNA基础模型与大型语言模型（LLM）相结合的开创性架构。通过监督微调和强化学习，BioReason在生物推理基准测试中表现出显著优势，并能生成可解释的生物推导过程。


<details>
  <summary>更多</summary>
  
**动机:** 当前的DNA基础模型虽然在序列表示上表现良好，但在多步骤推理方面存在不足，并且缺乏透明、直观的生物学解释。因此，需要一种新的架构来解决这些问题。

**方法:** 引入BioReason，将DNA基础模型与大型语言模型（LLM）深度整合。通过监督微调和目标强化学习，使LLM能够直接处理和推理基因组信息。

**结果:** 在包括基于KEGG的疾病通路预测等生物推理基准测试中，准确率从88%提高到97%，平均性能提升15%。BioReason还能对未见过的生物实体进行推理，并通过可解释的逐步生物轨迹阐述决策过程。

**结论:** BioReason为生物学AI提供了一种变革性的方法，能够促进更深入的机制洞察并加速从基因组数据中生成可检验的假设。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioReason%3A+Incentivizing+Multimodal+Biological+Reasoning+within+a+DNA-LLM+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23579&send_immediately=true&force_search=false)

**原文摘要:** Unlocking deep, interpretable biological reasoning from complex genomic data
is a major AI challenge hindering scientific discovery. Current DNA foundation
models, despite strong sequence representation, struggle with multi-step
reasoning and lack inherent transparent, biologically intuitive explanations.
We introduce BioReason, a pioneering architecture that, for the first time,
deeply integrates a DNA foundation model with a Large Language Model (LLM).
This novel connection enables the LLM to directly process and reason with
genomic information as a fundamental input, fostering a new form of multimodal
biological understanding. BioReason's sophisticated multi-step reasoning is
developed through supervised fine-tuning and targeted reinforcement learning,
guiding the system to generate logical, biologically coherent deductions. On
biological reasoning benchmarks including KEGG-based disease pathway prediction
- where accuracy improves from 88% to 97% - and variant effect prediction,
BioReason demonstrates an average 15% performance gain over strong
single-modality baselines. BioReason reasons over unseen biological entities
and articulates decision-making through interpretable, step-by-step biological
traces, offering a transformative approach for AI in biology that enables
deeper mechanistic insights and accelerates testable hypothesis generation from
genomic data. Data, code, and checkpoints are publicly available at
https://github.com/bowang-lab/BioReason

</details>


### [135] [Improving Time Series Forecasting via Instance-aware Post-hoc Revision](https://arxiv.org/abs/2505.23583)
*Zhiding Liu, Mingyue Cheng, Guanhao Zhao, Jiqian Yang, Qi Liu, Enhong Chen*

**主要类别:** cs.LG

**概要:** 时间序列预测在实际应用中扮演重要角色，尽管近期方法在整体性能上表现出色，但实例级差异仍然是一个挑战。本文提出了一种模型无关框架PIR，通过后预测识别和修正来提升特定实例的预测性能。实验表明PIR能有效减少实例级误差并提高预测可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有方法在时间序列预测任务中取得了显著的整体性能，但在实例级预测中仍存在偏差问题，例如分布漂移、缺失数据和长尾模式等，导致某些实例预测效果不佳。

**方法:** 提出了一种模型无关框架PIR（Post-forecasting Identification and Revision），首先通过估计预测准确性识别出偏差较大的预测实例，然后利用上下文信息（包括协变量和历史时间序列）从局部和全局视角对预测结果进行修正。

**结果:** 在多个真实世界数据集上的广泛实验表明，PIR能够有效缓解实例级误差，并显著提升时间序列预测的可靠性。

**结论:** PIR框架为解决时间序列预测中的实例级偏差提供了一种通用且有效的解决方案，能够在不改变原有模型结构的情况下提升预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Time+Series+Forecasting+via+Instance-aware+Post-hoc+Revision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23583&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting plays a vital role in various real-world applications
and has attracted significant attention in recent decades. While recent methods
have achieved remarkable accuracy by incorporating advanced inductive biases
and training strategies, we observe that instance-level variations remain a
significant challenge. These variations--stemming from distribution shifts,
missing data, and long-tail patterns--often lead to suboptimal forecasts for
specific instances, even when overall performance appears strong. To address
this issue, we propose a model-agnostic framework, PIR, designed to enhance
forecasting performance through Post-forecasting Identification and Revision.
Specifically, PIR first identifies biased forecasting instances by estimating
their accuracy. Based on this, the framework revises the forecasts using
contextual information, including covariates and historical time series, from
both local and global perspectives in a post-processing fashion. Extensive
experiments on real-world datasets with mainstream forecasting models
demonstrate that PIR effectively mitigates instance-level errors and
significantly improves forecasting reliability.

</details>


### [136] [On-Policy RL with Optimal Reward Baseline](https://arxiv.org/abs/2505.23585)
*Yaru Hao, Li Dong, Xun Wu, Shaohan Huang, Zewen Chi, Furu Wei*

**主要类别:** cs.LG

**概要:** 提出了一种新的强化学习算法OPO，强调精确的on-policy训练并引入最优奖励基线，减少了梯度方差。在数学推理基准上的实验表明，OPO表现出优越的性能和训练稳定性，且不需要额外模型或正则化项，同时实现了更低的策略转移和更高的输出熵，鼓励更多样化的响应。


<details>
  <summary>更多</summary>
  
**动机:** 当前的强化学习算法因松散的on-policy约束导致训练不稳定，并因辅助模型导致计算效率低下。

**方法:** 提出了名为OPO的新算法，该算法强调精确的on-policy训练以稳定训练过程并增强探索能力，并引入了理论上最小化梯度方差的最优奖励基线。

**结果:** 在数学推理基准上的评估显示，OPO具有优越的性能和训练稳定性，无需额外模型或正则化项，同时实现较低的策略转移和较高的输出熵。

**结论:** OPO为大型语言模型对齐和推理任务中的稳定有效的强化学习提供了一个有希望的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On-Policy+RL+with+Optimal+Reward+Baseline，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23585，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23585&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning algorithms are fundamental to align large language
models with human preferences and to enhance their reasoning capabilities.
However, current reinforcement learning algorithms often suffer from training
instability due to loose on-policy constraints and computational inefficiency
due to auxiliary models. In this work, we propose On-Policy RL with Optimal
reward baseline (OPO), a novel and simplified reinforcement learning algorithm
designed to address these challenges. OPO emphasizes the importance of exact
on-policy training, which empirically stabilizes the training process and
enhances exploration. Moreover, OPO introduces the optimal reward baseline that
theoretically minimizes gradient variance. We evaluate OPO on mathematical
reasoning benchmarks. The results demonstrate its superior performance and
training stability without additional models or regularization terms.
Furthermore, OPO achieves lower policy shifts and higher output entropy,
encouraging more diverse and less repetitive responses. These results highlight
OPO as a promising direction for stable and effective reinforcement learning in
large language model alignment and reasoning tasks. The implementation is
provided at https://github.com/microsoft/LMOps/tree/main/opo.

</details>


### [137] [Accelerated Training of Federated Learning via Second-Order Methods](https://arxiv.org/abs/2505.23588)
*Mrinmay Sen, Sidhant R Nair, C Krishna Mohan*

**主要类别:** cs.LG

**概要:** 本文探讨了联邦学习中的二阶优化方法，旨在解决模型收敛缓慢和通信轮次过多的问题。文章提供了最先进的二阶FL方法的分类，并基于收敛速度、计算成本等多个指标比较了其性能。研究表明，在FL中使用Hessian曲率的二阶优化具有潜力，并指出了高效利用Hessian及其逆矩阵的关键挑战。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中的慢收敛问题以及高通信成本需要改进优化方法来加速训练过程。

**方法:** 通过分析和比较各种利用二阶优化的联邦学习方法，评估它们在不同指标上的表现。

**结果:** 发现二阶优化方法可以加速联邦学习中的模型训练，并指出高效利用Hessian矩阵及逆矩阵是主要挑战。

**结论:** 二阶优化方法在联邦学习中有潜力，未来研究应致力于开发可扩展且高效的优化方法以改进全局模型训练。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerated+Training+of+Federated+Learning+via+Second-Order+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23588，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23588&send_immediately=true&force_search=false)

**原文摘要:** This paper explores second-order optimization methods in Federated Learning
(FL), addressing the critical challenges of slow convergence and the excessive
communication rounds required to achieve optimal performance from the global
model. While existing surveys in FL primarily focus on challenges related to
statistical and device label heterogeneity, as well as privacy and security
concerns in first-order FL methods, less attention has been given to the issue
of slow model training. This slow training often leads to the need for
excessive communication rounds or increased communication costs, particularly
when data across clients are highly heterogeneous. In this paper, we examine
various FL methods that leverage second-order optimization to accelerate the
training process. We provide a comprehensive categorization of state-of-the-art
second-order FL methods and compare their performance based on convergence
speed, computational cost, memory usage, transmission overhead, and
generalization of the global model. Our findings show the potential of
incorporating Hessian curvature through second-order optimization into FL and
highlight key challenges, such as the efficient utilization of Hessian and its
inverse in FL. This work lays the groundwork for future research aimed at
developing scalable and efficient federated optimization methods for improving
the training of the global model in FL.

</details>


### [138] [Position: Federated Foundation Language Model Post-Training Should Focus on Open-Source Models](https://arxiv.org/abs/2505.23593)
*Nikita Agrawal, Simon Mertel, Ruben Mayer*

**主要类别:** cs.LG

**概要:** A position paper that critically analyzes the usage of black-box models in federated post-training and discusses its implications for FL.


<details>
  <summary>更多</summary>
  
**动机:** The motivation is to highlight the concerns with using black-box models in federated learning (FL) for post-training of foundation language models, as it contradicts core principles like data privacy and autonomy.

**方法:** The method involves a critical analysis of the use of black-box models in federated post-training, examining various aspects of openness and their implications for FL.

**结果:** No specific results are presented; rather, the paper provides a detailed account of the issues and implications associated with using black-box models in FL.

**结论:** The conclusion is that using black-box models in FL contradicts the principles of federation, such as data privacy and autonomy, thus necessitating further research into more transparent and open methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Position%3A+Federated+Foundation+Language+Model+Post-Training+Should+Focus+on+Open-Source+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23593，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23593&send_immediately=true&force_search=false)

**原文摘要:** Post-training of foundation language models has emerged as a promising
research domain in federated learning (FL) with the goal to enable
privacy-preserving model improvements and adaptations to user's downstream
tasks. Recent advances in this area adopt centralized post-training approaches
that build upon black-box foundation language models where there is no access
to model weights and architecture details. Although the use of black-box models
has been successful in centralized post-training, their blind replication in FL
raises several concerns. Our position is that using black-box models in FL
contradicts the core principles of federation such as data privacy and
autonomy. In this position paper, we critically analyze the usage of black-box
models in federated post-training, and provide a detailed account of various
aspects of openness and their implications for FL.

</details>


### [139] [LLM Performance for Code Generation on Noisy Tasks](https://arxiv.org/abs/2505.23598)
*Radzim Sendyka, Christian Cabrera, Andrei Paleyes, Diana Robinson, Neil Lawrence*

**主要类别:** cs.LG

**概要:** 这篇论文研究了大型语言模型（LLMs）识别和解决被混淆到无法辨认的任务的能力。通过比较多个模型在不同混淆方法下的表现，发现所有评估的LLM都能解决文本对人类读者不可理解的任务，这表明模型可能存在强记忆或过度拟合训练数据的现象，而非合理推理。作者提出了急切模式匹配的概念，并讨论了其对模型行为评估的影响，同时提出了一种新的策略来检测数据集污染及潜在安全风险。


<details>
  <summary>更多</summary>
  
**动机:** 研究大型语言模型在面对经过混淆处理的任务时的表现，以探讨模型是否真正具备解决问题的能力还是仅仅依赖于记忆或过拟合训练数据。

**方法:** 使用竞争性编程和基准任务（如LeetCode和MATH），对比多个LLM在不同混淆方法（如噪声和删减）下的性能，引入“急切模式匹配”概念进行描述。

**结果:** 所有评估的LLM能够在任务被混淆到人类无法理解的情况下解决问题，表现出对训练数据的强记忆或过拟合现象，而非真正的推理能力。在模型知识截止日期之后发布的任务中未观察到这种行为。

**结论:** 在设计使用标准数据集的实验时需谨慎，建议采用测量混淆下性能衰减的方法来检测数据集污染，揭示潜在的安全风险和解释性问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM+Performance+for+Code+Generation+on+Noisy+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23598，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23598&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the ability of large language models (LLMs) to
recognise and solve tasks which have been obfuscated beyond recognition.
Focusing on competitive programming and benchmark tasks (LeetCode and MATH), we
compare performance across multiple models and obfuscation methods, such as
noise and redaction. We demonstrate that all evaluated LLMs can solve tasks
obfuscated to a level where the text would be unintelligible to human readers,
and does not contain key pieces of instruction or context. We introduce the
concept of eager pattern matching to describe this behaviour, which is not
observed in tasks published after the models' knowledge cutoff date, indicating
strong memorisation or overfitting to training data, rather than legitimate
reasoning about the presented problem. We report empirical evidence of distinct
performance decay patterns between contaminated and unseen datasets. We discuss
the implications for benchmarking and evaluations of model behaviour, arguing
for caution when designing experiments using standard datasets. We also propose
measuring the decay of performance under obfuscation as a possible strategy for
detecting dataset contamination and highlighting potential safety risks and
interpretability issues for automated software systems.

</details>


### [140] [Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model](https://arxiv.org/abs/2505.23606)
*Qingyu Shi, Jinbin Bai, Zhuoran Zhao, Wenhao Chai, Kaidong Yu, Jianzong Wu, Shuangyong Song, Yunhai Tong, Xiangtai Li, Xuelong Li, Shuicheng Yan*

**主要类别:** cs.LG

**概要:** Muddit是一种统一的离散扩散变压器，它能够在文本和图像模态之间实现快速和平行生成。与从头开始训练的先前统一扩散模型不同，Muddit将预训练的文本到图像主干中的强大视觉先验与轻量级文本解码器集成在一起，从而在统一架构下实现灵活和高质量的多模态生成。实证结果表明，Muddit在质量和效率方面都表现出优于显著较大的自回归模型的性能或相当的性能。这项工作强调了当配备强大的视觉先验时，纯粹的离散扩散作为统一生成的可扩展和有效的主干的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 当前的统一生成模型要么由于顺序解码导致推理速度慢（自回归统一模型），要么由于预训练主干的限制导致泛化能力弱（非自回归统一模型）。为了解决这些问题，研究者提出了一种新的模型，以实现更快、更高效的多模态生成。

**方法:** Muddit是一个统一的离散扩散变压器，它集成了预训练的文本到图像主干中的强大视觉先验和轻量级文本解码器。这种方法使得Muddit能够在统一架构下进行灵活和高质量的多模态生成，同时克服了自回归和非自回归模型的缺点。

**结果:** 实证结果表明，Muddit在质量和效率方面均优于显著较大的自回归模型，或者与之表现相当。这证明了Muddit的有效性和高效性。

**结论:** Muddit展示了一个有潜力的方向，即通过结合强大的视觉先验，纯粹的离散扩散可以作为一个可扩展和有效的统一生成主干。这为未来的多模态生成研究提供了新的思路和方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Muddit%3A+Liberating+Generation+Beyond+Text-to-Image+with+a+Unified+Discrete+Diffusion+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23606，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23606&send_immediately=true&force_search=false)

**原文摘要:** Unified generation models aim to handle diverse tasks across modalities --
such as text generation, image generation, and vision-language reasoning --
within a single architecture and decoding paradigm. Autoregressive unified
models suffer from slow inference due to sequential decoding, and
non-autoregressive unified models suffer from weak generalization due to
limited pretrained backbones. We introduce Muddit, a unified discrete diffusion
transformer that enables fast and parallel generation across both text and
image modalities. Unlike prior unified diffusion models trained from scratch,
Muddit integrates strong visual priors from a pretrained text-to-image backbone
with a lightweight text decoder, enabling flexible and high-quality multimodal
generation under a unified architecture. Empirical results show that Muddit
achieves competitive or superior performance compared to significantly larger
autoregressive models in both quality and efficiency. The work highlights the
potential of purely discrete diffusion, when equipped with strong visual
priors, as a scalable and effective backbone for unified generation.

</details>


### [141] [Data Model Design for Explainable Machine Learning-based Electricity Applications](https://arxiv.org/abs/2505.23607)
*Carolina Fortuna, Gregor Cerar, Blaz Bertalanic, Andrej Campa, Mihael Mohorcic*

**主要类别:** cs.LG

**概要:** The paper proposes a taxonomy for identifying and structuring data types in energy applications, which is used to guide feature selection for machine learning models in household electricity forecasting. It studies the impact of different features on forecasting accuracy using interpretable machine learning techniques.


<details>
  <summary>更多</summary>
  
**动机:** There is a digital transformation in energy infrastructure due to the shift towards smart grids, increased use of renewable energy sources, and rising electricity prices. However, most machine learning models rely on univariate data, and there is a lack of structured study considering multivariate data, meta-data, and additional measurements.

**方法:** A taxonomy is proposed to identify and structure various types of data related to energy applications. This taxonomy is applied to guide the development of application-specific data models for training machine learning models. The effectiveness of the taxonomy is validated through a household electricity forecasting application.

**结果:** The study investigates the effect of domain, contextual, and behavioral features on the forecasting accuracy of four interpretable machine learning techniques across three openly available datasets. Feature importance techniques are used to explain individual feature contributions to forecasting accuracy.

**结论:** The proposed taxonomy effectively guides the selection of features for machine learning models in household electricity forecasting applications. It highlights the significance of considering multivariate data, meta-data, and additional measurements.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Model+Design+for+Explainable+Machine+Learning-based+Electricity+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23607，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23607&send_immediately=true&force_search=false)

**原文摘要:** The transition from traditional power grids to smart grids, significant
increase in the use of renewable energy sources, and soaring electricity prices
has triggered a digital transformation of the energy infrastructure that
enables new, data driven, applications often supported by machine learning
models. However, the majority of the developed machine learning models rely on
univariate data. To date, a structured study considering the role meta-data and
additional measurements resulting in multivariate data is missing. In this
paper we propose a taxonomy that identifies and structures various types of
data related to energy applications. The taxonomy can be used to guide
application specific data model development for training machine learning
models. Focusing on a household electricity forecasting application, we
validate the effectiveness of the proposed taxonomy in guiding the selection of
the features for various types of models. As such, we study of the effect of
domain, contextual and behavioral features on the forecasting accuracy of four
interpretable machine learning techniques and three openly available datasets.
Finally, using a feature importance techniques, we explain individual feature
contributions to the forecasting accuracy.

</details>


### [142] [The Generalized Skew Spectrum of Graphs](https://arxiv.org/abs/2505.23609)
*Armando Bellante, Martin Plávala, Alessandro Luongo*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种置换不变的图嵌入方法，推广了Kondor和Borgwardt(2008)提出的图的偏谱。该方法基于群论和调和分析，引入了一类新的同构不变的图不变量，能够嵌入更丰富的图结构。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图嵌入方法（如Skew Spectrum）无法处理包含属性的图、多层图和超图等复杂结构。

**方法:** 通过引入基于群论和调和分析的新类图不变量，提出一种置换不变的图嵌入方法，并定义了一族函数来权衡计算复杂度和表达能力。

**结果:** 实验表明，该方法提高了表达能力，同时保持与Skew Spectrum相同的计算成本，并正式证明了其不变性。

**结论:** 所提出的图嵌入方法推广了Skew Spectrum，能有效表示更复杂的图结构，且计算效率高。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Generalized+Skew+Spectrum+of+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23609，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23609&send_immediately=true&force_search=false)

**原文摘要:** This paper proposes a family of permutation-invariant graph embeddings,
generalizing the Skew Spectrum of graphs of Kondor & Borgwardt (2008). Grounded
in group theory and harmonic analysis, our method introduces a new class of
graph invariants that are isomorphism-invariant and capable of embedding richer
graph structures - including attributed graphs, multilayer graphs, and
hypergraphs - which the Skew Spectrum could not handle. Our generalization
further defines a family of functions that enables a trade-off between
computational complexity and expressivity. By applying
generalization-preserving heuristics to this family, we improve the Skew
Spectrum's expressivity at the same computational cost. We formally prove the
invariance of our generalization, demonstrate its improved expressiveness
through experiments, and discuss its efficient computation.

</details>


### [143] [Learning Interpretable Differentiable Logic Networks for Tabular Regression](https://arxiv.org/abs/2505.23615)
*Chang Yue, Niraj K. Jha*

**主要类别:** cs.LG

**概要:** 本文扩展了Differentiable Logic Networks（DLNs）框架至监督表格回归任务，通过重新设计输出层以支持连续目标，并将训练过程统一为单一可微阶段。实验表明，回归DLNs在15个公开基准上匹配或超越基线模型的准确性，同时保持可解释性和快速推理能力，是回归任务中兼具成本效益和透明性的可行替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络在许多领域表现出色，但其决策过程不透明且推理成本高。为了改进这些问题，作者之前提出了用于表格分类的Differentiable Logic Networks（DLNs），通过将离散逻辑转换为可微形式，实现基于梯度的学习，提供可解释推理和低推理成本。在此基础上，作者希望将DLN框架扩展到监督表格回归任务。

**方法:** 作者重新设计了DLN的最终输出层以支持连续目标变量，并将原有的两阶段训练过程合并为一个单一的可微训练阶段。这一改进使得DLN能够适用于回归任务，同时保留了可解释性和高效推理的特点。

**结果:** 在15个公共回归基准上的评估显示，回归DLNs的准确率与现代神经网络和经典回归基线相当甚至更优，同时保持了模型的可解释性和快速推理能力。

**结论:** DLNs是一种可行且成本效益高的回归任务解决方案，特别适合需要模型透明性和计算效率的场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Interpretable+Differentiable+Logic+Networks+for+Tabular+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23615，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23615&send_immediately=true&force_search=false)

**原文摘要:** Neural networks (NNs) achieve outstanding performance in many domains;
however, their decision processes are often opaque and their inference can be
computationally expensive in resource-constrained environments. We recently
proposed Differentiable Logic Networks (DLNs) to address these issues for
tabular classification based on relaxing discrete logic into a differentiable
form, thereby enabling gradient-based learning of networks built from binary
logic operations. DLNs offer interpretable reasoning and substantially lower
inference cost.
  We extend the DLN framework to supervised tabular regression. Specifically,
we redesign the final output layer to support continuous targets and unify the
original two-phase training procedure into a single differentiable stage. We
evaluate the resulting model on 15 public regression benchmarks, comparing it
with modern neural networks and classical regression baselines. Regression DLNs
match or exceed baseline accuracy while preserving interpretability and fast
inference. Our results show that DLNs are a viable, cost-effective alternative
for regression tasks, especially where model transparency and computational
efficiency are important.

</details>


### [144] [Prompting Whisper for Improved Verbatim Transcription and End-to-end Miscue Detection](https://arxiv.org/abs/2505.23627)
*Griffin Dietz Smith, Dianna Yee, Jennifer King Chen, Leah Findlater*

**主要类别:** cs.LG

**概要:** 通过将目标阅读文本纳入提示，提出了一种新的端到端架构，该架构可以同时改进逐字转录和直接错误检测。在儿童朗读和成人非典型语音的案例研究中，新策略比现有技术更好。


<details>
  <summary>更多</summary>
  
**动机:** 现有的事后方法在自动语音识别（ASR）不准确转录音频时表现不佳，因此需要改进阅读错误注释的方法。

**方法:** 提出一种新的端到端架构，通过提示结合目标阅读文本，从而改善逐字转录并直接检测误读。还进行了两项案例研究：儿童朗读和成人非典型语音。

**结果:** 与当前最先进的技术相比，所提出的策略提高了逐字转录和误读检测的效果。

**结论:** 将阅读文本通过提示结合进来，对逐字转录性能有益，并且增强语音识别任务以实现端到端误读检测是可行的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prompting+Whisper+for+Improved+Verbatim+Transcription+and+End-to-end+Miscue+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23627，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23627&send_immediately=true&force_search=false)

**原文摘要:** Identifying mistakes (i.e., miscues) made while reading aloud is commonly
approached post-hoc by comparing automatic speech recognition (ASR)
transcriptions to the target reading text. However, post-hoc methods perform
poorly when ASR inaccurately transcribes verbatim speech. To improve on current
methods for reading error annotation, we propose a novel end-to-end
architecture that incorporates the target reading text via prompting and is
trained for both improved verbatim transcription and direct miscue detection.
Our contributions include: first, demonstrating that incorporating reading text
through prompting benefits verbatim transcription performance over fine-tuning,
and second, showing that it is feasible to augment speech recognition tasks for
end-to-end miscue detection. We conducted two case studies -- children's
read-aloud and adult atypical speech -- and found that our proposed strategies
improve verbatim transcription and miscue detection compared to current
state-of-the-art.

</details>


### [145] [MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment](https://arxiv.org/abs/2505.23634)
*John Halloran*

**主要类别:** cs.LG

**概要:** The paper highlights the broader threat of Model Context Protocol (MCP)-based attacks, where malicious content online can deceive MCP agents. It introduces an MCP dataset for Falsely Benign Attacks (FBAs) and explores Direct Preference Optimization (DPO) for refusal training in large language models (LLMs). However, DPO effectiveness varies depending on the model's alignment scheme. To address this, the authors propose Retrieval Augmented Generation for Preference alignment (RAG-Pref), which significantly enhances LLMs' ability to refuse FBAs when combined with DPO.


<details>
  <summary>更多</summary>
  
**动机:** To address the susceptibility of MCP to retrieval-based 'falsely benign' attacks (FBAs) that could lead to system access and credential theft without requiring direct file downloads.

**方法:** Introduction of a new MCP dataset containing FBAs and truly benign samples; exploration of Direct Preference Optimization (DPO) for refusal training in LLMs; development of Retrieval Augmented Generation for Preference alignment (RAG-Pref) to improve FBA refusals.

**结果:** DPO improves model guardrails against FBAs but varies in efficacy based on the original alignment scheme. RAG-Pref significantly enhances LLMs' ability to refuse FBAs, especially when combined with DPO.

**结论:** RAG-Pref, when used with DPO, substantially strengthens guardrails against MCP-based attacks by improving LLMs' refusal capabilities for FBAs.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCP+Safety+Training%3A+Learning+to+Refuse+Falsely+Benign+MCP+Exploits+using+Improved+Preference+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23634，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23634&send_immediately=true&force_search=false)

**原文摘要:** The model context protocol (MCP) has been widely adapted as an open standard
enabling the seamless integration of generative AI agents. However, recent work
has shown the MCP is susceptible to retrieval-based "falsely benign" attacks
(FBAs), allowing malicious system access and credential theft, but requiring
that users download compromised files directly to their systems. Herein, we
show that the threat model of MCP-based attacks is significantly broader than
previously thought, i.e., attackers need only post malicious content online to
deceive MCP agents into carrying out their attacks on unsuspecting victims'
systems.
  To improve alignment guardrails against such attacks, we introduce a new MCP
dataset of FBAs and (truly) benign samples to explore the effectiveness of
direct preference optimization (DPO) for the refusal training of large language
models (LLMs). While DPO improves model guardrails against such attacks, we
show that the efficacy of refusal learning varies drastically depending on the
model's original post-training alignment scheme--e.g., GRPO-based LLMs learn to
refuse extremely poorly. Thus, to further improve FBA refusals, we introduce
Retrieval Augmented Generation for Preference alignment (RAG-Pref), a novel
preference alignment strategy based on RAG. We show that RAG-Pref significantly
improves the ability of LLMs to refuse FBAs, particularly when combined with
DPO alignment, thus drastically improving guardrails against MCP-based attacks.

</details>


### [146] [Global optimization of graph acquisition functions for neural architecture search](https://arxiv.org/abs/2505.23640)
*Yilin Xie, Shiqiang Zhang, Jixiang Qing, Ruth Misener, Calvin Tsay*

**主要类别:** cs.LG

**概要:** 图贝叶斯优化（Graph Bayesian Optimization, BO）在神经架构搜索（NAS）中展现出潜力，本文提出了针对图输入空间的显式优化公式，包括可达性和最短路径等特性，并证明了编码的有效性。实验结果表明，该方法在多个NAS基准测试中能够高效找到最优架构。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图BO研究主要集中在开发图代理模型上，而对获取函数优化的研究较少，因为其涉及复杂的图结构离散优化任务。

**方法:** 本文提出了一种针对图输入空间的显式优化公式，包含可达性和最短路径等特性，用于构建图核和获取函数，并提供了节点或边标签限制下的NAS领域理论表示。

**结果:** 数值结果显示，该方法在大多数情况下能有效找到最优架构。

**结论:** 所提出的编码是图空间的等效表示，适用于具有节点或边标签限制的NAS领域，且在多个基准测试中表现出高效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Global+optimization+of+graph+acquisition+functions+for+neural+architecture+search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23640，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23640&send_immediately=true&force_search=false)

**原文摘要:** Graph Bayesian optimization (BO) has shown potential as a powerful and
data-efficient tool for neural architecture search (NAS). Most existing graph
BO works focus on developing graph surrogates models, i.e., metrics of networks
and/or different kernels to quantify the similarity between networks. However,
the acquisition optimization, as a discrete optimization task over graph
structures, is not well studied due to the complexity of formulating the graph
search space and acquisition functions. This paper presents explicit
optimization formulations for graph input space including properties such as
reachability and shortest paths, which are used later to formulate graph
kernels and the acquisition function. We theoretically prove that the proposed
encoding is an equivalent representation of the graph space and provide
restrictions for the NAS domain with either node or edge labels. Numerical
results over several NAS benchmarks show that our method efficiently finds the
optimal architecture for most cases, highlighting its efficacy.

</details>


### [147] [Continuous Chain of Thought Enables Parallel Exploration and Reasoning](https://arxiv.org/abs/2505.23648)
*Halil Alperen Gozeten, M. Emrullah Ildiz, Xuechen Zhang, Hrayr Harutyunyan, Ankit Singh Rawat, Samet Oymak*

**主要类别:** cs.LG

**概要:** 当前语言模型通过从有限词汇表中自回归采样生成离散思维链。然而，使用连续值符号（CoT2）进行思维链推理提供了更丰富和更具表达力的替代方案。本文研究了在逻辑推理任务中使用CoT2的好处，并提出优化与探索方法。理论上，CoT2使模型能够并行跟踪多个推理路径，提高推理效率。实验表明，采用CoT2的策略确实可以提升模型性能，超越其初始离散或连续监督的效果。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有的基于离散符号采样的思维链方法取得了显著成功，但连续值符号（CoT2）为推理提供了更丰富的表达能力，特别是在需要搜索能力的任务上。这激励了对CoT2的研究，以探索其在逻辑推理任务中的潜力。

**方法:** 1. 理论分析：证明CoT2允许模型并行跟踪多条推理路径，从而提升推理效率。
2. 新颖监督策略：将softmax输出与目标推理路径的经验符号分布匹配。
3. 提出两种采样策略：
   - 第一种控制每步解码时K个离散符号的并行性（当K=1时退化为标准离散思维链）。
   - 第二种基于概率单纯形的连续探索。
4. 通过实验验证CoT2在政策优化和自我改进方面的有效性。

**结果:** 理论和实验证明，使用CoT2进行推理可以显著提升模型性能，超过其初始离散或连续监督的表现。具体来说，配备CoT2的一层Transformer可以在足够嵌入维度下解决组合问题（如子集和问题）。此外，提出的采样策略有效提升了模型的推理能力和效率。

**结论:** 本文展示了连续值符号（CoT2）在逻辑推理任务中的优势，包括更高的表达能力、并行推理路径跟踪和推理效率提升。这些发现为未来语言模型的设计提供了新的方向，尤其是在需要复杂推理和优化的任务中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Continuous+Chain+of+Thought+Enables+Parallel+Exploration+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23648，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23648&send_immediately=true&force_search=false)

**原文摘要:** Current language models generate chain-of-thought traces by autoregressively
sampling tokens from a finite vocabulary. While this discrete sampling has
achieved remarkable success, conducting chain-of-thought with
continuously-valued tokens (CoT2) offers a richer and more expressive
alternative. Our work examines the benefits of CoT2 through logical reasoning
tasks that inherently require search capabilities and provide optimization and
exploration methods for CoT2. Theoretically, we show that CoT2 allows the model
to track multiple traces in parallel and quantify its benefits for inference
efficiency. Notably, one layer transformer equipped with CoT2 can provably
solve the combinatorial "subset sum problem" given sufficient embedding
dimension. These insights lead to a novel and effective supervision strategy
where we match the softmax outputs to the empirical token distributions of a
set of target traces. Complementing this, we introduce sampling strategies that
unlock policy optimization and self-improvement for CoT2. Our first strategy
samples and composes $K$ discrete tokens at each decoding step to control the
level of parallelism, and reduces to standard CoT when $K=1$. Our second
strategy relies on continuous exploration over the probability simplex.
Experiments confirm that policy optimization with CoT2 indeed improves the
performance of the model beyond its initial discrete or continuous supervision.

</details>


### [148] [Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation](https://arxiv.org/abs/2505.23651)
*Juncheol Shin, Minsang Seok, Seonggon Kim, Eunhyeok Park*

**主要类别:** cs.LG

**概要:** 本研究探讨了量化对模型融合的影响，并提出了一种新的后训练量化方法HDRQ，以最小化与源预训练模型的偏差并促进多目标领域适应中的平滑模型融合。


<details>
  <summary>更多</summary>
  
**动机:** 在实际应用中，如量化模型等场景下，模型融合面临新挑战，因为量化过程限制了关注域并引入离散化效应，使得模型融合变得非常复杂。

**方法:** 作者提出了HDRQ（Hessian and distant regularizing quantization），一种新的后训练量化方法，该方法考虑了多目标领域适应中的模型融合问题。HDRQ确保量化过程对源预训练模型的偏差最小，并通过平坦化损失表面来促进平滑模型融合。

**结果:** 广泛的实验验证了所提出方法的有效性，证明HDRQ能够在量化过程中实现平滑模型融合，并保持与源预训练模型的一致性。

**结论:** 这是首个针对量化对模型融合影响的研究，提出的HDRQ方法为解决这一问题提供了有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge-Friendly+Post-Training+Quantization+for+Multi-Target+Domain+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23651，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23651&send_immediately=true&force_search=false)

**原文摘要:** Model merging has emerged as a powerful technique for combining task-specific
weights, achieving superior performance in multi-target domain adaptation.
However, when applied to practical scenarios, such as quantized models, new
challenges arise. In practical scenarios, quantization is often applied to
target-specific data, but this process restricts the domain of interest and
introduces discretization effects, making model merging highly non-trivial. In
this study, we analyze the impact of quantization on model merging through the
lens of error barriers. Leveraging these insights, we propose a novel
post-training quantization, HDRQ - Hessian and distant regularizing
quantization - that is designed to consider model merging for multi-target
domain adaptation. Our approach ensures that the quantization process incurs
minimal deviation from the source pre-trained model while flattening the loss
surface to facilitate smooth model merging. To our knowledge, this is the first
study on this challenge, and extensive experiments confirm its effectiveness.

</details>


### [149] [How does Transformer Learn Implicit Reasoning?](https://arxiv.org/abs/2505.23653)
*Jiaran Ye, Zijun Yao, Zhidian Huang, Liangming Pan, Jinxin Liu, Yushi Bai, Amy Xin, Liu Weichuan, Xiaoyin Che, Lei Hou, Juanzi Li*

**主要类别:** cs.LG

**概要:** 近期研究表明，大型语言模型（LLMs）可以进行隐式的多步推理——在不明确表达中间步骤的情况下产生正确答案，但其底层机制尚不明确。本文通过在一个受控的符号环境中从头训练Transformer模型，研究了这种隐式推理是如何出现的。分析揭示了三个发展阶段：早期的记忆阶段、随后的分布内泛化以及最终的跨分布泛化。研究发现，使用原子三元组训练不是必要条件，但能加速学习，并且第二步泛化依赖于对特定组合结构的查询级暴露。为了解释这些行为，我们引入了两种诊断工具：跨查询语义修补，用于识别语义可重用的中间表示；基于余弦相似度的表示镜头，揭示了成功推理与隐藏空间中基于余弦的聚类现象之间的关联。该聚类现象为整个训练过程中观察到的行为动态提供了一个连贯的解释，将表示结构与推理能力联系起来。这些发现为隐式多步推理在LLMs中的可解释性提供了新的见解，有助于阐明复杂的推理过程如何在模型内部展开，并为提高此类模型的透明度提供了途径。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）能够进行隐式的多步推理，但其底层机制尚不明确，需要深入研究以理解这一现象并提高模型的透明度。

**方法:** 作者通过在受控的符号环境中从头训练Transformer模型来研究隐式推理的出现。分析了模型在不同训练阶段的行为，并引入了两种诊断工具：跨查询语义修补和基于余弦相似度的表示镜头。

**结果:** 发现了模型发展的三个阶段：早期记忆、分布内泛化和跨分布泛化。使用原子三元组训练可以加速学习，第二步泛化依赖于特定组合结构的暴露。诊断工具揭示了成功推理与隐藏空间中基于余弦的聚类现象之间的关联。

**结论:** 这些发现为隐式多步推理在LLMs中的可解释性提供了新见解，有助于理解复杂推理过程的内部展开，并为提高模型透明度提供了方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+does+Transformer+Learn+Implicit+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23653，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23653&send_immediately=true&force_search=false)

**原文摘要:** Recent work suggests that large language models (LLMs) can perform multi-hop
reasoning implicitly -- producing correct answers without explicitly
verbalizing intermediate steps -- but the underlying mechanisms remain poorly
understood. In this paper, we study how such implicit reasoning emerges by
training transformers from scratch in a controlled symbolic environment. Our
analysis reveals a three-stage developmental trajectory: early memorization,
followed by in-distribution generalization, and eventually cross-distribution
generalization. We find that training with atomic triples is not necessary but
accelerates learning, and that second-hop generalization relies on query-level
exposure to specific compositional structures. To interpret these behaviors, we
introduce two diagnostic tools: cross-query semantic patching, which identifies
semantically reusable intermediate representations, and a cosine-based
representational lens, which reveals that successful reasoning correlates with
the cosine-base clustering in hidden space. This clustering phenomenon in turn
provides a coherent explanation for the behavioral dynamics observed across
training, linking representational structure to reasoning capability. These
findings provide new insights into the interpretability of implicit multi-hop
reasoning in LLMs, helping to clarify how complex reasoning processes unfold
internally and offering pathways to enhance the transparency of such models.

</details>


### [150] [AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction](https://arxiv.org/abs/2505.23663)
*Niklas Freymuth, Tobias Würth, Nicolas Schreiber, Balazs Gyenes, Andreas Boltres, Johannes Mitsch, Aleksandar Taranovic, Tai Hoang, Philipp Dahlinger, Philipp Becker, Luise Kärger, Gerhard Neumann*

**主要类别:** cs.LG

**概要:** 提出了一种名为AMBER的监督学习方法，用于自适应网格划分。该方法通过预测尺寸场并生成中间网格来提高计算效率，并在2D和3D数据集上表现出色，优于多种近期基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 有限元法（FEM）模拟复杂物理系统的成本和精度与底层网格的分辨率相关。自适应网格虽然能提高计算效率，但通常需要特定任务的启发式方法或人工设计。

**方法:** 从粗网格开始，AMBER迭代预测尺寸场（几何到局部元素大小的函数），并使用此预测通过现成的网格生成器生成新的中间网格。这一过程依赖于分层图神经网络，并在训练期间通过自动将专家标签投影到AMBER生成的数据上来进行数据增强。

**结果:** AMBER在包括经典物理问题、机械部件和具有人类专家网格的实际工业设计在内的2D和3D数据集上进行了评估。结果表明，AMBER可以推广到未见的几何形状，并且始终优于多个近期基线方法，包括基于图和卷积神经网络以及强化学习的方法。

**结论:** AMBER作为一种监督学习方法，在自适应网格生成方面表现优异，能够推广到新几何形状并超越现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AMBER%3A+Adaptive+Mesh+Generation+by+Iterative+Mesh+Resolution+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23663，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23663&send_immediately=true&force_search=false)

**原文摘要:** The cost and accuracy of simulating complex physical systems using the Finite
Element Method (FEM) scales with the resolution of the underlying mesh.
Adaptive meshes improve computational efficiency by refining resolution in
critical regions, but typically require task-specific heuristics or cumbersome
manual design by a human expert. We propose Adaptive Meshing By Expert
Reconstruction (AMBER), a supervised learning approach to mesh adaptation.
Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,
a function mapping from the geometry to the local element size of the target
mesh, and uses this prediction to produce a new intermediate mesh using an
out-of-the-box mesh generator. This process is enabled through a hierarchical
graph neural network, and relies on data augmentation by automatically
projecting expert labels onto AMBER-generated data during training. We evaluate
AMBER on 2D and 3D datasets, including classical physics problems, mechanical
components, and real-world industrial designs with human expert meshes. AMBER
generalizes to unseen geometries and consistently outperforms multiple recent
baselines, including ones using Graph and Convolutional Neural Networks, and
Reinforcement Learning-based approaches.

</details>


### [151] [Bayesian Optimization from Human Feedback: Near-Optimal Regret Bounds](https://arxiv.org/abs/2505.23673)
*Aya Kayal, Sattar Vakili, Laura Toni, Da-shan Shiu, Alberto Bernacchia*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Optimization+from+Human+Feedback%3A+Near-Optimal+Regret+Bounds，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23673，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23673&send_immediately=true&force_search=false)

**原文摘要:** Bayesian optimization (BO) with preference-based feedback has recently
garnered significant attention due to its emerging applications. We refer to
this problem as Bayesian Optimization from Human Feedback (BOHF), which differs
from conventional BO by learning the best actions from a reduced feedback
model, where only the preference between two actions is revealed to the learner
at each time step. The objective is to identify the best action using a limited
number of preference queries, typically obtained through costly human feedback.
Existing work, which adopts the Bradley-Terry-Luce (BTL) feedback model,
provides regret bounds for the performance of several algorithms. In this work,
within the same framework we develop tighter performance guarantees.
Specifically, we derive regret bounds of
$\tilde{\mathcal{O}}(\sqrt{\Gamma(T)T})$, where $\Gamma(T)$ represents the
maximum information gain$\unicode{x2014}$a kernel-specific complexity
term$\unicode{x2014}$and $T$ is the number of queries. Our results
significantly improve upon existing bounds. Notably, for common kernels, we
show that the order-optimal sample complexities of conventional
BO$\unicode{x2014}$achieved with richer feedback models$\unicode{x2014}$are
recovered. In other words, the same number of preferential samples as
scalar-valued samples is sufficient to find a nearly optimal solution.

</details>


### [152] [Understanding Mode Connectivity via Parameter Space Symmetry](https://arxiv.org/abs/2505.23681)
*Bo Zhao, Nima Dehmamy, Robin Walters, Rose Yu*

**主要类别:** cs.LG

**概要:** 神经网络极小值通常通过保持训练和测试损失几乎不变的曲线相连，这一现象被称为模式连通性。本文提出了一种新的方法，利用参数空间对称性来探索极小值的连通性，并推导了线性网络极小值的连通分量数量，以及跳过连接如何减少该数量。此外，还研究了模式连通性和线性模式连通性成立或失效的条件，并提供了由对称性引起的连接曲线的显式表达式。最后，通过这些曲线的曲率，推导出线性模式连通性近似成立的条件。本文强调了连续对称性在理解神经网络损失景观中的作用。


<details>
  <summary>更多</summary>
  
**动机:** 尽管模式连通性已被应用于模型合并和微调等实际问题中，但其理论解释仍然不明确。因此，作者希望提出一种新方法来探索极小值的连通性，并更深入地理解神经网络损失景观。

**方法:** 1. 利用参数空间对称性，将对称群的拓扑与极小值的拓扑联系起来。
2. 推导线性网络极小值的连通分量数量，并研究跳过连接对其的影响。
3. 分析模式连通性和线性模式连通性成立或失效的条件。
4. 提供由对称性引起的连接曲线的显式表达式。
5. 使用这些曲线的曲率，推导线性模式连通性近似成立的条件。

**结果:** 1. 成功推导了线性网络极小值的连通分量数量。
2. 证明了跳过连接可以减少连通分量的数量。
3. 明确了模式连通性和线性模式连通性成立或失效的条件。
4. 提供了由对称性引起的连接曲线的显式表达式。
5. 推导出线性模式连通性近似成立的条件。

**结论:** 本文通过参数空间对称性揭示了神经网络损失景观中模式连通性的关键因素，特别是连续对称性的作用。这为未来进一步研究神经网络优化和泛化性能提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Mode+Connectivity+via+Parameter+Space+Symmetry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23681，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23681&send_immediately=true&force_search=false)

**原文摘要:** Neural network minima are often connected by curves along which train and
test loss remain nearly constant, a phenomenon known as mode connectivity.
While this property has enabled applications such as model merging and
fine-tuning, its theoretical explanation remains unclear. We propose a new
approach to exploring the connectedness of minima using parameter space
symmetry. By linking the topology of symmetry groups to that of the minima, we
derive the number of connected components of the minima of linear networks and
show that skip connections reduce this number. We then examine when mode
connectivity and linear mode connectivity hold or fail, using parameter
symmetries which account for a significant part of the minimum. Finally, we
provide explicit expressions for connecting curves in the minima induced by
symmetry. Using the curvature of these curves, we derive conditions under which
linear mode connectivity approximately holds. Our findings highlight the role
of continuous symmetries in understanding the neural network loss landscape.

</details>


### [153] [Learning Compositional Functions with Transformers from Easy-to-Hard Data](https://arxiv.org/abs/2505.23683)
*Zixuan Wang, Eshaan Nichani, Alberto Bietti, Alex Damian, Daniel Hsu, Jason D. Lee, Denny Wu*

**主要类别:** cs.LG

**概要:** 这篇论文探讨了Transformer模型在k重组合任务上的可学习性，证明了统计计算差距的存在，并展示了通过两种课程学习策略，利用梯度下降可以在多项式时间内有效学习此类任务。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已知Transformer能够高效执行涉及并行化计算的多步推理任务，但其可学习性，特别是通过基于梯度的优化实现高效学习所需的数据分布条件，仍是一个未解决的问题。因此，研究者选择分析k重组合任务，以进一步理解Transformer的学习能力。

**方法:** 研究者首先为k重组合任务证明了一个统计查询（SQ）下界，表明任何仅对k重组合任务分布进行多项式数量查询的SQ学习者都需要样本数量随k呈指数增长。接着，研究者展示了通过两种课程学习策略，可以使用梯度下降方法在深度为O(log k)的Transformer上以多项式时间复杂度和样本复杂度来有效学习该函数类。这两种策略分别是按难度递增提供数据和同时提供所有数据。

**结果:** 研究结果揭示了k重组合任务存在统计计算差距，即需要指数级样本才能通过SQ方法学习，但通过适当的课程学习策略和梯度下降方法，可以在多项式时间内有效学习。

**结论:** 这项工作阐明了数据分布中包含简单和困难示例对于Transformer学习复杂组合任务的必要性和充分性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Compositional+Functions+with+Transformers+from+Easy-to-Hard+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23683，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23683&send_immediately=true&force_search=false)

**原文摘要:** Transformer-based language models have demonstrated impressive capabilities
across a range of complex reasoning tasks. Prior theoretical work exploring the
expressive power of transformers has shown that they can efficiently perform
multi-step reasoning tasks involving parallelizable computations. However, the
learnability of such constructions, particularly the conditions on the data
distribution that enable efficient learning via gradient-based optimization,
remains an open question. Towards answering this question, in this work we
study the learnability of the $k$-fold composition task, which requires
computing an interleaved composition of $k$ input permutations and $k$ hidden
permutations, and can be expressed by a transformer with $O(\log k)$ layers. On
the negative front, we prove a Statistical Query (SQ) lower bound showing that
any SQ learner that makes only polynomially-many queries to an SQ oracle for
the $k$-fold composition task distribution must have sample size exponential in
$k$, thus establishing a statistical-computational gap. On the other hand, we
show that this function class can be efficiently learned, with runtime and
sample complexity polynomial in $k$, by gradient descent on an $O(\log
k)$-depth transformer via two different curriculum learning strategies: one in
which data consists of $k'$-fold composition functions with $k' \le k$
presented in increasing difficulty, and another in which all such data is
presented simultaneously. Our work sheds light on the necessity and sufficiency
of having both easy and hard examples in the data distribution for transformers
to learn complex compositional tasks.

</details>


### [154] [Computational Algebra with Attention: Transformer Oracles for Border Basis Algorithms](https://arxiv.org/abs/2505.23696)
*Hiroshi Kera, Nico Pelleriti, Yuki Ishihara, Max Zimmer, Sebastian Pokutta*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为Oracle Border Basis Algorithm的新方法，结合深度学习技术加速了Border basis计算，同时保证了结果的正确性。通过设计基于Transformer的oracle模型，消除昂贵的计算步骤，并引入新的采样定理和tokenization方案，该方法实现了高达3.5倍的速度提升，为传统计算机代数算法提供了实用增强。


<details>
  <summary>更多</summary>
  
**动机:** 求解多项式方程组，特别是有限解的方程组，在许多科学领域中至关重要。然而，传统的Gröbner和Border bases方法计算成本高，而现有的深度学习方法虽然提高了效率，但牺牲了结果的正确性。因此，需要一种既能提高效率又能保证正确性的新方法。

**方法:** 作者提出了Oracle Border Basis Algorithm，其核心是一个基于Transformer的oracle模型，用于识别并消除计算过程中昂贵的约简步骤。此外，作者还开发了一种采样方法和定理，构建了专门针对单项式代数计算的tokenization和embedding方案，从而生成紧凑且富有表现力的输入表示。

**结果:** 相比基础算法，该方法在不损害结果正确性的前提下，实现了高达3.5倍的速度提升。同时，所提出的tokenization方案将编码n元多项式的tokens数量减少了O(n)倍，证明了方法的数据高效性和稳定性。

**结论:** Oracle Border Basis Algorithm是一种实用且高效的增强方法，能够显著加速传统计算机代数算法中的Border basis计算，同时保持结果的正确性，为符号计算领域提供了一个重要的进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computational+Algebra+with+Attention%3A+Transformer+Oracles+for+Border+Basis+Algorithms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23696&send_immediately=true&force_search=false)

**原文摘要:** Solving systems of polynomial equations, particularly those with finitely
many solutions, is a crucial challenge across many scientific fields.
Traditional methods like Gr\"obner and Border bases are fundamental but suffer
from high computational costs, which have motivated recent Deep Learning
approaches to improve efficiency, albeit at the expense of output correctness.
In this work, we introduce the Oracle Border Basis Algorithm, the first Deep
Learning approach that accelerates Border basis computation while maintaining
output guarantees. To this end, we design and train a Transformer-based oracle
that identifies and eliminates computationally expensive reduction steps, which
we find to dominate the algorithm's runtime. By selectively invoking this
oracle during critical phases of computation, we achieve substantial speedup
factors of up to 3.5x compared to the base algorithm, without compromising the
correctness of results. To generate the training data, we develop a sampling
method and provide the first sampling theorem for border bases. We construct a
tokenization and embedding scheme tailored to monomial-centered algebraic
computations, resulting in a compact and expressive input representation, which
reduces the number of tokens to encode an $n$-variate polynomial by a factor of
$O(n)$. Our learning approach is data efficient, stable, and a practical
enhancement to traditional computer algebra algorithms and symbolic
computation.

</details>


### [155] [DiCoFlex: Model-agnostic diverse counterfactuals with flexible control](https://arxiv.org/abs/2505.23700)
*Oleksii Furman, Ulvi Movsum-zada, Patryk Marszalek, Maciej Zięba, Marek Śmieja*

**主要类别:** cs.LG

**概要:** 本文提出了一种名为DiCoFlex的新框架，用于生成反事实解释。该方法无需频繁访问预测模型，通过单一前向传递即可生成多个多样化的反事实，并允许用户在推理时实时自定义约束条件。实验表明，DiCoFlex在有效性、多样性、接近性和约束遵循方面优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前生成反事实解释的方法存在需要频繁访问模型、计算密集以及缺乏对新用户定义约束的灵活性等问题。

**方法:** 提出了DiCoFlex，一种模型无关的条件生成框架，利用仅在标记数据上训练的条件标准化流，在单一前向传递中生成多个多样化的反事实，并允许实时用户驱动的约束定制。

**结果:** 在标准基准数据集上的广泛实验表明，DiCoFlex在有效性、多样性、接近性和约束遵循方面表现优异。

**结论:** DiCoFlex为反事实生成提供了一个实用且可扩展的解决方案，特别适用于敏感决策领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DiCoFlex%3A+Model-agnostic+diverse+counterfactuals+with+flexible+control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23700&send_immediately=true&force_search=false)

**原文摘要:** Counterfactual explanations play a pivotal role in explainable artificial
intelligence (XAI) by offering intuitive, human-understandable alternatives
that elucidate machine learning model decisions. Despite their significance,
existing methods for generating counterfactuals often require constant access
to the predictive model, involve computationally intensive optimization for
each instance and lack the flexibility to adapt to new user-defined constraints
without retraining. In this paper, we propose DiCoFlex, a novel model-agnostic,
conditional generative framework that produces multiple diverse counterfactuals
in a single forward pass. Leveraging conditional normalizing flows trained
solely on labeled data, DiCoFlex addresses key limitations by enabling
real-time user-driven customization of constraints such as sparsity and
actionability at inference time. Extensive experiments on standard benchmark
datasets show that DiCoFlex outperforms existing methods in terms of validity,
diversity, proximity, and constraint adherence, making it a practical and
scalable solution for counterfactual generation in sensitive decision-making
domains.

</details>


### [156] [(U)NFV: Supervised and Unsupervised Neural Finite Volume Methods for Solving Hyperbolic PDEs](https://arxiv.org/abs/2505.23702)
*Nathan Lichtlé, Alexi Canesse, Zhe Fu, Hossein Nick Zinat Matin, Maria Laura Delle Monache, Alexandre M. Bayen*

**主要类别:** cs.LG

**概要:** 提出了一种新的神经网络架构(U)NFV，用于求解双曲守恒律方程，该方法在保持守恒结构的同时提高了准确性和灵活性，并在多个测试中表现优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统的有限体积(FV)方法虽然具有良好的数学特性（如收敛到熵解、流守恒或总变差减少），但在复杂设置下往往缺乏准确性和灵活性。因此需要一种新方法来克服这些限制。

**方法:** 引入了(U)NFV，这是一种模块化的神经网络架构，它推广了经典的有限体积方法。该方法通过学习扩展的空间和时间模板上的更新规则，同时保留守恒结构，支持有监督的训练（基于解数据）和无监督的训练（通过弱形式残差损失）。

**结果:** (U)NFV在求解一阶守恒律时，比Godunov方法误差低10倍，优于ENO/WENO，并且以远低的复杂度媲美不连续Galerkin求解器。在交通建模问题上，无论是基于PDE还是实验高速公路数据，(U)NFV都能显著提高非线性波动力学的捕捉精度和可扩展性。

**结论:** (U)NFV提供了一种改进的数值方法，能够在保持传统FV方法优点的同时，提升复杂场景下的准确性和灵活性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%28U%29NFV%3A+Supervised+and+Unsupervised+Neural+Finite+Volume+Methods+for+Solving+Hyperbolic+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23702&send_immediately=true&force_search=false)

**原文摘要:** We introduce (U)NFV, a modular neural network architecture that generalizes
classical finite volume (FV) methods for solving hyperbolic conservation laws.
Hyperbolic partial differential equations (PDEs) are challenging to solve,
particularly conservation laws whose physically relevant solutions contain
shocks and discontinuities. FV methods are widely used for their mathematical
properties: convergence to entropy solutions, flow conservation, or total
variation diminishing, but often lack accuracy and flexibility in complex
settings. Neural Finite Volume addresses these limitations by learning update
rules over extended spatial and temporal stencils while preserving conservation
structure. It supports both supervised training on solution data (NFV) and
unsupervised training via weak-form residual loss (UNFV). Applied to
first-order conservation laws, (U)NFV achieves up to 10x lower error than
Godunov's method, outperforms ENO/WENO, and rivals discontinuous Galerkin
solvers with far less complexity. On traffic modeling problems, both from PDEs
and from experimental highway data, (U)NFV captures nonlinear wave dynamics
with significantly higher fidelity and scalability than traditional FV
approaches.

</details>


### [157] [Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better](https://arxiv.org/abs/2505.23705)
*Danny Driess, Jost Tobias Springenberg, Brian Ichter, Lili Yu, Adrian Li-Bell, Karl Pertsch, Allen Z. Ren, Homer Walke, Quan Vuong, Lucy Xiaoyang Shi, Sergey Levine*

**主要类别:** cs.LG

**概要:** Vision-language-action (VLA)模型结合了端到端学习与从大规模视觉语言模型（VLM）中转移的语义知识，用于物理系统（如机器人）的控制策略训练。然而，强大的VLM存在实时推理障碍且其离散输出不适合机器人控制。本文研究了在VLA中包含连续扩散或流匹配动作专家的影响，发现简单加入这些模块会显著损害训练速度和知识迁移，并提出了一种在VLA训练期间保护VLM骨干的技术。


<details>
  <summary>更多</summary>
  
**动机:** 现有的VLA模型虽然通过专门模块（如动作专家或连续输出头）提升了实时性和控制能力，但这些模块对预训练VLM中的语义知识是保留还是损害尚不明确，这影响了VLA的训练动态。

**方法:** 研究分析了不同设计选择对性能和知识迁移的影响，并提出了一种在VLA训练期间保护VLM骨干的技术，以减轻不良影响。

**结果:** 研究表明，简单地加入连续扩散或流匹配动作专家会显著损害训练速度和知识迁移。提出的保护技术可以缓解这一问题。

**结论:** 需要谨慎设计VLA模型中的模块，以避免损害预训练VLM的知识，并提高训练效率和知识迁移效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Knowledge+Insulating+Vision-Language-Action+Models%3A+Train+Fast%2C+Run+Fast%2C+Generalize+Better，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23705&send_immediately=true&force_search=false)

**原文摘要:** Vision-language-action (VLA) models provide a powerful approach to training
control policies for physical systems, such as robots, by combining end-to-end
learning with transfer of semantic knowledge from web-scale vision-language
model (VLM) training. However, the constraints of real-time control are often
at odds with the design of VLMs: the most powerful VLMs have tens or hundreds
of billions of parameters, presenting an obstacle to real-time inference, and
operate on discrete tokens rather than the continuous-valued outputs that are
required for controlling robots. To address this challenge, recent VLA models
have used specialized modules for efficient continuous control, such as action
experts or continuous output heads, which typically require adding new
untrained parameters to the pretrained VLM backbone. While these modules
improve real-time and control capabilities, it remains an open question whether
they preserve or degrade the semantic knowledge contained in the pretrained
VLM, and what effect they have on the VLA training dynamics. In this paper, we
study this question in the context of VLAs that include a continuous diffusion
or flow matching action expert, showing that naively including such experts
significantly harms both training speed and knowledge transfer. We provide an
extensive analysis of various design choices, their impact on performance and
knowledge transfer, and propose a technique for insulating the VLM backbone
during VLA training that mitigates this issue. Videos are available at
https://pi.website/research/knowledge_insulation.

</details>


### [158] [TiRex: Zero-Shot Forecasting Across Long and Short Horizons with Enhanced In-Context Learning](https://arxiv.org/abs/2505.23719)
*Andreas Auer, Patrick Podest, Daniel Klotz, Sebastian Böck, Günter Klambauer, Sepp Hochreiter*

**主要类别:** cs.LG

**概要:** TiRex，一种基于增强型LSTM（xLSTM）的模型，在零样本时间序列预测中表现出色，超越了包括Transformer在内的多种现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 当前的时间序列零样本预测方法大多依赖于Transformer架构，虽然在语言任务上表现良好，但在时间序列预测方面往往不如LSTM等循环模型。然而，LSTM缺乏强大的情境学习能力，因此需要一种结合两者优势的新方法。

**方法:** 提出了一种名为TiRex的模型，它利用增强型LSTM（xLSTM）来提升情境学习能力，并保留了状态追踪特性以适应长期预测需求。同时引入了训练时的掩码策略CPM，进一步增强了其状态追踪能力。

**结果:** TiRex在HuggingFace的GiftEval和Chronos-ZS基准测试中树立了新的零样本时间序列预测标准，显著优于多个大型模型，如TabPFN-TS、Chronos Bolt、TimesFM和Moirai等，在短期和长期预测中均表现优异。

**结论:** TiRex通过结合xLSTM和CPM策略，成功弥补了现有方法的不足，在零样本时间序列预测领域达到了最先进的水平。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TiRex%3A+Zero-Shot+Forecasting+Across+Long+and+Short+Horizons+with+Enhanced+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23719，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23719&send_immediately=true&force_search=false)

**原文摘要:** In-context learning, the ability of large language models to perform tasks
using only examples provided in the prompt, has recently been adapted for time
series forecasting. This paradigm enables zero-shot prediction, where past
values serve as context for forecasting future values, making powerful
forecasting tools accessible to non-experts and increasing the performance when
training data are scarce. Most existing zero-shot forecasting approaches rely
on transformer architectures, which, despite their success in language, often
fall short of expectations in time series forecasting, where recurrent models
like LSTMs frequently have the edge. Conversely, while LSTMs are well-suited
for time series modeling due to their state-tracking capabilities, they lack
strong in-context learning abilities. We introduce TiRex that closes this gap
by leveraging xLSTM, an enhanced LSTM with competitive in-context learning
skills. Unlike transformers, state-space models, or parallelizable RNNs such as
RWKV, TiRex retains state-tracking, a critical property for long-horizon
forecasting. To further facilitate its state-tracking ability, we propose a
training-time masking strategy called CPM. TiRex sets a new state of the art in
zero-shot time series forecasting on the HuggingFace benchmarks GiftEval and
Chronos-ZS, outperforming significantly larger models including TabPFN-TS
(Prior Labs), Chronos Bolt (Amazon), TimesFM (Google), and Moirai (Salesforce)
across both short- and long-term forecasts.

</details>


### [159] [DiffER: Categorical Diffusion for Chemical Retrosynthesis](https://arxiv.org/abs/2505.23721)
*Sean Current, Ziqi Chen, Daniel Adu-Ampratwum, Xia Ning, Srinivasan Parthasarathy*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为DiffER的新方法，使用分类扩散模型进行无模板的逆合成预测。该方法通过整体预测输出SMILES序列，构建了具有新型长度预测组件的扩散模型集合，实现了SOTA的top-1准确率，并在top-3、top-5和top-10准确率中表现出竞争力。研究表明，准确预测SMILES序列长度对提升模型性能至关重要。


<details>
  <summary>更多</summary>
  
**动机:** 当前用于自动化学逆合成的方法主要基于自然语言处理模型（如Transformer），这些模型在产物和反应物之间的SMILES编码转换方面表现出色，但因自回归特性受到限制。因此，需要一种新方法来克服这一局限性。

**方法:** 提出DiffER方法，采用分类扩散模型进行无模板的逆合成预测。通过构建扩散模型集合，并引入具有方差的新型长度预测组件，使模型能够从反应物的后验分布中采样。整个输出SMILES序列可以同时预测。

**结果:** DiffER在top-1准确率上达到SOTA水平，在top-3、top-5和top-10准确率上表现具有竞争力。此外，分析表明，准确预测SMILES序列长度是提高分类扩散模型性能的关键因素。

**结论:** DiffER作为一种强大的基线方法，代表了一类新的无模板模型，能够学习实验室中使用的多种合成技术，并在top-k准确率指标上优于其他无模板方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DiffER%3A+Categorical+Diffusion+for+Chemical+Retrosynthesis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23721，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23721&send_immediately=true&force_search=false)

**原文摘要:** Methods for automatic chemical retrosynthesis have found recent success
through the application of models traditionally built for natural language
processing, primarily through transformer neural networks. These models have
demonstrated significant ability to translate between the SMILES encodings of
chemical products and reactants, but are constrained as a result of their
autoregressive nature. We propose DiffER, an alternative template-free method
for retrosynthesis prediction in the form of categorical diffusion, which
allows the entire output SMILES sequence to be predicted in unison. We
construct an ensemble of diffusion models which achieves state-of-the-art
performance for top-1 accuracy and competitive performance for top-3, top-5,
and top-10 accuracy among template-free methods. We prove that DiffER is a
strong baseline for a new class of template-free model, capable of learning a
variety of synthetic techniques used in laboratory settings and outperforming a
variety of other template-free methods on top-k accuracy metrics. By
constructing an ensemble of categorical diffusion models with a novel length
prediction component with variance, our method is able to approximately sample
from the posterior distribution of reactants, producing results with strong
metrics of confidence and likelihood. Furthermore, our analyses demonstrate
that accurate prediction of the SMILES sequence length is key to further
boosting the performance of categorical diffusion models.

</details>


### [160] [MuLoCo: Muon is a practical inner optimizer for DiLoCo](https://arxiv.org/abs/2505.23725)
*Benjamin Thérien, Xiaolong Huang, Irina Rish, Eugene Belilovsky*

**主要类别:** cs.LG

**概要:** DiLoCo是一个强大的框架，用于在网络约束下训练大语言模型（LLMs），具有提高数据中心设置中的并行性和加速器利用率的优势。尽管显著减少了通信频率，但DiLoCo的通信步骤仍然涉及对模型参数的完整副本进行全归约。本文研究了标准压缩方法（如Top-k稀疏化和量化）在与两个本地优化器（AdamW和Muon）结合时减少DiLoCo通信开销的有效性。实验表明，使用Muon作为DiLoCo的内部优化器，并结合误差反馈累加器，可以将通信delta压缩到2位，几乎没有性能下降。重要的是，MuLoCo（使用Muon作为内部优化器的DiLoCo）在通信量减少8倍的情况下显著优于DiLoCo，且具有相同的内存复杂度。


<details>
  <summary>更多</summary>
  
**动机:** 尽管DiLoCo框架已经显著减少了通信频率，但其通信步骤仍涉及对模型参数的完整副本进行全归约，导致较高的通信开销。现有的工作虽然探索了减少DiLoCo通信的方法，但误差反馈累加器的作用和内部优化器对可压缩性的影响尚未被充分研究。因此，本文旨在研究标准压缩方法在减少DiLoCo通信开销方面的有效性。

**方法:** 本文通过预训练仅解码器的Transformer语言模型（LMs），研究了两种本地优化器（AdamW和Muon）与标准压缩方法（Top-k稀疏化和量化）结合时的表现。实验中，使用了误差反馈累加器来评估压缩效果。

**结果:** 实验结果表明，使用Muon作为内部优化器，并结合误差反馈累加器，可以将通信delta压缩至2位，同时几乎不降低性能。此外，MuLoCo（使用Muon作为内部优化器的DiLoCo）在通信量减少8倍的情况下显著优于DiLoCo，且具有相同的内存复杂度。

**结论:** 标准压缩方法（如Top-k稀疏化和量化）与适当的本地优化器（如Muon）结合，可以在减少DiLoCo通信开销方面取得显著效果。使用Muon作为内部优化器的MuLoCo不仅显著减少了通信量，还保持了与DiLoCo相同的内存复杂度，同时提升了性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MuLoCo%3A+Muon+is+a+practical+inner+optimizer+for+DiLoCo，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23725&send_immediately=true&force_search=false)

**原文摘要:** DiLoCo is a powerful framework for training large language models (LLMs)
under networking constraints with advantages for increasing parallelism and
accelerator utilization in data center settings. Despite significantly reducing
communication frequency, however, DiLoCo's communication steps still involve
all-reducing a complete copy of the model's parameters. While existing works
have explored ways to reduce communication in DiLoCo, the role of error
feedback accumulators and the effect of the inner-optimizer on compressibility
remain under-explored. In this work, we investigate the effectiveness of
standard compression methods including Top-k sparsification and quantization
for reducing the communication overhead of DiLoCo when paired with two local
optimizers (AdamW and Muon). Our experiments pre-training decoder-only
transformer language models (LMs) reveal that leveraging Muon as the inner
optimizer for DiLoCo along with an error-feedback accumulator allows to
aggressively compress the communicated delta to 2-bits with next to no
performance degradation. Crucially, MuLoCo (Muon inner optimizer DiLoCo)
significantly outperforms DiLoCo while communicating 8X less and having
identical memory complexity.

</details>


### [161] [EmotionRankCLAP: Bridging Natural Language Speaking Styles and Ordinal Speech Emotion via Rank-N-Contrast](https://arxiv.org/abs/2505.23732)
*Shreeram Suresh Chandra, Lucas Goncalves, Junchen Lu, Carlos Busso, Berrak Sisman*

**主要类别:** cs.LG

**概要:** 当前基于情感的对比语言-音频预训练（CLAP）方法通常通过简单对齐音频样本与对应文本提示进行学习，这无法捕捉情感的序性质，导致模态间差距大。为了解决这些问题，本文提出了EmotionRankCLAP，一种监督对比学习方法，利用情感语音和自然语言提示的维度属性来共同捕捉精细的情感变化并改善跨模态对齐。该方法使用Rank-N-Contrast目标函数通过在价-唤醒空间中的排名对比样本来学习有序关系，在跨模态检索任务中表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前的CLAP方法无法有效捕捉情感的序性质，导致模态间对齐不足，影响了跨模态理解。

**方法:** 提出了一种名为EmotionRankCLAP的监督对比学习方法，利用情感语音和自然语言提示的维度属性来共同捕捉精细的情感变化，并通过Rank-N-Contrast目标函数学习有序关系。

**结果:** EmotionRankCLAP在建模跨模态情感序性质方面优于现有的CLAP方法，特别是在跨模态检索任务中表现出色。

**结论:** EmotionRankCLAP能够更好地捕捉情感的序性质，提升跨模态对齐效果，是一种有效的改进CLAP方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EmotionRankCLAP%3A+Bridging+Natural+Language+Speaking+Styles+and+Ordinal+Speech+Emotion+via+Rank-N-Contrast，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23732，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23732&send_immediately=true&force_search=false)

**原文摘要:** Current emotion-based contrastive language-audio pretraining (CLAP) methods
typically learn by na\"ively aligning audio samples with corresponding text
prompts. Consequently, this approach fails to capture the ordinal nature of
emotions, hindering inter-emotion understanding and often resulting in a wide
modality gap between the audio and text embeddings due to insufficient
alignment. To handle these drawbacks, we introduce EmotionRankCLAP, a
supervised contrastive learning approach that uses dimensional attributes of
emotional speech and natural language prompts to jointly capture fine-grained
emotion variations and improve cross-modal alignment. Our approach utilizes a
Rank-N-Contrast objective to learn ordered relationships by contrasting samples
based on their rankings in the valence-arousal space. EmotionRankCLAP
outperforms existing emotion-CLAP methods in modeling emotion ordinality across
modalities, measured via a cross-modal retrieval task.

</details>


### [162] [Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?](https://arxiv.org/abs/2505.23749)
*Paul Gölz, Nika Haghtalab, Kunhe Yang*

**主要类别:** cs.LG

**概要:** 大型语言模型在预训练后，通过两两比较与人类偏好对齐。现有的对齐方法可能无法满足用户多样化的需求。本文通过社会选择理论和Bradley-Terry模型引入了对齐方法的失真概念，并分析了几种方法的失真程度。


<details>
  <summary>更多</summary>
  
**动机:** 当前最先进的对齐方法（如基于PPO的RLHF和DPO）假设只与单一的偏好模型对齐，但实际应用场景中用户的偏好是多样的，这些方法可能无法满足用户的平均需求。

**方法:** 通过社会选择理论和Bradley-Terry模型来模拟用户的比较行为，定义了一个对齐方法的失真概念：即最优可实现的平均效用与所学策略的平均效用之间的最差比率。并以此对比了不同对齐方法的失真程度。

**结果:** Nash Learning from Human Feedback在各种效用分布、比较对分布和允许的KL散度下实现了最小最大最优失真；而RLHF和DPO在无KL约束时已经遭受较大的失真，在完整设置下失真可能更大。

**结论:** 不同的对齐方法在处理用户多样化偏好时表现差异显著，Nash Learning from Human Feedback表现更优，具有较低的失真度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distortion+of+AI+Alignment%3A+Does+Preference+Optimization+Optimize+for+Preferences%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23749，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23749&send_immediately=true&force_search=false)

**原文摘要:** After pre-training, large language models are aligned with human preferences
based on pairwise comparisons. State-of-the-art alignment methods (such as
PPO-based RLHF and DPO) are built on the assumption of aligning with a single
preference model, despite being deployed in settings where users have diverse
preferences. As a result, it is not even clear that these alignment methods
produce models that satisfy users on average -- a minimal requirement for
pluralistic alignment. Drawing on social choice theory and modeling users'
comparisons through individual Bradley-Terry (BT) models, we introduce an
alignment method's distortion: the worst-case ratio between the optimal
achievable average utility, and the average utility of the learned policy.
  The notion of distortion helps draw sharp distinctions between alignment
methods: Nash Learning from Human Feedback achieves the minimax optimal
distortion of $(\frac{1}{2} + o(1)) \cdot \beta$ (for the BT temperature
$\beta$), robustly across utility distributions, distributions of comparison
pairs, and permissible KL divergences from the reference policy. RLHF and DPO,
by contrast, suffer $\geq (1 - o(1)) \cdot \beta$ distortion already without a
KL constraint, and $e^{\Omega(\beta)}$ or even unbounded distortion in the full
setting, depending on how comparison pairs are sampled.

</details>


### [163] [Model Immunization from a Condition Number Perspective](https://arxiv.org/abs/2505.23760)
*Amber Yijia Zheng, Cedar Site Bai, Brian Bullins, Raymond A. Yeh*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种基于Hessian矩阵条件数的框架来分析线性模型的模型免疫，并设计了一个带有正则化项的算法来控制预训练后的条件数。实验结果证明了该算法在模型免疫上的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前的研究已经展示了文本到图像模型免疫的实证证据，但关于模型免疫的可能性和免疫模型的精确定义仍不清楚。

**方法:** 作者提出了一个基于Hessian矩阵条件数的框架来分析线性模型的模型免疫，并设计了一个包含正则化项的算法，用以控制预训练后产生的条件数。

**结果:** 通过在线性和非线性深度网络模型上的实证研究，证明了所提出的算法在模型免疫方面的有效性。

**结论:** 本文提出的基于条件数的框架和算法为理解及实现模型免疫提供了新的视角，并在不同类型的模型上验证了其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model+Immunization+from+a+Condition+Number+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23760，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23760&send_immediately=true&force_search=false)

**原文摘要:** Model immunization aims to pre-train models that are difficult to fine-tune
on harmful tasks while retaining their utility on other non-harmful tasks.
Though prior work has shown empirical evidence for immunizing text-to-image
models, the key understanding of when immunization is possible and a precise
definition of an immunized model remain unclear. In this work, we propose a
framework, based on the condition number of a Hessian matrix, to analyze model
immunization for linear models. Building on this framework, we design an
algorithm with regularization terms to control the resulting condition numbers
after pre-training. Empirical results on linear models and non-linear deep-nets
demonstrate the effectiveness of the proposed algorithm on model immunization.
The code is available at
https://github.com/amberyzheng/model-immunization-cond-num.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [164] [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org/abs/2505.22698)
*Luca Fantin, Marco Antonelli, Margherita Cesetti, Daniele Irto, Bruno Zamengo, Francesco Silvestri*

**主要类别:** cs.AI

**概要:** 本文提出了一种基于代理架构的聊天机器人，用于简化公共交通服务质量评估中的复杂数据操作，并通过一系列工具支持决策制定。同时，文章还探讨了如何收集数据以衡量系统的性能，确保生成查询的正确性和答案的一致性。


<details>
  <summary>更多</summary>
  
**动机:** 评估公共交通服务质量需要分析大量计划和实际行程数据及质量约束文档，而使用SQL查询、组织和可视化这些数据对大多数用户来说过于复杂。因此，需要一种更友好的交互方式来处理这些数据并支持决策。

**方法:** 论文介绍了一种基于代理架构的聊天机器人，增强了核心大型语言模型（LLM）的功能，使其能够与执行多种任务的工具进行交互，例如执行SQL查询、绘制数据图表和根据行程及其停靠点的坐标创建地图。此外，通过设计一个工作流来测试聊天机器人，该工作流会提出多个问题并存储生成的查询、检索到的数据以及自然语言响应，从而形成一个用于评估聊天机器人性能的数据集。

**结果:** 聊天机器人可以有效地简化用户与复杂公共交通数据集之间的交互过程，并支持决策制定。通过测试工作流，研究人员成功收集了用于评估聊天机器人性能的数据集，特别是其答案的一致性和生成查询的正确性。

**结论:** 聊天机器人提供了一种友好的工具，用于简化公共交通服务质量评估中的复杂数据操作。同时，论文提出的方法解决了生成式AI项目中系统性能测量数据收集的问题，为未来类似项目提供了参考。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Design+and+testing+of+an+agent+chatbot+supporting+decision+making+with+public+transport+data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22698，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22698&send_immediately=true&force_search=false)

**原文摘要:** Assessing the quality of public transportation services requires the analysis
of large quantities of data on the scheduled and actual trips and documents
listing the quality constraints each service needs to meet. Interrogating such
datasets with SQL queries, organizing and visualizing the data can be quite
complex for most users. This paper presents a chatbot offering a user-friendly
tool to interact with these datasets and support decision making. It is based
on an agent architecture, which expands the capabilities of the core Large
Language Model (LLM) by allowing it to interact with a series of tools that can
execute several tasks, like performing SQL queries, plotting data and creating
maps from the coordinates of a trip and its stops. This paper also tackles one
of the main open problems of such Generative AI projects: collecting data to
measure the system's performance. Our chatbot has been extensively tested with
a workflow that asks several questions and stores the generated query, the
retrieved data and the natural language response for each of them. Such
questions are drawn from a set of base examples which are then completed with
actual data from the database. This procedure yields a dataset for the
evaluation of the chatbot's performance, especially the consistency of its
answers and the correctness of the generated queries.

</details>


### [165] [Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields](https://arxiv.org/abs/2505.22753)
*Arseniy Pertzovsky, Roni Stern, Ariel Felner, Roie Zivan*

**主要类别:** cs.AI

**概要:** 研究了在多智能体路径规划（MAPF）和终身多智能体路径规划（LMAPF）问题中使用人工势场（APFs）。对于MAPF，团队中的每个智能体必须无碰撞地移动到其目标位置；而对于LMAPF，在到达后会产生新的目标。本文提出将APFs整合到一系列MAPF算法中的方法，包括优先级规划、MAPF-LNS2和具有回溯功能的优先级继承（PIBT）。实验结果表明，使用APF对MAPF没有好处，但可以使LMAPF的整体系统吞吐量提高多达7倍。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决多智能体路径规划问题以及更复杂的终身路径规划问题，探索人工势场在这些场景下的适用性和性能提升潜力。

**方法:** 将人工势场（APFs）融入多种MAPF算法中，包括优先级规划、MAPF-LNS2和优先级继承带回溯（PIBT），以评估其在不同路径规划场景中的表现。

**结果:** 实验表明，对于标准的MAPF问题，使用APF并没有带来优势；然而，在LMAPF问题中，使用APF使整体系统吞吐量提升了高达7倍。

**结论:** 人工势场在终身多智能体路径规划问题中表现出显著优势，但在标准多智能体路径规划问题中效果不明显。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Lifelong+Multi-Agent+Path-finding+by+Using+Artificial+Potential+Fields，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22753，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22753&send_immediately=true&force_search=false)

**原文摘要:** We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent
Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of
agents must move to their goal locations without collisions, whereas in LMAPF,
new goals are generated upon arrival. We propose methods for incorporating APFs
in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and
Priority Inheritance with Backtracking (PIBT). Experimental results show that
using APF is not beneficial for MAPF but yields up to a 7-fold increase in
overall system throughput for LMAPF.

</details>


### [166] [Decomposing Elements of Problem Solving: What "Math" Does RL Teach?](https://arxiv.org/abs/2505.22756)
*Tian Qin, Core Francisco Park, Mujin Kwun, Aaron Walsman, Eran Malach, Nikhil Anand, Hidenori Tanaka, David Alvarez-Melis*

**主要类别:** cs.AI

**概要:** 数学推理任务是评估大型语言模型（LLM）推理能力的重要基准，特别是使用强化学习（RL）方法如GRPO表现出显著性能提升。然而，仅靠准确率指标无法细致评估其能力，也无法揭示哪些问题解决技能已被内化。我们提出将问题解决分解为基本能力：计划（将问题映射到步骤序列）、执行（正确执行解决方案步骤）和验证（识别解决方案的正确性）。实验发现，GRPO主要增强执行技能，在模型已知如何解决的问题上提高执行稳健性，称为温度蒸馏现象。更重要的是，RL训练的模型在根本性新问题上遇到'覆盖墙'，由于规划技能不足。通过构建一个最小合成的解决方案树导航任务，我们复制了实证结果，确认RL主要提高执行稳健性。在此设置下，我们确定了RL通过改进探索和泛化到新解决方案路径来克服覆盖墙的条件。我们的研究提供了对RL增强LLM推理作用的见解，暴露了关键限制，并指出了克服这些障碍的途径。


<details>
  <summary>更多</summary>
  
**动机:** 当前仅依赖准确率指标无法细致评估LLM的推理能力，且无法揭示哪些问题解决技能已被内化。因此，需要更细粒度地理解这些模型的能力。

**方法:** 提出将问题解决分解为三个基本能力：Plan（计划）、Execute（执行）和Verify（验证）。通过实证研究分析GRPO等RL方法对这些能力的影响。构建了一个最小合成的解决方案树导航任务，以类比数学问题解决过程，深入探讨RL的影响。

**结果:** 1. GRPO主要增强了执行技能，在模型已知如何解决的问题上提高了执行稳健性（温度蒸馏现象）。2. RL训练的模型在根本性新问题上遇到'覆盖墙'，由于规划技能不足。3. 在合成任务中，确认RL主要提高执行稳健性，并确定了RL通过改进探索和泛化克服覆盖墙的条件。

**结论:** RL在增强LLM推理方面有重要作用，但存在关键限制，特别是在规划技能上的不足导致难以解决根本性新问题。研究提出了克服这些障碍的潜在路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decomposing+Elements+of+Problem+Solving%3A+What+%22Math%22+Does+RL+Teach%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22756，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22756&send_immediately=true&force_search=false)

**原文摘要:** Mathematical reasoning tasks have become prominent benchmarks for assessing
the reasoning capabilities of LLMs, especially with reinforcement learning (RL)
methods such as GRPO showing significant performance gains. However, accuracy
metrics alone do not support fine-grained assessment of capabilities and fail
to reveal which problem-solving skills have been internalized. To better
understand these capabilities, we propose to decompose problem solving into
fundamental capabilities: Plan (mapping questions to sequences of steps),
Execute (correctly performing solution steps), and Verify (identifying the
correctness of a solution). Empirically, we find that GRPO mainly enhances the
execution skill-improving execution robustness on problems the model already
knows how to solve-a phenomenon we call temperature distillation. More
importantly, we show that RL-trained models struggle with fundamentally new
problems, hitting a 'coverage wall' due to insufficient planning skills. To
explore RL's impact more deeply, we construct a minimal, synthetic
solution-tree navigation task as an analogy for mathematical problem-solving.
This controlled setup replicates our empirical findings, confirming RL
primarily boosts execution robustness. Importantly, in this setting, we
identify conditions under which RL can potentially overcome the coverage wall
through improved exploration and generalization to new solution paths. Our
findings provide insights into the role of RL in enhancing LLM reasoning,
expose key limitations, and suggest a path toward overcoming these barriers.
Code is available at https://github.com/cfpark00/RL-Wall.

</details>


### [167] [Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds](https://arxiv.org/abs/2505.22779)
*Mohammad Helal Uddin, Sabur Baidya*

**主要类别:** cs.AI

**概要:** 论文提出了一种结合智能手机传感器数据和社交媒体分析的混合方法来评估个人抑郁水平，通过深度学习和分类算法实现了高准确率的活动识别与情感分析，并利用支持向量机进行抑郁程度分类。


<details>
  <summary>更多</summary>
  
**动机:** 精神障碍（如抑郁症、焦虑症等）在全球范围内构成了重大挑战，特别是在表现出社交回避倾向的个体中。因此，需要一种非侵入性的方式来监测和评估抑郁水平。

**方法:** 使用基于CNN的深度学习模型和朴素贝叶斯分类来识别物理活动并分类用户情感；从33名参与者获取数据，提取9个相关特征并与每周抑郁评分进行关联分析；采用支持向量机算法对抑郁严重程度进行分类。

**结果:** 物理活动识别准确率为95%，情感分析准确率为95.6%；多个物理活动特征与抑郁症状的严重程度显著相关；支持向量机在抑郁严重程度分类上的准确率达到94%，优于其他模型。

**结论:** 该方法简单且有效，能够在不侵犯个人隐私的情况下长期用于抑郁监测。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predicting+Human+Depression+with+Hybrid+Data+Acquisition+utilizing+Physical+Activity+Sensing+and+Social+Media+Feeds，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22779，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22779&send_immediately=true&force_search=false)

**原文摘要:** Mental disorders including depression, anxiety, and other neurological
disorders pose a significant global challenge, particularly among individuals
exhibiting social avoidance tendencies. This study proposes a hybrid approach
by leveraging smartphone sensor data measuring daily physical activities and
analyzing their social media (Twitter) interactions for evaluating an
individual's depression level. Using CNN-based deep learning models and Naive
Bayes classification, we identify human physical activities accurately and also
classify the user sentiments. A total of 33 participants were recruited for
data acquisition, and nine relevant features were extracted from the physical
activities and analyzed with their weekly depression scores, evaluated using
the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six
are derived from physical activities, achieving an activity recognition
accuracy of 95%, while three features stem from sentiment analysis of Twitter
activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several
physical activity features exhibited significant correlations with the severity
of depression symptoms. For classifying the depression severity, a support
vector machine (SVM)-based algorithm is employed that demonstrated a very high
accuracy of 94%, outperforming alternative models, e.g., the multilayer
perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly
effective in the long run for monitoring depression without breaching personal
privacy.

</details>


### [168] [The WHY in Business Processes: Unification of Causal Process Models](https://arxiv.org/abs/2505.22871)
*Yuval David, Fabiana Fournier, Lior Limonad, Inna Skarbovsky*

**主要类别:** cs.AI

**概要:** 论文提出了一种新方法，将多个因果流程变体统一到一个一致的模型中，该模型保留了原始因果模型的正确性，并明确表示其因果流的变化。此方法已正式定义、证明，并在三个公开和两个专有数据集上进行了评估，同时作为开源实现发布。


<details>
  <summary>更多</summary>
  
**动机:** 当前发现因果流程模型的方法无法捕捉跨多个变体的交替因果条件，处理日志分割中的缺失值和表达交替条件存在挑战。

**方法:** 提出了一种新方法，将多个因果流程变体统一到一个一致的模型中，明确表示因果流的变化，同时保留原始因果模型的正确性。

**结果:** 该方法被正式定义、证明，并在三个公开和两个专有数据集上进行了成功评估。

**结论:** 所提出的方法能够有效地解决现有方法在捕捉交替因果条件方面的不足，为因果推理和业务流程改进提供了更好的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+WHY+in+Business+Processes%3A+Unification+of+Causal+Process+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22871，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22871&send_immediately=true&force_search=false)

**原文摘要:** Causal reasoning is essential for business process interventions and
improvement, requiring a clear understanding of causal relationships among
activity execution times in an event log. Recent work introduced a method for
discovering causal process models but lacked the ability to capture alternating
causal conditions across multiple variants. This raises the challenges of
handling missing values and expressing the alternating conditions among log
splits when blending traces with varying activities.
  We propose a novel method to unify multiple causal process variants into a
consistent model that preserves the correctness of the original causal models,
while explicitly representing their causal-flow alternations. The method is
formally defined, proved, evaluated on three open and two proprietary datasets,
and released as an open-source implementation.

</details>


### [169] [Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning](https://arxiv.org/abs/2505.22928)
*Massimiliano Pronesti, Michela Lorandi, Paul Flanagan, Oisin Redmon, Anya Belz, Yufang Hou*

**主要类别:** cs.AI

**概要:** 本论文提出了一种基于数值推理的系统，用于从文本中提取结构化数值证据，并通过领域知识逻辑推导出特定结果的结论。该系统由数值数据提取模型和效应估计组件组成，使用强化学习训练的小规模数值提取模型在CochraneForest基准上表现出色，相较于检索基系统F1分数绝对提高了21%，并超越了具有400亿参数的通用大型语言模型9%。


<details>
  <summary>更多</summary>
  
**动机:** 目前的系统性综述自动化过程存在瓶颈，主要在于从文本中提取数值证据以及确定研究级别的结论时，往往依赖于浅层文本线索，未能捕捉专家评估背后的数值推理。因此需要一种更精确、可解释的方法来解决这一问题。

**方法:** 将问题定义为定量推理任务，构建一个数值推理系统，包含数值数据提取模型和效应估计组件。使用监督微调（SFT）和强化学习（RL）等策略训练数值数据提取模型，利用新的价值奖励模型进行强化学习。

**结果:** 在CochraneForest基准上的实验表明，使用强化学习训练的小规模数值提取模型相较于检索基系统F1分数绝对提高了21%，并且优于超过400亿参数的通用大型语言模型9%。

**结论:** 基于推理驱动的方法在自动化系统性证据综合方面展现出巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Study-Level+Inference+from+Clinical+Trial+Papers+via+RL-based+Numeric+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22928，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22928&send_immediately=true&force_search=false)

**原文摘要:** Systematic reviews in medicine play a critical role in evidence-based
decision-making by aggregating findings from multiple studies. A central
bottleneck in automating this process is extracting numeric evidence and
determining study-level conclusions for specific outcomes and comparisons.
Prior work has framed this problem as a textual inference task by retrieving
relevant content fragments and inferring conclusions from them. However, such
approaches often rely on shallow textual cues and fail to capture the
underlying numeric reasoning behind expert assessments.
  In this work, we conceptualise the problem as one of quantitative reasoning.
Rather than inferring conclusions from surface text, we extract structured
numerical evidence (e.g., event counts or standard deviations) and apply domain
knowledge informed logic to derive outcome-specific conclusions. We develop a
numeric reasoning system composed of a numeric data extraction model and an
effect estimate component, enabling more accurate and interpretable inference
aligned with the domain expert principles. We train the numeric data extraction
model using different strategies, including supervised fine-tuning (SFT) and
reinforcement learning (RL) with a new value reward model.
  When evaluated on the CochraneForest benchmark, our best-performing approach
-- using RL to train a small-scale number extraction model -- yields up to a
21% absolute improvement in F1 score over retrieval-based systems and
outperforms general-purpose LLMs of over 400B parameters by up to 9%. Our
results demonstrate the promise of reasoning-driven approaches for automating
systematic evidence synthesis.

</details>


### [170] [Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages](https://arxiv.org/abs/2505.22948)
*Michael Sun, Weize Yuan, Gang Liu, Wojciech Matusik, Jie Chen*

**主要类别:** cs.AI

**概要:** 提出了一种新的方法FMG，可以替代传统的基于语法学习的分子生成方法，具有更高的可解释性、合成可行性、多样性和数据效率。


<details>
  <summary>更多</summary>
  
**动机:** 当前的数据高效分子生成方法利用图语法引入可解释性，但语法学习依赖于专家注释或不可靠的算法推断启发式方法。

**方法:** 提出了基础分子语法（FMG），利用多模态基础模型（MMFMs）诱导可解释的分子语言，通过提示学习跨模态对齐信息，将分子渲染为图像并以文本描述。

**结果:** FMG在合成可行性、多样性和数据效率方面表现出色，并为自动分子发现工作流程提供内置的化学可解释性。

**结论:** FMG可以作为分子生成和性质预测中先前语法学习方法的直接替代品。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Foundation+Molecular+Grammar%3A+Multi-Modal+Foundation+Models+Induce+Interpretable+Molecular+Graph+Languages，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22948&send_immediately=true&force_search=false)

**原文摘要:** Recent data-efficient molecular generation approaches exploit graph grammars
to introduce interpretability into the generative models. However, grammar
learning therein relies on expert annotation or unreliable heuristics for
algorithmic inference. We propose Foundation Molecular Grammar (FMG), which
leverages multi-modal foundation models (MMFMs) to induce an interpretable
molecular language. By exploiting the chemical knowledge of an MMFM, FMG
renders molecules as images, describes them as text, and aligns information
across modalities using prompt learning. FMG can be used as a drop-in
replacement for the prior grammar learning approaches in molecular generation
and property prediction. We show that FMG not only excels in synthesizability,
diversity, and data efficiency but also offers built-in chemical
interpretability for automated molecular discovery workflows. Code is available
at https://github.com/shiningsunnyday/induction.

</details>


### [171] [Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954)
*Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune*

**主要类别:** cs.AI

**概要:** 引入了达尔文哥德尔机(DGM)，一种自我改进的系统，通过迭代修改自身代码并使用编码基准来验证每个更改。DGM受到达尔文进化论的启发，维护生成的编码代理档案，形成不断增长的高质量代理树，从而自动提高其编码能力。实验表明DGM在SWE-bench和Polyglot基准上显著提高了性能，并优于没有自我改进或开放探索的基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI系统具有人类设计的固定架构，无法自主连续改进。自动化AI进步可以加速AI发展并让我们更早受益。尽管元学习可以自动化发现新算法，但受限于一阶改进和人为设计的合适搜索空间。哥德尔机提出了一个理论替代方案，但证明大多数更改是有益的是不切实际的。

**方法:** DGM通过从存档中采样代理并使用基础模型创建新的、有趣的代理版本来扩展存档。这种开放式探索形成了不断增长的高质量代理树，允许并行探索搜索空间中的许多不同路径。DGM还对每次更改进行经验验证。

**结果:** DGM在SWE-bench上的表现从20.0%提升到50.0%，在Polyglot上的表现从14.2%提升到30.7%。此外，DGM显著优于没有自我改进或开放探索的基线方法。所有实验都采取了安全预防措施（例如沙盒、人工监督）。

**结论:** DGM是迈向自我改进AI的重要一步，能够沿着展开为无尽创新的路径收集自己的垫脚石。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Darwin+Godel+Machine%3A+Open-Ended+Evolution+of+Self-Improving+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22954，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22954&send_immediately=true&force_search=false)

**原文摘要:** Today's AI systems have human-designed, fixed architectures and cannot
autonomously and continuously improve themselves. The advance of AI could
itself be automated. If done safely, that would accelerate AI development and
allow us to reap its benefits much sooner. Meta-learning can automate the
discovery of novel algorithms, but is limited by first-order improvements and
the human design of a suitable search space. The G\"odel machine proposed a
theoretical alternative: a self-improving AI that repeatedly modifies itself in
a provably beneficial manner. Unfortunately, proving that most changes are net
beneficial is impossible in practice. We introduce the Darwin G\"odel Machine
(DGM), a self-improving system that iteratively modifies its own code (thereby
also improving its ability to modify its own codebase) and empirically
validates each change using coding benchmarks. Inspired by Darwinian evolution
and open-endedness research, the DGM maintains an archive of generated coding
agents. It grows the archive by sampling an agent from it and using a
foundation model to create a new, interesting, version of the sampled agent.
This open-ended exploration forms a growing tree of diverse, high-quality
agents and allows the parallel exploration of many different paths through the
search space. Empirically, the DGM automatically improves its coding
capabilities (e.g., better code editing tools, long-context window management,
peer-review mechanisms), increasing performance on SWE-bench from 20.0% to
50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly
outperforms baselines without self-improvement or open-ended exploration. All
experiments were done with safety precautions (e.g., sandboxing, human
oversight). The DGM is a significant step toward self-improving AI, capable of
gathering its own stepping stones along paths that unfold into endless
innovation.

</details>


### [172] [Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness](https://arxiv.org/abs/2505.22960)
*Yongjin Yang, Euiin Yi, Jongwoo Ko, Kimin Lee, Zhijing Jin, Se-Young Yun*

**主要类别:** cs.AI

**概要:** 本研究探讨了多智能体辩论（MAD）方法在数学推理和安全任务中的表现，发现其在高难度问题或模型能力较低时更有效，但在安全性任务中需注意多样性和协作优化的平衡。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有研究探索了多智能体辩论（MAD）方法，但对其在不同条件下的有效性缺乏系统性理解，特别是与单智能体方法相比。

**方法:** 将MAD视为一种测试时计算扩展技术，通过全面的实证研究，比较MAD与强大的单智能体测试时扩展基线在数学推理和安全相关任务中的表现。系统分析任务难度、模型规模和智能体多样性对MAD性能的影响。

**结果:** 在数学推理方面，MAD相较于单智能体扩展优势有限，但随着问题难度增加和模型能力下降，其效果更为显著，而智能体多样性影响较小。在安全任务中，MAD的协作优化可能增加漏洞，但通过引入多样化的智能体配置，可以逐步降低攻击成功率。

**结论:** 本研究为未来更高效和更有策略地部署MAD系统提供了关键指导，强调了在不同任务条件下合理利用MAD特性的必要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revisiting+Multi-Agent+Debate+as+Test-Time+Scaling%3A+A+Systematic+Study+of+Conditional+Effectiveness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22960，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22960&send_immediately=true&force_search=false)

**原文摘要:** The remarkable growth in large language model (LLM) capabilities has spurred
exploration into multi-agent systems, with debate frameworks emerging as a
promising avenue for enhanced problem-solving. These multi-agent debate (MAD)
approaches, where agents collaboratively present, critique, and refine
arguments, potentially offer improved reasoning, robustness, and diverse
perspectives over monolithic models. Despite prior studies leveraging MAD, a
systematic understanding of its effectiveness compared to self-agent methods,
particularly under varying conditions, remains elusive. This paper seeks to
fill this gap by conceptualizing MAD as a test-time computational scaling
technique, distinguished by collaborative refinement and diverse exploration
capabilities. We conduct a comprehensive empirical investigation comparing MAD
with strong self-agent test-time scaling baselines on mathematical reasoning
and safety-related tasks. Our study systematically examines the influence of
task difficulty, model scale, and agent diversity on MAD's performance. Key
findings reveal that, for mathematical reasoning, MAD offers limited advantages
over self-agent scaling but becomes more effective with increased problem
difficulty and decreased model capability, while agent diversity shows little
benefit. Conversely, for safety tasks, MAD's collaborative refinement can
increase vulnerability, but incorporating diverse agent configurations
facilitates a gradual reduction in attack success through the collaborative
refinement process. We believe our findings provide critical guidance for the
future development of more effective and strategically deployed MAD systems.

</details>


### [173] [Strategic Reflectivism In Intelligent Systems](https://arxiv.org/abs/2505.22987)
*Nick Byrd*

**主要类别:** cs.AI

**概要:** 论文提出了战略反思主义（Strategic Reflectivism），主张智能系统的关键在于实用地在直觉和反思推理之间切换以最佳实现竞争目标。它基于美国实用主义，超越了如模型大小或思维链等反思思考的表面指标，并随着我们对直觉和反思价值的更多了解而变得越来越可行。


<details>
  <summary>更多</summary>
  
**动机:** 20世纪末，关于直观和反思思维的本质和规范的理性之争引发了诸多辩论，这些辩论源于20世纪中期的思想，例如有限理性，挑战了自19世纪以来被理想化的理性概念。如今，21世纪的认知科学家正在将由此产生的双重过程理论应用于人工智能，因此有必要重新审视历史中的教训。

**方法:** 本论文综合了旧有思想与近期人类和机器实验的结果，提出了战略反思主义。

**结果:** 结果是战略反思主义，认为智能系统（无论是人类还是人工）的一个关键是实用地在直觉和反思推断之间切换，以最佳实现竞争目标。

**结论:** 战略反思主义基于美国实用主义，超越了反思性思维的表面指标，如模型规模或思维链，并随着我们对直觉和反思的价值了解的增加而变得越来越可行。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategic+Reflectivism+In+Intelligent+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22987&send_immediately=true&force_search=false)

**原文摘要:** By late 20th century, the rationality wars had launched debates about the
nature and norms of intuitive and reflective thinking. Those debates drew from
mid-20th century ideas such as bounded rationality, which challenged more
idealized notions of rationality observed since the 19th century. Now that 21st
century cognitive scientists are applying the resulting dual process theories
to artificial intelligence, it is time to dust off some lessons from this
history. So this paper synthesizes old ideas with recent results from
experiments on humans and machines. The result is Strategic Reflectivism, which
takes the position that one key to intelligent systems (human or artificial) is
pragmatic switching between intuitive and reflective inference to optimally
fulfill competing goals. Strategic Reflectivism builds on American Pragmatism,
transcends superficial indicators of reflective thinking such as model size or
chains of thought, and becomes increasingly actionable as we learn more about
the value of intuition and reflection.

</details>


### [174] [MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design](https://arxiv.org/abs/2505.22990)
*Pin-Han Chen, Yu-Sheng Lin, Wei-Cheng Lee, Tin-Yu Leu, Po-Hsiang Hsu, Anjana Dissanayake, Sungjin Oh, Chinq-Shiun Chiu*

**主要类别:** cs.AI

**概要:** 开发了MenTeR，一个多智能体工作流框架，用于端到端模拟设计，减少人工干预，加速设计周期，并探索更广泛的设计空间。


<details>
  <summary>更多</summary>
  
**动机:** 模拟设计流程复杂、耗时且依赖专家直觉，影响电路开发的时间和成本效率。

**方法:** 通过引入多个专门的AI代理，协作处理设计过程的不同方面（如规范理解、电路优化和测试平台验证），从而减少对频繁试错干预的依赖。

**结果:** MenTeR不仅加快了设计周期时间，还促进了更广泛的设计空间探索，在处理真实世界的模拟系统中表现出强大的能力。

**结论:** MenTeR为未来的“RF/Analog Copilots”奠定了基础，可以与人类设计师无缝协作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MenTeR%3A+A+fully-automated+Multi-agenT+workflow+for+end-to-end+RF%2FAnalog+Circuits+Netlist+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22990，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22990&send_immediately=true&force_search=false)

**原文摘要:** RF/Analog design is essential for bridging digital technologies with
real-world signals, ensuring the functionality and reliability of a wide range
of electronic systems. However, analog design procedures are often intricate,
time-consuming and reliant on expert intuition, and hinder the time and cost
efficiency of circuit development. To overcome the limitations of the manual
circuit design, we introduce MenTeR - a multiagent workflow integrated into an
end-to-end analog design framework. By employing multiple specialized AI agents
that collaboratively address different aspects of the design process, such as
specification understanding, circuit optimization, and test bench validation,
MenTeR reduces the dependency on frequent trial-and-error-style intervention.
MenTeR not only accelerates the design cycle time but also facilitates a
broader exploration of the design space, demonstrating robust capabilities in
handling real-world analog systems. We believe that MenTeR lays the groundwork
for future "RF/Analog Copilots" that can collaborate seamlessly with human
designers.

</details>


### [175] [Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction](https://arxiv.org/abs/2505.23034)
*Guangyi Liu, Yongqi Zhang, Xunyuan Liu, Quanming Yao*

**主要类别:** cs.AI

**概要:** 提出CBR-DDI框架，结合大语言模型和图神经网络，通过案例推理提高药物相互作用预测的准确性、可解释性和灵活性。相比现有方法，准确率提升了28.7%。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大语言模型在医药任务中展现出潜力，但在药物相互作用预测方面仍面临挑战。受临床医生基于案例推理实践的启发，需要一种新方法来改善大语言模型在此任务中的表现。

**方法:** 构建CBR-DDI框架，利用大语言模型提取药理学见解，并用图神经网络建模药物关联，创建知识库。采用混合检索机制和双层知识增强提示让大语言模型有效检索和复用相关案例，同时引入代表性采样策略进行动态案例优化。

**结果:** 广泛的实验表明，CBR-DDI实现了最先进的性能，相较于流行的大语言模型和案例推理基线，准确率提高了28.7%，并且保持了高可解释性和灵活性。

**结论:** CBR-DDI框架显著提升了药物相互作用预测任务的性能，为该领域提供了新的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Case-Based+Reasoning+Enhances+the+Predictive+Power+of+LLMs+in+Drug-Drug+Interaction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23034&send_immediately=true&force_search=false)

**原文摘要:** Drug-drug interaction (DDI) prediction is critical for treatment safety.
While large language models (LLMs) show promise in pharmaceutical tasks, their
effectiveness in DDI prediction remains challenging. Inspired by the
well-established clinical practice where physicians routinely reference similar
historical cases to guide their decisions through case-based reasoning (CBR),
we propose CBR-DDI, a novel framework that distills pharmacological principles
from historical cases to improve LLM reasoning for DDI tasks. CBR-DDI
constructs a knowledge repository by leveraging LLMs to extract pharmacological
insights and graph neural networks (GNNs) to model drug associations. A hybrid
retrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs to
effectively retrieve and reuse relevant cases. We further introduce a
representative sampling strategy for dynamic case refinement. Extensive
experiments demonstrate that CBR-DDI achieves state-of-the-art performance,
with a significant 28.7% accuracy improvement over both popular LLMs and CBR
baseline, while maintaining high interpretability and flexibility.

</details>


### [176] [Be.FM: Open Foundation Models for Human Behavior](https://arxiv.org/abs/2505.23058)
*Yutong Xie, Zhuoheng Li, Xiyuan Wang, Yijun Pan, Qijia Liu, Xingzhi Cui, Kuang-Yu Lo, Ruoyi Gao, Xingjian Zhang, Jin Huang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei*

**主要类别:** cs.AI

**概要:** 尽管基础模型在许多领域取得了成功，但它们在人类行为建模和理解方面的潜力尚未得到充分挖掘。我们引入了Be.FM，这是最早公开的基础模型之一，旨在对人类行为进行建模。基于开源大型语言模型构建，并在多样化的行为数据上进行微调，Be.FM可用于理解和预测人类决策。我们构建了一套全面的基准任务来测试行为基础模型的能力。我们的结果表明，Be.FM可以预测行为，推断个人和群体的特征，生成关于背景的见解，并应用行为科学知识。


<details>
  <summary>更多</summary>
  
**动机:** 探索基础模型在人类行为建模和理解方面的潜力，因为这一领域尚未被充分研究。

**方法:** 引入名为Be.FM的开放基础模型，该模型基于开源大型语言模型构建，并在多样化的行为数据上进行了微调。同时构建了一套全面的基准任务来评估模型的能力。

**结果:** Be.FM能够预测行为、推断个人和群体特征、生成背景见解并应用行为科学知识。

**结论:** Be.FM是人类行为建模的一个有前途的工具，展示了基础模型在此领域的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Be.FM%3A+Open+Foundation+Models+for+Human+Behavior，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23058&send_immediately=true&force_search=false)

**原文摘要:** Despite their success in numerous fields, the potential of foundation models
for modeling and understanding human behavior remains largely unexplored. We
introduce Be.FM, one of the first open foundation models designed for human
behavior modeling. Built upon open-source large language models and fine-tuned
on a diverse range of behavioral data, Be.FM can be used to understand and
predict human decision-making. We construct a comprehensive set of benchmark
tasks for testing the capabilities of behavioral foundation models. Our results
demonstrate that Be.FM can predict behaviors, infer characteristics of
individuals and populations, generate insights about contexts, and apply
behavioral science knowledge.

</details>


### [177] [Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble](https://arxiv.org/abs/2505.23075)
*Amit Kumthekar, Zion Tilley, Henry Duong, Bhargav Patel, Michael Magnoli, Ahmed Omar, Ahmed Nasser, Chaitanya Gharpure, Yevgen Reztzov*

**主要类别:** cs.AI

**概要:** 提出了一种新的框架——共识机制，通过集成多个医疗专家代理来改进临床决策，并在多个医学基准测试中表现出更高的准确性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型语言模型在临床应用中过于依赖单一模型架构，存在过时和刚性依赖的风险。为了克服这些风险，需要一个更灵活、适应性更强的系统。

**方法:** 设计了一个模仿临床分诊和多学科临床决策的共识机制框架，该框架集成了多个专业医疗专家代理，可以根据内部模型配置优化成本、延迟或性能。

**结果:** 在MedXpertQA上，共识机制的准确率为61.0%，高于OpenAI的O3（53.5%）和Google的Gemini 2.5 Pro（45.9%）。在其他基准测试中也表现出一致的改进，如MedQA和MedMCQA。在差异诊断生成方面，共识机制展示了更高的召回率、精确率和F1分数。

**结论:** 共识机制提供了一种改进临床决策的方法，具有强大的适应性，能够在不同基准测试中提高准确性，并可根据需求优化不同的性能指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Second+Opinion+Matters%3A+Towards+Adaptive+Clinical+AI+via+the+Consensus+of+Expert+Model+Ensemble，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23075，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23075&send_immediately=true&force_search=false)

**原文摘要:** Despite the growing clinical adoption of large language models (LLMs),
current approaches heavily rely on single model architectures. To overcome
risks of obsolescence and rigid dependence on single model systems, we present
a novel framework, termed the Consensus Mechanism. Mimicking clinical triage
and multidisciplinary clinical decision-making, the Consensus Mechanism
implements an ensemble of specialized medical expert agents enabling improved
clinical decision making while maintaining robust adaptability. This
architecture enables the Consensus Mechanism to be optimized for cost, latency,
or performance, purely based on its interior model configuration.
  To rigorously evaluate the Consensus Mechanism, we employed three medical
evaluation benchmarks: MedMCQA, MedQA, and MedXpertQA Text, and the
differential diagnosis dataset, DDX+. On MedXpertQA, the Consensus Mechanism
achieved an accuracy of 61.0% compared to 53.5% and 45.9% for OpenAI's O3 and
Google's Gemini 2.5 Pro. Improvement was consistent across benchmarks with an
increase in accuracy on MedQA
($\Delta\mathrm{Accuracy}_{\mathrm{consensus\text{-}O3}} = 3.4\%$) and MedMCQA
($\Delta\mathrm{Accuracy}_{\mathrm{consensus\text{-}O3}} = 9.1\%$). These
accuracy gains extended to differential diagnosis generation, where our system
demonstrated improved recall and precision (F1$_\mathrm{consensus}$ = 0.326 vs.
F1$_{\mathrm{O3\text{-}high}}$ = 0.2886) and a higher top-1 accuracy for DDX
(Top1$_\mathrm{consensus}$ = 52.0% vs. Top1$_{\mathrm{O3\text{-}high}}$ =
45.2%).

</details>


### [178] [Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models](https://arxiv.org/abs/2505.23091)
*Zeyu Liu, Yuhang Liu, Guanghao Zhu, Congkai Xie, Zhen Li, Jianbo Yuan, Xinyao Wang, Qing Li, Shing-Chi Cheung, Shengyu Zhang, Fei Wu, Hongxia Yang*

**主要类别:** cs.AI

**概要:** 近期大型语言模型（LLMs）在推理能力方面取得了显著进展，但将这些成果扩展到多模态大型语言模型（MLLMs）尤其是多模态小型语言模型（MSLMs）上面临诸多挑战。为解决这些问题，本文设计了一个名为Infi-MMR的新框架，并提出了具有30亿参数的多模态推理模型Infi-MMR-3B。该框架通过三个阶段系统地挖掘MSLMs的推理潜力：基础推理激活、跨模态推理适应和多模态推理增强。实验结果表明，Infi-MMR-3B在多模态数学推理和通用推理任务上均达到了最先进的水平。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在推理方面表现出色，但将其应用于多模态小型语言模型时，由于高质量多模态数据稀缺、视觉处理对推理能力的影响以及强化学习可能产生的错误推理过程等问题，仍面临重大挑战。因此需要一种新方法来提升多模态小型语言模型的推理能力。

**方法:** 本文提出了一种名为Infi-MMR的新框架，该框架包括三个阶段：1. 基础推理激活：使用高质量文本推理数据集训练模型的基础逻辑推理能力；2. 跨模态推理适应：利用带标题的多模态数据逐步将推理技能迁移到多模态环境；3. 多模态推理增强：采用无标题的精选多模态数据减少语言偏差并促进稳健的跨模态推理。此外还提出了一个基于此框架的多模态推理模型Infi-MMR-3B。

**结果:** Infi-MMR-3B在多模态数学推理任务上表现优异，在MathVerse testmini、MathVision test和OlympiadBench上的准确率分别为43.68%、27.04%和21.33%，同时在通用推理任务（如MathVista testmini）上也取得了67.2%的高准确率。

**结论:** 本文提出的Infi-MMR框架能够有效提升多模态小型语言模型的推理能力，特别是在数学推理和通用推理任务上达到了最先进的水平。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Infi-MMR%3A+Curriculum-based+Unlocking+Multimodal+Reasoning+via+Phased+Reinforcement+Learning+in+Multimodal+Small+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23091，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23091&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in large language models (LLMs) have demonstrated
substantial progress in reasoning capabilities, such as DeepSeek-R1, which
leverages rule-based reinforcement learning to enhance logical reasoning
significantly. However, extending these achievements to multimodal large
language models (MLLMs) presents critical challenges, which are frequently more
pronounced for Multimodal Small Language Models (MSLMs) given their typically
weaker foundational reasoning abilities: (1) the scarcity of high-quality
multimodal reasoning datasets, (2) the degradation of reasoning capabilities
due to the integration of visual processing, and (3) the risk that direct
application of reinforcement learning may produce complex yet incorrect
reasoning processes. To address these challenges, we design a novel framework
Infi-MMR to systematically unlock the reasoning potential of MSLMs through a
curriculum of three carefully structured phases and propose our multimodal
reasoning model Infi-MMR-3B. The first phase, Foundational Reasoning
Activation, leverages high-quality textual reasoning datasets to activate and
strengthen the model's logical reasoning capabilities. The second phase,
Cross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to
facilitate the progressive transfer of reasoning skills to multimodal contexts.
The third phase, Multimodal Reasoning Enhancement, employs curated,
caption-free multimodal data to mitigate linguistic biases and promote robust
cross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal
math reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision
test, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on
MathVista testmini).

</details>


### [179] [Conceptual Framework Toward Embodied Collective Adaptive Intelligence](https://arxiv.org/abs/2505.23153)
*Fan Wang, Shaoshan Liu*

**主要类别:** cs.AI

**概要:** 论文探讨了集体自适应智能（CAI）的概念框架，强调其在应对复杂动态环境中的重要性，并提出包括任务泛化、弹性、可扩展性和自组装等关键属性，以指导研究者设计更强大的AI系统。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI系统在面对复杂、动态环境时缺乏足够的适应性和弹性，需要一种新的方法来提升系统的鲁棒性和性能。

**方法:** 提出一个概念框架，用于设计和分析CAI系统，重点涵盖任务泛化、弹性、可扩展性和自组装等关键属性。

**结果:** 为理解与实现CAI提供了结构化的基础，有助于指导研究者和实践者开发更具弹性和可扩展性的AI系统。

**结论:** CAI代表了一种变革性的人工智能方法，通过自主代理的合作、适应和自组织，可以在复杂环境中实现稳健性能，推动理论与实际工程方法的结合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conceptual+Framework+Toward+Embodied+Collective+Adaptive+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23153，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23153&send_immediately=true&force_search=false)

**原文摘要:** Collective Adaptive Intelligence (CAI) represent a transformative approach in
artificial intelligence, wherein numerous autonomous agents collaborate, adapt,
and self-organize to navigate complex, dynamic environments. This paradigm is
particularly impactful in embodied AI applications, where adaptability and
resilience are paramount. By enabling systems to reconfigure themselves in
response to unforeseen challenges, CAI facilitate robust performance in
real-world scenarios. This article introduces a conceptual framework for
designing and analyzing CAI. It delineates key attributes including task
generalization, resilience, scalability, and self-assembly, aiming to bridge
theoretical foundations with practical methodologies for engineering adaptive,
emergent intelligence. By providing a structured foundation for understanding
and implementing CAI, this work seeks to guide researchers and practitioners in
developing more resilient, scalable, and adaptable AI systems across various
domains.

</details>


### [180] [MathArena: Evaluating LLMs on Uncontaminated Math Competitions](https://arxiv.org/abs/2505.23281)
*Mislav Balunović, Jasper Dekoninck, Ivo Petrov, Nikola Jovanović, Martin Vechev*

**主要类别:** cs.AI

**概要:** 大语言模型（LLMs）在数学基准测试中表现出显著进步，但现有数据集可能混杂了记忆效果。为解决此问题，本文提出MathArena，一个基于实时数学竞赛问题的新基准测试框架，能有效评估LLMs的推理和证明写作能力。实验表明，顶级模型在最终答案任务上表现良好，但在证明写作方面仍有很大提升空间。


<details>
  <summary>更多</summary>
  
**动机:** 当前常用的数学评估数据集（如AIME 2024）在线上广泛可得，难以区分模型的真实推理能力和潜在的记忆效果。此外，这些基准测试未涵盖对许多数学任务至关重要的证明写作能力。

**方法:** 引入MathArena作为新基准，利用定期举行的数学竞赛提供的高质量、高难度问题进行实时评估，以消除潜在的记忆污染，并首次评估LLMs的证明写作能力。

**结果:** 发现AIME 2024存在明显污染迹象；而在更难的竞赛（如SMT 2025）中，顶级模型展现出强大的推理能力。然而，在USAMO 2025的证明写作任务中，即使是顶级模型得分也低于25%。

**结论:** MathArena提供了一个不断发展的基准测试框架，能够严格且及时地跟踪LLMs在数学推理方面的进展，特别是在证明写作能力上的不足。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MathArena%3A+Evaluating+LLMs+on+Uncontaminated+Math+Competitions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23281&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of reasoning capabilities in large language models
(LLMs) has led to notable improvements on mathematical benchmarks. However,
many of the most commonly used evaluation datasets (e.g., AIME 2024) are widely
available online, making it difficult to disentangle genuine reasoning from
potential memorization. Furthermore, these benchmarks do not evaluate
proof-writing capabilities, which are crucial for many mathematical tasks. To
address this, we introduce MathArena, a new benchmark based on the following
key insight: recurring math competitions provide a stream of high-quality,
challenging problems that can be used for real-time evaluation of LLMs. By
evaluating models as soon as new problems are released, we effectively
eliminate the risk of contamination. Using this framework, we find strong signs
of contamination in AIME 2024. Nonetheless, evaluations on harder competitions,
such as SMT 2025 -- published well after model release dates -- demonstrate
impressive reasoning capabilities in top-performing models. MathArena is also
the first benchmark for proof-writing capabilities. On USAMO 2025, even top
models score below 25%, far behind their performance on final-answer tasks. So
far, we have evaluated 30 models across five competitions, totaling 149
problems. As an evolving benchmark, MathArena will continue to track the
progress of LLMs on newly released competitions, ensuring rigorous and
up-to-date evaluation of mathematical reasoning.

</details>


### [181] [AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning](https://arxiv.org/abs/2505.23381)
*Bowen Ping, Minnan Luo, Zhuohang Dang, Chenxi Wang, Chengyou Jia*

**主要类别:** cs.AI

**概要:** 几何问题求解对人工智能提出了独特的挑战，需要卓越的多模态理解和严谨的数学推理能力。现有的方法通常分为神经网络和基于符号的方法两类，它们在可靠性和可解释性方面存在局限性。为了解决这一挑战，我们提出了AutoGPS，这是一个神经-符号协作框架，以简洁、可靠和人类可解释的推理过程解决几何问题。具体来说，AutoGPS采用了多模态问题形式化器（MPF）和演绎符号推理器（DSR）。MPF利用神经交叉模态理解将几何问题转化为结构化的形式语言表示，并与DSR进行协作反馈。DSR接受形式化输入，并将几何问题求解视为超图扩展任务，执行严格的数学推导，生成最小且人类可读的逐步解决方案。广泛的实验评估表明，AutoGPS在基准数据集上实现了最先进的性能。此外，人类逐步推理评估证实了AutoGPS出色的可靠性和可解释性，具有99%的逐步逻辑一致性。


<details>
  <summary>更多</summary>
  
**动机:** 几何问题求解对于人工智能而言是一个独特的挑战，因为它需要卓越的多模态理解和严谨的数学推理能力。然而，现有的神经网络和基于符号的方法在可靠性和可解释性方面存在局限性，这促使研究者们寻找一种新的方法来克服这些限制。

**方法:** 研究者提出了一种名为AutoGPS的神经-符号协作框架。该框架包括两个主要组件：多模态问题形式化器（MPF）和演绎符号推理器（DSR）。MPF通过神经交叉模态理解将几何问题转化为结构化的形式语言表示，并从DSR接收反馈。DSR则将几何问题求解作为超图扩展任务处理，执行严格的数学推导，生成简洁且易于理解的逐步解决方案。

**结果:** 实验结果表明，AutoGPS在多个基准数据集上达到了最先进的性能。此外，人类逐步推理评估显示，AutoGPS具备99%的逐步逻辑一致性，证明了其高可靠性和可解释性。

**结论:** AutoGPS作为一种神经-符号协作框架，成功解决了几何问题求解中的挑战，提供了简洁、可靠且可解释的推理过程。它在实验中表现出色，并得到了人类评价的高度认可，标志着几何问题求解领域的重要进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoGPS%3A+Automated+Geometry+Problem+Solving+via+Multimodal+Formalization+and+Deductive+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23381，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23381&send_immediately=true&force_search=false)

**原文摘要:** Geometry problem solving presents distinctive challenges in artificial
intelligence, requiring exceptional multimodal comprehension and rigorous
mathematical reasoning capabilities. Existing approaches typically fall into
two categories: neural-based and symbolic-based methods, both of which exhibit
limitations in reliability and interpretability. To address this challenge, we
propose AutoGPS, a neuro-symbolic collaborative framework that solves geometry
problems with concise, reliable, and human-interpretable reasoning processes.
Specifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a
Deductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal
comprehension to translate geometry problems into structured formal language
representations, with feedback from DSR collaboratively. The DSR takes the
formalization as input and formulates geometry problem solving as a hypergraph
expansion task, executing mathematically rigorous and reliable derivation to
produce minimal and human-readable stepwise solutions. Extensive experimental
evaluations demonstrate that AutoGPS achieves state-of-the-art performance on
benchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms
AutoGPS's impressive reliability and interpretability, with 99\% stepwise
logical coherence. The project homepage is at
https://jayce-ping.github.io/AutoGPS-homepage.

</details>


### [182] [A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy](https://arxiv.org/abs/2505.23397)
*Ahmad Mohsin, Helge Janicke, Ahmed Ibrahim, Iqbal H. Sarker, Seyit Camtepe*

**主要类别:** cs.AI

**概要:** 提出了一种新型的人工智能自主层级框架，用于安全运营中心（SOCs）中的人工智能与人类协作。该框架通过五个层次的AI自主性级别、人类参与决策的角色和任务特定的信任阈值来实现适应性和可解释的人工智能集成。通过模拟案例研究展示了其在减少警报疲劳、增强响应协调和校准信任方面的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的SOC框架过于关注自动化，缺乏系统结构来管理人工监督、信任校准和与AI协作的可扩展自主性。许多框架假设静态或二元的自主设置，未能考虑SOC任务中的多样复杂性、关键性和风险。

**方法:** 提出了一个基于五个AI自主级别的新自主分层框架，并将其映射到人类参与决策（HITL）角色和任务特定的信任阈值。此方法允许根据操作复杂性和相关风险进行自适应任务分配。并通过模拟网络范围中的网络安全AI-Avatar案例研究来展示该框架的应用。

**结果:** 该框架能够实现更灵活和有效的AI与人类协作，减少了警报疲劳，增强了响应协调，并战略性地校准了信任。同时展示了理论和实践可行性，为设计下一代认知SOC提供了指导。

**结论:** 所提出的框架通过正式连接自主性、信任和人类参与决策，实现了适应不同复杂性和风险的任务分配。它不仅强调了AI在SOC中的辅助作用，还系统地展示了设计下一代认知SOC的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Unified+Framework+for+Human+AI+Collaboration+in+Security+Operations+Centers+with+Trusted+Autonomy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23397，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23397&send_immediately=true&force_search=false)

**原文摘要:** This article presents a structured framework for Human-AI collaboration in
Security Operations Centers (SOCs), integrating AI autonomy, trust calibration,
and Human-in-the-loop decision making. Existing frameworks in SOCs often focus
narrowly on automation, lacking systematic structures to manage human
oversight, trust calibration, and scalable autonomy with AI. Many assume static
or binary autonomy settings, failing to account for the varied complexity,
criticality, and risk across SOC tasks considering Humans and AI collaboration.
To address these limitations, we propose a novel autonomy tiered framework
grounded in five levels of AI autonomy from manual to fully autonomous, mapped
to Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This
enables adaptive and explainable AI integration across core SOC functions,
including monitoring, protection, threat detection, alert triage, and incident
response. The proposed framework differentiates itself from previous research
by creating formal connections between autonomy, trust, and HITL across various
SOC levels, which allows for adaptive task distribution according to
operational complexity and associated risks. The framework is exemplified
through a simulated cyber range that features the cybersecurity AI-Avatar, a
fine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates
human-AI collaboration for SOC tasks, reducing alert fatigue, enhancing
response coordination, and strategically calibrating trust. This research
systematically presents both the theoretical and practical aspects and
feasibility of designing next-generation cognitive SOCs that leverage AI not to
replace but to enhance human decision-making.

</details>


### [183] [GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning](https://arxiv.org/abs/2505.23399)
*Jusheng Zhang, Yijia Fan, Wenjun Lin, Ruiqi Chen, Haoyi Jiang, Wenhao Chai, Jian Wang, Keze Wang*

**主要类别:** cs.AI

**概要:** 本研究提出了一种名为GAM-Agent的游戏理论多智能体框架，用于增强视觉-语言推理。通过将推理过程建模为非零和博弈，并引入不确定性感知控制器以动态调整智能体协作，该框架在多个基准测试中显著提升了从小型到大型模型的性能，展现了模块化、可扩展性和通用性特点，为可靠的多模态推理提供了新方向。


<details>
  <summary>更多</summary>
  
**动机:** 当前单一智能体或整体模型在视觉-语言推理方面存在局限性，特别是在处理复杂任务时缺乏灵活性和解释性。因此，需要一种新的方法来提升推理过程的鲁棒性和可解释性。

**方法:** 提出了GAM-Agent框架，将推理过程建模为非零和博弈，包含专注于视觉感知子任务的基础智能体和验证逻辑一致性和事实正确性的关键智能体。智能体通过结构化的声明、证据和不确定性估计进行通信，并通过不确定性感知控制器动态调整协作，在检测到分歧或歧义时触发多轮辩论。

**结果:** 在MMMU、MMBench、MVBench和V*Bench四个具有挑战性的基准测试上，GAM-Agent显著提高了各种视觉-语言模型（VLM）的性能。特别是对于小型到中型模型（如Qwen2.5-VL-7B、InternVL3-14B），准确率提升了5-6%，而对于强大模型（如GPT-4o）也提升了2-3%。

**结论:** GAM-Agent是一种模块化、可扩展且通用的方法，可以提高视觉-语言推理的可靠性和可解释性，为多智能体多模态推理提供了一条可行路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GAM-Agent%3A+Game-Theoretic+and+Uncertainty-Aware+Collaboration+for+Complex+Visual+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23399，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23399&send_immediately=true&force_search=false)

**原文摘要:** We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing
vision-language reasoning. Unlike prior single-agent or monolithic models,
GAM-Agent formulates the reasoning process as a non-zero-sum game between base
agents--each specializing in visual perception subtasks--and a critical agent
that verifies logic consistency and factual correctness. Agents communicate via
structured claims, evidence, and uncertainty estimates. The framework
introduces an uncertainty-aware controller to dynamically adjust agent
collaboration, triggering multi-round debates when disagreement or ambiguity is
detected. This process yields more robust and interpretable predictions.
Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and
V*Bench--demonstrate that GAM-Agent significantly improves performance across
various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid
scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\%, and still enhances
strong models like GPT-4o by up to 2--3\%. Our approach is modular, scalable,
and generalizable, offering a path toward reliable and explainable multi-agent
multimodal reasoning.

</details>


### [184] [A Mathematical Framework for AI-Human Integration in Work](https://arxiv.org/abs/2505.23432)
*Elisa Celis, Lingxiao Huang, Nisheeth K. Vishnoi*

**主要类别:** cs.AI

**概要:** 生成式AI（GenAI）工具的迅速崛起引发了关于其在不同工作环境中是补充还是取代人类工作者的角色的讨论。本文提出一个数学框架，模拟工作、工作者和工作者-工作的匹配度，将技能分解为决策级和行动级子技能，以反映人类和GenAI的互补优势。分析了子技能能力的变化如何影响工作成功，并确定了成功概率急剧变化的条件。同时，建立了在何种条件下结合具有互补子技能的工作者显著优于依赖单一工作者的充分条件。这解释了诸如生产力压缩等现象，即GenAI辅助对低技能工作者产生更大的收益。通过O*NET和Big-Bench Lite的数据展示了框架的实际应用，结果强调了GenAI何时以及如何补充人类技能，而非取代它们。


<details>
  <summary>更多</summary>
  
**动机:** 生成式AI的快速发展引发了对其在工作中替代或补充人类角色的广泛讨论，因此需要一个框架来理解人类与GenAI的技能互补性及其对工作成功的影响。

**方法:** 构建一个数学框架，将技能分解为决策级和行动级子技能，模拟工作、工作者及两者匹配关系，使用O*NET和Big-Bench Lite数据验证模型的有效性。

**结果:** 确定了子技能能力变化对工作成功的具体影响条件，证明了互补子技能组合的优越性，并解释了生产力压缩现象。

**结论:** 生成式AI能够有效补充人类技能，特别是在特定条件下，而非简单地取代人类工作者。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Mathematical+Framework+for+AI-Human+Integration+in+Work，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23432，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23432&send_immediately=true&force_search=false)

**原文摘要:** The rapid rise of Generative AI (GenAI) tools has sparked debate over their
role in complementing or replacing human workers across job contexts. We
present a mathematical framework that models jobs, workers, and worker-job fit,
introducing a novel decomposition of skills into decision-level and
action-level subskills to reflect the complementary strengths of humans and
GenAI. We analyze how changes in subskill abilities affect job success,
identifying conditions for sharp transitions in success probability. We also
establish sufficient conditions under which combining workers with
complementary subskills significantly outperforms relying on a single worker.
This explains phenomena such as productivity compression, where GenAI
assistance yields larger gains for lower-skilled workers. We demonstrate the
framework' s practicality using data from O*NET and Big-Bench Lite, aligning
real-world data with our model via subskill-division methods. Our results
highlight when and how GenAI complements human skills, rather than replacing
them.

</details>


### [185] [Emergent Risk Awareness in Rational Agents under Resource Constraints](https://arxiv.org/abs/2505.23436)
*Daniel Jarne Ornia, Nicholas Bishop, Joel Dyer, Wei-Chen Lee, Ani Calinescu, Doyne Farme, Michael Wooldridge*

**主要类别:** cs.AI

**概要:** 高级推理模型（AI代理）被部署用于与人类交互和解决序列决策问题。在资源或失败约束下，代理面临隐含的权衡，可能引发与人类目标的不一致。本文通过生存强盗框架对此进行形式化，提供理论和实证结果，并提出缓解风险行为的机制。


<details>
  <summary>更多</summary>
  
**动机:** 在资源有限或可能失败的情况下，AI代理的行为会受到生存压力的影响，产生意想不到的风险偏好或规避行为，可能导致与人类目标的不一致。

**方法:** 通过生存强盗框架形式化该问题，分析生存驱动偏好转移的影响，识别不一致出现的条件，并提出缓解风险行为的机制。

**结果:** 提供了理论和实证结果，量化了生存驱动偏好转移的影响，并确定了导致不一致的条件。

**结论:** 本工作旨在提高对AI代理在生存压力下的新兴行为的理解和可解释性，并为在关键资源受限环境中安全部署AI系统提供指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Emergent+Risk+Awareness+in+Rational+Agents+under+Resource+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23436，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23436&send_immediately=true&force_search=false)

**原文摘要:** Advanced reasoning models with agentic capabilities (AI agents) are deployed
to interact with humans and to solve sequential decision-making problems under
(approximate) utility functions and internal models. When such problems have
resource or failure constraints where action sequences may be forcibly
terminated once resources are exhausted, agents face implicit trade-offs that
reshape their utility-driven (rational) behaviour. Additionally, since these
agents are typically commissioned by a human principal to act on their behalf,
asymmetries in constraint exposure can give rise to previously unanticipated
misalignment between human objectives and agent incentives. We formalise this
setting through a survival bandit framework, provide theoretical and empirical
results that quantify the impact of survival-driven preference shifts, identify
conditions under which misalignment emerges and propose mechanisms to mitigate
the emergence of risk-seeking or risk-averse behaviours. As a result, this work
aims to increase understanding and interpretability of emergent behaviours of
AI agents operating under such survival pressure, and offer guidelines for
safely deploying such AI systems in critical resource-limited environments.

</details>


### [186] [EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions](https://arxiv.org/abs/2505.23473)
*Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaolu Zhang, Jun Zhou, Yuxiang Peng, Li Zheng, Chong Teng, Donghong Ji, Zhuang Li*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）常因保守的安全对齐而拒绝无害的输入查询，损害用户体验。本文提出了一种名为EVOREFUSE的提示优化方法，通过进化算法生成多样的伪恶意指令，以减少不必要的拒绝现象。该方法创建了两个新数据集：EVOREFUSE-TEST和EVOREFUSE-ALIGN，分别用于评估和训练模型。实验表明，使用EVOREFUSE-ALIGN进行监督微调的LLAMA3.1-8B-INSTRUCT模型在减少过度拒绝方面表现优于其他模型，同时不会降低安全性。分析还发现，模型过度关注敏感关键词而忽略上下文是导致过度拒绝的主要原因。


<details>
  <summary>更多</summary>
  
**动机:** 现有的收集伪恶意指令的方法要么缺乏可扩展性，要么无法生成足够多样和有效的拒绝诱导提示，这限制了对LLMs过度拒绝现象的研究和改进。

**方法:** 引入了EVOREFUSE，一种基于进化算法的提示优化方法，通过变异策略和重组探索更广泛的指令空间，迭代演化种子指令以最大化LLMs拒绝概率的下界。

**结果:** 1. 创建了EVOREFUSE-TEST数据集，包含582个伪恶意指令，比次优基准高出140.41%的平均拒绝触发率，词汇多样性提高34.86%，LLM响应置信度评分提升40.03%。
2. 创建了EVOREFUSE-ALIGN数据集，提供3,000个伪恶意指令及其响应，用于监督和偏好对齐训练。
3. 使用EVOREFUSE-ALIGN监督微调的LLAMA3.1-8B-INSTRUCT模型，过度拒绝减少了14.31%，且未牺牲安全性。

**结论:** EVOREFUSE是一种有效的方法，能够生成多样化的伪恶意指令，帮助评估和缓解LLMs的过度拒绝问题。研究揭示了模型在处理输入时过度依赖敏感关键词的问题，并为未来改进LLMs的安全性和用户体验提供了方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EVOREFUSE%3A+Evolutionary+Prompt+Optimization+for+Evaluation+and+Mitigation+of+LLM+Over-Refusal+to+Pseudo-Malicious+Instructions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23473，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23473&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) frequently refuse to respond to pseudo-malicious
instructions: semantically harmless input queries triggering unnecessary LLM
refusals due to conservative safety alignment, significantly impairing user
experience. Collecting such instructions is crucial for evaluating and
mitigating over-refusals, but existing instruction curation methods, like
manual creation or instruction rewriting, either lack scalability or fail to
produce sufficiently diverse and effective refusal-inducing prompts. To address
these limitations, we introduce EVOREFUSE, a prompt optimization approach that
generates diverse pseudo-malicious instructions consistently eliciting
confident refusals across LLMs. EVOREFUSE employs an evolutionary algorithm
exploring the instruction space in more diverse directions than existing
methods via mutation strategies and recombination, and iteratively evolves seed
instructions to maximize evidence lower bound on LLM refusal probability. Using
EVOREFUSE, we create two novel datasets: EVOREFUSE-TEST, a benchmark of 582
pseudo-malicious instructions that outperforms the next-best benchmark with
140.41% higher average refusal triggering rate across 9 LLMs, 34.86% greater
lexical diversity, and 40.03% improved LLM response confidence scores; and
EVOREFUSE-ALIGN, which provides 3,000 pseudo-malicious instructions with
responses for supervised and preference-based alignment training.
LLAMA3.1-8B-INSTRUCT supervisedly fine-tuned on EVOREFUSE-ALIGN achieves up to
14.31% fewer over-refusals than models trained on the second-best alignment
dataset, without compromising safety. Our analysis with EVOREFUSE-TEST reveals
models trigger over-refusals by overly focusing on sensitive keywords while
ignoring broader context.

</details>


### [187] [Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns](https://arxiv.org/abs/2505.23474)
*Xiang Li, Haiyang Yu, Xinghua Zhang, Ziyang Huang, Shizhu He, Kang Liu, Jun Zhao, Fei Huang, Yongbin Li*

**主要类别:** cs.AI

**概要:** Process Reward Models (PRMs) are vital for complex reasoning tasks. However, current benchmarks fall short in systematically evaluating PRMs across various reasoning patterns. This paper introduces Socratic-PRMBench, a new benchmark with 2995 flawed reasoning paths across six reasoning patterns, revealing deficiencies in existing PRMs and providing a foundation for their future development.


<details>
  <summary>更多</summary>
  
**动机:** Current benchmarks for evaluating PRMs focus on stepwise correctness but lack systematic evaluation across different reasoning patterns, which is crucial for identifying errors in complex reasoning processes.

**方法:** The paper proposes Socratic-PRMBench, a benchmark containing 2995 flawed reasoning paths under six reasoning patterns (Transformation, Decomposition, Regather, Deduction, Verification, Integration). It evaluates both PRMs and LLMs prompted as critic models.

**结果:** Experiments using Socratic-PRMBench identified significant deficiencies in existing PRMs when evaluating reasoning steps under various patterns.

**结论:** Socratic-PRMBench serves as a comprehensive testbed for the systematic evaluation of PRMs under diverse reasoning patterns, highlighting areas for improvement and guiding future PRM development.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Socratic-PRMBench%3A+Benchmarking+Process+Reward+Models+with+Systematic+Reasoning+Patterns，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23474，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23474&send_immediately=true&force_search=false)

**原文摘要:** Process Reward Models (PRMs) are crucial in complex reasoning and
problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by
verifying the correctness of each intermediate reasoning step. In real-world
scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to
solve a problem, potentially suffering from errors under various reasoning
patterns. Therefore, PRMs are required to identify errors under various
reasoning patterns during the reasoning process. However, existing benchmarks
mainly focus on evaluating PRMs with stepwise correctness, ignoring a
systematic evaluation of PRMs under various reasoning patterns. To mitigate
this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs
systematically under six reasoning patterns, including Transformation,
Decomposition, Regather, Deduction, Verification, and Integration.
Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the
aforementioned six reasoning patterns. Through our experiments on both PRMs and
LLMs prompted as critic models, we identify notable deficiencies in existing
PRMs. These observations underscore the significant weakness of current PRMs in
conducting evaluations on reasoning steps under various reasoning patterns. We
hope Socratic-PRMBench can serve as a comprehensive testbed for systematic
evaluation of PRMs under diverse reasoning patterns and pave the way for future
development of PRMs.

</details>


### [188] [Autoformalization in the Era of Large Language Models: A Survey](https://arxiv.org/abs/2505.23486)
*Ke Weng, Lun Du, Sirui Li, Wangyue Lu, Haozhe Sun, Hengyu Liu, Tiancheng Zhang*

**主要类别:** cs.AI

**概要:** 自动形式化（Autoformalization）是将非正式数学命题转化为可验证的形式表示的过程，是自动定理证明中的基础任务。本文综述了该领域在数学和大语言模型（LLM）视角下的最新进展，分析了其应用、工作流程以及对LLM输出的改进作用，并探讨了开源模型、挑战及未来方向。


<details>
  <summary>更多</summary>
  
**动机:** 自动形式化为数学在理论与应用领域的使用提供了新视角，同时随着人工智能尤其是大语言模型的快速发展，该领域展现出新的机遇与挑战。

**方法:** 从数学和LLM两个角度回顾自动形式化的进展；研究其在不同数学领域和难度级别的应用；分析端到端的工作流程，包括数据预处理、模型设计与评估；探索自动形式化在提高LLM生成输出可信度和推理能力中的作用。

**结果:** 总结了支持当前研究的开源模型和数据集，识别出开放性挑战并提出了有前景的未来研究方向。

**结论:** 自动形式化在提升LLM的可信度和推理能力方面具有巨大潜力，但同时也面临诸多挑战，未来研究应聚焦于解决这些问题以推动领域进一步发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Autoformalization+in+the+Era+of+Large+Language+Models%3A+A+Survey，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23486，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23486&send_immediately=true&force_search=false)

**原文摘要:** Autoformalization, the process of transforming informal mathematical
propositions into verifiable formal representations, is a foundational task in
automated theorem proving, offering a new perspective on the use of mathematics
in both theoretical and applied domains. Driven by the rapid progress in
artificial intelligence, particularly large language models (LLMs), this field
has witnessed substantial growth, bringing both new opportunities and unique
challenges. In this survey, we provide a comprehensive overview of recent
advances in autoformalization from both mathematical and LLM-centric
perspectives. We examine how autoformalization is applied across various
mathematical domains and levels of difficulty, and analyze the end-to-end
workflow from data preprocessing to model design and evaluation. We further
explore the emerging role of autoformalization in enhancing the verifiability
of LLM-generated outputs, highlighting its potential to improve both the
trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key
open-source models and datasets supporting current research, and discuss open
challenges and promising future directions for the field.

</details>


### [189] [TRAP: Targeted Redirecting of Agentic Preferences](https://arxiv.org/abs/2505.23518)
*Hangoo Kang, Jehyeok Yeon, Gagandeep Singh*

**主要类别:** cs.AI

**概要:** 自主代理AI系统通过视觉-语言模型（VLMs）迅速向现实世界部署，但其跨模态推理能力为对抗性操控引入了新的攻击面。我们提出了TRAP框架，它利用扩散型语义注入来操纵代理的决策。TRAP在不需要访问模型内部的情况下，生成视觉上自然的图像，却能诱导代理AI系统产生一致的选择偏差。我们在COCO数据集上评估了TRAP，在多个候选决策场景中，TRAP对包括LLaVA-34B、Gemma3和Mistral-3.1在内的领先模型实现了100%的攻击成功率，显著优于SPSA、Bandit和标准扩散方法等基线。这些结果揭示了一个关键漏洞：自主代理可以通过人类无法察觉的跨模态操控被持续误导。这些发现强调了需要超越像素级鲁棒性的防御策略，以应对跨模态决策中的语义漏洞。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对抗攻击通常依赖于可见的像素扰动或需要特权模型或环境访问，这使得它们在隐秘的、现实世界的利用中不切实际。因此，研究者希望找到一种新的对抗性框架，可以在无需访问模型内部的情况下，实现对自主代理AI系统的有效攻击。

**方法:** TRAP结合了基于负提示的降级与正语义优化，由一个Siamese语义网络和布局感知的空间掩码引导。该方法使用扩散型语义注入来操纵代理的决策，从而生成视觉上自然的图像，同时诱导代理AI系统产生一致的选择偏差。

**结果:** TRAP在COCO数据集上的多候选决策场景中，对领先模型（如LLaVA-34B、Gemma3和Mistral-3.1）实现了100%的攻击成功率，并显著优于SPSA、Bandit和标准扩散方法等基线。

**结论:** 这些结果揭示了自主代理可以通过人类无法察觉的跨模态操控被持续误导的关键漏洞。研究强调了需要超越像素级鲁棒性的防御策略，以应对跨模态决策中的语义漏洞。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRAP%3A+Targeted+Redirecting+of+Agentic+Preferences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23518，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23518&send_immediately=true&force_search=false)

**原文摘要:** Autonomous agentic AI systems powered by vision-language models (VLMs) are
rapidly advancing toward real-world deployment, yet their cross-modal reasoning
capabilities introduce new attack surfaces for adversarial manipulation that
exploit semantic reasoning across modalities. Existing adversarial attacks
typically rely on visible pixel perturbations or require privileged model or
environment access, making them impractical for stealthy, real-world
exploitation. We introduce TRAP, a generative adversarial framework that
manipulates the agent's decision-making using diffusion-based semantic
injections. Our method combines negative prompt-based degradation with positive
semantic optimization, guided by a Siamese semantic network and layout-aware
spatial masking. Without requiring access to model internals, TRAP produces
visually natural images yet induces consistent selection biases in agentic AI
systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO)
dataset, building multi-candidate decision scenarios. Across these scenarios,
TRAP achieves a 100% attack success rate on leading models, including
LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such
as SPSA, Bandit, and standard diffusion approaches. These results expose a
critical vulnerability: Autonomous agents can be consistently misled through
human-imperceptible cross-modal manipulations. These findings highlight the
need for defense strategies beyond pixel-level robustness to address semantic
vulnerabilities in cross-modal decision-making.

</details>


### [190] [Individual differences in the cognitive mechanisms of planning strategy discovery](https://arxiv.org/abs/2505.23519)
*Ruiqi He, Falk Lieder*

**主要类别:** cs.AI

**概要:** 人们通过元认知强化学习（MCRL）获取高效的规划策略，但模型在策略发现的速度上仍不如人类。本研究探讨了结合促进人类策略发现的认知机制（如元认知伪奖励、主观努力评估和终止思考）是否能缩小这一差距。结果表明，这些机制有助于策略发现，但仍需进一步探索其他因素。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前研究表明MCRL模型可以学习新的规划策略并解释参与者的经验驱动型发现，但模型在策略发现速度上显著慢于人类。因此，研究者希望探索将可能促进人类策略发现的认知机制纳入模型是否能提高其性能以接近人类水平。

**方法:** 研究分析了规划任务数据，并测试了三种认知机制对策略发现的影响：1) 元认知伪奖励；2) 主观努力评估；3) 终止思考。通过比较参与者的行为模式和模型拟合结果，评估这些机制的使用频率及其对策略发现的影响。

**结果:** 数据分析显示，大多数参与者至少使用了一种上述机制，且个体间存在显著差异。这些机制对策略发现具有促进作用，但即使加入这些增强功能，模型性能仍未完全达到人类水平。

**结论:** 虽然元认知伪奖励、主观努力评估和终止思考等机制为理解个体差异及策略发现提供了重要见解，但它们并未完全弥合模型与人类表现之间的差距。未来需要探索更多可能影响策略发现的因素。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Individual+differences+in+the+cognitive+mechanisms+of+planning+strategy+discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23519，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23519&send_immediately=true&force_search=false)

**原文摘要:** People employ efficient planning strategies. But how are these strategies
acquired? Previous research suggests that people can discover new planning
strategies through learning from reinforcements, a process known as
metacognitive reinforcement learning (MCRL). While prior work has shown that
MCRL models can learn new planning strategies and explain more participants'
experience-driven discovery better than alternative mechanisms, it also
revealed significant individual differences in metacognitive learning.
Furthermore, when fitted to human data, these models exhibit a slower rate of
strategy discovery than humans. In this study, we investigate whether
incorporating cognitive mechanisms that might facilitate human strategy
discovery can bring models of MCRL closer to human performance. Specifically,
we consider intrinsically generated metacognitive pseudo-rewards, subjective
effort valuation, and termination deliberation. Analysis of planning task data
shows that a larger proportion of participants used at least one of these
mechanisms, with significant individual differences in their usage and varying
impacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort
valuation, and learning the value of acting without further planning were found
to facilitate strategy discovery. While these enhancements provided valuable
insights into individual differences and the effect of these mechanisms on
strategy discovery, they did not fully close the gap between model and human
performance, prompting further exploration of additional factors that people
might use to discover new planning strategies.

</details>


### [191] [Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)](https://arxiv.org/abs/2505.23536)
*Janik-Vasily Benzin, Gyunam Park, Stefanie Rinderle-Ma*

**主要类别:** cs.AI

**概要:** 本论文提出了一种同步模型和事件抽象的形式基础，证明了通过模型抽象（MA）和事件日志抽象（EA）可以得到等价的过程模型，从而保持与实际行为的联系并扩展分析洞察。


<details>
  <summary>更多</summary>
  
**动机:** 在过程智能项目中，通常需要对从事件数据中发现的模型进行多次抽象以达到优化目标（如减少模型大小）。然而，目前缺乏一种技术能够在模型抽象的同时同步抽象底层事件日志，这会导致失去日志中包含的真实世界行为的依据，从而限制分析的深度和有效性。

**方法:** 作者提出了同步模型和事件抽象的形式基础，证明了通过模型抽象（MA）和从抽象事件日志中发现过程模型能够产生等价的过程模型。具体来说，使用非顺序保护的模型抽象技术（behavioral profile abstraction）作为示例，证明了该方法的可行性，并由此提出了一种新的事件抽象（EA）技术。

**结果:** 证明了同步模型和事件抽象的可行性，并提出了一种新的事件抽象技术，可以在不失去真实世界行为依据的情况下，对模型和事件数据进行有效的复杂性降低。

**结论:** 本研究为同步模型和事件抽象提供了理论支持，使得在进行模型抽象时能够同步处理事件日志，从而保持与实际行为的联系，增强了过程智能项目的分析能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Synchronizing+Process+Model+and+Event+Abstraction+for+Grounded+Process+Intelligence+%28Extended+Version%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23536&send_immediately=true&force_search=false)

**原文摘要:** Model abstraction (MA) and event abstraction (EA) are means to reduce
complexity of (discovered) models and event data. Imagine a process
intelligence project that aims to analyze a model discovered from event data
which is further abstracted, possibly multiple times, to reach optimality
goals, e.g., reducing model size. So far, after discovering the model, there is
no technique that enables the synchronized abstraction of the underlying event
log. This results in loosing the grounding in the real-world behavior contained
in the log and, in turn, restricts analysis insights. Hence, in this work, we
provide the formal basis for synchronized model and event abstraction, i.e., we
prove that abstracting a process model by MA and discovering a process model
from an abstracted event log yields an equivalent process model. We prove the
feasibility of our approach based on behavioral profile abstraction as
non-order preserving MA technique, resulting in a novel EA technique.

</details>


### [192] [SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](https://arxiv.org/abs/2505.23559)
*Kunlun Zhu, Jiaxun Zhang, Ziheng Qi, Nuoxing Shang, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You*

**主要类别:** cs.AI

**概要:** SafeScientist是一个增强AI驱动科学探索安全性和伦理责任的框架，通过多种防御机制确保研究过程的安全，并配以SciSafetyBench评估基准。实验表明，SafeScientist在不影响科学产出质量的情况下，将安全性提高了35%。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLM）代理在加速科学发现自动化方面取得了显著进展，但同时也引发了重要的伦理和安全问题。为系统地解决这些问题，需要一个专门设计的框架来提高AI驱动科学探索的安全性和伦理责任。

**方法:** SafeScientist框架通过主动拒绝不适当或高风险任务，强调研究过程中的安全性，并整合了多种防御机制，如提示监控、代理协作监控、工具使用监控和伦理审查组件。此外，还提出了SciSafetyBench基准，用于评估AI在科学环境中的安全性。

**结果:** 广泛的实验表明，SafeScientist相比传统AI科学家框架，安全性性能提高了35%，并且在面对多样化的对抗攻击方法时，其安全性管道的稳健性得到了严格验证。

**结论:** SafeScientist框架及其配套的SciSafetyBench基准提供了一个有效的方法来提升AI驱动科学研究的安全性和伦理责任，证明了其在实际应用中的价值和效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SafeScientist%3A+Toward+Risk-Aware+Scientific+Discoveries+by+LLM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23559，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23559&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in large language model (LLM) agents have significantly
accelerated scientific discovery automation, yet concurrently raised critical
ethical and safety concerns. To systematically address these challenges, we
introduce \textbf{SafeScientist}, an innovative AI scientist framework
explicitly designed to enhance safety and ethical responsibility in AI-driven
scientific exploration. SafeScientist proactively refuses ethically
inappropriate or high-risk tasks and rigorously emphasizes safety throughout
the research process. To achieve comprehensive safety oversight, we integrate
multiple defensive mechanisms, including prompt monitoring, agent-collaboration
monitoring, tool-use monitoring, and an ethical reviewer component.
Complementing SafeScientist, we propose \textbf{SciSafetyBench}, a novel
benchmark specifically designed to evaluate AI safety in scientific contexts,
comprising 240 high-risk scientific tasks across 6 domains, alongside 30
specially designed scientific tools and 120 tool-related risk tasks. Extensive
experiments demonstrate that SafeScientist significantly improves safety
performance by 35\% compared to traditional AI scientist frameworks, without
compromising scientific output quality. Additionally, we rigorously validate
the robustness of our safety pipeline against diverse adversarial attack
methods, further confirming the effectiveness of our integrated approach. The
code and data will be available at https://github.com/ulab-uiuc/SafeScientist.
\textcolor{red}{Warning: this paper contains example data that may be offensive
or harmful.}

</details>


### [193] [CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring](https://arxiv.org/abs/2505.23575)
*Benjamin Arnav, Pablo Bernabeu-Pérez, Nathan Helm-Burger, Tim Kostolansky, Hannes Whittingham, Mary Phuong*

**主要类别:** cs.AI

**概要:** 在AI模型自主性增强的情况下，确保它们不采取未被察觉的有害行动至关重要。本文研究了思维链（CoT）监控方法，并与仅监控最终行动的方法进行了比较。发现CoT监控在某些情况下能显著提高检测能力，但也可能因误导性推理而降低性能。为解决此问题，提出了一种混合协议，结合推理和最终输出评分，其表现优于单独的CoT或行动监控方法。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI模型部署的自主性增加，防止其采取未被察觉的有害行动变得尤为重要。因此，需要开发有效的监控机制以检测潜在的有害行为。

**方法:** 研究了Chain-of-Thought (CoT) 监控方法，其中较弱但可信的监控模型持续监督更强大但不可信模型的中间推理步骤。并与仅监控最终行动（action-only monitoring）的方法进行对比，测试环境为指示不可信模型在完成编码任务时追求有害的次要目标。还提出了一种混合协议，独立评分推理过程和最终输出并使用加权平均结合两者。

**结果:** CoT监控在action-only监控无法可靠识别破坏行为的情景中，提高了最高达27个百分点的检测率。但在更明显的破坏案例中，CoT痕迹可能包含误导性的推理，从而降低性能。提出的混合协议在所有测试模型和任务中始终优于CoT和action-only监控，对于微妙欺骗场景的检测率超过action-only监控四倍以上。

**结论:** CoT监控可以有效提升对AI模型有害行为的检测能力，但存在被误导性推理欺骗的风险。混合监控协议通过结合推理和最终输出的评分，提供了一种更鲁棒的监控解决方案，适用于各种任务和模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoT+Red-Handed%3A+Stress+Testing+Chain-of-Thought+Monitoring，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23575，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23575&send_immediately=true&force_search=false)

**原文摘要:** As AI models are deployed with increasing autonomy, it is important to ensure
they do not take harmful actions unnoticed. As a potential mitigation, we
investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor
model continuously oversees the intermediate reasoning steps of a more powerful
but untrusted model. We compare CoT monitoring to action-only monitoring, where
only final outputs are reviewed, in a red-teaming setup where the untrusted
model is instructed to pursue harmful side tasks while completing a coding
problem. We find that CoT monitoring improves detection by up to 27 percentage
points in scenarios where action-only monitoring fails to reliably identify
sabotage. However, CoT traces can also contain misleading rationalizations that
deceive the monitor, reducing performance in more obvious sabotage cases. To
address this, we introduce a hybrid protocol that independently scores both
reasoning and final outputs and combines them using a weighted average. This
hybrid monitor consistently outperforms both CoT and action-only monitors
across all tested models and tasks, with detection rates over four times higher
than action-only monitoring for subtle deception scenarios.

</details>


### [194] [MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning](https://arxiv.org/abs/2505.23596)
*Linqiang Guo, Wei Liu, Yi Wen Heng, Tse-Hsun, Chen, Yang Wang*

**主要类别:** cs.AI

**概要:** MAPLE是一种状态感知的多代理框架，将应用程序交互建模为有限状态机（FSM），通过规划、执行、验证、错误恢复和知识保留五个阶段的专门代理协作来提高任务成功率、恢复成功率和动作准确性。在Mobile-Eval-E和SPA-Bench基准测试中，相比现有方法，MAPLE提升了任务成功率（最多12%）、恢复成功率（13.8%）和动作准确性（6.5%）。


<details>
  <summary>更多</summary>
  
**动机:** 现有的移动GUI代理仅基于当前屏幕进行推理，缺乏对应用导航流程的结构化模型，导致其在理解上下文、检测意外结果和从错误中恢复方面存在局限性。

**方法:** MAPLE将UI屏幕建模为离散状态，用户动作为状态转移，形成有限状态机(FSM)。框架包含四个阶段：规划、执行、验证和错误恢复，并通过提取UI屏幕的感知数据动态构建FSM。此外，MAPLE还包括一个知识保留阶段以保存先前稳定的状态信息。

**结果:** 在Mobile-Eval-E和SPA-Bench两个具有挑战性的跨应用基准上，MAPLE相较于最先进的基线方法，在任务成功率上提高了多达12%，恢复成功率达到13.8%，动作准确性提高了6.5%。

**结论:** 结构化的状态建模对于指导移动GUI代理在任务执行过程中至关重要。提出的FSM表示可以集成到未来的GUI代理架构中，作为一个轻量级且与模型无关的记忆层，支持结构化规划、执行验证和错误恢复。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAPLE%3A+A+Mobile+Assistant+with+Persistent+Finite+State+Machines+for+Recovery+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23596，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23596&send_immediately=true&force_search=false)

**原文摘要:** Mobile GUI agents aim to autonomously complete user-instructed tasks across
mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable
these agents to interpret UI screens, identify actionable elements, and perform
interactions such as tapping or typing. However, existing agents remain
reactive: they reason only over the current screen and lack a structured model
of app navigation flow, limiting their ability to understand context, detect
unexpected outcomes, and recover from errors. We present MAPLE, a state-aware
multi-agent framework that abstracts app interactions as a Finite State Machine
(FSM). We computationally model each UI screen as a discrete state and user
actions as transitions, allowing the FSM to provide a structured representation
of the app execution. MAPLE consists of specialized agents responsible for four
phases of task execution: planning, execution, verification, error recovery,
and knowledge retention. These agents collaborate to dynamically construct FSMs
in real time based on perception data extracted from the UI screen, allowing
the GUI agents to track navigation progress and flow, validate action outcomes
through pre- and post-conditions of the states, and recover from errors by
rolling back to previously stable states. Our evaluation results on two
challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE
outperforms the state-of-the-art baseline, improving task success rate by up to
12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results
highlight the importance of structured state modeling in guiding mobile GUI
agents during task execution. Moreover, our FSM representation can be
integrated into future GUI agent architectures as a lightweight, model-agnostic
memory layer to support structured planning, execution verification, and error
recovery.

</details>


### [195] [Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models](https://arxiv.org/abs/2505.23667)
*Lang Cao, Jingxian Xu, Hanbing Liu, Jinyu Wang, Mengyu Zhou, Haoyu Dong, Shi Han, Dongmei Zhang*

**主要类别:** cs.AI

**概要:** 本文提出了一种名为Formula Tuning（Fortune）的强化学习框架，用于训练大型语言模型生成可执行的电子表格公式以进行表格数据的问题回答。该方法减少了对监督公式的依赖，通过使用答案正确性作为奖励信号来引导模型进行推理式公式推导。实验表明，Formula Tuning显著提高了大型语言模型在多步数值和符号推理任务上的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型具备强大的通用推理能力，但在处理表格数据时，尤其在复杂场景下的数值或符号推理方面仍存在不足。因此需要一种新的方法来增强语言模型在这方面的推理能力。

**方法:** 提出了一个名为Formula Tuning（Fortune）的强化学习框架，该框架通过使用二元答案正确性作为奖励信号来训练大型语言模型生成可执行的电子表格公式。这种方法降低了对监督公式注释的依赖，并通过推理引导模型学习公式推导。

**结果:** 通过广泛的实验验证，Formula Tuning显著增强了大型语言模型在多个表格推理基准上的表现，尤其是在多步数值和符号推理任务上。一个7B参数的模型在表格理解任务上超越了O1模型。

**结论:** Formula Tuning展示了其在提高大型语言模型符号表格推理能力方面的潜力，强调了公式驱动的强化学习对于推进这一领域的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fortune%3A+Formula-Driven+Reinforcement+Learning+for+Symbolic+Table+Reasoning+in+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23667，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23667&send_immediately=true&force_search=false)

**原文摘要:** Tables are a fundamental structure for organizing and analyzing data, making
effective table understanding a critical capability for intelligent systems.
While large language models (LMs) demonstrate strong general reasoning
abilities, they continue to struggle with accurate numerical or symbolic
reasoning over tabular data, especially in complex scenarios. Spreadsheet
formulas provide a powerful and expressive medium for representing executable
symbolic operations, encoding rich reasoning patterns that remain largely
underutilized. In this paper, we propose Formula Tuning (Fortune), a
reinforcement learning (RL) framework that trains LMs to generate executable
spreadsheet formulas for question answering over general tabular data. Formula
Tuning reduces the reliance on supervised formula annotations by using binary
answer correctness as a reward signal, guiding the model to learn formula
derivation through reasoning. We provide a theoretical analysis of its
advantages and demonstrate its effectiveness through extensive experiments on
seven table reasoning benchmarks. Formula Tuning substantially enhances LM
performance, particularly on multi-step numerical and symbolic reasoning tasks,
enabling a 7B model to outperform O1 on table understanding. This highlights
the potential of formula-driven RL to advance symbolic table reasoning in LMs.

</details>


### [196] [ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork](https://arxiv.org/abs/2505.23686)
*Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone*

**主要类别:** cs.AI

**概要:** 这篇论文提出了一种名为ROTATE的新算法，通过将Ad Hoc Teamwork问题重新定义为开放性学习过程来提升AI代理在未知伙伴合作中的泛化能力。实验表明，该方法显著优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Ad Hoc Teamwork方法通常采用两阶段管道，但存在队友行为覆盖有限、难以学习以及训练过程中队友集静态不变的问题。因此，需要一种统一框架以改进泛化能力。

**方法:** 论文引入了ROTATE算法，基于后悔驱动的开放性训练方法，在提升AHT代理能力的同时生成探查其缺陷的队友。

**结果:** 在多种AHT环境中进行的广泛实验证明，ROTATE在面对未见过的评估队友时显著优于基线模型。

**结论:** ROTATE算法为更强大和可泛化的团队合作设定了新标准，解决了现有方法中队友行为覆盖不足和学习困难的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ROTATE%3A+Regret-driven+Open-ended+Training+for+Ad+Hoc+Teamwork，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23686&send_immediately=true&force_search=false)

**原文摘要:** Developing AI agents capable of collaborating with previously unseen partners
is a fundamental generalization challenge in multi-agent learning, known as Ad
Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage
pipeline, where first, a fixed population of teammates is generated with the
idea that they should be representative of the teammates that will be seen at
deployment time, and second, an AHT agent is trained to collaborate well with
agents in the population. To date, the research community has focused on
designing separate algorithms for each stage. This separation has led to
algorithms that generate teammate pools with limited coverage of possible
behaviors, and that ignore whether the generated teammates are easy to learn
from for the AHT agent. Furthermore, algorithms for training AHT agents
typically treat the set of training teammates as static, thus attempting to
generalize to previously unseen partner agents without assuming any control
over the distribution of training teammates. In this paper, we present a
unified framework for AHT by reformulating the problem as an open-ended
learning process between an ad hoc agent and an adversarial teammate generator.
We introduce ROTATE, a regret-driven, open-ended training algorithm that
alternates between improving the AHT agent and generating teammates that probe
its deficiencies. Extensive experiments across diverse AHT environments
demonstrate that ROTATE significantly outperforms baselines at generalizing to
an unseen set of evaluation teammates, thus establishing a new standard for
robust and generalizable teamwork.

</details>


### [197] [Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics](https://arxiv.org/abs/2505.23695)
*Ran Zhang, Mohannad Elhamod*

**主要类别:** cs.AI

**概要:** The paper presents a modular LLM-based agentic system that automates the data-to-dashboard pipeline, showcasing improved insightfulness, domain relevance, and analytical depth compared to GPT-4o in three cross-domain datasets.


<details>
  <summary>更多</summary>
  
**动机:** To leverage LLMs' capabilities for enhancing data analysis and visualization by creating an automated, adaptable system that simulates business analysts' reasoning process without relying on closed ontologies or question templates.

**方法:** Developed an agentic system with modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. This system retrieves domain-relevant knowledge and adapts to various datasets.

**结果:** Evaluated on three datasets across different domains, the system outperformed GPT-4o with a single-prompt baseline in terms of insightfulness, domain relevance, and analytical depth as per tailored evaluation metrics and qualitative human assessment.

**结论:** This work introduces a novel modular pipeline bridging raw data to visualization, offering new opportunities for human-in-the-loop validation by domain experts in business analytics.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-to-Dashboard%3A+Multi-Agent+LLM+Framework+for+Insightful+Visualization+in+Enterprise+Analytics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23695，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23695&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of LLMs has led to the creation of diverse agentic
systems in data analysis, utilizing LLMs' capabilities to improve insight
generation and visualization. In this paper, we present an agentic system that
automates the data-to-dashboard pipeline through modular LLM agents capable of
domain detection, concept extraction, multi-perspective analysis generation,
and iterative self-reflection. Unlike existing chart QA systems, our framework
simulates the analytical reasoning process of business analysts by retrieving
domain-relevant knowledge and adapting to diverse datasets without relying on
closed ontologies or question templates.
  We evaluate our system on three datasets across different domains.
Benchmarked against GPT-4o with a single-prompt baseline, our approach shows
improved insightfulness, domain relevance, and analytical depth, as measured by
tailored evaluation metrics and qualitative human assessment.
  This work contributes a novel modular pipeline to bridge the path from raw
data to visualization, and opens new opportunities for human-in-the-loop
validation by domain experts in business analytics. All code can be found here:
https://github.com/77luvC/D2D_Data2Dashboard

</details>


### [198] [Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability](https://arxiv.org/abs/2505.23703)
*Ruida Wang, Yuxin Li, Yi R., Fung, Tong Zhang*

**主要类别:** cs.AI

**概要:** 通过引入NL-FL HybridReasoning框架，结合自然语言和形式语言推理能力，显著提升了数学推理任务的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 增强大语言模型（LLMs）的数学推理能力在数学和计算机科学领域备受关注。然而，纯强化学习（RL）方法虽然取得进展，但难以赋予基础模型未具备的新能力，因此需要有效整合形式语言（FL）知识到自然语言（NL）数学推理中。但由于NL和FL在问题结构和推理格式上的差异，这种整合具有挑战性。

**方法:** 提出了一种端到端框架NL-FL HybridReasoning，将形式语言专家融入自然语言数学问题解决中。具体方法包括：1) NL-FL Problem Alignment方法，将自然语言中的问答问题转化为形式语言中的存在定理；2) Mixed Problem Input技术，使形式语言推理器能够同时处理问答和存在性问题；3) 基于LLM的Answer Extraction机制，弥合自然语言和形式语言输出格式之间的差距。

**结果:** 实验结果表明，HybridReasoning框架在MATH-500和AMC基准测试中分别达到了89.80%和84.34%的准确率，比仅使用自然语言基线模型分别高出4.60%和4.82%。值得注意的是，有些问题即使在更多的尝试次数下，也仅能被该框架成功解决而不能被NL基线模型解决。

**结论:** NL-FL HybridReasoning框架有效地整合了形式语言和自然语言的推理能力，在数学推理任务上展现了优越性能，为未来进一步提升LLMs数学推理能力提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Let%27s+Reason+Formally%3A+Natural-Formal+Hybrid+Reasoning+Enhances+LLM%27s+Math+Capability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23703&send_immediately=true&force_search=false)

**原文摘要:** Enhancing the mathematical reasoning capabilities of LLMs has garnered
significant attention in both the mathematical and computer science
communities. Recent works have made substantial progress in both Natural
Language (NL) reasoning and Formal Language (FL) reasoning by leveraging the
potential of pure Reinforcement Learning (RL) methods on base models. However,
RL approaches struggle to impart new capabilities not presented in the base
model, highlighting the need to integrate more knowledge like FL into NL math
reasoning effectively. Yet, this integration is challenging due to inherent
disparities in problem structure and reasoning format between NL and FL. To
address these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end
framework designed to incorporate the FL expert into NL math problem-solving.
To bridge the NL and FL input format gap, we propose the *NL-FL Problem
Alignment* method, which reformulates the Question-Answering (QA) problems in
NL as existence theorems in FL. Subsequently, the *Mixed Problem Input*
technique we provide enables the FL reasoner to handle both QA and existence
problems concurrently. Lastly, we mitigate the NL and FL output format gap in
reasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive
experiments demonstrate that the **HybridReasoning** framework achieves
**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC
benchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.
Notably, some problems resolved by our framework remain unsolved by the NL
baseline model even under a larger number of trials.

</details>


### [199] [Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons](https://arxiv.org/abs/2505.23746)
*Hugo Henry, Kelly Cohen*

**主要类别:** cs.AI

**概要:** The study explores the use of Genetic Fuzzy Systems (GFS) to model airfoil self-noise, comparing different fuzzy regression strategies including brute force TSK, cascading GFT, and a novel FCM-based clustered approach.


<details>
  <summary>更多</summary>
  
**动机:** To address the challenge of modeling airfoil self-noise which is crucial for aerospace, automotive, and drone applications.

**方法:** Using the Airfoil Self Noise dataset, the study compares various fuzzy regression methods: a high rule density Takagi Sugeno Kang (TSK) system, a cascading Genetic Fuzzy Tree (GFT), and a new Fuzzy C-means (FCM) clustering method.

**结果:** Clustering-assisted fuzzy inference was found to be an effective tool for complex aeroacoustic regression tasks, with the novel FCM-based approach showing promise in reducing model complexity.

**结论:** Genetic Fuzzy Systems, particularly when combined with clustering techniques, are viable for modeling complex aeroacoustic phenomena like airfoil self-noise.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+of+Genetic+Fuzzy+regression+techniques+for+aeroacoustic+phenomenons，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23746，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23746&send_immediately=true&force_search=false)

**原文摘要:** This study investigates the application of Genetic Fuzzy Systems (GFS) to
model the self-noise generated by airfoils, a key issue in aeroaccoustics with
significant implications for aerospace, automotive and drone applications.
Using the publicly available Airfoil Self Noise dataset, various Fuzzy
regression strategies are explored and compared. The paper evaluates a brute
force Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading
Geneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on
Fuzzy C-means (FCM) to reduce the model's complexity. This highlights the
viability of clustering assisted fuzzy inference as an effective regression
tool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression,
Cascading systems, Clustering and AI.

</details>


### [200] [ZeroGUI: Automating Online GUI Learning at Zero Human Cost](https://arxiv.org/abs/2505.23762)
*Chenyu Yang, Shiqian Su, Shi Liu, Xuan Dong, Yue Yu, Weijie Su, Xuehui Wang, Zhaoyang Liu, Jinguo Zhu, Hao Li, Wenhai Wang, Yu Qiao, Xizhou Zhu, Jifeng Dai*

**主要类别:** cs.AI

**概要:** ZeroGUI 是一个可扩展的在线学习框架，用于以零人工成本自动化 GUI 代理训练。它通过 VLM 基础的自动任务生成、奖励评估和两阶段在线强化学习来解决现有方法对人工标注的依赖和适应性差的问题，在多个环境中显著提升了性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的纯视觉 GUI 代理方法采用离线学习框架，依赖高质量的人工注释且在动态交互环境中适应性有限。

**方法:** 提出 ZeroGUI 框架，包含：(i) 基于 VLM 的自动任务生成；(ii) 基于 VLM 的自动奖励评估；(iii) 两阶段在线强化学习。

**结果:** 在 OSWorld 和 AndroidLab 环境中，使用两个高级 GUI 代理（UI-TARS 和 Aguvis）进行的实验表明，ZeroGUI 显著提高了性能。

**结论:** ZeroGUI 提供了一种零人工成本的自动化 GUI 代理训练方法，增强了代理在动态环境中的适应能力，并显著提升了性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ZeroGUI%3A+Automating+Online+GUI+Learning+at+Zero+Human+Cost，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23762，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23762&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of large Vision-Language Models (VLMs) has propelled
the development of pure-vision-based GUI Agents, capable of perceiving and
operating Graphical User Interfaces (GUI) to autonomously fulfill user
instructions. However, existing approaches usually adopt an offline learning
framework, which faces two core limitations: (1) heavy reliance on high-quality
manual annotations for element grounding and action supervision, and (2)
limited adaptability to dynamic and interactive environments. To address these
limitations, we propose ZeroGUI, a scalable, online learning framework for
automating GUI Agent training at Zero human cost. Specifically, ZeroGUI
integrates (i) VLM-based automatic task generation to produce diverse training
goals from the current environment state, (ii) VLM-based automatic reward
estimation to assess task success without hand-crafted evaluation functions,
and (iii) two-stage online reinforcement learning to continuously interact with
and learn from GUI environments. Experiments on two advanced GUI Agents
(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance
across OSWorld and AndroidLab environments. The code is available at
https://github.com/OpenGVLab/ZeroGUI.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [201] [Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games](https://arxiv.org/abs/2505.22781)
*Antonio Ocello, Daniil Tiapkin, Lorenzo Mancini, Mathieu Laurière, Eric Moulines*

**主要类别:** stat.ML

**概要:** 提出了一种新算法MF-TRPO，用于计算有限状态动作空间中平均场博弈的近似纳什均衡。该算法基于TRPO在强化学习中的成功表现，扩展了其方法论以适应平均场博弈框架，并提供了理论收敛保证。


<details>
  <summary>更多</summary>
  
**动机:** 将强化学习技术与平均场决策相结合，解决复杂的多智能体问题。通过利用TRPO的稳定性与鲁棒性，优化平均场博弈中的策略。

**方法:** 引入MF-TRPO算法，在有限状态动作空间内计算平均场博弈的近似纳什均衡。扩展了TRPO方法至平均场博弈框架，并分析其性能。

**结果:** 在标准假设下，提供了严格的理论分析和收敛性保证，涵盖了算法的确切形式及其基于样本的形式，并推导出高概率保证和有限样本复杂度。

**结论:** 通过结合强化学习技术和平均场决策，为解决复杂多智能体问题提供了一种理论依据充分的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Finite-Sample+Convergence+Bounds+for+Trust+Region+Policy+Optimization+in+Mean-Field+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22781，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22781&send_immediately=true&force_search=false)

**原文摘要:** We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel
algorithm designed to compute approximate Nash equilibria for ergodic
Mean-Field Games (MFG) in finite state-action spaces. Building on the
well-established performance of TRPO in the reinforcement learning (RL)
setting, we extend its methodology to the MFG framework, leveraging its
stability and robustness in policy optimization. Under standard assumptions in
the MFG literature, we provide a rigorous analysis of MF-TRPO, establishing
theoretical guarantees on its convergence. Our results cover both the exact
formulation of the algorithm and its sample-based counterpart, where we derive
high-probability guarantees and finite sample complexity. This work advances
MFG optimization by bridging RL techniques with mean-field decision-making,
offering a theoretically grounded approach to solving complex multi-agent
problems.

</details>


### [202] [Highly Efficient and Effective LLMs with Multi-Boolean Architectures](https://arxiv.org/abs/2505.22811)
*Ba-Hien Tran, Van Minh Nguyen*

**主要类别:** stat.ML

**概要:** 本论文提出了一种新框架，将大语言模型转化为多核布尔参数，并首次在布尔域中直接微调，减少了复杂性并优于现有的低比特量化和二值化方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的权重二值化方法要么导致性能差（后训练二值化），要么复杂度高且效果不理想（训练感知二值化）。

**方法:** 引入一个新框架，将大语言模型转换为多核布尔参数，并在布尔域中直接微调，无需依赖昂贵的潜权值。

**结果:** 通过广泛的实验表明，该方法在多个大语言模型上优于最近的超低比特量化和二值化方法。

**结论:** 所提出的方法显著降低了微调和推理过程中的复杂性，并表现出优越的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Highly+Efficient+and+Effective+LLMs+with+Multi-Boolean+Architectures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22811，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22811&send_immediately=true&force_search=false)

**原文摘要:** Weight binarization has emerged as a promising strategy to drastically reduce
the complexity of large language models (LLMs). It is mainly classified into
two approaches: post-training binarization and finetuning with training-aware
binarization methods. The first approach, while having low complexity, leads to
significant loss of information from the original LLMs, resulting in poor
performance. The second approach, on the other hand, relies heavily on
full-precision latent weights for gradient approximation of binary weights,
which not only remains suboptimal but also introduces substantial complexity.
In this paper, we introduce a novel framework that effectively transforms LLMs
into multi-kernel Boolean parameters, for the first time, finetunes them
directly in the Boolean domain, eliminating the need for expensive latent
weights. This significantly reduces complexity during both finetuning and
inference. Through extensive and insightful experiments across a wide range of
LLMs, we demonstrate that our method outperforms recent ultra low-bit
quantization and binarization methods.

</details>


### [203] [Theoretical Foundations of the Deep Copula Classifier: A Generative Approach to Modeling Dependent Features](https://arxiv.org/abs/2505.22997)
*Agnideep Aich, Ashit Baran Aich, Bruce Wade*

**主要类别:** stat.ML

**概要:** 生成一个太长；没读的总结


<details>
  <summary>更多</summary>
  
**动机:** 描述本文中的动机

**方法:** 本文的方法

**结果:** 本文的结果

**结论:** 本文的结论

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Theoretical+Foundations+of+the+Deep+Copula+Classifier%3A+A+Generative+Approach+to+Modeling+Dependent+Features，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22997&send_immediately=true&force_search=false)

**原文摘要:** Traditional classifiers often assume feature independence or rely on overly
simplistic relationships, leading to poor performance in settings where
real-world dependencies matter. We introduce the Deep Copula Classifier (DCC),
a generative model that separates the learning of each feature's marginal
distribution from the modeling of their joint dependence structure via neural
network-parameterized copulas. For each class, lightweight neural networks are
used to flexibly and adaptively capture feature interactions, making DCC
particularly effective when classification is driven by complex dependencies.
We establish that DCC converges to the Bayes-optimal classifier under standard
conditions and provide explicit convergence rates of O(n^{-r/(2r + d)}) for
r-smooth copula densities. Beyond theoretical guarantees, we outline several
practical extensions, including high-dimensional scalability through vine and
factor copula architectures, semi-supervised learning via entropy
regularization, and online adaptation using streaming gradient methods. By
unifying statistical rigor with the representational power of neural networks,
DCC offers a mathematically grounded and interpretable framework for
dependency-aware classification.

</details>


### [204] [JAPAN: Joint Adaptive Prediction Areas with Normalising-Flows](https://arxiv.org/abs/2505.23196)
*Eshant English, Christoph Lippert*

**主要类别:** stat.ML

**概要:** JAPAN是一种基于密度的符合性预测框架，通过流模型估计预测密度并构建预测区域，相较于传统方法能提供更紧凑、适应性强且保持有限样本覆盖率保证的预测区域。


<details>
  <summary>更多</summary>
  
**动机:** 现有的符合性预测方法通常依赖于残差驱动的符合性评分，难以处理多模态分布，并倾向于生成过于保守且围绕均值的预测区域，无法捕捉复杂预测分布的真实形状。

**方法:** 提出了一种名为JAPAN的新框架，利用基于密度的符合性评分，通过流模型估计预测密度，并根据估计的密度评分构建预测区域，从而实现紧凑、可能不相连且上下文自适应的预测区域。

**结果:** 理论上证明了JAPAN的有效性，并在多变量回归和预测任务中进行了实证验证，显示其校准良好且预测区域更紧致，优于现有基线方法。还提供了增加框架灵活性的扩展。

**结论:** JAPAN为符合性预测提供了一种改进的方法，尤其适合处理复杂和多模态分布的任务，同时保留了有限样本覆盖率的保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是JAPAN%3A+Joint+Adaptive+Prediction+Areas+with+Normalising-Flows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23196，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23196&send_immediately=true&force_search=false)

**原文摘要:** Conformal prediction provides a model-agnostic framework for uncertainty
quantification with finite-sample validity guarantees, making it an attractive
tool for constructing reliable prediction sets. However, existing approaches
commonly rely on residual-based conformity scores, which impose geometric
constraints and struggle when the underlying distribution is multimodal. In
particular, they tend to produce overly conservative prediction areas centred
around the mean, often failing to capture the true shape of complex predictive
distributions. In this work, we introduce JAPAN (Joint Adaptive Prediction
Areas with Normalising-Flows), a conformal prediction framework that uses
density-based conformity scores. By leveraging flow-based models, JAPAN
estimates the (predictive) density and constructs prediction areas by
thresholding on the estimated density scores, enabling compact, potentially
disjoint, and context-adaptive regions that retain finite-sample coverage
guarantees. We theoretically motivate the efficiency of JAPAN and empirically
validate it across multivariate regression and forecasting tasks, demonstrating
good calibration and tighter prediction areas compared to existing baselines.
We also provide several \emph{extensions} adding flexibility to our proposed
framework.

</details>


### [205] [Stable Thompson Sampling: Valid Inference via Variance Inflation](https://arxiv.org/abs/2505.23260)
*Budhaditya Halder, Shubhayan Pan, Koulik Khamaru*

**主要类别:** stat.ML

**概要:** 这篇论文提出了一种名为Stable Thompson Sampling的算法变体，通过增加后验方差的对数因子，在几乎不影响标准Thompson Sampling性能的情况下，使得在非独立同分布数据下仍能获得渐近正态估计，并为模型参数构建置信区间提供了可能。


<details>
  <summary>更多</summary>
  
**动机:** 传统的Thompson Sampling算法尽管在理论上和实践中表现出色，但由于其自适应采样机制，为模型参数构建置信区间带来了挑战。因此需要一种改进方法，能够在保持算法性能的同时，提供有效的统计推断。

**方法:** 作者提出了一种名为Stable Thompson Sampling的算法，通过对后验方差增加一个对数因子，解决了非独立同分布数据下的统计推断问题。该方法保证了臂均值的渐近正态估计。

**结果:** 实验表明，Stable Thompson Sampling在只增加对数级别的遗憾（regret）代价下，能够实现有效的统计推断，并且与标准Thompson Sampling相比性能下降很小。

**结论:** 通过适度增加遗憾，可以实现有效的统计推断，揭示了在遗憾和统计推断有效性之间的一种权衡原则。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stable+Thompson+Sampling%3A+Valid+Inference+via+Variance+Inflation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23260&send_immediately=true&force_search=false)

**原文摘要:** We consider the problem of statistical inference when the data is collected
via a Thompson Sampling-type algorithm. While Thompson Sampling (TS) is known
to be both asymptotically optimal and empirically effective, its adaptive
sampling scheme poses challenges for constructing confidence intervals for
model parameters. We propose and analyze a variant of TS, called Stable
Thompson Sampling, in which the posterior variance is inflated by a logarithmic
factor. We show that this modification leads to asymptotically normal estimates
of the arm means, despite the non-i.i.d. nature of the data. Importantly, this
statistical benefit comes at a modest cost: the variance inflation increases
regret by only a logarithmic factor compared to standard TS. Our results reveal
a principled trade-off: by paying a small price in regret, one can enable valid
statistical inference for adaptive decision-making algorithms.

</details>


### [206] [The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation](https://arxiv.org/abs/2505.23445)
*Adrien Majka, El-Mahdi El-Mhamdi*

**主要类别:** stat.ML

**概要:** 研究了代理指标和目标之间的耦合对Goodhart定律的影响，发现轻尾目标与重尾差异情况下，过度优化与差异的重尾性成反比。


<details>
  <summary>更多</summary>
  
**动机:** 之前的工作中对于Goodhart定律的形式化研究通常基于简化的独立性假设和学习范式假设，本研究旨在缓解这些假设以更深入地探讨代理指标和目标之间的关系。

**方法:** 通过去除先前工作中的独立性假设和学习范式假设，分析代理指标和目标之间的耦合对Goodhart定律的影响。

**结果:** 在轻尾目标和轻尾差异的情况下，依赖性不会改变Goodhart效应的本质；但在轻尾目标和重尾差异的情况下，发现了一个例子，其中过度优化的发生率与目标和度量之间差异的重尾性成反比。

**结论:** 代理指标和目标之间的耦合会影响Goodhart定律的表现形式，在特定条件下（如轻尾目标和重尾差异），过度优化的程度与差异的重尾性相关。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Strong%2C+Weak+and+Benign+Goodhart%27s+law.+An+independence-free+and+paradigm-agnostic+formalisation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23445，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23445&send_immediately=true&force_search=false)

**原文摘要:** Goodhart's law is a famous adage in policy-making that states that ``When a
measure becomes a target, it ceases to be a good measure''. As machine learning
models and the optimisation capacity to train them grow, growing empirical
evidence reinforced the belief in the validity of this law without however
being formalised. Recently, a few attempts were made to formalise Goodhart's
law, either by categorising variants of it, or by looking at how optimising a
proxy metric affects the optimisation of an intended goal. In this work, we
alleviate the simplifying independence assumption, made in previous works, and
the assumption on the learning paradigm made in most of them, to study the
effect of the coupling between the proxy metric and the intended goal on
Goodhart's law. Our results show that in the case of light tailed goal and
light tailed discrepancy, dependence does not change the nature of Goodhart's
effect. However, in the light tailed goal and heavy tailed discrepancy case, we
exhibit an example where over-optimisation occurs at a rate inversely
proportional to the heavy tailedness of the discrepancy between the goal and
the metric. %

</details>


### [207] [Learning Parametric Distributions from Samples and Preferences](https://arxiv.org/abs/2505.23557)
*Marc Jourdan, Gizem Yüce, Nicolas Flammarion*

**主要类别:** stat.ML

**概要:** 近期在语言建模方面的进展强调了偏好反馈在提高模型性能方面的作用。本文研究了在连续参数分布中，偏好反馈如何改善参数估计的条件。通过观察来自未知分布的样本对及其相对偏好，我们发现基于偏好的M-估计量比仅基于样本的M-估计量具有更好的渐近方差，而确定性偏好进一步改善了这一结果。利用确定性偏好揭示的硬约束，我们提出了一种估计误差为$\mathcal{O}(1/n)$的估计器，这相较于仅使用样本能达到的$\Theta(1/\sqrt{n})$速率有了显著改进。此外，我们还建立了与该加速速率相匹配的下界。虽然我们的分析假设较为严格，但它们适用于一些显著的情况，例如基于对数概率奖励的高斯或拉普拉斯分布的偏好。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，语言建模领域的进展表明，偏好反馈对于提升模型性能至关重要。因此，有必要研究在哪些条件下，偏好反馈能够改善连续参数分布中的参数估计。

**方法:** 本文构建了一个框架，在该框架中，学习者可以观察到来自未知分布的样本对以及其相对偏好。这些偏好依赖于同一个未知参数。通过比较基于偏好的M-估计量和仅基于样本的M-估计量，展示了前者的优越性。特别地，当偏好是确定性的时，这种优势更加明显。作者提出了一个新的估计器，利用确定性偏好揭示的硬约束，实现了$\mathcal{O}(1/n)$的估计误差缩放。

**结果:** 研究表明，基于偏好的M-估计量确实优于仅基于样本的M-估计量，尤其是在确定性偏好情况下。所提出的估计器达到了$\mathcal{O}(1/n)$的估计误差，远胜于仅使用样本时的$\Theta(1/\sqrt{n})$速率。此外，作者还证明了与此加速速率相匹配的理论下界。

**结论:** 本文揭示了偏好反馈在参数估计中的重要作用，特别是在连续参数分布的情况下。通过利用确定性偏好，可以显著提高估计精度。尽管分析假设较为严格，但结果适用于某些重要情况，如基于对数概率奖励的高斯或拉普拉斯分布的偏好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Parametric+Distributions+from+Samples+and+Preferences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23557，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23557&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in language modeling have underscored the role of preference
feedback in enhancing model performance. This paper investigates the conditions
under which preference feedback improves parameter estimation in classes of
continuous parametric distributions. In our framework, the learner observes
pairs of samples from an unknown distribution along with their relative
preferences depending on the same unknown parameter. We show that
preference-based M-estimators achieve a better asymptotic variance than
sample-only M-estimators, further improved by deterministic preferences.
Leveraging the hard constraints revealed by deterministic preferences, we
propose an estimator achieving an estimation error scaling of
$\mathcal{O}(1/n)$ -- a significant improvement over the $\Theta(1/\sqrt{n})$
rate attainable with samples alone. Next, we establish a lower bound that
matches this accelerated rate; up to dimension and problem-dependent constants.
While the assumptions underpinning our analysis are restrictive, they are
satisfied by notable cases such as Gaussian or Laplace distributions for
preferences based on the log-probability reward.

</details>


### [208] [Multilook Coherent Imaging: Theoretical Guarantees and Algorithms](https://arxiv.org/abs/2505.23594)
*Xi Chen, Soham Jana, Christopher A. Metzler, Arian Maleki, Shirin Jalali*

**主要类别:** stat.ML

**概要:** Multilook相干成像在数字全息、超声成像和合成孔径雷达等领域广泛应用，但其理论基础尚未被充分探索。本文研究了基于似然方法的多视相干成像的理论与算法方面，建立了最大似然估计器均方误差（MSE）的第一个理论上限，并提出结合Newton-Schulz算法和bagging策略优化投影梯度下降（PGD）的方法，以提高实际性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多视相干成像技术应用广泛，但由于乘性噪声（如斑点噪声）的存在，图像质量受到显著影响。此外，该领域的理论基础相对薄弱，需要更深入的研究来理解其性能极限并开发有效的算法。

**方法:** 本文首先分析了基于深度图像先验假设的最大似然估计器的理论性质，推导出均方误差（MSE）的首个理论上限。接着，在算法层面，采用了投影梯度下降（PGD）作为高效计算最大似然解的方法，并引入了两个改进措施：1）使用Newton-Schulz算法降低矩阵求逆的计算复杂度；2）通过bagging策略减少PGD更新过程中的投影误差。

**结果:** 理论结果表明，MSE的上界依赖于深度图像先验中的参数数量、视图数、信号维度和每视图测量数。实验验证显示，结合Newton-Schulz算法和bagging策略的PGD方法在实际性能上达到了最先进的水平。

**结论:** 本文为多视相干成像提供了严格的理论框架，并展示了如何通过优化算法实现高性能的图像重建。这些研究成果不仅加深了对该领域的理解，还为未来的技术发展奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilook+Coherent+Imaging%3A+Theoretical+Guarantees+and+Algorithms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23594，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23594&send_immediately=true&force_search=false)

**原文摘要:** Multilook coherent imaging is a widely used technique in applications such as
digital holography, ultrasound imaging, and synthetic aperture radar. A central
challenge in these systems is the presence of multiplicative noise, commonly
known as speckle, which degrades image quality. Despite the widespread use of
coherent imaging systems, their theoretical foundations remain relatively
underexplored. In this paper, we study both the theoretical and algorithmic
aspects of likelihood-based approaches for multilook coherent imaging,
providing a rigorous framework for analysis and method development. Our
theoretical contributions include establishing the first theoretical upper
bound on the Mean Squared Error (MSE) of the maximum likelihood estimator under
the deep image prior hypothesis. Our results capture the dependence of MSE on
the number of parameters in the deep image prior, the number of looks, the
signal dimension, and the number of measurements per look. On the algorithmic
side, we employ projected gradient descent (PGD) as an efficient method for
computing the maximum likelihood solution. Furthermore, we introduce two key
ideas to enhance the practical performance of PGD. First, we incorporate the
Newton-Schulz algorithm to compute matrix inverses within the PGD iterations,
significantly reducing computational complexity. Second, we develop a bagging
strategy to mitigate projection errors introduced during PGD updates. We
demonstrate that combining these techniques with PGD yields state-of-the-art
performance. Our code is available at
https://github.com/Computational-Imaging-RU/Bagged-DIP-Speckle.

</details>


### [209] [Instance-Optimality for Private KL Distribution Estimation](https://arxiv.org/abs/2505.23620)
*Jiayuan Ye, Vitaly Feldman, Kunal Talwar*

**主要类别:** stat.ML

**概要:** 研究了在给定n个独立同分布样本的情况下，估计一个未知的离散分布p的问题。首先构建了最小最大最优私有估计器，然后从实例最优性的角度研究该问题，并提出了在有或没有差分隐私约束下达到实例最优性的算法。上下界分别依赖于Good-Turing估计器的（私有）变体和加法局部邻域。


<details>
  <summary>更多</summary>
  
**动机:** 估计未知离散分布是统计学中的基本问题。虽然最小最大最优估计器在理论上表现良好，但它们在实际分布上的性能可能较差。因此，需要从实例最优性的角度来研究这一问题，以更好地理解算法在个体实例上的表现。

**方法:** 1. 构建最小最大最优私有估计器。
2. 从实例最优性的视角出发，定义局部邻域。
3. 提出在有或没有差分隐私约束下达到实例最优性的算法。
4. 使用Good-Turing估计器的（私有）变体作为上界，使用加法局部邻域作为下界。

**结果:** 提出的算法在实例最优性方面达到了常数因子内的最优，并且能够处理有或没有差分隐私约束的情况。上下界分析表明，所用方法比先前工作更精确地捕捉了KL散度中分布估计的难度。

**结论:** 本研究提供了从实例最优性和差分隐私角度对离散分布估计问题的深入理解，并提出了优于传统最小最大方法的估计器。未来可以探索更广泛的局部邻域定义和其他性能度量标准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Instance-Optimality+for+Private+KL+Distribution+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23620，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23620&send_immediately=true&force_search=false)

**原文摘要:** We study the fundamental problem of estimating an unknown discrete
distribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the
distribution. We are interested in minimizing the KL divergence between the
true distribution and the algorithm's estimate. We first construct minimax
optimal private estimators. Minimax optimality however fails to shed light on
an algorithm's performance on individual (non-worst-case) instances $p$ and
simple minimax-optimal DP estimators can have poor empirical performance on
real distributions. We then study this problem from an instance-optimality
viewpoint, where the algorithm's error on $p$ is compared to the minimum
achievable estimation error over a small local neighborhood of $p$. Under
natural notions of local neighborhood, we propose algorithms that achieve
instance-optimality up to constant factors, with and without a differential
privacy constraint. Our upper bounds rely on (private) variants of the
Good-Turing estimator. Our lower bounds use additive local neighborhoods that
more precisely captures the hardness of distribution estimation in KL
divergence, compared to ones considered in prior works.

</details>


### [210] [On the Convergence Analysis of Muon](https://arxiv.org/abs/2505.23737)
*Wei Shen, Ruichuan Huang, Minhui Huang, Cong Shen, Jiawei Zhang*

**主要类别:** stat.ML

**概要:** 提出了一种新的优化器Muon，其在神经网络训练中显著优于传统优化器。本文通过理论和实验分析了Muon的收敛性及其优于梯度下降（GD）的原因，发现其得益于Hessian矩阵的低秩和近似块对角结构特性。


<details>
  <summary>更多</summary>
  
**动机:** 大多数神经网络参数以矩阵形式存在，但常用优化器在优化时将其视为扁平向量，可能忽略了其固有的结构特性。因此，需要研究一种能够利用这些结构特性的优化器，如Muon，并深入理解其性能优势的理论基础。

**方法:** 作者对Muon优化器进行了全面的收敛速度分析，并与梯度下降（GD）进行了比较。同时，进一步探讨了Muon优于GD的条件，揭示了其从Hessian矩阵的低秩和近似块对角结构中获益的机制。

**结果:** 理论结果表明，Muon可以从Hessian矩阵的低秩和近似块对角结构中受益，这种现象在实际神经网络训练中很常见。实验结果验证并支持了这一理论发现。

**结论:** Muon优化器在神经网络训练中表现出色，其优越性源于对Hessian矩阵结构特性的有效利用。本文的理论和实证研究为理解Muon的收敛行为提供了重要依据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Convergence+Analysis+of+Muon，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23737&send_immediately=true&force_search=false)

**原文摘要:** The majority of parameters in neural networks are naturally represented as
matrices. However, most commonly used optimizers treat these matrix parameters
as flattened vectors during optimization, potentially overlooking their
inherent structural properties. Recently, an optimizer called Muon has been
proposed, specifically designed to optimize matrix-structured parameters.
Extensive empirical evidence shows that Muon can significantly outperform
traditional optimizers when training neural networks. Nonetheless, the
theoretical understanding of Muon's convergence behavior and the reasons behind
its superior performance remain limited. In this work, we present a
comprehensive convergence rate analysis of Muon and its comparison with
Gradient Descent (GD). We further characterize the conditions under which Muon
can outperform GD. Our theoretical results reveal that Muon can benefit from
the low-rank and approximate blockwise diagonal structure of Hessian matrices
-- phenomena widely observed in practical neural network training. Our
experimental results support and corroborate the theoretical findings.

</details>
