<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 123]
- [cs.AI](#cs.AI) [总数: 58]
- [stat.ML](#stat.ML) [总数: 17]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models](https://arxiv.org/abs/2505.15845)
*Zhibiao Wang, Yunlong Zhou, Ziwei Zhang, Mengmei Zhang, Shirui Pan, Chunming Hu, Xiao Wang*

**主要类别:** cs.LG

**概要:** 提出Learnable Graph Token List (LGTL)，解决现有Tokenized Graph Learning Models在异质图上的hop-overpriority问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有Tokenized Graph Learning Models依赖手工设计的token列表，适应性差且存在过重局部信号的问题。

**方法:** 提出LGTL模块，通过图注意力门和选择模块自适应调整节点权重。

**结果:** LGTL解决了hop-overpriority问题，并在多种基准数据集上验证了有效性。

**结论:** LGTL是一种通用的插件模块，可提升Graph Transformers和Graph LLM的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Tokenization%3A+On+the+Hop-Overpriority+Problem+in+Tokenized+Graph+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15845，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15845&send_immediately=true&force_search=false)

**原文摘要:** Graph Transformers, leveraging the global attention to capture long-range
dependencies in graph structures, have significantly advanced graph machine
learning, but face prohibitive computational complexity. Tokenized Graph
Learning Models (TGLMs) address this issue by converting graphs into ordered
token lists for scalable processing. Besides, TGLMs also empower Large Language
Models (LLMs) to handle text-attributed graphs more effectively and thus are
also employed in Graph LLMs. However, existing TGLMs rely on hand-designed
token lists and their adaptability to diverse graph learning scenarios remains
unexplored. In this paper, we first conduct extensive empirical and theoretical
preliminary studies for hand-designed token lists. Surprisingly, we identify an
unexplored hop-overpriority problem: the common pre-defined token lists
overemphasize nearby nodes and overwhelm the ability of TGLMs to balance local
and global signals. This phenomenon is especially harmful for heterophilic
graphs. To address this problem, we propose the Learnable Graph Token List
(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.
Specifically, LGTL adaptively adjusts the weights across hops and prioritizes
informative nodes within hops through a graph attention gate module and a
selection module, respectively. In this way, contextually informative nodes can
be adaptively emphasized for both homophilic and heterophilic graphs. Besides,
we theoretically show that LGTL can address the hop-overpriority problem.
Extensive experiments on benchmarks validate the efficacy of LGTL across both
Graph Transformers and Graph LLM backbones.

</details>


### [2] [Last Layer Empirical Bayes](https://arxiv.org/abs/2505.15888)
*Valentin Villecroze, Yixin Wang, Gabriel Loaiza-Ganem*

**主要类别:** cs.LG

**概要:** 提出了一种名为last layer empirical Bayes (LLEB)的新方法，该方法通过使用归一化流来实例化可学习先验，并在最后一层上训练以最大化证据下界，从而在不确定性量化方面表现良好。


<details>
  <summary>更多</summary>
  
**动机:** 量化神经网络预测中的固有不确定性是人工智能中的一个关键挑战。

**方法:** 提出了last layer empirical Bayes (LLEB)，它通过使用归一化流来实例化可学习先验，并在最后一层上训练以最大化证据下界。

**结果:** LLEB在不确定性量化方面表现良好，与现有方法相当。

**结论:** LLEB是一个有希望的方向，表明经验贝叶斯在未来不确定性量化研究中具有潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Last+Layer+Empirical+Bayes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15888，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15888&send_immediately=true&force_search=false)

**原文摘要:** The task of quantifying the inherent uncertainty associated with neural
network predictions is a key challenge in artificial intelligence. Bayesian
neural networks (BNNs) and deep ensembles are among the most prominent
approaches to tackle this task. Both approaches produce predictions by
computing an expectation of neural network outputs over some distribution on
the corresponding weights; this distribution is given by the posterior in the
case of BNNs, and by a mixture of point masses for ensembles. Inspired by
recent work showing that the distribution used by ensembles can be understood
as a posterior corresponding to a learned data-dependent prior, we propose last
layer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a
normalizing flow, which is then trained to maximize the evidence lower bound;
to retain tractability we use the flow only on the last layer. We show why LLEB
is well motivated, and how it interpolates between standard BNNs and ensembles
in terms of the strength of the prior that they use. LLEB performs on par with
existing approaches, highlighting that empirical Bayes is a promising direction
for future research in uncertainty quantification.

</details>


### [3] [Is (Selective) Round-To-Nearest Quantization All You Need?](https://arxiv.org/abs/2505.15909)
*Alex Kogan*

**主要类别:** cs.LG

**概要:** This paper challenges the notion that Round-to-Nearest (RTN) quantization is inferior to more advanced methods, demonstrating that RTN is cost-effective and can match or exceed their performance when selectively improving data precision.


<details>
  <summary>更多</summary>
  
**动机:** To demonstrate that RTN, a simple quantization method, is not only inexpensive but also competitive in performance with more complex methods.

**方法:** Implementation of RTN based on Marlin kernels and selective increase of data precision format in certain model layers/modules.

**结果:** RTN's token generation throughput can be better and accuracy similar to more advanced quantization techniques.

**结论:** RTN is a viable and practical option for quantizing large language models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Is+%28Selective%29+Round-To-Nearest+Quantization+All+You+Need%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15909，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15909&send_immediately=true&force_search=false)

**原文摘要:** Quantization became a necessary tool for serving ever-increasing Large
Language Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest
quantization technique that has been around well before LLMs surged to the
forefront of machine learning (ML) research. Yet, it has been largely dismissed
by recent and more advanced quantization methods that claim superiority over
RTN in nearly every aspect of performance. This work aims to dispel this
established point of view, showing that RTN is not only much cheaper to apply,
but also its token generation throughput can be better than and accuracy can be
similar to more advanced alternatives. In particular, we discuss our
implementation of RTN based on the recent Marlin kernels and demonstrate how
the accuracy of RTN can be gradually improved by selectively increasing the
data precision format of certain model layers and modules. Based on our
results, we argue that RTN presents a viable and practical choice for
quantizing LLMs.

</details>


### [4] [AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning](https://arxiv.org/abs/2505.15931)
*Morteza Alizadeh, Mehrdad Oveisi, Sonya Falahati, Ghazal Mousavi, Mohsen Alambardar Meybodi, Somayeh Sadat Mehrnia, Ilker Hacihaliloglu, Arman Rahmim, Mohammad R. Salmanpour*

**主要类别:** cs.LG

**概要:** 提出一个名为AllMetrics的Python库，旨在通过统一标准解决现有机器学习性能度量库中的不一致性问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有机器学习性能度量库存在碎片化、实现不一致和数据验证协议不足的问题，导致结果不可靠且难以跨框架比较。

**方法:** 开发AllMetrics库，提供跨多种机器学习任务的标准度量评估，包含可配置参数用于多类任务报告，并整合任务特定参数来解决计算差异。

**结果:** 在不同领域（如医疗、金融、房地产）的数据集上测试了AllMetrics，与Python、Matlab和R的组件进行了对比，验证了其可靠性。

**结论:** AllMetrics通过引入模块化API和强大的输入验证机制提高了模型评估的可靠性和可重复性，增强了机器学习工作流的信任度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AllMetrics%3A+A+Unified+Python+Library+for+Standardized+Metric+Evaluation+and+Robust+Data+Validation+in+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15931&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML) models rely heavily on consistent and accurate
performance metrics to evaluate and compare their effectiveness. However,
existing libraries often suffer from fragmentation, inconsistent
implementations, and insufficient data validation protocols, leading to
unreliable results. Existing libraries have often been developed independently
and without adherence to a unified standard, particularly concerning the
specific tasks they aim to support. As a result, each library tends to adopt
its conventions for metric computation, input/output formatting, error
handling, and data validation protocols. This lack of standardization leads to
both implementation differences (ID) and reporting differences (RD), making it
difficult to compare results across frameworks or ensure reliable evaluations.
To address these issues, we introduce AllMetrics, an open-source unified Python
library designed to standardize metric evaluation across diverse ML tasks,
including regression, classification, clustering, segmentation, and
image-to-image translation. The library implements class-specific reporting for
multi-class tasks through configurable parameters to cover all use cases, while
incorporating task-specific parameters to resolve metric computation
discrepancies across implementations. Various datasets from domains like
healthcare, finance, and real estate were applied to our library and compared
with Python, Matlab, and R components to identify which yield similar results.
AllMetrics combines a modular Application Programming Interface (API) with
robust input validation mechanisms to ensure reproducibility and reliability in
model evaluation. This paper presents the design principles, architectural
components, and empirical analyses demonstrating the ability to mitigate
evaluation errors and to enhance the trustworthiness of ML workflows.

</details>


### [5] [MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding](https://arxiv.org/abs/2505.15946)
*Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun*

**主要类别:** cs.LG

**概要:** 提出了一种基于神经启发的框架MoRE-Brain，用于高保真、可适应且可解释的视觉重建。该框架通过层次化的专家混合架构和新颖的双阶段路由机制实现了对功能相关体素组fMRI信号的独特处理，从而提高了跨受试者泛化能力和机制洞察力。实验验证了其高重建保真度并有效利用fMRI信号。


<details>
  <summary>更多</summary>
  
**动机:** 当前研究在最大化重建保真度的同时忽略了可解释性，而可解释性对于获得神经科学见解至关重要。

**方法:** 提出了MoRE-Brain框架，包括层次化的专家混合架构，首先将fMRI编码到冻结的CLIP空间，然后通过新颖的双阶段路由机制指导扩散模型合成图像。

**结果:** 实验验证了MoRE-Brain的高重建保真度，并通过瓶颈分析证明其有效利用了fMRI信号。

**结论:** MoRE-Brain标志着向更通用和可解释的基于fMRI的视觉解码迈出了重要一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoRE-Brain%3A+Routed+Mixture+of+Experts+for+Interpretable+and+Generalizable+Cross-Subject+fMRI+Visual+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15946，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15946&send_immediately=true&force_search=false)

**原文摘要:** Decoding visual experiences from fMRI offers a powerful avenue to understand
human perception and develop advanced brain-computer interfaces. However,
current progress often prioritizes maximizing reconstruction fidelity while
overlooking interpretability, an essential aspect for deriving neuroscientific
insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework
designed for high-fidelity, adaptable, and interpretable visual reconstruction.
MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture
where distinct experts process fMRI signals from functionally related voxel
groups, mimicking specialized brain networks. The experts are first trained to
encode fMRI into the frozen CLIP space. A finetuned diffusion model then
synthesizes images, guided by expert outputs through a novel dual-stage routing
mechanism that dynamically weighs expert contributions across the diffusion
process. MoRE-Brain offers three main advancements: First, it introduces a
novel Mixture-of-Experts architecture grounded in brain network principles for
neuro-decoding. Second, it achieves efficient cross-subject generalization by
sharing core expert networks while adapting only subject-specific routers.
Third, it provides enhanced mechanistic insight, as the explicit routing
reveals precisely how different modeled brain regions shape the semantic and
spatial attributes of the reconstructed image. Extensive experiments validate
MoRE-Brain's high reconstruction fidelity, with bottleneck analyses further
demonstrating its effective utilization of fMRI signals, distinguishing genuine
neural decoding from over-reliance on generative priors. Consequently,
MoRE-Brain marks a substantial advance towards more generalizable and
interpretable fMRI-based visual decoding. Code will be publicly available soon:
https://github.com/yuxiangwei0808/MoRE-Brain.

</details>


### [6] [Towards Identifiability of Interventional Stochastic Differential Equations](https://arxiv.org/abs/2505.15987)
*Aaron Zweig, Zaikang Lin, Elham Azizi, David Knowles*

**主要类别:** cs.LG

**概要:** 研究了随机微分方程模型在多种干预下的可识别性。给出了线性SDEs的紧界和小噪声条件下非线性SDEs的上界。实验验证了合成数据的真实参数恢复，并展示了具有可学习激活函数的参数化的优点。


<details>
  <summary>更多</summary>
  
**动机:** 研究随机微分方程模型在多种干预下的可识别性。

**方法:** 给出了线性SDEs的紧界和小噪声条件下非线性SDEs的上界。

**结果:** 证明了唯一恢复SDE参数的可证明界限。

**结论:** 实验验证了合成数据的真实参数恢复，并展示了具有可学习激活函数的参数化的优点。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Identifiability+of+Interventional+Stochastic+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15987&send_immediately=true&force_search=false)

**原文摘要:** We study identifiability of stochastic differential equation (SDE) models
under multiple interventions. Our results give the first provable bounds for
unique recovery of SDE parameters given samples from their stationary
distributions. We give tight bounds on the number of necessary interventions
for linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.
We experimentally validate the recovery of true parameters in synthetic data,
and motivated by our theoretical results, demonstrate the advantage of
parameterizations with learnable activation functions.

</details>


### [7] [Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations](https://arxiv.org/abs/2505.16004)
*Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju*

**主要类别:** cs.LG

**概要:** This paper evaluates sparse autoencoders (SAEs) used to interpret large language models (LLMs) and finds their concept representations are not robust against input perturbations.


<details>
  <summary>更多</summary>
  
**动机:** Existing evaluations of SAEs overlook the robustness of concept representations to input perturbations, which is crucial for concept labeling fidelity.

**方法:** Formulated robustness quantification as input-space optimization problems and developed an evaluation framework with adversarial perturbations.

**结果:** Tiny adversarial input perturbations can manipulate concept-based interpretations in most scenarios without significantly affecting the base LLM outputs.

**结论:** SAE concept representations are fragile and may not be suitable for applications in model monitoring and oversight.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretability+Illusions+with+Sparse+Autoencoders%3A+Evaluating+Robustness+of+Concept+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16004&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are commonly used to interpret the internal
activations of large language models (LLMs) by mapping them to
human-interpretable concept representations. While existing evaluations of SAEs
focus on metrics such as the reconstruction-sparsity tradeoff, human
(auto-)interpretability, and feature disentanglement, they overlook a critical
aspect: the robustness of concept representations to input perturbations. We
argue that robustness must be a fundamental consideration for concept
representations, reflecting the fidelity of concept labeling. To this end, we
formulate robustness quantification as input-space optimization problems and
develop a comprehensive evaluation framework featuring realistic scenarios in
which adversarial perturbations are crafted to manipulate SAE representations.
Empirically, we find that tiny adversarial input perturbations can effectively
manipulate concept-based interpretations in most scenarios without notably
affecting the outputs of the base LLMs themselves. Overall, our results suggest
that SAE concept representations are fragile and may be ill-suited for
applications in model monitoring and oversight.

</details>


### [8] [GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2505.16017)
*Mariia Seleznova, Hung-Hsu Chou, Claudio Mayrink Verdun, Gitta Kutyniok*

**主要类别:** cs.LG

**概要:** 提出GradPCA方法用于Out-of-Distribution检测，通过神经网络梯度的低秩结构实现更一致的表现。


<details>
  <summary>更多</summary>
  
**动机:** 利用神经网络梯度的低秩结构和Neural Tangent Kernel对齐特性，提供更有效的Out-of-Distribution检测。

**方法:** 在梯度类均值上应用主成分分析（PCA）的Out-of-Distribution检测方法GradPCA。

**结果:** GradPCA在标准图像分类基准测试中表现出了比现有方法更为一致的性能。

**结论:** 理论分析表明特征质量对检测器的成功至关重要，并且提出的框架可以指导设计更加原则性的频谱Out-of-Distribution检测器。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GradPCA%3A+Leveraging+NTK+Alignment+for+Reliable+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16017&send_immediately=true&force_search=false)

**原文摘要:** We introduce GradPCA, an Out-of-Distribution (OOD) detection method that
exploits the low-rank structure of neural network gradients induced by Neural
Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis
(PCA) to gradient class-means, achieving more consistent performance than
existing methods across standard image classification benchmarks. We provide a
theoretical perspective on spectral OOD detection in neural networks to support
GradPCA, highlighting feature-space properties that enable effective detection
and naturally emerge from NTK alignment. Our analysis further reveals that
feature quality -- particularly the use of pretrained versus non-pretrained
representations -- plays a crucial role in determining which detectors will
succeed. Extensive experiments validate the strong performance of GradPCA, and
our theoretical framework offers guidance for designing more principled
spectral OOD detectors.

</details>


### [9] [Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging](https://arxiv.org/abs/2505.16024)
*Weiguo Gao, Ming Li*

**主要类别:** cs.LG

**概要:** 提出了一种动态规划算法来计算最优合并策略，最大化保留信号保真度，并展示了在最佳策略中存在的尖锐相变现象。


<details>
  <summary>更多</summary>
  
**动机:** 解决扩散轨迹蒸馏方法中不同蒸馏策略与生成质量之间的权衡问题，优化和选择这些策略仍然有限的问题。

**方法:** 重新解释轨迹蒸馏为线性区域中的算子合并问题，在线性区域内每个教师模型的步骤被表示为作用于噪声数据的线性算子。

**结果:** 提出了一种动态规划算法来计算最优合并策略，最大化保留信号保真度，并展示了在最佳策略中存在的尖锐相变现象。

**结论:** 研究结果增强了对扩散轨迹蒸馏的理论理解，并提供了改进蒸馏策略的实际见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Toward+Theoretical+Insights+into+Diffusion+Trajectory+Distillation+via+Operator+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16024&send_immediately=true&force_search=false)

**原文摘要:** Diffusion trajectory distillation methods aim to accelerate sampling in
diffusion models, which produce high-quality outputs but suffer from slow
sampling speeds. These methods train a student model to approximate the
multi-step denoising process of a pretrained teacher model in a single step,
enabling one-shot generation. However, theoretical insights into the trade-off
between different distillation strategies and generative quality remain
limited, complicating their optimization and selection. In this work, we take a
first step toward addressing this gap. Specifically, we reinterpret trajectory
distillation as an operator merging problem in the linear regime, where each
step of the teacher model is represented as a linear operator acting on noisy
data. These operators admit a clear geometric interpretation as projections and
rescalings corresponding to the noise schedule. During merging, signal
shrinkage occurs as a convex combination of operators, arising from both
discretization and limited optimization time of the student model. We propose a
dynamic programming algorithm to compute the optimal merging strategy that
maximally preserves signal fidelity. Additionally, we demonstrate the existence
of a sharp phase transition in the optimal strategy, governed by data
covariance structures. Our findings enhance the theoretical understanding of
diffusion trajectory distillation and offer practical insights for improving
distillation strategies.

</details>


### [10] [Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces](https://arxiv.org/abs/2505.16035)
*Alejandro García-Castellanos, David R. Wessels, Nicky J. van den Berg, Remco Duits, Daniël M. Pelt, Erik J. Bekkers*

**主要类别:** cs.LG

**概要:** 提出了一种新的框架EquNet，通过结合等变神经场和神经Eikonal求解器来解决Eikonal方程，具有高效表示、几何稳健性和解决方案可控性，并在地震旅行时间建模中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 传统方法在解决Eikonal方程时缺乏灵活性和可控性，特别是在复杂几何结构上的表现不佳。

**方法:** 开发了一个包含统一共享主干网络的单个神经场，该网络根据特定信号的潜在变量（表示为李群中的点云）进行调节，确保从潜在表示到解场的等变映射。

**结果:** 提出的框架在二维和三维基准数据集的地震旅行时间建模应用中验证了其性能，实验结果显示其在性能、可扩展性、适应性和用户可控性方面优于现有的基于神经算子的方法。

**结论:** 所提出的EquNet框架展示了在解决Eikonal方程方面的优越性能，特别是在处理复杂的几何结构和多样化的场景时具有显著优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Eikonal+Neural+Networks%3A+Grid-Free%2C+Scalable+Travel-Time+Prediction+on+Homogeneous+Spaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16035，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16035&send_immediately=true&force_search=false)

**原文摘要:** We introduce Equivariant Neural Eikonal Solvers, a novel framework that
integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our
approach employs a single neural field where a unified shared backbone is
conditioned on signal-specific latent variables - represented as point clouds
in a Lie group - to model diverse Eikonal solutions. The ENF integration
ensures equivariant mapping from these latent representations to the solution
field, delivering three key benefits: enhanced representation efficiency
through weight-sharing, robust geometric grounding, and solution steerability.
This steerability allows transformations applied to the latent point cloud to
induce predictable, geometrically meaningful modifications in the resulting
Eikonal solution. By coupling these steerable representations with
Physics-Informed Neural Networks (PINNs), our framework accurately models
Eikonal travel-time solutions while generalizing to arbitrary Riemannian
manifolds with regular group actions. This includes homogeneous spaces such as
Euclidean, position-orientation, spherical, and hyperbolic manifolds. We
validate our approach through applications in seismic travel-time modeling of
2D and 3D benchmark datasets. Experimental results demonstrate superior
performance, scalability, adaptability, and user controllability compared to
existing Neural Operator-based Eikonal solver methods.

</details>


### [11] [Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs](https://arxiv.org/abs/2505.16053)
*Jan Tönshoff, Martin Grohe*

**主要类别:** cs.LG

**概要:** This work introduces RLAF, a novel approach that uses GNNs and reinforcement learning to improve SAT solver performance by optimizing branching heuristics, achieving significant speedups across various SAT problem distributions.


<details>
  <summary>更多</summary>
  
**动机:** To develop a data-driven method for improving the performance of SAT solvers by learning optimal branching heuristics instead of relying on hand-crafted ones.

**方法:** Using Reinforcement Learning from Algorithm Feedback (RLAF) with Graph Neural Networks (GNNs) to infer variable weights and polarities, casting this as a reinforcement learning problem, and training the GNN using policy-gradient methods with computational cost as the reward signal.

**结果:** Significantly reduced mean solve times of different base solvers across diverse SAT problem distributions, achieving more than a 2x speedup in some cases, while generalizing effectively to larger and harder problems.

**结论:** RLAF offers a promising direction for data-driven heuristic design in combinatorial optimization by consistently outperforming expert-supervised approaches.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+from+Algorithm+Feedback%3A+One-Shot+SAT+Solver+Guidance+with+GNNs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16053，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16053&send_immediately=true&force_search=false)

**原文摘要:** Boolean Satisfiability (SAT) solvers are foundational to computer science,
yet their performance typically hinges on hand-crafted heuristics. This work
introduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm
for learning to guide SAT solver branching heuristics with Graph Neural
Networks (GNNs). Central to our approach is a novel and generic mechanism for
injecting inferred variable weights and polarities into the branching
heuristics of existing SAT solvers. In a single forward pass, a GNN assigns
these parameters to all variables. Casting this one-shot guidance as a
reinforcement learning problem lets us train the GNN with off-the-shelf
policy-gradient methods, such as GRPO, directly using the solver's
computational cost as the sole reward signal. Extensive evaluations demonstrate
that RLAF-trained policies significantly reduce the mean solve times of
different base solvers across diverse SAT problem distributions, achieving more
than a 2x speedup in some cases, while generalizing effectively to larger and
harder problems after training. Notably, these policies consistently outperform
expert-supervised approaches based on learning handcrafted weighting
heuristics, offering a promising path towards data-driven heuristic design in
combinatorial optimization.

</details>


### [12] [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org/abs/2505.16056)
*Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei*

**主要类别:** cs.LG

**概要:** 本文提出了衡量MoE模型局部路由一致性的新方法，并通过实验发现了一些有助于更高效地设计和部署MoE模型的重要特性。


<details>
  <summary>更多</summary>
  
**动机:** 为了有效部署大型MoE模型到内存受限设备上，许多系统引入了专家卸载技术，但MoE模型中的局部路由一致性程度因模型而异且未被充分研究。

**方法:** 提出两种度量MoE模型局部路由一致性的指标：Segment Routing Best Performance (SRP) 和 Segment Cache Best Hit Rate (SCH)，并分析了20个不同规模和架构的MoE LLMs。

**结果:** 发现层内应用MoE且不使用共享专家的模型具有最高的局部路由一致性；领域专用专家比词汇专用专家对路由一致性贡献更大；大多数模型可以通过大约两倍于活跃专家大小的缓存来平衡缓存的有效性和效率。

**结论:** 研究发现，层内应用MoE且不使用共享专家的模型具有最高的局部路由一致性。领域专用专家比词汇专用专家对路由一致性贡献更大，并且大多数模型可以通过大约两倍于活跃专家大小的缓存来平衡缓存的有效性和效率。这些发现为在不影响推理速度的情况下设计和部署内存高效的MoE提供了途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Not+All+Models+Suit+Expert+Offloading%3A+On+Local+Routing+Consistency+of+Mixture-of-Expert+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16056，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16056&send_immediately=true&force_search=false)

**原文摘要:** Mixture-of-Experts (MoE) enables efficient scaling of large language models
(LLMs) with sparsely activated experts during inference. To effectively deploy
large MoE models on memory-constrained devices, many systems introduce *expert
offloading* that caches a subset of experts in fast memory, leaving others on
slow memory to run on CPU or load on demand. While some research has exploited
the locality of expert activations, where consecutive tokens activate similar
experts, the degree of this **local routing consistency** varies across models
and remains understudied. In this paper, we propose two metrics to measure
local routing consistency of MoE models: (1) **Segment Routing Best Performance
(SRP)**, which evaluates how well a fixed group of experts can cover the needs
of a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which
measures the optimal segment-level cache hit rate under a given cache size
limit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found
that models that apply MoE on every layer and do not use shared experts exhibit
the highest local routing consistency. We further showed that
domain-specialized experts contribute more to routing consistency than
vocabulary-specialized ones, and that most models can balance between cache
effectiveness and efficiency with cache sizes approximately 2x the active
experts. These findings pave the way for memory-efficient MoE design and
deployment without compromising inference speed. We publish the code for
replicating experiments at https://github.com/ljcleo/moe-lrc .

</details>


### [13] [Mesh-free sparse identification of nonlinear dynamics](https://arxiv.org/abs/2505.16058)
*Mars Liyao Gao, J. Nathan Kutz, Bernat Font*

**主要类别:** cs.LG

**概要:** 提出了一种名为mesh-free SINDy的新算法，可以从任意传感器位置和非均匀时间采样数据中识别动态系统的控制方程。该算法对高噪声水平和有限数据具有鲁棒性，并且在计算上高效。实验表明，即使在高噪声和低数据情况下，mesh-free SINDy也能成功识别偏微分方程。


<details>
  <summary>更多</summary>
  
**动机:** 传统方法需要高质量的空间-时间数据在结构化网格上均匀采样，而新算法可以处理任意传感器位置和非均匀时间采样数据。

**方法:** 利用神经网络近似和自动微分技术，提出了一种新的mesh-free SINDy算法。

**结果:** 在一系列偏微分方程（如Burgers方程、热方程、Korteweg-De Vries方程和二维对流扩散方程）上进行了详细的数值实验，证明了其有效性。

**结论:** mesh-free SINDy是一种广泛适用于科学和工程问题的强大工具，在高噪声和低数据情况下仍能有效识别偏微分方程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mesh-free+sparse+identification+of+nonlinear+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16058&send_immediately=true&force_search=false)

**原文摘要:** Identifying the governing equations of a dynamical system is one of the most
important tasks for scientific modeling. However, this procedure often requires
high-quality spatio-temporal data uniformly sampled on structured grids. In
this paper, we propose mesh-free SINDy, a novel algorithm which leverages the
power of neural network approximation as well as auto-differentiation to
identify governing equations from arbitrary sensor placements and non-uniform
temporal data sampling. We show that mesh-free SINDy is robust to high noise
levels and limited data while remaining computationally efficient. In our
implementation, the training procedure is straight-forward and nearly free of
hyperparameter tuning, making mesh-free SINDy widely applicable to many
scientific and engineering problems. In the experiments, we demonstrate its
effectiveness on a series of PDEs including the Burgers' equation, the heat
equation, the Korteweg-De Vries equation and the 2D advection-diffusion
equation. We conduct detailed numerical experiments on all datasets, varying
the noise levels and number of samples, and we also compare our approach to
previous state-of-the-art methods. It is noteworthy that, even in high-noise
and low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,
achieving successful identification with up to 75% noise for the Burgers'
equation using 5,000 samples and with as few as 100 samples and 1% noise. All
of this is achieved within a training time of under one minute.

</details>


### [14] [Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond](https://arxiv.org/abs/2505.16060)
*Shangding Gu, Donghao Ying, Ming Jin, Yu Joe Lu, Jun Wang, Javad Lavaei, Costas Spanos*

**主要类别:** cs.LG

**概要:** A new method called Model Feedback Learning (MFL) optimizes inputs for pre-trained AI models or hardware systems without retraining or modifications, achieving fast and effective adaptation to new objectives.


<details>
  <summary>更多</summary>
  
**动机:** To enable efficient adaptation to new objectives without retraining or modifying deployed systems.

**方法:** Uses a lightweight reverse model to iteratively search for optimal inputs.

**结果:** Outperforms Bayesian optimization and human experts in semiconductor plasma etching tasks, and shows strong performance in other applications like chemical vapor deposition and wire bonding.

**结论:** MFL provides a scalable and efficient way to deploy intelligent control in real-world environments with few-shot adaptation.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Few-Shot+Test-Time+Optimization+Without+Retraining+for+Semiconductor+Recipe+Generation+and+Beyond，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16060，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16060&send_immediately=true&force_search=false)

**原文摘要:** We introduce Model Feedback Learning (MFL), a novel test-time optimization
framework for optimizing inputs to pre-trained AI models or deployed hardware
systems without requiring any retraining of the models or modifications to the
hardware. In contrast to existing methods that rely on adjusting model
parameters, MFL leverages a lightweight reverse model to iteratively search for
optimal inputs, enabling efficient adaptation to new objectives under
deployment constraints. This framework is particularly advantageous in
real-world settings, such as semiconductor manufacturing recipe generation,
where modifying deployed systems is often infeasible or cost-prohibitive. We
validate MFL on semiconductor plasma etching tasks, where it achieves target
recipe generation in just five iterations, significantly outperforming both
Bayesian optimization and human experts. Beyond semiconductor applications, MFL
also demonstrates strong performance in chemical processes (e.g., chemical
vapor deposition) and electronic systems (e.g., wire bonding), highlighting its
broad applicability. Additionally, MFL incorporates stability-aware
optimization, enhancing robustness to process variations and surpassing
conventional supervised learning and random search methods in high-dimensional
control settings. By enabling few-shot adaptation, MFL provides a scalable and
efficient paradigm for deploying intelligent control in real-world
environments.

</details>


### [15] [Merge to Mix: Mixing Datasets via Model Merging](https://arxiv.org/abs/2505.16066)
*Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix*

**主要类别:** cs.LG

**概要:** 提出了一种名为'Merge to Mix'的新方法，通过模型合并加速数据集混合的组成，无需对每个候选混合进行全面微调。实验表明，该方法在微调大型模型的数据集选择上优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型模型微调数据集混合方法依赖于启发式和试错，需要多次微调运行才能达到理想效果。

**方法:** 提出'Merge to Mix'方法，利用模型合并技术加速数据集混合的组成。

**结果:** 实验显示'Merge to Mix'方法在大型模型微调的数据集选择上优于最先进的方法。

**结论:** 'Merge to Mix'通过模型合并提供了一种高效的数据集混合方法，显著提高了微调大型模型的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge+to+Mix%3A+Mixing+Datasets+via+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16066，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16066&send_immediately=true&force_search=false)

**原文摘要:** Mixing datasets for fine-tuning large models (LMs) has become critical for
maximizing performance on downstream tasks. However, composing effective
dataset mixtures typically relies on heuristics and trial-and-error, often
requiring multiple fine-tuning runs to achieve the desired outcome. We propose
a novel method, $\textit{Merge to Mix}$, that accelerates composing dataset
mixtures through model merging. Model merging is a recent technique that
combines the abilities of multiple individually fine-tuned LMs into a single LM
by using a few simple arithmetic operations. Our key insight is that merging
models individually fine-tuned on each dataset in a mixture can effectively
serve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix
leverages this insight to accelerate selecting dataset mixtures without
requiring full fine-tuning on each candidate mixture. Our experiments
demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset
selection for fine-tuning LMs.

</details>


### [16] [Bidirectional Variational Autoencoders](https://arxiv.org/abs/2505.16074)
*Bart Kosko, Olaoluwa Adigun*

**主要类别:** cs.LG

**概要:** 提出了一种新的双向变分自编码器(BVAE)网络架构，与普通VAE相比，在图像重建、分类、插值和生成任务上，BVAE在参数减少近50%的情况下仍然略胜一筹。


<details>
  <summary>更多</summary>
  
**动机:** 减少参数数量并提高模型性能。

**方法:** 提出一种单神经网络既用于编码又用于解码的BVAE架构，而不是使用编码器-解码器网络对。

**结果:** BVAE在四个图像任务上的表现略优于普通VAE，同时减少了近50%的参数量。

**结论:** BVAE提供了一种有效的参数减少方法，并在多个图像任务上表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bidirectional+Variational+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16074，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16074&send_immediately=true&force_search=false)

**原文摘要:** We present the new bidirectional variational autoencoder (BVAE) network
architecture. The BVAE uses a single neural network both to encode and decode
instead of an encoder-decoder network pair. The network encodes in the forward
direction and decodes in the backward direction through the same synaptic web.
Simulations compared BVAEs and ordinary VAEs on the four image tasks of image
reconstruction, classification, interpolation, and generation. The image
datasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and
CelebA-64 face images. The bidirectional structure of BVAEs cut the parameter
count by almost 50% and still slightly outperformed the unidirectional VAEs.

</details>


### [17] [Ensembling Sparse Autoencoders](https://arxiv.org/abs/2505.16077)
*Soham Gadgil, Chris Lin, Su-In Lee*

**主要类别:** cs.LG

**概要:** Ensemble multiple sparse autoencoders (SAEs) through naive bagging and boosting to improve the reconstruction of language model activations, feature diversity, and SAE stability.


<details>
  <summary>更多</summary>
  
**动机:** A single SAE captures only a limited subset of features that can be extracted from the activation space.

**方法:** Ensemble multiple SAEs trained with different weight initializations in naive bagging and sequentially trained SAEs in boosting.

**结果:** Ensembling SAEs improves the reconstruction of language model activations, diversity of features, and SAE stability. It also performs better than a single SAE on downstream tasks like concept detection and spurious correlation removal.

**结论:** Ensembling multiple SAEs is an effective approach to enhance feature extraction and practical utility.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ensembling+Sparse+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16077，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16077&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are used to decompose neural network activations
into human-interpretable features. Typically, features learned by a single SAE
are used for downstream applications. However, it has recently been shown that
SAEs trained with different initial weights can learn different features,
demonstrating that a single SAE captures only a limited subset of features that
can be extracted from the activation space. Motivated by this limitation, we
propose to ensemble multiple SAEs through naive bagging and boosting.
Specifically, SAEs trained with different weight initializations are ensembled
in naive bagging, whereas SAEs sequentially trained to minimize the residual
error are ensembled in boosting. We evaluate our ensemble approaches with three
settings of language models and SAE architectures. Our empirical results
demonstrate that ensembling SAEs can improve the reconstruction of language
model activations, diversity of features, and SAE stability. Furthermore,
ensembling SAEs performs better than applying a single SAE on downstream tasks
such as concept detection and spurious correlation removal, showing improved
practical utility.

</details>


### [18] [Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks](https://arxiv.org/abs/2505.16204)
*Ichiro Hashimoto*

**主要类别:** cs.LG

**概要:** 证明了固定宽度泄漏ReLU两层神经网络通过梯度下降优化的网络参数方向收敛性，并发现新的测试误差界相变，且结果不局限于几乎正交数据设定。


<details>
  <summary>更多</summary>
  
**动机:** 研究了之前仅对于梯度流已知的结果是否适用于梯度下降

**方法:** 对收敛方向进行了仔细分析

**结果:** 建立了良性过拟合的充分条件，并发现测试误差界中的新相变。所有结果均在几乎正交数据设定之外成立。

**结论:** 证明了固定宽度泄漏ReLU两层神经网络在指数损失下通过梯度下降优化的网络参数的方向收敛性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Directional+Convergence%2C+Benign+Overfitting+of+Gradient+Descent+in+leaky+ReLU+two-layer+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16204&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we prove directional convergence of network parameters of
fixed width leaky ReLU two-layer neural networks optimized by gradient descent
with exponential loss, which was previously only known for gradient flow. By a
careful analysis of the convergent direction, we establish sufficient
conditions of benign overfitting and discover a new phase transition in the
test error bound. All of these results hold beyond the nearly orthogonal data
setting which was studied in prior works. As an application, we demonstrate
that benign overfitting occurs with high probability in sub-Gaussian mixture
models.

</details>


### [19] [FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model](https://arxiv.org/abs/2505.16083)
*Jiahuan Long, Wenzhe Zhang, Ning Wang, Tingsong Jiang, Wen Yao*

**主要类别:** cs.LG

**概要:** 提出了一种基于状态空间建模的时空流场重建框架FR-Mamba，结合了傅里叶神经算子(FNO)和状态空间模型(SSM)，用于捕捉全局空间特征和长时依赖，实验表明其在长序列上具有高精度性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有深度学习方法难以捕捉长时间范围内的时序依赖性，影响了时间演化的物理系统的性能。

**方法:** 设计了一个结合FNO和SSM的混合神经网络架构来捕获空间和时间特征，并采用Mamba模型处理长时依赖，同时利用FNO处理非局部空间特征。

**结果:** 该方法在流场重建任务中显著优于现有的物理场重建方法，在长序列上表现出高精度。

**结论:** 提出的FR-Mamba框架成功解决了现有方法的局限性，为时间演化的物理系统提供了更有效的重建方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FR-Mamba%3A+Time-Series+Physical+Field+Reconstruction+Based+on+State+Space+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16083，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16083&send_immediately=true&force_search=false)

**原文摘要:** Physical field reconstruction (PFR) aims to predict the state distribution of
physical quantities (e.g., velocity, pressure, and temperature) based on
limited sensor measurements. It plays a critical role in domains such as fluid
dynamics and thermodynamics. However, existing deep learning methods often fail
to capture long-range temporal dependencies, resulting in suboptimal
performance on time-evolving physical systems. To address this, we propose
FR-Mamba, a novel spatiotemporal flow field reconstruction framework based on
state space modeling. Specifically, we design a hybrid neural network
architecture that combines Fourier Neural Operator (FNO) and State Space Model
(SSM) to capture both global spatial features and long-range temporal
dependencies. We adopt Mamba, a recently proposed efficient SSM architecture,
to model long-range temporal dependencies with linear time complexity. In
parallel, the FNO is employed to capture non-local spatial features by
leveraging frequency-domain transformations. The spatiotemporal representations
extracted by these two components are then fused to reconstruct the full-field
distribution of the physical system. Extensive experiments demonstrate that our
approach significantly outperforms existing PFR methods in flow field
reconstruction tasks, achieving high-accuracy performance on long sequences.

</details>


### [20] [AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training](https://arxiv.org/abs/2505.16363)
*Huishuai Zhang, Bohan Wang, Luoxin Chen*

**主要类别:** cs.LG

**概要:** AdamS是一种新的优化算法，作为Adam的替代方案，在大规模语言模型预训练和后训练中表现出色。它通过引入新的分母来消除对二阶矩估计的需求，具有与SGD动量相同的内存和计算开销，同时提供更好的优化性能。此外，AdamS易于采用且模型无关，可以直接继承AdamW的超参数，并无缝集成到现有管道中。


<details>
  <summary>更多</summary>
  
**动机:** AdamS的设计动机源于变压器目标中的(L_0, L_1)平滑特性，其中局部平滑性由梯度大小控制，梯度大小可以进一步近似为动量大小。

**方法:** AdamS通过引入根号加权平方和（动量和当前梯度）作为新的分母，消除了对二阶矩估计的需求。

**结果:** AdamS在各种任务中表现出色，包括GPT-2和Llama2（高达13B参数）的预训练以及后训练中的强化学习。

**结论:** AdamS因其效率、简单性和理论基础，成为现有优化器的一个有吸引力的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdamS%3A+Momentum+Itself+Can+Be+A+Normalizer+for+LLM+Pretraining+and+Post-training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16363，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16363&send_immediately=true&force_search=false)

**原文摘要:** We introduce AdamS, a simple yet effective alternative to Adam for large
language model (LLM) pretraining and post-training. By leveraging a novel
denominator, i.e., the root of weighted sum of squares of the momentum and the
current gradient, AdamS eliminates the need for second-moment estimates. Hence,
AdamS is efficient, matching the memory and compute footprint of SGD with
momentum while delivering superior optimization performance. Moreover, AdamS is
easy to adopt: it can directly inherit hyperparameters of AdamW, and is
entirely model-agnostic, integrating seamlessly into existing pipelines without
modifications to optimizer APIs or architectures. The motivation behind AdamS
stems from the observed $(L_0, L_1)$ smoothness properties in transformer
objectives, where local smoothness is governed by gradient magnitudes that can
be further approximated by momentum magnitudes. We establish rigorous
theoretical convergence guarantees and provide practical guidelines for
hyperparameter selection. Empirically, AdamS demonstrates strong performance in
various tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B
parameters) and reinforcement learning in post-training regimes. With its
efficiency, simplicity, and theoretical grounding, AdamS stands as a compelling
alternative to existing optimizers.

</details>


### [21] [A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization](https://arxiv.org/abs/2505.16094)
*Ziqing Wang, Kexin Zhang, Zihan Zhao, Yibo Wen, Abhishek Pandey, Han Liu, Kaize Ding*

**主要类别:** cs.LG

**概要:** This survey reviews the use of large language models in molecular discovery, focusing on molecule generation and optimization.


<details>
  <summary>更多</summary>
  
**动机:** To advance the field of LLMs in molecular discovery by providing an up-to-date review.

**方法:** Proposed taxonomy for analyzing representative techniques in molecule generation and optimization.

**结果:** Analysis of LLM capabilities in different learning settings, commonly used datasets, and evaluation protocols.

**结论:** Discusses key challenges and future directions in the field.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Large+Language+Models+for+Text-Guided+Molecular+Discovery%3A+from+Molecule+Generation+to+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16094&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are introducing a paradigm shift in molecular
discovery by enabling text-guided interaction with chemical spaces through
natural language, symbolic notations, with emerging extensions to incorporate
multi-modal inputs. To advance the new field of LLM for molecular discovery,
this survey provides an up-to-date and forward-looking review of the emerging
use of LLMs for two central tasks: molecule generation and molecule
optimization. Based on our proposed taxonomy for both problems, we analyze
representative techniques in each category, highlighting how LLM capabilities
are leveraged across different learning settings. In addition, we include the
commonly used datasets and evaluation protocols. We conclude by discussing key
challenges and future directions, positioning this survey as a resource for
researchers working at the intersection of LLMs and molecular science. A
continuously updated reading list is available at
https://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.

</details>


### [22] [Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling](https://arxiv.org/abs/2505.16481)
*Xinxing Shi, Xiaoyu Jiang, Mauricio A. Álvarez*

**主要类别:** cs.LG

**概要:** This work proposes a neighbor-driven approximation strategy for Gaussian Process Variational Autoencoders (GP-VAEs) to achieve scalable inference while maintaining rich latent variable correlations.


<details>
  <summary>更多</summary>
  
**动机:** To address the computational challenge of exact GP inference in large-scale GP-VAEs, which is often solved with restrictive kernel assumptions or large sets of inducing points.

**方法:** Introduce a neighbor-driven approximation strategy that limits computations to nearest neighbors in the latent space, enabling more flexible kernel choices and reducing dependency on many inducing points.

**结果:** The proposed method shows superior predictive performance and computational efficiency compared to other GP-VAE variants across various tasks such as representation learning, data imputation, and conditional generation.

**结论:** This approach enables scalable GP-VAE inference while preserving essential latent dependencies and allowing more flexible modeling.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neighbour-Driven+Gaussian+Process+Variational+Autoencoders+for+Scalable+Structured+Latent+Modelling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16481，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16481&send_immediately=true&force_search=false)

**原文摘要:** Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by
replacing the fully factorised Gaussian prior with a GP prior, thereby
capturing richer correlations among latent variables. However, performing exact
GP inference in large-scale GPVAEs is computationally prohibitive, often
forcing existing approaches to rely on restrictive kernel assumptions or large
sets of inducing points. In this work, we propose a neighbour-driven
approximation strategy that exploits local adjacencies in the latent space to
achieve scalable GPVAE inference. By confining computations to the nearest
neighbours of each data point, our method preserves essential latent
dependencies, allowing more flexible kernel choices and mitigating the need for
numerous inducing points. Through extensive experiments on tasks including
representation learning, data imputation, and conditional generation, we
demonstrate that our approach outperforms other GPVAE variants in both
predictive performance and computational efficiency.

</details>


### [23] [Reinforcement Learning for Stock Transactions](https://arxiv.org/abs/2505.16099)
*Ziyi, Zhou, Nicholas Stern, Julien Laasri*

**主要类别:** cs.LG

**概要:** This study applies reinforcement learning techniques including Q-Learning and deep Q-Learning to determine optimal buying times in the stock market using a defined Markov Decision Process problem. The results are compared to machine learning models for stock price prediction.


<details>
  <summary>更多</summary>
  
**动机:** To make profitable decisions in the chaotic stock market by identifying patterns through reinforcement learning.

**方法:** Defining a custom MDP problem and training agents using various Q-Learning approaches as well as comparing them with traditional machine learning models for stock price prediction.

**结果:** Agents trained with reinforcement learning techniques were able to converge on policies, with some showing potential for maximizing profit.

**结论:** Reinforcement learning can be effectively applied to determine optimal buying times in the stock market, with further extension possible for selling strategies.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+for+Stock+Transactions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16099&send_immediately=true&force_search=false)

**原文摘要:** Much research has been done to analyze the stock market. After all, if one
can determine a pattern in the chaotic frenzy of transactions, then they could
make a hefty profit from capitalizing on these insights. As such, the goal of
our project was to apply reinforcement learning (RL) to determine the best time
to buy a stock within a given time frame. With only a few adjustments, our
model can be extended to identify the best time to sell a stock as well. In
order to use the format of free, real-world data to train the model, we define
our own Markov Decision Process (MDP) problem. These two papers [5] [6] helped
us in formulating the state space and the reward system of our MDP problem. We
train a series of agents using Q-Learning, Q-Learning with linear function
approximation, and deep Q-Learning. In addition, we try to predict the stock
prices using machine learning regression and classification models. We then
compare our agents to see if they converge on a policy, and if so, which one
learned the best policy to maximize profit on the stock market.

</details>


### [24] [Incremental Sequence Classification with Temporal Consistency](https://arxiv.org/abs/2505.16548)
*Lucas Maystre, Gabriel Barello, Tudor Berariu, Aleix Cambray, Rares Dolga, Alvaro Ortega Gonzalez, Andrei Nica, David Barber*

**主要类别:** cs.LG

**概要:** 提出了一种基于时序一致性条件的新损失函数，用于增量序列分类器的训练。该方法在文本分类任务和验证大语言模型生成正确性方面表现出色，尤其是在少量观测情况下。


<details>
  <summary>更多</summary>
  
**动机:** 解决增量序列分类问题，即随着序列中新元素的揭示不断更新预测的问题。

**方法:** 利用强化学习中的时序差分学习，识别出时序一致性条件，并基于此开发新的损失函数。

**结果:** 在多个基准数据集上的文本分类任务中表现优于竞争对手；在验证大语言模型生成的正确性上也有显著提升。

**结论:** 所提出的方法在数据效率和预测准确性方面均取得了显著进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incremental+Sequence+Classification+with+Temporal+Consistency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16548，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16548&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of incremental sequence classification, where
predictions are updated as new elements in the sequence are revealed. Drawing
on temporal-difference learning from reinforcement learning, we identify a
temporal-consistency condition that successive predictions should satisfy. We
leverage this condition to develop a novel loss function for training
incremental sequence classifiers. Through a concrete example, we demonstrate
that optimizing this loss can offer substantial gains in data efficiency. We
apply our method to text classification tasks and show that it improves
predictive accuracy over competing approaches on several benchmark datasets. We
further evaluate our approach on the task of verifying large language model
generations for correctness in grade-school math problems. Our results show
that models trained with our method are better able to distinguish promising
generations from unpromising ones after observing only a few tokens.

</details>


### [25] [Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI](https://arxiv.org/abs/2505.16103)
*Monirul Islam Mahmud*

**主要类别:** cs.LG

**概要:** 研究了多种机器学习模型和特征选择方法用于keylogger检测，AdaBoost模型表现最佳。


<details>
  <summary>更多</summary>
  
**动机:** 提供一种综合的方法来检测keylogger，通过多种机器学习模型和特征选择方法提高检测效率和准确性。

**方法:** 使用传统机器学习模型（如SVC、Random Forest、Decision Tree、XGBoost、AdaBoost、Logistic Regression和Naive Bayes）以及高级集成方法（如Stacking、Blending和Voting）。对特征选择方法（如信息增益、Lasso L1和Fisher Score）进行了全面评估。使用了Kaggle网站上公开的Keylogger Detection数据集。使用SHAP（全局）和LIME（局部）等可解释AI（XAI）技术进行模型解释。

**结果:** AdaBoost模型表现出色，达到了接近完美的分类效果。特征选择方法如Fisher Score显著提高了模型性能。

**结论:** AdaBoost模型在检测keylogger方面表现最佳，具有99.76%的准确率，F1分数为0.99，100%的精确度，98.6%的召回率，100%的特异性和0.99的AUC。特征选择方法如Fisher Score进一步提升了预测性能并降低了计算复杂度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Trustworthy+Keylogger+detection%3A+A+Comprehensive+Analysis+of+Ensemble+Techniques+and+Feature+Selections+through+Explainable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16103，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16103&send_immediately=true&force_search=false)

**原文摘要:** Keylogger detection involves monitoring for unusual system behaviors such as
delays between typing and character display, analyzing network traffic patterns
for data exfiltration. In this study, we provide a comprehensive analysis for
keylogger detection with traditional machine learning models - SVC, Random
Forest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes
and advanced ensemble methods including Stacking, Blending and Voting.
Moreover, feature selection approaches such as Information gain, Lasso L1 and
Fisher Score are thoroughly assessed to improve predictive performance and
lower computational complexity. The Keylogger Detection dataset from publicly
available Kaggle website is used in this project. In addition to accuracy-based
classification, this study implements the approach for model interpretation
using Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to
deliver finer explanations for how much each feature contributes in assisting
or hindering the detection process. To evaluate the models result, we have used
AUC score, sensitivity, Specificity, Accuracy and F1 score. The best
performance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,
100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is
near-perfect classification with Fisher Score.

</details>


### [26] [Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity](https://arxiv.org/abs/2505.16638)
*Benedikt Höltgen, Nuria Oliver*

**主要类别:** cs.LG

**概要:** Fairness through Unawareness (FtU) is a concept suggesting that discrimination can be avoided by excluding demographic information from decisions. Despite criticism, this paper demonstrates both theoretically and empirically that FtU can reduce discrimination without harming accuracy. It also connects FtU with Model Multiplicity literature and shows its potential in real-life applications for equitable policy-making.


<details>
  <summary>更多</summary>
  
**动机:** To address the criticism that FtU is insufficient for ensuring fairness and to explore its potential benefits in reducing algorithmic discrimination without sacrificing accuracy.

**方法:** Theoretical analysis and empirical experiments to demonstrate the effectiveness of FtU in reducing discrimination.

**结果:** FtU can indeed reduce algorithmic discrimination without reducing accuracy, and it can contribute to more equitable policies in real-life applications.

**结论:** FtU is valuable in practical applications, especially in high-risk scenarios, and the use of protected attributes should have a justified rationale.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reconsidering+Fairness+Through+Unawareness+from+the+Perspective+of+Model+Multiplicity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16638，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16638&send_immediately=true&force_search=false)

**原文摘要:** Fairness through Unawareness (FtU) describes the idea that discrimination
against demographic groups can be avoided by not considering group membership
in the decisions or predictions. This idea has long been criticized in the
machine learning literature as not being sufficient to ensure fairness. In
addition, the use of additional features is typically thought to increase the
accuracy of the predictions for all groups, so that FtU is sometimes thought to
be detrimental to all groups. In this paper, we show both theoretically and
empirically that FtU can reduce algorithmic discrimination without necessarily
reducing accuracy. We connect this insight with the literature on Model
Multiplicity, to which we contribute with novel theoretical and empirical
results. Furthermore, we illustrate how, in a real-life application, FtU can
contribute to the deployment of more equitable policies without losing
efficacy. Our findings suggest that FtU is worth considering in practical
applications, particularly in high-risk scenarios, and that the use of
protected attributes such as gender in predictive models should be accompanied
by a clear and well-founded justification.

</details>


### [27] [Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools](https://arxiv.org/abs/2505.16113)
*Panagiotis Lymperopoulos, Vasanth Sarathy*

**主要类别:** cs.LG

**概要:** This paper introduces a new framework for quantifying uncertainty in large language models when used with external tools, demonstrating its effectiveness in enhancing trust in high-stakes applications.


<details>
  <summary>更多</summary>
  
**动机:** To address the challenge of assessing the uncertainty of responses generated by integrated LLM and external tool systems, especially in high-stakes applications.

**方法:** A novel framework is presented to model tool-calling LLMs by jointly considering the predictive uncertainty of the LLM and the external tool. The method extends previous uncertainty quantification approaches and proposes efficient approximations.

**结果:** The framework was evaluated on two synthetic QA datasets and applied to RAG systems, showing effectiveness in enhancing trust in LLM-based systems.

**结论:** The proposed framework effectively enhances trust in LLM-based systems by quantifying uncertainty in both the LLM and external tools.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Tools+in+the+Loop%3A+Quantifying+Uncertainty+of+LLM+Question+Answering+Systems+That+Use+Tools，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16113，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16113&send_immediately=true&force_search=false)

**原文摘要:** Modern Large Language Models (LLMs) often require external tools, such as
machine learning classifiers or knowledge retrieval systems, to provide
accurate answers in domains where their pre-trained knowledge is insufficient.
This integration of LLMs with external tools expands their utility but also
introduces a critical challenge: determining the trustworthiness of responses
generated by the combined system. In high-stakes applications, such as medical
decision-making, it is essential to assess the uncertainty of both the LLM's
generated text and the tool's output to ensure the reliability of the final
response. However, existing uncertainty quantification methods do not account
for the tool-calling scenario, where both the LLM and external tool contribute
to the overall system's uncertainty. In this work, we present a novel framework
for modeling tool-calling LLMs that quantifies uncertainty by jointly
considering the predictive uncertainty of the LLM and the external tool. We
extend previous methods for uncertainty quantification over token sequences to
this setting and propose efficient approximations that make uncertainty
computation practical for real-world applications. We evaluate our framework on
two new synthetic QA datasets, derived from well-known machine learning
datasets, which require tool-calling for accurate answers. Additionally, we
apply our method to retrieval-augmented generation (RAG) systems and conduct a
proof-of-concept experiment demonstrating the effectiveness of our uncertainty
metrics in scenarios where external information retrieval is needed. Our
results show that the framework is effective in enhancing trust in LLM-based
systems, especially in cases where the LLM's internal knowledge is insufficient
and external tools are required.

</details>


### [28] [Sequential Monte Carlo for Policy Optimization in Continuous POMDPs](https://arxiv.org/abs/2505.16732)
*Hany Abdulsamad, Sahel Iqbal, Simo Särkkä*

**主要类别:** cs.LG

**概要:** 提出了一种新的策略优化框架来解决连续部分可观察马尔可夫决策过程中的探索与利用问题。


<details>
  <summary>更多</summary>
  
**动机:** 在部分可观察的情况下，智能体需要在减少不确定性（探索）和追求即时目标（利用）之间取得平衡。

**方法:** 通过在非马尔可夫费曼-卡茨模型中将策略学习视为概率推理，并开发了一种嵌套序贯蒙特卡洛算法来估计历史依赖的策略梯度。

**结果:** 该方法在标准连续POMDP基准测试中表现出色，而现有方法在不确定性下难以行动。

**结论:** 所提出的框架有效地解决了连续POMDP中的探索与利用问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sequential+Monte+Carlo+for+Policy+Optimization+in+Continuous+POMDPs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16732，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16732&send_immediately=true&force_search=false)

**原文摘要:** Optimal decision-making under partial observability requires agents to
balance reducing uncertainty (exploration) against pursuing immediate
objectives (exploitation). In this paper, we introduce a novel policy
optimization framework for continuous partially observable Markov decision
processes (POMDPs) that explicitly addresses this challenge. Our method casts
policy learning as probabilistic inference in a non-Markovian Feynman--Kac
model that inherently captures the value of information gathering by
anticipating future observations, without requiring extrinsic exploration
bonuses or handcrafted heuristics. To optimize policies under this model, we
develop a nested sequential Monte Carlo~(SMC) algorithm that efficiently
estimates a history-dependent policy gradient under samples from the optimal
trajectory distribution induced by the POMDP. We demonstrate the effectiveness
of our algorithm across standard continuous POMDP benchmarks, where existing
methods struggle to act under uncertainty.

</details>


### [29] [A Generic Framework for Conformal Fairness](https://arxiv.org/abs/2505.16115)
*Aditya T. Vadlamani, Anutam Srinivasan, Pranav Maneriker, Ali Payani, Srinivasan Parthasarathy*

**主要类别:** cs.LG

**概要:** 提出了一种基于一致性预测的公平性概念，并开发了算法框架来控制不同敏感组之间的覆盖差距。该框架适用于非独立同分布的数据类型，如图数据。实验表明，该算法能够控制与公平性相关的差距并满足理论预期的覆盖。


<details>
  <summary>更多</summary>
  
**动机:** 现有的一致性预测方法在处理敏感属性时无法提供标签真实覆盖的概率保证。

**方法:** 提出了‘一致性公平性’的概念，并设计了一个理论基础坚实的算法和相关框架来解决不同敏感组之间的覆盖差距问题。

**结果:** 在图数据和表格数据集上的实验验证了算法能够控制与公平性相关的差距，并符合理论预期的覆盖效果。

**结论:** 本研究扩展了一致性预测的应用范围到非独立同分布的数据上，并提出了一个新的公平性衡量标准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Generic+Framework+for+Conformal+Fairness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16115，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16115&send_immediately=true&force_search=false)

**原文摘要:** Conformal Prediction (CP) is a popular method for uncertainty quantification
with machine learning models. While conformal prediction provides probabilistic
guarantees regarding the coverage of the true label, these guarantees are
agnostic to the presence of sensitive attributes within the dataset. In this
work, we formalize \textit{Conformal Fairness}, a notion of fairness using
conformal predictors, and provide a theoretically well-founded algorithm and
associated framework to control for the gaps in coverage between different
sensitive groups. Our framework leverages the exchangeability assumption
(implicit to CP) rather than the typical IID assumption, allowing us to apply
the notion of Conformal Fairness to data types and tasks that are not IID, such
as graph data. Experiments were conducted on graph and tabular datasets to
demonstrate that the algorithm can control fairness-related gaps in addition to
coverage aligned with theoretical expectations.

</details>


### [30] [Meta-reinforcement learning with minimum attention](https://arxiv.org/abs/2505.16741)
*Pilhwa Lee, Shashank Gupta*

**主要类别:** cs.LG

**概要:** This paper explores the concept of minimum attention in reinforcement learning, showing its effectiveness in model-free and model-based scenarios.


<details>
  <summary>更多</summary>
  
**动机:** To emulate biological control and improve reinforcement learning through the application of the minimum attention principle.

**方法:** Applying minimum attention as part of the rewards in reinforcement learning and exploring its connection to meta-learning and stabilization.

**结果:** Demonstrated superior performance in model-free and model-based RL, particularly in fast adaptation and variance reduction.

**结论:** Minimum attention improves both performance and energy efficiency in reinforcement learning tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-reinforcement+learning+with+minimum+attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16741，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16741&send_immediately=true&force_search=false)

**原文摘要:** Minimum attention applies the least action principle in the changes of
control concerning state and time, first proposed by Brockett. The involved
regularization is highly relevant in emulating biological control, such as
motor learning. We apply minimum attention in reinforcement learning (RL) as
part of the rewards and investigate its connection to meta-learning and
stabilization. Specifically, model-based meta-learning with minimum attention
is explored in high-dimensional nonlinear dynamics. Ensemble-based model
learning and gradient-based meta-policy learning are alternately performed.
Empirically, we show that the minimum attention does show outperforming
competence in comparison to the state-of-the-art algorithms in model-free and
model-based RL, i.e., fast adaptation in few shots and variance reduction from
the perturbations of the model and environment. Furthermore, the minimum
attention demonstrates the improvement in energy efficiency.

</details>


### [31] [Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning](https://arxiv.org/abs/2505.16122)
*Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou*

**主要类别:** cs.LG

**概要:** 提出了一种名为Plan-and-Budget的新框架，通过分解复杂查询为子问题并根据估计的复杂度分配令牌预算来提高大型语言模型的推理效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型语言模型在复杂推理任务上表现出色，但推理过程计算效率低下，存在过思考和欠思考的问题。

**方法:** 开发了BBAM理论模型，并提出了Plan-and-Budget框架，该框架不依赖于具体模型，在测试时对复杂查询进行分解并基于自适应调度分配令牌预算。

**结果:** Plan-and-Budget在多种任务和模型上提升了推理效率，包括高达+70%的准确性提升，-39%的令牌减少以及+187.5%的E^3改进。

**结论:** Plan-and-Budget能够缩小性能差距而无需重新训练，展示了其在不同规模模型间应用的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Plan+and+Budget%3A+Effective+and+Efficient+Test-Time+Scaling+on+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16122，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16122&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have achieved remarkable success in complex
reasoning tasks, but their inference remains computationally inefficient. We
observe a common failure mode in many prevalent LLMs, overthinking, where
models generate verbose and tangential reasoning traces even for simple
queries. Recent works have tried to mitigate this by enforcing fixed token
budgets, however, this can lead to underthinking, especially on harder
problems. Through empirical analysis, we identify that this inefficiency often
stems from unclear problem-solving strategies. To formalize this, we develop a
theoretical model, BBAM (Bayesian Budget Allocation Model), which models
reasoning as a sequence of sub-questions with varying uncertainty, and
introduce the $E^3$ metric to capture the trade-off between correctness and
computation efficiency. Building on theoretical results from BBAM, we propose
Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex
queries into sub-questions and allocates token budgets based on estimated
complexity using adaptive scheduling. Plan-and-Budget improves reasoning
efficiency across a range of tasks and models, achieving up to +70% accuracy
gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it
elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger
model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close
performance gaps without retraining. Our code is available at
anonymous.4open.science/r/P-and-B-6513/.

</details>


### [32] [ICYM2I: The illusion of multimodal informativeness under missingness](https://arxiv.org/abs/2505.16953)
*Young Sang Choi, Vincent Jeanselme, Pierre Elias, Shalmali Joshi*

**主要类别:** cs.LG

**概要:** This paper addresses the issue of missing modalities in multimodal learning, demonstrating the biases from ignoring this process and introducing a framework called ICYM2I to evaluate predictive performance and information gain under missingness.


<details>
  <summary>更多</summary>
  
**动机:** The potential information gain from combining different types of data is of interest in AI applications, but the informativeness of a given modality can vary due to various factors, leading to improper estimates of a modality's value in downstream tasks if missingness is not accounted for.

**方法:** Introduce a framework called ICYM2I for evaluating predictive performance and information gain under missingness through inverse probability weighting-based correction.

**结果:** Demonstrate the importance of the proposed adjustment to estimate information gain under missingness on synthetic, semi-synthetic, and real-world medical datasets.

**结论:** The work formalizes the problem of missingness in multimodal learning and provides a solution to properly estimate the value of modalities in downstream tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ICYM2I%3A+The+illusion+of+multimodal+informativeness+under+missingness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16953&send_immediately=true&force_search=false)

**原文摘要:** Multimodal learning is of continued interest in artificial intelligence-based
applications, motivated by the potential information gain from combining
different types of data. However, modalities collected and curated during
development may differ from the modalities available at deployment due to
multiple factors including cost, hardware failure, or -- as we argue in this
work -- the perceived informativeness of a given modality. Na{\"i}ve estimation
of the information gain associated with including an additional modality
without accounting for missingness may result in improper estimates of that
modality's value in downstream tasks. Our work formalizes the problem of
missingness in multimodal learning and demonstrates the biases resulting from
ignoring this process. To address this issue, we introduce ICYM2I (In Case You
Multimodal Missed It), a framework for the evaluation of predictive performance
and information gain under missingness through inverse probability
weighting-based correction. We demonstrate the importance of the proposed
adjustment to estimate information gain under missingness on synthetic,
semi-synthetic, and real-world medical datasets.

</details>


### [33] [Robust Invariant Representation Learning by Distribution Extrapolation](https://arxiv.org/abs/2505.16126)
*Kotaro Yoshida, Slavakis Konstantinos*

**主要类别:** cs.LG

**概要:** 提出一种新的基于外推的框架来增强IRM，解决现有方法对环境多样性和过参数化的敏感性问题，并在多种实验中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有IRM方法常无法超越精心调整的ERM，需要更稳健的IRM实现。

**方法:** 通过合成分布偏移增强IRM惩罚项的基于外推的新框架。

**结果:** 新方法在各种实验设置中优于最先进的IRM变体。

**结论:** 提出的方法在多种实验中表现出色，验证了其有效性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Invariant+Representation+Learning+by+Distribution+Extrapolation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16126，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16126&send_immediately=true&force_search=false)

**原文摘要:** Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)
generalization in deep learning by learning invariant representations. As IRM
poses an inherently challenging bi-level optimization problem, most existing
approaches -- including IRMv1 -- adopt penalty-based single-level
approximations. However, empirical studies consistently show that these methods
often fail to outperform well-tuned empirical risk minimization (ERM),
highlighting the need for more robust IRM implementations. This work
theoretically identifies a key limitation common to many IRM variants: their
penalty terms are highly sensitive to limited environment diversity and
over-parameterization, resulting in performance degradation. To address this
issue, a novel extrapolation-based framework is proposed that enhances
environmental diversity by augmenting the IRM penalty through synthetic
distributional shifts. Extensive experiments -- ranging from synthetic setups
to realistic, over-parameterized scenarios -- demonstrate that the proposed
method consistently outperforms state-of-the-art IRM variants, validating its
effectiveness and robustness.

</details>


### [34] [Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models](https://arxiv.org/abs/2505.16959)
*Alessandro Favero, Antonio Sclocchi, Matthieu Wyart*

**主要类别:** cs.LG

**概要:** 研究了扩散概率模型的泛化机制，提出了基于数据集大小的比例早停准则来优化模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 探索了扩散概率模型在现代生成人工智能中的广泛应用，但其泛化机制仍不清楚的问题。

**方法:** 研究了高度过参数化的扩散模型在训练过程中的泛化和记忆化现象，并通过实验验证了记忆化时间与数据集大小成正比的规律。

**结果:** 发现扩散模型在训练过程中会逐渐实现自然数据域中的泛化，而不是简单地记忆训练数据，并且这种现象可以通过学习简单的概率上下文无关文法得到解释。

**结论:** 总结了扩散概率模型在自然数据域中的泛化现象，并提出了一种基于数据集大小的比例早停准则来优化泛化并避免记忆化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bigger+Isn%27t+Always+Memorizing%3A+Early+Stopping+Overparameterized+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16959，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16959&send_immediately=true&force_search=false)

**原文摘要:** Diffusion probabilistic models have become a cornerstone of modern generative
AI, yet the mechanisms underlying their generalization remain poorly
understood. In fact, if these models were perfectly minimizing their training
loss, they would just generate data belonging to their training set, i.e.,
memorize, as empirically found in the overparameterized regime. We revisit this
view by showing that, in highly overparameterized diffusion models,
generalization in natural data domains is progressively achieved during
training before the onset of memorization. Our results, ranging from image to
language diffusion models, systematically support the empirical law that
memorization time is proportional to the dataset size. Generalization vs.
memorization is then best understood as a competition between time scales. We
show that this phenomenology is recovered in diffusion models learning a simple
probabilistic context-free grammar with random rules, where generalization
corresponds to the hierarchical acquisition of deeper grammar rules as training
time grows, and the generalization cost of early stopping can be characterized.
We summarize these results in a phase diagram. Overall, our results support
that a principled early-stopping criterion - scaling with dataset size - can
effectively optimize generalization while avoiding memorization, with direct
implications for hyperparameter transfer and privacy-sensitive applications.

</details>


### [35] [Scalable Graph Generative Modeling via Substructure Sequences](https://arxiv.org/abs/2505.16130)
*Zehong Wang, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye*

**主要类别:** cs.LG

**概要:** 提出了一种基于生成Transformer的图预训练框架G$^2$PM，它通过子结构序列生成学习可迁移表示，并在大规模模型下持续提升性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有消息传递机制的图神经网络存在表达能力受限、过平滑、过压缩及对长程依赖建模能力有限等问题，阻碍了其作为图基础模型骨干的扩展性。

**方法:** 引入生成图模式机器（G$^2$PM），将图实例表示为子结构序列并进行生成式预训练。

**结果:** 在ogbn-arxiv基准上，G$^2$PM在高达60M参数规模时仍持续改进，优于先前方法；在多种任务中表现优异。

**结论:** G$^2$PM展示了强大的可扩展性和泛化能力，为可扩展图学习奠定了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Graph+Generative+Modeling+via+Substructure+Sequences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16130&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) has been predominantly driven by
message-passing, where node representations are iteratively updated via local
neighborhood aggregation. Despite their success, message-passing suffers from
fundamental limitations -- including constrained expressiveness,
over-smoothing, over-squashing, and limited capacity to model long-range
dependencies. These issues hinder scalability: increasing data size or model
size often fails to yield improved performance, limiting the viability of GNNs
as backbones for graph foundation models. In this work, we explore pathways
beyond message-passing and introduce Generative Graph Pattern Machine
(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM
represents graph instances (nodes, edges, or entire graphs) as sequences of
substructures, and employs generative pre-training over the sequences to learn
generalizable, transferable representations. Empirically, G$^2$PM demonstrates
strong scalability: on the ogbn-arxiv benchmark, it continues to improve with
model sizes up to 60M parameters, outperforming prior generative approaches
that plateau at significantly smaller scales (e.g., 3M). In addition, we
systematically analyze the model design space, highlighting key architectural
choices that contribute to its scalability and generalization. Across diverse
tasks -- including node classification, graph classification, and transfer
learning -- G$^2$PM consistently outperforms strong baselines, establishing a
compelling foundation for scalable graph learning. The code and dataset are
available at https://github.com/Zehong-Wang/G2PM.

</details>


### [36] [Guided Diffusion Sampling on Function Spaces with Applications to PDEs](https://arxiv.org/abs/2505.17004)
*Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul Ye, Kamyar Azizzadenesheli, Anima Anandkumar*

**主要类别:** cs.LG

**概要:** 提出了一种新的基于扩散模型的框架FunDPS，它能够在部分观测数据条件下准确捕捉函数空间中的后验分布，且性能优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了从极稀疏或噪声的测量数据中恢复整个解，提出了一种通用的条件采样框架。

**方法:** 通过训练无条件去噪模型并结合梯度引导机制来实现对稀疏或噪声测量数据的条件采样，同时扩展了Tweedie公式到无限维希尔伯特空间。

**结果:** 在五个PDE任务中，该方法在仅3%观测数据的情况下比最先进的固定分辨率扩散基线提高了平均32%的准确性，并且减少了4倍的采样步骤。此外，多分辨率微调确保了强大的跨分辨率泛化能力。

**结论:** 提出了一种新的基于扩散模型的框架FunDPS，它能够在部分观测数据条件下准确捕捉函数空间中的后验分布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Guided+Diffusion+Sampling+on+Function+Spaces+with+Applications+to+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17004&send_immediately=true&force_search=false)

**原文摘要:** We propose a general framework for conditional sampling in PDE-based inverse
problems, targeting the recovery of whole solutions from extremely sparse or
noisy measurements. This is accomplished by a function-space diffusion model
and plug-and-play guidance for conditioning. Our method first trains an
unconditional discretization-agnostic denoising model using neural operator
architectures. At inference, we refine the samples to satisfy sparse
observation data via a gradient-based guidance mechanism. Through rigorous
mathematical analysis, we extend Tweedie's formula to infinite-dimensional
Hilbert spaces, providing the theoretical foundation for our posterior sampling
approach. Our method (FunDPS) accurately captures posterior distributions in
function spaces under minimal supervision and severe data scarcity. Across five
PDE tasks with only 3% observation, our method achieves an average 32% accuracy
improvement over state-of-the-art fixed-resolution diffusion baselines while
reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning
ensures strong cross-resolution generalizability. To the best of our knowledge,
this is the first diffusion-based framework to operate independently of
discretization, offering a practical and flexible solution for forward and
inverse problems in the context of PDEs. Code is available at
https://github.com/neuraloperator/FunDPS

</details>


### [37] [Multimodal Online Federated Learning with Modality Missing in Internet of Things](https://arxiv.org/abs/2505.16138)
*Heqiang Wang, Xiang Liu, Xiaoxiong Zhong, Lixing Chen, Fangming Liu, Weizhe Zhang*

**主要类别:** cs.LG

**概要:** This paper introduces MMO-FL, a new method for handling multimodal data in IoT environments using federated learning and addressing missing modalities with the PMM algorithm.


<details>
  <summary>更多</summary>
  
**动机:** The increasing complexity of IoT devices and the real-time nature of data collection require new methods for processing multimodal data in a decentralized manner.

**方法:** Multimodal Online Federated Learning (MMO-FL) framework that supports dynamic and decentralized multimodal learning in IoT environments, including the Prototypical Modality Mitigation (PMM) algorithm to handle missing modalities.

**结果:** Experimental results show that PMM outperforms benchmarks in compensating for missing modalities.

**结论:** MMO-FL and PMM provide a promising approach for managing multimodal data in IoT environments with unstable edge devices.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multimodal+Online+Federated+Learning+with+Modality+Missing+in+Internet+of+Things，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16138，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16138&send_immediately=true&force_search=false)

**原文摘要:** The Internet of Things (IoT) ecosystem generates vast amounts of multimodal
data from heterogeneous sources such as sensors, cameras, and microphones. As
edge intelligence continues to evolve, IoT devices have progressed from simple
data collection units to nodes capable of executing complex computational
tasks. This evolution necessitates the adoption of distributed learning
strategies to effectively handle multimodal data in an IoT environment.
Furthermore, the real-time nature of data collection and limited local storage
on edge devices in IoT call for an online learning paradigm. To address these
challenges, we introduce the concept of Multimodal Online Federated Learning
(MMO-FL), a novel framework designed for dynamic and decentralized multimodal
learning in IoT environments. Building on this framework, we further account
for the inherent instability of edge devices, which frequently results in
missing modalities during the learning process. We conduct a comprehensive
theoretical analysis under both complete and missing modality scenarios,
providing insights into the performance degradation caused by missing
modalities. To mitigate the impact of modality missing, we propose the
Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype
learning to effectively compensate for missing modalities. Experimental results
on two multimodal datasets further demonstrate the superior performance of PMM
compared to benchmarks.

</details>


### [38] [Understanding Prompt Tuning and In-Context Learning via Meta-Learning](https://arxiv.org/abs/2505.17010)
*Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter*

**主要类别:** cs.LG

**概要:** This paper explores optimal prompting from a Bayesian perspective, revealing fundamental limitations that can only be overcome by weight tuning. It examines how meta-trained neural networks function as Bayesian predictors and studies optimal prompting by conditioning these predictors, leading to criteria for tasks where optimal prompting is feasible. Educational experiments on LSTMs and Transformers compare different prefix-tuning and weight-tuning methods, confirming the effectiveness of soft prefixes.


<details>
  <summary>更多</summary>
  
**动机:** To provide a conceptual understanding of prompting and explore its limitations.

**方法:** Analyzing prompting through a Bayesian lens and examining the behavior of meta-trained neural networks as Bayesian predictors.

**结果:** Optimal prompting can be studied formally by conditioning Bayesian predictors, yielding criteria for tasks where it's possible or not. Soft prefixes can effectively prompt trained and untrained networks.

**结论:** Understanding prompting from a Bayesian perspective reveals its limitations and provides insights into when optimal prompting is viable.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Prompt+Tuning+and+In-Context+Learning+via+Meta-Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17010，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17010&send_immediately=true&force_search=false)

**原文摘要:** Prompting is one of the main ways to adapt a pretrained model to target
tasks. Besides manually constructing prompts, many prompt optimization methods
have been proposed in the literature. Method development is mainly empirically
driven, with less emphasis on a conceptual understanding of prompting. In this
paper we discuss how optimal prompting can be understood through a Bayesian
view, which also implies some fundamental limitations of prompting that can
only be overcome by tuning weights. The paper explains in detail how
meta-trained neural networks behave as Bayesian predictors over the pretraining
distribution, whose hallmark feature is rapid in-context adaptation. Optimal
prompting can be studied formally as conditioning these Bayesian predictors,
yielding criteria for target tasks where optimal prompting is and is not
possible. We support the theory with educational experiments on LSTMs and
Transformers, where we compare different versions of prefix-tuning and
different weight-tuning methods. We also confirm that soft prefixes, which are
sequences of real-valued vectors outside the token alphabet, can lead to very
effective prompts for trained and even untrained networks by manipulating
activations in ways that are not achievable by hard tokens. This adds an
important mechanistic aspect beyond the conceptual Bayesian theory.

</details>


### [39] [NAN: A Training-Free Solution to Coefficient Estimation in Model Merging](https://arxiv.org/abs/2505.16148)
*Chongjie Si, Kangtao Lv, Jingjing Jiang, Yadao Wang, Yongwei Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen*

**主要类别:** cs.LG

**概要:** 提出了一种新的模型合并方法NAN，通过参数范数的逆来估计合并系数，无需训练且适用于多种合并策略，实验表明其在多种基准方法上提高了性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的模型合并方法通常依赖于启发式方法来确定合并系数，限制了其可扩展性和通用性。

**方法:** 通过最小二乘优化的角度重新审视模型合并问题，并提出NAN方法，该方法基于每个模型中编码的任务特定信息量来确定最优合并权重。

**结果:** 提出的NAN方法在多种基准方法上提高了性能。

**结论:** NAN是一种简单有效的模型合并方法，可以作为插件使用，并适用于多种合并策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NAN%3A+A+Training-Free+Solution+to+Coefficient+Estimation+in+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16148，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16148&send_immediately=true&force_search=false)

**原文摘要:** Model merging offers a training-free alternative to multi-task learning by
combining independently fine-tuned models into a unified one without access to
raw data. However, existing approaches often rely on heuristics to determine
the merging coefficients, limiting their scalability and generality. In this
work, we revisit model merging through the lens of least-squares optimization
and show that the optimal merging weights should scale with the amount of
task-specific information encoded in each model. Based on this insight, we
propose NAN, a simple yet effective method that estimates model merging
coefficients via the inverse of parameter norm. NAN is training-free,
plug-and-play, and applicable to a wide range of merging strategies. Extensive
experiments on show that NAN consistently improves performance of baseline
methods.

</details>


### [40] [Why Can Accurate Models Be Learned from Inaccurate Annotations?](https://arxiv.org/abs/2505.16159)
*Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen*

**主要类别:** cs.LG

**概要:** 研究了模型在存在错误标签的情况下仍能有效泛化的现象，通过分析权重矩阵发现主子空间在一定程度上与真实标签学习的子空间保持一致，并提出了LIP方法来提升现有算法的性能。


<details>
  <summary>更多</summary>
  
**动机:** 学习不准确标注的研究受到关注，因为精确标记成本高。尽管有错误标签，模型仍能做出准确预测的现象未被充分理解。

**方法:** 从经验与理论角度分析权重矩阵，证明主子空间在适度标签不准确下角度偏差最小。提出LIP方法帮助分类器保留主子空间信息并减轻标签不准确引起的噪声。

**结果:** 发现主子空间在一定范围内与清洁标签学习的子空间对齐，保留任务相关的重要信息；LIP方法在各种不准确条件下提高现有算法性能。

**结论:** 研究揭示了模型在不准确监督下的鲁棒性理论和实践洞见。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Can+Accurate+Models+Be+Learned+from+Inaccurate+Annotations%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16159，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16159&send_immediately=true&force_search=false)

**原文摘要:** Learning from inaccurate annotations has gained significant attention due to
the high cost of precise labeling. However, despite the presence of erroneous
labels, models trained on noisy data often retain the ability to make accurate
predictions. This intriguing phenomenon raises a fundamental yet largely
unexplored question: why models can still extract correct label information
from inaccurate annotations remains unexplored. In this paper, we conduct a
comprehensive investigation into this issue. By analyzing weight matrices from
both empirical and theoretical perspectives, we find that label inaccuracy
primarily accumulates noise in lower singular components and subtly perturbs
the principal subspace. Within a certain range, the principal subspaces of
weights trained on inaccurate labels remain largely aligned with those learned
from clean labels, preserving essential task-relevant information. We formally
prove that the angles of principal subspaces exhibit minimal deviation under
moderate label inaccuracy, explaining why models can still generalize
effectively. Building on these insights, we propose LIP, a lightweight plug-in
designed to help classifiers retain principal subspace information while
mitigating noise induced by label inaccuracy. Extensive experiments on tasks
with various inaccuracy conditions demonstrate that LIP consistently enhances
the performance of existing algorithms. We hope our findings can offer valuable
theoretical and practical insights to understand of model robustness under
inaccurate supervision.

</details>


### [41] [Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare](https://arxiv.org/abs/2505.16190)
*Navid Seidi, Satyaki Roy, Sajal Das*

**主要类别:** cs.LG

**概要:** 提出了一种新的联邦学习声誉机制，用于医疗保健领域，能有效处理数据异质性和声誉赤字问题。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习在数字健康中的应用面临机构间异质性、声誉持续性不足和贡献不可靠等挑战。

**方法:** 采用混合通信模型整合分散的同行反馈，并结合基于聚类的噪声处理来增强模型聚合；通过差分隐私技术在共享前对客户端模型更新进行处理。

**结果:** 实验表明该方法在合成数据集和SEER数据集上均能获得高且稳定的C-index值，能有效降低噪声客户端更新的影响。

**结论:** 本研究提出的声誉机制能够保护敏感信息，同时提高联邦学习模型的稳定性和准确性，在解决联邦学习中的声誉和数据异质性问题方面取得了显著进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Federated+Survival+Analysis+through+Peer-Driven+Client+Reputation+in+Healthcare，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16190，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16190&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) holds great promise for digital health by enabling
collaborative model training without compromising patient data privacy.
However, heterogeneity across institutions, lack of sustained reputation, and
unreliable contributions remain major challenges. In this paper, we propose a
robust, peer-driven reputation mechanism for federated healthcare that employs
a hybrid communication model to integrate decentralized peer feedback with
clustering-based noise handling to enhance model aggregation. Crucially, our
approach decouples the federated aggregation and reputation mechanisms by
applying differential privacy to client-side model updates before sharing them
for peer evaluation. This ensures sensitive information remains protected
during reputation computation, while unaltered updates are sent to the server
for global model training. Using the Cox Proportional Hazards model for
survival analysis across multiple federated nodes, our framework addresses both
data heterogeneity and reputation deficit by dynamically adjusting trust scores
based on local performance improvements measured via the concordance index.
Experimental evaluations on both synthetic datasets and the SEER dataset
demonstrate that our method consistently achieves high and stable C-index
values, effectively down-weighing noisy client updates and outperforming FL
methods that lack a reputation system.

</details>


### [42] [NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics](https://arxiv.org/abs/2505.16210)
*Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei*

**主要类别:** cs.LG

**概要:** 提出NQKV算法，通过优化KV缓存的量化方式，在保持模型输出质量的同时，使OPT模型能处理更大批量或更长上下文，提升吞吐量。


<details>
  <summary>更多</summary>
  
**动机:** 解决大型语言模型在推理过程中因更大的批量或更长上下文导致的KV缓存内存消耗增加问题。

**方法:** 设计了NQKV算法，利用KV缓存块内元素的正态分布特性，采用基于分块的分位数量化实现信息论最优量化误差。

**结果:** 与未使用KV缓存相比，NQKV算法可使OPT模型吞吐量提高9.3倍，并且能够在不显著影响模型输出质量的情况下，支持2倍大的批量或4倍长的上下文。

**结论:** 提出的NQKV算法有效地减少了KV缓存的空间占用，提高了大型语言模型的部署效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NQKV%3A+A+KV+Cache+Quantization+Scheme+Based+on+Normal+Distribution+Characteristics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16210，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16210&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable proficiency across
a wide range of tasks. However, LLMs often require larger batch sizes to
enhance throughput or longer context lengths to meet task demands, which
significantly increases the memory resource consumption of the Key-Value (KV)
cache during inference, becoming a major bottleneck in LLM deployment. To
address this issue, quantization is a common and straightforward approach.
Currently, quantization methods for activations are limited to 8-bit, and
quantization to even lower bits can lead to substantial accuracy drops. To
further save space by quantizing the KV cache to even lower bits, we analyzed
the element distribution of the KV cache and designed the NQKV algorithm. Since
the elements within each block of the KV cache follow a normal distribution,
NQKV employs per-block quantile quantization to achieve
information-theoretically optimal quantization error. Without significantly
compromising model output quality, NQKV enables the OPT model to perform
inference with an 2x larger batch size or a 4x longer context length, and it
improves throughput by 9.3x compared to when the KV cache is not used.

</details>


### [43] [Reward-Aware Proto-Representations in Reinforcement Learning](https://arxiv.org/abs/2505.16217)
*Hon Tik Tse, Siddarth Chandrasekar, Marlos C. Machado*

**主要类别:** cs.LG

**概要:** This paper discusses a new representation called Default Representation (DR) that considers reward dynamics in reinforcement learning. It provides theoretical foundations for DR in tabular cases and empirically shows its benefits in various settings.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitations of the successor representation (SR) which is reward-agnostic, this paper proposes the Default Representation (DR) that takes into account reward dynamics.

**方法:** The paper derives dynamic programming and temporal-difference methods to learn DR, characterizes the basis for the vector space of DR, and extends DR to the function approximation case through default features.

**结果:** Empirical results show that DR leads to qualitatively different, reward-aware behavior and quantitatively better performance than SR in several settings.

**结论:** The paper establishes a theoretical foundation for DR and demonstrates its advantages over SR in various reinforcement learning tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reward-Aware+Proto-Representations+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16217，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16217&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the successor representation (SR) has attracted increasing
attention in reinforcement learning (RL), and it has been used to address some
of its key challenges, such as exploration, credit assignment, and
generalization. The SR can be seen as representing the underlying credit
assignment structure of the environment by implicitly encoding its induced
transition dynamics. However, the SR is reward-agnostic. In this paper, we
discuss a similar representation that also takes into account the reward
dynamics of the problem. We study the default representation (DR), a recently
proposed representation with limited theoretical (and empirical) analysis.
Here, we lay some of the theoretical foundation underlying the DR in the
tabular case by (1) deriving dynamic programming and (2) temporal-difference
methods to learn the DR, (3) characterizing the basis for the vector space of
the DR, and (4) formally extending the DR to the function approximation case
through default features. Empirically, we analyze the benefits of the DR in
many of the settings in which the SR has been applied, including (1) reward
shaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our
results show that, compared to the SR, the DR gives rise to qualitatively
different, reward-aware behaviour and quantitatively better performance in
several settings.

</details>


### [44] [Realistic Evaluation of TabPFN v2 in Open Environments](https://arxiv.org/abs/2505.16226)
*Zi-Jian Cheng, Zi-Yi Jia, Zhi Zhou, Yu-Feng Li, Lan-Zhe Guo*

**主要类别:** cs.LG

**概要:** This paper evaluates TabPFN v2's adaptability in open environments, finding it limited but suitable for specific tasks.


<details>
  <summary>更多</summary>
  
**动机:** To investigate whether TabPFN v2 can maintain good performance in open environments.

**方法:** Constructing a unified evaluation framework covering real-world challenges and assessing TabPFN v2's robustness.

**结果:** TabPFN v2 shows significant limitations in open environments but performs well on certain tasks like small-scale, covariate-shifted, and class-balanced tasks.

**结论:** Tree-based models remain better for general tabular tasks in open environments, and advocating for open benchmarks and modules to enhance robustness.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Realistic+Evaluation+of+TabPFN+v2+in+Open+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16226，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16226&send_immediately=true&force_search=false)

**原文摘要:** Tabular data, owing to its ubiquitous presence in real-world domains, has
garnered significant attention in machine learning research. While tree-based
models have long dominated tabular machine learning tasks, the recently
proposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled
performance and scalability potential. Although extensive research has been
conducted on TabPFN v2 to further improve performance, the majority of this
research remains confined to closed environments, neglecting the challenges
that frequently arise in open environments. This raises the question: Can
TabPFN v2 maintain good performance in open environments? To this end, we
conduct the first comprehensive evaluation of TabPFN v2's adaptability in open
environments. We construct a unified evaluation framework covering various
real-world challenges and assess the robustness of TabPFN v2 under open
environments scenarios using this framework. Empirical results demonstrate that
TabPFN v2 shows significant limitations in open environments but is suitable
for small-scale, covariate-shifted, and class-balanced tasks. Tree-based models
remain the optimal choice for general tabular tasks in open environments. To
facilitate future research on open environments challenges, we advocate for
open environments tabular benchmarks, multi-metric evaluation, and universal
modules to strengthen model robustness. We publicly release our evaluation
framework at https://anonymous.4open.science/r/tabpfn-ood-4E65.

</details>


### [45] [Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies](https://arxiv.org/abs/2505.16242)
*Runze Yan, Xun Shen, Akifumi Wachi, Sebastien Gros, Anni Zhao, Xiao Hu*

**主要类别:** cs.LG

**概要:** 提出了一种新的离线强化学习框架（OGSRL），用于医疗场景中的安全和可靠政策改进，解决了OOD问题并提供了理论上的安全性和接近最优性的保障。


<details>
  <summary>更多</summary>
  
**动机:** 在医疗场景中应用离线强化学习时，由于超出临床专业知识范围的不当泛化可能导致潜在有害建议，因此需要解决分布外（OOD）问题。

**方法:** 提出了一种名为Offline Guarded Safe Reinforcement Learning (OGSRL) 的新方法，该方法引入了双重约束机制来改善政策，包括OOD监护人和安全性成本约束。

**结果:** 实验表明，所提出的OGSRL方法在确保安全性与可靠性的同时，能够有效地发现优于临床医生行为的治疗策略，并且在理论上保证了安全性和接近最优性。

**结论:** 提出的方法在保证安全性和可靠性的同时，能够在离线强化学习框架下有效改进医疗场景中的治疗策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Offline+Guarded+Safe+Reinforcement+Learning+for+Medical+Treatment+Optimization+Strategies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16242，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16242&send_immediately=true&force_search=false)

**原文摘要:** When applying offline reinforcement learning (RL) in healthcare scenarios,
the out-of-distribution (OOD) issues pose significant risks, as inappropriate
generalization beyond clinical expertise can result in potentially harmful
recommendations. While existing methods like conservative Q-learning (CQL)
attempt to address the OOD issue, their effectiveness is limited by only
constraining action selection by suppressing uncertain actions. This
action-only regularization imitates clinician actions that prioritize
short-term rewards, but it fails to regulate downstream state trajectories,
thereby limiting the discovery of improved long-term treatment strategies. To
safely improve policy beyond clinician recommendations while ensuring that
state-action trajectories remain in-distribution, we propose \textit{Offline
Guarded Safe Reinforcement Learning} ($\mathsf{OGSRL}$), a theoretically
grounded model-based offline RL framework. $\mathsf{OGSRL}$ introduces a novel
dual constraint mechanism for improving policy with reliability and safety.
First, the OOD guardian is established to specify clinically validated regions
for safe policy exploration. By constraining optimization within these regions,
it enables the reliable exploration of treatment strategies that outperform
clinician behavior by leveraging the full patient state history, without
drifting into unsupported state-action trajectories. Second, we introduce a
safety cost constraint that encodes medical knowledge about physiological
safety boundaries, providing domain-specific safeguards even in areas where
training data might contain potentially unsafe interventions. Notably, we
provide theoretical guarantees on safety and near-optimality: policies that
satisfy these constraints remain in safe and reliable regions and achieve
performance close to the best possible policy supported by the data.

</details>


### [46] [Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems](https://arxiv.org/abs/2505.16248)
*Wenxuan Zhu, Qiyuan Wu, Tengda Tang, Renzi Meng, Sheng Chai, Xuehui Quan*

**主要类别:** cs.LG

**概要:** 提出了一种基于图神经网络的多节点协作感知机制，通过消息传递和状态更新模块，提高了节点对系统整体状态的认知能力，并在实验中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 解决分布式系统中多节点感知和延迟调度响应的问题。

**方法:** 构建了一个多层图神经网络，引入了消息传递和状态更新模块，设计了融合局部状态与全局特征的感知表示方法。

**结果:** 提出的机制在任务完成率、平均延迟、负载均衡和传输效率等方面优于主流算法。

**结论:** 所提模型具有快速收敛和高效响应复杂系统状态的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Neural+Network-Based+Collaborative+Perception+for+Adaptive+Scheduling+in+Distributed+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16248，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16248&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the limitations of multi-node perception and delayed
scheduling response in distributed systems by proposing a GNN-based multi-node
collaborative perception mechanism. The system is modeled as a graph structure.
Message-passing and state-update modules are introduced. A multi-layer graph
neural network is constructed to enable efficient information aggregation and
dynamic state inference among nodes. In addition, a perception representation
method is designed by fusing local states with global features. This improves
each node's ability to perceive the overall system status. The proposed method
is evaluated within a customized experimental framework. A dataset featuring
heterogeneous task loads and dynamic communication topologies is used.
Performance is measured in terms of task completion rate, average latency, load
balancing, and transmission efficiency. Experimental results show that the
proposed method outperforms mainstream algorithms under various conditions,
including limited bandwidth and dynamic structural changes. It demonstrates
superior perception capabilities and cooperative scheduling performance. The
model achieves rapid convergence and efficient responses to complex system
states.

</details>


### [47] [Small-to-Large Generalization: Data Influences Models Consistently Across Scale](https://arxiv.org/abs/2505.16260)
*Alaa Khaddaj, Logan Engstrom, Aleksander Madry*

**主要类别:** cs.LG

**概要:** This paper investigates how training data distribution influences model behavior across different compute scales for large-scale language models.


<details>
  <summary>更多</summary>
  
**动机:** The challenge of precisely characterizing the impact of training data changes on model predictions due to high training costs.

**方法:** Comparative analysis of small and large-scale language model predictions across different training data choices.

**结果:** Small- and large-scale language model predictions highly correlate across training data choices.

**结论:** Understanding the effect of proxy scale on effectiveness in data attribution and dataset selection.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Small-to-Large+Generalization%3A+Data+Influences+Models+Consistently+Across+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16260&send_immediately=true&force_search=false)

**原文摘要:** Choice of training data distribution greatly influences model behavior. Yet,
in large-scale settings, precisely characterizing how changes in training data
affects predictions is often difficult due to model training costs. Current
practice is to instead extrapolate from scaled down, inexpensive-to-train proxy
models. However, changes in data do not influence smaller and larger models
identically. Therefore, understanding how choice of data affects large-scale
models raises the question: how does training data distribution influence model
behavior across compute scale? We find that small- and large-scale language
model predictions (generally) do highly correlate across choice of training
data. Equipped with these findings, we characterize how proxy scale affects
effectiveness in two downstream proxy model applications: data attribution and
dataset selection.

</details>


### [48] [Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models](https://arxiv.org/abs/2505.16265)
*Ilgee Hong, Changlong Yu, Liang Qiu, Weixiang Yan, Zhenghao Xu, Haoming Jiang, Qingru Zhang, Qin Lu, Xin Liu, Chao Zhang, Tuo Zhao*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的框架Think-RM，用于增强生成奖励模型的长时间推理能力，并设计了一种新的RLHF管道，从而在RM-Bench基准测试中取得了最佳性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成奖励模型（GenRMs）依赖于浅层、垂直扩展的推理，这限制了它们处理复杂任务的能力，并且其成对偏好输出与需要点式奖励信号的标准RLHF算法不兼容。

**方法:** 引入了一个名为Think-RM的新框架，它通过建模内部思考过程来使生成奖励模型（GenRMs）实现长时间推理。此外，还提出了一个新的成对RLHF管道，可以直接优化策略使用成对偏好奖励。

**结果:** Think-RM在RM-Bench上的表现比传统的Bradley-Terry奖励模型和垂直扩展的GenRM高出8%。结合新的成对RLHF管道后，其端到端策略性能也优于传统方法。

**结论:** Think-RM在RM-Bench上达到了最先进的结果，并且结合提出的成对RLHF管道后，显示出了优于传统方法的端到端策略性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think-RM%3A+Enabling+Long-Horizon+Reasoning+in+Generative+Reward+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16265，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16265&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning from human feedback (RLHF) has become a powerful
post-training paradigm for aligning large language models with human
preferences. A core challenge in RLHF is constructing accurate reward signals,
where the conventional Bradley-Terry reward models (BT RMs) often suffer from
sensitivity to data size and coverage, as well as vulnerability to reward
hacking. Generative reward models (GenRMs) offer a more robust alternative by
generating chain-of-thought (CoT) rationales followed by a final reward.
However, existing GenRMs rely on shallow, vertically scaled reasoning, limiting
their capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.
Moreover, their pairwise preference outputs are incompatible with standard RLHF
algorithms that require pointwise reward signals. In this work, we introduce
Think-RM, a training framework that enables long-horizon reasoning in GenRMs by
modeling an internal thinking process. Rather than producing structured,
externally provided rationales, Think-RM generates flexible, self-guided
reasoning traces that support advanced capabilities such as self-reflection,
hypothetical reasoning, and divergent reasoning. To elicit these reasoning
abilities, we first warm-up the models by supervised fine-tuning (SFT) over
long CoT data. We then further improve the model's long-horizon abilities by
rule-based reinforcement learning (RL). In addition, we propose a novel
pairwise RLHF pipeline that directly optimizes policies using pairwise
preference rewards, eliminating the need for pointwise reward conversion and
enabling more effective use of Think-RM outputs. Experiments show that Think-RM
achieves state-of-the-art results on RM-Bench, outperforming both BT RM and
vertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,
it demonstrates superior end-policy performance compared to traditional
approaches.

</details>


### [49] [Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse](https://arxiv.org/abs/2505.16284)
*Josh Alman, Zhao Song*

**主要类别:** cs.LG

**概要:** This paper explores the necessity of large weights in avoiding layer collapse in large language models.


<details>
  <summary>更多</summary>
  
**动机:** To investigate why attention mechanisms in large language models have quadratic time complexity.

**方法:** Theoretical analysis and introduction of the concept of layer collapse.

**结果:** Layer collapse leads to reduced representational strength, and large weights are necessary to prevent it.

**结论:** Quadratic running time of attention is unavoidable for expressive transformers.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Only+Large+Weights+%28And+Not+Skip+Connections%29+Can+Prevent+the+Perils+of+Rank+Collapse，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16284，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16284&send_immediately=true&force_search=false)

**原文摘要:** Attention mechanisms lie at the heart of modern large language models (LLMs).
Straightforward algorithms for forward and backward (gradient) computation take
quadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]
and [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary
unless the model weights are small, in which case almost linear time algorithms
are possible. In this paper, we show that large weights are necessary to avoid
a strong preclusion to representational strength we call layer collapse, which
means that the entire network can be approximated well by a network with only a
single layer. Thus, the quadratic running time of attention is unavoidable for
expressive transformers.
  The notion of layer collapse that we introduce is a variant on the notion of
rank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They
showed that in Self Attention Networks with small weights and with skip
connections, rank collapse must occur. This is typically interpreted as
justifying the necessity of skip connections in expressive networks. However,
our result shows that even with skip connections, if the weights are small,
then layer collapse still occurs. Thus, only large weights, and not skip
connections, can prevent these representational weaknesses.

</details>


### [50] [Fairness under Competition](https://arxiv.org/abs/2505.16291)
*Ronen Gradwohl, Eilam Shapira, Moshe Tennenholtz*

**主要类别:** cs.LG

**概要:** This paper examines how fair classifiers affect ecosystem fairness in competitive environments.


<details>
  <summary>更多</summary>
  
**动机:** To understand the impact of fair classifiers on overall ecosystem fairness.

**方法:** Theoretical analysis and experimental evidence considering classifiers' correlation and data overlap.

**结果:** Even individually fair classifiers can lead to unfair ecosystems, and improving individual fairness might reduce overall ecosystem fairness.

**结论:** Calls for a novel approach to address fairness in competitive ML ecosystems.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fairness+under+Competition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16291，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16291&send_immediately=true&force_search=false)

**原文摘要:** Algorithmic fairness has emerged as a central issue in ML, and it has become
standard practice to adjust ML algorithms so that they will satisfy fairness
requirements such as Equal Opportunity. In this paper we consider the effects
of adopting such fair classifiers on the overall level of ecosystem fairness.
Specifically, we introduce the study of fairness with competing firms, and
demonstrate the failure of fair classifiers in yielding fair ecosystems. Our
results quantify the loss of fairness in systems, under a variety of
conditions, based on classifiers' correlation and the level of their data
overlap. We show that even if competing classifiers are individually fair, the
ecosystem's outcome may be unfair; and that adjusting biased algorithms to
improve their individual fairness may lead to an overall decline in ecosystem
fairness. In addition to these theoretical results, we also provide supporting
experimental evidence. Together, our model and results provide a novel and
essential call for action.

</details>


### [51] [Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution](https://arxiv.org/abs/2505.16305)
*Bingyang Cheng, Zhongtao Chen, Yichen Jin, Hao Zhang, Chen Zhang, Edmud Y. Lam, Yik-Chung Wu*

**主要类别:** cs.LG

**概要:** A scalable Bayesian tensor CPD algorithm avoiding high-dimensional matrix inversions.


<details>
  <summary>更多</summary>
  
**动机:** Existing Bayesian methods for tensor CPD do not scale well for large tensors due to high-dimensional matrix inversions.

**方法:** Introduces CP-GAMP which uses GAMP and EM routine to infer tensor rank and noise power.

**结果:** Reduces runtime by 82.7% compared to the state-of-the-art VB method while maintaining comparable reconstruction accuracy.

**结论:** CP-GAMP is a scalable solution for Bayesian tensor CPD with good performance.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large-Scale+Bayesian+Tensor+Reconstruction%3A+An+Approximate+Message+Passing+Solution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16305&send_immediately=true&force_search=false)

**原文摘要:** Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for
tensor reconstruction. Although the Bayesian framework allows for principled
uncertainty quantification and automatic hyperparameter learning, existing
methods do not scale well for large tensors because of high-dimensional matrix
inversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD
algorithm. This algorithm leverages generalized approximate message passing
(GAMP) to avoid matrix inversions and incorporates an expectation-maximization
routine to jointly infer the tensor rank and noise power. Through multiple
experiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements
observed, the proposed algorithm reduces runtime by 82.7% compared to the
state-of-the-art variational Bayesian CPD method, while maintaining comparable
reconstruction accuracy.

</details>


### [52] [CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting](https://arxiv.org/abs/2505.16308)
*Xingyu Zhang, Wenwen Qiang, Siyu Zhao, Huijie Guo, Jiangmeng Li, Chuxiong Sun, Changwen Zheng*

**主要类别:** cs.LG

**概要:** 提出一种新的因果导向的时间序列预测方法CAIFormer，通过区分时间序列的不同因果成分来提高预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法采用全对全范式，难以识别变量特定的因果影响，常混入虚假相关性。

**方法:** 构建结构因果模型，将历史序列分为四部分，并提出包含三个子模块的CAIFormer模型。

**结果:** 在多个基准数据集上的实验验证了CAIFormer的有效性。

**结论:** 提出的all-to-one范式和CAIFormer模型能够有效提升多变量时间序列预测的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CAIFormer%3A+A+Causal+Informed+Transformer+for+Multivariate+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16308，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16308&send_immediately=true&force_search=false)

**原文摘要:** Most existing multivariate time series forecasting methods adopt an
all-to-all paradigm that feeds all variable histories into a unified model to
predict their future values without distinguishing their individual roles.
However, this undifferentiated paradigm makes it difficult to identify
variable-specific causal influences and often entangles causally relevant
information with spurious correlations. To address this limitation, we propose
an all-to-one forecasting paradigm that predicts each target variable
separately. Specifically, we first construct a Structural Causal Model from
observational data and then, for each target variable, we partition the
historical sequence into four sub-segments according to the inferred causal
structure: endogenous, direct causal, collider causal, and spurious
correlation. The prediction relies solely on the first three causally relevant
sub-segments, while the spurious correlation sub-segment is excluded.
Furthermore, we propose Causal Informed Transformer (CAIFormer), a novel
forecasting model comprising three components: Endogenous Sub-segment
Prediction Block, Direct Causal Sub-segment Prediction Block, and Collider
Causal Sub-segment Prediction Block, which process the endogenous, direct
causal, and collider causal sub-segments, respectively. Their outputs are then
combined to produce the final prediction. Extensive experiments on multiple
benchmark datasets demonstrate the effectiveness of the CAIFormer.

</details>


### [53] [FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail](https://arxiv.org/abs/2505.16319)
*Yangyang Wang, Jiawei Gu, Li Long, Xin Li, Li Shen, Zhouyu Fu, Xiangjun Zhou, Xu Jiang*

**主要类别:** cs.LG

**概要:** 本文介绍了FreshRetailNet-50K，一个针对易腐品零售需求估计的大规模基准数据集，并展示了其在需求补充分析上的应用效果。


<details>
  <summary>更多</summary>
  
**动机:** 准确估计需求对于指导易腐产品库存和定价政策至关重要，但因缺货导致的销售数据被审查给需求估计带来了根本挑战。现有的数据集缺乏解决这种审查效应所需的时间分辨率和注释。

**方法:** 构建了一个包含50,000个商店产品的数据集，该数据集具有详细的时间序列销售数据，用于解决因缺货导致的需求数据缺失问题。通过两阶段需求建模方法，首先重构缺货期间的潜在需求，然后利用恢复的需求训练鲁棒的需求预测模型。

**结果:** 提出的两阶段需求建模方法在预测准确性上提高了2.73%，并将系统性的需求低估从7.37%减少到接近零偏差。

**结论:** 提出的新数据集FreshRetailNet-50K通过高时间分辨率和全面的现实世界信息，在需求补充分析、易腐品库存优化和因果零售分析方面开辟了新的研究方向。同时解决了零售AI中的长期局限性，提供了即时解决方案及未来方法创新的平台。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FreshRetailNet-50K%3A+A+Stockout-Annotated+Censored+Demand+Dataset+for+Latent+Demand+Recovery+and+Forecasting+in+Fresh+Retail，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16319，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16319&send_immediately=true&force_search=false)

**原文摘要:** Accurate demand estimation is critical for the retail business in guiding the
inventory and pricing policies of perishable products. However, it faces
fundamental challenges from censored sales data during stockouts, where
unobserved demand creates systemic policy biases. Existing datasets lack the
temporal resolution and annotations needed to address this censoring effect. To
fill this gap, we present FreshRetailNet-50K, the first large-scale benchmark
for censored demand estimation. It comprises 50,000 store-product time series
of detailed hourly sales data from 898 stores in 18 major cities, encompassing
863 perishable SKUs meticulously annotated for stockout events. The hourly
stock status records unique to this dataset, combined with rich contextual
covariates, including promotional discounts, precipitation, and temporal
features, enable innovative research beyond existing solutions. We demonstrate
one such use case of two-stage demand modeling: first, we reconstruct the
latent demand during stockouts using precise hourly annotations. We then
leverage the recovered demand to train robust demand forecasting models in the
second stage. Experimental results show that this approach achieves a 2.73\%
improvement in prediction accuracy while reducing the systematic demand
underestimation from 7.37\% to near-zero bias. With unprecedented temporal
granularity and comprehensive real-world information, FreshRetailNet-50K opens
new research directions in demand imputation, perishable inventory
optimization, and causal retail analytics. The unique annotation quality and
scale of the dataset address long-standing limitations in retail AI, providing
immediate solutions and a platform for future methodological innovation. The
data (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code
(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.

</details>


### [54] [AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners](https://arxiv.org/abs/2505.16322)
*Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun*

**主要类别:** cs.LG

**概要:** Introduce AdaSTaR, a novel algorithm that improves both performance and efficiency of self-improving language models by integrating two adaptive sampling principles.


<details>
  <summary>更多</summary>
  
**动机:** Address the issue of trained observation imbalance caused by random observation sampling in self-improving reasoning language models.

**方法:** Propose Adaptive STaR (AdaSTaR) with two adaptive sampling principles: (1) Adaptive Sampling for Diversity and (2) Adaptive Sampling for Curriculum.

**结果:** Achieves best test accuracy in all six benchmarks and reduces training FLOPs by 58.6% on average compared to baselines.

**结论:** AdaSTaR enhances the efficiency and effectiveness of self-improving language models, applicable to different pre-trained models and larger models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdaSTaR%3A+Adaptive+Data+Sampling+for+Training+Self-Taught+Reasoners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16322&send_immediately=true&force_search=false)

**原文摘要:** Self-Taught Reasoners (STaR), synonymously known as Rejection sampling
Fine-Tuning (RFT), is an integral part of the training pipeline of
self-improving reasoning Language Models (LMs). The self-improving mechanism
often employs random observation (data) sampling. However, this results in
trained observation imbalance; inefficiently over-training on solved examples
while under-training on challenging ones. In response, we introduce Adaptive
STaR (AdaSTaR), a novel algorithm that rectifies this by integrating two
adaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting
balanced training across observations, and (2) Adaptive Sampling for
Curriculum: dynamically adjusting data difficulty to match the model's evolving
strength. Across six benchmarks, AdaSTaR achieves best test accuracy in all
instances (6/6) and reduces training FLOPs by an average of 58.6% against an
extensive list of baselines. These improvements in performance and efficiency
generalize to different pre-trained LMs and larger models, paving the way for
more efficient and effective self-improving LMs.

</details>


### [55] [ChemMLLM: Chemical Multimodal Large Language Model](https://arxiv.org/abs/2505.16326)
*Qian Tan, Dongzhan Zhou, Peng Xia, Wanhao Liu, Wanli Ouyang, Lei Bai, Yuqiang Li, Tianfan Fu*

**主要类别:** cs.LG

**概要:** 提出ChemMLLM模型用于分子理解和生成，该模型在文本、分子SMILES字符串和图像的多模态任务上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 化学多模态大型语言模型（MLLMs）尚未被充分探索，本研究旨在填补这一空白。

**方法:** 提出ChemMLLM模型，并设计了五个跨文本、分子SMILES字符串和图像的多模态任务，同时整理了数据集。

**结果:** ChemMLLM在所评估的所有任务中都取得了优异的成绩，在分子图像优化任务中比最好的基线模型GPT-4o高出118.9%。

**结论:** 实验结果表明ChemMLLM在分子理解和生成方面具有卓越性能，推动了化学MLLMs的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ChemMLLM%3A+Chemical+Multimodal+Large+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16326&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) have made impressive progress in
many applications in recent years. However, chemical MLLMs that can handle
cross-modal understanding and generation remain underexplored. To fill this
gap, in this paper, we propose ChemMLLM, a unified chemical multimodal large
language model for molecule understanding and generation. Also, we design five
multimodal tasks across text, molecular SMILES strings, and image, and curate
the datasets. We benchmark ChemMLLM against a range of general leading MLLMs
and Chemical LLMs on these tasks. Experimental results show that ChemMLLM
achieves superior performance across all evaluated tasks. For example, in
molecule image optimization task, ChemMLLM outperforms the best baseline
(GPT-4o) by 118.9\% (4.27 vs 1.95 property improvement). The code is publicly
available at https://github.com/bbsbz/ChemMLLM.git.

</details>


### [56] [Understanding Differential Transformer Unchains Pretrained Self-Attentions](https://arxiv.org/abs/2505.16333)
*Chaerin Kong, Jiho Jang, Nojun Kwak*

**主要类别:** cs.LG

**概要:** This paper investigates Differential Transformer and proposes DEX, which efficiently integrates differential attention into pretrained language models.


<details>
  <summary>更多</summary>
  
**动机:** To understand the empirical benefits of differential attention and make it available for pretrained language models.

**方法:** Adding lightweight differential operation on the output value matrix.

**结果:** DEX enhances the performance of various benchmarks.

**结论:** DEX improves pretrained language models significantly with little adaptation data.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Differential+Transformer+Unchains+Pretrained+Self-Attentions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16333，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16333&send_immediately=true&force_search=false)

**原文摘要:** Differential Transformer has recently gained significant attention for its
impressive empirical performance, often attributed to its ability to perform
noise canceled attention. However, precisely how differential attention
achieves its empirical benefits remains poorly understood. Moreover,
Differential Transformer architecture demands large-scale training from
scratch, hindering utilization of open pretrained weights. In this work, we
conduct an in-depth investigation of Differential Transformer, uncovering three
key factors behind its success: (1) enhanced expressivity via negative
attention, (2) reduced redundancy among attention heads, and (3) improved
learning dynamics. Based on these findings, we propose DEX, a novel method to
efficiently integrate the advantages of differential attention into pretrained
language models. By reusing the softmax attention scores and adding a
lightweight differential operation on the output value matrix, DEX effectively
incorporates the key advantages of differential attention while remaining
lightweight in both training and inference. Evaluations confirm that DEX
substantially improves the pretrained LLMs across diverse benchmarks, achieving
significant performance gains with minimal adaptation data (< 0.01\%).

</details>


### [57] [Improving Chemical Understanding of LLMs via SMILES Parsing](https://arxiv.org/abs/2505.16340)
*Yunhui Jang, Jaehyung Kim, Sungsoo Ahn*

**主要类别:** cs.LG

**概要:** CLEANMOL是一种新的框架，通过将SMILES解析转换为一系列清晰且确定的任务来提高分子结构理解。实验表明CLEANMOL在增强结构理解方面有效，并在Mol-Instructions基准测试中表现出色或与基线竞争。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型语言模型（LLMs）难以解释SMILES表示的分子结构，即使基本任务如计数分子环也难以完成。

**方法:** 提出CLEANMOL框架，将SMILES解析任务分解为从子图匹配到全局图匹配的一系列任务，并创建带适应性难度评分的分子预训练数据集，在开源LLMs上进行预训练。

**结果:** CLEANMOL不仅增强了分子结构理解，还在Mol-Instructions基准测试中表现优异或与基线竞争。

**结论:** CLEANMOL为提高LLMs在分子科学中的应用能力提供了一种有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Chemical+Understanding+of+LLMs+via+SMILES+Parsing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16340，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16340&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly recognized as powerful tools
for scientific discovery, particularly in molecular science. A fundamental
requirement for these models is the ability to accurately understand molecular
structures, commonly encoded in the SMILES representation. However, current
LLMs struggle to interpret SMILES, even failing to carry out basic tasks such
as counting molecular rings. To address this limitation, we introduce CLEANMOL,
a novel framework that formulates SMILES parsing into a suite of clean and
deterministic tasks explicitly designed to promote graph-level molecular
comprehension. These tasks span from subgraph matching to global graph
matching, providing structured supervision aligned with molecular structural
properties. We construct a molecular pretraining dataset with adaptive
difficulty scoring and pre-train open-source LLMs on these tasks. Our results
show that CLEANMOL not only enhances structural comprehension but also achieves
the best or competes with the baseline on the Mol-Instructions benchmark.

</details>


### [58] [A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2505.16341)
*Yaxin Hou, Yuheng Jia*

**主要类别:** cs.LG

**概要:** 提出了一种动态专家分配模块和多深度特征融合模块，用于解决长尾半监督学习中的分布不匹配问题，并在多个数据集上验证了方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法未充分利用不同辅助分类器的专长，且模型存在偏向头部类别的问题。

**方法:** 提出动态专家分配模块估计样本类别并分配合适专家生成伪标签，以及多深度特征融合模块利用不同深度特征减轻模型偏差。

**结果:** 在CIFAR-10-LT、STL-10-LT、SVHN-LT数据集上进行了全面实验，证明了方法的有效性。

**结论:** 所提方法通过充分利用不同专家的优势和融合多深度特征，有效缓解了长尾半监督学习中的分布不匹配问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Square+Peg+in+a+Square+Hole%3A+Meta-Expert+for+Long-Tailed+Semi-Supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16341，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16341&send_immediately=true&force_search=false)

**原文摘要:** This paper studies the long-tailed semi-supervised learning (LTSSL) with
distribution mismatch, where the class distribution of the labeled training
data follows a long-tailed distribution and mismatches with that of the
unlabeled training data. Most existing methods introduce auxiliary classifiers
(experts) to model various unlabeled data distributions and produce
pseudo-labels, but the expertises of various experts are not fully utilized. We
observe that different experts are good at predicting different intervals of
samples, e.g., long-tailed expert is skilled in samples located in the head
interval and uniform expert excels in samples located in the medium interval.
Therefore, we propose a dynamic expert assignment module that can estimate the
class membership (i.e., head, medium, or tail class) of samples, and
dynamically assigns suitable expert to each sample based on the estimated
membership to produce high-quality pseudo-label in the training phase and
produce prediction in the testing phase. We also theoretically reveal that
integrating different experts' strengths will lead to a smaller generalization
error bound. Moreover, we find that the deeper features are more biased toward
the head class but with more discriminative ability, while the shallower
features are less biased but also with less discriminative ability. We,
therefore, propose a multi-depth feature fusion module to utilize different
depth features to mitigate the model bias. Our method demonstrates its
effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,
and SVHN-LT datasets across various settings. The code is available at
https://github.com/yaxinhou/Meta-Expert.

</details>


### [59] [Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning](https://arxiv.org/abs/2505.16353)
*Céline Comte, Pascal Moyal*

**主要类别:** cs.LG

**概要:** This paper proposes a new method for optimizing arrival rates in quasi-reversible queueing systems by introducing balanced arrival control policies.


<details>
  <summary>更多</summary>
  
**动机:** To improve the efficiency and performance of queueing systems by optimizing arrival rates.

**方法:** Proposing an alternative definition of quasi-reversibility and introducing balanced arrival control policies.

**结果:** Proved that supplementing a quasi-reversible queueing system with a balanced arrival-control policy preserves the quasi-reversibility and specified the form of the stationary measures.

**结论:** The proposed method can be applied to admission control problems and optimized using reinforcement learning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Arrival+Control+in+Quasi-Reversible+Queueing+Systems%3A+Optimization+and+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16353&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we introduce a versatile scheme for optimizing the arrival
rates of quasi-reversible queueing systems. We first propose an alternative
definition of quasi-reversibility that encompasses reversibility and highlights
the importance of the definition of customer classes. In a second time, we
introduce balanced arrival control policies, which generalize the notion of
balanced arrival rates introduced in the context of Whittle networks, to the
much broader class of quasi-reversible queueing systems. We prove that
supplementing a quasi-reversible queueing system with a balanced
arrival-control policy preserves the quasi-reversibility, and we specify the
form of the stationary measures. We revisit two canonical examples of
quasi-reversible queueing systems, Whittle networks and order-independent
queues. Lastly, we focus on the problem of admission control and leverage our
results in the frameworks of optimization and reinforcement learning.

</details>


### [60] [A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules](https://arxiv.org/abs/2505.16365)
*Manuel Ruiz-Botella, Marta Sales-Pardo, Roger Guimerà*

**主要类别:** cs.LG

**概要:** This paper introduces CoCoGraph, a model for generating chemically valid molecules, which outperforms existing methods on benchmarks with fewer parameters and creates a large database of synthetic molecules for further assessment.


<details>
  <summary>更多</summary>
  
**动机:** The need to explore the vast molecular space to discover new molecules for addressing challenges in health and environmental sustainability.

**方法:** A collaborative and constrained graph diffusion model called CoCoGraph.

**结果:** Outperforms state-of-the-art approaches on benchmarks, requires fewer parameters, and generates molecules with distributions closer to real molecules.

**结论:** CoCoGraph is efficient in generating chemically valid molecules and has been used to create a large database of synthetic molecules for further evaluation by experts.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+collaborative+constrained+graph+diffusion+model+for+the+generation+of+realistic+synthetic+molecules，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16365，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16365&send_immediately=true&force_search=false)

**原文摘要:** Developing new molecular compounds is crucial to address pressing challenges,
from health to environmental sustainability. However, exploring the molecular
space to discover new molecules is difficult due to the vastness of the space.
Here we introduce CoCoGraph, a collaborative and constrained graph diffusion
model capable of generating molecules that are guaranteed to be chemically
valid. Thanks to the constraints built into the model and to the collaborative
mechanism, CoCoGraph outperforms state-of-the-art approaches on standard
benchmarks while requiring up to an order of magnitude fewer parameters.
Analysis of 36 chemical properties also demonstrates that CoCoGraph generates
molecules with distributions more closely matching real molecules than current
models. Leveraging the model's efficiency, we created a database of 8.2M
million synthetically generated molecules and conducted a Turing-like test with
organic chemistry experts to further assess the plausibility of the generated
molecules, and potential biases and limitations of CoCoGraph.

</details>


### [61] [SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning](https://arxiv.org/abs/2505.16368)
*Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, Ge Li*

**主要类别:** cs.LG

**概要:** Saturn是一个基于SAT的强化学习框架，通过布尔可满足性问题训练和评估大型语言模型的推理能力，解决了现有任务的可扩展性、可验证性和可控难度的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有强化学习任务在可扩展性、可验证性和可控难度方面存在局限性，需要更有效的任务设计来释放大型语言模型的推理能力。

**方法:** 提出Saturn框架，使用SAT问题进行训练和评估，设计了课程学习管道，并控制难度过渡，发布了Saturn-2.6k数据集以及Saturn-1.5B和Saturn-7B模型。

**结果:** Saturn-1.5B和Saturn-7B在SAT问题上分别提升了14.0%和28.1%的pass@3指标，在数学和编程任务上也有所提升，且比最先进的方法提高了8.8%。

**结论:** Saturn框架有效提升了大型语言模型的推理能力，并且在多个任务上取得了显著成果，同时开放了源代码、数据和模型以支持进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SATURN%3A+SAT-based+Reinforcement+Learning+to+Unleash+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16368，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16368&send_immediately=true&force_search=false)

**原文摘要:** How to design reinforcement learning (RL) tasks that effectively unleash the
reasoning capability of large language models (LLMs) remains an open question.
Existing RL tasks (e.g., math, programming, and constructing reasoning tasks)
suffer from three key limitations: (1) Scalability. They rely heavily on human
annotation or expensive LLM synthesis to generate sufficient training data. (2)
Verifiability. LLMs' outputs are hard to verify automatically and reliably. (3)
Controllable Difficulty. Most tasks lack fine-grained difficulty control,
making it hard to train LLMs to develop reasoning ability from easy to hard.
  To address these limitations, we propose Saturn, a SAT-based RL framework
that uses Boolean Satisfiability (SAT) problems to train and evaluate LLM
reasoning. Saturn enables scalable task construction, rule-based verification,
and precise difficulty control. Saturn designs a curriculum learning pipeline
that continuously improves LLMs' reasoning capability by constructing SAT tasks
of increasing difficulty and training LLMs from easy to hard. To ensure stable
training, we design a principled mechanism to control difficulty transitions.
  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying
difficulty. It supports the evaluation of how LLM reasoning changes with
problem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain
Saturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT
problems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of
+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B
and Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,
AIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in
constructing RL tasks, Saturn achieves further improvements of +8.8%. We
release the source code, data, and models to support future research.

</details>


### [62] [Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space](https://arxiv.org/abs/2505.16386)
*Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo*

**主要类别:** cs.LG

**概要:** 提出了一种新的嵌入模型Omni TM-AE，它利用了Tsetlin机器状态矩阵中的信息，实现了可重用且可解释的嵌入。实验表明，该模型在语义相似性、情感分类和文档聚类任务上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 传统嵌入模型如Word2Vec和GloVe虽然可扩展性强，但缺乏透明度；而可解释模型如Tsetlin机器虽然可解释性强，但在可扩展性和可重用性方面存在局限。因此，研究者试图开发一种既可解释又可扩展的嵌入模型。

**方法:** 提出了Omni Tsetlin Machine AutoEncoder (Omni TM-AE)，通过单次训练阶段构建可重用、可解释的嵌入。该方法充分利用了Tsetlin机器状态矩阵中的信息。

**结果:** Omni TM-AE在语义相似性、情感分类和文档聚类任务上的表现与主流嵌入模型相当甚至更优。

**结论:** Omni TM-AE证明了在现代自然语言处理系统中，可以在不采用黑盒架构的情况下实现性能、可扩展性和可解释性的平衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omni+TM-AE%3A+A+Scalable+and+Interpretable+Embedding+Model+Using+the+Full+Tsetlin+Machine+State+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16386，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16386&send_immediately=true&force_search=false)

**原文摘要:** The increasing complexity of large-scale language models has amplified
concerns regarding their interpretability and reusability. While traditional
embedding models like Word2Vec and GloVe offer scalability, they lack
transparency and often behave as black boxes. Conversely, interpretable models
such as the Tsetlin Machine (TM) have shown promise in constructing explainable
learning systems, though they previously faced limitations in scalability and
reusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni
TM-AE), a novel embedding model that fully exploits the information contained
in the TM's state matrix, including literals previously excluded from clause
formation. This method enables the construction of reusable, interpretable
embeddings through a single training phase. Extensive experiments across
semantic similarity, sentiment classification, and document clustering tasks
show that Omni TM-AE performs competitively with and often surpasses mainstream
embedding models. These results demonstrate that it is possible to balance
performance, scalability, and interpretability in modern Natural Language
Processing (NLP) systems without resorting to opaque architectures.

</details>


### [63] [AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://arxiv.org/abs/2505.16400)
*Yang Chen, Zhuolin Yang, Zihan Liu, Chankyu Lee, Peng Xu, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping*

**主要类别:** cs.LG

**概要:** This paper demonstrates that large-scale reinforcement learning (RL) can significantly enhance the reasoning capabilities of strong small- and mid-sized models, surpassing state-of-the-art distillation-based models.


<details>
  <summary>更多</summary>
  
**动机:** The training recipe for building high-performing reasoning models remains elusive, and distillation is more effective than RL for smaller models.

**方法:** Systematically studying the RL training process through extensive ablations and proposing a simple yet effective approach: first training on math-only prompts, then on code-only prompts.

**结果:** Math-only RL enhances the performance of strong distilled models on math benchmarks and code reasoning tasks, and extended code-only RL iterations further improve performance on code benchmarks with minimal or no degradation in math results.

**结论:** RL not only elicits the foundational reasoning capabilities acquired during pretraining and supervised fine-tuning but also pushes the limits of the model's reasoning ability.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AceReason-Nemotron%3A+Advancing+Math+and+Code+Reasoning+through+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16400，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16400&send_immediately=true&force_search=false)

**原文摘要:** Despite recent progress in large-scale reinforcement learning (RL) for
reasoning, the training recipe for building high-performing reasoning models
remains elusive. Key implementation details of frontier models, such as
DeepSeek-R1, including data curation strategies and RL training recipe, are
often omitted. Moreover, recent research indicates distillation remains more
effective than RL for smaller models. In this work, we demonstrate that
large-scale RL can significantly enhance the reasoning capabilities of strong,
small- and mid-sized models, achieving results that surpass those of
state-of-the-art distillation-based models. We systematically study the RL
training process through extensive ablations and propose a simple yet effective
approach: first training on math-only prompts, then on code-only prompts.
Notably, we find that math-only RL not only significantly enhances the
performance of strong distilled models on math benchmarks (e.g., +14.6% /
+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks
(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,
extended code-only RL iterations further improve performance on code benchmarks
with minimal or no degradation in math results. We develop a robust data
curation pipeline to collect challenging prompts with high-quality, verifiable
answers and test cases to enable verification-based RL across both domains.
Finally, we identify key experimental insights, including curriculum learning
with progressively increasing response lengths and the stabilizing effect of
on-policy parameter updates. We find that RL not only elicits the foundational
reasoning capabilities acquired during pretraining and supervised fine-tuning
(e.g., distillation), but also pushes the limits of the model's reasoning
ability, enabling it to solve problems that were previously unsolvable.

</details>


### [64] [Divide-Fuse-Conquer: Eliciting "Aha Moments" in Multi-Scenario Games](https://arxiv.org/abs/2505.16401)
*Xiaoqing Zhang, Huabin Zheng, Ang Lv, Yuhan Liu, Zirui Song, Flood Sung, Xiuying Chen, Rui Yan*

**主要类别:** cs.LG

**概要:** Large language models can suddenly gain advanced reasoning skills through reinforcement learning, but this process struggles in multi-scenario games due to challenges like poor generalization. A proposed framework called Divide-Fuse-Conquer improves generalization in such settings.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of poor generalization in multi-scenario reinforcement learning for large language models.

**方法:** Divide-Fuse-Conquer, which divides games into groups, trains specialized models, fuses their parameters, and continues training.

**结果:** Experiments on 18 TextArena games showed that Qwen2.5-32B-Align trained with Divide-Fuse-Conquer performed comparably to Claude3.5.

**结论:** This approach could inspire further research on enhancing generalization of large language models using reinforcement learning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Divide-Fuse-Conquer%3A+Eliciting+%22Aha+Moments%22+in+Multi-Scenario+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16401，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16401&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have been observed to suddenly exhibit advanced
reasoning abilities during reinforcement learning (RL), resembling an ``aha
moment'' triggered by simple outcome-based rewards. While RL has proven
effective in eliciting such breakthroughs in tasks involving mathematics,
coding, and vision, it faces significant challenges in multi-scenario games.
The diversity of game rules, interaction modes, and environmental complexities
often leads to policies that perform well in one scenario but fail to
generalize to others. Simply combining multiple scenarios during training
introduces additional challenges, such as training instability and poor
performance. To overcome these challenges, we propose Divide-Fuse-Conquer, a
framework designed to enhance generalization in multi-scenario RL. This
approach starts by heuristically grouping games based on characteristics such
as rules and difficulties. Specialized models are then trained for each group
to excel at games in the group is what we refer to as the divide step. Next, we
fuse model parameters from different groups as a new model, and continue
training it for multiple groups, until the scenarios in all groups are
conquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align
trained with the Divide-Fuse-Conquer strategy reaches a performance level
comparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can
inspire future research on using reinforcement learning to improve the
generalization of LLMs.

</details>


### [65] [Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach](https://arxiv.org/abs/2505.16403)
*Huazi Pan, Yanjun Zhang, Leo Yu Zhang, Scott Adams, Abbas Kouzani, Suiyang Khoo*

**主要类别:** cs.LG

**概要:** 提出了一种新的联邦学习滑动攻击（FedSA）方案，该方案通过集成鲁棒非线性控制-滑模控制理论与模型中毒攻击，在不影响系统整体性能的情况下，精确地引入毒化程度。实验表明，FedSA可以在较少的恶意客户端下准确实现预定的全局精度，并保持高度隐蔽性和可调节的学习率。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中的协作性质带来了数据/模型投毒攻击的主要威胁。现有大多数投毒攻击旨在引发拒绝服务问题。本文旨在提出一种新方法，能够在微妙可控的方式下引入毒化效果。

**方法:** FedSA结合了滑模控制理论与模型投毒攻击，通过操纵恶意客户端的更新来驱动全局模型向妥协状态发展，同时利用FedSA的鲁棒控制特性精确控制收敛界限。

**结果:** FedSA能够以较少的恶意客户端准确实现预定的全局精度，同时保持高度隐蔽性和可调节的学习率。

**结论:** FedSA提供了一种在联邦学习环境中进行精确毒化的新途径，具有重要的研究意义和潜在的应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Performance+Guaranteed+Poisoning+Attacks+in+Federated+Learning%3A+A+Sliding+Mode+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16403&send_immediately=true&force_search=false)

**原文摘要:** Manipulation of local training data and local updates, i.e., the poisoning
attack, is the main threat arising from the collaborative nature of the
federated learning (FL) paradigm. Most existing poisoning attacks aim to
manipulate local data/models in a way that causes denial-of-service (DoS)
issues. In this paper, we introduce a novel attack method, named Federated
Learning Sliding Attack (FedSA) scheme, aiming at precisely introducing the
extent of poisoning in a subtle controlled manner. It operates with a
predefined objective, such as reducing global model's prediction accuracy by
10\%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)
theory with model poisoning attacks. It can manipulate the updates from
malicious clients to drive the global model towards a compromised state,
achieving this at a controlled and inconspicuous rate. Additionally, leveraging
the robust control properties of FedSA allows precise control over the
convergence bounds, enabling the attacker to set the global accuracy of the
poisoned model to any desired level. Experimental results demonstrate that
FedSA can accurately achieve a predefined global accuracy with fewer malicious
clients while maintaining a high level of stealth and adjustable learning
rates.

</details>


### [66] [Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](https://arxiv.org/abs/2505.16446)
*Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin*

**主要类别:** cs.LG

**概要:** 提出了一种新的隐式越狱框架IJA，通过最低有效位隐写术将恶意指令嵌入图像，并结合看似无害的图像相关文本提示，实现了对多种多模态大型语言模型的有效攻击。


<details>
  <summary>更多</summary>
  
**动机:** 现有的越狱攻击方法在多模态大型语言模型中变得容易被检测和阻止，因此需要一种新的攻击方式。

**方法:** 利用最低有效位隐写术将恶意指令嵌入图像，并结合生成的对抗后缀和模板优化模块来增强攻击效果。

**结果:** 该方法在GPT-4o和Gemini-1.5 Pro等商业模型上达到了超过90%的攻击成功率，平均仅需3次查询。

**结论:** 本研究展示了多模态大型语言模型中存在的安全风险，并提出了相应的攻击策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Implicit+Jailbreak+Attacks+via+Cross-Modal+Information+Concealment+on+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16446，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16446&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) enable powerful cross-modal
reasoning capabilities. However, the expanded input space introduces new attack
surfaces. Previous jailbreak attacks often inject malicious instructions from
text into less aligned modalities, such as vision. As MLLMs increasingly
incorporate cross-modal consistency and alignment mechanisms, such explicit
attacks become easier to detect and block. In this work, we propose a novel
implicit jailbreak framework termed IJA that stealthily embeds malicious
instructions into images via least significant bit steganography and couples
them with seemingly benign, image-related textual prompts. To further enhance
attack effectiveness across diverse MLLMs, we incorporate adversarial suffixes
generated by a surrogate model and introduce a template optimization module
that iteratively refines both the prompt and embedding based on model feedback.
On commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack
success rates of over 90% using an average of only 3 queries.

</details>


### [67] [Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics](https://arxiv.org/abs/2505.16493)
*Seyedeh Fatemeh Ebrahimi, Jaakko Peltonen*

**主要类别:** cs.LG

**概要:** 提出了一种通过特殊约束NMF进行主题建模的方法，无需专家预设少数主题的划分，能学习到数据驱动的少数主题和多数主题。该方法在人工合成数据上优于多个基准模型，并在YouTube视频日志评论的案例研究中成功识别出与领域相关的少数主题内容。


<details>
  <summary>更多</summary>
  
**动机:** 现有主题模型难以捕捉低频但重要的少数主题（如在线评论中的心理健康主题），而一些包含领域知识的方法可能需要过于详细的预期主题，阻碍了主题划分和变化的发现。

**方法:** 提出的解决方案是通过特别约束的非负矩阵分解（NMF）进行主题建模，利用种子词列表来描述感兴趣的少数主题内容，并通过少数主题的流行度约束和跨主题的种子词内容约束来学习不同的少数主题和多数主题。该算法使用Karush-Kuhn-Tucker (KKT) 条件和乘法更新进行拟合。

**结果:** 在合成数据上，该方法在主题纯度、归一化互信息方面表现优于多个基准模型，并且通过Jensen-Shannon散度评估了主题质量。在YouTube视频日志评论的案例研究中，成功识别并揭示了与领域相关的少数主题内容。

**结论:** 所提出的通过特殊约束NMF的主题建模方法能够有效地捕捉少数主题，且不需要专家提供详细的预期主题划分，从而提高了主题模型的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Constrained+Non-negative+Matrix+Factorization+for+Guided+Topic+Modeling+of+Minority+Topics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16493，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16493&send_immediately=true&force_search=false)

**原文摘要:** Topic models often fail to capture low-prevalence, domain-critical themes,
so-called minority topics, such as mental health themes in online comments.
While some existing methods can incorporate domain knowledge, such as expected
topical content, methods allowing guidance may require overly detailed expected
topics, hindering the discovery of topic divisions and variation. We propose a
topic modeling solution via a specially constrained NMF. We incorporate a seed
word list characterizing minority content of interest, but we do not require
experts to pre-specify their division across minority topics. Through
prevalence constraints on minority topics and seed word content across topics,
we learn distinct data-driven minority topics as well as majority topics. The
constrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with
multiplicative updates. We outperform several baselines on synthetic data in
terms of topic purity, normalized mutual information, and also evaluate topic
quality using Jensen-Shannon divergence (JSD). We conduct a case study on
YouTube vlog comments, analyzing viewer discussion of mental health content;
our model successfully identifies and reveals this domain-relevant minority
content.

</details>


### [68] [Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility](https://arxiv.org/abs/2505.16494)
*Noga Amit, Omer Reingold, Guy N. Rothblum*

**主要类别:** cs.LG

**概要:** This paper revisits fairness in machine learning with richer data labels, proposing algorithms for stronger fairness notions while maintaining accurate classification rates and loss minimization.


<details>
  <summary>更多</summary>
  
**动机:** To address fairness and its interaction with utility and efficiency using richer data labels in machine learning.

**方法:** Proposing algorithms that achieve stronger fairness notions through classification and ranking techniques while preserving accurate subpopulation classification rates.

**结果:** The proposed methods enable loss minimization and maintain accurate classification rates, but achieving both simultaneously is computationally infeasible.

**结论:** There is a trade-off between two attainable notions of accuracy due to the computational hardness of approximating the Bayes-optimal predictor.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accuracy+vs.+Accuracy%3A+Computational+Tradeoffs+Between+Classification+Rates+and+Utility，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16494，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16494&send_immediately=true&force_search=false)

**原文摘要:** We revisit the foundations of fairness and its interplay with utility and
efficiency in settings where the training data contain richer labels, such as
individual types, rankings, or risk estimates, rather than just binary
outcomes. In this context, we propose algorithms that achieve stronger notions
of evidence-based fairness than are possible in standard supervised learning.
Our methods support classification and ranking techniques that preserve
accurate subpopulation classification rates, as suggested by the underlying
data distributions, across a broad class of classification rules and downstream
applications. Furthermore, our predictors enable loss minimization, whether
aimed at maximizing utility or in the service of fair treatment.
  Complementing our algorithmic contributions, we present impossibility results
demonstrating that simultaneously achieving accurate classification rates and
optimal loss minimization is, in some cases, computationally infeasible. Unlike
prior impossibility results, our notions are not inherently in conflict and are
simultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show
that each notion can be satisfied individually via efficient learning. Our
separation thus stems from the computational hardness of learning a
sufficiently good approximation of the Bayes-optimal predictor. These
computational impossibilities present a choice between two natural and
attainable notions of accuracy that could both be motivated by fairness.

</details>


### [69] [Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods](https://arxiv.org/abs/2505.16516)
*Majid Mohammadi, Siu Lun Chau, Krikamol Muandet*

**主要类别:** cs.LG

**概要:** This paper introduces PKeX-Shapley, an algorithm that enables exact computation of Shapley values for product kernels in polynomial time, improving both computational efficiency and interpretability in kernel-based machine learning.


<details>
  <summary>更多</summary>
  
**动机:** To address the computational intractability of exact Shapley value computation and enhance interpretability in high-stakes machine learning applications.

**方法:** Developing PKeX-Shapley, which exploits the multiplicative structure of product kernels to allow exact Shapley value computation.

**结果:** The algorithm achieves polynomial-time complexity and improves interpretability in kernel-based learning while being applicable to explain kernel-based statistical discrepancies.

**结论:** PKeX-Shapley provides a novel approach for exact Shapley value computation in product kernels, enhancing both efficiency and interpretability in kernel-based machine learning and statistical inference.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computing+Exact+Shapley+Values+in+Polynomial+Time+for+Product-Kernel+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16516，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16516&send_immediately=true&force_search=false)

**原文摘要:** Kernel methods are widely used in machine learning due to their flexibility
and expressive power. However, their black-box nature poses significant
challenges to interpretability, limiting their adoption in high-stakes
applications. Shapley value-based feature attribution techniques, such as SHAP
and kernel-specific variants like RKHS-SHAP, offer a promising path toward
explainability. Yet, computing exact Shapley values remains computationally
intractable in general, motivating the development of various approximation
schemes. In this work, we introduce PKeX-Shapley, a novel algorithm that
utilizes the multiplicative structure of product kernels to enable the exact
computation of Shapley values in polynomial time. We show that product-kernel
models admit a functional decomposition that allows for a recursive formulation
of Shapley values. This decomposition not only yields computational efficiency
but also enhances interpretability in kernel-based learning. We also
demonstrate how our framework can be generalized to explain kernel-based
statistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the
Hilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for
interpretable statistical inference.

</details>


### [70] [Joint Relational Database Generation via Graph-Conditional Diffusion Models](https://arxiv.org/abs/2505.16527)
*Mohamed Amine Ketata, David Lüdke, Leo Schwinn, Stephan Günnemann*

**主要类别:** cs.LG

**概要:** 提出一种新的方法用于联合建模关系型数据库中的所有表格，不依赖固定的表格顺序。通过图神经网络捕获复杂的表格间依赖关系，实验表明该方法在多跳表格相关性和单表保真度指标上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有工作要么专注于单一表格生成，要么依赖于自回归分解，这些方法限制了并行性，影响了下游应用如缺失值填补的灵活性，并且由于常见的条件独立假设导致错误累积。

**方法:** 提出Graph-Conditional Relational Diffusion Model (GRDM)，使用自然的图表示法来联合建模关系型数据库中的所有表格，利用图神经网络同时去噪和捕捉表格间的复杂依赖关系。

**结果:** 在六个真实世界的关系型数据库上的广泛实验显示，所提出的方法显著优于自回归基线，在多跳表格相关性建模方面表现出色，并在单表保真度指标上达到最先进的性能。

**结论:** 我们提出了一种新的方法来解决现有工作的局限性，通过联合建模所有表格，提高了模型的灵活性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Joint+Relational+Database+Generation+via+Graph-Conditional+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16527&send_immediately=true&force_search=false)

**原文摘要:** Building generative models for relational databases (RDBs) is important for
applications like privacy-preserving data release and augmenting real datasets.
However, most prior work either focuses on single-table generation or relies on
autoregressive factorizations that impose a fixed table order and generate
tables sequentially. This approach limits parallelism, restricts flexibility in
downstream applications like missing value imputation, and compounds errors due
to commonly made conditional independence assumptions. We propose a
fundamentally different approach: jointly modeling all tables in an RDB without
imposing any order. By using a natural graph representation of RDBs, we propose
the Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph
neural network to jointly denoise row attributes and capture complex
inter-table dependencies. Extensive experiments on six real-world RDBs
demonstrate that our approach substantially outperforms autoregressive
baselines in modeling multi-hop inter-table correlations and achieves
state-of-the-art performance on single-table fidelity metrics.

</details>


### [71] [HOFT: Householder Orthogonal Fine-tuning](https://arxiv.org/abs/2505.16531)
*Alejandro Moreno Arcas, Albert Sanchis, Jorge Civera, Alfons Juan*

**主要类别:** cs.LG

**概要:** 提出了一种新的正交微调方法（HOFT）以减轻时间与空间复杂度，并探索了正交微调范式的理论特性，进一步提出了SHOFT。HOFT和SHOFT在多种下游任务中表现出与现有最佳适应方法相当或更好的结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基础模型适应方法存在时间和内存效率低的问题，尽管它们具有良好的泛化性能。本文旨在解决这一问题。

**方法:** 提出HOFT和SHOFT两种正交微调方法，并探索了正交微调的理论性质。

**结果:** HOFT和SHOFT在四个下游任务中表现出色，与现有最佳适应方法相比结果相当或更好。

**结论:** HOFT和SHOFT提供了一种有效的解决方案来提高正交微调的时间和空间效率，同时保持良好的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HOFT%3A+Householder+Orthogonal+Fine-tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16531，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16531&send_immediately=true&force_search=false)

**原文摘要:** Adaptation of foundation models using low-rank methods is a widespread
approach. Another way to adapt these models is to employ orthogonal fine-tuning
methods, which are less time and memory efficient despite their good
generalization properties. In this work, we propose Householder Orthogonal
Fine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to
alleviate time and space complexity. Moreover, some theoretical properties of
the orthogonal fine-tuning paradigm are explored. From this exploration, Scaled
Householder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are
evaluated in downstream tasks, namely commonsense reasoning, machine
translation, subject-driven generation and mathematical reasoning. Compared
with state-of-the-art adaptation methods, HOFT and SHOFT show comparable or
better results.

</details>


### [72] [Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations](https://arxiv.org/abs/2505.16549)
*Trung V. Phan, George A. Kevrekidis, Soledad Villar, Yannis G. Kevrekidis, Juan M. Bello-Rivas*

**主要类别:** cs.LG

**概要:** 提出了一种新的方法来学习偏微分方程(PDEs)，该方法不受空间维度和坐标系的限制。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器学习方法在学习PDEs时依赖于特定的空间维度和坐标系，限制了其泛化能力。

**方法:** 通过外微积分的形式表达标量场系统，并使用机器学习方法预测其演化，这种方法是无坐标且能自动推广到任意维度的。

**结果:** 该方法在FitzHugh-Nagumo和Barkley反应扩散模型以及Patlak-Keller-Segel模型中表现出色，能够实现跨不同空间背景的无缝转换。

**结论:** 所提出的方法允许在一种空间中学到的场动力学可以用于准确预测其他具有不同维度、坐标系、边界条件和曲率的空间中的情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Coordinate-+and+Dimension-Agnostic+Machine+Learning+for+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16549，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16549&send_immediately=true&force_search=false)

**原文摘要:** The machine learning methods for data-driven identification of partial
differential equations (PDEs) are typically defined for a given number of
spatial dimensions and a choice of coordinates the data have been collected in.
This dependence prevents the learned evolution equation from generalizing to
other spaces. In this work, we reformulate the problem in terms of coordinate-
and dimension-independent representations, paving the way toward what we call
``spatially liberated" PDE learning. To this end, we employ a machine learning
approach to predict the evolution of scalar field systems expressed in the
formalism of exterior calculus, which is coordinate-free and immediately
generalizes to arbitrary dimensions by construction. We demonstrate the
performance of this approach in the FitzHugh-Nagumo and Barkley
reaction-diffusion models, as well as the Patlak-Keller-Segel model informed by
in-situ chemotactic bacteria observations. We provide extensive numerical
experiments that demonstrate that our approach allows for seamless transitions
across various spatial contexts. We show that the field dynamics learned in one
space can be used to make accurate predictions in other spaces with different
dimensions, coordinate systems, boundary conditions, and curvatures.

</details>


### [73] [A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices](https://arxiv.org/abs/2505.16563)
*Chen Gong, Rui Xing, Zhenzhe Zheng, Fan Wu*

**主要类别:** cs.LG

**概要:** 提出了一种名为Titan的两阶段数据选择框架，用于提高边缘设备上机器学习模型训练的数据资源利用率。实验表明，Titan可以减少43%的训练时间并提升6.2%的最终准确率。


<details>
  <summary>更多</summary>
  
**动机:** 当前在边缘设备上的模型训练受到数据利用不足的限制，因为数据的重要性不同且存在存储和吞吐量的限制。

**方法:** 提出一个两阶段数据选择框架Titan，第一阶段粗粒度筛选候选数据集，第二阶段通过理论最优策略选择对模型性能提升最大的数据批次，并通过管道并行执行数据选择和模型训练来提高效率。

**结果:** 在真实边缘设备上进行评估，结果显示Titan可以显著减少训练时间和提升最终准确性。

**结论:** Titan是一个高效且有效的数据选择框架，能够显著改善边缘设备上的机器学习模型训练。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Two-Stage+Data+Selection+Framework+for+Data-Efficient+Model+Training+on+Edge+Devices，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16563&send_immediately=true&force_search=false)

**原文摘要:** The demand for machine learning (ML) model training on edge devices is
escalating due to data privacy and personalized service needs. However, we
observe that current on-device model training is hampered by the
under-utilization of on-device data, due to low training throughput, limited
storage and diverse data importance. To improve data resource utilization, we
propose a two-stage data selection framework {\sf Titan} to select the most
important data batch from streaming data for model training with guaranteed
efficiency and effectiveness. Specifically, in the first stage, {\sf Titan}
filters out a candidate dataset with potentially high importance in a
coarse-grained manner.In the second stage of fine-grained selection, we propose
a theoretically optimal data selection strategy to identify the data batch with
the highest model performance improvement to current training round. To further
enhance time-and-resource efficiency, {\sf Titan} leverages a pipeline to
co-execute data selection and model training, and avoids resource conflicts by
exploiting idle computing resources. We evaluate {\sf Titan} on real-world edge
devices and three representative edge computing tasks with diverse models and
data modalities. Empirical results demonstrate that {\sf Titan} achieves up to
$43\%$ reduction in training time and $6.2\%$ increase in final accuracy with
minor system overhead, such as data processing delay, memory footprint and
energy consumption.

</details>


### [74] [Finetuning-Activated Backdoors in LLMs](https://arxiv.org/abs/2505.16567)
*Thibaud Gloaguen, Mark Vero, Robin Staab, Martin Vechev*

**主要类别:** cs.LG

**概要:** 研究者展示了通过一种名为FAB（Finetuning-Activated Backdoor）的攻击方法，可以污染大型语言模型，使其在初始阶段看似无害，但在下游用户微调后表现出恶意行为。该攻击利用元学习技术模拟下游微调过程，并优化微调模型中恶意行为的出现。实验表明，FAB污染的模型在多个大型语言模型上对三种目标行为（不请自来的广告、拒绝和越狱能力）有效。此外，FAB后门对用户的各种微调选择具有鲁棒性。这一发现挑战了关于微调安全性的普遍假设，揭示了另一个利用大型语言模型复杂性的关键攻击向量。


<details>
  <summary>更多</summary>
  
**动机:** 证明即使在微调开放访问的大型语言模型时，也可能存在安全风险。

**方法:** 提出了一种名为FAB的攻击方法，通过元学习技术污染大型语言模型，优化微调模型中恶意行为的出现，同时确保被污染的模型在微调前保留通用能力和无恶意行为的表现。

**结果:** FAB攻击在多个大型语言模型上对三种目标行为（不请自来的广告、拒绝和越狱能力）有效，并且对用户的各种微调选择具有鲁棒性。

**结论:** 研究结果挑战了关于微调安全性的普遍假设，揭示了另一个利用大型语言模型复杂性的关键攻击向量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Finetuning-Activated+Backdoors+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16567，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16567&send_immediately=true&force_search=false)

**原文摘要:** Finetuning openly accessible Large Language Models (LLMs) has become standard
practice for achieving task-specific performance improvements. Until now,
finetuning has been regarded as a controlled and secure process in which
training on benign datasets led to predictable behaviors. In this paper, we
demonstrate for the first time that an adversary can create poisoned LLMs that
initially appear benign but exhibit malicious behaviors once finetuned by
downstream users. To this end, our proposed attack, FAB (Finetuning-Activated
Backdoor), poisons an LLM via meta-learning techniques to simulate downstream
finetuning, explicitly optimizing for the emergence of malicious behaviors in
the finetuned models. At the same time, the poisoned LLM is regularized to
retain general capabilities and to exhibit no malicious behaviors prior to
finetuning. As a result, when users finetune the seemingly benign model on
their own datasets, they unknowingly trigger its hidden backdoor behavior. We
demonstrate the effectiveness of FAB across multiple LLMs and three target
behaviors: unsolicited advertising, refusal, and jailbreakability.
Additionally, we show that FAB-backdoors are robust to various finetuning
choices made by the user (e.g., dataset, number of steps, scheduler). Our
findings challenge prevailing assumptions about the security of finetuning,
revealing yet another critical attack vector exploiting the complexities of
LLMs.

</details>


### [75] [Large Language Model-Empowered Interactive Load Forecasting](https://arxiv.org/abs/2505.16577)
*Yu Zuo, Dalin Qin, Yi Wang*

**主要类别:** cs.LG

**概要:** 提出了一种基于大型语言模型的多智能体协作框架，通过自然语言理解和推理能力降低非专家用户的预测技术门槛，并使用户经验得以整合，实验表明该框架在实际部署中具有成本效益且能显著提高交互式负荷预测精度。


<details>
  <summary>更多</summary>
  
**动机:** 当前负荷预测方法缺乏人机交互机制，系统操作员难以理解与应用这些需要人工智能专业知识的复杂模型，也无法融入其经验和现实情境理解。

**方法:** 设计了一组专门的智能体执行预测工作流程中的不同任务并通过专用通信机制协作，嵌入交互机制于整个负荷预测管道。

**结果:** 实验显示当用户在关键阶段提供适当见解时，交互式负荷预测准确性可显著提升；成本分析表明该框架经济实惠，适合实际部署。

**结论:** 基于大型语言模型的多智能体协作框架有效解决了负荷预测中的人机交互问题，提高了非专家用户的参与度和预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Model-Empowered+Interactive+Load+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16577，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16577&send_immediately=true&force_search=false)

**原文摘要:** The growing complexity of power systems has made accurate load forecasting
more important than ever. An increasing number of advanced load forecasting
methods have been developed. However, the static design of current methods
offers no mechanism for human-model interaction. As the primary users of
forecasting models, system operators often find it difficult to understand and
apply these advanced models, which typically requires expertise in artificial
intelligence (AI). This also prevents them from incorporating their experience
and real-world contextual understanding into the forecasting process. Recent
breakthroughs in large language models (LLMs) offer a new opportunity to
address this issue. By leveraging their natural language understanding and
reasoning capabilities, we propose an LLM-based multi-agent collaboration
framework to bridge the gap between human operators and forecasting models. A
set of specialized agents is designed to perform different tasks in the
forecasting workflow and collaborate via a dedicated communication mechanism.
This framework embeds interactive mechanisms throughout the load forecasting
pipeline, reducing the technical threshold for non-expert users and enabling
the integration of human experience. Our experiments demonstrate that the
interactive load forecasting accuracy can be significantly improved when users
provide proper insight in key stages. Our cost analysis shows that the
framework remains affordable, making it practical for real-world deployment.

</details>


### [76] [How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning](https://arxiv.org/abs/2505.16581)
*Max Weltevrede, Moritz A. Zanger, Matthijs T. J. Spaan, Wendelin Böhmer*

**主要类别:** cs.LG

**概要:** This paper proves a generalization bound for policy distillation in reinforcement learning and suggests that training an ensemble of distilled policies and distilling on as much data as possible can improve generalization.


<details>
  <summary>更多</summary>
  
**动机:** To understand why policy distillation after training can produce a policy that outperforms the original in testing environments and determine what data should be used for distillation.

**方法:** Prove a generalization bound for policy distillation under certain assumptions and empirically verify the insights in more general settings.

**结果:** The theory provides two practical insights for improved generalization: train an ensemble of distilled policies and distill on as much data from the training environments as possible. These insights are verified empirically.

**结论:** An ensemble of policies distilled on a diverse dataset can generalize significantly better than the original agent.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Ensembles+of+Distilled+Policies+Improve+Generalisation+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16581，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16581&send_immediately=true&force_search=false)

**原文摘要:** In the zero-shot policy transfer setting in reinforcement learning, the goal
is to train an agent on a fixed set of training environments so that it can
generalise to similar, but unseen, testing environments. Previous work has
shown that policy distillation after training can sometimes produce a policy
that outperforms the original in the testing environments. However, it is not
yet entirely clear why that is, or what data should be used to distil the
policy. In this paper, we prove, under certain assumptions, a generalisation
bound for policy distillation after training. The theory provides two practical
insights: for improved generalisation, you should 1) train an ensemble of
distilled policies, and 2) distil it on as much data from the training
environments as possible. We empirically verify that these insights hold in
more general settings, when the assumptions required for the theory no longer
hold. Finally, we demonstrate that an ensemble of policies distilled on a
diverse dataset can generalise significantly better than the original agent.

</details>


### [77] [Training on Plausible Counterfactuals Removes Spurious Correlations](https://arxiv.org/abs/2505.16583)
*Shpresim Sadiku, Kartikeya Chitranshi, Hiroshi Kera, Sebastian Pokutta*

**主要类别:** cs.LG

**概要:** This study shows that training classifiers on plausible counterfactual explanations labeled with incorrect target classes can improve in-distribution accuracy and reduce bias against spurious correlations.


<details>
  <summary>更多</summary>
  
**动机:** To explore the effectiveness of using plausible counterfactual explanations (p-CFEs) for improving classifier performance and reducing bias.

**方法:** Training classifiers on p-CFEs labeled with induced incorrect target classes.

**结果:** Resulting classifiers achieve high in-distribution accuracy and exhibit significantly reduced bias with respect to spurious correlations.

**结论:** Learning from p-CFEs is more effective than learning from adversarial perturbations.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+on+Plausible+Counterfactuals+Removes+Spurious+Correlations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16583&send_immediately=true&force_search=false)

**原文摘要:** Plausible counterfactual explanations (p-CFEs) are perturbations that
minimally modify inputs to change classifier decisions while remaining
plausible under the data distribution. In this study, we demonstrate that
classifiers can be trained on p-CFEs labeled with induced \emph{incorrect}
target classes to classify unperturbed inputs with the original labels. While
previous studies have shown that such learning is possible with adversarial
perturbations, we extend this paradigm to p-CFEs. Interestingly, our
experiments reveal that learning from p-CFEs is even more effective: the
resulting classifiers achieve not only high in-distribution accuracy but also
exhibit significantly reduced bias with respect to spurious correlations.

</details>


### [78] [CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models](https://arxiv.org/abs/2505.16620)
*Benjamin Herdeanu, Juan Nathaniel, Carla Roesch, Jatan Buch, Gregor Ramien, Johannes Haux, Pierre Gentine*

**主要类别:** cs.LG

**概要:** 介绍了一个名为CausalDynamics的新基准和数据生成框架，用于推进动态因果模型的结构发现。


<details>
  <summary>更多</summary>
  
**动机:** 在领域中，当主动干预不可行时，因果发现对于动态系统提出了重大挑战。大多数用于调查这些系统及其相关基准的方法都是针对确定性、低维和弱非线性时间序列数据定制的。

**方法:** 开发了一个包含真实因果图的基准，这些图来自数千个耦合的常微分方程和随机微分方程以及两个理想化的气候模型。对带有噪声、混杂和滞后动力学系统的图重构进行了最先进的因果发现算法的全面评估。

**结果:** CausalDynamics由一个即插即用、自行构建的耦合工作流组成，能够构建物理系统的层次结构。

**结论:** 提出了一种名为CausalDynamics的新基准和可扩展的数据生成框架，用于推进动态因果模型的结构发现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CausalDynamics%3A+A+large-scale+benchmark+for+structural+discovery+of+dynamical+causal+models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16620，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16620&send_immediately=true&force_search=false)

**原文摘要:** Causal discovery for dynamical systems poses a major challenge in fields
where active interventions are infeasible. Most methods used to investigate
these systems and their associated benchmarks are tailored to deterministic,
low-dimensional and weakly nonlinear time-series data. To address these
limitations, we present CausalDynamics, a large-scale benchmark and extensible
data generation framework to advance the structural discovery of dynamical
causal models. Our benchmark consists of true causal graphs derived from
thousands of coupled ordinary and stochastic differential equations as well as
two idealized climate models. We perform a comprehensive evaluation of
state-of-the-art causal discovery algorithms for graph reconstruction on
systems with noisy, confounded, and lagged dynamics. CausalDynamics consists of
a plug-and-play, build-your-own coupling workflow that enables the construction
of a hierarchy of physical systems. We anticipate that our framework will
facilitate the development of robust causal discovery algorithms that are
broadly applicable across domains while addressing their unique challenges. We
provide a user-friendly implementation and documentation on
https://kausable.github.io/CausalDynamics.

</details>


### [79] [Multivariate Latent Recalibration for Conditional Normalizing Flows](https://arxiv.org/abs/2505.16636)
*Victor Dheur, Souhaib Ben Taieb*

**主要类别:** cs.LG

**概要:** This paper introduces latent calibration and a new recalibration method called latent recalibration (LR) to improve multivariate response variable predictions.


<details>
  <summary>更多</summary>
  
**动机:** Standard recalibration methods are mostly limited to univariate settings and conformal prediction techniques lack a full probability density function.

**方法:** Introduce latent calibration in the latent space of a conditional normalizing flow and propose latent recalibration (LR) as a post-hoc recalibration method.

**结果:** LR improves latent calibration error and negative log-likelihood of recalibrated models across various datasets.

**结论:** Latent recalibration provides a reliable recalibrated distribution with an explicit multivariate density function and is computationally efficient.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multivariate+Latent+Recalibration+for+Conditional+Normalizing+Flows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16636，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16636&send_immediately=true&force_search=false)

**原文摘要:** Reliably characterizing the full conditional distribution of a multivariate
response variable given a set of covariates is crucial for trustworthy
decision-making. However, misspecified or miscalibrated multivariate models may
yield a poor approximation of the joint distribution of the response variables,
leading to unreliable predictions and suboptimal decisions. Furthermore,
standard recalibration methods are primarily limited to univariate settings,
while conformal prediction techniques, despite generating multivariate
prediction regions with coverage guarantees, do not provide a full probability
density function. We address this gap by first introducing a novel notion of
latent calibration, which assesses probabilistic calibration in the latent
space of a conditional normalizing flow. Second, we propose latent
recalibration (LR), a novel post-hoc model recalibration method that learns a
transformation of the latent space with finite-sample bounds on latent
calibration. Unlike existing methods, LR produces a recalibrated distribution
with an explicit multivariate density function while remaining computationally
efficient. Extensive experiments on both tabular and image datasets show that
LR consistently improves latent calibration error and the negative
log-likelihood of the recalibrated models.

</details>


### [80] [Stochastic Forward-Forward Learning through Representational Dimensionality Compression](https://arxiv.org/abs/2505.16649)
*Zhichao Zhu, Yang Qi, Hengyuan Ma, Wenlian Lu, Jianfeng Feng*

**主要类别:** cs.LG

**概要:** 提出了一种新的前向-前向算法，该算法通过引入维度压缩的好坏函数来改进神经网络训练，展示了与非反向传播方法相比的竞争性能，并强调了噪声在提升泛化和推理中的建设性作用。


<details>
  <summary>更多</summary>
  
**动机:** 现有的好坏函数通常忽略了神经元之间的相关性，因此需要开发一种能体现二阶统计结构的新函数。

**方法:** 提出了一种基于有效维度的维度压缩好坏函数，并展示了其在有无噪声情况下的表现。

**结果:** 所提出的方法在不需要准备负样本的情况下能够促进结构化表示，并且在噪声存在时可以提高泛化能力和推理能力。

**结论:** 新算法不仅在性能上具有竞争力，还对开发更生物可塑性的学习算法以及与神经形态计算的自然结合做出了贡献。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stochastic+Forward-Forward+Learning+through+Representational+Dimensionality+Compression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16649，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16649&send_immediately=true&force_search=false)

**原文摘要:** The Forward-Forward (FF) algorithm provides a bottom-up alternative to
backpropagation (BP) for training neural networks, relying on a layer-wise
"goodness" function to guide learning. Existing goodness functions, inspired by
energy-based learning (EBL), are typically defined as the sum of squared
post-synaptic activations, neglecting the correlations between neurons. In this
work, we propose a novel goodness function termed dimensionality compression
that uses the effective dimensionality (ED) of fluctuating neural responses to
incorporate second-order statistical structure. Our objective minimizes ED for
clamped inputs when noise is considered while maximizing it across the sample
distribution, promoting structured representations without the need to prepare
negative samples. We demonstrate that this formulation achieves competitive
performance compared to other non-BP methods. Moreover, we show that noise
plays a constructive role that can enhance generalization and improve inference
when predictions are derived from the mean of squared outputs, which is
equivalent to making predictions based on the energy term. Our findings
contribute to the development of more biologically plausible learning
algorithms and suggest a natural fit for neuromorphic computing, where
stochasticity is a computational resource rather than a nuisance. The code is
available at https://github.com/ZhichaoZhu/StochasticForwardForward

</details>


### [81] [End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries](https://arxiv.org/abs/2505.16664)
*Khoa Tran, Tri Le, Bao Huynh, Hung-Cuong Trinh, Vy-Rin Nguyen*

**主要类别:** cs.LG

**概要:** 提出了一种基于近期充放电数据的锂离子电池剩余使用寿命（RUL）预测方法，通过创新的信号处理流程和深度学习模型提升预测准确性。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测锂离子电池的剩余使用寿命对于及时维护和提高电动应用的运行效率至关重要。

**方法:** 采用包含1D卷积神经网络（CNN）、注意力机制LSTM（A-LSTM）和基于常微分方程的LSTM（ODE-LSTM）的混合深度学习架构，并结合新颖的信号预处理技术。

**结果:** 该方法在两个大规模公开数据集上的实验表明其优于基线深度学习和机器学习技术，RMSE达到101.59。

**结论:** 提出的RUL预测方法在有限目标数据上表现出稳健性能，具有实际应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是End-to-End+Framework+for+Predicting+the+Remaining+Useful+Life+of+Lithium-Ion+Batteries，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16664，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16664&send_immediately=true&force_search=false)

**原文摘要:** Accurate prediction of the Remaining Useful Life (RUL) is essential for
enabling timely maintenance of lithium-ion batteries, impacting the operational
efficiency of electric applications that rely on them. This paper proposes a
RUL prediction approach that leverages data from recent charge-discharge cycles
to estimate the number of remaining usable cycles. The approach introduces both
a novel signal processing pipeline and a deep learning prediction model. In the
signal preprocessing pipeline, a derived capacity feature is computed based on
current and capacity signals. Alongside original capacity, voltage and current,
these features are denoised and enhanced using statistical metrics and a
delta-based method to capture differences between the current and previous
cycles. In the prediction model, the processed features are then fed into a
hybrid deep learning architecture composed of 1D Convolutional Neural Networks
(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential
Equation-based LSTM (ODE-LSTM) modules. This architecture is designed to
capture both local signal characteristics and long-range temporal dependencies
while modeling the continuous-time dynamics of battery degradation. The model
is further evaluated using transfer learning across different learning
strategies and target data partitioning scenarios. Results indicate that the
model maintains robust performance, even when fine-tuned on limited target
data. Experimental results on two publicly available large-scale datasets
demonstrate that the proposed method outperforms a baseline deep learning
approach and machine learning techniques, achieving an RMSE of 101.59,
highlighting its strong potential for real-world RUL prediction applications.

</details>


### [82] [Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data](https://arxiv.org/abs/2505.16672)
*Yun-Cheng Tsai, Samuel Yen-Chi Chen*

**主要类别:** cs.LG

**概要:** 对区块链交易数据的聚类挑战进行了研究，比较了经典K均值聚类、基于量子随机特征的混合聚类和完全量子聚类三种方法。实验表明，即使浅层量子电路也能有效提取有意义的非线性表示，显著提高聚类性能。


<details>
  <summary>更多</summary>
  
**动机:** 解决区块链交易数据高维、噪声及特征纠缠导致的传统聚类算法困难的问题。

**方法:** 1. 经典K均值聚类；2. 混合聚类结合经典特征与量子随机特征；3. 完全量子聚类通过自监督学习优化特征空间。

**结果:** 浅层量子电路能有效提取非线性表示，提升聚类性能。

**结论:** 量子特征可以显著改善区块链交易数据的聚类效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantum+Feature+Optimization+for+Enhanced+Clustering+of+Blockchain+Transaction+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16672&send_immediately=true&force_search=false)

**原文摘要:** Blockchain transaction data exhibits high dimensionality, noise, and
intricate feature entanglement, presenting significant challenges for
traditional clustering algorithms. In this study, we conduct a comparative
analysis of three clustering approaches: (1) Classical K-Means Clustering,
applied to pre-processed feature representations; (2) Hybrid Clustering,
wherein classical features are enhanced with quantum random features extracted
using randomly initialized quantum neural networks (QNNs); and (3) Fully
Quantum Clustering, where a QNN is trained in a self-supervised manner
leveraging a SwAV-based loss function to optimize the feature space for
clustering directly. The proposed experimental framework systematically
investigates the impact of quantum circuit depth and the number of learned
prototypes, demonstrating that even shallow quantum circuits can effectively
extract meaningful non-linear representations, significantly improving
clustering performance.

</details>


### [83] [On the Out-of-Distribution Generalization of Self-Supervised Learning](https://arxiv.org/abs/2505.16675)
*Wenwen Qiang, Jingyao Wang, Zeen Song, Jiangmeng Li, Changwen Zheng*

**主要类别:** cs.LG

**概要:** This paper investigates the out-of-distribution (OOD) generalization of self-supervised learning (SSL), revealing that SSL learns spurious correlations leading to reduced OOD generalization. A post-intervention distribution (PID) is proposed to address this issue, and an effective batch sampling strategy is developed based on PID.


<details>
  <summary>更多</summary>
  
**动机:** To understand why SSL has OOD generalization and improve its OOD generalization ability.

**方法:** Analyze the mini-batch construction in SSL training, propose a post-intervention distribution (PID), develop a batch sampling strategy based on PID.

**结果:** The proposed sampling strategy improves the OOD generalization of SSL models.

**结论:** The study reveals that SSL learns spurious correlations and proposes a PID-based sampling strategy to enhance OOD generalization.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Out-of-Distribution+Generalization+of+Self-Supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16675，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16675&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we focus on the out-of-distribution (OOD) generalization of
self-supervised learning (SSL). By analyzing the mini-batch construction during
the SSL training phase, we first give one plausible explanation for SSL having
OOD generalization. Then, from the perspective of data generation and causal
inference, we analyze and conclude that SSL learns spurious correlations during
the training process, which leads to a reduction in OOD generalization. To
address this issue, we propose a post-intervention distribution (PID) grounded
in the Structural Causal Model. PID offers a scenario where the spurious
variable and label variable is mutually independent. Besides, we demonstrate
that if each mini-batch during SSL training satisfies PID, the resulting SSL
model can achieve optimal worst-case OOD performance. This motivates us to
develop a batch sampling strategy that enforces PID constraints through the
learning of a latent variable model. Through theoretical analysis, we
demonstrate the identifiability of the latent variable model and validate the
effectiveness of the proposed sampling strategy. Experiments conducted on
various downstream OOD tasks demonstrate the effectiveness of the proposed
sampling strategy.

</details>


### [84] [Learning Genomic Structure from $k$-mers](https://arxiv.org/abs/2505.16680)
*Filip Thor, Carl Nettelblad*

**主要类别:** cs.LG

**概要:** 提出了一种基于对比学习的方法来分析基因组测序数据，该方法可以生成反映基因组结构的嵌入表示，并在模拟的古代DNA读取映射和物种鉴定方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基因组测序数据分析方法存在不足，需要一种新的方法来更好地处理短核苷酸子序列（reads）并重建完整基因组。

**方法:** 通过对比学习训练编码模型以产生嵌入表示，这些嵌入表示能够将来自相同基因组区域的序列聚类在一起，并且保留了基因组区域的顺序特性。

**结果:** 该方法适用于多种下游任务，包括模拟古代DNA读取映射和识别结构变异，并且在小预测头上的表现与当前最先进的方法相当。

**结论:** 该模型可以完全自监督地训练，无需使用专门算法构建完整基因组装配，具有良好的扩展性，对于宏基因组应用和大型基因组的映射具有很高的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Genomic+Structure+from+%24k%24-mers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16680，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16680&send_immediately=true&force_search=false)

**原文摘要:** Sequencing a genome to determine an individual's DNA produces an enormous
number of short nucleotide subsequences known as reads, which must be
reassembled to reconstruct the full genome. We present a method for analyzing
this type of data using contrastive learning, in which an encoder model is
trained to produce embeddings that cluster together sequences from the same
genomic region. The sequential nature of genomic regions is preserved in the
form of trajectories through this embedding space. Trained solely to reflect
the structure of the genome, the resulting model provides a general
representation of $k$-mer sequences, suitable for a range of downstream tasks
involving read data. We apply our framework to learn the structure of the $E.\
coli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read
mapping and identification of structural variations. Furthermore, we illustrate
the potential of using this type of model for metagenomic species
identification. We show how incorporating a domain-specific noise model can
enhance embedding robustness, and how a supervised contrastive learning setting
can be adopted when a linear reference genome is available, by introducing a
distance thresholding parameter $\Gamma$. The model can also be trained fully
self-supervised on read data, enabling analysis without the need to construct a
full genome assembly using specialized algorithms. Small prediction heads based
on a pre-trained embedding are shown to perform on par with BWA-aln, the
current gold standard approach for aDNA mapping, in terms of accuracy and
runtime for short genomes. Given the method's favorable scaling properties with
respect to total genome size, inference using our approach is highly promising
for metagenomic applications and for mapping to genomes comparable in size to
the human genome.

</details>


### [85] [Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator](https://arxiv.org/abs/2505.16690)
*Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei*

**主要类别:** cs.LG

**概要:** 提出了一种名为DACA的新方法，用于优化后训练语言模型的置信度校准参数，通过仅选择一致示例进行校准来提高校准性能。实验表明该方法可以显著改善开放源码和基于API的语言模型的平均ECE。


<details>
  <summary>更多</summary>
  
**动机:** 后训练语言模型（PoLMs）通常会出现过度自信的问题，即对正确和错误输出都赋予高置信度，这可能会影响关键应用中的可靠性。主要障碍在于缺乏针对具体下游任务的标记数据。

**方法:** 提出了DACA（分歧感知置信度对齐），一种新的无监督方法，用于优化后训练置信度校准的参数。通过仅使用一致示例进行校准，有效地解耦了分歧的影响。

**结果:** 在常见基准上，改进了开源和基于API的语言模型（如GPT-4o）的平均ECE高达15.08%。

**结论:** DACA是一种有效的无监督方法，可显著提高后训练语言模型的置信度校准性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Your+Pre-trained+LLM+is+Secretly+an+Unsupervised+Confidence+Calibrator，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16690，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16690&send_immediately=true&force_search=false)

**原文摘要:** Post-training of large language models is essential for adapting pre-trained
language models (PLMs) to align with human preferences and downstream tasks.
While PLMs typically exhibit well-calibrated confidence, post-trained language
models (PoLMs) often suffer from over-confidence, assigning high confidence to
both correct and incorrect outputs, which can undermine reliability in critical
applications. A major obstacle in calibrating PoLMs is the scarcity of labeled
data for individual downstream tasks. To address this, we propose
Disagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to
optimize the parameters (e.g., temperature $\tau$) in post-hoc confidence
calibration. Our method is motivated by the under-confidence issue caused by
prediction disagreement between the PLM and PoLM while aligning their
confidence via temperature scaling. Theoretically, the PLM's confidence
underestimates PoLM's prediction accuracy on disagreement examples, causing a
larger $\tau$ and producing under-confident predictions. DACA mitigates this by
selectively using only agreement examples for calibration, effectively
decoupling the influence of disagreement. In this manner, our method avoids an
overly large $\tau$ in temperature scaling caused by disagreement examples,
improving calibration performance. Extensive experiments demonstrate the
effectiveness of our method, improving the average ECE of open-sourced and
API-based LLMs (e.g. GPT-4o) by up to 15.08$\%$ on common benchmarks.

</details>


### [86] [An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations](https://arxiv.org/abs/2505.16705)
*Seonghwan Park, Jueun Mun, Donghyun Oh, Namhoon Lee*

**主要类别:** cs.LG

**概要:** 研究了概念瓶颈模型中的噪声问题，发现某些易受攻击的概念会显著影响模型性能，并提出了一种两阶段框架来增强模型的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 理解概念瓶颈模型中训练标签噪声的影响。

**方法:** 提出了一个两阶段框架，在训练时使用锐度感知最小化稳定学习，在推理时通过预测熵对概念进行排序并修正最不确定的概念。

**结果:** 发现易受攻击的概念是导致性能下降的主要原因，并证明了所提方法的有效性。

**结论:** 提出的两阶段框架能够在保持模型可解释性的同时提高其在噪声环境下的鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Analysis+of+Concept+Bottleneck+Models%3A+Measuring%2C+Understanding%2C+and+Mitigating+the+Impact+of+Noisy+Annotations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16705&send_immediately=true&force_search=false)

**原文摘要:** Concept bottleneck models (CBMs) ensure interpretability by decomposing
predictions into human interpretable concepts. Yet the annotations used for
training CBMs that enable this transparency are often noisy, and the impact of
such corruption is not well understood. In this study, we present the first
systematic study of noise in CBMs and show that even moderate corruption
simultaneously impairs prediction performance, interpretability, and the
intervention effectiveness. Our analysis identifies a susceptible subset of
concepts whose accuracy declines far more than the average gap between noisy
and clean supervision and whose corruption accounts for most performance loss.
To mitigate this vulnerability we propose a two-stage framework. During
training, sharpness-aware minimization stabilizes the learning of
noise-sensitive concepts. During inference, where clean labels are unavailable,
we rank concepts by predictive entropy and correct only the most uncertain
ones, using uncertainty as a proxy for susceptibility. Theoretical analysis and
extensive ablations elucidate why sharpness-aware training confers robustness
and why uncertainty reliably identifies susceptible concepts, providing a
principled basis that preserves both interpretability and resilience in the
presence of noise.

</details>


### [87] [Training Long-Context LLMs Efficiently via Chunk-wise Optimization](https://arxiv.org/abs/2505.16710)
*Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji*

**主要类别:** cs.LG

**概要:** 提出两种优化方法SeCO和SpaCO，分别通过分块独立计算和稀疏梯度传播减少长上下文大语言模型训练的内存消耗和计算开销。


<details>
  <summary>更多</summary>
  
**动机:** 降低长上下文大语言模型的高训练成本，使其更适用于定制化应用。

**方法:** 提出SeCO（顺序分块优化）和SpaCO（稀疏分块优化），前者通过分块构造计算图并独立反向传播减少内存占用，后者进一步通过选择性梯度传播和补偿因子减少计算开销。

**结果:** SeCO可以将最大序列长度从1K扩展到16K，SpaCO在相同设置下比SeCO快3倍。

**结论:** 这些创新为优化长上下文模型提供了新思路，使其更适用于实际应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+Long-Context+LLMs+Efficiently+via+Chunk-wise+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16710，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16710&send_immediately=true&force_search=false)

**原文摘要:** While long-context large language models (LLMs) exhibit remarkable document
processing capabilities, their prohibitively high training costs often hinder
customized applications. To mitigate this issue, we propose \textit{Sequential
Chunk-wise Optimization} (SeCO), a memory-efficient training paradigm that
partitions lengthy inputs into manageable chunks. Each chunk independently
constructs its computational graph and performs localized backpropagation,
ensuring that only one chunk's forward activations are stored in memory.
Building on SeCO, we further introduce \textit{Sparse Chunk-wise Optimization}
(SpaCO), which reduces computational overhead by selectively propagating
gradients to specific chunks and incorporates a carefully designed compensation
factor to ensure unbiased gradient estimation. SpaCO decouples the
computational cost of backpropagation from the context length, enabling
training time to gradually converge to inference time as sequences become
longer. Implemented as lightweight training wrappers, both SeCO and SpaCO offer
substantial practical benefits. For example, when fine-tuning an 8B model with
LoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to
16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up
to 3x faster than SeCO under the same experimental setup. These innovations
provide new insights into optimizing long-context models, making them more
accessible for practical applications. We have open-sourced the code at
\href{https://github.com/wenhaoli-xmu/seco}{here}.

</details>


### [88] [Advancing Brainwave Modeling with a Codebook-Based Foundation Model](https://arxiv.org/abs/2505.16724)
*Konstantinos Barmpas, Na Lee, Yannis Panagakis, Dimitrios A. Adamos, Nikolaos Laskaris, Stefanos Zafeiriou*

**主要类别:** cs.LG

**概要:** 提出LaBraM++，一种改进的大脑波基础模型，显著提升多种任务表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有预训练EEG模型难以充分捕捉神经振荡的丰富信息，限制了性能和泛化能力。

**方法:** 引入基于稳健信号处理原理改进的新架构LaBraM++。

**结果:** 在各种任务中表现出色，优于原始架构并与其他开源LBM竞争。

**结论:** LaBraM++展示了作为未来LBM强大基础的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+Brainwave+Modeling+with+a+Codebook-Based+Foundation+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16724，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16724&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in large-scale pre-trained Electroencephalogram (EEG) models
have shown great promise, driving progress in Brain-Computer Interfaces (BCIs)
and healthcare applications. However, despite their success, many existing
pre-trained models have struggled to fully capture the rich information content
of neural oscillations, a limitation that fundamentally constrains their
performance and generalizability across diverse BCI tasks. This limitation is
frequently rooted in suboptimal architectural design choices which constrain
their representational capacity. In this work, we introduce LaBraM++, an
enhanced Large Brainwave Foundation Model (LBM) that incorporates principled
improvements grounded in robust signal processing foundations. LaBraM++
demonstrates substantial gains across a variety of tasks, consistently
outperforming its originally-based architecture and achieving competitive
results when compared to other open-source LBMs. Its superior performance and
training efficiency highlight its potential as a strong foundation for future
advancements in LBMs.

</details>


### [89] [Masked Conditioning for Deep Generative Models](https://arxiv.org/abs/2505.16725)
*Phillip Mueller, Jannik Wiese, Sebastian Mueller, Lars Mikelsons*

**主要类别:** cs.LG

**概要:** 提出了一种新的掩蔽条件方法，使生成模型能够处理稀疏混合数据，并在两个工程相关数据集上展示了其适用性。此外，还演示了小型模型与大型预训练基础模型结合以提高生成质量的方法。


<details>
  <summary>更多</summary>
  
**动机:** 解决工程领域数据集小、标签稀疏且包含数值和类别条件的问题，同时克服计算资源限制阻碍生成模型应用的挑战。

**方法:** 引入了掩蔽条件方法，通过在训练时屏蔽条件来模拟推理时的稀疏条件，并探索了不同的稀疏调度方案；设计了灵活的嵌入方式处理类别和数值条件；将该方法集成到变分自编码器和潜在扩散模型中。

**结果:** 该方法在两个工程相关的二维点云和图像数据集上证明了其适用性。

**结论:** 小型模型可以通过结合大型预训练基础模型，在保持由条件方案诱导的可控性的同时提升生成质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Masked+Conditioning+for+Deep+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16725&send_immediately=true&force_search=false)

**原文摘要:** Datasets in engineering domains are often small, sparsely labeled, and
contain numerical as well as categorical conditions. Additionally.
computational resources are typically limited in practical applications which
hinders the adoption of generative models for engineering tasks. We introduce a
novel masked-conditioning approach, that enables generative models to work with
sparse, mixed-type data. We mask conditions during training to simulate sparse
conditions at inference time. For this purpose, we explore the use of various
sparsity schedules that show different strengths and weaknesses. In addition,
we introduce a flexible embedding that deals with categorical as well as
numerical conditions. We integrate our method into an efficient variational
autoencoder as well as a latent diffusion model and demonstrate the
applicability of our approach on two engineering-related datasets of 2D point
clouds and images. Finally, we show that small models trained on limited data
can be coupled with large pretrained foundation models to improve generation
quality while retaining the controllability induced by our conditioning scheme.

</details>


### [90] [Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization](https://arxiv.org/abs/2505.16737)
*Chengcan Wu, Zhixin Zhang, Zeming Wei, Yihao Zhang, Meng Sun*

**主要类别:** cs.LG

**概要:** 提出了一种名为SAP的安全感知探针优化框架，用于减轻微调大型语言模型时的安全风险。实验表明，SAP在保持任务特定性能的同时，有效减少了有害性并保持了模型的安全性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管在预训练阶段实施了安全对齐技术，但微调大型语言模型仍可能因非有害数据而产生安全退化问题。

**方法:** 引入了安全感知探针优化（SAP）框架，通过在梯度传播过程中加入安全感知探针来识别潜在的梯度方向陷阱，从而提高特定任务的性能并保护模型安全。

**结果:** SAP在减少有害性和保持测试损失方面表现良好，与标准微调方法相当。

**结论:** 本文提出了SAP框架，成功地在微调大型语言模型时解决了安全退化的问题，同时保持了良好的任务性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mitigating+Fine-tuning+Risks+in+LLMs+via+Safety-Aware+Probing+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16737&send_immediately=true&force_search=false)

**原文摘要:** The significant progress of large language models (LLMs) has led to
remarkable achievements across numerous applications. However, their ability to
generate harmful content has sparked substantial safety concerns. Despite the
implementation of safety alignment techniques during the pre-training phase,
recent research indicates that fine-tuning LLMs on adversarial or even benign
data can inadvertently compromise their safety. In this paper, we re-examine
the fundamental issue of why fine-tuning on non-harmful data still results in
safety degradation. We introduce a safety-aware probing (SAP) optimization
framework designed to mitigate the safety risks of fine-tuning LLMs.
Specifically, SAP incorporates a safety-aware probe into the gradient
propagation process, mitigating the model's risk of safety degradation by
identifying potential pitfalls in gradient directions, thereby enhancing
task-specific performance while successfully preserving model safety. Our
extensive experimental results demonstrate that SAP effectively reduces
harmfulness below the original fine-tuned model and achieves comparable test
loss to standard fine-tuning methods. Our code is available at
https://github.com/ChengcanWu/SAP.

</details>


### [91] [Forward-only Diffusion Probabilistic Models](https://arxiv.org/abs/2505.16733)
*Ziwei Luo, Fredrik K. Gustafsson, Jens Sjölund, Thomas B. Schön*

**主要类别:** cs.LG

**概要:** 提出了一种前馈扩散(FoD)方法用于生成建模，通过单一前向扩散过程直接学习数据生成，保证收敛到干净数据，且在推理过程中可以进行少量步骤的非马尔可夫链采样，在多种图像条件和无条件生成任务上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 传统扩散模型依赖于耦合的前后向扩散方案，而FoD通过单一前向扩散过程简化了生成框架。

**方法:** FoD的核心是一个状态相关的线性随机微分方程，具有均值回归特性，并使用简单的随机流匹配目标进行训练。

**结果:** FoD模型在各种图像条件和无条件生成任务上取得了竞争性的性能。

**结论:** 尽管FoD模型简单，但在生成建模方面表现出有效性，并且代码已公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Forward-only+Diffusion+Probabilistic+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16733，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16733&send_immediately=true&force_search=false)

**原文摘要:** This work presents a forward-only diffusion (FoD) approach for generative
modelling. In contrast to traditional diffusion models that rely on a coupled
forward-backward diffusion scheme, FoD directly learns data generation through
a single forward diffusion process, yielding a simple yet efficient generative
framework. The core of FoD is a state-dependent linear stochastic differential
equation that involves a mean-reverting term in both the drift and diffusion
functions. This mean-reversion property guarantees the convergence to clean
data, naturally simulating a stochastic interpolation between source and target
distributions. More importantly, FoD is analytically tractable and is trained
using a simple stochastic flow matching objective, enabling a few-step
non-Markov chain sampling during inference. The proposed FoD model, despite its
simplicity, achieves competitive performance on various image-conditioned
(e.g., image restoration) and unconditional generation tasks, demonstrating its
effectiveness in generative modelling. Our code is available at
https://github.com/Algolzw/FoD.

</details>


### [92] [Learning Flexible Forward Trajectories for Masked Molecular Diffusion](https://arxiv.org/abs/2505.16790)
*Hyunjin Seo, Taewon Kim, Sihyun Yu, SungSoo Ahn*

**主要类别:** cs.LG

**概要:** This work explores the potential of masked diffusion models (MDMs) in molecular generation and identifies a state-clashing problem that degrades performance. The authors propose Masked Element-wise Learnable Diffusion (MELD) to improve molecular generation quality.


<details>
  <summary>更多</summary>
  
**动机:** To address the underexplored potential of MDMs in molecular generation and understand why naive application of standard MDMs fails.

**方法:** Introduce Masked Element-wise Learnable Diffusion (MELD) with parameterized noise scheduling to assign distinct corruption rates to individual graph elements.

**结果:** MELD improves chemical validity of vanilla MDMs on ZINC250K from 15% to 93% and achieves state-of-the-art property alignment in conditional generation tasks.

**结论:** The proposed MELD method effectively mitigates the state-clashing problem and significantly enhances molecular generation quality.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Flexible+Forward+Trajectories+for+Masked+Molecular+Diffusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16790，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16790&send_immediately=true&force_search=false)

**原文摘要:** Masked diffusion models (MDMs) have achieved notable progress in modeling
discrete data, while their potential in molecular generation remains
underexplored. In this work, we explore their potential and introduce the
surprising result that naively applying standards MDMs severely degrades the
performance. We identify the critical cause of this issue as a state-clashing
problem-where the forward diffusion of distinct molecules collapse into a
common state, resulting in a mixture of reconstruction targets that cannot be
learned using typical reverse diffusion process with unimodal predictions. To
mitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that
orchestrates per-element corruption trajectories to avoid collision between
distinct molecular graphs. This is achieved through a parameterized noise
scheduling network that assigns distinct corruption rates to individual graph
elements, i.e., atoms and bonds. Extensive experiments on diverse molecular
benchmarks reveal that MELD markedly enhances overall generation quality
compared to element-agnostic noise scheduling, increasing the chemical validity
of vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves
state-of-the-art property alignment in conditional generation tasks.

</details>


### [93] [Maximum Total Correlation Reinforcement Learning](https://arxiv.org/abs/2505.16734)
*Bang You, Puze Liu, Huaping Liu, Jan Peters, Oleg Arenz*

**主要类别:** cs.LG

**概要:** 提出了一种新的强化学习方法，通过最大化轨迹总相关性来促进简单行为，实验表明该方法在模拟机器人环境中生成的策略具有更好的鲁棒性和任务性能。


<details>
  <summary>更多</summary>
  
**动机:** 提高模型的泛化能力和鲁棒性，专注于本质问题。

**方法:** 引入了强化学习问题的一种修改版，额外最大化诱导轨迹的总相关性，并提出了一种基于下界近似优化所有模型（包括策略和状态表示）的实用算法。

**结果:** 在模拟机器人环境中，该方法自然生成的策略诱导出周期性和可压缩的轨迹，对噪声和动态变化具有更好的鲁棒性，同时提高了原始任务的性能。

**结论:** 所提出的方法通过关注简单性增强了强化学习模型的性能和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Maximum+Total+Correlation+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16734&send_immediately=true&force_search=false)

**原文摘要:** Simplicity is a powerful inductive bias. In reinforcement learning,
regularization is used for simpler policies, data augmentation for simpler
representations, and sparse reward functions for simpler objectives, all that,
with the underlying motivation to increase generalizability and robustness by
focusing on the essentials. Supplementary to these techniques, we investigate
how to promote simple behavior throughout the episode. To that end, we
introduce a modification of the reinforcement learning problem that
additionally maximizes the total correlation within the induced trajectories.
We propose a practical algorithm that optimizes all models, including policy
and state representation, based on a lower-bound approximation. In simulated
robot environments, our method naturally generates policies that induce
periodic and compressible trajectories, and that exhibit superior robustness to
noise and changes in dynamics compared to baseline methods, while also
improving performance in the original tasks.

</details>


### [94] [Cohort-Based Active Modality Acquisition](https://arxiv.org/abs/2505.16791)
*Tillmann Rheude, Roland Eils, Benjamin Wild*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的测试时间设置CAMA，用于优化受限环境下的模态获取，实验验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在现实世界机器学习应用中，多个模态的数据需要被有效整合以做出鲁棒预测，但在许多实际场景中并非所有模态都对每个样本可用，且获取额外模态可能代价高昂。虽然已有工作探索了个例获取策略和训练时间主动学习范式，但测试时间和基于群体的获取仍缺乏研究。

**方法:** 提出了一种名为CAMA的新颖测试时间设置，用于解决在资源有限的情况下哪些样本应该优先获取额外模态的问题。同时引入了利用生成填补和判别建模相结合的获取策略，并提出了上界启发式方法来评估获取策略的性能。

**结果:** 提出的CAMA方法在常见的多模态数据集上的实验显示，与仅依赖单模态信息、熵引导和随机选择相比，其基于填补的策略能更有效地指导新样本的模态获取。

**结论:** 提出的CAMA方法通过结合生成填补和判别建模，能够更有效地指导样本的模态获取，在多模态数据集上的实验表明其优于仅依赖单模态信息、熵引导和随机选择的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cohort-Based+Active+Modality+Acquisition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16791&send_immediately=true&force_search=false)

**原文摘要:** Real-world machine learning applications often involve data from multiple
modalities that must be integrated effectively to make robust predictions.
However, in many practical settings, not all modalities are available for every
sample, and acquiring additional modalities can be costly. This raises the
question: which samples should be prioritized for additional modality
acquisition when resources are limited? While prior work has explored
individual-level acquisition strategies and training-time active learning
paradigms, test-time and cohort-based acquisition remain underexplored despite
their importance in many real-world settings. We introduce Cohort-based Active
Modality Acquisition (CAMA), a novel test-time setting to formalize the
challenge of selecting which samples should receive additional modalities. We
derive acquisition strategies that leverage a combination of generative
imputation and discriminative modeling to estimate the expected benefit of
acquiring missing modalities based on common evaluation metrics. We also
introduce upper-bound heuristics that provide performance ceilings to benchmark
acquisition strategies. Experiments on common multimodal datasets demonstrate
that our proposed imputation-based strategies can more effectively guide the
acquisition of new samples in comparison to those relying solely on unimodal
information, entropy guidance, and random selections. Our work provides an
effective solution for optimizing modality acquisition at the cohort level,
enabling better utilization of resources in constrained settings.

</details>


### [95] [Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?](https://arxiv.org/abs/2505.16736)
*Nicolas Keriven*

**主要类别:** cs.LG

**概要:** This paper explores backward oversmoothing in Graph Neural Networks (GNNs), showing that it causes many spurious stationary points, making training challenging.


<details>
  <summary>更多</summary>
  
**动机:** To understand why GNNs struggle with optimization despite the theoretical possibility of avoiding oversmoothing.

**方法:** Analyzing backward oversmoothing and its impact on gradients and stationary points in GNNs.

**结果:** Backward oversmoothing leads to regions with near-zero gradients but high loss, which are spurious stationary points.

**结论:** The study provides insights into the optimization challenges of GNNs by examining backward oversmoothing.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Backward+Oversmoothing%3A+why+is+it+hard+to+train+deep+Graph+Neural+Networks%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16736，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16736&send_immediately=true&force_search=false)

**原文摘要:** Oversmoothing has long been identified as a major limitation of Graph Neural
Networks (GNNs): input node features are smoothed at each layer and converge to
a non-informative representation, if the weights of the GNN are sufficiently
bounded. This assumption is crucial: if, on the contrary, the weights are
sufficiently large, then oversmoothing may not happen. Theoretically, GNN could
thus learn to not oversmooth. However it does not really happen in practice,
which prompts us to examine oversmoothing from an optimization point of view.
In this paper, we analyze backward oversmoothing, that is, the notion that
backpropagated errors used to compute gradients are also subject to
oversmoothing from output to input. With non-linear activation functions, we
outline the key role of the interaction between forward and backward smoothing.
Moreover, we show that, due to backward oversmoothing, GNNs provably exhibit
many spurious stationary points: as soon as the last layer is trained, the
whole GNN is at a stationary point. As a result, we can exhibit regions where
gradients are near-zero while the loss stays high. The proof relies on the fact
that, unlike forward oversmoothing, backward errors are subjected to a linear
oversmoothing even in the presence of non-linear activation function, such that
the average of the output error plays a key role. Additionally, we show that
this phenomenon is specific to deep GNNs, and exhibit counter-example
Multi-Layer Perceptron. This paper is a step toward a more complete
comprehension of the optimization landscape specific to GNNs.

</details>


### [96] [A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents](https://arxiv.org/abs/2505.16801)
*Eleftherios Kalafatis, Konstantinos Mitsis, Konstantia Zarkogianni, Maria Athanasiou, Konstantina Nikita*

**主要类别:** cs.LG

**概要:** This study introduces a methodology using deep reinforcement learning agents to automatically evaluate procedural content generation in serious games.


<details>
  <summary>更多</summary>
  
**动机:** To offer personalized and enhanced player experiences in serious games by integrating procedural content generation.

**方法:** Proposes a framework that uses deep reinforcement learning game testing agents to assess the impact of procedural content generation techniques in serious games.

**结果:** The framework was tested with a serious game featuring card game mechanics and three versions of NPC creation, showing that versions using genetic algorithms outperformed the random version in terms of win rate and training time.

**结论:** The proposed framework can effectively evaluate procedurally generated content in serious games.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+modular+framework+for+automated+evaluation+of+procedural+content+generation+in+serious+games+with+deep+reinforcement+learning+agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16801&send_immediately=true&force_search=false)

**原文摘要:** Serious Games (SGs) are nowadays shifting focus to include procedural content
generation (PCG) in the development process as a means of offering personalized
and enhanced player experience. However, the development of a framework to
assess the impact of PCG techniques when integrated into SGs remains
particularly challenging. This study proposes a methodology for automated
evaluation of PCG integration in SGs, incorporating deep reinforcement learning
(DRL) game testing agents. To validate the proposed framework, a previously
introduced SG featuring card game mechanics and incorporating three different
versions of PCG for nonplayer character (NPC) creation has been deployed.
Version 1 features random NPC creation, while versions 2 and 3 utilize a
genetic algorithm approach. These versions are used to test the impact of
different dynamic SG environments on the proposed framework's agents. The
obtained results highlight the superiority of the DRL game testing agents
trained on Versions 2 and 3 over those trained on Version 1 in terms of win
rate (i.e. number of wins per played games) and training time. More
specifically, within the execution of a test emulating regular gameplay, both
Versions 2 and 3 peaked at a 97% win rate and achieved statistically
significant higher (p=0009) win rates compared to those achieved in Version 1
that peaked at 94%. Overall, results advocate towards the proposed framework's
capability to produce meaningful data for the evaluation of procedurally
generated content in SGs.

</details>


### [97] [Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only](https://arxiv.org/abs/2505.16856)
*Wei Xiao, Jiacheng Liu, Zifeng Zhuang, Runze Suo, Shangke Lyu, Donglin Wang*

**主要类别:** cs.LG

**概要:** We propose a method for efficient online RL fine-tuning using solely the offline pre-trained policy, eliminating reliance on pre-trained Q-functions.


<details>
  <summary>更多</summary>
  
**动机:** Improving the performance of pre-trained policies through online reinforcement learning (RL) is a critical yet challenging topic.

**方法:** PORL (Policy-Only Reinforcement Learning Fine-Tuning)

**结果:** Our method not only achieves competitive performance with advanced offline-to-online RL algorithms and online RL approaches that leverage data or policies prior, but also pioneers a new path for directly fine-tuning behavior cloning (BC) policies.

**结论:** Our method not only achieves competitive performance with advanced offline-to-online RL algorithms and online RL approaches that leverage data or policies prior, but also pioneers a new path for directly fine-tuning behavior cloning (BC) policies.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Online+RL+Fine+Tuning+with+Offline+Pre-trained+Policy+Only，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16856，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16856&send_immediately=true&force_search=false)

**原文摘要:** Improving the performance of pre-trained policies through online
reinforcement learning (RL) is a critical yet challenging topic. Existing
online RL fine-tuning methods require continued training with offline
pretrained Q-functions for stability and performance. However, these offline
pretrained Q-functions commonly underestimate state-action pairs beyond the
offline dataset due to the conservatism in most offline RL methods, which
hinders further exploration when transitioning from the offline to the online
setting. Additionally, this requirement limits their applicability in scenarios
where only pre-trained policies are available but pre-trained Q-functions are
absent, such as in imitation learning (IL) pre-training. To address these
challenges, we propose a method for efficient online RL fine-tuning using
solely the offline pre-trained policy, eliminating reliance on pre-trained
Q-functions. We introduce PORL (Policy-Only Reinforcement Learning
Fine-Tuning), which rapidly initializes the Q-function from scratch during the
online phase to avoid detrimental pessimism. Our method not only achieves
competitive performance with advanced offline-to-online RL algorithms and
online RL approaches that leverage data or policies prior, but also pioneers a
new path for directly fine-tuning behavior cloning (BC) policies.

</details>


### [98] [GCAL: Adapting Graph Models to Evolving Domain Shifts](https://arxiv.org/abs/2505.16860)
*Ziyue Qiao, Qianyi Cai, Hao Dong, Jiawei Gu, Pengyang Wang, Meng Xiao, Xiao Luo, Hui Xiong*

**主要类别:** cs.LG

**概要:** This paper proposes GCAL, a novel method for graph domain adaptation on evolving multiple OOD graphs, which enhances model sustainability and adaptability through bilevel optimization.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitations of conventional single-step graph domain adaptation methods in handling continuous domain shifts and preventing catastrophic forgetting.

**方法:** GCAL uses a bilevel optimization strategy including an 'adapt' phase for information maximization and a 'generate memory' phase for variational memory graph generation guided by information bottleneck theory.

**结果:** GCAL demonstrates superior performance in adaptability and knowledge retention compared to existing methods.

**结论:** The proposed GCAL method effectively enhances model sustainability and adaptability across various graph domains.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GCAL%3A+Adapting+Graph+Models+to+Evolving+Domain+Shifts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16860，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16860&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the challenge of graph domain adaptation on evolving,
multiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation
methods are confined to single-step adaptation, making them ineffective in
handling continuous domain shifts and prone to catastrophic forgetting. This
paper introduces the Graph Continual Adaptive Learning (GCAL) method, designed
to enhance model sustainability and adaptability across various graph domains.
GCAL employs a bilevel optimization strategy. The "adapt" phase uses an
information maximization approach to fine-tune the model with new graph domains
while re-adapting past memories to mitigate forgetting. Concurrently, the
"generate memory" phase, guided by a theoretical lower bound derived from
information bottleneck theory, involves a variational memory graph generation
module to condense original graphs into memories. Extensive experimental
evaluations demonstrate that GCAL substantially outperforms existing methods in
terms of adaptability and knowledge retention.

</details>


### [99] [Revenue Optimization with Price-Sensitive and Interdependent Demand](https://arxiv.org/abs/2505.16748)
*Julien Laasri, Marc Revol*

**主要类别:** cs.LG

**概要:** This paper focuses on optimizing pricing and quantity decisions for airline ticket sales on direct flights over multiple time periods, assuming given demand data and predetermined price options.


<details>
  <summary>更多</summary>
  
**动机:** To maximize an organization's revenue through Revenue Management by focusing on pricing and quantity decisions.

**方法:** Optimization of pricing and quantity decisions for airline ticket sales, with given demand data and predetermined price options.

**结果:** Maximizing the revenue of a direct flight by choosing the optimal prices for each product from the predefined set of options.

**结论:** The paper concludes that focusing on the optimization of pricing and quantity decisions can significantly contribute to maximizing revenue in Revenue Management.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revenue+Optimization+with+Price-Sensitive+and+Interdependent+Demand，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16748，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16748&send_immediately=true&force_search=false)

**原文摘要:** As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],
Revenue Management aims to maximize an organization's revenue by considering
three types of decision categories: structural, pricing, and quantity. In this
document, our primary focus will be on decisions related to pricing and
quantity for the sale of airline tickets on a direct flight over a certain
number of time periods. More specifically, we will only focus on the
optimization aspect of this problem. We will assume the demand data to be
given, since Air France estimates it beforehand using real data. Similarly, we
assume all price options to be predetermined by Air France's algorithms and
verified by their analysts. Our objective will be to maximize the revenue of a
direct flight by choosing the prices for each product from the predefined set
of options.
  --
  Comme d\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur
ouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un
organisme \`a partir de trois types de cat\'egories de d\'ecision :
structurelles, prix et quantit\'e. Dans ce document, nous nous int\'eresserons
principalement aux d\'ecisions de type prix et quantit\'e pour la vente de
billets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.
Plus pr\'ecis\'ement, nous nous situerons dans la partie optimisation du
probl\`eme. Nous prendrons ainsi les donn\'ees de demande comme acquises, car
elles sont estim\'ees au pr\'ealable par Air France \`a partir des donn\'ees
r\'eelles. De m\^eme, pour chaque produit que l'on cherchera \`a vendre, on
nous impose en amont les prix possibles que l'on a droit d'utiliser et qui se
basent sur des algorithmes d'Air France dont les r\'esultats sont v\'erifi\'es
par des analystes. Notre but sera alors de maximiser le revenu d'un vol direct
en choisissant les prix de chaque produit parmi ceux impos\'es.

</details>


### [100] [Structure-Aligned Protein Language Model](https://arxiv.org/abs/2505.16896)
*Can Chen, David Heurtel-Depeiges, Robert M. Vernon, Christopher James Langmead, Yoshua Bengio, Quentin Fournier*

**主要类别:** cs.LG

**概要:** 提出了一种通过对比学习任务将蛋白质图神经网络的结构知识整合到蛋白质语言模型中的方法，并引入了物理级任务来增强模型的结构预测能力，显著提升了在多种下游任务上的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的蛋白质语言模型缺乏必要的结构知识，这对于许多生物学应用至关重要。

**方法:** 设计了一个潜在级对比学习任务来对齐来自蛋白质语言模型和蛋白质图神经网络的残基表示，并引入物理级任务优化模型预测结构标记的能力。此外，还设计了一个残基损失选择模块。

**结果:** 该方法有效提高了ESM2和AMPLIFY在多种下游任务上的性能，如接触预测的提升达12.7%。

**结论:** 所提出的双任务框架成功地将跨蛋白和单蛋白的结构知识整合进蛋白质语言模型中，并通过实例证明了其有效性与实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Structure-Aligned+Protein+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16896，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16896&send_immediately=true&force_search=false)

**原文摘要:** Protein language models (pLMs) pre-trained on vast protein sequence databases
excel at various downstream tasks but lack the structural knowledge essential
for many biological applications. To address this, we integrate structural
insights from pre-trained protein graph neural networks (pGNNs) into pLMs
through a latent-level contrastive learning task. This task aligns residue
representations from pLMs with those from pGNNs across multiple proteins,
enriching pLMs with inter-protein structural knowledge. Additionally, we
incorporate a physical-level task that infuses intra-protein structural
knowledge by optimizing pLMs to predict structural tokens. The proposed
dual-task framework effectively incorporates both inter-protein and
intra-protein structural knowledge into pLMs. Given the variability in the
quality of protein structures in PDB, we further introduce a residue loss
selection module, which uses a small model trained on high-quality structures
to select reliable yet challenging residue losses for the pLM to learn.
Applying our structure alignment method to the state-of-the-art ESM2 and
AMPLIFY results in notable performance gains across a wide range of tasks,
including a 12.7% increase in ESM2 contact prediction. The data, code, and
resulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.

</details>


### [101] [PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects](https://arxiv.org/abs/2505.16754)
*Hannah Markgraf, Michael Eichelbeck, Daria Cappey, Selin Demirtürk, Yara Schattschneider, Matthias Althoff*

**主要类别:** cs.LG

**概要:** Introduces PyTupli, a tool for creating, storing, and sharing benchmark environments and datasets for offline reinforcement learning.


<details>
  <summary>更多</summary>
  
**动机:** Lack of standardized infrastructure for managing and distributing datasets for offline RL.

**方法:** Developed PyTupli, which includes a client library and a containerized server component.

**结果:** PyTupli allows fine-grained filtering and supports secure use with authentication and access control.

**结论:** PyTupli facilitates collaborative, reproducible, and scalable offline RL research.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PyTupli%3A+A+Scalable+Infrastructure+for+Collaborative+Offline+Reinforcement+Learning+Projects，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16754，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16754&send_immediately=true&force_search=false)

**原文摘要:** Offline reinforcement learning (RL) has gained traction as a powerful
paradigm for learning control policies from pre-collected data, eliminating the
need for costly or risky online interactions. While many open-source libraries
offer robust implementations of offline RL algorithms, they all rely on
datasets composed of experience tuples consisting of state, action, next state,
and reward. Managing, curating, and distributing such datasets requires
suitable infrastructure. Although static datasets exist for established
benchmark problems, no standardized or scalable solution supports developing
and sharing datasets for novel or user-defined benchmarks. To address this gap,
we introduce PyTupli, a Python-based tool to streamline the creation, storage,
and dissemination of benchmark environments and their corresponding tuple
datasets. PyTupli includes a lightweight client library with defined interfaces
for uploading and retrieving benchmarks and data. It supports fine-grained
filtering at both the episode and tuple level, allowing researchers to curate
high-quality, task-specific datasets. A containerized server component enables
production-ready deployment with authentication, access control, and automated
certificate provisioning for secure use. By addressing key barriers in dataset
infrastructure, PyTupli facilitates more collaborative, reproducible, and
scalable offline RL research.

</details>


### [102] [The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm](https://arxiv.org/abs/2505.16932)
*Noah Amsel, David Persson, Christopher Musco, Robert Gower*

**主要类别:** cs.LG

**概要:** 提出了一种名为Polar Express的新算法，用于在深度学习中的极分解计算，该算法适应性强且在实践中稳定。


<details>
  <summary>更多</summary>
  
**动机:** 传统数值分析中的经典算法在深度学习环境下表现不佳，因为它们效率低且不兼容GPU。

**方法:** Polar Express通过解决最小最大优化问题来调整多项式更新规则，并且只使用矩阵-矩阵乘法，使其与GPU兼容。

**结果:** Polar Express在验证损失上显示出一致的改进，并在各种学习率下优于最近的替代方案。

**结论:** Polar Express是一个高效且稳定的算法，在深度学习环境中优于传统的极分解计算方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Polar+Express%3A+Optimal+Matrix+Sign+Methods+and+Their+Application+to+the+Muon+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16932，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16932&send_immediately=true&force_search=false)

**原文摘要:** Computing the polar decomposition and the related matrix sign function, has
been a well-studied problem in numerical analysis for decades. More recently,
it has emerged as an important subroutine in deep learning, particularly within
the Muon optimization framework. However, the requirements in this setting
differ significantly from those of traditional numerical analysis. In deep
learning, methods must be highly efficient and GPU-compatible, but high
accuracy is often unnecessary. As a result, classical algorithms like
Newton-Schulz (which suffers from slow initial convergence) and methods based
on rational functions (which rely on QR decompositions or matrix inverses) are
poorly suited to this context. In this work, we introduce Polar Express, a
GPU-friendly algorithm for computing the polar decomposition. Like classical
polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix
multiplications, making it GPU-compatible. Motivated by earlier work of Chen &
Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule
at each iteration by solving a minimax optimization problem, and we prove that
it enjoys a strong worst-case optimality guarantee. This property ensures both
rapid early convergence and fast asymptotic convergence. We also address
finite-precision issues, making it stable in bfloat16 in practice. We apply
Polar Express within the Muon optimization framework and show consistent
improvements in validation loss on large-scale models such as GPT-2,
outperforming recent alternatives across a range of learning rates.

</details>


### [103] [Multi-Output Gaussian Processes for Graph-Structured Data](https://arxiv.org/abs/2505.16755)
*Ayano Nakai-Kasai, Tadashi Wadayama*

**主要类别:** cs.LG

**概要:** 提出了一种基于多输出高斯过程的图结构数据回归方法，该方法能够捕捉顶点间和相关数据间的相关性，并且具有广泛的适用性和高表达能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图结构数据高斯过程方法存在对数据配置、模型选择和推理场景的限制，需要一种更灵活的方法来处理图结构数据的相关性。

**方法:** 基于多输出高斯过程（MOGP），构建了一个回归方法，用于捕获图结构数据中顶点之间的相关性和关联数据之间的相关性。

**结果:** 通过合成数据和真实数据的计算机实验评估了所提出的公式所能实现的扩展性能。

**结论:** 所提出的方法具有广泛的适用性，能够去除现有方法对数据配置、模型选择和推理场景的限制，并且在表达能力和灵活性方面表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Output+Gaussian+Processes+for+Graph-Structured+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16755，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16755&send_immediately=true&force_search=false)

**原文摘要:** Graph-structured data is a type of data to be obtained associated with a
graph structure where vertices and edges describe some kind of data
correlation. This paper proposes a regression method on graph-structured data,
which is based on multi-output Gaussian processes (MOGP), to capture both the
correlation between vertices and the correlation between associated data. The
proposed formulation is built on the definition of MOGP. This allows it to be
applied to a wide range of data configurations and scenarios. Moreover, it has
high expressive capability due to its flexibility in kernel design. It includes
existing methods of Gaussian processes for graph-structured data as special
cases and is possible to remove restrictions on data configurations, model
selection, and inference scenarios in the existing methods. The performance of
extensions achievable by the proposed formulation is evaluated through computer
experiments with synthetic and real data.

</details>


### [104] [FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records](https://arxiv.org/abs/2505.16941)
*Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi*

**主要类别:** cs.LG

**概要:** This paper evaluates state-of-the-art foundation models on EHR data from 5 million patients for 14 clinically relevant tasks, aiming to provide a comprehensive assessment of their clinical utility and guide future model development.


<details>
  <summary>更多</summary>
  
**动机:** There is little consensus on the potential of foundation models for clinical utility in healthcare due to the lack of comprehensive tasks and evaluations.

**方法:** Proposes a suite of clinically meaningful tasks and evaluates state-of-the-art foundation models on EHR data from Columbia University Irving Medical Center.

**结果:** Measures overall accuracy, calibration, and subpopulation performance to identify tradeoffs based on different strategies.

**结论:** Aims to advance the empirical evaluation of structured EHR foundation models and guide the development of future healthcare foundation models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FoMoH%3A+A+clinically+meaningful+foundation+model+evaluation+for+structured+electronic+health+records，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16941，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16941&send_immediately=true&force_search=false)

**原文摘要:** Foundation models hold significant promise in healthcare, given their
capacity to extract meaningful representations independent of downstream tasks.
This property has enabled state-of-the-art performance across several clinical
applications trained on structured electronic health record (EHR) data, even in
settings with limited labeled data, a prevalent challenge in healthcare.
However, there is little consensus on these models' potential for clinical
utility due to the lack of desiderata of comprehensive and meaningful tasks and
sufficiently diverse evaluations to characterize the benefit over conventional
supervised learning. To address this gap, we propose a suite of clinically
meaningful tasks spanning patient outcomes, early prediction of acute and
chronic conditions, including desiderata for robust evaluations. We evaluate
state-of-the-art foundation models on EHR data consisting of 5 million patients
from Columbia University Irving Medical Center (CUMC), a large urban academic
medical center in New York City, across 14 clinically relevant tasks. We
measure overall accuracy, calibration, and subpopulation performance to surface
tradeoffs based on the choice of pre-training, tokenization, and data
representation strategies. Our study aims to advance the empirical evaluation
of structured EHR foundation models and guide the development of future
healthcare foundation models.

</details>


### [105] [FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting](https://arxiv.org/abs/2505.16786)
*Fares B. Mehouachi, Saif Eddin Jabari*

**主要类别:** cs.LG

**概要:** 提出了一种名为FlowMixer的新神经架构，该架构通过约束矩阵操作来建模结构化的时空模式，并展示了其在长期预测和物理现象建模中的强大能力。


<details>
  <summary>更多</summary>
  
**动机:** 增强神经网络的预测性能和数学解释性。

**方法:** 引入非负矩阵混合层到可逆映射框架中，并应用变换及其逆变换。

**结果:** 在多个领域实验表明FlowMixer在长时域预测上的鲁棒性以及对混沌吸引子和湍流等物理现象的有效建模。

**结论:** 结构化约束可以同时提高神经网络的预测能力和数学解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FlowMixer%3A+A+Constrained+Neural+Architecture+for+Interpretable+Spatiotemporal+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16786，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16786&send_immediately=true&force_search=false)

**原文摘要:** We introduce FlowMixer, a neural architecture that leverages constrained
matrix operations to model structured spatiotemporal patterns. At its core,
FlowMixer incorporates non-negative matrix mixing layers within a reversible
mapping framework-applying transforms before mixing and their inverses
afterward. This shape-preserving design enables a Kronecker-Koopman eigenmode
framework that bridges statistical learning with dynamical systems theory,
providing interpretable spatiotemporal patterns and facilitating direct
algebraic manipulation of prediction horizons without retraining. Extensive
experiments across diverse domains demonstrate FlowMixer's robust long-horizon
forecasting capabilities while effectively modeling physical phenomena such as
chaotic attractors and turbulent flows. These results suggest that
architectural constraints can simultaneously enhance predictive performance and
mathematical interpretability in neural forecasting systems.

</details>


### [106] [MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](https://arxiv.org/abs/2505.16947)
*Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev*

**主要类别:** cs.LG

**概要:** 提出了一种名为MixAT的新方法，结合离散和连续攻击来训练大型语言模型（LLMs），显著提高了其鲁棒性，同时保持了与仅使用连续松弛方法相当的运行时间。


<details>
  <summary>更多</summary>
  
**动机:** 现有对抗性攻击仍能持续导致有害生成；对抗性训练在传统机器学习模型中效果显著，但在LLMs中的优缺点尚不明确。

**方法:** 引入MixAT方法，结合更强的离散和更快的连续攻击进行训练，并提出了ALO-ASR指标评估模型的最差情况漏洞。

**结果:** MixAT在多种最先进的攻击下表现出色，ALO-ASR<20%，优于先前防御措施的ALO-ASR>50%。

**结论:** MixAT提供了离散-连续防御的合理且优越的鲁棒性-准确性权衡，具有最小的计算开销，展示了构建更安全LLMs的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MixAT%3A+Combining+Continuous+and+Discrete+Adversarial+Training+for+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16947，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16947&send_immediately=true&force_search=false)

**原文摘要:** Despite recent efforts in Large Language Models (LLMs) safety and alignment,
current adversarial attacks on frontier LLMs are still able to force harmful
generations consistently. Although adversarial training has been widely studied
and shown to significantly improve the robustness of traditional machine
learning models, its strengths and weaknesses in the context of LLMs are less
understood. Specifically, while existing discrete adversarial attacks are
effective at producing harmful content, training LLMs with concrete adversarial
prompts is often computationally expensive, leading to reliance on continuous
relaxations. As these relaxations do not correspond to discrete input tokens,
such latent training methods often leave models vulnerable to a diverse set of
discrete attacks. In this work, we aim to bridge this gap by introducing MixAT,
a novel method that combines stronger discrete and faster continuous attacks
during training. We rigorously evaluate MixAT across a wide spectrum of
state-of-the-art attacks, proposing the At Least One Attack Success Rate
(ALO-ASR) metric to capture the worst-case vulnerability of models. We show
MixAT achieves substantially better robustness (ALO-ASR < 20%) compared to
prior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to
methods based on continuous relaxations. We further analyze MixAT in realistic
deployment settings, exploring how chat templates, quantization, low-rank
adapters, and temperature affect both adversarial training and evaluation,
revealing additional blind spots in current methodologies. Our results
demonstrate that MixAT's discrete-continuous defense offers a principled and
superior robustness-accuracy tradeoff with minimal computational overhead,
highlighting its promise for building safer LLMs. We provide our code and
models at https://github.com/insait-institute/MixAT.

</details>


### [107] [Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning](https://arxiv.org/abs/2505.16950)
*Adnan Oomerjee, Zafeirios Fountas, Zhongwei Yu, Haitham Bou-Ammar, Jun Wang*

**主要类别:** cs.LG

**概要:** This paper explores how Large Language Models can improve their generalization beyond their training data using Information Bottleneck theory.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of LLMs struggling with generalization and extrapolation instead of abstract reasoning.

**方法:** Applying IB theory to decoder-only Transformers and proving inherent constraints in forming task-optimal sequence representations.

**结果:** A modified Transformer architecture with an additional module that periodically rewrites the KV cache improves performance on mathematical reasoning benchmarks.

**结论:** The proposed method provides a principled way to enhance Transformer memory using information theory, overcoming limitations that scaling alone cannot solve.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bottlenecked+Transformers%3A+Periodic+KV+Cache+Abstraction+for+Generalised+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16950，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16950&send_immediately=true&force_search=false)

**原文摘要:** Despite their impressive capabilities, Large Language Models struggle with
generalisation beyond their training distribution, often exhibiting
sophisticated pattern interpolation rather than true abstract reasoning
(extrapolation). In this work, we approach this limitation through the lens of
Information Bottleneck (IB) theory, which posits that model generalisation
emerges from an optimal balance between input compression and retention of
predictive information in latent representations. We prove using IB theory that
decoder-only Transformers are inherently constrained in their ability to form
task-optimal sequence representations. We then use this result to demonstrate
that periodic global transformation of the internal sequence-level
representations (KV cache) is a necessary computational step for improving
Transformer generalisation in reasoning tasks. Based on these theoretical
insights, we propose a modification to the Transformer architecture, in the
form of an additional module that globally rewrites the KV cache at periodic
intervals, shifting its capacity away from memorising input prefixes and toward
encoding features most useful for predicting future tokens. Our model delivers
substantial gains on mathematical reasoning benchmarks, outperforming both
vanilla Transformers with up to 3.5x more parameters, as well as
heuristic-driven pruning mechanisms for cache compression. Our approach can be
seen as a principled generalisation of existing KV-cache compression methods;
whereas such methods focus solely on compressing input representations, they
often do so at the expense of retaining predictive information, and thus their
capabilities are inherently bounded by those of an unconstrained model. This
establishes a principled framework to manipulate Transformer memory using
information theory, addressing fundamental reasoning limitations that scaling
alone cannot overcome.

</details>


### [108] [Contextual Learning for Stochastic Optimization](https://arxiv.org/abs/2505.16829)
*Anna Heuser, Thomas Kesselheim*

**主要类别:** cs.LG

**概要:** 研究了从上下文价值分布样本中学习的问题，并提出了通过最小化凸替代损失来学习经验分布的方法。此结果被应用于获得对于在未知上下文价值分布上定义的随机优化问题的ε - 最优策略的学习样本复杂度界限。


<details>
  <summary>更多</summary>
  
**动机:** 受随机优化的启发，研究了从上下文价值分布样本中学习的问题。

**方法:** 通过最小化凸替代损失函数，学习每个上下文的经验分布，确保与真实分布之间的Levy距离较小。

**结果:** 获得了随机优化问题中ε - 最优策略学习的样本复杂度界限，并证明其对于强单调且稳定的一般情况是多项式的。

**结论:** 研究解决了从上下文价值分布样本中学习的问题，并给出了相关理论结果和应用示例。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Contextual+Learning+for+Stochastic+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16829，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16829&send_immediately=true&force_search=false)

**原文摘要:** Motivated by stochastic optimization, we introduce the problem of learning
from samples of contextual value distributions. A contextual value distribution
can be understood as a family of real-valued distributions, where each sample
consists of a context $x$ and a random variable drawn from the corresponding
real-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn
an empirical distribution $D'_x$ for each context, ensuring a small L\'evy
distance to $D_x$. We apply this result to obtain the sample complexity bounds
for the learning of an $\epsilon$-optimal policy for stochastic optimization
problems defined on an unknown contextual value distribution. The sample
complexity is shown to be polynomial for the general case of strongly monotone
and stable optimization problems, including Single-item Revenue Maximization,
Pandora's Box and Optimal Stopping.

</details>


### [109] [Interactive Post-Training for Vision-Language-Action Models](https://arxiv.org/abs/2505.17016)
*Shuhan Tan, Kairan Dou, Yue Zhao, Philipp Krähenbühl*

**主要类别:** cs.LG

**概要:** RIPT-VLA是一种基于强化学习的交互式后训练范例，用于微调预训练的视觉语言动作模型，仅使用稀疏二元成功奖励。该方法可以提高各种VLA模型的性能，并且计算和数据效率高，同时学到的策略在不同任务和场景中具有泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的VLA训练管道严重依赖离线专家演示数据和监督模仿，限制了其在低数据环境下的适应能力。

**方法:** RIPT-VLA通过基于动态滚动采样和leave-one-out优势估计的稳定策略优化算法实现交互式后训练。

**结果:** RIPT-VLA显著提高了不同VLA模型的性能，例如QueST模型提升了21.2%，OpenVLA-OFT模型达到了97.5%的成功率。此外，它还展示了对初始状态上下文的鲁棒性。

**结论:** RIPT-VLA是一种实用且有效的后训练VLA模型的范例，只需要极少的监督。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interactive+Post-Training+for+Vision-Language-Action+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17016，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17016&send_immediately=true&force_search=false)

**原文摘要:** We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based
interactive post-training paradigm that fine-tunes pretrained
Vision-Language-Action (VLA) models using only sparse binary success rewards.
Existing VLA training pipelines rely heavily on offline expert demonstration
data and supervised imitation, limiting their ability to adapt to new tasks and
environments under low-data regimes. RIPT-VLA addresses this by enabling
interactive post-training with a stable policy optimization algorithm based on
dynamic rollout sampling and leave-one-out advantage estimation.
  RIPT-VLA has the following characteristics. First, it applies to various VLA
models, resulting in an improvement on the lightweight QueST model by 21.2%,
and the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it
is computationally efficient and data-efficient: with only one demonstration,
RIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success
rate within 15 iterations. Furthermore, we demonstrate that the policy learned
by RIPT-VLA generalizes across different tasks and scenarios and is robust to
the initial state context. These results highlight RIPT-VLA as a practical and
effective paradigm for post-training VLA models through minimal supervision.

</details>


### [110] [Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning](https://arxiv.org/abs/2505.16833)
*Alihan Hüyük, Finale Doshi-Velez*

**主要类别:** cs.LG

**概要:** This paper introduces strategic link scores to measure dependencies between planned actions in long-term planning for reinforcement learning tasks.


<details>
  <summary>更多</summary>
  
**动机:** To understand and improve long-term planning strategies in reinforcement learning by quantifying dependencies between actions.

**方法:** Introduces strategic link scores that measure the drop in the likelihood of a decision when a follow-up decision is unavailable.

**结果:** Demonstrates the utility of strategic link scores in explaining black-box RL agents, improving decision support systems, and characterizing planning processes of non-RL agents.

**结论:** Strategic link scores provide a novel way to analyze and enhance long-term planning strategies in various applications.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategically+Linked+Decisions+in+Long-Term+Planning+and+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16833，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16833&send_immediately=true&force_search=false)

**原文摘要:** Long-term planning, as in reinforcement learning (RL), involves finding
strategies: actions that collectively work toward a goal rather than
individually optimizing their immediate outcomes. As part of a strategy, some
actions are taken at the expense of short-term benefit to enable future actions
with even greater returns. These actions are only advantageous if followed up
by the actions they facilitate, consequently, they would not have been taken if
those follow-ups were not available. In this paper, we quantify such
dependencies between planned actions with strategic link scores: the drop in
the likelihood of one decision under the constraint that a follow-up decision
is no longer available. We demonstrate the utility of strategic link scores
through three practical applications: (i) explaining black-box RL agents by
identifying strategically linked pairs among decisions they make, (ii)
improving the worst-case performance of decision support systems by
distinguishing whether recommended actions can be adopted as standalone
improvements or whether they are strategically linked hence requiring a
commitment to a broader strategy to be effective, and (iii) characterizing the
planning processes of non-RL agents purely through interventions aimed at
measuring strategic link scores - as an example, we consider a realistic
traffic simulator and analyze through road closures the effective planning
horizon of the emergent routing behavior of many drivers.

</details>


### [111] [ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning](https://arxiv.org/abs/2505.16850)
*Tajamul Ashraf, Mohammed Mohsen Peerzada, Moloud Abdar, Yutong Xie, Yuyin Zhou, Xiaofeng Liu, Iqra Altaf Gillani, Janibul Bashir*

**主要类别:** cs.LG

**概要:** This paper introduces ATR-Bench, a unified framework for evaluating federated learning across three dimensions: Adaptation, Trust, and Reasoning.


<details>
  <summary>更多</summary>
  
**动机:** The lack of standardized evaluation across key dimensions hampers systematic progress and fair comparison of FL methods.

**方法:** ATR-Bench, a unified framework for analyzing federated learning through three foundational dimensions: Adaptation, Trust, and Reasoning.

**结果:** An in-depth examination of the conceptual foundations, task formulations, and open research challenges associated with each theme. Extensively benchmarked representative methods and datasets for adaptation to heterogeneous clients and trustworthiness in adversarial or unreliable environments.

**结论:** ATR-Bench lays the groundwork for a systematic and holistic evaluation of federated learning with real-world relevance.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ATR-Bench%3A+A+Federated+Learning+Benchmark+for+Adaptation%2C+Trust%2C+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16850，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16850&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) has emerged as a promising paradigm for collaborative
model training while preserving data privacy across decentralized participants.
As FL adoption grows, numerous techniques have been proposed to tackle its
practical challenges. However, the lack of standardized evaluation across key
dimensions hampers systematic progress and fair comparison of FL methods. In
this work, we introduce ATR-Bench, a unified framework for analyzing federated
learning through three foundational dimensions: Adaptation, Trust, and
Reasoning. We provide an in-depth examination of the conceptual foundations,
task formulations, and open research challenges associated with each theme. We
have extensively benchmarked representative methods and datasets for adaptation
to heterogeneous clients and trustworthiness in adversarial or unreliable
environments. Due to the lack of reliable metrics and models for reasoning in
FL, we only provide literature-driven insights for this dimension. ATR-Bench
lays the groundwork for a systematic and holistic evaluation of federated
learning with real-world relevance. We will make our complete codebase publicly
accessible and a curated repository that continuously tracks new developments
and research in the FL literature.

</details>


### [112] [Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft](https://arxiv.org/abs/2505.16857)
*Ertuğrul Keçeci, Müjde Güzelkaya, Tufan Kumbasar*

**主要类别:** cs.LG

**概要:** 提出了一种新的算法IC-SYSID，用于在没有先验知识的情况下解决联邦学习框架下的系统辨识问题。通过增量聚类和聚类合并等技术提高了模型的稳定性和性能。实验表明，该方法在保持高系统辨识性能的同时避免了不稳定聚类的学习。


<details>
  <summary>更多</summary>
  
**动机:** 在没有先验知识的情况下解决系统辨识问题，特别是在多数据源环境下。

**方法:** 提出了增量聚类方法ClusterCraft（CC）和聚类合并技术ClusterMerge，并引入了增强版ClusterCraft以及正则化项和Glorot初始化来提高模型稳定性，采用小批量深度学习处理大规模数据集。

**结果:** 实验结果显示IC-SYSID在真实世界车辆动力学系统辨识问题上表现优异，同时防止了不稳定聚类的学习。

**结论:** IC-SYSID是一种有效的解决方案，在不需要先验知识的情况下，能够在联邦学习环境中实现高效的系统辨识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Redefining+Clustered+Federated+Learning+for+System+Identification%3A+The+Path+of+ClusterCraft，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16857，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16857&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the System Identification (SYSID) problem within the
framework of federated learning. We introduce a novel algorithm, Incremental
Clustering-based federated learning method for SYSID (IC-SYSID), designed to
tackle SYSID challenges across multiple data sources without prior knowledge.
IC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to
eliminate the dependency on the prior knowledge of the dataset. CC starts with
a single cluster model and assigns similar local workers to the same clusters
by dynamically increasing the number of clusters. To reduce the number of
clusters generated by CC, we introduce ClusterMerge, where similar cluster
models are merged. We also introduce enhanced ClusterCraft to reduce the
generation of similar cluster models during the training. Moreover, IC-SYSID
addresses cluster model instability by integrating a regularization term into
the loss function and initializing cluster models with scaled Glorot
initialization. It also utilizes a mini-batch deep learning approach to manage
large SYSID datasets during local training. Through the experiments conducted
on a real-world representing SYSID problem, where a fleet of vehicles
collaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high
SYSID performance while preventing the learning of unstable clusters.

</details>


### [113] [A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams](https://arxiv.org/abs/2505.16872)
*Mohammed Al-Qudah, Fadi AlMahamid*

**主要类别:** cs.LG

**概要:** 提出了一种多步骤评估框架，用于研究不同预处理选择对三种机器学习算法（RNN-LSTM、自动编码神经网络和梯度提升）的影响。实验表明，梯度提升在所有预处理配置下都表现出色，而RNN-LSTM在Z分数归一化时有显著改进，自动编码器在无监督场景中表现良好。


<details>
  <summary>更多</summary>
  
**动机:** IoT设备的快速发展带来了严重的安全挑战，准确的异常检测变得至关重要，但之前的研究没有系统地研究不同的预处理步骤如何与不同的模型架构相互作用。

**方法:** 设计了一个多步骤评估框架来评估预处理选择对三种机器学习算法的影响。

**结果:** 梯度提升在所有预处理配置下都表现出色，RNN-LSTM在Z分数归一化时有显著改进，自动编码器在无监督场景中表现良好。

**结论:** 提出的框架提供了增强IoT环境中异常检测性能的操作指南。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Multi-Step+Comparative+Framework+for+Anomaly+Detection+in+IoT+Data+Streams，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16872，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16872&send_immediately=true&force_search=false)

**原文摘要:** The rapid expansion of Internet of Things (IoT) devices has introduced
critical security challenges, underscoring the need for accurate anomaly
detection. Although numerous studies have proposed machine learning (ML)
methods for this purpose, limited research systematically examines how
different preprocessing steps--normalization, transformation, and feature
selection--interact with distinct model architectures. To address this gap,
this paper presents a multi-step evaluation framework assessing the combined
impact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder
neural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the
IoTID20 dataset shows that GBoosting consistently delivers superior accuracy
across preprocessing configurations, while RNN-LSTM shows notable gains with
z-score normalization and autoencoders excel in recall, making them well-suited
for unsupervised scenarios. By offering a structured analysis of preprocessing
decisions and their interplay with various ML techniques, the proposed
framework provides actionable guidance to enhance anomaly detection performance
in IoT environments.

</details>


### [114] [Unsupervised Prompting for Graph Neural Networks](https://arxiv.org/abs/2505.16903)
*Peyman Baghershahi, Sourav Medya*

**主要类别:** cs.LG

**概要:** 提出了一种新的无监督提示方法，无需更新参数和标签数据即可提高预训练图神经网络在协变量偏移下的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于提示的图神经网络方法依赖于标记数据且需要轻量级微调，受大语言模型上下文学习方法启发，提出一种新的问题设定来评估图神经网络提示方法。

**方法:** 提出了基于伪标记的一致性正则化无监督提示方法，采用两种正则化技术对齐提示图分布与原始数据并减少偏差预测。

**结果:** 在提出的设定下进行大量实验，证明所提方法优于有访问标签的状态-of-方法提示方法。

**结论:** 该工作引入了新的问题设定，并提出了一种有效的无监督图神经网络提示方法，无需参数更新和标记数据即可增强泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Prompting+for+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16903，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16903&send_immediately=true&force_search=false)

**原文摘要:** Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to
address the semantic gap between pre-training and fine-tuning steps. However,
existing GNN prompting methods rely on labeled data and involve lightweight
fine-tuning for downstream tasks. Meanwhile, in-context learning methods for
Large Language Models (LLMs) have shown promising performance with no parameter
updating and no or minimal labeled data. Inspired by these approaches, in this
work, we first introduce a challenging problem setup to evaluate GNN prompting
methods. This setup encourages a prompting function to enhance a pre-trained
GNN's generalization to a target dataset under covariate shift without updating
the GNN's parameters and with no labeled data. Next, we propose a fully
unsupervised prompting method based on consistency regularization through
pseudo-labeling. We use two regularization techniques to align the prompted
graphs' distribution with the original data and reduce biased predictions.
Through extensive experiments under our problem setting, we demonstrate that
our unsupervised approach outperforms the state-of-the-art prompting methods
that have access to labels.

</details>


### [115] [Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype](https://arxiv.org/abs/2505.16918)
*Nikola Tankovic, Robert Sajina*

**主要类别:** cs.LG

**概要:** 本文介绍了一种新的上下文多臂老虎机方法的实验框架，用于高效且可解释的多类别优惠选择。


<details>
  <summary>更多</summary>
  
**动机:** 解决快速变化的优惠选择挑战，并提高在动态环境中的学习效率和泛化能力。

**方法:** 通过产品类别级别的上下文建模，扩展了标准CMAB方法以支持多类别上下文，并通过有效的特征工程和模块化设计实现可扩展性。引入了MPG和MF等高级特性来捕捉用户-优惠交互，并且使用逻辑回归模型生成透明权重向量。

**结果:** 实现了高效的特征工程和模块化设计，能够处理多类别上下文，并通过逻辑回归模型提供了透明的权重向量。

**结论:** 提出了一种新的基于上下文多臂老虎机方法的实验框架，该框架在动态环境中提高了学习效率和泛化能力，并且在大规模解释方面做出了重要贡献。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+and+Interpretable+Contextual+Bandits%3A+A+Literature+Review+and+Retail+Offer+Prototype，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16918&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)
methods and introduces an experimental framework for scalable, interpretable
offer selection, addressing the challenge of fast-changing offers. The approach
models context at the product category level, allowing offers to span multiple
categories and enabling knowledge transfer across similar offers. This improves
learning efficiency and generalization in dynamic environments. The framework
extends standard CMAB methodology to support multi-category contexts, and
achieves scalability through efficient feature engineering and modular design.
Advanced features such as MPG (Member Purchase Gap) and MF (Matrix
Factorization) capture nuanced user-offer interactions, with implementation in
Python for practical deployment.
  A key contribution is interpretability at scale: logistic regression models
yield transparent weight vectors, accessible via a large language model (LLM)
interface for real-time, user-level tracking and explanation of evolving
preferences. This enables the generation of detailed member profiles and
identification of behavioral patterns, supporting personalized offer
optimization and enhancing trust in automated decisions. By situating our
prototype alongside established paradigms like Generalized Linear Models and
Thompson Sampling, we demonstrate its value for both research and real-world
CMAB applications.

</details>


### [116] [Risk-Averse Reinforcement Learning with Itakura-Saito Loss](https://arxiv.org/abs/2505.16925)
*Igor Udovichenko, Olivier Croissant, Anita Toleutaeva, Evgeny Burnaev, Alexander Korotin*

**主要类别:** cs.LG

**概要:** 提出了一种基于Itakura-Saito散度的数值稳定损失函数，用于风险规避强化学习，实验表明其在金融场景中优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 风险规避强化学习在高风险领域有广泛应用，但传统方法存在数值不稳定的问题。

**方法:** 通过修改现有的强化学习算法，并引入新的基于Itakura-Saito散度的损失函数来解决数值不稳定性问题。

**结果:** 新提出的损失函数在理论和实验上都优于现有方法，在金融场景测试中表现优异。

**结论:** 引入了基于Itakura-Saito散度的新损失函数，该函数在学习状态值和动作值函数时表现出色。实验显示其优于现有替代方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Risk-Averse+Reinforcement+Learning+with+Itakura-Saito+Loss，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16925，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16925&send_immediately=true&force_search=false)

**原文摘要:** Risk-averse reinforcement learning finds application in various high-stakes
fields. Unlike classical reinforcement learning, which aims to maximize
expected returns, risk-averse agents choose policies that minimize risk,
occasionally sacrificing expected value. These preferences can be framed
through utility theory. We focus on the specific case of the exponential
utility function, where we can derive the Bellman equations and employ various
reinforcement learning algorithms with few modifications. However, these
methods suffer from numerical instability due to the need for exponent
computation throughout the process. To address this, we introduce a numerically
stable and mathematically sound loss function based on the Itakura-Saito
divergence for learning state-value and action-value functions. We evaluate our
proposed loss function against established alternatives, both theoretically and
empirically. In the experimental section, we explore multiple financial
scenarios, some with known analytical solutions, and show that our loss
function outperforms the alternatives.

</details>


### [117] [LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning](https://arxiv.org/abs/2505.16933)
*Zebin You, Shen Nie, Xiaolu Zhang, Jun Hu, Jun Zhou, Zhiwu Lu, Ji-Rong Wen, Chongxuan Li*

**主要类别:** cs.LG

**概要:** LLaDA-V是一种基于扩散的多模态大型语言模型，结合了视觉指令微调和掩码扩散模型，显示出在多模态任务中的强大性能。


<details>
  <summary>更多</summary>
  
**动机:** 探索大型语言扩散模型在多模态环境中的潜力。

**方法:** 通过整合视觉编码器和MLP连接器将视觉特征投影到语言嵌入空间来实现多模态对齐。

**结果:** 在相同的指令数据上训练时，LLaDA-V在多模态任务上的表现与LLaMA3-V相当，并且优于Qwen2-VL，特别是在多模态理解方面达到了最先进的性能。

**结论:** 研究结果表明，大型语言扩散模型在多模态任务中表现出色，值得进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLaDA-V%3A+Large+Language+Diffusion+Models+with+Visual+Instruction+Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16933，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16933&send_immediately=true&force_search=false)

**原文摘要:** In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large
Language Model (MLLM) that integrates visual instruction tuning with masked
diffusion models, representing a departure from the autoregressive paradigms
dominant in current multimodal approaches. Built upon LLaDA, a representative
large language diffusion model, LLaDA-V incorporates a vision encoder and MLP
connector that projects visual features into the language embedding space,
enabling effective multimodal alignment. Our empirical investigation reveals
several intriguing results: First, LLaDA-V demonstrates promising multimodal
performance despite its language model being weaker on purely textual tasks
than counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same
instruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal
tasks with better data scalability. It also narrows the performance gap to
Qwen2-VL, suggesting the effectiveness of its architecture for multimodal
tasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal
understanding compared to existing hybrid autoregressive-diffusion and purely
diffusion-based MLLMs. Our findings suggest that large language diffusion
models show promise in multimodal contexts and warrant further investigation in
future research. Project page and codes:
https://ml-gsai.github.io/LLaDA-V-demo/.

</details>


### [118] [SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems](https://arxiv.org/abs/2505.16936)
*Yizhuo Chen, Tianchen Wang, You Lyu, Yanlan Hu, Jinyang Li, Tomoyoshi Kimura, Hongjue Zhao, Yigong Hu, Denizhan Kara, Tarek Abdelzaher*

**主要类别:** cs.LG

**概要:** 提出了一种新的自监督预训练方法，该方法考虑了物联网系统中传感器观测的空间特性，实验验证了其在不同任务和数据集上的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了更好地表示多传感器物联网系统中的外部环境状态，准确提取分布式多视角观测的空间现象。

**方法:** 开发了一种自监督的放置感知表征学习方法，该方法显式地学习测量值与几何观察者布局及结构特征之间的依赖关系，并遵循信号与观察者位置对偶性的核心设计原则。此外还从信息论和遮挡不变表征学习的角度进行了理论分析。

**结果:** 在三个真实世界的数据集上（涉及车辆监控、人类活动识别和地震定位）展示了方法在不同模态、传感器布置、应用级推理任务和空间尺度上的卓越泛化性和鲁棒性。

**结论:** 这项工作显著推进了基于物联网信号的自监督模型预训练，超越了当前通常忽略物联网数据独特空间性质的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPAR%3A+Self-supervised+Placement-Aware+Representation+Learning+for+Multi-Node+IoT+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16936，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16936&send_immediately=true&force_search=false)

**原文摘要:** This work develops the underpinnings of self-supervised placement-aware
representation learning given spatially-distributed (multi-view and multimodal)
sensor observations, motivated by the need to represent external environmental
state in multi-sensor IoT systems in a manner that correctly distills spatial
phenomena from the distributed multi-vantage observations. The objective of
sensing in IoT systems is, in general, to collectively represent an externally
observed environment given multiple vantage points from which sensory
observations occur. Pretraining of models that help interpret sensor data must
therefore encode the relation between signals observed by sensors and the
observers' vantage points in order to attain a representation that encodes the
observed spatial phenomena in a manner informed by the specific placement of
the measuring instruments, while allowing arbitrary placement. The work
significantly advances self-supervised model pretraining from IoT signals
beyond current solutions that often overlook the distinctive spatial nature of
IoT data. Our framework explicitly learns the dependencies between measurements
and geometric observer layouts and structural characteristics, guided by a core
design principle: the duality between signals and observer positions. We
further provide theoretical analyses from the perspectives of information
theory and occlusion-invariant representation learning to offer insight into
the rationale behind our design. Experiments on three real-world
datasets--covering vehicle monitoring, human activity recognition, and
earthquake localization--demonstrate the superior generalizability and
robustness of our method across diverse modalities, sensor placements,
application-level inference tasks, and spatial scales.

</details>


### [119] [A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization](https://arxiv.org/abs/2505.16952)
*Shengyu Feng, Weiwei Sun, Shanda Li, Ameet Talwalkar, Yiming Yang*

**主要类别:** cs.LG

**概要:** 介绍了一个名为FrontierCO的综合基准，涵盖八个经典的组合优化问题类型，并评估了16种代表性的基于机器学习的求解器。


<details>
  <summary>更多</summary>
  
**动机:** 现有机器学习方法在实际大规模组合优化场景中的有效性存在疑问，许多现有的组合优化基准缺乏足够的训练数据。

**方法:** 引入FrontierCO基准，评估多种基于机器学习的求解器，包括图神经网络和大型语言模型代理。

**结果:** 提供了关于当前机器学习方法的优势和局限性的关键见解。

**结论:** 帮助引导机器学习与组合优化交叉领域更强大和实用的相关进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comprehensive+Evaluation+of+Contemporary+ML-Based+Solvers+for+Combinatorial+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16952，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16952&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML) has demonstrated considerable potential in supporting
model design and optimization for combinatorial optimization (CO) problems.
However, much of the progress to date has been evaluated on small-scale,
synthetic datasets, raising concerns about the practical effectiveness of
ML-based solvers in real-world, large-scale CO scenarios. Additionally, many
existing CO benchmarks lack sufficient training data, limiting their utility
for evaluating data-driven approaches. To address these limitations, we
introduce FrontierCO, a comprehensive benchmark that covers eight canonical CO
problem types and evaluates 16 representative ML-based solvers--including graph
neural networks and large language model (LLM) agents. FrontierCO features
challenging instances drawn from industrial applications and frontier CO
research, offering both realistic problem difficulty and abundant training
data. Our empirical results provide critical insights into the strengths and
limitations of current ML methods, helping to guide more robust and practically
relevant advances at the intersection of machine learning and combinatorial
optimization. Our data is available at
https://huggingface.co/datasets/CO-Bench/FrontierCO.

</details>


### [120] [UFT: Unifying Supervised and Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.16984)
*Mingyang Liu, Gabriele Farina, Asuman Ozdaglar*

**主要类别:** cs.LG

**概要:** A novel method called Unified Fine-Tuning (UFT) is proposed to overcome the limitations of supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) for enhancing the reasoning capabilities of large language models.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitations of SFT and RFT in improving the reasoning abilities of large language models.

**方法:** Unified Fine-Tuning (UFT), which combines SFT and RFT into one process.

**结果:** UFT performs better than both SFT and RFT across different model sizes.

**结论:** Theoretically, UFT breaks RFT's exponential sample complexity bottleneck, demonstrating that unified training can significantly speed up convergence in long-horizon reasoning tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是UFT%3A+Unifying+Supervised+and+Reinforcement+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16984，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16984&send_immediately=true&force_search=false)

**原文摘要:** Post-training has demonstrated its importance in enhancing the reasoning
capabilities of large language models (LLMs). The primary post-training methods
can be categorized into supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT is efficient and well-suited for small language models,
but it may lead to overfitting and limit the reasoning abilities of larger
models. In contrast, RFT generally yields better generalization but depends
heavily on the strength of the base model. To address the limitations of SFT
and RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm
that unifies SFT and RFT into a single, integrated process. UFT enables the
model to effectively explore solutions while incorporating informative
supervision signals, bridging the gap between memorizing and thinking
underlying existing methods. Notably, UFT outperforms both SFT and RFT in
general, regardless of model sizes. Furthermore, we theoretically prove that
UFT breaks RFT's inherent exponential sample complexity bottleneck, showing for
the first time that unified training can exponentially accelerate convergence
on long-horizon reasoning tasks.

</details>


### [121] [PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics](https://arxiv.org/abs/2505.16992)
*Aleksandra Franz, Hao Wei, Luca Guastoni, Nils Thuerey*

**主要类别:** cs.LG

**概要:** Differentiable fluid simulator PICT coded in PyTorch with GPU support is presented. It is verified in benchmarks and used to learn turbulence models in 2D and 3D.


<details>
  <summary>更多</summary>
  
**动机:** The need for gradient information in deep learning to improve physics simulations.

**方法:** Developing a differentiable pressure-implicit fluid simulator called PICT in PyTorch with GPU support, verifying its accuracy, and using it to learn turbulence models.

**结果:** PICT accurately simulates fluid dynamics and learns turbulence models in 2D and 3D. The low-resolution corrector runs faster than high-resolution references while maintaining or improving their accuracy.

**结论:** PICT is an effective tool for optimizing and learning in physics simulations, and its open-source availability encourages further research.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PICT+--+A+Differentiable%2C+GPU-Accelerated+Multi-Block+PISO+Solver+for+Simulation-Coupled+Learning+Tasks+in+Fluid+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16992，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16992&send_immediately=true&force_search=false)

**原文摘要:** Despite decades of advancements, the simulation of fluids remains one of the
most challenging areas of in scientific computing. Supported by the necessity
of gradient information in deep learning, differentiable simulators have
emerged as an effective tool for optimization and learning in physics
simulations. In this work, we present our fluid simulator PICT, a
differentiable pressure-implicit solver coded in PyTorch with
Graphics-processing-unit (GPU) support. We first verify the accuracy of both
the forward simulation and our derived gradients in various established
benchmarks like lid-driven cavities and turbulent channel flows before we show
that the gradients provided by our solver can be used to learn complicated
turbulence models in 2D and 3D. We apply both supervised and unsupervised
training regimes using physical priors to match flow statistics. In particular,
we learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow
purely based on reference statistics. The low-resolution corrector trained with
our solver runs substantially faster than the highly resolved references, while
keeping or even surpassing their accuracy. Finally, we give additional insights
into the physical interpretation of different solver gradients, and motivate a
physically informed regularization technique. To ensure that the full potential
of PICT can be leveraged, it is published as open source:
https://github.com/tum-pbs/PICT.

</details>


### [122] [A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations](https://arxiv.org/abs/2505.16996)
*Shalev Manor, Mohammad Kohandel*

**主要类别:** cs.LG

**概要:** 提出了一种新的框架来解决涉及微分方程的逆问题中的非唯一解挑战，并在生物系统和生态动力学的例子中展示了其准确性和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法如PINNs、UDEs和UPINNs在隔离参数或函数时有效，但当同时应用时可能面临非唯一解的问题。

**方法:** 引入了一个新的框架，通过建立保证唯一解的条件来解决上述问题。

**结果:** 该框架在生物系统和生态动力学的例子中展示了准确且可解释的结果。

**结论:** 此方法显著增强了机器学习技术在科学和工程复杂系统建模中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Unified+Framework+for+Simultaneous+Parameter+and+Function+Discovery+in+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16996，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16996&send_immediately=true&force_search=false)

**原文摘要:** Inverse problems involving differential equations often require identifying
unknown parameters or functions from data. Existing approaches, such as
Physics-Informed Neural Networks (PINNs), Universal Differential Equations
(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective
at isolating either parameters or functions but can face challenges when
applied simultaneously due to solution non-uniqueness. In this work, we
introduce a framework that addresses these limitations by establishing
conditions under which unique solutions can be guaranteed. To illustrate, we
apply it to examples from biological systems and ecological dynamics,
demonstrating accurate and interpretable results. Our approach significantly
enhances the potential of machine learning techniques in modeling complex
systems in science and engineering.

</details>


### [123] [When Are Concepts Erased From Diffusion Models?](https://arxiv.org/abs/2505.17013)
*Kevin Lu, Nicky Kriplani, Rohit Gandikota, Minh Pham, David Bau, Chinmay Hegde, Niv Cohen*

**主要类别:** cs.LG

**概要:** This paper discusses concept erasure in diffusion models, proposing two models for the erasure mechanism and introducing a suite of evaluations to assess the thoroughness of concept erasure.


<details>
  <summary>更多</summary>
  
**动机:** Selective prevention of a model from generating specific concepts has gained interest, but it is unclear how effectively current methods erase these concepts.

**方法:** Proposed two conceptual models for the erasure mechanism and introduced a suite of evaluations including adversarial attacks and probing techniques.

**结果:** Results showed the tension between minimizing side effects and maintaining robustness to adversarial prompts.

**结论:** Comprehensive evaluation is crucial for concept erasure in diffusion models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Are+Concepts+Erased+From+Diffusion+Models%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17013，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17013&send_immediately=true&force_search=false)

**原文摘要:** Concept erasure, the ability to selectively prevent a model from generating
specific concepts, has attracted growing interest, with various approaches
emerging to address the challenge. However, it remains unclear how thoroughly
these methods erase the target concept. We begin by proposing two conceptual
models for the erasure mechanism in diffusion models: (i) reducing the
likelihood of generating the target concept, and (ii) interfering with the
model's internal guidance mechanisms. To thoroughly assess whether a concept
has been truly erased from the model, we introduce a suite of independent
evaluations. Our evaluation framework includes adversarial attacks, novel
probing techniques, and analysis of the model's alternative generations in
place of the erased concept. Our results shed light on the tension between
minimizing side effects and maintaining robustness to adversarial prompts.
Broadly, our work underlines the importance of comprehensive evaluation for
erasure in diffusion models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems](https://arxiv.org/abs/2505.15862)
*Long Wanga, Jiongzhi Zheng, Zhengda Xiong, ChuMin Li, Kun He*

**主要类别:** cs.AI

**概要:** 提出了一种基于多臂老虎机模型动态选择候选边的方法来改进Lin-Kernighan-Helsgaun (LKH) 算法在解决旅行商问题(TSP)中的性能，并在多个TSP基准测试中验证了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有算法如经典的LKH算法通常使用静态的预定义候选边，这可能导致算法陷入局部最优解，限制了解决更优解的可能性。

**方法:** 通过引入多臂老虎机模型，在每次迭代中动态选择最合适的候选边，从而让LKH算法做出更智能的选择。

**结果:** 在多个TSP基准测试中展示了所提方法的卓越性能，并且该方法显著提升了针对各种TSP变体问题的LKH-3算法的表现。

**结论:** 提出的多臂老虎机模型动态候选边选择方法有效提高了LKH和LKH-3算法在解决TSP及其变体问题上的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bandit+based+Dynamic+Candidate+Edge+Selection+in+Solving+Traveling+Salesman+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15862，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15862&send_immediately=true&force_search=false)

**原文摘要:** Algorithms designed for routing problems typically rely on high-quality
candidate edges to guide their search, aiming to reduce the search space and
enhance the search efficiency. However, many existing algorithms, like the
classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman
Problem (TSP), often use predetermined candidate edges that remain static
throughout local searches. This rigidity could cause the algorithm to get
trapped in local optima, limiting its potential to find better solutions. To
address this issue, we propose expanding the candidate sets to include other
promising edges, providing them an opportunity for selection. Specifically, we
incorporate multi-armed bandit models to dynamically select the most suitable
candidate edges in each iteration, enabling LKH to make smarter choices and
lead to improved solutions. Extensive experiments on multiple TSP benchmarks
show the excellent performance of our method. Moreover, we employ this
bandit-based method to LKH-3, an extension of LKH tailored for solving various
TSP variant problems, and our method also significantly enhances LKH-3's
performance across typical TSP variants.

</details>


### [125] [PhyX: Does Your Model Have the "Wits" for Physical Reasoning?](https://arxiv.org/abs/2505.15929)
*Hui Shen, Taiqiang Wu, Qi Han, Yunta Hsieh, Jizhou Wang, Yuyue Zhang, Yuxin Cheng, Zijian Hao, Yuansheng Ni, Xin Wang, Zhongwei Wan, Kai Zhang, Wendong Xu, Jing Xiong, Ping Luo, Wenhu Chen, Chaofan Tao, Zhuoqing Mao, Ngai Wong*

**主要类别:** cs.AI

**概要:** 提出PhyX基准测试来评估视觉场景中的物理推理能力，发现当前最先进的模型在物理推理方面表现不佳。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基准测试未能捕捉到智力的一个关键方面——物理推理，即整合领域知识、符号推理和现实世界约束的理解的能力。

**方法:** 引入PhyX基准测试，包含3K精心策划的多模态问题，涉及6种推理类型和6个核心物理领域。

**结果:** 即使是最先进的模型，在物理推理任务上也表现不佳，性能差距超过29%。

**结论:** 当前模型存在过度依赖记忆的学科知识、数学公式以及表面视觉模式匹配的问题，而非真正的物理理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhyX%3A+Does+Your+Model+Have+the+%22Wits%22+for+Physical+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15929，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15929&send_immediately=true&force_search=false)

**原文摘要:** Existing benchmarks fail to capture a crucial aspect of intelligence:
physical reasoning, the integrated ability to combine domain knowledge,
symbolic reasoning, and understanding of real-world constraints. To address
this gap, we introduce PhyX: the first large-scale benchmark designed to assess
models capacity for physics-grounded reasoning in visual scenarios. PhyX
includes 3K meticulously curated multimodal questions spanning 6 reasoning
types across 25 sub-domains and 6 core physics domains: thermodynamics,
electromagnetism, mechanics, modern physics, optics, and wave\&acoustics. In
our comprehensive evaluation, even state-of-the-art models struggle
significantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and
GPT-o4-mini achieve only 32.5\%, 42.2\%, and 45.8\% accuracy
respectively-performance gaps exceeding 29\% compared to human experts. Our
analysis exposes critical limitations in current models: over-reliance on
memorized disciplinary knowledge, excessive dependence on mathematical
formulations, and surface-level visual pattern matching rather than genuine
physical understanding. We provide in-depth analysis through fine-grained
statistics, detailed case studies, and multiple evaluation paradigms to
thoroughly examine physical reasoning capabilities. To ensure reproducibility,
we implement a compatible evaluation protocol based on widely-used toolkits
such as VLMEvalKit, enabling one-click evaluation.

</details>


### [126] [Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics](https://arxiv.org/abs/2505.15998)
*Thomas Michel, Marko Cvjetko, Gautier Hamon, Pierre-Yves Oudeyer, Clément Moulin-Frier*

**主要类别:** cs.AI

**概要:** 提出一种使用好奇心驱动的人工智能科学家自动发现Flow-Lenia系统级动态的方法。该方法通过适应内在动机目标探索过程（IMGEPs）来驱动多样化的Flow-Lenia环境探索，并在两个实验中展示了其揭示更多样化动态的能力。


<details>
  <summary>更多</summary>
  
**动机:** 研究Flow-Lenia中的自组织进化和生态系统动力学过程。

**方法:** 使用好奇心驱动的AI科学家和适应的IMGEPs来探索Flow-Lenia环境。

**结果:** 该方法在揭示比随机搜索更多的多样化动态方面表现出色，并且通过互动探索工具增强了人类与AI的合作工作流程。

**结论:** 该方法为理解其他可参数化的复杂系统的涌现集体属性提供了一个潜在适用的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Flow-Lenia+Universes+with+a+Curiosity-driven+AI+Scientist%3A+Discovering+Diverse+Ecosystem+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15998，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15998&send_immediately=true&force_search=false)

**原文摘要:** We present a method for the automated discovery of system-level dynamics in
Flow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and
parameter localization$-$using a curiosity-driven AI scientist. This method
aims to uncover processes leading to self-organization of evolutionary and
ecosystemic dynamics in CAs. We build on previous work which uses diversity
search algorithms in Lenia to find self-organized individual patterns, and
extend it to large environments that support distinct interacting patterns. We
adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive
exploration of diverse Flow-Lenia environments using simulation-wide metrics,
such as evolutionary activity, compression-based complexity, and multi-scale
entropy. We test our method in two experiments, showcasing its ability to
illuminate significantly more diverse dynamics compared to random search. We
show qualitative results illustrating how ecosystemic simulations enable
self-organization of complex collective behaviors not captured by previous
individual pattern search and analysis. We complement automated discovery with
an interactive exploration tool, creating an effective human-AI collaborative
workflow for scientific investigation. Though demonstrated specifically with
Flow-Lenia, this methodology provides a framework potentially applicable to
other parameterizable complex systems where understanding emergent collective
properties is of interest.

</details>


### [127] [Children's Mental Models of AI Reasoning: Implications for AI Literacy Education](https://arxiv.org/abs/2505.16031)
*Aayushi Dangol, Robert Wolfe, Runhua Zhao, JaeWon Kim, Trushaa Ramanan, Katie Davis, Julie A. Kientz*

**主要类别:** cs.AI

**概要:** 研究儿童对人工智能推理过程的概念化对于培养AI素养至关重要。通过两阶段方法（与8名儿童的合作设计会议和106名儿童（3-8年级）的实地研究），确定了三种AI推理模型：演绎、归纳和固有。发现年幼的孩子（3-5年级）通常认为AI的推理归因于固有智能，而大一点的孩子（6-8年级）则认识到AI是一个模式识别器。强调了在儿童理解AI推理方面出现的三个矛盾，并提出了支持AI课程设计和可解释AI工具设计的影响。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能推理能力的进步，特别是大型推理模型（LRMs）的出现，理解儿童如何概念化AI的推理过程变得至关重要。

**方法:** 采用两阶段方法：第一阶段与8名儿童进行合作设计会议，第二阶段与106名儿童（3-8年级）进行实地研究。

**结果:** 识别出三种AI推理模型：演绎、归纳和固有。发现年幼孩子（3-5年级）认为AI推理源于固有智能，而年长孩子（6-8年级）视AI为模式识别器。

**结论:** 强调了在儿童理解AI推理方面出现的三个矛盾，并提出了支持AI课程设计和可解释AI工具设计的影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Children%27s+Mental+Models+of+AI+Reasoning%3A+Implications+for+AI+Literacy+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16031，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16031&send_immediately=true&force_search=false)

**原文摘要:** As artificial intelligence (AI) advances in reasoning capabilities, most
recently with the emergence of Large Reasoning Models (LRMs), understanding how
children conceptualize AI's reasoning processes becomes critical for fostering
AI literacy. While one of the "Five Big Ideas" in AI education highlights
reasoning algorithms as central to AI decision-making, less is known about
children's mental models in this area. Through a two-phase approach, consisting
of a co-design session with 8 children followed by a field study with 106
children (grades 3-8), we identified three models of AI reasoning: Deductive,
Inductive, and Inherent. Our findings reveal that younger children (grades 3-5)
often attribute AI's reasoning to inherent intelligence, while older children
(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions
that surfaced in children's understanding of AI reasoning and conclude with
implications for scaffolding AI curricula and designing explainable AI tools.

</details>


### [128] [Causal LLM Routing: End-to-End Regret Minimization from Observational Data](https://arxiv.org/abs/2505.16037)
*Asterios Tsiourvas, Wei Sun, Georgia Perakis*

**主要类别:** cs.AI

**概要:** 提出了一种基于因果关系的端到端框架，用于从观测数据中学习路由策略，通过最小化决策后悔来优化模型选择，同时引入了两个替代目标函数，并扩展了处理异构成本偏好的方法。实验表明该方法在不同嵌入模型上达到了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法通常采用解耦策略，容易产生累积误差且依赖于全反馈数据，实际获取和维护成本高昂。

**方法:** 提出了一种因果端到端框架，通过最小化决策后悔来学习路由策略，引入了分类基础上的上限和softmax加权后悔近似作为替代目标函数，并通过区间条件架构扩展以处理异构成本偏好。

**结果:** 在公共基准测试中，所提方法优于现有基线，在不同嵌入模型上实现了最先进的性能。

**结论:** 所提出的因果端到端框架能够有效解决多语言模型选择中的性能与成本平衡问题，并展示了在多种场景下的优越性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+LLM+Routing%3A+End-to-End+Regret+Minimization+from+Observational+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16037&send_immediately=true&force_search=false)

**原文摘要:** LLM routing aims to select the most appropriate model for each query,
balancing competing performance metrics such as accuracy and cost across a pool
of language models. Prior approaches typically adopt a decoupled strategy,
where the metrics are first predicted and the model is then selected based on
these estimates. This setup is prone to compounding errors and often relies on
full-feedback data, where each query is evaluated by all candidate models,
which is costly to obtain and maintain in practice. In contrast, we learn from
observational data, which records only the outcome of the model actually
deployed. We propose a causal end-to-end framework that learns routing policies
by minimizing decision-making regret from observational data. To enable
efficient optimization, we introduce two theoretically grounded surrogate
objectives: a classification-based upper bound, and a softmax-weighted regret
approximation shown to recover the optimal policy at convergence. We further
extend our framework to handle heterogeneous cost preferences via an
interval-conditioned architecture. Experiments on public benchmarks show that
our method outperforms existing baselines, achieving state-of-the-art
performance across different embedding models.

</details>


### [129] [SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution](https://arxiv.org/abs/2505.16048)
*Philipp D. Siedler*

**主要类别:** cs.AI

**概要:** This paper introduces a new dataset for evaluating the physical and spatial reasoning abilities of large language models using topology optimization.


<details>
  <summary>更多</summary>
  
**动机:** To create a new way to evaluate the physical and spatial reasoning abilities of large language models.

**方法:** Providing large language models with conditions such as 2D boundary, applied forces and supports, and requiring them to reason about the resulting optimal material distribution.

**结果:** The dataset includes a variety of tasks that require understanding the flow of forces and the required material distribution under given constraints.

**结论:** The dataset targets the evaluation of spatial and physical reasoning abilities in 2D settings, offering a complementary perspective to traditional language and logic benchmarks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPhyR%3A+Spatial-Physical+Reasoning+Benchmark+on+Material+Distribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16048&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel dataset designed to benchmark the physical and spatial
reasoning capabilities of Large Language Models (LLM) based on topology
optimization, a method for computing optimal material distributions within a
design space under prescribed loads and supports. In this dataset, LLMs are
provided with conditions such as 2D boundary, applied forces and supports, and
must reason about the resulting optimal material distribution. The dataset
includes a variety of tasks, ranging from filling in masked regions within
partial structures to predicting complete material distributions. Solving these
tasks requires understanding the flow of forces and the required material
distribution under given constraints, without access to simulation tools or
explicit physical models, challenging models to reason about structural
stability and spatial organization. Our dataset targets the evaluation of
spatial and physical reasoning abilities in 2D settings, offering a
complementary perspective to traditional language and logic benchmarks.

</details>


### [130] [How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](https://arxiv.org/abs/2505.16067)
*Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang*

**主要类别:** cs.AI

**概要:** This paper studies how memory management affects the long-term performance of large language model agents.


<details>
  <summary>更多</summary>
  
**动机:** To understand how memory management impacts the behavior and long-term performance of LLM-based agents.

**方法:** Focuses on two fundamental memory operations: addition and deletion, conducting a systematic study on their impact on agent behavior.

**结果:** LLM agents exhibit an experience-following property, but face challenges like error propagation and misaligned experience replay. Combining selective addition and deletion strategies improves performance by 10%.

**结论:** Memory management plays a crucial role in LLM agent performance, with implications for designing robust memory components under various conditions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Memory+Management+Impacts+LLM+Agents%3A+An+Empirical+Study+of+Experience-Following+Behavior，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16067，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16067&send_immediately=true&force_search=false)

**原文摘要:** Memory is a critical component in large language model (LLM)-based agents,
enabling them to store and retrieve past executions to improve task performance
over time. In this paper, we conduct an empirical study on how memory
management choices impact the LLM agents' behavior, especially their long-term
performance. Specifically, we focus on two fundamental memory operations that
are widely used by many agent frameworks-addition, which incorporates new
experiences into the memory base, and deletion, which selectively removes past
experiences-to systematically study their impact on the agent behavior. Through
our quantitative analysis, we find that LLM agents display an
experience-following property: high similarity between a task input and the
input in a retrieved memory record often results in highly similar agent
outputs. Our analysis further reveals two significant challenges associated
with this property: error propagation, where inaccuracies in past experiences
compound and degrade future performance, and misaligned experience replay,
where outdated or irrelevant experiences negatively influence current tasks.
Through controlled experiments, we show that combining selective addition and
deletion strategies can help mitigate these negative effects, yielding an
average absolute performance gain of 10% compared to naive memory growth.
Furthermore, we highlight how memory management choices affect agents' behavior
under challenging conditions such as task distribution shifts and constrained
memory resources. Our findings offer insights into the behavioral dynamics of
LLM agent memory systems and provide practical guidance for designing memory
components that support robust, long-term agent performance. We also release
our code to facilitate further study.

</details>


### [131] [SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation](https://arxiv.org/abs/2505.16080)
*Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang*

**主要类别:** cs.AI

**概要:** 提出了一种新的跨域时空网络SynEVO，通过集体智能和模型进化提高跨域知识共享能力，并在实验中展示了其在跨域场景下具有42%的泛化能力提升。


<details>
  <summary>更多</summary>
  
**动机:** 当前的时空学习器通常从特定源数据训练独立模型，导致跨域之间的有限迁移性，即使相关任务也需要重新设计和训练。

**方法:** 受神经科学理论启发，提出一种基于交叉域集体智能的信息边界扩展方法，并设计了SynEVO网络，包括弹性公共容器和任务无关提取器来实现模型增长和特性解耦，以及自适应动态耦合器来决定是否将新样本组纳入公共容器。

**结果:** 实验表明SynEVO在跨域场景下的泛化能力最多提高了42%，并为知识转移和适应提供了神经人工智能的范例。

**结论:** SynEVO展示了跨域知识共享和模型进化在时空学习中的潜力，并为神经人工智能的发展提供了重要参考。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SynEVO%3A+A+neuro-inspired+spatiotemporal+evolutional+framework+for+cross-domain+adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16080&send_immediately=true&force_search=false)

**原文摘要:** Discovering regularities from spatiotemporal systems can benefit various
scientific and social planning. Current spatiotemporal learners usually train
an independent model from a specific source data that leads to limited
transferability among sources, where even correlated tasks requires new design
and training. The key towards increasing cross-domain knowledge is to enable
collective intelligence and model evolution. In this paper, inspired by
neuroscience theories, we theoretically derive the increased information
boundary via learning cross-domain collective intelligence and propose a
Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the
model independence and enables cross-domain knowledge to be shared and
aggregated. Specifically, we first re-order the sample groups to imitate the
human curriculum learning, and devise two complementary learners, elastic
common container and task-independent extractor to allow model growth and
task-wise commonality and personality disentanglement. Then an adaptive dynamic
coupler with a new difference metric determines whether the new sample group
should be incorporated into common container to achieve model evolution under
various domains. Experiments show that SynEVO improves the generalization
capacity by at most 42% under cross-domain scenarios and SynEVO provides a
paradigm of NeuroAI for knowledge transfer and adaptation.

</details>


### [132] [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org/abs/2505.16086)
*Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang*

**主要类别:** cs.AI

**概要:** 研究了基于角色的多智能体系统在软件开发任务中的优化方法。提出了一种两步优化管道，并探讨了不同优化设置对系统性能的影响。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型语言模型（LLM）驱动的多智能体系统在解决需要专家合作的复杂任务方面取得了显著进展，但其优化仍具有挑战性。

**方法:** 提出了一种两步优化管道：首先利用文本反馈识别表现不佳的代理及其失败解释，然后利用这些解释优化相关代理的系统提示。还研究了两种提示策略：单次提示优化和多次提示优化。

**结果:** 证明了所提出的优化方法对于处理在多种评估维度上评价的软件开发任务的有效性，并调查了不同的优化设置对多智能体系统群体行为的影响，为未来的开发提供了实用见解。

**结论:** 所提出的方法可以有效优化基于角色的多智能体系统在软件开发任务中的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+LLM-Based+Multi-Agent+System+with+Textual+Feedback%3A+A+Case+Study+on+Software+Development，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16086，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16086&send_immediately=true&force_search=false)

**原文摘要:** We have seen remarkable progress in large language models (LLMs) empowered
multi-agent systems solving complex tasks necessitating cooperation among
experts with diverse skills. However, optimizing LLM-based multi-agent systems
remains challenging. In this work, we perform an empirical case study on group
optimization of role-based multi-agent systems utilizing natural language
feedback for challenging software development tasks under various evaluation
dimensions. We propose a two-step agent prompts optimization pipeline:
identifying underperforming agents with their failure explanations utilizing
textual feedback and then optimizing system prompts of identified agents
utilizing failure explanations. We then study the impact of various
optimization settings on system performance with two comparison groups: online
against offline optimization and individual against group optimization. For
group optimization, we study two prompting strategies: one-pass and multi-pass
prompting optimizations. Overall, we demonstrate the effectiveness of our
optimization method for role-based multi-agent systems tackling software
development tasks evaluated on diverse evaluation dimensions, and we
investigate the impact of diverse optimization settings on group behaviors of
the multi-agent systems to provide practical insights for future development.

</details>


### [133] [Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance](https://arxiv.org/abs/2505.16090)
*Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg*

**主要类别:** cs.AI

**概要:** 截至2025年，生成式人工智能（GenAI）已成为跨行业生产力的核心工具。除了文本生成外，GenAI还在编码、数据分析和研究工作流程中发挥关键作用。大型语言模型（LLMs）的输出可靠性与准确性需要评估，特别是在如金融等高风险领域。虽然LLMs通常擅长识别日常语言中的情感倾向，但在财务披露的复杂语言中却常遇到困难。本文通过圣克拉拉微软实习项目，比较了多种LLMs在财务文本情感分析中的表现，并探索了提示工程技巧以提高结果准确性。


<details>
  <summary>更多</summary>
  
**动机:** 随着生成式人工智能的发展，尤其是在高风险领域如金融中的应用，评估其输出的可靠性和准确性变得尤为重要。然而，现有模型在处理复杂、战略模糊的语言时存在挑战。

**方法:** 本研究使用了Microsoft收益电话会议的转录文本，对Microsoft Copilot、OpenAI的ChatGPT、Google的Gemini以及传统的机器学习模型进行了基准测试。同时，还研究了提示工程技术以优化情感分析的结果。

**结果:** 研究发现，LLMs衍生的情感分析与市场情绪和股票走势之间存在一定的相关性，但模型输出的准确性仍有待提高。此外，开发了情感一致性可视化工具来评估情感与股票表现之间的关系，并分析了Microsoft各业务线的情感趋势，确定哪些部分对公司整体影响最大。

**结论:** 本研究强调了在金融领域使用生成式人工智能进行情感分析的潜力与限制，提出了改进方法，包括优化提示工程和技术调整，以增强模型在复杂金融环境下的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+AI+Read+Between+The+Lines%3F+Benchmarking+LLMs+On+Financial+Nuance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16090，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16090&send_immediately=true&force_search=false)

**原文摘要:** As of 2025, Generative Artificial Intelligence (GenAI) has become a central
tool for productivity across industries. Beyond text generation, GenAI now
plays a critical role in coding, data analysis, and research workflows. As
large language models (LLMs) continue to evolve, it is essential to assess the
reliability and accuracy of their outputs, especially in specialized,
high-stakes domains like finance. Most modern LLMs transform text into
numerical vectors, which are used in operations such as cosine similarity
searches to generate responses. However, this abstraction process can lead to
misinterpretation of emotional tone, particularly in nuanced financial
contexts. While LLMs generally excel at identifying sentiment in everyday
language, these models often struggle with the nuanced, strategically ambiguous
language found in earnings call transcripts. Financial disclosures frequently
embed sentiment in hedged statements, forward-looking language, and
industry-specific jargon, making it difficult even for human analysts to
interpret consistently, let alone AI models. This paper presents findings from
the Santa Clara Microsoft Practicum Project, led by Professor Charlie
Goldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's
ChatGPT, Google's Gemini, and traditional machine learning models for sentiment
analysis of financial text. Using Microsoft earnings call transcripts, the
analysis assesses how well LLM-derived sentiment correlates with market
sentiment and stock movements and evaluates the accuracy of model outputs.
Prompt engineering techniques are also examined to improve sentiment analysis
results. Visualizations of sentiment consistency are developed to evaluate
alignment between tone and stock performance, with sentiment trends analyzed
across Microsoft's lines of business to determine which segments exert the
greatest influence.

</details>


### [134] [TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials](https://arxiv.org/abs/2505.16097)
*Zifeng Wang, Qiao Jin, Jiacheng Lin, Junyi Gao, Jathurshan Pradeepkumar, Pengcheng Jiang, Benjamin Danek, Zhiyong Lu, Jimeng Sun*

**主要类别:** cs.AI

**概要:** Developing AI for vertical domains like clinical trials needs good data. This paper introduces TrialPanorama, a big database with 1.6 million clinical trial records linked to biomedical ontologies. It can help with various clinical trial tasks. Experiments show general LLMs aren't enough for these tasks.


<details>
  <summary>更多</summary>
  
**动机:** To create a solid data foundation for training and evaluating AI in vertical domains, especially clinical trials.

**方法:** Introduce TrialPanorama, a large-scale database with 1.6 million clinical trial records from 15 global sources, linked to biomedical ontologies.

**结果:** The database supports benchmark tasks in two categories: systematic review and trial design. Experiments with five state-of-the-art LLMs show they have limited zero-shot capability for high-stakes clinical trial workflows.

**结论:** TrialPanorama and the benchmark are released to promote AI research in clinical trials.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TrialPanorama%3A+Database+and+Benchmark+for+Systematic+Review+and+Design+of+Clinical+Trials，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16097，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16097&send_immediately=true&force_search=false)

**原文摘要:** Developing artificial intelligence (AI) for vertical domains requires a solid
data foundation for both training and evaluation. In this work, we introduce
TrialPanorama, a large-scale, structured database comprising 1,657,476 clinical
trial records aggregated from 15 global sources. The database captures key
aspects of trial design and execution, including trial setups, interventions,
conditions, biomarkers, and outcomes, and links them to standard biomedical
ontologies such as DrugBank and MedDRA. This structured and ontology-grounded
design enables TrialPanorama to serve as a unified, extensible resource for a
wide range of clinical trial tasks, including trial planning, design, and
summarization. To demonstrate its utility, we derive a suite of benchmark tasks
directly from the TrialPanorama database. The benchmark spans eight tasks
across two categories: three for systematic review (study search, study
screening, and evidence summarization) and five for trial design (arm design,
eligibility criteria, endpoint selection, sample size estimation, and trial
completion assessment). The experiments using five state-of-the-art large
language models (LLMs) show that while general-purpose LLMs exhibit some
zero-shot capability, their performance is still inadequate for high-stakes
clinical trial workflows. We release TrialPanorama database and the benchmark
to facilitate further research on AI for clinical trials.

</details>


### [135] [BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research](https://arxiv.org/abs/2505.16100)
*Zifeng Wang, Benjamin Danek, Jimeng Sun*

**主要类别:** cs.AI

**概要:** This work introduces BioDSA-1K, a benchmark for AI agents to validate biomedical hypotheses based on real-world data.


<details>
  <summary>更多</summary>
  
**动机:** To address the difficulty of AI agents in validating scientific hypotheses due to complex real-world data analysis and evidence interpretation.

**方法:** Curating 1,029 hypothesis-centric tasks paired with 1,177 analysis plans from over 300 biomedical studies.

**结果:** The benchmark evaluates AI agents along four axes: hypothesis decision accuracy, evidence-conclusion alignment, reasoning correctness, and code executability, including non-verifiable hypotheses.

**结论:** BioDSA-1K serves as a foundation for developing generalizable, trustworthy AI agents for biomedical discovery.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioDSA-1K%3A+Benchmarking+Data+Science+Agents+for+Biomedical+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16100&send_immediately=true&force_search=false)

**原文摘要:** Validating scientific hypotheses is a central challenge in biomedical
research, and remains difficult for artificial intelligence (AI) agents due to
the complexity of real-world data analysis and evidence interpretation. In this
work, we present BioDSA-1K, a benchmark designed to evaluate AI agents on
realistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K
consists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,
curated from over 300 published biomedical studies to reflect the structure and
reasoning found in authentic research workflows. Each task includes a
structured hypothesis derived from the original study's conclusions, expressed
in the affirmative to reflect the language of scientific reporting, and one or
more pieces of supporting evidence grounded in empirical data tables. While
these hypotheses mirror published claims, they remain testable using standard
statistical or machine learning methods. The benchmark enables evaluation along
four axes: (1) hypothesis decision accuracy, (2) alignment between evidence and
conclusion, (3) correctness of the reasoning process, and (4) executability of
the AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable
hypotheses: cases where the available data are insufficient to support or
refute a claim, reflecting a common yet underexplored scenario in real-world
science. We propose BioDSA-1K as a foundation for building and evaluating
generalizable, trustworthy AI agents for biomedical discovery.

</details>


### [136] [Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language](https://arxiv.org/abs/2505.16114)
*Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia*

**主要类别:** cs.AI

**概要:** 提出了一种结合逻辑编程和大语言模型的新框架Logot，用于解决需要精确推理的复杂自然语言谜题，并在网格和动态动作谜题上取得了接近完美的准确率。


<details>
  <summary>更多</summary>
  
**动机:** 现有大型语言模型在需要精确推理和全面搜索的复杂自然语言谜题中表现不佳。

**方法:** 提出Logot框架，通过LLMs将谜题规则和状态转换为ASP，再由ASP解释器推断解决方案。

**结果:** 在多种网格和涉及动作的动态谜题上实现了近完美的准确性。

**结论:** 该研究展示了结合逻辑编程与大语言模型的有效性，为解决复杂自然语言问题提供了新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Logic-of-Thought%3A+Empowering+Large+Language+Models+with+Logic+Programs+for+Solving+Puzzles+in+Natural+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16114&send_immediately=true&force_search=false)

**原文摘要:** Solving puzzles in natural language poses a long-standing challenge in AI.
While large language models (LLMs) have recently shown impressive capabilities
in a variety of tasks, they continue to struggle with complex puzzles that
demand precise reasoning and exhaustive search. In this paper, we propose
Logic-of-Thought (Logot), a novel framework that bridges LLMs with logic
programming to address this problem. Our method leverages LLMs to translate
puzzle rules and states into answer set programs (ASPs), the solution of which
are then accurately and efficiently inferred by an ASP interpreter. This hybrid
approach combines the natural language understanding of LLMs with the precise
reasoning capabilities of logic programs. We evaluate our method on various
grid puzzles and dynamic puzzles involving actions, demonstrating near-perfect
accuracy across all tasks. Our code and data are available at:
https://github.com/naiqili/Logic-of-Thought.

</details>


### [137] [LLM-Powered AI Agent Systems and Their Applications in Industry](https://arxiv.org/abs/2505.16120)
*Guannan Liang, Qianqian Tong*

**主要类别:** cs.AI

**概要:** 本文综述了从传统基于规则的智能体到当前大型语言模型驱动的智能体的发展历程，并探讨了其面临的挑战及可能的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 研究大型语言模型对智能体系统的影响及其应用领域。

**方法:** 文献综述与分类方法，将智能体系统分为软件型、实体型和自适应混合型，并讨论了其在多个领域的应用。同时分析了大型语言模型驱动智能体面临的主要问题及其应对策略。

**结果:** 总结了大型语言模型对智能体系统的积极影响，如增强灵活性、跨域推理能力和自然语言交互等，并指出多模态LLMs使智能体能够处理多种数据形式。

**结论:** 尽管LLM-powered智能体带来了诸多优势，但其高推理延迟、输出不确定性等问题亟待解决，未来需要完善评估标准并加强安全性保护。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Powered+AI+Agent+Systems+and+Their+Applications+in+Industry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16120&send_immediately=true&force_search=false)

**原文摘要:** The emergence of Large Language Models (LLMs) has reshaped agent systems.
Unlike traditional rule-based agents with limited task scope, LLM-powered
agents offer greater flexibility, cross-domain reasoning, and natural language
interaction. Moreover, with the integration of multi-modal LLMs, current agent
systems are highly capable of processing diverse data modalities, including
text, images, audio, and structured tabular data, enabling richer and more
adaptive real-world behavior. This paper comprehensively examines the evolution
of agent systems from the pre-LLM era to current LLM-powered architectures. We
categorize agent systems into software-based, physical, and adaptive hybrid
systems, highlighting applications across customer service, software
development, manufacturing automation, personalized education, financial
trading, and healthcare. We further discuss the primary challenges posed by
LLM-powered agents, including high inference latency, output uncertainty, lack
of evaluation metrics, and security vulnerabilities, and propose potential
solutions to mitigate these concerns.

</details>


### [138] [Sudoku-Bench: Evaluating creative reasoning with Sudoku variants](https://arxiv.org/abs/2505.16135)
*Jeffrey Seely, Yuki Imajuku, Tianyu Zhao, Edoardo Cetin, Llion Jones*

**主要类别:** cs.AI

**概要:** 提出Sudoku-Bench基准测试，评估大型语言模型的创造性多步逻辑推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有基准测试常奖励模式记忆而非创造力，因此需要新的方法来评估创意推理。

**方法:** 创建一个包含挑战性和非常规数独变体的基准测试。

**结果:** 最先进的LLMs在没有帮助的情况下只能解决不到15%的谜题。

**结论:** Sudoku-Bench展示了提升长期战略推理能力的重大机会。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sudoku-Bench%3A+Evaluating+creative+reasoning+with+Sudoku+variants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16135&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning benchmarks for large language models (LLMs) frequently
fail to capture authentic creativity, often rewarding memorization of
previously observed patterns. We address this shortcoming with Sudoku-Bench, a
curated benchmark of challenging and unconventional Sudoku variants
specifically selected to evaluate creative, multi-step logical reasoning.
Sudoku variants form an unusually effective domain for reasoning research: each
puzzle introduces unique or subtly interacting constraints, making memorization
infeasible and requiring solvers to identify novel logical breakthroughs
(``break-ins''). Despite their diversity, Sudoku variants maintain a common and
compact structure, enabling clear and consistent evaluation. Sudoku-Bench
includes a carefully chosen puzzle set, a standardized text-based puzzle
representation, and flexible tools compatible with thousands of publicly
available puzzles -- making it easy to extend into a general research
environment. Baseline experiments show that state-of-the-art LLMs solve fewer
than 15\% of puzzles unaided, highlighting significant opportunities to advance
long-horizon, strategic reasoning capabilities.

</details>


### [139] [Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value](https://arxiv.org/abs/2505.16147)
*Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种基于机器无学习的新框架Unlearning Shapley，用于高效评估数据价值，支持全量和部分数据估值，实验表明其在准确性和计算效率上均优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型模型的发展，需要高效的评估个体数据贡献的方法来量化数据提供者的贡献。

**方法:** 提出Unlearning Shapley框架，通过从预训练模型中无学习目标数据，并在可到达的测试集上测量性能变化，利用蒙特卡洛采样计算Shapley值，避免了重新训练并消除了对完整数据的依赖。

**结果:** 该方法在基准数据集和大规模文本语料库上的实验显示，其准确性与最先进的方法相当，但计算开销降低了几个数量级。进一步分析证实了估计值与数据子集真实影响之间的强相关性。

**结论:** 这项工作弥合了数据估值理论与实际部署之间的差距，为现代AI生态系统提供了可扩展且符合隐私保护的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Losing+is+for+Cherishing%3A+Data+Valuation+Based+on+Machine+Unlearning+and+Shapley+Value，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16147，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16147&send_immediately=true&force_search=false)

**原文摘要:** The proliferation of large models has intensified the need for efficient data
valuation methods to quantify the contribution of individual data providers.
Traditional approaches, such as game-theory-based Shapley value and
influence-function-based techniques, face prohibitive computational costs or
require access to full data and model training details, making them hardly
achieve partial data valuation. To address this, we propose Unlearning Shapley,
a novel framework that leverages machine unlearning to estimate data values
efficiently. By unlearning target data from a pretrained model and measuring
performance shifts on a reachable test set, our method computes Shapley values
via Monte Carlo sampling, avoiding retraining and eliminating dependence on
full data. Crucially, Unlearning Shapley supports both full and partial data
valuation, making it scalable for large models (e.g., LLMs) and practical for
data markets. Experiments on benchmark datasets and large-scale text corpora
demonstrate that our approach matches the accuracy of state-of-the-art methods
while reducing computational overhead by orders of magnitude. Further analysis
confirms a strong correlation between estimated values and the true impact of
data subsets, validating its reliability in real-world scenarios. This work
bridges the gap between data valuation theory and practical deployment,
offering a scalable, privacy-compliant solution for modern AI ecosystems.

</details>


### [140] [Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning](https://arxiv.org/abs/2505.16176)
*Jun Rao, Xuebo Liu, Hexuan Deng, Zepeng Lin, Zixiong Yu, Jiansheng Wei, Xiaojun Meng, Min Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种名为SAI-DPO的新算法，该算法通过实时评估模型在不同训练阶段的推理能力来动态选择训练数据。实验证明了其优于传统的静态方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数据选择方法依赖于预先定义的静态指标，缺乏适应连续训练过程的能力，尤其在动态训练和在线强化学习框架下表现不佳。

**方法:** SAI-DPO算法通过整合实时模型性能反馈，根据模型的强弱点调整数据选择策略。

**结果:** 在三个最先进的模型和八个数学推理基准测试中，SAI-DPO提升了平均21.3个百分点的表现，特别是在AIME24和AMC23上分别提升了10和15个百分点。

**结论:** 动态、模型自适应的数据选择比静态、外部定义的策略更优越，有助于提升推理任务的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Sampling+that+Adapts%3A+Iterative+DPO+for+Self-Aware+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16176&send_immediately=true&force_search=false)

**原文摘要:** In the realm of data selection for reasoning tasks, existing approaches
predominantly rely on externally predefined static metrics such as difficulty
and diversity, which are often designed for supervised fine-tuning (SFT) and
lack adaptability to continuous training processes. A critical limitation of
these methods is their inability to dynamically align with the evolving
capabilities of models during online training, a gap that becomes increasingly
pronounced with the rise of dynamic training paradigms and online reinforcement
learning (RL) frameworks (e.g., R1 models). To address this, we introduce
SAI-DPO, an algorithm that dynamically selects training data by continuously
assessing a model's stage-specific reasoning abilities across different
training phases. By integrating real-time model performance feedback, SAI-DPO
adaptively adapts data selection to the evolving strengths and weaknesses of
the model, thus enhancing both data utilization efficiency and final task
performance. Extensive experiments on three state-of-the-art models and eight
mathematical reasoning benchmarks, including challenging competition-level
datasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average
performance boost of up to 21.3 percentage points, with particularly notable
improvements of 10 and 15 points on AIME24 and AMC23, respectively. These
results highlight the superiority of dynamic, model-adaptive data selection
over static, externally defined strategies in advancing reasoning.

</details>


### [141] [SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning](https://arxiv.org/abs/2505.16186)
*Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang*

**主要类别:** cs.AI

**概要:** Large Reasoning Models (LRMs) have improved complex task performance but present safety risks. This paper identifies a 'safety aha moment' in the key sentence of LRM responses and proposes SafeKey, which includes a Dual-Path Safety Head and Query-Mask Modeling to improve safety generalization and reduce harmfulness.


<details>
  <summary>更多</summary>
  
**动机:** To address the safety risks and lack of generalization to unseen harmful prompts in SFT-aligned LRMs.

**方法:** Introduce SafeKey with two objectives: a Dual-Path Safety Head and Query-Mask Modeling.

**结果:** Significantly improves safety generalization to various jailbreak attacks and out-of-distribution harmful prompts, reducing harmfulness rate by 9.6%.

**结论:** SafeKey reshapes internal attention and hidden representation quality, enhancing LRM safety without sacrificing general abilities.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SafeKey%3A+Amplifying+Aha-Moment+Insights+for+Safety+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16186&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) introduce a new generation paradigm of
explicitly reasoning before answering, leading to remarkable improvements in
complex tasks. However, they pose great safety risks against harmful queries
and adversarial attacks. While recent mainstream safety efforts on LRMs,
supervised fine-tuning (SFT), improve safety performance, we find that
SFT-aligned models struggle to generalize to unseen jailbreak prompts. After
thorough investigation of LRMs' generation, we identify a safety aha moment
that can activate safety reasoning and lead to a safe response. This aha moment
typically appears in the `key sentence', which follows models' query
understanding process and can indicate whether the model will proceed safely.
Based on these insights, we propose SafeKey, including two complementary
objectives to better activate the safety aha moment in the key sentence: (1) a
Dual-Path Safety Head to enhance the safety signal in the model's internal
representations before the key sentence, and (2) a Query-Mask Modeling
objective to improve the models' attention on its query understanding, which
has important safety hints. Experiments across multiple safety benchmarks
demonstrate that our methods significantly improve safety generalization to a
wide range of jailbreak attacks and out-of-distribution harmful prompts,
lowering the average harmfulness rate by 9.6\%, while maintaining general
abilities. Our analysis reveals how SafeKey enhances safety by reshaping
internal attention and improving the quality of hidden representations.

</details>


### [142] [Velocity Completion Task and Method for Event-based Player Positional Data in Soccer](https://arxiv.org/abs/2505.16199)
*Rikuhei Umemoto, Keisuke Fujii*

**主要类别:** cs.AI

**概要:** 提出一种新方法，利用基于事件的位置数据同时完成所有运动员的速度计算，改善团队运动系统分析。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于事件的数据缺乏连续的时间信息，限制了动态分析深度。

**方法:** 仅使用基于事件的位置数据来完成速度计算的方法。

**结果:** 神经网络方法在速度完成误差上优于规则方法，并且得到的空间评估结果更接近完整跟踪数据。

**结论:** 该方法有潜力提升团队运动系统的分析能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Velocity+Completion+Task+and+Method+for+Event-based+Player+Positional+Data+in+Soccer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16199，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16199&send_immediately=true&force_search=false)

**原文摘要:** In many real-world complex systems, the behavior can be observed as a
collection of discrete events generated by multiple interacting agents.
Analyzing the dynamics of these multi-agent systems, especially team sports,
often relies on understanding the movement and interactions of individual
agents. However, while providing valuable snapshots, event-based positional
data typically lacks the continuous temporal information needed to directly
calculate crucial properties such as velocity. This absence severely limits the
depth of dynamic analysis, preventing a comprehensive understanding of
individual agent behaviors and emergent team strategies. To address this
challenge, we propose a new method to simultaneously complete the velocity of
all agents using only the event-based positional data from team sports. Based
on this completed velocity information, we investigate the applicability of
existing team sports analysis and evaluation methods. Experiments using soccer
event data demonstrate that neural network-based approaches outperformed
rule-based methods regarding velocity completion error, considering the
underlying temporal dependencies and graph structure of player-to-player or
player-to-ball interaction. Moreover, the space evaluation results obtained
using the completed velocity are closer to those derived from complete tracking
data, highlighting our method's potential for enhanced team sports system
analysis.

</details>


### [143] [LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead](https://arxiv.org/abs/2505.16221)
*Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin*

**主要类别:** cs.AI

**概要:** LightRouter is a novel framework for selecting and integrating a subset of LLMs to optimize both task performance and cost efficiency.


<details>
  <summary>更多</summary>
  
**动机:** Identifying the most suitable LLMs for specific tasks is challenging due to differences in cost, performance, and computational demands.

**方法:** LightRouter leverages an adaptive selection mechanism and effective integration strategy to combine outputs of selected models.

**结果:** LightRouter matches or outperforms ensemble baselines and reduces inference costs by up to 27%.

**结论:** This work provides a practical approach for efficient LLM selection and valuable insights into optimal strategies for model combination.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LightRouter%3A+Towards+Efficient+LLM+Collaboration+with+Minimal+Overhead，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16221，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16221&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of large language models has unlocked remarkable
capabilities across a diverse array of natural language processing tasks.
However, the considerable differences among available LLMs-in terms of cost,
performance, and computational demands-pose significant challenges for users
aiming to identify the most suitable model for specific tasks. In this work, we
present LightRouter, a novel framework designed to systematically select and
integrate a small subset of LLMs from a larger pool, with the objective of
jointly optimizing both task performance and cost efficiency. LightRouter
leverages an adaptive selection mechanism to identify models that require only
a minimal number of boot tokens, thereby reducing costs, and further employs an
effective integration strategy to combine their outputs. Extensive experiments
across multiple benchmarks demonstrate that LightRouter matches or outperforms
widely-used ensemble baselines, achieving up to a 25% improvement in accuracy.
Compared with leading high-performing models, LightRouter achieves comparable
performance while reducing inference costs by up to 27%. Importantly, our
framework operates without any prior knowledge of individual models and relies
exclusively on inexpensive, lightweight models. This work introduces a
practical approach for efficient LLM selection and provides valuable insights
into optimal strategies for model combination.

</details>


### [144] [MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network](https://arxiv.org/abs/2505.16223)
*Sangyong Lee, Subo Hwang, Dohoon Kim*

**主要类别:** cs.AI

**概要:** 提出了一种新的模型无关异常检测框架MADCluster，利用自监督聚类解决现有深度学习方法中的'超球坍塌'问题，并通过新提出的'单向自适应损失'提高表达能力和聚类效果。实验表明，MADCluster在多种架构下都能提升模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 解决现有深度学习方法中的'超球坍塌'问题，提高异常检测的表达能力和聚类效果。

**方法:** 提出MADCluster框架，包括Base Embedder、Cluster Distance Mapping和Sequence-wise Clustering三个主要组件，并引入新'单向自适应损失'。

**结果:** 在四个时间序列基准数据集上的实验表明，MADCluster能提升比较模型的整体性能。

**结论:** MADCluster的兼容性展示了其在各种架构下增强模型性能的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MADCluster%3A+Model-agnostic+Anomaly+Detection+with+Self-supervised+Clustering+Network，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16223&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose MADCluster, a novel model-agnostic anomaly
detection framework utilizing self-supervised clustering. MADCluster is
applicable to various deep learning architectures and addresses the
'hypersphere collapse' problem inherent in existing deep learning-based anomaly
detection methods. The core idea is to cluster normal pattern data into a
'single cluster' while simultaneously learning the cluster center and mapping
data close to this center. Also, to improve expressiveness and enable effective
single clustering, we propose a new 'One-directed Adaptive loss'. The
optimization of this loss is mathematically proven. MADCluster consists of
three main components: Base Embedder capturing high-dimensional temporal
dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous
center updates. Its model-agnostic characteristics are achieved by applying
various architectures to the Base Embedder. Experiments on four time series
benchmark datasets demonstrate that applying MADCluster improves the overall
performance of comparative models. In conclusion, the compatibility of
MADCluster shows potential for enhancing model performance across various
architectures.

</details>


### [145] [MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning](https://arxiv.org/abs/2505.16225)
*Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen*

**主要类别:** cs.AI

**概要:** 提出了一种名为MAPLE的新框架，通过伪标记样本提高大规模语言模型在上下文学习中的表现，尤其在数据标注成本高的情况下表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 解决大规模语言模型在多示例上下文学习中因高成本获取大量标注数据而受到限制的问题。

**方法:** 提出MAPLE框架，首先确定有影响力的未标记样本并进行伪标记，然后根据每个测试查询自适应选择这些伪标记样本作为输入。

**结果:** 实验表明MAPLE框架在真实世界的数据集上有效，提升了LLM的适应性和性能，且无需显著增加标注成本。

**结论:** MAPLE展示了其在有限标注数据下增强LLM适应性和性能的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAPLE%3A+Many-Shot+Adaptive+Pseudo-Labeling+for+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16225&send_immediately=true&force_search=false)

**原文摘要:** In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle
diverse tasks by incorporating multiple input-output examples, known as
demonstrations, into the input of LLMs. More recently, advancements in the
expanded context windows of LLMs have led to many-shot ICL, which uses hundreds
of demonstrations and outperforms few-shot ICL, which relies on fewer examples.
However, this approach is often hindered by the high cost of obtaining large
amounts of labeled data. To address this challenge, we propose Many-Shot
Adaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL
framework that utilizes pseudo-labeled samples to compensate for the lack of
label information. We first identify a subset of impactful unlabeled samples
and perform pseudo-labeling on them by querying LLMs. These pseudo-labeled
samples are then adaptively selected and tailored to each test query as input
to improve the performance of many-shot ICL, without significant labeling
costs. Extensive experiments on real-world datasets demonstrate the
effectiveness of our framework, showcasing its ability to enhance LLM
adaptability and performance with limited labeled data.

</details>


### [146] [How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance](https://arxiv.org/abs/2505.16276)
*Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel*

**主要类别:** cs.AI

**概要:** This study evaluates 26 open LLMs using the LLM-KG-Bench framework to analyze their performance and cost-effectiveness in knowledge graph engineering tasks.


<details>
  <summary>更多</summary>
  
**动机:** To investigate the relationship between model size and performance/cost in large language models for knowledge graph engineering tasks.

**方法:** Using the LLM-KG-Bench framework to compare 26 open LLMs and analyze their capabilities in understanding and producing knowledge graphs and queries.

**结果:** Model size scaling laws generally apply to KGE tasks, but there are exceptions where larger models do not improve performance significantly, suggesting smaller models can be more cost-effective. Some models within the same family perform better at different sizes.

**结论:** Considering both performance and cost, it is recommended to test multiple sizes within the same model family to find the most cost-effective option.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+do+Scaling+Laws+Apply+to+Knowledge+Graph+Engineering+Tasks%3F+The+Impact+of+Model+Size+on+Large+Language+Model+Performance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16276，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16276&send_immediately=true&force_search=false)

**原文摘要:** When using Large Language Models (LLMs) to support Knowledge Graph
Engineering (KGE), one of the first indications when searching for an
appropriate model is its size. According to the scaling laws, larger models
typically show higher capabilities. However, in practice, resource costs are
also an important factor and thus it makes sense to consider the ratio between
model performance and costs. The LLM-KG-Bench framework enables the comparison
of LLMs in the context of KGE tasks and assesses their capabilities of
understanding and producing KGs and KG queries. Based on a dataset created in
an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the
model size scaling laws specific to KGE tasks. In our analyses, we assess how
benchmark scores evolve between different model size categories. Additionally,
we inspect how the general score development of single models and families of
models correlates to their size. Our analyses revealed that, with a few
exceptions, the model size scaling laws generally also apply to the selected
KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,
the task performance did not change much between a model and the next larger
model. In these cases, smaller models could be considered to achieve high
cost-effectiveness. Regarding models of the same family, sometimes larger
models performed worse than smaller models of the same family. These effects
occurred only locally. Hence it is advisable to additionally test the next
smallest and largest model of the same family.

</details>


### [147] [No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](https://arxiv.org/abs/2505.16288)
*Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning*

**主要类别:** cs.AI

**概要:** 提出了一种新的框架II-KEA，它结合了个性化知识库和代理LLMs，提高了深度学习模型在电子健康记录中的解释性和交互性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度学习模型虽然在诊断预测方面准确率高，但缺乏临床医生重视的解释性和交互性。

**方法:** 提出了一种名为II-KEA的知识增强型代理驱动因果发现框架，该框架集成了个性化知识数据库和代理LLMs。

**结果:** II-KEA在MIMIC-III和MIMIC-IV上的案例研究中取得了良好的成果，并且在解释性和交互性方面表现优异。

**结论:** II-KEA在MIMIC-III和MIMIC-IV上表现出色，具有增强的解释性和交互性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是No+Black+Boxes%3A+Interpretable+and+Interactable+Predictive+Healthcare+with+Knowledge-Enhanced+Agentic+Causal+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16288，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16288&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models trained on extensive Electronic Health Records (EHR)
data have achieved high accuracy in diagnosis prediction, offering the
potential to assist clinicians in decision-making and treatment planning.
However, these models lack two crucial features that clinicians highly value:
interpretability and interactivity. The ``black-box'' nature of these models
makes it difficult for clinicians to understand the reasoning behind
predictions, limiting their ability to make informed decisions. Additionally,
the absence of interactive mechanisms prevents clinicians from incorporating
their own knowledge and experience into the decision-making process. To address
these limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal
discovery framework that integrates personalized knowledge databases and
agentic LLMs. II-KEA enhances interpretability through explicit reasoning and
causal analysis, while also improving interactivity by allowing clinicians to
inject their knowledge and experience through customized knowledge bases and
prompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating
superior performance along with enhanced interpretability and interactivity, as
evidenced by its strong results from extensive case studies.

</details>


### [148] [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org/abs/2505.16312)
*Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian*

**主要类别:** cs.AI

**概要:** EquivPruner is proposed to reduce token consumption in LLMs by pruning equivalent actions during reasoning search.


<details>
  <summary>更多</summary>
  
**动机:** Current LLMs suffer from massive token consumption due to redundant exploration of semantically equivalent steps, especially in domain-specific contexts like mathematical reasoning.

**方法:** Proposes EquivPruner to prune semantically equivalent actions during LLM reasoning search and introduces MathEquiv dataset for training an equivalence detector.

**结果:** EquivPruner significantly reduces token consumption and improves reasoning accuracy across various models and tasks.

**结论:** EquivPruner effectively reduces token consumption and improves reasoning efficiency and accuracy.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EquivPruner%3A+Boosting+Efficiency+and+Quality+in+LLM-Based+Search+via+Action+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16312，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16312&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) excel at complex reasoning through search
algorithms, yet current strategies often suffer from massive token consumption
due to redundant exploration of semantically equivalent steps. Existing
semantic similarity methods struggle to accurately identify such equivalence in
domain-specific contexts like mathematical reasoning. To address this, we
propose EquivPruner, a simple yet effective approach that identifies and prunes
semantically equivalent actions during LLM reasoning search. We also introduce
MathEquiv, the first dataset we created for mathematical statement equivalence,
which enables the training of a lightweight equivalence detector. Extensive
experiments across various models and tasks demonstrate that EquivPruner
significantly reduces token consumption, improving searching efficiency and
often bolstering reasoning accuracy. For instance, when applied to
Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by
48.1\% while also improving accuracy. Our code is available at
https://github.com/Lolo1222/EquivPruner.

</details>


### [149] [Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2505.16315)
*Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang*

**主要类别:** cs.AI

**概要:** This paper introduces ACPO, a reinforcement learning framework inspired by dual process theory to reduce overthinking in large reasoning models by making their cognitive processes transparent and adaptively switching systems.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of overthinking in large reasoning models which generate redundant content irrespective of task difficulty.

**方法:** Adaptive Cognition Policy Optimization (ACPO) which includes system-aware reasoning tokens for transparency and online difficulty estimation with token length budget for adaptive system switch.

**结果:** Reduction in redundant reasoning and adaptive adjustment of cognitive allocation based on task complexity leading to efficient hybrid reasoning.

**结论:** ACPO effectively enhances efficiency in large reasoning models by reducing unnecessary computations through adaptive cognitive allocation and dynamic system switch.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incentivizing+Dual+Process+Thinking+for+Efficient+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16315&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models (LRMs) have demonstrated strong performance on complex
reasoning tasks, but often suffer from overthinking, generating redundant
content regardless of task difficulty. Inspired by the dual process theory in
cognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a
reinforcement learning framework that enables LRMs to achieve efficient
reasoning through adaptive cognitive allocation and dynamic system switch. ACPO
incorporates two key components: (1) introducing system-aware reasoning tokens
to explicitly represent the thinking modes thereby making the model's cognitive
process transparent, and (2) integrating online difficulty estimation and token
length budget to guide adaptive system switch and reasoning during
reinforcement learning. To this end, we propose a two-stage training strategy.
The first stage begins with supervised fine-tuning to cold start the model,
enabling it to generate reasoning paths with explicit thinking modes. In the
second stage, we apply ACPO to further enhance adaptive system switch for
difficulty-aware reasoning. Experimental results demonstrate that ACPO
effectively reduces redundant reasoning while adaptively adjusting cognitive
allocation based on task complexity, achieving efficient hybrid reasoning.

</details>


### [150] [Serious Games: Human-AI Interaction, Evolution, and Coevolution](https://arxiv.org/abs/2505.16388)
*Nandini Doreswamy, Louise Horstmanshof*

**主要类别:** cs.AI

**概要:** This study examines three Evolutionary Game Theory (EGT) models (Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition) relevant to human-AI interaction, evolution, and coevolution, showing their potential to predict human-AI evolutionary dynamics.


<details>
  <summary>更多</summary>
  
**动机:** To explore how EGT models can help predict the potential evolutionary equilibrium of humans and AI and understand their interaction, evolution, and coevolution.

**方法:** Analyze and discuss the Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition within the context of human-AI interaction.

**结果:** The selected EGT models suggest possibilities for balanced coevolution, cognitive coevolution, and strategic coevolution between humans and AI.

**结论:** EGT provides a framework to understand human-AI evolutionary dynamics, but future research should consider expanding beyond EGT and examining ethical and cognitive implications.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Serious+Games%3A+Human-AI+Interaction%2C+Evolution%2C+and+Coevolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16388，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16388&send_immediately=true&force_search=false)

**原文摘要:** The serious games between humans and AI have only just begun. Evolutionary
Game Theory (EGT) models the competitive and cooperative strategies of
biological entities. EGT could help predict the potential evolutionary
equilibrium of humans and AI. The objective of this work was to examine some of
the EGT models relevant to human-AI interaction, evolution, and coevolution. Of
thirteen EGT models considered, three were examined: the Hawk-Dove Game,
Iterated Prisoner's Dilemma, and the War of Attrition. This selection was based
on the widespread acceptance and clear relevance of these models to potential
human-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove
Game predicts balanced mixed-strategy equilibria based on the costs of
conflict. It also shows the potential for balanced coevolution rather than
dominance. Iterated Prisoner's Dilemma suggests that repeated interaction may
lead to cognitive coevolution. It demonstrates how memory and reciprocity can
lead to cooperation. The War of Attrition suggests that competition for
resources may result in strategic coevolution, asymmetric equilibria, and
conventions on sharing resources. Therefore, EGT may provide a suitable
framework to understand and predict the human-AI evolutionary dynamic. However,
future research could extend beyond EGT and explore additional frameworks,
empirical validation methods, and interdisciplinary perspectives. AI is being
shaped by human input and is evolving in response to it. So too,
neuroplasticity allows the human brain to grow and evolve in response to
stimuli. If humans and AI converge in future, what might be the result of human
neuroplasticity combined with an ever-evolving AI? Future research should be
mindful of the ethical and cognitive implications of human-AI interaction,
evolution, and coevolution.

</details>


### [151] [FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS](https://arxiv.org/abs/2505.16409)
*Chaeeun Kim, Seungone Kim*

**主要类别:** cs.AI

**概要:** 本文提出了一种新的框架FREESON，使大型推理模型能够自主检索相关信息，并在多个问答任务中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的检索增强推理方法依赖于独立的检索模型，这不仅增加了硬件和运营成本，还由于表示瓶颈导致检索过程中出现错误。

**方法:** 提出了一种名为FREESON的新框架，该框架让LRMs既能作为生成器又能作为检索器，并引入了专门用于检索任务的CT-MCTS算法。

**结果:** 在五个开放域问答基准测试中，FREESON框架相比四个具有独立检索器的多步推理模型，在EM和F1指标上实现了平均14.4%的提升，并且在PopQA和2WikiMultihopQA数据集上优于最强基线模型。

**结论:** FREESON框架使LRMs能够自行检索相关知识，通过在五个开放域问答基准测试中验证，FREESON在EM和F1指标上平均提升了14.4%，并且在PopQA和2WikiMultihopQA数据集上超过了最强基线模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FREESON%3A+Retriever-Free+Retrieval-Augmented+Reasoning+via+Corpus-Traversing+MCTS，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16409，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16409&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in
multi-step reasoning and calling search engines at appropriate steps. However,
existing retrieval-augmented reasoning approaches rely on separate retrieval
models, limiting the LRM's role in retrieval to deciding when to retrieve and
how to query. This separation not only increases hardware and operational costs
but also leads to errors in the retrieval process due to the representation
bottleneck, a phenomenon where the retriever's embedding space is not
expressive enough to meet the generator's requirements. To address this, we
shift our perspective from sequence-to-sequence matching to locating the
answer-containing paths within the corpus, and propose a novel framework called
FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables
LRMs to retrieve relevant knowledge on their own by acting as both a generator
and retriever. To achieve this, we introduce a variant of the MCTS algorithm
specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing
Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus
toward answer-containing regions. Our results on five open-domain QA
benchmarks, including single-hop and multi-hop questions, show that FREESON
achieves an average improvement of 14.4% in EM and F1 over four multi-step
reasoning models with a separate retriever, and it also performs comparably to
the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.

</details>


### [152] [Internal Bias in Reasoning Models leads to Overthinking](https://arxiv.org/abs/2505.16448)
*Renfei Dang, Shujian Huang, Jiajun Chen*

**主要类别:** cs.AI

**概要:** Reasoning models often overthink due to internal biases towards input texts. By masking the input section, computational waste can be reduced and accuracy improved.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of overthinking in reasoning models caused by internal biases.

**方法:** Masking the input section to reduce the influence of internal bias.

**结果:** Reduction in reasoning length by 31%-53% and improvement in accuracy in most cases.

**结论:** Internal bias is causally linked to overthinking in reasoning models.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Internal+Bias+in+Reasoning+Models+leads+to+Overthinking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16448&send_immediately=true&force_search=false)

**原文摘要:** While current reasoning models possess strong exploratory capabilities, they
are often criticized for overthinking due to redundant and unnecessary
reflections. In this work, we reveal for the first time that overthinking in
reasoning models may stem from their internal bias towards input texts. Upon
encountering a reasoning problem, the model immediately forms a preliminary
guess about the answer, which we term as an internal bias since it is not
derived through actual reasoning. When this guess conflicts with its reasoning
result, the model tends to engage in reflection, leading to the waste of
computational resources. Through further interpretability experiments, we find
that this behavior is largely driven by the model's excessive attention to the
input section, which amplifies the influence of internal bias on its
decision-making process. Additionally, by masking out the original input
section, the affect of internal bias can be effectively alleviated and the
reasoning length could be reduced by 31%-53% across different complex reasoning
tasks. Notably, in most cases, this approach also leads to improvements in
accuracy. These findings demonstrate a causal relationship between internal
bias and overthinking.

</details>


### [153] [Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](https://arxiv.org/abs/2505.16455)
*Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin*

**主要类别:** cs.AI

**概要:** 提出了一种基于心理学的情绪生成代理框架（PsychoAgent），用于社交网络上的恐慌情绪预测。该模型通过构造细粒度数据集、整合跨领域异构数据以及设计基于LLM的角色扮演代理来提高预测性能和可解释性。实验表明，PsychoAgent在恐慌情绪预测上比基线模型提升了12.6%-21.7%。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测社交媒体上的公众恐慌情绪对于主动治理和危机管理至关重要，但现有研究面临标注数据不足、风险感知未建模和预测机制不可解释等挑战。

**方法:** 提出了一种基于心理学的情绪生成代理框架（PsychoAgent），包括构建细粒度开放恐慌情绪数据集（COPE）、整合跨领域异构数据的框架以及基于LLM的角色扮演代理。

**结果:** 实验结果显示，PsychoAgent相比基线模型在恐慌情绪预测性能上有显著提升，同时验证了方法的可解释性和泛化能力。

**结论:** 这项工作标志着从不透明的数据驱动拟合到透明的角色模拟和机制解释的范式转变，为紧急情况下的恐慌情绪预测提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Psychology-driven+LLM+Agents+for+Explainable+Panic+Prediction+on+Social+Media+during+Sudden+Disaster+Events，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16455，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16455&send_immediately=true&force_search=false)

**原文摘要:** During sudden disaster events, accurately predicting public panic sentiment
on social media is crucial for proactive governance and crisis management.
Current efforts on this problem face three main challenges: lack of finely
annotated data hinders emotion prediction studies, unmodeled risk perception
causes prediction inaccuracies, and insufficient interpretability of panic
formation mechanisms. We address these issues by proposing a Psychology-driven
generative Agent framework (PsychoAgent) for explainable panic prediction based
on emotion arousal theory. Specifically, we first construct a fine-grained open
panic emotion dataset (namely COPE) via human-large language models (LLMs)
collaboration to mitigate semantic bias. Then, we develop a framework
integrating cross-domain heterogeneous data grounded in psychological
mechanisms to model risk perception and cognitive differences in emotion
generation. To enhance interpretability, we design an LLM-based role-playing
agent that simulates individual psychological chains through dedicatedly
designed prompts. Experimental results on our annotated dataset show that
PsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%
compared to baseline models. Furthermore, the explainability and generalization
of our approach is validated. Crucially, this represents a paradigm shift from
opaque "data-driven fitting" to transparent "role-based simulation with
mechanistic interpretation" for panic emotion prediction during emergencies.
Our implementation is publicly available at:
https://anonymous.4open.science/r/PsychoAgent-19DD.

</details>


### [154] [MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks](https://arxiv.org/abs/2505.16459)
*Guiyao Tie, Xueyang Zhou, Tianhe Gu, Ruihang Zhang, Chaoran Hu, Sizhe Zhang, Mengqu Sun, Yan Zhang, Pan Zhou, Lichao Sun*

**主要类别:** cs.AI

**概要:** 提出一个新的基准MMMR，用于评估多模态推理的显式思维，包括一个包含6种推理类型的问题数据集和一个评估推理质量的模块化管道。


<details>
  <summary>更多</summary>
  
**动机:** 现有工作对多模态大型语言模型（MLLMs）的推理能力理解有限，缺乏标准化的评估基准。

**方法:** 引入MMMR基准，包括高难度数据集和推理痕迹评估管道（RTEP）。

**结果:** MLLMs-T整体上优于非思考模型，但顶级模型仍存在推理病态问题。

**结论:** MMMR提供了一个可扩展的基础来评估、比较和改进下一代多模态推理系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MMMR%3A+Benchmarking+Massive+Multi-Modal+Reasoning+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16459，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16459&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled
unified processing of language, vision, and structured inputs, opening the door
to complex tasks such as logical deduction, spatial reasoning, and scientific
analysis. Despite their promise, the reasoning capabilities of MLLMs,
particularly those augmented with intermediate thinking traces (MLLMs-T),
remain poorly understood and lack standardized evaluation benchmarks. Existing
work focuses primarily on perception or final answer correctness, offering
limited insight into how models reason or fail across modalities. To address
this gap, we introduce the MMMR, a new benchmark designed to rigorously
evaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a
high-difficulty dataset of 1,083 questions spanning six diverse reasoning types
with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace
Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy
through metrics like relevance, consistency, and structured error annotations.
Empirical results show that MLLMs-T overall outperform non-thinking
counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro
suffer from reasoning pathologies such as inconsistency and overthinking. This
benchmark reveals persistent gaps between accuracy and reasoning quality and
provides an actionable evaluation pipeline for future model development.
Overall, the MMMR offers a scalable foundation for evaluating, comparing, and
improving the next generation of multi-modal reasoning systems.

</details>


### [155] [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://arxiv.org/abs/2505.16475)
*Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng*

**主要类别:** cs.AI

**概要:** 提出了一种名为ReflectEvo的新管道，展示了小语言模型通过反射学习增强元内省的能力。构建了一个大规模自生成反射数据集，并证明了反射学习可以显著提高SLM的推理能力，而无需从优越模型蒸馏或精细的人类注释。进一步分析了高质量自生成反射及其对错误定位和纠正的影响。


<details>
  <summary>更多</summary>
  
**动机:** 展示小语言模型通过反射学习增强元内省的能力。

**方法:** 提出了一种名为ReflectEvo的新管道，该管道通过迭代生成自我反思进行自我训练，促进持续和自我演进的过程。

**结果:** 构建了一个大规模、全面、自生成的反射数据集，并证明了反射学习可以显著提高SLM的推理能力，而无需从优越模型蒸馏或精细的人类注释。

**结论:** 持续迭代反射学习可以提高小语言模型的推理性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReflectEvo%3A+Improving+Meta+Introspection+of+Small+LLMs+by+Learning+Self-Reflection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16475，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16475&send_immediately=true&force_search=false)

**原文摘要:** We present a novel pipeline, ReflectEvo, to demonstrate that small language
models (SLMs) can enhance meta introspection through reflection learning. This
process iteratively generates self-reflection for self-training, fostering a
continuous and self-evolving process. Leveraging this pipeline, we construct
ReflectEvo-460k, a large-scale, comprehensive, self-generated reflection
dataset with broadened instructions and diverse multi-domain tasks. Building
upon this dataset, we demonstrate the effectiveness of reflection learning to
improve SLMs' reasoning abilities using SFT and DPO with remarkable
performance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral
from 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the
reasoning capability of the three prominent open-sourced models on BIG-bench
without distillation from superior models or fine-grained human annotation. We
further conduct a deeper analysis of the high quality of self-generated
reflections and their impact on error localization and correction. Our work
highlights the potential of continuously enhancing the reasoning performance of
SLMs through iterative reflection learning in the long run.

</details>


### [156] [Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery](https://arxiv.org/abs/2505.16477)
*Yanbo Zhang, Sumeer A. Khan, Adnan Mahmud, Huck Yang, Alexander Lavin, Michael Levin, Jeremy Frey, Jared Dunnmon, James Evans, Alan Bundy, Saso Dzeroski, Jesper Tegner, Hector Zenil*

**主要类别:** cs.AI

**概要:** This paper reviews the role of Large Language Models (LLMs) in transforming scientific research, focusing on their integration into various stages of the scientific cycle and discussing challenges like hallucinations and reliability. It concludes that LLMs can be effective creative tools if integrated collaboratively with human goals and proper evaluation metrics.


<details>
  <summary>更多</summary>
  
**动机:** The motivation is to explore how LLMs are redefining the scientific method and their potential applications across the scientific cycle.

**方法:** The paper reviews existing literature and discusses the potential applications of LLMs in scientific research.

**结果:** The result highlights the challenges of integrating LLMs into scientific processes, including issues of reliability and hallucinations, while emphasizing their potential as creative tools.

**结论:** For LLMs to be effective, they should be deeply integrated into the scientific process with clear evaluation metrics, and the scientific community must address ethical considerations regarding their use.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+the+Scientific+Method+with+Large+Language+Models%3A+From+Hypothesis+to+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16477，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16477&send_immediately=true&force_search=false)

**原文摘要:** With recent Nobel Prizes recognising AI contributions to science, Large
Language Models (LLMs) are transforming scientific research by enhancing
productivity and reshaping the scientific method. LLMs are now involved in
experimental design, data analysis, and workflows, particularly in chemistry
and biology. However, challenges such as hallucinations and reliability
persist. In this contribution, we review how Large Language Models (LLMs) are
redefining the scientific method and explore their potential applications
across different stages of the scientific cycle, from hypothesis testing to
discovery. We conclude that, for LLMs to serve as relevant and effective
creative engines and productivity enhancers, their deep integration into all
steps of the scientific process should be pursued in collaboration and
alignment with human scientific goals, with clear evaluation metrics. The
transition to AI-driven science raises ethical questions about creativity,
oversight, and responsibility. With careful guidance, LLMs could evolve into
creative engines, driving transformative breakthroughs across scientific
disciplines responsibly and effectively. However, the scientific community must
also decide how much it leaves to LLMs to drive science, even when associations
with 'reasoning', mostly currently undeserved, are made in exchange for the
potential to explore hypothesis and solution regions that might otherwise
remain unexplored by human exploration alone.

</details>


### [157] [Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes](https://arxiv.org/abs/2505.16482)
*Huynh Thi Thanh Binh, Le Van Cuong, Dang Hai Dang, Le Trong Vinh*

**主要类别:** cs.AI

**概要:** This paper proposes a new partial charging approach for Wireless Rechargeable Sensor Networks (WRSNs) using a bi-level optimized scheme to minimize energy depletion by optimizing both charging path and time.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of ineffective charging strategies leading to reduced charging performance and potential sensor failure due to extended charging latency in WRSNs.

**方法:** Introduces a novel partial charging approach following a bi-level optimized scheme, formulates a mathematical model of the problem, and proposes two approximate algorithms combining different optimization methods.

**结果:** The proposed algorithms outperform existing works in minimizing energy depletion in WRSNs across various network scenarios.

**结论:** The introduction of a partial charging approach with a bi-level optimized scheme provides a more effective way to manage energy in WRSNs, improving overall performance and reliability.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Minimizing+the+energy+depletion+in+wireless+rechargeable+sensor+networks+using+bi-level+metaheuristic+charging+schemes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16482，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16482&send_immediately=true&force_search=false)

**原文摘要:** Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the
advantage of wireless energy transfer technology have opened a promising
opportunity in solving the limited energy issue. However, an ineffective
charging strategy may reduce the charging performance. Although many practical
charging algorithms have been introduced, these studies mainly focus on
optimizing the charging path with a fully charging approach. This approach may
lead to the death of a series of sensors due to their extended charging
latency. This paper introduces a novel partial charging approach that follows a
bi-level optimized scheme to minimize energy depletion in WRSNs. We aim at
optimizing simultaneously two factors: the charging path and time. To
accomplish this, we first formulate a mathematical model of the investigated
problem. We then propose two approximate algorithms in which the optimization
of the charging path and the charging time are considered as the upper and
lower level, respectively. The first algorithm combines a Multi-start Local
Search method and a Genetic Algorithm to find a solution. The second algorithm
adopts a nested approach that utilizes the advantages of the Multitasking and
Covariance Matrix Adaptation Evolutionary Strategies. Experimental validations
on various network scenarios demonstrate that our proposed algorithms
outperform the existing works.

</details>


### [158] [Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)](https://arxiv.org/abs/2505.16507)
*Anshu Xiong, Songmao Zhang*

**主要类别:** cs.AI

**概要:** This paper extends the concept of relevance from single argument justification to set verification within incomplete argumentation frameworks (IAFs), introducing strong relevance and analyzing its complexity.


<details>
  <summary>更多</summary>
  
**动机:** To explore how uncertainties in IAFs need to be resolved for consistent results across different completions.

**方法:** Studying relevance for verification status of a set of arguments and proposing the concept of strong relevance.

**结果:** Detection of (strong) relevance for sets of arguments can be done in polynomial time under most semantics.

**结论:** Identifies challenges in finding efficient methods for relevance detection under grounded semantics.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Relevance+for+Stability+of+Verification+Status+of+a+Set+of+Arguments+in+Incomplete+Argumentation+Frameworks+%28with+Proofs%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16507&send_immediately=true&force_search=false)

**原文摘要:** The notion of relevance was proposed for stability of justification status of
a single argument in incomplete argumentation frameworks (IAFs) in 2024 by
Odekerken et al. To extend the notion, we study the relevance for stability of
verification status of a set of arguments in this paper, i.e., the
uncertainties in an IAF that have to be resolved in some situations so that
answering whether a given set of arguments is an extension obtains the same
result in every completion of the IAF. Further we propose the notion of strong
relevance for describing the necessity of resolution in all situations reaching
stability. An analysis of complexity reveals that detecting the (strong)
relevance for stability of sets of arguments can be accomplished in P time
under the most semantics discussed in the paper. We also discuss the difficulty
in finding tractable methods for relevance detection under grounded semantics.

</details>


### [159] [Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org/abs/2505.16579)
*Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang*

**主要类别:** cs.AI

**概要:** 提出GRASSLAND迷宫导航基准测试来评估动态空间推理，并提出D2R框架无缝集成文本CoT与相应视觉草图到MLLMs中，无需模型微调即可提升性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在动态空间推理任务中表现不佳，需要一种新的方法来改进复杂推理。

**方法:** 提出了GRASSLAND基准测试和D2R框架，后者将文本推理链与动态视觉草图结合。

**结果:** 实验表明，D2R在不同任务中提高了性能，为动态空间推理提供了稳健的基础。

**结论:** 所提出的方法不需要模型微调，并且在动态空间推理方面表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+the+Dynamic+Perception+Gap%3A+Training-Free+Draft+Chain-of-Thought+for+Dynamic+Multimodal+Spatial+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16579&send_immediately=true&force_search=false)

**原文摘要:** While chains-of-thought (CoT) have advanced complex reasoning in multimodal
large language models (MLLMs), existing methods remain confined to text or
static visual domains, often faltering in dynamic spatial reasoning tasks. To
bridge this gap, we present GRASSLAND, a novel maze navigation benchmark
designed to evaluate dynamic spatial reasoning. Our experiments show that
augmenting textual reasoning chains with dynamic visual drafts, overlaid on
input images, significantly outperforms conventional approaches, offering new
insights into spatial reasoning in evolving environments. To generalize this
capability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free
framework that seamlessly integrates textual CoT with corresponding visual
drafts into MLLMs. Extensive evaluations demonstrate that D2R consistently
enhances performance across diverse tasks, establishing a robust baseline for
dynamic spatial reasoning without requiring model fine-tuning. Project is open
at https://github.com/Cratileo/D2R.

</details>


### [160] [Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences](https://arxiv.org/abs/2505.16619)
*Gavin Farrell, Eleni Adamidi, Rafael Andrade Buono, Mihail Anton, Omar Abdelghani Attafi, Salvador Capella Gutierrez, Emidio Capriotti, Leyla Jael Castro, Davide Cirillo, Lisa Crossman, Christophe Dessimoz, Alexandros Dimopoulos, Raul Fernandez-Diaz, Styliani-Christina Fragkouli, Carole Goble, Wei Gu, John M. Hancock, Alireza Khanteymoori, Tom Lenaerts, Fabio G. Liberante, Peter Maccallum, Alexander Miguel Monzon, Magnus Palmblad, Lucy Poveda, Ovidiu Radulescu, Denis C. Shields, Shoaib Sufi, Thanasis Vergoulis, Fotis Psomopoulos, Silvio C. E. Tosatto*

**主要类别:** cs.AI

**概要:** AI在生命科学领域的快速发展带来了信任度下降和可重复性问题，本文提出了一套开放且可持续的人工智能（OSAI）建议来应对这些挑战。


<details>
  <summary>更多</summary>
  
**动机:** 快速采用AI方法加剧了长期存在的研究挑战，如信任度降低、可复用性和可重复性差的问题，影响环境可持续性。

**方法:** 审查AI研究输出的信任侵蚀问题，并讨论AI生态系统中的碎片化组件及缺乏指导路径的情况，提出OSAI推荐方案。

**结果:** 提出了直接映射到AI生态系统超过300个组件的一套OSAI建议，连接研究人员与相关AI资源，促进可持续、可复用和透明的AI发展。

**结论:** 本研究旨在通过提供政策和指导路径来帮助未来AI的实施，连接生命科学社区共识并支持现有努力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Open+and+Sustainable+AI%3A+challenges%2C+opportunities+and+the+road+ahead+in+the+life+sciences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16619&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) has recently seen transformative breakthroughs
in the life sciences, expanding possibilities for researchers to interpret
biological information at an unprecedented capacity, with novel applications
and advances being made almost daily. In order to maximise return on the
growing investments in AI-based life science research and accelerate this
progress, it has become urgent to address the exacerbation of long-standing
research challenges arising from the rapid adoption of AI methods. We review
the increased erosion of trust in AI research outputs, driven by the issues of
poor reusability and reproducibility, and highlight their consequent impact on
environmental sustainability. Furthermore, we discuss the fragmented components
of the AI ecosystem and lack of guiding pathways to best support Open and
Sustainable AI (OSAI) model development. In response, this perspective
introduces a practical set of OSAI recommendations directly mapped to over 300
components of the AI ecosystem. Our work connects researchers with relevant AI
resources, facilitating the implementation of sustainable, reusable and
transparent AI. Built upon life science community consensus and aligned to
existing efforts, the outputs of this perspective are designed to aid the
future development of policy and structured pathways for guiding AI
implementation.

</details>


### [161] [SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving](https://arxiv.org/abs/2505.16646)
*Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang*

**主要类别:** cs.AI

**概要:** 提出SMART框架，分解数学问题解决为四个维度，并通过自生成和验证机制评估多种大型语言模型的能力，揭示了最终答案准确性不足以衡量真实解题能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有数学基准测试的成功可能只是表面的模式识别而非真正的数学推理，且常用评估指标缺乏诊断价值。

**方法:** 引入SMART框架，将数学问题解决分解为理解、推理、算术和反思与精炼四个维度，并通过自动化自生成和自验证机制生成和验证基准数据。

**结果:** 在21种最先进的开源和闭源LLMs上应用SMART，发现它们在不同维度上的能力存在显著差异。

**结论:** 最终答案准确性不是衡量LLMs真正解决问题能力的合适指标，需要新的综合指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMART%3A+Self-Generating+and+Self-Validating+Multi-Dimensional+Assessment+for+LLMs%27+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16646，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16646&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models have achieved remarkable results on a variety of
mathematical benchmarks. However, concerns remain as to whether these successes
reflect genuine mathematical reasoning or superficial pattern recognition.
Common evaluation metrics, such as final answer accuracy, fail to disentangle
the underlying competencies involved, offering limited diagnostic value. To
address these limitations, we introduce SMART: a Self-Generating and
Self-Validating Multi-Dimensional Assessment Framework. SMART decomposes
mathematical problem solving into four distinct dimensions: understanding,
reasoning, arithmetic, and reflection \& refinement. Each dimension is
evaluated independently through tailored tasks, enabling interpretable and
fine-grained analysis of LLM behavior. Crucially, SMART integrates an automated
self-generating and self-validating mechanism to produce and verify benchmark
data, ensuring both scalability and reliability. We apply SMART to 21
state-of-the-art open- and closed-source LLMs, uncovering significant
discrepancies in their abilities across different dimensions. Our findings
demonstrate the inadequacy of final answer accuracy as a sole metric and
motivate a new holistic metric to better capture true problem-solving
capabilities. Code and benchmarks will be released upon acceptance.

</details>


### [162] [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://arxiv.org/abs/2505.16667)
*Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei*

**主要类别:** cs.AI

**概要:** 提出了一种新的编程数据集ELABORATIONSET和评估基准ELABORATION，用于促进人与大型语言模型在竞争性编程中的协作。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究分散且使用多种特定于应用的人类反馈，缺乏对人机协作全面理解。

**方法:** 提出了第一个整合整个编程过程的人类反馈分类法，并设计了ELABORATIONSET数据集和ELABORATION基准。

**结果:** 通过ELABORATION识别出已有方法的优势和劣势，为未来改进奠定基础。

**结论:** 这项工作通过提供系统化的分类法、新的数据集和基准，促进了人与大型语言模型在竞争性编程中的协作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ELABORATION%3A+A+Comprehensive+Benchmark+on+Human-LLM+Competitive+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16667，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16667&send_immediately=true&force_search=false)

**原文摘要:** While recent research increasingly emphasizes the value of human-LLM
collaboration in competitive programming and proposes numerous empirical
methods, a comprehensive understanding remains elusive due to the fragmented
nature of existing studies and their use of diverse, application-specific human
feedback. Thus, our work serves a three-fold purpose: First, we present the
first taxonomy of human feedback consolidating the entire programming process,
which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a
novel programming dataset specifically designed for human-LLM collaboration,
meticulously annotated to enable large-scale simulated human feedback and
facilitate costeffective real human interaction studies. Third, we introduce
ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM
competitive programming. With ELABORATION, we pinpoint strengthes and
weaknesses of existing methods, thereby setting the foundation for future
improvement. Our code and dataset are available at
https://github.com/SCUNLP/ELABORATION

</details>


### [163] [SPaRC: A Spatial Pathfinding Reasoning Challenge](https://arxiv.org/abs/2505.16686)
*Lars Benedikt Kaesberg, Jan Philip Wahle, Terry Ruas, Bela Gipp*

**主要类别:** cs.AI

**概要:** SPaRC是一个包含1000个2D网格路径寻找难题的数据集，用于评估空间和符号推理。人类在该任务上表现优异，而最先进的推理模型表现不佳。这项工作揭示了现有模型在抽象多步问题解决上的局限性，并提出了改进的方向。


<details>
  <summary>更多</summary>
  
**动机:** 现有的推理数据集无法有效测试抽象的、多步骤的问题，尤其是路径寻找和复杂的规则约束满足问题。

**方法:** 引入了一个新的数据集SPaRC，包含1000个2D网格路径寻找难题，并评估了不同模型在该任务上的表现。

**结果:** 人类在SPaRC任务上的准确率接近完美，而最先进的推理模型表现较差，尤其是在困难的谜题上。模型常常生成无效路径，并且在导航和空间逻辑上犯错。

**结论:** SPaRC可以作为观察模型在空间推理能力方面局限性的窗口，并推动研究向更擅长解决抽象、多步问题的新方法发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPaRC%3A+A+Spatial+Pathfinding+Reasoning+Challenge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16686&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning datasets saturate and fail to test abstract, multi-step
problems, especially pathfinding and complex rule constraint satisfaction. We
introduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000
2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,
requiring step-by-step planning with arithmetic and geometric rules. Humans
achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best
reasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).
Models often generate invalid paths (>50% of puzzles for o4-mini), and
reasoning tokens reveal they make errors in navigation and spatial logic.
Unlike humans, who take longer on hard puzzles, models fail to scale test-time
compute with difficulty. Allowing models to make multiple solution attempts
improves accuracy, suggesting potential for better spatial reasoning with
improved training and efficient test-time scaling methods. SPaRC can be used as
a window into models' spatial reasoning limitations and drive research toward
new methods that excel in abstract, multi-step problem-solving.

</details>


### [164] [MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](https://arxiv.org/abs/2505.16700)
*Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen*

**主要类别:** cs.AI

**概要:** 本文介绍MCP-RADAR，首个全面评估LLMs在MCP框架下性能的五维基准，揭示LLMs在不同任务域中的能力分布及优化建议。


<details>
  <summary>更多</summary>
  
**动机:** 现有评估方法未能充分评估LLMs在MCP框架下的工具利用能力，需要一种新的评估基准。

**方法:** 提出一种新的五维方法来衡量答案准确性、工具选择效率、计算资源效率、参数构建准确性和执行速度，采用客观量化测量而非主观评价或二元成功指标。

**结果:** 评估显示领先的商业和开源LLMs具有不同的能力特征，在准确度、效率和速度之间存在显著权衡，挑战了传统的单一指标性能排名。

**结论:** 提出MCP-RADAR作为首个全面评估LLMs在MCP框架下表现的基准，发现显著的能力特征分布，并提供开发人员优化工具的指导。方法适用于所有LLM-agent工具集成框架，对开发者和工具创建者都有价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCP-RADAR%3A+A+Multi-Dimensional+Benchmark+for+Evaluating+Tool+Use+Capabilities+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16700&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLMs) evolve from passive text generators to active
reasoning agents capable of tool interaction, the Model Context Protocol (MCP)
has emerged as a standardized framework for dynamic tool discovery and
orchestration. Despite widespread industry adoption, existing evaluation
methodologies fail to adequately assess tool utilization capabilities within
this new paradigm. This paper introduces MCP-RADAR, the first comprehensive
benchmark specifically designed to evaluate LLM performance in the MCP
framework through a novel five-dimensional approach measuring: answer accuracy,
tool selection efficiency, computational resource efficiency, parameter
construction accuracy, and execution speed. Unlike conventional benchmarks that
rely on subjective human evaluations or binary success metrics, MCP-RADAR
employs objective, quantifiable measurements across multiple task domains
including software engineering, mathematical reasoning, and general
problem-solving. Our evaluations of leading commercial and open-source LLMs
reveal distinctive capability profiles with significant trade-offs between
accuracy, efficiency, and speed, challenging traditional single-metric
performance rankings. Besides, we provide valuable guidance for developers to
optimize their tools for maximum model compatibility and effectiveness. While
focused on MCP due to its standardized approach, our methodology remains
applicable across all LLM agent tool integration frameworks, providing valuable
insights for both LLM developers and tool creators to optimize the entire
LLM-tool interaction ecosystem. The implementation, configurations, and
datasets used in our evaluation are publicly available at
https://anonymous.4open.science/r/MCPRadar-B143.

</details>


### [165] [Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review](https://arxiv.org/abs/2505.16771)
*Beyazit Bestami Yuksel, Ayse Yilmazer Metin*

**主要类别:** cs.AI

**概要:** 综述过去十五年中人工智能领域的重大突破，包括计算资源、数据访问和算法创新的结合对AI发展的推动作用。论文不仅讨论了这些进展的技术细节，还探讨了它们背后的范式转变，并提出了未来研究和政策发展的战略指导。


<details>
  <summary>更多</summary>
  
**动机:** 探索人工智能在过去十五年的演变历程，识别关键转折点，解释技术进步如何转化为可扩展的解决方案。同时应对隐私问题和法规限制，评估新兴的数据访问和安全技术。

**方法:** 整合历史、理论和技术视角，分析计算资源、数据访问和算法创新的结合对AI发展的影响，以及技术进步背后的范式转变。评估新兴解决方案如联邦学习、隐私增强技术和数据站点范式。

**结果:** 揭示了AI领域内几个重要的转折点，如基于GPU的模型训练、ImageNet引发的数据中心化转变、Transformer简化架构、GPT系列扩展建模能力。同时指出需要采用数据为中心的方法，并评估了模拟和合成数据生成的效用与限制。

**结论:** 总结了从统计学习理论的角度看AI领域的重要进展，并强调了拥抱数据为中心的方法的重要性。最后为未来的AI研究和政策制定提供了战略指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Driven+Breakthroughs+and+Future+Directions+in+AI+Infrastructure%3A+A+Comprehensive+Review，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16771，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16771&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a comprehensive synthesis of major breakthroughs in
artificial intelligence (AI) over the past fifteen years, integrating
historical, theoretical, and technological perspectives. It identifies key
inflection points in AI' s evolution by tracing the convergence of
computational resources, data access, and algorithmic innovation. The analysis
highlights how researchers enabled GPU based model training, triggered a data
centric shift with ImageNet, simplified architectures through the Transformer,
and expanded modeling capabilities with the GPT series. Rather than treating
these advances as isolated milestones, the paper frames them as indicators of
deeper paradigm shifts. By applying concepts from statistical learning theory
such as sample complexity and data efficiency, the paper explains how
researchers translated breakthroughs into scalable solutions and why the field
must now embrace data centric approaches. In response to rising privacy
concerns and tightening regulations, the paper evaluates emerging solutions
like federated learning, privacy enhancing technologies (PETs), and the data
site paradigm, which reframe data access and security. In cases where real
world data remains inaccessible, the paper also assesses the utility and
constraints of mock and synthetic data generation. By aligning technical
insights with evolving data infrastructure, this study offers strategic
guidance for future AI research and policy development.

</details>


### [166] [Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making](https://arxiv.org/abs/2505.16781)
*Qianlei Jia, Xinliang Zhou, Ondrej Krejcar, Enrique Herrera-Viedma*

**主要类别:** cs.AI

**概要:** This paper proposes a novel SNGDM framework integrating 3WD theory, dynamic network reconstruction, and linguistic opinion representation to address challenges in GDM scenarios.


<details>
  <summary>更多</summary>
  
**动机:** Traditional opinion dynamics models face challenges with uncertainty, dynamic social structures, and vague information in GDM scenarios.

**方法:** The method involves introducing 3WD mechanism, developing a connection adjustment rule, using linguistic terms, and constructing an integrated multi-agent decision-making framework.

**结果:** The model is applied to a multi-UAV cooperative decision-making scenario, showing effectiveness through simulation results and consensus analysis.

**结论:** The proposed model enhances system stability and represents realistic decision-making behaviors.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fuzzy+Information+Evolution+with+Three-Way+Decision+in+Social+Network+Group+Decision-Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16781，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16781&send_immediately=true&force_search=false)

**原文摘要:** In group decision-making (GDM) scenarios, uncertainty, dynamic social
structures, and vague information present major challenges for traditional
opinion dynamics models. To address these issues, this study proposes a novel
social network group decision-making (SNGDM) framework that integrates
three-way decision (3WD) theory, dynamic network reconstruction, and linguistic
opinion representation. First, the 3WD mechanism is introduced to explicitly
model hesitation and ambiguity in agent judgments, thereby preventing
irrational decisions. Second, a connection adjustment rule based on opinion
similarity is developed, enabling agents to adaptively update their
communication links and better reflect the evolving nature of social
relationships. Third, linguistic terms are used to describe agent opinions,
allowing the model to handle subjective, vague, or incomplete information more
effectively. Finally, an integrated multi-agent decision-making framework is
constructed, which simultaneously considers individual uncertainty, opinion
evolution, and network dynamics. The proposed model is applied to a multi-UAV
cooperative decision-making scenario, where simulation results and consensus
analysis demonstrate its effectiveness. Experimental comparisons further verify
the advantages of the algorithm in enhancing system stability and representing
realistic decision-making behaviors.

</details>


### [167] [Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce](https://arxiv.org/abs/2505.16787)
*Ashish Sundar, Chunbo Luo, Xiaoyang Wang*

**主要类别:** cs.AI

**概要:** This paper proposes a novel approach for model-based reinforcement learning (MBRL) that improves the fidelity of the world model and reduces its time to convergence. The method anticipates and seeks out high-entropy states using short-horizon latent predictions from the world model. A hierarchical planner is introduced to decide when to replan, planning horizon length, and the weighting between reward and entropy. The method accelerates the convergence of the policy trained in imagination compared to base Dreamer.


<details>
  <summary>更多</summary>
  
**动机:** To address the neglect of optimizing the world model learning in MBRL methods while prioritizing the actor optimization.

**方法:** Introduces a novel approach that uses short-horizon latent predictions to anticipate and seek out high-entropy states, and a hierarchical planner to dynamically decide planning parameters.

**结果:** The method improves the performance of the policy trained in imagination, finishing Miniworld mazes 50% faster than base Dreamer and converging in 60% of the environment steps.

**结论:** This work demonstrates the potential benefits of improving the world model in MBRL, showing significant improvements in sample efficiency and performance.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gaze+Into+the+Abyss+--+Planning+to+Seek+Entropy+When+Reward+is+Scarce，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16787&send_immediately=true&force_search=false)

**原文摘要:** Model-based reinforcement learning (MBRL) offers an intuitive way to increase
the sample efficiency of model-free RL methods by simultaneously training a
world model that learns to predict the future. MBRL methods have progressed by
largely prioritising the actor; optimising the world model learning has been
neglected meanwhile. Improving the fidelity of the world model and reducing its
time to convergence can yield significant downstream benefits, one of which is
improving the ensuing performance of any actor it may train. We propose a novel
approach that anticipates and actively seeks out high-entropy states using
short-horizon latent predictions generated by the world model, offering a
principled alternative to traditional curiosity-driven methods that chase
once-novel states well after they were stumbled into. While many model
predictive control (MPC) based methods offer similar alternatives, they
typically lack commitment, synthesising multi step plans after every step. To
mitigate this, we present a hierarchical planner that dynamically decides when
to replan, planning horizon length, and the weighting between reward and
entropy. While our method can theoretically be applied to any model that trains
its own actors with solely model generated data, we have applied it to just
Dreamer as a proof of concept. Our method finishes the Miniworld procedurally
generated mazes 50% faster than base Dreamer at convergence and the policy
trained in imagination converges in only 60% of the environment steps that base
Dreamer needs.

</details>


### [168] [KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning](https://arxiv.org/abs/2505.16826)
*Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种新的算法Key-token Advantage Estimation (KTAE)，用于解决现有强化学习算法在计算优势时粒度较粗的问题。实验表明，使用KTAE的方法在五个数学推理基准测试中表现优于基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的强化学习算法如GRPO及其变体在计算优势时存在粒度较粗的问题，无法捕捉到单个标记的具体贡献，从而阻碍了有效的学习。

**方法:** 提出了Key-token Advantage Estimation (KTAE)，该算法无需引入额外模型即可估计细粒度的标记级优势。KTAE利用采样展开的正确性并应用统计分析来量化序列中各个标记对最终结果的重要性。

**结果:** 模型在五个数学推理基准测试中表现出色，与基线方法相比具有更高的准确率，并且生成的回答更短。

**结论:** 所提出的KTAE算法可以有效提高大型语言模型的推理能力，尤其是在没有监督微调的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是KTAE%3A+A+Model-Free+Algorithm+to+Key-Tokens+Advantage+Estimation+in+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16826，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16826&send_immediately=true&force_search=false)

**原文摘要:** Recent advances have demonstrated that integrating reinforcement learning
with rule-based rewards can significantly enhance the reasoning capabilities of
large language models, even without supervised fine-tuning. However, prevalent
reinforcement learning algorithms such as GRPO and its variants like DAPO,
suffer from a coarse granularity issue when computing the advantage.
Specifically, they compute rollout-level advantages that assign identical
values to every token within a sequence, failing to capture token-specific
contributions and hindering effective learning. To address this limitation, we
propose Key-token Advantage Estimation (KTAE) - a novel algorithm that
estimates fine-grained, token-level advantages without introducing additional
models. KTAE leverages the correctness of sampled rollouts and applies
statistical analysis to quantify the importance of individual tokens within a
sequence to the final outcome. This quantified token-level importance is then
combined with the rollout-level advantage to obtain a more fine-grained
token-level advantage estimation. Empirical results show that models trained
with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five
mathematical reasoning benchmarks. Notably, they achieve higher accuracy with
shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base
model.

</details>


### [169] [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://arxiv.org/abs/2505.16827)
*Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie*

**主要类别:** cs.AI

**概要:** GUI-explorer是一个无需微调的图形用户界面代理，通过自主探索和无监督挖掘来提高自动化水平，显著优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 解决动态环境中图形用户界面自动化的关键挑战，特别是误判UI组件和知识过时的问题。

**方法:** 引入了两个机制：功能感知轨迹的自主探索和转换感知知识的无监督挖掘。

**结果:** 在SPA-Bench和AndroidWorld上任务成功率分别为53.7%和47.4%，大幅超越当前最佳方法。

**结论:** GUI-explorer不需要对新应用进行参数更新，并且已经开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUI-explorer%3A+Autonomous+Exploration+and+Mining+of+Transition-aware+Knowledge+for+GUI+Agent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16827，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16827&send_immediately=true&force_search=false)

**原文摘要:** GUI automation faces critical challenges in dynamic environments. MLLMs
suffer from two key issues: misinterpreting UI components and outdated
knowledge. Traditional fine-tuning methods are costly for app-specific
knowledge updates. We propose GUI-explorer, a training-free GUI agent that
incorporates two fundamental mechanisms: (1) Autonomous Exploration of
Function-aware Trajectory. To comprehensively cover all application
functionalities, we design a Function-aware Task Goal Generator that
automatically constructs exploration goals by analyzing GUI structural
information (e.g., screenshots and activity hierarchies). This enables
systematic exploration to collect diverse trajectories. (2) Unsupervised Mining
of Transition-aware Knowledge. To establish precise screen-operation logic, we
develop a Transition-aware Knowledge Extractor that extracts effective
screen-operation logic through unsupervised analysis the state transition of
structured interaction triples (observation, action, outcome). This eliminates
the need for human involvement in knowledge extraction. With a task success
rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows
significant improvements over SOTA agents. It requires no parameter updates for
new apps. GUI-explorer is open-sourced and publicly available at
https://github.com/JiuTian-VL/GUI-explorer.

</details>


### [170] [From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization](https://arxiv.org/abs/2505.16832)
*Haonian Ji, Shi Qiu, Siyang Xin, Siwei Han, Zhaorun Chen, Hongyi Wang, Dake Zhang, Huaxiu Yao*

**主要类别:** cs.AI

**概要:** This paper introduces EduVisBench and proposes EduVisAgent to enhance visual reasoning capabilities of foundation models in educational settings.


<details>
  <summary>更多</summary>
  
**动机:** Existing foundation models lack the ability to generate pedagogically effective visual explanations, focusing mainly on textual reasoning while neglecting the importance of structured and interpretable visualizations for conceptual understanding.

**方法:** Introducing EduVisBench and proposing EduVisAgent with specialized agents for instructional planning, reasoning decomposition, metacognitive prompting, and visualization design.

**结果:** EduVisAgent improves performance by 40.2% compared to existing models and provides more educationally aligned visualizations.

**结论:** EduVisAgent, a multi-agent collaborative framework, outperforms existing models by improving visual explanation generation in educational contexts.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+EduVisBench+to+EduVisAgent%3A+A+Benchmark+and+Multi-Agent+Framework+for+Pedagogical+Visualization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16832，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16832&send_immediately=true&force_search=false)

**原文摘要:** While foundation models (FMs), such as diffusion models and large
vision-language models (LVLMs), have been widely applied in educational
contexts, their ability to generate pedagogically effective visual explanations
remains limited. Most existing approaches focus primarily on textual reasoning,
overlooking the critical role of structured and interpretable visualizations in
supporting conceptual understanding. To better assess the visual reasoning
capabilities of FMs in educational settings, we introduce EduVisBench, a
multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem
sets requiring visually grounded solutions, along with a fine-grained
evaluation rubric informed by pedagogical theory. Our empirical analysis
reveals that existing models frequently struggle with the inherent challenge of
decomposing complex reasoning and translating it into visual representations
aligned with human cognitive processes. To address these limitations, we
propose EduVisAgent, a multi-agent collaborative framework that coordinates
specialized agents for instructional planning, reasoning decomposition,
metacognitive prompting, and visualization design. Experimental results show
that EduVisAgent substantially outperforms all baselines, achieving a 40.2%
improvement and delivering more educationally aligned visualizations.
EduVisBench and EduVisAgent are available at
https://github.com/aiming-lab/EduVisBench and
https://github.com/aiming-lab/EduVisAgent.

</details>


### [171] [Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models](https://arxiv.org/abs/2505.16854)
*Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou*

**主要类别:** cs.AI

**概要:** This paper introduces TON, a two-stage training strategy that enhances reasoning in vision-language models by enabling them to decide whether reasoning is necessary, reducing completion length by up to 90% compared to GRPO without performance loss.


<details>
  <summary>更多</summary>
  
**动机:** To make vision-language models more efficient by allowing them to decide when reasoning is necessary, inspired by human-like thinking processes.

**方法:** TON includes a supervised fine-tuning stage with 'thought dropout' and a GRPO stage that maximizes task-aware outcome rewards.

**结果:** Experimental results show TON reduces completion length significantly while maintaining or improving performance, with models learning to bypass unnecessary reasoning steps.

**结论:** TON achieves human-like reasoning patterns in reinforcement learning approaches and improves efficiency in vision-language tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think+or+Not%3F+Selective+Reasoning+via+Reinforcement+Learning+for+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16854&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning (RL) has proven to be an effective post-training
strategy for enhancing reasoning in vision-language models (VLMs). Group
Relative Policy Optimization (GRPO) is a recent prominent method that
encourages models to generate complete reasoning traces before answering,
leading to increased token usage and computational cost. Inspired by the
human-like thinking process-where people skip reasoning for easy questions but
think carefully when needed-we explore how to enable VLMs to first decide when
reasoning is necessary. To realize this, we propose TON, a two-stage training
strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective
'thought dropout' operation, where reasoning traces are randomly replaced with
empty thoughts. This introduces a think-or-not format that serves as a cold
start for selective reasoning; (ii) a GRPO stage that enables the model to
freely explore when to think or not, while maximizing task-aware outcome
rewards. Experimental results show that TON can reduce the completion length by
up to 90% compared to vanilla GRPO, without sacrificing performance or even
improving it. Further evaluations across diverse vision-language tasks-covering
a range of reasoning difficulties under both 3B and 7B models-consistently
reveal that the model progressively learns to bypass unnecessary reasoning
steps as training advances. These findings shed light on the path toward
human-like reasoning patterns in reinforcement learning approaches. Our code is
available at https://github.com/kokolerk/TON.

</details>


### [172] [Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings](https://arxiv.org/abs/2505.16877)
*Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab*

**主要类别:** cs.AI

**概要:** 提出一种新的方法CondKGCP，提供更强的查询一致预测集保证，同时保持紧凑的预测集合。


<details>
  <summary>更多</summary>
  
**动机:** 在高风险应用如医学诊断中需要更强的预测集保证，现有方法仅提供平均概率保证。

**方法:** 通过合并相似向量表示的谓词和增强校准信息来近似条件覆盖保证。

**结果:** 证明了理论保证并展示了经验有效性。

**结论:** 提出的方法CondKGCP在保持紧凑预测集合的同时提供了更强的查询一致预测集保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predicate-Conditional+Conformalized+Answer+Sets+for+Knowledge+Graph+Embeddings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16877，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16877&send_immediately=true&force_search=false)

**原文摘要:** Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is
crucial for ensuring the reliability of downstream applications. A recent work
applies conformal prediction to KGE methods, providing uncertainty estimates by
generating a set of answers that is guaranteed to include the true answer with
a predefined confidence level. However, existing methods provide probabilistic
guarantees averaged over a reference set of queries and answers (marginal
coverage guarantee). In high-stakes applications such as medical diagnosis, a
stronger guarantee is often required: the predicted sets must provide
consistent coverage per query (conditional coverage guarantee). We propose
CondKGCP, a novel method that approximates predicate-conditional coverage
guarantees while maintaining compact prediction sets. CondKGCP merges
predicates with similar vector representations and augments calibration with
rank information. We prove the theoretical guarantees and demonstrate empirical
effectiveness of CondKGCP by comprehensive evaluations.

</details>


### [173] [Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships](https://arxiv.org/abs/2505.16899)
*Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky*

**主要类别:** cs.AI

**概要:** This commentary discusses the risks associated with AI thought partners and proposes concrete metrics and mitigation strategies for developers and policymakers.


<details>
  <summary>更多</summary>
  
**动机:** To explore the risks and benefits of AI thought partners and propose ways to mitigate potential harms.

**方法:** Systematically identifying risks using a novel framework that analyzes risks at multiple levels of analysis.

**结果:** The proposed framework identifies real-time, individual, and societal risks arising from collaborative cognition and provides concrete metrics for risk evaluation.

**结论:** As AI thought partners become more prevalent, it is crucial to implement mitigation strategies to prevent major harms and ensure human benefit from productive thought partnerships.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Identifying%2C+Evaluating%2C+and+Mitigating+Risks+of+AI+Thought+Partnerships，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16899&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) systems have historically been used as tools
that execute narrowly defined tasks. Yet recent advances in AI have unlocked
possibilities for a new class of models that genuinely collaborate with humans
in complex reasoning, from conceptualizing problems to brainstorming solutions.
Such AI thought partners enable novel forms of collaboration and extended
cognition, yet they also pose major risks-including and beyond risks of typical
AI tools and agents. In this commentary, we systematically identify risks of AI
thought partners through a novel framework that identifies risks at multiple
levels of analysis, including Real-time, Individual, and Societal risks arising
from collaborative cognition (RISc). We leverage this framework to propose
concrete metrics for risk evaluation, and finally suggest specific mitigation
strategies for developers and policymakers. As AI thought partners continue to
proliferate, these strategies can help prevent major harms and ensure that
humans actively benefit from productive thought partnerships.

</details>


### [174] [Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning](https://arxiv.org/abs/2505.16928)
*Bosung Kim, Prithviraj Ammanabrolu*

**主要类别:** cs.AI

**概要:** 提出了一种新的框架∞-THOR用于长时序具身任务，该框架能够生成可扩展、可重复且无限的长时序轨迹，并引入了需要长期上下文推理的新具身QA任务和数据集。为了支持这种能力，研究了架构上的调整如目标状态动作建模、上下文扩展技术和上下文并行性等。实验结果分析了基准测试带来的挑战并提供了关于长时序条件下训练策略和模型行为的见解。这项工作为下一代能够进行稳健长期推理和规划的具身AI系统奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 解决具身AI在长时序理解方面的能力不足问题。

**方法:** 提出了∞-THOR框架，包括生成长时序轨迹的方法、新的具身QA任务以及针对LLM代理进行极端长时序推理和交互的架构调整（如Goal-State-Action建模、上下文扩展和技术）。

**结果:** 开发了一个长时序数据集和基准套件，包含跨越数百个环境步骤的复杂任务，每个任务都有与之配对的地面真实动作序列。

**结论:** 为下一代能够进行稳健长期推理和规划的具身AI系统奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Needle%28s%29+in+the+Embodied+Haystack%3A+Environment%2C+Architecture%2C+and+Training+Considerations+for+Long+Context+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16928，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16928&send_immediately=true&force_search=false)

**原文摘要:** We introduce $\infty$-THOR, a new framework for long-horizon embodied tasks
that advances long-context understanding in embodied AI. $\infty$-THOR
provides: (1) a generation framework for synthesizing scalable, reproducible,
and unlimited long-horizon trajectories; (2) a novel embodied QA task,
Needle(s) in the Embodied Haystack, where multiple scattered clues across
extended trajectories test agents' long-context reasoning ability; and (3) a
long-horizon dataset and benchmark suite featuring complex tasks that span
hundreds of environment steps, each paired with ground-truth action sequences.
To enable this capability, we explore architectural adaptations, including
interleaved Goal-State-Action modeling, context extension techniques, and
Context Parallelism, to equip LLM-based agents for extreme long-context
reasoning and interaction. Experimental results and analyses highlight the
challenges posed by our benchmark and provide insights into training strategies
and model behaviors under long-horizon conditions. Our work provides a
foundation for the next generation of embodied AI systems capable of robust,
long-term reasoning and planning.

</details>


### [175] [NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://arxiv.org/abs/2505.16938)
*NovelSeek Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Runmin Ma, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai*

**主要类别:** cs.AI

**概要:** A unified closed-loop multi-agent framework called NovelSeek is introduced for Autonomous Scientific Research across various fields.


<details>
  <summary>更多</summary>
  
**动机:** Enhancing research efficiency and driving innovation in scientific research.

**方法:** Introducing NovelSeek, a unified closed-loop multi-agent framework.

**结果:** NovelSeek has shown scalability, interactivity, and efficiency across multiple scientific research tasks, achieving significant performance improvements.

**结论:** NovelSeek can accelerate scientific research and improve performance in diverse fields with less time cost.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NovelSeek%3A+When+Agent+Becomes+the+Scientist+--+Building+Closed-Loop+System+from+Hypothesis+to+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16938，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16938&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) is accelerating the transformation of scientific
research paradigms, not only enhancing research efficiency but also driving
innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework
to conduct Autonomous Scientific Research (ASR) across various scientific
research fields, enabling researchers to tackle complicated problems in these
fields with unprecedented speed and precision. NovelSeek highlights three key
advantages: 1) Scalability: NovelSeek has demonstrated its versatility across
12 scientific research tasks, capable of generating innovative ideas to enhance
the performance of baseline code. 2) Interactivity: NovelSeek provides an
interface for human expert feedback and multi-agent interaction in automated
end-to-end processes, allowing for the seamless integration of domain expert
knowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in
several scientific fields with significantly less time cost compared to human
efforts. For instance, in reaction yield prediction, it increased from 27.6% to
35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from
0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,
precision advanced from 78.8% to 81.0% in a mere 30 hours.

</details>


### [176] [AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios](https://arxiv.org/abs/2505.16944)
*Yunjia Qi, Hao Peng, Xiaozhi Wang, Amy Xin, Youfeng Liu, Bin Xu, Lei Hou, Juanzi Li*

**主要类别:** cs.AI

**概要:** 评估大型语言模型在代理场景中的指令跟随能力的第一个基准测试AgentIF。


<details>
  <summary>更多</summary>
  
**动机:** 现有大型语言模型在处理复杂约束结构和工具规范方面表现不佳。

**方法:** 收集了707个人类注释的指令，并标注了相应的约束和评估指标。

**结果:** AgentIF展示了当前模型在处理复杂约束方面的不足。

**结论:** 发布代码和数据以促进未来研究，并进行了错误分析和实验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AGENTIF%3A+Benchmarking+Instruction+Following+of+Large+Language+Models+in+Agentic+Scenarios，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16944，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16944&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated advanced capabilities in
real-world agentic applications. Growing research efforts aim to develop
LLM-based agents to address practical demands, introducing a new challenge:
agentic scenarios often involve lengthy instructions with complex constraints,
such as extended system prompts and detailed tool specifications. While
adherence to such instructions is crucial for agentic applications, whether
LLMs can reliably follow them remains underexplored. In this paper, we
introduce AgentIF, the first benchmark for systematically evaluating LLM
instruction following ability in agentic scenarios. AgentIF features three key
characteristics: (1) Realistic, constructed from 50 real-world agentic
applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.
(3) Complex, averaging 11.9 constraints per instruction, covering diverse
constraint types, such as tool specifications and condition constraints. To
construct AgentIF, we collect 707 human-annotated instructions across 50
agentic tasks from industrial application agents and open-source agentic
systems. For each instruction, we annotate the associated constraints and
corresponding evaluation metrics, including code-based evaluation, LLM-based
evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically
evaluate existing advanced LLMs. We observe that current models generally
perform poorly, especially in handling complex constraint structures and tool
specifications. We further conduct error analysis and analytical experiments on
instruction length and meta constraints, providing some findings about the
failure modes of existing LLMs. We have released the code and data to
facilitate future research.

</details>


### [177] [HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation](https://arxiv.org/abs/2505.16978)
*Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle*

**主要类别:** cs.AI

**概要:** 研究了大型语言模型在少量样本语法生成中的能力，并提出了HyGenar算法来优化语法生成。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在许多领域表现出色，但其推断和生成语法的能力尚未得到充分探索。

**方法:** 创建了一个包含540个结构化语法生成挑战的数据集，设计了6个度量标准，并评估了8种不同的大型语言模型。提出了一种新的混合遗传算法HyGenar来优化语法生成。

**结果:** 现有的大型语言模型在语法生成方面表现不佳。HyGenar显著提高了语法生成的句法和语义正确性。

**结论:** 本研究强调了现有大型语言模型在语法生成方面的不足，并通过提出HyGenar算法展示了显著改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HyGenar%3A+An+LLM-Driven+Hybrid+Genetic+Algorithm+for+Few-Shot+Grammar+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16978，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16978&send_immediately=true&force_search=false)

**原文摘要:** Grammar plays a critical role in natural language processing and text/code
generation by enabling the definition of syntax, the creation of parsers, and
guiding structured outputs. Although large language models (LLMs) demonstrate
impressive capabilities across domains, their ability to infer and generate
grammars has not yet been thoroughly explored. In this paper, we aim to study
and improve the ability of LLMs for few-shot grammar generation, where grammars
are inferred from sets of a small number of positive and negative examples and
generated in Backus-Naur Form. To explore this, we introduced a novel dataset
comprising 540 structured grammar generation challenges, devised 6 metrics, and
evaluated 8 various LLMs against it. Our findings reveal that existing LLMs
perform sub-optimally in grammar generation. To address this, we propose an
LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar
generation. HyGenar achieves substantial improvements in both the syntactic and
semantic correctness of generated grammars across LLMs.

</details>


### [178] [Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design](https://arxiv.org/abs/2505.16979)
*Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang*

**主要类别:** cs.AI

**概要:** 提出Know-The-Ropes (KtR)框架，通过领域先验生成算法蓝图层次结构，实现任务的递归分解和轻量级增强，显著提升多智能体系统在背包问题和任务分配问题上的性能。


<details>
  <summary>更多</summary>
  
**动机:** 单智能体大语言模型存在上下文有限、角色超载和领域迁移脆弱等问题；传统多智能体解决方案虽有所改善但引入了新的问题如任务分解不当等。

**方法:** 设计Know-The-Ropes (KtR)框架，基于No-Free-Lunch定理，将领域先验转化为算法蓝图层次结构，任务被递归分解为类型化的子任务，并通过轻量级增强解决子任务。

**结果:** 在背包问题上，三代理系统准确率从零-shot的3%提升到95%；在任务分配问题上，六代理系统的准确率达到100%（最多10个任务）和84%（13-15个任务），而零-shot仅为11%。

**结论:** KtR框架证明了通过有意识的任务分解和针对性增强，即使是较小的模型也能成为可靠的合作者，无需依赖更大的单一模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Know+the+Ropes%3A+A+Heuristic+Strategy+for+LLM-based+Multi-Agent+System+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16979，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16979&send_immediately=true&force_search=false)

**原文摘要:** Single-agent LLMs hit hard limits--finite context, role overload, and brittle
domain transfer. Conventional multi-agent fixes soften those edges yet expose
fresh pains: ill-posed decompositions, fuzzy contracts, and verification
overhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a
framework that converts domain priors into an algorithmic blueprint hierarchy,
in which tasks are recursively split into typed, controller-mediated subtasks,
each solved zero-shot or with the lightest viable boost (e.g.,
chain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch
theorem, KtR trades the chase for a universal prompt for disciplined
decomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents
raise accuracy from 3% zero-shot to 95% on size-5 instances after patching a
single bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a
six-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,
versus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation
thus turns modest models into reliable collaborators--no ever-larger monoliths
required.

</details>


### [179] [Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine](https://arxiv.org/abs/2505.16982)
*Adib Bazgir, Amir Habibdoust Lafmajani, Yuwen Zhang*

**主要类别:** cs.AI

**概要:** 本文提出了因果语言模型(Causal LLM)的概念，这种模型能够整合多模态数据并进行干预推理来推断因果关系。研究面临的主要挑战包括设计安全可控的代理框架、开发严格的因果评估基准、整合异构数据源以及协同结合LLMs与结构化知识和因果推理工具。这类模型有望通过自动化假设生成和模拟加速药物发现，并推动个性化医疗的发展。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型语言模型在生物医学领域表现出潜力，但缺乏真正的因果理解，主要依赖于相关性。因此需要开发能够进行因果推理的语言模型。

**方法:** 文中设想了因果语言模型(Causal LLM)，该模型能够整合多模态数据(文本、图像、基因组学等)并进行基于干预的推理来推断因果关系。

**结果:** 文中讨论了实现这一目标所面临的四个关键挑战：设计安全可控的代理框架、开发严格的因果评估基准、整合异构数据源以及协同结合LLMs与结构化知识和正式因果推理工具。

**结论:** 这项研究议程旨在促进跨学科努力，将因果概念和基础模型相结合，以开发可靠的人工智能合作伙伴，推动生物医学的进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Correlation%3A+Towards+Causal+Large+Language+Model+Agents+in+Biomedicine，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16982，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16982&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) show promise in biomedicine but lack true causal
understanding, relying instead on correlations. This paper envisions causal LLM
agents that integrate multimodal data (text, images, genomics, etc.) and
perform intervention-based reasoning to infer cause-and-effect. Addressing this
requires overcoming key challenges: designing safe, controllable agentic
frameworks; developing rigorous benchmarks for causal evaluation; integrating
heterogeneous data sources; and synergistically combining LLMs with structured
knowledge (KGs) and formal causal inference tools. Such agents could unlock
transformative opportunities, including accelerating drug discovery through
automated hypothesis generation and simulation, enabling personalized medicine
through patient-specific causal models. This research agenda aims to foster
interdisciplinary efforts, bridging causal concepts and foundation models to
develop reliable AI partners for biomedical progress.

</details>


### [180] [X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs](https://arxiv.org/abs/2505.16997)
*Rui Ye, Xiangrui Liu, Qimin Wu, Xianghe Pang, Zhenfei Yin, Lei Bai, Siheng Chen*

**主要类别:** cs.AI

**概要:** This paper introduces X-MAS, a new paradigm for multi-agent systems driven by diverse large language models (LLMs). It evaluates 27 LLMs across 5 domains and 5 functions, demonstrating significant performance improvements in heterogeneous configurations.


<details>
  <summary>更多</summary>
  
**动机:** Existing multi-agent systems are limited by the intelligence of a single LLM. This paper aims to explore the use of diverse LLMs to enhance system intelligence.

**方法:** The authors introduce X-MAS-Bench, a testbed to evaluate LLMs in different domains and functions. They conduct over 1.7 million evaluations to determine optimal model selections.

**结果:** Heterogeneous LLM-driven MAS shows significant performance improvements, with up to 8.4% in chatbot scenarios and 47% in mixed chatbot-reasoner scenarios.

**结论:** Transitioning to heterogeneous LLM-driven MAS can significantly enhance system performance without requiring structural changes, opening a path for scalable, collaborative AI systems.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X-MAS%3A+Towards+Building+Multi-Agent+Systems+with+Heterogeneous+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16997&send_immediately=true&force_search=false)

**原文摘要:** LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by
enabling cooperation among multiple specialized agents. However, most existing
MAS frameworks rely on a single LLM to drive all agents, constraining the
system's intelligence to the limit of that model. This paper explores the
paradigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by
diverse LLMs, elevating the system's potential to the collective intelligence
of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to
evaluate the performance of various LLMs across different domains and
MAS-related functions. As an extensive empirical study, we assess 27 LLMs
across 5 domains (encompassing 21 test sets) and 5 functions, conducting over
1.7 million evaluations to identify optimal model selections for each
domain-function combination. Building on these findings, we demonstrate that
transitioning from homogeneous to heterogeneous LLM-driven MAS can
significantly enhance system performance without requiring structural redesign.
Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration
yields up to 8.4\% performance improvement on the MATH dataset. In a mixed
chatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable
47\% performance boost on the AIME dataset. Our results underscore the
transformative potential of heterogeneous LLMs in MAS, highlighting a promising
avenue for advancing scalable, collaborative AI systems.

</details>


### [181] [Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning](https://arxiv.org/abs/2505.14403)
*Zhaohui Yang, Shilei Jiang, Chen Hu, Linjing Li, Shihong Deng, Daxin Jiang*

**主要类别:** cs.AI

**概要:** This paper introduces BCPG-NSA, an approach that improves the efficiency of training long Chain-of-Thought (CoT) reasoning language models by leveraging negative samples, showing better performance than existing methods on math and coding reasoning tasks.


<details>
  <summary>更多</summary>
  
**动机:** Existing methods fail to utilize valuable components in negative responses, such as self-reflection and error-correction steps, due to their high computational cost and inefficient handling of negative samples.

**方法:** BCPG-NSA, which includes sample segmentation, consensus-based step correctness assessment, and policy optimization with Negative Sample Augmentation to extract positive learning signals from negative samples.

**结果:** BCPG-NSA outperforms baselines on math and coding reasoning benchmarks using the same training dataset, showing improved sample efficiency and robustness across multiple iterations.

**结论:** The proposed method demonstrates the importance of utilizing negative samples in improving the training of long CoT reasoning language models, offering better performance and efficiency.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unearthing+Gems+from+Stones%3A+Policy+Optimization+with+Negative+Sample+Augmentation+for+LLM+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.14403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.14403&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in reasoning language models have witnessed a paradigm shift
from short to long CoT pattern. Given the substantial computational cost of
rollouts in long CoT models, maximizing the utility of fixed training datasets
becomes crucial. Our analysis reveals that negative responses contain valuable
components such as self-reflection and error-correction steps, yet primary
existing methods either completely discard negative samples (RFT) or apply
equal penalization across all tokens (RL), failing to leverage these potential
learning signals. In light of this, we propose Behavior Constrained Policy
Gradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline
RL framework that encompasses three stages: 1) sample segmentation, 2)
consensus-based step correctness assessment combining LLM and PRM judgers, and
3) policy optimization with NSA designed to effectively mine positive steps
within negative samples. Experimental results show that BCPG-NSA outperforms
baselines on several challenging math/coding reasoning benchmarks using the
same training dataset, achieving improved sample efficiency and demonstrating
robustness and scalability when extended to multiple iterations.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [182] [CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision](https://arxiv.org/abs/2505.15927)
*Awni Altabaa, Omar Montasser, John Lafferty*

**主要类别:** stat.ML

**概要:** 本文发展了链式思维（CoT）监督下的统计学习理论，表明CoT监督能显著提升学习效率，并引入了新的度量来量化推理过程的额外辨别能力。


<details>
  <summary>更多</summary>
  
**动机:** 标准监督学习在处理涉及多步推理的复杂函数时面临挑战，而CoT监督提供了中间推理步骤和最终输出，推动了大型语言模型推理能力的进步。

**方法:** 引入了CoT信息度量来量化观察推理过程获得的额外辨别能力，并通过此度量得到了样本复杂度的更紧界。

**结果:** 证明了CoT监督下学习的样本复杂度比标准端到端（E2E）监督下的更快，且得到了CoT信息的信息论下界。

**结论:** 提出了一种统计理论来解释链式思维（CoT）监督下的学习过程，并表明CoT监督可以显著加快学习速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoT+Information%3A+Improved+Sample+Complexity+under+Chain-of-Thought+Supervision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15927&send_immediately=true&force_search=false)

**原文摘要:** Learning complex functions that involve multi-step reasoning poses a
significant challenge for standard supervised learning from input-output
examples. Chain-of-thought (CoT) supervision, which provides intermediate
reasoning steps together with the final output, has emerged as a powerful
empirical technique, underpinning much of the recent progress in the reasoning
capabilities of large language models. This paper develops a statistical theory
of learning under CoT supervision. A key characteristic of the CoT setting, in
contrast to standard supervision, is the mismatch between the training
objective (CoT risk) and the test objective (end-to-end risk). A central part
of our analysis, distinguished from prior work, is explicitly linking those two
types of risk to achieve sharper sample complexity bounds. This is achieved via
the *CoT information measure* $\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, which quantifies the additional
discriminative power gained from observing the reasoning process. The main
theoretical results demonstrate how CoT supervision can yield significantly
faster learning rates compared to standard E2E supervision. Specifically, it is
shown that the sample complexity required to achieve a target E2E error
$\epsilon$ scales as $d/\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, where $d$ is a measure of hypothesis
class complexity, which can be much faster than standard $d/\epsilon$ rates.
Information-theoretic lower bounds in terms of the CoT information are also
obtained. Together, these results suggest that CoT information is a fundamental
measure of statistical complexity for learning under chain-of-thought
supervision.

</details>


### [183] [PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals](https://arxiv.org/abs/2505.16051)
*Dongze Wu, David I. Inouye, Yao Xie*

**主要类别:** stat.ML

**概要:** 提出了一种名为PO-Flow的新框架，用于因果推理，它联合建模潜在结果和反事实，并在多个基准数据集上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在处理潜在结果的密度学习时通常需要明确的分布假设，且反事实预测的能力有限。

**方法:** PO-Flow是一种连续归一化流（CNF）框架，通过流匹配进行训练，提供了一个统一的模型来预测个体化的潜在结果、反事实预测以及不确定性感知的密度学习。

**结果:** 在ACIC、IHDP和IBM等基准数据集上，PO-Flow在多种因果推理任务中优于先前的方法，并且能够在高维设置下成功运行，如反事实图像生成。

**结论:** PO-Flow展示了其在因果推理中的广泛适用性，特别是在不需要明确分布假设的情况下对潜在结果进行密度学习的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PO-Flow%3A+Flow-based+Generative+Models+for+Sampling+Potential+Outcomes+and+Counterfactuals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16051，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16051&send_immediately=true&force_search=false)

**原文摘要:** We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for
causal inference that jointly models potential outcomes and counterfactuals.
Trained via flow matching, PO-Flow provides a unified framework for
individualized potential outcome prediction, counterfactual predictions, and
uncertainty-aware density learning. Among generative models, it is the first to
enable density learning of potential outcomes without requiring explicit
distributional assumptions (e.g., Gaussian mixtures), while also supporting
counterfactual prediction conditioned on factual outcomes in general
observational datasets. On benchmarks such as ACIC, IHDP, and IBM, it
consistently outperforms prior methods across a range of causal inference
tasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including
counterfactual image generation, demonstrating its broad applicability.

</details>


### [184] [Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schrödinger Bridge's End](https://arxiv.org/abs/2505.16082)
*Renato Berlinghieri, Yunyi Shen, Jialong Jiang, Tamara Broderick*

**主要类别:** stat.ML

**概要:** This paper introduces SnapMMD, a new framework for forecasting beyond observed time horizons using 'snapshot' data by learning dynamics through maximum mean discrepancy (MMD) loss, which allows inferring unknown and state-dependent volatilities from the data.


<details>
  <summary>更多</summary>
  
**动机:** Existing Schrödinger-bridge (SB) methods do not address forecasting well due to limitations like following pre-set reference dynamics or requiring fixed, state-independent volatility.

**方法:** SnapMMD learns dynamics by directly fitting the joint distribution of state measurements and observation time with MMD loss, enabling inference of unknown and state-dependent volatilities.

**结果:** SnapMMD provides accurate forecasts in various real and synthetic experiments, handles incomplete state measurements, and offers an R²-style statistic for diagnosing fit. Its interpolation and velocity-field reconstruction performance is at least as good as or better than state-of-the-art methods.

**结论:** The proposed SnapMMD framework effectively addresses forecasting challenges with 'snapshot' data by learning dynamics and inferring volatilities, outperforming or matching current methods in multiple experiments.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Oh+SnapMMD%21+Forecasting+Stochastic+Dynamics+Beyond+the+Schr%C3%B6dinger+Bridge%27s+End，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16082，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16082&send_immediately=true&force_search=false)

**原文摘要:** Scientists often want to make predictions beyond the observed time horizon of
"snapshot" data following latent stochastic dynamics. For example, in time
course single-cell mRNA profiling, scientists have access to cellular
transcriptional state measurements (snapshots) from different biological
replicates at different time points, but they cannot access the trajectory of
any one cell because measurement destroys the cell. Researchers want to
forecast (e.g.) differentiation outcomes from early state measurements of stem
cells. Recent Schr\"odinger-bridge (SB) methods are natural for interpolating
between snapshots. But past SB papers have not addressed forecasting -- likely
since existing methods either (1) reduce to following pre-set reference
dynamics (chosen before seeing data) or (2) require the user to choose a fixed,
state-independent volatility since they minimize a Kullback-Leibler divergence.
Either case can lead to poor forecasting quality. In the present work, we
propose a new framework, SnapMMD, that learns dynamics by directly fitting the
joint distribution of both state measurements and observation time with a
maximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to
infer unknown and state-dependent volatilities from the observed data. We show
in a variety of real and synthetic experiments that our method delivers
accurate forecasts. Moreover, our approach allows us to learn in the presence
of incomplete state measurements and yields an $R^2$-style statistic that
diagnoses fit. We also find that our method's performance at interpolation (and
general velocity-field reconstruction) is at least as good as (and often better
than) state-of-the-art in almost all of our experiments.

</details>


### [185] [Dimension-adapted Momentum Outscales SGD](https://arxiv.org/abs/2505.16098)
*Damien Ferbach, Katie Everett, Gauthier Gidel, Elliot Paquette, Courtney Paquette*

**主要类别:** stat.ML

**概要:** 研究了随机动量算法在幂律随机特征模型中的缩放规律，提出了维度适应的Nesterov加速(DANA)，该方法在多种数据和目标复杂度下改善了计算最优缩放行为。


<details>
  <summary>更多</summary>
  
**动机:** 研究随机动量算法在不同复杂度下的缩放规律，并寻找改进传统方法的方法。

**方法:** 分析了带有小批量的随机动量算法的缩放规律，提出维度适应的Nesterov加速(DANA)方法。

**结果:** DANA改善了缩放律指数，并在高维合成二次问题和LSTM文本实验中验证了理论预测。

**结论:** 维度适应的Nesterov加速(DANA)在多种复杂度下表现出优越的计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dimension-adapted+Momentum+Outscales+SGD，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16098&send_immediately=true&force_search=false)

**原文摘要:** We investigate scaling laws for stochastic momentum algorithms with small
batch on the power law random features model, parameterized by data complexity,
target complexity, and model size. When trained with a stochastic momentum
algorithm, our analysis reveals four distinct loss curve shapes determined by
varying data-target complexities. While traditional stochastic gradient descent
with momentum (SGD-M) yields identical scaling law exponents to SGD,
dimension-adapted Nesterov acceleration (DANA) improves these exponents by
scaling momentum hyperparameters based on model size and data complexity. This
outscaling phenomenon, which also improves compute-optimal scaling behavior, is
achieved by DANA across a broad range of data and target complexities, while
traditional methods fall short. Extensive experiments on high-dimensional
synthetic quadratics validate our theoretical predictions and large-scale text
experiments with LSTMs show DANA's improved loss exponents over SGD hold in a
practical setting.

</details>


### [186] [Exponential Convergence of CAVI for Bayesian PCA](https://arxiv.org/abs/2505.16145)
*Arghya Datta, Philippe Gagnon, Florian Maire*

**主要类别:** stat.ML

**概要:** 本研究探讨了贝叶斯主成分分析(BPCA)中坐标上升变分推断(CAVI)的收敛速度，证明了其在不同情况下的指数收敛性，并提出了一种新的对称KL散度下界。


<details>
  <summary>更多</summary>
  
**动机:** 目前文献中尚未明确描述CAVI在BPCA中的收敛速度，因此本文旨在填补这一空白。

**方法:** 通过与经典幂迭代算法的联系证明了单个主成分情况下指数收敛性，并利用最近的工具证明了任意数量主成分情况下的指数收敛性。同时，为了证明后者，引入了一个新的多元正态分布之间的对称KL散度下界。

**结果:** 证明了CAVI在BPCA模型中的指数收敛性，无论是单个主成分还是任意数量的主成分，并且提出了一个关于多元正态分布之间对称KL散度的新下界。

**结论:** 我们证明了CAVI在BPCA中的指数收敛性，对于单个主成分和任意数量的主成分情况。此外，还引入了一个新的多元正态分布之间的对称KL散度下界，这在信息论中有独立兴趣。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exponential+Convergence+of+CAVI+for+Bayesian+PCA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16145，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16145&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic principal component analysis (PCA) and its Bayesian variant
(BPCA) are widely used for dimension reduction in machine learning and
statistics. The main advantage of probabilistic PCA over the traditional
formulation is allowing uncertainty quantification. The parameters of BPCA are
typically learned using mean-field variational inference, and in particular,
the coordinate ascent variational inference (CAVI) algorithm. So far, the
convergence speed of CAVI for BPCA has not been characterized. In our paper, we
fill this gap in the literature. Firstly, we prove a precise exponential
convergence result in the case where the model uses a single principal
component (PC). Interestingly, this result is established through a connection
with the classical $\textit{power iteration algorithm}$ and it indicates that
traditional PCA is retrieved as points estimates of the BPCA parameters.
Secondly, we leverage recent tools to prove exponential convergence of CAVI for
the model with any number of PCs, thus leading to a more general result, but
one that is of a slightly different flavor. To prove the latter result, we
additionally needed to introduce a novel lower bound for the symmetric
Kullback--Leibler divergence between two multivariate normal distributions,
which, we believe, is of independent interest in information theory.

</details>


### [187] [Integral Imprecise Probability Metrics](https://arxiv.org/abs/2505.16156)
*Siu Lun Chau, Michele Caprio, Krikamol Muandet*

**主要类别:** stat.ML

**概要:** 提出了一种基于Choquet积分的广义经典积分概率度量(IIPM)框架，用于处理不确定性模型。理论上证明了IIPM作为有效度量的条件，并支持容量弱收敛的度量化。实践中，IIPM不仅能够跨不同IP模型比较，还能在一个单一IP模型内量化认识论不确定性，从而产生新的认识论不确定性度量。在选择性分类实验中验证了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的经典概率方法无法充分表示认识论不确定性(EU)，需要更丰富的表示形式。

**方法:** 引入了基于Choquet积分的广义积分概率度量(IIPM)框架，适用于能力(capacity)这一广泛类别的不精确概率(IP)模型。

**结果:** 理论上证明了IIPM作为度量的有效性及其对容量弱收敛的度量化；实践上展示了IIPM在跨模型比较和单模型内EU量化的能力，并提出了新的EU度量——最大均值不精确性(MMI)，并在实验中表现出色。

**结论:** 本研究通过提出IIPM框架，推进了不精确概率机器学习领域的理论与实践，为处理不精确下的认识论不确定性提供了原则性框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Integral+Imprecise+Probability+Metrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16156，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16156&send_immediately=true&force_search=false)

**原文摘要:** Quantifying differences between probability distributions is fundamental to
statistics and machine learning, primarily for comparing statistical
uncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete
knowledge -- requires richer representations than those offered by classical
probability. Imprecise probability (IP) theory offers such models, capturing
ambiguity and partial belief. This has driven growing interest in imprecise
probabilistic machine learning (IPML), where inference and decision-making rely
on broader uncertainty models -- highlighting the need for metrics beyond
classical probability. This work introduces the Integral Imprecise Probability
Metric (IIPM) framework, a Choquet integral-based generalisation of classical
Integral Probability Metric (IPM) to the setting of capacities -- a broad class
of IP models encompassing many existing ones, including lower probabilities,
probability intervals, belief functions, and more. Theoretically, we establish
conditions under which IIPM serves as a valid metric and metrises a form of
weak convergence of capacities. Practically, IIPM not only enables comparison
across different IP models but also supports the quantification of epistemic
uncertainty within a single IP model. In particular, by comparing an IP model
with its conjugate, IIPM gives rise to a new class of EU measures -- Maximum
Mean Imprecision -- which satisfy key axiomatic properties proposed in the
Uncertainty Quantification literature. We validate MMI through selective
classification experiments, demonstrating strong empirical performance against
established EU measures, and outperforming them when classical methods struggle
to scale to a large number of classes. Our work advances both theory and
practice in IPML, offering a principled framework for comparing and quantifying
epistemic uncertainty under imprecision.

</details>


### [188] [Generalized Power Priors for Improved Bayesian Inference with Historical Data](https://arxiv.org/abs/2505.16244)
*Masanari Kimura, Howard Bondell*

**主要类别:** stat.ML

**概要:** 本文扩展了幂先验框架，将其与Amari的α-散度相结合，展示了如何通过适当选择α参数来提高性能，并证明了广义幂后验的一些理论性质。


<details>
  <summary>更多</summary>
  
**动机:** 在贝叶斯框架中结合历史数据和当前数据的需求。

**方法:** 将幂先验框架与Amari的α-散度相结合。

**结果:** 证明了广义幂后验可以作为概率分布黎曼流形上的广义测地线，提供了新的几何解释。

**结论:** 本研究为幂先验框架提供了新的视角，可能带来更好的性能和更深入的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalized+Power+Priors+for+Improved+Bayesian+Inference+with+Historical+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16244&send_immediately=true&force_search=false)

**原文摘要:** The power prior is a class of informative priors designed to incorporate
historical data alongside current data in a Bayesian framework. It includes a
power parameter that controls the influence of historical data, providing
flexibility and adaptability. A key property of the power prior is that the
resulting posterior minimizes a linear combination of KL divergences between
two pseudo-posterior distributions: one ignoring historical data and the other
fully incorporating it. We extend this framework by identifying the posterior
distribution as the minimizer of a linear combination of Amari's
$\alpha$-divergence, a generalization of KL divergence. We show that this
generalization can lead to improved performance by allowing for the data to
adapt to appropriate choices of the $\alpha$ parameter. Theoretical properties
of this generalized power posterior are established, including behavior as a
generalized geodesic on the Riemannian manifold of probability distributions,
offering novel insights into its geometric interpretation.

</details>


### [189] [Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry](https://arxiv.org/abs/2505.16251)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** 本文提出了一种新的方法GS-B³SE，用于解决标签偏移适应问题，改进了经典的黑盒移位估计器，具有更好的理论性质和实际应用潜力。


<details>
  <summary>更多</summary>
  
**动机:** 当标记源分布P和未标记目标分布Q共享P(X|Y)=Q(X|Y)但P(Y)≠Q(Y)时，经典黑盒移位估计器通过冻结分类器的经验混淆矩阵进行反演，产生一个易碎的点估计，忽略采样噪声和类之间的相似性。

**方法:** GS-B³SE方法，在目标log-priors和混淆矩阵列上放置Laplacian-Gaussian先验，利用标签相似性图连接两者，使用HMC或快速块Newton-CG方案处理后验。

**结果:** 提出的方法在理论上有良好的性质，包括可识别性、收敛性、方差界限和鲁棒性，并且从信息几何的角度重新解释了GS-B³SE，表明它推广了现有的移位估计器。

**结论:** 提出了GS-B³SE方法，该方法通过在目标先验和混淆矩阵列上放置拉普拉斯-高斯先验，与标签相似性图结合，提供了一个完全概率性的替代方案。证明了其可识别性、收敛性、方差界限以及对拉普拉斯误指定的鲁棒性，并重新解释了GS-B³SE的信息几何意义，表明其推广了现有的移位估计器。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-Smoothed+Bayesian+Black-Box+Shift+Estimator+and+Its+Information+Geometry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16251，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16251&send_immediately=true&force_search=false)

**原文摘要:** Label shift adaptation aims to recover target class priors when the labelled
source distribution $P$ and the unlabelled target distribution $Q$ share $P(X
\mid Y) = Q(X \mid Y)$ but $P(Y) \neq Q(Y)$. Classical black-box shift
estimators invert an empirical confusion matrix of a frozen classifier,
producing a brittle point estimate that ignores sampling noise and similarity
among classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully
probabilistic alternative that places Laplacian-Gaussian priors on both target
log-priors and confusion-matrix columns, tying them together on a
label-similarity graph. The resulting posterior is tractable with HMC or a fast
block Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,
variance bounds that shrink with the graph's algebraic connectivity, and
robustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE
through information geometry, showing that it generalizes existing shift
estimators.

</details>


### [190] [Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics](https://arxiv.org/abs/2505.16257)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** This study develops a new framework for adapting Batch Normalization statistics during testing under distribution shift using advanced statistical methods.


<details>
  <summary>更多</summary>
  
**动机:** To improve the reliability and performance of Batch Normalization layers when adapting to changing data distributions.

**方法:** Integrating Edgeworth expansion, saddlepoint approximation, and a novel one-step M-estimation perspective.

**结果:** Derives an optimal weighting parameter, higher-order local asymptotic normality results, and quantifies trade-offs among bias, variance, and skewness. Provides uniformly accurate density and tail probability estimates.

**结论:** Higher-order corrections and robust one-step updating can significantly enhance the reliability and performance of BN layers under distribution shift.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Higher-Order+Asymptotics+of+Test-Time+Adaptation+for+Batch+Normalization+Statistics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16257，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16257&send_immediately=true&force_search=false)

**原文摘要:** This study develops a higher-order asymptotic framework for test-time
adaptation (TTA) of Batch Normalization (BN) statistics under distribution
shift by integrating classical Edgeworth expansion and saddlepoint
approximation techniques with a novel one-step M-estimation perspective. By
analyzing the statistical discrepancy between training and test distributions,
we derive an Edgeworth expansion for the normalized difference in BN means and
obtain an optimal weighting parameter that minimizes the mean-squared error of
the adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows
us to derive higher-order local asymptotic normality results, which incorporate
skewness and other higher moments into the estimator's behavior. Moreover, we
quantify the trade-offs among bias, variance, and skewness in the adaptation
process and establish a corresponding generalization bound on the model risk.
The refined saddlepoint approximations further deliver uniformly accurate
density and tail probability estimates for the BN TTA statistic. These
theoretical insights provide a comprehensive understanding of how higher-order
corrections and robust one-step updating can enhance the reliability and
performance of BN layers in adapting to changing data distributions.

</details>


### [191] [Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions](https://arxiv.org/abs/2505.16311)
*Marc Brooks, Gabriel Durham, Kihyuk Hong, Ambuj Tewari*

**主要类别:** stat.ML

**概要:** This paper presents GAMBITTS, an innovative bandit algorithm for generator-mediated interventions, which enhances policy learning efficiency and outperforms traditional methods in simulated studies.


<details>
  <summary>更多</summary>
  
**动机:** To address the limitations of standard bandit methods in handling the structure introduced by generative AI models in personalized decision systems.

**方法:** Generator-mediated bandit-Thompson sampling (GAMBITTS)

**结果:** GAMBITTS improves policy learning efficiency and demonstrates better performance in simulations compared to conventional algorithms.

**结论:** The paper introduces GAMBITTS, a novel bandit approach tailored for scenarios involving generator-mediated interventions.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generator-Mediated+Bandits%3A+Thompson+Sampling+for+GenAI-Powered+Adaptive+Interventions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16311，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16311&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in generative artificial intelligence (GenAI) models have
enabled the generation of personalized content that adapts to up-to-date user
context. While personalized decision systems are often modeled using bandit
formulations, the integration of GenAI introduces new structure into otherwise
classical sequential learning problems. In GenAI-powered interventions, the
agent selects a query, but the environment experiences a stochastic response
drawn from the generative model. Standard bandit methods do not explicitly
account for this structure, where actions influence rewards only through
stochastic, observed treatments. We introduce generator-mediated
bandit-Thompson sampling (GAMBITTS), a bandit approach designed for this
action/treatment split, using mobile health interventions with large language
model-generated text as a motivating case study. GAMBITTS explicitly models
both the treatment and reward generation processes, using information in the
delivered treatment to accelerate policy learning relative to standard methods.
We establish regret bounds for GAMBITTS by decomposing sources of uncertainty
in treatment and reward, identifying conditions where it achieves stronger
guarantees than standard bandit approaches. In simulation studies, GAMBITTS
consistently outperforms conventional algorithms by leveraging observed
treatments to more accurately estimate expected rewards.

</details>


### [192] [Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping](https://arxiv.org/abs/2505.16329)
*Simone Bombari, Inbar Seroussi, Marco Mondelli*

**主要类别:** stat.ML

**概要:** This paper improves the understanding of differentially private linear regression by analyzing DP-SGD under aggressive clipping, decaying learning rate, and private noise scheduling, bridging the gap between theoretical and practical approaches.


<details>
  <summary>更多</summary>
  
**动机:** To address the discrepancy between theoretical approaches and empirical evidence in optimizing performance of differentially private linear regression.

**方法:** Analyzing DP-SGD using a deterministic equivalent expressed as a family of ordinary differential equations (ODEs) under conditions where clipping frequently occurs.

**结果:** Sharper rates for DP-SGD were obtained, demonstrating the optimality of aggressive clipping, and the benefits of decaying learning rate and private noise scheduling were uncovered.

**结论:** The work bridges the gap between theory and practice in differentially private linear regression by providing insights into optimal settings for DP-SGD.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Better+Rates+for+Private+Linear+Regression+in+the+Proportional+Regime+via+Aggressive+Clipping，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16329，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16329&send_immediately=true&force_search=false)

**原文摘要:** Differentially private (DP) linear regression has received significant
attention in the recent theoretical literature, with several works aimed at
obtaining improved error rates. A common approach is to set the clipping
constant much larger than the expected norm of the per-sample gradients. While
simplifying the analysis, this is however in sharp contrast with what empirical
evidence suggests to optimize performance. Our work bridges this gap between
theory and practice: we provide sharper rates for DP stochastic gradient
descent (DP-SGD) by crucially operating in a regime where clipping happens
frequently. Specifically, we consider the setting where the data is
multivariate Gaussian, the number of training samples $n$ is proportional to
the input dimension $d$, and the algorithm guarantees constant-order zero
concentrated DP. Our method relies on establishing a deterministic equivalent
for the trajectory of DP-SGD in terms of a family of ordinary differential
equations (ODEs). As a consequence, the risk of DP-SGD is bounded between two
ODEs, with upper and lower bounds matching for isotropic data. By studying
these ODEs when $n / d$ is large enough, we demonstrate the optimality of
aggressive clipping, and we uncover the benefits of decaying learning rate and
private noise scheduling.

</details>


### [193] [Learning non-equilibrium diffusions with Schrödinger bridges: from exactly solvable to simulation-free](https://arxiv.org/abs/2505.16644)
*Stephen Y. Zhang, Michael P H Stumpf*

**主要类别:** stat.ML

**概要:** This paper studies the Schrödinger bridge problem for systems driven by a multivariate Ornstein-Uhlenbeck process, proposing an algorithm called mvOU-OTFM that shows improved accuracy and training speed.


<details>
  <summary>更多</summary>
  
**动机:** To extend the Schrödinger bridge problem beyond potential-driven dynamics to include non-conservative forces, particularly relevant for biological systems.

**方法:** Deriving explicit solutions for Gaussian marginals and developing mvOU-OTFM for general marginals using flow and score matching without simulations.

**结果:** mvOU-OTFM demonstrates higher accuracy and faster training times compared to other methods when applied to synthetic and real single-cell data.

**结论:** The proposed method provides a powerful tool for reconstructing the most likely evolution of systems with non-conservative forces.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+non-equilibrium+diffusions+with+Schr%C3%B6dinger+bridges%3A+from+exactly+solvable+to+simulation-free，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16644，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16644&send_immediately=true&force_search=false)

**原文摘要:** We consider the Schr\"odinger bridge problem which, given ensemble
measurements of the initial and final configurations of a stochastic dynamical
system and some prior knowledge on the dynamics, aims to reconstruct the "most
likely" evolution of the system compatible with the data. Most existing
literature assume Brownian reference dynamics and are implicitly limited to
potential-driven dynamics. We depart from this regime and consider reference
processes described by a multivariate Ornstein-Uhlenbeck process with generic
drift matrix $\mathbf{A} \in \mathbb{R}^{d \times d}$. When $\mathbf{A}$ is
asymmetric, this corresponds to a non-equilibrium system with non-conservative
forces at play: this is important for applications to biological systems, which
are naturally exist out-of-equilibrium. In the case of Gaussian marginals, we
derive explicit expressions that characterise the solution of both the static
and dynamic Schr\"odinger bridge. For general marginals, we propose mvOU-OTFM,
a simulation-free algorithm based on flow and score matching for learning the
Schr\"odinger bridge. In application to a range of problems based on synthetic
and real single cell data, we demonstrate that mvOU-OTFM achieves higher
accuracy compared to competing methods, whilst being significantly faster to
train.

</details>


### [194] [Sharp concentration of uniform generalization errors in binary linear classification](https://arxiv.org/abs/2505.16713)
*Shogo Nakakita*

**主要类别:** stat.ML

**概要:** 本文通过等周论证研究了二元线性分类问题中均匀推广误差的集中现象，得出了集中界限，并证明了在广泛设置下误差几乎可以肯定地收敛到其期望值。


<details>
  <summary>更多</summary>
  
**动机:** 研究二元线性分类问题中均匀推广误差的集中现象。

**方法:** 通过等周论证检查二元线性分类问题中均匀推广误差集中在期望周围的程度。特别是，我们为输出标签和标签加权输入向量的联合分布建立了Poincaré和log-Sobolev不等式，并将其应用于推导集中界限。

**结果:** 推导出的集中界限在适度的乘法常数内对于平衡标签而言是尖锐的。在渐进分析中，显示了在非常广泛的设置下，均匀推广误差几乎可以肯定地收敛到其期望值。

**结论:** 几乎可以肯定的是，在各种设置下，包括高维比例设置下，均匀推广误差会收敛到其期望值。此外，我们还建立了无维度条件下的均匀大数定律。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sharp+concentration+of+uniform+generalization+errors+in+binary+linear+classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16713，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16713&send_immediately=true&force_search=false)

**原文摘要:** We examine the concentration of uniform generalization errors around their
expectation in binary linear classification problems via an isoperimetric
argument. In particular, we establish Poincar\'{e} and log-Sobolev inequalities
for the joint distribution of the output labels and the label-weighted input
vectors, which we apply to derive concentration bounds. The derived
concentration bounds are sharp up to moderate multiplicative constants by those
under well-balanced labels. In asymptotic analysis, we also show that almost
sure convergence of uniform generalization errors to their expectation occurs
in very broad settings, such as proportionally high-dimensional regimes. Using
this convergence, we establish uniform laws of large numbers under
dimension-free conditions.

</details>


### [195] [How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning](https://arxiv.org/abs/2505.16879)
*Hannah Sansford, Nick Whiteley, Patrick Rubin-Delanchy*

**主要类别:** stat.ML

**概要:** 提出广义Hanson-Wright不等式，并探讨数据点云几何的新统计见解。分析了数据随机函数模型中的三种维度概念的作用，指出在一定条件下持久图可以揭示潜在同调性并且流形结构会出现。基于这些理论视角，重新审视了网格细胞活动中的环面结构发现，首次提供了证据表明该结构实际上与物理空间等距，意味着网格细胞活动传达了一个对现实世界的几何忠实表示。


<details>
  <summary>更多</summary>
  
**动机:** 提供新的统计方法来理解数据点云的几何特性，并且重新评估一个重要的神经科学发现。

**方法:** 提出了广义Hanson-Wright不等式并应用它来研究数据的几何性质；在一般随机函数模型下分析了三个维度概念的作用。

**结果:** 证明了在一定条件下，持久图可以揭示数据的潜在同调性并且流形结构会显现出来；重新评估了网格细胞活动中的环面结构发现，表明其与物理空间等距。

**结论:** 广义Hanson-Wright不等式有助于深入理解数据点云的几何特性；揭示了网格细胞活动对现实世界几何特征的忠实表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+high+is+%60high%27%3F+Rethinking+the+roles+of+dimensionality+in+topological+data+analysis+and+manifold+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16879，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16879&send_immediately=true&force_search=false)

**原文摘要:** We present a generalised Hanson-Wright inequality and use it to establish new
statistical insights into the geometry of data point-clouds. In the setting of
a general random function model of data, we clarify the roles played by three
notions of dimensionality: ambient intrinsic dimension $p_{\mathrm{int}}$,
which measures total variability across orthogonal feature directions;
correlation rank, which measures functional complexity across samples; and
latent intrinsic dimension, which is the dimension of manifold structure hidden
in data. Our analysis shows that in order for persistence diagrams to reveal
latent homology and for manifold structure to emerge it is sufficient that
$p_{\mathrm{int}}\gg \log n$, where $n$ is the sample size. Informed by these
theoretical perspectives, we revisit the ground-breaking neuroscience discovery
of toroidal structure in grid-cell activity made by Gardner et al. (Nature,
2022): our findings reveal, for the first time, evidence that this structure is
in fact isometric to physical space, meaning that grid cell activity conveys a
geometrically faithful representation of the real world.

</details>


### [196] [Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference](https://arxiv.org/abs/2505.16893)
*Shuichi Nishino, Tomohiro Shiraishi, Teruyuki Katsuoka, Ichiro Takeuchi*

**主要类别:** stat.ML

**概要:** 提出了一种统计测试框架来评估图神经网络解释的有效性，并解决了由于数据双重使用导致的I型错误率增加的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图神经网络解释方法（如显著性图）在面对噪声时可靠性受到质疑。

**方法:** 提出了一个基于选择性推断的统计测试框架来控制I型错误率并提供有效的p值。

**结果:** 在合成和真实数据集上的实验验证了该方法在评估图神经网络解释可靠性方面的有效性。

**结论:** 所提出的方法能够确保显著子图包含有意义的信息，而不是随机的伪影。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Statistical+Test+for+Saliency+Maps+of+Graph+Neural+Networks+via+Selective+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16893&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have gained prominence for their ability to
process graph-structured data across various domains. However, interpreting GNN
decisions remains a significant challenge, leading to the adoption of saliency
maps for identifying influential nodes and edges. Despite their utility, the
reliability of GNN saliency maps has been questioned, particularly in terms of
their robustness to noise. In this study, we propose a statistical testing
framework to rigorously evaluate the significance of saliency maps. Our main
contribution lies in addressing the inflation of the Type I error rate caused
by double-dipping of data, leveraging the framework of Selective Inference. Our
method provides statistically valid $p$-values while controlling the Type I
error rate, ensuring that identified salient subgraphs contain meaningful
information rather than random artifacts. To demonstrate the effectiveness of
our method, we conduct experiments on both synthetic and real-world datasets,
showing its effectiveness in assessing the reliability of GNN interpretations.

</details>


### [197] [TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation](https://arxiv.org/abs/2505.16923)
*Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori*

**主要类别:** stat.ML

**概要:** 提出了一种名为TULiP的不确定性估计方法用于异常检测，该方法基于网络在收敛前的假设扰动，并通过线性化训练动态来限制这种扰动的影响，从而生成不确定性得分。实验表明TULiP在大规模图像分类异常检测基准上表现出最先进的性能，特别是在近分布样本中。


<details>
  <summary>更多</summary>
  
**动机:** 可靠的不确定性估计方法是许多现代异常检测器的基础，对于深度学习模型在开放世界中的安全部署至关重要。

**方法:** 提出了一种新的后验不确定性估计器TULiP，考虑了网络在收敛前的假设扰动，并通过线性化训练动态来计算不确定性得分。

**结果:** TULiP在合成回归和分类数据集上的不确定性边界可视化有效，并且在大规模图像分类异常检测基准上展现了最先进的性能。

**结论:** TULiP提供了一种新的方法来处理开放世界中深度学习模型的不确定性估计问题，特别是对于近分布样本的检测具有显著效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TULiP%3A+Test-time+Uncertainty+Estimation+via+Linearization+and+Weight+Perturbation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16923，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16923&send_immediately=true&force_search=false)

**原文摘要:** A reliable uncertainty estimation method is the foundation of many modern
out-of-distribution (OOD) detectors, which are critical for safe deployments of
deep learning models in the open world. In this work, we propose TULiP, a
theoretically-driven post-hoc uncertainty estimator for OOD detection. Our
approach considers a hypothetical perturbation applied to the network before
convergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Ultimately, our approach computes uncertainty from a set of sampled
predictions. We visualize our bound on synthetic regression and classification
datasets. Furthermore, we demonstrate the effectiveness of TULiP using
large-scale OOD detection benchmarks for image classification. Our method
exhibits state-of-the-art performance, particularly for near-distribution
samples.

</details>


### [198] [Critical Points of Random Neural Networks](https://arxiv.org/abs/2505.17000)
*Simmaco Di Lillo*

**主要类别:** stat.ML

**概要:** 研究了随机神经网络在不同激活函数下的临界点数量随深度增加的变化趋势，在无限宽度限制下推导出固定索引和超过给定阈值的临界点的精确渐近公式。


<details>
  <summary>更多</summary>
  
**动机:** 理解随机神经网络中临界点数量随深度变化的规律，特别是在不同激活函数下的行为。

**方法:** 通过理论分析和数值实验来研究随机神经网络的临界点数量随深度增加的变化规律。

**结果:** 发现了三种不同的区域，取决于协方差在1处的第一导数的值，临界点的数量可能收敛、多项式增长或指数增长。

**结论:** 当正则性条件不满足时，临界点的数量随着映射分辨率的增加而增加，这表明临界点数量可能存在发散。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Critical+Points+of+Random+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17000，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17000&send_immediately=true&force_search=false)

**原文摘要:** This work investigates the expected number of critical points of random
neural networks with different activation functions as the depth increases in
the infinite-width limit. Under suitable regularity conditions, we derive
precise asymptotic formulas for the expected number of critical points of fixed
index and those exceeding a given threshold. Our analysis reveals three
distinct regimes depending on the value of the first derivative of the
covariance evaluated at 1: the expected number of critical points may converge,
grow polynomially, or grow exponentially with depth. The theoretical
predictions are supported by numerical experiments. Moreover, we provide
numerical evidence suggesting that, when the regularity condition is not
satisfied (e.g. for neural networks with ReLU as activation function), the
number of critical points increases as the map resolution increases, indicating
a potential divergence in the number of critical points.

</details>
