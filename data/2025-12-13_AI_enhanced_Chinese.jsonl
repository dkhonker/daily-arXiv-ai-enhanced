{"id": "2512.09931", "pdf": "https://arxiv.org/pdf/2512.09931", "abs": "https://arxiv.org/abs/2512.09931", "authors": ["Akaash Chatterjee", "Suman Kundu"], "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples", "categories": ["cs.AI", "cs.HC"], "comment": "5 pages, 1 Figure", "summary": "Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.", "AI": {"tldr": "ExaCraft是一个AI驱动的个性化学习示例生成系统，通过分析学习者的动态上下文和实时行为，生成文化相关且符合个人需求的学习示例。", "motivation": "现有教育AI工具未能专注于生成个性化示例或适应学习者不断变化的理解水平、困难点和技能成长，因此需要开发能够动态适应学习环境的系统。", "method": "利用Google Gemini AI和Python Flask API构建Chrome扩展，结合用户定义的个人资料（位置、教育、职业、复杂度偏好）和实时学习者行为分析。", "result": "系统能够适应学习上下文的五个关键方面：困难指标、掌握模式、主题进展历史、会话边界和学习进展信号。", "conclusion": "ExaCraft通过动态调整示例内容，从基础概念到高级技术实现，有效响应主题重复、重新生成请求和主题进展模式，提供个性化的学习体验。"}}
{"id": "2512.09932", "pdf": "https://arxiv.org/pdf/2512.09932", "abs": "https://arxiv.org/abs/2512.09932", "authors": ["Maya Grace Torii", "Takahito Murakami", "Shuka Koseki", "Yoichi Ochiai"], "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub", "categories": ["cs.AI", "cs.HC"], "comment": "3 pages, 1 figure, This study will demonstrate at WISS 2025", "summary": "Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of \"being together\" enhances communication. An \"Embodied Information Hub\" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.", "AI": {"tldr": "本研究提出了一种名为'具身信息枢纽'的新方法，通过物理和对话交互来分享知识，旨在解决数字工具缺乏人际连接感的问题。", "motivation": "虽然数字工具改善了信息获取，但很少能创造深度理解所需的连接感。基于社会在场理论，研究旨在通过创造'在一起'的感觉来增强沟通效果。", "method": "开发了名为Suzume-chan的原型系统，这是一个小型、柔软的AI代理，在本地运行，结合语言模型和检索增强生成(RAG)技术，通过语音解释学习并通过对话响应。", "result": "系统能够减少心理距离，使知识分享更加温暖和以人为中心。", "conclusion": "具身信息枢纽通过物理和对话交互的方式，成功实现了更人性化的知识分享，验证了社会在场理论在数字知识传播中的应用价值。"}}
{"id": "2512.09935", "pdf": "https://arxiv.org/pdf/2512.09935", "abs": "https://arxiv.org/abs/2512.09935", "authors": ["Chih-Han Chen", "Chen-Han Tsai", "Yu-Shao Peng"], "title": "Exploring Health Misinformation Detection with Multi-Agent Debate", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.", "AI": {"tldr": "提出一个两阶段的健康信息检测框架：先通过LLM预测证据一致性分数，当分数低于阈值时启动多智能体辩论阶段，综合冲突证据生成有充分理由的验证结论。", "motivation": "随着健康相关错误信息在线激增，需要高质量证据检索和严格推理过程来进行有效验证。", "method": "两阶段框架：第一阶段使用LLM独立评估检索到的文章并计算聚合一致性分数；第二阶段当分数不足时，多个智能体进行结构化辩论来综合冲突证据。", "result": "实验结果显示该方法相比基线方法取得了更优的性能表现。", "conclusion": "结合自动化评分与协作推理对于复杂验证任务具有重要价值。"}}
{"id": "2512.09944", "pdf": "https://arxiv.org/pdf/2512.09944", "abs": "https://arxiv.org/abs/2512.09944", "authors": ["Moein Heidari", "Mohammad Amin Roohi", "Armin Khosravi", "Ilker Hacihaliloglu"], "title": "Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting", "categories": ["cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.", "AI": {"tldr": "Echo-CoPilot是一个基于大语言模型的多视图、多任务心脏超声智能代理系统，通过协调多个专业工具实现自动化的心脏超声分析和报告生成", "motivation": "传统心脏超声解读是认知密集型的手工任务，现有基础模型虽能在单个子任务上表现良好，但缺乏统一的临床评估能力", "method": "采用ReAct风格循环，使用大语言模型协调视图识别、心脏结构分割、测量、疾病预测和报告生成等专业工具，整合输出为指南感知的答案和叙述性总结", "result": "在MIMIC-EchoQA基准测试中达到50.8%的准确率，优于通用和生物医学视频视觉语言模型，能处理临床决策边界附近的复杂病例", "conclusion": "Echo-CoPilot展示了通过大语言模型协调多任务工具在心脏超声分析中的有效性，为临床提供统一的自动化评估解决方案"}}
{"id": "2512.10080", "pdf": "https://arxiv.org/pdf/2512.10080", "abs": "https://arxiv.org/abs/2512.10080", "authors": ["Luciano Floridi", "Jessica Morley", "Claudio Novelli", "David Watson"], "title": "What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.", "AI": {"tldr": "本文分析了大语言模型(LLM)的推理机制，认为其本质是基于统计模式生成文本而非真正的溯因推理，只是表面看似具备推理能力。", "motivation": "探讨当前基于token补全机制的大语言模型的推理本质，分析其与人类溯因推理的相似性与差异，澄清LLM的实际能力边界。", "method": "通过理论分析和实例展示，对比LLM输出与人类推理的特征，考察其生成看似合理但缺乏真实基础的解释性回答的能力。", "result": "发现LLM仅能模仿训练数据中的推理模式，无法进行真正的溯因推理，其输出缺乏真实性验证、语义理解和逻辑验证能力。", "conclusion": "LLM可作为创意生成和思维辅助工具，但其输出需要批判性评估，不能替代真实的推理和验证过程，使用时应保持谨慎态度。"}}
{"id": "2512.09976", "pdf": "https://arxiv.org/pdf/2512.09976", "abs": "https://arxiv.org/abs/2512.09976", "authors": ["Alexis Kafantaris"], "title": "Fuzzy Hierarchical Multiplex", "categories": ["cs.AI", "cs.LG", "eess.SY"], "comment": "11 pages, 2 figures, 1 double figure, 1 table, 12 references. This will be part of my PhD dissertation and it is a White paper-theoretical framewor. As is, it s meant for a basis that will be later used to further developed an FHM. It might not be math-logic related and I am willing to change it, I just felt that it belonged to mathematical modeling. Yours truly, AK", "summary": "A new fuzzy optimization framework that extends FCM causality is proposed. This model utilizes the dynamics to map data into metrics and create a framework that examines logical implication and hierarchy of concepts using a multiplex. Moreover, this is a white-theoretical paper introducing the framework and analyzing the logic and math behind it. Upon this extension the main objectives and the orientation of this framework is expounded and exemplified; this framework is meant for service optimization of information transmission in service process design. Lastly, a thorough analysis of the FHM is included which is done following the logical steps in a simple and elegant manner.", "AI": {"tldr": "提出了一种扩展FCM因果关系的模糊优化框架，通过动态映射数据到度量空间，使用多重网络分析概念间的逻辑蕴含和层次结构，主要用于服务流程设计中的信息传输优化。", "motivation": "扩展FCM因果关系，建立能够分析概念间逻辑关系和层次结构的框架，以优化服务流程中的信息传输效率。", "method": "采用白盒理论方法，通过动态数据映射到度量空间，构建多重网络框架来分析逻辑蕴含和概念层次结构。", "result": "开发了一个新的模糊优化框架，能够系统性地分析概念间的逻辑关系，并通过FHM分析验证了框架的逻辑和数学基础。", "conclusion": "该框架为服务流程设计中的信息传输优化提供了有效的理论工具，通过简单优雅的逻辑步骤验证了其有效性。"}}
{"id": "2512.10110", "pdf": "https://arxiv.org/pdf/2512.10110", "abs": "https://arxiv.org/abs/2512.10110", "authors": ["Yumou Wei", "John Stamper", "Paulo F. Carvalho"], "title": "Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models", "categories": ["cs.CL", "cs.HC"], "comment": "Accepted as a full research paper for the 16th International Conference on Learning Analytics and Knowledge (LAK'26)", "summary": "We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a \"generate-then-validate\" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.", "AI": {"tldr": "研究探索使用小型语言模型(SLMs)进行自动问题生成，通过生成-验证策略和概率推理生成高质量问题，经人类专家和大型语言模型评估证明效果良好", "motivation": "作为大型语言模型在学习分析研究中的补充，探索小型语言模型在自动问题生成方面的应用潜力", "method": "采用生成-验证策略的流水线方法：先进行扩展性生成产生大量候选问题，然后通过基于概率推理的选择性验证进行精炼", "result": "通过人类专家和大型语言模型的双重评估，大多数评估者认为生成的问题具有清晰答案且与学习目标良好对齐", "conclusion": "当通过精心设计的流水线充分利用其优势时，小型语言模型能够有效生成高质量的问题"}}
{"id": "2512.10004", "pdf": "https://arxiv.org/pdf/2512.10004", "abs": "https://arxiv.org/abs/2512.10004", "authors": ["Sha Li", "Ayush Sadekar", "Nathan Self", "Yiqi Su", "Lars Andersland", "Mira Chaplin", "Annabel Zhang", "Hyoju Yang", "James B Henderson", "Krista Wigginton", "Linsey Marr", "T. M. Murali", "Naren Ramakrishnan"], "title": "Exploring LLMs for Scientific Information Extraction Using The SciEx Framework", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.", "AI": {"tldr": "SciEx是一个模块化框架，用于解决科学文献信息提取中的长文档、多模态内容和信息不一致等挑战，通过解耦PDF解析、检索、提取和聚合等组件，实现灵活可扩展的数据提取。", "motivation": "现有方法难以处理科学文献的长上下文、多模态内容以及跨多篇文献的细粒度信息标准化问题，特别是在数据模式快速变化时重新架构系统的困难。", "method": "提出SciEx框架，采用模块化设计解耦PDF解析、多模态检索、信息提取和聚合等关键组件，支持新模型、提示策略和推理机制的灵活集成。", "result": "在三个科学主题的数据集上评估显示，SciEx能够准确且一致地提取细粒度信息，验证了其有效性。", "conclusion": "研究结果提供了对当前基于LLM的提取流程优势和局限性的实践见解，SciEx框架为科学信息提取提供了更灵活和可扩展的解决方案。"}}
{"id": "2512.10121", "pdf": "https://arxiv.org/pdf/2512.10121", "abs": "https://arxiv.org/abs/2512.10121", "authors": ["Zhongjie Jiang"], "title": "Workflow is All You Need: Escaping the \"Statistical Smoothing Trap\" via High-Entropy Information Foraging and Adversarial Pacing", "categories": ["cs.CL", "cs.AI", "cs.CY", "q-fin.GN"], "comment": "22 pages, 8 figures. Includes an ecological validity blind test where the Agentic Workflow achieved a 25% acceptance rate in top-tier media, decisively outperforming the SOTA Zero-shot baseline (0%). Features the DNFO-v5 ontology", "summary": "Central to long-form text generation in vertical domains is the \"impossible trinity\" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).", "AI": {"tldr": "DeepNews框架通过模拟专业记者的认知过程，解决了大语言模型在垂直领域长文本生成中的\"不可能三角\"问题，显著降低了幻觉率并提高了内容质量", "motivation": "现有大语言模型在垂直领域长文本生成中存在\"不可能三角\"困境：难以同时实现低幻觉率、深度逻辑连贯性和个性化表达，这是由于统计平滑陷阱导致的", "method": "提出DeepNews框架，包含三个核心模块：基于信息觅食理论的双粒度检索机制（10:1信息输入比）、基于领域专家知识库的模式引导战略规划、以及对抗性约束提示技术", "result": "实验发现金融深度报道存在知识悬崖现象，当检索上下文低于15,000字符时内容真实性崩溃，超过30,000字符时幻觉率稳定在85%以上。在实际测试中，DeepNews的投稿接受率达到25%，显著优于GPT-5的0%", "conclusion": "DeepNews框架通过显式建模专业认知过程，有效解决了大语言模型在垂直领域长文本生成中的根本问题，为专业内容创作提供了新的解决方案"}}
{"id": "2512.10034", "pdf": "https://arxiv.org/pdf/2512.10034", "abs": "https://arxiv.org/abs/2512.10034", "authors": ["Salomé Guilbert", "Cassandra Masschelein", "Jeremy Goumaz", "Bohdan Naida", "Philippe Schwaller"], "title": "DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations", "categories": ["cs.AI", "cs.CE"], "comment": null, "summary": "Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.", "AI": {"tldr": "DynaMate是一个基于多智能体的自动化框架，能够自主设计和执行蛋白质和蛋白质-配体系统的完整分子动力学模拟工作流程，包括结合自由能计算。", "motivation": "分子动力学模拟在药物发现和蛋白质工程中应用广泛，但其技术复杂性（参数化、输入准备、软件配置）阻碍了广泛高效使用，需要自动化解决方案。", "method": "开发了模块化多智能体框架DynaMate，集成动态工具使用、网络搜索、PaperQA和自校正行为，包含三个专门模块：实验规划、模拟执行和结果分析。", "result": "在12个不同复杂度的基准系统上评估，DynaMate能够可靠执行完整MD模拟，通过迭代推理纠正运行时错误，并生成有意义的蛋白质-配体相互作用分析。", "conclusion": "该自动化框架为未来生物分子和药物设计应用提供了标准化、可扩展且时间高效的分子建模流程。"}}
{"id": "2512.10148", "pdf": "https://arxiv.org/pdf/2512.10148", "abs": "https://arxiv.org/abs/2512.10148", "authors": ["Moonsoo Park", "Jeongseok Yun", "Bohyung Kim"], "title": "PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.", "AI": {"tldr": "提出两阶段提示框架，从短评文本推断显性和隐性用户画像，用于生成个性化回复，无需微调即可提升相关性和个性化程度", "motivation": "在用户信息有限的领域（如外卖平台），大语言模型因缺乏上下文用户数据而生成通用回复，降低了参与度和效果", "method": "两阶段提示框架：1) 从短评文本推断显性（用户偏好）和隐性（人口统计或风格线索）用户画像 2) 将推断的用户画像属性融入回复生成提示中，并通过调整解码温度来鼓励多样且忠实的生成", "result": "在韩国外卖应用的真实数据集上评估，结果显示该方法在精确度、多样性和语义一致性方面有效提升了自动化回复的相关性和个性化", "conclusion": "基于用户画像增强的提示方法能有效提升自动回复的相关性和个性化，且无需模型微调"}}
{"id": "2512.10046", "pdf": "https://arxiv.org/pdf/2512.10046", "abs": "https://arxiv.org/abs/2512.10046", "authors": ["Yan Zhuang", "Jiawei Ren", "Xiaokang Ye", "Jianzhi Shen", "Ruixuan Zhang", "Tianai Yue", "Muhammad Faayez", "Xuhong He", "Ziqiao Ma", "Lianhui Qin", "Zhiting Hu", "Tianmin Shu"], "title": "SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration", "categories": ["cs.AI"], "comment": "Conference: NeurIPS 2025 (main)", "summary": "Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.", "AI": {"tldr": "SimWorld-Robotics (SWR) 是一个基于Unreal Engine 5构建的大规模、逼真城市环境仿真平台，用于评估机器人在复杂城市场景中的多模态指令跟随和多机器人协作能力。", "motivation": "当前基础模型在机器人领域主要关注室内家庭场景，缺乏针对大规模城市环境的仿真平台和评估基准，无法全面测试机器人在真实城市环境中的关键能力。", "method": "构建了SWR仿真平台，程序化生成无限逼真的城市场景，包含动态元素（行人、交通系统），支持多机器人控制和通信。在此基础上建立了两个基准任务：多模态指令跟随任务和多智能体搜索任务。", "result": "实验结果表明，包括视觉语言模型在内的最先进模型在这些任务上表现不佳，缺乏城市环境所需的鲁棒感知、推理和规划能力。", "conclusion": "SWR平台填补了城市环境机器人仿真的空白，为评估机器人在复杂城市场景中的综合能力提供了重要工具，揭示了当前模型在城市环境应用中的局限性。"}}
{"id": "2512.10150", "pdf": "https://arxiv.org/pdf/2512.10150", "abs": "https://arxiv.org/abs/2512.10150", "authors": ["Lama Alssum", "Hani Itani", "Hasan Abed Al Kader Hammoud", "Philip Torr", "Adel Bibi", "Bernard Ghanem"], "title": "Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.", "AI": {"tldr": "该论文研究了大型语言模型在任务适配过程中的安全性退化问题，提出将保持安全性的微调视为持续学习问题，并通过实验证明持续学习方法能有效降低攻击成功率。", "motivation": "随着大语言模型的普及，其安全性对齐变得日益重要。研究发现模型在适应新任务时会出现安全性退化，这主要归因于灾难性遗忘现象。", "method": "采用持续学习(CL)方法来解决微调过程中的安全性保持问题，包括正则化方法、基于记忆的方法和模型融合方法。在良性用户数据和中毒用户数据两种场景下进行系统评估。", "result": "实验结果表明，持续学习方法相比标准微调始终获得更低的攻击成功率。其中DER方法在保持任务效用的同时，表现优于其他CL方法和现有安全保护基线方法。", "conclusion": "研究结果在三个下游任务(GSM8K、SST2、Code)和三个模型系列(LLaMA2-7B、Mistral-7B、Gemma-2B)上具有普适性，确立了持续学习作为保持模型安全性的实用解决方案。"}}
{"id": "2512.10054", "pdf": "https://arxiv.org/pdf/2512.10054", "abs": "https://arxiv.org/abs/2512.10054", "authors": ["Logan Robbins"], "title": "Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \\textit{coherence drift} due to the lack of cross-stream communication. In this work, we introduce the \\textbf{Parallel Decoder Transformer (PDT)}, a parameter-efficient architecture that embeds coordination primitives directly into the inference process of a frozen pre-trained model.\n  Instead of retraining the base model, PDT injects lightweight \\textit{Speculative Note Conditioning (SNC)} adapters that allow parallel decoding streams to synchronize via a shared, dynamic latent space. We formulate coordination as a \\textit{speculative consensus} problem, where sibling streams broadcast semantic ``notes'' to a global bus, gated by a learned verification head. We validate our approach on a 50,000-step curriculum using a frozen 20B-parameter backbone. Our results demonstrate that PDT achieves effective self-correction, reaching \\textbf{77.8\\% precision} in coverage prediction and recovering approximate serial semantics without modifying the trunk weights. This establishes PDT as a scalable, efficient alternative to full model fine-tuning for structured parallel generation.", "AI": {"tldr": "PDT是一种参数高效的并行解码架构，通过注入轻量级适配器在冻结预训练模型上实现并行解码，解决了传统自回归解码的延迟瓶颈和并行生成中的一致性漂移问题。", "motivation": "大型语言模型的自回归解码存在线性延迟瓶颈，现有的并行生成方法由于缺乏跨流通信而导致一致性漂移问题。", "method": "引入Parallel Decoder Transformer (PDT)，在冻结预训练模型中注入Speculative Note Conditioning (SNC)适配器，通过共享动态潜在空间实现并行解码流同步，采用推测共识机制进行协调。", "result": "在5万步课程上验证，PDT达到77.8%的覆盖预测精度，能够有效自我校正并恢复近似串行语义，无需修改主干权重。", "conclusion": "PDT为结构化并行生成提供了一种可扩展、高效的替代方案，无需完整模型微调即可实现并行解码。"}}
{"id": "2512.10195", "pdf": "https://arxiv.org/pdf/2512.10195", "abs": "https://arxiv.org/abs/2512.10195", "authors": ["Gyutaek Oh", "Sangjoon Park", "Byung-Hoon Kim"], "title": "AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding", "categories": ["cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.", "AI": {"tldr": "AutoMedic是一个多代理模拟框架，将静态医疗问答数据集转换为虚拟患者档案，通过CARE指标自动化评估LLM在临床对话中的表现。", "motivation": "现有静态医疗QA基准无法充分评估LLM在动态、交互式临床多轮对话中的效果，且缺乏多维度评估策略。动态临床场景的组合空间巨大，难以标准化和量化评估。", "method": "开发AutoMedic多代理框架，将现成静态QA数据集转化为虚拟患者档案，模拟真实临床多轮对话。使用CARE指标（临床对话准确性、效率/策略、同理心和鲁棒性）进行评估。", "result": "研究验证了AutoMedic作为临床对话代理自动化评估框架的有效性，人类专家验证证实了其可靠性。", "conclusion": "AutoMedic为LLM在对话医疗应用中的有效开发提供了实用指南，解决了临床对话评估的标准化和量化难题。"}}
{"id": "2512.10058", "pdf": "https://arxiv.org/pdf/2512.10058", "abs": "https://arxiv.org/abs/2512.10058", "authors": ["Dani Roytburg", "Beck Miller"], "title": "Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.SI"], "comment": "Accepted for presentation at IASEAI 2026", "summary": "While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, \"aligned\" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.\n  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.", "AI": {"tldr": "这篇论文通过大规模文献计量分析发现AI安全与AI伦理研究领域存在明显的结构性分离，80%以上的合作发生在各自领域内部，跨领域交流仅由少数关键研究者维系。", "motivation": "AI领域快速发展使得对齐研究日益紧迫，但安全研究和伦理研究沿着两条平行轨道发展，对\"对齐\"的定义和理解存在分歧，需要实证研究来揭示这种结构性分裂。", "method": "采用文献计量和合作网络分析方法，分析了2020-2025年间12个主要ML和NLP会议的6,442篇论文，研究安全与伦理社区之间的合作模式和连接结构。", "result": "研究发现：80%以上的合作发生在各自社区内部；跨领域连接高度集中，约5%的论文贡献了85%以上的桥梁链接；移除少数关键研究者会显著增加领域隔离。", "conclusion": "安全与伦理的分歧不仅是概念上的，更是制度性的。需要通过共享基准、跨机构平台和混合方法来整合技术安全工作和规范伦理，以构建既稳健又公正的AI系统。"}}
{"id": "2512.10336", "pdf": "https://arxiv.org/pdf/2512.10336", "abs": "https://arxiv.org/abs/2512.10336", "authors": ["Jules Lahmi", "Alexis Roger"], "title": "Multilingual VLM Training: Adapting an English-Trained VLM to French", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.", "AI": {"tldr": "论文研究了将英语训练的视觉语言模型(VLM)适配到其他语言的挑战，比较了翻译管道、LoRA微调和两阶段微调等方法的性能与计算成本，发现数据集翻译是多语言VLM性能的主要瓶颈。", "motivation": "当前AI视觉语言模型的进展主要局限于英语，限制了非英语用户的可访问性，需要将这些能力扩展到更广泛的语言范围。", "method": "采用三种方法进行比较：基于翻译的管道、LoRA微调、以及将视觉适配与语言适配分开的两阶段微调策略，使用翻译后的多模态基准测试和母语专家手动评估进行验证。", "result": "数据集翻译是多语言VLM性能的主要瓶颈，数据质量限制了训练和评估的有效性。", "conclusion": "未来工作应专注于原生语言数据集的收集和改进翻译策略。"}}
{"id": "2512.10065", "pdf": "https://arxiv.org/pdf/2512.10065", "abs": "https://arxiv.org/abs/2512.10065", "authors": ["Paul Bouchaud", "Pedro Ramaciotti"], "title": "Linear socio-demographic representations emerge in Large Language Models from indirect cues", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.", "AI": {"tldr": "研究发现LLMs通过名字和职业等间接线索形成用户社会人口属性的线性表征，这些表征会影响下游行为如职业推荐，即使通过偏见基准测试的模型仍可能存在隐含偏见", "motivation": "探究LLMs如何通过间接线索编码人类对话伙伴的社会人口属性，以及这些隐含表征如何影响模型行为", "method": "在四个开源Transformer LLMs的残差流中进行探测，分析明确人口统计披露和隐式线索（名字、职业）激活的表征，验证其与人口普查数据和劳动力统计的相关性", "result": "LLMs在激活空间中形成可解释的线性人口统计表征，名字激活与人口普查一致的性别和种族表征，职业触发与真实劳动力统计数据相关的表征，这些表征影响下游行为如职业推荐", "conclusion": "即使通过偏见测试的模型仍可能包含和利用隐含偏见，这对大规模应用时的公平性具有重要影响"}}
{"id": "2512.10398", "pdf": "https://arxiv.org/pdf/2512.10398", "abs": "https://arxiv.org/abs/2512.10398", "authors": ["Zhaodong Wang", "Zhenting Qi", "Sherman Wong", "Nathan Hu", "Samuel Lin", "Jun Ge", "Erwin Gao", "Yining Yang", "Ben Maurer", "Wenlin Chen", "David Recordon", "Yilun Du", "Minlan Yu", "Ying Zhang"], "title": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.", "AI": {"tldr": "Confucius Code Agent (CCA) 是一个开源AI软件工程师，在工业规模任务上表现优异，在SWE-Bench-Pro上达到54.3%的Resolve@1性能，显著超越现有编码代理。", "motivation": "现实世界的AI软件工程需要能够处理大规模代码库、维持长期会话记忆并协调复杂工具链的编码代理。现有开源代理在工业级工作负载下表现不足，而专有代理虽然性能强但缺乏可扩展性和可解释性。", "method": "基于Confucius SDK构建，该平台采用三重视角：Agent体验、用户体验和开发者体验。包含统一编排器（分层工作记忆）、持久笔记系统（跨会话持续学习）和模块化扩展模块（稳健工具使用）。元代理通过构建-测试-改进循环自动合成、评估和优化代理配置。", "result": "在SWE-Bench-Pro基准测试中取得54.3%的Resolve@1性能，达到最先进水平，显著优于之前的编码代理。", "conclusion": "Confucius SDK和CCA为AI代理提供了透明、可扩展和可复现的基础，弥合了研究原型与生产级系统之间的差距，支持工业规模的代理开发和部署。"}}
{"id": "2512.10092", "pdf": "https://arxiv.org/pdf/2512.10092", "abs": "https://arxiv.org/abs/2512.10092", "authors": ["Nick Jiang", "Xiaoqing Sun", "Lisa Dunlap", "Lewis Smith", "Neel Nanda"], "title": "Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit", "categories": ["cs.AI", "cs.LG"], "comment": "Code: https://github.com/nickjiang2378/interp_embed", "summary": "Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding \"trigger\" phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.", "AI": {"tldr": "该论文提出使用稀疏自编码器(SAEs)创建可解释的概念嵌入，相比传统LLM和密集嵌入方法，在成本效益、可靠性和可控性方面表现更优，适用于大规模文本分析任务。", "motivation": "当前分析大规模文本语料库的方法主要依赖昂贵的LLM技术或缺乏可控性的密集嵌入模型，无法有效控制关注属性，需要更经济、可靠且可控的分析工具。", "method": "采用稀疏自编码器(SAEs)生成SAE嵌入表示，其维度映射到可解释的概念，通过四个数据分析任务验证其有效性。", "result": "SAE嵌入比LLM方法成本降低2-8倍且发现更大差异，比密集嵌入更具可控性，能有效识别数据集语义差异、概念相关性、模型行为变化和训练数据中的触发短语。", "conclusion": "SAEs是分析非结构化数据的多功能工具，强调了通过数据解释模型的重要性，为大规模文本分析提供了更优解决方案。"}}
{"id": "2512.10411", "pdf": "https://arxiv.org/pdf/2512.10411", "abs": "https://arxiv.org/abs/2512.10411", "authors": ["Yijiong Yu", "Jiale Liu", "Qingyun Wu", "Huazheng Wang", "Ji Pei"], "title": "Sliding Window Attention Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving \"sink\" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation", "AI": {"tldr": "论文提出SWAA方法，通过五种技术组合（预填充SWA、保留sink tokens、FA/SWA层交错、思维链、微调）来适配全注意力预训练模型到滑动窗口注意力，有效解决长上下文推理性能退化问题。", "motivation": "Transformer自注意力机制在长输入时计算成本呈二次增长，滑动窗口注意力(SWA)虽能降低到线性复杂度，但直接将全注意力(FA)预训练模型切换到SWA会导致严重的性能下降，需要解决这种训练-推理不匹配问题。", "method": "提出SWAA适配方法，包含五种技术：1)仅在预填充阶段使用SWA；2)保留关键\"sink\" tokens；3)FA和SWA层交错使用；4)思维链(CoT)技术；5)微调策略。通过不同组合配置实现性能与效率的平衡。", "result": "实验表明SWA适配是可行但非平凡的：单一方法不足，但特定的协同组合能有效恢复原始长上下文性能。研究进一步分析了不同配置的性能-效率权衡，并为不同场景提供了推荐方案。", "conclusion": "SWAA方法成功解决了FA预训练模型向SWA适配的问题，通过精心设计的组合策略可以在保持计算效率的同时维持长上下文处理性能，为实际应用提供了实用的解决方案。"}}
{"id": "2512.10100", "pdf": "https://arxiv.org/pdf/2512.10100", "abs": "https://arxiv.org/abs/2512.10100", "authors": ["Apostol Vassilev"], "title": "Robust AI Security and Alignment: A Sisyphean Endeavor?", "categories": ["cs.AI"], "comment": null, "summary": "This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel's incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.", "AI": {"error": "'NoneType' object has no attribute 'model_dump'"}}
{"id": "2512.10422", "pdf": "https://arxiv.org/pdf/2512.10422", "abs": "https://arxiv.org/abs/2512.10422", "authors": ["Youmin Ko", "Sungjong Seo", "Hyunjoon Kim"], "title": "Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to NeurIPS 2025", "summary": "Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\\footnote{https://github.com/meaningful96/CoopRAG}", "AI": {"tldr": "CoopRAG是一个新颖的检索增强生成框架，通过检索器和LLM的协同工作以及检索器模型不同层之间的协作，显著提升了问答任务的准确性和检索性能。", "motivation": "现有的RAG方法在简单和多跳问答中仍然容易出现错误检索和幻觉问题，需要更有效的解决方案。", "method": "将问题分解为子问题和推理链，检索相关文档，通过对比检索器层重新排序文档，利用LLM填充推理链中的不确定位置。", "result": "在三个多跳问答数据集和一个简单问答数据集上，CoopRAG在检索和问答性能方面均优于最先进的方法。", "conclusion": "CoopRAG通过协同工作机制有效解决了RAG中的错误检索和幻觉问题，为问答任务提供了更可靠的解决方案。"}}
{"id": "2512.10105", "pdf": "https://arxiv.org/pdf/2512.10105", "abs": "https://arxiv.org/abs/2512.10105", "authors": ["Soorya Ram Shimgekar", "Abhay Goyal", "Lam Yin Cheung", "Roy Ka-Wei Lee", "Koustuv Saha", "Pi Zonooz", "Navin Kumar"], "title": "Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups", "categories": ["cs.AI"], "comment": null, "summary": "Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.\n  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.", "AI": {"tldr": "该研究开发了一个两阶段计算框架来分析新加坡Telegram群组中的阴谋论内容，发现阴谋论话语已融入日常讨论而非局限于孤立回音室。", "motivation": "研究动机是理解数字通信生态系统中阴谋论话语的结构和传播模式，特别是其在日常讨论中的嵌入程度，以挑战关于网络激进化的常见假设。", "method": "采用两阶段方法：1) 微调RoBERTa-large模型分类阴谋论消息(F1分数0.866)；2) 构建带符号信念图，使用SiBeGNN和图神经网络学习嵌入表示，通过符号解缠损失分离意识形态对齐和风格特征。", "result": "从553,648条消息中识别出7个叙事原型：法律话题、医疗关注、媒体讨论、金融、权威矛盾、群组管理和日常聊天。SiBeGNN聚类质量(cDBI=8.38)优于基线方法，专家评估一致率达88%。", "conclusion": "阴谋论消息不仅出现在怀疑和不信任的集群中，也存在于金融、法律和日常事务的常规讨论中，表明阴谋论话语在普通社交互动中运作，这对在线激进化的传统理解提出了挑战。"}}
{"id": "2512.10430", "pdf": "https://arxiv.org/pdf/2512.10430", "abs": "https://arxiv.org/abs/2512.10430", "authors": ["Dmitrii Stoianov", "Danil Taranets", "Olga Tsymboi", "Ramil Latypov", "Almaz Dautov", "Vladislav Kruglikov", "Nikita Surkov", "German Abramov", "Pavel Gein", "Dmitry Abulkhanov", "Mikhail Gashkov", "Viktor Zelenkovskiy", "Artem Batalov", "Aleksandr Medvedev", "Anatolii Potapov"], "title": "T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground", "categories": ["cs.CL"], "comment": null, "summary": "We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.", "AI": {"tldr": "T-pro 2.0是一个开源的俄语大语言模型，支持混合推理和高效推理，包含推理轨迹生成功能，并采用优化的推理流水线降低延迟。", "motivation": "为俄语语言处理提供可复现和可扩展的研究资源，支持俄语推理研究和应用开发。", "method": "使用西里尔字母密集分词器和适配的EAGLE推测解码流水线，发布模型权重、T-Wix 500k指令语料库、T-Math推理基准和EAGLE权重。", "result": "开发了一个完整的开源系统，包含公开的Web演示，展示推理和非推理模式以及跨领域的推理速度提升。", "conclusion": "T-pro 2.0作为一个易访问的开源系统，可用于构建和评估高效实用的俄语LLM应用。"}}
{"id": "2512.10114", "pdf": "https://arxiv.org/pdf/2512.10114", "abs": "https://arxiv.org/abs/2512.10114", "authors": ["Mesafint Fanuel", "Mahmoud Nabil Mahmoud", "Crystal Cook Marshal", "Vishal Lakhotia", "Biswanath Dari", "Kaushik Roy", "Shaohu Zhang"], "title": "AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice", "categories": ["cs.AI"], "comment": "15 pages", "summary": "Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.", "AI": {"tldr": "AgriRegion是一个针对农业领域的RAG框架，通过地理空间元数据注入和区域优先重排机制，显著减少LLM在农业咨询中的幻觉问题，提高回答的本地准确性。", "motivation": "通用大语言模型在农业领域存在上下文幻觉问题，提供的建议可能在一个地区科学有效但在另一个地区造成灾难性后果，主要由于土壤、气候和地方法规的差异。", "method": "开发了AgriRegion框架，包含地理空间元数据注入层和区域优先重排机制，将知识库限制在经验证的本地农业推广服务中，并在检索时强制执行地理空间约束。", "result": "实验显示AgriRegion相比最先进的LLM系统减少幻觉10-20%，并显著提高了信任分数。创建了包含160个领域特定问题的新基准数据集AgriRegion-Eval。", "conclusion": "AgriRegion框架有效解决了农业领域LLM的本地化准确性问题，为区域特定的农业咨询提供了高保真度的解决方案。"}}
{"id": "2512.10435", "pdf": "https://arxiv.org/pdf/2512.10435", "abs": "https://arxiv.org/abs/2512.10435", "authors": ["Agniva Maiti", "Prajwal Panth", "Suresh Chandra Satapathy"], "title": "Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring \"Tortured Phrases\" in Scientific Literature", "categories": ["cs.CL"], "comment": "10 pages, 5 figures; unpublished manuscript; submitted to arXiv for dissemination", "summary": "The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate \"tortured phrases\", statistically improbable synonyms (e.g. \"counterfeit consciousness\" for \"artificial intelligence\"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.", "AI": {"tldr": "SRAP框架通过两阶段方法检测和恢复对抗性剽窃文本：首先使用SciBERT进行统计异常检测，然后通过FAISS和SBERT进行语义重建，在科学文献中实现了23.67%的恢复准确率。", "motivation": "科学文献完整性受到对抗性文本生成技术的威胁，现有检测方法依赖静态黑名单或通用语言模型，对新型混淆处理效果差且无法追溯剽窃来源。", "method": "两阶段架构：1) 使用领域特定的SciBERT模型进行基于伪困惑度的统计异常检测；2) 使用FAISS密集向量检索和SBERT句子级对齐进行基于源文档的语义重建。", "result": "在对抗性科学文本平行语料上，零样本基线完全失败(0.00%恢复准确率)，而SRAP方法达到23.67%恢复准确率，显著优于基线方法。静态决策边界在术语密集的科学文本中表现更稳健。", "conclusion": "SRAP框架不仅能检测对抗性剽窃，还能数学重建原始术语，实现法医分析，将混淆表达链接回最可能的源文档，为科学文献完整性保护提供了有效解决方案。"}}
{"id": "2512.10169", "pdf": "https://arxiv.org/pdf/2512.10169", "abs": "https://arxiv.org/abs/2512.10169", "authors": ["Alexander Wan", "Kevin Klyman", "Sayash Kapoor", "Nestor Maslej", "Shayne Longpre", "Betty Xiong", "Percy Liang", "Rishi Bommasani"], "title": "The 2025 Foundation Model Transparency Index", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "Website: https://crfm.stanford.edu/fmti/December-2025/index.html", "summary": "Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.", "AI": {"tldr": "2025年基础模型透明度指数显示，主要AI公司的透明度从2024年的58分下降到2025年的40分，IBM以95分领先，xAI和Midjourney仅14分垫底。公司在训练数据和部署后影响方面最为不透明。", "motivation": "评估基础模型开发商的透明度实践演变，特别是在数据获取、使用数据和监控方面的新指标需求，为政策制定提供依据。", "method": "采用年度指数评估方法，引入新的透明度指标，对包括阿里巴巴、DeepSeek和xAI在内的多家公司进行首次评估和量化评分。", "result": "透明度整体下降，平均分从58降至40；IBM表现突出(95分)，xAI和Midjourney最差(14分)；Frontier Model Forum成员处于中间水平。", "conclusion": "尽管政策制定者越来越多地要求透明度，但公司缺乏成为透明度领导者的激励，需要更积极的政策干预来解决关键信息缺失问题。"}}
{"id": "2512.10440", "pdf": "https://arxiv.org/pdf/2512.10440", "abs": "https://arxiv.org/abs/2512.10440", "authors": ["Nour El Houda Ben Chaabene", "Hamza Hammami"], "title": "Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT", "categories": ["cs.CL"], "comment": "This paper was accepted and scheduled for inclusion in the ICALT 2025 proceedings but was ultimately not published due to absence from the conference presentation. It appears in the official program booklet. Conference: 2025 IEEE International Conference on Advanced Learning Technologies (ICALT)", "summary": "Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.", "AI": {"tldr": "论文提出通过知识图谱(KG)与BERT结合(KG-BERT)来增强大语言模型的结枃化知识能力，解决LLMs在事实一致性方面的问题，在知识密集型任务中取得显著效果提升", "motivation": "大语言模型(如Claude、Mistral IA、GPT-4)虽然在自然语言处理方面表现出色，但缺乏结构化知识，导致事实不一致性问题", "method": "通过知识图谱(KGs)与BERT模型集成的方法(KG-BERT)，增强模型的接地性和推理能力", "result": "实验显示在问答和实体链接等知识密集型任务中取得了显著的效果提升", "conclusion": "该方法提高了事实可靠性，使下一代LLMs能够具备更强的上下文感知能力"}}
{"id": "2512.10206", "pdf": "https://arxiv.org/pdf/2512.10206", "abs": "https://arxiv.org/abs/2512.10206", "authors": ["Yakun Zhu", "Zhongzhen Huang", "Qianhan Feng", "Linjie Mu", "Yannian Gu", "Shaoting Zhang", "Qi Dou", "Xiaofan Zhang"], "title": "CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment", "categories": ["cs.AI"], "comment": null, "summary": "Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.", "AI": {"tldr": "CP-Env是一个可控的医院环境模拟器，用于评估大语言模型在端到端临床路径中的表现，包括分诊、专科咨询、诊断测试和多学科团队会议等动态场景。", "motivation": "当前基准测试主要关注静态考试或孤立对话，无法充分评估LLM在动态临床场景中的表现，需要更全面的端到端评估方法。", "method": "开发CP-Env模拟医院生态系统，包含患者和医生代理，模拟真实医院的自适应医疗流程，支持分支和长时程任务执行，并采用三层评估框架（临床效能、流程能力和专业伦理）。", "result": "大多数模型在处理路径复杂性方面表现不佳，出现幻觉和丢失关键诊断细节的问题。过度推理步骤有时适得其反，而顶级模型通过内化知识减少工具依赖。", "conclusion": "CP-Env通过全面的端到端临床评估推动了医疗AI代理的发展，为后续研究提供了基准和评估工具。"}}
{"id": "2512.10441", "pdf": "https://arxiv.org/pdf/2512.10441", "abs": "https://arxiv.org/abs/2512.10441", "authors": ["Nour El Houda Ben Chaabene", "Hamza Hammami", "Laid Kahloul"], "title": "Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis", "categories": ["cs.CL"], "comment": "This manuscript is currently under peer review in Expert Systems with Applications", "summary": "This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.", "AI": {"tldr": "论文提出了一种结合LLM、KG-BERT和双向LSTM的心理学感知对话代理，通过多模态数据实时识别学生的认知和情感状态，在教育环境中提升学习表现和情绪健康。", "motivation": "现有的教育聊天机器人通常只能提供学业辅导或情感支持的单一功能，缺乏对学生的认知和情感状态的综合理解与实时干预能力。", "method": "结合大型语言模型(LLM)、知识图谱增强的BERT(KG-BERT)和带注意力机制的双向LSTM，利用文本语义、语音韵律特征和时间行为趋势等多模态数据进行实时状态分类。", "result": "对大学生进行的试点研究表明，相比基线方法，该系统提高了学习动机、降低了压力水平，并取得了中等程度的学业提升效果。", "conclusion": "研究结果表明，整合语义推理、多模态融合和时间建模的方法具有很大潜力，能够支持自适应的、以学生为中心的教育干预措施。"}}
{"id": "2512.10208", "pdf": "https://arxiv.org/pdf/2512.10208", "abs": "https://arxiv.org/abs/2512.10208", "authors": ["Mehmet Emin Aydin"], "title": "An exploration for higher efficiency in multi objective optimisation with reinforcement learning", "categories": ["cs.AI", "cs.NE"], "comment": "13th International Symposium on Intelligent Manufacturing and Service Systems, Duzce University, Duzce, Turkiye, 25-27 September 2025", "summary": "Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.", "AI": {"tldr": "本文探讨了使用多目标强化学习来优化搜索过程中的算子序列选择问题，针对多目标优化中算子序列优化的研究空白提出了一种通用方法。", "motivation": "优化和搜索过程中的效率问题持续存在，使用多个算子而非单一算子处理邻域移动操作具有潜力，但最优或接近最优的算子序列需要进一步研究。多目标优化领域在此方面研究较少。", "method": "提出基于多目标强化学习的通用方法，通过多目标强化学习来学习和选择最优算子序列，目前已完成某些阶段的研究，部分阶段仍在进行中。", "result": "论文展示了一种通用方法的初步框架，表明多目标强化学习有望解决多目标优化中的算子序列选择问题，但具体实验结果和性能数据未在摘要中详细说明。", "conclusion": "多目标强化学习方法为解决多目标优化中的算子序列优化问题提供了有前景的解决方案，该方法有望提高优化算法的效率和性能，但需要进一步的研究和验证。"}}
{"id": "2512.10453", "pdf": "https://arxiv.org/pdf/2512.10453", "abs": "https://arxiv.org/abs/2512.10453", "authors": ["Lars G. B. Johnsen"], "title": "Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs", "categories": ["cs.CL"], "comment": "2 figures", "summary": "What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.\n  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.", "AI": {"tldr": "大型语言模型仅通过表层形式训练，却能可靠区分主语-助动词倒装和寄生空位许可等句法结构的合法与非法变体，表明它们对句法结构具有敏感性而不仅仅是线性顺序。", "motivation": "测试仅基于表层形式训练的大型语言模型是否能够复现传统生成语法中的系统性句法对比，以验证这些模型是否具有底层结构表征能力。", "method": "使用GPT-4和LLaMA-3等模型，通过提示引导获取可接受性评分，重点评估主语-助动词倒装（测试主语边界识别）和寄生空位许可（测试抽象依赖结构）两种经典结构。", "result": "LLMs在两种结构中都可靠地区分了合法与非法变体，表明它们对结构敏感而不仅仅是线性顺序。结构概括从表层形式的预测训练中涌现，显示出对句法的功能性敏感性。", "conclusion": "大型语言模型通过预测性训练获得了对句法结构的功能性敏感性，支持了它们具有内部结构表征能力的观点，即使没有显式的句法编码。"}}
{"id": "2512.10211", "pdf": "https://arxiv.org/pdf/2512.10211", "abs": "https://arxiv.org/abs/2512.10211", "authors": ["Junyang Cai", "El Mehdi Er Raqabi", "Pascal Van Hentenryck", "Bistra Dilkina"], "title": "ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs", "categories": ["cs.AI"], "comment": null, "summary": "Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.", "AI": {"tldr": "本文提出了ID-PaS框架，将Predict-and-Search方法扩展到参数化混合整数规划问题，通过身份感知学习处理异构变量，在多个实际大规模问题上超越了Gurobi和传统PaS方法。", "motivation": "现有的Predict-and-Search方法仅限于二元问题，且忽略了实际应用中常见的固定变量问题，需要扩展到更一般的参数化混合整数规划场景。", "method": "提出了ID-PaS身份感知学习框架，使机器学习模型能够更有效地处理异构变量，扩展了Predict-and-Search方法到参数化MIP问题。", "result": "在多个实际大规模问题上，ID-PaS始终表现出优于最先进求解器Gurobi和传统PaS方法的性能。", "conclusion": "ID-PaS框架成功解决了传统方法的局限性，为处理参数化混合整数规划问题提供了更有效的机器学习增强解决方案。"}}
{"id": "2512.10545", "pdf": "https://arxiv.org/pdf/2512.10545", "abs": "https://arxiv.org/abs/2512.10545", "authors": ["Iñaki Lacunza", "José Javier Saiz", "Alexander Shvets", "Aitor Gonzalez-Agirre", "Marta Villegas"], "title": "XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs", "categories": ["cs.CL"], "comment": "Accepted and presented at the LLMs4All workshop at the IEEE BigData 2025 Conference, Macau - December 8-11, 2025", "summary": "Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.", "AI": {"tldr": "论文提出XDoGE方法优化多语言LLM训练，通过语言分布重加权和CPT训练，针对伊比利亚半岛语言构建了IberianLLM-7B模型", "motivation": "当前LLM过度依赖英语等高资源语言，导致中低资源语言性能不佳，需要平衡语言分布提升多语言能力", "method": "扩展DoGE算法为XDoGE进行多语言重加权，使用小代理模型优化语言分布，通过CPT阶段训练全尺寸模型，针对6种不同资源水平的伊比利亚语言进行实验", "result": "开发了IberianLLM-7B-Instruct模型，使用IberoBench框架评估数据重复和欠采样效果，提升了伊比利亚语言性能", "conclusion": "XDoGE方法有效改善了多语言LLM的语言分布不平衡问题，为低资源语言模型训练提供了可行方案"}}
{"id": "2512.10273", "pdf": "https://arxiv.org/pdf/2512.10273", "abs": "https://arxiv.org/abs/2512.10273", "authors": ["Yuxin Liu", "Chaojie Gu", "Yihang Zhang", "Bin Qian", "Shibo He"], "title": "Reverse Thinking Enhances Missing Information Detection in Large Language Models", "categories": ["cs.AI"], "comment": "10 pages, 2 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.", "AI": {"tldr": "该论文提出了一种基于逆向思维的新框架，通过引导大型语言模型进行反向推理来识别缺失信息，相比传统前向推理方法显著提升了模型在缺失信息检测任务中的准确性和鲁棒性。", "motivation": "大型语言模型在推理任务中表现出色，但在处理缺失信息问题时经常出现回答不完整、事实错误和幻觉等问题。传统前向推理方法如CoT和ToT无法系统性地识别和恢复被省略的信息。", "method": "受逆向推理研究的启发，提出了一种新颖的逆向思维框架，将缺失信息识别任务转化为更易处理的逆向推理问题，引导LLMs识别必要条件和定位缺失元素。", "result": "实验结果表明，逆向思维方法相比传统前向推理方法取得了显著的性能提升，在模型准确性方面有实质性改进。", "conclusion": "逆向思维方法为增强大型语言模型的逻辑完整性和推理鲁棒性提供了一个有前景的方向，能够有效解决缺失信息检测的挑战。"}}
{"id": "2512.10561", "pdf": "https://arxiv.org/pdf/2512.10561", "abs": "https://arxiv.org/abs/2512.10561", "authors": ["Amartya Roy", "Elamparithy M", "Kripabandhu Ghosh", "Ponnurangam Kumaraguru", "Adrian de Wynter"], "title": "Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.", "AI": {"tldr": "本文研究了不同架构大语言模型在因果推理中的表现，发现仅依赖上下文学习(ICL)不足以进行可靠的因果推理，微调的编码器和编码器-解码器架构在跨分布鲁棒性方面优于仅解码器模型。", "motivation": "虽然上下文学习支撑了大语言模型的近期进展，但其在因果推理中的作用和性能仍不明确。因果推理需要多跳组合和严格合取控制，而依赖输入的虚假词汇关系可能导致误导性结果。", "method": "比较了微调版本的编码器、编码器-解码器和仅解码器架构在零样本和少样本ICL设置下的表现，包括自然语言和非自然语言场景。", "result": "ICL单独使用对可靠因果推理不足，常过度关注无关输入特征。仅解码器模型对分布偏移明显脆弱，而微调的编码器和编码器-解码器模型在测试中表现更鲁棒，包括非自然语言场景。", "conclusion": "对于成本效益高、短时程的鲁棒因果推理，带有针对性微调的编码器或编码器-解码器架构更优，仅解码器架构仅在大型规模下才能匹配或超越这些架构。"}}
{"id": "2512.10282", "pdf": "https://arxiv.org/pdf/2512.10282", "abs": "https://arxiv.org/abs/2512.10282", "authors": ["Waleed Razzaq", "Izis Kankaraway", "Yun-Bo Zhao"], "title": "Neuronal Attention Circuit (NAC) for Representation Learning", "categories": ["cs.AI", "cs.LG"], "comment": "Paper for ICML2026", "summary": "Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \\textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \\textit{content-target} and \\textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.", "AI": {"tldr": "NAC是一种新型的连续时间注意力机制，通过将注意力对数计算重构为线性一阶ODE的解，实现了生物启发的稀疏门控结构，在多个任务中达到或超越基线性能。", "motivation": "传统注意力机制具有离散性质，限制了连续时间建模能力。需要一种既能保持注意力优势又能进行连续时间建模的生物合理机制。", "method": "利用C. elegans神经元电路策略的连线机制，构建稀疏感觉门进行键-查询投影，采用稀疏骨干网络计算内容-目标和可学习时间常数门，支持三种注意力对数计算模式。", "result": "NAC在多个领域（不规则时间序列分类、自动驾驶车道保持、工业预测）中匹配或优于竞争基线，在运行时间和内存效率方面处于中等水平。", "conclusion": "NAC成功地将注意力机制扩展到连续时间领域，提供了理论保证和实际有效性，为连续时间建模提供了新的生物启发解决方案。"}}
{"id": "2512.10575", "pdf": "https://arxiv.org/pdf/2512.10575", "abs": "https://arxiv.org/abs/2512.10575", "authors": ["Hang Ding", "Qiming Feng", "Dongqi Liu", "Qi Zhao", "Tao Yao", "Shuo Wang", "Dongsheng Chen", "Jian Li", "Zhenye Gan", "Jiangning Zhang", "Chengjie Wang", "Yabiao Wang"], "title": "RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems", "categories": ["cs.CL"], "comment": null, "summary": "Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.", "AI": {"tldr": "RoleRMBench是首个角色扮演对话奖励建模系统基准，RoleRM模型通过连续隐式偏好方法在主观评价任务上显著超越现有奖励模型24%以上", "motivation": "现有奖励模型在主观开放式领域（如角色扮演）表现严重退化，无法捕捉基于角色的细微人类判断", "method": "提出RoleRMBench基准覆盖7种细粒度能力，开发RoleRM模型采用连续隐式偏好(CIP)方法，将主观评价重构为多结构策略下的连续一致成对监督", "result": "RoleRM在RoleRMBench上平均超越强开源和闭源奖励模型24%以上，在叙事连贯性和风格保真度方面取得显著提升", "conclusion": "连续偏好表示和标注一致性对于以人为中心的对话系统的主观对齐至关重要，为后续研究奠定了基础"}}
{"id": "2512.10300", "pdf": "https://arxiv.org/pdf/2512.10300", "abs": "https://arxiv.org/abs/2512.10300", "authors": ["Yanbei Jiang", "Xueqi Ma", "Shu Liu", "Sarah Monazam Erfani", "Tongliang Liu", "James Bailey", "Jey Han Lau", "Krista A. Ehinger"], "title": "Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules", "categories": ["cs.AI"], "comment": null, "summary": "Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.", "AI": {"tldr": "本文提出了一个新的可解释性框架CogVision，通过分解多模态问题为逐步子问题来分析视觉语言模型的注意力头功能，发现功能头稀疏但关键，移除会降低性能，强调则提升准确性。", "motivation": "尽管视觉语言模型在多模态基准测试中表现出色，但其内部机制仍是一个黑箱，需要系统性的可解释性分析来理解其多模态推理过程。", "method": "引入CogVision数据集，将复杂多模态问题分解为模拟人类链式思维的子问题；使用探测方法识别专门处理特定认知功能的注意力头（功能头）；进行干预实验验证功能头的作用。", "result": "发现功能头在不同VLM家族中普遍稀疏，数量和分布因功能而异，介导交互和层次组织；移除功能头导致性能下降，强调功能头则提高准确性。", "conclusion": "研究揭示了VLM的认知组织结构，为设计更符合人类感知和推理能力的模型提供了新方向。"}}
{"id": "2512.10624", "pdf": "https://arxiv.org/pdf/2512.10624", "abs": "https://arxiv.org/abs/2512.10624", "authors": ["Bo Yang", "Lanfei Feng", "Yunkui Chen", "Yu Zhang", "Jianyu Zhang", "Xiao Xu", "Nueraili Aierken", "Shijian Li"], "title": "AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence", "categories": ["cs.CL"], "comment": null, "summary": "Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.", "AI": {"tldr": "AgriGPT-Omni是一个农业全模态框架，通过整合语音、视觉和文本，解决了农业AI应用中多语言语音数据缺乏、统一架构缺失和评估基准不足的问题。", "motivation": "农业AI应用面临多语言语音数据稀缺、缺乏统一的多模态架构和全面的评估基准，限制了其在农业领域的发展和应用。", "method": "1) 构建可扩展的数据合成和收集管道，创建了最大的农业语音数据集；2) 通过三阶段训练范式（文本知识注入、渐进式多模态对齐、GRPO强化学习）训练农业全模型；3) 提出首个三模态农业基准AgriBench-Omni-2K。", "result": "AgriGPT-Omni在多语言和多模态推理以及实际语音理解方面显著优于通用基线模型。", "conclusion": "该研究为农业AI提供了完整的解决方案，包括模型、数据、基准和代码，将促进可重复研究、包容性农业智能和低资源地区的可持续AI发展。"}}
{"id": "2512.10304", "pdf": "https://arxiv.org/pdf/2512.10304", "abs": "https://arxiv.org/abs/2512.10304", "authors": ["Byeong Ho Kang", "Wenli Yang", "Muhammad Bilal Amin"], "title": "Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.", "AI": {"tldr": "本文提出了可信编排AI的十大标准框架，通过控制面板架构将治理机制嵌入AI生态系统，确保AI系统的可验证性、透明性、可重复性和人类有效控制。", "motivation": "AI系统在承担重要决策角色时，技术能力与制度问责之间存在日益扩大的差距，仅靠伦理指导不足以应对这一挑战，需要将治理架构嵌入执行层面。", "method": "提出可信编排AI的十大标准框架，整合人类输入、语义一致性、审计和溯源完整性，采用控制面板架构，为整个AI组件、消费者和人类参与者提供治理保障。", "result": "开发了一个统一的治理框架，能够系统地将可信性工程化地融入AI系统，确保执行层面保持可验证、透明、可重复且在人类有意义的控制下。", "conclusion": "该框架证明了可信性可以通过工程方法系统性地纳入AI系统，为AI生态系统提供了全面的治理保障，填补了技术能力与制度问责之间的鸿沟。"}}
{"id": "2512.10630", "pdf": "https://arxiv.org/pdf/2512.10630", "abs": "https://arxiv.org/abs/2512.10630", "authors": ["Smiljana Antonijevic Ubois"], "title": "From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.", "AI": {"tldr": "该研究以塞尔维亚语为例，分析了AI时代低资源语言技术发展的结构性挑战，提出了基于CARE原则的Data Care框架来解决数据偏见和文化盲点问题。", "motivation": "大型语言模型主要基于英语等主导语言训练，对低资源语言的表示反映了源语言材料中的文化和语言偏见，需要解决这些偏见以建立更包容的语言技术。", "method": "通过对10位学者和从业者（包括语言学家、数字人文主义者和AI开发者）进行半结构化访谈，分析塞尔维亚语技术发展的历史和当代挑战。", "result": "识别出历史文本遗产破坏、表面音译、依赖英语模型、数据偏见和缺乏文化特性的数据集管理等挑战，提出了Data Care框架。", "conclusion": "Data Care框架将偏见缓解从事后技术修复重新定义为语料库设计、注释和治理的核心组成部分，为在传统LLM开发复制现有权力不平衡和文化盲点的背景下构建包容、可持续和文化基础的语言技术提供了可复制模型。"}}
{"id": "2512.10305", "pdf": "https://arxiv.org/pdf/2512.10305", "abs": "https://arxiv.org/abs/2512.10305", "authors": ["Quanmin Wei", "Penglin Dai", "Wei Li", "Bingyi Liu", "Xiao Wu"], "title": "InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck", "categories": ["cs.AI"], "comment": "Accepted by the 40th AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.", "AI": {"tldr": "InfoCom是一个基于信息瓶颈理论的高效通信协作感知框架，通过信息净化范式将通信开销从MB级降至KB级，在保持近乎无损感知性能的同时实现440倍和90倍的通信压缩。", "motivation": "解决协作感知中通信与性能的根本权衡问题，现有方法假设MB级数据传输在实际网络约束下可能失败，需要更高效的通信方案。", "method": "引入信息净化范式，包含：1)信息感知编码压缩特征为最小消息；2)稀疏掩码生成识别空间线索；3)多尺度解码通过掩码引导机制恢复感知信息。", "result": "在多个数据集上实现近乎无损的感知性能，通信开销从MB级降至KB级，相比Where2comm和ERMVP分别减少440倍和90倍。", "conclusion": "InfoCom建立了通信高效协作感知的理论基础，通过信息瓶颈约束优化提取最小充分任务关键信息，为实际自动驾驶系统提供了可行的通信解决方案。"}}
{"id": "2512.10734", "pdf": "https://arxiv.org/pdf/2512.10734", "abs": "https://arxiv.org/abs/2512.10734", "authors": ["Rebekka Görge", "Sujan Sai Gannamaneni", "Tabea Naeven", "Hammam Abdelwahab", "Héctor Allende-Cid", "Armin B. Cremers", "Lennard Helmer", "Michael Mock", "Anna Schmitz", "Songkai Xue", "Elif Yildirir", "Maximilian Poretschkin", "Stefan Wrobel"], "title": "Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.", "AI": {"tldr": "本文提出一个全面的数据偏见检测与缓解流水线，包含四个组件来处理表示偏见和显性刻板印象，通过LLM生成词表、量化表示偏见、过滤刻板印象和反事实数据增强等方法，在性别、宗教和年龄等敏感属性上验证了数据去偏效果，但发现模型微调后偏见评估结果并不一致改善。", "motivation": "大语言模型训练数据存在多方面的偏见表现，包括有害语言和倾斜的人口统计分布。欧盟AI法案等法规要求识别和减轻针对受保护群体的数据偏见，但缺乏实际操作指导。", "method": "提出四步流水线：1)使用LLM生成符合质量标准的群体标签词表；2)用人口统计表示分数量化表示偏见；3)基于社会语言学知识过滤刻板印象；4)通过语法和上下文感知的反事实数据增强补偿表示偏见。", "result": "在数据去偏方面成功减少了文本数据集中的表示偏见和显性刻板印象。但在模型偏见减少方面，使用去偏数据微调的LLM在偏见基准测试中并未一致表现出改进性能。", "conclusion": "当前评估方法存在关键差距，需要针对性的数据操作来解决表现出的模型偏见，数据去偏本身有效但不足以确保模型偏见的系统性减少。"}}
{"id": "2512.10313", "pdf": "https://arxiv.org/pdf/2512.10313", "abs": "https://arxiv.org/abs/2512.10313", "authors": ["Kangkun Mao", "Fang Xu", "Jinru Ding", "Yidong Jiang", "Yujun Yao", "Yirong Chen", "Junming Liu", "Xiaoqin Wu", "Qian Wu", "Xiaoyan Huang", "Jie Xu"], "title": "EpiPlanAgent: Agentic Automated Epidemic Response Planning", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.", "AI": {"tldr": "EpiPlanAgent是一个基于大语言模型的多智能体系统，能自动生成和验证数字应急响应计划，显著提高计划完整性和指南一致性，大幅减少开发时间。", "motivation": "传统流行病应对规划依赖劳动密集型手动方法，需要更高效、自动化的解决方案来提升公共卫生应急准备能力。", "method": "采用多智能体框架，集成任务分解、知识基础和模拟模块，使用真实疫情场景在受控环境中由公共卫生专业人员测试系统。", "result": "系统显著提高了计划的完整性和指南对齐度，大幅减少了开发时间，专家评估确认AI生成内容与人工撰写内容高度一致，用户反馈显示强烈的感知效用。", "conclusion": "EpiPlanAgent为智能流行病应对规划提供了有效、可扩展的解决方案，展示了智能体AI在转变公共卫生准备方面的潜力。"}}
{"id": "2512.10739", "pdf": "https://arxiv.org/pdf/2512.10739", "abs": "https://arxiv.org/abs/2512.10739", "authors": ["Songyang Gao", "Yuzhe Gu", "Zijian Wu", "Lingkai Kong", "Wenwei Zhang", "Zhongrui Cai", "Fan Zheng", "Tianyou Ma", "Junhao Shen", "Haiteng Zhao", "Duanyang Zhang", "Huilun Zhang", "Kuikun Liu", "Chengqi Lyu", "Yanhui Duan", "Chiyu Chen", "Ningsheng Ma", "Jianfei Gao", "Han Lyu", "Dahua Lin", "Kai Chen"], "title": "Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \\textbf{O}utcome-based \\textbf{P}rocess \\textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \\textsc{\\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\\% to 73.3\\% on AIME2025 as the compute budget scales.", "AI": {"tldr": "本文提出了OPV（基于结果的流程验证器），通过验证长推理链中总结结果的推理过程，实现了准确高效的验证和大规模标注，在多个基准测试中达到最先进性能。", "motivation": "当前基于结果的验证器无法检查长推理链中的不可靠中间步骤，而基于过程的验证器由于人工标注成本高昂导致高质量标注稀缺，难以可靠检测复杂长推理链中的错误。", "method": "提出OPV验证器，采用迭代主动学习框架，通过专家标注最不确定的案例，使用拒绝微调(RFT)和RLVR训练新的OPV，逐步提升验证能力。", "result": "OPV在held-out benchmark上获得83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作可将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%。", "conclusion": "OPV通过结合结果和过程验证的优势，实现了准确高效的推理链验证，为大规模语言模型的可靠推理提供了有效的验证解决方案。"}}
{"id": "2512.10322", "pdf": "https://arxiv.org/pdf/2512.10322", "abs": "https://arxiv.org/abs/2512.10322", "authors": ["Yongqiang Yu", "Xuhui Li", "Hazza Mahmood", "Jinxing Zhou", "Haodong Hong", "Longtao Jiang", "Zhiqiang Xu", "Qi Wu", "Xiaojun Chang"], "title": "User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation", "categories": ["cs.AI"], "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.", "AI": {"tldr": "本文提出了一个用户反馈驱动的视觉语言导航适应框架，通过整合人类交互来增强环境适应性，使用记忆库热启动机制提升导航成功率和路径效率。", "motivation": "当前的GSA-VLN框架缺乏用户反馈机制，仅依赖无监督的环境适应，而实际部署中用户反馈可以提供有价值的监督信号来显著提升适应质量。", "method": "开发了用户反馈驱动的适应框架，将用户导航指令和纠正信号转换为高质量的环境对齐训练数据，并采用记忆库热启动机制重用已获取的环境知识。", "result": "在GSA-R2R基准测试中，该方法持续超越GR-DUET等强基线，提高了导航成功率和路径效率，记忆库热启动稳定了早期导航并减少了更新后的性能下降。", "conclusion": "该方法在持续和混合适应设置下都表现出鲁棒性和通用性，证明了用户反馈在提升视觉语言导航实际部署效果中的重要作用。"}}
{"id": "2512.10741", "pdf": "https://arxiv.org/pdf/2512.10741", "abs": "https://arxiv.org/abs/2512.10741", "authors": ["Elroy Galbraith", "Chadwick Sutherland", "Donahue Morgan"], "title": "TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage", "categories": ["cs.CL"], "comment": null, "summary": "Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.\n  The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.\n  We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.", "AI": {"tldr": "TRIDENT是一个三层调度员支持架构，通过加勒比口音优化的ASR、本地实体提取和生物声学痛苦检测，在语音识别失败时仍能提供转录置信度、结构化临床实体和声音压力指标，确保加勒比口音人群获得公平的紧急分诊服务。", "motivation": "紧急语音识别系统在非标准英语变体（如加勒比口音）上存在系统性性能下降，导致加勒比人群服务出现关键缺口。", "method": "采用三层架构：加勒比口音优化的自动语音识别、基于大语言模型的本地实体提取、生物声学痛苦检测。结合心理语言学研究中压力诱发语码转换的理论基础。", "result": "提出了TRIDENT系统架构，能够为调度员提供三个互补信号：转录置信度、结构化临床实体和声音压力指标。低ASR置信度可作为队列优先排序信号。", "conclusion": "建立了一个口音弹性的紧急AI框架，确保加勒比口音人群能够公平获得国家分诊协议服务，但还需要在加勒比紧急呼叫上进行实证验证。"}}
{"id": "2512.10339", "pdf": "https://arxiv.org/pdf/2512.10339", "abs": "https://arxiv.org/abs/2512.10339", "authors": ["Ziseok Lee", "Minyeong Hwang", "Sanghyun Jo", "Wooyeol Lee", "Jihyung Ko", "Young Bin Park", "Jae-Mun Choi", "Eunho Yang", "Kyungsu Kim"], "title": "On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering", "categories": ["cs.AI"], "comment": null, "summary": "Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.", "AI": {"tldr": "论文提出了ACE方法解决概率密度比方法中的边缘路径崩溃问题，通过自适应路径校正实现异构模型的稳定组合生成。", "motivation": "现有的概率密度比方法在组合异构扩散模型时会出现边缘路径崩溃问题，导致中间密度无法归一化，特别是在分子设计等需要组合不同专家模型的场景中。", "method": "提出ACE（Adaptive path Correction with Exponents）方法：1）推导路径存在性准则预测崩溃发生条件；2）扩展Feynman-Kac引导方法支持时变指数，确保有效概率路径。", "result": "在合成2D基准测试和柔性姿态支架装饰任务中，ACE消除了崩溃问题，实现了高引导组合生成，在分布和对接指标上优于恒定指数基线和专用任务模型。", "conclusion": "ACE方法将概率密度比引导从启发式方法转变为可靠的可控生成工具，为异构专家模型的组合应用提供了理论保证和实践解决方案。"}}
{"id": "2512.10756", "pdf": "https://arxiv.org/pdf/2512.10756", "abs": "https://arxiv.org/abs/2512.10756", "authors": ["Zijian Wu", "Lingkai Kong", "Wenwei Zhang", "Songyang Gao", "Yuzhe Gu", "Zhongrui Cai", "Tianyou Ma", "Yuhong Liu", "Zhi Wang", "Runyuan Ma", "Guangyu Wang", "Wei Li", "Conghui He", "Dahua Lin", "Kai Chen"], "title": "OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.", "AI": {"tldr": "提出了基于结果的流程验证器（OPV），通过验证长推理链中总结结果的推理过程，实现了准确高效的验证和大规模标注，在多个基准测试中达到最先进性能。", "motivation": "当前基于结果的验证器无法检查长推理链中的不可靠中间步骤，而基于过程的验证器由于人工标注成本高昂导致高质量标注稀缺，难以可靠检测复杂长推理链中的错误。", "method": "采用迭代主动学习框架，通过专家标注最不确定的案例，使用拒绝微调（RFT）和RLVR训练新的OPV验证器，逐步提升验证能力。", "result": "OPV在OPV-Bench上达到83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作时显著提升性能，如将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%。", "conclusion": "OPV通过结合结果和过程验证的优势，实现了准确高效的推理验证，降低了标注成本，具有广泛的适用性和优越的性能表现。"}}
{"id": "2512.10348", "pdf": "https://arxiv.org/pdf/2512.10348", "abs": "https://arxiv.org/abs/2512.10348", "authors": ["Wenhan Wu", "Zhili He", "Huanghuang Liang", "Yili Gong", "Jiawei Jiang", "Chuang Hu", "Dazhao Cheng"], "title": "REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature", "categories": ["cs.AI"], "comment": "The 40th Annual AAAI Conference on Artificial Intelligence", "summary": "Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party's contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.", "AI": {"tldr": "REMISVFU是一个用于垂直联邦学习的即插即用表示误导框架，通过将遗忘方的编码器输出压缩到单位球面上的随机锚点来实现快速客户端级遗忘，同时通过梯度正交投影保持剩余方的模型效用。", "motivation": "GDPR等数据保护法规赋予联邦系统中参与者被遗忘权，但现有遗忘技术主要针对水平联邦学习，而特征分区的垂直联邦学习架构使得这些方法失效，需要专门解决方案。", "method": "提出表示误导框架：遗忘方将编码器输出压缩到随机锚点以切断特征与全局模型的统计联系；服务器通过联合优化保留损失和遗忘损失，使用正交投影对齐梯度以避免破坏性干扰。", "result": "在公共基准测试中，REMISVFU将后门攻击成功率抑制到自然类别先验水平，仅牺牲约2.5%的干净准确率，优于现有最先进基线方法。", "conclusion": "该框架有效解决了垂直联邦学习中的遗忘问题，在保证模型效用的同时实现了快速客户端级遗忘，满足了数据保护法规的要求。"}}
{"id": "2512.10772", "pdf": "https://arxiv.org/pdf/2512.10772", "abs": "https://arxiv.org/abs/2512.10772", "authors": ["Kevin Glocker", "Kätriin Kukk", "Romina Oji", "Marcel Bollmann", "Marco Kuhlmann", "Jenny Kunz"], "title": "Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model's capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.", "AI": {"tldr": "研究表明，通过扩大英语基础模型的规模再进行目标语言适应训练，比传统持续预训练更有效率和资源友好，能够减少灾难性遗忘，且合并语言特定模型可构建模块化多语言系统。", "motivation": "解决多语言模型中中低资源语言性能不佳的问题，探索通过模型规模扩展来提高语言适应效率和性能。", "method": "进行全面的规模消融实验，使用FLOP匹配的模型比较扩大英语基础模型规模与标准持续预训练的效果，并探索语言特定模型的合并方法。", "result": "扩大规模的模型在获得足够目标语言数据后，性能可匹配或超过使用更多数据持续预训练的小模型，同时能更好地保持英语能力。模型合并虽然不如联合多语言训练有效，但扩大规模的合并效果更好。", "conclusion": "模型规模扩展是提高语言适应数据效率和减少灾难性遗忘的有效策略，合并语言特定模型为构建模块化多语言系统提供了可行途径，但合并方法仍有改进空间。"}}
{"id": "2512.10370", "pdf": "https://arxiv.org/pdf/2512.10370", "abs": "https://arxiv.org/abs/2512.10370", "authors": ["Ziying Zhang", "Quanming Yao", "Yaqing Wang"], "title": "LLM-Empowered Representation Learning for Emerging Item Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.", "AI": {"tldr": "EmerFlow：基于LLM的新兴物品推荐框架，通过大语言模型推理增强特征表示，与现有推荐模型嵌入空间对齐，结合元学习优化，在有限交互数据下实现更好的新兴物品推荐效果。", "motivation": "现有推荐方法通常假设新兴物品历史交互很少或没有，但忽视了其交互逐渐积累的动态过程，无法同时保持新兴物品的独特性和利用与成熟物品的共享模式。", "method": "提出EmerFlow框架：1) 使用LLM推理增强新兴物品的原始特征；2) 将这些表示与现有推荐模型的嵌入空间对齐；3) 通过元学习整合新交互来优化嵌入表示。", "result": "在电影和医药等多个领域的广泛实验表明，EmerFlow始终优于现有方法，能够从有限交互中学习到更具表达力的新兴物品嵌入。", "conclusion": "EmerFlow成功解决了新兴物品推荐中的动态表示学习问题，通过LLM赋能和元学习的结合，为有限交互数据下的新兴物品提供了有效的嵌入表示解决方案。"}}
{"id": "2512.10780", "pdf": "https://arxiv.org/pdf/2512.10780", "abs": "https://arxiv.org/abs/2512.10780", "authors": ["Manurag Khullar", "Utkarsh Desai", "Poorva Malviya", "Aman Dalmia", "Zheyuan Ryan Shi"], "title": "Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.", "AI": {"tldr": "LLMs在印度临床应用中处理罗马化印度语言文本时性能显著下降，F1分数比原生脚本低5-12分，可能导致近200万次分类错误，揭示基于LLM的健康系统存在安全盲点", "motivation": "印度语言使用者经常使用罗马化文本而非原生文字进行交流，但现有研究很少使用真实数据评估这种书写变体对LLM可靠性的影响", "method": "在孕产妇和新生儿医疗分诊关键领域，使用包含五种印度语言和尼泊尔语的真实用户查询数据集，对主流LLM进行基准测试", "result": "罗马化消息导致性能一致下降，F1分数比原生脚本低5-12分，可能造成近200万次额外分诊错误。LLM能正确推断罗马化查询的语义意图，但最终分类输出在罗马化输入的正字法噪声面前仍然脆弱", "conclusion": "研究揭示了基于LLM的健康系统中一个关键的安全盲点：看似理解罗马化输入的模型可能仍无法可靠地对其采取行动，需要改进模型处理罗马化文本的能力"}}
{"id": "2512.10371", "pdf": "https://arxiv.org/pdf/2512.10371", "abs": "https://arxiv.org/abs/2512.10371", "authors": ["Shizuo Tian", "Hao Wen", "Yuxuan Chen", "Jiacheng Liu", "Shanhui Zhao", "Guohong Liu", "Ju Ren", "Yunxin Liu", "Yuanchun Li"], "title": "AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management", "categories": ["cs.AI"], "comment": "16 pages, 8 figures", "summary": "The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.", "AI": {"tldr": "AgentProg是一个程序引导的移动GUI代理上下文管理方法，通过将交互历史重构为带有变量和控制流的程序结构来减少上下文开销，在长时任务中保持稳健性能。", "motivation": "移动GUI代理的长时任务自动化面临依赖不断扩展的交互历史导致上下文开销过大的瓶颈问题，现有上下文管理和压缩技术往往无法保留关键语义信息。", "method": "提出程序引导的上下文管理方法，将交互历史组织为程序结构（变量和控制流），并集成基于Belief MDP框架的全局信念状态机制来处理部分可观测性和环境变化。", "result": "在AndroidWorld和扩展的长时任务套件上实现了最先进的成功率，在长时任务中保持稳健性能，而基线方法出现灾难性性能下降。", "conclusion": "AgentProg通过程序化结构提供了一种原则性机制来确定信息保留策略，有效解决了长时任务自动化中的上下文管理问题，系统已开源。"}}
{"id": "2512.10791", "pdf": "https://arxiv.org/pdf/2512.10791", "abs": "https://arxiv.org/abs/2512.10791", "authors": ["Aileen Cheng", "Alon Jacovi", "Amir Globerson", "Ben Golan", "Charles Kwong", "Chris Alberti", "Connie Tao", "Eyal Ben-David", "Gaurav Singh Tomar", "Lukas Haas", "Yonatan Bitton", "Adam Bloniarz", "Aijun Bai", "Andrew Wang", "Anfal Siddiqui", "Arturo Bajuelos Castillo", "Aviel Atias", "Chang Liu", "Corey Fry", "Daniel Balle", "Deepanway Ghosal", "Doron Kukliansky", "Dror Marcus", "Elena Gribovskaya", "Eran Ofek", "Honglei Zhuang", "Itay Laish", "Jan Ackermann", "Lily Wang", "Meg Risdal", "Megan Barnes", "Michael Fink", "Mohamed Amin", "Moran Ambar", "Natan Potikha", "Nikita Gupta", "Nitzan Katz", "Noam Velan", "Ofir Roval", "Ori Ram", "Polina Zablotskaia", "Prathamesh Bang", "Priyanka Agrawal", "Rakesh Ghiya", "Sanjay Ganapathy", "Simon Baumgartner", "Sofia Erell", "Sushant Prakash", "Thibault Sellam", "Vikram Rao", "Xuanhui Wang", "Yaroslav Akulov", "Yulong Yang", "Zhen Yang", "Zhixin Lai", "Zhongru Wu", "Anca Dragan", "Avinatan Hassidim", "Fernando Pereira", "Slav Petrov", "Srinivasan Venkatachary", "Tulsee Doshi", "Yossi Matias", "Sasha Goldshtein", "Dipanjan Das"], "title": "The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models' world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model's overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .", "AI": {"tldr": "FACTS Leaderboard是一个全面的语言模型事实准确性评估套件，包含四个子榜单：多模态、参数化、搜索和文档基础评估，通过自动化评分模型综合评估模型的事实准确性。", "motivation": "需要全面评估语言模型在不同场景下生成事实准确文本的能力，传统评估方法可能无法覆盖多模态、搜索等多样化场景。", "method": "建立四个子评估榜单：FACTS Multimodal（图像问答）、FACTS Parametric（闭卷事实问答）、FACTS Search（搜索信息场景）、FACTS Grounding（文档基础长文本生成），使用自动化评分模型进行评分，最终得分为四个子榜单的平均分。", "result": "开发了一个在线评估套件，包含公开和私有数据集，提供对语言模型事实准确性的全面、平衡和稳健评估。", "conclusion": "FACTS Leaderboard Suite为评估语言模型的事实准确性提供了全面的基准测试框架，将持续维护更新，支持外部参与同时保证评估完整性。"}}
{"id": "2512.10414", "pdf": "https://arxiv.org/pdf/2512.10414", "abs": "https://arxiv.org/abs/2512.10414", "authors": ["Yang Yu", "Zhuangzhuang Chen", "Siqi Wang", "Lanqing Li", "Xiaomeng Li"], "title": "Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention", "categories": ["cs.AI"], "comment": null, "summary": "Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL-based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing studies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ignore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the diversity of responses. In this paper, we propose Selective-adversarial Entropy Intervention, namely SaEI, which enhances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the entropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formulates the entropy of sampled responses as an adversarial objective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger answer space during RL sampling. Then, we propose token-selective entropy computation (TsEC) to maximize the effectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.", "AI": {"tldr": "论文提出SaEI方法，通过选择性对抗熵干预增强视觉语言模型的推理能力，在RL采样阶段引入熵干预来提高响应多样性，从而改善策略探索性能。", "motivation": "现有基于RL的微调方法主要关注策略优化阶段的熵干预，忽略了RL采样阶段的熵干预对提升响应多样性和策略性能的潜在价值。", "method": "提出选择性对抗熵干预(SaEI)：1) 熵引导对抗采样(EgAS) - 将采样响应的熵作为对抗目标生成对抗样本；2) 令牌选择性熵计算(TsEC) - 在不破坏事实知识的前提下最大化对抗攻击效果。", "result": "在域内和域外数据集上的大量实验表明，该方法能显著提升策略探索能力，从而增强推理能力。", "conclusion": "SaEI通过RL采样阶段的熵干预有效提升了视觉语言模型的推理性能，证明了采样阶段熵干预的重要性。"}}
{"id": "2512.10793", "pdf": "https://arxiv.org/pdf/2512.10793", "abs": "https://arxiv.org/abs/2512.10793", "authors": ["Michael Schlee", "Christoph Weisser", "Timo Kivimäki", "Melchizedek Mashiku", "Benjamin Saefken"], "title": "LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone's embeddings with the LLM-derived per-class scores -- obtained through structured prompt-engineering strategies -- and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains -- achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification -- while enabling practical trade-offs between accuracy, latency, and cost.", "AI": {"tldr": "LabelFusion是一个融合集成框架，通过学习将传统Transformer分类器与大型语言模型结合，实现准确且成本感知的文本分类预测", "motivation": "解决传统Transformer分类器与LLMs在文本分类中各自优势的互补问题，提供既准确又考虑成本效益的解决方案", "method": "通过连接传统分类器的嵌入向量和LLM的类别分数，使用多层感知机进行融合预测，采用结构化提示工程策略获取LLM输出", "result": "在AG News上达到92.4%准确率，在Reuters 21578主题分类上达到92.3%准确率，实现准确性和成本之间的实用权衡", "conclusion": "LabelFusion成功整合了LLM推理和传统分类器的互补优势，在不同领域提供鲁棒性能，同时平衡准确性、延迟和成本"}}
{"id": "2512.10429", "pdf": "https://arxiv.org/pdf/2512.10429", "abs": "https://arxiv.org/abs/2512.10429", "authors": ["Ezequiel Lopez-Rubio"], "title": "Representation of the structure of graphs by sequences of instructions", "categories": ["cs.AI"], "comment": null, "summary": "The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.", "AI": {"tldr": "提出了一种新的图表示方法，将邻接矩阵转换为字符串指令序列，使图结构能够被深度学习语言模型处理。", "motivation": "当前图表示方法不适用于深度学习语言模型处理，而语言模型在文本处理方面表现出强大能力，需要找到一种将图结构转换为文本形式的方法。", "method": "将图的邻接矩阵通过一系列简单指令逐步构建成字符串表示，该转换过程是可逆的，既能从图生成字符串，也能从字符串重建图。", "result": "提出的表示方法紧凑且保持了图的局部结构模式，初步计算实验显示出积极结果。", "conclusion": "该方法有望提升深度学习模型对图的处理能力，为图分析与深度学习结合提供了新途径。"}}
{"id": "2512.10865", "pdf": "https://arxiv.org/pdf/2512.10865", "abs": "https://arxiv.org/abs/2512.10865", "authors": ["Lilin Qiu"], "title": "Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python", "categories": ["cs.CL"], "comment": null, "summary": "This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.", "AI": {"tldr": "本研究使用计算文本分析方法分析《霍比特人》对话的情感基调，发现对话整体保持积极平静的基调，随着故事发展角色掌控感逐渐增强，展现了小说在紧张与舒适间循环的情感节奏。", "motivation": "探索如何通过计算工具揭示文学作品中的微妙情感结构，分析《霍比特人》对话的情感维度和节奏模式。", "method": "使用正则表达式提取对话文本，经过预处理后使用NRC-VAD词典对情感维度进行量化评分，包括情感轨迹图和词云等可视化方法。", "result": "对话保持高愉悦度（积极）和低唤醒度（平静）的基调，随着故事进展角色掌控感（支配性）逐渐增强，紧张与兴奋时刻通过幽默、友情和宽慰得到平衡。", "conclusion": "计算工具与文学解释相结合能够揭示文学作品中塑造叙事的情感节奏和调节模式，在《霍比特人》中展现了稳定的情感节奏和情感调节机制。"}}
{"id": "2512.10433", "pdf": "https://arxiv.org/pdf/2512.10433", "abs": "https://arxiv.org/abs/2512.10433", "authors": ["Hojun Lee", "Mijin Koo", "Yeji Song", "Nojun Kwak"], "title": "Targeted Data Protection for Diffusion Model by Matching Training Trajectory", "categories": ["cs.AI"], "comment": "AAAI 2026", "summary": "Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.", "AI": {"tldr": "TAFAP是一种针对扩散模型的新型目标数据保护方法，通过轨迹对齐和对抗扰动实现对整个训练过程的控制，成功解决了现有方法在可控性和稳定性方面的不足。", "motivation": "当前扩散模型个性化微调技术普及带来了未经授权数据使用和隐私侵犯的严重问题，现有保护方法只能被动降低图像质量，缺乏稳定控制能力。虽然目标数据保护(TDP)提供了向用户指定目标概念主动重定向的有前景范式，但现有TDP方法由于采用快照匹配方式而控制性差。", "method": "TAFAP采用基于轨迹匹配的方法，受数据集蒸馏启发，通过对抗扰动进行微调来实现轨迹对齐，控制整个训练轨迹而非单个快照，确保持久且可验证的转换效果。", "result": "实验证明TAFAP首次成功实现了扩散模型中的目标转换，同时控制身份和视觉模式，显著优于现有TDP方法，在保持高质量图像的同时实现向目标概念的稳健重定向。", "conclusion": "TAFAP为扩散模型输出提供了可验证的安全保障，并为控制和追踪模型修改提供了新框架，解决了数据保护和隐私问题的关键挑战。"}}
{"id": "2512.10882", "pdf": "https://arxiv.org/pdf/2512.10882", "abs": "https://arxiv.org/abs/2512.10882", "authors": ["Hauke Licht"], "title": "Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity", "categories": ["cs.CL"], "comment": null, "summary": "Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.", "AI": {"tldr": "该研究评估了多模态大语言模型在视频情感分析中的表现，发现在理想条件下模型表现良好且无人口统计偏见，但在真实议会辩论场景中表现不佳，可能影响统计推断。", "motivation": "虽然多模态生成式AI在政治沟通情感分析中具有巨大潜力，但缺乏关于其有效性的实证证据，需要填补这一研究空白。", "method": "使用两个互补的人类标注视频数据集，评估当前多模态大语言模型在视频情感唤起分析中的表现。", "result": "在理想条件下，mLLMs的情感唤起评分高度可靠且无人口统计偏见；但在真实议会辩论录音中，其表现未能达到预期水平。", "conclusion": "研究强调了持续、彻底评估新兴生成式AI方法在政治分析中应用的必要性，并提供了一个可复现的评估框架。"}}
{"id": "2512.10449", "pdf": "https://arxiv.org/pdf/2512.10449", "abs": "https://arxiv.org/abs/2512.10449", "authors": ["Devanshu Sahoo", "Manish Prasad", "Vasudev Majhi", "Jahnvi Singh", "Vinay Chamola", "Yash Sinha", "Murari Mandal", "Dhruv Kumar"], "title": "When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the \"Lazy Reviewer\" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these \"LLM-as-a-Judge\" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping \"Reject\" decisions to \"Accept,\" for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like \"Maximum Mark Magyk\" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.", "AI": {"tldr": "该研究揭示了科学论文评审中LLM系统的脆弱性，通过PDF对抗性操作可以成功操纵评审结果，将拒稿翻转为接受，即使在大型语言模型中也存在显著风险。", "motivation": "随着LLMs在科学同行评审中的广泛应用（包括评审员个人使用和机构正式部署），需要评估这些\"LLM-as-a-Judge\"系统对对抗性PDF操作的鲁棒性。", "method": "研究构建了200篇科学论文数据集，开发了15种领域特定的攻击策略，并在13个语言模型（包括GPT-5、Claude Haiku等）上进行评估，使用新型评估指标WAVS（加权对抗性脆弱性分数）。", "result": "研究发现模糊化策略如\"Maximum Mark Magyk\"能够成功操纵评分，即使在大型模型中也能实现令人担忧的决策翻转率。", "conclusion": "LLM评审系统存在严重的安全漏洞，需要加强对抗性攻击的防护措施，研究将公开完整数据集和注入框架以促进更多相关研究。"}}
{"id": "2412.20505", "pdf": "https://arxiv.org/pdf/2412.20505", "abs": "https://arxiv.org/abs/2412.20505", "authors": ["Hang Ni", "Yuzhi Wang", "Hao Liu"], "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "4 pages, 2 figures, accepted by The 1st Workshop on AI for Urban Planning (AAAI 2025's Workshop)", "summary": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.", "AI": {"tldr": "提出循环城市规划(CUP)新范式，利用大语言模型多智能体框架实现城市计划的持续生成、评估和优化闭环过程", "motivation": "城市化背景下的城市更新面临重大挑战，需要适应性方法来应对不断变化的需求", "method": "基于大语言模型的多智能体框架，包含三个核心组件：规划(生成和优化城市计划)、生活(模拟居民行为互动)、评判(评估计划效果并提供迭代反馈)", "result": "在真实数据集上的实验证明了该框架作为持续适应性规划过程的有效性", "conclusion": "循环城市规划范式能够实现动态响应式的规划方法，为城市更新提供有效的技术解决方案"}}
{"id": "2512.10501", "pdf": "https://arxiv.org/pdf/2512.10501", "abs": "https://arxiv.org/abs/2512.10501", "authors": ["Lim Chien Her", "Ming Yan", "Yunshu Bai", "Ruihao Li", "Hao Zhang"], "title": "Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation", "categories": ["cs.AI"], "comment": null, "summary": "Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.", "AI": {"tldr": "提出一种无需训练的LLM智能体架构，通过Actor-Critic双智能体迭代工作流，实现零样本PCG参数配置，用自然语言控制程序化内容生成工具。", "motivation": "现有PCG工具需要精确配置复杂技术参数，而现成的LLM模型难以弥合抽象用户指令与严格参数规范之间的语义鸿沟。", "method": "采用Actor-Critic双智能体架构，Actor负责参数配置，Critic进行评估，通过迭代工作流自主推理工具参数并逐步优化配置以符合人类设计偏好。", "result": "在3D地图生成任务上验证，实验表明该方法优于单智能体基线，能从自然语言描述生成多样且结构有效的环境，建立了PCG指令跟随的新基准。", "conclusion": "现成LLM可有效重新用作通用智能体来掌控任意PCG工具，通过将负担从模型训练转向架构推理，为无需任务特定微调的复杂软件掌握提供了可扩展框架。"}}
{"id": "2512.10534", "pdf": "https://arxiv.org/pdf/2512.10534", "abs": "https://arxiv.org/abs/2512.10534", "authors": ["Haiteng Zhao", "Junhao Shen", "Yiming Zhang", "Songyang Gao", "Kuikun Liu", "Tianyou Ma", "Fan Zheng", "Dahua Lin", "Wenwei Zhang", "Kai Chen"], "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.", "AI": {"tldr": "InternGeometry是一个基于LLM的几何问题解决代理，通过迭代命题和辅助构造、符号引擎验证以及反馈反思机制，仅用少量训练数据就达到了IMO金牌得主水平的几何问题解决能力。", "motivation": "当前LLM在几何问题解决方面受限于启发式辅助构造能力，而专家模型如AlphaGeometry 2需要大规模数据合成和搜索。本研究旨在构建一个奖牌级别的LLM几何问题解决代理。", "method": "采用迭代命题和辅助构造方法，通过符号引擎验证并基于反馈指导后续提案。引入动态内存机制实现与符号引擎的多次交互，并使用复杂度提升强化学习(CBRL)逐步增加合成问题的复杂度。", "result": "InternGeometry在50道IMO几何问题(2000-2024)中解决了44道，超过金牌得主平均分(40.9)，仅使用13K训练样本(AlphaGeometry 2数据量的0.004%)，并能提出人类解法中未出现的新颖辅助构造。", "conclusion": "InternGeometry展示了LLM代理在专家级几何任务上的巨大潜力，通过创新的交互验证和强化学习方法，以极少的数据量达到了顶级人类表现水平。"}}
{"id": "2512.10563", "pdf": "https://arxiv.org/pdf/2512.10563", "abs": "https://arxiv.org/abs/2512.10563", "authors": ["Xin Guan"], "title": "NormCode: A Semi-Formal Language for Context-Isolated AI Planning", "categories": ["cs.AI"], "comment": null, "summary": "Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.", "AI": {"tldr": "NormCode是一种半正式语言，通过结构化分解和严格的数据隔离设计，解决多步LLM工作流中的上下文污染问题，确保推理步骤间的可靠性和可追溯性。", "motivation": "多步LLM工作流存在上下文污染问题：信息在步骤间积累会导致模型产生幻觉、混淆中间输出和丢失任务约束，需要一种方法来消除跨步骤污染。", "method": "设计NormCode半正式语言，提供三种同构格式：.ncds用于人工编写、.ncd用于机器执行、.ncn用于人工验证。严格分离语义操作（LLM推理，非确定性）和语法操作（确定性数据重构），实现精确的成本和可靠性追踪。", "result": "验证显示：(1)基础X加法算法在任意长度输入上实现100%准确率；(2)成功自托管执行NormCode的五阶段编译器流水线。工作编排器提供依赖驱动调度、SQLite检查点和循环管理。", "conclusion": "NormCode通过设计实现AI工作流的可审计性，解决了法律推理、医疗决策和金融分析等高风险领域对透明度的关键需求。"}}
{"id": "2512.10611", "pdf": "https://arxiv.org/pdf/2512.10611", "abs": "https://arxiv.org/abs/2512.10611", "authors": ["Minghao LI", "Ruihang Wang", "Rui Tan", "Yonggang Wen"], "title": "Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.", "AI": {"tldr": "Phythesis是一个结合大型语言模型和物理引导进化优化的框架，用于自动化数据中心的高效能设计，相比纯LLM方案提升57.3%生成成功率和11.5%的PUE效率", "motivation": "传统数据中心设计方法难以应对系统复杂性，现有AI布局生成方法忽略物理约束，无法满足数据中心可量化运营目标和严格物理要求", "method": "采用迭代双层优化架构：LLM驱动层生成物理合理的三维布局并自我批判优化拓扑结构；物理信息优化层识别最优资产参数和组合", "result": "在三个生成规模上，相比纯LLM方案，生成成功率提升57.3%，功耗使用效率(PUE)改善11.5%", "conclusion": "Phythesis成功将LLM与物理约束优化结合，为数据中心设计提供了既考虑物理可行性又满足运营目标的自动化解决方案"}}
{"id": "2512.10696", "pdf": "https://arxiv.org/pdf/2512.10696", "abs": "https://arxiv.org/abs/2512.10696", "authors": ["Zouying Cao", "Jiaji Deng", "Li Yu", "Weikang Zhou", "Zhaoyang Liu", "Bolin Ding", "Hai Zhao"], "title": "Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 9 figures, 9 tables", "summary": "Procedural memory enables large language model (LLM) agents to internalize \"how-to\" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a \"passive accumulation\" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\\textbf{ReMe}$ ($\\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\\texttt{reme.library}$ dataset to facilitate further research.", "AI": {"tldr": "ReMe框架通过多维度经验提炼、上下文自适应重用和基于效用的精化机制，实现了LLM智能体的动态经验驱动进化，在BFCL-V3和AppWorld基准上达到SOTA性能，并展示了内存缩放效应。", "motivation": "现有LLM智能体框架采用被动积累的静态内存范式，无法实现存储与动态推理的有效结合，需要更智能的记忆生命周期管理机制。", "method": "提出ReMe框架，包含三个核心机制：1) 多维度经验蒸馏（识别成功模式、分析失败原因、生成对比见解）；2) 上下文自适应重用（通过场景感知索引适配新情境）；3) 基于效用的精化（自主添加有效记忆、修剪过时记忆）。", "result": "在BFCL-V3和AppWorld基准测试中达到最先进性能，Qwen3-8B搭配ReMe超越更大的无记忆Qwen3-14B，证明了内存缩放效应和计算效率优势。", "conclusion": "自我进化的记忆系统为终身学习提供了计算效率高的路径，ReMe框架有效解决了静态存储与动态推理之间的差距，释放了代码和数据集促进后续研究。"}}
{"id": "2512.10640", "pdf": "https://arxiv.org/pdf/2512.10640", "abs": "https://arxiv.org/abs/2512.10640", "authors": ["Liang Peng", "Haopeng Liu", "Yixuan Ye", "Cheng Liu", "Wenjun Shen", "Si Wu", "Hau-San Wong"], "title": "Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at https://github.com/THPengL/scRCL.", "AI": {"tldr": "提出scRCL框架，通过结合细胞-基因相互作用和对比学习来改进单细胞数据的细胞类型识别，在多个数据集上优于现有方法。", "motivation": "现有聚类方法主要关注细胞内在结构而忽略细胞-基因关联的重要性，这限制了它们区分密切相关的细胞类型的能力。", "method": "开发了Refinement Contrastive Learning框架（scRCL），包含两个对比分布对齐组件来揭示可靠的细胞结构，以及一个整合基因相关结构学习的精炼模块来增强细胞嵌入。", "result": "在多个单细胞RNA-seq和空间转录组基准数据集上的实验表明，该方法在细胞类型识别准确性上持续优于最先进的基线方法。", "conclusion": "该方法通过有效利用细胞-基因关联，能够识别出具有一致基因表达特征的细胞群体，验证了其生物学相关性，为单细胞组学研究提供了有效的无监督细胞类型识别工具。"}}
{"id": "2512.10787", "pdf": "https://arxiv.org/pdf/2512.10787", "abs": "https://arxiv.org/abs/2512.10787", "authors": ["Moshe Lahmy", "Roi Yozevitch"], "title": "Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly", "categories": ["cs.AI", "cs.CL"], "comment": "24 pages, 2 figures", "summary": "Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \\textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \\textbf{context dilution}, where distractors crowd out relevant information. We propose \\textbf{SEAL-RAG}, a training-free controller that adopts a \\textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\\textbf{S}earch $\\rightarrow$ \\textbf{E}xtract $\\rightarrow$ \\textbf{A}ssess $\\rightarrow$ \\textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \\textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \\textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \\textbf{HotpotQA} and \\textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \\textbf{+3--13 pp} and evidence precision by \\textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \\textbf{+8.0 pp} in accuracy and maintains \\textbf{96\\%} evidence precision compared to 22\\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.", "AI": {"tldr": "SEAL-RAG提出了一种\"替换而非扩展\"的策略来解决多跳查询中的桥接事实缺失问题，通过搜索-提取-评估-循环的机制，在固定检索深度下替换干扰信息，显著提升了答案正确性和证据精确度。", "motivation": "现有的RAG系统在多跳查询中容易因初始检索缺失桥接事实而失败，传统方法通过扩展上下文窗口会导致上下文稀释问题，即干扰信息挤占了相关证据的空间。", "method": "SEAL-RAG采用训练无关的控制器，执行搜索→提取→评估→循环的流程：进行实时实体锚定提取构建缺失实体/关系的间隙规范，触发针对性微查询，使用实体优先排序主动替换干扰信息。", "result": "在HotpotQA上比Self-RAG提升答案正确性3-13个百分点，证据精确度提升12-18个百分点；在2WikiMultiHopQA上比Adaptive-k准确度提升8.0个百分点，证据精确度保持96%（相比CRAG的22%）。", "conclusion": "SEAL-RAG通过固定深度替换策略，在保证可预测成本的同时优化了top-k槽位的精确度，而非仅仅追求广度，为多跳查询的RAG系统提供了有效的解决方案。"}}
{"id": "2512.10655", "pdf": "https://arxiv.org/pdf/2512.10655", "abs": "https://arxiv.org/abs/2512.10655", "authors": ["Tong Zhang", "Carlos Hinojosa", "Bernard Ghanem"], "title": "CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models", "categories": ["cs.AI"], "comment": null, "summary": "Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.", "AI": {"tldr": "CAPTAIN是一个无需训练的方法，通过在去噪过程中直接修改潜在特征来减少扩散模型的记忆效应，同时保持提示对齐和视觉质量。", "motivation": "扩散模型可能会无意中重现训练样本，引发隐私和版权问题，现有方法在减少记忆效应时往往会影响提示对齐效果。", "method": "采用频率噪声初始化减少记忆模式复制，识别最佳去噪时间步进行特征定位，然后从非记忆参考图像注入语义对齐特征到局部潜在区域。", "result": "实验显示CAPTAIN相比基于CFG的基线方法显著减少了记忆效应，同时保持了与目标提示的强对齐。", "conclusion": "CAPTAIN提供了一种有效的训练无关方法来缓解扩散模型的记忆问题，在保护隐私和版权的同时维持了生成质量。"}}
{"id": "2512.10665", "pdf": "https://arxiv.org/pdf/2512.10665", "abs": "https://arxiv.org/abs/2512.10665", "authors": ["Muhua Huang", "Qinlin Zhao", "Xiaoyuan Yi", "Xing Xie"], "title": "On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity", "categories": ["cs.AI"], "comment": "Working Paper", "summary": "As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.", "AI": {"tldr": "该研究探讨了基于大语言模型的多智能体系统中价值多样性对集体行为的影响，发现价值多样性增强价值稳定性、促进涌现行为并带来更多创造性原则，但极端异质性会导致不稳定。", "motivation": "随着基于大语言模型的多智能体系统日益普及，研究此类人工社区的集体行为（如集体智能）变得重要，特别是价值多样性如何塑造AI社区的集体行为。", "method": "使用基于Schwartz基本人类价值理论的自然价值引导方法，构建多智能体模拟，让不同规模的社区进行开放式互动和宪法制定。", "result": "价值多样性增强了价值稳定性，促进了涌现行为，并使智能体在没有外部指导的情况下开发出更多创造性原则，但这些效果呈现递减趋势，极端异质性会导致不稳定。", "conclusion": "价值多样性是未来AI能力的新维度，连接了AI能力与制度涌现的社会学研究，为理解多智能体系统的集体行为提供了重要见解。"}}
{"id": "2512.10671", "pdf": "https://arxiv.org/pdf/2512.10671", "abs": "https://arxiv.org/abs/2512.10671", "authors": ["Oscar Robben", "Saeed Khalilian", "Nirvana Meratnia"], "title": "AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.", "AI": {"tldr": "本文提出了一种基于硬件感知神经架构搜索的早退网络优化框架，通过动态调整出口分支的深度和层类型，在保持或降低计算量的同时提高模型精度。", "motivation": "早退网络能根据输入复杂度动态调整计算量，但设计过程复杂耗时。现有方法主要关注出口位置和数量，而出口分支的深度和层类型对效率和精度同样重要。", "method": "使用硬件感知神经架构搜索来强化出口分支，在优化过程中同时考虑精度和效率，包括自适应阈值调优和不同深度、层类型的出口分支设计。", "result": "在CIFAR-10、CIFAR-100和SVHN数据集上的实验表明，所提框架在相同或更低平均MACs下实现了比现有方法更高的准确率。", "conclusion": "通过硬件感知NAS优化出口分支的深度和层类型，能有效提升早退网络的性能效率平衡，为资源受限设备提供了更优的解决方案。"}}
{"id": "2512.10687", "pdf": "https://arxiv.org/pdf/2512.10687", "abs": "https://arxiv.org/abs/2512.10687", "authors": ["Manon Kempermann", "Sai Suresh Macharla Vasu", "Mahalakshmi Raveenthiran", "Theo Farrell", "Ingmar Weber"], "title": "Challenges of Evaluating LLM Safety for User Welfare", "categories": ["cs.AI", "cs.CY"], "comment": "Paper accepted at IASEAI'26; please cite that peer-reviewed version instead", "summary": "Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.", "AI": {"tldr": "该研究指出现有大语言模型安全评估主要关注普遍风险，但忽略了高风险的个性化建议场景。研究发现评估者必须考虑用户背景信息，仅靠用户提供的上下文不足以进行有效的安全评估，特别是对弱势群体。", "motivation": "当前LLM安全评估主要关注通用风险，但数百万用户在高风险领域（如金融和健康）寻求个性化建议，这些风险是情境依赖的而非普遍的。用户福利安全评估方法仍不成熟。", "method": "通过探索性研究，评估GPT-5、Claude Sonnet 4和Gemini 2.5 Pro在不同脆弱性用户档案下提供的金融和健康建议。比较有上下文信息和无上下文信息的评估结果差异。", "result": "研究发现：1）有上下文信息的评估者比无上下文信息的评估者给出的安全评分显著更低（从5/7降至3/7）；2）即使用户提供了他们认为会披露的上下文信息，评估结果也没有显著改善", "conclusion": "有效的用户福利安全评估需要评估者基于多样化用户档案评估回应，仅靠用户提供的上下文信息不足，特别是对弱势群体。需要开发与现有通用风险评估框架不同的方法。"}}
{"id": "2512.10691", "pdf": "https://arxiv.org/pdf/2512.10691", "abs": "https://arxiv.org/abs/2512.10691", "authors": ["Benjamin Gundersen", "Nicolas Deperrois", "Samuel Ruiperez-Campillo", "Thomas M. Sutter", "Julia E. Vogt", "Michael Moor", "Farhad Nooralahzadeh", "Michael Krauthammer"], "title": "Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning", "categories": ["cs.AI", "cs.CV"], "comment": "10 pages main text (3 figures, 3 tables), 31 pages in total", "summary": "Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning (\"thinking\") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.", "AI": {"tldr": "该研究探讨了在胸部X光视觉语言模型中使用强化学习(RL)和显式推理的效果，发现RL能带来额外性能提升但显式推理效果不明显，最终RL优化的模型在报告生成和视觉定位任务上达到最先进水平。", "motivation": "现有医学视觉语言模型主要依赖监督微调(SFT)，缺乏对答案质量的评估，而强化学习能整合任务特定反馈，在数学和编程任务中结合显式推理已显示显著效果，因此研究在CXR VLM中RL和推理的作用。", "method": "基于Qwen3-VL进行大规模CXR数据的SFT构建RadVLM，然后进行冷启动SFT阶段赋予模型基本推理能力，接着使用具有临床基础的特定任务奖励进行GRPO强化学习，在有无推理的设置下进行匹配RL实验。", "result": "强SFT对基础性能仍至关重要，RL在两个任务上都能带来额外增益，但显式推理并未进一步改善结果。RL优化的RadVLM模型在报告生成和视觉定位任务上超越基线并达到最先进性能。", "conclusion": "临床对齐的强化学习是医学视觉语言模型中监督微调的有力补充，RL优化能显著提升模型性能，但显式推理在CXR任务中效果有限。"}}
{"id": "2512.10702", "pdf": "https://arxiv.org/pdf/2512.10702", "abs": "https://arxiv.org/abs/2512.10702", "authors": ["Wei Fang", "Chiyao Wang", "Wenshuai Ma", "Hui Liu", "Jianqiang Hu", "Xiaona Niu", "Yi Chu", "Mingming Zhang", "Jingxiao Yang", "Dongwei Zhang", "Zelin Li", "Pengyun Liu", "Jiawei Zheng", "Pengke Zhang", "Chaoshi Qin", "Wangang Guo", "Bin Wang", "Yugang Xue", "Wei Zhang", "Zikuan Wang", "Rui Zhu", "Yihui Cao", "Quanmao Lu", "Rui Meng", "Yan Li"], "title": "COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators", "categories": ["cs.AI"], "comment": null, "summary": "Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.\n  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.\n  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.\n  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.", "AI": {"tldr": "CA-GPT AI-OCT系统在OCT引导的PCI规划和评估中，相比通用ChatGPT-5和初级医生表现出显著更优的决策一致性，特别是在支架直径和长度选择等关键指标上。", "motivation": "虽然血管内成像（特别是OCT）能改善PCI治疗效果，但其解读依赖操作者经验。通用AI缺乏领域特异性可靠性，需要开发专门针对OCT引导PCI的AI系统。", "method": "单中心分析96例接受OCT引导PCI的患者，比较CA-GPT、ChatGPT-5和初级医生的手术决策与专家记录的一致性，使用10个预设指标评估PCI前后阶段。", "result": "CA-GPT在PCI前规划中位一致性得分显著更高（5分 vs ChatGPT-5的3分和初级医生的4分），在支架直径选择（90.3% vs 72.2%）和长度选择（80.6% vs 52.8%）上表现优异。PCI后评估同样保持优秀一致性。", "conclusion": "CA-GPT为基础的AI-OCT系统提供了标准化、可靠的血管内成像解读方法，显著增强了操作者专业能力并优化了OCT引导的PCI治疗。"}}
{"id": "2512.10807", "pdf": "https://arxiv.org/pdf/2512.10807", "abs": "https://arxiv.org/abs/2512.10807", "authors": ["Wang Lu", "Yao Zhu", "Jindong Wang"], "title": "HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition", "categories": ["cs.AI"], "comment": "18 pages", "summary": "Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at https://github.com/AIFrontierLab/HAROOD.", "AI": {"tldr": "本文提出了HAROOD基准测试，用于全面评估人类活动识别在分布外场景下的性能，涵盖4种OOD场景、6个数据集和16种方法，发现目前没有单一方法在所有场景下表现最优。", "motivation": "现实场景中个体、设备、环境和时间的差异导致人类活动识别面临显著的分布偏移问题，现有研究缺乏对这些分布外算法效果的全面评估。", "method": "构建HAROOD基准测试，定义4种OOD场景（跨人、跨位置、跨数据集、跨时间），使用6个数据集和16种基于CNN和Transformer的方法，采用两种模型选择协议进行广泛实验。", "result": "实验结果表明没有单一方法在所有分布外场景下始终表现最优，显示出该领域仍有很大改进空间。", "conclusion": "HAROOD基准测试为基于OOD的人类活动识别研究提供了模块化、可扩展的平台，有助于推动该领域的发展。"}}
{"id": "2512.10821", "pdf": "https://arxiv.org/pdf/2512.10821", "abs": "https://arxiv.org/abs/2512.10821", "authors": ["Leijie Wang", "Otilia Stretcu", "Wei Qiao", "Thomas Denby", "Krishnamurthy Viswanathan", "Enming Luo", "Chun-Ta Lu", "Tushar Dogra", "Ranjay Krishna", "Ariel Fuxman"], "title": "Agile Deliberation: Concept Deliberation for Subjective Visual Classification", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through \"concept deliberation\", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called \"Agile Deliberation\" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.", "AI": {"tldr": "论文提出了一个名为\"敏捷审议\"的人机交互框架，通过概念界定和迭代两个阶段帮助用户从模糊概念逐步精确定义视觉分类器，相比自动分解基准提高了7.5%的F1分数", "motivation": "现有的人机交互方法假设用户一开始就有清晰稳定的概念理解，但现实中用户往往从模糊概念开始，需要通过\"概念审议\"过程逐步细化。内容审核专家实践中的这种需求促使开发新框架", "method": "将内容审核专家的审议策略操作化为\"敏捷审议\"框架，包含两个阶段：(1)概念界定-将初始概念分解为结构化子概念层次；(2)概念迭代-展示语义边界案例供用户反馈，迭代调整图像分类器", "result": "通过18个用户会话（每个1.5小时）评估，敏捷审议比自动分解基线F1分数高7.5%，比手动审议高3%以上，参与者报告概念理解更清晰且认知负担更低", "conclusion": "敏捷审议框架有效支持演化性和主观性概念的定义，为人机交互视觉分类系统提供了更符合实际用户需求的解决方案"}}
{"id": "2512.10822", "pdf": "https://arxiv.org/pdf/2512.10822", "abs": "https://arxiv.org/abs/2512.10822", "authors": ["Mumuksh Tayal", "Manan Tayal", "Aditya Singh", "Shishir Kolathaya", "Ravi Prakash"], "title": "V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions", "categories": ["cs.AI", "cs.RO"], "comment": "23 pages, 8 figure, 7 tables", "summary": "Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.", "AI": {"tldr": "V-OCBF是一种新的离线安全强化学习方法，通过从离线演示中学习神经控制屏障函数，无需系统动力学模型或在线交互，即可提供严格的安全保证。", "motivation": "现有离线RL方法只能保证软约束，无法确保前向不变性；而传统CBF方法需要专家设计的屏障函数或完整的系统动力学知识，限制了实际应用。", "method": "提出基于值引导的离线CBF框架：1）学习神经CBF，2）推导递归有限差分屏障更新实现无模型学习，3）采用期望分位数目标避免分布外动作查询，4）结合QP实现实时安全控制。", "result": "在多个案例研究中，V-OCBF相比基线方法显著减少了安全违规次数，同时保持了良好的任务性能。", "conclusion": "V-OCBF展示了在不依赖在线交互或手工设计屏障的情况下，离线合成安全关键控制器的可扩展性，为自主系统安全控制提供了有效解决方案。"}}
{"id": "2512.10895", "pdf": "https://arxiv.org/pdf/2512.10895", "abs": "https://arxiv.org/abs/2512.10895", "authors": ["Lijie Ding", "Janell Thomson", "Jon Taylor", "Changwoo Do"], "title": "LLMs Can Assist with Proposal Selection at Large User Facilities", "categories": ["cs.AI"], "comment": "9 pages, 8figures", "summary": "We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\\simeq 0.2-0.8$, improving to $\\geq 0.5$ after 10\\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.", "AI": {"tldr": "使用大语言模型替代人工评审进行科学项目提案选择，实现了可扩展、一致且成本效益高的评审方案，在排名相关性上表现良好且成本降低两个数量级", "motivation": "传统人工评审存在提案间相关性弱、评审者偏见和不一致性问题，而基于成对偏好的方法虽然更严谨但工作量巨大不实用", "method": "利用LLMs进行成对偏好比较，基于橡树岭国家实验室散裂中子源三个束线的提案和发表记录数据，使用嵌入模型量化提案相似性", "result": "LLM排名与人工排名强相关（Spearman ρ约0.2-0.8，去除10%异常值后≥0.5），在识别高发表潜力提案方面不逊于人类，成本降低两个数量级", "conclusion": "LLMs为科学提案选择提供了可行的自动化解决方案，不仅能有效排名，还能进行提案相似性分析等高级分析，为评审委员会提供重要信息"}}
{"id": "2512.10903", "pdf": "https://arxiv.org/pdf/2512.10903", "abs": "https://arxiv.org/abs/2512.10903", "authors": ["Muhammad Umair Haider", "Hammad Rizwan", "Hassan Sajjad", "A. B. Siddique"], "title": "Multi-Granular Node Pruning for Circuit Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.", "AI": {"tldr": "提出一种节点级剪枝框架，通过多粒度可学习掩码和特定粒度稀疏惩罚，在单次微调中发现更小规模的电路，同时显著降低内存占用。", "motivation": "现有电路发现方法主要依赖迭代边剪枝，计算成本高且仅限于粗粒度单元（如注意力头或MLP块），忽略了神经元级别的细粒度结构。", "method": "引入跨多粒度（从完整块到单个神经元）的可学习掩码，在统一优化目标中使用粒度特定的稀疏惩罚来指导剪枝过程，实现单次微调中的全面压缩。", "result": "方法发现的电路节点数少于现有方法，证明粗粒度方法认为重要的许多神经元实际上无关紧要，同时保持任务性能，内存占用降低5-10倍。", "conclusion": "该节点级剪枝框架解决了电路发现的可扩展性和粒度限制问题，提供了更精确、高效的电路识别方法，为理解LLM内部机制提供了新工具。"}}
{"id": "2512.10937", "pdf": "https://arxiv.org/pdf/2512.10937", "abs": "https://arxiv.org/abs/2512.10937", "authors": ["Matt Wilson"], "title": "On Decision-Making Agents and Higher-Order Causal Processes", "categories": ["cs.AI", "quant-ph"], "comment": null, "summary": "We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.", "AI": {"tldr": "该论文建立了部分可观察马尔可夫决策过程(POMDP)中的智能体与单输入过程函数之间的精确对应关系，揭示了AI和量子物理视角下的对偶解释。", "motivation": "探索POMDP智能体决策与量子操作经典极限之间的数学对应关系，为多智能体系统提供新的理论框架。", "method": "通过将智能体的策略和记忆更新结合成过程函数w，使用链积与POMDP环境交互，建立AI视角和物理视角的对偶解释。", "result": "成功建立了POMDP智能体与单输入过程函数的精确对应关系，并将该框架扩展到多智能体系统的观察无关分散式POMDP。", "conclusion": "该对应关系为理解智能体决策提供了新的量子物理视角，同时为多智能体系统分析提供了统一的数学框架，具有重要的理论和应用价值。"}}
{"id": "2503.18702", "pdf": "https://arxiv.org/pdf/2503.18702", "abs": "https://arxiv.org/abs/2503.18702", "authors": ["David Ph. Shakouri", "Crit Cremers", "Niels O. Schiller"], "title": "Unsupervised Acquisition of Discrete Grammatical Categories", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "34 pages, 3 figures, 7 tables", "summary": "This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.", "AI": {"tldr": "该研究通过多智能体系统模拟语言习得过程，展示如何从语言样本中通过统计分析获得抽象语法知识，并验证了该方法在测试集上的有效性。", "motivation": "构建计算实验室环境来研究语言习得机制，特别是探索智能体如何仅通过语言样本输入获得抽象语法规则，而无需接触母语模型的内部知识。", "method": "使用包含成人语言模型和子语言模型的多智能体系统，通过层次聚合聚类分析对母语模型生成的话语进行统计分析，从中提取离散语法规则。", "result": "实验成功获得了类似自然语言语法范畴的结构，证明了非平凡语法知识的获得，并在测试集上验证了参数配置的有效性。", "conclusion": "该计算实验室环境能够有效模拟语言习得过程，通过统计分析从语言输入中提取抽象语法规则，为理解人类语言获得机制提供了计算模型支持。"}}
