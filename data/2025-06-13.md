<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 89]
- [cs.AI](#cs.AI) [总数: 27]
- [stat.ML](#stat.ML) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Leveraging Pre-Trained Models for Multimodal Class-Incremental Learning under Adaptive Fusion](https://arxiv.org/abs/2506.09999)
*Yukun Chen, Zihuan Qiu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于多模态预训练模型的MCIL方法，包括一个基于MoE结构的多模态增量特征提取器、自适应音视频融合模块、一种新的多模态类增量对比训练损失以及两种针对MCIL的具体评估指标。


<details>
  <summary>更多</summary>
  
**动机:** 传统的MCIL方法仅关注视觉和文本，而本文旨在探索跨越视觉、音频和文本模态的MCIL，并解决整合互补信息及缓解灾难性遗忘的挑战。

**方法:** 1. 引入了基于Mixture-of-Experts (MoE) 结构的Multimodal Incremental Feature Extractor (MIFE)，用于AudioCLIP的有效增量微调。
2. 提出了Adaptive Audio-Visual Fusion Module (AAVFM)，它包含掩码阈值机制和动态特征融合机制，并且有一个策略来增强文本多样性。
3. 设计了一个新颖的多模态类增量对比训练损失，以优化MCIL中的跨模态对齐。
4. 为全面评估引入了两个MCIL特定的评价指标。

**结果:** 在三个多模态数据集上的广泛实验验证了所提方法的有效性。

**结论:** 本文通过提出一种全新的MCIL方法，解决了跨视觉、音频和文本模态学习中的挑战，实现了更好的特征提取、融合和跨模态对齐，并通过新提出的评估指标证明了该方法的优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Pre-Trained+Models+for+Multimodal+Class-Incremental+Learning+under+Adaptive+Fusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.09999，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.09999&send_immediately=true&force_search=false)

**原文摘要:** Unlike traditional Multimodal Class-Incremental Learning (MCIL) methods that
focus only on vision and text, this paper explores MCIL across vision, audio
and text modalities, addressing challenges in integrating complementary
information and mitigating catastrophic forgetting. To tackle these issues, we
propose an MCIL method based on multimodal pre-trained models. Firstly, a
Multimodal Incremental Feature Extractor (MIFE) based on Mixture-of-Experts
(MoE) structure is introduced to achieve effective incremental fine-tuning for
AudioCLIP. Secondly, to enhance feature discriminability and generalization, we
propose an Adaptive Audio-Visual Fusion Module (AAVFM) that includes a masking
threshold mechanism and a dynamic feature fusion mechanism, along with a
strategy to enhance text diversity. Thirdly, a novel multimodal
class-incremental contrastive training loss is proposed to optimize cross-modal
alignment in MCIL. Finally, two MCIL-specific evaluation metrics are introduced
for comprehensive assessment. Extensive experiments on three multimodal
datasets validate the effectiveness of our method.

</details>


### [2] [NOCL: Node-Oriented Conceptualization LLM for Graph Tasks without Message Passing](https://arxiv.org/abs/2506.10014)
*Wei Li, Mengcheng Lan, Jiaxing Xu, Yiping Ke*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为Node-Oriented Conceptualization LLM (NOCL)的新框架，它通过节点描述和节点概念两种核心技术，扩展了大型语言模型（LLMs）在图数据上的应用能力，并且在零样本场景下展示了优越的泛化性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统图神经网络如消息传递神经网络（MPNNs）严重依赖于监督学习，限制了它们在标签稀缺情况下的通用性和适用性；而最近的自监督方法仍需标记微调，在零样本场景中效果有限。同时，尽管大型语言模型（LLMs）擅长自然语言任务，但在应用于图形时面临挑战，包括保持推理能力、处理丰富的节点属性带来的大量token长度以及仅限于文本属性图（TAGs）和单级任务。

**方法:** 开发了一个称为Node-Oriented Conceptualization LLM (NOCL)的新框架，该框架利用两项核心技术：1) 节点描述，将异构节点属性转换为结构化的自然语言，使LLM从TAGs扩展到非TAGs；2) 节点概念，使用预训练的语言模型将节点描述编码成紧凑的语义嵌入，相比直接使用节点描述，显著减少了高达93.9%的token长度。此外，NOCL还采用图表示描述符来统一不同层次的图任务，形成共享的语言查询格式。

**结果:** 实验结果验证了NOCL相对于传统的MPNNs和混合LLM-MPNN方法具有竞争力的监督性能，并在零样本设置中显示了优越的泛化能力。

**结论:** NOCL框架提供了一种新的方法来克服现有图神经网络和大型语言模型在处理图数据方面的局限性，特别是在标签稀缺和零样本情况下。它不仅扩展了LLMs的应用范围，而且通过创新地将图任务转化为语言查询形式，为图基础模型开辟了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NOCL%3A+Node-Oriented+Conceptualization+LLM+for+Graph+Tasks+without+Message+Passing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10014，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10014&send_immediately=true&force_search=false)

**原文摘要:** Graphs are essential for modeling complex interactions across domains such as
social networks, biology, and recommendation systems. Traditional Graph Neural
Networks, particularly Message Passing Neural Networks (MPNNs), rely heavily on
supervised learning, limiting their generalization and applicability in
label-scarce scenarios. Recent self-supervised approaches still require labeled
fine-tuning, limiting their effectiveness in zero-shot scenarios. Meanwhile,
Large Language Models (LLMs) excel in natural language tasks but face
significant challenges when applied to graphs, including preserving reasoning
abilities, managing extensive token lengths from rich node attributes, and
being limited to textual-attributed graphs (TAGs) and a single level task. To
overcome these limitations, we propose the Node-Oriented Conceptualization LLM
(NOCL), a novel framework that leverages two core techniques: 1) node
description, which converts heterogeneous node attributes into structured
natural language, extending LLM from TAGs to non-TAGs; 2) node concept, which
encodes node descriptions into compact semantic embeddings using pretrained
language models, significantly reducing token lengths by up to 93.9% compared
to directly using node descriptions. Additionally, our NOCL employs graph
representation descriptors to unify graph tasks at various levels into a
shared, language-based query format, paving a new direction for Graph
Foundation Models. Experimental results validate NOCL's competitive supervised
performance relative to traditional MPNNs and hybrid LLM-MPNN methods and
demonstrate superior generalization in zero-shot settings.

</details>


### [3] [Improving the performance of optical inverse design of multilayer thin films using CNN-LSTM tandem neural networks](https://arxiv.org/abs/2506.10044)
*Uijun Jung, Deokho Jang, Sungchul Kim, Jungho Kim*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于深度学习的串联神经网络（TNN）方法来反向设计SiO2/TiO2多层薄膜的透射光谱，该方法解决了传统反向设计中的一对多映射问题。研究发现，基于LSTM-LSTM的TNN虽然准确度最高但训练时间最长，而CNN-LSTM TNN在准确性和速度方面提供了最佳解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 传统的薄层光学反向设计方法需要大量的数值模拟和优化过程，这非常耗时。因此，本文旨在利用深度学习技术来提高预测薄层厚度及其对应光学性质的效率与准确性。

**方法:** 使用了串联神经网络（TNN），它通过将逆向神经网络与预训练的前向神经网络背靠背连接而成。TNN可以基于多种算法实现，包括多层感知器(MLP)、卷积神经网络(CNN)或长短期记忆(LSTM)算法。

**结果:** 结果表明，在所有九种TNN配置中，基于LSTM-LSTM的TNN具有最高的精度但也需要最长的训练时间；相比之下，结合了CNN与LSTM优势的CNN-LSTM TNN被证明是在精度和速度上更优的选择。

**结论:** 深度学习特别是采用特定架构如CNN-LSTM组合的TNN为解决SiO2/TiO2多层薄膜透射光谱的反向设计问题提供了一个有效且高效的新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+the+performance+of+optical+inverse+design+of+multilayer+thin+films+using+CNN-LSTM+tandem+neural+networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10044，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10044&send_immediately=true&force_search=false)

**原文摘要:** Optical properties of thin film are greatly influenced by the thickness of
each layer. Accurately predicting these thicknesses and their corresponding
optical properties is important in the optical inverse design of thin films.
However, traditional inverse design methods usually demand extensive numerical
simulations and optimization procedures, which are time-consuming. In this
paper, we utilize deep learning for the inverse design of the transmission
spectra of SiO2/TiO2 multilayer thin films. We implement a tandem neural
network (TNN), which can solve the one-to-many mapping problem that greatly
degrades the performance of deep-learning-based inverse designs. In general,
the TNN has been implemented by a back-to-back connection of an inverse neural
network and a pre-trained forward neural network, both of which have been
implemented based on multilayer perceptron (MLP) algorithms. In this paper, we
propose to use not only MLP, but also convolutional neural network (CNN) or
long short-term memory (LSTM) algorithms in the configuration of the TNN. We
show that an LSTM-LSTM-based TNN yields the highest accuracy but takes the
longest training time among nine configurations of TNNs. We also find that a
CNN-LSTM-based TNN will be an optimal solution in terms of accuracy and speed
because it could integrate the strengths of the CNN and LSTM algorithms.

</details>


### [4] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
*Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为Omni-DPO的双重视角优化框架，该框架在训练过程中根据每个偏好对的质量和模型的学习动态自适应地加权样本，从而更有效地利用训练数据并提高性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于直接偏好优化（DPO）的方法通常将所有偏好对视为同等重要，忽略了它们内在质量和学习效用的关键差异，导致数据利用不足和性能不佳。

**方法:** 提出了Omni-DPO，一个能够同时考虑每个偏好对固有质量以及模型对于这些偏好对的表现变化的双重视角优化框架。

**结果:** 实验结果表明，Omni-DPO在各种模型和基准测试中都表现出了优越性和泛化能力，并且在文本理解和数学推理任务上均优于基线方法。

**结论:** Omni-DPO通过更智能的数据利用策略提高了从人类反馈中进行强化学习的效率和效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omni-DPO%3A+A+Dual-Perspective+Paradigm+for+Dynamic+Preference+Learning+of+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10054&send_immediately=true&force_search=false)

**原文摘要:** Direct Preference Optimization (DPO) has become a cornerstone of
reinforcement learning from human feedback (RLHF) due to its simplicity and
efficiency. However, existing DPO-based approaches typically treat all
preference pairs uniformly, ignoring critical variations in their inherent
quality and learning utility, leading to suboptimal data utilization and
performance. To address this challenge, we propose Omni-DPO, a dual-perspective
optimization framework that jointly accounts for (1) the inherent quality of
each preference pair and (2) the model's evolving performance on those pairs.
By adaptively weighting samples according to both data quality and the model's
learning dynamics during training, Omni-DPO enables more effective training
data utilization and achieves better performance. Experimental results on
various models and benchmarks demonstrate the superiority and generalization
capabilities of Omni-DPO. On textual understanding tasks, Gemma-2-9b-it
finetuned with Omni-DPO beats the leading LLM, Claude 3 Opus, by a significant
margin of 6.7 points on the Arena-Hard benchmark. On mathematical reasoning
tasks, Omni-DPO consistently outperforms the baseline methods across all
benchmarks, providing strong empirical evidence for the effectiveness and
robustness of our approach. Code and models will be available at
https://github.com/pspdada/Omni-DPO.

</details>


### [5] [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org/abs/2506.10060)
*Brendan Leigh Ross, Noël Vouitsis, Atiyeh Ashari Ghomi, Rasa Hosseinzadeh, Ji Xin, Zhaoyan Liu, Yi Sui, Shiyi Hou, Kin Kwan Leung, Gabriel Loaiza-Ganem, Jesse C. Cresswell*

**主要类别:** cs.LG

**AI概要:** 本文通过将大语言模型系统视为贝叶斯框架下的统计模型，提出了一种新的马尔可夫链蒙特卡洛算法（MHLP），该方法利用少量训练数据对提示进行贝叶斯推理，从而改进了预测准确性和不确定性量化。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）在解决现实世界中的挑战性任务方面变得越来越有能力，但准确量化其不确定性仍然是一个关键的开放问题，这限制了它们在高风险领域的适用性。此外，许多最先进的LLMs是闭源且黑盒性质的，使得这个问题更加复杂。而且，基于LLM的系统对绑定它们的提示非常敏感，通常需要大量的手动调整（即提示工程）。

**方法:** 作者们从贝叶斯视角来看待基于LLM的系统，将提示解释为统计模型中的文本参数，并使用少量训练数据来对这些提示执行贝叶斯推理。为了执行贝叶斯推理，他们引入了一种新颖的马尔可夫链蒙特卡洛（MCMC）算法——Metropolis-Hastings通过LLM提议（MHLP），该算法结合了提示优化技术与标准MCMC方法。

**结果:** 实验结果表明，该方法在一系列LLM基准和不确定性量化任务上提高了预测准确性和不确定性量化。

**结论:** 这项工作展示了如何将丰富的贝叶斯文献中的方法融入到LLM时代，为更可靠和校准良好的基于LLM的系统铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Textual+Bayes%3A+Quantifying+Uncertainty+in+LLM-Based+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10060，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10060&send_immediately=true&force_search=false)

**原文摘要:** Although large language models (LLMs) are becoming increasingly capable of
solving challenging real-world tasks, accurately quantifying their uncertainty
remains a critical open problem, which limits their applicability in
high-stakes domains. This challenge is further compounded by the closed-source,
black-box nature of many state-of-the-art LLMs. Moreover, LLM-based systems can
be highly sensitive to the prompts that bind them together, which often require
significant manual tuning (i.e., prompt engineering). In this work, we address
these challenges by viewing LLM-based systems through a Bayesian lens. We
interpret prompts as textual parameters in a statistical model, allowing us to
use a small training dataset to perform Bayesian inference over these prompts.
This novel perspective enables principled uncertainty quantification over both
the model's textual parameters and its downstream predictions, while also
incorporating prior beliefs about these parameters expressed in free-form text.
To perform Bayesian inference, a difficult problem even for well-studied data
modalities, we introduce Metropolis-Hastings through LLM Proposals (MHLP), a
novel Markov chain Monte Carlo (MCMC) algorithm that combines prompt
optimization techniques with standard MCMC methods. MHLP is a turnkey
modification to existing LLM pipelines, including those that rely exclusively
on closed-source models. Empirically, we demonstrate that our method yields
improvements in both predictive accuracy and uncertainty quantification (UQ) on
a range of LLM benchmarks and UQ tasks. More broadly, our work demonstrates a
viable path for incorporating methods from the rich Bayesian literature into
the era of LLMs, paving the way for more reliable and calibrated LLM-based
systems.

</details>


### [6] [Optimizing Latent Dimension Allocation in Hierarchical VAEs: Balancing Attenuation and Information Retention for OOD Detection](https://arxiv.org/abs/2506.10089)
*Dane Williamson, Yangfeng Ji, Matthew Dwyer*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+Latent+Dimension+Allocation+in+Hierarchical+VAEs%3A+Balancing+Attenuation+and+Information+Retention+for+OOD+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10089，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10089&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution (OOD) detection is a critical task in machine learning,
particularly for safety-critical applications where unexpected inputs must be
reliably flagged. While hierarchical variational autoencoders (HVAEs) offer
improved representational capacity over traditional VAEs, their performance is
highly sensitive to how latent dimensions are distributed across layers.
Existing approaches often allocate latent capacity arbitrarily, leading to
ineffective representations or posterior collapse. In this work, we introduce a
theoretically grounded framework for optimizing latent dimension allocation in
HVAEs, drawing on principles from information theory to formalize the trade-off
between information loss and representational attenuation. We prove the
existence of an optimal allocation ratio $r^{\ast}$ under a fixed latent
budget, and empirically show that tuning this ratio consistently improves OOD
detection performance across datasets and architectures. Our approach
outperforms baseline HVAE configurations and provides practical guidance for
principled latent structure design, leading to more robust OOD detection with
deep generative models.

</details>


### [7] [Efficient kernelized bandit algorithms via exploration distributions](https://arxiv.org/abs/2506.10091)
*Bingshan Hu, Zheng He, Danica J. Sutherland*

**主要类别:** cs.LG

**AI概要:** 提出了一类基于探索分布概念的高效核化bandit算法GP-Generic，该算法可以实现一系列具体算法，并达到与UCB-和汤普森采样算法相匹配的后悔界。


<details>
  <summary>更多</summary>
  
**动机:** 研究者们考虑了一个具有紧凑臂集的核化bandit问题，其中奖励函数在某个再生核希尔伯特空间(RKHS)中具有有限范数。目标是设计一类计算效率高的算法，能够适应不同的探索策略并达到最优后悔界。

**方法:** 提出了一个名为GP-Generic的算法类，它基于一种新的概念：探索分布。这类算法包括基于置信上界(UCB)的方法作为一个特殊情况，但同时允许各种随机化算法的存在。

**结果:** 通过仔细选择探索分布，所提出的通用算法能够实现一系列具体的算法，这些算法达到了$\tilde{O}(\gamma_T\sqrt{T})$的后悔界，这与已知的UCB-和汤普森采样算法的结果相匹配；还表明，在实践中随机化可以产生更好的实际结果。

**结论:** GP-Generic算法类为核化bandit问题提供了一种灵活且有效的解决方案，不仅理论上能达到与现有方法相当的性能，而且在实际应用中可能由于随机化而表现得更好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+kernelized+bandit+algorithms+via+exploration+distributions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10091，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10091&send_immediately=true&force_search=false)

**原文摘要:** We consider a kernelized bandit problem with a compact arm set ${X} \subset
\mathbb{R}^d $ and a fixed but unknown reward function $f^*$ with a finite norm
in some Reproducing Kernel Hilbert Space (RKHS). We propose a class of
computationally efficient kernelized bandit algorithms, which we call
GP-Generic, based on a novel concept: exploration distributions. This class of
algorithms includes Upper Confidence Bound-based approaches as a special case,
but also allows for a variety of randomized algorithms. With careful choice of
exploration distribution, our proposed generic algorithm realizes a wide range
of concrete algorithms that achieve $\tilde{O}(\gamma_T\sqrt{T})$ regret
bounds, where $\gamma_T$ characterizes the RKHS complexity. This matches known
results for UCB- and Thompson Sampling-based algorithms; we also show that in
practice, randomization can yield better practical results.

</details>


### [8] [Unsupervised Deep Clustering of MNIST with Triplet-Enhanced Convolutional Autoencoders](https://arxiv.org/abs/2506.10094)
*Md. Faizul Islam Ansari*

**主要类别:** cs.LG

**AI概要:** 该研究实现了基于两阶段深度自动编码器架构的MNIST手写数字高级无监督聚类系统，结合了重构误差和KMeans聚类损失，通过多种内在和外在度量标准达到了卓越的聚类性能，并使用t-SNE可视化展示了学习到的嵌入表示。


<details>
  <summary>更多</summary>
  
**动机:** 为了实现对手写数字图像的有效聚类，同时保持数据重建的准确性并提高聚类分离纯度，研究者们提出了一个结合深度自动编码器和KMeans聚类损失的联合距离目标函数的方法。

**方法:** 采用两阶段方法：第一阶段训练深度神经自动编码器以最小化重建误差；第二阶段将重建误差与KMeans聚类损失统一在一个联合目标中。模型中还包含了批量归一化、dropout和权重衰减等元素来确保结果的一致性和稳定性。

**结果:** 框架在广泛的测试中表现出色，利用轮廓分数、Davies-Bouldin指数以及NMI和ARI等外部指标评估了图像特征处理时的聚类性能。t-SNE可视化表明，所学得的嵌入能够清晰地区分不同的数字。

**结论:** 这种方法在数据重建准确性和聚类分离纯度之间找到了最优平衡点，同时提供了可理解的结果和可扩展性实现，为大规模图像聚类应用中的无监督表征学习奠定了可靠的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Deep+Clustering+of+MNIST+with+Triplet-Enhanced+Convolutional+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10094&send_immediately=true&force_search=false)

**原文摘要:** This research implements an advanced unsupervised clustering system for MNIST
handwritten digits through two-phase deep autoencoder architecture. A deep
neural autoencoder requires a training process during phase one to develop
minimal yet interpretive representations of images by minimizing reconstruction
errors. During the second phase we unify the reconstruction error with a KMeans
clustering loss for learned latent embeddings through a joint distance-based
objective. Our model contains three elements which include batch normalization
combined with dropout and weight decay for achieving generalized and stable
results. The framework achieves superior clustering performance during
extensive tests which used intrinsic measurements including Silhouette Score
and Davies-Bouldin Index coupled with extrinsic metrics NMI and ARI when
processing image features. The research uses t-SNE visualization to present
learned embeddings that show distinct clusters for digits. Our approach reaches
an optimal combination between data reconstruction accuracy and cluster
separation purity when adding the benefit of understandable results and
scalable implementations. The approach creates a dependable base that helps
deploy unsupervised representation learning in different large-scale image
clustering applications.

</details>


### [9] [Learning to Collaborate Over Graphs: A Selective Federated Multi-Task Learning Approach](https://arxiv.org/abs/2506.10102)
*Ahmed Elbakary, Chaouki Ben Issaid, Mehdi Bennis*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的联邦多任务学习方法，通过引入特征锚点和基于图的正则化来促进客户端之间的协作，并使用基于社区检测的方法确保知识转移的有效性。实验表明该方法优于现有基线，并且在计算和通信效率以及客户公平性方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 为了实现每个客户端的个性化学习，同时避免将整个模型传输到参数服务器，提高联邦学习中的通信效率和协作质量。

**方法:** 设计了一个通信高效的方案，其中包括：1. 特征锚点 - 一个紧凑的向量表示，总结了从客户端本地类学到的特征；2. 分享分类头 - 客户端分享轻量级线性层并执行基于图的正则化以促进协作；3. 动态图建模 - 通过不断更新和细化动态图来考虑客户端的漂移；4. 社区检测 - 将动态图分割成同质社区，以最大化每个社区内的任务相似度总和。

**结果:** 广泛的实验显示所提方法在两个异构数据集上显著优于最先进基线。此外，该方法展现了出色的计算和通信效率，并促进了跨客户端的公平性。

**结论:** 提出的新方法能够有效提升联邦学习场景下的个性化学习效果、通信效率及客户间的公平性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Collaborate+Over+Graphs%3A+A+Selective+Federated+Multi-Task+Learning+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10102，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10102&send_immediately=true&force_search=false)

**原文摘要:** We present a novel federated multi-task learning method that leverages
cross-client similarity to enable personalized learning for each client. To
avoid transmitting the entire model to the parameter server, we propose a
communication-efficient scheme that introduces a feature anchor, a compact
vector representation that summarizes the features learned from the client's
local classes. This feature anchor is shared with the server to account for
local clients' distribution. In addition, the clients share the classification
heads, a lightweight linear layer, and perform a graph-based regularization to
enable collaboration among clients. By modeling collaboration between clients
as a dynamic graph and continuously updating and refining this graph, we can
account for any drift from the clients. To ensure beneficial knowledge transfer
and prevent negative collaboration, we leverage a community detection-based
approach that partitions this dynamic graph into homogeneous communities,
maximizing the sum of task similarities, represented as the graph edges'
weights, within each community. This mechanism restricts collaboration to
highly similar clients within their formed communities, ensuring positive
interaction and preserving personalization. Extensive experiments on two
heterogeneous datasets demonstrate that our method significantly outperforms
state-of-the-art baselines. Furthermore, we show that our method exhibits
superior computation and communication efficiency and promotes fairness across
clients.

</details>


### [10] [NnD: Diffusion-based Generation of Physically-Nonnegative Objects](https://arxiv.org/abs/2506.10112)
*Nadav Torem, Tamar Sde-Chen, Yoav Y. Schechner*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种非负扩散(NnD)模型，用于生成符合物理意义的非负对象，并通过生成三维云体积来展示其效果。


<details>
  <summary>更多</summary>
  
**动机:** 自然物体具有内在复杂性和可变性，而许多现实世界的现象（如云形成）需要昂贵的计算模拟，这限制了扩展性。

**方法:** 提出了一种基于分数的生成模型——非负扩散(NnD)，它使用退火朗之万动力学来确保在场景生成和分析过程中维持非负性。

**结果:** NnD模型能够生成与云物理学趋势一致的3D云体积，并且这些生成的云不会被专家视为不符合物理现象。

**结论:** NnD方法成功地降低了生成物理上合理且非负对象所需的计算成本，同时保持了生成结果的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NnD%3A+Diffusion-based+Generation+of+Physically-Nonnegative+Objects，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10112&send_immediately=true&force_search=false)

**原文摘要:** Most natural objects have inherent complexity and variability. While some
simple objects can be modeled from first principles, many real-world phenomena,
such as cloud formation, require computationally expensive simulations that
limit scalability. This work focuses on a class of physically meaningful,
nonnegative objects that are computationally tractable but costly to simulate.
To dramatically reduce computational costs, we propose nonnegative diffusion
(NnD). This is a learned generative model using score based diffusion. It
adapts annealed Langevin dynamics to enforce, by design, non-negativity
throughout iterative scene generation and analysis (inference). NnD trains on
high-quality physically simulated objects. Once trained, it can be used for
generation and inference. We demonstrate generation of 3D volumetric clouds,
comprising inherently nonnegative microphysical fields. Our generated clouds
are consistent with cloud physics trends. They are effectively not
distinguished as non-physical by expert perception.

</details>


### [11] [GRAIL: A Benchmark for GRaph ActIve Learning in Dynamic Sensing Environments](https://arxiv.org/abs/2506.10120)
*Maryam Khalid, Akane Sano*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的基准测试框架GRAIL，旨在评估动态真实环境中的图主动学习策略。通过引入新的度量标准来衡量持续有效性、多样性和用户负担，揭示了现有主动学习方法在预测性能和用户负担之间的权衡，并强调了节点重要性、查询多样性和网络拓扑平衡的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图主动学习方法通常在静态图数据集上进行评估，主要关注预测准确性，而忽视了如采样多样性、查询公平性以及对动态环境的适应性等以用户为中心的考量。为了填补这一空白，研究者们提出了一个新的基准测试框架。

**方法:** 提出了一种名为GRAIL的新基准测试框架，设计用于在动态、真实的环境中评估图主动学习策略。该框架引入了新颖的指标来评估持续有效性、多样性和用户负担，从而能够在不同条件下全面评价主动学习方法的表现。

**结果:** 通过对包含动态、现实生活人类传感器数据的数据集进行广泛实验，发现现有主动学习策略在预测性能与用户负担之间存在权衡关系，突显出当前方法的一些局限性。

**结论:** GRAIL框架展示了平衡节点重要性、查询多样性和网络拓扑对于图主动学习解决方案在动态环境中至关重要，并为这类解决方案提供了一个评估机制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GRAIL%3A+A+Benchmark+for+GRaph+ActIve+Learning+in+Dynamic+Sensing+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10120&send_immediately=true&force_search=false)

**原文摘要:** Graph-based Active Learning (AL) leverages the structure of graphs to
efficiently prioritize label queries, reducing labeling costs and user burden
in applications like health monitoring, human behavior analysis, and sensor
networks. By identifying strategically positioned nodes, graph AL minimizes
data collection demands while maintaining model performance, making it a
valuable tool for dynamic environments. Despite its potential, existing graph
AL methods are often evaluated on static graph datasets and primarily focus on
prediction accuracy, neglecting user-centric considerations such as sampling
diversity, query fairness, and adaptability to dynamic settings. To bridge this
gap, we introduce GRAIL, a novel benchmarking framework designed to evaluate
graph AL strategies in dynamic, real-world environments. GRAIL introduces novel
metrics to assess sustained effectiveness, diversity, and user burden, enabling
a comprehensive evaluation of AL methods under varying conditions. Extensive
experiments on datasets featuring dynamic, real-life human sensor data reveal
trade-offs between prediction performance and user burden, highlighting
limitations in existing AL strategies. GRAIL demonstrates the importance of
balancing node importance, query diversity, and network topology, providing an
evaluation mechanism for graph AL solutions in dynamic environments.

</details>


### [12] [Survival Analysis as Imprecise Classification with Trainable Kernels](https://arxiv.org/abs/2506.10140)
*Andrei V. Konstantinov, Vlada A. Efremenko, Lev V. Utkin*

**主要类别:** cs.LG

**AI概要:** 本文提出了三种新的生存模型iSurvM、iSurvQ和iSurvJ，它们结合了不精确概率论与注意力机制来处理删失数据，并且无需参数假设。实验表明这些模型在准确性和计算复杂性方面优于传统的Beran估计量。


<details>
  <summary>更多</summary>
  
**动机:** 传统生存分析方法如Beran估计量在处理复杂数据结构和严重删失时遇到困难。本文旨在通过引入基于不精确概率理论的新型生存模型来解决这些问题。

**方法:** 提出三个新的生存模型：iSurvM（基于平均似然函数的不精确生存模型）、iSurvQ（基于似然函数分位数的不精确生存模型）以及iSurvJ（基于联合学习的不精确生存模型）。这些模型利用区间值概率分布表示删失观测值，采用基于核的Nadaraya-Watson回归及可训练的注意力权重来计算整个数据集的时间间隔上的不精确概率分布。

**结果:** 合成数据集和真实数据集上的实验结果表明，所提出的模型，特别是iSurvJ，在准确性和计算复杂性方面始终优于Beran估计量。

**结论:** 新提出的iSurvM, iSurvQ, 和iSurvJ模型能够有效处理删失数据，并且在性能上超越了传统的非参数方法Beran估计量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Survival+Analysis+as+Imprecise+Classification+with+Trainable+Kernels，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10140&send_immediately=true&force_search=false)

**原文摘要:** Survival analysis is a fundamental tool for modeling time-to-event data in
healthcare, engineering, and finance, where censored observations pose
significant challenges. While traditional methods like the Beran estimator
offer nonparametric solutions, they often struggle with the complex data
structures and heavy censoring. This paper introduces three novel survival
models, iSurvM (the imprecise Survival model based on Mean likelihood
functions), iSurvQ (the imprecise Survival model based on the Quantiles of
likelihood functions), and iSurvJ (the imprecise Survival model based on the
Joint learning), that combine imprecise probability theory with attention
mechanisms to handle censored data without parametric assumptions. The first
idea behind the models is to represent censored observations by interval-valued
probability distributions for each instance over time intervals between events
moments. The second idea is to employ the kernel-based Nadaraya-Watson
regression with trainable attention weights for computing the imprecise
probability distribution over time intervals for the entire dataset. The third
idea is to consider three decision strategies for training, which correspond to
the proposed three models. Experiments on synthetic and real datasets
demonstrate that the proposed models, especially iSurvJ, consistently
outperform the Beran estimator from the accuracy and computational complexity
points of view. Codes implementing the proposed models are publicly available.

</details>


### [13] [Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms](https://arxiv.org/abs/2506.10127)
*Xinyi Hu, Aldo Pacchiano*

**主要类别:** cs.LG

**AI概要:** 本文研究了无感知环境下分散式多玩家多臂老虎机问题，提出了一种名为A-CAPELLA的去中心化算法，该算法能够通过精心设计的碰撞模式实现同步连续消除和容量估计，从而在未知臂容量的情况下取得对数级遗憾。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决无感知设置下的分散式多玩家多臂老虎机问题，在这种环境中每个玩家只能收到自己的奖励，并且对于碰撞没有任何信息。每个臂都有一个未知的容量限制，如果超过这个限制，则所有选择该臂的玩家都将获得零奖励。这样的设定为协调和容量发现带来了新的挑战。

**方法:** 提出了A-CAPELLA（一种用于学习与分配的容量感知并行消除算法），这是一种去中心化的算法，它通过协作假设检验协议来实现同步连续消除以及通过精心构建的碰撞模式来进行容量估计。

**结果:** A-CAPELLA算法能够在未知臂容量的分散式无感知MMAB中达到对数级别的遗憾，表明它是有效的学习结果。

**结论:** 本研究表明，即使在反馈极为有限的情况下，也能够通过特定的设计来实现有效的协作学习和资源分配。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meet+Me+at+the+Arm%3A+The+Cooperative+Multi-Armed+Bandits+Problem+with+Shareable+Arms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10127，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10127&send_immediately=true&force_search=false)

**原文摘要:** We study the decentralized multi-player multi-armed bandits (MMAB) problem
under a no-sensing setting, where each player receives only their own reward
and obtains no information about collisions. Each arm has an unknown capacity,
and if the number of players pulling an arm exceeds its capacity, all players
involved receive zero reward. This setting generalizes the classical
unit-capacity model and introduces new challenges in coordination and capacity
discovery under severe feedback limitations. We propose A-CAPELLA (Algorithm
for Capacity-Aware Parallel Elimination for Learning and Allocation), a
decentralized algorithm that achieves logarithmic regret in this generalized
regime. Our main contribution is a collaborative hypothesis testing protocol
that enables synchronized successive elimination and capacity estimation
through carefully structured collision patterns. This represents a provably
efficient learning result in decentralized no-sensing MMAB with unknown arm
capacities.

</details>


### [14] [Probabilistic Variational Contrastive Learning](https://arxiv.org/abs/2506.10159)
*Minoh Jeong, Seonho Kim, Alfred Hero*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的变分对比学习(VCL)框架，通过将InfoNCE损失视为替代重构项，并在单位超球面上对均匀先验增加KL散度正则化来最大化证据下界(ELBO)。VCL不仅能够提供不确定性量化，还提高了分类准确率，并且在多个基准测试中优于确定性基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对比学习（如SimCLR和SupCon）虽然取得了最先进的性能，但缺乏一个原则性的机制来进行不确定性量化。为了解决这个问题，研究者提出了一个新的框架。

**方法:** 研究者提出了变分对比学习(VCL)，这是一种无解码器的框架，它通过将InfoNCE损失解释为代理重构项，并向单位超球面的均匀先验添加KL散度正则化来最大化证据下界(ELBO)。模型近似后验$q_θ(z|x)$作为投影正态分布，允许采样概率嵌入。

**结果:** 实验表明，VCL可以缓解维度坍缩问题，增强与类别标签的互信息，并且在分类准确性方面匹配或超越了确定性基线，同时通过后验模型提供了有意义的不确定性估计。

**结论:** VCL为对比学习提供了一个概率基础，它不仅能够处理不确定性量化的问题，而且在性能上也表现出色，为对比学习方法奠定了新的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probabilistic+Variational+Contrastive+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10159，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10159&send_immediately=true&force_search=false)

**原文摘要:** Deterministic embeddings learned by contrastive learning (CL) methods such as
SimCLR and SupCon achieve state-of-the-art performance but lack a principled
mechanism for uncertainty quantification. We propose Variational Contrastive
Learning (VCL), a decoder-free framework that maximizes the evidence lower
bound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstruction
term and adding a KL divergence regularizer to a uniform prior on the unit
hypersphere. We model the approximate posterior $q_\theta(z|x)$ as a projected
normal distribution, enabling the sampling of probabilistic embeddings. Our two
instantiations--VSimCLR and VSupCon--replace deterministic embeddings with
samples from $q_\theta(z|x)$ and incorporate a normalized KL term into the
loss. Experiments on multiple benchmarks demonstrate that VCL mitigates
dimensional collapse, enhances mutual information with class labels, and
matches or outperforms deterministic baselines in classification accuracy, all
the while providing meaningful uncertainty estimates through the posterior
model. VCL thus equips contrastive learning with a probabilistic foundation,
serving as a new basis for contrastive approaches.

</details>


### [15] [Provable Sim-to-Real Transfer via Offline Domain Randomization](https://arxiv.org/abs/2506.10133)
*Arnaud Fickinger, Abderrahim Bendahi, Stuart Russell*

**主要类别:** cs.LG

**AI概要:** 本文研究了离线领域随机化(ODR)，通过首先将模拟器参数的分布拟合到离线数据集，以减少仿真到现实世界的差距。文章形式化了ODR，并证明了其估计量的一致性，推导了误差界，并引入了一个新的算法E-DROPO来提高零样本迁移的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习代理在从模拟环境部署到现实世界时往往遇到困难。尽管已有方法如领域随机化(DR)可以减小这种差距，但标准DR忽略了已有的真实系统离线数据。为了充分利用这些数据并改进现有方法，提出了离线领域随机化(ODR)。

**方法:** 作者们形式化了ODR作为参数化模拟器族的最大似然估计，证明了该估计量在温和的正则性和可识别条件下的一致性，并且推导出了有限模拟器情况下ODR相比均匀DR的sim-to-real误差界。此外，他们还提出了一种新的DROPO版本——E-DROPO，它增加了熵奖励以防止方差崩溃，从而实现更广泛的随机化和更强健的实际零样本迁移。

**结果:** 研究表明，ODR估计量在一定条件下是一致的，并且随着数据集的增长，会收敛于真实的动态。对于有限模拟器情况，ODR相比均匀DR能提供至多O(M)因子更紧的sim-to-real误差界。提出的E-DROPO算法在实践中能够促进更广泛的随机化和更稳健的零样本迁移。

**结论:** ODR为利用离线数据进行领域随机化提供了坚实的理论基础，并且新提出的E-DROPO算法有助于增强实际应用中的零样本迁移能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Provable+Sim-to-Real+Transfer+via+Offline+Domain+Randomization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10133，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10133&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement-learning agents often struggle when deployed from simulation to
the real-world. A dominant strategy for reducing the sim-to-real gap is domain
randomization (DR) which trains the policy across many simulators produced by
sampling dynamics parameters, but standard DR ignores offline data already
available from the real system. We study offline domain randomization (ODR),
which first fits a distribution over simulator parameters to an offline
dataset. While a growing body of empirical work reports substantial gains with
algorithms such as DROPO, the theoretical foundations of ODR remain largely
unexplored. In this work, we (i) formalize ODR as a maximum-likelihood
estimation over a parametric simulator family, (ii) prove consistency of this
estimator under mild regularity and identifiability conditions, showing it
converges to the true dynamics as the dataset grows, (iii) derive gap bounds
demonstrating ODRs sim-to-real error is up to an O(M) factor tighter than
uniform DR in the finite-simulator case (and analogous gains in the continuous
setting), and (iv) introduce E-DROPO, a new version of DROPO which adds an
entropy bonus to prevent variance collapse, yielding broader randomization and
more robust zero-shot transfer in practice.

</details>


### [16] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
*Defang Chen, Zhenyu Zhou, Can Wang, Siwei Lyu*

**主要类别:** cs.LG

**AI概要:** 本文揭示了基于扩散的生成模型中确定性采样动态的几何规律性，即所有模拟采样轨迹都位于一个极低维度的子空间内，并且无论模型架构、应用条件或生成内容如何，这些轨迹都表现出几乎相同的“回力镖”形状。利用这一发现，作者提出了一种基于动态规划的方法来更好地使采样时间安排与潜在轨迹结构相匹配，从而以最小的修改和计算开销提高图像生成性能。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探索扩散式生成模型中的随机微分方程（SDEs）及其等价的概率流常微分方程（ODEs）在复杂高维数据分布与可处理先验分布之间建立平滑变换时所展现出来的内在几何规则。

**方法:** 通过观察到的几何规则性，特别是对基于核估计的数据建模下的闭式解进行了特性描述。接着，提出了一个基于动态规划的方案，用以优化采样时间表与底层轨迹结构的一致性。

**结果:** 结果表明，这种简单的策略只需对现有的基于ODE的数值求解器进行最小程度的改动，几乎不增加计算负担，并且特别是在仅有5至10次函数评估的区域里，能实现更优的图像生成表现。

**结论:** 论文结论是，在基于扩散的生成模型中发现了确定性采样轨迹的显著几何规律性，并且通过适当调整采样时间安排可以有效提升图像生成的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Geometric+Regularity+in+Deterministic+Sampling+of+Diffusion-based+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10177，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10177&send_immediately=true&force_search=false)

**原文摘要:** Diffusion-based generative models employ stochastic differential equations
(SDEs) and their equivalent probability flow ordinary differential equations
(ODEs) to establish a smooth transformation between complex high-dimensional
data distributions and tractable prior distributions. In this paper, we reveal
a striking geometric regularity in the deterministic sampling dynamics: each
simulated sampling trajectory lies within an extremely low-dimensional
subspace, and all trajectories exhibit an almost identical ''boomerang'' shape,
regardless of the model architecture, applied conditions, or generated content.
We characterize several intriguing properties of these trajectories,
particularly under closed-form solutions based on kernel-estimated data
modeling. We also demonstrate a practical application of the discovered
trajectory regularity by proposing a dynamic programming-based scheme to better
align the sampling time schedule with the underlying trajectory structure. This
simple strategy requires minimal modification to existing ODE-based numerical
solvers, incurs negligible computational overhead, and achieves superior image
generation performance, especially in regions with only $5 \sim 10$ function
evaluations.

</details>


### [17] [Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning](https://arxiv.org/abs/2506.10137)
*Daniel Lawson, Adriana Hugessen, Charlotte Cloutier, Glen Berseth, Khimya Khetarpal*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的表示学习目标，即BYOL-γ增强的目标条件行为克隆（GCBC），它不仅能够在有限MDP情况下理论上近似后续表示而无需对比样本或时序差分学习，而且在需要组合泛化的挑战性任务中也表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 虽然目标条件行为克隆（GCBC）方法在分布内训练任务上表现良好，但它们不一定能够零样本泛化到需要对新状态-目标对进行条件处理的任务，即组合泛化。这在一定程度上是由于通过行为克隆学到的状态表示缺乏时间一致性。如果将时间相关的状态编码为相似的潜在表示，则新颖状态-目标对的分布外差距会减少。因此，在表示空间中鼓励这种时间一致性应该有助于组合泛化。

**方法:** 研究者提出了一个简单却有效的表示学习目标：BYOL-γ增强GCBC，这个方法能够在没有对比样本或TD学习的情况下，理论地近似有限马尔可夫决策过程（MDP）中的后续表示。

**结果:** 所提出的方法在一系列要求组合泛化的具有挑战性的任务中展示了有竞争力的实际性能。

**结论:** 通过引入BYOL-γ增强的目标条件行为克隆，该方法能够促进组合泛化，并且在不需要对比样本或TD学习的情况下提供了一个有效的方法来近似后续表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Predictive+Representations+for+Combinatorial+Generalization+in+Behavioral+Cloning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10137，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10137&send_immediately=true&force_search=false)

**原文摘要:** Behavioral cloning (BC) methods trained with supervised learning (SL) are an
effective way to learn policies from human demonstrations in domains like
robotics. Goal-conditioning these policies enables a single generalist policy
to capture diverse behaviors contained within an offline dataset. While
goal-conditioned behavior cloning (GCBC) methods can perform well on
in-distribution training tasks, they do not necessarily generalize zero-shot to
tasks that require conditioning on novel state-goal pairs, i.e. combinatorial
generalization. In part, this limitation can be attributed to a lack of
temporal consistency in the state representation learned by BC; if temporally
related states are encoded to similar latent representations, then the
out-of-distribution gap for novel state-goal pairs would be reduced. Hence,
encouraging this temporal consistency in the representation space should
facilitate combinatorial generalization. Successor representations, which
encode the distribution of future states visited from the current state, nicely
encapsulate this property. However, previous methods for learning successor
representations have relied on contrastive samples, temporal-difference (TD)
learning, or both. In this work, we propose a simple yet effective
representation learning objective, $\text{BYOL-}\gamma$ augmented GCBC, which
is not only able to theoretically approximate the successor representation in
the finite MDP case without contrastive samples or TD learning, but also,
results in competitive empirical performance across a suite of challenging
tasks requiring combinatorial generalization.

</details>


### [18] [Meta-learning Representations for Learning from Multiple Annotators](https://arxiv.org/abs/2506.10259)
*Atsutoshi Kumagai, Tomoharu Iwata, Taishi Nishiyama, Yasutoshi Ida, Yasuhiro Fujiwara*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种元学习方法，用于从多个带有噪声的标注者那里学习。该方法通过神经网络将每个任务示例嵌入到潜在空间，并构建了一个概率模型来学习特定于任务的分类器，同时估计标注者在潜在空间中的能力。所提出的神经网络经过元学习，以提高分类器适应少量注释数据时的预期测试分类性能。


<details>
  <summary>更多</summary>
  
**动机:** 在许多应用中，如众包服务，监督学习的标签由多名标注者提供。由于标注者具有不同的技能或偏见，给定的标签可能会有噪声。为了学习准确的分类器，现有方法需要大量的带噪声标注的数据。然而，在实践中可能没有足够的数据。为了解决数据不足的问题，本文提出的方法利用了不同但相关任务中获得的标记数据。

**方法:** 提出的方法使用神经网络将每个任务示例映射到一个潜在空间，并且构造了一个概率模型，用来学习针对具体任务的分类器，同时也估计出标注者在这个潜在空间的能力。这个神经网络是通过元学习来改进的，目的是当分类器适应给定的一小部分标注数据时，能够提升预期的测试分类表现。分类器的适应过程是通过最大化后验概率来进行的，这利用了期望最大化(EM)算法。由于EM算法中的每一步都容易被计算成闭式并且是可微分的，因此提出的方法可以有效地通过EM算法反向传播损失，从而对神经网络进行元学习。

**结果:** 实验结果表明，该方法在含有合成噪声的真实世界数据集和真实世界的众包数据集上是有效的。

**结论:** 综上所述，该论文介绍了一种新的元学习方法，能够有效地处理来自多个噪声标注者的标签数据，并通过利用相关任务的数据克服了数据不足的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-learning+Representations+for+Learning+from+Multiple+Annotators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10259，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10259&send_immediately=true&force_search=false)

**原文摘要:** We propose a meta-learning method for learning from multiple noisy
annotators. In many applications such as crowdsourcing services, labels for
supervised learning are given by multiple annotators. Since the annotators have
different skills or biases, given labels can be noisy. To learn accurate
classifiers, existing methods require many noisy annotated data. However,
sufficient data might be unavailable in practice. To overcome the lack of data,
the proposed method uses labeled data obtained in different but related tasks.
The proposed method embeds each example in tasks to a latent space by using a
neural network and constructs a probabilistic model for learning a
task-specific classifier while estimating annotators' abilities on the latent
space. This neural network is meta-learned to improve the expected test
classification performance when the classifier is adapted to a given small
amount of annotated data. This classifier adaptation is performed by maximizing
the posterior probability via the expectation-maximization (EM) algorithm.
Since each step in the EM algorithm is easily computed as a closed-form and is
differentiable, the proposed method can efficiently backpropagate the loss
through the EM algorithm to meta-learn the neural network. We show the
effectiveness of our method with real-world datasets with synthetic noise and
real-world crowdsourcing datasets.

</details>


### [19] [Interpreting learned search: finding a transition model and value function in an RNN that plays Sokoban](https://arxiv.org/abs/2506.10138)
*Mohammad Taufeeque, Aaron David Tucker, Adam Gleave, Adrià Garriga-Alonso*

**主要类别:** cs.LG

**AI概要:** 研究者部分地逆向工程了一个用于玩推箱子游戏的卷积循环神经网络（RNN），该网络通过无模型强化学习训练。分析发现，这个RNN使用了一种类似于经典双向搜索机制的方法来规划游戏策略，并且在测试时能够利用更多的计算资源解决更多的关卡。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于理解一个已经训练好的卷积循环神经网络如何能够在推箱子游戏中随着测试时更多的计算而解决更多的关卡。

**方法:** 研究者对一个用无模型强化学习训练的卷积循环神经网络进行了部分逆向工程，以揭示其内部机制。

**结果:** 结果显示，该网络使用了一些与经典双向搜索组件类似的机制进行规划，每个方块都有自己的计划表示和价值函数，这使得搜索深度增加。

**结论:** 结论是，尽管该算法在某些方面与传统搜索不同，但通过无模型训练学到的机制可以被理解为熟悉的术语。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpreting+learned+search%3A+finding+a+transition+model+and+value+function+in+an+RNN+that+plays+Sokoban，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10138，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10138&send_immediately=true&force_search=false)

**原文摘要:** We partially reverse-engineer a convolutional recurrent neural network (RNN)
trained to play the puzzle game Sokoban with model-free reinforcement learning.
Prior work found that this network solves more levels with more test-time
compute. Our analysis reveals several mechanisms analogous to components of
classic bidirectional search. For each square, the RNN represents its plan in
the activations of channels associated with specific directions. These
state-action activations are analogous to a value function - their magnitudes
determine when to backtrack and which plan branch survives pruning. Specialized
kernels extend these activations (containing plan and value) forward and
backward to create paths, forming a transition model. The algorithm is also
unlike classical search in some ways. State representation is not unified;
instead, the network considers each box separately. Each layer has its own plan
representation and value function, increasing search depth. Far from being
inscrutable, the mechanisms leveraging test-time compute learned in this
network by model-free training can be understood in familiar terms.

</details>


### [20] [Collaborative Min-Max Regret in Grouped Multi-Armed Bandits](https://arxiv.org/abs/2506.10313)
*Moïse Blanchard, Vineet Goyal*

**主要类别:** cs.LG

**AI概要:** 研究了在多臂老虎机中，当多个组有重叠的可行动作集时共享探索的影响。提出了一种名为Col-UCB的算法来动态协调各组之间的探索，并证明了该算法能够达到最优最小化和实例相关的协作遗憾，且这些界限能适应组间共享动作集的结构。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决在分组设置下多臂老虎机问题中由于标准算法可能导致不同组间探索成本显著不平衡的问题，研究旨在通过组间的奖励观察共享来减少合作遗憾（定义为所有组中的最大遗憾）。

**方法:** 提出了Col-UCB算法，该算法能够在组间动态地协调探索行为，以优化整体的合作遗憾。

**结果:** Col-UCB算法被证实可以在对数因子内实现最优的最小化以及实例依赖型合作遗憾。这种算法还能够自适应于组间共享动作集合的结构。

**结论:** 研究表明，通过Col-UCB算法协调探索可以有效减轻不同组别之间探索负担的不平衡，并且相对于各自独立学习最佳行动而言，在某些情况下合作能带来明显的好处。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collaborative+Min-Max+Regret+in+Grouped+Multi-Armed+Bandits，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10313&send_immediately=true&force_search=false)

**原文摘要:** We study the impact of sharing exploration in multi-armed bandits in a
grouped setting where a set of groups have overlapping feasible action sets
[Baek and Farias '24]. In this grouped bandit setting, groups share reward
observations, and the objective is to minimize the collaborative regret,
defined as the maximum regret across groups. This naturally captures
applications in which one aims to balance the exploration burden between groups
or populations -- it is known that standard algorithms can lead to
significantly imbalanced exploration cost between groups. We address this
problem by introducing an algorithm Col-UCB that dynamically coordinates
exploration across groups. We show that Col-UCB achieves both optimal minimax
and instance-dependent collaborative regret up to logarithmic factors. These
bounds are adaptive to the structure of shared action sets between groups,
providing insights into when collaboration yields significant benefits over
each group learning their best action independently.

</details>


### [21] [Air in Your Neighborhood: Fine-Grained AQI Forecasting Using Mobile Sensor Data](https://arxiv.org/abs/2506.10332)
*Aaryam Sharma*

**主要类别:** cs.LG

**AI概要:** 本文通过使用时空图神经网络（Spatio-temporal GNNs）来预测1平方公里邻域内的空气质量指数(AQI)，并以AirDelhi数据集为例，超越了现有工作，将均方误差降低了79%，并且揭示了AQI的新的见解。


<details>
  <summary>更多</summary>
  
**动机:** 发展中国家的空气污染已成为一个重大的健康风险问题，而政府发布的空气质量指数数据由于传感器稀疏，无法准确反映当地的真实情况。

**方法:** 采用时空图神经网络（Spatio-temporal GNNs）对1平方公里大小的邻域进行空气质量指数(AQI)预测，并利用AirDelhi数据集作为案例研究。

**结果:** 在未见过的坐标上，与现有工作相比，MSE减少了71.654，相当于降低了79%。此外还发现了关于AQI的新见解，比如存在强烈的短期重复模式和变化的空间关系。

**结论:** 研究表明，利用时空图神经网络可以显著提高局部地区空气质量指数预测的准确性，并有助于发现AQI的一些新特性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Air+in+Your+Neighborhood%3A+Fine-Grained+AQI+Forecasting+Using+Mobile+Sensor+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10332，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10332&send_immediately=true&force_search=false)

**原文摘要:** Air pollution has become a significant health risk in developing countries.
While governments routinely publish air-quality index (AQI) data to track
pollution, these values fail to capture the local reality, as sensors are often
very sparse. In this paper, we address this gap by predicting AQI in 1 km^2
neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporal
GNNs we surpass existing works by 71.654 MSE a 79% reduction, even on unseen
coordinates. New insights about AQI such as the existence of strong repetitive
short-term patterns and changing spatial relations are also discovered. The
code is available on GitHub.

</details>


### [22] [Physiological-Model-Based Neural Network for Heart Rate Estimation during Daily Physical Activities](https://arxiv.org/abs/2506.10144)
*Yaowen Zhang, Libera Fresiello, Peter H. Veltink, Dirk W. Donker, Ying Wang*

**主要类别:** cs.LG

**AI概要:** 本研究开发了一种基于生理模型的神经网络框架(PMB-NN)，用于根据日常体力活动中的摄氧量(VO2)数据来估计心率(HR)。该框架在12名参与者的个人数据集上进行了训练和测试，通过嵌入生理约束条件提高了HR估计的准确性，并且能够识别个性化参数，从而实现精确的心脏健康监测。


<details>
  <summary>更多</summary>
  
**动机:** 现有的心力衰竭检测中心率监测工具依赖于人群平均值，而个体化心率估计可以作为动态数字孪生，更准确地追踪心脏健康生物标志物。目前的方法要么效率低下，要么难以解释。因此，需要一种新的方法来提高心率估计的准确性与个体适应性。

**方法:** 研究者提出了一种新颖的基于生理模型的神经网络（PMB-NN）架构，它利用参与者在休息、骑行和跑步等活动期间的摄氧量数据来估计心率。该模型在训练过程中嵌入了从简化的人体运动生理模型中得出的生理约束条件。

**结果:** PMB-NN模型实现了高估测精度，其R$^2$分数中位数为0.8，RMSE为8.3 bpm。对比统计分析表明，PMB-NN的表现与基准神经网络模型相当，但显著优于传统的生理模型（p=0.002）。此外，PMB-NN还能够很好地识别出PM的个性化参数。

**结论:** 提出的PMB-NN框架不仅达到了很高的心率估计精度，而且能够识别出个性化的生理模型参数，这使得未来有可能实现在日常生活体力活动中进行个性化和实时的心脏监测。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Physiological-Model-Based+Neural+Network+for+Heart+Rate+Estimation+during+Daily+Physical+Activities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10144，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10144&send_immediately=true&force_search=false)

**原文摘要:** Heart failure (HF) poses a significant global health challenge, with early
detection offering opportunities for improved outcomes. Abnormalities in heart
rate (HR), particularly during daily activities, may serve as early indicators
of HF risk. However, existing HR monitoring tools for HF detection are limited
by their reliability on population-based averages. The estimation of
individualized HR serves as a dynamic digital twin, enabling precise tracking
of cardiac health biomarkers. Current HR estimation methods, categorized into
physiologically-driven and purely data-driven models, struggle with efficiency
and interpretability. This study introduces a novel physiological-model-based
neural network (PMB-NN) framework for HR estimation based on oxygen uptake
(VO2) data during daily physical activities. The framework was trained and
tested on individual datasets from 12 participants engaged in activities
including resting, cycling, and running. By embedding physiological
constraints, which were derived from our proposed simplified human movement
physiological model (PM), into the neural network training process, the PMB-NN
model adheres to human physiological principles while achieving high estimation
accuracy, with a median R$^2$ score of 0.8 and an RMSE of 8.3 bpm. Comparative
statistical analysis demonstrates that the PMB-NN achieves performance on par
with the benchmark neural network model while significantly outperforming
traditional physiological model (p=0.002). In addition, our PMB-NN is adept at
identifying personalized parameters of the PM, enabling the PM to generate
reasonable HR estimation. The proposed framework with a precise VO2 estimation
system derived from body movements enables the future possibilities of
personalized and real-time cardiac monitoring during daily life physical
activities.

</details>


### [23] [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org/abs/2506.10378)
*Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了一种因果表示学习框架，用于评估语言模型能力，并通过该方法在包含1500多个模型的数据集上识别出简洁的三节点线性因果结构，揭示了从一般问题解决能力到指令跟随熟练度再到数学推理能力的清晰因果方向。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服在领域内进行严格因果评估时遇到的方法学挑战，比如复杂的混淆效应和与广泛再训练相关的高昂计算成本。

**方法:** 提出了一个因果表示学习框架，将观察到的基准性能建模为少数几个潜在能力因子的线性变换，并且这些潜在因子被确定为在适当控制基础模型作为共同混杂因素后具有因果关系。

**结果:** 应用此方法于涵盖Open LLM Leaderboard六个基准测试中超过1500个模型的综合数据集上，确定了一个能够可靠解释观察到的表现变化的简洁三节点线性因果结构。

**结论:** 结果强调了在评估过程中仔细控制基础模型变体的重要性，这是准确揭示潜在模型能力之间因果关系的关键步骤。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Discovering+Hierarchical+Latent+Capabilities+of+Language+Models+via+Causal+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10378，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10378&send_immediately=true&force_search=false)

**原文摘要:** Faithful evaluation of language model capabilities is crucial for deriving
actionable insights that can inform model development. However, rigorous causal
evaluations in this domain face significant methodological challenges,
including complex confounding effects and prohibitive computational costs
associated with extensive retraining. To tackle these challenges, we propose a
causal representation learning framework wherein observed benchmark performance
is modeled as a linear transformation of a few latent capability factors.
Crucially, these latent factors are identified as causally interrelated after
appropriately controlling for the base model as a common confounder. Applying
this approach to a comprehensive dataset encompassing over 1500 models
evaluated across six benchmarks from the Open LLM Leaderboard, we identify a
concise three-node linear causal structure that reliably explains the observed
performance variations. Further interpretation of this causal structure
provides substantial scientific insights beyond simple numerical rankings:
specifically, we reveal a clear causal direction starting from general
problem-solving capabilities, advancing through instruction-following
proficiency, and culminating in mathematical reasoning ability. Our results
underscore the essential role of carefully controlling base model variations
during evaluation, a step critical to accurately uncovering the underlying
causal relationships among latent model capabilities.

</details>


### [24] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
*Tejaswi Kasarla, Max van Spengler, Pascal Mettes*

**主要类别:** cs.LG

**AI概要:** 研究提出了一种平衡双曲学习方法，通过优化层次失真和浅层与宽子层次之间的平衡来嵌入类别，并使用这些类别嵌入作为双曲原型来进行分类。实验表明，该方法在区分分布内和分布外样本方面优于现有的方法。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是解决深度学习中一个重要的问题，即过滤掉不属于训练网络所基于的分布的样本。

**方法:** 提出了平衡双曲学习法，定义了一个双曲类嵌入算法，同时优化了层次失真和浅而宽的子层次间的平衡。之后，将类嵌入用作分布内数据分类的双曲原型，并概括了如何将现有的分布外评分函数推广以使用双曲原型。

**结果:** 通过13个数据集和13个评分函数的实证评估显示，当使用相同的数据和相同的骨干网络进行训练时，提出的双曲嵌入比现有处理分布外样本的方法表现更好。此外，还展示了其双曲嵌入超越其他双曲方法，击败了最先进的对比方法，并且自然地支持了层次化的分布外泛化。

**结论:** 良好的分层双曲嵌入有利于区分分布内和分布外样本，而且这种新的平衡双曲学习方法在实践中证明了这一点。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Balanced+Hyperbolic+Embeddings+Are+Natural+Out-of-Distribution+Detectors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10146，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10146&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution recognition forms an important and well-studied problem
in deep learning, with the goal to filter out samples that do not belong to the
distribution on which a network has been trained. The conclusion of this paper
is simple: a good hierarchical hyperbolic embedding is preferred for
discriminating in- and out-of-distribution samples. We introduce Balanced
Hyperbolic Learning. We outline a hyperbolic class embedding algorithm that
jointly optimizes for hierarchical distortion and balancing between shallow and
wide subhierarchies. We then use the class embeddings as hyperbolic prototypes
for classification on in-distribution data. We outline how to generalize
existing out-of-distribution scoring functions to operate with hyperbolic
prototypes. Empirical evaluations across 13 datasets and 13 scoring functions
show that our hyperbolic embeddings outperform existing out-of-distribution
approaches when trained on the same data with the same backbones. We also show
that our hyperbolic embeddings outperform other hyperbolic approaches, beat
state-of-the-art contrastive methods, and natively enable hierarchical
out-of-distribution generalization.

</details>


### [25] [Size-adaptive Hypothesis Testing for Fairness](https://arxiv.org/abs/2506.10586)
*Antonio Ferrara, Francesco Cozzi, Alan Perotti, André Panisson, Francesco Bonchi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种统一的、适应大小的假设检验框架，用于将公平性评估转化为基于证据的统计决策。对于足够大的子群体，提供了一个中心极限定理的结果来计算置信区间和Wald检验；对于较小的交叉群体，则采用贝叶斯Dirichlet-多项式估计器，并通过蒙特卡洛可信区间来校准任何样本大小。


<details>
  <summary>更多</summary>
  
**动机:** 当前对算法决策系统是否歧视特定人群的判断通常依赖于单一的公平度量点估计与预设阈值比较，这种方法在统计上不够稳健，因为它忽略了抽样误差，并且不论群体规模大小均一视同仁。尤其是在考虑多个敏感属性的交叉分析中，由于涉及更多但更小的群组，数据变得过于稀疏，导致公平度量指标产生过宽的置信区间，使得难以得出关于潜在不公平待遇的有效结论。

**方法:** 研究者们引入了一种新的假设检验框架，该框架能够根据子群体大小自适应地调整。对于较大的子群体，他们证明了统计奇偶差异的中心极限结果，从而提供了分析置信区间以及保证I型错误率（假阳性）为α水平的Wald检验。对于由多属性交叉形成的小群体，采用了完全贝叶斯Dirichlet-多项式估计方法，通过蒙特卡洛模拟生成的可信区间可以针对任意样本大小进行校准，并随着可用数据增加自然过渡到Wald区间。

**结果:** 通过基准数据集上的实证验证表明，所提出的测试方法能够在不同数据可用性和交叉性程度下提供可解释性强且统计严谨的决策依据。

**结论:** 新提出的框架能够有效应对因数据稀疏而引起的挑战，为算法公平性的评估提供了一种更为科学和可靠的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Size-adaptive+Hypothesis+Testing+for+Fairness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10586，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10586&send_immediately=true&force_search=false)

**原文摘要:** Determining whether an algorithmic decision-making system discriminates
against a specific demographic typically involves comparing a single point
estimate of a fairness metric against a predefined threshold. This practice is
statistically brittle: it ignores sampling error and treats small demographic
subgroups the same as large ones. The problem intensifies in intersectional
analyses, where multiple sensitive attributes are considered jointly, giving
rise to a larger number of smaller groups. As these groups become more
granular, the data representing them becomes too sparse for reliable
estimation, and fairness metrics yield excessively wide confidence intervals,
precluding meaningful conclusions about potential unfair treatments.
  In this paper, we introduce a unified, size-adaptive, hypothesis-testing
framework that turns fairness assessment into an evidence-based statistical
decision. Our contribution is twofold. (i) For sufficiently large subgroups, we
prove a Central-Limit result for the statistical parity difference, leading to
analytic confidence intervals and a Wald test whose type-I (false positive)
error is guaranteed at level $\alpha$. (ii) For the long tail of small
intersectional groups, we derive a fully Bayesian Dirichlet-multinomial
estimator; Monte-Carlo credible intervals are calibrated for any sample size
and naturally converge to Wald intervals as more data becomes available. We
validate our approach empirically on benchmark datasets, demonstrating how our
tests provide interpretable, statistically rigorous decisions under varying
degrees of data availability and intersectionality.

</details>


### [26] [Rethinking Losses for Diffusion Bridge Samplers](https://arxiv.org/abs/2506.10982)
*Sebastian Sanokowski, Lukas Gruber, Christoph Bartmann, Sepp Hochreiter, Sebastian Lehner*

**主要类别:** cs.LG

**AI概要:** 研究发现，对于扩散桥来说，使用带有对数导数技巧的反向KL损失(rKL-LD)不仅避免了概念上的问题，并且在实验中持续优于Log Variance (LV)损失。此外，rKL-LD损失在训练时需要更少的超参数优化并表现出更稳定的训练行为。


<details>
  <summary>更多</summary>
  
**动机:** 先前研究表明，在利用重参数化技巧计算rKL梯度时，Log Variance (LV)损失始终优于反向Kullback-Leibler (rKL)损失。然而，当应用于扩散桥或学习扩散系数时，LV损失与rKL损失之间的等价性不再成立。基于此，本文探讨了适用于扩散桥的最优损失函数。

**方法:** 分析了扩散桥在使用不同损失函数（特别是Log Variance损失和反向Kullback-Leibler损失）时的行为差异。进一步，通过实验对比了在不同类型的扩散桥上应用rKL-LD损失和LV损失的效果。

**结果:** 实验结果表明，使用rKL-LD损失训练的采样器在具有挑战性的基准测试中表现更好。从实际角度来看，rKL-LD损失需要显著较少的超参数优化并且提供了更加稳定的训练过程。

**结论:** 对于扩散桥而言，采用rKL-LD损失不仅解决了LV损失所带来的理论问题，还实验证明了其优越性，包括更好的性能、更低的超参数调整需求以及更稳定的训练过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Losses+for+Diffusion+Bridge+Samplers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10982，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10982&send_immediately=true&force_search=false)

**原文摘要:** Diffusion bridges are a promising class of deep-learning methods for sampling
from unnormalized distributions. Recent works show that the Log Variance (LV)
loss consistently outperforms the reverse Kullback-Leibler (rKL) loss when
using the reparametrization trick to compute rKL-gradients. While the on-policy
LV loss yields identical gradients to the rKL loss when combined with the
log-derivative trick for diffusion samplers with non-learnable forward
processes, this equivalence does not hold for diffusion bridges or when
diffusion coefficients are learned. Based on this insight we argue that for
diffusion bridges the LV loss does not represent an optimization objective that
can be motivated like the rKL loss via the data processing inequality. Our
analysis shows that employing the rKL loss with the log-derivative trick
(rKL-LD) does not only avoid these conceptual problems but also consistently
outperforms the LV loss. Experimental results with different types of diffusion
bridges on challenging benchmarks show that samplers trained with the rKL-LD
loss achieve better performance. From a practical perspective we find that
rKL-LD requires significantly less hyperparameter optimization and yields more
stable training behavior.

</details>


### [27] [The 2025 PNPL Competition: Speech Detection and Phoneme Classification in the LibriBrain Dataset](https://arxiv.org/abs/2506.10165)
*Gilad Landau, Miran Özdogan, Gereon Elvers, Francesco Mantegna, Pratik Somaiya, Dulhan Jayalath, Luisa Kurth, Teyun Kwon, Brendan Shillingford, Greg Farquhar, Minqi Jiang, Karim Jerbi, Hamza Abdelhedi, Yorguin Mantilla Ramos, Caglar Gulcehre, Mark Woolrich, Natalie Voets, Oiwi Parker Jones*

**主要类别:** cs.LG

**AI概要:** 论文介绍了2025 PNPL竞赛，旨在通过提供大规模的脑磁图(MEG)数据集LibriBrain和Python库pnpl来促进非侵入性神经解码技术的发展。比赛定义了两个基础任务（即从脑数据中进行语音检测和音素分类），并提供了标准化的数据分割、评估指标、基准模型、在线教程代码、社区讨论板和公开排行榜以促进参与和技术进步。


<details>
  <summary>更多</summary>
  
**动机:** 推动非侵入性神经解码技术的进步，特别是为了帮助因言语缺陷如构音障碍而瘫痪的个体恢复沟通能力，无需高风险外科手术干预。

**方法:** 通过提供迄今为止记录的最大规模的单个被试MEG数据集（LibriBrain）以及一个易于使用的Python库（pnpl），定义了两项基本任务：从大脑数据中进行语音检测和音素分类，并配有标准数据划分和评估度量、基准模型、在线教程代码等。

**结果:** 创建了一个平台，包括标准化的任务、数据集、工具包和社区支持，为机器学习社区提供了条件，以期在非侵入性神经解码方面取得突破。

**结论:** 通过举办2025 PNPL竞赛及提供相应的资源和支持，有望加速非侵入性脑机接口在语音领域的进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+2025+PNPL+Competition%3A+Speech+Detection+and+Phoneme+Classification+in+the+LibriBrain+Dataset，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10165，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10165&send_immediately=true&force_search=false)

**原文摘要:** The advance of speech decoding from non-invasive brain data holds the
potential for profound societal impact. Among its most promising applications
is the restoration of communication to paralysed individuals affected by speech
deficits such as dysarthria, without the need for high-risk surgical
interventions. The ultimate aim of the 2025 PNPL competition is to produce the
conditions for an "ImageNet moment" or breakthrough in non-invasive neural
decoding, by harnessing the collective power of the machine learning community.
  To facilitate this vision we present the largest within-subject MEG dataset
recorded to date (LibriBrain) together with a user-friendly Python library
(pnpl) for easy data access and integration with deep learning frameworks. For
the competition we define two foundational tasks (i.e. Speech Detection and
Phoneme Classification from brain data), complete with standardised data splits
and evaluation metrics, illustrative benchmark models, online tutorial code, a
community discussion board, and public leaderboard for submissions. To promote
accessibility and participation the competition features a Standard track that
emphasises algorithmic innovation, as well as an Extended track that is
expected to reward larger-scale computing, accelerating progress toward a
non-invasive brain-computer interface for speech.

</details>


### [28] [Wasserstein Barycenter Soft Actor-Critic](https://arxiv.org/abs/2506.10167)
*Zahra Shahrooei, Ali Baheri*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为WBSAC的算法，该算法通过结合悲观和乐观策略来提高探索效率，并在MuJoCo连续控制任务上展示了比现有方法更优的样本效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度非策略actor-critic算法在连续控制领域表现出色，但在稀疏奖励环境中样本效率低。

**方法:** 提出了Wasserstein Barycenter Soft Actor-Critic (WBSAC) 算法，利用悲观演员进行时间差分学习，乐观演员促进探索，并采用两者的Wasserstein重心作为探索策略，同时在整个学习过程中调整探索程度。

**结果:** WBSAC在MuJoCo连续控制任务中展现出比最先进的非策略actor-critic算法更高的样本效率。

**结论:** 通过提供一种有原则导向的探索策略，WBSAC算法能够有效解决现有算法在稀疏奖励环境中的样本效率问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Wasserstein+Barycenter+Soft+Actor-Critic，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10167，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10167&send_immediately=true&force_search=false)

**原文摘要:** Deep off-policy actor-critic algorithms have emerged as the leading framework
for reinforcement learning in continuous control domains. However, most of
these algorithms suffer from poor sample efficiency, especially in environments
with sparse rewards. In this paper, we take a step towards addressing this
issue by providing a principled directed exploration strategy. We propose
Wasserstein Barycenter Soft Actor-Critic (WBSAC) algorithm, which benefits from
a pessimistic actor for temporal difference learning and an optimistic actor to
promote exploration. This is achieved by using the Wasserstein barycenter of
the pessimistic and optimistic policies as the exploration policy and adjusting
the degree of exploration throughout the learning process. We compare WBSAC
with state-of-the-art off-policy actor-critic algorithms and show that WBSAC is
more sample-efficient on MuJoCo continuous control tasks.

</details>


### [29] [A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes](https://arxiv.org/abs/2506.10180)
*Mowafaq Salem Alzboon, Mohammad Al-Batah, Muhyeeddin Alqaraleh, Ahmad Abuashour, Ahmad Fuad Bader*

**主要类别:** cs.LG

**AI概要:** 该研究使用Pima Indians Diabetes数据集评估了多种机器学习方法在糖尿病预测中的有效性，发现神经网络算法表现最佳，准确率达到78.57%，其次是随机森林方法，准确率为76.30%。


<details>
  <summary>更多</summary>
  
**动机:** 糖尿病正在成为许多国家的重要健康问题，早期识别和控制至关重要。

**方法:** 研究中评估的方法包括逻辑回归、决策树、随机森林、k-最近邻、朴素贝叶斯、支持向量机、梯度提升以及神经网络。

**结果:** 神经网络算法表现出最高的准确性，为78.57%，其次为随机森林方法，准确性达到76.30%。

**结论:** 研究表明，机器学习算法可以辅助糖尿病预测，并且能够作为有效的早期检测工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comparative+Study+of+Machine+Learning+Techniques+for+Early+Prediction+of+Diabetes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10180，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10180&send_immediately=true&force_search=false)

**原文摘要:** In many nations, diabetes is becoming a significant health problem, and early
identification and control are crucial. Using machine learning algorithms to
predict diabetes has yielded encouraging results. Using the Pima Indians
Diabetes dataset, this study attempts to evaluate the efficacy of several
machine-learning methods for diabetes prediction. The collection includes
information on 768 patients, such as their ages, BMIs, and glucose levels. The
techniques assessed are Logistic Regression, Decision Tree, Random Forest,
k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting,
and Neural Network. The findings indicate that the Neural Network algorithm
performed the best, with an accuracy of 78.57 percent, followed by the Random
Forest method, with an accuracy of 76.30 percent. The study implies that
machine learning algorithms can aid diabetes prediction and be an efficient
early detection tool.

</details>


### [30] [Optimizing Genetic Algorithms with Multilayer Perceptron Networks for Enhancing TinyFace Recognition](https://arxiv.org/abs/2506.10184)
*Mohammad Subhi Al-Batah, Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh*

**主要类别:** cs.LG

**AI概要:** 本研究通过三个不同的数据集对MLP网络进行了实证检验，采用了三种方法：默认设置的基线训练、基于遗传算法（GA）的特征选择和基于主成分分析（PCA）的降维。结果表明，在低维度无噪声的数据集中PCA显示出优势，而在复杂数据集中GA能够准确识别关键特征从而提高准确性。研究强调了特征选择与降维在提升MLP性能方面相互依赖的作用，并为机器学习任务提供了实用指导。


<details>
  <summary>更多</summary>
  
**动机:** 这项研究旨在探讨多层感知机（MLP）网络在不同数据集上的表现，并通过实验比较了几种改进方法的效果，以期为特征工程和神经网络参数优化提供参考。

**方法:** 研究采用了三种主要方法：a) 使用默认设置进行MLP的基线训练；b) 采用基于遗传算法(GA)的方法来进行特征选择；c) 利用主成分分析(PCA)来减少数据维度。

**结果:** 结果显示，对于低维度且没有噪音的数据集，PCA方法能带来好处；而对于复杂的数据集，GA方法通过精确地识别关键特征而始终提高了准确性。

**结论:** 该研究表明，特征选择与降维技术在增强MLP模型性能方面起着相辅相成的作用，并为广泛的机器学习任务提供了实践指南。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+Genetic+Algorithms+with+Multilayer+Perceptron+Networks+for+Enhancing+TinyFace+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10184&send_immediately=true&force_search=false)

**原文摘要:** This study conducts an empirical examination of MLP networks investigated
through a rigorous methodical experimentation process involving three diverse
datasets: TinyFace, Heart Disease, and Iris. Study Overview: The study includes
three key methods: a) a baseline training using the default settings for the
Multi-Layer Perceptron (MLP), b) feature selection using Genetic Algorithm (GA)
based refinement c) Principal Component Analysis (PCA) based dimension
reduction. The results show important information on how such techniques affect
performance. While PCA had showed benefits in low-dimensional and noise-free
datasets GA consistently increased accuracy in complex datasets by accurately
identifying critical features. Comparison reveals that feature selection and
dimensionality reduction play interdependent roles in enhancing MLP
performance. The study contributes to the literature on feature engineering and
neural network parameter optimization, offering practical guidelines for a wide
range of machine learning tasks

</details>


### [31] [Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment](https://arxiv.org/abs/2506.10186)
*Yuhui Ding, Thomas Hofmann*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法，通过学习每个分子的样本依赖性SO(3)变换来构建对齐的潜在空间，从而允许使用非等变扩散模型进行训练。这种方法在保持与最先进的等变扩散模型相当的样本质量的同时，提高了训练和采样效率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管等变扩散模型在3D分子生成中表现优异，但它们的专门架构限制了可扩展性和效率。本文旨在放宽等变性约束以提高模型的效率和可扩展性。

**方法:** 本文的方法是为每个分子学习一个样本依赖性的SO(3)变换，以此创建一个对齐的潜在空间，并在这个对齐的空间上训练非等变扩散模型。

**结果:** 实验结果表明，所提出的方法相比之前报道的非等变模型有显著更好的性能，同时提供了与最先进等变扩散模型相媲美的样本质量，并且在训练和采样效率方面有所改进。

**结论:** 通过放松等变性约束并采用非等变扩散模型，本文展示了一种有效的方法，可以在保持高质量输出的同时提高3D分子生成模型的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Non-Equivariant+3D+Molecule+Generation+via+Rotational+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10186&send_immediately=true&force_search=false)

**原文摘要:** Equivariant diffusion models have achieved impressive performance in 3D
molecule generation. These models incorporate Euclidean symmetries of 3D
molecules by utilizing an SE(3)-equivariant denoising network. However,
specialized equivariant architectures limit the scalability and efficiency of
diffusion models. In this paper, we propose an approach that relaxes such
equivariance constraints. Specifically, our approach learns a sample-dependent
SO(3) transformation for each molecule to construct an aligned latent space. A
non-equivariant diffusion model is then trained over the aligned
representations. Experimental results demonstrate that our approach performs
significantly better than previously reported non-equivariant models. It yields
sample quality comparable to state-of-the-art equivariant diffusion models and
offers improved training and sampling efficiency. Our code is available at
https://github.com/skeletondyh/RADM

</details>


### [32] [Improving Oral Cancer Outcomes Through Machine Learning and Dimensionality Reduction](https://arxiv.org/abs/2506.10189)
*Mohammad Subhi Al-Batah, Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon*

**主要类别:** cs.LG

**AI概要:** 该研究综述了数据挖掘方法在口腔癌诊断和预后中的应用，发现神经网络模型在预测口腔癌方面表现最佳，准确率达到93.6%。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高口腔癌患者的生存率，需要早期诊断和准确的预后。机器学习和数据挖掘的进步为区分良性和恶性口腔病变提供了先进的自动化工具。

**方法:** 研究采用了包括神经网络、K-最近邻（KNN）、支持向量机（SVM）以及集成学习技术在内的多种前沿数据挖掘方法，并进行了严格的对比分析。

**结果:** 研究表明，神经网络模型在预测口腔癌方面超越了其他模型，达到了93.6%的分类准确率。此外，研究还强调了特征选择和降维技术结合使用可以提高模型性能。

**结论:** 先进的数据挖掘技术对于加强早期检测、优化治疗策略以及最终改善口腔肿瘤学领域的患者结果具有显著潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Oral+Cancer+Outcomes+Through+Machine+Learning+and+Dimensionality+Reduction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10189，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10189&send_immediately=true&force_search=false)

**原文摘要:** Oral cancer presents a formidable challenge in oncology, necessitating early
diagnosis and accurate prognosis to enhance patient survival rates. Recent
advancements in machine learning and data mining have revolutionized
traditional diagnostic methodologies, providing sophisticated and automated
tools for differentiating between benign and malignant oral lesions. This study
presents a comprehensive review of cutting-edge data mining methodologies,
including Neural Networks, K-Nearest Neighbors (KNN), Support Vector Machines
(SVM), and ensemble learning techniques, specifically applied to the diagnosis
and prognosis of oral cancer. Through a rigorous comparative analysis, our
findings reveal that Neural Networks surpass other models, achieving an
impressive classification accuracy of 93,6 % in predicting oral cancer.
Furthermore, we underscore the potential benefits of integrating feature
selection and dimensionality reduction techniques to enhance model performance.
These insights underscore the significant promise of advanced data mining
techniques in bolstering early detection, optimizing treatment strategies, and
ultimately improving patient outcomes in the realm of oral oncology.

</details>


### [33] [DynaSubVAE: Adaptive Subgrouping for Scalable and Robust OOD Detection](https://arxiv.org/abs/2506.10200)
*Tina Behrouzi, Sana Tonekaboni, Rahul G. Krishnan, Anna Goldenberg*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为DynaSubVAE的动态子群变分自编码器框架，该框架能够同时进行表征学习和自适应的OOD（Out-of-domain）检测。通过非参数聚类机制来发现并建模潜在子群，并且在近OOD、远OOD以及类OOD场景中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的观察数据往往包含了偏离全局模式的现有或正在出现的不同子群体，而大多数模型往往会忽略这些少数群体，导致预测不准确甚至有害。现有的解决方案通常依赖于将这些样本检测为域外(Out-of-domain, OOD)，而不是使模型适应新的出现模式。

**方法:** DynaSubVAE是一种动态子群变分自编码器框架，它能够同时执行表征学习和自适应的OOD检测。与传统方法不同的是，DynaSubVAE可以通过动态更新其潜在结构来随着数据的变化捕捉新趋势。它利用一种新颖的非参数聚类机制（受高斯混合模型启发），基于嵌入相似性发现并建模潜在子群。

**结果:** 广泛的实验表明，DynaSubVAE在近OOD和远OOD检测中都达到了有竞争力的表现，在训练过程中整个类别缺失的类OOD情景下表现尤为突出。此外，我们的动态子群划分机制在OOD准确性及遗憾精度方面优于GMM和KMeans++等独立聚类方法。

**结论:** DynaSubVAE提供了一个有效的框架，用于处理现实世界数据中存在的异质子群体问题，不仅能够识别出这些异常情况，还能让模型学会适应新兴的数据模式，从而提高对于未见数据的鲁棒性和泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DynaSubVAE%3A+Adaptive+Subgrouping+for+Scalable+and+Robust+OOD+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10200，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10200&send_immediately=true&force_search=false)

**原文摘要:** Real-world observational data often contain existing or emerging
heterogeneous subpopulations that deviate from global patterns. The majority of
models tend to overlook these underrepresented groups, leading to inaccurate or
even harmful predictions. Existing solutions often rely on detecting these
samples as Out-of-domain (OOD) rather than adapting the model to new emerging
patterns. We introduce DynaSubVAE, a Dynamic Subgrouping Variational
Autoencoder framework that jointly performs representation learning and
adaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves with
the data by dynamically updating its latent structure to capture new trends. It
leverages a novel non-parametric clustering mechanism, inspired by Gaussian
Mixture Models, to discover and model latent subgroups based on embedding
similarity. Extensive experiments show that DynaSubVAE achieves competitive
performance in both near-OOD and far-OOD detection, and excels in class-OOD
scenarios where an entire class is missing during training. We further
illustrate that our dynamic subgrouping mechanism outperforms standalone
clustering methods such as GMM and KMeans++ in terms of both OOD accuracy and
regret precision.

</details>


### [34] [AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent](https://arxiv.org/abs/2506.10205)
*Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法AWP，用于大型语言模型的权重剪枝和量化，并在实验中证明了该方法优于现有的剪枝和量化方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决大型语言模型（LLMs）的巨大规模问题，特别是在边缘设备上，通常会采用诸如量化和剪枝等模型压缩方法。

**方法:** 作者们提出了一个统一的方法AWP，该方法通过投影梯度下降来进行激活感知权重剪枝和量化，并借鉴了迭代硬阈值法（IHT）的成功经验。

**结果:** 实验表明AWP方法在大型语言模型的剪枝和量化方面超过了当前最先进方法的表现。

**结论:** 提供了所提方法在剪枝方面的理论收敛性保证，同时实验证明了AWP的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AWP%3A+Activation-Aware+Weight+Pruning+and+Quantization+with+Projected+Gradient+Descent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10205，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10205&send_immediately=true&force_search=false)

**原文摘要:** To address the enormous size of Large Language Models (LLMs), model
compression methods, such as quantization and pruning, are often deployed,
especially on edge devices. In this work, we focus on layer-wise post-training
quantization and pruning. Drawing connections between activation-aware weight
pruning and sparse approximation problems, and motivated by the success of
Iterative Hard Thresholding (IHT), we propose a unified method for
Activation-aware Weight pruning and quantization via Projected gradient descent
(AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLM
pruning and quantization methods. Theoretical convergence guarantees of the
proposed method for pruning are also provided.

</details>


### [35] [Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms](https://arxiv.org/abs/2506.10212)
*Sajjad Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni*

**主要类别:** cs.LG

**AI概要:** 本研究使用EPHNOGRAM数据集，通过线性和非线性机器学习模型包括非因果LSTM网络来重建ECG和PCG信号，并分析了因果关系、生理状态和跨受试者变异性的影响。研究表明非线性模型在重建性能上更优，并且从PCG估计ECG生物标志物是可行的。


<details>
  <summary>更多</summary>
  
**动机:** 尽管同时记录的心电图（ECG）和心音图（PCG）提供了心脏功能的全面多模态视角，但这些信号独特和重叠的信息内容以及它们相互重建和生物标志物提取的潜力仍不完全清楚，特别是在不同生理条件和个人之间。

**方法:** 研究使用了EPHNOGRAM数据集中的静息和运动期间的同时ECG-PCG记录，应用了一系列线性和非线性机器学习模型，特别是非因果LSTM网络，来进行每种模态之间的互重建，并分析了因果关系、生理状态及跨受试者变异性的影响力。

**结果:** 结果显示非线性模型，尤其是非因果LSTM，提供了更好的重建性能；重建ECG从PCG比反向更容易实现。锻炼和跨受试者情况提出了重大挑战，但是基于包络建模利用瞬时幅度特征显著提高了跨模态学习的跨受试者泛化能力。此外，展示了临床相关的心电图生物标志物如标志点和QT间期可以从心音图中估算出来。

**结论:** 这些发现增进了我们对心脏机电模式之间关系的理解，无论是在波形特征还是心脏事件的时间方面，都具有潜在的应用于新型多模态心脏监测技术的价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cross-Learning+Between+ECG+and+PCG%3A+Exploring+Common+and+Exclusive+Characteristics+of+Bimodal+Electromechanical+Cardiac+Waveforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10212，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10212&send_immediately=true&force_search=false)

**原文摘要:** Simultaneous electrocardiography (ECG) and phonocardiogram (PCG) provide a
comprehensive, multimodal perspective on cardiac function by capturing the
heart's electrical and mechanical activities, respectively. However, the
distinct and overlapping information content of these signals, as well as their
potential for mutual reconstruction and biomarker extraction, remains
incompletely understood, especially under varying physiological conditions and
across individuals.
  In this study, we systematically investigate the common and exclusive
characteristics of ECG and PCG using the EPHNOGRAM dataset of simultaneous
ECG-PCG recordings during rest and exercise. We employ a suite of linear and
nonlinear machine learning models, including non-causal LSTM networks, to
reconstruct each modality from the other and analyze the influence of
causality, physiological state, and cross-subject variability. Our results
demonstrate that nonlinear models, particularly non-causal LSTM, provide
superior reconstruction performance, with reconstructing ECG from PCG proving
more tractable than the reverse. Exercise and cross-subject scenarios present
significant challenges, but envelope-based modeling that utilizes instantaneous
amplitude features substantially improves cross-subject generalizability for
cross-modal learning. Furthermore, we demonstrate that clinically relevant ECG
biomarkers, such as fiducial points and QT intervals, can be estimated from PCG
in cross-subject settings.
  These findings advance our understanding of the relationship between
electromechanical cardiac modalities, in terms of both waveform characteristics
and the timing of cardiac events, with potential applications in novel
multimodal cardiac monitoring technologies.

</details>


### [36] [LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation](https://arxiv.org/abs/2506.10235)
*Chen-Chia Chang, Wan-Hsuan Lin, Yikang Shen, Yiran Chen, Xin Zhang*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于语言模型的模拟拓扑生成方法LaMAGIC2，该方法通过改进组件类型识别、减少token长度复杂度以及提高数值精度敏感性来解决现有方法存在的问题。实验表明，LaMAGIC2在严格的容差下成功率提高了34%，并且相比先前的方法MSE降低了10倍。


<details>
  <summary>更多</summary>
  
**动机:** 由于现代应用的定制化需求和大量的人工工程投入，自动化模拟拓扑设计至关重要。现有的工作虽然采用序列到序列的方法及语言模型上的监督微调来根据用户规格生成拓扑结构，但其电路表达式效率低下且对数值输入的精度敏感度低。

**方法:** 本文介绍了一种新的简明浮点输入规范表示法（SFCI），它通过基于标识符的表现方式改善了组件类型的识别，将token长度复杂度降至O(|V|)，同时增强了数值精度敏感性以实现更好的性能表现。

**结果:** LaMAGIC2在严格容差为0.01的情况下实现了比先前方法高出34%的成功率，并且MSE值降低了10倍。此外，对于具有更多节点的电路，LaMAGIC2表现出更好的迁移性，最高可达58.5%的提升。

**结论:** 这些进步确立了LaMAGIC2作为模拟拓扑生成的稳健框架的地位。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LaMAGIC2%3A+Advanced+Circuit+Formulations+for+Language+Model-Based+Analog+Topology+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10235，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10235&send_immediately=true&force_search=false)

**原文摘要:** Automation of analog topology design is crucial due to customized
requirements of modern applications with heavily manual engineering efforts.
The state-of-the-art work applies a sequence-to-sequence approach and
supervised finetuning on language models to generate topologies given user
specifications. However, its circuit formulation is inefficient due to O(|V |2)
token length and suffers from low precision sensitivity to numeric inputs. In
this work, we introduce LaMAGIC2, a succinct float-input canonical formulation
with identifier (SFCI) for language model-based analog topology generation.
SFCI addresses these challenges by improving component-type recognition through
identifier-based representations, reducing token length complexity to O(|V |),
and enhancing numeric precision sensitivity for better performance under tight
tolerances. Our experiments demonstrate that LaMAGIC2 achieves 34% higher
success rates under a tight tolerance of 0.01 and 10X lower MSEs compared to a
prior method. LaMAGIC2 also exhibits better transferability for circuits with
more vertices with up to 58.5% improvement. These advancements establish
LaMAGIC2 as a robust framework for analog topology generation.

</details>


### [37] [A new type of federated clustering: A non-model-sharing approach](https://arxiv.org/abs/2506.10244)
*Yuji Kawamata, Kaoru Kamijo, Maki Kihira, Akihiro Toyoda, Tomoru Nakayama, Akira Imakura, Tetsuya Sakurai, Yukihiko Okada*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的联邦聚类方法，称为数据协作聚类（DC-Clustering），它能够在同时存在水平和垂直分割的复杂数据分布场景下进行聚类。该方法通过只共享中间表示而非原始数据来确保隐私保护，并允许在k-means和谱聚类之间灵活选择。实验结果表明，该方法可以达到与集中式聚类相似的性能，同时具有隐私保护、通信效率高和灵活性等实用特性，适用于医疗保健和金融等对隐私敏感的领域。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于联邦学习的聚类方法通常假设简单的数据划分场景，如水平或垂直分割，无法处理更加复杂的分布式结构。本研究旨在解决这一问题，提出了一个支持复杂数据划分场景下聚类的新方法。

**方法:** 研究人员提出了一种名为数据协作聚类（DC-Clustering）的新方法，它允许在保持隐私的同时进行协作聚类，每个机构只需分享中间表示而不是原始数据。该方法兼容k-means和谱聚类算法的选择，并且仅需与中央服务器进行一轮通信即可得到最终聚类结果。

**结果:** 通过使用合成数据集和公开基准数据集进行了广泛的实验。结果显示，所提方法能够达到与所有数据汇集在一起进行集中式聚类相媲美的聚类效果。

**结论:** DC-Clustering 方法填补了当前联邦学习研究中的一个重要空白，即从分布式异构数据中有效发现知识的能力。其隐私保护、通讯效率以及灵活性的特点使其成为医疗保健和金融等隐私敏感领域的有前途工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+new+type+of+federated+clustering%3A+A+non-model-sharing+approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10244&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the growing need to leverage sensitive data across
institutions has led to increased attention on federated learning (FL), a
decentralized machine learning paradigm that enables model training without
sharing raw data. However, existing FL-based clustering methods, known as
federated clustering, typically assume simple data partitioning scenarios such
as horizontal or vertical splits, and cannot handle more complex distributed
structures. This study proposes data collaboration clustering (DC-Clustering),
a novel federated clustering method that supports clustering over complex data
partitioning scenarios where horizontal and vertical splits coexist. In
DC-Clustering, each institution shares only intermediate representations
instead of raw data, ensuring privacy preservation while enabling collaborative
clustering. The method allows flexible selection between k-means and spectral
clustering, and achieves final results with a single round of communication
with the central server. We conducted extensive experiments using synthetic and
open benchmark datasets. The results show that our method achieves clustering
performance comparable to centralized clustering where all data are pooled.
DC-Clustering addresses an important gap in current FL research by enabling
effective knowledge discovery from distributed heterogeneous data. Its
practical properties -- privacy preservation, communication efficiency, and
flexibility -- make it a promising tool for privacy-sensitive domains such as
healthcare and finance.

</details>


### [38] [Interior-Point Vanishing Problem in Semidefinite Relaxations for Neural Network Verification](https://arxiv.org/abs/2506.10269)
*Ryota Ueda, Takami Sato, Ken Kobayashi, Kazuhide Nakata*

**主要类别:** cs.LG

**AI概要:** 本文探讨了半定规划（SDP）松弛在深度神经网络验证中的局限性，并提出五种解决方案以增强验证问题的可行性条件，从而提高SDP方法对深层神经网络适用性的实际解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 研究者们发现，当应用于深层网络时，半定规划（SDP）松弛存在一个关键限制：内点消失，这会导致严格可行性的丧失，这是SDP数值稳定性和最优性的关键条件。随着DNN深度增加，这种严格可行性容易丢失，成为基于SDP验证扩展的根本障碍。

**方法:** 通过严谨的理论和实证分析，研究人员展示了随着DNN深度的增加，严格可行性可能丧失的问题。为了解决内点消失问题，设计并调查了五种方案来加强验证问题的可行性条件。

**结果:** 所提出的方法能够成功解决现有方法无法解决的88%的问题，占总数的41%。此外，分析还揭示了传统的ReLU单元上下界约束继承自先前工作且没有坚实依据，实际上不仅无益而且对问题的可行性有害。

**结论:** 这项工作提供了有关基于SDP的DNN验证基本挑战的重要见解，并提出了实用解决方案，以改善其对于更深层神经网络的适用性，有助于开发更可靠和安全的DNN系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interior-Point+Vanishing+Problem+in+Semidefinite+Relaxations+for+Neural+Network+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10269，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10269&send_immediately=true&force_search=false)

**原文摘要:** Semidefinite programming (SDP) relaxation has emerged as a promising approach
for neural network verification, offering tighter bounds than other convex
relaxation methods for deep neural networks (DNNs) with ReLU activations.
However, we identify a critical limitation in the SDP relaxation when applied
to deep networks: interior-point vanishing, which leads to the loss of strict
feasibility -- a crucial condition for the numerical stability and optimality
of SDP. Through rigorous theoretical and empirical analysis, we demonstrate
that as the depth of DNNs increases, the strict feasibility is likely to be
lost, creating a fundamental barrier to scaling SDP-based verification. To
address the interior-point vanishing, we design and investigate five solutions
to enhance the feasibility conditions of the verification problem. Our methods
can successfully solve 88% of the problems that could not be solved by existing
methods, accounting for 41% of the total. Our analysis also reveals that the
valid constraints for the lower and upper bounds for each ReLU unit are
traditionally inherited from prior work without solid reasons, but are actually
not only unbeneficial but also even harmful to the problem's feasibility. This
work provides valuable insights into the fundamental challenges of SDP-based
DNN verification and offers practical solutions to improve its applicability to
deeper neural networks, contributing to the development of more reliable and
secure systems with DNNs.

</details>


### [39] [Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning](https://arxiv.org/abs/2506.10282)
*Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan*

**主要类别:** cs.LG

**AI概要:** 本文提出了Graph-MLLM，一个用于多模态图学习的综合基准测试工具，它系统地评估了三种基于多模态大语言模型（MLLMs）的方法论：编码器、对齐器和预测器。通过六个不同领域的数据集进行广泛的实验，研究发现联合考虑节点的视觉和文本属性有利于图学习，并且将视觉属性转换为文本描述可以进一步提高性能。此外，针对特定MMGs微调MLLMs即使没有明确的图结构信息也能在大多数情况下达到最先进的结果。


<details>
  <summary>更多</summary>
  
**动机:** 当前的多模态大语言模型（MLLMs）虽然在表示和理解多种模态方面表现出了显著的能力，但它们通常只关注成对的模态对齐，而忽视了数据点之间的结构性关系。现有的多模态图（MMG）学习方法分为三大类：编码器、对齐器和预测器。然而，这个领域缺乏一个统一的基准来公平地评价这些方法，这使得难以衡量取得的进展。为了填补这一空白，作者们提出了Graph-MLLM。

**方法:** 作者们创建了一个名为Graph-MLLM的基准测试框架，它能够系统地评估上述三种MMG学习范式。该框架在六个不同领域的数据集上进行了广泛的实验，以检验各种方法的有效性。

**结果:** 研究显示，同时考虑节点的视觉和文本属性有助于提升图学习的表现，即使使用预训练的文本到图像对齐模型作为编码器也是如此。此外，把视觉属性转化为文本描述比直接使用视觉输入有更好的效果。并且，对于特定MMGs进行MLLMs的微调可以在大多数情况下取得最好的结果，即便不提供显式的图结构信息。

**结论:** 本文的工作为多模态图学习提供了重要的贡献，包括一个全面的基准测试平台Graph-MLLM，它促进了不同方法间的公平比较。研究表明，结合视觉与文本信息以及适当的MLLM微调策略能够有效改进MMG学习的效果。此外，作者还开源了其实验库，以促进快速公正的评估，并激励该领域的进一步创新研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-MLLM%3A+Harnessing+Multimodal+Large+Language+Models+for+Multimodal+Graph+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10282，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10282&send_immediately=true&force_search=false)

**原文摘要:** Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in representing and understanding diverse modalities. However,
they typically focus on modality alignment in a pairwise manner while
overlooking structural relationships across data points. Integrating
multimodality with structured graph information (i.e., multimodal graphs, MMGs)
is essential for real-world applications such as social networks, healthcare,
and recommendation systems. Existing MMG learning methods fall into three
paradigms based on how they leverage MLLMs: Encoder, Aligner, and Predictor.
MLLM-as-Encoder focuses on enhancing graph neural networks (GNNs) via
multimodal feature fusion; MLLM-as-Aligner aligns multimodal attributes in
language or hidden space to enable LLM-based graph reasoning; MLLM-as-Predictor
treats MLLMs as standalone reasoners with in-context learning or fine-tuning.
Despite their advances, the MMG field lacks a unified benchmark to fairly
evaluate across these approaches, making it unclear what progress has been
made. To bridge this gap, we present Graph-MLLM, a comprehensive benchmark for
multimodal graph learning by systematically evaluating these three paradigms
across six datasets with different domains. Through extensive experiments, we
observe that jointly considering the visual and textual attributes of the nodes
benefits graph learning, even when using pre-trained text-to-image alignment
models (e.g., CLIP) as encoders. We also find that converting visual attributes
into textual descriptions further improves performance compared to directly
using visual inputs. Moreover, we observe that fine-tuning MLLMs on specific
MMGs can achieve state-of-the-art results in most scenarios, even without
explicit graph structure information. We hope that our open-sourced library
will facilitate rapid, equitable evaluation and inspire further innovative
research in this field.

</details>


### [40] [PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation](https://arxiv.org/abs/2506.10351)
*Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于小波的生理信号分析新方法，并引入了针对EMG和ECG的大规模预训练模型，同时构建了一个统一的多模态框架，通过可学习加权融合解决了低信噪比、高个体间变异性及设备不匹配等挑战，在下游任务中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 生理信号常常受到运动伪影、基线漂移和其他低信噪比干扰的影响，给分析带来了很大的困难。此外，这些信号表现出强烈的非平稳性，有尖锐的峰值和突然的变化，这使得使用传统的时域或滤波方法难以表示。

**方法:** 开发了一种新的基于小波的方法来捕捉各种生理信号中的多尺度时频特征。利用这种方法，首次为肌电图（EMG）和心电图（ECG）引入了两个大规模的预训练模型。此外，通过集成预训练脑电图（EEG）模型，构造了一个统一的多模态框架，其中每个模态通过其专用分支进行处理，并通过可学习加权融合技术进行融合。

**结果:** 所提出的基于小波的方法在捕捉生理信号特性方面表现优异，并且针对EMG和ECG的预训练模型在下游任务中达到了领先性能。统一的多模态设计有效应对了低信噪比、高被试间变异性和设备不匹配等问题，相较于现有方法，在多模态任务上取得了更好的结果。

**结论:** 基于小波的架构为不同生理信号的分析奠定了坚实的基础，而多模态设计则指向下一代生理信号处理，有望影响可穿戴健康监测、临床诊断以及更广泛的生物医学应用领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhysioWave%3A+A+Multi-Scale+Wavelet-Transformer+for+Physiological+Signal+Representation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10351，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10351&send_immediately=true&force_search=false)

**原文摘要:** Physiological signals are often corrupted by motion artifacts, baseline
drift, and other low-SNR disturbances, which pose significant challenges for
analysis. Additionally, these signals exhibit strong non-stationarity, with
sharp peaks and abrupt changes that evolve continuously, making them difficult
to represent using traditional time-domain or filtering methods. To address
these issues, a novel wavelet-based approach for physiological signal analysis
is presented, aiming to capture multi-scale time-frequency features in various
physiological signals. Leveraging this technique, two large-scale pretrained
models specific to EMG and ECG are introduced for the first time, achieving
superior performance and setting new baselines in downstream tasks.
Additionally, a unified multi-modal framework is constructed by integrating
pretrained EEG model, where each modality is guided through its dedicated
branch and fused via learnable weighted fusion. This design effectively
addresses challenges such as low signal-to-noise ratio, high inter-subject
variability, and device mismatch, outperforming existing methods on multi-modal
tasks. The proposed wavelet-based architecture lays a solid foundation for
analysis of diverse physiological signals, while the multi-modal design points
to next-generation physiological signal processing with potential impact on
wearable health monitoring, clinical diagnostics, and broader biomedical
applications.

</details>


### [41] [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://arxiv.org/abs/2506.10314)
*Luc Raszewski, Christine De Kock*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种使用元学习的方法来提高在数据稀缺情况下识别维基百科上恶意傀儡账户的准确性，并发布了一个新的数据集以促进未来研究。


<details>
  <summary>更多</summary>
  
**动机:** 先前的机器学习方法依赖于风格和元数据特征，但未能适应作者特定的行为模式，尤其是在文本数据有限时，难以有效建模特定傀儡组的行为。

**方法:** 应用元学习技术，这种技术通过跨多个任务训练模型来改善在数据稀缺环境中的表现，旨在快速适应新傀儡组的写作风格。

**结果:** 结果显示，与预训练模型相比，元学习显著提高了预测精度，标志着在开放编辑平台上对抗傀儡行为的进步。

**结论:** 元学习为解决维基百科上的恶意傀儡账户问题提供了更有效的解决方案，并且通过发布新的数据集支持了未来的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+Sockpuppetry+on+Wikipedia+Using+Meta-Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10314，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10314&send_immediately=true&force_search=false)

**原文摘要:** Malicious sockpuppet detection on Wikipedia is critical to preserving access
to reliable information on the internet and preventing the spread of
disinformation. Prior machine learning approaches rely on stylistic and
meta-data features, but do not prioritise adaptability to author-specific
behaviours. As a result, they struggle to effectively model the behaviour of
specific sockpuppet-groups, especially when text data is limited. To address
this, we propose the application of meta-learning, a machine learning technique
designed to improve performance in data-scarce settings by training models
across multiple tasks. Meta-learning optimises a model for rapid adaptation to
the writing style of a new sockpuppet-group. Our results show that
meta-learning significantly enhances the precision of predictions compared to
pre-trained models, marking an advancement in combating sockpuppetry on open
editing platforms. We release a new dataset of sockpuppet investigations to
foster future research in both sockpuppetry and meta-learning fields.

</details>


### [42] [PyLO: Towards Accessible Learned Optimizers in PyTorch](https://arxiv.org/abs/2506.10315)
*Paul Janson, Benjamin Therien, Quentin Anthony, Xiaolong Huang, Abhinav Moudgil, Eugene Belilovsky*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PyLO，一个基于PyTorch的库，它将学习型优化器带给更广泛的机器学习社区，并提供了CUDA加速版本的小型全连接学习型优化器架构，以提高真实世界大规模预训练任务中的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管学习型优化器在过去十年中是一个活跃的研究领域，但最近的进步如VeLO由于依赖于JAX和缺乏用户友好的软件包而难以被广泛使用。为了填补这一空白，作者开发了PyLO，旨在通过熟悉的、广泛采用的工作流程让学习型优化器更容易被机器学习社区所接受。

**方法:** 开发了一个名为PyLO的PyTorch库，该库包含了CUDA加速的小型全连接学习型优化器（small_fc_lopt）架构，以及允许与现有优化工具如学习率调度和权重衰减结合的功能。

**结果:** PyLO显著提高了ViT B/16模型在批量大小为32的情况下的吞吐量，从每秒39.36个样本提升到每秒205.59个样本。此外，当与现有的优化工具相结合时，学习型优化器可以大大受益。

**结论:** PyLO作为一个开源库，为机器学习社区提供了易于使用的接口来应用学习型优化器，并且在实际的大规模预训练任务中显示出了性能上的优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PyLO%3A+Towards+Accessible+Learned+Optimizers+in+PyTorch，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10315&send_immediately=true&force_search=false)

**原文摘要:** Learned optimizers have been an active research topic over the past decade,
with increasing progress toward practical, general-purpose optimizers that can
serve as drop-in replacements for widely used methods like Adam. However,
recent advances -- such as VeLO, which was meta-trained for 4000 TPU-months --
remain largely inaccessible to the broader community, in part due to their
reliance on JAX and the absence of user-friendly packages for applying the
optimizers after meta-training. To address this gap, we introduce PyLO, a
PyTorch-based library that brings learned optimizers to the broader machine
learning community through familiar, widely adopted workflows. Unlike prior
work focused on synthetic or convex tasks, our emphasis is on applying learned
optimization to real-world large-scale pre-training tasks. Our release includes
a CUDA-accelerated version of the small_fc_lopt learned optimizer architecture
from (Metz et al., 2022a), delivering substantial speedups -- from 39.36 to
205.59 samples/sec throughput for training ViT B/16 with batch size 32. PyLO
also allows us to easily combine learned optimizers with existing optimization
tools such as learning rate schedules and weight decay. When doing so, we find
that learned optimizers can substantially benefit. Our code is available at
https://github.com/Belilovsky-Lab/pylo

</details>


### [43] [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org/abs/2506.10403)
*Tzu-Heng Huang, Harit Vishwakarma, Frederic Sala*

**主要类别:** cs.LG

**AI概要:** 介绍了PAJAMA，一种利用大语言模型合成可执行评判程序的方法，以低成本提供更一致、更少偏见的评估。


<details>
  <summary>更多</summary>
  
**动机:** 解决使用大语言模型直接评价生成内容时存在的高成本、不可靠性、不灵活性和内在偏见问题。

**方法:** 提出了一种名为PAJAMA的新方法，该方法利用大语言模型来合成可执行的评判程序，这些程序可以本地存储并运行，大大降低了成本，并且提供了更加透明与可审计的评判逻辑。

**结果:** 基于程序的评判者比基于Qwen2.5-14B的大语言模型作为评判者提高了15.83%的一致性和减少了23.7%的偏见响应；在将程序判断提炼成模型后，在RewardBench中的CHAT-HARD子集上表现优于LLM-as-a-judge，其中Prometheus指标提升2.19%，JudgeLM数据集上提升8.67%，同时成本降低三个数量级。

**结论:** PAJAMA作为一种新的自动模型评估方案，不仅显著降低了成本，还提高了评判的一致性和公平性，为大语言模型生成物质量评价提供了一个有效而经济的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time+To+Impeach+LLM-as-a-Judge%3A+Programs+are+the+Future+of+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10403&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are widely used to evaluate the quality of LLM
generations and responses, but this leads to significant challenges: high API
costs, uncertain reliability, inflexible pipelines, and inherent biases. To
address these, we introduce PAJAMA (Program-As-a-Judge for Automated Model
Assessment), a new alternative that uses LLMs to synthesize executable judging
programs instead of directly scoring responses. These synthesized programs can
be stored and run locally, costing orders of magnitude less while providing
interpretable, and auditable judging logic that can be easily adapted.
Program-based judges mitigate biases, improving judgment consistency by 15.83%
and reducing biased responses by 23.7% on average compared to a
Qwen2.5-14B-based LLM-as-a-judge. When program judgments are distilled into a
model, PAJAMA outperforms LLM-as-a-judge on the challenging CHAT-HARD subset of
RewardBench, outperforming metrics by 2.19% on Prometheus and 8.67% on the
JudgeLM dataset, all at three orders of magnitude lower cost.

</details>


### [44] [Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](https://arxiv.org/abs/2506.10412)
*Ching Chang, Jeehyun Hwang, Yidan Shi, Haixin Wang, Wen-Chih Peng, Tien-Fu Chen, Wei Wang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Time-IMM数据集和IMM-TSF基准库，用于处理真实世界应用中不规则、多模态的时间序列数据。通过引入这些工具，研究者能够更好地对复杂时间序列进行建模，并在实际条件下提高预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的时间序列数据往往是不规则的、多模态的且杂乱无章，而现有的基准通常假设干净、规则采样、单一模态的数据，这导致了研究与实际部署之间存在显著差距。

**方法:** 引入了名为Time-IMM的数据集，它专门设计来捕捉由原因驱动的不规则性在多模态多元时间序列中的表现；同时开发了IMM-TSF，一个针对不规则多模态时间序列预测的基准库，该库支持异步集成和现实评估，并包括了专门的融合模块。

**结果:** 实证结果表明，在不规则时间序列数据上明确地建模多模态可以显著提高预测性能。

**结论:** Time-IMM数据集和IMM-TSF基准库为在现实条件下推进时间序列分析提供了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time-IMM%3A+A+Dataset+and+Benchmark+for+Irregular+Multimodal+Multivariate+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10412，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10412&send_immediately=true&force_search=false)

**原文摘要:** Time series data in real-world applications such as healthcare, climate
modeling, and finance are often irregular, multimodal, and messy, with varying
sampling rates, asynchronous modalities, and pervasive missingness. However,
existing benchmarks typically assume clean, regularly sampled, unimodal data,
creating a significant gap between research and real-world deployment. We
introduce Time-IMM, a dataset specifically designed to capture cause-driven
irregularity in multimodal multivariate time series. Time-IMM represents nine
distinct types of time series irregularity, categorized into trigger-based,
constraint-based, and artifact-based mechanisms. Complementing the dataset, we
introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal
time series, enabling asynchronous integration and realistic evaluation.
IMM-TSF includes specialized fusion modules, including a timestamp-to-text
fusion module and a multimodality fusion module, which support both
recency-aware averaging and attention-based integration strategies. Empirical
results demonstrate that explicitly modeling multimodality on irregular time
series data leads to substantial gains in forecasting performance. Time-IMM and
IMM-TSF provide a foundation for advancing time series analysis under
real-world conditions. The dataset is publicly available at
https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the
benchmark library can be accessed at
https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.

</details>


### [45] [Provably Learning from Language Feedback](https://arxiv.org/abs/2506.10341)
*Wanqiao Xu, Allen Nie, Ruijie Zheng, Aditya Modi, Adith Swaminathan, Ching-An Cheng*

**主要类别:** cs.LG

**AI概要:** 本文提出了Learning from Language Feedback (LLF) 问题的正式定义，引入了转移逃避维度作为复杂度量，并开发了一个无悔算法HELiX来解决这一问题。实验表明，与基于奖励的学习相比，从丰富的语言反馈中学习可以指数级加快，且HELiX在多个领域表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLM）代理的出现，从观察和语言反馈中交互式学习成为越来越受关注的研究领域。尽管已经展示了令人印象深刻的实证结果，但这些决策问题的原则性框架仍然缺乏。

**方法:** 文章首先形式化了Learning from Language Feedback (LLF) 问题，提出了充分假设以支持即使存在潜在回报时也能进行学习，并引入了转移逃避维度作为衡量LLF问题难度的复杂度指标。接着，作者们开发了一种名为HELiX的无悔算法，通过序列交互证明能够解决LLF问题。

**结果:** 研究表明，当信息反馈改变LLF问题的学习复杂度时，转移逃避维度能够捕捉到这一点。此外，研究还展示了从丰富语言反馈中学习比从奖励中学习可以快得多。HELiX算法在多种实证领域表现良好，甚至在反复提示LLM不可靠的情况下也如此。

**结论:** 本文为设计通用语言反馈下的原则性交互学习算法迈出了第一步，提供了对LLF问题的理论理解和实用解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Provably+Learning+from+Language+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10341，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10341&send_immediately=true&force_search=false)

**原文摘要:** Interactively learning from observation and language feedback is an
increasingly studied area driven by the emergence of large language model (LLM)
agents. While impressive empirical demonstrations have been shown, so far a
principled framing of these decision problems remains lacking. In this paper,
we formalize the Learning from Language Feedback (LLF) problem, assert
sufficient assumptions to enable learning despite latent rewards, and introduce
$\textit{transfer eluder dimension}$ as a complexity measure to characterize
the hardness of LLF problems. We show that transfer eluder dimension captures
the intuition that information in the feedback changes the learning complexity
of the LLF problem. We demonstrate cases where learning from rich language
feedback can be exponentially faster than learning from reward. We develop a
no-regret algorithm, called $\texttt{HELiX}$, that provably solves LLF problems
through sequential interactions, with performance guarantees that scale with
the transfer eluder dimension of the problem. Across several empirical domains,
we show that $\texttt{HELiX}$ performs well even when repeatedly prompting LLMs
does not work reliably. Our contributions mark a first step towards designing
principled interactive learning algorithms from generic language feedback.

</details>


### [46] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
*Reza Karbasi, Masoud Rahimi, Abdol-Hossein Vahabie, Hadi Moradi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种两阶段方法来解决ECG记录数字化过程中信号重叠的问题，通过U-Net分割网络和自适应网格检测模块提高了准确性和鲁棒性，并在非重叠和重叠样本上都优于基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决纸质心电图（ECG）记录精确数字化的持久挑战，尤其是单导联因信号重叠而受到干扰的问题，这个问题在现有方法中未得到充分解决。

**方法:** 提出了一个两阶段流程：第一阶段使用基于U-Net的分割网络，该网络经过了含有信号重叠的数据集训练，并且加入了定制的数据增强技术；第二阶段则将精细化的二进制掩模转换成时间序列信号，同时利用了一个自适应网格检测模块以提高对不同ECG格式和尺度的适应能力。

**结果:** 实验结果表明，所提出的U-Net架构在精细分割任务中达到了0.87的交并比（IoU）。对于非重叠信号，相比基线方法，本方法实现了更低的均方误差（MSE）0.0010与更高的皮尔森相关系数（rho）0.9644；而在有信号重叠的情况下，本方法的MSE为0.0029、rho为0.9641，显著优于基线方法的表现。

**结论:** 这项工作展示了一种有效的策略，极大地提高了存在信号重叠时的ECG记录数字化准确性，为可靠的将模拟ECG记录转化为可分析的数字数据奠定了坚实基础，适用于现代研究和临床应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep+Learning-Based+Digitization+of+Overlapping+ECG+Images+with+Open-Source+Python+Code，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10617，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10617&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the persistent challenge of accurately digitizing
paper-based electrocardiogram (ECG) recordings, with a particular focus on
robustly handling single leads compromised by signal overlaps-a common yet
under-addressed issue in existing methodologies. We propose a two-stage
pipeline designed to overcome this limitation. The first stage employs a U-Net
based segmentation network, trained on a dataset enriched with overlapping
signals and fortified with custom data augmentations, to accurately isolate the
primary ECG trace. The subsequent stage converts this refined binary mask into
a time-series signal using established digitization techniques, enhanced by an
adaptive grid detection module for improved versatility across different ECG
formats and scales. Our experimental results demonstrate the efficacy of our
approach. The U-Net architecture achieves an IoU of 0.87 for the fine-grained
segmentation task. Crucially, our proposed digitization method yields superior
performance compared to a well-established baseline technique across both
non-overlapping and challenging overlapping ECG samples. For non-overlapping
signals, our method achieved a Mean Squared Error (MSE) of 0.0010 and a Pearson
Correlation Coefficient (rho) of 0.9644, compared to 0.0015 and 0.9366,
respectively, for the baseline. On samples with signal overlap, our method
achieved an MSE of 0.0029 and a rho of 0.9641, significantly improving upon the
baseline's 0.0178 and 0.8676. This work demonstrates an effective strategy to
significantly enhance digitization accuracy, especially in the presence of
signal overlaps, thereby laying a strong foundation for the reliable conversion
of analog ECG records into analyzable digital data for contemporary research
and clinical applications. The implementation is publicly available at this
GitHub repository: https://github.com/masoudrahimi39/ECG-code.

</details>


### [47] [History-Aware Neural Operator: Robust Data-Driven Constitutive Modeling of Path-Dependent Materials](https://arxiv.org/abs/2506.10352)
*Binyao Guo, Zihan Lin, QiZhi He*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一个端到端的学习框架HANO，用于路径依赖的非弹性材料的数据驱动建模。HANO能够从应变-应力历史的小片段预测材料响应，不依赖于隐藏状态变量，并通过层次自注意力机制提取多尺度特征。该模型在准确性、泛化能力和鲁棒性方面优于基线模型，适用于复杂条件下的非弹性材料仿真。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于RNN的模型在处理材料的不可逆演化时会遇到自我一致性问题和对初始隐藏状态敏感的问题，因此需要开发一种新的方法来克服这些问题，同时提高模型对于不同加载路径和复杂情况的适应能力。

**方法:** 研究者们提出了一种名为HANO（History-Aware Neural Operator）的历史感知神经算子，这是一种自动回归模型，可以从最近的应变-应力历史片段中预测路径依赖性的材料响应，而不必依赖于隐藏状态变量。它构建在基于傅里叶变换的神经算子骨架上，采用分层自注意力机制来促进多尺度特征提取。

**结果:** 实验结果表明，HANO在两个基准问题上的表现优于其他基线模型：具有硬化特性的弹塑性和脆性固体中的渐进各向异性损伤。HANO显示了更高的预测精度、更好的泛化能力和更强的鲁棒性。

**结论:** HANO为非弹性材料的模拟提供了一个有效的数据驱动代理模型，其能够自然地适应不同的路径离散化，并且在复杂条件下表现出稳健的性能。此外，HANO非常适合与经典数值求解器结合使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是History-Aware+Neural+Operator%3A+Robust+Data-Driven+Constitutive+Modeling+of+Path-Dependent+Materials，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10352，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10352&send_immediately=true&force_search=false)

**原文摘要:** This study presents an end-to-end learning framework for data-driven modeling
of path-dependent inelastic materials using neural operators. The framework is
built on the premise that irreversible evolution of material responses,
governed by hidden dynamics, can be inferred from observable data.
  We develop the History-Aware Neural Operator (HANO), an autoregressive model
that predicts path-dependent material responses from short segments of recent
strain-stress history without relying on hidden state variables, thereby
overcoming self-consistency issues commonly encountered in recurrent neural
network (RNN)-based models. Built on a Fourier-based neural operator backbone,
HANO enables discretization-invariant learning. To enhance its ability to
capture both global loading patterns and critical local path dependencies, we
embed a hierarchical self-attention mechanism that facilitates multiscale
feature extraction.
  Beyond ensuring self-consistency, HANO mitigates sensitivity to initial
hidden states, a commonly overlooked issue that can lead to instability in
recurrent models when applied to generalized loading paths. By modeling
stress-strain evolution as a continuous operator rather than relying on fixed
input-output mappings, HANO naturally accommodates varying path discretizations
and exhibits robust performance under complex conditions, including irregular
sampling, multi-cycle loading, noisy data, and pre-stressed states. We evaluate
HANO on two benchmark problems: elastoplasticity with hardening and progressive
anisotropic damage in brittle solids. Results show that HANO consistently
outperforms baseline models in predictive accuracy, generalization, and
robustness. With its demonstrated capabilities, HANO provides an effective
data-driven surrogate for simulating inelastic materials and is well-suited for
integration with classical numerical solvers.

</details>


### [48] [Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2506.10629)
*Yucheng Yang, Tianyi Zhou, Qiang He, Lei Han, Mykola Pechenizkiy, Meng Fang*

**主要类别:** cs.LG

**AI概要:** 本文分析了无监督强化学习中互信息技能学习（MISL）的不足，并提出了新的度量标准LSEPIN和基于Wasserstein距离的新技能学习目标WSEP，以提高下游任务适应性。


<details>
  <summary>更多</summary>
  
**动机:** 无监督强化学习的目标是为未见过的下游任务学习通用技能。尽管互信息技能学习（MISL）通过最大化状态与技能之间的互信息来解决这个问题，但缺乏足够的理论分析来证明其学习到的技能如何能初始化一个下游任务的策略。

**方法:** 论文引入了一个新颖的解纠缠度量LSEPIN，并建立了LSEPIN与下游任务适应成本之间信息几何上的联系。为了更好的几何性质，研究者探讨了用Wasserstein距离替换信息几何中的KL散度的新策略，并将这种几何分析扩展到了WSEP上。

**结果:** 提出了一个新的技能学习目标WSEP，它在理论上被证明对下游任务适应有帮助，并且能够比MISL发现更多的初始策略用于下游任务。此外，还提出了另一种基于Wasserstein距离的算法PWSEP，该算法可以理论上发现所有最优的初始策略。

**结论:** 研究表明，技能的多样性和可分离性对于下游任务适应至关重要，而MISL并不能保证这些属性。新提出的WSEP和PWSEP方法能够在理论上提供更好的下游任务适应性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Task+Adaptation+from+Skills%3A+Information+Geometry%2C+Disentanglement%2C+and+New+Objectives+for+Unsupervised+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10629，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10629&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised reinforcement learning (URL) aims to learn general skills for
unseen downstream tasks. Mutual Information Skill Learning (MISL) addresses URL
by maximizing the mutual information between states and skills but lacks
sufficient theoretical analysis, e.g., how well its learned skills can
initialize a downstream task's policy. Our new theoretical analysis in this
paper shows that the diversity and separability of learned skills are
fundamentally critical to downstream task adaptation but MISL does not
necessarily guarantee these properties. To complement MISL, we propose a novel
disentanglement metric LSEPIN. Moreover, we build an information-geometric
connection between LSEPIN and downstream task adaptation cost. For better
geometric properties, we investigate a new strategy that replaces the KL
divergence in information geometry with Wasserstein distance. We extend the
geometric analysis to it, which leads to a novel skill-learning objective WSEP.
It is theoretically justified to be helpful to downstream task adaptation and
it is capable of discovering more initial policies for downstream tasks than
MISL. We finally propose another Wasserstein distance-based algorithm PWSEP
that can theoretically discover all optimal initial policies.

</details>


### [49] [TreeLoRA: Efficient Continual Learning via Layer-Wise LoRAs Guided by a Hierarchical Gradient-Similarity Tree](https://arxiv.org/abs/2506.10355)
*Yu-Yang Qian, Yuan-Ze Xu, Zhen-Yu Zhang, Peng Zhao, Zhi-Hua Zhou*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的持续学习方法TreeLoRA，通过利用分层梯度相似性来构建层适配器，并使用稀疏梯度更新和基于下置信界的算法来提高大型预训练模型的效率。


<details>
  <summary>更多</summary>
  
**动机:** 在流数据环境中，需要进行持续学习（CL）以在线更新模型，使其适应新任务同时保留过去的知识。随着大型预训练模型（LPMs）的兴起，对于这些计算需求大且参数量不断增加的模型来说，效率变得尤为重要。

**方法:** 提出了TreeLoRA方法，该方法通过分层梯度相似性构建层适配器，采用赌博技术开发基于下置信界的算法来有效探索任务结构，并使用稀疏梯度更新来促进参数优化。

**结果:** 理论分析支持了该方法背后的原理，实验表明，在视觉转换器（ViTs）和大型语言模型（LLMs）上，该方法在包括视觉和自然语言处理任务在内的多个领域中既有效又高效。

**结论:** TreeLoRA为大型预训练模型提供了有效的持续学习策略，它通过减少任务相似性估计的计算负担并使用稀疏梯度更新来提高效率，从而能够适应新任务而不忘记旧知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TreeLoRA%3A+Efficient+Continual+Learning+via+Layer-Wise+LoRAs+Guided+by+a+Hierarchical+Gradient-Similarity+Tree，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10355&send_immediately=true&force_search=false)

**原文摘要:** Many real-world applications collect data in a streaming environment, where
learning tasks are encountered sequentially. This necessitates continual
learning (CL) to update models online, enabling adaptation to new tasks while
preserving past knowledge to prevent catastrophic forgetting. Nowadays, with
the flourish of large pre-trained models (LPMs), efficiency has become
increasingly critical for CL, due to their substantial computational demands
and growing parameter sizes. In this paper, we introduce TreeLoRA (K-D Tree of
Low-Rank Adapters), a novel approach that constructs layer-wise adapters by
leveraging hierarchical gradient similarity to enable efficient CL,
particularly for LPMs. To reduce the computational burden of task similarity
estimation, we employ bandit techniques to develop an algorithm based on lower
confidence bounds to efficiently explore the task structure. Furthermore, we
use sparse gradient updates to facilitate parameter optimization, making the
approach better suited for LPMs. Theoretical analysis is provided to justify
the rationale behind our approach, and experiments on both vision transformers
(ViTs) and large language models (LLMs) demonstrate the effectiveness and
efficiency of our approach across various domains, including vision and natural
language processing tasks.

</details>


### [50] [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)
*Yucong Luo, Yitong Zhou, Mingyue Cheng, Jiahao Wang, Daoyu Wang, Tingyue Pan, Jintao Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Time-R1的两阶段强化微调框架，旨在增强大型语言模型在时间序列预测中的多步推理能力。通过监督微调和强化学习相结合的方法，并设计了专门针对时间序列预测的细粒度多目标奖励机制以及一种基于组相对重要性的策略优化方法（GRIP），实验表明Time-R1能够显著提高不同数据集上的预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列预测方法大多依赖于从历史模式中提取信息并将其映射到未来值上，缺乏一个明确的思考过程来整合中间的时间序列推理。虽然新兴的慢思考大型语言模型展示出了卓越的多步推理能力，但仅靠提示工程存在计算成本高、隐私风险大及领域特定时间序列深入推理能力有限等问题。因此，有必要训练大型语言模型发展慢思考能力并获得强大的时间序列推理技能。

**方法:** 提出了Time-R1，这是一种两阶段强化微调框架，用于提升大型语言模型在时间序列预测任务中的多步推理能力。第一阶段进行有监督的微调以适应预热；第二阶段采用强化学习技术来提高模型的泛化能力。特别地，设计了一个专为时间序列预测定制的细粒度多目标奖励机制，并引入了GRIP（基于群体相对重要性的策略优化），利用非均匀采样进一步鼓励和优化模型探索有效推理路径的过程。

**结果:** 实验结果表明，在多种不同的数据集上，Time-R1相比现有方法能够显著提升预测性能。

**结论:** 通过结合监督微调与强化学习，并设计特定于时间序列预测任务的奖励机制及策略优化方法，Time-R1提供了一种有效的解决方案，用以增强大型语言模型在时间序列预测中的多步推理能力，从而实现更准确的预测结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time+Series+Forecasting+as+Reasoning%3A+A+Slow-Thinking+Approach+with+Reinforced+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10630，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10630&send_immediately=true&force_search=false)

**原文摘要:** To advance time series forecasting (TSF), various methods have been proposed
to improve prediction accuracy, evolving from statistical techniques to
data-driven deep learning architectures. Despite their effectiveness, most
existing methods still adhere to a fast thinking paradigm-relying on extracting
historical patterns and mapping them to future values as their core modeling
philosophy, lacking an explicit thinking process that incorporates intermediate
time series reasoning. Meanwhile, emerging slow-thinking LLMs (e.g., OpenAI-o1)
have shown remarkable multi-step reasoning capabilities, offering an
alternative way to overcome these issues. However, prompt engineering alone
presents several limitations - including high computational cost, privacy
risks, and limited capacity for in-depth domain-specific time series reasoning.
To address these limitations, a more promising approach is to train LLMs to
develop slow thinking capabilities and acquire strong time series reasoning
skills. For this purpose, we propose Time-R1, a two-stage reinforcement
fine-tuning framework designed to enhance multi-step reasoning ability of LLMs
for time series forecasting. Specifically, the first stage conducts supervised
fine-tuning for warmup adaptation, while the second stage employs reinforcement
learning to improve the model's generalization ability. Particularly, we design
a fine-grained multi-objective reward specifically for time series forecasting,
and then introduce GRIP (group-based relative importance for policy
optimization), which leverages non-uniform sampling to further encourage and
optimize the model's exploration of effective reasoning paths. Experiments
demonstrate that Time-R1 significantly improves forecast performance across
diverse datasets.

</details>


### [51] [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364)
*Penguin Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PropInfer，一个用于评估大型语言模型（LLMs）在领域特定数据集上进行微调后属性推断攻击的基准任务。该研究包括基于提示的生成攻击和利用词频信号的影子模型攻击两种定制攻击方法，并揭示了LLMs中未被认识到的漏洞。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型越来越多地在医疗保健、金融和法律等领域使用领域特定的数据集进行微调，这些数据集往往包含不应公开的敏感和机密属性，例如患者人口统计或疾病流行情况。尽管已有研究探讨了对判别模型和生成模型的属性推理攻击，但这种攻击是否适用于大型语言模型尚不清楚。

**方法:** 作者提出了PropInfer，这是一个基于ChatDoctor数据集建立的基准任务，用于评估大型语言模型在两种微调范式下的属性推理：问答和聊天完成。此外，还提出了两种针对性攻击：一种是基于提示的生成攻击，另一种是利用词频信号的影子模型攻击。

**结果:** 实证评估表明，对于多个预训练的大型语言模型，所提出的攻击取得了成功，揭示了大型语言模型中存在的此前未被认识的脆弱性。

**结论:** 这项工作强调了大型语言模型在处理敏感数据时存在潜在的安全风险，并为未来的研究提供了新的方向，即如何更好地保护这些模型免受属性推理攻击。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+We+Infer+Confidential+Properties+of+Training+Data+from+LLMs%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10364，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10364&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly fine-tuned on domain-specific
datasets to support applications in fields such as healthcare, finance, and
law. These fine-tuning datasets often have sensitive and confidential
dataset-level properties -- such as patient demographics or disease prevalence
-- that are not intended to be revealed. While prior work has studied property
inference attacks on discriminative models (e.g., image classification models)
and generative models (e.g., GANs for image data), it remains unclear if such
attacks transfer to LLMs. In this work, we introduce PropInfer, a benchmark
task for evaluating property inference in LLMs under two fine-tuning paradigms:
question-answering and chat-completion. Built on the ChatDoctor dataset, our
benchmark includes a range of property types and task configurations. We
further propose two tailored attacks: a prompt-based generation attack and a
shadow-model attack leveraging word frequency signals. Empirical evaluations
across multiple pretrained LLMs show the success of our attacks, revealing a
previously unrecognized vulnerability in LLMs.

</details>


### [52] [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org/abs/2506.10647)
*Lang Yin, Debangshu Banerjee, Gagandeep Singh*

**主要类别:** cs.LG

**AI概要:** 本文研究了思维链(CoT)在面对数据分布偏移和数据污染时对k-奇偶问题的影响，揭示了CoT可能比直接生成预测更糟糕的现象，并提供了这种影响的机制原因的严谨解释。


<details>
  <summary>更多</summary>
  
**动机:** 尽管思维链(CoT)提高了大型语言模型输出的质量，并且帮助transformers解决了一些困难的问题，但这些成果是基于相同训练和测试分布以及无污染训练数据这两个假设。现实世界中，这些假设并不总是成立。因此，本文首次严格地研究了当这些假设不成立时所带来的具体危害。

**方法:** 本研究聚焦于k-奇偶问题，考察了由分布偏移和数据污染两种类型的数据变化对使用已建立的CoT分解法所得到的训练模型质量的联合影响。

**结果:** 研究表明，在学习奇偶性问题上，CoT可能导致比直接生成预测更差的表现，并且技术结果给出了这种影响机制上的详细解释。

**结论:** 这项工作揭示了思维链方法在处理存在数据偏移和污染情况下的局限性，并为理解这些局限性的原因提供了坚实的理论基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Shifts+Hurt+CoT%3A+A+Theoretical+Study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10647，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10647&send_immediately=true&force_search=false)

**原文摘要:** Chain of Thought (CoT) has been applied to various large language models
(LLMs) and proven to be effective in improving the quality of outputs. In
recent studies, transformers are proven to have absolute upper bounds in terms
of expressive power, and consequently, they cannot solve many computationally
difficult problems. However, empowered by CoT, transformers are proven to be
able to solve some difficult problems effectively, such as the $k$-parity
problem. Nevertheless, those works rely on two imperative assumptions: (1)
identical training and testing distribution, and (2) corruption-free training
data with correct reasoning steps. However, in the real world, these
assumptions do not always hold. Although the risks of data shifts have caught
attention, our work is the first to rigorously study the exact harm caused by
such shifts to the best of our knowledge. Focusing on the $k$-parity problem,
in this work we investigate the joint impact of two types of data shifts: the
distribution shifts and data poisoning, on the quality of trained models
obtained by a well-established CoT decomposition. In addition to revealing a
surprising phenomenon that CoT leads to worse performance on learning parity
than directly generating the prediction, our technical results also give a
rigorous and comprehensive explanation of the mechanistic reasons of such
impact.

</details>


### [53] [Saturation Self-Organizing Map](https://arxiv.org/abs/2506.10680)
*Igor Urbanik, Paweł Gajewski*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Saturation Self-Organizing Maps (SatSOM)的模型，通过引入新的饱和机制来减少神经元的学习率和邻域半径，从而在连续学习场景中提高知识保留。


<details>
  <summary>更多</summary>
  
**动机:** 持续学习对神经系统提出了一个基本挑战，当面对顺序任务时，它们经常遭受灾难性遗忘的问题。尽管自组织映射（SOMs）具有可解释性和效率，但也不能幸免于此问题。

**方法:** 提出了Saturation Self-Organizing Maps (SatSOM)，这是一种扩展了SOMs的方法，旨在通过一种新的饱和机制改善连续学习情境下的知识保持。该饱和机制能够随着神经元积累信息而逐渐降低其学习率和邻域半径。

**结果:** SatSOM有效地冻结了训练良好的神经元，并将学习重定向到映射中未充分利用的区域。

**结论:** SatSOM提供了一种有效的方法来缓解自组织映射中的灾难性遗忘问题，通过逐步减小学习率和邻域半径来实现更好的知识保留。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Saturation+Self-Organizing+Map，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10680，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10680&send_immediately=true&force_search=false)

**原文摘要:** Continual learning poses a fundamental challenge for neural systems, which
often suffer from catastrophic forgetting when exposed to sequential tasks.
Self-Organizing Maps (SOMs), despite their interpretability and efficiency, are
not immune to this issue. In this paper, we introduce Saturation
Self-Organizing Maps (SatSOM)-an extension of SOMs designed to improve
knowledge retention in continual learning scenarios. SatSOM incorporates a
novel saturation mechanism that gradually reduces the learning rate and
neighborhood radius of neurons as they accumulate information. This effectively
freezes well-trained neurons and redirects learning to underutilized areas of
the map.

</details>


### [54] [EQA-RM: A Generative Embodied Reward Model with Test-time Scaling](https://arxiv.org/abs/2506.10389)
*Yuhang Chen, Zhen Tan, Tianlong Chen*

**主要类别:** cs.LG

**AI概要:** 论文提出了EQA-RM，一种专为具身问答任务设计的生成式多模态奖励模型，并通过创新的对比组相对策略优化（C-GRPO）策略训练。EQA-RM能够提供可解释、结构化的奖励反馈，并在测试时动态调整评估粒度。此外，还推出了EQARewardBench基准用于标准化评估EQA奖励模型。实验显示EQA-RM使用少量样本就能达到较高准确率，优于多个强基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有的奖励模型未能充分考虑像具身问答（EQA）这样复杂任务中对代理的空间、时间以及逻辑理解进行细致评估的需求。

**方法:** 研究者开发了EQA-RM，这是一种专为EQA设计的生成式多模态奖励模型，并通过名为对比组相对策略优化（C-GRPO）的新颖策略来学习细粒度的行为差异。同时创建了一个新的基准EQARewardBench，基于OpenEQA构建以支持对EQA奖励模型的标准化评估。

**结果:** EQA-RM展示出高样本效率，在仅使用700个样本的情况下达到了61.9%的准确率，超过了Gemini-2.5-Flash、GPT-4o、Claude-3.5-Haiku等强大的私有基线和RoVRM、VisualPRM等开源顶尖模型。

**结论:** EQA-RM作为一种针对EQA任务特别设计的奖励模型，不仅提供了更细致且可解释性强的反馈机制，还在有限的数据下表现出了卓越性能，这表明它在推动大模型对齐方面具有潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EQA-RM%3A+A+Generative+Embodied+Reward+Model+with+Test-time+Scaling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10389，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10389&send_immediately=true&force_search=false)

**原文摘要:** Reward Models (RMs), vital for large model alignment, are underexplored for
complex embodied tasks like Embodied Question Answering (EQA) where nuanced
evaluation of agents' spatial, temporal, and logical understanding is critical
yet not considered by generic approaches. We introduce EQA-RM, a novel
generative multimodal reward model specifically architected for EQA, trained
via our innovative Contrastive Group Relative Policy Optimization (C-GRPO)
strategy to learn fine-grained behavioral distinctions. The generative nature
of EQA-RM provides interpretable, structured reward feedback (beyond simple
scalars), uniquely enabling test-time scaling to dynamically adjust evaluation
granularity, from concise scores to detailed critiques of reasoning and
grounding, at inference without retraining. Concurrently, we introduce
EQARewardBench, a new benchmark built on OpenEQA for standardized EQA reward
model assessment. Demonstrating high sample efficiency, EQA-RM (fine-tuning
Qwen2-VL-2B-Instruct) achieves 61.9\% accuracy on EQA-RM-Bench with only 700
samples, outperforming strong proprietary baselines, including
Gemini-2.5-Flash, GPT-4o, Claude-3.5-Haiku, and open-sourced state-of-the-art
models such as RoVRM and VisualPRM. The code and dataset can be found here
https://github.com/UNITES-Lab/EQA-RM.

</details>


### [55] [ConTextTab: A Semantics-Aware Tabular In-Context Learner](https://arxiv.org/abs/2506.10707)
*Marco Spinaci, Marek Polewczyk, Maximilian Schambach, Sam Thelin*

**主要类别:** cs.LG

**AI概要:** ConTextTab结合了表格原生ICL框架与语义理解和对齐，通过使用针对不同数据模态的专门嵌入并在大规模真实世界表格数据上训练，以实现跨多个基准测试的SOTA性能，并在语义丰富的CARTE基准测试中树立新标准。


<details>
  <summary>更多</summary>
  
**动机:** 当前表格原生ICL架构仅在合成数据上训练，未能充分利用真实世界表格数据中的丰富语义和世界知识；而基于预训练大语言模型的表格ICL模型虽然集成了深度语义理解，但由于架构限制只能利用少量上下文。为了结合两者的优点，提出了ConTextTab。

**方法:** ConTextTab整合了语义理解和对齐到一个表格原生ICL框架中，它为不同的数据模态使用专门的嵌入，并且在大规模的真实世界表格数据上进行训练。

**结果:** ConTextTab在一系列广泛的基准测试中表现出了竞争力，并且在语义丰富的CARTE基准测试中设定了新的标准。

**结论:** ConTextTab成功地结合了表格原生ICL的优点和语义理解能力，在保持高效的同时提升了模型处理真实世界数据的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ConTextTab%3A+A+Semantics-Aware+Tabular+In-Context+Learner，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10707，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10707&send_immediately=true&force_search=false)

**原文摘要:** Tabular in-context learning (ICL) has recently achieved state-of-the-art
(SOTA) performance on several tabular prediction tasks. Previously restricted
to classification problems on small tables, recent advances such as TabPFN and
TabICL have extended its use to larger datasets. While being architecturally
efficient and well-adapted to tabular data structures, current table-native ICL
architectures, being trained exclusively on synthetic data, do not fully
leverage the rich semantics and world knowledge contained in real-world tabular
data. On another end of this spectrum, tabular ICL models based on pretrained
large language models such as TabuLa-8B integrate deep semantic understanding
and world knowledge but are only able to make use of a small amount of context
due to inherent architectural limitations. With the aim to combine the best of
both these worlds, we introduce ConTextTab, integrating semantic understanding
and alignment into a table-native ICL framework. By employing specialized
embeddings for different data modalities and by training on large-scale
real-world tabular data, our model is competitive with SOTA across a broad set
of benchmarks while setting a new standard on the semantically rich CARTE
benchmark.

</details>


### [56] [Efficiency Robustness of Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.10831)
*Ravishka Rathnasuriya, Tingxi Li, Zexin Xu, Zihe Song, Mirazul Haque, Simin Chen, Wei Yang*

**主要类别:** cs.LG

**AI概要:** 本文系统地探讨了动态深度学习系统的效率鲁棒性，提出了效率攻击的全面分类，并分析了针对这些系统效率的对抗策略以及现有防御机制的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 随着动态深度学习系统（DDLSs）在实时应用中的部署日益增多，尤其是资源受限环境如移动和物联网设备中，为了应对效率挑战，DDLSs根据输入复杂度调整推理计算来减少开销。然而这种动态行为带来了新的攻击面，特别是效率对抗攻击利用这些动态机制来降低系统性能。因此，研究DDLSs的效率鲁棒性和安全问题变得十分重要。

**方法:** 文章首先对效率攻击进行了综合分类，基于三种动态行为：每推理的动态计算攻击、动态推理迭代攻击以及下游任务的动态输出生成攻击。接着通过深入评估，分析了针对DDLSs效率的对抗策略，并识别出保护这些系统的关键挑战。此外，还研究了现有的防御机制，展示了它们面对越来越流行的效率攻击时的局限性。

**结果:** 研究发现，目前的防御机制不足以抵御日益增长的效率攻击，这表明需要开发新的缓解策略以确保未来自适应DDLSs的安全。

**结论:** 本研究表明，虽然动态深度学习系统提供了一种有效的方法来提高效率，但它们也引入了新的安全风险。为了解决这些问题，必须进一步研究和发展新的缓解措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficiency+Robustness+of+Dynamic+Deep+Learning+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10831，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10831&send_immediately=true&force_search=false)

**原文摘要:** Deep Learning Systems (DLSs) are increasingly deployed in real-time
applications, including those in resourceconstrained environments such as
mobile and IoT devices. To address efficiency challenges, Dynamic Deep Learning
Systems (DDLSs) adapt inference computation based on input complexity, reducing
overhead. While this dynamic behavior improves efficiency, such behavior
introduces new attack surfaces. In particular, efficiency adversarial attacks
exploit these dynamic mechanisms to degrade system performance. This paper
systematically explores efficiency robustness of DDLSs, presenting the first
comprehensive taxonomy of efficiency attacks. We categorize these attacks based
on three dynamic behaviors: (i) attacks on dynamic computations per inference,
(ii) attacks on dynamic inference iterations, and (iii) attacks on dynamic
output production for downstream tasks. Through an in-depth evaluation, we
analyze adversarial strategies that target DDLSs efficiency and identify key
challenges in securing these systems. In addition, we investigate existing
defense mechanisms, demonstrating their limitations against increasingly
popular efficiency attacks and the necessity for novel mitigation strategies to
secure future adaptive DDLSs.

</details>


### [57] [Generative Algorithms for Wildfire Progression Reconstruction from Multi-Modal Satellite Active Fire Measurements and Terrain Height](https://arxiv.org/abs/2506.10404)
*Bryan Shaddy, Brianna Binder, Agnimitra Dasgupta, Haitong Qin, James Haley, Angel Farguell, Kyle Hilburn, Derek V. Mallia, Adam Kochanski, Jan Mandel, Assad Oberai*

**主要类别:** cs.LG

**AI概要:** 本研究开发了一种基于VIIRS活动火点测量、GOES衍生的点火时间和地形高度数据来估计火灾进展的方法，并通过条件生成对抗网络训练，以将WRF-SFIRE物理特性融入估算中。该方法在五个太平洋美国野火上得到验证，平均Sorensen-Dice系数为0.81。


<details>
  <summary>更多</summary>
  
**动机:** 随着野火发生频率的增加，对野火蔓延预测的兴趣也在增长。然而，即使是最复杂的野火模型，在多日模拟过程中也与实际观察到的进展有所偏离，这促使了数据同化的需求。

**方法:** 研究人员开发了一种方法，使用VIIRS活动火点测量、GOES衍生的点火时间以及地形高度数据来估计火灾进程。他们采用了一个条件生成对抗网络（cGAN），并用WRF-SFIRE大气-野火模型的历史野火模拟进行训练，从而允许将WRF-SFIRE的物理特性纳入估计中。

**结果:** 该方法在五个位于太平洋沿岸的美国野火案例中进行了验证，其结果与高分辨率的空中测量边界相比，平均Sorensen-Dice系数达到了0.81。此外，还评估了地形高度对到达时间推断的影响，并观察到当推断条件是基于卫星测量时，地形影响很小。

**结论:** 研究表明，所提出的方法能够有效地利用卫星数据和地形信息来估计火灾蔓延情况，并且在多个野火案例中得到了有效的验证。这种方法为野火蔓延预测提供了新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generative+Algorithms+for+Wildfire+Progression+Reconstruction+from+Multi-Modal+Satellite+Active+Fire+Measurements+and+Terrain+Height，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10404，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10404&send_immediately=true&force_search=false)

**原文摘要:** Increasing wildfire occurrence has spurred growing interest in wildfire
spread prediction. However, even the most complex wildfire models diverge from
observed progression during multi-day simulations, motivating need for data
assimilation. A useful approach to assimilating measurement data into complex
coupled atmosphere-wildfire models is to estimate wildfire progression from
measurements and use this progression to develop a matching atmospheric state.
In this study, an approach is developed for estimating fire progression from
VIIRS active fire measurements, GOES-derived ignition times, and terrain height
data. A conditional Generative Adversarial Network is trained with simulations
of historic wildfires from the atmosphere-wildfire model WRF-SFIRE, thus
allowing incorporation of WRF-SFIRE physics into estimates. Fire progression is
succinctly represented by fire arrival time, and measurements for training are
obtained by applying an approximate observation operator to WRF-SFIRE
solutions, eliminating need for satellite data during training. The model is
trained on tuples of fire arrival times, measurements, and terrain, and once
trained leverages measurements of real fires and corresponding terrain data to
generate samples of fire arrival times. The approach is validated on five
Pacific US wildfires, with results compared against high-resolution perimeters
measured via aircraft, finding an average Sorensen-Dice coefficient of 0.81.
The influence of terrain height on the arrival time inference is also evaluated
and it is observed that terrain has minimal influence when the inference is
conditioned on satellite measurements.

</details>


### [58] [The Diffusion Duality](https://arxiv.org/abs/2506.10892)
*Subham Sekhar Sahoo, Justin Deschenaux, Aaron Gokaslan, Guanghan Wang, Justin Chiu, Volodymyr Kuleshov*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Duo的方法，通过借鉴高斯扩散过程的技术来改进均匀状态离散扩散模型的训练和采样效率。


<details>
  <summary>更多</summary>
  
**动机:** 虽然均匀状态离散扩散模型具有自我纠正的能力，有利于快速文本生成，但其表现通常不如自回归模型和掩码扩散模型。

**方法:** Duo方法包括两个主要部分：基于高斯过程引导的课程学习策略以及适用于离散设置的一致性蒸馏算法。

**结果:** 采用课程学习策略后，在7个基准测试中的3个上，训练速度加倍且在零样本困惑度方面超越了自回归模型；一致性蒸馏算法则将采样加速了两个数量级，并解锁了少步生成能力。

**结论:** 本研究通过引入Duo方法缩小了均匀状态离散扩散模型与自回归模型之间的性能差距，并显著提升了训练和采样的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Diffusion+Duality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10892，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10892&send_immediately=true&force_search=false)

**原文摘要:** Uniform-state discrete diffusion models hold the promise of fast text
generation due to their inherent ability to self-correct. However, they are
typically outperformed by autoregressive models and masked diffusion models. In
this work, we narrow this performance gap by leveraging a key insight:
Uniform-state diffusion processes naturally emerge from an underlying Gaussian
diffusion. Our method, Duo, transfers powerful techniques from Gaussian
diffusion to improve both training and sampling. First, we introduce a
curriculum learning strategy guided by the Gaussian process, doubling training
speed by reducing variance. Models trained with curriculum learning surpass
autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we
present Discrete Consistency Distillation, which adapts consistency
distillation from the continuous to the discrete setting. This algorithm
unlocks few-step generation in diffusion language models by accelerating
sampling by two orders of magnitude. We provide the code and model checkpoints
on the project page: http://s-sahoo.github.io/duo

</details>


### [59] [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org/abs/2506.10922)
*Adam Karvonen, Samuel Marks*

**主要类别:** cs.LG

**AI概要:** 研究发现，当引入现实背景细节时，简单的反偏见提示无法消除大型语言模型在高风险招聘应用中的性别和种族偏见。通过识别并中和模型激活内的敏感属性方向，可以实现所有测试场景下的稳健偏见减少。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前的研究表明简单的反偏见提示可以在受控评估中消除人口统计学偏见，但当引入现实背景细节时，这些缓解措施却失败了。本研究旨在解决这一问题，并提出了内部偏见缓解策略以确保公平的结果。

**方法:** 研究者采用了一种内部偏见缓解方法，即通过识别并中和模型激活过程中的敏感属性方向来实现偏见减少。此外，他们还使用了仿射概念编辑技术，在推理过程中针对种族和性别相关方向进行干预。

**结果:** 研究结果表明，所提出的内部偏见缓解方法能够显著降低测试的所有模型和情景中的偏见水平（通常低于1%，总是低于2.5%），同时保持模型性能。该方法即使是在使用简单合成数据集提供的方向时也表现出色。

**结论:** 为了确保大型语言模型在招聘应用中的公平性，实践者应当采取更为真实的评估方法论，并考虑实施内部偏见缓解策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robustly+Improving+LLM+Fairness+in+Realistic+Settings+via+Interpretability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10922，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10922&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly deployed in high-stakes hiring
applications, making decisions that directly impact people's careers and
livelihoods. While prior studies suggest simple anti-bias prompts can eliminate
demographic biases in controlled evaluations, we find these mitigations fail
when realistic contextual details are introduced. We address these failures
through internal bias mitigation: by identifying and neutralizing sensitive
attribute directions within model activations, we achieve robust bias reduction
across all tested scenarios. Across leading commercial (GPT-4o, Claude 4
Sonnet, Gemini 2.5 Flash) and open-source models (Gemma-2 27B, Gemma-3,
Mistral-24B), we find that adding realistic context such as company names,
culture descriptions from public careers pages, and selective hiring
constraints (e.g.,``only accept candidates in the top 10\%") induces
significant racial and gender biases (up to 12\% differences in interview
rates). When these biases emerge, they consistently favor Black over White
candidates and female over male candidates across all tested models and
scenarios. Moreover, models can infer demographics and become biased from
subtle cues like college affiliations, with these biases remaining invisible
even when inspecting the model's chain-of-thought reasoning. To address these
limitations, our internal bias mitigation identifies race and gender-correlated
directions and applies affine concept editing at inference time. Despite using
directions from a simple synthetic dataset, the intervention generalizes
robustly, consistently reducing bias to very low levels (typically under 1\%,
always below 2.5\%) while largely maintaining model performance. Our findings
suggest that practitioners deploying LLMs for hiring should adopt more
realistic evaluation methodologies and consider internal mitigation strategies
for equitable outcomes.

</details>


### [60] [Data-Driven Soil Organic Carbon Sampling: Integrating Spectral Clustering with Conditioned Latin Hypercube Optimization](https://arxiv.org/abs/2506.10419)
*Weiying Zhao, Aleksei Unagaev, Natalia Efremova*

**主要类别:** cs.LG

**AI概要:** 提出了一种结合谱聚类和条件拉丁超立方体采样(cLHS)的新混合方法，以提高土壤有机碳(SOC)采样的代表性。该方法通过多变量协变量数据将研究区域划分为K个同质区域，并在每个区域内应用cLHS来选择能够捕捉环境条件多样性的采样位置。实验证明该方法比标准cLHS提供了更均匀的协变量特征空间和空间异质性覆盖。


<details>
  <summary>更多</summary>
  
**动机:** 土壤有机碳监测依赖于基于环境协变量选择具有代表性的野外采样位置。传统cLHS方法可能忽略一些重要但面积较小的环境集群。

**方法:** 使用谱聚类将研究区划分为多个同质区域，然后在每个区域内采用条件拉丁超立方体抽样(cLHS)选取样本点。

**结果:** 与传统的cLHS相比，所提出的谱-CLHS方法在协变量特征空间和空间异质性上提供了更好的覆盖率。

**结论:** 这种改进的采样设计可以通过为机器学习模型提供更均衡的训练数据来提高SOC预测的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Driven+Soil+Organic+Carbon+Sampling%3A+Integrating+Spectral+Clustering+with+Conditioned+Latin+Hypercube+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10419&send_immediately=true&force_search=false)

**原文摘要:** Soil organic carbon (SOC) monitoring often relies on selecting representative
field sampling locations based on environmental covariates. We propose a novel
hybrid methodology that integrates spectral clustering - an unsupervised
machine learning technique with conditioned Latin hypercube sampling (cLHS) to
enhance the representativeness of SOC sampling. In our approach, spectral
clustering partitions the study area into $K$ homogeneous zones using
multivariate covariate data, and cLHS is then applied within each zone to
select sampling locations that collectively capture the full diversity of
environmental conditions. This hybrid spectral-cLHS method ensures that even
minor but important environmental clusters are sampled, addressing a key
limitation of vanilla cLHS which can overlook such areas. We demonstrate on a
real SOC mapping dataset that spectral-cLHS provides more uniform coverage of
covariate feature space and spatial heterogeneity than standard cLHS. This
improved sampling design has the potential to yield more accurate SOC
predictions by providing better-balanced training data for machine learning
models.

</details>


### [61] [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946)
*Evelyn Ma, Duo Zhou, Peizhi Niu, Huiting Zhou, Huan Zhang, Olgica Milenkovic, S. Rasoul Etesami*

**主要类别:** cs.LG

**AI概要:** 本文提出了GUARD框架，这是一种用于大型语言模型（LLMs）的新型数据归因方法，旨在解决在删除特定数据时避免非故意遗忘的问题。通过自适应地重新分配遗忘权重，GUARD能够减少对有价值信息的意外损失，并在多个LLM架构上进行了实验验证其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 随着监管合规、版权保护和隐私问题变得越来越重要，大型语言模型中的遗忘变得至关重要。然而，现有方法通常会导致高影响力数据被遗忘时保留性能下降。为了解决这个问题，需要一种新的方法来指导遗忘过程同时保持模型的有用性。

**方法:** GUARD框架引入了一种轻量级的数据归因指标，专为LLM遗忘设计，用以量化“遗忘”集与“保留”集之间的“一致性”。基于这个指标，研究者们设计了一个新的遗忘目标函数，该函数根据样本的数据归因分数反比地分配自适应的、非均匀的遗忘权重。

**结果:** 通过理论保证和TOFU基准测试上的大量实验表明，GUARD显著提高了保真度，同时保持了与先前方法相当的遗忘指标。特别地，在遗忘10%训练数据的情况下，GUARD将保留集上的实用性牺牲减少了高达194.92%。

**结论:** GUARD框架提供了一种有效的方法来提高大型语言模型在执行数据遗忘时的信息保留能力，从而解决了非故意遗忘的问题。它通过自适应地调整遗忘权重，确保了实用性的保存，同时也有效地实现了数据遗忘。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUARD%3A+Guided+Unlearning+and+Retention+via+Data+Attribution+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10946，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10946&send_immediately=true&force_search=false)

**原文摘要:** Unlearning in large language models (LLMs) is becoming increasingly important
due to regulatory compliance, copyright protection, and privacy concerns.
However, a key challenge in LLM unlearning is unintended forgetting, where the
removal of specific data inadvertently impairs the utility of the model and its
retention of valuable, desired information. While prior work has primarily
focused on architectural innovations, the influence of data-level factors on
unlearning performance remains underexplored. As a result, existing methods
often suffer from degraded retention when forgetting high-impact data. To
address this, we propose GUARD-a novel framework for Guided Unlearning And
Retention via Data attribution. At its core, GUARD introduces a lightweight
proxy data attribution metric tailored for LLM unlearning, which quantifies the
"alignment" between the forget and retain sets while remaining computationally
efficient. Building on this, we design a novel unlearning objective that
assigns adaptive, nonuniform unlearning weights to samples, inversely
proportional to their proxy attribution scores. Through such a reallocation of
unlearning power, GUARD mitigates unintended losses in retention. We provide
rigorous theoretical guarantees that GUARD significantly enhances retention
while maintaining forgetting metrics comparable to prior methods. Extensive
experiments on the TOFU benchmark across multiple LLM architectures demonstrate
that GUARD substantially improves utility preservation while ensuring effective
unlearning. Notably, GUARD reduces utility sacrifice on the Retain Set by up to
194.92% in terms of Truth Ratio when forgetting 10% of the training data.

</details>


### [62] [System Identification Using Kolmogorov-Arnold Networks: A Case Study on Buck Converters](https://arxiv.org/abs/2506.10434)
*Nart Gashi, Panagiotis Kakosimos, George Papafotiou*

**主要类别:** cs.LG

**AI概要:** 本文研究了Kolmogorov-Arnold网络（KANs）在建模和分析降压转换器系统动态中的应用，通过仿真数据近似状态导数、构建可解释的状态空间表示，并通过数值实验验证模型。结果表明KANs能够准确地识别系统动态、验证模型一致性并检测参数变化，为现代工业系统的系统识别提供了有价值的见解。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高动态系统中系统识别的可解释性和效率，本文探索了Kolmogorov-Arnold网络（KANs）作为一种强大的框架来实现这一目标。

**方法:** 本文的方法包括使用KANs近似降压转换器系统状态导数，创建可解释的状态空间表示，并通过数值实验对这些模型进行验证。

**结果:** 结果显示KANs可以准确地识别出系统动态，确保模型的一致性，并且能够检测到参数的变化，这表明KANs在现代工业系统识别方面具有很好的应用潜力。

**结论:** 结论是KANs不仅提高了系统识别的准确性，还增强了其可解释性，这对于复杂工业系统的建模和分析来说是一个重要的进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是System+Identification+Using+Kolmogorov-Arnold+Networks%3A+A+Case+Study+on+Buck+Converters，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10434，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10434&send_immediately=true&force_search=false)

**原文摘要:** Kolmogorov-Arnold Networks (KANs) are emerging as a powerful framework for
interpretable and efficient system identification in dynamic systems. By
leveraging the Kolmogorov-Arnold representation theorem, KANs enable function
approximation through learnable activation functions, offering improved
scalability, accuracy, and interpretability compared to traditional neural
networks. This paper investigates the application of KANs to model and analyze
the dynamics of a buck converter system, focusing on state-space parameter
estimation along with discovering the system equations. Using simulation data,
the methodology involves approximating state derivatives with KANs,
constructing interpretable state-space representations, and validating these
models through numerical experiments. The results demonstrate the ability of
KANs to accurately identify system dynamics, verify model consistency, and
detect parameter changes, providing valuable insights into their applicability
for system identification in modern industrial systems.

</details>


### [63] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
*Aayush Karan, Kulin Shah, Sitan Chen*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReGuidance%3A+A+Simple+Diffusion+Wrapper+for+Boosting+Sample+Quality+on+Hard+Inverse+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10955，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10955&send_immediately=true&force_search=false)

**原文摘要:** There has been a flurry of activity around using pretrained diffusion models
as informed data priors for solving inverse problems, and more generally around
steering these models using reward models. Training-free methods like diffusion
posterior sampling (DPS) and its many variants have offered flexible heuristic
algorithms for these tasks, but when the reward is not informative enough,
e.g., in hard inverse problems with low signal-to-noise ratio, these techniques
veer off the data manifold, failing to produce realistic outputs. In this work,
we devise a simple wrapper, ReGuidance, for boosting both the sample realism
and reward achieved by these methods. Given a candidate solution $\hat{x}$
produced by an algorithm of the user's choice, we propose inverting the
solution by running the unconditional probability flow ODE in reverse starting
from $\hat{x}$, and then using the resulting latent as an initialization for
DPS. We evaluate our wrapper on hard inverse problems like large box
in-painting and super-resolution with high upscaling. Whereas state-of-the-art
baselines visibly fail, we find that applying our wrapper on top of these
baselines significantly boosts sample quality and measurement consistency. We
complement these findings with theory proving that on certain multimodal data
distributions, ReGuidance simultaneously boosts the reward and brings the
candidate solution closer to the data manifold. To our knowledge, this
constitutes the first rigorous algorithmic guarantee for DPS.

</details>


### [64] [MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices](https://arxiv.org/abs/2506.10443)
*Zhaode Wang, Jingbang Yang, Xinyu Qian, Shiwen Xing, Xiaotang Jiang, Chengfei Lv, Shengyu Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为MNN-LLM的框架，它通过模型量化和DRAM-Flash混合存储解决了大型语言模型在移动端部署时内存使用问题，并通过一系列优化策略提升了推理速度，相比于当前主流框架，性能提高了8.6倍。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型虽然表现出色，但在推理过程中消耗大量计算资源，导致成本高昂。边缘设备上的推理提供了一个有前景的解决方案，但面临内存使用和推理速度的挑战。

**方法:** MNN-LLM框架利用了模型量化以及DRAM-Flash混合存储来降低内存占用，并且根据移动CPU指令集和GPU特性重新安排权重和输入数据。此外，该框架采用了多核负载均衡、混合精度浮点运算和几何计算等策略来提高性能。

**结果:** MNN-LLM相比现有主流针对大型语言模型设计的框架，在推理速度上实现了最高达8.6倍的提升。

**结论:** MNN-LLM为大型语言模型在移动设备上的高效部署提供了解决方案，通过特定的技术手段有效降低了内存需求并显著提高了推理速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MNN-LLM%3A+A+Generic+Inference+Engine+for+Fast+Large+Language+Model+Deployment+on+Mobile+Devices，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10443，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10443&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have demonstrated exceptional performance across
a variety of tasks. However, their substantial scale leads to significant
computational resource consumption during inference, resulting in high costs.
Consequently, edge device inference presents a promising solution. The primary
challenges of edge inference include memory usage and inference speed. This
paper introduces MNN-LLM, a framework specifically designed to accelerate the
deployment of large language models on mobile devices. MNN-LLM addresses the
runtime characteristics of LLMs through model quantization and DRAM-Flash
hybrid storage, effectively reducing memory usage. It rearranges weights and
inputs based on mobile CPU instruction sets and GPU characteristics while
employing strategies such as multicore load balancing, mixed-precision
floating-point operations, and geometric computations to enhance performance.
Notably, MNN-LLM achieves up to a 8.6x speed increase compared to current
mainstream LLM-specific frameworks.

</details>


### [65] [Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods](https://arxiv.org/abs/2506.10959)
*Zhaiming Shen, Alexander Hsu, Rongjie Lai, Wenjing Liao*

**主要类别:** cs.LG

**AI概要:** 本文首次对流形上Hölder函数的回归进行了在上下文学习（ICL）的理论研究，通过建立注意力机制与经典核方法之间的新联系，得出了关于提示长度和训练任务数量的一般化误差界。


<details>
  <summary>更多</summary>
  
**动机:** 尽管在自然语言和视觉领域中，在上下文学习（ICL）已经取得了显著的成功，但其理论理解特别是在结构化几何数据方面的理解仍未被探索。

**方法:** 文章通过对注意力机制和经典核方法之间建立新的关联来推导出一般化误差边界，并且分析了当观察到足够多的训练任务时，转换器如何导致流形上Hölder函数的最小最大回归率。

**结果:** 研究表明，当有足够多的训练任务时，转换器产生的Hölder函数在流形上的最小最大回归率是按流形的内在维度而非环境空间维度呈指数级增长的。同时结果也表明了一般化错误是如何随着训练任务数量的变化而变化的。

**结论:** 研究提供了对于几何学在ICL中的作用的基本见解，以及研究非线性模型ICL的新工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+In-Context+Learning+on+Structured+Manifolds%3A+Bridging+Attention+to+Kernel+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10959，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10959&send_immediately=true&force_search=false)

**原文摘要:** While in-context learning (ICL) has achieved remarkable success in natural
language and vision domains, its theoretical understanding--particularly in the
context of structured geometric data--remains unexplored. In this work, we
initiate a theoretical study of ICL for regression of H\"older functions on
manifolds. By establishing a novel connection between the attention mechanism
and classical kernel methods, we derive generalization error bounds in terms of
the prompt length and the number of training tasks. When a sufficient number of
training tasks are observed, transformers give rise to the minimax regression
rate of H\"older functions on manifolds, which scales exponentially with the
intrinsic dimension of the manifold, rather than the ambient space dimension.
Our result also characterizes how the generalization error scales with the
number of training tasks, shedding light on the complexity of transformers as
in-context algorithm learners. Our findings provide foundational insights into
the role of geometry in ICL and novels tools to study ICL of nonlinear models.

</details>


### [66] [Equivariant Neural Diffusion for Molecule Generation](https://arxiv.org/abs/2506.10532)
*François Cornet, Grigory Bartosh, Mikkel N. Schmidt, Christian A. Naesseth*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Equivariant Neural Diffusion (END)，一种对欧几里得变换具有等变性的3D分子生成扩散模型，通过可学习的前向过程提高了生成建模能力，并在标准分子生成基准测试中表现出与多个强大基线相比有竞争力的表现。


<details>
  <summary>更多</summary>
  
**动机:** 为了改进现有的等变扩散模型，提高三维分子生成的质量和灵活性，特别是对于无条件和有条件生成任务。

**方法:** 提出了一种名为Equivariant Neural Diffuction (END) 的新方法，该方法通过一个依赖时间和数据的可学习转换来参数化前向过程，这种转换对于刚性变换是等变的。

**结果:** END在一系列标准分子生成基准测试中被证明与几个强大的基线相比具有竞争性的表现。

**结论:** Equivariant Neural Diffusion (END) 作为一种新的扩散模型，它对欧几里得变换具有等变性，并且通过可学习的前向过程增强了生成建模能力，在分子生成任务上展示了良好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Neural+Diffusion+for+Molecule+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10532，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10532&send_immediately=true&force_search=false)

**原文摘要:** We introduce Equivariant Neural Diffusion (END), a novel diffusion model for
molecule generation in 3D that is equivariant to Euclidean transformations.
Compared to current state-of-the-art equivariant diffusion models, the key
innovation in END lies in its learnable forward process for enhanced generative
modelling. Rather than pre-specified, the forward process is parameterized
through a time- and data-dependent transformation that is equivariant to rigid
transformations. Through a series of experiments on standard molecule
generation benchmarks, we demonstrate the competitive performance of END
compared to several strong baselines for both unconditional and conditional
generation.

</details>


### [67] [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org/abs/2506.10972)
*Houyi Li, Wenzhen Zheng, Qiufeng Wang, Zhenyu Ding, Haoying Wang, Zili Wang, Shijie Xuyang, Ning Ding, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的扩展法则Farseer，用于提高大型语言模型训练过程中的预测准确性，并通过大规模实验验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 由于训练大型语言模型成本高昂，导致小规模实验得到的见解往往无法直接应用于实际生产系统中，这阻碍了创新效率。为了解决这个问题，研究者们开发了Farseer，一个能够跨越不同规模提供更准确预测的新方法。

**方法:** 通过构建一个模型损失面L(N, D)，Farseer相比之前的法则（如Chinchilla定律）能够更好地拟合实证数据。该方法经过约1000个跨不同规模和配置的语言模型的大规模测试，消耗大约3百万NVIDIA H100 GPU小时来验证其有效性。

**结果:** Farseer在预测能力上表现出色，特别是在外推性能方面比Chinchilla定律提高了433%。此外，它还提供了关于最佳计算资源分配的新见解，更加符合现代大型语言模型训练的需求。

**结论:** Farseer是一个强大而通用的工具，可以可靠地评估各种训练策略的表现，并且能够让小型消融研究的结果被自信地推广到预测大规模性能。所有相关资料已经开源，以促进进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Farseer%3A+A+Refined+Scaling+Law+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10972，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10972&send_immediately=true&force_search=false)

**原文摘要:** Training Large Language Models (LLMs) is prohibitively expensive, creating a
critical scaling gap where insights from small-scale experiments often fail to
transfer to resource-intensive production systems, thereby hindering efficient
innovation. To bridge this, we introduce Farseer, a novel and refined scaling
law offering enhanced predictive accuracy across scales. By systematically
constructing a model loss surface $L(N,D)$, Farseer achieves a significantly
better fit to empirical data than prior laws (e.g., Chinchilla's law). Our
methodology yields accurate, robust, and highly generalizable predictions,
demonstrating excellent extrapolation capabilities, improving upon Chinchilla's
law by reducing extrapolation error by 433\%. This allows for the reliable
evaluation of competing training strategies across all $(N,D)$ settings,
enabling conclusions from small-scale ablation studies to be confidently
extrapolated to predict large-scale performance. Furthermore, Farseer provides
new insights into optimal compute allocation, better reflecting the nuanced
demands of modern LLM training. To validate our approach, we trained an
extensive suite of approximately 1,000 LLMs across diverse scales and
configurations, consuming roughly 3 million NVIDIA H100 GPU hours. We are
comprehensively open-sourcing all models, data, results, and logs at
https://github.com/Farseer-Scaling-Law/Farseer to foster further research.

</details>


### [68] [Data-driven Day Ahead Market Prices Forecasting: A Focus on Short Training Set Windows](https://arxiv.org/abs/2506.10536)
*Vasilis Michalakopoulos, Christoforos Menos-Aikateriniadis, Elissaios Sarmas, Antonis Zakynthinos, Pavlos S. Georgilakis, Dimitris Askounis*

**主要类别:** cs.LG

**AI概要:** 研究了使用短历史训练窗口的机器学习模型在预测电力日前市场价格、检测季节性趋势和价格峰值方面的性能。LightGBM在不同训练窗口长度下表现出最高的预测准确性和鲁棒性，特别是在45天和60天的窗口期，并且在识别季节效应和峰值价格事件方面优于LSTM和其他增强模型。


<details>
  <summary>更多</summary>
  
**动机:** 本研究旨在评估机器学习模型在利用较短的历史数据窗口来预测电力日前市场(DAM)的价格时的表现，特别关注于检测季节性趋势和价格突增的能力。

**方法:** 研究中采用了四种不同的机器学习模型：带前馈误差校正(FFEC)的LSTM、XGBoost、LightGBM和CatBoost，在三个欧洲能源市场（希腊、比利时、爱尔兰）上进行了测试。特征集来自ENTSO-E预测数据，训练窗口长度从7到90天不等。

**结果:** 结果表明，LightGBM在所有测试条件下都达到了最高的预测精度和稳定性，尤其是当训练窗口为45天和60天时，这平衡了时间相关性和学习深度。此外，与LSTM及其他提升方法相比，LightGBM在识别季节性影响和最高价事件方面表现更优。

**结论:** 研究表明，结合了增强方法的短窗口训练方法能够有效地支持波动较大且数据稀缺环境下的DAM价格预测。特别是LightGBM显示出在不同训练窗口长度下具有较高的准确性以及对于季节性效应和价格峰值事件的更好捕捉能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-driven+Day+Ahead+Market+Prices+Forecasting%3A+A+Focus+on+Short+Training+Set+Windows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10536&send_immediately=true&force_search=false)

**原文摘要:** This study investigates the performance of machine learning models in
forecasting electricity Day-Ahead Market (DAM) prices using short historical
training windows, with a focus on detecting seasonal trends and price spikes.
We evaluate four models, namely LSTM with Feed Forward Error Correction (FFEC),
XGBoost, LightGBM, and CatBoost, across three European energy markets (Greece,
Belgium, Ireland) using feature sets derived from ENTSO-E forecast data.
Training window lengths range from 7 to 90 days, allowing assessment of model
adaptability under constrained data availability. Results indicate that
LightGBM consistently achieves the highest forecasting accuracy and robustness,
particularly with 45 and 60 day training windows, which balance temporal
relevance and learning depth. Furthermore, LightGBM demonstrates superior
detection of seasonal effects and peak price events compared to LSTM and other
boosting models. These findings suggest that short-window training approaches,
combined with boosting methods, can effectively support DAM forecasting in
volatile, data-scarce environments.

</details>


### [69] [Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning](https://arxiv.org/abs/2506.10973)
*Julius Berner, Miguel Liu-Schiaffini, Jean Kossaifi, Valentin Duruisseaux, Boris Bonev, Kamyar Azizzadenesheli, Anima Anandkumar*

**主要类别:** cs.LG

**AI概要:** 本文探讨了神经算子作为将神经网络泛化到函数空间映射的一种方法，并提出了一套原则来将流行的神经架构转化为神经算子，以解决科学问题中无限维函数空间之间的映射。


<details>
  <summary>更多</summary>
  
**动机:** 由于深度学习主要通过计算机视觉和自然语言处理等有限维空间的应用而发展起来，这与科学问题中常遇到的无限维函数空间之间存在本质差异，限制了神经网络在科学应用中的成功。

**方法:** 作者们识别并提炼出构建无限维函数空间之间实际映射实现的关键原则，并基于这些原则提出了将一些流行神经架构转换为神经算子的方法。

**结果:** 提出了一个通用的方法论，可以将多个流行的神经网络架构转变为神经算子，并且提供了实践指南和步骤细节。

**结论:** 论文为实践者提供了一个将传统神经网络转变为适用于科学问题中无限维函数空间映射的神经算子的流程，旨在促进神经算子在解决如偏微分方程等问题上的实际应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Principled+Approaches+for+Extending+Neural+Architectures+to+Function+Spaces+for+Operator+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10973，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10973&send_immediately=true&force_search=false)

**原文摘要:** A wide range of scientific problems, such as those described by
continuous-time dynamical systems and partial differential equations (PDEs),
are naturally formulated on function spaces. While function spaces are
typically infinite-dimensional, deep learning has predominantly advanced
through applications in computer vision and natural language processing that
focus on mappings between finite-dimensional spaces. Such fundamental
disparities in the nature of the data have limited neural networks from
achieving a comparable level of success in scientific applications as seen in
other fields. Neural operators are a principled way to generalize neural
networks to mappings between function spaces, offering a pathway to replicate
deep learning's transformative impact on scientific problems. For instance,
neural operators can learn solution operators for entire classes of PDEs, e.g.,
physical systems with different boundary conditions, coefficient functions, and
geometries. A key factor in deep learning's success has been the careful
engineering of neural architectures through extensive empirical testing.
Translating these neural architectures into neural operators allows operator
learning to enjoy these same empirical optimizations. However, prior neural
operator architectures have often been introduced as standalone models, not
directly derived as extensions of existing neural network architectures. In
this paper, we identify and distill the key principles for constructing
practical implementations of mappings between infinite-dimensional function
spaces. Using these principles, we propose a recipe for converting several
popular neural architectures into neural operators with minimal modifications.
This paper aims to guide practitioners through this process and details the
steps to make neural operators work in practice. Our code can be found at
https://github.com/neuraloperator/NNs-to-NOs

</details>


### [70] [Graph Neural Networks for Automatic Addition of Optimizing Components in Printed Circuit Board Schematics](https://arxiv.org/abs/2506.10577)
*Pascal Plettenberg, André Alcalde, Bernhard Sick, Josephine M. Thomas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于图神经网络的双分图表示方法，用于自动化添加PCB原理图中的新组件，以优化设计。通过对比几种流行的GNN架构在专家标记的真实世界数据集上的表现，证明了该方法能够高效准确地解决PCB设计优化问题。


<details>
  <summary>更多</summary>
  
**动机:** 由于熟练工程师短缺和手动优化耗时，导致最佳实践被忽略，从而增加了后期故障排除的成本、缩短了产品生命周期，并产生了难以回收的电子废物。

**方法:** 将PCB原理图表示为双分图，并利用基于图神经网络（GNNs）的节点对预测模型来自动化添加新的组件。

**结果:** 研究表明，GNNs可以高精度地解决这些问题，并且所提出的方法具有以时间和成本效益方式自动化PCB设计优化的潜力。

**结论:** 本研究展示了一种有效的方法，它使用GNNs来自动添加PCB设计中的必要组件，提高了设计的鲁棒性和可靠性，同时降低了成本和时间消耗。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Neural+Networks+for+Automatic+Addition+of+Optimizing+Components+in+Printed+Circuit+Board+Schematics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10577，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10577&send_immediately=true&force_search=false)

**原文摘要:** The design and optimization of Printed Circuit Board (PCB) schematics is
crucial for the development of high-quality electronic devices. Thereby, an
important task is to optimize drafts by adding components that improve the
robustness and reliability of the circuit, e.g., pull-up resistors or
decoupling capacitors. Since there is a shortage of skilled engineers and
manual optimizations are very time-consuming, these best practices are often
neglected. However, this typically leads to higher costs for troubleshooting in
later development stages as well as shortened product life cycles, resulting in
an increased amount of electronic waste that is difficult to recycle. Here, we
present an approach for automating the addition of new components into PCB
schematics by representing them as bipartite graphs and utilizing a node pair
prediction model based on Graph Neural Networks (GNNs). We apply our approach
to three highly relevant PCB design optimization tasks and compare the
performance of several popular GNN architectures on real-world datasets labeled
by human experts. We show that GNNs can solve these problems with high accuracy
and demonstrate that our approach offers the potential to automate PCB design
optimizations in a time- and cost-efficient manner.

</details>


### [71] [Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability](https://arxiv.org/abs/2506.10616)
*Yu-Jie Zhang, Peng Zhao, Masashi Sugiyama*

**主要类别:** cs.LG

**AI概要:** 本文通过利用混合性概念改进了非平稳在线学习中动态遗憾的最小化，特别是对于具有较强曲率的函数。提出了一种固定份额更新的指数权重方法，实现了对可混合损失的更优动态遗憾界，同时引入了一个简单而强大的分析框架。


<details>
  <summary>更多</summary>
  
**动机:** 现有的动态遗憾最小化研究主要集中在凸函数上，而对于具有更强曲率的函数（如平方或逻辑损失）则研究较少。文章旨在填补这一空白，通过探索混合性的概念来改善此类函数的动态遗憾表现。

**方法:** 采用基于指数权重的方法，并结合固定份额更新策略，以实现对具有混合性质损失函数的动态遗憾优化。此外，引入了一个不依赖于Karush-Kuhn-Tucker条件的新分析框架来评估性能。

**结果:** 展示了所提方法能够达到O(d T^(1/3) P_T^(2/3) log T)的动态遗憾边界，优于先前已知的最佳结果O(d^(10/3) T^(1/3) P_T^(2/3) log T)，特别是在维度d方面有所改进。

**结论:** 通过利用混合性，可以在非平稳环境下有效提高在线学习算法处理强曲率损失函数时的性能。新提出的分析框架不仅简化了证明过程，还为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Non-stationary+Online+Learning+for+Curved+Losses%3A+Improved+Dynamic+Regret+via+Mixability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10616，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10616&send_immediately=true&force_search=false)

**原文摘要:** Non-stationary online learning has drawn much attention in recent years.
Despite considerable progress, dynamic regret minimization has primarily
focused on convex functions, leaving the functions with stronger curvature
(e.g., squared or logistic loss) underexplored. In this work, we address this
gap by showing that the regret can be substantially improved by leveraging the
concept of mixability, a property that generalizes exp-concavity to effectively
capture loss curvature. Let $d$ denote the dimensionality and $P_T$ the path
length of comparators that reflects the environmental non-stationarity. We
demonstrate that an exponential-weight method with fixed-share updates achieves
an $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$ dynamic regret for mixable losses,
improving upon the best-known $\mathcal{O}(d^{10/3} T^{1/3} P_T^{2/3} \log T)$
result (Baby and Wang, 2021) in $d$. More importantly, this improvement arises
from a simple yet powerful analytical framework that exploits the mixability,
which avoids the Karush-Kuhn-Tucker-based analysis required by existing work.

</details>


### [72] [Leveraging Low-rank Factorizations of Conditional Correlation Matrices in Graph Learning](https://arxiv.org/abs/2506.10628)
*Thu Ha Phi, Alexandre Hippert-Ferrer, Florent Bouchard, Arnaud Breloy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于条件相关矩阵低秩分解的图学习框架，以解决从节点收集的数据中学习无向图的问题。通过利用黎曼优化技术，该方法能够有效地处理高维数据，并在合成和真实数据上展示了很好的性能与维度间的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 传统的图学习问题随着变量数量增加而变得难以处理，特别是当涉及大量节点时。为了解决这一挑战，本文旨在开发一种可扩展且高效的算法来学习图结构。

**方法:** 作者提出了一种新的图学习框架，该框架依赖于条件相关矩阵的低秩分解。为了求解由此产生的优化问题，他们开发了特定工具以便应用针对这种结构的黎曼优化技术。此外，还将该方法具体化为GLasso算法的一种低秩约束版本。

**结果:** 实验结果表明，在合成数据集和实际数据集中，所提方法能够在保持良好性能的同时显著减少计算复杂度。这意味着它提供了一个非常有效的维度与性能之间的折衷方案。

**结论:** 通过引入基于低秩分解的方法以及采用黎曼优化技术，本文成功地解决了大规模图学习中的关键难题，展示出其在不同应用场景下的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+Low-rank+Factorizations+of+Conditional+Correlation+Matrices+in+Graph+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10628，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10628&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the problem of learning an undirected graph from data
gathered at each nodes. Within the graph signal processing framework, the
topology of such graph can be linked to the support of the conditional
correlation matrix of the data. The corresponding graph learning problem then
scales to the squares of the number of variables (nodes), which is usually
problematic at large dimension. To tackle this issue, we propose a graph
learning framework that leverages a low-rank factorization of the conditional
correlation matrix. In order to solve for the resulting optimization problems,
we derive tools required to apply Riemannian optimization techniques for this
particular structure. The proposal is then particularized to a low-rank
constrained counterpart of the GLasso algorithm, i.e., the penalized maximum
likelihood estimation of a Gaussian graphical model. Experiments on synthetic
and real data evidence that a very efficient dimension-versus-performance
trade-off can be achieved with this approach.

</details>


### [73] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
*Alexander Lobashev, Dmitry Guskov, Maria Larchenko, Mikhail Tamm*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种通过重构Fisher信息度量来分析生成模型（包括统计物理模型和扩散模型）潜在空间几何的新方法。该方法能够近似给定生成样本的潜在变量的后验分布，并利用它来学习对数配分函数，从而为指数族定义Fisher度量。理论收敛性得到了保证，并且在Ising和TASEP模型上的验证表明，该方法在重建热力学量方面优于现有基准。当应用于扩散模型时，揭示了潜在空间中相变的分形结构特征。


<details>
  <summary>更多</summary>
  
**动机:** 研究者们希望通过分析生成模型的潜在空间几何，以更好地理解这些模型的内在机制，特别是与统计物理模型中的相变现象相关的复杂结构。

**方法:** 本文的方法是基于重构Fisher信息度量，通过近似给定生成样本条件下潜在变量的后验分布，并利用这个分布来学习对数配分函数。这一步骤允许我们对于属于指数族的模型定义出Fisher度量。

**结果:** 该方法在Ising和TASEP模型上成功应用，显示了在重建热力学量方面的优越性能。此外，在扩散模型上使用时，观察到了潜在空间内相变的分形结构以及在相界处线性插值失效的现象。

**结论:** 本研究提供了一种新的手段来探索生成模型潜在空间的复杂结构，特别是在与相变等现象的关系方面。所提出的基于Fisher信息度量的方法不仅理论上有良好的收敛性质，而且实践证明可以有效揭示潜在空间内的有趣结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hessian+Geometry+of+Latent+Space+in+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10632，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10632&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a novel method for analyzing the latent space geometry of
generative models, including statistical physics models and diffusion models,
by reconstructing the Fisher information metric. The method approximates the
posterior distribution of latent variables given generated samples and uses
this to learn the log-partition function, which defines the Fisher metric for
exponential families. Theoretical convergence guarantees are provided, and the
method is validated on the Ising and TASEP models, outperforming existing
baselines in reconstructing thermodynamic quantities. Applied to diffusion
models, the method reveals a fractal structure of phase transitions in the
latent space, characterized by abrupt changes in the Fisher metric. We
demonstrate that while geodesic interpolations are approximately linear within
individual phases, this linearity breaks down at phase boundaries, where the
diffusion model exhibits a divergent Lipschitz constant with respect to the
latent space. These findings provide new insights into the complex structure of
diffusion model latent spaces and their connection to phenomena like phase
transitions. Our source code is available at
https://github.com/alobashev/hessian-geometry-of-diffusion-models.

</details>


### [74] [Preserving Task-Relevant Information Under Linear Concept Removal](https://arxiv.org/abs/2506.10703)
*Floris Holstege, Shauli Ravfogel, Bram Wouters*

**主要类别:** cs.LG

**AI概要:** 我们提出了一种名为SPLICE的方法，该方法可以在消除表示中的敏感概念的同时保持它们与目标标签的协方差，从而最小化对主要任务信息的影响。


<details>
  <summary>更多</summary>
  
**动机:** 现代神经网络经常在编码任务相关信息的同时也编码了不需要的概念，这导致了公平性和可解释性的问题。现有的事后方法可以去除不想要的概念，但通常会降低有用信号的质量。

**方法:** 我们引入了SPLICE（同时投影以实现线性概念移除和协方差保留），它通过一个倾斜投影来消除表示中的敏感概念，同时准确地保持这些概念与目标标签之间的协方差。

**结果:** SPLICE在Bias in Bios和Winobias等基准测试中优于基线，能够在移除受保护属性的同时尽量减少对主任务信息的损害。

**结论:** 从理论上讲，SPLICE是唯一能够去除线性概念预测性并以最小嵌入失真维持目标协方差的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preserving+Task-Relevant+Information+Under+Linear+Concept+Removal，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10703&send_immediately=true&force_search=false)

**原文摘要:** Modern neural networks often encode unwanted concepts alongside task-relevant
information, leading to fairness and interpretability concerns. Existing
post-hoc approaches can remove undesired concepts but often degrade useful
signals. We introduce SPLICE-Simultaneous Projection for LInear concept removal
and Covariance prEservation-which eliminates sensitive concepts from
representations while exactly preserving their covariance with a target label.
SPLICE achieves this via an oblique projection that "splices out" the unwanted
direction yet protects important label correlations. Theoretically, it is the
unique solution that removes linear concept predictability and maintains target
covariance with minimal embedding distortion. Empirically, SPLICE outperforms
baselines on benchmarks such as Bias in Bios and Winobias, removing protected
attributes while minimally damaging main-task information.

</details>


### [75] [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org/abs/2506.10751)
*Sai Prasanna Teja Reddy Bogireddy, Abrar Majeedi, Viswanatha Reddy Gajjala, Zhuoyan Xu, Siddhant Rai, Vaishnav Potlapalli*

**主要类别:** cs.LG

**AI概要:** 本文介绍了在BioNLP 2025 ArchEHR-QA共享任务中获得亚军的Neural系统，该系统通过数据驱动的提示优化来提高临床QA任务中的证据检索和答案生成的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 自动化问答系统能够填补临床医生和患者之间的信息缺口，但需要在有限监督下进行准确的证据检索和忠实的答案生成。

**方法:** 所提出的方法将任务分解为句子级证据识别和带有明确引用的答案合成两个阶段，并使用DSPy的MIPROv2优化器自动探索提示空间，在开发集上联合调整指令和少量样本演示。此外，采用自一致性投票方案以提高证据召回率而不牺牲精确度。

**结果:** 该方法在隐藏测试集上取得了51.5分的整体得分，位居第二，比标准零样本和少量样本提示分别高出20多分和10多分。

**结论:** 结果表明，对于高风险的临床QA而言，数据驱动的提示优化是一种成本效益更高的模型微调替代方案，有助于提高医疗保健领域AI助手的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+at+ArchEHR-QA+2025%3A+Agentic+Prompt+Optimization+for+Evidence-Grounded+Clinical+Question+Answering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10751，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10751&send_immediately=true&force_search=false)

**原文摘要:** Automated question answering (QA) over electronic health records (EHRs) can
bridge critical information gaps for clinicians and patients, yet it demands
both precise evidence retrieval and faithful answer generation under limited
supervision. In this work, we present Neural, the runner-up in the BioNLP 2025
ArchEHR-QA shared task on evidence-grounded clinical QA. Our proposed method
decouples the task into (1) sentence-level evidence identification and (2)
answer synthesis with explicit citations. For each stage, we automatically
explore the prompt space with DSPy's MIPROv2 optimizer, jointly tuning
instructions and few-shot demonstrations on the development set. A
self-consistency voting scheme further improves evidence recall without
sacrificing precision. On the hidden test set, our method attains an overall
score of 51.5, placing second stage while outperforming standard zero-shot and
few-shot prompting by over 20 and 10 points, respectively. These results
indicate that data-driven prompt optimization is a cost-effective alternative
to model fine-tuning for high-stakes clinical QA, advancing the reliability of
AI assistants in healthcare.

</details>


### [76] [Skillful joint probabilistic weather forecasting from marginals](https://arxiv.org/abs/2506.10772)
*Ferran Alet, Ilan Price, Andrew El-Kadi, Dominic Masters, Stratis Markou, Tom R. Andersson, Jacklynn Stott, Remi Lam, Matthew Willson, Alvaro Sanchez-Gonzalez, Peter Battaglia*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为FGN的新型天气预测模型，它通过学习模型扰动生成集成预报，并直接训练以最小化每个位置预报的连续秩概率得分（CRPS）。该模型在一系列确定性和概率性度量中表现出色，能够进行有技巧的热带气旋路径预测，并捕捉到联合空间结构。


<details>
  <summary>更多</summary>
  
**动机:** 由于基于机器学习(ML)的天气模型相比传统的数值天气预报(NWP)，具有更高的准确性和速度，最近在全球概率天气预报方面超过了传统集合预报。因此，作者提出了一个更简单、可扩展且灵活的建模方法FGN，旨在显著超越当前最先进的模型。

**方法:** FGN通过学习适当约束下的模型扰动来生成集成预报，并直接训练这些模型以最小化每个地点预报的连续秩概率得分(CRPS)。

**结果:** FGN产生的集合预报在多种确定性和概率性指标上达到了最先进水平，能够做出技术性的集合热带气旋轨迹预测，并能捕捉到联合的空间结构，尽管它仅基于边际数据进行训练。

**结论:** FGN提供了一种优于现有最先进模型的新方法，它不仅在天气预报的关键性能指标上表现出色，而且还能有效地处理复杂的空间相关性问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Skillful+joint+probabilistic+weather+forecasting+from+marginals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10772&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML)-based weather models have rapidly risen to prominence
due to their greater accuracy and speed than traditional forecasts based on
numerical weather prediction (NWP), recently outperforming traditional
ensembles in global probabilistic weather forecasting. This paper presents FGN,
a simple, scalable and flexible modeling approach which significantly
outperforms the current state-of-the-art models. FGN generates ensembles via
learned model-perturbations with an ensemble of appropriately constrained
models. It is trained directly to minimize the continuous rank probability
score (CRPS) of per-location forecasts. It produces state-of-the-art ensemble
forecasts as measured by a range of deterministic and probabilistic metrics,
makes skillful ensemble tropical cyclone track predictions, and captures joint
spatial structure despite being trained only on marginals.

</details>


### [77] [Monotone Classification with Relative Approximations](https://arxiv.org/abs/2506.10775)
*Yufei Tao*

**主要类别:** cs.LG

**AI概要:** 本文首次研究了寻找一个单调分类器所需要的最小成本，该分类器的误差最多为最优单调分类器误差的$(1 + \epsilon)\cdot k^*$倍。


<details>
  <summary>更多</summary>
  
**动机:** 在单调分类中，目标是找到一个具有尽可能小误差的单调函数$h$作为分类器。之前的工作只能达到比最优误差高出绝对因子的误差，而本研究允许误差超过最优值至多相对因子。

**方法:** 文章提出了几乎匹配的上界和下界，适用于整个$\epsilon$范围。

**结果:** 研究给出了当误差被允许超出最优解最多相对因子时，寻找这样的单调分类器所需的最低成本。

**结论:** 这项工作对不同$\epsilon$值提供了几乎匹配的上下界，这是对于单调分类问题中误差相对于最优解可接受的最大增量的首个研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Monotone+Classification+with+Relative+Approximations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10775，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10775&send_immediately=true&force_search=false)

**原文摘要:** In monotone classification, the input is a multi-set $P$ of points in
$\mathbb{R}^d$, each associated with a hidden label from $\{-1, 1\}$. The goal
is to identify a monotone function $h$, which acts as a classifier, mapping
from $\mathbb{R}^d$ to $\{-1, 1\}$ with a small {\em error}, measured as the
number of points $p \in P$ whose labels differ from the function values $h(p)$.
The cost of an algorithm is defined as the number of points having their labels
revealed. This article presents the first study on the lowest cost required to
find a monotone classifier whose error is at most $(1 + \epsilon) \cdot k^*$
where $\epsilon \ge 0$ and $k^*$ is the minimum error achieved by an optimal
monotone classifier -- in other words, the error is allowed to exceed the
optimal by at most a relative factor. Nearly matching upper and lower bounds
are presented for the full range of $\epsilon$. All previous work on the
problem can only achieve an error higher than the optimal by an absolute
factor.

</details>


### [78] [Dense Associative Memory with Epanechnikov Energy](https://arxiv.org/abs/2506.10801)
*Benjamin Hoover, Zhaoyang Shi, Krishnakumar Balasubramanian, Dmitry Krotov, Parikshit Ram*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的DenseAM网络能量函数——log-sum-ReLU (LSR)，它基于Epanechnikov核，能够在不需要指数分离函数的情况下实现精确的记忆检索和指数级容量，并且在保持完美模式恢复的同时引入了大量额外的局部最小值（记忆）。实验结果表明，与基于LSE的模型相比，LSR能量具有更多具有可比对数似然性的局部最小值。


<details>
  <summary>更多</summary>
  
**动机:** 研究者受到最优核密度估计的启发，旨在开发一种新的能量函数，该函数可以克服现有DenseAM网络中记忆检索需要指数分离函数的问题，并提高记忆存储能力。

**方法:** 提出了基于Epanechnikov核的log-sum-ReLU (LSR) 函数作为DenseAM网络的新能量函数。

**结果:** 实验证明LSR能量函数能产生更多的局部最小值（即记忆），并且这些记忆与基于LSE的模型相比具有相当的对数似然性。此外，LSR还表现出在图像数据集上的创造性和新颖性，暗示其在大规模记忆存储和生成任务中的潜力。

**结论:** log-sum-ReLU (LSR) 能量函数为DenseAM网络提供了一种改进的记忆检索方法，不仅能够支持指数级的记忆容量，而且能够引入许多额外的局部最小值而不影响模式恢复。这表明LSR可能适合用于需要高存储能力和创造力的应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dense+Associative+Memory+with+Epanechnikov+Energy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10801&send_immediately=true&force_search=false)

**原文摘要:** We propose a novel energy function for Dense Associative Memory (DenseAM)
networks, the log-sum-ReLU (LSR), inspired by optimal kernel density
estimation. Unlike the common log-sum-exponential (LSE) function, LSR is based
on the Epanechnikov kernel and enables exact memory retrieval with exponential
capacity without requiring exponential separation functions. Moreover, it
introduces abundant additional \emph{emergent} local minima while preserving
perfect pattern recovery -- a characteristic previously unseen in DenseAM
literature. Empirical results show that LSR energy has significantly more local
minima (memories) that have comparable log-likelihood to LSE-based models.
Analysis of LSR's emergent memories on image datasets reveals a degree of
creativity and novelty, hinting at this method's potential for both large-scale
memory storage and generative tasks.

</details>


### [79] [Detecting High-Stakes Interactions with Activation Probes](https://arxiv.org/abs/2506.10805)
*Alex McKenzie, Urja Pawar, Phil Blandfort, William Bankes, David Krueger, Ekdeep Singh Lubana, Dmitrii Krasheninnikov*

**主要类别:** cs.LG

**AI概要:** 本文研究了用于检测可能造成重大伤害的高风险互动的激活探针，并发现它们在处理多样且分布外的真实数据时表现出稳健的泛化能力。这些探针的表现与经过提示或微调的中型语言模型监控器相当，但计算成本降低了六个数量级。


<details>
  <summary>更多</summary>
  
**动机:** 为了安全地部署大型语言模型（LLMs），监测潜在的高风险互动是一个重要而未充分探索的目标。

**方法:** 通过合成数据训练几种探针架构，并评估其在多样化、非分布内真实世界数据上的表现。

**结果:** 探针架构在处理未知数据时展现出良好的泛化性能，其效能可与提示或微调过的中等规模语言模型监控相媲美，同时提供了巨大的计算资源节省。

**结论:** 研究表明，使用探针作为初步筛选工具可以构建资源意识强的层次化监控系统，以实现更高效的语言模型监管。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+High-Stakes+Interactions+with+Activation+Probes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10805，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10805&send_immediately=true&force_search=false)

**原文摘要:** Monitoring is an important aspect of safely deploying Large Language Models
(LLMs). This paper examines activation probes for detecting "high-stakes"
interactions -- where the text indicates that the interaction might lead to
significant harm -- as a critical, yet underexplored, target for such
monitoring. We evaluate several probe architectures trained on synthetic data,
and find them to exhibit robust generalization to diverse, out-of-distribution,
real-world data. Probes' performance is comparable to that of prompted or
finetuned medium-sized LLM monitors, while offering computational savings of
six orders-of-magnitude. Our experiments also highlight the potential of
building resource-aware hierarchical monitoring systems, where probes serve as
an efficient initial filter and flag cases for more expensive downstream
analysis. We release our novel synthetic dataset and codebase to encourage
further study.

</details>


### [80] [Advanced fraud detection using machine learning models: enhancing financial transaction security](https://arxiv.org/abs/2506.10842)
*Nudrat Fariha, Md Nazmuddin Moin Khan, Md Iqbal Hossain, Syed Ali Reza, Joy Chakra Bortty, Kazi Sharmin Sultana, Md Shadidur Islam Jawad, Saniah Safat, Md Abdul Ahad, Maksuda Begum*

**主要类别:** cs.LG

**AI概要:** 该研究开发了一个端到端的机器学习框架，用于通过真实世界的数据检测信用卡交易异常和欺诈。它结合了多种数据集并进行了特征工程以提取行为信号，并使用无监督模型如Isolation Forest、One Class SVM和深度自动编码器来识别异常。PCA可视化和聚类方法帮助分离出可疑交易区域。


<details>
  <summary>更多</summary>
  
**动机:** 随着数字支付的兴起，对于智能且可扩展的系统来检测欺诈的需求日益增加。

**方法:** 研究中合并了来自关系数据库的交易、持卡人、商户以及商户类别等数据集创建统一分析视图，并通过特征工程过程提取诸如平均支出、与历史模式偏差、交易时间不规则性和类别频率指标等行为信号。这些特征被添加了时间标记，以便揭示所有可能指示欺诈行为的潜在模式。接着，利用交易数据训练和评估了一系列无监督模型：Isolation Forest、单分类SVM以及一个旨在重建正常行为的深度自动编码器。PCA可视化展示了每个模型在二维潜在空间中分离异常的能力。此外，还使用K-Means聚类和DBSCAN进一步细分交易场景，以识别正常的密集活动集群并隔离稀疏的可疑区域。

**结果:** 探索性数据分析揭示了整个数据集特征中的上下文交易趋势。无监督模型能够将前1%的重构错误标记为异常值。PCA可视化显示了每种模型区分正常和异常交易的能力。K-Means聚类和DBSCAN有助于确定正常的密集活动群集和稀疏的可疑区域。

**结论:** 本研究提出的端到端机器学习框架能够有效检测信用卡交易中的异常和欺诈行为，通过特征工程和无监督学习模型的应用，提升了对欺诈行为的识别能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advanced+fraud+detection+using+machine+learning+models%3A+enhancing+financial+transaction+security，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10842，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10842&send_immediately=true&force_search=false)

**原文摘要:** The rise of digital payments has accelerated the need for intelligent and
scalable systems to detect fraud. This research presents an end-to-end,
feature-rich machine learning framework for detecting credit card transaction
anomalies and fraud using real-world data. The study begins by merging
transactional, cardholder, merchant, and merchant category datasets from a
relational database to create a unified analytical view. Through the feature
engineering process, we extract behavioural signals such as average spending,
deviation from historical patterns, transaction timing irregularities, and
category frequency metrics. These features are enriched with temporal markers
such as hour, day of week, and weekend indicators to expose all latent patterns
that indicate fraudulent behaviours. Exploratory data analysis reveals
contextual transaction trends across all the dataset features. Using the
transactional data, we train and evaluate a range of unsupervised models:
Isolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct
normal behavior. These models flag the top 1% of reconstruction errors as
outliers. PCA visualizations illustrate each models ability to separate
anomalies into a two-dimensional latent space. We further segment the
transaction landscape using K-Means clustering and DBSCAN to identify dense
clusters of normal activity and isolate sparse, suspicious regions.

</details>


### [81] [Viability of Future Actions: Robust Safety in Reinforcement Learning via Entropy Regularization](https://arxiv.org/abs/2506.10871)
*Pierre-François Massiani, Alexander von Rohr, Lukas Haverbeck, Sebastian Trimpe*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种通过熵正则化和约束惩罚来实现强化学习中鲁棒安全性的新方法，这种方法能够在保证安全性和最优性的同时提高对干扰的适应能力。


<details>
  <summary>更多</summary>
  
**动机:** 在强化学习领域，尽管有许多最近的进步，但如何在未知干扰下稳健地满足状态约束仍然是一个未解决的问题。

**方法:** 分析了无模型强化学习中两种已建立的技术——熵正则化和约束惩罚之间的相互作用，并展示了熵正则化能够促进满足行动噪声下的约束条件；同时，通过处罚方式放松严格的安全约束，可以将受限的RL问题近似为不受限的问题。

**结果:** 研究结果表明，熵正则化有助于增加未来可行动作的数量，从而增强对于行动噪声的鲁棒性；另外，通过罚分放松安全约束后，可以使用标准无模型RL方法求解该问题，并且保留了安全性和最优性。

**结论:** 熵正率与鲁棒性之间的联系是一个值得进一步实证和理论探讨的方向，因为它可以通过简单的奖励塑形实现强化学习中的鲁棒安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Viability+of+Future+Actions%3A+Robust+Safety+in+Reinforcement+Learning+via+Entropy+Regularization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10871，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10871&send_immediately=true&force_search=false)

**原文摘要:** Despite the many recent advances in reinforcement learning (RL), the question
of learning policies that robustly satisfy state constraints under unknown
disturbances remains open. In this paper, we offer a new perspective on
achieving robust safety by analyzing the interplay between two well-established
techniques in model-free RL: entropy regularization, and constraints
penalization. We reveal empirically that entropy regularization in constrained
RL inherently biases learning toward maximizing the number of future viable
actions, thereby promoting constraints satisfaction robust to action noise.
Furthermore, we show that by relaxing strict safety constraints through
penalties, the constrained RL problem can be approximated arbitrarily closely
by an unconstrained one and thus solved using standard model-free RL. This
reformulation preserves both safety and optimality while empirically improving
resilience to disturbances. Our results indicate that the connection between
entropy regularization and robustness is a promising avenue for further
empirical and theoretical investigation, as it enables robust safety in RL
through simple reward shaping.

</details>


### [82] [Lattice Climber Attack: Adversarial attacks for randomized mixtures of classifiers](https://arxiv.org/abs/2506.10888)
*Lucas Gnecco-Heredia, Benjamin Negrevergne, Yann Chevaleyre*

**主要类别:** cs.LG

**AI概要:** 本文讨论了如何以原则性的方式攻击分类器混合体，并引入了基于问题几何分析的攻击的两个理想属性。现有攻击未能满足这两个属性，因此提出了一种新的晶格攀爬攻击，在二元线性设置下具有理论保证，并通过实验展示了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对抗性攻击并不适用于有限分类器混合（随机集成），作者希望通过研究提出一种更有效的攻击方法来针对这种类型的分类器。

**方法:** 作者首先定义了有效性和最大性作为评估攻击质量的两个重要属性；然后指出已有攻击方式无法同时满足这两个属性；最后提出了一种称为晶格攀爬的新攻击方法，并在二元线性场景下给出了该方法的理论保障。

**结果:** 提出的晶格攀爬攻击在合成数据集和真实数据集中均表现出良好的性能。

**结论:** 新提出的晶格攀爬攻击为对抗有限分类器混合提供了一个更好的解决方案，它不仅满足了所提出的两个理想属性，而且在实际测试中也证实了其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Lattice+Climber+Attack%3A+Adversarial+attacks+for+randomized+mixtures+of+classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10888，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10888&send_immediately=true&force_search=false)

**原文摘要:** Finite mixtures of classifiers (a.k.a. randomized ensembles) have been
proposed as a way to improve robustness against adversarial attacks. However,
existing attacks have been shown to not suit this kind of classifier. In this
paper, we discuss the problem of attacking a mixture in a principled way and
introduce two desirable properties of attacks based on a geometrical analysis
of the problem (effectiveness and maximality). We then show that existing
attacks do not meet both of these properties. Finally, we introduce a new
attack called {\em lattice climber attack} with theoretical guarantees in the
binary linear setting, and demonstrate its performance by conducting
experiments on synthetic and real datasets.

</details>


### [83] [NoLoCo: No-all-reduce Low Communication Training Method for Large Models](https://arxiv.org/abs/2506.10911)
*Jari Kolehmainen, Nikolay Blagoev, John Donaghy, Oğuzhan Ersoy, Christopher Nies*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的优化方法NoLoCo，它在训练过程中不显式地同步所有模型参数，因此不需要任何集体通信。该方法通过一种新颖的Nesterov动量优化器变体来隐式同步模型权重。实验结果表明，NoLoCo相比完全分片数据并行训练或低通信训练方法DiLoCo，在通信开销上显著减少，并且对于不同规模的加速器和模型大小，观察到了最高达4%的更快收敛速度。


<details>
  <summary>更多</summary>
  
**动机:** 当前大规模语言模型的训练通常需要使用包含数万个加速器的集群来进行，这些加速器通过高带宽互连进行通信。然而，扩大这种集群的成本很高，可能变得不切实际，从而限制了可以训练的模型大小。尽管已有研究提出了减少通信需求的训练方法，但它们仍然需要对模型参数进行同步步骤，这在低带宽网络中执行时可能会变得非常昂贵。

**方法:** 研究人员开发了一种名为NoLoCo的新颖优化方法，这种方法在训练期间不会显式地同步所有模型参数，因此不需要任何集体通信。NoLoCo通过部分平均模型权重与随机选取的另一个权重来实现模型权重的隐式同步，这是基于Nesterov动量优化器的一种新变体。

**结果:** 通过广泛的基准测试，NoLoCo在从1.25亿到68亿参数的不同加速器数量和模型大小之间进行了评估。结果显示，与全分片数据并行训练甚至广泛使用的低通信训练方法DiLoCo相比，NoLoCo所需的通信开销明显更少。估计同步步骤本身比DiLoCo所用的all-reduce快一个数量级。此外，没有全局阻塞通信也减少了加速器的空闲时间。

**结论:** 提出的NoLoCo优化方法在减少通信开销方面表现出色，同时保持了良好的收敛速度，这对于在有限网络资源下训练大型语言模型具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NoLoCo%3A+No-all-reduce+Low+Communication+Training+Method+for+Large+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10911，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10911&send_immediately=true&force_search=false)

**原文摘要:** Training large language models is generally done via optimization methods on
clusters containing tens of thousands of accelerators, communicating over a
high-bandwidth interconnect. Scaling up these clusters is expensive and can
become impractical, imposing limits on the size of models that can be trained.
Several recent studies have proposed training methods that are less
communication intensive, avoiding the need for a highly connected compute
cluster. These state-of-the-art low communication training methods still employ
a synchronization step for model parameters, which, when performed over all
model replicas, can become costly on a low-bandwidth network.
  In this work, we propose a novel optimization method, NoLoCo, that does not
explicitly synchronize all model parameters during training and, as a result,
does not require any collective communication. NoLoCo implicitly synchronizes
model weights via a novel variant of the Nesterov momentum optimizer by
partially averaging model weights with a randomly selected other one. We
provide both a theoretical convergence analysis for our proposed optimizer as
well as empirical results from language model training.
  We benchmark NoLoCo on a wide range of accelerator counts and model sizes,
between 125M to 6.8B parameters. Our method requires significantly less
communication overhead than fully sharded data parallel training or even widely
used low communication training method, DiLoCo. The synchronization step itself
is estimated to be one magnitude faster than the all-reduce used in DiLoCo for
few hundred accelerators training over the internet. We also do not have any
global blocking communication that reduces accelerator idling time. Compared to
DiLoCo, we also observe up to $4\%$ faster convergence rate with wide range of
model sizes and accelerator counts.

</details>


### [84] [Foundation Models for Causal Inference via Prior-Data Fitted Networks](https://arxiv.org/abs/2506.10914)
*Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel*

**主要类别:** cs.LG

**AI概要:** 本文提出了CausalFM，一个用于在多种因果推断场景中训练基于PFN的基础模型的综合框架。该框架通过构建贝叶斯先验和使用受因果启发的贝叶斯神经网络来实现贝叶斯因果推断，并且能够估计条件平均处理效应（CATEs）。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望开发一种新的方法，使得基础模型可以在各种因果推断环境中进行训练，并且能够执行贝叶斯因果推断。此外，他们还旨在提供一种通用的方法来训练这些模型，以适应不同领域的应用。

**方法:** 首先，文章正式化了基于结构因果模型（SCMs）的贝叶斯先验构造，并为这种先验的有效性制定了必要标准。接着，提出了一个新的先验分布家族，利用受因果关系启发的贝叶斯神经网络，使CausalFM能够在不同的设定下执行贝叶斯因果推断。最后，实现了CausalFM，并特别训练了一个基础模型，用于通过后门调整估计条件平均治疗效果（CATEs）。

**结果:** 研究结果表明，CausalFM在使用合成和半合成基准数据集进行CATE估计时表现具有竞争力。

**结论:** CausalFM作为一个通用的框架，可以用来训练适用于各种因果推断环境的基础模型，并且与当前因果推断领域的最先进方法相比，它提供了新的范式，有可能从根本上改变医学、经济学等学科中实践者进行因果推断的方式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Foundation+Models+for+Causal+Inference+via+Prior-Data+Fitted+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10914，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10914&send_immediately=true&force_search=false)

**原文摘要:** Prior-data fitted networks (PFNs) have recently been proposed as a promising
way to train tabular foundation models. PFNs are transformers that are
pre-trained on synthetic data generated from a prespecified prior distribution
and that enable Bayesian inference through in-context learning. In this paper,
we introduce CausalFM, a comprehensive framework for training PFN-based
foundation models in various causal inference settings. First, we formalize the
construction of Bayesian priors for causal inference based on structural causal
models (SCMs) in a principled way and derive necessary criteria for the
validity of such priors. Building on this, we propose a novel family of prior
distributions using causality-inspired Bayesian neural networks that enable
CausalFM to perform Bayesian causal inference in various settings, including
back-door, front-door, and instrumental variable adjustment. Finally, we
instantiate CausalFM and explicitly train a foundation model for estimating
conditional average treatment effects (CATEs) using back-door adjustment. We
show that CausalFM performs competitively for CATE estimation using various
synthetic and semi-synthetic benchmarks. In sum, our framework can be used as a
general recipe to train foundation models for various causal inference
settings. In contrast to the current state-of-the-art in causal inference,
CausalFM offers a novel paradigm with the potential to fundamentally change how
practitioners perform causal inference in medicine, economics, and other
disciplines.

</details>


### [85] [Sequential-Parallel Duality in Prefix Scannable Models](https://arxiv.org/abs/2506.10918)
*Morris Yau, Sharut Gupta, Valerie Engelmayer, Kazuki Irie, Stefanie Jegelka, Jacob Andreas*

**主要类别:** cs.LG

**AI概要:** 研究定义了一个新的模型类别——前缀可扫描模型(PSMs)，它统一了多种现有的神经序列模型，并引入了具有softmax类操作符的新模型，这些新模型在保持转换器架构的表现力的同时，达到了状态空间模型的推理效率。


<details>
  <summary>更多</summary>
  
**动机:** 为了寻找一类能够在近常数时间内进行并行评估，并在线性时间、常数空间内完成顺序推断的神经序列模型，研究人员提出了这个问题。

**方法:** 首先描述了一大类这样的模型——状态空间模型，其状态更新可以使用经典的并行前缀扫描算法和自定义的关联聚合运算符来计算。接着定义了一个更广泛的类别，即前缀可扫描模型(PSMs)，通过放宽状态聚合运算符到允许任意（可能是非关联的）函数如softmax注意机制。

**结果:** 实验表明，PSMs保留了基于transformer架构的表现力，同时与状态空间模型的推断效率相匹配，在某些情况下比两者都表现出更好的长度泛化能力。

**结论:** 该研究工作定义了前缀可扫描模型这一通用类别，它不仅统一了许多现有架构，还提出了一些新模型，这些模型在小规模语言建模和合成任务中表现出了良好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sequential-Parallel+Duality+in+Prefix+Scannable+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10918&send_immediately=true&force_search=false)

**原文摘要:** Modern neural sequence models are designed to meet the dual mandate of
parallelizable training and fast sequential inference. Recent developments have
given rise to various models, such as Gated Linear Attention (GLA) and Mamba,
that achieve such ``sequential-parallel duality.'' This raises a natural
question: can we characterize the full class of neural sequence models that
support near-constant-time parallel evaluation and linear-time, constant-space
sequential inference? We begin by describing a broad class of such models --
state space models -- as those whose state updates can be computed using the
classic parallel prefix scan algorithm with a custom associative aggregation
operator. We then define a more general class, Prefix-Scannable Models (PSMs),
by relaxing the state aggregation operator to allow arbitrary (potentially
non-associative) functions such as softmax attention. This generalization
unifies many existing architectures, including element-wise RNNs (e.g., Mamba)
and linear transformers (e.g., GLA, Mamba2, mLSTM), while also introducing new
models with softmax-like operators that achieve O(1) amortized compute per
token and log(N) memory for sequence length N. We empirically evaluate such
models on illustrative small-scale language modeling and canonical synthetic
tasks, including state tracking and associative recall. Empirically, we find
that PSMs retain the expressivity of transformer-based architectures while
matching the inference efficiency of state space models -- in some cases
exhibiting better length generalization than either.

</details>


### [86] [Developing a High-performance Framework for Speech Emotion Recognition in Naturalistic Conditions Challenge for Emotional Attribute Prediction](https://arxiv.org/abs/2506.10930)
*Thanathai Lertpetchpun, Tiantian Feng, Dani Byrd, Shrikanth Narayanan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种可重复的框架，通过多模态学习、多任务学习和不平衡数据处理，在自然条件下情绪识别挑战赛中取得了最佳表现。


<details>
  <summary>更多</summary>
  
**动机:** 在自然条件下的语音情感识别（SER）对语音处理社区来说是一个重大挑战，包括标注者之间的分歧和数据分布不均衡等问题。

**方法:** 系统设计采用了多模态学习、多任务学习以及处理不平衡数据的方法。最优秀的系统训练过程中加入了文本嵌入、性别预测，并将“其他”（O）和“无共识”（X）样本纳入训练集。

**结果:** 该系统在IS25-SER挑战赛的任务2中获得了第一和第二名，最高表现为一个简单的两系统集成。

**结论:** 所提出的框架成功应对了自然条件下语音情感识别的挑战，并在MSP-Podcast数据集上评估时达到了领先性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Developing+a+High-performance+Framework+for+Speech+Emotion+Recognition+in+Naturalistic+Conditions+Challenge+for+Emotional+Attribute+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10930，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10930&send_immediately=true&force_search=false)

**原文摘要:** Speech emotion recognition (SER) in naturalistic conditions presents a
significant challenge for the speech processing community. Challenges include
disagreement in labeling among annotators and imbalanced data distributions.
This paper presents a reproducible framework that achieves superior (top 1)
performance in the Emotion Recognition in Naturalistic Conditions Challenge
(IS25-SER Challenge) - Task 2, evaluated on the MSP-Podcast dataset. Our system
is designed to tackle the aforementioned challenges through multimodal
learning, multi-task learning, and imbalanced data handling. Specifically, our
best system is trained by adding text embeddings, predicting gender, and
including ``Other'' (O) and ``No Agreement'' (X) samples in the training set.
Our system's results secured both first and second places in the IS25-SER
Challenge, and the top performance was achieved by a simple two-system
ensemble.

</details>


### [87] [Self-Adapting Language Models](https://arxiv.org/abs/2506.10943)
*Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, Pulkit Agrawal*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为SEAL的框架，它允许大型语言模型通过生成自己的微调数据和更新指令来自我适应。使用强化学习循环训练该模型以产生有效的自我编辑，其奖励信号是更新后的模型下游性能。实验表明，SEAL是在知识整合和少量样本泛化方面朝着自我导向适应迈出的有希望的一步。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型虽然强大，但它们缺乏针对新任务、知识或示例调整权重的机制。

**方法:** 提出了Self-Adapting LLMs (SEAL) 框架，该框架让LLMs能够通过生成自身的微调数据和更新指令来进行自我适应。对于新的输入，模型会生成一个自我编辑版本，可能重新组织信息，指定优化超参数，或者调用工具进行数据增强和基于梯度的更新。利用监督微调(SFT)，这些自我编辑导致持久的权重更新，实现持续适应。为了训练模型产出有效的自我编辑，采用了一个强化学习回路，其中更新后模型的下游表现作为奖励信号。

**结果:** 实验显示，SEAL在知识整合与少量样本泛化方面表现出色，是朝向能够自我导向适应的语言模型迈进的一个有前景的方向。

**结论:** SEAL直接使用模型自身生成来控制其适应过程，与依赖独立适应模块或辅助网络的先前方法不同，并且在知识融入及少样本泛化中显示出潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Adapting+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10943，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10943&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are powerful but static; they lack mechanisms to
adapt their weights in response to new tasks, knowledge, or examples. We
introduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to
self-adapt by generating their own finetuning data and update directives. Given
a new input, the model produces a self-edit-a generation that may restructure
the information in different ways, specify optimization hyperparameters, or
invoke tools for data augmentation and gradient-based updates. Through
supervised finetuning (SFT), these self-edits result in persistent weight
updates, enabling lasting adaptation. To train the model to produce effective
self-edits, we use a reinforcement learning loop with the downstream
performance of the updated model as the reward signal. Unlike prior approaches
that rely on separate adaptation modules or auxiliary networks, SEAL directly
uses the model's own generation to control its adaptation process. Experiments
on knowledge incorporation and few-shot generalization show that SEAL is a
promising step toward language models capable of self-directed adaptation. Our
website and code is available at https://jyopari.github.io/posts/seal.

</details>


### [88] [Execution Guided Line-by-Line Code Generation](https://arxiv.org/abs/2506.10948)
*Boaz Lavon, Shahar Katz, Lior Wolf*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的神经代码生成方法EG-CFG，该方法在生成代码时引入实时执行反馈信号，以引导模型产生可执行的解决方案。实验表明，与标准方法相比，EG-CFG在不同复杂度的编码任务上显著提高了代码生成性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）已经展示了令人印象深刻的代码生成功能，但它们通常不会在推理过程中利用执行反馈，这是人类程序员经常使用的一个重要信号。

**方法:** Execution-Guided Classifier-Free Guidance (EG-CFG) 方法，它通过三个阶段的过程动态地将执行信号结合到代码生成中：首先进行束搜索来为每一行采样候选程序补全；其次，通过对这些候选方案执行测试用例来提取执行信号；最后，在生成过程中将这些信号纳入提示。

**结果:** 实验结果表明，EG-CFG 在多种编码任务上比标准方法显著提高了代码生成性能，并且在从基础问题到具有挑战性的竞争编程任务等各种复杂度级别上都取得了最先进的成果。

**结论:** EG-CFG 通过结合实时执行反馈，提供了一种有效的方法来改善代码生成的质量和可执行性，从而在不同类型的编程任务中超越了现有技术。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Execution+Guided+Line-by-Line+Code+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10948&send_immediately=true&force_search=false)

**原文摘要:** We present a novel approach to neural code generation that incorporates
real-time execution signals into the language model generation process. While
large language models (LLMs) have demonstrated impressive code generation
capabilities, they typically do not utilize execution feedback during
inference, a critical signal that human programmers regularly leverage. Our
method, Execution-Guided Classifier-Free Guidance (EG-CFG), dynamically
incorporates execution signals as the model generates code, providing
line-by-line feedback that guides the generation process toward executable
solutions. EG-CFG employs a multi-stage process: first, we conduct beam search
to sample candidate program completions for each line; second, we extract
execution signals by executing these candidates against test cases; and
finally, we incorporate these signals into the prompt during generation. By
maintaining consistent signals across tokens within the same line and
refreshing signals at line boundaries, our approach provides coherent guidance
while preserving syntactic structure. Moreover, the method naturally supports
native parallelism at the task level in which multiple agents operate in
parallel, exploring diverse reasoning paths and collectively generating a broad
set of candidate solutions. Our experiments across diverse coding tasks
demonstrate that EG-CFG significantly improves code generation performance
compared to standard approaches, achieving state-of-the-art results across
various levels of complexity, from foundational problems to challenging
competitive programming tasks. Our code is available at:
https://github.com/boazlavon/eg_cfg

</details>


### [89] [Build the web for agents, not agents for the web](https://arxiv.org/abs/2506.10953)
*Xing Han Lù, Gaurav Kamath, Marius Mosbach, Siva Reddy*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种新的交互范式——代理网络接口（AWI），专门针对代理设计，以克服现有方法中人类设计的界面与大型语言模型能力之间不匹配的问题。AWI的设计遵循六大原则，旨在提高安全性、效率和标准化，并促进更高效、可靠且透明的网络代理设计。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于大型语言模型（LLMs）和多模态技术的网络代理在处理复杂的网页输入时面临挑战，因为这些系统难以适应为人类设计的用户界面。

**方法:** 提出了一个专为代理设计的新交互范式——代理网络接口（AWI），并制定了六个指导性设计原则。

**结果:** 通过引入AWI概念，研究者期望能够克服现有的界面限制，推动更高效、可靠及透明的网络代理设计发展。

**结论:** 需要转变现有的网络代理研究方向，从让代理去适应为人设计的界面转变为开发一种特别优化了代理能力的新交互方式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Build+the+web+for+agents%2C+not+agents+for+the+web，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10953&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in Large Language Models (LLMs) and multimodal
counterparts have spurred significant interest in developing web agents -- AI
systems capable of autonomously navigating and completing tasks within web
environments. While holding tremendous promise for automating complex web
interactions, current approaches face substantial challenges due to the
fundamental mismatch between human-designed interfaces and LLM capabilities.
Current methods struggle with the inherent complexity of web inputs, whether
processing massive DOM trees, relying on screenshots augmented with additional
information, or bypassing the user interface entirely through API interactions.
This position paper advocates for a paradigm shift in web agent research:
rather than forcing web agents to adapt to interfaces designed for humans, we
should develop a new interaction paradigm specifically optimized for agentic
capabilities. To this end, we introduce the concept of an Agentic Web Interface
(AWI), an interface specifically designed for agents to navigate a website. We
establish six guiding principles for AWI design, emphasizing safety,
efficiency, and standardization, to account for the interests of all primary
stakeholders. This reframing aims to overcome fundamental limitations of
existing interfaces, paving the way for more efficient, reliable, and
transparent web agent design, which will be a collaborative effort involving
the broader ML community.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [90] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
*Luciano Floridi*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种猜想，该猜想明确地表述了AI系统中可证明正确性与广泛数据映射能力之间的基本权衡，并且这种权衡对AI的工程目标和哲学期望有重要影响。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在明确并严格验证先前隐含的AI系统中可证明正确性和广泛数据处理能力之间的权衡，从而重新定义AI领域的工程雄心和哲学预期。

**方法:** 通过回顾历史动机，将猜想以信息论形式表达，并将其置于认识论、形式验证和技术哲学更广泛的辩论背景中。

**结果:** 讨论了猜想的含义及其后果，包括不确定性的概念、谨慎的认识论风险以及道德责任，并指出如果该猜想正确，它将如何帮助重塑评估标准、治理框架和混合系统设计。

**结论:** 结论强调最终证明或反驳这一不等式对于未来可信AI的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Conjecture+on+a+Fundamental+Trade-Off+between+Certainty+and+Scope+in+Symbolic+and+Generative+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10130&send_immediately=true&force_search=false)

**原文摘要:** This article introduces a conjecture that formalises a fundamental trade-off
between provable correctness and broad data-mapping capacity in Artificial
Intelligence (AI) systems. When an AI system is engineered for deductively
watertight guarantees (demonstrable certainty about the error-free nature of
its outputs) -- as in classical symbolic AI -- its operational domain must be
narrowly circumscribed and pre-structured. Conversely, a system that can input
high-dimensional data to produce rich information outputs -- as in contemporary
generative models -- necessarily relinquishes the possibility of zero-error
performance, incurring an irreducible risk of errors or misclassification. By
making this previously implicit trade-off explicit and open to rigorous
verification, the conjecture significantly reframes both engineering ambitions
and philosophical expectations for AI. After reviewing the historical
motivations for this tension, the article states the conjecture in
information-theoretic form and contextualises it within broader debates in
epistemology, formal verification, and the philosophy of technology. It then
offers an analysis of its implications and consequences, drawing on notions of
underdetermination, prudent epistemic risk, and moral responsibility. The
discussion clarifies how, if correct, the conjecture would help reshape
evaluation standards, governance frameworks, and hybrid system design. The
conclusion underscores the importance of eventually proving or refuting the
inequality for the future of trustworthy AI.

</details>


### [91] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
*Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个愿景，即开发能够动态适应新的专业、人群、工作流程和临床角色的医疗AI模型，而无需重新训练。


<details>
  <summary>更多</summary>
  
**动机:** 当前的医学基础模型在处理未见过的输入和调整到训练过程中没有代表的临床情况时存在局限性，容易产生上下文错误。

**方法:** 文章提出了一种名为“上下文切换”的方法，让AI模型可以不经过再训练就动态地调整其推理过程以适应不同的医疗背景。

**结果:** 设想中的上下文切换AI能够诊断、管理和治疗跨专科和地区范围广泛的疾病，并扩大医疗服务的可及性。

**结论:** 未来的研究方向是开发出能够根据不断变化的医疗环境动态调整行为的医疗AI模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是One+Patient%2C+Many+Contexts%3A+Scaling+Medical+AI+Through+Contextual+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10157，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10157&send_immediately=true&force_search=false)

**原文摘要:** Medical foundation models, including language models trained on clinical
notes, vision-language models on medical images, and multimodal models on
electronic health records, can summarize clinical notes, answer medical
questions, and assist in decision-making. Adapting these models to new
populations, specialties, or settings typically requires fine-tuning, careful
prompting, or retrieval from knowledge bases. This can be impractical, and
limits their ability to interpret unfamiliar inputs and adjust to clinical
situations not represented during training. As a result, models are prone to
contextual errors, where predictions appear reasonable but fail to account for
critical patient-specific or contextual information. These errors stem from a
fundamental limitation that current models struggle with: dynamically adjusting
their behavior across evolving contexts of medical care. In this Perspective,
we outline a vision for context-switching in medical AI: models that
dynamically adapt their reasoning without retraining to new specialties,
populations, workflows, and clinical roles. We envision context-switching AI to
diagnose, manage, and treat a wide range of diseases across specialties and
regions, and expand access to medical care.

</details>


### [92] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
*Hamzah Dabool, Raghad Mustafa*

**主要类别:** cs.AI

**AI概要:** 该研究通过结合相关性分析、机器学习分类和模型解释技术，探讨了临床、认知、遗传及生物标志物特征之间的关系，并使用XGBoost算法识别了影响AD分类的关键特征。结果强调了强相关并不意味着因果关系，并为未来揭示真实病理机制的因果推断研究奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 理解因果关系与相关性的区别对于阿尔茨海默病（AD）的研究至关重要，因为它影响着疾病的诊断、治疗以及真正疾病驱动因素的识别。

**方法:** 实验采用了相关性分析、机器学习分类（特别是XGBoost算法）以及模型可解释性技术（如SHAP值）来探索不同特征间的关系及其对AD分类的影响。

**结果:** 研究确定了包括认知评分和遗传风险因子在内的关键特征，并揭示了变量间的相互关联集群。此外，还指出了在疾病不同阶段中各特征贡献的具体见解。

**结论:** 研究结论指出强烈的相关性并不必然表明存在因果联系，并且提示需要谨慎解读关联数据。这项工作将特征重要性和可解释性与经典统计分析相结合，为今后旨在揭示真实病理机制的因果推断研究打下了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Correlation+vs+causation+in+Alzheimer%27s+disease%3A+an+interpretability-driven+study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10179，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10179&send_immediately=true&force_search=false)

**原文摘要:** Understanding the distinction between causation and correlation is critical
in Alzheimer's disease (AD) research, as it impacts diagnosis, treatment, and
the identification of true disease drivers. This experiment investigates the
relationships among clinical, cognitive, genetic, and biomarker features using
a combination of correlation analysis, machine learning classification, and
model interpretability techniques. Employing the XGBoost algorithm, we
identified key features influencing AD classification, including cognitive
scores and genetic risk factors. Correlation matrices revealed clusters of
interrelated variables, while SHAP (SHapley Additive exPlanations) values
provided detailed insights into feature contributions across disease stages.
Our results highlight that strong correlations do not necessarily imply
causation, emphasizing the need for careful interpretation of associative data.
By integrating feature importance and interpretability with classical
statistical analysis, this work lays groundwork for future causal inference
studies aimed at uncovering true pathological mechanisms. Ultimately,
distinguishing causal factors from correlated markers can lead to improved
early diagnosis and targeted interventions for Alzheimer's disease.

</details>


### [93] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
*Filip Cano*

**主要类别:** cs.AI

**AI概要:** 该论文在安全、公平、透明和问责制方面推进了AI系统的可信度知识，通过引入新的防护措施和技术框架，为实现更安全、公平且可问责的AI系统奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 随着自主系统越来越多地影响关键的社会领域，确保人工智能负责任的使用变得至关重要。但是，可信AI的概念仍然广泛且多方面。

**方法:** 在安全性方面，研究者扩展了经典的确定性防护技术以抵御延迟观察，并将确定性和概率性安全防护措施应用于模拟自动驾驶车辆中，以防止与道路使用者发生碰撞。对于公平性，提出了一种新的后处理方法——公平防护，以强制执行有限和周期时间范围内的序列决策设置中的群体公平。关于透明度和问责制，提出了一个正式框架来评估概率决策代理中的故意行为，并引入了机构和意图商数的定量指标。

**结果:** 这些新方法和框架有效地平衡了公平性与最小干预之间的关系，同时提供了对意图的回顾性分析，有助于确定自主系统造成意外伤害时的责任归属。

**结论:** 通过“反应式决策”框架统一了这些贡献，提供了一个综合以前方法的一般形式化。总的来说，这些进展为实现更安全、公平和负责的AI系统做出了实际贡献，并为未来可信AI的研究奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Responsible+AI%3A+Advances+in+Safety%2C+Fairness%2C+and+Accountability+of+Autonomous+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10192，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10192&send_immediately=true&force_search=false)

**原文摘要:** Ensuring responsible use of artificial intelligence (AI) has become
imperative as autonomous systems increasingly influence critical societal
domains. However, the concept of trustworthy AI remains broad and
multi-faceted. This thesis advances knowledge in the safety, fairness,
transparency, and accountability of AI systems. In safety, we extend classical
deterministic shielding techniques to become resilient against delayed
observations, enabling practical deployment in real-world conditions. We also
implement both deterministic and probabilistic safety shields into simulated
autonomous vehicles to prevent collisions with road users, validating the use
of these techniques in realistic driving simulators. We introduce fairness
shields, a novel post-processing approach to enforce group fairness in
sequential decision-making settings over finite and periodic time horizons. By
optimizing intervention costs while strictly ensuring fairness constraints,
this method efficiently balances fairness with minimal interference. For
transparency and accountability, we propose a formal framework for assessing
intentional behaviour in probabilistic decision-making agents, introducing
quantitative metrics of agency and intention quotient. We use these metrics to
propose a retrospective analysis of intention, useful for determining
responsibility when autonomous systems cause unintended harm. Finally, we unify
these contributions through the ``reactive decision-making'' framework,
providing a general formalization that consolidates previous approaches.
Collectively, the advancements presented contribute practically to the
realization of safer, fairer, and more accountable AI systems, laying the
foundations for future research in trustworthy AI.

</details>


### [94] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
*Qiyue Yin, Pei Xu, Qiaozhe Li, Shengda Liu, Shengqi Shen, Tong Wang, Yihong Han, Xiaonan Zhao, Likun Yang, Shiyue Cao, Shiyu Qiu, Yuxuan Liu, Shizhao Yu, Lei Cui, Chengxin Yan, Jie Sun, Xiangquan Tang, Kaiqi Huang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了WGSR-Bench，这是首个使用战争游戏作为评估环境的大规模语言模型（LLMs）策略推理基准。它旨在评估这些模型在多智能体决策、意图推断和反事实推理方面的能力，并设计了三个核心任务来系统地评估策略推理的主要能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在数学、符号和常识推理等方面表现出色，但在策略推理这一高级人类认知的关键组成部分上，尚未有系统的评估或建模。为了填补这个空白，提出了WGSR-Bench。

**方法:** 通过引入WGSR-Bench，一个以战争游戏为评估环境的策略推理基准。围绕环境态势感知、对手风险建模和策略生成这三个核心任务进行设计，以系统地评估策略推理的主要能力。

**结果:** 开发了一个基于大规模语言模型的战争游戏代理，能够综合评估这些部分进行全面的策略推理。

**结论:** WGSR-Bench 提供了一种评估当前最先进的大规模语言模型在博弈论策略推理中优劣的方法，并推动了大型模型驱动的战略智能研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是WGSR-Bench%3A+Wargame-based+Game-theoretic+Strategic+Reasoning+Benchmark+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10264，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10264&send_immediately=true&force_search=false)

**原文摘要:** Recent breakthroughs in Large Language Models (LLMs) have led to a
qualitative leap in artificial intelligence' s performance on reasoning tasks,
particularly demonstrating remarkable capabilities in mathematical, symbolic,
and commonsense reasoning. However, as a critical component of advanced human
cognition, strategic reasoning, i.e., the ability to assess multi-agent
behaviors in dynamic environments, formulate action plans, and adapt
strategies, has yet to be systematically evaluated or modeled. To address this
gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark
for LLMs using wargame as its evaluation environment. Wargame, a quintessential
high-complexity strategic scenario, integrates environmental uncertainty,
adversarial dynamics, and non-unique strategic choices, making it an effective
testbed for assessing LLMs' capabilities in multi-agent decision-making, intent
inference, and counterfactual reasoning. WGSR-Bench designs test samples around
three core tasks, i.e., Environmental situation awareness, Opponent risk
modeling and Policy generation, which serve as the core S-POE architecture, to
systematically assess main abilities of strategic reasoning. Finally, an
LLM-based wargame agent is designed to integrate these parts for a
comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess
the strengths and limitations of state-of-the-art LLMs in game-theoretic
strategic reasoning and to advance research in large model-driven strategic
intelligence.

</details>


### [95] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
*Xinmin Fang, Lingfeng Tao, Zhengxiong Li*

**主要类别:** cs.AI

**AI概要:** 本文将人工智能重新定义为一种认知引擎，推动着一场不同于工业革命的生产力革新。通过与历史上的信息技术飞跃相比较，文章展示了AI如何放大知识工作，并通过多学科视角探讨了AI如何重塑工作和社会。


<details>
  <summary>更多</summary>
  
**动机:** 作者意图重新构建对人工智能的理解，将其视为类似于书写语言的认知革命，而非仅仅是一种机械工具。目的是展示AI作为人类智力的一种变革性增强，开启了新的生产力范式。

**方法:** 采用多学科的方法，结合计算机科学、经济学以及社会学的观点来分析AI如何改变工作和社会。通过概念框架，描绘了从体力劳动到认知劳动生产率的变化。

**结果:** 研究表明，AI在多个领域中作为认知任务的生产力驱动力具有显著影响。它不仅补充了人类的认知能力，还标志着生产力进化的一个新篇章。

**结论:** 结论是人工智能作为一种认知引擎，其潜力在于补充而非替代人类的认知能力，这需要我们重新思考技能、组织结构和政策等方面的议题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Closer+to+Language+than+Steam%3A+AI+as+the+Cognitive+Engine+of+a+New+Productivity+Revolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10281&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) is reframed as a cognitive engine driving a
novel productivity revolution distinct from the Industrial Revolution's
physical thrust. This paper develops a theoretical framing of AI as a cognitive
revolution akin to written language - a transformative augmentation of human
intellect rather than another mechanized tool. We compare AI's emergence to
historical leaps in information technology to show how it amplifies knowledge
work. Examples from various domains demonstrate AI's impact as a driver of
productivity in cognitive tasks. We adopt a multidisciplinary perspective
combining computer science advances with economic insights and sociological
perspectives on how AI reshapes work and society. Through conceptual
frameworks, we visualize the shift from manual to cognitive productivity. Our
central argument is that AI functions as an engine of cognition - comparable to
how human language revolutionized knowledge - heralding a new productivity
paradigm. We discuss how this revolution demands rethinking of skills,
organizations, and policies. This paper, balancing academic rigor with clarity,
concludes that AI's promise lies in complementing human cognitive abilities,
marking a new chapter in productivity evolution.

</details>


### [96] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
*Jasper Yao*

**主要类别:** cs.AI

**AI概要:** 本文从计算复杂性的角度探讨了AI安全验证的挑战，指出当AI系统的能力超过一定阈值时，安全验证将变得极其复杂（指数级时间和coNP完全问题）。文章通过四个核心定理证明了随着系统表达能力的增加，验证复杂性呈指数增长、安全策略在策略空间中占比极小、没有有限数量的对齐技术可以提供全面覆盖以及鲁棒的安全属性对于神经网络来说是零测度集。最后提出了一个战略上的三难困境：限制系统复杂性以保持可验证的安全性、接受不可验证的风险来扩展能力或开发超越验证的新安全范式。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于建立人工智能安全性验证的基本计算复杂性障碍，特别是在系统能力提升的情况下。

**方法:** 使用计算复杂性理论分析方法，并通过四个核心定理形式化了能力-风险扩展动态关系。

**结果:** 发现随着AI系统表达力增强，安全验证所需时间呈指数级增长；安全策略占所有可能策略的比例极低；没有任何一组有限数量的技术能够实现普遍适用的安全校准；对于神经网络而言，强健的安全特性构成了零测度集合。

**结论:** 提出了一种战略上的三难选择：要么控制住系统的复杂程度以便维持可验证的安全水平，要么在扩大功能的同时接受无法被证实的风险，抑或是探索出一套全新的不同于传统验证模式的安全框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Alignment+Trap%3A+Complexity+Barriers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10304，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10304&send_immediately=true&force_search=false)

**原文摘要:** We establish fundamental computational complexity barriers to verifying AI
safety as system capabilities scale. Our main results show that for AI systems
with expressiveness EXP$(m)$ above a critical threshold $\tau$, safety
verification requires exponential time and is coNP-complete. We formalize the
Capability-Risk Scaling (CRS) dynamic, which demonstrates how increasing AI
capability drives societal safety requirements toward perfection, creating an
inescapable tension with verification complexity. Through four core theorems,
we prove that (1) verification complexity grows exponentially with system
expressiveness, (2) safe policies comprise at most a $2^{-2^m}$ fraction of the
policy space, (3) no finite set of alignment techniques can provide universal
coverage, and (4) robust safety properties form measure-zero sets for neural
networks. These results characterize an "intractability gap" where practical
safety requirements fall within the region of computational intractability. We
conclude by presenting a strategic trilemma: AI development must either
constrain system complexity to maintain verifiable safety, accept unverifiable
risks while scaling capabilities, or develop fundamentally new safety paradigms
beyond verification. Our work provides the first systematic
complexity-theoretic analysis of AI alignment and establishes rigorous bounds
that any safety approach must confront. A formal verification of the core
theorems in Lean4 is currently in progress.

</details>


### [97] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
*Cameron Angliss, Jiaxun Cui, Jiaheng Hu, Arrasy Rahman, Peter Stone*

**主要类别:** cs.AI

**AI概要:** 本文介绍了VGC-Bench，这是一个针对宝可梦电子游戏锦标赛的基准测试平台，提供了关键基础设施、标准化评估协议和人类玩家数据集，并通过多种方法进行评测。结果显示，在单队配置下训练和评估的代理可以击败专业VGC选手，但当团队规模扩大时，即使是表现最好的算法也难以实现策略泛化。


<details>
  <summary>更多</summary>
  
**动机:** 多智能体学习面临的一个核心挑战是开发能够稳健适应截然不同的战略环境而无需重新训练的人工智能代理。宝可梦视频游戏锦标赛（VGC）是一个具有极大可能队伍配置空间的领域，其高度离散和组合性导致最优策略会根据所操作的队伍和对手队伍的不同而显著变化，这使得泛化变得尤其困难。

**方法:** 作者引入了VGC-Bench作为基准测试，它提供了必要的基础设施，统一了评估标准，并提供了人类玩家的数据集以及一系列基线方法，包括大型语言模型代理、行为克隆、强化学习及经验博弈论方法如自对弈、虚构对弈和双重oracle等。

**结果:** 在限定情况下，即代理在一个单一队伍配置上被训练和评估，该方法能够战胜职业VGC选手。然而，随着团队集合逐步增大，所有基线方法经过广泛评估后发现，即使是在单一队伍设置中表现最佳的算法，在团队规模增长时也会遇到扩展性的难题。

**结论:** 政策泛化到多样化的队伍策略仍然是社区面临的开放挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Benchmark+for+Generalizing+Across+Diverse+Team+Strategies+in+Competitive+Pok%C3%A9mon，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10326&send_immediately=true&force_search=false)

**原文摘要:** Developing AI agents that can robustly adapt to dramatically different
strategic landscapes without retraining is a central challenge for multi-agent
learning. Pok\'emon Video Game Championships (VGC) is a domain with an
extraordinarily large space of possible team configurations of approximately
$10^{139}$ - far larger than those of Dota or Starcraft. The highly discrete,
combinatorial nature of team building in Pok\'emon VGC causes optimal
strategies to shift dramatically depending on both the team being piloted and
the opponent's team, making generalization uniquely challenging. To advance
research on this problem, we introduce VGC-Bench: a benchmark that provides
critical infrastructure, standardizes evaluation protocols, and supplies
human-play datasets and a range of baselines - from large-language-model agents
and behavior cloning to reinforcement learning and empirical game-theoretic
methods such as self-play, fictitious play, and double oracle. In the
restricted setting where an agent is trained and evaluated on a single-team
configuration, our methods are able to win against a professional VGC
competitor. We extensively evaluated all baseline methods over progressively
larger team sets and find that even the best-performing algorithm in the
single-team setting struggles at scaling up as team size grows. Thus, policy
generalization across diverse team strategies remains an open challenge for the
community. Our code is open sourced at
https://github.com/cameronangliss/VGC-Bench.

</details>


### [98] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
*Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Weili Guan, Dongmei Jiang, Liqiang Nie*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个名为Optimus-3的通用代理，用于在Minecraft环境中执行多种任务。通过知识增强的数据生成管道、专家混合架构以及多模态推理强化学习方法来解决现有挑战。实验结果表明，Optimus-3的表现优于现有的多模态大语言模型和其他顶尖代理。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基于多模态大语言模型（MLLMs）的代理已经在多个领域取得了显著进步，但在开放世界环境如Minecraft中构建具有感知、规划、行动、落地和反思等能力的通用代理仍面临挑战：特定领域的数据不足、异构任务间的干扰以及开放世界设置中的视觉多样性。

**方法:** 1) 提出了一种知识增强的数据生成流程，为代理开发提供可扩展且高质量的训练数据。
2) 引入了带有任务级路由的混合专家（MoE）架构，以减少异构任务之间的干扰。
3) 开发了一种多模态推理增强的强化学习方法，以提高代理在Minecraft中面对视觉多样性时的推理能力。

**结果:** 广泛的实验结果表明，在Minecraft环境中，Optimus-3在各种任务上超越了通用多模态大语言模型以及当前最先进的代理。

**结论:** 通过提出创新性的解决方案，包括改进的数据生成方法、专门设计的任务处理架构和强化学习技术，研究者成功地创建了一个更高效、适应性更强的Minecraft环境下的代理——Optimus-3。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimus-3%3A+Towards+Generalist+Multimodal+Minecraft+Agents+with+Scalable+Task+Experts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10357，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10357&send_immediately=true&force_search=false)

**原文摘要:** Recently, agents based on multimodal large language models (MLLMs) have
achieved remarkable progress across various domains. However, building a
generalist agent with capabilities such as perception, planning, action,
grounding, and reflection in open-world environments like Minecraft remains
challenges: insufficient domain-specific data, interference among heterogeneous
tasks, and visual diversity in open-world settings. In this paper, we address
these challenges through three key contributions. 1) We propose a
knowledge-enhanced data generation pipeline to provide scalable and
high-quality training data for agent development. 2) To mitigate interference
among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture
with task-level routing. 3) We develop a Multimodal Reasoning-Augmented
Reinforcement Learning approach to enhance the agent's reasoning ability for
visual diversity in Minecraft. Built upon these innovations, we present
Optimus-3, a general-purpose agent for Minecraft. Extensive experimental
results demonstrate that Optimus-3 surpasses both generalist multimodal large
language models and existing state-of-the-art agents across a wide range of
tasks in the Minecraft environment. Project page:
https://cybertronagent.github.io/Optimus-3.github.io/

</details>


### [99] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
*Jim O'Connor, Yeonghun Lee, Gary B Parker*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为NeuroPAL的神经进化框架，它结合了拓扑结构增强的神经进化（NEAT）与间断性即时学习（PAL），以提高StarCraft: Brood War游戏中宏观管理AI训练效率。实验结果表明，相比传统的NEAT方法，NeuroPAL可以显著加速学习过程，并且能够使代理在大约一半的时间内达到竞争水平的游戏表现。


<details>
  <summary>更多</summary>
  
**动机:** 《星际争霸：母巢之战》作为人工智能研究中的一个挑战性基准，特别是在需要长期战略规划的宏观管理领域。传统的人工智能方法依赖于基于规则的系统或有监督的深度学习，它们在适应性和计算效率方面存在局限性。

**方法:** 提出了NeuroPAL，一种将拓扑结构增强的神经进化（NEAT）与间断性即时学习（PAL）相结合的神经进化框架。通过频繁的低精度训练和周期性的高精度评估交替进行，PAL提高了NEAT的样本效率。

**结果:** 实验结果显示，与仅使用NEAT相比，PAL显著加快了学习过程，使代理能够在大约一半的训练时间内达到具有竞争力的游戏水平。此外，演化的代理展示了如代理兵营放置和防御建筑优化等新兴行为。

**结论:** 结构化的评估机制，例如PAL，能够提高神经进化在复杂实时策略环境中的可扩展性和有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NeuroPAL%3A+Punctuated+Anytime+Learning+with+Neuroevolution+for+Macromanagement+in+Starcraft%3A+Brood+War，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10384，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10384&send_immediately=true&force_search=false)

**原文摘要:** StarCraft: Brood War remains a challenging benchmark for artificial
intelligence research, particularly in the domain of macromanagement, where
long-term strategic planning is required. Traditional approaches to StarCraft
AI rely on rule-based systems or supervised deep learning, both of which face
limitations in adaptability and computational efficiency. In this work, we
introduce NeuroPAL, a neuroevolutionary framework that integrates
Neuroevolution of Augmenting Topologies (NEAT) with Punctuated Anytime Learning
(PAL) to improve the efficiency of evolutionary training. By alternating
between frequent, low-fidelity training and periodic, high-fidelity
evaluations, PAL enhances the sample efficiency of NEAT, enabling agents to
discover effective strategies in fewer training iterations. We evaluate
NeuroPAL in a fixed-map, single-race scenario in StarCraft: Brood War and
compare its performance to standard NEAT-based training. Our results show that
PAL significantly accelerates the learning process, allowing the agent to reach
competitive levels of play in approximately half the training time required by
NEAT alone. Additionally, the evolved agents exhibit emergent behaviors such as
proxy barracks placement and defensive building optimization, strategies
commonly used by expert human players. These findings suggest that structured
evaluation mechanisms like PAL can enhance the scalability and effectiveness of
neuroevolution in complex real-time strategy environments.

</details>


### [100] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
*Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种分层多模态技能(HMS)模块和技能增强蒙特卡洛树搜索(SA-MCTS)算法，以解决多模态大语言模型(MLLM)作为GUI代理在执行长期任务时知识不足的问题。基于HMS，作者提出了Mirage-1，一种跨平台即插即用的GUI代理，并在新构建的基准AndroidLH上验证了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管将多模态大语言模型(MLLM)作为图形用户界面(GUI)代理的研究取得了积极成果，但在在线环境中执行长期任务方面仍面临挑战，主要是因为知识不足以及离线与在线领域间的差距。

**方法:** 为了解决知识不足问题，论文借鉴了人类在开放式环境中泛化知识的方式，提出了一种分层多模态技能(Hierarchical Multimodal Skills, HMS)模块；为了弥合领域差距，还提出了技能增强蒙特卡洛树搜索(Skill-Augmented Monte Carlo Tree Search, SA-MCTS)算法。此外，基于HMS模块，开发了一个名为Mirage-1的多模态、跨平台且即插即用的GUI代理。

**结果:** 实验结果表明，在AndroidWorld、MobileMiniWob++、Mind2Web-Live以及新建立的基准测试AndroidLH上，Mirage-1的表现分别优于之前的代理32%、19%、15%及79%。

**结论:** 通过引入HMS模块和SA-MCTS算法，该研究显著提升了GUI代理处理长期任务的能力，特别是在从离线到在线环境迁移时。提出的Mirage-1代理在多个基准测试中表现出色，展示了其在现实世界应用中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mirage-1%3A+Augmenting+and+Updating+GUI+Agent+with+Hierarchical+Multimodal+Skills，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10387，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10387&send_immediately=true&force_search=false)

**原文摘要:** Recent efforts to leverage the Multi-modal Large Language Model (MLLM) as GUI
agents have yielded promising outcomes. However, these agents still struggle
with long-horizon tasks in online environments, primarily due to insufficient
knowledge and the inherent gap between offline and online domains. In this
paper, inspired by how humans generalize knowledge in open-ended environments,
we propose a Hierarchical Multimodal Skills (HMS) module to tackle the issue of
insufficient knowledge. It progressively abstracts trajectories into execution
skills, core skills, and ultimately meta-skills, providing a hierarchical
knowledge structure for long-horizon task planning. To bridge the domain gap,
we propose the Skill-Augmented Monte Carlo Tree Search (SA-MCTS) algorithm,
which efficiently leverages skills acquired in offline environments to reduce
the action search space during online tree exploration. Building on HMS, we
propose Mirage-1, a multimodal, cross-platform, plug-and-play GUI agent. To
validate the performance of Mirage-1 in real-world long-horizon scenarios, we
constructed a new benchmark, AndroidLH. Experimental results show that Mirage-1
outperforms previous agents by 32\%, 19\%, 15\%, and 79\% on AndroidWorld,
MobileMiniWob++, Mind2Web-Live, and AndroidLH, respectively. Project page:
https://cybertronagent.github.io/Mirage-1.github.io/

</details>


### [101] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
*Jintao Liang, Gang Su, Huifeng Lin, You Wu, Rui Zhao, Ziyue Li*

**主要类别:** cs.AI

**AI概要:** 本文综述了推理代理RAG方法，将其分为预定义推理和自主推理两大类，并探讨了设计、策略以及工具协调技术。文章最后讨论了研究挑战并提出了未来的研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 传统的RAG系统在处理需要复杂推理、动态检索和多模态整合的真实场景时表现不佳，为了解决这些问题，研究领域转向了推理代理RAG，这种模式直接将决策制定和自适应工具使用结合到检索过程中。

**方法:** 论文提供了对推理代理RAG方法的全面回顾，并将其归类为两个主要体系：预定义推理和自主推理。预定义推理遵循固定的模块化流程来增强推理能力；而自主推理则让模型在推理过程中自主安排工具交互。

**结果:** 通过分析代表性技术，包括架构设计、推理策略和工具协调，论文揭示了当前推理代理RAG系统的优势和不足。

**结论:** 文章总结了现有研究中的关键问题，并对未来的发展方向提出了建议，以提高推理代理RAG系统的灵活性、鲁棒性和适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning+RAG+via+System+1+or+System+2%3A+A+Survey+on+Reasoning+Agentic+Retrieval-Augmented+Generation+for+Industry+Challenges，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10408，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10408&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to
overcome the knowledge limitations of Large Language Models (LLMs) by
integrating external retrieval with language generation. While early RAG
systems based on static pipelines have shown effectiveness in well-structured
tasks, they struggle in real-world scenarios requiring complex reasoning,
dynamic retrieval, and multi-modal integration. To address these challenges,
the field has shifted toward Reasoning Agentic RAG, a paradigm that embeds
decision-making and adaptive tool use directly into the retrieval process. In
this paper, we present a comprehensive review of Reasoning Agentic RAG methods,
categorizing them into two primary systems: predefined reasoning, which follows
fixed modular pipelines to boost reasoning, and agentic reasoning, where the
model autonomously orchestrates tool interaction during inference. We analyze
representative techniques under both paradigms, covering architectural design,
reasoning strategies, and tool coordination. Finally, we discuss key research
challenges and propose future directions to advance the flexibility,
robustness, and applicability of reasoning agentic RAG systems. Our collection
of the relevant research has been organized into a
https://github.com/ByebyeMonica/Reasoning-Agentic-RAG.

</details>


### [102] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
*Boris Sedlak, Alireza Furutanpey, Zihang Wang, Víctor Casamayor Pujol, Schahram Dustdar*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种基于代理的自动扩展框架，该框架能够动态调整硬件资源和内部服务配置，以在受限环境中最大化需求满足。通过比较四种类型的扩展代理，并使用YOLOv8和OpenCV两个实际处理服务进行实验，结果表明所有代理都达到了可接受的服务水平目标性能，并且具有不同的收敛模式。


<details>
  <summary>更多</summary>
  
**动机:** 边缘计算由于严格的资源限制，与传统的自动扩展方式不同，这促使了使用多个弹性维度来实现更灵活的扩展行为。

**方法:** 提出了一种基于代理的自动扩展框架，该框架可以同时动态调整硬件资源和内部服务配置。研究中对比了四种类型的扩展代理：主动推理、深度Q网络、结构知识分析以及深度主动推理，并使用了两个并行运行的实际处理服务——YOLOv8用于视觉识别，OpenCV用于二维码检测。

**结果:** 结果显示，所有代理均能达到可接受的服务等级目标（SLO）性能，但它们表现出不同的收敛模式。深度Q网络得益于预训练，而结构分析则快速收敛；深度主动推理代理结合了理论基础与实践中的可扩展性优势。

**结论:** 研究结果为基于多维代理的边缘环境自适应扩展方法提供了可行性证据，并鼓励未来在此研究方向上的进一步工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-dimensional+Autoscaling+of+Processing+Services%3A+A+Comparison+of+Agent-based+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10420，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10420&send_immediately=true&force_search=false)

**原文摘要:** Edge computing breaks with traditional autoscaling due to strict resource
constraints, thus, motivating more flexible scaling behaviors using multiple
elasticity dimensions. This work introduces an agent-based autoscaling
framework that dynamically adjusts both hardware resources and internal service
configurations to maximize requirements fulfillment in constrained
environments. We compare four types of scaling agents: Active Inference, Deep Q
Network, Analysis of Structural Knowledge, and Deep Active Inference, using two
real-world processing services running in parallel: YOLOv8 for visual
recognition and OpenCV for QR code detection. Results show all agents achieve
acceptable SLO performance with varying convergence patterns. While the Deep Q
Network benefits from pre-training, the structural analysis converges quickly,
and the deep active inference agent combines theoretical foundations with
practical scalability advantages. Our findings provide evidence for the
viability of multi-dimensional agent-based autoscaling for edge environments
and encourage future work in this research direction.

</details>


### [103] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
*Yaoming Zhu, Junxin Wang, Yiyang Li, Lin Qiu, ZongYu Wang, Jun Xu, Xuezhi Cao, Yuhuai Wei, Mingshi Wang, Xunliang Cai, Rong Ma*

**主要类别:** cs.AI

**AI概要:** 本文介绍了OIBench，一个高质量、私密且具有挑战性的信息学奥林匹克水平数据集，旨在为算法推理提供更难的基准。实验表明，尽管开源模型落后于闭源模型，但当前最先进模型在正确性和效率上已经超过了大多数人，但仍不如标准解法。


<details>
  <summary>更多</summary>
  
**动机:** 随着模型变得越来越复杂，传统的算法基准测试已接近饱和，需要更具有挑战性的基准来指导未来算法推理能力的改进。

**方法:** 构建了OIBench，这是一个包含250个精心策划的问题的数据集，并通过实验展示了其抗污染特性。提出了时间/空间完成曲线来进行更细致的效率分析，并通过高级参与者评估实现直接的人机比较。

**结果:** 实验显示，虽然开源模型落后于闭源版本，但现有的最先进模型已经在正确性和效率上超过了大多数人类参与者，尽管它们与规范解决方案相比仍不是最优。

**结论:** 通过发布OIBench作为完全开源资源，研究者希望该基准能够有助于提升未来大型语言模型的代码推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OIBench%3A+Benchmarking+Strong+Reasoning+Models+with+Olympiad+in+Informatics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10481，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10481&send_immediately=true&force_search=false)

**原文摘要:** As models become increasingly sophisticated, conventional algorithm
benchmarks are increasingly saturated, underscoring the need for more
challenging benchmarks to guide future improvements in algorithmic reasoning.
This paper introduces OIBench, a high-quality, private, and challenging
olympiad-level informatics dataset comprising 250 carefully curated original
problems. We detail the construction methodology of the benchmark, ensuring a
comprehensive assessment across various programming paradigms and complexities,
and we demonstrate its contamination-resistant properties via experiments. We
propose Time/Space Completion Curves for finer-grained efficiency analysis and
enable direct human-model comparisons through high-level participant
evaluations. Our experiments reveal that while open-source models lag behind
closed-source counterparts, current SOTA models already outperform most human
participants in both correctness and efficiency, while still being suboptimal
compared to the canonical solutions. By releasing OIBench as a fully
open-source resource (https://huggingface.co/datasets/AGI-Eval/OIBench), we
hope this benchmark will contribute to advancing code reasoning capabilities
for future LLMs.

</details>


### [104] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
*Yuhao Zhou, Yiheng Wang, Xuming He, Ruoyao Xiao, Zhiwei Li, Qiantai Feng, Zijie Guo, Yuejin Yang, Hao Wu, Wenxuan Huang, Jiaqi Wei, Dan Si, Xiuqi Yao, Jia Bu, Haiwen Huang, Tianfan Fu, Shixiang Tang, Ben Fei, Dongzhan Zhou, Fenghua Ling, Yan Lu, Siqi Sun, Chenhui Li, Guanjie Zheng, Jiancheng Lv, Wenlong Zhang, Lei Bai*

**主要类别:** cs.AI

**AI概要:** 本文提出了科学家首次考试（SFE）基准，旨在通过三个相互关联的层次来评估多模态大语言模型（MLLMs）的科学认知能力，并揭示了当前最先进的MLLMs在科学领域还有很大的改进空间。


<details>
  <summary>更多</summary>
  
**动机:** 现有的科学基准主要侧重于评估多模态大语言模型的知识理解能力，而对感知和推理能力的评估不足。为了解决这一问题，作者提出了一个新的基准——科学家首次考试（SFE），以更全面地评价这些模型的科学认知能力。

**方法:** 设计并实现了科学家首次考试（SFE）基准，该基准包含830个由专家验证的VQA配对，涵盖三种问题类型，涉及五个高价值学科中的66个多模态任务。

**结果:** 广泛的实验表明，当前最先进GPT-o3和InternVL-3在SFE上的得分分别为34.08%和26.52%，这表明多模态大语言模型在科学领域仍有显著的提升空间。

**结论:** SFE基准提供了一个新的框架来评估多模态大语言模型的科学认知能力，并且研究结果指出，为了促进AI增强的科学发现，需要进一步发展这些模型的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scientists%27+First+Exam%3A+Probing+Cognitive+Abilities+of+MLLM+via+Perception%2C+Understanding%2C+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10521，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10521&send_immediately=true&force_search=false)

**原文摘要:** Scientific discoveries increasingly rely on complex multimodal reasoning
based on information-intensive scientific data and domain-specific expertise.
Empowered by expert-level scientific benchmarks, scientific Multimodal Large
Language Models (MLLMs) hold the potential to significantly enhance this
discovery process in realistic workflows. However, current scientific
benchmarks mostly focus on evaluating the knowledge understanding capabilities
of MLLMs, leading to an inadequate assessment of their perception and reasoning
abilities. To address this gap, we present the Scientists' First Exam (SFE)
benchmark, designed to evaluate the scientific cognitive capacities of MLLMs
through three interconnected levels: scientific signal perception, scientific
attribute understanding, scientific comparative reasoning. Specifically, SFE
comprises 830 expert-verified VQA pairs across three question types, spanning
66 multimodal tasks across five high-value disciplines. Extensive experiments
reveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%
and 26.52% on SFE, highlighting significant room for MLLMs to improve in
scientific realms. We hope the insights obtained in SFE will facilitate further
developments in AI-enhanced scientific discoveries.

</details>


### [105] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
*Yanan Cai, Ahmed Salem, Besmira Nushi, Mark Russinovich*

**主要类别:** cs.AI

**AI概要:** 本文介绍了LogiPlan，一种新的基准测试工具，旨在评估大型语言模型在复杂关系结构上的逻辑规划和推理能力。它包括三个互补的任务：计划生成、一致性检测和比较问题，并通过动态调整任务复杂度来细致评估不同难度水平下模型的表现。研究还测试了模型自我纠正的能力，并对当前最先进的多个模型进行了评测，结果显示模型性能与其规模和架构有关，在处理需要深层逻辑规划的更复杂数组时仍面临挑战。


<details>
  <summary>更多</summary>
  
**动机:** 为了评估大型语言模型（LLMs）在面对复杂关系结构时进行逻辑规划和推理的能力，因为这对依赖于LLMs生成和查询如网络基础设施、知识库或业务流程模式等关系图的应用至关重要。

**方法:** 开发了一个名为LogiPlan的新基准，该基准允许通过控制对象数量、关系数目及关系链的最小深度来动态变化任务复杂性。此外，LogiPlan框架定义了三个相互补充的任务来全面考察模型表现，并且探索了模型自我修正其初始解决方案的能力。

**结果:** 评测表明，尽管近期增强推理能力的模型在较简单的实例上显示出良好的结果，但在处理需要更深层次逻辑规划的复杂数组配置时仍显得力不从心。同时，发现模型表现与它们的规模和架构紧密相关。

**结论:** 虽然最近的增强推理模型在简单情况下表现出色，但它们在涉及深层次逻辑规划的更复杂数组面前遇到了困难。这表明对于大型语言模型来说，提高其处理复杂关系结构的能力依然是一个重要的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LogiPlan%3A+A+Structured+Benchmark+for+Logical+Planning+and+Relational+Reasoning+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10527&send_immediately=true&force_search=false)

**原文摘要:** We introduce LogiPlan, a novel benchmark designed to evaluate the
capabilities of large language models (LLMs) in logical planning and reasoning
over complex relational structures. Logical relational reasoning is important
for applications that may rely on LLMs to generate and query structured graphs
of relations such as network infrastructure, knowledge bases, or business
process schema. Our framework allows for dynamic variation of task complexity
by controlling the number of objects, relations, and the minimum depth of
relational chains, providing a fine-grained assessment of model performance
across difficulty levels. LogiPlan encompasses three complementary tasks: (1)
Plan Generation, where models must construct valid directed relational graphs
meeting specified structural constraints; (2) Consistency Detection, testing
models' ability to identify inconsistencies in relational structures; and (3)
Comparison Question, evaluating models' capacity to determine the validity of
queried relationships within a given graph. Additionally, we assess models'
self-correction capabilities by prompting them to verify and refine their
initial solutions. We evaluate state-of-the-art models including DeepSeek R1,
Gemini 2.0 Pro, Gemini 2 Flash Thinking, GPT-4.5, GPT-4o, Llama 3.1 405B,
O3-mini, O1, and Claude 3.7 Sonnet across these tasks, revealing significant
performance gaps that correlate with model scale and architecture. Our analysis
demonstrates that while recent reasoning-enhanced models show promising results
on simpler instances, they struggle with more complex configurations requiring
deeper logical planning.

</details>


### [106] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
*Mohd Anwar Jamal Faiz*

**主要类别:** cs.AI

**AI概要:** 本文提出了Primender序列，这是一种结合了经典素数概念和基于模数位条件的新型整数序列。该序列用于评估大型语言模型（LLMs）的符号推理能力，并通过设计结构化的提示和评估框架来测试多个最先进的LLMs，包括ChatGPT、Copilot等。研究贡献了一个新的数学构造以及一个可重复的方法论，用于在符号推理、假设检验和模式泛化方面对LLMs进行基准测试。


<details>
  <summary>更多</summary>
  
**动机:** 本文的研究动机是需要可解释的、基于规则的测试平台，以评估大型语言模型（LLMs）推断隐藏规则、验证数学假设和大规模符号逻辑泛化的能力。

**方法:** 研究者提出了一种新的整数序列Primender，它结合了素性与基于模数的数字条件。为了评估不同大型语言模型（LLMs）的性能，研究者设计了一套结构化的提示和评估框架，要求模型识别潜在规则，验证关键假设，并生成序列中的下10万个项。

**结果:** 研究结果提供了比较指标，如规则推断准确性、假设评估、序列有效性和符号解释质量，用以评估模型表现。

**结论:** 这项工作为大型语言模型在符号推理、假设检验及模式泛化方面提供了一种新的数学结构和可复制的方法论，从而连接了数论、人工智能和软件工程领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Primender+Sequence%3A+A+Novel+Mathematical+Construct+for+Testing+Symbolic+Inference+and+AI+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10585，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10585&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces the Primender sequence, a novel integer sequence
defined by a hybrid rule that combines classical primality with modular
digit-based conditions. Specifically, a number n is included in the sequence if
it is prime or ends with a prime number of unit digit or any length. In other
words, numbers which are primes or have at least one prime suffix. The
resulting sequence exhibits a deterministic yet non-trivial structure, blending
number-theoretic properties with symbolic patterning. We propose the Primender
sequence as a benchmark for evaluating the symbolic reasoning capabilities of
Large Language Models (LLMs). The study is motivated by the need for
interpretable, rule-based testbeds that can assess an LLM's ability to infer
hidden rules, validate mathematical hypotheses, and generalize symbolic logic
at scale. A key hypothesis explored is: Whenever a number in the Primender
sequence is exactly one more than the largest prime less than or equal to it,
the difference between it and the previous number in the sequence is also 1. We
design a structured prompt and evaluation framework to test this hypothesis
across multiple state-of-the-art LLMs, including ChatGPT, Copilot, DeepSeek,
Gemini, Grok, and LLaMA. The models are tasked with identifying the underlying
rule, validating the hypothesis, and generating the next 100,000 terms of the
sequence. Comparative metrics such as rule inference accuracy, hypothesis
evaluation, sequence validity, and symbolic explanation quality are used to
assess model performance. This work contributes a novel mathematical construct
and a reproducible methodology for benchmarking LLMs in symbolic reasoning,
hypothesis testing, and scalable pattern generalization - bridging the domains
of number theory, artificial intelligence, and software engineering.

</details>


### [107] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
*Henrik Sebastian Steude, Alexander Diedrich, Ingo Pill, Lukas Moddemann, Daniel Vranješ, Oliver Niggemann*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的诊断方法，该方法仅需要最少的先验知识，通过结合基于神经网络的症状生成器和利用子系统间因果关系信息的新图诊断算法来工作。实验表明该方法在大多数情况下能够包含真实的因果组件，并有效缩小搜索空间，且在实际应用中展示了潜力。


<details>
  <summary>更多</summary>
  
**动机:** 针对复杂的信息物理系统，诊断过程通常需要详细的系统模型或全面的训练数据作为先验知识，但获取这些信息是一个重大挑战。

**方法:** 提出了一种新的诊断方法，只需要对子系统关系有基本了解以及来自正常操作的数据；该方法结合了基于神经网络的症状生成器（使用子系统级异常检测）与一种新的图诊断算法（利用子系统之间最小的因果关系信息）。

**结果:** 实验结果表明，在所有案例中，该方法有82%的概率将其诊断集合中包括真正的因果组件，同时在73%的情况下有效地减少了搜索空间。此外，通过对真实世界安全水处理数据集的测试进一步证明了该方法在实践场景中的潜力。

**结论:** 研究结果突出了这种方法对于具有有限先验知识的大规模复杂信息物理系统的潜在实用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Driven+Diagnosis+for+Large+Cyber-Physical-Systems+with+Minimal+Prior+Information，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10613，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10613&send_immediately=true&force_search=false)

**原文摘要:** Diagnostic processes for complex cyber-physical systems often require
extensive prior knowledge in the form of detailed system models or
comprehensive training data. However, obtaining such information poses a
significant challenge. To address this issue, we present a new diagnostic
approach that operates with minimal prior knowledge, requiring only a basic
understanding of subsystem relationships and data from nominal operations. Our
method combines a neural network-based symptom generator, which employs
subsystem-level anomaly detection, with a new graph diagnosis algorithm that
leverages minimal causal relationship information between
subsystems-information that is typically available in practice. Our experiments
with fully controllable simulated datasets show that our method includes the
true causal component in its diagnosis set for 82 p.c. of all cases while
effectively reducing the search space in 73 p.c. of the scenarios. Additional
tests on the real-world Secure Water Treatment dataset showcase the approach's
potential for practical scenarios. Our results thus highlight our approach's
potential for practical applications with large and complex cyber-physical
systems where limited prior knowledge is available.

</details>


### [108] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
*Vincenzo Colle, Mohamed Sana, Nicola Piovesan, Antonio De Domenico, Fadhel Ayed, Merouane Debbah*

**主要类别:** cs.AI

**AI概要:** 本文介绍了TeleMath，这是一个专为评估大型语言模型在解决电信领域数学问题方面性能的基准数据集。通过一系列由专家设计的问题来生成500个问答对，并测试了多种开源模型，发现专门针对数学或逻辑推理设计的新模型表现最佳。


<details>
  <summary>更多</summary>
  
**动机:** 由于人工智能在电信领域的应用日益增多，人们对于大型语言模型（LLMs）处理特定领域内富含数学计算任务的能力产生了兴趣。尽管近期LLMs在一般数学推理上的表现有所提升，但在如信号处理、网络优化和性能分析等专业领域中的有效性仍待探索。

**方法:** 为了填补这一空白，研究者们创建了名为TeleMath的数据集，它包含了500个问答对，覆盖了电信领域的广泛主题。该数据集是通过一个由主题专家精心挑选的问题种子开始，然后经过一定的流程生成的。

**结果:** 通过对多种开源LLMs进行评估后发现，那些专门为数学或逻辑推理设计的较新模型在TeleMath上取得了最好的成绩；而通用型模型即使参数量很大，在这些挑战面前也常常表现不佳。

**结论:** 研究团队发布了TeleMath数据集及评估代码，以促进结果可重复性和支持未来的研究工作。这表明了需要更多专注于特定领域内的数学推理能力的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TeleMath%3A+A+Benchmark+for+Large+Language+Models+in+Telecom+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10674，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10674&send_immediately=true&force_search=false)

**原文摘要:** The increasing adoption of artificial intelligence in telecommunications has
raised interest in the capability of Large Language Models (LLMs) to address
domain-specific, mathematically intensive tasks. Although recent advancements
have improved the performance of LLMs in general mathematical reasoning, their
effectiveness within specialized domains, such as signal processing, network
optimization, and performance analysis, remains largely unexplored. To address
this gap, we introduce TeleMath, the first benchmark dataset specifically
designed to evaluate LLM performance in solving mathematical problems with
numerical solutions in the telecommunications domain. Comprising 500
question-answer (QnA) pairs, TeleMath covers a wide spectrum of topics in the
telecommunications field. This paper outlines the proposed QnAs generation
pipeline, starting from a selected seed of problems crafted by Subject Matter
Experts. The evaluation of a wide range of open-source LLMs reveals that best
performance on TeleMath is achieved by recent models explicitly designed for
mathematical or logical reasoning. In contrast, general-purpose models, even
those with a large number of parameters, often struggle with these challenges.
We have released the dataset and the evaluation code to ease result
reproducibility and support future research.

</details>


### [109] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
*Tom Westermann, Aljosha Köcher, Felix Gehlhoff*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种将AutomationML模型映射到OWL本体并通过大语言模型将文本规则转化为SHACL约束的方法，以实现对建模规则的半自动化检查。


<details>
  <summary>更多</summary>
  
**动机:** 现有的AutomationML建模建议通常以非正式和文本形式表达，不能在AML内部自动验证这些约束条件。

**方法:** 首先通过RML和SPARQL将AML模型映射到OWL本体，然后使用大型语言模型将文本规则转换为SHACL约束，并针对先前生成的AML本体进行验证。最后，SHACL验证结果被自动解释成自然语言。

**结果:** 该方法在一个样本AML建议上进行了演示，结果显示即使是复杂的建模规则也可以进行半自动化检查，而不需要用户理解形式化方法或本体技术。

**结论:** 这项工作提供了一个流程来形式化和验证AutomationML中的约束条件，从而使得复杂建模规则的检查变得更加便捷。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+Validation+of+Textual+Constraints+Against+AutomationML+via+LLMs+and+SHACL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10678，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10678&send_immediately=true&force_search=false)

**原文摘要:** AutomationML (AML) enables standardized data exchange in engineering, yet
existing recommendations for proper AML modeling are typically formulated as
informal and textual constraints. These constraints cannot be validated
automatically within AML itself. This work-in-progress paper introduces a
pipeline to formalize and verify such constraints. First, AML models are mapped
to OWL ontologies via RML and SPARQL. In addition, a Large Language Model
translates textual rules into SHACL constraints, which are then validated
against the previously generated AML ontology. Finally, SHACL validation
results are automatically interpreted in natural language. The approach is
demonstrated on a sample AML recommendation. Results show that even complex
modeling rules can be semi-automatically checked -- without requiring users to
understand formal methods or ontology technologies.

</details>


### [110] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
*Michael Bartholomew, Joohyung Lee*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个名为aspsmt2smt的编译器，它能够将ASPMT程序转换为SMT实例，从而让SMT解算器可以计算ASPMT程序的稳定模型，并且展示了该系统能够有效处理实数计算以推理连续变化。


<details>
  <summary>更多</summary>
  
**动机:** 作者开发了aspsmt2smt编译器来实现从ASPMT到SMT实例的翻译，目的是为了利用SMT解算器的能力来计算ASPMT程序的稳定模型。

**方法:** 使用了ASP grounder gringo和SMT solver z3。gringo部分地对输入程序进行接地，而保留一些变量给z3处理。

**结果:** aspsmt2smt系统能够有效地处理涉及实数的计算，用于推理连续变化的问题。

**结论:** 通过结合ASP和SMT的技术，aspsmt2smt提供了一种新的方式来解决需要考虑连续变化的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是System+ASPMT2SMT%3AComputing+ASPMT+Theories+by+SMT+Solvers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10708，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10708&send_immediately=true&force_search=false)

**原文摘要:** Answer Set Programming Modulo Theories (ASPMT) is an approach to combining
answer set programming and satisfiability modulo theories based on the
functional stable model semantics. It is shown that the tight fragment of ASPMT
programs can be turned into SMT instances, thereby allowing SMT solvers to
compute stable models of ASPMT programs. In this paper we present a compiler
called {\sc aspsmt2smt}, which implements this translation. The system uses ASP
grounder {\sc gringo} and SMT solver {\sc z3}. {\sc gringo} partially grounds
input programs while leaving some variables to be processed by {\sc z3}. We
demonstrate that the system can effectively handle real number computations for
reasoning about continuous changes.

</details>


### [111] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
*Adam Ishay, Zhun Yang, Joohyung Lee, Ilgu Kang, Dongjae Lim*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种利用事件之间因果关系的符号推理来增强神经-符号模型以进行反事实推理的方法，通过定义因果图并在两个基准测试中验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经-符号模型在回答反事实问题方面存在局限性，因此需要一种新的方法来改进神经-符号模型对视频动态进行因果和时间推理的能力。

**方法:** 引入了一种方法，该方法利用事件之间的因果关系的符号推理来增强神经-符号模型，以便更好地处理反事实推理。研究者定义了一个因果图来表示这些关系，并使用答案集编程（ASP）这一声明式逻辑编程方法来协调感知和模拟模块的工作方式。对于CRAFT基准，研究还使用了大型预训练语言模型如GPT-3.5和GPT-4作为动力学模拟器的代理。

**结果:** 所提出的方法在CLEVRER挑战中达到了最先进的性能，显著优于现有模型。此外，在CRAFT基准测试中，通过提供由符号因果推理指导的替代提示，进一步提高了性能。

**结论:** 本研究表明，通过结合符号因果推理与神经感知预测，可以有效提升神经-符号模型解决反事实问题的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think+before+You+Simulate%3A+Symbolic+Reasoning+to+Orchestrate+Neural+Computation+for+Counterfactual+Question+Answering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10753，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10753&send_immediately=true&force_search=false)

**原文摘要:** Causal and temporal reasoning about video dynamics is a challenging problem.
While neuro-symbolic models that combine symbolic reasoning with neural-based
perception and prediction have shown promise, they exhibit limitations,
especially in answering counterfactual questions. This paper introduces a
method to enhance a neuro-symbolic model for counterfactual reasoning,
leveraging symbolic reasoning about causal relations among events. We define
the notion of a causal graph to represent such relations and use Answer Set
Programming (ASP), a declarative logic programming method, to find how to
coordinate perception and simulation modules. We validate the effectiveness of
our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves
state-of-the-art performance on the CLEVRER challenge, significantly
outperforming existing models. In the case of the CRAFT benchmark, we leverage
a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a
dynamics simulator. Our findings show that this method can further improve its
performance on counterfactual questions by providing alternative prompts
instructed by symbolic causal reasoning.

</details>


### [112] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
*Xiaozhe Li, Jixuan Chen, Xinyu Fang, Shengyuan Ding, Haodong Duan, Qingwen Liu, Kai Chen*

**主要类别:** cs.AI

**AI概要:** 研究引入了OPT-BENCH，这是一个全面的基准测试，用于评估大型语言模型（LLMs）在大规模搜索空间优化问题上的表现。该研究还提出了OPT-Agent框架来模拟人类解决复杂问题时的推理过程，并通过实验分析了历史反馈、温度设置和模型架构对解决方案质量和收敛性的影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）在解决各种任务方面展现了卓越的能力，但它们通过学习之前的反馈来迭代优化复杂解决方案的能力尚未得到充分探索。为了填补这一空白，本研究旨在提供一个能够评估LLMs在迭代推理和方案改进能力上的综合基准。

**方法:** 研究者设计了一个名为OPT-BENCH的基准，它包含了20个来自Kaggle的真实世界机器学习任务以及10个经典的NP问题。此外，研究还开发了OPT-Agent，一个端到端的优化框架，该框架模仿人类处理复杂问题时生成、验证并利用历史反馈逐步改进解决方案的过程。

**结果:** 实验结果表明，在机器学习和NP任务中，结合历史上下文可以显著提高优化性能。研究测试了来自6个不同模型家族的9种最先进LLM，分析了优化迭代次数、温度设定及模型结构对于解的质量与收敛速度的影响。

**结论:** 研究结论指出，通过整合历史信息，LLMs在迭代优化中的表现得到了明显提升；这为推动基于LLM的优化及迭代推理研究提供了新的视角。同时，所有数据集、代码和评估工具均已被开源以促进进一步的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OPT-BENCH%3A+Evaluating+LLM+Agent+on+Large-Scale+Search+Spaces+Optimization+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10764，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10764&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have shown remarkable capabilities in solving
diverse tasks. However, their proficiency in iteratively optimizing complex
solutions through learning from previous feedback remains insufficiently
explored. To bridge this gap, we present OPT-BENCH, a comprehensive benchmark
designed to evaluate LLM agents on large-scale search space optimization
problems. OPT-BENCH includes 20 real-world machine learning tasks sourced from
Kaggle and 10 classical NP problems, offering a diverse and challenging
environment for assessing LLM agents on iterative reasoning and solution
refinement. To enable rigorous evaluation, we introduce OPT-Agent, an
end-to-end optimization framework that emulates human reasoning when tackling
complex problems by generating, validating, and iteratively improving solutions
through leveraging historical feedback. Through extensive experiments on 9
state-of-the-art LLMs from 6 model families, we analyze the effects of
optimization iterations, temperature settings, and model architectures on
solution quality and convergence. Our results demonstrate that incorporating
historical context significantly enhances optimization performance across both
ML and NP tasks. All datasets, code, and evaluation tools are open-sourced to
promote further research in advancing LLM-driven optimization and iterative
reasoning. Project page:
\href{https://github.com/OliverLeeXZ/OPT-BENCH}{https://github.com/OliverLeeXZ/OPT-BENCH}.

</details>


### [113] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
*Yu Zhang, Yang Hu, De Wang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种结合思维链推理和模型上下文协议的框架，以提高大语言模型在模拟时空行为方面的能力，并通过上海陆家嘴地区的实验验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于规则和统计的方法在人类时空行为模拟中存在计算成本高、泛化能力有限和可扩展性差的问题，而大型语言模型虽然有潜力作为'世界模拟器'，但在时空推理方面存在局限性。

**方法:** 研究引入了一个集成思维链（CoT）推理与模型上下文协议（MCP）的框架，该框架包含一个五阶段的认知框架以及六类专门的MCP工具：时间管理、空间导航、环境感知、个人记忆、社交协作和经验评估。

**结果:** 在上海陆家嘴地区的1000个生成样本上进行了实验验证，结果表明生成的数据与真实的移动信号数据具有高度相似性，基础模型的质量评分介于7.86到8.36之间。并行处理实验显示效率提升，当进程数从2增加到12时，每样本生成时间从1.30分钟减少到0.17分钟。

**结论:** 本工作促进了CoT推理与MCP在城市行为建模中的整合，推进了大型语言模型在城市计算中的应用，为智能城市规划、交通预测和参与式城市设计提供了实用方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Study+on+Individual+Spatiotemporal+Activity+Generation+Method+Using+MCP-Enhanced+Chain-of-Thought+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10853，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10853&send_immediately=true&force_search=false)

**原文摘要:** Human spatiotemporal behavior simulation is critical for urban planning
research, yet traditional rule-based and statistical approaches suffer from
high computational costs, limited generalizability, and poor scalability. While
large language models (LLMs) show promise as "world simulators," they face
challenges in spatiotemporal reasoning including limited spatial cognition,
lack of physical constraint understanding, and group homogenization tendencies.
This paper introduces a framework integrating chain-of-thought (CoT) reasoning
with Model Context Protocol (MCP) to enhance LLMs' capability in simulating
spatiotemporal behaviors that correspond with validation data patterns. The
methodology combines human-like progressive reasoning through a five-stage
cognitive framework with comprehensive data processing via six specialized MCP
tool categories: temporal management, spatial navigation, environmental
perception, personal memory, social collaboration, and experience evaluation.
Experiments in Shanghai's Lujiazui district validate the framework's
effectiveness across 1,000 generated samples. Results demonstrate high
similarity with real mobile signaling data, achieving generation quality scores
of 7.86 to 8.36 across different base models. Parallel processing experiments
show efficiency improvements, with generation times decreasing from 1.30 to
0.17 minutes per sample when scaling from 2 to 12 processes. This work
contributes to integrating CoT reasoning with MCP for urban behavior modeling,
advancing LLMs applications in urban computing and providing a practical
approach for synthetic mobility data generation. The framework offers a
foundation for smart city planning, transportation forecasting, and
participatory urban design applications.

</details>


### [114] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
*Daniel Borrajo, Giuseppe Canonaco, Tomás de la Rosa, Alfredo Garrachón, Sriram Gopalakrishnan, Simerjot Kaur, Marianela Morales, Sunandita Patra, Alberto Pozanco, Keshav Ramani, Charese Smiley, Pietro Totis, Manuela Veloso*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为GenPlanX的系统，该系统结合了大型语言模型来理解自然语言描述的规划任务，并与经典的人工智能规划引擎以及执行和监控框架相结合。通过辅助办公相关任务展示了其在提高工作效率和促进人机协作方面的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的AI规划技术能够为复杂任务生成动作序列，但无法理解用自然语言描述的规划任务。大型语言模型（LLM）的发展为人机交互带来了新的能力，在理解和解释人类意图方面尤为突出。因此，存在一种动机将LLM的能力与经典的AI规划方法结合起来，以支持更自然的任务说明方式。

**方法:** 提出了一种名为GenPlanX的新系统，它整合了大型语言模型来处理基于自然语言的任务描述，并与一个经典AI规划引擎相连接，同时提供了一个执行和监控框架。

**结果:** GenPlanX被证明在帮助用户完成办公室相关任务时有效，表明其具有简化工作流程和通过无缝的人工智能协作增强生产力的潜力。

**结论:** GenPlanX代表了AI规划领域的一个进步，它利用大型语言模型来桥接自然语言理解与传统AI规划之间的差距，从而促进了更加直观高效的人机协作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GenPlanX.+Generation+of+Plans+and+Execution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10897，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10897&send_immediately=true&force_search=false)

**原文摘要:** Classical AI Planning techniques generate sequences of actions for complex
tasks. However, they lack the ability to understand planning tasks when
provided using natural language. The advent of Large Language Models (LLMs) has
introduced novel capabilities in human-computer interaction. In the context of
planning tasks, LLMs have shown to be particularly good in interpreting human
intents among other uses. This paper introduces GenPlanX that integrates LLMs
for natural language-based description of planning tasks, with a classical AI
planning engine, alongside an execution and monitoring framework. We
demonstrate the efficacy of GenPlanX in assisting users with office-related
tasks, highlighting its potential to streamline workflows and enhance
productivity through seamless human-AI collaboration.

</details>


### [115] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
*Fei Lin, Ziyang Gong, Cong Wang, Yonglin Tian, Tengchao Zhang, Xue Yang, Gen Luo, Fei-Yue Wang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了ToxiMol，这是首个专注于分子毒性修复的基准任务，为多模态大型语言模型（MLLMs）而设计。它包括一个标准化数据集、一个具有机制意识和任务适应能力的提示注解流程，以及一个自动评估框架ToxiEval。尽管当前MLLMs在该任务上面临挑战，但它们开始展示出对毒性理解、语义约束遵循和结构感知分子编辑的有希望的能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管分子设计和性质预测取得了进展，但分子毒性修复的任务——即生成具有较低毒性的结构有效分子替代物——尚未被系统地定义或设立基准。为了填补这一空白，作者们引入了ToxiMol。

**方法:** 创建了一个包含11个主要任务和560个代表有毒分子的标准数据集；设计了一种基于专家毒理学知识的提示注解流程；提出了集成毒性终点预测、合成可及性、药物相似性和结构相似性的自动化评估框架ToxiEval；系统评估了近30个主流通用MLLMs，并进行了多项消融研究来分析关键因素。

**结果:** 实验结果表明，虽然现有的MLLMs在这个任务上仍面临重大挑战，但它们开始显示出对毒性理解、遵守语义约束以及进行结构感知分子编辑方面有潜力的能力。

**结论:** 通过ToxiMol和ToxiEval的建立，为分子毒性修复提供了一个新的基准任务，揭示了当前MLLMs在该领域的潜力与局限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Breaking+Bad+Molecules%3A+Are+MLLMs+Ready+for+Structure-Level+Molecular+Detoxification%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10912&send_immediately=true&force_search=false)

**原文摘要:** Toxicity remains a leading cause of early-stage drug development failure.
Despite advances in molecular design and property prediction, the task of
molecular toxicity repair - generating structurally valid molecular
alternatives with reduced toxicity - has not yet been systematically defined or
benchmarked. To fill this gap, we introduce ToxiMol, the first benchmark task
for general-purpose Multimodal Large Language Models (MLLMs) focused on
molecular toxicity repair. We construct a standardized dataset covering 11
primary tasks and 560 representative toxic molecules spanning diverse
mechanisms and granularities. We design a prompt annotation pipeline with
mechanism-aware and task-adaptive capabilities, informed by expert
toxicological knowledge. In parallel, we propose an automated evaluation
framework, ToxiEval, which integrates toxicity endpoint prediction, synthetic
accessibility, drug-likeness, and structural similarity into a high-throughput
evaluation chain for repair success. We systematically assess nearly 30
mainstream general-purpose MLLMs and design multiple ablation studies to
analyze key factors such as evaluation criteria, candidate diversity, and
failure attribution. Experimental results show that although current MLLMs
still face significant challenges on this task, they begin to demonstrate
promising capabilities in toxicity understanding, semantic constraint
adherence, and structure-aware molecule editing.

</details>


### [116] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
*Rulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer*

**主要类别:** cs.AI

**AI概要:** 研究发现，即使在奖励信号与正确答案相关性很小、没有甚至为负的情况下，强化学习与可验证奖励（RLVR）也能在某些模型中激发强大的数学推理能力。尤其对于Qwen2.5-Math-7B模型，使用随机或误导性的奖励信号后，其MATH-500性能得到显著提升。然而，这些奖励信号并不适用于所有模型家族。


<details>
  <summary>更多</summary>
  
**动机:** 探索强化学习与可验证奖励(RLVR)是否能够在缺乏有用奖励信号的情况下仍然促进模型的数学推理能力，并且这种能力是否普遍适用于不同的模型家族。

**方法:** 采用不同类型的奖励信号（包括随机奖励、格式奖励、错误标签等）对Qwen2.5-Math-7B等特定模型进行RLVR训练，并比较它们在MATH-500任务上的表现变化。此外还观察了代码推理行为的变化情况。

**结果:** 结果表明，在给定各种非真实的奖励条件下，Qwen2.5-Math-7B模型的MATH-500成绩有了显著提高；同时，该模型展示出更加频繁地运用代码思考方式解决问题的趋势。不过，同样的方法并没有给其他模型家族带来相似的好处。

**结论:** 研究表明，即便是在缺少有效奖励信号的情况下，RLVR也能够激发出模型预训练期间学到的有效推理表示。未来的研究应该考虑在更多样化的模型上验证RLVR的效果，因为目前看来，仅针对Qwen模型就很容易通过完全无关的奖励信号获得性能大幅提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spurious+Rewards%3A+Rethinking+Training+Signals+in+RLVR，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10947，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10947&send_immediately=true&force_search=false)

**原文摘要:** We show that reinforcement learning with verifiable rewards (RLVR) can elicit
strong mathematical reasoning in certain models even with spurious rewards that
have little, no, or even negative correlation with the correct answer. For
example, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolute
points by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrect
label), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the
29.1% gained with ground truth rewards. However, the spurious rewards that work
for Qwen often fail to yield gains with other model families like Llama3 or
OLMo2. In particular, we find code reasoning -- thinking in code without actual
code execution -- to be a distinctive Qwen2.5-Math behavior that becomes
significantly more frequent after RLVR, from 65% to over 90%, even with
spurious rewards. Overall, we hypothesize that, given the lack of useful reward
signal, RLVR must somehow be surfacing useful reasoning representations learned
during pretraining, although the exact mechanism remains a topic for future
work. We suggest that future RLVR research should possibly be validated on
diverse models rather than a single de facto choice, as we show that it is easy
to get significant performance gains on Qwen models even with completely
spurious reward signals.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [117] [Fundamental Limits of Learning High-dimensional Simplices in Noisy Regimes](https://arxiv.org/abs/2506.10101)
*Seyed Amir Hossein Saberi, Amir Najafi, Abolfazl Motahari, Babak H. khalaj*

**主要类别:** stat.ML

**AI概要:** 本文研究了从带有噪声的数据中学习高维单纯形的样本复杂度，并证明了在一定条件下，存在一个算法可以以高概率输出与真实单纯形距离不超过ε的估计单纯形。此外，还提出了新的信息论下界，并引入了一种基于傅里叶的新方法来从噪声观测中恢复分布。


<details>
  <summary>更多</summary>
  
**动机:** 动机在于理解和量化在有噪声的情况下，从数据中学习高维单纯形所需的样本数量。

**方法:** 使用样本压缩技术，并引入了一种基于傅里叶变换的方法来处理噪声数据，从而能够从噪声观测值中恢复分布。

**结果:** 证明了当信噪比达到某个阈值时，带噪声情况下的样本复杂度与无噪声情况下的一致；同时给出了学习单纯形的信息论下界。

**结论:** 研究表明，对于给定的维度K和误差ε，如果信噪比足够大，则可以从噪声数据中有效学习到高维单纯形。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fundamental+Limits+of+Learning+High-dimensional+Simplices+in+Noisy+Regimes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10101，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10101&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we establish sample complexity bounds for learning
high-dimensional simplices in $\mathbb{R}^K$ from noisy data. Specifically, we
consider $n$ i.i.d. samples uniformly drawn from an unknown simplex in
$\mathbb{R}^K$, each corrupted by additive Gaussian noise of unknown variance.
We prove an algorithm exists that, with high probability, outputs a simplex
within $\ell_2$ or total variation (TV) distance at most $\varepsilon$ from the
true simplex, provided $n \ge (K^2/\varepsilon^2)
e^{\mathcal{O}(K/\mathrm{SNR}^2)}$, where $\mathrm{SNR}$ is the signal-to-noise
ratio. Extending our prior work~\citep{saberi2023sample}, we derive new
information-theoretic lower bounds, showing that simplex estimation within TV
distance $\varepsilon$ requires at least $n \ge \Omega(K^3
\sigma^2/\varepsilon^2 + K/\varepsilon)$ samples, where $\sigma^2$ denotes the
noise variance. In the noiseless scenario, our lower bound $n \ge
\Omega(K/\varepsilon)$ matches known upper bounds up to constant factors. We
resolve an open question by demonstrating that when $\mathrm{SNR} \ge
\Omega(K^{1/2})$, noisy-case complexity aligns with the noiseless case. Our
analysis leverages sample compression techniques (Ashtiani et al., 2018) and
introduces a novel Fourier-based method for recovering distributions from noisy
observations, potentially applicable beyond simplex learning.

</details>


### [118] [Momentum Multi-Marginal Schrödinger Bridge Matching](https://arxiv.org/abs/2506.10168)
*Panagiotis Theodoropoulos, Augustinos D. Saravanos, Evangelos A. Theodorou, Guan-Horng Liu*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种新的匹配框架3MSBM，用于学习满足多个位置约束的随机系统的平滑测度值样条，并通过将动力学提升到相空间和泛化条件为多点的随机桥梁来实现。该方法在一系列实际应用中表现出优于现有方法的性能，特别是在捕捉具有时间依赖性的复杂动态方面。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Bridge和Flow匹配框架依赖于相邻快照之间的成对插值，这限制了它们捕获长程时间依赖性以及可能影响推断轨迹连贯性的能力。

**方法:** 提出了Momentum Multi-Marginal Schrödinger Bridge Matching (3MSBM)框架，通过将动力学提升至相空间并泛化为基于多个点条件的随机桥，形成一个多边际条件随机最优控制问题。

**结果:** 通过广泛的实验验证，在真实世界的应用中，3MSBM在捕捉具有时间依赖性的复杂动态方面相较于现有方法展现出了优越的性能。

**结论:** 3MSBM作为一种新的匹配框架，能够更好地处理多边际设置下的训练问题，并且在保持中间边际的同时提高了收敛性和可扩展性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Momentum+Multi-Marginal+Schr%C3%B6dinger+Bridge+Matching，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10168，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10168&send_immediately=true&force_search=false)

**原文摘要:** Understanding complex systems by inferring trajectories from sparse sample
snapshots is a fundamental challenge in a wide range of domains, e.g.,
single-cell biology, meteorology, and economics. Despite advancements in Bridge
and Flow matching frameworks, current methodologies rely on pairwise
interpolation between adjacent snapshots. This hinders their ability to capture
long-range temporal dependencies and potentially affects the coherence of the
inferred trajectories. To address these issues, we introduce \textbf{Momentum
Multi-Marginal Schr\"odinger Bridge Matching (3MSBM)}, a novel matching
framework that learns smooth measure-valued splines for stochastic systems that
satisfy multiple positional constraints. This is achieved by lifting the
dynamics to phase space and generalizing stochastic bridges to be conditioned
on several points, forming a multi-marginal conditional stochastic optimal
control problem. The underlying dynamics are then learned by minimizing a
variational objective, having fixed the path induced by the multi-marginal
conditional bridge. As a matching approach, 3MSBM learns transport maps that
preserve intermediate marginals throughout training, significantly improving
convergence and scalability. Extensive experimentation in a series of
real-world applications validates the superior performance of 3MSBM compared to
existing methods in capturing complex dynamics with temporal dependencies,
opening new avenues for training matching frameworks in multi-marginal
settings.

</details>


### [119] [Distributionally-Constrained Adversaries in Online Learning](https://arxiv.org/abs/2506.10293)
*Moïse Blanchard, Samory Kpotufe*

**主要类别:** stat.ML

**AI概要:** 本文探讨了在线学习中从对抗性到随机性设置的连续统一体，通过引入分布约束对手这一更通用和灵活的框架来填补两者之间的空白。研究了哪些分布类在这种情况下是可学习的，并且发现对于一些自然函数类，包括线性分类器，可以在没有先验知识的情况下实现学习。


<details>
  <summary>更多</summary>
  
**动机:** 为了更好地理解在线学习中从完全随机到完全对抗环境的学习设定，文章提出了一种新的框架，即分布约束对手，以期对介于两者之间的学习场景有一个细致的理解。

**方法:** 作者们定义并分析了分布约束对手的框架，在这种框架下实例是从由对手在某些受约束的分布类中选择的分布抽取的。他们对什么样的分布类在这个上下文中是对抗性（无论是否具有适应性）对手可学习的进行了表征。

**结果:** 结果表明，该方法能够恢复并推广已知平滑设定下的可学习性。此外，研究还显示，对于诸如线性分类器等自然函数类，即使没有关于分布类的任何先验知识，也可以实现学习。

**结论:** 结论是，通过使用分布约束对手的框架，可以对在线学习中的不同设定提供更细致的理解，并且在某些条件下，学习者能够在不知道具体分布约束的情况下与各种受限对手竞争。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distributionally-Constrained+Adversaries+in+Online+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10293，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10293&send_immediately=true&force_search=false)

**原文摘要:** There has been much recent interest in understanding the continuum from
adversarial to stochastic settings in online learning, with various frameworks
including smoothed settings proposed to bridge this gap. We consider the more
general and flexible framework of distributionally constrained adversaries in
which instances are drawn from distributions chosen by an adversary within some
constrained distribution class [RST11]. Compared to smoothed analysis, we
consider general distributional classes which allows for a fine-grained
understanding of learning settings between fully stochastic and fully
adversarial for which a learner can achieve non-trivial regret. We give a
characterization for which distribution classes are learnable in this context
against both oblivious and adaptive adversaries, providing insights into the
types of interplay between the function class and distributional constraints on
adversaries that enable learnability. In particular, our results recover and
generalize learnability for known smoothed settings. Further, we show that for
several natural function classes including linear classifiers, learning can be
achieved without any prior knowledge of the distribution class -- in other
words, a learner can simultaneously compete against any constrained adversary
within learnable distribution classes.

</details>


### [120] [Measuring Semantic Information Production in Generative Diffusion Models](https://arxiv.org/abs/2506.10433)
*Florian Handke, Félix Koulischer, Gabriel Raya, Luca Ambrogioni*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种基于信息论的方法来衡量在生成过程中何时作出类语义的'决策'。通过使用最优贝叶斯分类器的在线公式，估计了给定噪声状态下的类标签条件熵，并确定了噪声状态与类标签之间信息传递最大的时间间隔。该方法应用于一维高斯混合模型和CIFAR10数据集上的DDPM模型。结果表明，在扩散过程的中间阶段语义信息传递最强，而在最终阶段消失；不同类别的熵率曲线存在显著差异，表明不同的'语义决策'发生在不同的中间时间点。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在量化在图像生成的逆向动力学过程中，类语义特征何时出现。这种现象与磁体和其他材料中的物理相变有关。

**方法:** 采用一种新的信息论方法，利用最优贝叶斯分类器的在线公式来估计给定噪声状态下类标签的条件熵。然后，通过对条件熵的时间导数，找出噪声状态与类标签间信息传输最高的时间间隔。

**结果:** 实验结果表明，在扩散过程的中间阶段观察到最高的语义信息转移，而在最后阶段则几乎消失。此外，还发现不同类别的熵率分布有明显差异，意味着不同的'语义决策'发生在不同的时间点上。

**结论:** 本研究提供了一个有效的方法来识别在扩散模型生成过程中关键的语义决策时刻。这些发现有助于更好地理解扩散模型中语义信息的发展，并可能为改进生成模型的设计提供指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+Semantic+Information+Production+in+Generative+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10433&send_immediately=true&force_search=false)

**原文摘要:** It is well known that semantic and structural features of the generated
images emerge at different times during the reverse dynamics of diffusion, a
phenomenon that has been connected to physical phase transitions in magnets and
other materials. In this paper, we introduce a general information-theoretic
approach to measure when these class-semantic "decisions" are made during the
generative process. By using an online formula for the optimal Bayesian
classifier, we estimate the conditional entropy of the class label given the
noisy state. We then determine the time intervals corresponding to the highest
information transfer between noisy states and class labels using the time
derivative of the conditional entropy. We demonstrate our method on
one-dimensional Gaussian mixture models and on DDPM models trained on the
CIFAR10 dataset. As expected, we find that the semantic information transfer is
highest in the intermediate stages of diffusion while vanishing during the
final stages. However, we found sizable differences between the entropy rate
profiles of different classes, suggesting that different "semantic decisions"
are located at different intermediate times.

</details>


### [121] [Box-Constrained Softmax Function and Its Application for Post-Hoc Calibration](https://arxiv.org/abs/2506.10572)
*Kyohei Atarashi, Satoshi Oyama, Hiromi Arai, Hisashi Kashima*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种新的Softmax函数的泛化形式——box-constrained softmax (BCSoftmax)，它能够在输出概率上施加硬性上下界约束，从而增强模型在预测时的可靠性和可信度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Softmax函数虽然可以通过温度参数进行软控制，但不能对输出概率实施硬性约束（如边界约束），这在某些需要可靠和可信赖模型的应用中是至关重要的。

**方法:** 提出了box-constrained softmax (BCSoftmax) 函数，它是传统Softmax函数的一种新颖泛化，能够明确地对输出概率设置下限和上限。为BCSoftmax开发了一个精确且高效的计算算法，并基于此引入了两种后处理校准方法来缓解模型预测中的欠自信和过自信问题。

**结果:** 通过实验展示了所提方法的有效性，在TinyImageNet、CIFAR-100以及20NewsGroups数据集上取得了校准指标上的改进。

**结论:** BCSoftmax及其衍生出的校准方法能够有效提升模型输出概率的可靠性，对于需要高置信度决策的任务具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Box-Constrained+Softmax+Function+and+Its+Application+for+Post-Hoc+Calibration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10572，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10572&send_immediately=true&force_search=false)

**原文摘要:** Controlling the output probabilities of softmax-based models is a common
problem in modern machine learning. Although the $\mathrm{Softmax}$ function
provides soft control via its temperature parameter, it lacks the ability to
enforce hard constraints, such as box constraints, on output probabilities,
which can be critical in certain applications requiring reliable and
trustworthy models. In this work, we propose the box-constrained softmax
($\mathrm{BCSoftmax}$) function, a novel generalization of the
$\mathrm{Softmax}$ function that explicitly enforces lower and upper bounds on
output probabilities. While $\mathrm{BCSoftmax}$ is formulated as the solution
to a box-constrained optimization problem, we develop an exact and efficient
computation algorithm for $\mathrm{BCSoftmax}$. As a key application, we
introduce two post-hoc calibration methods based on $\mathrm{BCSoftmax}$. The
proposed methods mitigate underconfidence and overconfidence in predictive
models by learning the lower and upper bounds of the output probabilities or
logits after model training, thereby enhancing reliability in downstream
decision-making tasks. We demonstrate the effectiveness of our methods
experimentally using the TinyImageNet, CIFAR-100, and 20NewsGroups datasets,
achieving improvements in calibration metrics.

</details>


### [122] [Logarithmic Smoothing for Adaptive PAC-Bayesian Off-Policy Learning](https://arxiv.org/abs/2506.10664)
*Maxime Haddouche, Otmane Sakhi*

**主要类别:** stat.ML

**AI概要:** 本文研究了自适应离策略学习，这是一种更实用和灵活的框架，通过迭代改进策略并重新部署以收集更高质量的数据。基于PAC-贝叶斯学习与对数平滑在静态设置中的成功，我们将该框架扩展到自适应场景，并证明了对LS估计器进行有原则的调整可以自然地适应多轮部署并在温和条件下提供更快的收敛速度。


<details>
  <summary>更多</summary>
  
**动机:** 传统的离策略学习主要依赖于从静态行为策略下收集的日志交互中学习最优策略。而本文旨在探索一个更为实用且灵活的方法，即自适应离策略学习，其中涉及迭代地精炼政策并重新部署来获取质量更高的数据。

**方法:** 作者们借鉴了PAC-贝叶斯学习结合对数平滑方法在固定环境下的成功经验，将此框架拓展到了动态适应性情景中，并利用在线PAC-贝叶斯理论工具。此外，他们展示了一种针对LS估计量的原则性调节能够很好地支持多次部署，并能在一定条件下加速收敛过程。

**结果:** 所提出的方法在静态环境下能与领先的离线方法相媲美，而在允许中间政策部署的情况下表现则显著优于这些方法。跨多种场景的实证评估突出了自适应数据收集的优势以及PAC-贝叶斯公式化方法的力量。

**结论:** 这项工作为自适应离策略学习提供了新的视角，表明了适当调整后的PAC-贝叶斯方法不仅能够适用于多轮次的策略部署，而且在某些情况下还能加快学习速度，从而在实际应用中展现出巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Logarithmic+Smoothing+for+Adaptive+PAC-Bayesian+Off-Policy+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10664，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10664&send_immediately=true&force_search=false)

**原文摘要:** Off-policy learning serves as the primary framework for learning optimal
policies from logged interactions collected under a static behavior policy. In
this work, we investigate the more practical and flexible setting of adaptive
off-policy learning, where policies are iteratively refined and re-deployed to
collect higher-quality data. Building on the success of PAC-Bayesian learning
with Logarithmic Smoothing (LS) in static settings, we extend this framework to
the adaptive scenario using tools from online PAC-Bayesian theory. Furthermore,
we demonstrate that a principled adjustment to the LS estimator naturally
accommodates multiple rounds of deployment and yields faster convergence rates
under mild conditions. Our method matches the performance of leading offline
approaches in static settings, and significantly outperforms them when
intermediate policy deployments are allowed. Empirical evaluations across
diverse scenarios highlight both the advantages of adaptive data collection and
the strength of the PAC-Bayesian formulation.

</details>


### [123] [Practical Improvements of A/B Testing with Off-Policy Estimation](https://arxiv.org/abs/2506.10677)
*Sakhi Otmane, Gilotte Alexandre, Rohde David*

**主要类别:** stat.ML

**AI概要:** 本文针对A/B测试中常用的均值差估计量提出了改进方法，引入了一组无偏的离线策略估计量，这些估计量具有更低的方差，并从中识别出方差最低的估计量。该估计量简单且在两个测试系统相似时能显著降低方差。理论分析和实验结果验证了所提方法的有效性和实用性。


<details>
  <summary>更多</summary>
  
**动机:** 本文旨在解决A/B测试协议中存在的问题，即如何更准确地评估新决策系统相对于基线系统的潜在改进。作者指出，虽然常用的均值差估计量是无偏的，但其存在改进空间。

**方法:** 文章提出了一类新的无偏离线策略估计量，它们比标准的方法具有更低的方差。在这一类估计量中，作者找到了方差最小的那个。

**结果:** 研究结果表明，当两个被测系统表现出相似性时，所提出的估计量能够提供实质性的方差减少。

**结论:** 通过理论分析与实证研究，证明了所提议的估计量不仅有效，而且在实践中也是可行的，从而为A/B测试提供了一个更优的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Practical+Improvements+of+A%2FB+Testing+with+Off-Policy+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10677，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10677&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of A/B testing, a widely used protocol for evaluating
the potential improvement achieved by a new decision system compared to a
baseline. This protocol segments the population into two subgroups, each
exposed to a version of the system and estimates the improvement as the
difference between the measured effects. In this work, we demonstrate that the
commonly used difference-in-means estimator, while unbiased, can be improved.
We introduce a family of unbiased off-policy estimators that achieves lower
variance than the standard approach. Among this family, we identify the
estimator with the lowest variance. The resulting estimator is simple, and
offers substantial variance reduction when the two tested systems exhibit
similarities. Our theoretical analysis and experimental results validate the
effectiveness and practicality of the proposed method.

</details>


### [124] [Demystifying Spectral Feature Learning for Instrumental Variable Regression](https://arxiv.org/abs/2506.10899)
*Dimitri Meunier, Antoine Moulin, Jakub Wornbard, Vladimir R. Kostic, Arthur Gretton*

**主要类别:** stat.ML

**AI概要:** 本文研究了存在隐藏混淆变量时使用非参数工具变量回归估计因果效应的问题，通过谱特征来进行两阶段最小二quares估计，并且分析了方法表现和失败模式的关键因素。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决在存在未观察到的混杂因素的情况下进行因果效应估计的问题，作者们采用了非参数工具变量回归的方法。

**方法:** 采用谱特征（即跨越处理与工具变量之间算子的顶级特征子空间的学习特征）的两阶段最小二乘法估计器来估计因果效应，并推导出其泛化误差界。

**结果:** 研究表明方法的表现取决于两个关键因素：谱对齐程度和条件算子的特征值衰减速率。根据这两个因素，结果可以分为好、坏和丑三种情况。

**结论:** 该方法在良好的情况下是最佳的，在不良情况下需要更多的样本量来学习有效的特征，而在最差的情况下，即使特征值特性良好，弱谱对齐也会导致方法失效。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Demystifying+Spectral+Feature+Learning+for+Instrumental+Variable+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10899&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of causal effect estimation in the presence of hidden
confounders, using nonparametric instrumental variable (IV) regression. A
leading strategy employs spectral features - that is, learned features spanning
the top eigensubspaces of the operator linking treatments to instruments. We
derive a generalization error bound for a two-stage least squares estimator
based on spectral features, and gain insights into the method's performance and
failure modes. We show that performance depends on two key factors, leading to
a clear taxonomy of outcomes. In a good scenario, the approach is optimal. This
occurs with strong spectral alignment, meaning the structural function is
well-represented by the top eigenfunctions of the conditional operator, coupled
with this operator's slow eigenvalue decay, indicating a strong instrument.
Performance degrades in a bad scenario: spectral alignment remains strong, but
rapid eigenvalue decay (indicating a weaker instrument) demands significantly
more samples for effective feature learning. Finally, in the ugly scenario,
weak spectral alignment causes the method to fail, regardless of the
eigenvalues' characteristics. Our synthetic experiments empirically validate
this taxonomy.

</details>


### [125] [Probably Approximately Correct Labels](https://arxiv.org/abs/2506.10908)
*Emmanuel J. Candès, Andrew Ilyas, Tijana Zrnic*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种方法，通过结合预训练模型的AI预测和专家标注来更经济地构建高质量标记数据集。该方法在文本、图像和蛋白质折叠分析上都展示了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 获取高质量标记数据集通常成本很高，需要大量的人工标注或昂贵的实验。

**方法:** 作者提出的方法是利用预训练模型的AI预测来补充“专家”标签，从而以较低的成本构建标记数据集。

**结果:** 这种方法可以产生大概率正确的标签，并且在文本注释、图像标记以及使用AlphaFold进行蛋白质折叠分析中得到了验证。

**结论:** 该解决方案允许使用现代AI模型实现严格而有效的数据集管理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Probably+Approximately+Correct+Labels，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10908&send_immediately=true&force_search=false)

**原文摘要:** Obtaining high-quality labeled datasets is often costly, requiring either
extensive human annotation or expensive experiments. We propose a method that
supplements such "expert" labels with AI predictions from pre-trained models to
construct labeled datasets more cost-effectively. Our approach results in
probably approximately correct labels: with high probability, the overall
labeling error is small. This solution enables rigorous yet efficient dataset
curation using modern AI models. We demonstrate the benefits of the methodology
through text annotation with large language models, image labeling with
pre-trained vision models, and protein folding analysis with AlphaFold.

</details>


### [126] [What Exactly Does Guidance Do in Masked Discrete Diffusion Models](https://arxiv.org/abs/2506.10971)
*He Ye, Rojas Kevin, Tao Molei*

**主要类别:** stat.ML

**AI概要:** 本文研究了带有无分类器指导的掩码离散扩散模型，得出了引导反向动力学的显式解，并分析了指导如何影响采样行为。研究还发现了一维和二维中不同的行为以及在大权重w下总变差衰减速率呈双指数关系。实验支持了理论分析。


<details>
  <summary>更多</summary>
  
**动机:** 为了理解无分类器指导(CFG)在掩码离散扩散模型中的作用，以及它如何精确地影响采样行为。

**方法:** 通过假设没有分数误差也没有离散化误差，推导出有指导反向动态过程的显式解。

**结果:** 研究表明，指导会放大特定类别的区域同时抑制与其他类别共享的区域；在不同维度（1D 和 2D）上观察到定量上的不同行为；对于较大的权重w，沿反向动态过程的总变差(TV)衰减率在一维和二维中都是关于w的双指数函数。

**结论:** 无分类器指导不仅在塑造输出分布方面发挥作用，还在控制采样轨迹的动力学方面起着重要作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Exactly+Does+Guidance+Do+in+Masked+Discrete+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.10971，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.10971&send_immediately=true&force_search=false)

**原文摘要:** We study masked discrete diffusion models with classifier-free guidance
(CFG). Assuming no score error nor discretization error, we derive an explicit
solution to the guided reverse dynamics, so that how guidance influences the
sampling behavior can be precisely characterized. When the full data
distribution is a mixture over classes and the goal is to sample from a
specific class, guidance amplifies class-specific regions while suppresses
regions shared with other classes. This effect depends on the guidance strength
$w$ and induces distinct covariance structures in the sampled distribution.
Notably, we observe quantitatively different behaviors in $1$D and $2$D. We
also show that for large $w$, the decay rate of the total variation
($\mathrm{TV}$) along the reverse dynamics is double-exponential in $w$ for
both $1$D and $2$D. These findings highlight the role of guidance, not just in
shaping the output distribution, but also in controlling the dynamics of the
sampling trajectory. Our theoretical analysis is supported by experiments that
illustrate the geometric effects of guidance and its impact on convergence.

</details>
