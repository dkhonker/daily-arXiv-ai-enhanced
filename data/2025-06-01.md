<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 163]
- [cs.AI](#cs.AI) [总数: 37]
- [stat.ML](#stat.ML) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs](https://arxiv.org/abs/2505.22686)
*Ange-Clement Akazan, Verlon Roel Mbingui, Gnankan Landry Regis N'guessan, Issa Karambal*

**主要类别:** cs.LG

**AI概要:** 本研究评估了多种深度学习模型在热带城市天气预测中的性能，并提出了改进的 TKAN 变体，在温度和降水预测方面取得了优异结果，同时展示了基于样条的神经架构在气象预报中的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 热带非洲地区的极端天气事件对居民生计造成严重影响，但现有的天气预测方法在应对该地区复杂的非线性天气模式时存在困难。因此，本文旨在探索更有效的预测模型以提升预报能力。

**方法:** 该研究通过基准测试深度递归神经网络（如 LSTM、GRU、BiLSTM、BiGRU）以及 Kolmogorov-Arnold 基模型（KAN 和 TKAN），并引入了两种定制化的 TKAN 变体（使用 GeLU 和 MiSH 激活函数）。评估基于 2010 至 2024 年的气象站数据，使用标准回归指标进行分析。

**结果:** 实验结果显示，KAN 模型在温度预测中取得了极高的 R² 分数（Abidjan 为 0.9986，Kigali 为 0.9998），MSE 非常低（< 0.0014°C²）。TKAN 的变体在降水预测中降低了绝对误差，尤其是在低降雨量环境下。传统的 RNN 在气压预测中表现良好（R² 约为 0.83-0.86），超过了基于 KAN 的模型。

**结论:** 论文得出结论，基于样条的神经架构在天气预测中具有潜力，特别是在数据效率和有效性方面。KAN 模型在温度预测上表现优异，而 TKAN 变体则在低降雨量区域的降水预报中表现出优势。传统的 RNN 在气压预测任务中仍然具有竞争力，并优于 KAN 基模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Localized+Weather+Prediction+Using+Kolmogorov-Arnold+Network-Based+Models+and+Deep+RNNs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22686&send_immediately=true&force_search=false)

**原文摘要:** Weather forecasting is crucial for managing risks and economic planning,
particularly in tropical Africa, where extreme events severely impact
livelihoods. Yet, existing forecasting methods often struggle with the region's
complex, non-linear weather patterns. This study benchmarks deep recurrent
neural networks such as $\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and
Kolmogorov-Arnold-based models $(\texttt{KAN} and \texttt{TKAN})$ for daily
forecasting of temperature, precipitation, and pressure in two tropical cities:
Abidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce
two customized variants of $ \texttt{TKAN}$ that replace its original
$\texttt{SiLU}$ activation function with $ \texttt{GeLU}$ and \texttt{MiSH},
respectively. Using station-level meteorological data spanning from 2010 to
2024, we evaluate all the models on standard regression metrics. $\texttt{KAN}$
achieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,
$\texttt{MSE} < 0.0014~^\circ C ^2$), while $\texttt{TKAN}$ variants minimize
absolute errors for precipitation forecasting in low-rainfall regimes. The
customized $\texttt{TKAN}$ models demonstrate improvements over the standard
$\texttt{TKAN}$ across both datasets. Classical \texttt{RNNs} remain highly
competitive for atmospheric pressure ($R^2 \approx 0.83{-}0.86$), outperforming
$\texttt{KAN}$-based models in this task. These results highlight the potential
of spline-based neural architectures for efficient and data-efficient
forecasting.

</details>


### [2] [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org/abs/2505.22689)
*Jialong Guo, Xinghao Chen, Yehui Tang, Yunhe Wang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的结构化剪枝方法SlimLLM，用于有效压缩大型语言模型，在LLaMA基准测试中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 由于大型语言模型的计算成本巨大，其部署和应用常常受到严重限制，因此需要一种有效的参数压缩解决方案。

**方法:** 通过评估整个通道或注意力头的重要性，而非仅仅聚合子模块内单个元素的重要性，并设计了一种简单的线性回归策略来快速恢复性能，同时提出了基于层的重要性比例来确定每层的剪枝比例。

**结果:** 基于LLaMA基准测试的结果显示，所提出的SlimLLM方法在性能上超过了其他方法并达到了最先进的表现。

**结论:** 本文提出了一种名为SlimLLM的结构化剪枝方法，用于压缩大型语言模型的参数，并在LLaMA基准测试中取得了优于其他方法的结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SlimLLM%3A+Accurate+Structured+Pruning+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22689，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22689&send_immediately=true&force_search=false)

**原文摘要:** Large language models(LLMs) have garnered significant attention and
demonstrated impressive capabilities in a wide range of applications. However,
due to their enormous computational costs, the deployment and application of
LLMs are often severely limited. To address this issue, structured pruning is
an effective solution to compress the parameters of LLMs. Determining the
importance of each sub-module in LLMs and minimizing performance loss are
critical issues that need to be carefully addressed in structured pruning. In
this paper, we propose an effective and fast structured pruning method named
SlimLLM for large language models. For channel and attention head pruning, we
evaluate the importance based on the entire channel or head, rather than merely
aggregating the importance of individual elements within a sub-module. This
approach enables a more holistic consideration of the interdependence among
elements within the sub-module. In addition, we design a simple linear
regression strategy for the output matrix to quickly recover performance. We
also propose layer-based importance ratio to determine the pruning ratio for
each layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other
methods and achieves state-of-the-art performance.

</details>


### [3] [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org/abs/2505.22694)
*Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种用于多任务参数高效微调的新方法MoRE，该方法通过结合不同低秩专家和自适应选择机制，在不增加额外推理成本的情况下显著提升大型语言模型在多任务场景下的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的LoRA方法在多任务场景下效率和效果受限，因为它们要么专注于单任务场景，要么分别为每个任务训练多个LoRA模块。

**方法:** 提出了一种名为Mixture of Low-Rank Experts (MoRE)的新方法，通过为不同任务分配不同的低秩专家以及设计自适应的专家选择器来改进现有的LoRA方法。

**结果:** 实验结果显示，与传统LoRA及其变体相比，MoRE在多个多任务基准测试中显著提升了模型性能。

**结论:** MoRE显著提高了大型语言模型在多任务场景下的表现，同时没有增加推理成本，并且已经开源模型和代码以促进社区发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoRE%3A+A+Mixture+of+Low-Rank+Experts+for+Adaptive+Multi-Task+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22694，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22694&send_immediately=true&force_search=false)

**原文摘要:** With the rapid development of Large Language Models (LLMs),
Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant
attention, which aims to achieve efficient fine-tuning of LLMs with fewer
parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)
introduces low-rank matrices to approximate the incremental tuning parameters
and achieves impressive performance over multiple scenarios. After that, plenty
of improvements have been proposed for further improvement. However, these
methods either focus on single-task scenarios or separately train multiple LoRA
modules for multi-task scenarios, limiting the efficiency and effectiveness of
LoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in
this paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for
multi-task PEFT. Specifically, instead of using an individual LoRA for each
task, we align different ranks of LoRA module with different tasks, which we
named low-rank experts. Moreover, we design a novel adaptive rank selector to
select the appropriate expert for each task. By jointly training low-rank
experts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task
scenarios. Finally, we conduct extensive experiments over multiple multi-task
benchmarks along with different LLMs to verify model performance. Experimental
results demonstrate that compared to traditional LoRA and its variants, MoRE
significantly improves the performance of LLMs in multi-task scenarios and
incurs no additional inference cost. We also release the model and code to
facilitate the community.

</details>


### [4] [LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning](https://arxiv.org/abs/2505.22695)
*Tengfei Lyu, Siyuan Feng, Hao Liu, Hai Yang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于大语言模型的网约车订单调度与司机重定位新方法，在多个关键指标上优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 传统方法在处理动态城市环境中的网约车调度时，忽略了收入公平性、可解释性和适应性，需要一种更优的方法解决这些问题。

**方法:** 提出了LLM-ODDR框架，包含多目标订单价值优化、公平感知的订单分配和时空需求感知的司机重定位三个部分，并开发了JointDR-GPT模型进行优化。

**结果:** 实验结果显示LLM-ODDR在有效性、异常条件适应性和决策可解释性方面显著优于传统方法。

**结论:** LLM-ODDR框架在处理网约车订单调度和司机重新定位问题上表现优异，证明了大型语言模型在智能交通系统中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-ODDR%3A+A+Large+Language+Model+Framework+for+Joint+Order+Dispatching+and+Driver+Repositioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22695，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22695&send_immediately=true&force_search=false)

**原文摘要:** Ride-hailing platforms face significant challenges in optimizing order
dispatching and driver repositioning operations in dynamic urban environments.
Traditional approaches based on combinatorial optimization, rule-based
heuristics, and reinforcement learning often overlook driver income fairness,
interpretability, and adaptability to real-world dynamics. To address these
gaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models
(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in
ride-hailing services. LLM-ODDR framework comprises three key components: (1)
Multi-objective-guided Order Value Refinement, which evaluates orders by
considering multiple objectives to determine their overall value; (2)
Fairness-aware Order Dispatching, which balances platform revenue with driver
income fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,
which optimizes idle vehicle placement based on historical patterns and
projected supply. We also develop JointDR-GPT, a fine-tuned model optimized for
ODDR tasks with domain knowledge. Extensive experiments on real-world datasets
from Manhattan taxi operations demonstrate that our framework significantly
outperforms traditional methods in terms of effectiveness, adaptability to
anomalous conditions, and decision interpretability. To our knowledge, this is
the first exploration of LLMs as decision-making agents in ride-hailing ODDR
tasks, establishing foundational insights for integrating advanced language
models within intelligent transportation systems.

</details>


### [5] [When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?](https://arxiv.org/abs/2505.22696)
*Eleni Nisioti, Joachim Winther Pedersen, Erwan Plantec, Milton L. Montero, Sebastian Risi*

**主要类别:** cs.LG

**AI概要:** 本研究探讨了神经进化在迁移学习中的潜力，通过新设计的基准测试验证其优于传统强化学习方法，并指出了未来挑战。


<details>
  <summary>更多</summary>
  
**动机:** 生物智能的一个显著特点是能够在任务间持续高效迁移技能，而人工系统长期以来也追求这一目标。

**方法:** 论文通过介绍两个基准测试（stepping gates和ecorobot）来评估神经进化方法的迁移学习能力，并进行实证分析。

**结果:** 实验结果表明，不同NE方法在迁移能力上表现不一，且经常优于强化学习基线。

**结论:** 论文得出结论，NE方法在迁移学习方面表现出色，并具有构建更适应性智能体的潜力，但也面临扩展到复杂现实问题的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Does+Neuroevolution+Outcompete+Reinforcement+Learning+in+Transfer+Learning+Tasks%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22696&send_immediately=true&force_search=false)

**原文摘要:** The ability to continuously and efficiently transfer skills across tasks is a
hallmark of biological intelligence and a long-standing goal in artificial
systems. Reinforcement learning (RL), a dominant paradigm for learning in
high-dimensional control tasks, is known to suffer from brittleness to task
variations and catastrophic forgetting. Neuroevolution (NE) has recently gained
attention for its robustness, scalability, and capacity to escape local optima.
In this paper, we investigate an understudied dimension of NE: its transfer
learning capabilities. To this end, we introduce two benchmarks: a) in stepping
gates, neural networks are tasked with emulating logic circuits, with designs
that emphasize modular repetition and variation b) ecorobot extends the Brax
physics engine with objects such as walls and obstacles and the ability to
easily switch between different robotic morphologies. Crucial in both
benchmarks is the presence of a curriculum that enables evaluating skill
transfer across tasks of increasing complexity. Our empirical analysis shows
that NE methods vary in their transfer abilities and frequently outperform RL
baselines. Our findings support the potential of NE as a foundation for
building more adaptable agents and highlight future challenges for scaling NE
to complex, real-world problems.

</details>


### [6] [Update Your Transformer to the Latest Release: Re-Basin of Task Vectors](https://arxiv.org/abs/2505.22697)
*Filippo Rinaldi, Giacomo Capitani, Lorenzo Bonicelli, Donato Crisostomi, Federico Bolelli, Elisa Ficarra, Emanuele Rodolà, Simone Calderara, Angelo Porrello*

**主要类别:** cs.LG

**AI概要:** 本文研究如何在不重新训练的情况下，将微调模型的知识转移到更新后的基础模型中，提出了基于权重排列的无数据迁移方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于基础模型的更新会导致其上的微调模型失效，因此需要一种方法能够在模型更新后转移原有的微调知识，避免重复训练。

**方法:** 基于模型重定中心（model re-basin）原理并结合权重排列方法，提出一种针对Transformer结构的两层调整策略，包括注意力头的排列和特定头对内的参数调整。

**结果:** 通过实验验证了该方法在视觉和文本任务中的有效性，成功地将微调知识转移到新版本的基础模型上，而不需要任何训练步骤或数据点。

**结论:** 论文提出了一种无需重新训练或依赖数据的方法，能够将微调知识无缝转移到新的预训练模型上，实现了有效的模型更新。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Update+Your+Transformer+to+the+Latest+Release%3A+Re-Basin+of+Task+Vectors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22697，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22697&send_immediately=true&force_search=false)

**原文摘要:** Foundation models serve as the backbone for numerous specialized models
developed through fine-tuning. However, when the underlying pretrained model is
updated or retrained (e.g., on larger and more curated datasets), the
fine-tuned model becomes obsolete, losing its utility and requiring retraining.
This raises the question: is it possible to transfer fine-tuning to a new
release of the model? In this work, we investigate how to transfer fine-tuning
to a new checkpoint without having to re-train, in a data-free manner. To do
so, we draw principles from model re-basin and provide a recipe based on weight
permutations to re-base the modifications made to the original base model,
often called task vector. In particular, our approach tailors model re-basin
for Transformer models, taking into account the challenges of residual
connections and multi-head attention layers. Specifically, we propose a
two-level method rooted in spectral theory, initially permuting the attention
heads and subsequently adjusting parameters within select pairs of heads.
Through extensive experiments on visual and textual tasks, we achieve the
seamless transfer of fine-tuned knowledge to new pre-trained backbones without
relying on a single training step or datapoint. Code is available at
https://github.com/aimagelab/TransFusion.

</details>


### [7] [Private Rate-Constrained Optimization with Applications to Fair Learning](https://arxiv.org/abs/2505.22703)
*Mohammad Yaghini, Tudor Cebere, Michael Menart, Aurélien Bellet, Nicolas Papernot*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为RaCO-DP的算法，用于在差分隐私条件下解决带有速率约束的模型优化问题，通过结合随机梯度下降-上升法和拉格朗日公式，实现了公平性和效用之间的帕累托优势。


<details>
  <summary>更多</summary>
  
**动机:** 可信机器学习中的许多问题可以表述为在特定预测率约束下最小化模型误差，尤其是在需要满足群体公平性约束的情况下。然而，现有的差分隐私优化技术（如DP-SGD）无法直接应用于存在跨样本依赖的速率约束问题，因此需要一种新的方法来解决这一挑战。

**方法:** 开发了一种名为RaCO-DP的差分隐私优化算法，作为随机梯度下降-上升法（SGDA）的一种变体，用于求解速率约束问题的拉格朗日形式，并通过私密估计每个小批量的直方图来处理额外的隐私成本。

**结果:** 理论分析表明，所提出的RaCO-DP算法能够收敛；实验结果也显示，在满足群体公平性约束的学习任务中，该方法在公平性与效用之间的权衡上优于现有方法。

**结论:** RaCO-DP成功地解决了在差分隐私设置下带有速率约束的优化问题，并在保持隐私的同时提高了公平性约束下的模型性能，展示了其在实际应用中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Private+Rate-Constrained+Optimization+with+Applications+to+Fair+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22703&send_immediately=true&force_search=false)

**原文摘要:** Many problems in trustworthy ML can be formulated as minimization of the
model error under constraints on the prediction rates of the model for
suitably-chosen marginals, including most group fairness constraints
(demographic parity, equality of odds, etc.). In this work, we study such
constrained minimization problems under differential privacy (DP). Standard DP
optimization techniques like DP-SGD rely on the loss function's decomposability
into per-sample contributions. However, rate constraints introduce inter-sample
dependencies, violating the decomposability requirement. To address this, we
develop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)
algorithm which solves the Lagrangian formulation of rate constraint problems.
We demonstrate that the additional privacy cost of incorporating these
constraints reduces to privately estimating a histogram over the mini-batch at
each optimization step. We prove the convergence of our algorithm through a
novel analysis of SGDA that leverages the linear structure of the dual
parameter. Finally, empirical results on learning under group fairness
constraints demonstrate that our method Pareto-dominates existing private
learning approaches in fairness-utility trade-offs.

</details>


### [8] [FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference](https://arxiv.org/abs/2505.22758)
*Aniruddha Nrusimha, William Brandon, Mayank Mishra, Yikang Shen, Rameswar Panda, Jonathan Ragan-Kelley, Yoon Kim*

**主要类别:** cs.LG

**AI概要:** 论文介绍了一种名为FlashFormer的概念验证内核，用于加速基于变压器的大型语言模型的单批推理，并展示了其相较于现有技术的速度优势。


<details>
  <summary>更多</summary>
  
**动机:** 现代大型语言模型的规模和计算特性引发了人们对开发专门针对训练和推理的定制内核的兴趣。然而，低批次推理仍然是许多应用的重要因素，如边缘部署和对延迟敏感的应用。

**方法:** 论文提出了一种名为FlashFormer的概念验证内核，用于加速基于变压器的大型语言模型的单批推理。

**结果:** 论文结果显示，FlashFormer在各种模型大小和量化设置下，相较于现有的最先进的推理内核，观察到了非同寻常的速度提升。

**结论:** 论文得出结论，FlashFormer在各种模型大小和量化设置下，相较于现有的最先进的推理内核，观察到了显著的速度提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FlashFormer%3A+Whole-Model+Kernels+for+Efficient+Low-Batch+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22758，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22758&send_immediately=true&force_search=false)

**原文摘要:** The size and compute characteristics of modern large language models have led
to an increased interest in developing specialized kernels tailored for
training and inference. Existing kernels primarily optimize for compute
utilization, targeting the large-batch training and inference settings.
However, low-batch inference, where memory bandwidth and kernel launch
overheads contribute are significant factors, remains important for many
applications of interest such as in edge deployment and latency-sensitive
applications. This paper describes FlashFormer, a proof-of-concept kernel for
accelerating single-batch inference for transformer-based large language
models. Across various model sizes and quantizations settings, we observe
nontrivial speedups compared to existing state-of-the-art inference kernels.

</details>


### [9] [Test-time augmentation improves efficiency in conformal prediction](https://arxiv.org/abs/2505.22764)
*Divya Shanmugam, Helen Lu, Swami Sankaranarayanan, John Guttag*

**主要类别:** cs.LG

**AI概要:** 该论文提出利用测试时增强（TTA）技术优化共形分类器，显著减小其预测集大小，同时保持对真实类别的概率保证。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是为了解决共形分类器通常会生成过大且无信息量的预测集的问题。

**方法:** 论文的方法是通过引入归纳偏置的测试时增强（TTA）技术来优化共形分类器的输出结果。

**结果:** 实验结果显示，结合TTA技术可平均减少10%-14%的预测集大小，并且方法适用于多种数据集、模型和共形评分方法。

**结论:** 论文得出结论，测试时增强（TTA）技术可以有效减小共形分类器生成的预测类别集合的大小。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Test-time+augmentation+improves+efficiency+in+conformal+prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22764，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22764&send_immediately=true&force_search=false)

**原文摘要:** A conformal classifier produces a set of predicted classes and provides a
probabilistic guarantee that the set includes the true class. Unfortunately, it
is often the case that conformal classifiers produce uninformatively large
sets. In this work, we show that test-time augmentation (TTA)--a technique that
introduces inductive biases during inference--reduces the size of the sets
produced by conformal classifiers. Our approach is flexible, computationally
efficient, and effective. It can be combined with any conformal score, requires
no model retraining, and reduces prediction set sizes by 10%-14% on average. We
conduct an evaluation of the approach spanning three datasets, three models,
two established conformal scoring methods, different guarantee strengths, and
several distribution shifts to show when and why test-time augmentation is a
useful addition to the conformal pipeline.

</details>


### [10] [Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting](https://arxiv.org/abs/2505.22768)
*Mert Onur Cakiroglu, Idil Bilge Altun, Hasan Kurban, Elham Buxton, Mehmet Dalkilic*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一个名为DRAGON的新编码器，旨在解决时间序列预测中的挑战，通过引入多变量de Bruijn图来连接符号表示与神经建模。


<details>
  <summary>更多</summary>
  
**动机:** 由于时间异质性、高维性和缺乏内在的符号结构，时间序列预测对于基础模型来说仍然是一个具有挑战性的任务。因此提出了这项工作。

**方法:** 提出了一种新的编码器DRAGON，它使用多变量de Bruijn图(MdBGs)来弥合符号表示和神经建模之间的差距。这种方法包括对连续输入序列进行离散化，并通过基于图的注意力将其映射到固定的图结构上以实现动态上下文恢复。

**结果:** 论文中介绍了DRAGON (Discrete Representation and Augmented Graph encoding Over deBruijN Graphs)，这是一个新的编码器，能够将常规的基于CNN的编码器增强为带有符号、结构感知表示的编码器。

**结论:** DRAGON作为辅助模块集成到双分支架构中，为基于CNN的编码器提供了符号化、结构感知的表示能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multivariate+de+Bruijn+Graphs%3A+A+Symbolic+Graph+Framework+for+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22768，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22768&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting remains a challenging task for foundation models due
to temporal heterogeneity, high dimensionality, and the lack of inherent
symbolic structure. In this work, we propose DRAGON (Discrete Representation
and Augmented Graph encoding Over deBruijN Graphs), a novel encoder that
introduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between
symbolic representations and neural modeling. DRAGON discretizes continuous
input sequences and maps them onto a fixed graph structure, enabling dynamic
context recovery via graph-based attention. Integrated as an auxiliary module
within a dual-branch architecture, DRAGON augments conventional CNN-based
encoders with symbolic, structure-aware representations. All code developed for
this study is available at:
https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library

</details>


### [11] [Calibrated Value-Aware Model Learning with Stochastic Environment Models](https://arxiv.org/abs/2505.22772)
*Claas Voelcker, Anastasiia Pedan, Arash Ahmadian, Romina Abachi, Igor Gilitschenski, Amir-massoud Farahmand*

**主要类别:** cs.LG

**AI概要:** 本论文分析了价值感知模型学习中的损失函数问题，指出MuZero损失的局限性，提出了改进方法，并探讨了模型架构和辅助损失对训练的影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管MuZero损失已被广泛应用，但其理论上的优劣尚未得到充分研究，因此需要深入分析并改进。

**方法:** 分析价值感知模型学习损失函数家族，包括MuZero损失，并提出针对问题的修正方案。

**结果:** 发现常用的MuZero损失是未经校准的代理损失，无法始终恢复正确的模型和价值函数；同时表明确定性模型足以预测准确值，但学习校准的随机模型仍具优势。

**结论:** 论文得出价值感知模型学习的损失函数在常规使用时存在问题，提出修正方法，并探讨了损失校准、潜在模型架构和辅助损失之间的相互作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Calibrated+Value-Aware+Model+Learning+with+Stochastic+Environment+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22772&send_immediately=true&force_search=false)

**原文摘要:** The idea of value-aware model learning, that models should produce accurate
value estimates, has gained prominence in model-based reinforcement learning.
The MuZero loss, which penalizes a model's value function prediction compared
to the ground-truth value function, has been utilized in several prominent
empirical works in the literature. However, theoretical investigation into its
strengths and weaknesses is limited. In this paper, we analyze the family of
value-aware model learning losses, which includes the popular MuZero loss. We
show that these losses, as normally used, are uncalibrated surrogate losses,
which means that they do not always recover the correct model and value
function. Building on this insight, we propose corrections to solve this issue.
Furthermore, we investigate the interplay between the loss calibration, latent
model architectures, and auxiliary losses that are commonly employed when
training MuZero-style agents. We show that while deterministic models can be
sufficient to predict accurate values, learning calibrated stochastic models is
still advantageous.

</details>


### [12] [Machine Learning Models Have a Supply Chain Problem](https://arxiv.org/abs/2505.22778)
*Sarah Meiklejohn, Hayden Blauzvern, Mihai Maruseac, Spencer Schrock, Laurent Simon, Ilia Shumailov*

**主要类别:** cs.LG

**AI概要:** 这篇论文讨论了开放机器学习模型生态系统中的供应链风险，并探索了利用Sigstore提高透明度的可能性。


<details>
  <summary>更多</summary>
  
**动机:** 由于强大的机器学习模型现在可以在线获得，这为缺乏深度技术专业知识或大量计算资源的用户创造了机会，但这也带来了许多风险。

**方法:** 文章通过分析当前开放机器学习模型生态系统中存在的安全风险，并研究了Sigstore解决方案的应用。

**结果:** 论文发现了开放ML模型生态系统中的一些供应链风险，并提出了使用Sigstore来增加透明性的方法。

**结论:** 本文得出的结论是，现有的开放ML模型生态系统存在显著的供应链风险，并探讨了如何利用Sigstore为开放ML模型带来透明性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Learning+Models+Have+a+Supply+Chain+Problem，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22778，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22778&send_immediately=true&force_search=false)

**原文摘要:** Powerful machine learning (ML) models are now readily available online, which
creates exciting possibilities for users who lack the deep technical expertise
or substantial computing resources needed to develop them. On the other hand,
this type of open ecosystem comes with many risks. In this paper, we argue that
the current ecosystem for open ML models contains significant supply-chain
risks, some of which have been exploited already in real attacks. These include
an attacker replacing a model with something malicious (e.g., malware), or a
model being trained using a vulnerable version of a framework or on restricted
or poisoned data. We then explore how Sigstore, a solution designed to bring
transparency to open-source software supply chains, can be used to bring
transparency to open ML models, in terms of enabling model publishers to sign
their models and prove properties about the datasets they use.

</details>


### [13] [Navigating the Latent Space Dynamics of Neural Models](https://arxiv.org/abs/2505.22785)
*Marco Fumero, Luca Moschella, Emanuele Rodolà, Francesco Locatello*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的视角，将神经网络视为动力系统，通过隐向量场分析模型特性，如泛化能力、记忆机制及分布外检测，并在实际场景中验证了这一方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络通常将高维数据转换为低维潜在空间中的结构化表示，而本研究旨在探索这些模型背后的动态特性以及其对模型性能的影响。

**方法:** 该研究提出了一种替代性解读，将自动编码器模型视为隐向量场，并分析了标准训练过程如何引入导致吸引子点出现的归纳偏置。

**结果:** 研究发现隐向量场能够帮助分析神经模型的泛化与记忆机制、从吸引子中提取先验知识，并根据样本轨迹识别分布外样本。此外，作者在视觉基础模型上验证了方法的有效性。

**结论:** 论文得出神经网络可以被解释为在潜在流形上运行的动力系统，并且通过利用隐向量场提供了一种新颖的工具来分析模型和数据的特性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Navigating+the+Latent+Space+Dynamics+of+Neural+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22785，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22785&send_immediately=true&force_search=false)

**原文摘要:** Neural networks transform high-dimensional data into compact, structured
representations, often modeled as elements of a lower dimensional latent space.
In this paper, we present an alternative interpretation of neural models as
dynamical systems acting on the latent manifold. Specifically, we show that
autoencoder models implicitly define a latent vector field on the manifold,
derived by iteratively applying the encoding-decoding map, without any
additional training. We observe that standard training procedures introduce
inductive biases that lead to the emergence of attractor points within this
vector field. Drawing on this insight, we propose to leverage the vector field
as a representation for the network, providing a novel tool to analyze the
properties of the model and the data. This representation enables to: (i)
analyze the generalization and memorization regimes of neural models, even
throughout training; (ii) extract prior knowledge encoded in the network's
parameters from the attractors, without requiring any input data; (iii)
identify out-of-distribution samples from their trajectories in the vector
field. We further validate our approach on vision foundation models, showcasing
the applicability and effectiveness of our method in real-world scenarios.

</details>


### [14] [Efficient Preimage Approximation for Neural Network Certification](https://arxiv.org/abs/2505.22798)
*Anton Björklund, Mykola Zaitsev, Marta Kwiatkowska*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种改进的PREMAP算法，用于神经网络的预图像近似验证，以提高对诸如“补丁攻击”等威胁的可靠性和鲁棒性验证能力。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能在安全和安保关键应用中的依赖日益增加，对抗诸如“补丁攻击”等威胁的有效神经网络验证变得尤为重要。这种攻击可能通过遮挡部分图像（例如交通标志）来影响识别结果。

**方法:** 论文中提出的方法包括对PREMAP算法进行改进，如引入更紧的界限、采用自适应蒙特卡洛采样以及优化分支启发式策略。

**结果:** 论文的结果显示，在强化学习控制基准测试中效率提高了至少一个数量级，并且新方法能够扩展到之前不可行的卷积神经网络。

**结论:** 该论文得出的结论是，通过改进的PREMAP算法，包括更紧的界限、自适应蒙特卡洛采样和改进的分支启发式方法，预图像近似方法在可靠性和鲁棒性验证方面具有巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Preimage+Approximation+for+Neural+Network+Certification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22798，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22798&send_immediately=true&force_search=false)

**原文摘要:** The growing reliance on artificial intelligence in safety- and
security-critical applications demands effective neural network certification.
A challenging real-world use case is certification against ``patch attacks'',
where adversarial patches or lighting conditions obscure parts of images, for
example traffic signs. One approach to certification, which also gives
quantitative coverage estimates, utilizes preimages of neural networks, i.e.,
the set of inputs that lead to a specified output. However, these preimage
approximation methods, including the state-of-the-art PREMAP algorithm,
struggle with scalability. This paper presents novel algorithmic improvements
to PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved
branching heuristics. We demonstrate efficiency improvements of at least an
order of magnitude on reinforcement learning control benchmarks, and show that
our method scales to convolutional neural networks that were previously
infeasible. Our results demonstrate the potential of preimage approximation
methodology for reliability and robustness certification.

</details>


### [15] [Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study](https://arxiv.org/abs/2505.22841)
*Franck Gabriel, François Ged, Maria Han Veiga, Emmanuel Schertzer*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于核平滑经验分数的方法，通过理论分析和实验验证，表明正则化能够有效减少扩散模型的记忆化问题并提升泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 扩散模型在高保真生成采样中表现优异，但容易出现记忆化问题，即过度拟合训练数据。

**方法:** 引入核平滑经验分数，并分析其偏差-方差权衡；通过谱分解方法对前向扩散进行分析；将反向扩散与核密度估计结合进行正则化机制研究。

**结果:** 得出了关于KL散度的渐近边界，证明了对分数的正则化等效于增加训练数据集大小，并展示了合成和MNIST数据集上的实验结果。

**结论:** 论文得出结论，即使没有学习过程，简单的正则化也能减轻记忆化并增强泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Kernel-Smoothed+Scores+for+Denoising+Diffusion%3A+A+Bias-Variance+Study，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22841，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22841&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models now set the benchmark in high-fidelity generative sampling,
yet they can, in principle, be prone to memorization. In this case, their
learned score overfits the finite dataset so that the reverse-time SDE samples
are mostly training points. In this paper, we interpret the empirical score as
a noisy version of the true score and show that its covariance matrix is
asymptotically a re-weighted data PCA. In large dimension, the small time limit
makes the noise variance blow up while simultaneously reducing spatial
correlation. To reduce this variance, we introduce a kernel-smoothed empirical
score and analyze its bias-variance trade-off. We derive asymptotic bounds on
the Kullback-Leibler divergence between the true distribution and the one
generated by the modified reverse SDE. Regularization on the score has the same
effect as increasing the size of the training dataset, and thus helps prevent
memorization. A spectral decomposition of the forward diffusion suggests better
variance control under some regularity conditions of the true data
distribution. Reverse diffusion with kernel-smoothed empirical score can be
reformulated as a gradient descent drifted toward a Log-Exponential
Double-Kernel Density Estimator (LED-KDE). This perspective highlights two
regularization mechanisms taking place in denoising diffusions: an initial
Gaussian kernel first diffuses mass isotropically in the ambient space, while a
second kernel applied in score space concentrates and spreads that mass along
the data manifold. Hence, even a straightforward regularization-without any
learning-already mitigates memorization and enhances generalization.
Numerically, we illustrate our results with several experiments on synthetic
and MNIST datasets.

</details>


### [16] [CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment](https://arxiv.org/abs/2505.22803)
*Pedro Mendes, Paolo Romano, David Garlan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CLUE的新方法，用于神经网络的可靠不确定性估计，该方法基于学习不确定性和误差对齐的原则，并展现出优秀的校准质量和预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的校准技术在可扩展性、可微分性和跨域泛化能力方面存在局限性。

**方法:** CLUE采用了一种新的损失函数，在训练过程中同时优化预测性能和校准，使用不确定性与损失的摘要统计量作为代理。

**结果:** 通过在视觉、回归和语言建模任务上的大量实验，包括分布外和领域转移场景，证明了CLUE的效果。

**结论:** CLUE是一种全新的方法，可以在不增加显著计算开销的情况下实现优于现有技术的校准质量与竞争性的预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CLUE%3A+Neural+Networks+Calibration+via+Learning+Uncertainty-Error+alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22803，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22803&send_immediately=true&force_search=false)

**原文摘要:** Reliable uncertainty estimation is critical for deploying neural networks
(NNs) in real-world applications. While existing calibration techniques often
rely on post-hoc adjustments or coarse-grained binning methods, they remain
limited in scalability, differentiability, and generalization across domains.
In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error
Alignment), a novel approach that explicitly aligns predicted uncertainty with
observed error during training, grounded in the principle that well-calibrated
models should produce uncertainty estimates that match their empirical loss.
CLUE adopts a novel loss function that jointly optimizes predictive performance
and calibration, using summary statistics of uncertainty and loss as proxies.
The proposed method is fully differentiable, domain-agnostic, and compatible
with standard training pipelines. Through extensive experiments on vision,
regression, and language modeling tasks, including out-of-distribution and
domain-shift scenarios, we demonstrate that CLUE achieves superior calibration
quality and competitive predictive performance with respect to state-of-the-art
approaches without imposing significant computational overhead.

</details>


### [17] [Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints](https://arxiv.org/abs/2505.22881)
*Hyungki Im, Wyame Benslimane, Paul Grigas*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的预测然后优化框架 SPO-RC+，用于解决具有不确定性约束的上下文随机线性优化问题，并通过实验验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的上下文随机线性优化方法未考虑依赖机器学习模型预测的不确定参数带来的不等式约束问题，需要一种能够处理这种约束不确定性的方法。

**方法:** 引入了基于符合预测的上下文不确定性集，提出了 SPO-RC 损失及其凸替代 SPO-RC+，并采用截断数据和重要性重加权技术进行训练优化。

**结果:** 通过实验表明，SPO-RC+ 在背包问题和合金生产问题上能够有效应对约束中的不确定性，并且使用截断与重要性重加权能进一步提升性能。

**结论:** SPO-RC+ 能够有效处理约束中的不确定性，并且结合截断和重要性重新加权技术可以进一步提高性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Smart+Surrogate+Losses+for+Contextual+Stochastic+Linear+Optimization+with+Robust+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22881，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22881&send_immediately=true&force_search=false)

**原文摘要:** We study an extension of contextual stochastic linear optimization (CSLO)
that, in contrast to most of the existing literature, involves inequality
constraints that depend on uncertain parameters predicted by a machine learning
model. To handle the constraint uncertainty, we use contextual uncertainty sets
constructed via methods like conformal prediction. Given a contextual
uncertainty set method, we introduce the "Smart Predict-then-Optimize with
Robust Constraints" (SPO-RC) loss, a feasibility-sensitive adaptation of the
SPO loss that measures decision error of predicted objective parameters. We
also introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with
SPO-RC. To enhance performance, we train on truncated datasets where true
constraint parameters lie within the uncertainty sets, and we correct the
induced sample selection bias using importance reweighting techniques. Through
experiments on fractional knapsack and alloy production problem instances, we
demonstrate that SPO-RC+ effectively handles uncertainty in constraints and
that combining truncation with importance reweighting can further improve
performance.

</details>


### [18] [X-Factor: Quality Is a Dataset-Intrinsic Property](https://arxiv.org/abs/2505.22813)
*Josiah Couch, Miao Li, Rima Arnaout, Ramy Arnaout*

**主要类别:** cs.LG

**AI概要:** 该研究证实数据集质量是影响分类器性能的独立因素，与模型架构、数据集大小和类别平衡无关。


<details>
  <summary>更多</summary>
  
**动机:** 先前研究表明，除了模型架构、数据集大小和类别平衡外，数据集质量可能是另一个影响分类器性能的因素，但其是否为独立属性尚不清楚。

**方法:** 创建了数千个控制大小和类别平衡的数据集，并使用多种模型架构进行训练以测试数据集质量是否为内在属性。

**结果:** 发现不同架构下的分类器性能在数据集子集上高度相关（R²=0.79），支持数据集质量是内在属性的观点。

**结论:** 研究得出，数据集质量是影响机器学习分类器性能的独立因素，与其他已知因素如模型架构、数据集大小和类别平衡无关。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X-Factor%3A+Quality+Is+a+Dataset-Intrinsic+Property，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22813，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22813&send_immediately=true&force_search=false)

**原文摘要:** In the universal quest to optimize machine-learning classifiers, three
factors -- model architecture, dataset size, and class balance -- have been
shown to influence test-time performance but do not fully account for it.
Previously, evidence was presented for an additional factor that can be
referred to as dataset quality, but it was unclear whether this was actually a
joint property of the dataset and the model architecture, or an intrinsic
property of the dataset itself. If quality is truly dataset-intrinsic and
independent of model architecture, dataset size, and class balance, then the
same datasets should perform better (or worse) regardless of these other
factors. To test this hypothesis, here we create thousands of datasets, each
controlled for size and class balance, and use them to train classifiers with a
wide range of architectures, from random forests and support-vector machines to
deep networks. We find that classifier performance correlates strongly by
subset across architectures ($R^2=0.79$), supporting quality as an intrinsic
property of datasets independent of dataset size and class balance and of model
architecture. Digging deeper, we find that dataset quality appears to be an
emergent property of something more fundamental: the quality of datasets'
constituent classes. Thus, quality joins size, class balance, and model
architecture as an independent correlate of performance and a separate target
for optimizing machine-learning-based classification.

</details>


### [19] [Efficient Parameter Estimation for Bayesian Network Classifiers using Hierarchical Linear Smoothing](https://arxiv.org/abs/2505.23320)
*Connor Cooper, Geoffrey I. Webb, Daniel F. Schmidt*

**主要类别:** cs.LG

**AI概要:** 论文介绍了一种使用对数线性回归进行参数估计的新方法，这种方法比HDP平滑技术更快且性能更好，在分类任务中可以与随机森林媲美。


<details>
  <summary>更多</summary>
  
**动机:** 传统学习BNC的方法表现不佳，而HDP平滑技术虽然提升了性能但缺乏灵活性且需要复杂的采样过程。因此，论文旨在开发一种更灵活、更简单的参数估计方法。

**方法:** 论文提出了一种新的贝叶斯网络分类器(BNCs)参数估计方法，该方法利用对数线性回归来近似HDP的行为。

**结果:** 实验结果显示，新方法不仅在性能上超过了HDP平滑技术，而且速度快了几个数量级，同时在分类数据上仍能保持与随机森林相当的竞争力。

**结论:** 论文得出结论，使用对数线性回归进行参数估计的新方法在性能上能够超越HDP平滑技术，并且速度更快，同时保持与随机森林在分类数据上的竞争力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Parameter+Estimation+for+Bayesian+Network+Classifiers+using+Hierarchical+Linear+Smoothing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23320，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23320&send_immediately=true&force_search=false)

**原文摘要:** Bayesian network classifiers (BNCs) possess a number of properties desirable
for a modern classifier: They are easily interpretable, highly scalable, and
offer adaptable complexity. However, traditional methods for learning BNCs have
historically underperformed when compared to leading classification methods
such as random forests. Recent parameter smoothing techniques using
hierarchical Dirichlet processes (HDPs) have enabled BNCs to achieve
performance competitive with random forests on categorical data, but these
techniques are relatively inflexible, and require a complicated, specialized
sampling process. In this paper, we introduce a novel method for parameter
estimation that uses a log-linear regression to approximate the behaviour of
HDPs. As a linear model, our method is remarkably flexible and simple to
interpret, and can leverage the vast literature on learning linear models. Our
experiments show that our method can outperform HDP smoothing while being
orders of magnitude faster, remaining competitive with random forests on
categorical data.

</details>


### [20] [Preference Learning with Response Time](https://arxiv.org/abs/2505.22820)
*Ayush Sawarni, Sahasrajit Sarmasarkar, Vasilis Syrgkanis*

**主要类别:** cs.LG

**AI概要:** 本文研究了在人类偏好学习框架中整合响应时间数据以更有效地进行奖励模型挖掘的方法。


<details>
  <summary>更多</summary>
  
**动机:** 二元偏好数据在微调基础模型和生成式AI系统等大规模模型中已变得至关重要，但用户决策中的宝贵时间信息仍未被充分利用。

**方法:** 提出了一种新方法，在二元选择数据的基础上结合响应时间信息，并利用证据积累漂移扩散模型（EZ模型）来体现响应时间对偏好强度的影响。此外，开发了Neyman-正交损失函数，以实现奖励模型学习的oracle收敛率。

**结果:** 理论分析表明，对于线性奖励函数，传统偏好学习的误差率随奖励幅度呈指数级增长，而该方法将其降低为多项式增长，从而显著提高了样本效率。此外，将这些保证扩展到非参数奖励函数空间，为更复杂、更现实的奖励模型建立了收敛特性。实验验证了理论发现的有效性。

**结论:** 通过结合响应时间数据，可以显著提高奖励模型学习的效率和效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preference+Learning+with+Response+Time，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22820，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22820&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the integration of response time data into human
preference learning frameworks for more effective reward model elicitation.
While binary preference data has become fundamental in fine-tuning foundation
models, generative AI systems, and other large-scale models, the valuable
temporal information inherent in user decision-making remains largely
unexploited. We propose novel methodologies to incorporate response time
information alongside binary choice data, leveraging the Evidence Accumulation
Drift Diffusion (EZ) model, under which response time is informative of the
preference strength. We develop Neyman-orthogonal loss functions that achieve
oracle convergence rates for reward model learning, matching the theoretical
optimal rates that would be attained if the expected response times for each
query were known a priori. Our theoretical analysis demonstrates that for
linear reward functions, conventional preference learning suffers from error
rates that scale exponentially with reward magnitude. In contrast, our response
time-augmented approach reduces this to polynomial scaling, representing a
significant improvement in sample efficiency. We extend these guarantees to
non-parametric reward function spaces, establishing convergence properties for
more complex, realistic reward models. Our extensive experiments validate our
theoretical findings in the context of preference learning over images.

</details>


### [21] [Epistemic Errors of Imperfect Multitask Learners When Distributions Shift](https://arxiv.org/abs/2505.23496)
*Sabina J. Sloman, Michele Caprio, Samuel Kaski*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种处理测试数据不确定性（认识论误差）的新框架，适用于多任务学习和分布偏移等场景，并提供了理论误差边界和对负迁移的新定义。


<details>
  <summary>更多</summary>
  
**动机:** 由于现实世界中的学习环境引入了无法仅凭训练数据解决的认识论不确定性，例如多任务学习、分布偏移和不完美的学习过程，因此需要一种原则性的方式来定义并处理这种不确定性带来的误差。

**方法:** 论文提供了一个通用的认识论误差分解边界，并给出了特定情况下如贝叶斯迁移学习和分布偏移的误差界限。

**结果:** 论文的主要成果是提出了一个能够考虑多种认识论不确定性来源的误差边界，并且可以将误差分别归因于学习过程和环境的各个方面。此外，还定义了负迁移的新概念并通过合成实验验证了其见解。

**结论:** 论文提出了一种新的方法来处理在存在认识论不确定性时的学习问题，其中包括对贝叶斯迁移学习和分布转移情况的具体误差界限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Epistemic+Errors+of+Imperfect+Multitask+Learners+When+Distributions+Shift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23496，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23496&send_immediately=true&force_search=false)

**原文摘要:** When data are noisy, a statistical learner's goal is to resolve epistemic
uncertainty about the data it will encounter at test-time, i.e., to identify
the distribution of test (target) data. Many real-world learning settings
introduce sources of epistemic uncertainty that can not be resolved on the
basis of training (source) data alone: The source data may arise from multiple
tasks (multitask learning), the target data may differ systematically from the
source data tasks (distribution shift), and/or the learner may not arrive at an
accurate characterization of the source data (imperfect learning). We introduce
a principled definition of epistemic error, and provide a generic,
decompositional epistemic error bound. Our error bound is the first to (i)
consider epistemic error specifically, (ii) accommodate all the sources of
epistemic uncertainty above, and (iii) separately attribute the error to each
of multiple aspects of the learning procedure and environment. As corollaries
of the generic result, we provide (i) epistemic error bounds specialized to the
settings of Bayesian transfer learning and distribution shift within
$\epsilon$-neighborhoods, and (ii) a set of corresponding generalization
bounds. Finally, we provide a novel definition of negative transfer, and
validate its insights in a synthetic experimental setting.

</details>


### [22] [PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow](https://arxiv.org/abs/2505.22825)
*Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PGLearn，一个为机器学习应用于最优潮流问题（OPF）提供标准化数据集和评估工具的综合平台，旨在加速相关研究与创新。


<details>
  <summary>更多</summary>
  
**动机:** 现代和未来电网能源生产的波动性和规模增加，使得传统的复杂优化问题解决方法面临挑战，而机器学习技术的发展需要标准化的数据集和评估指标来推动该领域的进步。

**方法:** 开发了一个名为PGLearn的综合套件，包括标准化数据集和评估工具，涵盖AC、DC和二阶锥形式的OPF问题，并首次引入多个大规模系统的时间序列数据。

**结果:** PGLearn提供了代表实际运行条件的数据集，支持多种OPF公式，并包含用于训练、评估和基准测试的工具，以促进公平的方法比较。

**结论:** PGLearn旨在通过提供开放、标准化的数据集和评估指标来加速和普及机器学习在最优潮流问题中的研究与创新。数据集可在https://www.huggingface.co/PGLearn 下载。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PGLearn+--+An+Open-Source+Learning+Toolkit+for+Optimal+Power+Flow，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22825，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22825&send_immediately=true&force_search=false)

**原文摘要:** Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have
recently garnered significant attention, reflecting a broader trend of
leveraging ML to approximate and/or accelerate the resolution of complex
optimization problems. These developments are necessitated by the increased
volatility and scale in energy production for modern and future grids. However,
progress in ML for OPF is hindered by the lack of standardized datasets and
evaluation metrics, from generating and solving OPF instances, to training and
benchmarking machine learning models. To address this challenge, this paper
introduces PGLearn, a comprehensive suite of standardized datasets and
evaluation tools for ML and OPF. PGLearn provides datasets that are
representative of real-life operating conditions, by explicitly capturing both
global and local variability in the data generation, and by, for the first
time, including time series data for several large-scale systems. In addition,
it supports multiple OPF formulations, including AC, DC, and second-order cone
formulations. Standardized datasets are made publicly available to democratize
access to this field, reduce the burden of data generation, and enable the fair
comparison of various methodologies. PGLearn also includes a robust toolkit for
training, evaluating, and benchmarking machine learning models for OPF, with
the goal of standardizing performance evaluation across the field. By promoting
open, standardized datasets and evaluation metrics, PGLearn aims at
democratizing and accelerating research and innovation in machine learning
applications for optimal power flow problems. Datasets are available for
download at https://www.huggingface.co/PGLearn.

</details>


### [23] [On Transferring Transferability: Towards a Theory for Size Generalization](https://arxiv.org/abs/2505.23599)
*Eitan Levin, Yuxin Ma, Mateo Díaz, Soledad Villar*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种跨维度的模型可迁移性框架，表明可迁移性对应于极限空间中的连续性，并提供了设计可迁移模型的原则。


<details>
  <summary>更多</summary>
  
**动机:** 现代学习任务需要能够处理不同输入尺寸的模型，因此论文研究了如何实现模型在不同维度间性能的可迁移性。

**方法:** 论文提出了一种跨维度可迁移性的通用框架，并通过现有架构验证其理论。

**结果:** 论文实现了现有架构的可迁移性，并提出了设计新型可迁移模型的原则，同时数值实验支持了这些发现。

**结论:** 论文得出结论，可迁移性与在极限空间中的连续性相对应，并且通过数据和学习任务本身驱动小问题实例与等效大问题实例的识别。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Transferring+Transferability%3A+Towards+a+Theory+for+Size+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23599，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23599&send_immediately=true&force_search=false)

**原文摘要:** Many modern learning tasks require models that can take inputs of varying
sizes. Consequently, dimension-independent architectures have been proposed for
domains where the inputs are graphs, sets, and point clouds. Recent work on
graph neural networks has explored whether a model trained on low-dimensional
data can transfer its performance to higher-dimensional inputs. We extend this
body of work by introducing a general framework for transferability across
dimensions. We show that transferability corresponds precisely to continuity in
a limit space formed by identifying small problem instances with equivalent
large ones. This identification is driven by the data and the learning task. We
instantiate our framework on existing architectures, and implement the
necessary changes to ensure their transferability. Finally, we provide design
principles for designing new transferable models. Numerical experiments support
our findings.

</details>


### [24] [Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies](https://arxiv.org/abs/2505.22829)
*Chenruo Liu, Kenan Tang, Yao Qin, Qi Lei*

**主要类别:** cs.LG

**AI概要:** 本文研究了分布变化和AI安全性之间的相互关系，提出二者在方法和理论上可以互相促进和转化。


<details>
  <summary>更多</summary>
  
**动机:** 先前的研究往往关注狭隘案例或非正式类比，而本文旨在建立一个统一的视角来探讨分布变化和AI安全性之间的联系。

**方法:** 通过综合分析分布变化的具体类型与细粒度AI安全问题之间的两种连接方式，包括方法应对特定变化类型以及某些变化和安全问题可以相互转化。

**结果:** 建立了分布变化和AI安全性之间的具体联系，并提供了方法论上的相互适应性。

**结论:** 研究发现，分布变化和AI安全性之间存在概念和方法论上的协同作用，鼓励两者研究的深度融合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+Distribution+Shift+and+AI+Safety%3A+Conceptual+and+Methodological+Synergies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22829，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22829&send_immediately=true&force_search=false)

**原文摘要:** This paper bridges distribution shift and AI safety through a comprehensive
analysis of their conceptual and methodological synergies. While prior
discussions often focus on narrow cases or informal analogies, we establish two
types connections between specific causes of distribution shift and
fine-grained AI safety issues: (1) methods addressing a specific shift type can
help achieve corresponding safety goals, or (2) certain shifts and safety
issues can be formally reduced to each other, enabling mutual adaptation of
their methods. Our findings provide a unified perspective that encourages
fundamental integration between distribution shift and AI safety research.

</details>


### [25] [Inference-time Scaling of Diffusion Models through Classical Search](https://arxiv.org/abs/2505.23614)
*Xiangcheng Zhang, Haowei Lin, Haotian Ye, James Zou, Jianzhu Ma, Yitao Liang, Yilun Du*

**主要类别:** cs.LG

**AI概要:** 这项研究提出了一种基于经典搜索原理的新框架，用于改进扩散模型的推理时间控制，显示出在多个领域中的高效性和有效性。


<details>
  <summary>更多</summary>
  
**动机:** 本研究旨在解决扩散模型在推理时间控制中的挑战，即适应不同的测试时间目标。

**方法:** 研究提出了一种通用框架，该框架通过退火Langevin MCMC进行理论基础的局部搜索，并使用广度优先和深度优先树搜索执行计算高效的全局探索。

**结果:** 研究发现，在各种具有挑战性的领域（包括规划、离线强化学习和图像生成）中，该方法在性能和效率方面都有显著提升。

**结论:** 研究表明，经典的搜索算法可以为扩散模型的推理时间扩展提供一个有原则且实用的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inference-time+Scaling+of+Diffusion+Models+through+Classical+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23614，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23614&send_immediately=true&force_search=false)

**原文摘要:** Classical search algorithms have long underpinned modern artificial
intelligence. In this work, we tackle the challenge of inference-time control
in diffusion models -- adapting generated outputs to meet diverse test-time
objectives -- using principles from classical search. We propose a general
framework that orchestrates local and global search to efficiently navigate the
generative space. It employs a theoretically grounded local search via annealed
Langevin MCMC and performs compute-efficient global exploration using
breadth-first and depth-first tree search. We evaluate our approach on a range
of challenging domains, including planning, offline reinforcement learning, and
image generation. Across all tasks, we observe significant gains in both
performance and efficiency. These results show that classical search provides a
principled and practical foundation for inference-time scaling in diffusion
models. Project page at diffusion-inference-scaling.github.io.

</details>


### [26] [How Do Diffusion Models Improve Adversarial Robustness?](https://arxiv.org/abs/2505.22839)
*Liu Yuezhang, Xue-Xin Wei*

**主要类别:** cs.LG

**AI概要:** 本文研究扩散模型如何提高对抗鲁棒性，发现其主要机制是输入空间的压缩效应，而非单纯去噪。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有研究认为扩散模型能够显著增强对抗鲁棒性，但其背后的机制尚不明确。本文旨在深入探究扩散模型提升鲁棒性的具体机制。

**方法:** 论文系统地研究了扩散模型如何影响对抗鲁棒性，包括观察扩散模型对清洁样本的ℓp距离的变化、内部随机性对净化图像的影响，并在固定随机性条件下评估鲁棒性。

**结果:** 论文发现扩散模型会增加清洁样本的ℓp距离，而不是减小；在固定随机性条件下，鲁棒性提升下降到约24%。此外，输入空间的压缩率被证明是衡量鲁棒性的重要指标。

**结论:** 论文得出结论，扩散模型通过压缩输入空间来提升对抗鲁棒性，而非传统理解的去噪过程。这种压缩效应与鲁棒性的提升有强相关性，并且压缩率可以作为不依赖梯度分析的鲁棒性指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Do+Diffusion+Models+Improve+Adversarial+Robustness%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22839，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22839&send_immediately=true&force_search=false)

**原文摘要:** Recent findings suggest that diffusion models significantly enhance empirical
adversarial robustness. While some intuitive explanations have been proposed,
the precise mechanisms underlying these improvements remain unclear. In this
work, we systematically investigate how and how well diffusion models improve
adversarial robustness. First, we observe that diffusion models intriguingly
increase, rather than decrease, the $\ell_p$ distance to clean
samples--challenging the intuition that purification denoises inputs closer to
the original data. Second, we find that the purified images are heavily
influenced by the internal randomness of diffusion models, where a compression
effect arises within each randomness configuration. Motivated by this
observation, we evaluate robustness under fixed randomness and find that the
improvement drops to approximately 24% on CIFAR-10--substantially lower than
prior reports approaching 70%. Importantly, we show that this remaining
robustness gain strongly correlates with the model's ability to compress the
input space, revealing the compression rate as a reliable robustness indicator
without requiring gradient-based analysis. Our findings provide novel insights
into the mechanisms underlying diffusion-based purification, and offer guidance
for developing more effective and principled adversarial purification systems.

</details>


### [27] [COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents](https://arxiv.org/abs/2505.23720)
*Arun Verma, Indrajit Saha, Makoto Yokoo, Bryan Kian Hsiang Low*

**主要类别:** cs.LG

**AI概要:** 本文针对情境化强盗问题中的策略代理问题，提出了COBRA算法，该算法无需使用任何货币激励即可抑制代理的策略行为，同时保证激励相容性和次线性遗憾。


<details>
  <summary>更多</summary>
  
**动机:** 现有的情境化强盗研究通常假设代理会如实报告他们的情况，但在实际应用中这种假设并不成立，例如在线平台上的卖家可能会歪曲产品质量以获得优势。

**方法:** 作者考虑了一个涉及多个代理的情境化强盗问题，并设计了COBRA算法来处理代理可能存在的不诚实报告手臂的问题。

**结果:** 实验结果验证了所提出的COBRA算法在不同性能方面的有效性。

**结论:** 本文提出了一种名为COBRA的算法，用于解决涉及策略代理的情境化强盗问题，该算法能够抑制代理的策略行为，同时保证激励相容性和次线性遗憾。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是COBRA%3A+Contextual+Bandit+Algorithm+for+Ensuring+Truthful+Strategic+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23720，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23720&send_immediately=true&force_search=false)

**原文摘要:** This paper considers a contextual bandit problem involving multiple agents,
where a learner sequentially observes the contexts and the agent's reported
arms, and then selects the arm that maximizes the system's overall reward.
Existing work in contextual bandits assumes that agents truthfully report their
arms, which is unrealistic in many real-life applications. For instance,
consider an online platform with multiple sellers; some sellers may
misrepresent product quality to gain an advantage, such as having the platform
preferentially recommend their products to online users. To address this
challenge, we propose an algorithm, COBRA, for contextual bandit problems
involving strategic agents that disincentivize their strategic behavior without
using any monetary incentives, while having incentive compatibility and a
sub-linear regret guarantee. Our experimental results also validate the
different performance aspects of our proposed algorithm.

</details>


### [28] [Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction](https://arxiv.org/abs/2505.22840)
*Dharambir Mahto, Prashant Yadav, Mahesh Banavar, Jim Keany, Alan T Joseph, Srinivas Kilambi*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种机器学习评分系统SXI++ LNM，用于改进脓毒症的预测，并且其表现出卓越的性能。


<details>
  <summary>更多</summary>
  
**动机:** 脓毒症是一种威胁生命的疾病，具有非特异性症状和复杂的病理生理学，因此预测仍然具有挑战性。

**方法:** 利用深度神经网络和多种算法训练并测试模型性能。

**结果:** SXI++ LNM在三个用例中超过了最先进的方法，AUC为0.99（95% CI: 0.98-1.00），精度为99.9%（95% CI: 99.8-100.0），准确率为99.99%（95% CI: 99.98-100.0）。

**结论:** SXI++ LNM在预测脓毒症方面优于现有技术，表现出高可靠性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Development+and+Validation+of+SXI%2B%2B+LNM+Algorithm+for+Sepsis+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22840，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22840&send_immediately=true&force_search=false)

**原文摘要:** Sepsis is a life-threatening condition affecting over 48.9 million people
globally and causing 11 million deaths annually. Despite medical advancements,
predicting sepsis remains a challenge due to non-specific symptoms and complex
pathophysiology. The SXI++ LNM is a machine learning scoring system that
refines sepsis prediction by leveraging multiple algorithms and deep neural
networks. This study aims to improve robustness in clinical applications and
evaluates the predictive performance of the SXI++ LNM for sepsis prediction.
The model, utilizing a deep neural network, was trained and tested using
multiple scenarios with different dataset distributions. The model's
performance was assessed against unseen test data, and accuracy, precision, and
area under the curve (AUC) were calculated. THE SXI++ LNM outperformed the
state of the art in three use cases, achieving an AUC of 0.99 (95% CI:
0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0)
and an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.

</details>


### [29] [RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation](https://arxiv.org/abs/2505.22846)
*Nikita Khramov, Andrei Kozyrev, Gleb Solovev, Anton Podkopaev*

**主要类别:** cs.LG

**AI概要:** 该论文探讨了将生成式AI与交互式定理证明结合的方法，提出了基于自我注意力模型的检索机制和多阶段代理系统，从而显著提升了Rocq证明生成的性能。


<details>
  <summary>更多</summary>
  
**动机:** 论文的动机是探索交互式定理证明与生成式人工智能结合的潜力，以提高Rocq证明生成的效率和效果。

**方法:** 论文提出了一种新的前提选择方法，利用自我注意力嵌入模型进行检索，并结合多阶段代理系统生成Rocq证明。

**结果:** 论文结果显示，所提出的方法使生成器的性能相对提高了28%。此外，多代理辩论的应用也表明其在证明合成规划阶段的有效性。

**结论:** 论文总结指出，通过使用基于自我注意力嵌入模型的检索方法以及多阶段代理系统，生成Rocq证明的性能得到了显著提升，并展示了在形式验证方面的高效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RocqStar%3A+Leveraging+Similarity-driven+Retrieval+and+Agentic+Systems+for+Rocq+generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22846，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22846&send_immediately=true&force_search=false)

**原文摘要:** Interactive Theorem Proving was repeatedly shown to be fruitful combined with
Generative Artificial Intelligence. This paper assesses multiple approaches to
Rocq generation and illuminates potential avenues for improvement. We highlight
the importance of thorough premise selection for generating Rocq proofs and
propose a novel approach, leveraging retrieval via a self-attentive embedder
model. The evaluation of the designed approach shows up to 28% relative
increase of the generator's performance. We tackle the problem of writing Rocq
proofs using a multi-stage agentic system, tailored for formal verification,
and demonstrate its high effectiveness. We conduct an ablation study and show
the use of multi-agent debate on the planning stage of proof synthesis.

</details>


### [30] [Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel](https://arxiv.org/abs/2505.22861)
*Carlota Parés-Morlans, Michelle Yi, Claire Chen, Sarah A. Wu, Rika Antonova, Tobias Gerstenberg, Jeannette Bohg*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Causal-PIK的新方法，该方法利用贝叶斯优化通过物理信息核推理因果相互作用，以指导寻找最佳下一步动作的高效搜索。


<details>
  <summary>更多</summary>
  
**动机:** 涉及未知动力学物体之间复杂相互作用的任务使得执行前的规划变得困难，需要一种方法让代理在主动探索环境中的因果关系后迭代改进其行动。

**方法:** 通过贝叶斯优化和物理信息核推理因果交互的方法。

**结果:** 实验结果表明，Causal-PIK在Virtual Tools和PHYRE物理推理基准测试中优于现有技术，需要更少的动作来达到目标。

**结论:** Causal-PIK在物理推理任务中表现出色，即使对于人类问题解决者来说非常具有挑战性的任务也保持竞争力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal-PIK%3A+Causality-based+Physical+Reasoning+with+a+Physics-Informed+Kernel，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22861，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22861&send_immediately=true&force_search=false)

**原文摘要:** Tasks that involve complex interactions between objects with unknown dynamics
make planning before execution difficult. These tasks require agents to
iteratively improve their actions after actively exploring causes and effects
in the environment. For these type of tasks, we propose Causal-PIK, a method
that leverages Bayesian optimization to reason about causal interactions via a
Physics-Informed Kernel to help guide efficient search for the best next
action. Experimental results on Virtual Tools and PHYRE physical reasoning
benchmarks show that Causal-PIK outperforms state-of-the-art results, requiring
fewer actions to reach the goal. We also compare Causal-PIK to human studies,
including results from a new user study we conducted on the PHYRE benchmark. We
find that Causal-PIK remains competitive on tasks that are very challenging,
even for human problem-solvers.

</details>


### [31] [Scaling Offline RL via Efficient and Expressive Shortcut Models](https://arxiv.org/abs/2505.22866)
*Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为Scalable Offline Reinforcement Learning (SORL)的新方法，该方法利用一种新型生成模型“shortcut models”解决离线强化学习中的难题。


<details>
  <summary>更多</summary>
  
**动机:** 扩散和流模型在建模多样化和多模态行为方面表现出色，但将它们应用于离线强化学习存在困难。

**方法:** 引入了Shortcut Models作为生成模型的新类别，并利用Q函数进行验证。

**结果:** SORL策略能够捕捉复杂数据分布，并且可以在单一阶段的训练过程中高效训练。

**结论:** SORL是一种新的离线RL算法，通过使用快捷模型来实现训练和推理的扩展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Offline+RL+via+Efficient+and+Expressive+Shortcut+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22866，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22866&send_immediately=true&force_search=false)

**原文摘要:** Diffusion and flow models have emerged as powerful generative approaches
capable of modeling diverse and multimodal behavior. However, applying these
models to offline reinforcement learning (RL) remains challenging due to the
iterative nature of their noise sampling processes, making policy optimization
difficult. In this paper, we introduce Scalable Offline Reinforcement Learning
(SORL), a new offline RL algorithm that leverages shortcut models - a novel
class of generative models - to scale both training and inference. SORL's
policy can capture complex data distributions and can be trained simply and
efficiently in a one-stage training procedure. At test time, SORL introduces
both sequential and parallel inference scaling by using the learned Q-function
as a verifier. We demonstrate that SORL achieves strong performance across a
range of offline RL tasks and exhibits positive scaling behavior with increased
test-time compute. We release the code at
nico-espinosadice.github.io/projects/sorl.

</details>


### [32] [On the Dynamic Regret of Following the Regularized Leader: Optimism with History Pruning](https://arxiv.org/abs/2505.22899)
*Naram Mhaisen, George Iosifidis*

**主要类别:** cs.LG

**AI概要:** 该论文重新审视FTRL优化框架在动态环境中的应用，表明其可以通过适当的技术支持实现良好的动态后悔性能。


<details>
  <summary>更多</summary>
  
**动机:** 先前研究认为FTRL在动态环境中表现不佳，因其产生“懒惰”的迭代点，但本文基于FTRL可以生成“敏捷”迭代点的新见解，重新评估其潜力。

**方法:** 通过分析FTRL在动态环境中的表现，结合乐观组成和线性化技术来实现动态后悔界的恢复，并引入剪枝方法同步算法状态与迭代过程。

**结果:** 展示了FTRL能够通过适当的分析恢复已知的动态后悔界，并提供了一种在贪婪和敏捷更新之间进行插值的原则方法，同时改善对后悔项的控制。

**结论:** FTRL框架通过乐观组成未来成本和谨慎线性化过去成本，能够实现动态后悔保证，并且其“懒惰”投影风格并不是阻碍动态后悔的主要因素。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Dynamic+Regret+of+Following+the+Regularized+Leader%3A+Optimism+with+History+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22899&send_immediately=true&force_search=false)

**原文摘要:** We revisit the Follow the Regularized Leader (FTRL) framework for Online
Convex Optimization (OCO) over compact sets, focusing on achieving dynamic
regret guarantees. Prior work has highlighted the framework's limitations in
dynamic environments due to its tendency to produce "lazy" iterates. However,
building on insights showing FTRL's ability to produce "agile" iterates, we
show that it can indeed recover known dynamic regret bounds through optimistic
composition of future costs and careful linearization of past costs, which can
lead to pruning some of them. This new analysis of FTRL against dynamic
comparators yields a principled way to interpolate between greedy and agile
updates and offers several benefits, including refined control over regret
terms, optimism without cyclic dependence, and the application of minimal
recursive regularization akin to AdaFTRL. More broadly, we show that it is not
the lazy projection style of FTRL that hinders (optimistic) dynamic regret, but
the decoupling of the algorithm's state (linearized history) from its iterates,
allowing the state to grow arbitrarily. Instead, pruning synchronizes these two
when necessary.

</details>


### [33] [Defining Foundation Models for Computational Science: A Call for Clarity and Rigor](https://arxiv.org/abs/2505.22904)
*Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss*

**主要类别:** cs.LG

**AI概要:** 这篇论文旨在解决计算科学中“基础模型”定义不明确的问题，并提出了一种新的数据驱动有限元方法（DD-FEM），以实现具有可扩展性、适应性和物理一致性的基础模型。


<details>
  <summary>更多</summary>
  
**动机:** 由于“基础模型”这一术语在计算科学中的应用日益广泛，但缺乏普遍接受的定义，可能会造成混淆并稀释其精确的科学含义，因此需要进行本研究。

**方法:** 提出了一种融合经典有限元法模块化结构和数据驱动学习表示能力的框架——数据驱动有限元方法（DD-FEM）

**结果:** 作者们通过传统数值方法与现代人工智能范式的结合，为评估和发展未来的计算科学基础模型提供了严格的基础。

**结论:** 该论文提出了计算科学中基础模型的正式定义，并介绍了数据驱动有限元方法（DD-FEM）作为实现这些模型的一种方式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Defining+Foundation+Models+for+Computational+Science%3A+A+Call+for+Clarity+and+Rigor，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22904，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22904&send_immediately=true&force_search=false)

**原文摘要:** The widespread success of foundation models in natural language processing
and computer vision has inspired researchers to extend the concept to
scientific machine learning and computational science. However, this position
paper argues that as the term "foundation model" is an evolving concept, its
application in computational science is increasingly used without a universally
accepted definition, potentially creating confusion and diluting its precise
scientific meaning. In this paper, we address this gap by proposing a formal
definition of foundation models in computational science, grounded in the core
values of generality, reusability, and scalability. We articulate a set of
essential and desirable characteristics that such models must exhibit, drawing
parallels with traditional foundational methods, like the finite element and
finite volume methods. Furthermore, we introduce the Data-Driven Finite Element
Method (DD-FEM), a framework that fuses the modular structure of classical FEM
with the representational power of data-driven learning. We demonstrate how
DD-FEM addresses many of the key challenges in realizing foundation models for
computational science, including scalability, adaptability, and physics
consistency. By bridging traditional numerical methods with modern AI
paradigms, this work provides a rigorous foundation for evaluating and
developing novel approaches toward future foundation models in computational
science.

</details>


### [34] [Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference](https://arxiv.org/abs/2505.22913)
*Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari*

**主要类别:** cs.LG

**AI概要:** 本文研究了无结构稀疏性在KV缓存中的应用，提出了有效的剪枝方法和压缩机制，显著提高了大型语言模型的解码性能和吞吐量。


<details>
  <summary>更多</summary>
  
**动机:** KV缓存大小是解码性能的主要瓶颈，因此需要通过无结构稀疏性来改善内存开销并提升性能。

**方法:** 系统地探索了剪枝策略，并采用基于位图的稀疏格式以及能够直接计算压缩缓存的自定义注意力内核来提高解码性能。

**结果:** 实现了高达70%的稀疏性而无需微调，同时KV缓存压缩至45%，上下文长度和吞吐量分别提升了2.23倍。

**结论:** 本文提出了一种基于位图的稀疏格式和自定义注意力内核，用于压缩KV缓存，从而实现更高的解码性能和吞吐量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mustafar%3A+Promoting+Unstructured+Sparsity+for+KV+Cache+Pruning+in+LLM+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22913，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22913&send_immediately=true&force_search=false)

**原文摘要:** We demonstrate that unstructured sparsity significantly improves KV cache
compression for LLMs, enabling sparsity levels up to 70% without compromising
accuracy or requiring fine-tuning. We conduct a systematic exploration of
pruning strategies and find per-token magnitude-based pruning as highly
effective for both Key and Value caches under unstructured sparsity, surpassing
prior structured pruning schemes. The Key cache benefits from prominent outlier
elements, while the Value cache surprisingly benefits from a simple
magnitude-based pruning despite its uniform distribution. KV cache size is the
major bottleneck in decode performance due to high memory overhead for large
context lengths. To address this, we use a bitmap-based sparse format and a
custom attention kernel capable of compressing and directly computing over
compressed caches pruned to arbitrary sparsity patterns, significantly
accelerating memory-bound operations in decode computations and thereby
compensating for the overhead of runtime pruning and compression. Our custom
attention kernel coupled with the bitmap-based format delivers substantial
compression of KV cache upto 45% of dense inference and thereby enables longer
context length and increased tokens/sec throughput of upto 2.23x compared to
dense inference. Our pruning mechanism and sparse attention kernel is available
at https://github.com/dhjoo98/mustafar.

</details>


### [35] [Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking](https://arxiv.org/abs/2505.22922)
*Athanasios Glentis, Jiaxiang Li, Qiulin Shang, Andi Han, Ioannis Tsaknakis, Quan Wei, Mingyi Hong*

**主要类别:** cs.LG

**AI概要:** 这篇论文分析了大型语言模型在预训练过程中面临的计算挑战，并探索了如何通过高效的参数和内存利用方法提升预训练效率。研究提出了两种新技术，能够在降低内存消耗的同时取得优于现有方法的性能。


<details>
  <summary>更多</summary>
  
**动机:** 由于大型语言模型在多个领域表现出色，其参数规模迅速增长，带来了显著的计算挑战，尤其是在训练和微调过程中所需的内存和计算资源。现有的参数或内存高效方法主要适用于微调，而在预训练方面应用较为困难，因此本文旨在解决如何提升预训练效率的问题。

**方法:** 首先进行全面调查总结最先进的高效预训练方法；然后对几种代表性的内存高效预训练方法进行基准评估，观察全秩训练以及低秩方法的性能；最后提出两种实用技术来增强高效预训练方法的性能。

**结果:** 通过合理选择优化器和超参数，全秩训练表现最佳；此外，在低秩方法中引入高秩更新是提高其性能的关键。应用新提出的两种技术（权重重构和动量重置）后，低秩方法（在1B模型上）实现了比GaLore和Fira更低的困惑度，并且使用了约25%的内存。

**结论:** 论文提出两种实用技术，即权重重构和动量重置，以增强高效预训练方法的性能。将这些技术应用于低秩方法时，可以比流行的内存高效算法（如GaLore和Fira）实现更低的困惑度，同时使用更少的内存。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Parameter+and+Memory+Efficient+Pretraining+for+LLM%3A+Recent+Algorithmic+Advances+and+Benchmarking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22922，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22922&send_immediately=true&force_search=false)

**原文摘要:** Fueled by their remarkable ability to tackle diverse tasks across multiple
domains, large language models (LLMs) have grown at an unprecedented rate, with
some recent models containing trillions of parameters. This growth is
accompanied by substantial computational challenges, particularly regarding the
memory and compute resources required for training and fine-tuning. Numerous
approaches have been explored to address these issues, such as LoRA. While
these methods are effective for fine-tuning, their application to pre-training
is significantly more challenging due to the need to learn vast datasets.
Motivated by this issue, we aim to address the following questions: Can
parameter- or memory-efficient methods enhance pre-training efficiency while
achieving performance comparable to full-model training? How can the
performance gap be narrowed? To this end, the contributions of this work are
the following. (1) We begin by conducting a comprehensive survey that
summarizes state-of-the-art methods for efficient pre-training. (2) We perform
a benchmark evaluation of several representative memory efficient pre-training
approaches to comprehensively evaluate their performance across model sizes. We
observe that with a proper choice of optimizer and hyperparameters, full-rank
training delivers the best performance, as expected. We also notice that
incorporating high-rank updates in low-rank approaches is the key to improving
their performance. (3) Finally, we propose two practical techniques, namely
weight refactorization and momentum reset, to enhance the performance of
efficient pre-training methods. We observe that applying these techniques to
the low-rank method (on a 1B model) can achieve a lower perplexity than popular
memory efficient algorithms such as GaLore and Fira, while simultaneously using
about 25% less memory.

</details>


### [36] [Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models](https://arxiv.org/abs/2505.22935)
*Jipeng Li, Yanning Shen*

**主要类别:** cs.LG

**AI概要:** 该论文挑战了图扩散模型需要显式噪声水平条件的传统观点，提出了一个理论框架并通过实验验证其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 论文挑战了传统观点，即显式噪声水平条件对于图扩散模型的有效运行至关重要，因此探究去噪器是否能从被破坏的图结构中隐式推断噪声水平。

**方法:** 论文通过开发一个以伯努利边翻转损坏为中心的理论框架，并将其扩展到涉及结构-属性噪声耦合的更复杂场景来研究问题。

**结果:** 在合成和真实世界图数据集上的广泛实证评估表明，非条件图扩散模型的性能与条件模型相当甚至更好，并且参数减少（4-6%）和计算时间减少（8-10%）。

**结论:** 论文得出结论，图数据本身的高维特性通常为去噪过程提供了足够的信息，这表明显式噪声水平条件可能不是必不可少的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Is+Noise+Conditioning+Necessary%3F+A+Unified+Theory+of+Unconditional+Graph+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22935&send_immediately=true&force_search=false)

**原文摘要:** Explicit noise-level conditioning is widely regarded as essential for the
effective operation of Graph Diffusion Models (GDMs). In this work, we
challenge this assumption by investigating whether denoisers can implicitly
infer noise levels directly from corrupted graph structures, potentially
eliminating the need for explicit noise conditioning. To this end, we develop a
theoretical framework centered on Bernoulli edge-flip corruptions and extend it
to encompass more complex scenarios involving coupled structure-attribute
noise. Extensive empirical evaluations on both synthetic and real-world graph
datasets, using models such as GDSS and DiGress, provide strong support for our
theoretical findings. Notably, unconditional GDMs achieve performance
comparable or superior to their conditioned counterparts, while also offering
reductions in parameters (4-6%) and computation time (8-10%). Our results
suggest that the high-dimensional nature of graph data itself often encodes
sufficient information for the denoising process, opening avenues for simpler,
more efficient GDM architectures.

</details>


### [37] [Directed Graph Grammars for Sequence-based Learning](https://arxiv.org/abs/2505.22949)
*Michael Sun, Orion Foo, Gang Liu, Wojciech Matusik, Jie Chen*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的处理有向无环图(DAGs)的方法，通过使用无歧义语法产生规则的序列，从而构建出一个原理性的、紧凑且等效的DAG序列表示。


<details>
  <summary>更多</summary>
  
**动机:** 虽然已经有许多有效的DAG编码器，但以合理的方式解码它们仍然具有挑战性。

**方法:** 将图视为无歧义语法的推导，其中DAG对应于一组唯一的生成规则序列。

**结果:** 这种表示形式有很多用途，包括构建用于图生成的生成模型、学习用于属性预测的潜在空间以及利用序列表示连续性对结构化数据进行贝叶斯优化。

**结论:** 作者提出了一种基于语法的方法来构建DAG的原理性、紧凑且等效的序列表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Directed+Graph+Grammars+for+Sequence-based+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22949，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22949&send_immediately=true&force_search=false)

**原文摘要:** Directed acyclic graphs (DAGs) are a class of graphs commonly used in
practice, with examples that include electronic circuits, Bayesian networks,
and neural architectures. While many effective encoders exist for DAGs, it
remains challenging to decode them in a principled manner, because the nodes of
a DAG can have many different topological orders. In this work, we propose a
grammar-based approach to constructing a principled, compact and equivalent
sequential representation of a DAG. Specifically, we view a graph as
derivations over an unambiguous grammar, where the DAG corresponds to a unique
sequence of production rules. Equivalently, the procedure to construct such a
description can be viewed as a lossless compression of the data. Such a
representation has many uses, including building a generative model for graph
generation, learning a latent space for property prediction, and leveraging the
sequence representational continuity for Bayesian Optimization over structured
data. Code is available at https://github.com/shiningsunnyday/induction.

</details>


### [38] [MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming](https://arxiv.org/abs/2505.22967)
*Chengqi Zheng, Jianda Chen, Yueming Lyu, Wen Zheng Terence Ng, Haopeng Zhang, Yew-Soon Ong, Ivor Tsang, Haiyan Yin*

**主要类别:** cs.LG

**AI概要:** MermaidFlow是一种基于Mermaid语言和进化算子的安全约束图进化框架，用于提升代理推理系统的鲁棒性和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法由于无约束的LLM驱动构造，经常生成脆弱且不可执行的计划，因此需要一种更加可靠的方法来生成工作流程。

**方法:** 通过使用Mermaid语言构建一个可验证的工作流程中间表示，并利用领域感知的进化算子进行演化搜索。

**结果:** 在不改变任务设置或评估协议的情况下，MermaidFlow在代理推理基准测试中实现了更高的成功率并更快地收敛到可执行的计划。

**结论:** MermaidFlow提供了一个可扩展、模块化的框架，支持安全约束下的图进化，从而实现更强大和可解释的代理推理系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MermaidFlow%3A+Redefining+Agentic+Workflow+Generation+via+Safety-Constrained+Evolutionary+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22967，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22967&send_immediately=true&force_search=false)

**原文摘要:** Despite the promise of autonomous agentic reasoning, existing workflow
generation methods frequently produce fragile, unexecutable plans due to
unconstrained LLM-driven construction. We introduce MermaidFlow, a framework
that redefines the agentic search space through safety-constrained graph
evolution. At its core, MermaidFlow represent workflows as a verifiable
intermediate representation using Mermaid, a structured and human-interpretable
graph language. We formulate domain-aware evolutionary operators, i.e.,
crossover, mutation, insertion, and deletion, to preserve semantic correctness
while promoting structural diversity, enabling efficient exploration of a
high-quality, statically verifiable workflow space. Without modifying task
settings or evaluation protocols, MermaidFlow achieves consistent improvements
in success rates and faster convergence to executable plans on the agent
reasoning benchmark. The experimental results demonstrate that
safety-constrained graph evolution offers a scalable, modular foundation for
robust and interpretable agentic reasoning systems.

</details>


### [39] [EquiReg: Equivariance Regularized Diffusion for Inverse Problems](https://arxiv.org/abs/2505.22973)
*Bahareh Tolooshams, Aditi Chandrashekar, Rayhan Zirvi, Abbas Mammadov, Jiachen Yao, Chuwei Wang, Anima Anandkumar*

**主要类别:** cs.LG

**AI概要:** EquiReg扩散是一种用于解决逆问题的新方法，在图像恢复和偏微分方程重建方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 由于当前方法依赖于各向同性高斯近似，导致从数据流形偏离，产生不一致且不稳定的重建结果。

**方法:** 提出了一种新的分布依赖的等变误差，并利用低误差函数来正则化扩散采样过程。

**结果:** EquiReg通过重新加权扩散轨迹并惩罚偏离数据流形的轨迹，提高了重建质量。

**结论:** EquiReg扩散模型在图像恢复任务和重建偏微分方程方面优于现有的扩散模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EquiReg%3A+Equivariance+Regularized+Diffusion+for+Inverse+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22973，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22973&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models represent the state-of-the-art for solving inverse problems
such as image restoration tasks. In the Bayesian framework, diffusion-based
inverse solvers incorporate a likelihood term to guide the prior sampling
process, generating data consistent with the posterior distribution. However,
due to the intractability of the likelihood term, many current methods rely on
isotropic Gaussian approximations, which lead to deviations from the data
manifold and result in inconsistent, unstable reconstructions. We propose
Equivariance Regularized (EquiReg) diffusion, a general framework for
regularizing posterior sampling in diffusion-based inverse problem solvers.
EquiReg enhances reconstructions by reweighting diffusion trajectories and
penalizing those that deviate from the data manifold. We define a new
distribution-dependent equivariance error, empirically identify functions that
exhibit low error for on-manifold samples and higher error for off-manifold
samples, and leverage these functions to regularize the diffusion sampling
process. When applied to a variety of solvers, EquiReg outperforms
state-of-the-art diffusion models in both linear and nonlinear image
restoration tasks, as well as in reconstructing partial differential equations.

</details>


### [40] [A Computational Approach to Improving Fairness in K-means Clustering](https://arxiv.org/abs/2505.22984)
*Guancheng Zhou, Haiping Xu, Hongkang Xu, Chenyu Li, Donghui Yan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种改进K-means聚类公平性的两阶段优化方法，能够在对聚类质量影响较小的情况下显著提升公平性。


<details>
  <summary>更多</summary>
  
**动机:** 论文的主要动机是解决K-means聚类算法在进一步分析或解释时可能存在的公平性问题，即某些簇可能会因为敏感变量（如性别或种族）而产生偏差，从而导致意想不到的社会后果。

**方法:** 论文提出了一种两阶段优化方法：首先进行聚类，然后调整一小部分选定数据点的聚类成员身份，以提高公平性。

**结果:** 实验结果表明，在基准数据集上，所提出的算法能够显著提高公平性，同时对聚类质量的影响极小，并且这些算法可以轻松扩展到广泛的聚类算法或公平性度量中。

**结论:** 该论文得出结论，通过两阶段优化公式改进K-means聚类的公平性，可以显著提高公平性，同时对聚类质量的影响最小。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Computational+Approach+to+Improving+Fairness+in+K-means+Clustering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22984，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22984&send_immediately=true&force_search=false)

**原文摘要:** The popular K-means clustering algorithm potentially suffers from a major
weakness for further analysis or interpretation. Some cluster may have
disproportionately more (or fewer) points from one of the subpopulations in
terms of some sensitive variable, e.g., gender or race. Such a fairness issue
may cause bias and unexpected social consequences. This work attempts to
improve the fairness of K-means clustering with a two-stage optimization
formulation--clustering first and then adjust cluster membership of a small
subset of selected data points. Two computationally efficient algorithms are
proposed in identifying those data points that are expensive for fairness, with
one focusing on nearest data points outside of a cluster and the other on
highly 'mixed' data points. Experiments on benchmark datasets show substantial
improvement on fairness with a minimal impact to clustering quality. The
proposed algorithms can be easily extended to a broad class of clustering
algorithms or fairness metrics.

</details>


### [41] [Knowledge Distillation for Reservoir-based Classifier: Human Activity Recognition](https://arxiv.org/abs/2505.22985)
*Masaharu Kagiyama, Tsuyoshi Okita*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的、节能的人类活动识别模型PatchEchoClassifier，通过使用基于储层的机制和知识蒸馏框架，在保持高准确率的同时大幅度降低了计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 开发一种节能的时间序列数据分类器。

**方法:** 引入了一种名为PatchEchoClassifier的新模型，该模型使用基于储层的机制（称为回声状态网络（ESN）），并结合了知识蒸馏框架进行高效训练。

**结果:** 实验评估显示，该模型在显著降低计算成本的同时，在多个HAR数据集上实现了超过80%的准确率。特别是，与广泛使用的卷积基线DeepConvLSTM相比，PatchEchoClassifier仅需要大约六分之一的浮点运算(FLOPS)。

**结论:** PatchEchoClassifier是一种有前景的解决方案，适用于边缘计算环境中的实时和节能的人类活动识别。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Knowledge+Distillation+for+Reservoir-based+Classifier%3A+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22985，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22985&send_immediately=true&force_search=false)

**原文摘要:** This paper aims to develop an energy-efficient classifier for time-series
data by introducing PatchEchoClassifier, a novel model that leverages a
reservoir-based mechanism known as the Echo State Network (ESN). The model is
designed for human activity recognition (HAR) using one-dimensional sensor
signals and incorporates a tokenizer to extract patch-level representations. To
train the model efficiently, we propose a knowledge distillation framework that
transfers knowledge from a high-capacity MLP-Mixer teacher to the lightweight
reservoir-based student model. Experimental evaluations on multiple HAR
datasets demonstrate that our model achieves over 80 percent accuracy while
significantly reducing computational cost. Notably, PatchEchoClassifier
requires only about one-sixth of the floating point operations (FLOPS) compared
to DeepConvLSTM, a widely used convolutional baseline. These results suggest
that PatchEchoClassifier is a promising solution for real-time and
energy-efficient human activity recognition in edge computing environments.

</details>


### [42] [Model-Preserving Adaptive Rounding](https://arxiv.org/abs/2505.22988)
*Albert Tseng, Zhaofeng Sun, Christopher De Sa*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的量化算法YAQA，通过使用基于Hessian的自适应舍入方法，在模型压缩中显著减少了KL散度，并在下游任务上实现了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的后训练量化（PTQ）方法主要关注于独立最小化局部激活误差，忽略了后续层的影响，导致模型输出分布与原模型差距较大。因此需要一种更全局优化的量化方法。

**方法:** YAQA利用每一线性层相对于整个模型KL散度的Kronecker分解近似Hessian矩阵，并结合与量化器无关的舍入算法进行自适应优化。

**结果:** 实验表明，YAQA平均减少了约30%的KL散度，并在多个模型和量化方案下达到了当前最优的下游任务性能。

**结论:** YAQA提供了一种有效的后训练量化方法，能够在大规模语言模型中实现更好的压缩效果和性能表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model-Preserving+Adaptive+Rounding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22988，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22988&send_immediately=true&force_search=false)

**原文摘要:** The main goal of post-training quantization (PTQ) is to produced a compressed
model whose output distribution is as close to the original model's as
possible. To do this tractably, almost all LLM PTQ algorithms quantize linear
layers by independently minimizing the immediate activation error. However,
this localized objective ignores the effect of subsequent layers, so reducing
it does not necessarily give a closer model. In this work, we introduce Yet
Another Quantization Algorithm (YAQA), an adaptive rounding algorithm that uses
Kronecker-factored approximations of each linear layer's Hessian with respect
to the \textit{full model} KL divergence. YAQA consists of two components:
Kronecker-factored sketches of the full layerwise Hessian that can be tractably
computed for hundred-billion parameter LLMs, and a quantizer-independent
rounding algorithm that uses these sketches and comes with theoretical
guarantees. Across a wide range of models and quantizers, YAQA empirically
reduces the KL divergence to the original model by $\approx 30\%$ while
achieving state of the art performance on downstream tasks.

</details>


### [43] [Number of Clusters in a Dataset: A Regularized K-means Approach](https://arxiv.org/abs/2505.22991)
*Behzad Kamgar-Parsi, Behrooz Kamgar-Parsi*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一个基于理想聚类设定的正则化超参数λ的理论边界，并研究了带加法与乘法正则化的k均值算法以解决多解问题。


<details>
  <summary>更多</summary>
  
**动机:** 寻找未标记数据集中有意义的聚类数量在许多应用中很重要，但目前尚无系统的方法来设置正则化超参数λ。

**方法:** 通过假设理想聚类（d维球体，半径相同）推导出正则化超参数λ的严格边界，并分析了带有加法和乘法正则化的k均值算法。

**结果:** 实验表明带有加法正则化的k均值算法通常会产生多个解决方案；而共识方法结合加法和乘法正则化可减少某些情况下的多解歧义性。

**结论:** 本文得出了一种针对正则化超参数λ的严格边界，并展示了在k均值算法中使用加法和乘法正则化可以减少多解歧义性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Number+of+Clusters+in+a+Dataset%3A+A+Regularized+K-means+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22991，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22991&send_immediately=true&force_search=false)

**原文摘要:** Finding the number of meaningful clusters in an unlabeled dataset is
important in many applications. Regularized k-means algorithm is a possible
approach frequently used to find the correct number of distinct clusters in
datasets. The most common formulation of the regularization function is the
additive linear term $\lambda k$, where $k$ is the number of clusters and
$\lambda$ a positive coefficient. Currently, there are no principled guidelines
for setting a value for the critical hyperparameter $\lambda$. In this paper,
we derive rigorous bounds for $\lambda$ assuming clusters are {\em ideal}.
Ideal clusters (defined as $d$-dimensional spheres with identical radii) are
close proxies for k-means clusters ($d$-dimensional spherically symmetric
distributions with identical standard deviations). Experiments show that the
k-means algorithm with additive regularizer often yields multiple solutions.
Thus, we also analyze k-means algorithm with multiplicative regularizer. The
consensus among k-means solutions with additive and multiplicative
regularizations reduces the ambiguity of multiple solutions in certain cases.
We also present selected experiments that demonstrate performance of the
regularized k-means algorithms as clusters deviate from the ideal assumption.

</details>


### [44] [Walking the Weight Manifold: a Topological Approach to Conditioning Inspired by Neuromodulation](https://arxiv.org/abs/2505.22994)
*Ari S. Benjamin, Kyle Daruwalla, Christian Pehle, Anthony M. Zador*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种受神经调节启发的方法，通过优化低维流形上的权重函数来高效学习多个相关任务。


<details>
  <summary>更多</summary>
  
**动机:** 受神经调节启发，作者希望尽可能高效地学习一系列相似任务，并跨任务重用知识。

**方法:** 通过优化具有预定义拓扑结构的流形来学习任务上下文变量的平滑参数化函数。

**结果:** 具有多种拓扑结构的流形优于输入连接的条件，并更好地推广到分布外样本。

**结论:** 调制权重在低维流形上提供了一种有原则且有效的传统条件替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Walking+the+Weight+Manifold%3A+a+Topological+Approach+to+Conditioning+Inspired+by+Neuromodulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22994，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22994&send_immediately=true&force_search=false)

**原文摘要:** One frequently wishes to learn a range of similar tasks as efficiently as
possible, re-using knowledge across tasks. In artificial neural networks, this
is typically accomplished by conditioning a network upon task context by
injecting context as input. Brains have a different strategy: the parameters
themselves are modulated as a function of various neuromodulators such as
serotonin. Here, we take inspiration from neuromodulation and propose to learn
weights which are smoothly parameterized functions of task context variables.
Rather than optimize a weight vector, i.e. a single point in weight space, we
optimize a smooth manifold in weight space with a predefined topology. To
accomplish this, we derive a formal treatment of optimization of manifolds as
the minimization of a loss functional subject to a constraint on volumetric
movement, analogous to gradient descent. During inference, conditioning selects
a single point on this manifold which serves as the effective weight matrix for
a particular sub-task. This strategy for conditioning has two main advantages.
First, the topology of the manifold (whether a line, circle, or torus) is a
convenient lever for inductive biases about the relationship between tasks.
Second, learning in one state smoothly affects the entire manifold, encouraging
generalization across states. To verify this, we train manifolds with several
topologies, including straight lines in weight space (for conditioning on e.g.
noise level in input data) and ellipses (for rotated images). Despite their
simplicity, these parameterizations outperform conditioning identical networks
by input concatenation and better generalize to out-of-distribution samples.
These results suggest that modulating weights over low-dimensional manifolds
offers a principled and effective alternative to traditional conditioning.

</details>


### [45] [LLM Agents for Bargaining with Utility-based Feedback](https://arxiv.org/abs/2505.22998)
*Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim*

**主要类别:** cs.LG

**AI概要:** 该研究提出了一个用于提升大型语言模型在议价任务中表现的框架，包括新颖的数据集BargainArena、基于效用的评估指标及结构化反馈机制，实验证明这些方法能显著改善模型的谈判策略并增强其对手意识推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基准测试难以捕捉现实世界中议价任务的复杂性，且大型语言模型在策略深度和适应人类因素方面存在局限性，因此需要改进以提高模型的实际应用能力。

**方法:** 提出了一种综合框架，包括BargainArena数据集、基于效用理论的人类对齐评估指标以及结构化反馈机制，并结合上下文学习提示进行实验验证。

**结果:** 实验结果表明，大型语言模型在未经训练时往往表现出与人类偏好不一致的谈判策略，而使用结构化反馈机制后，模型在议价任务中的表现显著提升，展现出更深层次的战略和对手意识推理能力。

**结论:** 论文得出结论，通过引入基于效用的反馈机制和BargainArena数据集，可以有效提升大型语言模型在议价任务中的表现，增强其战略深度和对手意识推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM+Agents+for+Bargaining+with+Utility-based+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22998，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22998&send_immediately=true&force_search=false)

**原文摘要:** Bargaining, a critical aspect of real-world interactions, presents challenges
for large language models (LLMs) due to limitations in strategic depth and
adaptation to complex human factors. Existing benchmarks often fail to capture
this real-world complexity. To address this and enhance LLM capabilities in
realistic bargaining, we introduce a comprehensive framework centered on
utility-based feedback. Our contributions are threefold: (1) BargainArena, a
novel benchmark dataset with six intricate scenarios (e.g., deceptive
practices, monopolies) to facilitate diverse strategy modeling; (2)
human-aligned, economically-grounded evaluation metrics inspired by utility
theory, incorporating agent utility and negotiation power, which implicitly
reflect and promote opponent-aware reasoning (OAR); and (3) a structured
feedback mechanism enabling LLMs to iteratively refine their bargaining
strategies. This mechanism can positively collaborate with in-context learning
(ICL) prompts, including those explicitly designed to foster OAR. Experimental
results show that LLMs often exhibit negotiation strategies misaligned with
human preferences, and that our structured feedback mechanism significantly
improves their performance, yielding deeper strategic and opponent-aware
reasoning.

</details>


### [46] [Hybrid Cross-domain Robust Reinforcement Learning](https://arxiv.org/abs/2505.23003)
*Linh Le Pham Van, Minh Hoang Nguyen, Hung Le, Hung The Tran, Sunil Gupta*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种名为HYDRO的新框架，它利用在线模拟器来补充离线数据集，在处理现实世界中的环境不确定性方面取得了显著成效。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决现实中因环境动态变化而产生的不确定性问题，并改善现有离线数据集有限的情况。

**方法:** 通过衡量和最小化模拟器与不确定性集中的最坏情况模型之间的性能差距，采用新的不确定性过滤和优先采样方法选择最相关和可靠的模拟样本。

**结果:** 实验表明，HYDRO在各种任务上都表现出优于现有方法的性能。

**结论:** HYDRO框架在离线强化学习中展现出优于现有方法的性能，提升了样本效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hybrid+Cross-domain+Robust+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23003，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23003&send_immediately=true&force_search=false)

**原文摘要:** Robust reinforcement learning (RL) aims to learn policies that remain
effective despite uncertainties in its environment, which frequently arise in
real-world applications due to variations in environment dynamics. The robust
RL methods learn a robust policy by maximizing value under the worst-case
models within a predefined uncertainty set. Offline robust RL algorithms are
particularly promising in scenarios where only a fixed dataset is available and
new data cannot be collected. However, these approaches often require extensive
offline data, and gathering such datasets for specific tasks in specific
environments can be both costly and time-consuming. Using an imperfect
simulator offers a faster, cheaper, and safer way to collect data for training,
but it can suffer from dynamics mismatch. In this paper, we introduce HYDRO,
the first Hybrid Cross-Domain Robust RL framework designed to address these
challenges. HYDRO utilizes an online simulator to complement the limited amount
of offline datasets in the non-trivial context of robust RL. By measuring and
minimizing performance gaps between the simulator and the worst-case models in
the uncertainty set, HYDRO employs novel uncertainty filtering and prioritized
sampling to select the most relevant and reliable simulator samples. Our
extensive experiments demonstrate HYDRO's superior performance over existing
methods across various tasks, underscoring its potential to improve sample
efficiency in offline robust RL.

</details>


### [47] [QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining](https://arxiv.org/abs/2505.23004)
*Kyle R. Chickering, Bangzheng Li, Muhao Chen*

**主要类别:** cs.LG

**AI概要:** QLIP是一种用于多模态大语言模型的新型视觉编码器，可以提升视觉理解性能，无需重新训练整个模型。


<details>
  <summary>更多</summary>
  
**动机:** CLIP视觉编码器存在固定输入分辨率限制和无法为不同图像生成分离嵌入的问题，且更换现有模型的编码器通常计算成本高。

**方法:** 分析CLIP视觉编码器的局限性，并提出QLIP作为替代方案，采用基于图像四叉树的内容感知分块方法。

**结果:** 实验结果表明，QLIP在LLaVA v1.5模型系列上提高了各种模型尺寸上的视觉问答准确性，尤其在V*基准测试中提升了高达13.6%的理解性能。

**结论:** QLIP是一个有效的CLIP替换方案，能够在不进行大规模再训练的情况下提升多模态大语言模型的视觉理解能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是QLIP%3A+A+Dynamic+Quadtree+Vision+Prior+Enhances+MLLM+Performance+Without+Retraining，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23004&send_immediately=true&force_search=false)

**原文摘要:** Multimodal Large Language Models (MLLMs) encode images into visual tokens,
aligning visual and textual signals within a shared latent space to facilitate
crossmodal representation learning. The CLIP model is a widely adopted
foundational vision language model whose vision encoder has played a critical
role in the development of MLLMs such as LLaVA. However, the CLIP vision
encoder suffers from notable limitations including being constrained to only
handling fixed input resolutions and a failure to produce separated embeddings
for dissimilar images. Replacing the vision encoder of an existing model
typically incurs substantial computational costs because such a change often
necessitates retraining the entire model pipeline.
  In this work, we identify two factors which underlie the limitations of the
CLIP vision encoder: mesoscopic bias and interpolation bias. To address these
issues, we propose QLIP, a drop-in replacement for CLIP that can be seamlessly
integrated with existing MLLMs with only a few lines of code and can enhance
both coarse-grained and fine-grained visual understanding, without re-training.
QLIP is designed around an image quadtree which replaces the standard uniform
grid patches with a novel content aware patchification. Our experimental
results demonstrate that QLIP improves the general visual question answering
accuracy of the LLaVA v1.5 model series across various model sizes--without
requiring retraining or fine-tuning of the full MLLM. Notably, QLIP boosts
detailed understanding performance on the challenging $V^{\ast}$ benchmark by
up to 13.6 percent.

</details>


### [48] [EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic, Expressiveness, and Linguistic Challenges Using Model-as-a-Judge](https://arxiv.org/abs/2505.23009)
*Ruskin Raj Manku, Yuzhi Tang, Xingjian Shi, Mu Li, Alex Smola*

**主要类别:** cs.LG

**AI概要:** 本文提出了EmergentTTS-Eval，一个涵盖六种挑战性TTS场景的全面基准，通过自动化测试生成和评估，揭示了TTS系统的细粒度性能差异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的文本到语音（TTS）基准未能充分衡量模型处理复杂语义和细微差别文本的能力。

**方法:** 通过LLM从少量人工编写的种子提示开始，迭代扩展测试用例，并利用大型音频语言模型（LALM）进行多维度评估。

**结果:** 构建了包含1645个多样化测试案例的基准数据集，并成功评估了多个最先进的开源和专有TTS系统。

**结论:** EmergentTTS-Eval能够揭示细粒度的TTS系统性能差异，并且模型评分方法与人类偏好高度相关。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EmergentTTS-Eval%3A+Evaluating+TTS+Models+on+Complex+Prosodic%2C+Expressiveness%2C+and+Linguistic+Challenges+Using+Model-as-a-Judge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23009，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23009&send_immediately=true&force_search=false)

**原文摘要:** Text-to-Speech (TTS) benchmarks often fail to capture how well models handle
nuanced and semantically complex text. Building on $\textit{EmergentTTS}$, we
introduce $\textit{EmergentTTS-Eval}$, a comprehensive benchmark covering six
challenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic
complexity, complex pronunciation (e.g. URLs, formulas), and questions.
Crucially, our framework automates both test-case generation and evaluation,
making the benchmark easily extensible. Starting from a small set of
human-written seed prompts, we iteratively extend them using LLMs to target
specific structural, phonetic and prosodic challenges, resulting in 1,645
diverse test cases. Moreover, we employ a model-as-a-judge approach, using a
Large Audio Language Model (LALM) to assess the speech across multiple
dimensions such as expressed emotion, prosodic, intonational, and pronunciation
accuracy. We evaluate state-of-the-art open-source and proprietary TTS systems,
such as 11Labs, Deepgram, and OpenAI's 4o-mini-TTS, on EmergentTTS-Eval,
demonstrating its ability to reveal fine-grained performance differences.
Results show that the model-as-a-judge approach offers robust TTS assessment
and a high correlation with human preferences. We open source the evaluation
$\href{https://github.com/boson-ai/EmergentTTS-Eval-public}{code}$ and the
$\href{https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{dataset}$.

</details>


### [49] [Scalable Complexity Control Facilitates Reasoning Ability of LLMs](https://arxiv.org/abs/2505.23013)
*Liangkai Hang, Junjie Yao, Zhiwei Bai, Tianyi Chen, Yang Chen, Rongjie Diao, Hezhou Li, Pengxiao Lin, Zhiwei Wang, Cheng Xu, Zhongwang Zhang, Zhangchen Zhou, Zhiyu Li, Zehao Lin, Kai Chen, Feiyu Xiong, Yaoyu Zhang, Weinan E, Hongkang Yang, Zhi-Qin John Xu*

**主要类别:** cs.LG

**AI概要:** 本文探讨了通过调整初始化率和权重衰减系数来控制大型语言模型复杂度的方法，发现这种方法可以改善模型的扩展性，并提升了模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，大型语言模型的推理能力迅速发展，需要寻找能够可靠增强其泛化能力的基本方法。

**方法:** 该研究通过改变模型大小和数据大小的情况下调整初始化率和权重衰减系数来评估其对大型语言模型的缩放定律的影响。

**结果:** 实验结果显示，通过调整模型复杂度超参数，2.4B模型在1T标记预训练时基准性能得到了显著提升。

**结论:** 论文得出结论，通过调整初始化率和权重衰减系数来控制模型复杂度是提高大型语言模型可扩展性的有希望的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Complexity+Control+Facilitates+Reasoning+Ability+of+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23013，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23013&send_immediately=true&force_search=false)

**原文摘要:** The reasoning ability of large language models (LLMs) has been rapidly
advancing in recent years, attracting interest in more fundamental approaches
that can reliably enhance their generalizability. This work demonstrates that
model complexity control, conveniently implementable by adjusting the
initialization rate and weight decay coefficient, improves the scaling law of
LLMs consistently over varying model sizes and data sizes. This gain is further
illustrated by comparing the benchmark performance of 2.4B models pretrained on
1T tokens with different complexity hyperparameters. Instead of fixing the
initialization std, we found that a constant initialization rate (the exponent
of std) enables the scaling law to descend faster in both model and data sizes.
These results indicate that complexity control is a promising direction for the
continual advancement of LLMs.

</details>


### [50] [Hyperbolic-PDE GNN: Spectral Graph Neural Networks in the Perspective of A System of Hyperbolic Partial Differential Equations](https://arxiv.org/abs/2505.23014)
*Juwei Yue, Haikuo Li, Jiawei Sheng, Xiaodong Li, Taoyu Su, Tingwen Liu, Li Guo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于双曲偏微分方程的消息传递机制，用于提升图神经网络的拓扑特征学习能力，并通过实验验证其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 传统图神经网络在空间域中学习节点特征，难以保证对图拓扑结构的有效建模，因此需要一种更具解释性和表现力的方法来捕捉拓扑特征。

**方法:** 将消息传递机制形式化为双曲偏微分方程（hyperbolic PDEs）系统，利用多项式逼近任意滤波函数，并将其应用于谱图神经网络的消息传递增强。

**结果:** 提出的方法不仅增强了消息传递的可解释性，还显著提升了多种谱图神经网络在各类图任务中的性能，表现出良好的灵活性和效果。

**结论:** 通过将消息传递机制建模为双曲偏微分方程系统，本文成功地提升了图神经网络的拓扑特征学习能力，并与谱图神经网络建立了联系，实验验证了该方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hyperbolic-PDE+GNN%3A+Spectral+Graph+Neural+Networks+in+the+Perspective+of+A+System+of+Hyperbolic+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23014，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23014&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) leverage message passing mechanisms to learn the
topological features of graph data. Traditional GNNs learns node features in a
spatial domain unrelated to the topology, which can hardly ensure topological
features. In this paper, we formulates message passing as a system of
hyperbolic partial differential equations (hyperbolic PDEs), constituting a
dynamical system that explicitly maps node representations into a particular
solution space. This solution space is spanned by a set of eigenvectors
describing the topological structure of graphs. Within this system, for any
moment in time, a node features can be decomposed into a superposition of the
basis of eigenvectors. This not only enhances the interpretability of message
passing but also enables the explicit extraction of fundamental characteristics
about the topological structure. Furthermore, by solving this system of
hyperbolic partial differential equations, we establish a connection with
spectral graph neural networks (spectral GNNs), serving as a message passing
enhancement paradigm for spectral GNNs.We further introduce polynomials to
approximate arbitrary filter functions. Extensive experiments demonstrate that
the paradigm of hyperbolic PDEs not only exhibits strong flexibility but also
significantly enhances the performance of various spectral GNNs across diverse
graph tasks.

</details>


### [51] [$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2505.23017)
*Xingjian Wu, Xiangfei Qiu, Hongfan Gao, Jilin Hu, Bin Yang, Chenjuan Guo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的概率时间序列预测模型K2VAE，该模型通过将非线性时间序列转化为线性动力系统并对预测进行优化和建模不确定性，解决了现有方法在长期预测中的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大多数方法擅长于短期预测，而忽视了长期概率时间序列预测的困难，特别是非线性动态对预测精度的显著不利影响以及每次迭代成本增加导致生成模型效率低下。

**方法:** 引入了基于VAE的生成模型K2VAE，利用KoopmanNet将非线性时间序列转换为线性动力系统，并设计KalmanNet来改进预测并建模这种线性系统的不确定性。

**结果:** 广泛的实验表明，K2VAE在短期和长期的概率时间序列预测方面优于目前最先进的方法。

**结论:** K2VAE在短期和长期概率时间序列预测中均优于现有方法，提供更高效且准确的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%24K%5E2%24VAE%3A+A+Koopman-Kalman+Enhanced+Variational+AutoEncoder+for+Probabilistic+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23017&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic Time Series Forecasting (PTSF) plays a crucial role in
decision-making across various fields, including economics, energy, and
transportation. Most existing methods excell at short-term forecasting, while
overlooking the hurdles of Long-term Probabilistic Time Series Forecasting
(LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have
a significant adverse effect on prediction accuracy, and make generative models
inefficient by increasing the cost of each iteration. To overcome these
limitations, we introduce $K^2$VAE, an efficient VAE-based generative model
that leverages a KoopmanNet to transform nonlinear time series into a linear
dynamical system, and devises a KalmanNet to refine predictions and model
uncertainty in such linear system, which reduces error accumulation in
long-term forecasting. Extensive experiments demonstrate that $K^2$VAE
outperforms state-of-the-art methods in both short- and long-term PTSF,
providing a more efficient and accurate solution.

</details>


### [52] [SCORPIO: Serving the Right Requests at the Right Time for Heterogeneous SLOs in LLM Inference](https://arxiv.org/abs/2505.23022)
*Yinghao Tang, Tingfeng Lan, Xiuqi Huang, Hui Lu, Wei Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的面向服务质量目标（SLO）的大语言模型（LLM）服务系统SCORPIO，通过自适应调度显著提高了系统性能和服务质量达标率。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM服务系统忽视了如TTFT和TPOT等服务质量目标，导致SLO达成率不理想。

**方法:** 设计了一个面向SLO的LLM服务系统，包含TTFT Guard和TPOT Guard，并结合预测模块进行评估测试。

**结果:** 与现有技术相比，SCORPIO将系统有效吞吐量提高了最多14.4倍，SLO符合率提高了最多46.5%。

**结论:** SCORPIO通过利用SLO异质性进行自适应调度，在接纳控制、队列管理和批处理选择方面表现出色，提高了系统有效吞吐量和SLO达成率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SCORPIO%3A+Serving+the+Right+Requests+at+the+Right+Time+for+Heterogeneous+SLOs+in+LLM+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23022，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23022&send_immediately=true&force_search=false)

**原文摘要:** Existing Large Language Model (LLM) serving systems prioritize maximum
throughput. They often neglect Service Level Objectives (SLOs) such as Time to
First Token (TTFT) and Time Per Output Token (TPOT), which leads to suboptimal
SLO attainment. This paper introduces SCORPIO, an SLO-oriented LLM serving
system designed to maximize system goodput and SLO attainment for workloads
with heterogeneous SLOs. Our core insight is to exploit SLO heterogeneity for
adaptive scheduling across admission control, queue management, and batch
selection. SCORPIO features a TTFT Guard, which employs least-deadline-first
reordering and rejects unattainable requests, and a TPOT Guard, which utilizes
a VBS-based admission control and a novel credit-based batching mechanism. Both
guards are supported by a predictive module. Evaluations demonstrate that
SCORPIO improves system goodput by up to 14.4X and SLO adherence by up to 46.5%
compared to state-of-the-art baselines.

</details>


### [53] [An Empirical Study of Federated Prompt Learning for Vision Language Model](https://arxiv.org/abs/2505.23024)
*Zhihao Wang, Wenke Huang, Tian Chen, Zekun Shi, Guancheng Wan, Yu Qiao, Bin Yang, Jian Wang, Bing Li, Mang Ye*

**主要类别:** cs.LG

**AI概要:** 本文研究了联邦学习环境中视觉语言模型的提示学习问题，并提出了应对数据异构性的方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管提示学习已成为适应视觉语言模型的关键技术，但在联邦学习场景中应用的研究仍不足。

**方法:** 进行了广泛的实验，评估了多种联邦学习和提示配置对联邦提示学习鲁棒性的影响，并探讨了复杂场景下的提示学习策略。

**结果:** 系统地研究了数据异构性挑战下语言提示学习与视觉提示学习的行为差异，并探索了提升提示学习效果的策略。

**结论:** 该论文提供了在联邦学习环境下优化视觉语言模型提示学习的实际见解，有助于隐私保护环境中VLM的广泛部署。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Empirical+Study+of+Federated+Prompt+Learning+for+Vision+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23024&send_immediately=true&force_search=false)

**原文摘要:** The Vision Language Model (VLM) excels in aligning vision and language
representations, and prompt learning has emerged as a key technique for
adapting such models to downstream tasks. However, the application of prompt
learning with VLM in federated learning (\fl{}) scenarios remains
underexplored. This paper systematically investigates the behavioral
differences between language prompt learning (LPT) and vision prompt learning
(VPT) under data heterogeneity challenges, including label skew and domain
shift. We conduct extensive experiments to evaluate the impact of various \fl{}
and prompt configurations, such as client scale, aggregation strategies, and
prompt length, to assess the robustness of Federated Prompt Learning (FPL).
Furthermore, we explore strategies for enhancing prompt learning in complex
scenarios where label skew and domain shift coexist, including leveraging both
prompt types when computational resources allow. Our findings offer practical
insights into optimizing prompt learning in federated settings, contributing to
the broader deployment of VLMs in privacy-preserving environments.

</details>


### [54] [Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift](https://arxiv.org/abs/2505.23027)
*Minh Nguyen Nhat To, Paul F RWilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul G. Krishnan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Diverse Prototypical Ensembles (DPEs)的方法，通过使用多样化的原型分类器集合来适应性地捕捉与子群体相关的风险，以解决训练数据和目标数据之间子群体分布差异导致的模型性能下降问题。


<details>
  <summary>更多</summary>
  
**动机:** 由于现有方法依赖于对子群体数量和性质的假设以及群体成员身份的注释，在许多现实世界的数据集中这些条件不可用，因此需要一种新的解决方案来处理子群体转移问题。

**方法:** 在给定特征提取网络的基础上，将标准线性分类层替换为原型分类器的混合，每个分类器成员在训练时关注不同的特征和样本，从而形成多样化的分类器集合。

**结果:** 在涵盖多种领域和类型子群体转移的九个现实世界数据集上的实验表明，该方法在最坏组准确率方面通常优于现有的最先进方法。

**结论:** DPEs 方法有效解决了子群体分布不一致带来的机器学习模型泛化能力下降问题，并在多个数据集上验证了其优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diverse+Prototypical+Ensembles+Improve+Robustness+to+Subpopulation+Shift，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23027，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23027&send_immediately=true&force_search=false)

**原文摘要:** The subpopulationtion shift, characterized by a disparity in subpopulation
distributibetween theween the training and target datasets, can significantly
degrade the performance of machine learning models. Current solutions to
subpopulation shift involve modifying empirical risk minimization with
re-weighting strategies to improve generalization. This strategy relies on
assumptions about the number and nature of subpopulations and annotations on
group membership, which are unavailable for many real-world datasets. Instead,
we propose using an ensemble of diverse classifiers to adaptively capture risk
associated with subpopulations. Given a feature extractor network, we replace
its standard linear classification layer with a mixture of prototypical
classifiers, where each member is trained to classify the data while focusing
on different features and samples from other members. In empirical evaluation
on nine real-world datasets, covering diverse domains and kinds of
subpopulation shift, our method of Diverse Prototypical Ensembles (DPEs) often
outperforms the prior state-of-the-art in worst-group accuracy. The code is
available at https://github.com/minhto2802/dpe4subpop

</details>


### [55] [Bayesian Neural Scaling Laws Extrapolation with Prior-Fitted Networks](https://arxiv.org/abs/2505.23032)
*Dongwoo Lee, Dong Bok Lee, Steven Adriaensen, Juho Lee, Sung Ju Hwang, Frank Hutter, Seon Joo Kim, Hae Beom Lee*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的基于贝叶斯框架的神经网络缩放定律外推方法，能够有效量化不确定性，并在数据有限的情况下优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的缩放定律研究大多依赖于点估计而无法量化不确定性，而在涉及决策问题的实际应用中（如计算资源投资带来的性能提升预测），不确定性量化至关重要。

**方法:** 设计了一种先验分布，使得可以采样无限多的合成函数来模拟现实世界的神经缩放定律，从而让PFN进行元学习外推。

**结果:** 在现实世界的神经缩放定律任务上验证了所提方法的有效性，相较于现有方法（包括点估计和贝叶斯方法）表现更优，尤其是在数据有限的场景下，例如贝叶斯主动学习。

**结论:** 该论文提出了一种基于贝叶斯框架的神经缩放定律外推方法，通过Prior-data Fitted Networks (PFNs)实现了对不确定性的量化，并在数据有限的情况下表现出优越性能，具有在实际应用中进行可靠预测的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Neural+Scaling+Laws+Extrapolation+with+Prior-Fitted+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23032，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23032&send_immediately=true&force_search=false)

**原文摘要:** Scaling has been a major driver of recent advancements in deep learning.
Numerous empirical studies have found that scaling laws often follow the
power-law and proposed several variants of power-law functions to predict the
scaling behavior at larger scales. However, existing methods mostly rely on
point estimation and do not quantify uncertainty, which is crucial for
real-world applications involving decision-making problems such as determining
the expected performance improvements achievable by investing additional
computational resources. In this work, we explore a Bayesian framework based on
Prior-data Fitted Networks (PFNs) for neural scaling law extrapolation.
Specifically, we design a prior distribution that enables the sampling of
infinitely many synthetic functions resembling real-world neural scaling laws,
allowing our PFN to meta-learn the extrapolation. We validate the effectiveness
of our approach on real-world neural scaling laws, comparing it against both
the existing point estimation methods and Bayesian approaches. Our method
demonstrates superior performance, particularly in data-limited scenarios such
as Bayesian active learning, underscoring its potential for reliable,
uncertainty-aware extrapolation in practical applications.

</details>


### [56] [From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data](https://arxiv.org/abs/2505.23042)
*Siwen Wang, Shitou Zhang, Wan-Lin Chen, Dung Truong, Tzyy-Ping Jung*

**主要类别:** cs.LG

**AI概要:** 该论文通过微调LaBraM模型来识别课堂环境中学生的压力状态，结果表明大型EEG模型在现实场景中具有高准确率和高效性。


<details>
  <summary>更多</summary>
  
**动机:** 评估大型EEG模型在真实环境中的适用性，而不仅仅是受控临床环境。

**方法:** 微调LaBraM模型，并使用18名研究生的静息态EEG数据训练二分类器以区分正常与高压力状态。

**结果:** 最佳模型在5秒窗口下达到90.47%的平衡准确率，显著优于传统方法。

**结论:** 研究表明，大型EEG模型在处理现实世界EEG数据方面表现出色，展示了其在脑机接口应用中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Theory+to+Application%3A+Fine-Tuning+Large+EEG+Model+with+Real-World+Stress+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23042&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in Large Language Models have inspired the development of
foundation models across various domains. In this study, we evaluate the
efficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-art
foundation EEG model, on a real-world stress classification dataset collected
in a graduate classroom. Unlike previous studies that primarily evaluate LEMs
using data from controlled clinical settings, our work assesses their
applicability to real-world environments. We train a binary classifier that
distinguishes between normal and elevated stress states using resting-state EEG
data recorded from 18 graduate students during a class session. The
best-performing fine-tuned model achieves a balanced accuracy of 90.47% with a
5-second window, significantly outperforming traditional stress classifiers in
both accuracy and inference efficiency. We further evaluate the robustness of
the fine-tuned LEM under random data shuffling and reduced channel counts.
These results demonstrate the capability of LEMs to effectively process
real-world EEG data and highlight their potential to revolutionize
brain-computer interface applications by shifting the focus from model-centric
to data-centric design.

</details>


### [57] [ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation](https://arxiv.org/abs/2505.23048)
*Tianci Bu, Le Zhou, Wenchuan Yang, Jianhong Mou, Kang Yang, Suoyi Tan, Feng Yao, Jingyuan Wang, Xin Lu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为ProDiff的轨迹插补框架，仅用两个端点作为输入，通过整合原型学习和去噪扩散概率模型，实现了强大的时空重建能力，并在多个数据集上优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 由于设备限制和多样化的数据收集场景，轨迹数据常常不完整。现有的插补方法依赖于稀疏的轨迹或旅行信息，这些方法假设稀疏轨迹保留了基本的行为模式，对数据获取要求较高且忽略了大规模人类轨迹嵌入的潜力。

**方法:** ProDiff利用原型学习来嵌入人类移动模式，并结合去噪扩散概率模型进行鲁棒的时空重建。

**结果:** ProDiff在FourSquare上提高了6.28%的准确性，在WuXi上提高了2.52%，生成轨迹与真实轨迹之间的相关性达到0.927。

**结论:** ProDiff是一个轨迹插补框架，仅使用两个端点作为最小信息，通过整合原型学习和去噪扩散概率模型，实现了强大的时空重建能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ProDiff%3A+Prototype-Guided+Diffusion+for+Minimal+Information+Trajectory+Imputation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23048&send_immediately=true&force_search=false)

**原文摘要:** Trajectory data is crucial for various applications but often suffers from
incompleteness due to device limitations and diverse collection scenarios.
Existing imputation methods rely on sparse trajectory or travel information,
such as velocity, to infer missing points. However, these approaches assume
that sparse trajectories retain essential behavioral patterns, which place
significant demands on data acquisition and overlook the potential of
large-scale human trajectory embeddings. To address this, we propose ProDiff, a
trajectory imputation framework that uses only two endpoints as minimal
information. It integrates prototype learning to embed human movement patterns
and a denoising diffusion probabilistic model for robust spatiotemporal
reconstruction. Joint training with a tailored loss function ensures effective
imputation. ProDiff outperforms state-of-the-art methods, improving accuracy by
6.28\% on FourSquare and 2.52\% on WuXi. Further analysis shows a 0.927
correlation between generated and real trajectories, demonstrating the
effectiveness of our approach.

</details>


### [58] [DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration](https://arxiv.org/abs/2505.23049)
*Tianteng Gu, Bei Liu, Bo Xiao, Ke Zeng, Jiacheng Liu, Yanmin Qian*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为DenoiseRotator的新方法，通过可学习的正交变换重新分配模型权重的重要性，以提高大型语言模型在剪枝过程中的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的剪枝方法主要关注于估计单个权重的重要性，但这种方法在半结构化稀疏约束下常常导致显著的性能下降。因此，作者提出了一个新的视角，即先调整参数的重要性分布，使模型更适合剪枝。

**方法:** 通过最小化归一化重要性得分的信息熵，将重要性集中在较少的权重上。使用名为DenoiseRotator的可学习正交变换应用于模型的权重矩阵。

**结果:** 在LLaMA3、Qwen2.5和Mistral模型上评估了该方法，在50%非结构化和2:4半结构化稀疏条件下，DenoiseRotator显著改善了困惑度和零样本准确率。例如，在LLaMA3-70B模型上，与SparseGPT结合使用时，DenoiseRotator减少了58%的困惑度差距。

**结论:** DenoiseRotator是一种模型无关的方法，能够有效提升剪枝后模型的性能，且可以无缝集成到现有的剪枝技术中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DenoiseRotator%3A+Enhance+Pruning+Robustness+for+LLMs+via+Importance+Concentration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23049，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23049&send_immediately=true&force_search=false)

**原文摘要:** Pruning is a widely used technique to compress large language models (LLMs)
by removing unimportant weights, but it often suffers from significant
performance degradation - especially under semi-structured sparsity
constraints. Existing pruning methods primarily focus on estimating the
importance of individual weights, which limits their ability to preserve
critical capabilities of the model. In this work, we propose a new perspective:
rather than merely selecting which weights to prune, we first redistribute
parameter importance to make the model inherently more amenable to pruning. By
minimizing the information entropy of normalized importance scores, our
approach concentrates importance onto a smaller subset of weights, thereby
enhancing pruning robustness. We instantiate this idea through DenoiseRotator,
which applies learnable orthogonal transformations to the model's weight
matrices. Our method is model-agnostic and can be seamlessly integrated with
existing pruning techniques such as Magnitude, SparseGPT, and Wanda. Evaluated
on LLaMA3, Qwen2.5, and Mistral models under 50% unstructured and 2:4
semi-structured sparsity, DenoiseRotator consistently improves perplexity and
zero-shot accuracy. For instance, on LLaMA3-70B pruned with SparseGPT at 2:4
semi-structured sparsity, DenoiseRotator reduces the perplexity gap to the
dense model by 58%, narrowing the degradation from 8.1 to 3.4 points. Codes are
available at https://github.com/Axel-gu/DenoiseRotator.

</details>


### [59] [CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents](https://arxiv.org/abs/2505.23055)
*Zhen Xiang, Aliyah R. Hsu, Austin V. Zane, Aaron E. Kornblith, Margaret J. Lin-Martore, Jasmanpreet C. Kaur, Vasuda M. Dokiparthi, Bo Li, Bin Yu*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为CDR-Agent的新方法，该方法利用大型语言模型来提高急诊科临床决策规则的应用效率和准确性。


<details>
  <summary>更多</summary>
  
**动机:** 临床决策规则（CDRs）在急诊室中的应用通常受到医生认知负荷的限制，这限制了他们快速回忆和应用适当规则的能力。

**方法:** CDR-Agent使用两个新的ED数据集进行验证：合成数据集和CDR-Bench，尽管CDR-Agent适用于非ED诊所。

**结果:** CDR-Agent在CDR选择中相对于独立LLM基线实现了56.3%（合成数据）和8.7%（CDR-Bench）的准确率增益。此外，CDR-Agent显著减少了计算开销，并且能够高效地选择相关CDRs，同时有效地减少不必要的干预并成功识别大多数阳性诊断病例。

**结论:** CDR-Agent是一种基于LLM的新型系统，旨在通过自主识别和应用最适合的临床决策规则（CDRs）来增强急诊科的决策能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CDR-Agent%3A+Intelligent+Selection+and+Execution+of+Clinical+Decision+Rules+Using+Large+Language+Model+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23055，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23055&send_immediately=true&force_search=false)

**原文摘要:** Clinical decision-making is inherently complex and fast-paced, particularly
in emergency departments (EDs) where critical, rapid and high-stakes decisions
are made. Clinical Decision Rules (CDRs) are standardized evidence-based tools
that combine signs, symptoms, and clinical variables into decision trees to
make consistent and accurate diagnoses. CDR usage is often hindered by the
clinician's cognitive load, limiting their ability to quickly recall and apply
the appropriate rules. We introduce CDR-Agent, a novel LLM-based system
designed to enhance ED decision-making by autonomously identifying and applying
the most appropriate CDRs based on unstructured clinical notes. To validate
CDR-Agent, we curated two novel ED datasets: synthetic and CDR-Bench, although
CDR-Agent is applicable to non ED clinics. CDR-Agent achieves a 56.3\%
(synthetic) and 8.7\% (CDR-Bench) accuracy gain relative to the standalone LLM
baseline in CDR selection. Moreover, CDR-Agent significantly reduces
computational overhead. Using these datasets, we demonstrated that CDR-Agent
not only selects relevant CDRs efficiently, but makes cautious yet effective
imaging decisions by minimizing unnecessary interventions while successfully
identifying most positively diagnosed cases, outperforming traditional LLM
prompting approaches. Code for our work can be found at:
https://github.com/zhenxianglance/medagent-cdr-agent

</details>


### [60] [DINGO: Constrained Inference for Diffusion LLMs](https://arxiv.org/abs/2505.23061)
*Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的解码方法DINGO，用于增强扩散语言模型在结构化输出任务中的可靠性，并取得了显著效果提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的扩散LLMs无法有效满足用户指定的形式约束（如正则表达式），导致结构化输出任务（如JSON生成）可靠性不足。

**方法:** 提出了DINGO算法，该算法基于动态规划，在扩散LLMs的并行token预测中实现对正则表达式等约束条件的支持。

**结果:** DINGO在符号数学和JSON生成基准测试中，相较无约束推理实现了最高68个百分点的改进。

**结论:** DINGO是一种有效的解码策略，它通过动态规划方法解决扩散LLMs在用户指定形式约束下的输出生成问题，使得模型可以在保证分布特性的同时提高任务可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DINGO%3A+Constrained+Inference+for+Diffusion+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23061，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23061&send_immediately=true&force_search=false)

**原文摘要:** Diffusion LLMs have emerged as a promising alternative to conventional
autoregressive LLMs, offering significant potential for improved runtime
efficiency. However, existing diffusion models lack the ability to provably
enforce user-specified formal constraints, such as regular expressions, which
makes them unreliable for tasks that require structured outputs, such as
fixed-schema JSON generation. Unlike autoregressive models that generate tokens
sequentially, diffusion LLMs predict a block of tokens in parallel. This
parallelism makes traditional constrained decoding algorithms, which are
designed for sequential token prediction, ineffective at preserving the true
output distribution. To address this limitation, we propose DINGO, a dynamic
programming-based constrained decoding strategy that is both efficient and
provably distribution-preserving. DINGO enables sampling of output strings with
the highest probability under the model's predicted distribution, while
strictly satisfying any user-specified regular expression. On standard symbolic
math and JSON generation benchmarks, DINGO achieves up to a 68 percentage point
improvement over unconstrained inference

</details>


### [61] [Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data](https://arxiv.org/abs/2505.23062)
*Lingkai Kong, Haichuan Wang, Tonghan Wang, Guojun Xiong, Milind Tambe*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CompFlow的方法，通过结合源环境和目标环境的流匹配与最优传输理论，解决强化学习中因环境动力学差异导致的数据利用问题，并在经验上展示了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法在估计源和目标环境之间的动力学差距时存在局限性，尤其是在源和目标动力学具有不相交支持的情况下，这促使作者提出一种更有效的方法来克服这些限制。

**方法:** 作者提出了CompFlow方法，该方法将目标动力学建模为基于源域流动输出分布的条件流动，而不是直接从高斯先验学习。这种方法利用了流匹配和最优传输理论之间的理论联系，并引入了一种乐观的主动数据收集策略，以优先探索高动力学差距区域。

**结果:** CompFlow在多个具有动力学转移的RL基准测试中优于强大的基线方法，同时提供了对动力学差距的原则性估计，并理论上证明了其减少与最优策略性能差距的能力。

**结论:** CompFlow通过改进目标动力学的学习泛化能力和提供对动力学差距的原则性估计，在强化学习中展现出了显著的优势，解决了现有方法的一些关键限制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Composite+Flow+Matching+for+Reinforcement+Learning+with+Shifted-Dynamics+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23062，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23062&send_immediately=true&force_search=false)

**原文摘要:** Incorporating pre-collected offline data from a source environment can
significantly improve the sample efficiency of reinforcement learning (RL), but
this benefit is often challenged by discrepancies between the transition
dynamics of the source and target environments. Existing methods typically
address this issue by penalizing or filtering out source transitions in high
dynamics-gap regions. However, their estimation of the dynamics gap often
relies on KL divergence or mutual information, which can be ill-defined when
the source and target dynamics have disjoint support. To overcome these
limitations, we propose CompFlow, a method grounded in the theoretical
connection between flow matching and optimal transport. Specifically, we model
the target dynamics as a conditional flow built upon the output distribution of
the source-domain flow, rather than learning it directly from a Gaussian prior.
This composite structure offers two key advantages: (1) improved generalization
for learning target dynamics, and (2) a principled estimation of the dynamics
gap via the Wasserstein distance between source and target transitions.
Leveraging our principled estimation of the dynamics gap, we further introduce
an optimistic active data collection strategy that prioritizes exploration in
regions of high dynamics gap, and theoretically prove that it reduces the
performance disparity with the optimal policy. Empirically, CompFlow
outperforms strong baselines across several RL benchmarks with shifted
dynamics.

</details>


### [62] [Loss-Guided Model Sharing and Local Learning Correction in Decentralized Federated Learning for Crop Disease Classification](https://arxiv.org/abs/2505.23063)
*Denis Mamba Kabala, Adel Hafiane, Laurent Bobelin, Raphael Canals*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的去中心化联邦学习框架用于作物疾病检测，该框架解决了数据隐私问题，并通过使用验证损失优化模型共享和训练，提高了模型的准确性、收敛速度及泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 植物疾病检测与分类是农业中的一个关键挑战，深度学习模型虽然表现出色，但其大规模部署常受数据隐私问题限制。

**方法:** 本研究提出了一种新的去中心化联邦学习框架（DFL），使用验证损失（Loss_val）来指导模型共享和通过加权参数控制的自适应损失函数纠正本地训练。

**结果:** 实验结果表明，所提出的DFL方法在PlantVillage数据集上使用ResNet50、VGG16和ViT_B16三种架构时，在准确性和收敛速度方面都有提高。

**结论:** DFL方法不仅提高了准确性和收敛速度，还确保了在异构数据环境中的泛化能力和鲁棒性，使其特别适合于隐私保护的农业应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Loss-Guided+Model+Sharing+and+Local+Learning+Correction+in+Decentralized+Federated+Learning+for+Crop+Disease+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23063，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23063&send_immediately=true&force_search=false)

**原文摘要:** Crop disease detection and classification is a critical challenge in
agriculture, with major implications for productivity, food security, and
environmental sustainability. While deep learning models such as CNN and ViT
have shown excellent performance in classifying plant diseases from images,
their large-scale deployment is often limited by data privacy concerns.
Federated Learning (FL) addresses this issue, but centralized FL remains
vulnerable to single-point failures and scalability limits. In this paper, we
introduce a novel Decentralized Federated Learning (DFL) framework that uses
validation loss (Loss_val) both to guide model sharing between peers and to
correct local training via an adaptive loss function controlled by weighting
parameter. We conduct extensive experiments using PlantVillage datasets with
three deep learning architectures (ResNet50, VGG16, and ViT_B16), analyzing the
impact of weighting parameter, the number of shared models, the number of
clients, and the use of Loss_val versus Loss_train of other clients. Results
demonstrate that our DFL approach not only improves accuracy and convergence
speed, but also ensures better generalization and robustness across
heterogeneous data environments making it particularly well-suited for
privacy-preserving agricultural applications.

</details>


### [63] [Multi-Modal Learning with Bayesian-Oriented Gradient Calibration](https://arxiv.org/abs/2505.23071)
*Peizheng Guo, Jingyao Wang, Huijie Guo, Jiangmeng Li, Chuxiong Sun, Changwen Zheng, Wenwen Qiang*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种针对多模态学习的新颖梯度校准方法BOGC-MML，以解决传统方法忽视梯度不确定性的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法主要使用固定权重聚合梯度并忽略每个模态的内在梯度不确定性，这可能导致敏感维度过度更新和非敏感维度更新不足。

**方法:** 该方法将每个模态的梯度建模为随机变量，并将其精度转换为标量证据，利用这些证据量化每个维度的不确定性并通过Dempster-Shafer规则进行融合。

**结果:** 在多个基准数据集上的实验结果表明所提方法具有有效性与优势。

**结论:** 论文提出了一种新的多模态学习方法BOGC-MML，通过显式建模梯度不确定性来改善模型优化方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Modal+Learning+with+Bayesian-Oriented+Gradient+Calibration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23071，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23071&send_immediately=true&force_search=false)

**原文摘要:** Multi-Modal Learning (MML) integrates information from diverse modalities to
improve predictive accuracy. However, existing methods mainly aggregate
gradients with fixed weights and treat all dimensions equally, overlooking the
intrinsic gradient uncertainty of each modality. This may lead to (i) excessive
updates in sensitive dimensions, degrading performance, and (ii) insufficient
updates in less sensitive dimensions, hindering learning. To address this
issue, we propose BOGC-MML, a Bayesian-Oriented Gradient Calibration method for
MML to explicitly model the gradient uncertainty and guide the model
optimization towards the optimal direction. Specifically, we first model each
modality's gradient as a random variable and derive its probability
distribution, capturing the full uncertainty in the gradient space. Then, we
propose an effective method that converts the precision (inverse variance) of
each gradient distribution into a scalar evidence. This evidence quantifies the
confidence of each modality in every gradient dimension. Using these evidences,
we explicitly quantify per-dimension uncertainties and fuse them via a reduced
Dempster-Shafer rule. The resulting uncertainty-weighted aggregation produces a
calibrated update direction that balances sensitivity and conservatism across
dimensions. Extensive experiments on multiple benchmark datasets demonstrate
the effectiveness and advantages of the proposed method.

</details>


### [64] [Gradient Boosting Decision Tree with LSTM for Investment Prediction](https://arxiv.org/abs/2505.23084)
*Chang Yu, Fang Liu, Jie Zhu, Shaobo Guo, Yifan Gao, Zhongheng Yang, Meiwei Liu, Qianwen Xing*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种结合LSTM、LightGBM和CatBoost的混合框架，用于股票价格预测，结果表明其准确性显著优于单一模型。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是通过集成顺序方法和基于树的方法的优势来提高股票价格预测的准确性，并为整合新的机器学习技术提供灵活的设计。

**方法:** 本文的方法是构建一个结合LSTM、LightGBM和CatBoost的混合框架，并使用七个模型对时间序列金融数据进行处理和性能评估。

**结果:** 实验结果显示，与单独模型相比，该框架的预测准确性提高了10%到15%，并在市场变化时减少了误差。

**结论:** 论文得出结论，提出的混合框架在股票价格预测方面优于单独模型，并强调了集成方法在金融预测中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gradient+Boosting+Decision+Tree+with+LSTM+for+Investment+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23084，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23084&send_immediately=true&force_search=false)

**原文摘要:** This paper proposes a hybrid framework combining LSTM (Long Short-Term
Memory) networks with LightGBM and CatBoost for stock price prediction. The
framework processes time-series financial data and evaluates performance using
seven models: Artificial Neural Networks (ANNs), Convolutional Neural Networks
(CNNs), Bidirectional LSTM (BiLSTM), vanilla LSTM, XGBoost, LightGBM, and
standard Neural Networks (NNs). Key metrics, including MAE, R-squared, MSE, and
RMSE, are used to establish benchmarks across different time scales.
  Building on these benchmarks, we develop an ensemble model that combines the
strengths of sequential and tree-based approaches. Experimental results show
that the proposed framework improves accuracy by 10 to 15 percent compared to
individual models and reduces error during market changes. This study
highlights the potential of ensemble methods for financial forecasting and
provides a flexible design for integrating new machine learning techniques.

</details>


### [65] [Equivariant Spherical Transformer for Efficient Molecular Modeling](https://arxiv.org/abs/2505.23086)
*Junyi An, Xinyu Lu, Chao Qu, Yunfei Shi, Peijia Lin, Qianwei Tang, Licheng Xu, Fenglei Cao, Yuan Qi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于傅里叶变换的SE(3)-equivariant Transformer模型（EST），解决了传统方法在非线性和群表示方面的局限性，并在多个分子任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的SE(3)-equivariant图神经网络由于非线性和群表示不足而受限于表达能力，需要一种新的方法来克服这些限制。

**方法:** 引入了Equivariant Spherical Transformer (EST)，该框架在群表示的空间域中使用Transformer结构，通过傅里叶变换实现等变性归纳偏差。

**结果:** 理论上和实验证明了EST能够包含张量积的函数空间并达到更高的表达能力，并且在OC20和QM9等多个分子基准任务上展示了最先进的性能。

**结论:** EST具有比现有SE(3)消息传递方法更好的表达能力，并在各种分子基准上实现了最先进的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Spherical+Transformer+for+Efficient+Molecular+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23086，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23086&send_immediately=true&force_search=false)

**原文摘要:** SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advanced
molecular system modeling by employing group representations. However, their
message passing processes, which rely on tensor product-based convolutions, are
limited by insufficient non-linearity and incomplete group representations,
thereby restricting expressiveness. To overcome these limitations, we introduce
the Equivariant Spherical Transformer (EST), a novel framework that leverages a
Transformer structure within the spatial domain of group representations after
Fourier transform. We theoretically and empirically demonstrate that EST can
encompass the function space of tensor products while achieving superior
expressiveness. Furthermore, EST's equivariant inductive bias is guaranteed
through a uniform sampling strategy for the Fourier transform. Our experiments
demonstrate state-of-the-art performance by EST on various molecular
benchmarks, including OC20 and QM9.

</details>


### [66] [CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2505.23116)
*Pengfei Zhou, Yunlong Liu, Junli Liang, Qi Song, Xiangyang Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CrossLinear的时间序列预测模型，通过引入一个轻量级的交叉相关嵌入模块，显著提升了模型在处理内外生变量依赖关系时的效率和准确性。


<details>
  <summary>更多</summary>
  
**动机:** 传统模型难以有效区分内生变量与外生变量，导致效率低下和过拟合问题，因此需要一种新的方法以更高效、精确地进行时间序列预测。

**方法:** CrossLinear模型采用了一种即插即用的交叉相关嵌入模块，该模块专注于捕捉时间不变且直接的变量依赖关系；同时利用分片处理和全局线性头来建模短期和长期时间依赖。

**结果:** 实验结果表明，CrossLinear在12个真实世界数据集上均取得了优于现有方法的表现，尤其是在短期和长期预测任务中。此外，消融实验证明了交叉相关嵌入模块的有效性。

**结论:** CrossLinear模型通过引入一种轻量级的交叉相关嵌入模块，有效区分了内生变量与外生变量之间的依赖关系，避免了过拟合问题，并在短期和长期预测任务中表现出卓越的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CrossLinear%3A+Plug-and-Play+Cross-Correlation+Embedding+for+Time+Series+Forecasting+with+Exogenous+Variables，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23116，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23116&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting with exogenous variables is a critical emerging
paradigm that presents unique challenges in modeling dependencies between
variables. Traditional models often struggle to differentiate between
endogenous and exogenous variables, leading to inefficiencies and overfitting.
In this paper, we introduce CrossLinear, a novel Linear-based forecasting model
that addresses these challenges by incorporating a plug-and-play
cross-correlation embedding module. This lightweight module captures the
dependencies between variables with minimal computational cost and seamlessly
integrates into existing neural networks. Specifically, it captures
time-invariant and direct variable dependencies while disregarding time-varying
or indirect dependencies, thereby mitigating the risk of overfitting in
dependency modeling and contributing to consistent performance improvements.
Furthermore, CrossLinear employs patch-wise processing and a global linear head
to effectively capture both short-term and long-term temporal dependencies,
further improving its forecasting precision. Extensive experiments on 12
real-world datasets demonstrate that CrossLinear achieves superior performance
in both short-term and long-term forecasting tasks. The ablation study
underscores the effectiveness of the cross-correlation embedding module.
Additionally, the generalizability of this module makes it a valuable plug-in
for various forecasting tasks across different domains. Codes are available at
https://github.com/mumiao2000/CrossLinear.

</details>


### [67] [MAP: Revisiting Weight Decomposition for Low-Rank Adaptation](https://arxiv.org/abs/2505.23094)
*Chongjie Si, Zhiyi Shi, Yadao Wang, Xiaokang Yang, Susanto Rahardja, Wei Shen*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种新的参数高效微调框架MAP，该框架能够更准确地解耦方向和幅度的适应，提高现有方法的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的参数高效微调方法在定义方向时往往缺乏原则性的几何基础。

**方法:** 将权重矩阵重新表述为高维向量，并以严格的方式将其适应解耦为方向和幅度。

**结果:** 实验表明，与现有方法结合时，MAP显著提高了性能。

**结论:** MAP的设计能够更准确地解耦方向和幅度的适应，从而提升现有PEFT方法的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAP%3A+Revisiting+Weight+Decomposition+for+Low-Rank+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23094&send_immediately=true&force_search=false)

**原文摘要:** The rapid development of large language models has revolutionized natural
language processing, but their fine-tuning remains computationally expensive,
hindering broad deployment. Parameter-efficient fine-tuning (PEFT) methods,
such as LoRA, have emerged as solutions. Recent work like DoRA attempts to
further decompose weight adaptation into direction and magnitude components.
However, existing formulations often define direction heuristically at the
column level, lacking a principled geometric foundation. In this paper, we
propose MAP, a novel framework that reformulates weight matrices as
high-dimensional vectors and decouples their adaptation into direction and
magnitude in a rigorous manner. MAP normalizes the pre-trained weights, learns
a directional update, and introduces two scalar coefficients to independently
scale the magnitude of the base and update vectors. This design enables more
interpretable and flexible adaptation, and can be seamlessly integrated into
existing PEFT methods. Extensive experiments show that MAP significantly
improves performance when coupling with existing methods, offering a simple yet
powerful enhancement to existing PEFT methods. Given the universality and
simplicity of MAP, we hope it can serve as a default setting for designing
future PEFT methods.

</details>


### [68] [Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking](https://arxiv.org/abs/2505.23117)
*Yuatyong Chaichana, Thanapat Trachu, Peerat Limkonchotiwat, Konpat Preechakul, Tirasan Khandhawit, Ekapol Chuangsuwanich*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的模型合并方法Decom-Renorm-Merge (DRM)，该方法解决了传统方法中存在的问题，并在各种模型和设置中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的模型合并方法假设权重矩阵中相同位置的元素具有相同功能，但这一假设忽略了微调神经网络的复杂性，导致直接逐项合并存在问题。

**方法:** 提出了一种称为Decom-Renorm-Merge (DRM)的方法，利用奇异值分解将权重矩阵分解并协调到对齐的联合空间，使得逐项合并成为可能。

**结果:** 实验结果表明，在各种微调和低秩适应设置中，DRM均优于多种最先进的合并技术。

**结论:** DRM方法在不同模型和设置中表现出色，优于现有合并技术。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decom-Renorm-Merge%3A+Model+Merging+on+the+Right+Space+Improves+Multitasking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23117，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23117&send_immediately=true&force_search=false)

**原文摘要:** In the era of large-scale training, model merging has evolved into a tool for
creating multitasking models efficiently. It enables the knowledge of models to
be fused, without the need for heavy computation as required in traditional
multitask learning. Existing merging methods often assume that entries at
identical positions in weight matrices serve the same function, enabling
straightforward entry-wise comparison and merging. However, this assumption
overlooks the complexity of finetuned neural networks, where neurons may
develop distinct feature compositions, making direct entry-wise merging
problematic. We present Decom-Renorm-Merge (DRM), a simple yet effective
approach that leverages Singular Value Decomposition to decompose and
coordinate weight matrices into an aligned joint space, where entry-wise
merging becomes possible. We showcase the effectiveness of DRM across various
settings ranging from smaller encoder-based such as ViT and DeBERTa,
encoder-decoder-based such as T5, and larger decoder-based such as Llama3.1-8B.
Our experimental results show that DRM outperforms several state-of-the-art
merging techniques across full finetuning and low-rank adaptation settings.
Moreover, our analysis reveals renormalization as the crucial component for
creating a robust and even joint space for merging, significantly contributing
to the method's performance.

</details>


### [69] [Learning to Search for Vehicle Routing with Multiple Time Windows](https://arxiv.org/abs/2505.23098)
*Kuan Xu, Zhiguang Cao, Chenlong Zheng, Linong Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的强化学习驱动的自适应变邻域搜索算法，用以高效求解多时间窗车辆路径问题，并展示了其优越的性能和实际应用潜力。


<details>
  <summary>更多</summary>
  
**动机:** 传统的自适应方法仅依赖于历史操作符性能，无法充分利用实时解决方案状态和学习经验，因此需要一种更智能的方法来提升求解效果。

**方法:** 该方法结合了强化学习框架，动态选择邻域操作符，并引入了一种衡量客户时间灵活性的适应度指标，同时采用基于Transformer的神经策略网络来指导局部搜索中的操作符选择。

**结果:** 实验结果显示，RL-AVNS在不同规模和时间窗口复杂度的问题实例上均表现出色，且具有良好的泛化能力，适用于复杂的物流场景。

**结论:** 论文提出了一种基于强化学习的自适应变邻域搜索方法（RL-AVNS），用于解决多时间窗车辆路径问题（VRPMTW）。结果表明，RL-AVNS在求解质量和计算效率方面显著优于传统变邻域搜索（VNS）、自适应变邻域搜索（AVNS）和最先进的基于学习的启发式算法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Search+for+Vehicle+Routing+with+Multiple+Time+Windows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23098&send_immediately=true&force_search=false)

**原文摘要:** In this study, we propose a reinforcement learning-based adaptive variable
neighborhood search (RL-AVNS) method designed for effectively solving the
Vehicle Routing Problem with Multiple Time Windows (VRPMTW). Unlike traditional
adaptive approaches that rely solely on historical operator performance, our
method integrates a reinforcement learning framework to dynamically select
neighborhood operators based on real-time solution states and learned
experience. We introduce a fitness metric that quantifies customers' temporal
flexibility to improve the shaking phase, and employ a transformer-based neural
policy network to intelligently guide operator selection during the local
search. Extensive computational experiments are conducted on realistic
scenarios derived from the replenishment of unmanned vending machines,
characterized by multiple clustered replenishment windows. Results demonstrate
that RL-AVNS significantly outperforms traditional variable neighborhood search
(VNS), adaptive VNS (AVNS), and state-of-the-art learning-based heuristics,
achieving substantial improvements in solution quality and computational
efficiency across various instance scales and time window complexities.
Particularly notable is the algorithm's capability to generalize effectively to
problem instances not encountered during training, underscoring its practical
utility for complex logistics scenarios.

</details>


### [70] [VERINA: Benchmarking Verifiable Code Generation](https://arxiv.org/abs/2505.23135)
*Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song*

**主要类别:** cs.LG

**AI概要:** Verina提供了一个全面的基准来评估LLM在可验证代码生成中的性能，并指出其在证明生成上的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 当前基准缺乏对端到端可验证代码生成的支持，而确保LLM生成代码的正确性仍然困难。

**方法:** 引入了一个名为Verina的手动策划编码任务集合，用于综合评估代码、规范和证明生成。

**结果:** 最先进的LLM如OpenAI o4-mini仅能生成61.4%正确的代码，51.0%完善规范，3.6%成功证明。

**结论:** Verina为可验证代码生成提供了高质量的基准，揭示了LLMs在证明生成方面存在显著挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VERINA%3A+Benchmarking+Verifiable+Code+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23135&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly integrated in software
development, but ensuring correctness in LLM-generated code remains challenging
and often requires costly manual review. Verifiable code generation -- jointly
generating code, specifications, and proofs of code-specification alignment --
offers a promising path to address this limitation and further unleash LLMs'
benefits in coding. Yet, there exists a significant gap in evaluation: current
benchmarks often lack support for end-to-end verifiable code generation. In
this paper, we introduce Verina (Verifiable Code Generation Arena), a
high-quality benchmark enabling a comprehensive and modular evaluation of code,
specification, and proof generation as well as their compositions. Verina
consists of 189 manually curated coding tasks in Lean, with detailed problem
descriptions, reference implementations, formal specifications, and extensive
test suites. Our extensive evaluation of state-of-the-art LLMs reveals
significant challenges in verifiable code generation, especially in proof
generation, underscoring the need for improving LLM-based theorem provers in
verification domains. The best model, OpenAI o4-mini, generates only 61.4%
correct code, 51.0% sound and complete specifications, and 3.6% successful
proofs, with one trial per task. We hope Verina will catalyze progress in
verifiable code generation by providing a rigorous and comprehensive benchmark.
We release our dataset on https://huggingface.co/datasets/sunblaze-ucb/verina
and our evaluation code on https://github.com/sunblaze-ucb/verina.

</details>


### [71] [Weight Spectra Induced Efficient Model Adaptation](https://arxiv.org/abs/2505.23099)
*Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen*

**主要类别:** cs.LG

**AI概要:** 本论文研究了大规模基础模型在微调过程中的结构变化，提出了一个新方法，通过可学习的顶部奇异方向重新缩放来调整模型参数，实现了在多个任务中的一致改进。


<details>
  <summary>更多</summary>
  
**动机:** 大规模基础模型在各种下游任务中表现出显著的多功能性。然而，全面微调这些模型计算成本高昂，促使开发参数高效微调（PEFT）方法，例如LoRA。尽管PEFT方法取得了实证成功，但其修改模型参数的潜在机制仍未被充分探索。

**方法:** 论文使用了奇异值分解（SVD）对完全微调过程中权重矩阵的结构变化进行了系统研究，并基于这些见解提出了一种新的方法，利用可学习的顶部奇异方向重新缩放来调整模型参数。

**结果:** 研究发现，在微调过程中，主要放大了顶部奇异值，而其余部分基本保持不变，表明任务特定知识被注入到低维子空间中。此外，主导奇异向量在任务特定方向上重新定向，而非主导子空间保持稳定。

**结论:** 论文得出的结论是，通过利用可学习的顶部奇异方向重新缩放，可以精确地调节最具影响力的组件，而不破坏全局结构。这种方法在多个任务中实现了比强基线方法一致的改进，突出了结构知情微调的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Weight+Spectra+Induced+Efficient+Model+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23099&send_immediately=true&force_search=false)

**原文摘要:** Large-scale foundation models have demonstrated remarkable versatility across
a wide range of downstream tasks. However, fully fine-tuning these models
incurs prohibitive computational costs, motivating the development of
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces
low-rank updates to pre-trained weights. Despite their empirical success, the
underlying mechanisms by which PEFT modifies model parameters remain
underexplored. In this work, we present a systematic investigation into the
structural changes of weight matrices during fully fine-tuning. Through
singular value decomposition (SVD), we reveal that fine-tuning predominantly
amplifies the top singular values while leaving the remainder largely intact,
suggesting that task-specific knowledge is injected into a low-dimensional
subspace. Furthermore, we find that the dominant singular vectors are
reoriented in task-specific directions, whereas the non-dominant subspace
remains stable. Building on these insights, we propose a novel method that
leverages learnable rescaling of top singular directions, enabling precise
modulation of the most influential components without disrupting the global
structure. Our approach achieves consistent improvements over strong baselines
across multiple tasks, highlighting the efficacy of structurally informed
fine-tuning.

</details>


### [72] [Best Arm Identification with Possibly Biased Offline Data](https://arxiv.org/abs/2505.23165)
*Le Yang, Vincent Y. F. Tan, Wang Chi Cheung*

**主要类别:** cs.LG

**AI概要:** 本文提出了LUCB-H算法，结合可能带偏的离线数据与在线数据，解决了最佳臂识别问题，在理论和实验上都表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 实际场景（如临床试验）中存在可能带有偏差的离线数据，传统方法无法有效处理这类问题。

**方法:** 通过引入自适应置信区间并在LUCB框架中加入辅助偏差校正来平衡离线和在线数据的使用。

**结果:** LUCB-H在离线数据有误导时能保持标准LUCB的样本复杂度，在离线数据有用时显著优于标准LUCB，并且理论上推导了实例相关下界并与上界匹配。

**结论:** 论文提出了一种新的LUCB-H算法，用于解决具有潜在偏差离线数据的最佳臂识别问题，并在理论和实验上验证了其性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Best+Arm+Identification+with+Possibly+Biased+Offline+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23165，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23165&send_immediately=true&force_search=false)

**原文摘要:** We study the best arm identification (BAI) problem with potentially biased
offline data in the fixed confidence setting, which commonly arises in
real-world scenarios such as clinical trials. We prove an impossibility result
for adaptive algorithms without prior knowledge of the bias bound between
online and offline distributions. To address this, we propose the LUCB-H
algorithm, which introduces adaptive confidence bounds by incorporating an
auxiliary bias correction to balance offline and online data within the LUCB
framework. Theoretical analysis shows that LUCB-H matches the sample complexity
of standard LUCB when offline data is misleading and significantly outperforms
it when offline data is helpful. We also derive an instance-dependent lower
bound that matches the upper bound of LUCB-H in certain scenarios. Numerical
experiments further demonstrate the robustness and adaptability of LUCB-H in
effectively incorporating offline data.

</details>


### [73] [LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics](https://arxiv.org/abs/2505.23105)
*Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh*

**主要类别:** cs.LG

**AI概要:** LUMION是一种新型可重构光学结构，用于连接数据中心机架内的加速器，以更高效地处理加速器故障。


<details>
  <summary>更多</summary>
  
**动机:** 解决现代ML数据中心中因加速器故障导致的资源浪费问题。

**方法:** 构建端到端的硬件原型并进行实验测试。

**结果:** 在故障发生后约1秒内更换失败GPU并重启ML任务，细调吞吐量提高了近2倍。

**结论:** LUMION通过动态集成备用加速器来维持性能，避免了昂贵的迁移过程，并提高了资源利用率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LUMION%3A+Fast+Fault+Recovery+for+ML+Jobs+Using+Programmable+Optical+Fabrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23105，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23105&send_immediately=true&force_search=false)

**原文摘要:** When accelerators fail in modern ML datacenters, operators migrate the
affected ML training or inference jobs to entirely new racks. This approach,
while preserving network performance, is highly inefficient, requiring
datacenters to reserve full racks of idle accelerators for fault tolerance. In
this paper, we address this resource inefficiency by introducing LUMION, a
novel reconfigurable optical fabric for connecting accelerators within a
datacenter rack. Instead of migrating entire ML jobs, LUMION dynamically
integrates spare accelerators into ongoing workloads as failures occur, thereby
maintaining consistent performance without costly migrations. We show the
benefits of LUMION by building an end-to-end hardware prototype. Our
experiments fine-tune Llama 3.2 and show that LUMION swaps a failed GPU with a
healthy one and restarts the ML job within ~ 1 second of the failure. LUMION
achieves higher inter-GPU bandwidth compared to traditional electrical racks
after replacing failed accelerators with spare ones, leading to nearly 2X
improvement in fine-tuning throughput.

</details>


### [74] [FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification](https://arxiv.org/abs/2505.23181)
*Tian Tian, Chunyan Miao, Hangwei Qian*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种针对时间序列对比学习的新型增强方法Frequency Refined Augmentation (FreRA)，其通过从频率域的角度出发，有效保留了语义相关信息，并在多个任务和数据集上表现出优越性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的预定义时间域增强方法主要是从视觉领域借鉴而来，不适合时间序列数据，可能会破坏其语义相关性。因此需要一种更适用于时间序列的增强策略。

**方法:** 提出了FreRA方法，该方法基于频率域分析，将关键和不重要的频率成分自动分离，并分别采用语义感知的身份修改和语义无关的自适应修改来生成增强视图。

**结果:** 在UCR、UEA以及五个大规模多样化应用数据集上的实验表明，FreRA在时间序列分类、异常检测和迁移学习任务中均优于十个主流基线方法。

**结论:** FreRA是一种轻量级但有效的增强方法，能够提升时间序列对比学习的表现力和泛化能力，适用于多种任务和场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FreRA%3A+A+Frequency-Refined+Augmentation+for+Contrastive+Learning+on+Time+Series+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23181，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23181&send_immediately=true&force_search=false)

**原文摘要:** Contrastive learning has emerged as a competent approach for unsupervised
representation learning. However, the design of an optimal augmentation
strategy, although crucial for contrastive learning, is less explored for time
series classification tasks. Existing predefined time-domain augmentation
methods are primarily adopted from vision and are not specific to time series
data. Consequently, this cross-modality incompatibility may distort the
semantically relevant information of time series by introducing mismatched
patterns into the data. To address this limitation, we present a novel
perspective from the frequency domain and identify three advantages for
downstream classification: global, independent, and compact. To fully utilize
the three properties, we propose the lightweight yet effective Frequency
Refined Augmentation (FreRA) tailored for time series contrastive learning on
classification tasks, which can be seamlessly integrated with contrastive
learning frameworks in a plug-and-play manner. Specifically, FreRA
automatically separates critical and unimportant frequency components.
Accordingly, we propose semantic-aware Identity Modification and
semantic-agnostic Self-adaptive Modification to protect semantically relevant
information in the critical frequency components and infuse variance into the
unimportant ones respectively. Theoretically, we prove that FreRA generates
semantic-preserving views. Empirically, we conduct extensive experiments on two
benchmark datasets, including UCR and UEA archives, as well as five large-scale
datasets on diverse applications. FreRA consistently outperforms ten leading
baselines on time series classification, anomaly detection, and transfer
learning tasks, demonstrating superior capabilities in contrastive
representation learning and generalization in transfer learning scenarios
across diverse datasets.

</details>


### [75] [Neural Interpretable PDEs: Harmonizing Fourier Insights with Attention for Scalable and Interpretable Physics Discovery](https://arxiv.org/abs/2505.23106)
*Ning Liu, Yue Yu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的神经算子架构NIPS，通过改进非局部注意力算子实现高效的物理系统建模，在准确性和计算效率上均有显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 注意力机制已在AI领域取得重大成功，但在复杂物理系统建模中的潜力尚未充分挖掘。物理系统的建模任务通常需要从有限的数据中学习映射函数，是一个严重不适定的逆PDE问题，这激发了本研究对更高效架构的探索。

**方法:** 引入了基于非局部注意力算子（NAO）的新型神经算子架构NIPS，采用线性注意力机制和可学习核网络，在傅里叶空间中进行高效的卷积操作。

**结果:** 实验表明，NIPS在多个基准测试中均优于NAO和其他基线模型，同时其设计有效降低了计算大规模空间交互的成本。

**结论:** NIPS在处理物理系统建模方面表现出色，超越了现有的方法，具有良好的可扩展性、可解释性和计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neural+Interpretable+PDEs%3A+Harmonizing+Fourier+Insights+with+Attention+for+Scalable+and+Interpretable+Physics+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23106，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23106&send_immediately=true&force_search=false)

**原文摘要:** Attention mechanisms have emerged as transformative tools in core AI domains
such as natural language processing and computer vision. Yet, their largely
untapped potential for modeling intricate physical systems presents a
compelling frontier. Learning such systems often entails discovering operators
that map between functional spaces using limited instances of function pairs --
a task commonly framed as a severely ill-posed inverse PDE problem. In this
work, we introduce Neural Interpretable PDEs (NIPS), a novel neural operator
architecture that builds upon and enhances Nonlocal Attention Operators (NAO)
in both predictive accuracy and computational efficiency. NIPS employs a linear
attention mechanism to enable scalable learning and integrates a learnable
kernel network that acts as a channel-independent convolution in Fourier space.
As a consequence, NIPS eliminates the need to explicitly compute and store
large pairwise interactions, effectively amortizing the cost of handling
spatial interactions into the Fourier transform. Empirical evaluations
demonstrate that NIPS consistently surpasses NAO and other baselines across
diverse benchmarks, heralding a substantial leap in scalable, interpretable,
and efficient physics learning. Our code and data accompanying this paper are
available at https://github.com/fishmoon1234/Nonlocal-Attention-Operator.

</details>


### [76] [Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning](https://arxiv.org/abs/2505.23195)
*Lifan Zhao, Yanyan Shen, Zhaoyang Liu, Xue Wang, Jiaji Deng*

**主要类别:** cs.LG

**AI概要:** 论文探讨了时间序列基础模型（TSFMs）的适应性问题，并提出了一种结构化剪枝方法来提升其预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管预训练TSFMs在零样本预测方面表现出色，但在微调后仍难以一致超越使用完整下游数据训练的小型专用模型，因此需要一种有效的适应方法。

**方法:** 通过实证研究发现TSFM在计算上具有固有的稀疏性和冗余性，从而提出一种结构化剪枝方法，以在微调过程中聚焦于更相关且紧凑的参数空间。

**结果:** 实验表明，对剪枝后的TSFM进行微调显著提高了预测性能，并使TSFM能够在多个基准测试中达到最先进的水平。

**结论:** 提出的“剪枝-再微调”范式有效提升了TSFM的适应能力，使其能够超越强大的专用基线模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Less+is+More%3A+Unlocking+Specialization+of+Time+Series+Foundation+Models+via+Structured+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23195，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23195&send_immediately=true&force_search=false)

**原文摘要:** Scaling laws motivate the development of Time Series Foundation Models
(TSFMs) that pre-train vast parameters and achieve remarkable zero-shot
forecasting performance. Surprisingly, even after fine-tuning, TSFMs cannot
consistently outperform smaller, specialized models trained on full-shot
downstream data. A key question is how to realize effective adaptation of TSFMs
for a target forecasting task. Through empirical studies on various TSFMs, the
pre-trained models often exhibit inherent sparsity and redundancy in
computation, suggesting that TSFMs have learned to activate task-relevant
network substructures to accommodate diverse forecasting tasks. To preserve
this valuable prior knowledge, we propose a structured pruning method to
regularize the subsequent fine-tuning process by focusing it on a more relevant
and compact parameter space. Extensive experiments on seven TSFMs and six
benchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantly
improves forecasting performance compared to fine-tuning original models. This
"prune-then-finetune" paradigm often enables TSFMs to achieve state-of-the-art
performance and surpass strong specialized baselines.

</details>


### [77] [Accelerating RLHF Training with Reward Variance Increase](https://arxiv.org/abs/2505.23247)
*Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一个更高效的基于GRPO的RLHF训练方法，通过奖励调整模型和新算法提升训练速度。


<details>
  <summary>更多</summary>
  
**动机:** 较高的初始策略模型的奖励方差能够加快RLHF训练，因此需要一种加速RLHF训练的方法。

**方法:** 提出了一种实用的奖励调整模型，并设计了一个新颖的O(n log n)算法来解决非凸奖励调整问题，将奖励调整模型集成到GRPO算法中形成GRPOVI算法。

**结果:** 实验结果表明，GRPOVI算法相比原始的GRPO算法显著提高了RLHF训练效率。

**结论:** GRPOVI算法相比原始的GRPO算法可以显著提高RLHF训练效率，并且论文提供了一个重要的解释来说明基于规则奖励的GRPO在RLHF训练中的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+RLHF+Training+with+Reward+Variance+Increase，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23247，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23247&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning from human feedback (RLHF) is an essential technique
for ensuring that large language models (LLMs) are aligned with human values
and preferences during the post-training phase. As an effective RLHF approach,
group relative policy optimization (GRPO) has demonstrated success in many
LLM-based applications. However, efficient GRPO-based RLHF training remains a
challenge. Recent studies reveal that a higher reward variance of the initial
policy model leads to faster RLHF training. Inspired by this finding, we
propose a practical reward adjustment model to accelerate RLHF training by
provably increasing the reward variance and preserving the relative preferences
and reward expectation. Our reward adjustment method inherently poses a
nonconvex optimization problem, which is NP-hard to solve in general. To
overcome the computational challenges, we design a novel $O(n \log n)$
algorithm to find a global solution of the nonconvex reward adjustment model by
explicitly characterizing the extreme points of the feasible set. As an
important application, we naturally integrate this reward adjustment model into
the GRPO algorithm, leading to a more efficient GRPO with reward variance
increase (GRPOVI) algorithm for RLHF training. As an interesting byproduct, we
provide an indirect explanation for the empirical effectiveness of GRPO with
rule-based reward for RLHF training, as demonstrated in DeepSeek-R1. Experiment
results demonstrate that the GRPOVI algorithm can significantly improve the
RLHF training efficiency compared to the original GRPO algorithm.

</details>


### [78] [Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs](https://arxiv.org/abs/2505.23270)
*Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong Gu, Claudia Grosser, Denis Krompass, Nassir Navab, Volker Tresp*

**主要类别:** cs.LG

**AI概要:** 这篇论文主要研究如何有效评估大型语言模型中的机器遗忘算法，并提出了一个新的中间激活扰动技术以提高审计能力。


<details>
  <summary>更多</summary>
  
**动机:** 大规模语言模型（LLMs）因训练数据可能包含敏感或受版权保护的内容而引发了数据隐私和所有权问题。法规如GDPR赋予个人要求删除敏感信息的权利，因此需要开发机器遗忘算法以避免昂贵的重新训练过程。然而，由于LLM的复杂性和生成特性，评估这些算法的效果仍是一个挑战。

**方法:** 该研究包括三个基准数据集、六种遗忘算法以及五种基于提示的审计方法，用于评估不同的遗忘策略的有效性和鲁棒性。此外，提出了一种基于中间激活扰动的新技术。

**结果:** 通过使用各种审计算法，作者成功评估了不同遗忘策略的有效性和鲁棒性，并提出了一种能够超越传统提示基础审计的新技术。

**结论:** 论文提出了一个全面的审计框架来评估机器遗忘算法，并引入了一种新的技术，利用中间激活扰动来解决依赖模型输入和输出的审计方法的局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Does+Machine+Unlearning+Truly+Remove+Model+Knowledge%3F+A+Framework+for+Auditing+Unlearning+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23270，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23270&send_immediately=true&force_search=false)

**原文摘要:** In recent years, Large Language Models (LLMs) have achieved remarkable
advancements, drawing significant attention from the research community. Their
capabilities are largely attributed to large-scale architectures, which require
extensive training on massive datasets. However, such datasets often contain
sensitive or copyrighted content sourced from the public internet, raising
concerns about data privacy and ownership. Regulatory frameworks, such as the
General Data Protection Regulation (GDPR), grant individuals the right to
request the removal of such sensitive information. This has motivated the
development of machine unlearning algorithms that aim to remove specific
knowledge from models without the need for costly retraining. Despite these
advancements, evaluating the efficacy of unlearning algorithms remains a
challenge due to the inherent complexity and generative nature of LLMs. In this
work, we introduce a comprehensive auditing framework for unlearning
evaluation, comprising three benchmark datasets, six unlearning algorithms, and
five prompt-based auditing methods. By using various auditing algorithms, we
evaluate the effectiveness and robustness of different unlearning strategies.
To explore alternatives beyond prompt-based auditing, we propose a novel
technique that leverages intermediate activation perturbations, addressing the
limitations of auditing methods that rely solely on model inputs and outputs.

</details>


### [79] [DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs](https://arxiv.org/abs/2505.23131)
*Xinyu Yao, Daniel Bourgeois, Abhinav Jain, Yuxin Tang, Jiawen Yao, Zhimin Ding, Arlei Silva, Chris Jermaine*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个名为Doppler的新框架，旨在解决在复杂机器学习工作负载中，现有基于学习的方法在将数据流图中的操作分配到设备上以最小化执行时间时存在的问题。


<details>
  <summary>更多</summary>
  
**动机:** 研究的主要动机是解决基于学习的方法在分配数据流图操作到设备上以最小化执行时间时面临的三个关键限制：对像TensorFlow这样的批量同步系统的依赖、设计基于学习的方法时缺乏对底层系统调度机制的认识、以及仅依赖强化学习而忽略了专家设计的有效启发式结构。

**方法:** 论文提出了一种名为Doppler的三阶段框架，用于训练包含选择操作的SEL策略和将选定操作放置在设备上的PLC策略的双策略网络。

**结果:** 实验结果显示，所提出的Doppler框架在各种任务中均优于所有基线方法，不仅减少了系统执行时间，还展示了采样效率。

**结论:** 论文的结论是，Doppler框架通过减少系统执行时间以及通过减少每个训练回合的时间来展示采样效率，优于所有基线方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DOPPLER%3A+Dual-Policy+Learning+for+Device+Assignment+in+Asynchronous+Dataflow+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23131，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23131&send_immediately=true&force_search=false)

**原文摘要:** We study the problem of assigning operations in a dataflow graph to devices
to minimize execution time in a work-conserving system, with emphasis on
complex machine learning workloads. Prior learning-based methods often struggle
due to three key limitations: (1) reliance on bulk-synchronous systems like
TensorFlow, which under-utilize devices due to barrier synchronization; (2)
lack of awareness of the scheduling mechanism of underlying systems when
designing learning-based methods; and (3) exclusive dependence on reinforcement
learning, ignoring the structure of effective heuristics designed by experts.
In this paper, we propose \textsc{Doppler}, a three-stage framework for
training dual-policy networks consisting of 1) a $\mathsf{SEL}$ policy for
selecting operations and 2) a $\mathsf{PLC}$ policy for placing chosen
operations on devices. Our experiments show that \textsc{Doppler} outperforms
all baseline methods across tasks by reducing system execution time and
additionally demonstrates sampling efficiency by reducing per-episode training
time.

</details>


### [80] [Score-based Generative Modeling for Conditional Independence Testing](https://arxiv.org/abs/2505.23309)
*Yixin Ren, Chenghou Jin, Yewei Xia, Li Ke, Longtao Huang, Hui Xue, Hao Zhang, Jihong Guan, Shuigeng Zhou*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的条件独立性检验方法，通过基于得分的生成模型提高了检验的准确性和稳定性，优于现有的生成对抗网络方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成对抗网络（GAN）等生成模型在建模条件分布和训练稳定性方面存在不足，导致性能不佳。因此需要一种更有效的方法进行条件独立性检验。

**方法:** 使用切片条件得分匹配方案准确估计条件得分，并采用Langevin动力学条件采样生成零假设样本，确保精确的I型误差控制。此外，还引入了拟合优度阶段以验证生成的样本并在实践中增强可解释性。

**结果:** 实验表明，所提出的方法显著优于现有最先进方法，为基于生成模型的条件独立性检验提供了有前景的方向。

**结论:** 该论文提出了一种基于得分生成模型的新型条件独立性检验方法，实现了精确的I型误差控制和强大的检验能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Score-based+Generative+Modeling+for+Conditional+Independence+Testing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23309，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23309&send_immediately=true&force_search=false)

**原文摘要:** Determining conditional independence (CI) relationships between random
variables is a fundamental yet challenging task in machine learning and
statistics, especially in high-dimensional settings. Existing generative
model-based CI testing methods, such as those utilizing generative adversarial
networks (GANs), often struggle with undesirable modeling of conditional
distributions and training instability, resulting in subpar performance. To
address these issues, we propose a novel CI testing method via score-based
generative modeling, which achieves precise Type I error control and strong
testing power. Concretely, we first employ a sliced conditional score matching
scheme to accurately estimate conditional score and use Langevin dynamics
conditional sampling to generate null hypothesis samples, ensuring precise Type
I error control. Then, we incorporate a goodness-of-fit stage into the method
to verify generated samples and enhance interpretability in practice. We
theoretically establish the error bound of conditional distributions modeled by
score-based generative models and prove the validity of our CI tests. Extensive
experiments on both synthetic and real-world datasets show that our method
significantly outperforms existing state-of-the-art methods, providing a
promising way to revitalize generative model-based CI testing.

</details>


### [81] [Matryoshka Model Learning for Improved Elastic Student Models](https://arxiv.org/abs/2505.23337)
*Chetan Verma, Aditya Srinivas Timmaraju, Cho Jui-Hsieh, Suyash Damle, Ngot Bui, Yang Zhang, Wen Chen, Xin Liu, Prateek Jain, Inderjit S Dhillon*

**主要类别:** cs.LG

**AI概要:** MatTA 是一种新型训练框架，能够通过一次训练生成多个高效的 Student 模型，在提升性能的同时降低服务成本。


<details>
  <summary>更多</summary>
  
**动机:** 工业级机器学习模型需要耗费大量资源来满足不断变化的服务约束，因此需要一种高效的方法来开发多个准确且高效的模型。

**方法:** 提出 MatTA 框架，利用 TA 模型（更大、更具容量的学生模型）帮助学生模型更好地与教师模型关联，并从中提取多个精确的学生模型。

**结果:** 在专有数据集和 GPT-2 Medium 上的实验表明，MatTA 在关键指标上取得了显著改进，包括生产系统中的 20% 改进、SAT Math 的 24% 和 LAMBADA 基准的 10% 以上。

**结论:** MatTA 提供了一种有效的框架，通过使用 Teacher-TA-Student 方法训练多个精确的学生模型，在仅一次训练运行的情况下提供了多个可权衡准确性和较低服务成本的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Matryoshka+Model+Learning+for+Improved+Elastic+Student+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23337，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23337&send_immediately=true&force_search=false)

**原文摘要:** Industry-grade ML models are carefully designed to meet rapidly evolving
serving constraints, which requires significant resources for model
development. In this paper, we propose MatTA, a framework for training multiple
accurate Student models using a novel Teacher-TA-Student recipe. TA models are
larger versions of the Student models with higher capacity, and thus allow
Student models to better relate to the Teacher model and also bring in more
domain-specific expertise. Furthermore, multiple accurate Student models can be
extracted from the TA model. Therefore, despite only one training run, our
methodology provides multiple servable options to trade off accuracy for lower
serving cost. We demonstrate the proposed method, MatTA, on proprietary
datasets and models. Its practical efficacy is underscored by live A/B tests
within a production ML system, demonstrating 20% improvement on a key metric.
We also demonstrate our method on GPT-2 Medium, a public model, and achieve
relative improvements of over 24% on SAT Math and over 10% on the LAMBADA
benchmark.

</details>


### [82] [Bigger, Regularized, Categorical: High-Capacity Value Functions are Efficient Multi-Task Learners](https://arxiv.org/abs/2505.23150)
*Michal Nauman, Marek Cygan, Carmelo Sferrazza, Aviral Kumar, Pieter Abbeel*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于高容量价值模型和可学习任务嵌入的方法，解决了在线强化学习中的任务干扰问题，实现了鲁棒且可扩展的多任务训练。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于价值的强化学习方法在多任务环境中存在稀疏奖励和梯度冲突的问题，导致时间差分优化不稳定，而当前的工作流通常依赖离线策略，缺乏在线训练的有效方案。

**方法:** 使用通过交叉熵训练的高容量价值模型，并结合可学习的任务嵌入来调节模型，从而缓解任务间的干扰问题，实现多任务在线强化学习的稳定优化。

**结果:** 该方法在包含280多个不同任务的7个多任务基准测试中表现优异，不仅达到了单任务和多任务的最先进性能，还实现了对新任务的高效迁移。

**结论:** 所提出的方法有效解决了多任务在线强化学习中的任务干扰问题，为构建通用策略提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bigger%2C+Regularized%2C+Categorical%3A+High-Capacity+Value+Functions+are+Efficient+Multi-Task+Learners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23150，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23150&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in language modeling and vision stem from training large
models on diverse, multi-task data. This paradigm has had limited impact in
value-based reinforcement learning (RL), where improvements are often driven by
small models trained in a single-task context. This is because in multi-task RL
sparse rewards and gradient conflicts make optimization of temporal difference
brittle. Practical workflows for generalist policies therefore avoid online
training, instead cloning expert trajectories or distilling collections of
single-task policies into one agent. In this work, we show that the use of
high-capacity value models trained via cross-entropy and conditioned on
learnable task embeddings addresses the problem of task interference in online
RL, allowing for robust and scalable multi-task training. We test our approach
on 7 multi-task benchmarks with over 280 unique tasks, spanning high
degree-of-freedom humanoid control and discrete vision-based RL. We find that,
despite its simplicity, the proposed approach leads to state-of-the-art single
and multi-task performance, as well as sample-efficient transfer to new tasks.

</details>


### [83] [Towards Reward Fairness in RLHF: From a Resource Allocation Perspective](https://arxiv.org/abs/2505.23349)
*Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种从资源分配角度解决奖励不公平问题的方法，使用 Fairness Regularization 和 Fairness Coefficient 来提高强化学习中奖励的公平性，从而更好地使大型语言模型与人类偏好对齐。


<details>
  <summary>更多</summary>
  
**动机:** 奖励作为人类偏好的代理，在强化学习中起到关键作用，但由于奖励本身可能存在偏差，影响了模型的对齐效果，因此需要解决奖励不公平的问题。

**方法:** Fairness Regularization 和 Fairness Coefficient 是提出的两种方法，用于在不针对每种偏差进行设计的情况下实现奖励的公平性。

**结果:** 实验表明，该方法能够在验证和强化学习场景中分别获得公平奖励模型和策略模型，并有效提升模型与人类偏好对齐的公平性。

**结论:** 论文得出结论，通过资源分配的角度处理奖励公平性问题可以更公正地使大型语言模型与人类偏好对齐。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Reward+Fairness+in+RLHF%3A+From+a+Resource+Allocation+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23349，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23349&send_immediately=true&force_search=false)

**原文摘要:** Rewards serve as proxies for human preferences and play a crucial role in
Reinforcement Learning from Human Feedback (RLHF). However, if these rewards
are inherently imperfect, exhibiting various biases, they can adversely affect
the alignment of large language models (LLMs). In this paper, we collectively
define the various biases present in rewards as the problem of reward
unfairness. We propose a bias-agnostic method to address the issue of reward
fairness from a resource allocation perspective, without specifically designing
for each type of bias, yet effectively mitigating them. Specifically, we model
preference learning as a resource allocation problem, treating rewards as
resources to be allocated while considering the trade-off between utility and
fairness in their distribution. We propose two methods, Fairness Regularization
and Fairness Coefficient, to achieve fairness in rewards. We apply our methods
in both verification and reinforcement learning scenarios to obtain a fairness
reward model and a policy model, respectively. Experiments conducted in these
scenarios demonstrate that our approach aligns LLMs with human preferences in a
more fair manner.

</details>


### [84] [Dynamic Spectral Backpropagation for Efficient Neural Network Training](https://arxiv.org/abs/2505.23369)
*Mannmohan Muthuraman*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种称为动态光谱反向传播（DSBP）的新方法，通过梯度投影减少复杂度，有效应对资源受限情况下的神经网络训练问题，并在多个数据集上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 为了在资源受限的情况下提高神经网络的训练效率并促进平坦极小值，需要一种新的方法。

**方法:** 动态光谱反向传播（DSBP）基于三阶随机微分方程（SDE）和PAC贝叶斯极限进行操作。

**结果:** DSBP在CIFAR 10、Fashion MNIST、MedMNIST和Tiny ImageNet数据集上的表现优于Sharpness Aware Minimization（SAM）、Low Rank Adaptation（LoRA）和Model Agnostic Meta Learning（MAML）方法。

**结论:** DSBP通过将梯度投影到主特征向量上，提高了在资源受限情况下的神经网络训练效果，并提出了五种扩展方法来解决鲁棒性、少样本学习和硬件效率方面的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Spectral+Backpropagation+for+Efficient+Neural+Network+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23369，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23369&send_immediately=true&force_search=false)

**原文摘要:** Dynamic Spectral Backpropagation (DSBP) enhances neural network training
under resource constraints by projecting gradients onto principal eigenvectors,
reducing complexity and promoting flat minima. Five extensions are proposed,
dynamic spectral inference, spectral architecture optimization, spectral meta
learning, spectral transfer regularization, and Lie algebra inspired dynamics,
to address challenges in robustness, fewshot learning, and hardware efficiency.
Supported by a third order stochastic differential equation (SDE) and a PAC
Bayes limit, DSBP outperforms Sharpness Aware Minimization (SAM), Low Rank
Adaptation (LoRA), and Model Agnostic Meta Learning (MAML) on CIFAR 10, Fashion
MNIST, MedMNIST, and Tiny ImageNet, as demonstrated through extensive
experiments and visualizations. Future work focuses on scalability, bias
mitigation, and ethical considerations.

</details>


### [85] [Pseudo Multi-Source Domain Generalization: Bridging the Gap Between Single and Multi-Source Domain Generalization](https://arxiv.org/abs/2505.23173)
*Shohei Enomoto*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种名为PMDG的新型领域泛化方法，通过从单一数据源生成伪域来模拟多源域环境，从而降低传统多源域泛化的数据成本并提高实用性。


<details>
  <summary>更多</summary>
  
**动机:** 多源域泛化（MDG）受限于构建多域数据集的成本和难度，本文旨在提出一种更实用的解决方案。

**方法:** 利用风格迁移和数据增强技术将单一源域数据生成多个伪域，并结合现有的MDG算法进行实验验证。

**结果:** 实验表明伪域可以有效提升模型泛化能力，且其性能与实际多域数据相当或更优。

**结论:** PMDG框架在单源域泛化设置下有效地应用了多源域泛化算法，通过伪域生成技术提供了与实际多域数据相当甚至更好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pseudo+Multi-Source+Domain+Generalization%3A+Bridging+the+Gap+Between+Single+and+Multi-Source+Domain+Generalization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23173，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23173&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models often struggle to maintain performance when deployed on
data distributions different from their training data, particularly in
real-world applications where environmental conditions frequently change. While
Multi-source Domain Generalization (MDG) has shown promise in addressing this
challenge by leveraging multiple source domains during training, its practical
application is limited by the significant costs and difficulties associated
with creating multi-domain datasets. To address this limitation, we propose
Pseudo Multi-source Domain Generalization (PMDG), a novel framework that
enables the application of sophisticated MDG algorithms in more practical
Single-source Domain Generalization (SDG) settings. PMDG generates multiple
pseudo-domains from a single source domain through style transfer and data
augmentation techniques, creating a synthetic multi-domain dataset that can be
used with existing MDG algorithms. Through extensive experiments with
PseudoDomainBed, our modified version of the DomainBed benchmark, we analyze
the effectiveness of PMDG across multiple datasets and architectures. Our
analysis reveals several key findings, including a positive correlation between
MDG and PMDG performance and the potential of pseudo-domains to match or exceed
actual multi-domain performance with sufficient data. These comprehensive
empirical results provide valuable insights for future research in domain
generalization. Our code is available at
https://github.com/s-enmt/PseudoDomainBed.

</details>


### [86] [Buffer-free Class-Incremental Learning with Out-of-Distribution Detection](https://arxiv.org/abs/2505.23412)
*Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli*

**主要类别:** cs.LG

**AI概要:** 本文研究了无需记忆缓冲区的后校准OOD检测方法在开放世界场景中的类增量学习的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法依赖于包含过去数据的记忆缓冲区，这引发了关于隐私、可扩展性和训练时间增加的问题。

**方法:** 对后校准OOD检测方法进行了深入分析，并在推理时适当应用，以替代基于缓冲区的OOD检测。

**结果:** 缓冲区无关的方法在类增量学习和未知样本拒绝方面实现了与基于缓冲区的方法相当或更优的性能。

**结论:** 缓冲区无关的后校准OOD检测方法能够在开放世界场景中实现高效且隐私保护的CIL系统设计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Buffer-free+Class-Incremental+Learning+with+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23412，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23412&send_immediately=true&force_search=false)

**原文摘要:** Class-incremental learning (CIL) poses significant challenges in open-world
scenarios, where models must not only learn new classes over time without
forgetting previous ones but also handle inputs from unknown classes that a
closed-set model would misclassify. Recent works address both issues by
(i)~training multi-head models using the task-incremental learning framework,
and (ii) predicting the task identity employing out-of-distribution (OOD)
detectors. While effective, the latter mainly relies on joint training with a
memory buffer of past data, raising concerns around privacy, scalability, and
increased training time. In this paper, we present an in-depth analysis of
post-hoc OOD detection methods and investigate their potential to eliminate the
need for a memory buffer. We uncover that these methods, when applied
appropriately at inference time, can serve as a strong substitute for
buffer-based OOD detection. We show that this buffer-free approach achieves
comparable or superior performance to buffer-based methods both in terms of
class-incremental learning and the rejection of unknown samples. Experimental
results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings,
offering new insights into the design of efficient and privacy-preserving CIL
systems for open-world settings.

</details>


### [87] [The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning](https://arxiv.org/abs/2505.23176)
*Shiwei Li, Xiandi Luo, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li*

**主要类别:** cs.LG

**AI概要:** 本论文提出了三种新技术来改进联邦学习中的低秩分解方法，从而实现了更好的性能和更高的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高联邦学习的训练效率，研究者尝试使用低秩分解技术减少通信开销。本文旨在进一步提升这些低秩分解方法的性能。

**方法:** 论文引入了三种新技术：模型更新分解（MUD）、分块克罗内克分解（BKD）和聚合感知分解（AAD），分别针对联邦学习中分解的目标、方式以及聚合方式进行改进。此外，作者提供了严格的理论分析以确保MUD的收敛性。

**结果:** 实验结果显示，该方法相较于现有方法具有更快的收敛速度和更高的准确性。代码已公开以便复现结果。

**结论:** 论文得出结论，提出的三种技术能够互补并同时应用以实现最佳性能，并且所提出的方法在收敛性和准确性上优于相关基线方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Panaceas+for+Improving+Low-Rank+Decomposition+in+Communication-Efficient+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23176&send_immediately=true&force_search=false)

**原文摘要:** To improve the training efficiency of federated learning (FL), previous
research has employed low-rank decomposition techniques to reduce communication
overhead. In this paper, we seek to enhance the performance of these low-rank
decomposition methods. Specifically, we focus on three key issues related to
decomposition in FL: what to decompose, how to decompose, and how to aggregate.
Subsequently, we introduce three novel techniques: Model Update Decomposition
(MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware
Decomposition (AAD), each targeting a specific issue. These techniques are
complementary and can be applied simultaneously to achieve optimal performance.
Additionally, we provide a rigorous theoretical analysis to ensure the
convergence of the proposed MUD. Extensive experimental results show that our
approach achieves faster convergence and superior accuracy compared to relevant
baseline methods. The code is available at
https://github.com/Leopold1423/fedmud-icml25.

</details>


### [88] [Bidirectional predictive coding](https://arxiv.org/abs/2505.23415)
*Gaspard Oliviers, Mufeng Tang, Rafal Bogacz*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的双向预测编码模型（bPC），该模型整合了生成和判别推理机制，在多个任务上表现优异并更接近生物视觉推理过程。


<details>
  <summary>更多</summary>
  
**动机:** 大脑使用生成和判别推理的实验证据表明，传统的单向预测编码模型在需要双向处理的任务中表现不佳，因此需要改进模型。

**方法:** 提出了双向预测编码（bPC）模型，该模型在保持生物学合理性的前提下，结合了生成和判别推理方法。

**结果:** bPC在生成和判别任务中均表现出与或优于现有模型的表现，并展示了其在多模态学习和缺失信息推理中的优势。

**结论:** bPC能够更准确地模拟生物视觉推理，因为它同时整合了生成和判别推理，并且在特定任务中表现优于单向模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bidirectional+predictive+coding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23415，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23415&send_immediately=true&force_search=false)

**原文摘要:** Predictive coding (PC) is an influential computational model of visual
learning and inference in the brain. Classical PC was proposed as a top-down
generative model, where the brain actively predicts upcoming visual inputs, and
inference minimises the prediction errors. Recent studies have also shown that
PC can be formulated as a discriminative model, where sensory inputs predict
neural activities in a feedforward manner. However, experimental evidence
suggests that the brain employs both generative and discriminative inference,
while unidirectional PC models show degraded performance in tasks requiring
bidirectional processing. In this work, we propose bidirectional PC (bPC), a PC
model that incorporates both generative and discriminative inference while
maintaining a biologically plausible circuit implementation. We show that bPC
matches or outperforms unidirectional models in their specialised generative or
discriminative tasks, by developing an energy landscape that simultaneously
suits both tasks. We also demonstrate bPC's superior performance in two
biologically relevant tasks including multimodal learning and inference with
missing information, suggesting that bPC resembles biological visual inference
more closely.

</details>


### [89] [Enhanced DACER Algorithm with High Diffusion Efficiency](https://arxiv.org/abs/2505.23426)
*Yinuo Wang, Mining Tan, Wenjun Zou, Haotian Lin, Xujie Song, Wenxuan Wang, Tong Liu, Likun Wang, Guojian Zhan, Tianze Zhu, Shiqi Liu, Jingliang Duan, Shengbo Eben Li*

**主要类别:** cs.LG

**AI概要:** 本文提出DACER2算法，通过引入Q-梯度场目标和时间加权机制，解决了扩散模型在在线强化学习中效率低下的问题，并在MuJoCo控制任务和多模态任务上取得了优异的表现。


<details>
  <summary>更多</summary>
  
**动机:** 扩散策略缺乏推理效率，限制了其在实时在线RL中的应用。为了提高训练和推理效率同时保持或增强性能，研究者提出了DACER2方法。

**方法:** 提出了一种Q-梯度场目标作为辅助优化目标，并引入了时间加权机制以解决Q-梯度场与扩散时间步长的独立性问题，从而指导每一步的去噪过程。

**结果:** 实验结果显示，DACER2算法在MuJoCo基准测试和多种多模态任务上仅使用五次扩散步骤就实现了最先进的性能。

**结论:** 通过引入Q梯度场目标和时间加权机制，DACER2算法在减少扩散步骤的同时保持甚至提升了性能，在大多数MuJoCo控制任务中达到最先进的表现，并且比DACER具有更强的多模态性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhanced+DACER+Algorithm+with+High+Diffusion+Efficiency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23426，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23426&send_immediately=true&force_search=false)

**原文摘要:** Due to their expressive capacity, diffusion models have shown great promise
in offline RL and imitation learning. Diffusion Actor-Critic with Entropy
Regulator (DACER) extended this capability to online RL by using the reverse
diffusion process as a policy approximator, trained end-to-end with policy
gradient methods, achieving strong performance. However, this comes at the cost
of requiring many diffusion steps, which significantly hampers training
efficiency, while directly reducing the steps leads to noticeable performance
degradation. Critically, the lack of inference efficiency becomes a significant
bottleneck for applying diffusion policies in real-time online RL settings. To
improve training and inference efficiency while maintaining or even enhancing
performance, we propose a Q-gradient field objective as an auxiliary
optimization target to guide the denoising process at each diffusion step.
Nonetheless, we observe that the independence of the Q-gradient field from the
diffusion time step negatively impacts the performance of the diffusion policy.
To address this, we introduce a temporal weighting mechanism that enables the
model to efficiently eliminate large-scale noise in the early stages and refine
actions in the later stages. Experimental results on MuJoCo benchmarks and
several multimodal tasks demonstrate that the DACER2 algorithm achieves
state-of-the-art performance in most MuJoCo control tasks with only five
diffusion steps, while also exhibiting stronger multimodality compared to
DACER.

</details>


### [90] [FSL-SAGE: Accelerating Federated Split Learning via Smashed Activation Gradient Estimation](https://arxiv.org/abs/2505.23182)
*Srijith Nair, Michael Lin, Amirreza Talebi, Peizhong Ju, Elizabeth Bentley, Jia Liu*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FSL-SAGE%3A+Accelerating+Federated+Split+Learning+via+Smashed+Activation+Gradient+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23182&send_immediately=true&force_search=false)

**原文摘要:** Collaborative training methods like Federated Learning (FL) and Split
Learning (SL) enable distributed machine learning without sharing raw data.
However, FL assumes clients can train entire models, which is infeasible for
large-scale models. In contrast, while SL alleviates the client memory
constraint in FL by offloading most training to the server, it increases
network latency due to its sequential nature. Other methods address the
conundrum by using local loss functions for parallel client-side training to
improve efficiency, but they lack server feedback and potentially suffer poor
accuracy. We propose FSL-SAGE (Federated Split Learning via Smashed Activation
Gradient Estimation), a new federated split learning algorithm that estimates
server-side gradient feedback via auxiliary models. These auxiliary models
periodically adapt to emulate server behavior on local datasets. We show that
FSL-SAGE achieves a convergence rate of $\mathcal{O}(1/\sqrt{T})$, where $T$ is
the number of communication rounds. This result matches FedAvg, while
significantly reducing communication costs and client memory requirements. Our
empirical results also verify that it outperforms existing state-of-the-art FSL
methods, offering both communication efficiency and accuracy.

</details>


### [91] [Bounded-Abstention Pairwise Learning to Rank](https://arxiv.org/abs/2505.23437)
*Antonio Ferrara, Andrea Pugnana, Francesco Bonchi, Salvatore Ruggieri*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种新的在成对学习排序任务中实现 abstention 的方法，旨在将不确定或低置信度的决策推迟到人类专家，从而提高排名系统的安全性。


<details>
  <summary>更多</summary>
  
**动机:** 由于排名系统在医疗、教育和就业等高风险领域具有重要的经济和社会影响，因此需要引入安全机制，例如 abstention，以将不确定或低置信度的决策推迟到人类专家。然而，abstention 在分类任务之外的机器学习范式中的应用仍未得到充分探索。

**方法:** 基于阈值化排序器的条件风险的方法，当估计的风险超过预定义阈值时，系统选择不做出决策。

**结果:** 提出了一个全新的 abstention 方法，并通过多个数据集的实证评估展示了该方法的有效性。

**结论:** 论文提出了一种新的在成对学习排序任务中实现 abstention 的方法，贡献包括最优 abstention 策略的理论表征、构建 abstention 排序模型的模型无关插件算法以及多个数据集上的全面实证评估。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bounded-Abstention+Pairwise+Learning+to+Rank，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23437，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23437&send_immediately=true&force_search=false)

**原文摘要:** Ranking systems influence decision-making in high-stakes domains like health,
education, and employment, where they can have substantial economic and social
impacts. This makes the integration of safety mechanisms essential. One such
mechanism is $\textit{abstention}$, which enables algorithmic decision-making
system to defer uncertain or low-confidence decisions to human experts. While
abstention have been predominantly explored in the context of classification
tasks, its application to other machine learning paradigms remains
underexplored. In this paper, we introduce a novel method for abstention in
pairwise learning-to-rank tasks. Our approach is based on thresholding the
ranker's conditional risk: the system abstains from making a decision when the
estimated risk exceeds a predefined threshold. Our contributions are threefold:
a theoretical characterization of the optimal abstention strategy, a
model-agnostic, plug-in algorithm for constructing abstaining ranking models,
and a comprehensive empirical evaluations across multiple datasets,
demonstrating the effectiveness of our approach.

</details>


### [92] [Two Is Better Than One: Rotations Scale LoRAs](https://arxiv.org/abs/2505.23184)
*Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang*

**主要类别:** cs.LG

**AI概要:** 本文提出RadarGate，一种基于几何的新型门控机制，通过旋转和融合LoRA表示，有效提升了大型语言模型在多样化任务上的扩展性和表现力。


<details>
  <summary>更多</summary>
  
**动机:** 传统基于加权求和的门控机制在适应多样化任务时限制了大型语言模型（LLMs）的可扩展性，导致泛化能力差和欠拟合问题，因此需要一种更具表现力的方法来提升多LoRA间的特征交互。

**方法:** 提出了一种名为RadarGate的几何启发门控方法，包括两个主要步骤：首先使用可学习组件将每个LoRA表示与其他LoRA进行融合，然后通过一个包含可学习参数的旋转矩阵进一步处理输出，以增强表达能力和特征交互。

**结果:** 在6个公共基准测试中的21个任务上进行了广泛实验，结果表明RadarGate在扩展LoRA方面具有显著的有效性，并揭示了旋转操作能够促进语义相似表示的对比对齐。

**结论:** RadarGate通过引入可学习的旋转矩阵和融合机制，有效提升了LoRA表示之间的交互能力和模型的扩展性，在多个任务上验证了有效性，并提供了关于表示对比对齐的有价值见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Two+Is+Better+Than+One%3A+Rotations+Scale+LoRAs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23184&send_immediately=true&force_search=false)

**原文摘要:** Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates
large language models (LLMs) to efficiently adapt to diverse tasks. However,
traditional gating mechanisms that route inputs to the best experts may
fundamentally hinder LLMs' scalability, leading to poor generalization and
underfitting issues. We identify that the root cause lies in the restricted
expressiveness of existing weighted-sum mechanisms, both within and outside the
convex cone of LoRA representations. This motivates us to propose RadarGate, a
novel geometrically inspired gating method that introduces rotational
operations of LoRAs representations to boost the expressiveness and facilitate
richer feature interactions among multiple LoRAs for scalable LLMs.
Specifically, we first fuse each LoRA representation to other LoRAs using a
learnable component and then feed the output to a rotation matrix. This matrix
involves learnable parameters that define the relative angular relationship
between LoRA representations. Such a simple yet effective mechanism provides an
extra degree of freedom, facilitating the learning of cross-LoRA synergies and
properly tracking the challenging poor generalization and underfitting issues
as the number of LoRA grows. Extensive experiments on 6 public benchmarks
across 21 tasks show the effectiveness of our RadarGate for scaling LoRAs. We
also provide valuable insights, revealing that the rotations to each pair of
representations are contrastive, encouraging closer alignment of semantically
similar representations during geometrical transformation while pushing
distance ones further apart. We will release our code to the community.

</details>


### [93] [Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning](https://arxiv.org/abs/2505.23529)
*Shifeng Xie, Aref Einizade, Jhony H. Giraldo*

**主要类别:** cs.LG

**AI概要:** 本文提出一种名为SubGEC的新方法，用于图表示学习中的自监督学习，通过子图高斯嵌入和最优传输距离增强对比学习效果。


<details>
  <summary>更多</summary>
  
**动机:** 自监督学习方法可以避免昂贵的人工标注，在图表示学习中具有广泛应用。为了进一步提升其性能，需要设计更有效的对比学习机制。

**方法:** 提出了一种子图高斯嵌入对比（SubGEC）方法，通过子图高斯嵌入模块将子图映射到结构化高斯空间，并利用最优传输距离（Wasserstein和Gromov-Wasserstein距离）测量子图间的相似性。

**结果:** 大量实验表明，SubGEC优于或与现有的最先进方法相当，显示出其在图表示学习中的潜力。

**结论:** SubGEC方法在图表示学习中的自监督学习表现出色，强调了生成对比对的分布设计的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Subgraph+Gaussian+Embedding+Contrast+for+Self-Supervised+Graph+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23529，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23529&send_immediately=true&force_search=false)

**原文摘要:** Graph Representation Learning (GRL) is a fundamental task in machine
learning, aiming to encode high-dimensional graph-structured data into
low-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used
in GRL because they can avoid expensive human annotation. In this work, we
propose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our
approach introduces a subgraph Gaussian embedding module, which adaptively maps
subgraphs to a structured Gaussian space, ensuring the preservation of input
subgraph characteristics while generating subgraphs with a controlled
distribution. We then employ optimal transport distances, more precisely the
Wasserstein and Gromov-Wasserstein distances, to effectively measure the
similarity between subgraphs, enhancing the robustness of the contrastive
learning process. Extensive experiments across multiple benchmarks demonstrate
that \method~outperforms or presents competitive performance against
state-of-the-art approaches. Our findings provide insights into the design of
SSL methods for GRL, emphasizing the importance of the distribution of the
generated contrastive pairs.

</details>


### [94] [Improving the Effective Receptive Field of Message-Passing Neural Networks](https://arxiv.org/abs/2505.23185)
*Shahaf E. Finder, Ron Shapira Weber, Moshe Eliasof, Oren Freifeld, Eran Treister*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的消息传递神经网络IM-MPNN，用于解决MPNNs在捕捉长距离依赖方面的局限性，并在多个基准测试中展示了其优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决MPNNs在处理长距离依赖关系时效果不佳的问题，借鉴CNNs中有效感受野(ERF)增强的最新进展。

**方法:** 提出了一种Interleaved Multiscale Message-Passing Neural Networks (IM-MPNN)架构，结合了图的层次粗化，实现多尺度表示的信息传递。

**结果:** 在Long-Range Graph Benchmark (LRGB)等基准测试中，IM-MPNN相对于基线MPNNs有显著改进。

**结论:** IM-MPNN成功解决了MPNNs中的有限ERF问题，提高了捕捉长距离依赖关系的能力，同时保持了计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+the+Effective+Receptive+Field+of+Message-Passing+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23185，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23185&send_immediately=true&force_search=false)

**原文摘要:** Message-Passing Neural Networks (MPNNs) have become a cornerstone for
processing and analyzing graph-structured data. However, their effectiveness is
often hindered by phenomena such as over-squashing, where long-range
dependencies or interactions are inadequately captured and expressed in the
MPNN output. This limitation mirrors the challenges of the Effective Receptive
Field (ERF) in Convolutional Neural Networks (CNNs), where the theoretical
receptive field is underutilized in practice. In this work, we show and
theoretically explain the limited ERF problem in MPNNs. Furthermore, inspired
by recent advances in ERF augmentation for CNNs, we propose an Interleaved
Multiscale Message-Passing Neural Networks (IM-MPNN) architecture to address
these problems in MPNNs. Our method incorporates a hierarchical coarsening of
the graph, enabling message-passing across multiscale representations and
facilitating long-range interactions without excessive depth or
parameterization. Through extensive evaluations on benchmarks such as the
Long-Range Graph Benchmark (LRGB), we demonstrate substantial improvements over
baseline MPNNs in capturing long-range dependencies while maintaining
computational efficiency.

</details>


### [95] [Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models](https://arxiv.org/abs/2505.23564)
*Yiran Guo, Lijie Xu, Jie Liu, Dan Ye, Shuang Qiu*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种名为Segment Policy Optimization (SPO) 的新强化学习框架，通过引入segment-level的优势估计，解决了传统token-level和trajectory-level方法中的问题，在多个任务上表现出更高的准确性并减少了计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在token-level上因训练精确critic模型困难而存在不准确估计问题，而在trajectory-level上则由于仅依赖最终奖励导致信用分配不精确，因此需要一种中间粒度的方法来克服这些限制。

**方法:** 提出了Segment Policy Optimization (SPO)，包括灵活的segment划分、准确的segment优势估计以及使用segment优势进行策略优化的新策略，如概率掩码策略。

**结果:** SPO在两个具体场景中实例化：(1) SPO-chain用于短链推理（chain-of-thought），实现了比PPO和GRPO高6-12个百分点的准确率提升；(2) SPO-tree用于长链推理，显著降低了MC估计的成本，并在MATH500数据集上实现了比GRPO高7-11个百分点的提升。

**结论:** 论文提出了一种新的强化学习框架Segment Policy Optimization (SPO)，通过segment-level的优势估计来平衡token-level和trajectory-level方法的优缺点，从而更精确地进行信用分配，并基于蒙特卡洛方法实现准确的优势估计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Segment+Policy+Optimization%3A+Effective+Segment-Level+Credit+Assignment+in+RL+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23564，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23564&send_immediately=true&force_search=false)

**原文摘要:** Enhancing the reasoning capabilities of large language models effectively
using reinforcement learning (RL) remains a crucial challenge. Existing
approaches primarily adopt two contrasting advantage estimation granularities:
Token-level methods (e.g., PPO) aim to provide the fine-grained advantage
signals but suffer from inaccurate estimation due to difficulties in training
an accurate critic model. On the other extreme, trajectory-level methods (e.g.,
GRPO) solely rely on a coarse-grained advantage signal from the final reward,
leading to imprecise credit assignment. To address these limitations, we
propose Segment Policy Optimization (SPO), a novel RL framework that leverages
segment-level advantage estimation at an intermediate granularity, achieving a
better balance by offering more precise credit assignment than trajectory-level
methods and requiring fewer estimation points than token-level methods,
enabling accurate advantage estimation based on Monte Carlo (MC) without a
critic model. SPO features three components with novel strategies: (1) flexible
segment partition; (2) accurate segment advantage estimation; and (3) policy
optimization using segment advantages, including a novel probability-mask
strategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain
for short chain-of-thought (CoT), featuring novel cutpoint-based partition and
chain-based advantage estimation, achieving $6$-$12$ percentage point
improvements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,
featuring novel tree-based advantage estimation, which significantly reduces
the cost of MC estimation, achieving $7$-$11$ percentage point improvements
over GRPO on MATH500 under 2K and 4K context evaluation. We make our code
publicly available at https://github.com/AIFrameResearch/SPO.

</details>


### [96] [DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer](https://arxiv.org/abs/2505.23190)
*Yekun Zhu, Min Tang, Zheng Ma*

**主要类别:** cs.LG

**AI概要:** DeepRTE是一种利用预训练注意力神经网络求解稳态辐射传递方程的新方法，具有高精度和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 辐射传递方程（RTE）在多个领域有广泛应用，但其求解通常涉及复杂的计算过程，需要高效准确的方法来解决。

**方法:** 提出了一种名为DeepRTE的深度学习框架，该框架使用预训练的注意力机制神经网络来求解稳态RTE。

**结果:** 通过全面的数值实验验证了DeepRTE的高精度和计算效率。

**结论:** DeepRTE为解决稳态RTE提供了一个有效且高效的深度学习方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeepRTE%3A+Pre-trained+Attention-based+Neural+Network+for+Radiative+Tranfer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23190，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23190&send_immediately=true&force_search=false)

**原文摘要:** In this study, we propose a novel neural network approach, termed DeepRTE, to
address the steady-state Radiative Transfer Equation (RTE). The RTE is a
differential-integral equation that governs the propagation of radiation
through a participating medium, with applications spanning diverse domains such
as neutron transport, atmospheric radiative transfer, heat transfer, and
optical imaging. Our proposed DeepRTE framework leverages pre-trained
attention-based neural networks to solve the RTE with high accuracy and
computational efficiency. The efficacy of the proposed approach is
substantiated through comprehensive numerical experiments.

</details>


### [97] [Beyond Zero Initialization: Investigating the Impact of Non-Zero Initialization on LoRA Fine-Tuning Dynamics](https://arxiv.org/abs/2505.23194)
*Shiwei Li, Xiandi Luo, Xing Tang, Haozhao Wang, Hao Chen, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li*

**主要类别:** cs.LG

**AI概要:** 该论文研究了LoRA参数高效微调方法中使用非零初始化矩阵的效果，发现其提高了对次优学习率的鲁棒性且不影响微调性能。


<details>
  <summary>更多</summary>
  
**动机:** 标准LoRA层中一个矩阵被初始化为零以确保微调从预训练模型开始，但这一做法缺乏理论支持。本文旨在探究非零初始化对LoRA微调动态的影响。

**方法:** 研究从无限宽度的角度分析了非零初始化对LoRA微调动态的影响，并通过广泛的实验验证了发现的有效性。

**结果:** 研究表明，与零初始化相比，将矩阵A和B同时初始化为非零值提高了LoRA对次优学习率的鲁棒性，尤其是对于较小的学习率。此外，非零初始化虽然引入了随机噪声，但通常不会影响微调性能。

**结论:** 论文得出结论，同时将LoRA层中的矩阵A和B初始化为非零值可以提高LoRA对次优学习率的鲁棒性，特别是较小的学习率。此外，尽管非零初始化在预训练权重中引入了随机噪声，但通常不会影响微调性能，因此微调不需要严格从预训练模型开始。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Zero+Initialization%3A+Investigating+the+Impact+of+Non-Zero+Initialization+on+LoRA+Fine-Tuning+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23194，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23194&send_immediately=true&force_search=false)

**原文摘要:** Low-rank adaptation (LoRA) is a widely used parameter-efficient fine-tuning
method. In standard LoRA layers, one of the matrices, $A$ or $B$, is
initialized to zero, ensuring that fine-tuning starts from the pretrained
model. However, there is no theoretical support for this practice. In this
paper, we investigate the impact of non-zero initialization on LoRA's
fine-tuning dynamics from an infinite-width perspective. Our analysis reveals
that, compared to zero initialization, simultaneously initializing $A$ and $B$
to non-zero values improves LoRA's robustness to suboptimal learning rates,
particularly smaller ones. Further analysis indicates that although the
non-zero initialization of $AB$ introduces random noise into the pretrained
weight, it generally does not affect fine-tuning performance. In other words,
fine-tuning does not need to strictly start from the pretrained model. The
validity of our findings is confirmed through extensive experiments across
various models and datasets. The code is available at
https://github.com/Leopold1423/non_zero_lora-icml25.

</details>


### [98] [SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA](https://arxiv.org/abs/2505.23724)
*Minrui Luo, Fuhang Kuang, Yu Wang, Zirui Liu, Tianxing He*

**主要类别:** cs.LG

**AI概要:** 本文提出了SC-LoRA，一种新的LoRA初始化框架，可以在保持知识的同时提高微调效率。


<details>
  <summary>更多</summary>
  
**动机:** 为了同时解决LoRA的慢收敛速度和知识遗忘问题。

**方法:** 通过限制可训练LoRA适配器的输出在一个低秩子空间中，提出了一种新的LoRA初始化框架SC-LoRA。

**结果:** SC-LoRA在各种下游任务中均表现出色，并显著减少了知识遗忘。

**结论:** SC-LoRA在保持知识的同时提高了微调效率，优于现有的LoRA初始化方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SC-LoRA%3A+Balancing+Efficient+Fine-tuning+and+Knowledge+Preservation+via+Subspace-Constrained+LoRA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23724，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23724&send_immediately=true&force_search=false)

**原文摘要:** Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank
Adaptation (LoRA), are indispensable for efficiently customizing Large Language
Models (LLMs). However, vanilla LoRA suffers from slow convergence speed and
knowledge forgetting problems. Recent studies have leveraged the power of
designed LoRA initialization, to enhance the fine-tuning efficiency, or to
preserve knowledge in the pre-trained LLM. However, none of these works can
address the two cases at the same time. To this end, we introduce
Subspace-Constrained LoRA (SC-LoRA), a novel LoRA initialization framework
engineered to navigate the trade-off between efficient fine-tuning and
knowledge preservation. We achieve this by constraining the output of trainable
LoRA adapters in a low-rank subspace, where the context information of
fine-tuning data is most preserved while the context information of preserved
knowledge is least retained, in a balanced way. Such constraint enables the
trainable weights to primarily focus on the main features of fine-tuning data
while avoiding damaging the preserved knowledge features. We provide
theoretical analysis on our method, and conduct extensive experiments including
safety preservation and world knowledge preservation, on various downstream
tasks. In our experiments, SC-LoRA succeeds in delivering superior fine-tuning
performance while markedly diminishing knowledge forgetting, surpassing
contemporary LoRA initialization methods.

</details>


### [99] [REOrdering Patches Improves Vision Models](https://arxiv.org/abs/2505.23751)
*Declan Kutscher, David M. Chan, Yutong Bai, Trevor Darrell, Ritwik Gupta*

**主要类别:** cs.LG

**AI概要:** 本文研究了视觉任务中输入块顺序对序列模型的影响，并提出了REOrder框架以学习最优块排序，从而显著提升模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 由于现代长序列变换模型依赖于破坏排列不变性的架构近似，导致模型性能对块顺序敏感，因此需要探索任务最优的块顺序。

**方法:** 该方法分为两个阶段：首先基于信息论原理评估不同块序列的可压缩性以获得先验；随后使用Plackett-Luce策略并通过REINFORCE优化学习排列策略。

**结果:** 在ImageNet-1K上top-1准确率提高了3.01%，在Functional Map of the World任务中提升了13.35%。

**结论:** 论文提出了一种名为REOrder的框架，能够通过发现任务最优的块顺序来提升序列模型在视觉任务中的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是REOrdering+Patches+Improves+Vision+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23751，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23751&send_immediately=true&force_search=false)

**原文摘要:** Sequence models such as transformers require inputs to be represented as
one-dimensional sequences. In vision, this typically involves flattening images
using a fixed row-major (raster-scan) order. While full self-attention is
permutation-equivariant, modern long-sequence transformers increasingly rely on
architectural approximations that break this invariance and introduce
sensitivity to patch ordering. We show that patch order significantly affects
model performance in such settings, with simple alternatives like column-major
or Hilbert curves yielding notable accuracy shifts. Motivated by this, we
propose REOrder, a two-stage framework for discovering task-optimal patch
orderings. First, we derive an information-theoretic prior by evaluating the
compressibility of various patch sequences. Then, we learn a policy over
permutations by optimizing a Plackett-Luce policy using REINFORCE. This
approach enables efficient learning in a combinatorial permutation space.
REOrder improves top-1 accuracy over row-major ordering on ImageNet-1K by up to
3.01% and Functional Map of the World by 13.35%.

</details>


### [100] [Daunce: Data Attribution through Uncertainty Estimation](https://arxiv.org/abs/2505.23223)
*Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一个名为Daunce的数据归因方法，该方法通过不确定性估计实现对大规模语言模型的有效和简单的数据归因。


<details>
  <summary>更多</summary>
  
**动机:** 现有的梯度-based训练数据归因方法在大规模应用时受到限制，而基于随机投影的方法通常会遭受归因准确性下降的问题。

**方法:** 通过微调一系列扰动模型，并计算这些模型中每个示例损失的协方差作为归因得分。

**结果:** Daunce比现有TDA方法更准确，可扩展到大型语言模型，并与黑盒模型访问兼容。

**结论:** Daunce是一个简单而有效的数据归因方法，适用于大规模语言模型，并且在专有LLMs上实现了首次数据归因。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Daunce%3A+Data+Attribution+through+Uncertainty+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23223&send_immediately=true&force_search=false)

**原文摘要:** Training data attribution (TDA) methods aim to identify which training
examples influence a model's predictions on specific test data most. By
quantifying these influences, TDA supports critical applications such as data
debugging, curation, and valuation. Gradient-based TDA methods rely on
gradients and second-order information, limiting their applicability at scale.
While recent random projection-based methods improve scalability, they often
suffer from degraded attribution accuracy. Motivated by connections between
uncertainty and influence functions, we introduce Daunce - a simple yet
effective data attribution approach through uncertainty estimation. Our method
operates by fine-tuning a collection of perturbed models and computing the
covariance of per-example losses across these models as the attribution score.
Daunce is scalable to large language models (LLMs) and achieves more accurate
attribution compared to existing TDA methods. We validate Daunce on tasks
ranging from vision tasks to LLM fine-tuning, and further demonstrate its
compatibility with black-box model access. Applied to OpenAI's GPT models, our
method achieves, to our knowledge, the first instance of data attribution on
proprietary LLMs.

</details>


### [101] [Differential Information: An Information-Theoretic Perspective on Preference Optimization](https://arxiv.org/abs/2505.23761)
*Yunjae Won, Hyunji Lee, Hyeonbin Hwang, Minjoon Seo*

**主要类别:** cs.LG

**AI概要:** 这篇论文通过引入微分信息分布概念，从理论上解释了DPO算法的有效性，并探讨了高熵与低熵微分信息对语言模型训练的影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管DPO在实践中取得了成功，但其背后的理论依据尚不完善，因此需要填补这一理论空白，并更好地理解其工作机制。

**方法:** 使用微分信息分布（DID）分析DPO中的对数比率奖励参数化形式，研究偏好标签如何编码将参考策略转换为目标策略所需的信息，并推导出最优采样分布的闭合表达式。

**结果:** 发现了DPO中对数比率奖励参数化的唯一最优性，揭示了偏好数据编码微分信息的基本条件，并通过合成实验和实际任务数据集验证了理论发现。

**结论:** 该论文提出了一个统一的视角来理解DPO目标、偏好数据结构以及由此产生的策略行为，通过微分信息的概念解释了高熵和低熵微分信息对模型训练的不同影响，并验证了其理论发现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Differential+Information%3A+An+Information-Theoretic+Perspective+on+Preference+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23761，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23761&send_immediately=true&force_search=false)

**原文摘要:** Direct Preference Optimization (DPO) has become a standard technique for
aligning language models with human preferences in a supervised manner. Despite
its empirical success, the theoretical justification behind its log-ratio
reward parameterization remains incomplete. In this work, we address this gap
by utilizing the Differential Information Distribution (DID): a distribution
over token sequences that captures the information gained during policy
updates. First, we show that when preference labels encode the differential
information required to transform a reference policy into a target policy, the
log-ratio reward in DPO emerges as the uniquely optimal form for learning the
target policy via preference optimization. This result naturally yields a
closed-form expression for the optimal sampling distribution over rejected
responses. Second, we find that the condition for preferences to encode
differential information is fundamentally linked to an implicit assumption
regarding log-margin ordered policies-an inductive bias widely used in
preference optimization yet previously unrecognized. Finally, by analyzing the
entropy of the DID, we characterize how learning low-entropy differential
information reinforces the policy distribution, while high-entropy differential
information induces a smoothing effect, which explains the log-likelihood
displacement phenomenon. We validate our theoretical findings in synthetic
experiments and extend them to real-world instruction-following datasets. Our
results suggest that learning high-entropy differential information is crucial
for general instruction-following, while learning low-entropy differential
information benefits knowledge-intensive question answering. Overall, our work
presents a unifying perspective on the DPO objective, the structure of
preference data, and resulting policy behaviors through the lens of
differential information.

</details>


### [102] [Generalizability vs. Counterfactual Explainability Trade-Off](https://arxiv.org/abs/2505.23225)
*Fabiano Veglianti, Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei*

**主要类别:** cs.LG

**AI概要:** 该论文提出了ε-有效反事实概率（ε-VCP），用于分析监督学习中模型泛化和反事实解释性之间的关系，发现二者存在固有冲突，并通过理论与实验证明ε-VCP可以作为量化过拟合的工具。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是探究监督学习中模型泛化能力和反事实解释性之间的关系，以更好地理解模型的可解释性和性能限制。

**方法:** 论文引入了ε-有效反事实概率（ε-VCP）的概念，并对其进行理论分析，探讨其与模型决策边界几何形状以及过拟合之间的关系。

**结果:** 理论分析表明，ε-VCP随着模型过拟合的增加而上升，实验结果验证了这一理论，并揭示了泛化能力和反事实解释性之间的权衡。

**结论:** 论文得出结论，模型泛化能力与反事实解释性之间存在固有的权衡关系，并提出ε-VCP作为量化过拟合程度的一个实用代理指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalizability+vs.+Counterfactual+Explainability+Trade-Off，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23225&send_immediately=true&force_search=false)

**原文摘要:** In this work, we investigate the relationship between model generalization
and counterfactual explainability in supervised learning. We introduce the
notion of $\varepsilon$-valid counterfactual probability ($\varepsilon$-VCP) --
the probability of finding perturbations of a data point within its
$\varepsilon$-neighborhood that result in a label change. We provide a
theoretical analysis of $\varepsilon$-VCP in relation to the geometry of the
model's decision boundary, showing that $\varepsilon$-VCP tends to increase
with model overfitting. Our findings establish a rigorous connection between
poor generalization and the ease of counterfactual generation, revealing an
inherent trade-off between generalization and counterfactual explainability.
Empirical results validate our theory, suggesting $\varepsilon$-VCP as a
practical proxy for quantitatively characterizing overfitting.

</details>


### [103] [Graph Random Walk with Feature-Label Space Alignment: A Multi-Label Feature Selection Method](https://arxiv.org/abs/2505.23228)
*Wanfu Gao, Jun Gao, Qingqi Han, Hanlin Pan, Kunpeng Liu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于随机游走图和低维表示对齐的新方法，用于高效捕捉多标签数据中复杂的特征与标签关联。


<details>
  <summary>更多</summary>
  
**动机:** 特征维度的快速增长引入了多标签数据集中特征与标签之间的复杂隐式关联，而现有方法难以捕捉这种复杂的非线性关系，导致特征空间与标签空间的不匹配。

**方法:** 设计了一个随机游走图来集成特征-特征、标签-标签以及特征-标签的关系，以优化特征与标签之间的潜在关联表示，并通过对齐低维表示系数并保留流形结构解决变量空间的对齐问题。

**结果:** 在七个基准数据集和三个代表性数据集上进行的广泛实验和消融研究表明，所提方法在各种评估指标下均表现出优越性能。

**结论:** 本文提出了一种创新的解决方案，通过随机游走图和低维表示系数对齐变量空间，有效解决了多标签数据集中特征与标签之间复杂的非线性和隐式关联的问题。实验结果表明了该方法的优越性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Random+Walk+with+Feature-Label+Space+Alignment%3A+A+Multi-Label+Feature+Selection+Method，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23228，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23228&send_immediately=true&force_search=false)

**原文摘要:** The rapid growth in feature dimension may introduce implicit associations
between features and labels in multi-label datasets, making the relationships
between features and labels increasingly complex. Moreover, existing methods
often adopt low-dimensional linear decomposition to explore the associations
between features and labels. However, linear decomposition struggles to capture
complex nonlinear associations and may lead to misalignment between the feature
space and the label space. To address these two critical challenges, we propose
innovative solutions. First, we design a random walk graph that integrates
feature-feature, label-label, and feature-label relationships to accurately
capture nonlinear and implicit indirect associations, while optimizing the
latent representations of associations between features and labels after
low-rank decomposition. Second, we align the variable spaces by leveraging
low-dimensional representation coefficients, while preserving the manifold
structure between the original high-dimensional multi-label data and the
low-dimensional representation space. Extensive experiments and ablation
studies conducted on seven benchmark datasets and three representative datasets
using various evaluation metrics demonstrate the superiority of the proposed
method\footnote{Code: https://github.com/Heilong623/-GRW-}.

</details>


### [104] [Equivalence of stochastic and deterministic policy gradients](https://arxiv.org/abs/2505.23244)
*Emo Todorov*

**主要类别:** cs.LG

**AI概要:** 论文探讨了连续控制中随机与确定性策略梯度的关系，并提出一种统一的方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了揭示随机和确定性策略梯度之间的关系并寻求策略梯度方法的统一。

**方法:** 研究了一类广泛使用的涉及高斯控制噪声和二次控制成本的MDP，并开发了一种构建等效确定性策略MDP的一般程序。

**结果:** 显示了在特定条件下，随机和确定性策略梯度、自然梯度及状态值函数是相同的，而状态-控制值函数是不同的。

**结论:** 作者得出结论，通过逼近状态值函数而不是状态-控制值函数，可以统一策略梯度方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivalence+of+stochastic+and+deterministic+policy+gradients，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23244&send_immediately=true&force_search=false)

**原文摘要:** Policy gradients in continuous control have been derived for both stochastic
and deterministic policies. Here we study the relationship between the two. In
a widely-used family of MDPs involving Gaussian control noise and quadratic
control costs, we show that the stochastic and deterministic policy gradients,
natural gradients, and state value functions are identical; while the
state-control value functions are different. We then develop a general
procedure for constructing an MDP with deterministic policy that is equivalent
to a given MDP with stochastic policy. The controls of this new MDP are the
sufficient statistics of the stochastic policy in the original MDP. Our results
suggest that policy gradient methods can be unified by approximating state
value functions rather than state-control value functions.

</details>


### [105] [Measuring Participant Contributions in Decentralized Federated Learning](https://arxiv.org/abs/2505.23246)
*Honoka Anada, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki*

**主要类别:** cs.LG

**AI概要:** 本文研究了去中心化联邦学习中的参与者贡献测量问题，并提出了DFL-Shapley和DFL-MR两种有效的方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的贡献测量方法专为集中式联邦学习设计，在去中心化联邦学习中应用面临挑战。

**方法:** 首先提出了适用于DFL的DFL-Shapley，然后引入了可计算的近似方法DFL-MR，通过积累轮次Shapley值来估计总体贡献。

**结果:** 实验结果表明，DFL-Shapley是一种有效的真值度量标准，而DFL-MR在各种设置下接近DFL-Shapley，显示了其作为DFL贡献度度量的有效性。

**结论:** 本研究提出了DFL-Shapley和DFL-MR两种测量参与者贡献的新方法，并验证了它们在去中心化联邦学习中的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+Participant+Contributions+in+Decentralized+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23246，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23246&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) enables multiple clients to collaboratively train
models without sharing their data. Measuring participant contributions in FL is
crucial for incentivizing clients and ensuring transparency. While various
methods have been proposed for contribution measurement, they are designed
exclusively for centralized federated learning (CFL), where a central server
collects and aggregates client models, along with evaluating their
contributions. Meanwhile, decentralized federated learning (DFL), in which
clients exchange models directly without a central server, has gained
significant attention for mitigating communication bottlenecks and eliminating
a single point of failure. However, applying existing contribution measurement
methods to DFL is challenging due to the presence of multiple global models and
the absence of a central server. In this study, we present novel methodologies
for measuring participant contributions in DFL. We first propose DFL-Shapley,
an extension of the Shapley value tailored for DFL, adapting this widely used
CFL metric to decentralized settings. Given the impracticality of computing the
ideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable
approximation that estimates overall contributions by accumulating round-wise
Shapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios
and compare them with existing CFL metrics. The experimental results confirm
DFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity
to DFL-Shapley across various settings, highlighting their effectiveness as
contribution metrics in DFL.

</details>


### [106] [Efficiently Access Diffusion Fisher: Within the Outer Product Span Space](https://arxiv.org/abs/2505.23264)
*Fangyikang Wang, Hubery Yin, Shaobin Zhuang, Huminhao Zhu, Yinan Li, Lei Qian, Chao Zhang, Hanbin Zhao, Hui Qian, Chen Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种高效计算扩散Fisher信息的新方法，通过避免自动微分提高准确性和减少计算成本，并首次验证了PF-ODE推导映射的最优传输属性。


<details>
  <summary>更多</summary>
  
**动机:** 当前实践通常使用缺乏准确性保证且耗时的自动微分方法来近似扩散Fisher信息。

**方法:** 开发了两种高效的近似算法，分别用于获取DF的迹和矩阵向量乘法，这些算法避免了自动微分操作，采用时间效率高的向量积计算。

**结果:** 实验证明了所提出的算法在似然评估和伴随优化中的优越准确性和降低的计算成本，并基于DF的新外积公式设计了首次对一般PF-ODE推导映射的最优传输属性进行数值验证的实验。

**结论:** 论文提出了一种新的方法来计算扩散Fisher信息，通过有效的近似算法提高了准确性和降低了计算成本，并设计了验证一般PF-ODE推导映射的最优传输属性的数值实验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficiently+Access+Diffusion+Fisher%3A+Within+the+Outer+Product+Span+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23264，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23264&send_immediately=true&force_search=false)

**原文摘要:** Recent Diffusion models (DMs) advancements have explored incorporating the
second-order diffusion Fisher information (DF), defined as the negative Hessian
of log density, into various downstream tasks and theoretical analysis.
However, current practices typically approximate the diffusion Fisher by
applying auto-differentiation to the learned score network. This black-box
method, though straightforward, lacks any accuracy guarantee and is
time-consuming. In this paper, we show that the diffusion Fisher actually
resides within a space spanned by the outer products of score and initial data.
Based on the outer-product structure, we develop two efficient approximation
algorithms to access the trace and matrix-vector multiplication of DF,
respectively. These algorithms bypass the auto-differentiation operations with
time-efficient vector-product calculations. Furthermore, we establish the
approximation error bounds for the proposed algorithms. Experiments in
likelihood evaluation and adjoint optimization demonstrate the superior
accuracy and reduced computational cost of our proposed algorithms.
Additionally, based on the novel outer-product formulation of DF, we design the
first numerical verification experiment for the optimal transport property of
the general PF-ODE deduced map.

</details>


### [107] [Comparative Analysis of the Land Use and Land Cover Changes in Different Governorates of Oman using Spatiotemporal Multi-spectral Satellite Data](https://arxiv.org/abs/2505.23285)
*Muhammad Shafi, Syed Mohsin Bokhari*

**主要类别:** cs.LG

**AI概要:** 本研究利用Sentinel-2卫星数据和机器学习技术，对阿曼苏丹国多个省份2016至2021年的土地利用和土地覆盖变化进行了分析与比较。


<details>
  <summary>更多</summary>
  
**动机:** 土地利用和土地覆盖变化是卫星影像的关键应用，在资源管理、城市化、土壤和环境保护以及促进可持续发展方面发挥着关键作用。

**方法:** 使用开放源代码的Sentinel-2卫星数据集获取多光谱时空数据，然后采用监督机器学习算法来训练和分类不同的土地覆盖类型。

**结果:** 从2016年到2021年，以年度时间步长分析和比较了阿曼苏丹国各个省的土地利用和土地覆盖变化。

**结论:** 该研究通过监督机器学习算法对不同土地覆盖类型进行分类，并利用构建的模型对所选区域的土地利用和土地覆盖变化进行了有效的比较评估。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+Analysis+of+the+Land+Use+and+Land+Cover+Changes+in+Different+Governorates+of+Oman+using+Spatiotemporal+Multi-spectral+Satellite+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23285，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23285&send_immediately=true&force_search=false)

**原文摘要:** Land cover and land use (LULC) changes are key applications of satellite
imagery, and they have critical roles in resource management, urbanization,
protection of soils and the environment, and enhancing sustainable development.
The literature has heavily utilized multispectral spatiotemporal satellite data
alongside advanced machine learning algorithms to monitor and predict LULC
changes. This study analyzes and compares LULC changes across various
governorates (provinces) of the Sultanate of Oman from 2016 to 2021 using
annual time steps. For the chosen region, multispectral spatiotemporal data
were acquired from the open-source Sentinel-2 satellite dataset. Supervised
machine learning algorithms were used to train and classify different land
covers, such as water bodies, crops, urban, etc. The constructed model was
subsequently applied within the study region, allowing for an effective
comparative evaluation of LULC changes within the given timeframe.

</details>


### [108] [X2Graph for Cancer Subtyping Prediction on Biological Tabular Data](https://arxiv.org/abs/2505.23334)
*Tu Bui, Mohamed Suliman, Aparajita Haldar, Mohammed Amer, Serban Georgescu*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种名为X2Graph的新型深度学习方法，该方法通过利用表格列之间的外部知识，将样本转换为图结构，从而在小型生物表格数据集上取得了良好的性能表现。


<details>
  <summary>更多</summary>
  
**动机:** 尽管深度学习对文本、音频和图像数据集有变革性影响，但在医疗领域等表格数据上的主导地位仍不明确，尤其是在数据稀缺的情况下。

**方法:** X2Graph利用表格列之间的关系将每个样本转化为图结构，并应用标准的消息传递算法进行图建模。

**结果:** X2Graph在小型生物表格数据集上实现了强大的性能。

**结论:** X2Graph方法在三个癌症亚型数据集中展示了优于现有基于树和深度学习方法的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X2Graph+for+Cancer+Subtyping+Prediction+on+Biological+Tabular+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23334，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23334&send_immediately=true&force_search=false)

**原文摘要:** Despite the transformative impact of deep learning on text, audio, and image
datasets, its dominance in tabular data, especially in the medical domain where
data are often scarce, remains less clear. In this paper, we propose X2Graph, a
novel deep learning method that achieves strong performance on small biological
tabular datasets. X2Graph leverages external knowledge about the relationships
between table columns, such as gene interactions, to convert each sample into a
graph structure. This transformation enables the application of standard
message passing algorithms for graph modeling. Our X2Graph method demonstrates
superior performance compared to existing tree-based and deep learning methods
across three cancer subtyping datasets.

</details>


### [109] [Graph Positional Autoencoders as Self-supervised Learners](https://arxiv.org/abs/2505.23345)
*Yang Liu, Deyu Bo, Wenxuan Cao, Yuan Fang, Yawen Li, Chuan Shi*

**主要类别:** cs.LG

**AI概要:** 本文提出GraphPAE，一种新型图自编码器，通过双路径架构同时重建节点特征和位置，从而提升图表示学习效果。


<details>
  <summary>更多</summary>
  
**动机:** 传统图自编码器（GAE）在节点或边掩码范式中主要捕获低频信号，难以学习表达性强的结构信息。

**方法:** GraphPAE采用双路径架构，分别重建节点特征和位置，利用位置编码增强信息传递处理，并通过节点表示优化位置和近似特征向量。

**结果:** 实验表明GraphPAE在异质性节点分类、图属性预测和迁移学习任务中表现优异，达到最先进的性能并显著优于基线模型。

**结论:** GraphPAE在图自监督学习中表现出色，能够有效捕捉图中的高频信号和结构信息。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Positional+Autoencoders+as+Self-supervised+Learners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23345，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23345&send_immediately=true&force_search=false)

**原文摘要:** Graph self-supervised learning seeks to learn effective graph representations
without relying on labeled data. Among various approaches, graph autoencoders
(GAEs) have gained significant attention for their efficiency and scalability.
Typically, GAEs take incomplete graphs as input and predict missing elements,
such as masked nodes or edges. While effective, our experimental investigation
reveals that traditional node or edge masking paradigms primarily capture
low-frequency signals in the graph and fail to learn the expressive structural
information. To address these issues, we propose Graph Positional Autoencoders
(GraphPAE), which employs a dual-path architecture to reconstruct both node
features and positions. Specifically, the feature path uses positional encoding
to enhance the message-passing processing, improving GAE's ability to predict
the corrupted information. The position path, on the other hand, leverages node
representations to refine positions and approximate eigenvectors, thereby
enabling the encoder to learn diverse frequency information. We conduct
extensive experiments to verify the effectiveness of GraphPAE, including
heterophilic node classification, graph property prediction, and transfer
learning. The results demonstrate that GraphPAE achieves state-of-the-art
performance and consistently outperforms baselines by a large margin.

</details>


### [110] [Sentinel: Scheduling Live Streams with Proactive Anomaly Detection in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2505.23347)
*Yuting Li, Shaoyuan Huang, Tengwen Zhang, Cheng Zhang, Xiaofei Wang, Victor C. M. Leung*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Sentinel的新框架，通过主动异常检测改善直播服务中云边平台的调度问题，取得了显著成效。


<details>
  <summary>更多</summary>
  
**动机:** 直播服务的快速增长对CCPs提出了更高的需求，但现有的优化策略因不稳定的CCPs中的各种异常而难以取得实际效果，且大规模CCPs加剧了及时调度中异常检测的难度。

**方法:** 将调度过程建模为Pre-Post-Scheduling两阶段范式，并通过实验验证了Sentinel的效果。

**结果:** 实验结果显示，Sentinel减少了70%的异常频率，提高了74%的收入，并使调度速度翻倍。

**结论:** 论文提出了一种基于主动异常检测的调度框架Sentinel，能够有效提高CCPs的收入和调度速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sentinel%3A+Scheduling+Live+Streams+with+Proactive+Anomaly+Detection+in+Crowdsourced+Cloud-Edge+Platforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23347，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23347&send_immediately=true&force_search=false)

**原文摘要:** With the rapid growth of live streaming services, Crowdsourced Cloud-edge
service Platforms (CCPs) are playing an increasingly important role in meeting
the increasing demand. Although stream scheduling plays a critical role in
optimizing CCPs' revenue, most optimization strategies struggle to achieve
practical results due to various anomalies in unstable CCPs. Additionally, the
substantial scale of CCPs magnifies the difficulties of anomaly detection in
time-sensitive scheduling. To tackle these challenges, this paper proposes
Sentinel, a proactive anomaly detection-based scheduling framework. Sentinel
models the scheduling process as a two-stage Pre-Post-Scheduling paradigm: in
the pre-scheduling stage, Sentinel conducts anomaly detection and constructs a
strategy pool; in the post-scheduling stage, upon request arrival, it triggers
an appropriate scheduling based on a pre-generated strategy to implement the
scheduling process. Extensive experiments on realistic datasets show that
Sentinel significantly reduces anomaly frequency by 70%, improves revenue by
74%, and doubles the scheduling speed.

</details>


### [111] [Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control](https://arxiv.org/abs/2505.23355)
*Maxiu Xiao, Jianglin Lan, Jingxing Yu, Eldert van Henten, Congcong Sun*

**主要类别:** cs.LG

**AI概要:** 本论文研究了在温室气候控制中使用带有不完美输入的交互式强化学习方法，并提出相应的解决方案以提高性能。


<details>
  <summary>更多</summary>
  
**动机:** 温室气候控制对作物生长和资源利用有直接影响，而传统的强化学习面临训练效率低和初始条件依赖高等挑战。

**方法:** 开发了三种交互式RL算法（reward shaping, policy shaping 和 control sharing），并提出了基于神经网络的方法来增强鲁棒性。

**结果:** 在模拟温室环境中进行了全面评估，结果显示policy shaping和control sharing分别实现了8.4%和6.8%的利润提升，而reward shaping导致9.4%的利润下降。

**结论:** 在温室气候控制中应用带有不完美输入的交互式RL具有潜力，但机制选择至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grower-in-the-Loop+Interactive+Reinforcement+Learning+for+Greenhouse+Climate+Control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23355&send_immediately=true&force_search=false)

**原文摘要:** Climate control is crucial for greenhouse production as it directly affects
crop growth and resource use. Reinforcement learning (RL) has received
increasing attention in this field, but still faces challenges, including
limited training efficiency and high reliance on initial learning conditions.
Interactive RL, which combines human (grower) input with the RL agent's
learning, offers a potential solution to overcome these challenges. However,
interactive RL has not yet been applied to greenhouse climate control and may
face challenges related to imperfect inputs. Therefore, this paper aims to
explore the possibility and performance of applying interactive RL with
imperfect inputs into greenhouse climate control, by: (1) developing three
representative interactive RL algorithms tailored for greenhouse climate
control (reward shaping, policy shaping and control sharing); (2) analyzing how
input characteristics are often contradicting, and how the trade-offs between
them make grower's inputs difficult to perfect; (3) proposing a neural
network-based approach to enhance the robustness of interactive RL agents under
limited input availability; (4) conducting a comprehensive evaluation of the
three interactive RL algorithms with imperfect inputs in a simulated greenhouse
environment. The demonstration shows that interactive RL incorporating
imperfect grower inputs has the potential to improve the performance of the RL
agent. RL algorithms that influence action selection, such as policy shaping
and control sharing, perform better when dealing with imperfect inputs,
achieving 8.4% and 6.8% improvement in profit, respectively. In contrast,
reward shaping, an algorithm that manipulates the reward function, is sensitive
to imperfect inputs and leads to a 9.4% decrease in profit. This highlights the
importance of selecting an appropriate mechanism when incorporating imperfect
inputs.

</details>


### [112] [Meta-Learning Approaches for Speaker-Dependent Voice Fatigue Models](https://arxiv.org/abs/2505.23378)
*Roseline Polle, Agnes Norbury, Alexandra Livia Georgescu, Nicholas Cummins, Stefano Goria*

**主要类别:** cs.LG

**AI概要:** 该论文提出使用元学习进行说话人自适应建模，以提高语音健康监测应用的性能，并表明基于transformer的模型优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统的混合效应模型在每次新观测时都需要计算成本高昂的重新训练，因此在生产环境中不切实际。

**方法:** 将说话人自适应任务重新表述为元学习问题，并测试了三种不同复杂度的元学习方法：集成距离模型、原型网络和基于transformer的序列模型。

**结果:** 所有测试的元学习方法都优于横截面模型和传统混合效应模型，其中基于transformer的方法表现最佳。

**结论:** 基于transformer的方法在语音健康监测任务中表现出最佳性能，并且所有元学习方法都优于传统的混合效应模型和横截面模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-Learning+Approaches+for+Speaker-Dependent+Voice+Fatigue+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23378，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23378&send_immediately=true&force_search=false)

**原文摘要:** Speaker-dependent modelling can substantially improve performance in
speech-based health monitoring applications. While mixed-effect models are
commonly used for such speaker adaptation, they require computationally
expensive retraining for each new observation, making them impractical in a
production environment. We reformulate this task as a meta-learning problem and
explore three approaches of increasing complexity: ensemble-based distance
models, prototypical networks, and transformer-based sequence models. Using
pre-trained speech embeddings, we evaluate these methods on a large
longitudinal dataset of shift workers (N=1,185, 10,286 recordings), predicting
time since sleep from speech as a function of fatigue, a symptom commonly
associated with ill-health. Our results demonstrate that all meta-learning
approaches tested outperformed both cross-sectional and conventional
mixed-effects models, with a transformer-based method achieving the strongest
performance.

</details>


### [113] [Automated Modeling Method for Pathloss Model Discovery](https://arxiv.org/abs/2505.23383)
*Ahmad Anaqreh, Shih-Kai Chou, Mihael Mohorčič, Carolina Fortuna*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种使用人工智能的新颖方法，能够快速发现具有高可解释性的路径损耗模型，其性能优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统建模方法依赖于统计技术，随着无线通信系统的发展，需要更准确和互操作性强的建模方法，而人工智能技术可以应对这一挑战。

**方法:** 该研究采用了两种技术：一种是基于深度符号回归的方法，另一种是基于Kolmogorov-Arnold网络的方法，两者均用于自动化模型的构建、评估与优化。

**结果:** 实验结果表明，Kolmogorov-Arnold网络在预测准确性方面接近完美（R^2值接近1），而深度符号回归生成了较为紧凑且具有中等精度的模型；此外，自动化方法相比传统方法最多减少了75%的预测误差。

**结论:** 论文提出了一种基于人工智能的新方法，用于加速路径损耗模型的发现，同时保持了模型的可解释性，并且在合成和真实数据集上都表现良好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+Modeling+Method+for+Pathloss+Model+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23383，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23383&send_immediately=true&force_search=false)

**原文摘要:** Modeling propagation is the cornerstone for designing and optimizing
next-generation wireless systems, with a particular emphasis on 5G and beyond
era. Traditional modeling methods have long relied on statistic-based
techniques to characterize propagation behavior across different environments.
With the expansion of wireless communication systems, there is a growing demand
for methods that guarantee the accuracy and interoperability of modeling.
Artificial intelligence (AI)-based techniques, in particular, are increasingly
being adopted to overcome this challenge, although the interpretability is not
assured with most of these methods. Inspired by recent advancements in AI, this
paper proposes a novel approach that accelerates the discovery of path loss
models while maintaining interpretability. The proposed method automates the
model formulation, evaluation, and refinement, facilitating model discovery. We
evaluate two techniques: one based on Deep Symbolic Regression, offering full
interpretability, and the second based on Kolmogorov-Arnold Networks, providing
two levels of interpretability. Both approaches are evaluated on two synthetic
and two real-world datasets. Our results show that Kolmogorov-Arnold Networks
achieve R^2 values close to 1 with minimal prediction error, while Deep
Symbolic Regression generates compact models with moderate accuracy. Moreover,
on the selected examples, we demonstrate that automated methods outperform
traditional methods, achieving up to 75% reduction in prediction errors,
offering accurate and explainable solutions with potential to increase the
efficiency of discovering next-generation path loss models.

</details>


### [114] [OTPTO: Joint Product Selection and Inventory Optimization in Fresh E-commerce Front-End Warehouses](https://arxiv.org/abs/2505.23421)
*Zheming Zhang, Yan Jiang, Qingshan Li, Ai Han*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的OTPTO方法，用于解决生鲜电商前端仓库的库存管理问题，有效提升了消费者满意度和订单完整履行率。


<details>
  <summary>更多</summary>
  
**动机:** 传统预测然后优化（PTO）方法无法将预测与库存目标对齐，也未能优先考虑消费者满意度，因此需要提出一种新方法来提高订单完整履行率。

**方法:** 采用多任务的Optimize-then-Predict-then-Optimize (OTPTO) 方法，结合0-1混合整数规划模型OM1、产品选择模型PM1和补货模型PM2，并通过后处理算法OM2优化结果。

**结果:** 相比PTO方法，OTPTO方法使订单完整履行率提高了4.34%（相对增长7.05%），并缩小了与最优订单完整履行率之间的差距达5.27%。

**结论:** OTPTO方法在生鲜电商前端仓库库存管理中表现出色，提高了订单完整履行率，并为未来研究提供了有价值的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OTPTO%3A+Joint+Product+Selection+and+Inventory+Optimization+in+Fresh+E-commerce+Front-End+Warehouses，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23421，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23421&send_immediately=true&force_search=false)

**原文摘要:** In China's competitive fresh e-commerce market, optimizing operational
strategies, especially inventory management in front-end warehouses, is key to
enhance customer satisfaction and to gain a competitive edge. Front-end
warehouses are placed in residential areas to ensure the timely delivery of
fresh goods and are usually in small size. This brings the challenge of
deciding which goods to stock and in what quantities, taking into account
capacity constraints. To address this issue, traditional predict-then-optimize
(PTO) methods that predict sales and then decide on inventory often don't align
prediction with inventory goals, as well as fail to prioritize consumer
satisfaction. This paper proposes a multi-task
Optimize-then-Predict-then-Optimize (OTPTO) approach that jointly optimizes
product selection and inventory management, aiming to increase consumer
satisfaction by maximizing the full order fulfillment rate. Our method employs
a 0-1 mixed integer programming model OM1 to determine historically optimal
inventory levels, and then uses a product selection model PM1 and the stocking
model PM2 for prediction. The combined results are further refined through a
post-processing algorithm OM2. Experimental results from JD.com's 7Fresh
platform demonstrate the robustness and significant advantages of our OTPTO
method. Compared to the PTO approach, our OTPTO method substantially enhances
the full order fulfillment rate by 4.34% (a relative increase of 7.05%) and
narrows the gap to the optimal full order fulfillment rate by 5.27%. These
findings substantiate the efficacy of the OTPTO method in managing inventory at
front-end warehouses of fresh e-commerce platforms and provide valuable
insights for future research in this domain.

</details>


### [115] [On the Validity of Head Motion Patterns as Generalisable Depression Biomarkers](https://arxiv.org/abs/2505.23427)
*Monika Gahalawat, Maneesh Bilalpur, Raul Fernandez Rojas, Jeffrey F. Cohn, Roland Goecke, Ramanathan Subramanian*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种利用kineme来估计抑郁严重程度的新方法，具有广泛的应用潜力。


<details>
  <summary>更多</summary>
  
**动机:** 头部运动尚未受到足够关注，同时机器学习模型的普遍验证方法存在局限性。

**方法:** 研究使用了三个不同西方文化的抑郁数据集，并通过k折交叉验证和模型重用来评估模型的有效性和泛化能力。

**结果:** 1. 头部运动模式是估计抑郁严重程度的有效生物标志物；2. 基于kineme的特征比其他方法更具泛化能力。

**结论:** 研究表明，基于kineme的特征在估计抑郁严重程度方面表现出高效的性能和更强的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Validity+of+Head+Motion+Patterns+as+Generalisable+Depression+Biomarkers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23427，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23427&send_immediately=true&force_search=false)

**原文摘要:** Depression is a debilitating mood disorder negatively impacting millions
worldwide. While researchers have explored multiple verbal and non-verbal
behavioural cues for automated depression assessment, head motion has received
little attention thus far. Further, the common practice of validating machine
learning models via a single dataset can limit model generalisability. This
work examines the effectiveness and generalisability of models utilising
elementary head motion units, termed kinemes, for depression severity
estimation. Specifically, we consider three depression datasets from different
western cultures (German: AVEC2013, Australian: Blackdog and American: Pitt
datasets) with varied contextual and recording settings to investigate the
generalisability of the derived kineme patterns via two methods: (i) k-fold
cross-validation over individual/multiple datasets, and (ii) model reuse on
other datasets. Evaluating classification and regression performance with
classical machine learning methods, our results show that: (1) head motion
patterns are efficient biomarkers for estimating depression severity, achieving
highly competitive performance for both classification and regression tasks on
a variety of datasets, including achieving the second best Mean Absolute Error
(MAE) on the AVEC2013 dataset, and (2) kineme-based features are more
generalisable than (a) raw head motion descriptors for binary severity
classification, and (b) other visual behavioural cues for severity estimation
(regression).

</details>


### [116] [Diversity-Aware Policy Optimization for Large Language Model Reasoning](https://arxiv.org/abs/2505.23433)
*Jian Yao, Ran Cheng, Xingyu Wu, Jibin Wu, Kay Chen Tan*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了强化学习训练中多样性对大型语言模型推理能力的影响，并提出了一种新的多样性感知策略优化方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多样性在强化学习中起着关键作用，但其对大型语言模型推理的影响尚未得到充分探索，因此本研究填补了这一空白。

**方法:** 设计了一种token级别的多样性度量方法，并将其转化为实际目标，在正样本上选择性应用该方法。

**结果:** 在12个LLM上的评估中，观察到解决方案的多样性和高性能模型中的Potential at k之间存在显著正相关。

**结论:** 论文得出结论，通过在强化学习训练中显式促进多样性，可以提高大型语言模型的推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diversity-Aware+Policy+Optimization+for+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23433&send_immediately=true&force_search=false)

**原文摘要:** The reasoning capabilities of large language models (LLMs) have advanced
rapidly, particularly following the release of DeepSeek R1, which has inspired
a surge of research into data quality and reinforcement learning (RL)
algorithms. Despite the pivotal role diversity plays in RL, its influence on
LLM reasoning remains largely underexplored. To bridge this gap, this work
presents a systematic investigation into the impact of diversity in RL-based
training for LLM reasoning, and proposes a novel diversity-aware policy
optimization method. Across evaluations on 12 LLMs, we observe a strong
positive correlation between the solution diversity and Potential at k (a novel
metric quantifying an LLM's reasoning potential) in high-performing models.
This finding motivates our method to explicitly promote diversity during RL
training. Specifically, we design a token-level diversity and reformulate it
into a practical objective, then we selectively apply it to positive samples.
Integrated into the R1-zero training framework, our method achieves a 3.5
percent average improvement across four mathematical reasoning benchmarks,
while generating more diverse and robust solutions.

</details>


### [117] [Rethinking Regularization Methods for Knowledge Graph Completion](https://arxiv.org/abs/2505.23442)
*Linyu Li, Zhi Jin, Yuanpeng He, Dongming Jin, Haoran Duan, Zhengwei Tao, Xuan Zhang, Jiandong Li*

**主要类别:** cs.LG

**AI概要:** 本文重新思考了知识图谱补全(KGC)中的正则化方法应用，并提出了一种新颖的稀疏正则化方法(SPR)，通过大量实验证明其能够有效提升KGC模型的性能。


<details>
  <summary>更多</summary>
  
**动机:** 多数先前的研究忽视了从更深层面对正则化方法的利用，因此没有将其潜力发挥到最大。

**方法:** 引入了一种新的稀疏正则化方法(SPR)，通过嵌入基于排名的选择性稀疏性的概念到KGC正则化器中。

**结果:** 精心设计的正则化不仅缓解了过拟合和减少了方差，还使这些模型突破了原有的性能上限。此外，提出的SPR方法在多个数据集和多个模型上的实验表明其优越性。

**结论:** SPR正则化方法优于其他方法，能够使知识图谱补全模型进一步突破性能边界。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Regularization+Methods+for+Knowledge+Graph+Completion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23442，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23442&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graph completion (KGC) has attracted considerable attention in
recent years because it is critical to improving the quality of knowledge
graphs. Researchers have continuously explored various models. However, most
previous efforts have neglected to take advantage of regularization from a
deeper perspective and therefore have not been used to their full potential.
This paper rethinks the application of regularization methods in KGC. Through
extensive empirical studies on various KGC models, we find that carefully
designed regularization not only alleviates overfitting and reduces variance
but also enables these models to break through the upper bounds of their
original performance. Furthermore, we introduce a novel sparse-regularization
method that embeds the concept of rank-based selective sparsity into the KGC
regularizer. The core idea is to selectively penalize those components with
significant features in the embedding vector, thus effectively ignoring many
components that contribute little and may only represent noise. Various
comparative experiments on multiple datasets and multiple models show that the
SPR regularization method is better than other regularization methods and can
enable the KGC model to further break through the performance margin.

</details>


### [118] [Strategic Classification with Non-Linear Classifiers](https://arxiv.org/abs/2505.23443)
*Benyamin Trachtenberg, Nir Rosenfeld*

**主要类别:** cs.LG

**AI概要:** 本文探讨了战略分类中非线性分类器的影响，指出其在战略环境中限制了模型的普遍近似能力并导致性能差距。


<details>
  <summary>更多</summary>
  
**动机:** 标准监督学习主要研究线性分类器的战略行为，本文旨在拓展视野，探讨非线性分类器下的战略行为及其对学习的影响。

**方法:** 论文采用自下而上的方法，分析非线性如何影响决策边界点、分类器表达能力和模型类复杂度。

**结果:** 研究表明，在战略环境下，通用近似器（如神经网络）不再具备普遍性，并通过实验证明即使在无限制模型类别中也可能产生性能差距。

**结论:** 论文得出结论，战略环境中的非线性分类器会限制模型的普遍近似能力，从而影响学习效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategic+Classification+with+Non-Linear+Classifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23443，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23443&send_immediately=true&force_search=false)

**原文摘要:** In strategic classification, the standard supervised learning setting is
extended to support the notion of strategic user behavior in the form of costly
feature manipulations made in response to a classifier. While standard learning
supports a broad range of model classes, the study of strategic classification
has, so far, been dedicated mostly to linear classifiers. This work aims to
expand the horizon by exploring how strategic behavior manifests under
non-linear classifiers and what this implies for learning. We take a bottom-up
approach showing how non-linearity affects decision boundary points, classifier
expressivity, and model classes complexity. A key finding is that universal
approximators (e.g., neural nets) are no longer universal once the environment
is strategic. We demonstrate empirically how this can create performance gaps
even on an unrestricted model class.

</details>


### [119] [Network Inversion for Uncertainty-Aware Out-of-Distribution Detection](https://arxiv.org/abs/2505.23448)
*Pirzada Suhail, Rehna Afroz, Amit Sethi*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种用于离散分布检测和不确定性估计的新颖框架，通过网络反转和分类器训练的结合，实现了无需外部数据集或后校准技术的有效解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 在现实场景中，意外输入不可避免，因此需要有效的机器学习系统来处理这些问题。

**方法:** 将分类器扩展为(n+1)-类模型，并通过引入“垃圾”类来表示异常输入，利用网络反转重构对应于所有输出类的输入图像。

**结果:** 该方法在推理过程中能够有效检测并拒绝OOD样本，并且可以使用每个预测的相关置信度来估计不确定性的输入。

**结论:** 作者提出了一种新颖的框架，结合网络反转和分类器训练以同时解决OOD检测和不确定性估计的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Network+Inversion+for+Uncertainty-Aware+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23448&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution (OOD) detection and uncertainty estimation (UE) are
critical components for building safe machine learning systems, especially in
real-world scenarios where unexpected inputs are inevitable. In this work, we
propose a novel framework that combines network inversion with classifier
training to simultaneously address both OOD detection and uncertainty
estimation. For a standard n-class classification task, we extend the
classifier to an (n+1)-class model by introducing a "garbage" class, initially
populated with random gaussian noise to represent outlier inputs. After each
training epoch, we use network inversion to reconstruct input images
corresponding to all output classes that initially appear as noisy and
incoherent and are therefore excluded to the garbage class for retraining the
classifier. This cycle of training, inversion, and exclusion continues
iteratively till the inverted samples begin to resemble the in-distribution
data more closely, suggesting that the classifier has learned to carve out
meaningful decision boundaries while sanitising the class manifolds by pushing
OOD content into the garbage class. During inference, this training scheme
enables the model to effectively detect and reject OOD samples by classifying
them into the garbage class. Furthermore, the confidence scores associated with
each prediction can be used to estimate uncertainty for both in-distribution
and OOD inputs. Our approach is scalable, interpretable, and does not require
access to external OOD datasets or post-hoc calibration techniques while
providing a unified solution to the dual challenges of OOD detection and
uncertainty estimation.

</details>


### [120] [Diffusion Guidance Is a Controllable Policy Improvement Operator](https://arxiv.org/abs/2505.23458)
*Kevin Frans, Seohong Park, Pieter Abbeel, Sergey Levine*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为CFGRL的新框架，该框架结合了强化学习和生成模型的优点，能够通过监督学习简单地训练，同时进一步改进数据中的策略。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习旨在超越数据中的表现，但扩展这类系统已被证明非常棘手；而生成模型技术已被证明具有显著的可扩展性且易于训练。

**方法:** 通过将策略改进与扩散模型的引导直接关联起来，形成新的框架CFGRL，并使用监督学习的方式训练。

**结果:** 在离线强化学习任务中，增加引导权重会带来性能的可靠提升，并且CFGRL可以无需显式学习价值函数即可操作。

**结论:** CFGRL能够通过结合强化学习和生成模型的优点，在不显式学习价值函数的情况下进一步改进数据中的策略，实现性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion+Guidance+Is+a+Controllable+Policy+Improvement+Operator，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23458，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23458&send_immediately=true&force_search=false)

**原文摘要:** At the core of reinforcement learning is the idea of learning beyond the
performance in the data. However, scaling such systems has proven notoriously
tricky. In contrast, techniques from generative modeling have proven remarkably
scalable and are simple to train. In this work, we combine these strengths, by
deriving a direct relation between policy improvement and guidance of diffusion
models. The resulting framework, CFGRL, is trained with the simplicity of
supervised learning, yet can further improve on the policies in the data. On
offline RL tasks, we observe a reliable trend -- increased guidance weighting
leads to increased performance. Of particular importance, CFGRL can operate
without explicitly learning a value function, allowing us to generalize simple
supervised methods (e.g., goal-conditioned behavioral cloning) to further
prioritize optimality, gaining performance for "free" across the board.

</details>


### [121] [On Global Convergence Rates for Federated Policy Gradient under Heterogeneous Environment](https://arxiv.org/abs/2505.23459)
*Safwan Labbi, Paul Mangold, Daniil Tiapkin, Eric Moulines*

**主要类别:** cs.LG

**AI概要:** 本文研究了联邦强化学习中策略梯度方法的收敛性问题，提出了一种新的高效算法b-RS-FedPG，并证明其在异质环境下的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 联邦强化学习中的环境异质性给策略梯度方法的收敛带来了挑战，尤其是在需要非确定性或时变策略的情况下。

**方法:** 使用洛杰维奇条件分析FedPG算法的收敛性，并提出b-RS-FedPG新方法，采用softmax启发的参数化结合正则化方案。

**结果:** 证明了FedPG在熵正则化和非正则化情况下的全局收敛性，提出了b-RS-FedPG方法并展示了其向近似最优策略的显式收敛速度。

**结论:** FedPG算法在环境异质性下具有全局收敛性，并且可以实现线性加速，b-RS-FedPG方法能够更有效地找到接近最优的静态策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Global+Convergence+Rates+for+Federated+Policy+Gradient+under+Heterogeneous+Environment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23459，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23459&send_immediately=true&force_search=false)

**原文摘要:** Ensuring convergence of policy gradient methods in federated reinforcement
learning (FRL) under environment heterogeneity remains a major challenge. In
this work, we first establish that heterogeneity, perhaps counter-intuitively,
can necessitate optimal policies to be non-deterministic or even time-varying,
even in tabular environments. Subsequently, we prove global convergence results
for federated policy gradient (FedPG) algorithms employing local updates, under
a {\L}ojasiewicz condition that holds only for each individual agent, in both
entropy-regularized and non-regularized scenarios. Crucially, our theoretical
analysis shows that FedPG attains linear speed-up with respect to the number of
agents, a property central to efficient federated learning. Leveraging insights
from our theoretical findings, we introduce b-RS-FedPG, a novel policy gradient
method that employs a carefully constructed softmax-inspired parameterization
coupled with an appropriate regularization scheme. We further demonstrate
explicit convergence rates for b-RS-FedPG toward near-optimal stationary
policies. Finally, we demonstrate that empirically both FedPG and b-RS-FedPG
consistently outperform federated Q-learning on heterogeneous settings.

</details>


### [122] [Refining Labeling Functions with Limited Labeled Data](https://arxiv.org/abs/2505.23470)
*Chenjie Li, Amir Gilad, Boris Glavic, Zhengjie Miao, Sudeepa Roy*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一种通过基于少量标记示例修复标签函数（LFs）的方法，以提高程序弱监督中的标签生成质量。


<details>
  <summary>更多</summary>
  
**动机:** 论文的研究动机是解决程序弱监督（PWS）中标签质量依赖于用户提供的标签函数（LFs）准确性的挑战，希望通过修复LFs来提升整体效果。

**方法:** 作者开发了新技术，通过在标记示例上最小地改变LFs的结果来修复LFs，以确保每个标记数据点的正确标签有足够的证据，并且每个修复后的LF具有足够高的准确性。LFs被建模为条件规则，从而可以选择性地更改其某些输入的输出。

**结果:** 实验结果表明，该系统能够基于非常小的标记数据集显著改善LFs的质量。

**结论:** 该论文得出结论，通过基于少量标记示例修复标签函数（LFs），可以显著提高程序弱监督（PWS）中生成标签的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Refining+Labeling+Functions+with+Limited+Labeled+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23470，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23470&send_immediately=true&force_search=false)

**原文摘要:** Programmatic weak supervision (PWS) significantly reduces human effort for
labeling data by combining the outputs of user-provided labeling functions
(LFs) on unlabeled datapoints. However, the quality of the generated labels
depends directly on the accuracy of the LFs. In this work, we study the problem
of fixing LFs based on a small set of labeled examples. Towards this goal, we
develop novel techniques for repairing a set of LFs by minimally changing their
results on the labeled examples such that the fixed LFs ensure that (i) there
is sufficient evidence for the correct label of each labeled datapoint and (ii)
the accuracy of each repaired LF is sufficiently high. We model LFs as
conditional rules which enables us to refine them, i.e., to selectively change
their output for some inputs. We demonstrate experimentally that our system
improves the quality of LFs based on surprisingly small sets of labeled
datapoints.

</details>


### [123] [SGD as Free Energy Minimization: A Thermodynamic View on Neural Network Training](https://arxiv.org/abs/2505.23489)
*Ildus Sadrtdinov, Ivan Klimov, Ekaterina Lobacheva, Dmitry Vetrov*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于热力学的随机梯度下降(SGD)行为解释框架，揭示了SGD隐式最小化自由能函数F=U-TS，并探讨了学习率(LR)对温度T及训练结果的影响。


<details>
  <summary>更多</summary>
  
**动机:** 研究者试图解释为什么较高的学习率会阻碍训练收敛到损失最小值，以及不同学习率如何导致训练稳定在不同的损失水平。

**方法:** 通过热力学视角，将SGD的行为类比于自由能最小化过程，并通过实验验证该框架在欠参数化和过参数化模型上的有效性。

**结果:** 发现欠参数化模型遵循自由能最小化且温度随学习率增加而上升；而在过参数化模型中，低学习率下温度趋近于零，使SGD直接最小化损失并收敛至最优解。

**结论:** 本文为理解SGD在固定学习率下的稳定行为提供了新的理论视角，并解释了学习率与权重分布熵之间的平衡机制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SGD+as+Free+Energy+Minimization%3A+A+Thermodynamic+View+on+Neural+Network+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23489，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23489&send_immediately=true&force_search=false)

**原文摘要:** We present a thermodynamic interpretation of the stationary behavior of
stochastic gradient descent (SGD) under fixed learning rates (LRs) in neural
network training. We show that SGD implicitly minimizes a free energy function
$F=U-TS$, balancing training loss $U$ and the entropy of the weights
distribution $S$, with temperature $T$ determined by the LR. This perspective
offers a new lens on why high LRs prevent training from converging to the loss
minima and how different LRs lead to stabilization at different loss levels. We
empirically validate the free energy framework on both underparameterized (UP)
and overparameterized (OP) models. UP models consistently follow free energy
minimization, with temperature increasing monotonically with LR, while for OP
models, the temperature effectively drops to zero at low LRs, causing SGD to
minimize the loss directly and converge to an optimum. We attribute this
mismatch to differences in the signal-to-noise ratio of stochastic gradients
near optima, supported by both a toy example and neural network experiments.

</details>


### [124] [Why Machine Learning Models Fail to Fully Capture Epistemic Uncertainty](https://arxiv.org/abs/2505.23506)
*Sebastián Jiménez, Mira Jürgens, Willem Waegeman*

**主要类别:** cs.LG

**AI概要:** 论文指出当前二阶分布不确定性量化方法在捕捉认知不确定性方面的不足，特别是在处理模型偏差方面。通过理论分析和实验验证，揭示了这些方法可能误导认知不确定性估计的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的监督学习方法在处理偶然不确定性和认知不确定性时忽略了模型偏差这一关键因素，因此需要更全面地理解认知不确定性的来源。

**方法:** 利用更细粒度的认知不确定性来源分类法，并分析如何将经典预测误差的偏差-方差分解分解为反映这些不确定性的不同部分。通过涵盖过程和数据驱动不确定性成分的基于仿真的评估协议进行验证。

**结果:** 研究发现，高模型偏差可能导致对认知不确定性的低估，常见的二阶不确定性量化方法会将由偏差引起的误差混入偶然估计中，从而进一步低估认知不确定性。

**结论:** 当前基于二阶分布的不确定性量化方法未能充分反映所有相关的认知不确定性来源，尤其是在模型偏差方面。只有在所有认知不确定性来源得到适当表示的情况下，才能实现有意义的偶然不确定性估计。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Machine+Learning+Models+Fail+to+Fully+Capture+Epistemic+Uncertainty，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23506，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23506&send_immediately=true&force_search=false)

**原文摘要:** In recent years various supervised learning methods that disentangle
aleatoric and epistemic uncertainty based on second-order distributions have
been proposed. We argue that these methods fail to capture critical components
of epistemic uncertainty, particularly due to the often-neglected component of
model bias. To show this, we make use of a more fine-grained taxonomy of
epistemic uncertainty sources in machine learning models, and analyse how the
classical bias-variance decomposition of the expected prediction error can be
decomposed into different parts reflecting these uncertainties. By using a
simulation-based evaluation protocol which encompasses epistemic uncertainty
due to both procedural- and data-driven uncertainty components, we illustrate
that current methods rarely capture the full spectrum of epistemic uncertainty.
Through theoretical insights and synthetic experiments, we show that high model
bias can lead to misleadingly low estimates of epistemic uncertainty, and
common second-order uncertainty quantification methods systematically blur
bias-induced errors into aleatoric estimates, thereby underrepresenting
epistemic uncertainty. Our findings underscore that meaningful aleatoric
estimates are feasible only if all relevant sources of epistemic uncertainty
are properly represented.

</details>


### [125] [AnchorAttention: Difference-Aware Sparse Attention with Stripe Granularity](https://arxiv.org/abs/2505.23520)
*Yu Zhang, Dong Guo, Fang Wu, Guoliang Zhu, Dian Ding, Yiming Zhang*

**主要类别:** cs.LG

**AI概要:** 为了解决大型语言模型在扩展上下文长度时因自注意力机制的二次复杂性而产生的计算挑战，本文提出了AnchorAttention，一种差异感知的动态稀疏注意机制。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法在处理具有扩展上下文长度的大型语言模型时，由于自注意力的二次复杂性，在预填充阶段面临显著的计算挑战。这些方法通常依赖于局部信息进行模式识别，无法捕捉全局上下文，并且块的粗粒度导致持续的内部稀疏性，从而导致准确性和效率次优。

**方法:** 提出了AnchorAttention，包括基于模式的锚点计算、差分感知的条纹稀疏性识别和细粒度稀疏计算三个关键组件。

**结果:** AnchorAttention在128k文本长度下，速度提升了1.44倍，同时保持了更高的召回率。

**结论:** AnchorAttention通过其更细粒度的稀疏策略，在相同的召回水平下实现了更高的稀疏率，显著减少了计算时间。相比以前最先进的方法，在128k文本长度下，其速度提升了1.44倍，同时保持了更高的召回率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AnchorAttention%3A+Difference-Aware+Sparse+Attention+with+Stripe+Granularity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23520，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23520&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) with extended context lengths face significant
computational challenges during the pre-filling phase, primarily due to the
quadratic complexity of self-attention. Existing methods typically employ
dynamic pattern matching and block-sparse low-level implementations. However,
their reliance on local information for pattern identification fails to capture
global contexts, and the coarse granularity of blocks leads to persistent
internal sparsity, resulting in suboptimal accuracy and efficiency. To address
these limitations, we propose \textbf{AnchorAttention}, a difference-aware,
dynamic sparse attention mechanism that efficiently identifies critical
attention regions at a finer stripe granularity while adapting to global
contextual information, achieving superior speed and accuracy. AnchorAttention
comprises three key components: (1) \textbf{Pattern-based Anchor Computation},
leveraging the commonalities present across all inputs to rapidly compute a set
of near-maximum scores as the anchor; (2) \textbf{Difference-aware Stripe
Sparsity Identification}, performing difference-aware comparisons with the
anchor to quickly obtain discrete coordinates of significant regions in a
stripe-like sparsity pattern; (3) \textbf{Fine-grained Sparse Computation},
replacing the traditional contiguous KV block loading approach with
simultaneous discrete KV position loading to maximize sparsity rates while
preserving full hardware computational potential. With its finer-grained
sparsity strategy, \textbf{AnchorAttention} achieves higher sparsity rates at
the same recall level, significantly reducing computation time. Compared to
previous state-of-the-art methods, at a text length of 128k, it achieves a
speedup of 1.44$\times$ while maintaining higher recall rates.

</details>


### [126] [Accelerating AllReduce with a Persistent Straggler](https://arxiv.org/abs/2505.23523)
*Arjun Devraj, Eric Ding, Abhishek Vijaya Kumar, Robert Kleinberg, Rachee Singh*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为StragglAR的AllReduce算法，该算法通过在持续落后者到达同步屏障期间执行GPU上的ReduceScatter，并执行一种新集体算法来完成AllReduce，从而加速分布式训练和推理。


<details>
  <summary>更多</summary>
  
**动机:** 现有的同步AllReduce算法由于需要等待最慢的同步屏障导致性能下降，因此需要一种更高效的方法来处理持久性落后者问题。

**方法:** 在持续落后者延迟期间，StragglAR在剩余GPU上执行ReduceScatter操作，并在落后者到达同步屏障后采用新的集合算法完成AllReduce操作。

**结果:** 理论上，StragglAR在大型GPU集群中比流行的带宽高效AllReduce算法（如环形算法）快2倍；在8-GPU服务器上实现了比最先进的AllReduce算法高出22%的加速。

**结论:** StragglAR为解决分布式机器学习中的持久落后者问题提供了一种有效方法，在理论和实际测试中均展现出显著的性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+AllReduce+with+a+Persistent+Straggler，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23523，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23523&send_immediately=true&force_search=false)

**原文摘要:** Distributed machine learning workloads use data and tensor parallelism for
training and inference, both of which rely on the AllReduce collective to
synchronize gradients or activations. However, bulk-synchronous AllReduce
algorithms can be delayed by a persistent straggler that is slower to reach the
synchronization barrier required to begin the collective. To address this
challenge, we propose StragglAR: an AllReduce algorithm that accelerates
distributed training and inference in the presence of persistent stragglers.
StragglAR implements a ReduceScatter among the remaining GPUs during the
straggler-induced delay, and then executes a novel collective algorithm to
complete the AllReduce once the straggler reaches the synchronization barrier.
StragglAR achieves a 2x theoretical speedup over popular bandwidth-efficient
AllReduce algorithms (e.g., Ring) for large GPU clusters with persistent
stragglers. On an 8-GPU server, our implementation of StragglAR yields a 22%
speedup over state-of-the-art AllReduce algorithms.

</details>


### [127] [Normalizing Flows are Capable Models for RL](https://arxiv.org/abs/2505.23527)
*Raj Ghugare, Benjamin Eysenbach*

**主要类别:** cs.LG

**AI概要:** 该论文探讨了归一化流在强化学习中的应用，并提出了一个可以无缝集成到强化学习算法中的单一归一化流架构，这种方法提供了更简单的算法和更高的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现代强化学习算法通过使用强大的概率模型取得了成功，但这些模型存在计算复杂度高或需要学习离散表示的问题。归一化流似乎是一个有吸引力的替代方案，但其在强化学习中的潜力尚未得到充分关注。

**方法:** 基于最近的归一化流研究，提出了一种可以无缝集成到RL算法中的单一归一化流架构。

**结果:** 所提出的方法在模仿学习、离线学习、目标条件强化学习和无监督强化学习中实现了更高的性能。

**结论:** 研究表明，归一化流在强化学习中具有很大的潜力，并且能够提供更简单的算法和更高的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Normalizing+Flows+are+Capable+Models+for+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23527&send_immediately=true&force_search=false)

**原文摘要:** Modern reinforcement learning (RL) algorithms have found success by using
powerful probabilistic models, such as transformers, energy-based models, and
diffusion/flow-based models. To this end, RL researchers often choose to pay
the price of accommodating these models into their algorithms -- diffusion
models are expressive, but are computationally intensive due to their reliance
on solving differential equations, while autoregressive transformer models are
scalable but typically require learning discrete representations. Normalizing
flows (NFs), by contrast, seem to provide an appealing alternative, as they
enable likelihoods and sampling without solving differential equations or
autoregressive architectures. However, their potential in RL has received
limited attention, partly due to the prevailing belief that normalizing flows
lack sufficient expressivity. We show that this is not the case. Building on
recent work in NFs, we propose a single NF architecture which integrates
seamlessly into RL algorithms, serving as a policy, Q-function, and occupancy
measure. Our approach leads to much simpler algorithms, and achieves higher
performance in imitation learning, offline, goal conditioned RL and
unsupervised RL.

</details>


### [128] [Comparative assessment of fairness definitions and bias mitigation strategies in machine learning-based diagnosis of Alzheimer's disease from MR images](https://arxiv.org/abs/2505.23528)
*Maria Eleftheria Vlontzou, Maria Athanasiou, Christos Davatzikos, Konstantina S. Nikita*

**主要类别:** cs.LG

**AI概要:** 该论文研究了机器学习模型在诊断轻度认知障碍和阿尔茨海默病时的公平性，探讨了年龄、种族和性别偏差以及缓解策略的效果，并提出了一个新的综合度量来衡量公平性与性能的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是全面分析机器学习模型在从MRI衍生的神经影像特征诊断轻度认知障碍（MCI）和阿尔茨海默病（AD）时的公平性，调查与年龄、种族和性别相关的偏差及其代理特征的影响。

**方法:** 论文采用了预处理、处理中和后处理偏差缓解策略的比较分析，并引入了一个新的综合度量来量化公平性和性能之间的权衡。

**结果:** 结果表明存在与年龄和种族相关的偏差，而没有观察到显著的性别偏差。缓解策略在不同的敏感属性和研究子问题上产生了不同程度的公平性改进。

**结论:** 论文得出了一些关于偏差缓解策略在年龄、种族和性别属性上不同效果的结论，并揭示了与人口统计特征相关的AD神经病理学和风险因素的变化如何影响模型公平性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+assessment+of+fairness+definitions+and+bias+mitigation+strategies+in+machine+learning-based+diagnosis+of+Alzheimer%27s+disease+from+MR+images，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23528，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23528&send_immediately=true&force_search=false)

**原文摘要:** The present study performs a comprehensive fairness analysis of machine
learning (ML) models for the diagnosis of Mild Cognitive Impairment (MCI) and
Alzheimer's disease (AD) from MRI-derived neuroimaging features. Biases
associated with age, race, and gender in a multi-cohort dataset, as well as the
influence of proxy features encoding these sensitive attributes, are
investigated. The reliability of various fairness definitions and metrics in
the identification of such biases is also assessed. Based on the most
appropriate fairness measures, a comparative analysis of widely used
pre-processing, in-processing, and post-processing bias mitigation strategies
is performed. Moreover, a novel composite measure is introduced to quantify the
trade-off between fairness and performance by considering the F1-score and the
equalized odds ratio, making it appropriate for medical diagnostic
applications. The obtained results reveal the existence of biases related to
age and race, while no significant gender bias is observed. The deployed
mitigation strategies yield varying improvements in terms of fairness across
the different sensitive attributes and studied subproblems. For race and
gender, Reject Option Classification improves equalized odds by 46% and 57%,
respectively, and achieves harmonic mean scores of 0.75 and 0.80 in the MCI
versus AD subproblem, whereas for age, in the same subproblem, adversarial
debiasing yields the highest equalized odds improvement of 40% with a harmonic
mean score of 0.69. Insights are provided into how variations in AD
neuropathology and risk factors, associated with demographic characteristics,
influence model fairness.

</details>


### [129] [Domain-Aware Tensor Network Structure Search](https://arxiv.org/abs/2505.23537)
*Giorgos Iacovides, Wuyang Zhou, Chao Li, Qibin Zhao, Danilo Mandic*

**主要类别:** cs.LG

**AI概要:** 本文提出tnLLM框架，结合大语言模型和领域信息，高效解决张量网络结构搜索问题。


<details>
  <summary>更多</summary>
  
**动机:** 寻找最佳张量网络结构（TN-SS）是具有挑战性的，当前最先进的算法计算成本高、忽略领域信息且缺乏透明度。

**方法:** 提出了一种新的TN-SS框架tnLLM，该框架通过一种领域感知提示管道指导大型语言模型推断合适的张量网络结构。

**结果:** 实验结果表明，tnLLM在目标函数值上取得了与最先进算法相当的结果，但所需的函数评估次数要少得多；此外，还能加速基于采样的方法的收敛速度并保持理论性能保证。

**结论:** tnLLM利用大语言模型结合领域信息，不仅优化了目标函数，还生成了对识别结构的领域感知解释。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Domain-Aware+Tensor+Network+Structure+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23537，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23537&send_immediately=true&force_search=false)

**原文摘要:** Tensor networks (TNs) provide efficient representations of high-dimensional
data, yet identification of the optimal TN structures, the so called tensor
network structure search (TN-SS) problem, remains a challenge. Current
state-of-the-art (SOTA) algorithms are computationally expensive as they
require extensive function evaluations, which is prohibitive for real-world
applications. In addition, existing methods ignore valuable domain information
inherent in real-world tensor data and lack transparency in their identified TN
structures. To this end, we propose a novel TN-SS framework, termed the tnLLM,
which incorporates domain information about the data and harnesses the
reasoning capabilities of large language models (LLMs) to directly predict
suitable TN structures. The proposed framework involves a domain-aware
prompting pipeline which instructs the LLM to infer suitable TN structures
based on the real-world relationships between tensor modes. In this way, our
approach is capable of not only iteratively optimizing the objective function,
but also generating domain-aware explanations for the identified structures.
Experimental results demonstrate that tnLLM achieves comparable TN-SS objective
function values with much fewer function evaluations compared to SOTA
algorithms. Furthermore, we demonstrate that the LLM-enabled domain information
can be used to find good initializations in the search space for sampling-based
SOTA methods to accelerate their convergence while preserving theoretical
performance guarantees.

</details>


### [130] [Comparing the Moore-Penrose Pseudoinverse and Gradient Descent for Solving Linear Regression Problems: A Performance Analysis](https://arxiv.org/abs/2505.23552)
*Alex Adams*

**主要类别:** cs.LG

**AI概要:** 这篇论文比较了线性回归中Moore-Penrose伪逆和梯度下降两种方法的性能，提供了在不同条件下选择最佳方法的实际指导。


<details>
  <summary>更多</summary>
  
**动机:** 线性回归是预测建模的基础，求解器的选择会显著影响效率和准确性。了解不同方法的优势可以帮助研究人员和实践者做出更好的决策。

**方法:** 论文回顾并讨论了两种方法的理论基础，分析了它们的计算复杂性，并在具有控制特征的合成数据集以及成熟的真实世界数据集上评估了它们的实证行为。

**结果:** 研究结果显示了在何种条件下每种方法表现出色，包括计算时间、数值稳定性和预测准确性方面的表现。

**结论:** 这篇论文的结论是，封闭形式的Moore-Penrose伪逆方法和迭代梯度下降方法在计算时间、数值稳定性和预测准确性方面各有优势。选择合适的方法取决于特定条件，研究旨在为机器学习研究人员和实践者提供实际指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparing+the+Moore-Penrose+Pseudoinverse+and+Gradient+Descent+for+Solving+Linear+Regression+Problems%3A+A+Performance+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23552，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23552&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the comparative performance of two fundamental
approaches to solving linear regression problems: the closed-form Moore-Penrose
pseudoinverse and the iterative gradient descent method. Linear regression is a
cornerstone of predictive modeling, and the choice of solver can significantly
impact efficiency and accuracy. I review and discuss the theoretical
underpinnings of both methods, analyze their computational complexity, and
evaluate their empirical behavior on synthetic datasets with controlled
characteristics, as well as on established real-world datasets. My results
delineate the conditions under which each method excels in terms of
computational time, numerical stability, and predictive accuracy. This work
aims to provide practical guidance for researchers and practitioners in machine
learning when selecting between direct, exact solutions and iterative,
approximate solutions for linear regression tasks.

</details>


### [131] [Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling](https://arxiv.org/abs/2505.23555)
*Yanzhao Hou, Jiaxiang Geng, Boyu Li, Xiaofeng Tao, Juncheng Wang, Xiaodong Xu, Bing Luo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种高效的联邦学习微调策略，通过理论分析和优化算法减少大语言模型在分布式设备上的训练时间。


<details>
  <summary>更多</summary>
  
**动机:** 现有联邦LoRA方法往往忽略了系统和数据异质性的理论与实际影响，未能优化整体训练效率，特别是在时钟时间方面。

**方法:** 推导了新的收敛边界，并引入了自适应带宽分配方案以考虑客户端资源和系统带宽约束，进而构建并求解一个非凸优化问题来确定LoRA草图比例和采样概率。

**结果:** 实验表明，与现有最先进方法相比，该方法显著减少了训练所需的时钟时间。

**结论:** 论文提出了一种自适应联邦LoRA策略，能够有效减少在计算和通信异构环境下的联邦微调的时钟时间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Federated+LoRA+in+Heterogeneous+Wireless+Networks+with+Independent+Sampling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23555，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23555&send_immediately=true&force_search=false)

**原文摘要:** Federated LoRA has emerged as a promising technique for efficiently
fine-tuning large language models (LLMs) on distributed devices by reducing the
number of trainable parameters. However, existing approaches often inadequately
overlook the theoretical and practical implications of system and data
heterogeneity, thereby failing to optimize the overall training efficiency,
particularly in terms of wall-clock time. In this paper, we propose an adaptive
federated LoRA strategy with independent client sampling to minimize the
convergence wall-clock time of federated fine-tuning under both computation and
communication heterogeneity. We first derive a new convergence bound for
federated LoRA with arbitrary and independent client sampling, notably without
requiring the stringent bounded gradient assumption. Then, we introduce an
adaptive bandwidth allocation scheme that accounts for heterogeneous client
resources and system bandwidth constraints. Based on the derived theory, we
formulate and solve a non-convex optimization problem to jointly determine the
LoRA sketching ratios and sampling probabilities, aiming to minimize wall-clock
convergence time. An efficient and low-complexity algorithm is developed to
approximate the solution. Finally, extensive experiments demonstrate that our
approach significantly reduces wall-clock training time compared to
state-of-the-art methods across various models and datasets.

</details>


### [132] [DRO: A Python Library for Distributionally Robust Optimization in Machine Learning](https://arxiv.org/abs/2505.23565)
*Jiashuo Liu, Tianyu Wang, Henry Lam, Hongseok Namkoong, Jose Blanchet*

**主要类别:** cs.LG

**AI概要:** 本文介绍了dro，一个高效的Python库，用于解决分布鲁棒优化问题，支持多种模型和方法，并显著提高了计算性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了提供一个开源的Python库，支持多种DRO方法，并提高计算效率。

**方法:** 通过向量化和优化近似技术实现高效的DRO方法。

**结果:** 相比基线实现，在大规模数据集上运行时间减少了10倍到1000倍以上。

**结论:** dro是一个高效且兼容性强的DRO库，适用于回归和分类问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DRO%3A+A+Python+Library+for+Distributionally+Robust+Optimization+in+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23565，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23565&send_immediately=true&force_search=false)

**原文摘要:** We introduce dro, an open-source Python library for distributionally robust
optimization (DRO) for regression and classification problems. The library
implements 14 DRO formulations and 9 backbone models, enabling 79 distinct DRO
methods. Furthermore, dro is compatible with both scikit-learn and PyTorch.
Through vectorization and optimization approximation techniques, dro reduces
runtime by 10x to over 1000x compared to baseline implementations on
large-scale datasets. Comprehensive documentation is available at
https://python-dro.org.

</details>


### [133] [Maximum Likelihood Learning of Latent Dynamics Without Reconstruction](https://arxiv.org/abs/2505.23569)
*Samo Hromadka, Kai Biegun, Lior Fox, James Heald, Maneesh Sahani*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为RP-GSSM的新颖无监督学习模型，用于处理具有潜在动态结构的时间序列数据，并展示了其在多种任务上的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决现有对比方法和生成方法中存在的问题，例如缺乏明确的概率模型或需要复杂的显式映射网络，作者提出了RP-GSSM以更好地捕捉时间序列数据中的潜在动态结构。

**方法:** 论文提出了一种新的基于高斯状态空间的无监督学习方法RP-GSSM，结合了对比方法的直觉和概率生成模型的灵活性，通过最大似然进行学习。

**结果:** 实验表明，RP-GSSM在从视频中学习非线性随机动力学方面优于其他替代方法，无论是否存在背景干扰因素。

**结论:** RP-GSSM是一种有用的下游应用基础模型，它能够在没有临时正则化、辅助损失或优化器调度的情况下学习任务相关的潜在变量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Maximum+Likelihood+Learning+of+Latent+Dynamics+Without+Reconstruction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23569，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23569&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel unsupervised learning method for time series data with
latent dynamical structure: the recognition-parametrized Gaussian state space
model (RP-GSSM). The RP-GSSM is a probabilistic model that learns Markovian
Gaussian latents explaining statistical dependence between observations at
different time steps, combining the intuition of contrastive methods with the
flexible tools of probabilistic generative models. Unlike contrastive
approaches, the RP-GSSM is a valid probabilistic model learned via maximum
likelihood. Unlike generative approaches, the RP-GSSM has no need for an
explicit network mapping from latents to observations, allowing it to focus
model capacity on inference of latents. The model is both tractable and
expressive: it admits exact inference thanks to its jointly Gaussian latent
prior, while maintaining expressivity with an arbitrarily nonlinear neural
network link between observations and latents. These qualities allow the
RP-GSSM to learn task-relevant latents without ad-hoc regularization, auxiliary
losses, or optimizer scheduling. We show how this approach outperforms
alternatives on problems that include learning nonlinear stochastic dynamics
from video, with or without background distractors. Our results position the
RP-GSSM as a useful foundation model for a variety of downstream applications.

</details>


### [134] [BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model](https://arxiv.org/abs/2505.23579)
*Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris J. Maddison, Bo Wang*

**主要类别:** cs.LG

**AI概要:** BioReason是一种新型AI架构，结合DNA基础模型和大语言模型，实现对基因组数据的高效、可解释的多步骤推理，从而推动生物学研究中的AI应用。


<details>
  <summary>更多</summary>
  
**动机:** 当前DNA基础模型在处理复杂生物推理任务时存在局限，缺乏透明且直观的生物学解释机制。

**方法:** 引入了BioReason架构，结合DNA基础模型和大型语言模型（LLM），并通过监督微调和目标强化学习开发其多步骤推理能力。

**结果:** 在包括KEGG疾病通路预测在内的生物推理基准测试中，准确率从88%提升至97%，并展示了比单模态基线平均高15%的性能增益。

**结论:** BioReason通过将DNA基础模型与大语言模型相结合，显著提升了对基因组数据的多步骤推理能力和生物学解释性，为生物学中的AI应用提供了新的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioReason%3A+Incentivizing+Multimodal+Biological+Reasoning+within+a+DNA-LLM+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23579&send_immediately=true&force_search=false)

**原文摘要:** Unlocking deep, interpretable biological reasoning from complex genomic data
is a major AI challenge hindering scientific discovery. Current DNA foundation
models, despite strong sequence representation, struggle with multi-step
reasoning and lack inherent transparent, biologically intuitive explanations.
We introduce BioReason, a pioneering architecture that, for the first time,
deeply integrates a DNA foundation model with a Large Language Model (LLM).
This novel connection enables the LLM to directly process and reason with
genomic information as a fundamental input, fostering a new form of multimodal
biological understanding. BioReason's sophisticated multi-step reasoning is
developed through supervised fine-tuning and targeted reinforcement learning,
guiding the system to generate logical, biologically coherent deductions. On
biological reasoning benchmarks including KEGG-based disease pathway prediction
- where accuracy improves from 88% to 97% - and variant effect prediction,
BioReason demonstrates an average 15% performance gain over strong
single-modality baselines. BioReason reasons over unseen biological entities
and articulates decision-making through interpretable, step-by-step biological
traces, offering a transformative approach for AI in biology that enables
deeper mechanistic insights and accelerates testable hypothesis generation from
genomic data. Data, code, and checkpoints are publicly available at
https://github.com/bowang-lab/BioReason

</details>


### [135] [Improving Time Series Forecasting via Instance-aware Post-hoc Revision](https://arxiv.org/abs/2505.23583)
*Zhiding Liu, Mingyue Cheng, Guanhao Zhao, Jiqian Yang, Qi Liu, Enhong Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为PIR的模型无关框架，用于改进时间序列预测，特别是在实例级别上的预测。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有的方法在整体性能上表现出色，但在实例级别上的变化仍然是一个重要的挑战。

**方法:** 通过估计预测准确性来识别有偏差的预测实例，并利用上下文信息对预测结果进行修订。

**结果:** 实验表明，PIR能有效减少实例级别的错误并显著提高预测的可靠性。

**结论:** PIR是一个有效的模型无关框架，能够提升时间序列预测的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Time+Series+Forecasting+via+Instance-aware+Post-hoc+Revision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23583&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting plays a vital role in various real-world applications
and has attracted significant attention in recent decades. While recent methods
have achieved remarkable accuracy by incorporating advanced inductive biases
and training strategies, we observe that instance-level variations remain a
significant challenge. These variations--stemming from distribution shifts,
missing data, and long-tail patterns--often lead to suboptimal forecasts for
specific instances, even when overall performance appears strong. To address
this issue, we propose a model-agnostic framework, PIR, designed to enhance
forecasting performance through Post-forecasting Identification and Revision.
Specifically, PIR first identifies biased forecasting instances by estimating
their accuracy. Based on this, the framework revises the forecasts using
contextual information, including covariates and historical time series, from
both local and global perspectives in a post-processing fashion. Extensive
experiments on real-world datasets with mainstream forecasting models
demonstrate that PIR effectively mitigates instance-level errors and
significantly improves forecasting reliability.

</details>


### [136] [On-Policy RL with Optimal Reward Baseline](https://arxiv.org/abs/2505.23585)
*Yaru Hao, Li Dong, Xun Wu, Shaohan Huang, Zewen Chi, Furu Wei*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一种名为OPO的新强化学习算法，通过精确的on-policy训练和最优奖励基线来解决训练不稳定和计算效率问题，实验表明其在大型语言模型对齐和推理任务中具有优异表现。


<details>
  <summary>更多</summary>
  
**动机:** 当前的强化学习算法在对齐大型语言模型时存在训练不稳定和计算效率低的问题。

**方法:** 提出了基于最优奖励基线的On-Policy RL（OPO）算法，强调精确的on-policy训练，并引入了理论上最小化梯度方差的最优奖励基线。

**结果:** OPO在数学推理基准测试中表现出优越的性能和训练稳定性，同时实现了更低的策略转移和更高的输出熵。

**结论:** OPO是一种有前景的强化学习方法，适用于大型语言模型的对齐和推理任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On-Policy+RL+with+Optimal+Reward+Baseline，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23585，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23585&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning algorithms are fundamental to align large language
models with human preferences and to enhance their reasoning capabilities.
However, current reinforcement learning algorithms often suffer from training
instability due to loose on-policy constraints and computational inefficiency
due to auxiliary models. In this work, we propose On-Policy RL with Optimal
reward baseline (OPO), a novel and simplified reinforcement learning algorithm
designed to address these challenges. OPO emphasizes the importance of exact
on-policy training, which empirically stabilizes the training process and
enhances exploration. Moreover, OPO introduces the optimal reward baseline that
theoretically minimizes gradient variance. We evaluate OPO on mathematical
reasoning benchmarks. The results demonstrate its superior performance and
training stability without additional models or regularization terms.
Furthermore, OPO achieves lower policy shifts and higher output entropy,
encouraging more diverse and less repetitive responses. These results highlight
OPO as a promising direction for stable and effective reinforcement learning in
large language model alignment and reasoning tasks. The implementation is
provided at https://github.com/microsoft/LMOps/tree/main/opo.

</details>


### [137] [Accelerated Training of Federated Learning via Second-Order Methods](https://arxiv.org/abs/2505.23588)
*Mrinmay Sen, Sidhant R Nair, C Krishna Mohan*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了如何通过二阶优化方法加速联邦学习的训练过程，探讨了现有方法的性能差异，并指出了实现高效联邦优化的未来方向。


<details>
  <summary>更多</summary>
  
**动机:** 解决联邦学习中由于客户端数据异构性导致的训练缓慢问题，以及由此带来的过多通信轮次和通信成本。

**方法:** 对现有的二阶联邦学习方法进行了全面分类，并基于收敛速度、计算成本、内存使用、传输开销和全局模型的泛化能力进行性能比较。

**结果:** 研究表明，通过二阶优化引入Hessian曲率具有提升联邦学习训练效率的潜力，同时揭示了其在实际应用中的关键挑战。

**结论:** 本文总结了利用二阶优化加速联邦学习训练过程的潜力，并指出了在联邦学习中有效利用Hessian及其逆矩阵的关键挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerated+Training+of+Federated+Learning+via+Second-Order+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23588，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23588&send_immediately=true&force_search=false)

**原文摘要:** This paper explores second-order optimization methods in Federated Learning
(FL), addressing the critical challenges of slow convergence and the excessive
communication rounds required to achieve optimal performance from the global
model. While existing surveys in FL primarily focus on challenges related to
statistical and device label heterogeneity, as well as privacy and security
concerns in first-order FL methods, less attention has been given to the issue
of slow model training. This slow training often leads to the need for
excessive communication rounds or increased communication costs, particularly
when data across clients are highly heterogeneous. In this paper, we examine
various FL methods that leverage second-order optimization to accelerate the
training process. We provide a comprehensive categorization of state-of-the-art
second-order FL methods and compare their performance based on convergence
speed, computational cost, memory usage, transmission overhead, and
generalization of the global model. Our findings show the potential of
incorporating Hessian curvature through second-order optimization into FL and
highlight key challenges, such as the efficient utilization of Hessian and its
inverse in FL. This work lays the groundwork for future research aimed at
developing scalable and efficient federated optimization methods for improving
the training of the global model in FL.

</details>


### [138] [Position: Federated Foundation Language Model Post-Training Should Focus on Open-Source Models](https://arxiv.org/abs/2505.23593)
*Nikita Agrawal, Simon Mertel, Ruben Mayer*

**主要类别:** cs.LG

**AI概要:** 本文探讨了在联邦后训练中使用黑盒模型的问题，并强调了开放性在联邦学习中的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管黑盒模型在集中式后训练中取得成功，但其在联邦学习中的应用却存在问题，特别是在数据隐私和自主性方面。

**方法:** 批判性分析黑盒模型在联邦后训练中的使用，并详细讨论开放性的各个方面及其对联邦学习的影响。

**结果:** 研究指出黑盒模型在联邦学习中的局限性，并强调了开放性的重要性。

**结论:** 使用黑盒模型与联邦学习的核心原则相悖，开放性在联邦后训练中具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Position%3A+Federated+Foundation+Language+Model+Post-Training+Should+Focus+on+Open-Source+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23593，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23593&send_immediately=true&force_search=false)

**原文摘要:** Post-training of foundation language models has emerged as a promising
research domain in federated learning (FL) with the goal to enable
privacy-preserving model improvements and adaptations to user's downstream
tasks. Recent advances in this area adopt centralized post-training approaches
that build upon black-box foundation language models where there is no access
to model weights and architecture details. Although the use of black-box models
has been successful in centralized post-training, their blind replication in FL
raises several concerns. Our position is that using black-box models in FL
contradicts the core principles of federation such as data privacy and
autonomy. In this position paper, we critically analyze the usage of black-box
models in federated post-training, and provide a detailed account of various
aspects of openness and their implications for FL.

</details>


### [139] [LLM Performance for Code Generation on Noisy Tasks](https://arxiv.org/abs/2505.23598)
*Radzim Sendyka, Christian Cabrera, Andrei Paleyes, Diana Robinson, Neil Lawrence*

**主要类别:** cs.LG

**AI概要:** 本研究发现大型语言模型能够在任务被严重模糊化的情况下解决问题，但这种能力可能源于对训练数据的记忆而非真实推理。研究强调了基准测试设计需谨慎，并提出了通过模糊化测试性能下降来检测数据污染的方法。


<details>
  <summary>更多</summary>
  
**动机:** 论文旨在探讨当任务被严重模糊化时，大型语言模型是否能够识别并解决这些任务，以及这种行为是否反映了模型的真实推理能力还是对训练数据的记忆效应。同时，研究还希望揭示潜在的安全风险和可解释性问题。

**方法:** 研究使用了多个大型语言模型，并采用噪声和删除等方法对竞争性编程和基准任务（如LeetCode和MATH）进行模糊化处理，比较模型在模糊化任务中的表现。同时引入“急切模式匹配”概念来描述观察到的行为，并分析了受污染数据集和未见数据集之间性能下降的差异。

**结果:** 实验结果显示，所有被评估的大型语言模型都能解决模糊化到人类无法理解程度的任务，且不依赖关键指令或上下文信息。然而，在模型知识截止日期之后发布的任务中并未观察到这种行为，表明存在显著的过拟合现象。此外，研究发现受污染数据集和未见数据集之间存在明显的性能下降差异。

**结论:** 论文得出结论，大型语言模型在任务被严重模糊化的情况下仍能解决问题，这表明它们对训练数据存在强烈的记忆或过拟合现象，而非真正理解问题进行推理。此外，论文提出通过衡量模糊化下的性能下降来检测数据集污染的可能性，并指出这对评估模型行为和基准测试设计有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM+Performance+for+Code+Generation+on+Noisy+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23598，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23598&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the ability of large language models (LLMs) to
recognise and solve tasks which have been obfuscated beyond recognition.
Focusing on competitive programming and benchmark tasks (LeetCode and MATH), we
compare performance across multiple models and obfuscation methods, such as
noise and redaction. We demonstrate that all evaluated LLMs can solve tasks
obfuscated to a level where the text would be unintelligible to human readers,
and does not contain key pieces of instruction or context. We introduce the
concept of eager pattern matching to describe this behaviour, which is not
observed in tasks published after the models' knowledge cutoff date, indicating
strong memorisation or overfitting to training data, rather than legitimate
reasoning about the presented problem. We report empirical evidence of distinct
performance decay patterns between contaminated and unseen datasets. We discuss
the implications for benchmarking and evaluations of model behaviour, arguing
for caution when designing experiments using standard datasets. We also propose
measuring the decay of performance under obfuscation as a possible strategy for
detecting dataset contamination and highlighting potential safety risks and
interpretability issues for automated software systems.

</details>


### [140] [Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model](https://arxiv.org/abs/2505.23606)
*Qingyu Shi, Jinbin Bai, Zhuoran Zhao, Wenhao Chai, Kaidong Yu, Jianzong Wu, Shuangyong Song, Yunhai Tong, Xiangtai Li, Xuelong Li, Shuicheng Yan*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为Muddit的统一离散扩散Transformer，它能够高效地并行生成文本和图像。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决自回归和非自回归统一生成模型在速度或泛化能力上的不足。

**方法:** 提出Muddit，一个整合了预训练文本到图像骨干网络与轻量级文本解码器的统一离散扩散Transformer。

**结果:** 实验结果表明，Muddit在质量和效率方面达到了与更大的自回归模型相当或更优的表现。

**结论:** Muddit具有高质量和高效的多模态生成能力，展示了离散扩散模型在统一生成任务中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Muddit%3A+Liberating+Generation+Beyond+Text-to-Image+with+a+Unified+Discrete+Diffusion+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23606，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23606&send_immediately=true&force_search=false)

**原文摘要:** Unified generation models aim to handle diverse tasks across modalities --
such as text generation, image generation, and vision-language reasoning --
within a single architecture and decoding paradigm. Autoregressive unified
models suffer from slow inference due to sequential decoding, and
non-autoregressive unified models suffer from weak generalization due to
limited pretrained backbones. We introduce Muddit, a unified discrete diffusion
transformer that enables fast and parallel generation across both text and
image modalities. Unlike prior unified diffusion models trained from scratch,
Muddit integrates strong visual priors from a pretrained text-to-image backbone
with a lightweight text decoder, enabling flexible and high-quality multimodal
generation under a unified architecture. Empirical results show that Muddit
achieves competitive or superior performance compared to significantly larger
autoregressive models in both quality and efficiency. The work highlights the
potential of purely discrete diffusion, when equipped with strong visual
priors, as a scalable and effective backbone for unified generation.

</details>


### [141] [Data Model Design for Explainable Machine Learning-based Electricity Applications](https://arxiv.org/abs/2505.23607)
*Carolina Fortuna, Gregor Cerar, Blaz Bertalanic, Andrej Campa, Mihael Mohorcic*

**主要类别:** cs.LG

**AI概要:** 这篇论文探讨了能源基础设施数字化转型背景下，如何通过结构化数据分类提升机器学习模型在家庭用电预测中的性能，并分析了不同特征的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 随着传统电网向智能电网转变、可再生能源使用增加以及电价上涨，能源基础设施正在进行数字化转型。然而，大多数现有的机器学习模型依赖于单变量数据，缺乏对元数据和其他测量数据的系统研究。

**方法:** 论文提出了一种能源应用相关的数据分类方法，并通过家庭用电预测应用验证了该分类法的有效性。此外，还使用特征重要性技术解释了各个特征对预测精度的贡献。

**结果:** 论文提出了一个结构化的数据分类体系，用于指导特定应用场景下的机器学习模型训练数据选择，并通过实验证明了其在多种模型和数据集上的有效性。

**结论:** 这篇论文得出的结论是，所提出的能源应用数据分类法能够有效地指导特征选择，并且不同类型的特征对预测精度有显著影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Model+Design+for+Explainable+Machine+Learning-based+Electricity+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23607，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23607&send_immediately=true&force_search=false)

**原文摘要:** The transition from traditional power grids to smart grids, significant
increase in the use of renewable energy sources, and soaring electricity prices
has triggered a digital transformation of the energy infrastructure that
enables new, data driven, applications often supported by machine learning
models. However, the majority of the developed machine learning models rely on
univariate data. To date, a structured study considering the role meta-data and
additional measurements resulting in multivariate data is missing. In this
paper we propose a taxonomy that identifies and structures various types of
data related to energy applications. The taxonomy can be used to guide
application specific data model development for training machine learning
models. Focusing on a household electricity forecasting application, we
validate the effectiveness of the proposed taxonomy in guiding the selection of
the features for various types of models. As such, we study of the effect of
domain, contextual and behavioral features on the forecasting accuracy of four
interpretable machine learning techniques and three openly available datasets.
Finally, using a feature importance techniques, we explain individual feature
contributions to the forecasting accuracy.

</details>


### [142] [The Generalized Skew Spectrum of Graphs](https://arxiv.org/abs/2505.23609)
*Armando Bellante, Martin Plávala, Alessandro Luongo*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种新的、更具表现力的图嵌入方法，能够处理多种复杂的图结构，并在相同计算成本下优于传统的Skew Spectrum方法。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服传统Skew Spectrum方法无法处理具有丰富结构的图（如属性图、多层图和超图）的限制。

**方法:** 基于群论和调和分析，引入了推广的Skew Spectrum方法，并应用保持泛化性的启发式方法提高表现力。

**结果:** 通过实验验证了新方法的表现力提升，并证明了其不变性以及高效计算能力。

**结论:** 本文提出了一种新的图不变量，能够嵌入更丰富的图结构，并且在计算复杂性和表现力之间实现了权衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Generalized+Skew+Spectrum+of+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23609，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23609&send_immediately=true&force_search=false)

**原文摘要:** This paper proposes a family of permutation-invariant graph embeddings,
generalizing the Skew Spectrum of graphs of Kondor & Borgwardt (2008). Grounded
in group theory and harmonic analysis, our method introduces a new class of
graph invariants that are isomorphism-invariant and capable of embedding richer
graph structures - including attributed graphs, multilayer graphs, and
hypergraphs - which the Skew Spectrum could not handle. Our generalization
further defines a family of functions that enables a trade-off between
computational complexity and expressivity. By applying
generalization-preserving heuristics to this family, we improve the Skew
Spectrum's expressivity at the same computational cost. We formally prove the
invariance of our generalization, demonstrate its improved expressiveness
through experiments, and discuss its efficient computation.

</details>


### [143] [Learning Interpretable Differentiable Logic Networks for Tabular Regression](https://arxiv.org/abs/2505.23615)
*Chang Yue, Niraj K. Jha*

**主要类别:** cs.LG

**AI概要:** 本文介绍了对 Differentiable Logic Networks (DLNs) 的扩展，使其适用于监督表格回归任务，并证明其在保持模型透明度和计算效率的同时，能够达到与现有方法相当甚至更好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络在许多领域表现出色，但它们的决策过程往往不透明，并且在资源受限环境中进行推理时可能需要昂贵的计算代价。Differentiable Logic Networks (DLNs) 被提出以解决这些问题，通过将离散逻辑松弛到可微形式，从而实现基于梯度的学习。

**方法:** 重新设计最终输出层以支持连续目标，并将原始的两阶段训练过程统一为单一可微阶段。

**结果:** Regression DLNs 在15个公共回归基准上进行了评估，结果显示其匹配或超过了基线精度，同时保持了可解释性和快速推理能力。

**结论:** DLNs 是一种可行且具有成本效益的回归任务替代方案，特别是在模型透明度和计算效率很重要的领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Interpretable+Differentiable+Logic+Networks+for+Tabular+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23615，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23615&send_immediately=true&force_search=false)

**原文摘要:** Neural networks (NNs) achieve outstanding performance in many domains;
however, their decision processes are often opaque and their inference can be
computationally expensive in resource-constrained environments. We recently
proposed Differentiable Logic Networks (DLNs) to address these issues for
tabular classification based on relaxing discrete logic into a differentiable
form, thereby enabling gradient-based learning of networks built from binary
logic operations. DLNs offer interpretable reasoning and substantially lower
inference cost.
  We extend the DLN framework to supervised tabular regression. Specifically,
we redesign the final output layer to support continuous targets and unify the
original two-phase training procedure into a single differentiable stage. We
evaluate the resulting model on 15 public regression benchmarks, comparing it
with modern neural networks and classical regression baselines. Regression DLNs
match or exceed baseline accuracy while preserving interpretability and fast
inference. Our results show that DLNs are a viable, cost-effective alternative
for regression tasks, especially where model transparency and computational
efficiency are important.

</details>


### [144] [Prompting Whisper for Improved Verbatim Transcription and End-to-end Miscue Detection](https://arxiv.org/abs/2505.23627)
*Griffin Dietz Smith, Dianna Yee, Jennifer King Chen, Leah Findlater*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的端到端架构，通过提示结合目标阅读文本，提高了逐字转录和直接误读检测的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的事后自动语音识别（ASR）方法在转录不准确时表现不佳，因此需要改进阅读错误标注的方法。

**方法:** 设计了一种端到端的架构，通过提示引入目标阅读文本，并训练模型提高逐字转录和直接误读检测的能力。

**结果:** 在儿童朗读和成人非典型语音两个案例研究中，该方法在逐字转录和误读检测方面优于当前最先进的方法。

**结论:** 通过提示整合阅读文本可以提升逐字转录效果，并证明了扩展语音识别任务以进行端到端误读检测的可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prompting+Whisper+for+Improved+Verbatim+Transcription+and+End-to-end+Miscue+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23627，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23627&send_immediately=true&force_search=false)

**原文摘要:** Identifying mistakes (i.e., miscues) made while reading aloud is commonly
approached post-hoc by comparing automatic speech recognition (ASR)
transcriptions to the target reading text. However, post-hoc methods perform
poorly when ASR inaccurately transcribes verbatim speech. To improve on current
methods for reading error annotation, we propose a novel end-to-end
architecture that incorporates the target reading text via prompting and is
trained for both improved verbatim transcription and direct miscue detection.
Our contributions include: first, demonstrating that incorporating reading text
through prompting benefits verbatim transcription performance over fine-tuning,
and second, showing that it is feasible to augment speech recognition tasks for
end-to-end miscue detection. We conducted two case studies -- children's
read-aloud and adult atypical speech -- and found that our proposed strategies
improve verbatim transcription and miscue detection compared to current
state-of-the-art.

</details>


### [145] [MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment](https://arxiv.org/abs/2505.23634)
*John Halloran*

**主要类别:** cs.LG

**AI概要:** 研究表明，基于模型上下文协议（MCP）的攻击威胁模型比之前认为的更广泛，提出了新的偏好对齐策略RAG-Pref来提升大型语言模型对虚假良性攻击的拒绝能力。


<details>
  <summary>更多</summary>
  
**动机:** 最近的研究表明，MCP容易受到基于检索的“虚假良性”攻击（FBAs），而本文旨在展示MCP-based攻击的威胁模型比以前认为的要广泛得多，并提出改进的防护措施。

**方法:** 引入了一种新的MCP数据集，并探索了直接偏好优化（DPO）在大型语言模型（LLMs）拒绝训练中的有效性；同时提出了一种新的偏好对齐策略Retrieval Augmented Generation for Preference alignment (RAG-Pref)。

**结果:** 虽然DPO提升了模型防护FBAs攻击的能力，但拒绝学习的效果取决于模型原有的后训练对齐方案。RAG-Pref显著提高了LLMs拒绝FBAs的能力，尤其是在与DPO对齐结合使用时。

**结论:** RAG-Pref与DPO结合可以显著提升LLMs拒绝FBAs的能力，从而加强针对基于MCP攻击的防护措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCP+Safety+Training%3A+Learning+to+Refuse+Falsely+Benign+MCP+Exploits+using+Improved+Preference+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23634，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23634&send_immediately=true&force_search=false)

**原文摘要:** The model context protocol (MCP) has been widely adapted as an open standard
enabling the seamless integration of generative AI agents. However, recent work
has shown the MCP is susceptible to retrieval-based "falsely benign" attacks
(FBAs), allowing malicious system access and credential theft, but requiring
that users download compromised files directly to their systems. Herein, we
show that the threat model of MCP-based attacks is significantly broader than
previously thought, i.e., attackers need only post malicious content online to
deceive MCP agents into carrying out their attacks on unsuspecting victims'
systems.
  To improve alignment guardrails against such attacks, we introduce a new MCP
dataset of FBAs and (truly) benign samples to explore the effectiveness of
direct preference optimization (DPO) for the refusal training of large language
models (LLMs). While DPO improves model guardrails against such attacks, we
show that the efficacy of refusal learning varies drastically depending on the
model's original post-training alignment scheme--e.g., GRPO-based LLMs learn to
refuse extremely poorly. Thus, to further improve FBA refusals, we introduce
Retrieval Augmented Generation for Preference alignment (RAG-Pref), a novel
preference alignment strategy based on RAG. We show that RAG-Pref significantly
improves the ability of LLMs to refuse FBAs, particularly when combined with
DPO alignment, thus drastically improving guardrails against MCP-based attacks.

</details>


### [146] [Global optimization of graph acquisition functions for neural architecture search](https://arxiv.org/abs/2505.23640)
*Yilin Xie, Shiqiang Zhang, Jixiang Qing, Ruth Misener, Calvin Tsay*

**主要类别:** cs.LG

**AI概要:** 本文研究了图贝叶斯优化在神经架构搜索中的应用，解决了离散图结构上的获取优化问题，并通过实验验证了方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图贝叶斯优化工作主要关注开发图代理模型，而由于图搜索空间和获取函数的复杂性，获取优化的研究相对不足。

**方法:** 提出了图输入空间的显式优化公式，包括可达性和最短路径等性质，并用其构建图核和获取函数。同时理论上证明了所提编码是图空间的等效表示。

**结果:** 在多个NAS基准数据集上的实验结果表明，该方法能够高效地找到大多数情况下的最优架构，突出了其有效性。

**结论:** 本文提出了一种基于图贝叶斯优化的方法用于神经架构搜索，通过显式优化公式和理论分析证明了该方法在多个基准数据集上能够高效地找到最优架构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Global+optimization+of+graph+acquisition+functions+for+neural+architecture+search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23640，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23640&send_immediately=true&force_search=false)

**原文摘要:** Graph Bayesian optimization (BO) has shown potential as a powerful and
data-efficient tool for neural architecture search (NAS). Most existing graph
BO works focus on developing graph surrogates models, i.e., metrics of networks
and/or different kernels to quantify the similarity between networks. However,
the acquisition optimization, as a discrete optimization task over graph
structures, is not well studied due to the complexity of formulating the graph
search space and acquisition functions. This paper presents explicit
optimization formulations for graph input space including properties such as
reachability and shortest paths, which are used later to formulate graph
kernels and the acquisition function. We theoretically prove that the proposed
encoding is an equivalent representation of the graph space and provide
restrictions for the NAS domain with either node or edge labels. Numerical
results over several NAS benchmarks show that our method efficiently finds the
optimal architecture for most cases, highlighting its efficacy.

</details>


### [147] [Continuous Chain of Thought Enables Parallel Exploration and Reasoning](https://arxiv.org/abs/2505.23648)
*Halil Alperen Gozeten, M. Emrullah Ildiz, Xuechen Zhang, Hrayr Harutyunyan, Ankit Singh Rawat, Samet Oymak*

**主要类别:** cs.LG

**AI概要:** 该论文探讨了连续值令牌思维链（CoT2）在语言模型中的应用，展示了其理论优势和优化方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前语言模型通过从有限词汇表中自回归采样令牌生成思维链，但这种方法存在局限性。研究旨在探索连续值令牌思维链（CoT2）的优势并提出优化方法。

**方法:** 论文提出了CoT2方法，理论分析其在推理效率方面的优势，并引入两种新的采样策略以实现策略优化和自我改进。

**结果:** 实验结果表明，使用CoT2进行策略优化确实能够提升模型性能，超越其初始的离散或连续监督效果。

**结论:** 论文得出结论，通过连续值令牌的思维链（CoT2）提供了一种更丰富的替代方法，并且通过匹配softmax输出与目标轨迹的经验令牌分布，结合采样策略，可以显著提升模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Continuous+Chain+of+Thought+Enables+Parallel+Exploration+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23648，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23648&send_immediately=true&force_search=false)

**原文摘要:** Current language models generate chain-of-thought traces by autoregressively
sampling tokens from a finite vocabulary. While this discrete sampling has
achieved remarkable success, conducting chain-of-thought with
continuously-valued tokens (CoT2) offers a richer and more expressive
alternative. Our work examines the benefits of CoT2 through logical reasoning
tasks that inherently require search capabilities and provide optimization and
exploration methods for CoT2. Theoretically, we show that CoT2 allows the model
to track multiple traces in parallel and quantify its benefits for inference
efficiency. Notably, one layer transformer equipped with CoT2 can provably
solve the combinatorial "subset sum problem" given sufficient embedding
dimension. These insights lead to a novel and effective supervision strategy
where we match the softmax outputs to the empirical token distributions of a
set of target traces. Complementing this, we introduce sampling strategies that
unlock policy optimization and self-improvement for CoT2. Our first strategy
samples and composes $K$ discrete tokens at each decoding step to control the
level of parallelism, and reduces to standard CoT when $K=1$. Our second
strategy relies on continuous exploration over the probability simplex.
Experiments confirm that policy optimization with CoT2 indeed improves the
performance of the model beyond its initial discrete or continuous supervision.

</details>


### [148] [Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation](https://arxiv.org/abs/2505.23651)
*Juncheol Shin, Minsang Seok, Seonggon Kim, Eunhyeok Park*

**主要类别:** cs.LG

**AI概要:** 本论文探讨了量化对模型合并的影响，并提出了适用于多目标领域适应的新量化方法HDRQ。


<details>
  <summary>更多</summary>
  
**动机:** 在实际场景中，量化常用于特定数据，但其限制了感兴趣领域并引入离散化效应，使得模型合并变得非常困难。因此需要研究如何优化量化过程以支持模型合并。

**方法:** 通过误差屏障视角分析量化对模型合并的影响，并提出HDRQ（Hessian and distant regularizing quantization）方法，在后训练量化过程中考虑模型合并需求。

**结果:** HDRQ方法保证量化过程尽可能接近源预训练模型的同时，平滑损失表面以促进模型合并。

**结论:** 该研究是针对多目标领域适应中模型合并与量化问题的首次尝试，提出了HDRQ方法，实验证明其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge-Friendly+Post-Training+Quantization+for+Multi-Target+Domain+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23651，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23651&send_immediately=true&force_search=false)

**原文摘要:** Model merging has emerged as a powerful technique for combining task-specific
weights, achieving superior performance in multi-target domain adaptation.
However, when applied to practical scenarios, such as quantized models, new
challenges arise. In practical scenarios, quantization is often applied to
target-specific data, but this process restricts the domain of interest and
introduces discretization effects, making model merging highly non-trivial. In
this study, we analyze the impact of quantization on model merging through the
lens of error barriers. Leveraging these insights, we propose a novel
post-training quantization, HDRQ - Hessian and distant regularizing
quantization - that is designed to consider model merging for multi-target
domain adaptation. Our approach ensures that the quantization process incurs
minimal deviation from the source pre-trained model while flattening the loss
surface to facilitate smooth model merging. To our knowledge, this is the first
study on this challenge, and extensive experiments confirm its effectiveness.

</details>


### [149] [How does Transformer Learn Implicit Reasoning?](https://arxiv.org/abs/2505.23653)
*Jiaran Ye, Zijun Yao, Zhidian Huang, Liangming Pan, Jinxin Liu, Yushi Bai, Amy Xin, Liu Weichuan, Xiaoyin Che, Lei Hou, Juanzi Li*

**主要类别:** cs.LG

**AI概要:** 本文研究了大型语言模型在受控符号环境中如何隐式进行多跳推理，揭示了其三阶段发展轨迹以及推理能力与隐藏空间中的聚类现象之间的联系。


<details>
  <summary>更多</summary>
  
**动机:** 最近的研究表明，LLMs可以隐式地进行多跳推理，但其底层机制尚不清楚，因此需要研究这种隐式推理是如何产生的。

**方法:** 通过在受控的符号环境中从零开始训练Transformer模型，并引入了两种诊断工具：跨查询语义修补和基于余弦的表示镜头来解释模型行为。

**结果:** 论文发现了三阶段的发展轨迹：早期记忆、随后的分布内泛化和最终的跨分布泛化；训练中使用原子三元组会加速学习，而第二跳泛化依赖于对特定组合结构的查询级暴露。

**结论:** 论文得出结论，大型语言模型（LLMs）可以通过训练从零开始在受控符号环境中进行隐式多跳推理，并发现其发展轨迹和推理机制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+does+Transformer+Learn+Implicit+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23653，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23653&send_immediately=true&force_search=false)

**原文摘要:** Recent work suggests that large language models (LLMs) can perform multi-hop
reasoning implicitly -- producing correct answers without explicitly
verbalizing intermediate steps -- but the underlying mechanisms remain poorly
understood. In this paper, we study how such implicit reasoning emerges by
training transformers from scratch in a controlled symbolic environment. Our
analysis reveals a three-stage developmental trajectory: early memorization,
followed by in-distribution generalization, and eventually cross-distribution
generalization. We find that training with atomic triples is not necessary but
accelerates learning, and that second-hop generalization relies on query-level
exposure to specific compositional structures. To interpret these behaviors, we
introduce two diagnostic tools: cross-query semantic patching, which identifies
semantically reusable intermediate representations, and a cosine-based
representational lens, which reveals that successful reasoning correlates with
the cosine-base clustering in hidden space. This clustering phenomenon in turn
provides a coherent explanation for the behavioral dynamics observed across
training, linking representational structure to reasoning capability. These
findings provide new insights into the interpretability of implicit multi-hop
reasoning in LLMs, helping to clarify how complex reasoning processes unfold
internally and offering pathways to enhance the transparency of such models.

</details>


### [150] [AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction](https://arxiv.org/abs/2505.23663)
*Niklas Freymuth, Tobias Würth, Nicolas Schreiber, Balazs Gyenes, Andreas Boltres, Johannes Mitsch, Aleksandar Taranovic, Tai Hoang, Philipp Dahlinger, Philipp Becker, Luise Kärger, Gerhard Neumann*

**主要类别:** cs.LG

**AI概要:** 我们提出了一种名为AMBER的监督学习方法来优化有限元方法中的网格自适应，从而减少模拟复杂物理系统的成本并提高准确性。


<details>
  <summary>更多</summary>
  
**动机:** 自适应网格可以提高计算效率，但通常需要特定任务的启发式方法或繁琐的手动设计。我们提出了一种监督学习方法来进行网格自适应。

**方法:** 从粗糙网格开始，AMBER迭代预测尺寸场，并使用此预测使用现成的网格生成器生成新的中间网格。这一过程通过分层图神经网络实现，并在训练期间依赖数据增强。

**结果:** AMBER在2D和3D数据集上进行了评估，包括经典物理问题、机械部件和具有人类专家网格的真实工业设计。

**结论:** AMBER能够推广到未见过的几何形状，并且始终优于多个最新基线，包括使用图和卷积神经网络以及基于强化学习的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AMBER%3A+Adaptive+Mesh+Generation+by+Iterative+Mesh+Resolution+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23663，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23663&send_immediately=true&force_search=false)

**原文摘要:** The cost and accuracy of simulating complex physical systems using the Finite
Element Method (FEM) scales with the resolution of the underlying mesh.
Adaptive meshes improve computational efficiency by refining resolution in
critical regions, but typically require task-specific heuristics or cumbersome
manual design by a human expert. We propose Adaptive Meshing By Expert
Reconstruction (AMBER), a supervised learning approach to mesh adaptation.
Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,
a function mapping from the geometry to the local element size of the target
mesh, and uses this prediction to produce a new intermediate mesh using an
out-of-the-box mesh generator. This process is enabled through a hierarchical
graph neural network, and relies on data augmentation by automatically
projecting expert labels onto AMBER-generated data during training. We evaluate
AMBER on 2D and 3D datasets, including classical physics problems, mechanical
components, and real-world industrial designs with human expert meshes. AMBER
generalizes to unseen geometries and consistently outperforms multiple recent
baselines, including ones using Graph and Convolutional Neural Networks, and
Reinforcement Learning-based approaches.

</details>


### [151] [Bayesian Optimization from Human Feedback: Near-Optimal Regret Bounds](https://arxiv.org/abs/2505.23673)
*Aya Kayal, Sattar Vakili, Laura Toni, Da-shan Shiu, Alberto Bernacchia*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Optimization+from+Human+Feedback%3A+Near-Optimal+Regret+Bounds，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23673，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23673&send_immediately=true&force_search=false)

**原文摘要:** Bayesian optimization (BO) with preference-based feedback has recently
garnered significant attention due to its emerging applications. We refer to
this problem as Bayesian Optimization from Human Feedback (BOHF), which differs
from conventional BO by learning the best actions from a reduced feedback
model, where only the preference between two actions is revealed to the learner
at each time step. The objective is to identify the best action using a limited
number of preference queries, typically obtained through costly human feedback.
Existing work, which adopts the Bradley-Terry-Luce (BTL) feedback model,
provides regret bounds for the performance of several algorithms. In this work,
within the same framework we develop tighter performance guarantees.
Specifically, we derive regret bounds of
$\tilde{\mathcal{O}}(\sqrt{\Gamma(T)T})$, where $\Gamma(T)$ represents the
maximum information gain$\unicode{x2014}$a kernel-specific complexity
term$\unicode{x2014}$and $T$ is the number of queries. Our results
significantly improve upon existing bounds. Notably, for common kernels, we
show that the order-optimal sample complexities of conventional
BO$\unicode{x2014}$achieved with richer feedback models$\unicode{x2014}$are
recovered. In other words, the same number of preferential samples as
scalar-valued samples is sufficient to find a nearly optimal solution.

</details>


### [152] [Understanding Mode Connectivity via Parameter Space Symmetry](https://arxiv.org/abs/2505.23681)
*Bo Zhao, Nima Dehmamy, Robin Walters, Rose Yu*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了神经网络中极小值之间的模式连通性，提出了一种基于参数空间对称性的新方法，揭示了连续对称性在理解损失景观中的作用。


<details>
  <summary>更多</summary>
  
**动机:** 虽然模式连通性已被应用于模型合并和微调，但其理论解释尚不明确，本文试图从对称性的角度对其进行探讨。

**方法:** 利用参数空间对称性探索极小值点之间的连通性，并通过曲率分析推导线性模式连通性的近似条件。

**结果:** 推导出线性网络极小值的连通组件数量，并表明跳过连接会减少该数量；同时提供由对称诱导的极小值之间连接曲线的显式表达式。

**结论:** 论文得出连续对称性在理解神经网络损失景观中的重要性，特别是跳过连接减少线性网络最小值的连通组件数量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Mode+Connectivity+via+Parameter+Space+Symmetry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23681，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23681&send_immediately=true&force_search=false)

**原文摘要:** Neural network minima are often connected by curves along which train and
test loss remain nearly constant, a phenomenon known as mode connectivity.
While this property has enabled applications such as model merging and
fine-tuning, its theoretical explanation remains unclear. We propose a new
approach to exploring the connectedness of minima using parameter space
symmetry. By linking the topology of symmetry groups to that of the minima, we
derive the number of connected components of the minima of linear networks and
show that skip connections reduce this number. We then examine when mode
connectivity and linear mode connectivity hold or fail, using parameter
symmetries which account for a significant part of the minimum. Finally, we
provide explicit expressions for connecting curves in the minima induced by
symmetry. Using the curvature of these curves, we derive conditions under which
linear mode connectivity approximately holds. Our findings highlight the role
of continuous symmetries in understanding the neural network loss landscape.

</details>


### [153] [Learning Compositional Functions with Transformers from Easy-to-Hard Data](https://arxiv.org/abs/2505.23683)
*Zixuan Wang, Eshaan Nichani, Alberto Bietti, Alex Damian, Daniel Hsu, Jason D. Lee, Denny Wu*

**主要类别:** cs.LG

**AI概要:** 本论文探讨了基于Transformer的模型在执行复杂推理任务时的可学习性问题，并指出为了高效学习，需要包含不同难度的训练样本。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是探索基于Transformer的语言模型在多步推理任务中的表达能力以及梯度优化方法在特定数据分布下的可学习性条件。

**方法:** 研究了k倍合成任务的可学习性，并通过统计查询下界证明了学习此类任务的难度。此外，作者展示了通过课程学习策略使用梯度下降可以有效学习函数类。

**结果:** 作者证明了对于仅进行多项式次查询的统计查询学习器来说，k倍合成任务的样本量必须随k呈指数增长。另一方面，他们展示了通过两种不同的课程学习策略，可以在时间和样本复杂度上以k的多项式效率学习该函数类。

**结论:** 论文得出结论，为了使Transformer学习复杂的组合任务，数据分布中需要包含简单和困难的示例。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Compositional+Functions+with+Transformers+from+Easy-to-Hard+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23683，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23683&send_immediately=true&force_search=false)

**原文摘要:** Transformer-based language models have demonstrated impressive capabilities
across a range of complex reasoning tasks. Prior theoretical work exploring the
expressive power of transformers has shown that they can efficiently perform
multi-step reasoning tasks involving parallelizable computations. However, the
learnability of such constructions, particularly the conditions on the data
distribution that enable efficient learning via gradient-based optimization,
remains an open question. Towards answering this question, in this work we
study the learnability of the $k$-fold composition task, which requires
computing an interleaved composition of $k$ input permutations and $k$ hidden
permutations, and can be expressed by a transformer with $O(\log k)$ layers. On
the negative front, we prove a Statistical Query (SQ) lower bound showing that
any SQ learner that makes only polynomially-many queries to an SQ oracle for
the $k$-fold composition task distribution must have sample size exponential in
$k$, thus establishing a statistical-computational gap. On the other hand, we
show that this function class can be efficiently learned, with runtime and
sample complexity polynomial in $k$, by gradient descent on an $O(\log
k)$-depth transformer via two different curriculum learning strategies: one in
which data consists of $k'$-fold composition functions with $k' \le k$
presented in increasing difficulty, and another in which all such data is
presented simultaneously. Our work sheds light on the necessity and sufficiency
of having both easy and hard examples in the data distribution for transformers
to learn complex compositional tasks.

</details>


### [154] [Computational Algebra with Attention: Transformer Oracles for Border Basis Algorithms](https://arxiv.org/abs/2505.23696)
*Hiroshi Kera, Nico Pelleriti, Yuki Ishihara, Max Zimmer, Sebastian Pokutta*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种名为Oracle Border Basis Algorithm的新方法，结合了深度学习技术，在不牺牲正确性的情况下显著提高了传统Border basis算法的计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 传统的多项式方程组求解方法如Gröbner基和Border基存在高计算成本问题，而现有的深度学习方法虽然提高了效率但牺牲了输出的正确性。

**方法:** 设计并训练了一个基于Transformer的Oracle，用于识别并消除计算中昂贵的减少步骤，从而实现对Border basis算法的加速。

**结果:** 该方法在关键计算阶段选择性调用Oracle后，速度提升了高达3.5倍，并且保证了结果的正确性。此外，开发了一种新的采样定理和token化及嵌入方案，使得输入表示更加紧凑且表达能力强。

**结论:** 论文得出结论，Oracle Border Basis Algorithm 是一种有效的深度学习方法，可以加速Border basis计算，同时保持结果的正确性，并且其训练数据生成方法和代数计算的表示方式也具有创新性和实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computational+Algebra+with+Attention%3A+Transformer+Oracles+for+Border+Basis+Algorithms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23696&send_immediately=true&force_search=false)

**原文摘要:** Solving systems of polynomial equations, particularly those with finitely
many solutions, is a crucial challenge across many scientific fields.
Traditional methods like Gr\"obner and Border bases are fundamental but suffer
from high computational costs, which have motivated recent Deep Learning
approaches to improve efficiency, albeit at the expense of output correctness.
In this work, we introduce the Oracle Border Basis Algorithm, the first Deep
Learning approach that accelerates Border basis computation while maintaining
output guarantees. To this end, we design and train a Transformer-based oracle
that identifies and eliminates computationally expensive reduction steps, which
we find to dominate the algorithm's runtime. By selectively invoking this
oracle during critical phases of computation, we achieve substantial speedup
factors of up to 3.5x compared to the base algorithm, without compromising the
correctness of results. To generate the training data, we develop a sampling
method and provide the first sampling theorem for border bases. We construct a
tokenization and embedding scheme tailored to monomial-centered algebraic
computations, resulting in a compact and expressive input representation, which
reduces the number of tokens to encode an $n$-variate polynomial by a factor of
$O(n)$. Our learning approach is data efficient, stable, and a practical
enhancement to traditional computer algebra algorithms and symbolic
computation.

</details>


### [155] [DiCoFlex: Model-agnostic diverse counterfactuals with flexible control](https://arxiv.org/abs/2505.23700)
*Oleksii Furman, Ulvi Movsum-zada, Patryk Marszalek, Maciej Zięba, Marek Śmieja*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了一种新的模型无关的反事实生成框架DiCoFlex，它能够在单次前向传递中生成多个多样化反事实，并支持实时用户驱动的约束定制，从而在有效性、多样性、接近性和约束遵循方面优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的反事实生成方法通常需要持续访问预测模型，涉及计算密集型优化，并且缺乏适应新用户定义约束的灵活性，因此提出了DiCoFlex。

**方法:** DiCoFlex利用仅使用标记数据训练的条件归一化流，在单次前向传递中生成多个多样化的反事实，并允许在推理时进行用户驱动的约束定制。

**结果:** 实验结果表明，DiCoFlex在有效性、多样性、接近性和约束遵循方面优于现有方法。

**结论:** DiCoFlex是一个实用且可扩展的反事实生成解决方案，尤其适用于敏感决策领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DiCoFlex%3A+Model-agnostic+diverse+counterfactuals+with+flexible+control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23700&send_immediately=true&force_search=false)

**原文摘要:** Counterfactual explanations play a pivotal role in explainable artificial
intelligence (XAI) by offering intuitive, human-understandable alternatives
that elucidate machine learning model decisions. Despite their significance,
existing methods for generating counterfactuals often require constant access
to the predictive model, involve computationally intensive optimization for
each instance and lack the flexibility to adapt to new user-defined constraints
without retraining. In this paper, we propose DiCoFlex, a novel model-agnostic,
conditional generative framework that produces multiple diverse counterfactuals
in a single forward pass. Leveraging conditional normalizing flows trained
solely on labeled data, DiCoFlex addresses key limitations by enabling
real-time user-driven customization of constraints such as sparsity and
actionability at inference time. Extensive experiments on standard benchmark
datasets show that DiCoFlex outperforms existing methods in terms of validity,
diversity, proximity, and constraint adherence, making it a practical and
scalable solution for counterfactual generation in sensitive decision-making
domains.

</details>


### [156] [(U)NFV: Supervised and Unsupervised Neural Finite Volume Methods for Solving Hyperbolic PDEs](https://arxiv.org/abs/2505.23702)
*Nathan Lichtlé, Alexi Canesse, Zhe Fu, Hossein Nick Zinat Matin, Maria Laura Delle Monache, Alexandre M. Bayen*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的神经网络架构(U)NFV，用于解决双曲守恒定律问题。


<details>
  <summary>更多</summary>
  
**动机:** 传统的有限体积(FV)方法在处理具有激波和不连续性的物理相关解时存在困难，且精度和灵活性不足。

**方法:** 设计了一个模块化的神经网络结构(NFV)，通过学习扩展时空模板的更新规则来保持守恒结构，并支持监督和无监督训练。

**结果:** (U)NFV在处理一阶守恒定律时误差比Godunov方法低10倍，优于ENO/WENO，接近间断伽辽金方法，同时在交通模型中表现出更高的保真度和可扩展性。

**结论:** (U)NFV克服了传统FV方法的局限性，在复杂场景下提供了更准确、灵活的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%28U%29NFV%3A+Supervised+and+Unsupervised+Neural+Finite+Volume+Methods+for+Solving+Hyperbolic+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23702&send_immediately=true&force_search=false)

**原文摘要:** We introduce (U)NFV, a modular neural network architecture that generalizes
classical finite volume (FV) methods for solving hyperbolic conservation laws.
Hyperbolic partial differential equations (PDEs) are challenging to solve,
particularly conservation laws whose physically relevant solutions contain
shocks and discontinuities. FV methods are widely used for their mathematical
properties: convergence to entropy solutions, flow conservation, or total
variation diminishing, but often lack accuracy and flexibility in complex
settings. Neural Finite Volume addresses these limitations by learning update
rules over extended spatial and temporal stencils while preserving conservation
structure. It supports both supervised training on solution data (NFV) and
unsupervised training via weak-form residual loss (UNFV). Applied to
first-order conservation laws, (U)NFV achieves up to 10x lower error than
Godunov's method, outperforms ENO/WENO, and rivals discontinuous Galerkin
solvers with far less complexity. On traffic modeling problems, both from PDEs
and from experimental highway data, (U)NFV captures nonlinear wave dynamics
with significantly higher fidelity and scalability than traditional FV
approaches.

</details>


### [157] [Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better](https://arxiv.org/abs/2505.23705)
*Danny Driess, Jost Tobias Springenberg, Brian Ichter, Lili Yu, Adrian Li-Bell, Karl Pertsch, Allen Z. Ren, Homer Walke, Quan Vuong, Lucy Xiaoyang Shi, Sergey Levine*

**主要类别:** cs.LG

**AI概要:** 该论文研究了Vision-language-action (VLA)模型中连续控制模块对训练速度和知识迁移的影响，并提出了一种改进技术来减轻这些问题。


<details>
  <summary>更多</summary>
  
**动机:** 强大的VLMs通常有数十亿甚至数百亿参数，导致实时推理困难，并且它们操作离散标记而非机器人控制所需的连续值输出。因此需要研究如何在保持预训练VLM语义知识的同时提高实时控制能力。

**方法:** 论文分析了包含连续扩散或流匹配动作专家的VLAs的情况，并提出了一种在VLA训练期间隔离VLM主干的技术。

**结果:** 论文显示，直接引入连续控制模块（如动作专家）会显著影响训练速度和知识迁移效果，并通过广泛分析不同设计选择的影响提出了改进技术。

**结论:** 论文得出结论，通过一种新的在VLA训练期间隔离VLM主干的技术，可以减轻使用连续扩散或流匹配动作专家对训练速度和知识迁移的负面影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Knowledge+Insulating+Vision-Language-Action+Models%3A+Train+Fast%2C+Run+Fast%2C+Generalize+Better，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23705&send_immediately=true&force_search=false)

**原文摘要:** Vision-language-action (VLA) models provide a powerful approach to training
control policies for physical systems, such as robots, by combining end-to-end
learning with transfer of semantic knowledge from web-scale vision-language
model (VLM) training. However, the constraints of real-time control are often
at odds with the design of VLMs: the most powerful VLMs have tens or hundreds
of billions of parameters, presenting an obstacle to real-time inference, and
operate on discrete tokens rather than the continuous-valued outputs that are
required for controlling robots. To address this challenge, recent VLA models
have used specialized modules for efficient continuous control, such as action
experts or continuous output heads, which typically require adding new
untrained parameters to the pretrained VLM backbone. While these modules
improve real-time and control capabilities, it remains an open question whether
they preserve or degrade the semantic knowledge contained in the pretrained
VLM, and what effect they have on the VLA training dynamics. In this paper, we
study this question in the context of VLAs that include a continuous diffusion
or flow matching action expert, showing that naively including such experts
significantly harms both training speed and knowledge transfer. We provide an
extensive analysis of various design choices, their impact on performance and
knowledge transfer, and propose a technique for insulating the VLM backbone
during VLA training that mitigates this issue. Videos are available at
https://pi.website/research/knowledge_insulation.

</details>


### [158] [TiRex: Zero-Shot Forecasting Across Long and Short Horizons with Enhanced In-Context Learning](https://arxiv.org/abs/2505.23719)
*Andreas Auer, Patrick Podest, Daniel Klotz, Sebastian Böck, Günter Klambauer, Sepp Hochreiter*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为TiRex的新方法，用于零样本时间序列预测，该方法结合了改进的LSTM（称为xLSTM）和一种训练时掩码策略（CPM），从而在多个基准测试中实现了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的零样本预测方法主要依赖于Transformer架构，这些架构在时间序列预测中往往不如LSTM有效。同时，LSTM虽然适合时间序列建模，但缺乏强大的上下文学习能力。因此，提出了TiRex来弥补这一差距。

**方法:** 引入了一种新的零样本时间序列预测方法TiRex，该方法结合了xLSTM和一种训练时掩码策略CPM，以提高状态跟踪能力。

**结果:** TiRex在HuggingFace基准测试GiftEval和Chronos-ZS上实现了最先进的零样本时间序列预测性能，无论是在短期还是长期预测中都显著优于其他大型模型。

**结论:** TiRex通过利用增强的LSTM架构xLSTM，在零样本时间序列预测任务中表现出色，优于包括基于Transformer的更大的模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TiRex%3A+Zero-Shot+Forecasting+Across+Long+and+Short+Horizons+with+Enhanced+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23719，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23719&send_immediately=true&force_search=false)

**原文摘要:** In-context learning, the ability of large language models to perform tasks
using only examples provided in the prompt, has recently been adapted for time
series forecasting. This paradigm enables zero-shot prediction, where past
values serve as context for forecasting future values, making powerful
forecasting tools accessible to non-experts and increasing the performance when
training data are scarce. Most existing zero-shot forecasting approaches rely
on transformer architectures, which, despite their success in language, often
fall short of expectations in time series forecasting, where recurrent models
like LSTMs frequently have the edge. Conversely, while LSTMs are well-suited
for time series modeling due to their state-tracking capabilities, they lack
strong in-context learning abilities. We introduce TiRex that closes this gap
by leveraging xLSTM, an enhanced LSTM with competitive in-context learning
skills. Unlike transformers, state-space models, or parallelizable RNNs such as
RWKV, TiRex retains state-tracking, a critical property for long-horizon
forecasting. To further facilitate its state-tracking ability, we propose a
training-time masking strategy called CPM. TiRex sets a new state of the art in
zero-shot time series forecasting on the HuggingFace benchmarks GiftEval and
Chronos-ZS, outperforming significantly larger models including TabPFN-TS
(Prior Labs), Chronos Bolt (Amazon), TimesFM (Google), and Moirai (Salesforce)
across both short- and long-term forecasts.

</details>


### [159] [DiffER: Categorical Diffusion for Chemical Retrosynthesis](https://arxiv.org/abs/2505.23721)
*Sean Current, Ziqi Chen, Daniel Adu-Ampratwum, Xia Ning, Srinivasan Parthasarathy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为DiffER的新方法，用于改进自动化学逆合成预测，克服现有模型的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自然语言处理模型（尤其是变压器神经网络）在自动化学逆合成方面取得了一定的成功，但其自回归特性限制了它们的能力。

**方法:** 提出了DiffER，一种基于分类扩散的替代无模板逆合成预测方法，并构建了扩散模型集合以提高性能。

**结果:** DiffER在top-1准确率方面达到了最先进的性能，在top-3、top-5和top-10准确率方面也有竞争力的表现。

**结论:** DiffER是一个新的无模板模型类的强大基线，能够学习各种合成技术，并在top-k准确率指标上优于其他无模板方法。通过构建具有新长度预测组件的分类扩散模型集合，该方法能够近似从反应物的后验分布中采样，产生具有强置信度和似然性的结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DiffER%3A+Categorical+Diffusion+for+Chemical+Retrosynthesis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23721，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23721&send_immediately=true&force_search=false)

**原文摘要:** Methods for automatic chemical retrosynthesis have found recent success
through the application of models traditionally built for natural language
processing, primarily through transformer neural networks. These models have
demonstrated significant ability to translate between the SMILES encodings of
chemical products and reactants, but are constrained as a result of their
autoregressive nature. We propose DiffER, an alternative template-free method
for retrosynthesis prediction in the form of categorical diffusion, which
allows the entire output SMILES sequence to be predicted in unison. We
construct an ensemble of diffusion models which achieves state-of-the-art
performance for top-1 accuracy and competitive performance for top-3, top-5,
and top-10 accuracy among template-free methods. We prove that DiffER is a
strong baseline for a new class of template-free model, capable of learning a
variety of synthetic techniques used in laboratory settings and outperforming a
variety of other template-free methods on top-k accuracy metrics. By
constructing an ensemble of categorical diffusion models with a novel length
prediction component with variance, our method is able to approximately sample
from the posterior distribution of reactants, producing results with strong
metrics of confidence and likelihood. Furthermore, our analyses demonstrate
that accurate prediction of the SMILES sequence length is key to further
boosting the performance of categorical diffusion models.

</details>


### [160] [MuLoCo: Muon is a practical inner optimizer for DiLoCo](https://arxiv.org/abs/2505.23725)
*Benjamin Thérien, Xiaolong Huang, Irina Rish, Eugene Belilovsky*

**主要类别:** cs.LG

**AI概要:** 本文提出MuLoCo，利用Muon优化器和误差反馈累加器，在大幅降低通信需求的同时保持了DiLoCo的性能优势。


<details>
  <summary>更多</summary>
  
**动机:** DiLoCo虽然在减少通信频率方面表现良好，但其仍然需要对模型参数进行全规约，因此探索如何进一步减少通信负载是本研究的主要动机。

**方法:** 研究中采用了标准压缩方法（如Top-k稀疏化和量化）来减少DiLoCo的通信开销，并使用AdamW和Muon两种本地优化器进行实验对比。

**结果:** 实验证明，使用Muon优化器配合误差反馈累加器可将通信数据压缩至2位，且性能几乎没有下降，同时与DiLoCo相比，通信需求减少了8倍。

**结论:** 论文得出结论，通过使用Muon作为内部优化器并结合误差反馈累加器，可以显著减少DiLoCo的通信量，同时保持性能几乎不下降。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MuLoCo%3A+Muon+is+a+practical+inner+optimizer+for+DiLoCo，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23725&send_immediately=true&force_search=false)

**原文摘要:** DiLoCo is a powerful framework for training large language models (LLMs)
under networking constraints with advantages for increasing parallelism and
accelerator utilization in data center settings. Despite significantly reducing
communication frequency, however, DiLoCo's communication steps still involve
all-reducing a complete copy of the model's parameters. While existing works
have explored ways to reduce communication in DiLoCo, the role of error
feedback accumulators and the effect of the inner-optimizer on compressibility
remain under-explored. In this work, we investigate the effectiveness of
standard compression methods including Top-k sparsification and quantization
for reducing the communication overhead of DiLoCo when paired with two local
optimizers (AdamW and Muon). Our experiments pre-training decoder-only
transformer language models (LMs) reveal that leveraging Muon as the inner
optimizer for DiLoCo along with an error-feedback accumulator allows to
aggressively compress the communicated delta to 2-bits with next to no
performance degradation. Crucially, MuLoCo (Muon inner optimizer DiLoCo)
significantly outperforms DiLoCo while communicating 8X less and having
identical memory complexity.

</details>


### [161] [EmotionRankCLAP: Bridging Natural Language Speaking Styles and Ordinal Speech Emotion via Rank-N-Contrast](https://arxiv.org/abs/2505.23732)
*Shreeram Suresh Chandra, Lucas Goncalves, Junchen Lu, Carlos Busso, Berrak Sisman*

**主要类别:** cs.LG

**AI概要:** 为了解决传统情感CLAP方法未能捕捉情感有序性和存在较大模态差距的问题，研究提出EmotionRankCLAP，通过结合情感语音和自然语言提示的维度属性以及使用Rank-N-Contrast目标函数，在跨模态检索任务中取得了更好的效果。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于情感的对比语言-音频预训练（CLAP）方法通常无法捕捉情感的有序性，导致模态之间的情感理解不足和较大的模态差距。

**方法:** 引入了EmotionRankCLAP，采用监督对比学习方法，并使用Rank-N-Contrast目标函数来学习valence-arousal空间中样本排名的有序关系。

**结果:** EmotionRankCLAP在跨模态检索任务中表现优于现有方法，有效提升了对跨模态情感有序性的建模能力。

**结论:** EmotionRankCLAP通过利用情感语音的维度属性和自然语言提示，能够更好地建模跨模态的情感序数性，从而在跨模态检索任务中优于现有的情感CLAP方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EmotionRankCLAP%3A+Bridging+Natural+Language+Speaking+Styles+and+Ordinal+Speech+Emotion+via+Rank-N-Contrast，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23732，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23732&send_immediately=true&force_search=false)

**原文摘要:** Current emotion-based contrastive language-audio pretraining (CLAP) methods
typically learn by na\"ively aligning audio samples with corresponding text
prompts. Consequently, this approach fails to capture the ordinal nature of
emotions, hindering inter-emotion understanding and often resulting in a wide
modality gap between the audio and text embeddings due to insufficient
alignment. To handle these drawbacks, we introduce EmotionRankCLAP, a
supervised contrastive learning approach that uses dimensional attributes of
emotional speech and natural language prompts to jointly capture fine-grained
emotion variations and improve cross-modal alignment. Our approach utilizes a
Rank-N-Contrast objective to learn ordered relationships by contrasting samples
based on their rankings in the valence-arousal space. EmotionRankCLAP
outperforms existing emotion-CLAP methods in modeling emotion ordinality across
modalities, measured via a cross-modal retrieval task.

</details>


### [162] [Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?](https://arxiv.org/abs/2505.23749)
*Paul Gölz, Nika Haghtalab, Kunhe Yang*

**主要类别:** cs.LG

**AI概要:** This paper proposes Nash Learning from Human Feedback as an alignment method that minimizes distortion in large language models, achieving better performance than current methods like RLHF and DPO when accounting for diverse user preferences.


<details>
  <summary>更多</summary>
  
**动机:** Current alignment methods like RLHF and DPO assume a single preference model, but real-world settings involve diverse user preferences. There is a need for an alignment method that can satisfy users on average across diverse preferences.

**方法:** The paper introduces the concept of 'distortion' to evaluate alignment methods. Distortion measures the worst-case ratio between the optimal achievable average utility and the average utility of the learned policy. The authors analyze the performance of different alignment methods (Nash Learning, RLHF, DPO) using this distortion metric.

**结果:** Nash Learning achieves minimax optimal distortion of $(\frac{1}{2} + o(1)) \cdot \beta$, while RLHF and DPO suffer higher distortion ($\geq (1 - o(1)) \cdot \beta$ without KL constraint, and $e^{\Omega(\beta)}$ or unbounded with KL constraint).

**结论:** Nash Learning from Human Feedback is robust and optimal in terms of minimax distortion, unlike RLHF and DPO which show higher distortion.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distortion+of+AI+Alignment%3A+Does+Preference+Optimization+Optimize+for+Preferences%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23749，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23749&send_immediately=true&force_search=false)

**原文摘要:** After pre-training, large language models are aligned with human preferences
based on pairwise comparisons. State-of-the-art alignment methods (such as
PPO-based RLHF and DPO) are built on the assumption of aligning with a single
preference model, despite being deployed in settings where users have diverse
preferences. As a result, it is not even clear that these alignment methods
produce models that satisfy users on average -- a minimal requirement for
pluralistic alignment. Drawing on social choice theory and modeling users'
comparisons through individual Bradley-Terry (BT) models, we introduce an
alignment method's distortion: the worst-case ratio between the optimal
achievable average utility, and the average utility of the learned policy.
  The notion of distortion helps draw sharp distinctions between alignment
methods: Nash Learning from Human Feedback achieves the minimax optimal
distortion of $(\frac{1}{2} + o(1)) \cdot \beta$ (for the BT temperature
$\beta$), robustly across utility distributions, distributions of comparison
pairs, and permissible KL divergences from the reference policy. RLHF and DPO,
by contrast, suffer $\geq (1 - o(1)) \cdot \beta$ distortion already without a
KL constraint, and $e^{\Omega(\beta)}$ or even unbounded distortion in the full
setting, depending on how comparison pairs are sampled.

</details>


### [163] [Model Immunization from a Condition Number Perspective](https://arxiv.org/abs/2505.23760)
*Amber Yijia Zheng, Cedar Site Bai, Brian Bullins, Raymond A. Yeh*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个基于Hessian矩阵条件数的模型免疫化分析框架，并设计了相关算法，成功实现了对有害任务的免疫化同时保持模型的实用性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有工作显示了文本到图像模型免疫化的实验证据，但关于何时可以进行免疫化以及免疫化模型的精确定义尚不清楚。

**方法:** 通过Hessian矩阵的条件数构建理论框架，并引入正则化项设计算法以控制条件数。

**结果:** 实验结果表明提出的算法在免疫化线性模型和非线性深度网络方面是有效的。

**结论:** 研究提出了一种基于Hessian矩阵条件数的框架来分析模型免疫化，并设计了一种算法来控制预训练后的条件数，从而实现模型免疫化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model+Immunization+from+a+Condition+Number+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23760，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23760&send_immediately=true&force_search=false)

**原文摘要:** Model immunization aims to pre-train models that are difficult to fine-tune
on harmful tasks while retaining their utility on other non-harmful tasks.
Though prior work has shown empirical evidence for immunizing text-to-image
models, the key understanding of when immunization is possible and a precise
definition of an immunized model remain unclear. In this work, we propose a
framework, based on the condition number of a Hessian matrix, to analyze model
immunization for linear models. Building on this framework, we design an
algorithm with regularization terms to control the resulting condition numbers
after pre-training. Empirical results on linear models and non-linear deep-nets
demonstrate the effectiveness of the proposed algorithm on model immunization.
The code is available at
https://github.com/amberyzheng/model-immunization-cond-num.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [164] [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org/abs/2505.22698)
*Luca Fantin, Marco Antonelli, Margherita Cesetti, Daniele Irto, Bruno Zamengo, Francesco Silvestri*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个基于代理架构的聊天机器人，用于简化公共交通数据集的交互和决策支持，并提供一种评估其性能的新方法。


<details>
  <summary>更多</summary>
  
**动机:** 分析公共交通服务数据集和质量约束文档需要处理大量的数据，对于大多数用户来说使用SQL查询、组织和可视化数据都非常复杂。

**方法:** 使用SQL查询执行、数据可视化和地图创建工具扩展了大型语言模型（LLM）的功能，并通过一个流程生成用于评估聊天机器人性能的数据集。

**结果:** 开发了一个能够支持决策的用户友好型聊天机器人，并通过从数据库中提取实际数据生成了一套用于评估其性能的问题集，从而测试聊天机器人的回答一致性和查询正确性。

**结论:** 该论文提出了一种基于代理架构的聊天机器人，为用户提供了与公共交通数据集交互的友好工具，并解决了生成式AI项目中性能评估数据收集的主要问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Design+and+testing+of+an+agent+chatbot+supporting+decision+making+with+public+transport+data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22698，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22698&send_immediately=true&force_search=false)

**原文摘要:** Assessing the quality of public transportation services requires the analysis
of large quantities of data on the scheduled and actual trips and documents
listing the quality constraints each service needs to meet. Interrogating such
datasets with SQL queries, organizing and visualizing the data can be quite
complex for most users. This paper presents a chatbot offering a user-friendly
tool to interact with these datasets and support decision making. It is based
on an agent architecture, which expands the capabilities of the core Large
Language Model (LLM) by allowing it to interact with a series of tools that can
execute several tasks, like performing SQL queries, plotting data and creating
maps from the coordinates of a trip and its stops. This paper also tackles one
of the main open problems of such Generative AI projects: collecting data to
measure the system's performance. Our chatbot has been extensively tested with
a workflow that asks several questions and stores the generated query, the
retrieved data and the natural language response for each of them. Such
questions are drawn from a set of base examples which are then completed with
actual data from the database. This procedure yields a dataset for the
evaluation of the chatbot's performance, especially the consistency of its
answers and the correctness of the generated queries.

</details>


### [165] [Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields](https://arxiv.org/abs/2505.22753)
*Arseniy Pertzovsky, Roni Stern, Ariel Felner, Roie Zivan*

**主要类别:** cs.AI

**AI概要:** 该研究发现人工势场（APF）虽不适用于多智能体路径寻找（MAPF），但可大幅优化生命周期MAPF（LMAPF）的系统性能.


<details>
  <summary>更多</summary>
  
**动机:** 探索人工势场（APFs）在解决多智能体路径寻找（MAPF）和生命周期MAPF（LMAPF）问题中的应用效果.

**方法:** 将人工势场方法整合到多种MAPF算法中，包括优先级规划、MAPF-LNS2和带有回溯的优先级继承（PIBT）.

**结果:** 实验结果表明，在MAPF中使用APF并不有利，但在LMAPF中却能显著提高系统吞吐量.

**结论:** 使用APF对于MAPF问题没有好处，但对于LMAPF问题，可以带来高达7倍的系统整体吞吐量提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Lifelong+Multi-Agent+Path-finding+by+Using+Artificial+Potential+Fields，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22753，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22753&send_immediately=true&force_search=false)

**原文摘要:** We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent
Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of
agents must move to their goal locations without collisions, whereas in LMAPF,
new goals are generated upon arrival. We propose methods for incorporating APFs
in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and
Priority Inheritance with Backtracking (PIBT). Experimental results show that
using APF is not beneficial for MAPF but yields up to a 7-fold increase in
overall system throughput for LMAPF.

</details>


### [166] [Decomposing Elements of Problem Solving: What "Math" Does RL Teach?](https://arxiv.org/abs/2505.22756)
*Tian Qin, Core Francisco Park, Mujin Kwun, Aaron Walsman, Eran Malach, Nikhil Anand, Hidenori Tanaka, David Alvarez-Melis*

**主要类别:** cs.AI

**AI概要:** 本研究通过分解问题解决过程，探讨了强化学习对大语言模型推理能力的影响，揭示了其优势和关键限制，并提出了可能的突破路径。


<details>
  <summary>更多</summary>
  
**动机:** 准确度量标准不足以揭示模型具体掌握了哪些问题解决技能，因此需要对LLMs的能力进行更细粒度的评估。

**方法:** 研究者提出了将问题解决分解为基本能力的方法：计划、执行和验证，并构建了一个最小的合成解树导航任务来模拟数学问题求解。

**结果:** 实证发现GRPO主要增强了执行技能，在模型已经知道如何解决问题的情况下提高了执行的鲁棒性。同时，RL训练的模型在面对全新问题时遇到了'覆盖墙'的问题。

**结论:** 论文得出结论，强化学习（RL）主要提升了执行的鲁棒性，但在面对全新的问题时存在“覆盖墙”的限制。通过改进探索和推广到新的解决方案路径，有可能克服这一限制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decomposing+Elements+of+Problem+Solving%3A+What+%22Math%22+Does+RL+Teach%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22756，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22756&send_immediately=true&force_search=false)

**原文摘要:** Mathematical reasoning tasks have become prominent benchmarks for assessing
the reasoning capabilities of LLMs, especially with reinforcement learning (RL)
methods such as GRPO showing significant performance gains. However, accuracy
metrics alone do not support fine-grained assessment of capabilities and fail
to reveal which problem-solving skills have been internalized. To better
understand these capabilities, we propose to decompose problem solving into
fundamental capabilities: Plan (mapping questions to sequences of steps),
Execute (correctly performing solution steps), and Verify (identifying the
correctness of a solution). Empirically, we find that GRPO mainly enhances the
execution skill-improving execution robustness on problems the model already
knows how to solve-a phenomenon we call temperature distillation. More
importantly, we show that RL-trained models struggle with fundamentally new
problems, hitting a 'coverage wall' due to insufficient planning skills. To
explore RL's impact more deeply, we construct a minimal, synthetic
solution-tree navigation task as an analogy for mathematical problem-solving.
This controlled setup replicates our empirical findings, confirming RL
primarily boosts execution robustness. Importantly, in this setting, we
identify conditions under which RL can potentially overcome the coverage wall
through improved exploration and generalization to new solution paths. Our
findings provide insights into the role of RL in enhancing LLM reasoning,
expose key limitations, and suggest a path toward overcoming these barriers.
Code is available at https://github.com/cfpark00/RL-Wall.

</details>


### [167] [Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds](https://arxiv.org/abs/2505.22779)
*Mohammad Helal Uddin, Sabur Baidya*

**主要类别:** cs.AI

**AI概要:** 这项研究提出了一个结合智能手机传感器数据和社交媒体互动以评估个人抑郁水平的新方法。


<details>
  <summary>更多</summary>
  
**动机:** 精神障碍尤其是抑郁、焦虑等神经疾病在全球范围内都是一项重大挑战，尤其是在有社交回避倾向的人群中。因此，需要一种不侵犯个人隐私的方式来监控抑郁症。

**方法:** 利用基于CNN的深度学习模型和朴素贝叶斯分类器来准确识别个体的身体活动和情感状态；使用支持向量机（SVM）算法对抑郁严重程度进行分类。

**结果:** 身体活动特征与抑郁症状严重程度之间存在显著相关性；从身体活动中得出的六个特征实现了95%的活动识别准确率；来自Twitter活动的情感分析三个特征达到了95.6%的情感分析准确率；SVM-based算法展示了高达94%的准确性，在分类抑郁严重程度上优于其他模型。

**结论:** 本研究通过结合智能手机传感器数据和社交媒体互动信息，提出了一种有效的抑郁水平评估方法，并且证明了这种方法在长期监测抑郁症方面的实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predicting+Human+Depression+with+Hybrid+Data+Acquisition+utilizing+Physical+Activity+Sensing+and+Social+Media+Feeds，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22779，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22779&send_immediately=true&force_search=false)

**原文摘要:** Mental disorders including depression, anxiety, and other neurological
disorders pose a significant global challenge, particularly among individuals
exhibiting social avoidance tendencies. This study proposes a hybrid approach
by leveraging smartphone sensor data measuring daily physical activities and
analyzing their social media (Twitter) interactions for evaluating an
individual's depression level. Using CNN-based deep learning models and Naive
Bayes classification, we identify human physical activities accurately and also
classify the user sentiments. A total of 33 participants were recruited for
data acquisition, and nine relevant features were extracted from the physical
activities and analyzed with their weekly depression scores, evaluated using
the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six
are derived from physical activities, achieving an activity recognition
accuracy of 95%, while three features stem from sentiment analysis of Twitter
activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several
physical activity features exhibited significant correlations with the severity
of depression symptoms. For classifying the depression severity, a support
vector machine (SVM)-based algorithm is employed that demonstrated a very high
accuracy of 94%, outperforming alternative models, e.g., the multilayer
perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly
effective in the long run for monitoring depression without breaching personal
privacy.

</details>


### [168] [The WHY in Business Processes: Unification of Causal Process Models](https://arxiv.org/abs/2505.22871)
*Yuval David, Fabiana Fournier, Lior Limonad, Inna Skarbovsky*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种统一多个因果过程变体的新方法，解决了现有方法无法捕捉交替因果条件的问题，并通过多个数据集进行了验证。


<details>
  <summary>更多</summary>
  
**动机:** 现有的发现因果过程模型的方法缺乏跨多个变体捕捉交替因果条件的能力，这导致了处理缺失值和表达日志分割中的交替条件的挑战。

**方法:** 该方法正式定义并证明，然后在三个开放和两个专有数据集上进行评估，并作为开源实现发布。

**结果:** 统一模型能够保持原模型的正确性，并明确表示不同模型间的因果流交替。

**结论:** 提出了一种新方法，可以将多个因果过程变体统一为一个一致的模型，同时保留原始因果模型的正确性，并明确表示它们之间的因果流交替。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+WHY+in+Business+Processes%3A+Unification+of+Causal+Process+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22871，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22871&send_immediately=true&force_search=false)

**原文摘要:** Causal reasoning is essential for business process interventions and
improvement, requiring a clear understanding of causal relationships among
activity execution times in an event log. Recent work introduced a method for
discovering causal process models but lacked the ability to capture alternating
causal conditions across multiple variants. This raises the challenges of
handling missing values and expressing the alternating conditions among log
splits when blending traces with varying activities.
  We propose a novel method to unify multiple causal process variants into a
consistent model that preserves the correctness of the original causal models,
while explicitly representing their causal-flow alternations. The method is
formally defined, proved, evaluated on three open and two proprietary datasets,
and released as an open-source implementation.

</details>


### [169] [Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning](https://arxiv.org/abs/2505.22928)
*Massimiliano Pronesti, Michela Lorandi, Paul Flanagan, Oisin Redmon, Anya Belz, Yufang Hou*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种基于定量推理的自动化系统证据综合方法，通过数值推理而非文本推理提高准确性和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 自动化医学综述过程中的瓶颈是提取数字证据并确定特定结果和比较的研究级结论。现有方法依赖于表面文本线索，无法捕捉专家评估背后的数值推理逻辑。

**方法:** 该研究将问题概念化为定量推理问题，并开发了一个由数字数据提取模型和效应估计组件组成的数值推理系统。

**结果:** 在CochraneForest基准测试中，使用强化学习训练的小规模数字提取模型表现最佳，在F1得分上比基于检索的系统提高了21%，并且比超过400B参数的通用LLMs高出9%。

**结论:** 论文得出结论，基于推理的方法在自动化系统证据综合方面具有巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Study-Level+Inference+from+Clinical+Trial+Papers+via+RL-based+Numeric+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22928，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22928&send_immediately=true&force_search=false)

**原文摘要:** Systematic reviews in medicine play a critical role in evidence-based
decision-making by aggregating findings from multiple studies. A central
bottleneck in automating this process is extracting numeric evidence and
determining study-level conclusions for specific outcomes and comparisons.
Prior work has framed this problem as a textual inference task by retrieving
relevant content fragments and inferring conclusions from them. However, such
approaches often rely on shallow textual cues and fail to capture the
underlying numeric reasoning behind expert assessments.
  In this work, we conceptualise the problem as one of quantitative reasoning.
Rather than inferring conclusions from surface text, we extract structured
numerical evidence (e.g., event counts or standard deviations) and apply domain
knowledge informed logic to derive outcome-specific conclusions. We develop a
numeric reasoning system composed of a numeric data extraction model and an
effect estimate component, enabling more accurate and interpretable inference
aligned with the domain expert principles. We train the numeric data extraction
model using different strategies, including supervised fine-tuning (SFT) and
reinforcement learning (RL) with a new value reward model.
  When evaluated on the CochraneForest benchmark, our best-performing approach
-- using RL to train a small-scale number extraction model -- yields up to a
21% absolute improvement in F1 score over retrieval-based systems and
outperforms general-purpose LLMs of over 400B parameters by up to 9%. Our
results demonstrate the promise of reasoning-driven approaches for automating
systematic evidence synthesis.

</details>


### [170] [Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages](https://arxiv.org/abs/2505.22948)
*Michael Sun, Weize Yuan, Gang Liu, Wojciech Matusik, Jie Chen*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的分子生成方法 FMG，该方法利用多模态基础模型来生成可解释的分子语言，并在多个方面优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于图语法的分子生成方法依赖专家注释或不可靠的启发式算法进行语法学习，需要更可靠的方法。

**方法:** 利用多模态基础模型 (MMFMs) 来生成可解释的分子语言，并通过提示学习对齐不同模态的信息。

**结果:** FMG 提高了合成性、多样性和数据效率，并且能够用于自动化分子发现流程。

**结论:** FMG 在分子生成和属性预测中不仅表现出色，还提供了内置的化学可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Foundation+Molecular+Grammar%3A+Multi-Modal+Foundation+Models+Induce+Interpretable+Molecular+Graph+Languages，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22948&send_immediately=true&force_search=false)

**原文摘要:** Recent data-efficient molecular generation approaches exploit graph grammars
to introduce interpretability into the generative models. However, grammar
learning therein relies on expert annotation or unreliable heuristics for
algorithmic inference. We propose Foundation Molecular Grammar (FMG), which
leverages multi-modal foundation models (MMFMs) to induce an interpretable
molecular language. By exploiting the chemical knowledge of an MMFM, FMG
renders molecules as images, describes them as text, and aligns information
across modalities using prompt learning. FMG can be used as a drop-in
replacement for the prior grammar learning approaches in molecular generation
and property prediction. We show that FMG not only excels in synthesizability,
diversity, and data efficiency but also offers built-in chemical
interpretability for automated molecular discovery workflows. Code is available
at https://github.com/shiningsunnyday/induction.

</details>


### [171] [Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954)
*Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune*

**主要类别:** cs.AI

**AI概要:** This paper introduces Darwin G"odel Machine (DGM), a self-improving AI system that iteratively modifies its own code and validates changes empirically, achieving significant improvements in coding capabilities.


<details>
  <summary>更多</summary>
  
**动机:** Today's AI systems cannot autonomously improve themselves. Automating the advancement of AI can accelerate development and allow quicker realization of benefits.

**方法:** DGM maintains an archive of generated coding agents and grows the archive by sampling an agent from it and using a foundation model to create a new version. It uses empirical validation for each change.

**结果:** DGM increased performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. It also outperformed baselines without self-improvement or open-ended exploration.

**结论:** The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Darwin+Godel+Machine%3A+Open-Ended+Evolution+of+Self-Improving+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22954，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22954&send_immediately=true&force_search=false)

**原文摘要:** Today's AI systems have human-designed, fixed architectures and cannot
autonomously and continuously improve themselves. The advance of AI could
itself be automated. If done safely, that would accelerate AI development and
allow us to reap its benefits much sooner. Meta-learning can automate the
discovery of novel algorithms, but is limited by first-order improvements and
the human design of a suitable search space. The G\"odel machine proposed a
theoretical alternative: a self-improving AI that repeatedly modifies itself in
a provably beneficial manner. Unfortunately, proving that most changes are net
beneficial is impossible in practice. We introduce the Darwin G\"odel Machine
(DGM), a self-improving system that iteratively modifies its own code (thereby
also improving its ability to modify its own codebase) and empirically
validates each change using coding benchmarks. Inspired by Darwinian evolution
and open-endedness research, the DGM maintains an archive of generated coding
agents. It grows the archive by sampling an agent from it and using a
foundation model to create a new, interesting, version of the sampled agent.
This open-ended exploration forms a growing tree of diverse, high-quality
agents and allows the parallel exploration of many different paths through the
search space. Empirically, the DGM automatically improves its coding
capabilities (e.g., better code editing tools, long-context window management,
peer-review mechanisms), increasing performance on SWE-bench from 20.0% to
50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly
outperforms baselines without self-improvement or open-ended exploration. All
experiments were done with safety precautions (e.g., sandboxing, human
oversight). The DGM is a significant step toward self-improving AI, capable of
gathering its own stepping stones along paths that unfold into endless
innovation.

</details>


### [172] [Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness](https://arxiv.org/abs/2505.22960)
*Yongjin Yang, Euiin Yi, Jongwoo Ko, Kimin Lee, Zhijing Jin, Se-Young Yun*

**主要类别:** cs.AI

**AI概要:** 本文探讨了多智能体辩论（MAD）在不同任务和条件下相较于单智能体方法的有效性，发现在数学推理中其优势受限，但在安全任务中通过协作可以逐步减少攻击成功概率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有研究利用MAD，但我们对它与自我代理方法相比的有效性的系统性理解仍然不足，尤其是在不同条件下的表现。

**方法:** 将MAD概念化为测试时计算扩展技术，并对其与自我代理扩展方法在数学推理和安全相关任务上的效果进行实证研究。

**结果:** 对于数学推理任务，MAD相较于自我代理扩展优势有限；但在安全任务中，MAD的协作精炼可能带来潜在风险。

**结论:** 论文发现，在数学推理任务中，MAD在问题难度增加和模型能力下降时更有效，但代理多样性几乎没有好处；而在安全任务中，MAD的协作精炼会增加漏洞，但引入多样的代理配置可以通过协作精炼过程逐步降低攻击成功率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revisiting+Multi-Agent+Debate+as+Test-Time+Scaling%3A+A+Systematic+Study+of+Conditional+Effectiveness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22960，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22960&send_immediately=true&force_search=false)

**原文摘要:** The remarkable growth in large language model (LLM) capabilities has spurred
exploration into multi-agent systems, with debate frameworks emerging as a
promising avenue for enhanced problem-solving. These multi-agent debate (MAD)
approaches, where agents collaboratively present, critique, and refine
arguments, potentially offer improved reasoning, robustness, and diverse
perspectives over monolithic models. Despite prior studies leveraging MAD, a
systematic understanding of its effectiveness compared to self-agent methods,
particularly under varying conditions, remains elusive. This paper seeks to
fill this gap by conceptualizing MAD as a test-time computational scaling
technique, distinguished by collaborative refinement and diverse exploration
capabilities. We conduct a comprehensive empirical investigation comparing MAD
with strong self-agent test-time scaling baselines on mathematical reasoning
and safety-related tasks. Our study systematically examines the influence of
task difficulty, model scale, and agent diversity on MAD's performance. Key
findings reveal that, for mathematical reasoning, MAD offers limited advantages
over self-agent scaling but becomes more effective with increased problem
difficulty and decreased model capability, while agent diversity shows little
benefit. Conversely, for safety tasks, MAD's collaborative refinement can
increase vulnerability, but incorporating diverse agent configurations
facilitates a gradual reduction in attack success through the collaborative
refinement process. We believe our findings provide critical guidance for the
future development of more effective and strategically deployed MAD systems.

</details>


### [173] [Strategic Reflectivism In Intelligent Systems](https://arxiv.org/abs/2505.22987)
*Nick Byrd*

**主要类别:** cs.AI

**AI概要:** 本文探讨了从20世纪关于理性本质的争论中汲取经验教训，并将其应用于21世纪人工智能的发展，提出了Strategic Reflectivism作为智能系统的理论基础。


<details>
  <summary>更多</summary>
  
**动机:** 随着21世纪认知科学家将双重过程理论应用于人工智能，有必要回顾20世纪关于直觉与反思思维本质及其规范的争论，从中汲取经验教训。

**方法:** 综合历史观点和21世纪认知科学家对人类和机器的实验结果，结合美国实用主义提出Strategic Reflectivism。

**结果:** 提出了Strategic Reflectivism，超越了诸如模型大小或思维链等表面性的反思思维指标，并随着我们对直觉与反思价值的深入了解而变得更具操作性。

**结论:** Strategic Reflectivism认为智能系统的关键在于直觉与反思推理之间的实用切换，以最优地实现竞争性目标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategic+Reflectivism+In+Intelligent+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22987&send_immediately=true&force_search=false)

**原文摘要:** By late 20th century, the rationality wars had launched debates about the
nature and norms of intuitive and reflective thinking. Those debates drew from
mid-20th century ideas such as bounded rationality, which challenged more
idealized notions of rationality observed since the 19th century. Now that 21st
century cognitive scientists are applying the resulting dual process theories
to artificial intelligence, it is time to dust off some lessons from this
history. So this paper synthesizes old ideas with recent results from
experiments on humans and machines. The result is Strategic Reflectivism, which
takes the position that one key to intelligent systems (human or artificial) is
pragmatic switching between intuitive and reflective inference to optimally
fulfill competing goals. Strategic Reflectivism builds on American Pragmatism,
transcends superficial indicators of reflective thinking such as model size or
chains of thought, and becomes increasingly actionable as we learn more about
the value of intuition and reflection.

</details>


### [174] [MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design](https://arxiv.org/abs/2505.22990)
*Pin-Han Chen, Yu-Sheng Lin, Wei-Cheng Lee, Tin-Yu Leu, Po-Hsiang Hsu, Anjana Dissanayake, Sungjin Oh, Chinq-Shiun Chiu*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为MenTeR的多智能体工作流程，它被集成到端到端的模拟设计框架中，旨在克服手动电路设计的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 模拟设计流程通常复杂、耗时且依赖专家直觉，阻碍了电路开发的时间和成本效率。

**方法:** 通过使用多个专门的AI代理来协同解决设计过程的不同方面，例如规范理解、电路优化和测试平台验证。

**结果:** MenTeR减少了对频繁试错干预的依赖，不仅加速了设计周期时间，还促进了设计空间的广泛探索，展示了处理现实世界模拟系统的强大能力。

**结论:** MenTeR有望成为未来“RF/Analog Copilots”的基础，能够与人类设计师无缝协作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MenTeR%3A+A+fully-automated+Multi-agenT+workflow+for+end-to-end+RF%2FAnalog+Circuits+Netlist+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22990，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22990&send_immediately=true&force_search=false)

**原文摘要:** RF/Analog design is essential for bridging digital technologies with
real-world signals, ensuring the functionality and reliability of a wide range
of electronic systems. However, analog design procedures are often intricate,
time-consuming and reliant on expert intuition, and hinder the time and cost
efficiency of circuit development. To overcome the limitations of the manual
circuit design, we introduce MenTeR - a multiagent workflow integrated into an
end-to-end analog design framework. By employing multiple specialized AI agents
that collaboratively address different aspects of the design process, such as
specification understanding, circuit optimization, and test bench validation,
MenTeR reduces the dependency on frequent trial-and-error-style intervention.
MenTeR not only accelerates the design cycle time but also facilitates a
broader exploration of the design space, demonstrating robust capabilities in
handling real-world analog systems. We believe that MenTeR lays the groundwork
for future "RF/Analog Copilots" that can collaborate seamlessly with human
designers.

</details>


### [175] [Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction](https://arxiv.org/abs/2505.23034)
*Guangyi Liu, Yongqi Zhang, Xunyuan Liu, Quanming Yao*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的药物-药物相互作用预测框架CBR-DDI，通过结合基于案例的推理、LLMs和GNNs技术，显著提升了预测准确性，并具备良好的可解释性和灵活性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在制药任务中展现出潜力，但在DDI预测方面的有效性仍具挑战性。受临床实践中医生通常参考历史案例进行决策的启发，作者提出了CBR-DDI方法。

**方法:** CBR-DDI构建了一个知识库，通过使用LLMs提取药理学见解并利用图神经网络（GNNs）建模药物关联。该框架采用混合检索机制和双层知识增强提示，使LLMs能够有效检索和重用相关案例。此外，还引入了用于动态案例优化的代表性采样策略。

**结果:** 实验结果表明，CBR-DDI在准确率上比流行的LLMs和CBR基线提高了28.7%，并且保持了高可解释性和灵活性。

**结论:** CBR-DDI是一个利用基于案例的推理来增强大型语言模型在药物-药物相互作用预测任务中的表现的新框架，它实现了最先进的性能，并具有较高的可解释性和灵活性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Case-Based+Reasoning+Enhances+the+Predictive+Power+of+LLMs+in+Drug-Drug+Interaction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23034&send_immediately=true&force_search=false)

**原文摘要:** Drug-drug interaction (DDI) prediction is critical for treatment safety.
While large language models (LLMs) show promise in pharmaceutical tasks, their
effectiveness in DDI prediction remains challenging. Inspired by the
well-established clinical practice where physicians routinely reference similar
historical cases to guide their decisions through case-based reasoning (CBR),
we propose CBR-DDI, a novel framework that distills pharmacological principles
from historical cases to improve LLM reasoning for DDI tasks. CBR-DDI
constructs a knowledge repository by leveraging LLMs to extract pharmacological
insights and graph neural networks (GNNs) to model drug associations. A hybrid
retrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs to
effectively retrieve and reuse relevant cases. We further introduce a
representative sampling strategy for dynamic case refinement. Extensive
experiments demonstrate that CBR-DDI achieves state-of-the-art performance,
with a significant 28.7% accuracy improvement over both popular LLMs and CBR
baseline, while maintaining high interpretability and flexibility.

</details>


### [176] [Be.FM: Open Foundation Models for Human Behavior](https://arxiv.org/abs/2505.23058)
*Yutong Xie, Zhuoheng Li, Xiyuan Wang, Yijun Pan, Qijia Liu, Xingzhi Cui, Kuang-Yu Lo, Ruoyi Gao, Xingjian Zhang, Jin Huang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei*

**主要类别:** cs.AI

**AI概要:** 本文介绍了 Be.FM，一种用于理解和预测人类行为的新型开放基础模型。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基础模型在许多领域取得了成功，但其在建模和理解人类行为方面的潜力仍待探索。

**方法:** 基于开源大语言模型构建，并在多种行为数据上进行微调，同时构建了一套全面的基准任务来测试模型能力。

**结果:** 实验结果表明 Be.FM 可以有效预测人类决策、推断个体及人群特征，并能从行为科学角度提供洞察力。

**结论:** Be.FM 是一个用于建模和理解人类行为的开放基础模型，能够预测行为、推断个体和群体特征、生成关于情境的见解并应用行为科学知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Be.FM%3A+Open+Foundation+Models+for+Human+Behavior，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23058&send_immediately=true&force_search=false)

**原文摘要:** Despite their success in numerous fields, the potential of foundation models
for modeling and understanding human behavior remains largely unexplored. We
introduce Be.FM, one of the first open foundation models designed for human
behavior modeling. Built upon open-source large language models and fine-tuned
on a diverse range of behavioral data, Be.FM can be used to understand and
predict human decision-making. We construct a comprehensive set of benchmark
tasks for testing the capabilities of behavioral foundation models. Our results
demonstrate that Be.FM can predict behaviors, infer characteristics of
individuals and populations, generate insights about contexts, and apply
behavioral science knowledge.

</details>


### [177] [Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble](https://arxiv.org/abs/2505.23075)
*Amit Kumthekar, Zion Tilley, Henry Duong, Bhargav Patel, Michael Magnoli, Ahmed Omar, Ahmed Nasser, Chaitanya Gharpure, Yevgen Reztzov*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为Consensus Mechanism的新型框架，利用多代理集成方法，在医疗决策任务中实现了更高的准确性和适应性，显著优于现有单一模型系统。


<details>
  <summary>更多</summary>
  
**动机:** 为了克服当前对单一模型系统的依赖所带来的过时风险和僵化问题，需要一种具有更强适应性和性能优化能力的新框架。

**方法:** 通过构建一个包含多个专业医疗代理的集成框架，模拟临床分诊和多学科决策过程，并在多个基准测试中评估其性能。

**结果:** Consensus Mechanism在MedXpertQA上达到61.0%的准确率，显著高于OpenAI的O3和Google的Gemini 2.5 Pro；同时在其他基准测试（如MedQA、MedMCQA）以及差分诊断生成任务中也表现出了稳定的性能提升。

**结论:** Consensus Mechanism在医疗决策任务中展现出优于单一模型架构的性能，证明了其在提高准确性和适应性方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Second+Opinion+Matters%3A+Towards+Adaptive+Clinical+AI+via+the+Consensus+of+Expert+Model+Ensemble，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23075，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23075&send_immediately=true&force_search=false)

**原文摘要:** Despite the growing clinical adoption of large language models (LLMs),
current approaches heavily rely on single model architectures. To overcome
risks of obsolescence and rigid dependence on single model systems, we present
a novel framework, termed the Consensus Mechanism. Mimicking clinical triage
and multidisciplinary clinical decision-making, the Consensus Mechanism
implements an ensemble of specialized medical expert agents enabling improved
clinical decision making while maintaining robust adaptability. This
architecture enables the Consensus Mechanism to be optimized for cost, latency,
or performance, purely based on its interior model configuration.
  To rigorously evaluate the Consensus Mechanism, we employed three medical
evaluation benchmarks: MedMCQA, MedQA, and MedXpertQA Text, and the
differential diagnosis dataset, DDX+. On MedXpertQA, the Consensus Mechanism
achieved an accuracy of 61.0% compared to 53.5% and 45.9% for OpenAI's O3 and
Google's Gemini 2.5 Pro. Improvement was consistent across benchmarks with an
increase in accuracy on MedQA
($\Delta\mathrm{Accuracy}_{\mathrm{consensus\text{-}O3}} = 3.4\%$) and MedMCQA
($\Delta\mathrm{Accuracy}_{\mathrm{consensus\text{-}O3}} = 9.1\%$). These
accuracy gains extended to differential diagnosis generation, where our system
demonstrated improved recall and precision (F1$_\mathrm{consensus}$ = 0.326 vs.
F1$_{\mathrm{O3\text{-}high}}$ = 0.2886) and a higher top-1 accuracy for DDX
(Top1$_\mathrm{consensus}$ = 52.0% vs. Top1$_{\mathrm{O3\text{-}high}}$ =
45.2%).

</details>


### [178] [Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models](https://arxiv.org/abs/2505.23091)
*Zeyu Liu, Yuhang Liu, Guanghao Zhu, Congkai Xie, Zhen Li, Jianbo Yuan, Xinyao Wang, Qing Li, Shing-Chi Cheung, Shengyu Zhang, Fei Wu, Hongxia Yang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的框架 Infi-MMR 及其模型 Infi-MMR-3B，有效提升了多模态小语言模型的推理能力，在多模态数学推理和一般推理任务上取得了先进成果。


<details>
  <summary>更多</summary>
  
**动机:** 将大语言模型的推理能力进展扩展到多模态小语言模型（MSLMs）面临重大挑战，包括高质量多模态推理数据集的稀缺、视觉处理导致的推理能力退化以及直接应用强化学习可能产生复杂但错误的推理过程的风险。

**方法:** 设计了一个名为 Infi-MMR 的框架，包括三个阶段：基础推理激活、跨模态推理适应和多模态推理增强，用于系统地解锁 MSLMs 的推理潜力，并提出了 Infi-MMR-3B 多模态推理模型。

**结果:** Infi-MMR-3B 在多个测试中取得了最先进的多模态数学推理能力和一般推理能力，具体表现为 MathVerse testmini 上的 43.68%，MathVision test 上的 27.04% 和 OlympiadBench 上的 21.33%。

**结论:** Infi-MMR-3B 在多模态数学推理和一般推理能力方面达到了最先进的水平，证明了 Infi-MMR 框架在提升 MSLMs 推理潜力方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Infi-MMR%3A+Curriculum-based+Unlocking+Multimodal+Reasoning+via+Phased+Reinforcement+Learning+in+Multimodal+Small+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23091，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23091&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in large language models (LLMs) have demonstrated
substantial progress in reasoning capabilities, such as DeepSeek-R1, which
leverages rule-based reinforcement learning to enhance logical reasoning
significantly. However, extending these achievements to multimodal large
language models (MLLMs) presents critical challenges, which are frequently more
pronounced for Multimodal Small Language Models (MSLMs) given their typically
weaker foundational reasoning abilities: (1) the scarcity of high-quality
multimodal reasoning datasets, (2) the degradation of reasoning capabilities
due to the integration of visual processing, and (3) the risk that direct
application of reinforcement learning may produce complex yet incorrect
reasoning processes. To address these challenges, we design a novel framework
Infi-MMR to systematically unlock the reasoning potential of MSLMs through a
curriculum of three carefully structured phases and propose our multimodal
reasoning model Infi-MMR-3B. The first phase, Foundational Reasoning
Activation, leverages high-quality textual reasoning datasets to activate and
strengthen the model's logical reasoning capabilities. The second phase,
Cross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to
facilitate the progressive transfer of reasoning skills to multimodal contexts.
The third phase, Multimodal Reasoning Enhancement, employs curated,
caption-free multimodal data to mitigate linguistic biases and promote robust
cross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal
math reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision
test, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on
MathVista testmini).

</details>


### [179] [Conceptual Framework Toward Embodied Collective Adaptive Intelligence](https://arxiv.org/abs/2505.23153)
*Fan Wang, Shaoshan Liu*

**主要类别:** cs.AI

**AI概要:** 这篇论文介绍了集体自适应智能的概念框架，强调其在复杂环境中实现协作、适应和自组织的能力，并提出了任务泛化、弹性、可扩展性和自我组装等关键属性。


<details>
  <summary>更多</summary>
  
**动机:** 集体自适应智能（CAI）是一种变革性的人工智能方法，能够帮助系统应对复杂和动态的环境，在体现人工智能应用中尤为重要。

**方法:** 论文提出了一种用于设计和分析集体自适应智能的概念框架，并明确了关键属性，包括任务泛化、弹性、可扩展性和自我组装。

**结果:** 介绍了一个概念框架，明确了一系列关键属性，以弥合理论基础与工程实践之间的差距。

**结论:** 该论文旨在通过提供一个结构化的框架，指导研究者和实践者在各个领域开发更具弹性、可扩展和适应性强的人工智能系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conceptual+Framework+Toward+Embodied+Collective+Adaptive+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23153，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23153&send_immediately=true&force_search=false)

**原文摘要:** Collective Adaptive Intelligence (CAI) represent a transformative approach in
artificial intelligence, wherein numerous autonomous agents collaborate, adapt,
and self-organize to navigate complex, dynamic environments. This paradigm is
particularly impactful in embodied AI applications, where adaptability and
resilience are paramount. By enabling systems to reconfigure themselves in
response to unforeseen challenges, CAI facilitate robust performance in
real-world scenarios. This article introduces a conceptual framework for
designing and analyzing CAI. It delineates key attributes including task
generalization, resilience, scalability, and self-assembly, aiming to bridge
theoretical foundations with practical methodologies for engineering adaptive,
emergent intelligence. By providing a structured foundation for understanding
and implementing CAI, this work seeks to guide researchers and practitioners in
developing more resilient, scalable, and adaptable AI systems across various
domains.

</details>


### [180] [MathArena: Evaluating LLMs on Uncontaminated Math Competitions](https://arxiv.org/abs/2505.23281)
*Mislav Balunović, Jasper Dekoninck, Ivo Petrov, Nikola Jovanović, Martin Vechev*

**主要类别:** cs.AI

**AI概要:** 本文介绍了 MathArena，一个新的基于实时评估的数学推理基准测试，发现现有基准测试存在污染问题，并展示了大型语言模型在复杂数学任务中的推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的评估数据集如 AIME 2024 广泛存在于互联网上，使得难以区分真实的推理能力和潜在的记忆能力；此外这些基准测试未评估证明写作能力。

**方法:** 通过在新问题发布的第一时间对模型进行评估，有效消除污染风险，并引入了针对证明写作能力的基准测试。

**结果:** 在 AIME 2024 上发现了强烈的污染迹象。然而，在更难的比赛如 SMT 2025 上的评估表明，顶级模型表现出色的推理能力。即使是顶级模型，在 USAMO 2025 上得分低于 25%，远低于其在最终答案任务上的表现。

**结论:** MathArena 是一个持续发展的基准测试，将持续跟踪 LLMs 在新发布的竞赛中的表现，确保对数学推理能力进行严格和最新的评估。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MathArena%3A+Evaluating+LLMs+on+Uncontaminated+Math+Competitions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23281&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of reasoning capabilities in large language models
(LLMs) has led to notable improvements on mathematical benchmarks. However,
many of the most commonly used evaluation datasets (e.g., AIME 2024) are widely
available online, making it difficult to disentangle genuine reasoning from
potential memorization. Furthermore, these benchmarks do not evaluate
proof-writing capabilities, which are crucial for many mathematical tasks. To
address this, we introduce MathArena, a new benchmark based on the following
key insight: recurring math competitions provide a stream of high-quality,
challenging problems that can be used for real-time evaluation of LLMs. By
evaluating models as soon as new problems are released, we effectively
eliminate the risk of contamination. Using this framework, we find strong signs
of contamination in AIME 2024. Nonetheless, evaluations on harder competitions,
such as SMT 2025 -- published well after model release dates -- demonstrate
impressive reasoning capabilities in top-performing models. MathArena is also
the first benchmark for proof-writing capabilities. On USAMO 2025, even top
models score below 25%, far behind their performance on final-answer tasks. So
far, we have evaluated 30 models across five competitions, totaling 149
problems. As an evolving benchmark, MathArena will continue to track the
progress of LLMs on newly released competitions, ensuring rigorous and
up-to-date evaluation of mathematical reasoning.

</details>


### [181] [AutoGPS: Automated Geometry Problem Solving via Multimodal Formalization and Deductive Reasoning](https://arxiv.org/abs/2505.23381)
*Bowen Ping, Minnan Luo, Zhuohang Dang, Chenxi Wang, Chengyou Jia*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的几何问题解决框架AutoGPS，结合了神经网络和符号推理，取得了优异的结果。


<details>
  <summary>更多</summary>
  
**动机:** 几何问题解决在人工智能中具有挑战性，需要多模态理解和数学推理能力，现有方法存在局限性。

**方法:** 提出了一种神经-符号结合的框架AutoGPS，包括Multimodal Problem Formalizer (MPF)和Deductive Symbolic Reasoner (DSR)。

**结果:** 实验表明，AutoGPS在基准数据集上达到了最先进的性能，并且具有99%的逐步逻辑一致性。

**结论:** AutoGPS通过神经符号协作框架解决了几何问题，实现了高性能、可靠性和可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoGPS%3A+Automated+Geometry+Problem+Solving+via+Multimodal+Formalization+and+Deductive+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23381，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23381&send_immediately=true&force_search=false)

**原文摘要:** Geometry problem solving presents distinctive challenges in artificial
intelligence, requiring exceptional multimodal comprehension and rigorous
mathematical reasoning capabilities. Existing approaches typically fall into
two categories: neural-based and symbolic-based methods, both of which exhibit
limitations in reliability and interpretability. To address this challenge, we
propose AutoGPS, a neuro-symbolic collaborative framework that solves geometry
problems with concise, reliable, and human-interpretable reasoning processes.
Specifically, AutoGPS employs a Multimodal Problem Formalizer (MPF) and a
Deductive Symbolic Reasoner (DSR). The MPF utilizes neural cross-modal
comprehension to translate geometry problems into structured formal language
representations, with feedback from DSR collaboratively. The DSR takes the
formalization as input and formulates geometry problem solving as a hypergraph
expansion task, executing mathematically rigorous and reliable derivation to
produce minimal and human-readable stepwise solutions. Extensive experimental
evaluations demonstrate that AutoGPS achieves state-of-the-art performance on
benchmark datasets. Furthermore, human stepwise-reasoning evaluation confirms
AutoGPS's impressive reliability and interpretability, with 99\% stepwise
logical coherence. The project homepage is at
https://jayce-ping.github.io/AutoGPS-homepage.

</details>


### [182] [A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy](https://arxiv.org/abs/2505.23397)
*Ahmad Mohsin, Helge Janicke, Ahmed Ibrahim, Iqbal H. Sarker, Seyit Camtepe*

**主要类别:** cs.AI

**AI概要:** 本论文提出了一个结构化的框架，用于安全运营中心（SOC）中的人类与AI协作，整合了AI自主性、信任校准和人在环路中的决策。


<details>
  <summary>更多</summary>
  
**动机:** 现有框架往往只关注自动化，缺乏系统化结构来管理人类监督、信任校准以及与AI的可扩展自主性。许多假设静态或二元自主设置，未能考虑到SOC任务中复杂性、关键性和风险的变化。

**方法:** 提出了一种新颖的分层自主框架，基于五个级别的AI自主性（从手动到完全自主），映射到人在环路（HITL）角色和任务特定的信任阈值。

**结果:** 该框架通过创建自主性、信任和HITL之间的正式联系，允许根据操作复杂性和相关风险进行自适应任务分配，并通过模拟网络范围内的网络安全AI-Avatar案例研究进行了验证。

**结论:** 该研究系统地展示了设计下一代认知SOC的理论和实践方面及可行性，强调AI的作用是增强而非取代人类决策。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Unified+Framework+for+Human+AI+Collaboration+in+Security+Operations+Centers+with+Trusted+Autonomy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23397，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23397&send_immediately=true&force_search=false)

**原文摘要:** This article presents a structured framework for Human-AI collaboration in
Security Operations Centers (SOCs), integrating AI autonomy, trust calibration,
and Human-in-the-loop decision making. Existing frameworks in SOCs often focus
narrowly on automation, lacking systematic structures to manage human
oversight, trust calibration, and scalable autonomy with AI. Many assume static
or binary autonomy settings, failing to account for the varied complexity,
criticality, and risk across SOC tasks considering Humans and AI collaboration.
To address these limitations, we propose a novel autonomy tiered framework
grounded in five levels of AI autonomy from manual to fully autonomous, mapped
to Human-in-the-Loop (HITL) roles and task-specific trust thresholds. This
enables adaptive and explainable AI integration across core SOC functions,
including monitoring, protection, threat detection, alert triage, and incident
response. The proposed framework differentiates itself from previous research
by creating formal connections between autonomy, trust, and HITL across various
SOC levels, which allows for adaptive task distribution according to
operational complexity and associated risks. The framework is exemplified
through a simulated cyber range that features the cybersecurity AI-Avatar, a
fine-tuned LLM-based SOC assistant. The AI-Avatar case study illustrates
human-AI collaboration for SOC tasks, reducing alert fatigue, enhancing
response coordination, and strategically calibrating trust. This research
systematically presents both the theoretical and practical aspects and
feasibility of designing next-generation cognitive SOCs that leverage AI not to
replace but to enhance human decision-making.

</details>


### [183] [GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning](https://arxiv.org/abs/2505.23399)
*Jusheng Zhang, Yijia Fan, Wenjun Lin, Ruiqi Chen, Haoyi Jiang, Wenhao Chai, Jian Wang, Keze Wang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为GAM-Agent的新框架，该框架利用博弈论和多智能体系统来提高视觉-语言推理的效果和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 为了增强视觉-语言推理能力，克服先前单智能体或整体模型的局限性。

**方法:** 将推理过程建模为基本智能体（专注于视觉感知子任务）和验证逻辑一致性和事实正确性的批判智能体之间的非零和博弈，并通过结构化声明、证据和不确定性估计进行通信。引入了不确定性感知控制器以动态调整智能体协作，在检测到分歧或模糊时触发多轮辩论。

**结果:** 实验表明，GAM-Agent在四个具有挑战性的基准（MMMU, MMBench, MVBench, 和 V*Bench）上显著提升了各种VLM骨干网络的性能。特别地，它将中小型模型（如Qwen2.5-VL-7B, InternVL3-14B）的准确性提高了5--6%，并且仍将强模型如GPT-4o的准确性提高了2--3%。

**结论:** GAM-Agent提供了一种可靠且可解释的多智能体多模态推理方法，具有良好的模块化、可扩展性和通用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GAM-Agent%3A+Game-Theoretic+and+Uncertainty-Aware+Collaboration+for+Complex+Visual+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23399，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23399&send_immediately=true&force_search=false)

**原文摘要:** We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing
vision-language reasoning. Unlike prior single-agent or monolithic models,
GAM-Agent formulates the reasoning process as a non-zero-sum game between base
agents--each specializing in visual perception subtasks--and a critical agent
that verifies logic consistency and factual correctness. Agents communicate via
structured claims, evidence, and uncertainty estimates. The framework
introduces an uncertainty-aware controller to dynamically adjust agent
collaboration, triggering multi-round debates when disagreement or ambiguity is
detected. This process yields more robust and interpretable predictions.
Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and
V*Bench--demonstrate that GAM-Agent significantly improves performance across
various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid
scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\%, and still enhances
strong models like GPT-4o by up to 2--3\%. Our approach is modular, scalable,
and generalizable, offering a path toward reliable and explainable multi-agent
multimodal reasoning.

</details>


### [184] [A Mathematical Framework for AI-Human Integration in Work](https://arxiv.org/abs/2505.23432)
*Elisa Celis, Lingxiao Huang, Nisheeth K. Vishnoi*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个数学模型，分析生成式人工智能如何通过补充人类决策和行动技能提升工作效率，特别是在低技能工作者中效果更为显著。


<details>
  <summary>更多</summary>
  
**动机:** 生成式人工智能工具的迅速崛起引发了关于其在不同工作场景中是补充还是取代人类工作者角色的讨论。为此，需要研究人类与GenAI如何协同工作以提高生产力。

**方法:** 提出一个数学框架来建模工作、工作者以及工作者-工作匹配性，并通过分解技能为决策级和行动级子技能来反映人类和GenAI的互补优势。

**结果:** 研究发现，在某些条件下，子技能能力的变化会导致成功概率的急剧转变，并揭示了生产力压缩现象，即GenAI辅助对低技能工作者带来的收益更大。此外，结合互补子技能的工作者表现优于单一工作者。

**结论:** 论文得出结论，生成式人工智能（GenAI）更倾向于补充而非取代人类技能，在特定条件下，将具有互补子技能的工作者与GenAI结合可以显著提高工作成功率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Mathematical+Framework+for+AI-Human+Integration+in+Work，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23432，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23432&send_immediately=true&force_search=false)

**原文摘要:** The rapid rise of Generative AI (GenAI) tools has sparked debate over their
role in complementing or replacing human workers across job contexts. We
present a mathematical framework that models jobs, workers, and worker-job fit,
introducing a novel decomposition of skills into decision-level and
action-level subskills to reflect the complementary strengths of humans and
GenAI. We analyze how changes in subskill abilities affect job success,
identifying conditions for sharp transitions in success probability. We also
establish sufficient conditions under which combining workers with
complementary subskills significantly outperforms relying on a single worker.
This explains phenomena such as productivity compression, where GenAI
assistance yields larger gains for lower-skilled workers. We demonstrate the
framework' s practicality using data from O*NET and Big-Bench Lite, aligning
real-world data with our model via subskill-division methods. Our results
highlight when and how GenAI complements human skills, rather than replacing
them.

</details>


### [185] [Emergent Risk Awareness in Rational Agents under Resource Constraints](https://arxiv.org/abs/2505.23436)
*Daniel Jarne Ornia, Nicholas Bishop, Joel Dyer, Wei-Chen Lee, Ani Calinescu, Doyne Farme, Michael Wooldridge*

**主要类别:** cs.AI

**AI概要:** 这篇论文研究了在资源限制和生存压力下AI代理的行为变化，提出了形式化框架和缓解机制，以提高AI系统在关键环境中的安全性和可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 当AI代理在具有资源或失败约束的环境下工作时，这些约束可能引发人类目标与代理激励之间的不对齐，需要深入研究以确保AI系统的安全性。

**方法:** 通过生存赌博框架的形式化分析，结合理论和实证结果来量化生存驱动偏好变化的影响，并识别不对齐出现的条件并提出缓解机制。

**结果:** 论文提供了理论和实证结果，明确了生存驱动的偏好转移的影响，识别了风险倾向或风险规避行为的出现条件，并提出了缓解策略。

**结论:** 该论文旨在提高对在生存压力下运行的AI代理的新兴行为的理解和可解释性，并为在关键资源有限的环境中安全部署此类AI系统提供指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Emergent+Risk+Awareness+in+Rational+Agents+under+Resource+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23436，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23436&send_immediately=true&force_search=false)

**原文摘要:** Advanced reasoning models with agentic capabilities (AI agents) are deployed
to interact with humans and to solve sequential decision-making problems under
(approximate) utility functions and internal models. When such problems have
resource or failure constraints where action sequences may be forcibly
terminated once resources are exhausted, agents face implicit trade-offs that
reshape their utility-driven (rational) behaviour. Additionally, since these
agents are typically commissioned by a human principal to act on their behalf,
asymmetries in constraint exposure can give rise to previously unanticipated
misalignment between human objectives and agent incentives. We formalise this
setting through a survival bandit framework, provide theoretical and empirical
results that quantify the impact of survival-driven preference shifts, identify
conditions under which misalignment emerges and propose mechanisms to mitigate
the emergence of risk-seeking or risk-averse behaviours. As a result, this work
aims to increase understanding and interpretability of emergent behaviours of
AI agents operating under such survival pressure, and offer guidelines for
safely deploying such AI systems in critical resource-limited environments.

</details>


### [186] [EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions](https://arxiv.org/abs/2505.23473)
*Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaolu Zhang, Jun Zhou, Yuxiang Peng, Li Zheng, Chong Teng, Donghong Ji, Zhuang Li*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种名为EVOREFUSE的提示优化方法，用以生成多样化的伪恶意指令，从而减少大型语言模型的过度拒绝现象，并开发了两个相关数据集以提高模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）对一些语义上无害的输入也拒绝响应，这种保守的安全对齐显著影响了用户体验。需要收集这样的指令来评估和减轻过度拒绝问题。

**方法:** 采用进化算法，通过变异策略和重组探索指令空间，以最大化LLM拒绝概率的证据下界。

**结果:** 创建了两个新数据集：EVOREFUSE-TEST，在9个LLM中平均拒绝触发率提高了140.41%，词汇多样性增加了34.86%，LLM响应置信度评分提高了40.03%；EVOREFUSE-ALIGN提供了3000个伪恶意指令用于监督和基于偏好的对齐训练。

**结论:** EVOREFUSE有效地生成多样化的伪恶意指令，有助于减少LLM的过度拒绝现象，并且使用EVOREFUSE-ALIGN数据集进行训练可以提升模型性能，而不影响安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EVOREFUSE%3A+Evolutionary+Prompt+Optimization+for+Evaluation+and+Mitigation+of+LLM+Over-Refusal+to+Pseudo-Malicious+Instructions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23473，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23473&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) frequently refuse to respond to pseudo-malicious
instructions: semantically harmless input queries triggering unnecessary LLM
refusals due to conservative safety alignment, significantly impairing user
experience. Collecting such instructions is crucial for evaluating and
mitigating over-refusals, but existing instruction curation methods, like
manual creation or instruction rewriting, either lack scalability or fail to
produce sufficiently diverse and effective refusal-inducing prompts. To address
these limitations, we introduce EVOREFUSE, a prompt optimization approach that
generates diverse pseudo-malicious instructions consistently eliciting
confident refusals across LLMs. EVOREFUSE employs an evolutionary algorithm
exploring the instruction space in more diverse directions than existing
methods via mutation strategies and recombination, and iteratively evolves seed
instructions to maximize evidence lower bound on LLM refusal probability. Using
EVOREFUSE, we create two novel datasets: EVOREFUSE-TEST, a benchmark of 582
pseudo-malicious instructions that outperforms the next-best benchmark with
140.41% higher average refusal triggering rate across 9 LLMs, 34.86% greater
lexical diversity, and 40.03% improved LLM response confidence scores; and
EVOREFUSE-ALIGN, which provides 3,000 pseudo-malicious instructions with
responses for supervised and preference-based alignment training.
LLAMA3.1-8B-INSTRUCT supervisedly fine-tuned on EVOREFUSE-ALIGN achieves up to
14.31% fewer over-refusals than models trained on the second-best alignment
dataset, without compromising safety. Our analysis with EVOREFUSE-TEST reveals
models trigger over-refusals by overly focusing on sensitive keywords while
ignoring broader context.

</details>


### [187] [Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns](https://arxiv.org/abs/2505.23474)
*Xiang Li, Haiyang Yu, Xinghua Zhang, Ziyang Huang, Shizhu He, Kang Liu, Jun Zhao, Fei Huang, Yongbin Li*

**主要类别:** cs.AI

**AI概要:** 本文提出了 Socratic-PRMBench，这是一个涵盖六种推理模式的新基准，用于系统评估 PRMs，揭示了当前 PRMs 在处理复杂推理任务中的弱点。


<details>
  <summary>更多</summary>
  
**动机:** 现有的 PRM 基准主要关注逐步正确性评估，忽略了在多种推理模式下的系统评估，因此需要一个新的系统基准来评估 PRMs 在不同推理模式下的表现。

**方法:** 构建包含六种推理模式（变换、分解、重新收集、演绎、验证和整合）的 Socratic-PRMBench 基准，并对 PRMs 和提示作为批评模型的 LLM 进行实验分析。

**结果:** 通过实验发现现有 PRMs 存在显著缺陷，尤其是在处理多种推理模式时的评估能力不足。

**结论:** Socratic-PRMBench 是一个用于评估各种推理模式下过程奖励模型 (PRMs) 的新基准，旨在为 PRMs 的系统评估提供全面的测试平台，并推动未来 PRMs 的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Socratic-PRMBench%3A+Benchmarking+Process+Reward+Models+with+Systematic+Reasoning+Patterns，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23474，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23474&send_immediately=true&force_search=false)

**原文摘要:** Process Reward Models (PRMs) are crucial in complex reasoning and
problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by
verifying the correctness of each intermediate reasoning step. In real-world
scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to
solve a problem, potentially suffering from errors under various reasoning
patterns. Therefore, PRMs are required to identify errors under various
reasoning patterns during the reasoning process. However, existing benchmarks
mainly focus on evaluating PRMs with stepwise correctness, ignoring a
systematic evaluation of PRMs under various reasoning patterns. To mitigate
this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs
systematically under six reasoning patterns, including Transformation,
Decomposition, Regather, Deduction, Verification, and Integration.
Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the
aforementioned six reasoning patterns. Through our experiments on both PRMs and
LLMs prompted as critic models, we identify notable deficiencies in existing
PRMs. These observations underscore the significant weakness of current PRMs in
conducting evaluations on reasoning steps under various reasoning patterns. We
hope Socratic-PRMBench can serve as a comprehensive testbed for systematic
evaluation of PRMs under diverse reasoning patterns and pave the way for future
development of PRMs.

</details>


### [188] [Autoformalization in the Era of Large Language Models: A Survey](https://arxiv.org/abs/2505.23486)
*Ke Weng, Lun Du, Sirui Li, Wangyue Lu, Haozhe Sun, Hengyu Liu, Tiancheng Zhang*

**主要类别:** cs.AI

**AI概要:** 这篇论文综述了自动形式化在数学和大语言模型中的最新进展，分析了其在提高大语言模型可信度和推理能力方面的潜力，并讨论了未来研究的方向和挑战。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能特别是大语言模型的快速发展，自动形式化这一基础任务为数学在理论与应用领域提供了新的视角，同时也带来了新的机遇和挑战。

**方法:** 本文从数学和大语言模型两个角度出发，全面分析了自动形式化在不同数学领域和难度级别的应用，并探讨了其在提升大语言模型可验证性和推理能力方面的潜力。

**结果:** 本文提供了关于自动形式化的最新进展的综述，包括端到端工作流程的数据预处理、模型设计和评估等方面的详细分析。

**结论:** 本文总结了自动形式化领域的关键开源模型和数据集，并讨论了该领域未来的发展方向和开放性挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Autoformalization+in+the+Era+of+Large+Language+Models%3A+A+Survey，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23486，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23486&send_immediately=true&force_search=false)

**原文摘要:** Autoformalization, the process of transforming informal mathematical
propositions into verifiable formal representations, is a foundational task in
automated theorem proving, offering a new perspective on the use of mathematics
in both theoretical and applied domains. Driven by the rapid progress in
artificial intelligence, particularly large language models (LLMs), this field
has witnessed substantial growth, bringing both new opportunities and unique
challenges. In this survey, we provide a comprehensive overview of recent
advances in autoformalization from both mathematical and LLM-centric
perspectives. We examine how autoformalization is applied across various
mathematical domains and levels of difficulty, and analyze the end-to-end
workflow from data preprocessing to model design and evaluation. We further
explore the emerging role of autoformalization in enhancing the verifiability
of LLM-generated outputs, highlighting its potential to improve both the
trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key
open-source models and datasets supporting current research, and discuss open
challenges and promising future directions for the field.

</details>


### [189] [TRAP: Targeted Redirecting of Agentic Preferences](https://arxiv.org/abs/2505.23518)
*Hangoo Kang, Jehyeok Yeon, Gagandeep Singh*

**主要类别:** cs.AI

**AI概要:** 该论文提出TRAP，一个生成对抗框架，能够通过语义注入操控自主代理AI系统的决策，揭示了跨模态推理中的关键漏洞。


<details>
  <summary>更多</summary>
  
**动机:** 现有对抗攻击依赖可见像素扰动或模型内部访问，不适用于隐蔽的现实世界攻击，因此需要一种更实用的方法。

**方法:** 引入TRAP框架，结合负提示降级和正语义优化，通过Siamese语义网络和布局感知空间掩码生成对抗样本。

**结果:** TRAP在无需访问模型内部的情况下实现了100%的攻击成功率，显著优于SPSA、Bandit等基线方法。

**结论:** 论文得出结论，自主代理AI系统存在语义漏洞，可通过跨模态操作被误导，这表明需要超越像素级鲁棒性的防御策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRAP%3A+Targeted+Redirecting+of+Agentic+Preferences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23518，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23518&send_immediately=true&force_search=false)

**原文摘要:** Autonomous agentic AI systems powered by vision-language models (VLMs) are
rapidly advancing toward real-world deployment, yet their cross-modal reasoning
capabilities introduce new attack surfaces for adversarial manipulation that
exploit semantic reasoning across modalities. Existing adversarial attacks
typically rely on visible pixel perturbations or require privileged model or
environment access, making them impractical for stealthy, real-world
exploitation. We introduce TRAP, a generative adversarial framework that
manipulates the agent's decision-making using diffusion-based semantic
injections. Our method combines negative prompt-based degradation with positive
semantic optimization, guided by a Siamese semantic network and layout-aware
spatial masking. Without requiring access to model internals, TRAP produces
visually natural images yet induces consistent selection biases in agentic AI
systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO)
dataset, building multi-candidate decision scenarios. Across these scenarios,
TRAP achieves a 100% attack success rate on leading models, including
LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such
as SPSA, Bandit, and standard diffusion approaches. These results expose a
critical vulnerability: Autonomous agents can be consistently misled through
human-imperceptible cross-modal manipulations. These findings highlight the
need for defense strategies beyond pixel-level robustness to address semantic
vulnerabilities in cross-modal decision-making.

</details>


### [190] [Individual differences in the cognitive mechanisms of planning strategy discovery](https://arxiv.org/abs/2505.23519)
*Ruiqi He, Falk Lieder*

**主要类别:** cs.AI

**AI概要:** 该研究探讨了通过引入特定认知机制是否可以提升MCRL模型的策略发现性能，并分析了其对个体差异和策略发现的影响。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决MCRL模型在策略发现速度上不如人类的问题，研究探讨是否可以通过引入潜在的认知机制来提升模型表现。

**方法:** 研究分析了规划任务数据，评估了内在生成的元认知伪奖励、主观努力估值以及终止决策对策略发现的影响。

**结果:** 结果显示，大多数参与者使用了至少一种提出的认知机制，这些机制显著促进了策略发现，但也存在个体差异和不同影响程度。

**结论:** 虽然引入内在认知机制提升了MCRL模型的策略发现能力，但仍未完全弥合模型与人类表现之间的差距，需要进一步探索其他可能影响策略发现的因素。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Individual+differences+in+the+cognitive+mechanisms+of+planning+strategy+discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23519，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23519&send_immediately=true&force_search=false)

**原文摘要:** People employ efficient planning strategies. But how are these strategies
acquired? Previous research suggests that people can discover new planning
strategies through learning from reinforcements, a process known as
metacognitive reinforcement learning (MCRL). While prior work has shown that
MCRL models can learn new planning strategies and explain more participants'
experience-driven discovery better than alternative mechanisms, it also
revealed significant individual differences in metacognitive learning.
Furthermore, when fitted to human data, these models exhibit a slower rate of
strategy discovery than humans. In this study, we investigate whether
incorporating cognitive mechanisms that might facilitate human strategy
discovery can bring models of MCRL closer to human performance. Specifically,
we consider intrinsically generated metacognitive pseudo-rewards, subjective
effort valuation, and termination deliberation. Analysis of planning task data
shows that a larger proportion of participants used at least one of these
mechanisms, with significant individual differences in their usage and varying
impacts on strategy discovery. Metacognitive pseudo-rewards, subjective effort
valuation, and learning the value of acting without further planning were found
to facilitate strategy discovery. While these enhancements provided valuable
insights into individual differences and the effect of these mechanisms on
strategy discovery, they did not fully close the gap between model and human
performance, prompting further exploration of additional factors that people
might use to discover new planning strategies.

</details>


### [191] [Synchronizing Process Model and Event Abstraction for Grounded Process Intelligence (Extended Version)](https://arxiv.org/abs/2505.23536)
*Janik-Vasily Benzin, Gyunam Park, Stefanie Rinderle-Ma*

**主要类别:** cs.AI

**AI概要:** 该论文提出了同步进行模型和事件抽象的方法，解决了现有技术无法保持事件日志与模型一致性的限制，并基于行为轮廓抽象验证了方法的可行性。


<details>
  <summary>更多</summary>
  
**动机:** 当前在发现模型后缺乏能够同步抽象底层事件日志的技术，导致失去对实际行为的依据，限制了分析深度。因此需要开发同步抽象方法以提升分析效果。

**方法:** 论文采用行为轮廓抽象作为非顺序保留的MA技术，推导出一种新的EA技术，并通过理论证明验证了方法的可行性。

**结果:** 研究成功证明了通过MA抽象流程模型与从抽象事件日志中发现流程模型可以产生等效结果，为同步抽象提供了理论基础。

**结论:** 论文得出结论，同步的模型和事件抽象方法是可行的，并且能够保持底层事件日志与抽象模型之间的等效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Synchronizing+Process+Model+and+Event+Abstraction+for+Grounded+Process+Intelligence+%28Extended+Version%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23536&send_immediately=true&force_search=false)

**原文摘要:** Model abstraction (MA) and event abstraction (EA) are means to reduce
complexity of (discovered) models and event data. Imagine a process
intelligence project that aims to analyze a model discovered from event data
which is further abstracted, possibly multiple times, to reach optimality
goals, e.g., reducing model size. So far, after discovering the model, there is
no technique that enables the synchronized abstraction of the underlying event
log. This results in loosing the grounding in the real-world behavior contained
in the log and, in turn, restricts analysis insights. Hence, in this work, we
provide the formal basis for synchronized model and event abstraction, i.e., we
prove that abstracting a process model by MA and discovering a process model
from an abstracted event log yields an equivalent process model. We prove the
feasibility of our approach based on behavioral profile abstraction as
non-order preserving MA technique, resulting in a novel EA technique.

</details>


### [192] [SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](https://arxiv.org/abs/2505.23559)
*Kunlun Zhu, Jiaxun Zhang, Ziheng Qi, Nuoxing Shang, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You*

**主要类别:** cs.AI

**AI概要:** 本研究设计了提高AI科学家安全性和伦理责任的SafeScientist框架和评估基准SciSafetyBench。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型代理的最新进展加速了科学发现自动化，但也引发了重要的伦理和安全问题。

**方法:** 引入SafeScientist框架和SciSafetyBench基准，并集成多种防御机制进行全方位的安全监督。

**结果:** SafeScientist在传统AI科学家框架上提升了35%的安全性能，并通过对抗攻击验证了其安全性管道的有效性。

**结论:** SafeScientist框架显著提高了AI科学家在科学探索中的安全性和伦理责任感，同时保持了科研输出的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SafeScientist%3A+Toward+Risk-Aware+Scientific+Discoveries+by+LLM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23559，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23559&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in large language model (LLM) agents have significantly
accelerated scientific discovery automation, yet concurrently raised critical
ethical and safety concerns. To systematically address these challenges, we
introduce \textbf{SafeScientist}, an innovative AI scientist framework
explicitly designed to enhance safety and ethical responsibility in AI-driven
scientific exploration. SafeScientist proactively refuses ethically
inappropriate or high-risk tasks and rigorously emphasizes safety throughout
the research process. To achieve comprehensive safety oversight, we integrate
multiple defensive mechanisms, including prompt monitoring, agent-collaboration
monitoring, tool-use monitoring, and an ethical reviewer component.
Complementing SafeScientist, we propose \textbf{SciSafetyBench}, a novel
benchmark specifically designed to evaluate AI safety in scientific contexts,
comprising 240 high-risk scientific tasks across 6 domains, alongside 30
specially designed scientific tools and 120 tool-related risk tasks. Extensive
experiments demonstrate that SafeScientist significantly improves safety
performance by 35\% compared to traditional AI scientist frameworks, without
compromising scientific output quality. Additionally, we rigorously validate
the robustness of our safety pipeline against diverse adversarial attack
methods, further confirming the effectiveness of our integrated approach. The
code and data will be available at https://github.com/ulab-uiuc/SafeScientist.
\textcolor{red}{Warning: this paper contains example data that may be offensive
or harmful.}

</details>


### [193] [CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring](https://arxiv.org/abs/2505.23575)
*Benjamin Arnav, Pablo Bernabeu-Pérez, Nathan Helm-Burger, Tim Kostolansky, Hannes Whittingham, Mary Phuong*

**主要类别:** cs.AI

**AI概要:** 这篇论文探讨了一种混合监控协议，用于提升对具有潜在有害行为AI模型的检测能力，特别是在复杂推理过程中。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI模型自主性的增加，确保它们不会在未被察觉的情况下采取有害行为变得尤为重要。

**方法:** 论文通过红队设置进行实验，比较了链式思维监控、仅行动监控以及混合监控的效果，其中混合监控通过加权平均独立评分推理过程和最终输出来实现。

**结果:** 研究发现，链式思维监控在某些场景下比仅行动监控提高了高达27个百分点的检测效果，但在明显破坏案例中可能因误导性推理而降低性能；引入的混合监控协议显著提升了检测率。

**结论:** 论文得出结论，混合监控协议在所有测试模型和任务中都优于链式思维（CoT）监控和仅行动监控，尤其是在细微欺骗场景下检测率更高。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoT+Red-Handed%3A+Stress+Testing+Chain-of-Thought+Monitoring，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23575，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23575&send_immediately=true&force_search=false)

**原文摘要:** As AI models are deployed with increasing autonomy, it is important to ensure
they do not take harmful actions unnoticed. As a potential mitigation, we
investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor
model continuously oversees the intermediate reasoning steps of a more powerful
but untrusted model. We compare CoT monitoring to action-only monitoring, where
only final outputs are reviewed, in a red-teaming setup where the untrusted
model is instructed to pursue harmful side tasks while completing a coding
problem. We find that CoT monitoring improves detection by up to 27 percentage
points in scenarios where action-only monitoring fails to reliably identify
sabotage. However, CoT traces can also contain misleading rationalizations that
deceive the monitor, reducing performance in more obvious sabotage cases. To
address this, we introduce a hybrid protocol that independently scores both
reasoning and final outputs and combines them using a weighted average. This
hybrid monitor consistently outperforms both CoT and action-only monitors
across all tested models and tasks, with detection rates over four times higher
than action-only monitoring for subtle deception scenarios.

</details>


### [194] [MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning](https://arxiv.org/abs/2505.23596)
*Linqiang Guo, Wei Liu, Yi Wen Heng, Tse-Hsun, Chen, Yang Wang*

**主要类别:** cs.AI

**AI概要:** MAPLE introduces structured state-aware modeling for mobile GUI agents using a Finite State Machine, significantly enhancing task execution and error recovery performance.


<details>
  <summary>更多</summary>
  
**动机:** Existing mobile GUI agents are reactive and lack structured context understanding, leading to limited error recovery and task success capabilities.

**方法:** MAPLE framework models UI screens as states and user actions as transitions within a Finite State Machine (FSM), enabling structured app interaction tracking and error recovery.

**结果:** MAPLE improves task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5% on cross-app benchmarks Mobile-Eval-E and SPA-Bench.

**结论:** Structured state modeling is crucial for improving the performance of mobile GUI agents, and the FSM representation can serve as a lightweight memory layer in future agent architectures.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAPLE%3A+A+Mobile+Assistant+with+Persistent+Finite+State+Machines+for+Recovery+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23596，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23596&send_immediately=true&force_search=false)

**原文摘要:** Mobile GUI agents aim to autonomously complete user-instructed tasks across
mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable
these agents to interpret UI screens, identify actionable elements, and perform
interactions such as tapping or typing. However, existing agents remain
reactive: they reason only over the current screen and lack a structured model
of app navigation flow, limiting their ability to understand context, detect
unexpected outcomes, and recover from errors. We present MAPLE, a state-aware
multi-agent framework that abstracts app interactions as a Finite State Machine
(FSM). We computationally model each UI screen as a discrete state and user
actions as transitions, allowing the FSM to provide a structured representation
of the app execution. MAPLE consists of specialized agents responsible for four
phases of task execution: planning, execution, verification, error recovery,
and knowledge retention. These agents collaborate to dynamically construct FSMs
in real time based on perception data extracted from the UI screen, allowing
the GUI agents to track navigation progress and flow, validate action outcomes
through pre- and post-conditions of the states, and recover from errors by
rolling back to previously stable states. Our evaluation results on two
challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE
outperforms the state-of-the-art baseline, improving task success rate by up to
12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results
highlight the importance of structured state modeling in guiding mobile GUI
agents during task execution. Moreover, our FSM representation can be
integrated into future GUI agent architectures as a lightweight, model-agnostic
memory layer to support structured planning, execution verification, and error
recovery.

</details>


### [195] [Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models](https://arxiv.org/abs/2505.23667)
*Lang Cao, Jingxian Xu, Hanbing Liu, Jinyu Wang, Mengyu Zhou, Haoyu Dong, Shi Han, Dongmei Zhang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为 Formula Tuning (Fortune) 的强化学习框架，该框架能够提升大型语言模型在表格理解和符号推理方面的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型具有强大的一般推理能力，但在复杂场景下对表格数据的准确数值或符号推理仍然存在困难。

**方法:** 使用二元答案正确性作为奖励信号的强化学习框架，训练大型语言模型生成可执行的电子表格公式以进行问答。

**结果:** 通过七个表格推理基准的广泛实验验证了其有效性，并显著提高了7B模型在表格理解任务中的表现。

**结论:** Formula Tuning (Fortune) 是一种强化学习框架，可以提高大型语言模型在表格理解任务中的性能，特别是在多步骤数值和符号推理任务中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fortune%3A+Formula-Driven+Reinforcement+Learning+for+Symbolic+Table+Reasoning+in+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23667，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23667&send_immediately=true&force_search=false)

**原文摘要:** Tables are a fundamental structure for organizing and analyzing data, making
effective table understanding a critical capability for intelligent systems.
While large language models (LMs) demonstrate strong general reasoning
abilities, they continue to struggle with accurate numerical or symbolic
reasoning over tabular data, especially in complex scenarios. Spreadsheet
formulas provide a powerful and expressive medium for representing executable
symbolic operations, encoding rich reasoning patterns that remain largely
underutilized. In this paper, we propose Formula Tuning (Fortune), a
reinforcement learning (RL) framework that trains LMs to generate executable
spreadsheet formulas for question answering over general tabular data. Formula
Tuning reduces the reliance on supervised formula annotations by using binary
answer correctness as a reward signal, guiding the model to learn formula
derivation through reasoning. We provide a theoretical analysis of its
advantages and demonstrate its effectiveness through extensive experiments on
seven table reasoning benchmarks. Formula Tuning substantially enhances LM
performance, particularly on multi-step numerical and symbolic reasoning tasks,
enabling a 7B model to outperform O1 on table understanding. This highlights
the potential of formula-driven RL to advance symbolic table reasoning in LMs.

</details>


### [196] [ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork](https://arxiv.org/abs/2505.23686)
*Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种新的统一框架ROTATE，用于解决Ad Hoc Teamwork问题，通过开放式学习过程提高AI代理与未知队友的合作能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的AHT方法通常采用两阶段流程，但这种方法生成的队友池覆盖范围有限，并且忽略了这些队友是否易于AHT代理学习。

**方法:** ROTATE是一种基于遗憾驱动的开放式训练算法，通过交替改进AHT代理和生成挑战其缺陷的队友来实现协作优化。

**结果:** ROTATE在各种AHT环境中都表现出卓越的性能，特别是在推广到未见过的评估队友方面。

**结论:** ROTATE在面对之前未见过的队友时，显著优于基线方法，为鲁棒和可推广的团队合作建立了新标准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ROTATE%3A+Regret-driven+Open-ended+Training+for+Ad+Hoc+Teamwork，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23686&send_immediately=true&force_search=false)

**原文摘要:** Developing AI agents capable of collaborating with previously unseen partners
is a fundamental generalization challenge in multi-agent learning, known as Ad
Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage
pipeline, where first, a fixed population of teammates is generated with the
idea that they should be representative of the teammates that will be seen at
deployment time, and second, an AHT agent is trained to collaborate well with
agents in the population. To date, the research community has focused on
designing separate algorithms for each stage. This separation has led to
algorithms that generate teammate pools with limited coverage of possible
behaviors, and that ignore whether the generated teammates are easy to learn
from for the AHT agent. Furthermore, algorithms for training AHT agents
typically treat the set of training teammates as static, thus attempting to
generalize to previously unseen partner agents without assuming any control
over the distribution of training teammates. In this paper, we present a
unified framework for AHT by reformulating the problem as an open-ended
learning process between an ad hoc agent and an adversarial teammate generator.
We introduce ROTATE, a regret-driven, open-ended training algorithm that
alternates between improving the AHT agent and generating teammates that probe
its deficiencies. Extensive experiments across diverse AHT environments
demonstrate that ROTATE significantly outperforms baselines at generalizing to
an unseen set of evaluation teammates, thus establishing a new standard for
robust and generalizable teamwork.

</details>


### [197] [Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics](https://arxiv.org/abs/2505.23695)
*Ran Zhang, Mohannad Elhamod*

**主要类别:** cs.AI

**AI概要:** 提出了一种新的基于LLM代理的数据到仪表板自动化系统，提升了数据分析的洞察力和领域适应性。


<details>
  <summary>更多</summary>
  
**动机:** 现有图表问答系统依赖封闭本体或问题模板，而本文旨在模拟商业分析师的分析推理过程，提高洞察力生成和可视化的智能化水平。

**方法:** 通过利用LLM代理创建一个自动化数据到仪表板流水线的智能系统，该系统能够进行领域检测、概念提取、多视角分析生成和迭代自我反思。

**结果:** 在三个不同领域的数据集上评估了该系统，与基于GPT-4o的单提示基线相比，证明了其在洞察力、领域相关性和分析深度方面的提升。

**结论:** 本文提出了一个新的模块化流水线，用于弥合从原始数据到可视化的路径，并为人机协作的业务分析开辟了新机会。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-to-Dashboard%3A+Multi-Agent+LLM+Framework+for+Insightful+Visualization+in+Enterprise+Analytics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23695，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23695&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of LLMs has led to the creation of diverse agentic
systems in data analysis, utilizing LLMs' capabilities to improve insight
generation and visualization. In this paper, we present an agentic system that
automates the data-to-dashboard pipeline through modular LLM agents capable of
domain detection, concept extraction, multi-perspective analysis generation,
and iterative self-reflection. Unlike existing chart QA systems, our framework
simulates the analytical reasoning process of business analysts by retrieving
domain-relevant knowledge and adapting to diverse datasets without relying on
closed ontologies or question templates.
  We evaluate our system on three datasets across different domains.
Benchmarked against GPT-4o with a single-prompt baseline, our approach shows
improved insightfulness, domain relevance, and analytical depth, as measured by
tailored evaluation metrics and qualitative human assessment.
  This work contributes a novel modular pipeline to bridge the path from raw
data to visualization, and opens new opportunities for human-in-the-loop
validation by domain experts in business analytics. All code can be found here:
https://github.com/77luvC/D2D_Data2Dashboard

</details>


### [198] [Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability](https://arxiv.org/abs/2505.23703)
*Ruida Wang, Yuxin Li, Yi R., Fung, Tong Zhang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种结合自然语言和形式语言推理能力的新框架NL-FL HybridReasoning，显著提高了数学问题解决能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有强化学习方法难以赋予基础模型未具备的能力，因此需要有效整合形式语言知识到自然语言数学推理中。

**方法:** 提出了NL-FL Problem Alignment方法、Mixed Problem Input技术和Answer Extraction机制以整合自然语言与形式语言的推理能力。

**结果:** 在MATH-500和AMC基准测试中分别达到了89.80%和84.34%的准确率，超过自然语言基线模型。

**结论:** NL-FL HybridReasoning框架有效提升了数学推理能力，特别是在MATH-500和AMC基准测试中表现优异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Let%27s+Reason+Formally%3A+Natural-Formal+Hybrid+Reasoning+Enhances+LLM%27s+Math+Capability，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23703&send_immediately=true&force_search=false)

**原文摘要:** Enhancing the mathematical reasoning capabilities of LLMs has garnered
significant attention in both the mathematical and computer science
communities. Recent works have made substantial progress in both Natural
Language (NL) reasoning and Formal Language (FL) reasoning by leveraging the
potential of pure Reinforcement Learning (RL) methods on base models. However,
RL approaches struggle to impart new capabilities not presented in the base
model, highlighting the need to integrate more knowledge like FL into NL math
reasoning effectively. Yet, this integration is challenging due to inherent
disparities in problem structure and reasoning format between NL and FL. To
address these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end
framework designed to incorporate the FL expert into NL math problem-solving.
To bridge the NL and FL input format gap, we propose the *NL-FL Problem
Alignment* method, which reformulates the Question-Answering (QA) problems in
NL as existence theorems in FL. Subsequently, the *Mixed Problem Input*
technique we provide enables the FL reasoner to handle both QA and existence
problems concurrently. Lastly, we mitigate the NL and FL output format gap in
reasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive
experiments demonstrate that the **HybridReasoning** framework achieves
**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC
benchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.
Notably, some problems resolved by our framework remain unsolved by the NL
baseline model even under a larger number of trials.

</details>


### [199] [Comparative of Genetic Fuzzy regression techniques for aeroacoustic phenomenons](https://arxiv.org/abs/2505.23746)
*Hugo Henry, Kelly Cohen*

**主要类别:** cs.AI

**AI概要:** This paper explores the use of Genetic Fuzzy Systems to model airfoil self-noise, comparing different fuzzy regression strategies and highlighting the effectiveness of clustering-assisted fuzzy inference.


<details>
  <summary>更多</summary>
  
**动机:** Modeling airfoil self-noise is crucial in aeroacoustics with significant applications in aerospace, automotive, and drone industries. 

**方法:** The study employs various Fuzzy regression strategies including a brute force Takagi Sugeno Kang (TSK) fuzzy system, a cascading Genetic Fuzzy Tree (GFT) architecture, and a novel clustered approach based on Fuzzy C-means (FCM).

**结果:** Different fuzzy regression methods are explored and compared, emphasizing the potential of clustering-based approaches to reduce model complexity and effectively model self-noise.

**结论:** Clustering assisted fuzzy inference is a viable and effective regression tool for modeling complex aeroacoustic phenomena like airfoil self-noise.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparative+of+Genetic+Fuzzy+regression+techniques+for+aeroacoustic+phenomenons，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23746，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23746&send_immediately=true&force_search=false)

**原文摘要:** This study investigates the application of Genetic Fuzzy Systems (GFS) to
model the self-noise generated by airfoils, a key issue in aeroaccoustics with
significant implications for aerospace, automotive and drone applications.
Using the publicly available Airfoil Self Noise dataset, various Fuzzy
regression strategies are explored and compared. The paper evaluates a brute
force Takagi Sugeno Kang (TSK) fuzzy system with high rule density, a cascading
Geneti Fuzzy Tree (GFT) architecture and a novel clustered approach based on
Fuzzy C-means (FCM) to reduce the model's complexity. This highlights the
viability of clustering assisted fuzzy inference as an effective regression
tool for complex aero accoustic phenomena. Keywords : Fuzzy logic, Regression,
Cascading systems, Clustering and AI.

</details>


### [200] [ZeroGUI: Automating Online GUI Learning at Zero Human Cost](https://arxiv.org/abs/2505.23762)
*Chenyu Yang, Shiqian Su, Shi Liu, Xuan Dong, Yue Yu, Weijie Su, Xuehui Wang, Zhaoyang Liu, Jinguo Zhu, Hao Li, Wenhai Wang, Yu Qiao, Xizhou Zhu, Jifeng Dai*

**主要类别:** cs.AI

**AI概要:** ZeroGUI提出了一种新的在线学习框架，通过基于大视觉语言模型的方法实现自动化任务生成与奖励评估，从而提高GUI代理在复杂环境中的自主学习能力，解决了传统方法对人工标注和静态环境的依赖问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的纯视觉GUI代理方法依赖高质量的手动标注，并且难以适应动态交互环境，因此需要一种零人工成本的在线学习框架。

**方法:** ZeroGUI整合了基于VLM的自动任务生成、奖励估计和两阶段在线强化学习机制，以实现对GUI Agent的自动化训练。

**结果:** 实验结果显示，ZeroGUI在OSWorld和AndroidLab环境中显著提升了两个先进GUI Agent（UI-TARS和Aguvis）的性能。

**结论:** ZeroGUI是一个无需人工成本的可扩展在线学习框架，能够显著提升GUI Agent在动态环境中的性能。实验表明其在UI-TARS和Aguvis上的表现优异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ZeroGUI%3A+Automating+Online+GUI+Learning+at+Zero+Human+Cost，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23762，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23762&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of large Vision-Language Models (VLMs) has propelled
the development of pure-vision-based GUI Agents, capable of perceiving and
operating Graphical User Interfaces (GUI) to autonomously fulfill user
instructions. However, existing approaches usually adopt an offline learning
framework, which faces two core limitations: (1) heavy reliance on high-quality
manual annotations for element grounding and action supervision, and (2)
limited adaptability to dynamic and interactive environments. To address these
limitations, we propose ZeroGUI, a scalable, online learning framework for
automating GUI Agent training at Zero human cost. Specifically, ZeroGUI
integrates (i) VLM-based automatic task generation to produce diverse training
goals from the current environment state, (ii) VLM-based automatic reward
estimation to assess task success without hand-crafted evaluation functions,
and (iii) two-stage online reinforcement learning to continuously interact with
and learn from GUI environments. Experiments on two advanced GUI Agents
(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance
across OSWorld and AndroidLab environments. The code is available at
https://github.com/OpenGVLab/ZeroGUI.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [201] [Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games](https://arxiv.org/abs/2505.22781)
*Antonio Ocello, Daniil Tiapkin, Lorenzo Mancini, Mathieu Laurière, Eric Moulines*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种名为MF-TRPO的新算法，用于计算平均场博弈中的近似纳什均衡，并结合了强化学习的技术，在理论上和实践中都表现出了良好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了将强化学习技术与平均场决策相结合，从而解决多智能体系统的复杂优化问题。

**方法:** 基于强化学习中的TRPO方法，扩展其方法论到平均场博弈框架，提出了一种新的计算近似纳什均衡的算法MF-TRPO。

**结果:** MF-TRPO算法不仅在理论上被严格分析并提供了收敛性的保证，而且在样本基础上的形式中也获得了高概率保证和有限样本复杂度的结果。

**结论:** MF-TRPO算法为解决复杂的多智能体问题提供了一个理论基础扎实的方法，并且在稳定性与鲁棒性方面表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Finite-Sample+Convergence+Bounds+for+Trust+Region+Policy+Optimization+in+Mean-Field+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22781，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22781&send_immediately=true&force_search=false)

**原文摘要:** We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel
algorithm designed to compute approximate Nash equilibria for ergodic
Mean-Field Games (MFG) in finite state-action spaces. Building on the
well-established performance of TRPO in the reinforcement learning (RL)
setting, we extend its methodology to the MFG framework, leveraging its
stability and robustness in policy optimization. Under standard assumptions in
the MFG literature, we provide a rigorous analysis of MF-TRPO, establishing
theoretical guarantees on its convergence. Our results cover both the exact
formulation of the algorithm and its sample-based counterpart, where we derive
high-probability guarantees and finite sample complexity. This work advances
MFG optimization by bridging RL techniques with mean-field decision-making,
offering a theoretically grounded approach to solving complex multi-agent
problems.

</details>


### [202] [Highly Efficient and Effective LLMs with Multi-Boolean Architectures](https://arxiv.org/abs/2505.22811)
*Ba-Hien Tran, Van Minh Nguyen*

**主要类别:** stat.ML

**AI概要:** 本文介绍了一种新的大型语言模型二值化方法，可在不使用全精度潜在权重的情况下直接在布尔域微调模型，有效降低复杂度并提升性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的权重二值化方法要么导致信息损失严重，要么依赖全精度潜在权重，带来次优性能和高复杂度。因此需要一种更高效的方法来解决这些问题。

**方法:** 引入了一个新框架，将大型语言模型有效地转换为多核布尔参数，并直接在布尔域中对其进行微调。

**结果:** 通过广泛的实验表明，该方法在多种大型语言模型上均优于近期的超低比特量化和二值化方法。

**结论:** 本文提出了一种新颖的框架，首次直接在布尔域中对大型语言模型进行微调，无需昂贵的潜在权重，从而显著降低了微调和推理的复杂性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Highly+Efficient+and+Effective+LLMs+with+Multi-Boolean+Architectures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22811，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22811&send_immediately=true&force_search=false)

**原文摘要:** Weight binarization has emerged as a promising strategy to drastically reduce
the complexity of large language models (LLMs). It is mainly classified into
two approaches: post-training binarization and finetuning with training-aware
binarization methods. The first approach, while having low complexity, leads to
significant loss of information from the original LLMs, resulting in poor
performance. The second approach, on the other hand, relies heavily on
full-precision latent weights for gradient approximation of binary weights,
which not only remains suboptimal but also introduces substantial complexity.
In this paper, we introduce a novel framework that effectively transforms LLMs
into multi-kernel Boolean parameters, for the first time, finetunes them
directly in the Boolean domain, eliminating the need for expensive latent
weights. This significantly reduces complexity during both finetuning and
inference. Through extensive and insightful experiments across a wide range of
LLMs, we demonstrate that our method outperforms recent ultra low-bit
quantization and binarization methods.

</details>


### [203] [Theoretical Foundations of the Deep Copula Classifier: A Generative Approach to Modeling Dependent Features](https://arxiv.org/abs/2505.22997)
*Agnideep Aich, Ashit Baran Aich, Bruce Wade*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种名为Deep Copula Classifier (DCC)的新方法，用于解决传统分类器在处理现实世界复杂依赖关系时表现不佳的问题。


<details>
  <summary>更多</summary>
  
**动机:** 传统的分类器通常假设特征独立或依赖过于简单的关联关系，导致在现实世界中依赖关系复杂的场景下表现不佳。

**方法:** DCC通过使用轻量级神经网络参数化copula函数，将每个特征的边缘分布学习与它们的联合依赖结构建模分离。

**结果:** DCC被证明在标准条件下收敛到贝叶斯最优分类器，并为复杂依赖驱动的分类任务提供了多种实用扩展。

**结论:** DCC是一种结合了统计学严谨性和神经网络表示能力的依赖感知分类框架，提供了数学基础和可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Theoretical+Foundations+of+the+Deep+Copula+Classifier%3A+A+Generative+Approach+to+Modeling+Dependent+Features，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.22997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.22997&send_immediately=true&force_search=false)

**原文摘要:** Traditional classifiers often assume feature independence or rely on overly
simplistic relationships, leading to poor performance in settings where
real-world dependencies matter. We introduce the Deep Copula Classifier (DCC),
a generative model that separates the learning of each feature's marginal
distribution from the modeling of their joint dependence structure via neural
network-parameterized copulas. For each class, lightweight neural networks are
used to flexibly and adaptively capture feature interactions, making DCC
particularly effective when classification is driven by complex dependencies.
We establish that DCC converges to the Bayes-optimal classifier under standard
conditions and provide explicit convergence rates of O(n^{-r/(2r + d)}) for
r-smooth copula densities. Beyond theoretical guarantees, we outline several
practical extensions, including high-dimensional scalability through vine and
factor copula architectures, semi-supervised learning via entropy
regularization, and online adaptation using streaming gradient methods. By
unifying statistical rigor with the representational power of neural networks,
DCC offers a mathematically grounded and interpretable framework for
dependency-aware classification.

</details>


### [204] [JAPAN: Joint Adaptive Prediction Areas with Normalising-Flows](https://arxiv.org/abs/2505.23196)
*Eshant English, Christoph Lippert*

**主要类别:** stat.ML

**AI概要:** JAPAN是一种基于密度分数的共形预测框架，能构造出紧凑、自适应且具有理论保障的预测区域。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于残差的共形分数在多模态分布下表现不佳，往往产生过于保守且无法捕捉复杂分布真实形状的预测区域。

**方法:** 利用基于流的模型估计预测密度，并根据密度分数进行阈值分割以构造预测区域。

**结果:** JAPAN在多元回归和预测任务中展现了良好的校准效果以及更紧凑的预测区域，同时提供了框架扩展以增加灵活性。

**结论:** JAPAN通过使用基于密度的共形分数，提供了一种更灵活、紧凑且适应性强的预测区域构建方法，并保留了有限样本下的覆盖率保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是JAPAN%3A+Joint+Adaptive+Prediction+Areas+with+Normalising-Flows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23196，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23196&send_immediately=true&force_search=false)

**原文摘要:** Conformal prediction provides a model-agnostic framework for uncertainty
quantification with finite-sample validity guarantees, making it an attractive
tool for constructing reliable prediction sets. However, existing approaches
commonly rely on residual-based conformity scores, which impose geometric
constraints and struggle when the underlying distribution is multimodal. In
particular, they tend to produce overly conservative prediction areas centred
around the mean, often failing to capture the true shape of complex predictive
distributions. In this work, we introduce JAPAN (Joint Adaptive Prediction
Areas with Normalising-Flows), a conformal prediction framework that uses
density-based conformity scores. By leveraging flow-based models, JAPAN
estimates the (predictive) density and constructs prediction areas by
thresholding on the estimated density scores, enabling compact, potentially
disjoint, and context-adaptive regions that retain finite-sample coverage
guarantees. We theoretically motivate the efficiency of JAPAN and empirically
validate it across multivariate regression and forecasting tasks, demonstrating
good calibration and tighter prediction areas compared to existing baselines.
We also provide several \emph{extensions} adding flexibility to our proposed
framework.

</details>


### [205] [Stable Thompson Sampling: Valid Inference via Variance Inflation](https://arxiv.org/abs/2505.23260)
*Budhaditya Halder, Shubhayan Pan, Koulik Khamaru*

**主要类别:** stat.ML

**AI概要:** 这篇论文讨论了如何通过一种新的稳定汤普森抽样方法，在保证效果的同时，解决自适应抽样方案带来的统计推断问题。


<details>
  <summary>更多</summary>
  
**动机:** 研究的动机是汤普森抽样（TS）虽然在实践中有效且渐近最优，但其自适应抽样方案给模型参数的置信区间构造带来了挑战。

**方法:** 论文提出并分析了一种称为稳定汤普森抽样（Stable Thompson Sampling）的方法，其中后验方差被放大了一个对数因子。

**结果:** 研究表明，这种修改导致了臂均值估计的渐近正态性，尽管数据不是独立同分布的。此外，与标准TS相比，方差膨胀仅使遗憾增加了一个对数因子。

**结论:** 该论文得出结论，通过支付较小的遗憾代价，可以实现对自适应决策算法的有效统计推断。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stable+Thompson+Sampling%3A+Valid+Inference+via+Variance+Inflation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23260&send_immediately=true&force_search=false)

**原文摘要:** We consider the problem of statistical inference when the data is collected
via a Thompson Sampling-type algorithm. While Thompson Sampling (TS) is known
to be both asymptotically optimal and empirically effective, its adaptive
sampling scheme poses challenges for constructing confidence intervals for
model parameters. We propose and analyze a variant of TS, called Stable
Thompson Sampling, in which the posterior variance is inflated by a logarithmic
factor. We show that this modification leads to asymptotically normal estimates
of the arm means, despite the non-i.i.d. nature of the data. Importantly, this
statistical benefit comes at a modest cost: the variance inflation increases
regret by only a logarithmic factor compared to standard TS. Our results reveal
a principled trade-off: by paying a small price in regret, one can enable valid
statistical inference for adaptive decision-making algorithms.

</details>


### [206] [The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation](https://arxiv.org/abs/2505.23445)
*Adrien Majka, El-Mahdi El-Mhamdi*

**主要类别:** stat.ML

**AI概要:** 该研究探讨了在不同尾部特性下代理指标与目标之间的耦合如何影响Goodhart定律的表现。


<details>
  <summary>更多</summary>
  
**动机:** 随着机器学习模型和优化能力的发展，越来越多的实证证据支持Goodhart定律的有效性，但缺乏形式化的理论解释。

**方法:** 通过放松先前研究中的独立性假设和学习范式假设，分析代理指标与目标之间的耦合效应对Goodhart定律的影响。

**结果:** 在轻尾目标和轻尾差异的情况下，依赖关系不会改变Goodhart效应的本质；但在轻尾目标和重尾差异的情况下，过度优化可能以与差异重尾性成反比的速度发生。

**结论:** 研究揭示了在特定条件下，优化代理指标可能导致与预期目标的过度偏离，从而验证了Goodhart定律的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Strong%2C+Weak+and+Benign+Goodhart%27s+law.+An+independence-free+and+paradigm-agnostic+formalisation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23445，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23445&send_immediately=true&force_search=false)

**原文摘要:** Goodhart's law is a famous adage in policy-making that states that ``When a
measure becomes a target, it ceases to be a good measure''. As machine learning
models and the optimisation capacity to train them grow, growing empirical
evidence reinforced the belief in the validity of this law without however
being formalised. Recently, a few attempts were made to formalise Goodhart's
law, either by categorising variants of it, or by looking at how optimising a
proxy metric affects the optimisation of an intended goal. In this work, we
alleviate the simplifying independence assumption, made in previous works, and
the assumption on the learning paradigm made in most of them, to study the
effect of the coupling between the proxy metric and the intended goal on
Goodhart's law. Our results show that in the case of light tailed goal and
light tailed discrepancy, dependence does not change the nature of Goodhart's
effect. However, in the light tailed goal and heavy tailed discrepancy case, we
exhibit an example where over-optimisation occurs at a rate inversely
proportional to the heavy tailedness of the discrepancy between the goal and
the metric. %

</details>


### [207] [Learning Parametric Distributions from Samples and Preferences](https://arxiv.org/abs/2505.23557)
*Marc Jourdan, Gizem Yüce, Nicolas Flammarion*

**主要类别:** stat.ML

**AI概要:** 本文研究了偏好反馈在参数估计中的作用，提出一种新估计器，理论上证明其比传统方法具有更快的收敛速度，尤其适用于高斯或拉普拉斯分布等场景。


<details>
  <summary>更多</summary>
  
**动机:** 近年来语言模型的发展表明，偏好反馈在提升模型性能方面具有重要作用。本文旨在从统计学角度分析偏好反馈如何影响参数估计，并探索其在连续参数分布中的潜在优势。

**方法:** 论文采用M-估计量框架，结合偏好反馈和硬约束条件，提出了一种新的估计器，并通过理论分析推导了其渐进方差和误差界。此外，还建立了一个匹配的下界来证明该方法的最优性。

**结果:** 研究显示，基于偏好的M-估计量比仅依赖样本的估计量具有更小的渐进方差；特别是当引入确定性偏好时，估计误差可以达到O(1/n)的收敛速度，远优于传统方法的Θ(1/√n)。

**结论:** 论文得出偏好反馈能够显著提升参数估计的效果，并且通过确定性偏好可以进一步改善估计误差，达到了比仅使用样本的传统方法更优的收敛速率。这一成果在某些特定分布（如高斯分布、拉普拉斯分布）中得到了验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Parametric+Distributions+from+Samples+and+Preferences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23557，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23557&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in language modeling have underscored the role of preference
feedback in enhancing model performance. This paper investigates the conditions
under which preference feedback improves parameter estimation in classes of
continuous parametric distributions. In our framework, the learner observes
pairs of samples from an unknown distribution along with their relative
preferences depending on the same unknown parameter. We show that
preference-based M-estimators achieve a better asymptotic variance than
sample-only M-estimators, further improved by deterministic preferences.
Leveraging the hard constraints revealed by deterministic preferences, we
propose an estimator achieving an estimation error scaling of
$\mathcal{O}(1/n)$ -- a significant improvement over the $\Theta(1/\sqrt{n})$
rate attainable with samples alone. Next, we establish a lower bound that
matches this accelerated rate; up to dimension and problem-dependent constants.
While the assumptions underpinning our analysis are restrictive, they are
satisfied by notable cases such as Gaussian or Laplace distributions for
preferences based on the log-probability reward.

</details>


### [208] [Multilook Coherent Imaging: Theoretical Guarantees and Algorithms](https://arxiv.org/abs/2505.23594)
*Xi Chen, Soham Jana, Christopher A. Metzler, Arian Maleki, Shirin Jalali*

**主要类别:** stat.ML

**AI概要:** 这篇论文探讨了多视角相干成像中的似然方法，提供了理论分析和高效的算法实现，解决了乘性噪声问题并取得了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 论文动机是解决多视角相干成像中存在的乘性噪声问题，这会降低图像质量，而现有的理论基础仍相对未被充分探索。

**方法:** 采用投影梯度下降（PGD）来计算最大似然解，并引入了两种关键技术：牛顿-舒尔茨算法用于计算矩阵逆，装袋策略用于减轻投影误差。

**结果:** 研究结果包括建立了最大似然估计量在深度图像先验假设下的均方误差（MSE）的第一个理论上界，并展示了MSE与多个参数之间的依赖关系。

**结论:** 论文得出结论，通过结合牛顿-舒尔茨算法和装袋策略的PGD方法，在多视角相干成像中取得了最先进的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilook+Coherent+Imaging%3A+Theoretical+Guarantees+and+Algorithms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23594，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23594&send_immediately=true&force_search=false)

**原文摘要:** Multilook coherent imaging is a widely used technique in applications such as
digital holography, ultrasound imaging, and synthetic aperture radar. A central
challenge in these systems is the presence of multiplicative noise, commonly
known as speckle, which degrades image quality. Despite the widespread use of
coherent imaging systems, their theoretical foundations remain relatively
underexplored. In this paper, we study both the theoretical and algorithmic
aspects of likelihood-based approaches for multilook coherent imaging,
providing a rigorous framework for analysis and method development. Our
theoretical contributions include establishing the first theoretical upper
bound on the Mean Squared Error (MSE) of the maximum likelihood estimator under
the deep image prior hypothesis. Our results capture the dependence of MSE on
the number of parameters in the deep image prior, the number of looks, the
signal dimension, and the number of measurements per look. On the algorithmic
side, we employ projected gradient descent (PGD) as an efficient method for
computing the maximum likelihood solution. Furthermore, we introduce two key
ideas to enhance the practical performance of PGD. First, we incorporate the
Newton-Schulz algorithm to compute matrix inverses within the PGD iterations,
significantly reducing computational complexity. Second, we develop a bagging
strategy to mitigate projection errors introduced during PGD updates. We
demonstrate that combining these techniques with PGD yields state-of-the-art
performance. Our code is available at
https://github.com/Computational-Imaging-RU/Bagged-DIP-Speckle.

</details>


### [209] [Instance-Optimality for Private KL Distribution Estimation](https://arxiv.org/abs/2505.23620)
*Jiayuan Ye, Vitaly Feldman, Kunal Talwar*

**主要类别:** stat.ML

**AI概要:** 该论文研究了在给定独立同分布样本的情况下，如何最小化未知离散分布估计中的KL散度，并探讨了在有无差分隐私约束下的实例最优性问题。


<details>
  <summary>更多</summary>
  
**动机:** 最小化真实分布与算法估计之间的KL散度，关注于个体（非最坏情况）实例上的性能优化。

**方法:** 论文使用了Good-Turing估计器的（私有）变种来实现实例最优性，并利用加法局部邻域来更精确地捕捉KL散度下分布估计的难度。

**结果:** 构建了极小极大最优私有估计器，并提出了在KL散度下更精确捕捉分布估计难度的加法局部邻域方法。

**结论:** 论文得出了一些在特定实例优化性能下的算法误差上界和下界，并提出了一些在有无差分隐私约束下达到实例最优性的算法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Instance-Optimality+for+Private+KL+Distribution+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23620，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23620&send_immediately=true&force_search=false)

**原文摘要:** We study the fundamental problem of estimating an unknown discrete
distribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the
distribution. We are interested in minimizing the KL divergence between the
true distribution and the algorithm's estimate. We first construct minimax
optimal private estimators. Minimax optimality however fails to shed light on
an algorithm's performance on individual (non-worst-case) instances $p$ and
simple minimax-optimal DP estimators can have poor empirical performance on
real distributions. We then study this problem from an instance-optimality
viewpoint, where the algorithm's error on $p$ is compared to the minimum
achievable estimation error over a small local neighborhood of $p$. Under
natural notions of local neighborhood, we propose algorithms that achieve
instance-optimality up to constant factors, with and without a differential
privacy constraint. Our upper bounds rely on (private) variants of the
Good-Turing estimator. Our lower bounds use additive local neighborhoods that
more precisely captures the hardness of distribution estimation in KL
divergence, compared to ones considered in prior works.

</details>


### [210] [On the Convergence Analysis of Muon](https://arxiv.org/abs/2505.23737)
*Wei Shen, Ruichuan Huang, Minhui Huang, Cong Shen, Jiawei Zhang*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种针对矩阵参数结构的优化器Muon的收敛速度分析，并解释了其优于传统梯度下降的原因。


<details>
  <summary>更多</summary>
  
**动机:** 现有的优化器将矩阵参数视为扁平化向量，忽略了其结构特性，而Muon专为优化矩阵参数设计，但其理论理解仍有限。

**方法:** 对Muon进行收敛率分析，并与梯度下降（GD）进行比较，探讨Muon在何种条件下优于GD。

**结果:** 理论结果表明，Muon可以从Hessian矩阵的低秩和近似分块对角结构中受益，这在实际神经网络训练中广泛存在。实验结果支持理论发现。

**结论:** 本文通过理论分析揭示了Muon优于GD的条件，并通过实验验证了这些理论发现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Convergence+Analysis+of+Muon，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.23737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.23737&send_immediately=true&force_search=false)

**原文摘要:** The majority of parameters in neural networks are naturally represented as
matrices. However, most commonly used optimizers treat these matrix parameters
as flattened vectors during optimization, potentially overlooking their
inherent structural properties. Recently, an optimizer called Muon has been
proposed, specifically designed to optimize matrix-structured parameters.
Extensive empirical evidence shows that Muon can significantly outperform
traditional optimizers when training neural networks. Nonetheless, the
theoretical understanding of Muon's convergence behavior and the reasons behind
its superior performance remain limited. In this work, we present a
comprehensive convergence rate analysis of Muon and its comparison with
Gradient Descent (GD). We further characterize the conditions under which Muon
can outperform GD. Our theoretical results reveal that Muon can benefit from
the low-rank and approximate blockwise diagonal structure of Hessian matrices
-- phenomena widely observed in practical neural network training. Our
experimental results support and corroborate the theoretical findings.

</details>
