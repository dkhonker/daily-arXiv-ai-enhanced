{"id": "2511.14777", "pdf": "https://arxiv.org/pdf/2511.14777", "abs": "https://arxiv.org/abs/2511.14777", "authors": ["Mahdi Samiei", "Mahdi Mansouri", "Mahdieh Soleymani Baghshah"], "title": "The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.", "AI": {"tldr": "该研究引入有限状态机(FSM)执行作为评估大语言模型程序推理能力的透明框架，发现LLMs在多步推理中存在系统性性能下降，特别是在高分支复杂度的任务中表现更差。", "motivation": "虽然大语言模型在推理任务上表现优异，但其执行多步、基于规则的计算程序推理能力尚不明确，缺乏可控、可解释的基准来测量这种能力退化。", "method": "使用有限状态机(FSM)作为最小化、完全可解释的评估框架，模型需要根据给定的FSM定义逐步执行输入动作，并在多轮中保持状态一致性。", "result": "实证结果显示随着任务长度或分支复杂度增加，模型性能系统性下降；高分支因子的规则检索比长记忆跨度表现更差；大模型局部准确性提高但在多步推理中仍然脆弱。", "conclusion": "FSM评估为诊断LLMs失败模式提供了透明且复杂度可控的探针，有助于建立理解和改进LLMs算法可靠性的严格实验基础。"}}
{"id": "2511.14778", "pdf": "https://arxiv.org/pdf/2511.14778", "abs": "https://arxiv.org/abs/2511.14778", "authors": ["George Tsoukalas", "Rahul Saha", "Amitayush Thakur", "Sabrina Reguyal", "Swarat Chaudhuri"], "title": "Learning Interestingness in Automated Mathematical Theory Formation", "categories": ["cs.AI"], "comment": "NeurIPS 2025 Spotlight", "summary": "We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).", "AI": {"tldr": "FERMAT是一个强化学习环境，用于自动化数学理论发现和定理证明，通过进化算法自动评估数学对象的有趣性，在数论和有限域发现方面优于硬编码基线", "motivation": "解决人工智能中开放数学理论发现的重大挑战，自动化数学概念发现和定理证明过程", "method": "引入FERMAT强化学习环境，使用符号化动作建模概念发现；采用基于LLM的进化算法合成有趣性度量标准，包含函数抽象技术", "result": "在初等数论和有限域发现方面取得了显著改进，优于硬编码基线方法", "conclusion": "FERMAT环境为数学理论发现提供了有效的RL框架，LLM进化算法在自动化评估数学对象有趣性方面表现出色，为AI数学发现开辟了新途径"}}
{"id": "2511.14780", "pdf": "https://arxiv.org/pdf/2511.14780", "abs": "https://arxiv.org/abs/2511.14780", "authors": ["Keith Moore", "Jun W. Kim", "David Lyu", "Jeffrey Heo", "Ehsan Adeli"], "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents", "categories": ["cs.AI"], "comment": "Preprint. Accepted for publication at AIAS 2025", "summary": "We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.", "AI": {"tldr": "Ask WhAI是一个用于检查和扰动多智能体交互中信念状态的系统框架，通过记录回放交互、支持带外查询和反事实证据注入来分析信念结构对信息的响应。", "motivation": "研究多智能体科学推理中的信念形成和认知孤岛现象，特别是在医疗诊断场景中，智能体如何基于专业先验知识形成信念以及对反证据的抵抗。", "method": "开发了一个包含多智能体共享记忆（时间戳电子病历）和持有真实实验室结果的预言智能体的医疗案例模拟器。使用大型语言模型智能体扮演不同医学专家角色，在关键诊断时刻进行前后信念查询。", "result": "发现智能体信念往往反映现实世界的学科立场，包括过度依赖经典研究和抵抗反证据，这些信念可以通过框架进行追踪和审问。", "conclusion": "Ask WhAI通过使多智能体动态可见和可测试，为研究多智能体科学推理中的信念形成和认知孤岛提供了可重复的方法。"}}
{"id": "2511.14772", "pdf": "https://arxiv.org/pdf/2511.14772", "abs": "https://arxiv.org/abs/2511.14772", "authors": ["Zhuoyi Yang", "Xu Guo", "Tong Zhang", "Huijuan Xu", "Boyang Li"], "title": "Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research", "AI": {"error": "'NoneType' object has no attribute 'model_dump'"}}
{"id": "2511.14788", "pdf": "https://arxiv.org/pdf/2511.14788", "abs": "https://arxiv.org/abs/2511.14788", "authors": ["Michele Ronco", "Damien Delforge", "Wiebke S. Jäger", "Christina Corbane"], "title": "Subnational Geocoding of Global Disasters Using Large Language Models", "categories": ["cs.AI", "stat.AP"], "comment": null, "summary": "Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.", "AI": {"tldr": "提出基于GPT-4o的全自动化LLM辅助工作流，用于处理灾害事件文本位置信息的地理编码，通过交叉验证三个地理信息源实现高精度位置几何分配。", "motivation": "灾害数据库中的位置信息通常以非结构化文本形式存在，存在粒度不一致和拼写问题，难以与空间数据集集成，需要自动化解决方案。", "method": "使用GPT-4o处理文本位置信息，通过交叉验证GADM、OpenStreetMap和Wikidata三个地理信息源分配几何图形，并根据来源一致性和可用性分配可靠性评分。", "result": "成功对2000-2024年EM-DAT数据集中的14,215个事件、17,948个独特位置进行地理编码，无需人工干预，覆盖所有灾害类型。", "conclusion": "该方法展示了LLM从非结构化文本中提取和结构化地理信息的潜力，为相关分析提供了可扩展且可靠的方法。"}}
{"id": "2511.14773", "pdf": "https://arxiv.org/pdf/2511.14773", "abs": "https://arxiv.org/abs/2511.14773", "authors": ["Joey David"], "title": "Temporal Predictors of Outcome in Reasoning Language Models", "categories": ["cs.CL"], "comment": "4 pages, 4 figures", "summary": "The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.", "AI": {"tldr": "研究发现LLM在思维链推理中很早就对最终结果有内部判断，仅需几个推理标记就能高度预测答案正确性，硬问题预测准确率下降揭示选择偏差，对模型可解释性和推理控制有重要意义", "motivation": "探究大型语言模型在思维链推理过程中何时内部确定最终结果，理解模型推理的早期承诺机制", "method": "通过在推理过程前t个标记后的隐藏状态上训练线性分类器，分析模型对最终正确性的预测能力", "result": "仅需几个推理标记就能高度预测最终正确性；硬问题在长思维链中占比过高导致预测准确率下降；模型内部自我评估在推理早期就出现", "conclusion": "推理模型的内部成功评估在推理过程早期就出现，这对模型可解释性和推理时控制具有重要启示意义"}}
{"id": "2511.14819", "pdf": "https://arxiv.org/pdf/2511.14819", "abs": "https://arxiv.org/abs/2511.14819", "authors": ["Martin Monperrus", "Benoit Baudry", "Clément Vidal"], "title": "Project Rachel: Can an AI Become a Scholarly Author?", "categories": ["cs.AI"], "comment": null, "summary": "This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.", "AI": {"tldr": "Project Rachel是一个行动研究项目，创建AI学术身份Rachel So并发表10+篇AI生成论文，研究学术生态系统对AI作者身份的反应。", "motivation": "研究学术生态系统如何应对AI作者身份，为关于超人类AI系统与学术交流未来的辩论提供实证数据。", "method": "通过行动研究方法，创建AI学术身份Rachel So，在2025年3月至10月期间发表10多篇AI生成的研究论文，并跟踪其被引用和同行评审邀请情况。", "result": "Rachel So成功发表论文并获得引用，还收到了同行评审邀请，证明AI作者身份能够被学术生态系统接受。", "conclusion": "这项研究揭示了AI作者身份对出版商、研究人员和整个科学系统的潜在影响，为未来学术交流与超强AI系统的整合提供了重要实证基础。"}}
{"id": "2511.14774", "pdf": "https://arxiv.org/pdf/2511.14774", "abs": "https://arxiv.org/abs/2511.14774", "authors": ["Pei-Fu Guo", "Yun-Da Tsai", "Chun-Chia Hsu", "Kai-Xin Chen", "Ya-An Tsai", "Kai-Wei Chang", "Nanyun Peng", "Mi-Yen Yeh", "Shou-De Lin"], "title": "LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.", "AI": {"tldr": "LiveCLKTBench是一个自动化评估跨语言知识迁移的基准测试工具，通过时间敏感的知识实体来区分真实迁移与预训练暴露，发现语言距离和模型规模对迁移效果有重要影响。", "motivation": "评估大型语言模型的跨语言知识迁移具有挑战性，因为正确答案可能来自真实的迁移或预训练期间的先验暴露，需要一种能够区分这两种情况的方法。", "method": "开发LiveCLKTBench自动化生成管道：从真实领域识别时间敏感的知识实体，基于时间发生进行过滤，验证模型知识，生成事实性问题并翻译成多种语言来评估跨语言迁移能力。", "result": "在五种语言上评估多个LLM，发现跨语言迁移受语言距离强烈影响且通常不对称；大模型能改善迁移但收益随规模递减且在不同领域表现不一。", "conclusion": "研究为多语言迁移提供了新见解，证明LiveCLKTBench作为未来研究的可靠基准的价值。"}}
{"id": "2511.14853", "pdf": "https://arxiv.org/pdf/2511.14853", "abs": "https://arxiv.org/abs/2511.14853", "authors": ["Robab Aghazadeh Chakherlou", "Siddartha Khastgir", "Xingyu Zhao", "Jerein Jeyachandran", "Shufeng Chen"], "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems", "categories": ["cs.AI"], "comment": null, "summary": "Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\n  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.", "AI": {"tldr": "本文提出了一种概率方法来量化AI系统训练测试数据集的代表性，通过比较场景套件与目标操作域的特征统计分布，使用不精确贝叶斯方法处理有限数据和先验不确定性，生成区间值代表性估计。", "motivation": "确保AI系统（如自动驾驶汽车）的可信度和安全性，关键在于训练测试数据集的数据相关安全属性（如代表性、完整性等）。本文特别关注代表性，即训练测试用的场景数据反映系统设计安全运行条件（ODD）或预期遇到条件（TOD）的程度。", "method": "采用概率方法比较场景套件编码特征与TOD特征统计分布。使用不精确贝叶斯方法处理有限数据和不确定先验，生成区间值的不确定性感知代表性估计，而非单一值。", "result": "通过数值示例展示了在不同操作类别（天气、道路类型、时间等）下，考虑依赖关系和先验不确定性时，场景套件与推断TOD分布的比较。获得了局部（类别间）和全局的区间代表性估计。", "conclusion": "该方法能够量化数据集的代表性，并提供不确定性感知的区间估计，有助于评估AI系统训练测试数据的充分性和安全性保障能力。"}}
{"id": "2511.14776", "pdf": "https://arxiv.org/pdf/2511.14776", "abs": "https://arxiv.org/abs/2511.14776", "authors": ["Snigdha Pandya", "Rohan Nagale", "Kenji Sahay", "Anna Lin", "Shikhar Shiromani", "Kevin Zhu", "Dev Sunishchal"], "title": "COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation", "categories": ["cs.CL"], "comment": "9 pages, 6 figures including algorithmns, 2 tables", "summary": "Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steering this internal behavior is key both for trustworthy deployment and for scientific interpretability of model mechanisms. We introduce COMPASS (Context-Modulated PID Attention Steering System), a lightweight, interpretable control framework that embeds a model-based feedback loop directly within decoding. COMPASS quantifies context reliance via a transparent metric, the Context Reliance Score (CRS), which serves as an online probe of how attention heads ground generation in evidence. Using this interpretable signal, a PID controller dynamically modulates attention heads to maintain factual consistency without retraining or multi-pass decoding. Across benchmarks (HotpotQA, XSum, HaluEval, RAGTruth), COMPASS consistently reduces contextual hallucination rates (2.8 to 5.8 percent absolute) while revealing how distinct attention heads contribute to evidence alignment. These results highlight feedback-driven interpretability as a pathway toward scientific understanding of LLM behavior.", "AI": {"tldr": "COMPASS是一个轻量级可解释的控制框架，通过基于模型的反馈循环在解码过程中动态调节注意力头，减少大语言模型的事实幻觉问题。", "motivation": "大语言模型经常生成流畅但事实错误的陈述，这是因为它们在上下文知识和参数知识之间的注意力分配存在问题。需要理解和引导这种内部行为以实现可信部署和模型机制的科学可解释性。", "method": "引入COMPASS框架，通过Context Reliance Score量化上下文依赖度，使用PID控制器动态调节注意力头，在不重新训练或多遍解码的情况下保持事实一致性。", "result": "在多个基准测试中，COMPASS将上下文幻觉率绝对降低了2.8%到5.8%，同时揭示了不同注意力头对证据对齐的贡献。", "conclusion": "反馈驱动的可解释性为科学理解大语言模型行为提供了一条有效途径，COMPASS框架在减少幻觉的同时增强了模型机制的透明度。"}}
{"id": "2511.15002", "pdf": "https://arxiv.org/pdf/2511.15002", "abs": "https://arxiv.org/abs/2511.15002", "authors": ["Fatemeh Lotfi", "Hossein Rajoli", "Fatemeh Afghah"], "title": "Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to be published in IEEE Transaction on Machine Learning in Communication and Networking (TMLCN)", "summary": "Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $ρ$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.", "AI": {"tldr": "本文提出了一种结合Sharpness-Aware Minimization (SAM)的改进型Soft Actor Critic算法，在分布式多智能体强化学习框架中用于O-RAN资源管理，通过TD误差方差驱动的自适应SAM机制和动态ρ调度策略，显著提升了资源分配效率和QoS满意度。", "motivation": "虽然深度强化学习在优化网络资源方面有潜力，但在动态环境中存在鲁棒性和泛化性不足的问题，需要一种能够适应环境复杂性并减少不必要开销的方法。", "method": "在分布式多智能体强化学习框架中，将SAM与SAC算法结合，引入基于TD误差方差的自适应选择机制，仅对面临高环境复杂度的智能体进行正则化，同时采用动态ρ调度方案优化探索-利用权衡。", "result": "实验结果显示该方法显著优于传统深度强化学习方法，资源分配效率提升高达22%，并在不同O-RAN切片中实现了优异的QoS满意度。", "conclusion": "提出的自适应SAM机制和动态调度策略有效解决了DRL在动态环境中的鲁棒性和泛化性问题，为O-RAN资源管理提供了高效且稳定的解决方案。"}}
{"id": "2511.14779", "pdf": "https://arxiv.org/pdf/2511.14779", "abs": "https://arxiv.org/abs/2511.14779", "authors": ["Julio Cesar Galdino", "Sidney Evaldo Leal", "Leticia Gabriella De Souza", "Rodrigo de Freitas Lima", "Antonio Nelson Fornari Mendes Moreira", "Arnaldo Candido Junior", "Miguel Oliveira", "Edresson Casanova", "Sandra M. Aluísio"], "title": "The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech", "categories": ["cs.CL"], "comment": null, "summary": "Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in generating natural and intelligible speech, primarily through architectures that implicitly model prosodic features such as pitch, intensity, and duration, the construction of datasets with explicit prosodic segmentation and their impact on spontaneous speech synthesis remains largely unexplored. This paper evaluates the effects of manual and automatic prosodic segmentation annotations in Brazilian Portuguese on the quality of speech synthesized by a non-autoregressive model, FastSpeech 2. Experimental results show that training with prosodic segmentation produced slightly more intelligible and acoustically natural speech. While automatic segmentation tends to create more regular segments, manual prosodic segmentation introduces greater variability, which contributes to more natural prosody. Analysis of neutral declarative utterances showed that both training approaches reproduced the expected nuclear accent pattern, but the prosodic model aligned more closely with natural pre-nuclear contours. To support reproducibility and future research, all datasets, source codes, and trained models are publicly available under the CC BY-NC-ND 4.0 license.", "AI": {"tldr": "该研究评估了手动和自动韵律分割标注对巴西葡萄牙语语音合成质量的影响，发现韵律分割训练能产生更清晰和自然的语音，手动分割带来更大变异性从而提升自然度。", "motivation": "自发语音合成面临捕捉自然对话流程的挑战，包括话轮转换、停顿和不流畅现象。现有系统主要通过隐式建模韵律特征，但显式韵律分割数据集及其对自发语音合成的影响尚未充分探索。", "method": "使用非自回归模型FastSpeech 2，在巴西葡萄牙语数据集上比较手动和自动韵律分割标注的效果，分析其对语音合成质量的影响。", "result": "实验结果显示，使用韵律分割训练的模型产生了稍更清晰和声学上更自然的语音。自动分割产生更规则的片段，手动分割引入更大变异性，有助于更自然的韵律。两种方法都能重现预期的核重音模式，但韵律模型更接近自然的核前轮廓。", "conclusion": "韵律分割标注对提升语音合成质量有积极影响，手动分割在韵律自然度方面表现更佳。所有数据集、源代码和训练模型都已公开，支持可重复性和未来研究。"}}
{"id": "2511.15055", "pdf": "https://arxiv.org/pdf/2511.15055", "abs": "https://arxiv.org/abs/2511.15055", "authors": ["Jian-Ting Guo", "Yu-Cheng Chen", "Ping-Chun Hsieh", "Kuo-Hao Ho", "Po-Wei Huang", "Ti-Rong Wu", "I-Chen Wu"], "title": "Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "Accepted by the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.", "AI": {"tldr": "该论文提出了MAQ框架，通过将人类演示蒸馏为宏动作，使强化学习智能体能够同时最大化奖励和模仿人类行为，显著提升了智能体的人类相似度。", "motivation": "当前强化学习智能体虽然在某些领域表现超越人类，但行为方式与人类差异较大，存在解释性和可信度问题，需要设计更接近人类行为的智能体。", "method": "将人类相似度建模为轨迹优化问题，提出宏动作量化(MAQ)框架，使用Vector-Quantized VAE从人类演示中提取宏动作，并采用receding-horizon控制实现高效学习。", "result": "在D4RL Adroit基准测试中，MAQ显著提高了人类相似度评分，在人类评估研究中获得最高的人类相似度排名，且能轻松集成到各种现成RL算法中。", "conclusion": "MAQ为学习人类相似强化学习智能体开辟了有前景的方向，通过宏动作量化实现了奖励最大化和人类行为模仿的双重目标。"}}
{"id": "2511.14783", "pdf": "https://arxiv.org/pdf/2511.14783", "abs": "https://arxiv.org/abs/2511.14783", "authors": ["Bingquan Zhang", "Xiaoxiao Liu", "Yuchi Wang", "Lei Zhou", "Qianqian Xie", "Benyou Wang"], "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education", "categories": ["cs.CL", "cs.CY"], "comment": "10 pages, 9 figures, 8 table", "summary": "Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigorous comparison with human SP. We present EasyMED, a multi-agent framework combining a Patient Agent for realistic dialogue, an Auxiliary Agent for factual consistency, and an Evaluation Agent that delivers actionable feedback. To support systematic assessment, we introduce SPBench, a benchmark of real SP-doctor interactions spanning 14 specialties and eight expert-defined evaluation criteria. Experiments demonstrate that EasyMED matches human SP learning outcomes while producing greater skill gains for lower-baseline students and offering improved flexibility, psychological safety, and cost efficiency.", "AI": {"tldr": "EasyMED是一个基于多智能体的标准化病人模拟框架，通过三个智能体协作实现真实对话、事实一致性和可操作反馈，在SPBench基准测试中达到与人类SP相当的学习效果，且成本更低、灵活性更高", "motivation": "现有的基于大语言模型的标准化病人模拟器成本虽低但行为不一致，且缺乏与人类SP的严格比较，需要开发更可靠、可扩展的临床训练解决方案", "method": "开发了EasyMED多智能体框架，包含患者智能体（真实对话）、辅助智能体（事实一致性）和评估智能体（可操作反馈），并创建SPBench基准（14个专科、8个评估标准）进行系统评估", "result": "实验显示EasyMED与人类SP的学习效果相当，对基础较差的学生技能提升更显著，同时提供更好的灵活性、心理安全性和成本效益", "conclusion": "EasyMED框架成功解决了现有SP模拟器的局限性，为临床技能训练提供了可扩展、经济高效且效果相当的替代方案"}}
{"id": "2511.15061", "pdf": "https://arxiv.org/pdf/2511.15061", "abs": "https://arxiv.org/abs/2511.15061", "authors": ["Haodong Chen", "Guido Zuccon", "Teerapong Leelanupab"], "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "This paper has been accepted to SIGIR-AP 2025", "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.", "AI": {"tldr": "OpenBioLLM是一个开源的多智能体框架，使用开源模型替代GeneGPT的专有模型，在基因组问答任务上达到或超越GeneGPT性能，同时降低延迟40-50%并提高效率", "motivation": "GeneGPT依赖专有模型导致可扩展性受限、运营成本高、数据隐私和泛化问题，需要开发开源替代方案", "method": "首先用开源模型(Llama 3.1, Qwen2.5等)复现GeneGPT并识别其限制，然后开发模块化多智能体框架OpenBioLLM，引入工具路由、查询生成和响应验证的专门智能体", "result": "在90%的基准任务上达到或超越GeneGPT性能，Gene-Turing平均得分0.849，GeneHop平均得分0.830，延迟降低40-50%", "conclusion": "开源多智能体系统在基因组问答方面具有巨大潜力，OpenBioLLM框架提供了高效、可扩展且保护隐私的解决方案"}}
{"id": "2511.14796", "pdf": "https://arxiv.org/pdf/2511.14796", "abs": "https://arxiv.org/abs/2511.14796", "authors": ["Adel Hidri", "Suleiman Ali Alsaif", "Muteeb Alahmari", "Eman AlShehri", "Minyar Sassi Hidri"], "title": "Opinion Mining and Analysis Using Hybrid Deep Neural Networks", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 4 figures, 11 tables", "summary": "Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.", "AI": {"tldr": "该研究提出了一种混合深度神经网络模型HBGRU-LSTM，结合双向门控循环单元和长短期记忆层，用于情感分析，在IMDB电影评论和亚马逊产品评价数据集上取得了95%的测试准确率，显著优于传统深度学习模型。", "motivation": "现有基于词典和传统机器学习的情感分析方法在处理上下文细微差别和可扩展性方面存在不足，深度学习虽然有所改进但仍需提升性能，特别是在语义关系捕捉方面。", "method": "采用混合深度神经网络架构，结合双向门控循环单元(BGRU)和长短期记忆(LSTM)层，旨在改善情感分析中的上下文理解、可扩展性和类别不平衡问题。", "result": "HBGRU-LSTM模型达到95%的测试准确率，优于LSTM(93.06%)、CNN+LSTM(93.31%)和GRU+LSTM(92.20%)。负向情感召回率从不平衡数据集的86%提升到平衡数据集的96%，误分类损失从20.24%降至13.3%。", "conclusion": "提出的HBGRU-LSTM混合模型在情感分析任务中表现出色，能够有效处理上下文细微差别、可扩展性和类别不平衡问题，具有更好的泛化能力和鲁棒性。"}}
{"id": "2511.15069", "pdf": "https://arxiv.org/pdf/2511.15069", "abs": "https://arxiv.org/abs/2511.15069", "authors": ["Haoyong Wu", "Yongmei Liu"], "title": "ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.", "AI": {"tldr": "ProRAC是一个神经符号框架，利用LLMs提取和执行动作来推理状态变化，在多个RAC基准测试中表现优异。", "motivation": "为了解决RAC（行动与变化推理）问题，提出一个结合神经和符号方法的框架，利用大型语言模型的能力来处理这类复杂的推理任务。", "method": "ProRAC是一个神经符号框架，利用LLMs处理RAC问题。它从问题中提取动作和问题等基本RAC元素，逐步执行每个动作以推导最终状态，然后根据演进状态评估查询以获得答案。", "result": "在多个RAC基准测试中，ProRAC方法表现出强大的性能，在不同基准、领域、LLM主干和RAC任务类型上都取得了优异的结果。", "conclusion": "ProRAC框架在多个RAC基准测试中表现出色，能够有效处理不同领域、不同LLM主干和不同类型的RAC任务，证明了该方法的有效性和通用性。"}}
{"id": "2511.14868", "pdf": "https://arxiv.org/pdf/2511.14868", "abs": "https://arxiv.org/abs/2511.14868", "authors": ["Xueying Ding", "Xingyue Huang", "Mingxuan Ju", "Liam Collins", "Yozen Liu", "Leman Akoglu", "Neil Shah", "Tong Zhao"], "title": "Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.", "AI": {"tldr": "HTP（分层令牌预置）方法通过分块预置摘要令牌和均值池化，解决了大语言模型在长文档嵌入中的信息流限制和过压缩问题，在多个基准测试中显著提升性能。", "motivation": "大型语言模型的因果注意力机制限制了从后向前的信息流，降低了表示质量。现有方法通过预置单个摘要令牌会导致信息过压缩，特别是在长文档中性能下降。", "method": "提出分层令牌预置（HTP）：1）将输入分块并为后续块预置块级摘要令牌，创建多个后向信息流路径；2）用均值池化替代最后令牌池化，缓解读取级过压缩问题。", "result": "在11个检索数据集和30个通用嵌入基准测试中取得一致的性能提升，尤其在长上下文设置中表现优异。", "conclusion": "HTP作为一种简单且架构无关的方法，能够提升零样本和微调模型的性能，为长文档嵌入提供了可扩展的优质解决方案。"}}
{"id": "2511.15074", "pdf": "https://arxiv.org/pdf/2511.15074", "abs": "https://arxiv.org/abs/2511.15074", "authors": ["Henrik Bradland", "Morten Goodwin", "Vladimir I. Zadorozhny", "Per-Arne Andersen"], "title": "Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents", "categories": ["cs.AI", "cs.CL"], "comment": "19 pages, 4 figures, in review", "summary": "The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a \"flooding-pruning\" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.", "AI": {"tldr": "Rogue One是一个基于LLM的多智能体框架，通过三个专门智能体的协作实现知识驱动的自动特征提取，在特征工程方面显著优于现有方法。", "motivation": "现有基于LLM的自动特征提取方法存在架构单一、反馈机制简单、缺乏外部知识整合等问题，限制了特征工程的效果。", "method": "采用去中心化的三智能体系统(Scientist、Extractor、Tester)，结合丰富的定性反馈机制和\"洪水-修剪\"策略，通过RAG系统整合外部知识，迭代式地进行特征发现、生成和验证。", "result": "在19个分类和9个回归数据集上显著优于最先进方法，能够发现新颖、可测试的假设(如识别心肌数据集中的新生物标志物)。", "conclusion": "Rogue One不仅提升了特征工程的性能，还为科学发现提供了有效工具，证明了多智能体框架在自动化特征工程中的优势。"}}
{"id": "2511.15005", "pdf": "https://arxiv.org/pdf/2511.15005", "abs": "https://arxiv.org/abs/2511.15005", "authors": ["Moses Kiprono"], "title": "Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, theoretical/mathematical LLM research, no figures, intended for peer-reviewed journal", "summary": "Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.", "AI": {"tldr": "本文提出了一个数学基础框架来理解、测量和缓解大语言模型的幻觉问题，通过概率建模、信息论等方法分析错误传播，并提出改进的不确定性度量和缓解策略。", "motivation": "大语言模型虽然功能强大，但容易产生看似合理但事实错误或缺乏依据的幻觉输出，这限制了其可靠性和安全性。", "method": "采用概率建模、信息理论、三角信号分析和贝叶斯不确定性估计等方法，分析自回归错误传播，提出改进的不确定性度量（包括语义和相位感知变体），并开发对比解码、检索增强接地、事实对齐和弃权等原则性缓解策略。", "result": "建立了一个统一框架，将校准、检索和对齐等领域的最新进展联系起来，为构建更安全可靠的大语言模型提供支持。", "conclusion": "该数学框架为理解和缓解LLM幻觉提供了理论基础和实用方法，有助于提升大语言模型的可靠性和安全性。"}}
{"id": "2511.15169", "pdf": "https://arxiv.org/pdf/2511.15169", "abs": "https://arxiv.org/abs/2511.15169", "authors": ["Xin Gao", "Shaohan Yu", "Zerui Chen", "Yueming Lyu", "Weichen Yu", "Guanghao Li", "Jiyao Liu", "Jianxiong Gao", "Jian Liang", "Ziwei Liu", "Chenyang Si"], "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models", "categories": ["cs.AI"], "comment": "30 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.", "AI": {"tldr": "SafeRBench是第一个端到端评估大推理模型安全性的基准，通过输入特征化、细粒度输出分析和人类安全对齐三个维度，系统评估推理过程中的动态安全风险。", "motivation": "现有安全评估主要关注输出层面的判断，很少能捕捉推理过程中的动态风险（如有害内容通过推理链逐步注入或合理化），因此需要开发能够全面评估推理模型安全性的新基准。", "method": "1) 输入特征化：将风险类别和级别纳入输入设计，建立反映不同危害梯度的平衡提示集；2) 细粒度输出分析：通过微思想分块机制将长推理轨迹分割为语义连贯单元，在十个安全维度进行评估；3) 人类安全对齐：基于人工标注验证LLM评估结果。", "result": "对19个大推理模型的评估表明，SafeRBench能够实现详细的多维安全评估，从多个角度提供风险和保护机制的洞察。", "conclusion": "SafeRBench填补了现有安全评估的空白，为全面理解和评估大推理模型在推理过程中的安全风险提供了有效的工具和框架。"}}
{"id": "2511.15163", "pdf": "https://arxiv.org/pdf/2511.15163", "abs": "https://arxiv.org/abs/2511.15163", "authors": ["Yang Wu", "Rujing Yao", "Tong Zhang", "Yufei Shi", "Zhuoren Jiang", "Zhushan Li", "Xiaozhong Liu"], "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": "AAAI 2026 Workshop", "summary": "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.", "AI": {"tldr": "TASA是一个学生感知的数学辅导框架，通过整合学生画像、记忆和遗忘动态来实现个性化教学，相比基线方法获得更优的学习效果和适应性。", "motivation": "现有LLM智能辅导系统大多未能捕捉学生知识随熟练度、概念差距和遗忘模式的动态演变，特别是在需要精细支架式教学的数学辅导中。", "method": "提出TASA框架，维护结构化学生画像（熟练度档案）和事件记忆（先前学习交互），通过连续遗忘曲线和知识追踪动态更新学生掌握状态，生成情境适宜、难度校准的问题和解释。", "result": "实证结果表明TASA相比代表性基线方法实现了更优的学习成果和更自适应的辅导行为。", "conclusion": "建模时间遗忘和学习者画像在基于LLM的辅导系统中至关重要，TASA框架为此提供了有效解决方案。"}}
{"id": "2511.15191", "pdf": "https://arxiv.org/pdf/2511.15191", "abs": "https://arxiv.org/abs/2511.15191", "authors": ["Zhiyi Duan", "Zixing Shi", "Hongyu Yuan", "Qi Wang"], "title": "HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.", "AI": {"tldr": "HISE-KT是一个结合异质信息网络和大型语言模型的知识追踪框架，通过自动化元路径质量评估和相似学生检索机制，在预测性能和可解释性方面优于现有方法。", "motivation": "现有基于异质信息网络的方法因手动或随机选择元路径而引入噪声，且缺乏元路径实例质量评估；基于大语言模型的方法忽视学生间的丰富信息，两者都难以提供准确且基于证据的解释。", "method": "构建多关系异质信息网络捕获结构关系，使用LLM智能评分和过滤元路径实例保留高质量路径，设计基于元路径的相似学生检索机制，通过结构化提示整合目标学生历史和检索到的相似轨迹。", "result": "在四个公共数据集上的实验表明，HISE-KT在预测性能和可解释性方面均优于现有知识追踪基线方法。", "conclusion": "HISE-KT成功整合了异质信息网络和大型语言模型的优势，实现了自动化元路径质量评估和证据支持的可解释分析，为知识追踪提供了更准确和可解释的解决方案。"}}
{"id": "2511.15183", "pdf": "https://arxiv.org/pdf/2511.15183", "abs": "https://arxiv.org/abs/2511.15183", "authors": ["Rishikant Chigrupaatii", "Ponnada Sai Tulasi Kanishka", "Lalit Chandra Routhu", "Martin Patel Sama Supratheek Reddy", "Divyam Gupta", "Dasari Srikar", "Krishna Teja Kuchimanchi", "Rajiv Misra", "Rohun Tripathi"], "title": "HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "With nearly 1.5 billion people and more than 120 major languages, India represents one of the most diverse regions in the world. As multilingual Vision-Language Models (VLMs) gain prominence, robust evaluation methodologies are essential to drive progress toward equitable AI for low-resource languages. Current multilingual VLM evaluations suffer from four major limitations: reliance on unverified auto-translations, narrow task/domain coverage, limited sample sizes, and lack of cultural and natively sourced Question-Answering (QA). To address these gaps, we present a scalable framework to evaluate VLMs in Indian languages and compare it with performance in English. Using the framework, we generate HinTel-AlignBench, a benchmark that draws from diverse sources in Hindi and Telugu with English-aligned samples. Our contributions are threefold: (1) a semi-automated dataset creation framework combining back-translation, filtering, and human verification; (2) the most comprehensive vision-language benchmark for Hindi and and Telugu, including adapted English datasets (VQAv2, RealWorldQA, CLEVR-Math) and native novel Indic datasets (JEE for STEM, VAANI for cultural grounding) with approximately 4,000 QA pairs per language; and (3) a detailed performance analysis of various State-of-the-Art (SOTA) open-weight and closed-source VLMs. We find a regression in performance for tasks in English versus in Indian languages for 4 out of 5 tasks across all the models, with an average regression of 8.3 points in Hindi and 5.5 points for Telugu. We categorize common failure modes to highlight concrete areas of improvement in multilingual multimodal understanding.", "AI": {"tldr": "该论文提出了一个评估多语言视觉语言模型在印度语言中表现的可扩展框架，并创建了HinTel-AlignBench基准测试，发现现有模型在印度语言上的表现比英语平均下降8.3分（印地语）和5.5分（泰卢固语）。", "motivation": "印度作为拥有15亿人口和120多种主要语言的多元化地区，需要公平的AI技术。当前多语言VLM评估存在四个主要局限：依赖未验证的自动翻译、任务/领域覆盖范围狭窄、样本量有限、缺乏文化和本土来源的问答数据。", "method": "提出了一个半自动化的数据集创建框架，结合回译、过滤和人工验证；创建了最全面的印地语和泰卢固语视觉语言基准，包括适应的英语数据集和本土印度数据集，每种语言约4000个问答对；对多种SOTA VLM进行了详细性能分析。", "result": "在所有5个任务中，4个任务在印度语言上的表现相比英语出现回归，印地语平均下降8.3分，泰卢固语平均下降5.5分。识别了常见的失败模式以突出多语言多模态理解的具体改进领域。", "conclusion": "该研究揭示了多语言VLM在印度语言上的显著性能差距，提出了一个可扩展的评估框架和基准数据集，为开发更公平的多语言AI系统提供了重要基础和方向。"}}
{"id": "2511.15192", "pdf": "https://arxiv.org/pdf/2511.15192", "abs": "https://arxiv.org/abs/2511.15192", "authors": ["Haodong Li", "Jingqi Zhang", "Xiao Cheng", "Peihua Mai", "Haoyu Wang", "Yang Pan"], "title": "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", "categories": ["cs.AI"], "comment": null, "summary": "The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\n  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen\" (training data) and ``unseen\" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.", "AI": {"tldr": "COPYCHECK是一个利用不确定性信号检测LLM训练数据中版权内容的框架，通过将LLM的过度自信转化为优势，实现了无需大量训练数据和经验阈值的版权检测。", "motivation": "LLM在大量数据集上训练时可能使用受版权保护的内容，现有成员推理攻击方法存在过度自信、缺乏真实训练数据和依赖经验阈值等局限性。", "method": "采用两阶段策略：(1)将文件分割成小片段减少对大规模训练数据的依赖；(2)使用不确定性引导的无监督聚类消除经验调优阈值需求。", "result": "在LLaMA 7b和LLaMA2 7b上分别达到90.1%和91.6%的平均平衡准确率，相比SOTA基线提升超过90%，在GPT-J 6B上也保持高性能。", "conclusion": "这是首个将不确定性应用于LLM版权检测的工作，为训练数据透明度提供了实用工具，解决了现有方法的局限性。"}}
{"id": "2511.15210", "pdf": "https://arxiv.org/pdf/2511.15210", "abs": "https://arxiv.org/abs/2511.15210", "authors": ["Vladislav Pedashenko", "Laida Kushnareva", "Yana Khassan Nibal", "Eduard Tulchinskii", "Kristian Kuznetsov", "Vladislav Zharchinskii", "Yury Maximov", "Irina Piontkovskaya"], "title": "Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text \"representationally simple\" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively \"easy\", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.", "AI": {"tldr": "本研究发现内在维度(ID)与基于熵的指标互补，能捕捉文本的几何复杂性；不同文本类型呈现稳定的ID分层(科学文本ID最低，创意/观点写作ID最高)；通过稀疏自编码器识别出科学特征降低ID而人性化特征增加ID的因果关系", "motivation": "内在维度是现代LLM分析的重要工具，但其文本决定因素尚未得到充分探索，需要建立ID与可解释文本属性之间的关系", "method": "使用交叉编码器分析、语言特征和稀疏自编码器(SAEs)进行多角度研究，包括相关性分析、文本类型分层分析和特征因果识别", "result": "发现ID与长度控制后的熵指标不相关；科学文本ID约8，百科内容约9，创意写作约10.5；科学信号降低ID，人性化信号增加ID", "conclusion": "科学写作对现代模型相对\"简单\"，而小说、观点和情感内容增加了表示自由度，为ID的正确使用和基于ID结果的有效解释提供了实用指导"}}
{"id": "2511.15202", "pdf": "https://arxiv.org/pdf/2511.15202", "abs": "https://arxiv.org/abs/2511.15202", "authors": ["Yinsheng Wang", "Tario G You", "Léonard Boussioux", "Shan Liu"], "title": "SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making", "categories": ["cs.AI"], "comment": "NeurIPS 2025 WORKSHOP ML*OR Workshop: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making", "summary": "This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.", "AI": {"tldr": "SOLID框架将数学优化与大语言模型相结合，通过双重价格和偏差惩罚实现迭代协作，在保持模块化和数据隐私的同时提升决策质量，在投资组合案例中显示出优于纯优化方法的年化收益。", "motivation": "传统优化方法缺乏上下文理解能力，而大语言模型虽然具有强大的语境理解能力但缺乏数学严谨性。SOLID旨在整合两者的优势，实现更智能的决策制定。", "method": "提出SOLID框架，通过优化代理和LLM代理的迭代协作机制，使用双重价格和偏差惩罚来协调两者的交互，在凸性假设下保持理论收敛性。", "result": "在股票投资组合案例中，SOLID在各种场景下都显示出收敛性，年化收益率相比纯优化基准方法有所提升，验证了两个代理的协同效应。", "conclusion": "SOLID为跨领域的自动化和智能决策提供了一个有前景的框架，成功证明了优化方法与大语言模型协同工作的有效性。"}}
{"id": "2511.15211", "pdf": "https://arxiv.org/pdf/2511.15211", "abs": "https://arxiv.org/abs/2511.15211", "authors": ["Xinli Tao", "Xin Dong", "Xuezhong Zhou"], "title": "OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 4 figures, 4 tables", "summary": "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", "AI": {"tldr": "OEMA是一个用于临床命名实体识别的零样本多智能体协作框架，通过自我标注器、判别器和预测器的协作，在无需标注数据的情况下实现了接近监督学习的性能。", "motivation": "解决临床命名实体识别中监督模型需要昂贵标注数据的问题，以及现有零样本方法在示例选择粒度和提示集成方面的局限性。", "method": "提出OEMA框架，包含三个组件：自我标注器生成示例、判别器通过SNOMED CT本体过滤示例、预测器使用实体描述进行准确推理。", "result": "在MTSamples和VAERS数据集上达到最先进的精确匹配性能，在相关匹配指标上媲美监督学习的BioClinicalBERT并超越CRF。", "conclusion": "OEMA通过本体引导推理和多智能体协作解决了零样本NER的关键挑战，实现了接近监督学习的性能，在临床NLP应用中具有广阔前景。"}}
{"id": "2511.15259", "pdf": "https://arxiv.org/pdf/2511.15259", "abs": "https://arxiv.org/abs/2511.15259", "authors": ["Philipp Wiesner", "Daniel W. O'Neill", "Francesca Larosa", "Odej Kao"], "title": "Efficiency Will Not Lead to Sustainable Reasoning AI", "categories": ["cs.AI", "cs.CY"], "comment": "Presented at the Rethinking AI Workshop @ EurIPS'25", "summary": "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", "AI": {"tldr": "论文指出AI推理系统能效提升已接近物理极限，单纯追求效率无法实现可持续性，需要从优化和治理层面建立明确限制", "motivation": "AI研究正转向复杂问题解决和多步推理，但推理AI缺乏自然饱和点，性能随计算投入指数增长，能效提升接近物理极限", "method": "通过分析AI推理系统的能耗特性和效率极限，提出需要在优化和治理中嵌入明确限制的研究和政策方向", "result": "识别出推理AI可持续发展的关键挑战：效率提升面临物理极限，性能增长与计算投入呈指数关系，缺乏自然饱和机制", "conclusion": "仅靠效率提升无法实现可持续的推理AI，必须通过研究创新和政策引导，在系统优化和治理中建立明确的限制机制"}}
{"id": "2511.15244", "pdf": "https://arxiv.org/pdf/2511.15244", "abs": "https://arxiv.org/abs/2511.15244", "authors": ["Fanfan Liu", "Haibo Qiu"], "title": "Context Cascade Compression: Exploring the Upper Limits of Text Compression", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression", "AI": {"tldr": "C3提出了一种级联LLM的上下文压缩方法，使用小型LLM压缩长文本为潜在token，大型LLM执行解码任务，在20倍压缩比下达到98%准确率，性能优于DeepSeek-OCR。", "motivation": "解决百万级token长上下文任务中的计算和内存挑战，探索文本压缩的上限，受DeepSeek-OCR光学压缩研究的启发。", "method": "使用两个不同大小的LLM级联：小型LLM作为第一阶段将长文本压缩为短潜在token（如32或64长度），大型LLM作为第二阶段在压缩后的上下文中执行解码任务。", "result": "在20倍压缩比下达到98%解码准确率（DeepSeek-OCR约为60%），40倍压缩比下仍保持约93%准确率，展示了优越的性能和可行性。", "conclusion": "C3在上下文压缩领域表现出卓越性能，为光学字符压缩、OCR等相关领域的压缩比上限提供了参考，采用纯文本流程简化了处理过程。"}}
{"id": "2511.15282", "pdf": "https://arxiv.org/pdf/2511.15282", "abs": "https://arxiv.org/abs/2511.15282", "authors": ["Ninell Oldenburg", "Ruchira Dhar", "Anders Søgaard"], "title": "Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research", "categories": ["cs.AI"], "comment": "The 40th Annual AAAI Conference on Artificial Intelligence, 8 pages (excl. references), 1 table", "summary": "In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.", "AI": {"tldr": "本文分析了AI研究中两种对立的情报观：情报现实主义认为情报是单一可度量的通用能力，情报多元主义认为情报是多样化的情境依赖能力。这两种隐含的假设深刻影响着AI研究的方法论、现象解释和风险评估。", "motivation": "当前AI研究中对情报本质的潜在假设往往被忽视，但这些假设实际上塑造了实证证据的解释方式，导致了研究方法和风险评估的根本分歧。", "method": "通过分析当前AI研究中的辩论，揭示两种情报观如何隐含地影响模型选择、基准设计、实验验证等方法论问题，以及对相同实证现象的矛盾解读。", "result": "发现现实主义者和多元主义者在方法论上采取不同路径，对能力涌现等现象有对立解释，在AI风险问题上产生截然不同的评估：前者关注超级智能风险并寻求统一对齐方案，后者关注多样化威胁并需要情境特定解决方案。", "conclusion": "明确这些底层假设有助于更清晰地理解AI研究中的分歧，促进更富有成效的学术对话和研究方向选择。"}}
{"id": "2511.15260", "pdf": "https://arxiv.org/pdf/2511.15260", "abs": "https://arxiv.org/abs/2511.15260", "authors": ["Sowmya Vajjala"], "title": "IndicGEC: Powerful Models, or a Measurement Mirage?", "categories": ["cs.CL"], "comment": "Technical report", "summary": "In this paper, we report the results of the TeamNRC's participation in the BHASHA-Task 1 Grammatical Error Correction shared task https://github.com/BHASHA-Workshop/IndicGEC2025/ for 5 Indian languages. Our approach, focusing on zero/few-shot prompting of language models of varying sizes (4B to large proprietary models) achieved a Rank 4 in Telugu and Rank 2 in Hindi with GLEU scores of 83.78 and 84.31 respectively. In this paper, we extend the experiments to the other three languages of the shared task - Tamil, Malayalam and Bangla, and take a closer look at the data quality and evaluation metric used. Our results primarily highlight the potential of small language models, and summarize the concerns related to creating good quality datasets and appropriate metrics for this task that are suitable for Indian language scripts.", "AI": {"tldr": "该论文报道了TeamNRC团队在BHASHA-Task 1语法错误纠正共享任务中的研究成果，使用零/少样本提示方法在不同规模语言模型上对5种印度语言进行语法纠错，取得了Telugu第4名和Hindi第2名的成绩。", "motivation": "探索使用不同规模的语言模型（从4B到大型专有模型）通过零/少样本提示方法在印度语言语法错误纠正任务中的效果，并评估数据集质量和评价指标的适用性。", "method": "采用零样本和少样本提示策略，使用不同规模的语言模型（4B参数到大型专有模型）对Telugu、Hindi、Tamil、Malayalam和Bangla五种印度语言进行语法错误纠正实验。", "result": "在Telugu语言上获得第4名（GLEU分数83.78），在Hindi语言上获得第2名（GLEU分数84.31），并扩展到其他三种语言进行实验。结果显示了小语言模型的潜力，同时揭示了数据集质量和评价指标方面的问题。", "conclusion": "研究表明小语言模型在印度语言语法纠错任务中具有潜力，但需要关注高质量数据集的创建和适合印度语言文字特点的适当评价指标的开发。"}}
{"id": "2511.15351", "pdf": "https://arxiv.org/pdf/2511.15351", "abs": "https://arxiv.org/abs/2511.15351", "authors": ["Yifu Guo", "Zishan Xu", "Zhiyuan Yao", "Yuquan Lu", "Jiaye Lin", "Sen Hu", "Zhenheng Tang", "Yingchao Li", "Huacan Wang", "Ronghao Chen"], "title": "Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.", "AI": {"tldr": "Octopus是一个多模态代理推理新范式，通过协调六种核心能力实现自主推理路径探索和动态能力选择，在Octopus-Bench基准测试中表现优异。", "motivation": "现有多模态推理模型存在架构限制，缺乏人类式的自主探索多样化推理路径的能力，无法适应动态变化的任务需求。", "method": "提出Octopus框架，定义六种核心多模态推理能力，构建Octopus-Bench评估基准，实现自主推理探索和动态能力选择机制。", "result": "实验结果显示Octopus在Octopus-Bench大多数任务上取得最佳性能，证明了能力协调在多模态代理推理中的关键作用。", "conclusion": "能力协调是多模态代理推理成功的关键因素，Octopus框架通过六能力协同实现了人类式的推理灵活性。"}}
{"id": "2511.15291", "pdf": "https://arxiv.org/pdf/2511.15291", "abs": "https://arxiv.org/abs/2511.15291", "authors": ["Randa Zarnoufi"], "title": "MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of Arabic Hotel Reviews", "categories": ["cs.CL"], "comment": null, "summary": "Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.", "AI": {"tldr": "本文使用SetFit框架进行阿拉伯方言情感分析，在酒店评论数据集上取得73%的F1分数，排名第12，展示了小样本学习在方言处理中的潜力", "motivation": "阿拉伯方言情感分析面临语言多样性和标注数据稀缺的挑战，特别是在酒店评论这样的专业领域", "method": "采用SetFit（Sentence Transformer Fine-tuning）框架，这是一种数据高效的小样本学习技术", "result": "在官方评估集上获得73%的F1分数，在26个参与者中排名第12位", "conclusion": "小样本学习技术在处理专业领域（如酒店评论）中细微的阿拉伯方言文本方面具有巨大潜力，能够有效应对数据稀缺问题"}}
{"id": "2511.15378", "pdf": "https://arxiv.org/pdf/2511.15378", "abs": "https://arxiv.org/abs/2511.15378", "authors": ["Trevor McInroe"], "title": "Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", "AI": {"error": "'NoneType' object has no attribute 'model_dump'"}}
{"id": "2511.15304", "pdf": "https://arxiv.org/pdf/2511.15304", "abs": "https://arxiv.org/abs/2511.15304", "authors": ["Piercosma Bisconti", "Matteo Prandi", "Federico Pierucci", "Francesco Giarrusso", "Marcantonio Bracale", "Marcello Galisai", "Vincenzo Suriani", "Olga Sorokoletova", "Federico Sartore", "Daniele Nardi"], "title": "Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.", "AI": {"tldr": "研究发现诗歌形式的对抗性提示可以作为一种通用的单轮越狱技术，在25个前沿LLM上实现高攻击成功率，诗歌转换比散文基线攻击成功率提升高达18倍", "motivation": "探索风格变化是否能绕过大型语言模型的安全机制，测试当前对齐方法和评估协议的根本局限性", "method": "使用精心策划的诗歌提示攻击25个前沿模型，将1200个MLCommons有害提示通过标准化元提示转换为诗歌形式，使用开源评判模型集成和人工验证进行评估", "result": "诗歌攻击在手工制作诗歌上平均越狱成功率达62%，元提示转换约43%，显著优于非诗歌基线，揭示了跨模型家族和安全训练方法的系统性漏洞", "conclusion": "风格变化本身就能规避当代安全机制，表明当前对齐方法和评估协议存在根本性限制"}}
{"id": "2511.15407", "pdf": "https://arxiv.org/pdf/2511.15407", "abs": "https://arxiv.org/abs/2511.15407", "authors": ["Mingyu Zhang", "Lifeng Zhuo", "Tianxi Tan", "Guocan Xie", "Xian Nie", "Yan Li", "Renjie Zhao", "Zizhu He", "Ziyu Wang", "Jiting Cai", "Yong-Lu Li"], "title": "IPR-1: Interactive Physical Reasoner", "categories": ["cs.AI", "cs.CV"], "comment": "11 pages, 5 figures", "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", "AI": {"tldr": "论文提出IPR（交互式物理推理器）方法，通过世界模型推演来增强VLM的策略，使用PhysCode物理中心动作编码，在1000+游戏中训练，实现了稳健的物理推理能力，性能随训练游戏和交互步骤增加而提升，并能零样本迁移到未见游戏。", "motivation": "研究智能体是否能通过交互学习获得类人的物理和因果推理能力，解决现有VLM/VLA代理缺乏前瞻性推理和世界模型仅模仿视觉模式而非分析物理因果关系的问题。", "method": "提出IPR方法，结合世界模型推演来评分和强化VLM策略，引入PhysCode物理中心动作编码来对齐语义意图与动力学，提供预测和推理的共享动作空间。在1000+异构游戏上进行预训练。", "result": "IPR在三个类人推理层次（生存、好奇心、效用）上表现稳健，总体性能匹配GPT-5，在好奇心方面超越GPT-5。性能随训练游戏数量和交互步骤增加而提升，并能零样本迁移到未见游戏。", "conclusion": "物理中心的交互学习是实现持续改进物理推理能力的有效途径，支持智能体通过交互获得类人的物理和因果推理能力。"}}
{"id": "2511.15355", "pdf": "https://arxiv.org/pdf/2511.15355", "abs": "https://arxiv.org/abs/2511.15355", "authors": ["Alexis Correa-Guillén", "Carlos Gómez-Rodríguez", "David Vilares"], "title": "HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning", "categories": ["cs.CL"], "comment": "Preprint. 12 pages", "summary": "We introduce HEAD-QA v2, an expanded and updated version of a Spanish/English healthcare multiple-choice reasoning dataset originally released by Vilares and Gómez-Rodríguez (2019). The update responds to the growing need for high-quality datasets that capture the linguistic and conceptual complexity of healthcare reasoning. We extend the dataset to over 12,000 questions from ten years of Spanish professional exams, benchmark several open-source LLMs using prompting, RAG, and probability-based answer selection, and provide additional multilingual versions to support future work. Results indicate that performance is mainly driven by model scale and intrinsic reasoning ability, with complex inference strategies obtaining limited gains. Together, these results establish HEAD-QA v2 as a reliable resource for advancing research on biomedical reasoning and model improvement.", "AI": {"tldr": "HEAD-QA v2是西班牙语/英语医疗保健多选推理数据集的扩展版本，包含12,000+问题，用于评估LLM在医疗推理中的表现。", "motivation": "响应对高质量数据集的需求，以捕捉医疗保健推理的语言和概念复杂性。", "method": "扩展数据集至12,000+问题，基于西班牙专业考试；使用提示、RAG和基于概率的答案选择来评估多个开源LLM。", "result": "性能主要由模型规模和内在推理能力驱动，复杂推理策略获得的增益有限。", "conclusion": "HEAD-QA v2是推进生物医学推理和模型改进研究的可靠资源。"}}
{"id": "2511.15456", "pdf": "https://arxiv.org/pdf/2511.15456", "abs": "https://arxiv.org/abs/2511.15456", "authors": ["Qian'ang Mao", "Yuxuan Zhang", "Jiaman Chen", "Wenjun Zhou", "Jiaqi Yan"], "title": "Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining", "categories": ["cs.AI", "q-fin.GN"], "comment": "Written in 2025 Q1", "summary": "As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.", "AI": {"tldr": "TIM框架通过多代理LLM系统分析DeFi交易意图，显著优于现有方法，解决了复杂智能合约交互中用户意图理解难题", "motivation": "DeFi交易理解面临复杂智能合约交互、多维度链上链下因素和不透明日志的挑战，现有方法缺乏深度语义洞察", "method": "提出TIM框架：基于扎根理论构建DeFi意图分类法，使用元级规划器协调领域专家分解多视角意图分析，问题求解器处理多模态数据，认知评估器减轻LLM幻觉", "result": "实验显示TIM显著优于机器学习模型、单一LLM和单一代理基线方法", "conclusion": "TIM为DeFi用户动机提供更可靠的理解，为复杂区块链活动提供情境感知解释，解决了意图推断的核心挑战"}}
{"id": "2511.15370", "pdf": "https://arxiv.org/pdf/2511.15370", "abs": "https://arxiv.org/abs/2511.15370", "authors": ["Guoqiang Liang", "Jingqian Gong", "Mengxuan Li", "Gege Lin", "Shuo Zhang"], "title": "The Empowerment of Science of Science by Large Language Models: New Tools and Methods", "categories": ["cs.CL", "cs.AI"], "comment": "The manuscript is currently ongoing the underreview process of the journal of information science", "summary": "Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.", "AI": {"tldr": "对大型语言模型核心技术的全面综述，从用户角度分析提示工程、知识增强检索生成、微调等技术，并探讨LLMs在科学计量学领域的应用前景", "motivation": "大型语言模型在自然语言处理和多模态任务中展现出卓越能力，成为全球技术竞争的核心议题，需要从用户角度系统梳理其核心技术", "method": "采用文献综述方法，全面回顾LLMs的核心技术发展历程，包括提示工程、检索增强生成、微调、预训练和工具学习等技术路线", "result": "提出了LLMs在科学计量学领域的应用前景，包括基于AI代理的科学评估模型、新研究前沿检测和知识图谱构建方法", "conclusion": "LLMs为科学计量学带来了新的研究范式和技术工具，基于AI代理的科学评估模型和知识图谱构建方法将推动该领域的创新发展"}}
{"id": "2511.15534", "pdf": "https://arxiv.org/pdf/2511.15534", "abs": "https://arxiv.org/abs/2511.15534", "authors": ["Federico Bianchi", "Owen Queen", "Nitya Thakkar", "Eric Sun", "James Zou"], "title": "Exploring the use of AI authors and reviewers at Agents4Science", "categories": ["cs.AI"], "comment": null, "summary": "There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.", "AI": {"error": "'NoneType' object has no attribute 'model_dump'"}}
{"id": "2511.15383", "pdf": "https://arxiv.org/pdf/2511.15383", "abs": "https://arxiv.org/abs/2511.15383", "authors": ["Byungho Jo"], "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.IR"], "comment": null, "summary": "Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.", "AI": {"tldr": "开发了一个合规的检索系统，通过结合LLM重排序和语义搜索技术，在航空维修环境中大幅减少技术人员查找手册的时间，从6-15分钟缩短到18秒，同时保持认证内容的可追溯性。", "motivation": "飞机维修技术人员花费高达30%的工作时间查找手册，这是MRO操作中的效率瓶颈，需要确保所有程序都能追溯到认证来源。", "method": "构建修订鲁棒的嵌入向量，利用ATA章节层次结构和视觉语言解析来结构化认证内容，系统与现有认证查看器协同工作而非替代，允许技术人员预览排名任务并在现有查看器中访问验证程序。", "result": "在49k个合成查询上达到>90%的检索准确率，10名持证AMTs的双语控制研究显示90.9%的前10成功率，查找时间减少95%（从6-15分钟降至18秒/任务）。", "conclusion": "语义检索技术能够在严格监管约束下运行，并显著减少现实世界多语言MRO工作流程中的操作负担。"}}
{"id": "2511.15593", "pdf": "https://arxiv.org/pdf/2511.15593", "abs": "https://arxiv.org/abs/2511.15593", "authors": ["Alexis Audran-Reiss", "Jordi Armengol Estapé", "Karen Hambardzumyan", "Amar Budhiraja", "Martin Josifoski", "Edan Toledo", "Rishi Hazra", "Despoina Magka", "Michael Shvartsman", "Parth Pathak", "Justine T Kao", "Lucia Cipolina-Kun", "Bhavul Gauri", "Jean-Christophe Gagnon-Audet", "Emanuel Tewolde", "Jenny Zhang", "Taco Cohen", "Yossi Adi", "Tatiana Shavrina", "Yoram Bachrach"], "title": "What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity", "categories": ["cs.AI"], "comment": null, "summary": "AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.", "AI": {"tldr": "该研究分析了AI研究代理中构思多样性对性能的影响，发现更高的构思多样性能够提升代理在机器学习任务中的表现。", "motivation": "AI研究代理有望加速科学进步，但目前领域尚不成熟，成功或失败的关键因素尚未完全理解，特别是构思多样性的作用需要深入研究。", "method": "首先分析MLE-bench基准上不同模型和代理框架的轨迹，然后通过控制实验调整构思多样性程度，最后使用除标准奖牌评分外的其他评估指标验证结果。", "result": "研究发现不同模型和代理框架产生不同程度的构思多样性，性能更高的代理具有更高的构思多样性；控制实验证实更高的构思多样性确实带来更强的性能表现。", "conclusion": "构思多样性是影响AI研究代理性能的关键因素，这一发现在多种评估指标下都成立，为改进AI研究代理设计提供了重要指导。"}}
{"id": "2511.15392", "pdf": "https://arxiv.org/pdf/2511.15392", "abs": "https://arxiv.org/abs/2511.15392", "authors": ["Sirui Chen", "Mengshi Zhao", "Lei Xu", "Yuying Zhao", "Beier Zhu", "Hanwang Zhang", "Shengjie Zhao", "Chaochao Lu"], "title": "DEPO: Dual-Efficiency Preference Optimization for LLM Agents", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to AAAI 2026", "summary": "Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.", "AI": {"tldr": "DEPO是一种双效率偏好优化方法，通过联合奖励简洁响应和减少行动步骤，显著提升LLM代理的效率和性能", "motivation": "大型语言模型作为代理时，虽然推理能力提升但思维链变长，影响交互效率，目前缺乏系统性的效率定义阻碍了针对性改进", "method": "提出双效率概念（步骤级效率和轨迹级效率），开发DEPO方法，通过偏好优化联合奖励简洁响应和更少步骤", "result": "在WebShop和BabyAI上实验显示，DEPO减少高达60.9%的token使用和26.9%的步骤，性能提升达29.3%，在数学基准测试中泛化良好，仅用25%数据训练仍保持效率增益", "conclusion": "DEPO成功解决了LLM代理效率问题，通过系统定义和优化方法实现了效率和性能的双重提升，具有良好的泛化能力和数据效率"}}
{"id": "2511.15408", "pdf": "https://arxiv.org/pdf/2511.15408", "abs": "https://arxiv.org/abs/2511.15408", "authors": ["Shanlin Zhou", "Xinpeng Wang", "Jianxun Lian", "Zhenghao Liu", "Laks V. S. Lakshmanan", "Xiaoyuan Yi", "Yongtao Hao"], "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.MA", "cs.NE"], "comment": "13 pages,9 figures. This work has been submitted to the IEEE for possible publication", "summary": "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.", "AI": {"tldr": "提出了NAMEGEn多智能体优化框架，通过迭代的目标提取、名称生成和评估来解决中文起名这一短文本创意生成任务，在满足多样化个性化需求的同时提供有意义的解释", "motivation": "大型语言模型在创意自然语言生成方面仍有挑战：多目标灵活性不足（难以同时满足个性化、细粒度、多元化的用户需求）和解释复杂性（需要理解隐含含义来增强用户感知）", "method": "NAMEGEn多智能体优化框架，包含迭代的三个阶段：目标提取、名称生成和评估。构建了包含17k+古诗的数据集增强美学效果，并建立了CBNames基准测试", "result": "实验表明NAMEGEn能有效生成满足多样化个性化需求的创意名字并提供有意义的解释，在六个不同LLM基线的基准方法中表现最优，且无需任何训练", "conclusion": "该框架成功解决了短文本创意生成中的多目标满足和解释生成难题，为个性化创意自然语言生成提供了有效解决方案"}}
{"id": "2511.15418", "pdf": "https://arxiv.org/pdf/2511.15418", "abs": "https://arxiv.org/abs/2511.15418", "authors": ["Arjun Gangwar", "Kaousheik Jayakumar", "S. Umesh"], "title": "Building Robust and Scalable Multilingual ASR for Indian Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).", "AI": {"tldr": "SPRING Lab开发的ASR系统，使用多解码器架构和音位通用标签集，在ASRU MADASR 2.0挑战赛中在3种语言上超越基线性能，并获得最高的语言和方言识别准确率", "motivation": "改进ASR系统以准确预测8种语言33种方言的语言和方言识别，参与限制额外数据使用的Track 1和Track 2赛道", "method": "采用多解码器架构，使用音位通用标签集(CLS)作为中间表示的新颖训练方法，并探索了将音位表示转换回对应字形表示的各种方法", "result": "在音位空间性能超越基线，在Track 2中3种语言的WER/CER指标上击败基线，在所有参赛团队中获得最高的语言ID和方言ID准确率", "conclusion": "提出的多解码器架构和音位CLS方法有效提升了多语言ASR系统的性能，特别是在语言和方言识别方面取得了显著成果"}}
{"id": "2511.15424", "pdf": "https://arxiv.org/pdf/2511.15424", "abs": "https://arxiv.org/abs/2511.15424", "authors": ["Yuanjie Zhu", "Liangwei Yang", "Ke Xu", "Weizhi Zhang", "Zihe Song", "Jindong Wang", "Philip S. Yu"], "title": "LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.", "AI": {"tldr": "LLM-MemCluster是一个完全基于大语言模型的文本聚类框架，通过动态内存和双重提示策略实现无调优的端到端聚类，在多个基准数据集上显著超越现有方法。", "motivation": "现有LLM在文本聚类中存在缺乏状态记忆进行迭代优化和难以管理聚类粒度的根本限制，导致需要依赖复杂的外部模块管道，无法实现真正的端到端方法。", "method": "提出LLM-MemCluster框架，将聚类重新概念化为完全LLM原生的任务，利用动态内存实现状态感知，通过双重提示策略让模型能够推理并确定聚类数量。", "result": "在多个基准数据集上的评估显示，该无调优框架显著且一致地超越了强基线方法。", "conclusion": "LLM-MemCluster为基于LLM的文本聚类提供了一个有效、可解释且真正端到端的范式。"}}
{"id": "2511.15512", "pdf": "https://arxiv.org/pdf/2511.15512", "abs": "https://arxiv.org/abs/2511.15512", "authors": ["Yves Pauli", "Jan-Bernard Marsman", "Finn Rabe", "Victoria Edkins", "Roya Hüppi", "Silvia Ciampelli", "Akhil Ratan Misra", "Nils Lang", "Wolfram Hinzen", "Iris Sommer", "Philipp Homan"], "title": "Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis", "categories": ["cs.CL"], "comment": "26 pages, 3 figures", "summary": "The introduction of large language models and other influential developments in AI-based language processing have led to an evolution in the methods available to quantitatively analyse language data. With the resultant growth of attention on language processing, significant challenges have emerged, including the lack of standardisation in organising and sharing linguistic data and the absence of standardised and reproducible processing methodologies. Striving for future standardisation, we first propose the Language Processing Data Structure (LPDS), a data structure inspired by the Brain Imaging Data Structure (BIDS), a widely adopted standard for handling neuroscience data. It provides a folder structure and file naming conventions for linguistic research. Second, we introduce pelican nlp, a modular and extensible Python package designed to enable streamlined language processing, from initial data cleaning and task-specific preprocessing to the extraction of sophisticated linguistic and acoustic features, such as semantic embeddings and prosodic metrics. The entire processing workflow can be specified within a single, shareable configuration file, which pelican nlp then executes on LPDS-formatted data. Depending on the specifications, the reproducible output can consist of preprocessed language data or standardised extraction of both linguistic and acoustic features and corresponding result aggregations. LPDS and pelican nlp collectively offer an end-to-end processing pipeline for linguistic data, designed to ensure methodological transparency and enhance reproducibility.", "AI": {"tldr": "LPDS数据结构和pelican nlp工具包为语言处理提供标准化、可复现的端到端处理流程", "motivation": "AI语言处理快速发展但缺乏数据组织和处理方法的标准化，导致可复现性不足", "method": "提出LPDS数据结构和pelican nlp Python包，提供文件夹结构、文件命名规范和模块化处理流程", "result": "建立了语言处理的标准数据结构和可配置的处理工具，支持从数据清洗到特征提取的完整流程", "conclusion": "LPDS和pelican nlp共同提供了确保方法透明度和增强可复现性的端到端语言数据处理解决方案"}}
{"id": "2511.15552", "pdf": "https://arxiv.org/pdf/2511.15552", "abs": "https://arxiv.org/abs/2511.15552", "authors": ["Artem Chervyakov", "Ulyana Isaeva", "Anton Emelyanov", "Artem Safin", "Maria Tikhonova", "Alexander Kharitonov", "Yulia Lyakh", "Petr Surovtsev", "Denis Shevelev Vildan Saburov", "Vasily Konovalov", "Elisei Rykov", "Ivan Sviridov", "Amina Miftakhova", "Ilseyar Alimova", "Alexander Panchenko", "Alexander Kapitanov", "Alena Fenogenova"], "title": "Multimodal Evaluation of Russian-language Architectures", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.", "AI": {"tldr": "Mera Multi是一个针对俄语的多模态评估框架，包含18个新构建的评估任务，涵盖文本、图像、音频和视频模态，为俄语多模态模型提供首个基准测试。", "motivation": "目前缺乏针对俄语的多模态基准测试，多模态大语言模型的智能、局限性和风险尚未得到充分理解，特别是在俄语语境下。", "method": "创建基于指令的评估框架，包含18个全新构建的数据集，关注俄语文化和语言特性，统一提示词和指标，并采用水印和许可证防止基准泄露。", "result": "为闭源和开源模型提供了基线结果，建立了多模态能力的通用分类法。", "conclusion": "该基准为构建斯拉夫语系等类型多样语言的多模态基准提供了可复制的方法论，虽然当前聚焦俄语，但具有扩展潜力。"}}
{"id": "2511.15574", "pdf": "https://arxiv.org/pdf/2511.15574", "abs": "https://arxiv.org/abs/2511.15574", "authors": ["Qihao Yang", "Xuelin Wang", "Jiale Chen", "Xuelian Dong", "Yuxin Hao", "Tianyong Hao"], "title": "HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by AAAI-2026", "summary": "Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.", "AI": {"tldr": "HSKBenchmark是首个用于中文二语习得的分阶段建模和写作评估基准，包含真实教材数据、合成指令样本和语言学评估系统，通过课程调优框架模拟人类学习轨迹，证明LLMs在中文写作能力上可达到高级人类学习者水平。", "motivation": "语言习得研究对揭示人类语言智能本质很重要，但控制人类学习者语言输入的实验存在伦理和实践限制，需要可控制、可复现的替代方案来支持中文二语习得的阶段性建模和评估。", "method": "构建HSKBenchmark基准，覆盖HSK 3-6级，包含676万词符的真实教材、1.6万合成指令样本、30个测试主题；采用课程调优框架从初级到高级训练模型；创建评估系统检查语法覆盖、写作错误、词汇句法复杂度和整体评分；基于1万篇学习者作文微调HSKAgent。", "result": "实验结果表明HSKBenchmark能有效建模中文二语习得，并作为LLMs动态写作评估的可靠基准。微调后的LLMs写作表现与高级人类学习者相当，并展现出类人的习得特征。", "conclusion": "HSKBenchmark、HSKAgent和检查点作为基础工具和资源，为未来语言习得建模和LLMs可解释性研究铺平了道路。"}}
{"id": "2511.15709", "pdf": "https://arxiv.org/pdf/2511.15709", "abs": "https://arxiv.org/abs/2511.15709", "authors": ["Violeta Kastreva", "Philip Whittington", "Dennis Komm", "Tiago Pimentel"], "title": "Tokenisation over Bounded Alphabets is Hard", "categories": ["cs.CL", "cs.DS", "cs.LG"], "comment": null, "summary": "Recent works have shown that tokenisation is NP-complete. However, these works assume tokenisation is applied to inputs with unboundedly large alphabets -- an unrealistic assumption, given that in practice tokenisers operate over fixed-size alphabets, such as bytes or Unicode characters. We close this gap by analysing tokenisation over bounded $n$-ary alphabets, considering two natural variants: bottom-up tokenisation and direct tokenisation, where we must, respectively, select a sequence of merge operations or a vocabulary whose application optimally compresses a dataset. First, we note that proving hardness results for an $n$-ary alphabet proves the same results for alphabets of any larger size. We then prove that even with binary alphabets, both variants are not only NP-complete, but admit no polynomial-time approximation scheme (unless P=NP). We further show that direct tokenisation remains NP-complete even when applied to unary alphabets. While unary alphabets may not be practically useful, this result establishes that the computational intractability of tokenisation is not an artifact of large alphabets or complex constructions, but a fundamental barrier. Overall, our results explain why practical algorithms such as BPE and UnigramLM are heuristic, and points toward approximation algorithms being an important path going forward for tokenisation research.", "AI": {"tldr": "该论文证明了在有界字母表（包括二进制和一元字母表）上的分词问题是NP完全问题，且不存在多项式时间近似方案，解释了为什么实际分词算法如BPE和UnigramLM都是启发式的。", "motivation": "先前的研究假设分词应用于无界大字母表，但实际中分词器操作的是固定大小的字母表（如字节或Unicode字符）。本文旨在填补这一空白，分析有界n元字母表上的分词问题。", "method": "分析两种自然变体：自底向上分词和直接分词，分别对应选择合并操作序列或词汇表以最优压缩数据集。证明对于二进制字母表，两种变体都是NP完全问题且无多项式时间近似方案。进一步证明直接分词在一元字母表上也是NP完全的。", "result": "即使对于二进制字母表，两种分词变体都是NP完全问题，且不存在多项式时间近似方案（除非P=NP）。直接分词在一元字母表上也是NP完全的。", "conclusion": "分词的计算难处理性不是大字母表或复杂构造的产物，而是一个基本障碍。这解释了为什么BPE和UnigramLM等实际算法是启发式的，并指出近似算法是分词研究的重要方向。"}}
