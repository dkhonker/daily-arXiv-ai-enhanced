<div id=toc></div>

# 目录

- [cs.AI](#cs.AI) [总数: 54]
- [cs.CL](#cs.CL) [总数: 31]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples](https://arxiv.org/abs/2512.09931)
*Akaash Chatterjee, Suman Kundu*

**主要类别:** cs.AI

**AI概要:** ExaCraft是一个个性化教育AI系统，通过实时分析学习者行为和用户配置文件，生成文化相关且适应个人学习需求的动态示例


<details>
  <summary>更多</summary>
  
**动机:** 现有教育AI工具缺乏生成个性化示例和适应学习者动态理解变化的能力，无法有效连接学习者的个人经验

**方法:** 结合Google Gemini AI和Python Flask API，通过Chrome扩展访问，整合用户配置文件（位置、教育、职业、复杂度偏好）和实时学习者行为分析

**结果:** 系统能够适应五个关键学习情境方面：困难指标、掌握模式、主题进展历史、会话边界和学习进展信号

**结论:** ExaCraft通过动态生成从基础概念到高级技术实现的演进示例，有效响应主题重复、重新生成请求和主题进展模式，提升学习效果

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ExaCraft%3A+Dynamic+Learning+Context+Adaptation+for+Personalized+Educational+Examples，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09931&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.

</details>


### [2] [Suzume-chan: Your Personal Navigator as an Embodied Information Hub](https://arxiv.org/abs/2512.09932)
*Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种名为'具身信息枢纽'的新方法，通过物理和对话交互来分享知识，开发了本地运行的软体AI代理Suzume-chan，使用语言模型和RAG技术，旨在减少心理距离，创造更温暖、更人性化的知识共享体验。


<details>
  <summary>更多</summary>
  
**动机:** 现有数字工具虽然改善了信息获取，但缺乏创造深度理解所需的连接感。基于社会临场感理论，研究旨在解决实时人类沟通中'在一起'的感觉缺失问题。

**方法:** 提出'具身信息枢纽'概念，开发原型Suzume-chan——一个小型软体AI代理，采用本地运行的语言模型和检索增强生成(RAG)技术，通过语音解释学习和对话响应实现交互。

**结果:** 开发了能够通过物理和对话交互分享知识的AI代理原型，实现了减少心理距离的目标。

**结论:** 该方法通过结合物理存在和对话交互，成功创造了更温暖、更人性化的知识共享方式，验证了社会临场感理论在数字知识传递中的应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Suzume-chan%3A+Your+Personal+Navigator+as+an+Embodied+Information+Hub，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09932，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09932&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of "being together" enhances communication. An "Embodied Information Hub" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.

</details>


### [3] [Exploring Health Misinformation Detection with Multi-Agent Debate](https://arxiv.org/abs/2512.09935)
*Chih-Han Chen, Chen-Han Tsai, Yu-Shao Peng*

**主要类别:** cs.AI

**AI概要:** 提出一个两阶段健康信息检测框架：先通过LLM计算证据一致性分数，当分数低于阈值时启动多智能体辩论来合成冲突证据并生成有理由的裁决


<details>
  <summary>更多</summary>
  
**动机:** 健康相关虚假信息在线传播日益严重，需要高质量证据检索和严谨推理过程来进行有效验证

**方法:** 两阶段框架：1)一致性分数预测阶段-使用大语言模型独立评估检索到的文章并计算总体证据立场的一致性分数；2)多智能体辩论阶段-当分数低于阈值时，多个智能体进行结构化辩论以合成冲突证据

**结果:** 实验结果表明，与基线方法相比，该两阶段方法取得了更优越的性能

**结论:** 结合自动评分与协作推理对于复杂验证任务具有重要价值

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Health+Misinformation+Detection+with+Multi-Agent+Debate，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09935，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09935&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.

</details>


### [4] [Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting](https://arxiv.org/abs/2512.09944)
*Moein Heidari, Mohammad Amin Roohi, Armin Khosravi, Ilker Hacihaliloglu*

**主要类别:** cs.AI

**AI概要:** Echo-CoPilot是一个基于大语言模型的多视图、多任务超声心动图智能代理系统，通过协调多个专业工具实现自动化的心脏超声分析和报告生成


<details>
  <summary>更多</summary>
  
**动机:** 当前超声心动图分析需要人工完成，虽然已有各种基础模型能处理单个子任务，但缺乏统一的临床连贯评估系统

**方法:** 采用ReAct风格的循环机制，使用大语言模型协调视图识别、心脏结构分割、测量、疾病预测和报告生成等专业工具

**结果:** 在MIMIC-EchoQA基准测试中达到50.8%的准确率，优于通用和生物医学视频视觉语言模型，能处理临床决策边界附近的复杂病例

**结论:** Echo-CoPilot展示了通过大语言模型协调专业工具在医疗影像分析中的潜力，为自动化超声心动图解释提供了有效解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Echo-CoPilot%3A+A+Multi-View%2C+Multi-Task+Agent+for+Echocardiography+Interpretation+and+Reporting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09944，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09944&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.

</details>


### [5] [Fuzzy Hierarchical Multiplex](https://arxiv.org/abs/2512.09976)
*Alexis Kafantaris*

**主要类别:** cs.AI

**AI概要:** 提出了一种扩展FCM因果关系的模糊优化框架，用于服务流程设计中的信息传输优化，包含对FHM的详细分析


<details>
  <summary>更多</summary>
  
**动机:** 扩展FCM因果关系，为服务流程设计中的信息传输服务优化提供理论框架

**方法:** 利用动态性将数据映射到度量中，建立多路复用机制来检查概念的逻辑蕴含和层次结构

**结果:** 提出了一个白盒理论框架，阐述了其主要目标和方向，并通过示例进行了说明

**结论:** 该框架为服务优化提供了一个逻辑严谨、数学基础扎实的理论基础，并以简洁优雅的方式完成了FHM的全面分析

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fuzzy+Hierarchical+Multiplex，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.09976，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.09976&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** A new fuzzy optimization framework that extends FCM causality is proposed. This model utilizes the dynamics to map data into metrics and create a framework that examines logical implication and hierarchy of concepts using a multiplex. Moreover, this is a white-theoretical paper introducing the framework and analyzing the logic and math behind it. Upon this extension the main objectives and the orientation of this framework is expounded and exemplified; this framework is meant for service optimization of information transmission in service process design. Lastly, a thorough analysis of the FHM is included which is done following the logical steps in a simple and elegant manner.

</details>


### [6] [Exploring LLMs for Scientific Information Extraction Using The SciEx Framework](https://arxiv.org/abs/2512.10004)
*Sha Li, Ayush Sadekar, Nathan Self, Yiqi Su, Lars Andersland, Mira Chaplin, Annabel Zhang, Hyoju Yang, James B Henderson, Krista Wigginton, Linsey Marr, T. M. Murali, Naren Ramakrishnan*

**主要类别:** cs.AI

**AI概要:** SciEx是一个模块化框架，用于从科学文献中提取细粒度信息，解决了长文档、多模态内容和快速变化的数据模式等挑战。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法难以处理科学文献的长上下文、多模态内容以及跨多篇文献的不一致细粒度信息标准化问题，特别是在数据模式快速变化时重新架构系统困难。

**方法:** 提出SciEx模块化框架，将PDF解析、多模态检索、提取和聚合等关键组件解耦，支持新模型、提示策略和推理机制的灵活集成。

**结果:** 在三个科学主题的数据集上评估了SciEx提取细粒度信息的准确性和一致性。

**结论:** 研究结果提供了对当前基于LLM的流水线优势和局限性的实用见解，SciEx框架实现了按需数据提取的简化和可扩展性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+LLMs+for+Scientific+Information+Extraction+Using+The+SciEx+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10004&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.

</details>


### [7] [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)
*Salomé Guilbert, Cassandra Masschelein, Jeremy Goumaz, Bohdan Naida, Philippe Schwaller*

**主要类别:** cs.AI

**AI概要:** DynaMate是一个基于多智能体LLM的框架，能够自主设计和执行蛋白质和蛋白质-配体系统的完整分子动力学模拟工作流，包括自由能结合亲和力计算，解决了MD模拟设置的技术复杂性问题。


<details>
  <summary>更多</summary>
  
**动机:** 分子动力学模拟在药物发现和蛋白质工程中应用广泛，但其参数化、输入准备和软件配置等技术复杂性阻碍了广泛高效使用。现有智能体LLM尚未成功自动化蛋白质-配体MD工作流。

**方法:** 开发了DynaMate模块化多智能体框架，集成动态工具使用、网络搜索、PaperQA和自校正行为。包含三个专业模块：实验规划、模拟执行和结果分析。在12个不同复杂度的基准系统上进行评估。

**结果:** DynaMate能够可靠执行完整的MD模拟，通过迭代推理纠正运行时错误，生成有意义的蛋白质-配体相互作用分析，展示了高成功率、效率和适应性。

**结论:** 该自动化框架为未来生物分子和药物设计应用提供了标准化、可扩展且时间高效的分子建模流程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DynaMate%3A+An+Autonomous+Agent+for+Protein-Ligand+Molecular+Dynamics+Simulations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10034&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.

</details>


### [8] [SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration](https://arxiv.org/abs/2512.10046)
*Yan Zhuang, Jiawei Ren, Xiaokang Ye, Jianzhi Shen, Ruixuan Zhang, Tianai Yue, Muhammad Faayez, Xuhong He, Ziqiao Ma, Lianhui Qin, Zhiting Hu, Tianmin Shu*

**主要类别:** cs.AI

**AI概要:** SWR是一个基于Unreal Engine 5构建的大规模、逼真城市环境仿真平台，用于评估机器人在复杂城市场景中的多模态指令跟随和多机器人协作能力


<details>
  <summary>更多</summary>
  
**动机:** 当前基础模型主要关注室内家庭场景，缺乏针对大规模城市环境的机器人仿真平台和评估基准

**方法:** 开发SimWorld-Robotics平台，通过程序化生成无限逼真的城市场景，包含动态元素（行人、交通系统），支持多机器人控制和通信，并建立两个新的机器人基准测试任务

**结果:** 实验结果表明，包括视觉语言模型在内的最先进模型在这些任务上表现不佳，缺乏城市环境所需的稳健感知、推理和规划能力

**结论:** SWR平台填补了城市环境机器人仿真的空白，提出的基准测试能够全面评估机器人在真实城市场景中的关键能力，揭示了当前模型在城市环境中的局限性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SimWorld-Robotics%3A+Synthesizing+Photorealistic+and+Dynamic+Urban+Environments+for+Multimodal+Robot+Navigation+and+Collaboration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10046，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10046&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.

</details>


### [9] [Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning](https://arxiv.org/abs/2512.10054)
*Logan Robbins*

**主要类别:** cs.AI

**AI概要:** PDT提出了一种参数高效的并行解码架构，通过在冻结预训练模型中嵌入协调原语来解决LLM自回归解码的延迟瓶颈问题。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型的自回归解码本质上是顺序的，导致延迟随输出长度线性增长。现有的分解填充方法存在连贯性漂移问题，缺乏跨流通信。

**方法:** 引入轻量级推测性笔记调节适配器(SNC)，允许并行解码流通过共享的动态潜在空间进行同步。将协调制定为推测共识问题，使用学习验证头门控的全局总线机制。

**结果:** 在5万步课程中使用冻结的200亿参数骨干验证，达到77.8%的覆盖预测精度，能够恢复近似串行语义而不修改主干权重。

**结论:** PDT为结构化并行生成提供了一个可扩展、高效的替代方案，无需进行完整的模型微调。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Parallel+Decoder+Transformer%3A+Model-Internal+Parallel+Decoding+with+Speculative+Invariance+via+Note+Conditioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10054&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \textit{coherence drift} due to the lack of cross-stream communication. In this work, we introduce the \textbf{Parallel Decoder Transformer (PDT)}, a parameter-efficient architecture that embeds coordination primitives directly into the inference process of a frozen pre-trained model.
  Instead of retraining the base model, PDT injects lightweight \textit{Speculative Note Conditioning (SNC)} adapters that allow parallel decoding streams to synchronize via a shared, dynamic latent space. We formulate coordination as a \textit{speculative consensus} problem, where sibling streams broadcast semantic ``notes'' to a global bus, gated by a learned verification head. We validate our approach on a 50,000-step curriculum using a frozen 20B-parameter backbone. Our results demonstrate that PDT achieves effective self-correction, reaching \textbf{77.8\% precision} in coverage prediction and recovering approximate serial semantics without modifying the trunk weights. This establishes PDT as a scalable, efficient alternative to full model fine-tuning for structured parallel generation.

</details>


### [10] [Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research](https://arxiv.org/abs/2512.10058)
*Dani Roytburg, Beck Miller*

**主要类别:** cs.AI

**AI概要:** 该论文通过大规模文献计量分析发现AI安全与AI伦理研究存在明显的结构性分离，80%以上的合作发生在各自领域内部，跨领域交流仅由少数关键研究者维系。


<details>
  <summary>更多</summary>
  
**动机:** AI领域快速发展使得对齐研究日益紧迫，但安全研究和伦理研究沿着两条平行轨道发展，对"对齐"的定义和理解存在分歧，导致研究相对孤立。

**方法:** 使用文献计量和合著网络分析方法，分析了2020-2025年间12个主要ML和NLP会议的6,442篇论文，评估安全与伦理研究社区之间的结构联系。

**结果:** 发现超过80%的合作发生在各自社区内部，跨领域连接高度集中：约5%的论文贡献了85%以上的桥梁链接，移除少数关键研究者会显著增加隔离程度。

**结论:** 安全与伦理的分歧不仅是概念性的，更是制度性的，需要通过共享基准、跨机构平台和混合方法学来整合技术安全工作和规范伦理，以构建既稳健又公正的AI系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mind+the+Gap%21+Pathways+Towards+Unifying+AI+Safety+and+Ethics+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10058&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, "aligned" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.
  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.

</details>


### [11] [Linear socio-demographic representations emerge in Large Language Models from indirect cues](https://arxiv.org/abs/2512.10065)
*Paul Bouchaud, Pedro Ramaciotti*

**主要类别:** cs.AI

**AI概要:** 研究发现大型语言模型通过名字和职业等间接线索在激活空间中线性编码用户的社会人口属性，这些编码会影响模型的下游行为如职业推荐，即使通过偏见基准测试的模型仍可能存在隐性偏见。


<details>
  <summary>更多</summary>
  
**动机:** 探究LLMs如何从名字和职业等间接线索推断人类对话伙伴的社会人口属性，并了解这些隐性表征如何影响模型行为。

**方法:** 在四个开源Transformer LLMs（Magistral 24B、Qwen3 14B、GPT-OSS 20B、OLMo2-1B）的残差流中进行探测，分析显性人口统计披露和隐性线索（名字、职业）的激活模式。

**结果:** 发现LLMs在激活空间中形成可解释的线性人口统计表征，名字激活与人口普查一致的性别和种族表征，职业触发与现实劳动力统计数据相关的表征，这些表征主动影响下游行为如职业推荐。

**结论:** 即使通过偏见测试的LLMs仍可能隐藏和利用隐性偏见，这对大规模应用时的公平性具有重要影响，需要更深入的表征层面偏见检测方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Linear+socio-demographic+representations+emerge+in+Large+Language+Models+from+indirect+cues，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10065，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10065&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

</details>


### [12] [Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit](https://arxiv.org/abs/2512.10092)
*Nick Jiang, Xiaoqing Sun, Lisa Dunlap, Lewis Smith, Neel Nanda*

**主要类别:** cs.AI

**AI概要:** 该论文提出使用稀疏自编码器(SAEs)生成可解释的概念嵌入表示，相比传统LLM方法和密集嵌入模型，在成本效益、可靠性和可控性方面表现更优，适用于大规模文本语料分析。


<details>
  <summary>更多</summary>
  
**动机:** 当前分析大规模文本语料的方法主要依赖昂贵的LLM技术或缺乏可控性的密集嵌入模型，需要一种更经济、可靠且可控的分析方法。

**方法:** 使用稀疏自编码器(SAEs)创建SAE嵌入表示，其维度映射到可解释的概念，通过四个数据分析任务验证其效果。

**结果:** SAE嵌入比LLM方法成本降低2-8倍且更可靠，比密集嵌入更具可控性；能够发现数据集间的语义差异、概念相关性，并在基于属性的检索中表现更优。

**结论:** SAEs成为非结构化数据分析的多功能工具，强调了通过数据解释模型的重要性，为模型行为分析和偏见检测提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Embeddings+with+Sparse+Autoencoders%3A+A+Data+Analysis+Toolkit，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10092，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10092&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding "trigger" phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.

</details>


### [13] [Robust AI Security and Alignment: A Sisyphean Endeavor?](https://arxiv.org/abs/2512.10100)
*Apostol Vassilev*

**主要类别:** cs.AI

**AI概要:** N/A


<details>
  <summary>更多</summary>
  
**动机:** N/A

**方法:** N/A

**结果:** N/A

**结论:** N/A

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+AI+Security+and+Alignment%3A+A+Sisyphean+Endeavor%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10100&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel's incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.

</details>


### [14] [Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups](https://arxiv.org/abs/2512.10105)
*Soorya Ram Shimgekar, Abhay Goyal, Lam Yin Cheung, Roy Ka-Wei Lee, Koustuv Saha, Pi Zonooz, Navin Kumar*

**主要类别:** cs.AI

**AI概要:** 该研究提出了一个两阶段计算框架来分析新加坡Telegram群组中的阴谋论内容，发现阴谋论话语被编织在日常讨论中而非局限于孤立回音室，挑战了关于网络激进化的常见假设。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是分析数字通信生态系统中日益嵌入的阴谋论话语，这些内容的结构和传播难以研究，特别是在新加坡Telegram群组中的表现和传播模式。

**方法:** 采用两阶段计算框架：1) 微调RoBERTa-large模型分类阴谋论消息(F1-score=0.866)；2) 构建带符号信念图，使用Signed Belief Graph Neural Network (SiBeGNN)和Sign Disentanglement Loss学习嵌入表示。

**结果:** 从553,648条消息中识别出7种叙事原型：法律话题、医疗关注、媒体讨论、金融、权威矛盾、群组管理和一般聊天。SiBeGNN聚类质量(cDBI=8.38)优于基线方法(13.60-67.27)，专家评估一致性达88%。

**结论:** 阴谋论消息不仅出现在怀疑或不信任的集群中，也存在于金融、法律和日常事务的常规讨论中，表明阴谋论话语在普通社交互动中运作，挑战了网络激进化的传统认知，为信念驱动的话语分析提供了新的计算方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Modeling+Narrative+Archetypes+in+Conspiratorial+Narratives%3A+Insights+from+Singapore-Based+Telegram+Groups，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10105，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10105&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.
  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.

</details>


### [15] [AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice](https://arxiv.org/abs/2512.10114)
*Mesafint Fanuel, Mahmoud Nabil Mahmoud, Crystal Cook Marshal, Vishal Lakhotia, Biswanath Dari, Kaushik Roy, Shaohu Zhang*

**主要类别:** cs.AI

**AI概要:** AgriRegion是一个针对农业领域的RAG框架，通过地理空间元数据注入和区域优先重排机制，有效减少LLM在农业咨询中的幻觉问题，提高地域适应性建议的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 通用LLM在农业领域存在上下文幻觉问题，由于土壤、气候和地方法规的差异，提供非事实性建议或在不同地区产生灾难性后果。

**方法:** 开发AgriRegion RAG框架，包含地理空间元数据注入层和区域优先重排机制，限制知识库为已验证的本地农业扩展服务，并在检索时强制地理空间约束。

**结果:** 相比最先进的LLM系统，AgriRegion减少幻觉10-20%，并显著提高信任分数。创建了包含160个领域特定问题的AgriRegion-Eval基准数据集。

**结论:** AgriRegion通过地域感知的检索增强生成方法，有效解决了农业咨询中的地域适应性挑战，为精准农业提供了可靠的技术支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgriRegion%3A+Region-Aware+Retrieval+for+High-Fidelity+Agricultural+Advice，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10114&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.

</details>


### [16] [The 2025 Foundation Model Transparency Index](https://arxiv.org/abs/2512.10169)
*Alexander Wan, Kevin Klyman, Sayash Kapoor, Nestor Maslej, Shayne Longpre, Betty Xiong, Percy Liang, Rishi Bommasani*

**主要类别:** cs.AI

**AI概要:** 2025年基础模型透明度指数显示，主要AI公司的透明度从2024年的58分（满分100）下降到2025年的40分，IBM以95分领先，xAI和Midjourney仅得14分，公司在训练数据和模型影响方面最为不透明。


<details>
  <summary>更多</summary>
  
**动机:** 随着基础模型开发公司的影响力日益增大，需要评估其透明度实践的变化情况，为政策制定提供依据。

**方法:** 采用年度透明度指数评估方法，新增数据获取、使用数据和监控等指标，首次评估阿里巴巴、DeepSeek和xAI等公司。

**结果:** 透明度整体下降，平均分从58降至40；IBM表现优异（95分），xAI和Midjourney最差（14分）；公司在训练数据和部署后影响方面最不透明。

**结论:** 尽管政策制定者开始要求透明度，但公司缺乏成为透明度领导者的动力，需要更积极的政策干预来解决关键信息缺失问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+2025+Foundation+Model+Transparency+Index，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10169，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10169&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.

</details>


### [17] [CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment](https://arxiv.org/abs/2512.10206)
*Yakun Zhu, Zhongzhen Huang, Qianhan Feng, Linjie Mu, Yannian Gu, Shaoting Zhang, Qi Dou, Xiaofan Zhang*

**主要类别:** cs.AI

**AI概要:** CP-Env是一个可控的医院环境模拟系统，用于评估大语言模型在端到端临床路径中的表现，包括分诊、专科咨询、诊断测试和多学科团队会议等完整医疗流程。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基准测试主要关注静态考试或孤立对话，无法充分评估LLMs在动态临床场景中的表现，需要更全面的医疗AI评估框架。

**方法:** 构建了包含患者和医生代理的医院生态系统模拟环境，采用三层评估框架（临床效能、流程能力和专业伦理），支持分支和长时程任务执行。

**结果:** 大多数模型在处理临床路径复杂性时表现不佳，出现幻觉现象并丢失关键诊断细节。过度推理步骤有时适得其反，顶级模型通过内化知识减少工具依赖。

**结论:** CP-Env通过全面的端到端临床评估推进了医疗AI代理的发展，提供了基准和评估工具供进一步研究使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CP-Env%3A+Evaluating+Large+Language+Models+on+Clinical+Pathways+in+a+Controllable+Hospital+Environment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10206，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10206&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.

</details>


### [18] [An exploration for higher efficiency in multi objective optimisation with reinforcement learning](https://arxiv.org/abs/2512.10208)
*Mehmet Emin Aydin*

**主要类别:** cs.AI

**AI概要:** 该论文提出使用多目标强化学习来优化搜索算法中的算子序列选择问题，旨在提高多目标优化问题的求解效率。


<details>
  <summary>更多</summary>
  
**动机:** 优化和搜索过程中的效率问题影响算法性能，使用多个算子代替单一算子处理邻域移动操作有潜力，但需要找到最优或接近最优的算子序列。多目标优化问题在此方面研究较少。

**方法:** 基于多目标强化学习的通用方法，通过经验泛化来学习最优算子序列，目前已完成部分阶段研究。

**结果:** 论文概述了一个正在开发中的通用化方法，部分阶段已完成，展示了多目标强化学习在提高效率方面的潜力。

**结论:** 多目标强化学习方法为解决多目标优化中的算子序列选择问题提供了有前景的解决方案，有望显著提升优化算法的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+exploration+for+higher+efficiency+in+multi+objective+optimisation+with+reinforcement+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10208，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10208&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.

</details>


### [19] [ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs](https://arxiv.org/abs/2512.10211)
*Junyang Cai, El Mehdi Er Raqabi, Pascal Van Hentenryck, Bistra Dilkina*

**主要类别:** cs.AI

**AI概要:** 本文提出ID-PaS框架，扩展了预测-搜索方法到参数化混合整数规划问题，通过身份感知学习处理异构变量，实验显示优于Gurobi和传统PaS方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有预测-搜索方法仅限于二元问题且忽略实际应用中常见的固定变量问题，需要扩展到更一般的参数化混合整数规划问题。

**方法:** 提出ID-PaS身份感知学习框架，使机器学习模型能更有效地处理异构变量，扩展预测-搜索方法到参数化MIP问题。

**结果:** 在多个实际大规模问题上的实验表明，ID-PaS始终优于最先进的求解器Gurobi和传统PaS方法。

**结论:** ID-PaS框架成功解决了传统预测-搜索方法的限制，为处理参数化混合整数规划问题提供了有效的机器学习增强解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ID-PaS+%3A+Identity-Aware+Predict-and-Search+for+General+Mixed-Integer+Linear+Programs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10211，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10211&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.

</details>


### [20] [Reverse Thinking Enhances Missing Information Detection in Large Language Models](https://arxiv.org/abs/2512.10273)
*Yuxin Liu, Chaojie Gu, Yihang Zhang, Bin Qian, Shibo He*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种逆向思维框架，通过反向推理来识别缺失信息，相比传统正向推理方法显著提升了LLMs在缺失信息检测任务中的性能表现。


<details>
  <summary>更多</summary>
  
**动机:** LLMs在涉及缺失信息的推理任务中经常出现回答不完整、事实错误和幻觉等问题，传统的正向推理方法如Chain-of-Thought和Tree-of-Thought无法系统性地识别和恢复被省略的信息。

**方法:** 基于反向推理的最新研究成果，提出了一个新颖的逆向思维框架，指导LLMs通过逆向思考来识别必要条件和定位缺失元素，将缺失信息识别任务转化为更易处理的逆向推理问题。

**结果:** 实验结果表明，逆向思维方法相比传统正向推理方法取得了显著的性能提升。

**结论:** 逆向思维方法为增强LLMs的逻辑完整性和推理鲁棒性提供了一个有前景的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reverse+Thinking+Enhances+Missing+Information+Detection+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10273，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10273&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.

</details>


### [21] [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)
*Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao*

**主要类别:** cs.AI

**AI概要:** NAC是一种新型生物启发的连续时间注意力机制，通过线性一阶ODE和稀疏门控结构实现高效自适应动力学，在多个任务中达到或超越基线性能


<details>
  <summary>更多</summary>
  
**动机:** 传统注意力机制的离散性质限制了连续时间建模能力，需要开发生物 plausible 的连续时间注意力机制

**方法:** 基于C. elegans神经元电路策略，将注意力logits计算重构为线性一阶ODE的解，使用稀疏感官门控和双头网络结构，支持三种计算模式

**结果:** 在非规则时间序列分类、自动驾驶车道保持和工业预测等任务中，NAC在准确性上匹配或超越基线方法，在运行时间和内存效率上处于中等水平

**结论:** NAC成功实现了生物启发的连续时间注意力机制，提供了理论保证并在多个实际应用中验证了有效性，为连续时间建模提供了新途径

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neuronal+Attention+Circuit+%28NAC%29+for+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10282，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10282&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \textit{content-target} and \textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.

</details>


### [22] [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)
*Yanbei Jiang, Xueqi Ma, Shu Liu, Sarah Monazam Erfani, Tongliang Liu, James Bailey, Jey Han Lau, Krista A. Ehinger*

**主要类别:** cs.AI

**AI概要:** 该研究提出了一个名为CogVision的新解释性框架，通过分解多模态问题为逐步子问题来分析视觉语言模型的内部机制，特别是注意力头在多模态推理中的功能作用。


<details>
  <summary>更多</summary>
  
**动机:** 尽管视觉语言模型在多模态基准测试中表现出色，但其内部机制仍是一个黑箱，需要系统性的解释性分析来理解其工作原理。

**方法:** 引入CogVision数据集将复杂多模态问题分解为模拟人类推理的逐步子问题，使用基于探测的方法识别专门处理特定认知功能的注意力头。

**结果:** 发现功能头在各类VLM中普遍稀疏，数量和分布因功能而异，干预实验表明移除功能头会导致性能下降，而强调它们能提高准确性。

**结论:** 这些发现为理解VLM的认知组织提供了新见解，并为设计具有更符合人类感知和推理能力的模型指明了方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Investigating+The+Functional+Roles+of+Attention+Heads+in+Vision+Language+Models%3A+Evidence+for+Reasoning+Modules，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10300，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10300&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.

</details>


### [23] [Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance](https://arxiv.org/abs/2512.10304)
*Byeong Ho Kang, Wenli Yang, Muhammad Bilal Amin*

**主要类别:** cs.AI

**AI概要:** 提出可信协调AI的十大标准框架，通过控制面板架构将治理嵌入AI系统执行层，确保可验证性、透明性、可重现性和人类控制。


<details>
  <summary>更多</summary>
  
**动机:** AI系统在决策中角色日益重要，但技术能力与制度问责之间存在差距，仅靠伦理指导不足以应对挑战，需要将治理架构嵌入生态系统执行层。

**方法:** 开发Ten Criteria for Trustworthy Orchestration AI框架，整合人类输入、语义一致性、审计和溯源完整性，采用Control-Panel架构，借鉴国际标准和澳大利亚国家AI保证框架。

**结果:** 建立了可信协调AI的综合保证框架，为整个AI组件、用户和人类参与者提供治理保护伞。

**结论:** 通过工程方法可以系统性地将可信性融入AI系统，确保执行层保持可验证、透明、可重现并在有意义的人类控制之下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trustworthy+Orchestration+Artificial+Intelligence+by+the+Ten+Criteria+with+Control-Plane+Governance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10304，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10304&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.

</details>


### [24] [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)
*Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu*

**主要类别:** cs.AI

**AI概要:** InfoCom是一个基于信息瓶颈理论的高效协作感知框架，通过信息净化范式将通信开销从MB级降至KB级，在保持接近无损感知性能的同时实现440倍和90倍的通信压缩。


<details>
  <summary>更多</summary>
  
**动机:** 解决协作感知中的通信-性能权衡问题，现有方法需要MB级数据传输，但实际网络条件可能无法支持，需要更高效的通信方案。

**方法:** 基于扩展信息瓶颈原理，采用信息感知编码将特征压缩为最小消息，稀疏掩码生成识别空间线索，多尺度解码通过掩码引导机制逐步恢复感知信息。

**结果:** 在多个数据集上验证，实现接近无损的感知性能，通信开销从MB级降至KB级，相比Where2comm和ERMVP分别减少440倍和90倍。

**结论:** InfoCom建立了通信高效协作感知的理论基础，通过信息净化范式在极低通信成本下实现高性能感知，为实际自动驾驶系统提供了可行的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是InfoCom%3A+Kilobyte-Scale+Communication-Efficient+Collaborative+Perception+with+Information+Bottleneck，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10305&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.

</details>


### [25] [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)
*Kangkun Mao, Fang Xu, Jinru Ding, Yidong Jiang, Yujun Yao, Yirong Chen, Junming Liu, Xiaoqin Wu, Qian Wu, Xiaoyan Huang, Jie Xu*

**主要类别:** cs.AI

**AI概要:** EpiPlanAgent是基于大语言模型的多智能体系统，能自动化生成和验证数字应急响应计划，显著提高计划完整性和指南符合度，大幅缩短开发时间。


<details>
  <summary>更多</summary>
  
**动机:** 传统的流行病应对计划制定依赖劳动密集型人工方法，需要更高效、自动化的解决方案来提升公共卫生应急准备能力。

**方法:** 采用基于大语言模型的多智能体框架，集成任务分解、知识基础和仿真模块，由公共卫生专家在真实疫情场景下进行控制评估。

**结果:** 系统显著提高了计划的完整性和指南符合度，大幅减少了开发时间，AI生成内容与人工撰写内容具有高度一致性，用户反馈显示强感知效用。

**结论:** EpiPlanAgent为智能流行病应对规划提供了有效、可扩展的解决方案，展示了智能体AI在转变公共卫生准备方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EpiPlanAgent%3A+Agentic+Automated+Epidemic+Response+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10313&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.

</details>


### [26] [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)
*Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang*

**主要类别:** cs.AI

**AI概要:** 提出了一个用户反馈驱动的视觉语言导航适应框架，通过整合人类交互指令和纠正信号来生成高质量训练数据，提升导航成功率并减少性能下降


<details>
  <summary>更多</summary>
  
**动机:** 当前GSA-VLN框架缺乏用户反馈机制，仅依赖无监督的环境适应，而实际应用中用户反馈能提供有价值的监督信号来显著提升适应质量

**方法:** 开发用户反馈驱动适应框架，将用户导航指令和纠正信号转换为环境对齐的训练数据，并采用记忆库热启动机制重用已获取的环境知识

**结果:** 在GSA-R2R基准测试中超越GR-DUET等强基线，提升导航成功率和路径效率，记忆库热启动稳定了早期导航并减少了更新后的性能下降

**结论:** 该方法在持续和混合适应设置下均表现出鲁棒性和通用性，在不同部署条件下实现了持续改进，证明了用户反馈在VLN适应中的重要性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是User-Feedback-Driven+Continual+Adaptation+for+Vision-and-Language+Navigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10322&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

</details>


### [27] [On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering](https://arxiv.org/abs/2512.10339)
*Ziseok Lee, Minyeong Hwang, Sanghyun Jo, Wooyeol Lee, Jihyung Ko, Young Bin Park, Jae-Mun Choi, Eunho Yang, Kyungsu Kim*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种名为ACE的新方法，解决了异构扩散/流模型在推理时引导中的边际路径崩溃问题，通过自适应路径校正确保概率路径有效性，在分子设计等任务中显著提升了生成质量。


<details>
  <summary>更多</summary>
  
**动机:** 现有的ratio-of-densities方法在组合异构模型时存在边际路径崩溃问题，导致中间密度不可归一化，特别是在分子设计中需要组合不同噪声调度和数据集的模型时。

**方法:** 提出了ACE方法：1）推导路径存在性准则预测崩溃发生条件；2）引入自适应路径校正技术，将Feynman-Kac引导扩展到时变指数，保证有效概率路径。

**结果:** 在合成2D基准测试和柔性姿态支架装饰任务中，ACE消除了崩溃问题，实现了高引导组合生成，在分布性和对接指标上优于恒定指数基线和专用任务模型。

**结论:** ACE方法将ratio-of-densities引导从不稳定启发式方法转变为可控生成的可靠工具，为异构专家模型的组合应用提供了理论保证和实践解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Collapse+of+Generative+Paths%3A+A+Criterion+and+Correction+for+Diffusion+Steering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10339，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10339&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.

</details>


### [28] [REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature](https://arxiv.org/abs/2512.10348)
*Wenhan Wu, Zhili He, Huanghuang Liang, Yili Gong, Jiawei Jiang, Chuang Hu, Dazhao Cheng*

**主要类别:** cs.AI

**AI概要:** REMISVFU是一个即插即用的表示误导框架，用于垂直联邦学习中的快速客户端级遗忘，通过将遗忘方的编码器输出坍塌到随机锚点来切断特征与全局模型的统计联系，同时通过正交投影保持剩余方的模型效用。


<details>
  <summary>更多</summary>
  
**动机:** GDPR等数据保护法规赋予联邦系统参与者被遗忘权，但现有遗忘技术主要针对水平联邦学习，而垂直联邦学习的特征分区架构使得这些方法无效，需要专门解决方案。

**方法:** 提出表示误导框架：遗忘方将编码器输出坍塌到单位球面上的随机锚点；服务器通过正交投影联合优化保留损失和遗忘损失，消除破坏性干扰。

**结果:** 在公开基准测试中，REMISVFU将后门攻击成功率抑制到自然类先验水平，仅牺牲约2.5%的清洁准确率，优于现有基线方法。

**结论:** REMISVFU有效解决了垂直联邦学习中的遗忘问题，在保证模型效用的同时实现了快速客户端级遗忘，为数据保护法规合规提供了可行方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是REMISVFU%3A+Vertical+Federated+Unlearning+via+Representation+Misdirection+for+Intermediate+Output+Feature，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10348，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10348&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party's contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.

</details>


### [29] [LLM-Empowered Representation Learning for Emerging Item Recommendation](https://arxiv.org/abs/2512.10370)
*Ziying Zhang, Quanming Yao, Yaqing Wang*

**主要类别:** cs.AI

**AI概要:** EmerFlow：一个基于LLM的新兴物品推荐框架，通过LLM推理增强特征表示，与现有推荐模型嵌入空间对齐，并通过元学习优化嵌入，在有限交互下学习表达性嵌入


<details>
  <summary>更多</summary>
  
**动机:** 现有推荐方法通常忽视新兴物品随时间积累交互的动态过程，过度简化假设新兴物品只有很少甚至没有历史交互，无法同时保持新兴物品独特性和利用与成熟物品的共享模式

**方法:** 提出EmerFlow框架：1）通过LLM推理丰富新兴物品的原始特征；2）将这些表示与现有推荐模型的嵌入空间对齐；3）通过元学习整合新交互来优化嵌入

**结果:** 在电影和医药等多个领域的广泛实验表明，EmerFlow始终优于现有方法

**结论:** EmerFlow能够从有限交互中学习表达性嵌入，有效解决了新兴物品推荐中保持独特性与利用共享模式的平衡问题

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Empowered+Representation+Learning+for+Emerging+Item+Recommendation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10370，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10370&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.

</details>


### [30] [AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management](https://arxiv.org/abs/2512.10371)
*Shizuo Tian, Hao Wen, Yuxuan Chen, Jiacheng Liu, Shanhui Zhao, Guohong Liu, Ju Ren, Yunxin Liu, Yuanchun Li*

**主要类别:** cs.AI

**AI概要:** AgentProg是一种程序引导的移动GUI智能体上下文管理方法，通过将交互历史重构为带有变量和控制流的程序来减少上下文开销，在长时任务中保持稳定性能


<details>
  <summary>更多</summary>
  
**动机:** 移动GUI智能体在长时任务自动化中面临上下文管理瓶颈，现有技术无法有效保留关键语义信息导致性能下降

**方法:** 提出程序引导的上下文管理方法，将交互历史组织为程序结构，并集成基于Belief MDP框架的全局信念状态机制处理部分可观测性

**结果:** 在AndroidWorld和扩展的长时任务套件上达到最先进成功率，在长时任务中保持稳健性能而基线方法出现灾难性退化

**结论:** AgentProg通过程序化结构提供有原则的信息保留机制，有效解决了长时任务中的上下文管理问题，系统已开源

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgentProg%3A+Empowering+Long-Horizon+GUI+Agents+with+Program-Guided+Context+Management，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10371，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10371&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.

</details>


### [31] [Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention](https://arxiv.org/abs/2512.10414)
*Yang Yu, Zhuangzhuang Chen, Siqi Wang, Lanqing Li, Xiaomeng Li*

**主要类别:** cs.AI

**AI概要:** 提出SaEI方法，通过选择性对抗熵干预增强视觉语言模型的推理能力，在RL采样阶段引入熵干预来提升响应多样性


<details>
  <summary>更多</summary>
  
**动机:** 现有RL微调方法只在策略优化阶段进行熵干预，忽略了采样阶段的熵干预对提升响应多样性和性能的重要性

**方法:** 提出选择性对抗熵干预(SaEI)：1) 熵引导对抗采样(EgAS)，将采样响应的熵作为对抗目标生成对抗样本；2) 令牌选择性熵计算(TsEC)，在不破坏事实知识的前提下最大化对抗攻击效果

**结果:** 在域内和域外数据集上的广泛实验表明，该方法能显著提升策略探索能力和推理性能

**结论:** SaEI通过RL采样阶段的熵干预有效增强了视觉语言模型的推理能力，为RL-based VLM微调提供了新思路

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Boosting+RL-Based+Visual+Reasoning+with+Selective+Adversarial+Entropy+Intervention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10414，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10414&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.

</details>


### [32] [Representation of the structure of graphs by sequences of instructions](https://arxiv.org/abs/2512.10429)
*Ezequiel Lopez-Rubio*

**主要类别:** cs.AI

**AI概要:** 提出一种新的图表示方法，将邻接矩阵转换为可逆的指令字符串，使深度学习语言模型能够处理图数据


<details>
  <summary>更多</summary>
  
**动机:** 现有的图表示方法（基于邻接矩阵）不适合深度学习语言模型处理，而深度学习模型在文本处理方面表现出色，需要一种新的图表示形式来利用这些模型的能力

**方法:** 将图的邻接矩阵通过一系列简单指令逐步构建成字符串表示，这种转换是可逆的（图↔字符串），保持图的局部结构模式

**结果:** 提出的表示方法紧凑且保持图结构特征，初步计算实验显示出积极结果

**结论:** 这种新的图字符串表示方法有望促进深度学习模型对图数据的处理，为图分析与深度学习结合提供了新途径

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Representation+of+the+structure+of+graphs+by+sequences+of+instructions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10429，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10429&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.

</details>


### [33] [Targeted Data Protection for Diffusion Model by Matching Training Trajectory](https://arxiv.org/abs/2512.10433)
*Hojun Lee, Mijin Koo, Yeji Song, Nojun Kwak*

**主要类别:** cs.AI

**AI概要:** TAFAP是一种针对扩散模型的主动数据保护方法，通过控制整个训练轨迹来实现目标概念重定向，解决了现有方法在可控性和稳定性方面的不足。


<details>
  <summary>更多</summary>
  
**动机:** 当前扩散模型个性化微调技术普及，但存在未经授权数据使用和隐私侵犯问题。现有保护方法只能被动降低图像质量，缺乏稳定控制能力。目标数据保护(TDP)方法虽然提供了主动重定向的范式，但现有TDP方法因快照匹配方式无法考虑完整学习动态，导致可控性差。

**方法:** TAFAP采用基于轨迹对齐的方法，通过对抗性扰动进行微调，控制整个训练轨迹而非单个快照。该方法受到数据集蒸馏的启发，在整个微调过程中强制执行持久且可验证的变换。

**结果:** 实验验证显示TAFAP首次成功实现了扩散模型中的目标变换，同时控制身份和视觉模式。显著优于现有TDP方法，实现了对目标概念的稳健重定向，同时保持高图像质量。

**结论:** TAFAP为扩散模型输出提供了可验证的安全保障，并建立了控制和追踪模型修改的新框架，为解决扩散模型中的数据保护和隐私问题提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Targeted+Data+Protection+for+Diffusion+Model+by+Matching+Training+Trajectory，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10433&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.

</details>


### [34] [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449)
*Devanshu Sahoo, Manish Prasad, Vasudev Majhi, Jahnvi Singh, Vinay Chamola, Yash Sinha, Murari Mandal, Dhruv Kumar*

**主要类别:** cs.AI

**AI概要:** 本研究探讨了科学论文评审中LLM系统的脆弱性，通过对抗性PDF操作成功实现了将'拒绝'决策翻转为'接受'，揭示了现有AI评审系统的安全风险。


<details>
  <summary>更多</summary>
  
**动机:** 随着LLMs在科学同行评审中的广泛应用（包括评审员个人使用和机构正式部署），需要评估这些'LLM-as-a-Judge'系统对对抗性PDF操纵的鲁棒性。

**方法:** 构建了200篇科学论文数据集，开发了15种领域特定的攻击策略，提出了WAVS评估指标，在包括GPT-5、Claude Haiku和DeepSeek在内的13个语言模型上进行测试。

**结果:** 研究发现混淆策略如'Maximum Mark Magyk'能够成功操纵评分，即使在大型模型中也能实现令人担忧的决策翻转率。

**结论:** LLM评审系统存在严重的安全漏洞，需要加强对抗性攻击的防护措施，研究将公开完整数据集和注入框架以促进进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Reject+Turns+into+Accept%3A+Quantifying+the+Vulnerability+of+LLM-Based+Scientific+Reviewers+to+Indirect+Prompt+Injection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10449，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10449&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the "Lazy Reviewer" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these "LLM-as-a-Judge" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping "Reject" decisions to "Accept," for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like "Maximum Mark Magyk" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.

</details>


### [35] [Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning](https://arxiv.org/abs/2412.20505)
*Hang Ni, Yuzhi Wang, Hao Liu*

**主要类别:** cs.AI

**AI概要:** 提出了基于大语言模型的循环城市规划(CUP)新范式，通过多智能体框架实现城市计划的生成、评估和迭代优化


<details>
  <summary>更多</summary>
  
**动机:** 城市化背景下城市更新面临重大挑战，需要适应性方法来应对不断变化的需求

**方法:** 基于大语言模型的多智能体框架，包含三个核心组件：规划(生成和优化城市计划)、生活(模拟居民行为互动)、评判(评估计划效果并提供迭代反馈)

**结果:** 在真实数据集上的实验证明了该框架作为连续自适应规划过程的有效性

**结论:** 循环城市规划范式能够实现动态响应的规划方法，为城市更新提供持续优化的解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Planning%2C+Living+and+Judging%3A+A+Multi-agent+LLM-based+Framework+for+Cyclical+Urban+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2412.20505，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2412.20505&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.

</details>


### [36] [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)
*Lim Chien Her, Ming Yan, Yunshu Bai, Ruihao Li, Hao Zhang*

**主要类别:** cs.AI

**AI概要:** 提出无需训练的LLM智能体架构，通过Actor-Critic双智能体迭代工作流，实现零样本PCG参数配置，在3D地图生成任务上超越单智能体基线


<details>
  <summary>更多</summary>
  
**动机:** PCG需要精确配置复杂技术参数，现成LLM难以弥合抽象用户指令与严格参数规范之间的语义鸿沟

**方法:** 采用Actor-Critic双智能体架构，Actor负责参数配置，Critic进行评估和迭代优化，实现自主推理和渐进式参数精炼

**结果:** 在3D地图生成任务上建立了新基准，相比单智能体基线表现更优，能从自然语言描述生成多样且结构有效的环境

**结论:** 现成LLM可有效重用作通用PCG工具智能体，通过架构推理而非模型训练的方式，为掌握复杂软件提供了可扩展框架

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zero-shot+3D+Map+Generation+with+LLM+Agents%3A+A+Dual-Agent+Architecture+for+Procedural+Content+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10501，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10501&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.

</details>


### [37] [Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](https://arxiv.org/abs/2512.10534)
*Haiteng Zhao, Junhao Shen, Yiming Zhang, Songyang Gao, Kuikun Liu, Tianyou Ma, Fan Zheng, Dahua Lin, Wenwei Zhang, Kai Chen*

**主要类别:** cs.AI

**AI概要:** InternGeometry是一个基于LLM的几何问题解决智能体，通过迭代提出命题和辅助构造、符号引擎验证和反馈机制，在仅使用13K训练样本的情况下解决了44/50的IMO几何问题，超过了人类金牌选手平均水平，展示了LLM在专家级几何任务上的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 当前LLM在几何问题解决方面存在启发式构造能力不足的问题，主要依赖像AlphaGeometry 2这样的专家模型，需要大规模数据合成和搜索。本文旨在构建一个达到IMO奖牌水平的LLM几何问题解决智能体。

**方法:** 提出InternGeometry系统，通过迭代提出命题和辅助构造、符号引擎验证、基于反馈指导后续建议的动态记忆机制，以及复杂度递增强化学习(CBRL)来逐步提升训练问题的复杂度。

**结果:** 在仅使用13K训练样本(仅为AlphaGeometry 2数据量的0.004%)的情况下，解决了50个IMO几何问题中的44个，超过了人类金牌选手平均得分(40.9)，并且能够提出人类解法中未出现的新颖辅助构造。

**结论:** InternGeometry展示了LLM智能体在专家级几何任务上的巨大潜力，通过创新的迭代验证和反馈机制，以极少的训练数据达到了超越人类专家的性能水平，为未来几何AI研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Achieving+Olympia-Level+Geometry+Large+Language+Model+Agent+via+Complexity+Boosting+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10534，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10534&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.

</details>


### [38] [NormCode: A Semi-Formal Language for Context-Isolated AI Planning](https://arxiv.org/abs/2512.10563)
*Xin Guan*

**主要类别:** cs.AI

**AI概要:** NormCode是一种半正式语言，通过设计消除多步LLM工作流中的上下文污染问题，实现语义操作和语法操作的严格分离，确保数据隔离和精确的可靠性追踪。


<details>
  <summary>更多</summary>
  
**动机:** 多步LLM工作流存在上下文污染问题：随着信息在步骤间积累，模型会产生幻觉、混淆中间输出并丢失任务约束，需要一种方法来消除跨步骤污染。

**方法:** 开发NormCode语言，提供三种同构格式：.ncds用于人工编写、.ncd用于机器执行、.ncn用于人工验证，支持从草图到生产的渐进式形式化。

**结果:** 验证显示：1）基础X加法算法在任意长度输入上实现100%准确率；2）成功自托管执行NormCode的五阶段编译器流水线。

**结论:** NormCode通过依赖驱动调度、SQLite检查点和循环管理，使AI工作流具有可审计性，满足法律、医疗和金融等高风险领域对透明度的关键需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NormCode%3A+A+Semi-Formal+Language+for+Context-Isolated+AI+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10563&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.

</details>


### [39] [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)
*Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen*

**主要类别:** cs.AI

**AI概要:** Phythesis框架结合大语言模型和物理引导的进化优化，自动化生成仿真就绪的数据中心布局，相比纯LLM方案提升57.3%生成成功率和11.5%能效


<details>
  <summary>更多</summary>
  
**动机:** 传统数据中心设计方法难以应对系统复杂性，现有AI生成方法忽略物理约束，无法满足数据中心可量化运营目标和严格物理限制的需求

**方法:** 采用迭代双层优化架构：LLM驱动层生成物理合理3D布局并自我批判优化拓扑；物理信息优化层识别最优资产参数和组合

**结果:** 在三个生成规模上，相比纯LLM方案，生成成功率提升57.3%，功率使用效率(PUE)改善11.5%

**结论:** Phythesis成功将LLM与物理约束优化相结合，为数据中心能效设计提供了自动化、仿真就绪的场景合成解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Phythesis%3A+Physics-Guided+Evolutionary+Scene+Synthesis+for+Energy-Efficient+Data+Center+Design+via+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10611，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10611&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.

</details>


### [40] [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)
*Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao*

**主要类别:** cs.AI

**AI概要:** ReMe框架通过多维度经验提炼、上下文自适应重用和基于效用的精炼机制，实现了LLM代理从被动积累到主动进化的记忆系统，在多个基准测试中达到SOTA性能，并展现出内存扩展效应。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM代理记忆框架主要采用被动积累模式，将记忆视为静态的只读档案，无法实现存储与动态推理的有效结合，需要更主动的记忆进化机制。

**方法:** 提出ReMe框架，包含三个创新机制：1) 多维度经验提炼 - 识别成功模式、分析失败原因、生成对比见解；2) 上下文自适应重用 - 通过场景感知索引将历史经验适配到新情境；3) 基于效用的精炼 - 自主添加有效记忆并修剪过时记忆，保持紧凑高质量经验池。

**结果:** 在BFCL-V3和AppWorld基准测试中达到最先进性能。Qwen3-8B配备ReMe后超越更大的无记忆Qwen3-14B，显示出显著的内存扩展效应。

**结论:** 自我进化记忆为终身学习提供了计算高效的途径，ReMe框架成功实现了从静态存储到动态推理的跨越，推动了LLM代理记忆系统的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Remember+Me%2C+Refine+Me%3A+A+Dynamic+Procedural+Memory+Framework+for+Experience-Driven+Agent+Evolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10696&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.

</details>


### [41] [Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification](https://arxiv.org/abs/2512.10640)
*Liang Peng, Haopeng Liu, Yixuan Ye, Cheng Liu, Wenjun Shen, Si Wu, Hau-San Wong*

**主要类别:** cs.AI

**AI概要:** 提出了scRCL框架，通过整合细胞-基因相互作用和对比学习来改进无监督细胞类型识别，在单细胞RNA测序和空间转录组数据上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有聚类方法主要关注细胞内在结构而忽略细胞-基因关联的关键作用，限制了区分密切相关的细胞类型的能力。

**方法:** 开发了Refinement Contrastive Learning框架，包含两个对比分布对齐组件揭示细胞结构关系，以及一个整合基因相关结构学习的精炼模块来增强细胞嵌入表示。

**结果:** 在多个单细胞RNA-seq和空间转录组基准数据集上实验表明，该方法在细胞类型识别准确率上一致优于最先进的基线方法。

**结论:** scRCL通过有效利用细胞-基因关联，能够识别出具有一致基因表达特征的细胞群体，验证了该方法的生物学相关性，代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Refinement+Contrastive+Learning+of+Cell-Gene+Associations+for+Unsupervised+Cell+Type+Identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10640，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10640&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at https://github.com/THPengL/scRCL.

</details>


### [42] [Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly](https://arxiv.org/abs/2512.10787)
*Moshe Lahmy, Roi Yozevitch*

**主要类别:** cs.AI

**AI概要:** SEAL-RAG提出了一种新的检索增强生成方法，采用"替换而非扩展"策略来解决多跳查询中的上下文稀释问题，通过搜索-提取-评估-循环的机制，在固定检索深度下显著提升答案正确性和证据精确度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的RAG系统在多跳查询中经常因为初始检索遗漏桥接事实而失败，传统方法通过增加上下文或修剪列表来纠正，但这会导致上下文稀释问题，即干扰信息挤占了相关信息的空间。

**方法:** SEAL-RAG采用训练自由的控制器，执行搜索→提取→评估→循环的周期：进行实时实体锚定提取构建缺失实体/关系规范，触发定向微查询，并使用实体优先排序主动替换干扰信息为填补空白的证据。

**结果:** 在HotpotQA上，SEAL比Self-RAG提高答案正确性3-13个百分点，证据精确度提高12-18个百分点；在2WikiMultiHopQA上，比Adaptive-k准确度提高8.0个百分点，保持96%的证据精确度（CRAG仅为22%）。

**结论:** 通过强制执行固定k值替换，SEAL提供了可预测的成本特征，同时确保top-k槽位为精确度而非广度进行优化，在多个数据集上取得了统计显著的性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Replace%2C+Don%27t+Expand%3A+Mitigating+Context+Dilution+in+Multi-Hop+RAG+via+Fixed-Budget+Evidence+Assembly，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10787&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \textbf{context dilution}, where distractors crowd out relevant information. We propose \textbf{SEAL-RAG}, a training-free controller that adopts a \textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\textbf{S}earch $\rightarrow$ \textbf{E}xtract $\rightarrow$ \textbf{A}ssess $\rightarrow$ \textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \textbf{HotpotQA} and \textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \textbf{+3--13 pp} and evidence precision by \textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \textbf{+8.0 pp} in accuracy and maintains \textbf{96\%} evidence precision compared to 22\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.

</details>


### [43] [CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.10655)
*Tong Zhang, Carlos Hinojosa, Bernard Ghanem*

**主要类别:** cs.AI

**AI概要:** CAPTAIN是一个无需训练的框架，通过在去噪过程中直接修改潜在特征来减少扩散模型的记忆效应，在保持提示对齐和视觉质量的同时显著降低记忆化问题。


<details>
  <summary>更多</summary>
  
**动机:** 扩散模型可能无意中复制训练样本，引发隐私和版权问题。现有方法通常通过操纵分类器自由引导或扰动提示嵌入来缓解，但往往难以在不损害提示对齐的情况下减少记忆化。

**方法:** CAPTAIN采用基于频率的噪声初始化减少早期记忆模式复制，识别最佳去噪时间步进行特征注入和定位记忆区域，然后将非记忆参考图像的语义对齐特征注入到定位的潜在区域。

**结果:** 实验表明，CAPTAIN相比基于CFG的基线方法在记忆化减少方面取得显著成效，同时保持与目标提示的强对齐。

**结论:** CAPTAIN提供了一种有效的训练免费解决方案，能够在保持生成质量的同时有效缓解扩散模型的记忆化问题，为隐私和版权保护提供了实用方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CAPTAIN%3A+Semantic+Feature+Injection+for+Memorization+Mitigation+in+Text-to-Image+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10655，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10655&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.

</details>


### [44] [On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity](https://arxiv.org/abs/2512.10665)
*Muhua Huang, Qinlin Zhao, Xiaoyuan Yi, Xing Xie*

**主要类别:** cs.AI

**AI概要:** 本研究探讨价值多样性如何影响AI多智能体系统的集体行为，发现适度的价值多样性能够增强价值稳定性、促进涌现行为并提升创造力，但过度多样性会导致不稳定性。


<details>
  <summary>更多</summary>
  
**动机:** 随着基于大语言模型的多智能体系统日益普及，人工智能社区的集体行为（如集体智能）受到越来越多的关注。本研究旨在回答一个基本问题：价值多样性如何塑造AI社区的集体行为？

**方法:** 使用基于Schwartz基本人类价值理论的自然主义价值引导方法，构建了多智能体模拟环境，让不同规模的社区进行开放式互动和宪法制定。

**结果:** 结果显示价值多样性能够增强价值稳定性、促进涌现行为，并在没有外部指导的情况下带来更多由智能体自身开发的创造性原则。但这些效应也呈现边际递减：极端异质性会引发不稳定性。

**结论:** 价值多样性是未来AI能力的新维度，连接了AI能力与制度涌现的社会学研究，为构建更智能和稳定的AI社区提供了重要见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Dynamics+of+Multi-Agent+LLM+Communities+Driven+by+Value+Diversity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10665，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10665&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.

</details>


### [45] [AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2512.10671)
*Oscar Robben, Saeed Khalilian, Nirvana Meratnia*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于硬件感知神经架构搜索的早退网络设计框架，通过优化退出分支的深度和层类型，在保持或降低计算量的同时提高模型精度。


<details>
  <summary>更多</summary>
  
**动机:** 早退网络能根据输入数据复杂度调整计算量，降低能耗和延迟，但设计过程复杂耗时，需要平衡效率与性能。现有NAS方法主要关注退出位置和数量，而退出分支的深度和层类型对效率精度同样重要。

**方法:** 使用硬件感知神经架构搜索来强化退出分支，在优化过程中同时考虑精度和效率，采用自适应阈值调优，并在CIFAR-10、CIFAR-100和SVHN数据集上进行性能评估。

**结果:** 提出的框架设计的早退网络在相同或更低平均MACs计算量下，相比最先进方法实现了更高的准确率。

**结论:** 通过硬件感知NAS优化退出分支的深度和层类型，结合自适应阈值调优，能够有效提升早退网络的性能效率平衡，为资源受限设备提供更优的深度学习解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AEBNAS%3A+Strengthening+Exit+Branches+in+Early-Exit+Networks+through+Hardware-Aware+Neural+Architecture+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10671，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10671&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.

</details>


### [46] [Challenges of Evaluating LLM Safety for User Welfare](https://arxiv.org/abs/2512.10687)
*Manon Kempermann, Sai Suresh Macharla Vasu, Mahalakshmi Raveenthiran, Theo Farrell, Ingmar Weber*

**主要类别:** cs.AI

**AI概要:** 该研究挑战了传统大语言模型安全评估只关注通用风险的做法，提出了需要考虑用户具体情境的个性化安全评估方法，发现在金融和健康建议场景中，缺乏用户背景信息的评估会高估安全性，特别是对脆弱人群。


<details>
  <summary>更多</summary>
  
**动机:** 当前大语言模型的安全评估主要关注通用风险，但数百万用户在高风险领域（如金融和健康）寻求个性化建议，这些风险是情境依赖的而非通用的。现有评估框架未能充分考虑用户个体风险。

**方法:** 研究评估了GPT-5、Claude Sonnet 4和Gemini 2.5 Pro在金融和健康建议方面的表现，使用不同脆弱程度的用户档案。通过比较有背景信息和无背景信息的评估者评分，以及分析用户实际会披露的上下文信息的效果。

**结果:** 研究发现：1）有背景信息的评估者比无背景信息的评估者给出更低的安全评分（从5/7降至3/7）；2）即使用户提供真实上下文信息，安全评估也没有显著改善；3）脆弱人群面临更大的安全风险。

**结论:** 有效的用户福利安全评估需要评估者基于多样化用户档案来评估响应，仅靠用户披露的上下文信息不足以保证安全评估的有效性。研究提供了情境感知评估的方法论基础，表明个性化福利评估需要不同于通用风险评估的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Challenges+of+Evaluating+LLM+Safety+for+User+Welfare，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10687，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10687&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.

</details>


### [47] [Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning](https://arxiv.org/abs/2512.10691)
*Benjamin Gundersen, Nicolas Deperrois, Samuel Ruiperez-Campillo, Thomas M. Sutter, Julia E. Vogt, Michael Moor, Farhad Nooralahzadeh, Michael Krauthammer*

**主要类别:** cs.AI

**AI概要:** 该研究探索了在胸部X光视觉语言模型中结合强化学习和显式推理的效果，发现RL能提升报告生成和视觉定位性能，但显式推理并未带来额外增益。


<details>
  <summary>更多</summary>
  
**动机:** 现有医学VLM主要依赖监督微调，缺乏对答案质量的评估。强化学习能整合任务特定反馈，结合显式推理在数学和编程任务中已显示显著效果，但在医学影像领域的应用效果尚不清楚。

**方法:** 基于Qwen3-VL构建RadVLM，进行大规模SFT后增加冷启动SFT赋予基本推理能力。然后应用GRPO强化学习算法，使用临床任务特定的奖励函数进行报告生成和视觉定位优化。

**结果:** RL在报告生成和视觉定位任务上均带来额外提升，而显式推理未显示进一步改进效果。RL优化的RadVLM模型在两项任务上均达到最先进性能。

**结论:** 强化学习是医学VLM中监督微调的有力补充，能通过临床对齐的奖励函数进一步提升模型性能，但显式推理在医学影像任务中效果有限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Radiology+Report+Generation+and+Visual+Grounding+using+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10691，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10691&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning ("thinking") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.

</details>


### [48] [COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators](https://arxiv.org/abs/2512.10702)
*Wei Fang, Chiyao Wang, Wenshuai Ma, Hui Liu, Jianqiang Hu, Xiaona Niu, Yi Chu, Mingming Zhang, Jingxiao Yang, Dongwei Zhang, Zelin Li, Pengyun Liu, Jiawei Zheng, Pengke Zhang, Chaoshi Qin, Wangang Guo, Bin Wang, Yugang Xue, Wei Zhang, Zikuan Wang, Rui Zhu, Yihui Cao, Quanmao Lu, Rui Meng, Yan Li*

**主要类别:** cs.AI

**AI概要:** CA-GPT专业AI-OCT系统在冠状动脉介入治疗规划和评估中，显著优于通用ChatGPT-5和初级医师，提供标准化的血管内成像解读方法。


<details>
  <summary>更多</summary>
  
**动机:** 血管内成像（特别是OCT）可改善PCI结果，但解读依赖操作者经验。通用AI缺乏领域特异性可靠性，需要开发专业AI系统。

**方法:** 单中心分析96例OCT引导PCI患者，比较CA-GPT、ChatGPT-5和初级医师的手术决策与专家记录的一致性，使用10个预设指标评估术前术后阶段。

**结果:** CA-GPT术前规划中位一致性评分5分，显著高于ChatGPT-5的3分和初级医师的4分。在支架直径和长度选择上表现优异。术后评估同样保持优秀表现。

**结论:** CA-GPT为基础的AI-OCT系统在PCI决策一致性方面优于通用大语言模型和初级医师，为血管内成像解读提供了标准化可靠方法，有望增强操作者专业知识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是COMPARE%3A+Clinical+Optimization+with+Modular+Planning+and+Assessment+via+RAG-Enhanced+AI-OCT%3A+Superior+Decision+Support+for+Percutaneous+Coronary+Intervention+Compared+to+ChatGPT-5+and+Junior+Operators，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10702&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.
  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.
  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.
  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.

</details>


### [49] [HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition](https://arxiv.org/abs/2512.10807)
*Wang Lu, Yao Zhu, Jindong Wang*

**主要类别:** cs.AI

**AI概要:** 该论文提出了HAROOD基准测试，用于系统评估分布外(OOD)算法在人类活动识别(HAR)中的性能，涵盖4种OOD场景、6个数据集和16种方法，发现没有单一方法始终最优。


<details>
  <summary>更多</summary>
  
**动机:** 现实场景中个体、设备、环境和时间的变化导致相同活动的分布偏移，现有研究只在特定场景下应用OOD算法，缺乏全面评估。

**方法:** 定义4种OOD场景（跨人、跨位置、跨数据集、跨时间），构建包含6个数据集和16种比较方法的测试平台，采用两种模型选择协议进行广泛实验。

**结果:** 实验显示没有单一方法在所有场景下始终最优，表明该领域仍有很大改进空间。

**结论:** HAROOD基准为OOD-based HAR研究提供了模块化、易扩展的测试平台，有助于推动该领域发展，代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HAROOD%3A+A+Benchmark+for+Out-of-distribution+Generalization+in+Sensor-based+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10807，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10807&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at https://github.com/AIFrontierLab/HAROOD.

</details>


### [50] [Agile Deliberation: Concept Deliberation for Subjective Visual Classification](https://arxiv.org/abs/2512.10821)
*Leijie Wang, Otilia Stretcu, Wei Qiao, Thomas Denby, Krishnamurthy Viswanathan, Enming Luo, Chun-Ta Lu, Tushar Dogra, Ranjay Krishna, Ariel Fuxman*

**主要类别:** cs.AI

**AI概要:** 论文提出了一个名为"敏捷审议"的人机交互框架，通过概念范围界定和概念迭代两个阶段，帮助用户从模糊概念出发逐步精确定义视觉分类器的概念，在内容审核等应用中取得了比自动分解基准高7.5% F1分数和比人工审议高3%以上的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的人机交互方法假设用户一开始就有清晰稳定的概念理解，但现实中用户往往从模糊概念开始，需要通过"概念审议"过程逐步细化。通过对内容审核专家的结构化访谈发现了这一实践需求。

**方法:** 开发了"敏捷审议"框架，包含两个阶段：(1)概念范围界定-将初始概念分解为结构化子概念层次；(2)概念迭代-呈现语义边界案例供用户反思和反馈，迭代对齐图像分类器与用户不断演变的意图。采用18次用户会话（每次1.5小时）进行细致评估。

**结果:** 敏捷审议比自动分解基准实现了7.5%更高的F1分数，比人工审议高出3%以上。参与者报告获得了更清晰的概念理解和更低的认知努力。

**结论:** 该框架有效支持了演化性和主观性概念的定义，为需要视觉概念分类器的应用提供了更符合实际用户需求的人机交互解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Agile+Deliberation%3A+Concept+Deliberation+for+Subjective+Visual+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10821，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10821&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

</details>


### [51] [V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions](https://arxiv.org/abs/2512.10822)
*Mumuksh Tayal, Manan Tayal, Aditya Singh, Shishir Kolathaya, Ravi Prakash*

**主要类别:** cs.AI

**AI概要:** V-OCBF是一种新的离线强化学习方法，通过从离线演示中学习神经控制屏障函数，无需在线交互或系统动态模型即可实现安全控制，相比基线方法显著减少安全违规。


<details>
  <summary>更多</summary>
  
**动机:** 现有安全离线RL方法只能保证软约束，无法确保前向不变性；而控制屏障函数需要专家设计或完整系统动态知识。需要一种既能从离线数据学习又提供严格安全保证的方法。

**方法:** 提出价值引导离线控制屏障函数框架：1）从离线演示学习神经CBF；2）使用递归有限差分屏障更新实现无模型学习；3）采用expectile目标避免分布外动作查询；4）通过QP合成实时安全控制。

**结果:** 在多个案例研究中，V-OCBF相比基线方法显著减少了安全违规次数，同时保持了强大的任务性能。

**结论:** V-OCBF框架展示了在不依赖在线交互或人工设计屏障的情况下，离线合成安全关键控制器的可扩展性，为自主系统安全控制提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是V-OCBF%3A+Learning+Safety+Filters+from+Offline+Data+via+Value-Guided+Offline+Control+Barrier+Functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10822，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10822&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.

</details>


### [52] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding, Janell Thomson, Jon Taylor, Changwoo Do*

**主要类别:** cs.AI

**AI概要:** 使用大语言模型(LLMs)替代传统人工评审，通过成对偏好方法实现更一致、可扩展且成本效益更高的科研项目提案评审系统


<details>
  <summary>更多</summary>
  
**动机:** 传统人工评审存在提案间相关性弱、评审者偏见和不一致性问题，而成对偏好方法虽然逻辑上更严谨但工作量呈二次增长，人工无法承担

**方法:** 利用LLMs进行成对偏好比较，基于美国橡树岭国家实验室散裂中子源三个光束线的精心策划提案和发表记录进行实验

**结果:** LLM排名与人工排名强相关(Spearman ρ≈0.2-0.8，去除10%异常值后≥0.5)，在识别高发表潜力提案方面不逊于人工评审，成本降低两个数量级

**结论:** LLMs不仅能提供与人工评审相当的提案排名，还能进行人类难以实现的先进分析(如通过嵌入模型量化提案相似性)，为评审委员会提供关键信息

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLMs+Can+Assist+with+Proposal+Selection+at+Large+User+Facilities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10895，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10895&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [53] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique*

**主要类别:** cs.AI

**AI概要:** 提出了一种节点级剪枝框架，用于在大型语言模型中发现最小子网络（电路），解决了现有方法计算成本高、粒度粗的问题，能够在单次微调中实现多粒度压缩，显著降低内存占用。


<details>
  <summary>更多</summary>
  
**动机:** 现有电路发现方法主要依赖迭代边剪枝，计算成本高且仅限于粗粒度单元（如注意力头或MLP块），忽略了神经元级别的精细结构。

**方法:** 提出节点级剪枝框架，引入可学习掩码覆盖从整个块到单个神经元的多粒度级别，通过粒度特定的稀疏性惩罚指导剪枝过程，在统一优化目标下实现全面压缩。

**结果:** 实验表明该方法发现的电路节点数少于先前方法，证明许多粗粒度方法认为重要的神经元实际上无关紧要，同时保持任务性能，内存占用降低5-10倍。

**结论:** 该方法在可扩展性和粒度方面都有显著改进，为大型语言模型的电路发现提供了更高效、更精细的解决方案，且不需要在内存中保存中间激活值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Granular+Node+Pruning+for+Circuit+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10903，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10903&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>


### [54] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

**主要类别:** cs.AI

**AI概要:** 该论文建立了部分可观察马尔可夫决策过程(POMDP)中的智能体与一输入过程函数之间的精确对应关系，揭示了AI与量子物理概念的统一性，并将此视角扩展到多智能体系统。


<details>
  <summary>更多</summary>
  
**动机:** 探索AI中的决策智能体与量子物理中高阶量子操作经典极限(过程函数)之间的数学对应关系，为跨学科理论框架提供基础。

**方法:** 通过将智能体的策略和记忆更新结合为过程函数w，使用链接积与POMDP环境交互，建立形式化的对应关系。

**结果:** 成功建立了POMDP智能体与一输入过程函数的精确对应，发现了物理视角和AI视角的双重解释，并将该框架扩展到多输入过程函数的多智能体系统。

**结论:** 这项工作为理解AI决策理论与量子信息理论之间的深层联系提供了新视角，展示了跨学科概念的统一性，为未来多智能体系统的形式化分析奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Decision-Making+Agents+and+Higher-Order+Causal+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10937&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [55] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi, Jessica Morley, Claudio Novelli, David Watson*

**主要类别:** cs.CL

**AI概要:** 本文分析当前基于token补全的大型语言模型（LLMs）的推理机制，指出其看似像人类溯因推理的表现实际上是基于统计模式生成，而非真正的推理能力。


<details>
  <summary>更多</summary>
  
**动机:** 研究LLMs的推理本质，澄清它们表面上的溯因推理能力实际上是通过学习人类文本中的推理模式而产生的统计行为，而非真正的逻辑推理。

**方法:** 通过理论分析和示例展示，比较LLM输出与人类溯因推理的异同，分析其随机生成特性与表面推理表现之间的关系。

**结果:** 发现LLMs能够生成看似合理的想法、模仿常识推理和提供解释性回答，但这些输出缺乏真实性、语义理解、验证能力或真正的推理基础。

**结论:** LLMs具有双重性：统计基础但表面呈现推理特征，这对其评估和应用有重要影响。它们可辅助创意生成和思维支持，但输出需要批判性评估，因为无法识别真理或验证解释。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Kind+of+Reasoning+%28if+any%29+is+an+LLM+actually+doing%3F+On+the+Stochastic+Nature+and+Abductive+Appearance+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10080&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [56] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei, John Stamper, Paulo F. Carvalho*

**主要类别:** cs.CL

**AI概要:** 研究探索使用小型语言模型(SLM)进行自动问题生成，提出基于"生成-验证"策略的新流程，通过概率推理生成高质量问题，实验证明SLM在精心设计的流程下能有效生成符合学习目标的问题


<details>
  <summary>更多</summary>
  
**动机:** 作为大型语言模型在学习分析研究中的补充，探索小型语言模型在自动问题生成中的应用潜力，解决大型模型资源消耗大的问题

**方法:** 采用"生成-验证"策略的流程：先进行扩展性生成产生大量候选问题，然后通过新颖的概率推理进行选择性验证和精炼

**结果:** 通过人类专家和大型语言模型的双重评估，大多数评判者认为生成的问题答案清晰，与预期学习目标高度一致

**结论:** 小型语言模型在精心设计的流程指导下能够有效生成高质量的问题，为学习分析提供了更经济高效的替代方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generate-Then-Validate%3A+A+Novel+Question+Generation+Approach+Using+Small+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10110，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10110&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [57] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

**主要类别:** cs.CL

**AI概要:** DeepNews框架通过模拟金融记者的认知过程，使用三重模块机制解决了长文本生成中的"不可能三角"问题，在金融报道中显著降低了幻觉率并提高了内容质量


<details>
  <summary>更多</summary>
  
**动机:** 当前大语言模型在垂直领域长文本生成中面临"不可能三角"困境：难以同时实现低幻觉率、深度逻辑连贯性和个性化表达，这源于统计平滑陷阱忽略了专家写作所需的高熵信息获取和结构化认知过程

**方法:** 提出DeepNews框架，包含三个核心模块：1)基于信息觅食理论的双粒度检索机制，强制10:1的信息输入比；2)基于领域专家知识库的模式引导战略规划；3)对抗性约束提示技术，使用节奏打破和逻辑迷雾等策略

**结果:** 实验发现金融报道存在知识悬崖现象：检索上下文低于15,000字符时内容真实性崩溃，超过30,000字符的高冗余输入可使无幻觉率稳定在85%以上。在盲测中，DeepNews系统获得25%的采纳率，显著优于SOTA模型的0%

**结论:** DeepNews框架通过显式建模专家认知过程，成功解决了长文本生成的质量瓶颈，证明了结构化工作流在垂直领域内容生成中的有效性，为专业级文本生成提供了新范式

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Workflow+is+All+You+Need%3A+Escaping+the+%22Statistical+Smoothing+Trap%22+via+High-Entropy+Information+Foraging+and+Adversarial+Pacing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10121，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10121&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [58] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park, Jeongseok Yun, Bohyung Kim*

**主要类别:** cs.CL

**AI概要:** 提出两阶段提示框架，从短评论文本推断显性和隐性用户画像，用于生成个性化回复，无需微调模型即可提升相关性和个性化


<details>
  <summary>更多</summary>
  
**动机:** 在用户信息有限的领域（如外卖平台），大语言模型因缺乏上下文用户数据而生成通用回复，降低了参与度和效果

**方法:** 两阶段提示框架：1）从短评论文本推断显性（用户声明的偏好）和隐性（人口统计或风格线索）用户画像 2）将推断的画像属性融入回复生成提示中，通过调整解码温度鼓励多样且忠实的生成

**结果:** 在韩国外卖应用的真实数据集上评估，显示该方法在精确度、多样性和语义一致性方面有效提升了自动回复的相关性和个性化

**结论:** 人物画像增强提示能有效提升自动回复的相关性和个性化，无需模型微调

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PARAN%3A+Persona-Augmented+Review+ANswering+system+on+Food+Delivery+Review+Dataset，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10148，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10148&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [59] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum, Hani Itani, Hasan Abed Al Kader Hammoud, Philip Torr, Adel Bibi, Bernard Ghanem*

**主要类别:** cs.CL

**AI概要:** 研究表明大语言模型在任务适配时会出现安全性退化，将安全问题建模为持续学习问题，发现持续学习方法能有效降低攻击成功率，其中DER方法表现最佳


<details>
  <summary>更多</summary>
  
**动机:** 随着大语言模型的普及，安全对齐变得越来越重要。研究发现模型在适应新任务时会出现安全性退化问题，需要找到在微调过程中保持安全性的方法

**方法:** 将微调过程中的安全问题建模为持续学习问题，采用基于正则化、基于记忆和模型融合等持续学习方法，在良性用户数据和中毒用户数据两种场景下进行系统评估

**结果:** 持续学习方法相比标准微调始终获得更低的攻击成功率，其中DER方法在保持任务效用的同时优于其他持续学习方法和现有安全保护基线方法

**结论:** 持续学习是保持大语言模型安全性的实用解决方案，该发现在三个下游任务和三个模型家族中都得到了验证

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unforgotten+Safety%3A+Preserving+Safety+Alignment+of+Large+Language+Models+with+Continual+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10150，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10150&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [60] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh, Sangjoon Park, Byung-Hoon Kim*

**主要类别:** cs.CL

**AI概要:** AutoMedic是一个多智能体模拟框架，用于自动化评估大型语言模型在临床对话中的表现，通过将静态医学问答数据集转换为虚拟患者档案，实现多轮临床对话模拟，并使用CARE指标进行多维度评估。


<details>
  <summary>更多</summary>
  
**动机:** 当前医学领域LLM评估主要依赖静态问答基准，缺乏对动态交互式临床对话场景的有效评估方法，且评估维度单一，难以标准化和量化复杂的临床交互情境。

**方法:** 开发AutoMedic框架：1）将现成静态QA数据集转换为虚拟患者档案；2）构建LLM智能体间的多轮临床对话模拟；3）设计CARE评估指标（临床准确性、效率/策略、同理心、鲁棒性）。

**结果:** 研究验证了AutoMedic作为自动化评估框架的有效性，人类专家验证表明该框架能提供实用的临床对话代理评估指南。

**结论:** AutoMedic为解决临床对话LLM评估的标准化难题提供了可行方案，为医学对话应用的LLM有效开发提供了实践指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoMedic%3A+An+Automated+Evaluation+Framework+for+Clinical+Conversational+Agents+with+Medical+Dataset+Grounding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10195，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10195&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


### [61] [Multilingual VLM Training: Adapting an English-Trained VLM to French](https://arxiv.org/abs/2512.10336)
*Jules Lahmi, Alexis Roger*

**主要类别:** cs.CL

**AI概要:** 本文探讨了将英语训练的视觉语言模型(VLM)适配到其他语言的挑战，比较了翻译管道、LoRA微调和两阶段微调三种方法，发现数据集翻译是主要瓶颈，建议未来应专注于原生语言数据收集和改进翻译策略。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI视觉语言模型的进展主要局限于英语，限制了非英语用户的可访问性，需要将这些能力扩展到更广泛的语言范围。

**方法:** 采用翻译管道、LoRA微调和两阶段微调(分离视觉适配和语言适配)三种方法进行比较评估，使用翻译后的多模态基准测试和母语专家手动评估。

**结果:** 数据集翻译是多语言VLM性能的主要瓶颈，数据质量限制了训练和评估的有效性。

**结论:** 未来工作应专注于原生语言数据集的收集和改进翻译策略，以提升多语言视觉语言模型的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multilingual+VLM+Training%3A+Adapting+an+English-Trained+VLM+to+French，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10336，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10336&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.

</details>


### [62] [Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale](https://arxiv.org/abs/2512.10398)
*Zhaodong Wang, Zhenting Qi, Sherman Wong, Nathan Hu, Samuel Lin, Jun Ge, Erwin Gao, Yining Yang, Ben Maurer, Wenlin Chen, David Recordon, Yilun Du, Minlan Yu, Ying Zhang*

**主要类别:** cs.CL

**AI概要:** Confucius Code Agent (CCA) 是一个开源AI软件工程师，在工业规模任务中表现出色，在SWE-Bench-Pro上达到54.3%的state-of-the-art性能，通过Confucius SDK提供透明、可扩展的AI代理开发平台。


<details>
  <summary>更多</summary>
  
**动机:** 现有开源编码代理在工业规模工作负载下表现不足，而专有代理虽性能强但缺乏可扩展性、可解释性和可控性，需要构建既能处理大规模存储库又具有跨会话持久记忆的AI软件工程代理。

**方法:** 基于Confucius SDK构建，采用三层视角设计：Agent体验(AX)、用户体验(UX)、开发者体验(DX)。包含分层工作记忆的统一编排器、跨会话持续学习的持久笔记系统、模块化扩展工具，以及通过构建-测试-改进循环自动合成和优化代理配置的元代理。

**结果:** 在SWE-Bench-Pro基准测试中取得54.3%的Resolve@1性能，显著优于之前的编码代理，实现了state-of-the-art性能。

**结论:** Confucius SDK和CCA为AI代理提供了透明、可扩展和可复现的基础，弥合了研究原型与生产级系统之间的差距，支持工业规模的代理开发和部署。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Confucius+Code+Agent%3A+An+Open-sourced+AI+Software+Engineer+at+Industrial+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10398，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10398&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.

</details>


### [63] [Sliding Window Attention Adaptation](https://arxiv.org/abs/2512.10411)
*Yijiong Yu, Jiale Liu, Qingyun Wu, Huazheng Wang, Ji Pei*

**主要类别:** cs.CL

**AI概要:** 提出了SWAA方法，通过五种技术的组合适配，让使用全注意力预训练的LLM能够有效适配滑动窗口注意力，在保持线性计算复杂度的同时恢复长上下文性能。


<details>
  <summary>更多</summary>
  
**动机:** Transformer的自注意力机制计算复杂度随输入长度二次增长，滑动窗口注意力(SWA)可降低到线性复杂度，但直接将预训练的全注意力模型转为SWA会导致长上下文性能严重下降。

**方法:** 提出SWAA适配方法，包含五种技术：1)仅在预填充阶段使用SWA；2)保留"sink"令牌；3)交替使用FA/SWA层；4)思维链(CoT)；5)微调。通过不同组合方式实现适配。

**结果:** 实验表明SWA适配是可行但非平凡的：单一方法不足，但特定协同组合能有效恢复原始长上下文性能。分析了不同配置的性能-效率权衡。

**结论:** SWAA提供了一套实用的适配方案，为不同场景推荐了适配配置，实现了在保持计算效率的同时维持模型性能的目标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sliding+Window+Attention+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10411，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10411&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation

</details>


### [64] [Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers](https://arxiv.org/abs/2512.10422)
*Youmin Ko, Sungjong Seo, Hyunjoon Kim*

**主要类别:** cs.CL

**AI概要:** CoopRAG是一种新颖的检索增强生成框架，通过检索器和LLM的协作交互，以及检索器模型不同层间的协同工作，显著提升问答任务的准确性和检索效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有RAG方法在简单和多跳问答中仍存在错误检索和幻觉问题，需要更有效的协作机制来解决这些局限性。

**方法:** 将问题分解为子问题和推理链，检索相关文档，通过检索器层对比重新排序文档，利用LLM填充推理链中的掩码位置。

**结果:** 在三个多跳问答数据集和一个简单问答数据集上，CoopRAG在检索和问答性能方面均优于最先进的方法。

**结论:** CoopRAG通过多层次的协作机制有效解决了RAG中的错误检索和幻觉问题，为问答任务提供了更可靠的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cooperative+Retrieval-Augmented+Generation+for+Question+Answering%3A+Mutual+Information+Exchange+and+Ranking+by+Contrasting+Layers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10422，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10422&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

</details>


### [65] [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)
*Dmitrii Stoianov, Danil Taranets, Olga Tsymboi, Ramil Latypov, Almaz Dautov, Vladislav Kruglikov, Nikita Surkov, German Abramov, Pavel Gein, Dmitry Abulkhanov, Mikhail Gashkov, Viktor Zelenkovskiy, Artem Batalov, Aleksandr Medvedev, Anatolii Potapov*

**主要类别:** cs.CL

**AI概要:** T-pro 2.0是一个开源俄语大语言模型，支持混合推理和高效推理，包含西里尔字母密集分词器和优化的推理流水线，同时发布了模型权重、指令语料库和推理基准等资源。


<details>
  <summary>更多</summary>
  
**动机:** 为俄语语言处理提供可复现和可扩展的研究基础，支持俄语推理能力的研究和应用开发，解决俄语LLM资源匮乏的问题。

**方法:** 使用西里尔字母密集分词器(Cyrillic-dense tokenizer)和适配的EAGLE推测解码流水线来降低延迟，支持直接回答和推理轨迹生成两种模式。

**结果:** 开发了完整的开源系统，包括模型权重、T-Wix 50万条指令语料库、T-Math推理基准和EAGLE权重，并提供了公开网页演示展示推理加速效果。

**结论:** T-pro 2.0为构建和评估高效实用的俄语LLM应用提供了一个易访问的开源系统，促进了俄语语言推理研究的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是T-pro+2.0%3A+An+Efficient+Russian+Hybrid-Reasoning+Model+and+Playground，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10430，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10430&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.

</details>


### [66] [Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring "Tortured Phrases" in Scientific Literature](https://arxiv.org/abs/2512.10435)
*Agniva Maiti, Prajwal Panth, Suresh Chandra Satapathy*

**主要类别:** cs.CL

**AI概要:** SRAP框架通过两阶段方法检测并恢复科学文献中的对抗性抄袭文本，使用统计异常检测和语义重建技术，在对抗性科学文本上达到23.67%的恢复准确率。


<details>
  <summary>更多</summary>
  
**动机:** 科学文献的完整性面临对抗性文本生成技术的威胁，现有检测方法依赖静态黑名单或通用语言模型，对新型混淆技术检测效果差且无法溯源。

**方法:** 两阶段架构：1) 使用SciBERT进行统计异常检测（基于token级伪困惑度）；2) 使用FAISS和SBERT进行基于源的语义重建和句子对齐。

**结果:** 实验显示零基线方法完全失败(0.00%恢复准确率)，而SRAP方法达到23.67%恢复准确率，显著优于基线方法，并证明静态决策边界在科学文本检测中的必要性。

**结论:** SRAP框架不仅能检测对抗性抄袭，还能数学上恢复原始术语，实现法医分析，将混淆表达链接回最可能的源文档。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semantic+Reconstruction+of+Adversarial+Plagiarism%3A+A+Context-Aware+Framework+for+Detecting+and+Restoring+%22Tortured+Phrases%22+in+Scientific+Literature，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10435，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10435&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate "tortured phrases", statistically improbable synonyms (e.g. "counterfeit consciousness" for "artificial intelligence"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.

</details>


### [67] [Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT](https://arxiv.org/abs/2512.10440)
*Nour El Houda Ben Chaabene, Hamza Hammami*

**主要类别:** cs.CL

**AI概要:** 该论文通过将知识图谱(KG)与BERT结合(KG-BERT)来增强大语言模型的结枃化知识能力，在知识密集型任务中显著提升性能


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型如Claude、Mistral IA和GPT-4在NLP任务中表现出色，但缺乏结构化知识，导致事实不一致的问题

**方法:** 通过知识图谱(KG)与BERT的集成方法(KG-BERT)来增强模型的知识基础和推理能力

**结果:** 实验结果显示在问答和实体链接等知识密集型任务中取得了显著提升

**结论:** 这种方法提高了大语言模型的事实可靠性，并使其能够开发出更具上下文感知能力的下一代模型

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Next-Generation+Language+Models+with+Knowledge+Graphs%3A+Extending+Claude%2C+Mistral+IA%2C+and+GPT-4+via+KG-BERT，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10440，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10440&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.

</details>


### [68] [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)
*Nour El Houda Ben Chaabene, Hamza Hammami, Laid Kahloul*

**主要类别:** cs.CL

**AI概要:** 本文提出了一种心理感知对话代理，结合LLM、知识图谱增强BERT和双向LSTM注意力机制，通过多模态数据分析学生认知和情感状态，在试点研究中显示出提升学习动机、减轻压力和适度学业进步的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有教育聊天机器人通常只能提供学业辅导或情感支持的单一功能，缺乏对学生认知和情感状态的实时综合分析能力，无法提供个性化的适应性教育干预。

**方法:** 结合大型语言模型(LLMs)、知识图谱增强BERT(KG-BERT)和带注意力的双向长短期记忆网络(LSTM)，利用文本语义、语音韵律特征和时间行为趋势等多模态数据，实时分类学生的认知和情感状态。

**结果:** 在大学学生中进行的试点研究表明，相比基线方法，该系统能提高学习动机、减轻压力，并带来适度的学业进步。

**结论:** 研究结果表明，整合语义推理、多模态融合和时间建模的方法具有很大潜力，能够支持自适应的、以学生为中心的教育干预措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decoding+Student+Minds%3A+Leveraging+Conversational+Agents+for+Psychological+and+Learning+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10441，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10441&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.

</details>


### [69] [Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs](https://arxiv.org/abs/2512.10453)
*Lars G. B. Johnsen*

**主要类别:** cs.CL

**AI概要:** 大型语言模型在仅接受表层形式训练的情况下，能够可靠地区分语法正确和不正确的句子结构，表明它们对句法结构具有敏感性，而不仅仅是线性顺序。


<details>
  <summary>更多</summary>
  
**动机:** 测试仅基于表层形式训练的大型语言模型是否能重现传统生成语法中的系统性语法对比，以判断这些模型是否具有内在的层级语法表征。

**方法:** 使用GPT-4和LLaMA-3等模型，通过提示词引发可接受性评分，重点测试主语-助动词倒置和寄生空位许可这两个经典句法结构。

**结果:** LLMs能够可靠地区分两种结构中的语法正确和不正确变体，表明它们对结构敏感而不仅仅是线性顺序。

**结论:** 结构概括性从表层形式的预测训练中浮现出来，表明LLMs具有对句法的功能性敏感性，无需显式编码。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grammaticality+Judgments+in+Humans+and+Language+Models%3A+Revisiting+Generative+Grammar+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10453，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10453&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.

</details>


### [70] [XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](https://arxiv.org/abs/2512.10545)
*Iñaki Lacunza, José Javier Saiz, Alexander Shvets, Aitor Gonzalez-Agirre, Marta Villegas*

**主要类别:** cs.CL

**AI概要:** 该论文提出XDoGE方法优化多语言LLM训练的语言分布，通过代理模型重新权衡数据，针对伊比利亚半岛6种不同资源水平的语言进行实验，最终发布了IberianLLM-7B-Instruct模型。


<details>
  <summary>更多</summary>
  
**动机:** 当前大语言模型过度依赖英语等高资源语言，导致在中低资源语言上表现不佳，需要优化多语言训练数据的分布。

**方法:** 扩展DoGE算法为XDoGE用于多语言设置，通过小代理模型优化语言分布权重，然后重新缩放数据训练全尺寸模型（从头训练或持续预训练）。

**结果:** 针对6种伊比利亚语言（英语、西班牙语、葡萄牙语、加泰罗尼亚语、加利西亚语、巴斯克语）进行实验，研究了数据重复和欠采样效果，并发布了新的IberianLLM-7B模型。

**结论:** XDoGE方法能有效改善多语言LLM的性能，特别是在中低资源语言上，通过优化语言分布权重可以提升模型的多语言能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是XDoGE%3A+Multilingual+Data+Reweighting+to+Enhance+Language+Inclusivity+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10545，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10545&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.

</details>


### [71] [Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models](https://arxiv.org/abs/2512.10561)
*Amartya Roy, Elamparithy M, Kripabandhu Ghosh, Ponnurangam Kumaraguru, Adrian de Wynter*

**主要类别:** cs.CL

**AI概要:** 本文比较了不同架构模型在因果推理任务中的表现，发现ICL单独使用不可靠，微调的编码器和编码器-解码器架构在因果推理中表现更稳健，而仅解码器模型需要大规模才能匹配或超越其性能。


<details>
  <summary>更多</summary>
  
**动机:** 研究上下文学习(ICL)在因果推理中的角色和性能，因为因果推理需要多跳组合和严格连接控制，而依赖输入的虚假词汇关系可能导致误导性结果。

**方法:** 比较微调的编码器、编码器-解码器与仅解码器架构在零样本和少样本ICL设置下的表现，涵盖自然语言和非自然语言场景。

**结果:** ICL单独使用对可靠因果推理不足，常过度关注无关输入特征。仅解码器模型对分布偏移脆弱，而微调的编码器和编码器-解码器模型在测试中（包括非自然语言分割）表现更稳健。仅解码器架构需要大规模才能匹配或超越其他架构。

**结论:** 对于成本效益高、短期稳健的因果推理，带有针对性微调的编码器或编码器-解码器架构更优。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Reasoning+Favors+Encoders%3A+On+The+Limits+of+Decoder-Only+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10561，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10561&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.

</details>


### [72] [RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems](https://arxiv.org/abs/2512.10575)
*Hang Ding, Qiming Feng, Dongqi Liu, Qi Zhao, Tao Yao, Shuo Wang, Dongsheng Chen, Jian Li, Zhenye Gan, Jiangning Zhang, Chengjie Wang, Yabiao Wang*

**主要类别:** cs.CL

**AI概要:** 论文提出了RoleRMBench基准和RoleRM奖励模型，针对角色扮演对话中的奖励建模问题，通过连续隐式偏好方法显著提升了主观领域下LLM与人类偏好对齐的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有奖励模型在主观开放领域（如角色扮演）中表现严重退化，无法捕捉细致入微且基于角色的人类判断，需要专门针对此类场景的评估基准和建模方法。

**方法:** 提出RoleRMBench基准（覆盖7种细粒度能力）和RoleRM奖励模型，采用连续隐式偏好（CIP）方法，通过多种结构化策略将主观评估重新表述为连续一致的两两监督。

**结果:** RoleRM在RoleRMBench上平均超越现有开源和闭源奖励模型24%以上，在叙事连贯性和风格保真度方面获得显著提升。

**结论:** 连续偏好表示和标注一致性对于主观对齐至关重要，为以人为中心的对话系统的主观对齐奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RoleRMBench+%26+RoleRM%3A+Towards+Reward+Modeling+for+Profile-Based+Role+Play+in+Dialogue+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10575，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10575&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.

</details>


### [73] [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)
*Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li*

**主要类别:** cs.CL

**AI概要:** AgriGPT-Omni是一个农业多模态统一框架，整合语音、视觉和文本，通过三阶段训练实现跨语言和模态的统一推理，在农业多语言多模态任务上显著优于通用基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 解决农业应用中缺乏多语言语音数据、统一多模态架构和综合评估基准的问题，促进低资源地区的农业智能发展。

**方法:** 1)构建可扩展的数据合成和收集管道，创建最大的农业语音数据集；2)通过三阶段范式训练：文本知识注入、渐进多模态对齐和GRPO强化学习；3)提出首个农业三模态基准AgriBench-Omni-2K。

**结果:** AgriGPT-Omni在多语言多模态推理和实际语音理解任务上显著优于通用基线模型，数据集包含492K合成和1.4K真实语音样本，覆盖六种语言。

**结论:** 该框架为农业AI发展提供了完整的解决方案，包括模型、数据、基准和代码的全面开源，将促进可重复研究、包容性农业智能和低资源地区的可持续发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgriGPT-Omni%3A+A+Unified+Speech-Vision-Text+Framework+for+Multilingual+Agricultural+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10624，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10624&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.

</details>


### [74] [From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages](https://arxiv.org/abs/2512.10630)
*Smiljana Antonijevic Ubois*

**主要类别:** cs.CL

**AI概要:** 该研究以塞尔维亚语为例，分析了AI时代低资源语言技术发展的结构性和社会技术因素，提出了基于CARE原则的Data Care框架来解决语言偏见问题


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型主要基于英语等主导语言训练，对低资源语言的表示反映了源语言材料中的文化和语言偏见，需要解决这种不平等现象

**方法:** 通过对10位学者和从业者（包括语言学家、数字人文主义者和AI开发者）进行半结构化访谈，分析塞尔维亚语面临的挑战

**结果:** 识别出历史文本遗产破坏、表面音译、依赖英语训练模型、数据偏见和缺乏文化特性的数据集管理等挑战

**结论:** 提出了基于CARE原则（集体利益、控制权、责任和伦理）的Data Care框架，将偏见缓解从技术修复转变为语料库设计、注释和治理的核心组成部分

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Data+Scarcity+to+Data+Care%3A+Reimagining+Language+Technologies+for+Serbian+and+other+Low-Resource+Languages，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10630，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10630&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.

</details>


### [75] [Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation](https://arxiv.org/abs/2512.10734)
*Rebekka Görge, Sujan Sai Gannamaneni, Tabea Naeven, Hammam Abdelwahab, Héctor Allende-Cid, Armin B. Cremers, Lennard Helmer, Michael Mock, Anna Schmitz, Songkai Xue, Elif Yildirir, Maximilian Poretschkin, Stefan Wrobel*

**主要类别:** cs.CL

**AI概要:** 该论文提出了一个针对LLM训练数据的偏见检测和缓解流程，包含四个组件来处理表示偏见和刻板印象，并通过实验验证了数据去偏见的效果，但发现模型偏见评估方法存在局限性。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型训练数据存在多方面的偏见表现，包括有害语言和人口统计分布偏差。欧盟AI法案等法规要求识别和减轻对受保护群体的偏见，但缺乏实际操作指导。

**方法:** 提出包含四个组件的综合数据偏见检测和缓解流程：1)基于质量标准的LLM生成群体标签词表；2)使用人口统计表示分数量化表示偏见；3)社会语言学过滤检测和缓解刻板印象；4)语法和上下文感知的反事实数据增强补偿表示偏见。

**结果:** 通过性别、宗教和年龄案例的双重评估：1)人类验证和基线比较显示成功减少了文本数据集中的表示偏见和刻板印象；2)模型偏见基准测试显示，在去偏见数据上微调的LLM并未一致改善偏见表现，暴露了当前评估方法的局限性。

**结论:** 虽然数据去偏见方法有效减少了数据层面的偏见，但模型层面的偏见评估存在关键差距，需要针对性的数据操作来解决显现的模型偏见问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Textual+Data+Bias+Detection+and+Mitigation+-+An+Extensible+Pipeline+with+Experimental+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10734&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.

</details>


### [76] [Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving](https://arxiv.org/abs/2512.10739)
*Songyang Gao, Yuzhe Gu, Zijian Wu, Lingkai Kong, Wenwei Zhang, Zhongrui Cai, Fan Zheng, Tianyou Ma, Junhao Shen, Haiteng Zhao, Duanyang Zhang, Huilun Zhang, Kuikun Liu, Chengqi Lyu, Yanhui Duan, Chiyu Chen, Ningsheng Ma, Jianfei Gao, Han Lyu, Dahua Lin, Kai Chen*

**主要类别:** cs.CL

**AI概要:** 该论文提出了OPV（基于结果的流程验证器），通过验证长推理链的总结结果来准确高效地进行验证，并采用迭代主动学习框架降低标注成本，在多个基准测试中达到最先进性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于结果的验证器无法检查长推理链中的不可靠中间步骤，而基于过程的验证器由于人工标注成本高昂导致高质量标注稀缺，难以可靠检测复杂长推理链中的错误。

**方法:** 提出OPV验证器，通过验证长推理链的总结结果来进行流程验证；采用迭代主动学习框架，通过专家标注最不确定的案例，使用拒绝微调(RFT)和RLVR训练新的OPV。

**结果:** OPV在held-out benchmark上达到83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作时显著提升性能，如将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%。

**结论:** OPV通过结合结果和过程验证的优势，实现了准确高效的验证能力，同时通过主动学习降低了标注成本，在多个任务中展现出卓越性能和广泛适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Long-horizon+Reasoning+Agent+for+Olympiad-Level+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10739，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10739&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbf{O}utcome-based \textbf{P}rocess \textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc{\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\% to 73.3\% on AIME2025 as the compute budget scales.

</details>


### [77] [TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage](https://arxiv.org/abs/2512.10741)
*Elroy Galbraith, Chadwick Sutherland, Donahue Morgan*

**主要类别:** cs.CL

**AI概要:** TRIDENT是一个三层调度员支持架构，通过加勒比口音优化的语音识别、本地实体提取和生物声学痛苦检测，在语音识别失败时仍能为调度员提供结构化信息，确保加勒比口音用户获得公平的紧急分诊服务。


<details>
  <summary>更多</summary>
  
**动机:** 紧急语音识别系统在非标准英语变体上存在系统性性能下降，导致加勒比人群服务缺口，需要解决口音差异带来的识别问题。

**方法:** 采用三层架构：加勒比口音优化的ASR、基于大语言模型的本地实体提取、生物声学痛苦检测，提供转录置信度、结构化临床实体和声音压力指标三种信号。

**结果:** 系统将低ASR置信度转化为有价值的队列优先级信号，结合声音压力标记识别危机呼叫者，通过语义分析捕捉临床指标。

**结论:** 建立了一个口音弹性的紧急AI框架，确保加勒比声音能够公平获得国家分诊协议服务，但需要未来在加勒比紧急呼叫上进行实证验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TRIDENT%3A+A+Redundant+Architecture+for+Caribbean-Accented+Emergency+Speech+Triage，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10741，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10741&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.
  The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.
  We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.

</details>


### [78] [OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification](https://arxiv.org/abs/2512.10756)
*Zijian Wu, Lingkai Kong, Wenwei Zhang, Songyang Gao, Yuzhe Gu, Zhongrui Cai, Tianyou Ma, Yuhong Liu, Zhi Wang, Runyuan Ma, Guangyu Wang, Wei Li, Conghui He, Dahua Lin, Kai Chen*

**主要类别:** cs.CL

**AI概要:** 提出了一种基于结果的流程验证器(OPV)，通过验证长思维链的总结结果来准确高效地进行验证，并采用迭代主动学习框架降低标注成本，在多个基准测试中达到最先进性能


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于结果的验证器无法检查长思维链中的不可靠中间步骤，而基于过程的验证器由于人工标注成本高昂导致高质量标注稀缺，难以可靠检测复杂长思维链中的错误

**方法:** 提出OPV验证器，验证长思维链总结结果的推理过程；采用迭代主动学习框架，通过拒绝微调(RFT)和RLVR逐步提升验证能力；每轮迭代标注当前最佳OPV最不确定的案例用于训练新版OPV

**结果:** 在OPV-Bench上达到83.1的F1分数，优于Qwen3-Max-Preview的76.3；能有效检测合成数据集中的假阳性；与策略模型协作时持续带来性能提升，如将DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%

**结论:** OPV通过结合结果和过程验证的优势，实现了准确高效的验证能力，同时降低了标注成本，为大语言模型的复杂推理任务提供了可靠的验证解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OPV%3A+Outcome-based+Process+Verifier+for+Efficient+Long+Chain-of-Thought+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10756，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10756&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.

</details>


### [79] [Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation](https://arxiv.org/abs/2512.10772)
*Kevin Glocker, Kätriin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz*

**主要类别:** cs.CL

**AI概要:** 研究表明，通过放大英语基础模型规模，可以在较少目标语言数据下实现与更多数据持续预训练的小模型相当或更好的性能，提高数据效率并减少灾难性遗忘。虽然模型合并效果仍不如联合多语言训练，但放大后的模型合并表现更佳。


<details>
  <summary>更多</summary>
  
**动机:** 解决多语言模型中低资源语言性能不佳的问题，探索通过模型缩放策略来更有效地适应新目标语言，同时保持基础语言能力。

**方法:** 进行全面的缩放消融实验，使用FLOP匹配的模型对比放大英语基础模型与标准持续预训练的效果，并探索语言特定模型的合并方法。

**结果:** 放大模型在获得足够目标语言数据后，性能可匹配或超越使用更多数据持续预训练的小模型；缩放有助于保持英语能力；放大后的模型合并表现优于小模型合并。

**结论:** 缩放是提高多语言模型适应效率和性能的有效策略，模型合并方法在多语言系统构建中仍有改进空间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Grow+Up+and+Merge%3A+Scaling+Strategies+for+Efficient+Language+Adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10772&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model's capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.

</details>


### [80] [Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting](https://arxiv.org/abs/2512.10780)
*Manurag Khullar, Utkarsh Desai, Poorva Malviya, Aman Dalmia, Zheyuan Ryan Shi*

**主要类别:** cs.CL

**AI概要:** LLMs在印度临床应用中处理罗马化文本时性能显著下降，F1分数比原生脚本低5-12分，可能导致近200万次分诊错误，虽然模型能理解语义意图但分类输出仍不可靠


<details>
  <summary>更多</summary>
  
**动机:** 印度语言使用者常用罗马化文本而非原生文字进行交流，但现有研究很少使用真实数据评估这种书写变体对LLMs可靠性的影响

**方法:** 在孕产妇和新生儿医疗分诊领域，使用包含5种印度语言和尼泊尔语的真实用户查询数据集，对主流LLMs进行基准测试

**结果:** 罗马化消息导致性能持续下降，F1分数比原生脚本低5-12个百分点，这种性能差距不是临床推理失败造成的

**结论:** 研究揭示了基于LLMs的健康系统中一个关键安全盲点：看似理解罗马化输入的模型可能仍无法可靠地对其采取行动

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Script+Gap%3A+Evaluating+LLM+Triage+on+Indian+Languages+in+Native+vs+Roman+Scripts+in+a+Real+World+Setting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10780，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10780&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.

</details>


### [81] [The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality](https://arxiv.org/abs/2512.10791)
*Aileen Cheng, Alon Jacovi, Amir Globerson, Ben Golan, Charles Kwong, Chris Alberti, Connie Tao, Eyal Ben-David, Gaurav Singh Tomar, Lukas Haas, Yonatan Bitton, Adam Bloniarz, Aijun Bai, Andrew Wang, Anfal Siddiqui, Arturo Bajuelos Castillo, Aviel Atias, Chang Liu, Corey Fry, Daniel Balle, Deepanway Ghosal, Doron Kukliansky, Dror Marcus, Elena Gribovskaya, Eran Ofek, Honglei Zhuang, Itay Laish, Jan Ackermann, Lily Wang, Meg Risdal, Megan Barnes, Michael Fink, Mohamed Amin, Moran Ambar, Natan Potikha, Nikita Gupta, Nitzan Katz, Noam Velan, Ofir Roval, Ori Ram, Polina Zablotskaia, Prathamesh Bang, Priyanka Agrawal, Rakesh Ghiya, Sanjay Ganapathy, Simon Baumgartner, Sofia Erell, Sushant Prakash, Thibault Sellam, Vikram Rao, Xuanhui Wang, Yaroslav Akulov, Yulong Yang, Zhen Yang, Zhixin Lai, Zhongru Wu, Anca Dragan, Avinatan Hassidim, Fernando Pereira, Slav Petrov, Srinivasan Venkatachary, Tulsee Doshi, Yossi Matias, Sasha Goldshtein, Dipanjan Das*

**主要类别:** cs.CL

**AI概要:** FACTS Leaderboard是一个综合评估语言模型事实准确性的在线基准测试套件，包含四个子测试板：多模态、参数知识、搜索能力和文档基础，使用自动化评判模型进行评分


<details>
  <summary>更多</summary>
  
**动机:** 需要全面评估语言模型在不同场景下生成事实准确文本的能力，提供比单一测试更全面的真实性衡量标准

**方法:** 创建包含四个子测试板的综合评估套件：FACTS Multimodal（图像问题）、FACTS Parametric（闭卷事实问题）、FACTS Search（信息搜索场景）、FACTS Grounding v2（长文本文档基础），使用自动化评判模型评分并平均四个组件得分

**结果:** 开发了一个完整的在线领导板套件，包含公开和私有数据集，提供对模型整体事实性的稳健平衡评估

**结论:** FACTS Leaderboard Suite将积极维护，为评估语言模型事实准确性提供全面的基准测试平台，可通过指定网址访问

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+FACTS+Leaderboard%3A+A+Comprehensive+Benchmark+for+Large+Language+Model+Factuality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10791&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models' world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model's overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .

</details>


### [82] [LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification](https://arxiv.org/abs/2512.10793)
*Michael Schlee, Christoph Weisser, Timo Kivimäki, Melchizedek Mashiku, Benjamin Saefken*

**主要类别:** cs.CL

**AI概要:** LabelFusion是一个融合集成框架，通过将传统Transformer分类器与大型语言模型结合，使用多层级感知机进行特征融合，实现高精度且成本感知的文本分类。


<details>
  <summary>更多</summary>
  
**动机:** 传统Transformer分类器和大型语言模型各有优势，但单独使用时在准确性、延迟和成本之间存在权衡。需要一种方法能够结合两者的互补优势，实现更鲁棒的文本分类性能。

**方法:** 1. 使用RoBERTa等传统Transformer分类器生成嵌入向量；2. 通过结构化提示工程策略从LLMs（如GPT、Gemini）获取每类分数；3. 将两种特征拼接后输入紧凑的多层级感知机（FusionMLP）进行融合；4. 提供端到端的AutoFusionClassifier高级接口。

**结果:** 在多个数据集上取得优异性能：AG News准确率达到92.4%，10类Reuters 21578主题分类准确率达到92.3%。实现了准确性、延迟和成本之间的实用权衡。

**结论:** LabelFusion成功融合了LLM推理能力和传统分类器的优势，提供了一个简单易用且灵活的框架，能够在多领域实现鲁棒的文本分类性能，同时保持成本效益。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LabelFusion%3A+Learning+to+Fuse+LLMs+and+Transformer+Classifiers+for+Robust+Text+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10793，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10793&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone's embeddings with the LLM-derived per-class scores -- obtained through structured prompt-engineering strategies -- and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains -- achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification -- while enabling practical trade-offs between accuracy, latency, and cost.

</details>


### [83] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

**主要类别:** cs.CL

**AI概要:** 使用计算文本分析方法分析《霍比特人》对话的情感基调，发现对话保持积极平静的语调，随着故事发展逐渐增强控制感，体现了小说在紧张与舒适间循环的情感节奏


<details>
  <summary>更多</summary>
  
**动机:** 通过计算工具与文学解读相结合，揭示文学作品中微妙的情感结构，展示数字方法如何分析文学作品的情感模式

**方法:** 使用正则表达式提取对话文本，通过NRC-VAD词典进行预处理和情感维度评分，量化情感特征

**结果:** 对话整体呈现高愉悦度（积极）和低唤醒度（平静）的基调，随着故事进展控制感（支配性）逐渐增强，情感在紧张与舒适间循环

**结论:** 计算分析方法能够有效揭示《霍比特人》中稳定的情感节奏和情感调节机制，展现了托尔金语言在张力与慰藉间的循环模式

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantifying+Emotional+Tone+in+Tolkien%27s+The+Hobbit%3A+Dialogue+Sentiment+Analysis+with+RegEx%2C+NRC-VAD%2C+and+Python，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10865，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10865&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [84] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

**主要类别:** cs.CL

**AI概要:** 本文评估了多模态大语言模型在视频情绪分析中的表现，发现在理想条件下表现良好且无人口统计偏差，但在真实议会辩论场景中效果不佳，强调了持续评估AI方法的必要性。


<details>
  <summary>更多</summary>
  
**动机:** 虽然多模态生成式AI在政治沟通情绪分析中具有巨大潜力，但缺乏关于其有效性的实证证据，需要填补这一研究空白。

**方法:** 使用两个互补的人类标注视频数据集，评估当前多模态大语言模型在视频情绪唤醒度分析中的表现。

**结果:** 在理想条件下，mLLMs的情绪唤醒度评分高度可靠且无人口统计偏差；但在真实议会辩论录音中，其表现未能达到预期，可能对下游统计推断产生负面影响。

**结论:** 研究强调了持续、彻底评估新兴生成式AI方法在政治分析中应用的必要性，并提供了一个可复现的评估框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computational+emotion+analysis+with+multimodal+LLMs%3A+Current+evidence+on+an+emerging+methodological+opportunity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.10882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.10882&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


### [85] [Unsupervised Acquisition of Discrete Grammatical Categories](https://arxiv.org/abs/2503.18702)
*David Ph. Shakouri, Crit Cremers, Niels O. Schiller*

**主要类别:** cs.CL

**AI概要:** 本文介绍了一个多智能体语言习得计算实验系统，通过母语模型生成语言样本，子代模型通过统计分析学习抽象语法知识，成功获得了类似自然语言的语法类别。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索如何通过计算模型模拟语言习得过程，特别是子代如何仅通过观察母语生成的语料来获得抽象语法知识，而不依赖母语的内部知识。

**方法:** 使用包含母语模型和子代模型的多智能体系统，母语模型生成语言样本，子代模型应用层次凝聚聚类分析对输入数据进行统计分析，从中提取离散语法规则。

**结果:** 实验成功从输入数据中识别出类似语言学家提出的语法类别，验证了非平凡语法知识的获得，并在测试集上验证了参数配置的有效性。

**结论:** 该计算实验室环境能够有效模拟语言习得过程，通过统计分析从语言样本中获取抽象语法结构，为理解人类语言习得机制提供了计算模型支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Acquisition+of+Discrete+Grammatical+Categories，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2503.18702，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2503.18702&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.

</details>
