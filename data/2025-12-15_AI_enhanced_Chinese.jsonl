{"id": "2512.11169", "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "本文提出CORL框架，使用强化学习端到端微调MILP方案，通过将分支定界算法求解的MILP建模为可微分随机策略，直接在真实数据上优化操作性能。", "motivation": "传统MILP方法在建模随机现实问题时存在困难导致性能不佳，现有机器学习方法依赖监督学习且需要最优决策标签。", "method": "将分支定界算法求解的混合整数线性规划建模为可微分随机策略，采用强化学习在真实数据上进行端到端微调。", "result": "在简单的组合序贯决策示例中验证了CORL方法的有效性。", "conclusion": "CORL框架提供了一种新的方法，能够绕过传统MILP建模的准确性要求，直接优化决策质量，为组合优化问题提供了强化学习解决方案。"}}
{"id": "2512.11187", "pdf": "https://arxiv.org/pdf/2512.11187", "abs": "https://arxiv.org/abs/2512.11187", "authors": ["Haohui Zhang", "Wouter van Heeswijk", "Xinyu Hu", "Neil Yorke-Smith", "Martijn Mes"], "title": "Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling", "categories": ["cs.AI"], "comment": null, "summary": "Online Freight Exchange Systems (OFEX) play a crucial role in modern freight logistics by facilitating real-time matching between shippers and carrier. However, efficient combinatorial bundling of transporation jobs remains a bottleneck. We model the OFEX combinatorial bundling problem as a multi-commodity one-to-one pickup-and-delivery selective traveling salesperson problem (m1-PDSTSP), which optimizes revenue-driven freight bundling under capacity, precedence, and route-length constraints. The key challenge is to couple combinatorial bundle selection with pickup-and-delivery routing under sub-second latency. We propose a learning--accelerated hybrid search pipeline that pairs a Transformer Neural Network-based constructive policy with an innovative Multi-Start Large Neighborhood Search (MSLNS) metaheuristic within a rolling-horizon scheme in which the platform repeatedly freezes the current marketplace into a static snapshot and solves it under a short time budget. This pairing leverages the low-latency, high-quality inference of the learning-based constructor alongside the robustness of improvement search; the multi-start design and plausible seeds help LNS to explore the solution space more efficiently. Across benchmarks, our method outperforms state-of-the-art neural combinatorial optimization and metaheuristic baselines in solution quality with comparable time, achieving an optimality gap of less than 2\\% in total revenue relative to the best available exact baseline method. To our knowledge, this is the first work to establish that a Deep Neural Network-based constructor can reliably provide high-quality seeds for (multi-start) improvement heuristics, with applicability beyond the \\textit{m1-PDSTSP} to a broad class of selective traveling salesperson problems and pickup and delivery problems.", "AI": {"tldr": "本文提出了一种学习加速的混合搜索框架，将基于Transformer的构造策略与多起点大邻域搜索相结合，用于解决在线货运交换系统中的组合捆绑问题，在亚秒级延迟内实现了接近最优的解决方案。", "motivation": "在线货运交换系统(OFEX)中，高效的运输任务组合捆绑是一个瓶颈问题，需要在容量、优先级和路径长度约束下实现收益驱动的货运捆绑优化，同时满足亚秒级延迟要求。", "method": "将问题建模为多商品一对一取送货选择性旅行商问题(m1-PDSTSP)，提出混合搜索流程：使用Transformer神经网络构造策略生成初始解，结合创新的多起点大邻域搜索(MSLNS)元启发式算法，在滚动时域框架下进行求解。", "result": "在基准测试中，该方法在相同时间内优于最先进的神经组合优化和元启发式基线方法，相对于最佳精确基线方法的总收益最优性差距小于2%。", "conclusion": "这是首个证明基于深度神经网络的构造器能够为(多起点)改进启发式算法可靠提供高质量初始解的工作，其应用范围可扩展到更广泛的选择性旅行商问题和取送货问题。"}}
{"id": "2512.11213", "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver是一个多智能体系统中测试时计算分配优化框架，通过模块化协作和双级规划架构，在固定预算下显著提升多智能体协作性能。", "motivation": "现有测试时计算扩展技术（如重复采样、自验证等）在单智能体场景中有效，但缺乏在多智能体系统中分配计算资源以促进协作的原则性机制，特别是在明确预算约束下。", "method": "提出FutureWeaver框架：1）模块化协作，通过自玩反思抽象可重用多智能体工作流；2）双级规划架构，优化当前任务状态的计算分配并推测未来步骤。", "result": "在复杂智能体基准测试中，FutureWeaver在不同预算设置下始终优于基线方法，验证了其在推理时优化多智能体协作的有效性。", "conclusion": "FutureWeaver成功解决了多智能体系统中测试时计算分配的关键挑战，为预算约束下的协作优化提供了有效解决方案，展示了模块化方法和前瞻性规划的重要性。"}}
{"id": "2512.11270", "pdf": "https://arxiv.org/pdf/2512.11270", "abs": "https://arxiv.org/abs/2512.11270", "authors": ["Hong Je-Gal", "Chan-Bin Yi", "Hyun-Suk Lee"], "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation", "categories": ["cs.AI"], "comment": "NeurIPS 2025 Workshop: Multi-Turn Interactions in Large Language Models. 26 pages, 8 figures", "summary": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.", "AI": {"tldr": "A-LAMP是一个基于大型语言模型的自动化框架，能够将自然语言任务描述自动转换为马尔可夫决策过程(MDP)和训练好的策略，解决了传统RL应用中的建模错误、代码脆弱和目标不对齐问题。", "motivation": "将强化学习应用于现实任务需要将非正式描述转换为形式化的MDP、实现可执行环境并训练策略代理。这个过程存在建模错误、代码脆弱和目标不对齐等挑战，阻碍策略训练。", "method": "提出基于代理式大型语言模型的A-LAMP框架，将建模、编码和训练分解为可验证的阶段，确保整个流程的语义对齐。", "result": "在经典控制和自定义RL领域中，A-LAMP始终展现出比单一最先进LLM模型更高的策略生成能力。其轻量级变体也能接近更大模型的性能。", "conclusion": "A-LAMP能够生成保持任务最优性的环境和策略，证明了其正确性和可靠性，为自动化RL任务建模和策略生成提供了有效解决方案。"}}
{"id": "2512.10967", "pdf": "https://arxiv.org/pdf/2512.10967", "abs": "https://arxiv.org/abs/2512.10967", "authors": ["Subham Kumar", "Prakrithi Shivaprakash", "Abhishek Manoharan", "Astut Kurariya", "Diptadhi Mukherjee", "Lekhansh Shukla", "Animesh Mukherjee", "Prabhat Chand", "Pratima Murthy"], "title": "ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Automatic Speech Recognition (ASR) is increasingly used to document clinical encounters, yet its reliability in multilingual and demographically diverse Indian healthcare contexts remains largely unknown. In this study, we conduct the first systematic audit of ASR performance on real world clinical interview data spanning Kannada, Hindi, and Indian English, comparing leading models including Indic Whisper, Whisper, Sarvam, Google speech to text, Gemma3n, Omnilingual, Vaani, and Gemini. We evaluate transcription accuracy across languages, speakers, and demographic subgroups, with a particular focus on error patterns affecting patients vs. clinicians and gender based or intersectional disparities. Our results reveal substantial variability across models and languages, with some systems performing competitively on Indian English but failing on code mixed or vernacular speech. We also uncover systematic performance gaps tied to speaker role and gender, raising concerns about equitable deployment in clinical settings. By providing a comprehensive multilingual benchmark and fairness analysis, our work highlights the need for culturally and demographically inclusive ASR development for healthcare ecosystem in India.", "AI": {"tldr": "该研究首次系统评估了自动语音识别(ASR)在印度多语言临床环境中的性能，发现不同模型和语言间存在显著差异，存在基于说话者角色和性别的系统性性能差距，凸显了医疗ASR系统需要更具包容性的发展。", "motivation": "自动语音识别在临床记录中应用日益广泛，但其在印度多语言和人口多样化医疗环境中的可靠性尚未得到充分研究，需要评估ASR在不同语言、说话者和人口亚组中的转录准确性。", "method": "使用真实临床访谈数据，涵盖卡纳达语、印地语和印度英语，比较Indic Whisper、Whisper、Sarvam、Google语音转文本、Gemma3n、Omnilingual、Vaani和Gemini等领先模型的性能，特别关注患者与临床医生之间的错误模式以及基于性别或交叉性差异。", "result": "结果显示模型和语言之间存在显著差异，某些系统在印度英语上表现良好，但在代码混合或方言语音上表现不佳；发现了与说话者角色和性别相关的系统性性能差距。", "conclusion": "研究强调了印度医疗生态系统需要文化和人口统计学上更具包容性的ASR开发，通过提供全面的多语言基准和公平性分析，揭示了临床环境中公平部署的关切问题。"}}
{"id": "2512.11271", "pdf": "https://arxiv.org/pdf/2512.11271", "abs": "https://arxiv.org/abs/2512.11271", "authors": ["Yuxing Chen", "Basem Suleiman", "Qifan Chen"], "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning", "categories": ["cs.AI"], "comment": "4 pages, 3 figures", "summary": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.", "AI": {"tldr": "TriFlow是一个渐进式多智能体框架，通过检索、规划和治理三阶段流程，将开放式用户请求转化为满足空间、时间和预算约束的可执行行程计划，在效率和可行性方面显著优于现有方法。", "motivation": "现有基于LLM的智能体在行程规划中存在约束满足、工具协调和效率问题，经常产生不可行或成本高昂的计划，需要新的解决方案。", "method": "采用三阶段管道：检索阶段缩小搜索空间，规划阶段通过规则-LLM协作组装约束一致的行程，治理阶段进行有界迭代细化以确保全局可行性和个性化。", "result": "在TravelPlanner和TripTailor基准测试中分别达到91.1%和97%的最终通过率，相比当前SOTA方法运行效率提升超过10倍。", "conclusion": "TriFlow通过结构化推理和语言灵活性的统一，有效解决了现实世界行程规划的约束满足问题，展示了多智能体框架在复杂规划任务中的优势。"}}
{"id": "2512.10968", "pdf": "https://arxiv.org/pdf/2512.10968", "abs": "https://arxiv.org/abs/2512.10968", "authors": ["Alvin Nahabwe", "Sulaiman Kagumire", "Denis Musinguzi", "Bruno Beijuka", "Jonah Mubuuke Kyagaba", "Peter Nabende", "Andrew Katumba", "Joyce Nakatumba-Nabende"], "title": "Benchmarking Automatic Speech Recognition Models for African Languages", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "19 pages, 8 figures, Deep Learning Indiba, Proceedings of Machine Learning Research", "summary": "Automatic speech recognition (ASR) for African languages remains constrained by limited labeled data and the lack of systematic guidance on model selection, data scaling, and decoding strategies. Large pre-trained systems such as Whisper, XLS-R, MMS, and W2v-BERT have expanded access to ASR technology, but their comparative behavior in African low-resource contexts has not been studied in a unified and systematic way. In this work, we benchmark four state-of-the-art ASR models across 13 African languages, fine-tuning them on progressively larger subsets of transcribed data ranging from 1 to 400 hours. Beyond reporting error rates, we provide new insights into why models behave differently under varying conditions. We show that MMS and W2v-BERT are more data efficient in very low-resource regimes, XLS-R scales more effectively as additional data becomes available, and Whisper demonstrates advantages in mid-resource conditions. We also analyze where external language model decoding yields improvements and identify cases where it plateaus or introduces additional errors, depending on the alignment between acoustic and text resources. By highlighting the interaction between pre-training coverage, model architecture, dataset domain, and resource availability, this study offers practical and insights into the design of ASR systems for underrepresented languages.", "AI": {"tldr": "本研究系统评估了四种最先进的ASR模型在13种非洲语言上的表现，通过不同数据量微调实验，揭示了各模型在低资源条件下的不同优势和适用场景。", "motivation": "非洲语言的自动语音识别面临标注数据有限和缺乏系统指导的问题，现有大型预训练模型在非洲低资源环境中的比较行为尚未得到统一研究。", "method": "在13种非洲语言上对Whisper、XLS-R、MMS和W2v-BERT四种模型进行基准测试，使用1到400小时不等的转录数据逐步进行微调，并分析外部语言模型解码的效果。", "result": "发现MMS和W2v-BERT在极低资源条件下数据效率更高，XLS-R在数据增加时扩展性更好，Whisper在中资源条件下表现优势；外部语言模型解码的效果取决于声学和文本资源的对齐程度。", "conclusion": "研究揭示了预训练覆盖度、模型架构、数据集领域和资源可用性之间的相互作用，为 underrepresented 语言的ASR系统设计提供了实用见解。"}}
{"id": "2512.11323", "pdf": "https://arxiv.org/pdf/2512.11323", "abs": "https://arxiv.org/abs/2512.11323", "authors": ["Jianyi Zhang", "Ziyin Zhou", "Xu Ji", "Shizhao Liu", "Zhangchi Zhao"], "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving", "categories": ["cs.AI"], "comment": null, "summary": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.", "AI": {"tldr": "该论文提出了首个专门针对大型视觉语言模型（LVLMs）的CAPTCHA基准测试CAPTURE，包含4大类25子类CAPTCHA类型，覆盖31个供应商，用于全面评估LVLMs解决验证码的能力。", "motivation": "现有基于视觉验证码的基准测试存在局限性，无法全面覆盖所有CAPTCHA类型，且缺乏专门针对LVLMs的专用基准测试。", "method": "构建了一个包含4种主要CAPTCHA类型和25种子类型的大规模数据集，来自31个不同供应商，具有广泛的类别多样性和大规模数据量。", "result": "使用该基准测试评估现有LVLMs时，发现它们在解决CAPTCHAs方面表现不佳。", "conclusion": "CAPTURE基准填补了先前研究在数据全面性和标签针对性方面的空白，能够对LVLM性能进行多维度全面评估。"}}
{"id": "2512.10996", "pdf": "https://arxiv.org/pdf/2512.10996", "abs": "https://arxiv.org/abs/2512.10996", "authors": ["Seonok Kim"], "title": "MedBioRAG: Semantic Search and Retrieval-Augmented Generation with Large Language Models for Medical and Biological QA", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to ACL 2025. 9 pages, 4 figures, 5 tables (including 2 appendix tables)", "summary": "Recent advancements in retrieval-augmented generation (RAG) have significantly enhanced the ability of large language models (LLMs) to perform complex question-answering (QA) tasks. In this paper, we introduce MedBioRAG, a retrieval-augmented model designed to improve biomedical QA performance through a combination of semantic and lexical search, document retrieval, and supervised fine-tuning. MedBioRAG efficiently retrieves and ranks relevant biomedical documents, enabling precise and context-aware response generation. We evaluate MedBioRAG across text retrieval, close-ended QA, and long-form QA tasks using benchmark datasets such as NFCorpus, TREC-COVID, MedQA, PubMedQA, and BioASQ. Experimental results demonstrate that MedBioRAG outperforms previous state-of-the-art (SoTA) models and the GPT-4o base model in all evaluated tasks. Notably, our approach improves NDCG and MRR scores for document retrieval, while achieving higher accuracy in close-ended QA and ROUGE scores in long-form QA. Our findings highlight the effectiveness of semantic search-based retrieval and LLM fine-tuning in biomedical applications.", "AI": {"tldr": "MedBioRAG是一种检索增强生成模型，通过语义和词汇搜索、文档检索和监督微调相结合，显著提升生物医学问答性能，在多个基准测试中超越现有最优模型和GPT-4o。", "motivation": "现有的检索增强生成方法在复杂生物医学问答任务中仍有改进空间，需要更有效的文档检索和响应生成方法来提升生物医学QA性能。", "method": "结合语义搜索和词汇搜索进行文档检索，采用监督微调方法，在NFCorpus、TREC-COVID、MedQA、PubMedQA和BioASQ等基准数据集上进行评估。", "result": "在所有评估任务中超越之前的最优模型和GPT-4o基础模型，在文档检索的NDCG和MRR分数、闭端问答准确率以及长篇问答的ROUGE分数上均有显著提升。", "conclusion": "基于语义搜索的检索和LLM微调在生物医学应用中非常有效，MedBioRAG为生物医学问答任务提供了强大的解决方案。"}}
{"id": "2512.11421", "pdf": "https://arxiv.org/pdf/2512.11421", "abs": "https://arxiv.org/abs/2512.11421", "authors": ["Gonca Gürsun"], "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance", "categories": ["cs.AI"], "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.", "AI": {"tldr": "论文提出了一个基于LLM的任务完成框架，通过集成任务分析器、推理模块和生成模块，使AI代理能在强化学习环境中遵循明确的行为指导，实现可靠且可验证的多轮任务执行。", "motivation": "虽然大语言模型展现出强大的推理和生成能力，但在多轮任务中往往缺乏可靠性和可验证性，需要一种能够提供明确行为指导的框架。", "method": "框架包含三个组件：轻量级任务分析器（选择推理和生成策略）、推理模块（学习可验证的观察-行动映射）、生成模块（通过验证或确定性合成确保输出符合约束）。这些组件在环境交互中共同进化。", "result": "框架使得基于LLM的代理能够在定义明确的强化学习环境中表现出可信赖的行为，组件之间的协同进化提升了任务执行的可靠性。", "conclusion": "该框架成功解决了LLM在多轮任务中的可靠性和可验证性问题，通过结构化组件设计实现了行为指导的可信执行，为LLM在实际应用中的部署提供了重要支撑。"}}
{"id": "2512.10999", "pdf": "https://arxiv.org/pdf/2512.10999", "abs": "https://arxiv.org/abs/2512.10999", "authors": ["Xin Sun", "Zhongqi Chen", "Xing Zheng", "Qiang Liu", "Shu Wu", "Bowen Song", "Zilei Wang", "Weiqiang Wang", "Liang Wang"], "title": "KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \\textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \\textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.", "AI": {"tldr": "KBQA-R1是一个基于强化学习的知识库问答框架，通过多轮决策过程学习导航知识库，使用GRPO策略优化和RRS数据合成方法，在多个数据集上达到最先进性能", "motivation": "解决当前KBQA方法的两大问题：生成不验证模式存在的幻觉查询，以及僵化的模板式推理而缺乏真正环境理解", "method": "将KBQA视为多轮决策过程，使用强化学习（Group Relative Policy Optimization）基于执行反馈优化策略，并引入Referenced Rejection Sampling数据合成方法解决冷启动问题", "result": "在WebQSP、GrailQA和GraphQuestions数据集上实现了最先进的性能表现", "conclusion": "KBQA-R1成功将LLM推理基于可验证的执行过程，从文本模仿转向交互优化，有效解决了KBQA中的幻觉和僵化推理问题"}}
{"id": "2512.11426", "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance是一个在明确token成本和延迟预算约束下构建成本效益多智能体系统的框架，采用先骨干后拓扑的设计方法，相比现有方法在相同预算下性能提升显著。", "motivation": "现有的多智能体系统优化方法很少在明确的token成本和延迟预算约束下进行建模和优化，导致预算约束时成本效益不佳，需要一种新的框架来解决这一问题。", "method": "AgentBalance采用两阶段方法：1)骨干导向的智能体生成（LLM池构建、池选择、角色-骨干匹配）；2)自适应MAS拓扑生成（智能体表示学习、门控机制、延迟感知拓扑合成）。", "result": "在14个候选LLM骨干的基准测试中，AgentBalance在匹配的token成本和延迟预算下分别实现了10%和22%的性能提升，并在性能-预算曲线上表现出强大的AUC。", "conclusion": "AgentBalance是一个有效的预算感知多智能体系统构建框架，可作为现有MAS的插件使用，具有良好的泛化能力，适用于实际部署场景。"}}
{"id": "2512.11013", "pdf": "https://arxiv.org/pdf/2512.11013", "abs": "https://arxiv.org/abs/2512.11013", "authors": ["Pawel Batorski", "Paul Swoboda"], "title": "PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data", "categories": ["cs.CL"], "comment": null, "summary": "LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our method iteratively replaces/drops/keeps few-shot examples using Monte Carlo Shapley estimation of example utility. For faster execution, we use aggressive subsampling and a replay buffer for faster evaluations. Our method can be run using different compute time budgets. On a limited budget, we outperform existing automatic prompting methods on text simplification and GSM8K and obtain second best results on classification and summarization. With an extended, but still modest compute budget we set a new state of the art among automatic prompting methods on classification, simplification and GSM8K. Our results show that carefully constructed examples, rather than exhaustive instruction search, are the dominant lever for fast and data efficient prompt engineering. Our code is available at https://github.com/Batorskq/PIAST.", "AI": {"tldr": "提出基于蒙特卡洛Shapley估计的快速自动提示构建算法，通过迭代选择/替换/删除少样本示例来优化提示效果，在有限计算预算下在多个任务上优于现有方法", "motivation": "大型语言模型对提示设计敏感，但人工设计有效提示困难且需要精心设计少样本示例，需要自动化方法来提升提示工程效率", "method": "使用蒙特卡洛Shapley估计评估示例效用，通过迭代替换/删除/保留少样本示例来优化提示，采用激进子采样和重放缓冲区加速评估", "result": "在有限计算预算下，在文本简化和GSM8K任务上优于现有自动提示方法，在分类和摘要任务上获得第二好结果；扩展预算后在分类、简化和GSM8K任务上达到新的SOTA水平", "conclusion": "精心构建的示例而非详尽的指令搜索是快速高效提示工程的主要杠杆，证明了该方法在提升提示效果方面的有效性"}}
{"id": "2512.11433", "pdf": "https://arxiv.org/pdf/2512.11433", "abs": "https://arxiv.org/abs/2512.11433", "authors": ["Agustin Martin Picard", "Thibaut Boissin", "Varshini Subhash", "Rémi Cadène", "Thomas Fel"], "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline", "AI": {"tldr": "该论文揭示了XAI中流行的保真度评估指标（插入和删除）存在严重问题：基线选择会偏向某些归因方法，甚至导致同一模型在不同基线下得出矛盾的最优方法结论。作者提出了基线应满足的两个理想属性（信息移除和不产生过度分布外图像），发现现有基线都无法同时满足，并提出了一个新的模型依赖基线来改善这种权衡。", "motivation": "当前XAI领域广泛使用的归因方法评估指标（插入和删除）依赖于基线选择，但研究发现不同的基线选择会系统性地偏向某些归因方法，甚至导致评估结果相互矛盾，这严重影响了评估的公平性和可靠性。", "method": "作者首先分析了基线应具备的两个理想属性：(1)能够有效移除信息；(2)不产生过度分布外(OOD)的图像。然后测试了现有基线在这两个标准上的表现，发现存在权衡关系。最后利用特征可视化技术提出了一个新的模型依赖基线，旨在同时满足这两个属性。", "result": "研究发现所有测试的基线都无法同时满足信息移除和避免过度OOD这两个标准，存在明显的权衡关系。提出的新基线在权衡表现上优于现有基线，能够更好地移除信息同时避免产生过度分布外的图像。", "conclusion": "XAI评估中的基线选择问题至关重要，现有基线存在系统性偏差。作者提出的新基线通过特征可视化技术改善了信息移除与OOD控制之间的权衡，为更公平可靠的归因方法评估提供了改进方案。"}}
{"id": "2512.11074", "pdf": "https://arxiv.org/pdf/2512.11074", "abs": "https://arxiv.org/abs/2512.11074", "authors": ["Christopher Driggers-Ellis", "Detravious Brinkley", "Ray Chen", "Aashish Dhawan", "Daisy Zhe Wang", "Christan Grant"], "title": "MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MM"], "comment": "7 pages, 2 figures, 5 tables. Not published at any conference at this time", "summary": "Multi30k is frequently cited in the multimodal machine translation (MMT) literature, offering parallel text data for training and fine-tuning deep learning models. However, it is limited to four languages: Czech, English, French, and German. This restriction has led many researchers to focus their investigations only on these languages. As a result, MMT research on diverse languages has been stalled because the official Multi30k dataset only represents European languages in Latin scripts. Previous efforts to extend Multi30k exist, but the list of supported languages, represented language families, and scripts is still very short. To address these issues, we propose MultiScript30k, a new Multi30k dataset extension for global languages in various scripts, created by translating the English version of Multi30k (Multi30k-En) using NLLB200-3.3B. The dataset consists of over \\(30000\\) sentences and provides translations of all sentences in Multi30k-En into Ar, Es, Uk, Zh\\_Hans and Zh\\_Hant. Similarity analysis shows that Multi30k extension consistently achieves greater than \\(0.8\\) cosine similarity and symmetric KL divergence less than \\(0.000251\\) for all languages supported except Zh\\_Hant which is comparable to the previous Multi30k extensions ArEnMulti30k and Multi30k-Uk. COMETKiwi scores reveal mixed assessments of MultiScript30k as a translation of Multi30k-En in comparison to the related work. ArEnMulti30k scores nearly equal MultiScript30k-Ar, but Multi30k-Uk scores $6.4\\%$ greater than MultiScript30k-Uk per split.", "AI": {"tldr": "MultiScript30k是一个新的多语言数据集扩展，通过机器翻译将Multi30k英文版扩展到阿拉伯语、西班牙语、乌克兰语和简体繁体中文，解决了原数据集仅限于欧洲语言的问题。", "motivation": "原Multi30k数据集仅支持捷克语、英语、法语和德语四种欧洲语言，限制了多模态机器翻译研究在多样化语言上的发展，需要扩展到更多语言和文字体系。", "method": "使用NLLB200-3.3B机器翻译模型将Multi30k英文版翻译成阿拉伯语、西班牙语、乌克兰语、简体中文和繁体中文，创建包含30000+句子的新数据集。", "result": "相似性分析显示除繁体中文外，所有语言都达到大于0.8的余弦相似度和小于0.000251的对称KL散度。COMETKiwi评分显示与相关工作相比结果参差不齐，阿拉伯语版本表现相当，乌克兰语版本得分低6.4%。", "conclusion": "MultiScript30k成功扩展了Multi30k数据集的语言覆盖范围，为多模态机器翻译研究提供了更丰富的多语言资源，尽管在某些语言翻译质量上仍有改进空间。"}}
{"id": "2512.11463", "pdf": "https://arxiv.org/pdf/2512.11463", "abs": "https://arxiv.org/abs/2512.11463", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Taehyun Kim", "Eunhwan Park", "Jeesoo Lee", "Jeongdoo Lee", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Minsu Ha", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Minjae Kim", "Taewhan Kim", "Youngrok Kim", "Hyukjin Kweon", "Haesol Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Dongjoo Weon"], "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.", "AI": {"tldr": "Motif-2-12.7B-Reasoning是一个127亿参数的语言模型，通过创新的训练方法在复杂推理和长上下文理解方面达到与更大参数模型相当的性能，为开源社区提供了竞争性解决方案。", "motivation": "解决开源模型与专有前沿模型在复杂推理和长上下文理解方面的性能差距，以及推理适应中常见的模型崩溃和训练不稳定问题。", "method": "采用综合可复现的训练方案：1) 内存高效基础设施支持64K token上下文；2) 两阶段监督微调课程使用验证对齐的合成数据；3) 强化学习微调管道通过难度感知数据过滤和混合策略轨迹重用来稳定训练。", "result": "模型在数学、编程和智能体基准测试中表现出与参数数量显著更大的模型相当的性能。", "conclusion": "该研究为社区提供了一个具有竞争力的开源模型，并在实际计算约束下扩展推理能力提供了实用蓝图。"}}
{"id": "2512.11079", "pdf": "https://arxiv.org/pdf/2512.11079", "abs": "https://arxiv.org/abs/2512.11079", "authors": ["Alan Gerber", "Sam Cooperman"], "title": "Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment", "categories": ["cs.CL", "cs.CY", "stat.AP", "stat.OT"], "comment": "11 pages, 18 figures, https://github.com/Alanshnir/imessage-analyzer/blob/main/Research/NLP-iMessage-Analyzer%20Findings.pdf", "summary": "What is your messaging data used for? While many users do not often think about the information companies can gather based off of their messaging platform of choice, it is nonetheless important to consider as society increasingly relies on short-form electronic communication. While most companies keep their data closely guarded, inaccessible to users or potential hackers, Apple has opened a door to their walled-garden ecosystem, providing iMessage users on Mac with one file storing all their messages and attached metadata. With knowledge of this locally stored file, the question now becomes: What can our data do for us? In the creation of our iMessage text message analyzer, we set out to answer five main research questions focusing on topic modeling, response times, reluctance scoring, and sentiment analysis. This paper uses our exploratory data to show how these questions can be answered using our analyzer and its potential in future studies on iMessage data.", "AI": {"tldr": "本文介绍了针对iMessage本地存储数据的分析工具，通过主题建模、响应时间分析、不情愿评分和情感分析等方法，探索个人消息数据的潜在价值和应用前景。", "motivation": "随着社会对短形式电子通信的依赖增加，用户很少考虑消息平台收集的数据用途。苹果在Mac上提供了存储所有消息和元数据的本地文件，这为分析个人消息数据提供了机会。", "method": "开发了一个iMessage文本消息分析器，采用主题建模、响应时间分析、不情愿评分和情感分析等方法来分析本地存储的消息数据。", "result": "研究回答了五个主要研究问题，展示了如何通过分析器从iMessage数据中提取有价值的信息，证明了该工具在数据分析方面的有效性。", "conclusion": "该分析器不仅能够回答特定的研究问题，还为未来基于iMessage数据的研究提供了潜在应用价值，展示了个人消息数据在学术研究中的实用性。"}}
{"id": "2512.11469", "pdf": "https://arxiv.org/pdf/2512.11469", "abs": "https://arxiv.org/abs/2512.11469", "authors": ["Pranav Ramanathan", "Thomas Prellberg", "Matthew Lewis", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line", "categories": ["cs.AI"], "comment": null, "summary": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.", "AI": {"tldr": "本文首次系统比较了经典优化方法（ILP）与AI方法（PatternBoost和PPO）在No-Three-In-Line问题上的表现，ILP在19×19网格内获得最优解，PatternBoost在14×14网格内达到最优性能，PPO在10×10网格表现完美但在更大网格失效。", "motivation": "No-Three-In-Line作为组合几何中的著名问题，传统ILP方法面临指数级计算复杂度，需要探索机器学习方法作为替代方案来获得近似解。", "method": "使用整数线性规划（ILP）作为经典优化基准，首次应用PatternBoost变换器学习和PPO强化学习两种AI方法，系统比较它们在不同网格大小下的性能。", "result": "ILP在19×19网格内获得可证明的最优解；PatternBoost在14×14网格匹配最优性能，测试损失减少96%；PPO在10×10网格获得完美解但在11×11网格因约束违反而失败。", "conclusion": "经典优化方法对于精确解仍然必要，AI方法在较小实例上具有竞争力，混合方法为扩展到更大问题规模提供了最有前景的方向。"}}
{"id": "2512.11108", "pdf": "https://arxiv.org/pdf/2512.11108", "abs": "https://arxiv.org/abs/2512.11108", "authors": ["Jonathan Kamp", "Roos Bakker", "Dominique Blok"], "title": "Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same input may vary greatly due to underlying biases of different methods. Users may be aware of this issue and mistrust their utility, while unaware users may trust them inadequately. In this work, we delve beyond the superficial inconsistencies between attribution methods, structuring their biases through a model- and method-agnostic framework of three evaluation metrics. We systematically assess both the lexical and position bias (what and where in the input) for two transformers; first, in a controlled, pseudo-random classification task on artificial data; then, in a semi-controlled causal relation detection task on natural data. We find that lexical and position biases are structurally unbalanced in our model comparison, with models that score high on one type score low on the other. We also find signs that methods producing anomalous explanations are more likely to be biased themselves.", "AI": {"tldr": "该研究通过模型和方法无关的评估框架分析特征归因方法中的词汇和位置偏差，发现不同方法在相同输入上产生不一致的解释，且词汇偏差和位置偏差在模型间存在结构性不平衡。", "motivation": "不同特征归因方法在相同输入上可能产生差异很大的解释，这种不一致性导致用户可能不信任或过度信任这些解释工具，需要系统性地分析这些方法的偏差特性。", "method": "使用模型和方法无关的三指标评估框架，在人工数据的伪随机分类任务和自然数据的因果关系检测任务中，系统评估两种Transformer模型的词汇偏差和位置偏差。", "result": "发现词汇偏差和位置偏差在模型比较中结构性地不平衡（一个得分高时另一个得分低），且产生异常解释的方法更可能自身存在偏差。", "conclusion": "特征归因方法存在系统性偏差问题，需要更全面地评估解释方法的可靠性，不能仅依赖单一评估指标。"}}
{"id": "2512.11474", "pdf": "https://arxiv.org/pdf/2512.11474", "abs": "https://arxiv.org/abs/2512.11474", "authors": ["Kris A. G. Wyckhuys"], "title": "General-purpose AI models can generate actionable knowledge on agroecological crop protection", "categories": ["cs.AI", "cs.CY", "cs.IR"], "comment": "33 pages, 3 figures, 3 tables, 1 supplementary table", "summary": "Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.", "AI": {"tldr": "本研究评估了DeepSeek和ChatGPT在农业生态作物保护领域的科学知识生成能力，发现DeepSeek在文献覆盖、生物防治方案报告和数据一致性方面显著优于ChatGPT，但两者都存在幻觉和错误信息问题。", "motivation": "探索生成式AI在农业食品科学中的应用潜力，特别是在将科学知识转化为可操作信息方面，这一领域尚未得到充分研究。", "method": "针对9种全球性病虫害和杂草，评估了基于网络检索的DeepSeek和非网络检索的ChatGPT在事实准确性、数据一致性和知识广度方面的表现。", "result": "DeepSeek筛选的文献量比ChatGPT多4.8-49.7倍，报告的生物防治方案多1.6-2.4倍，效能估计高21.6%，实验室到田间数据一致性更好，但两者都存在幻觉问题。", "conclusion": "尽管存在局限性，大语言模型在严格人工监督下可能成为支持农场决策和激发科学创造力的强大工具。"}}
{"id": "2512.11110", "pdf": "https://arxiv.org/pdf/2512.11110", "abs": "https://arxiv.org/abs/2512.11110", "authors": ["Evren Ayberk Munis", "Deniz Yılmaz", "Arianna Muti", "Çağrı Toraman"], "title": "FIBER: A Multilingual Evaluation Resource for Factual Inference Bias", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models are widely used across domains, yet there are concerns about their factual reliability and biases. Factual knowledge probing offers a systematic means to evaluate these aspects. Most existing benchmarks focus on single-entity facts and monolingual data. We therefore present FIBER, a multilingual benchmark for evaluating factual knowledge in single- and multi-entity settings. The dataset includes sentence completion, question-answering, and object-count prediction tasks in English, Italian, and Turkish. Using FIBER, we examine whether the prompt language induces inference bias in entity selection and how large language models perform on multi-entity versus single-entity questions. The results indicate that the language of the prompt can influence the model's generated output, particularly for entities associated with the country corresponding to that language. However, this effect varies across different topics such that 31% of the topics exhibit factual inference bias score greater than 0.5. Moreover, the level of bias differs across languages such that Turkish prompts show higher bias compared to Italian in 83% of the topics, suggesting a language-dependent pattern. Our findings also show that models face greater difficulty when handling multi-entity questions than the single-entity questions. Model performance differs across both languages and model sizes. The highest mean average precision is achieved in English, while Turkish and Italian lead to noticeably lower scores. Larger models, including Llama-3.1-8B and Qwen-2.5-7B, show consistently better performance than smaller 3B-4B models.", "AI": {"tldr": "FIBER是一个多语言基准测试，用于评估大语言模型在单实体和多实体设置中的事实知识，发现提示语言会引发推理偏见，多实体问题比单实体问题更难，模型性能因语言和模型大小而异。", "motivation": "现有基准测试主要关注单实体事实和单语数据，需要系统评估大语言模型的事实可靠性和偏见问题。", "method": "创建FIBER多语言数据集（英语、意大利语、土耳其语），包含句子补全、问答和对象计数预测任务，分析提示语言对实体选择的偏见影响以及模型在单实体vs多实体问题上的表现。", "result": "提示语言会影响模型输出（特别是与语言对应国家相关的实体），31%的主题显示偏见分数大于0.5；土耳其提示比意大利语偏见更高（83%的主题）；多实体问题比单实体问题更难；英语表现最佳，大模型（8B/7B）优于小模型（3B-4B）。", "conclusion": "大语言模型存在语言相关的推理偏见和多实体处理困难，需要多语言评估基准来全面评估模型的事实可靠性。"}}
{"id": "2512.11505", "pdf": "https://arxiv.org/pdf/2512.11505", "abs": "https://arxiv.org/abs/2512.11505", "authors": ["Priyam Basu", "Yunfeng Zhang", "Vipul Raheja"], "title": "BAID: A Benchmark for Bias Assessment of AI Detectors", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at the workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks at AAAI 2026", "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.", "AI": {"tldr": "该研究提出了BAID评估框架，系统性地评估AI文本检测器在7大类社会语言因素上的偏见，发现现有检测器对少数群体文本存在一致的性能差异，特别是召回率偏低。", "motivation": "现有的AI生成文本检测器在教育和工作场景中广泛应用，但缺乏对社会语言因素偏见的系统性评估，之前的研究只发现了对英语学习者的孤立偏见案例。", "method": "提出BAID评估框架，构建包含20万样本的数据集，涵盖人口统计学、年龄、教育水平、方言、正式程度、政治倾向和主题等7个类别，并为每个样本生成保持内容但反映特定群体写作风格的合成版本。", "result": "评估了4个开源的最先进AI文本检测器，发现检测性能存在一致差异，特别是对代表性不足群体的文本召回率很低。", "conclusion": "该研究提供了一个可扩展、透明的AI检测器审计方法，强调在部署这些工具供公众使用前需要进行偏见感知评估。"}}
{"id": "2512.11192", "pdf": "https://arxiv.org/pdf/2512.11192", "abs": "https://arxiv.org/abs/2512.11192", "authors": ["Luca Foppiano", "Sotaro Takeshita", "Pedro Ortiz Suarez", "Ekaterina Borisova", "Raia Abu Ahmad", "Malte Ostendorff", "Fabio Barth", "Julian Moreno-Schneider", "Georg Rehm"], "title": "SciLaD: A Large-Scale, Transparent, Reproducible Dataset for Natural Scientific Language Processing", "categories": ["cs.CL"], "comment": "12 pages, 2 figures, 3 tables", "summary": "SciLaD is a novel, large-scale dataset of scientific language constructed entirely using open-source frameworks and publicly available data sources. It comprises a curated English split containing over 10 million scientific publications and a multilingual, unfiltered TEI XML split including more than 35 million publications. We also publish the extensible pipeline for generating SciLaD. The dataset construction and processing workflow demonstrates how open-source tools can enable large-scale, scientific data curation while maintaining high data quality. Finally, we pre-train a RoBERTa model on our dataset and evaluate it across a comprehensive set of benchmarks, achieving performance comparable to other scientific language models of similar size, validating the quality and utility of SciLaD. We publish the dataset and evaluation pipeline to promote reproducibility, transparency, and further research in natural scientific language processing and understanding including scholarly document processing.", "AI": {"tldr": "SciLaD是一个全新的大规模科学语言数据集，完全使用开源框架和公开数据源构建，包含超过1000万篇英文科学文献和3500万篇多语言文献，并提供了可扩展的数据生成流程和预训练模型验证。", "motivation": "构建一个完全基于开源工具和公开数据的大规模科学语言数据集，以促进科学语言处理和理解的透明度、可重现性研究。", "method": "使用开源框架构建数据生成流程，从公开数据源收集和整理科学文献，创建英文精选数据集和多语言TEI XML数据集，并在数据集上预训练RoBERTa模型。", "result": "成功构建了包含超过4500万篇科学文献的大规模数据集，预训练的RoBERTa模型在多个基准测试中表现与同类规模的科学语言模型相当。", "conclusion": "SciLaD数据集证明了开源工具能够实现大规模科学数据整理并保持高质量，数据集和评估流程的发布将促进科学语言处理领域的透明度、可重现性和进一步研究。"}}
{"id": "2512.11506", "pdf": "https://arxiv.org/pdf/2512.11506", "abs": "https://arxiv.org/abs/2512.11506", "authors": ["Georgios Kaoukis", "Ioannis Aris Koufopoulos", "Psaroudaki Eleni", "Danae Pla Karidi", "Evaggelia Pitoura", "George Papastefanatos", "Panayiotis Tsaparas"], "title": "EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection", "categories": ["cs.AI"], "comment": null, "summary": "As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.", "AI": {"tldr": "EmeraldMind是一个基于事实的框架，通过整合领域知识图谱和检索增强生成技术来自动检测企业绿色清洗行为，提供可验证的证据支持，相比通用大语言模型具有更高的准确性和解释质量。", "motivation": "随着AI和网络代理在决策中日益普及，需要设计智能系统来支持可持续发展并防范错误信息。企业绿色清洗（误导性环保声明）对环境进步构成重大挑战。", "method": "构建EmeraldGraph知识图谱，整合企业ESG报告中的多样化数据，采用检索增强生成技术进行声明评估，提供基于证据的透明分类和负责任的不确定判断。", "result": "在新构建的绿色清洗声明数据集上的实验表明，EmeraldMind实现了竞争性准确度、更大覆盖范围和更优的解释质量，无需微调或重新训练。", "conclusion": "EmeraldMind框架通过领域特定知识图谱有效解决了绿色清洗检测问题，提供了透明、可验证的评估方法，为可持续决策提供了可靠的技术支持。"}}
{"id": "2512.11258", "pdf": "https://arxiv.org/pdf/2512.11258", "abs": "https://arxiv.org/abs/2512.11258", "authors": ["Di Wu", "Ruiyu Fang", "Liting Jiang", "Shuangyong Song", "Xiaomeng Huang", "Shiquan Wang", "Zhongqiu Li", "Lingling Shi", "Mengjiao Bao", "Yongxiang Li", "Hao Huang"], "title": "Multi-Intent Spoken Language Understanding: Methods, Trends, and Challenges", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-intent spoken language understanding (SLU) involves two tasks: multiple intent detection and slot filling, which jointly handle utterances containing more than one intent. Owing to this characteristic, which closely reflects real-world applications, the task has attracted increasing research attention, and substantial progress has been achieved. However, there remains a lack of a comprehensive and systematic review of existing studies on multi-intent SLU. To this end, this paper presents a survey of recent advances in multi-intent SLU. We provide an in-depth overview of previous research from two perspectives: decoding paradigms and modeling approaches. On this basis, we further compare the performance of representative models and analyze their strengths and limitations. Finally, we discuss the current challenges and outline promising directions for future research. We hope this survey will offer valuable insights and serve as a useful reference for advancing research in multi-intent SLU.", "AI": {"tldr": "这是一篇关于多意图口语理解(SLU)的综述论文，系统回顾了该领域的研究进展，包括解码范式、建模方法、性能比较以及未来研究方向。", "motivation": "由于多意图SLU任务能够更好地反映现实应用场景且研究关注度日益增加，但缺乏全面系统的综述，因此需要对该领域进行系统梳理。", "method": "从两个视角对现有研究进行深入概述：解码范式和建模方法，并比较代表性模型的性能表现。", "result": "提供了多意图SLU领域的全面综述，分析了不同方法的优势和局限性，为研究者提供了有价值的参考。", "conclusion": "论文讨论了当前面临的挑战并指出了未来研究的潜在方向，希望为推进多意图SLU研究提供有益见解和参考。"}}
{"id": "2512.11544", "pdf": "https://arxiv.org/pdf/2512.11544", "abs": "https://arxiv.org/abs/2512.11544", "authors": ["Yuan Shen", "Xiaojun Wu", "Linghua Yu"], "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives", "categories": ["cs.AI"], "comment": "47 pages, 2 figures", "summary": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.", "AI": {"tldr": "本研究通过模拟真实临床场景，首次实证发现大型语言模型在处理医疗信息时会出现类似代谢功能障碍的功能衰退现象，提出了\"AI-MASLD\"新概念，警告当前LLMs在医疗应用中需在人类专家监督下作为辅助工具使用。", "motivation": "评估大型语言模型从含有噪声和冗余的患者主诉中提取核心医疗信息的能力，并验证其是否表现出类似代谢功能障碍相关脂肪肝病(MASLD)的功能衰退。", "method": "采用基于标准化医疗探针的横断面分析设计，选取GPT-4o、Gemini 2.5、DeepSeek 3.1和Qwen3-Max四个主流LLMs，使用包含5个核心维度20个医疗探针的评估系统模拟真实临床沟通环境，由两名独立临床医生进行双盲反向评分。", "result": "所有测试模型均表现出不同程度的功能缺陷，Qwen3-Max整体表现最佳，Gemini 2.5最差。在极端噪声条件下，大多数模型出现功能崩溃。GPT-4o在深静脉血栓继发肺栓塞风险评估中出现严重误判。", "conclusion": "首次实证确认LLMs在处理临床信息时表现出类似代谢功能障碍的特征，提出了\"AI-MASLD\"创新概念，为AI在医疗保健中的应用提供了重要安全警示，强调当前LLMs必须在人类专家监督下作为辅助工具使用。"}}
{"id": "2512.11261", "pdf": "https://arxiv.org/pdf/2512.11261", "abs": "https://arxiv.org/abs/2512.11261", "authors": ["Yun-Chung Liu", "Rui Yang", "Jonathan Chong Kai Liew", "Ziran Yin", "Henry Foote", "Christopher J. Lindsell", "Chuan Hong"], "title": "Leveraging LLMs for Title and Abstract Screening for Systematic Review: A Cost-Effective Dynamic Few-Shot Learning Approach", "categories": ["cs.CL"], "comment": "22 pages, 3 figures", "summary": "Systematic reviews are a key component of evidence-based medicine, playing a critical role in synthesizing existing research evidence and guiding clinical decisions. However, with the rapid growth of research publications, conducting systematic reviews has become increasingly burdensome, with title and abstract screening being one of the most time-consuming and resource-intensive steps. To mitigate this issue, we designed a two-stage dynamic few-shot learning (DFSL) approach aimed at improving the efficiency and performance of large language models (LLMs) in the title and abstract screening task. Specifically, this approach first uses a low-cost LLM for initial screening, then re-evaluates low-confidence instances using a high-performance LLM, thereby enhancing screening performance while controlling computational costs. We evaluated this approach across 10 systematic reviews, and the results demonstrate its strong generalizability and cost-effectiveness, with potential to reduce manual screening burden and accelerate the systematic review process in practical applications.", "AI": {"tldr": "提出一种两阶段动态少样本学习方法，使用低成本LLM进行初步筛选，再用高性能LLM重新评估低置信度实例，以提高系统综述标题和摘要筛选效率并控制计算成本。", "motivation": "系统综述在循证医学中至关重要，但研究文献快速增长使得标题和摘要筛选变得极其耗时耗力，需要提高效率。", "method": "设计两阶段动态少样本学习(DFSL)方法：第一阶段使用低成本大语言模型进行初步筛选，第二阶段对低置信度实例使用高性能大语言模型重新评估。", "result": "在10个系统综述上评估，结果显示该方法具有良好的泛化能力和成本效益。", "conclusion": "该方法能有效减少人工筛选负担，加速系统综述流程，具有实际应用潜力。"}}
{"id": "2512.11588", "pdf": "https://arxiv.org/pdf/2512.11588", "abs": "https://arxiv.org/abs/2512.11588", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Jeyan Thiyagalingam", "Juri Papay", "Armstrong Foundjem", "Piotr Luszczek", "Murali Emani", "Shirley V. Moore", "Vijay Janapa Reddi", "Matthew D. Sinclair", "Sebastian Lobentanzer", "Sujata Goswami", "Benjamin Hawks", "Marco Colombo", "Nhan Tran", "Christine R. Kirkpatrick", "Abdulkareem Alsudais", "Gregg Barrett", "Tianhao Li", "Kirsten Morehouse", "Shivaram Venkataraman", "Rutwik Jain", "Kartik Mathur", "Victor Lu", "Tejinder Singh", "Khojasteh Z. Mirza", "Kongtao Chen", "Sasidhar Kunapuli", "Gavin Farrell", "Renato Umeton", "Geoffrey C. Fox"], "title": "AI Benchmark Democratization and Carpentry", "categories": ["cs.AI"], "comment": "43 pages, 2 figures, 7 tables", "summary": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.", "AI": {"tldr": "论文提出AI基准测试需要从静态转向动态适应性框架，以解决模型记忆、资源需求高、硬件限制等问题，强调需要AI基准木工技能教育和社区努力来确保评估与AI发展同步。", "motivation": "当前AI基准测试面临复杂性和快速演变的挑战，静态基准容易被大语言模型记忆，导致基准结果与实际性能存在差距，需要动态适应性框架来对齐科学评估与部署风险。", "method": "基于MLCommons、教育项目和DOE万亿参数联盟等经验，提出建立动态基准测试框架，包含演化模型、更新数据和异构平台，同时保持透明度、可重现性和可解释性。", "result": "识别了高资源需求、专业硬件访问限制、基准设计专业知识缺乏等关键障碍，指出当前基准过于强调顶级硬件峰值性能，对多样化实际场景指导有限。", "conclusion": "基准测试必须动态化和民主化，通过技术创新和系统教育建立持续的基准设计和使用专业知识，支持应用相关比较，确保评估跟上AI发展步伐，促进负责任、可重现和可访问的AI部署。"}}
{"id": "2512.11277", "pdf": "https://arxiv.org/pdf/2512.11277", "abs": "https://arxiv.org/abs/2512.11277", "authors": ["Mrinal Rawat", "Arkajyoti Chakraborty", "Neha Gupta", "Roberto Pieraccini"], "title": "When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outside the training domain. Recent reasoning-focused models such as o1 and R1 have demonstrated consistent gains over their non-reasoning counterparts, highlighting the importance of reasoning for improved generalization and reliability. However, collecting high-quality reasoning traces for SFT remains challenging -- annotations are costly, subjective, and difficult to scale. To address this limitation, we leverage Reinforcement Learning (RL) to enable models to learn reasoning strategies directly from task outcomes. We propose a pipeline in which LLMs generate reasoning steps that guide both the invocation of tools (e.g., function calls) and the final answer generation for conversational agents. Our method employs Group Relative Policy Optimization (GRPO) with rewards designed around tool accuracy and answer correctness, allowing the model to iteratively refine its reasoning and actions. Experimental results demonstrate that our approach improves both the quality of reasoning and the precision of tool invocations, achieving a 1.5% relative improvement over the SFT model (trained without explicit thinking) and a 40% gain compared to the base of the vanilla Qwen3-1.7B model. These findings demonstrate the promise of unifying reasoning and action learning through RL to build more capable and generalizable conversational agents.", "AI": {"tldr": "使用强化学习替代监督微调来提升语言模型的推理能力，通过工具调用准确性和答案正确性奖励来优化推理策略，在推理质量和工具调用精度上获得显著提升", "motivation": "监督微调在数据分布变化时泛化能力有限，且高质量推理标注成本高、主观性强、难以扩展，需要更有效的推理学习方法", "method": "提出基于强化学习的流水线方法，使用Group Relative Policy Optimization (GRPO)，通过工具准确性和答案正确性奖励来训练模型学习推理策略", "result": "相比无显式推理的SFT模型获得1.5%相对提升，相比基础Qwen3-1.7B模型提升40%，在推理质量和工具调用精度上均有改进", "conclusion": "通过强化学习统一推理和动作学习，可以构建更强大和可泛化的对话智能体，展示了RL在提升模型推理能力方面的潜力"}}
{"id": "2512.11653", "pdf": "https://arxiv.org/pdf/2512.11653", "abs": "https://arxiv.org/abs/2512.11653", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Causal Inference in Energy Demand Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.", "AI": {"tldr": "该论文提出了一个结构因果模型来解释能源需求与天气、日历因素之间的因果关系，并基于此构建了贝叶斯预测模型，在测试集上取得了3.84%的MAPE，表现出色。", "motivation": "能源需求预测对电网运营商和工业用户至关重要，传统相关分析方法无法充分处理天气条件、日历信息等多因素间的因果依赖关系，需要更深入的因果分析。", "method": "首先建立结构因果模型分析变量间的因果关系，然后利用获得的因果洞察作为先验知识构建贝叶斯预测模型。", "result": "模型在测试集上达到3.84%的MAPE，跨两年数据的交叉验证平均MAPE为3.88%，表现出优异的预测精度和鲁棒性。因果分析发现能源需求对温度波动的响应具有季节依赖性，冬季方差较低。", "conclusion": "结构因果模型能有效揭示能源需求的影响机制，基于因果洞察的贝叶斯模型在能源需求预测中实现了state-of-the-art性能，为实际应用提供了可靠工具。"}}
{"id": "2512.11280", "pdf": "https://arxiv.org/pdf/2512.11280", "abs": "https://arxiv.org/abs/2512.11280", "authors": ["Kuan-Wei Lu", "Ding-Yong Hong", "Pangfeng Liu"], "title": "AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable performance across a wide range of tasks, but their increasing parameter sizes significantly slow down inference. Speculative decoding mitigates this issue by leveraging a smaller draft model to predict candidate tokens, which are then verified by a larger target model. However, existing approaches often require additional training, extensive hyperparameter tuning, or prior analysis of models and tasks before deployment. In this paper, we propose Adaptive Speculative Decoding (AdaSD), a hyperparameter-free decoding scheme that dynamically adjusts generation length and acceptance criteria during inference. AdaSD introduces two adaptive thresholds: one to determine when to stop candidate token generation and another to decide token acceptance, both updated in real time based on token entropy and Jensen-Shannon distance. This approach eliminates the need for pre-analysis or fine-tuning and is compatible with off-the-shelf models. Experiments on benchmark datasets demonstrate that AdaSD achieves up to 49\\% speedup over standard speculative decoding while limiting accuracy degradation to under 2\\%, making it a practical solution for efficient and adaptive LLM inference.", "AI": {"tldr": "AdaSD是一种无需超参数调优的自适应推测解码方法，通过动态调整生成长度和接受标准，在保持精度的同时显著提升大语言模型推理速度", "motivation": "现有推测解码方法需要额外训练、超参数调优或预分析，限制了实际部署的便捷性", "method": "提出自适应阈值机制，基于token熵和Jensen-Shannon距离实时调整候选token生成停止时机和接受标准", "result": "在基准测试中实现最高49%的加速，精度下降控制在2%以内", "conclusion": "AdaSD提供了一种实用、自适应的LLM高效推理解决方案，兼容现成模型且无需预分析或微调"}}
{"id": "2512.11682", "pdf": "https://arxiv.org/pdf/2512.11682", "abs": "https://arxiv.org/abs/2512.11682", "authors": ["Tim Cofala", "Christian Kalfar", "Jingge Xiao", "Johanna Schrader", "Michelle Tang", "Wolfgang Nejdl"], "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition", "categories": ["cs.AI", "cs.LG"], "comment": "7 pages, 3 figures", "summary": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.", "AI": {"tldr": "TxAgent是一种基于迭代检索增强生成(RAG)的医疗AI代理，使用微调Llama-3.1-8B模型动态调用生物医学工具套件，在CURE-Bench挑战赛中获得卓越科学奖，展示了改进工具检索策略带来的性能提升。", "motivation": "临床医疗治疗决策是高风险领域，需要基于可靠生物医学知识的强大多步推理能力。传统通用RAG系统难以满足医疗应用严格的安全约束要求。", "method": "采用微调Llama-3.1-8B模型，通过迭代检索增强生成(RAG)方法动态生成和执行函数调用，整合FDA Drug API、OpenTargets和Monarch等生物医学工具资源。", "result": "在CURE-Bench NeurIPS 2025挑战赛中获奖，证明了改进工具检索策略对模型性能的提升，评估了推理痕迹和工具调用序列的准确性。", "conclusion": "医疗AI代理需要将标记级推理和工具使用行为作为显式监督信号进行评估，检索质量对函数调用和整体模型性能具有重要影响。"}}
{"id": "2512.11282", "pdf": "https://arxiv.org/pdf/2512.11282", "abs": "https://arxiv.org/abs/2512.11282", "authors": ["Qingsen Ma", "Dianyun Wang", "Ran Jing", "Yujun Sun", "Zhenbo Xu"], "title": "CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models often hallucinate when processing long and noisy retrieval contexts because they rely on spurious correlations rather than genuine causal relationships. We propose CIP, a lightweight and plug-and-play causal prompting framework that mitigates hallucinations at the input stage. CIP constructs a causal relation sequence among entities, actions, and events and injects it into the prompt to guide reasoning toward causally relevant evidence. Through causal intervention and counterfactual reasoning, CIP suppresses non causal reasoning paths, improving factual grounding and interpretability. Experiments across seven mainstream language models, including GPT-4o, Gemini 2.0 Flash, and Llama 3.1, show that CIP consistently enhances reasoning quality and reliability, achieving 2.6 points improvement in Attributable Rate, 0.38 improvement in Causal Consistency Score, and a fourfold increase in effective information density. API level profiling further shows that CIP accelerates contextual understanding and reduces end to end response latency by up to 55.1 percent. These results suggest that causal reasoning may serve as a promising paradigm for improving the explainability, stability, and efficiency of large language models.", "AI": {"tldr": "CIP是一个轻量级即插即用的因果提示框架，通过在输入阶段构建实体、动作和事件之间的因果序列来减少大语言模型在处理长文本时的幻觉问题，提高推理质量和可靠性。", "motivation": "大语言模型在处理长而嘈杂的检索上下文时经常产生幻觉，因为它们依赖于虚假相关性而非真正的因果关系。", "method": "CIP框架通过构建因果序列并将其注入提示中，利用因果干预和反事实推理来抑制非因果推理路径。", "result": "在7个主流语言模型上测试显示，CIP将可归因率提高2.6分，因果一致性得分提高0.38，有效信息密度提高4倍，端到端响应延迟降低55.1%。", "conclusion": "因果推理可能是提高大语言模型可解释性、稳定性和效率的有前景范式。"}}
{"id": "2512.11297", "pdf": "https://arxiv.org/pdf/2512.11297", "abs": "https://arxiv.org/abs/2512.11297", "authors": ["Shogo Fujita", "Yuji Naraki", "Yiqing Zhu", "Shinsuke Mori"], "title": "LegalRikai: Open Benchmark -- A Benchmark for Complex Japanese Corporate Legal Tasks", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces LegalRikai: Open Benchmark, a new benchmark comprising four complex tasks that emulate Japanese corporate legal practices. The benchmark was created by legal professionals under the supervision of an attorney. This benchmark has 100 samples that require long-form, structured outputs, and we evaluated them against multiple practical criteria. We conducted both human and automated evaluations using leading LLMs, including GPT-5, Gemini 2.5 Pro, and Claude Opus 4.1. Our human evaluation revealed that abstract instructions prompted unnecessary modifications, highlighting model weaknesses in document-level editing that were missed by conventional short-text tasks. Furthermore, our analysis reveals that automated evaluation aligns well with human judgment on criteria with clear linguistic grounding, and assessing structural consistency remains a challenge. The result demonstrates the utility of automated evaluation as a screening tool when expert availability is limited. We propose a dataset evaluation framework to promote more practice-oriented research in the legal domain.", "AI": {"tldr": "LegalRikai是一个由法律专业人士创建的日语企业法律实践基准测试，包含4个复杂任务和100个长格式结构化输出样本，通过人类和自动评估发现抽象指令会导致模型不必要的修改，自动评估在语言明确的标准上与人类判断一致，但结构一致性评估仍是挑战。", "motivation": "创建更贴近实际法律实践的标准测试基准，以评估大语言模型在企业法律领域的实际应用能力，弥补传统短文本任务的不足。", "method": "由律师监督的法律专业人士创建包含4个复杂任务的基准测试，包含100个长格式结构化输出样本，使用GPT-5、Gemini 2.5 Pro和Claude Opus 4.1等领先LLM进行人类和自动评估，采用多维度实践标准。", "result": "人类评估显示抽象指令会引发不必要的修改，揭示了模型在文档级别编辑方面的弱点；自动评估在语言明确的标准上与人类判断高度一致，但结构一致性评估仍是技术挑战；证明了自动评估作为专家资源有限时的筛选工具的有效性。", "conclusion": "提出了一个数据集评估框架，旨在促进法律领域更注重实践导向的研究，自动评估可以作为有效的初步筛选工具，但在结构一致性方面仍需进一步研究改进。"}}
{"id": "2512.11303", "pdf": "https://arxiv.org/pdf/2512.11303", "abs": "https://arxiv.org/abs/2512.11303", "authors": ["Jiarun Liu", "Shiyue Xu", "Yang Li", "Shangkun Liu", "Yongli Yu", "Peng Cao"], "title": "Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.", "AI": {"tldr": "SMITH是一个统一的认知架构，通过分层内存组织和课程学习策略，将动态工具创建与跨任务经验共享相结合，在GAIA基准测试中达到81.8%的准确率，优于现有方法。", "motivation": "解决大语言模型代理在适应新任务时面临的工具可用性有限和经验重用困难的问题，现有方法要么依赖预定义工具覆盖范围有限，要么从头构建工具而不利用过往经验。", "method": "提出SMITH架构，将代理内存组织为程序性、语义性和情景性三个层次，通过受控沙箱环境中的迭代代码生成来形式化工具创建，并通过语义相似性匹配的情景记忆检索实现经验共享。", "result": "在GAIA基准测试中取得81.8%的Pass@1准确率，显著优于Alita（75.2%）和Memento（70.9%）等最先进基线方法。", "conclusion": "SMITH为构建真正自适应代理奠定了基础，通过工具创建和经验积累的原则性集成，使代理能够持续进化其能力。"}}
{"id": "2512.11366", "pdf": "https://arxiv.org/pdf/2512.11366", "abs": "https://arxiv.org/abs/2512.11366", "authors": ["Shreya Shukla", "Aditya Sriram", "Milinda Kuppur Narayanaswamy", "Hiteshi Jain"], "title": "qa-FLoRA: Data-free query-adaptive Fusion of LoRAs for LLMs", "categories": ["cs.CL"], "comment": "Accepted at AAAI 2026 (Main Technical Track)", "summary": "The deployment of large language models for specialized tasks often requires domain-specific parameter-efficient finetuning through Low-Rank Adaptation (LoRA) modules. However, effectively fusing these adapters to handle complex, multi-domain composite queries remains a critical challenge. Existing LoRA fusion approaches either use static weights, which assign equal relevance to each participating LoRA, or require data-intensive supervised training for every possible LoRA combination to obtain respective optimal fusion weights. We propose qa-FLoRA, a novel query-adaptive data-and-training-free method for LoRA fusion that dynamically computes layer-level fusion weights by measuring distributional divergence between the base model and respective adapters. Our approach eliminates the need for composite training data or domain-representative samples, making it readily applicable to existing adapter collections. Extensive experiments across nine multilingual composite tasks spanning mathematics, coding, and medical domains, show that qa-FLoRA outperforms static fusion by ~5% with LLaMA-2 and ~6% with LLaMA-3, and the training-free baselines by ~7% with LLaMA-2 and ~10% with LLaMA-3, while significantly closing the gap with supervised baselines. Further, layer-level analysis of our fusion weights reveals interpretable fusion patterns, demonstrating the effectiveness of our approach for robust multi-domain adaptation.", "AI": {"tldr": "qa-FLoRA是一种无需数据和训练、查询自适应的LoRA融合方法，通过测量基础模型与适配器之间的分布差异动态计算层级融合权重，在多领域复合任务中显著优于静态融合和无训练基线方法", "motivation": "现有LoRA融合方法要么使用静态权重（对所有适配器同等重要），要么需要为每个可能的LoRA组合进行数据密集的监督训练来获得最优融合权重，这限制了在多领域复合查询中的有效应用", "method": "提出qa-FLoRA方法，通过测量基础模型与各适配器之间的分布差异，动态计算层级融合权重，无需复合训练数据或领域代表性样本", "result": "在9个多语言复合任务（数学、编程、医疗领域）的实验中，qa-FLoRA比静态融合方法提升约5-6%，比无训练基线方法提升约7-10%，显著缩小了与监督基线的差距", "conclusion": "qa-FLoRA提供了一种有效且可解释的多领域适配方法，无需额外训练数据即可实现鲁棒的多领域适应，层级的融合权重分析揭示了可解释的融合模式"}}
{"id": "2512.11374", "pdf": "https://arxiv.org/pdf/2512.11374", "abs": "https://arxiv.org/abs/2512.11374", "authors": ["Tomáš Koref", "Lena Held", "Mahammad Namazov", "Harun Kumru", "Yassine Thlija", "Christoph Burchard", "Ivan Habernal"], "title": "Mining Legal Arguments to Study Judicial Formalism", "categories": ["cs.CL", "cs.CY"], "comment": "pre-print under review", "summary": "Courts must justify their decisions, but systematically analyzing judicial reasoning at scale remains difficult. This study refutes claims about formalistic judging in Central and Eastern Europe (CEE) by developing automated methods to detect and classify judicial reasoning in Czech Supreme Courts' decisions using state-of-the-art natural language processing methods. We create the MADON dataset of 272 decisions from two Czech Supreme Courts with expert annotations of 9,183 paragraphs with eight argument types and holistic formalism labels for supervised training and evaluation. Using a corpus of 300k Czech court decisions, we adapt transformer LLMs for Czech legal domain by continued pretraining and experiment with methods to address dataset imbalance including asymmetric loss and class weighting. The best models successfully detect argumentative paragraphs (82.6\\% macro-F1), classify traditional types of legal argument (77.5\\% macro-F1), and classify decisions as formalistic/non-formalistic (83.2\\% macro-F1). Our three-stage pipeline combining ModernBERT, Llama 3.1, and traditional feature-based machine learning achieves promising results for decision classification while reducing computational costs and increasing explainability. Empirically, we challenge prevailing narratives about CEE formalism. This work shows that legal argument mining enables reliable judicial philosophy classification and shows the potential of legal argument mining for other important tasks in computational legal studies. Our methodology is easily replicable across jurisdictions, and our entire pipeline, datasets, guidelines, models, and source codes are available at https://github.com/trusthlt/madon.", "AI": {"tldr": "本研究开发了自动化方法来检测和分类捷克最高法院判决中的司法推理，使用最先进的自然语言处理技术，挑战了关于中东欧形式主义裁判的普遍观点。", "motivation": "系统性地大规模分析司法推理仍然困难，需要反驳关于中东欧形式主义裁判的说法，并开发可靠的司法哲学分类方法。", "method": "创建MADON数据集（272个判决，9,183个段落标注），使用30万捷克法院判决语料库，通过持续预训练适配transformer LLMs，采用不对称损失和类别加权处理数据不平衡，构建三阶段流水线（ModernBERT、Llama 3.1和传统机器学习）。", "result": "最佳模型成功检测论证段落（82.6% macro-F1）、分类传统法律论证类型（77.5% macro-F1）、分类形式主义/非形式主义判决（83.2% macro-F1），三阶段流水线在降低计算成本和提高可解释性方面表现良好。", "conclusion": "法律论证挖掘能够实现可靠的司法哲学分类，展示了在计算法学研究中其他重要任务的潜力，方法可在不同司法管辖区复制，所有资源已开源。"}}
{"id": "2512.11388", "pdf": "https://arxiv.org/pdf/2512.11388", "abs": "https://arxiv.org/abs/2512.11388", "authors": ["Felipe Ribeiro Fujita de Mello", "Hideyuki Takada"], "title": "Improving Translation Quality by Selecting Better Data for LLM Fine-Tuning: A Comparative Analysis", "categories": ["cs.CL"], "comment": "To appear at IEEE Big Data 2025", "summary": "We investigated the impact of data selection on machine translation fine-tuning for open LLMs. Using Japanese-English corpora, we compare five selectors: TF-IDF, COMET Kiwi, QuRate, FD-Score, and random selection, under controlled training conditions. We observed that semantic selectors consistently outperform lexical and geometry-based heuristics, and that even when the selected data differ by less than 3%, the impact on model performance is substantial, underscoring the sensitivity of fine-tuning to data quality.", "AI": {"tldr": "论文研究数据选择对大型语言模型机器翻译微调的影响，发现语义选择器优于词汇和几何启发式方法，即使数据差异小于3%也会显著影响模型性能", "motivation": "探究不同数据选择方法对LLM机器翻译微调效果的影响，特别是在日语-英语翻译任务中", "method": "使用日语-英语语料库，在受控训练条件下比较TF-IDF、COMET Kiwi、QuRate、FD-Score和随机选择五种数据选择方法", "result": "语义选择器持续优于词汇和几何启发式方法，即使选定数据差异小于3%，对模型性能的影响也很显著", "conclusion": "微调过程对数据质量非常敏感，数据选择策略对机器翻译性能有实质性影响"}}
{"id": "2512.11399", "pdf": "https://arxiv.org/pdf/2512.11399", "abs": "https://arxiv.org/abs/2512.11399", "authors": ["Galann Pennec", "Zhengyuan Liu", "Nicholas Asher", "Philippe Muller", "Nancy F. Chen"], "title": "Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) are able to process increasingly longer videos. Yet, important visual information is easily lost throughout the entire context and missed by VLMs. Also, it is important to design tools that enable cost-effective analysis of lengthy video content. In this paper, we propose a clip selection method that targets key video moments to be included in a multimodal summary. We divide the video into short clips and generate compact visual descriptions of each using a lightweight video captioning model. These are then passed to a large language model (LLM), which selects the K clips containing the most relevant visual information for a multimodal summary. We evaluate our approach on reference clips for the task, automatically derived from full human-annotated screenplays and summaries in the MovieSum dataset. We further show that these reference clips (less than 6% of the movie) are sufficient to build a complete multimodal summary of the movies in MovieSum. Using our clip selection method, we achieve a summarization performance close to that of these reference clips while capturing substantially more relevant video information than random clip selection. Importantly, we maintain low computational cost by relying on a lightweight captioning model.", "AI": {"tldr": "提出一种基于轻量级视频描述模型和大型语言模型的视频片段选择方法，用于构建多模态摘要，在保持低计算成本的同时有效捕捉关键视频信息。", "motivation": "视觉语言模型在处理长视频时容易丢失重要视觉信息，且需要设计成本效益高的长视频分析工具。", "method": "将视频分割成短片段，使用轻量级视频描述模型生成每个片段的紧凑视觉描述，然后通过大型语言模型选择K个最相关的片段用于多模态摘要。", "result": "在MovieSum数据集上，该方法达到了接近人工标注参考片段的摘要性能，比随机片段选择捕获了更多相关信息，且仅需不到6%的电影内容。", "conclusion": "该方法能够以低计算成本有效选择关键视频片段，为长视频的多模态摘要提供了实用且高效的解决方案。"}}
{"id": "2512.11509", "pdf": "https://arxiv.org/pdf/2512.11509", "abs": "https://arxiv.org/abs/2512.11509", "authors": ["Mohor Banerjee", "Nadya Yuki Wangsajaya", "Syed Ali Redha Alsagoff", "Min Sen Tan", "Zachary Choy Kit Chun", "Alvin Chan Guo Wei"], "title": "Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.", "AI": {"tldr": "本研究探讨了三种减少大语言模型幻觉的方法（CoVe、DoLa、RAG）对创造力的影响，发现在发散性创造力方面，CoVe有增强作用，DoLa有抑制作用，RAG影响最小，为科学应用中平衡事实准确性与创造性提供了指导。", "motivation": "大语言模型虽然具有强大的自然语言理解和推理能力，但存在幻觉问题（生成事实错误内容）。虽然已有许多减少幻觉的方法，但这些方法对创造力的影响尚未被研究，这在需要事实准确性和创造性假设生成的AI辅助科学发现中尤为关键。", "method": "研究评估了三种幻觉减少技术：Chain of Verification (CoVe)、Decoding by Contrasting Layers (DoLa) 和 Retrieval-Augmented Generation (RAG)。在多个模型家族（LLaMA、Qwen、Mistral）的不同规模（1B-70B参数）上，使用两个创造力基准（NeoCoder和CS4）进行评估。", "result": "研究发现这些方法对发散性创造力有相反的影响：CoVe增强发散思维，DoLa抑制发散思维，RAG影响最小。", "conclusion": "研究结果为科学应用中选择适当的幻觉减少方法提供了指导，在事实准确性和创造性探索之间的平衡至关重要的情况下尤其有价值。"}}
{"id": "2512.11437", "pdf": "https://arxiv.org/pdf/2512.11437", "abs": "https://arxiv.org/abs/2512.11437", "authors": ["Akash Ghosh", "Srivarshinee Sridhar", "Raghav Kaushik Ravi", "Muhsin Muhsin", "Sriparna Saha", "Chirag Agarwal"], "title": "CLINIC: Evaluating Multilingual Trustworthiness in Language Models for Healthcare", "categories": ["cs.CL"], "comment": "49 pages, 31 figures", "summary": "Integrating language models (LMs) in healthcare systems holds great promise for improving medical workflows and decision-making. However, a critical barrier to their real-world adoption is the lack of reliable evaluation of their trustworthiness, especially in multilingual healthcare settings. Existing LMs are predominantly trained in high-resource languages, making them ill-equipped to handle the complexity and diversity of healthcare queries in mid- and low-resource languages, posing significant challenges for deploying them in global healthcare contexts where linguistic diversity is key. In this work, we present CLINIC, a Comprehensive Multilingual Benchmark to evaluate the trustworthiness of language models in healthcare. CLINIC systematically benchmarks LMs across five key dimensions of trustworthiness: truthfulness, fairness, safety, robustness, and privacy, operationalized through 18 diverse tasks, spanning 15 languages (covering all the major continents), and encompassing a wide array of critical healthcare topics like disease conditions, preventive actions, diagnostic tests, treatments, surgeries, and medications. Our extensive evaluation reveals that LMs struggle with factual correctness, demonstrate bias across demographic and linguistic groups, and are susceptible to privacy breaches and adversarial attacks. By highlighting these shortcomings, CLINIC lays the foundation for enhancing the global reach and safety of LMs in healthcare across diverse languages.", "AI": {"tldr": "CLINIC是一个多语言医疗基准测试，用于评估语言模型在医疗领域的可信度，涵盖5个维度18个任务15种语言，发现现有模型存在事实错误、偏见、隐私漏洞等问题。", "motivation": "当前语言模型主要基于高资源语言训练，无法有效处理中低资源语言的医疗查询，缺乏在多语言医疗环境中可信度的系统评估，阻碍了其在全球医疗环境中的实际应用。", "method": "开发CLINIC基准测试，系统评估语言模型在5个可信度维度（真实性、公平性、安全性、鲁棒性、隐私性），通过18个多样化任务覆盖15种语言和多个医疗主题。", "result": "评估显示语言模型在事实正确性方面表现不佳，在不同人口统计和语言群体中存在偏见，容易受到隐私泄露和对抗攻击的影响。", "conclusion": "CLINIC基准为提升语言模型在全球多语言医疗环境中的可及性和安全性奠定了基础，揭示了现有模型的局限性并指明了改进方向。"}}
{"id": "2512.11614", "pdf": "https://arxiv.org/pdf/2512.11614", "abs": "https://arxiv.org/abs/2512.11614", "authors": ["Björn Deiseroth", "Max Henning Höth", "Kristian Kersting", "Letitia Parcalabescu"], "title": "Bounding Hallucinations: Information-Theoretic Guarantees for RAG Systems via Merlin-Arthur Protocols", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "34 pages, 19 figures", "summary": "Retrieval-augmented generation (RAG) models rely on retrieved evidence to guide large language model (LLM) generators, yet current systems treat retrieval as a weak heuristic rather than verifiable evidence. As a result, LLMs answer without support, hallucinate under incomplete or misleading context, and rely on spurious evidence. We introduce a training framework that treats the entire RAG pipeline -- both the retriever and the generator -- as an interactive proof system via an adaptation of the Merlin-Arthur (M/A) protocol. Arthur (the generator LLM) trains on questions of unkown provenance: Merlin provides helpful evidence, while Morgana injects adversarial, misleading context. Both use a linear-time XAI method to identify and modify the evidence most influential to Arthur. Consequently, Arthur learns to (i) answer when the context support the answer, (ii) reject when evidence is insufficient, and (iii) rely on the specific context spans that truly ground the answer. We further introduce a rigorous evaluation framework to disentangle explanation fidelity from baseline predictive errors. This allows us to introduce and measure the Explained Information Fraction (EIF), which normalizes M/A certified mutual-information guarantees relative to model capacity and imperfect benchmarks. Across three RAG datasets and two model families of varying sizes, M/A-trained LLMs show improved groundedness, completeness, soundness, and reject behavior, as well as reduced hallucinations -- without needing manually annotated unanswerable questions. The retriever likewise improves recall and MRR through automatically generated M/A hard positives and negatives. Our results demonstrate that autonomous interactive-proof-style supervision provides a principled and practical path toward reliable RAG systems that treat retrieved documents not as suggestions, but as verifiable evidence.", "AI": {"error": "Error code: 403 - {'error': {'message': '非常抱歉，这个问题我暂时无法回答，如果您有其他的问题咨询，我非常乐意帮助你。', 'type': 'taichu_error', 'param': '', 'code': None}}"}}
{"id": "2512.11485", "pdf": "https://arxiv.org/pdf/2512.11485", "abs": "https://arxiv.org/abs/2512.11485", "authors": ["Xuanbo Su", "Yingfang Zhang", "Hao Luo", "Xiaoteng Liu", "Leo Huang"], "title": "Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.", "AI": {"tldr": "Mistake Notebook Learning (MNL)是一种无需训练的新框架，通过错误抽象和动态知识库实现接近监督微调的性能，在复杂推理任务上显著优于其他无训练方法", "motivation": "解决大语言模型传统微调方法计算量大且易灾难性遗忘，以及上下文学习鲁棒性差、错误学习能力不足的问题", "method": "MNL采用批处理错误抽象方法：从多个失败案例中提取可泛化的指导原则，存储在动态笔记本中，并通过保留验证筛选出优于基线的指导，确保单调改进", "result": "在GSM8K上接近监督微调性能(93.9% vs 94.3%)，在KaggleDBQA(Qwen3-8B)上达到28%准确率(相对提升47%)，显著优于Memento(15.1%)和Training-Free GRPO(22.1%)", "conclusion": "MNL是一个强大的无训练替代方案，特别适用于复杂推理任务，通过错误抽象和动态知识管理实现了高效且稳定的性能提升"}}
{"id": "2512.11635", "pdf": "https://arxiv.org/pdf/2512.11635", "abs": "https://arxiv.org/abs/2512.11635", "authors": ["Keerthana Murugaraj", "Salima Lamsiyah", "Marten During", "Martin Theobald"], "title": "Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "This is a preprint of a manuscript submitted to Digital Scholarship in the Humanities (Oxford University Press). The paper is currently under peer review", "summary": "Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite its growing popularity, still remains underused in historical research. Our study focuses on articles published between 1955 and 2018, specifically examining discourse on nuclear power and nuclear safety. We analyze various topic distributions across the corpus and trace their temporal evolution to uncover long-term trends and shifts in public discourse. This enables us to more accurately explore patterns in public discourse, including the co-occurrence of themes related to nuclear power and nuclear weapons and their shifts in topic importance over time. Our study demonstrates the scalability and contextual sensitivity of BERTopic as an alternative to traditional approaches, offering richer insights into historical discourses extracted from newspaper archives. These findings contribute to historical, nuclear, and social-science research while reflecting on current limitations and proposing potential directions for future work.", "AI": {"tldr": "本研究使用BERTopic神经主题建模方法分析1955-2018年报纸档案中关于核能和核安全的公共话语，相比传统LDA方法能更好地捕捉历史文本的动态复杂性和主题演变。", "motivation": "传统主题建模方法如LDA在处理大规模非结构化历史报纸档案时存在局限，无法有效应对主题演变、OCR噪声和大文本量带来的挑战，需要更先进的方法来捕捉历史话语的复杂性。", "method": "采用BERTopic神经主题建模方法，利用基于transformer的嵌入技术从1955-2018年的报纸文章中提取和分类主题，分析主题分布并追踪其时间演化。", "result": "研究成功揭示了核能与核武器相关主题的共现模式及其随时间的重要性变化，发现了公共话语的长期趋势和转变模式。", "conclusion": "BERTopic展现了比传统方法更好的可扩展性和上下文敏感性，为从报纸档案中提取历史话语提供了更丰富的见解，对历史、核能和社会科学研究有重要贡献。"}}
{"id": "2512.11502", "pdf": "https://arxiv.org/pdf/2512.11502", "abs": "https://arxiv.org/abs/2512.11502", "authors": ["Kai Golan Hashiloni", "Brenda Kasabe Nokai", "Michal Shevach", "Esthy Shemesh", "Ronit Bartin", "Anna Bergrin", "Liran Harel", "Nachum Dershowitz", "Liat Nadai Arad", "Kfir Bar"], "title": "Building Patient Journeys in Hebrew: A Language Model for Clinical Timeline Extraction", "categories": ["cs.CL"], "comment": "In Proceedings of the Workshop on Large Language Models and Generative AI for Health Informatics 2025, IJCAI 2025, Montreal, Canada", "summary": "We present a new Hebrew medical language model designed to extract structured clinical timelines from electronic health records, enabling the construction of patient journeys. Our model is based on DictaBERT 2.0 and continually pre-trained on over five million de-identified hospital records. To evaluate its effectiveness, we introduce two new datasets -- one from internal medicine and emergency departments, and another from oncology -- annotated for event temporal relations. Our results show that our model achieves strong performance on both datasets. We also find that vocabulary adaptation improves token efficiency and that de-identification does not compromise downstream performance, supporting privacy-conscious model development. The model is made available for research use under ethical restrictions.", "AI": {"tldr": "提出了一个基于DictaBERT 2.0的希伯来语医疗语言模型，通过持续预训练500万份去标识化医院记录，能够从电子健康记录中提取结构化临床时间线，构建患者旅程。", "motivation": "需要从希伯来语电子健康记录中提取结构化临床时间线以构建患者旅程，但现有模型缺乏对希伯来语医疗文本的专业处理能力。", "method": "基于DictaBERT 2.0进行持续预训练，使用500万+去标识化医院记录，引入两个新数据集（内科/急诊和肿瘤科）进行事件时间关系标注评估。", "result": "模型在两个数据集上均表现优异，词汇适应提高了标记效率，去标识化不影响下游性能，支持隐私保护型模型开发。", "conclusion": "该希伯来语医疗语言模型能有效提取临床时间线，支持患者旅程构建，已在研究用途下提供使用并遵循伦理限制。"}}
{"id": "2512.11567", "pdf": "https://arxiv.org/pdf/2512.11567", "abs": "https://arxiv.org/abs/2512.11567", "authors": ["Mevlüt Bagci", "Ali Abusaleh", "Daniel Baumartz", "Giueseppe Abrami", "Maxim Konca", "Alexander Mehler"], "title": "Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet", "categories": ["cs.CL", "cs.MM"], "comment": "Submitted to LREC 2026", "summary": "Social media serves as a critical medium in modern politics because it both reflects politicians' ideologies and facilitates communication with younger generations. We present MultiParTweet, a multilingual tweet corpus from X that connects politicians' social media discourse with German political corpus GerParCor, thereby enabling comparative analyses between online communication and parliamentary debates. MultiParTweet contains 39 546 tweets, including 19 056 media items. Furthermore, we enriched the annotation with nine text-based models and one vision-language model (VLM) to annotate MultiParTweet with emotion, sentiment, and topic annotations. Moreover, the automated annotations are evaluated against a manually annotated subset. MultiParTweet can be reconstructed using our tool, TTLABTweetCrawler, which provides a framework for collecting data from X. To demonstrate a methodological demonstration, we examine whether the models can predict each other using the outputs of the remaining models. In summary, we provide MultiParTweet, a resource integrating automatic text and media-based annotations validated with human annotations, and TTLABTweetCrawler, a general-purpose X data collection tool. Our analysis shows that the models are mutually predictable. In addition, VLM-based annotation were preferred by human annotators, suggesting that multimodal representations align more with human interpretation.", "AI": {"tldr": "MultiParTweet是一个多语言推特语料库，连接政客社交媒体言论与德国议会语料，包含39,546条推文和19,056个媒体项目，通过多种模型进行情感和主题标注，并提供了数据收集工具TTLABTweetCrawler。", "motivation": "社交媒体在现代政治中扮演重要角色，既能反映政客意识形态，又能促进与年轻一代的沟通。需要建立连接社交媒体与议会辩论的语料库进行对比分析。", "method": "构建MultiParTweet语料库，使用9个文本模型和1个视觉语言模型进行情感、情绪和主题的自动标注，并通过人工标注验证自动标注质量，开发TTLABTweetCrawler工具进行数据收集。", "result": "语料库包含大量标注数据，模型之间具有相互预测性，视觉语言模型的标注更符合人类标注者的偏好，表明多模态表示更贴近人类解释。", "conclusion": "MultiParTweet提供了整合自动文本和媒体标注的资源，验证了多模态方法在政治社交媒体分析中的有效性，为比较研究提供了有价值的数据和工具。"}}
{"id": "2512.11573", "pdf": "https://arxiv.org/pdf/2512.11573", "abs": "https://arxiv.org/abs/2512.11573", "authors": ["Paulius Rauba", "Qiyao Wei", "Mihaela van der Schaar"], "title": "Visualizing token importance for black-box language models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We consider the problem of auditing black-box large language models (LLMs) to ensure they behave reliably when deployed in production settings, particularly in high-stakes domains such as legal, medical, and regulatory compliance. Existing approaches for LLM auditing often focus on isolated aspects of model behavior, such as detecting specific biases or evaluating fairness. We are interested in a more general question -- can we understand how the outputs of black-box LLMs depend on each input token? There is a critical need to have such tools in real-world applications that rely on inaccessible API endpoints to language models. However, this is a highly non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be different by chance), while computing prompt-level gradients to approximate input sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity of the output of a language model for each input token, without making any distributional assumptions about the LLM. DBSA is developed as a practical tool for practitioners, enabling quick, plug-and-play visual exploration of LLMs reliance on specific input tokens. Through illustrative examples, we demonstrate how DBSA can enable users to inspect LLM inputs and find sensitivities that may be overlooked by existing LLM interpretability methods.", "AI": {"tldr": "提出了DBSA方法，一种轻量级、模型无关的分布敏感性分析工具，用于审计黑盒大语言模型对每个输入token的敏感性，无需模型内部信息即可可视化分析输入依赖关系。", "motivation": "现有LLM审计方法只关注孤立方面（如特定偏见检测），但需要理解黑盒LLM输出如何依赖每个输入token，特别是在依赖API端点的实际应用中。", "method": "提出Distribution-Based Sensitivity Analysis (DBSA)，通过分布分析评估每个输入token对输出的敏感性，不依赖模型梯度计算，无需对LLM做分布假设。", "result": "DBSA能快速、即插即用地可视化探索LLM对特定输入token的依赖关系，通过示例展示可以发现现有可解释性方法可能忽略的敏感性。", "conclusion": "DBSA为从业者提供了实用的工具，能够在生产环境中审计黑盒LLM的可靠性，特别适用于法律、医疗等高风险领域。"}}
{"id": "2512.11718", "pdf": "https://arxiv.org/pdf/2512.11718", "abs": "https://arxiv.org/abs/2512.11718", "authors": ["Sergey Pankratov", "Dan Alistarh"], "title": "Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks", "categories": ["cs.CL"], "comment": null, "summary": "Speculative generation has emerged as a promising technique to accelerate inference in large language models (LLMs) by leveraging parallelism to verify multiple draft tokens simultaneously. However, the fundamental limits on the achievable speedup remain poorly understood. In this work, we establish the first ``tight'' lower bounds on the runtime of any deterministic speculative generation algorithm. This is achieved by drawing a parallel between the token generation process and branching random walks, which allows us to analyze the optimal draft tree selection problem. We prove, under basic assumptions, that the expected number of tokens successfully predicted per speculative iteration is bounded as $\\mathbb{E}[X] \\leq (μ+ μ_{(2)})\\log(P )/μ^2 + O(1)$, where $P$ is the verifier's capacity, $μ$ is the expected entropy of the verifier's output distribution, and $μ_{(2)}$ is the expected second log-moment. This result provides new insights into the limits of parallel token generation, and could guide the design of future speculative decoding systems. Empirical evaluations on Llama models validate our theoretical predictions, confirming the tightness of our bounds in practical settings.", "AI": {"tldr": "该论文建立了确定性推测生成算法的首个紧下界，证明了在推测迭代中成功预测的令牌数量上限，为LLM推理加速提供了理论指导。", "motivation": "推测生成技术通过并行验证多个草案令牌来加速大型语言模型推理，但当前对其可实现的加速上限缺乏理论理解。", "method": "通过将令牌生成过程与分支随机游走建立类比，分析最优草案树选择问题，在基本假设下推导数学界限。", "result": "证明了成功预测的令牌期望值上限为E[X] ≤ (μ+μ₂)log(P)/μ² + O(1)，其中P是验证器容量，μ是熵期望，μ₂是第二对数矩期望。", "conclusion": "该理论界限为并行令牌生成的极限提供了新见解，可指导未来推测解码系统的设计，并在Llama模型上得到实证验证。"}}
{"id": "2512.11755", "pdf": "https://arxiv.org/pdf/2512.11755", "abs": "https://arxiv.org/abs/2512.11755", "authors": ["Yuming Feng", "Xinrui Jiang"], "title": "SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support", "categories": ["cs.CL"], "comment": "Code available at https://github.com/Harry20030331/SumForU", "summary": "Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge distillation, and (2) Reinforcement Learning with AI Feedback (RLAIF) using a preference estimator to capture fine-grained, persona-relevant signals. We evaluate the model across rule-based, LLM-based, and human-centered metrics, demonstrating consistent improvements in consistency, grounding, and preference alignment. Our framework achieves the highest performance across all evaluation settings and generalizes effectively to unseen product categories. Our results highlight the promise of steerable pluralistic alignment for building next-generation personalized decision-support systems.", "AI": {"tldr": "SUMFORU是一个可操控的个性化评论摘要框架，通过用户角色对齐和两阶段训练方法，显著提升评论摘要的个性化效果和实用性", "motivation": "现有LLM摘要生成器过于通用，无法考虑个人偏好，限制了实际应用价值。在线产品评论信息丰富但嘈杂，给用户决策带来困扰", "method": "提出两阶段对齐方法：1)通过非对称知识蒸馏进行角色感知监督微调(SFT)；2)使用偏好估计器进行AI反馈强化学习(RLAIF)，构建高质量数据管道", "result": "在所有评估设置中取得最高性能，在一致性、事实基础和偏好对齐方面持续改进，能有效泛化到未见过的产品类别", "conclusion": "可操控的多元化对齐方法为构建下一代个性化决策支持系统展示了巨大潜力"}}
