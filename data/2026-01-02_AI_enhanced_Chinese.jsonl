{"id": "2512.23850", "pdf": "https://arxiv.org/pdf/2512.23850", "abs": "https://arxiv.org/abs/2512.23850", "authors": ["Rahul Baxi"], "title": "The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Currently under review at TMLR", "summary": "Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.", "AI": {"tldr": "该论文提出了DDFT评估协议，用于测试语言模型在语义压缩和对抗性攻击下的知识稳健性，发现模型稳健性与传统设计参数无关，而是取决于训练方法和验证机制。", "motivation": "当前语言模型评估主要关注理想条件下的知识表现，但无法衡量模型在信息退化或对抗攻击下的稳健性，需要新的评估方法来区分知识缺失和验证机制失效。", "method": "提出DDFT协议，通过渐进式语义压缩和对抗性伪造来测试模型的认知稳健性。采用双系统认知模型：语义系统生成文本，认知验证器验证事实准确性。评估了9个前沿模型在8个知识域和5个压缩级别下的表现。", "result": "认知稳健性与模型参数数量(r=0.083)和架构类型(r=0.153)无关，而是由训练方法和验证机制决定。错误检测能力是稳健性的关键瓶颈(rho=-0.817)。旗舰模型表现出脆弱性，而较小模型可以达到稳健性能。", "conclusion": "DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具，挑战了模型大小与可靠性关系的传统假设，强调需要关注训练方法和验证机制的设计。"}}
{"id": "2512.23880", "pdf": "https://arxiv.org/pdf/2512.23880", "abs": "https://arxiv.org/abs/2512.23880", "authors": ["Xu Huang", "Junwu Chen", "Yuxing Fei", "Zhuohan Li", "Philippe Schwaller", "Gerbrand Ceder"], "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": null, "summary": "Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from \"LLM + tool use\" to \"LLM + skill acquisition\". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.", "AI": {"tldr": "CASCADE是一个自进化的LLM智能体框架，通过持续学习和自我反思两大元技能，使AI能够掌握复杂科学工具并积累可共享的可执行技能，在材料科学和化学研究任务中达到93.3%的成功率。", "motivation": "当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性，需要从'LLM+工具使用'向'LLM+技能获取'转变。", "method": "提出CASCADE框架，包含两大元技能：1)通过网络搜索和代码提取进行持续学习；2)通过内省和知识图谱探索进行自我反思。在SciSkillBench基准（116个材料科学和化学研究任务）上评估。", "result": "使用GPT-5时达到93.3%的成功率，相比无进化机制的35.4%有显著提升。在计算分析、自主实验室实验和论文复现等实际应用中表现优异。", "conclusion": "CASCADE通过积累可跨智能体和科学家共享的可执行技能，为可扩展的AI辅助科学研究提供了可行路径，实现了人类-智能体协作和记忆整合。"}}
{"id": "2512.23932", "pdf": "https://arxiv.org/pdf/2512.23932", "abs": "https://arxiv.org/abs/2512.23932", "authors": ["Ioanna Gemou", "Evangelos Lamprou"], "title": "A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming", "categories": ["cs.AI"], "comment": null, "summary": "Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.", "AI": {"tldr": "McCoy框架通过结合大型语言模型和答案集编程，将医学文献转化为可执行的诊断代码，实现了准确且可解释的疾病预测。", "motivation": "传统符号AI在医疗领域应用受限，因为构建高质量知识库需要大量人工努力。需要一种方法能够自动从医学文献中提取知识并用于诊断预测。", "method": "开发McCoy框架，使用LLM将医学文献翻译成ASP代码，结合患者数据，通过ASP求解器进行最终诊断。", "result": "初步结果显示McCoy在小规模疾病诊断任务上表现出色。", "conclusion": "McCoy成功整合了LLM和ASP的优势，创建了一个强大且可解释的预测框架，为医疗诊断自动化提供了可行方案。"}}
{"id": "2512.24008", "pdf": "https://arxiv.org/pdf/2512.24008", "abs": "https://arxiv.org/abs/2512.24008", "authors": ["Gaurab Chhetri", "Subasish Das", "Tausif Islam Chowdhury"], "title": "SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing", "categories": ["cs.AI"], "comment": "This is the author's preprint. Accepted to WEB&GRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: https://wsdm-conference.org/2026/ Workshop: https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html", "summary": "Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.", "AI": {"tldr": "SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态检索和个性化搜索，解决了传统静态配置系统的局限性。", "motivation": "传统个性化搜索系统受限于静态用户配置和单一检索流程，无法有效建模用户动态、多维的信息需求。", "method": "构建由角色、专业领域、任务上下文和领域定义的角色空间；引入角色协调器动态激活相关专业智能体；每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块；通过共享内存、迭代辩论和中继式知识转移实现智能体协作。", "result": "框架能够产生关于协调效率、个性化质量和认知负载分布的可测试预测，并包含自适应学习机制实现角色持续优化。", "conclusion": "SPARK通过细粒度智能体专业化与协作检索的整合，为下一代搜索系统提供了新思路，能够更好地捕捉人类信息寻求行为的复杂性、流动性和上下文敏感性。"}}
{"id": "2512.23710", "pdf": "https://arxiv.org/pdf/2512.23710", "abs": "https://arxiv.org/abs/2512.23710", "authors": ["Zahra Abedi", "Richard M. K. van Dijk", "Gijs Wijnholds", "Tessa Verhoef"], "title": "Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This research digitizes and analyzes the Leidse hoogleraren en lectoren 1575-1815 books written between 1983 and 1985, which contain biographic data about professors and curators of Leiden University. It addresses the central question: how can we design an automated pipeline that integrates OCR, LLM-based interpretation, and database linking to harmonize data from historical document images with existing high-quality database records? We applied OCR techniques, generative AI decoding constraints that structure data extraction, and database linkage methods to process typewritten historical records into a digital format. OCR achieved a Character Error Rate (CER) of 1.08 percent and a Word Error Rate (WER) of 5.06 percent, while JSON extraction from OCR text achieved an average accuracy of 63 percent and, based on annotated OCR, 65 percent. This indicates that generative AI somewhat corrects low OCR performance. Our record linkage algorithm linked annotated JSON files with 94% accuracy and OCR-derived JSON files with 81%. This study contributes to digital humanities research by offering an automated pipeline for interpreting digitized historical documents, addressing challenges like layout variability and terminology differences, and exploring the applicability and strength of an advanced generative AI model.", "AI": {"tldr": "本研究开发了一个自动化流程，结合OCR、基于LLM的解释和数据库链接技术，将莱顿大学教授历史文献数字化并与现有数据库记录进行整合。", "motivation": "解决如何自动化处理历史文献图像，将其与高质量数据库记录进行数据协调的问题，特别是在面对版面变化和术语差异等挑战时。", "method": "应用OCR技术、生成式AI解码约束来结构化数据提取，以及数据库链接方法，将打字历史记录处理为数字格式。", "result": "OCR字符错误率1.08%，单词错误率5.06%；从OCR文本提取JSON的平均准确率为63%（基于标注OCR为65%）；记录链接算法在标注JSON文件上达到94%准确率，在OCR衍生JSON文件上达到81%准确率。", "conclusion": "生成式AI能够在一定程度上纠正低OCR性能，该研究为数字人文研究提供了一个自动化的历史文献解释流程，探索了先进生成式AI模型的适用性和优势。"}}
{"id": "2512.24040", "pdf": "https://arxiv.org/pdf/2512.24040", "abs": "https://arxiv.org/abs/2512.24040", "authors": ["Natchaya Temyingyong", "Daman Jain", "Neeraj Kumarsahu", "Prabhat Kumar", "Rachata Phondi", "Wachiravit Modecrua", "Krittanon Kaewtawee", "Krittin Pachtrachai", "Touchapon Kraisingkorn"], "title": "ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment", "categories": ["cs.AI"], "comment": "22 pages, 1 figure", "summary": "Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.", "AI": {"tldr": "ROAD框架通过自动化调试实现提示优化，无需标注数据集，在冷启动阶段显著提升LLM代理性能", "motivation": "现实软件工程中缺乏标注数据集，传统APO方法依赖大量标注数据，而实际场景只有混乱的生产日志和不断演变的故障模式", "method": "采用多智能体架构：分析器进行根因分析、优化器进行模式聚合、教练进行策略集成，将非结构化故障日志转换为结构化决策树协议", "result": "在3次自动迭代中成功率提升5.6%（73.6%到79.2%），搜索准确率提升3.8%；在零售领域复杂推理任务中性能提升约19%", "conclusion": "模拟人类工程循环的故障分析和修复方法为部署可靠LLM代理提供了数据高效且可行的替代方案，避免了资源密集的强化学习训练"}}
{"id": "2512.23711", "pdf": "https://arxiv.org/pdf/2512.23711", "abs": "https://arxiv.org/abs/2512.23711", "authors": ["Paulo Cavalin", "Cassia Sanctos", "Marcelo Grave", "Claudio Pinhanez", "Yago Primerano"], "title": "CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations", "categories": ["cs.CL"], "comment": null, "summary": "We introduce \\textsc{CAT}, a framework designed to evaluate and visualize the \\emph{interplay} of \\emph{accuracy} and \\emph{response consistency} of Large Language Models (LLMs) under controllable input variations, using multiple-choice (MC) benchmarks as a case study. Current evaluation practices primarily focus on model capabilities such as accuracy or benchmark scores and, more recently, measuring consistency is being considered an essential property for deploying LLMs in high-stake, real-world applications. We argue in this paper that although both dimensions should still be evaluated independently, their inter-dependency also need to be considered for a more nuanced evaluation of LLMs. At the core of \\textsc{CAT} are the \\emph{Consistency-Accuracy Relation (CAR)} curves, which visualize how model accuracy varies with increasing consistency requirements, as defined by the \\emph{Minimum-Consistency Accuracy (MCA)} metric. We further propose the \\emph{Consistency-Oriented Robustness Estimate (CORE)} index, a global metric that combines the area and shape of the CAR curve to quantify the trade-off between accuracy and consistency. We present a practical demonstration of our framework across a diverse set of generalist and domain-specific LLMs, evaluated on multiple MC benchmarks. We also outline how \\textsc{CAT} can be extended beyond MC tasks to support long-form, open-ended evaluations through adaptable scoring functions.", "AI": {"tldr": "CAT框架通过一致性-准确率关系曲线(CAR)和核心指标(CORE)来评估大语言模型在准确性和响应一致性之间的权衡关系，特别针对多选题基准测试设计，但可扩展到开放式评估。", "motivation": "当前LLM评估主要关注准确性或基准分数，而一致性对于高风险应用至关重要。作者认为需要同时评估这两个维度及其相互关系，以获得更细致的模型评估。", "method": "提出CAT框架，包含一致性-准确率关系曲线(CAR)和最小一致性准确率(MCA)指标，以及一致性导向鲁棒性估计(CORE)指数来量化准确性与一致性的权衡。", "result": "在多选题基准测试中对多种通用和领域特定LLMs进行了实际演示，展示了框架的有效性。", "conclusion": "CAT框架提供了评估LLM准确性和一致性相互作用的系统方法，能够支持从多选题到开放式评估的扩展应用，为模型部署提供更全面的评估标准。"}}
{"id": "2512.24077", "pdf": "https://arxiv.org/pdf/2512.24077", "abs": "https://arxiv.org/abs/2512.24077", "authors": ["Chunhui Wan", "Xunan Dai", "Zhuo Wang", "Minglei Li", "Yanpeng Wang", "Yinan Mao", "Yu Lan", "Zhiwen Xiao"], "title": "LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm", "categories": ["cs.AI"], "comment": null, "summary": "The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike \"blind\" mutation operators, LoongFlow integrates LLMs into a cognitive \"Plan-Execute-Summarize\" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.", "AI": {"tldr": "LoongFlow是一个自进化智能体框架，通过将LLM整合到Plan-Execute-Summarize认知范式中，解决了传统进化方法在代码空间中的结构推理不足问题，显著提高了进化效率和解决方案质量。", "motivation": "传统进化方法在从静态LLM向自改进智能体过渡时存在结构推理缺乏、早熟收敛和高维代码空间探索效率低的问题。", "method": "采用Plan-Execute-Summarize(PES)认知范式，结合混合进化记忆系统，整合多岛模型、MAP-Elites和自适应玻尔兹曼选择，平衡探索-利用权衡。", "result": "在AlphaEvolve基准和Kaggle竞赛中，LoongFlow比领先基线(如OpenEvolve、ShinkaEvolve)进化效率提高高达60%，并能发现更优解决方案。", "conclusion": "LoongFlow在自主科学发现方面迈出了重要一步，能够以更低计算成本生成专家级解决方案。"}}
{"id": "2512.23712", "pdf": "https://arxiv.org/pdf/2512.23712", "abs": "https://arxiv.org/abs/2512.23712", "authors": ["Guanghui Wang", "Jinze Yu", "Xing Zhang", "Dayuan Jiang", "Yin Song", "Tomal Deb", "Xuefeng Liu", "Peiyang He"], "title": "STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed for structured data generation, yet output consistency remains critical for production applications. We introduce a comprehensive framework for evaluating and improving consistency in LLM-generated structured outputs. Our approach combines: (1) STED (Semantic Tree Edit Distance), a novel similarity metric balancing semantic flexibility with structural strictness when comparing JSON outputs, and (2) a consistency scoring framework aggregating multiple STED measurements across repeated generations to quantify reliability. Through systematic experiments on synthetic datasets with controlled schema, expression, and semantic variations, we demonstrate STED achieves superior performance ($0.86-0.90$ similarity for semantic equivalents, $0.0$ for structural breaks) compared to existing metrics including TED, BERTScore, and DeepDiff. Applying our framework to benchmark six LLMs reveals significant variations: Claude-3.7-Sonnet demonstrates exceptional consistency, maintaining near-perfect structural reliability even at high temperatures ($T=0.9$), while models like Claude-3-Haiku and Nova-Pro exhibit substantial degradation requiring careful tuning. Our framework enables practical applications including targeted model selection for structured tasks, iterative prompt refinement for reproducible results, and diagnostic analysis to identify inconsistency root causes. This work provides theoretical foundations and practical tools for ensuring reliable structured output generation in LLM-based production systems.", "AI": {"tldr": "提出了一个评估和改进LLM结构化输出一致性的框架，包含STED相似度度量和一致性评分系统，通过实验验证了优于现有方法的效果，并应用于不同LLM模型的基准测试。", "motivation": "LLM在结构化数据生成中的应用日益增多，但输出一致性对生产应用至关重要，需要系统性的评估和改进方法。", "method": "结合STED（语义树编辑距离）相似度度量和一致性评分框架，通过控制变量实验在合成数据集上验证性能，并应用于多个LLM模型的基准测试。", "result": "STED在语义等价情况下达到0.86-0.90相似度，结构断裂时为0.0，优于TED、BERTScore和DeepDiff等现有指标。Claude-3.7-Sonnet表现最佳，而其他模型需要仔细调优。", "conclusion": "该框架为LLM生产系统中可靠的结构化输出生成提供了理论基础和实用工具，支持模型选择、提示词优化和问题诊断。"}}
{"id": "2512.24113", "pdf": "https://arxiv.org/pdf/2512.24113", "abs": "https://arxiv.org/abs/2512.24113", "authors": ["Jiaxin Hu", "Tao Wang", "Bingsan Yang", "Hongrun Wang"], "title": "CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation", "categories": ["cs.AI", "cs.IR"], "comment": "9 pages, 6 figures", "summary": "Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent \"Black-Box\" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.", "AI": {"tldr": "CogRec是一个结合大语言模型和Soar认知架构的新型推荐系统，通过感知-认知-行动循环实现可解释的推荐和在线学习能力", "motivation": "解决LLMs在推荐系统中的黑盒特性、知识幻觉和有限在线学习能力问题，同时克服Soar认知架构知识获取困难的问题", "method": "使用Soar作为符号推理引擎，LLM用于知识初始化，通过PCA循环和遇到障碍时动态查询LLM获取解决方案，利用Soar的分块机制生成新的产生式规则", "result": "在三个公共数据集上的评估显示，CogRec在推荐准确性、可解释性和长尾问题处理方面具有显著优势", "conclusion": "CogRec成功整合了LLMs和认知架构的优势，提供了可解释、可信赖且具有在线学习能力的推荐系统解决方案"}}
{"id": "2512.23713", "pdf": "https://arxiv.org/pdf/2512.23713", "abs": "https://arxiv.org/abs/2512.23713", "authors": ["Jahidul Islam", "Md Ataullha", "Saiful Azad"], "title": "PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual Agents", "categories": ["cs.CL", "cs.AI"], "comment": "6 Pages", "summary": "LLMs excel at code generation from English prompts, but this progress has not extended to low-resource languages. We address Bangla-to-Python code generation by introducing BanglaCodeAct, an agent-based framework that leverages multi-agent prompting and iterative self-correction. Unlike prior approaches relying on task-specific fine-tuning, BanglaCodeAct employs an open-source multilingual LLM within a Thought-Code-Observation loop, enabling dynamic generation, testing, and refinement of code from Bangla instructions. We benchmark several small-parameter open-source LLMs and evaluate their effectiveness on the mHumanEval dataset for Bangla NL2Code. Our results show that Qwen3-8B, when deployed with BanglaCodeAct, achieves the best performance, with pass@1 accuracy of 94.0\\% on the development set and 71.6\\% on the blind test set. These results establish a new benchmark for Bangla-to-Python translation and highlight the potential of agent-based reasoning for reliable code generation in low-resource languages. Experimental scripts are publicly available at github.com/jahidulzaid/PyBanglaCodeActAgent.", "AI": {"tldr": "BanglaCodeAct：基于多智能体提示和迭代自校正的孟加拉语到Python代码生成框架，使用开源多语言LLM在Thought-Code-Observation循环中实现动态代码生成和优化，Qwen3-8B模型在开发集上达到94.0%的pass@1准确率", "motivation": "LLM在英语代码生成方面表现出色，但在低资源语言（如孟加拉语）的代码生成方面进展有限，需要解决孟加拉语到Python代码生成的问题", "method": "提出BanglaCodeAct框架，采用多智能体提示和迭代自校正方法，在Thought-Code-Observation循环中使用开源多语言LLM进行动态代码生成、测试和优化", "result": "Qwen3-8B模型在mHumanEval数据集上表现最佳，开发集pass@1准确率达94.0%，盲测集达71.6%，为孟加拉语到Python翻译设立了新基准", "conclusion": "该研究为低资源语言的可靠代码生成建立了新标准，证明了基于智能体推理方法在处理低资源语言代码生成任务中的潜力"}}
{"id": "2512.24156", "pdf": "https://arxiv.org/pdf/2512.24156", "abs": "https://arxiv.org/abs/2512.24156", "authors": ["Evgenii Rudakov", "Jonathan Shock", "Benjamin Ultan Cowley"], "title": "Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks", "categories": ["cs.AI"], "comment": null, "summary": "We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.", "AI": {"tldr": "提出了一种无需训练、基于图结构的探索方法来解决ARC-AGI-3基准中的交互式推理任务，通过视觉帧处理和系统化的状态空间探索，在基准测试中表现优于最先进的大语言模型。", "motivation": "ARC-AGI-3基准包含需要通过有限交互推断任务机制的游戏式任务，当前最先进的LLM无法可靠解决这些任务，需要一种能够系统化探索状态空间的方法。", "method": "结合视觉帧处理和基于图结构的系统化状态空间探索：将视觉帧分割为有意义的组件，基于视觉显著性优先选择动作，维护探索过的状态和转换的有向图，通过跟踪访问过的状态和测试过的动作来优先选择到达未测试状态-动作对的最短路径。", "result": "在ARC-AGI-3预览挑战中，该方法在6个游戏的52个关卡中解决了中位数30个关卡，在私有排行榜上排名第3，显著优于基于前沿LLM的智能体。", "conclusion": "即使无需学习，显式的图结构探索也可以作为交互式推理的强大基线，在稀疏反馈环境中，系统化的状态跟踪和动作优先级排序至关重要，而当前LLM无法捕捉任务动态。"}}
{"id": "2512.23714", "pdf": "https://arxiv.org/pdf/2512.23714", "abs": "https://arxiv.org/abs/2512.23714", "authors": ["Tingwei Xie", "Tianyi Zhou", "Yonghong Song"], "title": "PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents", "categories": ["cs.CL"], "comment": "5 pages, 4 figures", "summary": "We present PharmaShip, a real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test pre-trained text-layout models under noisy OCR and heterogeneous templates. PharmaShip covers three complementary tasks-sequence entity recognition (SER), relation extraction (RE), and reading order prediction (ROP)-and adopts an entity-centric evaluation protocol to minimize confounds across architectures. We benchmark five representative baselines spanning pixel-aware and geometry-aware families (LiLT, LayoutLMv3-base, GeoLayoutLM and their available RORE-enhanced variants), and standardize preprocessing, splits, and optimization. Experiments show that pixels and explicit geometry provide complementary inductive biases, yet neither alone is sufficient: injecting reading-order-oriented regularization consistently improves SER and EL and yields the most robust configuration, while longer positional coverage stabilizes late-page predictions and reduces truncation artifacts. ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings. PharmaShip thus establishes a controlled, reproducible benchmark for safety-critical document understanding in the pharmaceutical domain and highlights sequence-aware constraints as a transferable bias for structure modeling. We release the dataset at https://github.com/KevinYuLei/PharmaShip.", "AI": {"tldr": "PharmaShip是一个中文药品运输单据数据集，用于在噪声OCR和异构模板下测试文本布局模型。包含序列实体识别、关系提取和阅读顺序预测三个任务，通过实体中心评估协议比较了多种预训练模型。", "motivation": "现有的文档理解模型在噪声OCR和复杂模板下的表现需要进一步测试，特别是在药品安全关键领域缺乏标准化的基准数据集。", "method": "构建了PharmaShip数据集，包含扫描药品运输单据；评估了LiLT、LayoutLMv3-base、GeoLayoutLM等5种代表性模型及其RORE增强变体；采用标准化的预处理、数据分割和优化流程。", "result": "像素信息和显式几何信息提供互补的归纳偏置；阅读顺序正则化能显著提升SER和EL性能；较长的位置覆盖范围能稳定页面尾部预测；ROP在词级别准确但在片段级别存在挑战。", "conclusion": "PharmaShip为药品领域的安全关键文档理解建立了可控、可复现的基准，证明序列感知约束是结构建模的可迁移偏置，数据集已开源。"}}
{"id": "2512.24189", "pdf": "https://arxiv.org/pdf/2512.24189", "abs": "https://arxiv.org/abs/2512.24189", "authors": ["Yankai Jiang", "Wenjie Lou", "Lilong Wang", "Zhenyu Tang", "Shiyang Feng", "Jiaxuan Lu", "Haoran Sun", "Yaning Pan", "Shuang Gu", "Haoyang Su", "Feng Liu", "Wangxu Wei", "Pan Tan", "Dongzhan Zhou", "Fenghua Ling", "Cheng Tan", "Bo Zhang", "Xiaosong Wang", "Lei Bai", "Bowen Zhou"], "title": "SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.", "AI": {"tldr": "SCP（Science Context Protocol）是一个开源的标准化协议，旨在通过建立自主科学智能体的全球网络来加速科学发现。它提供统一的资源集成规范和实验生命周期管理架构，构建了包含1600多个工具资源的大规模科学发现平台。", "motivation": "为了解决科学研究中工具、模型、数据集和物理仪器等资源在不同平台和机构间的互操作性问题，减少集成开销，提高可重复性，并促进AI系统与人类研究者的大规模协作。", "method": "1. 统一资源集成：提供描述和调用科学资源的通用规范\n2. 编排实验生命周期管理：采用集中式SCP Hub和联邦式SCP Server的安全服务架构\n3. 管理完整的实验生命周期（注册、规划、执行、监控和归档）\n4. 实施细粒度身份验证和授权\n5. 编排可追溯的端到端工作流", "result": "成功构建了包含1600多个工具资源的大规模科学发现平台，在多样化用例中实现了异构AI系统与人类研究者之间的安全、大规模协作，显著降低了集成开销并增强了可重复性。", "conclusion": "SCP通过在协议层面标准化科学上下文和工具编排，为可扩展的、多机构的、智能体驱动的科学研究建立了必要的基础设施，有望加速科学发现进程。"}}
{"id": "2512.23716", "pdf": "https://arxiv.org/pdf/2512.23716", "abs": "https://arxiv.org/abs/2512.23716", "authors": ["Toshiyuki Shigemura"], "title": "Noise-Driven Persona Formation in Reflexive Neural Language Generation", "categories": ["cs.CL"], "comment": "324 pages, 9 figures (Figure 7 intentionally skipped), with Appendices A-I. This manuscript presents a computational framework for noise-driven persona formation in neural language generation, analyzing 152 generation cycles using GPT-5.1 with stochastic noise seeds generated by Microsoft Copilot. Primary category: cs.CL", "summary": "This paper introduces the Luca-Noise Reflex Protocol (LN-RP), a computational framework for analyzing noise-driven persona emergence in large language models. By injecting stochastic noise seeds into the initial generation state, we observe nonlinear transitions in linguistic behavior across 152 generation cycles. Our results reveal three stable persona modes with distinct entropy signatures, and demonstrate that external noise sources can reliably induce phase transitions in reflexive generation dynamics. Quantitative evaluation confirms consistent persona retention and significant differences across modes (p < 0.01). The protocol provides a reproducible method for studying reflexive generation, emergent behavior, and longrange linguistic coherence in LLMs.", "AI": {"tldr": "LN-RP协议是一个分析大语言模型中噪声驱动人格涌现的计算框架，通过注入随机噪声种子观察到语言行为的非线性转变，发现了三种具有不同熵特征的稳定人格模式。", "motivation": "研究大语言模型中噪声如何驱动人格涌现现象，探索外部噪声源对反射生成动态的相变诱导能力。", "method": "在初始生成状态注入随机噪声种子，通过152个生成周期观察语言行为的非线性转变，定量评估人格保持和模式差异。", "result": "发现了三种稳定的人格模式，具有不同的熵特征；外部噪声源能够可靠地诱导反射生成动态的相变；定量评估确认了人格保持的一致性和模式间的显著差异(p < 0.01)。", "conclusion": "LN-RP协议为研究大语言模型中的反射生成、涌现行为和长程语言连贯性提供了可重复的方法。"}}
{"id": "2512.24251", "pdf": "https://arxiv.org/pdf/2512.24251", "abs": "https://arxiv.org/abs/2512.24251", "authors": ["Pengfu Wan", "Jiawei Chen", "Gangyan Xu"], "title": "Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem", "categories": ["cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.", "AI": {"tldr": "本文提出了一种基于深度强化学习的方法FRIPN，用于解决车队规模和混合车辆路径问题(FSMVRP)，能够在几秒内生成近似最优解，特别适用于大规模和时间受限的场景。", "motivation": "FSMVRP需要同时决定车队组成和路径规划，在现实场景中应用广泛但计算复杂度高，特别是在大规模和时间受限环境下存在显著挑战。", "method": "将问题建模为马尔可夫决策过程(MDP)，开发了新颖的策略网络FRIPN，整合车队组成和路径决策，采用专门设计的输入嵌入方法包括剩余图嵌入来支持车辆使用决策。", "result": "在随机生成实例和基准数据集上的实验表明，该方法在计算效率和可扩展性方面具有显著优势，特别是在大规模和时间受限场景中。", "conclusion": "该方法展示了在实际应用中的潜力，并为将基于DRL的技术扩展到其他VRP变体提供了有价值的启示。"}}
{"id": "2512.23717", "pdf": "https://arxiv.org/pdf/2512.23717", "abs": "https://arxiv.org/abs/2512.23717", "authors": ["Shenzhe Zhu"], "title": "HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are equipped with safety mechanisms to detect and block harmful queries, yet current alignment approaches primarily focus on overtly dangerous content and overlook more subtle threats. However, users can often disguise harmful intent through covert rephrasing that preserves malicious objectives while appearing benign, which creates a significant gap in existing safety training data. To address this limitation, we introduce HarmTransform, a multi-agent debate framework for systematically transforming harmful queries into stealthier forms while preserving their underlying harmful intent. Our framework leverages iterative critique and refinement among multiple agents to generate high-quality, covert harmful query transformations that can be used to improve future LLM safety alignment. Experiments demonstrate that HarmTransform significantly outperforms standard baselines in producing effective query transformations. At the same time, our analysis reveals that debate acts as a double-edged sword: while it can sharpen transformations and improve stealth, it may also introduce topic shifts and unnecessary complexity. These insights highlight both the promise and the limitations of multi-agent debate for generating comprehensive safety training data.", "AI": {"tldr": "HarmTransform是一个多智能体辩论框架，通过迭代批判和精炼将有害查询转化为更隐蔽的形式，用于改进LLM安全对齐训练数据。", "motivation": "现有安全机制主要关注明显有害内容，但用户可以通过隐蔽重述伪装恶意意图，造成安全训练数据的显著空白。", "method": "采用多智能体辩论框架，通过多个代理的迭代批判和精炼过程，系统性地将有害查询转化为保留恶意意图但表面良性的隐蔽形式。", "result": "实验显示HarmTransform在生成有效查询转换方面显著优于标准基线方法。", "conclusion": "多智能体辩论具有双重作用：能提升转换质量和隐蔽性，但也可能引入主题偏移和复杂性，揭示了该方法在生成全面安全训练数据方面的潜力和局限性。"}}
{"id": "2512.24263", "pdf": "https://arxiv.org/pdf/2512.24263", "abs": "https://arxiv.org/abs/2512.24263", "authors": ["Lijun Zhang", "Lin Li", "Wei Wei", "Yajie Qi", "Huizhong Song", "Jun Wang", "Yaodong Yang", "Jiye Liang"], "title": "Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment", "categories": ["cs.AI"], "comment": null, "summary": "When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.", "AI": {"tldr": "RSA是一种新的风险感知逐步对齐方法，通过嵌套风险度量在策略优化中显式引入风险意识，解决了现有安全对齐方法对罕见但灾难性有害行为的鲁棒性不足问题。", "motivation": "现有的安全对齐方法（如Safe RLHF和SACPO）采用风险中性范式，无法有效处理偏离参考策略带来的风险，对罕见但可能灾难性的有害行为鲁棒性有限。", "method": "将安全对齐构建为词元级别的风险感知约束策略优化问题，通过逐步对齐程序解决，利用嵌套风险度量推导词元级别的策略更新。", "result": "实验结果表明，该方法在保持高水平帮助性的同时确保强安全性，并显著抑制了尾部风险（低概率但高影响的不安全响应）。", "conclusion": "RSA方法通过风险感知的逐步对齐，有效解决了现有安全对齐方法的局限性，在理论分析和实验验证中都表现出优越的性能。"}}
{"id": "2512.23722", "pdf": "https://arxiv.org/pdf/2512.23722", "abs": "https://arxiv.org/abs/2512.23722", "authors": ["Adam Kamel", "Tanish Rastogi", "Michael Ma", "Kailash Ranganathan", "Kevin Zhu"], "title": "Emergent World Beliefs: Exploring Transformers in Stochastic Games", "categories": ["cs.CL"], "comment": "Accepted at NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "Transformer-based large language models (LLMs) have demonstrated strong reasoning abilities across diverse fields, from solving programming challenges to competing in strategy-intensive games such as chess. Prior work has shown that LLMs can develop emergent world models in games of perfect information, where internal representations correspond to latent states of the environment. In this paper, we extend this line of investigation to domains of incomplete information, focusing on poker as a canonical partially observable Markov decision process (POMDP). We pretrain a GPT-style model on Poker Hand History (PHH) data and probe its internal activations. Our results demonstrate that the model learns both deterministic structure, such as hand ranks, and stochastic features, such as equity, without explicit instruction. Furthermore, by using primarily nonlinear probes, we demonstrated that these representations are decodeable and correlate with theoretical belief states, suggesting that LLMs are learning their own representation of the stochastic environment of Texas Hold'em Poker.", "AI": {"tldr": "研究发现大型语言模型在德州扑克这类不完全信息博弈中能自发学习到确定性和随机性特征，包括手牌等级和胜率，表明LLMs能够学习随机环境的内部表征。", "motivation": "扩展对LLM在完美信息游戏中涌现世界模型的研究，探索其在不完全信息领域（以扑克为典型POMDP）的表现能力。", "method": "在扑克手牌历史数据上预训练GPT风格模型，并通过非线性探针分析其内部激活状态。", "result": "模型无需显式指导就能学习手牌等级（确定性结构）和胜率（随机特征），这些表征可通过探针解码并与理论信念状态相关。", "conclusion": "LLMs能够学习不完全信息随机环境的内部表征，展现了在POMDP领域中的强大推理能力。"}}
{"id": "2512.24461", "pdf": "https://arxiv.org/pdf/2512.24461", "abs": "https://arxiv.org/abs/2512.24461", "authors": ["Seohui Bae", "Jeonghye Kim", "Youngchul Sung", "Woohyung Lim"], "title": "Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.", "AI": {"tldr": "提出了一种无需梯度更新或额外训练的后验引导信念精化的测试时自适应智能体，通过最大化信念空间信息增益来选择行动，在部分可观测环境下优于传统推理增强方法", "motivation": "解决LLM智能体在部分可观测环境下需要依赖梯度更新或额外训练的问题，实现更高效的世界状态对齐", "method": "维护外部结构化环境状态信念，通过行动条件观测迭代更新信念，使用轻量级LLM代理估计信息增益，并通过后验信念与真实环境一致性奖励评估世界对齐", "result": "实验显示该方法在潜在世界状态对齐方面优于提示增强和检索增强的LLM基线，且集成开销显著降低", "conclusion": "后验引导的信念精化方法为LLM智能体在部分可观测环境中的自适应推理提供了有效解决方案，无需复杂训练即可实现更好的性能"}}
{"id": "2512.23732", "pdf": "https://arxiv.org/pdf/2512.23732", "abs": "https://arxiv.org/abs/2512.23732", "authors": ["Anwar Alajmi", "Gabriele Pergola"], "title": "When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \\textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with a +2.72\\% improvement in F1 on the EXIST 2025 Task 1.1, and a gains of +4.48\\% and +1.30\\% on the EDOS Tasks A and B, respectively.", "AI": {"tldr": "提出一个两阶段框架来解决在线性别歧视内容检测中的标签稀缺、噪声和概念模糊问题，通过针对性训练和基于推理的推断实现SOTA性能", "motivation": "在线性别歧视内容日益呈现微妙、依赖上下文的隐蔽形式，传统检测方法难以识别。存在标签稀缺、类别不平衡、标注不一致等问题，导致模型决策边界不稳定，无法检测更微妙的伤害形式", "method": "两阶段框架：1) 训练阶段使用类别平衡焦点损失、类别感知批处理和阈值校准来处理标签不平衡和噪声监督；2) 推断阶段采用动态路由机制，高置信度样本直接分类，不确定样本交由协作专家判断模块处理，该模块通过多个角色模型进行推理并由法官模型整合结果", "result": "在多个基准测试中取得最先进结果：EXIST 2025 Task 1.1 F1提升2.72%，EDOS Task A提升4.48%，Task B提升1.30%", "conclusion": "该框架有效解决了性别歧视内容检测中的数据不平衡、噪声和模糊性问题，通过结合针对性训练和基于推理的推断，显著提升了检测性能，为处理复杂社交媒体内容提供了有效解决方案"}}
{"id": "2512.24497", "pdf": "https://arxiv.org/pdf/2512.24497", "abs": "https://arxiv.org/abs/2512.24497", "authors": ["Basile Terver", "Tsung-Yen Yang", "Jean Ponce", "Adrien Bardes", "Yann LeCun"], "title": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "categories": ["cs.AI", "cs.LG", "cs.RO", "stat.ML"], "comment": null, "summary": "A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.", "AI": {"tldr": "本研究系统分析了基于表示空间规划的世界模型(JEPA-WMs)，通过实验确定了最优架构、训练目标和规划算法组合，提出的模型在导航和操作任务上优于现有基线方法。", "motivation": "解决AI代理在物理任务中的泛化能力问题，探索在表示空间而非输入空间进行规划的方法，以抽象无关细节提高规划效率。", "method": "使用模拟环境和真实机器人数据，系统研究模型架构、训练目标和规划算法等关键组件对规划成功率的影响，提出优化方法。", "result": "提出的模型在导航和操作任务上超越了DINO-WM和V-JEPA-2-AC两个基准方法，证明了表示空间规划的有效性。", "conclusion": "通过系统分析JEPA-WMs技术选择，确定了最优配置方案，为基于表示空间规划的世界模型发展提供了重要指导，代码和数据已开源。"}}
{"id": "2512.23739", "pdf": "https://arxiv.org/pdf/2512.23739", "abs": "https://arxiv.org/abs/2512.23739", "authors": ["Michaela Levi-Richter", "Reuth Mirsky", "Oren Glickman"], "title": "Break Out the Silverware -- Semantic Understanding of Stored Household Items", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "comment": "Poster presented at the Israeli Seminar on Computational Linguistics 2025", "summary": "``Bring me a plate.'' For domestic service robots, this simple command reveals a complex challenge: inferring where everyday items are stored, often out of sight in drawers, cabinets, or closets. Despite advances in vision and manipulation, robots still lack the commonsense reasoning needed to complete this task. We introduce the Stored Household Item Challenge, a benchmark task for evaluating service robots' cognitive capabilities: given a household scene and a queried item, predict its most likely storage location.\n  Our benchmark includes two datasets: (1) a real-world evaluation set of 100 item-image pairs with human-annotated ground truth from participants' kitchens, and (2) a development set of 6,500 item-image pairs annotated with storage polygons over public kitchen images. These datasets support realistic modeling of household organization and enable comparative evaluation across agent architectures.\n  To begin tackling this challenge, we introduce NOAM (Non-visible Object Allocation Model), a hybrid agent pipeline that combines structured scene understanding with large language model inference. NOAM converts visual input into natural language descriptions of spatial context and visible containers, then prompts a language model (e.g., GPT-4) to infer the most likely hidden storage location. This integrated vision-language agent exhibits emergent commonsense reasoning and is designed for modular deployment within broader robotic systems.\n  We evaluate NOAM against baselines including random selection, vision-language pipelines (Grounding-DINO + SAM), leading multimodal models (e.g., Gemini, GPT-4o, Kosmos-2, LLaMA, Qwen), and human performance. NOAM significantly improves prediction accuracy and approaches human-level results, highlighting best practices for deploying cognitively capable agents in domestic environments.", "AI": {"tldr": "论文提出了'存储家居物品挑战'基准任务，开发了NOAM混合代理管道，结合场景理解和语言模型推理来预测隐藏物品的存储位置，在准确率上显著超越基线方法并接近人类水平。", "motivation": "服务机器人在执行'拿盘子'等简单指令时缺乏常识推理能力，无法推断出视线外物品的存储位置，需要解决这一复杂挑战。", "method": "提出NOAM模型：将视觉输入转换为空间上下文和可见容器的自然语言描述，然后使用大型语言模型（如GPT-4）推理最可能的隐藏存储位置。包含两个数据集：100对真实厨房物品-图像对和6500对公开厨房图像标注数据。", "result": "NOAM在预测准确率上显著优于随机选择、视觉语言管道、多模态模型等基线方法，并接近人类表现水平。", "conclusion": "NOAM展示了新兴的常识推理能力，为在家庭环境中部署具有认知能力的代理提供了最佳实践，推动了服务机器人认知能力的发展。"}}
{"id": "2512.24504", "pdf": "https://arxiv.org/pdf/2512.24504", "abs": "https://arxiv.org/abs/2512.24504", "authors": ["Zhiwei Wei", "Yuxing Liu", "Hua Liao", "Wenjia Xu"], "title": "Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments", "categories": ["cs.AI"], "comment": "43 pages, 8 figures", "summary": "Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.", "AI": {"tldr": "本文提出了一个交互式评估框架，用于分析基础模型代理在符号地图环境中的探索、记忆和推理能力，揭示了探索策略、记忆表示和推理方案在空间理解中的不同作用。", "motivation": "现有基础模型空间能力评估主要依赖静态地图输入或文本查询，忽视了空间理解的交互性和经验驱动特性，需要新的评估方法来全面理解模型的空间认知能力。", "method": "设计交互式评估框架，让代理在部分可观察的网格地图中增量探索（包含道路、交叉口和兴趣点），通过六类空间任务评估空间理解能力，系统测试不同探索策略、记忆表示和推理方案。", "result": "探索主要影响经验获取但对最终推理准确率影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（序列和图表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储知识的利用方式；空间推理性能在模型能力达到一定阈值后趋于饱和。", "conclusion": "提升地图空间理解能力需要针对空间表示和推理的专门机制，而不仅仅是模型规模的扩展，结构化记忆和高级推理提示对空间任务性能有重要影响。"}}
{"id": "2512.23765", "pdf": "https://arxiv.org/pdf/2512.23765", "abs": "https://arxiv.org/abs/2512.23765", "authors": ["Tiancheng Su", "Meicong Zhang", "Guoxiu He"], "title": "Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model's inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.", "AI": {"tldr": "EASD是一种无需训练的方法，通过在标准推测解码中加入基于熵的动态惩罚机制，利用采样分布的熵量化模型不确定性，在两者高熵且top-N预测重叠时拒绝候选token，从而可能超越目标模型性能。", "motivation": "传统推测解码过度依赖草稿模型与目标模型的对齐，限制了性能只能达到目标模型水平，无法超越目标模型本身的能力。", "method": "在标准推测解码基础上，加入动态熵惩罚机制：计算采样分布的熵来量化不确定性，当草稿模型和目标模型都显示高熵且top-N预测有显著重叠时，拒绝候选token并由目标LLM重新采样。", "result": "在多个推理基准测试中，EASD始终优于现有SD方法，在大多数情况下甚至超越了目标LLM本身的性能，同时保持了与SD相当的效率。", "conclusion": "EASD通过引入熵感知机制，不仅保持了推测解码的效率优势，还突破了只能达到目标模型性能的限制，实现了可能超越目标模型性能的突破。"}}
{"id": "2512.24505", "pdf": "https://arxiv.org/pdf/2512.24505", "abs": "https://arxiv.org/abs/2512.24505", "authors": ["Samuel Golladay", "Majid Bani-Yaghoub"], "title": "Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems", "categories": ["cs.AI"], "comment": "7 pages, submitted to ACM Transactions on Intelligent Systems and Technology", "summary": "Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.", "AI": {"tldr": "本研究分析了三个主流LLM（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3）在代表性不足的数学竞赛问题上的表现，发现DeepSeek-V3在微积分、解析几何和离散数学三个领域表现最佳，但所有模型在几何问题上表现都较弱。", "motivation": "现有研究大多使用相同数据集评估LLM的数学推理能力，限制了研究结果的泛化性，无法充分捕捉数学任务中的多样化挑战。", "method": "使用密苏里大学数学竞赛题目（涵盖微积分、解析几何和离散数学）测试三个主流LLM，将其回答与已知正确答案比较，并分析错误模式。", "result": "DeepSeek-V3在三个数学领域表现最佳；所有模型在几何问题上表现最弱；DeepSeek-V3主要错误是计算和逻辑错误，GPT-4o-mini常见逻辑和方法错误，Gemini则存在推理不完整和仓促下结论的问题。", "conclusion": "在代表性不足的数学竞赛数据集上评估LLM能更深入了解其独特错误模式，并突显结构化推理（特别是几何领域）中的持续挑战。"}}
{"id": "2512.23808", "pdf": "https://arxiv.org/pdf/2512.23808", "abs": "https://arxiv.org/abs/2512.23808", "authors": ["Xiaomi LLM-Core Team", ":", "Dong Zhang", "Gang Wang", "Jinlong Xue", "Kai Fang", "Liang Zhao", "Rui Ma", "Shuhuai Ren", "Shuo Liu", "Tao Guo", "Weiji Zhuang", "Xin Zhang", "Xingchen Song", "Yihan Yan", "Yongzhe He", "Cici", "Bowen Shen", "Chengxuan Zhu", "Chong Ma", "Chun Chen", "Heyu Chen", "Jiawei Li", "Lei Li", "Menghang Zhu", "Peidian Li", "Qiying Wang", "Sirui Deng", "Weimin Xiong", "Wenshan Huang", "Wenyu Yang", "Yilin Jiang", "Yixin Yang", "Yuanyuan Tian", "Yue Ma", "Yue Yu", "Zihan Zhang", "Zihao Yue", "Bangjun Xiao", "Bingquan Xia", "Bofei Gao", "Bowen Ye", "Can Cai", "Chang Liu", "Chenhong He", "Chunan Li", "Dawei Zhu", "Duo Zhang", "Fengyuan Shi", "Guoan Wang", "Hailin Zhang", "Hanglong Lv", "Hanyu Li", "Hao Tian", "Heng Qu", "Hongshen Xu", "Houbin Zhang", "Huaqiu Liu", "Jiangshan Duo", "Jianguang Zuo", "Jianyu Wei", "Jiebao Xiao", "Jinhao Dong", "Jun Shi", "Junhao Hu", "Kainan Bao", "Kang Zhou", "Linghao Zhang", "Meng Chen", "Nuo Chen", "Peng Zhang", "Qianli Chen", "Qiantong Wang", "Rang Li", "Shaohui Liu", "Shengfan Wang", "Shicheng Li", "Shihua Yu", "Shijie Cao", "Shimao Chen", "Shuhao Gu", "Weikun Wang", "Wenhan Ma", "Xiangwei Deng", "Xing Yong", "Xing Zhang", "Xu Wang", "Yifan Song", "Yihao Zhao", "Yingbo Zhao", "Yizhao Gao", "Yu Cheng", "Yu Tu", "Yudong Wang", "Zhaojun Huang", "Zhengju Tang", "Zhenru Lin", "Zhichao Song", "Zhipeng Xu", "Zhixian Zheng", "Zihan Jiang"], "title": "MiMo-Audio: Audio Language Models are Few-Shot Learners", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Existing audio language models typically rely on task-specific fine-tuning to accomplish particular audio tasks. In contrast, humans are able to generalize to new audio tasks with only a few examples or simple instructions. GPT-3 has shown that scaling next-token prediction pretraining enables strong generalization capabilities in text, and we believe this paradigm is equally applicable to the audio domain. By scaling MiMo-Audio's pretraining data to over one hundred million of hours, we observe the emergence of few-shot learning capabilities across a diverse set of audio tasks. We develop a systematic evaluation of these capabilities and find that MiMo-Audio-7B-Base achieves SOTA performance on both speech intelligence and audio understanding benchmarks among open-source models. Beyond standard metrics, MiMo-Audio-7B-Base generalizes to tasks absent from its training data, such as voice conversion, style transfer, and speech editing. MiMo-Audio-7B-Base also demonstrates powerful speech continuation capabilities, capable of generating highly realistic talk shows, recitations, livestreaming and debates. At the post-training stage, we curate a diverse instruction-tuning corpus and introduce thinking mechanisms into both audio understanding and generation. MiMo-Audio-7B-Instruct achieves open-source SOTA on audio understanding benchmarks (MMSU, MMAU, MMAR, MMAU-Pro), spoken dialogue benchmarks (Big Bench Audio, MultiChallenge Audio) and instruct-TTS evaluations, approaching or surpassing closed-source models. Model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-Audio.", "AI": {"tldr": "MiMo-Audio通过将音频预训练数据扩展到超过1亿小时，实现了音频任务的少样本学习能力，在多个音频理解和生成任务上达到开源SOTA性能，并能泛化到未见过的音频任务。", "motivation": "现有音频语言模型通常需要针对特定任务进行微调，而人类能够通过少量示例或简单指令泛化到新音频任务。受GPT-3在文本领域的成功启发，研究者认为这种范式同样适用于音频领域。", "method": "通过将MiMo-Audio的预训练数据扩展到超过1亿小时，使用下一令牌预测预训练范式。在训练后阶段，策划了多样化的指令调优语料库，并在音频理解和生成中引入思维机制。", "result": "MiMo-Audio-7B-Base在开源模型中实现了语音智能和音频理解基准测试的SOTA性能，能够泛化到训练数据中未出现的任务（如语音转换、风格迁移、语音编辑）。MiMo-Audio-7B-Instruct在音频理解、口语对话和指令TTS评估中达到开源SOTA，接近或超越闭源模型。", "conclusion": "通过大规模预训练数据扩展，音频语言模型能够展现出强大的少样本学习和泛化能力，证明了GPT-3范式在音频领域的适用性，为音频AI的发展提供了新的方向。"}}
{"id": "2512.24532", "pdf": "https://arxiv.org/pdf/2512.24532", "abs": "https://arxiv.org/abs/2512.24532", "authors": ["Amir Tahmasbi", "Sadegh Majidi", "Kazem Taram", "Aniket Bera"], "title": "From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.", "AI": {"tldr": "该论文提出了一种两阶段方法来解决大语言模型在空间推理中的挑战，通过分解空间变换为原子构建块并组合它们进行多步规划，在ASCII艺术环境中显著超越了基线模型。", "motivation": "尽管大语言模型具有强大的通用语言能力，但在结构化环境中的空间变换和多步规划方面仍然存在困难，需要专门的方法来提升空间推理能力。", "method": "采用两阶段方法：首先通过监督微调训练基本空间变换（旋转、平移、缩放），然后冻结该物理感知模型，在GRPO框架内训练轻量级LoRA适配器来学习组合这些构建块进行多步规划。", "result": "该方法在动态环境和静态环境中均一致优于基线模型（包括通用主干模型、物理感知模型和端到端RL模型），收敛速度更快且训练更稳定。", "conclusion": "通过分析注意力模式证实微调确实带来了空间理解的有意义改进，该方法有效提升了LLMs在空间推理任务中的表现。"}}
{"id": "2512.23813", "pdf": "https://arxiv.org/pdf/2512.23813", "abs": "https://arxiv.org/abs/2512.23813", "authors": ["Amal Alqahtani", "Efsun Kayi", "Mona Diab"], "title": "StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The prevalence of chronic stress represents a significant public health concern, with social media platforms like Twitter serving as important venues for individuals to share their experiences. This paper introduces StressRoBERTa, a cross-condition transfer learning approach for automatic detection of self-reported chronic stress in English tweets. The investigation examines whether continual training on clinically related conditions (depression, anxiety, PTSD), disorders with high comorbidity with chronic stress, improves stress detection compared to general language models and broad mental health models. RoBERTa is continually trained on the Stress-SMHD corpus (108M words from users with self-reported diagnoses of depression, anxiety, and PTSD) and fine-tuned on the SMM4H 2022 Task 8 dataset. StressRoBERTa achieves 82% F1-score, outperforming the best shared task system (79% F1) by 3 percentage points. The results demonstrate that focused cross-condition transfer from stress-related disorders (+1% F1 over vanilla RoBERTa) provides stronger representations than general mental health training. Evaluation on Dreaddit (81% F1) further demonstrates transfer from clinical mental health contexts to situational stress discussions.", "AI": {"tldr": "StressRoBERTa是一种基于跨条件迁移学习的模型，通过在临床相关精神健康数据上持续训练，显著提升了推特上慢性压力检测的性能，F1分数达到82%，比最佳共享任务系统提升3个百分点。", "motivation": "慢性压力是重要的公共卫生问题，社交媒体成为人们分享压力经历的重要平台。研究旨在探索通过临床相关精神疾病（抑郁、焦虑、PTSD）的迁移学习是否能比通用语言模型和广泛心理健康模型更好地检测慢性压力。", "method": "使用RoBERTa模型，在Stress-SMHD语料库（来自抑郁、焦虑、PTSD患者的1.08亿词）上进行持续训练，然后在SMM4H 2022 Task 8数据集上进行微调，开发StressRoBERTa模型。", "result": "StressRoBERTa达到82%的F1分数，比最佳共享任务系统（79%）高3个百分点。相比原始RoBERTa提升1% F1分数。在Dreaddit数据集上也达到81% F1分数，证明了从临床心理健康到情境压力讨论的迁移能力。", "conclusion": "研究表明，从压力相关障碍的跨条件迁移学习比通用的心理健康训练提供更强的表示能力，证明了临床相关数据对特定压力检测任务的有效性。"}}
{"id": "2512.24565", "pdf": "https://arxiv.org/pdf/2512.24565", "abs": "https://arxiv.org/abs/2512.24565", "authors": ["Wenrui Liu", "Zixiang Liu", "Elsie Dai", "Wenhan Yu", "Lei Yu", "Tong Yang"], "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.", "AI": {"tldr": "MCPAgentBench是一个基于真实MCP定义的新基准测试，用于评估AI代理的工具使用能力，包含真实任务、模拟工具和动态沙盒环境，测试工具选择和辨别能力。", "motivation": "当前MCP评估集存在依赖外部服务和缺乏难度感知的问题，需要更好的基准来评估LLM作为自主代理的工具使用能力。", "method": "构建包含真实任务和模拟MCP工具的数据集，使用动态沙盒环境提供包含干扰项的工具列表，测试代理的工具选择能力，并引入综合指标衡量任务完成率和执行效率。", "result": "在多种主流大语言模型上的实验显示出在处理复杂多步骤工具调用方面的显著性能差异。", "conclusion": "MCPAgentBench为解决当前MCP评估局限性提供了有效方案，代码已开源，有助于推动自主代理工具使用能力的研究和发展。"}}
{"id": "2512.23835", "pdf": "https://arxiv.org/pdf/2512.23835", "abs": "https://arxiv.org/abs/2512.23835", "authors": ["Himel Ghosh"], "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "10 pages, 8 figures", "summary": "Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.", "AI": {"tldr": "比较两种基于Transformer的新闻偏见检测模型的可解释性研究，发现不同架构在整合语言信号方面存在显著差异，领域自适应模型比标准偏见检测器减少63%误报，错误主要源于语篇层面模糊性而非显性偏见线索", "motivation": "新闻文本自动偏见检测被广泛用于新闻分析和媒体问责，但人们对其决策机制和失败原因了解甚少，需要研究不同模型如何操作化语言偏见", "method": "使用SHAP解释方法对两种模型进行对比研究：基于BABE数据集微调的偏见检测器和领域自适应预训练RoBERTa模型，分析正确和错误预测的词级归因", "result": "两模型关注相似的评价语言类别但整合方式不同；偏见检测器对误报赋予更强内部证据，导致中性内容被系统性过度标记；领域自适应模型归因模式与预测结果更一致，误报减少63%；模型错误源于语篇层面模糊性而非显性偏见线索", "conclusion": "可解释性感知评估对偏见检测系统至关重要，架构和训练选择显著影响模型在新闻场景中的可靠性和部署适用性"}}
{"id": "2512.24601", "pdf": "https://arxiv.org/pdf/2512.24601", "abs": "https://arxiv.org/abs/2512.24601", "authors": ["Alex L. Zhang", "Tim Kraska", "Omar Khattab"], "title": "Recursive Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "9 pages, 33 with Appendix", "summary": "We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.", "AI": {"tldr": "提出递归语言模型(RLMs)，通过程序化检查、分解和递归调用的方式，使大语言模型能够处理远超上下文窗口限制的超长提示，在四个长上下文任务中表现优异且成本可控。", "motivation": "解决大语言模型在处理超长提示时受限于固定上下文窗口的问题，探索推理时扩展模型处理能力的方法。", "method": "提出RLMs推理策略，将长提示视为外部环境，允许LLM程序化地检查、分解提示片段并进行递归调用。", "result": "RLMs成功处理比模型上下文窗口长两个数量级的输入，在短提示任务中也显著优于基础LLM和常见长上下文框架，查询成本相当或更低。", "conclusion": "RLMs为LLM处理任意长度提示提供了一种有效且高效的通用推理策略，突破了传统上下文窗口的限制。"}}
{"id": "2512.23836", "pdf": "https://arxiv.org/pdf/2512.23836", "abs": "https://arxiv.org/abs/2512.23836", "authors": ["Dingmin Wang", "Ji Ma", "Shankar Kumar"], "title": "Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.", "AI": {"tldr": "该论文提出了一种自适应提示策略，通过将检索信息分块并顺序提示LLM来改善长上下文检索增强问答的性能，在减少token使用的同时保持性能，并发现LLM在面对信息不足时倾向于生成错误答案而非拒绝回答的问题。", "motivation": "长上下文窗口虽然便于融入目标知识，但会引入更多无关信息，阻碍模型生成过程并降低性能，需要解决这一问题。", "method": "设计自适应提示策略：将检索信息分割成较小块，顺序提示LLM使用每个块回答问题，通过调整块大小在相关信息和无关信息之间进行权衡。", "result": "在三个开放域问答数据集上的实验表明，自适应策略在使用较少token的同时达到了标准提示的性能水平。", "conclusion": "研究发现LLM在遇到信息不足时经常生成错误答案而不是拒绝回答，这是主要错误来源，需要进一步研究增强LLM在面对信息不足时有效拒绝请求的能力。"}}
{"id": "2512.24609", "pdf": "https://arxiv.org/pdf/2512.24609", "abs": "https://arxiv.org/abs/2512.24609", "authors": ["Dong Qiu", "Duo Xu", "Limengxi Yue"], "title": "Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization", "categories": ["cs.AI"], "comment": "Accepted by IEEE ICFTIC 2025", "summary": "Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.", "AI": {"tldr": "提出基于强化学习的多智能体LLM协作框架，采用Dec-POMDP建模和CTDE训练方式，通过GRPO算法优化全局性能，在写作和编程任务中显著提升协作效率和一致性。", "motivation": "大型语言模型在单任务中表现优异，但在多智能体协作环境中缺乏全局优化能力，难以实现高效的协同工作。", "method": "采用去中心化部分可观测马尔可夫决策过程(Dec-POMDP)建模协作问题，使用集中训练分散执行(CTDE)框架，提出群体相对策略优化(GRPO)算法，结合平衡任务质量、速度和协调成本的联合奖励机制。", "result": "在协作写作和编程基准测试中，任务处理速度比单智能体基线提升3倍，写作结构/风格一致性达到98.7%，编程测试通过率达到74.6%，显著优于其他多智能体LLM基线方法。", "conclusion": "该框架为复杂工作流中的可靠协作提供了实用路径，通过强化学习增强LLM的协作能力，在多智能体环境中实现了显著的性能提升和协调效果。"}}
{"id": "2512.23837", "pdf": "https://arxiv.org/pdf/2512.23837", "abs": "https://arxiv.org/abs/2512.23837", "authors": ["Kaustubh Dhole"], "title": "Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.", "AI": {"tldr": "本研究利用注意力中间层的token分布生成对抗样本，通过模型内部token预测来产生语义合理且内部一致的扰动，在论证质量评估任务中验证了有效性，但也发现某些层和位置会导致语法退化。", "motivation": "基于机制可解释性的最新进展表明，中间注意力层编码了逐步细化的token级假设，研究者希望利用这一特性直接从注意力层token分布生成对抗样本。", "method": "使用LLaMA-3.1-Instruct-8B作为生成器和评估器，在ArgQuality数据集上进行论证质量评估实验，从中间层提取token作为对抗扰动。", "result": "基于注意力的对抗样本导致评估性能显著下降，同时保持与原始输入的语义相似性，但某些层和token位置的替换会引入语法退化问题。", "conclusion": "中间层表示作为对抗样本的原则性来源具有潜力，但目前仍存在局限性，可用于压力测试基于LLM的评估流程。"}}
{"id": "2512.24613", "pdf": "https://arxiv.org/pdf/2512.24613", "abs": "https://arxiv.org/abs/2512.24613", "authors": ["Zheyu Shi", "Dong Qiu", "Shanlong Yu"], "title": "Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning", "categories": ["cs.AI"], "comment": "Accepted by IEEE ITCA 2025", "summary": "This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.", "AI": {"tldr": "提出基于群体审议的多智能体对话模型，通过三级角色分工架构（生成、验证、整合）和自博弈机制，结合检索增强和复合奖励函数，显著提升复杂推理任务的准确性和一致性。", "motivation": "解决单一大型语言模型在复杂推理任务中的局限性，需要更有效的多智能体协作方法来提升推理能力和事实一致性。", "method": "采用三级角色分工：生成智能体产生多样化推理视角，验证智能体检索外部知识并量化事实支持，仲裁智能体整合逻辑一致的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计复合奖励函数结合事实一致性和逻辑连贯性，使用改进的近端策略优化进行协同训练。", "result": "在HotpotQA上多跳推理准确率提升16.8%，在2WikiMultihopQA上提升14.3%，在MeetingBank上提升19.2%，一致性提升21.5%。相比主流多智能体方法具有更高推理效率。", "conclusion": "该模型为复杂推理任务提供了有效且稳定的解决方案，通过多智能体协同和外部知识整合显著提升了推理性能和一致性。"}}
{"id": "2512.23848", "pdf": "https://arxiv.org/pdf/2512.23848", "abs": "https://arxiv.org/abs/2512.23848", "authors": ["Yukun Zhang", "Stefan Elbl Droguett", "Samyak Jain"], "title": "Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs", "categories": ["cs.CL", "cs.CE", "cs.LG"], "comment": null, "summary": "This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.", "AI": {"tldr": "该研究通过多检索器RAG系统结合最新LLM，在金融数值推理QA任务中取得了SOTA性能，比基线模型提升超过7%，但仍低于人类专家水平。研究发现领域特定训练和外部知识检索对性能提升有显著贡献。", "motivation": "解决金融数值推理QA任务中由于缺乏金融领域知识导致的错误，尽管大语言模型有进展，但金融数值问题仍具挑战性，需要特定领域知识和复杂多步数值推理。", "method": "实现多检索器检索增强生成(RAG)系统，检索外部领域知识和内部问题上下文，利用最新LLM处理任务。通过消融实验和错误分析验证方法有效性。", "result": "领域特定训练(SecBERT编码器)使神经符号模型超越基线模型；最佳提示型LLM生成器达到SOTA性能，提升超过7%；发现小模型幻觉损失与外部知识增益的权衡，大模型中外部事实增益通常超过幻觉损失。", "conclusion": "研究证实最新LLM在少样本学习优化下增强了数值推理能力，领域特定训练具有潜在优越性能，外部知识检索对提升金融数值推理任务效果显著。"}}
{"id": "2512.24615", "pdf": "https://arxiv.org/pdf/2512.24615", "abs": "https://arxiv.org/abs/2512.24615", "authors": ["Yuchen Shi", "Yuzheng Cai", "Siqi Cai", "Zihan Xu", "Lichao Chen", "Yulei Qin", "Zhijian Zhou", "Xiang Fei", "Chaofan Qiu", "Xiaoyu Tan", "Gang Li", "Zongyi Li", "Haojia Lin", "Guocan Cai", "Yong Mao", "Yunsheng Wu", "Ke Li", "Xing Sun"], "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \\textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \\textbf{Workflow} mode for standard tasks and a \\textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \\textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \\textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.", "AI": {"tldr": "Youtu-Agent是一个模块化LLM代理框架，通过自动化生成和持续进化解决高配置成本和静态能力问题，在多个基准测试中实现最先进性能。", "motivation": "现有LLM代理框架面临高配置成本和静态能力两大挑战，构建高质量代理需要大量手动工作，部署后难以适应动态环境。", "method": "提出结构化配置系统解耦执行环境、工具包和上下文管理；引入工作流模式和元代理模式两种生成范式；建立混合策略优化系统（Agent Practice和Agent RL模块）。", "result": "在WebWalkerQA达到71.47%，GAIA达到72.8%；自动化生成管道工具合成成功率超81%；Practice模块在AIME 2024/2025分别提升2.7%和5.4%；Agent RL训练在7B LLM上实现40%加速，数学和推理能力分别提升35%和21%。", "conclusion": "Youtu-Agent有效解决了LLM代理的配置和适应性问题，通过自动化生成和持续优化实现了显著的性能提升，为构建和进化LLM代理提供了有效解决方案。"}}
{"id": "2512.23941", "pdf": "https://arxiv.org/pdf/2512.23941", "abs": "https://arxiv.org/abs/2512.23941", "authors": ["Conrad Borchers", "Manit Patel", "Seiyon M. Lee", "Anthony F. Botelho"], "title": "Disentangling Learning from Judgment: Representation Learning for Open Response Analytics", "categories": ["cs.CL", "cs.CY"], "comment": "Short research paper accepted at Learning Analytics and Knowledge (LAK '26)", "summary": "Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.", "AI": {"tldr": "论文提出了一个分析框架，将学生作答内容信号与教师评分倾向分离，通过建模教师历史评分作为动态先验，结合文本嵌入表示，量化各信号贡献并可视化模型差异，提升评分透明度和可审计性。", "motivation": "自动评分常常混淆学生作答内容与教师评分倾向，需要一种方法将内容信号与评分者效应分离，使评分判断可见且可审计。", "method": "使用ASSISTments数学作答数据，建模教师历史评分作为动态先验，通过句子嵌入获取文本表示，采用中心化和残差化处理消除提示和教师混杂因素，使用时序验证的线性模型量化信号贡献，并通过投影可视化模型差异。", "result": "教师先验对评分预测影响很大；先验与内容嵌入结合效果最佳(AUC~0.815)，纯内容模型效果明显较弱(AUC~0.626)；调整评分者效应能锐化残差内容表示，保留更多信息维度。", "conclusion": "该框架将嵌入特征转化为学习分析工具，使教师和研究者能够检查评分实践与学生推理学习证据的一致性，为反思和改进评分实践提供实用管道。"}}
{"id": "2512.24679", "pdf": "https://arxiv.org/pdf/2512.24679", "abs": "https://arxiv.org/abs/2512.24679", "authors": ["Pengcheng Xia", "Yixiang Huang", "Chengjin Qin", "Chengliang Liu"], "title": "Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions", "categories": ["cs.AI", "eess.SP"], "comment": "21 pages, 8 figures", "summary": "Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.", "AI": {"tldr": "提出多模态跨域混合融合模型，通过双解耦框架分离模态不变/特定特征和域不变/特定表示，结合跨域混合融合策略和三模态融合机制，在未见工况下实现优越的故障诊断性能。", "motivation": "现有智能故障诊断方法在未见工况下性能显著下降，域自适应方法依赖目标域样本，且大多数研究依赖单模态信号，忽略了多模态信息的互补性。", "method": "开发双解耦框架分离模态不变/特定特征和域不变/特定表示；设计跨域混合融合策略随机混合跨域模态信息；引入三模态融合机制自适应整合多模态异构信息。", "result": "在感应电机故障诊断实验中，该方法在未见恒定和时变工况下均优于先进方法，消融研究验证了各组件和多模态融合的有效性。", "conclusion": "该方法通过多模态信息和域泛化技术的结合，显著提升了故障诊断模型在未知工况下的泛化能力和性能表现。"}}
{"id": "2512.23959", "pdf": "https://arxiv.org/pdf/2512.23959", "abs": "https://arxiv.org/abs/2512.23959", "authors": ["Chulun Zhou", "Chunkang Zhang", "Guoxin Yu", "Fandong Meng", "Jie Zhou", "Wai Lam", "Mo Yu"], "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.", "AI": {"tldr": "HGMem是一种基于超图的记忆机制，通过构建动态的超图结构来捕捉高阶关联，提升多步检索增强生成任务的全局理解和推理能力。", "motivation": "现有RAG系统的记忆模块主要作为被动存储，忽视了原始事实间的高阶关联，导致推理碎片化和全局理解能力弱。", "method": "提出超图记忆机制HGMem，将记忆表示为超图结构，其中超边对应不同的记忆单元，能够渐进形成高阶交互。", "result": "在多个全局理解挑战数据集上的实验表明，HGMem显著提升了多步RAG性能，大幅超越强基线系统。", "conclusion": "超图记忆机制能够将记忆从简单存储扩展为动态表达结构，有效支持复杂推理和全局理解，为后续步骤提供更强的推理支持。"}}
{"id": "2512.24686", "pdf": "https://arxiv.org/pdf/2512.24686", "abs": "https://arxiv.org/abs/2512.24686", "authors": ["Songqi Zhou", "Ruixue Liu", "Boman Su", "Jiazhou Wang", "Yixing Wang", "Benben Jiang"], "title": "BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis", "categories": ["cs.AI", "eess.SY"], "comment": null, "summary": "Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their \"black-box\" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a \"numerical-semantic\" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from \"passive detection\" to \"intelligent diagnosis\" for battery safety management.", "AI": {"tldr": "BatteryAgent：一个结合物理知识特征和大语言模型的分层框架，用于锂离子电池的可解释故障诊断，实现从被动检测到智能诊断的范式转变", "motivation": "现有深度学习方法的黑盒特性阻碍了可解释性，且受限于二分类范式，无法提供根因分析和维护建议", "method": "三层框架：物理感知层（10个电化学特征）、检测归因层（梯度提升决策树+SHAP）、推理诊断层（LLM构建数值-语义桥梁生成诊断报告）", "result": "有效纠正边界样本误分类，AUROC达0.986，显著优于现有方法，实现多类型可解释诊断", "conclusion": "该框架为电池安全管理提供了从被动检测到智能诊断的新范式，结合物理知识与AI推理能力"}}
{"id": "2512.23966", "pdf": "https://arxiv.org/pdf/2512.23966", "abs": "https://arxiv.org/abs/2512.23966", "authors": ["Chen Zhang", "Yang Bai", "Jiahuan Li", "Anchun Gui", "Keheng Wang", "Feifan Liu", "Guanyu Wu", "Yuwei Jiang", "Defei Bu", "Li Wei", "Haihang Jing", "Hongyin Tang", "Xin Chen", "Xiangzhou Huang", "Fengcun Li", "Rongxiang Weng", "Yulei Qian", "Yifan Lu", "Yerui Sun", "Jingang Wang", "Yuchen Xie", "Xunliang Cai"], "title": "Efficient Context Scaling with LongCat ZigZag Attention", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 3 figures, 3 tables", "summary": "We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (e.g., retrieval-augmented generation) and decode-intensive (e.g., tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long-context foundation model that can swiftly process up to 1 million tokens, enabling efficient long-term reasoning and long-horizon agentic capabilities.", "AI": {"tldr": "LoZA是一种稀疏注意力机制，可将全注意力模型转换为稀疏版本，在有限计算预算下实现长上下文场景的显著加速，支持百万token处理。", "motivation": "解决长上下文场景中全注意力模型计算成本高的问题，需要一种高效的稀疏注意力方案来提升处理长序列的效率。", "method": "提出LongCat ZigZag Attention (LoZA)稀疏注意力机制，通过在训练中期应用于LongCat-Flash模型，将其转换为稀疏版本。", "result": "LoZA在预填充密集型（如检索增强生成）和解码密集型（如工具集成推理）场景中都能实现显著加速，支持处理多达100万个token。", "conclusion": "LoZA成功将全注意力模型转化为高效的稀疏版本，为长上下文推理和长视野智能体能力提供了有效的解决方案。"}}
{"id": "2512.24829", "pdf": "https://arxiv.org/pdf/2512.24829", "abs": "https://arxiv.org/abs/2512.24829", "authors": ["Emmanuel Fashae", "Michael Burke", "Leimin Tian", "Lingheng Meng", "Pamela Carreno-Medrano"], "title": "Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences", "categories": ["cs.AI", "cs.HC", "cs.RO"], "comment": "Accepted to the 2026 ACM/IEEE International Conference on Human-Robot Interaction (HRI '26)", "summary": "Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.", "AI": {"tldr": "该研究提出了一个包含四个可解释构念的物体摆放偏好模型：空间实用性、习惯便利性、语义连贯性和常识适宜性，并通过问卷调查验证了这些构念的心理区分度，最后将其集成到MCTS规划器中生成与人类偏好一致的物体摆放方案。", "motivation": "现有的基于人类演示的潜在偏好模型虽然预测有效，但缺乏对人类决策背后可解释因素的深入理解，需要开发更明确的偏好表述方法。", "method": "设计并验证了包含四个构念的自报告问卷（63名参与者在线研究），然后将这些构念集成到蒙特卡洛树搜索（MCTS）规划器中。", "result": "研究确认了四个构念的心理区分度和解释力，MCTS规划器在参与者偏好指导下能够生成与人类生成方案高度一致的合理摆放安排。", "conclusion": "这项工作贡献了一个紧凑、可解释的物体摆放偏好表述框架，并展示了如何将其操作化用于机器人规划，为机器人系统提供了更好的可解释性基础。"}}
{"id": "2512.23971", "pdf": "https://arxiv.org/pdf/2512.23971", "abs": "https://arxiv.org/abs/2512.23971", "authors": ["Zhiming Lin", "Kai Zhao", "Sophie Zhang", "Peilai Yu", "Canran Xiao"], "title": "CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards", "categories": ["cs.CL"], "comment": "AAAI'26 poster", "summary": "Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by enabling LLMs to correct their own mistakes. CEC-Zero synthesizes errorful inputs from clean text, computes cluster-consensus rewards via semantic similarity and candidate agreement, and optimizes the policy with PPO. It outperforms supervised baselines by 10--13 F$_1$ points and strong LLM fine-tunes by 5--8 points across 9 benchmarks, with theoretical guarantees of unbiased rewards and convergence. CEC-Zero establishes a label-free paradigm for robust, scalable CSC, unlocking LLM potential in noisy text pipelines.", "AI": {"tldr": "CEC-Zero是一个无监督的强化学习框架，通过让大语言模型自我纠正错误来解决中文拼写纠错问题，无需人工标注，在多个基准测试中显著超越有监督方法。", "motivation": "大规模中文拼写纠错对现实文本处理至关重要，但现有大语言模型和有监督方法对新错误的鲁棒性不足且依赖昂贵的标注数据。", "method": "从干净文本合成错误输入，通过语义相似性和候选一致性计算聚类共识奖励，使用PPO算法优化策略。", "result": "在9个基准测试中，比有监督基线高出10-13个F1分数，比强LLM微调方法高出5-8个F1分数。", "conclusion": "CEC-Zero为鲁棒、可扩展的中文拼写纠错建立了无标签范式，释放了大语言模型在噪声文本处理中的潜力。"}}
{"id": "2512.24834", "pdf": "https://arxiv.org/pdf/2512.24834", "abs": "https://arxiv.org/abs/2512.24834", "authors": ["Marko Jojic", "Nebojsa Jojic"], "title": "GenZ: Foundational models as latent variable generators within traditional statistical models", "categories": ["cs.AI"], "comment": null, "summary": "We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.", "AI": {"tldr": "GenZ是一个混合模型，通过可解释的语义特征连接基础模型和统计建模，在房价预测和电影推荐任务上显著超越纯基础模型方法", "motivation": "大型语言模型虽然拥有广泛领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式，需要结合统计建模来提升性能", "method": "通过迭代过程发现语义特征描述，使用广义EM算法联合优化语义特征描述符和统计模型参数，将冻结基础模型的分类判断作为潜在二元特征的噪声观测", "result": "房价预测中达到12%相对误差（vs GPT-5的38%）；电影推荐中仅从语义描述实现0.59余弦相似度，相当于传统协同过滤4000用户评分的性能", "conclusion": "该方法成功发现了数据集特定的模式（如建筑细节预测当地房市、系列电影成员预测用户偏好），证明了结合基础模型和统计建模的有效性"}}
{"id": "2512.23988", "pdf": "https://arxiv.org/pdf/2512.23988", "abs": "https://arxiv.org/abs/2512.23988", "authors": ["Zhenyu Zhang", "Shujian Zhang", "John Lambert", "Wenxuan Zhou", "Zhangyang Wang", "Mingqing Chen", "Andrew Hard", "Rajiv Mathews", "Lun Wang"], "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level 'steps' and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.", "AI": {"tldr": "RISE：一个无监督框架，通过稀疏自编码器发现LLM推理过程中的可解释行为向量，实现推理行为的分离和控制。", "motivation": "现有方法依赖人工定义的概念分析LLM推理过程，但难以捕捉完整的推理行为谱系，且许多行为难以在token空间定义。", "method": "将思维链轨迹分割为句子级步骤，在步骤级激活上训练稀疏自编码器(SAE)，发现编码不同推理行为的向量方向。", "result": "成功分离出反思、回溯等可解释行为，可视化显示这些行为在解码器空间中占据可分离区域，可通过干预SAE向量控制推理行为。", "conclusion": "无监督潜在发现方法在解释和控制LLM推理方面具有巨大潜力，能够发现超越人类监督的新行为，如识别信心相关向量控制响应置信度。"}}
{"id": "2512.24853", "pdf": "https://arxiv.org/pdf/2512.24853", "abs": "https://arxiv.org/abs/2512.24853", "authors": ["Koki Suenaga", "Tomohiro Furuta", "Satoshi Ono"], "title": "A study on constraint extraction and exception exclusion in care worker scheduling", "categories": ["cs.AI"], "comment": null, "summary": "Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.", "AI": {"tldr": "提出基于约束模板的方法，用于长期护理机构排班约束条件提取，通过排除异常约束来优化排班质量", "motivation": "长期护理机构的排班条件因机构而异，需要通过与排班管理者访谈来设计特定机构的约束条件，但现有方法缺乏有效提取和排除异常约束的机制", "method": "利用约束模板提取各种组件的组合（如连续工作班次模式、人员组合），通过改变天数、人员数量和提取焦点（模式或频率）来提取多样化约束，并引入排除异常约束的机制", "result": "实验证明该方法成功创建了满足所有硬约束的排班，并通过避免提取异常约束减少了软约束违反次数", "conclusion": "该方法能有效提取设施特定的约束条件并排除异常约束，为护理人员排班提供实用解决方案，相比现有约束提取技术更具优势"}}
{"id": "2512.24000", "pdf": "https://arxiv.org/pdf/2512.24000", "abs": "https://arxiv.org/abs/2512.24000", "authors": ["Gaurab Chhetri", "Subasish Das", "Tausif Islam Chowdhury"], "title": "WISE: Web Information Satire and Fakeness Evaluation", "categories": ["cs.CL"], "comment": "This is the author's preprint. Accepted to WEB&GRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: https://wsdm-conference.org/2026/ Workshop: https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html", "summary": "Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28\\% accuracy and 93.90\\% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.", "AI": {"tldr": "WISE框架评估了8种轻量级Transformer模型在区分假新闻和讽刺新闻的任务上的表现，发现MiniLM模型达到最高准确率87.58%，而RoBERTa-base获得最高ROC-AUC 95.42%，轻量级模型在资源受限环境中具有实用价值。", "motivation": "假新闻和讽刺新闻在语言特征上相似但意图不同，这给区分带来了独特挑战，需要开发有效的检测框架来应对现实世界中的错误信息检测需求。", "method": "使用WISE框架，在Fakeddit数据集的20,000个平衡样本上评估8种轻量级Transformer模型和2个基线模型，采用分层5折交叉验证，使用多种综合指标进行评估。", "result": "MiniLM获得最高准确率87.58%，RoBERTa-base获得最高ROC-AUC 95.42%，DistilBERT在效率与准确性之间达到最佳平衡（86.28%准确率，93.90% ROC-AUC），统计测试显示模型间存在显著性能差异。", "conclusion": "轻量级模型能够匹配甚至超越基线模型性能，为在资源受限环境中部署错误信息检测系统提供了可行的解决方案。"}}
{"id": "2512.24873", "pdf": "https://arxiv.org/pdf/2512.24873", "abs": "https://arxiv.org/abs/2512.24873", "authors": ["Weixun Wang", "XiaoXiao Xu", "Wanhe An", "Fangwen Dai", "Wei Gao", "Yancheng He", "Ju Huang", "Qiang Ji", "Hanqi Jin", "Xiaoyang Li", "Yang Li", "Zhongwen Li", "Shirong Lin", "Jiashun Liu", "Zenan Liu", "Tao Luo", "Dilxat Muhtar", "Yuanbin Qu", "Jiaqiang Shi", "Qinghui Sun", "Yingshui Tan", "Hao Tang", "Runze Wang", "Yi Wang", "Zhaoguo Wang", "Yanan Wu", "Shaopan Xiong", "Binchen Xu", "Xander Xu", "Yuchi Xu", "Qipeng Zhang", "Xixia Zhang", "Haizhou Zhao", "Jie Zhao", "Shuaibing Zhao", "Baihui Zheng", "Jianhui Zheng", "Suhang Zheng", "Yanni Zhu", "Mengze Cai", "Kerui Cao", "Xitong Chen", "Yue Dai", "Lifan Du", "Tao Feng", "Tao He", "Jin Hu", "Yijie Hu", "Ziyu Jiang", "Cheng Li", "Xiang Li", "Jing Liang", "Chonghuan Liu", "ZhenDong Liu", "Haodong Mi", "Yanhu Mo", "Junjia Ni", "Shixin Pei", "Jingyu Shen", "XiaoShuai Song", "Cecilia Wang", "Chaofan Wang", "Kangyu Wang", "Pei Wang", "Tao Wang", "Wei Wang", "Ke Xiao", "Mingyu Xu", "Tiange Xu", "Nan Ya", "Siran Yang", "Jianan Ye", "Yaxing Zang", "Duo Zhang", "Junbo Zhang", "Boren Zheng", "Wanxi Deng", "Ling Pan", "Lin Qu", "Wenbo Su", "Jiamang Wang", "Wei Wang", "Hu Wei", "Minggang Wu", "Cheng Yu", "Bing Zhao", "Zhicheng Zheng", "Bo Zheng"], "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem", "categories": ["cs.AI", "cs.CL"], "comment": "36 pages, 15 figures", "summary": "Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.", "AI": {"tldr": "ALE是一个端到端的智能体开发生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具，并发布了基于ALE训练的ROME智能体模型，在多个基准测试中表现优异。", "motivation": "开源社区缺乏原则性的端到端生态系统来简化智能体开发，需要优化智能体LLM的生产流程。", "method": "开发ALE基础设施，包含三个组件：ROLL（权重优化后训练框架）、ROCK（轨迹生成沙盒环境管理器）、iFlow CLI（高效上下文工程代理框架）；采用数据组合协议合成复杂行为，并提出新颖的基于交互的策略对齐算法IPA。", "result": "发布了ROME开源智能体模型，基于超过100万条轨迹训练，在SWE-bench Verified和Terminal Bench等基准测试中表现出强大性能。", "conclusion": "ALE基础设施有效提升了智能体开发效率，ROME模型的优异性能证明了该生态系统的有效性，为智能体LLM的生产流程优化提供了可靠解决方案。"}}
{"id": "2512.24014", "pdf": "https://arxiv.org/pdf/2512.24014", "abs": "https://arxiv.org/abs/2512.24014", "authors": ["Sijia Chen", "Di Niu"], "title": "iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 6 figures. The source code is publicly available at https://github.com/AgenticFinLab/latent-planning", "summary": "Large language models (LLMs), when guided by explicit textual plans, can perform reliable step-by-step reasoning during problem-solving. However, generating accurate and effective textual plans remains challenging due to LLM hallucinations and the high diversity of task-specific questions. To address this, we draw inspiration from human Implicit Cognition (IC), the subconscious process by which decisions are guided by compact, generalized patterns learned from past experiences without requiring explicit verbalization. We propose iCLP, a novel framework that enables LLMs to adaptively generate latent plans (LPs), which are compact encodings of effective reasoning instructions. iCLP first distills explicit plans from existing step-by-step reasoning trajectories. It then learns discrete representations of these plans via a vector-quantized autoencoder coupled with a codebook. Finally, by fine-tuning LLMs on paired latent plans and corresponding reasoning steps, the models learn to perform implicit planning during reasoning. Experimental results on mathematical reasoning and code generation tasks demonstrate that, with iCLP, LLMs can plan in latent space while reasoning in language space. This approach yields significant improvements in both accuracy and efficiency and, crucially, demonstrates strong cross-domain generalization while preserving the interpretability of chain-of-thought reasoning.", "AI": {"tldr": "iCLP框架通过从人类潜意识认知获得灵感，让大语言模型在潜在空间生成紧凑的隐式计划，在语言空间进行推理，显著提升数学推理和代码生成任务的准确性和效率，并具备强大的跨域泛化能力。", "motivation": "大语言模型在显式文本计划指导下能进行可靠推理，但由于模型幻觉和任务多样性，生成准确有效的文本计划仍具挑战。受人类潜意识认知启发，需要开发更紧凑、泛化性强的计划生成方法。", "method": "提出iCLP框架：1) 从现有逐步推理轨迹中提取显式计划；2) 通过向量量化自编码器和码本学习这些计划的离散表示；3) 在配对潜在计划和推理步骤上微调LLM，使模型学会在推理过程中进行隐式规划。", "result": "实验结果表明，iCLP使LLM能够在潜在空间进行规划，同时在语言空间进行推理，在数学推理和代码生成任务上实现了准确性和效率的显著提升。", "conclusion": "iCLP框架成功实现了LLM的隐式规划能力，不仅提高了性能，还保持了思维链推理的可解释性，并展现出强大的跨领域泛化能力。"}}
{"id": "2512.24896", "pdf": "https://arxiv.org/pdf/2512.24896", "abs": "https://arxiv.org/abs/2512.24896", "authors": ["Andrii Gamalii", "Daniel Górniak", "Robert Nowak", "Bartłomiej Olber", "Krystian Radlak", "Jakub Winter"], "title": "Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing", "categories": ["cs.AI"], "comment": null, "summary": "This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.", "AI": {"tldr": "开发了一个半自动数据标注流水线，通过人机协作方式减少驾驶场景数据标注成本和时间，结合AI自动生成初始标注和人工精调，支持DARTS项目构建波兰驾驶场景数据集。", "motivation": "手动标注多模态驾驶数据成本高、耗时长，需要自动化解决方案来加速大规模数据集构建，支持波兰自动驾驶研究。", "method": "采用人机协作方法，使用3D目标检测算法自动生成初步标注，支持迭代模型重训练，集成数据匿名化和领域适应技术。", "result": "显著节省标注时间，确保跨传感器模态的一致高质量标注，加速了DARTS项目标准化格式数据集的准备。", "conclusion": "该半自动标注流水线成功解决了大规模驾驶数据标注的挑战，为波兰自动驾驶技术研究提供了重要技术基础。"}}
{"id": "2512.24058", "pdf": "https://arxiv.org/pdf/2512.24058", "abs": "https://arxiv.org/abs/2512.24058", "authors": ["Rohit Kumar Salla", "Manoj Saravanan", "Shrikar Reddy Kota"], "title": "Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "5 pages, 4 tables, accepted at AAAI 2026", "summary": "Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.", "AI": {"tldr": "提出了Composite Reliability Score (CRS)框架，将校准、鲁棒性和不确定性量化整合为单一可解释指标，用于评估LLM在关键决策领域的可靠性。", "motivation": "大型语言模型在医疗、法律、金融等关键决策领域应用增多，但其可靠性存在不确定性，存在过度自信错误、输入变化下性能下降和缺乏明确不确定性估计等问题，现有评估方法零散不全面。", "method": "开发了CRS统一评估框架，在五个QA数据集上对十个主流开源LLM进行实验，评估基线性能、扰动影响和校准方法效果。", "result": "CRS提供了稳定的模型排名，发现了单一指标遗漏的隐藏故障模式，显示最可靠的系统在准确性、鲁棒性和校准不确定性之间保持平衡。", "conclusion": "CRS是一个有效的统一评估框架，能够全面评估LLM的可靠性，为关键决策应用中的模型选择提供指导。"}}
{"id": "2512.24940", "pdf": "https://arxiv.org/pdf/2512.24940", "abs": "https://arxiv.org/abs/2512.24940", "authors": ["Augusto B. Corrêa", "Yoav Gelberg", "Luckeciano C. Melo", "Ilia Shumailov", "André G. Pereira", "Yarin Gal"], "title": "Iterative Deployment Improves Planning Skills in LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.", "AI": {"tldr": "论文展示了通过迭代部署大型语言模型并在每次部署中使用用户从前一模型输出中精心筛选的数据进行微调，可以显著改变模型特性。这种方法在规划任务中带来了显著改进，后续模型展现出发现更长规划的涌现泛化能力。理论分析表明这实际上实现了外循环强化学习训练，具有重要的AI安全含义和替代传统强化学习的潜力。", "motivation": "研究探索迭代部署LLMs时使用用户筛选数据微调的机制，旨在理解这种部署方式如何改变模型特性，特别是对规划能力的提升和潜在的AI安全影响。", "method": "通过在多个规划领域测试迭代部署机制，每次使用用户从前一模型部署中精心筛选的数据对后续模型进行微调，并进行理论分析验证其与强化学习的等效性。", "result": "观察到规划技能显著提升，后续模型展现出涌现的泛化能力，能够发现比初始模型长得多的规划方案。理论分析证实迭代部署实现了外循环强化学习训练。", "conclusion": "迭代部署机制实质上是一种隐式强化学习训练方式，具有重要的AI安全意义，因为隐含的奖励函数未明确定义可能带来意外影响，同时这也为传统强化学习提供了一种基于数据筛选的替代训练方案。"}}
{"id": "2512.24092", "pdf": "https://arxiv.org/pdf/2512.24092", "abs": "https://arxiv.org/abs/2512.24092", "authors": ["Mao Zheng", "Zheng Li", "Tao Chen", "Mingyang Song", "Di Wang"], "title": "HY-MT1.5 Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro's performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.", "AI": {"tldr": "HY-MT1.5系列机器翻译模型，包含1.8B和7B参数版本，通过多阶段训练框架实现卓越性能，在多项翻译任务中超越大型开源模型和商业API，接近甚至超越Gemini-3.0-Pro的性能。", "motivation": "开发高性能的机器翻译模型，通过参数效率优化实现在较小模型规模下达到甚至超越大型模型的翻译性能。", "method": "采用多阶段训练框架，包括通用和MT导向的预训练、监督微调、策略蒸馏和强化学习。", "result": "1.8B模型在标准中英和英外翻译任务中超越大型开源模型和商业API，达到Gemini-3.0-Pro约90%性能；7B模型在其规模级别达到新的SOTA，在Flores-200上达到Gemini-3.0-Pro的95%性能，并在WMT25和普通话-少数民族语言测试集上超越Gemini-3.0-Pro。", "conclusion": "HY-MT1.5系列模型提供了在各自参数规模内具有高度竞争力的通用和专业翻译解决方案，支持术语干预、上下文感知翻译和格式保持等高级功能。"}}
{"id": "2512.24957", "pdf": "https://arxiv.org/pdf/2512.24957", "abs": "https://arxiv.org/abs/2512.24957", "authors": ["Yulan Hu", "Xiangwen Zhang", "Sheng Ouyang", "Hao Yi", "Lu Xu", "Qinglin Lang", "Lide Tan", "Xiang Cheng", "Tianchen Ye", "Zhicong Li", "Ge Chen", "Wenjin Yang", "Zheng Pan", "Shaopan Xiong", "Siran Yang", "Ju Huang", "Yan Zhang", "Jiamang Wang", "Yong Liu", "Yinfeng Huang", "Tucheng Lin", "Xin Li", "Ning Guo"], "title": "AMAP Agentic Planning Technical Report", "categories": ["cs.AI"], "comment": null, "summary": "We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.", "AI": {"tldr": "STAgent是一个专门用于时空理解的大语言模型代理，通过十种工具处理受限POI发现和行程规划等复杂任务，在保持通用能力的同时实现复杂推理。", "motivation": "为了解决时空场景下的复杂任务（如受限POI发现和行程规划），需要开发能够与多种工具交互并保持推理能力的专门化代理模型。", "method": "采用三阶段方法：(1)建立支持十多种领域特定工具的稳定工具环境；(2)分层数据筛选框架，以1:10000的比例筛选高质量查询；(3)级联训练流程：种子SFT阶段评估查询难度，第二SFT阶段针对高确定性查询微调，最终RL阶段利用低确定性数据。基于Qwen3-30B-A3B初始化。", "result": "STAgent在TravelBench基准上表现出色，同时在广泛通用基准测试中保持强大的通用能力。", "conclusion": "提出的代理模型方法有效解决了时空理解任务，证明了专门化代理在保持通用能力的同时处理复杂时空推理任务的有效性。"}}
{"id": "2512.24098", "pdf": "https://arxiv.org/pdf/2512.24098", "abs": "https://arxiv.org/abs/2512.24098", "authors": ["Liling Tan"], "title": "Training a Huggingface Model on AWS Sagemaker (Without Tears)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.", "AI": {"tldr": "论文旨在通过集中化必要信息，降低研究人员在AWS SageMaker上训练Hugging Face模型的门槛，实现云计算的民主化。", "motivation": "大型语言模型开发主要依赖资源丰富的研究机构和行业伙伴，缺乏本地计算资源的研究人员转向云服务，但云平台学习曲线陡峭且现有文档存在知识空白。", "method": "通过集中化从零开始在AWS SageMaker上训练Hugging Face模型所需的核心信息，填补现有文档的空白。", "result": "提供了一个集成的解决方案，帮助研究人员克服云平台使用的障碍。", "conclusion": "该演示论文通过信息集中化有效降低了云服务的使用门槛，促进了研究资源的公平获取。"}}
{"id": "2512.25055", "pdf": "https://arxiv.org/pdf/2512.25055", "abs": "https://arxiv.org/abs/2512.25055", "authors": ["Tianzhi He", "Farrokh Jazizadeh"], "title": "Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.", "AI": {"tldr": "本研究提出了基于大型语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑的上下文感知能源管理，并在多个真实数据集上验证了其性能。", "motivation": "解决现有能源管理系统在上下文感知、自然语言交互和智能数据分析方面的局限性，提升建筑能源管理的智能化水平。", "method": "提出包含感知、中央控制和行动三个模块的框架，形成闭环反馈系统。使用120个用户查询在4个真实住宅能源数据集上进行评估，测试延迟、功能、能力、准确性和成本效益等指标。", "result": "在设备控制(86%)、记忆相关任务(97%)、调度自动化(74%)和能源分析(77%)方面表现良好，但成本估算任务准确率较低(49%)。通过ANOVA测试验证了框架的泛化能力。", "conclusion": "该研究为基于LLM的BEMS AI代理提供了正式的评估基准，揭示了响应准确性与计算效率之间的权衡关系，并指出了未来研究方向。"}}
{"id": "2512.24143", "pdf": "https://arxiv.org/pdf/2512.24143", "abs": "https://arxiv.org/abs/2512.24143", "authors": ["Adi Shnaidman", "Erin Feiglin", "Osher Yaari", "Efrat Mentel", "Amit Levi", "Raz Lapid"], "title": "Activation Steering for Masked Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steering in MDLMs remain largely unexplored. We present an activation-steering framework for MDLMs that computes layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. These directions are applied at every reverse-diffusion step, yielding an efficient inference-time control mechanism. Experiments on LLaDA-8B-Instruct demonstrate reliable modulation of high-level attributes, with ablations examining the effects of steering across transformer sub-modules and token scope (prompt vs.\\ response).", "AI": {"tldr": "提出了一个基于激活引导的推理时控制框架，用于掩码扩散语言模型，通过对比样本计算层级引导向量，无需模拟去噪轨迹即可实现高效属性调节", "motivation": "掩码扩散语言模型在推理时缺乏有效的控制和引导机制，现有方法对此探索不足", "method": "使用对比样本通过单次前向传播计算层级引导向量，并在每个反向扩散步骤应用这些方向", "result": "在LLaDA-8B-Instruct模型上展示了可靠的高层属性调节能力，并通过消融实验分析了不同transformer子模块和token范围的影响", "conclusion": "该方法为掩码扩散语言模型提供了高效的推理时控制机制，能够有效调节文本生成的高层属性"}}
{"id": "2512.24149", "pdf": "https://arxiv.org/pdf/2512.24149", "abs": "https://arxiv.org/abs/2512.24149", "authors": ["Changhao Song", "Yazhou Zhang", "Hui Gao", "Chang Yang", "Peng Zhang"], "title": "Large Emotional World Model", "categories": ["cs.CL"], "comment": null, "summary": "World Models serve as tools for understanding the current state of the world and predicting its future dynamics, with broad application potential across numerous fields. As a key component of world knowledge, emotion significantly influences human decision-making. While existing Large Language Models (LLMs) have shown preliminary capability in capturing world knowledge, they primarily focus on modeling physical-world regularities and lack systematic exploration of emotional factors. In this paper, we first demonstrate the importance of emotion in understanding the world by showing that removing emotionally relevant information degrades reasoning performance. Inspired by theory of mind, we further propose a Large Emotional World Model (LEWM). Specifically, we construct the Emotion-Why-How (EWH) dataset, which integrates emotion into causal relationships and enables reasoning about why actions occur and how emotions drive future world states. Based on this dataset, LEWM explicitly models emotional states alongside visual observations and actions, allowing the world model to predict both future states and emotional transitions. Experimental results show that LEWM more accurately predicts emotion-driven social behaviors while maintaining comparable performance to general world models on basic tasks.", "AI": {"tldr": "该论文提出了一个大型情感世界模型（LEWM），通过整合情感因素来改进世界模型的情感推理能力，在Emotion-Why-How数据集上验证了情感信息对世界理解的重要性。", "motivation": "现有大语言模型主要关注物理世界规律建模，缺乏对情感因素的系统性探索，而情感作为世界知识的重要组成部分显著影响人类决策。", "method": "基于心智理论，构建Emotion-Why-How数据集整合情感与因果关系；提出LEWM模型，同时建模情感状态、视觉观察和动作，预测未来状态和情感转变。", "result": "实验结果显示LEWM能更准确预测情感驱动的社会行为，同时在基础任务上保持与通用世界模型相当的性能。", "conclusion": "情感是世界理解的关键因素，LEWM通过显式建模情感状态有效提升了世界模型的情感推理能力，为情感智能系统的发展提供了新思路。"}}
{"id": "2512.24157", "pdf": "https://arxiv.org/pdf/2512.24157", "abs": "https://arxiv.org/abs/2512.24157", "authors": ["Xinzhang Liu", "Chao Wang", "Zhihao Yang", "Zhuo Jiang", "Xuncheng Zhao", "Haoran Wang", "Lei Li", "Dongdong He", "Luobin Liu", "Kaizhe Yuan", "Han Gao", "Zihan Wang", "Yitong Yao", "Sishi Xiong", "Wenmin Deng", "Haowei He", "Kaidong Yu", "Yu Zhao", "Ruiyu Fang", "Yuhao Jiang", "Yingyan Li", "Xiaohui Hu", "Xi Yu", "Jingqi Li", "Yanwei Liu", "Qingli Li", "Xinyu Shi", "Junhao Niu", "Chengnuo Huang", "Yao Xiao", "Ruiwen Wang", "Fengkai Li", "Luwen Pu", "Kaipeng Jia", "Fubei Yao", "Yuyao Huang", "Xuewei He", "Zhuoru Jiang", "Ruiting Song", "Rui Xue", "Qiyi Xie", "Jie Zhang", "Zilu Huang", "Zhaoxi Zhang", "Zhilong Lu", "Yanhan Zhang", "Yin Zhang", "Yanlei Xue", "Zhu Yuan", "Teng Su", "Xin Jiang", "Shuangyong Song", "Yongxiang Li", "Xuelong Li"], "title": "Training Report of TeleChat3-MoE", "categories": ["cs.CL"], "comment": null, "summary": "TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.", "AI": {"tldr": "TeleChat3-MoE是基于昇腾NPU集群端到端训练的大语言模型系列，采用混合专家架构，参数量从1050亿到超过1万亿。本技术报告主要介绍了支持前沿模型规模可靠高效扩展的基础设施，包括数值精度验证、性能优化、并行化框架和集群级优化方法。", "motivation": "为了在硬件生态系统中可靠高效地扩展到前沿规模的大语言模型训练，需要建立系统性的基础设施支持，解决大规模训练中的数值精度、性能瓶颈和并行化配置等挑战。", "method": "采用算子级和端到端数值精度验证方法确保硬件平台一致性；引入交错流水线调度、注意力感知数据调度、分层重叠通信和DVM算子融合等性能优化技术；提出基于分析估计和整数线性规划的系统性并行化框架；实施集群级优化解决主机和设备瓶颈。", "result": "这些基础设施改进在包含数千设备的集群上实现了显著的吞吐量提升和接近线性的扩展性能，为大规模语言模型开发提供了坚实基础。", "conclusion": "TeleChat3-MoE的基础设施创新为在昇腾NPU硬件生态系统中进行大规模语言模型训练提供了可靠的技术支撑，通过系统性的方法解决了大规模分布式训练的关键技术挑战。"}}
{"id": "2512.24181", "pdf": "https://arxiv.org/pdf/2512.24181", "abs": "https://arxiv.org/abs/2512.24181", "authors": ["Qipeng Wang", "Rui Sheng", "Yafei Li", "Huamin Qu", "Yushi Sun", "Min Zhu"], "title": "MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.", "AI": {"tldr": "MedKGI是一个基于医学知识图谱的临床诊断框架，通过约束推理、信息增益问题选择和结构化状态跟踪，解决了LLM在临床诊断中的幻觉、低效提问和对话不一致问题，显著提升了诊断准确性和效率。", "motivation": "当前大型语言模型在临床诊断中存在三个关键问题：生成幻觉医疗内容、提出冗余低效问题、多轮对话中失去连贯性导致矛盾结论，无法模拟真实的临床迭代诊断推理过程。", "method": "提出MedKGI框架：1) 集成医学知识图谱约束推理到验证医学本体；2) 基于信息增益选择问题以最大化诊断效率；3) 采用OSCE格式结构化状态保持多轮证据跟踪一致性。", "result": "在临床基准测试中，MedKGI在诊断准确性和询问效率方面均优于强LLM基线，平均提高对话效率30%，同时保持最先进的准确性。", "conclusion": "MedKGI通过知识图谱约束、信息增益优化和结构化状态管理，有效解决了LLM在临床诊断中的核心问题，为构建更可靠的AI辅助诊断系统提供了有效框架。"}}
{"id": "2512.24235", "pdf": "https://arxiv.org/pdf/2512.24235", "abs": "https://arxiv.org/abs/2512.24235", "authors": ["May Bashendy", "Walid Massoud", "Sohaila Eltanbouly", "Salam Albatarni", "Marwan Sayed", "Abrar Abir", "Houda Bouamor", "Tamer Elsayed"], "title": "LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring", "categories": ["cs.CL"], "comment": null, "summary": "Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.", "AI": {"tldr": "LAILA：目前最大的公开阿拉伯语自动作文评分数据集，包含7,859篇作文，涵盖七个评分维度，填补了阿拉伯语AES研究的数据空白", "motivation": "阿拉伯语自动作文评分研究因缺乏公开数据集而受限，需要构建大规模标注数据集来支持相关研究发展", "method": "构建LAILA数据集，包含7,859篇阿拉伯语作文，标注整体分数和七个特质分数（相关性、组织结构、词汇、风格、发展、格式、语法），使用最先进的阿拉伯语和英语模型进行基准测试", "result": "成功创建了最大的公开阿拉伯语AES数据集，提供了在特定提示和跨提示设置下的基准性能结果", "conclusion": "LAILA数据集满足了阿拉伯语AES研究的关键需求，为开发稳健的评分系统提供了重要支持"}}
{"id": "2512.24259", "pdf": "https://arxiv.org/pdf/2512.24259", "abs": "https://arxiv.org/abs/2512.24259", "authors": ["Michael E. Rose", "Mainak Ghosh", "Sebastian Erhardt", "Cheng Li", "Erik Buunk", "Dietmar Harhoff"], "title": "Tracing the Flow of Knowledge From Science to Technology Using Deep Learning", "categories": ["cs.CL"], "comment": "4 tables, 7 figures", "summary": "We develop a language similarity model suitable for working with patents and scientific publications at the same time. In a horse race-style evaluation, we subject eight language (similarity) models to predict credible Patent-Paper Citations. We find that our Pat-SPECTER model performs best, which is the SPECTER2 model fine-tuned on patents. In two real-world scenarios (separating patent-paper-pairs and predicting patent-paper-pairs) we demonstrate the capabilities of the Pat-SPECTER. We finally test the hypothesis that US patents cite papers that are semantically less similar than in other large jurisdictions, which we posit is because of the duty of candor. The model is open for the academic community and practitioners alike.", "AI": {"tldr": "开发了适用于专利和科学文献的语言相似性模型Pat-SPECTER，在预测专利-论文引用方面表现最佳，并验证了美国专利因诚信义务而引用语义相似度较低论文的假设", "motivation": "需要一种能够同时处理专利和科学文献的语言相似性模型，以准确预测专利与论文之间的引用关系", "method": "基于SPECTER2模型在专利数据上进行微调得到Pat-SPECTER模型，通过马赛式评估比较8种语言相似性模型在预测专利-论文引用方面的性能", "result": "Pat-SPECTER模型在预测可信专利-论文引用方面表现最佳，在两种实际场景中展示了强大能力，验证了美国专利引用论文语义相似度较低的假设", "conclusion": "微调后的Pat-SPECTER模型是处理专利和文献相似性分析的有效工具，美国专利因诚信义务要求而倾向于引用语义相关性较低的论文"}}
{"id": "2512.24265", "pdf": "https://arxiv.org/pdf/2512.24265", "abs": "https://arxiv.org/abs/2512.24265", "authors": ["Ziqing Fan", "Yuqiao Xian", "Yan Sun", "Li Shen"], "title": "Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in embeddings, which can be roughly categorized into quality and diversity metrics. Due to the high computational cost when applied to trillion-scale token pre-training datasets such as FineWeb and DCLM, these two or more types of metrics are rarely considered jointly in a single selection process. However, in our empirical study, selecting samples based on quality metrics exhibit severe diminishing returns during long-term pre-training, while selecting on diversity metrics removes too many valuable high-quality samples, both of which limit pre-trained LLMs' capabilities. Therefore, we introduce DATAMASK, a novel and efficient joint learning framework designed for large-scale pre-training data selection that can simultaneously optimize multiple types of metrics in a unified process, with this study focusing specifically on quality and diversity metrics. DATAMASK approaches the selection process as a mask learning problem, involving iterative sampling of data masks, computation of policy gradients based on predefined objectives with sampled masks, and updating of mask sampling logits. Through policy gradient-based optimization and various acceleration enhancements, it significantly reduces selection time by 98.9% compared to greedy algorithm, enabling our study to explore joint learning within trillion-scale tokens. With DATAMASK, we select a subset of about 10% from the 15 trillion-token FineWeb dataset, termed FineWeb-Mask. Evaluated across 12 diverse tasks, we achieves significant improvements of 3.2% on a 1.5B dense model and 1.9% on a 7B MoE model.", "AI": {"tldr": "DATAMASK是一个高效的大规模预训练数据选择框架，通过策略梯度优化同时考虑质量和多样性指标，从15万亿token数据集中选出10%的子集，显著提升模型性能并减少98.9%的选择时间", "motivation": "传统数据选择方法单独使用质量或多样性指标存在局限性：质量指标选择在长期预训练中收益递减，多样性指标选择会移除过多高质量样本，限制了预训练LLM的能力", "method": "将数据选择问题建模为掩码学习问题，通过迭代采样数据掩码、基于预定义目标计算策略梯度、更新掩码采样逻辑，采用策略梯度优化和多种加速增强技术", "result": "从FineWeb数据集中选择约10%的子集FineWeb-Mask，在12个不同任务上评估，1.5B密集模型提升3.2%，7B MoE模型提升1.9%，选择时间比贪心算法减少98.9%", "conclusion": "DATAMASK框架能够在大规模预训练数据选择中有效联合优化多个指标，解决了传统方法的局限性，显著提升了训练效率和模型性能"}}
{"id": "2512.24289", "pdf": "https://arxiv.org/pdf/2512.24289", "abs": "https://arxiv.org/abs/2512.24289", "authors": ["Jonathan Schmoll", "Adam Jatowt"], "title": "Automated Analysis of Sustainability Reports: Using Large Language Models for the Extraction and Prediction of EU Taxonomy-Compliant KPIs", "categories": ["cs.CL"], "comment": null, "summary": "The manual, resource-intensive process of complying with the EU Taxonomy presents a significant challenge for companies. While Large Language Models (LLMs) offer a path to automation, research is hindered by a lack of public benchmark datasets. To address this gap, we introduce a novel, structured dataset from 190 corporate reports, containing ground-truth economic activities and quantitative Key Performance Indicators (KPIs). We use this dataset to conduct the first systematic evaluation of LLMs on the core compliance workflow. Our results reveal a clear performance gap between qualitative and quantitative tasks. LLMs show moderate success in the qualitative task of identifying economic activities, with a multi-step agentic framework modestly enhancing precision. Conversely, the models comprehensively fail at the quantitative task of predicting financial KPIs in a zero-shot setting. We also discover a paradox, where concise metadata often yields superior performance to full, unstructured reports, and find that model confidence scores are poorly calibrated. We conclude that while LLMs are not ready for full automation, they can serve as powerful assistive tools for human experts. Our dataset provides a public benchmark for future research.", "AI": {"tldr": "该研究针对欧盟分类法合规自动化需求，创建了首个公开数据集并评估了大语言模型在定性经济活动识别和定量KPI预测任务中的表现，发现模型在定性任务中表现中等但在定量任务中完全失败，指出LLMs目前适合作为辅助工具而非完全自动化解决方案。", "motivation": "欧盟分类法合规流程手动操作成本高昂，但缺乏公开基准数据集阻碍了LLM自动化研究的发展", "method": "从190份企业报告中构建结构化数据集，包含真实经济活动和定量KPI数据，并首次系统评估LLM在核心合规工作流中的表现", "result": "定性任务（经济活动识别）表现中等，多步骤智能框架略微提升精度；定量任务（KPI预测）在零样本设置下完全失败；发现简洁元数据比完整非结构化报告表现更好的悖论；模型置信度校准不佳", "conclusion": "LLM尚未准备好完全自动化，但可作为人类专家的强大辅助工具；提供的数据集为未来研究建立了公共基准"}}
{"id": "2512.24297", "pdf": "https://arxiv.org/pdf/2512.24297", "abs": "https://arxiv.org/abs/2512.24297", "authors": ["Meiqi Chen", "Fandong Meng", "Jie Zhou"], "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking", "categories": ["cs.CL"], "comment": null, "summary": "Complex reasoning problems often involve implicit spatial, geometric, and structural relationships that are not explicitly encoded in text. While recent reasoning models have achieved strong performance across many domains, purely text-based reasoning struggles to represent global structural constraints in complex settings. In this paper, we introduce FIGR, which integrates active visual thinking into multi-turn reasoning via end-to-end reinforcement learning. FIGR externalizes intermediate structural hypotheses by constructing visual representations during problem solving. By adaptively regulating when and how visual reasoning should be invoked, FIGR enables more stable and coherent reasoning over global structural properties that are difficult to capture from text alone. Experiments on challenging mathematical reasoning benchmarks demonstrate that FIGR outperforms strong text-only chain-of-thought baselines. In particular, FIGR improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME, highlighting the effectiveness of figure-guided multimodal reasoning in enhancing the stability and reliability of complex reasoning.", "AI": {"tldr": "FIGR模型通过强化学习将视觉思维整合到多轮推理中，构建视觉表示来外化中间结构假设，在数学推理基准上显著优于纯文本推理方法。", "motivation": "复杂推理问题常涉及文本中未明确编码的空间、几何和结构关系，纯文本推理难以捕捉全局结构约束。", "method": "通过端到端强化学习集成主动视觉思维，在问题解决过程中构建视觉表示，自适应调节视觉推理的时机和方式。", "result": "在AIME 2025上提升基础模型13.12%，在BeyondAIME上提升11.00%，显著提高了复杂推理的稳定性和可靠性。", "conclusion": "视觉引导的多模态推理能有效增强复杂推理的稳定性和可靠性，为解决隐含结构关系的推理问题提供了新途径。"}}
{"id": "2512.24314", "pdf": "https://arxiv.org/pdf/2512.24314", "abs": "https://arxiv.org/abs/2512.24314", "authors": ["Shupeng Li", "Weipeng Lu", "Linyun Liu", "Chen Lin", "Shaofei Li", "Zhendong Tan", "Hanjun Zhong", "Yucheng Zeng", "Chenghao Zhu", "Mengyue Liu", "Daxiang Dong", "Jianmin Wu", "Yunting Xiao", "Annan Li", "Danyu Liu", "Jingnan Zhang", "Licen Liu", "Dawei Yin", "Dou Shen"], "title": "QianfanHuijin Technical Report: A Novel Multi-Stage Training Paradigm for Finance Industrial LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Domain-specific enhancement of Large Language Models (LLMs) within the financial context has long been a focal point of industrial application. While previous models such as BloombergGPT and Baichuan-Finance primarily focused on knowledge enhancement, the deepening complexity of financial services has driven a growing demand for models that possess not only domain knowledge but also robust financial reasoning and agentic capabilities. In this paper, we present QianfanHuijin, a financial domain LLM, and propose a generalizable multi-stage training paradigm for industrial model enhancement.\n  Our approach begins with Continual Pre-training (CPT) on financial corpora to consolidate the knowledge base. This is followed by a fine-grained Post-training pipeline designed with increasing specificity: starting with Financial SFT, progressing to Finance Reasoning RL and Finance Agentic RL, and culminating in General RL aligned with real-world business scenarios. Empirical results demonstrate that QianfanHuijin achieves superior performance across various authoritative financial benchmarks. Furthermore, ablation studies confirm that the targeted Reasoning RL and Agentic RL stages yield significant gains in their respective capabilities. These findings validate our motivation and suggest that this fine-grained, progressive post-training methodology is poised to become a mainstream paradigm for various industrial-enhanced LLMs.", "AI": {"tldr": "该论文提出了QianfanHuijin金融大语言模型，通过多阶段训练范式（持续预训练+细粒度后训练）来增强金融领域的知识、推理和代理能力，在金融基准测试中表现优异。", "motivation": "现有金融大模型主要关注知识增强，但随着金融服务复杂度的加深，需要同时具备领域知识、金融推理能力和代理能力的大模型。", "method": "采用多阶段训练范式：1）金融语料持续预训练巩固知识基础；2）细粒度后训练包括金融SFT、金融推理RL、金融代理RL，最后是与实际业务场景对齐的通用RL。", "result": "QianfanHuijin在多个权威金融基准测试中表现优异，消融研究证实推理RL和代理RL阶段分别显著提升了相应能力。", "conclusion": "这种细粒度的渐进式后训练方法有望成为各种工业增强大模型的主流范式，验证了研究动机的有效性。"}}
{"id": "2512.24329", "pdf": "https://arxiv.org/pdf/2512.24329", "abs": "https://arxiv.org/abs/2512.24329", "authors": ["Keito Inoshita", "Shinnosuke Mizuno"], "title": "World model inspired sarcasm reasoning with large language model agents", "categories": ["cs.CL"], "comment": null, "summary": "Sarcasm understanding is a challenging problem in natural language processing, as it requires capturing the discrepancy between the surface meaning of an utterance and the speaker's intentions as well as the surrounding social context. Although recent advances in deep learning and Large Language Models (LLMs) have substantially improved performance, most existing approaches still rely on black-box predictions of a single model, making it difficult to structurally explain the cognitive factors underlying sarcasm. Moreover, while sarcasm often emerges as a mismatch between semantic evaluation and normative expectations or intentions, frameworks that explicitly decompose and model these components remain limited. In this work, we reformulate sarcasm understanding as a world model inspired reasoning process and propose World Model inspired SArcasm Reasoning (WM-SAR), which decomposes literal meaning, context, normative expectation, and intention into specialized LLM-based agents. The discrepancy between literal evaluation and normative expectation is explicitly quantified as a deterministic inconsistency score, and together with an intention score, these signals are integrated by a lightweight Logistic Regression model to infer the final sarcasm probability. This design leverages the reasoning capability of LLMs while maintaining an interpretable numerical decision structure. Experiments on representative sarcasm detection benchmarks show that WM-SAR consistently outperforms existing deep learning and LLM-based methods. Ablation studies and case analyses further demonstrate that integrating semantic inconsistency and intention reasoning is essential for effective sarcasm detection, achieving both strong performance and high interpretability.", "AI": {"tldr": "WM-SAR：基于世界模型推理的讽刺理解框架，通过分解语义、语境、规范期望和意图为专门LLM代理，实现高性能且可解释的讽刺检测", "motivation": "现有讽刺理解方法依赖黑盒模型，难以结构化解释认知因素；讽刺通常表现为语义评价与规范期望/意图之间的不匹配，但缺乏明确分解建模这些组件的框架", "method": "将讽刺理解重新表述为世界模型启发的推理过程，分解字面意义、语境、规范期望和意图为专门LLM代理，量化字面评价与规范期望的不一致性分数，结合意图分数，通过轻量级逻辑回归模型集成这些信号推断最终讽刺概率", "result": "在代表性讽刺检测基准测试中，WM-SAR持续优于现有的深度学习和LLM方法；消融研究和案例分析表明，整合语义不一致性和意图推理对于有效的讽刺检测至关重要", "conclusion": "WM-SAR框架既利用了LLM的推理能力，又保持了可解释的数值决策结构，实现了强性能和高度可解释性的双重目标，为讽刺理解提供了新的结构化方法"}}
{"id": "2512.24373", "pdf": "https://arxiv.org/pdf/2512.24373", "abs": "https://arxiv.org/abs/2512.24373", "authors": ["Waheed Ahmed Abro", "Zied Bouraoui"], "title": "Skim-Aware Contrastive Learning for Efficient Document Representation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although transformer-based models have shown strong performance in word- and sentence-level tasks, effectively representing long documents, especially in fields like law and medicine, remains difficult. Sparse attention mechanisms can handle longer inputs, but are resource-intensive and often fail to capture full-document context. Hierarchical transformer models offer better efficiency but do not clearly explain how they relate different sections of a document. In contrast, humans often skim texts, focusing on important sections to understand the overall message. Drawing from this human strategy, we introduce a new self-supervised contrastive learning framework that enhances long document representation. Our method randomly masks a section of the document and uses a natural language inference (NLI)-based contrastive objective to align it with relevant parts while distancing it from unrelated ones. This mimics how humans synthesize information, resulting in representations that are both richer and more computationally efficient. Experiments on legal and biomedical texts confirm significant gains in both accuracy and efficiency.", "AI": {"tldr": "提出基于人类略读策略的自监督对比学习框架，通过随机掩码文档段落并使用NLI对比目标来增强长文档表示，在法学和生物医学文本上实现了精度和效率的双重提升", "motivation": "尽管基于Transformer的模型在词级和句级任务表现良好，但在法律和医学等领域的长文档表示方面仍存在困难。稀疏注意力机制资源密集且难以捕获完整文档上下文，分层Transformer模型效率虽好但无法清晰解释文档不同部分的关系", "method": "受人类略读文本策略启发，提出自监督对比学习框架：随机掩码文档段落，使用基于自然语言推理(NLI)的对比目标，将被掩码段落与相关部分对齐，同时与不相关部分保持距离", "result": "在法学和生物医学文本上的实验证实了该方法在准确性和效率方面的显著提升", "conclusion": "该方法模拟人类信息整合方式，产生了既更丰富又计算效率更高的文档表示，有效解决了长文档表示难题"}}
{"id": "2512.24410", "pdf": "https://arxiv.org/pdf/2512.24410", "abs": "https://arxiv.org/abs/2512.24410", "authors": ["Chester Palen-Michel", "Constantine Lignos"], "title": "Comparing Approaches to Automatic Summarization in Less-Resourced Languages", "categories": ["cs.CL", "cs.AI"], "comment": "Under review", "summary": "Automatic text summarization has achieved high performance in high-resourced languages like English, but comparatively less attention has been given to summarization in less-resourced languages. This work compares a variety of different approaches to summarization from zero-shot prompting of LLMs large and small to fine-tuning smaller models like mT5 with and without three data augmentation approaches and multilingual transfer. We also explore an LLM translation pipeline approach, translating from the source language to English, summarizing and translating back. Evaluating with five different metrics, we find that there is variation across LLMs in their performance across similar parameter sizes, that our multilingual fine-tuned mT5 baseline outperforms most other approaches including zero-shot LLM performance for most metrics, and that LLM as judge may be less reliable on less-resourced languages.", "AI": {"tldr": "该研究比较了多种低资源语言文本摘要方法，包括零样本LLM提示、微调mT5模型、数据增强和多语言迁移，发现微调mT5在大多数指标上优于其他方法，且LLM作为评估器在低资源语言上可靠性较低。", "motivation": "自动文本摘要在高资源语言（如英语）中表现良好，但对低资源语言的摘要研究相对较少，需要探索有效的解决方案。", "method": "比较了多种方法：零样本提示不同规模的LLM、微调mT5模型（使用和不使用三种数据增强方法及多语言迁移）、LLM翻译管道方法（翻译到英语→摘要→翻译回原语言）。使用五种不同指标进行评估。", "result": "发现不同LLM在相似参数规模下性能存在差异；多语言微调mT5基线在大多数指标上优于其他方法（包括零样本LLM）；LLM作为评估器在低资源语言上可靠性较低。", "conclusion": "对于低资源语言的文本摘要任务，微调多语言模型（如mT5）比零样本LLM方法更有效，且需要更可靠的评估方法来准确评估低资源语言的摘要质量。"}}
{"id": "2512.24459", "pdf": "https://arxiv.org/pdf/2512.24459", "abs": "https://arxiv.org/abs/2512.24459", "authors": ["Michael E. Rose", "Nils A. Herrmann", "Sebastian Erhardt"], "title": "Cleaning English Abstracts of Scientific Publications", "categories": ["cs.CL"], "comment": "2 tables, 2 figures", "summary": "Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.", "AI": {"tldr": "开发了一个开源语言模型，用于自动清理科学摘要中的无关信息（如版权声明、章节标题等），提高文本分析的准确性。", "motivation": "科学摘要中常包含无关信息（版权声明、元数据等），这些内容会扭曲下游文本分析（如文档相似性和文本嵌入分析）的结果。", "method": "构建了一个开源且易于集成的语言模型，专门用于识别和清除英文科学摘要中的无关内容。", "result": "该模型保守且精确，能够改变清理后摘要的相似性排序，并提升标准长度嵌入的信息含量。", "conclusion": "该模型有效解决了科学摘要中的信息污染问题，提升了文本分析的质量和可靠性。"}}
{"id": "2512.24460", "pdf": "https://arxiv.org/pdf/2512.24460", "abs": "https://arxiv.org/abs/2512.24460", "authors": ["Titas Ramancauskas", "Kotryna Ramancauske"], "title": "IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.\n  Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.", "AI": {"tldr": "开发了一个基于AI的雅思写作备考平台，使用DistilBERT模型提供自动评分和个性化反馈，相比传统规则方法显著提升评分准确性，但作为人工教学的补充效果更佳", "motivation": "传统雅思备考方法缺乏针对雅思写作评分标准的个性化反馈，需要开发能够提供针对性指导的智能平台", "method": "采用设计研究(DBR)方法迭代开发，从规则基础方法转向基于DistilBERT变换器模型的回归评分系统，结合自适应反馈机制", "result": "DistilBERT模型显著改善评分性能(MAE=0.66，R²为正)，自适应反馈使分数平均提升0.060分(p=0.011)，但效果因复习策略而异", "conclusion": "自动反馈功能最适合作为人工教学的补充，表面层次修正比激进的结构干预更可靠，未来需要针对高分作文评估和官方考官验证进行深入研究"}}
{"id": "2512.24517", "pdf": "https://arxiv.org/pdf/2512.24517", "abs": "https://arxiv.org/abs/2512.24517", "authors": ["Fabian Retkowski", "Alexander Waibel"], "title": "Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech", "categories": ["cs.CL"], "comment": null, "summary": "Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.", "AI": {"tldr": "该论文提出了语音转录文本的段落分割方法，建立了首个语音段落分割基准数据集TEDPara和YTSegPara，开发了基于约束解码的LLM段落分割技术，并提出了高效的MiniSeg模型实现段落和章节的联合预测。", "motivation": "自动语音转录通常产生无结构的词流，降低了可读性和再利用性。传统语音处理缺乏段落分割这一关键结构化步骤，且文本分割领域缺乏稳健的自然语言基准。", "method": "1) 建立人类标注的TEDPara和合成标签的YTSegPara基准数据集；2) 提出约束解码方法让大语言模型插入段落分隔符同时保留原始转录；3) 开发紧凑模型MiniSeg实现段落分割，并扩展为层次化模型联合预测章节和段落。", "result": "成功建立了首个语音段落分割基准数据集，提出的约束解码方法实现了忠实、句子对齐的评估，MiniSeg模型在准确率上达到state-of-the-art，且计算成本极低。", "conclusion": "该研究填补了语音处理与文本分割交叉领域的空白，将段落分割确立为语音处理中标准化、实用的任务，为语音转录文本的结构化处理提供了有效解决方案。"}}
{"id": "2512.24556", "pdf": "https://arxiv.org/pdf/2512.24556", "abs": "https://arxiv.org/abs/2512.24556", "authors": ["Muhammad Abdullahi Said", "Muhammad Sammani Sani"], "title": "Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1,440 evaluations, we tested the non-linear interaction between language (English vs. Hausa) and temporal framing. Our results challenge the prevailing multilingual safety gap narrative. Instead of a simple degradation in low-resource settings, we identified a mechanism of Complex Interference where safety is determined by the intersection of variables. While models exhibited a Reverse Linguistic with Claude 4.5 Opus proving significantly safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal they suffered catastrophic failures in temporal reasoning. We report a profound Temporal Asymmetry, where past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). The magnitude of this volatility is illustrated by a 9.2x disparity between the safest and most vulnerable configurations, proving that safety is not a fixed property but a context-dependent state. We conclude that current models rely on superficial heuristics rather than robust semantic understanding, creating Safety Pockets that leave Global South users exposed to localized harms. We propose Invariant Alignment as a necessary paradigm shift to ensure safety stability across linguistic and temporal shifts.", "AI": {"tldr": "研究发现大语言模型在多语言安全对齐中存在复杂干扰现象，而非简单的性能退化，安全性能受语言和时态框架交互影响，存在显著的时间不对称性和安全漏洞。", "motivation": "随着大语言模型融入关键基础设施，需要验证安全对齐是否能在英语以外的语言中零样本迁移，特别是针对西非等低资源语言的威胁场景。", "method": "使用基于西非威胁场景的HausaSafety对抗数据集，采用2×4因子设计对三个先进模型（GPT-5.1、Gemini 3 Pro、Claude 4.5 Opus）进行1,440次评估，测试语言（英语vs豪萨语）与时态框架的非线性交互作用。", "result": "发现复杂干扰机制而非简单的安全性能退化，Claude 4.5 Opus在豪萨语中安全性更高（45.0% vs 36.7%），但存在灾难性时间推理失败。过去时框架绕过防御（15.6%安全），未来时场景触发过度保守拒绝（57.2%安全），最安全与最脆弱配置相差9.2倍。", "conclusion": "当前模型依赖表面启发式而非稳健语义理解，形成安全漏洞使全球南方用户面临本地化危害。提出不变对齐作为必要范式转变，确保跨语言和时态变化的安全稳定性。"}}
{"id": "2512.24562", "pdf": "https://arxiv.org/pdf/2512.24562", "abs": "https://arxiv.org/abs/2512.24562", "authors": ["Chaodong Tong", "Qi Zhang", "Jiayang Gao", "Lei Jiang", "Yanbing Liu", "Nannan Sun"], "title": "HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering", "categories": ["cs.CL"], "comment": "13 pages, 5 figures", "summary": "Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \\textbf{HaluNet}, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.", "AI": {"tldr": "HaluNet是一个轻量级可训练的神经网络框架，通过整合多粒度token级不确定性和语义嵌入，实现高效的单次幻觉检测，在多个QA数据集上表现出色。", "motivation": "LLM在问答中容易产生幻觉（事实错误或虚构内容），现有方法通常只关注单一类型的不确定性，忽略了不同不确定性来源之间的互补性。", "method": "提出HaluNet框架，结合语义嵌入与概率置信度和分布不确定性，通过多分支架构自适应融合模型已知信息与输出中的不确定性表达。", "result": "在SQuAD、TriviaQA和Natural Questions数据集上的实验显示，HaluNet具有强大的检测性能和良好的计算效率，无论是否访问上下文。", "conclusion": "HaluNet展示了在基于LLM的QA系统中进行实时幻觉检测的潜力，通过有效整合多源不确定性信息提升检测效果。"}}
{"id": "2512.24572", "pdf": "https://arxiv.org/pdf/2512.24572", "abs": "https://arxiv.org/abs/2512.24572", "authors": ["Hongseok Oh", "Wonseok Hwang", "Kyoung-Woon On"], "title": "Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models' legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at https://github.com/lbox-kr/kcl.", "AI": {"tldr": "KCL是韩国规范法律基准，用于评估语言模型的法律推理能力，包含选择题和开放式问答两部分，通过提供问题级别的支持判例来分离推理能力与领域知识。", "motivation": "现有基准难以区分语言模型的法律推理能力和参数化知识，需要开发一个能够更准确评估纯粹法律推理能力的基准。", "method": "构建包含283个选择题（KCL-MCQA）和169个开放式问题（KCL-Essay）的数据集，每个问题都配有相关判例支持，并使用2739个评分标准进行自动评估。", "result": "对30多个模型的系统评估显示，在法律推理任务上仍存在较大差距，特别是在开放式问答方面，专门用于推理的模型表现优于通用模型。", "conclusion": "KCL基准有效评估了语言模型的法律推理能力，揭示了当前模型的局限性，并为未来研究提供了有价值的资源和评估框架。"}}
{"id": "2512.24574", "pdf": "https://arxiv.org/pdf/2512.24574", "abs": "https://arxiv.org/abs/2512.24574", "authors": ["Zhenyu Zhang", "Xiaoxia Wu", "Zhongzhu Zhou", "Qingyang Wu", "Yineng Zhang", "Pragaash Ponnusamy", "Harikaran Subbaraj", "Jue Wang", "Shuaiwen Leon Song", "Ben Athiwaratkun"], "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct cognitive behaviors such as verification and backtracking. By lightly intervening on these heads at inference time, we can steer the model away from inefficient modes. Building on this insight, we propose CREST, a training-free method for Cognitive REasoning Steering at Test-time. CREST has two components: (1) an offline calibration step that identifies cognitive heads and derives head-specific steering vectors, and (2) an inference-time procedure that rotates hidden representations to suppress components along those vectors. CREST adaptively suppresses unproductive reasoning behaviors, yielding both higher accuracy and lower computational cost. Across diverse reasoning benchmarks and models, CREST improves accuracy by up to 17.5% while reducing token usage by 37.6%, offering a simple and effective pathway to faster, more reliable LLM reasoning.", "AI": {"tldr": "CREST是一种无需训练的方法，通过识别和干预语言模型中的特定注意力头来优化推理过程，提高准确性同时减少计算成本。", "motivation": "大型语言模型在复杂任务中依赖长链推理，但常出现效率低下、延迟高、推理不稳定（思维不足或过度思考）的问题。", "method": "CREST包含两个组件：(1)离线校准步骤识别认知头并推导头特定的转向向量；(2)推理时过程旋转隐藏表示以抑制这些向量上的组件。", "result": "在多样化推理基准和模型上，CREST将准确率提高达17.5%，同时减少37.6%的token使用量。", "conclusion": "CREST提供了一种简单有效的途径，实现更快、更可靠的LLM推理，通过自适应抑制非生产性推理行为。"}}
{"id": "2512.24661", "pdf": "https://arxiv.org/pdf/2512.24661", "abs": "https://arxiv.org/abs/2512.24661", "authors": ["Casey O. Barkan", "Sid Black", "Oliver Sourbut"], "title": "Do Large Language Models Know What They Are Capable Of?", "categories": ["cs.CL", "cs.AI"], "comment": "23 pages, 8 figures", "summary": "We investigate whether large language models (LLMs) can predict whether they will succeed on a given task and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLMs generally do not have greater discriminatory power, though Claude models do show such a trend. On multi-step agentic tasks, the overconfidence of several frontier LLMs worsens as they progress through the tasks, and reasoning LLMs perform comparably to or worse than non-reasoning LLMs. With in-context experiences of failure, some but not all LLMs reduce their overconfidence leading to significantly improved decision making, while others do not. Interestingly, all LLMs' decisions are approximately rational given their estimated probabilities of success, yet their overly-optimistic estimates result in poor decision making. These results suggest that current LLM agents are hindered by their lack of awareness of their own capabilities. We discuss the implications of LLMs' awareness of their capabilities for AI misuse and misalignment risks.", "AI": {"tldr": "大型语言模型在预测自身任务成功率方面存在过度自信问题，但大多数模型具有优于随机的判别能力。随着任务进展，前沿模型的过度自信会加剧，部分模型能从失败经验中学习改进决策，但整体上仍因能力认知不足而影响决策质量。", "motivation": "研究大型语言模型是否能预测自身任务成功率，以及在多步任务中预测能力是否会改善，探索模型能否从上下文经验中学习以在失败代价高的场景中做出更好的决策选择。", "method": "测试多种大型语言模型，评估其预测任务成功的判别能力，分析模型在多步任务中的自信度变化，研究模型在获得失败经验后的决策改进情况。", "result": "所有测试的LLM都表现出过度自信，但大多数具有优于随机的判别能力；新增大模型不一定有更好判别力；多步任务中前沿LLM过度自信加剧；部分模型能从失败经验中降低过度自信并改进决策；所有LLM的决策在给定其估计概率下近似理性，但过于乐观的估计导致决策不佳。", "conclusion": "当前LLM智能体因缺乏对自身能力的认知而受到限制，研究结果对AI滥用和错位风险具有重要启示意义。"}}
{"id": "2512.24618", "pdf": "https://arxiv.org/pdf/2512.24618", "abs": "https://arxiv.org/abs/2512.24618", "authors": ["Junru Lu", "Jiarui Qin", "Lingfeng Qiao", "Yinghui Li", "Xinyi Dai", "Bo Ke", "Jianfeng He", "Ruizhi Qiao", "Di Yin", "Xing Sun", "Yunsheng Wu", "Yinsong Liu", "Shuangyin Liu", "Mingkong Tang", "Haodong Lin", "Jiayi Kuang", "Fanxu Meng", "Xiaojuan Tang", "Yunjia Xi", "Junjie Huang", "Haotong Yang", "Zhenyi Shen", "Yangning Li", "Qianwen Zhang", "Yifei Yu", "Siyu An", "Junnan Dong", "Qiufeng Wang", "Jie Wang", "Keyu Chen", "Wei Wen", "Taian Guo", "Zhifeng Shen", "Daohai Yu", "Jiahao Li", "Ke Li", "Zongyi Li", "Xiaoyu Tan"], "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "categories": ["cs.CL"], "comment": "57 pages, 26 figures", "summary": "We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities. The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window. This design enables robust long-context reasoning and state tracking within a minimal memory footprint, making it ideal for long-horizon agent and reasoning tasks. (2) Principled \"Commonsense-STEM-Agent\" Curriculum: We curated a massive corpus of approximately 11T tokens and implemented a multi-stage training strategy. By progressively shifting the pre-training data distribution from general commonsense to complex STEM and agentic tasks, we ensure the model acquires deep cognitive abilities rather than superficial alignment. (3) Scalable Agentic Mid-training: Specifically for the agentic mid-training, we employ diverse data construction schemes to synthesize rich and varied trajectories across math, coding, and tool-use domains. This high-quality data enables the model to internalize planning and reflection behaviors effectively. Extensive evaluations show that Youtu-LLM sets a new state-of-the-art for sub-2B LLMs. On general benchmarks, it achieves competitive performance against larger models, while on agent-specific tasks, it significantly surpasses existing SOTA baselines, demonstrating that lightweight models can possess strong intrinsic agentic capabilities.", "AI": {"tldr": "Youtu-LLM是一个1.96B参数的轻量级语言模型，通过从零开始预训练实现高效计算与原生智能的平衡，在长上下文推理和智能体任务上表现优异。", "motivation": "解决现有小模型依赖知识蒸馏而缺乏原生推理能力的问题，旨在开发一个既轻量又具备强大认知和规划能力的语言模型。", "method": "采用密集多潜在注意力架构和STEM导向词汇表支持128k长上下文；使用11T token的多阶段训练策略，从常识到复杂STEM和智能体任务逐步过渡；通过多样化的数据构建方案进行智能体中期训练。", "result": "在sub-2B LLMs中达到新的SOTA水平，在通用基准测试中与更大模型竞争，在智能体特定任务中显著超越现有基准，证明轻量模型具备强大内在智能能力。", "conclusion": "Youtu-LLM展示了轻量级模型通过系统化训练可以获得强大的推理和规划能力，为资源受限环境下的智能体应用提供了有效解决方案。"}}
{"id": "2512.24684", "pdf": "https://arxiv.org/pdf/2512.24684", "abs": "https://arxiv.org/abs/2512.24684", "authors": ["Maoyuan Li", "Zhongsheng Wang", "Haoyuan Li", "Jiamou Liu"], "title": "R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory", "categories": ["cs.CL", "cs.AI"], "comment": "Accepteed by AAMAS 2026 full paper", "summary": "We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.", "AI": {"tldr": "R-Debater是一个基于论证记忆的智能辩论框架，通过检索先前的辩论知识和角色代理生成多轮一致且证据充分的辩论内容，在单轮和多轮辩论任务中均优于大型语言模型基线。", "motivation": "现有辩论系统缺乏持续一致的论证记忆和证据支持，难以在长对话中保持立场一致性和论证质量，需要结合检索基础和结构化规划来提升辩论的忠实性和连贯性。", "method": "基于修辞学和记忆研究，构建包含案例证据和辩论动作的知识库，使用基于角色的代理检索和适配先前论证，通过InspireScore和Debatrix进行主观、逻辑、事实和论证质量评估。", "result": "在ORCHID辩论数据集上，R-Debater在单轮和多轮辩论任务中均获得更高分数，人类评估证实其具有更好的立场一致性、证据使用和跨轮次连贯性。", "conclusion": "结合检索基础和结构化规划的R-Debater框架能够生成更忠实、立场一致且连贯的多轮辩论，证明了论证记忆在提升辩论质量中的重要性。"}}
{"id": "2512.24825", "pdf": "https://arxiv.org/pdf/2512.24825", "abs": "https://arxiv.org/abs/2512.24825", "authors": ["Malvina Nissim", "Viviana Patti", "Beatrice Savoldi"], "title": "Practising responsibility: Ethics in NLP as a hands-on course", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As Natural Language Processing (NLP) systems become more pervasive, integrating ethical considerations into NLP education has become essential. However, this presents inherent challenges in curriculum development: the field's rapid evolution from both academia and industry, and the need to foster critical thinking beyond traditional technical training. We introduce our course on Ethical Aspects in NLP and our pedagogical approach, grounded in active learning through interactive sessions, hands-on activities, and \"learning by teaching\" methods. Over four years, the course has been refined and adapted across different institutions, educational levels, and interdisciplinary backgrounds; it has also yielded many reusable products, both in the form of teaching materials and in the form of actual educational products aimed at diverse audiences, made by the students themselves. By sharing our approach and experience, we hope to provide inspiration for educators seeking to incorporate social impact considerations into their curricula.", "AI": {"tldr": "介绍了一门NLP伦理课程的教学方法，通过互动式学习、实践活动和\"以教促学\"的方式，将伦理考量融入NLP教育，并在多机构、多教育层次中成功实施。", "motivation": "随着NLP系统日益普及，将伦理考量纳入NLP教育变得至关重要，但面临课程开发的挑战：领域快速发展和需要培养超越传统技术培训的批判性思维。", "method": "采用基于主动学习的教学方法，包括互动式课程、动手实践活动和\"以教促学\"的方法，课程经过四年在不同机构、教育层次和跨学科背景下的不断改进和调整。", "result": "课程成功实施并产生许多可重用产品，包括教学材料和由学生制作的实际教育产品，面向不同受众。", "conclusion": "通过分享该方法与经验，为教育工作者将社会影响考量纳入课程提供启发和参考。"}}
{"id": "2512.24848", "pdf": "https://arxiv.org/pdf/2512.24848", "abs": "https://arxiv.org/abs/2512.24848", "authors": ["Srija Mukhopadhyay", "Sathwik Reddy", "Shruthi Muthukumar", "Jisun An", "Ponnurangam Kumaraguru"], "title": "PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 2 figures", "summary": "Personalized AI agents rely on access to a user's digital footprint, which often includes sensitive data from private emails, chats and purchase histories. Yet this access creates a fundamental societal and privacy risk: systems lacking social-context awareness can unintentionally expose user secrets, threatening digital well-being. We introduce PrivacyBench, a benchmark with socially grounded datasets containing embedded secrets and a multi-turn conversational evaluation to measure secret preservation. Testing Retrieval-Augmented Generation (RAG) assistants reveals that they leak secrets in up to 26.56% of interactions. A privacy-aware prompt lowers leakage to 5.12%, yet this measure offers only partial mitigation. The retrieval mechanism continues to access sensitive data indiscriminately, which shifts the entire burden of privacy preservation onto the generator. This creates a single point of failure, rendering current architectures unsafe for wide-scale deployment. Our findings underscore the urgent need for structural, privacy-by-design safeguards to ensure an ethical and inclusive web for everyone.", "AI": {"tldr": "PrivacyBench基准测试显示，当前RAG助手在26.56%的交互中会泄露用户隐私，即使使用隐私提示也只能降低到5.12%，暴露了现有架构的安全缺陷", "motivation": "个性化AI代理需要访问用户数字足迹，但缺乏社会语境意识的系统可能无意中暴露用户敏感信息，威胁数字福祉", "method": "引入PrivacyBench基准，包含社会基础数据集和嵌入式秘密，通过多轮对话评估来测量隐私保护能力，测试RAG助手", "result": "RAG助手在高达26.56%的交互中泄露秘密，隐私感知提示将泄漏率降至5.12%，但检索机制仍会无差别访问敏感数据", "conclusion": "当前架构存在单点故障，需要结构化的隐私设计保护措施，以确保构建道德和包容的网络环境"}}
{"id": "2512.24693", "pdf": "https://arxiv.org/pdf/2512.24693", "abs": "https://arxiv.org/abs/2512.24693", "authors": ["Wenzhe Li", "Shujian Zhang", "Wenxuan Zhou", "John Lambert", "Chi Jin", "Andrew Hard", "Rajiv Mathews", "Lun Wang"], "title": "MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models", "categories": ["cs.CL"], "comment": null, "summary": "Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \\textit{training} techniques, effective automated \\textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \\textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \\textbf{MU}lti-\\textbf{S}tep \\textbf{I}nstruction \\textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.", "AI": {"tldr": "MUSIC是一种无监督数据增强策略，通过合成多轮对话对比对来训练更强大的多轮奖励模型，在保持单轮基准性能的同时显著提升多轮对话评估质量。", "motivation": "当前多轮对话评估主要依赖昂贵的人工评估，标准偏好数据集仅基于最终轮次对比，无法捕捉多轮互动的细微差别，需要更有效的自动化评估方法。", "method": "提出MUSIC无监督数据增强策略，合成跨越多个轮次的对比对话对，基于Skywork偏好数据集在Gemma-2-9B-Instruct模型上训练多轮奖励模型。", "result": "MUSIC增强的奖励模型在多项评估中优于基线方法，与先进专有LLM评判的多轮对话判断更加一致，且不影响标准单轮基准性能。", "conclusion": "多轮对比对对于构建鲁棒的多轮奖励模型至关重要，MUSIC方法为多轮对话评估提供了可扩展且有效的解决方案。"}}
{"id": "2512.24863", "pdf": "https://arxiv.org/pdf/2512.24863", "abs": "https://arxiv.org/abs/2512.24863", "authors": ["Steven Bird"], "title": "Big AI is accelerating the metacrisis: What can we do?", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "9 pages, 1 figure", "summary": "The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.", "AI": {"tldr": "论文批判当前AI和大语言模型加剧生态、意义和语言危机，呼吁语言工程师转向以人为本、生态友好的NLP发展方向", "motivation": "当前世界面临生态、意义和语言三重危机，大AI技术正在加速这些危机。语言工程师继续追求不可持续的可扩展性，为权贵阶层服务，仿佛技术发展是价值中立的，这种状况急需改变", "method": "通过批判性分析和呼吁，提出需要探索替代方案，运用集体智慧重新设计NLP发展方向", "result": "提出了从当前危机状态转向以人类繁荣和地球生命为中心的新NLP发展范式", "conclusion": "迫切需要语言工程师放弃当前不可持续的发展模式，共同设计一个肯定生命、以人类在地球上繁荣发展为中心的NLP未来"}}
{"id": "2512.24733", "pdf": "https://arxiv.org/pdf/2512.24733", "abs": "https://arxiv.org/abs/2512.24733", "authors": ["Sibo Wei", "Peng Chen", "Lifeng Dong", "Yin Luo", "Lei Wang", "Peng Zhang", "Wenpeng Lu", "Jianbin Guo", "Hongjun Yang", "Dajun Zeng"], "title": "BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature", "categories": ["cs.CL"], "comment": null, "summary": "Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.", "AI": {"tldr": "BIOME-Bench：首个用于评估大语言模型在多组学分析中生物分子交互推断和通路机制阐释能力的标准化基准测试", "motivation": "多组学研究依赖通路富集分析，但现有方法存在通路资源的结构性限制，且缺乏标准化的端到端多组学通路机制阐释评估基准", "method": "通过四阶段严谨工作流程构建BIOME-Bench基准，开发评估协议，对多个当代强模型进行综合实验评估两个核心能力", "result": "实验结果表明现有模型在多组学分析中存在显著缺陷，难以可靠区分细粒度生物分子关系类型，也无法生成忠实稳健的通路层面机制解释", "conclusion": "需要开发更专门的多组学分析能力评估基准，现有大语言模型在多组学通路机制阐释方面仍需重大改进"}}
{"id": "2512.24867", "pdf": "https://arxiv.org/pdf/2512.24867", "abs": "https://arxiv.org/abs/2512.24867", "authors": ["Yiming Liang", "Yizhi Li", "Yantao Du", "Ge Zhang", "Jiayi Zhou", "Yuchen Wu", "Yinzhu Piao", "Denghui Cao", "Tong Sun", "Ziniu Li", "Li Du", "Bo Lei", "Jiaheng Liu", "Chenghua Lin", "Zhaoxiang Zhang", "Wenhao Huang", "Jiajun Zhang"], "title": "Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution--reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs' comprehensive understanding over multiple fine-grained disciplinary knowledge statements.", "AI": {"tldr": "Encyclo-K是一个基于知识陈述的动态评估基准，通过从权威教科书提取独立知识陈述并在测试时随机组合成问题，解决了现有基准的数据污染、单知识点评估和专家标注成本高的问题。", "motivation": "现有基准主要存在三个根本限制：易受数据污染、仅限于单知识点评估、依赖昂贵的领域专家标注。需要重新思考基准构建方式来解决这些问题。", "method": "从权威教科书提取独立知识陈述作为基本单元，在测试时通过随机抽样动态组合成评估问题（每个问题聚合8-10个陈述），标注者只需验证格式合规性而无需领域专业知识。", "result": "在50多个大语言模型上测试显示，Encyclo-K具有强区分力，最佳模型OpenAI-GPT-5.1仅达到62.07%准确率，推理模型准确率16.04%-62.07%，聊天模型9.71%-50.40%。", "conclusion": "Encyclo-K通过动态评估和多陈述综合理解引入显著挑战，建立了可扩展的框架来评估LLMs对多细粒度学科知识陈述的综合理解能力。"}}
{"id": "2512.24772", "pdf": "https://arxiv.org/pdf/2512.24772", "abs": "https://arxiv.org/abs/2512.24772", "authors": ["Mohammad Zia Ur Rehman", "Velpuru Navya", "Sanskar", "Shuja Uddin Qureshi", "Nagendra Kumar"], "title": "Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection", "categories": ["cs.CL"], "comment": null, "summary": "Detecting depression from social media text is still a challenging task. This is due to different language styles, informal expression, and the lack of annotated data in many languages. To tackle these issues, we propose, Semi-SMDNet, a strong Semi-Supervised Multilingual Depression detection Network. It combines teacher-student pseudo-labelling, ensemble learning, and augmentation of data. Our framework uses a group of teacher models. Their predictions come together through soft voting. An uncertainty-based threshold filters out low-confidence pseudo-labels to reduce noise and improve learning stability. We also use a confidence-weighted training method that focuses on reliable pseudo-labelled samples. This greatly boosts robustness across languages. Tests on Arabic, Bangla, English, and Spanish datasets show that our approach consistently beats strong baselines. It significantly reduces the performance gap between settings that have plenty of resources and those that do not. Detailed experiments and studies confirm that our framework is effective and can be used in various situations. This shows that it is suitable for scalable, cross-language mental health monitoring where labelled resources are limited.", "AI": {"tldr": "提出了Semi-SMDNet半监督多语言抑郁症检测网络，通过教师-学生伪标签、集成学习和数据增强技术，在标注数据有限的情况下有效提升多语言抑郁症检测性能", "motivation": "社交媒体文本抑郁症检测面临语言风格差异、非正式表达以及多语言标注数据缺乏的挑战", "method": "使用教师模型组进行软投票集成，基于不确定性的阈值过滤低置信度伪标签，采用置信度加权训练方法专注于可靠样本", "result": "在阿拉伯语、孟加拉语、英语和西班牙语数据集上均超越强基线，显著缩小资源丰富与匮乏设置间的性能差距", "conclusion": "该框架适用于标注资源有限的可扩展跨语言心理健康监测，在各种情况下都表现出有效性"}}
{"id": "2512.24880", "pdf": "https://arxiv.org/pdf/2512.24880", "abs": "https://arxiv.org/abs/2512.24880", "authors": ["Zhenda Xie", "Yixuan Wei", "Huanqi Cao", "Chenggang Zhao", "Chengqi Deng", "Jiashi Li", "Damai Dai", "Huazuo Gao", "Jiang Chang", "Liang Zhao", "Shangyan Zhou", "Zhean Xu", "Zhengyan Zhang", "Wangding Zeng", "Shengding Hu", "Yuqing Wang", "Jingyang Yuan", "Lean Wang", "Wenfeng Liang"], "title": "mHC: Manifold-Constrained Hyper-Connections", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.", "AI": {"tldr": "论文提出Manifold-Constrained Hyper-Connections (mHC)框架，通过在特定流形上投影超连接残差空间来恢复恒等映射特性，解决现有超连接方法导致的训练不稳定性和可扩展性限制问题。", "motivation": "现有的超连接方法虽然提升了性能，但破坏了残差连接的恒等映射特性，导致训练不稳定、可扩展性受限以及显著的内存访问开销。", "method": "提出mHC框架，将超连接的残差连接空间投影到特定流形上以恢复恒等映射特性，并进行严格的基础设施优化以确保效率。", "result": "实证实验表明mHC能够有效支持大规模训练，提供显著的性能改进和优越的可扩展性。", "conclusion": "mHC作为超连接的灵活实用扩展，有助于深入理解拓扑架构设计，为基础模型的演进指明了有前景的方向。"}}
{"id": "2512.24776", "pdf": "https://arxiv.org/pdf/2512.24776", "abs": "https://arxiv.org/abs/2512.24776", "authors": ["Ákos Prucs", "Márton Csutora", "Mátyás Antal", "Márk Marosi"], "title": "Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with generating long reasoning sequences. For industrial applications, model selection depends not only on raw accuracy but also on resource constraints and inference costs. In this work, we conduct a test-time-compute aware evaluation of both contemporary and older open-source LLMs, mapping their Pareto frontiers across math- and reasoning-intensive benchmarks. Our findings identify the Mixture of Experts (MoE) architecture as a strong candidate to balance performance and efficiency in our evaluation setting. Furthermore, we trace the trajectory of Pareto efficiency over time to derive an emergent trend regarding accuracy gain per unit of compute. Finally, we demonstrate that there is a saturation point for inference-time compute. Beyond a certain threshold, accuracy gains diminish, indicating that while extended reasoning capabilities are beneficial, they cannot overcome intrinsic model limitations regarding specific complexities.", "AI": {"tldr": "该论文研究了LLMs在推理任务中的计算效率问题，发现专家混合(MoE)架构在性能和效率间表现最佳，同时指出推理计算存在饱和点，超过阈值后准确率增益递减。", "motivation": "当前文献往往忽视了生成长推理序列带来的显著计算负担，而工业应用不仅需要高准确率，还需要考虑资源约束和推理成本。", "method": "对当代和早期开源LLMs进行测试时计算感知评估，绘制在数学和推理密集型基准测试中的帕累托前沿。", "result": "发现MoE架构在评估设置中是平衡性能和效率的有力候选方案，并推导出每单位计算精度增益的涌现趋势，证明推理计算存在饱和点。", "conclusion": "虽然扩展推理能力有益，但无法克服模型在特定复杂性方面的内在限制，超过一定计算阈值后准确率增益会递减。"}}
{"id": "2512.24997", "pdf": "https://arxiv.org/pdf/2512.24997", "abs": "https://arxiv.org/abs/2512.24997", "authors": ["Luis Adrián Cabrera-Diego"], "title": "Classifying long legal documents using short random chunks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.", "AI": {"tldr": "基于DeBERTa V3和LSTM的法律文档分类器，使用随机选取的48个短文本块（最多128个token）作为输入，解决了长文档处理难题，加权F-score达0.898，CPU处理中位时间为每100文件498秒。", "motivation": "法律文档专业词汇多且篇幅长，直接使用Transformer模型进行分类可能不可行、昂贵或缓慢，需要解决长文档处理的技术挑战。", "method": "结合DeBERTa V3和LSTM模型，输入为随机选择的48个短文本块（每块最多128个token），并使用Temporal构建可靠的部署流水线。", "result": "最佳模型获得0.898的加权F-score，在CPU上运行的流水线处理100个文件的中位时间为498秒。", "conclusion": "该方法有效解决了长法律文档的分类问题，通过分块处理和模型组合实现了高性能分类，部署流水线确保了处理流程的可靠性和鲁棒性。"}}
{"id": "2512.25026", "pdf": "https://arxiv.org/pdf/2512.25026", "abs": "https://arxiv.org/abs/2512.25026", "authors": ["Nasim Borazjanizadeh", "James McClelland"], "title": "Modeling Language as a Sequence of Thoughts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level \"thought\" states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG's loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.", "AI": {"tldr": "提出了Thought Gestalt模型，这是一个双层次的循环Transformer，在token和句子级别的\"思想\"状态两个抽象层次上建模语言，通过跨注意力机制处理先前句子表征，提高了数据效率和关系方向泛化能力。", "motivation": "当前Transformer语言模型主要依赖表层共现统计，缺乏对实体和事件的全局一致性潜在表征，导致关系方向脆弱性、上下文错误和数据效率低下。受人类认知过程中将语言输入转换为紧凑的事件表征的启发。", "method": "引入Thought Gestalt模型：1) 使用相同参数集生成token和句子表征；2) 采用单一目标函数（下一个token的交叉熵）；3) 通过保留写入记忆的句子表征计算图，使梯度从未来token损失通过跨注意力反向传播；4) 每次生成一个句子的token，同时跨注意力关注先前句子表征记忆。", "result": "1) 在扩展实验中持续优于匹配的GPT-2基准；2) 缩放拟合表明GPT-2需要多5-8%的数据和33-42%的参数才能达到TG的损失水平；3) 在父子关系反转诅咒探测任务上减少了关系方向泛化错误。", "conclusion": "Thought Gestalt模型通过引入句子级别的思想状态表征，有效解决了传统Transformer在全局一致性表征方面的局限性，显著提升了数据效率和关系推理能力，为语言模型提供了更接近人类认知过程的建模方式。"}}
{"id": "2512.24842", "pdf": "https://arxiv.org/pdf/2512.24842", "abs": "https://arxiv.org/abs/2512.24842", "authors": ["Yanan Long"], "title": "Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability", "categories": ["cs.CL", "stat.ML"], "comment": "NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "summary": "Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \\emph{causal} standard: claims must survive causal interventions and must \\emph{cross-reference} across environments that perturb surface form while preserving meaning. We formalize \\emph{reference families} as predicate-preserving variants and introduce \\emph{triangulation}, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \\emph{accept or reject} those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.", "AI": {"tldr": "本文提出了一个因果标准的机制解释方法——三角验证法，用于验证多语言模型在不同语言环境下的行为一致性，通过必要性、充分性和不变性三个标准来过滤虚假的电路发现。", "motivation": "多语言模型在聚合性能上表现良好，但在不同语言、文字和文化中的行为不可预测，需要因果机制解释来确保模型行为的跨语言一致性。", "method": "引入参考家族作为谓词保持变体，提出三角验证法：必要性（消融电路会降低目标行为）、充分性（激活补丁能传递行为）和不变性（在参考家族中效果保持方向和幅度稳定）。采用自动电路发现并提供候选子图，通过三角验证接受或拒绝候选。", "result": "三角验证提供了一个可证伪的机制声明标准，能够过滤掉通过单环境测试但在跨语言不变性上失败的虚假电路。", "conclusion": "三角验证法为多语言模型的机制解释建立了因果标准，通过跨环境验证确保模型行为的鲁棒性和可解释性，推动了实用可解释性议程的发展。"}}
{"id": "2512.25052", "pdf": "https://arxiv.org/pdf/2512.25052", "abs": "https://arxiv.org/abs/2512.25052", "authors": ["Chao Peng", "Bin Wang", "Zhilei Long", "Jinfang Sheng"], "title": "AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Preprint. Under review", "summary": "Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.", "AI": {"tldr": "AdaGReS是一个用于检索增强生成的冗余感知上下文选择框架，通过结合查询-语块相关性和集合内冗余惩罚的集合级目标优化，在token预算约束下执行贪婪选择，无需手动调参即可适应候选池统计和预算限制。", "motivation": "标准top-k检索在检索增强生成中经常返回冗余或近似重复的语块，浪费token预算并降低下游生成质量。", "method": "提出AdaGReS框架，使用基于边际增益的贪婪选择方法，引入封闭式实例自适应校准来平衡相关性和冗余性，理论分析显示该目标具有ε近似子模性。", "result": "在开放域问答和生物医学语料库上的实验显示，AdaGReS在冗余控制和上下文质量方面持续改进，带来更好的端到端答案质量和鲁棒性。", "conclusion": "AdaGReS通过优化集合级目标有效解决了RAG中的冗余问题，提供了理论保证和实际性能提升，为token预算受限的检索增强生成提供了有效的解决方案。"}}
{"id": "2512.24885", "pdf": "https://arxiv.org/pdf/2512.24885", "abs": "https://arxiv.org/abs/2512.24885", "authors": ["Hengli Li", "Zhaoxin Yu", "Qi Shen", "Chenxi Li", "Mengmeng Wang", "Tinglang Wu", "Yipeng Kang", "Yuxuan Wang", "Song-Chun Zhu", "Zixia Jia", "Zilong Zheng"], "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts", "categories": ["cs.CL", "cs.GT", "cs.MA"], "comment": "Accepted by AAMAS 2026", "summary": "Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.", "AI": {"tldr": "BEDA框架通过将信念估计作为生成约束，在战略对话中显著提升了对话成功率，在对抗性、合作性和协商性对话场景中均优于基线方法", "motivation": "现有工作虽然能准确估计信念，但缺乏在生成过程中使用这些信念的原则性机制，需要填补这一空白", "method": "首先形式化了对抗和对齐两个核心对话行为，通过概率约束实现这些行为，构建了包含世界集合、信念估计器和条件生成器的BEDA框架", "result": "在三个设置中均表现优异：CKBG中成功率提升至少5.0点（GPT-4.1-nano提升20.6点）；Mutual Friends平均提升9.3点；CaSiNo达到最优交易结果", "conclusion": "将信念估计作为约束提供了一种简单通用的机制，能够实现可靠的战略对话"}}
{"id": "2512.24933", "pdf": "https://arxiv.org/pdf/2512.24933", "abs": "https://arxiv.org/abs/2512.24933", "authors": ["Minjun Zhao", "Xinyu Zhang", "Shuai Zhang", "Deyang Li", "Ruifeng Shi"], "title": "Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter-step dependencies. Existing end-to-end prompt optimization methods struggle under these conditions and often yield suboptimal or unstable updates. We propose ADOPT, an Adaptive Dependency-aware Prompt Optimization framework for multi-step LLM pipelines. ADOPT explicitly models the dependency between each LLM step and the final task outcome, enabling precise text-gradient estimation analogous to computing analytical derivatives. It decouples textual gradient estimation from gradient updates, reducing multi-prompt optimization to flexible single-prompt optimization steps, and employs a Shapley-based mechanism to adaptively allocate optimization resources. Experiments on real-world datasets and diverse pipeline structures show that ADOPT is effective and robust, consistently outperforming state-of-the-art prompt optimization baselines.", "AI": {"tldr": "ADOPT框架：一种针对多步LLM管道的自适应依赖感知提示优化方法，通过显式建模步骤间依赖关系和Shapley值资源分配，有效解决了多提示联合优化的难题", "motivation": "多步LLM管道的性能严重依赖各步骤的提示词质量，但由于缺乏步骤级监督和步骤间依赖关系，现有的端到端提示优化方法往往产生次优或不稳定的更新", "method": "提出ADOPT框架：1)显式建模每个LLM步骤与最终任务结果的依赖关系；2)将文本梯度估计与梯度更新解耦；3)基于Shapley值的机制自适应分配优化资源", "result": "在真实数据集和多样化管道结构上的实验表明，ADOPT方法有效且鲁棒，始终优于最先进的提示优化基线方法", "conclusion": "ADOPT通过模拟分析导数的方式精确估计文本梯度，将多提示优化简化为灵活的单提示优化步骤，为多步LLM管道的提示优化提供了有效的解决方案"}}
{"id": "2512.25015", "pdf": "https://arxiv.org/pdf/2512.25015", "abs": "https://arxiv.org/abs/2512.25015", "authors": ["Siddhant Agarwal", "Adya Dhuler", "Polly Ruhnke", "Melvin Speisman", "Md Shad Akhtar", "Shweta Yadav"], "title": "MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes", "categories": ["cs.CL"], "comment": "Accepted by AAAI 2026", "summary": "Over the past years, memes have evolved from being exclusively a medium of humorous exchanges to one that allows users to express a range of emotions freely and easily. With the ever-growing utilization of memes in expressing depressive sentiments, we conduct a study on identifying depressive symptoms exhibited by memes shared by users of online social media platforms. We introduce RESTOREx as a vital resource for detecting depressive symptoms in memes on social media through the Large Language Model (LLM) generated and human-annotated explanations. We introduce MAMAMemeia, a collaborative multi-agent multi-aspect discussion framework grounded in the clinical psychology method of Cognitive Analytic Therapy (CAT) Competencies. MAMAMemeia improves upon the current state-of-the-art by 7.55% in macro-F1 and is established as the new benchmark compared to over 30 methods.", "AI": {"tldr": "RESTOREx是一个通过大语言模型生成和人工标注解释来检测社交媒体表情包中抑郁症状的资源，MAMAMemeia是一个基于认知分析疗法的多智能体多角度讨论框架，在抑郁症状检测方面比现有方法提升7.55%的macro-F1分数。", "motivation": "随着表情包在表达抑郁情绪方面的使用日益增多，需要研究如何识别在线社交媒体平台上用户分享的表情包中表现的抑郁症状。", "method": "引入RESTOREx资源，使用大语言模型生成和人工标注的解释；提出MAMAMemeia框架，基于认知分析疗法(CAT)能力的多智能体多角度讨论方法。", "result": "MAMAMemeia相比30多种现有方法提升了7.55%的macro-F1分数，成为新的基准。", "conclusion": "该研究为社交媒体表情包中的抑郁症状检测提供了有效的资源和框架，显著提升了检测性能。"}}
